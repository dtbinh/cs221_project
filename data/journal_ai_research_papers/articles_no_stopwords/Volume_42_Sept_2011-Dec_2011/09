journal artificial intelligence

submitted published

learning make predictions partially observable
environments without generative model
erik talvitie

erik talvitie fandm edu

mathematics computer science
franklin marshall college
lancaster pa usa

satinder singh

baveja umich edu

computer science engineering
university michigan
ann arbor mi usa

abstract
faced learning model high dimensional environment
common limit model make restricted set predictions thereby
simplifying learning partial may directly useful making
decisions may combined together form complete structured model however partially observable non markov environments standard model learning methods
learn generative e provide probability distribution possible futures pomdps straightforward restrict make
certain predictions simplify learning
present prediction profile non generative partial partially
observable systems make given set predictions therefore far simpler
generative cases formalize learning prediction
profile model transformation original model learning empirically one learn prediction profile make small set important
predictions even systems complex standard generative

introduction
learning model dynamics environment experience critical capability artificial agent agents learn make predictions future events
anticipate consequences actions use predictions plan
make better decisions agents environment complex however learning pose serious challenges one common dealing complex
environments learn partial focusing model learning making
restricted set particularly important predictions often predictions
need made much complexity dynamics modeled safely ignored sometimes partial model directly useful making decisions instance
model makes predictions agents future rewards e g see mccallum
mahmud cases many partial making restricted predictions
combined form complete model instance factored mdps boutilier
dean hanks factored psrs wolfe james singh collections
local talvitie singh b
c

ai access foundation rights reserved

fitalvitie singh

common learning partial model apply abstraction
whether learned supplied domain expert filters detail training data irrelevant making important predictions model learning methods
applied abstract data typically learning
tractable however especially case partially observable systems abstraction alone may sufficiently simplify learning even see
subsequent examples model asked make intuitively simple predictions
counter intuitive complexity learning partial model partially observable case
direct fact standard model learning approaches partially observable systems learn generative attempt make every possible prediction
future cannot straightforwardly restricted making particularly
important predictions
present alternative learns non generative
make specified predictions conditioned history following illustrative
example see sometimes small set predictions necessary
good control performance learning make predictions high dimensional
environment standard generative pose serious challenges contrast
see exists simple non generative model make maintain
predictions form learning target method
example
consider simple game three card monte dealer perhaps crowded street
three cards one ace dealer shows location ace flips
cards mixes swapping two cards every time step player
game must keep track location ace eventually dealer stops mixing
cards asks guess player correctly guesses ace win
money guess wrong lose money
consider artificial agent attempting learn model dynamics game
experience takes sequence actions perceives sequence observations
raw data received agent includes rich high dimensional scene including
activities crowd movement cars weather well game
dealer swapping cards clearly learning model encompasses complex
phenomena infeasible unnecessary order win game agent needs
focus making predictions cards need anticipate future behavior city scene around particular agent need make three predictions
flip card ace corresponding predictions cards
one safely ignore much detail agents experience still make
important predictions accurately one filters irrelevant detail agents
experience might look
bet pos watch swap watch swap
agent takes bet action starting game observes dealer showing
card position agent takes watch action observes dealer swapping
cards takes watch action observes dealer swapping cards


filearning make predictions without generative model

dealer prompts agent guess note uncontrolled
system watch indeed action agent must select say reaching
flipping cards real game three card monte would certainly
negative utility data reflects movement cards one could learn
model data set learning would far simpler
since complex irrelevant phenomena crowd weather ignored
markov case agent directly observes entire state environment
therefore learn make predictions direct function state abstraction simplifies
representation state thereby simplifies learning note however
three card monte partially observable non markov agent cannot
directly observe state environment location ace state
dealers mind hidden agent partially observable case agent
must learn maintain compact representation state well learn dynamics
state common methods achieve expectation maximization
em learning pomdps baum petrie soules weiss learn generative
provide probability distribution possible futures
three card monte even irrelevant details ignored data
contains information cards movement generative model still intractably complex generative model makes predictions future events
includes predictions model meant make whether flipping card
next time step reveal ace many irrelevant predictions generative
model predict instance whether flipping card time steps
reveal ace whether cards swapped next time step make
predictions model must capture dynamics cards
dealers decision making process dealer decides cards swap
complex process human dealer might learning generative model
abstract system correspondingly complex
course three card monte predicting dealers future behavior entirely
unnecessary win required maintain aces current location time
learning model devotes complexity anticipating dealers
decisions counter intuitive best far reasonable model seen figure
states model labeled predictions aces location
transitions labeled observations dealers behavior agent plays
game could use model maintain predictions location ace
time taking dealers behavior account predicting dealers future
behavior note non generative model provide distribution
possible futures cannot used simulate world
predict dealers next move provides limited set conditional predictions
future given history past actions observations hand
far simpler generative model would model dealers
decision making process model states regardless underlying process
used dealer
model figure example term prediction profile model
formalize prediction profile present learning
data assumptions specified established necessary


fitalvitie singh

figure maintaining predictions location ace three card monte transitions labeled dealers swaps states labeled predicted
position special card

terminology empirically demonstrate partially observable systems
prove complex standard generative model learning methods possible
learn prediction profile model makes small set important predictions allow
agent make good decisions next sections formally describe setting
establish notation terminology formalize general learning
addressed subsequent sections formally present prediction profile
learning well several relevant theoretical empirical
discrete dynamical systems
focus discrete dynamical systems agent finite set actions
take environment finite set observations produce every
time step agent chooses action ai environment stochastically emits
observation oi
definition time step sequence past actions observations since
beginning time hi ai oi called history time
history time zero agent taken actions seen observations
h called null history
predictions
agent uses model make conditional predictions future events given history actions observations given future behavior environment
assumed stochastic predictions probabilities future events primitive
building block used describe future events called test rivest schapire
littman sutton singh test simply sequence actions observations


filearning make predictions without generative model

could possibly occur ak ok agent actually takes action sequence
observes observation sequence say test succeeded prediction
p h probability test succeeds history h assuming agent takes
actions test essentially prediction test answer question
take particular sequence actions probability would see
particular sequence observations given history far formally
def

p h pr h pr ha pr ok ha ak ok ak



let set tests set possible action observation sequences
lengths set possible histories h set action observation
sequences could possibly occur starting null history null history
def
h p h h
model make prediction p h h h make
conditional prediction future littman et al represents
probability distribution futures model used sample
distribution order simulate world sample possible future trajectories
call model makes predictions generative model
note use word generative closely related broader sense
general density estimation one attempting represent conditional probability
distribution pr b generative would represent full joint distribution pr b conditional probabilities computed pr b
pr b
say generative model sense makes predictions even variables wish
condition non generative settings discriminitive would
instead directly represent conditional distribution taking value b un modeled
input non generative sometimes significant savings pr b
difficult represent learn pr b relatively simple long one truly
disinterested modeling joint distribution
particular setting generative model one provides probability distribution futures given agents actions one would use generative model

fact equation one
compute p h particular h p ht h
p h h
see prediction multi step test computed predictions
one step tests
p ak ok h p h p ha p ak ok ha ak ok
leads simple definition generative model
definition model provide predictions p ao h actions
observations histories h h generative model
non generative model would make one step predictions histories
consequently would directly represent prediction p h history h
un modeled input would condition given history necessarily capable
computing probability history sequence saw three card monte
example beneficial making maintaining predictions substantially
simpler making predictions every possible action observation sequence


fitalvitie singh

note test describes specific future event sequence specific actions
observations many cases one might wish make predictions abstract
events achieved composing predictions many tests instance set
tests wingate soni wolfe singh sequence actions set observation
sequences set test succeeds agent takes specified action sequence sees
observation sequence contained within set occur traditional tests allow
agent instance express question go outside probability see
exact sequence images set test express far useful abstract question
go outside probability sunny grouping together
observations sunny day even generally option tests wolfe singh soni
singh express future events agents behavior described abstractly
well resulting observations types abstract predictions computed
linear combination set concrete predictions
system dynamics matrix linear dimension
sometimes useful describe dynamical system conceptual object called
system dynamics matrix singh james rudary system dynamics matrix
contains values possible predictions therefore fully encodes dynamics
system specifically
definition system dynamics matrix dynamical system infinity infinity
matrix column corresponding every test row corresponding
every history h h ijth entry system dynamics matrix prediction
p tj hi test corresponding column j history corresponding row
entry every history test pair
though system dynamics matrix infinitely many entries many cases
finite rank rank system dynamics matrix thought measure
complexity system singh et al
definition linear dimension dynamical system rank corresponding
system dynamics matrix
popular modeling representations linear dimension major factor
complexity representing learning generative model system instance
pomdps number hidden states required represent system lower bounded
linear dimension work adopt linear dimension measure
complexity dynamical system say system simpler another
mean lower linear dimension
markov property
dynamical system markov one needs know history order make
predictions future events recent observation
definition system markov two histories h h may null
history two actions observation test p hao p h


filearning make predictions without generative model

markov case use notational shorthand p indicate prediction
history ends observation markov case observations
contain information needed make prediction future often
called state describe state world system markov
partially observable partially observable systems predictions depend arbitrarily
entire history focus partially observable case

learning make predictions
work assume three card monte though agent may live
complex environment small set important predictions make
predictions could identified important designer learning
process address identifying predictions made
rather focus learning make predictions identified
general imagine given finite set tm tests
interest would model make accurate predictions term
test construed broadly possibly including abstract tests addition raw
sequences actions observations tests interest future events model
predict instance three card monte order perform well
agent must predict whether see ace flips card
three one step tests interest f lip ace f lip ace f lip ace representing
future events agent flips card respectively sees ace
agent learn maintain probability events time win
game
general learn function h
def

h hp h p h p tm h



function histories predictions test interest refer
predictions interest history note output necessarily
probability distribution tests interest may selected arbitrarily therefore
need represent mutually exclusive exhaustive events call particular vector
predictions tests interest prediction profile
definition call h prediction profile history h
describe two existing general approaches learning learning direct function history predictions common markov case learning fully
generative model maintains finite dimensional summary history common
partially observable case strengths weaknesses approaches learning
section contrast combines strengths
approaches
direct function approximation
system markov learning conceptually straightforward essentially
learning function observation state predictions rather


fitalvitie singh

learning takes histories input one instead learn function arkov
maps observation predictions tests interest resulting
histories end observation note immediate consequence
discrete markov systems finite number distinct prediction profiles fact
distinct prediction profiles observations
number observations number tests interest small enough
arkov represented look table entries estimated
sample averages
p ti

times succeeds histories ending

times acts taken histories ending



main challenge learning markov arises number observations
large becomes necessary generalize across observations data gathered
one observation learn many others specifically one may able exploit
fact observations associated similar identical prediction
profiles predictions tests interest share data amongst
restricting attention predictions afford generalization
learning partial model beneficial markov setting
even system partially observable one still attempt learn directly
typically performing sort regression set features entire histories
instance u tree mccallum takes set history features learns decision tree
attempts distinguish histories different expected asymptotic return
optimal behavior wolfe barto apply u tree rather
restricting model predicting future rewards learn make predictions
pre selected set features next observation special case
general concept tests interest dinculescu precup learn expected value
given feature future direct function given real valued feature history
clustering futures histories similar associated values
directly approximate types make predictions
therefore non generative therefore able instance avoid falling
trap predicting dealers decisions three card monte though
demonstrated promise faces clear pragmatic challenge especially partially
observable setting feature selection function history ever expanding
sequence actions observations finding reasonable set compactly represented features collectively capture history information needed make predictions
interest significant challenge sense even partially observable setting
type takes small step away markov case still requires
good idea priori information extracted history form
features order make predictions interest
bowling mccracken james neufeld wilkinson showed estimator unbiased
case data collected blind policy action selection depend
history observations provided alternative estimator unbiased policies
simplicitys sake however assume throughout data gathering policy blind



filearning make predictions without generative model

generative
one good idea priori features extracted history
make accurate predictions one faces additional challenge learning summarize
relevant information history compact sufficient statistic
exist methods learn training data maintain finite dimensional
statistic history prediction computed analogy markov
case statistic called state vector clearly model maintain state
used compute since make predictions briefly mention two
examples particularly relevant development analysis
method
pomdps far popular representation partially observable
systems partially observable markov decision process pomdp monahan
pomdp posits underlying mdp puterman set hidden states
agent never observes given time step system particular hidden
state si unknown agent agent takes action ai system
transitions next state si according transition probability pr si si ai
observation oi emitted according probability distribution general
may depend upon si ai si pr oi si ai si
agent observe hidden states cannot know hidden
state system given moment agent however maintain probability
distribution represents agents current beliefs hidden state probability distribution called belief state belief state associated history h
known straightforward compute prediction test
x
p h
pr h pr
ss

pr computed transition observation emission probabilities
belief state finite summary history prediction
future computed belief state state vector pomdp given
transition probabilities observation emission probabilities possible maintain
belief state time bayes rule current history h one knows pr h
hidden states agent takes action observes observation one
compute probability hidden state history
p



pr h pr ai pr oi ai
p
pr hao p








pr h pr ai pr oi ai
parameters pomdp must learned order able maintain
state transition probabilities observation emission probabilities given
parameters belief state corresponding given history recursively computed
model thereby make prediction history pomdp parameters
typically learned expectation maximization em baum et al
given training data number actions observations hidden states
input em essentially performs gradient ascent transition emission distributions
locally maximize likelihood provided data


fitalvitie singh

psrs another recently introduced modeling representation predictive state
representation psr littman et al instead hidden states psrs defined
directly terms system dynamics matrix described section specifically
psrs set core tests q whose corresponding columns system dynamics matrix
form basis recall system dynamics matrix often finite rank instance
matrix associated pomdp finite hidden states finite linear dimension
thus q finite many systems interest since predictions q basis
prediction test history computed linear combination
predictions q history
vector predictions q called predictive state belief state
state vector pomdps predictive state state vector psrs
maintained application bayes rule specifically history h p q h
known core tests q agent takes action observes
observation one compute prediction core test q
history
p


p aoq h
q q p q h maoq q
p
p q hao





p ao h
q q p q h mao q
maoq q coefficient p q h linear combination computes
prediction p aoq h
given set core tests parameters psr must learned order
maintain state coefficients mao every action observation
coefficients maoq every action observation core tests q given parameters
predictive state given history recursively computed used make
prediction future psrs learned directly estimating system dynamics matrix james singh wolfe james singh recently
sub matrix derived matrix thereof boots siddiqi gordon sample
averages training data estimated matrix used set core tests
parameters estimated linear regression
note types inherently generative rely
upon maintenance state vector order make predictions
seen equations state update equations rely upon access
one step predictions perform bayesian update unlike direct function
approximation one cannot simply choose set predictions model
make necessity make predictions
many reasons desire complete generative model makes
possible predictions model used sample possible future trajectories
useful capability generative model definition flexible
predictions used make hand many cases complete
generative model may difficult obtain psr pomdp training methods scale
poorly linear dimension system learned linear dimension
lower bounds number hidden states needed represent system pomdp
precisely number core tests needed represent psr learning methods
pomdps psrs rarely successfully applied systems linear dimension


filearning make predictions without generative model

figure size ball bounce
hundred though work boots et al pushing limits
systems interest several orders magnitude higher linear dimension
furthermore complete generative model overkill hand recall
seek make predictions focused making particularly
important predictions even learning make predictions might
intractable still possible make simple important predictions
abstract generative
discussed earlier restricted set tests interest learning
often simplified ignoring irrelevant details abstraction course
abstraction solve partial observability typically done
apply abstraction training data discarding irrelevant details
three card monte example apply model learning methods
ones described abstract data set markov setting cases
observation abstraction greatly simplify learning certainly learning
cards three card monte easier learning cards crowd
weather
ignoring details irrelevant making predictions interest intuitive
significantly simplify learning hand generative
abstract pomdp psr still make abstract predictions typically
includes predictions directly interest extra predictions
require complex model even abstract generative model intractible learn
true three card monte example generative model ends modeling
dealer well cards following another simple example phenomenon
example consider uncontrolled system pictured figure called ball
bounce system agent observes strip pixels black white
black pixel represents position ball moves around strip ball
current direction every time step moves one pixel direction whenever
reaches edge pixel current direction changes move away edge figure
complete pomdp model pixel version system pictured
k pixels pomdp k hidden states ball one
possible directions one k possible positions except two ends
one possible direction
say agent wishes predict whether ball position marked
x next time step clearly prediction made paying
attention immediate neighborhood x details happens
ball far away matter making predictions one could apply


fitalvitie singh



b

figure pomdp model size ball bounce system abstracted
ball bounce system b

abstraction lumps together observations neighborhood x
looks abstract generative model system makes
predictions x pixels surrounding x specifically
model still makes predictions whether ball enter neighborhood near
future course depends long since ball left neighborhood
pomdp model abstract system pictured figure b exactly
state diagram original system though observations changed reflect
abstraction abstract system primitive system linear dimension
order make predictions x one must condition information
pixels surrounding x consequently generative model makes predictions
pixels counterintuitively abstract complexity mainly devoted making
predictions predictions interest general learning abstract
model drastically simplify learning ignoring irrelevant details abstract generative model still learns make predictions details relevant
even directly interest

prediction profile
contribution prediction profile seek combine main strengths
two model learning approaches discussed direct approximation
prediction profile model make predictions interest others
far simpler generative model typically make many
extraneous predictions however learning method prediction profile
require set history features given priori leveraging existing generative
model learning methods prediction profile learn maintain state information
necessary making predictions interest


filearning make predictions without generative model

figure prediction profile model ball bounce system
typical model learns make predictions future observations emitted
system main idea behind prediction profile instead model values
predictions change time conditioned actions chosen
agent observations emitted system
already seen example three card monte prediction profile
model shown figure takes observations dealers behavior input outputs
predictions tests interest predict dealers behavior takes
account updating predictions interest recall though three card
monte system arbitrarily complicated depending dealer prediction
profile system three states regardless dealers decision making process
another example shown figure prediction profile system
ball bounce system figure model must predict whether ball enter
position x next time step state prediction profile model labeled
prediction pixel x white black transitions labeled observations
pixel neighborhood centered position x case transitions capture ball
entering neighborhood moving position x leaving neighborhood staying away
undetermined amount time returning recall pomdp model
system k hidden states k number pixels even ignoring
pixels irrelevant making predictions pixel x contrast prediction profile
model three states regardless number pixels
next section formally describe prediction profile dynamical system transformation original system subsequent sections
discuss learn prediction profile data converting data
original system data transformed system learning model converted data set present help characterize conditions
prediction profile best applied

prediction profile system
formally describe theoretical dynamical system defined terms
dynamics original system given tests interest call constructed
system prediction profile system prediction profile model goal


fitalvitie singh

construct model prediction profile system system ideal
theoretical construct model may imperfect approximate etc analysis
learning prediction profile model depend great deal understanding
properties prediction profile system
make restrictive assumption markov case
finite number distinct prediction profiles predictions interest take
finite number distinct values certainly true partially observable
systems sets tests interest though true many interesting examples
formally assumption requires map histories finite set prediction profiles
assumption assume exists finite set prediction profiles p k
every history h h p
assumption allows definition prediction profile system p p short
discrete dynamical system captures sequence prediction profiles time
given action observation sequence prediction profile systems actions observations
dynamics defined terms quantities associated original system
definition prediction profile system defined set observations set
actions rule governing dynamics
observations set prediction profile observations op p defined set
def
distinct prediction profiles op p p k
actions set prediction profile actions ap p defined set actiondef
observation pairs original system ap p
dynamics dynamics prediction profile system deterministically governed prediction profile history ha ha haj oj ij
next p p action haj oj prediction profile system deterministically
emits p p observation aj oj aj oj
present key facts prediction profile system specifically
noted prediction profile system deterministic though
prediction profile system may markov three card monte example
general partially observable
proposition even original system stochastic prediction profile system
deterministic
proof follows immediately definition every history corresponds exactly
one prediction profile p p history action observation profile sequence p p action action observation pair fully determine next p p observation prediction profile stochastic observations original system folded unmodeled actions prediction profile system
proposition original system markov prediction profile system markov


filearning make predictions without generative model

proof definition original system markov prediction profile time
step depends recent observation time step current profile
agent takes action observes observation ot next profile simply
arkov ot fact original system markov prediction profile
system satisfies even stronger condition next p p observation fully determined
p p action dependence history whatsoever including recent
p p observation
proposition even original system partially observable prediction profile
system may markov
proof consider three card monte example original system clearly non markov
recent observation dealers recent swap tells one little
location ace however prediction profile system tests interest
regarding location special card pictured figure markov next profile
fully determined current profile p p action
general however p p system may partially observable though three
card monte example current prediction profile next action observation pair
together fully determine next prediction profile general next prediction profile
determined history action observation pairs prediction profiles
proposition prediction profile system may partially observable
proof recall ball bounce example corresponding prediction profile system
shown figure note two distinct states update graph associated
prediction profile pixel x white given current prediction profile
pixel x white p p action observe ball neighboring pixel left
right one cannot determine whether ball entering leaving neighborhood
thus cannot uniquely determine next profile prediction profile system
partially observable
general prediction profile system deterministic partially observable dynamical system model prediction profile system used make
predictions interest one wishes use prediction profile model generative
model one must select tests interest carefully instance
proposition tests interest include set one step primitive tests
ao model prediction profile system used
generative model original system
proof follows immediately definition generative model
special case prediction profile model complete generative
model system shown section one desires generative model
essentially never preferable learn prediction profile model traditional
representation prediction profile model best applied relatively simple make
maintain predictions interest comparison making predictions general


fitalvitie singh

figure flow
prediction profile model conditions observations necessarily predict
next observation model prediction profile system cannot typically
used purposes model control generative model could
experiments section demonstrate output prediction profile
however useful model free control methods

learning prediction profile model
definition prediction profile system straightforwardly suggests method
learning prediction profile estimate prediction profiles learn model
dynamics standard model learning technique section present
learning discussing main practical challenges arise
let training data set trajectories experience original system actionobservation sequences let tk set tests interest
presented section learn model prediction profile system
data three main steps pictured figure first training
data used estimate prediction profiles number unique profiles
values next learned set prediction profiles used translate training data
trajectories experience prediction profile system finally applicable model
learning method trained transformed data learn model prediction
profile system ultimately experiments learned prediction profile
evaluated useful predictions features control
estimating prediction profiles
given first step learning prediction profile model determine
many distinct prediction profiles well values estimated prediction
test interest history h
p h

times succeeds h

times acts taken h
def



one could point directly estimate letting h hp h p h p tk
h course due sampling error unlikely estimated profiles
exactly even true underlying prediction profiles identical


filearning make predictions without generative model

estimate number distinct underlying profiles statistical tests used
histories significantly different prediction profiles
compare profiles two histories likelihood ratio test homogeneity performed counts test interest two histories statistical test
associated test interest rejects null hypothesis prediction
histories two histories different prediction profiles
order set distinct prediction profiles greedily cluster estimated
prediction profiles specifically initially empty set exemplar histories maintained
searches histories agents experience comparing historys
estimated profile exemplar histories estimated profiles candidate historys
profile significantly different profiles exemplar histories candidate
added exemplar end estimated profiles corresponding exemplar
histories used set prediction profiles order obtain best estimates
possible search ordered prioritize histories lots associated data
prediction profile estimation procedure two main sources complexity
first sample complexity estimating prediction profiles take great
deal exploration see history enough times obtain good statistics especially
number actions observations large issue could addressed adding
generalization estimation procedure data one sample trajectory could
improve estimates many similar histories one experiments section
observation abstraction employed simple form generalization second
bottleneck computational complexity searching prediction profiles involves exhaustively enumerating histories agents experience would valuable
develop heuristics identify histories likely provide profiles order
avoid searching histories experiments section simple heuristic
limiting search short histories employed long histories tend less
associated data therefore less likely provide distinguishably profiles
generating prediction profile trajectories
generated finite set distinct prediction profiles next step translate
agents experience sequences action observation pairs prediction profiles
trajectories used train model prediction profile system
process translating action observation sequence prediction profile trajectory straightforward apart practical concerns follows directly
definition recall action observation sequence ak ok corresponding p p action sequence ha iha hak ok corresponding sequence
profiles ak ok thus principle every primitive actionobservation sequence translated action observation profile sequence
course available generate sequence prediction profiles
necessary use approximation generated training data specifically
estimated predictions tests interest history h computed equation
compared statistical tests set distinct estimated prediction profiles
section one estimated profile statistically significantly
different estimated predictions h let h


fitalvitie singh

given sufficient data statistical tests uniquely identify correct match
high probability practice however histories much associated
data possible case test homogeneity fail reject null
hypothesis two profiles indicates enough data distinguish multiple possible matches experiments section two different
heuristic strategies handling situation employed first strategy lets h
matching profile smallest empirical kl divergence estimated
predictions summed tests interest heuristic choice may lead
noise prediction profile labeling could turn affect accuracy learned
model second strategy simply cut trajectory point multiple
matches occur rather risk assigning incorrect labeling ensures labels
appear prediction profile trajectories reasonable level confidence
correctness however wasteful throw training data way
learning prediction profile model
translation step produces set trajectories interaction prediction
profile system recall prediction profile system deterministic partially observable discrete dynamical system trajectories used train model
prediction profile system principle applicable model learning method
issue faced prediction profile system present
usual discrete dynamical systems modeling setting prediction profile labels
present training data actually model available say
current history h action taken observation emitted together
action observation pair constitutes p p action model prediction profile
system prediction profile model identify next profile profile used
compute predictions p ha tests interest history ha
another action observation occur necessary update pp
state order obtain next prediction profile typical dynamical systems model
makes predictions next observation able update state
actual observation occurred prediction profile observations prediction
profiles observable interacting world
prediction profile model update state prediction profile predicted
updated prediction profile model obtain profile follows ha
gives predictions tests interest history ha
prediction profile model perfect model prediction profile system
poses prediction profile system deterministic need
observe true prediction profile label fully determined history practice
course model imperfect different modeling representations require
different considerations performing two functions providing predictions
tests interest providing profile sake updating model
pp pomdps
since prediction profile system partially observable natural model pomdp unfortunately even training data deterministic sys

filearning make predictions without generative model

tem pomdp training em generally provide deterministic
pomdp thus given history learned pomdp model prediction profile
system pp pomdp provide distribution prediction profiles instead deterministically providing one profile associated history implementation
used section simply takes likely profile distribution profile
associated history uses make predictions tests interest well
update pomdp model
pp lpsts
another natural choice representation prediction profile model looping predictive
suffix tree lpst holmes isbell lpsts specialized deterministic partially
observable systems could used model original system
assumed stochastic general apply prediction profile system
determinized pomdp
briefly lpst captures parts recent history relevant predicting next
observation every node tree corresponds action observation pair node
may leaf may children may loop one ancestors every leaf
tree corresponds history suffix deterministic prediction observation
every action order predict next observation particular history one
reads history reverse order following corresponding links tree leaf
reached gives prediction holmes isbell provide learning
certain conditions training data guaranteed produce optimal tree
reader referred work holmes isbell details
one weakness lpsts however fail make prediction next
observation current history lead leaf node tree leaf
node reached prediction action queried typically occurs
history suffixes occur training data occur
model pp lpst mean histories model cannot uniquely
determine corresponding prediction profile happens implementation
used section simply finds longest suffix current history occur
data suffix associated multiple prediction profiles otherwise lpst
would provided prediction make predictions tests interest model
provides average prediction set profiles profile used update
model picked set uniformly randomly
pp psrs
applying psr learning prediction profile data poses practical concern
specifically methods attempt estimate system dynamics matrix james singh
wolfe et al implicitly presume every action sequence could principle
taken every history action sequences taken histories
others matrix undefined entries poses challenges rank
estimation indeed definition model representation unfortunately
case prediction profile system since p p actions action observation
pairs completely agents control partly selected environ

fitalvitie singh

ment recent spectral learning presented boots et al may
able side step issue flexibility selecting predictions
estimated use model learning process though investigated
possibility work
note though method learning prediction profile model involves standard
model learning methods partially observable environments generative
model original system prediction profile model generative model
prediction profile system cannot used make predictions
original system predictions interest

complexity prediction profile system
learning presented evaluated empirically section first
however analyze complexity prediction profile system relation complexity original system give indication difficult learn
prediction profile model provide insight appropriate learn prediction
profile model typical generative model
many factors affect complexity learning model section
largely focus linear dimension measure complexity taking view
generally speaking systems lower linear dimension easier learn systems
larger linear dimension discussed section generally true pomdps
linear dimension lower bounds number hidden states comparing
linear dimension prediction profile system original system give
idea whether would easier learn pp pomdp learn standard
pomdp original system course model learning methods
complexity measures would appropriate instance known
precisely lpsts interact linear dimension extending
measures complexity may interesting topic future investigation
linear dimension comparison
section discuss linear dimension prediction profile system relates
original system first proof concept simply states
exist prediction profile system vastly simple
original system fact already presented
proposition prediction profile system linear dimension arbitrarily
lower original system
proof recall three card monte example thus far domain described
without describing dealers behavior however note prediction profile system
tests interest relating location special card pictured figure
linear dimension regardless dealers swaps chosen complex
dealer chosen original system high linear dimension prediction
profile systems linear dimension remain constant instance experiments
section dealer chooses cards swap stochastically likely choose


filearning make predictions without generative model

swap selected least often far thus order predict dealers
next decision one must count many times swap chosen history
system effectively infinite linear dimension
hand prediction profile panacea following
indicate learning prediction profile model would
advisable learning standard generative model linear dimension
prediction profile system far greater original system later
section special cases characterized prediction profile likely
useful next shows linear dimension prediction profile model
infinite original system finite linear dimension via lower bound
linear dimension true deterministic dynamical systems
proposition deterministic dynamical system actions observations
linear dimension n log log

log
proof see appendix
proposition applies deterministic dynamical systems certainly applies prediction profile system though loose bound basic implication
number prediction profiles observations p p increases comparison number action observation pairs actions p p linear dimension
prediction profile system necessarily increases bound clearly illustrates
importance assumption finite number distinct prediction profiles
corollary infinitely many distinct prediction profiles prediction profile
system infinite linear dimension
proof clearly ap p finite long finitely many actions
observations last follows immediately number distinct
prediction profiles op p approaches infinity must linear dimension
prediction profile system
hence long prediction profile represented methods rely
finite linear dimension critical finitely many prediction profiles
note fundamental barrier side effect representational choice
model learning methods sensitive linear dimension designed
model continuous dynamical systems may able effectively capture systems
infinitely many prediction profiles
one conclusion drawn last knowing linear dimension
original system necessarily say much complexity
prediction profile system prediction profile system may far simpler far
complex original system thus may informative turn factors
trying characterize complexity prediction profile system


fitalvitie singh

bounding complexity prediction profile system
previous section take account obviously important aspect
prediction profile system predictions asked make predictions
interest made simply keeping track little information
predictions rely great deal history information therefore require
complex model next identifies worst case set tests interest
system tests interest whose corresponding prediction profile model highest
linear dimension ultimately section present non exhaustive conditions
prediction profile system likely simpler original system
proposition given system set tests interest linear dimension
corresponding prediction profile system greater prediction profile
system associated set core tests system described section
proof see appendix
worst case identified one immediately obtain bounds complex
prediction profile system possibly
corollary system set tests interest corresponding prediction
profile system linear dimension greater number distinct predictive states
original system
proof prediction profile system set core tests q deterministic mdp
observations prediction profiles q predictive states state
associated unique prediction profile linear dimension mdp never
greater number observations singh et al therefore previous
prediction profile system set tests interest linear dimension
greater number predictive states
corollary original system pomdp prediction profile system set
tests interest linear dimension greater number distinct belief states
proof follows immediately previous fact number
distinct predictive states greater number distinct belief states littman
et al
bounds presented far help explain prediction profile system
complex original system however focused worst possible
choice tests interest little illuminate opposite true prediction
profile model complex asked perform task generative
model keep track much information history necessary make possible
predictions equivalently predictive state belief state indicate
generally speaking one desires generative model standard approaches would
preferable learning prediction profile model
hand stated goal learn generative model instead
focus particular predictions hopefully far simpler make
predictions examples seen make clear cases predictions


filearning make predictions without generative model

made prediction profile model far simpler generative model original
system general one might expect prediction profile model simple
predictions interest rely small amount state information required
maintain generative model next bound aligns intuitive reasoning
essentially points often much hidden state information
pomdp irrelevant predictions interest linear dimension
prediction profile system bounded number distinct beliefs relevant
parts hidden state rather number distinct beliefs states overall idea
one impose abstraction hidden states pomdp
observations still allows predictions interest made accurately
allows abstract belief states computed accurately prediction profile
systems linear dimension bounded number abstract belief states
proposition consider pomdp hidden states actions observations
let set tests interest let ai action taken time step si
hidden state reached taking action ai oi observation emitted si
consider surjection mapping hidden states set abstract states
following properties
pair primitive states time step
test interest p si p si
pair primitive states time step
abstract state observation action
pr si si ai oi
pr si si ai oi
prediction profile system linear dimension greater
number distinct beliefs abstract states
proof see appendix
things note first surjection exists
def
properties one define degenerate
case trivially satisfies requirements proposition recovers bound given
corollary however proposition applies surjections satisfy conditions
must surjection satisfies conditions smallest number
beliefs abstract states essentially one ignores much state information
possible still allowing predictions interest made accurately
surjection tightly bounds complexity prediction profile system even
known
course may still large even infinite number distinct beliefs even
abstract states factors must come play ensure simple prediction profile
system furthermore characterize settings prediction
profile system simple said support intuition


fitalvitie singh

prediction profile system tend simple predictions asked make
depend small amounts state information
order build intuition relates earlier examples recall
three card monte three card monte two sources hidden state
aces unobserved position whatever hidden mechanism dealer uses make
decisions clearly agents predictions interest depend first part
hidden state case one satisfy property surjection maps
two hidden states abstract state ace position regardless
dealers state abstract states one possible
position even though might infinitely many true hidden states different
states corresponding ace position different distributions aces
next position distribution depend upon dealers state however
property statement distribution next abstract state given
observation emitted entering abstract state one knows current
abstract state observes dealer next abstract state fully determined
property holds well fact since aces position known beginning
game means current abstract state known absolute certainty even
though beliefs dealers state general uncertain hence
distinct beliefs abstract states one state prediction profile
linear dimension upper bounded regardless dealers complexity
case bound met
bounding number prediction profiles
previous section describes conditions prediction profile system
may lower linear dimension original system concern number
prediction profiles whether number finite section briefly discuss
non exhaustive cases number prediction profiles bounded
one case already discussed original system markov
case number prediction profiles bounded number observations states
course original system markov little need use prediction profile
another similar case system partially observable completely
deterministic next observation completely determined history
selected action system deterministic pomdp given history
current hidden state known number belief states bounded
number hidden states since cannot prediction profiles belief states
number prediction profiles bounded well
one move away determinism different ways first note key
property deterministic pomdp hidden state fully determined history
possible satisfy property even stochastic systems long one uniquely
determine hidden state given observation emitted arriving
case observations emitted stochastically number belief states
number prediction profiles still bounded number hidden states
another step away determinism class systems introduced littman
called det pomdps det pomdp pomdp transition function


filearning make predictions without generative model

observation function deterministic initial state distribution may
stochastic det pomdp deterministic dynamical system uncertainty
hidden state uncertainty system appears emit observations
stochastically underlying dynamics deterministic littman showed
det pomdp n hidden states initial state distribution states
support n distinct belief states bounds number
prediction profiles well
finally importantly hidden state abstracted proposition
properties really need hold abstract beliefs environment
may complex stochastic arbitrary ways abstract hidden state
described proposition fully determined history number prediction
profiles bounded number abstract states case three card monte
similarly det pomdp properties imagined abstract hidden states well
cases means cover situations number prediction profiles
bounded seem indicate class number
prediction profiles finite quite broad may contain many interesting examples

experiments
section empirically evaluate prediction profile model learning procedure developed section experiment agent faces environment generative
model would challenge learn due high linear dimension however
agent could make good decisions could predictions small
number important tests prediction profile model learned important tests
accuracy learned predictions evaluated
experiments demonstrate one possible use prediction profile
partial general control generative prediction profile
cannot typically used directly offline model methods however output may useful model free methods control specifically
experiments predictions made learned prediction profile provided
features policy gradient
predictive features policy gradient
policy gradient methods e g williams baxter bartlett peters schaal
successful viable options model free control partially observable domains though differences common
thread assume parametric form agents policy attempt
alter parameters direction gradient respect expected average reward experiments make use online gpomdp average reward baseline
weaver tao olgarb readers referred original details
olgarb assumes set features history agents policy takes
parametric form
pr h w
p

e

p





wi h
p
wi h



e

fitalvitie singh

h ith feature parameter wi weight specific feature
action considered
typically features used policy gradient features directly read
history e g features recent observations presence absence
event history difficult know priori historical features
important making good control decisions contrast idea experiments
provide values predictions features predictive features direct
consequences control provide information effects possible behaviors
agent might engage may easier select set predictive features
likely informative optimal action take e g agent
reach goal state takes action taking action damage
agent furthermore information may expressed compactly terms prediction
would complex specify purely terms past observations seen
discussion psrs section arbitrary length history fully captured
finite set short term predictions reasons seems reasonable speculate
predictive features maintained prediction profile model may particularly
valuable model free control methods policy gradient
experimental setup
learning applied two example prediction
profile learned amounts training data lpsts
pomdps representation strategies dealing multiple matches
described section prediction accuracy evaluated well
useful predictions features control training data generated
executing uniform random policy environment
free parameter learning significance value statistical
tests given large number contingency tests performed
data set compound probability false negative set fairly
low experiments use though several reasonable values tried
similar discussed section maximum length
histories consider search prediction profiles cutoff allows search
avoid considering long histories many long histories search
unlikely provide prediction profiles
prediction profile model learned predictions evaluated features
policy gradient olgarb specifically test interest unit
interval split equally sized bins b binary feature ft b provided
prediction lies bin b otherwise provided binary features fo
possible observation feature fo recent observation
otherwise parameters olgarb learning rate discount factor set
respectively experiments
evaluate prediction profile model olgarb run steps average
reward obtained root mean squared error rmse predictions tests
interest accrued model along way reported prediction performance
compared obtained learning pomdp training data


filearning make predictions without generative model

prediction performance

control performance


avg reward trials

avg rmse trials




flat pomdp


pplpst kld
pplpst cut





pppomdp kld
pppomdp cut





training trajectories

true




pppomdp kld
pppomdp cut



pplpst kld
pplpst cut


flat pomdp








expert



som







training trajectories x



x

figure three card monte domain
make predictions interest complex feasibly train
pomdp correct number underlying states state pomdps used
stopping em maximum iterations control performance compared
obtained olgarb predictions provided learned pomdp model
features well olgarb true predictions features best prediction
profile model could hope olgarb second order markov features two
recent observations well action predictive features
hand coded expert policy
three card monte
first domain three card monte example agent presented three
cards initially card middle card ace agent four actions
available watch f lip f lip f lip agent chooses flip action observes
whether card flipped special card agent chooses watch action
dealer swap positions two cards case agent observes two
cards swapped dealer ask guess dealer asked
guess watch reward flip action reward dealer
asks guess agent flips special card agent gets reward
agent flips one two cards doesnt flip card selecting watch
gets reward agent three tests interest take form f lipx ace
card x flip card x see ace
discussed previously complexity system directly related complexity dealers decision making process experiment agent chooses
watch dealer swaps pair cards swapped least far probability
probability chooses uniformly amongst pairs cards otherwise
asks guess since dealer keeping count many times swap
made process governing dynamics effectively infinite linear dimension
similar obtained states



fitalvitie singh

prediction profile system hand states regardless dealers
complexity see figure
training trajectories length figure shows amounts
training data averaged trials pp pomdps pp lpsts learned make
accurate predictions tests interest eventually achieving zero prediction error
case pp pomdps less data likely pomdp model
readily able take advantage fact prediction profile system three
card monte markov expected standard pomdp model unable accurately
predict tests interest
compared two different strategies dealing multiple matches discussed section recall first one marked kld graph picks
matching profile smallest empirical kl divergence estimated predictions
second marked cut graph simply cuts trajectory point
multiple match avoid incorrect labels two strategies almost exactly performance likely profiles three
card monte deterministic therefore quite easy distinguish making multiple
matches unlikely next experiment stochastic profiles
predictive features provided prediction profile clearly useful
control control performance olgarb predictions approaches
eventually exactly matches olgarb true predictions marked true
inaccurate predictions provided pomdp useful control olgarb pomdp provided predictions even break even meaning loses
game often wins pomdp features however seem contain
useful information beyond provided second order markov features marked
som one might expect performed poorly
shooting gallery
second example called shooting gallery pictured figure agent
gun aimed fixed position grid marked x target moves
diagonally bouncing boundaries image obstacles example
trajectory pictured agents task shoot target agent two actions
watch shoot agent chooses watch gets reward agent chooses
shoot target crosshairs step agent shoots agent gets
reward otherwise gets reward whenever agent hits target
shooting range resets agent receives special reset observation square
range made obstacle probability target placed random
position probability range reset every time step
difficulty target sticky every time step probability moves
current direction probability sticks place thus looking recent
history agent may able determine targets current direction agent
needs know probability target sights next step clearly
single test interest watch target choose watch action
target enter crosshairs target far crosshairs prediction
test target crosshairs target


filearning make predictions without generative model



b

figure shooting gallery domain possible arrangement obstacles trajectory target lighter back time case target
definitely enter agents crosshairs since bounce obstacle
b abstraction applied recent observation

near crosshairs model must determine whether prediction
targets previous behavior direction configuration nearby obstacles
stochastic prediction profiles expected data
required differentiate due number possible configurations
obstacles positions target system roughly observations
even latent states large number possible histories
small probability occurring discussed section lead large sample
complexity obtaining good estimates prediction profiles addressed
simple form generalization observation abstraction two observations treated
target position configuration obstacles
immediate vicinity target words abstract observation
contains information targets position obstacles surrounding
target placement obstacles far away target see figure b
example abstraction abstract observations still provide enough detail
make accurate predictions two histories indeed prediction profile
action sequence observation sequences correspond
sequence aggregate observations enables one sample trajectory improve
estimates several histories though even abstraction still
action observation pairs observation abstraction applied training
pomdp model
training trajectories length search profiles restricted length
histories shown figure perhaps eye catching feature
upward trending curve prediction error graph corresponding
pp pomdp kl divergence matching labeled pp pomdp kld
recall danger kl divergence matching strategy may produce
incorrect labels training data apparently errors severe enough
drastically mislead pomdp model small amount data obtained


fitalvitie singh

prediction performance

control performance


avg reward trials

avg rmse trials



pppomdp cut


flat pomdp



pppomdp kld



pplpst cut
pplpst kld












training trajectories





pplpst kld
pppomdp kld

pplpst cut


pppomdp cut







x

expert
true

som
flat pomdp











training trajectories x

figure shooting gallery domain
good prediction error data came misleading labelings
performance suffered pp pomdp trained matching method pppomdp cut displays typical learning curve data better error
though takes great deal data begins make reasonable predictions
cutting trajectories multiple matches throws away data might
informative model pp lpsts generally outperform pp pomdps
trajectory cutting method pp lpst pp lpst cut
quickly outperforms flat pomdp enough data outperforms versions
pp pomdp pp lpst kl divergence matching pp lpst kld
far best performer quickly achieving small prediction error clearly incorrect
labels training data dramatic effect lpst learning possibly
suffix tree lpst mostly makes predictions recent history
limiting effects labeling errors time steps
control performance essentially mirrors prediction performance interesting
exceptions note even though pp pomdp kld obtains roughly prediction
error flat pomdp training trajectories predictive features provides
still substantially better control performance indicates even though
pp pomdp making errors exact values predictions still captured
important dynamics predictions flat pomdp flat pomdp
provides features roughly useful second order markov features
good performance olgarb features break
even meaning wasting bullets target likely enter crosshairs
best performing prediction profile model pp lpst kld approaches performance
olgarb true predictions sufficient data

related work
idea modeling aspects observations dynamical system
certainly raised instance recent example rudary learned linear

filearning make predictions without generative model

gaussian continuous partially observable environments dimensions
observation treated unmodeled exogenous input inputs assumed
linear effect state transition along somewhat similar lines context
model minimization taking given complete model deriving simpler abstract model
preserves value function wolfe constructed abstract model
shadow model predicts observation details ignored abstraction
shadow model takes abstract observations abstract model unmodeled input
splitting observation modeled un modeled components learning
generative model certainly related case model would make
conditional predictions modeled portion observation given exogenous
inputs well actual actions history prediction profile take
extreme treating entire observation input instead predicting future sequences
piece next observation conditioned another piece prediction profile
predict values arbitrary set predictions interest next time step given
entire action observation allows significantly freedom choosing
predictions model make importantly make
one modeling method closely related prediction profiles causal state splitting
reconstruction cssr shalizi klinker cssr learning generative discrete partially observable uncontrolled dynamical systems basic
idea define equivalence relation histories two histories considered
equivalent associated identical distributions possible futures
equivalence classes relation called causal states cssr learns
number causal states distribution next observations associated
causal state transitions one causal state next given observation
straightforward see one one correspondance causal states
predictive states psr causal state model precisely prediction
profile model set tests interest q set core tests correspondance hand section many cases number causal
states greatly exceed linear dimension original system therefore
cssr may inadvisable many comparison standard modeling
approaches possible cssr could adapted general
setting arbitrary sets tests interest however rely heavily
fact prediction profile model q tests interest markov
generally case sets tests interest
mentioned section mccallum presented utree suffix tree learning value functions partially observable environments utree
learns value function prediction future rewards make
predictions observations utree learn non generative partial model wolfe
barto extend utree make one step predictions particular observation
features rather limiting predictions value function learns suffix
tree utree able operate non episodic domains whereas method requires seeing
histories multiple times required explicitly search distinct prediction profiles utree directly incorporates abstraction learning learning simultaneously
observation features important history suffix attend
said main drawback suffix tree tree takes account


fitalvitie singh

information relatively recent history suffix history cannot remember
important information arbitrary number steps recurrent state model
three card monte example instance access depth limited suffix
history would little help order track ace one must take account
every move dealer made since beginning game utree would essentially
forget card games length surpassed depth memory
mccallum mahmud provide methods learning state machines
predict immediate reward resulting given action observation pair partially observable control tasks thus suffer issue finite depth memory
suffix trees thus learning special case
restrict make one step predictions immediate reward
cases simple model incrementally greedily elaborated proposing states split
evaluating via statistical tests case mccallum via likelihood
hill climbing case mahmud mccallum expressed concern
difficulty extracting long range dependencies instance learning attend event
appear affect distribution rewards many steps later
clear extent mahmuds addresses issue methods
advantages utree notably applied non episodic
domains said advantages well casting
learning non generative model standard generative model learning
able gain deeper understanding complexity applicability prediction
profile compared standard generative furthermore allowed us incorporate standard well studied generative model learning methods
learning thereby leveraging strengths non generative setting
specifically resulting principled albeit heuristic learning
rely guess check stochastic local search
prediction profile system similar spirit finite state controllers
pomdps sondik noted cases possible represent optimal policy pomdp finite state machine finite state controllers
much prediction profile take action observation pairs inputs
instead outputting predictions associated current history output
optimal action take multiple authors e g hansen poupart boutilier
provide techniques learning finite state controllers however typically
require access complete pomdp model world begin setting
assumed impractical

conclusions future directions
standard methods learning partially observable environments learn
generative one small set predictions interest make
therefore require full power generative model one ignore irrelevant
detail via abstraction simplify learning even generative model
necessarily make predictions relevant details even directly
interest seen example resulting model counter intuitively
complex even predictions model asked make quite simple


filearning make predictions without generative model

presented prediction profile non generative partially
observable systems make predictions interest others main idea
prediction profile learn model dynamics predictions
change time rather model dynamics system learning
method prediction profile learns transformation training data
applies standard methods transformed data assuming predictions interest
take finite number distinct values retains advantages methods
em pomdps learn information history must maintained order
make predictions rather requiring set history features priori showed
prediction profile model far simpler generative model though
far complex depending predictions asked make however
predictions interest depend relatively little state information prediction profile
provide substantial savings standard modeling methods pomdps
experiments section demonstrate possible learn prediction
profile contrived systems complex pomdps specific learning presented likely scale natural domains without modification
critical scaling issues prediction profile sample complexity
estimating prediction profiles computational complexity searching prediction profiles translating data cases critical source complexity
essentially many distinct histories training data distinct histories
means data spread thin amongst estimated profiles search
generalization prediction estimates across many histories would
key step toward applying ideas realistic domains currently developing learning combine ideas behind prediction profile
methods learning abstractions allow many essentially equivalent histories
lumped together purposes estimating predictions interest
another limitation prediction profile model learning method presented
reliance assumption finite number prediction profiles assumption
hold many cases ideal method would able deal gracefully large
infinite number prediction profiles one possibility simply cluster predictions
ways instance one may desire certain level prediction accuracy
may therefore willing lump distinct prediction profiles together exchange
simpler prediction profile system another idea would learn prediction profile model
continuous valued representations kalman filters kalman plgs
rudary singh wingate nonlinear variants e g julier uhlmann
wingate representations learning explicitly deal
systems infinite number observations prediction profiles case even
finitely many prediction profiles methods learning non linear continuous
may still able approximately capture discrete dynamics
additionally though focused discrete systems main motivation
behind prediction profile purchase continuous setting typical methods learning partially observable systems continuous systems much
discrete valued counterparts learn generative non generative
prediction profile may provide similar benefits continuous setting
predictions need made setting prediction profiles might represented


fitalvitie singh

parametric form instance mean variance gaussian main idea
prediction profile though specific method presented could still
applied learn model dynamics distribution parameters rather
dynamics system
finally discussed work tests interest determined predict selected automatically selecting interesting important predictive features targets partial would certainly
interesting challenge course would depend predictions
used predictions used features control done
experiments would certainly seem intuitive start predictive features
regarding reward signal perhaps observation features strongly correlate
reward intuitively done hand experiments may useful
consider making predictions predictions style td networks sutton
tanner instance one could imagine learning make predictions
profile another model emit way could chained together
make predictions extant rewards rather focusing solely predicting
immediate reward signal particularly good feature temporal
decision another common use partial decompose large modeling
many small ones instance factored mdps boutilier et al
factored psrs wolfe et al collections local talvitie singh b
setting choosing tests interest would example structure learning
decomposing one step predictions relatively independent components
assigning different

acknowledgments
erik talvitie supported nsf grfp satinder singh supported nsf
grant iis opinions findings conclusions recommendations expressed
material authors necessarily reflect views nsf
work presented extension work presented ijcai talvitie
singh grateful anonymous reviewers whose helpful comments
improved presentation work

appendix
proof proposition
follow straightforwardly general fact dynamical systems let
h j sequence actions observations h starting ith time step
sequence ending jth time step sequence conveniences sake
j let h j h null sequence following two
test ever positive probability must positive probability history
length less linear dimension system



filearning make predictions without generative model

figure matrix constructed lemma full rank contradiction
lemma linear dimension dynamical system n test
history h length h k n p h j j k
p h h j k
proof note p h p h k h p h p h k h
k assume j j k p h j k h
p h h j k p h j k h seek contradiction consider submatrix
system dynamics matrix rows submatrix correspond prefixes h h
k columns correspond suffixes h pre pended test h j k
j k k k matrix assumption
matrix triangular positive entries along diagonal figure shows matrix
k matrix full rank rank k contradiction since
k n submatrix never higher rank matrix contains
next follows immediately lemma
corollary system linear dimension n test history h
p h exists possibly non consecutive subsequence h h
length h n p h
proof lemma every history h length k n p h must
subsequence h length k k p h k n h must
subsequence h length k k argument repeated subsequence
length less n
consequence corollary every test ever positive probability
must positive probability following history length less n fact
hand proposition proven
proposition deterministic dynamical system actions observa
tions linear dimension n log log
log


fitalvitie singh

proof since system deterministic history action correspond exactly one
resulting observation history sequence actions observations however since
sequence observations fully determined sequence actions deterministic
system number distinct histories length k simply k history
action choices could different observation number
observations could possibly occur histories length k simply k
corollary linear dimension n observations must occur history h
length h n thus number observations possibly follow histories
length less n


n
x





n



solving n yields bound linear dimension terms number actions
number observations
proof proposition
proposition given system set tests interest linear dimension
corresponding prediction profile system greater prediction profile
system associated set core tests system described section
proof recall discussion psrs section set core tests q
set tests whose corresponding columns system dynamics matrix constitute
basis predictions core tests given history form predictive state
history predictive state precisely prediction profile core tests q
prediction test computed linear function prediction profile
q note prediction profile system q mdp shown
section compute next predictive state given current predictive state
action observation pair
consider set tests interest predictions q
used compute prediction test must
function maps prediction profiles q prediction profiles
general multiple predictive states may map prediction profile
surjection easy see prediction profile system
applying observation abstraction prediction profile system q performing
observation abstraction mdp generally produces pomdp never increases
linear dimension talvitie hence prediction profile system set tests
interest linear dimension greater prediction profile system
set core tests q
proof proposition
proposition consider pomdp hidden states actions observations
let set tests interest let ai action taken time step si
hidden state reached taking action ai oi observation emitted si


filearning make predictions without generative model

consider surjection mapping hidden states set abstract states
following properties
pair primitive states time step
test interest p si p si
pair primitive states time step
abstract state observation action
pr si si ai oi
pr si si ai oi
exists prediction profile system linear dimension greater
number distinct beliefs abstract states
proof proof follows similar reasoning proof proposition note
property belief abstract states given history sufficient compute
prediction profile history h test interest
x
x x
p h
pr h p
pr h p
ss



x

ss

p

x

ss ss

pr h

x

p pr h

ss

ss

third equality follows property hidden states
associated probabilities tests interest
consider dynamical system beliefs abstract states observations
action observation pairs actions call abstract belief system
predictive state possible compute prediction profile
abstract beliefs prediction profile model seen
observation aggregation abstract belief system prediction profile
system linear dimension greater abstract belief system
rest proof shows property abstract belief system
mdp therefore linear dimension greater number distinct beliefs
abstract states
given probability distribution abstract states given history h agent
takes action observes observation possible compute probability
abstract state history
x
x x
pr hao
pr h pr
pr h pr
ss



x



pr

x

ss

pr h

x

pr pr h



ss

third equality follows property hidden states
associated conditional distribution next abstract states given action
observation


fitalvitie singh

one compute next abstract beliefs previous abstract beliefs
abstract belief system mdp therefore linear dimension greater
number observations number distinct abstract beliefs one
compute prediction profile abstract beliefs prediction profile system
constructed applying observation abstraction abstract belief system thus
prediction profile system linear dimension greater number distinct
abstract beliefs

references
baum l e petrie soules g weiss n maximization technique occuring
statistical analysis probabilistic functions markov chains annals
mathematical statistics
baxter j bartlett p l reinforcement learning pomdps via direct gradient ascent proceedings eighteenth international conference machine
learning icml pp
boots b siddiqi gordon g closing learning loop predictive state representations proceedings robotics science systems zaragoza
spain
boots b siddiqi gordon g online spectral learning
partially observable nonlinear dynamical systems proceedings twenty fifth
national conference artificial intelligence aaai
boutilier c dean hanks decision theoretic structural assumptions computational leverage journal artificial intelligence

bowling mccracken p james neufeld j wilkinson learning
predictive state representations non blind policies proceedings twentythird international conference machine learning icml pp
dinculescu precup approximate predictive representations partially
observable systems proceedings twenty seventh international conference
machine learning icml pp
hansen e finite memory control partially observable systems ph thesis
university massachussetts amherst
holmes isbell c looping suffix tree inference partially observable hidden state proceedings twenty third international conference
machine learning icml pp
james singh learning discovery predictive state representations
dynamical systems reset proceedings twenty first international
conference machine learning icml pp
julier j uhlmann j k extension kalman filter nonlinear
systems proceedings aerosense eleventh international symposium
aerospace defense sensing simulation controls pp


filearning make predictions without generative model

kalman r e linear filtering prediction transactions asme journal basic engineering
littman sutton r singh predictive representations state advances
neural information processing systems nips pp
littman l sequential decision making ph thesis brown
university providence ri
mahmud h constructing states reinforcement learning proceedings
twenty seventh international conference machine learning icml pp

mccallum k reinforcement learning selective perception hidden
state ph thesis rutgers university
mccallum r overcoming incomplete perception utile distinction memory
proceedings tenth international conference machine learning icml
pp
monahan g e survey partially observable markov decisions processes theory
management science
peters j schaal natural actor critic neurocomputing
poupart p boutilier c bounded finite state controllers advances neural
information processing systems nips
puterman l markov decision processes discrete stochastic dynamic programming john wiley sons york ny
rivest r l schapire r e diversity inference finite automata journal
association computing machinery
rudary predictive linear gaussian ph thesis university
michigan
rudary singh wingate predictive linear gaussian stochastic dynamical systems uncertainty artificial intelligence proceedings
twenty first conference uai pp
shalizi c r klinker k l blind construction optimal nonlinear recursive
predictors discrete sequences proceedings twentieth conference
uncertainty artificial intelligence uai pp
singh james r rudary r predictive state representations
theory modeling dynamical systems uncertainty artificial intelligence
proceedings twentieth conference uai pp
sondik e j optimal control partially observable markov processes
infinite horizon discounted costs operations
soni v singh abstraction predictive state representations proceedings
twenty second national conference artificial intelligence aaai pp



fitalvitie singh

sutton r tanner b temporal difference networks advances neural
information processing systems nips pp
talvitie e simple partial complex dynamical systems ph thesis
university michigan ann arbor mi
talvitie e singh maintaining predictions time without model
proceedings twenty first international joint conference artificial intelligence ijcai pp
talvitie e singh b simple local complex dynamical systems
advances neural information processing systems nips pp
weaver l tao n optimal reward baseline gradient reinforcement learning uncertainty artificial intelligence proceedings seventeenth
conference uai pp
williams r simple statistical gradient following connectionist reinforcement learning machine learning
wingate exponential family predictive representations state ph thesis
university michigan
wingate soni v wolfe b singh relational knowledge predictive
state representations proceedings twentieth international joint conference
artificial intelligence ijcai pp
wolfe p paying attention matters observation abstraction partially
observable environments ph thesis university massachussetts amherst
wolfe p barto g decision tree methods finding reusable mdp
homomorphisms proceedings twenty first national conference artificial
intelligence aaai
wolfe b james singh approximate predictive state representations
proceedings seventh conference autonomous agents multiagent systems
aamas
wolfe b james r singh learning predictive state representations
dynamical systems without reset proceedings twenty second international
conference machine learning icml pp
wolfe b singh predictive state representations options proceedings twenty third international conference machine learning icml pp





