journal artificial intelligence

submitted published

efficient markov network structure discovery
independence tests
facundo bromberg

fbromberg frm utn edu ar

departamento de sistemas de informacion
universidad tecnologica nacional
mendoza argentina

dimitris margaritis
vasant honavar

dmarg cs iastate edu
honavar cs iastate edu

dept computer science
iowa state university
ames ia

abstract
present two learning structure markov network data
gsmn gsimn use statistical independence tests infer structure successively constraining set structures consistent
tests recently structure learning maximum likelihood estimation proved np hard markov networks due
difficulty estimating parameters network needed computation
data likelihood independence require computation
likelihood thus gsmn gsimn compute structure efficiently
shown experiments gsmn adaptation grow shrink
margaritis thrun learning structure bayesian networks gsimn extends gsmn additionally exploiting pearls well known properties conditional
independence relation infer novel independences known ones thus avoiding performance statistical tests estimate accomplish efficiently gsimn uses
triangle theorem introduced work simplified version set
markov axioms experimental comparisons artificial real world data sets
gsimn yield significant savings respect gsmn generating markov
network comparable cases improved quality compare gsimn
forward chaining implementation called gsimn fch produces possible conditional independences resulting repeatedly applying pearls theorems known
conditional independence tests comparison gsimn
sole use triangle theorem nearly optimal terms set independences
tests infers

introduction
graphical bayesian markov networks important subclass statistical possess advantages include clear semantics sound widely
accepted theoretical foundation probability theory graphical used
represent efficiently joint probability distribution domain used
numerous application domains ranging discovering gene expression pathways
bioinformatics friedman linial nachman peer computer vision e g geman

c

ai access foundation rights reserved

fibromberg margaritis honavar

figure example markov network nodes represent variables domain v


geman besag york mollie isard anguelov taskar chatalbashev
koller gupta heitz ng one naturally arises construction
data heckerman geiger chickering buntine solution
besides theoretically interesting holds potential
advancing state art application domains used
focus task learning markov networks mns data
domains variables discrete continuous distributed according
multidimensional gaussian distribution mns graphical consist two
parts undirected graph model structure set parameters example
markov network shown figure learning data consists two interdependent tasks learning structure network given learned structure
learning parameters work focus learning structure
mn domain data
present two mn structure learning data gsmn grow shrink
markov network learning gsimn grow shrink inference markov
network learning gsmn adaptation markov networks
gs margaritis thrun originally developed learning
structure bayesian networks gsmn works first learning local neighborhood
variable domain called markov blanket variable
information subsequent steps improve efficiency although interesting
useful use gsmn point reference performance regard
time complexity accuracy achieved gsimn main work
gsimn extends gsmn pearls theorems properties
conditional independence relation pearl infer additional independences
set independences resulting statistical tests previous inferences thus avoiding
execution tests data allows savings execution time data
distributed communication bandwidth
rest organized follows next section present previous
related section introduces notation definitions presents
intuition behind two section contains main gsmn
gsimn well concepts practical details related operation evaluate
gsmn gsimn present section followed summary


fiefficient markov network structure discovery independence tests

work possible directions future section appendices b contain
proofs correctness gsmn gsimn

related work
markov networks used physics computer vision communities geman
geman besag et al anguelov et al historically
called markov random fields recently interest use spatial
data mining applications geography transportation agriculture climatology
ecology others shekhar zhang huang vatsavai
one broad popular class learning structure graphical
score exemplified markov networks della pietra della pietra
lafferty mccallum score approaches conduct search
space legal structures attempt discover model structure maximum score
due intractable size search space e space legal graphs
super exponential size score must usually resort heuristic search
step structure search probabilistic inference step necessary evaluate
score e g maximum likelihood minimum description length lam bacchus
pseudo likelihood besag bayesian networks inference step tractable
therefore several practical score structure learning developed
lam bacchus heckerman acid de campos markov networks
however probabilistic inference requires calculation normalizing constant
known partition function known np hard jerrum sinclair
barahona number approaches considered restricted class graphical
e g chow liu rebane pearl srebro karger however
srebro karger prove finding maximum likelihood network np hard
markov networks tree width greater
work area structure learning undirected graphical concentrated learning decomposable called chordal mns srebro karger
example learning non decomposable mns presented work hofmann tresp learning structure continuous domains
non linear relationships among domain attributes removes edges
greedily leave one cross validation log likelihood score non score
work abbeel koller ng introduces class efficient structure parameter learning factor graphs class graphical
subsumes markov bayesian networks
parameterization gibbs distribution potential functions forced
probability distributions supported generalization hammersley clifford
theorem factor graphs promising theoretically sound may
lead future practical efficient undirected structure learning
work present belong independence constraintbased spirtes glymour scheines independence exploit fact graphical model implies set independences exist distribution domain therefore data set provided input
assumptions see next section work conducting set conditional independence


fibromberg margaritis honavar

tests data successively restricting number possible structures consistent
tests singleton possible inferring structure
possible one desirable characteristic independence approaches fact
require use probabilistic inference discovery structure
amenable proofs correctness assumptions
bayesian networks independence mainly exemplified
sgs spirtes et al pc spirtes et al learn
markov blanket step learning bayesian network structure grow shrink
gs margaritis thrun iamb variants tsamardinos aliferis
statnikov hiton pc hiton mb aliferis tsamardinos statnikov
mmpc mmmb tsamardinos aliferis statnikov b max min hill
climbing mmhc tsamardinos brown aliferis widely used
field restricted classes trees chow liu polytrees
rebane pearl exist
learning markov networks previous work mainly focused learning gaussian
graphical assumption continuous multivariate gaussian distribution
made linear dependences among variables gaussian noise whittaker edwards recent approaches included works dobra
hans jones nevins yao west castelo roverato pena
schafer strimmer focus applications gaussian graphical
bioinformatics make assumption continuous gaussian variables
present applicable domains use
appropriate conditional independence test partial correlation gsmn
gsimn presented apply case arbitrary faithful distribution assumed probabilistic conditional independence test distribution
available first introduced bromberg margaritis honavar
contributions present include extending conducting
extensive evaluation experimental theoretical properties specifically
contributions include extensive systematic experimental evaluation proposed data sets sampled artificially generated networks varying
complexity strength dependences well b data sets sampled networks
representing real world domains c formal proofs correctness guarantee
proposed compute correct markov network structure domain
stated assumptions

notation preliminaries
denote random variables capitals e g x z sets variables bold
capitals e g x z particular denote v n set n
variables domain name variables indices v instance
refer third variable v simply denote data set size
number data points n use notation xy z denote
proposition x independent conditioned z disjoint sets variables x
z x z denotes conditional dependence use xy z shorthand
x z improve readability


fiefficient markov network structure discovery independence tests

markov network undirected graphical model represents joint probability
distribution v node graph represents one random variables
domain absences edges encode conditional independences among
assume underlying probability distribution graph isomorph pearl faithful
spirtes et al means faithful undirected graph graph g
said faithful distribution graph connectivity represents exactly
dependencies independences existent distribution detail means
disjoint sets x z v x independent given z set
vertices z separates set vertices x set vertices graph g
sometimes called global markov property lauritzen words means
removing vertices z g including edges incident
exists undirected path remaining graph variable x
variable example figure set variables separates set
set generally shown pearl theorem page definition
graph isomorphism page necessary sufficient condition distribution
graph isomorph set independence relations satisfy following axioms
disjoint sets variables x z w individual variable

symmetry
decomposition
intersection
strong union
transitivity

xy z
xy w z
xy z w
xw z
xy z
xy z




yx z
xy z xw z





xy w z
xy z w
x z z



operation assume existence oracle
answer statistical independence queries standard assumptions needed
formally proving correctness independence structure learning
spirtes et al
independence structure learning
gsmn gsimn independence learning structure
markov network domain works evaluating number statistical
independence statements reducing set structures consistent
tests singleton possible inferring structure possible one
mentioned theory assume existence independence query oracle
provide information conditional independences among domain variables
viewed instance statistical query oracle kearns vazirani
practice oracle exist however implemented approximately
statistical test evaluated data set example discrete data
pearsons conditional independence chi square test agresti mutual
information test etc continuous gaussian data statistical test used
measure conditional independence partial correlation spirtes et al determine
conditional independence two variables x given set z data


fibromberg margaritis honavar

statistical test returns p value p value test equals probability obtaining
value test statistic least extreme one actually observed
given null hypothesis true corresponds conditional independence
case assuming p value test p x z statistical test concludes
dependence p x z less equal threshold e
x z p x z
quantity sometimes referred tests confidence threshold use
standard value experiments corresponds confidence
threshold
faithful domain shown pearl paz edge exists
two variables x v markov network domain
dependent conditioned remaining variables domain e
x edge iff x v x
thus learn structure theoretically suffices perform n n tests e
one test x v x pair variables x v x unfortunately
non trivial domains usually involves test conditions large number
variables large conditioning sets produce sparse contingency tables count histograms
unreliable tests number possible configurations
variables grows exponentially size conditioning setfor example
n cells test involving n binary variables fill table one data point
per cell would need data set least exponential size e n n exacerbating
one data point per cell typically necessary reliable test
recommended cochran cells contingency table
less data points test deemed unreliable therefore gsmn
gsimn presented attempt minimize conditioning set size
choosing order examining variables irrelevant variables
examined last

related concepts
section present main gsmn gsimn supporting concepts required description purpose aiding understanding
reader discussing first describe abstract gsmn next
section helps showing intuition behind laying foundation

abstract gsmn
sake clarity exposition discussing first gsmn
describe intuition behind describing general structure abstract gsmn
deliberately leaves number details unspecified filled
concrete gsmn presented next section note choices



fiefficient markov network structure discovery independence tests

gsmn outline g gsmn v
initialize g empty graph
variables x domain v

learn markov blanket bx x gs

bx gs x v

add undirected edge g x variable bx
return g

gs returns markov blanket bx variable x v bx
gs x v













bx
grow phase
variable v x
x bx estimated data
bx bx
goto restart grow loop
shrink phase
variable bx
xy bx estimated data
bx bx
goto restart shrink loop
return bx

details source optimizations reduce computational cost
make explicit discuss concrete gsmn gsimn
abstract gsmn shown given input data set
set variables v gsmn computes set nodes variables bx adjacent
variable x v completely determine structure domain mn
consists main loop learns markov blanket bx node
variable x domain gs constructs markov network
structure connecting x variable bx
gs first proposed margaritis thrun shown
consists two phases grow phase shrink phase grow phase
x proceeds attempting add variable current set hypothesized
neighbors x contained bx initially empty bx grows variable
iteration grow loop x found dependent x
given current set hypothesized neighbors bx due unspecified ordering
variables examined explicitly specified concrete gsmn
presented next section end grow phase variables bx
might true neighbors x underlying mnthese called false positives
justifies shrink phase removes false positive bx
testing independence x conditioned bx found independent
x shrink phase cannot true neighbor e cannot edge x
gsmn removes bx assuming faithfulness correctness independence
query end shrink phase bx contains exactly neighbors x
underlying markov network


fibromberg margaritis honavar

next section present concrete implementation gsmn called gsmn
augments gsmn specifying concrete ordering variables x examined
main loop gsmn lines well concrete order
variables examined grow shrink phases gs lines
respectively
concrete gsmn
section discuss first gsmn grow shrink markov network
learning learning structure markov network domain note
reason introducing gsmn addition main contribution gsimn
presented later section comparison reasons particular gsimn
gsmn identical structure following order examination variables
difference use inference gsimn see details subsequent
sections introducing gsmn therefore makes possible measure precisely
experimental section benefits use inference performance
gsmn shown structure similar abstract
gsmn one notable difference order variables examined
specified done initialization phase called examination order
grow order x variable x v determined x priority
queues initially permutation v x permutation v x
position variable queue denotes priority e g means
variable highest priority examined first followed finally
similarly position variable x determines order examined
grow phase x
initialization phase computes strength unconditional
dependence pair variable x given unconditional p value
p x independence test pair variables x denoted
pxy practice logarithm p values computed allows
greater precision domains dependencies may strong weak
particular gives higher priority examines earlier variables
lower average log p value line indicating stronger dependence average defined

x

avg log pxy
log pxy
v

x

grow order x variable x gives higher priority variables
whose p value equivalently log p value variable x small line
ordering due intuition behind folk theorem koller sahami
puts states probabilistic influence association attributes tends
attenuate distance graphical model suggests pair variables x
high unconditional p value less likely directly linked note ordering
heuristic guaranteed hold general example may hold
underlying domain bayesian network e g two spouses may independent
unconditionally dependent conditional common child note however
example apply faithful domains e graph isomorph markov network


fiefficient markov network structure discovery independence tests

gsmn concrete implementation gsmn g gsmn v






initialize g empty graph
initialization
x v x
pxy p x


initialize n avg log pi j avg log pi j
j

j

x v

bx



initialize x j j n j j pxx pxx
j

j


remove x x
main loop
empty

x dequeue

propagation phase

examined x

f examined x


move end x

f move end x

grow phase



x empty

dequeue x

pxy

igsmn x f



change grow order

move x beginning

w

move w beginning

change examination order

w

w

move w beginning

break line

shrink phase



igsmn x f



bx

add undirected edge g x variable bx
return g

note correctness present depend holding e
prove appendices b gsmn gsimn guaranteed return
correct structure assumptions stated section note
computational cost calculation pxy low due empty conditioning set
remaining gsmn contains main loop lines
variable v examined according examination order determined


fibromberg margaritis honavar

igsmn x f calculate independence test x propagation possible otherwise run statistical test data










attempt infer dependence propagation

return false
attempt infer independence propagation
f
return true
else statistical test data
p x z true iff p value statistical test x
return

initialization phase main loop includes three phases propagation phase lines
grow phase lines shrink phase lines propagation
phase optimization variables already computed
e variables already examined collected two sets f set f contains
variables x
x sets passed independence
procedure igsmn shown purpose avoiding execution
tests x justified fact undirected
graphs markov blanket x x markov blanket
variables already found contain x blanket set f cannot members
bx exists set variables rendered conditionally
independent x previous step independence therefore inferred easily
note experiments section section evaluate gsmn
without propagation phase order measure effect propagation
optimization performance turning propagation accomplished simply setting
sets f computed lines respectively empty set
another difference gsmn abstract gsmn use condition pxy line additional optimization avoids independence test
case x found unconditionally independent initialization
phase since case would imply x independent given conditioning
set axiom strong union
crucial difference gsmn abstract gsmn gsmn
changes examination order grow order every variable x since
x
x excludes grow order x changes ordering proceed
follows end grow phase variable x examination order set
lines dictates next variable w examined x last
added growing phase yet examined e w still
grow order variables found dependent x changed done
maximize number optimizations gsimn main contribution
shares structure gsmn changes grow order
therefore explained detail section gsimn presented
final difference gsmn abstract gsmn restart
actions grow shrink phases gsmn whenever current markov blanket
modified lines present gsmn restarting



fiefficient markov network structure discovery independence tests

figure illustration operation gsmn independence graph figure
shows growing phase variable variables examined according
grow order

loops necessary gs due original usage learning
structure bayesian networks task possible true member
blanket x found initially independent grow loop conditioning
set found dependent later conditioned superset
could happen unshielded spouse x e one common
children x existed direct link x underlying bayesian
network however behavior impossible domain distribution faithful
markov network one assumptions independence x given
must hold superset axiom strong union see eqs
restart grow shrink loops therefore omitted gsmn order save
unnecessary tests note even though possible behavior impossible
faithful domains possible unfaithful ones experimentally evaluated
real world domains assumption markov faithfulness may
necessarily hold section
proof correctness gsmn presented appendix
independence graphs
demonstrate operation gsmn graphically concept independence
graph introduce define independence graph undirected
graph conditional independences dependencies single variables
represented one annotated edges solid dotted edge
variables x annotated z represents fact x found
dependent independent given z conditioning set z enclosed parentheses
edge represents independence dependence inferred eqs
opposed computed statistical tests shown graphically


fibromberg margaritis honavar

x
x
x
x

z


x z



xy z



x z inferred



xy z inferred

z
z
z

instance figure dotted edge annotated represents
fact absence edge two variables indicates
absence information independence dependence variables
conditioning set
example figure illustrates operation gsmn independence graph
domain whose underlying markov network shown figure figure shows
independence graph end grow phase variable first examination
order discuss example initialization phase gsmn instead
assume examination grow orders shown figure according
vertex separation underlying network figure variables found
dependent growing phase e




therefore connected independence graph solid edges annotated sets
respectively variables found independent e



thus connected dotted edges annotated
respectively
triangle theorem
section present prove theorem used subsequent gsimn
seen main idea behind gsimn attempt decrease number tests done exploiting properties conditional independence
relation faithful domains e eqs properties seen inference rules
used derive independences ones know true careful
study axioms suggests two simple inference rules stated triangle
theorem sufficient inferring useful independence information
inferred systematic application inference rules confirmed
experiments section


fiefficient markov network structure discovery independence tests

figure independence graph depicting triangle theorem edges graph
labeled sets represent conditional independences dependencies solid
dotted edge x labeled z means x dependent
independent given z set label enclosed parentheses means edge
inferred theorem

theorem triangle theorem given eqs every variable x w sets z
z x w z x w z
x w z w z



x z z

xw z w z z



xy z

call first relation triangle rule second triangle rule
proof strong union transitivity eqs shown contrapositive form
proof triangle rule
strong union x w z get x w z z
strong union w z get w z z
transitivity x w z z w z z get x z z
proof triangle rule
strong union w z z get w z
transitivity xw z w z get xy z

represent triangle theorem graphically independence graph construct section figure depicts two rules triangle theorem two
independence graphs
triangle theorem used infer additional conditional independences
tests conducted operation gsmn example shown figure illustrates application triangle theorem example presented
figure independence information inferred triangle theorem shown
curved edges note conditioning set edge enclosed parentheses



fibromberg margaritis honavar

figure illustration use triangle theorem example figure set
variables enclosed parentheses correspond tests inferred triangle
theorem two adjacent edges antecedents example
inferred triangle rule independence
dependence

example independence edge inferred triangle rule adjacent edges annotated respectively annotation
inferred edge intersection annotations
example application triangle rule edge inferred edges
annotations respectively annotation
inferred edge intersection annotations
gsimn
previous section saw possibility two rules triangle
theorem infer novel tests grow phase gsimn
grow shrink inference markov network learning introduced section uses triangle theorem similar fashion extend gsmn inferring value
number tests gsmn executes making evaluation unnecessary gsimn
gsmn work exactly way thus gsimn shares exactly
algorithmic description e follow differences
concentrated independence procedure use instead independence
procedure igsmn gsmn gsimn uses procedure igsimn shown procedure igsimn addition attempting propagate blanket information obtained
examination previous variables igsmn attempts infer
value independence test provided input strong union
axiom listed eqs triangle theorem attempt successful igsimn
returns value inferred true false otherwise defaults statistical test
data set igsmn purpose assisting inference process gsimn


fiefficient markov network structure discovery independence tests

igsimn x f calculate independence test inference including propagation possible record test knowledge base



























attempt infer dependence propagation

return false
attempt infer independence propagation
f
return true
attempt infer dependence strong union
false kxy
return false
attempt infer dependence triangle rule
w
false kxw b false kw b
add b false kxy ky x
return false
attempt infer independence strong union
true kxy
return true
attempt infer independence triangle rule
w
true kxw b false kw b
add true kxy ky x
return true
else statistical test data
p x z true iff p value statistical test x
add kxy ky x
return

igsimn maintain knowledge base kxy pair variables x containing
outcomes tests evaluated far x data inferred
knowledge bases empty beginning gsimn initialization step shown since gsmn use maintained
within test procedure igsimn
explain igsimn detail igsimn attempts infer independence value input triplet x applying single step backward
chaining strong union triangle rules e searches knowledge base
k kxy x v antecedents instances rules input triplet
x consequent strong union rule used direct shown
eqs contrapositive form direct form used infer independences therefore refer su rule contrapositive form
su rule becomes x w x referred su rule
since used infer dependencies according triangle su rules
dependence x inferred knowledge base k contains
test x
tests x w w b variable w b


fibromberg margaritis honavar

figure illustration operation gsimn figure shows grow phase two
consecutively examined variables figure shows variable
examined second according change examination order
lines set variables enclosed parentheses
correspond tests inferred triangle theorem two adjacent edges
antecedents
b shown highlighted executed inferred tests
done

respectively according triangle su rules independence xy
inferred knowledge base contains
test xy
tests xw w b variable w b
respectively
changes grow orders variables occur inside grow phase
currently examined variable x lines gsimn e igsmn replaced igsimn particular variable reaches line
e pxy igsimn x false x variables found
dependent x e variables currently promoted beginning
grow order illustrated figure variable depicts grow
phase two consecutively examined variables figure curved edges
tests inferred igsimn grow phase variable grow
order changes grow phase
variable complete variables promoted order
beginning queue rationale observation increases
number tests inferred gsimn next step change examination
grow orders described chosen inferred tests learning
blanket variable match exactly required future step


fiefficient markov network structure discovery independence tests

particular note example set inferred dependencies variable
found dependent exactly required initial part grow
phase variable shown highlighted figure b first four dependencies
independence tests inferred conducted resulting computational savings
general last dependent variable grow phase x maximum number
dependences independences inferred provides rationale change
grow order selection examined next
shown assumptions gsmn structure returned
gsimn correct one e set bx computed gsimn equals
exactly neighbors x proof correctness gsimn correctness
gsmn presented appendix b
gsimn technical implementation details
section discuss number practical issues subtly influence accuracy
efficiency implementation gsimn one order application su su
triangle triangle rules within function igsimn given independence query
oracle order application matterassuming one rules
inferring value independence guaranteed produce
value due soundness axioms eqs pearl practice however
oracle implemented statistical tests conducted data incorrect
previously mentioned particular importance observation false independences
likely occur false dependencies one example case
domain dependencies weakin case pair variables connected dependent
underlying true network structure may incorrectly deemed independent paths
long enough hand false dependencies much rare
confidence threshold statistical test tells us probability
false dependence chance alone assuming data test chance
multiple false dependencies even lower decreasing exponentially fast practical
observation e dependencies typically reliable independences provide
rationale way igsimn works particular igsimn prioritizes
application rules whose antecedents contain dependencies first e triangle
su rules followed triangle su rules effect uses statistical
typically known greater confidence ones usually less reliable
second practical issue concerns efficient inference gsimn uses onestep inference procedure shown utilizes knowledge base k kxy
containing known independences dependences pair variables x
implement inference efficiently utilize data structure k purpose
storing retrieving independence facts constant time consists two arrays
one dependencies another independencies array n n size n
number variables domain cell array corresponds pair
variables x stores known independences dependences x
form list conditioning sets conditioning set z list knowledge
base kxy represents known independence xy z dependence x z
important note length list two



fibromberg margaritis honavar

tests done variable x execution gsimn done
growing shrinking phases thus takes constant time retrieve store
independence dependence therefore inferences knowledge base
constant time well note uses strong union axion igsimn
constant time well accomplished testing
two sets stored kxy subset superset inclusion

experimental
evaluated gsmn gsimn artificial real world data sets
experimental presented simple application
pearls inference rules gsimn significant reduction number
tests performed compared gsmn without adversely affecting quality
output network particular report following quantities
weighted number tests weighted number tests computed
summation weight test executed weight test x z
defined z quantity reflects time complexity gsmn
gsimn used assess benefit gsimn inference instead
executing statistical tests data standard method comparison
independence justified observation running
time statistical test triplet x z proportional size n data
set number variables involved e n z exponential
number variables involved nave implementation might assume
one construct non zero entries contingency table used
test examining data point data set exactly time proportional
number variables involved test e proportional x z z
execution time order assess impact inference running time
addition impact statistical tests report execution time

quality resulting network measure quality two ways
normalized hamming distance hamming distance output
network structure underlying model another measure
quality output network actual network used generate
data known hamming distance defined number reversed
edges two network structures e number times actual
edge true network missing returned network edge absent
true network exists output network value zero
means output network correct structure able compare
domains
different dimensionalities number variables n normalize

n
total number node pairs corresponding domain
accuracy real world data sets underlying network unknown
hamming distance calculation possible case impossible know
true value independence therefore approximate statistical
test entire data set use limited randomly chosen subset
data set learn network measure accuracy compare


fiefficient markov network structure discovery independence tests

true false number conditional independence tests network
output vertex separation tests performed full data
set
experiments involving data sets used statistical test estimation
conditional independences mentioned rules thumb exist deem certain
tests potentially unreliable depending counts contingency table involved
example one rule cochran deems test unreliable
cells contingency table less data points test due requirement
answer must obtained independence conducting test used
outcomes tests well experiments effect possibly unreliable
tests quality resulting network measured accuracy measures listed

next section present domains underlying probabilistic
model known followed real world data experiments model structure
available
known model experiments
first set experiments underlying model called true model true network
known markov network purpose set experiments conduct controlled
evaluation quality output network systematic study
behavior varying conditions domain size number variables amount
dependencies average node degree network
true network contains n variables generated randomly follows
network initialized n nodes edges user specified parameter
network structure average node degree equals average number neighbors
per node given every node set neighbors determined randomly
uniformly selecting first n pairs random permutation possible pairs
factor necessary edge contributes degree two nodes
conducted two types experiments known network structure exact learning
experiments sample experiments
exact learning experiments
set known model experiments assume statistical queries
asked gsmn gsimn available assumes existence
oracle answer independence queries underlying model known
oracle implemented vertex separation benefits querying
true network independence two first ensures faithfulness correctness
independence query allows evaluation
assumptions correctness second tests performed much faster actual
statistical tests data allowed us evaluate large networkswe
able conduct experiments domains containing variables
first report weighted number tests executed gsmn without
propagation gsimn summarized figure shows ratio
weighted number tests gsimn two versions gsmn one


fiwc gsimn wc gsmn propagation

ratio weighted cost gsimn vs gsmn without propagation




























domain size number variables





wc gsimn wc gsmn without propagation

bromberg margaritis honavar

ratio weighted cost gsimn vs gsmn propagation




























domain size number variables





figure ratio weighted number tests gsimn gsmn without propagation left plot propagation right plot network sizes number
nodes n average degree
ifch x f forward chaining implementation independence test
igsimn x f








query knowledge base
kxy
return
test x true iff test x returns independence
add kxy ky x
run forward chaining inference k update k
return

hundred true networks generated randomly pair n figure shows
mean value see limiting reduction n grows large weighted
number tests depends primarily average degree parameter reduction
gsimn large n dense networks approximately compared gsmn
propagation compared gsmn without propagation optimization
demonstrating benefit gsimn vs gsmn terms number tests executed
one reasonable question performance gsimn extent inference
procedure complete e tests gsimn needs operation
number tests infers applying single step backward chaining
strong union axiom triangle theorem rather executing statistical test
data compare number tests inferred example complete
automated theorem prover eqs measure compared number tests
done gsimn number done alternative call gsimnfch gsimn forward chaining gsimn fch differs gsimn function
ifch shown replaces function igsimn gsimn ifch exhaustively
produces independence statements inferred properties eqs
forward chaining procedure process iteratively builds knowledge base k
containing truth value conditional independence predicates whenever outcome
test required k queried line ifch value test


fiefficient markov network structure discovery independence tests

ratio number tests gsimn fch gsimn









ratio


























number variables n

figure ratio number tests gsimn fch gsimn network sizes number
variables n n average degrees

found k returned line gsimn fch performs test uses
standard forward chaining automatic theorem prover subroutine line produce
independence statements inferred test k adding
facts k
comparison number tests executed gsimn vs gsimn fch presented
figure shows ratio number tests gsimn gsimn fch
figure shows mean value four runs corresponding network generated
randomly pair n n unfortunately two
days execution gsimn fch unable complete execution domains containing
variables therefore present domain sizes
figure shows n every ratio exactly e tests inferable
produced use triangle theorem gsimn smaller domains ratio
exception single case n
sample experiments
set experiments evaluate gsmn without propagation gsimn
data sampled true model allows realistic assessment
performance data sampled true known markov
network gibbs sampling
exact learning experiments previous section structure true
network required generated randomly fashion described sample data
known structure however one needs specify network parameters
random network parameters determine strength dependencies among connected
variables graph following agresti used log odds ratio measure
strength probabilistic influence two binary variables x defined

pr x pr x
xy log

pr x pr x



fibromberg margaritis honavar

hamming distance sampled data
n

gsmn without propagation
gsmn propagation
gsimn































data set size thousands data points

gsmn without propagation
gsmn propagation
gsimn

















































data set size thousands data points


















































data set size thousands data points

































gsmn without propagation
gsmn propagation
gsimn




























hamming distance sampled data
n







data set size thousands data points

gsmn without propagation
gsmn propagation
gsimn














hamming distance sampled data
n







data set size thousands data points







gsmn without propagation
gsmn propagation
gsimn





gsmn without propagation
gsmn propagation
gsimn





normalized hamming distance

normalized hamming distance











hamming distance sampled data
n







data set size thousands data points

gsmn without propagation
gsmn propagation
gsimn







hamming distance sampled data
n





hamming distance sampled data
n











data set size thousands data points



data set size thousands data points











normalized hamming distance

normalized hamming distance









hamming distance sampled data
n









data set size thousands data points

gsmn without propagation
gsmn propagation
gsimn







hamming distance sampled data
n





gsmn without propagation
gsmn propagation
gsimn













data set size thousands data points





gsmn without propagation
gsmn propagation
gsimn



hamming distance sampled data
n
normalized hamming distance

normalized hamming distance

hamming distance sampled data
n







data set size thousands data points






normalized hamming distance





normalized hamming distance



gsmn without propagation
gsmn propagation
gsimn



normalized hamming distance



hamming distance sampled data
n



normalized hamming distance

normalized hamming distance

normalized hamming distance

hamming distance sampled data
n





gsmn without propagation
gsmn propagation
gsimn




























data set size thousands data points

figure normalized hamming distances true network network output
gsmn without propagation gsimn domain size n
average degrees

network parameters generated randomly log odds ratio every
pair variables connected edge graph specified value set
experiments used values every pair variables
network
figures plots normalized hamming distance true
network output gsmn without propagation gsimn
domain sizes n n variables respectively plots
hamming distance gsimn comparable ones gsmn



fiefficient markov network structure discovery independence tests

hamming distance sampled data
n

gsmn without propagation
gsmn propagation
gsimn































data set size thousands data points

gsmn without propagation
gsmn propagation
gsimn

















































data set size thousands data points


















































data set size thousands data points

































gsmn without propagation
gsmn propagation
gsimn




























hamming distance sampled data
n







data set size thousands data points

gsmn without propagation
gsmn propagation
gsimn














hamming distance sampled data
n







data set size thousands data points







gsmn without propagation
gsmn propagation
gsimn





gsmn without propagation
gsmn propagation
gsimn





normalized hamming distance

normalized hamming distance











hamming distance sampled data
n







data set size thousands data points

gsmn without propagation
gsmn propagation
gsimn







hamming distance sampled data
n





hamming distance sampled data
n











data set size thousands data points



data set size thousands data points











normalized hamming distance

normalized hamming distance









hamming distance sampled data
n









data set size thousands data points

gsmn without propagation
gsmn propagation
gsimn







hamming distance sampled data
n





gsmn without propagation
gsmn propagation
gsimn













data set size thousands data points





gsmn without propagation
gsmn propagation
gsimn



hamming distance sampled data
n
normalized hamming distance

normalized hamming distance

hamming distance sampled data
n







data set size thousands data points






normalized hamming distance





normalized hamming distance



gsmn without propagation
gsmn propagation
gsimn



normalized hamming distance



hamming distance sampled data
n



normalized hamming distance

normalized hamming distance

normalized hamming distance

hamming distance sampled data
n





gsmn without propagation
gsmn propagation
gsimn




























data set size thousands data points

figure normalized hamming distance figure domain size n

domain sizes n n average degrees log odds ratios
reinforces claim inference done gsimn small
impact quality output networks
figure shows weighted number tests gsimn vs gsmn without
propagation sampled data set points domains n n
average degree parameters log odds ratios gsimn
shows reduced weighted number tests respect gsmn without propagation
cases compared gsmn propagation cases exceptions
sparse networks weak dependences e
reduction larger domain sizes reduction much larger



fibromberg margaritis honavar

weighted cost sampled data
data points

weighted cost sampled data
data points









gsmn without propagation
gsmn propagation
gsimn











weighted cost sampled data
data points







gsmn without propagation
gsmn propagation
gsimn








gsmn without propagation
gsmn propagation
gsimn










weighted cost sampled data
data points

weighted cost sampled data
data points










gsmn without propagation
gsmn propagation
gsimn

weighted number tests

gsmn without propagation
gsmn propagation
gsimn











gsmn without propagation
gsmn propagation
gsimn









number variables





number variables

weighted cost sampled data
data points

weighted cost sampled data
data points


weighted number tests

gsmn without propagation
gsmn propagation
gsimn










gsmn without propagation
gsmn propagation
gsimn










number variables

weighted cost sampled data
data points




number variables


weighted number tests

weighted number tests



number variables

weighted cost sampled data
data points

weighted number tests

weighted cost sampled data
data points










number variables

number variables



number variables









weighted number tests







weighted cost sampled data
data points
weighted number tests

weighted number tests

gsmn without propagation
gsmn propagation
gsimn













gsmn without propagation
gsmn propagation
gsimn

number variables










number variables



weighted number tests

gsmn without propagation
gsmn propagation
gsimn



weighted number tests



weighted cost sampled data
data points


weighted number tests

weighted number tests





gsmn without propagation
gsmn propagation
gsimn










number variables




number variables

figure weighted number tests executed gsmn without propagation
gsimn domains sizes n average degree
parameters log odds ratios

one observed exact learning experiments actual execution times
data set sizes network densities shown figure largest domain
n verifying reduction cost gsimn data set sizes
note reduction proportional number data points reasonable
test executed must go entire data set construct contingency table
confirms claim cost inference gsimn small constant time per
test see discussion section compared execution time tests
indicates increasing cost benefits use gsimn even large data sets



fiefficient markov network structure discovery independence tests

execution times sampled data sets
n variables

execution times sampled data sets
n variables




gsmn without propagation
gsmn propagation
gsimn

gsmn without propagation
gsmn propagation
gsimn


execution time sec

execution time sec





















execution times sampled data sets
n variables

execution times sampled data sets
n variables




gsmn without propagation
gsmn propagation
gsimn

gsmn without propagation
gsmn propagation
gsimn


execution time sec


execution time sec
























figure execution times sampled data experiments top row
bottom row domain n variables

real world network sampled data experiments
conducted sampled data experiments well known real world networks
known repository markov networks drawn real world domains instead
utilized well known bayesian networks widely used bayesian network
available number repositories generate markov networks
bayesian network structures used process moralization lauritzen
consists two steps connect pair nodes bayesian network
common child undirected edge b remove directions edges
markov network local markov property valid e node
conditionally independent nodes domain given direct neighbors
procedure conditional independences may lost however affect
accuracy compare independencies output network
moralized markov network opposed bayesian network
conducted experiments real world domains hailfinder insurance alarm
mildew water domain sampled varying number data points
corresponding bayesian network logic sampling henrion used input
gsmn without propagation gsimn compared
network output original moralized network
normalized hamming distance metric previously described shown
used http compbio cs huji ac il repository accessed december



fibromberg margaritis honavar

hamming distance hailfinder data set

hamming distance insurance data set

hamming distance alarm data set

gsmn without propagation
gsmn propagation
gsimn
























gsmn without propagation
gsmn propagation
gsimn
















data set size thousands data points











normalized hamming distance

normalized hamming distance


























data set size thousands data points

hamming distance water data set

gsmn without propagation
gsmn propagation
gsimn




gsmn without propagation
gsmn propagation
gsimn




data set size thousands data points

hamming distance mildew data set



normalized hamming distance


normalized hamming distance

normalized hamming distance














gsmn without propagation
gsmn propagation
gsimn



























data set size thousands data points













data set size thousands data points

figure normalized hamming distance network output gsmn
without propagation gsimn true markov networks network
varying data set sizes sampled markov networks real world
domains modeled bayesian networks

fig indicate distances produced three similar
cases e g water hailfinder network resulting use gsimn
actually better smaller hamming distance ones output gsmn

measured weighted cost three domains
shown fig plots significant decrease weighted number tests
gsimn respect gsmn cost gsimn cost
gsmn without propagation average savings cost gsimn
cost gsmn without propagation average savings
real world data experiments
artificial data set studies previous section advantage allowing
controlled systematic study performance experiments
real world data necessary realistic assessment performance real data
challenging may come non random topologies e g possibly
irregular lattice many cases spatial data underlying probability distribution
may faithful
conducted experiments number data sets obtained uci machine
learning data set repository newman hettich blake merz continuous variables
data sets discretized method widely recommended introductory statistics texts scott dictates optimal number equally spaced discretization
bins continuous variable k log n n number points


fiefficient markov network structure discovery independence tests

gsmn without propagation
gsmn propagation
gsimn








gsmn without propagation
gsmn propagation
gsimn



weighted cost tests

weighted cost tests



weighted cost tests insurance data set



































data set size thousands data points













gsmn without propagation
gsmn propagation
gsimn




























data set size thousands data points









data set size thousands data points

figure weighted cost tests conducted gsmn without propagation
gsimn real world domains modeled bayesian
networks
weighted cost accuracy real world data sets

acc gsimn acc gsmn without propagation
acc gsimn acc gsmn propagation
wc gsimn wc gsmn without propagation
wc gsimn wc gsmn propagation





















data set index



figure ratio weighted number tests gsimn versus gsmn difference
accuracy gsimn gsmn real data sets ratios smaller
positive bars indicate advantage gsimn gsmn
numbers x axis indices data sets shown table

data set data set report weighted number conditional independence tests conducted discover network accuracy defined






data set size thousands data points

weighted cost tests water data set

gsmn without propagation
gsmn propagation
gsimn

weighted cost tests

weighted cost tests



data set size thousands data points

weighted cost tests mildew data set


gsmn without propagation
gsmn propagation
gsimn







weighted cost tests alarm data set

weighted cost tests

weighted cost tests hailfinder data set

fibromberg margaritis honavar

table weighted number tests accuracy several real world data sets
evaluation measure best performance gsmn without
propagation gsimn indicated bold number variables
domain denoted n number data points data set n






















data set
name
echocardiogram
ecoli
lenses
hayes roth
hepatitis
cmc
balance scale
baloons
flag
tic tac toe
bridges
car
monks
haberman
nursery
crx
imports
dermatology
adult

n

n









































weighted number tests
gsmn
gsmn
gsimn
w prop w prop


























































gsmn
w prop




















accuracy
gsmn
w prop




















gsimn




















real world data structure underlying bayesian network
unknown impossible measure hamming distance resulting network
structure instead measured estimated accuracy network produced gsmn
gsimn comparing true false number conditional independence
tests network learned vertex separation tests
performed data set test similar estimating accuracy
classification task unseen instances inputs triplets x z
class attribute value corresponding conditional independence test
used real world data set randomly sampled input gsmn gsimn
entire data set test corresponds hypothetical scenario
much smaller data set available researcher approximates true value
test outcome entire data set since number possible tests
exponential estimated independence accuracy sampling triplets x z
randomly evenly distributed among possible conditioning set sizes n
e n tests triplets constructed follows
first two variables x drawn randomly v second conditioning set
determined picking first variables random permutation v x
denoting set triplets triplet idata test
performed entire data set inetwork test performed



fiefficient markov network structure discovery independence tests

network output gsmn gsimn estimated accuracy defined

ofifi
fifin
inetwork idata fifi
accuracy



data sets table shows detailed accuracy weighted
number tests gsmn gsimn plotted
figure horizontal axis indicating data set index appearing first column
table figure plots two quantities graph real world data sets
ratio weighted number tests gsimn versus two gsmn
difference accuracies data set improvement gsimn
gsmn corresponds number smaller ratios positive histogram bar
accuracy differences observe gsimn reduced weighted number
tests every data set maximum savings gsmn without propagation
crx data set gsmn propagation crx data set
well moreover data sets gsimn resulted improved accuracy tie
somewhat reduced accuracy compared gsmn propagation
nursery balance scale data sets

conclusions future
presented two gsmn gsimn learning efficiently
structure markov network domain data independence
opposed np hard maximum likelihood estimation
evaluated performance measurement weighted number tests
require learn structure network quality networks learned
artificial real world data sets gsimn showed decrease vast majority
artificial real world domains output network quality comparable
gsmn cases showing improvement addition gsimn shown
nearly optimal number tests executed compared gsimn fch uses
exhaustive search produce independence information inferred pearls
axioms directions future include investigation way topology
underlying markov network affects number tests required quality
resulting network especially commonly occurring topologies grids another
topic impact number tests examination grow orderings
variables

acknowledgments
thank adrian silvescu insightful comments accuracy measures general advice
theory undirected graphical

appendix correctness gsmn
variable x v examined main loop gsmn lines
set bx variable x v constructed growing shrinking set


fibromberg margaritis honavar

starting empty set x connected member bx produce
structure markov network prove procedure returns actual markov
network structure domain
proof correctness make following assumptions
axioms eqs hold
probability distribution domain strictly positive required intersection
axiom hold
tests conducted querying oracle returns true value underlying model
examines every variable x inclusion thus bx
grow phase lines added grow phase
considers removal shrinking phase lines note
one test executed x growing phase x call grow
test x line similarly one tests executed x
shrinking phase test executed called shrink test x line

general idea behind proof learning blanket x
variable end shrinking phase dependence x
v x x holds according theorem end
appendix implies edge x immediately prove one
direction
lemma
end shrink phase xy v x
proof let us assume
end shrink phase
added set grow phase e line never reached removed
shrink phase e line reached former true
pxy line indicating x unconditionally independent found
independent x line latter true found independent x
line cases v x xy strong union
xy v x
opposite direction proved lemma however proof involved
requiring auxiliary lemmas observations definitions two main auxiliary
lemmas use lemma presented next lemma inductively extend
conditioning set dependencies found grow shrink tests x
remaining variables v x lemma shows certain independence
holds conditioning set dependence increased one variable
lemma let x v z v x z z w v
x z xw z x z w



fiefficient markov network structure discovery independence tests

proof prove contradiction make use axioms intersection strong
union su decomposition let us assume x z xw z
xy z w
xy z w xw z
su



xy z w xw z



x w z





xy z xw z



xy z



contradicts assumption x z
introduce notation definitions prove auxiliary lemmas
denote sg value end grow phase line e set
variables found dependent x grow phase ss value end
shrink phase line denote g set variables found independent
x grow phase u u uk sequence variables shrunk
bx e found independent x shrink phase sequence u assumed
ordered follows j variable ui found independent x uj
shrinking phase prefix first variables u ui u denoted
ui test performed define k integer
uk prefix u containing variables found independent x
loop furthermore abbreviate uk ut
definition u fact grow phase conditioning set
increases dependent variables immediately make following observation
observation variable ui u denotes shrink test performed
x ui ut ui
relate conditioning set shrink test ut follows
lemma ss x z shrink test z sg ut
proof according line z beginning shrink
phase line sg variables found independent afterward conducted
removed line thus time performed sg ut
conditioning set becomes sg ut
corollary xui sg ui
proof proof follows immediately lemma observation fact
ui ui ui
following two lemmas use lemma inductively extend conditioning set
dependence x variable ss first lemma starts shrink
test x dependence extends conditioning set ss
equivalently sg ut according lemma sg


fibromberg margaritis honavar

lemma ss shrink test x sg
proof proof proceeds proving
x sg ui
induction decreasing values k starting k
lemma follows noticing u
base case k lemma x sg ut equals
x sg uk definition ut since ss must case
found dependent e x sg uk
inductive step let us assume statement true k
x sg um



need prove true
x sg um
corollary
xum sg um
strong union
xum sg um

xum sg um



eqs lemma get desired relation
x sg um um x sg um

observation definition sg every test x z performed
grow phase z sg
following lemma completes extension conditioning set dependence
x ss universe variables v x starting sg
lemma left extending sg g
lemma ss x sg g
proof proof proceeds proving
x sg gi
induction increasing values g gi denotes first elements
arbitrary ordering set g


fiefficient markov network structure discovery independence tests

base case follows directly lemma since g
inductive step let us assume statement true g
x sg gm



need prove true
x sg gm



observation grow test gm independence
xgm z z sg
strong union axiom become
xgm z z sg



xgm z z sg



equivalently
since z sg sg gm z sg gm eq
lemma get desired relation
x sg gm gm x sg gm

finally prove x dependent every variable ss given universe
v x
lemma ss x v x
proof lemma
x sg g
suffices prove sg g v x loop gsmn
queue x populated elements v x line removed
x grow phase partitions x variables dependent x set sg
independent x set g
corollary ss x v x
proof follows directly lemmas
corollary immediately graph returned
connecting x member bx ss exactly markov network domain
following theorem first published pearl paz
theorem pearl paz every dependence model satisfying symmetry decomposition intersection eqs unique markov network g v e produced
deleting complete graph every edge x xy v x holds
e
x
e xy v x


fibromberg margaritis honavar

appendix b correctness gsimn
gsimn differs gsmn use test subroutine igsimn
instead igsmn respectively turn differs number
additional inferences conducted obtain independencies lines
inferences direct applications strong union axiom holds assumption
triangle theorem proven hold theorem correctness
gsmn proven appendix therefore conclude gsimn
correct

references
abbeel p koller ng learning factor graphs polynomial time
sample complexity journal machine learning
acid de campos l searching bayesian network structures
space restricted acyclic partially directed graphs journal artificial intelligence

agresti categorical data analysis nd edition wiley
aliferis c f tsamardinos statnikov hiton novel markov blanket
optimal variable selection proceedings american medical
informatics association amia fall symposium
anguelov taskar b chatalbashev v koller gupta heitz g ng
discriminative learning markov random fields segmentation range
data proceedings conference computer vision pattern recognition
cvpr
barahona f computational complexity ising spin glass journal
physics mathematical general
besag j spacial interaction statistical analysis lattice systems journal
royal statistical society series b
besag j york j mollie bayesian image restoration two applications
spatial statistics annals institute statistical mathematics
bromberg f margaritis honavar v efficient markov network structure discovery independence tests proceedings siam international conference
data mining
buntine w l operations learning graphical journal artificial
intelligence
castelo r roverato robust procedure gaussian graphical model search
microarray data p larger n journal machine learning

chow c liu c approximating discrete probability distributions dependence trees ieee transactions information theory



fiefficient markov network structure discovery independence tests

cochran w g methods strengthening common tests biometrics

della pietra della pietra v lafferty j inducing features random fields
ieee transactions pattern analysis machine intelligence
dobra hans c jones b nevins j r yao g west sparse graphical
exploring gene expression data journal multivariate analysis

edwards introduction graphical modelling nd edition springer
york
friedman n linial nachman peer bayesian networks
analyze expression data computational biology
geman geman stochastic relaxation gibbs distributions bayesian
relation images ieee transactions pattern analysis machine intelligence

heckerman tutorial learning bayesian networks tech rep msr tr
microsoft
heckerman geiger chickering learning bayesian networks
combination knowledge statistical data machine learning
henrion propagation uncertainty probabilistic logic sampling bayes
networks lemmer j f kanal l n eds uncertainty artificial intelligence elsevier science publishers b v north holland
hofmann r tresp v nonlinear markov networks continuous variables
neural information processing systems vol pp
isard pampas real valued graphical computer vision ieee
conference computer vision pattern recognition vol pp
jerrum sinclair polynomial time approximation ising
model siam journal computing
kearns j vazirani u v introduction computational learning theory
mit press cambridge
koller sahami toward optimal feature selection international conference machine learning pp
lam w bacchus f learning bayesian belief networks
mdl principle computational intelligence
lauritzen l graphical oxford university press
margaritis thrun bayesian network induction via local neighborhoods
solla leen muller k r eds advances neural information processing
systems pp mit press
mccallum efficiently inducing features conditional random fields proceedings uncertainty artificial intelligence uai



fibromberg margaritis honavar

newman j hettich blake c l merz c j uci repository machine
learning databases tech rep university california irvine dept information
computer sciences
pena j learning gaussian graphical gene networks false discovery rate control proceedings th european conference evolutionary
computation machine learning data mining bioinformatics pp
pearl j probabilistic reasoning intelligent systems networks plausible inference morgan kaufmann publishers inc
pearl j paz graphoids graph logic reasoning releveance
relations tech rep r l cognitive systems laboratory university
california
rebane g pearl j recovery causal poly trees statistical data
kanal l n levitt lemmer j f eds uncertainty artificial
intelligence pp amsterdam north holland
schafer j strimmer k empirical bayes inferring large scale
gene association networks bioinformatics
scott w multivariate density estimation wiley series probability
mathematical statistics john wiley sons
shekhar zhang p huang vatsavai r r kargupta h joshi
sivakumar k yesha eds trends spatial data mining chap pp
aaai press mit press
spirtes p glymour c scheines r causation prediction search nd
edition adaptive computation machine learning series mit press
srebro n karger learning markov networks maximum bounded tree width
graphs acm siam symposium discrete
tsamardinos aliferis c f statnikov large scale markov
blanket discovery proceedings th international flairs conference pp

tsamardinos aliferis c f statnikov b time sample efficient discovery markov blankets direct causal relations proceedings th acm
sigkdd international conference knowledge discovery data mining pp

tsamardinos brown l e aliferis c f max min hill climbing bayesian
network structure learning machine learning
whittaker j graphical applied multivariate statistics john wiley
sons york




