journal artificial intelligence

submitted published

coherent predictive inference exchangeability
imprecise probabilities
gert de cooman
jasper de bock

gert decooman ugent
jasper debock ugent

ghent university systems group
technologieparkzwijnaarde
zwijnaarde belgium

mrcio alves diniz

marcio alves diniz gmail com

federal university carlos department statistics
rod washington luis km
carlos brazil

abstract
coherent reasoning uncertainty represented general manner
coherent sets desirable gambles context allow indecision leads
mathematically equivalent working coherent conditional
probabilities allow indecision leads general foundation coherent
imprecise probabilistic inference framework given finite category set
coherent predictive inference exchangeability represented bernstein
coherent cones multivariate polynomials simplex generated category set
powerful generalisation de finettis representation theorem allowing
imprecision indecision
define inference system map associates bernstein coherent cone
polynomials every finite category set many inference principles encountered
literature interpreted represented mathematically restrictions
maps discuss particular examples two important inference principles representation
insensitivitya strengthened version walleys representation invarianceand specificity
infinity inference systems satisfy two principles
amongst discuss particular skeptically cautious inference system inference
systems corresponding modified version walley bernards imprecise dirichlet
multinomial idmm skeptical idmm inference systems haldane
inference system prove latter produces posterior inferences
would obtained haldanes improper prior implying infinity
proper priors produce coherent posterior inferences haldanes improper one
finally impose additional inference principle allows us characterise uniquely
immediate predictions idmm inference systems

introduction
deals predictive inference categorical variables therefore concerned
possibly infinite sequence variables xn assume values finite set
categories observed number n found say x x
x x xn xn consider subjects belief model next n variables
xn xn n probabilistic traditionand want build tradition
ai access foundation rights reserved

fide cooman de bock diniz

context paperthis belief modelled conditional predictive probability
mass function pn x xn set possible values probability mass
functions used prediction estimation statistical inferences decision
making involving uncertain values variables sense predictive inference lies
heart statistics generally learning uncertainty reason
crucial importance dealing uncertainty artificial intelligence
instance intelligent systems learn multinomial probabilities markov
transition probabilities rates occurrence phenomena local probabilities bayesian
credal networks refer synthesis geisser collection
essays zabell good introductions predictive inference underlying
issues present concerned
connects predictive probability mass functions values n n
x xn requirements time consistency coherence former requires
n n pn x xn obtained pn x xn
usual marginalisation procedure latter essentially demands conditional
probability mass functions connected time consistent unconditional probability
mass functions bayess rule
common assumption variables xn exchangeable meaning
roughly subject believes order observed present
influence decisions inferences make regarding
variables assumption analysis consequences goes back de finetti
see cifarelli regazzini famous representation theorem states
essence time consistent coherent conditional unconditional predictive
probability mass functions associated countably infinite exchangeable sequence
variables completely characterised completely characterisea unique
probability measure borel sets simplex probability mass functions
called representation
leads us central predictive inference since infinity
probability measures simplex one subject choose particular
context given choice motivated justified subjectivists de
finettis persuasion might answer question needs answer subjects personal
predictive probabilities entirely time consistency coherence
requirements heed earlier scholars laplace bayes would
call subjectivists invoked principle indifference justify specific class
predictive mass functions proponents logicist predictive inference would
try enunciating general inference principles order narrow hopefully eliminate
entirely possible choices representing probability measures simplex
logicians w e johnson much systematic fashion rudolf carnap
unless observed sequence probability zero
actually order clarify connection shall later essence de finettis
argument representation coherent prevision set multinomial polynomialsor
equivalently continuous real functionson simplex de cooman quaeghebeur miranda
b finitely additive coherent prevision extended uniquely far set
lower semicontinuous functions determine unique countably additive probability
measure borel sets simplex f riesz representation theorem de cooman
miranda troffaes de cooman



ficoherent predictive inference exchangeability

tried develop axiom system predictive inference reasonable inference
principles carnaps first group axioms related called coherence
suggested weak single particular predictive
model second group consisted invariance axioms including exchangeability
included axiom instantial relevance translating intuitive principle predictive
inferences actually learn experience last axiom predictive irrelevance
proposed earlier johnson called sufficientness postulate good
armed axioms carnap able derive continuum probabilistic inference
rules closely related dirichlet multinomial model imprecise dirichlet
multinomial model idmm proposed walley walley bernard
discuss appendices c respectively
point view holds middle ground subjectivist logicist positions
possible subject make assessments certain predictive probabilities
combine certain inference principles finds reasonable suit
purpose hand indeed inference systems introduce discuss
section notion conservative coherent inferenceor natural extensionwe
associate provide elegant framework tools making conservative coherent
predictive inferences combine local subjective probability assessments general
inference principles work section characterising immediate predictions
idmm constitutes exercise inor example forprecisely
idea conservative probabilistic inference brings us believe
main contribution central idea de finettis
probabilitybut course implicit markov chebyshev inequalitiesthat
subject makes probability assessments consider bounds called
precise probability calculating conservative tightest bounds indeed
de finettis fundamental theorem prevision see lad
theory imprecise probabilities brought synthesis williams walley
going back boole keynes crucial contributions
quite number statisticians philosophers smith levi seidenfeld
schervish kadane looks conservative probabilistic inference precisely
way calculate efficiently possible consequencesin sense
conservative tightest boundsof making certain probability assessments may local
assessments inequalities imposed probabilities previsions certain events
variables structural assessments independence exchangeability
one advantage imprecise probability allow imprecision
words use partial probability assessments bounding inequalities rather
equalities another related advantage allow indecision modelled
explicitly loosely stated imposed bounds probabilities allow one
probability model solution may well two actions first
higher expected utility one compatible probability model smaller another
compatible probability model meaning neither action robustly preferred
current stated model beliefs subject undecided
actions section give concise overview relevant ideas techniques
field imprecise probabilities much extensive detailed recent overview
area published augustin coolen de cooman troffaes


fide cooman de bock diniz

present described application ideas imprecise probabilities predictive inference aim studyand develop general framework
dealing withconservative coherent predictive inference imprecise probability
allow us represent subjects indecision believe
natural state knowing learned little hand
seems important theories learning uncertainty general predictive
inference particular least allow us start conservative imprecise
indecisive little learned ii become precise decisive
observations come shall see abstract notion inference system
introduce allows forbut necessarily forcesuch behaviour
shall give number examples concrete inference systems display
work builds manages reach much earlier
one authors de cooman miranda quaeghebeur one reason
earlier work deals immediate prediction shall
see predictive inference imprecise probabilities completely determined
immediate prediction contrary expect precise probabilities
main reason position use powerful mathematical
language represent imprecise probabilistic inferences walleys coherent sets
desirable gambles earlier imprecise probability boole koopman
centred lower upper probability bounds eventsor propositions later walley
section became apparent language events lower upper
probabilities lacking power expression much expressive theory uses random
variables lower previsions expectations successful theory coherent lower
previsions quite well developed walley augustin et al troffaes
de cooman faces number mathematical well
conceptual complexity especially dealing conditioning independence
fact case many approaches probability shall see
section issues conditioning sets lower probability zero
attractive solution offered walley form
coherent sets desirable gambles inspired earlier ideas smith williams b
seidenfeld schervish kadane primitive notions probabilities
events expectations random variables focus rather whether gamble
risky transaction desirable subjectstrictly preferred zero transaction
status quo basic belief model probability measure lower prevision
set desirable gambles course stating gamble desirable leads
particular lower prevision assessment provides lower bound zero prevision
gamble explain prefer use sets desirable gambles basic uncertainty
section
summary aim use sets desirable gambles extend
existing probabilistic theory predictive inference let us explain detail
intend go basic building blocks introduced sections
already indicated give overview relevant notions concerning
imprecise probability model choicecoherent sets desirable gamblesin section
particular explain use conservative inference well conditioning


ficoherent predictive inference exchangeability

derive commonly used lower previsions lower probabilities
relate precise probability
section explain describe subjects beliefs sequence
variables terms predictive sets desirable gambles derived notion predictive
lower previsions imprecise probability generalise mentioned predictive
probability mass functions pn x xn constitute basic tools shall
working explain proper formulations mentioned
time consistency coherence requirements general context
section discuss number inference principles believe could reasonably
imposed predictive inferences represent mathematically
terms predictive sets desirable gambles lower previsions pooling invarianceor
walley called representation invariance principle rip renaming
invariance seem reasonable requirements type predictive inference category
permutation invariance seems natural thing require starting state
complete ignorance taken together constitute call representation insensitivity
means predictive inferences remain essentially unchanged transform
set categories words essentially insensitive choice
representationthe category set another inference principle look imposes called
specificity property predictive inference specific certain type question
involving restricted number categories general model replaced
specific model deals categories interest produce
relevant inferences bernard
next important step taken section recall literature de
cooman et al b de cooman quaeghebeur deal exchangeability
predictive inference imprecise recall de finettis representation
theorem significantly generalised case time consistent coherent
predictive sets desirable gambles completely characterised set multivariate
polynomials simplex probability mass functions category set
set polynomials must satisfy number properties taken together define
notion bernstein coherence without becoming technical point conclusion
section general context precise probabilistic notion
representing probability measure simplex probability mass functions replaced
bernstein coherent set polynomials simplex set polynomials serves
completely purpose representing probability measure completely determines
conveniently densely summarises predictive inferences reason
rest developments expressed terms bernstein coherent
sets polynomials
introduce coherent inference systems section maps associate
finite set categories bernstein coherent set polynomials simplex probability
mass functions set coherent inference system way fixing completely
coherent predictive inferences possible category sets reasons introducing
coherent inference systems twofold first inference principles section impose
connections predictive inferences different category sets represent
contradistinction de finettis version version conditioning observed
sequences lower probability zero



fide cooman de bock diniz

inference principles mathematically restrictions coherent inference systems
main topic section secondly allows us extend method natural extensionor
conservative inferenceintroduced section take account principles
predictive inference generally predictive inference multiple category sets
leads method combining local predictive probability assessments global
inference principles produce conservative predictive inferences compatible

first illustration power methodology look immediate prediction
section implications representation insensitivity specificity
predictive inference single next observation allows us
streamline simplify significantly extend previous attempts direction de
cooman et al
material sections shows producing explicit examples
quite different typeseven uncountable infinitiesof coherent inference systems
representation insensitive specific discuss vacuous nearly vacuous
inference systems sections skeptically cautious inference system section
family idmm inference systems section family skeptical idmm inference
systems section haldane inference system section inference
systems apart idmm appear first time believe
first detailed explicitas well still elegantproof idmm
inference systems indeed representation insensitive specific already
mentioned however idmm inference systems modified
arguably better behaved version originally introduced walley bernard
see walley walley bernard bernard refer appendix
explanation proof original idmm specific contrary
often claimed satisfy called nestedness property
disprove conjecture bernard de cooman et al
idmm inference systemsour version original oneare ones even
conservative ones satisfy representation insensitivity specificity
section idmm family immediate predictionswhich
version original oneare definite sense conservative ones
representation insensitive specific satisfy another requirement
called concave surprise
conclusion section point number surprising consequences
discuss avenues
order make self contained possible included number
appendices additional discussion help reader way many
notions notations need appendix provides list common
ones short hint meaning introduced appendix b provides
useful necessary background theory multivariate polynomials simplices
important part bernstein basis polynomials discussion idmm
inference systems relies quite heavily dirichlet densities simplices expectation
operators associated discuss important relevant properties
appendix c appendix contains discussion original idm idmm
proposed walley bernard see walley walley bernard bernard


ficoherent predictive inference exchangeability

claims make model need
carefully formulated stated main reason introducing
section modified version idmm suffer
shortcomings produces immediate prediction original version
finally effort make lengthy readable possible moved
proofs additional technical discussion appendix e

imprecise probability
section give concise overview imprecise probability representing
making inferences decisions uncertainty suggested introduction
shall focus sets desirable gambles uncertainty choice
let us briefly summarise next section present work
sets basic uncertainty conservative probabilistic inference reader
wants dispense motivation proceed section introduce
mathematics behind later sections shall course briefly mention
derived terms familiar language lower previsions probabilities
sets desirable gambles
first number examples literature moral couso moral de
cooman quaeghebeur de cooman miranda shown working
making inferences general expressive
simpler elegant mathematical point view intuitive
geometrical interpretation quaeghebeur shall see sections
marginalisation conditioning especially straightforward issues
conditioning sets lower probability zero
become apparent discussion section explained
detail moral wilson de cooman miranda
similarity accepting gamble one hand accepting proposition true
gives logical flavour conservative probabilistic inference indeed
strong analogy two connects conservative probabilistic inferencealso
called natural extension fieldwith logical deduction classical propositional
logic looking smallest deductively closed set contains number given
propositions imprecise probabilities context looking smallest coherent set
desirable gambles contains number given gambles context analogy
precise probability closely related complete maximal deductively closed
setsperfect information states clear indication precise probability
well suited dealing conservative inference need
broader context imprecise probability natural language setting
summary working sets desirable gambles encompasses subsumes
special cases classical precise probabilistic inference inference classical
propositional logic see detailed discussion de cooman miranda
finally briefly explain section de cooman quaeghebeur
shown working sets coherent desirable gambles especially illuminating
context modelling exchangeability assessments exposes simple geometrical meaning


fide cooman de bock diniz

notion exchangeability leads simple particularly elegant proof
significant generalisation de finettis representation theorem exchangeable
random variables
summary work sets desirable gambles powerful
expressive general hand intuitive work withthough
unfortunately less familiar people closely involved field
importantly avoid conditioning sets lower probability
zero details refer work walley moral couso moral
de cooman quaeghebeur quaeghebeur
coherent sets desirable gambles natural extension
consider variable x assumes values finite possibility space model
subjects beliefs value x looking gambles variable
subject finds desirable meaning strictly prefers zero gamblethe status
quo general extends usual rationalist subjectivist
probabilistic modelling allow indecision imprecision
gamble real valued function f interpreted uncertain reward f x
depends value x expressed units predetermined linear utility
represents reward subject gets transaction first actual value x
x determined subject receives amount utility f x may
negative meaning pay throughout use device writing f x
want make clear variable x gamble f depends
events subsets possibility space event b associate
special gamble ib called indicator assumes value b elsewhere
denote set gambles l linear space point wise
addition gambles point wise multiplication gambles real numbers
subset l posi set positive linear combinations gambles
posi


n


k fk fk k r n n



k

n set natural numbers without zero r set positive real
numbers convex cone gambles subset l closed positive linear
combinations meaning posi
two gambles f g write f g x f x g x f g
f g f g gamble f called positive gamble g called non positive
sake simplicity restrict discussion finite possibility spaces
really need purposes limited number remarks shall
occasion mention related notions infinite possibility spaces give ample references
guide interested reader relevant literature
want point notion strict preferenceor preference without indifferencecommonly
used preference modelling confused walleys section notion strict
desirability one many ways construct lower prevision set gambles
strictly preferred zero gamble see discussion near end section
details refer recent quaeghebeur de cooman hermans



ficoherent predictive inference exchangeability

l denotes convex cone positive gambles l convex cone
non positive gambles
collect gambles subject finds desirablestrictly prefers zero gamble
set desirable gambles shall take sets basic uncertainty
course satisfy certain rationality criteria
definition coherence set desirable gambles l called coherent
satisfies following requirements


l
posi
denotes set coherent sets desirable gambles
requirement turns convex cone due includes l
avoids non positivity
f f
posi equivalently l posi
l smallest coherent subset l called vacuous model therefore
reflects minimal commitments part subject knows absolutely nothing
likelihood different outcomes strictly prefer zero
gambles never decrease wealth possibility increasing
subject set desirable gambles conservative less
committal subject set desirable gambles simply latter strictly
prefers zero gambles former possibly inclusion relation
imposes natural partial ordering sets desirable gambles simple interpretation
least conservative
non empty family coherent sets desirable gambles di intersection
ii di still coherent simple underlies notion conservative coherent
inference subject gives us assessmenta set l gambles
finds desirablethen tells us exactly assessment extended coherent
set desirable gambles construct smallestand therefore least committal
conservativesuch set
theorem natural extension de cooman quaeghebeur let l
define natural extension

ea

following statements equivalent
avoids non positivity l posi
ii included coherent set desirable gambles
see footnote

usual expression let l



fide cooman de bock diniz

iii ea l
iv set desirable gambles ea coherent
v ea smallest coherent set desirable gambles includes
hence equivalent statements holds ea posi l
moreover coherent l ea
maximal coherent sets desirable gambles
element called maximal strictly included element
words adding gamble f makes sure longer extend
set f set still coherent

denotes set maximal elements coherent set desirable gambles
maximal non zero gambles f f
f see couso
moral case finite de cooman quaeghebeur infinite
case coherence natural extension described completely terms maximal
elements
theorem couso moral de cooman quaeghebeur set avoids
non positivity
maximal moreover

ea
conditioning sets desirable gambles
let us suppose subject coherent set desirable gambles expressing
beliefs value variable x assumes ask called
updated set dcb desirable gambles b would receive additional
informationand nothing morethat x actually belongs subset b
updating conditioning rule sets desirable gambles states
g dcb gib gambles g b



states gamble g desirable subject observe x b
called gamble gib desirable called gamble gib
gamble variable x gives zero rewardis called offunless x b
case reduces gamble g possibility space b updated set dcb
set desirable gambles b still coherent provided de cooman
quaeghebeur see discussions moral couso moral de
cooman quaeghebeur de cooman miranda quaeghebeur
detailed information updating sets desirable gambles
coherent lower previsions
use coherent sets desirable gambles introduce derived concepts coherent
lower previsions probabilities


ficoherent predictive inference exchangeability

given coherent set desirable gambles functional p defined l
p f sup r f f l



coherent lower prevision walley thm means lower
envelope expectations associated set probability mass functions
equivalently satisfies following coherence properties walley de
cooman quaeghebeur miranda de cooman troffaes de cooman
p p f min f gambles f
p p f g p f p g gambles f g
p p f p f gambles f real
used notation min f min f x x max f defined similarly
conjugate upper prevision p defined p f inf r f p f
following properties implied p p
p max f p f p f min f gambles f
p p f p f p f p f gambles f r
gamble f p f called lower prevision f follows equation
interpreted subjects supremum desirable price buying gamble f
event b p ib denoted p b called lower probability b
interpreted subjects supremum desirable rate betting b similarly
upper previsions upper probabilities
lower prevision associated vacuous set desirable gambles l given
p f min f called vacuous lower prevision point wise smallest
conservative coherent lower previsions
coherent conditional model dcb b non empty subset induces conditional lower prevision p b l b invoking equation
p g b sup r g dcb sup r g ib
gambles g b
difficult walley p p b related following
coherence condition
p g p g b ib g l b
gbr
called generalised bayes rule rule allows us infer p b uniquely p
provided p b otherwise usually infinity coherent lower previsions
p b coherent p sense satisfy gbr equivalently
coherent set desirable gambles leads p p b two
statement valid working finite infinite similar shown
hold walley de cooman quaeghebeur miranda de cooman troffaes
de cooman expectations involved coherent previsionsexpectation operators
associated finitely additive probability measures see discussion section



fide cooman de bock diniz

particular conditioning rules namely natural regular extension walley miranda
de cooman produce conditional lower previsions satisfy gbr
therefore coherent p p b necessarily p b
produce point wise smallest largest coherent conditional lower previsions
respectively miranda miranda de cooman
many different coherent sets desirable gambles lead coherent lower prevision
p typically differ boundaries sense coherent sets desirable
gambles informative coherent lower previsions gamble positive lower
prevision desirable one negative lower prevision never gamble
zero lower prevision lies border set desirable gambles lower
prevision generally provide information desirability gambles
border behaviour importantand dealing conditioning events
zero lower probability walley moral couso moral quaeghebeur
useful work sets desirable gambles rather lower previsions
equations tell us allow us derive unique conditional
unconditional ones coherent set desirable gambles corresponds unique
conditional set desirable gambles dcb unique conditional lower prevision p b
non empty event b smallest set desirable gambles induces given coherent
lower prevision called associated set strictly desirable gambles walley
given f l f p f see papers walley quaeghebeur
additional discussion sets desirable gambles informative
coherent lower previsions
linear previsions credal sets
coherent lower upper prevision coincide gambles real
functional p defined l p f p f p f f l coherent prevision
since assumed finite means corresponds
expectation

operator associated probability mass function p p f xa f x p x ep f
f l p x p x x happens particular lower
upper previsions induced maximal coherent set desirable gambles indeed
boundary behaviour called precise probability p correspond maximal
coherent sets desirable gambles see discussions williams miranda
zaffalon proposition couso moral section information
coherent previsions p generalised bayes rule gbr reduces bayess rule
p gib p b p g b g l b

br

indicating central probabilistic updating rule special case equation
conditional lower previsions section idmm produced regular extension
sections lower previsions amongst nearly cases
different conditional lower previsions even though cases natural regular extensions
coincidethey vacuous
already hinted footnote similar things still said infinite would unduly
complicate discussion details see work walley troffaes de cooman
miranda de cooman



ficoherent predictive inference exchangeability

assumed finite define called credal set p associated
coherent lower prevision p
p p f l ep f p f
closed convex subset called simplex probability mass
functions p lower envelope p p f min ep f p p
f l walley miranda de cooman troffaes de cooman
sense convex closed sets precise probability seen
imprecise probability mathematically equivalent coherent lower
previsions therefore less general powerful coherent sets desirable
gambles suffer conditioning events lower probability
zero

predictive inference
predictive inference specific sense focussing considers number
variables x xn assuming values category set awe define category set
non empty finite set follows shall occasion use many different
category sets shall use italic capitals b c refer
start discussion predictive inference general representationally powerful language coherent sets desirable gambles introduced previous
section shall pay attention specific derived
predictive lower previsions predictive lower probabilities
predictive inference assumes generally number n observations made
x xn first n variables x xn
know values
n c
values
subject posterior predictive model da
observation sample
n
n
coherent set
next n variables xn xn n assume da c
desirable gambles f xn xn n assume n n
hand want allow n n n set natural numbers
zero want able deal case previous observations
n prior predictive model course
made case call corresponding model da
technically speaking n n n
said subject may prior unconditional model obn
servations yet made general form coherent set da
see section explicit definition
sets full conditional measures dubins cozman rather sets probability
mass functions leads imprecise probability model related sets desirable gambles couso
moral conditioning sets lower probability zero
feel less elegant mathematically complicated
formal reasons include trivial case category sets single element case
certain value variables assume
terms posterior prior association predictive indicate whether previous
observations made order avoid well known issues temporal coherence
zaffalon miranda assuming prior posterior
subjects beliefs observations made posterior refer hypothetical
future situations



fide cooman de bock diniz

n
desirable gambles f x xn n n may coherent sets da
n
desirable gambles f x xn n natural number
n n must related following
n n sets da

marginalisation time consistency requirement
n
n
f x xn da
f x xn da
gambles f



expression throughout identify gamble f cylindrical
extension f defined f x xn xn f x xn x xn
introduce marginalisation operator margn l time consistency
n marg n n l
condition rewritten simply da
n


n posterior conditional ones n c
prior unconditional predictive da
must
related following updating requirement
n
n
f xn xn n
f xn xn n da
c
x xn da

gambles f
special case equation gamble f xn xn n desirable observ gamble f xn xn n
ing sample
x xn desirable
observations made called gamble f xn xn n
x xn

gamble gives zero rewardis called offunless first n observations
case reduces gamble f xn xn n remaining variables
xn xn n updating requirement generalisation bayess rule updating
fact reduces sets desirable gambles lead precise probability
mass functions described section proved detail walley
de cooman miranda contrary bayess rule probability mass
functions updating rule coherent sets desirable gambles clearly suffer
conditioning event lower probability zero allows us infer
unique conditional model unconditional one regardless lower upper
probability conditioning event refer work de cooman miranda
detailed discussions marginalisation updating sets desirable gambles
many variable context
explained section use relationship derive prior unconditional
n
predictive lower previsions p na l prior set da
n
p na f sup r f da
gambles f n n

l posterior
posterior conditional predictive lower previsions p na
n

sets da c


n
sup r f da
gambles f
p na f
c
see related discussion notion de cooman miranda b de cooman
quaeghebeur confused temporal consistency discussed goldstein
zaffalon miranda



ficoherent predictive inference exchangeability

shall want condition predictive lower previsions additional
information xn xn n b n proper subset b ideas
sections leads instance following lower prevision


n
b n sup r g ib n da
gambles g b n
p na g
c

conditioned event b n
lower prevision p na

principles predictive inference
far introduced coherence marginalisation updating basic rationality
requirements prior posterior predictive inference must satisfy could
envisaged requirementsother inference principlescan imposed
inference want deal additional
requirements theory conservative predictive inference discuss way
examples number additional conditions suggested number
authors reasonable properties ofor requirements forpredictive inference
want stress considering requirements examples want
defend circumstances mean suggest reasonable
useful inference principles might want impose whose
implications conservative predictive inference might therefore want investigate
pooling invariance
first consider walleys notion representation invariance prefer call
pooling invariance consider set categories partition b non empty
partition classes course consider partition b set categories well
therefore order streamline discussion notation shall henceforth denote
bas stated want use italic capitals category sets elements
subset c acorresponds single category consists original
categories x c pooledconsidered one denote x unique element
partition b original category x belongs leads us consider surjective
onto map b
say gamble g differentiate pooled categories
g g k n xk yk
means gamble f b n
g f x xn
idea underlying formulaor requirementis sample x xn
corresponds sample x xn b n pooled categories pooling
invariance requires gambles g f differentiate pooled
categories make difference whether make predictive inferences set
original categories set pooled categories b formally terms
predictive lower previsions



fide cooman de bock diniz

p nb f

p na f p nb f p na f

n n n considered gambles f b n
alternatively generally terms predictive sets desirable gambles
n
n
n
n
f db

f da
f db
f da
c
c


n n n considered gambles f b n
pooling invariance seems reasonable principle uphold cases category
set known full detail case useful start limited set broadly
defined categories allow creation ones pooling splitting old categories
observations proceed context recall walleys example
closed bag containing coloured marbles probability drawing red marble
information subject idea colours
marbles bag making difficult construct suitable detailed category set
experiment draws bag predictive inference model used
respects pooling invariance inferences made red marbles uses
category set red yellow blue category
set red non red colours different red pooled together single
category appears pooling invariance typically useful principle instance
sampling species one wants assess prevalence given species
certain area
special case pooling invariance called embedding invariance concentrates case without prior observations terms lower previsions
p na f p nb f n n considered gambles f b n
alternatively generally terms sets desirable gambles
n
n
f da
f db
n n considered gambles f b n

renaming invariance
besides pooling invariance may require renaming invariance long confusion
arise matter subjects predictive inferences names labels
gives different categories
may seem trivial even mention far know implicitly
taken granted predictive inference well devote attention
order distinguish category permutation invariance discussed
shortly easily confused pay proper attention
renaming bijection one one onto map set original categories
set renamed categories c clearly distinguish elements
c sample x xn original categories
corresponds sample renamed categories x xn gamble
walley calls underlying requirement lower probability event depend
possibility space embedded embedding principle walley section



ficoherent predictive inference exchangeability

f set c n renamed samples corresponds gamble f set
original samples clearly require make difference whether
make predictive inferences set original categories set renamed
categories c formally terms predictive lower previsions
p nc f

p na f p nc f p na f

n n n considered gambles f c n
alternatively generally terms predictive sets desirable gambles
n
n
n
n
f dc

f da
f dc
f da
c
c


n n n considered gambles f c n
category permutation invariance
shall especially interested predictive inference subject starts state
prior ignorance state reason distinguish different elements
set categories chosen formalise idea consider permutation
elements sample corresponds permuted sample
x xn gamble f corresponds permuted
gamble f subject reason distinguish categories z
images z make sense require following category permutation invariance
p na f

p na f p na f p na f

n n n considered gambles f
alternatively generally terms predictive sets desirable gambles
n
n
n
n
f da

f da
f da
f da
c
c


n n n considered gambles f
formally requirement closely resembles renaming invariance whereas latter
trivial requirement category permutation invariance symmetry requirement
categories justified subject reason distinguish
may instance justified starts state prior ignorance
draw attention difference two somewhat loose manner category
permutation invariance allows confusion old categories something
renaming invariance carefully avoids
see principle could reasonable recall walleys bag marbles
example introduced discussing pooling invariance since drawn
permutation elements words categories contrasted
permutations order observations e time set n considered discussion
exchangeability section
requirement related notion weak permutation invariance de cooman miranda
studied much detail dealing symmetry uncertainty modelling goes
back walleys section symmetry principle



fide cooman de bock diniz

marbles bag subject idea marbles coloured state
complete prior ignorance therefore starts sample space red non red
observes outcomes draws say twice non red consider probability
obtaining red marble next draw due symmetry originating complete
ignorance permute categories calling red marbles non red
non red ones red situation looking completely
therefore probability obtaining non red marble next draw observing
twice red must observing red one observing non red twice
principle reminiscent axiom proposed carnap system
inductive logic course reasonable principle subject prior
knowledge would instance allow impose ordering
categories
representation insensitivity
shall call representation insensitivity combination pooling renaming category
permutation invariance means predictive inferences remain essentially unchanged
transform set categories words insensitive
choice representationthe category set difficult see representation
insensitivity formally characterised follows consider two category sets
called relabelling map onto e
x x sample corresponds transformed
sample x xn dn gamble f dn corresponds
gamble f
representation insensitivity
category sets onto map n n n
gambles f dn
considered
p nd f

p na f p nd f p na f

ri

alternatively generally terms predictive sets desirable gambles
n
n
n
n
f dd

f da
f dd
f da
c
c

ri

weaker combination pooling renaming category permutation
invariance prior observations
prior representation insensitivity
category sets onto map n n considered
gambles f dn
p na f p nd f
ei
alternatively generally terms sets desirable gambles
n
n
f da
f dd




ei

ficoherent predictive inference exchangeability

specificity
turn another rather peculiar view intuitively appealing potential property predictive inferences assume addition observing sample observations
n observations category set subject comes know determine

way n following observations belong proper subset b nothing
elsewe might suppose instance observation xn xn n made
imperfect allows conclude xn xn n b n
impose following requirement uses conditioned
event b n conditional introduced equations see
discussion leading equation near end section
specificity

category sets b b n n n considered
gambles f b n
b n p nb f
b
p na f b n p nb f p na f

sp

alternatively generally terms predictive sets desirable gambles
n
n
n
n
f db
b
f ib n da
f db
f ib n da
c
c

sp

b tuple observations obtained eliminating tuple
observawhere
b empty tuple observations
tions b expressions
b posterior predictive model simply taken reduce prior predictive

model
specificity means predictive inferences subject makes
ones would get focussing category set b time discarding
previous observations producing values outside b effect retaining observations
inside b knowing future observations belong b allows
subject ignore previous observations happened lie outside b term
specificity context seems proposed bernard
work rouanet lecoutre called specific inference questions
inferences decisions involving restricted number categories general
model replaced specific model deals categories interest
specificity respected general specific produce
inferences specificity seems relevant principle analysing categorical data
described tree structures case instance patients classified
according symptoms bernard
give simple example involving walleys bag marbles subject
may observed drawings green red blue white marbles asked
probability drawing red marble next observer already seen
informs us green redperhaps due bad lighting conditions
shes colour blind subject uses specific inference model disregard
previous observations involving colours green red


fide cooman de bock diniz

prior near ignorance
use notion near ignorance defined walley p give following
definition prior near ignorance context predictive inference see related
discussions walley section walley section walley bernard
section refer piatti zaffalon trojani hutter
interesting discussion prior near ignorance may produce undesirable
certain contexts
prior near ignorance
prior model single variable xk assuming values arbitrary category set
vacuous category set n n considered k n gambles
f
p na extnk f min f
alternatively generally terms sets desirable gambles
n
extnk f da
f

extnk f denotes cylindrical extension f gamble defined
extnk f x xn f xk x xn perhaps intuitive less
formally correct notation gamble f xk
theorem prior representation insensitivity implies prior near ignorance
simple implies model whose predictive previsions precise
prior representation insensitive let alone representation insensitive prior model
immediate predictions vacuous shall see section
nevertheless possible representation insensitive coherent inferences deploy precise
posterior predictive previsions

adding exchangeability picture
remainder going add two additional assumptions
first assumption principle upper bound number
variables take account words considering n variables
x xn envisage looking one variable xn effectively
means dealing countably infinite sequence variables x xn
assume values category set
n coherent
predictive inference means sequence da
sets desirable gambles n n sequence course time consistent
sense requirement meaning
n
n
n
n n n n n da
margn da
da
l

second assumption sequence variables exchangeable means
roughly speaking subject believes order variables observed


ficoherent predictive inference exchangeability

present influence decisions inferences make regarding

section explain succinctly deal assumptions technically
consequences predictive interested detailed
discussion derivation presented refer papers de cooman
et al b de cooman quaeghebeur
begin useful notation employed numerous times
follows consider element ra consider tuple many real
components
x r categories x subset b denote
b xb x sum components b
permutations count vectors hypergeometric distribution
consider arbitrary n n denote x xn generic arbitrary element
p n set permutations index set n permutation
associate permutation denoted defined k x k
words x xn x x n similarly lift permutation
l letting f f f f
permutation invariant atoms p n smallest permutation invariant subsets introduce counting map nan
count vector tuple components
tz k n xk z z
set possible count vectors n observations given


nan na
n





tz number times category z appears sample
atom completely determined single count
vector elements therefore denoted
consider linear expectation operator hyna associated uniform
distribution invariant atom
hyna f



f gambles f






number elements invariant atom given
multinomial coefficient



n
n







za mz
expectation operator equation characterisesor one associated
multivariate hyper geometric distribution johnson kotz balakrishnan section associated random sampling without replacement urn n balls
exchangeability assumed carnaphis axiom johnson named
permutation postulate



fide cooman de bock diniz

types z whose composition characterised count vector borne

fact n n


hyna

otherwise
probability randomly selecting without replacement sequence n balls types
urn n balls whose composition determined count vector see
running example concrete illustration
hyper geometric expectation operator seen linear transformation
hyna linear space l generally much lower dimensional linear space
l nan turning gamble f called count gamble hyna f hyna f
count vectors
running example order make argumentation notions introduce
discuss tangible concrete shall use simple running example
shall come back repeatedly number sections notations assumptions made
maintained throughout series
consider potentially infinite sequence coin flips whose successive outcomes
denote variables x x xn assuming values category set h
make somewhat interesting usual run mill example assume
stepfor coin flipnathalie selects coin bag three coins hands
arthur proceeds flip coin put back bag next
step subject whose beliefs modelling may may know something
nature coins nathalie choosing coins subsequent flips
might choose completely random might specific deterministic
mechanism selecting
h h h first n observed coin flips count
consider sequence
corresponds sequence given components
vector
th h h h tt h h h
letting first component refer h
denote
corresponding permutation invariant atom
h h h h h h h h h h h h h h h




elements set possible count vectors given n h

h h h
consider event ht
two different outcomes first two observations





hy h iht



probability observing two different outcomes two random draws without replacement urn containing three balls marked h one ball marked whose
composition therefore determined count vector



ficoherent predictive inference exchangeability

multinomial distribution
next consider simplex probability mass functions



ra
x



xa

probability mass function corresponds following multinomial
expectation operator mnna
mnna f




f



ztz gambles f



za

characterises multinomial distribution associated n independent trials
experiment possible outcomes probability mass function observe




f
zmz
mnna f

n
za
na



n
mz

hya f
z comnna hyna f
n
na

za

used called count multinomial expectation operator


comnna g
g
zmz gambles g nan
n
na



za

running example consider n independent trials experiment possible outcomes
category set h probability mass function h




mn h iht
h h h h h h h

observe way mnn
gives probability event ht
h
h iht
h n
gamble fht
iht
observation sequences x x corresponds

count gamble ght
hy h fht
given
ght
ght





ght
ght
ght













comn h g h h
h
h
h



leads polynomial



avoid confusion make perhaps non standard distinction multinomial expectation
associated sequences observations count multinomial expectation associated
count vectors
see footnote



fide cooman de bock diniz

multivariate polynomials

let us introduce notation na mn nam set possible count vectors
corresponding samples least one observation equation let n
turns na singleton
containing null count vector whose

components zero mn nam na set possible count vectors
count vector na consider multivariate bernstein basis
polynomial ba degree defined



mz
mz
ba
z
z


za

za

particular course ba
linear combination p bernstein basis polynomials degree n multivariate
polynomial whose degree deg p n denote linear space
polynomials degree n v n course polynomials degree zero simply real
constants gathered relevant useful information multivariate polynomials
appendix b follows discussion n introduce
linear isomorphism comnna linear spaces l nan v n
gamble g
nan corresponds polynomial comnna g comnna g n n g ba

v n conversely polynomial p v n unique gamble bnp nan
p comnna bnp observe particular n nan
comnna ba


denote v nn v n linear space multivariate polynomials
arbitrary degree
set ha v polynomials called bernstein coherent satisfies
following properties
b
ha
b v ha
b posi ha ha
v set bernstein positive polynomials polynomials p
n deg p bnp follows proposition appendix b
v subset set v polynomials p p
interior int x x consequence b b
set v v bernstein negative polynomials
b v ha
degree may smaller n sum bernstein basis polynomials fixed degree
one strictly speaking polynomials p restrictions multivariate polynomials q ra
called representations p p multiple representations possibly different degrees
smallest degree called degree deg p p
strictly speaking equation defines count multinomial expectation operator comnn

n clear definition extends trivially case n



ficoherent predictive inference exchangeability

finally every bernstein coherent set ha polynomials induces lower prevision
h v defined
h p sup r p ha p v



lower prevision coherent mathematical sense satisfies coherence
requirements p p
exchangeability representation theorem
ready deal exchangeability shall give definition coherent sets
desirable gambles generalises de finettis definition allows
significant generalisation representation theorem
first fix n n subject considers variables x xn
exchangeable distinguish gamble f permuted
version f words gamble f f equivalent zero gamble foror
indifferent tohim means called set indifferent gambles


n
f f f l p n
ia
n set must compatible
subject coherent set desirable gambles da
n sense must satisfy rationality
set indifferent gambles ia
n
n
n
requirement da ia da see detailed explanations justifications de cooman
quaeghebeur quaeghebeur et al called desiring sweetened
n
deals requirement say sequence x xn model da
exchangeable
next countably infinite sequence variables x xn called exchangeable
n n n
finite subsequences x xn n n means da
exchangeable course time consistent
formulate powerful generalisation de finettis representation
theorem straightforward compilation proved de cooman
quaeghebeur

theorem representation theorem de cooman quaeghebeur sequence
n desirable gambles n n coherent time consistent exchangeable
sets da
bernstein coherent set ha polynomials
na


n n gambles f
n
n
mnna f ba
f da
mnna f ha f da
c
ha

case representation ha unique given ha





n
n
nn mna da

follows condition ha completely determines predictive inferences
n
sequence variables x xn fixes prior predictive da
actually suitably adapted version underlying possibility space need longer finite
walley troffaes de cooman domain restricted polynomials
de cooman quaeghebeur



fide cooman de bock diniz

n c
tells us representation ha set
posterior predictive da
polynomials plays role probability measure density distribution
function precise probabilistic case
indeed corresponding coherent lower prevision h v given equation
shown determine convex closed compact set

h ha p v ha p h p
coherent previsions ha v walley de cooman et al b de cooman
quaeghebeur troffaes de cooman pointed footnote
come back footnote coherent prevision ha uniquely
determines additive probability measure borel sets therefore set
polynomials ha via h uniquely determines set probability measures
argued ha informative h h
conditioning sets lower probability zero bernstein coherent set polynomials
ha determines unique lower prevision h therefore h unique set
probability measuresand densities absolutely continuouson simplex
converse necessarilyand usually notthe case set probability densities
used define coherent set polynomialswe provide example
section generally one coherent set polynomials
leads set densities updating behaviour different sets
polynomials different conditioning events lower probability zero
n c
depend
condition tells us posterior predictive da
count vector

count vectors sufficient
observed sequence
statistics exchangeability reason shall denote posterior
n c
n c
well da
every shall use
predictive da
n
n
da c alternative notation da
immediate interesting consequence theorem updating observations
preserves exchangeability observing values first n variables count
remaining sequence variables xn xn still exchangeable
vector
condition tells us representation given bernstein coherent set
defined
polynomials ha c
p v ba
ha c
p ha



compare expressions tells us essentially bernstein
basis polynomials serve likelihood functions updating sets polynomials use
refer coherent lower prevision v derived ha c
means
h
ha c ha h h
equation special case
related following version generalised
observe h h
bayes rule

h p h p b

p v

completely determined ha one consider ha prior model
clearly ha c
plays role posterior derived
parameter space ha c
contrasted usual precise probabilistic version posterior predictive
uniquely determined observed sequences non zero probability see footnote



ficoherent predictive inference exchangeability

see condition equation thatsimilarly happens preciseprobabilistic settingthe multinomial distribution serves direct link one
n hand
hand prior ha prior predictive inference da
n c
posterior predictive inference da
recalling
posterior ha c

na
convention summarise follows n n


n
f l mnna f ha c

da
c

immediate consequence


sup r mnna f ha c
f l
p na f



equivalently
h mnna f
f l
p na f



practical point view equation often easier work equa often admit simpler expression
tion shall see h
compare equations equations
ha c
uniquely determined h relaand respectively h
uniquely h prior lower probability
tion allows us determine h

h ba


observing

non zero
therefore
sets polynomials ha


uniquely quite dramatic
fundamental allow us determine ha c
illustration shall sections come across number
quite different inference systemswith different ha give rise prior h

different posterior h
running example assume subject assesses sequence coin flips
exchangeable finds desirable gamble type h xn fixed
upper probability observing heads coin flip since
infer equation n n mnn
h h xn h infer
theorem assessment corresponds following coherent set polynomials


h p h p v h r max
smallest bernstein coherent set polynomials contains polynomial
h explanation see discussions de cooman et al b
de cooman quaeghebeur followsafter manipulationsfrom
equation proposition corresponding lower prevision v h
completely determined following optimisation
h p sup

min p h

h

given
hence lower probability event ht
h h sup min x x x
x

upper probability
h h h h inf max x x x
x



fide cooman de bock diniz









otherwise


tells us exchangeability alone already guarantees upper probability ht

three coins bag assumed biased towards heads
upper probability drops

finish section representation want stress polynomials
given behavioural interpretation gambles may may desirable
merely mathematical representational tools help us characterise
gambles observation sequences desirable similarly set polynomials ha
lower prevision h merely mathematical tools allow convenient
representation predictive observation sequences
running example illustrate polynomial representation much convenient
efficient recall want make inferences sequence coin flips
length n need work sets desirable gambles h n words
cones n dimensional space work polynomial representations
led consider cones polynomials degree n constitute linear
space spanned n bernstein basis polynomials degree n therefore
n dimensional working polynomial representations therefore leads
dramaticexponentialreduction complexity


reasoning inference systems
seen previous section fix category set predictive inferences
exchangeable sequences assuming values completely determined bernstein
coherent set ha polynomials way associating bernstein
coherent set ha every possible set categories would completely fix predictive
inferences leads us following definition
definition inference systems denote f collection category sets e finite
non empty sets inference system map maps category set f
set polynomials ha inference system called coherent
category sets f bernstein coherent set polynomials
coherent inference system way systematically associate coherent predictive
inferences category set since inference principles section impose connections
predictive inferences different category sets see interpret
inference principlesor rather represent mathematicallyas properties
restrictions coherent inference systems shall section
provides one important motivation introducing systems another equally
makes operational behavioural sense consider notion accepting polynomial finding
desirable much classical case de finetti probability distributions
simplex used mathematical representations direct behavioural
meaningalthough bayesians less careful foundations de finetti might care make
distinction



ficoherent predictive inference exchangeability

important reason allows us extend method natural extension
conservative inferenceintroduced section take account inference
principles predictive inference generally predictive inference multiple category
sets
see comes let us conservative reasoning
inference systems two inference systems say less committal
conservativethan write v
f
simply means predictive inferences category set less committal
first second inference system denote set inference
systems clearly set partially ordered v actually complete lattice
infimum supremum non empty family given







inf
sup
category sets
ii

ii

ii

ii

denote c set coherent inference systems
c f bernstein coherent



clear c complete meet semilattice meaning closed arbitrary
non empty infima
c inf c

ii

bottom structurethe conservative coherent inference systemis called
vacuous inference system v coherent inference system given
v v category sets
shall come back detail vacuous inference system section
property allows us conservative reasoning coherent inference systems
suppose instance collection category sets f f assessments
form set polynomials aa v f exists
conservative coherent inference system compatible assessments given

inf c f aa
course exist set polynomials aa included
bernstein coherent set polynomials ha f case difficult
see given discussion section posi v aa f
v f f
necessarily closed suprema however union bernstein coherent sets polynomials
need bernstein coherent



fide cooman de bock diniz

representation insensitivity specificity exchangeability
let us investigate form inference principles representation insensitivity ri
specificity sp take predictive inference exchangeability inference
completely characterised bernstein coherent sets polynomials allow us
reformulate principles constraints onor properties ofinference systems
representation insensitivity
recall notations assumptions section surjective onto map
associate surjective map r ra rd letting
r z



x

ra z



xa x z

map allows us give following elegant characterisation representation insensitivity
theorem coherent inference system representation insensitive
category sets onto map p v
na
p r ba pbd r
ri
running example assume coins bag actually rather thick implying
non negligible chance fall one flat sides
remain upright denote state u category set
h u consider flat state f meaning heads tails
consider instead category set f u distinguish
heads tails relabelling map h f u u
identifies proper relations categories
suppose want say something lower probability event
observing u one flip h immediately observing
uf
sequence h u h count vector last count three
refers number u observation sequence domain gamble iuf

n

expressed polynomial q mn h u iuf
n given
q h u h u
belong
want whether polynomials type h u h
u
h u see equation
hand seen previously domain gamble iuf

expressed polynomial p given p f u f u observe
q p r count vector domain corresponds count vector
r domain first component refers number f
second number u need check whether polynomials type
f u f u belong f u

similar contexts easy check polynomial remains n



ficoherent predictive inference exchangeability

nice thing representation insensitivity makes checking whether

polynomials type h u h
u belong h u adomain equivalent checking whether polynomials type f u f u belong
f u domain

interestingly representation insensitivity preserved taking arbitrary nonempty infima coherent inference systems allows us look conservative
representation insensitive coherent inference system compatible assessment
f way straightforward extension discussion near end section
theorem consider non empty family representation insensitive coherent
inference systems infimum inf ii representation insensitive coherent
inference system well
specificity
next turn specificity recall notations assumptions section let us
define surjective restriction map rb ra rb
rb z z ra z b



particular rb count vector b obtained restricting b indices
components count vector define one one injection map
ia rb ra

x x b
ia x
rb x


otherwise
map used define following one one maps irb v b v
r n follows

irb p
bdeg p r
ba ia polynomials p v b

p
deg p r

nb

derive meaning following observation polynomial p b
equivalently represented bernstein basis b degree deg p r
interpret different representations polynomials longer equivalent
lead different polynomials irb p r n following propositions clarify
exactly effect operator irb
proposition polynomial p b r n irb p ia p
introduce following notation b
b rb b
observe


whenever



b
b
b
proposition consider polynomial p b r n
deg p r p c r irb p c otherwise deg p r

deg p r
b
p
b
b
irb p

otherwise


fide cooman de bock diniz

maps irb allow us give following elegant characterisation specificity
theorem coherent inference system specific category sets
b b p v b na r n
irb p ba pbb rb b

sp

running example suppose made observation h u h
count vector interested posterior lower probability
somebody told us neither two subsequent coin flipsafter
event ht
first fourresulted u specific inference system allowed consider
predictive inference reduced category space b h rather
category space h u b space use reduced count
vector rb obtained leaving number observed u polynomials
lead consider therefore type h h want
know whether belong f u
space polynomial p h whose degree deg p
transformed polynomials



h
r
ib p
h r h h h r
h h
r n follows argumentation proof theorem original
requires us check whether polynomials type

h h h r h
u

h u specificity allows us look b space
easier

observe close formal similarity conditions ri sp
therefore surprise us specificity preserved taking arbitrary non empty
infima inference systems
theorem consider non empty family specific coherent inference systems
infimum inf ii specific coherent inference system well
let us denote crs set coherent inference systems representation
insensitive specific follows theorems crs c closed
arbitrary non empty infima perform conservative reasoning much
way discussed near end section

immediate prediction
inference system look special case immediate prediction
given category set observing sample n variables count vector
nan want express beliefs value next observation xn

assume specific case predictive inference n condition
nan
simplified somewhat gambles f


ba
f da
sa f f da
c
sa f



ficoherent predictive inference exchangeability

let
called sampling expectation sa f linear polynomial given
sa f xa f x x
reason na x x x count vector corresponding
single observation category x words exz xz z kronecker
delta hence x




x
x
f
z

f
x

b


zez x
hy f x

x
x

x
za

z

leading
mn f



hy f x ba x


x na



f x x sa f



xa

matter straightforward verification due bernstein coherence ha
c
coherent set desirable gambles
called immediate prediction model da
na induces following predictive lower previsions
every count vector



sup r f da

p f
c
sup r sa f ba




immediate prediction context exchangeable imprecise probability
studied detail de cooman et al lower previsions rather
sets desirable gambles model choice
authors encountered conditioning sets lower probability zero fact
provided motivation dealing much general
necessarily immediate predictive inference sets desirable gambles
present section want illustrate many proved
made stronger easier proofs borne appendix e
present context
requirement ri representation insensitivity reduces following simpler
requirement immediate prediction category sets
onto map gambles f na


f da
c f dd
cr

ri

similarly requirement sp specificity reduces following simpler requirement
immediate prediction category sets b b
gambles f b na


f ib da
c f db
crb

sp

let us simple characterisation immediate prediction
satisfy representation insensitivity get observe consider
gamble g category set surjective pooling map finite subset
g ralso category set corresponding rg ra rg given

rg r
x r g
xa g x r



fide cooman de bock diniz

simple idea allows intriguing reformulation representation insensitivity
requirement immediate prediction
proposition immediate prediction associated coherent inference
system representation insensitive category sets gambles g
count vectors na


g da
c idg dg
crg

ri

non empty set b denote idb identity map b defined idb z z
z b
proposition tells us whether gamble desirable depends values
assumesand assumedand number times
values observed pastor rather would observing
g xk rather xk
let us focus happens events consider event b nontrivial meaning b neither empty equal real gamble
ib assumes two values see applying proposition
na


ib da
c id
c mb b

therefore



p b sup r ib da
c



sup r id
c mb b mb




meaning representation insensitivity predictive lower probability non trivial
event b depends number times mb observed past
experiments total number observations thing holds predictive
upper probability mb precise predictive probabilities similar property
known johnsons sufficientness postulate johnson zabell
representation insensitive coherent inference system
see define


called lower probability function n k n k n equation
completely characterises one step ahead predictive lower upper probabilities
non trivial events count vectors shall use representation insensitivity
specificity requirements try say lower probability function
following theorem strengthens simplifies extends similar de cooman et al

theorem consider representation insensitive coherent inference system
associated lower probability function following properties
l bounded n k n k n k n
l super additive second argument n k n k n
n k n k n
necessarily predictive lower upper previsions



ficoherent predictive inference exchangeability

l n n n
l n k k n n n n k n k n
l non decreasing second argument n k n n k n
k n
l n k n k n k n k n k n k n
k n
l non increasing first argument n k n k n k n
k n
l suppose n n n let sn

sn sn sn
n n
n


n

n equivalently

moreover specific following properties
n
l consider real suppose n n n


n n consequence consider suppose
n
n n n
n n

know theorem representation insensitive coherent inference systems
near ignorant meaning vacuous therefore completely indecisive
single observation prior observations made borne
theorem l let us define imprecision function
n k n n k n k n k n k n





clear p b p b mb width probability interval
event b observed mb times representation
insensitive coherent inference system whose imprecision function n k satisfies following
property

n k n k
k n

n k n k
imprecision increase total number observations increases suggests
representation insensitive coherent inference systems display
desirable behaviour mentioned introduction conservative little
learned never become less precise observations come following
sections intendamongst thingsto take closer look whether behaviour
present number systems
immediate prediction important predictive inference precise probabilities
law total probability guarantees completely determined immediate
predictions perhaps surprisingly case predictive inference imprecise
probabilities appendix provides counterexample points
limitations scope earlier work de cooman et al reason
leave immediate prediction rest concentrate
general notion inference system


fide cooman de bock diniz

vacuous inference system
following sections provide explicit interesting examples representation insensitive specific coherent inference systems begin simplest
one vacuous inference system v introduced section smallest
conservative coherent inference system associates category set
smallest bernstein coherent set v hv v containing bernstein positive
polynomialsthe ones guaranteed anyway bernstein coherence alone
deduce proposition appendix b
hv v
na
hv c
proposition appendix b


h v p sup r p v
h v p
min p min p p v


predictive inference system straightforward
na
follow directly equations n n
deduce


n
n
f l mnna f v
dv
dv
c


min mnna f f l
p nv f p nv f




particular


l
dv
dv
c

p v f




p v f



min f f l




v n k n k n k n



conservative exchangeable predictive arise
making assessments exchangeability alone gather equations
interesting involve non trivial commitments
allow learning observations borne corresponding
imprecision function given
v n k n k n k n
running example seen mnn h iht
h n
therefore
n
p nv h iht
p v h iht


min

mnn h iht


max

mnn h iht


h

min

h

h


n

n

p v h iht
p v h iht


h




h
h

max

ficoherent predictive inference exchangeability

shows vacuous inference model produce completely vacuous inferences
allows us consequences making assessments exchangeability
allow us change lower upper probabilities previsions
observations come

even though makes non trivial inferences vacuous inference system satisfies
representation insensitivity specific
theorem vacuous inference system v coherent representation insensitive
let us means counterexample v specific
running example let us go back inferences category space h u
reduced category space b h consider polynomial p h h
h polynomial bernstein positiveso p v h
p h h h h
expansion bernstein basis degree positive let us consider
corresponding polynomial h u


q b p h
h




polynomial bernstein positive easy see every n n


q h
h
h u n
n q p
term h u
v h u infer
b
theorem v cannot specific


following sections shall prove infinity committal
specific representation insensitive coherent inference systems begin introducing
slightly modified version vacuous inference system coherent representation
insensitive specific

nearly vacuous inference system
let us introduce nearly vacuous inference system nv reason name
become clear presentlyby
nv hnv v p v int p
category sets
since v consists polynomials positive int deduce
na hnv c
hnv v
proposition appendix b

h nv p
h nv p

p min p p v

inf
int





fide cooman de bock diniz

since know proposition appendix b counterexample following
generally speaking v v see inference system less conservative
vacuous one case vacuous inference system predictive
nearly vacuous inference system straightforward follow directly
na deduce
equations n n


n
n
f l mnna f v
dnv
dnv
c

min mnna f f l
p nnv f p nnv f


particular


l
dnv
dnv
c

min f f l
p nv f p nv f
see immediate prediction predictive lower previsions
inference system exactly ones vacuous inference systems
allow learning observations
interestingly contrast vacuous inference system nearly vacuous
inference system specific already tells us crs
theorem nearly vacuous inference system nv coherent representation insensitive specific nv crs

skeptically cautious inference system
construct rather simple inference system quite intuitive slightly
informative vacuous nearly vacuous ones suppose subject uses
following system making inferences sequence n observations count
category set skeptical believes future
vector
observe categories seen previously categories set
x mx




cautious beliefs already observed categories
observed future nearly vacuous explain assume first
particular n future observations vacuous beliefs count vector
observe set


n
n


na na


holds possible observing count vector

future count vectors
lemma appendix b
namely count vectors observation outside
first example shows immediate prediction completely determine
inference system shall come across another example appendix
last equality equation actually device allows us identify count vectors
zero count vectors
shall repeatedly
whose components outside
without explicit mention rest



ficoherent predictive inference exchangeability

would lead us associate following set polynomials count vector na



n
v
p v n deg p bnp na




p v p v
already know vacuous v lead specific systems
whereas nearly vacuous v modify slightly rather
associate following set polynomials count vector na



v
p v p v

polynomials v
desirable representation observing sample
count vector infer equation subject considers desirable
representation polynomials




v
ba pba p v


thus led consider following assessment


asc
v
ba
na

set positive linear combinations
hsc

posi asc




pk ba k n nk n k

nank pk






v

k



k

following proposition guarantees sets hsc appropriate conservative
summarise exchangeable inferences skeptically cautious subject
proposition hsc smallest bernstein coherent set polynomials
includes asc
shows inference system sc defined sc hsc category
sets coherent shall call skeptically cautious inference system
want updating works system end introduce
slight generalisation set defined equation consider na let
hsc




pk ba k n nk n nk k

nank pk






v

k



k


see particular hsc hsc
sets hsc following interesting characterisation
stated polynomials direct behavioural indirect representational meaning
conveniently condensed representations desirable gambles observation sequences hence
caution term desirable representation



fide cooman de bock diniz

proposition na


hsc p v k min sa p p k v k






sa p
k k p k



min sa p mean set minimal non dominating elements sa p
min sa p c sa p k sa p k c k c formally extend

equation include case sa p
k p k
proposition na hsc c hsc
combining equation deriveadmittedly rather involved
expressions predictive sets desirable gambles skeptically cautious inference
na
system n n


n
f l mnna f hsc
c

dsc

na
immediate prediction expressions simplify significantly




f l f
dsc
l dsc
c
l



na
lower previsions derived hsc
tractable

h sc p min p x h sc p
xa

min p p v






x x degenerate probability mass function assigns
probability mass x
predictive lower previsions skeptically cautious inference system
na
easily obtained combining equations n n

p nsc f

min mnna f f l







p nsc f min f x x x f l



min f x f l
p sc f min f p sc f



xa

particular

xa

lower probability function given

k n
sc n k
otherwise

n k n k n

corresponding imprecision function

n k n
sc n k
otherwise


n k n k n

ficoherent predictive inference exchangeability

running example mnn h iht
h n take
account h h get
n
p nsc h iht
p sc h iht


min

mnn h iht


h

max

mnn h iht


h

h

min

h

max


h



n

n

p sc h iht
p sc h iht


h

categories observed count vector meaning h
h inferences vacuous inference system

interestingly coherent inference system sc satisfies representation insensitivity specificity
theorem skeptically cautious inference system sc coherent representation
insensitive specific sc crs

idmm inference systems
imprecise dirichlet modelsor idms shortare family parametric inference
introduced walley conveniently chosen sets dirichlet densities dia
constant prior weight


dia ksa ksa ra

int
value called hyperparameter r category set dirichlet
densities dia defined int see appendix c explicit definition
extensive discussion
idms generalise imprecise beta introduced earlier walley
later walley bernard focussed closely related family predictive
inference called imprecise dirichlet multinomial modelsor idmms
short refer papers recent overview bernard
extensive motivating discussion idm inferences properties
precise dirichlet expectations related dirichlet multinomial
gathered appendix c important facts properties
necessary proper understanding present discussion idm context
inference systems
one reasons walley suggesting idm reasonable model
precisely satisfies pooling invariance properties discussed section
discussed emphasis walley bernard bernard
know detailed explicit formulations properties literature
proofs seen fairly sketchy bernard suggests idm
later walley bernard clearly distinguish name parametric idms
predictive idmms earlier walley types referred
idms
walley uses term representation invariance rather pooling invariance



fide cooman de bock diniz

underlying precise dirichlet satisfy called specificity property
tried translate present context predictive inference section
present section use ideas behind walley bernards idm construct
interesting family coherent inference systems give detailed formal proof
appendix e fact inference systems indeed representation insensitive
specific interestingly shall need slightly modified version walleys idm
make things work reason walleys original version described
expression number less desirable properties seem
unknown ignored walley bernard describe shortcomings
detail appendix present purposes suffices mention contrary
often claimed contradistinction version inferences original
version idm necessarily become conservative less committal
hyperparameter increases
version rather hyperparameter sets ksa consider sets


sa ra
r
observe


sa r int





ksa



r category set consider following set polynomials
p positive dirichlet expectation dia p hyperparameters sa

p v sa dia p
hidm

shall see theorem set bernstein coherent call inference
system sidm defined

sidm hidm
category sets

idmm inference system hyperparameter corresponding updated
na given


p v sa dia p

hidm
c



inf dia p
p v
h sidm p






expressions predictive idmm inference system straightforward suffices apply equations n n
na



n
f l sa dia mnna f

didm
c


inf dia mnna f
f l
p n
idm f






ficoherent predictive inference exchangeability

notations introduced appendix c
dimnna hyna f

dia mnna f


n

n


hya f
mx x mx
n


n
xa

n





general expressions seem forbidding immediate prediction
na
manageable enough




f l f

didm c
f x mx

xa




p
f



f x mx
min f f l

idm


xa



k
n k n k n
n
corresponding imprecision function given
sidm n k

sidm n k


n k n k n
n

decreasing first constant second argument implies
satisfies condition suggests idmm inference systems conservative
little learned become precise observations come
running example mnn h iht
h n
appendix c



di h mnn h iht


h

h h

difficult verify equation
n

p n
p idm h iht

idm h iht





observing count vector manipulations







p n
inf
idm h iht
similarly








n
p idm h iht











observe infinitely large recover inferences vacuous system




fide cooman de bock diniz

interestingly immediate prediction version idmm inference
system coincide walleys original version hence many practical applications concerned immediate prediction approaches yield identical

idmm inference systems constitute uncountably infinite family coherent
inference systems satisfies representation insensitivity specificity
requirements
theorem r idmm inference system sidm coherent representation
insensitive specific sidm crs

since crs closed non empty infima infimum
idm idm
still coherent representation insensitive specific conservative
idmm inference systems given




p v ra
idm v
dia p

although set generally strictly includes sets v v associated
immediate prediction predictive lower previsions shown coincide
ones vacuous nearly vacuous inference systems

skeptical idmm inference systems
combine ideas previous two sections suppose subject uses
following system making inferences sequence n observations
category set section skeptical
count vector
believes future observe categories seen previously
rather cautious completely vacuous
categories set
beliefs already observed categories observed future
uses idmm inference described section
turns done quite simply replacing characterisation
sets hsc skeptically cautious inference system nearly vacuous

v k appropriate idmm hidm k
crk define category
set na r following set polynomials




p v k min sa p p k hidm k
hsi
crk

recall k min sa p k therefore k rk
k rk essentially count vectors let


hsi
hsi
words




p v k min sa p p k hidm k
hsi



sa p
k p k remainder section

sets polynomials hsi
indeed lead definition reasonable potentially
useful type inference system begin coherence

proposition hsi
bernstein coherent set polynomials



ficoherent predictive inference exchangeability


shows inference system ssi given ssi hsi
category sets

coherent call si skeptical idmm inference system hyperparameter
want updating works inference system following
proposition really come surprise


proposition na hsi
c hsi


combining equation obtain followingagain rather involved
predictive sets desirable gambles skeptical idmm inference systems n n
na



n

f l mnna f hsi
dsi
c




rather abstract case
although expressions hsi
c
na
corresponding lower previsions

h ssi p min p x p v
xa





h ssi p

inf

sa



dia
ra
p



p v
h sidm
ra

p





combining equation immediately obtain following predictive lower
na
previsions skeptical idmm inference systems n n
n
p n
si f min f x x x f l
xa



p n
si f

inf

sa


n

dia
mna

f
n ra

f l
p n

n ra
f
idm



immediate prediction skeptical idmm inference systems surprisingly
manageable

dsi
l p
si f min f f l

na





f l f
dsi c
f x mx l






xa






f
f x mx
min f x f l
p si

xa


xa





fide cooman de bock diniz

lower probability function given

k
k n n

si n k n

k n
corresponding imprecision function


n k n

si n k n

otherwise

n k n k n

n k n k n

consider case n see ssi n n ssi n n
imprecision function satisfy condition


n



running example h h infer equation
idmm inference systems
inferences event ht

coherent inference systems ssi satisfy representation insensitivity
specificity
theorem r corresponding skeptical idmm inference system
coherent representation insensitive specific ssi crs

since crs closed non empty infima infimum
si si still
coherent representation insensitive specific conservative
skeptical idmm inference systems shown associated immediate prediction
predictive lower previsions coincide ones skeptically cautious
inference system

haldane inference system
already know discussion near ignorance following theorem representation insensitive coherent inference system fully precise immediate prediction
observations made must completely vacuous ask
whether representation insensitive specific inference systems whose
posterior predictive lower previsions become precise linear previsions
address section shall first construct inference system
system definite sense unique linear posterior predictive previsions
use family idmm inference systems sidm r define inference
system h committal



hidm

sidm category sets
h hh
sr

sr

call h haldane inference system reasons become clear
section
theorem haldane inference system h coherent representation insensitive
specific h crs


ficoherent predictive inference exchangeability

due representation insensitivity haldane system satisfies prior near ignorance
implies making observation immediate prediction model vacuous
far away precise probability model possible
making even single observation inferences become precise probabilistic
coincide inferences generated haldane improper prior
get first take look involving sets desirable gambles
na



p v r sa dia p


hh c
hidm
c
sr

corresponding predictive easily derived applying equation
na
n n


n
f l r sa dia mnna f

dh
c

n


didm
c

sr

immediate prediction obtained combining equations
na






f l
dh l dh c
f x mx l
xa

turns expressions corresponding lower previsions much
na
manageable first
lim h sidm p
p v
inf dia p

lim
h h p

sa





simplifies
particular
h h p min p x p v
xa



na linear previsions
whereas
h h p
hh p
dia p
p v
h h p



corresponding predictive easily derived applying equation
na
n n
lim
p nh f

lim p n
f l
inf dia mnna f
idm f

sa





particular
p nh f min f x x x f l
xa

dirichlet expectations dia strictly speaking defined ra
argue
appendix c continuously extended components zero others strictly
positive



fide cooman de bock diniz

na


p nh f



n

p h f



n

ph
f




n
na


nx
n
xa mx

n



hyna f





na
immediate prediction

mx


p h f min f ph
f
f x
f l

xa

lower probability function given

k
n
h n k n
n k n k n

n
corresponding imprecision function given

n
h n k
n k n k n
n
satisfies condition suggests haldane inference system displays
albeit extreme interesting mannerthe desirable behaviour mentioned
introduction conservative little learned never become less
precise observations come
running example use equation previously obtained
idmm inference systems
n

n
p nh h iht
ph h iht

p h h iht





want point first equalities contradict prior near ignorance
haldane inference system pertains immediate predictions predictions
single future observations

precise posterior predictive previsions equation exactly ones
would found formally apply bayess rule multinomial likelihood
haldanes improper prior haldane
jeffreys jaynes whose density
function int proportional xa x course use haldanes name
inference system produces argumentation shows nothing
wrong posterior predictive previsions coherent inferences
fact analysis shows infinity precise proper priors simplex
together multinomial likelihood coherent posterior predictive
previsions every coherent prevision v dominates coherent lower prevision
h h v binomial parametric inferences haldane prior walley
section comes related conclusion completely different manner
immediate consequence f riesz representation theorem coherent prevision
restriction polynomials expectation operator unique additive probability measure
borel sets see instance discussion de cooman miranda
footnote



ficoherent predictive inference exchangeability

simple argument haldane posterior predictive previsions
precise ones compatible representation insensitivity indeed
shown representation insensitive coherent inference system precise
posterior predictive previsions lower probability function must satisfy n k k n
n k n straightforward prove bayess theorem go
immediate prediction general predictive inference posterior predictive
previsions must haldanes

characterisation idmm immediate predictions
lower probability function n k representation insensitive coherent inference
system gives lower probability observing non trivial event observed k
times n trials
suppose subject specifies single lower probability namely value
probability observing something observed
single trial ask conservative consequences
assessment take representation insensitivity specificity granted
words conservative representation insensitive specific coherent inference
system least given value lower probability function
question makes sense representation insensitive specific coherent inference
systems constitute complete meet semilattice statement theorems
clearly smallest representation insensitive specific coherent
inference system know discussion sections must
immediate prediction predictive lower previsions nearly vacuous
inference system consider case words use
parametrisation turn convenient purposes




positive real number






let us denote conservative inference system lower probability

function assumption
follows theorem l
n

n n n n n since idmm inference system sidm equation
n
tells us sidm n n n
since assumption sidm n n n n conclude

n
n n sidm n n
n n

n
surmised bernard de cooman et al idmm inference
system hyperparameter could smallest conservative representation

insensitive specific coherent inference system given value

fact trying prove made us start present
conjecture turns false apart lower bound n n
suffices exploit additivity precise probabilities symmetry implied representation
insensitivity explicit proof see de cooman et al thm
see discussion near end section
surmise prove conservative representation insensitive specific
coherent inference system corresponding might skeptically cautious one



fide cooman de bock diniz

representation insensitivity specificity impose lower bounds n k k n
see consider inference system smc inf sc sidm statement
theorems coherent representation insensitive specific smc crs
lower probability function smc satisfies

n
n
min n
n
k n
smc n k min sc n k sidm n k
k
min n
otherwise
substantiating claim made see figure depicted lower
upper probability functions haldane system h idmm system sidm smc
n

inference system inf
si idm latter three share value n n n
n conjecture smc could smallest conservative representation

insensitive specific coherent inference system given value
offer
proof
n k

n
n


n










n

n

k

figure lower upper probability functions h haldane system dark grey

sidm idmm system hyperparameter blue min
si idm
orange smc min sc sidm red specific plot made
n
means want characterise idmm inference systems way
conservative ones need add besides coherence representation insensitivity
specificity another requirement preserved taking infima one possible
candidate shall prove job inspired figure
following requirement
let us define subjects surprise event supremum rate betting
opposite event words lower probability opposite event surprise
highclose onewhen subject believes strongly event occur
lowclose zerowhen subject strong beliefs occur


ficoherent predictive inference exchangeability

allows us associate called surprise function n k n n k
lower probability function n k subjects surprise observing non trivial
event observed k n times
follows theorem l representation insensitive system surprise
function non increasing second argument
n k n k n k n n k n n k k n
fairly intuitive property often event observed
smaller surprise seeing
shall say representation insensitive system concave surprise
n k n k n k k n
course n k n n k n n k n n k
difficult see concave surprise preserved taking non empty infima
inference systems makes sense go looking smallest conservative
coherent representation insensitive specific coherent inference system concave
surprise satisfies additional local assessments
looking figure makes us suspect idmm inference system sidm might
system offer proof conjecture however provide proof
following related probably weaker statement focusses immediate
prediction
theorem immediate prediction p na smallest
conservative coherent representation insensitive specific coherent inference system
concave surprise satisfies coincide ones idmm inference
system sidm hyperparameter

conclusion
believe first tries deal systematic fashion principles
predictive inference exchangeability imprecise probability two salient
features consistently use coherent sets desirable gambles
uncertainty choice ii notion inference system allows us
derive conservative predictive inference method combining local predictive probability
assessments general inference principles
first feature allows us contradistinction approaches
probability theory avoid determining unique conditional
unconditional ones conditioning events lower probability zero set
n c

polynomials ha completely determines prior posterior predictive da
n
n
even lower prior probability p
h ba
p
observing
zero lower previsions probabilities would make
count vector
much complicated involved impossible interestingly provide
perfect illustration fact sections three
something similarly dramatic happens sections inference systems
immediate prediction predictive lower previsions one specific




fide cooman de bock diniz

inference systems described therethe skeptically cautious skeptical idmm
haldane systemshave given category set three different sets polynomials
ha nevertheless gather equations
lower prevision h therefore prior predictive p na count vector
na prior lower probability


h ba
p na
min ba
x
xa


zero lower probability makes sure posterior lower previsions h
uniquely determined prior lower prevision
posterior predictive p na
h infer equations indeed different
three types inference systems fail see could come withlet alone
proved necessary forthese three systems relying lower prevision credal
set theory
canand musttake line argumentation even theorem
inference system satisfies prior representation insensitivity near vacuous prior
predictive therefore time consistency coherence monotonicity see
n

prior predictive lower previsions must satisfy h ba
p
na well simply means impossible prior representation insensitive

coherent inference system lower prevision h uniquely determine conditional
therefore systematic way dealing inference
lower previsions h
systems must able resolveor deal withthis non unicity way believe
involving coherent sets desirable gambles one mathematically
elegant ways
second feature allowed us example characterise idmm immediate
predictions conservative ones satisfying number inference principles
follow canat least principlealso used types inference
systems inference principles key requirement inference principle
make amenable formulated property inference
system preserved taking arbitrary non empty infima three inference
principles considering aboverepresentation insensitivity specificity
concave surprisehave property nothing prevents analysis
extended inference principle
complications see point technical mathematical nature reader
doubt noticed proofs later sections quite involved
technical rely quite heavily properties polynomials simplex feel
present made headway mathematical territory instance
discussion bernstein positivity polynomials near proposition
appendix b conclusions de cooman quaeghebeur
characterisation bernstein positivity mentioned open interesting
practical applications inferencenatural extensionunder exchangeability
much remains open exploration determined study mathematical
structure properties polynomials would certainly help alleviating technical
difficulties working inference principles inference systems
opened feel interesting line
foundations predictive inference nevertheless provided answers


ficoherent predictive inference exchangeability

number ofif allopen formulated conclusions earlier
de cooman et al tried deal representation insensitivity immediate
prediction first example asked whether representation insensitive
coherent inference systems whose lower probability functions additive second
argument suffices look figure see answer clearly yes another
question representation insensitive coherent inference systems
mixing predictive systems follows equation answer yes
skeptical idmm inference systems provides example finally use infimum
smc skeptically cautious inference system sc idmm inference system sidm
mentioned briefly section answer two questions representation
insensitive coherent inference systems inequality theorem l strict
representation insensitive coherent inference systems whose behaviour
gambles completely determined lower probability function inference
system smc provides positive answer questions
inference systems mentioned apart idmm haldane
systems appear first time may appear contrived perhaps
even artificial found useful constructing counter examples
shaping intuition building figure argumentation clearly
indicate might wonder whether representation insensitive
specific coherent inference systems cannot produced appropriately chosen infima
examples introduced suggest candidates consideration
inference systems derived walleys bounded derivative model
inference systems constructed sets infinitely divisible distributions
recently proposed mangili benavoli framework provided well
simple characterisation theorems quite useful addressing
similar
end want draw attention simple direct quite appealing
consequence argumentation section infinity precise proper
priors together multinomial likelihood coherent haldane posterior
predictive previsions need improper priors justify posteriors
proper priors job perfectly well precise probabilistic conclusion
follows easily looking general powerful language
imprecise probabilities moreover seen properties representation
insensitivity cannot satisfied precise probabilistic finally entire framework
conservative predictive inference inference principles would impossible develop
within limitative context precise probabilities shows distinct
advantages imprecise probability dealing predictive inference

acknowledgements
gert de coomans partially funded project number g
foundation flanders fwo jasper de bock phd fellow
loosely speaking cannot written specific kind convex mixture haldane inference
system idmm inference system see de cooman et al section
information



fide cooman de bock diniz

foundation flanders wishes acknowledge financial support marcio diniz
supported fapesp paulo foundation project
wishes thank systems group ghent university hospitality
support sabbatical visit authors would thank three anonymous
reviewers many insightful comments suggestions aimed making
easier read cleaning misunderstandings special thank great
arthur van camp enthusiasm everything particular helping us check
little examples

appendix notation
appendix provide list commonly used important notation
defined first introduced
notation

meaning

introduced

b c
ib
x xn
n
n
posi
l
l
l




n
da

category sets events
indicator event b
variable variable time n
number already observed variables
number observed variables
cone generated
set gambles
set positive gambles
set non positive gambles
observed sample
observed count vector
prior predictive set desirable gambles
category set n future observations
posterior predictive set desirable gambles
prior predictive lower prevision
posterior predictive lower prevision
pooling map relabelling map
renaming bijection
category permutation
sample observations outside b eliminated
counting map
set count vectors n observations
set count vectors zero
hypergeometric expectation operator
multinomial coefficient count vector
multinomial expectation operator
simplex probability mass functions
sum components x x b
bernstein basis polynomial
set polynomials degree n

section
section
section
section
section
equation
section
section
section
section
section
section

n c
n c
da

da
n
p
p na

p na



b


nan
na na
hyna

mnna

b
ba
v n



section
section
section
sections
section
sections
section
equation
equation
section
equation
equation
equation
equation
equation
equation
section

ficoherent predictive inference exchangeability

v
v
v
ha

ha c
ha

h
f

c
crs
r
rb
ia
irb
sa



subscript
subscript
subscript
subscript
subscript
subscript
subscript



v


v
nv
sc
idm
si
h
oi

dia
dia
dimnna
bnp

set polynomials
set bernstein positive polynomials
set polynomials
positive int
representing set polynomials
updated representing set polynomials
lower prevision induced ha

lower prevision induced ha c
set category sets
inference system
set coherent inference systems
set coherent inference systems
representation insensitive specific
extended relabelling map
restriction map
injection map
extended injection map
sampling expectation
lower probability function
imprecision function
surprise function
related vacuous inference system
related nearly vacuous inference system
related skeptically cautious inference system
related idmm inference systems
related skeptical idmm inference systems
related haldane inference system
related original idmm inference systems
categories already observed
set polynomials
positive int
dirichlet density
dirichlet expectation operator
dirichlet multinomial expectation operator
expansion polynomial p
bernstein basis degree n

section
section
section
theorem
equation
equation
equation
definition
definition
equation
theorem
equation
equation
equation
equation
section
equation
equation
section
section
section
section
section
section
section
appendix
equation
section
appendix
appendix
appendix
appendix

c
c
c
b

appendix b multivariate bernstein basis polynomials
n nan corresponds
bernstein basis polynomial
multivariate

x

degree n given ba
xa x polynomials
number interesting properties see instance prautzsch boehm paluszny
chapters list
bb set ba
nan bernstein basis polynomials fixed degree n linearly
independent n n ba nan




fide cooman de bock diniz

nan bernstein basis polynomials fixed degree n forms
bb set ba
partition unity n n ba


bb bernstein basis polynomials non negative strictly positive interior
int
bb set ba nan bernstein basis polynomials fixed degree n forms
basis linear space polynomials whose degree n
property bb follows bb bb follows bb
bb polynomial p unique expansion terms bernstein basis polynomials
called bernstein expansionof fixed degree n deg p
words unique count gamble bnp nan

p
bnp ba



n
na

tells us use bb bb p convex combination bernstein
coefficients bnp nan whence
min bnp min p p max p max bnp



following proposition adds detail picture
proposition polynomial p
lim min bnp max bnp min p max p p

n
ndeg p

proof proposition since bnp converges uniformly polynomial p n
trump prautzsch sense




lim maxn p
bnp
n na
n
ndeg p


lim

n
ndeg p

min bnp min p

lim



minn bnp min p

n na
ndeg p



minn bnp p
n na
n
ndeg p




lim maxn p
bnp
n na
n



lim

ndeg p

therefore limn ndeg p min bnp min p furthermore statement see
limn ndeg p min bnp min p hence indeed limn ndeg p min bnp min p proof
equality completely analogous
see clearly polynomials definition linear combinations bernstein basis polynomials
possibly different degrees terms use bb raise degree common higher
degree nmultiply appropriate version shows bernstein basis polynomials
fixed degree n generating polynomials lower degrees independent bb



ficoherent predictive inference exchangeability

prove number useful relations bernstein
positivity polynomial positivity interior simplex related
property first proved hausdorff univariate case hausdorff p
proposition let p polynomial consider following statements
p
ii p v meaning n deg p bnp
iii p v meaning int p
iv p
ii iii iv
proof proposition first implication direct consequence proposition
infer continuity p min p therefore proposition
limn ndeg p min bnp min p implies ii
prove ii iii assume n deg p bnp
consider int since ba nan bb since
assumption bnp bnp nan see
p



bnp ba bnp ba

n
na

third implication immediate consequence continuity p
following counterexample shows necessarily v v
running example go back polynomial q h u defined equation


q h
h
h h h u

already argued polynomial bernstein positive nevertheless
obviously positive interior h u

quite easy trace effect bernstein expansion multiplying
bernstein basis polynomial
proposition polynomials p natural n deg p na
nan


bn

p
n



bpba


otherwise
proof proposition observe



n
pba
bp ba ba
bnp ba ba
n
na

n
na



fide cooman de bock diniz





bnp

n
na


ba


use uniqueness bernstein basis expansion
allows us prove following simple interesting bernstein positivity
proposition consider na polynomial p
pba v p v
proof proposition first assume pba v natural n
n

deg p bn
pba follows proposition bp
therefore p v
assume conversely p v n deg p bnp


follows proposition bn
pba therefore pba v

appendix c dirichlet distribution
density dia dirichlet distribution hyperparameter ra
given
dia



xx int


x
xa
xa

polynomial p define corresponding expectation



p
dia p
xx


x

xa
xa

particular








xx
x

xa
xa
xa



n

mx x

n

x mx

n
x
n

dia ba

n


xmx



xa

xa

ascending factorial r r
r r
r n
dirichlet distribution used prior combination multinomial
likelihood leading called dirichlet multinomial distribution described
follows probability observing sample n observations count vector
na multinomial process dirichlet prior density dia given

n
dimna
comnna dia


integrals section interpreted multiple riemann integrals



ficoherent predictive inference exchangeability


ba dia dia ba




second equality follows equation therefore generally take
expansion polynomial p bernstein basis polynomials degree n deg p
dia p



bnp dia ba

n
na

dimnna



bnp dimnna

n
na


n
na



n
bp dimnna bnp

dirichlet multinomial expectation count gamble bnp general
useful relationship dirichlet expectation polynomial p dirichlet
multinomial expectation bernstein expansion bnp although expectations
strictly speaking defined ra
extend definition continuously
elements ra



taking
appropriate
limits equation indicates

c special properties dirichlet distribution
recall interesting properties dirichlet distribution begin
updating property
proposition updating category set polynomial p v count
vector na ra

dia pba dia ba dia p
proof proposition

dia pba
p ba dia





mx
xx

p
x



x

xa
xa
xa




mx x



p dia

x

xa

dia ba dia p
last equality follows equation
next turn called renaming property
proposition renaming category sets c bijective
one one onto map c polynomial p v c ra

dia p r dic p r


fide cooman de bock diniz

proof proposition due linear nature dirichlet expectation clearly
suffices prove property bernstein basis polynomials p bc
nc observe r bijection equation let r
r z z mz n z z c c
na mc get


mz z
mc
c
dic bc r dic bc
mc c
z
zc

n z z

na

na
z
zc

nx x

na

dia ba
na
x
xa

take account int
bc r bc r






mc mz
mc
mc n z
mz

z
z
r z



zc
zc
zc

na
xnx ba


xa

see indeed dic bc r dia bc r
called pooling property generalises renaming property
proposition pooling category sets onto
map polynomial p v ra

dia p r p r
proof proposition due linear nature dirichlet expectation suffices
prove property bernstein basis polynomials p bd nd
take account renaming property proposition enough consider
following special case non empty set different categories b
c belonging let b c define letting
x x x b c
one hand taking account equation letting r


mz z
md

bd r bd
md
z
zd


md

md mz z



md
z
zdo

hand



ficoherent predictive inference exchangeability

dia bd r




md
md
mz
b c
z
dia



zdo





md


b c md bb cc
zmz z

xa x
zdo







md


md

bk b cmd k c
zmz z

k



x

xa
zdo
k









md k b md k c zdo mz z
md




k
md
xa x
k

compare recall z z z b c
see must prove

md


md
md b c

k b md k c
b c
b c
k
k

equivalently ascending factorials
b c md


md

md
b k c md k
k



k

see proving pooling property essentially equivalent proving equation
binomial theorem ascending factorials well known
follows fact ascending factorials sheffer sequences binomial type sheffer
completeness give proof easy
shown hold prove pooling property particular case
category different b c b c
case rewrite equation
bd r


md
b c
md b c


md b c b c

whereas
dia bd r
let















md bb

md ama





md b c


b c





b c ama db

bb

b

c


da



db da



md b c
b
c





dt da










fide cooman de bock diniz

b md b c b b c

md b c b c

md b c b c

well known evaluation beta function terms gamma functions
finally look properties related restriction
proposition restriction category sets b b
polynomial p v b ra
r n
dia irb p

deg p r b

dib p rb
deg p r
b

proof proposition let n deg p r due linearity dirichlet
expectation operator equations

dia irb p
bnp dia ba ia
n
nb




n

xb nx x
xa b x



n
n
xa b x
xb x
nb


n
nx x

bnp
n
x
n


bnp

nb




n
nb



xb

bnp

n b
dib bb rb
n b

n b
dib p rb
n b

concluding proof

appendix original idmm inference system walley
bernard
idmm inference system sidm introduced section differs one
originally proposed walley bernard appendix discuss original
idmm inference system denote soi explain related
illustrate advantages version one walley bernard
defining original idmm inference system
r category set consider following set polynomials

p v ksa dia p
hoi

p v int dia p
strictly speaking walley bernard propose inference system sense rather
collection prior posterior predictive lower previsions category set inference system
call original idmm inference system one produces predictive lower previsions



ficoherent predictive inference exchangeability

reasons become clear shortly call inference system soi defined

soi hoi
category sets

original idmm inference system hyperparameter updating done much
na
way inference system sidm section

p v int dia p

hoi
c

compared equation leave exercise reader
check soi coherent representation insensitive however illustrated
counterexample section soi specific
predictive soi easily derived mimicking used
section derive predictive sidm see equations
nan
n n n n


n
f l int dia mnna f

doi
c




p n
oi f




inf
int

gambles f
dia mnna f

latter expression motivates refer soi original idmm inference system
predictive lower previsions coincide proposed walley bernard
equation n mimicking argument proof equation
appendix e see


doi
c


f l f





na
f x mx didm
c

xa

tells us idmm original idmm immediate prediction
corresponding immediate predictive lower previsions original idmm
well known course identical ones produced version idmm
inference system given equation however examples next section
illustrate equality extend beyond immediate prediction idmm
original idmm different coherent inference systems leads us general
important conclusion coherent inference systems completely determined
immediate prediction
nevertheless approaches closely related comparing equations
nan
see n n n n


n
inf p soi
gambles f
p n
f
idm f


proof similar one sidm see theorem





fide cooman de bock diniz

original idmm inference system monotone
hyperparameter original idmm inference system usually interpreted
degree caution higher values often claimed produce inferences
cautious less informative following quote walley bernard
section makes explicit
b event concerning future observations idmm produces intervals
posterior probabilities p b p b nested become wider
increases means inferences produced two idmms different
values consistent effect increasing
simply make inferences cautious less informative
similar statements found related papers walley section bernard
section although indeed true many inferences including many important
onesfor example immediate predictions hold event concerning
future observations illustrated following example lower probability
event concerning two future observations shown initially increase
example consider situation possibility space consists two elements
say heads h tails observed n
mh mt interested predictive lower probability

next two trials heads tails observed n looking
h h
mh mt
predictive lower probability event
original idmm inference system following formula provides closed form
expression

p n

oi

inf dia ba

dia mnna


int


n
mx stx mx
inf
n


int n
xa
inf

int

inf



st






initially increases see figure
conclude p n

oi




version idmm inference system statement made aforementioned
quote hold event concerning future observations follows trivially
equation illustrate next example
example consider example time solve version
idmm depicted figure function hyperparameter
n
p idm
non increasing function indeed
contrast p n



oi

n





p soi


slim


n

p idm




p n



oi

closed form expression combining equations




ficoherent predictive inference exchangeability




p n

oi





p n

idm














figure lower probability observing two different outcomes next two experiments given possibility space consists two categories
already observed solutions according soi solid line sidm
dashed solid line see examples information

clearly inferences soi sidm differ suffices compare
examples see figure well therefore seems clear walleys p
statement allowed vary produces exactly
inferences idm equivalently soi sidm produce
inferences taken apply immediate prediction
original idmm inference system specific
announced theorem version idmm inference system specific
least values hyperparameter true original
version
nbn b f l b n
consider n n n n
n
int dia mnna f ib n ia

f ib n doi
cia

srb
int dib mnnb f
last equivalence consequence propositions fact

particular b hard see sb srb int
rb ia
implies
n
n
sb dib mnnb f
f didm b

f ib n doi
cia
c

therefore

b n inf dib mnnb f
p n
p n
oi f ia
idm b f
b



fide cooman de bock diniz

hand due equation sp soi specific would
b n p n


p n
p n
oi f ia
oi b f rb ia
oi b f
p n

hence order soi specific necessary p n
oi b
idm b
coincide illustrated examples previous section necessarily
case therefore soi specific counterexample provided
difference occurs whereas practice usually chosen
walley bernard section would interesting see whether similar
counterexamples constructed
original idmm inference systems specific apparently contradicts theorem de cooman et al seems state fact
theorem states original idmm immediate prediction satisfy weaker
specificity condition tailored immediate prediction since immediate prediction
original idmm idmm coincide contradiction

appendix e proofs additional technical
e proofs section
proof theorem sake notational simplicity use intuitive notation f xk
extnk f give proof general definition terms sets desirable
gambles proof lower previsions follows immediately
consider category set n n k n gamble f
n may assume without loss generality singleton
f xk da
already implies f coherence hence particular f max f
assume ex absurdo f must f define
gamble g letting g f g x max f x
g f therefore g xk f xk implies coherence use
n let max f f f define
g xk da
n
gamble h g ia coherence h xk da
consider natural number n follows repeatedly applying pooling
n
renaming invariance appropriate manner zk


zk variable assumes value xk assumes value
xk repeatedly applying category permutation invariance
n
zk
n coherence tells us

n
n
n zk
leads contradiction coherence

choose n large enough
e proofs section
proposition n n r
proof proposition consider z
tz k n xk z


ya z



k n xk

ficoherent predictive inference exchangeability





ty r z

ya z

concluding proof
lemma n n nan dn







r r



proof lemma consider map dn r defined
permutation index set n dn see























tells us permutation invariant thereforeconstant atoms
ndn means obvious notations n n

implies therefore
proposition r r therefore r tells
us unless r therefore r r
plug f equation see




r r r r
dn

dn

lemma n n ndn


bd r

ba

n r
na


proof lemma

nz
n
bd r
x

zd x z



n
nz

z


nz
z
zd n


n




z




n r
na



n
na

r



n




xa

z

xmx

x z

xmx



xa



concluding proof



xmx

zd



nz

z


n
na

r

ba

fide cooman de bock diniz

lemma allows us prove two related propositions
proposition n n gambles f dn mnna f mnnd f r
proof proposition first count vector nan
hyna f





f
f


n








f

dn










f
r r
n















r



f hynd f r

r

fourth equality follows lemma therefore indeed


mnna f
hyna f ba
hynd f r ba
n
na





n
na

hynd f

n
nd







ba

n r
na


hynd f bd r mnnd f r

n
nd

fourth equality follows lemma
proposition polynomials p n n n deg p
bnpr bnp r
proof proposition expanding p appropriate bernstein basis



n
p r
bp bd r
bnp bd r
n
nd





bnp

n
nd





n
nd



ba





bnp r ba

n
n r
nd
na


n r
na


bnp r ba

n
na

third equality follows lemma desired follows
uniqueness expansion bernstein basis
proof theorem fix category sets onto map
gamble f dn use notation ha
n n n


ficoherent predictive inference exchangeability

hd transform condition ri equivalence condition


one hand letting
n
f da
mnna f ha mnnd f r ha
n
n
n
ba
f da
c
mna f ha ba
mnd f r ha

second equivalences follow proposition hand recalling
r
r
proposition

n
f dd
mnnd f hd
n
n
bd r
f dd
c
mnd f hd

tells us equivalences condition ri rewritten
mnnd f r ha mnnd f hd
n
n
ba
mnd f r ha bd r
mnd f hd

proof complete observe recall discussion section
appendix b varying n n f l dn let p mnnd f range
let

range
polynomials varying n n
count vectors na
proof theorem let ease notation inf ii coherent equation consider category sets onto map
p v na representation insensitivity
coherent theorem
p r ba p r ba
pbd r pbd r
concludes proof
proposition b rb
proof proposition immediate since b sample whose components belong
b category b number times occurs b exactly
number times occurs
proof proposition consider b let simplicity notation ia
since nbn n deg p r



n
n
ia x
ba ia
x

nx x bb
ia

xa

xb

see indeed
irb p



bnp ba ia

n
nb


n
nb



bnp bb p

fide cooman de bock diniz

proof proposition deg p r r p c r trivially
irb p b c c let us assume deg p r first observe
deg p r

nb






deg p r ia x
deg p r nx
ba ia
x

x
ia

xa
xb

deg p r
b
bb
b
b


otherwise



therefore already follows condition irb p b let us therefore
assume b condition equation tell us

irb p
bdeg p r
ba ia
p
deg p r

nb

deg p r





bdeg p r
b
p

bb
b

deg p r

nb

deg p r

deg p r



b

bdeg p r
bb
p
b b

p
b

deg p r

nb

concludes proof
proposition n n gambles f b n
mnna f ib n irb mnnb f r n deg mnnb f
proof proposition first count vector nan thatwith
slight abuse notation
hyna f ib n




f ib n






f

b n

zero unless ia nbn case since obviously
ia b n slight abuse notation
hyna f ib n ia


f hynb f



therefore recall condition


hynb f ba ia
mnna f ib n
hyna f ib n ia ba ia
n
nb

n
nb

irb mnnb f
r n deg mnnb f


ficoherent predictive inference exchangeability

proof theorem fix category sets b b n n n
gamble f b n use notation ha hb b

transform condition sp equivalence condition one hand

r n deg mnnb f
letting
n
f ib n da
mnna f ib n ha irb mnnb f ha
n
n
r
n
ba
f ib n da
c
mna f ib n ha ba
ib mnb f ha

second equivalences follow proposition hand recalling
b rb
rb
proposition

n
f db
mnnb f hb
n
n
b bb rb
f db
c
mnb f hb

tells us equivalences condition sp rewritten
irb mnnb f ha mnnb f hb
r
n
n
ba
ib mnb f ha bb rb
mnb f hb

proof complete recall discussion section appendix b
varying n n f l b n let p mnnb f comnnb hynb f range
polynomials b r n deg mnnb f range elements n
let

range count vectors na
varying n n
proof theorem let ease notation inf ii coherent
equation consider category sets b b p v b
na r n specificity
irb p ba irb p ba
pbb rb b pbb rb b
concludes proof
e proofs section
proof proposition sufficiency fix category set gamble g count
vector na condition ri g g f idd yields condition ri
necessity fix category sets onto map
gamble f count vector na observe f f
r f



rf r
mx
mx
xa f x r

zd f z r xa x z





zd f z r



r z rf r r

fide cooman de bock diniz

rf rf r infer invoking condition ri twice


f da
c id f f
crf

idf df crf r f dd
cr

concluding proof
proof theorem arguments proof rely heavily following expression
lower probability function



n k sup r b
c k n k


sup r ak bnk b

related expressions equivalent representation insensitivity
bernstein coherence b expressions follow equations bernstein
coherence b representation insensitivity form ri
l immediate bernstein coherence fact n k lower probability
use equation b b
l fix non negative integers n k k n consider real
n k n follows applying equation condition ri
xk znk x x z xk znk x z whence
bernstein coherence b xk znk x x z applying
equation condition ri tells us uk znk u u z
whence n k
l l l immediate consequences l l
l consider category set b count vector k
mb n k define gamble g g n k g b n k
g g b l therefore coherence p p predictive lower
prevision p tells us p g g b g g b p n k
n k n k n k see equation clearly suffices prove
p g n k p consider p g follows
equation
ak bnk g g b b

ak bnk g ak bn k g b
therefore coherence b recalling b
ak bnk g ak bn k g b
ak bnk g g b b
combining statements coherence b leads ak bnk
whence n k completes proof
l use l l n k n k n k use l
l sn follows l need prove sn sn equivalently
n n n indeed
n n n n n


ficoherent predictive inference exchangeability

n n n n
n n n
first inequality follows l k second l l
l inequalities hold trivially n due l consider n n
category sets x b x x xn let
since see x x equivalently x x
since x representation insensitivity use equation condition ri
tells us xk xk
xk specificity use theorem allows us
infer nk xk
xk
n b k n
n
infer coherence b k xk k xk ny b apply
representation insensitivity get xn x ny since x
n
equivalent xn x n n shows n n n

equation rest proof immediate
e proofs section
proof theorem v coherent obvious category set f
v v bernstein coherent set polynomials
prove representation insensitivity use theorem consider category sets
onto map p v na
indeed
p r ba v p r v p v pbd r v
first last equivalences follow proposition second one
lemma k
e proofs section
proof theorem v coherent obvious category set f
v v obviously convex cone includes v proposition
contain zero polynomial v therefore bernstein coherent set polynomials

prove representation insensitivity use theorem consider category sets
onto map p v na
indeed
p r ba v int p r ba
int p r
int p
int p bd r pbd r v
second fourth equivalences follow bernstein positivity bernstein
basis polynomials proposition third one lemma k


fide cooman de bock diniz

prove specificity use theorem consider category sets b
b p v b na r n indeed
irb p ba v int irb p ba
int irb p
int b p
int b p bb rb pbb rb v b
second fourth equivalences follow bernstein positivity bernstein
basis polynomials proposition third one lemma k
e proofs section
use convenient device identifying proper subset b element
b unique corresponding element ia whose components outside
b zero
x b x x x b x
observe convention identify int subset
characterise follows
int x x mx
proof proposition clearly suffices prove v hsc
hsc
first statement easy prove asc trivially includes non constant
bernstein basis polynomials proposition since v consists finite strictly positive
linear combinations non constant bernstein basis polynomials immediately
v hsc
prove second statement suppose ex absurdo hsc implies

finitely many nk count vectors k nank pk v

k

k pk ba k possible least one count vector say
k k words k
k consider int k

ba k k ba k moreover since pk v

k

pk hence k pk ba k contradiction
lemma consider na p hsc n nk n


nk k nank pk v
p k pk ba k
k

sa p k k k k
therefore
min sa p min k k
proof lemma second statement trivial given first restrict
attention proving first statement
assume first r k r clearly k
since nr may assume without loss generality r minimal


ficoherent predictive inference exchangeability

element set k k consider int r whence
k k k r

clearly least one kwe see pk since pk v

k
ba k whence pk ba k k must k
r therefore pk ba k since ba k guarantees

p k pk ba k whence indeed k sa p since already know
k r k k
assume conversely k sa p implies k k
k p observe k k
assume ex absurdo k k therefore k k k
fix k x
k therefore x
k x
whence ba k shows p k pk ba k contradiction
lemma consider na p v n n n deg p
nan
bnp k min sa p k
proof lemma fix nan prove contraposition suppose
k min sa p k therefore k since
hence
sa p since moreover
infer equation p b let ease
notation b rewrite see lemma
p b


n
na

bnp ba b


n
nb

bnp ba b



bnp bb

n
nb

due uniqueness bernstein expansion possible bnp
n
n
na
concludes proof since clearly na


proof proposition first assume p hsc implying p k pk ba k

n nk n nk k nank pk v
already
k
follows lemma p
min sa p min k k
consider k min k k int k
k k k k k k kwhich
happens least one k due choice kthen pk ba k
k k since k k k
implying ba k
hence p since holds int k p k v k
assume conversely p v
p k v k
k n min sa p
n
fix n n n deg p p n n bp ba bp ba



nan bnp since p infer equation min sa p
observe sa p know lemma least
one k min sa p k let us pick k call
k let k min sa p mk k k found
way divide disjoint subsets mk one every k min sa p


fide cooman de bock diniz


may empty k mk kmin sa p mk


therefore p kmin sa p mk bnp ba
fix k min sa p construct count vector k letting mk x
x k mk x otherwise notice k nank nk number
elements k set k therefore nk n consider mk
since mk x implies x therefore x see
ba



xx

xa



xx mk x

xa



x mk x

xa

k ba k ba k

n
hence rewrite
k


k
k
mk bp ba

mk k bnp ba k way p

pk ba k pk
kmin sa p ba k pk
hence fix k min sa p left prove nk

pk v
assume first ex absurdo nk particular
k

k contradicts k sa p remains prove pk v

k
consider int k derive k min sa p sa p
k since k k implies k k
k k therefore int k k min sa p k
k k
therefore ba k hence p ba k pk know
p p k v k ba k k k k
conclude indeed pk
lemma na p v
sa p sa pba therefore min sa p min sa pba
proof lemma first assume k sa p k k
p k last inequality continuity polynomials infer
int k p since k p ba
therefore pba k
assume conversely k sa pba
k pba k
last inequality implies k pba therefore
ba p ba derive k
p derive p k
proof proposition way hsc hsc constructed see defining
expressions clearly suffices prove hsc c hsc consider
therefore p v pba hsc proposition implies
pba pba k v k k min sa pba set
prove p hsc applying proposition since clearly p
see suffices p k v k k min sa p consider
k min sa p lemma k min sa pba already argued
pba k v k hence indeed p k v k


ficoherent predictive inference exchangeability


proof equation combining equations see
na

f l sa f hsc
dsc
c


f l
k
sa f f sa f k v k f k sa f k f k
f l
start case
min sa sa f x x f x

statement hence proposition equations dsc

l
na f l
next consider




f


min sa
sa f
x x
f x f





equation recall proposition equations


consider two cases f
f
f
f dsc c
f redundant
f
equivalently since f




f h l h
l f
f dsc c
equivalently since f
f f x
x

f h l h
l
proof equation start first part equation due equation
proposition suffices prove p v minxa p x p
hsc minxa p x p
hsc

first assume minxa p x p
hence since p p min sa p therefore
p
hsc proposition
next assume minxa p x p x p x x implying
min sa p x x therefore since p p hsc
proposition
turn second part equation due equation proposition
na p v mina
suffices prove
p p

hsc
p p
hsc
mina


first assume mina
p



int





p implying p
p

v
hence


min sa
hsc
p therefore p
proposition

next assume mina
p



p

p
v



therefore since p p hsc
hence min sa
p

proposition


fide cooman de bock diniz

proof equation first part equation trivial consequence equa na f l combining
tion second part consider
equations


min
f x x min f x
p sc f
f x x min



xa





xa


xa

lemma consider category sets onto map
p v
k p r k p k
proof lemma first assume p k k
p choose k r clearly p r
p r p therefore p r k
assume conversely pr k k pr
let r k p p r p r hence
p k
lemma consider category sets onto map
p v na


sa p r k k k sd r p
therefore
sa p r sd r p min sa p r min sd r p
proof lemma start proving first statement first assume k sa p
r implying
k k p r k k
r k lemma p k hence k sd r p
conversely assume k k k sd r p
k
implies
k p k lemma implies p r k
hence k sa p r
first statement implies sa p r sd r p therefore order
prove second statement suffices sd r p sa p r
equivalently every l sd r p k sa p r
k l choose l sd r p let k x x l l
k l onto since r l follows k
hence first statement k sa p r
prove third statement first assume k min sa p r implying
k sa p r k sa p r k k second statement
k sd r p prove k min sd r p assume ex absurdo
l sd r p l k let k x k x l k l
k k k l therefore lemma p r k
k p l
since l sd r p see r l
therefore l since k sa p r know k
therefore k l k tells us k sa p r contradiction
assume conversely l min sd r p implying l sd r p


ficoherent predictive inference exchangeability

second statement k sa p r k l hence
k min sa p r k k therefore k k l since
l min sd r p since due second statement k sd r p
k l therefore k l
lemma let
k let p polynomial n deg p
bnp bnp nkn
k

proof lemma follows

p
bnp ba
n
na

k
p k


n
na







bnp ba ia

bnp ba ia

n k
na

bnp nkn bk

n
nk

completes proof
lemma consider category sets onto map
p v
k
p r k v k p k v k
ii p r k v k p k v k
proof lemma first statement follows fact n deg p
bn pr

k

n
bn pr nkn bnp r nkn bnp n k
bnp


k

first last equivalence due lemma second equivalence follows
n nn
proposition third equivalence holds r nk
k
turn second statement prove following statements
equivalent
int k p r
b int k p
first assume holds consider int k prove p

construct k follows
consider z k x z k choose
x way xk x z x z way found k
satisfying r moreover x x k whence int k
infer indeed p p r
assume conversely b holds consider int k z
r z z k r z otherwise means r int k
infer b indeed p r


fide cooman de bock diniz

proposition sc representation insensitive
proof proposition use characterisation representation insensitivity theorem consider category sets onto map
p v na proposition need prove
p r hsc p hsc r
first assume p hsc r proposition implies p
p l v l l min sd r p applying lemma k infer
p
p r consider k min sa p r lemma
k min sd r p implying due assumption p k v k since
k apply lemma p r k v k hence proposition
p r hsc
assume conversely pr hsc proposition implies pr
p r k v k k min sa p r applying lemma
k infer p r p consider l min sd r p
lemma k min sa p r k l since k

assumption p r k v k infer lemma p l v l hence
proposition p hsc r
lemma consider category sets b b p v b
k k b r n irb p k p kb
proof lemma may assume without loss generality r deg p
proof trivial otherwise
first assume p kb
means kb
p ia k infer proposition irb p p
therefore irb p k
assume conversely irb p k means due continuity polynomials int k irb p infer k b

b proposition guarantees p
b since b kb
p kb
lemma consider category sets b b p v b
r n r deg p na


sa irb p k k k b sb rb p
therefore


sb rb p k b k sa irb p



min sb rb p k b k min sa irb p
proof lemma begin first statement first assume k sa irb p
therefore k k irb p k
k implies
kb b k implies b rb b kb moreover irb p k

together proposition r deg p implies k b turn
lemma implies p kb hence k b sb rb p conversely assume


ficoherent predictive inference exchangeability

k k k b sb rb p k b implying k
p kb lemma implies irb p k hence k sa irb p
order prove second statement clearly suffices sb rb p
k b k sa irb p since converse inclusion follows directly first
statement consider l sb rb p let k l k k
k b l b l b rb l hence first statement indeed
k sa irb p
prove third statement first assume k min sa irb p implying
particular k sa irb p second statement k b sb rb p
prove k b min sb rb p consider l sb rb p l k b
let k l argument identical one used proof second
statement k b l k sa irb p however since k b l k b
k b b k b k k b k b k b k b k
therefore k k assumption hence indeed l k b k b assume
conversely l min sb rb p implying l sb rb p second
statement k sa irb p k b l
k min sa irb p k k therefore k b k b l since
l min sb rb p second statement k b sb rb p
k b l
lemma consider category sets b b p v b k
k b r n irb p k v k p kb v k b
proof lemma may assume without loss generality r deg p
proof trivial otherwise proposition considering since k b
b
int k suffices prove following statements equivalent
int k p
b
b int kb p
first assume holds consider int kb prove p
construct
k follows x k b choose x way

xk b x possible x k b let x x
follows construction b
b int k
infer indeed p p



b
assume conversely b holds consider int k b

k b
therefore z b
b z z k b hence b int kb

infer b p b
proposition sc specific
proof proposition use characterisation specificity theorem consider
category sets b b p v b na r n
proposition need prove irb p hsc p hsc b rb
first assume p hsc b rb proposition implies p
p l v l l min sb rb p applying lemma k infer
p irb p consider k min sa irb p lemma


fide cooman de bock diniz

k b min sb rb p implying due assumption p kb v k b
since k b apply lemma irb p k v k hence
proposition irb p hsc
assume conversely irb p hsc proposition implies
r
ib p irb p k v k k min sa irb p lemma
k irb p infer p consider l min sb rb p
lemma k min sa irb p kb l since therefore
k b since assumption irb p k v k infer lemma
p l v l hence proposition p hsc b rb
proof theorem immediate consequence propositions coherence
representation insensitivity specificity
e proofs section
na p v
proof equation consider


ba p hidm
p hidm
c
sa dia ba p


sa dia ba dia p

sa dia p
third equivalence follows updating property dirichlet expectation
proposition
na combining equations
proof equation consider
n



mx x

f l sa
didm
c
f x


xa

consider f l sa

xa

f x



mx x
x


f x mx x

f x
f x mx



xa

xa

combining equations letting c


xa



xa f x mx


int
f didm
c

ease notation


f x tx c




xa

f c f c therefore statement

choose ty close enough respectively f c due
f
didm
c

finally let us
definition c f c hence statement f
didm
c
see happens
f c clearly c consider
int


since f c xa f x tx c therefore since c ss xa f x tx ss c c

statement
hence f didm
c


ficoherent predictive inference exchangeability

na f l combining
proof equation consider
equations

mx x
mx tx
inf
inf
f x

int

xa
xa






inf
f x mx
inf
f x tx
int

xa
xa





inf
f x mx
min f


xa



f x mx
min f




inf
p
idm f



f x

xa

last equality follows min f

mx
xa f x



property convex combinations

proof theorem coherence fix category set must prove

hidm
satisfies requirements b b bernstein coherence trivial

definition hidm
linearity dirichlet expectation operator fact
dirichlet expectation bernstein basis polynomial positive
next turn representation insensitivity use characterisation theorem
consider category sets onto map p v
na pooling property proposition dirichlet
expectation equation indeed

p r ba hidm
sa dia p r

sa p r

sd p r pbd r hidm


third equivalence follows equality sd r sa
finally turn specificity use characterisation theorem consider
category sets b b p v b na
r n restriction property proposition dirichlet expectation
equation indeed

irb p ba hidm
sa dia irb p

sa dib p rb

sb dib p rb pbb rb hidm b


third equivalence follows sb rb sa
e proofs section

lemma p p hsi
sa p p sa p sa p



fide cooman de bock diniz

proof lemma first consider k sa p p meaning k
p p k assume ex absurdo k
sa p k
sa p p k
p k therefore p p k contradiction hence indeed
k sa p sa p
next consider k sa p sa p implying
k
least one k min sa p sa p k k assume without
loss generality k sa p since k min sa p sa p
l k l sa p sa p therefore k min sa p already tells us


p k hidm k
two possibilities first one k sa p

much way p k hidm k hence


due bernstein coherence b hidm k
p p p p hidm k
k
k
k


second possibility k
sa p p k since k

p p k p k p k p k hidm k
cases therefore


p p k hidm k bernstein coherence b hidm k
allows us conclude
since k k p p k therefore
p p k
k sa p p


proof proposition since
hsi
left prove v hsi




p p p hsi p hsi p p hsi

first consider p hsi
clearly sa p sa p therefore
min sa p min sa p k min sa p k min sa p


since p hsi
implies p k hidm k
therefore due bernstein


coherence hidm k p k p k hidm k
furthermore since p

p therefore p hsi

next consider p p hsi
p p implying sa p
sa p therefore sa p sa p applying lemma
sa p p k k p p k

therefore p p k min sa p p equivalently due lemma
k min sa p sa p applying reasoning second part


proof lemma p p k hidm k
hence p p hsi

since already shown hsi closed taking positive linear combinations
since v consists positive linear combinations bernstein basis polynomials

need hsi
contains bernstein basis polynomials order prove


v hsi consider na k k
ba k bk rk k ba k otherwise implies

sa ba
k k due bernstein coherence hidm k



ba k bk rk hidm k k sa ba hence ba k hidm k

k min sa ba since ba indeed ba hsi



proof proposition first prove hsi
c hsi
consider p v


pba hsi meaning pba pba k hidm k


k min sa pba set prove p hsi since clearly p suffices

p k hidm k
crk k min sa p consider k min sa p
implying k therefore k rk infer

lemma k min sa pba tells us pba k hidm k
since

pba k p k ba k p k bk rk p k hidm k crk



ficoherent predictive inference exchangeability




next prove hsi
hsi
c consider p hsi
meaning

p p k hidm k crk k min sa p set prove


pba hsi
equivalently pba

pba k hidm k
k min sa pba since p continuity polynomials guarantees
int p therefore pba know already
pba consider k min sa pba lemma k min sa p


implying k p k hidm k
crk therefore p k bk rk hidm k


since moreover p k bk rk pba k indeed pba k hidm k

proof equation due equation suffices prove p v


minxa p x p hsi
minxa p x p
hsi


first assume minxa p x p
hence since p p min sa p therefore due


bernstein coherence hidm
see theorem p
hidm


infer p
hsi
next assume minxa p x p x p x x implying

min sa p x x x p x hidm x



bernstein coherence hidm x hence since p p hsi

proof equations equation follows directly equation
prove equation due equation proposition suffices prove
na p v



p hsi
p
c p
hsi
c p




ease notation let

c p

inf

sa



dia
ra
p



implying dia

first assume c p
ra
p




equation p


therefore p





hidm
p therefore
hence min sa
cra

p
hsi



implying p
next assume c p
equation



therefore
p

h
cr


hence



min

p




idm


p hsi

na
proof equation combining equations see




f l sa f hsi
dsi
c



consider f l distinguish two cases f
f

f
therefore f


sa f
f dsi
c
hidm

cra



sa
f
hidm

cra



fide cooman de bock diniz


f
didm

cra



f


f
x


f


f x mx f
x






xa


xa

first equivalence due statement equations
second equivalence follows definition sa sa
third one due
equations fourth equivalence consequence equation
final equivalence holds f redundant given f

f
statement equations

f x

f dsi
c

f x sa f x
hidm
cra x



x


since f
cra x
bernstein coherent theorem
hidm x


latter statement equivalent f x hence

f x f

f dsi
c
x

f
f



f x mx f


xa

second third equivalences consequences f

lemma consider category sets onto map
p v na k k


p r k hidm k
crk p k hidm k
cr k r
proof lemma let k k k p p k
onto map p v p r p k r k p r k

since k identify element rk nk
therefore
follows representation insensitivity idmm inference system
hyperparameter r r k rk r k r





p r hidm
c p hidm cr

proposition ssi representation insensitive
proof proposition use characterisation representation insensitivity theorem consider category sets onto map
p v na proposition need prove


p r hsi
p hsi r




first assume p hsi r meaning p p l hidm l
crl r
l min sd r p applying lemma k infer p
p r consider k min sa p r k k
lemma k min sd r p implying due assumption p k


ficoherent predictive inference exchangeability



hidm k
cr k r applying lemma p r k hidm k
crk

hence p r hsi

assume conversely p r hsi
meaning p r p r k

hidm k crk k min sa p r applying lemma k infer
p r p consider l min sd r p lemma
k min sa p r k l since k k

assumption p r k hidm k
crk infer lemma


p l hidm l crl r hence p hsi r

lemma consider category sets b b p v b
na r n k k b k


irb p k hidm k
crk p kb hidm kb
crkb
proof lemma let k b k b p p kb r deg p deg p r
b p v b r r r deg p r deg p


bdeg p r
ba ia k
bdeg p r
ba ia k
irb p k
p
p
deg p r

deg p r

nb





nb
b k


bdeg p r
bk ik irb p
p
kb

deg p r

nkb

third equality follows unicity bernstein expansion polynomial
since k identify element rk nk therefore
follows specificity idmm inference system hyperparameter
rb rkb







irb p hidm
c p hidm b crb

proposition ssi specific
proof proposition use characterisation specificity theorem consider
category sets b b p v b na


r n proposition need prove irb p hsi
p hsi b r

b
clear propositions assume without loss generality
r deg p


first assume p hsi b r
implying p
p l hidm l
crbl
b
l min sb rb p applying lemma k infer p
irb p consider k min sa irb p infer lemma k

crkb
b min sb rb p implying due assumption p kb hidm kb
r

since k b k ib p k hidm k crk lemma hence

irb p hsi


assume conversely irb p hsi
implies irb p
r

ib p k hidm k crk k min sa irb p applying lemma
k infer irb p p consider l min sb rb p
lemma k min sa irb p k b l since k b


fide cooman de bock diniz


k assumption irb p k hidm k
crk infer lemma


p kb hidm kb crkb words p l hidm l
crbl hence

p hsi b rb

proof theorem immediate consequence propositions coherence
representation insensitivity specificity
e proofs section
proof theorem begin coherence consider category set

prove hh bernstein coherent b recall
hidm



therefore
hh similarly b recall v hidm

therefore v hh b consider n n k r pk hh

k
n pk hidm
k n
n


n therefore k k pk hidm bernstein coherence theorem hence indeed
k k pk hh
next turn representation insensitivity use characterisation theorem
consider category sets onto map p v
na indeed

p r ba hh r p r ba hidm

r pbd r hidm
pbd r hh

second equivalence follows representation insensitivity idmm
inference systems theorem
finally turn specificity use characterisation theorem consider
category sets b b p v b na r n
indeed

irb p ba hh r irb p ba hidm

r pbb rb hidm b
pbb rb hh b

second equivalence follows specificity idmm inference systems theorem
na p v
proof equation

pba
p hh c
hh r pba
hidm


r p hidm
c

combined equation yields desired
na p v
proof equation
sup r p hh c

h h p




sup sup r p hidm
c
sr



ficoherent predictive inference exchangeability

lim
inf dia p

sup


inf dia p

sa

sr

second equality due equation third one due equation
proof equation consider p v apply equation
h h p lim

inf dia p lim

sa

inf dia p

inf

int



fix n max deg p int equation
nan






dia ba

n



n mx
n


tx
n
tx x




xa
xa

x
mx

tx

tx tx tx mx tx mx

similarly

n



n





hence



dia ba

xa tx mx





n



consider two cases since n cases
exhaustive dia ba equivalently
x nx dia ba nx tx combine
equation
dia p



bnp dia ba

n
na



bnp nx tx

xa

furthermore due equation
bnp nx



bnp ba x p x x

n
na

hence conclude
dia p



p x tx

xa

combined equation leads desired


fide cooman de bock diniz

na p v use equation
proof equation consider
lim
h h p

lim sup dia p

h h p
inf dia p

sa





bernstein coherent theorem follows h h
coherent
since hh c
super additive conjugate upper
lower prevision implies h h
sub additive hence suffices prove equalities equation
prevision h h
bernstein basis polynomial p ba na sa
gather equation appendix b

n

mx x nx
dia ba
n

xa


observe
x
mx x nx mx x mx x mx x nx n
x
x

similarly since



n





n





therefore

nx

n
xa mx

dia ba




x

n


xa



equation leads

nx
n
xa mx
h h ba


h h ba
dia ba
n




e proofs section
proof theorem already argued smallest inference
system shall denote lower probability function first assume n
denote n k n k n k follows assumptions
n k n k k n



first going prove induction implies
n k

k
n n k n
n

see footnote





ficoherent predictive inference exchangeability

observe inequality holds trivially k theorem l assume
inequality holds k n must holds
k assume ex absurdo therefore
n



n n n n n
n
n



second inequality follows induction hypothesis
n n n

n


n n n n






n
n n
n n n n
n
n

first inequality follows equation second first
second inequalities equation contradiction completes proof
induction
infer theorem l assumption
n k

k n
k

k n
nn
n



observe inequality holds trivially n get predictive
lower prevision p h gamble h

h x min h p x
p h min h p h min h min h
xa

min h



h x min h n mx

xa

min h


xa

h x min h

mx
p
idm h
n

first equality first inequality follow coherence p p p
p second equality representation insensitivity equation
second inequality equation converse inequality observe idmm
inference system sidm coherent representation insensitive specific theorem
clearly concave surprise satisfies assumption therefore dominates smallest
inference system

references
augustin coolen f p de cooman g troffaes c eds
introduction imprecise probabilities john wiley sons
bernard j bayesian analysis tree structured categorized data revue internationale de systmique
bernard j introduction imprecise dirichlet model multinomial
data international journal approximate reasoning


fide cooman de bock diniz

bernard j personal conversation
boole g reprinted laws thought dover publications york
boole g reprint work originally published watts co london
studies logic probability dover publications mineola ny
carnap r continuum inductive methods university chicago press
cifarelli regazzini e de finettis contributions probability statistics
statistical science
couso moral sets desirable gambles conditioning representation
precise probabilities international journal approximate reasoning

cozman f g independence full conditional probabilities structure factorization non uniqueness bayesian networks international journal approximate
reasoning
de cooman g miranda e symmetry versus symmetry
harper w l wheeler g r eds probability inference essays honor
henry e kyburg jr pp kings college publications
de cooman g miranda e f riesz representation theorem finite
additivity dubois lubiano prade h gil grzegorzewski
p hryniewicz eds soft methods handling variability imprecision
proceedings smps pp springer
de cooman g miranda e b weak strong laws large numbers coherent
lower previsions journal statistical inference
de cooman g miranda e irrelevant independent natural extension
sets desirable gambles journal artificial intelligence
de cooman g miranda e quaeghebeur e representation insensitivity
immediate prediction exchangeability international journal approximate
reasoning
de cooman g quaeghebeur e exchangeability sets desirable gambles
international journal approximate reasoning special issue
honour henry e kyburg jr
de cooman g quaeghebeur e miranda e b exchangeable lower previsions
bernoulli
de finetti b la prvision ses lois logiques ses sources subjectives annales de
linstitut henri poincar english translation kyburg jr smokler

de finetti b teoria delle probabilit einaudi turin
de finetti b theory probability critical introductory treatment john
wiley sons chichester english translation de finettis book two volumes
dubins l e finitely additive conditional probabilities conglomerability
disintegrations annals probability


ficoherent predictive inference exchangeability

geisser predictive inference introduction chapman hall
goldstein prevision prevision journal american statistical
society
goldstein temporal coherence bernardo j degroot h lindley
v smith f eds bayesian statistics vol pp north holland
amsterdam discussion
good j estimation probabilities essay modern bayesian methods
mit press
haldane j b method estimating frequencies biometrika
hausdorff f momentprobleme fr ein endliches intervall mathematische zeitschrift

jaynes e probability theory logic science cambridge university press
jeffreys h theory probability oxford classics series oxford university press
reprint third edition corrections
johnson n l kotz balakrishnan n discrete multivariate distributions
wiley series probability statistics john wiley sons york
johnson w e logic part iii logical foundations science cambridge
university press reprinted dover publications
keynes j treatise probability macmillan london
koopman b axioms algebra intuitive probability annals
mathematics second series
kyburg jr h e smokler h e eds studies subjective probability wiley
york second edition material
lad f operational subjective statistical methods mathematical philosophical
historical introduction john wiley sons
levi enterprise knowledge mit press london
mangili f benavoli prior near ignorance simplex
cozman f denux destercke seidenfeld eds isipta
proceedings eighth international symposium imprecise probability theories
applications pp sipta
miranda e updating coherent lower previsions finite spaces fuzzy sets
systems
miranda e de cooman g introduction imprecise probabilities chap lower
previsions john wiley sons
miranda e zaffalon notes desirability conditional lower previsions
annals mathematics artificial intelligence
moral epistemic irrelevance sets desirable gambles annals mathematics
artificial intelligence


fide cooman de bock diniz

moral wilson n revision rules convex sets probabilities coletti
g dubois scozzafava r eds mathematical handling partial
knowledge artificial intelligence pp plenum press york
piatti zaffalon trojani f hutter limits learning categorical
latent variable prior near ignorance international journal approximate
reasoning
prautzsch h boehm w paluszny bzier b spline techniques springer
berlin
quaeghebeur e introduction imprecise probabilities chap desirability john
wiley sons
quaeghebeur e de cooman g hermans f accept reject statement
uncertainty international journal approximate reasoning accepted
publication
rouanet h lecoutre b specific inference anova significance tests
bayesian procedures british journal mathematical statistical psychology

seidenfeld schervish j kadane j b representation partially ordered
preferences annals statistics reprinted collection
seidenfeld et al pp
seidenfeld schervish j kadane j b rethinking foundations
statistics cambridge university press cambridge
sheffer properties polynomial sets type zero duke mathematical
journal
smith c b consistency statistical inference decision journal
royal statistical society series
troffaes c de cooman g lower previsions wiley
trump w prautzsch h arbitrary degree elevation bzier representations
computer aided geometric design
walley p statistical reasoning imprecise probabilities chapman hall
london
walley p inferences multinomial data learning bag marbles journal
royal statistical society series b discussion
walley p bounded derivative model prior ignorance real valued
parameter scandinavian journal statistics
walley p towards unified theory imprecise probability international journal
approximate reasoning
walley p bernard j imprecise probabilistic prediction categorical data
tech rep caf laboratoire cognition et activites finalises universit de
paris


ficoherent predictive inference exchangeability

williams p coherence strict coherence zero probabilities proceedings
fifth international congress logic methodology philosophy science
vol vi pp dordrecht proceedings conference held warsaw
williams p b notes conditional previsions tech rep school mathematical
physical science university sussex uk see revised journal version
williams
williams p indeterminate probabilities przelecki szaniawski k
wojcicki r eds formal methods methodology empirical sciences pp
reidel dordrecht proceedings conference held warsaw
williams p notes conditional previsions international journal approximate
reasoning
zabell l w e johnsons sufficientness postulate annals statistics
reprinted collection zabell
zabell l symmetry discontents essays history inductive probability cambridge studies probability induction decision theory cambridge
university press cambridge uk
zaffalon miranda e probability time artificial intelligence




