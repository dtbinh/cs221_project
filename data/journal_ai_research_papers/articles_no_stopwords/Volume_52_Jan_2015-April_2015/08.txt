Journal Artificial Intelligence Research 52 (2015) 399443

Submitted 08/14; published 03/15

Computing Convex Coverage Sets
Faster Multi-objective Coordination
Diederik M. Roijers
Shimon Whiteson
Frans A. Oliehoek

d.m.roijers@uva.nl
s.a.whiteson@uva.nl
f.a.oliehoek@uva.nl

Informatics Institute
University Amsterdam
Amsterdam, Netherlands

Abstract
article, propose new algorithms multi-objective coordination graphs (MOCoGs). Key efficiency algorithms compute convex coverage
set (CCS) instead Pareto coverage set (PCS). CCS sufficient solution
set large class problems, important characteristics facilitate
efficient solutions. propose two main algorithms computing CCS MO-CoGs.
Convex multi-objective variable elimination (CMOVE) computes CCS performing
series agent eliminations, seen solving series local multi-objective
subproblems. Variable elimination linear support (VELS) iteratively identifies single
weight vector w lead maximal possible improvement partial CCS
calls variable elimination solve scalarized instance problem w. VELS
faster CMOVE small medium numbers objectives compute
-approximate CCS fraction runtime. addition, propose variants
methods employ AND/OR tree search instead variable elimination achieve
memory efficiency. analyze runtime space complexities methods, prove
correctness, compare empirically naive baseline existing
PCS method, terms memory-usage runtime. results show that,
focusing CCS, methods achieve much better scalability number
agents current state art.

1. Introduction
many real-world problem domains, maintenance planning (Scharpff, Spaan,
Volker, & De Weerdt, 2013) traffic light control (Pham et al., 2013), multiple agents
need coordinate actions order maximize common utility. Key coordinating
efficiently domains exploiting loose couplings agents (Guestrin, Koller,
& Parr, 2002; Kok & Vlassis, 2004): agents actions directly affect subset
agents.
Multi-agent coordination complicated fact that, many domains, agents need
balance multiple objectives (Roijers, Vamplew, Whiteson, & Dazeley, 2013a). example, agents might maximize performance computer network minimizing
power consumption (Tesauro, Das, Chan, Kephart, Lefurgy, Levine, & Rawson, 2007),
maximize cost efficiency maintenance tasks road network minimizing traffic
delays (Roijers, Scharpff, Spaan, Oliehoek, de Weerdt, & Whiteson, 2014).
c
2015
AI Access Foundation. rights reserved.

fiRoijers, Whiteson, & Oliehoek

Figure 1: Mining company example.
However, presence multiple objectives per se necessitate use
specialized multi-objective solution methods. problem scalarized, i.e.,
utility function converted scalar utility function, problem may solvable
existing single-objective methods. conversion involves two steps (Roijers et al.,
2013a). first step specify scalarization function.
Definition 1. scalarization function f , function maps multi-objective utility
solution decision problem, u(a), scalar utility uw (a):
uw (a) = f (u(a), w),
w weight vector parameterizes f .
second step define single-objective version decision problem
utility solution equals scalarized utility original problem uw (a).
Unfortunately, scalarizing problem solving always possible
w may known advance. example, consider company mines different
resources. Figure 1, depict problem company faces: morning one van
per village needs transport workers village nearby mine, various
resources mined. Different mines yield different quantities resource per worker.
market prices per resource vary stochastic process every price change
alter optimal assignment vans. expected price variation increases
passage time. maximize performance, thus critical act based latest
possible price information. Since computing optimal van assignment takes time, redoing
computation every price change highly undesirable.
settings, need multi-objective method computes, advance, optimal solution possible prices, w. call set coverage set (CS). many
cases, w revealed solution must executed, case solution
automatically selected CS given w. cases, w never made explicit
instead human involved decision making selects one solution
CS, perhaps basis constraints preferences difficult formalize
objectives (Roijers et al., 2013a). cases, CS typically
much smaller complete set solutions, selecting optimal joint action
CS typically much easier selecting directly complete set solutions.
400

fiComputing CCSs Faster Multi-objective Coordination

article, consider multi-objective methods made efficient problems require coordination multiple, loosely coupled agents. particular, address multi-objective coordination graphs (MO-CoGs): one-shot multi-agent decision problems loose couplings expressed using graphical model. MO-CoGs form
important class decision problems. used model variety realworld problems (Delle Fave, Stranders, Rogers, & Jennings, 2011; Marinescu, 2011; Rollon,
2008), many sequential decision problems modeled series MO-CoGs,
common single-objective problems (Guestrin et al., 2002; Kok & Vlassis, 2004; Oliehoek,
Spaan, Dibangoye, & Amato, 2010).
Key efficiency MO-CoG methods propose compute convex
coverage set (CCS) instead Pareto coverage set (PCS). CCS subset
PCS sufficient solution multi-objective problem linear scalarization
function. example, mining company example Figure 1, f linear, since
total revenue simply sum quantity resource mined times price per
unit. However, even f nonlinear, stochastic solutions allowed, CCS
sufficient.1
CCS previously considered solution concept MO-CoGs
computing CCS requires running linear programs, whilst computing PCS requires
pairwise comparisons solutions. However, key insight article2 that, loosely
coupled systems, CCSs easier compute PCSs, two reasons. First, CCS
(typically much smaller) subset PCS. loosely coupled settings, efficient methods
work solving series local subproblems; focusing CCS greatly reduce size
subproblems. Second, focusing CCS makes solving MO-CoG equivalent
finding optimal piecewise-linear convex (PWLC) scalarized value function,
efficient techniques adapted. reasons, argue CCS often
concept choice MO-CoGs.
propose two approaches exploit insights solve MO-CoGs efficiently
existing methods (Delle Fave et al., 2011; Dubus, Gonzales, & Perny, 2009; Marinescu,
Razak, & Wilson, 2012; Rollon & Larrosa, 2006). first approach deals multiple
objectives level individual agents, second deals global
level.
first approach extends algorithm Rollon Larrosa (2006) refer
Pareto multi-objective variable elimination (PMOVE) 3 , computes local Pareto
sets agent elimination, compute CCS instead. call resulting algorithm
convex multi-objective variable elimination (CMOVE).
second approach new abstract algorithm call optimistic linear support
(OLS) much faster small medium numbers objectives. Furthermore, OLS
1. precise, case stochastic strategies CCS deterministic strategies always sufficient
(Vamplew, Dazeley, Barker, & Kelarev, 2009); case deterministic strategies, linearity
scalarization function makes CCS sufficient (Roijers et al., 2013a).
2. article synthesizes extends research already reported two conference papers. Specifically,
CMOVE algorithm (Section 4) previously published ADT (Roijers, Whiteson, & Oliehoek,
2013b) VELS algorithm (Section 5) AAMAS (Roijers, Whiteson, & Oliehoek, 2014).
memory-efficient methods computing CCSs (Section 6) novel contribution article.
3. original article, algorithm called multi-objective bucket elimination (MOBE). However,
use PMOVE consistent names algorithms mentioned article.

401

fiRoijers, Whiteson, & Oliehoek

used produce bounded approximation CCS, -CCS,
enough time compute full CCS. OLS generic method employs single-objective
solvers subroutine. article, consider two implementations subroutine.
Using variable elimination (VE) subroutine yields variable elimination linear support
(VELS), particularly fast small moderate numbers objectives
memory-efficient CMOVE. However, memory highly limited, reduction
memory usage may enough. cases, using AND/OR search (Mateescu &
Dechter, 2005) instead yields AND/OR tree search linear support (TSLS),
slower VELS much memory efficient.
prove correctness CMOVE OLS. analyze runtime space
complexities methods show methods better guarantees
PCS methods. show CMOVE OLS complementary, i.e., various trade-offs exist
variants.
Furthermore, demonstrate empirically, randomized realistic problems, CMOVE VELS scale much better previous algorithms. empirically confirm trade-offs CMOVE OLS. show OLS, used
bounded approximation algorithm, save additional orders magnitude runtime,
even small . Finally, show that, even memory highly limited, TSLS
still solve large problems.
rest article structured follows. First, provide formal definition
model, well overview existing solution methods Section 2.
presenting naive approach Section 3, Sections 4, 5 6, analyze runtime
space complexities algorithm, compare empirically,
existing algorithms, end section. Finally, conclude Section 7
overview contributions findings, suggestions future research.

2. Background
section, formalize multi-objective coordination graph (MO-CoG).
however, describe single-objective version problem, coordination graph
(CoG), MO-CoG extension, variable elimination (VE) algorithm
solving CoGs. methods present Section 4 5 build different ways.
2.1 (Single-Objective) Coordination Graphs
coordination graph (CoG) (Guestrin et al., 2002; Kok & Vlassis, 2004) tuple hD, A, Ui,

= {1, ..., n} set n agents,
= Ai ... joint action space: Cartesian product finite action
spaces agents. joint action thus tuple containing action agent
= ha1 , ..., i,


U = u1 , ..., u set scalar local payoff functions, limited
scope, i.e., depends onlyPa subset agents. total team payoff sum
local payoffs: u(a) = e=1 ue (ae ).
402

fiComputing CCSs Faster Multi-objective Coordination

Figure 2: (a) CoG 3 agents 2 local payoff functions (b) eliminating agent 3
adding u3 (c) eliminating agent 2 adding u4 .

a1
a1

a2
3.25
1.25

a2
0
3.75

a2
a2

a3
2.5
0

a3
1.5
1

Table 1: payoff matrices u1 (a1 , a2 ) (left) u2 (a2 , a3 ) (right). two possible
actions per agent, denoted dot (a1 ) bar (a1 ).

agents share payoff function u(a). abuse notation e index local
payoff function ue denote subset agents scope; ae thus local joint
action, i.e., joint action subset agents.
decomposition u(a) local payoff functions represented factor
graph (Bishop, 2006), bipartite graph containing two types vertices: agents (variables)
local payoff functions (factors), edges connecting local payoff functions
agents scope.
Figure 2a shows factor graph example CoG team payoff function
decomposes two local payoff functions, two agents scope:
u(a) =


X

ue (ae ) = u1 (a1 , a2 ) + u2 (a2 , a3 ).

e=1

local payoff functions defined Table 1. factor graph illustrates loose
couplings result decomposition local payoff functions. particular,
agents choice action directly depends immediate neighbors, e.g.,
agent 1 knows agent 2s action, choose action without considering agent 3.
2.2 Variable Elimination
discuss variable elimination (VE) algorithm, several multi-objective
extensions (Rollon & Larrosa, 2006; Rollon, 2008) build, including CMOVE algorithm (Section 4). use subroutine OLS algorithm (Section 5).
exploits loose couplings expressed local payoff functions efficiently
compute optimal joint action, i.e., joint action maximizing u(a). First, forward
403

fiRoijers, Whiteson, & Oliehoek

pass, eliminates agents turn computing value agents best
response every possible joint action neighbors. values used construct
new local payoff function encodes value best response replaces agent
payoff functions participated. original algorithm, agents
eliminated, backward pass assembles optimal joint action using constructed
payoff functions. Here, present slight variant payoff tagged
action generates it, obviating need backwards pass. two algorithms
equivalent, variant amenable multi-objective extension present
Section 4.
eliminates agents graph predetermined order. Algorithm 1 shows
pseudocode elimination single agent i. First, determines set local
payoff functions connected i, Ui , neighboring agents i, ni (lines 1-2).
Definition 2. set neighboring local payoff functions Ui set local
payoff functions agent scope.
Definition 3. set neighboring agents i, ni , set agents
scope one local payoff functions Ui .
Then, constructs new payoff function computing value agent best
response possible joint action ani agents ni (lines 3-12). so,
loops joint actions Ani (line 4). ani , loops actions Ai
available agent (line 6). ai Ai , computes local payoff agent
responds ani ai (line 7). tags total payoff ai , action generates
(line 8) order able retrieve optimal joint action later. already
tags present, appends ai them; way, entire joint action incrementally
constructed. maintains value best response taking maximum
payoffs (line 11). Finally, eliminates agent payoff functions Ui replaces
newly constructed local payoff function (line 13).
Algorithm 1: elimVE(U, i)
1
2
3
4
5
6
7

Input: CoG U, agent
Ui set local payoff functions involving
ni set neighboring agents
unew new factor taking joint actions ni , ani , input
foreach ani Ani

foreach aX
Ai
v
uj (ani , ai )
uj Ui

8
9
10
11
12
13

tag v ai
{v}
end
unew (ani ) max(S)
end
return (U \ Ui ) {unew }

404

fiComputing CCSs Faster Multi-objective Coordination

Consider example Figure 2a Table 1. optimal payoff maximizes sum
two payoff functions:
max u(a) = max u1 (a1 , a2 ) + u2 (a2 , a3 ).


a1 ,a2 ,a3

eliminates agent 3 first, pushes maximization a3 inward
goes local payoff functions involving agent 3, case u2 :


1
2
max u(a) = max u (a1 , a2 ) + max u (a2 , a3 ) .


a1 ,a2

a3

solves inner maximization replaces new local payoff function u3
depends agent 3s neighbors, thereby eliminating agent 1:

max u(a) = max u1 (a1 , a2 ) + u3 (a2 ) ,


a1 ,a2

leads new factor graph depicted Figure 2b. values u3 (a2 ) u3 (a2 ) =
2.5, using a3 , u3 (a2 ) = 1 using a3 , optimal payoffs actions
agent 2, given payoffs shown Table 1. ultimately want optimal joint
action, optimal payoff, tags payoff u3 action agent 3
generates it, i.e., think u3 (a2 ) (value, tag) pair. denote pair
parentheses subscript: u3 (a2 ) = (2.5)a3 , u3 (a2 ) = (1)a3 .
next eliminates agent 2, yielding factor graph shown Figure 2c:


1
3
max u(a) = max max u (a1 , a2 ) + u (a2 ) = max u4 (a1 ).


a1

a2

a1

appends new tags agent 2 existing tags agent 3, yielding following
tagged payoff values: u4 (a1 ) = maxa2 u1 (a1 , a2 ) + u3 (a2 ) =(3.25)a2 + (2.5)a2 a3 = (5.75)a2 a3
u4 (a1 ) = (3.75)a2 + (1)a2 a3 = (4.75)a2 a3 . Finally, maximizing a1 yields optimal
payoff (5.75)a1 a2 a3 , optimal action contained tags.
runtime complexity exponential, number agents,
induced width, often much less number agents.
Theorem 1. computational complexity O(n|Amax |w ) |Amax |
maximal number actions single agent w induced width, i.e., maximal
number neighboring agents agent plus one (the agent ), moment
eliminated (Guestrin et al., 2002).
Theorem 2. space complexity O( n |Amax |w ).
space complexity arises because, every agent elimination, new local payoff
function created O(|Amax |w ) fields (possible input actions). Since impossible
tell priori many new local payoff functions exist given time
execution VE, need multiplied total number new local payoff
functions created execution, n.
designed minimize runtime4 methods focus memory efficiency
instead (Mateescu & Dechter, 2005). discuss memory efficiency Section 6.1.
4. fact, proven best runtime guarantees within large class algorithms (Rosenthal,
1977).

405

fiRoijers, Whiteson, & Oliehoek

a1
a1

a2
(4,1)
(1,2)

a2
(0,0)
(3,6)

a2
a2

a3
(3,1)
(0,0)

a3
(1,3)
(1,1)

Table 2: two-dimensional payoff matrices u1 (a1 , a2 ) (left) u2 (a2 , a3 ) (right).
2.3 Multi-objective Coordination Graphs
multi-objective coordination

graph (MO-CoG) tuple hD, A, Ui
but, U = u1 , ..., u set , d-dimensional local P
payoff functions.
total team payoff sum local vector-valued payoffs: u(a) = e=1 ue (ae ). use
ui indicate value i-th objective. denote set possible joint action
values V. Table 2 shows two-dimensional MO-CoG structure
single-objective example Section 2.1, multi-objective payoffs.
solution MO-CoG coverage set (CS) joint actions associated values
u(a) contains least one optimal joint action possible parameter vector w
scalarization function f (Definition 1). CS subset undominated set:
Definition 4. undominated set (U) MO-CoG, set joint actions
associated payoff values optimal w scalarization function f .


U (V) = u(a) : u(a) V wa0 uw (a) uw (a0 ) .
care least one optimal joint action every w, rather
optimal joint actions, lossless subset U suffices:
Definition 5. coverage set (CS), CS(V), subset U , possible w,
least one optimal solution CS, i.e.,
wa


u(a) CS(V) a0 uw (a) uw (a0 ) .

Note CS necessarily unique. Typically seek smallest possible CS.
convenience, assume payoff vectors CS contain values associated
joint actions, suggested tagging scheme described Section 2.2.
payoff vectors V CS depends know
scalarization function f . minimal assumption f monotonically increasing, i.e.,
value one objective ui , increases uj6=i stay constant, scalarized value
u(a) cannot decrease. assumption ensures objectives desirable, i.e., else
equal, always better.
Definition 6. Pareto front undominated set arbitrary strictly monotonically
increasing scalarization functions f .


P F (V) = u(a) : u(a) V a0 u(a0 ) P u(a) ,
P indicates Pareto dominance (P-dominance): greater equal objectives
strictly greater least one objective.
406

fiComputing CCSs Faster Multi-objective Coordination

order optimal scalarized values, necessary compute entire
PF. E.g., two joint actions equal payoffs need retain one those.
Definition 7. Pareto coverage set (PCS), P CS(V) P F (V), coverage set
arbitrary strictly monotonically increasing scalarization functions f , i.e.,

a0 u(a) P CS(V) (u(a) P u(a0 ) u(a) = u(a0 )) .
Computing P-dominance requires pairwise comparison payoff vectors (Feng &
Zilberstein, 2004).5
highly prevalent scenario that, addition f monotonically increasing,
know linear, is, parameter vectors w weights
values individual objectives multiplied, f = w u(a). mining example
Figure 1, resources traded open market resources positive unit
price. case, scalarization linear combination amount resource
mined, weights correspond price per unit resource. Many
examples linear scalarization functions exist literature, e.g., (Lizotte, Bowling, &
Murphy, 2010). assume linear scalarization monotonically increasing,
represent without loss generality convex combination objectives: i.e.,
weights positive sum 1. case, convex coverage set (CCS)
needed, subset convex hull (CH) 6 :
Definition 8. convex hull (CH) undominated set linear non-decreasing
scalarizations f (u(a), w) = w u(a):


CH(V) = u(a) : u(a) V wa0 w u(a) w u(a0 ) .
is, CH contains solutions attain optimal value least one weight.
Vectors CH C-dominated. contrast P-domination, C-domination cannot
tested pairwise comparisons take two payoff vectors
C-dominate payoff vector. Note CH contains solutions needed guarantee optimal scalarized value value: contain multiple solutions optimal
one specific weight. lossless subset CH respect linear scalarizations
called convex coverage set (CCS), i.e., CCS retains least one u(a) maximizes
scalarized payoff, w u(a), every w:
Definition 9. convex coverage set (CCS), CCS(V) CH(V), CS linear nondecreasing scalarizations, i.e.,

wa u(a) CCS(V) a0 w u(a) w u(a0 ) .
Since linear non-decreasing functions specific type monotonically increasing function, always CCS subset smallest possible PCS.
previously mentioned, CSs PCS CCS, may unique. example,
two joint actions equal payoff vectors, need one
make PCS CCS.
5. P-dominance often called pairwise dominance POMDP literature.
6. Note term convex hull overloaded. graphics, convex hull superset mean
convex hull article.

407

fiRoijers, Whiteson, & Oliehoek

Figure 3: CCS (filled circles left, solid black lines right) versus PCS (filled circles
squares left, dashed solid black lines right) twelve random
2-dimensional payoff vectors.

practice, PCS CCS often equal PF CH. However,
algorithms proposed article guaranteed produce PCS CCS,
necessarily entire PF CH. PCSs CCSs sufficient solutions
terms scalarized value, say algorithms solve MO-CoGs.
Figure 3 (left) values joint actions, u(a), represented points valuespace, two-objective MO-CoG. joint action value CCS
PCS. B, however, PCS, CCS, weight
linear scalarization Bs value would optimal, shown Figure 3 (right),
scalarized value strategies plotted function weight first objective
(w2 = 1 w1 ). C neither CCS PCS: Pareto-dominated A.
Many multi-objective methods, e.g., (Delle Fave et al., 2011; Dubus et al., 2009; Marinescu et al., 2012; Rollon, 2008) simply assume PCS appropriate solution
concept. However, argue choice CS depends one assume
utility defined respect multiple objectives, i.e., scalarization function used scalarize vector-valued payoffs. argue many situations
scalarization function linear, cases one use CCS.
addition shape f , choice solution concept depends whether
deterministic joint actions considered whether stochastic strategies permitted. stochastic strategy assigns probabilityPto joint action [0, 1].
probabilities joint actions together sum 1, aA (a) = 1. value stochastic strategy linear
P combination value vectors joint actions

mixture: u =
aA (a)u(a). Therefore, optimal values, monotonically
increasing f , lie convex upper surface spanned strategies CCS,
indicated lines Figure 3 (left). Therefore, optimal values monotonically
increasing f , including nonlinear ones, constructed taking mixture policies
CCS (Vamplew et al., 2009).
article considers methods computing CCSs, which, show Sections 4
5, computed efficiently PCSs. Furthermore, CCSs typically much
408

fiComputing CCSs Faster Multi-objective Coordination

smaller. particularly important final selection joint done (a
group of) humans, compare possible alternatives solution set.
methods presented article based variable elimination (VE) (Sections
4 5) AND/OR tree search (TS) (Section 6). algorithms exact solution
methods CoGs.
CMOVE algorithm propose Section 5 based VE. differs another
multi-objective algorithm based VE, refer PMOVE (Rollon & Larrosa,
2006), produces CCS rather PCS. alternative messagepassing algorithms, max-plus (Pearl, 1988; Kok & Vlassis, 2006a). However,
guaranteed exact tree-structured CoGs. Multi-objective methods build
max-plus Delle Fave et al. (2011), limitation, unless
preprocess CoG form clique-tree GAI network (Dubus et al., 2009).
tree structured graphs, message-passing algorithms produce optimal solutions
similar runtime guarantees. Note that, PMOVE, existing multi-objective methods
based message passing produce PCS rather CCS.
Section 5, take different approach multi-objective coordination based
outer loop approach. explain, approach applicable computing CCS,
PCS, considerable advantages terms runtime memory usage.

3. Non-graphical Approach
naive way compute CCS ignore graphical structure, calculate set
possible payoffs joint actions V, prune away C-dominated joint actions.
first translate problem set value set factors (VSFs), F. VSF f function
mapping local joint actions sets payoff vectors. initial VSFs constructed
local payoff functions
f e (ae ) = {ue (ae )},
i.e., VSF maps local joint action singleton set containing actions
local payoff. define V terms F using cross-sum operator VSFs
F joint action a:
[M
V(F) =
f e (ae ),
f e F

cross-sum two sets B contains possible vectors made
summing one payoff vector set:
B = {a + b : b B} .
CCS calculated applying pruning operator CPrune (described below)
removes C-dominated vectors set value vectors, V:
[M
CCS(V(F)) = CPrune(V(F)) = CPrune(
f e (ae )).
(1)
f e F

non-graphical CCS algorithm simply computes righthand side Equation 1, i.e.,
computes V(F) explicitly looping actions, action looping
local VSFs, pruning set CCS.
409

fiRoijers, Whiteson, & Oliehoek

CCS contains least one payoff vector maximizes scalarized value every
w:
w



= arg max w u(a)



= a0

u(a0 ) CCS(V(F)) w u(a) = w u(a0 ). (2)

aA

is, every w solution a0 part CCS achieves
value maximizing solution a. Moreover value solutions given
dot product. Thus, finding CCS analogous problem faced partially observable
Markov decision processes (POMDPs) (Feng & Zilberstein, 2004), optimal -vectors
(corresponding value vectors u(a)) beliefs (corresponding weight vectors
w) must found. Therefore, employ pruning operators POMDP literature.
Algorithm 2 describes implementation CPrune, based Feng
Zilberstein (2004) one modification. order improve runtime guarantees, CPrune
first pre-prunes candidate solutions U PCS using PPrune (Algorithm 3) line
1. PPrune computes PCS O(d|U||P CS|) running pairwise comparisons. Next,
partial CCS, U , constructed follows: random vector u U selected line 4.
u algorithm tries find weight vector w u better vectors
U (line 5), solving linear program Algorithm 4. w, CPrune
finds best vector v w U moves U (line 1113). weight
u better C-dominated thus removed u U (line 8).
Algorithm 2: CPrune(U)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Input: set payoff vectors U
U PPrune(U)
U
notEmpty(U)
select random u U
w findWeight(u, U )
w=null
//did find weight u optimal
remove u U
end
else
v arg maxuU w u
U U \ {v}
U U {v}
end
end
return U

runtime CPrune defined Algorithm 2
O(d|U||P CS| + |P CS|P (d|CCS|)),

(3)

P (d|CCS|) polynomial size CCS number objectives d,
runtime linear program tests C-domination (Algorithm 4).
410

fiComputing CCSs Faster Multi-objective Coordination

Algorithm 3: PPrune(U)
1
2
3
4
5
6
7
8
9
10
11
12

Input: set payoff vectors U
U
U 6=
u first element U
foreach v U
v P u
u v // Continue v instead u
end
end
Remove u, vectors P-dominated u, U
Add u U
end
return U

Algorithm 4: findWeight(u, U)
max x
x,w

subject w (u u0 ) x 0, u0 U

X

wi = 1

i=1

x > 0 return w else return null

key downside non-graphical approach requires explicitly enumerating
possible joint actions calculating payoffs associated one. Consequently,
intractable small numbers agents, number joint actions grows
exponentially number agents.
Theorem 3. time complexity computing CCS MO-CoG containing local
payoff functions, following non-graphical approach (Equation 1) is:
O(d|Amax |n + d|Amax |n |P CS| + |P CS|P (d|CCS|)
Proof. First, V computed looping VSFs joint action a, summing
vectors length d. maximum size action space agent Amax
O(|Amax |n ) joint actions. V contains one payoff vector joint action. V input
CPrune.
next two sections, present two approaches compute CCSs efficiently.
first approach pushed CPrune operator Equation 1 cross-sum
union, max-operator pushed summation VE. call
inner loop approach, uses pruning operators agent eliminations,
inner loop algorithm. second approach inspired linear support (Cheng,
411

fiRoijers, Whiteson, & Oliehoek

1988), POMDP pruning operator requires finding optimal solution certain w. Instead performing maximization entire set V, original linear
support algorithm, show use finite number scalarized instances
MO-CoG, avoiding explicit calculation V. call approach outer loop
approach, creates outer loop around single objective method (like VE),
calls subroutine.

4. Convex Variable Elimination MO-CoGs
section show exploit loose couplings calculate CCS using inner loop approach, i.e., pushing pruning operators cross-sum union
operators Equation 1. result CMOVE, extension Rollon Larrosas
Pareto-based extension VE, refer PMOVE (Rollon & Larrosa, 2006).
analyzing CMOVEs complexity terms local convex coverage sets, show
approach yields much better runtime complexity guarantees non-graphical
approach computing CCSs presented Section 3.
4.1 Exploiting Loose Couplings Inner Loop
non-graphical approach, computing CCS expensive computing PCS,
shown Section 3. show that, MO-CoGs, compute CCS
much efficiently exploiting MO-CoGs graphical structure. particular,
VE, solve MO-CoG series local subproblems, eliminating agents
manipulating set VSFs F describe MO-CoG. key idea compute
local CCSs (LCCSs) eliminating agent instead single best response (as VE).
computing LCCS, algorithm prunes away many vectors possible.
minimizes number payoff vectors calculated global level,
greatly reduce computation time. describe elim operator eliminating agents
used CMOVE Section 4.2.
first need update definition neighboring local payoff functions (Definition
2), neighboring VSFs.
Definition 10. set neighboring VSFs set local payoff functions
agent scope.
neighboring agents ni agent agents scope VSF
, except itself, corresponding Definition 3. possible local joint action
ni , compute LCCS contains payoffs C-undominated responses
agent i, best response values i. words, CCS subproblem
arises considering fixing specific local joint action ani . compute
LCCS, must consider payoff vectors subproblem, Vi , prune dominated
ones.
Definition 11. fix actions
ani , ai , set payoff vectors
L
subproblem is: Vi (Fi , ani ) = ai f e f e (ae ), ae formed ai
appropriate part ani .
Using Definition 11, define LCCS CCS Vi .
412

fiComputing CCSs Faster Multi-objective Coordination

Definition 12. local CCS, LCCS, C-undominated subset Vi (Fi , ani ):
LCCSi (Fi , ani ) = CCS(Vi (Fi , ani )).

Using LCCSs, create new VSF, f new , conditioned actions
agents ni :
ani f new (ani ) = LCCS (Fi , ani ).
elim operator replaces VSFs F new factor:
elim(F, i) = (F \ ) {f new (ani )}.
Theorem 4. elim preserves CCS: F CCS(V(F)) = CCS(V(elim(F, i))).
Proof. show using implication Equation 2, i.e., joint actions
w scalarized value maximal, vector-valued payoff
u(a0 ) w u(a0 ) = w u(a0 ) CCS. show maximal scalarized
payoff cannot lost result elim.

function distributes local payoff functions: w u(a) =
P linear scalarization
P
w e ue (ae ) = e w ue (ae ). Thus, eliminating agent i, divide set VSFs
non-neighbors (nn), agent participate, neighbors (ni )
that:
X
X
w u(a) =
w ue (ae ) +
w ue (ae ).
enn

eni

Now, following Equation 2, CCS contains maxaA w u(a) w. elim pushes
maximization in:
max w u(a) = max
aA

ai Ai

X

w ue (ae ) + max

ai Ai

enn

X

w ue (ae ).

eni

elim
agent-i factors term f new (ani ) satisfies w f new (ani ) = maxai
P replaces
e
eni w u (ae ) per definition, thus preserving maximum scalarized value w
thereby preserving CCS.
Instead LCCS, could compute local PCS (LPCS), is, using PCS
computation Vi instead CCS computation. Note that, since LCCS LPCS Vi ,
elim reduces problem size respect Vi , would
possible considered P-dominance. Therefore, focusing CCS greatly
reduce sizes local subproblems. Since solution local subproblem input
next agent elimination, size subsequent local subproblems reduced,
lead considerable speed-ups.
413

fiRoijers, Whiteson, & Oliehoek

4.2 Convex Multi-objective Variable Elimination
present convex multi-objective variable elimination (CMOVE) algorithm,
implements elim using CPrune. VE, CMOVE iteratively eliminates agents none
left. However, implementation elim computes CCS outputs correct
joint actions payoff vector CCS, rather single joint action. CMOVE
extension Rollon Larrosas Pareto-based extension VE, refer
PMOVE (Rollon & Larrosa, 2006).
important difference CMOVE PMOVE CMOVE computes CCS, typically leads much smaller subproblems thus much better
computational efficiency. addition, identify three places pruning take
place, yielding flexible algorithm different trade-offs. Finally, use tagging scheme instead backwards pass, Section 2.2.
Algorithm 5 presents abstract version CMOVE leaves pruning operators
unspecified. Section 3, CMOVE first translates problem set vector-set
factors (VSFs), F line 1. Next, CMOVE iteratively eliminates agents using elim (line
25). elimination order determined using techniques devised single-objective
(Koller & Friedman, 2009).
Algorithm 5: CMOVE(U, prune1, prune2, prune3, q)

1
2
3
4
5
6
7
8

Input: set local payoff functions U elimination order q (a queue containing
agents)
F create one VSF every local payoff function U
ani Ani
q.dequeue()
F elim(F, i, prune1, prune2)
end
f retrieve final factor F
f (a )
return prune3(S)

Algorithm 6 shows implementation elim, parameterized two pruning operators, prune1 prune2, corresponding two different pruning locations inside
operator computes LCCSi : ComputeLCCSi (Fi , ani , prune1, prune2).
Algorithm 6: elim(F, i, prune1, prune2)
1
2
3
4
5
6
7
8

Input: set VSFs F, agent
ni set neighboring agents
subset VSF scope
f new (ani ) new VSF
foreach ani Ani
f new (ani ) ComputeLCCS (Fi , ani , prune1, prune2)
end
F F \ {f new }
return F

414

fiComputing CCSs Faster Multi-objective Coordination

ComputeLCCSi implemented follows: first define new cross-sum-and-prune
= prune1(A B). LCCSi applies operator sequentially:
operator AB
[M

f e (ae )).
(4)
ComputeLCCSi (Fi , ani , prune1, prune2) = prune2(
e
ai

f

operator, leading incremental
prune1 applied cross-sum two sets, via
pruning (Cassandra, Littman, & Zhang, 1997). prune2 applied coarser level,
union. CMOVE applies elim iteratively agents remain, resulting CCS.
Note that, agents left, f new line 3 agents condition on.
case, consider actions neighbors single empty action: .
Pruning applied end, agents eliminated,
call prune3. increasing level coarseness, thus three pruning operators: incremental pruning (prune1), pruning union actions eliminated
agent (prune2), pruning agents eliminated (prune3), reflected
Algorithm 5. agents eliminated, final factor taken set
factors (line 6), single set, contained factor retrieved (line 7). Note
use empty action denote field final factor, agents
scope. Finally prune3 called S.
Consider example Figure 2a, using payoffs defined Table 2, apply
CMOVE. First, CMOVE creates VSFs f 1 f 2 u1 u2 . eliminate agent 3,
creates new VSF f 3 (a2 ) computing LCCSs every a2 tagging element
set action agent 3 generates it. a2 , CMOVE first generates
set {(3, 1)a3 , (1, 3)a3 }. Since vectors optimal w, neither
removed pruning thus f 3 (a2 ) = {(3, 1)a3 , (1, 3)a3 }. a2 , CMOVE first generates
{(0, 0)a3 , (1, 1)a3 }. CPrune determines (0, 0)a3 dominated consequently removes
it, yielding f 3 (a2 ) = {(1, 1)a3 }. CMOVE adds f 3 graph removes f 2
agent 3, yielding factor graph shown Figure 2b.
CMOVE eliminates agent 2 combining f 1 f 3 create f 4 . f 4 (a1 ),
CMOVE must calculate LCCS of:
(f 1 (a1 , a2 ) f 3 (a2 )) (f 1 (a1 , a2 ) f 3 (a2 )).
first cross sum yields {(7, 2)a2 a3 , (5, 4)a2 a3 } second yields {(1, 1)a2 a3 }. Pruning
union yields f 4 (a1 ) = {(7, 2)a2 a3 , (5, 4)a2 a3 }. Similarly, a1 taking union yields
{(4, 3)a2 a3 , (2, 5)a2 a3 , (4, 7)a2 a3 }, LCCS f 4 (a1 ) = {(4, 7)a2 a3 }. Adding f 4
results graph Figure 2c.
Finally, CMOVE eliminates agent 1. Since neighboring agents left, Ai
contains empty action. CMOVE takes union f 4 (a1 ) f 4 (a1 ). Since
(7, 2){a1 a2 a3 } (4, 7){a1 a2 a3 } dominate (5, 4){a1 a2 a3 } , latter pruned, leaving CCS =
{(7, 2){a1 a2 a3 } , (4, 7){a1 a2 a3 } }.
4.3 CMOVE Variants
several ways implement pruning operators lead correct instantiations CMOVE. PPrune (Algorithm 2) CPrune (Algorithm 1) used,
long either prune2 prune3 CPrune. Note prune2 computes CCS, prune3
necessary.
415

fiRoijers, Whiteson, & Oliehoek

article, consider Basic CMOVE, use prune1 prune3
prunes prune2 using CPrune, well Incremental CMOVE, uses CPrune
prune1 prune2. latter invests effort intermediate pruning,
result smaller cross-sums, resulting speedup. However, vectors
pruned intermediate steps, additional speedup may occur,
algorithm creates unnecessary overhead.7 empirically investigate variants
Section 4.5
One could consider using pruning operators contain prior knowledge
range possible weight vectors. information available, could easily
incorporated changing pruning operators accordingly, leading even smaller LCCSs,
thus faster algorithm. article however, focus case
prior knowledge available.
4.4 Analysis
analyze correctness complexity CMOVE.
Theorem 5. MOVE correctly computes CCS.
Proof. proof works induction number agents. base case original
MO-CoG, f e (ae ) F singleton set. Then, since elim preserves CCS
(see Theorem 1), necessary vectors lost. last agent eliminated,
one factor remains; since conditioned agent actions result
LCCS computation, must contain one set: CCS.
Theorem 6. computational complexity CMOVE
O( n |Amax |wa (wf R1 + R2 ) + R3 ),

(5)

wa induced agent width, i.e., maximum number neighboring agents (connected via factors) agent eliminated, wf induced factor width, i.e.,
maximum number neighboring factors agent eliminated, R1 , R2 R3
cost applying prune1, prune2 prune3 operators.
Proof. CMOVE eliminates n agents one computes LCCS joint
action eliminated agents neighbors, field new VSF. CMOVE computes
O(|Amax |wa ) fields per iteration, calling prune1 (Equation 4) adjacent factor,
prune2 taking union actions eliminated agent. prune3 called
exactly once, eliminating agents (line 8 Algorithm 5).
Unlike non-graphical approach, CMOVE exponential wa , number
agents. respect, results similar PMOVE (Rollon, 2008).
However, earlier complexity results make effect pruning explicit. Instead,
complexity bound makes use additional problem constraints, limit total
number possible different value vectors. Specifically, analysis PMOVE,
payoff vectors integer-valued, maximum value objectives. practice,
7. compute PCS first, using prune1 prune2, compute CCS prune3.
However, useful small problems PCS cheaper compute CCS.

416

fiComputing CCSs Faster Multi-objective Coordination

bounds loose even impossible define (e.g., payoff values
real-valued one objectives). Therefore, instead give description
computational complexity makes explicit dependence effectiveness
pruning. Even though complexity bounds better worst case (i.e.,
pruning possible), allow greater insight runtimes algorithms
evaluate, apparent analysis experimental results Section 4.5.
Theorem 6 demonstrates complexity CMOVE depends heavily runtime
pruning operators, turn depends sizes input sets. input
set prune2 union returned series applications prune1,
prune3 uses output last application prune2. therefore need balance
effort lower-level pruning higher-level pruning, occurs less
often dependent output lower level. bigger LCCSs,
gained lower-level pruning.
Theorem 7. space complexity CMOVE
O( n |Amax |wa |LCCSmax | + |Amax ||emax | ),
|LCCSmax | maximum size local CCS, original number VSFs,
|emax | maximum scope size original VSFs.
Proof. CMOVE computes local CCS new VSF joint action eliminated agents neighbors. maximally wa neighbors. maximally n new
factors. payoff vector stores real numbers.
VSFs created initialization CMOVE. VSFs
exactly one payoff vector containing real numbers, per joint action agents scope.
maximally |Amax ||emax | joint actions.
PMOVE, space complexity |P CCSmax | instead |LCCSmax |.
LCCS subset corresponding LPCS, CMOVE thus strictly
memory efficient PMOVE.
Note Theorem 7 rather loose upper bound space complexity,
VSFs, original new, exist time. However, possible predict
priori many VSFs exist time, resulting space complexity
bound basis VSFs exist point execution CMOVE.
4.5 Empirical Evaluation
test efficiency CMOVE, compare runtimes PMOVE8
non-graphical approach problems varying numbers agents objectives.
analyze runtimes correspond sizes PCS CCS.
use two types experiments. first experiments done random MOCoGs directly control variables. second experiment, use
Mining Day, realistic benchmark, structured random MO-CoGs
still randomized.
8. compare PMOVE using prune2 = PPrune, rather prune1 = prune2 = PPrune,
proposed original article (Rollon & Larrosa, 2006) found former option slightly
consistently faster.

417

fiRoijers, Whiteson, & Oliehoek

(a)

(b)

(c)

Figure 4: (a) Runtimes (ms) log-scale nongraphical method, PMOVE CMOVE
standard deviation mean (error bars), (b) corresponding number vectors
PCS CCS, (c) corresponding spread induced width.

4.5.1 Random Graphs
generate random MO-CoGs, employ procedure takes input: n, number
agents; d, number payoff dimensions; number local payoff functions;
|Ai |, action space size agents, agents. procedure
starts fully connected graph local payoff functions connecting two agents
each. Then, local payoff functions randomly removed, ensuring graph
remains connected, local payoff functions remain. values different
objectives local payoff function real numbers drawn independently
uniformly interval [0, 10]. compare algorithms set randomly
generated MO-CoGs separate value n, d, , |Ai |.
compare basic CMOVE, incremental CMOVE, PMOVE, non-graphical
method, test random MO-CoGs number agents ranging
10 85, average number factors per agent held = 1.5n, number
objectives = 2. experiment run 2.4 GHz Intel Core i5 computer, 4 GB
memory. Figure 4 shows results, averaged 20 MO-CoGs number agents.
runtime (Figure 4a) non-graphical method quickly explodes. CMOVE
variants slower PMOVE small numbers agents, runtime grows much
slowly PMOVE. 70 agents, CMOVE variants faster
PMOVE average. 75 agents, one MO-CoGs generated caused PMOVE
time 5000s, basic CMOVE maximum runtime 132s, incremental
CMOVE 136s. explained differences size solutions, i.e.,
PCS CCS (Figure 4b). PCS grows much quickly number
agents CCS does. two-objective problems, incremental CMOVE seems
consistently slower basic CMOVE.
CMOVEs runtime grows much slowly nongraphical method,
still exponential number agents, counterintuitive result since worst-case
complexity linear number agents. explained induced width
MO-CoGs, runtime CMOVE exponential. Figure 4c, see
induced width increases linearly number agents random graphs.
418

fiComputing CCSs Faster Multi-objective Coordination

Figure 5: Runtimes (ms) non-graphical method, PMOVE CMOVE log-scale
standard deviation mean (error bars) (left) corresponding number vectors
PCS CCS (right), increasing numbers agents 5 objectives.

therefore conclude that, two-objective MO-CoGs, non-graphical method
intractable, even small numbers agents, runtime CMOVE increases
much less number agents PMOVE does.
test runtime behavior changes higher number objectives, run
experiment average number factors per agent held = 1.5n
increasing numbers agents again, = 5. remaining experiments
described section executed Xeon L5520 2.26 GHz computer 24 GB
memory. Figure 5 (left) shows results experiment, averaged 85 MO-CoGs
number agents. Note plot induced widths,
change number objectives. results demonstrate that, number
agents grows, using CMOVE becomes key containing computational cost solving
MO-CoG. CMOVE outperforms nongraphical method 12 agents onwards.
25 agents, basic CMOVE 38 times faster. CMOVE significantly better
PMOVE. Though one order magnitude slower 10 agents (238ms (basic)
416ms (incremental) versus 33ms average), runtime grows much slowly
PMOVE. 20 agents, CMOVE variants faster PMOVE
28 agents, Basic CMOVE almost one order magnitude faster (228s versus 1, 650s
average), difference increases every agent.
before, runtime CMOVE exponential induced width, increases
number agents, 3.1 n = 10 6.0 n = 30 average, result
random MO-CoG generation procedure. However, CMOVEs runtime polynomial
size CCS, size grows exponentially, shown Figure 5 (right).
fact CMOVE much faster PMOVE explained sizes PCS
CCS, former grows much faster latter. 10 agents, average PCS
size 230 average CCS size 65. 30 agents, average PCS size risen
51, 745 average CCS size 1, 575.
Figure 6 (left) compares scalability algorithms number objectives,
random MO-CoGs n = 20 = 30, averaged 100 MO-CoGs. CMOVE
always outperforms nongraphical method. Interestingly, nongraphical method
419

fiRoijers, Whiteson, & Oliehoek

Figure 6: Runtimes (ms) non-graphical method, PMOVE CMOVE logscale
standard deviation mean (error bars) (left) corresponding number vectors
PCS CCS (right), increasing numbers objectives.

several orders magnitude slower = 2, grows slowly = 5, starts
grow exponent PMOVE. explained fact
time takes enumerate joint actions payoffs remains approximately constant,
time takes prune increases exponentially number objectives.
= 2, CMOVE order magnitude slower PMOVE (163ms (basic)
377 (incremental) versus 30ms). However, = 5, CMOVE variants already
faster PMOVE 8 dimensions respectively 3.2 2.4 times faster.
happens CCS grows much slowly PCS, shown Figure
6 (right). difference incremental basic CMOVE decreases number
dimensions increases, factor 2.3 = 2 1.3 = 8. trend indicates
pruning every cross-sum, i.e., prune1, becomes (relatively) better higher
numbers objectives. Although unable solve problem instances many
objectives within reasonable time, expect trend continue incremental
CMOVE would faster basic CMOVE problems many objectives.
Overall, conclude that, random graphs, CMOVE key solving MO-CoGs
within reasonable time, especially problem size increases either number
agents, number objectives, both.
4.5.2 Mining Day
Mining Day, mining company mines gold silver (objectives) set mines
(local payoff functions) located mountains (see Figure 1). mine workers live
villages foot mountains. company one van village (agents)
transporting workers must determine every morning mine van
go (actions). However, vans travel nearby mines (graph connectivity). Workers
efficient workers mine: 3% efficiency bonus per
worker amount resource mined per worker x 1.03w , x
base rate per worker w number workers mine. base rate
gold silver properties mine. Since company aims maximize revenue,
best strategy depends fluctuating prices gold silver. maximize revenue,
420

fiComputing CCSs Faster Multi-objective Coordination

Figure 7: Runtimes (ms) basic incremental CMOVE, PMOVE, log-scale
standard deviation mean (error bars) (left) corresponding number vectors
PCS CCS (right), increasing numbers agents.

mining company wants use latest possible price information, lose time
recomputing optimal strategy every price change. Therefore, must calculate
CCS.
generate Mining Day instance v villages (agents), randomly assign 2-5
workers village connect 2-4 mines. village connected mines
greater equal index, i.e., village connected mines, connected
mines + 1. last village connected 4 mines thus number mines
v + 3. base rates per worker resource mine drawn uniformly
independently interval [0, 10].
order compare runtimes basic incremental CMOVE PMOVE
realistic benchmark, generate Mining Day instances varying numbers
agents. Note include non-graphical method, runtime mainly
depends number agents, thus considerably faster problem
random graphs. runtime results shown Figure 7 (left). CMOVE
PMOVE able tackle problems 100 agents. However, runtime
PMOVE grows much quickly CMOVE. two-objective setting,
basic CMOVE better incremental CMOVE. Basic CMOVE PMOVE
runtimes around 2.8s 60 agents, 100 agents, basic CMOVE runs 5.9s
PMOVE 21s. Even though incremental CMOVE worse basic CMOVE,
runtime still grows much slowly PMOVE, beats PMOVE
many agents.
difference PMOVE CMOVE results relationship
number agents sizes CCS, grows linearly, PCS, grows
polynomially, shown Figure 7 (right). induced width remains around 4 regardless
number agents. results demonstrate that, CCS grows slowly
PCS number agents, CMOVE solve MO-CoGs efficiently
PMOVE number agents increases.
421

fiRoijers, Whiteson, & Oliehoek

5. Linear Support MO-CoGs
section, present variable elimination linear support (VELS). VELS new
method computing CCS MO-CoGs several advantages CMOVE:
moderate numbers objectives, runtime complexity better; anytime
algorithm, i.e., time, VELS produces intermediate results become better
better approximations CCS therefore, provided maximum scalarized
error , VELS compute -optimal CCS.
Rather dealing multiple objectives inner loop (like CMOVE), VELS
deals outer loop employs subroutine. VELS thus builds
CCS incrementally. iteration outer loop, VELS adds one new
vector partial CCS. find vector, VELS selects single w (the one offers
maximal possible improvement), passes w inner loop. inner loop,
VELS uses (Section 2.2) solve single-objective coordination graph (CoG)
results scalarizing MO-CoG using w selected outer loop. joint
action optimal CoG multi-objective payoff added
partial CCS.
departure point creating VELS Chengs linear support (Cheng, 1988). Chengs
linear support originally designed pruning algorithm POMDPs. Unfortunately,
algorithm rarely used POMDPs practice, runtime exponential
number states. However, number states POMDP corresponds number
objectives MO-CoG, realistic POMDPs typically many states, many
MO-CoGs handful objectives. Therefore, MO-CoGs, scalability
number agents important, making Chengs linear support attractive starting
point developing efficient MO-CoG solution method.
Building Chengs linear support, Section 5.1 create abstract algorithm
call optimistic linear support (OLS), builds CCS incrementally.
OLS takes arbitrary single-objective problem solver input, seen generic
multi-objective method. show OLS chooses w iteration that,
finite number iterations, improvements partial CCS made
OLS terminate. Furthermore, bound maximum scalarized error
intermediate results, used bounded approximations CCS.
Then, Section 5.2, instantiate OLS using single-objective problem solver,
yielding VELS, effective MO-CoG algorithm.
5.1 Optimistic Linear Support
OLS constructs CCS incrementally, adding vectors initially empty partial CCS :
Definition 13. partial CCS, S, subset CCS, turn subset V:
CCS V.
define scalarized value function S, corresponding convex upper surface
(shown bold) Figure 8b-d:
Definition 14. scalarized value function partial CCS, S, function takes
weight vector w input, returns maximal attainable scalarized value
422

fiComputing CCSs Faster Multi-objective Coordination

(a)

(b)

(c)

(d)

Figure 8: (a) possible payoff vectors 2-objective MO-CoG. (b) OLS finds two payoff
vectors extrema (red vertical lines), new corner weight wc = (0.5, 0.5)
found, maximal possible improvement . CCS shown dotted line.
(c) OLS finds new vector (0.5, 0.5), adds two new corner weights Q.
(d) OLS calls SolveCoG corner weights (in two iterations), finds
new vectors, ensuring = CCS = CCS.
payoff vector S:
uS (w) = max w u(a).
u(a)S

Similarly, define set maximizing joint actions:
Definition 15. optimal joint action set function respect function
gives joint actions maximize scalarized value:
(w) = arg max w u(a).
u(a)S

Note (w) set w multiple joint actions provide
scalarized value.
Using definitions, describe optimistic linear support (OLS). OLS adds
vectors partial CCS, S, finding new vectors so-called corner weights. corner
weights weights uS (w) (Definition 14) changes slope directions.
must thus weights (w) (Definition 15) consists multiple payoff vectors. Every
corner weight prioritized maximal possible improvement finding new payoff
vector corner weight. maximal possible improvement 0, OLS knows
partial CCS complete. example process given Figure 8,
(corner) weights algorithm searched new payoff vectors indicated
red vertical lines.
OLS shown Algorithm 7. find optimal payoff corner weight, OLS
assumes access function called SolveCoG computes best payoff vector
given w. now, leave implementation SolveCoG abstract. Section 5.2,
discuss implement SolveCoG. OLS takes input m, MO-CoG solved,
, maximal tolerable error result.
first describe OLS initialized (Section 5.1.1). Then, define corner weights
formally describe OLS identifies (Section 5.1.2). Finally, describe
423

fiRoijers, Whiteson, & Oliehoek

Algorithm 7: OLS(m, SolveCoG, )
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24

Input:
CoGGCCS,
agent eliminate.

//partial
W //set checked weights
Q empty priority queue
foreach extremum weight simplex
Q.add(we , ) // add extrema infinite priority
end
Q.isEmpty() timeOut
w Q.pop()
u SolveCoG(m, w)
u 6
Wdel remove corner weights made obsolete u Q, store
Wdel {w} Wdel //corner weights removed adding u
Wu newCornerWeights(u, Wdel , S)
{u}
foreach w Wu
r (w) calculate improvement using maxValueLP(w, S, W)
r (w) >
Q.add(w, r (w))
end
end
end
W W {w}
end
return highest r (w) left Q

OLS prioritizes corner weights used bound error
stopping OLS done finding full CCS (Section 5.1.3).
5.1.1 Initialization
OLS starts initializing partial CCS, S, contain payoff vectors
CCS discovered far (line 1 Algorithm 7), well set visited weights W (line
2). Then, adds extrema weight simplex, i.e., points
weight one objective, priority queue Q, infinite priority (line 5).
extrema popped priority queue OLS enters main loop (line
7), w highest priority selected (line 8). SolveCoG called
w (line 9) find u, best payoff vector w.
example, Figure 8b shows two payoff vectors 2-dimensional MOCoG found applying SolveCoG extrema weight simplex: =
{(1, 8), (7, 2)}. vectors must part CCS optimal
least one w: one SolveCoG returned solution (the extrema
weight simplex). set weights W OLS tested far marked vertical
red line segments.
424

fiComputing CCSs Faster Multi-objective Coordination

5.1.2 Corner Weights
evaluated extrema, consists (the number objectives) payoff vectors
associated joint actions. However, many weights simplex, yet
contain optimal payoff vector. Therefore, identifying new vector u add
(line 9), OLS must determine new weights add Q. Chengs linear support,
OLS identifying corner weights: weights corners convex
upper surface, i.e., points PWLC surface uS (w) changes slope. define
corner weights precisely, must first define P , polyhedral subspace weight
simplex uS (w) (Bertsimas & Tsitsiklis, 1997). corner weights
vertices P, defined set linear inequalities:
Definition 16. set known payoff vectors, define polyhedron
X
P = {x <d+1 : + x ~0, i, wi > 0,
wi = 1},


+ matrix elements row vectors, augmented column vector
1s. setPof linear inequalities + x ~0, supplemented simplex constraints:
wi > 0 wi = 1. vector x = (w1 , ..., wd , u) consists weight vector
scalarized value weights. corner weights weights contained
vertices P , form (w1 , ..., wd , u).
Note that, due simplex constraints, P d-dimensional. Furthermore,
extrema weight simplex special cases corner weights.
identifying u, OLS identifies corner weights change polyhedron P
adding u S. Fortunately, require recomputation corner weights,
done incrementally: first, corner weights Q u yields better
value currently known deleted queue (line 11) function
newCornerWeights(u, Wdel , S) line 13 calculates new corner weights involve u
solving system linear equations see u intersects boundaries
relevant subset present vectors S.
newCornerWeights(u, Wdel , S) (line 13) first calculates set relevant payoff
vectors, Arel , taking union maximizing vectors weights Wdel 9 :
Arel =

[

(w).

wWdel

(w) contains fewer payoff vectors, boundary weight simplex
involved. boundaries stored. possible subsets size 1 (of vectors
boundaries) taken. subset weight 1 payoff vectors
(and/or boundaries) intersect u computed solving system
linear equations. intersection weights subsets together form set candidate
corner weights: Wcan . newCornerWeights(u, Wdel , S) returns subset Wcan
inside weight simplex u higher scalarized value payoff
9. fact, implementation, optimize step caching (w) w Q.

425

fiRoijers, Whiteson, & Oliehoek

vector already S. Figure 8b shows one new corner weight labelled wc = (0.5, 0.5).
practice, |Arel | small, systems linear equations need solved.10
calculating new corner weights Wu line 13, u added line 14.
Cheng showed finding best payoff vector corner weight adding
partial CCS, i.e., {SolveCoG(w)}, guarantees best improvement S:
Theorem 8. (Cheng 1988) maximum value of:
max

min w u w v,

w,uCCS vS

i.e., maximal improvement adding vector it, one corner weights
(Cheng, 1988).
Theorem 8 guarantees correctness OLS: corner weights checked,
new payoff vectors; thus maximal improvement must 0 OLS found
full CCS.
5.1.3 Prioritization
Chengs linear support assumes corner weights checked inexpensively,
reasonable assumption POMDP setting. However, since SolveCoG expensive
operation, testing corner weights may feasible MO-CoGs. Therefore, unlike
Chengs linear support, OLS pops one w Q tested per iteration. Making
OLS efficient thus critically depends giving w suitable priority adding
Q. end, OLS prioritizes corner weight w according maximal possible
improvement, upper bound improvement uS (w). upper bound computed
respect CCS, optimistic hypothetical CCS, i.e., best-case scenario
final CCS given current partial CCS W set weights already
tested SolveCoG. key advantage OLS Chengs linear support
priorities computed without calling SolveCoG, obviating need run SolveCoG
corner weights.
Definition 17. optimistic hypothetical CCS, CCS set payoff vectors yields
highest possible scalarized value possible w consistent finding vectors
weights W.
Figure 8b denotes CCS = {(1, 8), (7, 2), (7, 8)} dotted line. Note CCS
superset value uCCS (w) uS (w) weights W.

given w, maxValueLP finds scalarized value uCCS
(w) solving:
max w v
subject W v uS,W ,
10. However, theory possible construct partial CCS, corner weight
payoff vectors Adel .

426

fiComputing CCSs Faster Multi-objective Coordination

uS,W vector containing uS (w0 ) w0 W. Note abuse notation
W, case matrix whose rows consist weight vectors set
W.11
Using CCS, define maximal possible improvement:
(w) = uCCS (w) uS (w).
Figure 8b shows (wc ) dashed line. use maximal relative possible improvement, r (w) = (w)/uCCS (w), priority new corner weight w Wu .

Figure 8b, r (wc )= (0.5,0.5)((7,8)(1,8))
= 0.4. corner weight w identified (line 13),
7.5
added Q priority r (w) long r (w) > (lines 16-18).
wc Figure 8b added Q, popped (as element
Q). SolveCoG(wc ) generates new vector (5, 6), yielding = {(1, 8), (7, 2), (5, 6)},
illustrated Figure 8c. new corner weights (0.667, 0.333) (0.333, 0.667)
points (5, 6) intersects (7, 2) (1, 8). Testing weights, illustrated
Figure 8d, result new payoff vectors, causing OLS terminate. maximal
improvement corner weights 0 thus, due Theorem 8, = CCS upon
termination. OLS called solveCoG 5 weights resulting exactly 3 payoff
vectors CCS. 7 payoff vectors V (displayed grey dashed black
lines Figure 8a) never generated.
5.2 Variable Elimination Linear Support
exact CoG algorithm used implement SolveCoG. naive approach
explicitly compute values joint actions V select joint action maximizes
value:
SolveCoG(m, w) = arg max w u(a).
u(a)V

implementation SolveCoG combination OLS yields algorithm
refer non-graphical linear support (NGLS), ignores graphical structure,
flattening CoG standard multi-objective cooperative normal form game.
main downside computational complexity SolveCoG linear |V| (which
equal |A|), exponential number agents, making feasible
MO-CoGs agents.
contrast, use (Section 2.2) implement SolveCoG, better.
call resulting algorithm variable elimination linear support (VELS). dealt
multiple objectives outer loop OLS, VELS relies exploit graphical
structure inner loop, yielding much efficient method NGLS.
5.3 Analysis
analyze computational complexity VELS.
11. implementation OLS reduces size LP using subset weights W
joint actions involved w, (w), found optimal. lead slight

overestimation uCCS
(w).

427

fiRoijers, Whiteson, & Oliehoek

Theorem 9. runtime VELS = 0
O((|CCS| + |WCCS |)(n|Amax |w + Cnw + Cheur )),
w induced width running VE, |CCS| size CCS, |WCCS |
number corner weights uCCS (w), Cnw time costs run newCornerWeights,
Cheur cost computation value optimistic CCS using maxValueLP.
Proof. Since n|Amax |w runtime (Theorem 1), runtime VELS
quantity (plus overhead per corner weight Cnw + Cheur ) multiplied number
calls VE. count calls, consider two cases: calls result adding
new vector result new vector instead confirm
optimality scalarized value weight. former size final CCS,
|CCS|, latter number corner weights final CCS, |WCCS |.
overhead OLS itself, i.e., computing new corner weights, Cnw , calculating
maximal relative improvement, Cheur , small compared SolveCoG calls.
practice, newCornerWeights(u, Wdel , S) computes solutions small set
linear equations (of equations each). maxValueLP(w, S, W) computes solutions
linear programs, polynomial size inputs.12
= 2, number corner weights smaller |CCS| runtime
VELS thus O(n|Amax |w |CCS|). = 3, number corner weights twice |CCS|
(minus constant) because, SolveCoG finds new payoff vector, one corner weight
removed three new corner weights added. > 3, loose bound |WCCS |

total number possible combinations payoff vectors boundaries: O( |CCS|+d
).

However, obtain tighter bound observing counting number corner
weights given CCS equivalent vertex enumeration, dual problem
facet enumeration, i.e., counting number vertices given corner weights (Kaibel &
Pfetsch, 2003).
Theorem 10. arbitrary d, |WCCS | bounded O(
(Avis & Devroye, 2000).

|CCS|b d+1
c
2
|CCS|d

+

|CCS|b d+2
c
2
)
|CCS|d

Proof. result follows directly McMullens upper bound theorem facet enumeration (Henk, Richter-Gebert, & Ziegler, 1997; McMullen, 1970).
reasoning used prove Theorems 9 used establish following:
Corollary 1. runtime VELS 0
O((|-CCS| + |WCCS |)(n|Amax |w + Cnw + Cheur ), |-CCS| size -CCS,
|WCCS | number corner weights uCCS (w).
practice, VELS often test corner weights polyhedron spanned
-CCS, cannot guaranteed general. Section 5.4, show empirically
|-CCS| decreases rapidly increases.
12. reduction Footnote 11 used, small subset W used, making even smaller.

428

fiComputing CCSs Faster Multi-objective Coordination

Figure 9: (left) runtimes PMOVE, CMOVE VELS different values ,
varying numbers agents, n, = 1.5n factors, 2 actions per agent,
2 objectives (right) corresponding sizes -CCSs.
Theorem 11. space complexity VELS O(d|-CCS|+d|WCCS |+n|Amax |w )
0.
Proof. OLS needs store every corner weight (a vector length d) queue,
|WCCS |. OLS needs store every vector (also vectors length d).
Furthermore, SolveCoG called, memory usage added memory
usage outer loop OLS. memory usage n|Amax |w (Theorem 2).
OLS adds memory requirements VE, VELS almost memory
efficient thus considerably memory efficient CMOVE (Theorem 7).
5.4 Empirical Evaluation
empirically evaluate VELS, comparison CMOVE PMOVE. longer
compare non-graphical method clearly dominated CMOVE
PMOVE. refer CMOVE section, mean basic CMOVE,
fastest tested scenarios. before, use random graphs Mining Day
benchmark. experiments section run 2.4 GHx Intel Core i5 computer,
4 GB memory.
5.4.1 Random Graphs
test VELS randomly generated MO-CoGs, use MO-CoG generation
procedure Section 4. determine scalability exact approximate
VELS compares PMOVE CMOVE, tested random MO-CoGs
increasing numbers agents. average number factors per agent held
= 1.5n number objectives = 2. Figure 9 shows results,
averaged 30 MO-CoGs number agents. Note runtimes left,
y-axis, log-scale set sizes right not.
results demonstrate VELS efficient CMOVE two-objective
random MO-CoGs. runtime exact VELS ( = 0) average 16 times less
429

fiRoijers, Whiteson, & Oliehoek

CMOVE. CMOVE solves random MO-CoGs 85 agents 74s average, whilst
exact VELS handle 110 agents 71s.
already large gain, achieve even lower growth rate permitting
small . 110 agents, permitting 0.001 error margin yields gain
order magnitude, reducing runtime 5.7s. Permitting 0.01 error reduces
runtime 1.3s. thus reduce runtime VELS factor 57,
retaining 99% accuracy. Compared CMOVE 85 agents, VELS = 0.01 109
times faster.
speedups explained slower growth -CCS (Figure 9 (right)).
small numbers agents, size -CCS grows slightly slowly
size full CCS. However, certain number agents onwards, size
-CCS grows marginally size full CCS keeps growing. = 0.01,
-CCS grew 2.95 payoff vectors 5.45 payoff vectors 5 20 agents,
marginally 5.50 110 agents. contrast, full CCS grew 3.00
9.90 vectors 5 20 agents, keeps growing 44.50 110 agents.
similar picture holds 0.001-CCS, grows rapidly 3.00 vectors 5
14.75 vectors 50 agents, grows slowly 16.00 90 agents, stabilizes,
reach 16.30 vectors 120 agents. 90 120 agents, full CCS grows
35.07 vectors 45.40 vectors, making almost 3 times large 0.001-CCS 9
times larger 0.01-CCS .
test scalability VELS respect number objectives, tested
random MO-CoGs constant number agents factors n = 25 = 1.5n,
increased number objectives, = 0 = 0.1. compare
scalability CMOVE. kept number agents (n = 25) number local
payoff functions ( = 37) small order test limits scalability number
objectives. number actions per agent 2. Figure 10 (left) plots number
objectives runtime (in log scale). CCS grows exponentially
number objectives (Figure 10 (right)), runtime CMOVE exponential
number objectives. VELS however linear number corner weights,
exponential size CCS, making VELS doubly exponential. Exact VELS ( = 0)
faster CMOVE = 2 = 3, = 4 approximate VELS = 0.1
20 times faster. However = 5 even approximate VELS = 0.1
slower CMOVE.
Unlike number agents grows, size -CCS (Figure 10 (right))
stabilize number objectives grows, seen following table:
|CCS|
d=2
d=3
d=4

=0
10.6
68.8
295.1

= 0.001
7.3
64.6
286.1

= 0.01
5.6
41.0
242.6

= 0.1
3.0
34.8
221.7

therefore conclude VELS compute CCS faster CMOVE 3 objectives
less, CMOVE scales better number objectives. VELS however, scales
better number agents.
430

fiComputing CCSs Faster Multi-objective Coordination

Figure 10: (left) runtimes CMOVE VELS ( = 0 = 0.1), varying numbers objectives (right) size -CCS varying numbers objectives.

Figure 11: (left) plot runtimes CMOVE VELS different values ,
varying n (up 500). (right) loglogplot runtime VELS 250, 500,
1000 agent mining day instances, varying values .
5.4.2 Mining Day
compare CMOVE VELS Mining Day benchmark using generation procedure Section 4.5.2. generated 30 Mining Day instances increasing n
averaged runtimes (Figure 11 (left)). 160 agents, CMOVE reached runtime
22s. Exact VELS ( = 0) compute complete CCS MO-CoG 420 agents
time. indicates VELS greatly outperforms CMOVE structured
2-objective MO-CoG. Moreover, allow 0.1% error ( = 0.001), takes
1.1s compute -CCS 420 agents, speedup order magnitude.
measure additional speedups obtainable increasing , test VELS
large problems, generated Mining Day instances n {250, 500, 1000}.
averaged 25 instances per value . instances, exact VELS runs 4.2s
n = 250, 30s n = 500 218s n = 1000 average. expected, increasing
leads greater speedups (Figure 11 (right)). However, close 0, i.e.,
431

fiRoijers, Whiteson, & Oliehoek

-CCS close full CCS, speedup small. increased beyond certain
value (dependent n), decline becomes steady, shown line log-log plot.
increases factor 10, runtime decreases factor 1.6.
Thus, results show VELS compute exact CCS unprecedented
numbers agents (1000) well-structured problems. addition, show small
values enable large speedups, increasing leads even bigger improvements
scalability.

6. Memory-Efficient Methods
CMOVE VELS designed minimize runtime required compute CCS.
However, cases, bottleneck may memory instead. Memory-efficient methods
CoGs related problems recently received considerable attention (Dechter &
Mateescu, 2007; Marinescu, 2008, 2009; Mateescu & Dechter, 2005). section,
show that, outer loop method, VELS naturally memory efficient
therefore solve much larger MO-CoGs inner loop method CMOVE
memory restricted. addition, show CMOVE VELS modified
produce even memory-efficient variants.
6.1 And/Or Tree Search
begin background AND/OR tree search (Dechter & Mateescu, 2007;
Marinescu, 2008; Mateescu & Dechter, 2005; Yeoh, Felner, & Koenig, 2010), class
algorithms solving single-objective CoGs tuned provide better space
complexity guarantees VE. However, improvement space complexity comes
price, i.e., runtime complexity worse (Mateescu & Dechter, 2005). background
provide brief; broader overview AND/OR tree search CoGs related
models please see work Dechter (2013) Marinescu (2008), multi-objective
versions work Marinescu (2009, 2011).
AND/OR tree search algorithms work converting graph pseudo tree (PT)
agent need know actions ancestors descendants PT
take order select action. example, agent (a node) PT two
subtrees (T1 T2 ) it, agents T1 conditionally independent
agents T2 given ancestors i. Figure 12a shows PT coordination
graph Figure 2a.
Next, AND/OR tree search algorithms perform tree search results AND/OR
search tree (AOST). agent AOST OR-node. children AND-nodes,
corresponding one agent actions. turn, children AND-nodes
OR-nodes corresponding agent children PT. action (AND-nodes)
agent agents OR-nodes, agents actions appear
tree multiple times. Figure 12b shows AOST graph Figure 2a.
specific joint action constructed traversing tree, starting root
selecting one alternative childen OR-node, i.e., one action agent,
continuing children AND-node. example, Figure 12b, joint
action < a1 , a2 , a3 > indicated grey. retrieve value joint action, must
first define value AND-nodes.
432

fiComputing CCSs Faster Multi-objective Coordination

Figure 12: (a) pseudo tree, (b) corresponding AND/OR search tree.
Definition 18. value AND-node vai , representing action ai agent
sum local payoff functions scope; ai , together AND-node
ancestors actions, specifies action agent scope local payoff functions.
example, Figure 12b, total payoff CoG u(a1 , a2 , a3 ) = u1 (a1 , a2 ) +
u2 (a2 , a3 ). value grey AND-node a3 u2 (a2 , a3 ), u3 payoff function
agent 3 scope and, together ancestral AND-nodes, grey a2 -node, a3
completes joint local action u2 .
retrieve optimal action, must define value subtree AOST:
Definition 19. value subtree v(Ti ) rooted OR-node AOST
maximum value subtrees rooted (AND-node) children i. value
subtree v(Tai ) rooted AND-node ai AOST value ai (Definition
18) plus sum value subtrees rooted (OR-node) children ai .
memory-efficient way retrieve optimal joint action using AOST
Euler-touring it, i.e., performing depth-first search computing values
subtrees. generating nodes fly deleting evaluated, memory
usage minimized. refer algorithm simply AND/OR tree search (TS).
earlier sections, implementation employs tagging scheme, tagging value
subtree actions maximize it.
TS single-objective method, extended compute PCS,
yielding algorithm call Pareto TS (PTS) (Marinescu, 2009). define PTS, must
update Definition 19 set Pareto-optimal payoffs. refer subtree value
set intermediate PCS (IPCS).
Definition 20. intermediate PCS subtree, IP CS(Ti ) rooted OR-node
PCS union intermediate PCSs children, ch(i), i:
IP CS(Ti ) = PPrune(

[

aj ch(i)

433

IP CS(Taj )).

fiRoijers, Whiteson, & Oliehoek

intermediate PCS subtree, IP CS(Tai ) rooted AND-node ai PCS
value ai (Definition 18) plus cross-sum intermediate PCSs subtrees
rooted (OR-node) children ai :



IP CS(Tj ) {vai }).
IP CS(Tai ) = PPrune(
jch(ai )

Thus, PTS replaces max operator TS pruning operator, PMOVE replaces
max operator pruning operator.
6.2 Memory-Efficient CCS Algorithms
propose two memory-efficient algorithms computing CCS. straightforward variants CMOVE VELS.
first algorithm, call Convex TS (CTS), simply replaces PPrune CPrune
Definition 20. Thus, CTS PTS different pruning operator.
seen CMOVE replaced TS. advantage CTS PTS
analogous CMOVE PMOVE: highly beneficial compute local
CCSs instead local PCSs intermediate coverage sets input next
subproblem sequential search scheme, regardless whether scheme TS.
CTS memory efficient CMOVE, still requires computing intermediate
coverage sets take space. typically large CCS,
size bounded total number joint actions.
second algorithm addresses problem employing OLS TS singleobjective solver subroutine, SolveCoG, yielding tree search linear support (TSLS). Thus,
TSLS VELS replaced TS. TSLS outer-loop method,
runs TS sequence, requiring memory used TS overhead
outer loop, consists partial CCS (Definition 13) priority queue.
Consequently, TSLS even memory efficient CTS.
6.3 Analysis
TS much better space complexity VE, i.e., linear number agents n:
Theorem 12. time complexity TS O(n|Amax |m ), n number agents,
|Amax | maximal number actions single agent depth pseudo
tree, uses linear space, O(n).
Proof. number nodes AOST bounded O(n|Amax |m ). tree creates
maximally |Amax | children OR-node. every AND-node exactly one child,
number nodes would bounded O(|Amax |m ), PT deep. However,
branching PT, AND-node multiple children. branch increases
size AOST O(|Amax |m ) nodes. exactly n agents
PT, happen n times. node AOST, TS performs either
summation scalars, maximization scalars. TS performs depth-first
search, O(n) nodes need exist point execution.
434

fiComputing CCSs Faster Multi-objective Coordination

TSs memory usage usually lower required store original (singleobjective) problem memory: O(|Amax |emax ), number local payoff
functions problem, |Amax | maximal size action space single agent,
emax maximal size scope single local payoff function.
PT-depth different constant induced width w, typically
larger. However, bounded w.
Theorem 13. Given MO-CoG induced width w, exists pseudo tree
depth w log n (Dechter & Mateescu, 2007).
Thus, combining Theorems 12 13 shows that, agents, TS
much memory efficient relatively small runtime penalty.
Using time space complexity results TS, establish following
corollaries time space complexity CTS TSLS.
Corollary 2. time complexity CTS O(n|Amax |m R), R runtime
CPrune.
Proof. O(n|Amax |m ) bounds number nodes AOST. node AOST
CPrune called.
runtime CPrune terms size input given Equation 3. Note
size input CPrune depends size intermediate CCSs
children node. case AND-node, input size O(|ICCSmax |c ),
c maximum number children AND-node.13 OR-nodes
O(|Amax ||ICCSmax |).
Corollary 3. space complexity CTS O(n|ICCSmax |), |ICCSmax |
maximum size intermediate CCS execution CTS.
Proof. TS, O(n) nodes AOST need exist point
execution, node contains intermediate CCS.
CTS thus much memory efficient CMOVE, space complexity
exponential induced width (Theorem 7).
Corollary 4. time complexity TSLS O((|-CCS|+|W -CCS |) (n |Amax |m +Cnw +
Cheur )), w log n 0.
Proof. proof Theorem 9 time complexity
replaced TS.
terms memory usage, outer loop approach (OLS) large advantage
inner loop approach, overhead outer loop consists partial
CCS (Definition 13) priority queue. VELS (Theorem 11) thus much better
space complexity CMOVE (Theorem 7). TSLS advantage CTS
VELS CMOVE. Therefore, TSLS low memory usage, since requires
memory used TS plus overhead outer loop.
13. Note c turn upper bounded n loose bound.

435

fiRoijers, Whiteson, & Oliehoek

Corollary 5. space complexity TSLS O(d|-CCS| + d|W -CCS | + n)),
w log n 0.
Proof. proof Theorem 11 space complexity
replaced TS.
mentioned Section 6.1, TS memory-efficient member class
AND/OR tree search algorithms. members class offer different trade-offs
time space complexity. possible create inner loop algorithms
corresponding outer loop algorithms basis algorithms. time
space complexity analyses algorithms performed similar manner
Corollaries 25. advantages outer loop methods compared corresponding
inner loop methods however remain TSLS CTS. Therefore,
article focus comparing memory-efficient inner loop method
memory-efficient outer loop method.
6.4 Empirical Evaluation
section, compare CTS TSLS CMOVE VELS. before, use
random graphs Mining Day benchmark. obtain PTs CTS TSLS,
use heuristic CMOVE VELS generate elimination order
transform PT w log n holds (whose existence guaranteed
Theorem 13), using procedure suggested Bayardo Miranker (1995).
6.4.1 Random Graphs
First, test algorithms random graphs, employing generation procedure
Section 4.5.1. connections agents graphs generated
randomly, induced width varies different problems. average, induced
width increases number local payoff functions, even ratio
local payoff factors number agents remains constant.
order test sizes problems different MO-CoG solution methods
handle within limited memory, generate random graphs two objectives, varying
number agents n, = 1.5n local payoff functions, previous sections.
limited maximal available memory 1kB imposed timeout 1800s.
Figure 13a shows VELS scale agents within given memory constraints non-memory efficient methods. particular, PMOVE CMOVE
handle 30 40 agents, respectively, because, given induced width w,
must store O(|Amax |w ) local CSs. 30 agents, induced width (Figure 13c)
6, 40 agents induced width 8. VELS handle 65 agents,
induced width 11, memory demands come running
inner loop, outer loop adds little overhead. need store one payoff
new local payoff function results agent elimination, whereas PMOVE
CMOVE must store local coverage sets. Thus, using outer loop approach (VELS)
instead inner loop approach (CMOVE) already yields significant improvement
problem sizes tackled limited memory.
436

fiComputing CCSs Faster Multi-objective Coordination

(a)

(b)

(c)

Figure 13: (a) Runtimes ms TSLS, VELS, CTS, CMOVE PMOVE random 2objective MO-CoGs varying numbers agents n = 1.5n local payoff
factors. (b) Runtimes approximate TSLS varying amounts allowed error
, compared (Exact) VELS, problem parameters (a). (c)
corresponding induced widths MO-CoGs (b).

However, scaling beyond 65 agents requires memory-efficient approach. Figure 13a
shows that, CTS TSLS require runtime, handle agents
within memory constraints. fact, unable generate MO-CoG enough
agents cause methods run memory. TSLS faster CTS, case
4.2 times faster, reasons VELS faster CMOVE.
However, speed advantage outer loop approach. allow
bit error scalarized value, , trade accuracy runtime (Figure 13b). 65
agents, exact TSLS ( = 0), average runtime 106s, 51 times slower
VELS. However, = 0.0001, runtime 70s (33 times slower). = 0.01
11s (5.4 times slower), = 0.1 6s (2.9 times slower). Furthermore,
relative increase runtime number agents increases less higher . Thus,
approximate version TSLS highly attractive method cases memory
runtime limited.
6.4.2 Mining Field
compare performance CMOVE VELS TSLS variation Mining
Day call Mining Field. longer consider CLS consistently higher
runtime TSLS worse space complexity. use Mining Field order ensure
interesting problem memory-restricted setting. Mining Day (see Section 4),
induced width depends parameter specifying connectivity villages
increase number agents factors. Therefore, whether
VELS memory-efficient enough handle particular instance depends primarily
parameter number agents.
Mining Field, villages situated along mountain ridge placed
grid. number agents thus n = s2 . use random placement mines,
ensuring graph connected. induced width connected grid
generate grid-like graphs, larger instances higher induced width.
437

fiRoijers, Whiteson, & Oliehoek

village

(a)

mine

(b)

(c)

Figure 14: (a) example 4 4 Mining Field instance. additional mines
marked +. (b) Runtimes ms TSLS (for varying amounts allowed
error ), VELS ( = 0), CMOVE 2-objective Mining Field instances
varying numbers additional mines [2..14] grid size = 7. (c)
corresponding induced widths Mining Field instances.

induced width thus longer depends connectivity parameter increases
number agents factors graph.
example Mining Field instance provided Figure 14a. choose distance
adjacent villages grid unit length. map, place
mines (local payoff functions). connect agents using arbitrary tree using 2-agent
local payoff functions (mines). figures, mines span tree unmarked
connected mines black edges. require s2 1 factors build tree.
add additional mines, (independently) placing random point
map inside grid. mine placed, connect villages within
r = 12 + radius mine map. chose = 0.2. Therefore, maximum
connectivity factor (mine) created fashion 4. figure, mines
marked +. rewards per mine per worker, well number workers per
village, generated way Mining Day.
compare runtimes memory requirements CMOVE, VELS, TSLS
Mining Field, tested 7 7 instance (49 agents), 1MB available memory.
TSLS, use three different values : 0 (exact), 0.01 0.1. use time limit
1.8 106 (30 minutes). increase number additional mines 2 (50 factors
total) onwards, steps 2.
Using setup, possible solve problem instances using PMOVE,
ran memory problems. fact, PMOVE succeeded tree-shaped
problem. i.e., one without additional factors. Figures 14b 14c) show results
remaining methods. CMOVE runs memory 6 additional factors (54 factors
total). contrast, VELS runs memory 16 additional factors, induced
width 6.
Compared random-graph results Section 6.4.1, induced widths
problems CMOVE VELS handle lower Mining Field. suspect
438

fiComputing CCSs Faster Multi-objective Coordination

because, grid-shaped problem, number factors highest induced
width need exist parallel execution algorithms higher.
TSLS run memory tested instances. face,
unable generate instances TSLS run memory. However,
run time. = 0, TSLS first exceeds time limit = 10 additional mines.
= 0.01, happens = 14. = 0.1, TSLS ran time = 16.
differences runtime TSLS VELS larger random graphs
therefore difficult compensate slower runtime TSLS choosing
higher . much slower TSLS compared VELS thus seems depend
structure MO-CoG.
Mining Field results confirm conclusion random-graph experiments
using outer loop approach (VELS) instead inner loop approach (CMOVE) yields
significant improvement problem sizes tackled limited memory.
Futhermore, TSLS used solve problem sizes beyond VELS handle
within limited memory. approximate version TSLS appealing choice cases
memory runtime limited.

7. Conclusions Future Work
article, proposed new algorithms exploit loose couplings compute CCS
multi-objective coordination graphs. showed exploiting loose couplings
key solving MO-CoGs many agents. particular, showed, theoretically
empirically, computing CCS considerable advantages computing PCS
terms runtime memory usage. experiments consistently shown
runtime PCS methods grows lot faster CCS methods.
CMOVE deals multiple objectives inner loop, i.e., computes local CCSs
looping agents. contrast, VELS deals multiple objectives
outer loop, i.e., identifies weights maximal improvement upon partial CCS
made solves scalarized (single-objective) problems using weights, yielding
anytime approach. addition, CTS TSLS memory-efficient variants
methods. proved correctness algorithms analyzed complexity.
CMOVE VELS complementary methods. CMOVE scales better number
objectives, VELS scales better number agents compute CCS, leading large additional speedups. Furthermore, VELS memory-efficient
CMOVE. fact, VELS uses little memory single-objective VE.
However, memory restricted VELS cannot applied, TSLS provides
memory-efficient alternative. TSLS considerably slower VELS,
loss compensated allowing error ().
numerous possibilities future work. mentioned Section 5, OLS
generic method applied multi-objective problems. fact, (together
authors) already applied OLS large multi-objective MDPs showed
OLS extended permit non-exact single-objective solvers (Roijers et al., 2014).
future work, intend investigate -approximate methods MO-CoGs, using approximate single-objective solvers CoGs, using, e.g., LP-relaxation methods (Sontag,
Globerson, & Jaakkola, 2011). attempt find optimal balance
439

fiRoijers, Whiteson, & Oliehoek

levels approximation inner outer loop, respect runtime guarantees
empirical runtimes.
Many methods exist single-objective coordination graphs single parameter
controls trade-off memory usage runtime (Furcy & Koenig, 2005; Rollon,
2008). algorithms, corresponding multi-objective inner-loop version
computes PCS (Marinescu, 2009, 2011) devised. would interesting
create inner outer loop methods based methods compute CCS
instead compare performance. particular, shown OLS requires
little extra memory usage compared single-objective solvers. would interesting
investigate much extra memory could used single-objective solver inside OLS,
comparison corresponding inner-loop method.
addition work MO-CoGs, aim extend work sequential
settings. particular, look developing efficient planning method multiagent multi-objective MDPs better exploiting loosely couplings. First, try
develop -approximate planning version sparse-cooperative Q-learning (Kok & Vlassis,
2006b). However, may possible general effects agent
agents via state impossible bound general. Therefore, hope identify
broadly applicable subclass multi-agent MOMDPs -approximate planning
method yields substantial speed-up compared exact planning methods.

Acknowledgements
thank Rina Dechter introducing us memory-efficient methods CoGs
MO-CoGs, Radu Marinescu tips memory-efficient methods implementation. Also, would thank Maarten Inja, well anonymous reviewers, valuable feedback. research supported NWO DTC-NCAP
(#612.001.109) NWO CATCH (#640.005.003) projects NWO Innovational Research Incentives Scheme Veni (#639.021.336). Frans Oliehoek affiliated
University Amsterdam University Liverpool.

References
Avis, D., & Devroye, L. (2000). Estimating number vertices polyhedron. Information processing letters, 73 (3), 137143.
Bayardo, R. J. J., & Miranker, D. P. (1995). space-time trade-off solving constraint
satisfaction problems. IJCAI 1995: Proceedings Fourteenth International
Joint Conference Artificial Intelligence.
Bertsimas, D., & Tsitsiklis, J. (1997). Introduction Linear Optimization. Athena Scientific.
Bishop, C. M. (2006). Pattern Recognition Machine Learning. Springer.
Cassandra, A., Littman, M., & Zhang, N. (1997). Incremental pruning: simple, fast, exact
method partially observable markov decision processes. UAI 1997: Proceedings
Thirteenth Conference Uncertainty Artificial Intelligence, pp. 5461.
440

fiComputing CCSs Faster Multi-objective Coordination

Cheng, H.-T. (1988). Algorithms partially observable Markov decision processes. Ph.D.
thesis, University British Columbia, Vancouver.
Dechter, R. (2013). Reasoning Probabilistic Deterministic Graphical Models: Exact Algorithms, Vol. 7 Synthesis Lectures Artificial Intelligence Machine
Learning. Morgan & Claypool Publishers.
Dechter, R., & Mateescu, R. (2007). And/or search spaces graphical models. Artificial
intelligence, 171 (2), 73106.
Delle Fave, F., Stranders, R., Rogers, A., & Jennings, N. (2011). Bounded decentralised
coordination multiple objectives. Proceedings Tenth International Joint
Conference Autonomous Agents Multiagent Systems, pp. 371378.
Dubus, J., Gonzales, C., & Perny, P. (2009). Choquet optimization using gai networks
multiagent/multicriteria decision-making. ADT 2009: Proceedings First
International Conference Algorithmic Decision Theory, pp. 377389.
Feng, Z., & Zilberstein, S. (2004). Region-based incremental pruning POMDPs. UAI
2004: Proceedings Twentieth Conference Uncertainty Artificial Intelligence, pp. 146153.
Furcy, D., & Koenig, S. (2005). Limited discrepancy beam search. IJCAI 2005: Proceedings Nineteenth International Joint Conference Artificial Intelligence, pp.
125131.
Guestrin, C., Koller, D., & Parr, R. (2002). Multiagent planning factored MDPs.
Advances Neural Information Processing Systems 15 (NIPS02).
Henk, M., Richter-Gebert, J., & Ziegler, G. M. (1997). Basic properties convex polytopes.
Handbook Discrete Computational Geometry, Ch.13, pp. 243270. CRC
Press, Boca.
Kaibel, V., & Pfetsch, M. E. (2003). algorithmic problems polytope theory.
Algebra, Geometry Software Systems, pp. 2347. Springer.
Kok, J. R., & Vlassis, N. (2004). Sparse cooperative Q-learning. Proceedings
twenty-first international conference Machine learning, ICML 04, New York, NY,
USA. ACM.
Kok, J. R., & Vlassis, N. (2006a). Using max-plus algorithm multiagent decision
making coordination graphs. RoboCup 2005: Robot Soccer World Cup IX, pp.
112.
Kok, J., & Vlassis, N. (2006b). Collaborative multiagent reinforcement learning payoff
propagation. Journal Machine Learning Research, 7, 17891828.
Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles Techniques. MIT Press.
Lizotte, D., Bowling, M., & Murphy, S. (2010). Efficient reinforcement learning multiple
reward functions randomized clinical trial analysis. Proceedings 27th
International Conference Machine Learning (ICML-10), pp. 695702.
441

fiRoijers, Whiteson, & Oliehoek

Marinescu, R., Razak, A., & Wilson, N. (2012). Multi-objective influence diagrams.
UAI 2012: Proceedings Twenty-Eighth Conference Uncertainty Artificial
Intelligence.
Marinescu, R. (2008). AND/OR Search Strategies Combinatorial Optimization Graphical Models. Ph.D. thesis, University California, Irvine.
Marinescu, R. (2009). Exploiting problem decomposition multi-objective constraint optimization. Principles Practice Constraint Programming-CP 2009, pp. 592
607. Springer.
Marinescu, R. (2011). Efficient approximation algorithms multi-objective constraint
optimization. ADT 2011: Proceedings Second International Conference
Algorithmic Decision Theory, pp. 150164. Springer.
Mateescu, R., & Dechter, R. (2005). relationship AND/OR search variable
elimination. UAI 2005: Proceedings Twenty-First Conference Uncertainty
Artificial Intelligence, pp. 380387.
McMullen, P. (1970). maximum numbers faces convex polytope. Mathematika,
17 (2), 179184.
Oliehoek, F. A., Spaan, M. T. J., Dibangoye, J. S., & Amato, C. (2010). Heuristic search
identical payoff bayesian games. AAMAS 2010: Proceedings Ninth International Joint Conference Autonomous Agents Multiagent Systems, pp.
11151122.
Pearl, J. (1988). Probabilistic reasoning intelligent systems: networks plausible inference. Morgan Kaufmann.
Pham, T. T., Brys, T., Taylor, M. E., Brys, T., Drugan, M. M., Bosman, P. A., Cock,
M.-D., Lazar, C., Demarchi, L., Steenhoff, D., et al. (2013). Learning coordinated
traffic light control. Proceedings Adaptive Learning Agents workshop (at
AAMAS-13), Vol. 10, pp. 11961201.
Roijers, D. M., Scharpff, J., Spaan, M. T. J., Oliehoek, F. A., de Weerdt, M., & Whiteson,
S. (2014). Bounded approximations linear multi-objective planning uncertainty. ICAPS 2014: Proceedings Twenty-Fourth International Conference
Automated Planning Scheduling, pp. 262270.
Roijers, D. M., Vamplew, P., Whiteson, S., & Dazeley, R. (2013a). survey multiobjective sequential decision-making. Journal Artificial Intelligence Research, 47,
67113.
Roijers, D. M., Whiteson, S., & Oliehoek, F. (2013b). Computing convex coverage sets
multi-objective coordination graphs. ADT 2013: Proceedings Third International Conference Algorithmic Decision Theory, pp. 309323.
Roijers, D. M., Whiteson, S., & Oliehoek, F. A. (2014). Linear support multi-objective
coordination graphs. AAMAS 2014: Proceedings Thirteenth International
Joint Conference Autonomous Agents Multi-Agent Systems, pp. 12971304.
Rollon, E. (2008). Multi-Objective Optimization Graphical Models. Ph.D. thesis, Universitat Politecnica de Catalunya, Barcelona.
442

fiComputing CCSs Faster Multi-objective Coordination

Rollon, E., & Larrosa, J. (2006). Bucket elimination multiobjective optimization problems. Journal Heuristics, 12, 307328.
Rosenthal, A. (1977). Nonserial dynamic programming optimal. Proceedings
Ninth Annual ACM Symposium Theory Computing, pp. 98105. ACM.
Scharpff, J., Spaan, M. T. J., Volker, L., & De Weerdt, M. (2013). Planning uncertainty coordinating infrastructural maintenance. Proceedings 8th annual
workshop Multiagent Sequencial Decision Making Certainty.
Sontag, D., Globerson, A., & Jaakkola, T. (2011). Introduction dual decomposition
inference. Optimization Machine Learning, 1, 219254.
Tesauro, G., Das, R., Chan, H., Kephart, J. O., Lefurgy, C., Levine, D. W., & Rawson, F.
(2007). Managing power consumption performance computing systems using
reinforcement learning. Advances Neural Information Processing Systems 20
(NIPS07).
Vamplew, P., Dazeley, R., Barker, E., & Kelarev, A. (2009). Constructing stochastic mixture policies episodic multiobjective reinforcement learning tasks. Advances
Artificial Intelligence, pp. 340349.
Yeoh, W., Felner, A., & Koenig, S. (2010). BnB-ADOPT: asynchronous branch-andbound DCOP algorithm. Journal Artificial Intelligence Research, 38, 85133.

443


