Journal Artificial Intelligence Research 54 (2015) 369435

Submitted 9/15; published 11/15

Continuing Plan Quality Optimisation
Fazlul Hasan Siddiqui
Patrik Haslum

fazlul.siddiqui@anu.edu.au
patrik.haslum@anu.edu.au

Australian National University &
NICTA Optimisation Research Group
Canberra, Australia

Abstract
Finding high quality plans large planning problems hard. Although current
anytime planners often able improve plans quickly, tend reach limit
plans produced still far best possible, planners fail
find improvement, even given several hours runtime.
present approach continuing plan quality optimisation larger time scales,
implementation system called BDPO2. Key approach decomposition
subproblems improving parts current best plan. decomposition based
block deordering, form plan deordering identifies hierarchical plan structure.
BDPO2 seen application large neighbourhood search (LNS) local search
strategy planning, neighbourhood plan defined replacing one
subplans improved subplans. On-line learning used adapt strategy
selecting subplans subplanners course plan optimisation.
Even starting best plans found means, BDPO2 able continue
improving plan quality, often producing better plans anytime planners
given enough runtime. best results, however, achieved combination
different techniques working together.

1. Introduction
classical AI planning problem involves representing models world (initial
goal states) available actions formal modelling language, reasoning
preconditions effects actions. Given planning problem, planning system
(or planner, short) generates sequence actions, whose application transforms
world initial state desired goal state. Thus, planning makes intelligent
system autonomous construction plans action achieve goals.
key concern automated planning producing high quality plans. Planners using
optimal bounded suboptimal (heuristic) search methods offer guarantees plan quality,
unable solve large problems. Fast planners, using greedy heuristic search
techniques, hand, solve large problems often find poor quality plans.
gap capabilities two kinds planners means producing high
quality plans large problems still challenge. example gap shown
Figure 1. seek address gap proposing new approach continuing plan
improvement, able tackle large problems works varying time scales.
Anytime search tries strike balance optimal (or bounded suboptimal)
greedy heuristic search methods. Anytime search algorithms finding initial
solution, possibly poor quality, quickly continuing search better solutions
c
2015
AI Access Foundation. rights reserved.

fi20
0

10

Plan cost

30

Siddiqui & Haslum

**
**********
*
*
****
0

50

100

150

Problem (sorted)

Figure 1: Illustration plan quality gap. dashed line represents best (lowestcost) plan 156 problems Genome Edit Distance (GED) domain (Haslum, 2011)
found different non-optimal planners, including anytime planners. solid line represents corresponding highest known lower bound. difference two
optimality gap. ? points represent plans found optimal planners,
vertical bars show optimality gap obtained problem-specific algorithm (GRIMM).

time given. Anytime search algorithms as, example, RWA*
(Richter, Thayer, & Ruml, 2010) AEES (Thayer, Benton, & Helmert, 2012b)
successfully used anytime planners. However, planners often effective
making use increasing runtime beyond first minutes. Xie, Valenzano, & Muller
(2010) define unproductive time planner amount time remaining
finds best plan, total time given. show four IPC-2011 domains
(Barman, Elevators, Parcprinter, Woodworking), unproductive time LAMA
planner (which uses RWA*), given 30 minutes per problem, 90%.
observed similar results, shown Figure 2. figure shows average
IPC quality score function time several anytime planners plan optimisation
methods, including LAMA planner. (A full description experiment setup,
results even anytime planners, presented Section 3, page 392.) LAMA
finds first solution quickly: 92.3% problems solves (within maximum 7
hours CPU time per problem), first plan found less 10 minutes. quality
LAMAs plans improve rapidly early on, later trend one flattening out, i.e.,
decreasing increase. (The drop beginning due figure showing average
plan quality solved problems: initial, low-quality, plans problems found
average drops, increasing better plans found.) 1 7
hours CPU time, LAMA improves plans 21.3% solved problems. Yet
51.6% problems better plans exist, found methods. time
interval, LAMAs average plan quality score increases 2.7%, increase
370

fiContinuing Plan Quality Optimisation

0.96
0.95

Average Quality Score (Relative IPC Quality Score / Coverage)

0.94
0.93
0.92
0.91




































































































0.9
0.89
0.88
0.87
0.86
0.85
0.84


0.83









































BDPO2 PNGS base plans
BDPO2 base plans
PNGS base plans
IBCS base plans
BSS base plans
LAMA scratch
IBaCoP2 scratch








0.82



7

6.5

6

5.5

5

4.5

4

3.5

3

2.5

2

1.5

1

0.5

0

0.81

Time (hours)

Figure 2: Average IPC quality score function time per problem, set 182
large-scale planning problems. quality score plan cref/c, c cost
plan cref reference cost (least cost plans problem); hence
higher score represents better plan quality. Anytime planners (LAMA, IBaCoP2) start
scratch, post-processing (PNGS, BDPO) bounded-cost search (IBCS, BeamStack Search) methods start set base plans. curves delayed 1 hour
account maximum time given generating base plan. experiment setup
results additional planners described Section 3.1 (page 392).

371

fiSiddiqui & Haslum

Figure 3: General framework BDPO2

least 14.6% possible. Memory-limited branch-and-bound algorithms, Beam Stack
Search (Zhou & Hansen, 2005) may run indefinitely, find improvements slowly.
increase average plan quality made BSS entire time depicted Figure
2 1.8%.
Plan optimisation approaches based post-processing start valid plan seek
improve it. Figure 2 shows results Plan Neighbourhood Graph Search (Nakhost
& Muller, 2010). PNGS searches shortcuts subgraph state space
problem, constructed around current plan. (The PNGS implementation used
experiment applies Nakhosts Mullers action elimination technique.) Applying
PNGS results substantial plan quality improvements quickly 94.8% improved plans
found less 10 minutes stops, runs memory.
summary, experiment shows current anytime plan optimisation methods
become unproductive runtime increases, suffer slow rate plan quality
improvement.
present post-processing approach plan optimisation, implementation
system called BDPO2. (The source code BDPO2 provided on-line appendix
article.) post-processor, BDPO2 work own: depends
methods providing initial plan. experiment, set input plans (referred
base plans) best plans found LAMA 1 hour, plan found IBaCoP2
2014 IPC. Figure 2 shows switching approach time
overcome limitation current anytime planning techniques, continue improve
plan quality allotted time increases. best result, shown, obtained chaining
several techniques together, applying first PNGS base plans, BDPO2
best result produced PNGS. result could achieved previous anytime
planning approaches alone.
BDPO2 uses Large Neighborhood Search (LNS), local search technique. local
search explores neighbourhood around current solution plan better quality valid
plan. LNS, neighbourhood solution defined destroy repair methods,
together replace part current solution, keeping rest unchanged.
BDPO2, destroy step selects subsequence linearisation deordering
current plan (we call window) repair step applies bounded-cost
planner subproblem finding better replacement subplan. focus
solving smaller subproblems makes local search, LNS particular, scale better
large problems. size structure neighborhood, however, plays crucial
372

fiContinuing Plan Quality Optimisation

role performance local search (Hoffmann, 2001). setting, neighbourhood determined strategies used select windows subplanners. destroy
methods used LNS algorithms often contain element randomness, local
search may accept moves lower-quality solutions (Ropke & Pisinger, 2006; Schrimpf,
Schneider, Stamm-Wilbrandt, & Dueck, 2000). contrast, explore neighbourhood
systematically, examining candidate windows generated ordered several heuristics,
accept moves strictly better plans. introduce LNS idea
delayed restarting, meaning search combine multiple local improvements
restarting next iteration new best plan. found delayed
restarts allow better exploration subplans different parts current plan,
helps avoid local minima otherwise occur system attempts re-optimise
part plan successive iterations.
BDPO2 framework, shown Figure 3, broadly consists four components: plan
decomposition, LNS (i.e., repeated destroy repair steps), windowing, on-line
adaptation. first step, decomposition, uses deordering produce partially ordered
plan. Deordering enables windowing strategies find subplans easier
improve on, leading much better anytime performance. use block deordering (Siddiqui
& Haslum, 2012), simultaneously decomposes given plan coherent subplans,
called blocks, relaxes ordering constraints blocks. Block deordering removes
inherent limitations existing, step-wise deordering techniques, able
deorder sequential plans cases step-wise deordering possible.
windowing component collection strategies extracting windows block
deordered plan, ranking policies order windows system attempts
optimise promising windows first.
BDPO2 extends earlier system, BDPO (Siddiqui & Haslum, 2013b), mainly using
variety alternatives task: BDPO used single windowing strategy (with
ranking) single subplanner, BDPO2 uses portfolios window generation
ranking strategies several subplanners. improves capability robustness
system, since single alternative (windowing strategy, subplanner, etc.) dominates
others across problems. Furthermore, take advantage fact system
solves many subproblems course local search learn on-line
best alternatives current problem. particular, use UCB1 multi-armed
bandit learning policy (Auer, Cesa-Bianchi, & Fischer, 2002) subplanner selection,
sequential portfolio window ranking policies.
remainder article structured follows: Section 2 describes block deordering. theory block deordering presented slightly different earlier
account (Siddiqui & Haslum, 2012), allowing deordering cases better contrasting traditional partially ordered plan semantics. Section 3 presents
overview BDPO2 system main empirical results, Sections 4 5 give
details windowing on-line adaptation components, respectively, including
empirical analysis impact performance system whole. Section 6
reviews related work, Section 7 presents conclusions outlines ideas future work.
373

fiSiddiqui & Haslum

2. Plan Decomposition
approach continuing plan quality improvement based optimising plan
parts, one time. Every subplan consider local optimisation subsequence
linearisation partially ordered plan. Therefore, key step removing unnecessary ordering constraints the, typically sequential, input plan. process called
plan deordering. importance deordering demonstrated one experiments
(presented Section 3.6, page 402), apply BDPO2 input plans
already high quality: total plan quality improvement (measured increase
average IPC plan quality score) achieved BDPO2 without deordering 28.7%
less achieved BDPO2 using plan deordering technique.
standard notion valid partially ordered plan requires unordered steps
plan non-interfering (i.e., two subsequences plan unordered, every
interleaving steps two must form valid execution). limits amount
deordering done, cases extent deordering sequential
plan possible. (An example situation shown Figure 6 page 381.)
remedy this, introduced block deordering (Siddiqui & Haslum, 2012), creates
hierarchical decomposition plan non-interleaving blocks deorders
blocks. makes possible deorder plans further, including cases
conventional, step-wise, deordering possible. (Again, example found
Figure 6 page 381.) section, present new, slightly different account
theory practice block deordering. First, relaxes restriction block deordered
plans, thereby allowing deordering plans. Second, contrasts semantics
block decomposed partially ordered plans traditional partially ordered plan
semantics clearer way.
Sections 2.12.3 describe necessary background, Sections 2.42.6 introduce block
decomposed partially ordered plans block deordering algorithm.
2.1 Planning Problem, Sequential Plan Validity
consider standard STRIPS representation classical planning problems action
costs. planning problem tuple = hM, A, C, I, Gi, set atoms
(alternatively called fluents propositions), set actions, C : R0+ cost
function actions, assigns action non-negative cost, initial
state, G goal.
action characterised triple hpre(a), add(a), del(a)i, pre(a), add(a),
del(a) preconditions, add delete effects respectively. say
action consumer atom pre(a), producer add(a),
deleter del(a). action applicable state pre(a) S,
applied S, results state apply(a, S) = (S \ del(a)) add(a). sequence
actions = hai , ai+1 , ..., aj applicable state Si (1) pre(ak ) Sk k j,
(2) Si+1 = apply(ai , Si ), Si+2 = apply(ai+1 , Si+1 ), on; resulting state
apply(, Si ) = Si+j+1 .
valid sequential plan (also totally ordered plan) seq = ha1 , ..., planning
problem sequence actions applicable G apply(seq , I).
actions seq must executed specified order.
374

fiContinuing Plan Quality Optimisation

2.2 Partially Ordered Plan Validity
Plans partially ordered, case actions unordered respect
other. partially ordered plan (p.o. plan) tuple, pop = hS, i,
set steps (each labelled action A) represents strict (i.e.,
irreflexive) partial order S. unordered steps pop executed order.
+ denotes transitive closure . element hsi , sj (also si sj ) basic
ordering constraint iff transitively implied constraints . plan
step s, use pre(s), add(s) del(s) denote preconditions, add delete effects
action associated s. use terms producer, consumer, deleter,
cost plan steps, referring associated actions. include two steps,
sI sG . sI ordered steps, consumes nothing produces initially
true atoms, sG ordered steps, consumes goal atoms produces
nothing.
linearisation pop total ordering steps respects . p.o. plan
pop valid (for planning problem ) iff every linearisation pop valid sequential
plan (for ). words, p.o. plan viewed compact representation
set totally ordered plans, namely linearisations.
Every basic ordering constraint, si sj , pop set associated reasons, denoted
Re(si sj ). reasons explain ordering necessary plan
valid: Re(si sj ) non-empty, step precondition may unsatisfied
execution linearisations pop violate si sj . reasons three
types:
PC(m) (producerconsumer atom m): first step, si , produces precondition second step, sj . Thus, order changed, sj executed si ,
precondition sj may established required.
CD(m) (consumerdeleter m): second step, sj deletes m, precondition
si . Thus, order changed, may deleted required.
DP(m) (deleterproducer m): first step, si deletes m, produced
second step, sj . order changed, add effect producer step may
undone deleter, causing later step fail. is, however, necessary
order producer deleter step may occur producer plan
depends added atom.
Note ordering constraint several associated reasons, including several
reasons type referring different atoms. producerconsumer relation
PC(m) Re(si sj ) usually called causal link si sj (McAllester &
Rosenblitt, 1991), denoted triple hsi , m, sj i. causal link hsi , m, sj threatened
deleter may ordered last producer sj
sj , since implies possibility false required execution
sj . formal definition follows.
Definition 1. Let pop = hS, p.o. plan, hsp , m, sc causal link pop .
hsp , m, sc threatened step sd deletes neither (1) sc + sd
(2) s0p : add(s0p ) sd + s0p + sc true.
375

fiSiddiqui & Haslum

mentioned above, p.o. plan, pop = hS, planning problem valid iff
every linearisation pop valid sequential plan . However, following theorem
gives alternative, equivalent, condition p.o. plan validity.
Theorem 1 (e.g., Nebel & Backstrom, 1994). p.o. plan valid iff every step precondition
supported causal link threat causal link.
condition Chapmans (1987) modal truth criterion,
sc S, pre(sc ) :
sp : (PC(m) Re(sp sc )
st : del(st ) sc + sd s0p : add(s0p ) sd + s0p + sc



.

2.3 Deordering
process deordering converts sequential plan p.o. plan removing ordering
constraints steps, steps plan successfully executed
order consistent partial order still achieve goal (Backstrom, 1998).
refer step-wise deordering, distinguish block decomposition
deordering introduce later section. Since current state space search planners
produce sequential plans efficiently, deordering plays important role efficient
generation p.o. plans.
Let pop = hS, valid p.o. plan. (step-wise) deordering pop valid plan
0
0
pop
= hS, 0 (0 )+ + . is, pop
result removing basic
ordering constraints without invalidating plan. sequential plan seq = ha1 , ...,
represented p.o. plan one step si action ai seq ordering
si sj whenever < j, two steps unordered. Thus, deordering
sequential plan different (further) deordering p.o. plan.
Computing (step-wise) deordering minimum number ordering constraints
NP-hard (Backstrom, 1998), several non-optimal algorithms (e.g., Pednault,
1986; Veloso, Perez, & Carbonell, 1990; Regnier & Fade, 1991). used variant
explanation-based generalisation algorithm Kambhampati Kedar (1994).
algorithm works two phases: first phase constructs validation structure,
exactly one causal link hsp , m, sc precondition step sc . sp chosen
earliest producer preceding sc input plan, intervening threatening
step (i.e., deletes m) sp sc . (The algorithm Veloso, Perez Carbonell
similar, selects latest producer instead.) second phase, algorithm builds
partial ordering, keeping orderings original plan either correspond
causal links validation structure required prevent threatening step
becoming unordered w.r.t. steps causal link.
Kambhampati Kedars deordering algorithm, due greedy strategy,
guarantee optimality. example fails transform totally ordered plan
least-constrained plan shown Figure 4. However, recent study found
algorithm produce optimal step-wise plan deorderings plans
tested (Muise, McIlraith, & Beck, 2012).
However, motivation plan deordering find deordering adequate
generating useful candidate subplans local optimisation. important achieving
376

fiContinuing Plan Quality Optimisation

Figure 4: example Kambhampati Kedars (1994) algorithm fails find
least constrained plan. (Derived Figure 14 Backstroms 1998 article plan
deordering.) Figure (a) sequential input plan, (b) plan produced algorithm
choosing earliest producer (for validation structure) preconditions p
q D, (c) minimally ordered version (a). simplicity, goal atoms
produced steps A, B, C shown figure.

optimal step-wise deordering overcoming inherent limitation step-wise deordering, allows plan steps unordered non-interfering. Block
deordering, described next two sections, remove orderings input
plans forming blocks, helps generate decomposed plan suitable
extracting subplans local optimisation.
2.4 Block Decomposition
conventional p.o. plan, whenever two subplans unordered every interleaving steps
two forms valid execution. limits deordering cases individual steps
non-interfering. remove restriction, proposed block decomposed partial
ordering, restricts interleaving steps dividing plan steps blocks,
steps block must interleaved steps block. However,
steps within block still partially ordered. illustrated example
Figure 5. figure shows difference linearisations p.o. plan block
decomposed p.o. plan. b, a, c, valid linearisation standard partial ordering
block decomposed p.o. plan. formal definition block follows.
Definition 2. Let pop = hS, p.o. plan. block w.r.t. , subset b steps
two steps s, s0 b, exists step s00 (S \b) + s00 + s0 .
decomposition plan blocks recursive, i.e., block wholly
contained another. However, blocks cannot partially overlapping. Two blocks
ordered bi bj exist steps si bi sj bj si sj neither block
contained (i.e., bi 6 bj bj 6 bi ).
Definition 3. Let pop = hS, p.o. plan. set B subsets block
decomposition pop iff (1) b B block w.r.t. (2) every bi , bj B,
either bi bj , bj bi , bi bj disjoint. block decomposed plan denoted
bdp = hS, B, i.
377

fiSiddiqui & Haslum

Figure 5: normal p.o. plan (left) represents set sequential plans linearisations plan steps, example ha, b, c, di, hb, a, c, di, hb, c, a, di, hb, c, d, ai.
block decomposed p.o. plan (shown right dashed outlines blocks) allows
unordered blocks executed order, steps different blocks
interleaved. Thus, ha, b, c, di, hb, c, a, di, hb, c, d, ai possible linearisations
plan.

semantics block decomposed plan defined restricting linearisations (for
must valid) respect block decomposition, i.e.,
interleave steps disjoint blocks. bi bj , steps bi must precede steps bj
linearisation block decomposed plan.
Definition 4. Let bdp = hS, B, block decomposed p.o. plan planning problem
. linearisation bdp total order lin (1) lin (2) every
b B block w.r.t. lin . bdp valid iff every linearisation bdp plan .
Blocks behave much (non-sequential) macro steps, preconditions, add
delete effects subset union constituent steps.
enables blocks encapsulate plan effects preconditions, reducing interference
thus allowing deordering. following definition captures preconditions
effects visible outside block, i.e., give rise dependencies
interference parts plan. need consider
deciding two blocks unordered. (Note responsible step step block
causes produce, consume threaten atom.)
Definition 5. Let bdp = hS, B, block decomposed p.o. plan, b B block.
block semantics defined as:
b adds iff b precondition m, responsible step b
add(s), s0 b, s0 deletes s0 s.
b precondition iff responsible step b pre(s),
step s0 b causal link hs0 , m, si without active threat.
b deletes iff responsible step b del(s), step
s0 b s0 adds m.
Note block consumes proposition, cannot produce proposition.
reason taking black box view block execution, proposition
simply persists: true execution block begins remains true
finished. steps within block totally ordered, preconditions effects
block according Definition 5 nearly cumulative preconditions
378

fiContinuing Plan Quality Optimisation

effects action sequence defined Haslum Jonsson (2000), difference
consumer block cannot producer proposition.
conventional p.o. plan, valid, must contain threat causal link.
contrast, block decomposed p.o. plan allows threat causal link exist plan,
long causal link protected threat block structure. causal
link protected threat iff either (i) causal link contained block
contain threat, (ii) threat contained block contain
causal link delete threatened atom (i.e., encapsulates delete effect).
threat causal link active link protected it, otherwise inactive.
formal definition follows.
Definition 6. Let bdp = hS, B, block decomposed p.o. plan, st threat
causal link hsp , m, sc bdp . hsp , m, sc protected st iff exist block
b B either following true: (1) sp , sc b; st
/ b; (2) st b, sp , sc
/ b,

/ del(b).
example block decomposition protects causal link seen Figure
7(i) page 382.
following theorem provides alternative criterion validity block decomposed p.o. plan, analogy condition conventional p.o. plan given
theorem cited above. difference block decomposed p.o. plan allows
threats causal links, long threats inactive. Let bdp = hS, B, block
decomposed p.o. plan. Analogously Chapmans modal truth criterion, condition
stated follows:
sc S, pre(sc )
sp : (m add(sp )
st : (m del(st ) st 6+ sp sc 6+ st hsp , m, sc protected st )).
Theorem 2. block decomposed p.o. plan valid iff every step precondition supported
causal link active threat.
Proof. Let bdp = hS, B, block decomposed p.o. plan planning problem . Let
us first prove part, i.e., every step precondition supported causal
link active threat every linearisation bdp valid plan . Let
seq = h. . . , sc , . . .i arbitrary linearisation bdp total order seq S,
pre(sc ). Then, according validity criteria sequential plan, show
must satisfied execution sc seq . Since every step precondition
supported causal link bdp active threat, must supported
causal link hsp , m, sc active threat. Moreover, since seq sp seq sc .
Let st threat hsp , m, sc bdp . Clearly, sp seq st seq sc possibility
may cause unsatisfied execution sc . Since hsp , m, sc active
threat, hsp , m, sc protected st , therefore, according Definition 6, either (1)
sp , sc b st
/ b, (2) st b, sp , sc
/ b,
/ del(b), must hold. (1) true,
sp seq st seq sc occur valid linearisation bdp , since interleaves
steps sp , sc b st
/ b, thus b block w.r.t. seq . second case, since
379

fiSiddiqui & Haslum


/ del(b) must producer m, s0p b, st seq s0p . Moreover,
since sp , sc
/ b, sp seq st seq sc true sp seq st seq s0p seq sc .
makes true execution sc seq .
Let us prove part, i.e., bdp valid every step precondition
supported causal link active threat. Let sc S, pre(sc ),
seq = h. . . , sc , . . .i linearisation bdp total order seq S. consider two
possible situations: (1) producer s0 causal link hs0 , m, sc bdp
constructed, (2) least one producer construct causal
link sc atom causal link active threat bdp . show
none situations happen long bdp valid. According situation
(1), s0 seq well s0 seq sc . causes unsatisfied
execution sc seq , i.e., seq become invalid. Consequently, bdp become invalid
(since one linearisation invalid), contradicts assumption. Therefore,
must exist least one producer s0 construct causal link hs0 , m, sc bdp .
Now, situation (2), assume sp last producer execution sc
seq , i.e., s0p \ sp : add(s0p ) (s0p seq sp sc seq s0p ). Let sp producer
causal link hsp , m, sc bdp (which possible, since sp ordered sc
bdp ). Assume hsp , m, sc active threat st bdp . Since hsp , m, sc active
threat st (i.e., hsp , m, sc protected st ), neither (i) sp , sc b; st
/ b,
(ii) st b; sp , sc
/ b,
/ del(b), true. Therefore, sp seq st seq sc possible
linearisation bdp . Moreover, since producer sp sc ,
must unsatisfied execution sc , i.e., seq becomes invalid. Consequently,
bdp invalid since one linearisations invalid. Therefore, hsp , m, sc must
active threat.
2.5 Block Deordering
Block deordering (Siddiqui & Haslum, 2012) process removing orderings
plan steps adding blocks block decomposed p.o. plan. may add plan
new ordering constraints, transitively implied ordering
constraints. Block deordering often remove ordering constraints step-wise deordering not. no-interleaving restriction among blocks affords
us simplified, black box, view blocks localises interactions,
preconditions effects executing block whole important. Thus, allows deordering able ignore dependencies effects matter
internally within block. addition providing linearisations, improving
deordering, blocks formed block deordering often correspond coherent, selfcontained subplans, form basis windowing strategies (described detail
Section 4) use generate candidate subplans local optimisation.
subsection presents conditions adding blocks block decomposition allows removal basic ordering constraints. complete block deordering
algorithm presented next subsection.
simple example block deordering, Figure 6(i) shows sequential plan small
Logistics problem. plan deordered conventional p.o. plan,
plan step reason ordered previous. Block deordering, however,
380

fiContinuing Plan Quality Optimisation

Figure 6: sequential plan block deordering plan two unordered blocks
b1 b2. Ordering constraints labelled reasons: producerconsumer (PC),
i.e., causal link, deleterproducer (DP), consumerdeleter (CD). Note ordering
constraint sequential plan removed without invalidating it. Thus, step-wise
deordering plan possible.

able break ordering s3 s4 removing reason PC(at P1 A) based
formation two blocks b1 b2 shown Figure 6(ii). Neither two blocks
delete add atom P1 (although precondition both). removes
interference them, allows two blocks executed order
without interleaving. Therefore, possible linearisations block decomposed
p.o. plan hs1, s2, s3, s4i hs4, s1, s2, s3i. Note b2 ordered b1,
b1 optimised removing step s3.
Besides necessary orderings pair steps plan due reasons PC,
CD, DP (stated Section 2.2), valid block decomposed p.o. plan must maintain one
type necessary ordering, called threat protection ordering. removing ordering
sx + sy causes block containing steps delete effect,
ordering, delete effect causes causal link outside block become
unprotected (not satisfying either two conditions Definition 6), sx + sy
threat protection ordering, may removed. threat protection ordering
introduced block deordering process, introduced removed.
demonstrated Figure 7, removing kind ordering leads invalid
block decomposed p.o. plan. threat protection ordering defined formally follows.
Definition 7. Let bdp = hS, B, block decomposed p.o. plan, hsp , m, sc
causal link protected st bdp . Let b B; st , s0 b; sp , sc
/ b; add(s0 );

/ del(b); st + s0 . st + s0 threat protection ordering breaking ordering
causes del(b) causes hsp , m, sc become unprotected st .
381

fiSiddiqui & Haslum

Figure 7: Two block decompositions plan containing five steps: s1, s2, s3, s4, s5.
decomposition (i), three (transitively reduced) necessary orderings: s1 s2,
s2 s3, s4 s5, Re(s1 s2) = {DP(m), DP(n)}, Re(s2 s3) = {PC(m)},
Re(s4 s5) = {PC(n)}. decomposition valid since every step precondition
satisfied causal link without active threats. threat s1 causal link hs4, n,
s5i inactive, since link protected block bx = {s1, s2, s3} contains s1
delete m, disjoint causal link. forming two blocks, = {s1}
bz = {s2, s3} would possible remove s1 s2, shown (ii), since hs2, m, s3i
protected s1 bz . However, decomposition delete effect block bx
becomes del(bx ) = {m, n}, block therefore longer protects hs4, n, s5i. Therefore,
decomposition deordering invalid. ordering s1 s2 threat protection
ordering, must broken. Note (i) s2 consumers produced
atom n, yet acts white knight hs4, n, s5i protect n deleter s1.

notion threat protection ordering missing earlier block deordering
procedure (Siddiqui & Haslum, 2012), relied (implicitly) stronger restriction
delete effects block change due subsequent deordering inside block.
Explicitly checking necessary threat protection orderings allows deordering
inside created blocks take place.
remove basic ordering, si sj , block decomposed p.o. plan bdp = hS, B, i,
create two blocks, bi bj , si bi , sj bj , bi bj = . Note one
two blocks consist single step. blocks must consistent existing
decomposition, i.e., B {bi , bj } must still valid block decomposition, sense
Definition 2. remainder subsection, define four rules state conditions
blocks bi bj allow different reasons ordering si sj eliminated.
Since ordering si sj exist several reasons (including several reasons
type, referring different atoms), blocks bi bj found
allow us remove every reason Re(si sj ) ordering steps
removed.
Rule 1. Let bdp = hS, B, valid block decomposed p.o. plan, si sj basic
ordering whose removal cause threat protection ordering removed,
PC(m) Re(si sj ). Let bi block, si bi , sj
/ bi , s0 bi : si s0 . PC(m)
removed Re(si sj ) pre(bi ) sp
/ bi sp establish
causal link bi sj .
382

fiContinuing Plan Quality Optimisation

Figure 8: Formation block {s,p} addition causal link hr,m,qi (ii) order
remove reason PC(m) behind basic ordering constraint p q (i). Different
situations, (iii iv), threat, t, may active hr,m,qi.

explanation Rule 1, PC(m) Re(si sj ), bi must produce m. Since
si produces followed deleter within bi (because si sj basic
ordering sj
/ bi ) way happen bi consumes m. Since plan
valid, must producer, sp
/ bi , necessarily precedes step (in bi )
+
consumes m. Note sp sj . adding causal link PC(m) Re(sp sj ) (i.e.,
adding hsp , sj already present) allows PC(m) removed Re(si sj ).
Theorem 3. Deordering according Rule 1 preserves plan validity.
Proof. Let bdp = hS, B, valid block decomposed p.o. plan. Therefore, according
Theorem 2, every step precondition bdp supported causal link active
threat. Let p q basic ordering constraint (where p, q S), bp , bq B blocks
meet conditions removing PC(m) Re(p q), bp , bq ordered
ordering constraints. show removing PC(m) Re(p q) results
0
new plan, bdp
= hS, B 0 , 0 i, meets condition Theorem 2, therefore
remains valid.
Assume PC(m) Re(p q) removed, precondition q supplied
step r based newly established causal link hr,m,qi deordering formulating
0
bp = {s,...,p}, bq = {q} bdp
, shown Figure 8 (ii). show hr,m,qi
0
0
active threat bdp , therefore, bdp
valid. Assume, active threat,
0
+
t, hr,m,qi bdp . Then, course, r q + t. examine every
situation, active threat hr,m,qi.
Situation (1): assume + t, shown Figure 8 (iii). Since active threat
hr,m,si bdp , according Theorem 2, either contained block
383

fiSiddiqui & Haslum

Figure 9: Formation blocks removing reason CD(m) behind basic ordering
p q.

delete threatened atom contain hr,m,si, hr,m,si contained
0
block b0 = {r, s, ...} contain t. first case, holds true bdp
,
0
therefore, active threat hr,m,qi. second case, b partially
overlap bp = {s,...,p}, therefore, either bp b0 b0 bp . bp b0 , bp must contain r,
happen according PC removing criteria (i.e., r
/ bp must hold) stated
Rule 1. b0 bp , b0 must contain least r, s, p, b0 partially
overlap bp = {s,...,p}. Since active threat hp,m,qi bdp , hp,m,qi
must contained block b00 = {p, q, ...} contain t. Now, since b0
b00 partially overlap, b0 b00 (whichever bigger) must contain least r, s, p,
q, b0 b00 (whichever bigger) protects hr,m,qi t.
Situation (2): assume + p, shown Figure 8 (iii). Since active
threat hp,m,qi bdp , before, show either contained block
encapsulates threatened atom (i.e., delete m) contain hp,m,qi,
hp,m,qi contained block b0 = {r, s, p, q, ...} contain t. cases,
hr,m,qi protected t.
Situation (3): assume + + p shown Figure 8 (iv). possible bp ,
since interleave steps bp
/ bp . Therefore, bp , causes
hr,m,qi protected t. bp contain hr,m,qi
delete (since add(p) + p).
Therefore, conclude never active threat hr,m,qi
situation.
Rule 2. Let bdp = hS, B, valid block decomposed p.o. plan, si sj basic ordering
whose removal cause threat protection ordering removed, CD(m)
384

fiContinuing Plan Quality Optimisation

Re(si sj ). Let bi bj two blocks, si bi , sj bj , bi bj = .
CD(m) removed Re(si sj ) bi consume m.
Theorem 4. Deordering according Rule 2 preserves plan validity.
Proof. Let bdp = hS, B, valid block decomposed p.o. plan, p q basic
ordering constraint, p, q CD(m) Re(p q). order meet
condition Rule 2, let us assume bp block includes r p hr,m,pi
causal link every consumer bp (if exist) ordered r bdp (as
shown Figure 9 (i)). Therefore meets condition bp must consume m. Also,
assume bq block contains {q} bp , bq ordered ordering
constraints. Therefore, CD(m) Re(p q) well p q removed, results
0
0
new plan bdp
= hS, B 0 , 0 i. show bdp
valid according Theorem 2.
Since bdp valid, active threat causal link bdp according
Theorem 2, due deordering p q, deleter q becomes new threat
0
. However, hr,m,pi contained bp contain
causal link hr,m,pi bdp
q, therefore, according Definition 6, hr,m,pi protected q, i.e., q becomes
0
remains valid.
inactive threat. result, bdp
Rule 3. Let bdp = hS, B, valid block decomposed p.o. plan, si sj basic ordering
whose removal cause threat protection ordering removed, CD(m)
Re(si sj ). Let bi bj two blocks, si bi , sj bj , bi bj = .
CD(m) removed Re(si sj ) bj delete m.
Theorem 5. Deordering according Rule 3 preserves plan validity.
Proof. Let bdp = hS, B, valid block decomposed p.o. plan, p q basic
ordering constraint, p, q CD(m) Re(p q). order meet condition
Rule 3, let us assume bq block includes q DP(m) Re(q s)
every deleter bq (if exist) ordered bdp (as shown
Figure 9 (ii)). Therefore meets condition bq must delete m. Also, assume bp
block contains {p}, bp , bq ordered ordering constraints.
Therefore, CD(m) Re(p q) well p q removed, results new plan
0
0
valid according Theorem 2.
= hS, B 0 , 0 i. show bdp
bdp
Since bdp valid, active threat causal link bdp according
Theorem 2, due deordering p q, deleter q becomes new threat
0
causal link hr,m,pi bdp
. However, q contained bq contain hr,m,pi,
delete m; therefore, according Definition 6, hr,m,pi protected q, i.e.,
0
q becomes inactive threat. result, bdp
satisfies condition Theorem 2
therefore remains valid.
Rule 4. Let bdp = hS, B, valid block decomposed p.o. plan, si sj basic ordering
whose removal cause threat protection ordering removed, DP(m)
Re(si sj ). Let bj block, sj bj si
/ bj . DP(m) removed
Re(si sj ) bj includes every step s0 PC(m) Re(sj s0 ).
Theorem 6. Deordering according Rule 4 preserves plan validity.
385

fiSiddiqui & Haslum

Figure 10: Formation blocks removing reason DP(m) behind basic ordering
p q.

Proof. Let bdp = hS, B, valid block decomposed p.o. plan, let p q basic
ordering constraint (where p, q S). Let bq block includes steps r
hq,m,ri, hq,m,si causal links bdp (as shown Figure 9 (ii)). Hence,
meets condition Rule 4. Also, assume bp block contains {p} bp , bq
ordered ordering constraints. result, DP(m) Re(p q) well
0
0
= hS, B 0 , 0 i. show bdp
p q removed, results new plan bdp
satisfies condition Theorem 2 therefore remains valid.
Since bdp valid, active threat causal link bdp according
Theorem 2, due deordering p q, deleter p becomes new threat
0
. However, causal links contained
causal links hq,m,ri hq,m,si bdp
bq contain p, therefore, according Definition 6, protected p,
0
i.e., p becomes inactive threat. result, bdp
remains valid.

Even when, applying four rules above, find blocks bi bj remove
reasons ordering si sj , thus permitting ordering removed,
guaranteed two blocks bi bj unordered. may ordered
bi contains step si ordered step bj (whether sj
another). Even not, block b B contains bi (or bj both),
b still ordered bj (resp. bi ) due constraint +
hsi , sj i, blocks bi bj still ordered, sense bi appear bj
linearisation consistent block decomposition.
386

fiContinuing Plan Quality Optimisation

2.6 Block Deordering Algorithm
previous subsection described four conditions (Rules 14) adding blocks
decomposition allows reasons ordering constraints, thus ultimately ordering
constraints themselves, removed preserving plan validity. Next, describe
algorithm uses rules perform block deordering, i.e., convert sequential
plan seq block decomposed p.o. plan bdp .
algorithm divided two phases. First, apply step-wise deordering procedure convert seq p.o. plan pop = (S, 0 ). used Kambhampati
Kedars (1994) algorithm this, simple shown produce
good results (Muise et al., 2012), even though optimality guarantee.
step-wise plan deordering, extend ordering blocks: two blocks ordered
bi bj exist steps si bi sj bj si sj neither block contained
(i.e., bi 6 bj bj 6 bi ). case, steps bi must precede steps bj
linearisation block decomposed plan. extend reasons ordering
(PC, CD DP) ordering constraints blocks, set propositions
produced, consumed deleted block given Definition 5. Recall responsible
step step block causes produce, consume delete proposition.
example, b produces p, must step b produces p, step
block ordered deletes p; say step responsible b producing p.
next phase block deordering, converts p.o. plan pop = (S, )
block decomposed p.o. plan bdp = (S, B, 0 ). done greedy procedure,
examines basic ordering constraint bi bj turn attempts create blocks
consistent decomposition built far allow ordering
removed. core algorithm Resolve procedure (Algorithm 1). takes
input two blocks, bi bj , ordered (one blocks may consist single step),
tries break ordering extending larger blocks, b0i b0j . procedure
examines reason ordering constraint extends one blocks remove
reason, following rules given previous subsection. this, sets
propositions produced, consumed deleted new blocks (b0i b0j ) recomputed
(following Definition 5) new reasons ordering constraint arisen
steps included added Re(b0i b0j ). repeated
either reason ordering remains, case new blocks returned
procedure safely unordered, reason cannot removed, case
deordering possible (signalled returning null). function Intermediate(bi , bj )
returns set steps ordered bi bj , i.e., {s | bi + + bj }. Algorithm
1 refers nearest step s0 preceding following another step s, means step
smallest number basic ordering constraints s0 s.
applied Resolve procedure basic ordering constraint would obtain
collection blocks break orderings. collection
necessarily valid decomposition, since blocks may partial overlap.
find valid decomposition, use greedy procedure. repeatedly examine basic
ordering constraint bi bj call Resolve find two extended blocks b0i bi b0j bj
allow ordering removed. iteration, constraints checked order
beginning plan. block, added bdp , removed
387

fiSiddiqui & Haslum

Algorithm 1 Resolve ordering constraints pair blocks.
1: procedure Resolve(bi , bj )
2:
Initialise b0i = bi , b0j = bj .
3:
Re(b0i b0j ) 6=
4:
r Re(b0i b0j )
5:
r = PC(p)
// try Rule 1
6:
Find responsible step b0i nearest s0 6 b0i consumes
p s0 + s.
7:
s0 exists
8:
Set b0i = b0i {s0 } Intermediate(s0 , b0i ).
9:
else return null
10:
else r = DP(p)
// try Rule 4
11:
Find responsible step b0j s0 6 b0j
hs, p, s0 causal link.
12:
s0 exists
13:
Set b0j = b0j {s0 } Intermediate(b0j , s0 ).
14:
else return null
15:
else r = CD(p)
// try Rule 3
16:
Find responsible step b0j nearest s0 6 b0j produces p,
+ s0 .
17:
s0 exists
18:
Set b0j = b0j {s0 } Intermediate(b0j , s0 ).
19:
else
// try Rule 2
20:
Find responsible step b0i nearest s0 6 b0i produces
p, s0 + s.
21:
s0 exists
22:
Set b0i = b0i {s0 } Intermediate(s0 , b0i ).
23:
else return null.
24:
Recompute Re(b0i b0j ).
25:

return (b0i , b0j ).

accommodate another block partially overlaps existing block throughout
procedure, even later (rejected) block could produce deordering one
created earlier. Since choice deordering apply greedy, result guaranteed
optimal. b0i b0j cannot added decomposition (because one
partially overlaps existing block), consider blocks ordered immediately
bi , check orderings broken simultaneously, using union
blocks returned Resolve ordering constraint. (Symmetrically, check
set blocks immediately bj , though rarely useful.) additional
388

fiContinuing Plan Quality Optimisation

heuristic, discard two blocks basic ordering constraint step
internal one blocks (i.e., preceding following steps within
block) step outside block.
ordering removed, inner loop exits ordering relation updated
new constraints b0i blocks ordered bj b0j blocks
ordered bi . done checking three reasons (PC, CD DP) based
sets propositions produced, consumed deleted b0i b0j . inner loop
restarted, ordering constraints previously could broken checked
again. done removing ordering constraints make possible resolution
constraints, since removal orderings change set steps intermediate
two steps.
main loop repeats deordering consistent current decomposition found. iteration runs polynomial time, know upper
bound number iterations. Note, however, procedure anytime,
sense interrupted running completion, result end last completed iteration still block deordering plan. BDPO2, use time-limit 5
minutes whole deordering procedure. However, almost every problem considered
experiments (described Section 3.1), block deordering finishes seconds
(except problems Visitall domain, takes couple minutes).
summary, deordering makes structure plan explicit, showing us parts
necessarily sequential (because dependency interference) independent non-interfering. Block deordering improves creating on-the-fly
hierarchical decomposition plan, encapsulating dependencies interferences
within block. Considering blocks, instead primitive actions, units partial
ordering thus enables deordering plans greater extent, including cases deordering possible using standard, step-wise, partial order plan notion. impact
block decomposition anytime performance plan quality optimisation system
discussed Section 3.6.

3. System Overview
BDPO2 post-processing-based plan quality optimisation system. Starting initial
plan, seeks optimise parts plan, i.e. subplans, replacing lower-cost
subplans. refer subplans candidates replacement windows.
better plan found certain conditions met, starts new
plan. viewed local search, using large neighborhood search (LNS)
strategy, neighborhood plan defined set plans
reached replacing window new subplan. local search plain hill-climbing:
move strictly better neighbouring plan. LNS algorithms, searching
better plan neighbourhood done formulating local optimisation problems,
solved using bounded-cost subplanners.
Block deordering, described previous section, helps identify candidate windows
providing large set possible plan linearisations; block decomposition used
windowing strategies. window subsequence linearisation
block deordered input plan. However, represent window slightly different
389

fiSiddiqui & Haslum

way, partitioning blocks part replaced (w), ordered
(p) (q) part.
Definition 8. Let bdp = (S, B, ) block decomposed p.o. plan. window bdp
partitioning B sets p, w, q, bdp linearisation consistent
{bp bw bq | bp p, bw w, bq q}.
window defines subproblem, problem finding plan
fill gap left removing steps w linearisation bdp consistent
window. problem formally defined follows.
Definition 9. Let bdp = (S, B, ) block decomposed p.o. plan planning problem
, hp, w, qi window bdp , s1 , . . . , s|p| , s|p|+1 , . . . , s|p|+|w| , s|p|+|w|+1 , . . . , sn linearisation bdp consistent window. subproblem corresponding hp, w, qi,
sub , atoms actions . initial state sub , Isub , result
progressing initial state s1 , . . . , s|p| (i.e., applying s1 , . . . , s|p| I),
goal sub , Gsub , result regressing goal sn , . . . , s|p|+|w|+1 .
Theorem 7. Let bdp = (S, B, ) block decomposed p.o. plan planning problem , hp, w, qi window bdp , sub subproblem corresponding window,
s1 , . . . , s|p| , s|p|+1 , . . . , s|p|+|w| , s|p|+|w|+1 , . . . , sn linearisation sub constructed
0
0
0 = s0 , . . . , s0 plan
from. Let w
sub . s1 , . . . , s|p| , s1 , . . . , sk , s|p|+|w|+1 , . . . , sn
1
k
valid sequential plan .
Proof. proof straightforward. subsequence s1 , . . . , s|p| applicable initial
state , I, and, construction sub , results initial state sub , Isub . Hence
s1 , . . . , s|p| , s01 , . . . , s0k applicable I, and, construction sub , results state
sG satisfies goal sub , Gsub . Since Gsub result regressing goal ,
G, s|p|+|w|+1 , . . . , sn reverse, follows subsequence applicable sG ,
applying results state satisfying G. (For relevant properties regression,
see, example, Ghallab, Nau, & Traverso, 2004, Section 2.2.2.)
subproblem corresponding window hp, w, qi always solution, form
linearisation steps w. improve plan quality, however, replacement
subplan must cost strictly lower cost w, C(w). amounts
solving bounded-cost subproblems. subplanners used BDPO2
described Section 3.3. return question multiple windows
within plan simultaneously replaced Section 3.5.
Algorithm 2 describes BDPO2 performs one step local search, exploring
neighbourhood current plan. first step block deorder current plan
(line 3). Next, optimisation using bounded-cost subplanner tried systematically
candidate windows (lines 419), restart condition met (line 18),
local improvements possible, time limit reached. point difference
LNS algorithms used delayed restart, meaning exploration
neighbourhood continue better plan found. helps avoid
local minima, driving exploration different parts current plan. restart
conditions, impact local search, described Section 3.4.
390

fiContinuing Plan Quality Optimisation

Algorithm 2 neighbourhood exploration procedure BPDO2.
1: procedure BDPO2(in , tlimit , banditPolicy, rankPolicy, optSubprob)
2:
Initialize: telapsed = 0, last = , trialLimit[1...n] = 1, windowDB =
3:
bdp = BlockDeorder(in )
4:
telapse < tlimit last locally optimal
5:
windows needed
6:
ExtractMoreWindows(bdp , windowDB, optSubprob)
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:

p = SelectPlanner(banditPolicy)
w = SelectWindow(p, rankPolicy, trialLimit, windowDB)
w = null windows extract trialLimit[p] += 1
w = null continue
wnew , searchResult = OptimiseWindow(p, w)
UpdateWindowDB(p, w, wnew , optSubprob, searchResult, windowDB)
C(wnew ) < C(w)
new = Merge(bdp , windowDB)
C(new ) < C(last ) last = new
UpdateBanditPolicy(p, w, wnew , searchResult, banditPolicy)
UpdateRankPolicy(p, searchResult, rankPolicy)
C(last ) < C(in ) restart condition true
return BDPO2 (last , tlimt telapsed , banditPolicy, rankPolicy, optSubprob)
return last

key design goal procedure avoid unproductive time, meaning spending
much time one step trying optimise one window options could
lead improvement left waiting. Therefore, steps done incrementally,
time limit step could take unbounded time.
database (windowDB) stores unique window extracted block deordered
plan, records status (how many times optimisation window tried
subplanner result), structural summary information window. window database populated incrementally (lines 56), applying different
windowing strategies limit time spent number windows added.
limits used 120 seconds 20 windows, respectively. balances time
window extraction optimisation, prevent procedure spending unproductive time. windowing strategies described Section 4. compute lower
bound cost replacement plan window, using admissible LM-Cut
heuristic (Helmert & Domshlak, 2009). window proven optimal current subplan cost equals bound, previous attempt optimise window exhausted
bounded-cost search space. Already optimal windows are, course, excluded
optimisation. windows added database number windows eligible selected optimisation one subplanner (defined next paragraph)
drops threshold. used 75% current window database size
threshold.
391

fiSiddiqui & Haslum

subplanner use selected using UCB1 multi-armed bandit policy (Auer et al.,
2002), learns repeated trials select often subplanner succeeds
often finding improvements. next window try chosen, among eligible
ones database, according ranking policy. Windows eligible optimisation
chosen subplanner (1) already proven optimal; (2)
tried chosen subplanner current trial limit; (3) overlap
improved window already found. ranking policy heuristic aimed selecting
windows likely improved chosen subplanner. use several ranking
policies switch one next subplanner fails find improvement
number consecutive tries, since indicates current ranking policy may
recommending right windows current problem. threshold used
switching ranking policy 13. (This 2/3 maximum number windows added
window database call ExtractMoreWindows.) ranking policies
described Section 4.6. subplanner given time limit, increased time
retried window. used limit 15 seconds, increasing another
15 seconds retry. limit number times retried
window kept subplanner. Initially set 1, limit increased
subplanner tried every window database (excluding windows
already proven optimal overlap windows better replacement
found) strategy generate new windows (line 9). lower-cost
replacement subplan window found, together improvements already
found current neighbourhood fed Merge procedure, tries
combine several replacements achieve greater overall plan cost reduction. Merge
procedure described Section 3.5.
procedure restarts new best plan, learned bandit policy subplanner selection current ranking policy (for subplanner) carried
next iteration. keep database subproblems (defined initial
state goal) whose plan cost proven optimal, avoid trying fruitlessly optimise further. window database, contains information specific
current input plan, reset.
remainder section organised follows: next two sections describe
settings used experiments overview main results, respectively.
describe subplanners used BDPO2 (Section 3.3), restart conditions
(Section 3.4) Merge procedure (Section 3.5). Section 3.6 discusses impact
block deordering performance system. windowing strategies ranking
policies described Section 4, details on-line adaptation methods
used presented Section 5.
3.1 Experiment Setup
presenting overview results, outline three different experimental
setups used. experiment setup 2 3 used 182 large-scale instances
21 IPC domains. selection domains instances described below.
experiment 1, included additional medium-sized instances total 219 instances
21 domains. used domains sequential satisficing track
392

fiContinuing Plan Quality Optimisation

2008, 2011, 2014 IPC, except CyberSec, CaveDiving CityCar domains.
(The CyberSec domain slow system parse. two conditional
effects, implementation handle.) used Alarm Processing
Power Networks (APPN) domain (Haslum & Grastien, 2011). plans used input
BDPO2 plan produced IBaCoP2 (Cenamor, de la Rosa, & Fernandez, 2014)
2014 IPC problems competition, best plan found LAMA
(Richter & Westphal, 2010, IPC 2011 version) 1 hour CPU time problems.
refer base plans. experiments 2 3, selected domain
10 last instances base plan exists. (In domains less 10 instances
solved LAMA/IBaCoP2, total 182 rather 210.) domains
appeared one competition, used instances IPC 2011 set.
experiments run 6-Core, 3.1GHz AMD CPUs 6M L2 cache, 8
GB memory limit every system. comparing anytime performance BDPO2
systems require input plan, count time generate base plan
1 hour CPU time. maximum time allocated generating base plan;
found much quickly.
first experiment, use BDPO2 system. Instead, ran two
subplanners, PNGS IBCS, 30 seconds every subproblem corresponding
window extracted (by six windowing strategies) base plans, excluding
subproblems window proven optimal lower bound obtained
admissible LM-Cut heuristic (Helmert & Domshlak, 2009). experiment provided
information inform design combined window extraction procedure, window
ranking policies, aspects system. present results here,
refer later discuss system components detail.
experiment 2, compare BDPO2 eight anytime planners plan optimisation systems: LAMA (Richter & Westphal, 2010, IPC 2011 version); AEES (implemented
Fast Downward code base; cf. Thayer et al., 2012b); IBCS (as described Section
3.3); Beam-Stack Search (BSS) (Zhou & Hansen, 2005); PNGS, including Action Elimination (Nakhost & Muller, 2010); IBaCoP2 (Cenamor et al., 2014); LPG (Gerevini &
Serina, 2002); Arvand (Nakhost & Muller, 2009). BDPO2 uses PNGS IBCS
subplanners, configured described above. AEES uses LM-Cut (Helmert & Domshlak, 2009) admissible heuristic, heuristic, without action costs
inadmissible estimates. BSS uses LM-Cut heuristic. implementation BSS
use divide-and-conquer solution reconstruction, run beam width
500. systems described Section 6.
system run 7 hours CPU time per problem. BDPO2 PNGS
use base plans input, IBCS Beam-Stack Search use base
plan cost initial cost bound. mentioned above, allocated 1 hour CPU time
generating base plan. Therefore, comparing systems planners
starting scratch (LAMA, AEES, IBaCoP2, LPG Arvand), add 1 hour start
delay runtime. Beam-Stack Search much slower planners used
experiment. Therefore, ran 24 hours CPU time, reporting
results divide runtime 4. words, results shown hypothetical
implementation Beam-Stack Search amount search, faster
constant factor 4.
393

fiSiddiqui & Haslum

Experiment 3 uses setup experiment 2, except input BDPO2
best plan found running PNGS 1 hour CPU time, 8 GB memory
limit, base plans. (As mentioned previously, vast majority cases PNGS runs
memory much less time that, cases run 1 hour
limit.) use setup primarily run different configurations BDPO2 analyse
impact different designs (e.g., planner selection window ranking policies,
immediate vs. delayed restart, on) setting input plans already good
quality. comparing anytime result BDPO2 experiment
systems, add 2 hours runtime.
3.2 Overview Results
Figure 11 shows headline result, form average plan quality achieved
BDPO2 systems time-per-problem increases. IPC quality score plan
calculated cref /c, c cost plan cref cost best plan
problem instance found runs systems used experiments. Thus,
higher score reflects lower-cost plan. results Figure 11 experiment 2
3, described previous section. shown Figure 2 (on page 371),
including results compared anytime planning systems. None planners
starting scratch find solution 182 problems: LAMA solves 155 problems,
IBaCoP2 144, Arvand 134, AEES 87 LPG 49. planners, average quality
score shown Figure 11 average problems have,
time, found least one plan. (As previously mentioned, reason
average quality sometimes falls: first plan, low quality, previously unsolved
problem found, average decrease.) words, metric unaffected
differences coverage. Likewise, none post-processing bounded cost search
methods improve base plans: BDPO2 finds plan lower cost base plan
147 problems, PNGS 133, IBCS 66 Beam-Stack Search 14.
systems, average quality shown Figure 11 taken 182 problems, using
base plan quality score problems system improved on.
majority compared systems show trend similar LAMA, i.e.,
improving quickly early flattening ultimately stagnating. reasons
vary: Memory limiting factor algorithms, notably PNGS, exhausts
8 GB available memory reaching 7 hour CPU time limit 93.7% problems,
LAMA, 67% problems. AEES runs memory
50% problems. hand, planners use limited-memory algorithms,
Beam-Stack Search, LPG Arvand (both use local search), never run
memory thus could conceivably run indefinitely. However, rate
find plan quality improvements small: 4 7 hours, average quality produced
LPG Arvand increases 0.0049 0.0094, respectively. (The latter excludes three
problems solved Arvand first time 4 7 hours; including
brings average down, making increase less 0.002.) increase average
quality achieved BDPO2, starting high-quality plans generated PNGS
base plans, time interval 0.0115.
394

fiContinuing Plan Quality Optimisation

0.96
0.94
0.92


Average Quality Score (Relative IPC Quality Score / Coverage)

0.9













































































































































0.88
0.86



0.84





0.82
0.8
0.78
0.76
0.74
0.72
0.7
0.68
0.66
0.64



0.62



BDPO2 PNGS base plans
BDPO2 base plans
PNGS base plans
IBCS base plans
BSS base plans
LAMA scratch
AEES scratch
IBaCoP2 scratch
Arvand scratch
LPG scratch

0.6
0.58



0.56
0.54










































































7

6.5

6

5.5

5

4.5

4

3.5

3

2.5

2

1.5



0.5



0

0.5



1

0.52





Time (hours)

Figure 11: Average IPC quality score function time per problem, set 182
large-scale planning problems. quality score plan cref/c, c cost
plan cref least cost plans problem; hence higher score represents
better plan quality. LAMA, AEES, LPG, Arvand IBaCoP2 planners start
scratch, whereas post-processing (PNGS, BDPO2) bounded cost search (IBCS,
Beam-Stack Search) methods start set base plans; curves delayed 1
hour, maximum time allocated generating base plan. experimental
setup described detail Section 3.1.

395

fiSiddiqui & Haslum

BDPO2
BDPO2
PNGS
= < ? = < ?
Appn
50
20 40
10
Barman
100 90
10
Childsnack
100 30
70
Elevators
60 60
10 10
Floortile
67
78 22
GED
30
20
Hiking
50
70 20
Maintenance 100
100
Nomystery
100
100 100
100
Openstacks
Parcprinter
100
22 100
22
43
43 14
Parking
Scanalyzer
75 12
38 12
Sokoban
100
100
Tetris
80 40
60 20
Thoughtful
80 30
50 20
Tidybot
43
29
Transport
60 60
40 40
Visitall
60 60
30 30
Woodworking 70 30
50 20
Overall
66 24 4 47 12 3
Domains

LAMA

AEES

Arvand

LPG

IBCS

BSS

PNGS

IBaCoP2

= < ? = < ? = < ? = < ? = < ? = < ? = < ? = <
40
10
40
10 70 20 20

?

10
10

10
11

80 70
40 30

20 20
11 11

10

33

10
50
29

50

50 50

33

11

50

50

50 50

50

22 33

67

22

88 88
11 33

43 43

20
71 29

33

33

43

43

12 12
67
11
29
75 12
67

29 14

10

12

14

10 10
18 14

8

1

1

1

2

1

8

1 12 2 3 13 1

20 10
8 2

1

Table 1: plan improvement method, percentage instances found
plan cost matching best plan (=); found plan strictly better method
(<); found plan known optimal, i.e., matched highest lower bound
(?). percentage instances domain shown Figure 12. (Zeros
omitted improve readability.) BDPO2 PNGS result BDPO2 experiment
3; results experiment 2 (see Section 3.1).

draw two main conclusions: First, BDPO2 achieves aim continuing quality
improvement even time limit grows. fact, continues find better plans, though
decreasing rate, even beyond 7 hour time limit used experiment. Second,
combination PNGS BDPO2 achieves better result either alone. Partly
work well different sets problems figure showing
average, BDPO2 sometimes produces better result started best plan
found PNGS domains BDPO2 already outperforms PNGS start
base plans (e.g., Elevators Transport). However, seen
opposite domains (e.g., Floortile Hiking), starting BDPO2 worse
input plan often yields better final plan. seen Figure 12, provides
detailed view. shows problem cost best plan found
system 7 hour total time limit, scaled interval base plan cost
highest known lower bound (HLB) plan problem. (Lower bounds
obtained variety methods, including several optimal planners; cf. Haslum,
2012.) 18 182 problems excluded Figure 12: 3 cases, base plan cost
already matches lower bound, improvement possible; another 15 problems,
method improves base plans within stipulated time. (The Pegsol domain
appear graph, base plans one optimal, method
improves cost last one.)
396

fiContinuing Plan Quality Optimisation

Base Plans









































Best cost achieved (normalised)



































Nomystery

Maintenance

Ged

Floortile

Barman

Hiking



Elevators



Childsnack



Appn

HLB







LAMA scratch
AEES scratch
Arvand scratch
LPG scratch
IBaCoP2 scratch
PNGS base plans
IBCS base plans
BSS base plans
BDPO2 base plans
BDPO2 PNGS base plans

Base Plans




































Best cost achieved (normalised)

































HLB



LAMA scratch
AEES scratch
Arvand scratch
LPG scratch
IBaCoP2 scratch
PNGS base plans
IBCS base plans
BSS base plans
BDPO2 base plans
BDPO2 PNGS base plans
Woodworking

Visitall

Transport

Tidybot

Thoughtful

Tetris

Sokoban

Scanalyzer

Parking

Parcprinter

Openstacks





Figure 12: Best plan cost, normalised interval cost base plan
corresponding highest known lower bound, achieved different anytime plan
optimisation methods experiment 2, BDPO2 experiments 2 & 3 (see Section
3.1).

397

fiSiddiqui & Haslum

Table 1 provides different summary information Figure 12, showing
domain system percentage instances found plan cost (1)
matching best plan instance; (2) strictly better method;
(3) matching lower bound, i.e., known optimal. aggregate, combination
BDPO2 PNGS base plans achieves best result three measures.
However, 5 domains (GED, Hiking, Openstacks, Parking, Tidybot), LAMA finds
plans strictly better method. tried using LAMA
one subplanners BDPO2, lead better results overall.
domains, OpenStacks GED, smallest improvable subplan often whole,
almost whole, plan, LAMA finds improvement plan searching
longer time. Although BDPO2 increases time limit given subplanners
retry, average time limit, across local optimisation attempts experiment,
18.48 seconds. Thus, strategy searching quick improvements plan parts
work well domains.
3.3 Subplanners Used Window Optimisation
subplanners used BDPO2 used find plan window subproblem,
stated Definition 9, cost less cost current window, C(w).
considered three subplanners:
(1) Iterated bounded-cost search (IBCS), using greedy search admissible heuristic pruning.
(2) Plan neighbourhood graph search (PNGS), including action elimination technique (Nakhost & Muller, 2010).
(3) Restarting weighted A? (Richter et al., 2010), implemented LAMA planner.
However, experimental setups described previous section, BDPO2 uses
two subplanners, IBCS PNGS. two reasons choosing two: First,
show good complementarity across domains. example, IBCS significantly better PNGS APPN, Barman, Floortile, Hiking, Maintenance, Parking, Sokoban,
Thoughtful Woodworking domains, PNGS better Elevators, Scanalyzer,
Tetris, Transport Visitall domains. Second, learning policy use subplanner selection learns faster smaller number options. Therefore, adding third
subplanner improve overall performance BPDO2, given limited time per
problem, subplanner complements two well, i.e., performs well
significant fraction instances two not. set benchmark
problems used experiment, case. (A different set benchmarks
could course yield different outcome.) experiment comparing effectiveness
three subplanners, individually well combination IBCS PNGS
learning policy, BDPO2 presented Section 5.2 page 420.
solve bounded-cost problem, IBCS uses greedy best-first search guided
unit-cost heuristic, pruning states cannot lead plan within cost bound
using f-value based admissible LM-Cut heuristic (Helmert & Domshlak, 2009).
implemented Fast Downward planner. search complete: plan
398

fiContinuing Plan Quality Optimisation

within cost bound, prove exhausting search space, given sufficient
time memory. bounded-cost search return plan within cost
bound. get best subplan possible within given time limit, iterate it: whenever
plan found, long time remains, search restarted bound set
strictly less cost new plan.
PNGS (Nakhost & Muller, 2010) plan improvement technique. searches subgraph state space around input plan, limited bound number states,
lower cost plan. better plan found exploration limit increased (usually
doubled); continues time memory limit reached. IBCS,
iterate PNGS get best subplan possible within given time limit. improves
current subplan, process repeated around new best plan.
LAMA (Richter & Westphal, 2010) finds first solution using greedy best-first search.
switches RWA? (Richter et al., 2010) search better quality solutions.
3.4 Restart
restart condition determines trade-off exploring neighbourhood
current solution continuing local search different parts solution space.
obvious choice, one used LNS algorithms, restart
new best solution soon one found. call immediate restart. However,
found continuing explore neighbourhood current plan even better
plan found, merging together several subplan improvements, described
Section 3.5 below, often produces better results. call delayed restart.
Setting right conditions make delayed restart critical success
approach. used disjunction two conditions: First, union
improved windows found neighbourhood covers 50% steps input plan.
Recall continue exploration loop (Algorithm 2) improvement
found, windows overlap already improved window excluded
optimisation. drives procedure search improvements different
parts current plan, helps avoid certain myopic behaviour occur
immediate restarts: restarting new best plan, get new block
decomposition new set windows; lead attempting re-optimise
part plan improved, even several restarts, may lead
local optimum time-consuming escape. second condition 39 consecutive
subplanner calls failed find improvement. threshold 39 three
times threshold switching ranking policy (cf. description Algorithm 2
beginning section). means 39 attempts tried optimise
13 promising windows, among remaining eligible ones, recommended
ranking policies, without success. suggests improvable windows
found, none ranking policies good current neighbourhood.
Making restart point allows exploration return parts plan
intersect already improved windows, thus increasing set eligible windows.
average plan quality, function time-per-problem, achieved BDPO2 using
immediate restart delayed restart based conditions shown top
two lines Figure 13 (page 403). experiment, configurations run using
399

fiSiddiqui & Haslum

Algorithm 3 Merge Improved Windows
1: procedure Merge(bdp , windowDB)
2:
Initialise bdp = bdp
3:
W = improved windows windowDB sorted cost reduction (C(w) C(wnew ))
4:
W 6=
5:
(hp, w, qi, wnew ) = pop window highest C(w) C(wnew ) W
6:
bdp = ReplaceIfPossible(bdp , hp, w, qi, wnew )
7:
W = RemoveConflictingWindows(W, bdp )
8:

return bdp

setup experiment 3, described Section 3.1 page 392. seen,
delayed restart yields better results overall. Compared BDPO2 immediate restart,
achieves total improvement 12% higher. However, found immediate restart
work better instances, especially Visitall Woodworking domains,
BDPO2 immediate restart found better final plan nearly 20% instances.
average number iterations (i.e., steps LNS) done BDPO2 using
delayed restart condition 3.48 per problems across domains considered
experiment; highest average single domain 8.7, Thoughtful solitaire.
immediate restart average domains increases 4.87. words,
configurations BDPO2 spend significant time exploring neighbourhood plan.
anytime performance curve Figure 13 shows additional time spent
neighbourhood using delayed restarts pays off.
3.5 Merging Improved Windows
Delayed restarting would benefit without ability simultaneously replace
several improved windows current plan. improved windows always nonoverlapping (because better subplan window found, windows overlap
longer considered optimisation) corresponding subproblems may
generated different linearisations block deordered plan.
this, replacement subplans may additional preconditions delete effects
replaced windows not, lack add effects. Thus, may
linearisation permits two windows simultaneously replaced.
Merge procedure shown Algorithm 3 greedy procedure. maintains
times valid block deordered plan (bdp ), meaning precondition block
supported causal link active threat. (Recall block context
block consists single step.) Initially, input plan (bdp ),
causal links, ordering constraints, computed block deordering.
procedure gets improved windows (W ) window database, tries replace
current plan bdp order contribution decreasing plan cost, i.e.,
cost replaced window (C(w)) minus cost new subplan (C(wnew )).
first replacement always succeeds, since, construction subproblem,
linearisation input plan wnew valid (cf. Theorem 7). Subsequent
replacements may fail, case Merge proceeds next improved window W .
400

fiContinuing Plan Quality Optimisation

Since replacing window different subplan may impose new ordering constraints,
remaining improved windows conflict partial order current plan
removed W .
ReplaceIfPossible function takes current plan (bdp ), returns updated plan (which becomes current plan), plan replacement
possible. replacement subplan (wnew ) made single block whose steps totally ordered. preconditions effects block, replaced window
(w), computed according Definition 5 (page 378). atom pre(wnew )
w, existing causal link kept; likewise, causal links effect add(w)
add(wnew ) kept. links unthreatened consistent
order, since plan valid replacement. additional precondition
new subplan, pre(wnew ) \ pre(wi ), causal link hbp , m, bc bdp
producer replaced window (bp w), consumer (bc 6 w),
atom link produced replacement subplan (m 6 add(wnew )), new
causal link must found. Given consumer (bc ) atom requires (m pre(bc )),
procedure tries following two ways creating unthreatened causal link:
(C1) block b0 + bc add(b0 ), every threatening block (i.e.,
b00 del(b00 )), either b00 b0 bc b00 added existing plan ordering
without contradiction, b0 chosen, ordering constraints necessary resolve
threats (if any) added.
(C2) Otherwise, block b0 add(b0 ) unordered w.r.t. bc ,
every threatening block either b00 b0 bc b00 enforced, b0 chosen,
causal link (implying new ordering b0 bc ) threat resolution ordering constraints
(if any) added plan.
two tried order, C1 first C2 C1 fails. neither rule find
required causal link, replacement fails. wnew may threaten existing causal
links bdp w not. threatened link, hbp , m, bc i, procedure tries
resolve threat three ways:
(T1) consumer bc ordered w linearisation corresponding
subproblem (bc p), bc wnew consistent, threat removed adding
ordering.
(T2) producer bp ordered w linearisation corresponding subproblem (bp q), wnew bp consistent, threat removed adding ordering.
(T3) new, unthreatened causal link supplying bc found one two
rules C1 C2 above, threatened link replaced new causal link.
rules tried order, none resolve threat, replacement
fails.
non-basic ordering constraints blocks w may disappear w
replaced wnew ; likewise, ordering constraints w rest
plan may become unnecessary, wnew may delete every atom w deletes
may preconditions w, thus removed. may make pairs
blocks b, b0 plan ordered replacement unordered, thus create
new threats. new threats checked ReplaceIfPossible, found
resolved restoring ordering constraint lost.
401

fiSiddiqui & Haslum

Lemma 8. current plan bdp valid, wnew solves subproblem corresponding
window hp, w, qi, plan returned ReplaceIfPossible valid.
Proof. procedure ensures every precondition every step supported causal
link active threat: link either existed plan replacement (and
new threats created replacement resolved ordering constraints),
added procedure. Thus, replacement succeeds, resulting plan valid
according Theorem 2. replacement fails, plan returned current plan,
bdp , unchanged, valid assumption.
Theorem 9. input plan, bdp valid, plan returned Merge.
Proof. Immediate Lemma 8 induction sequence accepted replacements.

3.6 Impact Plan Decomposition
neighbourhood explored step LNS BDPO2 defined substituting
improved subplans current plan. subplan considered local optimisation
subsequence linearisation block deordering current plan. Obviously,
restrict windows consecutive subsequences totally ordered input
plan; fact, similar approaches plan optimisation adopted restriction (Ratner
& Pohl, 1986; Estrem & Krebsbach, 2012; Balyo, Bartak, & Surynek, 2012). section,
address question much block deordering contributes performance
BDPO2.
preliminary experiment (setup 1, described Section 3.1 page 392)
observed 75% subproblems improved subplan found
correspond non-consecutive part sequential input plan. However, prove optimising 25% subplans found without
deordering would lead equally good end result.
Therefore, conducted another experiment, using setup experiment 3 (described Section 3.1). experiment, ran BDPO2 separately different degrees
plan decomposition: (1) block deordering (as default BDPO2 configuration,
one used experiments 2 3 presented Section 3.2 page 394). (2) standard, i.e., step-wise, plan deordering only. configuration, used Kambhampati
Kedars (1994) algorithm (described Section 2.3) plan deordering. (3) Without
deordering, i.e., passing totally ordered input plan directly LNS process.
addition, configurations run immediate restarting
delayed restarting, described Section 3.4.
Figure 13 shows average IPC plan quality score function time-per-problem
achieved configurations BDPO2. shows simple clear picture:
immediate restart, LNS applied block deordered plans outperforms LNS applied
step-wise deordered plans, turn outperforms use totally ordered plans.
total improvement, measured increase average IPC plan quality score,
achieved BDPO2 without deordering 28.7% less achieved best
configuration. see deordering enabler delayed restarting:
block step-wise deordering, delayed restarting boosts performance LNS
402

fiContinuing Plan Quality Optimisation

0.962












0.958








0.954







0.95



0.946










0.942






















0.938









0.934



0.93

6

5.5

5

4.5

1

0.5

0

0.922

4



3.5



3



0.926

BDPO2 delayed restart block deordered plans
BDPO2 immediate restart block deordered plans
BDPO2 delayed restart standard partially ordered plans
BDPO2 immediate restart standard partially ordered plans
BDPO2 delayed restart totally ordered plans
BDPO2 immediate restart totally ordered plans
2.5



2




1.5

Average Quality Score (Relative IPC Quality Score / Coverage)



Time (hours)

Figure 13: Average IPC quality score function time per problem BDPO2 applied
totally ordered input plan; standard (step-wise) deordering plan;
block deordering plan. plan type, system run two configurations: delayed restarting immediate restarting (cf. Section 3.4
page 399). experiment run setup 3, described Section 3.1 page 392.
time shown runtime BDPO2 (i.e., without 2 hour delay
generating input plans, shown Figure 11). Note y-axis truncated:
curves start average quality input plans, 0.907.

403

fiSiddiqui & Haslum

plan optimisation 12% 14.7%, respectively, totally ordered plans
significant effect.
Deordering increases number linearisations therefore enables many
distinct candidate windows created. However, recall BDPO2s neighbourhood
exploration procedure (Algorithm 2) interleaves incremental window generation optimisation attempts; many windows could generated current plan may
never generated restart occurs. Thus, average number windows generated
iteration reflect difference performance. (With block deordering,
average number windows generated 277.23, 183.19 remain filtering,
totally ordered plans 376.8, 149.94 filtering; using immediate
restart.) deordering helps windowing strategies generate windows
easily optimised. Recall neighbourhood exploration retry subplanner
window (with higher time limit) windows tried
subplanner. average number optimisation attempts, using either subplanner,
window selected optimisation least once, around 1.7 either block deordering
standard deordering used input plan. Without deordering, however,
average number attempts higher, high domains: leaving
highest 5% neighbourhoods encountered, average slightly 2;
10% plan neighbourhoods average number attempts 5,
cases 10. words, generating windows totally ordered plan
causes procedure spend, average, time window improving
plan found.
hand, noted Section 3.2, domains subplanners need
runtime find better plans improvable windows, BDPO2 configuration without
deordering find better plan default configuration 26 182 problems.
current BDPO2 system, subplanner time limit increased window
retried. procedure either attempts candidate windows likely improved
(for example, indicated window ranking policies described Section 4.6)
frequently, varies amount time given optimise window may perform better.
optimal amount deordering plan may well different problem problem. averaged across set benchmark problems, deordering
unarguably better none.

4. Windowing Strategies Ranking Windows
window subplan linearisation block deordered plan, extracted order
attempt local optimisation. section describes strategies use generate
rank windows, experimental evaluation impact systems performance.
Recall Definition 8 (page 390) window represented triple hp, w, qi,
w set blocks replaced, p q sets blocks ordered
w, respectively, linearisation. block decomposed p.o. plan
many linearisations, producing many possible windows typically far many
attempt optimise all. windowing heuristic procedure extracts reduced
set windows, hopefully including promising ones, systematic way.
404

fiContinuing Plan Quality Optimisation

Figure 14: block deordered plan transformation extended blocks: blocks b1
b3 merged single block, blocks b5 b6.

Windowing heuristics
Rule-based
Cyclic thread
Causal followers

Generated
Basic
Ext.
108
35
59
47
72
45

filtered
Basic
Ext.
59
22
45
31
41
20

Improved
Basic
Ext.
23
9
15.5
11
15.5
7

Impr./Gen.
Basic
Ext.
0.21
0.26
0.26
0.23
0.22
0.16

Table 2: total number (in thousands) windows generated, filtered out,
finally improved, using different windowing heuristics different block types (basic
extended). number possible windows sequential input plans,
even considering deordering, 1.47 million. rightmost pair columns shows
rate success, meaning fraction improved windows generated windows.
numbers results experiment 1 (described Section 3.1 page 392).
present three windowing heuristics, called rule-based, cyclic thread, causal followers
heuristics. described detail following subsections.
heuristic applied two types block basic extended one time.
Basic blocks blocks generated block deordering. (For purpose windowing,
step included block created block deordering considered
block own.) Extended blocks created merging basic blocks block
deordered plan form complete non-branching subsequences. block bi
immediate predecessor block bj , bj immediate successor bi ,
merged one extended block. Algorithm 4 shows procedure extended block
formation. (IP(b) denotes set bs immediate predecessors, IS(b) bs immediate
successors.)
Algorithm 4 Computing extended blocks.
1: Bext Bbasic
2: bi , bj Bext : IP(bj ) = {bi }, IS(bi ) = {bj }
3:
Bext Bext {bi bj } \ {bi , bj }
process illustrated example Figure 14. Note blocks b5
b2 merged one extended block. although b5
immediate successor b2, b2 immediate predecessor b5. Extended blocks
useful allow windowing heuristics capture larger windows.
experiment results show windows different sizes useful different domains:
405

fiSiddiqui & Haslum

Algorithm 5 Extract Candidate windows
/* global array strategy[1..6] stores state windowing strategy */
1: procedure ExtractMoreWindows(bdp , windowDB, optSubprob)
2:
W =
3:
tlimit = initial time limit Tincrement
4:
telapsed < tlimit |W | < nWindowsLimit
5:
= NextWindowingStrategy()
6:
= null break /* windowing strategies exhausted */
7:
W = strategy[i].GetWindows(bdp , windowDB, optSubprob,
nWindowsLimit |W |, tlimit telapsed )
8:
telapsed tlimit W = tlimit += Tincrement
9:

windowDB.Insert(W )

example, larger windows likely improved Pegsol, Openstacks
Parcprinter domains, optimising smaller windows better Elevators, Transport,
Scanalyzer Woodworking domains.
windowing strategy windowing heuristic applied block type. Thus, use
total six different strategies. strategies contributes improvable
windows generated strategies (cf. Section 4.4,
particular Table 3 page 411). Thus, are, sense, useful.
hand, size set windows generates fraction improvable
windows set varies strategies, sense useful
others.
Table 2 shows results first experiment, systematically tried two
subplanners (PNGS IBCS) every window generated (and filtered out)
windowing strategy 219 input plans. table shows total number (in thousands)
windows generated, remain filtering, finally improved
least one two subplanners. experiment, windows filtered
window cost matched lower bound given admissible LM-Cut heuristic
(Helmert & Domshlak, 2009). experiment setup described Section 3.1 (on
page 392). first observation strategies selective. number
windows could potentially generated, even without considering deordering, i.e.,
taking subsequences totally ordered input plans, 1.47 million. Thus,
even prolific strategy generates less tenth possible windows. Second,
used rate success, meaning fraction windows generated improved
subplanners used experiment, order strategies. order
follows:
1. Rule-based heuristic extended blocks.
2. Cyclic thread heuristic basic blocks.
3. Cyclic thread heuristic extended blocks.
4. Causal followers heuristic basic blocks.
5. Rule-based heuristic basic blocks.
6. Causal followers heuristic extended blocks.
406

fiContinuing Plan Quality Optimisation

neighbourhood exploration procedure (Algorithm 2 page 391) adds windows
database incrementally, calling ExtractMoreWindows procedure shown
Algorithm 5. procedure selects next strategy try, cycling
order above, asks strategy generate specified number windows,
limited time. strategy keeps state (what part heuristic
applied part plan), next time queried resume
generating new windows. windows possible given strategy
generated, say strategy exhausted. windowing strategies discard (1)
windows known optimal, either cost matches lower bound
given admissible LM-Cut heuristic (Helmert & Domshlak, 2009),
stored set optimally solved subproblems, (2) windows overlap
already improved window. windows eligible optimisation (cf. Section 3),
generating redundant. selected strategy finishes without generating enough
windows time remains, next not-yet-exhausted strategy order queried,
on, either |W | = nWindowsLimit time up. windows generated,
strategies still exhausted, time limit increased.
4.1 Rule-Based Windowing Heuristic
first version BDPO (Siddiqui & Haslum, 2013b) used single windowing strategy,
based applying fixed set rules extended blocks. strategy complements new windowing heuristics well, kept BDPO2.
rule applied block b block deordered plan bdp selects set
blocks go replaced part (w) based relation b. ensure
window consistent block deordering (i.e., consistent linearisation,
stated Definition 8 page 390), blocks constrained ordered
blocks window must included. call intermediate blocks, formally
defined follows.
Definition 10. Let bdp = hS, B, block decomposed p.o. plan. intermediate
blocks B B IB(B) = {b | b0 , b00 B : b0 b b00 }.
Let b block bdp , let Un(b) set blocks ordered w.r.t. b,
IP(b) immediate predecessors b, IS(b) immediate successors. rules used
windowing heuristic are:
1. w0 {b}.
2. w0 {b} IP(b).
3. w0 {b} IS(b).
4. w0 {b} Un(b).
5. w0 {b} Un(b) IP(b).
6. w0 {b} Un(b) IS(b).
7. w0 {b} Un(b) IP(b) IS(b).
8. w0 {b} Un(b) IP({b} Un(b)).
9. w0 {b} Un(b) IS({b} Un(b)).
407

fiSiddiqui & Haslum

Figure 15: Window formation applying 1st rule rule-based windowing heuristic
block b1, i.e., w {b1}, p Un(b1). unordered block b2 placed
predecessor set. Note window optimised removing s3 step
causal link successors.

10. w0 {b} Un(b) IP({b} Un(b)) IS({b} Un(b)).
Given blocks selected one rules above, partitioning blocks hp, w, qi
made setting w = w0 IB (w0 ) assigning p block ordered
unordered w, q block ordered w. Figure 15 shows example
rule-based windowing, 1st rule applied block b1. Applied blocks,
rules produce duplicates; course, unique windows kept.
first rules, include fewer blocks, generally produce smaller windows,
later rules tend produce larger window (though exact relation, since
number actions block varies). heuristic applies rules block
block deordered plan bdp turn. Rules applied order 1,10,2,9,3,8,4,7,5,6, i.e.,
starting first, last, second, second last, on. blocks
ordered size (descending), ties broken order input plan (in opposite
direction extended blocks).
Recall ExtractMoreWindows repeatedly asks windowing strategy generate limited number windows. ordering blocks rules described helps
ensure heuristic generates varied set windows, including small
large, covering different parts current plan, time queried.
4.2 Cyclic Thread Windowing Heuristic
discover new windowing heuristics, noted key changes decomposed plan
structure frequently occur plan improved. One significant observation
multiple steps input plan add effects, steps together
steps necessarily ordered form subplan often im408

fiContinuing Plan Quality Optimisation

proved. call cyclic behavior. one experiment, found cycles type
either removed plan replaced different cycles 87%
improvements across domains. definition cyclic behavior based
individual atom. Intuitively, atom cyclic behavior multiple producers (as
defined below).
Definition 11. Let bdp = hS, B, block decomposed p.o. plan, Pm
set producers atom m, i.e., sPm add(s). cyclic behavior iff |Pm | > 1.
Note Pm contains init step sI iff I. However, since window never contains
initial step sI , candidate windows formed extended producers instead. step

/ {sI , sG } extended producer atom iff produces m, consumes
s0 6= sI produces ordered block deordered plan.
formal definition follows.
Definition 12. Let bdp = hS, B, block decomposed p.o. plan. step
extended producer atom iff
/ {sI , sG } and:
1. add(s)
2. pre(s) kS\sI add(k) + k.
order form candidate windows respect atom cyclic behavior,
first extract blocks contain least one extended producer atom m.
cyclic thread (cf. Definition 14) formed taking linearisation blocks,
consistent input plan.
Definition 13. Let bdp = hS, B, block deordering sequential plan seq ,
bx , B two blocks bx = . Let hbx , linearisation {bx , }.
hbx , consistent seq least one step bx appears step seq .
way linearise blocks consistent input plan clarified
following example. Assume bx : {sa , sc } : {sb , sd } two blocks
linearise, orderings constituent steps input plan
sa sb sc sd . linearisation starts block contains first
element , i.e., bx case (since contains sa ); updated \bx ,
linearisation continues fashion empty. resulting linearisation
example blocks hbx , i. multiple (nested) blocks contain first element
, innermost one picked. formal definitions thread cyclic thread
follows.
Definition 14. Let bdp = hS, B, block deordering sequential plan seq , EPm
set extended producers atom m, Bm B set blocks,
element Bm contains least one element EPm . thread m, Tm ,
linearisation blocks Bm linearisation consistent seq . thread
called cyclic iff cyclic behavior.
example, plan shown Figure 15(i), atom (at t1 A) cyclic behaviour,
since holds initial state added step s3. extended producers s1, s3
s4, cyclic thread T(at t1 A) = hb1, b2i.
409

fiSiddiqui & Haslum

Finally, candidate windows formed taking consecutive subsequence blocks
(and intermediate blocks, necessary) cyclic thread. rule-based windowing,
blocks unordered respect window assigned set blocks
precede window.
Definition 15. Let Tm = b1 , ..., bk cyclic thread atom m. cyclic thread-based
windows cyclic thread Tm Wl,m = {B IB(B) | B = bi , ..., bi+l consecutive
subsequence Tm }, unordered blocks always placed predecessor set.
rule-based windowing heuristic, cyclic thread heuristic generates windows order aims ensure returns varied set windows time
called. first identifies cyclic threads block deordered plan generates
stream candidate windows one cyclic thread another. mentioned,
candidate window formed taking consecutive subsequence blocks (and intermediate blocks required form consistent window) cyclic thread. Given
thread |Tm | blocks, subsequences generated according following order sizes:
1, |Tm |, 2, |Tm | 1, . . . , |Tm |/2. words, subsequence lengths ordered
smallest, biggest, second smallest, second biggest, on. size
order, windows generated moving beginning end thread.
4.3 Causal Followers Windowing Heuristic
third strategy use obtain broader range potentially improvable
windows similar cyclic thread heuristic creates windows subsequences linearisation blocks connected particular atom, different
connections via causal links.
Definition 16. Let bdp = hS, B, block decomposed p.o. plan, c set
causal links . causal followers atom producer p CFhm,pi =
{p, sj , ..., sk |{hp, m, sj i, ..., hp, m, sk i} c } \ {sI , sG }. causal followers (for
producers), CFm , sequence hCFhm,p1 , ..., CFhm,pn i, p1 , ..., pn linearisation
producers m.
words, causal followers atom list sets steps.
set steps, one producer others consumers sj m,
causal link every sj m, i.e., PC(m) Re(s sj ). example, atom (at t1 B)
block deordered plan Figure 15(i) appears two causal links,
producer: hs1, (at t1 B), s2i hs1, (at t1 B), s3i. Thus, causal followers
CF(at t1 B) = h{s1, s2, s3}i.
block deordered plan extract sequence sets blocks corresponding
causal follower steps, according definition below. example, sequence
causal follower blocks CF(at t1 B) plan Figure 15(i) CFB(at t1 B) = h{b1}i,
since steps CF(at t1 B) contained block b1.
Definition 17. Let bdp = hS, B, block decomposed p.o. plan, CFhm,pi
causal followers atom respect producer p S. causal follower
blocks respect producer p atom m, CFBhm,pi , set blocks,
block contains least one element CFhm,pi . causal follower blocks
410

fiContinuing Plan Quality Optimisation

Exclusive


Basic block
66.52%
91.86%

Ext. block
8.14%
33.48%

Rule-based
24.50%
63.22%

Cyclic thread
6.09%
34.01%

Causal followers
17.78%
66.34%

Table 3: Percentage improvable windows found using two block types three
windowing heuristics, total number improvable windows found using blocks
types windowing heuristics. first row gives percentage improvable windows
found one block type (or one windowing heuristic
others), second row gives percentage improvable windows found one
block type (or windowing heuristic). results first experiment, described
Section 3.1.
(for producers), CFBm , sequence hCFBhm,p1 , ..., CFBhm,pn i, p1 , ..., pn
linearisation producers bdp .
Candidate windows formed taking consecutive subsequences sequence
causal follower blocks (with intermediate blocks, necessary). formal definition
given below. windowing heuristics, blocks unordered respect
window assigned set blocks precede window.
Definition 18. Let bdp = hS, B, block decomposed p.o. plan, CFBm =
hCFBhm,p1 , ..., CFBhm,pn causal follower blocks m. causal followers-based
windows CFBm Wl,m = {B IB(B) | B = CFBhm,pi ... CFBhm,pi+l
consecutive subsequence CFBm length l}, unordered blocks always placed
predecessor list.
order windows generated causal followers heuristic based
principle cyclic thread heuristic. generates stream candidate
windows causal follower blocks CFBm associated atom turn.
windows consecutive subsequences sets blocks CFBm , lengths chosen
according pattern 1, l, 2, l 1, ..., (l/2), l length CFBm .
4.4 Impact Windowing Heuristics
one single windowing heuristic block type, combination them, guaranteed
find improvable windows. first row Table 3 shows percentage improvable
windows found using one block type (or one windowing heuristic
others), total number improvable windows found using blocks types
windowing heuristics. (The results first experiment, described Section
3.1). shows every windowing heuristic block type contributes improvable
windows found strategies. example, 24.5% improvable windows
found rule-based windowing heuristic (using basic extended blocks).
hand, 36.78% improvable windows found heuristic.
windowing heuristics strengths limitations. rule-based heuristic,
example, generate windows contain sequences extended blocks
fixed length, cyclic thread causal followers heuristics make windows
blocks connected single atom.
411

fiSiddiqui & Haslum

0.963

0.955

0.951




0.947














































0.943




















0.939


































0.935



















0.931





0.927



3

2.5

2

1.5

1

0.5

0

6



0.919

5.5




5

0.923

BDPO2 (combined windowing heuristics)
BDPO2 (random windowing)
BDPO2 (rulebased windowing only)
BDPO2 (causal followers windowing only)
BDPO2 (cyclic thread windowing only)
4.5



4



3.5

Average Quality Score (Relative IPC Quality Score / Coverage)

0.959

Time (hours)

Figure 16: Average IPC quality score function time separate runs BDPO2 using
three windowing heuristics alone, three heuristics combined, random
window generation. run done using setup experiment 3, described
Section 3.1 (on page 392). x-axis shows runtime BDPO2 (i.e., without
2 hour delay generating input plans, shown Figure 11). Note
y-axis truncated: average quality input plans 0.907.

412

fiContinuing Plan Quality Optimisation

Figure 16 shows impact different windowing heuristics anytime performance
BDPO2, measured average IPC plan quality score achieved function timeper-problem. experiment, ran BDPO2 three windowing heuristics
alone, three combined sequential portfolio, described beginning
section. (The combined portfolio windowing heuristic configuration
BDPO2 presented experimental results Section 3.2, page 394.)
compare non-heuristic, random windowing strategy, window
formed taking random subsequence blocks random linearisation
block deordered plan. Subsequences chosen distribution window sizes
(measured number actions window) roughly produced
combined heuristics. experiment uses setup 3 (described Section 3.1 page
392), i.e., input plans BDPO2 already high quality. (Their average IPC plan
quality score 0.907.)
predicted data Table 3, using three windowing heuristics
results much worse system performance, since fails find substantial
fraction improvable windows. fact, random window generation better
heuristics own. However, combined portfolio heuristics outperforms
random windowing good margin: total quality improvement achieved
random windowing strategy 17.1% less best BDPO2 configuration.
demonstrates heuristics capture information useful guide selection
windows.
4.5 Possible Extensions Windowing Strategies
Since window formed partitioning plan steps three disjoint sets blocks,
number possible windows exponential. challenge good windowing heuristic
extract reduced set contains windows likely improved. Every windowing
strategy limitations. Hence, always scope developing new windowing
heuristics extending existing ones; one extension discussed section.
combination strategies use may miss improvable windows. example,
long sequence blocks form part cyclic thread causal followers sequence
respect single atom captured heuristics. example
shown Figure 17, three candidate windows, W1, W2 W3, found causal
followers windowing heuristic improvable separately. situation, forming
window union separate windows, found one several strategies, overcome
limitations strategies. example, union W1 W2 improvable.
type composite windows could formed later stages plan improvement
process, individual windowing heuristics exhausted. However,
number composite windows created large set candidate windows
combinatorial thus optimising take long time.
4.6 Window Ranking
Although windowing strategies generate fraction possible windows,
number candidate windows still often large (cf. Table 2). order speed
413

fiSiddiqui & Haslum

Figure 17: Three candidate windows, W1, W2, W3, found causal followers
windowing heuristic atoms (at t1 B), (in p1 t2), (in p2 t3) respectively. None
improvable. However, composite window formed merging W1 W2
improvable substituting delivery package p1 (from location B C) provided
truck t2 truck t1. atom (at t2 C) required
successors (i.e., goal example).

plan improvement process, helpful order windows likely
improved optimised first. role window ranking.
Ranking windows made difficult fact properties improvable windows
vary one another, lot domain domain. example, mentioned
beginning section, larger windows likely improved Pegsol,
Openstacks Parcprinter domains, smaller windows better Elevators,
Transport, Scanalyzer, Woodworking domains. Sokoban domain,
hand, medium-sized windows better. Moreover, improvable window may
improved particular subplanner within given time bound. noted
domains, e.g., Pegsol Scanalyzer, subplanners require, average, time
find lower-cost plan.
developed set window ranking policies examining structural properties
generated candidate windows generated results first experiment (cf.
Section 3.1) ran two subplanners (IBCS PNGS) generated window
30 second time limit, excluding windows whose cost already shown
optimal admissible LM-Cut heuristic (Helmert & Domshlak, 2009). Investigating
properties improved unimproved windows, identified four metrics work
relatively well across domains:
414

fiContinuing Plan Quality Optimisation

0.74
Random ranking
Outgoing causal links per length (min max)
Incoming causal links per length (min max)
Pairwise ordering disagreement (min max)
Gap cost & admissible heuristic (max min)

Fraction improvable windows selected windows



0.72

0.7

0.68

0.66

0.64

0.62






























400

375

350

325

300

275

250

225

200

175

150

125

100

75

50

25

0.6

Number selected (top ranked) windows

Figure 18: Fraction improvable windows, across domains, selected top
windows ranked orders generated ranking policies (see text).

(1) total number causal links whose producers reside window whose consumers outside window, divided length window lower
value higher rank. call property outgoing causal links per length.
(2) total number causal links whose consumers reside window whose producers outside window, divided length window lower
value higher rank. call property incoming causal links per length.
(3) gap cost window lower bound cost plan
corresponding subproblem given admissible heuristic higher value
higher rank.
(4) number pairwise ordering (of steps) disagreements window hp, w, qi
sequential input plan lower value higher rank. calculate
first take linearisation hp, w, qi used generate corresponding
subproblem. Then, every pair plan steps, ordering
linearisation input plan call pairwise ordering
disagreement. lower total number disagreements window,
higher rank. words, ordering steps window different
input plan less likely improved.

415

fiSiddiqui & Haslum

0.64
Fraction improvable windows selected windows

Random ranking
Outgoing causal links per length (min max)
Incoming causal links per length (min max)
Pairwise ordering disagreement (min max)
Gap cost & admissible heuristic (max min)



0.62
0.6
0.58
0.56
0.54
0.52
0.5
0.48
0.46
0.44
0.42












0.4

















0.38




0.36
0.34
0.32

400

375

350

325

300

275

250

225

200

175

150

125

100

75

50

25

0.3

Number selected (top ranked) windows

Figure 19: Fraction improvable windows Parking domain, selected top
windows ranked orders generated ranking policies (see text).

infer first two ranking policies disconnected window
blocks decomposed plan likely improved. Figure 18
compares ranking policies performance random ordering windows.
average across domains, four ranking policies good picking improvable
windows. example, take top 25 windows order generated
incoming causal links per length policy, nearly 74% windows improvable (by
least one subplanner), top 25 windows random order contain
61% improvable windows. random ranking Figure 18 best result three
separate random rankings values x-axis. expected, exhibits
roughly ratio improvable windows ranges (from 25 400). Nearly 61%
selected windows, across domains, improvable. However, performance
individual ranking policies varies domain, policy find domain
good. example, Figure 19 shows ranking results instances
Parking domain only: Here, outgoing causal links per length policy work
well. Considering top 90 windows ranked order, even worse random.
However, ranking policies quite beneficial domain.
BDPO2 uses first three ranking policies sequential portfolio (as explained
Section 3). subplanner, BDPO2 uses current ranking policy select next
416

fiContinuing Plan Quality Optimisation

0.963

Average Quality Score (Relative IPC Quality Score / Coverage)

0.961
0.959
0.957



0.955



0.953












0.951





0.949








0.947





0.945





0.943




0.941





0.939




0.937





0.935


0.933




0.931

BDPO2 (rankbased)
BDPO2 (randomranked)
6

5.5

5

4.5

4

3.5

3

2.5

2

1.5

1

0.5

0



Time (hours)

Figure 20: Average IPC plan quality score function time two separate runs:
without window ranking. second case, order candidate windows
randomised. run done using experimental setup 3, described Section 3.1
page 392. time shown runtime BDPO2 (excluding 2 hour delay
generating input plans, shown Figure 11). Also, y-axis truncated:
curves start average quality score input plans, 0.907.

window chosen subplanner (from eligible optimisation subplanner).
improvement found subplanner certain number attempts (13,
current configuration), system switches different ranking policy, produce different
ordering candidate windows subplanner.
use window ranking beneficial effect anytime performance
plan improvement process, shown Figure 20. achieve higher quality scores,
particular, achieve faster, using window ranking compared random ranking.
experiment, ran BDPO2 portfolio ranking policies, described
417

fiSiddiqui & Haslum

above, windows chosen optimisation random order. experiment
used setup experiment 3 (described Section 3.1 page 392).
tried many alternative methods combining ordered lists generated different
ranking policies, order achieve ranking stable performance across domains.
problem combining rankings, often called rank aggregation, studied many
disciplines, social choice theory, sports competitions, machine learning, information retrieval, database middleware, on. Rank aggregation techniques range
quite simple (based rank average number pairwise wins) complex procedures
require solving optimisation problem. tried five simple popular rank aggregation techniques, namely Bordas (1781) method, Kemenys (1978) optimal
ordering, Copelands (1951) majority graph, MC4 (Dwork, Kumar, Naor, & Sivakumar,
2001), multivariate Spearmans rho (Bedo & Ong, 2014). result experiments, however, rank aggregation produce better, stable, window
rankings, especially cases one individual policy relatively bad. Hence choice
using ranking policies cyclic portfolio instead.

5. On-line Adaptation
LNS approach optimisation repeatedly solving local subproblems gives us
opportunity adapting process on-line current problem. noted
different subplanners, windowing strategies, ranking policies work better different
domains. example, Figure 21 shows fraction local improvements found
three subplanners different domains. seen, IBCS subplanner
productive, compared PNGS LAMA, APPN, Barman, Maintenance, Parking,
Sokoban, Woodworking domains. PNGS, hand, better Scanalyzer
Visitall domains, LAMA Elevators Openstacks domains. Therefore,
learn course local search relative success rate different subplanners
current problem, system perform better. similar fashion, window
generation strategies ranking policies may adapted current problem,
system likely select subplans optimisation improvable.
use on-line machine learning technique multi-armed bandit (MAB) model,
specific select subplanner local optimisation attempt. technique, impact anytime performance BPO2 described following
subsections.
window selection, on-line adaptation limited switching alternative
ranking policies. window selected optimisation subplanner top one
order given current ranking policy subplanner (cf. Section 4.6).
long improvements found among windows, consider current
policy useful. subplanner reaches certain number attempts
improvements found, switch using next policy subplanner. number
windows neighbourhood optimised typically small compared
number candidate windows generated. average across problems experiment 3
(cf. Section 3.1 page 392) optimisation least one subplanner tried 24.8%
generated windows. this, adapting ranking policy influence
418

fiContinuing Plan Quality Optimisation

Figure 21: percentage improved windows found subplanners (PNGS,
IBCS, LAMA), total number improved windows found subplanners. experiment, BDPO2 run three times, time one subplanner.
setup experiment 3 (described Section 3.1 page 392).

windows tried adapting windowing strategies. effect adaptive
window ranking anytime performance BDPO2 shown Figure 20 (page 417).
5.1 Bandit Learning
multi-armed bandit (MAB) model popular machine learning formulation dealing
exploration versus exploitation dilemma. MAB problem, algorithm
presented sequence trials. round, algorithm chooses one set
alternatives (often called arms) based past history, receives reward
choice. goal maximise total reward time. bandit learning algorithm
balances exploiting arms highest observed average reward exploring poorly
understood arms discover yield better reward.
MAB found numerous applications diverse fields (e.g., control, economics, statistics, learning theory) influential paper Robbins (1952). Many policies
proposed MAB problem different assumptions, example, independent (Auer et al., 2002) dependent arms (Pandey, Chakrabarti, & Agarwal, 2007),
exponentially infinitely many arms (Wang, Audibert, & Munos, 2008), finite infinite
time horizon (Jones & Gittins, 1974), without contextual information (Slivkins,
2014), on.
cast problem selecting subplanner local optimisation attempt
multi-armed bandit problem. goal maximise total number improved
windows time. use learning algorithm based optimistic exploration strategy, chooses arm favorable environments high probability
best, given observed far. strategy often called optimism
face uncertainty. trial t, arm k, strategy use past
observations probabilistic argument define high-probability confidence intervals
expected reward k . favorable environment arm k thus upper
419

fiSiddiqui & Haslum

confidence bound (UCB) k . simple policy based strategy play arm
highest UCB.
number algorithms developed optimistic exploration bandit arms,
UCB1, UCB2 UCB1-NORMAL Auer et al. (2002), UCB-V Audibert,
Munos Szepesvari (2009), KL-UCB Garivier Cappe (2011). use
UCB1 algorithm planner selection. UCB1 algorithm
selects trial arm
q
2 ln
highest upper confidence bound Bk,t =
bk,t +
nk , sum exploitation term
exploration term, respectively.
bk,t empirical mean rewards received
arm k

trial
t,

n


number
times arm k tried far.
k
q
2 ln
second term,
nk , confidence interval average reward, within true
expected reward falls almost certain probability. Hence, Bk,t upper confidence
bound. UCB1 algorithm achieve logarithmic regret uniformly number
trials without preliminary knowledge reward distributions (Auer et al.,
2002).
Applied subplanner selection BDPO2, algorithm works follows: First,
select subplanner p once, initialise average reward
bp . optimisation
attempt, give reward 1 chosen subplanner found improvement
reward 0 otherwise. could use scheme assigning rewards rather
simply 0 1, example, making reward proportional amount improvement
(or time taken find it). However, observed assigning varying rewards
subplanners makes bandit learning system complicated, help
achieving better overall result. Next, select
q attempt subplanner p
maximises upper confidence bound p, Bp,t =
bp + 2nlnp , explained above. Here,
np number times p tried far, total number optimisation
attempts (by subplanners) done far. see Bp,t grows shrinks
np increase uniformly. ensures alternative tried infinitely often
still balances exploration exploitation. words, try p,
smaller size confidence interval closer gets mean value
bp .

p cannot tried becomes smaller p , p planner best
average reward.
5.2 Impact Bandit Learning
response bandit policy subplanner selection shown Figure 22. figure
shows fraction total number optimisation attempts one subplanner, IBCS,
selected, fraction total number window improvements found
subplanner. Since BDPO2 experiment uses two subplanners, IBCS PNGS,
corresponding fraction PNGS 1 y. example, third problem (from
left) APPN domain, 100% window improvements found IBCS,
bandit policy selects subplanner 84% total number optimisation attempts.
PNGS chosen 16%, finds improvement. see bandit
policy selects promising subplanner often across problems. However,
bandit policy somewhat conservative, ensures rule
subplanners fare poorly early on. Moreover, current plan improved
420

fiContinuing Plan Quality Optimisation

1
improvement ratio
exploitation ratio



0.9
Exploitation improvement ratio IBCS



0.8
0.7




0.6
0.5

























































0.4



0.3














0.2
0.1

Woodworking

Visitall

Transport

Thoughtful

Tetris

Sokoban

Parking

Scanalyzer

Parcprinter

Nomystery

Maintenance

Hiking

Ged

Floortile

Elevators

Childsnack

Barman

Appn

0

Figure 22: response bandit policy subplanner success rates. exploitation
ratio fraction total number optimisation attempts IBCS
subplanner chosen, total number attempts subplanners.
improvement ratio fraction total number improved windows found IBCS,
total number improved windows found subplanners. Since IBCS
PNGS two subplanners used experiment, corresponding ratios
PNGS opposite (i.e., 1 y). experiment run setup
experiment 2, described Section 3.1 page 392.

becomes harder find improvements (within given time bound), average
reward subplanners decreases. forces bandit policy switch
subplanners often.
Figure 23 shows impact combining subplanners using UCB1 bandit policy,
compared simply alternating subplanners using subplanner alone,
anytime performance BDPO2. experiment ran BDPO2 IBCS,
PNGS LAMA subplanner, combining two (IBCS PNGS)
using simple alternation policy, selects two turn, combining
two using bandit policy. run done experiment setup 3 (as described
Section 3.1 page 392), i.e., input plans high quality. (The IPC plan quality
score plan calculated before; see page 394). average score input
plans 0.907.) expected, combining IBCS PNGS subplanners fashion
leads quality improvement across entire time scale achieved running
BDPO2 individual subplanner. figure shows combining multiple
subplanners using bandit policy better strategy simply alternating
421

fiSiddiqui & Haslum

0.963

Average Quality Score (Relative IPC Quality Score / Coverage)

0.959




















0.955






















0.951















0.947






0.943







0.939




0.935


0.931




0.927



















































0.923

BDPO2 (PNGS+IBCS: Bandit)
BDPO2 (PNGS+IBCS: Alternating)
BDPO2 (PNGS only)
BDPO2 (IBCS only)
BDPO2 (LAMA only)









0.919


6

5.5

5

4.5

4

3.5

3

2.5

2

1.5

1

0.5

0

0.915

Time (hours)

Figure 23: Average IPC quality score function time per problem five different
runs BDPO2: using one three subplanners, using two (IBCS
PNGS) combined UCB1 bandit policy, without (using simple alternation
instead). experiment run setup 3 described Section 3.1 (on page 392).
Note y-axis truncated: curves start average quality input plans,
0.907. time shown runtime BDPO2 only, excluding 2 hour
delay generating input plans shown Figure 11).

422

fiContinuing Plan Quality Optimisation

them. total quality improvement achieved BDPO2 using alternation policy
6.8% less BDPO2 using bandit policy.

6. Related Work
survey four areas related work: Anytime search algorithms post-processing approaches, common approach aim continuing plan quality
improvement; uses local search planning; finally, uses algorithm portfolios
planning.
6.1 Anytime Search
Large state-space search problems, kind frequently arise planning problems,
often cannot solved optimally optimal search algorithms exhaust memory
finding solution. Anytime search algorithms try deal problems finding
first solution quickly, possibly using greedy suboptimal heuristic search, continue
(or restart) searching better quality solution. Anytime algorithms attractive allow users stop computation time, i.e., good enough solution
found, long wait. contrasts algorithms require
user decide advance deadline, suboptimality bound, parameter
fixes trade-off time solution qualty.
Bounded suboptimal search problem finding solution cost less
equal user specified factor w optimal. Weighted A* (WA*) search (Pohl, 1970)
Explicit Estimation Search (EES) (Thayer & Ruml, 2011) two algorithms
kind used planning. Iteratively applying bounded suboptimal
search algorithm lower value w whenever new best solution found provides
anytime improvement plan quality. Restarting WA* (Richter et al., 2010) this, using
schedule decreasing weights. RWA* used LAMA planner (Richter & Westphal,
2010) LAMA finds first plan using greedy best-first search (Bonet & Geffner, 2001).
uses several search enhancements, preferred operators deferred evaluation
(Richter & Helmert, 2009). EES conducts bounded suboptimal best-first search restricted
expanding nodes may lead solution cost given factor w
times optimal. Among open nodes set, expands one estimated
fewest remaining actions goal. uses admissible heuristic plan
cost informative inadmissible estimates guide search. AEES (Thayer
et al., 2012b) anytime version EES. achieve anytime behavior, AEES lowers
value w whenever new best solution found.
bounded-cost search (Stern, Puzis, & Felner, 2011) problem, subproblems solved approach example, requires finding solution cost less
equal user-specified cost bound C. aim bounded-cost search algorithm find solution quickly possible. Iteratively applying bounded-cost
search algorithm bound less cost best solution found far provides
anytime quality improvement. IBCS algorithm, used one subplanners BDPO2, does. BEES BEEPS algorithms (Thayer, Stern, Felner, &
Ruml, 2012a) adapt EES setting bounded cost search. algorithms expand
423

fiSiddiqui & Haslum

best open node among whose inadmissible cost estimate C, falling back
expanding node best admissible estimate set empty.
Branch-and-bound algorithms explore search space systematic fashion, using
admissible heuristic (lower bound cost) prune nodes cannot lead solution
better best found far. Branch-and-bound implemented linearmemory, depth-first search strategy well top strategies. experiment
reported Section 3.2 (page 394) used Beam-Stack Search (BSS) (Zhou & Hansen,
2005) bounded-cost search algorithm providing initial upper bound cost
base plan problem. BSS combines backtracking branch-and-bound beam
search, behaves breadth-first search limits size open list
layer user-specified parameter, known beam width. forced backtrack,
BSS reconstructs nodes pruned open list search complete. beam
width parameter used control memory consumption BSS never
exceeds available memory. planning problems, however, whose state spaces often
dense transpositions accurate admissible heuristics expensive compute,
repeatedly reconstructing paths unexplored nodes becomes time-consuming.
Anytime search planners aim provide continuing improvement plan quality given
time, often succeed early stages search. However,
observed results experiments, algorithms often stagnate, reaching
point find better plans even several hours CPU time. (cf.
Figure 11 page 395 Section 3.2 page 394.) example, experiment LAMA
AEES found better plans 8.7% 6.1%, respectively, total number
problems 3 hours 6 hours CPU time, BDPO2 found better plans
30.4% problems time interval. Memory one limiting factor,
one. almost half problems, AEES ran full 7 hours CPU time
without running memory, yet found improved plans. BSS found plans
cost less initial upper bound (the cost base plans) 14 182
problems even 24 hours CPU time per problem.
6.2 Local Search
Local search explores space searching small neighbourhood current element
search space one is, way, better, moving neighbour
repeating process. Compared systematic search algorithms, advantage local
search needs much less memory. Therefore, local search algorithms widely
used solve hard optimisation problems. However, local search algorithms cannot offer
guarantees global optimality, bounded suboptimality. planning, local search
used mainly find plans quickly, rarely improve plan quality, though
post-processing methods discussed next section viewed local searches.
(Hoffmann & Nebel, 2001) forward-chaining heuristic state space search planner.
heuristic used estimates distance state nearest goal state.
uses local search strategy, called enforced hill-climbing, state uses breadthfirst search find neighbour state (which may several steps away current
state) strictly better heuristic value, i.e., believed closer goal.
commits state starts new search neighbour better yet
424

fiContinuing Plan Quality Optimisation

heuristic value. local search fails, due getting trapped dead end, falls back
complete best-first search algorithm. RW-LS planning algorithm (Xie, Nakhost,
& Muller, 2012) similar FFs hill-climbing approach, uses combination greedy
best-first search exploration random walks find better next state local
search step. Nakhost Muller (2009) developed planning system, called Arvand,
uses random walk-based local exploration conjunction search heuristic.
showed Arvand outperforms hard problems many domains. execution
Arvand consists series search episodes. episode starts set random
walks initial state. endpoint random walk evaluated using
heuristic function choose next state. search episode continues set
random walks state. process repeats either goal reached,
enough transitions made without heuristic progress, case process
restarted. IPC 2011 2014 versions Arvand apply post-processing improve
quality generated plan. post-processing techniques Action Elimination
Plan Neighborhood Graph Search (Nakhost & Muller, 2010); discussed next
subsection. Arvands search randomised, system continue generating
alternative plans, optmised, indefinitely, storing times best plan
generated far. provides certain anytime capability. manner
used experiment reported Section 3.2 page 394.
LPG planner (Gerevini & Serina, 2002) based local search space
action graphs, represent partial plans. neighbourhood defined operators
modify action graph, inserting removing actions. function
evaluates nodes neighbourhood combines terms estimate far action
graph becoming valid plan, termed search cost, expected quality
plan may become. choice neighbour move involves element
randomness. LPG performs continuing search better plans; this, similar
anytime search algorithms discussed last subsection. Whenever finds plan,
local search restarts partial plan obtained removing randomly selected
actions current plan. numerical constraint forcing cost next plan
lower added. provides guidance towards better quality next plan.
close relationship local search approaches planning plan repair
adaptation methods (Garrido, Guzman, & Onaindia, 2010). LPG planner originated
method plan repair (Gerevini & Serina, 2000), iterative repair methods
used plan generation (Chien, Knight, Stechert, Sherwood, & Rabideau, 2000).
key difference use local search previous uses planning
carry local search space valid plans. permits neighbourhood
evaluation focus exclusively plan quality. Searching space partial plans (represented states) done FF, incomplete (invalid) plans, done LPG, requires
neighbourhood evaluation consider close element becoming valid plan,
balancing quality.
large neighbourhood search (LNS) strategy formulates problem finding
good neighbor optimisation problem, rather simply enumerating evaluating
neighbours. allows much larger neighbourhood considered. LNS used
successfully solve hard combinatorial optimisation problems vehicle routing
time windows (Shaw, 1998) scheduling (Godard, Laborie, & Nuijten, 2005). Theoretical
425

fiSiddiqui & Haslum

experimental studies shown increased neighborhood size may improve
effectiveness (quality solutions) local search algorithms (Ahuja, Goodstein, Mukherjee,
Orlin, & Sharma, 2007). neighbourhood current solution small
difficult escape local minima. case, additional meta-heuristic techniques,
Simulated Annealing Tabu Search, may needed escape local minimum.
LNS, size neighborhood may sufficient allow search process
avoid escape local minima.
LNS literature, neighborhood solution usually defined set
solutions reached applying destroy heuristic repair method.
destroy heuristic selects part current solution removed (unassigned),
repair method rebuilds destroyed part, keeping rest current solution
fixed. destroy heuristic often includes element randomness, enabling search
explore modifications different parts current solution. role destroy
heuristic system played windowing strategies, select candidate windows (subplans) re-optimisation. explore windows systematically. LNS
algorithms (e.g., Ropke & Pisinger, 2006; Schrimpf et al., 2000) allow local search
move neighbouring solution lower quality (e.g., using simulated annealing).
consider strictly improving moves. However, difference previous LNS algorithms,
immediately move better plan restart neighbourhood exploration
local improvement found. Instead, use delayed restarting, allows better
solution found one local search step destroying repairing multiple parts
current plan. Experimentally, found delayed restarting produces better quality
plans, produces faster, immediate restarts (cf. Section 3.4 page 399).
6.3 Plan Post-Processing
post-processing method, mean one takes valid plan input attempts
improve it, making modifications. related plan repair adaptation
(Chien et al., 2000; Fox, Gerevini, Long, & Serina, 2006; Garrido et al., 2010),
key difference plan repair adaptation starts plan valid
current situation focuses making work; discrepancy current
state goals plan originally built provide guidance repairs
needed. contrast, post-processing plan optimisation may require modifications
anywhere current plan.
Nakhost Muller (2010) proposed two post-processing techniques Action Elimination (AE) Plan Neighborhood Graph Search (PNGS). Action elimination identifies
removes unnecessary actions given plan. PNGS constructs plan neighborhood graph, subgraph state space problem, built around
path state space induced current plan expanding limited number
states state path. searches least-cost plan subgraph.
finds plan better current, process repeated around new best
plan; otherwise, exploration limit increased, time memory limit exceeded.
Furcys (2006) Iterative Tunneling Search A* (ITSA*) similar PNGS. ITSA*
explores area, called tunnel, state space using A* search, restricted fixed
distance current plan. methods seen creating neighborhood
426

fiContinuing Plan Quality Optimisation

includes small deviations current plan, anywhere along plan.
contrast, BDPO2 focuses one section decomposed plan time, often grouping
together different parts input plan, puts restriction much section
changes; hence, creates different neighbourhood. experiments show best
results obtained exploring neighbourhoods. example, PNGS often finds
plan improvements quickly, running additional 6 hours improves average
IPC plan quality score, best plans finds first hour, 0.01%.
Running instead BDPO2, using PNGS subplanner taking best plans
found PNGS 1 hour input, improves average plan quality score 3% 6
hours.
Ratner Pohl (1986) used local optimisation shortening solutions sequential
search problems. select subpath optimise, used sliding window predefined size dmax consecutive segments current path. Estrem Krebsbach
(2012) instead used form windowing heuristic: select local optimisation pairs
states current path maximise estimate redundancy, based ratio
estimated distances two states, given state space heuristic,
cost current path. Balyo, Bartak Surynek (2012) used sliding window
approach minimise parallel plan length (that is, makespan, assuming actions
unit duration). Rather take segments single path state space, use block
deordering input plan create candidate windows local optimisation. shown
experimental results, important success BDPO2: total
improvement average plan quality achieved without deordering 28.7% less
achieved BDPO2 using block deordering input plans (cf. Section 3.6 page 402).
planning-by-rewriting approach (Ambite & Knoblock, 2001) uses local modifications partially ordered plans improve quality. Plan modifications defined
domain-specific rewrite rules, provided domain designer learned
many examples good bad plans. Hence, technique effective
solving many problem instances domain. Using planner solve subproblems may time-consuming applying pre-defined rules, makes process
automatic. However, consider solving many problems domain may
possible reduce average planning time learning (generalised) rules subplan
improvements discover using applicable avoid invoking subplanner.
6.4 Portfolio Planning Automatic Parameter Tuning
portfolio planning system runs several subplanners sequence (or parallel) short
timeouts, hope least one component planners find solution
time allotted it. Portfolio planning systems motivated observations
single planner dominates others domains, planner solve
planning task quickly, often solve all. Therefore, many todays
successful planners run sequential portfolio planners (Coles, Coles, Olaya, Celorrio,
Linares Lopez, Sanner, & Yoon, 2012).
Gerevini, Saetti Vallati (2009) introduced PbP planner, learns portfolio
given set planners specific domain, well domain-specific macro-actions.
Fast Downward Stone Soup (FDSS, Helmert, Roger, Seipp, Karpas, Hoffmann, Keyder,
427

fiSiddiqui & Haslum

Nissim, Richter, & Westphal, 2011) uses fixed portfolio, computed optimise performance
large sample training domains, domains. IBaCoP2 (Cenamor et al., 2014)
dynamically configures portfolio using predictive model planner success.
Another recent trend use automatic algorithm configuration tools,
ParamILS framework (Hutter, Hoos, Leyton-Brown, & Stutzle, 2009), enhance planner
performance specific domain. ParamILS local search space configurations, using suite training problems evaluate performance different parameter
settings. combinatorial explosion caused many parameters many different values managed varying one parameter time. ParamILS used configure
LPG planner (Vallati, Fawcett, Gerevini, Hoos, & Saetti, 2011) Fast Downward planner (Fawcett, Helmert, Hoos, Karpas, Roger, & Seipp, 2011). PbP2 portfolio
planner (Gerevini, Saetti, & Vallati, 2011), successor PbP, includes version LPG
customised domain ParamILS learned portfolio.
BDPO2, course, uses portfolio subplanners, and, shown, selecting
right subplanner current problem important (cf. Section 5). Much important,
however, focus subproblems approach brings: comparing Figures 11 (page
395) 23 (page 422), clear using even single subplanner within BDPO2
effective using subplanners own. multiple window ranking
policies used BDPO2 (cf. Section 4.6) viewed simple sequential portfolio.
Compared previous portfolio planners, iterated use subplanners, windowing strategies components approach offers possibility learn best portfolio
configuration on-line; is, rather spend time configuring system using
training problems, learn experience solving several subproblems,
actually working optimising current plan.
Finally, although explored great depth, results suggest combining different anytime search post-processing methods, effectively kind
sequential portfolio (such running BDPO2 result running PNGS result
LAMA IBaCoP2, results experiment 3, shown Figure 2 page 371),
often achieves better quality final plans investing available time single
method.

7. Conclusions Future Work
Plan quality optimisation, particularly large problems, central concern automated
planning. Anytime planning, aims deliver continuing stream better plans
given time, attractive idea, offering flexibility stop process
point, best plan found good enough wait next plan
becomes long. presented approach anytime plan improvement,
realisation BDPO2 system. approach based large neighbourhood local
search strategy (Shaw, 1998), using windowing heuristics select candidate windows
block deordering current plan, local optimisation using off-the-shelf bounded-cost
planning techniques.
Experiments demonstrate BDPO2 achieves continuing plan quality improvement
even large time scales (several hours CPU time), anytime planners stagnate.
Key achieving focus optimising subproblems, corresponding windows.
428

fiContinuing Plan Quality Optimisation

mentioned Section 4.5, extending windowing heuristics improving on-line
learning effective window rankings one way improve approach. Also, complementing window ranking, estimates promising window is,
estimate difficult windows optimise, using inform time allocated subplanners, currently uniform windows, may contribute better
performance. best result, however, achieved chaining several techniques together
(for example, applying BDPO2 best plan found PNGS applied best plan
found LAMA IBaCoP2). result cannot achieved previous anytime planning approaches alone. Thus, another area future work examine greater
depth best way combine different plan improvement methods,
learned on-line optimising plan. example, conducted study
optimal time switch base plan generation, using LAMA, post-processing
using PNGS BDPO, function total runtime (Siddiqui & Haslum, 2013a).
demonstrated experimentally, block deordering step essential
good performance BDPO2 (cf. Section 3.6 page 402). Block deordering creates
decomposition plan non-interleaving blocks removing ordering constraints
blocks. lifts limitation conventional, step-wise, deordering,
requires unordered steps plan non-interfering. shown, validity
condition block decomposed partially ordered plans stated almost
Chapmans (1987) modal truth criterion, allowing threats causal link
remain unordered long link protected block structure (Theorem 2
page 379). Therefore, block deordering yield less order-constrained plans, including
cases conventional deordering possible.
plan structure uncovered block decomposition uses. Recently used planner independent macro generation system BloMa (Chrpa &
Siddiqui, 2015) find longer macros capture compound activities order improve
planners coverage efficiency. domains (e.g., Barman, ChildSnack, Scanalyzer,
Parcprinter, Gripper, Woodworking, etc.), block deordering often identifies structurally similar subplans, symmetric improvement patterns. could potentially
exploited learning plan rewrite rules (Ambite, Knoblock, & Minton, 2000). structure
block deordered plans, often comprises nested, hierarchical decomposition
meaningful subplans, reminiscent Hierarchical Task Network (HTN) representations.
Hence, block deordering technique could potentially applied generating (or helping
generate) HTN structures domain independent way, reducing knowledge-engineering
effort. Recent work Scala Torasso (2015) extends deordering plans planning
domains numeric state variables, identifying numeric dependencies capture
additional reasons necessary orderings. Defining conditions blocks sufficient
encapsulate dependencies would allow block deordering numeric plans.
may synergy block deordering numeric planning, since numeric dependencies often involve groups plan steps, rather single producerconsumer pair.
Acknowledgment
work partially supported Australian Research Council discovery project
DP140104219 Robust AI Planning Hybrid Systems. NICTA funded Aus429

fiSiddiqui & Haslum

tralian Government Department Communications Australian Research Council ICT Centre Excellence Program.

References
Ahuja, R. K., Goodstein, J., Mukherjee, A., Orlin, J. B., & Sharma, D. (2007).
large-scale neighborhood search algorithm combined through-fleet-assignment
model. INFORMS Journal Computing, 19 (3), 416428.
Ambite, J. L., & Knoblock, C. A. (2001). Planning rewriting. Journal Artificial
Intelligence Research (JAIR), 15 (1), 207261.
Ambite, J. L., Knoblock, C. A., & Minton, S. (2000). Learning plan rewriting rules.
Proc. 5th International Conference Artificial Intelligence Planning Systems,
AIPS 2000, Breckenridge, CO, USA, April 14-17, 2000, pp. 312. AAAI Press.
Audibert, J.-Y., Munos, R., & Szepesvari, C. (2009). Explorationexploitation tradeoff using
variance estimates multi-armed bandits. Theoretical Computer Science, 410 (19),
18761902.
Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis multiarmed
bandit problem. Machine Learning, 47 (2-3), 235256.
Backstrom, C. (1998). Computational aspects reordering plans. Journal Artificial
Intelligence Research (JAIR), 9, 99137.
Balyo, T., Bartak, R., & Surynek, P. (2012). improving plan quality via local enhancements. Proc. 5th International Symposium Combinatorial Search, SOCS
2012, Niagara Falls, Canada, July 19-21, 2012. AAAI Press.
Bedo, J., & Ong, C. S. (2014). Multivariate Spearmans rho aggregating ranks using
copulas. CoRR, abs/1410.4391.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (12), 533.
Cenamor, I., de la Rosa, T., & Fernandez, F. (2014). IBaCoP IBaCoP2 planners.
Proc. 8th International Planning Competition, IPC 2014, Deterministic Part,
pp. 3538.
Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32 (3), 333377.
Chien, S., Knight, R., Stechert, A., Sherwood, R., & Rabideau, G. (2000). Using iterative
repair improve responsiveness planning scheduling. Proc.
5th International Conference Artificial Intelligence Planning Systems, AIPS 2000,
Breckenridge, CO, USA, April 14-17, 2000, pp. 300307. AAAI Press.
Chrpa, L., & Siddiqui, F. H. (2015). Exploiting block deordering improving planners efficiency. Proc. 24th International Joint Conference Artificial Intelligence,
IJCAI 2015, Buenos Aires, Argentina, July 25-31, 2015, pp. 15371543. AAAI Press.
Coles, A. J., Coles, A., Olaya, A. G., Celorrio, S. J., Linares Lopez, C., Sanner, S., & Yoon,
S. (2012). survey seventh international planning competition. AI Magazine,
33 (1), 8388.
430

fiContinuing Plan Quality Optimisation

Copeland, A. H. (1951). reasonable social welfare function. University Michigan
Seminar Applications Mathematics social sciences.
de Borda, J. C. (1781). Memory election ballot. History Royal Academy
Sciences, Paris, 657664.
Dwork, C., Kumar, R., Naor, M., & Sivakumar, D. (2001). Rank aggregation methods
web. Proc. 10th International Conference World Wide Web, WWW
2001, Hong Kong, May 1-5, 2001, pp. 613622, New York, NY, USA. ACM.
Estrem, S. J., & Krebsbach, K. D. (2012). AIRS: Anytime iterative refinement solution. Proc. 25th International Florida Artificial Intelligence Research Society
Conference, Marco Island, Florida. May 23-25, 2012.
Fawcett, C., Helmert, M., Hoos, H., Karpas, E., Roger, G., & Seipp, J. (2011). FD-Autotune:
Domain-specific configuration using Fast Downward. Proc. 2011 ICAPS
Workshop Planning Learning, PAL 2011, Freiburg, Germany, June 11-16,
2011, pp. 1320. AAAI Press.
Fox, M., Gerevini, A., Long, D., & Serina, I. (2006). Plan stability: Replanning versus plan
repair. Proc. 16th International Conference Automated Planning
Scheduling, ICAPS 2006, Cumbria, UK, June 6-10, 2006., pp. 212221. AAAI Press.
Furcy, D. (2006). ITSA*: Iterative tunneling search A*. Proc. 2006 AAAI
Workshop Heuristic Search, Memory-Based Heuristics Applications,
July 1620, 2006, Boston, Massachusetts, pp. 2126. AAAI Press.
Garivier, A., & Cappe, O. (2011). KL-UCB algorithm bounded stochastic bandits
beyond. CoRR, abs/1102.2490.
Garrido, A., Guzman, C., & Onaindia, E. (2010). Anytime plan-adaptation continuous
planning. Proc. joint 28th Workshop UK Special Interest Group
Planning Scheduling 4th Italian Workshop Planning Scheduling, pp.
4754.
Gerevini, A., Saetti, A., & Vallati, M. (2009). automatically configurable portfolio-based
planner macro-actions: PbP. Proc. 19th International Conference
Automated Planning Scheduling, ICAPS 2009, Thessaloniki, Greece, September
19-23, 2009, pp. 350353. AAAI Press.
Gerevini, A., Saetti, A., & Vallati, M. (2011). PbP2: Automatic configuration portfoliobased multi-planner. 7th International Planning Competition (IPC 2011), Learning
Track. http://www.plg.inf.uc3m.es/ipc2011-learning.
Gerevini, A., & Serina, I. (2002). LPG: planner based local search planning graphs
action costs. Proc. 6th International Conference Artificial Intelligence
Planning Scheduling, AIPS 2002, April 23-27, 2002, Toulouse, France, pp. 281
290. AAAI Press.
Gerevini, A. E., & Serina, I. (2000). Fast plan adaptation planning graphs: Local
systematic search techniques. Proc. 5th International Conference
Artificial Intelligence Planning Systems, AIPS 2000, Breckenridge, CO, USA, April
14-17, 2000, pp. 112121. AAAI Press.
431

fiSiddiqui & Haslum

Ghallab, M., Nau, D. S., & Traverso, P. (2004). Automated Planning: Theory & Practice.
Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.
Godard, D., Laborie, P., & Nuijten, W. (2005). Randomized large neighborhood search
cumulative scheduling. Proc. 15th International Conference Automated
Planning Scheduling, ICAPS 2005, Monterey, California, USA, June 5-10 2005,
pp. 8189. AAAI Press.
Haslum, P. (2011). Computing genome edit distances using domain-independent planning.
Proc. 2011 ICAPS Workshop Scheduling Planning Applications,
SPARK 2011, Freiburg, Germany, June 11-16, 2011. AAAI Press.
Haslum, P. (2012). Incremental lower bounds additive cost planning problems. Proc.
22nd International Conference Automated Planning Scheduling, ICAPS
2012, Atibaia, Sao Paulo, Brazil, June 25-19, 2012, pp. 7482. AAAI Press.
Haslum, P., & Grastien, A. (2011). Diagnosis planning: Two case studies. Proc.
2011 ICAPS Workshop Scheduling Planning Applications, SPARK 2011,
Freiburg, Germany, June 11-16, 2011. AAAI Press.
Haslum, P., & Jonsson, P. (2000). Planning reduced operator sets. Proc.
5th International Conference Artificial Intelligence Planning Systems, AIPS 2000,
Breckenridge, CO, USA, April 14-17, 2000, pp. 150158. AAAI Press.
Helmert, M., Roger, G., Seipp, J., Karpas, E., Hoffmann, J., Keyder, E., Nissim, R., Richter,
S., & Westphal, M. (2011). Fast Downward Stone Soup (planner abstract).
Proc. 7th International Planning Competition, IPC 2011, Deterministic Part.
http://www.plg.inf.uc3m.es/ipc2011-deterministic.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whats
difference anyway?. Proc. 19th International Conference Automated
Planning Scheduling, ICAPS 2009, Thessaloniki, Greece, September 19-23, 2009,
pp. 162169. AAAI Press.
Hoffmann, J. (2001). Local search topology planning benchmarks: empirical analysis.
Proc. 17th International Joint Conference Artificial Intelligence, IJCAI
2001, Seattle, Washington, USA, August 4-10, 2001, pp. 453458, San Francisco, CA,
USA. Morgan Kaufmann Publishers Inc.
Hoffmann, J., & Nebel, B. (2001). planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research (JAIR), 14, 253302.
Hutter, F., Hoos, H. H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: automatic
algorithm configuration framework. Journal Artificial Intelligence Research (JAIR),
36 (1), 267306.
Jones, D. M., & Gittins, J. (1974). dynamic allocation index sequential design
experiments. University Cambridge, Department Engineering.
Kambhampati, S., & Kedar, S. (1994). unified framework explanation-based generalization partially ordered partially instantiated plans. Artificial Intelligence,
67 (1), 2970.
432

fiContinuing Plan Quality Optimisation

McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proc. 9th
National Conference Artificial Intelligence, AAAI 1991, Anaheim, CA, USA, July
14-19, 1991, Volume 2., pp. 634639. AAAI Press / MIT Press.
Muise, C. J., McIlraith, S. A., & Beck, J. C. (2012). Optimally relaxing partial-order plans
maxsat. Proc. 22nd International Conference Automated Planning
Scheduling, ICAPS 2012, Atibaia, Sao Paulo, Brazil, June 25-19, 2012, pp. 358
362. AAAI Press.
Nakhost, H., & Muller, M. (2009). Monte-carlo exploration deterministic planning.
Proc. 21st International Joint Conference Artificial Intelligence, IJCAI
2009, Pasadena, California, USA, July 11-17, 2009, Vol. 9, pp. 17661771.
Nakhost, H., & Muller, M. (2010). Action elimination plan neighborhood graph search:
Two algorithms plan improvement. Proc. 20th International Conference
Automated Planning Scheduling, ICAPS 2010, Toronto, Canada, May 12-16,
2010, pp. 121128. AAAI Press.
Nebel, B., & Backstrom, C. (1994). computational complexity temporal projection, planning, plan validation. Artificial Intelligence, 66 (1), 125160.
Pandey, S., Chakrabarti, D., & Agarwal, D. (2007). Multi-armed bandit problems
dependent arms. Proc. 24th International Conference Machine Learning,
ICML 2007, Corvallis, Oregon, USA, June 20-24, 2007, Vol. 227, pp. 721728. ACM.
Pednault, E. P. D. (1986). Formulating multiagent, dynamic-world problems classical
planning framework. Reasoning actions plans, 4782.
Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence,
1 (3), 193204.
Ratner, D., & Pohl, I. (1986). Joint LPA*: Combination approximation search.
Proc. 5th National Conference Artificial Intelligence, AAAI 1986, Philadelphia, PA, August 11-15, 1986. Volume 1: Science., pp. 173177. Morgan Kaufmann.
Regnier, P., & Fade, B. (1991). Complete determination parallel actions temporal
optimization linear plans action. Proc. European Workshop Planning,
EWSP 1991, Sankt Augustin, FRG, March 18-19, 1991, Vol. 522 Lecture Notes
Computer Science, pp. 100111. Springer.
Richter, S., & Helmert, M. (2009). Preferred operators deferred evaluation satisficing
planning. Proc. 19th International Conference Automated Planning
Scheduling, ICAPS 2009, Thessaloniki, Greece, September 19-23, 2009, pp. 273280.
AAAI Press.
Richter, S., Thayer, J. T., & Ruml, W. (2010). joy forgetting: Faster anytime search
via restarting. Proc. 20th International Conference Automated Planning
Scheduling, ICAPS 2010, Toronto, Canada, May 12-16, 2010, pp. 137144. AAAI
Press.
Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime
planning landmarks. Journal Artificial Intelligence Research (JAIR), 39, 127
177.
433

fiSiddiqui & Haslum

Robbins, H. (1952). aspects sequential design experiments. Herbert
Robbins Selected Papers, Vol. 58, pp. 527535. Springer.
Ropke, S., & Pisinger, D. (2006). adaptive large neighborhood search heuristic
pickup delivery problem time windows. Transportation Science, 40 (4),
455472.
Scala, E., & Torasso, P. (2015). Deordering numeric macro actions plan repair.
Proc. 24th International Joint Conference Artificial Intelligence, IJCAI
2015, Buenos Aires, Argentina, July 25-31, 2015, pp. 16731681. AAAI Press.
Schrimpf, G., Schneider, J., Stamm-Wilbrandt, H., & Dueck, G. (2000). Record breaking
optimization results using ruin recreate principle. Journal Computational
Physics, 159 (2), 139171.
Shaw, P. (1998). Using constraint programming local search methods solve vehicle
routing problems. Proc. 4th International Conference Principles
Practice Constraint Programming, CP 1998, , Pisa, Italy, October 26-30, 1998,
Vol. 1520 Lecture Notes Computer Science, pp. 417431. Springer.
Siddiqui, F. H., & Haslum, P. (2012). Block-structured plan deordering. Proc. 25th
Australasian Joint Conference Advances Artificial Intelligence, AI 2012, Sydney,
Australia, December 4-7, 2012, Vol. 7691 Lecture Notes Computer Science, pp.
803814, Berlin, Heidelberg. Springer.
Siddiqui, F. H., & Haslum, P. (2013a). Local search space valid plans. Proc.
2013 ICAPS Workshop Evolutionary Techniques Planning Scheduling, EVOPS 2013, Rome, Italy, June 10-14, 2013, pp. 2231. http://icaps13.icapsconference.org/wp-content/uploads/2013/05/evops13-proceedings.pdf.
Siddiqui, F. H., & Haslum, P. (2013b). Plan quality optimisation via block decomposition.
Proc. 23rd International Joint Conference Artificial Intelligence, IJCAI
2013, Beijing, China, August 3-9, 2013, pp. 23872393. AAAI Press.
Slivkins, A. (2014). Contextual bandits similarity information. Journal Machine
Learning Research, 15 (1), 25332568.
Stern, R. T., Puzis, R., & Felner, A. (2011). Potential search: bounded-cost search
algorithm. Proc. 21st International Conference Automated Planning
Scheduling, ICAPS 2011, Freiburg, Germany June 11-16, 2011, pp. 234241. AAAI
Press.
Thayer, J., Stern, R., Felner, A., & Ruml, W. (2012a). Faster bounded-cost search using
inadmissible heuristics. Proc. 22nd International Conference Automated
Planning Scheduling, ICAPS 2012, Atibaia, Sao Paulo, Brazil, June 25-19, 2012,
pp. 270278. AAAI Press.
Thayer, J. T., Benton, J., & Helmert, M. (2012b). Better parameter-free anytime search
minimizing time solutions. Proc. 5th International Symposium
Combinatorial Search, SOCS 2012, Niagara Falls, Canada, July 19-21, 2012, pp.
120128. AAAI Press.
434

fiContinuing Plan Quality Optimisation

Thayer, J. T., & Ruml, W. (2011). Bounded suboptimal search: direct approach using
inadmissible estimates. Proc. 22nd International Joint Conference Artificial Intelligence, IJCAI 2011, Barcelona, Catalonia, Spain, July 16-22, 2011, pp.
674679. AAAI Press.
Vallati, M., Fawcett, C., Gerevini, A., Hoos, H., & Saetti, A. (2011). ParLPG: Generating domain-specific planners automatic parameter configuration LPG.
Proc. 7th International Planning Competition, IPC 2011, Deterministic Part.
http://www.plg.inf.uc3m.es/ipc2011-deterministic.
Veloso, M. M., Perez, A., & Carbonell, J. G. (1990). Nonlinear planning parallel
resource allocation. Proc. DARPA Workshop Innovative Approaches
Planning, Scheduling Control, San Diego, California, November 5-8, 1990, pp.
207212. Morgan Kaufmann.
Wang, Y., Audibert, J., & Munos, R. (2008). Algorithms infinitely many-armed bandits.
Proc. 22nd Annual Conference Neural Information Processing Systems,
NIPS 2008, Vancouver, British Columbia, Canada, December 8-11, 2008, pp. 1729
1736. Curran Associates, Inc.
Xie, F., Nakhost, H., & Muller, M. (2012). Planning via random walk-driven local search.
Proc. 22nd International Conference Automated Planning Scheduling,
ICAPS 2012, Atibaia, Sao Paulo, Brazil, June 25-19, 2012, pp. 315322. AAAI Press.
Xie, F., Valenzano, R. A., & Muller, M. (2010). Better time constrained search via randomization postprocessing. Proc. 23rd International Conference
Automated Planning Scheduling, ICAPS 2013, Rome, Italy, June 10-14, 2013,
pp. 269277. AAAI Press.
Young, H. P., & Levenglick, A. (1978). consistent extension condorcets election principle. SIAM Journal Applied Mathematics, 35 (2), 285300.
Zhou, R., & Hansen, E. A. (2005). Beam-stack search: Integrating backtracking beam
search. Proc. 15th International Conference Automated Planning
Scheduling, ICAPS 2005, Monterey, California, USA, June 5-10, 2005, pp. 9098.
AAAI Press.

435


