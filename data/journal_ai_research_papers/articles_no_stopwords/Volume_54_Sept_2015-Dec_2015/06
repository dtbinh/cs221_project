Journal Artificial Intelligence Research 54 (2015) 593-629

Submitted 07/15; published 12/15

Compressing Optimal Paths Run Length Encoding
Ben Strasser

STRASSER @ KIT. EDU

Karlsruhe Institute Technology
Karlsruhe, Germany

Adi Botea

ADIBOTEA @ IE . IBM . COM

IBM Research
Dublin, Ireland

Daniel Harabor

DANIEL . HARABOR @ NICTA . COM . AU

NICTA
Sydney, Australia

Abstract
introduce novel approach Compressed Path Databases, space efficient oracles used
quickly identify first edge shortest path. algorithm achieves query running times
100 nanosecond scale, significantly faster state-of-the-art first-move oracles
literature. Space consumption competitive, due compression approach rearranges
rows columns first-move matrix performs run length encoding (RLE)
contents matrix. One variant implemented system was, convincing margin,
fastest entry 2014 Grid-Based Path Planning Competition.
give first tractability analysis compression scheme used algorithm.
study complexity computing database minimum size general directed undirected
graphs. find cases problem NP-complete. show that, graphs
decomposed along articulation points, problem decomposed independent
parts, corresponding reduction level difficulty. particular, leads simple
tractable algorithms linear running time yield optimal compression results trees.

1. Introduction
Compressed Path Database (CPD) index-based data-structure graphs used
quickly answer first-move queries. query takes input pair nodes, namely source node
target node t, asks first edge shortest st-path (i.e., path t). CPDs
successfully applied number contexts important AI. instance, Copa (Botea,
2012), CPD-based pathfinding algorithm, one joint winners 2012 edition
Grid-Based Path Planning Competition, shorter GPPC (Sturtevant, 2012b). related algorithm,
MtsCopa, fast method moving target search known partially known terrain (Botea,
Baier, Harabor, & Hernandez, 2013; Baier, Botea, Harabor, & Hernandez, 2014).
Given graph G = (V, E), trivial CPD consists square matrix dimensions
|V | |V |. matrix m, constructed precomputation step, stores cell m[s, t]
identity first edge shortest st-path. call first-move matrix. convention
say rows correspond fixed source nodes columns fixed target nodes.
optimal terms query time O(|V |2 ) space consumption quickly becomes prohibitive
larger graphs. challenge design compact representation trades small increase
query times large decrease space consumption.
c
2015
AI Access Foundation. rights reserved.

fiS TRASSER , B OTEA , & H ARABOR

number different techniques compress first-move matrix suggested
purpose (Sankaranarayanan, Alborzi, & Samet, 2005; Botea, 2011; Botea & Harabor, 2013a).
case objective conserve space grouping together entries share
common source node store first-edge information.
work present Single-Row-Compression (SRC) Multi-Row-Compression
(MRC) indexing algorithms compressing all-pairs shortest paths. 2014s GPPC, SRC outperformed competitors terms query running time. contributions presented article
go three main directions: new approach compressing first-move matrix; experiments
demonstrate advancing state-of-the-art terms response time memory consumption;
thorough theoretical analysis, discussing NP-hardness results islands tractability.
introduce new matrix compression technique based run-length encoding (RLE).
main idea algorithm simple: compute order nodes input graph
assign numeric IDs nodes (e.g., 1 |V |) order. purpose ordering
nodes located close proximity graph small ID difference. ordering
used order rows columns first-move matrix, computed
preprocessing. Then, apply run-length encoding (RLE) row first-move matrix.
study three types heuristic orderings: graph-cut order, depth-first order input-graph order.
study two types run-length encoding. first involves straightforward application
algorithm row. second type sophisticated multi-row scheme eliminates
redundancies adjacent RLE-compressed rows. answer first-move queries employ
binary search fragment compressed result.
undertake detailed empirical analysis including comparisons techniques stateof-the-art variants CPDs (Botea, 2012), Hub-Labeling (Delling, Goldberg, Pajor, & Werneck,
2014). Copa recent fast CPD oracle among joint winners 2012
International Grid-Based Path Planning Competition (GPPC). Using variety benchmarks
competition show techniques improve Copa, terms storage query
time. Hub-Labeling technique initially developed speedup queries roads,
work graphs, gridmaps. Hub-Labeling best knowledge fastest
technique known roads. experiments, show approach leads better query times
Hub-Labeling graphs reasonably compute m.
technique relies all-pairs-shortest-path pre-computation, plays tradeoff
query-response speed, preprocessing time memory required store compressed
path database. Thus, algorithm faster, requires larger preprocessing time
memory techniques literature. words, memory
preprocessing time available, technique provide state-of-the-art speed performance. hand, larger larger graphs create memory preprocessing time
bottleneck, techniques considered. See detailed comparison experiments
section.
theoretical analysis, formally define study optimal RLE-compression first-move
matrices produced input graphs. consider case directed input graphs case
undirected weighted input graphs. show versions NP-complete. Focusing
distinct types graphs, result brings something new compared other. Related (Kou,
1977; Oswald & Reinelt, 2009) weaker, less specific (Mohapatra, 2009) results RLE-based
matrix compression available literature. However, known, NP-hardness class
problems necessarily imply NP-hardness subset class. Thus, despite
594

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

previous related results (Mohapatra, 2009), open question whether optimal RLEcompression first-move matrix computed input graph tractable.
show that, graphs decomposed along articulation points, problem
decomposed independent subproblems. optimal orderings available subproblems, global optimal ordering easily obtained. particular, depth-first preorder
optimal trees, general ordering problem fixed-parameter tractable size
largest 2-connected component.
approach part evaluation previously reported shorter conference
paper (Strasser, Harabor, & Botea, 2014). theoretical analysis topic another conference paper (Botea, Strasser, & Harabor, 2015). Putting together current submission
provides unique source describes method, performance theoretical properties.
Compared previous conference papers, provide complete proofs theoretical
results. included details examples presentation, better clarity.
report additional results, performance pathfinding competition GPPC 2014,
originally published paper competition (Sturtevant, Traish, Tulip, Uras,
Koenig, Strasser, Botea, Harabor, & Rabin, 2015).

2. Related Work
Many techniques literature employed order quickly answer first-move queries.
Standard examples include optimal graph search techniques Dijkstras algorithm (Dijkstra,
1959) A* (Hart, Nilsson, & Raphael, 1968). Significant improvements methods
achieved preprocessing input graph, done CPDs, instance. shortest paths
numerous applications various fields, plethora different preprocessing-based algorithms
proposed. overview, refer interested reader recent survey article (Bast,
Delling, Goldberg, MullerHannemann, Pajor, Sanders, Wagner, & Werneck, 2015). common
approach consists adding online pruning rules Dijkstras algorithm, rely data computed preprocessing phase, significantly reducing explored graphs size. approach
significantly differs technique described paper, omit details refer
interested reader aforementioned survey article.
SILC (Sankaranarayanan et al., 2005) Copa (Botea & Harabor, 2013a) CPD-based techniques fast first-move computation. SILC employs recursive quad-tree mechanism compression Copa uses simpler effective (Botea, 2011) decomposition rectangles.
Hub Labels (HL) initially introduced 2-Hop Labels (Cohen, Halperin, Kaplan, & Zwick,
2002). nearly decade much research topic, Abraham, Delling,
Goldberg, Werneck (2011) showed technique practical huge road networks,
coined term Hub Labels. realization drastically increased interest HL thus
spawned numerous follow works, (Abraham, Delling, Goldberg, & Werneck, 2012;
Delling, Goldberg, & Werneck, 2013; Abraham, Delling, Fiat, Goldberg, & Werneck, 2012; Akiba,
Iwata, & Yoshida, 2013). context, relevant one probably RXL (Delling et al.,
2014), HL variant. authors show algorithm works well road
graphs variety graphs different sources including graphs derived maps used
GPPC. compare algorithm RXL.
HL index consists forward backward label node, contains list hub
nodes exact distances them. st-pair must exist meeting hub h
595

fiS TRASSER , B OTEA , & H ARABOR

forward hub backward hub shortest st-path. shortest distance query
node node answered enumerating common hubs t. labeling
good labels contain hubs. Computing labeling minimizing index size
NP-hard (Babenko, Goldberg, Kaplan, Savchenko, & Weller, 2015).
works consider HL general form, consider restrictive variant
called Hierarchical Hub Labels (HHL). term introduced Abraham et al. (2012)
labels used previous work (Abraham et al., 2011) already hierarchical. labeling called
hierarchical ordering vertices exists, every hub h vertex v comes v
order. Given fixed node order, optimal labeling computed efficiently (Abraham
et al., 2012). difficult task HHL consists computing node order. Computing node
order minimizing index size NP-hard task (Babenko et al., 2015).
HHL deeply coupled different popular speedup technique shortest path computations called Contraction Hierarchies (CH) (Geisberger, Sanders, Schultes, & Delling, 2008). CH
achieve query speeds HHL significantly smaller index sizes. However,
applications even CH query times already faster necessary, makes CH
strong competitor. CH iteratively contracts nodes inserting shortcuts maintain shortest
path distances remaining graph. following inserted shortcuts small fraction
graph needs explored every node. node order good CH search
spaces every node small. Again, computing optimal order NP-hard (Bauer, Columbus,
Katz, Krug, & Wagner, 2010). first HL paper road graphs (Abraham et al., 2011) computed
label v explicitly storing nodes reachable v CH search space applying pruning rules. Later papers refined rules, every hierarchical label
viewed explicitly stored pruned CH search space. consequence node orders
good CH good HHL vice versa, even though formal optimization
criteria differ therefore optimal order one respect criterion
slightly suboptimal other.
node orders used HHL original CH depend weights input graph.
Substantial changes weights requires recomputing node ordering. recent work
(Bauer, Columbus, Rutter, & Wagner, 2013; Dibbelt, Strasser, & Wagner, 2014) introduced
Customizable Contraction Hierarchies (CCH) shown node orders exist work well
depend structure input graph. node orders exploit input graph
small balanced node-separators comparative small treewidth.
paper consider two types node orders. first depth first search preorder
second based small balanced edge-cuts. thus independent input
graphs weights. However, confuse orders CCH node orders.
interchangeable. Using CCH ordering result bad performance technique,
using one node orders CCH work well. fact, using preorder CCH
maximizes maximum search space terms vertices instead minimizing it. is,
order works well technique CCH worst case node order. Further, orders
interchanged weight-dependent orders needed HHL CH.
described literature, HL answers distance queries. However, hinted Abraham
et al. (2012), easy extend hub labels first move queries. achieve this, entries
forward backward labels extended third component: first move edge ID. h
forward hub corresponding entry extended using first edge ID shortest
sh-path. h backward hub entry extended first edge shortest ht-path.
596

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

st-query first corresponding meeting hub h determined. 6= h first move
edge ID stored forward label otherwise first move contained backward
label t. slightly increases memory consumption negligible impact
performance. Note distance values needed even one wishes compute first-moves
need distances determine right hub several hubs common.
context program analysis sometimes desirable construct oracle determines particular section code ever reached. PWAH (van Schaik & de Moor, 2011)
one example. Similarly work, authors precompute quadratic matrix employ
compression scheme based run-length encoding. main difference reachability
oracles return yes-no answer every query rather identity first-edge.
Another speedup technique low average query times Transit Node Routing (TNR) (Bast,
Funke, & Matijevic, 2009; Bast, Funke, Matijevic, Sanders, & Schultes, 2007; Antsfeld, Harabor,
Kilby, & Walsh, 2012). However, two independent studies (Abraham et al., 2011; Arz, Luxen, &
Sanders, 2013) come conclusion (at least roads) TNR dominated HL
terms query time. Further, TNR optimize short range queries. scenario often
arises unit chases another unit. situations units tend close,
results many short range queries. TNR rather ineffective scenario.
Bulitko, Bjornsson, Lawrence (2010) present subgoal-based approach pathfinding. Similarities work include preprocessing stage paths map precomputed,
results compressed stored database. database used speed
response time path query posed system. substantial differences
two approaches well. method precomputes all-pairs shortest paths, eliminating graph
search entirely production mode (i.e., stage system queried provide full
shortest paths fragments shortest paths). contrast, Bulitko et al. restrict precomputed
database subset nodes, turn requires additional search production mode.
compression method different case. system provides optimal paths,
guaranteed case Bulitko et al.s method. Besides Bulitko et al. (2010) work, pathfinding
sub-goals turned popular successful idea recent work (Hernandez &
Baier, 2011; Bulitko, Rayner, & Lawrence, 2012; Lawrence & Bulitko, 2013; Uras, Koenig, &
Hernandez, 2013).
Pattern databases (PDBs) (Culberson & Schaeffer, 1998) lookup tables provide heuristic
estimations true distance search node goal state. obtained abstracting
original search space smaller space. Optimal distances abstracted space, every
state pre-established goal, precomputed stored pattern database estimations
distances original space. such, techniques memory-based enhancements
problems solution represented path graph. several key
distinctions PDBs CPDs. PDBs lossy abstractions, specific goal
subset goals. CPDs lossless compressions, encode shortest paths every starttarget
pair. Given lossy nature, PDBs need used heuristic within search algorithm,
example A*, opposed complete optimal method own. PDBs commonly
used large graphs, implicitly defined search spaces, exploring entire graph
preprocessing impractical. PDBs, coarseness abstraction impacts accurracy
heuristic estimations. finer abstraction better quality, result larger PDB.
Work addressing bottleneck include compressing pattern databases (Felner, Korf, Meshulam,
597

fiS TRASSER , B OTEA , & H ARABOR

& Holte, 2007; Samadi, Siabani, Felner, & Holte, 2008). contrast, CPDs compress all-pairs
shortest paths.

3. Preliminaries
denote G = (V, E) graph node set V edge1 set E V V . denote
deg(u) number outgoing edges u.2 maximum out-degree denoted . node
order : V [1, |V |] assigns every node v unique node ID o(v). out-going edges every
node ordered arbitrary fixed order position (index ordering) referred
out-edge ID.
Further, weight function w : E R>0 3 . st-path sequence edges a1 . . . ak
a1 starts ak ends tP
every edge ai ends node ai+1
starts. weight (or cost) path w(ai ). st-path shortest st-path exists
strictly smaller weight. distance two nodes weight shortest
st-path, one exists. st-path exists, distance . Notice may multiple
shortest st-paths weight.
Without loss generality assume duplicate edges (multi-edges) exist
graphs, were, could drop shortest edge, edges used
shortest path. Further, using similar argument, assume without loss generality
reflexive loops exist.
6= t, st-first-move first edge shortest st-path. multiple shortest
st-paths, may multiple st-first-moves. st-path exists, st-first-move exists.
formal problem consider following: Given pair nodes t, find st-first-move.
several valid first-moves, algorithm freely choose return.
Given oracle answers first move queries, easily extract shortest paths. Compute
st-first move a. words, first edge shortest path. Next, set end a.
long 6= t, apply procedure iteratively. Notice, works edge weights
guaranteed non-zero. allowed zero-weights, could run infinite-loop problem,
following example illustrates: Consider graph G two nodes x connected edges
xy yx weights zero. Denote node G. valid xt-first-move using xy.
valid yt-first-move using yx. oracle always returned two first-moves,
path extraction algorithm would oscillate x would terminate.
depth first search (DFS) way traversing graph constructing special sort
spanning tree using backtracking. depth-first preorder node order orders nodes
way DFS first sees them. search parameterized root node order
neighbors node visited. work regularly refer depthfirst preorders without stating parameters. always implicitly assume root
arbitrary node neighbors visited arbitrary order.
1. term arc used literature. Sometimes, distinction made whether graph directed (in
case authors prefer say arcs) undirected. paper, stick term edge cases.
2. directed graph, every ordered pair (u, v) E outgoing edge u. undirected graph, every edge
incident u outgoing edge u.
3. assume function E R>0 able apply Dijkstras algorithm preprocessing phase.
However, one could consider arbitrary weights without negative cycles replace every occurrence Dijkstras
algorithm algorithm Bellman Ford (Bellman, 1958; Ford, 1956).

598

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

Run length encoding (RLE) compresses string symbols representing compactly
substrings, called runs, consisting repetitions symbol. instance, string aabbbaaa
three runs, namely aa, bbb, aaa. run replaced pair contains start
value run. start index first element substring, whereas value
symbol contained substring. example, first run aa start 1 value a.
Run bbb start 3 value b, whereas last run start 6 value a.4
first last run value, need encode both. first
run easily reconstructed constant time case. First, decide whether first run
removed not, done checking first run among preserved ones
start equal 1. Secondly, needed, reconstruct first run, using 1 start position value
equal value last encoded run. Another way looking that, first
last run value, allow merge, wrapped around string
form cycle. allow this, say using cyclic runs. Otherwise (never consider
merging ends string), say use sequential runs. See Example 1 below.
Given ordered sequence elements (string), say two positions are: adjacent
next other; cyclic-adjacent adjacent one first last
position ordering; separated otherwise.
Let ordered sequence elements (symbols) dictionary (or alphabet) . Given
symbol , let -run RLE run containing symbol . every string , denote
N () total number occurrences symbol . Further, number sequential -runs
denoted Rs () number cyclic Rc (). Notice 0 Rs ()Rc () 1.
words, number sequential runs number cyclic runs never differ
1. Finally, denote Rs () total number sequential runs Rc () total number
cyclic runs. paper, assume first-move compression uses cyclic runs, unless
explicitly say otherwise.
Example 1. Consider string = aabbbaaa. Compressing yields 1, a; 3, b; 6, a.
means position 1 string consists as. Similarily position 3 bs
finally position 6 elements string ends. Na () = 5 Nb () = 3.
three sequential runs, namely aa, bbb aaa. first third ones a-runs,
whereas middle one b-run. Thus, Ras () = 2, Rbs () = 1, Rs () = 2 + 1 = 3.
time, one cyclic a-run. Indeed, put next two ends
string, string cyclic, occurrences string become one solid block (i.e.,
one cyclic a-run). Thus, Rac () = 1, Rbc () = 1, Rc () = 1 + 1 = 2.

4. Basic Idea
mentioned introduction, algorithm starts building |V | |V | all-pairs first-move
matrix m. entry position m[i, j] ij-first-move. central idea algorithm
compress row using RLE. compression performed gradually, matrix
rows computed, uncompressed matrix kept memory.
answer st-first-move query, run binary search row s. However, achieve
good compression ratio, first reorder columns decrease total number runs.
columns correspond nodes, regard problem reordering columns problem
4. Alternative encodings exist, value followed run length. E.g., a, 2; b, 3; a, 3 example.

599

fiS TRASSER , B OTEA , & H ARABOR

1
b,5

a,2
e,3
3

c,3
5

d,6
(a) Input

2
f ,4
4


12345
1a
2 ae f e
3 e ed c
4 f f dd
5 c c c c
(b) First-Move Matrix

1
2
3
4
5

1/a
1/a 3/e 4/f 5/e
1/e 4/d 5/c
1/f 3/d
1/c

(c) Compressed Path Database

Figure 1: toy example algorithm
computing good node order. Computing optimal node order minimizes number
runs NP-hard, show theoretical analysis. Fortunately, simple depth-first preorder
works well practice.
Sometimes, formal analysis, technical details annoying sense
make presentation somewhat complicated. question symbol
use m[i, i] example. practical implementation, say care
symbol, never query it. reduce number runs therefore assign either
value m[i 1, i] m[i + 1, i]. theoretical analysis, make similar assumption (i.e.,
dont care symbol) Sections 5 6. state Section 7, assumption
m[i, i] symbol different edge symbol. every case, assumptions
purpose keeping analysis simple possible.
Example 2. Figure 1a shows toy weighted undirected graph, 5 nodes 6 edges.
edge, show weight (cost), number, unique label, letter. first-move
matrix graph, corresponding node ordering 1, 2, 3, 4, 5, shown Figure 1b.
Recall entry m[r, c], r row c column, id first move
shortest path node r node c. example, m[3, 1] = e e first step ea,
optimal path node 3 node 1. Another optimal path would single-step path b,
ea b optimal weight (cost) 5. Thus, free choose m[3, 1] = e
m[3, 1] = b. prefer e leads better compression row 3 m, since
first two symbols third row, identical, part RLE run. show
Section 9 breaking ties optimal way feasible computationally easy.
compression given node ordering (or equivalently, matrix column ordering) shown
Figure 1c.
Notice ordering nodes impacts size compressed matrix. Example 2,
swapping nodes 3 4, illustrated Figure 2, would reduce number RLE runs
row 2, two e symbols become adjacent. total number runs decreases 11
runs 10 runs. Thus, challenge find optimal least good enough node ordering,
objective function size compressed first-move matrix.
compression strategy RLE illustrated Example 2 key component approach. study theoretically next three sections, showing computing optimal
node ordering NP-hard general, identifying tractability islands. present number
effective heuristic node orderings Section 8. variant implemented method, called SRC,
600

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

1
b,5

a,2
e,3
4

c,3
5

d,6
(a) Input

2
f ,4
3


12345
1a
2 af e e
3 f f
4 e e dc
5 c c c c
(b) First-Move Matrix

1
2
3
4
5

1/a
1/a 3/f 4/e
1/f 3/d
1/e 3/d 4/c
1/c

(c) Compressed Path Database

Figure 2: toy example Figure 1 different node ordering (i.e., nodes 3
4 swapped).
performs compression illustrated example. Another version program, called
MRC, goes beyond idea compressing row independently, implementing multi-row
compression strategy. discussed Section 9 evaluated empirically Section 12.

5. First-Move Compression Directed Graphs
Recall ordering columns first-move matrix affects number RLE runs
matrix. section show obtaining optimal ordering intractable general
input graph directed. construction works uniform edge weights. simplicitly
therefore omit weights section.
Definition 1. FMComp-d (First Move CompressionDirected) problem:
Input: directed graph G = (V, E); matrix size |V | |V | cell m[i, j] encodes
first move optimal path node node j; integer k.
Question: ordering columns that, apply RLE row,
total number cyclic RLE runs summed rows k?
Theorem 1. FMComp-d problem NP-complete.
Proof. easy see problem belongs NP, solution guessed verified
polynomial time.
NP-hardness shown reduction Hamiltonian Path Problem (HPP)
undirected graph. Let GH = (VH , EH ) arbitrary undirected graph, define n = |VH |
e = |EH |. Starting GH , build instance FMComp-d problem. According
Definition 1, instance includes directed graph, call GF , first-move matrix
GF , number.
GF = (VF , EF ) defined follows. node u VH , define node VF . call
nodes VF type-n nodes, indicate created original nodes VH .
edge (u, v) EH , define new node nuv VF (type-e nodes). new node nuv , define
two edges EF , one nuv u one nuv v. edges EF . See
Figure 3 example.
Table 1 shows first-move matrix running example. Given type-n node u,
nodes unreachable u graph GF . Thus, matrix row corresponding u
601

fiS TRASSER , B OTEA , & H ARABOR

nxy



x

x



w

z

nxw
w

z

nwz
Figure 3: Left: sample graph GH . Right: GF built GH . GF , x, y, w, z type-n nodes.
Nodes nij type e.

x

w
z
nxy
nxw
nwz

x
2
2
2
0
0
2


2
2
2
1
2
2

w
2
2
2
2
1
0

z
2
2
2
2
2
1

nxy
2
2
2
2
2
2

nxw
2
2
2
2
2
2

nwz
2
2
2
2
2
2
-

Nr. cyclic runs
1
1
1
1
3
4
3

Table 1: First-move matrix running example. rows columns follow node
ordering x, y, w, z, nxy , nxw , nwz .
one non-trivial symbol,5 chose symbol 2, denotes node
reachable. rows one RLE run each, regardless node ordering.
matrix row corresponding type-e node nuv three distinct (non-trivial) symbols total:
one symbol edge node u, another symbol edge node v, non-reachable
symbol 2 every node. Without generality loss, use symbol 0 edge u,
symbol 1 edge v. easy see that, nodes u v cyclic-adjacent given
ordering, nuv row 3 RLE runs. u v separated, row 4 RLE runs.
See Table 1 sample orderings.
claim HPP solution iff FMComp-d solution 4e + 1 RLE runs. Let
vi1 , vi2 . . . , vin solution HPP (i.e., Hamiltonian path GH ), let P EH set
edges included solution. show node ordering VF starting vi1 , . . . , vin ,
followed type-e nodes arbitrary order, result 4e+1 = 3(n1)+4(en+1)+n
runs, 3n 3 runs total type-e rows6 corresponding edges P ; 4(e n + 1) runs
total remaining type-e rows; n runs total type-n rows.
5. trivial symbol mean dont care symbol . Recall impact number runs.
simplicity, safely ignore symbol discussion.
6. say row type-n (or type-e) iff associated node type.

602

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

Indeed, edge (u, v) P , type-e row corresponding node nuv VF
3 RLE runs, since u v adjacent ordering. n 1 edges Hamiltonian
path, total number RLE runs 3(n 1) rows.
edge (u, v)
/ P , two nodes separated therefore corresponding matrix row
4 runs. sums 4(e n + 1) RLE runs rows corresponding edges
included Hamiltonian path.
Conversely, consider node ordering creates 4e + 1 = 3(n 1) + 4(e n + 1) + n RLE
runs total. show ordering type-n nodes contiguous block,7
ordering Hamiltonian path GH . equivalent saying exist n 1 pairs
type-n nodes u v u v cyclic-adjacent ordering, (u, v) EH .
proof contradiction. Assume p < n 1 pairs type-n nodes u v
u v cyclic-adjacent ordering, (u, v) edge EH .
p pairs, row corresponding type-e node nuv 3 RLE runs. remaining e p
type-e rows 4 RLE runs each. mentioned earlier, type-n rows n runs total,
regardless ordering. Thus, total number RLE runs 3p + 4(e p) + n = 4e p + n >
4e (n 1) + n = 4e + 1. Contradiction.

6. Compression Undirected Weighted Graphs
turn attention undirected weighted graphs, showing computing optimal ordering
NP-complete.
Definition 2. FMComp-uw problem (First Move CompressionUndirected, Weighted) defined follows.
Input: undirected weighted graph G = (V, E); matrix size |V | |V | cell m[i, j]
stores first move optimal path node node j; integer k.
Question: ordering ms columns that, apply run length encoding (RLE)
row, total number cyclic RLE runs matrix k?
stepping stone proving NP-hardness FMComp-uw, introduce problem
call SimMini1Runs (Definition 3), prove NP-completeness. SimMini1Runs inspired
work Oswald Reinelt (2009), studied complexity problem involving
so-called k-augmented simultaneous consecutive ones property (C1Sk ) 0/1 matrix (i.e.,
matrix two symbols, 0 1). definition, 0/1 matrix C1Sk property if,
replacing k 1s 0s, columns rows matrix ordered that,
row column, 1s row column come one contiguous block.
Oswald Reinelt (2009) proven checking whether 0/1 matrix C1Sk property
NP-complete. proof SimMini1Runs related, point later proof.
Given 0/1 matrix o, ordering columns, ordering rows, let global
sequential 1-runs count Gs1 (o) number sequential 1-runs summed rows
columns. is,
X
Gs1 (o) =
R1s (),


7. Here, notion contiguous block allows case part block end sequence,
part beginning, sequence cyclic.

603

fiS TRASSER , B OTEA , & H ARABOR

o=

r1
r2



c1

c2

c3

0
1

1
0

1
1



Figure 4: Running example 0/1 matrix o. Rows labelled ri , whereas cj represent column
labels.
iterated os rows columns. instance, Gs1 (o) = 6 matrix shown
Figure 4.
Definition 3. Simultaneous Mini 1-Runs (SimMini1Runs) problem defined follows.
Input: 0/1 matrix every row column contain least one value 1; integer k.
Question: ordering columns, ordering rows, Gs1 (o) k?
Theorem 2. SimMini1Runs NP-complete.
proof available Appendix A.
Lemma 1. Let 0/1 string starts 0, ends 0, both.
R1s () = R0c ().
Proof. Case (i): starts 0 ends 1. two end symbols different, sequential
runs cyclic runs identical. 0-runs 1-runs alternate, numbers identical. Case
(ii), starts 1 ends 0, similar previous one.
Case (iii): 0 ends. 0-runs 1-runs alternate, 0-runs
ends, follows R1s () = R0s () 1 = R0c ().
Theorem 3. FMComp-uw NP-complete.
Proof. NP-hardness shown reduction SimMini1Runs. Consider arbitrary
SimMini1Runs instance rows n columns. Figure 4 shows running example.
build undirected weighted graph G = (V, E) follows. V 3 types nodes, total
+ n + 1 nodes. column generates one node V . call c-nodes. row
generates one node well (r-nodes). extra node p called hub node.
One r-node ri one c-node cj connected unit-cost edge iff o[ri , cj ] = 1.
addition, edge weight 0.75 p every node. edges
exist graph G. See Figure 5 example.
Let first-move matrix G. row p fixed number runs, namely + n,8
regardless ordering ms columns. Let v c-node r-node. Apart vs adjacent
nodes, nodes reached shortest path cost 1.5 whose first move edge
(v, p). matrix running example shown Figure 6.
Let T1 total number occurrences symbol 1 matrix o. claim
ordering os rows columns results k sequential 1-runs (summed rows
columns) iff ordering columns resulting k + 2T1 + + n
8. Recall ignore dont care symbol m[p, p] = , impact number RLE runs.

604

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

p

c1

c2

c3

r1

r2

Figure 5: Graph running example. Dashed edges weight .75, whereas solid lines
unit-cost edges.

r1

m=

r1



r2









c1
c2
c3
p

r2

c1

c2

c3

p

0 0 1 2 0
0 1 0 2 0
0 1 0 0 0
1 0 0 0 0
1 2 0 0 0
1 2 3 4 5










Figure 6: first-move matrix running example. Without generality loss, 0 move
towards p. incident edges given node counted starting 1.
cyclic RLE runs total (summed rows). Thus rows m, except ps row,
k + 2T1 runs total.
Let ri1 , . . . rim cj1 , . . . cjn row column orderings result k
sequential RLE runs rows columns. show ordering ri1 , . . . rim , cj1 , . . . cjn , p
ms columns generates k + 2T1 + + n cyclic runs. Clearly, every row column
o, corresponding row 0 (see Figures 4 6 example). According
steps explained earlier illustrated Figures 4 6, 0 obtained follows.
original 0s preserved. original 1s replaced distinct consecutive integers starting
1. addition, 0 padded 0s one ends. Since 0 0s one
ends, follows R1s () = R0c ( 0 ).9 follows Rc ( 0 ) = R0c ( 0 )+N1 () = R1s ()+N1 ().
Summing Rc ( 0 ) rows 0 m, except ps row, obtain
X
0 (m)\{p}

Rc ( 0 ) =

X

R1s () +

(o)

X
(o)

N1 () k + 2T1 ,

denotes set rows matrix, set columns, = . follows
ms rows k + 2T1 + + n cyclic RLE runs total (that is, summed rows).
Conversely, assume ordering ms columns k + 2T1 + + n cyclic RLE runs
total (for rows). means summing runs rows m, except node ps
row, results k + 2T1 runs. exactly 2T1 distinct runs different 0-runs,
9. R1s () = R0c () Lemma 1, R0c () = R0c ( 0 ) construction.

605

fiS TRASSER , B OTEA , & H ARABOR

follows k 0-runs total:
X
0 (m)\{p}

R0c ( 0 ) k.

Let ri1 , . . . rim , cj1 , . . . cjn , p re-arragement ms columns that: r-nodes come
one contiguous block, relative ordering preserved; c-nodes one contiguous block,
relative ordering preserved.
Since G restricted c-nodes r-nodes bi-partite, rearrangement cannot possibly increase number RLE runs. (If anything, could eliminate 0-runs). hard
prove. example, current matrix row corresponds r-node source node,
m[a, b] = 0 every r-node b, since a, p, b optimal path b. Also,
m[a, p] = 0. rearrangement moves nodes b block cyclic-adjacent p,
create new run. case c-node source similar.
order os columns cj1 , . . . cjn , os rows ri1 , . . . rim . orderings,
relation row column corresponding row 0 follows.
non-zero values 0 converted 1s . 0 0s one ends cut
away . Since 0 contains 0s one ends, R1s () = R0c ( 0 ), according Lemma 1.
follows
X
X
R1s () =
R0c ( 0 ) k.
(o)(o)

0 (m)\{p}

7. Fighting Complexity Decomposition
far results negative. shown computing optimal order large
class graphs NP-hard. section identify tractability islands. show problem
decomposed along articulation points (which related cuts size 1). particular,
implies (as shown section) depth-first preorder optimal node ordering trees.
able construct optimal orders efficiently broader class graphs trees:
show problem fixed-parameter tractable size largest component
graph articulation points.
Definition 4. say node x graph G articulation point removing x adjacent edges G would split graph two disjoint connected subgraphs G1 . . . Gn .
Figure 7 shows example. rest section focus graphs G articulation
points x. consider cyclic runs. previous sections, treated m[s, s] dont care symbol,
impact number runs. section, make different assumption. Every cell
m[s, s] gets distinct symbol, called s-singleton, always creates run,
merged adjacent symbols common run. makes proofs easier
clearly significant impact number runs.
Definition 5. call x-block ordering node ordering x comes first, nodes G1
come next contiguous block, way block Gn .
606

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

Figure 7: graph articulation point x. Removing x would decompose graph four
disjoint components, depicted G1 G4 .

example shown Figure 7, ordering = x, a, b, c, d, e, f, g example
x-block ordering.
use o|G0 denote projection node ordering subset nodes corresponding
subgraph G0 G. use denote subgraph induced nodes Gi {x}.10
say order rotation another order o0 obtained o0 taking block
o0 elements beginning appending end. instance, d, e, f, g, x, a, b, c
rotation x, a, b, c, d, e, f, g. formally, rotation o0 two sub-orders
exist o0 = , = , .
Lemma 2. Let x articulation point graph G. Every node order rearranged
x-block ordering o0 without increasing number runs row.
Given graph G, node ordering row subset S, let N (o, G, S) number runs
restricted subset S. Clearly, N (o, G, G) total number runs.
Lemma 3. Given x-block ordering o, that:
1. N (o, G, Gi ) = N (o|i , , Gi );
P
2. N (o, G, {x}) = 1 n + N (o|i , , {x});
P
3. N (o, G, G) = 1 n + N (o|i , , ).
proofs Lemmas 2 3 available Appendix B.
Theorem 4. Given optimal order oi every subgraph induced , construct
optimal global ordering G following. Obtain new orderings o0i rotating oi x
comes first, removing x. Then, = x, o01 , . . . , o0n optimal.
Proof. show, contradiction, global ordering optimal. Notice o|i optimal
. Assume strictly better ordering o0 . According Lemma 2, exists x-block
10. subgraph induced subset nodes contains nodes edges whose ends belong S.

607

fiS TRASSER , B OTEA , & H ARABOR

ordering o00 least good o0 .
N (o, G, G) = 1 n +

X

1n+

X

N (o|i , , )





N (o00 |i , , )

= N (o00 , G, G) N (o0 , G, G)
contradiction o0 strictly better (i.e., N (o0 , G, G) < N (o, G, G)).
Lemma 4. G tree depth-first preorder G (with arbitrary root) rotated
x-block order every node x.
Proof. Every preorder induces rooted tree. respect root every node x (except root)
parent p possibly empty sequence direct children c1 . . . cn ordered way
depth-first search visited them. removing x, G decomposed subgraphs Gp ,
Gc1 . . . Gcn . x root Gp empty graph. order following structure:
nodes Gp , x, nodes Gc1 . . . nodes Gcn , remaining nodes Gp . Clearly
rotated x-block ordering.
Theorem 5. G = (V, E) tree depth-first preorder G N (o, G, G) = 3|V | 2.
Proof. direct consequence Lemma 4 every node v many runs d(v) + 1,
d(v) degree node. +1 comes v-singleton. thus
N (o, G, G) =

X
vV

(d(v) + 1) = 2|E| + |V | = 3|V | 2.

Theorem 6. Computing optimal order graph G fixed-parameter tractable size
largest two-connected component G (i.e., largest component articulation points).
Proof. Recursively decompose G articulation points two-connected parts left.
size parts depend size G enumerate orders pick
best one. Given optimal orders every part use Theorem 4 construct optimal global
order.
able decompose graphs along articulation points useful real-world road networks.
graphs tend large two-connected component many small trees attached. example Europe graph made available 9th DIMACS challenge (Demetrescu, Goldberg,
& Johnson, 2009) 18M nodes total 11.8M within largest twoconnected component. result allows us position 6.2M nodes order fast optimally
using local information.
608

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

8. Heuristic Node Orderings
Sections 5 6 shown computing optimal order NP-hard theory. Fortunately, NP-hardness rule existence good heuristic orderings
computed quickly. Indeed, simple depth-first preorder works well practice. observation partially explained fact that, shown Section 7, depth-first preorder
optimal trees. However, explain using informal intuitive terms.
ordering good neighboring nodes graph assigned neighboring IDs.
consistent previous observation (Sankaranarayanan et al., 2005; Botea, 2011) that, two
target nodes close other, chances first move current node towards
targets same. depth-first preorder achieves goal assigning close IDs
neighboring nodes low degree graphs. node either interior node, root, leaf
DFS tree. nodes graph tend interior nodes. these, depth-first preorder
assign two neighboring nodes adjacent IDs. Denote v internal node, p parent
c first child v. ID p ID v minus 1, whereas ID c ID
v plus one. guarantee nothing children. However, average node degree
low, case example road graphs, many children.
Besides using depth-first preorders, propose another heuristic based intuition assigning close IDs close nodes. based cuts. formulated intuitive
optimization criterion formulated following: every edge, endpoints
close ID. Obviously fulfilled edges once. reason proposed ordering tries identify small set edges property may violated.
using balanced edge cuts. Given graph n nodes want assign IDs range [1, n]
using recursive bisection. first step algorithm bisects graph two parts nearly
equal node counts small edge cut size. divides ID range middle assigns
lower IDs one part upper IDs part. continues recursively bisecting
parts dividing associated ID ranges parts constant size left.
described far algorithm free decide part assigns lower
upper ID ranges. reason augment tracking every node v two counters h(v)
`(v) representing number neighbors guaranteed higher lower IDs. Initially
counters zero. every bisection ranges assigned algorithm iterates
edge cut increasing counters border nodes. deciding two parts p q
gets ranges uses counters estimate ID distance parts nodes around
them. evaluates
X
X
X
X
h(v)
`(v) <
h(v)
`(v)
vq

vq

vp

vp

assigns higher IDs p condition holds. algorithm encounters part
small bisected assigns IDs ordered `(v) h(v).

9. Compression
Let a1 . . . denote uncompressed row first-move matrix. stated previously, SRC
compresses list runs ordered start. compressed rows vary size, need
additional index array maps source node onto memory offset first run
609

fiS TRASSER , B OTEA , & H ARABOR

row corresponding s. arrange rows consecutively memory therefore end ss
row start + 1s row. therefore need store row ends.
9.1 Memory Consumption
required node IDs encodable 28 bits out-edge IDs 4 bits. encode runs
start upper 28 bits 32-bit machine word value lower 4 bits. total memory
consumption therefore 4 (|V | + 1 + r) bytes r total number runs rows
|V | + 1 number offsets index array. Notice that, implementation, assume
4 bytes per index entry sufficient, equivalent saying r < 232 . formula
easily adapted sizes (i.e., number bits) node IDs, edge IDs, index entries.
instance, sum one node ID one edge ID K bytes, J bytes sufficient
encode index run (in words, number r fits J bytes), formula becomes
J (|V | + 1) + K r bytes.
9.2 Computing Rows
Rows computed individually running variant Dijkstras one-to-all algorithm every
source node compressed described detail Section 9.3. However, depending
graph possible shortest paths unique may differ first edge. therefore
possible multiple valid uncompressed rows exist tie-break paths differently. rows
may differ number runs therefore different compressed sizes. minimize
compressed size row, instead using Dijkstras algorithm compute one specific row
a1 . . . modify compute sets A1 . . . valid first move edges. require
shortest st-path must exist uses first edge. algorithm maintains alongside
tentative distance array d(t) node set valid first move edges . algorithm
relaxes edge (u, v) decreasing d(v) performs Av Au . d(u) + w(u, v) = d(v)
performs Av Av Au . restricted out-degree node 15 store
sets 16-bit bitfields. Set union performed using bitwise-or operation.
9.3 Compressing Rows Run Length Encoding
every target compression method given set valid first move edges may pick one
minimizes compressed size. formalize subproblem following: Given sequence
sets A1 . . . find sequence a1 . . . ai Ai minimizes number runs.
show subproblem solved optimally using greedy algorithm. algorithm begins
determining longest run
includes a1 .
done scanning A1 . . . Ai Ai+1
intersection empty: j[1,i] Aj 6= j[1,i+1] Aj = . algorithm chooses
value intersection (it matter which) assigns a1 . . . ai . continues
determining longest run starts contains ai+1 way. procedure
iterated rows end reached. approach optimal show
optimal solution longest first run exists. valid solution longer first run.
optimal solution shorter first run transformed increasing first runs length
decreasing second ones without modifying values. subsequences exchanged
without affecting surroundings conclude greedy strategy optimal.
610

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

1
b,5

a,2
e,3
4

c,3
5

d,6

2
f ,4
3

1
2
3
4
5

1/a
1/a 3/f 4/e
1/f 3/d
1/e 3/d 4/c
1/c

(a) Input

(b) SRC

1
2
3
4
5

X
X 3/f 4/e
1/f
1/e 4/c
Z

(c) MRC per row info.

X 1/a
3/d
Z 1/c

(d) MRC per group info.

Figure 8: MRC applied toy graph Figure 2, reproduced convenience, left.
Part (b) illustrates SRC input full runs Rs every row. Part (c) show groups (X,
, Z) row row-specific runs R0 . Finally, part (d) depicts runs R0 g shared
rows group.

9.4 Merging Rows using Groups
compress individual rows exploited shortest paths t1 t2 often
first move t1 t2 close. similar observation made close source nodes
s1 s2 . compressed rows tend resemble other. want compress
data exploiting redundancy. call technique multi-row compression (MRC)
illustrate Figure 8. partition nodes groups store group information
shared nodes group. row store information unique it. Denote
g(s) unique group node s. Two runs different rows start value
32-bit pattern. Denote Rs set runs row s. Instead storing
row
whole set Rs store group h intersection rows. is,
0
store R h = ih Ri . row store R0 = Rs \ Rg(s) . Recall query target
consists finding max{x Rs | x < t0 } (where t0 = 15t + 16). Notice formula
rewritten using basic set logic max{max{x R0 | x < t0 }, max{x R0 g(s) | x < t0 }}
implemented using two binary searches R0 stored ordered arrays. Note
need second index array lookup R0 g groups g.
9.5 Computing Row Groups
design close source nodes close node IDs thus neighbouring rows. motivates
restricting row-run groupings. is, group h rows j
rows [i, j] belong group. optimal row-run grouping computed using
dynamic programming. Denote S(n) maximum number runs saved compared using
group-compression restricted first n rows. Notice S(1) = 0. Given S(1) . . . S(n)
want compute S(n + 1). Obviously n + 1s row must part theT
last group. Suppose
last group length ` save total S(n + 1 `) + (` 1) | i[n+1`,n+1] Ri | runs.
n different values ` enumerate, brute force, possible values,
resulting algorithm running time (n2 ). observe intersection large
groups often seems nearly empty therefore test values ` 100 resulting
(n) heuristic.
611

fiS TRASSER , B OTEA , & H ARABOR

10. Queries
Given source node target node (with 6= t) algorithm determines first edge
shortest st-path. first determining start end compressed row
using index array. runs binary search determine run containing
corresponding out-edge ID. precisely algorithm searches run largest start
still smaller equal t. Recall encode run single 32-bit machine word
higher 28 bits runs start. reinterpret 32-bits unsigned integers.
algorithm consists binary search ordered 32-bit integer largest element
larger 16t + 15 (i.e., higher 28 bits 4 lower bits set).
Extracting path using CPDs extremely simple recursive procedure: beginning start
node extract first move toward target. follow resultant edge neighbouring
node repeat process target reached.

11. Experimental Setup
evaluate work consider two types graphs: road graphs grid-based graphs.
cases assume node IDs encoded within 28-bit integers. assume
15, use distinct value (15) indicate invalid edge. allows us encode
out-edge IDs within 4 bits. Note concatenation node ID out-edge ID fits
single 32-bit machine word.
experiments performed quad core i7-3770 CPU @ 3.40GHz 8MB combined cache, 8GB RAM running Ubuntu 13.10. algorithms compiled using g++ 4.8.1
-O3. reported query times use single core.
11.1 Grid Graphs
chosen three benchmark problem sets drawn real computer games. first two sets
benchmark instances appeared 2012 Grid-Based Path Planning Competition. third
benchmark set consists two worst case maps terms size. two maps available part
Nathan Sturtevants extended problem repository http://movingai.com/benchmarks/
part 2012 competition set.
first benchmark set features 27 maps come game Dragon Age Origins.
maps 16K nodes 119K edges, average.
second benchmark set features 11 maps come game StarCraft.
maps 288K nodes 2.24M edges, average.
third benchmark set comprises two large grids evaluate separately.
largest maps available two games. extended Dragon Age Origins
problem set choose map called ost100d. 137K nodes 1.1M edges.
extended StarCraft problem set choose map called TheFrozenSea.
754K nodes 5.8M edges. Note ost100d, largest Dragon Age
Origins map, smaller average StarCraft map.
grid maps evaluation undirected feature two types
edges: straight edges
weight 1.0 diagonal edges weight 2.
612

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

11.2 Road Graphs
case road graphs chosen several smaller benchmarks made available
9th DIMACS challenge (Demetrescu et al., 2009).
New York City map (henceforth, NY) 264K nodes 730K edges.
San Francisco Bay Area (henceforth, BAY) 321K nodes 800K edges.
Finally, State Colorado (henceforth, COL) 436K nodes 1M edges.
three graphs travel time weights (denoted using -t suffix) geographic distance weights
(denoted using -d) available.
11.3 Comparisons
implemented algorithm two variants: single-row-compression (SRC) using row
merging optimization, multi-row-compression (MRC), using optimization. compare
approaches two recent state-of-the-art methods: Copa (Botea & Harabor, 2013b)
RXL (Delling et al., 2014). evaluate two variants Copa. first variant,
denote Copa-G, appeared 2012 GPPC optimised grid-graphs. use original
C++ implementation available competition repository (Sturtevant, 2012a).
second variant, denote Copa-R, optimised road graphs. algorithm described
(Botea & Harabor, 2013a); used original C++ implementation program version
well.
RXL newest version Hub-Labeling algorithm. asked original authors
run experiments us presented below. experiments carried Xeon E52690 @ 2.90 GHz. compensate lower clock speed, compared test machine,
scale query times RXL factor 2.90/3.40 = 85%. important note
implementation RXL computes path distances instead first-moves. discussed Section 2
make significant difference query times. However unclear us whether
possible incorporate additional data needed first-move computation compression
schemes presented Delling et al. (2014). reported RXL database sizes therefore
regarded lower bounds.

12. Results
evaluate two algorithms (SRC MRC) terms preprocessing time, compression
performance query performance. study impact range heuristic node orderings
using metrics. three variants, distinguished suffix. suffix +cut
indicates node ordering based balanced edge-separators graph cutting technique described
Section 8. suffix +dfs indicates node ordering based depth-first search traversal,
described Section 8. suffix +input (or shorter +inp) indicates order nodes taken
associated input file. case grid graphs ordered nodes lexicographically, first
y- x-coordinates. applicable compare work state-of-the-art
first-move algorithms Copa-R Copa-G. compare recent hub labeling
technique known RXL space efficient (but fast) variant called CRXL.
613

fiS TRASSER , B OTEA , & H ARABOR

Benchmark
DIMACS
Dragon Age Origins
StarCraft
ost100d
TheFrozenSea

Average Preprocessing Time (seconds)
Compute Order
Single Row Compression
Multi Row Compression
+cut
+dfs
+input
+cut
+dfs
+input
+cut
+dfs
+input
16
<1
0
1950
1982
2111
1953
1985
2125
2
<1
0
32
35
38
33
36
40
18
<1
0
1979
2181
2539
1993
2195
2574
19
<1
n/m
101
100
n/m
104
105
n/m
110
<1
n/m
3038
3605
n/m
3133
3690
n/m

Table 2: Preprocessing time road grid graphs. give results (i) average time required
compute node ordering; (ii) total time required compute entire database SRC
MRC. Values given nearest second. ost100d TheFrozenSea preprocessing experiments
run AMD Opteron 6172 48 cores @ 2.1 GHz accelerate APSP computation.
experiments smaller graphs clearly show input order fully dominated. therefore omit
numbers two larger test graphs. n/m stands measured.
Graph
|V |

|E|
|V |

CopaG

+cut

Min < 1K
7
Q1
2K 7.2
Med
5K 7.4
Avg 31K 7.4
Q3
52K 7.6
Max 100K 7.7

<1
<1
1
12
18
75

<1
<1
<1
5
6
31

Min
Q1
Med
Avg
Q3
Max

60
128
183
351
510
934

20
28
69
148
189
549

105K
173K
274K
288K
396K
494K

7.7
7.7
7.8
7.8
7.8
7.8

DB Size (MB)
Query Time (nano seconds)
MRC
SRC
MRC
SRC
UM CopaG
+dfs +inp +cut +dfs +inp
+cut +dfs +inp +cut +dfs
Dragon Age: Origins (27 maps)
<1 <1 <1 <1 <1
<1
34
19 26 26
14 19
<1 <1 <1 <1 <1
2
63
22 31 35
16 22
1
1
<1 1
2
12.5
81
30 44 54
20 31
7
23
6
8
53
480.5
156
34 50 72
25 36
10
29
7
12
65
1352
266
36 62 106 28 45
39 106 35 44 349 5000
316
95 116 176 67 78
StarCraft (11 maps)
35
89
25 42 187 5512.5 304
63 93 130 47 63
61 144 33 71 281 14964
324
70 103 142 51 69
111 393 83 126 956 37538
334
95 121 187 66 77
203 444 172 222 983 41472
358
105 130 195 66 82
282 621 222 308 1318 78408
396
126 146 226 72 90
626 1245 630 660 2947 122018 436
197 195 311 108 118

+inp
18
26
38
54
82
138
88
102
133
132
156
208

Table 3: Performance SRC MRC grid graphs. use two problem sets taken 2012
GPPC compare Copa-G, one winners competition. measure (i) size
compressed database (in MB) and; (ii) time needed extract first query (in nanos). values
rounded nearest whole number (either MB nano, respectively). baseline, column UM shows
size naive, non-compressed first-move matrix.

12.1 Preprocessing Time
Table 2 gives average preprocessing time SRC MRC 6 road graphs two
competition sets. time case dominated need compute full APSP table.
previously commented, APSP compression central point work;
APSP-computation. preprocessing approach involves executing Dijkstras algorithm repeatedly
resulting total running time O(n2 log n) sparse graphs non-negative weights; using
modern APSP techniques (e.g., Delling, Goldberg, Nowatzyk, Werneck 2013) succeeded
significantly reducing hidden constants behind big-O able exploit specific
graphs structures (e.g., road graphs) get running time down. However, techniques
give benefit repeatedly running Dijkstras algorithm asymptotic worst-case.
614

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

Graph
Name

|V |

|E|
|V |

BAY-d
BAY-t
COL-d
COL-t
NY-d
NY-t

321K
321K
436K
436K
264K
264K

2.5
2.5
2.4
2.4
2.8
2.8

DB Size (MB)
Query Time (nano seconds)
Copa Hub Labels
MRC
SRC
Copa Hub Labels
MRC
SRC
UM
-R RXL CRXL +cut +dfs +cut +dfs
-R RXL CRXL +cut +dfs +cut +dfs
317 90
19
141 129 160 144 51521 527 488 3133 89 100 62 69
248 65
17
102 95 117 107 51521 469 371 1873 74 87 52 60
586 138 24
228 206 268 240 95048 677 564 3867 125 111 68 85
503 90
22
162 150 192 175 95048 571 390 2131 88 97 58 65
363 99
21
226 207 252 229 34848 617 621 4498 112 122 75 83
342 66
18
192 177 217 198 34848 528 425 2529 98 111 67 75

Table 4: Comparative performance SRC, MRC, Copa-R two recent Hub Labeling algorithms.
report size UM uncompressed matrix. test one six graphs 9th DIMACS
challenge. measure (i) database sizes (in MB); (ii) time needed extract first query (in nanos).
Values rounded nearest whole number. Graph sizes rounded nearest thousand nodes.

Creating node order fast; +dfs requires fractions second. Even +cut order
requires 18 seconds average using METIS (Karypis & Kumar, 1998). Meanwhile,
difference running times SRC MRC indicate multi-row compression
add small overhead total time. test instances
recorded preprocessing overhead order seconds.
12.2 Compression Query Performance
Table 3 give overview compression query time performance Copa-G
range SRC MRC variants competition benchmark sets. measure query
performance run 108 random queries source target nodes picked uniformly random
average running times.
MRC outperforms SRC terms compression expense query time. Node orders
significantly impact performance SRC MRC. cases +cut yields smaller database
faster queries. SRC MRC using +cut +dfs convincingly outperform Copa-G
majority test maps, terms space consumption query time.
naive, non-compressed first-move matrix impractical due large memory requirements. size uncompressed matrix would 4 |V |2 bits, reflecting assumption
outgoing edge stored 4 bits. Tables 3, 4, 5 specify column UM memory consumption uncompressed matrix. example, ost100d game graph 137K,
non-compressed matrix requires bit 9GB memory, two orders magnitude higher 49MB, respectively 39MB SRC+cut respectively MRC+cut
need. larger graphs, difference striking. example TheFrozenSea, largest
game graph, 754K nodes leads 576MB MRC+cut database compared 284GB noncompressed matrix. hand, smaller graphs matrix would fit memory,
fetching moves would extremely fast, one table lookup per move. comparison,
fetch one move, method performs binary search compressed string whose length
larger, usually much smaller |V |.
Table 4 look performance 6 road graphs compare Copa-R, SRC, MRC,
RXL CRXL. main observations road graphs +dfs leads smaller CPDs
+cut. Surprisingly, lower average row lengths yield faster query times. Copa-R dominated RXL, SRC, MRC. SRC+cut outperforms competitors several factors terms
615

fiS TRASSER , B OTEA , & H ARABOR

Graph
Name
ost100d
FrozenSea

|V |

|E|
|V |

137K
754K

7.7
7.7

DB Size (MB)
MRC
SRC
UM
RXL CRXL +cut +dfs +cut +dfs
62
24
39
50
49
57
9436
429 135
576 634 753 740 284405
Hub Labels

Query Time (nano seconds)
Hub Labels
MRC
SRC
RXL CRXL +cut +dfs +cut +dfs
598 5501
89 110
58
71
814 9411 176 192 104 109

Table 5: Performance SRC MRC large grid graphs Nathan Sturtevants extended repository.
compare Hub Labeling methods RXL, CRXL. report size UM uncompressed matrix. run tests TheFrozenSea, drawn game StarCraft, ost100d, comes
game Dragon Age Origins. measure (i) database sizes (in MB); (ii) time needed extract
first query (in nanos). Values rounded nearest whole number. RXL & CRXL exploit graphs
undirected SRC & MRC not. directed graphs space consumption RXL would double.

Graph
BAY-d
BAY-t
COL-d
COL-t
NY-d
NY-t
FrozenSea
ost100d

Average Row Label
Length
Space (Bytes)
SRC
SamPG
SRC
SamPG
+cut +dfs + Plain +cut +dfs
51
129 108
816
516 432
34
94
79
544
376 316
59
160 131
944
640 524
35
114
96
560
456 384
70
248 203
1120
992 812
44
214 175
704
856 700
92
260 256
1472
1040 1024
80
91
108
1280
364 432

Table 6: report average number hubs per label (length), number runs per row (length),
average space usage per node SamPG+Plain SRC.

speed. RXL wins terms database size. However factor gained space smaller
factor lost query time compared SRC. CRXL clearly wins terms space two
orders magnitude slower competition. road graphs distance weights harder
travel time weights. already known algorithms exploit similar graph features
RXL. However, interesting seemingly unrelated first-move compression based algorithms
incur penalties.
Table 5 evaluate performance SRC, MRC, RXL CRXL larger game
maps. dropped Copa-R experiments smaller graphs clear
fully dominated. road graphs, space consumption SRC MRC lower
+cut order +dfs. result +cut order clearly superior +dfs game maps.
ost100d SRC MRC beat RXL terms query time space consumption.
TheFrozenSea RXL needs less space SRC MRC. However, note game maps RXL
gains factor 2 exploiting graphs undirected SRC MRC not.
CRXL employs powerful compression techniques specific shortest paths. RXL use
uncompressed uses basic encoding techniques delta encoding.
basic HL variant stores nodes distances explicitly needs memory. refer
basic variant SamPG+Plain. SamPG ordering algorithm used RXL11 Plain refers
11. RXL-paper describes several node orders. However, SamPG order suggest using. RXL
CRXL numbers paper use SamPG.

616

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

1
b,5

a,2
e,3

2
f ,4

4
c,3
5

d,6

3

(a) Input Graph

(b) Computing rectangles

(c) List rectangles

Figure 9: Copas rectangle decomposition toy example Figures 2 8 first
moves source node 2. Similar decompositions needed every source node.

elementary HL encoding 4 bytes per hub ID 4 bytes per distance value. want
comparse SRC SamPG+Plain. therefore report Table 6 average number hubs
per label average number runs per row using SRC. reported number hubs per
label. Note directed graphs every node needs two labels: forward backward label.
undirected graphs two labels coincide one stored. contrasts
SRC cannot exploit input graph undirected. numbers table therefore
assume two HL-labels needed per node better comparability. HL need store
32-bit distance value, 28-bit node ID 4-bit out-edge ID times 2
two labels per node. total space consumption thus 16h bytes h average
number hubs per label. SRC need store 28-bit node ID 4-bit out-edge ID per
run. results 4r bytes r average number runs per row. Table 6
seen SamPG+Plain consistently occupies space SRC, even though experiments
thus far suggest RXL compact. basic compression techniques RXL therefore
important enough make performance ordering algorithms tip respect
space consumption.
RXL advantages visible tables. example require computing
APSP preprocessing step significantly reducing preprocessing time. computes
besides first move shortest path distance.
12.3 Discussion
compared SRC MRC Copa RXL. Copa recent successful technique creating compressed path databases. one joint winners 2012 Grid-Based Path Planning
Competition (GPPC-12) regard Copa current state-of-the-art range pathfinding
problems including efficient storage extraction optimal first-moves. RXL newest
version Hub-Labeling algorithm knowledge state-of-the-art terms minimizing query times road graphs.
617

fiS TRASSER , B OTEA , & H ARABOR

SRC MRC illustrated Figures 1, 2 8. Figure 9 illustrates Copa
works preprocessing, better understanding section, without intention fully
detailed description. Copa assumes every node graph labelled x, coordinates.
toy example 3 rows 3 columns, shown Figure 9 (a). Copa iterates
nodes graph. Let n current node (source node) given iteration. Copa splits
map rectangles, labels rectangle id outgoing edge n.
target belongs given rectangle, optimal move n towards precisely label
rectangle. Figure 9 (a) shows map decomposition source node 2, rectangles depicted
dashed line. three rectangles constructed figure: one bottom left,
size 2 2 label e; one top left, size 1 1 label a; one bottom right,
size 1 1 label f . part (b), rectangle represented 5 symbols each: upper
row, left column, width, height, label. show rectangles source node 2,
concatenated lists nodes. rectangles safely removed (list
trimming) skip example. Then, 5 columns Figure 9 (a) treated
separate string, compressed sliding window compression run-length
encoding.
performed experiments large number realistic grid-graphs used GPPC-12 find
SRC MRC significantly improve query time compression power
Copa. large number experiments broad range input maps able extract
first move tens hundreds nano-seconds (a factor 3 5 faster Copa).
two main reasons SRC MRC performant vs. Copa: approach uses less memory
query running time logarithmic (cf. linear) label size.
approach requires less memory Copa. Part explanation stems differences sizes building blocks approach. SRC MRC, building
block RLE run represented two numbers: start run, node id
thus requires log2 (|V |) bits, value run, out-edge id requires log2 ()
bits. Copa, building block rectangle requires 2 log2 (|V |) + log2 () bits. actual
implementations, SRC MRC store single 32-bit machine word per run, allows graphs 228 nodes. Copa code used 2012 Grid-Based Path Planning
Competition stores rectangle 48 bits, corresponding max node count 222 .
Clearly, size building blocks reason different compression
results. number RLE runs SRC MRC differ total number rectangles
Copa. one optimal out-edge exists, SRC MRC select edge
improve compression, whereas Copa sticks one arbitrary optimal out-edge.
hand, besides rectangle decomposition, Copa implements additional compression methods,
list trimming, run length encoding sliding window compression, performed top
original rectangle decomposition (Botea & Harabor, 2013a).
approach asymptotic query time O(log2 (k)) k number compressed
labels must searched. comparison, given source node, Copa stores corresponding
list rectangles decreasing order size. Rectangles checked order. While,
worst-case, total number rectangle checks linear size list, average number
much improved due ordering mentioned (Botea, 2011; Botea & Harabor, 2013a).
reason CPD faster RXL due basic query algorithm. algorithm
underlying RXL consists merge-sort merge two integer arrays formed forward
label backward label t. fast cache friendly operation needs look
618

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

entry resulting inherently linear time operation. SRC hand builds upon
binary search slightly less cache friendly memory accesses sequential
logarithmic running time.
One regard compressed SRC rows one-sided labels. st-pair first move
determined using label s. HL hand needs forward label
backward label t. HL-labels tend less entries SRC labels. However,
HL-entry needs space need store distance values addition node-IDs.

13. Results 2014 Grid-Based Path Planning Competition
recently submitted algorithms SRC+cut SRC+dfs 2014 edition GridBased Path Planning Competition GPPC (Sturtevant, 2014). section give brief overview
competition short summary results. full description methodology employed
organisers, well full account results, given (Sturtevant et al., 2015).
13.1 Competition Setup
Grid-Based Path Planning Competition features one hundred grid maps
three hundred thousand distinct problem instances drawn. Individual maps differ size,
ranging several thousand several million nodes. topography maps varied
many maps originating computer games StarCraft, Dragon Age: Origins Dragon
Age 2. maps appearing part competition synthetically generated grids; mazes,
rooms randomly placed obstacles varying density. 2014 edition competition
total 14 different entries, submitted 6 different teams. Several entries variants
algorithm submitted team.
6 entries employ symmetry breaking speed search. entries BLJPS, BLJPS2, JPS+
JPS+Bucket roughly described extensions Jump Point Search (Harabor &
Grastien, 2011) JPS+ (Harabor & Grastien, 2014). entry NSubgoal makes use
multi-level Subgoal Graphs (Uras & Koenig, 2014). Finally entry named BLJPS Sub
hybrid algorithm makes use Jump Point Search Subgoal Graphs.
1 entry (CH) employs variation Contraction Hierarchies (Dibbelt et al., 2014).
3 entries directly improve performance A* algorithm; either use faster
priority queues (A* Bucket) trading optimality speed (RA* RA*-Subgoal).
4 entries use Compressed Path Databases. Two (SRC+dfs-i SRC+cut-i)
incremental algorithms return optimal path one segment time; is, must
called repeatedly target location returned. two algorithms (SRC+dfs
SRC+cut) non-incremental queried return complete path.
Unfortunately, 3 entries contained bugs therefore finish instances.
SRC+cut one them. therefore omit tables discussion.
13.2 Results
summary results competition given Table 7. observe following:
619

fiS TRASSER , B OTEA , & H ARABOR

Entry


RA*
BLJPS
JPS+
BLJPS2

RA*-Subgoal
JPS+ Bucket
BLJPS2 Sub
NSubgoal
CH
SRC-dfs
SRC-dfs-i

Averaged Query Time Test Paths (s)
Slowest Move
First 20 Moves
Full Path
Path
path
Extraction
282 995
282 995
282 995
14 453
14 453
14 453
7 732
7 732
7 732
7 444
7 444
7 444
1 688
1 688
1 688
1 616
1 616
1 616
1 571
1 571
1 571
773
773
773
362
362
362
145
145
145
1
4
189

Preprocessing Requirements
DB Size
Time
(MB)
(Minutes)
0
0.0
20
0.2
947
1.0
47
0.2
264
0.2
947
1.0
524
0.2
293
2.6
2 400
968.8
28 000
11649.5
28 000
11649.5

Table 7: Results 2014 Grid-Based Path Planning Competition. Figures summarised
official competition results, appear (Sturtevant et al., 2015). Entries denoted
indicate approximate algorithms guaranteed always find shortest path.
measurments bold indicate entry performed best regard single criterion.
entries whose name bold fully Pareto-dominated respect every
criterion. preprocessing running times time needed process 132 test maps.
1. CPD-based entries fastest methods competition across query time metrics. includes fastest (average) time required extract complete optimal path,
fastest (average) time extract first 20 steps optimal path fastest (average)
time required extract single step optimal path.
2. Performing first move query algorithm faster resolution competitions microsecond timer. Even iteratively extracting 20 edges path barely
measurable without finer timer resolution. testing observed significant
amount query running time spent within benchmarking code provided
competition. therefore opted submit two variants. SRC+dfs extracts path
whole. benchmarking code thus run per path. hand SRC+dfs-i
extracts path one edge time. allows measuring time needed individual
first move query. Unfortunately, requires executing benchmarking code per
edge. difference path extraction running times SRC-dfs SRC-dfs-i (i.e.,
44s) time spent benchmarking code.
3. algorithm competitor able answer first-move queries faster
full path extraction.
4. entries database driven require generous amounts preprocessing time
storage space. SRC+dfs therefore largest total preprocessing time largest
total storage cost entries competition.

14. Conclusion Future Work
study problem creating efficient compressed path database (CPD): shortest path
oracle which, given two nodes weighted directed graph, always returns first-move
620

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

optimal path connecting them. Starting all-pairs first-move matrix, assume
given, create oracles compact answer arbitrary first-move queries
optimally many orders faster otherwise possible using conventional online graph search
techniques. employ run-length encoding (RLE) compression scheme throughout analyse
problem theoretical perspective empirical one. main idea simple:
look re-order nodes (i.e., columns) input first-move matrix good way
RLE-compressed size subsequently reduced.
theoretical side show problem finding optimal node ordering,
general case directed directed graphs, NP-complete. specific cases,
graphs decomposed along articulation points, problem efficiently tackled
solving series independent sub-problems. particular show depth-first traversal
tree provides optimal node ordering. results give first theoretical underpinning
problem creating space-efficient CPDs using RLE. work extends theoretical results
areas information processing databases (Oswald & Reinelt, 2009; Mohapatra, 2009).
empirical side study efficacy three heuristic node orderings: (i) depth-first
ordering; (ii) graph-cut ordering based balanced edge separators; (iii) naive baseline given
ordering specified input graph. Given ordering first-move matrix, describe
two novel approaches creating CPDs. first these, SRC, uses simple run-length encoding
compress individual rows matrix. second approach, MRC, sophisticated
identifies commonalities sets labels compressed SRC.
range experiments show SRC MRC compress APSP matrix graphs
hundreds thousands nodes little 1-200MB. Associated query times regularly
require less 100 nanoseconds. compare approaches Copa (Botea, 2012;
Botea & Harabor, 2013a), RXL (Delling et al., 2014). range experiments grid
road graphs show SRC MRC competitive Copa often several
factors better, terms compression query times. show SRC MRC
outperform RXL terms query time. summarise results 2014 Grid-Based
Path Planning Competition. particular report SRC fastest method
competition across query-time metrics SRC performed better resolution
competitions microsecond timer.
appear several promising directions current work could extended. One
immediate possibility harness available results efficient appproximate TSP algorithms
order compute better space-efficient node orderings. Another immediate possibility
improve current MRC compression scheme devising algorithm optimizes
assignment first-move IDs.
Looking broadly, strength CPDs have, addition fast move extraction,
compress kind path network-distance optimal.12
multi-agent pathfinding example sometimes useful guarantee properties must
always local detour available (Wang & Botea, 2011). Another example turn-costs road
graphs. Thus one possible possible direction future work create CPDs store
paths satisfying constraints.
weakness approach preprocessing APSP-computation required.
Delling et al. (2013) shown APSP sometimes computed reasonably fast
12. Suboptimal paths, however, introduce additional challenge avoiding infinite loops extracting path
CPD.

621

fiS TRASSER , B OTEA , & H ARABOR

graphs many nodes, APSP remains inherently quadratic number nodes
graph class output size quadratic. approach would therefore hugely profit
algorithm directly compute compressed CPD without first computing first-move
matrix intermediate step.

15. Acknowledgments
thank Patrik Haslum, Akihiro Kishimoto, Jakub Marecek, Anika Schumman Jussi Rintanen
feedback earlier versions parts work. would thank Daniel Delling &
Thomas Pajor running Hub-Labeling experiments us.

Appendix A. Proof Theorem 2
Theorem 2. SimMini1Runs NP-complete.
Proof. membership NP straightforward. hardness proof uses reduction
Hamiltonian Path Problem (HPP) undirected graph. Let G = (V, E) arbitrary undirected
graph, without duplicate edges, define n = |V | e = |E|. Figure 10 shows toy graph used
running example.
Starting G, build SimMini1Runs instance follows. define 0/1 matrix
e rows n columns. Let r row corresponding edge (u, v), let cu cv
columns associated nodes u v. m[r, cv ] = m[r, cu ] = 1 m[r, c] = 0
columns. Notice least value 1 every row column. Figure 11 shows
matrix running example.
x



w

z

Figure 10: Sample graph G.
Let r matrix row corresponding edge (u, v). easy see that, given
ordering columns (nodes) makes two nodes u v adjacent, number sequential

(x, y)
(x, w)
(x, z)
(w, z)

x
1
1
1
0


1
0
0
0

w
0
1
0
1

z
0
0
1
1

Figure 11: Matrix built G.
622

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

(x, z)
(w, z)
(x, w)
(x, y)


0
0
0
1

x
0
0
1
1

w
0
1
1
0

z
1
1
0
0

Figure 12: matrix after: i) converting 1s 0s (shown bold); ii) re-ordering columns
Hamiltonian path; iii) re-ordering rows lexicographically.

(x, z)
(w, z)
(x, w)
(x, y)


0
0
0
1

x
1
0
1
1

w
0
1
1
0

z
1
1
0
0

Figure 13: Matrix restoring back previously replaced 1s (shown bold).
RLE 1-runs13 row r 1. nodes adjacent, number sequential RLE 1-runs
row r 2.
claim HPP solution iff SimMini1Runs solution = 3e n + 2 RLE
1-runs. Let vi1 , . . . , vin solution HPP (i.e., Hamiltonian path), let P set
edges included solution. running example, let P contain (y, x), (x, w) (w, z).
every row corresponding edge contained P , switch one two 1-entries
0. Then, order columns respect sequence nodes Hamiltonian path
rearrange rows lexicographical order. Figure 12 illustrates changes.
construction matrix, trick converting 1s 0s, ordering
rows columns reused Oswald Reinelts proof hardness deciding
whether 0/1 matrix C1Sk property (Oswald & Reinelt, 2009). rest proof,
coming below, significantly different.
Now, restore previously replaced 1s, shown Figure 13. e n + 1 1s
replaced restored adjacent 1s matrix.14 such, counts two
1-runs, one horizontal one vertical. sums total 2(e n + 1) 1-runs corresponding
1s replaced restored. addition, row column one 1-run. follows
matrix 3e n + 2 1-runs.
Conversely, consider row column ordering creates 3e n + 2 RLE 1-runs total.
show matrix least e + 1 vertical 1-runs, regardless row ordering. Consider
rows, order, starting top. first row introduces exactly 2 vertical 1-runs, one
column contains value 1. subsequent row introduces least one vertical
1-run. Otherwise, new row would identical previous one, contradicts fact
graph duplicate edges.
13. runs used proof sequential.
14. adjacent 1 column, would imply two identical rows, would mean
G duplicate edges. adjacent 1 row, would mean edge hand belongs
Hamiltonian path, contradicts fact 1s replaced restored complementary set edges.

623

fiS TRASSER , B OTEA , & H ARABOR

least e + 1 vertical 1-runs, number horizontal 1-runs
(3e n + 2) (e + 1) = 2e n + 1. show column ordering Hamiltonian path.
Assuming contrary, p < n 1 edges nodes adjacent
ordering. follows number horizontal 1-runs p + 2(e p) = 2e p > 2e n + 1.
Contradiction.

Appendix B. Proofs Lemma 2 Lemma 3
start pointing two simple important properties stemming notion articulation point:
Remark 1. Given graph G, let x articulation point, let G1 . . . Gn corresponding
connected components obtained removing x.
1. Given source node Gi , first optimal move towards anywhere outside Gi
same.15
2. Given two distinct components Gi Gj , first optimal move x towards anywhere
Gi different first optimal move x towards anywhere Gj .
Remark 1 follows easily obvious observation way going one
subgraph Gi another subgraph Gj passing x. See Figure 7 illustration.
Lemma 2. Let x articulation point graph G. Every node order rearranged
x-block ordering o0 without increasing number runs row.
Proof. construct desired ordering o0 applying following steps:
1. Rotate x comes first.
2. every {1 . . . n} project resulting order onto Gi , obtaining suborder o0i .
3. Define o0 as: o0 = x, o01 , . . . , o0n .
clear construction nodes every subgraph Gi consecutive o0 . remains
show number runs per row grow.
Denote source node. distinguish two cases:
Case Gi i. rotation,
step 1 impact number

cyclic runs. Steps 2 3 take nodes k6=i Gk put one two blocks
cyclic
adjacent x. know Remark 1, point 1 m[s, x] = m[s, n]
nodes n k6=i Gk . Thus, re-arrangement brings next x nodes n
first-move symbol x. Clearly, increase number runs.
Case = x. previous case, rotation performed step 1 increase
number cyclic runs. step 1, cyclic runs sequential runs equivalent, since
first position contains distinct symbol, namely x-singleton. Steps 2 3 separate
15. Assuming split ties among optimal paths consistent manner, easy ensure.

624

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

Gi contiguous block. increase number sequential runs since,
according Remark 1, point 2, every two blocks corresponding Gi Gj , 6= j,
common symbol. follows number cyclic runs increase either.

Lemma 3. Given x-block ordering o, that:
1. N (o, G, Gi ) = N (o|i , , Gi );
P
2. N (o, G, {x}) = 1 n + N (o|i , , {x});
P
3. N (o, G, G) = 1 n + N (o|i , , ).
Proof. prove point follows.
1. x-block ordering, nodes come order x, G1 , . . . Gi , . . . Gn . Consider
node Gi corresponding row first-move matrix. pointed Remark 1,
every path node outside Gi pass x, therefore first move
anywhere outside Gi same. follows nodes sequence x, G1 , . . . Gi1 ,
together nodes sequence Gi+1S
, . . . Gn , form one cyclic run. effect, removing
consideration nodes contained k6=i Gk leaves number runs unchanged,
completes proof case.
2. case focused x start node. According Remark 1, Gi 6= Gj ,
first move x towards anywhere Gi different first move x towards
anywhere Gj . follows two runs two adjacent subsets Gi Gi+1 never merge
one run. Thus,
X
N (o, G, {x}) = 1 +
(N (o|i , , {x}) 1)


= 1n+

X


N (o|i , , {x}).

3. case follows previous two, standard arithmetic manipulation.
X
N (o, G, G) = N (o, G, {x}) +
N (o, G, Gi )


= 1n+

X

= 1n+

X
(N (o|i , , {x}) + N (o|i , , Gi ))



N (o|i , , {x}) +

X



X
= 1n+
(N (o|i , , {x} Gi )


= 1n+

X

N (o|i , , ).



625

N (o|i , , Gi )



fiS TRASSER , B OTEA , & H ARABOR

References
Abraham, I., Delling, D., Fiat, A., Goldberg, A. V., & Werneck, R. F. (2012). HLDB: Locationbased services databases. Proceedings 20th ACM SIGSPATIAL International
Symposium Advances Geographic Information Systems (GIS12), pp. 339348. ACM
Press. Best Paper Award.
Abraham, I., Delling, D., Goldberg, A. V., & Werneck, R. F. (2011). hub-based labeling algorithm
shortest paths road networks. Proceedings 10th International Symposium
Experimental Algorithms (SEA11), Vol. 6630 Lecture Notes Computer Science, pp.
230241. Springer.
Abraham, I., Delling, D., Goldberg, A. V., & Werneck, R. F. (2012). Hierarchical hub labelings
shortest paths. Proceedings 20th Annual European Symposium Algorithms
(ESA12), Vol. 7501 Lecture Notes Computer Science, pp. 2435. Springer.
Akiba, T., Iwata, Y., & Yoshida, Y. (2013). Fast exact shortest-path distance queries large networks pruned landmark labeling.. Proceedings 2013 ACM SIGMOD International
Conference Management Data (SIGMOD13), pp. 349360. ACM Press.
Antsfeld, L., Harabor, D., Kilby, P., & Walsh, T. (2012). Transit routing video game maps..
AIIDE.
Arz, J., Luxen, D., & Sanders, P. (2013). Transit node routing reconsidered. Proceedings
12th International Symposium Experimental Algorithms (SEA13), Vol. 7933 Lecture
Notes Computer Science, pp. 5566. Springer.
Babenko, M., Goldberg, A. V., Kaplan, H., Savchenko, R., & Weller, M. (2015). complexity hub labeling. Proceedings 40th International Symposium Mathematical
Foundations Computer Science (MFCS15), Lecture Notes Computer Science. Springer.
Baier, J., Botea, A., Harabor, D., & Hernandez, C. (2014). fast algorithm catching prey
quickly known partially known game maps. Computational Intelligence AI
Games, IEEE Transactions on, PP(99).
Bast, H., Delling, D., Goldberg, A. V., MullerHannemann, M., Pajor, T., Sanders, P., Wagner, D., &
Werneck, R. F. (2015). Route planning transportation networks. Tech. rep. abs/1504.05140,
ArXiv e-prints.
Bast, H., Funke, S., & Matijevic, D. (2009). Ultrafast shortest-path queries via transit nodes.
Shortest Path Problem: Ninth DIMACS Implementation Challenge, Vol. 74 DIMACS
Book, pp. 175192. American Mathematical Society.
Bast, H., Funke, S., Matijevic, D., Sanders, P., & Schultes, D. (2007). transit constant shortestpath queries road networks. Proceedings 9th Workshop Algorithm Engineering
Experiments (ALENEX07), pp. 4659. SIAM.
Bauer, R., Columbus, T., Katz, B., Krug, M., & Wagner, D. (2010). Preprocessing speed-up
techniques hard. Proceedings 7th Conference Algorithms Complexity
(CIAC10), Vol. 6078 Lecture Notes Computer Science, pp. 359370. Springer.
Bauer, R., Columbus, T., Rutter, I., & Wagner, D. (2013). Search-space size contraction hierarchies. Proceedings 40th International Colloquium Automata, Languages,
626

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

Programming (ICALP13), Vol. 7965 Lecture Notes Computer Science, pp. 93104.
Springer.
Bellman, R. (1958). routing problem. Quarterly Applied Mathematics, 16, 8790.
Botea, A. (2011). Ultra-fast optimal pathfinding without runtime search. Proceedings Seventh AAAI Conference Artificial Intelligence Interactive Digital Entertainment (AIIDE11), pp. 122127. AAAI Press.
Botea, A. (2012). Fast, optimal pathfinding compressed path databases. Proceedings
Symposium Combinatorial Search (SoCS12).
Botea, A., Baier, J. A., Harabor, D., & Hernandez, C. (2013). Moving target search compressed
path databases. Proceedings International Conference Automated Planning
Scheduling ICAPS.
Botea, A., & Harabor, D. (2013a). Path planning compressed all-pairs shortest paths data.
Proceedings 23rd International Conference Automated Planning Scheduling.
AAAI Press.
Botea, A., & Harabor, D. (2013b). Path planning compressed all-pairs shortest paths data.
Proceedings International Conference Automated Planning Scheduling ICAPS.
Botea, A., Strasser, B., & Harabor, D. (2015). Complexity Results Compressing Optimal Paths.
Proceedings National Conference AI (AAAI15).
Bulitko, V., Bjornsson, Y., & Lawrence, R. (2010). Case-based subgoaling real-time heuristic
search video game pathfinding. J. Artif. Intell. Res. (JAIR), 39, 269300.
Bulitko, V., Rayner, D. C., & Lawrence, R. (2012). case base formation real-time heuristic
search. Proceedings Eighth AAAI Conference Artificial Intelligence Interactive Digital Entertainment, AIIDE-12, Stanford, California, October 8-12, 2012.
Cohen, E., Halperin, E., Kaplan, H., & Zwick, U. (2002). Reachability distance queries via
2-hop labels. Proceedings Thirteenth Annual ACM-SIAM Symposium Discrete
Algorithms, SODA 02, pp. 937946, Philadelphia, PA, USA. Society Industrial Applied Mathematics.
Culberson, J. C., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence, 14(3),
318334.
Delling, D., Goldberg, A. V., Nowatzyk, A., & Werneck, R. F. (2013). PHAST: Hardwareaccelerated shortest path trees. Journal Parallel Distributed Computing, 73(7), 940
952.
Delling, D., Goldberg, A. V., Pajor, T., & Werneck, R. F. (2014). Robust distance queries massive
networks. Proceedings 22nd Annual European Symposium Algorithms (ESA14),
Vol. 8737 Lecture Notes Computer Science, pp. 321333. Springer.
Delling, D., Goldberg, A. V., & Werneck, R. F. (2013). Hub label compression. Proceedings
12th International Symposium Experimental Algorithms (SEA13), Vol. 7933
Lecture Notes Computer Science, pp. 1829. Springer.
Demetrescu, C., Goldberg, A. V., & Johnson, D. S. (Eds.). (2009). Shortest Path Problem: Ninth
DIMACS Implementation Challenge, Vol. 74 DIMACS Book. American Mathematical
Society.
627

fiS TRASSER , B OTEA , & H ARABOR

Dibbelt, J., Strasser, B., & Wagner, D. (2014). Customizable contraction hierarchies. Proceedings
13th International Symposium Experimental Algorithms (SEA14), Vol. 8504
Lecture Notes Computer Science, pp. 271282. Springer.
Dijkstra, E. W. (1959). note two problems connexion graphs. Numerische Mathematik,
1, 269271.
Felner, A., Korf, R. E., Meshulam, R., & Holte, R. C. (2007). Compressed pattern databases.. J.
Artif. Intell. Res. (JAIR), 30, 213247.
Ford, Jr., L. R. (1956). Network flow theory. Tech. rep. P-923, Rand Corporation, Santa Monica,
California.
Geisberger, R., Sanders, P., Schultes, D., & Delling, D. (2008). Contraction hierarchies: Faster
simpler hierarchical routing road networks. Proceedings 7th International
Conference Experimental Algorithms (WEA08), pp. 319333.
Harabor, D. D., & Grastien, A. (2011). Online graph pruning pathfinding grid maps. Burgard, W., & Roth, D. (Eds.), Proceedings Twenty-Fifth AAAI Conference Artificial
Intelligence, AAAI 2011, San Francisco, California, USA, August 7-11, 2011. AAAI Press.
Harabor, D. D., & Grastien, A. (2014). Improving jump point search. Chien, S., Do, M. B.,
Fern, A., & Ruml, W. (Eds.), Proceedings Twenty-Fourth International Conference
Automated Planning Scheduling, ICAPS 2014, Portsmouth, New Hampshire, USA, June
21-26, 2014. AAAI.
Hart, P. E., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. IEEE Transactions Systems Science Cybernetics, 4, 100107.
Hernandez, C., & Baier, J. A. (2011). Fast subgoaling pathfinding via real-time search..
Proceedings International Conference Automated Planning Scheduling ICAPS11.
Karypis, G., & Kumar, V. (1998). Metis, software package partitioning unstructured graphs,
partitioning meshes, computing fill-reducing orderings sparse matrices, version 4.0..
Kou, L. T. (1977). Polynomial complete consecutive information retrieval problems. SIAM Journal
Computing, 6(1), 6775.
Lawrence, R., & Bulitko, V. (2013). Database-driven real-time heuristic search video-game
pathfinding. Computational Intelligence AI Games, IEEE Transactions on, 5(3), 227
241.
Mohapatra, A. (2009). Optimal Sort Ordering Column Stores NP-Complete. Tech. rep., Stanford University.
Oswald, M., & Reinelt, G. (2009). simultaneous consecutive ones problem. Theoretical Computer Science, 410(21-23), 19861992.
Samadi, M., Siabani, M., Felner, A., & Holte, R. (2008). Compressing pattern databases
learning. Proceedings 2008 Conference ECAI 2008: 18th European Conference
Artificial Intelligence, pp. 495499, Amsterdam, Netherlands, Netherlands. IOS
Press.
628

fiC OMPRESSING PTIMAL PATHS RUN L ENGTH E NCODING

Sankaranarayanan, J., Alborzi, H., & Samet, H. (2005). Efficient query processing spatial networks. Proceedings 13th Annual ACM International Workshop Geographic Information Systems (GIS05), pp. 200209.
Strasser, B., Harabor, D., & Botea, A. (2014). Fast First-Move Queries Run Length Encoding. Proceedings Symposium Combinatorial Search (SoCS14).
Sturtevant, N. (2012a). 2012 Grid-Based Path Planning Competition. https://code.google.
com/p/gppc-2012/.
Sturtevant, N. (2012b). Website Grid-Based Path Planning Competition 2012. http:
//movingai.com/GPPC/.
Sturtevant, N. (2014). Website Grid-Based Path Planning Competition 2014. http:
//movingai.com/GPPC/.
Sturtevant, N., Traish, J., Tulip, J., Uras, T., Koenig, S., Strasser, B., Botea, A., Harabor, D., &
Rabin, S. (2015). grid-based path planning competition: 2014 entries results.
Proceedings 6th International Symposium Combinatorial Search (SoCS15). AAAI
Press.
Uras, T., & Koenig, S. (2014). Identifying hierarchies fast optimal search. Brodley, C. E., &
Stone, P. (Eds.), Proceedings Twenty-Eighth AAAI Conference Artificial Intelligence,
July 27 -31, 2014, Quebec City, Quebec, Canada., pp. 878884. AAAI Press.
Uras, T., Koenig, S., & Hernandez, C. (2013). Subgoal graphs optimal pathfinding eightneighbor grids.. Proceedings International Conference Automated Planning
Scheduling ICAPS-13.
van Schaik, S. J., & de Moor, O. (2011). memory efficient reachability data structure bit
vector compression. Proceedings 2011 ACM SIGMOD International Conference
Management Data, SIGMOD 11, pp. 913924, New York, NY, USA. ACM.
Wang, K.-H. C., & Botea, A. (2011). MAPP: Scalable Multi-Agent Path Planning Algorithm
Tractability Completeness Guarantees. Journal Artificial Intelligence Research (JAIR),
42, 5590.

629


