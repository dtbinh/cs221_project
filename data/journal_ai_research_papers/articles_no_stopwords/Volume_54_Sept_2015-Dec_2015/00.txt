Journal Artificial Intelligence Research 54 (2015) 1-57

Submitted 09/14; published 09/15

Knowledge-Based Textual Inference via
Parse-Tree Transformations
Roy Bar-Haim

barhair@gmail.com

Ido Dagan

dagan@cs.biu.ac.il

Computer Science Department, Bar-Ilan University
Ramat-Gan 52900, Israel

Jonathan Berant

yonatan@cs.stanford.edu

Computer Science Department, Stanford University

Abstract
Textual inference important component many applications understanding
natural language. Classical approaches textual inference rely logical representations
meaning, may regarded external natural language itself. However,
practical applications usually adopt shallower lexical lexical-syntactic representations,
correspond closely language structure. many cases, approaches lack principled meaning representation inference framework. describe inference formalism
operates directly language-based structures, particularly syntactic parse trees. New
trees generated applying inference rules, provide unified representation
varying types inferences. use manual automatic methods generate rules,
cover generic linguistic structures well specific lexical-based inferences.
present novel packed data-structure corresponding inference algorithm allows
efficient implementation formalism. proved correctness new algorithm
established efficiency analytically empirically. utility approach
illustrated two tasks: unsupervised relation extraction large corpus,
Recognizing Textual Entailment (RTE) benchmarks.

1. Introduction
Textual inference Natural Language Processing (NLP) concerned deriving target
meanings texts. textual entailment framework (Dagan, Roth, Sammons, &
Zanzotto, 2013), reduced inferring textual statement (the hypothesis h)
source text (t). Traditional approaches formal semantics perform inferences
logical forms derived text. contrast, practical NLP applications avoid
complexities logical interpretation. Instead, operate shallower representations
parse trees, possibly supplemented limited semantic information named
entities, semantic roles, forth. clearly demonstrated recent PASCAL
Recognizing Textual Entailment (RTE) Challenges (Dagan, Glickman, & Magnini, 2006b;
Bar-Haim, Dagan, Dolan, Ferro, Giampiccolo, Magnini, & Szpektor, 2006; Giampiccolo,
Magnini, Dagan, & Dolan, 2007; Giampiccolo, Trang Dang, Magnini, Dagan, & Dolan,
2008; Bentivogli, Dagan, Dang, Giampiccolo, & Magnini, 2009; Bentivogli, Clark, Dagan,
c
2015
AI Access Foundation. rights reserved.

fiBar-Haim, Dagan & Berant

Dang, & Giampiccolo, 2010), popular framework evaluating application-independent
semantic inference.1
Inference representations commonly made applying transformations
substitutions tree graph representing text. transformations based
available knowledge paraphrases, lexical relations synonyms hyponyms,
syntactic variations, (de Salvo Braz, Girju, Punyakanok, Roth, & Sammons,
2005; Haghighi, Ng, & Manning, 2005; Kouylekov & Magnini, 2005; Harmeling, 2009).
transformations may generally viewed inference rules. available semantic knowledge bases composed manually, either experts, example WordNet
(Fellbaum, 1998), large community contributors, Wikipedia-based
DBPedia resource (Lehmann et al., 2009). knowledge bases learned automatically distributional pattern-based methods, using aligned monolingual
bilingual parallel texts (Lin & Pantel, 2001; Shinyama, Sekine, Sudo, & Grishman,
2002; Szpektor, Tanev, Dagan, & Coppola, 2004; Chklovski & Pantel, 2004; Bhagat &
Ravichandran, 2008; Ganitkevitch, Van Durme, & Callison-Burch, 2013). Overall, applied
knowledge-based inference prominent line research gained much interest. Recent examples include series workshops Knowledge Reasoning Answering
Questions (Saint-Dizier & Mehta-Melkar, 2011) evaluation knowledge resources
recent Recognizing Textual Entailment challenges (Bentivogli et al., 2010).
many applied systems use semantic knowledge inference rules,
use typically limited, application-specific, somewhat heuristic. Formalizing
practices important textual inference research, analogous role well-formalized
models parsing machine translation. take step direction introducing
generic inference formalism parse trees. formalism uses inference rules capture
wide variety inference knowledge simple uniform manner, specifies small
set operations suffice broadly utilize knowledge.
formalism, applying inference rule clear, intuitive interpretation generating new sentence parse (a consequent), semantically entailed source sentence.
inferred consequent may subject rule applications, on. Rule applications may independent other, modifying disjoint parts source tree,
may specify mutually-exclusive alternatives (e.g., different synonyms source
word). Deriving hypothesis text analogous proof search logic,
propositions parse trees deduction steps correspond rule applications.
nave implementation formalism would generate consequent explicitly
separate tree. However, discuss Section 5, implementation raises
severe efficiency issues, since number consequents may grow exponentially
number possible rule applications. Previous work proposed partial solutions
problem (cf. Section 8). work present novel data-structure, termed compact
forest, packed representation entailed consequents, corresponding inference
algorithm. prove new algorithm valid implementation formalism,
establish efficiency analytically, showing typical exponential-to-linear reduction,
empirically, showing improvement orders magnitude. Together, formalism
1. See, instance, listing techniques per submission provided organizers first
three challenges (Dagan et al., 2006b; Bar-Haim et al., 2006; Giampiccolo et al., 2007).

2

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

novel efficient inference algorithm open way large-scale rule application within
well-formalized framework.
Based formalism inference algorithm, built inference engine
incorporates variety semantic syntactic knowledge bases (cf. Section 6).
evaluated inference engine following tasks:
1. Unsupervised relation extraction large corpus. setting allows evaluation
knowledge-based inferences real-world distribution texts.
2. Recognizing textual entailment (RTE). cope complex RTE examples, complemented knowledge-based inference engine machine-learningbased entailment classifier, provides necessary approximate matching capabilities.
inference engine shown substantial contribution tasks, illustrating
utility approach.
Bar-Haim, Dagan, Greental, Shnarch (2007) Bar-Haim, Berant, Dagan
(2009) described earlier versions inference framework algorithm efficient implementation, respectively. current article includes major enhancements
contributions. formalism presented detail, including
examples pseudo-code algorithms. present several extensions formalism, including treatment co-reference, traces long-range dependencies, enhanced
modeling polarity. efficient inference algorithm presented detail,
including pseudo-code. addition, provide complete proofs theorems,
establish correctness algorithm. Finally, article contains extended analysis
inference component RTE system, terms applicability, coverage,
correctness rule applications.

2. Background
section, provide background textual entailment. survey various
approaches applied task Recognizing Textual Entailment (RTE). particular,
focus use semantic knowledge within current RTE systems.
2.1 Textual Entailment
Many semantic applications need identify meaning expressed by,
inferred from, various language expressions. example, Question-Answering systems
need verify retrieved passage text entails selected answer. Given question
John Lennons widow?, text Yoko Ono unveiled bronze statue late
husband, John Lennon, complete official renaming Englands Liverpool Airport
Liverpool John Lennon Airport. entails expected answer Yoko Ono John Lennons
widow 2 . Similarly, Information Extraction systems need validate given text
indeed entails semantic relation expected hold extracted slot fillers
(e.g., X works ). Information Retrieval queries Alzheimers drug treatment3
2. example taken RTE-2 dataset (Bar-Haim et al., 2006).
3. one topics TREC-6 IR benchmark (Voorhees & Harman, 1997).

3

fiBar-Haim, Dagan & Berant

rephrased propositions (e.g., Alzheimers disease treated using drugs),
expected entailed relevant documents. selecting sentences
included summary, multi-document summarization systems verify
meaning candidate sentence entailed sentences already summary,
avoid redundancy.
observation led Dagan Glickman propose unifying framework modeling
language variability, termed Textual Entailment (TE) (Dagan & Glickman, 2004). Dagan
et al. (2006b) define TE follows:
say entails h if, typically, human reading would infer h
likely true. somewhat informal definition based (and assumes) common human understanding language well common background knowledge.
Dagan et al. (2013) discuss TE definition relation classical semantic
entailment linguistics literature. Recognizing Textual Entailment Challenges (RTE),
held annually since 2004 (Dagan et al., 2006b; Bar-Haim et al., 2006;
Giampiccolo et al., 2007, 2008; Bentivogli et al., 2009, 2010), formed growing research
community around task.
holy grail TE research development entailment engines, used
generic modules within different semantic applications, similar current use
syntactic parsers morphological analyzers. Since textual entailment defined
relation surface texts, bound particular semantic representation.
allows black-box view entailment engine, input/output interface
independent internal implementation, may employ different types
semantic representations inference methods.
2.2 Determining Entailment
Consider following (t,h) pair4 :

h

oddest thing UAE 500,000 2 million
people living country UAE citizens.
population United Arab Emirates 2 million.

Understanding h involves several inference steps. First, infer
reduced relative clause 2 million people living country proposition:
(1) 2 million people live country.
Next, observe country refers UAE, rewrite (1)
(2) 2 million people live UAE.
Knowing UAE acronym United Arab Emirates, obtain:
(3) 2 million people live United Arab Emirates.
4. Taken RTE1 test set (Dagan et al., 2006b).

4

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

finally paraphrase obtain h:
(4) population United Arab Emirates 2 million.
general, textual inference involves diverse linguistic world knowledge, including
knowledge relevant syntactic phenomena (e.g., relative clauses), paraphrasing (X people
live population X ), lexical knowledge (UAE United Arab Emirates),
on. may require co-reference resolution, example, substituting country UAE. may think types knowledge representing inference
rules define derivation new entailed propositions consequents. work
introduce formal inference framework based inference rule application. current
discussion, however, informal notion inference rules would suffice.
example illustrates derivation h sequence inference
rule applications, procedure generally known forward chaining. Finding sequence
rule applications would get us h (or close possible) thus search
problem, defined space possible rule application chains.
Ideally, would base entailment engine solely trusted knowledge-based
inferences. practice, however, available knowledge incomplete, full derivation h
often feasible. Therefore, requiring strict knowledge-based proofs likely
yield limited recall. Alternatively, may back heuristic approximate
entailment classification.
next two sections survey two complementary inference types: knowledgebased inference, focus research, approximate entailment matching
classification.
2.3 Knowledge-Based Inference
section, describe common resources inference rules (2.3.1),
use textual entailment systems (2.3.2).
2.3.1 Semantic Knowledge Resources
Lexical Knowledge Lexical-semantic relations words phrases play important role textual inference. prominent lexical resource WordNet (Fellbaum,
1998), manually composed wide-coverage lexical-semantic database. following WordNet relations typically used inference: synonyms (buy purchase), antonyms (win
lose), hypernyms/hyponyms (is-a relations, violin musical instrument), meronyms
(part-of relations, Provence France) derivations meeting meet.
Many researchers aimed deriving lexical relations automatically, using diverse methods sources. Much automatically-extracted knowledge complementary
WordNet, however, typically less accurate. Snow, Jurafsky, Ng (2006a) presented
method automatically expanding WordNet new synsets, achieving high precision.
Lins thesaurus (Lin, 1998) based distributional similarity. Recently, several works
aimed extract lexical-semantic knowledge Wikipedia, using metadata, well
textual definitions (Kazama & Torisawa, 2007; Ponzetto & Strube, 2007; Shnarch, Barak,
& Dagan, 2009; Lehmann et al., 2009, others). recent empirical study
5

fiBar-Haim, Dagan & Berant

inferential utility common lexical resources, see work Mirkin, Dagan, Shnarch
(2009).
Paraphrases Lexical-Syntactic Inference Rules rules typically represent
entailment equivalence predicates, including correct mapping
arguments (e.g., acquisition X X purchase ). Much work dedicated
unsupervised learning relations comparable corpora (Barzilay & McKeown, 2001; Barzilay & Lee, 2003; Pang, Knight, & Marcu, 2003), querying Web
(Ravichandran & Hovy, 2002; Szpektor et al., 2004), local corpus (Lin & Pantel,
2001; Glickman & Dagan, 2003; Bhagat & Ravichandran, 2008; Szpektor & Dagan, 2008;
Yates & Etzioni, 2009). particular, textual entailment systems widely used
DIRT resource Lin Pantel. common idea underlying algorithms,
predicates sharing argument instantiations likely semantically related.
NomLex-Plus (Meyers, Reeves, Macleod, Szekeley, Zielinska, & Young, 2004) lexicon containing mostly nominalizations verbs, allowed argument structures (e.g.,
Xs acquisition Y/Ys acquisition X etc.). Argument-mapped WordNet (AmWN)
(Szpektor & Dagan, 2009) resource inference rules verbal nominal predicates, including argument mapping. based WordNet NomLex-Plus,
verified statistically intersection unary-DIRT algorithm (Szpektor &
Dagan, 2008).
Syntactic Transformations Textual entailment often involves inference generic
syntactic phenomena passive/active transformations, appositions, conjunctions, etc.,
illustrated following examples:
John smiled laughed John laughed (conjunction)
neighbor, John, came John neighbor (apposition)
paper Im reading interesting Im reading paper (relative clause).
Syntactic transformations addressed extent de Salvo Braz et al.
(2005) Romano, Kouylekov, Szpektor, Dagan, Lavelli (2006). describe novel
syntactic rule base entailment, based survey relevant linguistic literature, well
extensive data analysis (Sections 6.16.2).
2.3.2 Use Semantic Knowledge Textual Entailment Systems
Following description common knowledge sources textual inference, discuss
use knowledge textual entailment systems.
Textual entailment systems usually represent h trees graphs, based
syntactic parse, predicate-argument structure, various semantic relations. Entailment
determined measuring well h matched (or embedded ) t, estimating
distance h, commonly defined cost transforming h.
next section, briefly cover various methods proposed approximate
matching heuristic transformations graphs trees. role semantic knowledge
general scheme bridge gaps h stem language
variability. example, applying lexical-semantic rule purchase buy allows
matching word buy appearing h word purchase appearing t.
6

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

RTE systems restrict type allowed inference rules search space.
Systems based lexical (word-based phrase-based) matching h (Haghighi et al.,
2005; MacCartney, Galley, & Manning, 2008) heuristic transformation h
(Kouylekov & Magnini, 2005; Harmeling, 2009) typically apply lexical rules (without
variables), sides rule matched directly h.
Hickl (2008) derived given (t, h) pair small set consequents terms
discourse commitments. commitments generated several different tools
techniques, based syntax (conjunctions, appositions, relative clauses, etc.), co-reference,
predicate-argument structure, extraction certain relations, paraphrase acquisition
Web. Pairs commitments derived h fed next stages
RTE system lexical alignment entailment classification. Prior commitment
generation, several linguistic preprocessing modules applied text, including
syntactic dependency parsing, semantic dependency parsing, named entity recognition,
co-reference resolution. Hickl employed probabilistic finite-state transducer (FST)-based
extraction framework commitment generation, extraction rules modeled
series weighted regular expressions. commitments textual form fed
back system, additional commitments generated.
De Salvo Braz et al. (2005) first incorporate syntactic semantic inference
rules comprehensive entailment system. system, inference rules applied
hybrid syntactic-semantic structures called concept graphs. left hand side (LHS)
rule matched concept graph, graph augmented instantiation
right hand side (RHS) rule. several iterations rule application,
system attempts embed hypothesis augmented graph. types semantic
knowledge, verb normalization lexical substitutions, applied either
rule application (at preprocessing time) rule application, part hypothesis
subsumption (embedding).
Several entailment systems based logical inference. Bos Markert (2005, 2006)
represented h DRS structures used Discourse Representation Theory (Kamp &
Reyle, 1993), translated first-order logic. Background knowledge
(BK) encoded axioms, comprised lexical relations WordNet, geographical
knowledge, small set manually composed axioms encoding generic knowledge.
Bos Markert used logic theorem prover find proof entails h (alone
together background knowledge BK), h inconsistent
(implying non-entailment) background knowledge. logic prover
complemented model builder aimed find counter-examples (e.g., model
h holds). logical inference system suffered low coverage, due limited
background knowledge available, able find proofs small fraction
RTE2 dataset. Therefore, RTE system Bos Markert combined logical inference
shallow approximate matching method, based mainly word overlap.
LCCs logic-based entailment system (Tatu & Moldovan, 2006) one top performers RTE2 RTE3 (Tatu, Iles, Slavick, Novischi, & Moldovan, 2006; Tatu &
Moldovan, 2007). based proprietary tools deriving rich semantic representations, extensive knowledge engineering. syntactic parses h
transformed logic forms (Moldovan & Rus, 2001), representation enriched
variety relations extracted semantic parser, well named entities
7

fiBar-Haim, Dagan & Berant

temporal relations. Inference knowledge included on-demand axioms based extended
WordNet lexical chains, WordNet glosses, NLP rewrite rules. Additional knowledge
types included several hundreds world knowledge axioms, temporal axioms, semantic composition axioms (e.g., encoding transitivity kinship relation). Based
rich semantic representation extensive set axioms, theorem prover aimed
prove refutation entails h. proof failed, h repeatedly simplified
proof found, reducing proof score simplification.
2.4 Approximate Entailment Classification
Semantic knowledge always incomplete. Therefore, cases, knowledge-based inference must complemented approximate, heuristic methods determining entailment. RTE systems employ limited amount semantic knowledge,
focus methods approximate entailment classification. common architecture
RTE systems (Hickl, Bensley, Williams, Roberts, Rink, & Shi, 2006; Snow, Vanderwende,
& Menezes, 2006b; MacCartney, Grenager, de Marneffe, Cer, & Manning, 2006) comprises
following stages:
1. Linguistic processing: Includes syntactic (and possibly semantic) parsing, namedentity recognition, co-reference resolution, etc. Often, h represented trees
graphs, nodes correspond words edges represent relations
words.
2. Alignment: Find best mapping h nodes nodes, taking account
node edge matching.
3. Entailment classification: Based alignment found, set features extracted
passed classifier determining entailment. features measure
alignment quality, try detect cues false entailment. example,
node h negated aligned node negated, may indicate false
entailment.
alternative approach aims transform text hypothesis, rather
aligning them. Kouylekov Magnini (2005) applied tree edit distance algorithm
textual entailment. edit operation (node insertion/deletion/substitution) assigned
cost. algorithm aims find minimum-cost sequence operations transform
h. Mehdad Magnini (2009b) proposed method estimating cost
edit operation based Particle Swarm Optimization. Wang Manning (2010)
presented probabilistic tree-edit approach models edit operations using structured
latent variables. Tree edits represented state transitions Finite-State Machine
(FSM), model parameterized Conditional Random Field (CRF). Harmeling
(2009) developed probabilistic transformation-based approach. defined fixed set
operations, including syntactic transformations, WordNet-based substitutions,
heuristic transformations adding/removing verb noun. probability
transformation estimated development set. Similarly, Heilman Smith
(2010) classify entailment based sequence edits transforming h. employ
generic edit operations greedy search heuristic, guided cost function
measures remaining distance h using tree kernel.
8

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

Zanzotto, Pennacchiotti, Moschitti (2009) aimed classify given (t, h) pair
analogy similar pairs training set. method based finding intra-pair
alignment (i.e., h) capturing transformation h, interpair alignment, capturing analogy new pair (t, h) previously seen
pair (t0 , h0 ). cross-pair similarity kernel computed, based tree kernel similarity
applied aligned texts aligned hypotheses. Another cross-pair similarity kernel
proposed Wang Neumann (2007). extracted tree skeletons h,
consisting left right spines, defined unlexicalized paths starting root.
found sections h spines differ compared sections across pairs
using subsequence kernel.

3. Research Goal
goal textual entailment research develop entailment engines used
generic inference components within various text-understanding applications. Logic-based
entailment systems provide formalized expressive framework textual inference.
However, deriving logic representations text complex task, available tools
match accuracy robustness current syntactic parsers (which often basis
semantic parsing). Furthermore, interpretation logic forms often unnecessary,
many common inferences modeled shallower representations.
follows textual entailment systems (and text-understanding applications
general) operate lexical-syntactic representations, possibly supplemented
partial semantic annotation. However, unlike logic-based approaches, systems
lack clear, unified formalism knowledge representation inference; instead
employ multiple representations inference mechanisms. notable exception
natural logic framework MacCartney Manning (2009), rather different
focus current work. discuss Section 8.
work, develop well-formalized entailment approach lexical-syntactic
level. formalism models wide variety inference rules composition, based
unified representation small set inference operations. Moreover, present
efficient implementation formalism using novel data structure algorithm
allow compact representation proof search space.
see contribution work practical theoretical. practical
(or engineering) perspective, formalism may simplify development entailment
systems, number representations inference mechanisms need dealt
minimal. Furthermore, efficient implementation may allow entailment engines
explore much larger search spaces. theoretical perspective, concise, formal modeling
leads better insight phenomenon investigation. particular,
formal model entailment engine makes possible apply formal methods investigating properties. enabled us prove correctness efficient implementation
formalism (cf. Appendix A). next present inference formalism.
9

fiBar-Haim, Dagan & Berant

Rule
Type
Syntactic

Sources

Examples

Manually-composed

Lexical

Learned unsupervised algorithms (DIRT, TEASE),
derived automatically integrating information WordNet
Nomlex, verified using corpus
statistics (AmWN)
WordNet, Wikipedia

Passive/active, apposition, relative
clause, conjunctions
Xs wife, X married

Syntactic

Lexical

X bought sold X

X maker X produces
steal take, AlbanianAlbania
Janis Joplinsinger
AmazonSouth America

Table 1: Representing diverse knowledge types inference rules

4. Inference Formalism Parse Trees
previous sections highlighted need principled, well-formalized approach
textual inference lexical-syntactic level. section, propose step towards
filling gap, defining formalism textual inference parse-based representations. semantic knowledge required inference represented inference rules,
encode parse tree transformations. rule application generates new consequent sentence (represented parse tree) source tree. Figure 1b shows sample inference
rule, representing passive-to-active transformation.
knowledge representation usage perspective, inference rules provide simple
unifying formalism representing applying broad range inference knowledge.
examples breadth illustrated Table 1. knowledge acquisition
perspective, representing inference rules lexical-syntactic level allows easy incorporation rules learned unsupervised methods, important scaling inference
systems. Interpretation stipulated semantic representations, often difficult
inherently supervised semantic task learning, circumvented altogether.
historical machine translation perspective, approach similar transfer-based translation, contrasted semantic interpretation Interlingua. overall research goal
explore reach inference approach, identify scope
semantic interpretation may needed.
Given syntactically parsed source text set inference rules, formalism
defines set consequents derivable text using rules. consequent
obtained sequence rule applications, generating intermediate parse
tree, similar proof process logic. addition, new consequents may inferred based
co-reference relations identified traces. formalism includes annotation rules
add features existing trees. According formalism, text entails hypothesis
h h consequent t.
rest section, define illustrate formalism components:
sentence representation (Section 4.1), inference rules application (Sections 4.2
4.3), inference based co-reference relations traces (Section 4.4), annotation
10

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

Input: source tree ; rule E : L R
Output: set derived trees
set matches L

f
l subtree matched L according match f
// R instantiation
r copy R
variable v r
Instantiate v f (v)
aligned pair nodes uL l uR r
daughter uL
/ l
Copy subtree rooted uR r, dependency relation
// Derived tree generation
substitution rule
copy l (and descendants nodes) replaced r
else // introduction rule
dr
add

Algorithm 1: Applying rule tree
rules (Section 4.5). components form inference process specifies set
inferable consequents given text set rules (Section 4.6). Section 4.7 extends
hypothesis definition, allowing h template rather proposition. Finally,
Section 4.8 discusses limitations possible extensions formalism.
4.1 Sentence Representation
assume sentences represented form parse trees. work, focus
dependency tree representation, often preferred directly capture predicateargument relations. Two dependency trees shown Figure 1a. Nodes represent words
hold set features values. features include word lemma
part-of-speech, additional features may added inference process.
Edges annotated dependency relations.
4.2 Inference Rules
entailment (or inference) rule L R primarily composed two templates, lefthand-side (LHS) L right-hand-side (RHS) R. Templates dependency subtrees,
may contain POS-tagged variables, matching lemma. Figure 1 shows passiveto-active transformation rule, illustrates application.
rule application procedure given Algorithm 1. Rule application generates set
derived trees (consequents) source tree steps described below.
11

fiBar-Haim, Dagan & Berant

root




rain VERB

expletive

r

wha



,

ADJ


r

Mary NOUN
mod

see VERB

obj

q


mod

bysubj



VERB

PREP

,

yesterday NOUN

pcompn


little ADJ

John NOUN

Source: rained little Mary seen John yesterday.

root




rain VERB

r

expletive

wha



,

ADJ



subj

r

John NOUN

see VERB
obj

mod

,

Mary NOUN yesterday NOUN
mod



little ADJ
Derived: rained John saw little Mary yesterday.

(a) Passive-to-active tree transformation


V VERB
obj

L

u

N1 NOUN

V VERB

bysubj


subj

obj



)

u

)

VERB

PREP

N2 NOUN

N1 NOUN

pcompn

R



N2 NOUN
(b) Passive active substitution rule.
Figure 1: Application inference rule. POS relation labels based Minipar
(Lin, 1998). N 1, N 2 V variables, whose instances L R implicitly aligned.
by-subj dependency relation indicates passive sentence.

12

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

root

root









V1 VERB V2 VERB
L



wha

R

ADJ




V2 VERB
Figure 2: Temporal clausal modifier extraction (introduction rule)

4.2.1 L Matching
First, matches L source tree sought. L matched exists
one-to-one node mapping function f L s, that:
1. node u L, f (u) features feature values u. Variables
match lemma value f (u).
2. edge u v L, edge f (u) f (v) s, dependency
relation.
matching fails, rule applicable s. example, variable V matched
verb see, N 1 matched Mary N 2 matched John. matching succeeds,
following performed match found.
4.2.2 R Instantiation
copy R generated variables instantiated according matching node
L. addition, rule may specify alignments, defined partial function L nodes
R nodes. alignment indicates modifier source node
part rule structure, subtree rooted copied modifier
target node. addition explicitly defining alignments, variable L implicitly
aligned counterpart R. example, alignment V nodes implies
yesterday (modifying see) copied generated sentence, similarly
little (modifying Mary) copied N 1.
4.2.3 Derived Tree Generation
Let r instantiated R, along descendants copied L alignment,
l subtree matched L. formalism two methods generating
derived tree d: substitution introduction, specified rule type. Substitution
rules specify modification subtree s, leaving rest unchanged. Thus,
formed copying replacing l (and descendants ls nodes) r.
case passive rule, well lexical rules buy purchase.
contrast, introduction rules used make inferences subtree s,
parts ignored affect d. typical example inferring proposition
embedded relative clause s. case, derived tree simply taken
13

fiBar-Haim, Dagan & Berant

root


root




buy VERB
subj



purchase VERB

obj

subj

obj

v

(

v

(

John NOUN

books NOUN

John NOUN

books NOUN

John bought books.

L

buy VERB

John purchased books.



purchase VERB

R

Figure 3: Application lexical substitution rule. dotted arc represents explicit
alignment.

r. Figure 2 presents rule, enables deriving propositions embedded
within temporal modifiers. Note derived tree depend main clause.
Applying rule right part Figure 1a yields proposition John saw little
Mary yesterday.
4.3 Examples Rule Application
section illustrate rule representation application additional
examples.
4.3.1 Lexical Substitution Rule Explicit Alignment
Figure 3 shows derivation consequent John purchased books sentence
John bought books using lexical substitution rule buy purchase. example
illustrates role explicit alignment: since buy purchase variables,
implicitly aligned. However, need aligned explicitly, otherwise daughters
buy would copied purchase.
4.3.2 Lexical-Syntactic Introduction Rule
Figure 4 illustrates application lexical-syntactic rule, derives sentence
husband died knew late husband. defined introduction rule, since
resulting tree derived based solely phrase late husband, ignoring
rest source tree. example illustrates leaf variable L (variable
leaf node) may become non-leaf R vice versa. alignment
instances variable N (matched husband ) allows copying modifier, (recall
alignments defined implicitly formalism). note correctness
rule application may depend context applied. instance,
rule example correct late meaning longer alive given
context. discuss context-sensitivity rule application Section 4.8.
14

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

root

root







know VERB
subj

die VERB

obj

subj

v

(

NOUN

husband NOUN
gen




husband NOUN

mod

v

(

NOUN

late ADJ

gen



NOUN

knew late husband.

husband died.

root


L



N NOUN

die VERB



subj

mod

late ADJ



R

N NOUN

Figure 4: Application lexical-syntactic introduction rule

4.4 Co-Reference Trace-Based Inference
Aside primary inference mechanism rule application, formalism allows
inference based co-reference relations long-distance dependencies. view coreference equivalence relation complete subtrees, either within tree
different trees, linked co-reference chain. practice, relations
obtained external co-reference resolution tool, part text pre-processing.
co-reference substitution operation similar application substitution rule.
Given pair co-referring subtrees, t1 t2 , derived tree generated copying
tree containing t1 , replacing t1 t2 ; operation symmetrically
applicable t2 .5 example, given sentences [My brother] musician. [He] plays
drums, infer brother plays drums.
Long-distance dependencies another type useful relation inference, illustrated following examples:
(1) Relative clause: boyi [I saw ti ] went home.
( saw boy.)
(2) Control verbs: Johni managed [ti open door].
( John opened door.)
5. view co-referring expressions substitutional found seminal paper van
Deemter Kibble (2000), noun phrases shown non-substitutable evidence
co-referring.

15

fiBar-Haim, Dagan & Berant

(3) Verbal conjunction: [Johni sang] [ti danced].
( John danced.)
parsers including Minipar, use current work, recognize annotate
long distance dependencies. instance, Minipar generates node representing
trace (ti examples), holds pointer antecedent (e.g., Johni (2)).
shown examples, inference sentences may involve resolving long- distance
dependencies, traces substituted antecedent. Thus, generalize
co-reference substitution operate trace-antecedent pairs, well. mechanism
works together inference rule application. instance, substituting trace
antecedent (2) obtain John managed [John opened door].
apply introduction rule N managed extract embedded clause John
opened door.
4.5 Polarity Annotation Rules
addition inference rules, formalism implementation includes mechanism
adding semantic features parse tree nodes. However, many cases natural
way define semantic features classes. Hence, often difficult agree right
set semantic annotations (a common example definition word senses).
approach, aim keep semantic annotation minimum, sticking lexicalsyntactic representation, widely-agreed schemes exist.
Consequently, semantic annotation employ predicate polarity. feature
marks truth predicate, may take one following values: positive(+),
negative(-) unknown(?). examples polarity annotation shown below:
(4) John called[+] Mary.
(5) John hasnt called[] Mary yet.
(6) John forgot call[] Mary.
(7) John might called[?] Mary.
(8) John wanted call[?] Mary.
Sentences (5) (6) entail John didnt call Mary, hence negative annotation
call. contrast, truth John called Mary cannot determined (7) (8),
therefore predicate call marked unknown. general, polarity predicates
may affected existence modals, negation, conditionals, certain verbs, etc.
Technically, annotation rules right-hand-side R, rather node L
may contain annotation features. L matched tree, annotations contains
copied matched nodes. Figure 5 shows example annotation rule application.
Predicates assumed positive polarity default. polarity rules used
mark negative unknown polarity. one rule applies predicate
(as sentence John forgot call Mary), may applied order,
following simple calculus employed combine current polarity new polarity:
16

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

root


V[]
L





listen[]
subj

VERB

VERB





v

(

VERB

John NOUN

VERB

neg

neg



ADJ



ADJ
John listening[] .

(a) Annotation rule

(b) Annotated sentence

Figure 5: Application annotation rule (a), marking predicate listen negative
polarity (b)

Current polarity
+

?
+/ /?

New polarity



?

Result

+
?
?

Annotation rules used detecting polarity mismatches text hypothesis. Incompatible polarity would block hypothesis matched text.
case approximate entailment classification, polarity mismatches detected
annotation rules used features classifier, discuss Section 7.3.
addition, existence polarity annotation features may prevent inappropriate inference
rule applications, blocking L matching. discuss Section 6.1.
4.6 Inference Process
Let set dependency trees representing text, along co-reference
trace information. Let h dependency tree representing hypothesis, let R
collection inference rules (including inference polarity rules). Based
previously defined components inference framework, next give procedural
definition set trees inferable using R, denoted I(T, R). inference
process comprises following steps:
1. Initialize I(T, R) .
2. Apply matching polarity rules R trees I(T, R) (cf. Section 4.5).
3. Replace trace nodes copy antecedent subtree (cf. Section 4.4).
4. Add I(T, R) trees derivable co-reference substitution (cf. Section 4.4).
17

fiBar-Haim, Dagan & Berant

5. Apply matching inference rules R trees I(T, R) (cf. Section 4.2),
add derived trees I(T, R). Repeat step iteratively newly added
trees, new trees added.
Steps 2 3 performed h well.6 h inferable using R h I(T, R).
Since I(T, R) may infinite large, practical implementation process must
limit search space, example restricting number iterations applied
rules iteration.
inference rule applied, polarity annotation propagated source
tree derived tree follows. First, nodes copied retain original
polarity. Second, node gets polarity aligned node s.
4.7 Template Hypotheses
many applications useful allow hypothesis h template rather
proposition, is, contain variables. variables case existentially quantified: entails h exists proposition h0 , obtained h variable instantiation,
entails h0 . variable X instantiated (replaced) subtree SX . X
modifiers h (i.e., X leaf), become modifiers SX root. obtained
variable instantiations may stand answers sought questions slots filled relation extraction. example, applying framework question-answering setting,
question killed Kennedy? may transformed hypothesis X killed Kennedy.
successful proof h sentence assassination Kennedy Oswald shook
nation would instantiate X Oswald, providing sought answer.
4.8 Limitations Possible Extensions
conclude section discussing limitations presented inference formalism,
well possible extensions address limitations. First, inference rules match
single subtree, therefore less expressive logic axioms used Bos
Markert (2005) Tatu Moldovan (2006), may combine several predicates
originating text representation well background knowledge.
allows logic-based systems make inferences combine multiple pieces information.
instance, text says person X lives city , background knowledge
tells us city country Z, infer X lives country Z, using
rule person(X) location(Y) location(Z) live(X,Y) in(Y,Z) live(X,Z) .
Schoenmackers, Etzioni, Weld, Davis (2010) describe system acquires rules
(first-order horn clauses) Web text. Allowing rules match multiple subtrees
t, well information background knowledge, seems plausible future extension
formalism.
Another limitation formalism lack context disambiguation. Word sense
mismatch potential cause incorrect rule applications. example, rule hit
score applied correctly (9) (10):
6. Step 4 applied h since hypothesis typically short, simple sentence usually
include co-referring NPs. Moreover, presented formalism h single tree. Applying co-referencebased inference would resulted additional trees inferred h, thus would required
extending formalism accordingly.

18

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

(9) team hit home run. team scored home run.
(10) car hit tree. ; car scored tree.
Several works past years addressed problem context-dependent rule application (Dagan, Glickman, Gliozzo, Marmorshtein, & Strapparava, 2006a; Pantel, Bhagat,
Coppola, Chklovski, & Hovy, 2007; Connor & Roth, 2007; Szpektor, Dagan, Bar-Haim, &
Goldberger, 2008; Dinu & Lapata, 2010; Ritter, Mausam, & Etzioni, 2010; Berant, Dagan,
& Goldberger, 2011; Melamud, Berant, Dagan, Goldberger, & Szpektor, 2013). Szpektor
et al. (2008) proposed comprehensive framework modeling context matching, termed
Contextual Preferences (CP). Given text t, hypothesis h (possibly template hypothesis) inference rule r bridging h, objects annotated
two context components: (a) global (topical) context, (b) preferences constraints instantiation objects variables (for r template h). CP requires
h r matched t, h matched r7 , context component
matched counterpart. Szpektor et al. proposed concrete implementations
components. example, could model global context
r sets content words, compute semantic relatedness
two sets, using methods Latent Semantic Analysis (LSA) (Deerwester, Dumais,
Furnas, Landauer, & Harshman, 1990), Explicit Semantic Analysis (ESA) (Gabrilovich
& Markovitch, 2007). would expect semantic relatedness {score}
{team, home run} much higher {score} {car, tree}, would
permit inference (9) (10).
RTE systems (including system RTE experiments, described
Section 7.3) lexicalized rules bridge h directly, rules LHS
RHS matched h, respectively. Since RTE benchmarks h tend
semantic context, setting alleviates context matching problems
extent. However, analysis, presented later work (Subsection 7.5.2), shows
context matching remains issue even setting, expected become even
important chaining lexicalized rules attempted. Adding contextual preferences
formalism important direction future work.
validity rule application depends monotonicity properties application site. instance, hypernym rule poodle dog applicable upward
monotone contexts. Monotonicity may affected presence quantifiers, negation, certain verbs implicatives counterfactives (Nairn, Condoravdi, &
Karttunen, 2006). common textual entailment systems, assume upward monotonicity anywhere. assumption usually holds true, cases may lead
incorrect inferences. following examples show correct applications rule
upward monotone contexts ((11),(14)), incorrect applications downward monotone
contexts ((12),(13),(15)):
(11) bought poodle. bought dog.
(12) didnt buy poodle ; didnt buy dog
(13) Poodles smart. ; Dogs smart.
7. Context matching, textual entailment, directional relation.

19

fiBar-Haim, Dagan & Berant

(14) failed avoid buying poodle failed avoid buying dog.
(15) fail avoid buying poodle ; fail avoid buying dog.
MacCartney Manning (2009) address monotonicity well semantic relations
exclusion, Natural Logic framework based syntactic representation.
discuss work detail Section 8.
Finally, since polarity annotation rules applied locally, may fail complex
cases, computing polarity buying sentences (14) (15), polarity
information need propagated along syntactic structure sentence.
TruthTeller system (Lotan, Stern, & Dagan, 2013), computes predicate polarity (truth
value) combination annotation rules global polarity propagation algorithm,
extending previous work Nairn et al. (2006) MacCartney Manning (2009).
4.9 Summary
section, presented well-formalized approach textual inference parsebased representations, core paper. framework, semantic knowledge
represented uniformly inference rules specifying tree transformations. provided
detailed definitions representation rules well inference mechanisms
apply them. formalism models inferences based co-reference relations
traces. addition, includes annotation rules used detect contexts affecting
polarity predicates. next section present efficient implementation
formalism.

5. Compact Forest Scalable Inference
According formalism, rule application generates new sentence parse (a consequent), semantically entailed source sentence. inferred consequent may
subject rule applications, on. straightforward implementation
formalism would generate consequent separate tree. Unfortunately, nave
approach raises severe efficiency issues, since number consequents may grow exponentially number rule applications. Consider, example, sentence Children
fond candies, following rules: childrenkids, candiessweets, X
fond YX likes Y. number derivable sentences, including source sentence,
would 23 (the power set size), rule either applied not, independently.
found exponential explosion leads poor scalability nave implementation
approach practice.
Intuitively, would rule application add entailed part rule
(e.g., kids) packed sentence representation. Yet, still want resulting structure
represent set entailed sentences, rather mixture sentence fragments
unclear semantics. discussed Section 8, previous work proposed partial solutions
problem.
section, introduce novel data structure, termed compact forest, corresponding inference algorithm, efficiently generate represent consequents
preserving identity individual one. data structure allows compact representation large set inferred trees. rule application generates explicitly
20

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

nodes rules right-hand-side. rest consequent tree shared source
sentence, reduces number redundant rule applications, explained later
section. show representation based primarily disjunction edges,
extension dependency edges specify set alternative edges multiple trees.
Since follow well-defined inference formalism, able prove inference
operations formalism equivalently applied compact forest. compare
inference cost compact forests explicit consequent generation theoretically,
illustrating exponential-to-linear complexity ratio, empirically, showing improvement
orders magnitude (empirical results reported Section 7.2).
5.1 Compact Forest Data Structure
compact forest F represents set dependency trees. Figure 6d shows example
compact forest containing trees sentences Little Mary seen John yesterday
John saw little Mary yesterday. first define general data structure
directed graphs, narrow definition case trees.
Compact Directed Graph (cDG) pair G = (V, E) V set nodes E
set disjunction edges (d-edges). Let set dependency relations. d-edge
triple (Sd , reld , Td ), Sd Td disjoint sets source nodes target
nodes; reld : Sd function specifying dependency relation corresponds
source node. Graphically, d-edges shown point nodes, incoming edges
source nodes outgoing edges target nodes. instance, let bottommost
d-edge Figure 7. Sd = {of, like}, Td = {candy, sweet}, rel(of ) = pcomp-n,
rel(like) = obj .
d-edge represents, si Sd , set alternative directed edges {(si , tj ) : tj
Td }, labeled relation given reld (si ). edges,
termed embedded edge (e-edge), would correspond different graph represented G.
obj

obj

pcompn

previous example, e-edges likecandy, likesweet, ofcandy
pcompn
ofsweet (the definition implies source nodes Sd set
alternative target nodes Td ). d-edge called outgoing d-edge node v v Sd
incoming d-edge v v Td . Compact Directed Acyclic Graph (cDAG)
cDG contains cycles e-edges.
DAG G rooted node v V cDAG G embedded G derived
follows: initialize G v alone; then, expand v choosing exactly one target
node Td outgoing d-edge v, adding corresponding e-edge
(v, t) G. expansion process repeated recursively new node added G.
set choices results different DAG v root. Figure 6d,
may choose connect root either left see, resulting source passive
sentence, right see, resulting derived active sentence.
Compact Forest F cDAG single root r (i.e., r incoming d-edges)
embedded DAGs rooted r trees. set trees, termed embedded
trees, denoted (F) comprise set trees represented F.
Figure 7 shows another example compact forest efficiently representing 23 sentences resulting three independently applied rules presented beginning
section.
21

fiBar-Haim, Dagan & Berant

ROOT

ROOT





see

V

by-subj obj





Mary

pcomp-n

John

see

mod



by-subj obj

yesterday



mod

pcomp-n

little

mod



yesterday

little

(b) Variable instantiation

ROOT

ROOT





see
obj



mod

John

(a) Right-hand-side generation

by-subj

Mary

see

see

see



by-subj

mod mod

see
mod

mod

obj

obj

subj


pcomp-n

John

Mary



yesterday



mod



yesterday
pcomp-n

little

John

(c) Alignment sharing

Mary
mod

little

(d) Dual-leaf variable sharing

Figure 6: Step-by-step construction compact forest containing source sentence Little Mary seen John yesterday sentence John saw little Mary
yesterday derived via application passive rule Figure 1b. Parts
speech omitted.

5.2 Inference Process
next describe algorithm implementing inference process described Section 4.6
compact forest (henceforth, compact inference), illustrated Figures 1b (the
passive-to-active rule) 6.
22

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

ROOT



pred

fond



mod subj

subj
obj



child

kid
pcomp-n

candy

sweet

Figure 7: compact forest representing 23 sentences derivable sentence Children fond candies using following three rules: childrenkids, candiessweets,
X fond YX likes Y.

5.2.1 Forest Initialization
F initialized set dependency trees representing text sentences,
roots connected forest root target nodes single d-edge. Dependency
edges transformed trivially d-edges single source target. Annotation
rules applied stage initial F. Figure 6a, without node labeled V
incoming edge, corresponds initial forest (containing single sentence
example).
5.2.2 Inference Rule Application
Inference rule application comprises steps described below, summarized
Algorithm 2.
L Matching first find matches rules LHS L forest F (line 1).
sake brevity, omitted technical details L matching implementation
pseudocode Algorithm 2. following high-level description matching
procedure, focusing key algorithmic points.
L matched F exists embedded tree F L matched
t, Section 4.2. denote l subtree L matched (line 3).
23

fiBar-Haim, Dagan & Berant

Input: compact forest F ; inference rule E : L R
Output: modified F, denoted F 0 , (F 0 ) = (F) D, set trees derived
applying E subset Ls matches trees (F)
1: set matches L F
2: match f
3:
l subtree F L matched according f
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:

// Right-hand-side generation
SR copy R excluding dual leaf variable nodes
Add SR F
SL l excluding dual leaf variable nodes
rR root(SR )
rL root(l)
E substitution rule
incoming d-edge rL // set SR alternative SL
else // introduction rule
outgoing d-edge root(F) // set SR alternative trees (F)
Add rR Td

15:
16:
17:
18:
19:

// Variable instantiation
variable X held node xR SR // Rs variables excluding dual leaves
X leaf L
xL f (X) // node SL matched X
(xR .lemma, xR .polarity) (xL .lemma, xL .polarity)

20:
21:
22:
23:
24:
25:
26:

else // X leaf L matched whole target node set
(xR .lemma, xR .polarity) (n.lemma, n.polarity) node n f (X)
n0 f (X); n0 6= n
generate substitution rule n n0 n n0 aligned, apply xR
x0R instantiation n0
u SL u aligned xR
add alignment u x0R

27:
28:
29:
30:
31:
32:

// Alignment sharing
aligned pair nodes nL SL nR SR
nR .polarity nL .polarity
outgoing d-edge nL whose e-edges part SL
Add nR Sd
reld (nR ) reld (nL )

33:
34:
35:
36:

// Dual leaf variable sharing
dual-leaf variable X matched node v l
incoming d-edge v
p parent node X SR

37:
38:
39:
40:
41:

// go p alternatives p generated variable instantiation
P set target nodes ps incoming d-edge
p0 P
Add p0 Sd
reld (p0 ) relation X p

Algorithm 2: Applying inference rule compact forest

24

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

subtree may shared multiple trees represented F, case rule
applied simultaneously trees. Section 4.2, match example
(V, N 1, N 2)=(see, Mary, John). definition allow l scattered
multiple embedded trees. Matches constructed incrementally, aiming add Ls nodes
one one partial matches constructed far, verifying candidate node
F node content corresponding edge labels match. verified
match contain one e-edge d-edge. nodes F
indexed using hash table enable fast lookup.
target nodes d-edge specify alternatives position tree,
parts-of-speech expected substitutable. assume target nodes
d-edge part-of-speech8 polarity. Consequently, variables
leaves L may match certain target node d-edge mapped whole
set target nodes Td rather single node. yields compact representation
multiple matches, prevents redundant rule applications. instance, given compact
representation {Children/kids} fond {candies/sweets} (cf. Figure 7), rule X
fond YX likes matched applied once, rather four times (for
combination matching X ).
Right-Hand-Side Generation Given inference rule L R, define dual-leaf
variable variable leaf L R. example, N 1 N 2
dual-leaf variables passive-to-active rule Figure 1b. Variables
node R (and hence root leaf), variables additional
alignments (other implicit alignment occurrences L R)
considered dual-leaves. explained below, instantiations dual leaf variables
shared source target trees.
right-hand-side generation step, template SR (line 5), consisting R
excluding dual-leaf variables, generated inserted F (line 6). example,
SR includes node V passive rules RHS. Similarly, define SL l
excluding dual-leaf variables (line 7).
case substitution rule (as example), SR set alternative SL
adding SR root Td , incoming d-edge SL root (line 11). case
introduction rule, set alternative trees forest adding
SR root target node set forest roots outgoing d-edge (line 13). Figure 6a
illustrates results step example. SR gray node labeled
variable V , becomes additional target node d-edge entering original
(left) see.
Variable Instantiation variable SR (i.e., non dual-leaf) instantiated (lines
16-26) according match L (as Section 4.2). example, V instantiated
see (Figure 6b, lines 17-19). specified above, variable SR leaf L (which
case example) matched set nodes,
instantiated SR (lines 20-26). decomposed sequence simpler
operations: first, SR instantiated representative set (line 21).
apply ad-hoc lexical substitution rules creating new node additional node
8. case current implementation, based coarse tag-set Minipar.

25

fiBar-Haim, Dagan & Berant

set (line 22-26). nodes, addition usual alignment source nodes
SL (lines 25-26), share daughters SR (due alignment n
n0 , defined line 23).
Alignment Sharing Modifiers aligned nodes shared (rather copied) follows.
Given node nL SL aligned node nR SR , outgoing d-edge nL
part l, share nL nR adding nR Sd setting
reld (nR ) = reld (nL ) (lines 28-32). example (Figure 6c), aligned nodes nL
nR left right see nodes, respectively, shared modifier yesterday.
dependency relation mod copied right see node. copy polarity annotation
nL nR (line 29).
note point instantiation variables dual leaves cannot
shared typically different modifiers two sides rule. Yet,
modifiers, part rule, shared alignment operation
(recall common variables always considered aligned). Dual leaf variables,
hand, might shared, described next, since rule doesnt specify modifiers
them.
Dual Leaf Variable Sharing final step (lines 34-41) performed similarly
alignment sharing. Suppose dual leaf variable X matched node v l whose
incoming d-edge d. simply add parent p X SR Sd set reld (p)
relation p X (in R). Since v shared, modifiers become shared
well, implicitly implementing alignment operation. subtrees little Mary John
shared way variables N 1 N 2 (Figure 6d). ad-hoc substitution rules
applied p variable instantiation phase, generated nodes serve alternative
parents X, thus sharing procedure applied p repeated them.
Applying rule example added single node linked four d-edges,
compared duplicating whole tree explicit inference.
5.2.3 Co-reference Substitution
Section 4.4 defined co-reference substitution, inference operation allows replacing subtree t1 co-referring subtree t2 . operation implemented generating
on-the-fly substitution rule t1 t2 applying t1 . implementation,
initial compact forest annotated co-reference relations obtained external
co-reference resolution tool, substitutions performed prior rule applications.
Substitutions t2 pronoun ignored, usually useful.
5.3 Correctness
section, present two theorems proving inference process presented
valid implementation inference formalism. provide full proofs Appendix A.
Theorem 1, argue applying rule compact forest results compact
forest. Since begin valid compact forest created initialization step, follows
induction sequence rule applications result inference process
compact forest. fact embedded DAGs generated inference
process indeed trees trivial, since nodes generally many incoming e-edges
26

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

many nodes. However, show pair parent nodes cannot part
embedded DAG. example, Figure 7, node candy incoming
e-edge node node . However, nodes
part embedded DAG. d-edge emanating root
forces us choose node node be. Thus, see reason
correctness local: two incoming e-edges leaf node candies cannot
embedded DAG rule applied root tree. turn
theorem proof scheme:
Theorem 1 Applying rule compact forest results compact forest.
Proof scheme prove applying rule compact forest creates cycle
embedded DAG tree, cycle non-tree DAG already existed
prior rule application. contradicts assumption original structure
compact forest. crucial observation proof directed path
node u node v passes SR , u v outside SR ,
analogous path u v passes SL instead.
next theorem main result. argue inference process compact
forest complete sound, is, generates exactly set consequents derivable
text according inference formalism.
Theorem 2 Given rule base R set initial trees , tree represented
compact forest derivable inference process consequent according
inference formalism.
Proof scheme first show completeness induction number explicit rule
applications. Let tn+1 tree derived tree tn using rule rn according
inference formalism. inductive assumption determines tn embedded
derivable compact forest F. easy verify applying rn F yield compact
forest F 0 tn+1 embedded.
Next, show soundness induction number rule applications
compact forest. Let tn+1 tree represented derived compact forest Fn+1 (tn+1
(F n+1 )). Fn+1 derived compact forest Fn , using rule rn . inductive
assertion states trees (F n ) consequents according formalism.
Hence, tn+1 already (F n ) consequent . Otherwise, shown
exists tree tn (F n ) applying rn tn yield tn+1 according
formalism. tn consequent according inductive assertion therefore
tn+1 consequent well.
two theorems guarantee compact inference process valid, is,
yields compact forest represents exactly set consequents derivable given
text given rule set.
27

fiBar-Haim, Dagan & Berant

5.4 Complexity
section, explain compact inference exponentially reduces time space
complexity typical scenarios.
consider set rule matches tree independent matched left-handsides (excluding dual-leaf variables) overlap , application
chained order. example, three rule matches presented Figure 7
independent.
Let us consider explicit inference first. Assume start single tree k
independent rules matched. Applying k rules yield 2k trees, since subset
rules might applied . Therefore, time space complexity applying k
independent rule matches (2k ). Applying rules newly derived consequents
behaves similar manner.
Next, examine compact inference. Applying rule using compact inference adds
right-hand-side rule shares existing d-edges. Since size
right-hand-side number outgoing d-edges per node practically bounded
low constants, applying k rules tree yields linear increase size forest.
Thus, resulting size O(|T | + k), see Figure 7.
time complexity rule application composed matching rule forest
applying matched rule. Applying matched rule linear size. Matching
rule size r forest F takes O(|F|r ) time even performing exhaustive
search matches forest. Since r tends quite small bounded
low constant9 , already gives polynomial time complexity. Furthermore, matches
constructed incrementally, step aim extend partial matches found.
Due typical low connectivity forest, well various constraints imposed
rule (lemma, POS, dependency relation), number candidates extending
matches step << |F|, candidates retrieved efficiently using
proper indexing. Thus, matching procedure fast practice, illustrated
empirical evaluation described Section 7.2.
5.5 Related Work Packed Representations
Packed representations various NLP tasks share common principles, underlie
compact forest: factoring common substructures representing choice local
disjunctions. Applying general scheme individual problems typically requires specific representations algorithms, depending type alternatives
represented specified operations creating them. create alternatives rule
application, newly derived subtree set alternative existing subtrees.
Alternatives specified locally using d-edges.
Packed chart representations parse forests introduced classical parsing algorithms CYK Earley (Jurafsky & Martin, 2008), extended later
work various purposes (Maxwell III & Kaplan, 1991; Kay, 1996). Alternatives
parse chart stem syntactic ambiguities, specified locally possible decompositions phrase sub-phrases.
9. RTE system, average rule LHS size found 2 nodes, maximal size 7
nodes, experimental setting described Section 7.2.2, applied RTE3 test set.

28

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

Packed representations utilized transfer-based machine translation.
Emele Dorna (1998) translated packed source language representation packed target
language representation avoiding unnecessary unpacking transfer. Unlike
rule application, work transfer rules preserve ambiguity stemming source
language, rather generating new alternatives. Mi et al. (2008) applied statistical
machine translation source language parse forest, rather 1-best parse.
transfer rules tree-to-string, contrary tree-to-tree rules, chaining
attempted (rules applied single top-down pass source forest). Thus,
representation algorithms quite different ours.

6. Incorporated Knowledge Bases
section, describe various knowledge bases used inference engine.
first describe novel rule base addressing generic linguistic structures. rule base
composed manually, based formalism, includes inference rules (Section 6.1)
polarity annotation rules (Section 6.2). addition, derived inference rules
several large scale semantic resources (Section 6.3). Overall, variety illustrates
suitability formalism representing diverse types inference knowledge.
6.1 Inference Rules Generic Linguistic Phenomena
rules capture inferences associated common syntactic structures,
summarized Table 2. rules three major functions:
1. Simplification canonization source tree (categories 6 7 Table 2).
2. Extracting embedded propositions (categories 1, 2, 3).
3. Inferring propositions non-propositional subtrees source tree (category 4).
Inference rules merely extract subtree source tree without changing
structure (such relative clause rule) useful exact inference aims generate
hypothesis, used evaluation inferences (cf. Section 7.1). However, currently implemented approximate classification features focused matching
substructures hypothesis forest (as described Section 7.3), hence
take advantage extractions. Therefore, rules excluded rest
experiments, reported Sections 7.27.3.
rules categories 1-7 depend solely syntactic structure closed-class words,
referred generic rules. contrast, verb complement extraction rules (category
8) considered lexicalized rules, since specific certain verbs: replace forced
advised example, entailment would hold. extracted PARC
polarity lexicon (Nairn et al., 2006) list verbs allow inference appearing
positive polarity contexts, generated inference rules verbs. list
complemented reporting verbs, say announce, since information
news domain, rules applied experiments (cf. Section 7.1)
often given reported speech, speaker usually considered reliable.
sidestep issue polarity propagation applying rules main
clause, implemented including tree root node rule LHS.
29

fiBar-Haim, Dagan & Berant

#
1

Category
Conjunctions

2

Clausal extraction
connectives
Relative
clauses

3

4

Appositives

5

Determiner
Canonization

6

Passive

7

Genitive
modifier

8

Verb complement clause
extraction

Example: source
Helenas experienced
played long time
tour.
celebrations muted
many Iranians observed
Shiite mourning month.
assailants fired six bullets car, carried
Vladimir Skobtsov.
Frank Robinson, onetime manager Indians, distinction
NL.
plaintiffs filed lawsuit last year U.S. District
Court Miami.
approached
investment banker.
Malaysias crude palm oil
output estimated
risen six percent.
Yadav forced resign.

Example: derived
Helena played long
time tour.
Many Iranians observed
Shiite mourning month.
car carried Vladimir
Skobtsov.
Frank Robinson onetime manager Indians.

plaintiffs filed lawsuit last year U.S. District
Court Miami.
investment banker approached us.
crude palm oil output Malaysia estimated
risen six percent.
Yadav resigned.

Table 2: Inference rules generic linguistic structures

embedded clause extracted, becomes main clause derived tree, rules
extract embedded clauses. polarity verb detected applying
annotation rules, described next. verb annotated negative unknown
polarity, matching complement extraction rules fails. example, last sentence
Table 2 Yadav forced resign, forced would annotated negative
polarity, consequently matching corresponding complement extraction rule
would fail, Yadav resigned would entailed. Hence, annotation rules may block
erroneous inference rule applications. polarity important correct application
rules, case rule types, passive-to-active transformation.
therefore checked polarity matching rule application exact inference
experiment (Section 7.1), verb complement extraction rules used. leave
analysis polarity-dependence rules future work.
6.2 Polarity Annotation Rules
use annotation rules mark negative unknown polarity predicates (cf. Section 4.5). Table 3 summarizes polarity-inducing contexts address. inference rules, annotation rules comprise generic rules (categories 1-4) lexicalized
30

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

#
1

Category
Explicit Negation

2
3
4

Implied Negation
Modal Auxiliaries
Overt Conditionals

5
6
7

Verb complements
Adjectives
Adverbs

Example
weve never seen[] actual costs come
down.
one stayed[] last lecture.
could eat[?] whale now!
Venus wins[?] game, meet[?] Sarena
finals.
pretend know[] calculus.
impossible survived[] fall.
probably danced[?] night.

Table 3: Polarity annotation rules

rules (categories 5-7). verb complement embedded clause negative unknown
polarity, extracted, however, polarity annotated (category 5; compare
category 8 Table 2). list verbs imply negative/unknown polarity
clausal complements taken PARC lexicon, well VerbNet (Kipper,
2005).
6.3 Lexical Lexical-Syntactic Rules
addition manually-composed generic rules, system integrates inference knowledge variety large-scale semantic resources, introduced Section 2.3. information derived resources represented uniformly inference rules
formalism. examples rules shown Table 1. following resources
used:
WordNet: extracted WordNet (Fellbaum, 1998) lexical rules based synonym, hyponym (a word entailed hyponym, e.g., dog animal ), instance
hyponym 10 derivation relations.
Wikipedia: used lexical rulebase Shnarch et al. (2009), extracted rules
Janis Joplin singer Wikipedia based metadata (e.g.,
links redirects) text definitions, using patterns X .11
DIRT: DIRT algorithm (Lin & Pantel, 2001) learns corpus inference rules
binary predicates, example, X fond YX likes Y. used
version learns canonical rule forms (Szpektor & Dagan, 2007).
Argument-Mapped WordNet (AmWN): resource inference rules predicates, covering verbal nominal forms (Szpektor & Dagan, 2009), includ10. According WordNet glossary, instance proper noun refers particular, unique
referent (as distinguished nouns refer classes). specific form hyponym.
example, Ganges instance river.
11. addition extraction methods described Shnarch et al. (2009), employed two additional
methods. First, extraction entailments among terms redirected page. Second,
generalization rules RHS common LHS head, different modifiers. instance,
rules Ferrari F430 car Ferrari Ascari car generalized Ferrari car .

31

fiBar-Haim, Dagan & Berant

ing argument mapping. based WordNet NomLex-plus (Meyers
et al., 2004), verified statistically intersection unary-DIRT algorithm (Szpektor & Dagan, 2008). AmWN rules defined unary templates,
example, kill XX die
automatically-extracted inference rules lack two attributes defined formalism: rule type (substitution/introduction) explicit alignments (beyond alignments
Rs variables L counterparts, defined default). attributes added automatically using following heuristics:
1. roots L R part-of-speech, substitution rule
(e.g., X buy sold X ). Otherwise (e.g., Ys acquisition X
sold X ), introduction rule.
2. roots L R assumed aligned.
Note application rules, (e.g., WordNet derivations
rules learned DIRT), result valid parse tree. rules
used aiming exact derivation h t. However, may useful
inference engine used together approximate matching component,
RTE system. approximate matcher (described Section 7.3) employs features
coverage words subtrees h F, therefore benefit
inferences. rules preferably applied last step inference
process, avoid cascading errors.

7. Evaluation
section, present empirical evaluation entailment system whole,
well evaluation individual components. evaluate quality systems
output (in terms accuracy, precision, recall) computational efficiency (in terms
running time space, using various application settings.
first evaluate knowledge-based inference engine. Section 7.1, describe
experiment engine aims prove simple template hypotheses, representing
binary predicates, texts sampled large corpus. Next, Section 7.2 evaluate
efficiency engine implementation using compact forest data structure.
evaluate complete entailment system, including approximate entailment classifier
(Section 7.3). Finally, Sections 7.47.5 provide in-depth analysis performance
inference component RTE data.
7.1 Proof System Evaluation
experiment, evaluate inference engine finding strict proofs. is,
inference process must derive precisely target hypothesis (or instantiation
it, case template hypotheses, contain variables defined Section 4.7).
Thus, evaluate precision text-hypothesis pairs complete proof
chain found, using available rules. note PASCAL RTE datasets
suitable purpose. rather small datasets include many text-hypothesis pairs
32

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

available inference rules would suffice deriving complete proofs. Furthermore,
since focus research applied textual inference, inference engine
evaluated NLP application setting texts represent realistic distribution
linguistic phenomena. Manually-composed benchmarks FraCas test suite
(Cooper et al., 1996), contains synthetic examples specific semantic phenomena,
clearly suitable evaluation.
alternative, chose Relation Extraction (RE) setting, complete
proofs achieved large number corpus sentences. setting, system
needs identify pairs arguments sentences target semantic relation (e.g., X buy
).
7.1.1 System Configuration
experiment, first reported Bar-Haim et al. (2007), used earlier
version engine rule bases. engine experiment make use
compact forest, rather generates consequent explicitly. Polarity annotations
propagated source derived trees. Instead, polarity annotation rules
applied original text t, inferred consequent, prior application
inference rule. following rule bases used experiment:
Generic Linguistic Rules used generic rule base presented Section 6, including inference polarity annotation rules. early version include
lexicalized polarity rules derived VerbNet PARC lexicon (category 5
Table 3).
Lexical-Syntactic Rules Nominalization rules: inference rules Xs acquisition
X acquired capture relations verbs nominalizations.
rules derived automatically (Ron, 2006) Nomlex, hand-coded database
English nominalizations (Macleod, Grishman, Meyers, Barrett, & Reeves, 1998),
WordNet.
Automatically Learned Rules: used DIRT paraphrase collection, well
output TEASE (Szpektor et al., 2004), another unsupervised algorithm learning
lexical-syntactic rules. TEASE acquires entailment relations Web given
input template identifying characteristic variable instantiations shared
templates. algorithms provide ranked list output templates given input
template. learned rules linguistic paraphrases, (e.g., X confirm X
approve ), others capture world knowledge, (e.g., X buy X ).
algorithms learn entailment direction rule, reduces accuracy
applied given direction. system, considered top 15 bi-directional
rules learned template.
Generic Default Rules rules used define default behavior, situations
case-by-case rules available. used one default rule allows removal
modifiers nodes. Ideally, rule would replaced future work
specific rules removing modifiers.
33

fiBar-Haim, Dagan & Berant

7.1.2 Evaluation Process
use sample test template hypotheses correspond typical relations,
X approve Y. identify large test corpus, sentences instantiation
test hypothesis proved. example, sentence budget approved
parliament found prove instantiated hypothesis parliament approve budget
(via passive-to-active inference rule). Finally, sample candidate sentenceshypothesis pairs judged manually true entailment. repeated process compare
different system configurations.
Since publicly available sample output TEASE much smaller
resources12 randomly selected resource 9 transitive verbs may correspond
typical predicates13 . formed test templates adding subject object varisubj

able nodes. example, verb accuse constructed template XNOUN
obj

accuse VERB YNOUN .
test template h identify sentences corpus template
proved system. efficiently find proof chains generate h corpus
sentences combine forward backward (Breadth-First) searches available
rules. First, use backward search lexical-syntactic rules, starting rules
whose right-hand-side identical test template. process backward chaining
DIRT/TEASE nominalization rules generates set templates ti ,
proving (deriving) h. example, hypothesis X approve may generate
template X confirm Y, backward application DIRT/TEASE rule,
generate template confirmation X, nominalization rule.
Since templates ti generated lexical-syntactic rules, modify open-class
lexical items, may considered lexical expansions h.
Next, specific ti generate search engine query composed open-class
words ti . query fetches candidate sentences corpus, ti might
proven using generic linguistic rules (recall rules modify openclass words). end, use forward search applies generic rules, starting
candidate sentence trying derive ti sequence rule applications.
successful, variables ti instantiated (cf. Section 4.7). Consequently, know
variable instantiations, h proven (since derives ti turn
derives h).
performed search sentences prove test template
Reuters RCV1 corpus, CD#2, applying Minipar parsing. random sampling,
obtained 30 sentences prove (according tested system configuration)
9 test templates, yielding total 270 pairs sentence, instantiated hypothesis, four tested configurations, described (1080 pairs overall).
pairs split entailment judgment two human annotators (graduate students
Bar-Ilan NLP group). annotators achieved, sample 100 shared exam12. output TEASE DIRT, well many knowledge resources, available RTE
knowledge resources page:
http://aclweb.org/aclwiki/index.php?title=RTE_Knowledge_Resources
13. verbs approach, approve, consult, lead, observe, play, seek, sign, strike.

34

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

#
1
2
3
4

Configuration
Baseline (embed h anywhere s)
Proof (embed h root s)
Proof + Generic
Proof + Generic + Lexical-Syntactic

Precision
67.0%
78.5%
74.8%
23.6%

Yield
2,414
1,426
2,967
18,809

Table 4: Proof system evaluation

ples, agreement level 87%, Kappa value 0.71 (corresponding substantial
agreement).
7.1.3 Results
tested four configurations proof system:
1. Baseline: baseline configuration follows prominent approach graph-based
entailment systems: system tries embed given hypothesis anywhere
candidate sentence tree s, negative unknown polarity (detected
annotation rules) may block embedding.
2. Proof: configuration h strictly generated candidate sentence s. inference rule available default rule removing modifiers
(polarity annotation rules active Baseline). configuration equivalent
embedding h root h matched root s, since modifiers
part match removed default rule. However,
h embedded elsewhere extracted, opposed Baseline
configuration.
3. Proof + Generic: Proof, plus generic linguistic rules.
4. Proof + Generic + Lexical-Syntactic: previous configuration, plus
lexical-syntactic rules.
system configuration measure precision, percentage examples judged
correct (entailing), average extrapolated yield, expected number
truly entailing sentences corpus would proven system.
extrapolated yield specific template calculated number sample sentences
judged entailing, multiplied sampling proportion. average calculated
test templates. note that, similar IR evaluations, possible compute
true recall setting since total number entailing sentences corpus
known (recall equal yield divided total). However, straightforward
measure relative recall differences among different configurations based yield. Thus,
using two measures estimated large corpus possible conduct robust
comparison different configurations, reliably estimate impact different
rule types. analysis possible RTE datasets, rather small,
hand-picked examples represent actual distribution linguistic phenomena.
35

fiBar-Haim, Dagan & Berant

results reported Table 4. First, comparing results Proof
results Baseline, observe requirement matching h root (i.e.,
main clause s), rather allowing matched anywhere s, improves
precision considerably baseline (by 11.5%), reducing yield nearly 40%.
Proof configuration avoids errors resulting improper extraction embedded
clauses.
Remarkably, using generic inference rules, system able gain back lost
yield Proof surpass yield baseline configuration. addition,
obtain higher precision baseline (a 7.8% difference), statistically
significant p < 0.05 level, using z test proportions. demonstrates
principled proof approach appears superior heuristic baseline embedding
approach, exemplifies contribution generic rule base. Overall, generic rules
used 46% proofs.
Adding lexical-syntactic rules increased yield factor six. shows
importance acquiring lexical-syntactic variability patterns. However, precision
DIRT TEASE currently quite low, causing overall low precision. Manual filtering
rules learned systems currently required obtain reasonable precision.
Error analysis revealed third configuration Proof + Generic rules,
significant 65% errors due parsing errors, notably incorrect dependency
relation assignment, incorrect POS assignment, incorrect argument selection, incorrect analysis complex verbs (e.g., play text vs. play hypothesis) ungrammatical sentence fragments. Another 30% errors represent conditionals, negation,
modality phenomena, could handled additional rules, making use elaborate syntactic information verb tense. remaining,
rather small, 5% errors represent truly ambiguous sentences would require
considerable world knowledge successful analysis.
7.2 Compact Forest Efficiency Evaluation
Next, evaluate efficiency compact inference (cf. Section 5) setting recognizing textual entailment, using RTE-3 RTE-4 datasets (Giampiccolo et al., 2007,
2008). datasets consist (text, hypothesis) pairs, need classified
entailing/non entailing. first experiment, using generic inference rule set, shows
compact inference outperforms explicit inference (efficiency-wise) orders magnitude (Section 7.2.1). second experiment shows compact inference scales well
full-blown RTE setting several large-scale rule bases, hundreds rules
applied per text (Section 7.2.2).
7.2.1 Compact vs. Explicit Inference
compare explicit compact inference randomly sampled 100 pairs RTE-3
development set, parsed text pair using Minipar (Lin, 1998). avoid
memory overflow explicit inference, applied sentences subset
generic inference rules described Section 6.1. fair comparison, aimed make
explicit inference implementation reasonably efficient, example preventing multiple
generations tree different permutations rule applications.
36

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

Time (msec)
Rule applications
Node count
Edge endpoints

Compact
61
12
69
141

Explicit
24,184
123
5,901
11,552

Ratio
396
10
86
82

Table 5: Compact vs. explicit inference, using generic rules. Results averaged per
text-hypothesis pair.

configurations perform rule application iteratively, new matches found.
iteration, first find rule matches apply matching rules. compare run
time, number rule applications, overall generated size nodes edges,
edge size represented sum endpoints (2 regular edge, |Sd | + |Td |
d-edge).
results summarized Table 5. expected, results show compact
inference orders magnitude efficient explicit inference. avoid memory
overflow, inference terminated reaching 100,000 nodes. Three 100 test
texts reached limit explicit inference, maximal node count compact
inference 268. number rule applications reduced due sharing
common subtrees compact forest, single rule application operates
simultaneously large number embedded trees. results suggest scaling
larger rule bases longer inference chains would feasible compact inference,
prohibitive explicit inference.
7.2.2 Application RTE System
goal second experiment test compact inference scales well broad
inference rule bases. experiment used Bar-Ilan RTE system (Bar-Haim et al.,
2008). system operates two primary stages:
Inference: inference rules first applied initial compact forest F, aiming bring
closer hypothesis h. experiment, use knowledge bases
described Section 6. Overall, rule bases contain millions rules.
current system implemented simple search strategy, spirit
(de Salvo Braz et al., 2005): first, applied three exhaustive iterations generic
rules. Since rules low fan-out (few possible right-hand-sides given
left-hand-side), affordable apply chain freely. iteration
first find rule matches, apply matched rules. avoid repeated
identical rule applications, mark newly added nodes iteration,
next iteration consider matches containing new nodes. perform single
iteration lexical lexical-syntactic rules, applying L
part matched F R part matched h. investigation
effective search heuristics representation left future research.
Classification: Following inference, set features extracted resulting F
h fed SVM classifier, determines entailment. describe
37

fiBar-Haim, Dagan & Berant

Rule applications
Node count
Edge endpoints

RTE3-Dev
Avg. Max.
14
275
71
606
155 1,741

RTE4
Avg. Max.
15
110
80
357
173 1,062

Table 6: Application compact inference RTE-3 Dev. RTE-4 datasets, using
rule types

classification stage detail next section, discusses performance
RTE system.
Table 6 provides statistics rule applications using rule bases, RTE-3
development set RTE-4 dataset14 . Overall, primary result compact
forest indeed accommodates well extensive rule applications large-scale rule bases.
resulting forest size kept small, even maximal cases causing memory
overflow explicit inference.
7.3 Complete RTE System Evaluation
previous sections, evaluated knowledge-based inference engine (the proof system) respect quality output (precision, recall) well computational
efficiency (time, space). evaluate complete RTE system, combines
inference engine approximate classification module.
classification setting features quite typical RTE literature. Features broadly categorized two subsets: (a) lexical features solely depend
lexical items F h, (b) lexical-syntactic features take account
syntactic structures dependency relations F h. brief description
features. complete description appears RTE system report (Bar-Haim et al.,
2008).
Lexical features: Coverage features check words h present (covered) F.
assume high degree lexical coverage correlates entailment.
features measure proportion uncovered content words, verbs, nouns, adjectives
adverbs, named entities numbers. Polarity mismatch features detect cases
nouns verbs h matched F incompatible polarity.
features assumed indicate non-entailment.
Edge coverage features: say edge h matched F edge
F matching relation, source node target node. say edge h
loosely-matched path F matching source node matching
target node. Based definitions extract two features: proportion h
edges matched/loosely matched F.15
14. Running time included since dedicated rule fetching, rather slow
available implementation resources. elapsed time seconds per (t, h) pair.
15. look subset edges labeled relevant dependency relations.

38

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

Predicate-argument features: F entails h, predicates h matched
F along arguments. Predicates include verbs (except verb be)
subject complements copular sentences, example, smart Joseph smart.
Arguments daughters predicate node h.16 Four features computed
F, h pair. categorize every predicate h match F one
four possible categories:
1. complete match - matching predicate exists F matching arguments
dependency relations.
2. partial match - matching predicate exists F matching arguments
dependency relations.
3. opposite match - matching predicate exists F matching arguments
incorrect dependency relations.
4. match - matching predicate F matching arguments.
predicate categorized complete match category.
Finally, compute four features F, h pair: proportion predicates
h complete match F, three binary features, checking
predicate h categorized partial match/opposite match/no match. Since
subject object arguments crucial textual entailment, compute four
similar features subset predicates arguments (ignoring
arguments).
global lexical-syntactic feature: feature measures well subtrees h
covered F, weighted according proximity root h. feature
somewhat similar dependency tree kernel Collins Duffy (2001),
measures similarity two dependency trees counting common
subtrees. However, measure several distinct properties makes suitable
needs: (a) directional measure, estimating coverage h F,
vice versa (b) operates compact forest tree, rather pair
trees. (c) takes account distance root h, assuming nodes
closer root important.
system trained RTE-3 development set, tested RTE3
RTE-4 test sets (no development set released RTE-4). Co-reference substitution
disabled due insufficient accuracy co-reference resolution tool used.
first report overall performance, provide analysis inference module,
focus work.
accuracies obtained experiment shown Table 7 (under inference
column). results RTE-3 quite competitive: compared 66.4%, 3 teams
26 participated RTE-3 scored higher 67%, three systems
scored 66% 67%. results RTE4 rank 9-10 26, 6 teams
scoring higher 1%. Overall, results show system well-situated
state art RTE task.
Table 8 provides detailed view systems performance. Precision, recall,
F1 results given entailing non-entailing pairs, well overall accuracy.
16. dependent preposition clause take complement preposition head
clause respectively dependent.

39

fiBar-Haim, Dagan & Berant

table shows results per task (IE, IR, QA SUM). Overall, system tends
predict entailment often non-entailment. recall entailing pairs much
higher recall non-entailing pairs, precision non-entailing pairs
much higher entailing pairs. Performance varies considerably among different tasks.
RTE3 accuracy results QA IR considerably higher average results
achieved RTE3 submissions, reported organizers (Giampiccolo et al., 2007)
(0.71 0.66, respectively), IE SUM, results bit average
(0.52 0.58). RTE4 results better IR SUM, seem easier
tasks RTE4 (Giampiccolo et al., 2008).17
7.4 Usage Contribution Knowledge Bases
evaluate accuracy gain knowledge-based inference, ran system
inference module disabled, entailment classification applied directly initial
parse tree text. results shown inference column Table 7.
Comparing results full system accuracy (inference), see applying
inference module resulted higher accuracy test sets. contribution
prominent RTE-4 dataset. results illustrate typical contribution current
knowledge sources current RTE systems. contribution likely increase
current near future research, topics extending improving knowledge
resources, applying semantically suitable contexts, improved classification
features, broader search strategies.
Tables 9 10 illustrate usage contribution individual rule bases. Table 9
shows distribution rule applications various rule bases. Table 10 presents
ablation study showing marginal accuracy gain rule base. results show
rule bases applicable large portion pairs, contributes
overall accuracy. note results highly dependent search
strategy. instance, chaining lexical rules expected increase number lexical
rule applications, reduce accuracy. provide detailed analysis rule
applications system next section.
7.5 Manual Analysis
conclude evaluation two manual analyses inference component within
RTE system. first analysis (Subsection 7.5.1) assesses applicability inference
framework RTE task well actual coverage current system.
categorizes cases formalism falls short. (Subsection 7.5.2) assess
correctness applied rules, analyze various causes incorrect applications.
analyses done one authors randomly sampled subsets RTE-3
test set.

17. According RTE4 organizers, IE task appeared difficult task, SUM
IR seemed easier tasks. However, report average accuracy per task.

40

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

Test set
RTE3
RTE4

Accuracy
inference Inference
64.6%
66.4%
57.5%
60.6%


1.8 %
*3.1%

Lexical
Overlap
62.4%
56.6%

Best RTE
Result
80.0%
74.6%

Table 7: Inference contribution RTE performance. system trained RTE3 development set. * indicates statistically significant difference (at level p < 0.02, using
McNemars test). best results achieved RTE3 RTE4 challenges (Hickl &
Bensley, 2007; Bensley & Hickl, 2008), well lexical overlap baseline results (Mehdad
& Magnini, 2009a), given reference. Mehdad Magnini tested eight
configurations lexical overlap baselines, chose one performs best average
RTE1-4 test sets.

RTE3

RTE4

Task
IE
IR
QA
SUM

IE
IR
QA
SUM


Non-Entailing Pairs
Precision Recall
F1
0.500
0.095 0.159
0.764
0.743 0.753
0.822
0.787 0.804
0.545
0.341 0.420
0.722
0.505 0.594
0.596
0.187 0.284
0.721
0.587 0.647
0.636
0.210 0.316
0.685
0.630 0.656
0.680
0.400 0.504

Entailing Pairs
Precision Recall
F1
0.527
0.914 0.669
0.678
0.701 0.689
0.818
0.849 0.833
0.600
0.777 0.677
0.634
0.815 0.713
0.518
0.873 0.650
0.652
0.773 0.707
0.527
0.880 0.659
0.657
0.710 0.683
0.575
0.812 0.673

Accuracy
0.525
0.725
0.820
0.585
0.664
0.530
0.680
0.545
0.670
0.606

Table 8: RTE results breakdown task pair type

Rule base
WordNet
AmWN
Wikipedia
DIRT
Generic
Polarity

RTE3-Dev
Rules App
0.6
1.2
0.3
0.4
0.6
1.7
0.5
0.7
4.7 10.4
0.2
0.2

RTE4
Rules App
0.6
1.1
0.3
0.4
0.6
1.3
0.5
1.0
5.4 11.5
0.2
0.2

Table 9: Average number rule applications per (t, h) pair, rule base. App counts
rule application, Rules ignores multiple matches rule
iteration.

7.5.1 Applicability Coverage
analysis assesses ability inference framework derive complete proofs
RTE (t,h) pairs idealized setting perfect knowledge bases co-reference
resolution available. provides upper bound coverage inference
41

fiBar-Haim, Dagan & Berant

Rule base
WordNet
AmWN
Wikipedia
DIRT
Generic
Polarity

Accuracy (RTE4)
0.8%
0.7%
1.0%
0.9%
0.4%
0.9%

Table 10: Contribution various rule bases. Results show accuracy loss RTE-4, obtained
removing rule base (ablation tests).

engine. similar analysis previously done Bar-Haim, Szpektor, Glickman
(2005) subset RTE-1 dataset. However, go (a) assess
actual coverage required inferences implemented RTE system, (b) present
classification uncovered cases different categories.
carried analysis follows: 80 positive (entailing) pairs randomly
sampled RTE-3 test set. pair aimed manually derive proof
comprising inference steps expressible formalism, similar example
Section 2.2. complete proof could derived, pair classified inferable.
Otherwise, classified one following categories:
Discourse references: Complete proof requires incorporating pieces information
discourse, including event co-reference bridging (Mirkin et al., 2010). Nominal co-reference substitution included, covered formalism.
instance, text Titanics sinking hitting iceberg April 14,
1912. . . , year 1912 explicitly specified time Titanics sinking,
relation derived discourse order infer hypothesis
Titanic sank 1912.
Non-decomposable: inference cannot reasonably decomposed sequence
local rewrites. case, example, text black plague lasted
four years killed one-third population Europe, approximately 20
million people hypothesis Black plague swept Europe.
Other: cases fall categories.
distribution categories shown Table 11. found 60%
pairs could proven formalism given appropriate inference rules co-reference
information, demonstrates utility approach. results somewhat
higher 50% reported Bar-Haim et al. (2005), may attributed
fact RTE1 considered difficult dataset, entailment systems consistently
perform better RTE3.
remaining 40% pairs, analysis highlights significance discourse
references, occur 16.3% pairs. previous analysis discourse references
textual entailment applied RTE-5 search task, text sentences
interpreted context full discourse (Mirkin et al., 2010), analysis shows
42

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

Category
Inferable
Non-decomposable
Discourse references


Count
48
14
13
5

%
60.0%
17.5%
16.3%
6.3%

Table 11: Applicability inference framework RTE task. 80 randomly selected
entailing pairs RTE-3 test set analyzed.

significance discourse references even short, self-contained texts, RTE3 composed. Mirkin et al. show framework, similar methods based
tree transformations, extended utilize discourse references. Several works
last years targeted implied predicate-argument relationships, notable
SemEval-2010 Task Linking Events Participants Discourse
(Ruppenhofer, Sporleder, Morante, Baker, & Palmer, 2009). particular, Stern Dagan
(2014) recently showed identifying relations improves performance
RTE system. Finally, entailment 17.5% pairs could established
sequence local rewrites, thus cases likely require deeper methods semantic
analysis inference.
manually-derived proofs 48 inferable pairs included total 79 rule applications, average 1.65 rule applications per pair.18 maximal number rules per
pair 3. 28 rules (35.4%) applied system. 21% proofs
inferable pairs fully derived RTE system. Partial proofs derived
additional 25% pairs. remaining 54% pairs, system apply
rules manual proof. results demonstrate utility inference
mechanisms rule bases system, hand suggest still
much room improvement coverage existing rule bases.
7.5.2 Correctness Applied Rules
next assess correctness rules applied inference engine. focus
four lexical lexical-syntactic rule bases described Section 6.3: WordNet, Wikipedia,
DIRT, Argument-Mapped WordNet (AmWN). Except WordNet, rule bases
generated automatically, therefore accuracy issue accuracy
manually-composed generic inference rules polarity annotation rules. Furthermore, lexicalized rules often context sensitive, additional potential source
incorrect rule applications.
evaluation randomly sampled 75 pairs RTE-3 test set, analyzed
lexical lexical-syntactic rule applications performed system pairs,
total 201 rule applications. define two levels rule application correctness:

18. previously mentioned, RTE system apply rules merely extract subtree
given source tree. Accordingly, rules ignored analysis well.

43

fiBar-Haim, Dagan & Berant

Propositional: derived tree resulting rule application grammatical
entailed source tree. level correctness assumed
formalism.
Referential: case propositional correctness hold, turn weaker criterion Referential Correctness, following notion Lexical Reference (Glickman,
Shnarch, & Dagan, 2006; Shnarch et al., 2009), extend case
template-based rules variables. Let rule E : L R inference rule matched
source tree s. Let l r instantiations L R respectively, according
variable matching L s. say referential correctness holds l generates reference possible meaning r. examples rules found
analyzed sample are: popepapal, TurkishTurkey fishermenfishing.
rule applications result valid entailed tree, still useful
context RTE system applies approximate matching (as previously
discussed end Section 6).
Incorrect rule applications classified one following categories:
1. Bad rule: rule a-priori incorrect (e.g., Walesyear ).
2. Bad context: rule incorrect context source sentence. example,
WordNet rule strikecreate corresponds rare sense strike defined
produce ignition blow (as strike fire flint stone).
3. Bad match: rule applied due incorrect matching left-hand-side,
resulting incorrect parse source tree.
results summarized Table 12. Overall, 52.7% rule applications correct.
Interestingly, referential (29.4%) propositional (23.4%) rule applications. Unsurprisingly, accurate knowledge resource manually composed
WordNet (75.9% correct applications), followed AmWN (57.9%) Wikipedia
(57.4%) rule bases, derived automatically human-generated resources.
least accurate resource DIRT (21.4%), makes use human knowledge engineering, rather learned automatically based corpus statistics. accuracy DIRT
considerably lower accuracy resources, substantially decreasing
overall accuracy well. errors DIRT Wikipedia due bad rules.
overall dominant cause incorrect applications, WordNet
AmWN a-priori rule quality high errors due bad context. Wikipedia rules suffer bad context, explained fact
left-hand-side often unambiguous named entity (Madrid, Antelope Valley
Freeway, Microsoft Office). analysis highlights need improving accuracy
automatically-generated rule bases, whose quality still far human generated resources. analysis shows context-sensitivity lexicalized rules still issue
even rules applied conservatively experiment (no chaining, L
R matched F h). addressed future research.
44

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

% rule applications
Propositional
Referential
Correct
Bad rule
Bad context
Bad matching
Incorrect

DIRT
27.9%
17.9%
3.6%
21.4%
58.9%
7.1%
12.5%
78.6%

AmWN
9.5%
21.1%
36.8%
57.9%
5.3%
31.6%
5.3%
42.1%

Wikipedia
33.8%
19.1%
38.2%
57.4%
42.6%
0.0%
0.0%
42.6%

WordNet
28.9%
34.5%
41.4%
75.9%
0.0%
17.2%
6.9%
24.1%


100.0%
23.4%
29.4%
52.7%
31.3%
10.0%
6.0%
47.3%

Table 12: Analysis lexical lexical-syntactic rule applications

8. Discussion: Comparison Related Approaches
section, compare work several closely-related inference methods,
described Section 2.3.2.
discourse commitments derived Hickl (2008) quite similar kind consequents generate applying syntactic, lexical-syntactic, co-reference substitution rules. However, work differs Hickls several respects. First foremost,
Hickls work fully describe knowledge representation inference framework,
main focus work. Hickl briefly mentions commitments
generated using probabilistic FST-based extraction framework, explanations examples given paper. Second, framework allows unified modeling
variety inference types addressed various tools components Hickls
system (FST, relation extraction, paraphrase acquisition, etc.). addition, system
operates lexical-syntactic representations, rely semantic parsing. Finally, consequents generated formalism packed efficient data structure,
whereas Hickls commitments generated explicitly discuss commitment
generation efficiency. noted, however, explicit generation commitments restricts search space, may simplify approximate matching (e.g., finding
alignment h given consequent vs. aligning h whole compact forest).
De Salvo Braz et al. (2005) presented semantic inference framework augments
text representation right-hand-side applied rule, respect
similar ours. However, work, rule application semantics
resulting augmented structure fully specified. particular, distinction
individual consequents lost augmented graph. contrast, compact
inference fully formalized proved equivalent expressive, well-defined
formalism operating individual trees, inferred consequent recovered
compact forest.
MacCartney Manning (2009) proposed model natural language inference which,
similar framework, operates directly parse-based representations. work extends previous work natural logic (Valencia, 1991), focused semantic containment monotonicity, incorporating semantic exclusion implicativity. model
inference h sequence atomic edits; thought generating
intermediate premise. calculus computes semantic relation source
45

fiBar-Haim, Dagan & Berant

derived premise propagating semantic relation local edit upward
parse tree according properties intermediate nodes. example,
correctly infer first-year students arrived students arrived ,
Every first-year student arrived Every student arrived . composition semantic relations along inference chain yields semantic relation holding
h. contribution complementary ours. approaches, inference
h modeled sequence atomic steps (rule applications edits). focus
framework representation application diverse types transformations
needed textual inference, well efficient representation possible inference chains.
Application inference rule assumed always generate entailed consequent,
polarity rules may used detect situations assumption hold
block rule application. comparison, formalism MacCartney Manning assumes
rather simple edit operations, focused precise predication semantic relation
h given sequence edits transform h. Thus, combining
two complementary approaches natural direction future research.

9. Conclusion
subject work representation use semantic knowledge textual
inference lexical-syntactic level. defined novel inference framework parse
trees, represents diverse semantic knowledge inference rules. proof process
aims transform source text target hypothesis sequence rule
applications, generating intermediate parse tree. complementary contribution
work novel data structure associated rule application algorithm,
proved valid implementation inference formalism. illustrated inference
efficiency analytically empirically.
approach several advantageous properties. First, ability represent
apply wide variety inferences combine rule chaining makes framework expressive previous RTE architectures. Second, expressive
power obtained well-formalized compact framework, based unified knowledge
representation inference mechanisms. Finally, shown RTE experiments,
compact forest data structure allows approach scale well practical settings
involve large rule bases hundreds rule applications per text-hypothesis pair.
demonstrated utility approach two different semantic tasks. Experiments unsupervised relation extraction showed exact proofs outperform
heuristic common practice hypothesis embedding. achieved competitive
results RTE benchmarks, adding simple approximate matching module
inference engine. contribution semantic knowledge illustrated tasks.
Limitations possible extensions formalism discussed Section 4.8.
Manual analysis inference engines performance relation extraction RTE
tasks suggested promising directions future research, discussed Subsections
7.1.3 7.5. Two additional major areas research approximate matching
heuristics proof search strategy. Stern Dagan (2011) Stern, Stern, Dagan,
Felner (2012) extended work address two aspects, respectively.
46

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

Acknowledgments
article based doctoral dissertation first author, completed
guidance second author Bar-Ilan University (Bar-Haim, 2010).
work partially supported Israel Science Foundation grants 1095/05 1112/08,
IST Programme European Community PASCAL Network Excellence IST-2002-506778, PASCAL-2 Network Excellence European Community
FP7-ICT-2007-1-216886, Israel Internet Association (ISOC-IL), grant 9022,
FBK-irst/Bar-Ilan University collaboration. third author grateful Azrieli
Foundation award Azrieli Fellowship. authors wish thank Cleo Condoravdi making polarity lexicon developed PARC available research.
grateful Eyal Shnarch help implementing experimental setup described
Section 7.1. thank Iddo Greental collaboration developing generic rule
base. Finally, would thank Dan Roth, Idan Szpektor, Yonatan Aumann, Marco
Pennacchiotti, Marc Dymetman anonymous reviewers valuable feedback
work.

Appendix A: Compact Forest Complete Proofs
section, provide complete proofs correctness compact inference
algorithm presented Section 5. start definitions.
Definition Let L R rule matched applied compact forest F. Section 5.2, let l subtree represented tree (F), L matched. Recall
SL defined l excluding nodes matched dual-leaf variables, similarly SR
defined copy R without dual-leaf variables generated inserted
F part rule application. roots SL SR denoted rL rR respectively.
say node SR tied node s0 SL , set source node one
outgoing d-edges s0 , due alignment sharing dual leaf variable sharing.
graph operations performed applying rule L R compact forest F
summarized follows:
1. Adding subtree SR F.
2. Setting rR target node d-edge F.
3. Setting nodes SR tied nodes SL source nodes d-edges F,
according rules variable sharing dual leaf variable sharing. Recall
d-edges part SL .
First, show simple property cDGs generated inference process:
Lemma 1 Every node cDG generated inference process one incoming d-edge.
47

fiBar-Haim, Dagan & Berant

Proof construction, initial forest node one incoming d-edge.
rule application adds subtree SR , whose nodes one incoming d-edge.
Last, root rR , initially incoming edges, set target single
d-edge rule application (the incoming d-edge rL ). Therefore, lemma follows
induction number rule applications.
Using following theorem show inference process generates compact
forest:
Theorem 1 Applying rule compact forest results compact forest.
Proof Let F 0 cDG generated applying rule L R compact forest F.
show F 0 compact forest, is, cDAG single root r
embedded DAGs rooted r trees. First, show F 0 cDAG, (i.e.,
contain cycle e-edges).
Assume contradiction F 0 contains simple cycle e-edges C. Applying
rule L R add e-edges nodes F. Therefore, C must pass
rR , root SR contain e-edge (p, rR ). Since SR tree, C must leave SR
e-edge (u, v) (u SR v
/ SR ). cycle written p rR ...
u v ... p. Notice path v p fully contained F since cycle
C simple entering SR possible rR .
L R must substitution rule, otherwise p would root F.
impossible, since root incoming d-edges. Therefore, rR rL
single incoming d-edge, e-edge (p, rL ) exists F. addition, u added
source node d-edge F since tied u0 SL , source node d.
Therefore, path rL ... u0 v exists F. Finally, know path v
p fully contained F, therefore construct cycle p rL ... u0 v ... p
F, contradiction assumption F compact forest.
shown F 0 cDAG. Next, define generalization embedded DAGs,
help us show embedded DAGs F 0 rooted r trees.
Definition embedded partial DAG G = (V, E) cDAG G rooted node v V
similar embedded DAG generated using following process:
1. Initialize G v alone
2. Repeat number iterations:
(a) choose node V
(b) choose outgoing d-edge already chosen previous
iteration. d-edges chosen - halt.
(c) choose target node Td add e-edge (s, t)d G.
show embedded partial DAGs F 0 rooted node trees. Since
embedded DAG embedded partial DAG, proves embedded DAGs
F 0 rooted r trees. Assume contradiction applying L R
48

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

embedded partial DAG 0 rooted node n tree. assume n
SR , otherwise, extend 0 adding path p rR ... n, p
node outside SR source node incoming edge rR .
Since 0 tree, two simple paths P1 P2 n reach
node z two different e-edges. z cannot SR , since two paths meet
subtree SR , must first meet root rR entering incoming d-edge. However, could
construct F two paths, selecting rL instead rR , contradiction
assumption F compact forest. Clearly, either P1 P2 must pass
new subtree SR , otherwise two paths already existed F.
first handle case where, without loss generality, P1 passes SR
P2 not. P1 passes SR contains e-edge (p, rR ). Since z
/ SR ,
contains e-edge (u, v) u SR v
/ SR . P1 written
n ... p rR ... u v ... z. paths n p v z
F, way enter SR rR P1 simple.
incrementally construct F following embedded partial DAG : First, construct
P2 section P1 n p 0 . Next, expand p e-edge (p, rL )
instead (p, rR ). would expand rL reach z possible.
previously explained, u tied node u0 SL therefore e-edge (u0 , v) exists
F. Therefore, path P 0 SL , rL (u0 , v) z. However,
guaranteed whole P 0 added . try expand incrementally
P 0 , step adding next e-edge path. succeed, embedded
graph F two paths z, contradiction. fail, due e-edge
(z 0 , t) P 0 cannot add. Thus, z 0 must already P2 , node
two distinct paths embedded graph , contradiction. path constructed
indeed different P2 since contains e-edge (p, rL ) cannot part P2 , since
P1 contains disjoint edge (p, rR ).
remaining case, P1 P2 pass SR reach node z
/ SR . P1
written n ... u1 v1 ... z P2 n ... u2 v2 ... z,
u1 , u2 SR , v1 , v2
/ SR . Assume first e-edges (u1 , v1 ) (u2 , v2 )
originate d-edge d. u1 6= u2 , otherwise (u1 , v1 ) (u2 , v2 ) could
embedded partial DAG. u1 ,u2 tied nodes u01 , u02 SL .
show u01 6= u02 : Assume contradiction u01 = u02 = u0 . u0 tied u1
u2 due alignment sharing dual leaf variable sharing. u0 cannot tied u1
u2 due alignment sharing since alignment function nodes SL nodes
SR . cannot tied due dual leaf variable sharing, since variable appears
R. Finally, u0 tied u1 (without loss generality) due dual leaf
variable sharing, d-edge part l. Therefore, u2 include
aligned modifier, thus u2 tied u0 due alignment.
construct embedded graph rooted rL F: SL part
match L F, construct embedded graph rooted rL path
node SL , particular paths u01 u02 . Since u01 6= u02 , u01
u02 source nodes d, part SL , expand two paths
e-edges (u01 , v1 ) (u02 , v1 ) get embedded graph Gn tree,
contradiction.
49

fiBar-Haim, Dagan & Berant

Suppose e-edges (u1 , v1 ) (u2 , v2 ) originate different d-edges d1
d2 respectively. u1 u2 tied u01 u02 . Therefore, v1 6= v2 construct
following embedded graph rooted rL : previous case, expand
paths SL rL u01 u02 . Next, add e-edges (u01 , v1 ) d1 (u02 , v2 )
d2 . Recall d1 d2 SL therefore used expansion. try
expand embedded graph include paths v1 v2 z. succeed,
two paths leading z. fail two paths Tn meeting
node z 0 , explained above. Last, v1 = v2 = v, v node F two
incoming d-edges, contradicting Lemma 1.
case introduction rule quite similar simpler. P1 passes SR
P2 not, n must root compact forest (the node path
rR ). However, case n single outgoing d-edge, therefore outgoing
e-edges disjoint (i.e. cannot part embedded DAG). Thus, P2 must
pass rR - contradiction. P1 P2 pass SR , proof identical
case substitution rule.
shown F 0 cDAG whose embedded DAGs rooted r trees. F 0
single root new nodes added applying L R incoming
edge. Hence, F 0 compact forest.
Corollary 1 inference process generates compact forest.
Proof easy verify initialization generates compact forest. Since applying
rule compact forest results compact forest, inference process generates
compact forest induction number rule applications.
Theorem 2 Given rule base R set initial trees , tree represented
compact forest derivable inference process consequent according
inference formalism.
Proof () first show completeness induction number rule applications n.
n = 0 one initial trees represented initial compact forest.
Let tn+1 tree derived formalism applying sequence n + 1 rules. show
tn+1 represented derivable compact forest. tn+1 derived applying
rule L R tree tn . According inductive assumption, tn represented
compact forest F derivable inference process. Therefore, rule L R
matched applied F. assume L R substitution rule since case
introduction rule similar. tn+1 almost identical tn except contains subtree
R instead L instantiated variables aligned modifiers. easy verify
application L R F resulting F 0 , F 0 contain embedded tree
almost identical tn , except root SR , rR , chosen instead root
SL , rL , rest SR chosen appropriate instantiated variables
modifiers. Therefore, tn+1 = contained F 0 required. guaranteed
tree according Corollary 1.
() Next, prove soundness induction number rule applications
forest. initialization, initial trees consequents. Let Fn+1 compact
forest derived n + 1 rule applications (Corollary 1 guarantees Fn+1 indeed
50

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

compact forest). Given tree tn+1 represented Fn+1 , show tn+1 consequent
formalism.
tn+1 already represented compact forest n rule applications,
according assumption induction consequent formalism. not,
tn+1 new embedded tree created application rule L R. Therefore,
tn+1 contains entire subtree SR . incrementally construct embedded tree tn
represented Fn tn+1 result applying L R tn .
substitution rule, first construct part tn+1 include
subtree rooted rR . introduction rule, take path forests root
rL . Next, construct SL rL instead SR rR . possible since
according Corollary 1 embedded graphs trees, therefore nodes SL
already tn . look set e-edges (s, t) tn+1 SR
/ SR .
Let (s, z) edge originating d-edge Sz subtree rooted z
tn+1 . Notice Sz already part Fn . tied s0 SL therefore s0 source
node d. expand tn include edge (s0 , z) Sz s0 already used
d-edge tn . guaranteed part SL (only d-edges
part SL shared). Finally, complete construction tn arbitrarily
expanding unused outgoing d-edge tn nodes, obtain complete embedded
tree.
constructed embedded tree tn Fn . Therefore, according inductive
assumption, tn consequent formalism. tn contains SL instantiation
dual leaf variables. Therefore, matched L rule L R applied.
easy verify application rule tn yield tn+1 , required. Thus, tn+1
consequent formalism.

sake simplicity, proofs ignored case one leaf
variables L match multiple target nodes l appear R non-leaves. described
Section 5.2, case matched target nodes inserted SR alternatives (with
proper sharing modifiers). Consequently, SR becomes compact forest containing
multiple trees. Similarly, SL compact forest, whose represented trees correspond
possible choices matching leaf variables. mapping nodes matched
leaf variables SL nodes generated SR defines one-to-one
mapping trees SL SR .
proofs easily adapted handle case, follows. First, proof
Lemma 1 need change. Theorem 1, proof rule application create
cycles still holds underlying graph SR DAG rather tree. prove
embedded partial DAG 0 tree, observe exactly one trees embedded
SR part 0 . Thus, consider tree SR corresponding tree
SL , ignoring rest SR SL , proceed original proof. Similarly,
prove completeness Theorem 2, refer tree represented SL , part
tn , corresponding tree SR . prove soundness, consider subtrees
SR corresponding tree SL .
51

fiBar-Haim, Dagan & Berant

References
Bar-Haim, R. (2010). Semantic Inference Lexical-Syntactic Level. Ph.D. thesis,
Department Computer Science, Bar-Ilan University, Ramat-Gan, Israel.
Bar-Haim, R., Berant, J., & Dagan, I. (2009). compact forest scalable inference
entailment paraphrase rules. Proceedings EMNLP.
Bar-Haim, R., Berant, J., Dagan, I., Greental, I., Mirkin, S., Shnarch, E., & Szpektor, I.
(2008). Efficient semantic deduction approximate matching compact parse
forests. Proceedings TAC 2008 Workshop.
Bar-Haim, R., Dagan, I., Dolan, B., Ferro, L., Giampiccolo, D., Magnini, B., & Szpektor,
I. (2006). Second PASCAL Recognising Textual Entailment Challenge.
Second PASCAL Challenges Workshop Recognizing Textual Entailment.
Bar-Haim, R., Dagan, I., Greental, I., & Shnarch, E. (2007). Semantic inference
lexical-syntactic level. Proceedings AAAI.
Bar-Haim, R., Szpektor, I., & Glickman, O. (2005). Definition analysis intermediate
entailment levels. Proceedings ACL Workshop Empirical Modeling
Semantic Equivalence Entailment.
Barzilay, R., & Lee, L. (2003). Learning paraphrase: unsupervised approach using
multiple-sequence alignment. Proceedings HLT-NAACL.
Barzilay, R., & McKeown, K. R. (2001). Extracting paraphrases parallel corpus.
Proceedings ACL.
Bensley, J., & Hickl, A. (2008). Workshop: Application LCCs GROUNDHOG system
RTE-4. Proceedings TAC 2008 Workshop.
Bentivogli, L., Clark, P., Dagan, I., Dang, H. T., & Giampiccolo, D. (2010). Sixth
PASCAL Recognizing Textual Entailment Challenge. Proceedings TAC 2010
Workshop.
Bentivogli, L., Dagan, I., Dang, H. T., Giampiccolo, D., & Magnini, B. (2009). Fifth
PASCAL Recognizing Textual Entailment Challenge. Proceedings TAC 2009
Workshop.
Berant, J., Dagan, I., & Goldberger, J. (2011). Global learning typed entailment rules.
Proceedings ACL.
Bhagat, R., & Ravichandran, D. (2008). Large scale acquisition paraphrases learning
surface patterns. Proceedings ACL-08: HLT.
Bos, J., & Markert, K. (2005). Recognising textual entailment logical inference techniques. Proceedings EMNLP.
Bos, J., & Markert, K. (2006). logical inference helps determining textual entailment
(and doesnt). Proceedings Second PASCAL Recognising Textual
Entailment Challenge.
Chklovski, T., & Pantel, P. (2004). VerbOcean: Mining web fine-grained semantic
verb relations. Proceedings EMNLP.
52

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

Collins, M., & Duffy, N. (2001). Convolution kernels natural language. Advances
Neural Information Processing Systems 14.
Connor, M., & Roth, D. (2007). Context sensitive paraphrasing single unsupervised
classifier. ECML.
Cooper, R., Crouch, R., van Eijck, J., Fox, C., van Genabith, J., Jaspars, J., Kamp, H.,
Pinkal, M., Milward, D., Poesio, M., Pulman, S., Briscoe, T., Maier, H., & Konrad, K.
(1996). Using framework. Tech. rep., FraCaS: Framework Computational
Semantics.
Dagan, I., & Glickman, O. (2004). Probabilistic textual entailment: Generic applied modeling language variability. PASCAL workshop Text Understanding Mining.
Dagan, I., Glickman, O., Gliozzo, A., Marmorshtein, E., & Strapparava, C. (2006a). Direct
word sense matching lexical substitution. Proceedings COLING-ACL.
Dagan, I., Glickman, O., & Magnini, B. (2006b). PASCAL Recognising Textual Entailment Challenge. Quinonero-Candela, J., Dagan, I., Magnini, B., & dAlche Buc, F.
(Eds.), Machine Learning Challenges. Lecture Notes Computer Science, Vol. 3944,
pp. 177190. Springer.
Dagan, I., Roth, D., Sammons, M., & Zanzotto, F. M. (2013). Recognizing Textual Entailment: Models Applications. Synthesis Lectures Human Language Technologies.
Morgan & Claypool Publishers.
de Salvo Braz, R., Girju, R., Punyakanok, V., Roth, D., & Sammons, M. (2005). inference
model semantic entailment natural language.. Proceedings AAAI.
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990).
Indexing latent semantic analysis. Journal American Society Information
Science, 41 (6), 391407.
Dinu, G., & Lapata, M. (2010). Topic models meaning similarity context. Proceedings Coling 2010: Posters.
Emele, M. C., & Dorna, M. (1998). Ambiguity preserving machine translation using packed
representations. Proceedings COLING-ACL.
Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. Language, Speech
Communication. MIT Press.
Gabrilovich, E., & Markovitch, S. (2007). Computing semantic relatedness using Wikipediabased Explicit Semantic Analysis. Proceedings IJCAI.
Ganitkevitch, J., Van Durme, B., & Callison-Burch, C. (2013). PPDB: paraphrase
database. Proceedings HLT-NAACL.
Giampiccolo, D., Magnini, B., Dagan, I., & Dolan, B. (2007). Third PASCAL Recognizing Textual Entailment Challenge. Proceedings ACL-PASCAL Workshop
Textual Entailment Paraphrasing.
Giampiccolo, D., Trang Dang, H., Magnini, B., Dagan, I., & Dolan, B. (2008). Fourth
PASCAL Recognizing Textual Entailment Challenge. Proceedings TAC 2008
Workshop.
53

fiBar-Haim, Dagan & Berant

Glickman, O., & Dagan, I. (2003). Identifying lexical paraphrases single corpus:
case study verbs. Proceedings RANLP.
Glickman, O., Shnarch, E., & Dagan, I. (2006). Lexical reference: semantic matching
subtask. Proceedings EMNLP.
Haghighi, A. D., Ng, A. Y., & Manning, C. D. (2005). Robust textual inference via graph
matching. Proceedings EMNLP.
Harmeling, S. (2009). Inferring textual entailment probabilistically sound calculus.
Natural Language Engineering, 15 (4), 459477.
Heilman, M., & Smith, N. A. (2010). Tree edit models recognizing textual entailments,
paraphrases, answers questions. Proceedings HLT-NAACL.
Hickl, A. (2008). Using discourse commitments recognize textual entailment. Proceedings COLING.
Hickl, A., & Bensley, J. (2007). discourse commitment-based framework recognizing textual entailment. Proceedings ACL-PASCAL Workshop Textual
Entailment Paraphrasing.
Hickl, A., Bensley, J., Williams, J., Roberts, K., Rink, B., & Shi, Y. (2006). Recognizing textual entailment LCCs GROUNDHOG system. Second PASCAL
Challenges Workshop Recognizing Textual Entailment.
Jurafsky, D., & Martin, J. H. (2008). Speech Language Processing: Introduction
Natural Language Processing, Computational Linguistics Speech Recognition
(Second edition). Prentice Hall.
Kamp, H., & Reyle, U. (1993). Discourse Logic. Introduction Modeltheoretic
Semantics Natural Language, Formal Logic Discourse Representation Theory.
Kluwer Academic Publishers, Dordrecht.
Kay, M. (1996). Chart generation. Proceedings ACL.
Kazama, J., & Torisawa, K. (2007). Exploiting Wikipedia external knowledge named
entity recognition. Proceedings EMNLP-CoNLL.
Kipper, K. (2005). VerbNet: broad-coverage, comprehensive verb lexicon. Ph.D. thesis,
University Pennsylvania.
Kouylekov, M., & Magnini, B. (2005). Tree edit distance textual entailment. Proceedings RANLP.
Lehmann, J., Bizer, C., Kobilarov, G., Auer, S., Becker, C., Cyganiak, R., & Hellmann,
S. (2009). DBpedia - crystallization point web data. Journal Web
Semantics.
Lin, D. (1998). Dependency-based evaluation minipar. Proceedings Workshop
Evaluation Parsing Systems LREC.
Lin, D., & Pantel, P. (2001). Discovery inference rules question answering. Natural
Language Engineering, 7 (4), 343360.
Lotan, A., Stern, A., & Dagan, I. (2013). TruthTeller: Annotating predicate truth.
Proceedings HLT-NAACL.
54

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

MacCartney, B., Galley, M., & Manning, C. D. (2008). phrase-based alignment model
natural language inference. Proceedings EMNLP.
MacCartney, B., Grenager, T., de Marneffe, M.-C., Cer, D., & Manning, C. D. (2006).
Learning recognize features valid textual entailments. Proceedings HLTNAACL.
MacCartney, B., & Manning, C. D. (2009). extended model natural logic. Proceedings IWCS-8.
Macleod, C., Grishman, R., Meyers, A., Barrett, L., & Reeves, R. (1998). Nomlex: lexicon
nominalizations. Proceedings Euralex98.
Maxwell III, J. T., & Kaplan, R. M. (1991). method disjunctive constraint satisfaction. Tomita, M. (Ed.), Current Issues Parsing Technology. Kluwer Academic
Publishers.
Mehdad, Y., & Magnini, B. (2009a). word overlap baseline recognizing textual
entailment task. Unpublished manuscript.
Mehdad, Y., & Magnini, B. (2009b). Optimizing textual entailment recognition using particle swarm optimization. Proceedings 2009 Workshop Applied Textual
Inference.
Melamud, O., Berant, J., Dagan, I., Goldberger, J., & Szpektor, I. (2013). two level
model context sensitive inference rules. Proceedings ACL.
Meyers, A., Reeves, R., Macleod, C., Szekeley, R., Zielinska, V., & Young, B. (2004).
cross-breeding dictionaries. Proceedings LREC.
Mi, H., Huang, L., & Liu, Q. (2008). Forest-based translation. Proceedings ACL-08:
HLT.
Mirkin, S., Dagan, I., & Pado, S. (2010). Assessing role discourse references
entailment inference. Proceedings ACL.
Mirkin, S., Dagan, I., & Shnarch, E. (2009). Evaluating inferential utility lexicalsemantic resources. Proceedings EACL.
Moldovan, D. I., & Rus, V. (2001). Logic form transformation WordNet applicability question answering. Proceedings ACL.
Nairn, R., Condoravdi, C., & Karttunen, L. (2006). Computing relative polarity textual
inference. Proceedings International workshop Inference Computational
Semantics (ICoS-5).
Pang, B., Knight, K., & Marcu, D. (2003). Syntax-based alignment multiple translations:
Extracting paraphrases generating new sentences. Proceedings HLT-NAACL.
Pantel, P., Bhagat, R., Coppola, B., Chklovski, T., & Hovy, E. (2007). ISP: Learning
inferential selectional preferences. Proceedings HLT-NAACL.
Ponzetto, S. P., & Strube, M. (2007). Deriving large-scale taxonomy wikipedia.
Proceedings AAAI.
Ravichandran, D., & Hovy, E. (2002). Learning surface text patterns question answering system. Proceedings ACL.
55

fiBar-Haim, Dagan & Berant

Ritter, A., Mausam, & Etzioni, O. (2010). latent dirichlet allocation method selectional
preferences. Proceedings ACL.
Romano, L., Kouylekov, M., Szpektor, I., Dagan, I., & Lavelli, A. (2006). Investigating
generic paraphrase-based approach relation extraction. Proceedings EACL.
Ron, T. (2006). Generating entailment rules based online lexical resources. Masters
thesis, Computer Science Department, Bar-Ilan University.
Ruppenhofer, J., Sporleder, C., Morante, R., Baker, C., & Palmer, M. (2009). Semeval2010 task 10: Linking events participants discourse. Proceedings
Workshop Semantic Evaluations: Recent Achievements Future Directions
(SEW-2009).
Saint-Dizier, P., & Mehta-Melkar, R. (Eds.). (2011). Proceedings Joint Workshop FAM-LbR/KRAQ11. Learning Reading Applications Intelligent
Question-Answering.
Schoenmackers, S., Etzioni, O., Weld, D. S., & Davis, J. (2010). Learning first-order horn
clauses web text. Proceedings EMNLP.
Shinyama, Y., Sekine, S., Sudo, K., & Grishman, R. (2002). Automatic paraphrase acquisition news articles. Proceedings HLT.
Shnarch, E., Barak, L., & Dagan, I. (2009). Extracting lexical reference rules
Wikipedia. Proceedings ACL-IJCNLP.
Snow, R., Jurafsky, D., & Ng, A. Y. (2006a). Semantic taxonomy induction heterogenous evidence. Proceedings COLING-ACL.
Snow, R., Vanderwende, L., & Menezes, A. (2006b). Effectively using syntax recognizing
false entailment. Proceedings HLT-NAACL.
Stern, A., & Dagan, I. (2011). confidence model syntactically-motivated entailment
proofs. Proceedings RANLP.
Stern, A., & Dagan, I. (2014). Recognizing implied predicate-argument relationships
textual inference. Proceedings ACL.
Stern, A., Stern, R., Dagan, I., & Felner, A. (2012). Efficient search transformation-based
inference. Proceedings ACL.
Szpektor, I., & Dagan, I. (2007). Learning canonical forms entailment rules. Proceedings
RANLP.
Szpektor, I., & Dagan, I. (2008). Learning entailment rules unary templates. Proceedings COLING.
Szpektor, I., & Dagan, I. (2009). Augmenting WordNet-based inference argument
mapping. Proceedings ACL-IJCNLP Workshop Applied Textual Inference
(TextInfer).
Szpektor, I., Dagan, I., Bar-Haim, R., & Goldberger, J. (2008). Contextual preferences.
Proceedings ACL-08: HLT.
Szpektor, I., Tanev, H., Dagan, I., & Coppola, B. (2004). Scaling web based acquisition
entailment patterns. Proceedings EMNLP.
56

fiKnowledge-Based Textual Inference via Parse-Tree Transformations

Tatu, M., Iles, B., Slavick, J., Novischi, A., & Moldovan, D. (2006). COGEX Second Recognizing Textual Entailment Challenge. Second PASCAL Challenges
Workshop Recognizing Textual Entailment.
Tatu, M., & Moldovan, D. (2006). logic-based semantic approach recognizing textual
entailment. Proceedings COLING-ACL.
Tatu, M., & Moldovan, D. (2007). COGEX RTE3. Proceedings ACL-PASCAL
Workshop Textual Entailment Paraphrasing.
Valencia, V. S. (1991). Studies Natural Logic Categorial Grammar. Ph.D. thesis,
University Amsterdam.
van Deemter, K., & Kibble, R. (2000). coreferring: Coreference MUC related
annotation schemes. Computational Linguistics, 26 (4), 629637.
Voorhees, E. M., & Harman, D. (1997). Overview sixth Text REtrieval Conference
(TREC-6). Proceedings TREC.
Wang, M., & Manning, C. (2010). Probabilistic tree-edit models structured latent
variables textual entailment question answering. Proceedings COLING.
Wang, R., & Neumann, G. (2007). Recognizing textual entailment using subsequence
kernel method. Proceedings AAAI.
Yates, A., & Etzioni, O. (2009). Unsupervised methods determining object relation
synonyms web. Journal Artificial Intelligence Research (JAIR), 34, 255296.
Zanzotto, F. m., Pennacchiotti, M., & Moschitti, A. (2009). machine learning approach
textual entailment recognition. Natural Language Engineering, 15 (4), 551582.

57


