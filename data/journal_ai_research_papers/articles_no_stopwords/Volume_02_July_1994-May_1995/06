journal artificial intelligence

submitted published

adaptive load balancing study multi agent
learning
andrea schaerf

aschaerf dis uniroma

dipartimento di informatica e sistemistica
universita di roma la sapienza via salaria roma italy

yoav shoham

robotics laboratory computer science department
stanford university stanford ca usa

moshe tennenholtz

faculty industrial engineering management
technion haifa israel

shoham flamingo stanford edu
moshet ie technion ac il

abstract
study process multi agent reinforcement learning context load balancing distributed system without use central coordination explicit communication first define precise framework study adaptive load balancing
important features stochastic nature purely local information
available individual agents given framework illuminating
interplay basic adaptive behavior parameters effect system eciency
investigate properties adaptive load balancing heterogeneous populations
address issue exploration vs exploitation context finally
naive use communication may improve might even harm system eciency

introduction
article investigates multi agent reinforcement learning context concrete
undisputed importance load balancing real life provides us many examples emergent uncoordinated load balancing trac alternative highways tends
even time members computer science department tend use powerful networked workstations eventually lower load machines
inviting would understand dynamics emergent
load balancing systems apply lesson design multi agent systems
define formal yet concrete framework study issues called multiagent multi resource stochastic system involves set agents set resources
probabilistically changing resource capacities probabilistic assignment jobs agents
probabilistic job sizes agent must select resource job
eciency resource handles job depends capacity resource
lifetime job well number jobs handled resource
period time performance measure system aims globally optimizing
resource usage system ensuring fairness system made
ecient expense particular agent two common criteria load balancing
c ai access foundation morgan kaufmann publishers rights reserved

fischaerf shoham tennenholtz

agent choose appropriate resource order optimize measures
make important assumption spirit reinforcement learning sutton
information available agent prior experience particular
agent necessarily know past present future capacities resources
unaware past current future jobs submitted agents even
relevant probability distributions goal agent thus adapt resourceselection behavior behavior agents well changing capacities
resources changing load without explicitly knowing
interested several basic questions

good resource selection rules
fact different agents may use different resource selection rules affect
system behavior

communication among agents improve system eciency
following sections illuminating answers questions contribution therefore twofold apply multi agent reinforcement learning
domain adaptive load balancing use basic domain order demonstrate
basic phenomena multi agent reinforcement learning
structure follows section discuss general setting
objective section motivate study point impact formal
framework defined discussed section section completes discussion
framework introducing resource selection rule parameters function
control knobs adaptive process section present experimental
adaptive behavior within framework parameters affect
eciency adaptive behavior case heterogeneous populations investigated
section case communicating populations discussed section section
discuss impact section put work perspective
related work finally section conclude brief summary

general setting

applies reinforcement learning domain adaptive load balancing however presenting model use detailed study need clarify several
points general setting particular need explain interpretation
reinforcement learning interpretation load balancing adopt
much work devoted recent years distributed adaptive load balancing one related work field distributed computer systems e g pulidas
towsley stankovic mirchandaney stankovic billard pasquale
glockner pasquale mirchandaney towsley stankovic zhou eager
lazowska zahorjan organization theory management science e g malone
many applications capacities resources known least extent point
discussed later basically wish investigate far one go purely
local feedback without use global information kaelbling sutton



fiadaptive load balancing study multi agent learning

distributed ai e g bond gasser although motivations
mentioned lines similar settings discussed essential
differences
work distributed computer systems adopts view set computers
controls certain resources autonomous decision making capability jobs
arrive dynamic fashion decision making agents different computers
called nodes try share system load coordinate activities means
communication actual action performed information received
computers may controlled ways one ways adopted control
related decisions learning automata narendra thathachar
mentioned work agent associated set resources
agent related resources associated node distributed system
much work management science distributed ai adopts somewhat complementary
view difference classical work distributed operating systems agent
associated set resources controls agents autonomous entities
negotiate among zlotkin rosenschein kraus wilkenfeld
use shared resources alternatively agents called managers case may
negotiate task executed processors may execute malone
model adopt avor used distributed ai organization
theory assume strict separation agents resources jobs arrive agents
make decisions execute resources passive e
make decisions typical example setting computerized framework set
pcs controlled different user submits jobs executed
one several workstations workstations assumed independent
shared among users example real life situation motivated
study terminology adopt taken framework however
real life situations related model areas different classical distributed
computer systems
canonical related model following one arthur agent
embedded multi agent system select among set bars set restaurants
agent makes autonomous decision performance bar therefore
agents use function capacity number agents use
decision going bar stochastic process decision bar use
autonomous decision respective agent similar situation arises product
manager decides processor use order perform particular task model
present section general model situations investigated
situations job arrives agent rather node consisting particular resources
decides upon resource e g restaurant job executed
priori association agents resources
discuss way agents behave framework common theme
among mentioned lines load balancing achieved means
communication among active agents active resources related decisionmaking agents study adopt complementary view consider agents
act purely local fashion purely local information described recent
reinforcement learning literature mentioned learning automata used


fischaerf shoham tennenholtz

field distributed computer systems order perform adaptive load balancing nevertheless related learning procedures rely heavily communication among agents
among decision making agents autonomous computers work applies recent work
reinforcement learning ai information agent gets purely local hence
agent know ecient service restaurant choosing
place eat assume agents may informed agents load
restaurants restaurants announce current load makes
work strictly different work applying reinforcement learning adaptive load
balancing
features make model study basic general moreover
discussion raises question whether reinforcement learning purely
local information feedback guarantee useful load balancing combination
model use perspective reinforcement learning makes contribution
novel nevertheless mentioned discuss section model
use original us captures many known situations distributed
load balancing apply reinforcement learning discussed recent ai literature
model investigate properties related process

multi agent multi resource stochastic system

section define concrete framework study dynamic load balancing
model present captures adaptive load balancing general setting mentioned
section restrict discussion discrete synchronous systems thus
definition refer n natural numbers similar definitions possible
continuous case concentrate case job executed
resources although somewhat restricting common practice much work
distributed systems mirchandaney stankovic

definition multi agent multi resource stochastic system tuple ha r p c
sri fa g set agents r fr rm g set resources
p n job submission function n probabilistic job size
function c rn probabilistic capacity function sr resource selection
rule

intuitive interpretation system follows resources
certain capacity real number capacity changes time determined
function c time point agent idle engaged idle may
submit job probability given p job certain size
real number size submitted job determined function
use unit token referring job sizes resource capacities mean
tokens come integer quantities job agent selects one
resources choice made according rule sr since much say
rule discuss separately next section
model job may run resource furthermore limit
number jobs served simultaneously given resource thus queuing occurs
however quality service provided resource given time deteriorates


fiadaptive load balancing study multi agent learning

number agents time specifically every time point resource
distributes current capacity e tokens equally among jobs served
size job reduced amount drops zero job
completed agent notified becomes idle thus execution time
job j depends size capacity time resource processing
number agents resource execution j
measure system performance twofold aim minimize timeper token averaged jobs well minimize standard deviation
random variable minimizing quantities ensure overall system eciency well
fairness question selection rules yield ecient behavior turn next
definition rules

adaptive resource selection rules
rule agents select resource job selection rule sr
heart adaptive scheme topic section throughout section
following one make assumption homogeneity namely assume
agents use sr notice although system homogeneous agent
act local information sections relax homogeneity
assumption discuss heterogeneous communicating populations
already emphasized among possible adaptive srs interested
purely local srs ones access experience particular agent
setting experience consists previous job submissions job submitted
agent already completed agent knows name r resource used
point time tstart job started point time tstop job finished
job size therefore input sr principle list elements form
r tstart tstop notice type input captures general type systems
interested basically wish assume little possible information
available agent order capture real loosely coupled systems global
information unavailable
whenever agent selects resource job execution may get feedback
non negligible time feedback may depend decisions made agents
agent decision forces agent rely non trivial portion
history makes much harder
uncountably many possible adaptive srs aim gain exhaustive understanding rather experimented family intuitive
relatively simple srs compared non adaptive ones motivation choosing particular family srs partially due observations made
cognitive psychologists people tend behave multi agent stochastic recurrent situations principle set srs captures two robust aspects
observations law effect thronkide power law practice blackburn family rules called
partially resembles learning rules
discussed learning automata literature narendra thathachar partially resembles interval estimation kaelbling agents maintain
complete history experience instead agent condenses history


fischaerf shoham tennenholtz

vector called eciency estimator denoted eea length vector
number resources th entry vector represents agent evaluation
current eciency resource specifically eea r positive real number
vector seen state learning automaton addition eea agent keeps
vector jda stores number completed jobs submitted agent
resources since beginning time thus within
need specify
two elements
agent updates eea job completed
agent selects resource job given eea jda
loosely speaking eea maintained weighted sum feedback
previous value eea resource selected probably one highest
eea entry except low probability resource chosen two
steps explained precisely following two subsections

updating eciency estimator
take function updating eea

eea r wt w eea r
represents time per token newly completed job computed
feedback r tstart tstop following way

tstop tstart
take w real value interval whose actual value depends jda r
means take weighted average feedback value old
value eciency estimator w determines weights given pieces
information value w obtained following function

w w w jda r
formula w real valued constant term w jda r correcting
factor major effect jda r low jda r increases reaching
value several hundreds term becomes negligible respect w

selecting resource

second ingredient adaptive srs
function pda selecting resource
job eea jda function probabilistic first define following
function

jda r
r n

pda r ee

n
e ee
jd r




parallel processing terminology viewed stretch factor quantifies stretching
program processing time due multiprogramming ferrari serazzi zeigner



fiadaptive load balancing study multi agent learning

n positive real valued parameter e eea represents average values
eea r resources satisfying jda r turn probability function
define pda normalized version pd

pda r pd r
rpd r normalization factor
function pda clearly biases selection towards resources performed
well past strength bias depends n larger value n
stronger bias extreme cases value n high e g agent
choose resource best record strategy choosing
best although perhaps intuitively appealing general good one
allow agent exploit improvements capacity load resources
discuss sr following subsection expand issue exploration versus
exploitation sections
summarize defined general setting investigate emergent load
balancing particular defined family adaptive resource selection rules
parameterized pair w n parameters serve knobs tune
system optimize performance next section turn experimental
obtained system

best choice sr bcsr

best choice sr bcsr learning rule assumes high value n e
chooses best resource given point assume w fixed given
value discussing bcsr previous work shoham tennenholtz
showed learning rules strongly resemble bcsr useful several natural
multi agent learning settings suggests need carefully study case
adaptive load balancing demonstrate bcsr useful load
balancing setting
difference bcsr learning rule value n low
latter case agent gives relatively high probability selection resource
give best past case agent might able notice
behavior one resources improved due changes system
note exploration non best resources crucial dynamics
system includes changes capacities resources cases agent could
take advantage possible increases capacity resources uses bcsr one
might wonder however whether cases main dynamic changes system
stem load changes relying bcsr sucient latter true
able ignore parameter n concentrate bcsr systems
capacity resources fixed order clarify point consider following
example
r jda r e agent going submit first job assume
agent chooses resource randomly uniform probability distribution



fischaerf shoham tennenholtz

suppose two resources r r whose respective fixed capacities
cr cr satisfy equality cr cr assume load system varies

certain low value certain high one
system load low agents adopt bcsr system evolve
way almost agents would preferring r r due
fact case low load overlaps jobs hence r much
ecient hand system load high r could busy
agents would prefer r since performance obtained
less crowded resource r could better one obtained overly crowded
resource r extreme case high load expect agents use r one
third time
assume load system starts low level increases
high value decreases reach original value load increases
agents mostly r start observing r performance becoming
worse therefore following bcsr start r load
decreases agents r observe improvement performance
r value stored r e eea still ect previous
situation hence agents keep r ignoring possibility obtaining
much better moved back r situation randomized selection
makes agents able use r certain probability therefore
may discover performance r better r switch back r
improve system eciency significant manner
example shows bcsr general case good choice
general true value n high
discussion assumed changes load unforeseen
able predict changes load agents simply use bcsr
load fixed use low value n changes case instead
without even realizing system changed way agents would need
see would able adapt dynamic changes well

experimental
section compare srs
another well non adaptive
benchmark selection rules
non adaptive srs consider agents partition
according capacities load system fixed predetermined
manner agent uses resource later sr
kind identified configuration vector specifies resource many
agents use test adaptive srs compare performance nonadaptive srs perform best particular creates highly competitive
set benchmarks adaptive srs
addition compare adaptive srs load querying sr defined
follows agent job asks resources busy
chooses less crowded one


fiadaptive load balancing study multi agent learning

experimental setting
introduce particular experimental setting many described
obtained present order concrete experiments however
qualitative experiments observed variety experimental
settings
one motivation particular setting stems pcs workstations
mentioned section example part study related set computers
located single site computers relatively high load peak hours
day low load night e chances user pc submits job
higher day time week days night weekend another
part study related set computers split around world
load quite random structure e due difference time zones users may use pcs
unpredictable hours
another motivation particular setting stems restaurant mentioned section discussion related bar see arthur
example consider set snack bars located industrial park snack
bars relatively high loads peak hours day low load night
e chances employee choose go snack bar higher day
employees present day conversely assume
set bars near airport load quite random structure e airport
employees may use snack bars quite unpredicted hours
although particular real situations would emphasize general
motivation study fact related phenomena observed
different settings
take n number agents number resources
first set experiments take capacities resources fixed
particular take c c c c c assume
agents probability submitting job assume
agents distribution size jobs submit specifically assume
uniform distribution integers range
ease exposition assume point time corresponds second
consequently count time minutes hours days weeks hour
main point reference assume simplicity changes system e load
change capacity change happen beginning hour probability
submitting job second corresponds load system vary
time crucial factor agents must adapt note agents
submit jobs second probability submission may change particular
concentrate three different values quantity called llo lhi lpeak
assume system load switches values actual values llo lhi
lpeak following quantitative roughly correspond
agent submitting jobs per hour per agent respectively


fischaerf shoham tennenholtz

load

configuration
time per token
llo
f g

lhi
f g

lpeak f g

figure best non adaptive srs fixed load
following measuring success refer average time pertoken however adaptive srs give best average time per token
found fair

fixed load

start case load fixed case interesting
adaptive behavior however satisfactory sr reasonably ecient behavior
basic case order useful system stabilizes
start showing behavior non adaptive benchmark srs case fixed
load figure shows give best three loads
see big difference three loads mentioned
load particularly high agents scatter around resources rate
proportional capacities load low use best resource
given easy see adaptive sr effective enables
moving quickly one configuration
static setting expect best non adaptive srs perform better adaptive ones since information gained exploration adaptive srs
built non adaptive ones experimental confirm intuition
shown figure lhi figure shows performance obtained population
value n varies three values w
note values n w good choices dynamic cases see later
values intervals respectively deterioration
performance adaptive srs respect non adaptive ones small
encouraging since adaptive srs meant particularly suitable dynamic
systems following subsections see indeed

changing load

begin explore dynamic settings consider case
load system probability agents submitting job time changes
time present two dynamic settings one load changes
according fixed pattern random perturbations another
load varies random fashion specifically first case fix load lhi
data shown later refer convenience time tokens
non adaptive srs human designed srs used benchmarks assume knowledge
load capacity available adaptive srs design



fiadaptive load balancing study multi agent learning


v
e
r

g
e



e
p
e
r


k
e
n








weight w
weight w
weight w


















































exponent randomization function n



figure performance adaptive selection rules fixed load
ten consecutive hours five days week two randomly chosen hours
lpeak llo rest week second case fix number
hours week load first case distribute completely
randomly week
obtained two cases similar figure shows obtained
adaptive srs case random load best non adaptive deterministic
sr gives time per token value obtained configuration partition
agents f g adaptive srs superior load querying sr instead gets
time per token value obviously better far
performances adaptive srs
observe following phenomenon given fixed n resp fixed w average
time per token non monotonic w resp n phenomenon strongly related
issue exploration versus exploitation mentioned phenomena observed
study q learning watkins
notice two parameters n w interplay fact value
w minimum time per token value obtained different value n
precisely higher w lower n must order obtain best means
order obtain high performance highly exploratory activity low n
matched giving greater weight recent experience high w parameter


fischaerf shoham tennenholtz


v
e
r

g
e



e
p
e
r


k
e
n







weight w




weight w
weight w
















































exponent randomization function n



figure performance adaptive selection rules random load
matching intuitively explained following qualitative way exploration
activity pays allows agent detect changes system however
effective change detected significantly affect eciency estimator
e w high otherwise cost exploration activity greater gain

changing capacities
consider case capacity resources vary time
particular demonstrate case previously mentioned setting
assume capacities rotate randomly among resources five consecutive
days resource gets capacity one day days
days load varies randomly
experiment shown figure best non adaptive sr
case gives time per token value obtained configuration
f g adaptive srs give much better slightly
usually capacities change less dramatic fashion use mentioned setting
order demonstrate applicability severe conditions
load querying sr gives case fixed capacities sr
obviously uenced change



fiadaptive load balancing study multi agent learning


v
e
r

g
e



e
p
e
r


k
e
n
















































weight w

weight w
weight w











exponent randomization function n

figure performance adaptive selection rules changing capacities
worse case fixed capacities phenomena mentioned visible
case see example weight mismatches low values n

heterogeneous populations
throughout previous section assumed agents use sr e
homogeneity assumption assumption situation sort
centralized line controller beginning tells agents behave
leaves agents make decisions
situation described different line centralized controller makes every decision however would move even
investigate situation agent able make decision
strategy use maybe adjust time
step toward study systems kind drop homogeneity assumption
consider situation part population uses one sr part
uses second one
first set experiments consider setting discussed subsection
confront one two populations called size agents
population uses different sr
sr population


fischaerf shoham tennenholtz




v
e
r

g
e



e
p
e
r


k
e
n




























































exponent randomization function n



figure performance populations agents n w w
determined pair parameters wi ni measure success population
defined average time per token members denoted ti
figure shows obtained w w n different
values n case randomly varying load
expose following phenomenon two populations obtain different
outcomes ones obtain homogeneous case specifically
n obtained agents use n generally better
obtained ones use n despite fact homogeneous population
uses n gets better homogeneous population uses n
phenomenon described following intuitive explanation n
mentioned range population uses n less exploring e
exploiting one left might able
adapt changes satisfactory manner however joined
population gets advantages experimental activity agents population
without paying fact exploring agents trying unload
crowded resources make service agents well
worth observing figure n low e g n agents use
n take role explorers lose lot agents use n gain
situation conversely high values n e g n performances exploiters


fiadaptive load balancing study multi agent learning


v
e
r

g
e



e
p
e
r


k
e
n




























































exponent randomization function n



figure performance populations agents n w w
use n deteriorate means exploiters static hinder
explorers take advantage
better understanding phenomena involved experimented
asymmetric population composed one large group one small one instead two
groups similar size figure shows obtained setting similar
one population composed members population consists
members case every value n exploiters better
explorers experiments case higher n better
e exploiters exploit gain
suggest single agent gets best noncooperative adopting resource best performance e use bcsr
given rest agents use adaptive e cooperative sr however
agents non cooperative lose conclusion selfish interest
agent match interest population contrary
obtained basic contexts multi agent learning shoham tennenholtz
shown fixed value w coexisting populations adopting
different values n interact similar obtained fix value n
fact illuminating instance well known prisoners dilemma axelrod



fischaerf shoham tennenholtz


v
e
r

g
e



e
p
e
r


k
e
n

































































weight estimator parameter w



figure performance populations agents n n w
use two different values w cases agents adopting lower value w
general winners shown figure n n w w
low corresponding agents get poor longer winners
case high n figure
another interesting phenomenon obtained confronting adaptive agents
load querying agents load querying agents agents able consult resources
submit jobs load querying agent submit job
unloaded resource given point confronting load querying agents
adaptive ones obtained adaptive agents obviously worse
obtained load querying ones better obtained
complete population adaptive agents means load querying agents play
role parasites mentioned exploiters load querying agents help
maintaining load balancing among resources therefore help rest
agents another obtain agents adopt deterministic srs may behave
parasites worsen performance adaptive agents
assertions supported experiments described figure population agents uses adaptive sr parameters n w faced
minority agents use different srs stated particular four
cases consider minority behaves following ways choose resource


fiadaptive load balancing study multi agent learning

agents
agents







load querying

res








figure performance populations agents srs
gave best ii conservative updating history iii
load querying agents iiii use deterministically resource capacity
basic experimental setting

communication among agents
point assumed direct communication among agents
motivation considered situations absolutely
transmission channels protocols assumption agreement idea
multi agent reinforcement learning systems massive communication feasible
much concerned multiple agent adaptation reduces
supplying satisfactory communication mechanisms multi agent reinforcement learning
interesting real life forces agents act without priori arranged communication channels must rely action feedback mechanisms however interest
understand effects communication system eciency shoham tennenholtz tan agents augmented sort communication
capabilities study extension led illuminating
present
assume agent communicate agents
call neighbors therefore consider relation neighbor assume exive symmetric transitive consequence relation neighbor partitions
population equivalence classes call neighborhoods
form communication consider idea eciency estimators agents within neighborhood shared among decision made
e agent chooses resource reader notice naive
form communication sophisticated types communication possible
however form communication natural concentrate agents
update behavior past information particular type
communication similar ones used mentioned work incorporating
communication framework multi agent reinforcement learning
suppose different srs may used different agents population
impose condition within single neighborhood sr used
members
assume agent keeps history updates
usual way choice instead agent eciency estimator


fischaerf shoham tennenholtz


v
e
r

g
e



e
p
e
r


k
e
n

































































cns agents
cns agents
cns agents






exponent randomization function n



figure performance adaptive selection rules random load profile communicating agents
average eciency estimators agents corresponding neighborhood
average called neighborhood eciency estimator neighborhood eciency
estimator physical storage value recalculated time member needs
order compare behavior communicating agents non communicating ones
assume single population might aside neighborhoods defined
neighborhoods allow sharing eciency estimators among
members members neighborhoods behave described previous
sections e agent relies history thing common
among members neighborhood members use sr
call communicating neighborhood cn neighborhood eciency estimators shared decision taken non communicating neighborhood ncn
neighborhood done
first set experiments ran regards population composed cns
size particular considered cns sizes starting cns
size going cns size load profile exploited random load change
defined subsection value w taken n taken
values obtained shown figure


fiadaptive load balancing study multi agent learning

communicating populations get good
reason members cn tend conservative sense
mostly use best resource fact since rely average several agents
picture system tends much static particular bigger
cn conservative members tend example consider values
n w give best non communicating agents values give quite bad
performance cns since turn conservative
adaptive values n w behavior communicating population improves reaches performance slightly worse performance
non communicating population tuning parameters finer grain possible
obtain performance equal one obtained non communicating population
however seems clear obvious gain achieved form communication
capability intuitive explanation two opposite effects caused
communication one hand agents get fairer picture system prevents bad resources therefore getting bad performance
hand since agents cn better picture system tend
use best resources thus compete fact agents behave
selfishly selfish interest may agree interest population
whole
interesting message get fact agents may
distorted picture system typical non communicating populations
turns advantage population whole
sharing data among agents leads poorer performances case
agents common views loads target jobs toward lightly loaded
resources quickly become overloaded order profitably use shared data
allow form reasoning fact data shared
however scope see e g lesser
order understand behavior system cns ncns face
consider ncn agents together set cns equal size different values
size corresponding experiments shown figure
members cns inclined use best resources behave parasites
sense explained section exploit adaptiveness rest population
obtain good performance best resources reason get better
rest population shown experimental
interesting observe ncn uses conservative selection rule
cns obtain even better intuitive explanation behavior
although groups e communicating ones one high value n
tend conservative communicating ones win conservative
clever way making use better picture situation
conclusion draw section proposed form communication
agents may provide useful means improve performance population
setting however claim communication agents completely
useless nevertheless observed provide straightforward significant
improvement support claim sole past history agent


fischaerf shoham tennenholtz

agents
ncn
ncn
ncn
ncn
ncn
ncn
ncn
ncn

agents
cn
cns
cns
cns
cn
cns
cns
cns























figure performance cns ncns together
reasonable information base decision assuming consider available
kind real time information e g current load resources

discussion
previous sections devoted report experimental study synthesize observations view motivation discussed sections
mentioned model general model active autonomous agents
select among several resources dynamic fashion local information
fact agents use local information makes possibility ecient loadbalancing questionable however showed adaptive load balancing purely
local feedback feasible task hence complementary ones obtained
distributed computer systems literature mirchandaney stankovic put
significant work illustrated possible design
learning controller able dynamically acquire relevant job scheduling information
process trial error use information provide good performance
study presented supplies complementary contribution able
useful adaptive load balancing obtained purely local information
framework general organizational theoretic model
study identified parameters adaptive process investigated
affect eciency adaptive load balancing part study supplies
useful guidelines systems designer may force agents work
common selection rule observations although somewhat related previous observations made contexts huberman hogg enable demonstrate
aspects purely local adaptive behavior non trivial model
disagreement selfish interest agents common
interest population sharp contrast previous work multi agent learning
shoham tennenholtz dynamic programming perspective
earlier work distributed systems bertsekas tsitsiklis moreover explore
interaction different agent types affects system eciency well


fiadaptive load balancing study multi agent learning

individual agent eciency related interpreted guidelines
designer may partial control system
synthesis observations teaches us adaptive load balancing
one adopts reinforcement learning perspective agents rely local
information activity additional step performed attempts bridge
gap local view previous work adaptive load balancing communicating
agents whose decisions may controlled learning automata means
therefore rule possibility communication current status resources
joint decision making enable limited sharing previous history
limited communication may help even deteriorate system eciency
leaves us major gap previous work communication among agents
basic tool adaptive load balancing work much left done attempting
bridge gap see major challenge

related work
section mentioned related work field distributed computer systems
mirchandaney stankovic billard pasquale glockner pasquale
mirchandaney et al zhou eager et al typical example work
mirchandaney stankovic work learning automata
used order decide action taken however suggested heavily
rely communication information sharing among agents sharp contrast
work addition differences type model use
model presented mentioned work work distributed computer
systems
applications learning load balancing given mehra
mehra wah however work well agents sites
authors terminology ability communicate exchange workload values
even though values subject uncertainty due delays addition differently
work learning activity done line particular learning phase
whole system dedicated acquisition workload indices load indices
used running phase threshold values job migration different sites
spite differences similarities work abovementioned work one important similarity use learning procedures
difference classical work parallel distributed computation bertsekas
tsitsiklis applies numerical iterative methods solution
network ow parallel computing similarities related study
division society groups somewhat resembles work group formation
billard pasquale distributed computer systems information sharing
allow section similar limited communication discussed tan
classification load balancing given ferrari work falls
category load independent non preemptive pure load balancing
investigate seen sender initiated although case sender
agent overloaded resource


fischaerf shoham tennenholtz

one may wonder work differs work adaptive load balancing
operations e g queuing theory bonomi doshi kaufmann lee
kumar indeed commonalities work individual
decisions made locally information obtained dynamically runtime
cases systems constructed suciently complex interesting
tend obtained experimentally however careful look relevant
literature reveals essential difference perspective topic
reinforcement learning perspective permits free communication within system
thus significant element uncertainty framework particular issue
exploration versus exploitation lies heart completely
absent work
work adaptive load balancing related topics carried
artificial intelligence community see e g kosoresow gmytrasiewicz durfee
wehe wellman work however tends form
communication among agents whereas case load balancing obtained purely
learning activity
article related previous work co learning shoham tennenholtz
framework co learning framework multi agent learning
differs frameworks discussed multi agent reinforcement learning narendra
thathachar tan yanco stein sen sekaran hale due
fact considers case stochastic interactions among subsets agents
purely local feedback revealed agents interactions
framework co learning similar respects number dynamic frameworks
economics kandori mailath rob physics kinderman snell computational ecologies huberman hogg biology altenberg feldman
study adaptive load balancing treated study co learning
relevant work literature field learning automata see narendra thathachar fact agent setting seen learning automaton therefore one may hope theoretical interconnected automata
n player games see e g el fattah abdel fattah narendra wheeler jr
wheeler jr narendra could imported framework unfortunately
due stochastic nature job submissions e agent interactions real valued
instead binary feedback fit completely theoretical
framework learning automata hence concerning optimality convergence expediency learning rules linear reward penalty linear reward inaction
easily adapted setting fact use stochastic model
interaction among agents makes work closely related mentioned work
co learning nevertheless work largely uenced learning automata theory
resource selection rules closely resemble reinforcement schemes learning automata
last least work related work applying organization theory management techniques field distributed ai fox malone durfee lesser
corkill model closely related decision making management
organization theory e g malone applies reinforcement learning perspective context makes work related psychological decision making
arthur


fiadaptive load balancing study multi agent learning

summary

work applies idea multi agent reinforcement learning load
balancing loosely coupled multi agent system agents need adapt one another well changing environment demonstrated adaptive behavior
useful ecient load balancing context identified pair parameters
affect eciency non trivial fashion parameter holding parameter
fixed gives rise certain tradeoff two parameters interplay non trivial
illuminating way exposed illuminating regarding heterogeneous
populations group parasitic less adaptive agents gain exibility agents addition showed naive use communication may
improve might even deteriorate system eciency

acknowledgments

thank anonymous reviewers steve minton whose stimulating comments helped
us improving earlier version

references

abdel fattah stochastic automata modeling certain collective
behavior ieee transactions systems man cybernetics
altenberg l feldman w selection generalized transmission
evolution modifier genes reduction principle genetics
arthur w inductive reasoning bounded rationality bar tech rep
working santa fe institute appeared american economic
review
axelrod r evolution cooperation york basic books
bertsekas tsitsiklis j parallel distributed computation numerical
methods prentice hall
billard e pasquale j effects delayed communication dynamic group
formation ieee transactions systems man cybernetics
blackburn j acquisition skill analysis learning curves ihrb report

bond h gasser l readings distributed artificial intelligence ablex
publishing corporation
bonomi f doshi b kaufmann j lee kumar case study
adaptive load balancing queuing systems
durfee e h lesser v r corkill coherent cooperation among communicating solvers ieee transactions computers


fischaerf shoham tennenholtz

eager lazowska e zahorjan j adaptive load sharing homogeneous
distributed systems ieee transactions software engineering
el fattah stochastic automata modeling certain collective
behavior ieee transactions systems man cybernetics
ferrari study load indices load balancing schemes tech rep ucb csd
computer science division eecs univ california berkeley
ferrari serazzi g zeigner measurement tuning computer
systems prentice hall
fox organizational view distributed systems ieee transactions
systems man cybernetics
glockner pasquale j coadaptive behavior simple distributed job
scheduling system ieee transactions systems man cybernetics

gmytrasiewicz p durfee e wehe utility communication coordinating intelligent agents proc th nat conf artificial intelligence
aaai pp
huberman b hogg behavior computational ecologies huberman b ed ecology computation elsevier science
kaelbling l learning embedded systems mit press
kandori mailath g rob r learning mutation long equilibria
games mimeo university pennsylvania
kinderman r snell l markov random fields applications
american mathematical society
kosoresow p fast first cut protocol agent coordination proc
th nat conf artificial intelligence aaai pp
kraus wilkenfeld j function time cooperative negotiations
proc th nat conf artificial intelligence aaai pp
lesser v r retrospective view fa c distributed solving ieee
transactions systems man cybernetics
malone w modeling coordination organizations markets management
science
mehra p automated learning load balancing strategies distributed
computer system ph thesis department electrical computer engineering
university illinois urbana champaign


fiadaptive load balancing study multi agent learning

mehra p wah b w population learning load balancing policies
distributed computer system proceedings computing aerospace conference
aiaa pp
mirchandaney r stankovic j stochastic learning automata job
scheduling distributed processing systems journal parallel distributed
computing
mirchandaney r towsley stankovic j analysis effects delays
load sharing ieee transactions computers
narendra k thathachar l learning automata introduction
prentice hall
narendra k wheeler jr r n player sequential stochastic game
identical payoffs ieee transactions systems man cybernetics

pulidas towsley stankovic j imbedding gradient estimators load balancing proceedings th international conference distributed
computer systems ieee pp
sen sekaran hale j learning coordinate without sharing information
proc th nat conf artificial intelligence aaai
shoham tennenholtz emergent conventions multi agent systems initial experimental observations proc rd int conf principles
knowledge representation reasoning kr pp
shoham tennenholtz co learning evolution social activity
tech rep stan cs tr dept computer science stanford university
sutton r special issue reinforcement learning machine learning
tan multi agent reinforcement learning independent vs cooperative agents
proceedings th international conference machine learning
thronkide e l animal intelligence experimental study associative
processes animals psychological monographs
watkins c learning delayed rewards ph thesis cambridge university
wellman p market oriented programming environment application
distributed multicommodity ow journal artificial intelligence

wheeler jr r narendra k learning decentralized decision
making automatica


fischaerf shoham tennenholtz

yanco h stein l adaptive communication protocol cooperating mobile robots animals animats proceedings second international
conference simulation adaptive behavior pp
zhou trace driven simulation study dynamic load balancing ieee transactions software engineering
zlotkin g rosenschein j domain theory task oriented negotiation
proc th int joint conf artificial intelligence ijcai pp




