journal artificial intelligence

submitted published

framing image description ranking task
data evaluation metrics
micah hodosh
peter young
julia hockenmaier

mhodosh illinois edu
pyoung illinois edu
juliahmr illinois edu

department computer science
university illinois
urbana il usa

abstract
ability associate images natural language sentences describe
depicted hallmark image understanding prerequisite applications sentence image search analogy image search propose
frame sentence image annotation task ranking given pool captions
introduce benchmark collection sentence image description search
consisting images paired five different captions provide
clear descriptions salient entities events introduce number systems
perform quite well task even though features
obtained minimal supervision clearly indicate importance
training multiple captions per image capturing syntactic word order
semantic features captions perform depth comparison human
automatic evaluation metrics task propose strategies collecting human
judgments cheaply large scale allowing us augment collection
additional relevance judgments captions describe image analysis shows
metrics consider ranked list query image sentence
significantly robust metrics single response per query moreover study suggests evaluation ranking image description systems
may fully automated

introduction
ability automatically describe entities events scenes depicted image
possibly ambitious test image understanding advances task
significant practical implications since billions images web
personal photo collections ability efficiently access wealth information
contain hampered limitations standard image search engines must rely
text appears near image datta joshi li wang popescu tsikrika
kludas lot work multi label classification
associating images individual words tags see e g blei jordan barnard
duygulu forsyth freitas blei jordan feng lapata deschacht moens
lavrenko manmatha jeon makadia pavlovic kumar weston
bengio usunier much harder automatically associating images
complete sentences describe recently begun attract attention

ai access foundation rights reserved

fihodosh young hockenmaier

related work
although approaches framed sentence image description task mapping images sentences written people farhadi hejrati sadeghi young rashtchian
hockenmaier forsyth ordonez kulkarni berg
area focused task automatically generating novel captions kulkarni premraj
dhar li choi berg berg yang teo daume iii aloimonos li kulkarni berg berg choi mitchell dodge goyal yamaguchi stratos han mensch
berg berg daume iii kuznetsova ordonez berg berg choi gupta
verma jawahar argue framing image description natural language generation introduces number linguistic difficulties detract
attention underlying image understanding wish address since
sentence image description retrieval system requires ability associate images
captions describe depicted argue important evaluate
mapping images sentences independently generation aspect caption generation ignored image search task arguably
much greater practical importance
systems cited evaluated data set group released
earlier work rashtchian young hodosh hockenmaier sbu captioned photo dataset ordonez et al data set consists images
pascal voc object recognition challenge annotated five descriptive captions purposely collected task sbu data set consists one
million images captions harvested flickr gupta et al system
use grubinger clough mller deselaerss iapr tc data set consists
images paired longer descriptions
although details differ rely existing detectors define map images
explicit meaning representation language consisting fixed number scenes objects
stuff attributes spatial relations farhadi et al kulkarni et al
li et al yang et al ordonez et al mitchell et al
unclear well detector approaches generalize evaluated
pascal voc data set farhadi et al kulkarni et al li et al
yang et al mitchell et al rely detectors may trained
images contained corpus kuznetsova et al select test set images
sbu data set detectors work well moreover among systems
evaluated pascal voc data set kulkarni et al li et al
li et al mitchell et al may directly comparable since different
groups report different evaluation metrics use different parts data set
test training data evaluation generation systems generally well known
difficult see e g dale white reiter belz typically requires expensive
human judgments consider quality content selection
described surface realization fluency generated text syntactic
pragmatic issues confound purely semantic question whether image correctly
described caption



fiframing image description ranking task


focus task associating images sentences drawn large
predefined pool image descriptions descriptions generated automatically
harvested web feng lapata ordonez et al written
people asked describe argue evaluating ability select
rank rather generate appropriate captions image direct test
fundamental semantic question well associate images sentences
describe well framing image description ranking task number
additional advantages first allows us handle sentence image annotation
search unified framework allowing us evaluate whether advances one task
carry second framing image description ranking greatly
simplifies evaluation establishing parallel description retrieval
use metrics evaluate tasks moreover rank
original caption easily determined automatically leads metrics correlate
highly systems rankings obtained human judgments even underestimate
actual performance standard automatic metrics bleu papineni
roukos ward zhu rouge lin used evaluate
caption generation systems poor correlation human judgments leading us
believe evaluation caption generation system automated
perform large scale human evaluation since sentences data set image
descriptions written people need collect purely semantic judgments whether
describe images system associated since judgments
independent task use evaluate image description retrieval
systems since collect judgments image caption pairs publicly available
data set establish common benchmark enables direct comparison different
systems believe another advantage caption generation task since
many possible ways describe image generation systems liberty
less specific describe image makes direct comparison
independently obtained judgments quality two different systems difficult
since one system may aiming solve much harder task implies
unless system outputs common benchmark collection images made publicly
available cannot shared objective evaluation would allow community
measure progress difficult since caption generation systems
need able determine well caption describes image data set could
potentially used evaluate semantic component
contributions outline
section discuss need data set image description introduce
high quality data set image description enable community compare
different systems benchmark pascal voc data set
images rashtchian et al used number image description systems
farhadi et al kulkarni et al li et al yang et al mitchell et al
gupta et al number shortcomings limit usefulness first
domain relatively limited captions relatively simple second since


fihodosh young hockenmaier

images drawn data used pascal voc object classes challenge
difficult guarantee fair evaluation description systems rely shelf
object detectors e g felzenszwalb mcallester ramanan data set since
may possible identify images detectors trained
experiments therefore larger diverse data set
images unlike data sets pair images sentences merely related
image feng lapata ordonez et al image data sets
paired five different captions purposely written describe image
section describe image description systems image description
novel task remains largely unknown kind model kind
visual linguistic features requires instead unidirectional mapping images
sentences common current caption generation systems map images
sentences space allows us apply system image search
retrieving images closest query sentence image description
annotating images sentences closest technique use
kernel canonical correlation analysis kcca bach jordan already
successfully used associate images hardoon szedmak shawe taylor hwang
grauman hardoon saunders szedmak shawe taylor image regions
socher li individual words sets tags canonical correlation
analysis hotelling used associate images related wikipedia
articles ten different categories rasiwasia pereira coviello doyle lanckriet levy
vasconcelos however performance techniques much
stringent task associating images sentences describe depicted
evaluated compare number text kernels capture different linguistic
features experimental discussed section demonstrate importance
robust textual representations consider semantic similarity words hence take
linguistic diversity different captions associated image account
visual features relatively simple number image description systems farhadi et al
kulkarni et al li et al yang et al kuznetsova et al largely
rely trained detectors e g obtain explicit intermediate meaning representation
depicted objects scenes events would ultimately require separate
detectors hence labeled training data term phrase chosen meaning
representation language image features capture low level
perceptual properties fact work surprisingly well larger data set
domain detectors available
section consider question evaluation use number different metrics
compare systems since focus learning appropriate mapping
images captions follow standard machine learning practice evaluate
ability function generalize unseen examples hence separate pool
captions images used testing used train systems first consider
metrics quality single image caption pair compare automatically computed
scores detailed human judgments examine metrics evaluate ranked
lists returned systems analysis reveals current level performance
differences may become apparent single caption per image
considered commonly done caption generation systems even two


fiframing image description ranking task

equally likely fail return suitable caption first still prefer
one likely rank good captions higher since arguably
provides better approximation semantic space images near captions
describe well since test pool contains single gold item query
first consider metrics rank recall gold item
simpler binary judgments image descriptions good approximations
fine grained human judgments collected large scale via crowdsourcing
augment test pool data set relevance judgments hope
add usefulness community resource benchmark judgments
actual performance systems higher recall gold item
indicates however comparison system rankings obtained via different metrics
suggests differences rank recall gold item correlate highly
difference performance according binary relevance judgments

data set image description
used crowdsourcing collect descriptive captions large number images
people animals mostly dogs describing data set annotation methodology discuss kind captions useful image description motivate
need create data sets task
mean image description
since automatic image description relatively novel task worth reflecting
means describe images wish say image fact
substantial body work image description related image libraries jaimes jaimes
chang shatford useful revisit purpose argue
three different kinds image descriptions commonly distinguished one
type called conceptual descriptions relevance image understanding aim achieve automatic captioning conceptual image descriptions identify
depicted image may abstract e g concerning mood
picture may convey image understanding mostly interested concrete descriptions
depicted scene entities attributes relations well events
participate focus actually image conceptual descriptions
differ called non visual descriptions provide additional background information cannot obtained image alone e g situation time location
image taken perceptual descriptions capture low level visual properties
images e g whether photograph drawing colors shapes dominate little interest us unless link properties explicitly depicted
entities among concrete conceptual descriptions distinction drawn specific descriptions may identify people locations names
generic descriptions may e g describe person woman skateboarder
scene city street room exception iconic entities
recognized e g well known public figures landmark locations eiffel
tower argue image understanding focus information captured



fihodosh young hockenmaier

bbc captions
feng lapata

consumption
soared
real price
drink fallen

amd destroys
central vision

sbu captioned photo dataset flickr
ordonez et al

downers grove
chew couch
train station condo pee kitchen
building
mama
background
way ag store
chicago

iapr tc data set
grubinger et al

blue white airplane standing grey airport
man red cones standing front two
red dressed hostesses two passengers directly
stairs front airplane brown landscape
high dark brown mountains snow covered
summits light grey sky background

figure data sets images captions
generic descriptions leaves question obtain data set images paired
suitable descriptions train automatic description systems
need data sets
dearth images associated text available online argue
text suitable task work notably natural language
processing community focused images news articles feng lapata
however images often used illustrate stories little direct connection
text figure left furthermore even captions describe depicted event
tend focus information cannot obtained image similarly
people provide captions images upload websites flickr figure
center often describe situation images taken rather
actually depicted image captions often provide non visual overly
specific information e g naming people appearing image location
image taken simple reason people typically provide kinds
generic conceptual descriptions use purposes gricean maxims
relevance quantity grice entail image captions written people
usually provide precisely kind information could obtained image
thus tend bear tenuous relation actually depicted
state succinctly captions usually written seen along images
accompany users may wish bore readers obvious
ordonez et al harvested images captions flickr create
sbu captioned photo dataset discard vast majority images
captions actually descriptive analysis random sample
images final data set revealed majority captions describe
information cannot obtained image e g naming people
locations appearing image substantial fraction describe small
detail image otherwise commentary image examples
issues shown figure center makes data set less useful kind
image understanding interested unless refer specific entities one may
actually wish identify e g celebrities famous landmarks appear image
proper nouns little help learning visual properties entity types unless one


fiframing image description ranking task

data set flickr images crowd sourced captions
man tricks bicycle ramps front crowd
man bike executes jump part competition crowd watches
man rides yellow bike ramp others watch
bike rider jumping obstacles
bmx biker jumps ramp
group people sit table front large building
people drinking walking front brick building
people enjoying drinks table outside large brick building
two people seated table drinks
two people sitting outdoor cafe front old building

figure data set images paired generic conceptual descriptions
infer kind entity refer iapr tc data set grubinger et al
consists photographs potentially useful purposes since
contains descriptions recognized image without prior information
extra knowledge however descriptions consist often multiple sentences
sentence fragments tendency lengthy average length words
overly detailed instead focusing salient aspects photograph example
photo airplane figure right two hostesses barely visible
nevertheless described detail
data sets
since kinds captions normally provided images describe images
collected data sets images captions captions
obtained crowdsourcing service provided amazon mechanical turk
annotate image five descriptive captions asking people describe
people objects scenes activities shown picture without giving
information context picture taken able
obtain conceptual descriptions focus information obtained
image alone annotation process quality control described detail
rashtchian et al annotated two different data sets manner
pascal voc data set
first data set produced relatively small consists images randomly selected training validation set pascal object recognition
challenge everingham gool williams winn zisserman used
large number image description systems farhadi et al kulkarni et al li
et al yang et al mitchell et al gupta et al since almost
systems exception gupta et al rely detectors trained
data set ordonez et al differs significantly content collection
focuses images eventualities e people animals something majority ordonez et
al images depict people animals e g still lifes landscape shots



fihodosh young hockenmaier

images data set felzenszwalb et al unclear well
approaches would generalize domains labeled data train detectors
available captions pascal data set relatively simple example
since data set contains many pictures depict focus people something captions contain verb additional captions
contain common static verbs sit stand wear look
flickr k data set
work reported therefore collected larger diverse data set
consisting images flickr com website unlike static pascal
images images data set focus people animals mainly dogs performing
action examples data set shown figure images chosen
six different flickr groups tend contain well known people locations
manually selected depict variety scenes situations order avoid
ungrammatical captions allowed workers united states passed
brief spelling grammar test devised annotate images
interested conceptual descriptions annotators asked write sentences describe
depicted scenes situations events entities people animals objects
collected multiple captions image considerable degree variance
way many images described consequence captions
images often direct paraphrases entity event situation
described multiple ways man vs bike rider tricks vs jumping
everybody mentions bike rider everybody mentions crowd ramp
dynamic nature images reflected described
captions data set average length words compared words
pascal data set pascal captions contain verb
sit stand wear look captions flickr k set contain
verb additional contain common verbs data sets flickr
training test development splits human relevance judgments used evaluation
test items section publicly available online appendix contains
instructions workers including qualification test pass
allowed complete tasks

systems sentence image description
since image description requires ability associate images sentences image
description systems viewed terms affinity function f measures
degree association images sentences evaluate ability compute
affinity functions measuring performance two tasks depend directly
given candidate pool sentences scand candidate pool images icand sentencebased image retrieval aims image icand maximizes f sq query
sentence sq scand conversely image annotation aims sentence scand
groups called strangers wild child kids action dogs action read rules
outdoor activities action photography flickr social two people photo
http nlp cs illinois edu hockenmaiergroup data html



fiframing image description ranking task

maximizes f iq query image iq icand cases f course
maximized image sentence pairs sentence describes image well
image search
image annotation

arg maxiicand f sq




arg maxsscand f iq

formulation completely general although evaluation purposes define
scand set captions originally written images icand
case scand could example defined implicitly via caption generation
system order evaluate well f generalizes unseen examples evaluate
system test pools itest stest drawn domain disjoint
training data dtrain itrain strain development data ddev idev sdev
challenge defining f lies fact images sentences drawn two
different spaces present two different kinds image description
systems one nearest neighbor search nn uses technique called
kernel canonical correlation analysis kcca bach jordan hardoon et al
rely set known image sentence pairs dtrain hi si
nearest neighbor search image description
nearest neighbor systems use unimodal text image similarity functions directly
first image sentence pair training corpus dtrain contains closest
item query score items space similarity
item pair
image retrieval fnn sq inn

hinn snn arg max fs sq st
hit st idtrain

image annotation fnn iq fs snn hinn snn arg max iq
hit st idtrain

despite simplicity nearest neighbor systems non trivial baselines
task annotating images tags keywords methods annotate unseen images
tags nearest neighbors among training images known achieve competitive performance makadia et al similar methods recently proposed
image description ordonez et al since task address allow
us return items training data requires us rerank pool unseen captions
images nearest neighbor search requires two similarity functions nearestneighbor systems use image representation kcca systems described
section main nearest neighbor system nn nn idf
f treats five captions
associated training image single document reweights token
inverse document frequency idf w defines similarity two sentences
f measure harmonic mean precision recall computed idf reweighted
bag words representation dtrain w subset training images whose captions
word w appears least inverse document frequency idf w defined
dtrain
w log dtrain
w idf reweighting potentially helpful task since words
describe fewer images may particularly discriminative captions


fihodosh young hockenmaier

appendix provide nn systems use text representation
two kcca systems
kernel canonical correlation analysis image description
systems present technique called kernel canonical correlation
analysis bach jordan hardoon et al first provide brief introduction
explain apply task
kernel canonical correlation analysis kcca
kcca extension canonical correlation analysis hotelling takes
training data consisting pairs corresponding items hxi yi drawn two different
feature spaces xi x yi finds maximally correlated linear projections x
sets items newly induced common space z since linear projections
raw features may capture patterns necessary explain pairing
data kcca implicitly maps original items higher order spaces x via
kernel functions kx hx xi x xj compute dot product two data points
xi xj higher dimensional space x without requiring explicit computation
mapping x kcca operates two resulting kernel matrices kx j
hx xi x xj ky j hy yi yj evaluate kernel functions
pairwise combinations items training data returns two sets projection weights
maximize correlation two projected kernel matrices
arg max q


kx ky
k x kx k ky



cast generalized eigenproblem kx ky ky kx
solved partial gram schmidt orthogonalization hardoon et al socher li
regularization parameter penalizes size possible solutions used
avoid overfitting arises matrices invertible
one disadvantage kcca requires two kernel matrices training
data kept memory training becomes prohibitive large data
sets cause since training data consists
items see section
kcca associate images sentences
kcca successfully used associate images hardoon et al hwang
grauman hardoon et al image regions socher li individual
words sets tags case two original spaces x correspond
images sentences describe images first mapped vectors ki
whose elements ki ki evaluate image kernel function ki th
image dtrain similarly sentences mapped vectors ks evaluate
sentence kernel function ks sentences dtrain learned projection weights
map ki ks induced space z expect images
appear near sentences describe well kcca image annotation


fiframing image description ranking task

search system therefore define f cosine similarity sim points space
fkcca sim ki ks



describe image text kernels used kcca systems
image kernels
contrast much work done image description assumes existence
large number preexisting detectors image representations used
basic rely three different kinds low level pixel perceptual
features capture color texture varma zisserman shape information
form sift descriptors lowe vedaldi fulkerson believe
establishes important baseline leave question complex image
representations affect performance future work use two different kinds kernels
histogram kernel k histo represents image single histogram feature
values computes similarity two images intersection histograms
pyramid kernel k py lazebnik schmid ponce represents image
pyramid nested regions computes similarity two images terms
intersection histograms corresponding regions cases compute separate
kernel three types image features average
histogram kernel k histo
image xi represented histogram hi discrete valued features hi v
fraction pixels xi value v similarity two images xi xj defined
intersection histograms e percentage pixels mapped
onto pixel feature value image
k xi xj

v
x

min hi v hj v



v

combine three kernels different kinds visual features kc captures color
represented three cielab coordinates kt captures texture represented descriptors capture edge information different orientations centered pixel varma
zisserman ks sift descriptors capture edge shape information manner invariant changes rotation illumination
shown distinct across possible objects image lowe vedaldi fulkerson
use color words texture words sift words obtained unsupervised fashion k means clustering points images pascal
data set everingham et al final histogram kernel k histo average
responses three kernels kchisto kthisto kshisto taken pth power

p
x
k histo xi xj
kfhisto xi xj


f c



fihodosh young hockenmaier

pyramid kernel k py
spatial pyramid kernel lazebnik et al generalization histogram kernel
captures similarities global local level image xi
represented multiple levels scale l l level partitions
image smaller smaller grid cl l l cells c c c
cell c represented histogram hic similarity images xi xj level l
iijl turn defined sum histogram similarities corresponding cells
l cl level
iijl



cl x
v
x

min hic v hjc v



c l v

although similarities level l subsume fine grained level l iijl
iijl similarities hold fine grained level deemed important since
indicate greater local similarity pyramid kernel therefore proceeds
fine grained l l coarsest whole image scale l weights

similarities first encountered level l iijl iijl


k

py

xi xj

iijl



l
x
l


l iijl
ij



l



x

il
l ij
ij
l

compute three separate pyramid kernels kcpy ktpy kspy
color texture sift features described combine single pyramid
kernel k py equation
basic text kernels
examine three different basic text kernels bag words bow kernel hwang
graumans tagrank kernel truncated string kernel tri
bag words kernel bow
since bag words representations successfully used tasks involving text
images e g grangier bengio hardoon et al include basic bag
words kernel ignores word order represents caption simply vector
word frequencies bow kernel function defined cosine similarity
corresponding bag words vectors merge five captions training item
single document bow reduce training item single arbitrarily chosen
caption bow words frequency reweighted idf score
dtrain
nearest neighbor idf weight word w defined w log dtrain
w
dtrain w subset training images whose captions word w appears least



fiframing image description ranking task

found square root w bow
idf score w bow idf



idf

give better standard

tag rank kernel tagrank
hwang grauman apply kcca keyword image annotation retrieval
focus data set image paired list tags ranked importance propose kernel kind data called tag rank kernel
tagrank variant bag words kernel aims capture relative importance tags reweighting according position list although hwang
grauman evaluate ability system associate images entire
sentences consider another data set lists tags correspond
words descriptive captions argue linear order words captions
reflects relative importance corresponding objects image words
appear beginning sentence describe salient aspects image
tagrank kernel sentence represented two vectors r
weight word absolute position first words sentence
assigned high weight absolute tag rank representation caption
mapped vector v v size vocabulary
depends absolute position pi wi wi occurs multiple times pi averaged
positions wi occur otherwise



log pi



r weight word depends current position compares distribution positions occupies training data intuition behind relative rank
representation words higher weight occur earlier sentence usual caption mapped vector r r r v relative
tag ranks wi appear r otherwise wi relative tag rank
r indicates percent occurrences training data appear position pi
defining
p nik number times word wi appears position k training data
ni k nik total frequency wi training data
ppi
r

k nik



ni

final kernel kt given average two kernels computed r
normalization terms





v
v

x ri k rj k
x ai k aj k
kt xi xj
exp
exp



ri k rj k

ai k aj k
k

k

since image training data associated multiple independently generated captions evaluate kernel separately sentence pair average
response instead treating multiple sentences single document


fihodosh young hockenmaier

tagrank kernel relatively sensitive overall sentence length especially cases
subject preceded multiple adjectives modifiers large brown
dog vs dog english absolute tag rank generally assign high weights
subjects sentences lower weight verbs even lower weight objects scene
descriptions tend follow main verb relative tag rank may downweight
verbs objects scene descriptions much long used similar
positions sentence
trigram kernel tri
since bag words representations ignore words appear close
sentence lose important information image small child red hair playing
large brown dog white carpet looks quite different one small white dog
playing large red ball brown grass although descriptions share majority
words capture information define trigram kernel truncated variant
string kernels shawe taylor cristianini considers many single
words two captions share many short sequences pairs triples words
occur
word sequence w w wk ordered list words sentence sn contains
w w long words w appear order specified w
sentence large white dog runs catches red ball beach lemmatized
contains subject verb object triple dog catch ball subject verb location
triple dog run beach formally every substring j si sj starts si w
ends sj wk contains w considered match w ms w set
substrings match sequence w
ms w j w w wk si sj w si wk sj



w restricted individual words k string kernels identical standard
bow kernel
match strings pair substrings j j
match word sequence w standard string kernels k weight matches


factor ji j depends adjustable parameter respective
length matching substrings
k

x

x

x





ji j



w j ms w j ms w

order distinguish length matching subsequence l w
length gaps j j replace two parameters g reformulate

k

x

x

x





l w
l w
ji j

g



w j ms w j ms w

found gap score g means gaps penalized
match score perform best task


fiframing image description ranking task

although string kernels generally defined sequences arbitrary length k
found allowing longer sequences seem impact performance task
incurred significant computational cost intuitively word pairs triplets represent
linguistic information need capture beyond bow representation since
include head modifier dependencies large dog vs small dog subject verb object
dependencies child play dog vs dog play ball therefore consider sequences
length k w restricted sequences length k ms w ms w
yields following trigram kernel tri
ktri

x

ms w ms w l w




w k

deal differences sentence length normalize kernel response
two examples geometric mean two example responses
since trigram kernel captures sequences merely coincidental
large white red may seem advantageous use richer syntactic representations
dependency tree kernels moschitti pighin basili consider word
tuples correspond syntactic dependencies however kernels significantly
expensive compute initial experiments indicated may perform
well trigram kernel believe due fact image captions
contain little syntactic variation hence surface word order may sufficient
differentiate e g agent action whose mention subject
sentence participants entities whose mentions appear verb
hand many image captions contain lot syntactic ambiguity e g
multiple prepositional phrases vocabulary distinct standard
parsers trained may able benefit richer
representation simply able recover sufficient accuracy
order capture
relative importance words reweight sequences

idf idf weight theirqwords
w defined idf weight
j
sequence w wi wj w
idf weighted trigram kernel ktriidf
k wk
tri



idf

therefore

ktriidf

x

w ms w ms w l w




w k

extending trigram kernel lexical similarities
one obvious shortcoming basic text kernels require exact matches
words cannot account fact situation event entity
described variety ways see figure examples one way capturing
linguistic diversity lexical similarities allow us define partial matches
words semantic relatedness lexical similarity found success
tasks e g semantic role labeling croce moschitti basili
fully exploited image description ordonez et al define explicit equivalence classes
synonyms hyponyms increase natural language vocabulary corresponding
object detectors e g word dalmatian may trigger dog detector


fihodosh young hockenmaier

change underlying pre trained detectors ignoring potential
variation appearance e g different breeds dog similarly yang et al
generative model produce variety words type detected object scene
given object scene label word choice independent visual features
therefore investigate effect incorporating different kinds lexical similarities
trigram kernel allow us capture partial matches words
explore effect incorporating lexical similarities tag rank kernel since
unclear affect computation ranks within sentence
string kernels lexical similarities
since standard lexical similarities sims w wi necessarily yield valid kernel functions
follow bloehdorn basili cammisa moschitti use similarities
map word w vectors w
n dimensional space defined fixed vocabulary
size n vector component w
corresponds similarity w wi defined



w
sims w wi

define corresponding word kernel function w w captures partial
match words w w according cosine angle w
w

w w cos
ws w




may defined subset vocabulary similarity words outside
vocabulary defined identify function standard string kernel
similarity sequences w w length l defined product word
kernels corresponding pairs sequence elements wi wi
w w

l


wi wi





w w w w l w l w set sequences non zero
match w string kernel ks similarity
ks

x

x

ms w ms w l w
w w




w w w


idf

obtain
idf weighted version kernel ks inner term multiplied w w
x x p
ks
w w ms w ms w l w
w w


w w w

experiments use trigram variants kernels restrict w
sequences length k
consider three different kinds lexical similarities wordnet lin similarity
lin lin distributional similarity metric novel alignment


fiframing image description ranking task

similarity metric takes advantage fact image associated
five independently generated captions metrics computed training corpus
distributional similarity computed british national corpus bnc consortium
corpora lemmatized stop words removed similarities
computed since almost pair words non zero similarity word kernel
matrices dense since similarities close zero
little effect resulting kernel therefore zero entries smaller
alignment kernel less distributional kernel dc
lin similarity kernel lin
lins similarity relies hypernym hyponym relations wordnet fellbaum
well corpus statistics wordnet directed graph nodes synsets
represent word senses edges indicate relations parent sense e g dog
hypernym children e g poodle dachshund kernels lins similarity
found perform well tasks text categorization bloehdorn et al
exception farhadi et al incorporate lins similarity
model evaluate benefit obtain wordnets hypernym hyponym
relations used superficially associating images text weston et al
ordonez et al gupta et al lin similarity two word senses si sj
defined
log p lcs si sj
simlin si sj

log p si log p sj
lcs refers lowest common subsumer wordnet e
specific synset ancestor hypernym p probability
randomly drawn word instance synset descendants hyponyms
use training data estimate p follow bloehdorn et al assigning
word w frequent first noun sense sw wordnet hence represent
word w wordnet sense vector w
lin lin similarities hypernyms h sw
log f si

log f log f si
w
lin





si h
sw si
otherwise



distributional similarity dc
distributional similarity metrics observation words similar
tend appear similar contexts jurafsky martin components
w
dc non negative pointwise mutual information scores pmi w wi computed
corpus c


pc w wi

w
dc max log
pc w pc wi
pc w probability random sentence c contains w pc w wi
probability random sentence c contains w wi compute two variants


fihodosh young hockenmaier

metric dic computed image captions training corpus
defined cooccurrences words appear least times corpus
dbnc uses british national corpus bnc consortium defined
words appear least times corpora considers pmi scores
words appear least times bnc
alignment similarity
propose novel alignment similarity metric takes advantage
fact image associated five independently generated captions
specifically designed capture likely two words describe event
entity data set borrow concept alignment machine translation
brown pietra pietra mercer instead aligning words sentences two
different languages align pairs captions describe image
similarity metric better coverage data set wordnet metrics
much specific distributional similarities capture broad topical relatedness
rather semantic equivalence instead aligning complete captions found
beneficial align nouns verbs independently ignore parts
speech create two versions training corpus one consisting nouns
caption another one consisting verbs caption
use giza och ney train ibm alignment brown et al
pairs noun verb captions image obtain two sets translation
probabilities one nouns pn w one verbs pv w finally combine
noun verb translation probabilities sum weighted relative frequency
word w tagged noun pn w verb pv w training corpus
ith entry wa therefore
w
pn wi w pn w pv wi w pv w



define noun verb vocabulary follows words appear least times
noun tagged noun least occurrences considered
nouns since verbs polysemous nouns leading broader translation
probabilities often mistagged nouns domain include words
verbs tagged verbs least times least occurrences
noun verb lemmas including nouns verbs
use opennlp pos tagger lemmatization
comparing similarity metrics figure
figure illustrates different similarity metrics words rider swim
examples distributional similarities high words topically related
e g swim pool alignment similarity tends high words used
describe entity usually synonyms hyper hyponyms activity swim
paddle distributional similarities obtained image captions
specific domain bnc similarities much broader help overcome data
sparsity although bnc relatively low coverage kinds sports occur
data set lin similarity associates swim hypernyms sport activity


fiframing image description ranking task

comparing similarity metrics five words similar rider swim
alignment
strain
wi


wi

rider

biker
bicyclist
cyclist
bmx
bicycler







bike
dirt
motocross
motorcycle
ride







ride
horse
race
bike
jockey

swim

retrieve
paddle
dive
come
wade







pool
trunk
water
dive
goggles







fish
water
sea
pool
beach

corpus
w

distributional
strain
bnc
dic wi
dbnc

lin
strain
wi

lin







traveler
cyclist
bicyclist
horseman
jockey













bathe
sport
football
activity
soccer







figure comparison lexical similarities noun rider verb swim
kinds sport football soccer makes least suitable similarity
task see section experimental since terms
considered similar purposes identifying different ways visually similar
events entities described
combining different similarities
combining different distributional alignment similarities allows us
capture different strengths method define averaged similarity
captures aspects distributional similarities computed corpora
dbnc w w dic w w


every distributional kernel w w define variant w w
incorporates alignment similarities taking maximum kernel
dbnc ic w w

w w max w w w w



evaluation procedures metrics image description
order evaluate scoring functions f image caption pairs need evaluate
ability associate previously unseen images captions analogy
caption generation systems first examine metrics aim measure quality
single image description pair section focus image annotation task
restrict attention first caption returned test item subset
systems collect graded human judgments small number native speakers
american english investigate whether expert judgments approximated
operation may preserve positive definiteness matrix required valid kernel
simply means effectively use plain cca representation



fihodosh young hockenmaier

automatically computed bleu papineni et al rouge lin hovy
scores simpler crowdsourced human judgments collected much
larger scale section consider approaches evaluation aim measure
quality ranked list image caption pairs returned system allow us
evaluate large number systems reasons space focus discussion
subset systems refer interested reader appendix b
complete since candidate pool contains one sentence image originally
associated query image sentence first compare systems rank recall
original item metrics computed automatically
considered lower bounds actual performance since image may associated
number captions describe well perhaps minor errors
crowdsourced human judgments mapped binary relevance judgments
correlate well fine grained expert judgments consider metrics
relevance judgments
experimental setup
describe data tasks systems evaluate experiments
data
since pascal data set contains total images perform
experiments exclusively flickr k set split images corpus see
section three disjoint sets training data dtrain hitrain strain consists
images associated five captions whereas test development data
dtest ddev consist images associated one arbitrarily chosen caption
captions preprocessed spellchecking linux spell normalizing compound words
e g shirt shirt tee shirt shirt stop word removal lemmatization
tasks
evaluate systems two tasks sentence image annotation description
sentence image search image search task return ranked list
images itest captions queries stest image annotation defined
analogously retrieval task return ranked list captions
stest test query images itest cases ranked lists
produced independently possible queries
systems
total different systems uses nearest neighbor
kcca paired different combination image text representations
purposes discussing different evaluation metrics focus small number
systems best performing nearest neighbor system nn nn idf
f
small number kcca systems different text kernels bow bow
use simple bag words kernel tagrank uses
hwang graumans

idf
kernel tri uses trigram kernel tri sem tri dbnc ic appendix b uses


fiframing image description ranking task



idf reweighted trigram kernel distributional alignment similarities
exception bow arbitrarily selected single caption
training image use five captions training images bow
merge single document cases follow moschitti
sum kernel responses cross product sentences normalization
systems including nn use pyramid kernel image representation
large scale evaluations section scores given appendix b
systems use hardoon et al kcca implementation allows us
vary regularization parameter vary n number dimensions largest
eigenvalues learned projection allowable values parameters
early exploratory experiments experiments reported sampled
possible values n chosen possible values range
two additional parameters fixed advance text
image kernel pair image kernels squared cubed text kernels
regularized multiplying values diagonal factor range
kernel two tasks image annotation search use
development set pick five settings n maximize recall original
item first five settings maximize recall among first five
five settings maximize recall among first ten yielding total
different pair kernels task query image annotation
caption search test set returns ranking test
items sentences images combine rankings use borda counts van erp
schomaker simple deterministic method rank aggregation n items
ranked system assigns score n r item ranks position r n
final rank item determined sum scores across systems
break ties items median ranks across
metrics quality individual image caption pairs
consider metrics consider quality ranked list section
first examine metrics measure quality individual image caption pairs
human evaluation graded expert judgments
expert scores decision well caption describes image ultimately requires
human judgment caption generation task number different evaluation schemes
proposed image description ordonez et al presented judges
caption produced model asked make forced choice random
image image caption produced kuznetsova et al asked judges
choose captions two given test image forced
choice tasks may give clear ranking cannot compared across different
experiments unless output system made publicly available one advantage
framing image description ranking task different systems compared
directly test pool forced choice evaluations directly measure
quality captions following common practice natural language generation yang
et al kulkarni et al evaluated captions graded scale relevance


fihodosh young hockenmaier

describes image
without errors
score

selected caption
describes image
minor errors
score

somewhat
related image
score

unrelated
image
score

girl wearing
yellow shirt
sunglasses smiles

man climbs
sheer wall
ice

miami basketball
player dribbles
arizona state player

group people
walking city street
warm weather

boy jumps
blue pool
water

dog grassy field
looking

basketball players
action

man riding motor
bike kicks dirt

dogs pulling
sled
sled race

two little girls
practice martial
arts

snowboarder
air snowy
mountain

child jumping
tennis court

boy blue life
jacket jumps
water

black dog
purple collar
running

figure rating scale fine grained expert judgments actual examples
returned best model tri sem
readability li et al added creativity score mitchell et al
compared systems whether captions describe main aspects images
introduce objects appropriate order semantically correct seemed
written human
since captions test pool produced people need evaluate
linguistic quality focus semantic correctness order obtain
fine grained assessment description quality asked three different judges score imagecaption pairs returned systems graded scale judges
adult native speakers american english mostly recruited among local graduate
student population contrast anonymous crowdsourcing evaluation described
section refer experts rating scale illustrated figure
actual examples returned score means caption describes
image perfectly without mistakes score caption almost describes
image minor mistakes allowed e g number entities whereas score
indicates caption describes aspects image could
used description score indicates caption bears relation
image online appendix contains annotation guidelines annotators
took average ten minutes per image caption pairs image caption pairs
judged independently three different annotators inter annotator agreement measured
krippendorffs high artstein poesio final score
image caption pair obtained averaging three individual scores since
time consuming evaluation judged highest ranked caption
test image annotation task focused subset described
gauge difficulty task data set include random
baseline since evaluate single caption image interested
percentage images suitable caption returned therefore
cumulative distribution test items scores thresholds ranging


fiframing image description ranking task

quality first caption image annotation
cumulative distribution expert scores x



bow

bow


tagrank
































tri sem











random
nn



table cumulative distribution expert judgments scale figure indicating
percentage image caption pairs judged given score scores
averaged three judges superscripts indicate statistically significant difference
tri sem p p p
threshold interpreted less strict mapping
fine grained scores binary relevance judgments order assess whether difference
given threshold reaches statistical significance use mcnemars
significance test paired non parametric test advocated evaluation
binary classifiers dietterich given output b
set items mcnemars test considers items bs output differ
discordant pairs output test null hypothesis outputs drawn
underlying population among discordant pairs compares proportion
items model successful model b proportion items
model b successful model tables superscripts indicate
whether difference model tri sem statistically significant p
p p
expert table first interpret expert scores binary relevance
judgments therefore cumulative distribution different thresholds
see clear differences random baseline nn kcca
thresholds differences nn random model well
kcca model nn highly significant p threshold random
baseline returns perfect caption images good caption assuming
threshold images best kcca model tri sem returns
perfect caption good caption images however
differences among kcca subtle may become apparent
lower thresholds significant difference bow tagrank
threshold significantly better bow p thresholds
tri sem outperforms differences bow
tagrank reach statistical significance threshold considered
suitable caption lowered p p p
p lack statistical significance partially explained
fact mcnemars test relatively low power percentage items
two successful low case higher thresholds



fihodosh young hockenmaier

sections significant difference
tri sem two image annotation extend analysis
beyond highest ranked caption shows evaluations
single caption returned per image may fail uncover significant differences
become apparent multiple considered may important
consider performance annotation retrieval image retrieval task
see tri sem significantly outperforms even first
considered table reveals another artefact mcnemars test since
absolute differences performance number discordant pairs
difference bow tri sem thresholds considered less
significant bow tri sem thresholds even though
bow scores lower bow table present systems average expert
scores use fishers randomization test determine statistical significance according
evaluation tri sem significantly better p
cases since average score tri sem difference reflected
higher thresholds cumulative distribution shown table
automatic evaluation bleu rouge
since human judgments expensive time consuming collect examine
well approximated bleu papineni et al rouge lin
two standard metrics machine translation summarization
bleu rouge scores bleu rouge scores computed automatically
number reference captions used evaluate number caption
generation systems kulkarni et al ordonez et al li et al kuznetsova
et al yang et al gupta et al although unclear well
correlate human judgments task
given caption image associated set reference captions ri
bleu score proposed image caption pair n gram precision
ri rouge corresponding n gram recall common
image description consider unigram scores possible imagecaption pairs test non zero bigram bleu score set
non zero bleu score ignore bleus brevity penalty since data set
relatively little variation sentence length would avoid penalizing short
generic captions include details otherwise correct hence cs w
number times word w occurs
p

bleu
rouge



min cs w maxrri cr w
p
ws cs w
p
p
min cs w cr w
rri
p wrp
rr
wr cr w
ws





reference candidate captions preprocessed first tokenize sentences
opennlp tools break hyphenated words stripping non alphanumeric
http opennlp apache org



fiframing image description ranking task

avg score first caption
image annotation
expert

bleu


rouge

bow
bow
tagrank



















tri sem







random
nn



table comparison averaged scores according point expert evaluation figure bleu rouge five test captions reference superscripts indicate
statistically significant difference tri sem p p p
hyphen characters converting words lower case following work lin
use stemmer porter remove stopwords compute rouge
scores compute bleu rouge score system average bleu
rouge scores items test set
use fishers randomization test fisher smucker allan carterette
assess statistical significance difference paired
sampling test evaluates null hypothesis
b produced underlying distribution sample scores
b assign test item randomly reassigned two p values
obtained comparing actual difference bs performance
fraction samples equal greater difference sample
reassignments entire test set
bleu rouge table table shows average bleu rouge scores
highest ranked caption pairs returned image annotation systems computed
reference pool consisting five original captions test image including
caption randomly selected part candidate pool scores
lead broad conclusions average expert scores metrics clear
differences p random baseline
well nn kcca none significant difference
bow tagrank tri sem outperforms kcca according
metrics expert evaluation rouge much larger difference
bow experts p rouge p tagrank experts p
rouge p bleu finds significant difference tagrank p
bow p indicates bleu may less well suited identify
subtle differences systems
agreement bleu rouge expert scores since difficult measure
directly well bleu rouge scores agree expert judgments consider
systems bleu score usually computed corpus level since dealing
unigram scores evaluate systems sentences corpus averaged sentence level
bleu scores systems report almost identical r corpus level bleu scores



fihodosh young hockenmaier

number different relevance thresholds type score b r e turn
binary relevance judgments allows us use cohens measure
agreement corresponding binarized scores since bleu rouge
require set reference captions test image compare four different ways
defining set reference captions detailed scores see tables appendix
since data set contains multiple descriptions image first use five
captions reference setting bleu reaches best agreement
e b e b however high bleu
scores generally obtained system proposes original caption rouge
much lower agreement expert scores obtained r vs
e e r e since data sets may
one caption per image evaluate reference corpus consists
single caption test pool case metrics reach highest
agreement expert threshold e bleu rouge
thresholds b r conclude neither bleu rouge
useful scenario since require high thresholds capture
often system returned reference caption
bleu rouge used evaluate caption generation systems cannot
assume generated caption identical one reference captions therefore
examine extent bleu rouge scores agree human judgments
candidate pool contains human generated captions disjoint reference captions first use reference corpus four captions per image excluding caption
use candidate pool case three metrics significantly lower agreement
human judgments candidate pool contains reference caption bleu
reaches b e rouge reaches
r e simulate case single caption per
image available evaluate reference corpus consisting one
four captions case agreement human judgments even lower bleu reaches
rouge reaches suggest bleu rouge
appropriate metrics pool candidate captions contain reference
captions lead us question usefulness evaluation caption generation
systems consistent findings reiter belz studied
bleu rouge scores evaluate natural language generation systems concluded
may useful metrics fluency poor measures content quality
metrics large scale evaluation image description systems
metrics consider first caption returned image cannot capture fact
better model score good captions higher captions even fails
consider best possible caption since systems return ranked list
item examine metrics allow us evaluate quality list
contrast human evaluations described section evaluate
image retrieval systems first consider metrics computed automatically
recall median rank item image sentence originally associated
query sentence image section use crowdsourcing



fiframing image description ranking task

performance rank original item
r k percentage queries original item among top x responses
median r median rank original item
r

image annotation
r r median r

bow
bow
tagrank
tri



















tri sem







nn








r

image retrieval
r r median r
































table model performance measured rank original image caption
correct response r k percentage queries correct response among
first x median r median position correct response ranked list
superscripts indicate statistically significant difference tri sem p
p
collect large number human judgments section use relevance
judgments define two additional metrics rate success akin recall
r precision established information retrieval metric section although
metrics allow us evaluate systems focus discussion small set
systems considered far refer interested reader section b appendix
scores systems
recall median rank original item
one advantage ranking framework position original caption image
among complete list test items determined automatically since better
system average assign higher rank original items worse system
use ranks define number different evaluation metrics
recall r k median rank scores since query associated
single gold need concerned precision however recall position k
r k e percentage test queries model returns original item among
top k useful indicator performance especially context search
user may satisfied first k contain single relevant item focus
k r r r since binary metric query gold item
found among top k use mcnemars test identify
statistically significant differences conversely median rank indicates
k system recall e number one would
consider order original item half queries use fishers
randomization identify significant differences
recall r k median rank table table confirm
earlier observation nn baseline clearly beaten kcca p
metrics except r search difference bow


fihodosh young hockenmaier

p value p since r annotation scores image caption
pairs expert scores table compare directly difference
r expert scores even strictest threshold experts indicates
measures capture often original caption returned viewed
lower bound actual performance tri sem returns original caption first
images human judges found captions describe
images without errors discrepancy even larger bow vs
tagrank vs consequence automatically computed r scores
indicate erroneously statistically significant difference quality
first captions returned tri sem returned bow tagrank even
though differences significant according human evaluation however
metrics first caption may fail identify differences
become apparent metrics example r reveals
significant difference tri tri sem annotation task although
difference highly significant according metrics section present
large scale human evaluation confirm actual differences
tri sem tri annotation identified first caption
taken account
table section b provides recall median rank scores
collecting binary relevance judgments large scale
order perform human evaluation system goes beyond measuring quality
highest ranked would obtain relevance judgments imagecaption pairs among top k query since two tasks
total different systems set consists distinct image caption pairs
k rendering exhaustive evaluation four point scale described section
infeasible therefore needed reduce total number judgments needed
define simpler annotation task could completed less time crowdsourcing
platforms amazon mechanical turk offer possibilities evaluation
enable us collect large number human judgments rapidly inexpensively
number researchers evaluated caption generation systems mechanical turk
ordonez et al yang et al kuznetsova et al kulkarni et al li
et al experiments performed scale analysis
evaluated well crowdsourced judgments task approximate
obtained smaller pool judges given detailed instructions
examine whether crowdsourcing allows us collect reliable relevance judgments
large scale evaluation image description systems
crowdsourcing task presented workers images paired ten
different captions asked indicate via checkboxes captions describe
image adapted guidelines developed fine grained annotation
caption describes image minor errors corresponding score
point scale would still permitted receive positive score guidelines
found online appendix individual task consisted six different
images paired ten captions included copy guidelines accessed


fiframing image description ranking task

amazon mechanical turk service provided crowdflower com makes
easy include control items quality control one six images task
control item generated taking random images development
set one three original captions correct responses adding
another nine seven randomly selected captions verified manually
describe image incorrect responses used workers judged
control items correctly image caption pair annotated three different
annotators total cost final score image caption pair
computed average number positive judgments received
filtering unlikely image caption pairs order reduce number annotations
needed devised filter bleu scores papineni et al filter imagecaption pairs whose caption dissimilar five captions originally written
image highly unlikely describes image found filter
unigram bleu scores combination stemming stop word removal
standardly done lins rouge script bleupre proved particularly effective
threshold bleupre filters possible image caption
pairs test set eliminates pairs expert score
greater pairs expert score greater slightly higher cutoff
bleupre would filter image caption pairs discard
image caption pairs expert score image caption pairs
expert score among image caption pairs actually wished
obtain judgments filter eliminates reducing number pairs
needed annotate since setup required us pair image number
captions multiple annotated additional image caption
pairs filtered allowing us evaluate performance filter
filtered pairs mechanical turk judges decided caption
describe image majority annotators thought
found standard bleu without preprocessing effective filter threshold
bleu misses good captions expert score
filtering entire data set whereas threshold bleu filters
entire data set misses good captions
agreement crowdsourced expert judgments use cohens
measure agreement crowdsourced expert judgments table
appendix best agreement obtained crowdsourced scores threshold
e least two three judges think caption describes image
expert scores threshold one expert thinks caption describes
image perfectly two agree think describes image minor
errors two experts think describes image perfectly one thinks
least related significantly better approximation expert
scores possible bleu rouge examine precision recall
f scores approximate relevance judgments achieve compared
relevance judgments obtained binarizing expert judgments table
items perfect expert score items almost perfect expert
score identified least items pass threshold


fihodosh young hockenmaier

expert score greater e majority experts agreed caption describes
image perfectly minor errors threshold adds suitable
image caption pairs test images paired original caption among
test captions still describe single image describe two test images
three describe four images among test images
single e original caption two possible captions three possible
captions four captions
large scale evaluation relevance judgments
crowdsourced relevance judgments allow us define two metrics rate
success k r precision believe r precision reliable indicator
overall performance since summarizes human judgments single number
depend arbitrary cutoff therefore use section depth
analysis impact different linguistic features incorporate k
rate success scores motivated fact search engines commonly return multiple
since users may satisfied long contain least one
relevant item k scores provide direct measure utility hypothetical users
rate success k scores rate success metric k analogous
recall r k scores used table intended measure utility
system hypothetical user indicates percentage test items least
one relevant found among highest ranked k following analysis
section image caption pair considered relevant majority judges say
caption describes image
rate success table table confirms nn performs clearly
worse kcca differences tri sem
shown table highly statistically significant p metrics except
annotation scores agreement expert scores table
differences nn bow significant unclear quality first
caption tri sem returns annotation significantly better returned
since outperforms metrics k scores
table indicate tri sem returns relevant caption among top responses
images relevant image captions comparison
expert scores table shows annotation scores lie expert scores
threshold comparison r k table shows
scores least twice high corresponding r scores
highest ranked response often relevant item originally associated
query original gold item
r precision scores given crowdsourced relevance judgments test image may
associated multiple relevant captions test caption may
deemed relevant multiple images besides one originally written
queries variable number relevant answers performance retrieval systems
commonly measured terms r precision manning raghavan schtze unlike
k scores metric depend arbitrary cutoff summarizes


fiframing image description ranking task

rate success k
percentage items relevant response among top x
image annotation




image retrieval




bow
bow
tagrank
tri





































tri sem













nn

table rate success k indicates percentage test items top x
contain least one relevant response superscripts indicate statistically significant
difference tri sem p p p
r precision
annotation
nn



search


total

bow
bow
tagrank
tri



















tri sem







table model performance measured r precision statistically significant differences tri sem p p p
performance system single number allowing us rank according
overall performance see section k scores measure
whether least one relevant items ranked highly r precision requires relevant
items ranked highly therefore better indicator quality mapping
images sentences since better mapping prefer relevant captions
images irrelevant caption image
r precision system query qi ri known relevant items test data
defined precision rank ri e percentage relevant items among top ri
responses returned r precision obtained averaging test queries
use fishers randomization test assess whether differences
reaches statistical significance
r precision table table gives r precision model types
used collecting expert judgments section see nearest neighbor
baseline clearly kcca p r precision indicates
little difference bow bow tagrank terms overall performance although tagrank tri outperform bow slightly search p
statistically significant difference among three bow
tri search p contrast human evaluation considered


fihodosh young hockenmaier

r precision

tri
ann search

idf
ann search

ann

align
search

align idf
ann search

tri





ii



aaa

aa



aaa ii

dbnc
dic
dbnc ic

dd
dd
dd

dd
ddd
ddd





ddd
ddd
ddd



aa



dd









table effect adding idf weighting alignment similarities distributional similarities tri model bolded scores indicate tri top left
tri sem tri align idf dbnc ic bottom right superscripts indicate statistically
significant differences addition corresponding feature x p
xx xxx p dc distributional similarities computed corpus c
bnc training corpus image captions ic
first table tri sem clearly outperforms annotation
retrieval differences p table appendix b shows scores

measuring impact linguistic features table
presented far indicate clearly tri sem outperforms simpler tri
model considered impact individual text features distinguish
two since r precision summarizes performance system single
number allows us easily perform analysis
r precision model comparison table shows ablation
study compares r precision tri tri sem trigrambased kcca use subset tri sems additional features basic tri
model yields bolded scores shown top left corner tri sems scores given
bottom right corner top row contains capture distributional
similarities bottom three rows corresponds addition one kind
distributional similarity computed bnc image captions training
corpus corpora corresponding model top column first column
contains capture idf reweighting alignment similarities
second column corresponds addition idf reweighting first
column third column adds alignment similarities first
column last column adds idf reweighting alignment similarities
scores compared second third column superscripts indicate addition particular feature leads statistically significant improvement
model include feature otherwise identical
superscripts addition distributional similarity metric leads significant improvement model top cell column superscripts
indicate addition idf reweighting leads significant improvement
corresponding model without idf reweighting immediately preceding cell



fiframing image description ranking task

row superscripts third column addition alignment
similarity leads significant improvement model without idf reweighting shown
first column row superscripts fifth column
addition alignment similarity model idf reweighting shown
second column row leads significant improvement
impact idf weighting distributional alignment similarities
idf weighting almost beneficial improvements obtained adding
idf weighting given text kernel reach statistical significance indicated superscripts table two cases performance basic tri model image
annotation performance alignment tri model image search
contrast adding lexical similarities leads almost significant highly significant
improvement distributional similarities superscripts beneficial basic
tri model tasks help idf weighted tri model image search distributional similarities computed corpora significantly improve performance
alignment tri model incorporate idf weighting adding
alignment tri model without idf weighting leads improvement
search helping slightly decreasing performance annotation albeit
significantly improvements search reach statistical significance
similarities computed corpora added conversely adding alignment
similarities non idf weighted tri model distributional similarities
corpora leads significant improvement annotation finally top cell last
column shows adding alignment similarities idf weighted tri model
leads significant improvement tasks although impact search even
greater comparing performance alignment tri model without
idf weighting shows case idf weighting helps search bottom
cells column adding alignment similarities already
use idf weighting distributional similarities adding idf weighting
distributional alignment similarities generally lead minor improvements
table shows whether difference performance obtained addition
one kind feature reaches statistical significance worth noting model
captures lexical similarities kind significantly better basic tri
model tasks p search p annotation idf reweighting
leads significant improvement annotation task p moreover
difference tri sem search annotation basic tri kernel
idf reweighting search annotation highly significant p search
p annotation
impact lins similarity shown table performance tri lin
model augments trigram kernel lins wordnet similarity
tri sem include lins similarity since found development tri lin
performed similarly worse basic tri model automatic r k median
rank scores reflected tri lin r precision scores annotation tri
search tri lins similarity may simply coarse
purposes shown table hypernym relations wordnet lead associate terms
swimming football even though semantically


fihodosh young hockenmaier

correlation system rankings
k r k
annotation














correlation system rankings
r precision

search






k vs r k





annotation


r
r
r
median rank











search












b r precision vs r k median rank

table correlation spearmans kendalls system rankings obtained
human metrics k r precision automated scores r k median rank
related fact different kinds sports activities visually
dissimilar considered related systems
human evaluations approximated automatic techniques
r precision k scores require human judgements therefore cannot applied
datasets judgements yet collected whose scale may prohibit
ever creating definitive set judgements however evaluation intended measure
relative progress image description rather absolute performance automatic
metrics may sufficient approximation since yield similar ranking systems
r precision k scores table shows correlations rankings
nn kcca systems n obtained k scores obtained
corresponding r k scores table b shows correlations r precision
automatic metrics report two rank correlation coefficients spearmans
kendalls first observe system rankings obtained via r correlate highly
r precision rankings hand observe
r r median rank scores correlate well r precision r
r correlate well corresponding k metrics suggests rankingbased metrics significantly robust metrics consider quality
first moreover indicate framework systems
expected rank pool images sentences written people may enable large scale
fully automated evaluation image description systems require equally
large scale effort collect human judgments

summary contributions conclusions
proposed frame image description task selecting ranking
descriptions among large pool descriptions provided people framework
provides direct test purely semantic aspects image description need
concerned difficulties involved automatic generation syntactically
correct pragmatically appropriate sentences introduced data set
images paired multiple captions used data set evaluate number
nearest neighbor kcca sentence image annotation well


fiframing image description ranking task

converse task sentence image search experiments indicate importance
capturing lexical similarities finally performed depth analysis different
evaluation metrics image description
advantages framing image description ranking task
one main motivations framing image description ranking rather
generation question objective comparable evaluation ability
understand depicted images order make progress challenging
task important define tasks evaluation metrics allow objective
comparison different approaches argued task ranking pool
captions written people attractive number reasons first obtained
data set compared directly second human evaluation easier
generated captions since needs focus factual correctness description rather
grammaticality fluency creativity third statistically significant differences
systems may become apparent single caption per image considered
finally ranking makes possible automate evaluation e g considering position
original caption moreover framing image description ranking task establishes
clear parallels image retrieval allowing metrics used tasks
data set
flickr k data set images paired five crowdsourced captions
unique resource image description although much smaller sbu corpus
ordonez et al believe generic conceptual descriptions corpus
useful image understanding original flickr captions sbu data set
data set perhaps similar iapr data set grubinger et al
captions corpus shorter focus salient aspects
image focus images people animals iapr data set covers
slightly different domain including city pictures landscape shots typically
depict focus people distinct advantage corpus pairs image
multiple independently written captions indicate
single caption training time leads significant increase performance
shown use multiple captions define alignment lexical similarity
may useful image description standard distributional wordnet
similarities

first apply kernel canonical correlation analysis kcca sentencebased image description kcca significantly outperforms nearest
neighbor approaches data set training images test images
although may scale better large data sets ordonez et al
sbu corpus memory requirements train kcca may prohibitive one
advantage kcca approaches image description systems geared
specifically towards caption generation applied image de



fihodosh young hockenmaier

scription image retrieval indicate performance
tasks fairly similar
important difference taken image
description systems features used presented computed minimal supervision feature relies supervised classifier
alignment similarity uses pos tagger identify nouns verbs despite
simplicity underlying features achieve relatively high performance
considering difficulty task although chance randomly
chosen test caption describe test image well fine grained human judgments reveal
image annotation first caption returned best kcca system good
description test images furthermore large scale evaluation shows
best system almost chance suitable image caption
returned among first ten indicate two main reasons
high performance availability multiple captions image training
time use robust text representations capture lexical similarities rather
requiring strict equality words however clear task remains
far solved leave question kcca may benefit
rely richer visual linguistic features detector responses rich syntactic
analyses future work
evaluating ranking image description systems
main advantage framing image description ranking allows
direct comparison different approaches since evaluated data set
makes possible borrow established evaluation metrics information retrieval
use metrics data sets sentence image annotation image
search
one hand shown crowdsourcing used collect large number
binary judgments image caption pairs relatively low price crowdsourced judgments correlate well fine grained judgments able collect
human judgments large scale particularly important retrieval approaches
image description since number relevance judgments need collected
test collection may significantly larger number judgments commonly
used evaluate single caption generation system however experiments image
annotation provided example human judgments first caption returned
test image reveal differences systems become apparent
taken account fine grained evaluation indicates evaluations
single may require potentially much larger number test items
order reveal robust statistically significant differences among human evaluation
metrics compared believe r precision computed crowdsourced
relevance judgments robust r precision standard metric evaluating
ranked retrieval items varying number relevant responses since
yields single score makes particularly easy compare systems however
k scores measure percentage items top k responses contain
relevant perhaps direct measure useful system may prac



fiframing image description ranking task

tice release crowdsourced relevance judgments collected order
enable others evaluate image description system data hope
establish benchmark used direct fair large scale comparison
arbitrary number image description systems
hand shown framework systems evaluated ability rank pool images sentences may make possible perform
fully automated evaluation contrary current practice analysis indicates clearly
standard metrics bleu rouge reliable indicators
well captions describe images even bleu rouge style preprocessing used
effective filter implausible image caption pairs although consider humangenerated captions stipulate similar observations may hold automatically generated captions since similar criticisms bleus appropriateness generation
machine translation evaluation well known reiter belz callison burch osborne koehn however ranking framework test query associated
gold response originally associated indicate
metrics rank gold item lead similar conclusions human judgments suggest evaluation ranking image description task
automated performed potentially much larger scale examined
implications evaluation caption generation systems
image description treated natural language
generation community automatically generating captions indistinguishable
captions written people evaluation criterion used mitchell et al
comparison caption generation systems requires much ability
provide factually correct information image believe linguistic
issues need solved generation setting need evaluated separately
ability decide whether given caption describes image unclear kinds
evaluations performed e g mitchell et al could ever automated since question
natural automatically produced caption seems may require human judgment
human experiments expensive since system generates captions
judgments collected anew system experiment since
consensus constitutes good image description independently obtained human
assessments different caption generation systems compared directly
means direct comparison systems e g performed mitchell et al typically
possible within one group since common data set different
system outputs publicly available although automatic scores bleu rouge
may still useful caption generation measures fluency reiter belz
shown reliable metrics well caption describes image
especially candidate pool disjoint reference captions suggests
evaluation syntactic pragmatic aspects caption generation task
automated may rely human judgments however may
possible use framework proposed evaluate semantic affinity
functions f implicitly used caption generations systems



fihodosh young hockenmaier

acknowledgments
gratefully acknowledge support project national science foundation
iis medium grant career award cns ci p

appendix agreement approximate metrics expert
human judgments
tables use cohens kappa measure agreement bleu rouge
scores expert judgments selected thresholds yield optimal
table shows agreement crowdsourced judgments expert
judgments since best agreement expert scores obtained crowdsourced
judgments threshold table b measures precision recall resulting binary relevance judgments binarized expert judgments obtained varying
thresholds

appendix b performance systems
following tables give section body nn
idf
corresponds nn idf
f tri sem corresponds tri dbnc ic
r k median rank scores table gives recall median rank original
item section
agreement expert bleu rouge scores cohens
case scand sref
reference captions test image scand sref r
expert
e



bleu b





rouge r













































reference caption test image scand sref r gold
expert
e



bleu


































rouge













table agreement cohens binarized expert bleu rouge scores
pool candidate captions contains test images reference caption



fiframing image description ranking task

agreement expert bleu rouge scores cohens
case scand sref
reference captions test image r
expert
e



bleu




rouge












































reference caption test image r
expert
e



bleu




rouge












































table agreement cohens binarized expert bleu rouge scores
pool candidate captions may contain test images reference caption

agreement expert
lay scores cohens
expert
e













lay vs expert
relevance judgments l

lay l













agreement cohens relevance judgments obtained expert
scores relevance score e lay
scores relevance score l

e

precision

recall

f





























b precision recall f scores binarized lay scores l
binarized expert scores varying
thresholds e

table comparing relevance judgments obtained lay scores
obtained expert scores



fihodosh young hockenmaier

k r precision scores table gives k success rate section
r precision scores section crowdsourced human
judgments section



fiframing image description ranking task

performance automatic evaluation
r k percentage queries original item top x
median r median rank original item
r

image annotation
r r median r

r

image search
r r median r

nn f
nn idf
f
nn bow
nn tri best









































bow
tri

























bow histo
bow
bow idf

bow idf
tagrank

















































tri histo
tri

























tri lin
tri dbnc
tri dic
tri dbnc ic









































tri
tri dbnc
tri dic
tri dbnc ic

























































































































idf histo
tri
bnc ic

















idf
dbnc ic



















tri

idf



idf
tri
dbnc
idf
tri
dic
idf
tri dbnc ic


idf
tri

idf
tri
dbnc
idf
tri
ic



tri

table performance measured percentage test items
original item returned among top
well median rank

idf
idf
original item section nn f nn tri dbnc ic tri sem



fihodosh young hockenmaier

performance human evaluation
k percentage items relevant response among top x
r prec r precision computed relevant responses

nn f
nn idf
f
nn bow
nn tri best

image annotation
r prec



image search
r prec









































bow
tri

























bow histo
bow
bow idf

bow idf
tagrank

















































tri histo
tri

























tri lin
tri dbnc
tri dic
tri dbnc ic
tri
tri dbnc
tri dic
tri dbnc ic

























































































































































































tri
tri
tri
tri
tri
tri
tri
tri
tri


idf

idf

bnc
idf

ic
idf
dbnc ic

idf


idf

bnc
idf
dic

idf histo
dbnc ic

idf
dbnc ic

table performance measured percentage test items
return item deemed relevant according crowdsourced judgments
among top
r precision computed judgments

idf
idf
section nn f nn tri dbnc ic tri sem



fiframing image description ranking task

references
artstein r poesio inter coder agreement computational linguistics
computational linguistics
bach f r jordan kernel independent component analysis journal
machine learning
barnard k duygulu p forsyth freitas n blei jordan
matching words pictures journal machine learning
blei jordan modeling annotated data sigir proceedings
th annual international acm sigir conference development
information retrieval pp toronto ontario canada
bloehdorn basili r cammisa moschitti semantic kernels text
classification topological measures feature similarity proceedings
th ieee international conference data mining icdm pp hong
kong china
bnc consortium british national corpus version bnc xml edition
http www natcorp ox ac uk
brown p f pietra v j pietra mercer r l mathematics
statistical machine translation parameter estimation computational linguistics

callison burch c osborne koehn p evaluation role bleu
machine translation proceedings th conference european chapter association computational linguistics eacl pp
trento italy
cohen j coefficient agreement nominal scales educational psychological measurement
croce moschitti basili r structured lexical similarity via convolution
kernels dependency trees proceedings conference empirical
methods natural language processing emnlp pp edinburgh uk
dale r white eds workshop shared tasks comparative evaluation natural language generation position papers arlington va usa
datta r joshi li j wang j z image retrieval ideas influences
trends age acm computing surveys
deschacht k moens f text analysis automatic image annotation
proceedings th annual meeting association computational linguistics acl pp prague czech republic
dietterich g approximate statistical tests comparing supervised classification
learning neural computation
everingham gool l v williams c winn j zisserman
pascal visual object classes challenge voc http www
pascal network org challenges voc voc workshop


fihodosh young hockenmaier

farhadi hejrati sadeghi young p rashtchian c hockenmaier j
forsyth every picture tells story generating sentences images
proceedings european conference computer vision eccv part iv pp
heraklion greece
fellbaum c wordnet electronic lexical database bradford books
felzenszwalb p mcallester ramanan discriminatively trained multiscale deformable part model proceedings ieee conference computer vision pattern recognition cvpr pp anchorage ak usa
feng lapata automatic image annotation auxiliary text information proceedings th annual meeting association computational
linguistics human language technologies acl hlt pp columbus
oh usa
feng lapata many words picture worth automatic caption generation news images proceedings th annual meeting association
computational linguistics acl pp uppsala sweden
fisher r design experiments olyver boyd edinburgh uk
grangier bengio discriminative kernel rank images
text queries ieee transactions pattern analysis machine intelligence

grice h p logic conversation davidson harman g h eds
logic grammar pp dickenson publishing co encino ca usa
grubinger clough p mller h deselaers iapr benchmark
evaluation resource visual information systems ontoimage workshop
language resources content image retrieval lrec pp
genoa italy
gupta verma jawahar c choosing linguistics vision describe
images proceedings twenty sixth aaai conference artificial intelligence
toronto ontario canada
hardoon r saunders c szedmak shawe taylor j correlation automatic image annotation li x zaane r li z h eds
advanced data mining applications vol lecture notes computer science pp springer berlin heidelberg
hardoon r szedmak r shawe taylor j r canonical correlation
analysis overview application learning methods neural computation

hotelling h relations two sets variates biometrika
hwang grauman k learning relative importance objects tagged
images retrieval cross modal search international journal computer vision




fiframing image description ranking task

jaimes jaimes r chang f conceptual framework indexing visual
information multiple levels internet imaging vol proceedings
spie pp san jose ca usa
jurafsky martin j h speech language processing nd edition prentice
hall
krippendorff k content analysis introduction methodology sage
kulkarni g premraj v dhar li choi berg c berg l
baby talk understanding generating simple image descriptions proceedings
ieee conference computer vision pattern recognition cvpr
pp
kuznetsova p ordonez v berg berg choi collective generation
natural image descriptions proceedings th annual meeting association computational linguistics long papers pp jeju
island korea
lavrenko v manmatha r jeon j model learning semantics pictures thrun saul l schlkopf b eds advances neural information
processing systems cambridge usa
lazebnik schmid c ponce j spatial pyramid matching dickinson
leonardis b tarr eds object categorization computer human
vision perspectives chap pp cambridge university press
li kulkarni g berg l berg c choi composing simple image descriptions web scale n grams proceedings fifteenth conference
computational natural language learning conll pp portland
usa
lin c rouge package automatic evaluation summaries mariefrancine moens ed text summarization branches proceedings
acl workshop pp barcelona spain
lin c hovy e h automatic evaluation summaries n gram cooccurrence statistics proceedings human language technology conference north american chapter association computational linguistics
hlt naacl pp edmonton ab canada
lin information theoretic definition similarity proceedings fifteenth international conference machine learning icml pp madison
wi usa
lowe g distinctive image features scale invariant keypoints internationa
journal computer vision
makadia pavlovic v kumar baselines image annotation international
journal computer vision
manning c raghavan p schtze h introduction information retrieval
cambridge university press



fihodosh young hockenmaier

mitchell dodge j goyal yamaguchi k stratos k han x mensch berg
berg daume iii h midge generating image descriptions
computer vision detections proceedings th conference european
chapter association computational linguistics eacl pp avignon france
moschitti syntactic semantic kernels short text pair categorization
proceedings th conference european chapter association
computational linguistics eacl pp athens greece
moschitti pighin basili r tree kernels semantic role labeling
computational linguistics
och f j ney h systematic comparison statistical alignment
computational linguistics
ordonez v kulkarni g berg l im text describing images million
captioned photographs advances neural information processing systems
pp
papineni k roukos ward zhu w j bleu method automatic
evaluation machine translation proceedings th annual meeting association computational linguistics acl pp philadelphia pa usa
popescu tsikrika kludas j overview wikipedia retrieval task
imageclef clef notebook papers labs workshops padua italy
porter f suffix stripping program
rashtchian c young p hodosh hockenmaier j collecting image annotations amazons mechanical turk naacl workshop creating speech
language data amazons mechanical turk pp los angeles ca
usa
rasiwasia n pereira j c coviello e doyle g lanckriet g r levy r vasconcelos n cross modal multimedia retrieval proceedings
international conference multimedia mm pp york ny
usa
reiter e belz investigation validity metrics automatically evaluating natural language generation systems computational linguistics

shatford analyzing subject picture theoretical cataloging
classification quarterly
shawe taylor j cristianini n kernel methods pattern analysis cambridge
university press
smucker allan j carterette b comparison statistical significance
tests information retrieval evaluation proceedings sixteenth acm conference information knowledge management cikm pp lisbon
portugal



fiframing image description ranking task

socher r li f f connecting modalities semi supervised segmentation
annotation images unaligned text corpora proceedings ieee
conference computer vision pattern recognition cvpr pp san
francisco ca usa
van erp schomaker l variants borda count method combining
ranked classifier hypotheses proceedings seventh international workshop
frontiers handwriting recognition iwfhr pp nijmegen netherlands
varma zisserman statistical texture classification
single images international journal computer vision
vedaldi fulkerson b vlfeat open portable library computer
vision http www vlfeat org
weston j bengio usunier n large scale image annotation learning rank
joint word image embeddings machine learning
yang teo c daume iii h aloimonos corpus guided sentence generation natural images proceedings conference empirical methods
natural language processing emnlp pp edinburgh uk




