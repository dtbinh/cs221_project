Journal Artificial Intelligence Research 47 (2013) 697740

Submitted 05/13; published 08/13

Heuristic Search Time Matters
Ethan Burns
Wheeler Ruml

eaburns cs.unh.edu
ruml cs.unh.edu

Department Computer Science
University New Hampshire
Durham, NH 03824 USA

Minh B.

minh.b.do nasa.gov

Planning Scheduling Group
SGT Inc.
NASA Ames Research Center
Moffett Field, CA 94035 USA

Abstract
many applications shortest-path algorithms, impractical find provably
optimal solution; one hope achieve appropriate balance search
time solution cost respects users preferences. Preferences come many
forms; consider utility functions linearly trade-off search time solution cost.
Many natural utility functions expressed form. example, solution
cost represents makespan plan, equally weighting search time plan makespan
minimizes time arrival goal achieved. Current state-of-theart approaches optimizing utility functions rely anytime algorithms, use
extensive training data compute termination policy. propose direct
approach, called Bugsy, incorporates utility function directly search,
obviating need separate termination policy. describe new method based
off-line parameter tuning novel benchmark domain planning time pressure
based platform-style video games. present believe first
empirical study applying anytime monitoring heuristic search, compare
proposals. results suggest parameter tuning technique give
best performance representative set training instances available. not, Bugsy
algorithm choice, performs well require off-line training.
work extends tradition research metareasoning search illustrating
benefits embedding lightweight reasoning time search algorithm itself.

1. Introduction
Many problems artificial intelligence formulated shortest path problems,
solved using heuristic search algorithms A* (Hart, Nilsson, & Raphael,
1968). Unfortunately, state spaces often grow exponentially problem size,
usually infeasible find optimal solutions shortest path problems practical interest.
Instead, practitioners tend settle suboptimal solutions, often found
efficiently expensive execute. One left choice spending
long time searching cheap solution, little time searching expensive one.
argue new approach strictly concerned optimizing solution cost,
optimizing utility function given terms solution cost search time.
c
2013
AI Access Foundation. rights reserved.

fiBurns, Ruml, &

utility function, user specify preference search time solution
cost, algorithm handles rest.
consider utility functions given linear combination search time solution
cost. important form utility function two reasons. First, easily elicited
user already explicitly application domain. example, cost
given monetary terms, usually possible ask much time one willing spend
decrease solution cost certain amount. Second, solution cost given terms
time (i.e., cost represents time required agent execute solution),
form utility function used optimize call goal achievement time;
weighting search time execution time equally, utility-aware search attempt
minimize sum two, thus attempting behave agent achieve
goal quickly possible.
existing techniques problem based anytime algorithms (Dean &
Boddy, 1988), general class algorithms emit stream solutions decreasing
cost converging optimal one. sufficient knowledge performance
profile anytime algorithm, represents probability decrease
solution cost certain amount given current solution cost additional search time,
possible create stopping policy aware users preference trading
solving time solution cost (Hansen & Zilberstein, 2001; Finkelstein & Markovitch, 2001).
two disadvantages using anytime algorithms trade-off solving time
solution cost. first profile anytime algorithm must learned off-line
representative set training instances. many settings, domain-independent
planning, problem set unknown, one cannot easily assemble representative training set. Also, often obvious parameters problem affect performance
difficult tell problem set representative. Even instance generator
available, instances generates may represent seen real world.
second issue that, stopping policy aware users preference time
cost, underlying anytime algorithm oblivious emit stream
solutions regardless desired trade-off. policy must simply best
solutions found, algorithm may waste lot time finding many
solutions simply discarded. search algorithm fully aware
possible candidate solutions available relative estimated merits.
paper presents four main contributions. First, combine anytime heuristic search
dynamic programming-based monitoring technique Hansen Zilberstein
(2001). best knowledge, first apply anytime monitoring
anytime heuristic search. Second, present simple portfolio-based method
estimates good parameter use bounded-suboptimal search algorithm optimize
given utility function. Third, present Bugsy, best-first search algorithm
rely off-line training, yet accounts users preference search time
solution cost.1 One important difference Bugsy previous proposals
trading-off deliberation time solution cost Bugsy considers trade-off directly search algorithm, whereas previous techniques, based anytime
algorithms, consider trade-off externally actual search algorithm. Finally,
1. previous version Bugsy proposed Ruml (2007), see Appendix discussion
improvements incorporated version presented here.

698

fiHeuristic Search Time Matters

present results set experiments comparing portfolio-based method, anytime monitoring, Bugsy, along utility-oblivious algorithms A* greedy
best-first search, real-time search algorithms, decision-theoretic A* (DTA*, Russell &
EricWefald, 1991), previously proposed utility-aware search. much
work discussing trade-off deliberation solution cost, best
knowledge first implement thoroughly evaluate many ideas
context heuristic search.
results experiments reveal two surprises. First, representative set
training instances available, effective approach simple technique
selecting bound use bounded-suboptimal search. Surprisingly, convincingly
dominates anytime algorithms monitoring tests. Second, neither Bugsy
anytime search monitoring dominates other. Bugsy require off-line
training, yet surprisingly, Bugsy perform well methods use training data.
representative problem set available, Bugsy algorithm choice.
work extends tradition research metareasoning planning illustrating
benefits embedding lightweight reasoning time search algorithm itself.

2. Background
section briefly describe heuristic search, present terminology used
remainder paper, discuss type utility functions addressing.
2.1 Heuristic Search
considered paper, heuristic search technique finding shortest path
nodes weighted graph; many problems specified form. Since
typical graphs much large represent explicitly, algorithms usually
generate graph lazily using function called expand. expand function returns
successors node graph. call process evaluating expand function
node expanding node, expanding node say generating
successors.
A* (Hart et al., 1968) probably best-known heuristic search algorithm. maintains two sets nodes: open list contains frontier nodes generated
yet expanded, closed list contains nodes already expanded
(a common optimization closed list include nodes already
open list too), therefore represent duplicate states encountered again. open list
sorted f (n) = g(n) + h(n), g(n) cost path initial node
node n, h(n) heuristic estimate cheapest path cost n goal node
reachable n. algorithm proceeds removing node minimum f value
open list, expanding it, putting children open list, putting node
closed list. A* removes goal node open list, stops searching
returns path goal solution. Finally, heuristic never over-estimates
cost go called admissible. admissible heuristic, A* returns optimal
solutions.
Dechter Pearl (1988) prove heuristic satisfies property called consistency
(for nodes n m, h(n) h(m) + c(n, m), c(n, m) cost cheapest
699

fiBurns, Ruml, &

path n m), A* expands fewest possible nodes required prove
optimality solution given heuristic. practice A* often takes long
(Helmert & Roger, 2008), thus given optimal efficiency infeasible look optimal
solutions many problems. Instead, one must settle suboptimal solutions,
hope possible find sufficiently cheap solution within reasonable amount
time memory.
2.2 Suboptimal Search
Greedy best-first search (Michie & Ross, 1969) popular suboptimal search algorithm.
proceeds A*, orders open list heuristic, h(n), idea
remaining search effort correlates remaining solution cost. words, assumes
easier find path goal nodes low h. strictly
attempting minimize search time, Thayer Ruml (2009) show greedy best-first
search different heuristic, d, effective. Instead estimating cost go,
done traditional h functions, heuristic, called distance estimate, estimates
number remaining search nodes path cheapest solution beneath node.
practice, distance estimates readily available cost-to-go heuristics provide
much better performance used greedy best-first search domains less cost
go directly correlated less search go. call greedy best-first search using
heuristic Speedy search, analogy greedy search.
greedy best-first search find solutions quickly, bound
cost solutions. Bounded-suboptimal search algorithms remedy problem. Weighted
A* (Pohl, 1970) perhaps common techniquesit proceeds A*,
orders open list f (n) = g(n) + w h(n), w 1. weighting parameter,
w, puts emphasis heuristic estimate cost arriving node, thus
greedier A* often finds suboptimal solutions much faster A* finds
optimal ones. addition, weight provides bound suboptimality solutions:
solutions w times cost optimal solution (Pohl, 1970). Unlike
greedy best-first search, weighted A* lets user select weight, allowing provide
either cheaper solutions faster solutions depending needs.
refer reader work Thayer (2012) in-depth study suboptimal
bounded-suboptimal search algorithms, including many use heuristics.
2.3 Utility Functions
far, described A*, optimizes solution cost, bounded-suboptimal search,
finds solutions within constant factor optimal, greedy best-first search,
attempts minimize solver time. Often, none really desired: optimal solutions
require impractical amount resources, one rarely requires solutions strictly within
given bound optimal, unboundedly suboptimal solutions costly. Instead,
propose optimizing simple utility function given linear combination search time
solution cost:
U (s, t) = (wf g (s) + wt t)
(1)
solution, g (s) cost solution, time solution
returned, wf wt user-specified weights used express preference trading-off
700

fiHeuristic Search Time Matters

search time solution cost. number time units user willing spend
achieve improvement one cost unit wf /wt . quantity usually easily elicited
users already explicit application domain. cost empty
solution, g ({}), user-specified value defines utility achieved case
search gives without returning solution
linear utility function two main benefits. First, fairly expressive.
example, one optimize cost solution search time given
monetary terms. situation occur cloud computing environments computation time costs money. linear utility function capture optimal greedy search
using 0 weight execution time solution cost respectively. Additionally,
linear utility function express goal achievement time weighting search time equally
solution makespan. practical examples minimizing goal achievement time
desired include robotic video game pathfinding problems. settings, user
often care optimal solutions take long find, may
care achieving goal quickly possible.
demonstration minimizing goal achievement time, made video
A*, Speedy search, Bugsy solving pathfinding video game pathfinding problem.
available online appendix paper web: http://youtu.be/
Yluf88V1PLU. video includes three panels, showing agent using different
search algorithm. Since focus finding cost-optimal solutions,
Speedy Bugsy agents begin moving almost immediately. A* agent stands still
long time plans optimal path, doesnt start moving Bugsy
arrived goal. occurring, Speedy agent following
extremely circuitous path; doesnt reach goal approximately 30 seconds
A*. didnt show agonizing seconds video, instead stopped recording
soon A* reached goal. Clearly, Bugsy agent, optimizes goal achievement
time, solution cost search time, preferred scenario.
quite expressive, linear utility functions rather simple. One main benefit
simplicity that, fixed utility function, passage time decays utility
values rate. simplification allows us ignore time passed
current decision point. express utility values terms utility
outcome starting current moment time. Without benefit, mere passage
time would change relative ordering utilities different outcomes;
would need re-compute utility values every point time order select best
outcome.
consider linear utility functions work, noted one
could consider expressive functions. Step functions, example, represent
deadlines certain amount time elapsed utility acting greatly
decreases. Bugsy support functions, anytime monitoring technique
discussed Section 3.1 restrictions utility functions optimize.
Anytime monitoring naturally handle expressive functions, step functions.

3. Previous Work
Next describe previous techniques trading-off solver time solution cost.
701

fiBurns, Ruml, &

3.1 Monitoring Anytime Algorithms
Much previous work optimizing utility functions solving time cost, Equation 1, focused finding stopping policies anytime algorithms. Anytime algorithms
(Dean & Boddy, 1988) general class algorithms find one solution,
stream solutions strictly decreasing cost. get name one
stop anytime algorithm time get current best solution. Anytime algorithms
attractive candidate optimizing utility function: since
single solution pick, opportunity choose solution
greater utility using algorithm finds single solution. Different
solutions found different times, knew time algorithm
would find solutions cost solutions, could compute
utilities return solution maximizes utility. Unfortunately, usually
possible know solutions anytime algorithm return without running it.
Instead, algorithm running, one must continually make decision: stop now,
keep going?
Deciding stop easy task, utility solution depends
cost time needed find it. one hand, stopping early reduce
amount computation time expense costly solution.
hand, algorithm continues, may reduce solution cost enough
justify extra computation time. case, final utility worse would
algorithm stopped earlier. little extra information, however,
possible create reasonable policy.
Near Optimal Response-Time Algorithm (NORA, Shekhar & Dutta, 1989) provides
one simple stopping policy optimizing goal achievement time. NORA, simply stops
anytime algorithm current search time user-specified factor current
incumbent solutions execution time. Shekhar Dutta (1989) prove the, search
stops time factor incumbent solution cost, goal achievement
time within factor min(1 + , 1 + 1 ) optimal goal achievement time.
use NORA slightly different Shekhar Dutta (1989).
apply NORA anytime heuristic search. Instead, evaluated empirically
database query optimization problems, tree search problems, every leaf
node possible solution. describe one could use NORA A* search,
make assumption A* stopped early without reaching goal
heuristic planning procedure used achieve goal executing partial
solution found A*. procedure often available. using NORA
anytime heuristic search, here, incumbent solution guaranteed reach
goal. disadvantage that, anytime stopping policies, cannot
better best solution found utility-oblivious anytime algorithm.
NORA finds solution within specified bound optimal goal achievement time.
Instead, Hansen Zilberstein (2001) present dynamic programming-based technique
building optimal stopping policy utility function. requires one extra piece
information: profile anytime algorithm. Hansen Zilberstein define
profile probability distribution cost solution returned algorithm,
conditioned current solution cost additional time given improve
702

fiHeuristic Search Time Matters

solution: P (qj |qi , t), qj qi two possible solution costs
additional time. profile allows reasoning solution cost may decrease
algorithm given time improve it. requires extra knowledge,
performed small experiment (not shown here) found optimal policy found
using dynamic programming performs better simpler NORA technique.
Hansen Zilbersteins technique monitors progress anytime algorithm
evaluating stopping policy discrete time intervals. algorithm considers stopping
every time units, utility achievable time algorithms current
solution costs qi is:

U (qi , t)
= stop,
(2)
V (qi , t) = max P
P
(q
|q
,
t)V
(q
,

+
t)

= continue

j
j
j
stopping policy is:

(qi , t) = argmax




U (qi , t)
= stop,
P
P
(q
|q
,
t)V
(q
,

+
t)

= continue
j
j
j

(3)

U user-specified utility function P profile anytime algorithm.
show sophisticated technique accounts cost evaluating
policy, however, algorithms presented paper, cost evaluating policy
consists mere array lookup essentially free.
Since profile anytime algorithm usually known, must estimated.
possible estimate profile off-line one access representative set training instances. estimate profile, algorithm run training
instances 3-dimensional histogram created represent conditional probability distribution, P (qj |qi , t), needed compute stopping policy (cf. Equation 3).
Appendix C gives detailed description implementation procedure.
3.2 Anytime Heuristic Search
Anytime algorithms general class many anytime algorithms
heuristic search (Likhachev, Gordon, & Thrun, 2003; Hansen & Zhou, 2007; Richter,
Thayer, & Ruml, 2010; van den Berg, Shah, Huang, & Goldberg, 2011; Thayer, Benton, &
Helmert, 2012). paper use Anytime Repairing A* (ARA*, Likhachev et al., 2003)
since tended give best performance approaches according experiments
done Thayer Ruml (2010). ARA* executes series weighted A* searches,
smaller weight previous. Since weight bounds solution cost,
looser bounds early iterations tend find costly solutions quickly. time passes
weight decreases, solution cost, eventually converging optimal. ARA*
special handling duplicates encountered search enables
efficient still guaranteeing bound solutions.
anytime heuristic search algorithms, ARA* parameters. running
ARA*, user must select weight schedule, typically comprised initial
weight amount decrement weight solution found.
behavior ARA* varies different weight schedules. experiments, used
initial weight 3.0 decrement 0.02. schedule used Likhachev
703

fiBurns, Ruml, &


1
100
h=2
B
d=2


1

h=100
d=1

h=1
C
d=1
100
1
E

Figure 1: small example graph.
et al. (2003), found gave best performance compared several
alternative schedules domains considered.
Given fixed weight schedule, anytime heuristic search algorithm emit fixed
stream solutions given problem instance; algorithm take users
utility function account. solutions found regardless whether
user wants solution fast possible optimal solution costs. Figure 1
shows small, concrete example, goal find path node node E.
node labelled heuristic value (h) number nodes remaining
goal (d), edges labelled costs. user wants optimal
solution, algorithm would ideally return path A, B, C, E. However, user
wants solution fast possible, may better find solution A, D, E,
fewer nodes, may found fewer expansions. ARA* considers cost,
distance, initial weight less 66 23 , longer, cheaper, solution
found regardless users preference. monitoring technique select
best solutions found.
3.3 Contract Search
Dionne, Thayer, Ruml (2011) consider problem contract search, goal
must returned hard deadline. Unlike real-time search (Korf, 1990),
agents next action must ready deadline, contract search requires algorithm
return complete path goal. optimizing utility function, contract search must
aware cost solutions amount time required find them.
conventional approaches contract search use anytime algorithms, Dionne et al.
(2011) present Deadline-Aware Search (DAS) considers search time directly.
basic idea behind DAS consider states lead solutions deemed
reachable within deadline. Two different estimates used determine set
nodes: estimate maximum-length solution path search explore
deadline arrives, called dmax , estimate distance solution beneath
704

fiHeuristic Search Time Matters

search node open list, words d. States dmax , deemed
reachable, states pruned. search expands non-pruned nodes best-first
order f = g + h, updating dmax estimates on-line. updates cause
remaining nodes pruned remaining time deadline, DAS uses
recovery mechanism repopulate open list set pruned nodes continues
searching deadline reached.
mentioned previously, estimates readily available normal cost-to-go heuristics, h, domains. leaves question estimate dmax . Dionne et al.
(2011) show simply using remaining number possible expansions, computed via
expansion rate remaining time, appropriate due phenomenon
call search vacillation. best-first search expands nodes, typically expand straight single solution path, instead considers multiple solution paths
time, expanding nodes each. this, said vacillating
many different paths, may return work particular path
performed many expansions along others. account vacillation, Dionne et al.
introduce metric called expansion delay estimates number additional expansions performed search expansion two successive nodes along single

texp
path. define dmax = rem
delay , trem time remaining deadline,
texp average expansion rate, delay average expansion delay. compute
average expansion delay averaging difference algorithms total expansion
count node expanded generated.
Dionne et al. (2011) showed experimentally DAS performs favorably anytimebased approaches alternative contract search algorithms, indicating approach
directly considers search time may beneficial utility function optimization.

4. Off-line Bound Selection
turn first two new methods introduced paper.
section, present simple technique trading search time
solution cost based bounded-suboptimal search. Recall bounded-suboptimal
search algorithms return solutions guaranteed within user-specified factor
optimal solution cost. practice, applications require actual bound, instead
bound used practitioners parameter tweaked speed-up search
finding solutions quickly enough. fact bound trade search time
solution cost makes prime candidate automatic parameter tuning (Rice, 1976).
exactly propose.
anytime methods discussed previous section, off-line bound selection requires representative set training instances. instances used gather
information bounded-suboptimal search trades-off search time solution
cost. requirement user select set diverse bounds try
parameters search algorithm. algorithm run N training instances suboptimality bound, creating list N pairs bound:
sols b = h(c1 , t1 ), ..., (cN , tN )i b bound passed parameter algorithm,
ci cost solution ith training instance ti time ith
solution found. Given utility function U : cost time R, select bound
705

fiBurns, Ruml, &

gives greatest expected utility training set:


X
1
bound U = argmax

U (c, t)
|sols b |
b

(4)

(c,t)sols b )

experiments, select different weight use utility function
set 1.1, 1.5, 2, 2.5, 3, 4, 6, 10. may possible reduce number weights
training set using linear interpolation estimate performance parameters
used training. simple approach extended select
portfolio different algorithms addition different bounds. may beneficial,
example, include A* Speedy search portfolio, algorithms
likely selected cheap solutions required solution must found quickly.
see Section 6 simple technique outperforms ARA* using anytime
monitor experimental evaluation. fact, representative set training instances
available, technique tends perform better algorithms
evaluate.
related technique dove-tailing method Valenzano, Sturtevant, Schaeffer, Buro,
Kishimoto (2010). approach presented way side-stepping need
parameter tuning running parameter settings simultaneously. found that,
dove-tailing, weighted IDA* (Korf, 1985) able return first solution much faster,
dove-tailing greatly reduced high variance solving times given weight.
found dove-tailing different operator orderings effective IDA*.
main difference work Valenzano et al. quite
different goals. concern find first solution quickly, rather select
setting better optimizes user-specified utility function. such, approach
run multiple settings time instead selects single parameter run
single search. fact, approaches complementary. Given utility-aware
algorithms parameters, one could use dove-tailing avoid need perform
offline parameter selection.

5. Best-First Utility-Guided Search
Anytime search aware utility. Monitoring bound selection require training.
section, present Bugsy2 , utility-aware search algorithm require
off-line training.
5.1 Expansion Order
A*, Bugsy best-first search, instead ordering open list f , Bugsy
orders open list estimate utility outcome resulting node
expansion. Since utility dependent time, mere passage time affects utility
values. differs traditional search algorithms values used order
expansions remain constant. Recall, however, using linear utility function,
utility values decay exact rate. Given this, Bugsy ignores past time
2. Bugsy acronym Best-first Utility-Guided SearchYes!

706

fiHeuristic Search Time Matters

compares utility estimates assuming time begins current decision point.
utility values match utility ultimate outcome, still
preserve relative order different choices agent make.
understand Bugsys ordering function, first consider best utility
outcome resulting node expansion computed oracle. foreknowledge maximum utility outcome, purpose search algorithm would
achieve expanding nodes along path initial node order build
solution path. Since utility function given linear combination solution cost
search time, utility value outcome written terms cost
length (possibly empty) maximum utility outcome, s:
U = (wf g (s) + wt (s) texp )

(5)

g (s) cost path (recall cost empty path user-specified
constant), (s) number nodes s, texp time required expand node.3
Given maximum utility value U , best utility outcome resulting
expanding node n is:

U
n leads maximum utility outcome

(6)
u (n) =

U wt texp otherwise
words, utility get expanding node leads maximum utility
outcome maximum utility; expanding node simply waste time,
utility maximum utility minus cost performing unnecessary expansion.
practice, know maximum utility, must rely estimates. Bugsy
uses two estimates approximate maximum utility. First, estimates cost
solution find beneath node as, f . Note f estimate,
heuristic estimate true cost go, cheapest
solution beneath node may solution greatest utility. See Appendix
possible alternatives. Second estimates number expansions required find
solution beneath node n, exp(n). One crude estimate remaining expansions d,
distance heuristic estimates remaining nodes solution path. reality,
Bugsy experience search vacillation, discussed earlier, expanding nodes
along single solution path. account vacillation, use expansion
delay technique Dionne et al. (2011) estimate exp(n) = delay d(n). is,
expect remaining d(n) steps goal require delay expansions.
Bugsy either choose expand node, stop return empty solution.
one way Bugsy differs A*: Bugsy decides among actions search
level (such terminating search, expanding one many open nodes), whereas
A* committed expanding nodes fixed order. Bugsy node open
list represents possible outcome, Bugsys maximum utility estimated using
maximum utility estimates open nodes Equation 5:


U = max max (wf f (n) + wt d(n) delay texp ), U ({}, 0)
(7)
nopen

3. Note expansion time constant general, includes time add remove elements
data structures open list.

707

fiBurns, Ruml, &

Bugsy(initial , u())
1. open {initial }, closed {}
2.
3.
n remove node open highest u(n) value
4.
n goal, return
5.
add n closed
6.
ns children c,
7.
c goal u(c) < 0 old version c open closed
8.
skip c
9.
else add c open
10.
expansion count power two
11.
re-compute u(n) nodes open list using recent estimates
12.
re-heapify open list
13. loop step 3
Figure 2: Pseudo-code Bugsy.
estimate U found, would possible substitute U Equation 6
estimate u (n), utility outcome expanding node open list.
However, Bugsy going expand one node, need estimate u (n)
open node; Bugsy simply expands node best estimated outcome.
Additionally, instead computing maximization Equation 7 scratch time
expand node, Bugsy simply orders open list u(n) = (wf f (n) + wt
d(n)delay texp ), iteration popping node maximum u(n) expansion.
way, algorithm directly attempts maximize utility.
Recall Figure 1, shows two paths initial node, A, goal node, E.
Bugsy accounts distance utility function, find shorter path A,
D, E utility function sufficiently emphasizes finding solutions quickly finding
cheaper solutions. hand, utility function gives preference finding
cheap solutions Bugsy spend extra search time find cheaper path, A,
B, C, E.
5.2 Implementation
Figure 2 shows high-level pseudo-code Bugsy. clarity, code elides details
computing u(n) values. algorithm proceeds A*, selecting open node
highest u(n) expansion (line 3). node goal, returned solution
(line 4), otherwise node put closed list (line 5) children generated.
new child put onto open list (line 9) except duplicate nodes nodes
expansion estimated negative utility (which occurs utility returning
solution greater continuing search); discarded (lines 78).
Bugsy estimates current expansion time expansion delay online,
estimates change expansion. Instead re-sorting open list
expansion, Bugsy re-sorts whenever number nodes expanded power
708

fiHeuristic Search Time Matters

two, utility open node re-computed using latest set estimates
texp expansion delay (as described Section 3.3), open list re-heapified
(lines 1012). describe re-sorting step greater detail Section 5.5.
5.3 Stopping
Bugsy orders open list decreasing order u(n), stops searching maximum estimated utility less returning empty solution. may
possible continue searching anytime fashion first goal found,
utility perspective correct approach. prove here:
Theorem 1 Assuming expansion time texp constant, h admissible, exp never
overestimates expansions go, time Bugsy finds first solution, s,
solutions Bugsy would find beneath remaining nodes would result less utility
immediately returning s.
Proof: Let current time Bugsy found solution s. utility returning
U (s, ) = u (s) = (wf f (s)+wt ), u (s) utility returning now,
f (s) cost solution s. Note h admissible goal, h(s) = 0,
g(s) = g (s), f (s) = f (s), therefore u(s) = u (s). exp never overestimates
expansions go exp(s) = 0. Since chosen expansion u(n) u (s) every
node n open list.
Let t(n) minimum amount additional time Bugsy requires find solution
beneath unexpanded node n. t(n) texp since Bugsy must least expand n.
node n open list, best utility Bugsy could achieve going straight
cheapest goal n is:
u (n) = (wf f (n) + wt (t(n) + ))

(wf f (n) + wt (t(n) + )), since f (n) f (n) due admissibility h

(wf f (n) + wt (exp(n) texp + )), since exp never overestimates

= u(n), definition u(n)

u (s), since u (s) = u(s) chosen expansion, n

justifies Bugsys strategy returning first goal node selects expansion.
noted Bugsys estimate exp(n) = delay d(n) lower bound,
see later sections, stopping criterion performs quite well practice.
5.4 Heuristic Corrections
Many best-first search algorithms use admissible heuristic estimates never overestimate
true cost go. proof optimality A* proofs bounded suboptimality
bounded suboptimal search algorithms rely crucially admissibility property
heuristic. Bugsy fixate cost-optimal solutions guarantee bounded
cost. Instead, Bugsy attempts optimize utility function solution cost
one two terms. Since strict cost guarantees, Bugsy free drop
admissibility requirement informed inadmissible estimates available.
709

fiBurns, Ruml, &

Thayer, Dionne, Ruml (2011) show inadmissible estimates provide better
performance bounded suboptimal search. One technique attempts correct
heuristic estimates on-line using average single-step error heuristic values
node best child. Thayer et al. show technique provides good
search guidance, actually less accurate estimating true cost-to-go values
standard admissible heuristics. Bugsy, undesirable, need
good guidance, proper estimates. Thayer et al. show learning heuristic
off-line linear regression provide accurate estimates. Unfortunately, using
off-line training would negate one Bugsys main benefits. matter empirical
evaluation whether techniques provide better performance Bugsy.
Section 6.5, show using standard admissible heuristics often gives best
performance anyway.
5.5 Resorting
Instead requiring off-line training previous approaches, Bugsy uses on-line
estimates order nodes open list. First, many analyses regard texp
constant, practice depend log-time heaps, cache behavior, multiprogramming overhead, among factors, implementation Bugsy estimates texp
global average computed search. Second, Bugsys expansion delay estimate
calculated global average difference expansion count node
generated expanded; must done on-line. Unfortunately,
on-line estimates may change node expansion, navely using latest estimates
compute u value newly generated nodes lead poor performance.
due comparisons used order open list: instead fair comparisons based
estimated utility node, recent fresh estimates new nodes
compared old possibly stale estimates nodes open
long time.
alleviate problem, implementation Bugsy uses two sets estimates:
one stable set used order open list, one ever-changing set maintaining
recent estimates. certain points throughout search, Bugsy copies upto-date estimates stable set, recomputes utility values open nodes,
re-sorts open list. open list implemented binary heap re-establish
heap property linear time number elements heap. Unfortunately,
would still expensive every node expansion, so, instead, Bugsy reorders
open list exponentially less frequently search progressesit reorders
number expansions power two. prove logarithmic scheme
adds constant amount overhead per-expansion amortized entire search.
Theorem 2 search space grows geometrically finite branching factor,
overhead reordering open list power-of-two expansions constant expansion amortized search.
Proof: Let b maximum branching factor. maximum number nodes
open list n expansions N (n) = bn n = n(b 1). total cost
710

fiHeuristic Search Time Matters

re-sorting n expansions than:
lg n

X
i=0

lg n


O(N (2 )) =

X
i=0

O(2i (b 1)), definition N
lg n

= c(b 1)

X

2i , c > 0, definition

i=0
lg n+1

= c(b 1)(2

1), identity

c(b 1)(2 2lg n 1)

Pj


i=0 2

= 2j+1 1

= c(b 1)(2n 1)

= O(n)


So, overhead per-expansion constant amortized expansions.
matter empirical evaluation determine constant overhead detrimentalwe
address Section 6.4.

6. Experimental Evaluation
techniques discussed involve approximations estimations may may
work well practice. section, present results experimental comparison
techniques better understand performance. algorithms
domains implemented C++; source code available https://github.com/
eaburns/search.
6.1 Overview
following sections, answer several questions experimentally. First, would
ensure monitored ARA* algorithm performing best comparing
profile learned off-line oracle. see, off-line profile,
estimate true profile algorithm, quite well-informed.
Section 5.5, proved re-sorting adds constant overhead per-expansion
amortized entire search. matter empirical evaluation determine
whether benefits outweigh overhead. experiments show re-sorting
logarithmic schedule greatly outperforms Bugsy without re-sorting.
Section 5.4 pointed Bugsy require admissible heuristic estimates,
fact may perform better inadmissible, accurate heuristics. show
Bugsy performs admissible heuristics, two different types corrected
heuristics. Overall, conclude best configuration Bugsy standard
admissible heuristics.
discussed expansion delay Section 5.1. show results demonstrate
using expansion delay better simply using estimate expansions
goal. compare two variants Bugsy: one ignores newly generated nodes
found already closed list (we call duplicate nodes) one
reinserts nodes onto open list better utility estimates
711

fiBurns, Ruml, &

previously closed version. Ignoring duplicates always performs better domains,
others performs better preference short search times.
Then, compare A*, Speedy search, monitored ARA*, weighted A* learned
weight, Bugsy. find simplest approach learning good weight
weighted A* gives best performance. find Bugsy, doesnt use
off-line training, performs well monitored ARA*, use off-line
training. Therefore, training instances available, recommend simple weighted
A* approach weight selected based performance training set.
training instances available Bugsy algorithm choice.
Lastly, compare Bugsy real-time search DTA* platform pathfinding domain. experiments, Bugsy achieves best utility.
6.2 Domains
order verify results hold variety different problems, performed
experiments four different domains. domains used described briefly
following paragraphs, detailed descriptions given Appendix B.
6.2.1 15-Puzzle
15-puzzle popular heuristic search benchmark small branching factor
duplicates. domain, used reasonably informed Manhattan distance
heuristic, implementation followed heavily optimized solver presented Burns,
Hatem, Leighton, Ruml (2012). ran 100 instances created Korf (1985),
plots including A* use results 94 instances solvable A* 6GB
memory.
6.2.2 Pancake Problem
pancake problem another standard puzzle large constant branching factor.
experiments, used instances 50 pancakes, gap heuristic (Helmert,
2010). Since many problems difficult A*, used IDA* instead A*
domain.
6.2.3 Platform Pathfinding
platform domain pathfinding domain creation dynamics based
2-dimensional platform-style video game, player must jump platforms
traverse maze. Video games often naturally element time pressure.
large state-space many cycles, reasonably informed heuristic based
visibility navigation. instances used experiments created randomly, using
generator described Appendix B. domain particular interest
action costs given units time (each action 50ms), objective minimizing
goal achievement time expressed linear combination search time solution
cost.
712

fiHeuristic Search Time Matters

6.2.4 Grid Pathfinding
Grid pathfinding popular heuristic search benchmark, motivated robotics video
games. experiments, used two different cost models, two different movement
models. cost models standard unit-cost model life-cost model
assigns action costs shortest, direct path expensive longer,
circuitous path. captures popular adage time money. Instances
5,0005,000 grids uniformly distributed obstacles. heuristics based
Manhattan distance heuristic four-way grids, octile distance heuristic eightway grids. octile distance heuristic simple modification Manhattan
distance

multiplies shorter horizontal vertical displacement 2 accounts
eight-way move costs.
6.3 Anytime Profile Accuracy
want ensure implementation works well training instance sets
representative enough monitored ARA* perform best. subsection,
evaluate accuracy stopping policies created using estimated anytime profiles
comparing oracle. Since stopping policy guaranteed optimal
true algorithm profile, matter empirical study determine whether
estimated profile lead good policy.
estimate profile used monitored version ARA*, ran ARA*
6GB memory limit convergence 1,000 separate test instances domain.
Next, created histogram discretizing costs times solutions
10,000 bins (100 100). experimented different utility functions varying
ratio wf /wt Equation 1. Small values wf /wt give preference finding solutions
quickly, whereas large values prefer finding cheaper solutions. case platform
game, example, viewed way change speed agent
moves: slow agent might benefit search order find shorter path,
fast agent execute path quickly, may prefer find feasible solution fast
possible.
Figure 3 shows results experiment. box plots represent distribution
utility values found ARA* using estimated stopping policy, given factor
oracles utility. oracle finds solutions anytime algorithm converges
optimal solution, picks solution would maximized utility
function. Since utility values negative, larger factors represent smaller (more negative) utilities thus worse outcome. boxes surround second third quartiles,
whiskers extend extremes, circles show values 1.5
inter-quartile range outside box. center line box shows median,
gray rectangles show 95% confidence interval means. box represents
different wf /wt shown x axis. reference line drawn across = 1 (the
point oracle estimated policy performed equally well), many cases
boxes narrow indistinguishable line.
points figures lie slightly = 1 line, indicating instances
oracle performed worse estimated policy. possible due
variance solving times. experiment, ARA* runs used compute oracles
713

fiBurns, Ruml, &

platform
factor oracle

factor oracle

15-puzzle
2
1.6
1.2
1e-4

1e-3 1e-2 1e-1
cost/time preference

3
2
1

1

1e-4

1e-3
1e-2
1e-1
cost/time preference

4-way unit grids

50-pancake
factor oracle

1.3

factor oracle

1

1.2
1.1
1

1.08
1.04
1
0.96

1e-4

1e-3 1e-2 1e-1
cost/time preference

1

1e-4

1e-3 1e-2 1e-1
cost/time preference

8-way unit grids

1

4-way life grids
factor oracle

factor oracle

1.014
1.2
1.12
1.04

1.008
1.002
0.996

1e-4

1e-3 1e-2 1e-1
cost/time preference

1

1e-4

1e-3 1e-2 1e-1
cost/time preference

1

8-way life grids
factor oracle

1.012
1.008
1.004
1
1e-4

1e-3 1e-2 1e-1
cost/time preference

1

Figure 3: Comparison optimal stopping policy learned stopping policy.
714

fi15-puzzle

1

0.6

0

0
-6

-3

log10 cost/time preference

0

-6

0.6

0
-3

log10 cost/time preference

0.5

0
-6

0

0

1.6

0.8

0
-9

-6

log10 cost/time preference

-3

log10 cost/time preference

0

8-way life grids
log10 factor best utility

1.2

-6

-3

log10 cost/time preference

Resort
Resort

1

4-way life grids
log10 factor best utility

8-way unit grids
log10 factor best utility

4-way unit grids

platform
1.2

log10 factor best utility

2

log10 factor best utility

log10 factor best utility

Heuristic Search Time Matters

-3

1

0
-9

-6

log10 cost/time preference

-3

Figure 4: Bugsy: Resorting open list (circles) vs (boxes).
utilities occasionally found solutions slowly ARA* runs using estimated
stopping policy. words, caused non-determinism inherent utility
function depends solving time. obvious figure, instances quite
rare usually happened small values wf /wt , miniscule time differences
large effect utility.
results, conclude monitored ARA* implementation performs
quite well, stopping policy often stopped best solution available
emitted underlying anytime algorithm.
6.4 Resort Resort?
Section 5.5 proved re-sorting Bugsys open list power-of-two expansions
added constant overhead per-expansion amortized search. matter
empirical evaluation determine whether overhead worth effort.
re-sorting schedules possible, tried re-sorting power-of-two expansions.
Figure 4 shows utility achieved Bugsy without re-sorting.
x axes show wf /wt ratio determining preference solution cost search time
log10 scale. previous plots, smaller values indicate preference faster
search times larger values indicate preference cheaper solutions. axes show
factor utility achieved best technique instance, log10
scale. value log10 1 = 0 indicates best utility achieved technique given
715

fiBurns, Ruml, &

instance; values greater zero indicate less utility. Points show mean value
test instances error bars giving 95% confidence intervals. plots,
see re-sorting open list led significant improvements domains.
pancake puzzle, Bugsy without re-sorting unable solve instances within
6GB memory limit. remaining experiments, always enable re-sorting
exponential schedule.
6.5 Heuristic Corrections
Section 5.4, mentioned Bugsy require admissible heuristic estimates,
provides guarantees solution cost. section compare Bugsy using
standard admissible heuristics Bugsy using on-line off-line corrected heuristics.
Following Thayer et al. (2011), on-line heuristic correction used global average
single-step heuristic error node best offspring, off-line heuristic
linear combination h, g, depth, d, node. coefficients term
off-line heuristic learned solving set training problems using linear
least squares regression.
comparison shown Figure 5. plots style Figure 4. Typically on-line correction technique performed worstsome times significantly worse
two. attribute poor accuracy observed Thayer et al.
(2011). problems, 15-puzzle 8-way unit-cost grid pathfinding, off-line correction technique performed best, general simple admissible
heuristics best competitive best. remainder experiments, chose use simplest variant without corrections require
off-line training (which one Bugsys main benefits), never worst
often best near best.
6.6 Expansion Delay
Section 5.1 described simply using approximation exp(n), number
nodes expanded arrive goal beneath node n, inaccurate. search algorithm
expand nodes along path goal, instead vacillates
different solutions. account search vacillation, choose estimate exp(n) =
delay d(n), delay average expansion delaythe average number nodes
expanded search makes progress along single path goal. subsection,
show experimentally using expansion delay provides much better performance
using alone.
Figure 6 shows two versions Bugsy: one uses expansion delay, labelled
Exp. Delay, one not, labelled Without Exp. Delay. clear
figure using expansion delay beneficial. Also, see right side
plots, cheaper solutions preferred short search times, using expansion delay
using itself. wf relatively large compared
wt utility functions, exp(n) term little influence utility estimates.
716

fiHeuristic Search Time Matters

15-puzzle

0.6

log10 factor best utility

log10 factor best utility



log10 factor best utility

50-pancake

platform
Online
None
Offline

0.2

0.1

0

0
-6

-3

-3

log10 factor best utility

log10 factor best utility

0.06

0
-3

0.04

0
-6

-3

0

log10 cost/time preference
8-way life grids

log10 factor best utility

4-way life grids
log10 factor best utility

0

0.08

0

log10 cost/time preference

0.1

0.05

0
-6

-2

log10 cost/time preference
8-way unit grids

0.12

-9

-4

0

log10 cost/time preference

4-way unit grids

-6

0.08

0
-6

0

log10 cost/time preference

0.16

-3

0.06

0.03

0
-9

log10 cost/time preference

-6

-3

log10 cost/time preference

Figure 5: Bugsy: Heuristic corrections.

6.7 Duplicate Dropping
Suboptimal search algorithms expand nodes strict order increasing f . Consequently, expand node, later re-generate node via cheaper path.
call re-generations duplicates, generated via cheaper paths
say inconsistent, current path cost (and subsequently cost
paths descendants) expensive necessary (Likhachev et al.,
2003). face inconsistent nodes, search algorithm put already expanded
node back open list cost accounts new, cheaper path.
node comes front open list, re-expanded inconsistency
717

fiBurns, Ruml, &

platform

2.4

1.6

50-pancake

1.2

log10 factor best utility

log10 factor best utility

log10 factor best utility

15-puzzle

0.8

0.4

0

0
-6

-4

-2

log10 cost/time preference

0

-6

-4

-2

log10 cost/time preference

Without Exp. Delay
Exp. Delay

log10 factor best utility

log10 factor best utility

0.4

-5

0

-3

-4

-2

-1

log10 cost/time preference

0

8-way unit grids

0

0.9
0.6
0.3
0

-6

-4

-2

log10 cost/time preference

0

-6

-4

-2

log10 cost/time preference

4-way life grids

0

8-way life grids

1.8

log10 factor best utility

log10 factor best utility

0.8

0

4-way unit grids
1.2

1.2

1.2

0.6

0

1.8

1.2

0.6

0
-8

-6

-8

-4

log10 cost/time preference

-6

-4

log10 cost/time preference

Figure 6: Bugsy: Expansion delay.
propagate descendants. Unfortunately, lot
inconsistencies, search algorithm spend lot time re-expanding
nodes again. alternative technique simply ignore inconsistency
drop duplicate nodes generated. Dropping duplicates reduce
search effort needed find goal cost finding expensive solutions. Whether
dropping duplicates beneficial typically depends domain (Thayer & Ruml,
2008).
Figure 7 shows comparison Bugsy without duplicate dropping.
platform, tiles, pancake domains using duplicate dropping nearly always better
re-expanding duplicates. grid pathfinding problems,with notable excep718

fiHeuristic Search Time Matters

0.15

0.1

0.05

50-pancake
log10 factor best utility

platform
log10 factor best utility

log10 factor best utility

15-puzzle
0.8
0.6
0.4
0.2

0.24

0.16

0

0
-6

-4

-2

log10 cost/time preference

0

0
-6

-4

-2

log10 cost/time preference

Duplicate Reexpansion
Duplicate Dropping

0.12

0.06

0

-3

-2

-1

0

0.04

0.02
0.01
0

-6

-4

-2

log10 cost/time preference

0

-6

-4

-2

log10 cost/time preference

0

8-way life grids
log10 factor best utility

4-way life grids
log10 factor best utility

-4

log10 cost/time preference

8-way unit grids
log10 factor best utility

log10 factor best utility

4-way unit grids
0.18

-5

0

1.8
1.2
0.6
0

0.018
0.012
0.006
0

-8

-6

-8

-4

log10 cost/time preference

-6

-4

log10 cost/time preference

Figure 7: Bugsy: Duplicate dropping.

tion 4-way life-cost gridsre-expanding duplicate nodes seems give better performance
except solutions needed quickly possible (on left-hand side plots).
reasonable, duplicate dropping tends sacrifice solution cost order
reduce search time. Note also, values axes plots small,
results statistically significant, difference two techniques
grid problems duplicate re-expansion performs better quite small. next
section see A* actually achieves utility many cases
duplicate re-expansion outperforms duplicate dropping.
719

fiBurns, Ruml, &

platform

log10 factor best utility

log10 factor best utility

15-puzzle
0.4

0.2

0

0
-6

-3

log10 cost/time preference

0

-6

-3

log10 cost/time preference

0

log10 factor best utility

50-pancake

pee
ugsy


0.4

0.

0
-4

-

log10 cost/time preference

0

Figure 8: Comparison techniques.

6.8 Comparing Techniques
understand promising configurations techniques studying, finally turn attention comparing them.
Figures 8 9 show comparison three different techniques utility-aware
search. plots larger previous plots improve clarity,
lines. plots include A*, Speedy Search, Bugsy, ARA* monitoring
(ARA*), weighted A* weight chosen automatically different utility
function set 1.1, 1.5, 2, 2.5, 3, 4, 6, 10 (wA*). would expect,
preference shorter search times (on left-end x axis), A* performed poorly,
stubbornly stuck optimal solutions. Speedy search, however, performed quite well.
preference shifted toward desiring cheaper solutions, A* began better whereas
Speedy worse. utility-aware techniques much robust A*
720

fiHeuristic Search Time Matters

8-way unit grids
log10 factor best utility

log10 factor best utility

4-way unit grids

0.1

0

0.1

0
-6

-3

log10 cost/time preference

0

-6

0

log10 factor best utility

8-way life grids

log10 factor best utility

4-way life grids

-3

log10 cost/time preference

0

0
-9

-6

log10 cost/time preference

-9

-3

-6

log10 cost/time preference

-3

Figure 9: Comparison techniques (continued).
Speedy, neither take users preference search time solution cost
account all.
utility-aware techniques, Bugsy weighted A* automatically
selected weight performed best. Bugsy better 15-puzzle
platform domain. grid problems, Bugsy weighted A* roughly
performance right side x axes. left side, Bugsy tended get worse
relative utility-aware techniques, ARA* anytime monitor often
best performer. However, ARA* performed significantly worse middle
right-hand portion plot domains, leading us recommend weighted
A* technique simpler robust approach.
utility-aware techniques often performed well A* low-cost solutions
preferred. fast solutions preferred, techniques sometimes outperformed
Speedy search. likely indicates solution cost still played roll final utility
721

fiBurns, Ruml, &

log10 factor best utility

orz100d

0.2

0.1

0
-6

Bugsy

ARA*

-3

0

log10 cost/time preference
wA*
A*
Speedy

Figure 10: Grid pathfinding video game map.
left-most points plots. ARA* tended achieve greater utility
Bugsy solutions needed quickly, cheaper solutions preferred,
Bugsy tended better ARA*. domains, ARA* spike low utility
ratios 0.001, 1, peak appearing 106 103 life-cost
grids. peak approximately coincides utility functions estimated
profile performed worse oracle shown Figure 3, possibly indicating
1,000 training instances required utility functions.
Overall, utility-aware techniques able achieve much greater utility
utility-oblivious A* Speedy algorithms. terribly surprising. Surprisingly,
results suggest simple parameter tuning technique often give best
performance representative set training instances available. not, Bugsy
algorithm choice performs well require off-line training.
Indeed, putting reasoning search time search algorithm itself, Bugsy
competitive techniques requiring previous experience.
6.9 Limitations
previous set experiments, saw utility-aware algorithms outperformed
Speedy search A* wide range utility functions. section, look
one domain tends case: video game grid maps.
Video games one main motivations research grid pathfinding problems.
Sturtevant (2012) observed grid maps created game designers often exhibit
different properties maps generated algorithmically. Figure 10 shows comparison
Bugsy, monitored ARA*, weighted A* automatically selected weight, Speedy,
722

fiHeuristic Search Time Matters

Figure 11: Grid pathfinding video game map.

150
100
50

200

% Speedy time

200

planning time

execution time

200

% Speedy time

% Speedy nodes

nodes expanded

150
100
50

0

8

16

instance

24

150
100
50

0

8

16

instance

24

0

8

16

instance

24

Figure 12: Nodes expanded, search time, execution time.
A* Dragon Age Origins map orz100d benchmark set Sturtevant.
map shown Figure 11. fairly wide-open area top, closed-off
bottom half containing rooms hallways. format plot figure
previous subsection. see, A* gave best performance
large range utility functions, Bugsy actually never outperformed Speedy A*
entire experiment (neither ARA*, wA* gave best performance
single data point). hypothesized Bugsys poor performance
problems easy solve, Bugsys extra computation overhead, small,
prominent.
explore hypothesis, plotted performance Bugsy given difference
Speedy using single utility function given wf = 106 , wt = 1.
723

fiBurns, Ruml, &

left-most utility function Figure 10, function Speedy search performed
best Bugsy performed poorly. Figure 12 shows number nodes expanded,
time spent executing, time spent searching Bugsyas percentages
equivalent values Speedy search. data points gathered random sample
25 instances Sturtevants (2012) scenario set orz100d map. Values
line 100% represent instances Bugsy expanded fewer nodes spent less
time searching executing, values line represent instances Bugsy
expanded nodes spent time Speedy. x axes shows rank
instances sample increasing order optimal solution lengths.
see Figure 12, Bugsy expanded number nodes
similar execution times Speedy. problems larger optimal solution
costs Bugsy slightly less execution time. major difference performance
two algorithms, however, shown right-most plot see Bugsy
required search time Speedy search almost every instance. Since Bugsy
Speedy expanded number nodes, additional time must due
Bugsys small amount extra overhead incurred re-sorting computing utility.
conclude that, barring extra overhead, Bugsy would performed well
best performer utility function. domains node expansion heuristic
computation isnt simplistic, overhead would insignificant.
6.10 Training Set Homogeneity
Section 6.8 showed weighted A* approach outperformed techniques
domains, notable exception platform domain 15-puzzle,
Bugsy best. Additionally, compared domains, weighted A* technique
performed relatively poorly video game pathfinding (cf. Figure 10 wA* outperformed utility oblivious approaches points except one). believe
poor performance wA* domains due heterogeneous training sets.
verify this, looked mean standard deviation optimal path lengths
problems domains. optimal path length viewed proxy
problem difficulty, high standard deviation statistic points diverse
set instancessome easy solve, quite difficult. platform
video game path finding domains, standard deviation optimal path length
greater 50% mean; twice domains. Note that,
domains video game map, variety layout different areas map
means instances inherently differ characteristicsmerely gathering
instances produce homogeneous set. evidence supports hypothesis
weighted A*s performance greatly hindered situations representative
training set available.
6.11 Real-time Search
main focus study algorithms off-line searchthey find entire paths
goal execution begins. real-time search (Korf, 1990), search execution
happen parallel, agent allowed fixed amount time plan
must perform action. Real-time search possibility efficient
724

fiHeuristic Search Time Matters

off-line search terms goal achievement time, search happens
parallel execution, goal achievement time simply execution time plus
small amount time required find first action. contrast off-line
approach goal achievement time sum entire search time execution
time. situations, however, starting execution complete plan
goal acceptable, may lead agent dead-end longer
reach goal, real-time search may applicable. Examples domains deadends include robotics, manufacturing (Ruml, Do, Zhou, & Fromherz, 2011), spacecraft
control: exactly applications involving high value danger, automation
worthwhile. cases, desirable find entire plan guaranteed reach
goal, execution begins.
Hernandez, Baier, Uras, Koenig (2012) introduce model comparing real-time
algorithms off-line techniques A*, called game time model. game time
model partitions time uniform intervals, agent execute single action
interval. Path planning happen parallel execution (the agent
plan step execution step t-1), goal move agent start
location goal location time intervals possible, minimizing goal achievement
time, objective discuss Section 1. game time model special
case utility functions considered paper solution cost given discrete,
fixed-duration units time.
Real-time search provides two benefits: first, may possible reduce goal
achievement time allowing search execution happen time, second,
agent start moving toward goal right awaya necessary property video games.
leaves us question whether real-time search algorithms achieve
better goal achievement time off-line utility-aware methods. one hand, realtime search algorithms spend little time searching without making progress toward
goal. hand, real-time search algorithms tend make decisions based
local information find costly solutions. results, Hernandez et al.
report best approach solves problems initially-known grid maps
number time intervals A*. previous section, showed utilityaware techniques outperformed A* utility functions. section, compare
state-of-the-art real-time search algorithm called LSS-LRTA* (Koenig & Sun, 2009)
Bugsy platform pathfinding domain.4
previous experiments, tested algorithms variety values
ratio wf /wt . Since interested goal achievement time, set wt = 1
calculate search time units seconds. means wf represents number
seconds one unit execution costthe speed agent. set real-time
constraint LSS-LRTA* allowed plan duration one unit
execution, always next action ready execution currently
executing action completed.
4. compare Time-bounded A* (TBA, Bjornsson, Bulitko, & Sturtevant, 2009), method
performed best Hernandez et al. (2012), platform domain forms directed search
graph, TBA* works undirected search graphs. compare newer
f -LRTA* (Sturtevant, 2011), perform well LSS-LRTA* platform domain,
directed edges.

725

fiBurns, Ruml, &

platform
log10 factor best GAT

2.4

LSS-LRTA*
A*
Speedy
Bugsy

1.6

0.8

0
-4

-3

-2

log10 w_f / w_t

-1

0

Figure 13: Comparison Bugsy real-time search.
Figure 13 shows results comparison. see, LSS-LRTA* gives rather
poor performance; goal achievement times nearly match A*, Bugsy able
achieve goal much faster. shows simply allowing search execution
take place parallel sufficient reduce goal achievement time; better
spend time searching solution way goal alternative spend
long time executing poor plan.
6.12 Decision-theoretic A*
Decision-theoretic A* (DTA*, Russell & EricWefald, 1991) utility-aware algorithm
allows concurrent search execution. based ideas real-time heuristic
search, unlike traditional real-time search, action emitted fixed
amount search, DTA* decides stop searching emit action using decisiontheoretic analysis. time single best top-level action lowest cost
estimate. search emits action decided utility emitting
action outweighs utility search. DTA* uses approximation (found
off-line training) solution cost estimate top-level action improves
additional search. Using consistent heuristic, estimate increase (Nilsson,
1980), DTA* stops searching decides time required raise best
actions estimated cost point longer best action costly
expected gain determining different best action.
Compared Bugsy, DTA* relatively myopic considers cost
search involved selecting individual actions. DTA* consider additional search
required solution path commits choosing action. Bugsy
uses expansion delay reason required search effort entire
726

fiHeuristic Search Time Matters

log10 factor best utility

platform (small instances)
Speedy
A*
DTA*
Bugsy

1.2

0.8

0.4

0
-4

-3

-2

log10 w_f / w_t

-1

0

Figure 14: Comparison Bugsy DTA*.
path beneath node, DTA* reasons search required determine best
action emit right now.
implemented DTA* assess utility-aware real-time search might compare
utility-aware off-line search planning time pressure. Figure 14 shows
results comparison DTA* Bugsy platform pathfinding domain.
Unfortunately, DTA* fairly poor performance, experiment used smaller instances
consisting 25x25 blocks, instead 50x50 block instances used previous experiments.
Following Russell EricWefald (1991), gathered off-line training data DTA* using
states sampled uniformly probability 0.1 among visited real-time
search algorithm. Russell EricWefald (1991), used algorithm called SLRTA*,
used LSS-LRTA*, current state art. training set consisted
100 25x25 platform instances. verified implementation ensuring
compared favorably A* Speedy search 15-puzzlethe domain used
Russell EricWefaldusing variety different utility functions. Figure 14,
see DTA* often significantly worse utility Bugsy, often performing
slightly better Speedy search, sometimes performing worse A*, example,
cheap solutions desired.

7. Related Work
Bugsy uses estimates search time select whether terminate continue, select node expand, may said engaging metareasoning,
is, reasoning reasoning action take. much work
topic AI since late 1980s (Dean & Boddy, 1988) continuing today (Cox & Raja,
2011).
727

fiBurns, Ruml, &

Dean Boddy (1988) consider problem faced agent trying respond
predicted events time constraints. Unlike setting, concern
choosing much time allocate prediction much allocate deliberation. solve type time-dependent planning problem, suggest use (and
coined term) anytime algorithms. Unlike anytime-based techniques discussed
previously, attempt find stopping policy optimize utility function, Dean
Boddy used anytime algorithms means allowing different allocations time
predicting deliberation. Later, Boddy Dean (1989) show anytime
algorithms time-dependent planning framework used delivery agent
must traverse set waypoints grid, allocating time ordering
waypoints planning used travel them. Dean, Kaelbling, Kirman,
Nicholson (1993) adapt technique scheduling deliberation execution
planning face uncertainty.
Garvey Lesser (1993) present design-to-time methods advocate using available time find best possible solution. Unlike anytime approaches interrupted time, design-to-time method requires time deadline given
upfront. way, algorithm spend time focusing finding single
good solution, instead possibly wasting time finding intermediate results. Design-to-time
differs contract techniques DAS (Dionne et al., 2011), designto-time framework must predefined set solvers known (or predictable)
solution times costs. design-to-time method select appropriate solver
problem deadline, possibly interleaving different solvers deemed appropriate.
information cost solutions times, design-to-time methods require, usually unavailable must learned off-line. Techniques DAS Bugsy,
hand, use information computed on-line.
Hansen, Zilberstein, Danilchenko (1997) show heuristic search inadmissible
heuristics used make anytime heuristic search algorithms. techniques
presented paper, consider problem trading-off search effort solution
quality. end, propose one possible optimization function anytime heuristic
search search attempts maximize rate algorithm decreases solution
cost. anytime monitoring technique shown Section 3.1, evaluation function
relies learning profile anytime algorithm offline. analysis 8puzzle, conclude that, method good anytime behavior, little
benefit using instead trial-and-error-based hand tuning. surprising given
strong performance demonstrated offline-tuned weighted A* experiments.
recently, Thayer et al. (2012) proposed approach minimizing time solutions anytime algorithms. demonstrate new state-of-the-art
algorithm performs well wide variety domains, robust
previous approaches. Bugsy, technique relies using heuristics estimate
search effort required find solutions. However, focus solutions
require least amount effort, optimize trade-off search time
solution cost.
addition controlling expansion decisions, metareasoning used
heuristic evaluation. Often search algorithms use maximum value computed
multiple heuristics accurate estimate cost goal. problems,
728

fiHeuristic Search Time Matters

domain-independent planning, heuristics quite expensive, increased accuracy
gained via maximizing many heuristics may worth increased computation
time. Domshlak, Karpas, Markovitch (2010) introduce on-line learning technique
decide single heuristic compute state, instead computing many
taking max.
related work using metareasoning control combinatorial search done
area constraint satisfaction problems (CSPs), boolean satisfiability (SAT). Tolpin
Shimony (2011) use rational metareasoning decide compute value ordering
heuristics CSP solver. focus work value ordering heuristics
gave solution count estimates; solver bothered compute heuristic decision
points deemed worthwhile. experiments demonstrate new
metareasoning variant outperformed variant always computed heuristic
one computed heuristic randomly. Horvitz, Ruan, Gomes, Kautz, Selman,
Chickering (2001) apply Bayesian structure learning CSPS SAT problems.
consider problem quasi-group completion, unlike Tolpin Shimony (2011)
use on-line metareasoning control search, use off-line Bayesian learning set
hand-selected variables predict whether instances long short running.
lot work attempting estimate size search trees offline (Burns & Ruml, 2013; Knuth, 1975; Chen, 1992; Kilby, Slaney, Thiebaux, & Walsh,
2006; Korf, Reid, & Edelkamp, 2001; Zohavi, Felner, Burch, & Holte, 2010).
related topic, concerned estimating search effort entire search
performed. One may imagine leveraging technique predict search time
algorithm Bugsy. Unfortunately, estimation methods rather costly
terms computation time, suitable estimator needed every
single node generation. Another possibility use off-line estimations find parameters
affect performance search given domain. knowledge could helpful
creating representative training sets used algorithms weighted A* anytime
monitoring, require off-line training.

8. Conclusions
investigated utility-aware search algorithms take account user-specified
preference trading-off search time solution cost. presented three different techniques
addressing problem. first method based previous work area
learning stopping policies anytime algorithms. best knowledge,
first demonstrate techniques area heuristic search. second method
novel use algorithm selection bounded-suboptimal search chooses correct
weight use weighted A* given utility function. last technique
presented Bugsy algorithm. Bugsy technique three
require off-line training.
performed empirical study techniques context heuristic search,
investigated effect parameters algorithm performance, compared
different techniques other. Surprisingly, simplest technique learning
weight weighted A* able achieve greatest utility many problems, outperforming conventional anytime monitoring approach. surprisingly, Bugsy,
729

fiBurns, Ruml, &

algorithm use off-line training, performed well off-line
techniques advantage learning thousands off-line training instances.
representative set training instances available Bugsy algorithm
choice. Overall, utility-aware methods outperformed A* Speedy search
wide range utility functions. demonstrates heuristic search longer
restricted solely optimizing solution cost, freeing user choice either slow
search times expensive solutions.
Unlike previous methods trading deliberation time solution quality, Bugsy considers trade-off directly search algorithmdeciding, node, whether
result expansion worth time. new approach provides alternative anytime algorithms. Instead returning stream solutions relying external
process decide additional search effort longer justified, search process
makes judgments based node evaluations available it. empirical
results demonstrate Bugsy provides simple effective way solve shortest-path
problems computation time matters. would suggest search procedures
usefully thought black boxes controlled external termination policy
complete intelligent agents, informed users goals acting rationally
basis information collect directly maximize users utility.

Acknowledgments
greatly appreciate feedback suggestions Shlomo Zilberstein Scott Kiesel.
would think Richard Korf pointing work Shekhar Dutta
(1989). grateful support NSF (grant 0812141 grant 1150068),
DARPA CSSG program (grant D11AP00242), University New Hampshire
Dissertation Year Fellowship. preliminary version Bugsy presented Ruml
(2007); see Appendix A. Elisabeth Crawford assisted original version
summer internship PARC.

Appendix A. Previous Bugsy
previous version Bugsy proposed Ruml (2007), however, early
realization differs substantially one presented here. used aggressive duplicate
re-expansion, heuristic corrections, used estimate remaining expansions
goal reached. Section 6.7 showed duplicate dropping outperforms duplicate re-expansion many domains. found inadmissible heuristics performed
poorly (cf Section 6.5) practice, even compared standard admissible estimates. Also, temper inadmissible corrected estimates, previous Bugsy
multiplied heuristic estimates arbitrary weight (min(200, (wt /wf ))/1000); version require ad hoc fix. discussed poor estimate number
remaining expansions Section 5.1, Section 6.6 showed, experimentally,
using expansion delay performs much better using alone.
Recall Bugsy uses f approximate cost path length best
utility outcome enabled expansion node. Note, however, f
function used throughout paper refer cheapest solution beneath node n,
730

fiHeuristic Search Time Matters

may goal results maximum utility. better assess available
outcomes, previous version Bugsy computed two utility estimates node: one
cheapest solution beneath node nearest solution terms
node expansions. non-unit-cost domains, two estimates may differ. example,
life-cost grid pathfinding domains, cheapest solution usually involves moving toward
top grid actions cheap, nearest solution follow straight-line
path goal. general, large number different solutions
search node, solutions may cover whole spectrum different cost/time trade-offs.
considering cheapest solution, done implementation,
may possible find solutions better utility. hand, may
costly compute multiple heuristics node, whether modification
beneficial depends domain.

Appendix B. Domains
performed experiments variety different domains, describe
detail here.
B.1 15-Puzzle
15-puzzle one popular benchmark domains heuristic search algorithms.
consists 4-by-4 frame 15 tiles placed. One slot board
contain tile, called blank. Tiles above, below, left right
blank may slid blank slot. objective 15-puzzle slide tiles
around order transform initially scrambled puzzle goal state blank
upper-left corner tiles ordered 115 going left right, top bottom.
domain interesting plans hard find, branching factor small
varies little mean 2.13 (Korf et al., 2001), duplicates,
heuristic reasonably informed.
experiments use popular 100 15-puzzle instances created Korf (1985).
plots include A*, however, used 94 instances solvable A* 6GB
memory. average optimal solution length instances 52.4. training
set, generated 1,000 instances using 1 million step random walk back goal
position. used Manhattan distance heuristic, sums vertical horizontal
distance tile must move arrive goal position. implementation follows
heavily optimized solver presented Burns et al. (2012).
B.2 Pancake Puzzle
pancake puzzle (Dweighter, 1975; Gates & Papadimitriou, 1979) another permutation
puzzle. consists stack differently sized pancakes numbered 1N . pancakes
must presented fancy breakfast, chef needs sort originally unordered
stack pancakes continually sticking spatula stack reversing order
pancakes above. Said another way, pancake problem involves sorting sequence
numbers using prefix reversal operations. simple problem interesting
creates search graph large branching factor (the number pancakes minus one).
731

fiBurns, Ruml, &

Figure 15: screenshot platform pathfinding domain (left), zoomed-out image
single instance (right). knight must find path starting
location, maze, door (on right-side left image,
center right image).

experiments, used 25 randomly generated 50-pancake puzzle instances,
training set consisted 1,000 randomly generated instances. used powerful GAP
heuristic Helmert (2010), sums number pairs adjacent pancakes
sequence.
B.3 Platform Pathfinding
platform domain pathfinding domain creation dynamics based
2-dimensional platform-style video game, written partially first author, called
mid5 . left image Figure 15 shows screenshot mid. goal knight
traverse maze initial location, jumping platform platform,
reaches door. Mid open source game available http://code.google.com/p/
mid-game. experiments game physics game ported C C++
embedded C++ search codebase. generated 1,000 training instances
100 test instances using level generator mid. example instance shown
right panel Figure 15. domain unit-cost large state space
well-informed heuristic.
available actions different combinations controller keys may pressed
single iteration games main loop: left, right, jump. Left right move
knight respective directions (holding time never considered
search domain, movements would cancel out, leaving knight
5. author Steve McCoy, drew tile graphics shown Figure 15.

732

fiHeuristic Search Time Matters

place), jump button makes knight jump, applicable. knight jump
different heights holding jump button across multiple actions row
maximum 8. actions unit cost, cost entire solution number
game loop iterations, called frames, required execute path. frame corresponds
50ms game play.
state state space contains x, position knight using doubleprecision floating point values, velocity direction (x velocity stored
determined solely left right actions), number remaining actions
pressing jump button add additional height jump, boolean stating
whether knight currently falling. knight moves speed 3.25 units per
frame horizontal direction, jumps speed 7 units per frame, simulate
gravity falling, 0.5 units per frame added knights downward velocity
maximum 12 units per frame.
details platform domain, please refer source code repository
given start Section 6.
B.3.1 Level Generator
instances used experiments created using level generator mid,
special maze generator builds 2-dimensional platform mazes 5050 grid blocks.
block either open occluded, ensure solvability given constraints imposed
limited jump height, generator builds maze stitching together pieces
hand-created portfolio. piece consists number blocks either free
occluded, start end location traversability ensured within piece.
piece added grid location fits. piece fits
occlude block belongs previously placed piece. maze built using depthfirst procedure: piece selected random fits grid start location
lined end location predecessor placed procedure recurs.
number successors node chosen uniformly range 39 inclusive,
procedure backtracks pieces fit previous block.
maze constructed, blocks belong piece marked occluded.
right image Figure 15 shows sample level generated procedure. source
code level generator available mid source repository mentioned above.
B.3.2 Heuristic
developed heuristic platform domain based visibility navigation
(Nilsson, 1969). maze pre-processed convert grid representation set
polygons representing connected component occluded cells level. space
scaled account movement speed knight; knight fall faster
move horizontal direction, polygons end squished vertically
stretched horizontally. visibility navigation problem solved reverse
four corners goal cell center every non-occluded cell maze.
maintain admissibility, cost edge visibility problem length


visibility line, instead maximum length line divided 2
X displacements end points line. accounts fact
733

fiBurns, Ruml, &

Figure 16: visibility navigation instance platform domains heuristic. visibility path initial state goal state drawn red.

knight bemoving horizontally vertically time,
moving distance 2 scaled space still takes single frame.
search, heuristic value state computed one two different ways.
straight-line path center knight goal occluded
maximum X distances goal scaled travel speed used
heuristic estimate. Otherwise, heuristic cost path visibility graph
center cell contains knights center point minus maximum
X distance (in number frames) knights center point center
cell. Figure 16 shows map right image Figure 15, scaled, broken
polygon components, visibility path initial state goal
state drawn red.
B.4 Grid Pathfinding
final domain grid pathfinding. popular domain video games
robotics, garnered much attention heuristic search community.
experiments, used 5,000x5,000 grids four-way eight-way connectivity
uniform obstacle distributions. four-way connected grids, cell blocked
probability 0.35, eight-way connected grids cells blocked
probability 0.45. consider two different cost models, standard
unit cost model
horizontal vertical moves cost 1 diagonal moves cost 2.
called life cost model, move cost equal row number
move took place, causing cells toward top grid preferred.
life cost model, short direct solutions found quickly, however relatively
expensive, least-cost solution involves many annoying economizing steps (Ruml &
Do, 2007). model viewed instantiation popular belief time
money, one choose incur additional cost shorter simpler path.
combination movement model cost model, generated 25 test instances 1,000
training instances. Finally, used Manhattan distance heuristic four-connected
grids octile distance heuristic eight-connected grids. life cost model
734

fiHeuristic Search Time Matters

heuristics took account fact moving toward top grid back
may cheaper direct path.

Appendix C. Anytime Policy Estimation
challenging write algorithms rely off-line training data. algorithm
behaves unexpectedly, unclear bug implementation, bug
off-line learning procedure, training set merely insufficiently representative.
appendix, describe implemented verified procedure estimating
anytime profile.
Figure 17 shows pseudocode building profile based description given
Hansen Zilberstein (2001). algorithm accepts set solution streams
input, one stream solved instance, proceeds two steps. first step
Count-Solutions function counts number times solution cost
improved upon. function iterates solution (line 5), computes bin
histogram cost value falls (line 7), subsequent solution count
added qqtcounts time step first solution improved second
solution. addition, number total improvements solution time bin
counted qtcounts array. costbin timebin functions bin cost time values
respectively returning integer corresponding index histogram:


q qmin
costbin(q) =
(qmax qmin )/ncost


tmin
timebin(t) =
(tmax tmin )/ntime
.
second step Probabilities function converts counts computed
first step normalized probability values. achieved dividing number
steps solution cost qi improved solution cost qj (qqtcounts)
total number steps solution cost qi improved (qtcounts,
lines 28). probability values smoothed adding half smallest probability
bin representing solution cost improvement. step removes zero-probabilities,
allowing improvement considered. Finally, probabilities normalized
probability non-decreasing-cost solutions current cost time step sum
one (lines 3137). profile computed, saved disk later use
computing stopping policy.
found extremely useful simple way validate policies
debugging implementation. One option create stopping policy, run ARA*
monitoring handful instances handful utility functions verify
gives expected behavior. Unfortunately, approach rather cumbersome
prone error, evaluated policy small number instances
willing run hand. Instead, chose validate implementation plotting
polices generated training data different utility functions. plotting
extreme policies care solution cost search time, along
intermediate policies trade-off two, much simpler debug code.
735

fiBurns, Ruml, &

Profile(streams)
1. qtcounts, qqtcounts Count-Solutions(streams)
2. return Probabilities(qtcounts, qqtcounts)
Count-Solutions(streams)
3. qtcounts new int[ncost][ntime] // Initialized zero.
4. qqtcounts new int[ncost][ncost][ntime] // Initialized zero.
5. streams
6.
1 |s|
7.
qi costbin(s[i].cost)
8.
qcur qi , tcur 0
9.
// Count cost time increment solution i.
10.
j + 1 |s|
11.
qnext costbin(s[j].cost)
12.
tnext timebin(s[j].time s[i].time)
13.
// Current solution cost time solution j.
14.
= tcur tnext 1
15.
increment qtcounts[qi ][t]
16.
increment qqtcounts[qcur ][qi ][t]
17.
qcur qnext , tcur tnext
18.
// Last solution cost final time.
19.
= tcur ntime
20.
increment qtcounts[qi ][t]
21.
increment qqtcounts[qcur ][qi ][t]
22. return qtcounts, qqtcounts
Probabilities(qtcounts, qqtcounts)
23. probs new float[ncost][ncost][ntime]
24. qi 1 ncost
25.
1 ntime
26.
qtcounts[qi ][t] = 0 continue
27.
qj 1 ncost
28.
probs[qj ][qi ][t] qqtcounts[qj ][qi ][t]/qtcounts[qi ][t]
29. Smoothing: add half smallest probability elements probs improving solution cost.
30. // Normalize.
31. qi 1 ncost
32.
1 ntime
33.
sum 0
34.
qj 1 ncost
35.
sum sum + probs[qj ][qi ][t]
36.
qj 1 ncost
37.
probs[qj ][qi ][t] probs[qj ][qi ][t]/sum
38. return probs

Figure 17: Pseudocode profile estimation.

Figure 18 shows plots created platform domain. plot cost
axis time x axis. Green circles represent inputs policy
says keep searching, red crosses represent inputs policy says stop
736

fiHeuristic Search Time Matters

(a)

(b)

1000

100

200

300

2000

cost

2000

cost

cost

2000

(c)

1000

100

time

200

time

300

1000

100

200

300

time

Figure 18: Three different policies: (a) prefers cheaper solutions expense (wf =
1, wt = 0), (b) attempts trade search time solution cost (wf =
0.6, wt = 1), (c) prefers solution fast possible (wf = 0, wt =
1).

searching return solution. expected, policy always continues goal
minimize solution cost always stops goal minimize search time (cf.
left-most right-most plots Figure 18 respectively). center plot shows
successfully found policies trade search time solution cost stopping
cost sufficiently low. Finally, left-most plot, bottom-most rightmost sides policy always stop implementation chose stop
training data available estimate profile given input values.

References
Bjornsson, Y., Bulitko, V., & Sturtevant, N. (2009). TBA*: time-bounded A*. Proceedings
Twenty-first International Joint Conference Artificial Intelligence (IJCAI09), pp. 431436.
Boddy, M., & Dean, T. (1989). Solving time-dependent planning problems,. Proceedings
Eleventh International Joint Conference Artificial Intelligence (IJCAI-89),
Vol. 2, pp. 979984.
Burns, E., Hatem, M., Leighton, M. J., & Ruml, W. (2012). Implementing fast heuristic
search code. Proceedings Fifth Annual Symposium Combinatorial Search
(SoCS-12).
Burns, E., & Ruml, W. (2013). Iterative-deepening search on-line tree size prediction.
Annals Mathematics Artificial Intelligence, S68, 123.
Chen, P. C. (1992). Heuristic sampling: method predicting performance tree
searching programs. SIAM Journal Computing, 21 (2), 295315.
Cox, M. T., & Raja, A. (2011). Metareasoning: Thinking thinking. MIT Press.
737

fiBurns, Ruml, &

Dean, T., & Boddy, M. (1988). analysis time-dependent planning. Proceedings
Seventh National Conference Artificial Intelligence (AAAI-88), pp. 4954.
Dean, T., Kaelbling, L. P., Kirman, J., & Nicholson, A. (1993). Planning deadlines
stochastic domains. Proceedings eleventh national conference Artificial
intelligence, Vol. 574, p. 579. Washington, DC.
Dechter, R., & Pearl, J. (1988). optimality A*. Kanal, L., & Kumar, V. (Eds.),
Search Artificial Intelligence, pp. 166199. Springer-Verlag.
Dionne, A. J., Thayer, J. T., & Ruml, W. (2011). Deadline-aware search using on-line measures behavior. Proceedings Fourth Annual Symposium Combinatorial
Search (SoCS-11).
Domshlak, C., Karpas, E., & Markovitch, S. (2010). max max: Online learning
speeding optimal planning. AAAI Conference Artificial Intelligence
(AAAI-10), pp. 17011706.
Dweighter, H. (1975). Elementary problem E2569. American Mathematical Monthly, 82 (10),
1010.
Finkelstein, L., & Markovitch, S. (2001). Optimal schedules monitoring anytime algorithms. Artificial Intelligence, 126 (1), 63108.
Garvey, A. J., & Lesser, V. R. (1993). Design-to-time real-time scheduling. Systems, Man
Cybernetics, IEEE Transactions on, 23 (6), 14911502.
Gates, W. H., & Papadimitriou, C. H. (1979). Bounds sorting prefix reversal. Discrete
Mathematics, 27 (1), 4757.
Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. Journal Artificial Intelligence
Research, 28 (1), 267297.
Hansen, E. A., & Zilberstein, S. (2001). Monitoring control anytime algorithms:
dynamic programming approach. Artificial Intelligence, 126, 139157.
Hansen, E. A., Zilberstein, S., & Danilchenko, V. A. (1997). Anytime heuristic search: First
results. Tech. rep., University Massachusetts, Amherst.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination minimum cost paths. IEEE Transactions Systems Science Cybernetics,
SSC-4 (2), 100107.
Helmert, M. (2010). Landmark heuristics pancake problem. Proceedings
Third Symposium Combinatorial Search (SoCS-10).
Helmert, M., & Roger, G. (2008). good almost perfect. Proceedings
Twenty-Third AAAI Conference Artificial Intelligence (AAAI-08).
Hernandez, C., Baier, J., Uras, T., & Koenig, S. (2012). Time-bounded adaptive A*.
Proceedings Eleventh International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS-12).
Horvitz, E., Ruan, Y., Gomes, C., Kautz, H., Selman, B., & Chickering, M. (2001).
Bayesian approach tackling hard computational problems. Proceetings
Seventeenth Conference Uncertainty Artificial Intelligence (UAI-01).
738

fiHeuristic Search Time Matters

Kilby, P., Slaney, J., Thiebaux, S., & Walsh, T. (2006). Estimating search tree size.
Proceedings twenty-first national conference artificial intelligence (AAAI06).
Knuth, D. E. (1975). Estimating efficiency backtrack programs. Mathematics
computation, 29 (129), 121136.
Koenig, S., & Sun, X. (2009). Comparing real-time incremental heuristic search
real-time situated agents. Autonomous Agents Multi-Agent Systems, 18 (3), 313
341.
Korf, R. E. (1985). Iterative-deepening-A*: optimal admissible tree search. Proceedings Ninth International Joint Conference Artificial Intelligence, pp.
10341036.
Korf, R. E. (1990). Real-time heuristic search. Artificial intelligence, 42 (2-3), 189211.
Korf, R. E., Reid, M., & Edelkamp, S. (2001). Time complexity iterative-deepening-A*.
Artificial Intelligence, 129 (1), 199218.
Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Anytime a* provable bounds
sub-optimality. Advances Neural Information Processing Systems (NIPS-03),
16.
Michie, D., & Ross, R. (1969). Experiments adaptive graph traverser. Machine
Intelligence 5, pp. 301318.
Nilsson, N. J. (1969). mobile automaton: application artificial intelligence techniques. Proceedings First International Joint Conference Artificial intelligence (IJCAI-69), pp. 509520.
Nilsson, N. J. (1980). Principles Artificial Intelligence. Tioga Publishing Co.
Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence,
1, 193204.
Rice, J. R. (1976). algorithm selection problem. Advances Computers, 15, 65118.
Richter, S., Thayer, J. T., & Ruml, W. (2010). joy forgetting: Faster anytime search
via restarting. Proceedings Twentieth International Conference Automated
Planning Scheduling (ICAPS-10), pp. 137144.
Ruml, W., Do, M., Zhou, R., & Fromherz, M. P. (2011). On-line planning scheduling:
application controlling modular printers. Journal Artificial Intelligence Research,
40 (1), 415468.
Ruml, W., & Do, M. B. (2007). Best-first utility-guided search. Proceedings 20th
International Joint Conference Artificial Intelligence (IJCAI-07), pp. 23782384.
Russell, S., & EricWefald (1991). right thing: studies limited rationality.
MIT Press.
Shekhar, S., & Dutta, S. (1989). Minimizing response times real time planning
search. Proceedings Eleventh International Joint Conference Artificial
Intelligence (IJCAI-89), pp. 238242. Citeseer.
739

fiBurns, Ruml, &

Sturtevant, N. (2012). Benchmarks grid-based pathfinding. Transactions Computational Intelligence AI Games, 4 (2), 144 148.
Sturtevant, N. R. (2011). Distance learning agent-centered heuristic search. Proceedings
Fourth Annual Symposium Combinatorial Search (SoCS-11).
Thayer, J. (2012). Faster Optimal Suboptimal Heuristic Search. Ph.D. thesis, University
New Hampshire.
Thayer, J. T., Benton, J., & Helmert, M. (2012). Better parameter-free anytime search
minimizing time solutions. Proceedings Fifth Annual Symposium
Combinatorial Search (SoCS-12).
Thayer, J. T., Dionne, A., & Ruml, W. (2011). Learning inadmissible heuristics
search. Proceedings Twenty-first International Conference Automated
Planning Scheduling (ICAPS-11).
Thayer, J. T., & Ruml, W. (2008). Faster weighted a*: optimistic approach
bounded suboptimal search. Proceedings Eighteenth International Conference
Automated Planning Scheduling (ICAPS-08).
Thayer, J. T., & Ruml, W. (2009). Using distance estimates heuristic search. Proceedings Nineteenth International Conference Automated Planning Scheduling (ICAPS-09).
Thayer, J. T., & Ruml, W. (2010). Anytime heuristic search: Frameworks algorithms.
Proceedings Third Annual Symposium Combinatorial Search (SoCS-10).
Tolpin, D., & Shimony, S. E. (2011). Rational deployment CSP heuristics. Proceedings Twenty-Second International Joint Conference Artificial Intelligence
(IJCAI-11).
Valenzano, R. A., Sturtevant, N., Schaeffer, J., Buro, K., & Kishimoto, A. (2010). Simultaneously searching multiple settings: alternative parameter tuning
suboptimal single-agent search algorithms. Proceedings Twentieth International Conference Automated Planning Scheduling (ICAPS-10).
van den Berg, J., Shah, R., Huang, A., & Goldberg, K. (2011). ANA*: Anytime nonparametric A*. Proceedings Twenty-fifth AAAI Conference Artificial Intelligence
(AAAI-11).
Zohavi, U., Felner, A., Burch, N., & Holte, R. (2010). Predicting performance ida*
using conditional distributions. Journal Artificial Intelligence Research, 37 (1), 41
84.

740


