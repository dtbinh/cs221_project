journal artificial intelligence

submitted published

feature subset selection automatic
recommendation method
guangtao wang
qinbao song
heli sun
xueying zhang

gt wang stu xjtu edu cn
qbsong mail xjtu edu cn
hlsun mail xjtu edu cn
zhangxueying stu xjtu edu cn

department computer science technology
xian jiaotong university china

baowen xu
yuming zhou

bwxu nju edu cn
zhouyuming nju edu cn

department computer science technology
nanjing university china

abstract
many feature subset selection fss proposed
appropriate given feature selection time far
rarely good way choose appropriate fss hand thus
fss automatic recommendation important practically useful
meta learning fss automatic recommendation method
presented proposed method first identifies data sets similar
one hand k nearest neighbor classification distances among
data sets calculated commonly used data set characteristics
ranks candidate fss according performance similar
data sets chooses best performance appropriate ones
performance candidate fss evaluated multi criteria metric
takes account classification accuracy selected features
runtime feature selection number selected features proposed
recommendation method extensively tested real world data sets frequently used different fss five representative classifiers
effectiveness proposed fss recommendation method

introduction
feature subset selection fss plays important role fields data mining
machine learning good fss effectively remove irrelevant redundant
features take account feature interaction leads insight
understanding data improves performance learner enhancing
generalization capacity interpretability learning model pudil novovicova
somol vrnata pudil novovicova somol vrnata b molina belanche
nebot guyon elisseeff saeys inza larranaga liu yu
liu motoda setiono zhao
c

ai access foundation rights reserved

fiwang song sun zhang xu zhou

although large number fss proposed single
performs uniformly well feature selection experiments
hall zhao liu confirmed could exist significant differences
performance e g classification accuracy among different fss given
data set means given data set fss outperform others
raises practical important question fss
picked given data set common solution apply candidate fss given data set choose one best performance crossvalidation strategy however solution quite time consuming especially highdimensional data brodley
purpose addressing efficient way fss
automatic recommendation method proposed assumption underlying
proposed method performance fss data set related
characteristics data set rationality assumption demonstrated
follows
generally fss proposed performance needs extensively evaluated least real world data sets however published fss
rarely tested identical group data sets hall zhao liu yu
liu dash liu kononenko two
usually tested different data implies performance fss
biases data sets
time famous nfl free lunch wolpert theory tells us
particular data set different different data conditioned performance performance differences vary data sets
evidences imply relationship performance
fss characteristics data sets intend explore
relationship utilize automatically recommend appropriate fss
given data set recommendation process viewed specific application
meta learning vilalta drissi brazdil carrier soares vilalta
used recommend classification ali smith king
feng sutherland brazdil soares da costa kalousis gama hilario
smith miles song wang wang
model relationship three fundamental issues considered
features often referred meta features used characterize data set ii
evaluate performance fss identify applicable one
given data set iii recommend fss data set
meta features frequently used meta learning vilalta
drissi ali smith king et al brazdil et al castiello castellano
fanelli employed characterize data sets time multi criteria
metric takes account classification accuracy classifier
fss runtime feature selection number selected features
used evaluate performance fss meanwhile k nn k nearest
neighbor method proposed recommend fss data set


fisubset selection automatic recommendation

proposed fss recommendation method extensively tested
real world data sets well known frequently used different fss
five representative classifiers effectiveness proposed recommendation method
rest organized follows section introduces preliminaries
section describes proposed fss recommendation method section provides experimental section conducts sensitivity analysis number
nearest data sets recommendation finally section summarizes
work draws conclusions

preliminaries
section first describe meta features used characterize data sets
introduce multi criteria evaluation metric used measure performance fss

meta features data sets
proposed fss recommendation method relationship
performance fss meta features data sets
recommendation viewed data mining performance
fss meta features target function input variables
respectively due ubiquity garbage garbage lee lu ling ko
field data mining selection meta features crucial proposed
fss recommendation method
meta features measures extracted data sets used
uniformly characterize different data sets underlying properties reflected
meta features conveniently efficiently calculated related
performance machine learning castiello et al
years study improve meta features proposed
statlog project michie spiegelhalter taylor number meta features
employed characterize data sets brazdil et al castiello et al
michie et al engels theusinger gama brazdil lindner studer
sohn demonstrated working well modeling relationship
characteristics data sets performance e g classification accuracy
learning ali smith king et al brazdil et al kalousis et al
smith miles meta features characterize data sets
connection learning types use model
relationship data sets fss
commonly used meta features established focusing following three
aspects data set general properties ii statistic properties iii informationtheoretic properties castiello et al table shows details
order compute information theoretic features data sets continuous valued features
needed well known mdl minimum description length method fayyad irani criterion
used discretize continuous values



fiwang song sun zhang xu zhou

category
general properties

statistical properties

information theoretic properties

notation

f


x
skew x
kurt x
h c norm
h x norm
c x
c x max
enattr
n sratio

measure description
number instances
number features
number target concept values
data set dimensionality f
mean absolute linear correlation coefficient possible pairs features
mean skewness
mean kurtosis
normalized class entropy
mean normalized feature entropy
mean mutual information class attribute
maximum mutual information class attribute
equivalent number features enattr h c c x
noise signal ratio n sratio h x c x c x

table meta features used characterize data set
multi criteria metric fss evaluation
section first classical metrics evaluating performance fss
introduced analyzing user requirements practice application
metrics user oriented multi criteria metric proposed fss
evaluation combining metrics together
classical performance metrics
evaluating performance fss following three metrics
extensively used feature selection literature classification accuracy ii runtime
feature selection iii number selected features
classification accuracy acc classifier selected features used
measure well selected features describe classification
given data set different feature subsets generally different classification
accuracies thus reasonable feature subset higher classification accuracy stronger capability depicting classification classification
accuracy reflects ability fss identifying salient features
learning
runtime feature selection measures efficiency fss
picking useful features viewed metric measure cost feature
selection longer runtime higher expenditure feature selection
number selected features n measures simplicity feature selection
classification accuracies two fss similar usually
favor fewer features
feature subset selection aims improve performance learning
usually measured classification accuracy fss higher classification accuracy favor however mean runtime
number selected features could ignored explained following two
considerations
suppose two different fss ai aj given data set
classification accuracy ai slightly greater aj


fisubset selection automatic recommendation

runtime ai number features selected ai much greater
aj aj often chosen
usually prefer use higher accuracy longer runtime
lower accuracy shorter runtime therefore need tradeoff classification accuracy runtime feature selection number selected
features example real time systems impossible choose
high time consumption even classification accuracy high
therefore necessary allow users making user oriented performance evaluation
different fss purpose needed address
integrate classification accuracy runtime feature selection number
selected features obtain unified metric resort multi criteria
metric explore underlying reason lies multi criteria metric
successfully used evaluate data mining considering positive
properties e g classification accuracy negative ones e g runtime number
selected features simultaneously nakhaeizadeh schnabl
comparing two besides metrics used evaluate performance
ratio metric values used example suppose two
different fss better terms classification accuracy e
acc acc ratio acc acc used better well
contrary negative metrics runtime feature selection number
selected features corresponding ratio means better
actually multi criteria metric adjusted ratio ratios arr brazdil et al
combines classification accuracy runtime together unified metric
proposed evaluate performance learning extend arr integrating runtime feature selection number selected features
multi criteria metric earr extened arr proposed following discussion
metric earr inclusive flexible easy understand
multi criteria metric earr
let dset dn set n data sets aset
set fss suppose accji classification accuracy classifier fss
ai data set dj j n tji nji denote runtime
number selected features fss ai data set dj respectively
earr ai aj dk defined
k
earrd
ai aj

accki acckj
log tki tkj log nki nkj

j k n



user predefined parameters denote relative importance
runtime feature selection number selected features respectively
computation metric earr ratios classical fss performance metrics classification accuracy runtime feature selection
acc acc corresponding classification accuracies respectively



fiwang song sun zhang xu zhou

number selected features definition know earr evaluates
fss comparing another reasonable since
objective assert good comparing another one instead
focusing performance example suppose classifier
classification accuracy data set get confused whether classifier good
however compare another classifier obtain classification
accuracy data set definitely say first classifier good
compared second one
noted practice runtime difference two different fss
usually quite great meanwhile high dimensional data sets difference
number selected features two different fss great well thus
ratio runtime ratio number selected features usually much
wide ranges classification accuracy simple ratio runtime
simple ratio number selected features employed would dominate
value earr ratio classification accuracy drowned order
avoid situation common logarithm e logarithm base ratio
runtime common logarithm ratio number selected features
employed
parameters represent amount classification accuracy user
willing trade times speedup reduction runtime feature selection
number selected features respectively allows users choose
shorter runtime less features acceptable accuracy illustrated
following example suppose accki acckj runtime ai
given data set times aj e tki tkj number selected
features ai times aj e nki nkj according
dk


k
eq earr
ai aj earr aj ai case aj outperforms
ai user prefers fast less features aj choice
k
value earr varies around value earr
ai aj greater equal
k
smaller earr
aj ai indicates ai better equal
worse aj
eq directly used evaluate performance two different fss
comparing multiple fss performance ai aset
given data set evaluated metric earr
ai defined follows

earrd
ai





x

earrd
ai aj



j j

equation shows earr fss ai arithmetic
mean earrd
ai aj ai aj performance
fss ai aset evaluated comparisons
aset ai larger value earr better corresponding fss
given data set
since log x log x



fisubset selection automatic recommendation

fss recommendation method
section first give framework fss recommendation
introduce nearest neighbor recommendation method detail
framework
assumption relationship performance fss
given data set data set characteristics aka meta features
proposed recommendation method firstly constructs meta knowledge database consisting
data set meta features fss performance help
meta knowledge database k nn method used model relationship
recommend appropriate fss data set
therefore proposed recommendation method consists two parts meta knowledge
database construction fss recommendation fig shows details
meta knowledge database construction
feature selection


historical
data sets

performance metric
aquirement
meta features
extraction

performance metrics

meta features

fss recommendation

data set
recommended
fss

metaknowledge
database
performance
metrics

meta features

meta features
extraction

meta features

nearest data sets
identification

top r
recommendation

ranks

fss
ranking

nearest
data sets

metric
collection

performance
metrics

figure framework feature subset selection recommendation
meta knowledge database construction
mentioned previously meta knowledge database consists meta features
set historical data sets performance group fss
foundation proposed recommendation method effectiveness
recommendations depends heavily database
meta knowledge database constructed following three steps firstly
meta features table extracted historical data set module metafeatures extraction candidate fss applied historical data
set classification accuracy runtime feature selection number selected
features recorded corresponding value performance metric earr
calculated accomplished module performance metric calculation finally
data set tuple composed meta features values
performance metric earr candidate fss obtained added
knowledge database
fss recommendation


fiwang song sun zhang xu zhou

introduction first part meta knowledge database construction
presented learning target meta knowledge data set earr values
instead appropriate fss case demonstrated
researchers usually resort instance k nn nearest neighbors methods
variations brazdil et al recommendation thus k nn
fss recommendation procedure proposed
recommending fss data set firstly meta features
data set extracted distance data set historical
data set calculated according meta features k nearest data sets
identified earr values candidate fss k data sets
retrieved meta knowledge database finally candidate fss
ranked according earr values highest earr
achieves top rank one second highest earr gets second rank
forth top r recommended
recommendation method
recommend appropriate fss data set dnew k nearest
data sets two foundational issues solved identify k nearest
data sets ii recommend appropriate fss k data
sets
k nearest data sets identification
k nearest data sets dnew identified calculating distance dnew
historical data set meta features smaller distance
similar corresponding data set dnew
order effectively calculate distance two data sets l norm distance
atkeson moore schaal adopted since easy understand calculate
ability measuring similarity two data sets demonstrated
brazdil et al
let h meta features data set di p
value pth feature h length meta features l norm distance
data sets di dj formulated
dist di dj kfi fj k

h
x

p fj p



p

worth noting ranges different meta features quite different example
meta features introduced table value normalized class entropy varies
number instances millions thus meta features
different ranges directly used calculate distance two data sets metafeatures large range would dominate distance meta features small
range ignored order avoid standardized method eq
employed make meta features range
p min f p

max f p min f p




fisubset selection automatic recommendation

p p h value pth meta feature data set di min f p
max f p denote minimum maximum values pth meta feature historical
data sets respectively
fss recommendation
getting k nearest data sets dnew performance candidate fss
dnew evaluated according k nearest data sets
best performance recommended

let dknn dk k nearest data sets dnew earr aij
performance metric fss ai data set dj dknn j k
performance ai data set dnew evaluated
knn
earrd
ai



k
x

j


earraij

j dj



k
x
dt dj dist dnew dj






j

eq indicates performance fss ai dnew evaluated
performance dknn dnew data set dj dknn smaller distance
dj dnew similar two data sets means two data
sets dp dq dp dq data set dp similar dnew earr
ai dp important evaluating performance ai dnew thus
weighted average takes account relative importance data set dknn
rather treating data set equally employed moreover domain machine
learning reciprocal distance usually used measure similarity
k
p
j dj dt used weight earr ai dj dknn


according earr candidate fss aset dnew rank
candidate fss obtained greater earr higher
rank top r e g r fss picked
appropriate ones data set dnew
procedure fssalgorithmrecommendation shows pseudo code recommendation
time complexity recommendation procedure consists two parts first part
lines k nearest data sets given data set identified firstly
meta features f extracted function metafeatureextraction
k nearest historical data sets identified function neighborrecognition
distance f meta features historical data set di suppose
p number instances q number features given data set
time complexity function metafeatureextraction p q function
neighborrecognition time complexity n depends number
historical data sets n consequently time complexity first part p q n
second part lines r fss recommended data set
since weights earrs k nearest data sets obtained directly
time complexity two steps time complexity estimating ranking
earrs aset k log k preassigned
number nearest data sets number candidate fss


fiwang song sun zhang xu zhou

procedure fssalgorithmrecommendation
inputs
given data set
dset dn historical data sets
aset candidate fss
metadatabase earrsi n earrs
meta features earrs aset di respectively
k predefined number nearest neighbors
r number recommended fss
output recalgs recommended fss
part recognition k nearest data sets
f metafeatureextraction extract meta features
metafeatureset f f fn meta feature data set dset
neighbors neighborrecognition k f metafeatureset
part appropriate fss recommendation
weightset calculate weight data set neighbors see eq
earrset corresponding earrs data set neighbors metadatabase
estimate earr fss aset according weightset earrset

eq rank aset earrs
recalgs top r fss
return recalgs

sum time complexity recommendation procedure p q n
km mlog practice data set needs conduct feature selection
number instances p number features q much greater
number nearest data sets k number candidate fss
major time consumption recommendation procedure determined
first part

experimental analysis
section experimentally evaluate proposed feature subset selection fss
recommendation method recommending benchmark data
sets
benchmark data sets
extensively used real world data sets come different areas computer
image life biology physical text employed experiment sizes
data sets vary instances numbers features

statistical summary data sets shown table terms number
instances denoted number features denoted f number target
concepts denoted
data sets available http archive ics uci edu ml datasets html http
featureselection asu edu datasets php http sci ugr es keel datasets php http www
upo es eps bigs datasets html http tunedit org repo data respectively



fisubset selection automatic recommendation

data id



























































data name
ada agnostic
ada prior
anneal
anneal orig
ar p
arrhythmia
audiology
autos
balance scale
breast cancer
breast w
bridges version
bridges version
car
cll sub
cmc
colic
colic orig
colon
credit
credit g
cylinder bands
dermatology
diabetes
ecml x
ecoli
embryonaldataset c
eucalyptus
flags
gcm test
gina agnostic
gina prior
gina prior
glass
grub damage
heart c
heart h
heart statlog
hepatitis
hypothyroid
ionosphere
iris
kdd ipums la small
kdd ipums la small
kdd ipums la small
kdd japanesevowels test
kdd japanesevowels train
kdd synthetic control
kr vs kp
labor
leukemia
leukemia c
leukemia test x
leukemia train x
lung cancer
lymph
lymphoma x classes
lymphoma x classes





























































f























































































































data id


























































data name
lymphoma x classes
mfeat fourier
mfeat morphological
mfeat pixel
mfeat zernike
molecular biology promoters
monks test
monks train
monks test
monks train
monks test
monks train
mushroom
oh wc
oh wc
oh wc
oh wc
pasture
pendigits
pie p
postoperative patient data
primary tumor
segment
shuttle landing control
sick
smk
solar flare
solar flare
sonar
soybean
spectf test
spectf train
spectrometer
spect test
spect train
splice
sponge
squash stored
squash unstored
sylva agnostic
sylva prior
tox
tr wc
tr wc
tr wc
tr wc
tr wc
tr wc
trains
vehicle
vote
vowel
wap wc
waveform
white clover
wine
zoo




























































f





















































































































table statistical summary data sets

experimental setup
order evaluate performance proposed fss recommendation
method verify whether proposed method potentially useful practice
confirm reproducibility experiments set experimental study follows
fss
fss grouped two broad categories wrapper filter molina et al
kohavi john wrapper method uses error rate classification
evaluation function measure feature subset evaluation
function filter method independent classification accuracy
wrapper method usually high however generality limited
computational complexity high comparison filter method generality
computational complexity low due fact wrapper method
computationally expensive dash liu filter method usually good choice


fiwang song sun zhang xu zhou

number features large thus focus filter method
experiment
number filter fss proposed handle feature selection
significantly distinguished search method used
generate feature subset evaluated ii evaluation measures used assess
feature subset liu yu de souza dash liu pudil novovicova
kittler
order guarantee generality experimental twelve well known
latest search methods four representative evaluation measures employed
brief introduction search methods evaluation measures follows
search methods
sequential forward search sfs starting empty set sequentially add
feature highest value objective function current
feature subset
ii sequential backward search sbs starting full set sequentially eliminate
feature smallest decrease value objective function
current feature subset
iii bi direction search bis parallel implementation sfs sbs searches
feature subset space two directions
iv genetic search gs randomized search method performs simple
genetic goldberg genetic finds feature subset
maximize special output function techniques inspired natural evolution
v linear search ls extension bestfirst search gutlein frank hall karwath searches space feature subsets greedy hill climbing
augmented backtracking facility
vi rank search rs battiti uses feature evaluator gain ratio
rank features feature evaluator specified forward selection
search used generate ranking list
vii scatter search ss garcia lopez garcia torres melian batista moreno perez
moreno vega method performs scatter search feature
subset space starts population many significant diverse feature
subsets stops assessment criteria higher given threshold
improvement longer
viii stepwise search sws kohavi john variation forward search
step search process feature added test performed
check features eliminated without significant reduction
output function
ix tabu search ts hedar wang fukushima proposed combinatorial optimization adaptive memory responsive exploration
combining local search process anti cycling memory rules avoid
trapping local optimal solutions


fisubset selection automatic recommendation

x interactive search zhao liu traverses feature subset space
maximizing target function taking consideration interaction among
features
xi fcbf search yu liu evaluates features via relevance redundancy analysis uses analysis guideline choose features
xii ranker kononenko kira rendell liu setiono evaluates
feature individually ranks features values evaluation
metrics
evaluation measures
consistency liu setiono zhao liu kind measure evaluates worth feature subset level consistency target concept
instances projected onto feature subset consistency
feature subset never lower full feature set
ii dependency hall yu liu kind measure evaluates worth
subset features considering individual predictive ability feature
along degree redundancy among features fss methods
kind measure assume good feature subsets contain features closely
correlated target concept uncorrelated
iii distance kira rendell kononenko kind measure proposed assumption distance instances different target
concepts greater target concepts
iv probabilistic significance zhou dillon liu setiono measure
evaluates worth feature calculating probabilistic significance
two way function e association feature target concept
good feature significant association target concept
pay attention besides four evaluation measures
another basic kind measure information measure liu yu de souza
dash liu contemplated experiments reason demonstrated follow information measure usually conjunction ranker
search method thus fss kind measure usually provide
rank list features instead telling us features relevant learning target case preassign particular thresholds fss pick
relevant features however effective method set thresholds
acknowledged default threshold fss moreover unfair
conclude information measure fss assigned threshold
appropriate comparing fss therefore kind
fss employed experiments
search methods evaluation measures introduced different
fss obtained table shows brief introduction fss
available data mining toolkit weka hall frank
http www cs waikato ac nz ml weka



fiwang song sun zhang xu zhou

holmes pfahringer reutemann witten search method interact
implemented weka source codes available online
id












search method
bestfirst sequential forward search
bestfirst sequential backward search
bestfirst bi direction search
genetic search
linear search
rank search
scatter search
stepwise search
tabu search
interactive search
bestfirst sequential forward search

evaluation measure
dependency
dependency
dependency
dependency
dependency
dependency
dependency
dependency
dependency
dependency
consistency

notation
cfs sfs
cfs sbs
cfs bis
cfs gs
cfs ls
cfs rs
cfs ss
cfs sws
cfs ts
interact
cons sfs

id












search method
bestfirst sequential backward search
bestfirst bi direction search
genetic search
linear search
rank search
scatter search
stepwise search
interactive search
fcbfsearch
ranker
ranker

evaluation measure
consistency
consistency
consistency
consistency
consistency
consistency
consistency
consistency
dependency
distance
probabilistic significance

notation
cons sbs
cons bis
cons gs
cons ls
cons rs
cons ss
cons sws
interact c
fcbf
relief f
signific

table introduction fss
noted require particular settings certain parameters purpose allowing researchers confirm introduce
parameter settings fss fss interact
interact c parameter c contribution threshold used identify
irrelevant features set threshold suggested zhao liu
fss fcbf set relevance threshold su symmetric uncertainty value bn log n cth ranked feature suggested yu liu fss
relief f set significance threshold used robnik sikonja
kononenko fss signific threshold statistical significance level used identify irrelevant features set commonly used value
experiment fss conducted weka environment
default setting
classification
since actual relevant features real world data sets usually known advance
impracticable directly evaluate fss selected features classification
accuracy extensively used metric evaluating performance fss
plays important role proposed performance metric earr assessing
different fss
however different classification different biases fss may
suitable classification others de souza fact
affects performance evaluation fss
mind order demonstrate proposed fss recommendation method limited particular classification five representative
classification different hypotheses employed bayes
naive bayes john langley bayes network friedman geiger goldszmidt
information gain c quinlan rule part frank witten
instance ib aha kibler albert respectively
although naive bayes bayes net bayes classification
quite different since naive bayes proposed hypoth http www public asu edu huanliu interact interactsoftware html



fisubset selection automatic recommendation

esis features conditional independent john langley bayes net
takes account feature interaction friedman et al
measures evaluate recommendation method
fss recommendation application meta learning far know
unified measures evaluate performance meta learning methods
order assess proposed fss recommendation method two measures
recommendation hit ratio recommendation performance ratio defined
let given data set arec fss recommended recommendation method two measures introduced follows
recommendation hit ratio
intuitive evaluation criterion whether recommended fss arec meets
users requirements whether arec optimal fss performance arec significant difference optimal fss
suppose aopt represents optimal fss asetopt denotes fss
set significant difference aopt course
includes aopt well measure named recommendation hit defined assess
whether recommended arec effective
definition recommendation hit fss arec recommended data
set recommendation hit hit arec defined

arec asetopt
hit arec


otherwise
hit arec means recommendation effective since recommended
fss arec one asetopt hit arec indicates
recommended fss arec member asetopt e arec significantly
worse optimal fss aopt thus recommendation bad
definition know recommendation hit hit arec used evaluate
recommendation method single data set thus extended recommendation
hit ratio evaluate recommendation set data sets defined follows
definition recommendation hit ratio
g

x
hit ratio arec
hit arec di
g





g number historical data sets e g g experiment
definition represents percentage data sets appropriate fss effectively recommended recommendation method larger value
better recommendation method
recommendation performance ratio
recommendation hit ratio reveals whether appropriate fss
recommended given data set cannot tell us margin recommended
best one thus measure recommendation performance ratio
recommendation defined


fiwang song sun zhang xu zhou

definition recommendation performance ratio let earrrec earropt
performance recommended fss arec optimal fss
respectively recommendation performance ratio rpr arec defined
rpr arec earrrec eaaropt



definition best performance earr opt employed benchmark without
benchmark hard determine recommended good
example suppose earr arec earr opt
recommendation effective since earr arec close earr opt however
recommendation poor earr opt
rpr ratio earr recommended fss optimal one
measures close recommended fss optimal one reveals
relative performance recommended fss value varies
larger value rpr closer performance recommended fss
optimal one recommended optimal one
rpr
values parameters
multi criteria metric earr proposed evaluate performance
fss proposed metric earr two parameters established
users express requirements performance
experiment presenting two representative value pairs parameters used follows
setting represents situation classification
accuracy important higher classification accuracy selected features
better corresponding fss
setting represents situation user tolerate
accuracy attenuation favor fss shorter runtime fewer
selected features experiment set quite different
allows us explore impact two parameters
recommendation
moreover order explore parameters affect recommended fss
terms classification accuracy runtime number selected features
different parameters settings provided specifically values vary
increase
experimental process
order make sure soundness experimental conclusion guarantee
experiments reported reproducible part introduce four crucial processes
used experiments meta knowledge database construction ii optimal
fss set identification given data set iii recommendation method validation
iv sensitivity analysis number nearest data sets recommendations
meta knowledge database construction


fisubset selection automatic recommendation

procedure performanceevaluation
inputs data given data set e one data sets
learner given classification e one naive bayes c part
ib bayes network
fssalgset fssalg fssalg fssalg set fss

output earrset earr earr earr earrs fss
data
folds


earr


randomized order data

generate folds bins data

j folds

testdata bin j

traindata data testdata

numberlist null runtimelist null accuracylist null

k

subset runtime apply fssalg k traindata

number subset

redtestdata reduce testdata according selected subset

redtraindata reduce traindata according selected subset

classifier learner redtraindata

accuracy apply classifier redtestdata

numberlist k number runtimelist k runtime accuracylist k

accuracy




k
earr earrcompution accuracylist runtimelist numberlist k
compute earr fssalg k jth bin pass according eqs
earr k earr k earr



earr earr folds
return earrset

data set di extract meta features ii calculate
earrs candidate fss stratified fold cross validation
strategy kohavi iii combine meta features earr fss
together form tuple finally added meta knowledge database
since extraction meta features combination meta features
earrs straightforward present calculation earrs procedure performanceevaluation shows details
optimal fss set identification
optimal fss set given data set di consists optimal fss data set significant performance difference
optimal one di
optimal fss set given data set di obtained via non parametric
friedman test followed holm procedure test performance


fiwang song sun zhang xu zhou

estimated cross validation strategy fss
friedman test shows significant performance difference among
fss fss added optimal fss set
otherwise fss highest performance viewed optimal one
added optimal fss set holm procedure test performed
identify rest fss
significant performance differences optimal one added optimal fss
set
reason non parametric test employed lies difficult
performance values follow normal distribution satisfy variance homogeneous
condition
note optimal fss sets different settings parameters
different since values two parameters directly affect required performance
values
recommendation method validation
leave one strategy used empirically evaluate proposed fss recommendation method follows data set di
viewed test data identify k nearest data sets training data
di di excluding di ii calculate performance candidate fss according eq k nearest data sets value
k determined standard cross validation strategy recommend top three
di iii evaluate recommendations measures introduced section
sensitivity analysis number nearest data sets recommendations
order explore effect number nearest data sets recommendations provide users empirical method choose value data set
possible numbers nearest data sets tested identifying k
nearest data sets given data set k set number historical data
sets minus e g experiment
analysis
section present recommendation terms recommended fss hit ratio performance ratio respectively due space limit
list recommendations instead present two
significantly different pairs e
afterward provide experimental influence user oriented
parameters recommendations terms classification accuracy runtime
number selected features respectively
recommended hit ratio
figs first recommended fss data sets
classification naive bayes c part ib bayes network
used respectively


fisubset selection automatic recommendation

figure two sub figures corresponding recommendation
respectively sub figure
denote correctly incorrectly recommended respectively

fss id

correctly recommended

incorrectly recommended


















































































































































































data set id

fss id









































































































































































data set id

b

figure fss recommended data sets naive bayes used

fss id

correctly recommended

incorrectly recommended


















































































































































































data set id

fss id









































































































































































data set id

b

figure fss recommended data sets c used
figures observe
five classifiers proposed method effectively recommend appropriate
fss data sets
case number data sets whose appropriate fss
correctly recommended naive bayes
c part ib bayes


fiwang song sun zhang xu zhou

fss id

correctly recommended

incorrectly recommended


















































































































































































data set id

fss id









































































































































































data set id

b

figure fss recommended data sets part used

fss id

correctly recommended

incorrectly recommended


















































































































































































data set id

fss id









































































































































































data set id

b

figure fss recommended data sets ib used

network respectively states recommendation method effective
classification accuracy important
case number data sets whose appropriate fss
correctly recommended naive bayes
c part ib bayes
network respectively indicates recommendation method works well
tradeoff required among classification accuracy runtime number
selected features
distribution recommended fss data sets different
different parameters settings distribution relatively uniform


fisubset selection automatic recommendation

fss id

correctly recommended

incorrectly recommended


















































































































































































data set id

fss id









































































































































































data set id

b

figure fss recommended data sets bayes network used

seriously biased e g th fss

phenomenon similar five classifiers explained follows
fss best classification accuracy distribute data sets
uniformly thus case users favor accurate classifiers
distribution recommended fss relatively uniform well however
exist fss run faster e g th signific
select fewer features e g th cfs sws th conssws th signific data sets reason
case users prefer fss less runtime
fewer features distribution fss best performance
data sets biased recommended fss
th fss performs well data sets classifiers
seems fss generally wellperformed fss adopted fss tasks need
fss recommendation unfortunately case th fss
still failing perform well quarter data sets
yet recommendation method distinguish data sets effectively
recommend appropriate fss indicates recommendation
method still necessary case
compared know case due larger
values explained follows fss although
classification accuracies classifier features selected different
differences usually bounded meanwhile eq know
set greater bound value value earr dominated
runtime number selected features means set
relatively large value lower time complexity
chooses smaller number features recommended classification


fiwang song sun zhang xu zhou

accuracy selected features ignored however know one
important targets feature selection improve performance learning
unreasonable ignore classification accuracy focus
speed simplicity fss
thus real applications values set limit classification accuracies generally bounded accmax accmin accmin
accmax accmin denote maximum minimum classification accuracies respectively
parameter setting





recommendation
alg st
alg nd
alg rd
top
alg st
alg nd
alg rd
top

naive bayes









c









part









ib









bayes network









algx denotes x th ranking list recommended top means top three
recommended

table hit ratio recommendations five classifiers different settings

table shows hit ratio recommended fss five classifiers
observe
single fss recommended hit ratio first recommended alg st highest value least
five classifiers thus alg st first choice
top three recommended hit ratio least
indicates confidence top three including
appropriate one high reason top three
recommended moreover proposed recommendation method reduced
number candidate three users pick one fits
specific requirement
recommendation performance ratio
figs recommendation performance ratio rpr first recommended
fss five classifiers
respectively two figures observe data sets two
settings rprs recommended fss greater
matter classifier used indicates
fss recommended proposed method close optimal one
table shows average rprs data sets five classifiers
different settings table classifier columns rec def
shows rpr value corresponding recommended fss default fss
respectively default fss frequent best one
data sets classifier


fisubset selection automatic recommendation

rpr

naive bayes

























data set id

rpr

c

























data set id

rpr

part

























data set id

rpr

ib

























data set id

rpr

bayes network

























data set id

figure rpr st recommended fss five
classifiers
rpr

naive bayes

























data set id

rpr

c

























data set id

rpr

part

























data set id

rpr

ib

























data set id

rpr

bayes network

























data set id

figure rpr st recommended fss
five classifiers



fiwang song sun zhang xu zhou

observe average rprs range
respectively moreover
average rpr recommended fss surpasses default fss
five different classifiers means proposed recommendation
method works well greatly fits users performance requirement
parameter setting



naive bayes
rec
def



c
rec
def





part
rec
def



ib
rec
def





bayes network
rec
def





table average rpr data sets five classifiers

data id




























































nb



























































c



























































part



























































ib



























































bnet



























































data id

























































average

nb



























































c



























































part



























































ib



























































bnet



























































nb bnet denote naive bayes bayes network respectively

table recommendation time data sets five classifiers second



fisubset selection automatic recommendation

recommendation time
recommending fss feature selection recommendation
time contributed meta features extraction k nearest data sets identification
candidate ranking according performance k data sets
three recommendation time contributors candidate ranking
related parameters performance metric earr
however computation performance earr whatever values
means recommendation time independent specific settings
thus present recommendation time table
shows details
table observe given data set recommendation time differences
five classifiers small reason recommendation time mainly
contributed extraction meta features relation classifiers
consistent time complexity analysis section observe
data sets recommendation time less second average value
data sets around second five classifiers much faster
conventional cross validation method
impact parameters
figs impact settings classification
accuracy runtime feature selection number selected features hit ratio
rpr value respectively
naivebayes

c

part

average accuracy



average accuracy

ib

bayes network































figure classification accuracies five classifiers recommended fss different values
fig shows classification accuracies five classifiers different values
observe increase classification
accuracies five classifiers recommended fss decrease
increase indicates users much prefer faster fss
fss get less features thus proportion classification accuracy
performance decreased means ranks fss run faster
get less features improved corresponding fss finally
selected


fiwang song sun zhang xu zhou

c

part

ib

bayes network



average runtime ms

average runtime ms

naivebayes


































figure runtime fss recommended five classifiers different
values
fig shows runtime fss recommended five classifiers
different values five classifiers observe
increase average runtime recommended fss
classifier decreases note larger value means users favor faster fss thus indicates users performance requirement met since faster fss
recommended
increase average runtime recommended fss increases
well proposed recommendation method appropriate
fss given data set recommended nearest data sets
moreover experiment half e data sets
negative correlation number selected features runtime
fss thus data sets kind negative correlation
possible nearest neighbors given data set negative correlation
therefore larger means longer runtime another possible reason larger
value means users favor fss choose fewer features order
get fewer features fss need consume relatively time
c

part

average number features

average number features

naivebayes












ib

bayes network













figure number features selected fss recommended
five classifiers different values
fig shows number features selected fss recommended
five classifiers different values observe


fisubset selection automatic recommendation

increase average number selected features increases well
proposed recommendation method appropriate fss
given data set recommended nearest data sets moreover
experiment half e data sets negative correlation number selected features runtime fss
thus data sets kind negative correlation possible
nearest neighbors given data set negative correlation therefore larger
means features another possible reason larger value means users
favor faster fss possible shorter computation time obtained
via filter less features features remained
note exception average number selected features
c decreases value small however decrement comes quite
small range e
increase average number features selected recommended
fss decreases note larger value means users favor fss
get fewer features thus indicates users requirement met since
fss get fewer features recommended
naivebayes

c

part

average hit ratio

average hit ratio

ib

bayes network

































figure average hit ratio fss recommended five classifiers
different values
c

part






average rpr

average rpr

naivebayes







ib

bayes network


















figure average rpr fss recommended five classifiers
different values
figs average hit ratio rpr recommended fss
different values five classifiers


fiwang song sun zhang xu zhou

observe average hit ratio falls intervals
average rpr varies intervals
change hit
ratio rpr recommended fss vary well however change
intervals fall relative small interval lower bound stands fairly high level
minimum average hit ratio minimum average rpr
indicates proposed fss recommendation method
general application works well different settings

sensitivity analysis number nearest data sets
recommendation
section analyze number nearest data sets affects recommendation performance experimental provide guidelines
selecting appropriate number nearest data sets practice
experimental method
generally different numbers nearest data sets e k different recommendations thus recommending fss feature selection
appropriate k value important
k value higher recommendation performance preferred however
recommendation performance difference two different k values sometimes might
random significant thus order identify appropriate k value
alternatives first determine whether performance differences among
statistically significant non parametric statistical test friedman test followed
holm procedure test suggested demsar used purpose
experiment conducted fss recommendation possible k
values e data sets identifying appropriate k
values non parametric statistical test conducted follows
firstly friedman test performed recommendation performance
significance level null hypothesis k values perform equivalently
well proposed recommendation method data sets
friedman test rejects null hypothesis exists significant difference
among k values choose one recommendation best
performance reference holm procedure test performed
k values recommendation performance significant difference
reference identified k values including reference appropriate
numbers nearest data sets
analysis
fig shows number nearest data sets e k affects performance
recommendation method different settings denotes
k recommendation performance significantly worse others
significance level observe


fisubset selection automatic recommendation

naive bayes

c

part

ib

bayes network

inappropriate number neighbors




rpr



























































































































































number nearest data sets


naive bayes

c

part

ib

bayes network

inappropriate number neighbors



rpr



























































































































































number nearest data sets

b

figure number nearest data sets vs rpr
fig five classifiers rpr varies
different k values specifically rpr fluctuant k smaller
relatively flat middle part decreases k larger except
c however increment c small might due
c picks useful features build tree impact feature
selection methods less moreover difference among accuracies c
data sets relatively small performance metric earr used evaluate
different fss depends classification accuracy thus
rpr c relatively stable different values k
case fig b variation rpr different
five classifiers rpr first decreases fluctuations
increases finally decreases slowly steadily could due
parameters set relatively large value experiment
runtime number features selected fss play
important role evaluating performance fss thus
given data set fss lower time complexity smaller number
selected features possibly higher ranked larger rpr therefore
increasing k possibly recommended meanwhile
data sets real appropriate
larger rpr rpr averaged data sets relatively stable increasing
k


fiwang song sun zhang xu zhou

comparing cases found appears
k former k latter emerges k
former means cannot choose k values falling ranges
time found peak values rpr appear
range one peak value ranges except c
means set k number data sets better recommendation
performance obtained

conclusion
presented fss recommendation method aim
support automatic selection appropriate fss feature selection
number candidates
proposed recommendation method consists meta knowledge database construction recommendation former obtains meta features performance candidate fss latter relationship
meta features fss performance k nn method recommends appropriate feature selection built model
thoroughly tested recommendation method real world data sets
different fss five representative classification two typical
users performance requirements experimental recommendation
method effective
conducted sensitivity analysis explore number nearest
data sets k impacts fss recommendation suggest set k
number historical data sets
utilized well known commonly used meta features
characterize different data sets meta features informative
informative meta features still open questions knowledge
still exist effective method answer questions thus future
work plan explore measure information meta features
whether informative meta features lead improvements fss recommendation

acknowledgements
work supported national natural science foundation china grant


references
aha w kibler albert k instance learning machine learning
ali smith k learning selection classification applied
soft computing


fisubset selection automatic recommendation

atkeson c g moore w schaal locally weighted learning artificial
intelligence review
battiti r mutual information selecting features supervised neural net
learning ieee transactions neural networks
brazdil p carrier c soares c vilalta r metalearning applications data
mining springer
brazdil p b soares c da costa j p ranking learning ibl
meta learning accuracy time machine learning
brodley c e addressing selective superiority automatic model class selection proceedings tenth international conference
machine learning pp citeseer
castiello c castellano g fanelli meta data characterization input
features meta learning modeling decisions artificial intelligence
dash liu h feature selection classification intelligent data analysis

dash liu h consistency search feature selection artificial intelligence
de souza j feature selection general hybrid ph thesis
university ottawa
demsar j statistical comparisons classifiers multiple data sets journal
machine learning
engels r theusinger c data metric preprocessing advice data
mining applications
frank e witten h generating accurate rule sets without global optimization
proceedings th international conference machine learning pp
morgan kaufmann san francisco ca
friedman use ranks avoid assumption normality implicit
analysis variance journal american statistical association

friedman n geiger goldszmidt bayesian network classifiers machine
learning
gama j brazdil p characterization classification progress
artificial intelligence
garcia lopez f garcia torres melian batista b moreno perez j morenovega j solving feature subset selection parallel scatter
search european journal operational
goldberg e genetic search optimization machine learning
addison wesley professional


fiwang song sun zhang xu zhou

gutlein frank e hall karwath large scale attribute selection
wrappers proceedings ieee symposium computational intelligence
data mining pp ieee
guyon elisseeff introduction variable feature selection
journal machine learning
hall frank e holmes g pfahringer b reutemann p witten
weka data mining software update acm sigkdd explorations newsletter

hall correlation feature selection machine learning ph thesis
university waikato
hedar r wang j fukushima tabu search attribute reduction
rough set theory soft computing fusion foundations methodologies
applications
hommel g stagewise rejective multiple test procedure modified
bonferroni test biometrika
john g h langley p estimating continuous distributions bayesian classifiers proceedings eleventh conference uncertainty artificial intelligence
vol pp citeseer
kalousis gama j hilario data understanding
inductive performance machine learning
king r feng c sutherland statlog comparison classification large real world applied artificial intelligence
kira k rendell l practical feature selection proceedings ninth international workshop machine learning pp morgan
kaufmann publishers inc
kohavi r study cross validation bootstrap accuracy estimation
model selection international joint conference artificial intelligence vol
pp citeseer
kohavi r john g wrappers feature subset selection artificial intelligence

kononenko estimating attributes analysis extensions relief proceedings european conference machine learning machine learning pp
springer verlag york
lee lu h ling ko cleansing data mining warehousing
proceedings th international conference database expert systems
applications pp springer
lindner g studer r ast support selection cbr principles data mining knowledge discovery
liu h motoda h setiono r zhao z feature selection ever evolving
frontier data mining fourth workshop feature selection data
mining pp citeseer


fisubset selection automatic recommendation

liu h setiono r chi feature selection discretization numeric attributes proceedings seventh international conference tools artificial intelligence pp ieee
liu h setiono r probabilistic feature selection filter solution
pp citeseer
liu h yu l toward integrating feature selection classification
clustering ieee transactions knowledge data engineering

michie spiegelhalter j taylor c c
statistical classification

machine learning neural

molina l c belanche l nebot feature selection survey
experimental evaluation proceedings ieee international conference data
mining pp ieee
nakhaeizadeh g schnabl development multi criteria metrics evaluation data mining proceedings rd international conference
knowledge discovery data mining pp
nakhaeizadeh g schnabl towards personalization evaluation data mining proceedings th international conference knowledge
discovery data mining pp
pudil p novovicova j kittler j floating search methods feature selection
pattern recognition letters
pudil p novovicova j somol p vrnata r conceptual base feature
selection consulting system kybernetika
pudil p novovicova j somol p vrnata r b feature selection expertuser
oriented advances pattern recognition
quinlan j r c programs machine learning morgan kaufmann
robnik sikonja kononenko theoretical empirical analysis relieff
rrelieff machine learning
saeys inza larranaga p review feature selection techniques
bioinformatics bioinformatics
smith miles k cross disciplinary perspectives meta learning
selection acm computing surveys
sohn meta analysis classification pattern recognition ieee
transactions pattern analysis machine intelligence
song q b wang g wang c automatic recommendation classification
data set characteristics pattern recognition
vilalta r drissi perspective view survey meta learning artificial
intelligence review


fiwang song sun zhang xu zhou

wolpert h supervised learning free lunch theorems proceedings
th online world conference soft computing industrial applications pp
citeseer
yu l liu h feature selection high dimensional data fast correlationbased filter solution proceedings twentieth international conference
machine leaning vol pp
zhao z liu h searching interacting features proceedings th
international joint conference artifical intelligence pp morgan kaufmann publishers inc
zhou x dillon heuristic statistical feature selection criterion inductive machine learning real world proceedings ieee international
conference systems man cybernetics vol pp ieee




