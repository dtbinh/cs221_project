Journal Artificial Intelligence Research 46 (2013) 511-577

Submitted 12/12; published 03/13

Probabilistic Planning Continuous Dynamic Systems
Bounded Risk
Masahiro Ono

ONO @ APPI . KEIO . AC . JP

Keio University
3-14-1 Hiyoshi, Kohoku-ku
Yokohama, Kanagawa, 223-8522 Japan

Brian C. Williams

WILLIAMS @ MIT. EDU

Massachusetts Institute Technology
77 Massachusetts Avenue
Cambridge, 02139 USA

Lars Blackmore

LARS . BLACKMORE @ SPACEX . COM

SpaceX
1 Rocket Road
Hawthorne, CA 90250 USA

Abstract
paper presents model-based planner called Probabilistic Sulu Planner p-Sulu
Planner, controls stochastic systems goal directed manner within user-specified risk
bounds. objective p-Sulu Planner allow users command continuous, stochastic
systems, unmanned aerial space vehicles, manner intuitive safe.
end, first develop new plan representation called chance-constrained qualitative state
plan (CCQSP), users specify desired evolution plant state well
acceptable level risk. example CCQSP statement go B within 30
minutes, less 0.001% probability failure. develop p-Sulu Planner,
tractably solve CCQSP planning problem. order enable CCQSP planning, develop
following two capabilities paper: 1) risk-sensitive planning risk bounds, 2)
goal-directed planning continuous domain temporal constraints. first capability
ensures probability failure bounded. second capability essential planner
solve problems continuous state space vehicle path planning. demonstrate
capabilities p-Sulu Planner simulations two real-world scenarios: path planning
scheduling personal aerial vehicle well space rendezvous autonomous cargo
spacecraft.

1. Introduction
increasing need risk-sensitive optimal planning uncertain environments,
guaranteeing acceptable probability success. motivating example article
Boeing concept future aerial personal transportation system (PTS), shown Figure 1.
PTS consists fleet small personal aerial vehicles (PAV) enable flexible point-to-point
transportation individuals families.
c
2013
AI Access Foundation. rights reserved.

fiO , W ILLIAMS , & B LACKMORE

order provide safety, PTS highly automated. 2004, US, pilot error
listed primary cause 75.5% fatal general aviation accidents, according 2005 Joseph
T. Nall Report (Aircraft Owners Pilots Association Air Safety Foundation, 2005). Automated
path planning, scheduling, collision avoidance, traffic management significantly improve
safety PTS, well efficiency. challenges operating system include
adapting uncertainties environment, storms turbulence, satisfying
complicated needs users.
substantial body work planning uncertainty relevant. However,
approach distinctive three key respects. First, planner, p-Sulu Planner, allows
users explicitly limit probability constraint violation. capability particularly important risk-sensitive missions impact failure significant. Second, planner
goal-directed, mean achieves time-evolved goals within user-specified temporal constraints. Third, planner works continuous state space. continuous state space
representation fits naturally many real-world applications, planning aerial, space,
underwater vehicles. important problems resources.

Figure 1: Personal Transportation System (PTS). (Courtesy Boeing Company)
Figure 2 shows sample PTS scenario. passenger PAV starts Provincetown,
wants go Bedford within 30 minutes. passenger wants go scenic
area remain 5 10 minutes flight. no-fly zone (NFZ)
storm must avoided. However, storms future location uncertain; vehicles
location uncertain well, due control error exogenous disturbances. Thus risk
penetrating NFZ storm. passengers want limit risk 0.001%.
order handle planning problem, introduce novel planner called Probabilistic
Sulu Planner (p-Sulu Planner), building upon prior work model-based plan executive called
Sulu (Leaute & Williams, 2005). p-Sulu Planner provides following three capabilities,
order meet needs described scenario: 1) goal-directed planning continuous
domain, 2) near-optimal planning, 3) risk-sensitive planning risk bounds.
Goal-directed planning continuous domain p-Sulu Planner must plan actions
continuous effects achieve time evolved goals specified users. case PTS
scenario Figure 2, PAV must sequentially achieve two temporally extended goals, called
512

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Figure 2: sample plan personal aerial vehicle (PAV)

episodes: going scenic area arriving Bedford. additional
temporal constraints goals inherent scenario; temporal constraints
come physical limitations, fuel capacity, others come passenger requirements.
Near-optimal stochastic planning Cost reduction performance improvement important issues system. PTS scenario, passengers may want minimize trip
time fuel usage. p-Sulu Planner finds near-optimal control sequence according
user-defined objective function, satisfying given constraints.
Risk-sensitive planning risk bounds Real-world systems subject various uncertainties, state estimation error, modeling uncertainty, exogenous disturbance.
case PAVs, position velocity vehicle estimated Kalman filter
typically involve Gaussian-distributed uncertainties; system model used planning
control perfect; vehicles subject unpredictable disturbances turbulence. uncertainty, executed result plan inevitably deviates
original plan hence involves risk constraint violation. Deterministic plan execution
particularly susceptible risk optimized order minimize given cost function,
since optimal plan typically pushes one constraint boundaries, hence
leaves margin error. example, shortest path PTS scenario shown Figure
2 cuts close NFZs storm, generally, constraint boundaries. Then,
tiny perturbation planned path may result penetration obstacles.
risk reduced setting safety margin path obstacles, cost
longer path length. However, often impossible guarantee zero risk, since typically non-zero probability disturbance large enough push vehicle
feasible region. Therefore, passengers vehicle must accept risk,
time need limit certain level. generally, users autonomous
system uncertainty able specify bounds risk. planner must
guarantee system able operate within bounds. constraints called
chance constraints.
513

fiO , W ILLIAMS , & B LACKMORE

1.1 Overview Planner
section describes inputs outputs p-Sulu Planner informally. rigorously
defined Section 2.
1.1.1 NPUTS
Initial Condition p-Sulu Planner plans control sequence starting current state,
typically estimated noisy sensor measurements. Therefore, p-Sulu Planner takes
probability distribution, instead point estimate, current state initial condition.
Stochastic Plant Model control community planning problem generate sequence
control inputs actuate physical system, called plant. action model plant
typically system real-valued equations control, state observable variables. pSulu Planner takes input linear stochastic plant model, specifies probabilistic state
transitions continuous domain. stochastic extension continuous plant model used
Leaute Williams (2005). paper limit focus Gaussian-distributed uncertainty.
Chance-constrained qualitative state plan (CCQSP) order provide users intuitive way command stochastic systems, develop new plan representation called chanceconstrained qualitative state plan (CCQSP). extension qualitative state plan (QSP), developed used Leaute Williams (2005), Hofmann Williams (2006), Blackmore,
Li, Williams (2006). CCQSP specifies desired evolution plant state time,
defined set discrete events, set episodes, impose constraints plant state
evolution, set temporal constraints events, set chance constraints specify
reliability constraints success sets episodes plan.
CCQSP may depicted directed acyclic graph, shown Figure 3. circles
represent events squares represent episodes. Flexible temporal constraints represented
simple temporal network (STN) (Dechter, Meiri, & Pearl, 1991), specifies upper lower
bounds duration two events (shown pairs numbers parentheses).
plan Figure 3 describes PTS scenario depicted Figure 2, stated informally as:
Start Provincetown, reach scenic region within 30 time units, remain
5 10 time units. end flight Bedford. probability
failure episodes must less 1%. times, remain safe region
avoiding no-fly zones storm. Limit probability penetrating
obstacles 0.0001%. entire flight must take 60 time units.
formal definition CCQSP given Section 2.4.3.
Objective function user p-Sulu Planner specify objective function (e.g., cost
function). assume convex function.
1.1.2 UTPUT
Executable control sequence p-Sulu Planner plans finite horizon. One two
outputs p-Sulu Planner executable control sequence horizon satisfies
constraints specified input CCQSP. case PTS scenario, outputs vehicles actuation inputs, acceleration ladder angle, result nominal paths shown
514

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Figure 3: example chance-constrained qualitative state plan (CCQSP), new plan representation specify desired evolution plant state acceptable levels
risk. PTS scenario Figure 2, passengers PAV would go
Provincetown Bedford, fly scenic region way. safe region
means entire state space except obstacles. Risk episodes must within
risk bounds specified chance constraints.

Figure 2. order control sequence executable, must dynamically feasible.
example, curvature PAVs path must exceed vehicles maneuverability.
Optimal schedule output p-Sulu Planner optimal schedule, set execution time steps events input CCQSP minimizes given cost function. case
PTS scenario shown Figure 3, schedule specifies leave scenic region
arrive Bedford, example. p-Sulu Planner finds schedule satisfies simple
temporal constraints specified CCQSP, minimizes cost function.
two outputs control sequence schedule must consistent other:
time-evolved goals achieved optimal schedule applying control sequence
given initial conditions.
1.2 Approach
p-Sulu Planner must solve difficult problem generating executable control sequence
CCQSP, involves combinatorial optimization discrete schedule non-convex
optimization continuous control sequence. approach article develop p-Sulu
Planner three technical steps, call spirals.
first spiral, described Section 4, solve special case CCQSP planning problem, feasible state space convex (e.g., path planning problem without obstacles)
schedule fixed, shown Figure 4-(a). problem transformed convex optimization problem risk allocation approach, presented previous work (Ono
& Williams, 2008a). obtain feasible, near-optimal solution CCQSP planning problem
optimally solving convex optimization using interior point method (Blackmore & Ono,
2009).
second spiral, presented Section 5, consider CCQSP problem
non-convex state space order include obstacles, Figure 4-(b). develop branch
bound-based algorithm, called non-convex iterative risk allocation (NIRA). Subproblems
branch-and-bound search NIRA convex chance-constrained optimal control problems,
solved first spiral. NIRA algorithm cannot handle problem flexible schedule.
515

fiO , W ILLIAMS , & B LACKMORE

third spiral, described Section 6, develop another branch boundbased algorithm, namely p-Sulu Planner, solve general CCQSP planning problem
flexible schedule obstacles. Subproblems branch-and-bound search pSulu Planner non-convex chance-constrained optimal control problems, solved
NIRA algorithm.
dp-SuluW (Section 6)

NIRA (Section 5)

(Ono & Williams 2008b) (Section 4)

Fixed schedule

Fixed schedule

t=5

Simple temporal
constraints

[2 4]

t=5
t=1

C

t=1

Goal

[1 3]

Goal

C

Obstacle
Start

Start

(a) Convex, fixed schedule

Obstacle

Waypoint

Waypoint

Waypoint
Start

(b) Non-convex, fixed schedule

Goal

[0 5]

(c) Non-convex, flexible schedule

Figure 4: Three-spiral approach CCQSP planning problem

1.3 Related Work
Recall CCQSP planning problem distinguished use time-evolved goals, continuous states actions, stochastic optimal solutions chance constraints. planning
control disciplines explored aspects problem, solution total novel,
approach solving problem efficiently risk allocation novel.
specifically, extensive literature planning discrete actions achieve
temporally extended goals (TEGs), TLPlan (Bacchus & Kabanza, 1998) TALPlan
(Kvarnstrom & Doherty, 2000), treat TEGs temporal domain control knowledge prune
search space progressing temporal formula. However, since TEG planners assume
discrete state spaces, cannot handle problems continuous states effects without discretization. Ignoring chance constraints, representation time evolved goals used TLPlan
p-Sulu Planner similar. TLPlan uses version metric interval temporal logic (MITL)
(Alur, Feder, & Henzinger, 1996) applied discrete states, p-Sulu Planner uses qualitative state plans (QSPs) (Leaute & Williams, 2005; Hofmann & Williams, 2006; Li, 2010)
continuous states. Li (2010) shows that, given state space, QSP expressed MITL.
key difference defines p-Sulu Planner addition chance constraints, together
use continuous variables.
Several planners, particularly employed components model-based executives, command actions continuous state space. example, Sulu (Leaute & Williams, 2005)
takes input deterministic linear model QSP, specifies desired evolution plant
state well flexible temporal constraints, outputs continuous control sequence. Chekhov
(Hofmann & Williams, 2006) takes input QSP nonlinear deterministic system model,
outputs continuous control sequence. order enable fast real-time plan execution, Chekhov
precomputes flow tubes, sets continuous state trajectories end goal regions specified given plan. Kongming (Li, 2010) provides generative planning capability hybrid
516

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

systems, involving continuous discrete actions. employs compact representation
hybrid plans, called Hybrid Flow Graph, combines strengths Planning Graph
discrete actions flow tubes continuous actions. planners adapt effects uncertainty, explicitly reason effects uncertainty planning. example,
Sulu employs receding horizon approach, continuously replans control sequence using
latest measurements. Chekhovs flow tube representation feasible policies allows executive generate new control sequences response disturbances on-line. p-Sulu Planner
distinct continuous planners plans model uncertainty dynamics, instead reacting it. plan guarantees user-specified probability success explicitly
reasoning effects uncertainty.
AI planning literatures, planning domain description language, PDDL+, supports mixed
discrete-continuous planning domains (Fox & Long, 2006). Probabilistic PDDL (Younes & Littman,
2004) Relational Dynamic influence Diagram Language (RDDL) (Sanner, 2011) handle stochastic systems. Recently, Coles, Coles, Fox, Long (2012) developed forward-chaining
heuristic search planner named COLIN, deal continuous linear change durationdependent effects. However, planners handle chance constraints. note
outputs p-Sulu Planner continuous space discrete time. time-dependent MDP
developed Boyan Littman (2000) handle continuous time encoding time state.
Extension p-Sulu Planner continuous-time planning would interesting future direction.
work within AI community probabilistic planning focused planning discrete domains builds upon Markov decision process (MDP) framework. growing subcommunity focused extensions MDPs continuous domain. However, tractability
issue, since typically require partitioning approximation continuous state space.
straightforward partitioning continuous state action spaces discrete states actions often leads exponential blow-up running time. Furthermore, feasible state
space unbounded, impossible partition space finite number compact subspaces. alternative approach function approximation (Boyan & Moore, 1995),
convergence guaranteed approximation error bounded (Bertsekas & Tsitsiklis,
1996; Lagoudakis & Parr, 2003). Time-dependent MDPs (Boyan & Littman, 2000; Feng, Dearden,
Meuleau, & Washington, 2004) efficient partitioning continuous state space, make
assumption set available states actions finite (i.e., discrete). Hence, planning
MDPs continuous state space, Rn , requires approximate state space
finite number discrete states. approach essentially different MDP approaches
continuous variables directly optimized convex optimization without discretization continuous state space. Hence, continuity state space harm tractability
p-Sulu Planner.
second point comparison treatment risk. p-Sulu Planner, MDP
framework offers approach marrying utility risk. However, MDP algorithms balance
utility risk assigning large negative utility event constraint violation.
approach cannot guarantee bounds probability constraint violation. constrained MDP
approach (Altman, 1999) explicitly impose constraints. Dolgov Durfee (2005) showed
stationary deterministic policies constrained MDPs obtained solving mixed
integer linear program (MILP). However, constrained MDP framework impose bounds
expected value costs, again, cannot guarantee strict upper bounds probability
517

fiO , W ILLIAMS , & B LACKMORE

constraint violation. contrast, p-Sulu Planner allows users impose chance constraints,
explicitly restrict probability constraint violation. far authors know,
risk-sensitive reinforcement learning approach proposed Geibel Wysotzki (2005)
work considers chance constraints MDP framework. developed reinforcement
learning algorithm MDPs constraint probability entering error states. work
distinct p-Sulu Planner goal-directed, mean achieves
time-evolved goals within user-specified temporal constraints. summarize, prior MDP work
supports continuous state actions combination general continuous noise transitions
ensuring probability failure bounded.
Risk-sensitive control methods continuous domain extensively studied discipline control theory. example, celebrated H control method minimizes effect
disturbances output system guaranteeing stability system (Stoorvogel,
1992). Risk-sensitive control approaches allow users choose level risk averseness
minimization expected exponentiated cost function (Jacobson, 1973; Fleming & McEneaney, 1995). However, approaches address chance constraints optimal scheduling. Several methods proposed solving stochastic optimal control problems
continuous variables chance constraints. method proposed van Hessem (2004) turns
stochastic problem deterministic problem using conservative ellipsoidal relaxation.
Blackmore (2006) proposes sampling-based method called Particle Control, evaluates joint
chance constraints Monte-Carlo simulation, instead using conservative bound. result,
stochastic planning problem reduced MILP problem. Although theoretical guarantee obtain exactly optimal solution infinite number samples used,
computation time issue. Blackmore et al. (2006) Nemirovski Shapiro (2006) employed
Booles inequality decompose joint chance constraint individual chance constraints. Although Booles inequality less conservative ellipsoidal relaxation, approach still
non-negligible conservatism since fixes individual risk bound uniform value.
approach builds upon approach, modifications allow flexible individual risk bounds.
best authors knowledge, p-Sulu Planner first goal-directed planner
able plan continuous state space chance constraints.
1.4 Innovations
p-Sulu Planner enabled six innovations presented article.
First, order allow users command stochastic systems intuitively, develop new plan
representation, CCQSP (Section 2.4.3).
Second, order decompose chance constraint disjunctive clause disjunction
individual chance constraints, introduce risk selection approach (Section 5.1.2).
Third, order obtain lower bounds branch-and-bound search NIRA, develop
fixed risk relaxation (FRR), linear program relaxation subproblems (Section 5.4.2).
Fourth, minimize search space optimal schedule introducing new forward
checking method efficiently prunes infeasible assignment execution time steps (Section 6.2).
Fifth, order enhance computation time schedule optimization, introduce method
obtain lower bound branch-and-bound solving fixed-schedule planning problems
partial assignment schedule. (Section 6.3)
518

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Sixth, order minimize number non-convex subproblems solved branch-andbound search, introduce variable ordering heuristic, namely convex-episode-first (CEF)
heuristic, explores episodes convex feasible state region ones
non-convex state region (Section 6.2.2).
rest article organized follows. Section 2 formally defines CCQSP
states CCQSP planning problem. Section 3 derives encoding problem chanceconstrained optimization problem, well encodings two limited versions CCQSP
planning problem: one fixed schedule convex state space, another fixed
schedule non-convex state space. Section 4 reviews solution fixed-schedule CCQSP
planning problem convex state space. Section 5 develops NIRA algorithm, solves
fixed-schedule CCQSP planning problem non-convex state space, Section 6 introduces
p-Sulu Planner, solves CCQSP planning problem flexible schedule nonconvex state space. Finally, Section 7 shows simulation results various scenarios, including
personal transportation system (PTS).

2. Problem Statement
Recall p-Sulu Planner takes input linear stochastic plant model, specifies
effects actions; initial state description, describing distribution initial states; CCQSP,
specifies desired evolutions state variables, well acceptable levels risk;
objective function. output executable control sequence optimal schedule. Planning
performed finite horizon, since p-Sulu Planner incorporated finite-horizon
optimal control. first define variables used problem formulations. define
elements inputs outputs.
2.1 Definition Time Step
consider series discretized finite time steps = 0, 1, 2, N fixed time interval
, integer N size planning horizon. Since time interval take
positive real value, suffices consider time steps integer indices approximate
systems dynamics. use term time step mean integer index discretized time
steps, using term time mean real-valued time. define sets follows:
:= {0, 1, 2, N }.


:= {0, 1, 2, N 1}.

(1)
(2)

limit scope article discrete-time stochastic system. optimizing
control sequence continuous-time stochastic system requires solving stochastic differential
equation (SDE) repeatedly. Performing computation tractable except simple
problems.
2.2 Definitions Events
event denotes start end episode behavior plan representation.
Definition 1. event e E instance executed certain time step T.
519

fiO , W ILLIAMS , & B LACKMORE

define two special events, start event e0 end event eE . Without loss generality,
assume e0 executed = 0. end event eE represents termination entire
plan.
2.3 Definitions Variables
Variables used problem formulation involve discrete schedule, continuous state vector,
continuous control vector.
formally define event well schedule follows:
Definition 2. execution time step s(e) integer-valued scalar represents
time step event e E executed. schedule := [s(e0 ), s(e1 ), s(eE )]
sequence execution time steps events e E. Finally, partial schedule :=
[(e) | e E E] ordered set execution time steps subset events E .
definition, start event executed = 0 i.e, s(e0 ) = 0. Following notation
schedule, denote (e) execution time event e E . See definition
schedule (Definition 2).
consider continuous state space, state vector state sequence defined
follows:
Definition 3. state vector xt Rnx real-valued vector represents state plant
time step t. state sequence x0:N := [x0 xN ] vector state variables time step 0
N .
actions assignments continuous decision variables, referred control
vector:
Definition 4. control vector ut Rnu real-valued vector represents control input
system time step t. control sequence u0:N 1 := [u0 uN 1 ] vector control inputs
time 0 N 1.
2.4 Definitions Inputs
subsection defines four inputs p-Sulu Planner: initial condition, stochastic plant
model, CCQSP, objective function.
2.4.1 NITIAL C ONDITION
belief state beginning plan represented initial state, assumed
Gaussian distribution known mean x0 covariance matrix x0 :
x0 N (x0 , x0 ).

(3)

parameters (3) specified initial condition, defined follows:
Definition 5. initial condition pair = x0 , x0 , x0 mean initial state
x0 covariance matrix initial state.
520

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

2.4.2 TOCHASTIC P LANT ODEL
p-Sulu Planner controls dynamical systems actions correspond settings continuous control variables, whose effects continuous state variables. p-Sulu Planner
specifies actions effects plant model. plant model considered state
transition model continuous space. employ variant linear plant model additive
Gaussian uncertainty commonly used context chance-constrained stochastic optimal control (Charnes & Cooper, 1959; Nemirovski & Shapiro, 2006; Oldewurtel, Jones, & Morari,
2008; van Hessem, 2004), modification consider controller saturation. Specifically,
assume following plant model:
xt+1 = xt + B U (ut ) + wt

(4)

wt Rnx state-independent disturbance t-th time step zero-mean Gaussian
distribution given covariance matrix denoted wt :
wt N (0, wt ).

(5)

Although model prohibits state-dependent disturbance, types noise involved
target applications state independent. example, PTS scenario introduced Section
1, primary source uncertainty wind turbulence, typically dependent
state vehicle. space rendezvous scenario discussed Section 7.5, main sources
perturbations space craft tidal force unmodeled gravitational effects Sun, Moon,
planets (Wertz & Wiley J. Larson, 1999). noises modeled state-dependent
noise practice scale planned actions significantly smaller Solar
System.
dependent state space craft. note problem formulation encode
time-varying noise specifying different covariance matrices wt time step.
set U Rnu compact convex set represents continuous domain feasible
control inputs. infeasible control input ut
/ U given plant, actuators saturate.
function U () : Rnu 7 U (4) represents effect actuator saturation follows:
{
u
(if u U)
U (u) :=
,
PU (u) (otherwise)
PU (u) projection u U. example, u one-dimensional U = [l, u],
PU (u) = max(min(u, u), l). Note U introduces nonlinearity plant.
parameters (4) (5) specified stochastic plant model, defined
follows:
Definition 6. stochastic plant model four-tuple = A0:N 1 , B 0:N 1 , w0:N 1 , U,
A0:N 1 B 0:N 1 sets N matrices A0:N 1 := {A0 , A1 , 1 }, B 0:N 1 :=
{B 0 , B 1 , B N 1 }, w0:N 1 set N covariance matrices w0:N 1 = {w0 , w1 , , wN 1 },
U Rnu compact convex set represents domain feasible control inputs.
Note xt , well wt , random variable, ut deterministic variable. Figure
5 illustrates plant model. typical plant model, probability circles grow time since
disturbance wt added every time step, drawn figure. effect represents commonly
observed tendency distant future involves uncertainty near future.
521

fiO , W ILLIAMS , & B LACKMORE

x2

x3

99.9%
99%
90%

x1
x0

99.9%
99%

x1

99.9%
99%
90%

Nominal
path

x2

90%

x3

Figure 5: Illustration stochastic plant model used p-Sulu Planner.
order mitigate accumulation uncertainty, employ close-loop control approach,
generates control input ut incorporating nominal control input ut Rnu
error feedback, follows:
ut = ut + K (xt xt ),
(6)
K matrix representing constant stabilizing feedback gain time xt
nominal state vector. nominal state xt obtained following recursion:
x0 := x0
xt+1 = xt + B ut .

(7)
(8)

closed-loop control approach employed Geibel Wysotzki (2005) Oldewurtel
et al. (2008) context chance-constrained optimal control shown significantly
improves performance.
closed-loop planning method, nominal control input ut planned execution. actual control input ut computed real time using (6). feedback term
(6) linearly responds error xt xt . choosing feedback gain K appropriately,
growth probability circles Figure 5 slowed down. Neglecting effect controller
saturation (i.e., assuming U = Rnx ), follows (4) (6) xt Gaussian distribution
covariance matrix xt , evolves follows:
xt+1 = (At + B K )xt (At + B K )T + wt .

(9)

typical plant, eigenvalues one. Therefore, error feedback
(i.e., K = 0), size xt grows wt iteration. choosing K
norm largest eigenvalue (At + B K ) less one, covariance xt grow
continuously. feedback gain found using standard control techniques,
linear quadratic regulator (LQR) (Bertsekas, 2005). Since consider finite-horizon, discretetime planning problem, optimal time-varying LQR gain K obtained solving finitehorizon, discrete-time Riccati equation. practice, often suffices use steady-state (i.e.,
time-invariant) LQR gain, obtained solving infinite-horizon, discrete-time Riccati
equation simplicity. note feedback gain K optimized real time.
approach often used robust stochastic model predictive controls (Goulart, Kerrigan, &
Maciejowski, 2006; Oldewurtel et al., 2008; Ono, 2012). However, extension beyond
scope paper.
522

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

issue that, error xt xt happens large, control input ut may exceed
feasible domain U, resulting actuator saturation. Therefore, (9) hold due
nonlinearity function U (). address issue risk allocation approach.
specifically, impose chance constraints control saturation, allocate risk state
control constraints. approach discussed detail Section 4.1.5.
2.4.3 C HANCE - CONSTRAINED Q UALITATIVE TATE P LAN (CCQSP)
qualitative state plan (QSP) (Leaute & Williams, 2005) temporally flexible plan specifies
desired evolution plant state. activities QSP called episodes specify
constraints plant state. CCQSP extension QSPs stochastic plans involve
chance constraints, defined follows:
Definition 7. chance-constrained qualitative state plan (CCQSP) four-tuple P = E, A, , C,
E set discrete events, set episodes, set simple temporal constraints,
C set chance constraints.
four elements CCQSP defined precisely moment. QSP, CCQSP
illustrated diagrammatically directed acyclic graph discrete events E
represented vertices, drawn circles, episodes arcs ovals. CCQSP start
event e0 end eE , corresponds beginning end mission, respectively.
example, Figure 3 shows CCQSP PTS scenario. state regions obstacles
CCQSP illustrated Figure 2. involves four events: E = {e0 , e1 , e2 , eE }. meanings
described follows.
1. start event e0 corresponds take PAV Provincetown.
2. second event e1 corresponds time step PAV reaches scenic region.
3. Event e2 associated time instant PAV left scenic region.
4. end event eE corresponds arrival PAV Bedford.
CCQSP four episodes = {a1 , a2 , a3 , a4 } two chance constraints C = {c1 , c2 }.
natural language expression CCQSP is:
Start Provincetown, reach scenic region within 30 time units, remain
5 10 time units. end flight Bedford. probability
failure activities must less 1%. times, remain safe region
avoiding no-fly zones storm. Limit probability penetrating
obstacles 0.0001%. entire flight must take 60 time units.
formally define three types constraints - episodes, temporal constraints,
chance constraint.
Episodes episode specifies desired state system control time
interval.

Definition 8. episode = eSa , eE
, (tS , tE ), Ra associated start event ea end
N
event eE
. Ra R region state space. set time steps state xt
must region Ra .

523

fiO , W ILLIAMS , & B LACKMORE

feasible region Ra subset RN . approximate Ra set linear
constraints later Section 3.1.1.
(tS , tE ) subset given function episodes start time step tS = s(eSa )
end time step tE = s(eE
). Different forms (tS , tE ) result various types episodes.
following three types episodes particularly interest us:
1. Start-in episode: (tS , tE ) = {tS }
2. End-in episode: (tS , tE ) = {tE }
3. Remain-in episode: (tS , tE ) = {tS , tS + 1, , tE }
given episode a, set time steps plant state must region Ra
obtained substituting s(eSa ) s(eE
), execution time steps start event end
event episode, tS and( tE . other) words, episode requires plant state
Ra time steps s(eSa ), s(eE
) . rest article, use following
abbreviated notation:
(
)
(s) := s(eSa ), s(eE
a) .
Using notation, episode equivalent following state constraint:

xt Ra .

(10)

ta (s)

example, CCQSP shown Figure 3, four episodes: a1 (Start [Provincetown]), a2 (Remain [Scenic region]), a3 (End Bedford), a4 (Remain [safe region]).
Section 6, solve relaxed optimization problem partial schedule (Definition 2)
order obtain lower bound optimal objective value. relaxed problems,
subset episodes relevant given partial schedule imposed. formally
define partial episode set partial schedule follows:
Definition 9. Given partial schedule , A() partial episode set, subset
involves episodes whose start event end event assigned execution time steps.
}
{
A() = | eSa E eE
E ,
definition E given Definition 2.
Chance constraint Recall chance constraint probabilistic constraint requires
constraints defining episode satisfied within user-specified probability. CCQSP
multiple chance constraints. chance constraint associated least one episode.
chance constraint formally defined follows:
Definition 10. chance constraint c = c , c constraint requiring that:



Pr
xt Ra 1 c ,

(11)

ac ta (s)

c user-specified risk bound c set episodes associated chance
constraint c.
524

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Note every episode CCQSP must associated exactly one chance constraint.
episode must involved one chance constraint unassociated
chance constraint.
example, CCQSP shown Figure 3 two chance constraints, c1 c2 . associated episodes c1 = {a1 , a2 , a3 } c2 = {a4 }. Therefore, c1 requires probability
satisfying three episodes a1 , a2 , a3 (colored green) 99%, c2
requires probability satisfying episode a4 99.99999%.
make following assumption, necessary order guarantee convexity
constraints Section 4.2.
Assumption 1.
c 0.5
assumption requires risk bounds less 50%. claim assumption
constrain practical applications, since typically user autonomous system would
accept 50% risk.
Temporal constraint CCQSP includes simple temporal constraints (STCs) (Dechter et al.,
1991), impose upper lower bounds duration episodes temporal
distances two events E.
min max constraint, specifyDefinition 11. simple temporal constraint = eS , eE
, b , b
ing duration start event eS end event eE
real-valued interval
max ] [0, +].
[bmin
,
b



Temporal constraints represented diagrammatically arcs nodes, labeled
max ], labels episodes. example, CCQSP shown Figure 3
time bounds [bmin
, b
four simple temporal constraints. One requires time e0 e1 30
time units. One requires time e1 e2 least 5 units 10 units. One
requires time e2 eE 40 time units. One requires time e0
eE 60 time units.
schedule feasible satisfies temporal constraints CCQSP. number
feasible schedules finite, since discrete finite. denote SF domain feasible
schedules, formally defined follows:
SF = {s T|E| |


max
bmin
{s(eE
},

) s(e )} b

(12)

|E| number events CCQSP. temporal duration multiplied time
real-valued time, set discrete time steps T.
bmin
interval bmin


2.4.4 BJECTIVE F UNCTION
section, formally define objective function.
Definition 12. objective function J : UN XN SF 7 R real-valued function
nominal control sequence u0:N 1 , nominal state sequence x1:N , schedule s. assume
J convex function x1:N u0:N 1 .
525

fiO , W ILLIAMS , & B LACKMORE

typical example objective function quadratic sum control inputs, requires
total control efforts minimized:
J(u0:N 1 , x1:N , s) =

N
1


||ut ||2 .

t=0

Another example is:
J(u0:N 1 , x1:N , s) = s(eE ),

(13)

minimizes total plan execution time, requiring end event eE qualitative
state plan scheduled soon possible.
often need minimize expectation cost function. Note that, case,
expectation function x1:N u0:N 1 reduced function u0:N 1
follows (4)-(6) probability distributions x1:N u0:N 1 uniquely determined
u0:N 1 K . practice, often convenient express objective function
function u0:N 1 x1:N , rather function u0:N 1 . Since x1:N specified
u0:N 1 using (8), two expressions equivalent. conversion expectation cost
function function nominal values conducted priori.
controller saturation, conversion often obtained closed form.
conversion particularly straight forward cost function polynomial, since
expectation equivalent combination raw moments, readily derived
cumulants. Note third higher cumulants Gaussian distribution zero.
show examples conversion regarding three commonly-used cost functions: linear, quadratic,
Manhattan norm.
E[xt ] = xt
E[xTt Qxt ]

(14)
= xTt Qxt +

nx


E[||xt ||1 ] =

xt ,i

i=1

tr(Qxt )
(
)
x2t,i
2
1 1
,
1 F1 , ,

2 2 2x2t ,i

(15)
(16)

Q positive definite matrix, xt ,i ith diagonal element xt , 1 F1 ()
confluent hypergeometric function. functions convex. expectation function
ut transformed function ut manner. Note second term
right hand side (15) constant. Hence, minimizing xTt Qxt yields solution
minimizing E[xTt Qxt ].
controller saturation, difficult obtain conversion closed-form due
nonlinearity U () (4). practice, use approximation assumes saturation.
Since closed-loop control approach explicitly limits probability controller saturation
small probability (see Section 4.1.5 detail), approximation error trivial. claim
empirically validated Section 7.2.4.
2.5 Definitions Outputs
output p-Sulu Planner optimal solution, consists optimal control sequence u0:N 1 UN optimal schedule SF .
526

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Definition 13. optimal solution pair u0:N 1 , . solution satisfies constraints
given CCQSP (Definition 7), initial condition I, stochastic plant model .
solution minimizes given objective function J(u0:N 1 , x1:N , s) (Definition 12).
2.6 Problem Statement
formally define CCQSP planning problem.
Problem 1: CCQSP Planning Problem
Given stochastic plant model = A0:N 1 , B 0:N 1 , w0:N 1 , initial condition =
x0 , x0 , CCQSP P = E, A, , C, objective function J(u0:N 1 , x1:N , s), CCQSP
planning problem find optimal solution u0:N 1 , M, I, P , J.
note p-Sulu Planner gives near-optimal solution Problem 1. p-Sulu Planner
employs two approximations, namely risk allocation (Section 4.1.1) risk selection (Section
5.1.1), sake computational tractability. result, solution strictly optimal
general. However, empirically show Section 7 suboptimality due risk allocation
risk selection significantly smaller existing approximation methods.

3. Problem Encoding
section encodes CCQSP planning problem stated previous section mathematical programming problem. Sections 4 - 6 address solve form mathematical
problem. Recall build CCQSP planner, p-Sulu Planner, three spirals. first
present problem encoding general CCQSP planning problem non-convex state space
flexible schedule (Figure 4-(c)) Subsection 3.1. present encodings two
special cases CCQSP planning problem Subsections 3.2 3.3: one non-convex
state space fixed schedule (Figure 4-(b)), one convex state space fixed schedule (Figure 4-(a)).
3.1 Encoding CCQSP Planning Problem Non-convex State Space Flexible
Schedule
3.1.1 E NCODING F EASIBLE R EGIONS
order encode Problem 1 mathematical programming problem, geometric constraint
(11), xt Ra , must represented algebraic constraints. purpose, approximate
feasible state regions Ra set half-spaces, represented linear state
constraint.
Figure 6 shows two simple examples. feasible region (a) outside obstacle,
approximated triangle. feasible region (b) inside pickup region,
approximated triangle. feasible region approximated set linear constraints
follows:
(a)

3


hTi x g ,

(b)

i=1

3


hTi x g .

i=1

approximate feasible regions set linear constraints sufficient condition
original state constraint xt Ra .
527

fiO , W ILLIAMS , & B LACKMORE

Figure 6: Approximate representation feasible regions set linear constraints

assume set linear state constraints approximates feasible region
reduced conjunctive normal form (CNF) follows:




hTa,k,j xt ga,k,j 0,

(17)

kKa jJa,k

Ka = {1, 2, |Ka |} Jc,i = {1, 2, |Jc,i |} sets indices. replacing xt Ra
(11) (17), chance constraint c encoded follows:

Pr










hTc,a,k,j xt gc,a,k,j 0 1 c .

(18)

ac ta (s) kKa jJa,k

order simplify notation, merge indices c , (s),
k Ka new
index Ic (s), Ic (s) = {1, 2, |Ic (s)|} |Ic (s)| = |Ka | ac |a (s)|. let ai ,
ki , ti indices correspond combined index i, let hc,i,j = hc,ai ,ki ,j . Using
notations, three conjunctions (18) combined one, obtain following
encoding chance constraint:

Pr






hTc,i,j xti gc,i,j 0 1 c .

(19)

iIc (s) jJc,i

specification chance constraints given (19) requires |Ic (s)| disjunctive clauses
state constraints must satisfied probability 1 c . ith disjunctive clause cth
chance constraint composed |Jc,i | linear state constraints.
3.1.2 CCQSP P LANNING P ROBLEM E NCODING
Using (3), (4), (5), (6), (19), CCQSP planning problem (Problem 1), solved
third spiral, encoded follows:
528

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Problem 2: General CCQSP Planning Problem
min
u0:N 1 ,s
s.t.

J(u0:N 1 , x1:N , s)

(20)

SF

(21)

xt+1 = xt + B U (ut ) + wt ,





(22)



ut = ut + K (xt xt ),




Pr
hTc,i,j xti gc,i,j 0 1 c .
cC

(23)
(24)

iIc (s) jJc,i

x0 N (x0 , x0 ),

wt N (0, wt ),



(25)

Recall SF , formally defined (12), set schedules satisfy temporal constraints given CCQSP. CCQSP execution problem hybrid optimization problem
discrete variables (schedule) continuous variables u0:N 1 (control sequence). Note
temporal constraints within Problem 2 solved Section 6. similar problem encoding
employed chance-constraint MDP proposed Geibel Wysotzki (2005). However,
encoding differs Geibel Wysotzki two respects: 1) optimize continuous control sequence u0:N 1 discrete schedule temporal constraints; 2)
allow joint chance constraints, require satisfaction multiple state constraints given
probability. Problem 2 solved Section 6.
3.2 Encoding CCQSP Planning Problem Non-convex State Space Fixed
Schedule
restricted version CCQSP planning problem fixed schedule, solved
second spiral, obtained fixing Problem 2 follows:
Problem 3: CCQSP Planning Problem Fixed Schedule
J (s) = min
u0:N 1
s.t.

J (u0:N 1 , x1:N )

(26)

xt+1 = xt + B U (ut ) + wt ,




ut = ut + K (xt xt ),




Pr
hTc,i,j xti gc,i,j 0 1 c ,
cC

(27)
(28)
(29)

iIc (s) jJc,i

x0 N (x0 , x0 ),

wt N (0, wt ),



(30)

J (s) optimal objective value CCQSP Planning problem schedule fixed
s. Note schedule s, decision variable Problem 2, treated constant
Problem 3. Therefore, objective function J function control sequence mean
529

fiO , W ILLIAMS , & B LACKMORE

state, since fixed schedule. Since assumed J convex function regarding
u0:N 1 x1:N , J convex function. Section 5 solves Problem 3.
3.3 Encoding CCQSP Planning Problem Convex State Space Fixed Schedule
restrictive version CCQSP planning problem fixed schedule convex state
space, solved first spiral, obtained removing disjunctions chance
constraints Problem 3 follows:
Problem 4: CCQSP Planning Problem Fixed Schedule Convex State Space

min
u0:N 1

J (u0:N 1 , x1:N )

(31)

xt+1 = xt + B U (ut ) + wt ,




ut = ut + K (xt xt ),




Pr
hTc,i xti gc,i 0 1 c .
cC

(32)
(33)
(34)

iIc (s)

x0 N (x0 , x0 ),

wt N (0, wt ),



(35)

Section 4 solves Problem 4.

4. CCQSP Planning Convex State Space Fixed Schedule
section presents solution methods Problem 4, CCQSP planning problem
convex state space fixed schedule, shown Figure 4-(a). obstacles
environment execution time steps achieve time-evolved goals fixed, CCQSP
planning problem reduced convex chance-constrained finite-horizon optimal control problem.
past work presented risk allocation approach, conservatively approximates
chance-constrained finite-horizon optimal control problem tractable convex optimization
problem (Ono & Williams, 2008a, 2008b; Blackmore & Ono, 2009). Although optimal solution
approximated convex optimization problem exactly optimal solution original convex chance-constrained finite-horizon optimal control problem, suboptimality significantly smaller previous approaches. section gives brief overview risk allocation
approach, well solution convex chance-constrained finite-horizon optimal control
problem.
4.1 Deterministic Approximation Problem 4
Evaluating whether joint chance constraint (34) satisfied requires computing integral
multivariate probability distribution arbitrary region, since probability (34) involves
multiple constraints. integral cannot obtained closed form. address issue
decomposing intractable joint chance constraint (34) set individual chance constraints,
involves univariate probability distribution. key feature individual
530

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Goal

Goal
Walls

Walls

Nominal path
Safety margin

Start

Start

(a) Uniform risk allocation

(b) Optimal risk allocation

Figure 7: Risk allocation strategies racing car example

chance constraint transformed equivalent deterministic constraint
evaluated analytically.
4.1.1 R ISK LLOCATION PPROACH
decomposition considered allocation risk. decomposition, risk
bound joint chance constraint distributed individual chance constraints.
many feasible risk allocations. problem find risk allocation results minimum
cost. offer readers intuitive understanding risk allocation approach using example
below.

Racing Car Example Consider racing car example, shown Figure 7. dynamics
vehicle Gaussian-distributed uncertainty. task plan path minimizes time
reach goal, guarantee probability crashing wall race less
0.1% (chance constraint). Planning control sequence equivalent planning nominal
path, shown solid lines Figure 7. limit probability crashing wall,
good driver would set safety margin, colored dark gray Figure 7, plan
nominal path outside safety margin.
driver wants set safety margin small possible order make nominal path
shorter. However, since probability crashing race bounded, certain
lower bound size safety margin. Given constraint, different ways
setting safety margin; Figure 7(a) width margin uniform; Figure 7(b) safety
margin narrow around corner, wide places.
intelligent driver would take strategy (b), since knows going closer wall
corner makes path shorter, straight line not. key observation
taking risk (i.e., setting narrow safety margin) corner results greater reward
(i.e. time saving) taking risk straight line. gives rise notion risk
allocation. good risk allocation strategy save risk reward small, taking
reward great. illustrated example, risk allocation must optimized
order minimize objective function joint chance-constrained stochastic optimization
problem.
531

fiO , W ILLIAMS , & B LACKMORE

4.1.2 ECOMPOSITION C ONJUNCTIVE J OINT C HANCE C ONSTRAINTS R ISK
LLOCATION
derive mathematical representation risk allocation reformulating chance constraint conjunction constraints conjunction chance constraints. reformulation
initially presented Prekopa (1999) introduced chance-constrained optimal control
Ono Williams (2008b). concept risk allocation originally developed Ono
Williams (2008a). Let Ci proposition either true false. following lemma
holds:
Lemma 1.
Pr

[N


]
Ci 1



N


0,

i=1

Pr [Ci ] 1

i=1

N




i=1

Proof.
Pr

[N


]
Ci 1 Pr

i=1





[N

i=1
N


]
Ci

(36)

[ ]
Pr Ci

(37)

cC i=1

0
0

N

i=1
N

i=1

N

[ ]
Pr Ci

i=1

Pr [Ci ] 1

N


.

(38)

i=1

overline C negation literal C. use following Booles inequality obtain (37)
(36):
]
[N
N


Pr[Cc,i ].
Pr
Cc,i
i=1

i=1

following result immediately follows Lemma 1 substituting linear constraint
hTc,i xti gc,i 0 Ci chance constraint c.
Corollary 1. following set constraints sufficient condition joint chance constraint
(34) Problem 4:





[
]
c,i 0
Pr hc,i xti gc,i 0 1 c,i
c,i c
(39)


cC

iIc (s)

iIc (s)

newly introduced variables c,i represent upper bounds probability violating
linear state constraint. refer individual risk bounds. individual risk bound,
532

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

c,i , viewed amount risk allocated ith clause. fact c,i bound
probability implies 0 c,i 1. second term (39) requires total amount risk
upper-bounded original risk bound c . find analogue resource allocation
problem, allocation resource optimized upper bound total amount
available resource. Likewise, allocation risk c,i must optimized order minimize
cost. Therefore, call decomposition method risk allocation.
4.1.3 C ONSERVATISM R ISK LLOCATION PPROACH
mentioned previously, risk allocation approach gives conservative approximation
original chance constraint. subsection evaluates level conservatism risk allocation
approach.
Let Pf ail true probability failure, defined probability solution violates
constraints (i.e., left hand side (34)). Since (39) sufficient necessary condition
(34), Pf ail smaller equal risk bound general: Pf ail . Hence,
conservatism introduced risk allocation represented
Pf ail .
best-case scenario risk allocation approach violations constraints
mutually exclusive, meaning solution violates one constraint always satisfies
constraints. case, (39) becomes necessary sufficient condition (34) hence,
risk allocation involve conservatism. Therefore,
Pf ail = 0.
hand, worst-case scenario constraints equivalent, meaning
solution violates one constraint always violates constraints. case,
Pf ail =

N 1
,
N

N number constraints.
practical problems lie somewhere best-case scenario worst-case scenario, typically closer best-case worst-case scenario. example,
two separate obstacles path planning problem, collisions two obstacles mutually
exclusive events. Collision obstacle one time step usually imply collisions
time steps. rough approximation real-world situation assume satisfaction constraints probabilistically independent. assumption, true probability
failure is:


Pf ail =
Pr [qc,i (u) 0] 1
(1 ),
iIc

iIc

Ic set index state constraints. Note . Therefore, conservatism introduced risk allocation second order :
Pf ail O(2 ).
example, = 1%, true probability failure approximately Pf ail 0.99%.
practical cases, users prefer set small risk bounds, typically less 1%. cases,
conservatism introduced risk allocation becomes small.
533

fiO , W ILLIAMS , & B LACKMORE

4.1.4 C ONVERSION ETERMINISTIC C ONSTRAINTS
individual chance constraint (39) involves single linear constraint. Furthermore,
assuming actuator saturation, xti Gaussian distribution covariance
matrix given (9). Hence, hTc,i xti univariate Gaussian distribution. following lemma
transforms individual chance constraint equivalent deterministic constraint involves
mean state variables, instead random state variables:
Lemma 2. following two conditions equivalent.
[
]
Pr hTc,i xti gc,i 0 1 c,i hTc,i xti gc,i mc,i (c,i )

mc,i (c,i ) =



2hTc,i x,ti hc,i erf 1 (2c,i 1).

(40)

Note erf1 inverse Gauss error function x,ti covariance matrix
xti . lemma holds mc,i () inverse cumulative distribution function
univariate, zero-mean Gaussian distribution variance hTc,i x,ti hc,i .
4.1.5 R ISK LLOCATION PPROACH C LOSED - LOOP C ONTROL P OLICY
close-loop control policy employed (i.e., K = 0 (6)), risk actuator
saturation. Since nonlinearity function U () (5) makes probability distribution
xti non-Gaussian, mc,i () cannot obtained (40). Although theoretically possible
derive mc,i () non-Gaussian distributions, difficult case since inverse
cumulative distribution function xti cannot obtained closed-form.
solution issue summarized Lemma 3 below, allows us assume xti
Gaussian-distributed hence use (40), even possibility actuator saturation.
approach enabled imposing additional chance constraints bound risk actuator
saturation follows:
Pr [ut U] 1 , ,
(41)
bound risk actuator saturation time step t. Using method presented
Section 3.1.2, approximate U polytope follows:

ut U
hU,i ut gU,i 0
iIU

Assuming xti Gaussian-distributed, use Lemma 2 transform (41) deterministic
constraints nominal control inputs follows:


hU,i ut gU,i mU,t,i (t,i )
t,i , ,
(42)
iIU

iIU


mU,t,i (c,i ) =



2hTU,i x,t hU,i erf 1 (2c,i 1).

following lemma holds:
534

(43)

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Lemma 3. following set constraints sufficient condition joint chance constraint
(34) Problem 4:


c,i 0, 0
hTc,i xti gc,i mc,i (c,i )

cC iIc (s)

Tcmax




c,i +
t,i c

t=0 iIU
iIc (s)


hU,i ut gU,i mU,t,i (t,i ),
(44)
tT iIU

(45)
mc,i () mU,t,i given (40) (43). Tcmax last time step episodes
associated chance constraint c executed, given schedule s:
Tcmax = max s(eE
).
ac

Intuitively, constraint (44) requires that, probability 1 c , episode constraints
satisfied actuators saturate episodes associated c executed.
Proof. consider two plants: = A0:N 1 , B 0:N 1 , w0:N 1 , U
= A0:N 1 , B 0:N 1 , w0:N 1 , Rnu , U Rnu compact convex set (see Definition
6). difference two plants possibility actuator saturation,
not. result, probability distribution state variables non-Gaussian,
Gaussian. Note result different probability distributions xti
ut . order explicitly show plant model considered, use notations xM
ti


ut proof.
first consider . follows Lemmas 1 2 that:


max

Tc










Pr
hTc,i xM

g

0

u

U

1


.
(44) =
c,i
c
ti



cC

t=0

iIc (s)

Let w0:N 1 := [w0 wN 1 ]. define feasible disturbance set, Wc (v 0:N 1 , s) RN nx ,
follows:


max

Tc












hTc,i xM
u

U
.

g

0

Wc (v 0:N 1 , s) := w0:N 1 RN nx
c,i
ti




iIc (s)

t=0

(46)
Then, definition,


max
Tc





U = Pr [w0:N 1 Wc (v 0:N 1 , s)] .
Pr
hTc,i xM
uM
ti gc,i 0

iIc (s)

t=0

535

fiO , W ILLIAMS , & B LACKMORE

Next consider . Note identical long actuator saturations

(i.e., uM
U). Therefore, given w 0:N 1 Wc (v 0:N 1 , s), follows (46) xt =




xM
ut = ut . Hence,

max

Tc




w0:N 1 Wc (v 0:N 1 , s) =
hTc,i xM
uM
ti gc,i 0
U .
t=0

iIc (s)

Accordingly, given c C,




hTc,i xM
Pr
ti gc,i 0
iIc (s)





Pr





Tcmax


hTc,i xM
ti gc,i 0





uM
U

t=0

iIc (s)

Pr [w0:N 1 Wc (v 0:N 1 , s)]
max


Tc





uM
U
= Pr
hTc,i xM

ti gc,i 0
t=0

iIc (s)

1 c .
completes proof Lemma 3
note Lemma 3 probabilistic extension closed-loop robust model predictive
control (RMPC) methods proposed Acikmese, Carson III, Bayard (2011) Richards
(2006). methods avoid risk actuator saturation imposing tightened control
constraints ut . Since consider stochastic uncertainty, replace constraint tightening
chance constraints.
4.2 Convex Programming Solution Problem 4
Using Lemma 3, replace stochastic optimization problem, Problem 4, deterministic
convex optimization problem:
Problem 5: Deterministic Approximation Problem 4
min
u1:N ,c,i 0,t,i 0
s.t.

J (u1:N , x1:N )
,


(47)

xt+1

hc,i xti

= xt + B ut

(48)

gc,i mc,i (c,i )

(49)

cC iIc (s)



tT

hU,i ut gU,i mU,t,i (t,i )

(50)

iIU



Tcmax

c,i +

cC iIc (s)

536


t=0 iIU

t,i c .

(51)

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

follows immediately Corollaries 1 2 feasible solution Problem 5 always
feasible solution Problem 4. Furthermore, Blackmore Ono (2009) showed optimal
solution Problem 5 near-optimal solution Problem 4. following lemma guarantees
tractability Problem 5.
Lemma 4. Problem 5 convex optimization problem.
Proof. inverse error function erf1 (x) concave x. Since assume Section 2.4.3
c 0.5, feasible ranges upperbounded 0.5. Since safety margin function
mc,i (c,i ) mU,t,i (t,i ) convex 0 < c,i 0.5 0 < t,i 0.5, constraints (49)
(50) convex within feasible region. constraints convex since
linear. Finally, objective function convex assumption (Section 2.4.4). Therefore, Problem
5 convex optimization problem.
Since Problem 5 convex optimization problem, solved interior point method
optimally efficiently. completes first spiral, planning CCQSPs fixed schedule
convex constraints. next section present solution method non-convex problem
branch-and-bound algorithm, whose subproblems convex problems.

5. CCQSP Planning Non-convex State Space
Next, consider second spiral, comprised Problem 3 Section 3.2, variant CCQSP
planning problem involves fixed schedule non-convex constraints, obstacles,
shown Figure 4-(b). again, encoded chance-constrained optimization problem,
addition obstacle avoidance constraints requires disjunctive state constraints. Hence,
problem results non-convex, chance-constrained optimization. section introduces
novel algorithm, called Non-convex Iterative Risk Allocation (NIRA), optimally solves deterministic approximation Problem 3.
solution CCQSP planning problem non-convex state space two-fold.
first step, described Section 5.1, obtain deterministic approximation Problem 3. order
handle disjunctive chance constraints, develop additional decomposition approach called
risk selection, reformulates chance constraint disjunction constraints disjunction individual chance constraints. chance constraints (29) decomposed
set individual chance constraints risk allocation risk selection, technique
Section 4.1.4 used obtain equivalent deterministic constraints. result, obtain
disjunctive convex programming problem (Problem 6 Section 5.1.3).
deterministic disjunctive convex programming problem solved second step, described Sections 5.2-5.4. introduce NIRA algorithm (Algorithm 1) significantly reduces computation time without making compromise optimality solution.
reduction computation time enabled new bounding approach, Fixed Risk Relaxation
(FRR). FRR relaxes nonlinear constraints subproblems branch-and-bound algorithm
linear constraints. many cases, FRR nonlinear subproblems formulated linear
programming (LP) approximated LP. NIRA obtains strictly optimal solution Problem
6 solving subproblems exactly without FRR unpruned leaf nodes search tree,
subproblems solved approximately FRR order reduce computation time.
537

fiO , W ILLIAMS , & B LACKMORE

5.1 Deterministic Approximation
Section 4, first obtain deterministic approximation Problem 3.
5.1.1 R ISK ELECTION PPROACH
deterministic approximation obtained decomposing non-convex joint chance constraint
(29) set individual chance constraints, risk allocation risk selection. revisit
race car example explain concept risk selection intuitively.

Figure 8: racing car example, risk selection approach guarantees 0.1% risk bound
paths, lets vehicle choose better one.

Racing Car Example consider example shown Figure 8, vehicle uncertain
dynamics plans path minimizes time reach goal. vehicle allowed choose
one two routes shown Figure 8. impose chance constraint limits probability
crashing wall mission 0.1%.
satisfaction chance constraint guaranteed following process. First,
routes, find safety margin limits probability crash throughout route
0.1% start goal. Then, let vehicle plan nominal path operates within
safety margins. Since routes 0.1% safety margin, chance constraint satisfied
matter route vehicle chooses. Therefore, vehicle optimize path choosing
route results smaller cost. optimization process considered selection
risk; vehicle given two options Figure 8, routes (a) (b), involve
level risk; vehicle selects one results less cost. Hence, name
decomposition approach risk selection.
5.1.2 ECOMPOSITION C ONJUNCTIVE J OINT C HANCE C ONSTRAINT R ISK
ELECTION
subsection, derive mathematical representation risk selection. Let Ci proposition either true false. following lemma holds:

538

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Lemma 5.
Pr

[N


]
Ci 1

i=1

N


Pr [Ci ] 1

i=1

Proof. following inequality always holds:


Pr

[N


]
Ci Pr [Ci ] .

(52)

i=1

Hence,

Pr

[N


]
Ci 1 Pr [Ci ] 1

i=1

N


Pr [Ci ] 1 .

(53)

i=1

following corollary follows immediately Lemmas 3 5.
Corollary 2. following set constraints sufficient condition disjunctive joint chance
constraint (29) Problem 3:

c,i 0, 0



cC







iIc (s) jJc,i



Tcmax

c,i +



tT


t=0 iIU

iIc (s)



hTc,i,j xti gc,i,j mc,i (c,i )

t,i c





5

hU,i ut gU,i mU,t,i (t,i ).

(54)

iIU

Note resulting set constraints (54) sufficient condition original chance
constraint (29). Therefore, solution satisfies (54) guaranteed satisfy (29). Furthermore,
although (54) conservative approximation (29), conservatism introduced risk selection
generally small many practical applications. claim empirically validated Section
7.2.3.
5.1.3 ETERMINISTIC PPROXIMATION P ROBLEM 3
Using Corollary 2, non-convex fixed-schedule CCQSP planning problem (Problem 3) approximated following deterministic convex optimization problem. later convenience,
label part optimization problem (objective function), (plant model), C (chance
constraints states), (chance constraints control inputs), R (risk allocation constraint).
539

fiO , W ILLIAMS , & B LACKMORE

Problem 6: Deterministic Approximation Problem 3
min
u1:N ,c,i 0,t,i 0
s.t.

(O :)

J (u1:N , x1:N )

(55)

(M :) , xt+1 = xt + B ut

(C :)
hTc,i,j xti gc,i,j mc,i,j (c,i )

(56)
(57)

cC iIc (s) jJc,i

(D :)



hU,i ut gU,i mU,t,i (t,i )

(58)

tT iIU

(R :)



Tcmax

c,i +

cC iIc (s)



t,i c .

(59)

t=0 iIU

follows immediately Corollary 2 optimal solution Problem 6 guaranteed
feasible solution original problem regard satisfying chance constraints
(Problem 3). Furthermore, empirically demonstrate Section 7.2.3 near-optimal
solution Problem 3 applications.
5.2 NIRA: Branch Bound-Based Solution Problem 6
next present Non-convex Iterative Risk Allocation (NIRA) algorithm. Recall NIRA
optimally solves Problem 6 branch-and-bound algorithm. standard branch-and-bound
solution problems involving disjunctive nonlinear constraints, Problem 6,
use bounding approach nonlinear convex relaxed subproblems constructed
removing non-convex constraints corresponding disjunction. approach
used Balas (1979) Li Williams (2005) different problem known disjunctive linear
programming, whose subproblems LPs instead convex programmings. However, although
standard branch-and-bound algorithm guaranteed find globally optimal solution Problem 6,
computation time slow algorithm needs solve numerous nonlinear subproblems
order compute relaxed bounds.
new bounding approach, Fixed Risk Relaxation (FRR), addresses issue computing
lower bounds efficiently. observe relaxed subproblems nonlinear convex optimization problems. FRR relaxes nonlinear constraints linear constraints. Particularly,
objective function linear, FRR subproblem (Problem 8) LP,
efficiently solved. optimal objective value FRR subproblem lower bound
optimal objective value original subproblem.
NIRA solves FRRs subproblems order efficiently obtain lower bounds,
solving original subproblems exactly without relaxation unpruned leaf nodes order obtain
exact optimal solution. result, NIRA achieves significant reduction computation time,
without loss optimality.
5.2.1 NIRA LGORITHM OVERVIEW
Algorithm 1 shows pseudocode NIRA algorithm. input deterministic approximation non-convex chance-constrained optimal control problem (Problem 6), five-tuple
540

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Algorithm 1 Non-convex Iterative Risk Allocation (NIRA) algorithm
function NIRA(problem) returns optimal solution Problem 6
1: Set queue FILO queue
2: Incumbent
3: rootSubproblem obtainRootSubproblem(problem)
4: queue rootSubproblem
5: queue empty
6:
subproblem last entry queue
7:
Remove subproblem queue
8:
lb obtainLowerBound(subproblem)
9:
lb Incumbent
10:
c = |C| = |Ic (s)|
11:
(J, U ) Solve(subproblem)
12:
J < Incumbent

13:
Incumbent J, U U //Update optimal solution
14:
end
15:
else
16:
ii+1
17:
> |Ic (s)|
18:
c c + 1, 1
19:
end
20:
j Jc,i
21:
newSubproblems Expand(subproblem,problem,c,i,j)
22:
Add newSubproblems queue
23:
end
24:
end
25:
end
26: end

27: return U

O, M, C, D, R, well fixed schedule s. output optimal nominal control sequence

U := [u0 uN 1 ].
node branch-and-bound search tree corresponds subproblem convex
chance-constrained optimization problem (Problem 5). use FILO queue store subproblems
search conducted depth-first manner (Line 1). node, corresponding
subproblem solved obtain lower bound objective value subsequent subproblems
(Line 8). details bounding approaches explained Subsection 5.4. lower bound
larger incumbent, algorithm prunes branch. Otherwise, branch expanded
(Line 21). branch expanded leaf without pruned, subproblems solved exactly
(Line 11). Subsection 5.3 explains expansion procedure detail. NIRA algorithm always

results globally optimal solution Problem 6, since solution U obtained solving
subproblems leaf nodes exactly. next two subsections introduces branching bounding
methods.
541

fiO , W ILLIAMS , & B LACKMORE

5.3 Branching
subsection explains NIRA constructs root subproblem (Line 3 Algorithm 1),
well expands nodes (Line 21 Algorithm 1). root subproblem convex
optimal CCQSP planning problem without chance constraints. node expanded,
subproblems children nodes constructed adding one constraint disjunction
subproblem parent node. order simplify notations, let Cc,i,j represent individual
chance constraint (57) Problem 6:
{
rue (if hTc,i,j gc,i,j xti mc,i,j (c,i ))
Cc,i,j :=
F alse (otherwise).
5.3.1 WALK - E XAMPLE
first present walk-through example intuitively explain branching procedure. example instance Problem 6, involves four individual chance constraints:


hT1,i,j xti g1,i,j m1,i,j (1,i )
(60)
i{1,2} j{1,2}

Using notation defined above, set individual chance constraints (57) represented
follows:
(C1,1,1 C1,1,2 ) (C1,2,1 C1,2,2 )

(61)

Figure 9-(a) shows tree obtained dividing original problem subproblems sequentially.
subproblems corresponding trees four leaf nodes (Nodes 4-7 Figure 9-(a)) exhaust
conjunctive (i.e., convex) combinations among chance constraints (61). hand,
subproblems corresponding three branch nodes (Nodes 1-3 Figure 9-(a)) involve disjunctive
(i.e., nonconvex) clauses chance constraints. relax non-convex subproblems convex
subproblems removing clauses contain disjunctions order obtain search tree
shown Figure 9-(b).

Figure 9: Branch-and-bound search tree sample disjunctive convex programming problem
(Problem 6) constraints (60). (a) Tree non-convex subproblems, (b) Tree relaxed convex subproblems.

542

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

non-convex problem (Problem 6) optimally solved repeatedly solving relaxed
convex subproblems using algorithms presented Section 4. following subsections introduce algorithms construct search tree relaxed convex subproblems, one
Figure 9-(b).
5.3.2 R ELAXED C ONVEX UBPROBLEM
formulation relaxed convex subproblems given Problem 7. represent index
j j(c, i) since convex relaxation chooses one disjunct disjunction specified
optimal objective value relaxed
(c, i). Let Ic set indices i. denote JSP
subproblem.
Problem 7: Convex Relaxed Subproblem NIRA


JSP
=

min
u1:N ,c,i 0,t,i 0
s.t.

(O :) J (u1:N , x1:N )
(M :)
(C :)

, xt+1 = xt + B ut

hTc,i,j(c,i) xti gc,i,j(c,i) mc,i,j(c,i) (c,i ) (62)
cC iIc

(D :)



hU,i ut gU,i mU,t,i (t,i )

(63)

tT iIU

(R :)



Tcmax

c,i +

cC iIc



t,i c .

(64)

t=0 iIU

Note Problem 7 identical Problem 5. Hence, algorithms introduced Section 4
used solve relaxed subproblems.
5.3.3 C ONSTRUCTION ROOT UBPROBLEM
root subproblem special case Problem 7 Ic empty set c C.
function presented Algorithm 2 used Line 3 NIRA algorithm (Algorithm 1)
construct root subproblem branch-and-bound tree. Note that, Algorithm 2,
use object-oriented notation, subproblem.O, represent objective function
subproblem. resulting root subproblem follows:
5.3.4 E XPANSION UBPROBLEMS
order create child subproblem subproblem, function described Algorithm 3
used Line 21 NIRA algorithm (Algorithm 1). adds individual chance constraint
specified indices (c, i, j) conjunct. Note resulting child subproblem still
convex optimization, individual chance constraint added conjunctively. NIRA
algorithm (Algorithm 1) enumerates children nodes disjuncts Jc,i (Lines 20-23).
543

fiO , W ILLIAMS , & B LACKMORE

Algorithm 2 Construction root subproblem NIRA
function obtainRootSubproblem(problem) returns root subproblem
1: rootSubproblem.O problem.O
2: rootSubproblem.M problem.M
3: rootSubproblem.D problem.D
4: c C
5:
rootSubproblem.Ic max
Tc
6:
rootSubproblem.Rc .lhs t=0
iIU t,i
7:
rootSubproblem.Rc .rhs problem.Rc .rhs
8: end
9: return rootSubproblem
Algorithm 3 Expansion subproblem NIRA
function
Expand(subproblem, problem, c, i, j)
lem
1: subproblem.Ic subproblem.Ic
2: subproblem.Rc .lhs subproblem.Rc .lhs + c,i
3: return subproblem

returns



child

subprob-

5.4 Bounding
subsection, present two implementations obtainLowerBound function Line 8
Algorithm 1. first one uses optimal solution convex subproblems (Problem 7)
lower bounds. approach typically results extensive computation time. second one solves
LP relaxation convex subproblems, called fixed risk relaxation (FRR). FRR dramatically
reduces computation time compared first implementation. NIRA algorithm employs
second implementation.
5.4.1 IMPLE B OUNDING
Algorithm 4 shows straightforward way obtain lower bounds. simply solves
convex relaxed subproblems (Problem 7) using methods presented Section 4.2. optimal
objective value relaxed subproblem gives lower bound optimal objective value
subproblems it. example, optimal solution relaxed subproblem Node 2
Figure 9-(b) gives lower bound objective value subproblems Nodes 4 5.
constraints relaxed subproblems always subset constraints
subproblems below. Note optimization problems formulated minimizations.
However, despite simplicity approach, computation time slow algorithm needs solve myriad subproblems. example, simple path planning problem
Algorithm 4 simple implementation obtainLowerBound function Line 8 Algorithm 1
function obtainLowerBound-Naive(subproblem) returns lower bound
1: Solve subproblem using algorithms presented Section 4.2
2: return optimal objective value

544

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

ten time steps one rectangular obstacle requires solution 410 = 1, 048, 576 worst
case, although branch-and-bound process often significantly reduces number subproblems
solved. Moreover, subproblems (Problem 7) nonlinear convex optimization problems
due nonlinearity mc,i,j mU,t,i (62) (63). general nonlinear optimization problem requires significantly solution time specific classes optimization problems,
linear programmings (LPs) quadratic programmings (QPs).
5.4.2 F IXED R ISK R ELAXATION
new relaxation approach, fixed risk relaxation (FRR), addresses issue. FRR linearizes
nonlinear constraints (62) (63) Problem 7 fixing individual risk allocations,
c,i t,i , upper bound . objective function linear, FRR LP.
FRR convex piecewise linear objective function reformulated LP
introducing slack variables (See Section 7.1.1 example.). general convex objective function
approximated convex piecewise linear function. Hence, many cases, FRRs
subproblems result LPs, solved efficiently. fixed risk relaxation Problem
7 follows:
Problem 8: Fixed Risk Relaxation Problem 7

JF RR = min
u1:N
s.t.

J (u1:N , x1:N )
,


xt+1 = xt + B ut
hTc,i xti gc,i mc,i,j(c,i) (c )

(65)

cC iIc (s)



hU,i ut gU,i mU,t,i (c )

(66)

tT iIU

Note nonlinear terms (62) (63), mc,i,j mU,t,i , become constant fixing c,i
t,i c , constant. optimal objective value FRR provides tightest lower
bound among linear relaxations constraints (62) (63). following lemmas hold:
Lemma 6. Problem 8 gives lower bound optimal objective value Problem 7:

JF RR JSP

Proof. mc,i,j () mU,t,i () monotonically decreasing functions. Since c,i c t,i
c , individual chance constraints (65) (66) Fixed Risk Relaxation less stricter
first conjunct (62) (63). Therefore, cost optimal solution Fixed Risk
Relaxation less equal original subproblem.
Lemma 7. FRR gives tightest lower bound among linear relaxations constraints (62)
(63).
Proof. linear relaxation (62) (63) becomes tighter fixing c,i t,i lesser value.
However, setting c,i t,i values less c may exclude feasible solutions, one
545

fiO , W ILLIAMS , & B LACKMORE

Algorithm 5 FRR implementation obtainLowerBound function Line 8 Algorithm 1
function obtainLowreBound-FRR(subproblem) returns lower bound
1: (c, i, j) subproblem.C
2:
subproblem.Cc,i,j .rhs mc,i,j (c ) //Apply fixed risk relaxation
3: end
4: (t, i)
5:
subproblem.Dt,i .rhs mU,t,i //Apply fixed risk relaxation
6: end
7: Remove subproblem.R
8: Solve subproblem using LP solver
9: return optimal objective value

sets c,i = c (c, i). Hence, FRR tightest linear relaxation (62) (63),
resulting tightest lower bound.
Note optimal solution Fixed Risk Relaxation (Problem 8) typically infeasible
solution Problem 7, since setting c,i = t,i = c violates constraint (64).
Algorithm 5 implements fixed risk relaxation. LP relaxation solved LP solver,
optimal objective value returned.
completes second spiral, planning CCQSPs fixed schedule nonconvex
constraints. next section, turn final spiral, involves flexible temporal constraints.

6. CCQSP Planning Flexible Schedule
section presents complete p-Sulu Planner, efficiently solves general CCQSP
planning problem flexible schedule non-convex state space (Problem 2 Section
3.1.2). problem find schedule events satisfies simple temporal constraints,
well nominal control sequence u0:N 1 satisfies chance constraints minimizes cost.
approach first generate feasible schedule extend control sequence
schedule, iteratively improving candidate schedules using branch-and-bound.
build p-Sulu Planner upon NIRA algorithm presented previous section. Recall
NIRA optimizes nominal control sequence u0:N 1 given fixed schedule s. p-Sulu
Planner uses NIRA subroutine takes schedule input, outputs optimal
objective value well executable control sequence. denote optimal objective value
given schedule J (s). Using notation, CCQSP planning problem flexible
schedule (Problem 2) rewritten schedule optimization problem follows:
min J (s).

sSF

(67)

Recall domain feasible schedules SF (Definition 11) finite set, since consider
discretized, finite set time steps (see Section 2.1). Hence, schedule optimization problem
(67) combinatorial constraint optimization problem, constraints given form
simple temporal constraints.
546

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Algorithm 6 p-Sulu Planner
function pSulu(ccqsp) returns optimal schedule control sequence
1: Incumbent =
2: Set queue FILO queue
3: E0 = {e0 }, 0 (e0 ) = 0
//initialize partial schedule
4: queue E0 , 0
5: queue empty
6:
E , last entry queue
7:
Remove E , queue
8:
[J , u0:N 1 ] obtainLowerBound(ccqsp, E , )
9:
J < Incumbent
10:
E = E
11:
Incumbent J , OptCtlSequence u0:N 1 , OptSchedule
12:
else
13:
expand(ccqsp, queue, e, E , )
14:
end
15:
end
16: end
17: return OptCtlSequence, OptSchedule

6.1 Algorithm Overview
solution approach use branch-and-bound algorithm. branch-and-bound
search, p-Sulu Planner incrementally assigns execution time step event order
find schedule minimizes J (s) (67). objective function evaluated solving
fixed schedule CCQSP planning problem using NIRA algorithm. Although combination
two branch-and-bound searches p-Sulu Planner NIRA equivalent one unified
branch-and-bound search practice, treat separately ease explanation.
shown Figure 12, branch-and-bound algorithm searches optimal schedule
incrementally assigning execution time steps event depth-first manner. node
search tree corresponds partial schedule (Definition 2), assigns execution time steps
subset events included CCQSP. partial schedule root node involves
assignment start node e0 . tree expanded assigning execution time step one new
event time. example, node (e1 ) = 2 Figure 12-(a) represents partial schedule
assigns execution time step = 0 event e0 = 2 e1 , leaving eE unassigned.
p-Sulu Planner obtains lower bound objective function value J (s) solving
CCQSP planning problem partial schedule extended s. p-Sulu
Planner minimizes search space dynamically pruning domain forward checking.
specifically, execution time assigned event iteration branch-andbound search, p-Sulu Planner runs shortest-path algorithm tighten real-valued upper
lower bounds execution time step unassigned events according newly assigned
execution time step.
Algorithm 6 shows pseudocode algorithm. node search tree, fixedschedule CCQSP planning problem solved given partial schedule. node
547

fiO , W ILLIAMS , & B LACKMORE

leaf tree optimal objective value less incumbent, optimal solution
updated (Line 11). node leaf, optimal objective value corresponding
subproblem lower bound optimal objective value subsequent nodes. lower
bound less incumbent, node expanded enumerating feasible execution time
assignments unassigned event (Line 13). Otherwise, node expanded, hence
pruned. Details branch-and-bound process described later subsections.

Figure 10: (a) example CCQSP; (b) plan satisfies CCQSP (a)

Figure 11: (a) directed distance graph representation CCQSP Figure 10-(a); (b) dgraph (a), shows shortest distances nodes; (c) updated d-graph
execution time = 2 assigned event e1 .

(e0) = 0
(e1)

(e0) = 0

0
1

2

(e1) = 2

3

(eE)

(eE)
(a)

0
1

2
4

3
5

(b)

Figure 12: Branch-and-bound search schedule s. assume time interval =
1.0. (a)
node (e0]) = 0 expanded; De1 () = {1, 2, 3} given (e0 ) = 0,
[ max
since de (), dmin
1) = 2
e () = [0.8, 3.9] Figure 11-(b); (b)
]
[ node (emin
()
=
(),

expanded; DeE () = 4, 5 given (e0 ) = 0 (e1 ) = 2, since dmax
e
e
[3.6, 5.5] Figure 11-(c).

548

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Walk-through example present walk-through example give readers insight solution process. consider CCQSP shown Figure 10-(a). CCQSP specifies mission
go waypoint get goal region B avoiding obstacle C, shown
Figure 10-(b). assume time interval = 1.0.
Figures 11 12 illustrate solution process. p-Sulu Planner algorithm initialized
assigning execution time 0 start event e0 . Figure 11-(a) distance graph representation simple temporal constraints (Dechter, 2003) CCQSP. Note simple chance
constraint equivalently represented pair inequality constraints follows:
s(e) s(e ) [l, u] s(e) s(e ) u s(e ) s(e) l.
two inequality constraints represented two directional edges two nodes
distance graph. p-Sulu Planner runs all-pair shortest-path algorithm distance
graph obtain d-graph shown Figure 11-(b). d-graph completed distance graph
edge labeled shortest-path length. d-graph represents tightest temporal
constraints. algorithm enumerates feasible execution-time assignments event
e1 using d-graph. According d-graph, execution time event e1 must
0.8 3.9. Since consider discrete time steps time interval = 1.0, feasible
execution time steps e1 {1, 2, 3}. idea behind enumerating feasible execution time
steps assign event, thus tighten bounds unassigned events order ensure
feasibility.
node (e1 ) = 1, p-Sulu Planner solves FRR fixed-schedule CCQSP
planning problem End episode execution schedule (e1 ) = 1.
words, tries find optimal path goes = 1, neglects goal B
obstacle C. solution exists, optimal cost gives lower bound objective value
feasible paths go = 1. Assume solution exist. Then,
p-Sulu Planner prunes node (e1 ) = 1, goes next node (e1 ) = 2. solves
FRR corresponding fixed-schedule subproblem find best path goes
= 2. Assume p-Sulu Planner finds solution. Then, p-Sulu Planner expands
node following process. First, fixes execution time (e1 ) = 2 d-graph,
runs shortest-path algorithm order tighten temporal constraints (11-(c)). pSulu Planner uses updated d-graph enumerate feasible execution-time assignments
event eE , {4, 5}. visits nodes solves fixed-schedule subproblems exactly
episodes fully assigned schedule. example, node (eE ) = 5, computes
best path goes = 2 reaches B = 5 avoiding obstacle C,
shown Figure 10-(b). Assume optimal objective values subproblems 10.0
(eE ) = 4 8.0 (eE ) = 5. algorithm records solution (eE ) = 5 cost
8.0 incumbent.
algorithm backs visits node (e1 ) = 3, relaxed subproblem
End episode solved obtain lower bound objective value subsequent
nodes. lower bound turns 9.0, exceeds incumbent. Therefore, branch
pruned. Since nodes expand, algorithm terminated, incumbent
solution returned.
549

fiO , W ILLIAMS , & B LACKMORE

Algorithm 7 Implementation expand function Line 13 Algorithm 6
function expand(ccqsp, queue, e, E , )
1: Fix distance e0 e (e)T d-graph ccqsp
2: Update d-graph running shortest-path algorithm
3: Choose e E\E
//choose unassigned event
4: E := E e
max
5: De () := { | dmin
e () tT de ()}
6: De ()
{
(e) (e E )

7:
(e) :=
//update partial schedule

(e = e )
8:
queue E ,
9: end
6.2 Branching
Algorithm 7 outlines implementation expand() function Algorithm 6. takes partial
schedule input, adds queue set schedules assign execution time step
additional event e . words, domain newly added schedules E one
assigned event domain input partial schedule E . details Algorithm 7
explained following parts subsection.
6.2.1 E NUMERATION F EASIBLE IME TEP SSIGNMENTS USING - GRAPH
enumerating feasible time steps, simple temporal constraints must respected.
accomplish this, use d-graph translate bounds durations two events
bounds execution time step event. shown Dechter et al. (1991)
set feasible execution times event e bounded distance e e0 dgraph. d-graph directed graph, weights edges represent shortest distances
nodes, Figure 11-(b). order obtain d-graph representation, first translate
simple temporal constraints directed distance graph, Figure 11-(a). weight
edge two nodes (events) corresponds maximum duration time origin node
destination node, specified corresponding simple temporal constraint. distance
takes negative value represent lower bounds. d-graph (Figure 11-(b)) obtained
distance graph (Figure 11-(a)) running all-pair shortest-path algorithm (Dechter et al., 1991).
Forward checking d-graph p-Sulu Planner algorithm incrementally assigns
execution time step event, explained walk-through example. p-Sulu Planner
minimizes search space forward checking using d-graph. forward checking
methods Constraint Programming, method prunes values unassigned variables (i.e.,
execution times unassigned event) violate simple temporal constraints. different
normal forward checking back tracking performed, due decomposability
d-graph. forward checking conducted following process. execution time step
assigned event e (i.e., (e) = t), distance e0 e fixed tT , distance
e e0 fixed tT distance graph (Line 1 Algorithm 7). Recall
index discretized time steps fixed interval , temporal bounds given
real-valued times (Section 2.1). run shortest-path algorithm update d-graph (Line
550

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

2). Given partial schedule , denote updated shortest distance start event e0 e

min
d-graph dmax
e (), distance e e0 de ().
example, execution time 2 assigned event e1 Figure 11-(c) (i.e., (e1 ) = 2),
distance e0 e1 fixed 2 distance opposite direction fixed
2. run shortest-path algorithm update d-graph. result, obtain
min
updated distances dmax
eE () = 5.5 deE () = 3.6.
max
Dechter et al. (1991) showed de () corresponds upper bound feasible execution time unassigned event e , dmin
eE () corresponds negative lower bound.
Hence, partial schedule assigned events e E , updated domain unassigned
max
event e
/ E bounded dmin
e () de (). Note domain execution time steps
max
e included in, equal [dmin
e (), de ()], consider discrete execution
time steps finite set T. forward checking, p-Sulu Planner computes
max

real-valued bounds [dmin
e (), de ()]. feasible values unassigned variable e

enumerated search tree expanded e .
Enumerating domain execution time steps unassigned event readily
extract feasible execution time steps unassigned event e
/ E updated d-graph
partial schedule . Let De () domain execution time steps unassigned event
e
/ E , given partial schedule . finite domain De () obtained follows:
max
De () := { | dmin
e () tT de ()}.

Note De () may empty temporal constraints tight, even though feasible. user p-Sulu Planner must make small enough De empty.
example, Figure 11-(b) d-graph given partial schedule {(e0 ) = 0}. According
d-graph, e1 must executed 0.8 3.9. Assuming = 1, set feasible
execution time steps e1 De1 () = {1, 2, 3}, shown Figure 12-(a). Likewise, Figure 11-(c)
d-graph given partial schedule {(e0 ) = 0, (e1 ) = 2}; feasible execution time eE
3.6 5.5. Hence, set feasible execution time steps eE DeE () = {4, 5},
shown Figure 12-(b).
enumeration conducted Line 6 Algorithm 7. algorithm creates extensions
input partial schedule assigning time steps e (Line 7), puts extended
partial schedules queue (Line 8).
6.2.2 E FFICIENT VARIABLE RDERING B RANCH - -B OUND EARCH
choosing next event assign time step Line 3 Algorithm 7, two variable ordering
heuristics found effective order reduce computation time.
first heuristic new convex-episode-first (CEF) heuristic, prioritizes events
associated non-convex constraints. idea CEF heuristic based
observation subproblems branch-and-bound algorithm particularly difficult solve
episodes A(E ) involve non-convex state constraints. Remain R2 \C (2D
plane minus obstacle C) episode walk-through example Figures 10 example
non-convex episodes. Therefore, effective approach reduce computation time
p-Sulu Planner minimize number non-convex subproblems solved branch-andbound process. idea realized sorting events episodes convex
feasible region always examined branch-and-bound process episodes
551

fiO , W ILLIAMS , & B LACKMORE

non-convex feasible region. walk-through example, note visited event e1
event eE example. End episode involves convex state
constraint Remain R2 \C (2D plane minus obstacle C) non-convex.
second one well-known constrained variable heuristic. p-Sulu Planner
expands node, counts number feasible time steps unassigned events, chooses
one least number feasible time steps. second heuristic used break ties
first heuristic.

6.3 Bounding
next present implementation obtainLowerBound() function Line 8 Algorithm 6.
algorithm obtains lower bound solving relaxed CCQSP planning problem fixed
partial schedule.
Algorithm 8 outlines implementation obtainLowerBound() function. takes partial
schedule input, outputs lower bound objective function, well optimal
control sequence, given partial schedule . constructs relaxed optimization problem,
involves episodes whose start end events assigned execution time steps (Line 1).
optimization problem involves non-convex constraints, NIRA algorithm used obtain
solution problem (Line 3). Otherwise solve FRR convex optimization problem
obtain lower bound efficiently (Line 5). input fully assigned schedule (E = E),
corresponding node leaf node. case obtain exact solution CCQSP
planning problem fixed schedule running NIRA algorithm (Line 3). details
Algorithm 8 explained subsequent part subsection.

Algorithm 8 Implementation obtainLowerBound function Line 8 Algorithm 6
function obtainLowerBound(ccqsp, E , ) returns optimal objective value control sequence
1: subprblem Problem 9 given ccqsp
2: E = E A() episodes non-convex state regions,
3:
[J , u0:N 1 ] NIRA(subprblem) //Algorithm 1
4: else
5:
J obtainLowreBound-FRR(subprblem) //Algorithm 5
6:
u0:N 1
7: end
8: return [J , u0:N 1 ]

6.3.1 R ELAXED PTIMIZATION P ROBLEM PARTIAL CHEDULE
consider relaxed optimization problem follows:
552

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Problem 9: Relaxed Optimization Problem Partial Schedule
J () =

min
u0:N 1 UN
s.t.

J(u0:N 1 , x1:N , )

(68)

, xt+1 = xt + B ut




(69)
hTc,a,k,j xt gc,a,k,j mc,a,k,j (c,a,k )

cC a(c A()) ta () kKa jJa,k

(70)



c,a,k 1 c ,

(71)

kKa ,a(c A())

J () optimal objective value relaxed subproblem partial schedule .
Recall A() partial episode set , involves episodes whose start
end nodes assigned execution time steps partial schedule (Definition 9).
notational simplicity, merge three conjunctions (70) obtain following:

hTc,i,j xti gc,i,j mc,i,j (c,i ).
cC iIc () jJc,i

Note chance constraint exactly (57), except partial schedule
specified instead fully assigned schedule s. Hence, Problem 9 instance non-convex
CCQSP planning problem fixed schedule (Problem 6), optimally solved
NIRA algorithm. note fully assigned schedule leaf node branch-andbound search tree.
optimal objective value Problem 9 gives lower bound optimal objective value
subsequent subproblems branch-and-bound tree. property formally stated
Lemma 8 below. order prove feature, first define concept extension
partial schedule follows:
Definition 14. schedule : E 7 extension partial schedule : E 7
assign time steps events domain :
(e) = s(e) e E .
example, Figure 12-(b), fully assigned schedule {s(e0 ) = 0, s(e1 ) = 2, s(eE ) = 4}
{s(e0 ) = 0, s(e1 ) = 2, s(eE ) = 5} extension partial schedule {(e0 ) = 0, (e1 ) = 2}.
following lemma always holds:
Lemma 8. schedule extension partial schedule , optimal objective value
Problem 9 lower bound optimal objective value s:
J () J (s).
Proof. Since partial schedule, E E, hence A() A. Also, since (e) = s(e)
e E , state constraints chance constraint (70) Problem 9 partial schedule
included problem full schedule s. means feasible state space
553

fiO , W ILLIAMS , & B LACKMORE

problem subset one . Hence, chance constraint (24) problem
satisfied, chance constraint (70) problem satisfied. Therefore,
problem always results better (less) equal cost problem ,
former looser constraints.

example, Figure 12-(b), e1 assigned execution time step eE not.
Therefore, node (e1 ) = 2, chance-constrained optimization problem End
episode solved partial schedule {(e0 ) = 0, (e1 ) = 2} (see Figure 10-(a)). gives
lower bound cost problems fully assigned schedules {s(e0 ) = 0, s(e1 ) =
2, s(eE ) = 4} {s(e0 ) = 0, s(e1 ) = 2, s(eE ) = 5}.
Algorithm 8 obtains lower bound solving Problem 9 exactly using NIRA algorithm,
involves episodes non-convex state regions (Line 3). function called leaf node,
Problem 9 solved exactly NIRA. solutions leaf subproblems
candidate solutions optimal solution overall problem. Hence, solving exactly,
ensure optimality branch-and-bound search.
6.3.2 F URTHER B OUNDING FRR
relaxed subproblem (Problem 9) convex, p-Sulu Planner solves FRR subproblem, instead solving exactly NIRA, order obtain lower bound efficiently
(Line 5 Algorithm 8). Many practical CCQSP execution problems one episode
non-convex feasible region. example, CCQSP planning problem shown Figures
2 3, safe region (R2 minus obstacles) non-convex, Provincetown (start
region), Scenic region, Bedford (goal region) convex. case subproblems
solved exactly leaf nodes, lower bounds always evaluated approximate
solutions FRRs subproblems non-leaf nodes.

7. Results
section empirically demonstrate p-Sulu Planner efficiently operate various
systems within given risk bound. first present simulation settings Section 7.1. Section 7.2 presents simulation results NIRA algorithm, validates claim
efficiently compute feasible near-optimal solution. Section 7.3 demonstrates p-Sulu Planner two different benchmark problems. simulation results highlight p-Sulu Planners
capability operate within user-specified risk bound. Section 7.4 deploys p-Sulu Planner
PTS scenarios, Section 7.5 applies p-Sulu Planner space rendezvous
autonomous cargo spacecraft International Space Station.
7.1 Simulation Settings
Recall that, stated Section 2.4, p-Sulu Planner takes four inputs: stochastic plant model
M, initial condition I, CCQSP P , objective function J. section specifies
J, commonly used problems Sections 7.2-7.4. specify P
problem corresponding section.
554

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

7.1.1 TOCHASTIC P LANT ODEL
section explains plant model used Sections 7.2 - 7.4. Section 7.5 uses different plant
model described detail Section 7.5.2. consider point-mass double-integrator plant,
shown (72)-(73). Parameters, umax , vmax , 2 , set individually
problem. plant model commonly assumed literatures unmanned aerial vehicle (UAV)
path planning (Kuwata & How, 2011; Leaute, 2005; Wang, Yadav, & Balakrishnan, 2007).
state vector xt consists positions velocities x directions, control
vector consists accelerations:
xt := [x vx vy ]T ,

ut := [ax ay ]T .

plant model specified following matrices:





1 0 0
t2 /2
0
0 1 0


0
t2 /2
, B =
, w =
A=
0 0 1




0
0 0 0
1
0

T, ||ut || umax , ||Cxt || vmax ,
(


C=

0 0 1 0
0 0 0 1

2 0
0 2
0 0
0 0

0
0
0
0


0
0
(72)
0
0
(73)

)
.

first constraint (73) imposed order limit acceleration. nonlinear constraint
approximated following set linear constraints:
T, r n ut umax (n = 1, 2, , Nr )
]
[
2n
2n
, sin
r n = cos
Nr
Nr
choose Nr = 16. second constraint (73) imposed order limit velocity. use
linear approximation above.
7.1.2 BJECTIVE F UNCTION
Sections 7.2.3, 7.3, 7.4, cost function Manhattan norm control input
planning horizon, follows:
J(xti , U , s) =




(|ux,t | + |uy,t |) .

t=1

cost function represents total change momentum, roughly proportional
fuel consumption aerial vehicle. Note minimization problem piece-wise linear
cost function equivalently replaced following minimization problem
linear cost function additional linear constraints introducing slack variables x,t y,t :
min




(x,t + y,t )

t=1

s.t.

T,

x,t ux,t x,t ux,t y,t uy,t y,t uy,t
555

fiO , W ILLIAMS , & B LACKMORE

Section 7.2.4, minimize expected quadratic cost follows:


[
]
J(xti , U , s) =
E u2x,t + u2y,t .

(74)

t=1

7.1.3 C OMPUTING ENVIRONMENT
simulations except ones Section 7.2 conducted machine dual-core
Intel Xeon CPU clocked 2.40 GHz, 16 GB RAM. algorithms implemented
C/C++, run Debian 5.0.8 OS. simulations Section 7.2 conducted machine
quad-core Intel Core i7 CPU clocked 2.67 GHz, 8 GB RAM. algorithms
implemented Matlab, run Windows 7 OS. used IBM ILOG CPLEX Optimization
Solver Academic Edition version 12.2 linear program solver, SNOPT version 7.2-9
convex optimization solver.
7.2 NIRA Simulation Results
first statistically compare performance NIRA prior art. Recall NIRA
solver CCQSP planning problems non-convex state constraints fixed schedule
(Problem 3), used subroutine p-Sulu Planner.
7.2.1 C OMPARED LGORITHMS
two existing algorithms solve problem:
1. Fixed risk allocation (Blackmore et al., 2006) - approach fixes risk allocation
uniform value. result, assumption cost function linear, Problem 6
reformulated mixed-integer linear programming (MILP) problem,
solved efficiently MILP solver, CPLEX.
2. Particle Control (Blackmore, 2006) - Particle Control sampling-based method,
uses finite number samples approximate joint chance constraints. control
sequence optimized number samples violate constraints less c Np ,
Np total number samples. optimization problem reformulated
MILP, assumption cost function linear.
compare NIRA MDP Section 7.2.5. Although MDP solve
exactly problem NIRA, avoid risk considering penalty cost constraint
violations. purpose comparison highlight capabilities chance-constrained
planning provide guarantee probability failure.
7.2.2 P ROBLEM ETTINGS
compare closed-loop open-loop NIRAs two algorithms 2-D path planning
problem randomized location obstacle, shown Figure 13. vehicle starts
[0, 0] heads goal [1.0, 1.0], avoiding rectangular obstacle. obstacle
edge length 0.6 placed random location within square region corners [0, 0],
[1, 0], [1, 1], [0, 1]. consider ten time steps time interval = 1.0. require
556

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

mean state = 10 [1.0, 1.0]. risk bound set = 0.01. set standard
deviation disturbance = 0.01. use expected quadratic cost function given (74).
steady-state LQR gain used closed-loop NIRA Q = I4 R = 10000I2 ,
n n identity matrix Q R cost matrices state control variables,
respectively.
1

NIRA (closed-loop)
NIRA (open-loop)
Fixed Risk Allocation
Particle Control

0.8

NIRA (closed-loop)
NIRA (open-loop)

1
0.8

0.6

0.6

0.4

0.4

0.2

0.2
0

0
0

0.2

0.4

0.6

0.8

1

0

(a) Nominal trajectories

0.2

0.4

0.6

0.8

1

(b) Nominal trajectories 3 ellipses

Figure 13: (a) instance 2-D path planning problem used 7.2.3. obstacle
fixed size randomly placed within unit square run. (b) mean
standard deviation closed-loop open-loop NIRAs.

7.2.3 P ERFORMANCE C OMPARISON
Recall solution NIRA algorithm, used p-Sulu Planner solve subproblems, exactly optimal solution Problem 3, since risk allocation (Section 4.1.1)
risk selection (Section 5.1.1) replace chance constraint (29) sufficient condition (57)
(59). Since chance constraint (29) difficult evaluate, previously proposed
methods solve optimization approximation. provide empirical evidence risk
allocation/selection approach results solution significantly closer optimal solution
prior art, satisfaction original constraint (29) guaranteed.
evaluate suboptimality solutions difference risk bound, =
0.001, resulting probability constraint violation, Pf ail , estimated Monte-Carlo simulation. 1 Pf ail equal left-hand-side value (29) Problem 3. Hence, chance
constraint (29) equivalent to:
Pf ail .
strictly optimal solution problem achieve Pf ail = , although exact
solution unavailable, since algorithm solve Problem 3 exactly. solution suboptimal Pf ail < , ratio /Pf ail represents degree suboptimality. solution
violates chance constraint Pf ail > .
557

fiO , W ILLIAMS , & B LACKMORE

Algorithm
NIRA (Closed-loop)
NIRA (Open-loop)
Fixed Risk Allocation
Particle Control
(100 particles)

Computation time
[sec]
54.8 36.9
25.0 13.1
0.42 0.04

Probability failure

Cost

0.0096 0.0008
0.0095 0.0008
(2.19 0.40) 104

0.666 0.061
0.672 0.068
0.726 0.113

41.7 12.8

0.124 0.036

0.635 0.048

Table 1: averages standard deviations computation time, probability constraint violation, cost four algorithms. algorithms run 100 times
random location obstacle. risk bound set = 0.01. Note Particle
Control results less cost two methods solutions violate
chance constraint.

Table 1 compares performance four algorithms. values table averages standard deviations 100 runs random locations obstacle. probability
constraint violation, Pf ail , evaluated Monte-Carlo simulations 106 samples.
Comparison closed-loop open-loop NIRAs comparing NIRA existing algorithms, first compare two variants NIRA: closed-loop open loop NIRAs. Table
1 shows closed-loop NIRA results less cost open-loop NIRA. Importantly,
former outperforms latter 100 test cases. reduction cost closed-loop
approach explained Figure 13-(b), shows 3 ellipses probability distribution
state. Since closed-loop NIRA assumes feedback control, future position less uncertain. result, plan generated closed-loop NIRA less conservative. fact, Table
1 shows Pf ail closed-loop NIRA closer risk bound open-loop
NIRA. However, closed-loop planning problem requires twice much solution time
open-loop one since complicated due additional chance constraints control input.
Comparison fixed risk allocation approach Table 1 shows closed open NIRAs
result average probabilities failure 0.0096 0.0095 respectively, within userspecified risk bound = 0.01. hand, fixed risk allocation approach results
conservative probability failure, Pf ail = 0.000219, 98% smaller .
result indicates solution NIRA significantly closer exactly optimal solution
fixed risk allocation approach. fact, NIRA algorithm results less cost fixed risk
allocation approach 100 runs. optimizes risk allocation
fixed risk allocation approach uses predetermined risk allocation.
Figure 14 shows suboptimality measure /Pf ail open-loop NIRA different settings risk bound . values , suboptimality NIRA significantly smaller
fixed risk allocation approach. graph shows tendency suboptimality NIRA
gets smaller less , suboptimality fixed risk allocation approach approximately constant.
NIRA achieves improvement solution optimality cost computation time; Table
1 shows NIRA takes longer computation time risk allocation approach factor
558

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Pfail /

Figure 14: Suboptimality NIRA fixed risk allocation approach. Strictly optimal solution
/Pf ail = 1. smaller value /Pf ail indicates solution suboptimal.

two. Hence, NIRA fixed risk allocation approach provide users trade-off
suboptimality computation time.
Comparison Particle Control Table 1 shows average probability failure
Particle Control approach higher risk bound = 0.01, meaning approach
tends generate infeasible solutions. hand, NIRA guarantees satisfaction
chance constraint since employs conservative approximation joint chance constraint.
Particle Control guarantee solution converges optimal solution increasing number samples infinity. However, using large number samples impractical,
since computation time memory usage grow exponentially number samples increases.
example, used 100 samples analysis Table 1. using 300 samples, took
4596 seconds (about 1.5 hours) solve problem obstacles centered [0.5, 0.5].
Computation 1000 samples could conducted, shortage memory.
hand, computation time NIRA significantly shorter PC, guaranteeing
feasibility solution.
7.2.4 PTIMAL P LANNING E XPECTED C OST
Next demonstrate capability p-Sulu Planner handle expected cost, instead cost
expected trajectory, path planning problem presented above. Specifically,
consider expected quadratic cost function shown (74). conducting open-loop planning,
cost function transformed function nominal control inputs constant term
using equality (15). However, performing closed-loop planning, equality
exact, due controller saturation. Nevertheless, use (15) approximation expected
cost, explained Section 2.4.4. subsection empirically evaluate error
approximation.
559

fiO , W ILLIAMS , & B LACKMORE

Approximate expected cost
0.048434950 0.010130589

Actual expected cost
0.048434956 0.010130588

Table 2: Comparison approximate expected cost obtained closed-loop NIRA
actual expected cost. table shows mean variance 100 runs random
location obstacle.

Table 2 compares approximate expected cost function value obtained closed-loop
NIRA actual expected cost estimated Monte-Carlo simulation one million samples.
path planning problem solved 100 times randomized location obstacle. risk
bound set = 0.01. shown table, approximate cost almost exactly agrees
actual cost. closed-loop planning approach explicitly bounds risk
controller saturation.
7.2.5 C OMPARISON MDP
Next compare NIRA MDP formulation. sake tractability MDP,
consider single integrator dynamics two-dimensional state space two-dimensional
control input, specifies velocity vehicle. rest problem setting same,
except state space discretized 100-by-100 grid. implement finite-horizon
MDP-based path planner, imposes penalty c event failure minimizes
expected cost based explicit state dynamic programming. MDP-based path planner imposes
cost follows:
]
[
(
)
u2x,t + u2y,t + cI(xt ) ,
E
t=1

I(xt ) indicator function one xt obstacle zero otherwise.
resulting optimization problem solved via dynamic programming.
ran MDP-based path planner three values penalty c: 1, 10, 100.
choice c, conducted 100 simulations randomized obstacle position. Figure 14 shows
typical output MDP-based path planner. Note that, small penalty (c = 1), path
planner chooses take 100% risk failure ignoring obstacle. simply
penalty failure smaller expected reduction cost going obstacle.
issue utilitarian approaches MDPs minimization unconstrained cost
sometimes lead impractical solution.
Table 3 shows mean standard deviation path lengths, well maximum,
minimum, mean resulting probability failure among 100 runs. expected,
imposing larger penalty, MDP-path planner chooses risk-averse path,
longer nominal path length. sense, MDP conduct trade-off cost
risk. MDP particularly useful primary concern user cost failure instead
probability failure. hand, user would impose hard bound
probability failure, chance constrained planning approach advantage. Observe that,
even penalty value, MDP-based path planner results wide range failure
probabilities depending location obstacle. notably, c = 10,
560

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

paths move directly across obstacle, doing, accept 100% probability failure,
others go around obstacle. Undesirable behaviors, crossing obstacle, likely
suppressed imposing greater penalty, without guarantee. Moreover, imposing heavy
penalty failure often results overly conservative, risk averse solution. hand,
behavior NIRA regarding risk predictable, sense path guaranteed
go around obstacle, regardless location. chance constraint requires
exists margin path boundary obstacle. p-Sulu Planner
inherits property NIRA.

1

0.8

0.6

0.4

0.2

c=1
c=10
c=100

0
0

0.2

0.4

0.6

0.8

1

Figure 15: Optimal paths generated MDP-based planner different penalty levels , c.
red rectangle represents obstacle. Note path c = 1 cuts
obstacle.

Penalty c

path length

1
10
100

1.41 0.00
1.54 0.05
1.57 0.06

Probability failure
Max
Mean Min
1.000 1.000 1.000
1.000 0.375 0.096
0.1215 0.031 0.009

Table 3: 100 runs randomized obstacle location

7.3 p-Sulu Planner Simulation Results
Next present simulation results p-Sulu Planner two problems, order illustrate
capability planning schedule constraints. empirically evaluate scalability
p-Sulu.
561

fiO , W ILLIAMS , & B LACKMORE

Figure 16: sample CCQSP personal aerial vehicles path planning scheduling problem.

Figure 17: Output p-Sulu Planner CCQSP Figure 16 three different settings
risk bound obs , compared path planned deterministic planner, Sulu,
consider chance constraints.

7.3.1 PATH P LANNING BSTACLES
simulation test p-Sulu Planner path planning problem environment shown
Figure 17. input CCQSP shown Figure 16. CCQSP requires vehicle arrive
goal region within 15 minutes, going Waypoint 1 Waypoint 2 temporal
constraints specified Figure 16. imposes two chance constraints: one requires
vehicle achieve time-evolved goals 90% certainty, another requires vehicle
limit probability violating obstacles obs . set = 1 2 = 0.0025.
Figure 17 shows plans generated p-Sulu Planner three different risk bounds:
obs = 10%, 0.1%, 0.001%. computation times 79.9 seconds, 86.4 seconds,
88.1 seconds, respectively. Figure 17 shows plan generated Sulu, deterministic planner
explicitly consider uncertainty (Leaute & Williams, 2005). Observe Sulu leaves
margin path obstacles. result, Sulu path results 94.1% probability
hitting obstacles, estimated Monte-Carlo simulation 107 samples. hand,
p-Sulu Planner leaves margins path obstacles order satisfy risk bound,
562

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

specified chance constraint. margins larger plans smaller risk bounds.
probabilities failure three plans generated p-Sulu Planner, estimated Monte-Carlo
simulations 107 samples, 9.53%, 0.0964%, 0.00095%, respectively. Hence chance
constraints satisfied. schedule optimized p-Sulu Planner {s(e0 ) = 0, s(e1 ) =
5, s(e2 ) = 10, s(eE ) = 15}, satisfies temporal constraints CCQSP.
Figure 16, appears path cuts across obstacle. due discretization
time; optimization problem requires vehicle locations discrete time step
satisfy constraints, consider state between. issue addressed
constraint-tightening method (Kuwata, 2003).
7.3.2 PATH P LANNING NDOOR E NVIRONMENT

Figure 18: sample CCQSP path planning problem indoor environment.

= 10%
= 1%
= 0.1%

1.2
1
Goal
0.8
0.6
0.4
0.2
0

Start

0.2
0.2

0

0.2

0.4

0.6

0.8

1

1.2

Figure 19: Output p-Sulu Planner CCQSP Figure 16 three different settings
risk bound obs .

next give p-Sulu Planner CCQSP shown Figure 18, simulates path planning problem indoor environment. vehicle must get goal region side
room three five seconds. Remain safe region episode requires vehicle stay
563

fiO , W ILLIAMS , & B LACKMORE

within room outside obstacle five-second planning horizon. CCQSP
imposes two chance constraints shown Figure 18. set = 0.5 2 = 5.0 105 .
Given CCQSP, planner faces choice: heading straight goal going
narrow passage left wall obstacle minimizes path length, involves
higher risk constraint violation; making detour around right side obstacle involves
less risk, results longer path.
Figure 19 shows p-Sulu Planners outputs obs = 10%, 1%, 0.1%. computation times 35.1 seconds, 84.5 seconds, 13.3 seconds, respectively. result consistent
intuition. p-Sulu Planner allowed 10% risk, planner chooses go straight
goal, resulting cost function value 1.21; user gives 1% 0.1% risk bound,
chooses risk-averse path, resulting cost function values 3.64 3.84, respectively.
example demonstrates p-Sulu Planners capability make intelligent choice order
minimize cost, limiting risks user-specified levels.
7.3.3 CALABILITY NALYSIS
subsection conduct empirical analysis scalability p-Sulu Planner,
environment becomes increasingly constrained.. shown Figure 20, measured computation time solve path planning problem different numbers obstacles waypoints.
simulations, path starts [0, 12] ends square region centered [24, 12]. Figure 20
shows twenty simulation results, zero three obstacles zero four waypoints. Obstacles
waypoints represented blue red squares figure, respectively. positions
center obstacles [6, 12], [12, 12], [18, 12], positions center
waypoints [9, 9], [9, 15], [15, 15], [15, 9]. computation time shown caption
subfigure Figure 20.
comparing results Figure 20 horizontally, observe exponential growth computation time number obstacles. result expected since number disjunctive
clauses state constraint p-Sulu Planner increases exponentially number
obstacles. Building tractable extension p-Sulu Planner large number obstacles
future work. hand, comparing results vertically, find computation
time number obstacles different number waypoints stays order
magnitude. adding extra waypoint increases number conjunctive
clauses state constraints.
remaining sections describe application psulu two real world problems, air
vehicle space vehicle control. third application, building energy management, using variant
p-Sulu Planner, reported Ono, Graybill, Williams (2012).
7.4 PTS Scenarios
Next, deploy p-Sulu Planner PTS scenarios, robotic air taxi system introduced
Section 1.
7.4.1 CENARIOS
consider three scenarios, specified CCQSPs shown Figure 21. Scenarios 1 2
similar scenic flight scenario introduced beginning paper (see Figure 1).
564

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

0.003 sec

0.173 sec

51.47 sec

677.2 sec

0.016 sec

0.518 sec

48.25 sec

648.4 sec

0.034 sec

1.047 sec

118.3 sec

4327 sec

0.076 sec

2.613 sec

159.1 sec

5686 sec

0.036 sec

3.873 sec

165.9 sec

6845 sec

15
12
9

15
12
9

15
12
9

15
12
9

15
12
9
0

9

15

24

0

9

15

24

0

9

15

24

0

9

15

24

Figure 20: Computation time p-Sulu Planner path planning problem different numbers obstacles waypoints.

Scenario 1, personal aerial vehicle (PAV) takes Runway 71 Provincetown Municipal
Airport (KPVC) Provincetown, Massachusetts, fly scenic region, lands Runway 23
Hanscom Field (KBED) Bedford, Massachusetts. vehicle required stay within
scenic region least 2 minutes 10 minutes. entire flight must take
13 minutes less 15 minutes. Scenario 2 Scenario 1, except runways
used take-off landing.
Scenario 3 simulates leisure flight coast Massachusetts. PAV takes Runway 7
Provincetown Municipal Airport, flies two regions whales often seen.
vehicle lands Runway 11 Hanscom Field.
place three no-fly zones, shown Figure 22. entire flight must take 13
minutes less 15 minutes. scenario three chance constraints, {c1 , c2 , c3 }, shown
Figure 21. first one, c1 , concerned vehicles operation; requires vehicle
take land right runways right airports less 10 % probability
failure. second chance constraint, c2 , concerned leisure activities; requires
vehicle fly scenic regions less 10 % probability failure. Finally, c3
concerned passengers safety; requires vehicle limit risk penetrating
no-fly zones 0.01 %.
1. runway airport specified number, represents clockwise angle north. example,
Runway 7 points 70 degrees away north.

565

fiO , W ILLIAMS , & B LACKMORE

7.4.2 P LANT PARAMETERS
set umax = 250 m/s, approximates maximum cruise speed private jet airplanes,
Gulfstream V. maximum acceleration determined maximum bank angle.
Assuming aircraft flying constant speed, lateral acceleration given function
bank angle follows:
= g tan ,
g acceleration gravity. Typically passenger aircraft limits bank angle 25
degrees passenger comfort, even though aircraft capable turning larger bank
angle. Hence, use:
umax = 9.8 m/s2 tan(25 ) = 4.6 m/s2 .
set = 100 = 60 seconds.
7.4.3 IMULATION R ESULTS
Figure 22 shows paths planned p-Sulu Planner three scenarios. scenarios,
episode requirements CCQSPs Figure 21 met within specified temporal
chance constraints.
Table 4 compares performance Sulu p-Sulu Planner. expected, Sulus plans
result excessive probabilities failure scenarios. Sulu consider
uncertainty planning process, although PAV subject disturbance reality.
hand, p-Sulu Planner successfully limits probability failure within user-specified
risk bounds three scenarios. Furthermore, although p-Sulu Planner significantly reduces
risk failure, cost higher Sulu 9.5 - 12.8 %. capability
limiting risk maximizing efficiency time desirable feature PTS,
transports passengers.
Scenario number
Planner
Computation time [sec]
Pf ail,1
Pf ail,2
Pf ail,3
Cost function value J

1
Sulu
2.58
0.999
0.807
0.373
24.2

2

p-Sulu
60.2
9.12 102
8.46 102
2.74 105
27.5

Sulu
2.00
0.996
0.813
0.227
21.0

p-Sulu
390
9.14 102
8.59 102
2.62 105
23.7

3
Sulu
5.17
0.999
0.603
0.372
20.0

p-Sulu
198
9.23 102
7.65 102
2.81 105
22.3

Table 4: Performance Comparison prior art, Sulu, p-Sulu Planner. Pf ail,1 , Pf ail,2 ,
Pf ail,3 represent probabilities failure regarding chance constraints c1 , c2 ,
c3 Figure 21, respectively.

566

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Figure 21: CCQSPs PTS scenarios.

Figure 22: paths planned p-Sulu Planner.

567

fiO , W ILLIAMS , & B LACKMORE

shown Table 4, p-Sulu Planner typically takes several minutes compute plan.
length computation time would allowed PTS applications, since assume pSulu Planner used preplanning; take-off, passengers PAV specify requirements,
p-Sulu Planner creates risk-sensitive flight plan. assume real-time plan executive
executes plan take-off.
note desirable real-time risk-sensitive plan executive, since risk factors, location storms, change time. future work reduce computation
time p-Sulu Planner used real-time execution.
7.5 Space Rendezvous Scenario
p-Sulu Planner general planner whose application limited specific plant model.
order show generality planner, deployed p-Sulu Planner system whose
plant model significantly different PTS.
Specifically, chose autonomous space rendezvous scenario H-II Transfer Vehicle
(HTV), shown Figure 23, subject. HTV unmanned cargo spacecraft developed
Japanese Aerospace Exploration Agency (JAXA), used resupply International Space
Station (ISS). Collision vehicle ISS may result fatal disaster, even collision
speed low. example, August 1994, Russian unmanned resupply vehicle Progress M34 collided Mir space station failed attempt automatic rendezvous docking.
result, one modules Mir permanently depressurized. order avoid
accident, HTV required follow specified safety sequence automated rendezvous,
described following subsection.

Figure 23: H-II Transfer Vehicle (HTV), Japanese unmanned cargo vehicle, conducts autonomous
rendezvous International Space Station. Image courtesy NASA.

7.5.1 HTV R ENDEZVOUS EQUENCE
HTVs autonomous rendezvous mission, final approach phase starts Approach Initiation (AI) point, located 5 km behind ISS, shown Figure 24. First, HTV moves
R-bar Initiation (RI) point, located 500 ISS, guided relative GPS
568

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

navigation. RI point, HTV switches navigation mode Rendezvous Sensor (RVS) Navigation. RVS Navigation, HTV measures distance ISS precisely beaming laser
reflector placed nadir (earth-facing) side ISS. Then, HTV proceeds Hold Point
(HP), located 300 ISS. required hold HP order perform 180-degree
yaw-around maneuver. new orientation HTV allows vehicle abort rendezvous
quickly case emergency. yaw-around maneuver, HTV resumes approach,
holds Parking Point (PP), 30 ISS. Finally, HTV approaches
distance 10 meters ISS, stops within Capture Box (CB) ISSs robotic
arm. robotic arm grabs HTV docks ISS. Please refer report Japan
Aerospace Exploration Agency (2009) details rendezvous sequence.
RI

HP

PP CB


ISS

-300m

-30m -10m

ISS Orbit

-500

x

Earth
AI: Approach Initiation
RI: R-bar Initiation
HP: Hold Point
PP: Parking Point
CB: Capture Box

AI Point
-5000

Figure 24: HTVs final approach sequence (Japan Aerospace Exploration Agency, 2009).
rendezvous sequence described represented CCQSP shown Figure 25.
addition time-evolved goals specified actual rendezvous sequence, specify temporal
constraints chance constraints simulation, shown figure. require HTV hold
intermediate goal least 240 seconds. transition goals must take
least 600 seconds, order make sure vehicle moves slowly enough. entire mission
must completed within 4800 seconds (1 hour 20 minutes). require HTV stay within
Safe Zone, conic area ISS, RVS navigation phase 99.5% probability,
since otherwise laser may reflected back HTV properly. assume goals
square regions, 10 sides RI HP, 2 sides PP, 1 sides CB. Finally,
require HTV achieves time-evolved goals 99.5% success probability.
7.5.2 RBITAL DYNAMICS
rendezvous considered two-body problem, chaser spacecraft (e.g., HTV)
moves relation target spacecraft (e.g., ISS), circular orbit. problem,
convenient describe motion chaser spacecraft using rotating frame fixed
target space craft, known Hill coordinate frame (Schaub & Junkins, 2003). shown
Figure 24, set x-axis pointing away center earth y-axis along
569

fiO , W ILLIAMS , & B LACKMORE

Figure 25: CCQSP representation HTVs final approach sequence. assume
time-evolved goals ones used actual flight missions. temporal constraints
chance constraints added authors.

orbital velocity target spacecraft. Since HTVs path within x-y plane, dont consider
z-axis.
known relative motion chase spacecraft Hill coordinate frame described following Clohessy-Wiltshire (CW) equation (Vallado, 2001):
x = 2 + 3 2 x + Fx
= 2 x + Fy
angular speed target spacecrafts orbit, Fx Fy force per unit
mass, acceleration x directions. first terms right-hand sides represent
Coriolis force.
object follows CW equation moves unintuitive manner. unforced motion
straight line due Coriolis effect; general, object cannot stay position
without external force. example, Figure 26 shows fuel-optimal path visit two waypoints,
B, come back start. seen figure, optimal path typically
straight line. virtue p-Sulu Planner handle irregular dynamic systems
way regular systems, setting B matrices plant model (4)
appropriately.
state vector consists positions velocity x plane:
x = [x vx vy ]T
obtain discrete-time CW equation using impulse-invariant discretization:
xk+1 = Axk + Buk ,
570

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK



Start

B

Figure 26: typical motion spacecraft Hill coordinate frame. solid line fuel
optimal path visits B returns Start 30 minutes. Note
optimal path straight line Hill coordinate frame.






=




B =


4 3 cos(T )
6{T sin(T )}
3 sin(T )
6{1 cos(T )}

0
1
0
0

sin(T )

2{1cos(T )}


2{1cos(T )}

4 sin(T )
3T


cos(T )
2 sin(T )


2 sin(T )
4 cos(T ) 3

sin(T )

2{1cos(T )}


2{1cos(T )}

4 sin(T )
3T


cos(T )
2 sin(T )

2 sin(T )
4 cos(T ) 3












use ISSs orbital angular speed, = 0.001164 rad/sec, station goes around
Earth 90 minutes. choose interval = 120 seconds. number time steps N
set 40. Hence, entire plan 4800 seconds (1 hour 20 minutes). discretization,
assumed impulse inputs follows:
[

Fx
Fy

]
=

N
1


(t k)uk ,

k=0

() Dirac delta function. assumption justified thrusters
Reaction Control System (RCS) spacecraft, used final approach maneuver,
operate short duration (0.01 5.0 seconds) burn (Wertz & Wiley J. Larson, 1999).
consider stochastic uncertainty w, added discrete-time dynamic equation:
xk+1 = Axk + Buk + w.
assumption additive uncertainty commonly used past research autonomous
rendezvous formation flight space (Shields, Sirlin, & Wette, 2002; Smith & Hadaegh, 2007;
571

fiO , W ILLIAMS , & B LACKMORE

Campbell & Udrea, 2002). assume w
following covariance matrix:
6
10
0
0
106
w =
0
0
0
0

zero-mean Gaussian distribution,

0
0
0
0


0
0
.
0
0

7.5.3 BJECTIVE F UNCTION
employ objective function J requires p-Sulu Planner minimize fuel consumption. follows Tsiolkovsky rocket equation fuel consumption spacecraft
proportional total change velocity, called Delta-V V (Wertz & Wiley J. Larson, 1999).
total fuel consumption summation fuel consumption reaction jets x
directions time steps. Hence objective function described follows:
J(u0:N ) = Vx + Vy
(N 1)T
=
|Fx | + |Fy |dt
0



k=N
(N 1)T

1 fifi (N 1)T


=
(t k)ux,k dtfi +
(t k)uy,k dtfi

0
0

=

k=0
k=N
1

|ux,k | + |uy,k |.

k=0

7.5.4 IMULATION R ESULT
Figure 27 shows planning result p-Sulu Planner. compare result Sulu,
well nominal planning approach, assume HTV moves AI RI using
two-impulse transition (called CW guidance law) (Matsumoto, Dubowsky, Jacobsen, & Ohkami,
2003; Vallado, 2001). RI CB, follows predetermined path goes center
Safe Zone, shown Figure 27-(b), constant speed.
shown Figure 27, optimal paths generated p-Sulu Planner Sulu
straight. curved paths exploit Coriolis effect minimize fuel consumption.
Table 5 compares performance three planning approaches. two rows regarding
probabilities failure correspond two chance constraints specified CCQSP, shown
Figure 25. probabilities evaluated Monte Carlo simulation one million samples.
expected, probabilities failure path generated p-Sulu Planner less
risk bounds specified CCQSP, shown Figure 25. hand, again,
Sulus path results almost 100% probability failure. Sulu minimizes fuel
consumption without considering uncertainty. resulting path pushes boundaries
feasible regions, evident Figure 27-(c). note that, although p-Sulu Planner
significantly reduces probability constraint violation compared Sulu, cost (Delta V)
higher Sulu 0.2%. p-Sulu Planner results significantly smaller cost (Delta
V) nominal planning approach. 1.42 m/sec reduction Delta V equivalent
11.9 kg saving fuel, assuming 16, 500 kg mass vehicle 200 sec specific impulse
572

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Figure 27: Planning results Sulu, p-Sulu Planner, nominal planning approach.
input CCQSP shown Figure 25.

(ISP ) thrusters. Although p-Sulu Planner takes longer compute plan
two approaches, 11.4 second computation time negligible compared 1 hour 20
minute plan duration.

Computation time [sec]
Probability failure Pf ail (Navigation)
Probability failure Pf ail (Goals)
Cost function value (Delta V) J [m/sec]

Sulu
3.9
0.92
1.0
7.30

p-Sulu Planner
11.4
0.0024
0.0029
7.32

Nominal
0.09
< 106
< 106
8.73

Table 5: Performance comparison Sulu, p-Sulu Planner, nominal approach
HTV rendezvous scenario.

573

fiO , W ILLIAMS , & B LACKMORE

8. Conclusions
article introduced model-based planner, p-Sulu Planner, operates within userspecified risk bounds. p-Sulu Planner optimizes continuous control sequence discrete
schedule, given input continuous stochastic plant model, objective function, newly
developed plan representation, chance-constrained qualitative state plan (CCQSP). CCQSP
involves time-evolved goals, simple temporal constraints, chance constraints, specify
users acceptable levels risk subsets plan.
approach developing p-Sulu Planner two-fold. first step, developed
efficient algorithm, called non-convex iterative risk allocation (NIRA), plan nonconvex state space fixed schedule. solved problem based key concept
risk allocation risk selection, achieves tractability allocating specified risk individual constraints mapping result equivalent disjunctive convex program.
NIRA algorithm employs branch-and-bound algorithm solve disjunctive convex program.
subproblems fixed-schedule CCQSP problems convex state space, solved
previously developed algorithms (Blackmore & Ono, 2009). developed novel relaxation method called fixed risk relaxation (FRR), provides tightest linear relaxation
nonlinear constraints convex subproblems.
second step, developed p-Sulu Planner, solve CCQSP planning problem flexible schedule. scheduling problem formulated combinatorial constrained
optimization problem (COP), solved branch-and-bound algorithm. subproblem branch-and-bound search CCQSP planning problem fixed schedule,
solved NIRA. domain feasible schedule pruned running shortest-path algorithm d-graph representation given temporal constraints. lower bounds optimal objective value subproblems obtained solving fixed-schedule CCQSP planning
problems subset state constraints imposed. proposed efficient variable
ordering prioritizes convex subproblems non-convex ones. demonstrated p-Sulu
Planner various examples, personal aerial transportation system autonomous space
rendezvous, showed efficiently solve CCQSP planning problems small suboptimality, compared past algorithms.

Acknowledgments
paper based upon work supported part Boeing Company Grant No. MITBA-GTA-1 National Science Foundation Grant No. IIS-1017992. opinions,
findings, conclusions recommendations expressed publication authors
necessarily reflect view sponsoring agencies. would thank Michael
Kerstetter, Scott Smith, Ronald Provine, Hui Li Boeing Company support. Thanks
Robert Irwin advice draft.

References
Acikmese, B., Carson III, J. M., & Bayard, D. S. (2011). robust model predictive control algorithm
incrementally conic uncertain/nonlinear systems. International Journal Robust
Nonlinear Control, 21(5), 563590.
574

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Aircraft Owners Pilots Association Air Safety Foundation (2005). 2005 Joseph T. Nall Report
- accident trands factors 2004..
Altman, E. (1999). Constrained Markov decision processes. Stochastic modeling. Chapman &
Hall/CRC.
Alur, R., Feder, T., & Henzinger, T. A. (1996). benefits relaxing punctuality. Journal
ACM, 43.
Bacchus, F., & Kabanza, F. (1998). Planning temporally extended goals. Annals Mathematics
Artificial Intelligence, pp. 527.
Balas, E. (1979). Disjunctive programming. Annals Discrete Mathematics.
Bertsekas, D. P. (2005). Dynamic Programming Optimal Control Volume (Third Edition).
Athena Scientific.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming (1st edition). Athena
Scientific.
Blackmore, L. (2006). probabilistic particle control approach optimal, robust predictive control.
Proceedings AIAA Guidance, Navigation Control Conference.
Blackmore, L., Li, H., & Williams, B. C. (2006). probabilistic approach optimal robust path
planning obstacles. Proceedings American Control Conference.
Blackmore, L., & Ono, M. (2009). Convex chance constrained predictive control without sampling.
Proceedings AIAA Guidance, Navigation Control Conference.
Boyan, J. A., & Littman, M. L. (2000). Exact solutions time-dependent MDPs. Advances
Neural Information Processing Systems, pp. 10261032. MIT Press.
Boyan, J. A., & Moore, A. W. (1995). Generalization reinforcement learning: Safely approximating value function. Advances Neural Information Processing Systems 7.
Campbell, M. E., & Udrea, B. (2002). Collision avoidance satellite clusters. Proceedings
American Control Conference.
Charnes, A., & Cooper, W. W. (1959). Chance-constrained programming. Management Science, 6,
7379.
Coles, A. J., Coles, A., Fox, M., & Long, D. (2012). Colin: Planning continuous linear numeric
change. J. Artif. Intell. Res. (JAIR), 44, 196.
Dechter, R. (2003). Constraint Processing. Elsevier.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49,
6195.
Dolgov, D., & Durfee, E. (2005). Stationary deterministic policies constrained MDPs multiple rewards, costs, discount factors. Proceedings Nineteenth International
Joint Conference Artificial Intelligence (IJCAI-05, pp. 13261331.
Feng, Z., Dearden, R., Meuleau, N., & Washington, R. (2004). Dynamic programming structured
continuous markov decision problems. Proceedings Proceedings Twentieth
Conference Annual Conference Uncertainty Artificial Intelligence (UAI-04), pp. 154
161, Arlington, Virginia. AUAI Press.
575

fiO , W ILLIAMS , & B LACKMORE

Fleming, W., & McEneaney, W. (1995). Risk-sensitive control infinite time horizon. SIAM
Journal Control Optimization, 33(6), 18811915.
Fox, M., & Long, D. (2006). Modelling mixed discrete-continuous domains planning. Journal
Artificial Intelligence Research, 27, 235297.
Geibel, P., & Wysotzki, F. (2005). Risk-sensitive reinforcement learning applied control
constraints. Journal Artificial Intelligence Research, 24, 81108.
Goulart, P. J., Kerrigan, E. C., & Maciejowski, J. M. (2006). Optimization state feedback
policies robust control constraints. Automatica, 42(4), 523 533.
Hofmann, A. G., & Williams, B. C. (2006). Robust execution temporally flexible plans bipedal
walking devices. Proceedings International Conference Automated Planning
Scheduling (ICAPS-06).
Jacobson, D. (1973). Optimal stochastic linear systems exponential performance criteria
relation deterministic differential games. Automatic Control, IEEE Transactions on,
18(2), 124 131.
Japan Aerospace Exploration Agency (2009). HTV-1 mission press kit. Available on-line http:
//www.jaxa.jp/countdown/h2bf1/pdf/presskit_htv_e.pdf.
Kuwata, Y., & How, J. P. (2011). Cooperative distributed robust trajectory optimization using receding horizon MILP. IEEE Transactions Control Systems Technology, 19(2), 423431.
Kuwata, Y. (2003). Real-time trajectory design unmanned aerial vehicles using receding horizon
control. Masters thesis, Massachusetts Institute Technology.
Kvarnstrom, J., & Doherty, P. (2000). Talplanner: temporal logic based forward chaining planner.
Annals Mathematics Artificial Intelligence.
Lagoudakis, M. G., & Parr, R. (2003). Least-squares policy iteration. Journal Machine Learning
Research, 4, 2003.
Leaute, T. (2005). Coordinating agile systems model-based execution temporal plans.
Masters thesis, Massachusetts Institute Technology.
Leaute, T., & Williams, B. C. (2005). Coordinating agile systems model-based execution temporal plans. Proceedings Twentieth National Conference Artificial
Intelligence (AAAI).
Li, H., & Williams, B. C. (2005). Generalized conflict learning hybrid discrete linear optimization. Proc. 11th International Conf. Principles Practice Constraint Programming.
Li, H. X. (2010). Kongming: Generative Planner Hybrid Systems Temporally Extended
Goals. Ph.D. thesis, Massachusetts Institute Technology.
Matsumoto, S., Dubowsky, S., Jacobsen, S., & Ohkami, Y. (2003). Fly-by approach guidance
uncontrolled rotating satellite capture. Proceedings AIAA Guidance, Navigation,
Control Conference Exhibit.
Nemirovski, A., & Shapiro, A. (2006). Convex approximations chance constrained programs.
SIAM Journal Optimization, 17, 969996.
576

fiP ROBABILISTIC P LANNING C ONTINUOUS DYNAMIC YSTEMS B OUNDED R ISK

Oldewurtel, F., Jones, C. N., & Morari, M. (2008). tractable approximation chance constrained
stochastic MPC based affine disturbance feedback. Proceedings Conference Decision Control.
Ono, M. (2012). Closed-loop chance-constrained MPC probabilistic resolvability. Proceedings IEEE Conference Decision Control.
Ono, M., Graybill, W., & Williams, B. C. (2012). Risk-sensitive plan execution connected sustainable home:. Proceedings 4th ACM Workshop Embedded Systems (BuildSys).
Ono, M., & Williams, B. C. (2008a). efficient motion planning algorithm stochastic dynamic
systems constraints probability failure. Proceedings Twenty-Third AAAI
Conference Artificial Intelligence (AAAI-08).
Ono, M., & Williams, B. C. (2008b). Iterative risk allocation: new approach robust model
predictive control joint chance constraint. Proceedings 47th IEEE Conference
Decision Control.
Prekopa, A. (1999). use discrete moment bounds probabilistic constrained stochastic
programming models. Annals Operations Research, 85, 2138.
Richards, A., & How, J. (2006). Robust stable model predictive control constraint tightening.
American Control Conference, 2006, p. 6 pp.
Sanner, S. (2011). Relational dynamic influence diagram language (RDDL): Language description.
Available http://users.cecs.anu.edu.au/ssanner/IPPC_2011/RDDL.
pdf.
Schaub, H., & Junkins, J. L. (2003). Analytical mechanics space systems. American Institute
Aeronautics Astronautics, Inc.
Shields, J., Sirlin, S., & Wette, M. (2002). Metrology sensor characterization pointing control
formation interferometer testbed (fit). Proceedings IEEE Aerospace Conference.
Smith, R., & Hadaegh, F. (2007). Distributed estimation, communication control deep space
formations. IET Control Theory Applications.
Stoorvogel, A. (1992). H Control Problem: State Space Approach. Prentice Hall.
Vallado, D. A. (2001). Fundamentals Astrodynamics Applications, Second Edition. Microcosm Press.
van Hessem, D. H. (2004). Stochastic inequality constrained closed-loop model predictive control
application chemical process operation. Ph.D. thesis, Delft University Technology.
Wang, X., Yadav, V., & Balakrishnan, S. N. (2007). Cooperative uav formation flying obstacle/collision avoidance. IEEE Transactions Control Systems Technology, 15(4).
Wertz, J. R., & Wiley J. Larson, e. (1999). Space Mission Analysis Design (Third Edition).
Microcosm/Springer.
Younes, H. L. S., & Littman, M. L. (2004). PPDDL1.0: extension pddl expressing planning
domains probabilistic effects. Tech. rep., Carnegie Mellon University.

577


