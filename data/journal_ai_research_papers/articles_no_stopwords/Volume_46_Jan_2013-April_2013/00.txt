Journal Artificial Intelligence Research 46 (2013) 1 45

Submitted 07/12; published 01/13

Short Long Supports Constraint Propagation
Peter Nightingale
Ian P. Gent
Christopher Jefferson
Ian Miguel

pwn1@st-andrews.ac.uk
ian.gent@st-andrews.ac.uk
caj21@st-andrews.ac.uk
ijm@st-andrews.ac.uk

School Computer Science, University St Andrews,
St Andrews, Fife KY16 9SX, UK

Abstract
Special-purpose constraint propagation algorithms frequently make implicit use short
supports examining subset variables, infer support (a justification
variable-value pair may still form part assignment satisfies constraint)
variables values save substantial work short supports
studied right. two main contributions paper identification short supports important constraint propagation, introduction
HaggisGAC, efficient effective general purpose propagation algorithm exploiting short supports. Given complexity HaggisGAC, present optimised
version simpler algorithm ShortGAC. Although experiments demonstrate efficiency ShortGAC compared general-purpose propagation algorithms
compact set short supports available, show theoretically experimentally
HaggisGAC even better. find HaggisGAC performs better
GAC-Schema full-length supports. introduce variant algorithm HaggisGACStable, adapted avoid work backtracking cases faster
significant reductions memory use. proposed algorithms excellent
propagating disjunctions constraints. experiments disjunctions found
algorithms faster Constructive GAC-Schema least order
magnitude, three orders magnitude.

1. Introduction
Constraint solvers typically employ systematic backtracking search, interleaving choice
assignment decision variable propagation constraints determine
consequences assignment made. Propagation algorithms broadly divided
two types. first specialised reason efficiently constraint patterns
occur frequently models. Examples include global cardinality constraint (Regin,
1996) element constraint (Gent, Jefferson, & Miguel, 2006b). feasible
support every possible constraint expression specialised propagator way,
case general-purpose constraint propagators, GAC-Schema (Bessiere & Regin,
1997), GAC2001/3.1 (Bessiere, Regin, Yap, & Zhang, 2005), STR2 (Lecoutre, 2011)
MDDC (Cheng & Yap, 2010) used. typically expensive specialised
propagators important tool specialised propagator available.
support constraint domain value variable justification value
may still form part assignment satisfies constraint. usually given terms
set literals: variable-value pairs corresponding possible assignments
c
2013
AI Access Foundation. rights reserved.

fiNightingale, Gent, Jefferson, & Miguel

variables constraint. One efficiencies typically found specialised propagators
use short supports: examining subset variables, infer support
variables values save substantial work. use typically implicit,
i.e. achieved specialised algorithm examine variables
cases. One contributions highlight general importance short supports.
example, consider element constraint xy = z, x0 , x1 , x2 , {0 . . . 2},
z {0 . . . 3}. constraint satisfied iff element position vector [x0 , x1 , x2 ]
equals z. Consider set literals = {x0 7 1, 7 0, z 7 1}. set clearly satisfies
definition constraint xy = z, contain literal variable.
extension valid literals variables x1 x2 support. example
short support.
previous work introduced ShortGAC (Nightingale, Gent, Jefferson, & Miguel,
2011), general-purpose propagation algorithm exploits short supports. introduction ShortGAC, general-purpose propagators relied upon supports involving
variables. paper develop concept introduce new algorithm
HaggisGAC,1 consistently efficient ShortGAC. available,
use compact sets short supports allows HaggisGAC outperform greatly existing general-purpose propagation algorithms. cases, HaggisGAC even approaches
performance special-purpose propagators. HaggisGAC well suited
propagating disjunctions constraints, outperforms traditional Constructive
algorithm (Lagerkvist & Schulte, 2009; Wurtz & Muller, 1996) orders magnitude.
HaggisGAC efficient GAC-Schema full-length supports.
describe variant, HaggisGAC-Stable, supports need deleted
backtracking. Applied full-length supports, version greatly reduced memory
usage.
ShortGAC, HaggisGAC HaggisGAC-Stable instantiated function named findNewSupport (and similar GAC-Schema way). function
specific constraint, generate short supports procedurally. Alternatively,
generic findNewSupport retrieve short supports data structure.
Section 2 presents necessary background, Section 3 introduces concept
short support. Section 4 outlines basic idea used deal implicit supports
throughout paper. Section 5 gives full details ShortGAC, including complexity
key operations alternative implementations short supports provided list
form. Section 6 presents new algorithm HaggisGAC development ShortGAC.
ShortGAC HaggisGAC evaluated experimentally Section 7. Section 8
describes HaggisGAC-Stable, corresponding experiments Section 9. Finally,
Sections 10 11 discuss related work present conclusions.

1. HaggisGAC named legendary wild haggis Scotland, short legs long
legs walking around hills. namesake, HaggisGAC copes full-length shorter
supports originates Scotland. Details wild haggis found Wikipedia, http:
//en.wikipedia.org/wiki/Wild_haggis, Veterinary Record (King, Cromarty, Paterson, &
Boyd, 2007).

2

fiShort Long Supports Constraint Propagation

2. Supports, GAC, Triggers
constraint satisfaction problem (CSP) defined set variables X, function
maps variable domain, : X 2Z domain finite set, set
constraints C. constraint c C relation subset variables X.
scope constraint c, named scope(c), set variables c constrains.
solution CSP function : X Z maps variable x X value
D(x), every constraint c C, values scope(c) form tuple
c (i.e. constraint satisfied ).
systematic search solution CSP, values progressively removed
domains D. Therefore, distinguish initial domains current
domains. function refers current domains unless stated otherwise. literal
defined variable-value pair, written x 7 v. literal x 7 v valid v
current domain x (i.e. v D(x)).
Definition 2.1. [Support] support constraint c domains defined
set valid literals contains exactly one valid literal variable scope(c)
satisfies c. necessary disambiguation, call support full-length
support simply long support, contrast short supports defined later.
property commonly established constraint propagation algorithms generalised
arc consistency (GAC) (Mackworth, 1977). constraint c GAC exists
full-length support every valid literal every variable scope(c). GAC established
identifying literals x 7 v full-length support exists removing v
domain x. consider algorithms establishing GAC paper.
GAC propagation algorithm usually situated systematic search. Hence,
must operate three contexts: initialisation (at root node), support established
scratch; following deletion one domain values (as result branching
decision and/or propagation constraints), support must re-established
selectively; upon backtracking, data structures must restored correct
state point search. primary focus second context, operation
following value deletion, although discuss efficient backtracking Section 8.
GAC propagation algorithm would typically called deleted domain value
turn. algorithm called domain value, constraint
GAC.
propagation algorithms present concept active support, inspired
GAC-Schema (Bessiere & Regin, 1997). active support support currently
use support set literals. literal set active supports support
it. active support found invalid, removed. set
literal empty, say literal lost support. new support sought literal,
found new support becomes active. new support found, literal
support deleted.
propagation algorithms present, efficiency make use watched literals
provided Minion (Gent et al., 2006b), propagators need called every
deleted domain value establish GAC. say propagators attach remove triggers
literals. domain value v variable x deleted, propagator called
3

fiNightingale, Gent, Jefferson, & Miguel

trigger attached literal x 7 v. means literal
deleted attached trigger, zero work incurred. emphasise
use watched literals fundamental work. available
given solver, algorithms need minor adaptation. called literal
removal, may return immediately literal active support,
checked time O(1). Thus algorithms fit traditional fine-grained scheme
(Bessiere & Regin, 1997) except cases invoked
use watched literals.

3. Short Supports
concept short support generalisation full-length support. defined below.
Definition 3.1. [Short support] short support constraint c domains
defined set valid literals x 7 v x scope(c), x occurs S,
every superset contains one valid literal variable scope(c)
full-length support. strict short support short support full-length
support.
definition short support includes extremes. empty set short support constraint entailed (i.e. every tuple scope(c) within satisfies
constraint). Similarly, every full-length support necessarily short support,
superset itself. case studies see examples empty short
supports short supports happen full length.
Short supports used maintain GAC. full-length support,
short support provides GAC support literal contained within it. call
explicit support literals. new feature short support provides
support valid literals variables contained short support.
because, definition, every valid extension short support cover variables
scope(c) full-length support. say short support gives implicit GAC support
valid literals variables short support.
define concept complete set short supports constraint.
Definition 3.2. [Short support set] short support set S(c, D) set short supports
constraint c domains D, every full-length support c
(not necessarily strict) superset least one short support 0 S(c, D).
constraint may many short support sets. gives us latitude implement one efficient compute.
natural ask identify correct short supports given constraint c.
simple fundamental result given Lemma 3.3.
Lemma 3.3. Given constraint c domains D, empty set {} short support
c iff GAC propagation constraint not(c) leads empty domain.
Proof. {} short support every valid assignment variables scope(c)
satisfies c. Every assignment satisfies c iff every assignment violates not(c). every assignment violates not(c), GAC propagation constraint not(c) leads empty
4

fiShort Long Supports Constraint Propagation

domain. complete last equivalence, note assignment violate
not(c), literals assignment supported, GAC propagation cannot cause
empty domain.
lemma two important consequences. First, check short support
correctness, empty support. check short support = {x1 7 v1 , . . . , xk 7
vk }, simply set D(x1 ) = {v1 }, . . . , D(xk ) = {vk }. assignments extend S,
short support iff {} is. Lemma 3.3 applies check correctness
propagating not(c) seeing domain emptied.
second consequence negative, however. Determining whether GAC propagation
empty domain polynomially equivalent actually performing GAC propagation
(Bessiere, Hebrard, Hnich, & Walsh, 2007). Since constraints NP hard GAC
propagate, follows easy even check empty set short support.
Thus cannot expect find method fast general finding short
supports constraint.
Given provable difficulty finding short supports set full-length supports,
construct sets short supports specifically three experimental case studies
Section 7. focus paper show value strict short supports
given system. situation analogous important area
constraints, namely exploiting symmetries constraint problems (Gent, Petrie,
& Puget, 2006). large majority research assumed sets symmetries
provided system, even though finding sets hard. inhibited
research exploiting symmetry, within automated detection symmetry
become important subarea (Mears, 2009; Puget, 2005): however leave automated
construction compact short support sets future research. Analogously patterns
matrix symmetries (Flener, Frisch, Hnich, Kiziltan, Miguel, Pearson, & Walsh, 2002),
least identify pattern often lets us identify strict short supports,
describe.
3.1 Short Supports Disjunction
Strict short supports arise naturally disjunctions. constraint expressed
disjunction shorter constraints, set strict short supports constructed
it. Suppose following constraint.
c(x1 , x2 , x3 , x4 ) c1 (x1 , x2 ) c2 (x2 , x3 ) c3 (c3 , x4 )
Suppose = {x1 7 2, x2 7 1} valid assignment satisfies c1 . satisfy
c1 , satisfy c regardless values x3 x4 . Therefore = {x1 7 2, x2 7 1}
strict short support c.
Lemma 3.4. Given constraint c, domain set D, set constraints {c1 . . . ck }
ci {c1 . . . ck } : scope(ci ) scope(c) c c1 ck , following short support
set (where write fls(ci , D) mean full-length supports ci w.r.t. domains D):
S(c, D) = {S | fls(c1 , D) fls(ck , D)}
5

fiNightingale, Gent, Jefferson, & Miguel

Proof. (a) element S(c, D) short support according Definition 3.1
semantics disjunction. (b) S(c, D) short support set Definition 3.2. Every fulllength support c must satisfy disjunct ci , therefore full-length support contains
full-length support ci included S(c, D).
Lemma 3.4 allows short support set created disjunction, given initial
domains. two three case studies (for third, set prohibitively
large).
Using similar approach Lemma 3.4 create function generates short
supports demand. function takes valid literal x 7 v current domains
D, returns short support supports x 7 v (explicitly implicitly), Null
none exists. function constructed follows. create new domains D0
D0 (x) = {v}, otherwise D0 identical D. disjunct satisfiable D0 ,
function returns Null. Otherwise, function picks disjunct ck satisfiable
D0 , returns satisfying assignment ck valid D0 .
three case studies Section 7, created function follows scheme
optimisations.
Propagating disjunctions recognised important topic. Many papers
published area (Wurtz & Muller, 1996; Lhomme, 2003; Lagerkvist & Schulte,
2009; Jefferson, Moore, Nightingale, & Petrie, 2010). Exploiting strict short supports
algorithms ShortGAC, HaggisGAC HaggisGAC-Stable allows us outperform
traditional Constructive algorithm (Wurtz & Muller, 1996) orders magnitude.
3.2 Backtrack Stability Short Supports
Within search tree, propagation algorithms often spend significant time backtracking
data structures. Reducing eliminating backtracking improve efficiency. example,
avoiding backtracking triggers speed simple table propagator 2 times
(Gent et al., 2006b), MAC-6 MAC-7 much efficient (in space
time) backtracking avoided (Regin, 2005). two potential advantages
reducing use backtracking state: saves time restoring data structures, saves
space avoiding storing supports backtrack stack.
Definition 3.5. [Backtrack Stable] short support constraint c current domains
backtrack stable iff always remains short support (according Definition 3.1)
backtracking search tree.
short support may support variable x implicitly, backtrack may
add values back domain x consistent s, meaning
longer meets definition short support. give example below.
Example 3.1. Consider constraint b [x] = y, boolean variable b, array
variables variables x y. b assigned False, constraint entailed,
empty short support used support literals M, x y.
support backtrack stable, backtracking True restored domain
b, empty set longer short support.
6

fiShort Long Supports Constraint Propagation

support full length backtrack stable: whenever support valid
supports literals contains. Backtrack stable supports always exist use
full-length supports cases (as GAC-Schema), although may much longer
necessary.
Section 8 exploit backtrack stability define new algorithm.

4. ShortGAC: Overview
section summarises key ideas ShortGAC propagation algorithm, along
illustrative example.2
ShortGAC maintains set short supports sufficient support valid literals
variables scope constraint propagating. refer active
supports. algorithm rests exploiting observation that, using short supports,
support established literal two ways. First, usual, short support
contains literal supports literal. Second, literal x 7 v supported short
support contains literal variable x. Hence, short supports
support x 7 v contain literal x 7 w value w 6= v.
following data structures central operation ShortGAC algorithm:
numSupports total number active short supports.
supportsPerVar array (indexed [x]) indicating number active short supports
containing variable x.
supportListPerLit array (indexed [x 7 v]) lists active short supports containing literal x 7 v.
number supports containing variable x less total number
supports exists support contain x. Therefore, supports
literals x. algorithm spends time processing variables whose literals
known supported way. variables involved active supports
seek support literals active supports.
illustrate, consider element example introduction: xy = z,
x0 , x1 , x2 , {0 . . . 2}, z {0 . . . 3}. constraint satisfied iff element
position vector [x0 , x1 , x2 ] equals z. Suppose current state ShortGAC storing
one support: = {x0 7 1, 7 0, z 7 1}. data structures follows,
indicates literal valid.3
2. details present different presented previously (Nightingale et al., 2011),
optimised data structures algorithms compared previous work. two
significant changes are: longer keep count supports per literal, saving overhead maintaining
this; data stored one dimensional vector literal, instead two dimensional array
variable/value, saving space variables constraint different domain sizes. Experiments
Appendix demonstrate algorithms data structures presented perform better
previous implementation.
3. clarity, presented one-dimensional array supportListPerLit two-dimensional format.

7

fiNightingale, Gent, Jefferson, & Miguel

Supports:
supportListPerLit:
Value
0
1
2
3
supportsPerVar:
numSupports:

x0
7 1, 7 0, z
Variable
x1 x2

{} {} {A}
{} {}
{}
{} {}
{}


0
0
1
1

A:
x0
{}
{A}
{}

1

7 1
z
{}
{A}
{}
{}
1

values x1 x2 support, since supportsPerVar counters
less numSupports. Therefore ShortGAC algorithm ignore x1 x2
look new supports x0 , z. Consider finding new support literals
z. ShortGAC ignore literals least one support case z 7 1.
algorithm looks literals z 7 supportListPerLit[z, a] = {}. Here, z 7 0
literal, ShortGAC seeks new support it. possible new support
B = {x1 7 0, 7 1, z 7 0}. Following discovery, update data structures:
Supports:
supportListPerLit:
Value
0
1
2
3
supportsPerVar:
numSupports:

A:
B:
x0
{}
{A}
{}

1

x0
7 1, 7 0, z
x1
7 0, 7 1, z
Variable
x1
x2

{B} {} {A}
{}
{} {B}
{}
{}
{}



1
0
2
2

7 1
7 0
z
{B}
{A}
{}
{}
2

variable x0 fully supported, since supportsPerVar[x0 ] < numSupports.
remain three literals support established: 7 2, z 7 2 z 7 3.
first two ShortGAC finds supports C = {x0 7 2, 7 0, z 7 2}
= {x2 7 0, 7 2, z 7 0}. support exists z 7 3, 3 deleted, giving:
Supports:

supportListPerLit:
Value
0
1
2
3
supportsPerVar:
numSupports:

A:
B:
C:
D:
x0
{}
{A}
{C}

2

7 1, 7 0, z
7 0, 7 1, z
7 2, 7 0, z
7 0, 7 2, z
Variable
x2

{D} {A, C}
{}
{B}
{}
{D}


1
4
4

x0
x1
x0
x2
x1
{B}
{}
{}

1

7 1
7 0
7 2
7 0
z
{B, D}
{A}
{C}

4

valid literals supported. Nothing need done change
state, removal value branching decision propagation.
8

fiShort Long Supports Constraint Propagation

5. ShortGAC: Details
key tasks implementing ShortGAC are: data structure update; iteration
variables supportsPerVar equals numSupports; iteration unsupported
values variable. section describes infrastructure allows us perform
tasks efficiently.
5.1 ShortGAC Data Structures
active short support arity k provides explicit support k literals
contains. Therefore, reference must appear k lists supportListPerLit.
this, represent two types object: ShortSupport ShortSupportCell.
ShortSupport object contains k ShortSupportCell objects, contains literal
x 7 v,4 reference parent ShortSupport. elements array supportListPerLit doubly-linked lists ShortSupportCells. reference parent
ShortSupport, iterate active short supports given literal.
algorithm iterates variables x supportsPerVar[x] equals numSupports.
following data structure represents partition variables number supports. allows constant time size checking linear-time iteration cell
partition, allows variable moved adjacent cell (i.e. number
supports increases decreases 1) constant time. inspired indexed
dependency array Gecode (Schulte & Tack, 2010).
varsBySupport array containing permutation variables. Variables ordered
non-decreasing number active supports (supportsPerVar[x]).
supportNumLowIdx array integers, indexed 0 number literals,
maximum number active supports possible. Either supportNumLowIdx[i]
smallest index varsBySupport active supports, (when
variables) supportNumLowIdx[i]= k k total number variables.
k acts sentinel value. set variables supports is:
varsBySupport[supportNumLowIdx[i] . . . supportNumLowIdx[i + 1] 1]
Initially, variables 0 active supports, supportNumLowIdx[0] = 0 rest
array set k.
following table illustrates partition data structure works (on different
example 11 variables). Suppose supportsPerVar[x2 ] changed 7 6. x2 y1
(boxed) swapped varsBySupport cell boundary moved x2
lower cell. Consequently, supportNumLowIdx[7] incremented 1.
varsBySupport[]
supportsPerVar
x2 updated

w1
6
w1

w2
6
w2

y1
7
x2

x1
7
x1

x2
7
y1

y2
7
y2

y3
7
y3

x3
7
x3

z1
8
z1

z2
8
z2

z3
8
z3

4. literal x 7 v represented using single integer i. mapping x 7 v i,
allows O(1) access x v vice-versa.

9

fiNightingale, Gent, Jefferson, & Miguel

Require: sup: ShortSupport
1: sc: ShortSupportCell sup
2:
(x 7 v) sc.literal
3:
supportListPerLit[x 7 v] = {}
4:
attachTrigger(x 7 v)
5:
Add sc doubly linked list supportListPerLit[x 7 v]
6:
supportsPerVar[x]++
7:
sx supportsPerVar[x]
8:
cellend supportNumLowIdx[sx ]1
9:
swap(x, varsBySupport[cellend ])
10:
supportNumLowIdx[sx ]-11: numSupports++

Procedure 1: addSupport(sup)
variable x supportsPerVar[x] = numSupports, ShortGAC iterates
values zero explicit supports. avoid iterating values, use set data
structure:
zeroLits array (indexed [x]) stacks containing literals variable x zero
explicit support, particular order.
inZeroLits array (indexed [x 7 v]) booleans indicating whether literal x 7
v zeroLits[x].
supportListPerLit[x 7 v] reduced empty list, inZeroLits[x 7 v]
false x 7 v pushed onto zeroLits[x] (and inZeroLits[x 7 v] set true).
optimisation, values eagerly removed set; removed lazily
set iterated. Also, set backtracked. iteration, non-zero value
removed swapping top stack, popping. lazy maintenance never
costs work overall because, value would removed eagerly,
removed next time set iterated, costing O(1). save work, may
never iterate list value would restored set again.
use free list manage set ShortSupport objects avoid cost unnecessary object construction/destruction. ShortSupport object retrieved free list
may contain ShortSupportCell objects, use resizable vector data structure.
size ever increased.
5.2 Adding Deleting Supports
support added deleted, data structures described must
updated. done Procedures 1 (addSupport) 2 (deleteSupport).
procedures iterate given short support, literal update
supportListPerLit, supportsPerVar, varsBySupport supportNumLowIdx. Procedure 2
inserts literal zeroLits necessary. briefly explain maintenance varsBySupport become important Section 6.2. Suppose adding support
literal x 7 v Procedure 1. additional support, x must moved
next cell varsBySupport. Line 8 finds end cell x in, swap x
10

fiShort Long Supports Constraint Propagation

Require: sup: ShortSupport
1: sc: ShortSupportCell sup
2:
(x 7 v) sc.literal
3:
Remove sc doubly-linked list supportListPerLit[x 7 v]
4:
supportsPerVar[x]-5:
supportListPerLit[x 7 v] = {}
6:
removeTrigger(x 7 v)
7:
inZeroLits[x 7 v]
8:
inZeroLits[x 7 v] true
9:
zeroLits[x].push(x 7 v)
10:
sx supportsPerVar[x]
11:
cellend supportNumLowIdx[sx +1]
12:
swap(x, varsBySupport[cellend ])
13:
supportNumLowIdx[sx +1]++
14: numSupports--

Procedure 2: deleteSupport(sup)

Require: x 67 v (where v pruned domain x)
1: supportListPerLit[x 7 v] 6= {}
2:
deleteSupport(supportListPerLit[x 7 v].pop())
3: repeat
4:
continueLoop false
5:
{supportNumLowIdx[numSupports]. . . supportNumLowIdx[numSupports+1]-1}
6:
varsBySupport[i]
7:
ShortGAC-variableUpdate(y) = true
8:
continueLoop true
9:
break loop Line 5
10: continueLoop = false

Procedure 3: ShortGAC-Propagate: propagate(x 67 v)

end cell using subroutine swap(xi , xj ). simple procedure (not given) locates
swaps two variables varsBySupport, leaving variables unaffected.
makes use second array, varsBySupInv, inverse mapping varsBySupport.
done this, cell boundary decremented (in new position), x
higher cell. Another point note addSupport add trigger x 7 v
sup active explicit support contain literal, deleteSupport
remove trigger deleted support support.
Finally, note special-purpose methods undo changes
backtracking. backtracking past point support added, simply
call deleteSupport, similarly call addSupport backtrack past supports
deletion.
11

fiNightingale, Gent, Jefferson, & Miguel

Require: variable x
1: (x 7 v) zeroLits[x]
2:
supportListPerLit[x 7 v] 6= {}
3:
Remove (x 7 v) zeroLits[x]
4:
else
5:
v D(x)
6:
sup findNewSupport(x 7 v)
7:
sup = Null
8:
prune(x 7 v)
9:
else
10:
addSupport(sup)
11:
supportListPerLit[x 7 v] 6= {}
12:
Remove (x 7 v) zeroLits[x]
13:
return true
14: return false

Procedure 4: ShortGAC-variableUpdate: (x). pseudocode abstract
detailed maintenance zeroLits inZeroLits data structures. might seem
test Line 11 must always succeed. However, although sup must support x 7 v,
contain x 7 v might implicit support. findNewSupport
function discussed Section 5.5.
5.3 Propagation Algorithm
ShortGAC propagator (Procedure 3) invoked literal contained
one active short supports pruned.5 first deletes supports involving
pruned literal. checks variables implicitly supported, i.e.
supportsPerVar[y]=numSupports (Line 5). variable checked Procedure 4
(ShortGAC-variableUpdate, described below). call results new support
found, data structures changed (ShortGAC-variableUpdate(y) returns
true indicate this) must break for-all-loop (Line 9) go round again.
Iteration therefore continues either new support necessary new support
found.
ShortGAC-variableUpdate (Procedure 4) used check status every variable
lacking implicit support. iterates zeroLits, i.e. literals variable might
zero explicit supports. Since zeroLits maintained lazily, iteration first
check literal indeed explicit support, correct zeroLits necessary
(Lines 23). important case literal indeed support. Then, provided
v current domain x, must seek new support calling findNewSupport
constraint. support, value v must pruned domain x,
found support update data structures calling addSupport.
initialise data structures root search, Lines 310 Procedure 3 invoked.
Notice lines refer parameter x 67 v, first calling
supports initial iteration Line 5 variables.
5. noted earlier, watched literals available solver, simple check made
start procedure, return immediately removed literal active support.

12

fiShort Long Supports Constraint Propagation

5.4 Complexity Analysis ShortGAC
section provide complexity analysis ShortGAC used incrementally search constraint solver. analysis parameters arity
constraint n, maximum domain size d, cost f calling findNewSupport.
assume attaching removing trigger literal O(1). case
Minion 0.12.
First observe swap procedure executes O(1) time: operation swap
O(1) loop. Secondly establish time complexity procedures
addSupport deleteSupport, key algorithm.
Lemma 5.1. Procedure 1 (addSupport) time complexity O(n).
Proof. outer loop Line 1 iterates literals short support. worst
case, n literals. consider steps within loop. list test
Line 3 O(1), call attachTrigger Line 4. Adding ShortSupportCell
doubly-linked list Line 5 O(1), following five array dereferences.
established above, swap procedure O(1). Hence, addSupport O(n).
Lemma 5.2. Procedure 2 (deleteSupport) time complexity O(n).
Proof. Similarly add Support procedure, outer loop Line 1 n
iterations. removal doubly-linked list Line 3 O(1), array
dereferences Line 4 subsequently. list test Line 5 call removeTrigger Line 6 O(1), stack push operation Line 9. Recalling
swap procedure O(1), deleteSupport O(n).
Theorem 5.3. Procedure 3 (ShortGAC-propagate) time complexity O(n2 d2 +ndf ).
upper bound obtained, i.e. worst case time complexity (n2 d2 + ndf ).
Proof. Analysis first statement breaks three parts.
First, loop Line 1 elements supportListPerLit. worst case occurs
nd literals explicit support. supports, maximum (n 1)d + 1
involve particular literal, literal may short support every
literal every variable ((n 1)d), (1). cost body loop
O(n) Lemma 5.2, total O(n2 d). dominated next part.
second part loop lines 310. maximum number iterations
Line 5 n supports full length iteration Line 5 contains n
variables. Successive calls Procedure 4 Line 7 add O(d) new supports.
support addition triggers restart loop beginning Line 5 n
variables, total O(n2 d) calls Procedure 4. call involves O(d)
iterations loop Line 1 Procedure 4. Therefore innermost loop run
O(n2 d2 ) times.
complete proof first statement, consider cost innermost loop
Procedure 4. Within loop, operations O(1), exceptions call
findNewSupport Line 6 (cost f ) call addSupport Line 10 (cost n
Lemma 5.1). f dominating cost, since must least traverse new support
record it. However, n2 d2 iterations, nd calls findNewSupport,
13

fiNightingale, Gent, Jefferson, & Miguel

time valid literals explicit support. cost either O(n2 d2 )
O(ndf ), whichever greater. case cost O(n2 d2 + ndf ).
upper bounds ndf n2 d2 attained worst case. literal
needs new support, (ndf ) calls findNewSupport. cost (n2 d2 )
nd literals explicit support, size n, variable ends
(for example) d/2 values supported d/2 values deleted. worst case thus
(n2 d2 + ndf ).
Procedure 3 invoked n(d 1) times one branch search tree,
therefore complexity one branch O(n3 d3 + n2 d2 f ).
5.4.1 Second Complexity Analysis
analysis conservative total number, maximum size,
short supports small. Therefore, give another complexity analysis two additional
parameters: maximum length l short supports returned findNewSupport,
total number distinct short supports may returned findNewSupport.
analysis pertains branch search rather single call propagate
algorithm.
first part complexity analysis concerns short supports length l.
short support may added active set once, may deleted
branch. short support must found calling findNewSupport, cost O(f ).
Lemma 5.1 shows addSupport procedure takes O(n) time. lemma
re-stated terms l, loop addSupport iterate O(l) times, giving
total time O(l). applies deleteSupport. Since short supports,
cost finding, adding deleting (collectively processing) short supports O(s(l + f ))
branch.
Secondly, algorithm may make calls findNewSupport return Null.
happen n(d 1) + 1 times, maximum number domain values
may deleted. Therefore cost O(ndf ).
addition, ShortGAC operations charged either
categories. analyse these, must top-down analysis algorithm.
Procedure 3 invoked O(s) times (each time short support invalidated). Lines 12
already charged processing short supports. body loop lines 310 may
executed times new support found, times new
support found, therefore O(s) times total branch search.
come inner loop lines 59. Lemma 5.4 (below), unless domain
empty always one active short support. Therefore, l variables
contained active short supports, l variables relevant
partition varsBySupport, loop body executed O(l) times.
Lemma 5.4. initialisation, Procedure 3 always least one active short support
variable domain empty.
Proof. Suppose opposite. algorithm invoked time literal active short
support pruned, therefore delete active short supports must contain one
literal x 7 v. active short supports contain variable x, values domain
14

fiShort Long Supports Constraint Propagation

x implicitly supported must explicitly supported. Therefore v must
last remaining value D(x). prune x 7 v empties domain
contradiction.
branch, causes O(sl) calls ShortGAC-variableUpdate, Line 7.
call ShortGAC-variableUpdate takes O(d) time may 1 invalid
literals explicitly supported literals zeroLits. time spent procedure
charged processing short supports, pruning domains. Therefore top-down
analysis cost O(sld).
Overall, time complexity O(s(l + f ) + ndf + sld), tighter bound cases
one given section above. example, SAT clause = n, f = n, l = 1
= 2, giving time complexity O(n2 ) branch search.
5.5 Instantiation findNewSupport
Similarly GAC-Schema (Bessiere & Regin, 1997), ShortGAC must instantiated
findNewSupport function. function takes valid literal, returns support one
exists, otherwise returns Null. One way write specialist findNewSupport
function constraint. empirical case studies below.
case, findNewSupport function much simpler propagator
constraint. use Lemma 3.4 build findNewSupport functions, reduces
task finding satisfying tuples simple constraints x < x = y.
alternative write generic version findNewSupport case
short supports given list. detail two generic instantiations findNewSupport lists, case studies compare specialist functions.
5.5.1 findNewSupport-List
provide generic instantiation named findNewSupport-List (Procedure 5) takes
list short supports literal (supportList), including explicit implicit
short supports literal. analogous Positive instantiation GACSchema (Bessiere & Regin, 1997). FindNewSupport-List persistent state: listPos,
array integers indexed variable value, initially 0. indicates current
position supportList. algorithm simply iterates list supports,
seeking one literals valid. ListPos backtracked, consequence
end list reached, cannot fail immediately must search
start back listPos. branch search tree, particular element
list may looked once. However, algorithm optimal
time space across search tree (Gent, 2012). surprising result achieved
amortizing cost across branches. Practically, using listPos stops algorithm always
starting first element list, seems good tradeoff avoiding
provably unnecessary work much data structure maintenance.
constraint-specific findNewSupport sometimes find shorter supports findNewSupport-List. specific findNewSupport take advantage current
domains whereas supportList may contain supports given initial domains.
example, constraint becomes entailed, specific findNewSupport return
15

fiNightingale, Gent, Jefferson, & Miguel

Require: x, v, supportList
1: j {listPos[x, v]. . .(supportList[x, v].size-1)}
2:
sup supportList[x, v, j]
3:
literals sup valid
4:
listPos[x, v] j
5:
return sup
6: j {0 . . .listPos[x, v]1}
7:
sup supportList[x, v, j]
8:
literals sup valid
9:
listPos[x, v] j
10:
return sup
11: return Null

Procedure 5: findNewSupport-List: findNewSupport(x, v). first block searches
location previous support end support list. unsuccessful
search restarts start list second block. circular approach removes
need backtrack listPos.
empty support whereas list version presented cannot. exploit fact
Case Study 3 below.
5.5.2 findNewSupport-NDList
list instantiation two major disadvantages. First, inefficient
unable skip sets invalid tuples. literature contains many solutions
problem context full-length supports, example binary search (Lecoutre &
Szymanek, 2006) tries (Gent, Jefferson, Miguel, & Nightingale, 2007). Second,
require large amount memory. short support S, potentially nd
pointers S, pointer literal implicitly supports.
section give second generic list instantiation based NextDifference lists
(Gent et al., 2007). single list (named supportList) containing short supports (indexed integer), second list named NDList support
=supportList[j], literal support s[k], NDList[j][k] index next
support contain literal s[k]. Thus, searching list, algorithm
able jump sets short supports contain invalid literal.
version findNewSupport NextDifference lists given Procedure 6.
approach solves problems list instantiation: able jump
sets invalid short supports, usually requires substantially less memory. fact
optimal space (unlike list instantiation): given short supports length
l, NextDifference list O(tl). However uses one list supports, therefore
spend time searching short supports support desired literal.
5.6 Literals Assigned Variables
Suppose ShortGAC discovers new support contains literal x 7 v, x assigned v. Since x take value v, sound remove x 7 v
save overhead adding it. apply minor optimisation cases using
ShortGAC, cases using HaggisGAC (described Section 6). How16

fiShort Long Supports Constraint Propagation

Require: x, v, supportList, NDList
1: j listPos[x, v]
2: j < supportList.size
3:
sup supportList[j]
4:
nextDiff NDList[j]
5:
k {0 . . . sup.size 1}
6:
(y 7 b) sup[k]
7:
b
/ D(y) (x = v 6= b)
8:
j nextDiff [k] {Jump next short support assigned different value.}
9:
continue loop Line 2
10:
listPos[x, v] j
11:
return sup
12: j 0
13: j < listPos[x, v]
14:
sup supportList[j]
15:
nextDiff NDList[j]
16:
k {0 . . . sup.size 1}
17:
(y 7 b) sup[k]
18:
b
/ D(y) (x = v 6= b)
19:
j nextDiff [k] {Jump next short support assigned different value.}
20:
continue loop Line 13
21:
listPos[x, v] j
22:
return sup
23: return Null

Procedure 6: findNewSupport-NDlist: findNewSupport(x, v)

ever optimisation cannot used HaggisGAC-Stable (described Section 8)
algorithm retains active supports backtracks, backtracking
literal x 7 v may longer assigned.

6. HaggisGAC: Dealing Full-Length Strict Short Supports
introduce HaggisGAC. show better theoretical properties
ShortGAC. Furthermore, experiments show runs substantially faster many cases
strict short supports ShortGAC (which specialised strict short supports),
substantially faster full-length supports GAC-Schema.
6.1 Introduction Motivating Example
ShortGAC designed exploit concept implicit support, inefficiencies dealing explicit supports especially full-length supports. Consider
example constraint AllDifferentExceptZero, constraint non-zero
values array must different, zero may occur freely. constraint might
used, example, timetabling problem classes taking place different rooms
must different, use zero represent room unused occur
multiple times. Suppose AllDifferentExceptZero([w, x, y, z]), variable initial domain {0, 1, 2, 3}. Supports constraint full-length supports every
17

fiNightingale, Gent, Jefferson, & Miguel

non-zero value different, three variables equalling zero last variable may
take value. Suppose execute ShortGAC reach following situation:
Supports:

supportListPerLit:
Value
0
1
2
3
supportsPerVar:
numSupports:

A:
B:
C:
D:
E:
w
{A, B, E}
{}
{}
{C}
4

w
7 0, x 7 2, 7 3, z 7 1
w
7 0, x 7 3, 7 2, z 7 1
w
7 3, x 7 0, 7 1, z 7 2
x 7 0, 7 0, z 7 0
w 7 0, x 7 1, 7 2, z 7 3
Variable
x

z
{C, D}
{D}
{D}
{E}
{C}
{A, B}
{A}
{B, E}
{C}
{B}
{A}
{E}
5
5
5
5

Notice lack explicit supports w 7 1 w 7 2 acceptable
supportsPerVar[w] = 4 < numSupports = 5. suppose literal 7 0 deleted
constraint. causes support deleted, causing following state:
Supports:

supportListPerLit:
Value
0
1
2
3
supportsPerVar:
numSupports:

A:
B:
C:
E:

7 0, x 7 2,
7 0, x 7 3,
7 3, x 7 0,
7 0, x 7 1,
Variable
x

{C}

{E}
{C}
{A} {B, E}
{B}
{A}
4
4
4

w
w
w
w

w
{A, B, E}
{}
{}
{C}
4

7 3, z
7 2, z
7 1, z
7 2, z

7 1
7 1
7 2
7 3

z
{}
{A, B}
{C}
{E}
4

point ShortGAC iterates zeroLits lists variables
supportsPerVar = numSupports, case four variables. discover must
find new supports w 7 1, w 7 2 z 7 0. However, inefficient two reasons.
First, need check zeroLits[z] discover z 7 0, support list
z 7 0 became empty deletion support D, could discovered then.
Second, need look zeroLits[w] deletion caused
w lose implicit support. need check zeroLits x, y, z
variables implicitly supported prior Ds deletion. Removing two
reasons inefficiency motivation behind development HaggisGAC.
example, focus directly literal z 7 0 set zeroLits[w] literals
potentially needing new support.
fundamental problem ShortGAC cannot efficiently detect
literal loses last support. Every variable implicit support checked every time
support deleted, ShortGAC take O(nd) time find single literal needs
new support discover literal. improve upon this, wish
18

fiShort Long Supports Constraint Propagation


varsBySupport[i]
supportsPerVar
x2 updated
x3 updated
z2 updated
x1 updated
z3 updated
z1 updated
supportsPerVar

0
w1
6
w1
w1
w1
w1
w1
w1
6

1
w2
6
w2
w2
w2
w2
w2
w2
6

2
y1
7
x2
x2
x2
x2
x2
x2
6

3
x1
7
x1
x3
x3
x3
x3
x3
6

4
x2
7
y1
y1
y1
x1
x1
x1
6

5
y2
7
y2
y2
y2
y2
y2
y2
7

6
y3
7
y3
y3
y3
y3
y3
y3
7

7
x3
7
x3
x1
x1
y1
y1
y1
7

8
z1
8
z1
z1
z2
z2
z2
z2
7

9
z2
8
z2
z2
z1
z1
z3
z3
7

10
z3
8
z3
z3
z3
z3
z1
z1
7

Figure 1: Illustration deleteSupport concentrates variables lost
last implicit support. See main text full description.

HaggisGAC able detect loss literals last explicit support time O(1),
loss variables last implicit support time O(1). Perhaps surprisingly,
goals achievable use data structures already existing ShortGAC.
6.2 Finding Literals Support Efficiently
two types support, detecting last explicit support literal lost
simpler task. delete support, Procedure 2 iterates literals
short support. literal removes ShortSupportCell corresponding
supportListPerLit updates data structures appropriately. list empty tested
Line 5 Procedure 2 literal lost last explicit support. add literal
scratch list literals lost last explicit support: describe
process scratch list. additional cost O(1) detect empty list.
inside existing test, zero additional cost literal
lost last support. contrasts ShortGAC tests (in Procedure 4) every
variable implicit support, worst case cost O(n) even literal
lost last explicit support.
subtle task detect variable (and thus literals involving it)
lost last implicit support. reason difficult seeking
variables involved support deleted, Procedure 2 iterate
literals support deleted. variables seek
x supportsPerVar[x] = numSupports support deletion,
supportsPerVar[x] < numSupports support deletion. (Variables
supportsPerVar[x] = numSupports deletion implicit support
now, lose implicit support deletion.) Fortunately, existing
maintenance data structures happens compact exactly variables particular
region varsBySupport, find easily efficiently. compaction
happens sequence calls Procedure swap made Procedure 2.
first show worked example prove general properties need.
Figure 1, suppose 11 variables constraint, currently 8
supports, deleting support involving variables x1 , x2 , x3 , z1 , z2 z3 ,
19

fiNightingale, Gent, Jefferson, & Miguel

literals deleted arbitrary order top (start) bottom (finish).
start, z variables already supportsPerVar = numSupports = 8; variables x
supportsPerVar = 7; variables w supportsPerVar = 6. process literals
deleteSupport, pairs variables swapped (marked boxes line)
boundaries move cells (marked vertical lines) variables equal supportsPerVar. end, w x variables still supportsPerVar = 6 < numSupports = 7.
z variables supportsPerVar=numSupports deletion.
variables lost last implicit support variables. crucial point
end lie precisely final boundary 6 7 supports
(from = 5), initial boundary 7 8 supports (from = 8). following
simple results show variables losing last implicit support always compacted
similar way.
Lemma 6.1. Suppose, delete support S, numSupports = p (and numSupports = p 1 afterwards). variable x lose last implicit support, p 1
explicit supports deletion S.
Proof. x initially fewer p1 explicit supports, x one implicit
support deleting removes one these. x initially p explicit supports,
involved (since involved supports) implicit support
lose. Hence, x must initially p 1 explicit supports one implicit support
must one implicit support. Therefore deletion S, x p 1 explicit
supports implicit supports.
Lemma 6.2. set p Lemma 6.1, value supportNumLowIdx[p]
deleteSupport called, j value supportNumLowIdx[p 1] deleteSupport
exits. deleteSupport finishes, variables lost last implicit support
call deleteSupport exactly set variables indices range [j, i)
varsBySupport.
Proof. variables implicit supports deleteSupport exits lie index j
greater varsBySupport. establishes lower bound index range.
variable z implicit support start call must p explicit
supports must index higher. z must support deleted,
supports. z updated deleteSupport, always swapped
variable index supportNumLowIdx[p]. index supportNumLowIdx[p] increases
deleteSupport, z stays index higher throughout. Thus variables
index upwards finish permutation start, meaning variables
lost last implicit support must range [j, i). Finally, variable
range [j, i) implicit support end call (as index j above)
implicit support start (as i). Therefore variables
lost last implicit support lie indices range [j, i).
Lemma 6.2, run deleteSupport trivial enumerate variables
lost last implicit support result. exactly variables
varsBySupport[k] k = j, j + 1, ...i 1 j defined Lemma. Enumerating
list additional work already done Procedure 2, have:
20

fiShort Long Supports Constraint Propagation

Corollary 6.3. Given constraint n variables, additional work identify variables
lost last implicit support O(1) variable
some, O(1) none.
Proof. already argued case variables lost implicit
support. variables, still O(1) work check range
empty.
low level complexity contrasts favourably ShortGAC. support deleted, Procedure 4 iterates variables numSupports explicit supports.
worst case O(n) work even variable lost last implicit support, compared O(1) work have. move details incorporating
optimisations full suite procedures maintaining GAC.
6.3 HaggisGAC: Details
Two issues complicate implementation HaggisGAC compared ShortGAC.
First, Lemmas depend literals support deleted single pass.
Therefore, instead acting immediately finding literal supports, keep list
literals lost supports later treatment. Second, two cases
might detect lost support lost support explicit implicit compared
single case ShortGAC, lost supports detected way.
introduce two simple data structures storing literals variables lost
explicit implicit support find them.
litsLostExplicitSupport set containing literals lost final explicit support
supported implicitly.
varsLostImplicitSupport set containing variables lost final implicit
support.
adapt deleteSupport procedure Procedure 2. new version
shown Procedure 7. find literal explicit support, immediately
check implicit support instead (Line 8). not, add
set litsLostExplicitSupport later processing find new support delete it. Variables
implicit support detected literals deleted. done
lines 15-16, justified Lemma 6.2.
new propagate procedure shown Procedure 8. earlier Procedure 3,
first delete supports involving literal deleted, rest procedure
different. first iterate literals lost last explicit support,
variables lost last implicit support.
lost explicit supports, call HaggisGAC-literalUpdate (Procedure 9).
procedure analogue ShortGAC, straightforward. point interest
still check whether literal supported, even though added
litsLostExplicitSupport not. reason support found unrelated
call findNewSupport might support literal. done,
Procedure 9 calls findNewSupport. new support found added,
prune literal longer supported.
21

fiNightingale, Gent, Jefferson, & Miguel

Require: Short Support sup
1: oldIndex supportNumLowIdx[numSupports]
2: (x 7 v) sup
3:
Remove sup supportListPerLit[x 7 v]
4:
supportListPerLit[x 7 v] = {}
5:
detachTrigger(x,v)
6:
(x 7 v) 6 zeroLits[x]
7:
Add (x 7 v) zeroLits[x]
8:
supportsPerVar[x] = numSupports
9:
Add (x 7 v) litsLostExplicitSupport
10:
sPV supportsPerVar[x]
11:
swap(x, varsBySupport[sPV])
12:
supportNumLowIdx[sPV] supportNumLowIdx[sPV]+1
13:
supportsPerVar[x] sPV1
14: numSupports-15: {supportNumLowIdx[numSupports] . . . oldIndex 1}
16:
Add varsBySupport[i] varsLostImplicitSupport

Procedure 7: HaggisGAC-DeleteSupport: (sup). One subtlety must add (x 7
v) zeroLits (line 7) even add litsLostExplicitSupport (line 9).
case matters seek find new implicit support, i.e. containing
x 7 v, later lost. later point Procedure 10 requires x 7 v zeroLits
x 7 v might still explicit support.
Require: x 67 v (where v pruned domain x)
1: litsLostExplicitSupport {}
2: varsLostImplicitSupport {}
3: supportListPerLit[x 7 v] 6= {}
4:
sup first element supportListPerLit[x 7 v]
5:
deleteSupport(sup)
6: (y 7 b) litsLostExplicitSupport
7:
HaggisGAC-literalUpdate(y 7 b)
8: z varsLostImplicitSupport
9:
HaggisGAC-variableUpdate(z)

Procedure 8: HaggisGAC-Propagate: propagate(x 67 v)
variables lost implicit supports, call HaggisGAC-variableUpdate (Procedure 10), similar Procedure 4. differences return statements
Procedure 4 omitted; check every iteration whether new implicit support
found x exit loop; remove x 7 v zeroLits
new explicit support found, allowing done lazily later call Line 5.
gain efficiency ShortGAC two reasons. First, variableUpdate
called variables lost implicit support. Second, outer loop
HaggisGAC-Propagate must restarted new support found,
Procedure 3. write number variables lost last
implicit support, reduced worst case number calls variableUpdate
HaggisGAC-Propagate O(n2 d) n arity constraint m. Since
n often much smaller n even zero, significant gain.
22

fiShort Long Supports Constraint Propagation

Require: x 7 v, last explicit support x 7 v deleted
1: v D(x) supportsPerVar[x] = numSupports
supportListPerLit[x 7 v] = {}
2:
sup findNewSupport(x, v)
3:
sup = Null
4:
prune(x 7 v)
5:
else
6:
addSupport(sup)

Procedure 9: HaggisGAC-literalUpdate(x 7 v)

Require: variable x
1: (x 7 v) zeroLits[x]
2:
supportsPerVar[x] < numSupports
3:
return
4:
supportListPerLit[x 7 v] 6= {}
5:
Remove (x 7 v) zeroLits[x]
6:
else
7:
v D(x)
8:
sup findNewSupport(x 7 v)
9:
sup = Null
10:
prune(x 7 v)
11:
else
12:
addSupport(sup)

Procedure 10: HaggisGAC-variableUpdate(x)

6.4 Dealing Efficiently Full-length Supports
full-length support added, ShortGAC increments numSupports supportsPerVar every variable. Since interested condition numSupports =
supportsPerVar[x], full-length support cannot change status variable. Therefore save overheads case add full-length support. achieved
case split HaggisGACs versions addSupport deleteSupport:
support full length update numSupports, supportsPerVar, related data
structures. Note test apply final support arity n,
initial one omission assigned literals optimisation correct
even assigned literals omitted. omit pseudocode optimisation,
changes straightforward. optimisation often improves performance instances
full-length supports 20%, important effect instances
runtimes within 2.5% without it. optimisation applicable
ShortGAC, implement case address key
inefficiency algorithm has, i.e. repeated checking variables cannot
lost last implicit support. affect experimental results dramatically:
cases found improved performance HaggisGAC larger
optimisation provides.
23

fiNightingale, Gent, Jefferson, & Miguel

7. Experimental Evaluation ShortGAC HaggisGAC
Minion solver 0.12 (Gent, Jefferson, & Miguel, 2006a) used experiments,
changes additional propagators. experiments, compared
methods maintain GAC. Therefore, solver explores search space case.
Since number nodes searched invariant, compare rate search exploration,
measured search nodes per second.6
used 8-core machine 2.27GHz Intel Xeon E5520 CPUs 12GB memory,
running Ubuntu Linux. possible ran 12 processes parallel. combination problem instance propagator, report median 11 runs.7 cases
possible run 12 processes parallel exceed 1GB memory. these,
ran one process time, report median 5 runs. instances
marked tables results. one method exceeded 1GB, sometimes
ran comparable methods series well. allows consistent comparison
List NDList, different propagation algorithms. means tables
necessarily indicate method uses 1GB memory. find
median robust measure performance, reasons described Appendix B.
cases, imposed time limit one hour, limit 1,000,000 search nodes
(whichever first). avoid short runs solver find solution easily,
searched solutions. report complete cpu times, i.e. attempted
measure time attributable given propagator include initialisation.
advantage automatically take account factors affecting runtime,
including aspects (e.g. cache usage) may realise affect runtime. however
mean results tend understate difference methods studied.
case study, implemented findNewSupport method ShortGAC
HaggisGAC specific constraint. used generic list instantiation (Section 5.5.1) Next-Difference List instantiation (Section 5.5.2) comparison
possible. compare ShortGAC HaggisGAC special-purpose propagator
(when available).
compare ShortGAC-Long (ShortGAC full-length supports),
HaggisGAC-Long, GAC-Schema (Bessiere & Regin, 1997) closest equivalent algorithm without strict short supports. discuss GAC-Schema Section 7.4.
GAC-Schema, ShortGAC-Long HaggisGAC-Long use (constraint-specific)
findNewSupport ShortGAC, subsequently extend short support full length
using minimum value extra variable.
case, constraint compactly represented disjunction. Therefore
compare ShortGAC HaggisGAC Constructive Or. algorithm used
based Lagerkvist Schultes (2009), without rule entailment detection.

6. Source code solver three algorithms available http://www.cs.st-andrews.ac.
uk/~pn/haggisgac-source.tgz problem instances experimental results http://www.cs.
st-andrews.ac.uk/~pn/haggisgac-data-instances.tgz.
7. preliminary investigations, found running 12 processes parallel gives consistent cpu time
results, consistency improved taking median.

24

fiShort Long Supports Constraint Propagation

3

element
element long
element list
element ndlist
lex
lex long
squarepack
squarepack long
squarepack list
squarepack ndlist

2.5

2

1.5

1.25
1.1
1
0.9
1

10

100

1000

10000

100000

Figure 2: Summary comparison ShortGAC HaggisGAC. x-axis median
nodes per second ShortGAC. y-axis speedup (or slowdown) HaggisGAC, i.e. ratio ShortGAC nodes per second HaggisGAC.
Hence 1 represents equal behaviour, 1 means HaggisGAC
faster.

implementation Minion fully incremental: disjunct propagated incrementally
branch search backtracked search backtracks.8
compare table constraints, described (for example) Gent et al.
(2007), constraints large. example, smallest element constraints
reported 638 allowed tuples, making impossible even generate store
list allowed tuples.
aid comparison HaggisGAC ShortGAC, addition tables
compare graphically Figure 2. figure shows relative speedup (or
cases slowdown) using HaggisGAC compared ShortGAC.
7.1 Case Study 1: Element
use quasigroup existence problem QG3 (Colton & Miguel, 2001) evaluate ShortGAC HaggisGAC element constraint. problem class one parameter
n, specifying size n n table (qg) variables domains {0 . . . n 1}. Rows,
columns one diagonal GAC allDifferent constraints, following Colton Miguels
model. element constraints represent QG3 property (i j) (j i) = (where
j members quasigroup quasigroup operator). translates
i, j : element(qg, aux[i, j], i), aux[i, j]= n qg[i, j] + qg[j, i], aux[i, j]
domain {0 . . . n n 1}.
8. Personal communication Pascal Van Hentenryck indicated unpublished optimisation
Constructive whereby disjuncts need propagated cases. implement
optimisation.

25

fiNightingale, Gent, Jefferson, & Miguel

n
6
7
8
9
10

Watch
Elt.
27,825
22,259
15,635
15,898
15,088

Specific
6,956
4,866
2,773
2,374

1,594

ShortGAC
List NDL
4,122 2,182
3,226 1,233
1,609
545
1,377
398


1,060
280

Long
25.9

8.5

3.6

2.2

1.6

Specific
11,131
9,035
5,652
5,419

4,227

HaggisGAC
List NDL
5,300 2,473
4,833 1,415
2,367
622
2,116
451


1,911
317

Long
36.5

15.2

6.2

3.7

2.6

GAC
Sch.
22.5
7.1

3.0

3.0
mem

Con

53.5
24.2
9.1

6.2

4.2

Table 1: Nodes searched per second quasigroup existence problems. mem indicates
running memory (>12 GB). Columns correspond propagation algorithms.
Watch Elt special-purpose propagator. ShortGAC HaggisGAC
four instantiations: Specific (special-purpose findNewSupport function
constraint), List, NDL (Next-Difference List), Long (as described text).
GAC-Sch GAC-Schema, Con Constructive Or.

constraint element(X, y, z), findNewSupport method ShortGAC returns
tuples form hxi 7 j, 7 i, z 7 ji, index vector X j
common value z xi . ShortGAC-list supports form. Constructive
Or, used (x0 = z = 0) (x1 = z = 1) .
compare ShortGAC HaggisGAC special-purpose Watched Element
propagator (Gent et al., 2006b), GAC-Schema Constructive Or. Table 1 presents
results QG3. general purpose methods, using short supports (with Specific, List
NDList instantiations) dramatically better alternative. example n = 10,
even HaggisGAC-List method (which slower HaggisGAC-Specific)
450 times faster Constructive Or, best methods.
ShortGAC-Long runs 1020% faster GAC-Schema n = 6 8, slower
n = 9 better n = 10 GAC-Schema uses memory. Recall
use findNewSupport method, fair comparison efficiently
exploit supports. contrast results reported previously (Nightingale
et al., 2011), ShortGAC half speed GAC-Schema. Two substantial differences account improvement: improved data structures described
Section 5; remove assigned literals full-length supports described
Section 5.6. HaggisGAC-Long consistently faster ShortGAC-Long
GAC-Schema.
much faster methods using full-length supports, list variants HaggisGACList HaggisGAC-NDList slower HaggisGAC-Element (and
true ShortGAC). expected neither specialised Element
constraint, deal data structures containing lists tuples.
two list variants, NDList variant runs much slowly. However, memory usage is,
expected, much less HaggisGAC-List. used less half much memory
n = 6, improving almost 10 times less memory n = 10.
HaggisGAC-Element approximately twice fast ShortGAC-Element
instances. believe two variables short supports index
result variables meaning always supported explicitly. seen
26

fiShort Long Supports Constraint Propagation

n

GACLex

3
4
5
6
7
8
9
10
12
14
16
18
20
22
24

104,955
103,950
95,420
80,841
72,307
66,445
64,267
57,208
48,146
36,751
30,057
22,432
16,625
12,450
9,526

ShortGAC
Specific Long
87,463 7,020
99,602 6,481
89,127 6,358
73,260 3,456
65,062 2,424
51,335 1,290
47,059
786
38,344
557
31,626
293
22,712
139
17,813
85.9
13,843
52.4
10,734
35.9
7,976
24.9
6,255
14.3

HaggisGAC
Specific Long
91,265 9,288
100,100 8,628
90,009 8,503
74,184 4,666
65,359 3,271
52,659 1,609
47,847
914
39,683
634
32,425
311
23,063
142
18,420
90.9
13,845
53.8
10,711
38.9
8,141
26.0
6,268
18.9

GACSchema
3,622
3,030
2,734
1,638
1,190
670
451
318
170
82.3
51.5
33.3
21.0
12.5

7.3

Con

5,735
4,997
4,104
2,109
1,188
456
263
184
105

99.1

62.6

48.3

36.7

27.0

21.8

Table 2: Nodes searched per second BIBDs. GACLex special-purpose propagator,
columns named Table 1.

Figure 2, List, NDList Long instantiations HaggisGAC faster
instantiations ShortGAC smaller margin. special purpose
Watched Element propagator fastest method, 3.6 times faster n = 10.
Watched Element appears scaling better n increases. Constructive
much slower methods exploit strict short supports, however faster
HaggisGAC-Long. Overall clear exploiting strict short supports
beneficial compared general purpose methods.
7.2 Case Study 2: Lex-ordering
use BIBD problem evaluate ShortGAC HaggisGAC lexicographic
ordering constraint. lex constraint placed rows columns, perform
Double Lex symmetry breaking method (Flener et al., 2002). use BIBD model
given Frisch, Hnich, Kiziltan, Miguel, Walsh (2002), GACLex propagator given Frisch, Hnich, Kiziltan, Miguel, Walsh (2006). use BIBDs
parameter values (4n + 3, 4n + 3, 2n + 1, 2n + 1, n).
constraint lexleq(X, ) arrays X , define mxi = min(Dom(xi ))
myi = max(Dom(yi )). findNewSupport method ShortGAC finds lowest
index {0 . . . n} mxi < myi , = n. case = n arises X cannot
lexicographically less , support sought X = . < n, support
contains xi 7 mxi , yi 7 myi . index j < i, mxj = myj , short support
contains xj 7 mxj , yj 7 myj otherwise valid support Null returned.
lex constraint two arrays length n domain size dn short
supports short support set, assignments two arrays equal
satisfy constraint cannot reduced. ShortGAC-List ShortGAC-NDList
27

fiNightingale, Gent, Jefferson, & Miguel

practical substantial constraint omit comparison.
Constructive use following representation n + 1 disjuncts: (x0 < y0 ) (x0 =
y0 x1 < y1 ) , including final case pairs equal.
Table 2 presents results experiments non-list based methods values
n 3 24. clear best method special-purpose GACLex propagator,
HaggisGAC coming second. problem, HaggisGAC ShortGAC perform similarly. HaggisGAC ShortGAC far best general purpose methods.
largest instances run 1.5 times slower special purpose method,
outperforming next best method almost 300 times. Again, HaggisGAC-Long
ShortGAC-Long outperform GAC-Schema, instances difference
even marked.
HaggisGAC-Long substantially faster ShortGAC-Long, seen
Figure 2: largely explained optimisation Section 6.4.
summarise, experiments Lex constraint clearly show benefit
HaggisGAC ShortGAC compared general-purpose propagation methods.
speed even approaches special purpose GACLex propagator.
7.3 Case Study 3: Rectangle Packing
rectangle packing problem (Simonis & OSullivan, 2008) (with parameters n, width
height) consists packing squares size 1 1 n n rectangle size
width height. modelled follows: variables x1 . . . xn y1 . . . yn ,
(xi , yi ) represents Cartesian coordinates lower-left corner square.
Domains xi variables {0 . . . width i}, yi variables {0 . . . height i}.
Variables branched decreasing order (to place largest square first),
xi yi , smallest value first. type constraint non-overlap squares
j: (xi + xj ) (xj + j xi ) (yi + yj ) (yj + j yi ). Minion
special-purpose non-overlap constraint (Simonis & OSullivan, 2008),
report comparison general-purpose methods. experiment used optimum
rectangle sizes reported Simonis OSullivan.
domains xn yn reduced break flip symmetries described Simonis
OSullivan (2008). focus performance non-overlap constraint,
implement commonly-used implied constraints.
findNewSupport function ShortGAC follows. four disjuncts
entailed given current domains, return empty support (indicating entailment). Otherwise, return support two literals satisfy one four disjuncts.
list used ShortGAC-List ShortGAC-NDList supports size 2.
Table 3, compare HaggisGAC ShortGAC general purpose
methods. see HaggisGAC fastest method, ShortGAC second.
HaggisGAC-List HaggisGAC-NDList (as well ShortGAC-List ShortGACNDList) performed well compared GAC-Schema Constructive Or. However
n = 20, HaggisGAC-List consumes 971MB memory HaggisGAC-NDList 496MB,
n > 20 possible run methods 12 processes parallel.
Interestingly, performance two List variants HaggisGAC reversed
Case Study 1: here, NDList significantly faster List cases. expected,
28

fiShort Long Supports Constraint Propagation

n-w-h
18-31-69
19-47-53
20-34-85
21-38-88
22-39-98
23-64-68
24-56-88
25-43-129
26-70-89
27-47-148

Specific
14,923
38,329
13,949
8,568
8,059
31,486
12,317
5,310
25,860
2,943

ShortGAC
List
NDL
6,339
6,919
4,446
8,460
3,181
3,911

2,668 2,781

1,865 1,889

1,226 2,805

1,717 2,238


1,007
986


909
1,977


1,034
786

Long
1,093
1,282
914
641
599
718
492
377
455
252

Specific
19,524
39,185
21,000
12,262
11,966
30,628
16,075
10,228
23,132
4,677

HaggisGAC
List
NDL
7,999
7,988
5,295
9,330
4,261
4,734

3,955 3,981

3,013 2,896

1,663 3,863

2,441 3,152

1,634 1,506

1,219 2,577

1,265 1,187

Long
1,471
1,684
1,296
886
858
971
702
583
584
400

GAC
Sch.
1,033
1,181
775
592
518
590
474
348
376
272

Con

441
478
276
245
185
349
167
96
245
74

Table 3: Nodes searched per second Rectangle Packing instances. columns named
Table 1.

NDList used less memory, though less dramatically before. used 30%
50% memory HaggisGAC-List.
methods, always least 10 times slower HaggisGAC.
HaggisGAC-Long faster GAC-Schema cases. ShortGAC-Long
faster GAC-Schema instances except 27-47-148 (this contradicts result
previously reported (Nightingale et al., 2011), explanation given
first case study).
Table 3 shows HaggisGAC (with SquarePack instantiation) substantially
faster ShortGAC instances, exception n = 23 n = 26
ShortGAC slightly faster. compared ShortGAC List, NDList,
Long instantiations Figure 2, see HaggisGAC mostly 10
50% faster. summary, results clearly show benefits using strict short
supports.
7.4 Comparing HaggisGAC GAC-Schema
Across experiments, HaggisGAC-Long runs significantly faster GACSchema minimum 20% faster three times faster even
though code contains overhead dealing strict short supports. compared
memory usage across experiments, found similar performance across instances. found HaggisGAC-Long uses less 5% memory except
BIBD instances, BIBD uses less 17% memory GAC-Schema.
However, comparison functional instantiations full-length supports, constraints admit strict short supports. section, broaden
comparison using list instantiations rather functional ones, using problem
instances used previously comparing table constraints.
compared GAC-Schema similar HaggisGAC
ShortGAC conceptually. three algorithms maintain list supports literal,
updated backtracked search. GAC-Schema carefully implemented
29

fiNightingale, Gent, Jefferson, & Miguel

Sports
CarSeq
Graceful
PQueens
BIBD

20

10

5

2

1

0.5
100

1000

10000

100000

Figure 3: Comparison GAC-Schema HaggisGAC-List full-length table constraints. x-axis nodes per second GAC-Schema, y-axis speedup
HaggisGAC-List.

following pseudocode original paper (Bessiere & Regin, 1997). code
shared among three algorithms, optimised independently. example,
GAC-Schema different implementation supportListPerLit, named SC (Bessiere &
Regin, 1997), specialised full-length supports.
contrast GAC-Schema, table constraint propagators STR2 (Lecoutre,
2011) MDDC (Cheng & Yap, 2010) entirely different HaggisGAC, would
difficult create truly comparable implementations them.
report use HaggisGAC-List only, searches supports
way GAC-Schema (with one difference discuss below.) used structured
instances Gent et al. (2007), except Semigroup class. addition, used Car
Sequencing instances Nightingale (2011), specifically model B instances numbered
60-79. instances contain large number ternary table constraints.
Figure 3 shows HaggisGAC-List almost always faster GAC-Schema
problems. BIBDs clear algorithm better. HaggisGAC
always least marginally faster Sports Scheduling, Prime Queens Graceful
Graphs instances, cases range 10-20% faster. HaggisGAC substantially
faster Car Sequencing. seek new supports, HaggisGAC calls Procedure 5,
finds new support stores index listPos. HaggisGAC backtrack
listPos described Section 5.5.1. GAC-Schema similar, backtrack listPos,
ensures optimality branch search iterating listPos
end list (Bessiere & Regin, 1997). Profiling shows GAC-Schema hindered
backtracking listPos (by block-copying memory) Car Sequencing,
large number table constraints (2000 instance 60) large domains (some size
30

fiShort Long Supports Constraint Propagation

1000). Alternative memory management techniques might speed GAC-Schema,
claim HaggisGAC fundamentally 10 times faster GAC-Schema.
7.5 Results Summary
summarise three case studies, HaggisGAC indeed outperform ShortGAC
many instances, sometimes two times commonly 25%.
ShortGAC rarely faster, one instance much 10%. Overall,
experiments, HaggisGAC clearly better algorithm ShortGAC. Furthermore,
HaggisGAC ShortGAC perform well compared Constructive GACSchema, result validates idea strict short supports.
Finally, shown experimentally HaggisGAC outperform GAC-Schema
problems containing full-length supports. discuss Appendix C major focus paper.

8. Backtrack Stability Short Supports
Within search tree, HaggisGAC often spends significant time backtracking data structures. Reducing eliminating backtracking improve efficiency. example MAC-6
MAC-7 much efficient (in space time) backtracking avoided
(Regin, 2005). section present new algorithm saves time deleting
short supports backtrack, saves memory bounding total number stored
short supports (including backtrack stack).
new algorithm requires short supports backtrack stability property.
short support backtrack stable iff remains short support backtracking (Section 3.2).
three case studies, find short supports construct element
lex constraints backtrack stable, rectangle packing not. rectangle
packing, generate empty support constraint entailed. empty support
backtrack stable unless constraint entailed root node search.
introduce algorithm HaggisGAC-Stable know short supports
backtrack stable. key change delete supports backtrack
past point introduction. stable, still correct ancestors
node introduced at. save time previous algorithms, since
sometimes need work backtracking. Also, show below, obtain
tight limits space usage stored supports.
present HaggisGAC-Stable, introduce notion prime support
deleted literal. prime support deleted literal support (either explicit implicit)
valid support literal literal restored backtracking.
invariant maintain deleting literal either labelled deleted
support backtrack stack prime support literals variable currently
implicitly supported. invariant, guarantee backtrack
point literal restored, must supported again: either prime support
restore, known implicit support.
task finding prime support literal naturally splits three cases.
simplest case HaggisGAC-Stable deletes literals able find
31

fiNightingale, Gent, Jefferson, & Miguel

necessary new support. prime support implicit explicit support
whose deletion caused fruitless search new support.
second case literal pruned constraint search
procedure, pruned literal explicit support constraint. explicit
supports must deleted longer valid, label arbitrary one
literals prime support: simply choose last one deleted.
third case unfortunately complicated. literal pruned outside
current constraint, literal implicit support explicit support.
difficult precisely pruned literal link implicit support.
Providing maintaining link throughout search would negate efficiencies
gained. solution problem lazy. variable pruned
literal implicitly supported. implicit support variable,
maintaining invariant described above. literal pruned need nothing
case. need work variable loses last implicit support,
ever does. happens, invalid literal explicit support must
definition relevant zeroLits list. Whereas previously ignored invalid literals
iterating zeroLits, label deleted implicit support prime
support invalid literal.
show Lemma 8.1 HaggisGAC-Stable stores time
O(z) supports, z total number literals. save lot memory
HaggisGAC ShortGAC may store O(z 2 ) supports,
O(z) deletions literals branch, deletion new set O(z) supports
may stored. experiments later show difference memory usage
significant practice. effective, memory usage reduced 20 times.
8.1 Details HaggisGAC-Stable
HaggisGAC-Stable, control great care deletion restoration
supports, instead (as rest paper) simply reversing addition deletion
support node respectively deleting adding back backtrack past
node. short never delete active support backtracking, add back
deleted support prime support literal current active support.
deleting support, setup counter numPrimeSupported. initially 0,
incremented time find support prime support. propagation
algorithm finishes, support numPrimeSupported = 0, support destroyed space reclaimed. Otherwise, place numPrimeSupported new pairs
backtrack stack. pair consists deleted support literal prime
support for. backtracking, pop pair, first check current support
already supports literal. so, simply decrement numPrimeSupported,
reduces 0, reclaim supports space. literal supported,
restore support via call addSupport. way literals support prime
guaranteed supported.
relatively minor difference iterate zeroLits delete invalid literals zeroLits. backtracking restore
32

fiShort Long Supports Constraint Propagation

Require: x 7 v, last explicit support x 7 v deleted
1: v D(x)
2:
supportsPerVar[x] = numSupports supportListPerLit[x 7 v] = {}
3:
sup findNewSupport(x, v)
4:
sup = Null
5:
prune(x 7 v)
6:
increment lastSupportPerLit[x 7 v].numPrimeSupported
7:
push hx 7 v, lastSupportPerLit[x 7 v]i onto BacktrackStack
8:
else
9:
addSupport(sup)
10: else
11:
increment lastSupportPerLit[x 7 v].numPrimeSupported
12:
push hx 7 v, lastSupportPerLit[x 7 v]i onto BacktrackStack

Procedure 11: HaggisGAC-Stable-literalUpdate: (x 7 v). comparison Procedure 9, update numPrimeSupported BacktrackStack.

zeroLits backtrack stack, enables space complexity
result Lemma 8.1.
HaggisGAC-Stable similar HaggisGAC. appropriate simply describe
differences save space. Procedure HaggisGAC-Stable-Propagate almost
Procedure 8, calling backtrack stable variants deleteSupport, literalUpdate
(Procedure 11) variableUpdate (Procedure 12). addition, end algorithm
destroy reclaim space deleted support numPrimeSupported = 0.
Procedure HaggisGAC-Stable-DeleteSupport (called support S)
similar predecessor, Procedure 7, additions. First, initialises numPrimeSupported 0. Second, new data structures lastSupportPerLit deleted
literal x 7 lastSupportPerVar variable x. terms Procedure 7,
assigned Line 9 Line 16 (respectively). Note assignments
make prime support: checked later.
Procedure 11 analogous Procedure 9 enough differences show
detail here. identifies prime supports, necessary increments numPrimeSupported pushes invalid literal/support pairs onto backtrack stack. present
Procedure 12 detail, analogue Procedure 10. identifies prime supports,
increments counter adds pairs BacktrackStack. One difficult case arises,
Line 17. Here, x 7 pruned, externally constraint.
pruned Procedure 11, would zeroLits. x 7 restored backtracking still need make sure support. Since explicit support (it
zeroLits), last support must implicit support deleting. Therefore store
support BacktrackStack. minor change note remove literals
zeroLits, Lines 13 19.
Whenever new search node (including root) entered, Null pushed onto
BacktrackStack. used marker procedure HaggisGAC-StableBacktrack (Procedure 13), processes literal/support pairs reaches Null.
restores prime supports literals put back domain backtracking,
support currently known. numPrimeSupported counter
33

fiNightingale, Gent, Jefferson, & Miguel

Require: variable x
1: (x 7 v) zeroLits[x]
2:
supportsPerVar[x] < numSupports
3:
return
4:
supportListPerLit[x 7 v] 6= {}
5:
Remove (x 7 v) zeroLits[x]
6:
else
7:
v D(x)
8:
sup findNewSupport(x, v)
9:
sup = Null
10:
prune(x 7 v)
11:
increment lastSupportPerVar[x].numPrimeSupported
12:
push hx 7 v, lastSupportPerVar[x]i onto BacktrackStack
13:
Remove (x 7 v) zeroLits[x]
14:
else
15:
addSupport(sup)
16:
else
17:
increment lastSupportPerVar[x].numPrimeSupported
18:
push hx 7 v, lastSupportPerVar[x]i onto BacktrackStack
19:
Remove (x 7 v) zeroLits[x]
Procedure 12: HaggisGAC-Stable-variableUpdate: (x). similar Procedure 10
addition maintenance numPrimeSupported BacktrackStack.
1: top element BacktrackStack Null
2:
pop hx 7 v, supi BacktrackStack
3:
sup yet restored
4:
supportsPerVar(x) = numSupports supportListPerLit[x 7 v] = {}
5:
HaggisGAC-Stable-AddSupport(sup)
6:
else
7:
{Another support exists x 7 v}
8:
decrement sup.numPrimeSupported
9:
sup.numPrimeSupported = 0
10:
destroy sup reclaim space
11:
supportListPerLit[x 7 v] = {}
12:
Add (x 7 v) zeroLits[x]
13: pop Null BacktrackStack

Procedure 13: HaggisGAC-Stable-Backtrack. Performs backtracking using BacktrackStack.

support becomes zero, support destroyed longer necessary. Note
literals put back zeroLits necessary Line 12, reversing deletion
Procedure 12.
cannot use optimisation described Section 5.6, deleting literals supports
variables assigned, may break backtrack stability property.
34

fiShort Long Supports Constraint Propagation

However, retain optimisation Section 6.4 full-length supports, omit
pseudocode showing interest focusing essential aspects algorithms.
8.2 Improved Space Complexity HaggisGAC-Stable
approach improves space complexity HaggisGAC-Stable compared HaggisGAC, following lemma shows.
Lemma 8.1. constraint involving z literals, 2z supports stored, either
active deleted supports backtrack stack.
Proof. define function supports literals. support still active,
found call findNewSupport specific literal, map support
literal. Similarly, support backtrack stack, pair least
one literal prime support for. Map support one literals. Every
stored support falls one two categories, support deleted
put onto backtrack stack, space reclaimed. three supports mapped
literal because:
valid literals, findNewSupport called existing active support
exists literal.
invalid literals, literal appears pair backtrack stack
twice. case literal appears often twice literal
prime support already stack processed variable loses last implicit
support. case, literal must zeroLits, newly deleted implicit
support added backtrack stack literal. happen
delete literal zeroLits first time happens.
Thus number supports bounded 2z.
bound 2z Lemma 8.1 would improve z maintained zeroLits eagerly
instead lazily, expense higher overheads elsewhere.

9. Experimental Evaluation HaggisGAC-Stable
compare HaggisGAC-Stable HaggisGAC using experimental setup
Section 7. well tables results, provide graphical comparison runtimes
HaggisGAC-Stable HaggisGAC Figure 4, memory usage Figure 5.
Table 4 Figure 4 shows results instances Section 7.1. present
four instantiations HaggisGAC-Stable, along fastest instantiation HaggisGAC, Watched Element special-purpose propagator, Constructive (which
faster GAC-Schema Table 1). element, observe 10% slowdown,
slight slowdown List variants. full-length supports, see almost
identical performance.
Table 5 shows results instances Section 7.2. HaggisGAC-Stable-Lex performs slightly worse HaggisGAC-Lex, though fact never 10% worse
slightly faster largest instances. might supports found
35

fiNightingale, Gent, Jefferson, & Miguel

deep search likely contain literals supports found earlier, meaning
backtrack longer supports retained instead replaced earlier
efficient short supports. so, advantage disappears Long variants. Indeed, HaggisGAC-Stable-Long performs much better HaggisGAC-Long,
improvement increases n, 4.5 times n = 24.
Rectangle Packing instantiation ShortGAC described Section 7 generates
empty support constraint becomes entailed, causing variables implicitly
supported point on. empty support backtrack stable, cannot
used HaggisGAC-Stable. implemented new backtrack stable variant
findNewSupport, empty support returned, otherwise
before. List Long variants affected return
empty support case. Table 6, use instances Section 7.3. Results show
significant slowdowns using backtrack stability rectangle packing, 2 times
n = 24. probably inability return empty support.
hand, see speedups 50% list variants, cases factor
2 speedup full-length supports.
see Figure 5 memory usage goes greatly stability used
full-length supports, possibly contributing speedups cases. greatest
reductions case element, two cases 20 times less memory.
hand, significant reduction memory usage non-long variant.
tested HaggisGAC-Stable GAC-Schema Section 7.4. gave
similar performance HaggisGAC therefore better GAC-Schema:
omit detailed results. significant memory advantage compared HaggisGAC, Stable variant saving less 25%. therefore seem gain
advantages saw earlier backtrack stability full-length supports.
conclude backtrack stability speed HaggisGAC significantly,
greatly reduce memory usage using full-length supports. However, care must
used, backtrack stability harmful insisting backtrack stability increases
size returned supports.

10. Related Work
use counters count supports inspired AC4 (Mohr & Henderson, 1986).
study compressing tuples constraint compact data structure
order make propagation efficient. example, Gent et al. (2007) used tries,
Cheng Yap (2010) applied MDDs. extensive study searching
list tuples find first valid tuple. Approaches include binary search (Lecoutre &
Szymanek, 2006), trie search (Gent et al., 2007), approaches similar skip lists
NDLists (Gent et al., 2007) hologram-tuples (Lhomme, 2004; Lhomme & Regin, 2005).
techniques orthogonal main focus paper assist
finding supports, maintaining set active supports. adapted NDLists
contain short supports Section 5.5.2; may interesting adapt
approaches.
STR2 maintains sparse set valid satisfying tuples constraint (Lecoutre,
2011). Updated variable domains computed set time algorithm
36

fiShort Long Supports Constraint Propagation

n

WatchElt

6
7
8
9
10

27,825
22,259
15,635
15,898
15,088

HaggisGAC
Specific
11,131
9,035
5,652
5,419

4,227

HaggisGAC-Stable
Specific
List NDList Long
10,305
4,881
2,358
30.3
8,302
4,225
1,349 15.1

4,986
1,950
550
7.0

4,579
1,711
388
4.4



4,008 2,409
309
2.5

Con

53.5
24.2
9.1

6.2

4.2

Table 4: Nodes searched per second quasigroup existence problems. columns
named Table 1.
n

GACLex

3
4
5
6
7
8
9
10
12
14
16
18
20
22
24

104,955
103,950
95,420
80,841
72,307
66,445
64,267
57,208
48,146
36,751
30,057
22,432
16,625
12,450
9,526

HaggisGAC
Specific Long
91,265 9,288
100,100 8,628
90,009 8,503
74,184 4,666
65,359 3,271
52,659 1,609
47,847
914
39,683
634
32,425
311
23,063
142
18,420
90.9
13,845
53.8
10,711
38.9
8,141
26.0
6,268
18.9

HaggisGAC-Stable
Specific
Long
90,473
12,008
103,470
9,056
93,382
7,248
76,777
3,844
67,273
2,615
52,113
1,591
47,881
1,114
39,176
806
32,310
533
23,709
345
18,556
248
14,504
177
10,438
135
8,159
106
6,165
85

GACSchema
3,622
3,030
2,734
1,638
1,190
670
451
318
170
82.3
51.5
33.3
21.0
12.5

7.3

Con

5,735
4,997
4,104
2,109
1,188
456
263
184
105

99.1

62.6

48.3

36.7

27.0

21.8

Table 5: Nodes searched per second BIBDs. GACLex special-purpose propagator
Lex, columns named Table 1.
n-w-h
18-31-69
19-47-53
20-34-85
21-38-88
22-39-98
23-64-68
24-56-88
25-43-129
26-70-89
27-47-148

HaggisGAC
Specific
19,524
39,185
21,000
12,262
11,966
30,628
16,075
10,228
23,132
4,677

HaggisGAC-Stable
Specific
List NDList
16,950
9,544
8,383
22,580
4,663
8,264
12,865
4,950
4,840

5,827
9,783 6,492

8,798 4,744
4,319


28,987
2,377
4,511

6,741 3,894
3,998

5,706 2,405
2,199


27,507
1,689
4,024

3,996 1,591
1,735

Long
1,686
1,621
2,607
957
921
1,095
1,149
1,265
890
344

GACSchema
1,033
1,181
775
592
518
590
474
348
376
272

Table 6: Nodes searched per second Rectangle Packing instances. columns named
Table 1.

37

fiNightingale, Gent, Jefferson, & Miguel

element
element long
element list
element ndlist
lex
lex long
squarepack
squarepack long
squarepack list
squarepack ndlist

6
5
4
3
2
1.5
1.1
1
0.9
0.7
0.5
0.4
0.3
1

10

100

1000

10000

100000

1e+06

Figure 4: Summary comparison HaggisGAC HaggisGAC-Stable. x-axis
median nodes per second HaggisGAC. y-axis speedup (or slowdown)
HaggisGAC-Stable.

2

1

0.5

0.2

0.1

0.05

0.02
1000

element
element long
element list
element ndlist
lex
lex long
squarepack
squarepack long
squarepack list
squarepack ndlist
10000

100000

1e+06

1e+07

1e+08

Figure 5: Summary comparison memory usage (KiB) HaggisGAC HaggisGACStable. x-axis median memory usage HaggisGAC. y-axis
reduction (or increase) usage HaggisGAC-Stable, i.e. ratio HaggisGAC memory usage HaggisGAC-Stable. Hence 1 represents
equal behaviour, 1 means HaggisGAC-Stable used less memory.

38

fiShort Long Supports Constraint Propagation

invoked. concept maintaining support, seeking new support literal.
would interesting investigate adapting STR2 handle short supports. would
result entirely different algorithm ones presented paper, possibly
complementary strengths.
MDD propagator MDDC (Cheng & Yap, 2010) maintains MDD incrementally
search. MDD compressed representation satisfying tuples
constraint. time complexity MDDC linear initial size MDD, therefore
degree compression vital efficiency algorithm. cases,
constraint amenable strict short supports, compress well MDD
(given appropriate variable ordering). example, lex constraint compresses well
partly (given variable order x1 , y1 , x2 , y2 , . . .) constraint satisfied
assigning prefix variables. Lex amenable short supports reason.
However, constraints small set short supports cannot compressed
effectively MDD. Suppose disjunction equality constraints pair
n variables domain size d. n 1 variables, MDD must Cn1 states.
Another property MDD compression might indicate interesting direction future
work. Lex compresses well MDD multiple assignments prefix
variables lead subsequent vertex (e.g. {x1 7 1, y1 7 1} {x1 7 2, y1 7 2}).
something short support algorithms currently able exploit.
Katsirelos Walsh (2007) proposed different generalisation support, named ctuples. c-tuple contains set values variable scope constraint.
valid tuple whose values drawn c-tuple (full-length) support. Katsirelos
Walsh give outline modified version GAC-Schema directly stores c-tuples.
present experiments based different propagator, GAC3.1r, demonstrating
modest speed improvement c-tuples compared conventional full-length supports.
c-tuple contains values variable, nevertheless recorded (in SC )
support value individually (Katsirelos & Walsh, 2007). algorithm
concept implicit support.
context Constructive Or, Lhomme (2003) observed support one
disjunct support values variable contained A. concept similar
short support albeit less general, length supports fixed
length disjuncts. presented non-incremental Constructive algorithm two
disjuncts.
algorithms similar flavour GAC-Schema (Bessiere & Regin, 1997),
natural compare GAC-Schema. However GAC algorithms
GAC2001/3.1 (Bessiere et al., 2005) would interesting compare
algorithms.

11. Conclusions
introduced detailed three general purpose propagation algorithms short
supports. either given specialised function find new supports
constraint, used function accepts explicit list short supports.
strict short supports available, three algorithms perform well, provide much
39

fiNightingale, Gent, Jefferson, & Miguel

better performance general purpose methods GAC-Schema Constructive Or.
shows value using strict short supports.
first algorithm studied ShortGAC, described improvements
compared earlier report algorithm (Nightingale et al., 2011). identified significant inefficiency ShortGAC dealing explicit supports.
introduced new algorithm, HaggisGAC corrects flaw, better theoretical
complexities, performs much better ShortGAC experiments. three
case studies, HaggisGAC far faster general purpose methods. best case
even achieved speeds 90% special purpose propagator. Perhaps
remarkably, able deal strict short full-length supports, HaggisGAC outperformed ShortGAC strict short supports GAC-Schema full-length
supports, i.e. cases algorithms respectively specialised for.
third algorithm, HaggisGAC-Stable, retain supports backtracking.
less effective HaggisGAC invalidates use certain strict short supports,
significantly faster problems full-length supports, reduce
memory usage greatly cases.
proposed algorithms excellent propagating disjunctions constraints.
experiments disjunctions found algorithms faster Constructive
GAC-Schema least order magnitude, three orders magnitude.
summarise, shown value explicit use strict short supports
general purpose propagation algorithms generalised arc consistency. strict short
supports available, exploiting yields orders magnitude improvements generic
propagation algorithms. cases, even found generic algorithm come
close performance specialised propagator. Previously, short supports
seem recognised important right. overall contribution
correct focus short supports first class objects.

Acknowledgments
would thank anonymous reviewers Bilal Syed Hussain comments,
EPSRC funding work grants EP/H004092/1 EP/E030394/1.

Appendix A. Comparison ShortGAC ShortGAC-IJCAI
Section 4, noted optimised data structures algorithms ShortGAC, compared previous presentation (Nightingale et al., 2011). demonstrate
indeed improvements, compared two implementations ShortGAC
three case studies used paper. use name ShortGAC-IJCAI
previous version. quoting results previous work (Nightingale et al.,
2011), rerun experiments using environment described Section 7.
updated codebase Minion 0.12 instead Minion 0.10 earlier paper.
algorithm instance, report nodes searched per second peak memory use.
Table 7 shows results instances Section 7.1. clear results
ShortGAC makes much better use memory faster ShortGAC-IJCAI
40

fiShort Long Supports Constraint Propagation

0.16

low memory, Sections 7 9
high memory, Sections 7 9
List + NDList, Section 7.4
GAC-Schema + Constructive

0.14
0.12
0.1
0.08
0.06
0.04
0.02
0
0.1

1

10

100

1000

10000

100000

1e+06

Figure 6: Scatterplot median nodes per second (x-axis) median absolute
deviation divided median (y-axis). distinguish
main experiments Sections 7 9, cases medians 5
runs, list variants used table constraints Section 7.4, data
paper GAC-Schema Constructive Or.

instances. Table 8 shows results instances Section 7.2. Element,
ShortGAC makes better use memory faster ShortGAC-IJCAI, although
improvements great before. Table 9, use instances Section 7.3.
previous two case studies, ShortGAC consistently better speed
memory use. conclude algorithms data structures used paper
indeed superior used previously (Nightingale et al., 2011).

Appendix B. Median Absolute Deviation Experiments
experiments report median either 11 5 runs. assess robust
median measure looked, combination instances algorithm,
median absolute deviation (MAD), i.e. median absolute difference data
points median. Figure 6 shows MAD algorithm/instance combinations
fraction median case. shows 511 algorithm/instance combinations
tested (including combinations reported detail paper). nodes per
second, maximum MAD found always less 15% median, worst
case 14.5%. HaggisGAC-Long n = 9 Table 1. four
cases MAD 8% median. Figures memory usage even
consistent, two cases (at 6.3% 6.1%) showing MAD 5% median
others 2%. major conclusions draw regard 10% change
behaviour one method another significant, therefore say
median robust measure performance.
41

fiNightingale, Gent, Jefferson, & Miguel

n
6
7
8
9
10

ShortGAC
node rate
6,956
4,866
2,773
2,374

1,594

ShortGAC-IJCAI
node rate
4,839
3,273
1,673
1,511

1,294

ShortGAC
memory
5,684
6,624
8,996
12,560

17,048

ShortGAC-IJCAI
memory
27,880
72,916
188,812
461,648

991,768

Table 7: Nodes searched per second memory use (KiB) quasigroup existence problems. Comparison ShortGAC ShortGAC-IJCAI.

n
3
4
5
6
7
8
9
10
12
14
16
18
20
22
24

ShortGAC
node rate
87,463
99,602
89,127
73,260
65,062
51,335
47,059
38,344
31,626
22,712
17,813
13,843
10,734
7,976
6,255

ShortGAC-IJCAI
node rate
83,964
98,135
89,286
74,184
63,091
50,480
45,085
36,179
29,455
20,868
16,087
12,356
9,614
7,208
5,398

ShortGAC
memory
7,476
11,680
16,408
22,568
31,348
42,420
55,660
74,348
120,024
181,252
263,792
360,500
493,368
632,064
811,104

ShortGAC-IJCAI
memory
8,392
12,992
18,512
26,260
36,356
49,012
65,684
85,700
138,496
209,492
308,400
422,536
570,188
735,548
939,796

Table 8: Nodes searched per second memory use BIBD problems. Comparison
ShortGAC ShortGAC-IJCAI.

n-w-h
18-31-69
19-47-53
20-34-85
21-38-88
22-39-98
23-64-68
24-56-88
25-43-129
26-70-89
27-47-148

ShortGAC
node rate
14,923
38,329
13,949
8,568
8,059
31,486
12,317
5,310
25,860
2,943

ShortGAC-IJCAI
node rate
10,892
29,647
10,288
6,109
5,821
24,528
8,386
3,828
21,146
2,086

ShortGAC
memory
11,876
10,172
13,988
16,100
18,868
13,988
17,548
27,580
19,796
39,848

ShortGAC-IJCAI
memory
24,568
19,680
33,020
38,828
46,344
31,700
43,708
74,064
49,512
106,144

Table 9: Nodes searched per second memory use rectangle packing. Comparison
ShortGAC ShortGAC-IJCAI.

42

fiShort Long Supports Constraint Propagation

Appendix C. Comparison GAC-Schema HaggisGAC
showed Section 7.4 HaggisGAC outperforms GAC-Schema dealing
full-length supports. despite fact HaggisGAC small overheads
dealing strict short supports even none exist. discuss briefly
may so.
GAC-Schema concept current supports literal one current support,
one active supports contain literal. additional data
structure S( ). active support , S( ) list literals
current support. Hence invalidated, GAC-Schema finds new current support
literal S( ) (or deletes literal). HaggisGAC dispensed
entirely. sign literal needs new support lost current support,
support list (supportListPerLit) empty. small potential saving
maintaining S( ).
second, possibly important, difference GAC-Schema eager
HaggisGAC. literal x 7 v loses current support, GAC-Schema check
active supports containing x 7 v valid, O(n) operation one.
invalid, GAC-Schema calls findNewSupport. returns Null x 7 v
deleted. HaggisGAC none this, avoiding completely cost checking validity. safe every support invalid, literal deletion support
cause call deleteSupport last result empty list, causing call
findNewSupport. approaches correct, GAC-Schemas wasteful
performs unnecessary validity checks. However, one cannot guarantee time saving, GAC-Schema perform deletions sooner, possibly affecting way propagator
interacts propagators.

References
Bessiere, C., Hebrard, E., Hnich, B., & Walsh, T. (2007). complexity reasoning
global constraints. Constraints, 12 (2), 239259.
Bessiere, C., & Regin, J.-C. (1997). Arc consistency general constraint networks: Preliminary results. Proceedings IJCAI 1997, pp. 398404.
Bessiere, C., Regin, J.-C., Yap, R. H. C., & Zhang, Y. (2005). optimal coarse-grained
arc consistency algorithm. Artificial Intelligence, 165 (2), 165185.
Cheng, K. C. K., & Yap, R. H. C. (2010). MDD-based generalized arc consistency
algorithm positive negative table constraints global constraints.
Constraints, 15 (2), 265304.
Colton, S., & Miguel, I. (2001). Constraint generation via automated theory formation.
Proceedings CP 2001, pp. 575579.
Flener, P., Frisch, A. M., Hnich, B., Kiziltan, Z., Miguel, I., Pearson, J., & Walsh, T. (2002).
Breaking row column symmetries matrix models. Proceedings CP 2002, pp.
462476.
Frisch, A. M., Hnich, B., Kiziltan, Z., Miguel, I., & Walsh, T. (2002). Global constraints
lexicographic orderings. Proceedings CP 2002, pp. 93108.
43

fiNightingale, Gent, Jefferson, & Miguel

Frisch, A. M., Hnich, B., Kiziltan, Z., Miguel, I., & Walsh, T. (2006). Propagation algorithms
lexicographic ordering constraints. Artificial Intelligence, 170 (10), 803834.
Gent, I. P. (2012). optimality result maintaining list pointers backtracking
search. Tech. rep. CIRCA preprint 2012/1, University St Andrews.
Gent, I. P., Jefferson, C., & Miguel, I. (2006a). Minion: fast scalable constraint solver.
Proceedings ECAI 2006, pp. 98102.
Gent, I. P., Jefferson, C., & Miguel, I. (2006b). Watched literals constraint propagation
Minion. Proceedings CP 2006, pp. 182197.
Gent, I. P., Jefferson, C., Miguel, I., & Nightingale, P. (2007). Data structures generalised
arc consistency extensional constraints. Proceedings AAAI 2007, pp. 191197.
Gent, I. P., Petrie, K., & Puget, J.-F. (2006). Handbook Constraint Programming (Foundations Artificial Intelligence), chap. Symmetry Constraint Programming, pp.
329376. Elsevier Science Inc., New York, NY, USA.
Jefferson, C., Moore, N. C. A., Nightingale, P., & Petrie, K. E. (2010). Implementing logical
connectives constraint programming. Artificial Intelligence, 174 (16-17), 14071429.
Katsirelos, G., & Walsh, T. (2007). compression algorithm large arity extensional
constraints. Proceedings CP 2007, pp. 379393.
King, A., Cromarty, L., Paterson, C., & Boyd, J. (2007). Applications ultrasonography
reproductive management dux magnus gentis venteris saginati. Veterinary
record, 160 (3), 94.
Lagerkvist, M. Z., & Schulte, C. (2009). Propagator groups. Proceedings CP 2009, pp.
524538.
Lecoutre, C. (2011). STR2: optimized simple tabular reduction table constraints. Constraints, 16 (4), 341371.
Lecoutre, C., & Szymanek, R. (2006). Generalized arc consistency positive table constraints. Proceedings CP 2006, pp. 284298.
Lhomme, O., & Regin, J.-C. (2005). fast arc consistency algorithm n-ary constraints.
Proceedings AAAI 2005, pp. 405410.
Lhomme, O. (2003). efficient filtering algorithm disjunction constraints.
Proceedings CP 2003, pp. 904908.
Lhomme, O. (2004). Arc-consistency filtering algorithms logical combinations constraints. Integration AI Techniques Constraint Programming
Combinatorial Optimization Problems (CP-AI-OR04), pp. 209224.
Mackworth, A. K. (1977). reading sketch maps. Reddy, R. (Ed.), IJCAI, pp. 598606.
William Kaufmann.
Mears, C. D. (2009). Automatic Symmetry Detection Dynamic Symmetry Breaking
Constraint Programming. Ph.D. thesis, Clayton School Information Technology,
Monash University.
Mohr, R., & Henderson, T. C. (1986). Arc path consistency revisited. Artificial Intelligence, 28 (2), 225233.
44

fiShort Long Supports Constraint Propagation

Nightingale, P. (2011). extended global cardinality constraint: empirical survey.
Artificial Intelligence, 175 (2), 586614.
Nightingale, P., Gent, I. P., Jefferson, C., & Miguel, I. (2011). Exploiting short supports
generalised arc consistency arbitrary constraints. Proceedings IJCAI 2011,
pp. 623628.
Puget, J.-F. (2005). Automatic detection variable value symmetries. Proceedings
CP 2005, pp. 475489.
Regin, J.-C. (1996). Generalized arc consistency global cardinality constraint. Proceedings AAAI 1996, pp. 209215.
Regin, J.-C. (2005). Maintaining arc consistency algorithms search without
additional space cost. Proceedings CP 2005, pp. 520533.
Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006). Handbook Constraint Programming.
Elsevier.
Schulte, C., & Tack, G. (2010). Implementing efficient propagation control. Proceedings
TRICS: Techniques Implementing Constraint programming Systems, conference
workshop CP 2010, St Andrews, UK.
Simonis, H., & OSullivan, B. (2008). Search strategies rectangle packing. Proceedings
CP 2008, pp. 5266.
Wurtz, J., & Muller, T. (1996). Constructive disjunction revisited. Proceedings
20th Annual German Conference Artificial Intelligence: Advances Artificial
Intelligence, KI 96, pp. 377386. Springer-Verlag.

45


