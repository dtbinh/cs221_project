journal artificial intelligence

submitted published

automatic aggregation joint modeling
aspects values
christina sauper
regina barzilay

csauper csail mit edu
regina csail mit edu

computer science artificial intelligence laboratory
massachusetts institute technology
vassar st
cambridge usa

abstract
present model aggregation product review snippets joint aspect identification sentiment analysis model simultaneously identifies underlying set
ratable aspects presented reviews product e g sushi miso japanese
restaurant determines corresponding sentiment aspect
directly enables discovery highly rated inconsistent aspects product generative model admits efficient variational mean field inference easily
extensible describe several modifications effects model structure
inference test model two tasks joint aspect identification sentiment analysis set yelp reviews aspect identification alone set medical summaries
evaluate performance model aspect identification sentiment analysis
per word labeling accuracy demonstrate model outperforms applicable
baselines considerable margin yielding relative error reduction aspect
identification relative error reduction sentiment analysis

introduction
online product reviews become increasingly valuable influential source information consumers ability explore range opinions allows consumers
form general opinion product gather information positive negative
aspects e g packaging battery life however reviews added time
information overload gets progressively worse example hundreds
reviews restaurant consumers read handful making decision
work goal summarize large number reviews discovering
informational product aspects associated user sentiment
address need online retailers often use simple aggregation mechanisms represent spectrum user sentiment many sites amazon simply present
distribution user assigned star ratings lacks reasoning
products given rating retailers use breakdowns specific
predefined domain specific aspects food service atmosphere restaurant
breakdowns continue assist effective aggregation however aspects
predefined generic particular domain explanation one aspect rated well poorly instead truly informative aggregation
c

ai access foundation rights reserved

fisauper barzilay

product needs assigned set fine grained aspects specifically tailored
product
goal work provide mechanism effective unsupervised content
aggregation able discover specific fine grained aspects associated values specifically
represent data set collection entities instance represent
products domain online reviews interested discovering fine grained
aspects entity e g sandwiches dessert restaurant additionally would
recover value associated aspect e g sentiment product reviews
summary input output found figure input consists short
text snippets multiple reviews several products restaurant domain
figure restaurants assume snippet opinion bearing
discusses one aspects relevant particular product output
consists set dynamic e pre specified aspects product snippets labeled
aspect discuss sentiment values snippet individually
aspect whole figure aspects identified tasca spanish tapas include
chicken dessert drinks snippets labeled aspects describe
correct polarity
one way treat multi class classification
given set predefined domain specific aspects would fairly straightforward
humans identify aspect particular snippet describes however task
discovering fine grained entity specific aspects way know priori
aspects may present across entire data set provide training data instead
must select aspects dynamically intuitively one potential solution cluster
input snippets grouping lexically similar without prior knowledge
aspects represent however without knowledge words represent
aspect given snippet clusters may align ones useful cross review analysis
consider example two clusters restaurant review snippets shown figure
clusters share many words among members first describes
coherent aspect cluster namely drinks aspect snippets second cluster
discuss single product aspect instead share expressions sentiment
successfully navigate challenge must distinguish words indicate aspect words indicate sentiment extraneous words neither
aspect identification sentiment analysis crucial know words within
snippet relevant task distinguishing straightforward however
work sentiment analysis relies predefined lexicon wordnet provide
hints way anticipate every possible expression aspect sentiment
especially user generated data e g use slang deeeeeee lish delicious
lieu explicit lexicon attempt use information proxy
part speech example aspect words likely nouns value words
likely adjectives however later additional information
sufficient tasks hand
instead propose analyze collection product review snippets
jointly induce set learned aspects respective value e g sentiment
capture idea generative bayesian topic model set aspects
corresponding values represented hidden variables model takes collection


fiautomatic aggregation joint modeling aspects values

input

output

tasca spanish tapas

tasca spanish tapas

review
chicken cooked perfectly
dessert good

chicken
chicken cooked perfectly
chicken tough tasty
moist delicious chicken

review
red wines cheap
excellent creme brulee
review
used frozen small shrimp
chicken tough tasty
pitcher sangria pretty good

douzo sushi bar
review
sushi creative pretty good
ponzu overpowering
review
real wasabi thats fresh
torched roll tasted rather bland


dessert
dessert good
excellent creme brulee





drinks
red wines cheap
pitcher sangria pretty good

douzo sushi bar
sushi
sushi creative pretty good
torched roll tasted rather bland
condiments
ponzu overpowering
real wasabi thats fresh



figure example desired input output system restaurant
domain input consists collection review snippets several restaurants
output aggregation snippets aspect e g chicken dessert along
associated sentiment snippet note input data completely unannotated
information given snippets describe restaurant

snippets input explains observed text arises latent variables
thereby connecting text fragments corresponding aspects values
specifically begin defining sets sentiment word distributions aspect word
distributions expect types sentiment words consistent across
products e g product may labeled great terrible allow positive
negative sentiment word distributions shared across products
hand case restaurant reviews similar domains aspect words expected
quite distinct products therefore assign product set aspect
word distributions addition word distributions model takes account
several factors first model idea particular aspect product
underlying quality already snippets praising particular aspect
likely th snippet positive well second account common
patterns language transition distribution types words example
common see pattern value aspect phrases great pasta
third model distributions parts speech type distribution


fisauper barzilay

coherent aspect cluster


martinis
good

drinks

wine
martinis tasty





wine
list pricey


wine
selection horrible

incoherent aspect cluster



sushi
best
ive
ever

best
paella
id
ever



fillet best
steak wed ever

best
soup
ive
ever


figure example clusters restaurant review snippets generated lexical clustering
words relevant clustering highlighted first cluster represents coherent aspect underlying product namely drinks aspect latter cluster simply
shares common sentiment expression represent snippets discussing
product aspect work aim produce first type aspect cluster along
corresponding values

covers intuition aspect words frequently nouns whereas value words often
adjectives describe factors model whole detail section
formulation provides several advantages first model require set
predefined aspects instead capable assigning latent variables discover
appropriate aspects data second joint analysis aspect value
allows us leverage several pieces information determine words relevant
aspect identification used sentiment analysis including part
speech global entity specific distributions words third bayesian model
admits efficient mean field variational inference procedure parallelized
run quickly even large numbers entities snippets
evaluate domain restaurant reviews specifically use set
snippets automatically extracted restaurant reviews yelp collection consists
average snippets restaurants boston area representing
wide spectrum opinions several aspects restaurant demonstrate
model accurately identify clusters review fragments describe
aspect yielding relative error reduction absolute f standalone clustering
baseline model effectively identify snippet sentiment
relative error reduction absolute accuracy applicable baselines finally
test ability correctly label aspect sentiment words discovering
aspect identification high precision sentiment identification highrecall
additionally apply slimmed version model focuses exclusively
aspect identification set lab exam related snippets medical summaries
provided pediatric environmental health clinic pehc childrens hospital
boston summaries represent concise overviews patient information par

fiautomatic aggregation joint modeling aspects values

ticular visit relayed pehc doctor childs referring physician model
achieves absolute f standalone clustering baseline
remainder structured follows section compares work
previous work aspect identification sentiment analysis section describes
specific formulation task setup concretely section presents details
full model model extensions section describes inference procedure necessary adjustments extension details data sets
experimental formulation presented section summarize findings
consider directions future work section code data used
available online http groups csail mit edu rbg code review aggregation

related work
work falls area multi aspect sentiment analysis section first
describe approaches toward document level sentence level sentiment analysis section
provide foundation future work including describe
three common directions multi aspect sentiment analysis specifically use
data mining fixed aspect analysis section incorporate sentiment
analysis multi document summarization section finally focused
topic modeling additional sentiment components section
single aspect sentiment analysis
early sentiment analysis focused primarily identification coarse document level sentiment pang lee vaithyanathan turney pang lee specifically
approaches attempted determine overall polarity documents approaches included rule machine learning approaches turney used
rule method extract potentially sentiment bearing phrases compared
sentiment known polarity words pang et al used discriminative
methods features unigrams bigrams part speech tags word position
information
document level sentiment analysis give us overall view opinion looking individual sentences within document yields fine grained analysis
work sentence level sentiment analysis focuses first identifying sentiment bearing sentences determining polarity yu hatzivassiloglou dave lawrence
pennock kim hovy pang lee identification
sentiment bearing sentences polarity analysis performed supervised
classifiers yu hatzivassiloglou dave et al similarity known text yu
hatzivassiloglou kim hovy measures distributional
similarity wordnet relationships
recognizing connections parts document sentiment analysis
improved pang lee mcdonald hannan neylon wells reynar
pang lee pang lee leverage relationship sentences
improve document level sentiment analysis specifically utilize subjectivity
individual sentences information strength connection sentences
min cut formulation provide better sentiment focused summaries text mcdonald


fisauper barzilay

et al examine different connection instead constructing hierarchical model
sentiment sentences documents model uses complete labeling
subset data learn generalized set parameters improve classification accuracy
document level sentence level
none approaches attempt identify aspects analyze sentiment
aspect fashion intuitions provide key insight approaches take
work example importance distinguishing opinion sentences follows
intuition necessity identifying sentiment bearing words within snippet
aspect sentiment analysis
following work single aspect document level sentence level sentiment analysis
came intuition modeling aspect called feature sentiment review analysis divide approaches roughly three types systems
techniques systems use fixed aspect approaches data mining techniques
aspect selection sentiment analysis systems adapt techniques multi document
summarization systems jointly model aspect sentiment probabilistic
topic examine avenue work relevant examples contrast
work
data mining fixed aspect techniques sentiment analysis
one set approaches toward aspect sentiment analysis follow traditional techniques data mining hu liu liu hu cheng popescu nguyen
etzioni systems may operate full documents snippets generally require rule templates additional resources wordnet identify
aspects determine sentiment polarity another fix predetermined
relevant set aspects focus learning optimal opinion assignment
aspects snyder barzilay summarize compare
contrast work
one set work relies combination association mining rule extraction
nouns noun phrases aspect identification hu liu liu et al
developed three step system first initial aspects selected association miner
pruned series rules second related opinions aspect identified
rule fashion word positions polarity determined wordnet
search set seed words third additional aspects identified similar
fashion position selected polarity words steps part ofspeech information provides key role extraction rules later work
additional component identify implicit aspects deterministic fashion e g heavy
maps deterministically weight liu et al task similar
utilize part speech information important feature well additionally
leverage distributional information identify aspects sentiment furthermore
avoid reliance wordnet predefined rule mappings order preserve
generality system instead joint modeling allows us recover relationships
without need additional information


fiautomatic aggregation joint modeling aspects values

approaches rely wordnet relationships identify sentiment
polarity aspects parts properties particular product class
popescu et al first use relations generate set aspects given
product class e g camera following apply relaxation labeling sentiment
analysis procedure gradually expands sentiment individual words aspects
sentences similar cascade pattern mentioned work mcdonald et al
system liu et al system requires set manual rules several
outside resources model require seed words require
manual rules additional resources due joint formulation
separate direction work relies predefined aspects focusing improvement
sentiment analysis prediction snyder barzilay define set aspects specific
restaurant domain specifically define individual rating model aspect
plus overall agreement model attempts determine whether resulting ratings
agree disagree jointly trained supervised fashion
extension pranking crammer singer best overall
star rating aspect formulation differs significantly work
several dimensions first desire refined analysis fine grained aspects
instead coarse predefined features second would use little supervised
training data possible rather supervised training required pranking

work attempt capture intuitions approaches reducing
need outside resources rule components example rather supplying
rule patterns extraction aspect sentiment instead leverage distributional patterns across corpus infer relationships words different types
likewise rather relying wordnet relationships synonymy antonymy hyponymy hypernymy hu liu liu et al popescu et al bootstrap
model small set seed words
multi document summarization application sentiment
analysis
multi document summarization techniques generally look repetition across documents
signal important information radev mckeown barzilay mckeown elhadad
radev jing budzikowska mani aspect sentiment analysis
work focused augmenting techniques additional components sentiment
analysis seki eguchi kanodo aono carenini ng pauls kim
zhai general end goal approaches task forming coherent text
summaries text extraction natural language generation unlike work
many approaches explicitly identify aspects instead extracted
repeated information additionally model explicitly looks connection
content sentiment rather treating secondary computation
information selected
one technique incorporating sentiment analysis follows previous work identification opinion bearing sentences seki et al present duc summarization


fisauper barzilay

systems designed create opinion focused summaries task topics system
employ subjectivity component supervised svm lexical features similar
work yu hatzivassiloglou dave et al component
used identify subjective sentences work seki et al polarity
task sentences selected response summary however
previous work unlike task aspect analysis summarization
task fully supervised relying hand annotated set sentences
train svm
another line work focuses augmenting summarization system aspect
selection similar data mining approaches hu liu rather
single aspect analysis carenini ng zwart carenini et al augment
previous aspect selection user defined hierarchical organization aspects e g
digital zoom part lens polarity aspect assumed given previous
work aspects incorporated existing summarization systems mead
sentence extraction radev et al sea natural language generation carenini
moore form final summaries work seki et al work
create techniques aspect identification sentiment analysis instead
focus process integrating sources information summarization systems
aspects produced comparable across reviews particular product
highly supervised nature means feasible large set products
corpus reviews many types restaurants instead must able
dynamically identify relevant aspects
final line related work relies traditional summarization technique identifying contrastive contradictory sentences kim zhai focus generating
contrastive summaries identifying pairs sentences express differing opinions
particular product feature define metrics representativeness coverage opinions contrastiveness alignment quality semantic similarity
wordnet matches word overlap comparison work follows orthogonal goal try defining aspects instead
contradictory ones additionally selected pairs hint disagreements rating
identification many people agree side overall rating
particular aspect work aim produce concrete set aspects
user sentiment whether unanimous shows disagreement
overall methods designed produce output summaries focus
subjective information specifically targeted aspect analysis instead
aspects identified supervised fashion carenini et al defined
seki et al kim zhai work crucial
dynamically selected aspects feasible preselect aspects supervised
fashion
probabilistic topic modeling sentiment analysis
work closest direction aspect analysis focuses use
probabilistic topic modeling techniques identification aspects may aggre task examples see work dang



fiautomatic aggregation joint modeling aspects values

gated without specific sentiment polarity lu zhai combined additional
sentiment modeling jointly mei ling wondra su zhai blei mcauliffe
titov mcdonald separate post processing step titov mcdonald
b work approaches share intuition aspects may represented
topics
several approaches focus extraction topics sentiment blog articles
one used expert articles aspect extraction combination
larger corpus user reviews lu zhai introduce model semi supervised
probabilistic latent semantic analysis plsa identifies sentiment bearing aspects
segmentation expert review model extracts compatible supporting
supplementary text aspect set user reviews aspect selection
constrained rule approaches specifically aspect words required
nouns work differs work significantly share common goal
identifying aggregating opinion bearing aspects additionally desire identify
polarity opinions task addressed work addition obtaining aspects
expert review unnecessarily constraining practice expert reviewers may
mention key aspects mention every aspect crucial discover
aspects entire set articles
work direction aspect identification blog posts example
mei et al use variation latent dirichlet allocation lda similar
explicitly model topics sentiment use hidden markov model discover
sentiment dynamics across topic life cycles general sentiment polarity distribution
computed combining distributions several separate labeled data sets e g movies
cities etc however work sentiment measured document level rather
topic level additionally topics discovered model broad example processing query da vinci code returned topics may labeled
book movie religion rather fine grained aspects desire model
representing major characters events model expands work discovering fine grained aspects associating particular sentiment individual
aspect addition tying sentiment aspects able identify sentiment bearing
words associated polarities without additional annotation required train
external sentiment model
sentiment may combined lda additional latent variables
document order predict document level sentiment blei mcauliffe propose
form supervised lda slda incorporates additional response variable
used represent sentiment star rating movie jointly
model documents responses order latent topics best predict
response variables future unlabeled documents work significantly different
work supervised predict multi aspect framework
building approaches comes work fine grained aspect identification sentiment analysis titov mcdonald b introduce multi grain unsupervised
topic model specifically built extension lda technique yields mixture
global local topics word distributions topics global local drawn
global level however unlike model consequence topics
easy compare across products corpus however topics gen

fisauper barzilay

eral less dynamic hope achieve must shared among every
product one consequence defining global topics difficulty finding relevant topics
every product little overlap example case restaurant reviews
italian restaurants completely different set aspects indian restaurants
course factors known would possible run separately
subset restaurants distinctions immediately clear priori increasing number topics could assist recovering additional aspects however
aspects still global still difficult identify restaurant specific aspects
sentiment analysis pranking snyder barzilay incorporated two ways first pranking trained pipeline fashion
topics generated titov mcdonald b later incorporated model
inference joint formulation titov mcdonald however cases
original set aspects fixed aspects corresponds
fixed set topics found model additionally learning supervised
fixed aspects necessary additional supervision global topic distribution model formulation sufficient domain requires
fine grained aspects
approaches structural similarity work present
variations lda none however intent model mei et al
model aspect sentiment jointly however aspects vague treat
sentiment document level rather aspect level likewise titov mcdonald
b model fine grained aspects still coarser aspects
require even increase number aspects distributions shared
globally finally lu zhai blei mcauliffe titov mcdonald
b require supervised annotation supervised expert review
attempt solve issues joint formulation order proceed
minimal supervision discover truly fine grained aspects

formulation
explaining model details describe random variables abstractions
model well intuitions assumptions visual explanation model
components shown figure present complete details generative story
section
model components
model composed five component types entities snippets aspects values
word topics describe type provide examples

explain complete model value selection sentiment restaurant domain
simplified case medical domain would use aspects may simply ignore
value related components model



fiautomatic aggregation joint modeling aspects values

tasca spanish tapas
entity
aspects

chicken




chicken cooked perfectly
chicken tough tasty
moist delicious chicken
snippets

values

dessert



dessert good
excellent creme brulee


douzo sushi bar
sushi



sushi creative pretty good
torched roll tasted rather bland



figure labeled model components example figure note aspects
never given explicit labels ones shown presented purely ease
understanding aspects exist simply groups snippets share common subject
word topics pictured word topic aspect value background
assigned word snippet model components described high level
section depth section

entity
entity represents single object described review restaurant
domain represent individual restaurants tasca spanish tapas douzo sushi
bar outback steakhouse
snippet
snippet user generated short sequence words describing entity snippets
provided user example quick reaction box extracted
complete reviews phrase extraction system one sauper
haghighi barzilay assume snippet contains one single
aspect e g pizza one single value type e g positive restaurant domain
corresponds giving opinion one particular dish category dishes examples
restaurant domain include pasta dishes perfection
fantastic drinks lasagna rustica cooked perfectly


fisauper barzilay

aspect
aspect corresponds one several properties entity restaurant domain
entities represent restaurants aspects may correspond individual dishes categories dishes pizza alcoholic drinks domain entity
unique set aspects allows us model aspects appropriate granularity
example italian restaurant may dessert aspect pertains information variety cakes pies gelato however bakerys menu would
fall dessert aspect instead present useful aspect summary
would require separate aspects cakes pies aspects
entity specific rather shared ties restaurants aspects
common e g sushi restaurants sashimi aspect consider
point potential future work note still possible compare aspects across
entities e g best restaurant burger comparing respective word
distributions
value
values represent information associated aspect review domain two
value types represent positive negative sentiment respectively general possible
use value represent distinctions example domain aspects
associated numeric value others associated text description
set value type intended distinctions may encouraged
use seed words see section may left unspecified model assign
whatever finds best fit data number value types must prespecified
however possible use many types
word topic
words snippet observed word associated underlying
latent topic possible latent topics correspond aspect value background
topic example review domain latent topic words great terrible would
value words represent entity aspects pizza would aspect
stop words domain white noise food would background
setup
work assume snippet words observed correlation
snippets entities known e know entity given snippet describes
addition assume part speech tags word snippet final source
supervision may optionally include small sets seed words lexical distribution
order bias distribution toward intended meaning example sentiment
case add seed words order bias one value distribution toward positive one
toward negative seed words certainly required simply tool constrain
use distributions fit prior expectations
note formulation relevant aspects restaurant observed
instead represented lexical distributions induced inference time


fiautomatic aggregation joint modeling aspects values

system output aspects represented unlabeled clusters snippets given
formulation goal work induce latent aspect value underlying
snippet

model
model generative formulation snippets corpus section
first describe detail general formulation notation model discuss
novel changes enhancements particular corpora types inference model
discussed section mentioned previously describe complete model
including aspect values
general formulation
model assume collection snippet words entities use si j w
denote wth word jth snippet ith entity assume fixed vocabulary
words w
present summary notation table concise summary model
figure model diagram figure three levels model design
global distributions common snippets entities collection entity level
distributions common snippets describing single entity snippet word level
random variables describe turn
global distributions
global level draw set distributions common entities corpus
include everything shared across domain background stop word distribution
value types word topic transitions
background distribution global background word distribution b drawn represent stop words domain white noise e g food becomes white noise corpus
restaurant reviews distribution drawn symmetric dirichlet concentration parameter b experiments set
value distributions value word distribution vv drawn value type v
example review domain positive negative sentiment types
distribution words positive type one negative type seed words
wseedv given additional probability mass value priors type v specifically
non seed word receives hyperparameter seed word receives v
experiments set
transition distribution transition distribution drawn represent transition
probabilities underlying word topics example may likely
value aspect transition review domain fits phrases great pizza
experiments distribution given slight prior bias toward helpful transitions
label desired automatically extract one selecting highest probability words
particular aspect simplicity exactness provide manual cluster labels examples




fisauper barzilay

data set

si j w
ti j w
w
wseedv

collection snippet words entities
wth word jth snippet ith entity
part speech tag corresponding si j w
fixed vocabulary
seed words value type v

lexical distributions
b




v
v


background word distribution
aspect word distribution aspect entity
value word distribution type v
ignored words distribution

distributions





transition distribution word topics
aspect value multinomial aspect entity
aspect multinomial entity
part speech tag distribution

latent variables
j
za
zvi j
j w
zw

aspect selected si j
value type selected si j
word topic v b selected si j w

notation
k

v
b


number aspects
indicator corresponding
indicator corresponding
indicator corresponding
indicator corresponding






aspect word
value word
background word
ignored word

table notation used items marked
section



relate extensions mentioned

example encouraging sticky behavior providing small boost self transitions
bias easily overridden data however provides useful starting point
entity specific distributions
naturally variations aspects snippets describe many snippets
describe aspect example mobile device popular long battery life likely
snippets describing battery device known large screen
domains may enormous variation aspect vocabulary example restaurant
reviews two restaurants may serve food items compare account


fiautomatic aggregation joint modeling aspects values

global level
draw background word distribution b dirichlet b w
value type v
draw value word distribution vv dirichlet w v wseedv
entity level
entity

draw aspect word distributions
dirichlet w k

draw aspect value multinomial dirichlet av n k
draw aspect multinomial dirichlet k
snippet level
snippet j describing ith entity
j

draw snippet aspect za
j

draw snippet value zvi j za

j w
j w
zw
draw sequence word topic indicators zw
j
value zvi j
draw snippet word given aspect za

si j w


z j



z j

v v



b

j w

zw
j w
v
zw
j w
zw b

figure summary generative model presented section use dirichlet w denote finite dirichlet prior hyper parameter counts scalar
times unit vector vocabulary items global value word distribution prior
hyper parameter counts vocabulary items v wseedv vector
vocabulary items set seed words value v

variations define set entity specific distributions generate
aspect vocabulary popularity well distribution value types aspect

aspect distributions aspect word distribution
drawn aspect
represents distribution unigrams particular aspect example
domain restaurant reviews aspects may correspond menu items pizza
reviews cell phones may correspond details battery life



fisauper barzilay

value v
background word
distribution

transition
distribution

value word
distributions

b



vv

entity

aspect
aspect
multinomial

aspect word
distributions

aspect value
multinomial



ai



snippet j

snippet aspect

snippet value

zai j

zvi j

hmm snippet words



j w
zw

j w
zw

j w
zw

si j w

si j w

si j w

zai j ai
zvi j vv
b
figure graphical description model presented section written description generative process located figure curved arrows indicate additional links
present model drawn readability



fiautomatic aggregation joint modeling aspects values

aspect word distribution drawn symmetric dirichlet prior hyperparameter
experiments set
aspect value multinomials aspect value multinomials determine likelihood
value type v corresponding aspect example value types represent
positive negative sentiment corresponds agreement sentiment across snippets
likewise value types represent formatting integers decimals text aspect
generally prefers type value multinomials drawn symmetric
dirichlet prior hyperparameter av experiments set
aspect multinomial aspect multinomial controls likelihood aspect
discussed given snippet encodes intuition certain aspects
likely discussed others given entity example particular italian
restaurant famous pizza likely pizza aspect frequently
discussed reviews drinks aspect may mentioned occasionally
aspect multinomial encode higher likelihood choosing pizza snippet
aspect drinks multinomial drawn symmetric dirichlet distribution
hyperparameter experiments set
snippet word specific random variables
distributions described draw random variables snippet
determine aspect value type described well sequence
underlying word topics words
j
snippet describe drawn aspect
aspect single aspect za

multinomial aspect words snippet e g pizza corpus restaurant
j
za

reviews drawn corresponding aspect word distribution



value type single value type zvi j drawn conditioned selected aspect
j
corresponding aspect value multinomial za value words snippet e g great
z j

review domain drawn corresponding value word distribution v v
j
j
generword topic indicators sequence word topic indicators zw
zw
ated first order markov model parameterized transition matrix
indicators determine unigram distribution generates word snippet
j w
example zw
b wth word snippet generated background word
distribution b

model extensions
optional components model may improve performance
cases briefly list present necessary modifications model
detail case modifications inference procedure presented section
first corpora contain irrelevant snippets may introduce additional word
distribution word topic ignore allow model ignore certain snippets
pieces snippets altogether second possible acquire part speech tags


fisauper barzilay

snippets extra piece information quite beneficial finally corpora
every entity expected share aspects model altered use
set aspect distributions entities
ignoring snippets
snippet data automatically extracted may noisy snippets may
violate initial assumptions one aspect one value example
snippets mistakenly extracted neither aspect value
extraneous snippets may difficult identify priori compensate modify
model allow partial entire snippets ignored addition global
unigram distribution namely ignore distribution distribution drawn
symmetric dirichlet concentration parameter
ignore distribution differs background distribution includes
common uncommon words intended select whole snippets large portions
snippets words may overlap background distribution distributions order successfully incorporate distribution model must allow
j w
consider ignore topic additionally ensure
word topic indicator zw
selects long segments text give large boost prior ignore ignore
sequence transition distribution similar boost self transitions
part speech tags
part speech tags provide valuable evidence determining snippet words
drawn distribution example aspect words often nouns represent
concrete properties concepts domain likewise domains value words
describe aspects therefore tend expressed numbers adjectives
intuition directly incorporated model form additional
outputs specifically modify hmm produce words tags additionally
v similar corresponding unigram
define distributions tags
v
b
distributions
shared aspects
domains regular every entity expected express aspects
consistent set beneficial share aspect information across entities example
medical domain general set lab tests physical exam categories run
patients note quite unlike restaurant review case restaurants
aspects completely different e g pizza curry scones
sharing aspects way accomplished modifying aspect distributions

likewise aspect value multinomials become

become global distributions
shared across entities treatment aspect multinomials depend
domain properties distribution aspects expected across
entities made global however individual entity expected exhibit
variation number snippets related aspect kept entityspecific example reviews set cell phones may expected focus varying


fiautomatic aggregation joint modeling aspects values

value v
background word
distribution

transition
distribution

value word
distributions

b



vv

entity

aspect
aspect
multinomial

aspect word
distributions

aspect value
multinomial



aa



snippet j

snippet aspect

snippet value

zai j

zvi j

hmm snippet words



j w
zw

j w
zw

j w
zw

si j w

si j w

si j w

zai j ai
zvi j vv
b
figure graphical description model shared aspects presented section
note similarities figure however version aspects shared entire
corpus rather entity specific would possible share aspect
multinomial corpus wide case would indicate entities share
general distribution aspects version individual entities allowed
completely different distributions

parts depending unique problematic phones graphical
description changes compared original model shown figure


fisauper barzilay

mean field factorization
q b v z
q b q

n



q vv

v




q





k




q
q








j j j w

q zv q za
q zw
w

j

snippet aspect indicator
j
log q za
eq log

x

j w
j w
q zw
eq log




w

n
x

q zvi j v eq log v

v

snippet value type indicator
x
x
j
j w
log q zvi j v
q za
eq log v
q zw
v eq vv log vv si j w


w

word topic indicator
x





j w
j
j j w
j w
j w

eq log
zw
q za

log q zw
log p zw eq log zw

















j w

j w
j w
v log p zw v eq log zw
v v zw
log q zw





x

q zvi j v eq vv log vv si j w


v

log q

j w
zw

b log p zw b eq log


j w
b
zw

j w
b zw



eq b log b si j w



figure mean field variational used learning inference obtain posterior predictions snippet properties attributes described section
mean field inference consists updating latent variable factors well
straightforward update latent parameters round robin fashion

inference
goal inference model predict aspect value snippet
product j given text observed snippets marginalizing remaining
hidden parameters
j
p za
zvi j
accomplish task variational inference blei ng jordan specifically goal variational inference tractable approximation q full
posterior model
p b v z q b v z
model assume full mean field factorization variational distribution
shown figure variational approximation defined product factors q
assumed independent approximation allows tractable inference
factor individually obtain closest possible approximation attempt set




fiautomatic aggregation joint modeling aspects values

q factors minimize kl divergence true model posterior
arg min kl q b v z kp b v z
q

optimization
optimize objective coordinate descent q factors concretely
update factor optimizing criterion factors fixed
current values
q eq q log p b v z
summary variational update equations given figure graphical
representation involved variables step presented figure
present update factor
snippet aspect indicator
j
first consider update snippet aspect indicator za
figure
j
log q za
eq log
x
j w
j w

q zw
eq log





b



w
n
x



q zvi j v eq log v

c

v

optimal aspect particular snippet depends three factors first include
likelihood discussing aspect eqn mentioned earlier encodes
prior probability aspects discussed frequently others second
examine likelihood particular aspect words snippet eqn b
word identified aspect word add probability discusses
aspect third determine compatibility chosen aspect type
current aspect eqn c example know value type likely integer
assigned aspect accept integers
snippet value type indicator
next consider update snippet value type indicator zvi j figure b
x
j
log q zvi j v
q za
eq log v







x

j w
q zw
v eq vv log vv si j w

b

w

best value type snippet depends two factors first snippet aspect
indicator must take consideration compatibility snippet aspect
value type eqn second word identified value word include
likelihood comes given value type


fisauper barzilay

v
b

v
vv













j



zv v
za
b



j

zvi j

w
zw

w
zw

w
zw

sw

sw

sw

zv v
za
b



vv



j

j
za

w
zw



za
sw

z





j





w
zw

w
zw

sw

sw

sw

vv




w
zw



w
zw


sw

sw

z

zv
sw v





vv






b


j
za

w
zw

w
zw


w
zw

v





zvi j



b





zvi j

v






b inference procedure snippet value zvi j

v





j
za



j
inference procedure snippet aspect za

b

vv





j
za



b





zvi j



j

w
zw

w
zw



sw

sw

z



j
za

w
zw

zvi j
w
zw

w
zw

sw

sw



w
ii zw
v

sw b

w
iii zw
b

j w
c inference procedure word topic zw

figure variational inference update steps latent variable latent variable
currently updated shown double circle variables relevant
update highlighted black variables impact update
grayed note snippet aspect snippet value type b update takes
form possible aspect value type however word topic c
update symmetric relevant variables different possible word topic



fiautomatic aggregation joint modeling aspects values

word topic indicator
j w
finally consider update word topic indicators zw
figure c unlike
previous indicators possible topic slightly different equation must
marginalize possible aspects value types






j w
j w
j w
log q zw
log p zw eq log zw
zw
x

j
j j w

q za
eq log













j w
j w
j w
log q zw
v log p zw v eq log zw
v v zw
x



q zvi j v eq vv log vv si j w

b

v






j w
j w
j w
b b zw
b log p zw b eq log zw
log q zw

eq b log b si j w

c

update topic composed prior probability topic transition probabilities topic probability word coming appropriate unigram distribution marginalized possibilities snippet aspect value
indicators
parameter factors
updates parameter factors variational inference derived simple
counts latent variables za zv zw note include partial counts
j
would contribute
particular snippet aspect probability p za

count
details
given set update equations update procedure straightforward first iterate
corpus computing updated values random variable batch
update factors simultaneously update run convergence
practice convergence achieved th iteration quite efficient
note batch update means update computed values
previous iteration unlike gibbs sampling uses updated values runs
corpus difference allows variational update parallelized yielding
nice efficiency boost specifically parallelize simply split set
entities evenly among processors updates entity specific factors variables
computed pass data updates global factors collected
combined end pass


fisauper barzilay

inference model extensions
discussed section add additional components model improve
performance data certain attributes briefly discuss modifications
inference equations extension
ignoring snippets
main modifications model extension addition unigram
distribution word topic chosen zw update equation zw
modified addition following
j w
log q zw
log p zw eq log si j w

pieces equation eqn composed prior probability
word topic likelihood word generated
addition transition distribution must updated include transition probabilities mentioned earlier ii transition receives high weight
transitions receive low weight
part speech tags
add part speech tags model updated include part speech distributions

v b one word topic note unlike unigram distributions
vv corresponding tag distributions dependent snippet entity aspect
value included referenced updates zw follows





j w
j w
j w
zw
log q zw
log p zw eq log zw
x

j j w
j
eq log ti j w
eq log

q za









j w
j w
j w
v v zw
v log p zw v eq log zw
log q zw
x


q zvi j v eq vv log vv si j w
eq v log v ti j w
v






j w
j w
j w
log q zw
b log p zw b eq log zw
b b zw


eq b log b ti j w eq b log b si j w
define set tags ti j w tag corresponding word si j w
shared aspects
global set shared aspects simplification model reduces total
aspect value
number parameters model redefines aspect distributions
multinomials depending domain may redefine aspect multinomial
resulting latent variable update equations parameter


fiautomatic aggregation joint modeling aspects values

factor updates changed rather collecting counts snippets describing single
entity counts collected across corpus

experiments
perform experiments two tasks first test full model joint prediction
aspect sentiment corpus review data second use simplified version
model designed identify aspects corpus medical summary data
domains structured quite differently therefore present different challenges
model
joint identification aspect sentiment
first task test full model jointly predicting aspect sentiment
collection restaurant review data specifically would dynamically select
set relevant aspects restaurant identify snippets correspond
aspect recover polarity snippet individually aspect whole
perform three experiments evaluate effectiveness first test
quality learned aspects evaluating predicted snippet clusters second assess
quality polarity classification third examine per word labeling accuracy
data set
data set task consists snippets selected yelp restaurant reviews
previous system sauper et al system trained extract snippets containing
short descriptions user sentiment towards aspect restaurant purpose
experiment select snippets labeled system referencing food
order ensure enough data meaningful analysis ignore restaurants
fewer snippets across reviews model easily operate
restaurants fewer snippets want ensure cases select evaluation
nontrivial e sufficient number snippets cluster make
valid comparison snippets total taken restaurants
around boston cambridge area average snippet length words
average snippets per restaurant use mxpost tagger ratnaparkhi
gather pos tags data figure shows example snippets
domain value distributions consist one positive one negative distribution seeded seed words respectively seed words hand selected
restaurant review domain therefore include domain specific words
delicious gross complete list seed words included table
domain challenges modeling techniques
domain presents two challenging characteristics model first wide
variety restaurants within domain including everything high end asian fusion
cuisine greasy burger fast food places try represent single
exact training procedures please reference



fisauper barzilay

positive
amazing
delightful
extraordinary
flavorful
generous
heaven
inexpensive
perfect
recommend
stimulating
wonderful

negative
awesome
divine
fantastic
free
good
huge
love
phenomenal
rich
strong
yummy

best
enjoy
fav
fresh
great
incredible
nice
pleasant
sleek
tasty

delicious
excellent
favorite
fun
happy
interesting
outstanding
quality
stellar
tender

average
bland
disappointed
expensive
gross
lame
meh
poor
tacky
tiny
uninspiring

awful
boring
disgusting
fatty
horrible
less
mushy
pricey
tasteless
unappetizing
worse

bad
confused
dry
greasy
inedible
mediocre
overcooked
salty
terrible
underwhelming
worst

table seed words used model restaurant corpus positive words
negative words total words manually selected data set
shared set aspects number aspects required would immense would
extremely difficult model make fine grained distinctions
defining aspects separately restaurant mentioned section achieve
proper granularity aspects individual restaurant without overwhelming
overlapping selection choices example model able distinguish
italian restaurant may need single dessert aspect bakery requires separate
pie cake cookie aspects
second usually fairly cohesive set words refer particular
aspect e g pizza aspect might commonly seen words slice pepperoni
cheese near unlimited set potential sentiment words especially
pronounced social media domain many novel words used express
sentiment e g deeeeeeeelish substitute delicious mentioned section
part speech transition components model helps identify unknown
words likely sentiment words however additionally need identify polarity sentiment leverage aspect value multinomial
represents likelihood positive negative sentiment particular aspect
snippets given aspect positive likely word deeeeeeeelish
represents positive sentiment well
cluster prediction
j
goal task evaluate quality aspect clusters specifically za
variable
section ideal clustering predicted clusters cohesive e snippets
predicted discuss given aspect related comprehensive e
snippets discuss aspect selected example snippet
assigned aspect pizza snippet mentions aspect pizza
crust cheese toppings

annotation experiment use set gold clusters complete sets
snippets restaurants snippets total average snippets per
restaurant cluster annotations provided graduate students fluent english
annotator provided complete set snippets particular restaurant
asked cluster naturally clusters total yields average


fiautomatic aggregation joint modeling aspects values

noodles meat actually
pretty
good

recommend chicken noodle pho
soggy
noodles
chicken pho good

though
spring rolls coffee good


spring roll wrappers little
dry tasting

crispy
spring
rolls
favorites



crispy tuna spring rolls fantastic






lobster roll mother ordered
dry scant

portabella mushroom go
sandwich

bread sandwich stale

rather
measly
slice tomato

shumai california maki sushi
decent

spicy tuna roll eel roll perfect



great
rolls spicy mayo

love thai rolls


figure example snippets data set grouped according aspect aspect words
underlined colored blue negative value words labeled colored red
positive value words labeled colored green grouping labeling
given data set must learned model

clusters per restaurant annotations high quality average annotator
agreement muc evaluation metric described detail could
define different number clusters restaurant varying number aspect
distributions simplicity ask baseline systems full model produce
aspect clusters per restaurant matching average annotated number varying
number clusters simply cause existing clusters merge split large
surprising changes clustering
baseline use two baselines task clustering weighted
tf idf implemented publicly available cluto package karypis
agglomerative clustering cosine similarity distance metric chen branavan
barzilay karger chen benson naseem barzilay
first baseline cluster clusters entire snippets data set
baseline put strong connection things lexically similar
model uses aspect words tie together clusters baseline may capture correlations
words model correctly identify aspect words
available http glaros dtc umn edu gkhome cluto cluto overview



fisauper barzilay

cluster
cluster noun
model

precision

recall









f




table muc metric cluster prediction joint aspect value
identification task muc deficiency putting everything single
cluster artificially inflate score set use number clusters
note task cluster noun significantly outperforms cluster
baseline indicating part speech crucial piece information task

second baseline cluster noun works nouns snippets
snippet pos tagged mxpost ratnaparkhi non noun e
nn nns nnp nnps words removed expect aspects contain
least one noun acts proxy aspect identification model
metric use muc cluster evaluation metric task vilain burger aberdeen
connolly hirschman metric measures number cluster merges
splits required recreate gold clusters given output therefore
concisely accurate clusters whole would possible
artificially inflate score putting everything single cluster parameters
model likelihood objective model prefers use available
clusters number baseline system
cluster prediction task table model shows strong
performance baseline total error reduction cluster noun
baseline cluster baseline common cause poor cluster
choices baseline systems inability distinguish words relevant
aspect words example cluster baseline many snippets use word
delicious may end cluster alone cluster noun
baseline able avoid pitfalls thanks built filter able
avoid common value words adjectives focus seems
concrete portion aspect e g blackened chicken however still cannot make
correct distinctions assumptions broken model capable
distinguishing words aspect words e words relevant clustering
choose clusters make sense overall
sentiment analysis
evaluate systems predictions snippet sentiment predicted posterior
j
value distributions snippet e za
task consider binary
j
judgment simply one higher value q za
see section goal
task evaluate whether model correctly distinguishes sentiment value words
available http www inf ed ac uk resources nlp local doc mxpost html



fiautomatic aggregation joint modeling aspects values

majority
discriminative small
seed
discriminative large
model

accuracy






table sentiment prediction accuracy model compared discriminative
seed baselines well majority representing majority class positive baseline
one advantage system ability distinguish aspect words sentiment words
order restrict judgment relevant terms another leverage gains
biasing unknown sentiment words follow polarity observed snippets
relating aspect
annotation task use set randomly selected snippets yelp
reviews express opinions get clear set specifically excludes neutral
mixed potentially ambiguous snippets fries salty tasty
blackened chicken spicy make overall data set
split training set snippets test set snippets snippet
manually labeled positive negative one baseline use set positive
negative seed words manually chosen model shown table note
model access full corpus unlabeled data plus seed words
labeled examples
baseline use two baselines task one standard discriminative
classifier one seed words model
discriminative baseline task standard maximum entropy discriminative binary classifier unigrams given enough snippets enough unrelated aspects
classifier able identify words great indicate positive sentiment
bad indicate negative sentiment words chicken neutral
effect illustrate effect training size include discriminativesmall uses training examples discriminative large uses
training examples
seed baseline simply counts number words positive
negative seed lists used model vseed vseed listed table
words vseed snippet labeled positive words
vseed snippet labeled negative tie seed words split
prediction seed word lists manually selected specifically restaurant
reviews e contain food related sentiment words delicious baseline
perform well
overall sentiment classification accuracy system shown table model outperforms baselines obvious flaw seed baseline
available https github com lzhang maxent



fisauper barzilay



accuracy














discriminative
seed
model







number snippets training data

figure discriminative baseline performance number training examples increases performance generally increases inconsistencies main
issue baseline needs see examples words training data
improve phenomenon seen plateau graph

inability pre specify every possible sentiment word perform highly due
tailoring restaurant domain good coverage frequent words e g
delicious good great performance model indicates generalize
beyond seed words
discriminative large outperforms seed baseline test set however
given smaller training set discriminative small performs worse training
curve discriminative baseline shown figure discriminative
baseline system correctly identify polarity statements containing information
seen past two main weaknesses first every sentiment word must
present training data example test data rancid appears negative
sentence however appear training data model labels example
incorrectly problematic way training data every possible
sentiment word especially social media data novel words typos frequent
occurrence ability generalize polarity snippets describing
particular aspect allows predict sentiment values words unknown polarity
example already several positive snippets describing particular aspect
system guess snippet unknown polarity likely positive
per word labeling accuracy
goal task evaluate whether word correctly identified aspect
word value word background word distinction crucial order achieve
correctness clustering sentiment analysis errors may help us identify
weaknesses model


fiautomatic aggregation joint modeling aspects values

rolls nt
well made

pita
beyond dry

tasted
cardboard


falafel
falafel king best

rolls spicy mayo
good


ordered spicy tuna california roll amazing


table correct annotation set phrases containing elements may confusing
annotators tested allowed annotate actual test data aspect words colored blue underlined value words colored orange underlined
wavy line common mistakes include annotating nt background
attached background word annotating cardboard aspect
noun annotating falafel king aspect subject position
annotation per word annotation acquired mechanical turk per word labeling task seems difficult turk annotators implement filtering procedure
ensure high quality annotators allowed submit specifically
ask annotators produce labels set difficult phrases known labels shown
table annotators successfully produced correct mostly correct annotations allowed access annotation tasks containing phrases
unknown tasks presented annotators majority label taken word
total test labeled phrases total labeled words
baseline baseline task relies intuition part speech
useful proxy aspect value identification know aspects usually represent
concrete entities often nouns value words descriptive counting
often adjectives adverbs therefore use mxpost tagger
pos word snippet main baseline tags full assign noun
nn aspect label numeral adjective adverb verb participle cd rb
jj vbg vbn value label comparison present smaller tagset
small tags labeling nouns nn aspect adjectives jj values note
tags added tags full baseline beneficial baselines score
tree expansion full model baselines designed pick
relevant individual words rather phrases may correspond well phrases
humans selected relevant therefore evaluate set expanded
labels identified parse trees stanford parser klein manning specifically non background word identify largest containing noun phrase
aspects values adjective adverb phrase values
contain oppositely labeled words example noun phrase blackened chicken
chicken labeled aspect word blackened labeled background word
labeled aspect words however noun phrase tasty chicken
tasty already labeled value label changed expansion
attempted final heuristic step punctuation determiners conjunctions
available http nlp stanford edu software lex parser shtml



fisauper barzilay

tree expansion procedure aspect words
noun phrases contain aspect word pork


innovative



appetizers pork apple glaze
np
np
np

highlights


select largest noun phrase contain value sentiment words
np valid contain value words however largest valid np
np valid contain value words largest valid np selected
np contains value word innovative
invalid


convert background words within selected noun phrase aspect words
except punctuation determiners conjunctions


innovative



appetizers pork apple glaze

highlights


figure tree expansion procedure value words example snippet
procedure similar aspect words except adjective phrases adverb phrases
considered expansion
aspect
precision recall

f

value
precision recall

f

tags small
tree



















tags full
tree





































model
tree

table per word labeling precision recall model compared tags small
tags full baselines without expansion trees model
precise aspect better recall value note general process expanding labels tree structure increases recall expense precision
would newly labeled aspect value words ignored kept background
words steps procedure illustrative example shown figure
evaluate systems precision recall aspect value separately
systems shown table model without tree expansion
highly precise expense recall however expansion performed recall
improves tremendously especially value words
initially disappointing possible adjust model parameters
increase performance task example aspect words could put additional


fiautomatic aggregation joint modeling aspects values

moqueca delicious

perfect winter food
warm filling hearty


heavy

bacon wrapped almond dates
amazing plantains cheese boring


artichoke homemade pasta appetizers
great

table high precision low recall aspect word labeling full model note
human would likely identify complete phrases bacon wrapped almond dates
homemade pasta appetizers however additional noise degrades performance
clustering task

start

v
b









v






b













end






table learned transition distribution model pattern high precision
aspect words represented preference continuing string several aspect
words causing model prefer single precise aspect words likewise better recall
value words indicated higher value v v transition encourage
several words row marked value words
j w
mass prior zw
increase dirichlet hyperparameter however
increases performance word labeling task decreases performance
correspondingly clustering task examination data correlation
perfectly reasonable order succeed clustering task model selects
relevant portions snippet aspect words entire aspect value
identified clustering becomes noisy table shows examples high precision
labeling achieves high clustering performance table shows example
learned transition distribution creates labeling

aspect identification shared aspects
second task uses simplified version model designed aspect identification
task use corpus medical visit summaries domain
summary expected contain similar relevant information therefore set aspects
shared corpus wide evaluate model formulation examine predicted
clusters snippets full model
data set
data set task consists phrases selected dictated patient summaries
pediatric environmental health clinic pehc childrens hospital boston specializing
treatment children lead poisoning specifically patients office visit lab
completed pehc doctor dictates letter referring physician containing


fisauper barzilay

information previous visits current developmental family status office exam
lab current diagnosis plan future
experiment select phrases office exam lab sections
summaries phrases separated heuristically commas semicolons domain contains significant amount extraneous information restaurant
domain must extract phrases believe bear relevance task hand
however medical text dense nearly relevant heuristic separation
sufficient extract relevant phrases snippets total taken
summaries average snippet length words average snippets
per summary yelp domain use mxpost tagger ratnaparkhi
gain pos tags figure shows example snippets domain
values simply concentrate aspect identification task unlike restaurant
domain use seed words
domain challenges modeling techniques
contrast restaurant domain medical domain uses single global set aspects
represent individual lab tests e g lead level white blood cell count particular body systems e g lungs cardiovascular aspects far common
others uncommon summary include one two snippets
given aspect therefore mentioned section model aspect word
distributions aspect multinomial shared entities corpus
contrast restaurant domain aspects defined words taken
entire snippet rather aspects associated names measurements
e g weight units descriptions measurement e g kilograms
relevant aspect definition property extends numeric written measurements example aspect lungs commonly described clear auscultation
bilaterally order achieve high performance model must leverage
clues provide proper aspect identification name measurement missing
e g patient cm part speech still important factor model
predict greater importance additional parts speech
nouns
finally data set noisy contains irrelevant snippets section
headings e g physical examination review systems extraneous information
described section modify model ignore partial complete
snippets
cluster prediction
joint aspect sentiment prediction goal task evaluate quality
aspect identification aspects shared across documents clusters
generally much larger set annotated snippets represents fraction
cluster
annotation experiment use set gold clusters gathered snippets annotated doctor expert domain pediatric environmental health clinic childrens hospital boston note mentioned clusters


fiautomatic aggregation joint modeling aspects values

cm height
patients height cm
lungs clear bilaterally auscultation
lungs normal
heart regular rate rhythm murmurs
heart normal

figure example snippets medical data set grouped according aspect
aspect words underlined colored blue grouping labeling given
data set must learned model

cluster
cluster noun
model

precision

recall









f




table muc metric cluster prediction aspect identification
task note cluster baseline significantly outperforms cluster noun
opposite observe joint aspect value prediction task due
dependence aspect identification name lab test
units description test mentioned section

global domain e g many patients snippets representing blood lead
level grouped one cluster doctor asked cluster
snippets time spanning several patients clustering entire set would
infeasible human annotator sets snippets clustered resulting
clusters manually combined match similar clusters set example blood lead level cluster first set snippets combined
corresponding blood lead level clusters set snippets cluster
final set fewer members removed total yields gold set
clusters snippets total average snippets per cluster
match baseline systems full model asked produce clusters across
full data set
baselines metric keep consistent previous task
use baselines evaluation metric baselines rely tf idfweighted clustering specifically implemented cluto package karypis
agglomerative clustering cosine similarity distance metric
cluster represents baseline unigrams snippets entire data set
cluster noun works nouns snippets use
muc cluster evaluation metric task details baselines
evaluation metric please see section


fisauper barzilay

experiment system demonstrates improvement
cluster baseline absolute performance relatively high systems
medical domain indicating lexical clustering task less misleading
restaurant domain interesting note unlike restaurant domain
cluster baseline outperforms cluster noun baseline mentioned section medical data notable relevance entire snippet clustering
e g weight kilograms useful identify weight aspect
property nouns cluster cluster noun baseline hurts performance
significantly

conclusions future work
presented fine grained content aggregation
probabilistic topic modeling techniques discover structure individual text snippets
model able successfully identify clusters snippets data set discuss
aspect entity well associated values e g sentiment requires
annotation small list seed vocabulary bias positive negative
distributions proper direction
demonstrate delving structure snippet assist
identifying key words important unique domain hand
values learned joint identification aspect value help improve
quality word labeling analysis reveals model learns different
type labeling task specifically strict high precision labeling clustering
task high recall labeling sentiment follows intuition important
identify specific main points clustering sentiment analysis task
may often several descriptions conflicting opinions presented need
weighed together determine overall sentiment
model admits fast parallelized inference procedure specifically entire inference procedure takes roughly minutes run restaurant corpus less
minutes medical corpus additionally model neatly extensible adjustable
fit particular characteristics given domain
limitations model improved future work
first model makes attempt explicitly model negation word interactions
increasing difficulty aspect sentiment analysis model performing error analysis negation common source error sentiment
analysis task likewise aspect side model make errors attempting
differentiate aspects ice cream cream cheese share common aspect
word cream despite phrases occurring bigrams connections
stronger way indicator variable negation higher order hmm
model could make informed decisions
second defining aspects per entity restaurant domain advantages
possible get fine grained set applicable aspects fails leverage
potential information data set specifically know restaurants sharing
type e g italian indian bakery etc share common aspects
however ties current model likewise even global


fiautomatic aggregation joint modeling aspects values

level may aspects tie across restaurants hierarchical version
model would able tie together identify different types aspects
global e g presentation type level e g pasta italian type restaurant level
e g restaurants special dish

bibliographic note
portions published previously conference publication sauper
haghighi barzilay however significantly extends work describe several model generalizations extensions section effects
inference procedure section present experimental including additional baseline comparisons additional experiment section introduce
domain medical summary text quite different domain restaurant
reviews therefore requires several fundamental changes model section

acknowledgments
authors acknowledge support nsf career grant iis nih grant
r lm nokia darpa machine reading program afrl prime
contract fa c thanks peter szolovits mit nlp group
helpful comments opinions findings conclusions recommendations expressed
authors necessarily reflect views funding
organizations

references
barzilay r mckeown k r elhadad information fusion context
multi document summarization proceedings acl pp
blei mcauliffe j supervised topic advances nips pp

blei ng jordan latent dirichlet allocation journal
machine learning
carenini g moore j generating evaluating evaluative arguments
artificial intelligence
carenini g ng r pauls multi document summarization evaluative text
proceedings eacl pp
carenini g ng r zwart e extracting knowledge evaluative text
proceedings k cap pp
chen h benson e naseem barzilay r domain relation discovery
meta constraints via posterior regularization proceedings acl pp
chen h branavan r k barzilay r karger r global
document structure latent permutations proceedings acl hlt pp



fisauper barzilay

crammer k singer pranking ranking advances nips pp
mit press
dang h overview duc proceedings duc emnlp hlt
dang h overview duc proceedings duc naacl hlt
dave k lawrence pennock mining peanut gallery opinion
extraction semantic classification product reviews proceedings www
pp
hu liu b mining summarizing customer reviews proceedings
sigkdd pp
karypis g cluto clustering toolkit tech rep dept computer
science university minnesota available http www cs umn educluto
kim h zhai c generating comparative summaries contradictory opinions
text proceedings cikm pp
kim hovy e automatic detection opinion bearing words sentences
proceedings ijcnlp pp
kim hovy e automatic identification pro con reasons online
reviews proceedings coling acl pp
klein manning c accurate unlexicalized parsing proceedings acl
pp
liu b hu cheng j opinion observer analyzing comparing opinions
web proceedings www pp
lu zhai c opinion integration semi supervised topic modeling
proceedings www pp
mani automatic summarization vol john benjamins pub co
mcdonald r hannan k neylon wells reynar j structured
fine coarse sentiment analysis proceedings acl pp
mei q ling x wondra su h zhai c topic sentiment mixture modeling
facets opinions weblogs proceedings www pp
pang b lee l sentimental education sentiment analysis subjectivity
summarization minimum cuts proceedings acl pp
pang b lee l opinion mining sentiment analysis foundations trends
information retrieval
pang b lee l vaithyanathan thumbs sentiment classification
machine learning techniques proceedings emnlp pp
popescu nguyen b etzioni opine extracting product features
opinions reviews proceedings emnlp hlt pp
radev mckeown k generating natural language summaries multiple
line sources computational linguistics


fiautomatic aggregation joint modeling aspects values

radev r jing h budzikowska centroid summarization multiple documents sentence extraction utility evaluation user studies
proceedings naacl anlp workshop automatic summarization pp

ratnaparkhi maximum entropy model part speech tagging proceedings emnlp pp
sauper c haghighi barzilay r incorporating content structure text
analysis applications proceedings emnlp pp
sauper c haghighi barzilay r content attitude proceedings acl pp
seki eguchi k kanodo n aono multi document summarization
subjectivity analysis duc proceedings duc emnlp hlt
seki eguchi k kanodo n aono opinion focused summarization
analysis duc proceedings duc naacl hlt pp
snyder b barzilay r multiple aspect ranking good grief
proceedings naacl hlt pp
titov mcdonald r joint model text aspect ratings sentiment
summarization proceedings acl pp
titov mcdonald r b modeling online reviews multi grain topic
proceedings www pp
turney p thumbs thumbs semantic orientation applied unsupervised classification reviews proceedings acl pp
vilain burger j aberdeen j connolly hirschman l modeltheoretic coreference scoring scheme proceedings muc pp
yu h hatzivassiloglou v towards answering opinion questions separating
facts opinions identifying polarity opinion sentences proceedings
emnlp pp association computational linguistics




