Journal Artificial Intelligence Research 18 (2003) 183-215

Submitted 9/01; published 2/03

Evolutionary Algorithm Advanced Goal Priority
Specification Multi-objective Optimization
Kay Chen Tan
Eik Fun Khor
Tong Heng Lee
Ramasubramanian Sathikannan

ELETANKC@NUS.EDU.SG
EIKFUN.KHOR@SEAGATE.COM
ELELEETH@NUS.EDU.SG
K.SATHI@GSK.COM

National University Singapore
4 Engineering Drive 3, Singapore 117576
Republic Singapore

Abstract
paper presents evolutionary algorithm new goal-sequence domination scheme
better decision support multi-objective optimization. approach allows inclusion
advanced hard/soft priority constraint information objective component, capable
incorporating multiple specifications overlapping non-overlapping objective functions via
logical connectives drive search towards multiple regions trade-off.
addition, propose dynamic sharing scheme simple adaptively estimated according
on-line population distribution without needing priori parameter setting. feature
proposed algorithm examined show respective contribution, performance
algorithm compared evolutionary optimization methods. shown proposed
algorithm performed well diversity evolutionary search uniform distribution
non-dominated individuals along final trade-offs, without significant computational effort.
algorithm applied design optimization practical servo control system hard disk
drives single voice-coil-motor actuator. Results evolutionary designed servo control
system show superior closed-loop performance compared classical PID RPT approaches.

1. Introduction
Many real-world design tasks involve optimizing vector objective functions feasible
decision variable space. objective functions often non-commensurable
competition other, cannot simply aggregated scalar function
optimization. type problem known multi-objective (MO) optimization problem,
solution family points known Pareto-optimal set (Goldberg, 1989),
objective component member set improved degrading least one
objective components. obtain good solution via conventional MO optimization
techniques methods inequalities, goal attainment weighted sum approach,
continuous cost function and/or set precise settings weights goals required,
usually well manageable understood (Grace, 1992; Osyczka, 1984).
Emulating Darwinian-Wallace principle survival-of-the-fittest natural selection
genetics, evolutionary algorithms (EAs) (Holland, 1975) found effective
efficient solving complex problems conventional optimization tools fail work well.
2003 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiTAN, KHOR, LEE, & SATHIKANNAN

EAs evaluate performances candidate solutions multiple points simultaneously,
capable approaching global optimum noisy, poorly understood and/or non-differentiable
search space (Goldberg, 1989).
Since Schaffers work (1985), evolutionary algorithm-based search techniques MO
optimization gaining significant attention researchers various disciplines.
reflected high volume publications topic last years well first
international conference Evolutionary Multi-criteria Optimization (EMO01) held March
2001 Zurich, Switzerland. Readers may refer (Coello Coello, 1996; 1999; Deb, 2001;
Fonseca, 1995; Van Veldhuizen & Lamont, 1998; Zitzler & Thiele, 1999) detailed
implementation various evolutionary techniques MO optimization.
Unlike conventional methods linearly combine multiple attributes form composite
scalar objective function, concept Pareto's optimality modified selection scheme
incorporated evolutionary MO optimization evolve family solutions multiple points
along trade-off surface simultaneously (Fonseca & Fleming, 1993). Among various selection
techniques evolutionary MO optimization, Pareto-dominance scheme (Goldberg, 1989)
assigns equal rank non-dominated individuals effective approach comparing
strengths among different candidate solutions population (Fonseca & Fleming, 1993). Starting
principle, Fonseca Fleming (1993) proposed Pareto-based ranking scheme
include goal priority information MO optimization. underlying reason certain
user knowledge may available optimization problem, preferences and/or goals
achieved certain objective components. information could useful incorporated
means goal priority vectors, simplify optimization process allow
evolution directed towards certain concentrated regions trade-offs. Although
ranking scheme good approach, works single goal priority vector setting,
may difficult define accurately prior optimization process real-world
optimization problems. Moreover, scheme allow advanced specifications,
logical operations among multiple goals priorities.
Based Pareto-based domination approach, paper reformulates domination scheme
incorporate advanced specifications better decision support MO optimization. Besides
flexibility incorporating goal priority information objective component,
proposed domination scheme allows inclusion hard/soft priority constraint
specifications. addition, approach capable incorporating multiple specifications
overlapping non-overlapping objective functions via logical connectives
drive search towards multiple regions trade-off. paper proposes dynamic
sharing scheme, computes sharing distance adaptively based upon on-line
population distribution objective domain without need priori parameter setting.
dynamic sharing approach essential since eliminates difficulty manually finding
appropriate sharing distance prior optimization process. choice distance would
sensitive size geometry discovered trade-offs (Coello Coello, 1999; Fonseca &
Fleming, 1993).
paper organized follows: formulation proposed domination scheme
better decision support presented Section 2. dynamic sharing scheme estimates
184

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

sharing distance adaptively based upon on-line population distribution described Section 3.
Section 4 examines usefulness contribution proposed feature algorithm.
performance comparison proposed algorithm evolutionary MO optimization
methods shown section. Practical application proposed algorithm servo
control system design optimization given Section 5. Conclusions drawn Section 6.

2. Advanced Goal Priority Specifications MO Optimization
multi-objective optimization problem seeks optimize vector non-commensurable
often competing objectives, i.e., tends find parameter set P Min F ( P ) , P R n , P
P

= {p1, p2,, pn} n-dimensional vector n decision variables parameters, defines
feasible set P. F = {f1, f2,, fm} objective vector objectives minimized.
MO optimization problem simple goal priority specification objective function,
Pareto-based ranking scheme sufficient (Fonseca & Fleming, 1993). practice, however,
may difficult define accurate goal priority setting priori optimization process
real-world optimization problems. Besides goal priority information, could
additional supporting specifications useful need satisfied evolutionary search,
optimization constraints feasibility solution. Moreover, Pareto-based ranking
scheme allow advanced specifications, logical operations
among multiple goals priorities better decision support complex MO optimization.
section, new goal-sequence Pareto-based domination scheme proposed address
issues provide hard/soft goal priority specifications better controls
evolutionary optimization process.
2.1 Pareto-based Domination Goal Information

section effective two-stage Pareto-based domination scheme MO optimization,
extended incorporate advanced soft/hard goal priority specifications. Consider
minimization problem. objective vector Fa said dominate another objective vector Fb
based idea Pareto dominance, denoted Fa Fb, iff f ,i f b,i {1,2,..., m}
f , j < f b, j j {1,2,..., m} . Adopting basic principle Pareto dominance, first

stage proposed domination approach ranks individuals satisfy goal setting
minimize objective functions much possible. assigns smallest cost
non-dominated individuals, dominated individuals ranked according many
individuals population dominate them. second stage ranks remaining individuals
meet goal setting based upon following extended domination scheme. Let Fa
Fb

)


)




denote component vector Fa Fb respectively, Fa meet
185

fiTAN, KHOR, LEE, & SATHIKANNAN

goal G . Fa Fb totally satisfy goal G , vector Fa said
dominate vector Fb (denoted Fa Fb ) iff
G

)


)


( Fa Fb ) (abs( Fa -G) abs( Fb -G))

(1)

this, rank begins one increment maximum rank value obtained first
stage cost assignment. Therefore individuals meet goal directed toward
goal infinum objective domain, satisfied goal
directed towards infinum. Note domination comparison operator
non-commutative ( Fa Fb Fb Fa ). Figure 1 shows optimization problem two
G

G

objectives f1 f2 minimized. arrows Figure 1 indicate transformation according
F' = F G objective function F F' individuals satisfy goal,
goal new reference point transformed objective domain. obvious
domination scheme simple efficient comparing strengths among partially totally
unsatisfactory individuals population. comparisons among totally satisfactory individuals,
basic Pareto-dominance sufficient.
study computational efficiency approach, population divided two
separate groups classified goal satisfaction, domination comparison performed
separately group individuals. total number domination comparisons
two-stage domination scheme Nc = [ nG( ( nG( -1)+ nG) ( nG) -1)] nG( number
individuals completely satisfy goal G nG) number individuals partially satisfy
completely satisfy goal G. Note nG( + nG) = N population size N. Hence,
generation, Nc always less equal total number domination comparisons
among individuals population (each individual population compared (N-1)
individuals), i.e., Nc Nnc = N ( N 1) . next section, two-stage Pareto-based
domination scheme extended incorporate soft/hard priority specifications advanced
MO optimization.

186

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

f2

6
6

6

5

5

5

G
4
1

6
2
1

6

f1

Figure 1: Advanced Pareto Domination Scheme Goal Information
2.2 Goal-Sequence Domination Scheme Soft/Hard Priority Specifications

One advanced capabilities evolutionary MO optimization incorporate cognitive
specification, priority information indicates relative importance multiple
tasks provide useful guidance optimization. Consider problem multiple
non-commensurable tasks, task assigned qualitative form priority indicating
relative importance. general, exist two alternatives accomplish tasks, i.e.,
consider one task time sequence according task priority accomplish tasks
considering individual task according task priority. Intuitively, former
approach provides good optimization performance tasks higher priority may result
relatively poor performance others. due fact optimizing higher priority
tasks may performance expense lower priority tasks. definition priority
denoted hard priority paper. hand, latter approach provides
distributed approach tasks aim compromise solution importance
priority individual task considered. defined "soft" priority. Similarly, priorities
different objective components MO optimization classified "hard" "soft" priority.
hard priorities, goal settings (if applicable) higher priority objective components must
satisfied first attaining goals lower priority. contrast, soft priorities first optimize
overall performance objective components, much possible, attaining goal
setting individual objective component sequence according priority vector.
achieve greater flexibility MO optimization, two-stage Pareto-based domination
scheme extended incorporate soft hard priority specifications without
goal information means new goal-sequence domination. Here, instead one priority
vector indicate priorities among multiple objective components (Fonseca & Fleming, 1998),
two kinds priority vectors used accommodate soft/hard priority information. Consider
objective priority vector, Pf 1xm goal priority vector, Pg 1xm, Pf(i) represents
priority ith objective component F(i) minimized; Pg(i) denotes priority
187

fiTAN, KHOR, LEE, & SATHIKANNAN

ith goal component G(i) attained; number objectives minimized
denotes natural numbers. elements vector Pf Pg take value
natural numbers, lower number representing higher priority zero representing dont
care priority assignment. Note repeated values among elements Pf Pg used
indicate equal priority provided Pf(i) Pg(i) {1, 2, , m}, avoiding contradiction
priority assignment. combination objective priority vector Pf goal priority
vector Pg, soft hard priorities defined provided one preference
among objective components given
{(Pf : Pf (j) > 1) (Pg : Pg (j) > 1)} j {1, 2, , m}
(2)
Based this, priority setting regarded soft iff
{1, 2, , m} {(Pf : Pf (i) = 1) (Pg : Pg (i) = 1)}
(3)
else, priority denoted hard.
example, settings Pf = [1, 1, 2, 2] Pg = [0, 0, 0, 0] 4-objective optimization
problem indicate first second objective components given top priority
minimized, much possible, considering minimization third fourth objective
components. Since elements Pg zeros (dont care), goal components considered
minimization case. hand, setting Pf = [0, 0, 0, 0] Pg = [1, 1, 2, 2]
imply first second objective components given first priority meet
respective goal components considering goal attainment third fourth
objective components. two different priority settings categorized hard
priorities since cases, objective components higher priority minimized
considering objective components lower priority. soft priority defined Eq. 3,
objective priority vector goal priority vector set Pg = [1, 1, 1, 1] Pf = [2, 2, 3, 3],
respectively. implies evolution directed towards minimizing objective
components goal region attempt minimize higher priority objective
components sequence defined priority vector.
systematically rank individuals population incorporate soft/hard priority
specifications, sequence goals corresponding priority information generated
represented goal-sequence matrix G kth row matrix represents goal vector
corresponding kth priority. number goal vectors generated depends last
level priority z, z maximum value one element Pg Pf given
z = max[Pg(i), Pf(j)]

i, j {1,2,..., m}

(4)

this, goal vectors kth priority goal-sequence matrix Gk(i) priority index k
= 1, 2,, z defined

G (i )

= 1,..., m, G k (i ) = min[F j =1,..., N (i )]
max[F
j =1,..., N (i )]


Pg (i ) = k
P f (i ) = k

(5)

otherwise

N denotes population size; min[F j =1,..., N (i )] max[F j =1,..., N (i )] represents
minimum maximum value ith objective function on-line population distribution,
188

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

respectively. Eq. 5, ith objective component k priority level, reason
assigning Gk(i) G(i) guide individuals towards goal regions; min[F j =1,..., N (i )]
minimize corresponding objective component much possible; max[F j =1,..., N (i )]
relax requirements individuals give objective components room
improvement. According Eq. 5, goal-sequence matrix Gk(i) dynamic generation,
values min[F j =1,..., N (i )] max[F j =1,..., N (i )] dynamically computed depending
on-line population distribution. computing sequence goals Gk k {1, 2,, z},
individuals first ranked according computed goal G1 first priority.
group individuals ranks compared ranked according next
goal G2 second priority evaluate individuals' domination population.
general, ranking process continues individual rank value
ranking goal Gz lowest priority goal-sequence matrix. Note individuals
rank value evaluated components dont care
assignments.
proposed goal-sequence domination scheme given Eq. 5, hard soft
priority specifications incorporated MO optimization. Without loss generality, consider
two-objective optimization problem, f1 higher priority f2, well goal
setting G = [g1, g2]. soft priority optimization defined Eq. 3, goal priority vector
objective priority vector set Pg = [1, 1] Pf = [2, 0], respectively. Let min[F(i)]
max[F(i)] denote minimum maximum value i-objective component F
population, respectively. relevant goals goal-sequence matrix priority level
defined Eq. 5 given G1 = G first priority G2 = {min[F(1)], max[F(2)]}
second priority. goal-sequence domination scheme two-objective minimization
problem illustrated Figure 2. Here, rank value individual denoted r1 r2,
r1 r2 rank value goal-sequence ranking first second priority,
respectively. preference setting indicates g1 g2 given priority
attained optimization individuals ranked according higher priority
f1. illustrated Figure 3a, shows location desired Pareto-front (represented
dark region) expected evolution direction (represented curved arrow)
objective domain example unfeasible goal setting G.
hard priority optimization defined Eqs. 2 3, goal priority vector objective
priority vector set Pg = [1, 2] Pf = [0, 0], respectively. According Eq. 5, gives
goal sequence G1 = [g1, max[F(2)] G2 = [max[F(1)], g2] first second priority,
respectively. implies g1 given higher priority g2 attained optimization.
Figure 3b shows location desired Pareto-front (represented dark region)
expected evolution direction (represented curved arrow) objective domain. compared
solutions obtained soft priority optimization, hard priority optimization attempts attain
first goal component leads solution better f1 (higher priority) worse f2 (lower
priority). mentioned setting soft/hard priority may subjective problem
189

fiTAN, KHOR, LEE, & SATHIKANNAN

dependent practice. general, hard priority optimization may appropriate problems
well-defined goals order avoid stagnation unfeasible goal settings. Soft priority
optimization suitable applications moderate performance among various
objective components desired. Besides soft/hard priority information, may additional
specifications optimization constraints required satisfied optimization.
specifications could easily incorporated MO optimization formulating
constraints additional objective components optimized (Fonseca & Fleming, 1998).
discussed next section.
f2
G'2

77
55
56

G'1

g2

4 4
11

78
23
12

g1

f1

Figure 2: Goal-sequence Domination Goal G = {g1, g2}, Priority Pg = [1, 1] Pf = [2, 0]

f2

f2

G2'

G '1

max[F(2)]

tinon


Evoluti

luo
EEvvooluti

n

desired solution
desired solution

g2

G
G '1

g2

Unfeasible
Region

G

G'2

Unfeasible
Region

g1

g1

f1

max[F(1)]

f1

(a) Soft priority f1 higher f2
(b) Hard priority f1 higher f2
Figure 3: Illustration Soft Hard Priority Unfeasible Goal Setting
2.3 Optimization Soft Hard Constraints

Constraints often exist practical optimization problems (Luus et al. 1995; Michalewicz &
Schoenauer, 1996). constraints often incorporated MO optimization function
190

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

one objective components optimized. could form "hard" constraint
optimization directed towards attaining threshold goal, optimization
meaningless desirable whenever goal satisfied. contrast, "soft" constraint
requires value objective component corresponding constraint optimized much
possible. easy approach deal hard soft constraints concurrently
evolutionary MO optimization given here. generation, updated objective function Fx#
concerning hard soft constraints individual x objective function Fx
computed priori goal-sequence domination scheme given
G (i ) [G (i) hard] & [F x (i) < G (i )]
#
F x (i) =
otherwise
F x (i )

= {1,..., m}

(6)

Eq. 6, objective component corresponds hard constraint assigned value
G(i) whenever hard constraint satisfied. underlying reason
ranking preference particular objective component value
evolutionary optimization process, thus evolution directed towards optimizing
soft constraints unattained hard constraints, desired.
2.4 Logical Connectives among Goal Priority Specifications

MO optimization problems single goal priority specification, decision maker often
needs guess appropriate initial goal priority vector manually observe
optimization progress. goal components stringent generous, goal
setting adjusted accordingly satisfactory solution obtained.
approach obviously requires extensive human observation intervention, tedious
inefficient practice. Marcu (1997) proposed method adapting goal values based upon
on-line population distribution every generation. However, adaptation goal values
formulated way search always uniformly directed towards middle region
trade-offs. restriction may undesirable many applications, trade-off
surface unknown search needs directed direction middle region
trade-off surface. reduce human interaction allow multiple sets goal priority
specifications direct evolutionary search towards different portion trade-off surface
single run, goal-sequence domination scheme extended section enable logical
statements ( ) ( ) operations among multiple goal priority
specifications.
logical operations built top goal-sequence domination procedure
specification. this, unified rank value individual determined taken
effect immediately evolution towards regions concerned. Consider ranking
objective vector Fx comparing rest individuals population reference
two different specification settings Si Sj, Si Sj specifications concerning
set objective functions without goals priorities. Let ranks denoted
rank(Fx, Si) rank(Fx, Sj), respectively. operations two goal
settings defined as,
191

fiTAN, KHOR, LEE, & SATHIKANNAN

rank ( Fx , j ) = min{rank ( Fx , ), rank ( Fx , j )}

(7a)

rank ( Fx , j ) = max{rank ( Fx , ), rank ( Fx , j )}

(7b)

According Eq. 7, rank value vector Fx operation two
specifications Si Sj takes minimum rank value respect two specification settings.
order evolve population towards one specifications objective
vector less strongly violated. contrast, operation takes maximum rank value
order direct evolutionary search towards minimizing amount violation
specifications concurrently. Clearly, operations Eq. 7 easily
extended include general logical specifications complex connectives, (Si
Sj) (Sk Sl), desired.

3. Dynamic Sharing Scheme MOEA Program Flowchart
3.1 Dynamic Sharing Scheme

Fitness sharing proposed Goldberg Richardson (1987) evolve equally distributed
population along Pareto-optimal front distribute population multiple optima
search space. method creates sub-divisions objective domain degrading individual
fitness upon existence individuals neighborhood defined sharing distance.
niche count, mi = Nj sh(d , j ) , calculated summing sharing function members
population, distance di,j represents distance individual j.
sharing function defined

i,j

sh(d , j ) = 1 share

0


, j < share

(8)

otherwise

parameter commonly set 1.
sharing function Eq. 8 requires good setting sharing distance share estimated
upon trade-off surface, usually unknown many optimization problems (Coello
Coello, 1999). Moreover, size objective space usually cannot predefined, exact
bounds objective space often undetermined. Fonseca Fleming (1993) proposed
method Kernel density estimation determine appropriate sharing distance MO
optimization. However, sharing process performed sphere space may
reflect actual objective space population expected uniformly distributed.
Miller Shaw (1996) proposed dynamic sharing method peaks parameter
domain dynamically detected recalculated every generation sharing distance
remains predefined. However, approach made assumption number niche
peaks estimated peaks minimum distance 2share other.
192

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

Moreover, formulation defined parameter space handle multi-modal function
optimization, may appropriate distributing population uniformly along
Pareto-optimal front objective domain.
contrast existing approaches, propose dynamic sharing method adaptively
computes sharing distance share uniformly distribute individuals along Pareto-optimal
front generation. requires prior knowledge trade-off surface. Intuitively,
trade-offs m-objective optimization problem form (m-1) dimensional
hyper-volume (Tan et al. 1999), approximated hyper-volume Vpop(n)
hyper-sphere given by,

V pop

(n)

=

(n)


2
1

!
2

( 1) / 2

1

(9)

(n ) diameter hyper-sphere generation n. Note computation
diameter (n ) depends curvature trade-off curve formed non-dominated
individuals objective space. two-objective optimization problem, diameter (n )
equal interpolated distance trade-off curve covered non-dominated individuals
shown Figure 4. Although computation (n ) accurately represents interpolated
curvature non-dominated individuals distribution complex, estimated
average distance shortest longest possible diameter given dmin(n) dmax(n)
respectively (Tan et al. 1999). Let Fx Fy denote objective function two furthest
individuals population. dmin(n) equal minimum length Fx Fy,
dmax(n) estimated d1(n) + d2(n) shown Figure 4.
procedure extended multi-dimensional objective space. achieve
uniformly distributed population along trade-off set, sharing distance share(n) could
computed half distance individual (m-1)-dimensional hyper-volume
Vpop(n) covered population size N generation n,
N

( 1) / 2
1

!
2

(n)
)
( share

1

(n)
= V pop

(10)

Substituting Eq. 9 Eq. 10 gives sharing distance share(n) generation n term
diameter (n ) population size N given
(n)
share
= N 1 /(1 )

(n)
2

(11)

Clearly, Eq. 11 provides simple computation share capable distributing
population evenly along Pareto front, without need prior knowledge usually
193

fiTAN, KHOR, LEE, & SATHIKANNAN

unknown fitness landscape. Moreover, adopting computation sharing distance
dynamically based upon population distribution generation appropriate
effective method off-line estimation pre-assumed trade-off surface employed
existing sharing methods, since trade-off surface may changed time along
evolution whenever goal setting altered.
f2

Fx

dmin(n)
(n)

Discovered
trade-off curve

d1 (n)
Fy

d2 (n)

f1

Figure 4: Diameter (n ) Trade-off Curve
3.2 MOEA Program Flowchart

overall program flowchart papers multi-objective evolutionary algorithm (MOEA)
illustrated Figure 5. beginning evolution, population candidate solutions
initialized evaluated according vector objective functions. Based upon user-defined
specifications, goals, constraints, priorities logical operations, evaluated individuals
ranked according goal-sequence domination scheme (described Section 2) order
evolve search towards global trade-off surface. resulted rank values
refined dynamic sharing scheme (described Section 3.1) order distribute
non-dominated individuals uniformly along discovered Pareto-optimal front. stopping
criterion met, individuals undergo series genetic operations detailed
within genetic operations Figure 6. Here, simple genetic operations consisting
tournament selection (Tan et al. 1999), simple crossover mating restriction selects
individuals within sharing distance mating (Fonseca & Fleming, 1998) well simple
mutation performed reproduce offspring next generation.
genetic operations, newly evolved population evaluated combined
non-dominated individuals preserved previous generation. combined population
subjected domination comparison scheme pruned desired population size
according Switching Preserved Strategy (SPS) (Tan et al. 1999). maintains set
stable well-distributed non-dominated individuals along Pareto-optimal front. SPS,
number non-dominated individuals combined population less equal
desired population size, extra individuals removed according rank values order
promote stability evolutionary search towards final trade-offs. Otherwise,
194

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

non-dominated individuals high niched count value discarded order distribute
individuals uniformly along discovered Pareto-optimal front. process, remaining
individuals allowed survive next generation evolutionary cycle repeated
stopping criterion met.

P opulation initialization
Function evaluation
om ination com parison

es


stopping criterion
et?

non-dominated individuals

Final
population


G enetic operations
Function evaluation
evolved
population



new population

ynam ic sharing

com bined
population

om ination com parison

Size(nondom )
> popsize?



Filtering - based
P areto ranked cost

es
ynam ic sharing

Filtering - based
shared costs

Figure 5: Program Architecture MOEA
Genetic Operations MOEA:
Let,
pop(n) = population current generation n
Step 1) Perform tournament selection select individuals pop(n). selected population
called selpop(n).
Step 2) Perform simple crossover mating restriction selpop(n) using dynamic sharing
distance Step 1. resulted population called crosspop(n).
Step 3) Perform simple mutation crosspop(n). resulted population called evolpop(n).
Figure 6: Detailed procedure within box genetic operations Figure 5

195

fiTAN, KHOR, LEE, & SATHIKANNAN

4. Validation Results Benchmark Problems
section validates proposed algorithm two ways. first kind validation (presented
Section 4.1) illustrates proposed features, including goal-sequence domination
scheme, hard/soft goal priority specifications, logical operations among multiple goals
dynamic sharing, enhances performance MOEA MO optimization. shown Section
4.2, second type validation compares performance proposed MOEA various
evolutionary algorithms based upon benchmark problem. Various performance measures used
comparison results discussed.
4.1 Validation Proposed Features MOEA

section, various proposed features MOEA examined usefulness MO
optimization. study adopts simple two-objective minimization problem (Fonseca &
Fleming, 1993) allows easy visual observation optimization performance. function
large non-linear trade-off curve, challenges algorithms ability find
maintain entire Pareto-optimal front uniformly. two-objective functions, f1 f2,
minimized given
8
1

f1 ( x1 ,..., x8 ) = 1 exp xi
=1
8



2






2
8
1

f 2 ( x1 ,..., x8 ) = 1 exp xi +
=1
8


(12)

where, 2 xi < 2, = 1,2,...,8 . trade-off line shown curve Figure 7,
shaded region represents unfeasible area objective domain.

f

2

Trade-off
Curve

Unfeasible
Region

f

1

Figure 7: Pareto-optimal Front Objective Domain
196

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

simulations run 70 generations population size 100. Standard mutation
probability 0.01 standard two-point crossover probability 0.7 used. study
merit dynamic sharing scheme MOEA proposed Section 3.1, 4 different types
simulations performed. first type without fitness sharing. second third
employ fixed sharing distance 0.01 0.1, respectively. fourth uses dynamic sharing
scheme require predefined sharing distance setting. Figure 8 illustrates
respective population distribution objective domain end evolution.
observed four simulations able discover final trade-off,
performance difference terms closeness uniformity population distribution
along trade-off curve.
MOEA without fitness sharing shown Figure 8a, population tends converge
arbitrary part trade-off curve. agrees findings Fonseca Fleming,
(1993). MOEA fitness sharing, shown Figures 8b 8c, population
distributed along trade-off curve rather well, although sharing distance 0.01 provides
uniform distribution 0.1. indicates although fitness sharing contributes
population diversity distribution along trade-off curve, sharing distance
chosen carefully order ensure uniformity population distribution. often
involves tedious trial-and-error procedures order guess appropriate sharing distance,
since problem dependent based upon size discovered trade-offs well
number non-dominated individuals. difficulties solved proposed dynamic
sharing scheme, ability automatically adapt sharing distance along
evolution without need predefined parameter, shown Figure 8d.

(b) Sharing distance = 0.01

(a) sharing

197

fiTAN, KHOR, LEE, & SATHIKANNAN

(c) Sharing distance = 0.1
(d) Dynamic sharing
Figure 8: Performance Validation Dynamic Sharing Scheme MOEA

f2

f2

validate contribution switching preserved strategy (SPS) MOEA,
simulation repeated different scenarios settings. Figure 9a depicts simulation
result without implementation SPS, evolution faces difficulty converging
trade-off curve. solid dots represent non-dominated individuals empty circles
represent dominated individuals. seen, final population crowded
non-dominated individuals distributed distance away trade-off curve.
Figure 9b shows simulation result MOEA SPS filtering solely based upon
Pareto domination. final population managed converge Pareto-optimal front.
However, non-dominated individuals equally distributed diversity
population poor: concentrate portion entire trade-off curve (c.f. Figures 8d,
9b). results clearly show SPS MOEA necessary order achieve good stability
diversity population converging towards complete set trade-offs.

Unfeasible
region

Unfeasible
region

f1

f1

(b) SPS solely based Pareto ranked cost
(a) Without SPS
Figure 9: Performance Validation SPS MOEA

198

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

f2

f2

proposed goal-sequence domination scheme validated problems different
goal settings, including feasible extreme goal setting (0.98, 0.2) unfeasible goal
setting (0.7, 0.4) shown Figures 10 11, respectively. desired, population seen
concentrate preferred region trade-off curve end evolution, regardless
unattainable extreme goal settings. shown Figures 10 11, MOEA capable
uniformly distributing non-dominated individuals along trade-offs size resulting
different goal settings, help dynamic sharing scheme automatically computes
suitable sharing distance optimal population distribution generation.

f1

f1

Figure 10: Feasible Extreme Goal Setting

Figure 11: Unfeasible Goal Setting

Figure 12 shows trace sharing distance evolution. thin thick lines
represent average sharing distance without goal setting (see Figure 8d corresponding
Pareto-front) goal setting (0.7, 0.4) (see Figure 11 corresponding
Pareto-front), respectively. Generally, MO optimization without goal setting initially small
size discovered Pareto-front, subsequently grows along evolution approach
cover entire trade-off region end evolution. behavior explained Figure 12
sharing distance increases asymptotically along evolution steady value
0.0138 reached. noted value close fixed sharing distance 0.01
Figure 8b, carefully chosen trial-and-error procedures. case MOEA
goal setting (0.7, 0.4), sharing distance increases initially subsequently decreases
0.0025 along evolution, lower value 0.0138 (without goal setting).
reason concentrated trade-off region within goal setting smaller entire
trade-off region (without goal setting), hence results smaller distance uniform sharing
non-dominated individuals. experiments show proposed dynamic sharing scheme
effectively auto-adapt sharing distance arrive appropriate value uniform
population distribution along discovered trade-off region different sizes, without need
priori parameter setting.

199

fiTAN, KHOR, LEE, & SATHIKANNAN

Figure 12: Trace Dynamic Sharing Distance Along Evolution

Non-dominated
individual

f2

f2

Figures 13 14 show MOEA simulation results case infeasible goal setting
soft hard priorities, respectively. figures, diamonds represent goals, small circles
represent non-dominated individuals solid dots represent dominated individuals. soft
priority setting Figure 13, goals treated first priority followed objective component
f1 second priority, i.e., Pg = [1, 1] Pf = [2, 0]. seen, provides distributive
optimization approach goals pushing population towards objective component
f1 higher priority, taking goal vector consideration (c.f. Figures 3a, 13b).
contrast, Figure 14 shows minimization results hard priority setting priority f1
higher f2, i.e., Pg = [1, 2] Pf = [0, 0]. Unlike soft priority optimization, hard priority
minimizes objective f1 relevant goal component g1 = 0.5 satisfied
attaining objective component f2 second goal component g2 = 0.5, shown
Figure 14 (c.f. Figures 3b, 14b). seen, objective values hard priority settings
better higher priority worse lower priority, compared solutions obtained
soft priority optimization (c.f. Figures 13b, 14b).

Non-dominated
individual

ff1

f1

(a) generation 5
(b) generation 70
Figure 13: MOEA Optimization Unfeasible Goal Setting: f1 Soft Priority Higher f2
200

fiNon-dominated
individual

f2

f2

EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

Non-dominated
individual

ff11

f1

(a) generation 5
(b) generation 70
Figure 14: MOEA Optimization Unfeasible Goal Setting: f1 Hard Priority Higher f2

ff22

Figure 15 shows MOEA minimization result f1 hard constraint. population
continuously evolves towards minimizing f2 hard constraint f1 satisfied.
general, objective components hard constraints may assigned hard priorities order
meet hard constraints minimizing objective components.

Non-dominated
individuals

ff11

Figure 15: MOEA Minimization Hard Constraint f1
Figures 16 17 show MO optimization results include multiple goal settings specified
logical ( ) ( ) connectives, respectively. operation shown
Figure 16, population automatically distributed equally spread different
concentrated trade-off regions satisfy goal settings separately, regardless overlapping
feasibility goals. proposed dynamic sharing scheme, sub-population size
goal general based upon relative size concentrated trade-off surface goal,
201

fiTAN, KHOR, LEE, & SATHIKANNAN

thus individuals capable equally distributing along different concentrated
trade-off regions. operation illustrated Figure 17, whole population
evolves towards minimizing goals G1, G2 G3 simultaneously. result, individuals
equally distributed common concentrated trade-off surface formed three goals,
desired.
Pareto optimality observation

GG1 1

G
G22
f2

G3
G
3
GG4 4

f1

Figure 16: MOEA Minimization (G1 G2 G3 G4)
Pareto optimality observation

GG11

G22

f2

G
G33

f1

Figure 17: MOEA Minimization (G1 G2 G3)
4.2 Performance Comparisons MOEA

section studies compares performance proposed MOEA
multi-objective evolutionary optimization methods based upon benchmark MO optimization
problem. comprehensive comparison, various performance measures used
comparison results discussed section.
4.2.1 Test Problem
202

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

test problem used performance comparisons two-objective minimization problem
(Deb, 1999). problem chosen discontinuous Pareto-front challenges
evolutionary algorithms ability find maintain Pareto-optimal solutions
discontinuously spread search space. problem involves minimizing objective
functions f1 f2 given below,

f1 ( x1 ) = x1
g ( x2 ,..., x10 ) = 1 + 10
h( f 1 , g ) = 1 ( f 1 g )

0.25

(13a)

10
= 2 xi
,
10 1

( f1 g )sin (10f1 )

f 2 ( x1 ) = g ( x2 ,..., x10 )h( f1 , g )

(13b)
(13c)

(13d)

variables varied [0, 1] true Pareto-optimal solutions constituted xi = 0
= 2, , 10 discontinuous values x1 range [0, 1] (Deb, 1999). Figure 18
depicts discontinuous Pareto-optimal front (in bold). shaded region represents
unfeasible region search space.

Figure 18: Pareto-optimal Front Objective Domain
4.2.2 Current Evolutionary MO Optimization Methods

Besides MOEA, five well-known multi-objective evolutionary optimization methods used
comparison. approaches differ working principles
mechanisms widely cited applied real-world applications. algorithms
summarized readers may refer respective references detailed information.
(i) Fonseca Flemings Genetic Algorithm (FFGA): MO optimization, Fonseca
Fleming (1993) proposed multi-objective genetic algorithm (MOGA) Pareto-based ranking
scheme, rank individual based number individuals current

203

fiTAN, KHOR, LEE, & SATHIKANNAN

population dominate it. algorithm incorporated fitness sharing
mating restriction distribute population uniformly along Pareto-optimal front.
(ii) Niched Pareto Genetic Algorithm (NPGA): method NPGA (Horn & Nafpliotis, 1993)
works Pareto-dominance-based tournament selection scheme handle multiple objectives
simultaneously. reduce computational effort, pre-specified number individuals
picked comparison set help determine dominance. competitors end tie,
winner decided fitness sharing (Goldberg Richardson, 1987).
(iii) Strength Pareto Evolutionary Algorithm (SPEA): main features SPEA (Zitzler &
Thiele, 1999) usage two populations (P P) clustering. general,
non-dominated individual archived P dominated individual dominated
members P removed. number individuals P exceeds maximum value,
clustering adopted remove extra individuals P. Tournament selection applied
reproduce individuals P + P evolution proceeds next generation.
(iv) Non-Generational Genetic Algorithm (NGGA): NGGA (Borges & Barbosa, 2000), cost
function individual non-linear function domination measure density measure
individual. Instead evolving whole population iteration, pair parents
selected reproduce two offsprings. offspring replace worst individual population
offspring lower cost function worst individual.
(v) Murata Ishibuchis Genetic Algorithm (MIGA): Unlike evolutionary
optimization methods, MIGA (Murata & Ishibuchi, 1996) applies method weighted-sum
construct fitness individual population. keep diversity population
along Pareto-optimal front, weights randomly specified pair parent solutions
selected current population generating offspring.
4.2.3 Performance Measures

section considers three different performance measures complementary
other: Size space covered (SSC), uniform distribution (UD) index non-dominated individuals
number function evaluation (Neval).
(i) Size Space Covered (SSC): measure proposed Zitzler Thiele (1999)
measure quantify overall size phenotype space covered (SSC) population. general,
higher value SSC, larger space covered population hence better
optimization result.
(ii) Uniform Distribution (UD) Non-dominated Population: Besides size space covered
population, essential examine ability evolutionary optimization
distribute non-dominated individuals uniformly possible along discovered
204

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

Pareto-optimal front, unless prohibited geometry Pareto front. achieve
smooth transition one Pareto-optimal solution neighbors, thus facilitating
decision-maker choosing his/her final solution. Mathematically, UD(X') given set
non-dominated individuals X' population X, X' X, defined (Tan et al. 2001a),
UD(X' ) =

1
1 + nc

(14)

Snc standard deviation niche count overall set non-dominated individuals X'.
seen larger value UD(X) indicates uniform distribution vice versa.
(iii) Number Function Evaluation (Neval): computational effort required solve
optimization problem often important issue, especially limited computing
resources available. case fixed period CPU time allocated CPU time
function evaluation assumed equal, function evaluations
performed optimization indirectly indicates less additional computational effort required
algorithm.
4.2.4 Simulation Settings Comparison Results
decimal coding scheme (Tan et al. 1999) applied evolutionary methods studied
comparison, parameter coded 3-digit decimals parameters
concatenated together form chromosome. cases, two-point crossover probability
0.07 standard mutation probability 0.01 used. reproduction scheme applied
according method used original literature algorithm comparison.
population size 100 used FFGA, NPGA, NGGA MOEA, require single
population evolution. SPEA MIGA assigned population size 30 70
external/archive evolving population size, respectively, form overall population size
100. approaches comparison implemented common sub-functions
using programming language Matlab (The Math Works, 1998) Intel Pentium II
450 MHz computer. simulation terminated automatically fixed simulation period
180 seconds reached. simulation period determined, preliminary runs,
way different performance among algorithms could observed. avoid random effects,
30 independent simulation runs, randomly initialized population, performed
algorithm performance distributions visualized box plot format (Chambers
et al. 1983; Zitzler & Thiele, 1999).
Figure 19 displays performance SSC (size space covered) algorithm. general,
SPEA MOEA produce relatively high value SSC indicating ability
distributed discovered Pareto-optimal front and/or produce non-dominated solutions
nearer global trade-offs. observed that, compared others, FFGA,
SPEA MOEA consistent performance SSC. performance UD
(uniform distribution) algorithms summarized Figure 20. general, UD
distributions mostly overlapping thus little evidence draw
205

fiTAN, KHOR, LEE, & SATHIKANNAN

strong conclusion. However, average performance concerned (see bold horizontal line
box plots), SPEA, MIGA MOEA outperform others slightly consistent
terms measure UD. Figure 21 shows distribution Neval (number function
evaluation) performed algorithm specified time. function evaluations fixed
CPU time indirectly indicates less CPU time required algorithm. Intuitively,
means less computational efforts required algorithm find trade-offs. shown
Figure 21, MIGA requires least algorithm effort performances FFGA, NPGA
MOEA moderate terms Neval. observed SPEA NGGA suitable
problems time-consuming function evaluations: effects algorithm effort become less
significant problems. summary, results show MOEA requires moderate
computational effort exhibits relatively good performance terms SSC UD test
problem, compared MO evolutionary optimization methods study.

Figure 19: Box Plot SSC

Figure 20: Box Plot UD

206

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

Figure 21: Box Plot Neval
Figure 22 shows distribution non-dominated individuals objective domain,
range axis identical range shown Figure 18. algorithm,
distribution best selected, among 30 independent runs, respect measure SSC.
seen Figure 22 MOEA benefits evolving non-dominated individuals
methods. MOEAs individuals better distributed within trade-off region.

FFGA

NPGA

SPEA

NGGA

MIGA

MOEA

Figure 22: Best Selected Distribution Non-dominated Individuals Algorithm
Respect Measure SSC

207

fiTAN, KHOR, LEE, & SATHIKANNAN

5. Application Practical Servo Control System Design
5.1 Hard Disk Drive Servo System
typical plant model hard disk drive (HDD) servo system includes driver (power amplifier),
VCM (Voice Coil Motor) rotary actuator driven VCM. Figure 23 (Goh et al.
2001) shows basic schematic diagram head disk assembly (HDA), several rotating
disks stacked spindle motor shaft.
VOICE COIL MOTOR
ACTUATOR

DISK

ARM

SUSPENSION
RECORDING HEAD

DATA TRACK

Figure 23: HDD Single VCM Actuator Servo System
dynamics ideal VCM actuator often formulated second-order state-space model
(Weerasooriya, 1996),

y& 0 K 0
+ u
=
v& 0 0 v K v

(15)

u actuator input (in volts), v position (in tracks) velocity
R/W head, Kv acceleration constant Ky position measurement gain,
K = K Kt current-force conversion coefficient mass
VCM actuator. discrete-time HDD plant model used evolutionary servo controller
design study given (Tan et al. 2000),
1 1.664
1.384
x(k ) +


1.664 u
1
0



x(k + 1) =

(16)

5.2 Evolutionary HDD Controller Design Implementation

two-degree-of-freedom (2DOF) control structure adopted read/write head servo system
shown Figure 24. simplicity easy implementation, simple first-order discrete-time

208

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

controller sampling frequency 4 kHz used feedforward feedback controllers,
form
z + 1

K p = K f
z + 2

z + fb1

K = K b
z + fb2

(17)

respectively. control objective tracking HDD follow destination track
minimum tracking error. Note time domain performance specifications
considered paper, design task search set optimal controller parameters
{Kf, Kb, ff1, ff2, fb1, fb2} HDD servo system meets design requirements.
requirements overshoots undershoots step response kept less 5%
since head read write within 5% target; 5% settling time step
response less 2 milliseconds settle steady-state quickly possible
(Goh et al. 2001). Besides performance specifications, system subject hard
constraint actuator saturation, i.e., control input exceed 2 volts due
physical constraint VCM actuator.

r

Kp

u

+-

VCM

Feedforward
controller



Plant
Ks
Feedback controller

Figure 24: Two Degree-of-freedom Servo Control System
multi-objective evolutionary algorithm (MOEA) proposed paper embedded
powerful GUI-based MOEA toolbox (Tan et al. 2001b) ease-of-use
straightforward application practical problems. toolbox developed Matlab (The
Math Works, 1998) programming environment, allows users make use versatile
Matlab functions useful toolboxes Simulink (The Math Works, 1999). allows
trade-off scenario MO design optimization examined effectively, aiding
decision-making global solution best meets design specifications. addition,
toolbox equipped powerful graphical user interface (GUI) ready immediate use
without much knowledge evolutionary computing programming Matlab. file handling
capability saving simulation results model files Mat-file format Matlab
text-file format software packages Microsoft Excel available toolbox.
GUI window MOEA toolbox, time domain design specifications conveniently set
depicted Figure 25, Tr, OS, Ts, SSE, u ue represents rise time, overshoot,
settling time, steady-state error, control input change control input, respectively.

209

fiTAN, KHOR, LEE, & SATHIKANNAN

Figure 25: MOEA GUI Window Settings Design Specifications
simulation adopts generation population size 200, design specifications
listed Figure 25 successfully satisfied end evolution. design trade-off
graph shown Figure 26, line representing solution found. x-axis shows
design specifications y-axis shows normalized cost objective. Clearly,
trade-offs adjacent specifications result crossing lines (e.g.,
steady-state error (SSE) control effort (u)), whereas concurrent lines cross
indicating specifications compete one another (e.g., overshoots (OS)
settling time (Ts)).

Figure 26: Trade-off Graph HDD Servo Control System Design

210

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

closed-loop step response overall system arbitrary selected set MOEA
designed 2DOF controller parameters given {Kf, Kb, ff1, ff2, fb1, fb2} = {0.029695, -0.58127,
0.90279, -0.3946, -0.70592, 0.83152} shown Figure 27. sampling frequency 4 kHz,
time domain closed-loop performance evolutionary designed controller
compared manually designed discrete-time PID controller given Eq. 18 (Goh et al.
2001) well Robust Perfect Tracking (RPT) controller (Goh et al. 2001) given Eq.
19,
0.13 z 2 0.23 z + 0.1
u=
(r )
(18)
z 2 1.25 z + 0.25
x(k + 1) = 0.04 x(k ) + 15179r (k ) 453681y (k )

(19)

u (k ) = 3.43 10 7 x(k ) + 0.04r (k ) 0.18 ( k )

seen Figure 27 evolutionary designed 2DOF controller outperformed
PID RPT controllers, fastest rise time, smallest overshoots shortest
settling time closed-loop response. control performance excellent destination
track crossover occurs approximately 1.8 milliseconds.
1.8
1 : MOEA Based 2DOF Controller

1.6

2

2 : PID Controller
3 : RPT Controller

Head Position (Tracks)

1.4
1.2
3

1

1

0.8
0.6
0.4
0.2
0

0

0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009

0.01

Time Seconds

Figure 27: Closed-loop Servo System Responses Evolutionary 2DOF, RPT PID
Controllers
performance evolutionary 2DOF servo control system verified tested
physical 3.5-inch HDD TMS320 digital signal processor (DSP) sampling rate
4 kHz. R/W head position measured using laser doppler vibrometer (LDV)
resolution used 1 m/volt. Real-time implementation result evolutionary HDD servo
control system given Figure 28, consistent simulated step response Figure
27, shows excellent closed-loop performance.

211

fiTAN, KHOR, LEE, & SATHIKANNAN

Output Response
1.4

Tracks ( Actuator Output )

1.2

1

0.8

0.6

0.4

0.2

0

0

0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009
Time Seconds

0.01

Figure 28: Real-time Implementation Response Evolutionary 2DOF Servo System

6. Conclusions
paper presented multi-objective evolutionary algorithm (MOEA) new
goal-sequence domination scheme allow advanced specifications hard/soft priorities
constraints incorporated better decision support multi-objective optimization.
addition, dynamic fitness sharing scheme simple computation adaptively based upon
on-line population distribution generation proposed. dynamic sharing
approach avoids need priori parameter settings user knowledge usually unknown
trade-off surface often required existing methods. effectiveness proposed features
MOEA demonstrated showing features contains specific merits
usage benefit performance MOEA. comparison existing evolutionary
approaches, simulation results show MOEA performed well diversity
evolutionary search uniform distribution non-dominated individuals along final
trade-offs, without significant computational effort. MOEA applied practical
engineering design problem HDD servo control system. Simulation real-time
implementation results show evolutionary designed servo system provides excellent
closed-loop transient tracking performance.

Acknowledgements
authors wish thank Andrew Moore anonymous reviewers valuable
comments helpful suggestions greatly improved paper quality.

212

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

References
Borges, C. C. H., & Barbosa, H. J.C. (2000). non-generational genetic algorithm
multiobjective optimization. IEEE Congress Evolutionary Computation, 1, 172-179.
Chambers, J. M., Cleveland, W. S., Kleiner, B., & Turkey, P. A. (1983). Graphical Methods
Data Analysis, Wadsworth & Brooks/Cole, Pacific CA.
Coello Coello, C. A. (1996). Empirical Study Evolutionary Techniques Multiobjective
Optimization Engineering Design, Ph.D. Thesis, Dept. Computer Science, Tulane University,
New Orleans, LA.
Coello Coello, C. A. (1999). Comprehensive Survey Evolutionary-Based Multiobjective
Optimization Techniques. Knowledge Information Systems, 1(3), 269-308.
Deb, K. (1999). Evolutionary algorithms multi-criterion optimization engineering design.
Miettinen. Evolutionary Algorithms Engineering Computer science: Recent Advances
Genetic Algorithms, Evolution Strategies, Evolutionary Programming, Genetic Programming,
Industrial Applications, Wiley, New York, 135-161.
Deb, K. (2001). Multi-objective Optimization using Evolutionary Algorithms. John Wiley & Sons,
London.
Fonseca, C. M. (1995). Multiobjective Genetic Algorithms Application Control Engineering
Problems. Ph.D. Thesis, Dept. Automatic Control Systems Engineering, University
Sheffield, UK.
Fonseca, C. M., & Fleming, P. J. (1993). Genetic algorithm multiobjective optimization,
formulation, discussion generalization. (Forrest, 1993), 416-423.
Fonseca, C. M. & Fleming, P. J., (1998). Multiobjective optimization multiple constraint
handling evolutionary algorithms Part I: unified formulation. IEEE Trans. System, Man,
Cybernetics-Part A: System Humans, 28(1), 26-37.
Goh, T. B., Li, Z. M., Chen, B. M., Lee, T. H., & Huang, T., (2001). Design implementation
hard disk drive servo system using robust perfect tracking approach. IEEE Trans. Control
Systems Technology, 9(2), 221-233.
Goldberg, D. E., & Richardson, J. (1987). Genetic algorithms sharing multimodal function
optimization. Proc. 2nd Int. Conf. Genetic Algorithms, 41-49.
Goldberg, D. E. (1989). Genetic Algorithms Search, Optimization Machine Learning.
Addison-Wesley, Reading, Massachusetts.
Grace, A. (1992). Optimisation Toolbox Users Guide, MathWorks, Inc.
Holland, J. H. (1975). Adaptation Natural Artificial Systems. University Michigan, Ann
Harbor.

213

fiTAN, KHOR, LEE, & SATHIKANNAN

Horn, J., & Nafpliotis, N. (1993). Multiobjective Optimization Using Niche Pareto Genetic
Algorithm. IlliGAL Report 93005, University Illinois, Urbana, Illinois, USA.
Luus, R., Hartig, F. & Keil, F. J., (1995). Optimal drug scheduling cancer chemotherapy
direct search optimization. Hungarian Journal Industrial Chemistry, 23, 55-58.
Marcu, T. (1997). Multiobjective evolutionary approach pattern recognition robust
diagnosis process faults. Proc. IFAC Fault Detection, Supervision Safety Technical
Process, UK, 1183-1188.
Michalewicz, Z., & Schoenauer, M., (1996). Evolutionary algorithms constrained parameter
optimization problems. Evolutionary Computation, 4(1), 1-32.
Miller, B. L., & Shaw, M. J. (1996). Genetic algorithms dynamic niche sharing multimodal
function optimization. IEEE Conf. Evolutionary Computation, Japan, 786-791.
Murata, T., & Ishibuchi, H., (1996). Multi-objective genetic algorithm applications
flowshop scheduling. Int. Journal Computers Engineering, 957-968.
Osyczka, A. (1984). Multicriterion Optimisation Engineering. Ellis Horwood, Chichester.
Schaffer, J. D. (1985). Multiple-objective optimization using genetic algorithm. Proc. first Int.
Conf. Genetic Algorithms, 93-100.
Tan, K. C., Lee, T. H., & Khor, E. F. (1999). Evolutionary algorithms goal priority
information multi-objective optimization. IEEE Congress Evolutionary Computation, 1,
106-113.
Tan, K. C., Sathikannan, R., Tan, W. W., Loh, A. P., Lee, T. H., & Mamun, A. Al. (2000)
Evolutionary Design Real-Time Implementation Hard Disk Drive Servo Control System.
Int. Conf. Control 2000, University Cambridge, UK, Section 6C.
Tan, K. C., Lee, T. H., & Khor, E. F., (2001a). Evolutionary algorithms multi-objective
optimization: Performance assessments comparisons. IEEE Congress Evolutionary
Computation, 2, 979-986.
Tan, K. C., Lee, T. H., Khoo, D., & Khor, E. F., (2001b). multi-objective evolutionary algorithm
toolbox computer-aided multi-objective optimization. IEEE Trans. Systems, Man
Cybernetics - Part B: Cybernetics, 31(4), 537-556.
Math Works, Inc. (1998). Using MATLAB, Version 5.
Math Works, Inc. (1999). Simulink: User's Guild, Version 3.
Van Veldhuizen, D. A., & Lamont, G. B. (1998). Multiobjective evolutionary algorithm research:
history analysis. Technical Report TR-98-03, Dept. Electrical Computer Eng.,
Graduate School Eng., Air Force Institute Technology, Wright-Patterson AFB, Ohio.

214

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

Weerasooriya, S. (1996). Basic Servo Problem: Technical Report. Data Storage Institute,
National University Singapore, Singapore.
Zitzler, E., & Thiele, L., (1999). Multiobjective evolutionary algorithms: comparative case
study strength Pareto approach. IEEE Trans. Evolutionary Computation, 3(4), 257-271.

215


