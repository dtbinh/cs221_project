Journal Artificial Intelligence Research 18 (2003) 217-261

Submitted 8/02; published 3/03

Interactive Execution Monitoring Agent Teams
David E. Wilkins
Thomas J. Lee
Pauline Berry

WILKINS @ AI . SRI . COM
TOMLEE @ AI . SRI . COM
BERRY @ AI . SRI . COM

Artificial Intelligence Center, SRI International
333 Ravenswood Ave., Menlo Park, CA 94025 USA

Abstract
increasing need automated support humans monitoring activity
distributed teams cooperating agents, human machine. characterize domainindependent challenges posed problem, describe properties domains influence
challenges solutions. concentrate dynamic, data-rich domains humans ultimately responsible team behavior. Thus, automated aid interactively
support effective timely decision making human. present domain-independent
categorization types alerts plan-based monitoring system might issue user,
type generally requires different monitoring techniques. describe monitoring framework
integrating many domain-specific task-specific monitoring techniques using
concept value alert avoid operator overload.
use framework describe execution monitoring approach used implement Execution Assistants (EAs) two different dynamic, data-rich, real-world domains assist
human monitoring team behavior. One domain (Army small unit operations) hundreds
mobile, geographically distributed agents, combination humans, robots, vehicles.
domain (teams unmanned ground air vehicles) handful cooperating robots.
domains involve unpredictable adversaries vicinity. approach customizes monitoring behavior specific task, plan, situation, well user preferences.
EAs alert human controller reported events threaten plan execution physically threaten
team members. Alerts generated timely manner without inundating user
many alerts (less 10% alerts unwanted, judged domain experts).

1. Introduction
automation reliable, high-bandwidth communication networks become common, humans increasingly responsible monitoring controlling activity distributed teams
cooperating agents, human machine. control decisions many realistic domains
complex, require human experience judgment. vision human decision makers
able perform important tasks continuously monitoring incoming information
relying automated execution aid alert significant new information warrants
attention. primarily interested domains requiring human control describe
two domains. However, majority techniques analysis apply completely
automated execution monitoring. fact, one domains interact human
controller autonomously adjust robot behavior plans.
rapidly make effective control decisions distributed agent teams, human needs automated support, several reasons. First, inexpensive sensors reliable, high-bandwidth communication networks provide large volumes pertinent data arriving sensors, team members,

c
2003
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiW ILKINS , L EE , & B ERRY

sources. Without automated support, human cannot cope volume incoming
information. Second, plans coordinate activity several team members, many several
hundred first domain, become complex monitor without automated help. Third,
addressing domains dynamic, sometimes requiring responses seconds less.
Fourth, automated team members (robots) complex, different failure modes recovery procedures, automated support controlling often essential. challenges
magnified tempo decision cycle increases user becomes stressed. Thus,
domains properties require interactive, automated assistant support humans
monitoring incoming information controlling agent teams.
concentrate dynamic, data-rich domains humans ultimately responsible
team behavior. Realistic domains often adversaries overcome. may range
fairly benign forces nature introduce uncertainty, intelligent adversaries trying
actively thwart plans. automated execution assistant interactively support effective
timely decision making human, interact human take advantage knowledge
human possesses explicitly modeled machine. Ideally, execution assistant
would allow human user to, among things:
Guide system minimal effort
Focus external events, assuming system alert user human attention
desirable
Understand, evaluate, modify plans/actions
Understand action decision taken/recommended/rejected
system
constant multimodal feedback
Recommend actions decisions violate constraints warranted
One key idea rich plan representations allow execution aid share context users,
understand semantics plans requests. Understanding plan key helping
user deal possible information glut created advanced information systems.
execution aid uses plan filter, interpret, react large volume incoming information,
alert user appropriately events threaten plan users physical existence.
user develops trust execution aid, reduction need human
monitoring display information system, simultaneously increasing amount
relevant information monitored aid analyzes every piece incoming data. Relying
alerts automated aid allows human pay attention important tasks
monitoring incoming data, attending display alerted execution aid.
next section, characterize domain-independent challenges posed problem,
concentrating unique interactive execution aids dynamic domains distributed
teams cooperating agents. Then, describe properties various domains influence
challenges solutions. Section 4, present domain-independent categorization
types alerts plan-based monitoring system might issue user. Next, describe concept
value information alerts key reducing unwanted alerts (alarms). Sections 6
218

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

7 describe Execution Assistants implemented small unit operations robotics
domains, respectively. Sections 6.8 7.5 contain results evaluations performed
domain. Finally, discuss related work present conclusions.

2. Interactive Monitoring Challenges
great interest plan generation algorithms, less work using plans dynamically control execution. Much execution monitoring work describes monitors specific domains,
first characterize domain-independent challenges monitoring agent teams.
several universal challenges execution monitoring particular dynamic, data-rich domains interactive monitoring. issues part monitoring
ontology addressed EAs, stress discussion
discussed elsewhere (Kaminka, Pynadath, & Tambe, 2001; Jonsson, Morris, Muscettola, & Rajan,
2000; Muscettola, Nayak, Pell, & Williams, 1998; Myers, 1999; Wilkins, Myers, Lowrance, &
Wesley, 1995; Coiera, 1993; Durfee, Huber, Kurnow, & Lee, 1997). issues include following:
Sensitivity monitor ability detect problems meet requirements. system
must remain reactive incoming data performing monitoring tasks.
Temporal reasoning temporal sensitivity. Execution takes place time plans specify future actions, thus making temporal reasoning central.
Concurrent temporal processes. Multiple tasks agents may executing concurrently.
Synchronization agents. execution assistant must get right information
right team members right time support cooperative activity specified plan.
domains, may require plan recognition team members (Kaminka
et al., 2001).
False redundant alarms. Unwanted alarms ubiquitous data-rich domains
medicine (Koski, Makivirta, Sukuvaara, & Kari, 1990; Tsien, 1997) domains described paper.
Combining event-driven goal-driven behavior. execution assistant must respond
unfolding events acceptable latency concurrently invoking actions continue execution (perhaps modified) plan satisfy user requests. Goal-driven tasks
include responses events, generating modified, new, contingency plans,
invoking standard operating procedures.
Adversarial reasoning, including plan pattern recognition. Many real-world domains
adversaries activity must closely monitored.
concerned execution monitoring agent teams, team members may
combination humans and/or machines. concentrate challenges unique
interactive execution aids dynamic domains, categorize challenges following
four categories.
Adaptivity. output execution assistant must meet human requirements preferences monitoring behavior, providing high-value alerts suggestions. execution
219

fiW ILKINS , L EE , & B ERRY

monitoring, sensitivity crucial, interactive monitoring sensitivity monitor must
adaptable. addition adapting user preferences, analysis done execution
assistant level autonomy must adjustable operational tempo incoming data rate.
system ideally adapt output users capabilities cognitive load.
Plan situation-specific monitoring. Coordinating activities many teams members
requires plan shared team. assume plans contain partial orders tasks
team member, well necessary coordinating instructions commitments (Grosz &
Kraus, 1999). plan representation encodes expected outcomes (effects) plan
execution, execution aids detect deviations. analysis done execution assistant
suggested responses must depend plan situation effective, events
often cause problem plans others. found monitoring algorithms
must often tailored specific tasks compose plans. facilitate interaction, plan
representations must understandable humans system, although human might
aided multiple plan views internal representation user-friendly interface.
Reactivity. execution monitor must react events uncertainty introduced environment. dynamic, data-rich domains, particular care must taken ensure system
remains reactive high rates incoming information fast decision cycles. Resources
generally available perform desired analyses every input example, projecting
future problems multiple simulation runs searching better plans may computationally
expensive. often obvious boundaries types support execution aid might
provide real-world domain. Therefore, balance must struck capabilities provided resources used. examples show types issues arise practice.
first domain, coarse terrain reasoning used, projections using fine-grained terrain data
computationally expensive. robot domain, adjust time quanta assigned
processes scheduler monitoring processes executed least every second. Finally, domains dangerous intelligent adversaries, reacting detected activity
becomes high priority. considerable research guaranteeing real-time response
(Ash, Gold, Seiver, & Hayes-Roth, 1993; Mouaddib & Zilberstein, 1995), tradeoffs generally different every application usually critical aspect design execution
assistant.
High-value, user-appropriate alerts. Alerting every occurrence monitored condition
possibly problem relatively easy; however, user would quickly ignore assistant
gave many alerts. challenge give false alarms inundate user
unwanted redundant alerts. system must estimate utility information alerts
user, give high-value alerts, present alerts manner appropriate value
users cognitive state. found common challenge avoid cascading alerts events get
progressively away expectations along number dimensions (such time,
space, resource availability). Another challenge discuss depth aggregating
lower-level data (e.g., sensor fusion), reduce number alerts consolidating inputs.
Estimates value alerts used adjust alerting behavior users cognitive load.
Interactive alerting execution naturally leads equally important challenging
topic human directing responses plan modifications. monitoring technologies
used continuous planning frameworks (Wilkins et al., 1995; Myers, 1999), limit
scope paper interactive alerting. briefly mention ongoing research
topic either using plan use conjunction execution aids.
220

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Agent systems interact humans active area research, issues discussed literature (Myers & Morley, 2001; Ferguson & Allen, 1998; Schreckenghost & et al.,
2001). Myers Morley (2001), example, describe Taskable Reactive Agent Communities
(TRAC) framework supports human supervisors directing agent teams. address topics
adjustable agent autonomy, permission requirements, consultation requirements,
ability communicate strategy preferences guidance. TRAC complementary execution
monitoring described paper.
Another active research area fits naturally execution monitoring approach theories collaboration. fact, use SharedPlans theory collaboration (Grosz & Kraus, 1999)
second domain (Ortiz & Hsu, 2002) direct agents conjunction execution monitor. theory models elements working together team well levels partial
information associated states evolving shared plan. Central theory SharedPlans
notion agents committed providing helpful support team members. Within
theory, notion helpful behavior formally defined (Ortiz, 1999). work
collaboration complimentary monitoring approach, discussed detail.

3. Monitoring Approach Determined Domain Features
domain features monitoring challenges concerned common many
domains addition robot teams small unit operations (SUO). example, occur
monitoring spacecraft (Bonasso, Kortenkamp, & Whitney, 1997; Muscettola et al., 1998)
monitoring medicine (Coiera, 1993) ICU patients anesthesia. domains
data rich medical clinicians difficulty using vast amount information
presented current monitoring systems (Weigner & Englund, 1990; Coiera, 1993).
particular, problem flooding human users false redundant alarms ubiquitous
medical monitoring (Koski et al., 1990; Tsien, 1997). One study found 86% alarms
pediatric ICU false alarms (Tsien & Fackler, 1997). False alarms distract humans
important tasks. false alarm rate would likely make monitor useless fast-paced
operations. Research domains concentrated automated monitoring, little
emphasis interactive monitoring.
challenges described previous section apply interactive, dynamic domains, properties individual domains influence solutions. One brief case study shows
features communication system use legacy agents indicate different
monitoring approach two similar problems. Kaminka et al. (2001) address problem similar ours: many geographically distributed team members coordinating plan dynamic
environment. use approach based applying plan-recognition techniques observable actions team members, rather communicating state information among team members,
refer report-based monitoring.
list four problems report-based monitoring (Kaminka et al., 2001): (1) intrusive modifications required legacy agents report state, (2) necessary state information changes
monitoring task, (3) monitored agents communication lines heavy computational bandwidth burdens, (4) assumes completely reliable secure communication
team members. say (1) main concern, (3) next
important.

221

fiW ILKINS , L EE , & B ERRY

Plan constraint violated
Policy constraint violated
New opportunity detected
Adversarial activity detected
Constraint violation, opportunity, adversarial activity projected
Contingency plan suggested
System problem detected
Reporting requirement triggered
Figure 1: Top-level categories alert ontology.

domains, use report-based monitoring. agents already report state
easily modified so, example, attaching Global Positioning (GPS) devices.
monitoring tasks performed using reports already available, although one imagine
adding functionality would change reporting requirements. first domain,
reports distributed Situation Awareness Information Management (SAIM) system
high-bandwidth network. SAIM uses novel peer-to-peer (P2P) dissemination algorithms
forward fusion sensor reports, greatly reducing bandwidth requirements. P2P fault tolerant,
allowing node server. Dissemination based agents current task, geographic
location, relationship hierarchical organization team members.
summary, report-based monitoring works domains rely less unmodifiable legacy agents, reliable communications, enough bandwidth available
network dissemination algorithms. Kaminkas approach provides automated support,
must address problem modeling value information user. Kaminkas
system extended interact humans, believe alert ontology techniques
avoiding operator overload would applicable, whether alerts come sources based planrecognition reports. rely humans ultimately responsible team
behavior, require much state information complete reliability communication.
Unreliable communication degrade monitoring performance, human decision maker
must take missing inputs account making decision. execution assistant monitor
communications alert human possible communications problems.

4. Types Alerts
Alerts used focus users attention aspect situation execution aid
determined high value. discuss problem determining value information
alerts later sections, determines whether alert presented. alert may
indicate response required, may informative. Many different types alerts
given, useful categorize alerts, thus providing beginning reusable, domainindependent ontology execution monitoring.
Figure 1 shows top-level categories alerts identified starting superset categories found useful two domains generalizing cover
broad range domains. assumed execution directed plan shared
team. categories generally require different monitoring techniques different responses
222

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

detected problems. example, adversarial activity could subclass relevant
classes, requires different monitoring techniques. friendly location data precise (within
error GPS) trustworthy, adversarial data comes fusion engines running
data sensor networks. adversarial data highly uncertain, may come significantly different rates, generally different algorithms determining value information,
adversarial entities actively trying thwart plan perhaps trying kill you.
top-level categories ontology generally differ along following dimensions
important monitoring:
Properties data sources (such reliability uncertainty).
Rates incoming data
Method acquiring data (such receiving messages, pulling data databases,
plan recognition)
Monitoring algorithms, including tradeoff complexity analysis reactivity
Desired responses alerts
Value information algorithms
different monitoring techniques category often domain specific, even
task specific cases, adapting monitoring tasks plan executed.
monitoring framework integrates various techniques uses concept value
alert control interaction user.
briefly discuss top-level categories. provided next lower level
ontology space possibilities large, domain-specific concerns important.
example, adversarial alerts could include subclasses fixed mobile adversaries, size
capabilities adversarial team, alliance tightly coordinated adversarial team,
adversarial intent plan, forth. Later paper, describe alerts given
implemented execution assistants (EAs) fit categories.
Plan constraints. Plans provide expectations execution proceed,
category richest set alerts. fairly large hierarchical ontology could produced
describe different types alerts plan constraints. Gil Blythe (1999) present domainindependent ontology representing plans plan evaluations. concept evaluation
ontology could source alert evaluation becomes sufficiently important
user. Plans real-world domains often hierarchical, constraints different levels
layers may violated. may desirable customize alerts based hierarchical level
plan constraint question. indicate range possible alerts category, list
common examples:
coordinating team member (or agent) position late.
effects agents (or team members) actions achieved expected.
team member retracted commitment perform certain task, requiring reallocation
tasks resources.
223

fiW ILKINS , L EE , & B ERRY

Conditions required plan true expected.
Resources used plan available degraded.
Policy constraints. real-world domains persistent constraints policies
rules engagement must violated. could considered part
plan representing maintenance conditions extend entire plan,
significantly different practice often monitored different techniques, may
require additional domain knowledge specialized monitoring algorithms, must invoked
efficiently. example, domains, never want human team members killed
robots destroyed. Therefore, monitor physical safety agents times give
alerts user agent danger. Dangers adversarial agents covered
category. However, system alert user threats team members
(fratricide) local agents actions (e.g., robots battery running low).
New opportunities. Even though current plan still executed without change, may
possible generate better plan current situation new opportunities arise. Determining
execution-time update world state permits desirable plan difficult problem
general, similar generating new plan new situation. However, real-world domains,
often methods detecting new opportunities indicate plan revision might cost
effective. example, certain key features (such pop-up targets military domains)
represent new opportunities, often encoded standard operating procedures (SOPs)
invoked triggered current situation improve plan and/or react
events. monitoring interactive, avoid difficult decision whether
search better plan alerting user high-value opportunities relying user
judge best response.
Adversarial activity. category assumes team members operating environments adversaries trying actively thwart team plans. adversaries dangerous
(e.g., worthy human opponents), reacting detected activity becomes top priority and,
experience, merits customized monitoring algorithms. Recognizing immediate threats team
members physical existence accomplishment plan obviously important. addition, information allows human discern patterns recognize opponents plan
intent valuable. EAs recognize physical threats adversarial activity expected
plan, currently perform automated plan intent recognition data adversaries.
automated plan recognition (Kaminka et al., 2001) inference adversarial intent (Franke,
Brown, Bell, & Mendenhall, 2000; Bell, Jr., & Brown, 2002) active areas research. algorithms developed reliably recognize adversarial plans intent using acceptable
computational resources, could easily invoked within monitoring framework.
Projections. Even though current plan still executed without change time
being, may possible predict future failure plan global constraints occur,
varying degrees certainty. example, suppose plan requires robot move location X
time T, robot getting progressively behind schedule course.
point T, system predict acceptable certainty location constraint
violated alert user, may revise plan. addition, new opportunities probable
adversarial activity could projected. Projection/simulation algorithms computationally
expensive, execution monitor must adjust calculation projections match available
resources constraints.
224

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Contingency plans. plan may specify contingency plans subplans,
invoked certain, specified conditions arise. execution monitor monitor conditions alert user contingency plan triggered. system notify
team members automatically user decides switch execution contingency plan. Another desirable alert domains might suggestion system new contingency
plans generated certain situations events unfold unexpected manner. EAs
monitor triggering contingencies suggest generation.
System problems. Depending domain, user may want alerted problems
incoming data streams functioning execution assistant itself. example, data
arriving sensors, network team members, may crucial
helping user interpret situation system alerts.
Reporting requirements. One basic assumptions human user experience
knowledge modeled within system. Therefore, system cannot always recognize new piece information affect plan execution. information
trigger alerts might still valuable user. system given reporting requirements allow recognize information. One generally useful reporting requirement would
execution status, user quickly determine execution proceeding planned. Reporting requirements may take number forms, appropriate domain. comments
recognizing new opportunities apply domains might specify requirements SOPs,
key features, declarative statements, heuristic algorithms. Several things fall category,
information reduces uncertainty and/or indicates plan executing expected.
another example, robot might told immediately report murder fire witnesses
executing planned tasks.

5. Value Information Alerts
Algorithms alert constraint violations threats straightforward manner inundate
user dynamic domains. Unwanted alerts problem domains many
domains well, medical monitoring (Koski et al., 1990). aid gives alerts every
second quickly discarded user stressful situations (if immediately). useful,
execution aid must produce high-value, user-appropriate alerts. Alerts presentation may
adjusted situation, including users cognitive state (or computational
state software agent). example, high-stress situations, tolerances could increased
certain types alerts might ignored postponed. section, provide conceptual
framework alerting algorithms monitoring framework domain-specific EAs.
approach grounded concept determining value alert. First, system
must estimate value new information user. Information theory derives communication theory work Shannon (1948). theory, value information refers
reduction uncertainty resulting receipt message, meaning
message (or uncertainty reduction) receiver (Weinberger, 2002). use term
value information (VOI) different sense, namely, pragmatic import information
relative receiver. (Of course, reduction uncertainty often pragmatic import.)
Weinberger (2002), assume practical value information derives usefulness
making informed decisions.

225

fiW ILKINS , L EE , & B ERRY

However, alerting user valuable information could negative impact certain
situations, alert distracts user important tasks, many
alerts overwhelm user. therefore introduce concept value alert (VOA),
pragmatic import (for making informed decisions) taking action focus users
attention piece information. VOA takes VOI account weighs costs
benefits interrupting user. user busy something significantly important,
issuing alert might valuable, even VOI high. VOA must generally estimate
users cognitive state current activities. VOA generally determine modality
qualities alert presentation (e.g., whether one flash red text computer display
issue loud audible warning).
VOI VOA highly correlated situations, general comments VOI
apply VOA well. However, VOA may low VOI high user highly stressed
preoccupied important tasks. possible high VOA low VOI.
example, mission-specific monitors might alert user information known
time (and thus little value information) information crucial
upcoming decision user may forgotten it, may behaving way indicates
lack awareness.
Weinberger gives quantitative definition pragmatic information, assuming finite set
alternatives lead well-defined outcomes, value decision maker.
realistic domains ours, alternatives outcomes precisely defined. Furthermore,
information decision theories (including Weinbergers) assume decision maker aware
(or processed) previous information devote sufficient resources analyzing
current information. assumptions unlimited processing power, VOA VOI
same. realistic domains, assumptions hold. Humans resource bounded and,
fast-paced operations, alerts information may ignored user may realize
implications information complex plan coordinates many team members.
5.1 Estimating VOI VOA
interactive, dynamic, real-world domains SUO, cannot model alternatives, payoffs, knowledge probabilities required enough precision compute
theoretical VOI VOA. Much knowledge VOI resides human experts,
even might different preferences opinions VOI. example, SUO domain, user might concerned public-relations effects plan execution
reported international media. precisely humans knowledge modeled
system want execution assistants interactive. realistic domains,
generally obvious boundaries types support system provide,
precisely defined evaluation functions payoff matrixes. Thus, Weinbergers theory formal
techniques computing value information (Athey & Levin, 2001) cannot applied. Horty
Pollack (2001) develop foundations theory rational choice involves
estimating cost decisions context plans. approach comes closer addressing
concerns. However, determining costs utilities actions continue require human
judgment many domains, especially human lives put risk.
Therefore, developed algorithms heuristically estimate VOI using domain knowledge,
although quantitative VOI functions easily used framework. inputs al-

226

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

gorithms described Section 5.3. domain-specific algorithms are, must be, easily
customized tuned user preferences, well situation. invoked domainindependent ways variety purposes monitoring framework, developed
feedback domain experts. believe feasible use machine-learning techniques
replace supplement hand-coded heuristics VOI/VOA estimation and/or user preferences
affect it, explored.
VOI VOA computed qualitatively domains, using several domain-specific quantitative measures qualitative reasoning process. Issuing alert discrete event, generally
small number options presenting alert. Therefore, estimating VOA primarily problem categorizing potential alert small number alert presentation types
modalities. need determine VOA crosses thresholds (defined VOI/VOA
specification) indicating, example, valuable issue alert, alert
issued high-priority. framework, thresholds customizable user
mission specific, change automatically different missions plan executed.
VOI algorithms determine information include alert.
Different alert presentations handled assigning qualitative priority alert. example, SUO EA divides alerts VOA four equivalence classes levels priority,
already defined SUO domain. priority presented differently user,
using different modalities simply using different colors sizes text graphics. Currently,
use three priority levels robotics domain, may add future collaborating team
members make use EA. priority levels used adjust alerting behavior
users cognitive load. example, fast-paced operations, highest-priority alerts
could presented.
several reasons preferring qualitative reasoning, draw Forbuss work
describing advantages (Donlon & Forbus, 1999; Forbus, 2002). Qualitative models fit perfectly
making decisions, discrete events, effectively divide continuous properties
important transitions. Thus, changes qualitative value generally indicate important changes
underlying situation. Qualitative models facilitate communication built
reasoning human experts thus similar peoples understanding. example,
priority levels used VOA algorithms long named defined military.
Qualitative reasoning important framework integrating results various qualitative
computations way humans understand. Finally, precision quantitative models
serious weakness underlying models accurately reflect real-world situation.
Precise data lead precise incorrect results low-accuracy model, precise results
lead false sense security.
advantages qualitative reasoning apparent common sense military reasoning. Common sense reasoning continuous quantities often done qualitatively.
continuous value interest different action decision required. example,
ignore fuel gauge driving decided whether must refuel reaching destination. addition priorities already mentioned, military
quantizes many continuous properties used describe terrain ways relevant military
operations, creating phase lines, decision points, named areas interest, key terrain avenues
approach, forth. SUO EA incorporates quantizations reason terrains influence VOI VOA effectively communicate information alerts, military
used years facilitate communication, collaboration, decision making.
227

fiW ILKINS , L EE , & B ERRY

5.2 Properties VOI VOA
VOI VOA dynamic domain depends primarily whether information influence
decisions/responses. execution aid must ensure human awareness high-value data
support decisions human user make. Thus, system must estimate model
human needs know (e.g., specifying reporting requirements), even system cannot predict
information might influence decision. example, emerging adversarial friendly
pattern might crucial. system human-level ability recognize plans
patterns, ensure human decision maker aware relevant data.
One obvious important property VOI zero user already aware
information. Another property information indicating plan execution proceeding
according plan valuable, influences decision continue planned.
value confirming information depends features domain information
valuable domains high uncertainty active adversaries.
Another feature may useful certain domains classifying responses suggested
piece information alert. example, new report may require significant plan
modification, minor plan modification, invocation contingency plan, application
standard operating procedure (SOP), identification new opportunity. However, type
response necessarily correlate VOI, minor plan modification might life saving,
major modification might simply reduce resource usage ten percent. distinction
important simpler responses likely handled automated fashion, thus
reducing need involve user.
Determining information present alert requires addressing human factors. Initially,
important present alert concisely human determine import glance,
assess whether divert attention tasks. EAs, user drill
detailed information alert order assess situation accurately.
Finally, domains may concerns making informed decisions. example,
emotional state user recording data scientific value might beneficial. particular,
concern analyzing debugging system performance rather making good execution
decisions, different VOI estimator used provide alerts system behavior.
5.3 VOI VOA Criteria
described above, VOI VOA algorithms generally heuristic, domain-specific,
user customizable. identify inputs applicable interactive,
dynamic domains. started superset VOI criteria found useful two domains
generalized domain independent. (The properties user listed
estimates system models user, users mental state accessible.)
plan
Policies
Users awareness current situation
Systems view current situation
Users cognitive load
228

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Resources, especially time, available analysis response
Information adversarial agents
Characterization uncertainty
Age information age users awareness
Source information
plan provides several VOI criteria: plan may provide explicit implicit decision
points, high-value places, times, team members, forth. value task, constraint,
adversarial action, team member often determined plan structure plan annotations.
tasks plan invoke task-specific VOI algorithms within monitoring framework,
described Section 6. Domain policies (or specialized reasoners implement them)
reporting requirements provide knowledge necessary determine value alerts
various types constraint violations reports. example, domains, monitor
physical safety agents. Alerts life-threatening situations highest priority.
noted VOI tends zero extent user already aware information. Thus,
determining VOI must access current view situation determine arriving reports offer
new information simply confirm existing view. data-rich domains, assume
execution aid may detailed description situation user (for aspects
situation described incoming data), user may performing tasks
monitoring situation alerted EA. Therefore, value alerting
user depend much new information differs users last situation update,
even system recent data differs slightly new information.
Ideally, would model users cognitive load, give lower values noncritical
alerts user consumed addressing critical aspects situation. Similarly,
want overload systems computational resources ability remain reactive,
value certain information may depend time resources available analyze it.
determining value information adversaries, often useful compare
developing patterns information adversarys plans tendencies, could
obtained human intelligence analysts generated plan-recognition pattern-matching
algorithms. mentioned above, information reduces uncertainty valuable domains
high uncertainty active adversaries. VOI estimated characterization
uncertainty present current view situation.
age information factor VOI outdated reports may zero value newer
information already arrived. modeling users awareness, elapsed time factor.
user aware alerts issued last minutes, may longer aware something
brought attention yesterday last week. Thus, value proposed new alert
may increase elapsed time since similar alert issued.
variety sources information exists, source factor VOI. Often, different
information sources inherently different levels certainty, authority, importance. example, SUO EA accepts reports human observers automated sensors. EA
inputs might want weigh human observations differently depending human
situation. later sections implemented EAs, describe domain-specific VOI/VOA
algorithms, inputs corresponding inputs listed above.
229

fiW ILKINS , L EE , & B ERRY

6. Implementing Execution Monitors Small Unit Operations
developed execution-monitoring framework easily adapted produce interactive monitors agent teams dynamic domains. support claim, describe two
dynamic, data-rich, real-world domains Execution Assistants (EAs) implemented
using framework. first domain, Army small unit operations (SUO), hundreds mobile,
geographically distributed agents, combination humans, robots, vehicles.
domain, UV-Robotics (Ortiz, Agno, Berry, & Vincent, 2002), described Section 7
teams composed handful cooperating, unmanned ground air vehicles (UGVs
UAVs) human controller. domains involve unpredictable adversaries vicinity
team members.
originally developed monitoring framework SUO domain using several personmonths effort, although majority effort knowledge acquisition modeling.
SUO monitoring framework, described below, designed modular support
easy insertion domain-specific (and user-customized) system components, task models,
monitoring algorithms, value-of-information estimators. design validated
implemented complex execution monitor UV-Robotics domain one person-week
(as described Section 7.2). UV EA uses plan representation basic architecture
SUO EA, inputs different tasks monitoring algorithms
respond inputs generate alerts.
majority framework applies completely automated execution monitoring
demonstrated UV EA. UV EA runs robot team used autonomously
adjust robot control blending desired behaviors automatically revising plans execution. UV EA provides alerts human controller monitoring robots.
framework described section general, follow domain-specific
details clarify concepts tradeoffs. details may interest readers.
6.1 SUO Problem Description
Small unit operations military involve hundreds mobile, geographically distributed soldiers
vehicles cooperatively executing fast-paced actions unpredictable adversary. Computational support bandwidth restricted must use lightweight portable devices. Currently,
planning decisions made humans, plans machine understandable.
implemented SUO EA part larger system: Situation Awareness Information Management (SAIM) system, distributes timely, consistent situation data friendly
agents. SAIM uses new technologies demonstrate new concept automated support (described
below) SUO domain. assume many small teams agents (human, vehicles, eventually robots), separated dispersed throughout large space, operating concert achieve
goals. assume agent equipment providing robust geolocation (GPS), computing,
communication capabilities. SAIM assumes unpredictable adversary, fast-paced action,
rich population sensors controlled cooperating team members.
key innovations SAIM, addition EA, self-organizing peer-to-peer information architecture forward fusion tracking. Fusion information tracking distributed
done close source minimize latency, bandwidth requirements, ambiguity. Adjudication maintains consistency distributed databases. information architecture supports ad hoc
information dissemination based multicast groups centered mission, geography, command.
230

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Self-elected servers provide robustness information dissemination peer-to-peer
network brings transport layer.
SAIM provides large volumes geolocation data much information human controller monitor, particularly high-stress situations. EA alleviates problem using
machine-understandable plan filter information SAIM alert user events
threaten user execution plan. plan-aware, situation-aware, action-specific EA
alert appropriately situation, thus improving decision making enabling hands-free
operations, reducing need human monitoring, increasing amount relevant information
monitored, prompting user action required.
complexities plans, number agents, volume data pose challenge
existing execution-monitoring techniques. Unlike lot AI planning work, particularly robotics,
actions domain performed external agents, mostly humans, monitor
access state executing agents. Status information must obtained external inputs.
focus problem alerting human users situation requires attention;
assume human modify plan needed. done several reasons. First,
users unwilling cede decision making machine, first develop trust giving useful
alerts, capability well suited automation plan represented enough fidelity,
something provides obvious value dealing information glut. Second, mistakes
matter life death, systems must verifiably robust given decisionmaking power. Human decision makers must take imperfect information account, including
reports sensor networks, humans, execution assistants. Third, demonstrating
utility automated, plan-based monitoring large complex domain likely facilitate
future acceptance users plan-related automation.
name
Battalion
Company
Platoon

Abbrev
BN
CO
PLT

Entities controlled
400-600
100
30

Figure 2: Echelons command hierarchy EAs.

Execution monitoring requires coordination multiple echelons (levels hierarchy),
users know subordinates doing. Figure 2 shows echelons
demonstrated EA. Multiple agents echelon must coordinate fast-paced activities
wide area real time. task requires solution three difficult problems: handling large
volume incoming information, developing sufficiently rich plan representation capturing
tactical Army plans, determining alert user.
mentioned before, EA must give high-value alerts useful. example,
unit position late, system must recognize import condition
situation changed sufficiently issue another alert, without issuing many alerts.
Consider seemingly simple example plan specifying squad 10 agents move
Objective Golf 0700. location squad? obvious solution compute
centroid members location. However, one near centroid members
large semicircle centroid center (this situation arises squad follows
231

fiW ILKINS , L EE , & B ERRY

road around sweeping curve). one member immobile GPS still broadcasting,
centroid may seriously inaccurate. centroid need near Golf, one member near
Golf sufficient, must members near Golf? depends mission (task) situation.
mission observe valley, one member sufficient, might want members
attack. solution use mission-specific algorithms (specified mission model described
Section 6.5) reasoning location units.
EA must avoid cascading alerts events get progressively away expectations
along number dimensions (such time, space, resource availability).
example, close time 0700 squad problem achieving
plans objectives? Similarly, close distance Golf? Again, time distance thresholds
indicate problem depend mission situation. human uses background world
knowledge quickly determine delay affects plan, execution aids must much
knowledge encoded this. problems become exacerbated plans missions
become complex. Detecting friendly-fire (fratricide) risks poses even difficult issues,
typically many friendly units close proximity.
6.2 SUO Approach
Machine understanding plan key helping humans deal information glut created advanced situation-awareness systems SAIM. plan specifies expectations
events unfold, EA compare actual events situations anticipated.
use rich, knowledge-based plan representations (Wilkins & desJardins, 2001) allow computers
share context users, understand semantics plans requests.
two tasks involving significant knowledge acquisition domain modeling: (1)
model SUO plans actions compose them, (2) model value
information various types alerts users. interacted several domain experts
develop models. tasks aided centuries analysis modeling
already done domain. task 1, Army already standard plan representation
called Operations Order, required structure, entries mostly free text.
Primitive actions domain referred missions, Army field manuals
describe missions detail. modeled missions hierarchical mission model. mission
model plans described Section 6.5. task 2, extensive accumulated experience
analysis errors opportunities arise execution SUO plans, many
tradeoffs made. tradeoffs models described Sections 6.4, 6.6, 6.7.
Mission-specific execution monitoring achieved novel integration mission knowledge
represented methods AI reactive control system. EA invokes methods appropriate
points plan execution. methods employ mission-specific algorithms turn invoke
EA capabilities mission-specific manner. Much domain mission knowledge encoded mission model explicitly represented plan itself, specifies partial
order missions team member. EA uses plan invoke knowledge
mission model appropriate time appropriate arguments.
Another feature approach, particularly terrain reasoning, pervasive use specialized programs, possibly external EA, perform complex computations important
system performance. using alternative specialized programs, EA easily adapt granularity reasoning improve performance better modules become available. example,

232

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

API functions design used terrain reasoning compute enemy strength
current tracks.
approach builds SRIs continuous planning technology (Wilkins & desJardins, 2001;
Wilkins & Myers, 1998; Wilkins et al., 1995) domain-independent Act formalism
(Wilkins & Myers, 1995). Act represents procedural knowledge plans Acts, provides
rich set goal modalities encoding activity (see Section 6.5), used several
institutions (Wilkins & Myers, 1998; Durfee et al., 1997). EA uses P RS (Georgeff & Ingrand,
1989; Wilkins et al., 1995) reactive control system (other reactive control systems similar capabilities, e.g., UM-PRS (Durfee et al., 1997)). P RS good framework constructing
EA supports parallel activities within agent, smoothly interleave responses
external requests events internal goal-driven activities uniform processing
goal- event-directed behavior. P RS uses procedures encoded Acts extensive graphical
tracing provides valuable insights EA operation.
6.3 SUO Architecture
architecture EA interactions SAIM system shown Figure 3.
developed two major modules, Planning Assistant (PA) Execution Assistant (EA),
assist user generating executing plans, respectively. implemented skeletal
PA produce machine-understandable plans, using IPE 2 hierarchical task network planner
(Wilkins et al., 1995). PA EA use Acts common knowledge base, ontology,
mission model object-based easily extended. Knowledge actions represented
mission model, knowledge plans, strategies, procedures represented Acts.
inputs EA plans execute, location reports, sensor tracks, messages
agents (e.g., reporting mission success failure, ordering execution new plans).
SAIM broadcasts up-to-date locations friendly agents, broadcasts tracks represent
results fusing sensor hits nonfriendly entities. SAIM provides EA supports rates
dozen inputs per second.
EA monitors current mission every immediate subordinate EA owner,
alerts threats subordinates (subordinate depth customizable). events threaten successful
execution plan, threaten user subordinate units, trigger planned contingencies,
EA issues alert user, depending value alert determined applying
VOA algorithms. user must decide respond. design technology
suggest responses and/or plan modifications (Wilkins et al., 1995), left future work.
addition giving alerts, SUO EA dynamically change command hierarchy, abort
execution one plan switch monitoring new plan, reduce unwanted alerts avoid
inundating user.
EAs every unit every echelon process reports give alerts locally. SAIM provides
tactical picture EAs (modulo EAs registration SAIM multicast groups). Therefore,
necessary EA report new threat superior, superiors EA (as well
EA affected team members) information would already issued
similar alert. architecture fault tolerant EAs rely reports subordinates
determine alerts. Thus, EA maintains functionality even contact
EAs, long gets SAIM position reports one node.

233

fiW ILKINS , L EE , & B ERRY

PA

EA
PDA Domain KB

PDA Domain KB
Acts used
planning

Plan
Initializer

Cue:
ACT2
(TEST (ready unit1))
Cue:

ACT1
Answer query

Executable
Plan (Act)

Execution
Manager
Requests, updates

Executable
Plan

Cue:

ACT1
Answer query

Executable plan,
monitors

Advisable
Planner Agent
Partial plan
Task organization
Assets
Guidance

Cue:
ACT2
(TEST (ready unit1))

Common: ontology
mission model

PRS

Common: ontology
mission model

SIPE

Acts used
monitoring

Requests
Registrations
Notifications
Updates

SimFlex

Watchman
PRS

PRS

SAIM: Persistent Data Store (PDS), Disseminator, ...

Situation
Updates
Requests
Scripted Events

Figure 3: Internal architecture EA PA interaction SAIM. PDS archives
plans data continuously changing picture current situation.

shown Figure 3, EA implemented multiple asynchronous P RS agents (defined below) alleviate computational burden central EA Manager agent. Asynchronous agents
provide faster response better alerts would synchronous architecture, agents
always using latest information available without wait synchronize
agents. implement EA, extended P RS monitor temporal constraints batch
incoming facts could handle much higher data rates.
Internal EA agents (as opposed external team members) use Belief-Desire-Intention (BDI)
model agency (Rao & Georgeff, 1995). agent beliefs state world, desires
achieved, intentions representing actions agent adopted achieve desires.
EA agent controller process, operates database beliefs,
set intentions, monitors, set Acts encode procedural knowledge
accomplish goals, L ISP functions implement primitive actions
agent. EA agent continually applies Acts accomplish current intentions (tasks). EA
appears single agent SAIM outside world. following internal EA agents.
Plan Initializer. agent gets plan PA sends messages EA Manager
agent performing initializations necessary begin monitoring plan execution. Primarily,
involves creating loading plan monitors, posting facts EA Manager database.
Watchman. agent monitors incoming message traffic SAIM network, mainly
querying tracks information. filters irrelevant insignificantly changed reports,
sends message EA Manager report message requires attention.
simultaneously monitors files scripted events monitoring requested. Watchman
inserts events scripts appropriate times, interleaving live messages.

234

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

EA Manager. agent begins plan execution immediately receiving plan
Plan Initializer. agent implements core EA functionality compares reports
Watchman agent plan plan monitors, generates high-value alerts.
SimFlex. agent provides powerful flexible way define execution semantics
action using Acts (and thus full power PRS). SimFlex (simulated, flexible execution)
enables mission-specific execution monitoring (by Act mission) makes
system easily extendible. example, certain missions automatically command robotic
vehicles send messages EAs, actions could easily implemented SimFlex.
actions plans executed external human agents, case agent
little except perhaps prompt user. actions, reorganizations, automatically
executed SimFlex invoking Execute-Mission method defined mission model.
6.4 SUO Alert Types
extensive accumulated experience regarding execution SUO plans, selecting
types alerts detect involved trading several factors, whether alert
detected available data, utility alert user, cost implementation,
ability maintain reactivity given computational expense detecting alert. earlier gave
example balancing usefulness fine-grained terrain reasoning movement projection
computational impact reactivity. Thus, modeling value information types
alerts detected involved interaction domain experts system developers.
describe types alerts decided detect. details implement
model value information alerts given Sections 6.6 6.7.
Figure 4 describes 13 types alerts detected SUO EA.
time location checking. Comparing alerts categories Section 4, proximity
alerts instances adversarial activity detected. adversarial alerts fit category
last three adversarial alerts type plan constraint violated expectations requirements specified plan (such locations routes monitor) violated.
contingency alert, triggered either friendly hostile actions, type
contingency plan suggested. out-of-position, coordination, schedule alerts type plan
constraint violated, would type constraint violation projected violation projected. fratricide alert type policy constraint violated, unknown-position alert
type reporting requirement.
6.5 SUO Plans Mission Model
hierarchical mission model specifies ontology primitive actions, methods
encode domain knowledge constraints expected behaviors. Tailoring
monitoring mission crucial behaviors, even something simple denoting
location unit, mission specific. plan representation novel combination
mission model extended version Act formalism (Wilkins & Myers, 1995).1
1. EA plans represent plans expressed Army operations orders, parts current Army fiveparagraph order represented machine-understandable form. Primarily, task organization specific maneuver tasks coordinating instructions Execution Paragraph represented, aspects
encoded well.

235

fiW ILKINS , L EE , & B ERRY

Alert Type
fratricide
out-of-position
unknown-position
coordination
schedule
contingency
contingency
monitored
ave-of-approach
hostile-expected
contact
distance
strength
proximity

FRIENDLY ALERTS
Friendly units pose threat other.
Location constraints plan violated.
Unknown location subordinate/coordinating unit.
Coordinating units cannot synchronize planned.
Time constraint plan violated.
event triggered queued contingency.
ADVERSARIAL ALERTS
event triggered queued contingency.
Activity monitored map location.
Activity monitored route (avenue approach).
Expected hostile activity absent.
PROXIMITY ALERTS
friendly units first contact hostile entity.
Hostile entities closer since last alert.
Threat grown stronger since last alert.
merged alert one above.

Figure 4: Types alerts generated SUO EA.

Act formalism domain-independent AI language representing kinds knowledge activity used plan generation reactive execution systems. provides rich
set goal modalities encoding activity, including notions achievement, maintenance, testing, conclusion, waiting. expressiveness necessary representing SUO plans,
must coordinate distributed units, trigger preplanned contingencies, enforce variety execution constraints. basic unit representation Act, used encode plans,
strategies, standard operating procedures (SOPs).
EA monitor plan composed missions mission model. mission
model derived Army field manuals elaboration domain experts. includes set
mission templates (with associated parameters) units various echelons could ordered
perform, either written verbal order. Since mission model grounded field manuals,
first step toward formalizing plan representation meaningful end users yet amenable
execution monitoring AI-related capabilities (e.g., plan generation, replanning, course
action evaluation).
mission model class hierarchy (implemented L ISP CLOS, Common Lisp
Object System), inherited methods encode knowledge monitor particular
mission. leaf class corresponds monitorable action may occur plan; nonleaf
class encapsulates common parameters behaviors subclasses. mission model allows
aspects system behavior tailored mission-specific manner. Thus, specialized
methods mission model can, example, use mission-specific algorithms monitoring
progress movement. Methods invoked EA Manager turn invoke processing
EA Manager posting mission-specific facts invoke capabilities EA Manager
(there API facts, important facts described later).

236

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

mission model contains name parameters describe mission. example, mission model contains nonleaf movement-mission class, contains destination
parameter method checking executing unit arrived destination. Five
different movement missions inherit behavior. root class model mission class,
encapsulates parameters behaviors shared missions. missions inherit
start-time end-time scheduling constraints methods superclass.
Coverage. mission model formalizes substantial subset missions mentioned
Army field manuals. enumerated 62 mission classes, implemented 37 these,
superset required scenarios. mission model covers multiple echelons, emphasis battalion, company, platoon. model aspects missions,
SAIM provide monitoring data, is, related time location. example,
alert potential mission failure due casualties incurred.
Contingencies. mission model contains nonleaf contingent-mission class. class
leaf children classes used implement mission sequence part plan
executed certain conditions fulfilled. Domain experts term portions
plan branches sequels. missions contingent-mission contain parameters describe
condition, specified plan, activates contingency.
Dynamic resubordination. Army operations orders allow command hierarchy (termed
task organization) changed operation, although existing command control software support dynamic changes command hierarchy. reorganization-mission
class provides capability EA. reorganization mission executed, causes
EA update representation command hierarchy accordingly. substantial effect
EA behavior, many EA algorithms use command hierarchy.
Methods. mission provides several methods invoked appropriate times
EA monitor execution mission. set methods serves API mission-specific
execution monitoring semantics. following methods comprise bulk API:
Post-Execution-Constraints main API method invoked EA monitoring mission.
invokes methods post enforce various constraints.
Check-Initial-Location, Check-Final-Location confirm unit(s) positioned correctly
start end mission respectively.
Start-Time-Constraints, End-Time-Constraints check mission beginning ending
execution scheduled. methods usually post facts EA Manager invoke
Timed Monitor mechanisms.
Location-Constraints enforces location checking friendly units hostile tracks variety
missions.
Contingency-Satisfied determines whether contingent mission sequence executed.
Respond-To-Monitored-Red-Activity algorithm responding hostile activity places
plan calls monitoring activity.
Execute-Mission invokes processing required execute mission. invoked posting
goal SimFlex agent, internal agents continue P RS execution ExecuteMission running.
237

fiW ILKINS , L EE , & B ERRY

Compute-Priority computes priority alert.
Desired-Strength-Ratio heuristic expresses desired friendly:hostile ratio combat
power.
Red-Alert-Priority computes priority proximity alert, whether alert issued
all, based recent changes reported strengths friendly unit nearby hostile
tracks.
Wait-Until-Mission-Start, Wait-Until-Mission-End control interaction EA GUI regard mission start end times.
Specialization methods useful expressing desired behavior EA. example,
Location-Constraints method specialized movement-mission, coordination-mission,
several missions. movement missions, EA checks whether centroid moving
unit destination. coordination missions, EA checks whether elements two
coordinating units specified coordination point.
6.6 SUO Execution Monitoring
EA Manager continuously responds new goals facts posted database. Watchman agent asynchronously posting facts EA Manager database receives messages
SAIM. Facts posted include confirmations mission starts completions (from subordinate
EAs), orders aborting current plan executing new plan (from superior EA), sensor
tracks, calls fire, location reports (from SAIM network).
methods mission model post facts EA Manager invoke mission-specific
monitoring. Examples fact-invoked capabilities provided EA Manager include monitoring several types time constraints monitoring specified location activity (with options
friendly enemy, expected unexpected).
behavior EA Manager determined posted goals facts, relative timing, set Acts used respond. EA Manager switches focus highest-priority
task execution cycle goals facts generate responses acceptable latency
(Georgeff & Ingrand, 1989). Execution cycles order milliseconds. System behavior
nondeterministic depends exactly facts goals posted execution cycle, may turn depend CPU scheduling EA Manager, Watchman,
SAIM processes. number alerts rarely varies vary exact times
alerts (which vary seconds), hostile strengths reported (which change
Watchman agent gets fewer CPU cycles accumulate tracks EA Manager
executes).
EA Manager must constantly monitor status behavior currently executing missions, simultaneously monitoring dozen incoming facts per second determining
impact plan. monitoring plan, typically order 100 intentions
trying accomplish one time, 107 Acts (Procedures) apply intentions.
intentions cause alert generated. unprocessed report track forms intention. Typically, five subordinate missions executing simultaneously. produces multiple
intentions: least one detecting start end mission, time

238

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

location constraint (every mission least start time end time constraint). example, time constraint, EA Manager intentions monitor specified time
elapsed required event occurred.
plan-based monitoring EA viewed asynchronously simultaneously
interleaving following activities. describe detail mention
important design tradeoffs.
Initiating aborting plan execution upon request
Monitoring incoming location sensor reports
Monitoring progress missions time constraints specified executing plans
Responding types incoming requests
6.6.1 P LAN MONITORING
monitor plan, request goal posted database. invokes Initialize-Plan Act
computes conditions globally monitored plan posts facts EA
Manager database declaring current plan monitors. facts turn cause
Acts execute EA Manager, load execute plan. EA Manager traverses
parallel branches plan missions complete.
global monitors computed using API function compute-plan-monitoring-data,
specify domain-specific monitors. Domain-independent capabilities available,
system determine predicates plan preconditions must true initially
(as opposed predicates achieved plan actions precede them). SUO domain,
compute-plan-monitoring-data finds decision points named areas interest specified
plan, sets monitors them. monitoring accomplished posting facts EA
Manager database cause EA notice adversarial activity locations.
EA abort monitoring one plan switch monitoring new plan. process
involves removing facts old missions monitors EA Manager database, aborting
execution Acts currently intended execution, posting goal execute new plan.
6.6.2 L OCATION REPORTS
Blue Report Act Figure 5 invoked every time location report posted EA Manager
database, happen several times second. However, Watchman agent filters location reports interest EA Manager (e.g., entities irrelevant plan
EA owner, change last report), updates representation
current situation EA. Blue Report Act specific SUO domain, framework
requires similar Act written type input actively monitored. example, similar UV-Robotics Act responds state updates (see Section 7.4). Acts
written using Act-Editor (Wilkins & Myers, 1995), tool graphically editing procedural
knowledge (Acts) intuitive user interface.
Act begins invoking domain-specific specialized reasoner check fratricide risk,
may side effect giving alert (using API function issue-alert). specialized reasoner easily replaced better fratricide detection algorithms future. Next,
Blue Report Act checks whether current plan expectations unit, so, calls
239

fiW ILKINS , L EE , & B ERRY

BLUE-REPORT fact: Check-blue-report
Cue:
(CONCLUDE
(Blue-report Unit.1 X.1 Y.1 Time.2))
Preconditions:
- entry Setting:
- entry Resources:
- entry Properties:
(Authoring-system Act-Editor)

N1:
(ACHIEVE (Check-fratricide-risk Unit.1 X.1 Y.1 Time.2))

N2:
(TEST
(Expected-location Unit.1 Id.1
Dest-map-object.1 Time.1 Loc-fuzz.1)

N4:
(TEST
(Not (Expected-location Unit.1 Id.1
Dest-map-object.1 Time.1 Loc-fuzz.1)))

Comment:

N3:

Act invoked every time
blue location report posted
database. invokes API
function check fratricide
risk, another check
units expected location
whenever database
expected location (from plan)
unit report.

(ACHIEVE
(Check-expected-location Unit.1 Id.1
Dest-map-object.1 Time.1 Loc-fuzz.1 :In-progress))

N5:
(RETRACT (Blue-report Unit.1 X.1 Y.1 Time.2))

Figure 5: Graphical representation Act responds every friendly location report.
API function check-expected-location compare current location expected location,
posting alert appropriate. Finally, report fact removed database.
Responding fused sensor track indicating adversarial activity controlled similar Red
Report Act, compares adversarial activity plan expectations. Instead analyzing fratricide
risk, Red Report Act invokes reasoner evaluating adversarial threats. described
Section 6.7, involves updating threat envelope friendly unit.
6.6.3 ISSION MONITORING
explain mission monitoring, give example move mission plan monitored.
move-mission ready execution following parameters:
(move-mission unit start-time-constraint start-time end-time-constraint end-time destination
route formation march-technique contingency contingency-satisfied).

EA Manager begins execution calling three methods defined mission model: StartTime-Constraints, End-Time-Constraints, Location-Constraints. posts facts
EA Manager database invoke mission-specific monitoring capabilities. example, LocationConstraints (which specialized class movement-mission) posts facts locations
mission expects friendly units occupy time (derived destination route
arguments), might post facts locations mission expects adversarial activity
adversarial activity monitored/alerted.
EA receives confirmation mission start subordinate EA. Location reports
continuously posted Watchman, Act Figure 5 analyzes respect
location facts posted Location-Constraints. Sensor tracks similarly analyzed different
Act. Let us suppose point mission execution, track shows activity location monitored mission. EA would detect invoke mission-specific method
240

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Respond-To-Monitored-Red-Activity, describes mission respond
event. example, could issue alert, abort move, execute contingency plan, ask
user choose set options.
Type
ASAP
ON-ORDER
START-AT
START-NLT
START-NET
END-AT
END-NLT
END-NET

Meaning
start/end specified
start/end ordered
start exactly given time
start later given time
start earlier given time
end exactly given time
end later given time
end earlier given time

Figure 6: Temporal constraint types.

6.6.4 EMPORAL MONITORING
mission model includes starting ending time constraints every mission. time
constraint consists temporal constraint type absolute time. temporal constraint
types EA shown Figure 6. constraints require two types monitoring tasks:
detecting time constraints plan passed without met, detecting events
occur specified time.
extended P RS domain-independent Timed Monitor mechanism provides general
capability covering temporal monitoring requirements. capability implemented
form Acts, supporting L ISP code. Four special types timed monitors
provided, invoked posting facts predicates Check-Not-Later-Than, Check-Not-EarlierThan, Check-In-Window, Check-Near-Time. describe implementation one these;
others similar. Act Check-Near-Time checks event occurs within specified
threshold time point invoked fact form:
(Check-Near-Time event.1 time.1 mode.1 fuzz.1)
succeed, event.1 must occur within fuzz.1 seconds time.1, mode.1 indicating whether
time absolute relative (to time fact posted). Timed Monitor Act sets
timer expires given time, P RS reacts appropriately either expiration
timer occurrence event, posting facts database note success failure
temporal constraint. Acts fact invoked, mechanisms enable
establishment separate intentions perform timing, without blocking processing.
modularization enables triggers set independently respond timing results.
6.6.5 ESIGN TRADEOFFS
described Section 2, balance must struck capabilities provided resources
used. tradeoffs different every application usually critical aspect design
execution assistant. SUO domain, terrain reasoning key factor tradeoff. Using

241

fiW ILKINS , L EE , & B ERRY

fine-grained terrain data analyze progress project future failures overload computational
resources. Therefore, EA uses coarse terrain reasoning, design allows higher-fidelity
terrain reasoners respond defined set terrain analysis requests. feature allows
system adjust analysis tempo operations.
key features consider making tradeoffs reactivity capabilities
amount processing done mission-monitoring methods, report-monitoring Acts,
specialized reasoners (such terrain reasonsers) invoked methods Acts. user
adjust frequency monitoring time customizing parameter settings. Currently,
SUO EA computationally overburdened analyzing every report full, adding
computationally expensive projections alerts future could cause reconsideration
design decision. Finally, amount filtering incoming reports done Watchman
agent affects balance.
6.6.6

FEATURES IMPLEMENTATION

EA responds requests, calls fire, described Section 6.7. Several
capabilities implemented make EA easier use understand. Two briefly
mentioned here. implemented GUI, meant military users, rather facilitate evaluation understanding EA. GUI displays alerts different scrollable windows
priority level, current time, current mission subordinate EA owner.
user confirm mission starts ends locally, although might done voice
modality fielded system. confirmation arrives subordinate EA,
confirmation window mission destroyed. Thus, confirmations prompts given
locally received messages, seamless interleaving two types confirmation.
EA, PA, mission model, P RS IPE 2 implemented C OMMON L ISP, CLIM,
CLOS. EA contains procedural knowledge form Acts. SAIM implemented
C++ Java, using ACE Object Request Broker CORBA. C++ used interface
EA SAIM CORBA.
6.7 Alert Detection VOI/VOA
central task EA notify user important changes situation may demand
attention. EA must avoid excessive alerting; otherwise, user would abandon EA
nuisance. model users cognitive state respect awareness threats would
ideal, unavailable. described Section 5, developed algorithms heuristically
estimate VOI VOA using domain knowledge. inputs algorithms described
Section 5.3. avoid excessive alerts issuing high-VOA alerts. techniques include
Keeping event histories friendly unit, map coordinates important map
locations named plan (e.g., decision points).
alerts expire sense longer used suppress future alerts.
Using alert histories suppressing alerts time (similar alert given recently), strength
(threat significantly stronger), distance (threat significantly closer).
Merging several related alerts apply subordinates one alert common parent.

242

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Providing parameters user customize alerting behavior VOI/VOA estimates.
event histories currently model users cognitive state, except global
properties situation, operational tempo. VOA calculations take account
frequency timing alerts already given. histories include alerts
issued object history, may include additional events, described Section 7.4.
assume user aware information recently alerted.
idea behind alerts expire user may forgotten information provided
far past. Thus, EA use alerts older specified threshold reduce estimate
value giving alert now.
EAs behavior must easily customizable, users plan, users
different preferences situations impose different requirements. EA customized
many different ways. VOA algorithms, recommend alerts classify priority level, controlled thresholds repetition parameters, allow alerting behavior
customized user situation. Examples customizable VOA parameters alert
expiration periods described (default 12 minutes) alert suppression intervals (90 seconds
hostile alerts, 120 seconds alerts friendly team members) alerts
type objects suppressed given interval. terms VOA, another
fratricide alert value first 120 seconds user alerted fratricide
risk team member.
Examples customizable VOI parameters out-of-position distance threshold (150 m),
thresholds strength adversarial threats, time threshold schedule alerts (30
seconds). time threshold, example, would smaller tightly coordinated operations,
larger loosely coordinated plans. terms VOI, detecting team member late
significant value tardiness reaches given 30-second threshold. certain missions
plan change threshold, say 10 seconds, indicates information tardiness 10
30 seconds value context missions.
problem avoiding unnecessary repetition similar alerts occurs every type alert.
Schedule deviations become progressively schedule, position deviations become
progressively position, threats move progressively closer become progressively
stronger, fratricide threats persist time. EA must avoid cascading alerts
cases. framework, customizable thresholds often paired either customizable
ratios customizable sequence thresholds, control often repeat alert
mission deviates progressively expectations. Repeated alerts generally lower
VOA given lower priorities.
evaluation showed two types alerts SUO domain pose particular problems
avoiding inundation user. proximity alerts adversarial activity alerts
fratricide risks among team members. developed VOI/VOA algorithms especially
two types alerts.
6.7.1 P ROXIMITY

ALERTS

high volume sensor tracks near friendly units prior battle; would
overwhelm user see alert every change every track. keep threat envelope
friendly unit, consisting tracks close enough pose threat it. Tracks placed zero

243

fiW ILKINS , L EE , & B ERRY

threat envelopes appear move. significant changes strength
aggregate force envelope closeness nearest track causes alert.
6.7.2 F RATRICIDE RISKS
Fratricide one biggest dangers modern battlefield. risk increases range,
lethality, accuracy weapons increase. Increased range increases risk bigger
area every team member must correctly identified. Increased accuracy increases risk
incorrectly targeted team member likely suffer harm. Hopefully, tools
EA SAIM increase situational awareness greatly reduce frequency incorrect
targeting. Usually, large number friendly entities close proximity, many potential
fratricide situations exist.
EA detects two types fratricide risks: (1) calls fire team members
(which appear messages SAIM), (2) friendly units near (which detected
geolocation data). first case, user issues call fire warned asked
confirmation team members within given threshold target. request confirmed,
SAIM message sent team members, EA entity within target threshold
immediately alerts owner risk planned fire.
second case produces far many alerts simple algorithms used. algorithms
based Armys notion unit boundaries, specified plan. two units
within boundaries, alert issued even within weapons range other.
Fratricide alerts issued one unit another units boundaries within weapons range
unit. handle numerous special cases, two units outside
boundaries within weapons range other. Detection fratricide situations left
future work (e.g., misoriented units within boundary).
6.8 SUO Evaluation
EA evaluated respect usefulness output, frequency unwanted alerts,
real-time performance realistic data streams. SAIM EA tested data
produced high-fidelity military simulator two scenarios. simulator detailed models
type vehicle sensor. One scenario lasted 13.5 hours, last 90 minutes
simulated high fidelity. (The first 12 hours file scripted events, dozen
tracks reports.) second scenario, terrain, simulated 20 minutes.
90-minute simulation 45,000 events passed Watchman SAIM,
13,000 passed EA Manager, monitors squad level (8 10 entities).
simulator run, scripted events simulate messages team members
running live (such messages confirming mission starts completions). high fidelity
simulation provides realistic data rates inputs, thus providing evidence indicating
EA perform desired real world.
formal evaluation ran live SAIM, simulator, several team members, running copy SAIM EA different physical machines. shorter development
cycle, implemented event generator reproduces SAIM behavior, making SAIM network unnecessary. event generator creates messages files scripted events include
confirmations mission starts completions (that normally would come subordinate
EA), orders aborting current plan executing new plan (that normally would come

244

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

superior EA), sensor tracks location reports (that normally would come SAIM
network). event scripts contain messages captured run included simulator
SAIM.
6.8.1 Q UALITY

ALERTS

Figure 7 presents total number alerts type echelon typical run. Flash
highest four priorities, immediate second highest. Flash alerts generally life
threatening (first contact adversarial entities fratricide), lower-priority alerts
plan threatening.
analyzed evaluated alerts generated first challenging scenario.
Analysis SRI domain experts indicates important situations alerted. Less
10% alerts judged low value issued,
Flash alerts judged. Judging VOA alert subjective: different domain experts
may different alerting preferences, alert new information.
firm data number unwanted alerts would lead performance degradation
typical user (or would cause user shut EA). clear 86% false-alarm rate
found pediatric ICU (Tsien & Fackler, 1997) would acceptable battlefield.
judgment domain experts, rates low-value alerts achieved acceptable.
number alerts Figure 7 reasonable 90-minute interval fast-paced action,
elimination alerts risks missing high-value alert. purposefully erred side
missing alerts.
compared alerts generated EAs operating different echelons (running
different machines SAIM network) simulation. analysis shows
detect threat time tracks, threat relevant
plans. alerts show plan-specific mission-specific behavior expected.
nondeterminism inherent asynchronous agents, alerts always show exact
strength, bearing location threat. Figure 8 shows one example, BN CO alerts near
08:05. time, 2nd PLT, CO moving outside unit boundary specified plan,
hostile force appears north CO moving south. Note EAs issue flash fratricide
alerts 8:05. However, alerts different, specific plan owner EA,
would expect.
plan called Attack-By-Fire mission tracks observed location DP2 (a decision
point hostile activity calls human decision). immediate alert appears
BN EA (because contingent fire mission BN plan) notifies user hostile
entities entered DP2, triggering contingency. AA-Diamond route, defined BN
plan, along adversaries likely approach. second alert notifies BN user (only)
activity route reports number entities detected.
EAs independently identify fratricide risk 8:05, would EAs two platoons
involved. message details two platoons facilitate quick response. Next, BN EA
issues distance alert detecting tracks 450m SE Recon PLT, subordinated
BN earlier plan (so BN EA alerts). tracks closer
earlier first-contact alert issued. Finally, out-of-position alert 07:58 indicates 2 PLT
1 km south route specified move mission. (The 2 PLT EA simultaneously alerts
one subordinate squads position.)

245

fiW ILKINS , L EE , & B ERRY

Number
78
33
3
2
17
5
5
9
36
19
3
1
6
0
3
4
7
6
1
0

Type Alert
Battalion EA - 41 missions
total alerts 13.5 hrs, 26 flash
proximity alerts
schedule alerts
position alerts
avenue approach alerts
triggers contingency alerts
at-monitored alerts
fratricide alerts
CO EA - 11 missions
total alerts 1.5 hrs, 14 flash
proximity alerts
schedule alerts
position alert
avenue approach alerts
triggers contingency alerts
at-monitored alerts
fratricide alerts
3 PLT, CO EA - 6 missions
total alerts 1.5 hrs, 2 flash
proximity alerts
schedule alert
alerts

Figure 7: Number alerts type echelon. number missions echelon
indicates size plan. last 90 minutes 13.5-hour scenario
simulated high fidelity. 78 Battalion alerts, 5 issued last
90 minutes.

6.8.2 P ERFORMANCE
EA Manager must handle 100 simultaneous intentions, determining import
dozen new facts second checking alert histories redundancy. clear
system could still alert user within 5 seconds new fact arriving,
required users. tested EA scenarios determine met requirements.
real time, EA generated alerts less 2 seconds receipt new fact. found
EA keep up, run 10x 20x real time. (There may
anomalous schedule alerts granularity issues high time expansion rates.) Thus, current
data rates close stressing system 10x real time processing average 24
events per second 90-minute simulation, double design requirement dozen
events per second. determine multiple degradation would occur
difficult detect degradation complex system. establish EA, using

246

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

BN EA 0803-0805
DAY 2, 08:04 IMMEDIATE notification:
Red activity DP2 triggers contingency Attack-By-Fire
DAY 2, 08:05 ROUTINE notification:
Enemy activity ave approach AA-Diamond (8 vehicles)
DAY 2, 08:05 FLASH notification:
Fratricide risk 2 Plt, Co moved position near 3 Plt, B
DAY 2, 08:05 IMMEDIATE notification:
Closest threat (tracked) closer- 450m SE Recon PLT
CO EA 0758-0805
DAY 2, 07:58 IMMEDIATE notification:
2 PLT position Move mission GL180837, Line-0003 (1000 m. N 2 PLT)
DAY 2, 08:05 FLASH notification:
Fratricide risk - 2 PLT position near 3-3-B-2-66

Figure 8: BN CO alerts around 0805 Day 2. one CO alert 8:03
8:06, time several BN alerts.

100-meter map granularity, easily sufficient plan monitoring SAIM data rates (running
Sun Ultra 60s Solaris Pentium-based machines Linux).2
Prior implementation EA, performance evaluation P RS determine
could handle input data rates required EA. briefly describe results many
reactive control systems based P RS, e.g., UM-PRS (Durfee et al., 1997). found
could handle 12 facts per second without unacceptably long delays, using randomly
generated facts two predicates fact invoked trivial processing (incrementing
counter). determined effects combinatorial P RS algorithms could avoided
batching new facts time control loop. modified control loop so,
performance improved remarkably. test case 2,000 facts posted 1 second, reduced
time respond first (any) fact 84%, reduced time respond facts 72%,
reduced memory usage 83%. Experiments showed fact batch size near 55 optimal
reducing response time, value roughly 25 100 near optimal.
6.8.3 L IMITATIONS
EA limited modeled, low fidelity models heuristics,
scenario-specific population knowledge base. many aspects plan execution
currently monitor, although monitoring framework easily extended
aspects plans modeled. selected capabilities mostly function available
input data available funding modeling. EA monitor much broader range plans
used scenarios. fact, monitor plan composed partial order
defined missions team members.
2. performance data Sun Ultra 60 Solaris. product company names mentioned
document trademarks respective holders.

247

fiW ILKINS , L EE , & B ERRY

7. Monitoring Robot Teams
using team robots cooperatively track pursue enemy entities detected. Unmanned air vehicles (UAVs) unmanned combat air vehicles (UCAVs) growing
research interest (Musliner, Durfee, & Shin, 1993), led availability cheaper platforms
easier use. SRI UV-robotics project focuses building system carry mission
objective using team UGVs UAVs. UGV UAV autonomous agent
view world, onboard reasoning capabilities, set resources (such power,
computation, unique set sensors). mission, may limited opportunity
communicate human controller. Therefore, agents must rely one another complete mission. research concentrates providing reactive regulation low-level sensor
systems vehicle controllers attain high-level mission goals, reacting unforeseen
circumstances taking advantage evolving situation.
UV-robotics domain resembles SUO domain requires rapid assessment
operational situation, determination viability existing plans control policies,
modification goals objectives based findings available resources.
Unlike SUO domain, decisions made (automated) agents
agents must negotiate solutions cooperative fashion. One challenges UVs (or
physically mobile agent) need reactive system. Perception of, knowledge about,
events actions physical world generally imprecise. perform tasks reliably
repeatedly requires dynamic monitoring.
SUO EA filters alerts avoid overloading human decision maker, must
filter alerts autonomous agent avoid overloading computational resources. Resources
always limited, particularly mobile platform, balance must struck usefulness
resources used. good example balance computational resources available
onboard robots. infinite number CPU cycles, would able generate large
numbers contingency plans evaluate simulation. However, 20%
CPU available robot control monitoring. Therefore, make design decisions
limit complexity control monitoring algorithms, possibly leaving extension
hooks anticipation greater processing power future.
7.1 UV-Robotics: Problem Description
long-term goal build, test validate architecture agent support multiple
goals dynamic environment cooperative mobile agents. Initial tasks teams include
surveillance reconnaissance, search destroy, pursuit, evasion. team robots would
expected perform tasks minimal supervision. Key components architecture
identified negotiation, strategic planning, execution tasking control, execution monitoring, recovery failure. challenge several robots working together
understand effects actions common team goals.
One challenge agent may working toward multiple, possibly conflicting, goals.
Thus, agent must constantly evaluating commitment actions, tasks, contribute
satisfaction goals. imprecision action sensory input taken
account, contribution toward satisfaction current goals plans assessed. addition,
user must kept informed progress team toward goals. user
want actively involved robot control, must able intervene necessary. Thus,
248

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

monitoring must ensure robust autonomous operation provide user window
operation team.
7.2 UV-Robotics: Architecture
SRI UV robot architecture based several years research SRI intelligent reactive
control, planning, negotiation, robot motion control (Wilkins & Myers, 1995; Myers, 1996;
Wilkins & Myers, 1998; Cheyer & Martin, 2001; Konolige & Myers, 1998). similar systems
SAFER (Holness, Karuppiah, & Ravela, 2001) SRTA (Vincent, Horling, Lesser, & Wagner,
2001) ability deal multiple goals evaluate discard goals. Figure 9
shows Multi-Level Agent Adaptation (MLAA) architecture. Clearly, monitoring pervasive
serves layer architecture well user (not shown).
Agents
Uses
Coordination

Policy Maker
Update/Ask Achievable

Query

Uses

Uses

Strategic Planner

TEAM
LEVEL
STRATEGIC
LEVEL

Update
Update

Resource Mgr.

EA Watchman
Insert Goal
Update

Query

EA Plan Initializer
EA Plan Manager

Update

TACTICAL
LEVEL
(PRS)

Process
Query

Task Blender
Primitive Action
Executor

Update

CONTROL
LEVEL

Low-level Actions

Figure 9: Multi-level Agent Adaptation Architecture.
coordination module receives goal requests human commander agents.
agent participates negotiation process determine role achieving goal.
negotiation, agent consults strategic planner create plan, plan segment (referred
recipe), assess recipes viability given current commitments. negotiation process
results goal recipe accepted, EA Manager (see Figure 3) instantiates
recipe initiates execution. Plan Initializer creates monitoring sentinels use
EA detect deviation recipe execution. execution recipe involves
activation tasks must blended active tasks maximize satisfaction
multiple goals. example, robot needs reach waypoint set time, take picture
location nearby, remain concealed, task blender modifies path planner runtime

249

fiW ILKINS , L EE , & B ERRY

achieve three tasks. Finally, lowest layer architecture interface
tasking architecture physical, simulated, robot controller.
monitoring Figure 9 done UV EA, created using architecture
representations SUO EA. modular design SUO EA made adaptation
straightforward. architecture internal EA agents depicted Figure 3 used little
modification, plan representation techniques monitoring plans, applying
VOI VOA calculations, issuing alerts. implementation initial UV EA (using code
SUO EA) done one person-week, impressive result given complexity
task. implementation included connecting new data sources, parsing messages,
determining implementing valuable monitoring algorithms, integrating plans
missions already defined, writing domain-specific VOI/VOA algorithms. Achieving
missions requires recalculating waypoints least every second using 20% CPU,
trade speed complexity waypoint calculation monitoring.
initial version UV EA detected first five types alerts listed Section 7.4.
7.3 UV-Robotics: Execution Monitoring Issues
initial monitoring issues apparent within UV-Robotics domain divided following four categories:
Monitoring completion of, progress toward, basic action (e.g., go waypoint)
Monitoring satisfaction completion multiple tasks robot currently
committed (e.g., pursue evader, patrol area, photograph target every 2 hours)
Monitoring activity unknown adversarial entities
Monitoring state communication network, robot, team members (e.g.,
communication network quality integrity, robot mobility, battery level)
Comparing ontology Section 4, first two categories involve general alert
types plan constraint violated constraint violation projected. However, exist different
levels abstraction often different temporal impact associated monitoring requirements. third category cleanly fits adversarial activity detected alert type triggers alerts
autonomous control user reporting. fourth category essential team-based
automated operation effective user interaction, involves policy constraint violated alerts,
reporting requirement alerts, system problem detected alerts.
7.4 UV-Robotics Execution Assistant
SUO EA, robot controller uses rich plan representation allow team members
share context communicate user. Primitive actions domain basic motion control communication requests physical robot. goal request user decomposed
individual agent plans (recipes) intentions aid interact agents. Recipes
composed partially ordered sequences tasks turn evolve primitive actions.
UV EA uses internal architecture similar SUO EA, shown Figure 3.
SUO EA, EA Manager continually applies Acts respond new goals facts posted

250

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

database. Acts correspond algorithms monitoring requirements layer
MLAA architecture. implement user alerts others implement autonomous control.
inputs UV EA plans execute, policy declarations, status reports (including
location, speed orientation) sensor suite, messages agents.
messages include status reports agents, reports mission success failure, shared information, requests help. Depending communication conditions policy restrictions,
agent may, may not, receive team members status reports (up-to-date locations)
friendly agents entities within visual range. Sentinels extracted plans policy
declarations, evaluated status reports received, may produce alerts. alerts
produced designed serve autonomous control via plan manager component,
user, although needs vary considerably.
initial experimentation, monitoring alerts derived regular state messages
team member. state message reports current location, velocity, attitude, sensor
imprecision agent. UV-Robotics Act similar SUO Act Figure 5 invoked every
time location report posted EA Manager database. postings happen several times
second, robot receives two messages every second sensors
two team member, based network conditions. receives similar state messages
entities within field vision. means team three robots agent
handling minimum least six state messages per second possibly many depending
environment. Also, messages agents sharing information,
currently considering except update state knowledge adversarial entities.
future, UV EA extended serve higher layers architecture
common SUO-EA alert types triggers.
initial implementation UV EA detects following types alerts. plan
implement additional monitoring project.
At-goal robot current waypoint
Stuck robot stuck current waypoint
Divergent robot diverging current waypoint
No-status robot longer reporting state
Target-visible robot target within sensor range
Lost-target robot lost track target pursue mission
Target-gone target moved assigned sector pursue mission
Collision robot anticipates hit nearby object next seconds
Handoff robot delegated/accepted task to/from another team member
UV EA uses techniques SUO EA (Section 6.7) estimating VOA
greatly reducing number low-value alerts. particular, UV EA keeps event histories
team member monitored. histories used determine value information
alerts, detect Stuck, Divergent, No-status alerts. example, history indicates
251

fiW ILKINS , L EE , & B ERRY

time robot location last progress check, current waypoint changed
robot away waypoint, value issuing Divergent alert
calculated.
value issuing alert takes consideration customizable latency thresholds repetition parameters, associated automated agent user.
agent parameters customized improve performance, others function behavior robot. example, value divergent alert function expected
velocity agent, agent traveling speed diverge quickly slow
agent. Similarly, change orientation influence value alert turning agent,
decreasing distance waypoint, may indeed making progress toward goal.
example monitoring used facilitate autonomous control illustrated
situation agent patrolling designated area. evader becomes visible, agent
receives Target-visible alert, type adversarial activity detected. Reacting either
high-priority policy pursue evaders explicit plan step, agent commits new goal
Pursue named-evader. goal achieved activation blending three tasks: Follow
named-evader, Relocate named-evader Search-for named-evader. Thus, robot maintain
pursuit even evader slips field vision.
users preferred strategy might report first sighting evader track
position, noting whenever disappears view. However, autonomous control requires notification likelihood recovering visual contact deteriorating robot searching
aimlessly. point, Target-Lost alert, type plan constraint violated, sent
agents EA Manager (and possibly user). example, policy exists reacting
type alert. cause pursuit goal dropped original Patrol plan resumed.
7.5 UV-Robotics: Evaluation
UV EA evaluated within SRI experimental framework called SRI Augmented
Reaility Simulator (SARS) (Ortiz et al., 2002). framework allows autonomous agent architecture software tested within entirely simulated environment, team physical
robots, mixture two. physical robots three pioneer robots equipped
GPS, shown Figure 10. Initial experiments carried simulated environment.
ran system entirely physical world team two cooperating robots searching
pursuing two independent evader robots. run environments composed
combination physical robots simulated entities illustrate scalability operation
UAVs. monitoring technology effective ensuring robust execution environments,
giving human operators insight state activity robot. insight facilitated debugging process moving simulated world physical robots
problems quickly identified.
SARS specifically designed simulate robots UAVs. produces output terms
sensors, actuators, resources (battery status, communication range, forth). SARS
computation simulation based precise 3D model environment. SARS precise
enough mix physical robots moving real world virtual evaders see
physical robots following virtual evader thus, name augmented reality. Using SARS,
able simulate team UGVs moving and/or UAVs flying larger space
available. team UAVs may larger available physical UAVs, well.

252

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Figure 10: SRI experimental Pioneer UGV.
initial UV EA implementation evaluated respect usefulness output,
value alerts, real-time performance realistic data streams. analysis shows
important situations alerted simulated executions, tests actual robots,
never exactly reproducible.
No-status alerts proven useful human user, indicate hardware software
problem robot network. problems recognized immediately (after customizable interval noncommunication passed) UV EA, take considerably longer
detect without alerts EA. customizable threshold (which currently defaults 5 seconds)
determines value alert robot reported state certain interval.
At-goal, Stuck, Divergent essential alerts autonomous-control agent-navigation
system, well useful human user wants monitor activity single
robot. Knowing robot reached goal point, stopped making
progress toward goal point, diverging planned route essential robust
autonomous operation. Customizable intervals control alerts. Subtleties domain
must considered avoid false alarms. example, robot may paused GPS
uncertainty GPS given time establish connection satellites. Also, robot
takes time turn thus regarded stuck divergent turns steering
adjustments time complete.
Target-visible, Target-lost, Handoff useful user autonomous controller, particularly task monitor pursue target. autonomous controller
requires immediate awareness loss sensor contact, adjust lower-level behavior
sensor parameters find evader. However, immediate alerts would unproductive
human user plan-level controller. customizable interval gives agent time relocate

253

fiW ILKINS , L EE , & B ERRY

evader, possibly avoiding alert human. types alerts time critical
evaluation domain.
Good tracking evader requires recalculating waypoints orientation least every second. UV EA able keep data inputs, detect occurrences types alerts
mentioned within 1 second, recalculate waypoint orientation twice per second. constraints difficult meet desktop machines, success UV EA
slower processors physical robot involved tradeoffs speed complexity waypoint
calculation monitoring. One useful technique using latest state report agent
one state report accumulated one cycle monitoring loop.
relative CPU access various agents processes became important. example,
adjust time quantum given scheduler EA processes ensure
process receiving messages various P RS agent processes EA executed frequently
enough waypoint recalculation. problem alleviated recent upgrades
onboard computer, could recur computationally expensive projections alerts
added EA.

8. Related Work
Plan generation received lot attention recently, rarely plans used control
monitor execution. Even rarely plans monitored involve activity hundreds
agents requiring tight coordination. Previous work execution monitoring focused
models executor performs planned actions (e.g., robot controller) usually
direct access internal state information. SUO domain, actions performed
external agents, usually humans, monitor access state executing agents.
indirect execution requires different monitoring techniques, executor must use incoming
messages determine status agents activities whether actions initiated
completed. Continuous Planning Execution Framework (Myers, 1999) addressed
indirect execution problem, system builds ideas. However, domain requires
monitoring many constraints greater time sensitivity. much higher rates
incoming data, must customize monitoring action generate appropriate, high-value
alerts.
Robot designers often avoided plan representations used AI plan-generation
community restrictive assumptions (Pollack & McCarthy, 1999; Arkin, 1998).
domains required expressive plan representation, combination Act formalism
hierarchical, object-oriented mission model proved sufficiently expressive, providing rich
set goal modalities encoding activity, including notions achievement, maintenance, testing,
conclusion, waiting.
SAM system (Kaminka & Tambe, 1999) ISI addresses similar problem: automated
pilot agents battlefield. SAM direct access local automated agent much lower
incoming data rates EA. addresses difficult problem plan recognition (of plans
friendly agents). humans involved, SAM need produce alerts
tailored human cognitive capabilities. Experiments SAM showed distributed monitoring
outperformed centralized monitoring using simpler algorithms. EAs SAIM use
distributed design, building insights.

254

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

recent work ISI produced monitoring agent named OVERSEER (Kaminka et al.,
2001), addresses problem similar ours: many geographically distributed team members coordinating plan dynamic environment. address problem modeling value
information user. OVERSEER use report-based monitoring approach adopted
EAs, must rely unmodifiable legacy agents sufficient bandwidth reliability communication. detailed analysis given Section 3.
NASAs Remote Agent Deep Space One (Jonsson et al., 2000; Muscettola et al., 1998)
autonomous execution monitoring spacecraft. domains many requirements NASAs, including core requirements concurrent temporal processes interacting
recoveries. However, NASAs remote agent fully automated, places heavier burden
module generates plans responses, alleviates burden address human
interaction issues considered VOA. Monitoring algorithms described detail, based procedural executive, assume similar procedural reactive
control system. NASAs domain, agents mechanical devices onboard spacecraft,
behaviors formally modeled. agents include humans, whose behaviors
easily modeled, EAs estimate value alerts interact human decision
maker, ultimately responsible control decisions.
Work rationale-based monitoring (Pollack & McCarthy, 1999; Veloso, Pollack, & Cox, 1998)
addressed problem monitoring world plan generation process (in causal-link
planners) see events invalidate plan generated. monitor subgoals, preconditions,
usability conditions, user preferences. monitored framework plans
executed, EAs additional capabilities, monitoring policy constraints applying mission-specific monitoring methods. rationale-based work address time-critical
monitoring execution time, monitoring large volumes incoming data, problem
alerting users without overwhelming them.
Doyle (1995) describes technique focus users attention anomalous system behavior,
particularly sensor behavior. work would applicable within lowest layer robotics
control module. uses causal modeling understand normal behavior sensor. Anomaly
detection based measures causal distance distance normal behavior. distance
measures related plan goals/actions; instead measure deviation typical behavior. user still relate reported sensor anomaly higher-level effects,
threat plan action execution. work provides monitoring technique specific sensor system types could easily incorporated monitoring framework. resulting
anomaly detection might give low-level alerts contributory factor reasoning process
higher-level alert classes.
Phoenix system uses concept plan envelope (Hart, Anderson, & Cohen, 1990)
represent priori expectations actions progress. Envelopes used action
executes time interrupted altered execution. envelope captures
range possible performance action successful execution. execution,
actual performance system recorded and, deviates predefined envelope,
possible failure detected. concept provides useful monitoring technique specific alerttypes, particularly concerning actions consume variable amount resources time.
Envelopes identify action performing better required allowing opportunistic alerts. Envelopes could easily incorporated monitoring framework additional
monitoring technique, could useful higher levels domains.
255

fiW ILKINS , L EE , & B ERRY

SUO EA provides capability currently exist, machineunderstandable representation plan battlefield. Currently, small-unit warfighters must
monitor incoming information relevance, manual notification team members.
SUO EA improves next-generation Army systems FBCB2 (Force XXI Battle
Command Brigade Below) (Garamone, 2001). Unlike FBCB2, EA alerts important
changes, automatically update areas monitored plan executed, dynamically change force structure, alert user many issues monitored
systems, fratricide risks, triggering contingencies, schedule, coordination
positional deviations plan.

9. Conclusions
characterized domain-independent challenges posed execution aid interactively
supports humans monitoring activity distributed teams cooperating agents, human
machine. important issues interactive monitoring adaptivity, plan- situationspecific monitoring, reactivity, high-value, user-appropriate alerts. showed properties
various domains influence challenges solutions. presented top-level
domain-independent categorization types alerts plan-based monitoring system might
issue user. different monitoring techniques generally required category often
domain specific task specific.
monitoring framework integrates various techniques uses concept
value alert control interaction user. conceptual framework facilitates integration new monitoring techniques provides domain-independent context future discussions monitoring systems. discussed various design tradeoffs must made
application monitoring framework domain (Sections 6.4 6.6).
use framework describe monitoring approach developed used implement Execution Assistants (EAs) two different dynamic, data-rich, real-world domains.
approach based rich plan representations, allow execution aid filter, interpret,
react large volume incoming information, alert user appropriately. expressive plan representation necessary representing SUO plans, must coordinate distributed
units, trigger contingencies, enforce variety constraints. equally important
representation monitorable machines meaningful humans. plan representation
mission model able model representative SUO scenario enough fidelity provide value (as judged domain experts) sufficient plans UV-Robotics
domain.
developed sufficiently rich plan representation extending existing plan representation
hierarchical, object-oriented mission model encodes knowledge primitive actions
mission-specific monitoring methods. SUO EA implements novel integration
hierarchical monitoring methods reactive control system. EA invokes specific
methods defined hierarchy appropriate points monitoring.
One central challenge, domains well medical monitoring, avoid overwhelming
user unwanted alerts and/or false alarms. define concepts value information
value giving alert principles determining give alert. describe
properties VOI VOA, criteria computing them, advantages qualitative reasoning

256

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

domains, successful use concepts applications. VOI VOA algorithms
must customizable user, plan, situation.
using asynchronous multiagent architecture extended version P RS reactive
control system, monitored execution SUO UV-Robotics plans acceptable
latency, given dozen incoming events per second. P RS extensions include temporal monitors efficiency improvements. Methods mission model used throughout SUO
monitoring process action-specific monitoring. evaluation showed plan-aware EAs
generated appropriate alerts timely manner without overwhelming user many alerts,
although small percentage alerts unwanted. shown utility using advanced AI planning execution technologies small unit operations.
application UV-Robotics showed generality SUO framework monitoring
concepts. implemented complex execution assistant one person-week, using code
SUO EA. UV EA uses plan representation basic architecture SUO
EA, inputs different tasks algorithms respond inputs
generate alerts.
Future work. obvious area future work SUO domain incorporation
planning assistant complete loop continuous planning execution. integration
already accomplished UV-Robotics domain, difficulty SUO domain
interface allows soldier interact effectively planning tool, using wearable
computer battlefield situation. Several research programs addressing problem,
mentioned Section 2.
Within scope execution monitoring, future work EAs could model detect
types plan deviations (such loss surprise additional types fratricide risks), project
future failures, provide higher-fidelity specialized reasoners, particularly terrain reasoning.
Additional theoretical work VOI VOA would support better quantitative estimates VOI
VOA. SUO mission model already method projecting failures low-fidelity
projection capability could easily added. UV-Robotics domain, plan implement
additional types alerts near future, extend UV EA serve higher layers
architecture common SUO EA alert types triggers. fragility
UV communication network hostile domains provides set interesting monitoring challenges may result incorporation specific monitoring-related tasks within cooperative
team missions. Monitoring strategies uncertain communication environments important
research challenge UV-Robotics domain. Additional alerts considered future implementation include monitoring movement entities geographical sectors mentioned
plan, monitoring deterioration improvement communication conditions, monitoring actions intentions coordinating team members facilitate cooperative behavior.

257

fiW ILKINS , L EE , & B ERRY

ACKNOWLEDGMENTS
SUO research supported Contract F30602-95-C-0235 Defense Advanced Research Projects Agency (from DARPA Planning Decision Aids Program DARPA
Small Unit Operations Program), supervision Air Force Research Laboratory Rome.
UCAV research supported Office Naval Research Unmanned Combat Air Vehicles Program (Contract N00014-00-C-0304). SRI International Artificial Intelligence Center
supported writing paper. thank subject matter experts assisted us. primary collaborators evaluators Kenneth Sharpe SAIC Richard Diehl Institute
Defense Analyses. used expertise Andy Fowles, Chris Kearns, David Miller
U.S. Army Dismounted Battlespace Battle Laboratory (DBBL) Fort Benning, CPT
Dan Ray Mounted Maneuver Battlespace Laboratory (MMBL) Fort Knox.

References
Arkin, R. (1998). Behavior-based robotics. MIT Press.
Ash, D., Gold, G., Seiver, A., & Hayes-Roth, B. (1993). Guaranteeing real-time response
limited resources. Artificial Intelligence Medicine, 5(1), 4966.
Athey, S., & Levin, J. (2001). value information monotone decision problems. Tech. rep.,
Stanford University, Stanford, CA.
Bell, B., Jr., E. S., & Brown, S. M. (2002). Making adversary decision modeling tractable intent
inference information fusion. Proc. 11th Conference Computer Generated
Forces Behavioral Representation, Orlando, FL.
Bonasso, R. P., Kortenkamp, D., & Whitney, T. (1997). Using robot control architecture automate space shuttle operations. Proc. 1997 National Conference Artificial Intelligence, pp. 949956, Providence, RI. AAAI Press.
Cheyer, A., & Martin, D. (2001). open agent architecture. Journal Autonomous Agents
Multi-Agent Systems, 4(1), 143148.
Coiera, E. (1993). Intelligent monitoring control dynamic physiological systems. Artificial
Intelligence Medicine, 5(1), 18.
Donlon, J., & Forbus, K. (1999). Using geographic information system qualitative spatial
reasoning trafficability. Proc. Qualitative Reasoning Workshop, Loch Awe,
Scotland.
Doyle, R. J. (1995). Determining loci anomalies using minimal causal models. Proc.
1995 International Joint Conference Artificial Intelligence, pp. 18211827, Montreal,
Quebec, Canada. Morgan Kaufmann Publishers Inc., San Francisco, CA.
Durfee, E. H., Huber, M. J., Kurnow, M., & Lee, J. (1997). TAIPE: Tactical assistants interaction
planning execution. Proc. Autonomous Agents 97. ACM Press, New York.
Ferguson, G., & Allen, J. (1998). TRIPS: integrated intelligent problem-solving assistant.
Proc. 1998 National Conference Artificial Intelligence, pp. 567572. AAAI Press.
Forbus, K. D. (2002). Towards Qualitative Modeling Battlespace. Technical report unpublished manuscript, Northwestern University, Evanston, IL.
258

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Franke, J., Brown, S. M., Bell, B., & Mendenhall, H. (2000). Enhancing teamwork teamlevel intent inference. Proc. 2000 International Conference Artificial Intelligence,
Las Vegas, NV.
Garamone, J. (2001). Digital world meets combat desert exercise. Tech. rep., American
Forces Information Service, www.defenselink.mil/news/Apr2001/.
Georgeff, M. P., & Ingrand, F. F. (1989). Decision-making embedded reasoning system.
Proc. 1989 International Joint Conference AI, pp. 972978, Detroit, MI. Morgan
Kaufmann Publishers Inc., San Francisco, CA.
Gil, Y., & Blythe, J. (1999). problem-solving method plan evaluation critiquing. Proc.
Tenth Banff Knowledge Acquisition Knowledge-Based Systems Workshop, Banff,
Alberta, Canada.
Grosz, B., & Kraus, S. (1999). evolution SharedPlans. Rao, A., & Wooldridge, M. (Eds.),
Foundations Theories Rational Agencies, pp. 227262.
Hart, D. M., Anderson, S. D., & Cohen, P. R. (1990). Envelopes vehicle improving
efficiency plan execution. Tech. rep. UM-CS-1990-021, University Massachusetts,
Amherst, MA.
Holness, G., Karuppiah, D.and Uppala, S., & Ravela, S. C. (2001). service paradigm reconfigurable agents. Proc. 2nd Workshop Infrastructure Agents, MAS, Scalable
MAS (Agents 2001), Montreal, Canada.
Horty, J., & Pollack, M. (2001). Evaluating new options context existing plans. Artificial
Intelligence, 127(2), 199220.
Jonsson, A., Morris, P., Muscettola, N., & Rajan, K. (2000). Planning interplanetary space:
Theory practice. Proc. 2000 International Conference AI Planning
Scheduling, pp. 177186, Breckenridge, CO. AAAI Press, Menlo Park, CA.
Kaminka, G., Pynadath, D., & Tambe, M. (2001). Monitoring deployed agent teams. Proc.
Autonomous Agents 01, pp. 308315, Montreal, Canada.
Kaminka, G., & Tambe, M. (1999). Experiments distributed centralized socially attentive
monitoring. Proc. Autonomous Agents 99, pp. 213220, Seattle, WA.
Konolige, K., & Myers, K. (1998). Artificial Intelligence Based Mobile Robots: Case studies
Successful Robot Systems, chap. Saphira architecture: design autonomy. MIT Press.
Koski, E., Makivirta, A., Sukuvaara, T., & Kari, A. (1990). Frequency reliability alarms
monitoring cardiac postoperative patients. International Journal Clinical Monitoring
Computing, 7, 129133.
Mouaddib, A.-I., & Zilberstein, S. (1995). Knowledge-based anytime computation. Proc.
1995 International Joint Conference Artificial Intelligence, pp. 775783. Morgan Kaufmann Publishers Inc., San Francisco, CA.
Muscettola, N., Nayak, P. P., Pell, B., & Williams, B. C. (1998). Remote agent: boldly go
AI system gone before. Artificial Intelligence, 103(1-2), 547.
Musliner, D. J., Durfee, E. H., & Shin, K. G. (1993). CIRCA: cooperative intelligent real-time
control architecture. IEEE Transactions Systems, Man, Cybernetics, 23(6).
259

fiW ILKINS , L EE , & B ERRY

Myers, K. L. (1996). procedural knowledge approach task-level control. Proc. 1996
International Conference AI Planning Systems. AAAI Press, Menlo Park, CA.
Myers, K. L., & Morley, D. N. (2001). Human directability agents. Proc. 1st International
Conference Knowledge Capture, Victoria, B.C.
Myers, K. L. (1999). CPEF: continuous planning execution framework. AI Magazine, 20,
6370.
Ortiz, C., Agno, A., Berry, P., & Vincent, R. (2002). Multilevel adaptation teams unmanned
air ground vehicles. First AIAA Unmanned Aerospace Vehicles, Systems, Technologies
Operations Conference.
Ortiz, C. L. (1999). Introspective elaborative processes rational agents. Annals Mathematics Artificial Intelligence, 25(12), 134.
Ortiz, C. L., & Hsu, E. (2002). Structured negotiation. Proc. First International Conference
Autonomous Agents Multiagent Systems.
Pollack, M. E., & McCarthy, C. (1999). Towards focused plan monitoring: technique
application mobile robots. Proc. IEEE International Symposium Computational
Intelligence Robotics Automation (CIRA), pp. 144149.
Rao, A. S., & Georgeff, M. P. (1995). BDI-agents: theory practice. Proc. First
Intl. Conference Multiagent Systems, San Francisco.
Schreckenghost, D., & et al. (2001). Adjustable control autonomy anomaly response spacebased life support systems. Proc. IJCAI Workshop Autonomy, Delegation,
Control.
Shannon, C. (1948). mathematical theory communication. Bell System Technical Journal, 27,
379423, 623656.
Tsien, C. (1997). Reducing false alarms intensive care unit: systematic comparison four
algorithms. Proc. American Medical Informatics Association Annual Fall Symposium.
Tsien, C., & Fackler, J. (1997). Poor prognosis existing monitors intensive care unit.
Critical Care Medicine, 25(4), 614619.
Veloso, M., Pollack, M., & Cox, M. (1998). Rationale-based monitoring planning dynamic
environments. Proc. 1998 International Conference AI Planning Systems, pp.
171180. AAAI Press, Menlo Park, CA.
Vincent, R., Horling, B., Lesser, V., & Wagner, T. (2001). Implementing soft real-time agent control.
Proceedings 5th International Conference Autonomous Agents. ACM Press.
Weigner, M. B., & Englund, C. E. (1990). Ergonomic human factors affecting anesthetic vigilance monitoring performance operating room environment. Anesthesiology, 73(5),
9951021.
Weinberger, E. (2002). theory pragmatic information application quasispecies
model biological evolution. Biosystems, 66(3), 105119.
Wilkins, D. E., & desJardins, M. (2001). call knowledge-based planning. AI Magazine, 22(1),
99115.
260

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Wilkins, D. E., & Myers, K. L. (1995). common knowledge representation plan generation
reactive execution. Journal Logic Computation, 5(6), 731761.
Wilkins, D. E., & Myers, K. L. (1998). multiagent planning architecture. Proc. 1998
International Conference AI Planning Systems, pp. 154162, Pittsburgh, PA.
Wilkins, D. E., Myers, K. L., Lowrance, J. D., & Wesley, L. P. (1995). Planning reacting
uncertain dynamic environments. Journal Experimental Theoretical AI, 7(1),
121152.

261


