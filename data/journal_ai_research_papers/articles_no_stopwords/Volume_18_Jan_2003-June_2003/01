Journal Artificial Intelligence Research 18 (2003) 45-81

Submitted 08/02; published 01/03

Monte Carlo Methods Tempo Tracking
Rhythm Quantization
Ali Taylan Cemgil
Bert Kappen

SNN, Geert Grooteplein 21 cpk1 - 231, University Nijmegen
NL 6525 EZ Nijmegen, Netherlands

cemgil@snn.kun.nl
bert@snn.kun.nl

Abstract

present probabilistic generative model timing deviations expressive music performance. structure proposed model equivalent switching state
space model. switch variables correspond discrete note locations musical
score. continuous hidden variables denote tempo. formulate two well known
music recognition problems, namely tempo tracking automatic transcription (rhythm
quantization) filtering maximum posteriori (MAP) state estimation tasks. Exact computation posterior features MAP state intractable model
class, introduce Monte Carlo methods integration optimization. compare
Markov Chain Monte Carlo (MCMC) methods (such Gibbs sampling, simulated annealing iterative improvement) sequential Monte Carlo methods (particle filters).
simulation results suggest better results sequential methods. methods
applied online batch scenarios tempo tracking transcription
thus potentially useful number music applications adaptive automatic
accompaniment, score typesetting music information retrieval.
1. Introduction
Automatic music transcription refers extraction human readable interpretable
description recording musical performance. Traditional music notation
description lists pitch levels (notes) corresponding timestamps.
Ideally, one would recover score directly audio signal. representation surface structure music would useful music information retrieval
(Music-IR) content description musical material large audio databases. However,
operating sampled audio data polyphonic acoustical signals, extraction
score-like description challenging auditory scene analysis task (Vercoe, Gardner,
& Scheirer, 1998).
paper, focus subproblem music-ir, assume exact timing
information notes available, example stream MIDI1 events digital
keyboard.
model tempo tracking transcription MIDI-like music representation
useful broad spectrum applications. One example automatic score typesetting,
1. Musical Instruments Digital Interface. standard communication protocol especially designed digital
instruments keyboards. time key pressed, MIDI keyboard generates short message
containing pitch key velocity. computer tag received message timestamp real-time
processing and/or recording file.

c 2003 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiCemgil & Kappen
musical analog word processing. Almost score typesetting applications provide
means automatic generation conventional music notation MIDI data.
conventional music notation, onset time note implicitly represented
cumulative sum durations previous notes. Durations encoded simple rational
numbers (e.g., quarter note, eighth note), consequently events music placed
discrete grid. basic task MIDI transcription associate onset times
discrete grid locations, i.e., quantization.
However, unless music performed mechanical precision, identification
correct association becomes dicult. due fact musicians introduce
intentional (and unintentional) deviations mechanical prescription. example
timing events deliberately delayed pushed. Moreover, tempo uctuate
slowing accelerating. fact, deviations natural aspects expressive
performance; absence these, music tends sound rather dull mechanical.
hand, deviations accounted transcription, resulting
scores often poor quality.
Robust fast quantization tempo tracking important requirement
interactive performance systems; applications \listen" performer generating
accompaniment improvisation real time (Raphael, 2001b; Thom, 2000). last,
models useful musicology systematic study characterization expressive
timing principled analysis existing performance data.
theoretical perspective, simultaneous quantization tempo tracking
\chicken-and-egg" problem: quantization depends upon intended tempo interpretation tempo interpretation depends upon quantization. Apparently, human
listeners resolve ambiguity (in cases) without effort. Even persons without
musical training able determine beat tempo rapidly. However,
still unclear precisely constitutes tempo relates perception
beat, rhythmical structure, pitch, style music etc. Tempo perceptual construct
cannot directly measured performance.
goal understanding tempo perception stimulated significant body research psychological computational modeling aspects tempo tracking
beat induction, e.g., see (Desain & Honing, 1994; Large & Jones, 1999; Toiviainen, 1999).
papers assume events presented onset list. Attempts made
deal directly audio signal (Goto & Muraoka, 1998; Scheirer, 1998; Dixon &
Cambouropoulos, 2000).
Another class tempo tracking models developed context interactive
performance systems score following. models make use prior knowledge
form annotated score (Dannenberg, 1984; Vercoe & Puckette, 1985). recently,
Raphael (2001b) demonstrated interactive real-time system follows solo player
schedules accompaniment events according player's tempo interpretation.
Tempo tracking crucial quantization, since one uniquely quantize onsets
without estimate tempo beat. converse, quantization
help identification correct tempo interpretation already noted Desain
Honing (1991). Here, one defines correct tempo one results simpler
quantization. However, schema never fully implemented practice due
computational complexity obtaining perceptually plausible quantization. Hence

46

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
quantization methods proposed literature either estimate tempo using simple
heuristics (Longuet-Higgins, 1987; Pressing & Lawrence, 1993; Agon, Assayag, Fineberg,
& Rueda, 1994) assume tempo known constant (Desain & Honing, 1991;
Cambouropoulos, 2000; Hamanaka, Goto, Asoh, & Otsu, 2001).
approach transcription tempo tracking probabilistic, i.e., Bayesian
modeling perspective. Cemgil et al. (2000), introduced probabilistic approach
perceptually realistic quantization. work assumed tempo known
estimated external procedure. tempo tracking, introduced Kalman filter
model (Cemgil, Kappen, Desain, & Honing, 2001). approach, modeled tempo
smoothly varying hidden state variable stochastic dynamical system.
current paper, integrate quantization tempo tracking. Basically,
model balances score complexity versus smoothness tempo deviations. correct tempo
interpretation results simple quantization correct quantization results
smooth tempo uctuation. essentially similar model proposed recently Raphael
(2001a). However, Raphael uses inference technique applies small models;
namely continuous hidden state one dimensional. severely restricts
models one consider. current paper, survey general widely used state-ofthe-art techniques inference.
outline paper follows: Section 2, propose probabilistic model
timing deviations expressive music performance. Given model, define tempo
tracking quantization inference posterior quantities. turn model
switching state space model computation exact probabilities becomes intractable. Section 3, introduce approximation techniques based simulation,
namely Markov Chain Monte Carlo (MCMC) sequential Monte Carlo (SMC) (Doucet,
de Freitas, & Gordon, 2001; Andrieu, de Freitas, Doucet, & Jordan, 2002). approaches
provide exible powerful inference methods successfully applied diverse fields applied sciences robotics (Fox, Burgard, & Thrun, 1999), aircraft
tracking (Gordon, Salmond, & Smith, 1993), computer vision (Isard & Blake, 1996), econometrics (Tanizaki, 2001). Finally present simulation results conclusions.

2. Model
Assume pianist improvising recording exact onset times key
presses performance. denote observed onset times y0 ; y1 ; y2 : : :
yk : : : yK compactly y0:K . neither access musical notation
piece know initial tempo started performance with. Moreover,
pianist allowed freely change tempo introduce expression. Given onset
time information y0:K , wish find score 1:K track tempo uctuations z0:K .
refine meaning z later.
problem apparently ill-posed. pianist allowed change tempo
arbitrarily possible assign \correct" score given performance.
words performance y0:K represented using suitable combination
arbitrary score arbitrary tempo trajectory. Fortunately, Bayes theorem provides
elegant principled guideline formulate problem. Given onsets y0:K ,
best score 1:K tempo trajectory z0:K derived posterior distribution

47

fiCemgil & Kappen
given
1
p(y j ; z )p( ; z )
p(y0:K ) 0:K 1:K 0:K 1:K 0:K
quantity, proportional product likelihood term p(y0:K j 1:K ; z0:K )
prior term p( 1:K ; z0:K ).
rhythm transcription tempo tracking, prior encodes background knowledge nature musical scores tempo deviations. example, construct prior prefers \simple" scores smooth tempo variations.
likelihood term relates tempo score actual observed onset times.
respect, likelihood model short time expressive timing deviations motor
errors introduced performer.

p( 1:K ; z0:K jy0:K ) =

/ c1
/ c2
/ : : :F
/ ck
EE

CC
F
EE
EE
CC

EE
EE
CC

EE
EE
CC

CC
E"
E"
#
!: : :

c0 EE

1

k 1

2

/ :::
/ 1
/ 2
BB
@@
BB
BB
@@
BB
BB
@@
BB
BB
@@
BB
B
@@
B!
B!
/ 1
/ 2
/ :::

0 B

0


y0



y1



y2

/ :::
CC Quantization
CC
HH
CC
HH
CC
HH
CC
H#
!
/ ck

1 HH

k

Score

/ k
/ :Tempo
::
Trajectory
@@
EE
@
EE
@@
EE
@@
EE
@@
E"
@
/ k
/ : :Noiseless
:
onsets

k 1E
/

/



k 1


:::

:::

Locations



yk 1

yk

: Observed
::
Onsets

Figure 1: Graphical Model. Square oval nodes correspond discrete continuous
variables respectively. text, sometimes refer continuous hidden
variables (k ; k ) zk . dependence c deterministic.
c, , hidden; onsets observed.

2.1 Score prior
define score 1:K , first introduce sequence quantization locations c0:K .
quantization location ck specifies score time k'th onset. let k denote
interval quantization locations two consecutive onsets
k = ck

ck 1

(1)

example consider conventional music notation
encodes score 1:3 =
[1 0:5 0:5]. Corresponding quantization locations c0:3 = [0 1 1:5 2].
One simple way defining prior distribution quantization locations p(ck ) specifying table probabilities ck mod 1 (the fraction ck ). example wish


48





fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
allow scores sixteenth notes triplets, define table probabilities
states c mod 1 = f0; 0:25; 0:5; 0:75g[f0; 0:33; 0:67g. Technically, resulting prior
p(ck ) periodic improper (since ck principle unbounded normalize
distribution).
However, number states ck mod 1 large, may dicult estimate
parameters prior reliably. situations propose \generic" prior follows:
define probability, k'th onset gets quantized location ck , p(ck ) /
exp( d(ck )) d(ck ) number significant digits binary expansion ck
mod 1. example d(1) = 0, d(1:5) = 1, d(7 + 9=32) = 5 etc. positive parameter
used penalize quantization locations require bits represented. Assuming
quantization locations onsets independent a-priori, (besides increasing
k, i.e., ck ck 1 ), P
prior probability sequence quantization locations given
p(c0:K ) / exp( K
k=0 d(ck )). assume c0 2 [0; 1). One check
) < p(
). generalize
prior prefers simpler notations, e.g., p(
prior subdivisions triplets quintiplets Appendix A.
Formally, given distribution c0:K , prior score 1:K given






6

p( 1:K ) =

X

c0:K











6

p( 1:K jc0:K )p(c0:K )

(2)

Since relationship c0:K 1:K deterministic, p( 1:K jc0:K ) degenerate
given c0:K ,

p( 1:K ) / exp



K
k
X
X

!

d( k0 )
(3)
=1 k0 =1
One might tempted specify prior directly 1:K get rid c0:K entirely.
However, simpler approach easy devise realistic priors. example,
consider sequence note durations [1 1=16 1 1 1 : : : ]. Assuming factorized prior
penalizes short note durations, rhythm would relatively high probability
whereas quite uncommon conventional music.
k

2.2 Tempo prior
represent tempo terms inverse, i.e., period, denote .
example tempo 120 beats per minute (bpm) corresponds = 60=120 = 0:5 seconds.
onset tempo changes unknown amount k . assume change k
iid N (0; Q ). 2 assume first order Gauss-Markov process tempo
k = k 1 + k
(4)
Eq. 4 defines distribution tempo sequences 0:K . Given tempo sequence,
\ideal" \intended" time k next onset given

k = k 1 + k k 1 + k

(5)

2. denote (scalar multivariate) Gaussian distribution p(x) mean vector covariance
1
matrix P N (; P )=
^ j2P j 2 exp( 21 (x )T P 1 (x )).

49

fiCemgil & Kappen
noise term k denotes amount accentuation (that deliberately playing
note ahead back time) without causing tempo changed. assume k
N (0; Q ). Ideal onsets actually observed \noisy" onsets related

yk = k + k

(6)

noise term k models small scale expressive deviations motor errors timing individual notes. paper assume k Gaussian distribution parameterized
N (0; R).
initial tempo distribution p(0 ) specifies range reasonable tempi given
Gaussian broad variance. assume uninformative ( at) prior 0 .
conditional independence structure given graphical model Figure 1. Table 1
shows possible realization model.
note model particular instance well known switching state space
model (also known conditionally linear dynamical system, jump Markov linear system,
switching Kalman filter) (See, e.g., Bar-Shalom & Li, 1993; Doucet & Andrieu, 2001;
Murphy, 2002).

k 0
1
2
3
k
...
ck 0 1/2 3/2 2 . . .
k 0.5 0.6 0.7 . . . . . .
k 0 0.25 0.85 1.20 . . .
yk 0 0.23 0.88 1.24 . . .


(





(

Table 1: possible realization model: ritardando. clarity assume = 0.
following sections, sometimes refer use zk = (k ; k )T refer z0:K
tempo trajectory. Given definition, compactly represent Eq. 4 Eq. 5

zk =



1 k
0 1



zk 1 + k

(7)

k = (k ; k ).

2.3 Extensions
several possible extensions basic parameterization. example, one could
represent period logarithmic scale. warping ensures positivity seems
perceptually plausible since promotes equal relative changes tempo rather
absolute scale (Grubb, 1998; Cemgil et al., 2001). Although resulting model
becomes nonlinear, approximated fairly well extended Kalman filter (BarShalom & Li, 1993).
simple random walk model tempo uctuations Eq. 7 seems
realistic. would expect tempo deviations structured smoother.

50

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
dynamical system framework smooth deviations modeled increasing
dimensionality z include higher order \inertia" variables (Cemgil et al., 2001).
example consider following model,

0
k
B
1;k
B
B
2;k
B
B
@ ...

1;k

1
0
10
1 k k 0 : : : 0
k 1
C
B
C
B
0 1 0 0 : : : 0 C B 1;k 1
C
B
C
B
C
B
2;k 1
= B0 0
C
C
B
C
B
C
B
.
.
..

@ .. ..
A@

.
0 0

1;k 1

1
C
C
C
+ k
C
C


(8)

choose particular parameterization wish interpret 1 slowly
varying \average" tempo 2 temporary change tempo. model useful
situations performer uctuates around almost constant tempo; random
walk model sucient case forgets initial values. Additional state
variables 3 ; : : : ; 1 act additional \memory" elements. choosing parameter
matrix noise covariance matrix Q, one model rich range temporal structures
expressive timing deviations.
score prior improved using richer model. example allow
different time signatures alternative rhythmic subdivisions, one introduce additional
hidden variables (See Cemgil et al. (2000) Appendix A) use Markov chain (Raphael,
2001a). Potentially, extensions make easier capture additional structure musical
rhythm (such \weak" positions followed likely \strong" positions).
hand, number model parameters rapidly increases one
cautious order avoid overfitting.
score typesetting, need quantize note durations well, i.e., associate note
offsets quantization locations. simple way accomplishing define
indicator sequence u0:K identifies whether yk onset (uk = 1) offset (uk =
0). Given uk , redefine observation model p(yk jk ; uk ) = uk N (0; R) + (1
uk )N (0; Roff ) Roff observation noise associated offsets. typical model
would Roff R. Roff ! 1, offsets would effect tempo process.
Moreover, since uk always observed, extension requires simple lookup.
principle, one must allow arbitrary long intervals onsets, hence k
drawn infinite (but discrete) set. subsequent derivations, assume
number possible intervals fixed a-priori. Given estimate zk 1 observation yk ,
almost virtually infinite number choices k almost zero probability
easy identify candidates would significant probability mass.
Conceptually, listed extensions easy incorporate model
none introduces fundamental computational diculty basic problems
quantization tempo tracking.

51

fiCemgil & Kappen
2.4 Problem Definition
Given model, define rhythm transcription, i.e., quantization MAP state estimation problem
1: K = argmax p( 1:K jy0:K )
(9)
p( 1:K jy0:K ) =

Z 1:K

dz0:K p( 1:K ; z0:K jy0:K )

tempo tracking filtering problem
X
zk = argmax p( 1:k ; zk jy0:k )
zk

1:k

(10)

quantization problem smoothing problem: wish find likely score

1:K given onsets performance. useful \oine" applications
score typesetting.
real-time interaction, need online estimate tempo/beat zk .
information carried forth filtering density p( 1:k ; zk jy0:k ) Eq.10.
definition best tempo zk maximum somewhat arbitrary. Depending upon
requirements application, P
one make use features filtering
density. example, variance 1:k p( 1:k ; zk jy0:k ) used estimate \amount
confidence" tempo interpretation arg maxzk ; 1:k p( 1:k ; zk jy0:k ) estimate
likely score-tempo pair far.
Unfortunately, quantities Eq. 9 Eq. 10 intractable due explosion
number mixture components required represent exact posterior step k
(See Figure 2). example, calculate exact posterior Eq. 9 need evaluate
following expression:
Z
1
dz0:K p(y0:K jz0:K ; 1:K )p(z0:K j 1:K )p( 1:K )
(11)
p( 1:K jy0:K ) =

Z
1
= p(y0:K j 1:K )p( 1:K )
(12)
Z
P
normalization constant given Z = p(y0:K ) = 1:K p(y0:K j 1:K )p( 1:K ).
trajectory 1:K , integral z0:K computed stepwise k Kalman
filter (See appendix B.1). However, find MAP state Eq. 11, need evaluate
p(y0:K j 1:K ) independently exponentially many trajectories. Consequently,
quantization problem Eq. 9 solved approximately.
accurate approximation, wish exploit inherent independence structure
exact posterior. Unfortunately, since z c integrated over, k become coupled
general p( 1:K jy0:K ) possess conditional independence structure (e.g.,
Markov chain) would facilitate ecient calculation. Consequently, resort
numerical approximation techniques.

3. Monte Carlo Simulation
Consider high dimensional probability distribution
1
p(x) = p (x)
Z

52

(13)

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

0.6

0.6

0.4

0.4

0.2

0.2

2.2769

0

0

4.6765
10.5474





2.6972

0.2

0.2
3.2828
5.0002

0.4

0.4

0.6

0.8
0.5

0.6

0

0.5

1

1.5


2

2.5

3

3.5

(a)

0.8
0.5

0

0.5

1

3

3.5

1.5


2

2.5

3

3.5

(b)

0.6

0.4
0.4593
0.2

7.9036
10.3422
6.6343



0

0.2

10.1982
0.76292
2.393

0.4

2.7957

0.6

0.8
0.5

Figure 2:

0

0.5

1

1.5


2

2.5

(c)

Example demonstrating explosion number components represent
exact posterior. Ellipses denote conditional marginals p(k ; !k jc0:k ; y0:k ). (We show
period logarithmic scale !k = log2 k ). toy example, assume
score consists notes length , i.e., k either 1=2 1.
(a) start unimodal posterior p(0 ; !0 jc0 ; y0 ), e.g., Gaussian centered
(; !) = (0; 0). Since assume score consist eight- quarter
notes, i.e., k 2 f1=2; 1g. predictive distribution p(1 ; !1jc0:1; y0) bimodal
modes centered (0:5; 0) (1; 0) respectively (shown dashed contour
line). next observation y1 observed (shown dashed vertical line around
= 0:5), predictive distribution updated yield p(1 ; !1 jc0:1 ; y0:1 ). numbers
denote respective log-posterior weight mixture component. (b) predictive
distribution p(2 ; !2jc0:1; y0:1) step k = 2 4 modes, two component
p(1; !1jc0:1; y0:1). (c) number components grows exponentially k.




53

(

fiCemgil & Kappen
R
normalization constant Z = dxp (x) known p (x) evaluated
particular x. Suppose want estimate expectation function f (x)
distribution p(x) denoted
Z

hf (x)ip(x) = dxf (x)p(x)
e.g., mean x p(x) given hxi. intractable integration approximated average find N points x(i) , = 1 : : : N p(x)

hf (x)ip(x) N1

N
X

=1



f (x(i) )

(14)

x(i) generated independently sampling p(x), shown N
approaches infinity, approximation becomes exact.
However, generating independent samples p(x) dicult task high dimensions usually easier generate dependent samples, generate x(i+1)
making use x(i) . somewhat surprising, even x(i) x(i+1) correlated
(and provided ergodicity conditions satisfied), Eq. 14 remains still valid estimated
quantities converge true values number samples N goes infinity.
sequence dependent samples x(i) generated using Markov chain
stationary distribution p(x). chain defined collection transition probabilities, i.e., transition kernel (x(i+1) jx(i) ). definition kernel implicit,
sense one defines procedure generate x(i+1) given x(i) . Metropolis
algorithm (Metropolis & Ulam, 1949; Metropolis, Rosenbluth, Rosenbluth, Teller, & Teller,
1953) provides simple way defining ergodic kernel desired stationary
distribution p(x). Suppose sample x(i) . candidate x0 generated sampling symmetric proposal distribution q(x0 jx(i) ) (for example Gaussian centered
x(i) ). candidate x0 accepted next sample x(i+1) p(x0 ) > p(x(i) ). x0
lower probability, still accepted, probability p(x0 )=p(x(i) ).
algorithm initialized generating first sample x(0) according (arbitrary)
proposal distribution.
However given transition kernel , hard assess time required converge
stationary distribution practice one run simulation large
number samples obtained, (see e.g., Roberts & Rosenthal, 1998). choice
proposal distribution q critical. poor choice may lead rejection
many candidates x0 hence resulting slow convergence stationary distribution.
large class probability models, full posterior p(x) intractable, one
still eciently compute marginals form p(xk jx k ), x k = x1 : : : xk 1 ; xk+1 ; : : : xK
exactly. case one apply specialized Markov chain Monte Carlo (MCMC)
algorithm, Gibbs sampler given below.
1. Initialize x(0)
1:K sampling proposal q(x1:K )
2. = 0 : : : N

1

54

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

k = 1; : : : ; K , Sample

(i)
x(ki+1) p(xk jx(1:i+1)
(15)
k 1 ; xk+1:K )
contrast Metropolis algorithm, new candidate vector x0 ,
Gibbs sampler uses exact marginal p(xk jx k ) proposal distribution.
step, sampler updates one coordinate current state x, namely xk ,
new candidate guaranteed accepted.
Note that, principle don't need sample xk sequentially, i.e., choose k
randomly provided slice visited equally often limit. However, deterministic scan algorithm k = 1; : : : K , provides important time savings type
models consider here.
3.1 Simulated Annealing Iterative Improvement
shift focus sampling MAP state estimation. principle, one use
samples generated sampling algorithm (Metropolis-Hastings Gibbs) estimate
MAP state x p(x) argmax p(x(i) ). However, unless posterior much
i=1:N
concentrated around MAP state, sampler may visit x even though samples
x(i) obtained stationary distribution. case, problem simply
reformulated sample p(x) distribution concentrated local
maxima p(x). One class distributions given pj (x) / p(x)j . sequence
exponents 1 < 2 < < j < : : : called cooling schedule annealing schedule
owing inverse temperature interpretation j statistical mechanics, hence
name Simulated Annealing (SA) (Aarts & van Laarhoven, 1985). j ! 1 suciently
slowly j , cascade MCMC samplers stationary distribution pj (x)
guaranteed (in limit) converge global maximum p(x). Unfortunately,
convergence result hold, cooling schedule must go slowly (in fact, logarithmically)
infinity. practice, faster cooling schedules must employed.
Iterative improvement (II) (Aarts & van Laarhoven, 1985) heuristic simulated annealing algorithm fast cooling schedule. fact, j = 1 j . eventual
advantage greedy algorithm converges iterations local maximum. restarting many times different initial configurations x, one hopes find
different local maxima p(x) eventually visit MAP state x . practice, using
II heuristic one may find better solutions SA limited computation time.
implementation point view, trivial convert MCMC code SA (or II)
code. example, consider Gibbs sampler. implement SA, need construct
cascade Gibbs samplers, stationary distribution p(x)j . exact one time
slice marginal distribution p(xk jx k )j . So, SA samples actual
(temperature=1) marginal p(xk jx k ) raised power j .
3.2 Switching State Space Model MAP Estimation
solve rhythm quantization problem, need calculate MAP state
posterior Eq. 11
p( 1:K jy0:K )

Z

/ p( 1:K ) dz0:K p(y0:K jz0:K ; 1:K )p(z0:K j 1:K )
55

(16)

fiCemgil & Kappen
combinatorial optimization problem: seek maximum function p( 1:K jy0:K )
associates number discrete configurations 1:K . Since feasible
visit exponentially many configurations find maximizing configuration
1: K , resort stochastic search algorithms simulated annealing (SA)
iterative improvement (II). Due strong relationship Gibbs sampler
SA (or II), first review Gibbs sampler switching state space model.
first important observation that, conditioned 1:K , model becomes linear
state space model integration z0:K computed analytically using Kalman
filtering equations. Consequently, one sample 1:K integrate z .
analytical marginalization, called Rao-Blackwellization (Casella & Robert, 1996), improves
eciency sampler (e.g., see Doucet, de Freitas, Murphy, & Russell, 2000a).
Suppose switch variable k distinct states wish
) ; = 1 : : : N g. naive implementation
generate N samples (i.e trajectories) f 1:(iK
Gibbs sampler requires step k run Kalman filter times whole
observation sequence y0:K compute proposal p( k j 1:(ik) 1 ; k(i+1:1)K ; y0:K ). would
result algorithm time complexity O(NK 2 ) prohibitively slow K
large. Carter Kohn (1996) proposed much time ecient deterministic scan
Gibbs sampler circumvents need run Kalman filtering equations
step k whole observation sequence y0:K . See (Doucet & Andrieu, 2001; Murphy,
2002).
method based observation proposal distribution p( k j )
factorized product terms either depend past observations y0:k
future observations yk+1:K . contribution future computed a-priori
backward filtering pass. Subsequently, proposal computed samples k(i)
generated forward pass. sampling distribution given

p( k j k ; y0:K ) / p( k j k )p(y0:K j 1:K )

(17)

first term proportional joint prior p( k j k ) / p( k ; k ). second
term decomposed

p(y0:K j 1:K ) =
=

Z
Z

dzk p(yk+1:K jy0:k ; zk ; 1:K )p(y0:k ; zk j 1:K )

(18)

dzk p(yk+1:K jzk ; k+1:K )p(y0:k ; zk j 1:k )

(19)

terms (unnormalized) Gaussian potentials hence integral evaluated
analytically. term p(yk+1:K jzk ; k+1:K ) unnormalized Gaussian potential zk
computed backwards filtering. second term filtering distribution
p(zk jy0:k ; 1:k ) scaled likelihood p(y0:k j 1:k ) computed forward
filtering. outline algorithm given below, see appendix B.1 details.
1. Initialize 1:(0)K sampling proposal q( 1:K )
2. = 1 : : : N

k = K 1; : : : ; 0,
56

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization



{ Compute p(yk+1:K jzk ; k(i+1:1)K )
k = 1; : : : ; K ,
{ = 1 : : :
Compute proposal
p( k = sj ) / p( k = s; k )

Z

dzk p(y0:k ; zk j 1:(ik) 1 ; k = s)p(yk+1:K jzk ; k(i+1:1)K )

{ Sample k(i) p( k j )
resulting algorithm time complexity O(NKS ), important saving terms
time. However, space complexity increases O(1) O(K ) since expectations
computed backward pass need stored.
step, Gibbs sampler generates sample single time slice k.
certain types \sticky" models, dependence k k+1
strong, sampler may get stuck one configuration, moving rarely. due
fact singleton ips end low probability configurations due strong
dependence adjacent time slices. example, consider quantization model
two configurations [: : : k ; k+1 : : : ] = [: : : 1; 1 : : : ] [: : : 3=2; 1=2 : : : ]. updating
single slice, may dicult move two configurations. Consider
intermediate configuration [: : : 3=2; 1 : : : ]. Since duration ( k + k+1 ) increases,
future quantization locations ck:K shifted 1=2. may correspond score
heavily penalized prior, thus \blocking" path.
allow sampler move freely, i.e., allow global jumps, one
sample L slices jointly. case proposal distribution takes form
p( k:k+L 1j ) / p( k:k+L 1; (k:k+L 1))
Z
dzk+L 1 p(y0:k+L 1; zk+L 1 j 1:(ik) 1 ; k:k+L 1)p(yk+L:K jzk+L 1 ; k(i+L1):K )
Similar one slice case, terms integral unnormalized Gaussian potentials
(on zk+L 1 ) representing contribution past future observations. Since k:k+L 1
L states, resulting time complexity generating N samples O(NKS L ), thus
practice L must kept rather small. One remedy would use Metropolis-Hastings
algorithm heuristic proposal distribution q( k:k+L 1jy0:K ) circumvent exact calculation, obvious construct q.
One shortcoming Gibbs sampler (and related MCMC methods)
algorithm standard form inherently oine; need access
observations y0:K start simulation. certain applications, e.g., automatic score
typesetting, batch algorithm might still feasible. However scenarios require
real-time interaction, interactive music performance tempo tracking, online
methods must used.
3.3 Sequential Monte Carlo
Sequential Monte Carlo, a.k.a. particle filtering, powerful alternative MCMC
generating samples target posterior distribution. SMC especially suitable
application dynamical systems, observations arrive sequentially.

57

fiCemgil & Kappen
basic idea SMC represent posterior p(x0:k 1 jy0:k 1 ) time k 1
(possibly weighted) set samples fx(0:i)k 1 ; = 1 : : : N g extend representation
f(x(0:i)k 1 ; x(ki) ); = 1 : : : N g observation yk becomes available time k.
common practice use importance sampling.
3.3.1 Importance Sampling

Consider high dimensional probability distribution p(x) = p (x)=Z unknown
normalization constant. Suppose given proposal distribution q(x) close
p(x) high probability regions distributions fairly overlap.
P generate
independent samples, i.e., particles, x(i) proposal q(x) Ni=1 (x
x(i) )=N . approximate
1 p (x)
q(x)
(20)
p(x) =
Z q(x)
N

X
Z1 pq((xx)) N1 (x x(i) )
(21)
i=1
N
X
w(i)

(22)
PN (j) (x x(i) )
j =1 w
i=1
w(i) = p (x(i) )=q(x(i) ) importance weights. One interpret w(i) correction factors compensate fact sampled \incorrect" distribution q(x). Given approximation Eq.22 estimate expectations weighted
averages
N
X
hf (x)ip(x)
w~ (i) f (x(i) )

w~ (i) = w(i) =

PN
j

=1

(23)



=1 w

(j ) normalized importance weights.

3.3.2 Sequential Importance Sampling

wish apply importance sampling dynamical model

p(x0:K jy0:K )

/

K

k

=0

p(yk jxk )p(xk jx0:k 1 )

(24)

x = fz; g. principle one naively apply standard importance sampling using
arbitrary proposal distribution q(x0:K ). However finding good proposal distribution
hard K 1. key idea sequential importance sampling sequential
construction proposal distribution, possibly using available observations y0:k , i.e.,

q(x0:K jy0:K ) =

K

k

=0

58

q(xk jx0:k 1 ; y0:k )

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
Given sequentially constructed proposal distribution, one compute importance
weight recursively

p (x(0:i)k jy0:k ) p(yk jx(ki) )p(x(ki) jx(0:i)k 1 ; y0:k 1 ) p(y0:k 1 jx(0:i)k 1 )p(x(0:i)k 1 )
=
(25)
q(x(0:i)k jy0:k )
q(x(ki) jx(0:i)k 1 y0:k )
q(x(0:i)k 1 jy0:k 1 )
p(yk jx(ki) )p(x(ki) jx(0:i)k 1 ; y0:k 1 ) (i)
=
wk 1
(26)
q(x(ki) jx(0:i)k 1 y0:k )

wk(i) =

sequential update schema potentially accurate naive importance sampling since step k, one generate particle fairly accurate proposal
distribution takes current observation yk account. natural choice
proposal distribution filtering distribution given

q(xk jx(0:i)k 1 y0:k ) = p(xk jx(0:i)k 1 ; y0:k )

(27)

case weight update rule Eq. 26 simplifies

wk(i) = p(yk jx(0:i)k 1 )wk(i) 1
fact, provided proposal distribution q constructed sequentially past sampled trajectories updated, filtering distribution optimal choice sense
minimizing variance importance weights w(i) (Doucet, Godsill, & Andrieu, 2000b).
Note Eq. 27 identical proposal distribution used Gibbs sampling k = K
(Eq 15). k < K , SMC proposal take future observations account;
introduce discount factors wk compensate sampling wrong distribution.
3.3.3 Selection

Unfortunately, sequential importance sampling may degenerate, fact,
shown variance wk(i) increases k. practice, iterations
algorithm, one particle almost probability mass
computation time wasted updating particles negligible probability.
avoid undesired degeneracy problem, several heuristic approaches proposed
literature. basic idea duplicate discard particles according
normalized importance weights. selection procedure deterministic stochastic. Deterministic selection usually greedy; one chooses N particles highest
importance weights. stochastic case, called resampling, particles drawn
probability proportional importance weight wk(i) . Recall normalized weights
fw~k(i) ; = 1 : : : N g interpreted discrete distribution particle labels (i).

3.4 SMC Switching State Space Model
SIS algorithm directly applied switching state space model sampling
directly xk = (zk ; k ). However, particulate approximation quite poor z

59

fiCemgil & Kappen
0.6

0.4

0.2



0

0.2

0.4

0.6

0.8
0.5

0

0.5

1

1.5


2

2.5

3

3.5

Figure 3: Outline algorithm. ellipses correspond conditionals
p(zk j k(i) ; y0:k ). Vertical dotted lines denote observations yk . step
k, particles low likelihood discarded. Surviving particles linked
parents.

high dimensional. Hence, many particles may needed accurately represent
posterior.
Similar MCMC methods introduced previous section, eciency
improved analytically integrating z0:k sampling 1:k . fact,
form Rao-Blackwellization reported give superior results compared standard
particle filtering z sampled jointly (Chen & Liu, 2000; Doucet et al.,
2000b). improvement perhaps surprising, since importance sampling performs
best sampled space low dimensional.
algorithm intuitive interpretation terms randomized breadth first tree
search procedure: new step k, expand N kernels obtain N new kernels.
Consequently, avoid explosion number branches, select N N
branches proportional likelihood, See Figure 3. derivation technical details
algorithm given Appendix C.
tree search interpretation immediately suggests deterministic version algorithm one selects (without replacement) N branches highest weight.
refer method greedy filter (GF). method known split-track
filter (Chen & Liu, 2000) closely related Multiple Hypothesis Tracking (MHT)
(Bar-Shalom & Fortmann, 1988). One problem greedy selection schema GF
loss particle diversity. Even particles initialized different locations z0 ,
(e.g., different initial tempi), mainly due discrete nature state space k ,
particles become identical steps k. Consequently, results
improved increasing number particles N . Nevertheless,
particles used, say e.g., real time application, GF may still viable choice.

60

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

(i) optimal.
Figure 4: hypothetical situation neither two particles 1:5
would obtain eventually higher likelihood configuration interchanging 3
particles.
3.5 SMC estimation MAP trajectory
MCMC, SMC sampling method. Hence comments made Section 3.1
) jy )
eventual suboptimality estimating MAP trajectory particles arg max p( 1:(iK
0:K
apply here. hypothetical situation shown figure 4.
One obvious solution employ SA \trick" raise proposal distribution
power p( k j) . However, proposal peaked time
slice. Consequently, particles become identical time algorithm
eventually degenerates greedy filtering.
algorithm estimating MAP trajectory set SMC samples recently
proposed literature (Godsill, Doucet, & West, 2001). algorithm relies
observation particles x(ki) sampled forward pass, one left
N
discrete distribution defined (discrete) supportN
X1:K = K
k=1 Xk . Xk denotes
support filtering distribution time k Cartesian product

sets. Formally, Xk set distinct samples time k given Xk = fx(ki) g.
distribution p(X1:K jy1:K )3 Markovian original state transition model
Markovian, i.e., posterior represented exactly
p(X1:K jy1:K ) /

K


p(yk jXk )p(Xk jXk 1 )
=1
Consequently, one find best MAP trajectory arg max p(X1:K ) using algorithm
analogous Viterbi algorithm hidden Markov models (Rabiner, 1989).
However, idea carry directly case one applies Rao-Blackwellization. general, subset hidden variables
NisK integrated out,Sall time
slices posterior p( 1:K jy1:k ) coupled, 1:K = k=1 k k = f k(i) g.
One still employ chain approximation run Viterbi, (e.g., Cemgil & Kappen,
2002), guarantee find arg max p( 1:K jy1:k ).
hand, k(i) drawn discrete set, several particles become
identical k usually small cardinality compared number particles
N . Consequently, becomes feasible employ SA II reduced state space 1:K ;
possibly using proposal distribution extends several time slices L.
k

3. slight abuse notation use symbol Xk set general element used
argument density, p(yk jXk ) means p(yk jxk ) s.t. xk 2 Xk

61

fiCemgil & Kappen
) ; = 1 : : : N g,
practice, finding MAP solution particle set f 1:(iK
) )p( (i) ) apply iterative
propose find best trajectory = arg maxi p(y0:K j 1:(iK
1:K

improvement starting initial configuration 1:(iK) .

4. Simulations
compared inference methods terms quality solution execution time. tests carried artificial real data.
Given true notation 1:true
K , measure quality solution terms
log-likelihood difference
L = log

p(y0:K j 1:K )p( 1:K )
true
p(y0:K j 1:true
K )p( 1:K )

terms edit distance

e( 1:K ) =

K
X

(1 ( k

ktrue ))

=1
edit distance e( 1:K ) gives simply number notes quantized wrongly.
k

4.1 Artificial data: Clave pattern
(c = [1, 2, 4, 5:5,
synthetic example repeating \son-clave" pattern
7 : : : ]) uctuating tempo. repeat pattern 6 times obtain score 1:K
K = 30.
syncopated rhythms usually hard transcribe make dicult track
tempo even experienced human listeners. Moreover, since onsets absent
prominent beat locations, standard beat tracking algorithms usually loose track.
Given score 1:K , generated 100 observation sequences y0:K sampling
tempo model Eq. 7. parameterized observation noise variance4
Q = k Qa + Qb . formulation, variance depends length interval
consecutive onsets; longer notes score allow tempo timing
uctuation. tests clave example used prior model ects
true source statistics, instead, used generic prior model defined Section 2.1
= 1.
example cases sampled score (clave pattern). However, due
use generic prior (that capture exact source statistics well)
relatively broad noise model, MAP trajectory 1: K given y0:K always identical
;i
original clave pattern. i'th example, defined \ground truth" 1:true
K
highest likelihood solution found using sampling technique independent
run. Although definition ground truth introduces bias, found
exercise realistic well discriminative among various methods
compared to, e.g.,, using dataset essentially shorter sequences exact MAP
7

7



>









>

4. noise covariance parameters R = 0:022 , Qa = 0:062 Qb = 0:022 . 2 2 identity
matrix.

62

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
trajectory computed exhaustive enumeration. wish stress main
aim simulations synthetic dataset compare effectiveness different inference
techniques; postpone actual test whether model good one simulations
real data.
tested MCMC methods, namely Gibbs sampling (Gibbs), simulated annealing (SA) iterative improvement (II) one two time slice optimal proposal
10 50 sweeps. onset yk , optimal proposal p( k j) computed
always fixed set, = f0; 1=4; 2=4 : : : 3g. Figure 6 shows typical run MCMC.
Similarly, implemented SMC N = f1; 5; 10; 50; 100g particles.
selection schema random drawing optimal proposal p( k j) computed using
one two time slices. special case greedy filtering (GF), i.e., N = 1,
selected switch maximum probability. example run shown Figure 5.
observe average SMC results superior MCMC (Figure 7). observe
that, increasing number sweeps MCMC improve solution significantly.
hand, increasing number particles seems improve quality
SMC solution monotonically. Moreover, results suggest sampling two time
slices jointly (with exception SA ) big effect. GF outperforms
particle filter 5 particles draws randomly proposal. suggests
PF small number particles N , may desirable use hybrid selection
schema selects particle maximum weight automatically randomly selects
remaining N 1.
compare inference methods terms execution time quality solutions (as
measured edit distance). Figure 8 suggests, using two slice proposal justified.
Moreover seems comparable computational effort, SMC tends outperform
MCMC methods.

4.2 Real Data: Beatles
evaluate performance model polyphonic piano performances. 12 pianists
invited play two Beatles songs, Michelle Yesterday. pieces relatively
simple rhythmic structure ample opportunity add expressiveness uctuating
tempo. original score shown Figure 9(a). subjects different musical education background: four professional jazz players, four professional classical performers
four amateur classical pianists. arrangement played three tempo
conditions, three repetitions per tempo condition. tempo conditions normal, slow
fast tempo, musically realistic range according judgment
performer. details reported (Cemgil et al., 2001).
4.2.1 Preprocessing

original performances contained several errors, missing notes additional notes
original score. errors eliminated using matching technique (Heijink, Desain, & Honing, 2000) based dynamical programming. However, visual
inspection resulting dataset suggested still several matching errors interpret
outliers. remove outliers, extended quantization model two
state switching observation model, i.e., discrete space consists ( k ; ik ). simple

63

fiCemgil & Kappen

1

0.8

0.6

0.4



0.2

0

0.2

0.4

0.6

0.8

1

0

2

4

6

8


10

12

14

16

Figure 5: Particle filtering clave example 4 particles. circle denotes mean
(k(n) ; !k(n) ) !k(n) = log2 k . diameter particle proportional
normalized importance weight generation. '*' denote true
(; !) pairs; modulated tempo deterministically according
!k = 0:3 sin(2ck =32), observation noise variance R = 0:0252 .

64

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

0

Log Likelihood

10

20
Gibbs
SA
II
GF
Desired

30

40

Figure 6:

1

10

20
30
Gibbs Sweep

40

50

Typical runs Gibbs sampling, Simulated Annealing (SA) Iterative Improvement
(II) clave example. algorithms initialized greedy filter solution.
annealing schedule SA linear 1 = 0:1 33 = 10 proceeding deterministically 34:50 = 1. SA II converge configuration, reinitialize
particle filter one particle draws randomly proportional optimal
proposal. Sharp drops likelihood correspond reinitializations. see that,
first sweep, greedy filter solution slightly improved II. Consequently sampler reinitializes. likelihood SA drops considerably, mainly due
high temperature, consequently stabilizes suboptimal solution. Gibbs
sampler seems explore support posterior able visit MAP
state run.

65

fiCemgil & Kappen

Log Likelihood Difference

0

5

10

15

20
1 Slice
2 Slice
25

SA

Gibbs

II

GF

PF

(a) Likelihood Difference
30

1 Slice
2 Slice

Edit Distance

25
20
15
10
5
0
SA

Gibbs

II

GF

PF

(b) Edit Distance. MCMC results 10 sweeps omitted.

Figure 7:

Comparison inference methods clave data. squares ovals denote
median vertical bars correspond interval %25 %75 quantiles.
tested MCMC methods (Gibbs, SA II) independently 10 50
(shown left right). SMC methods greedy filter (GF) particle filter
(PF). tested filters N = f5; 10; 50; 100g particles independently (shown
left right.).

66

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

SA1

SA2

Median Edit Distance

20

15

PF25

PF15

PF110

10
GF1

II1 PF210

GF2

Gi1

Gi2
II2

5

0

PF150

PF1100

PF250
PF2100

Flops (log scale)

Figure 8:

Comparison execution time terms oating point operations. methods,
first number (1 2) denotes number slices used optimal proposal distribution.
particle filter (PF), second number denotes number particles.
dashed lines merely used connect related methods.

outlier detection mechanism, switch ik binary indicator variable specifying whether
onset yk outlier not. assume indicators independent a-priori
uniform prior. observation model given p(yk jik ; k ) = N (0; Rik ) 5 .
Since score 1:K known, unknown discrete quantities indicators i0:K .
used greedy filtering followed iterative improvement find MAP state
indicators i0:K eliminated outliers studies. many performances,
around 2 4 outliers, less 1% notes. resulting dataset
downloaded url http://www.snn.kun.nl/cemgil.
4.2.2 Parameter Estimation

trained tempo tracking models different dimensionality D, denotes
dimension hidden variable z . models, use transition matrix
form Eq. 8.
Since true score known, i.e., quantization location ck onset yk given,
clamp discrete variables model. Consequently, estimate
observation noise variance R, transition noise variance Q transition matrix
coecients data.
optimized parameters Expectation-Maximization (EM) linear
dynamical systems (Shumway & Stoffer, 1982; Ghahramani & Hinton, 1996) using perfor5. took Rik =0 = 0:002 Rik =1 = 2.

67

fiCemgil & Kappen
mances \Yesterday" training data. Similarly, score prior parameters estimated
frequency counts score \Yesterday" 6 . tests carried \Michelle".
4.2.3 Results

Figure 9 show result typesetting performance without tempo
tracking. Due uctuations tempo, quality automatically generated score
poor. quality significantly improved using model.
Figure 10 shows tempo tracking examples Michelle dataset pianists
different background training. observe cases results satisfactory.
Figure 11, give summary test results Michelle data terms loglikelihood edit distance function model order number particles used
inference. Figure 11(a) shows median likelihood test data increasing
model order. suggests higher order filter able capture structure pianists' expressive timing. Moreover, sythetic data, see somewhat monotonic
increase likelihood solutions found using particles.
edit distance original score estimates given Figure 11(b).
Since pieces arranged piano, due polyphony, many onsets
associated quantization location. Consequently, many ktrue original
score effectively zero. cases, typically, corresponding inter onset interval
yk yk 1 small correct quantization (namely k = 0) identified
even tempo estimate completely wrong. consequence, edit distance remains
small. make task slightly challenging, exclude onsets ktrue = 0
edit distance calculation.
observe extra prediction ability obtained using higher order model
directly translate better transcription. errors around 5% models.
hand, variance edit distance higher order models smaller.
suggests higher order models tend robust divergence
original tempo track.

5. Discussion
presented switching state space model joint rhythm quantization tempo
tracking. model describes rhythmic structure musical pieces prior distribution quantization locations. representation, easy construct generic
prior prefers simpler notations learn parameters data set. prior
quantization locations c0:K translates non-Markovian distribution score 1:K .
Timing deviations introduced performers (tempo uctuation, accentuations motor errors) modeled independent Gaussian noise sources. Performer specific timing
preferences captured parameters distributions.
Given model, formulated rhythm quantization MAP state estimation
problem tempo tracking filtering problem. introduced Markov chain
6. maximum likelihood parameters model dimension = 3 found be: = 0:072, R =
0:0132 q = 0:0082 , q1 = 0:0072 q2 = 0:0502 . prior p(c) p(0) = 0:80, p(1=3) = 0:0082,
p(1=2) = 0:15 p(5=6) = 0:0418. Remaining p(c) set 10 6 .

68

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

Michelle
Lennon/McCartney

bb 4




& b b 4 n n ww n


w
? b b b 44
w



w
b


1

Piano







6

bb
& b b

? bb
bb



n


n


bb
& b b n


? bb

bb





6

11







n



n

n n . w n
. J



n
n n


n


n





3

n n


n

n

n






































































































10

3

13

17
3

bb
& b b . n.
.
? bb
bb
16

n n


bb
& b b

J
? bb
bb
n

21

bb
& b b n w
w
? bb
bb

3

j

.. .


b ..

..





j
.
..






n









n



j
ww
w



.



n




j











20

24








27

26



n ww
w

n n

w



(a) Original Score






































(b) Typesetting without
processing model.
Due uctuations
tempo, quality
score poor.

Figure 9:

























q = 130

6

11

16

3












3






3








































































20



24

(c) Typesetting tempo
tracking quantization
particle filter.

Results Typesetting scores.

69























fiCemgil & Kappen

0

0
Estimated
Original

Estimated
Original

0.4

0.4
2

log

2

log

k

0.2

k

0.2

0.6

0.6

0.8

0.8

1

0

10

20

30



40

50

60

1
10

70

0

10

20

30

k



40

50

60

70

80

k

(a) Professional Jazz Pianist

(b) Amateur

0

0
Estimated
Original

Estimated
Original

0.2

0.2

0.4
0.6

2

log

2

log

k

0.8

k

0.4

0.6

1

1.2
1.4

0.8

1.6
1.8

1
10

0

10

20

30



40

50

60

70

80

k

0

10

20

30



40

50

60

70

k

(c) Professional Classical Pianist.
filter temporarily loses track.

Figure 10:

2

(d) Tracking twice rate
original tempo.

Examples filtered estimates
z0:K = [k ; k ]T Beatles data set. Circles
original
denote mean p(zk j 1:k ; y0:k ) \x" denote mean p(zk j 1: k ; y0:k ) obtained
SMC. interesting note different timing characteristics. example classical
pianist uses lot tempo uctuation professional jazz pianist. Jazz pianist
slows dramatically end piece, amateur \rushes", i.e., constantly
accelerates beginning. tracking quantization results (a) (b)
satisfactory. (a), filter loses track last two notes, pianist
dramatically slows down. (c), filter loses track catches again. (d),
filter jumps metrical level twice fast original performance.
would translate duplication note durations only.

70

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

500

480

Likelihood

460

440

420

400

380

360

2

3
Model Dimension

4

(a) Likelihood. dashed horizontal line shows median
likelihood original score Michelle model.
50

45

40

Percent Edit Distance

35

30

25

20

15

10

5

0

2

3
Model Dimension

4

(b) Edit Distance

Figure 11:

SMC results test data (108 performances Michelle). model show
results obtained N = 1; 10; 20 50 particles. \-" show median
best particle \x" denote median applying iterative improvement.
vertical bars correspond interval %25 %75 quantiles.
71

fiCemgil & Kappen
Monte Carlo (MCMC) sequential Monte Carlo (SMC) approximate respective
distributions.
quantization model propose similar (Raphael, 2001a). transcription, Raphael proposes compute arg max p(c0:K ; z0:K jy0:K ) uses message propagation scheme essentially analogous Rao-Blackwellized particle filtering. prevent
number kernels explosion, uses deterministic selection method, called
\thinning". advantage Raphael's approach joint MAP trajectory
computed exactly, provided continuous hidden state z one dimensional
model parameter regime keeps number propagated Gaussian kernels
limited, e.g., R small, thinning eliminate many kernels. One disadvantage
number kernels varies depending upon features filtering distribution;
dicult implement scheme real time. Perhaps importantly, simple extensions increasing dimensionality z introducing nonlinearities
transition model would render approach quickly invalid. contrast, Monte Carlo
methods provide generic inference technique allow great exibility models one
employ.
tested method challenging artificial problem (clave example). SMC
outperformed MCMC terms quality solutions, measured terms
likelihood well edit distance. propose use SMC problems.
finding MAP quantization, propose apply iterative improvement (II) SMC
solution reduced configuration space.
correct choice score prior important overall performance
system. music pieces tend certain rhythmical vocabulary, certain
rhythmical motives reoccur several times given piece. rhythmic structure depends
mostly upon musical genre composer. seems rather dicult devise
general prior model would work well large spectrum styles. Nevertheless,
given genre, expect simple prior capture enough structure sucient good
transcription. example, Beatles dataset, estimated prior counting
original score \Yesterday". statistics fairly close \Michelle".
good results test set partially accounted fact pieces
similar rhythmical structure.
Conditioned score, tempo tracking model linear dynamical system.
optimized several tempo models using EM varied dimension
tempo variables z . test results suggest increasing dimensionality z improves
likelihood. However, increase likelihood whole dataset translate
directly overall better quantization results (as measured edit distance). observe
models trained whole training data fail consistently subjects, especially
professional classical pianists. Perhaps interestingly, train \custom" models specifically
optimized subjects, improve results significantly test cases.
observation suggests kind multimodality parameter space modes
correspond different performer regimes. seems Kalman filter able capture
structure expressive timing deviations. However, averaged subjects,
details tend wiped out, suggested quantization results
vary significantly among models different dimensions.

72

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
related problem edit distance measure \average" model,
likelihood desired score (e.g., original score \Michelle") may lower likelihood
solution found inference method. cases increasing likelihood may
even decrease edit distance. test cases even observe solutions higher
likelihood original notation notes wrong. cases,
tempo trajectory solution correspond half twice original tempo
consequently note durations halved doubled (e.g., whole notes notated
half notes, half notes quarters e.t.c.). Considering fact model \self
initializing" tempo, assume broad uncertainty a-priori, results still
satisfactory practical application perspective.
One potential shortcoming model takes timing information onsets
account. reality, believe pitch melodic grouping well articulation
(duration note onsets offsets) dynamics (louder softer) provide useful
additional information tempo tracking well quantization. Moreover, current model
assumes onsets equally relevant estimation. probably general
true: example, kick-drum provide information tempo
ute. hand, simulations suggest even limited model one
obtain quite satisfactory results, least simple piano music.
somewhat surprising, SMC, basically method samples filtering
distribution outperforms MCMC method SA specifically designed
finding MAP solution given observations. intuitive explanation relatively
poorer MCMC results MCMC proceeds first proposing global solution
tries improve local adjustments. human transcriber, hand, would
listen shorter segments music gradually write score. respect,
sequential update schema SMC seems natural rhythm transcription problem. Similar results, SMC outperforms MCMC already reported
literature, e.g., so-called \Growth Monte Carlo" generating self-avoiding random
walks (Liu, Chen, & Logvinenko, 2001). seems large class dynamical problems, including rhythm transcription, sequential updating preferable batch methods.
note theoretical convergence results SA require use logarithmic
cooling schedule. seems cooling schedule fast meet requirement;
one still careful interpreting poor performance negative SA result.
maintain using richer neighborhood structure configuration space (e.g.,
using block proposal distribution) slower cooling schedule, SA results
improved significantly. Moreover, MCMC methods modified operate
sequentially, example see (Marthi, Pasula, Russell, & Peres, 2002).
Another family inference methods switching state space models rely deterministic approximate methods. family includes variational approximations (Ghahramani &
Hinton, 1998) expectation propagation (Heskes, 2002). remains interesting open
question whether deterministic approximation methods provide advantage terms
computation time accuracy; particular quantization problem
switching state space models. potential application deterministic approximation
techniques MCMC schema designing proposal distributions extend
several time slices. schema would circumvent burden computing optimal
proposal distribution exhaustively hence allowing global moves sampler.

73

fiCemgil & Kappen
current results suggest superiority SMC problem. Perhaps
important advantage SMC essentially \anytime" algorithm;
faster computer increase number particles make use additional
computational power. computing time becomes short one decrease number
samples. features make SMC attractive real-time applications one
easily tune quality/computation-time tradeoff.
Motivated practical advantages SMC positive simulation results,
implemented prototype SMC method real-time. current computer system
(a 800 MHz P3 laptop PC running MS Windows) allows us use 5 particles
almost delay even busy passages. expect significantly improve eciency
translating MATLAB c constructs native C code. Hence, method used
tempo tracker automatic interactive performance system quantizer
automatic score typesetting program.

Acknowledgments
research supported Technology Foundation STW, applied science division
NWO technology programme Dutch Ministry Economic Affairs.
would thank associate editor Daphne Koller anonymous reviewers
comments helped us significantly improve article. would
thank Ric Ashley, Peter Desain, Henkjan Honing Paul Trilsbeek suggestions
contributions data collection. Moreover gratefully acknowledge pianists
Northwestern University Nijmegen University excellent performances.

Appendix A. generic prior model quantization locations c
traditional western music notation, note durations generated recursive subdivisions
starting whole note, hence convenient generate quantization locations
similar fashion regular subdivisions. decompose quantization location
integer part fraction: c = bcc + (c mod 1). defining prior, use
fraction.
set fractions generated recursively subdividing unit interval
[0; 1). let = [si ] denote subdivision schema, [si ] (finite) sequence
arbitrary integers (usually small primes 2,3 5). choice particular
depends mainly assumed time signature. generate set fractions C
follows: first iteration, divide unit interval s1 intervals equal length
append endpoints c0 resulting intervals set C . following iteration i,
subdivide intervals generated previous iteration si equal parts append
resulting endpoints C . Note thisQprocedure generates regular grid two
neighboring grid points distance 1= si . denote iteration number
endpoint c0 first inserted C depth c0 (with respect ). number
denoted d(c0 jS ). easy see definition coincides number
significant bits represent c mod 1 = [2; 2; : : : ].
illustirative example consider subdivision = [3; 2]. first iteration,
unit interval divided s1 = 3 equal intervals, resulting endpoints 0, 1=3,

74

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
2=3 inserted C depths d(0) = d(1=3) = d(2=3) = 1. second iteration,
new endpoints 1=6, 3=6 5=6 inserted C assigned depth 2.
Given , define distribution quantization locations

p(ck jS ) / exp( d(ck mod 1jS ))
wish consider several time signatures, i.e., different subdivision schemata,
interpret hidden indicator variable define
P prior p(S ). case, prior
becomes multinomial mixture given p(ck ) = p(ck jS )p(S ). details
empirical results justifying choice see (Cemgil et al., 2000).

Appendix B. Derivation two pass Kalman filtering Equations
Consider Gaussian potential mean covariance defined domain
indexed x.
1
1
(28)
(x) = Z N (; ) = Z j2j 2 exp( (x )T 1 (x ))
2
R
dx(x) = Z > 0. Z = 1 potential normalized. exponent Eq. 28
quadratic form potential written
1
x Kx)
(29)
(x) = exp(g + hT x
2

1
K 1 1
K= 1
h= 1
g = log Z + log j j
h K h
2
2 2
denote potential canonical form use notation

(x) = Z N (; ) [h; K; g]
refer g, h K canonical parameters. consider Gaussian
potential (x1 ; x2 )T . canonical representation

(x1 ; x2 ) =



h1
h2


;

K11 K12
K21 K22


;g

models several variables interacting, one find desired quantities applying
three basic operations defined Gaussian potentials. multiplication, conditioning, marginalization. multiplication two Gaussian potentials index
set x follows directly Eq. 29 given
0 (x) = (x) b (x)
[h0 ; K 0 ; g0 ] = [ha ; Ka ; ga ] [hb ; Kb ; gb ] = [ha + hb ; Ka + Kb ; ga + gb ]
domain b overlaps subset, potentials extended
appropriate domain appending zeros corresponding dimensions.

75

fiCemgil & Kappen
marginalization operation given

(x1 ) =

Z

K12 K221 h2 ; K11

(x1 ; x2 ) = [h1

x2

K12 K221 K21 ; g0 ]

g0 = g 21 log jK22 =2 j + 21 h2 (K22 ) 1 h2 g initial constant term (x1 ; x2 ).
conditioning operation given
(x1 ; x2 = x^2 ) = [h1 K12 x^2 ; K11 ; g0 ]

1 x^T K22 x^2 .
2 2

g0 = g + hT2 x^2

B.1 Kalman Filter Recursions
Suppose given following linear model subject noise
zk = Azk 1 + k
yk = Czk + k
C constant matrices, k N (0; Q) k N (0; R)
model encodes joint distribution
K


p(yk jzk )p(zk jzk 1 )
=1
p(z1 jz0 ) = p(z1 )

p(z1:K ; y1:K ) =

k

(30)
(31)

1
1 1
p(z1 ) = [P 1 ; P 1 ; log j2P j
P ]
2
T2 1

TR 1
1
0
C
R
C
C
p(y1 jz1 ) =
;
; log j2Rj
0
R 1C
R 1
2
1
1 1
p(y1 = y^1 jz1 ) = [0 + C R 1 y^1 ; C R 1 C; log j2Rj
y^ R y^1 ]
2
2 1

1

TQ 1
1
0

Q


p(z2 jz1 ) =
; log j2Qj
0 ;
Q 1A
Q 1
2
:::
B.1.1 Forward Message Passing

Suppose wish compute likelihood

p(y1:K ) =

Z

zK

p(yK jzK ) : : :

Z

z2

p(z3 jz2 )p(y2 jz2 )

Z
z1

p(z2 jz1 )p(y1 jz1 )p(z1 )

7 compute integral starting z1 proceeding zK . define forward
\messages"
R
R
7. let z dz

76

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

ff1j0 = p(z1 )
k=1:K
{ ffkjk = p(yk = y^k jzk )ffkjk 1
R
{ ffk+1jk = zk p(zk+1 jzk )ffkjk
forward recursion given
ff1j0 = [P 1 ; P 1; 12 log j2P j
k = 1:::K

1 P 1 ]
2

{ ffkjk = [hkjk ; Kkjk ; gkjk ]
hkjk = C R 1 y^k + hkjk 1
Kkjk = C R 1 C + Kkjk 1
gkjk = gkjk 1 21 log j2Rj 12 y^1T R 1 y^k
{ ffk+1jk = [hk+1jk ; Kk+1jk ; gk+1jk ]
Mk = (AT Q 1 + Kkjk ) 1
hk+1jk = Q 1 AMk hkjk
Kk+1jk = Q 1 Q 1 AMk Q 1
gk+1jk = gkjk 21 log j2Qj + 12 log j2Mk j + 12 hTkjk Mk hkjk
B.1.2 Backward Message Passing

compute likelihood starting yK .

p(y1:K ) =

Z

z1

p(z1 )p(y1 jz1 )

Z

z2

p(z2 jz1 )p(y2 jz2 ) : : :

Z
zK

case backward propagation summarized

fiK jK +1 = 1
k = K :::1
{ fikjk = p(yk = y^k jzk )fikjk+1
R
{ fik 1jk = zk p(zk jzk 1 )fikjk
recursion given

[hK jK +1; KK jK +1; gK jK +1] = [0; 0; 0]
k = K :::1
{ fikjk = [hkjk ; Kkjk ; gkjk ]
hkjk = C R 1 y^k + hkjk+1
Kkjk = C R 1 C + Kkjk+1

77

p(zK jzK 1 )p(yK jzK )

fiCemgil & Kappen
gkjk = 21 log j2Rj 12 y^kT R 1 y^k + gkjk+1
{ fik 1jk = [hk 1jk ; Kk 1jk ; gk 1jk ]
Mk = (Q 1 + Kkjk ) 1
hk 1jk = Q 1 Mk hkjk
Kk 1jk = Q 1 (Q Mk )Q 1
gk 1jk = gkjk 21 log j2Qj + 12 log j2Mk j + 12 h Tkjk Mk hkjk
B.2 Kalman Smoothing
Suppose wish find distribution particular zk given observations y1:K .
combine forward backward messages
p(zk jy1:K )

/ p(yk+1:K ; zk ; y1:k )

= p(y1:k ; zk )p(yk+1:K jzk )
= ffkjk fikjk+1
= [hkjk + hkjk+1 ; Kkjk + Kkjk+1; gkjk + gkjk+1]

Appendix C. Rao-Blackwellized SMC Switching State space
Model
let = 1 : : : N index particles = 1 : : : index states .
denote (unnormalized) filtering distribution time k 1
(ki) 1 =^ p(y0:k 1; zk 1 j 1:(ik) 1 )
Since y0:k 1 observed, (ki) 1 Gaussian potential zk 1 parameters Zk(i) 1
N
((i) ; (i) ). Note normalization constant Zk(i) 1 data likelihood p(y0:k 1j 1:(ik) 1 ) =
R k (1i) k 1
dzk k 1 . Similarly, denote filtered distribution next slice conditioned
k =

(ksji) =
^

Z

dzk 1 p(yk jzk )p(zk jzk 1 ; k = s)(ki) 1
(32)
= p(y0:k ; zk j 1:(ik) 1 ; k = s)
denote normalization constant (ksji) Zk(sji). Hence joint proposal
(i) given
qk(sji) =

Z

dzk (ksji) p( k = s; 1:(ik) 1 )
= p( k = s; 1:(ik) 1 ; y0:k )

outline algorithm given below:
Initialize. = 1 : : : N , (0i) p(y0; x0)

78

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

k = 1 : : : K
{ = 1 : : : N , = 1 : : :
Compute (ksji) (ki) 1 using Eq.32.
qk(sji) Zk(sji) p( k = s; 1:(ik) 1 )
{ = 1 : : : N
Select tuple (sjj ) qk
1:(ik) ( 1:(jk) 1 ; k = s)
(ki) (ksjj )
P (sjj)
wk(i)
qk
Note procedure \built-in" resampling schema eliminating particles
small importance weight. Sampling jointly (sji) equivalent sampling single
resampling according weights wk(i) . One check that,
since using optimal proposal distribution Eq.27, weight step
given wk(i) = p( 1:(ik) 1 ; y0:k ).

References

Aarts, E. H. L., & van Laarhoven, P. J. M. (1985). Statistical cooling: general approach
combinatorial optimization problems. Philips Journal Research, 40 (4), 193{226.
Agon, C., Assayag, G., Fineberg, J., & Rueda, C. (1994). Kant: critique pure quantification.
Proceedings International Computer Music Conference, pp. 52{9, Aarhus, Denmark.
International Computer Music Association.
Andrieu, C., de Freitas, N., Doucet, A., & Jordan, M. I. (2002). introduction MCMC
machine learning. Machine Learning, appear.
Bar-Shalom, Y., & Fortmann, T. E. (1988). Tracking Data Association. Academic Press.
Bar-Shalom, Y., & Li, X.-R. (1993). Estimation Tracking: Principles, Techniques Software.
Artech House, Boston.
Cambouropoulos, E. (2000). MIDI traditional musical notation. Proceedings AAAI
Workshop Artificial Intelligence Music: Towards Formal Models Composition, Performance Analysis, Austin, Texas.
Carter, C. K., & Kohn, R. (1996). Markov Chain Monte Carlo conditionally Gaussian state space
models. Biometrika, 83 (3), 589{601.
Casella, G., & Robert, C. P. (1996). Rao-Blackwellisation sampling schemas. Biometrika, 83,
81{94.
Cemgil, A. T., Desain, P., & Kappen, H. J. (2000). Rhythm quantization transcription. Computer
Music Journal, 24:2, 60{76.
Cemgil, A. T., & Kappen, H. J. (2002). Rhythm quantization tempo tracking sequential
Monte Carlo. Dietterich, T. G., Becker, S., & Ghahramani, Z. (Eds.), Advances Neural
Information Processing Systems 14. MIT Press.
Cemgil, A. T., Kappen, H. J., Desain, P., & Honing, H. (2001). tempo tracking: Tempogram
representation Kalman filtering. Journal New Music Research, 28:4, 259{273.
Chen, R., & Liu, J. S. (2000). Mixture Kalman filters. J. R. Statist. Soc., 10.
79

fiCemgil & Kappen
Dannenberg, R. (1984). on-line algorithm real-time accompaniment. Proceedings ICMC,
pp. 193{198, San Francisco.
Desain, P., & Honing, H. (1991). Quantization musical time: connectionist approach. Todd,
P. M., & Loy, D. G. (Eds.), Music Connectionism., pp. 150{167. MIT Press., Cambridge,
Mass.
Desain, P., & Honing, H. (1994). brief introduction beat induction. Proceedings ICMC,
San Francisco.
Dixon, S., & Cambouropoulos, E. (2000). Beat tracking musical knowledge. Horn, W. (Ed.),
Proceedings ECAI 2000 (14th European Conference Artificial Intelligence), Amsterdam.
Doucet, A., & Andrieu, C. (2001). Iterative algorithms state estimation jump Markov linear
systems. IEEE Trans. Signal Processing, 49 (6), 1216{1227.
Doucet, A., de Freitas, N., & Gordon, N. J. (Eds.). (2001). Sequential Monte Carlo Methods
Practice. Springer-Verlag, New York.
Doucet, A., de Freitas, N., Murphy, K., & Russell, S. (2000a). Rao-Blackwellised particle filtering
dynamic Bayesian networks. Uncertainty Artificial Intelligence.
Doucet, A., Godsill, S., & Andrieu, C. (2000b). sequential Monte Carlo sampling methods
Bayesian filtering. Statistics Computing, 10 (3), 197{208.
Fox, D., Burgard, W., & Thrun, S. (1999). Markov localization mobile robots dynamic
environments. Journal Artificial Intelligence Research (JAIR), 11.
Ghahramani, Z., & Hinton, G. (1998). Variational learning switching state-space models. Neural
Computation, 12 (4), 963{996.
Ghahramani, Z., & Hinton, G. E. (1996). Parameter estimation linear dynamical systems. (crgtr-96-2). Tech. rep., University Totronto. Dept. Computer Science.
Godsill, S., Doucet, A., & West, M. (2001). Maximum posteriori sequence estimation using Monte
Carlo particle filters. Annals Institute Statistical Mathematics, 52 (1), 82{96.
Gordon, N. J., Salmond, D. J., & Smith, A. F. M. (1993). Novel approach nonlinear/nonGaussian Bayesian state estimation. IEE Proceedings Part F, Radar Signal Processing,
Vol. 140(2), pp. 107{113.
Goto, M., & Muraoka, Y. (1998). Music understanding beat level: Real-time beat tracking
audio signals. Rosenthal, D. F., & Okuno, H. G. (Eds.), Computational Auditory Scene
Analysis.
Grubb, L. (1998). Probabilistic Method Tracking Vocalist. Ph.D. thesis, School Computer
Science, Carnegie Mellon University, Pittsburgh, PA.
Hamanaka, M., Goto, M., Asoh, H., & Otsu, N. (2001). learning-based quantization: Estimation
onset times musical score. Proceedings 5th World Multi-conference Systemics,
Cybernetics Informatics (SCI 2001), Vol. X, pp. 374{379.
Heijink, H., Desain, P., & Honing, H. (2000). Make match: evaluation different approaches
score-performance matching. Computer Music Journal, 24(1), 43{56.
Heskes, T. Zoeter, O. (2002). Expectation propagation approximate inference dynamic
Bayesian networks. Proceedings UAI.
Isard, M., & Blake, A. (1996). Contour tracking stochastic propagation conditional density.
ECCV (1), pp. 343{356.
Large, E. W., & Jones, M. R. (1999). dynamics attending: track time-varying events.
Psychological Review, 106, 119{159.
Liu, J. S., Chen, R., & Logvinenko, T. (2001). theoretical framework sequential importance
sampling resaampling. Doucet, A., de Freitas, N., & Gordon, N. J. (Eds.), Sequential
Monte Carlo Methods Practice, pp. 225{246. Springer Verlag.
80

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
Longuet-Higgins, H. C. (1987). Mental Processes: Studies Cognitive Science. MIT Press, Cambridge. 424p.
Marthi, B., Pasula, H., Russell, S., & Peres, Y. (2002). Decayed MCMC filtering. Proceedings
UAI.
Metropolis, N., Rosenbluth, A., Rosenbluth, M., Teller, A., & Teller, E. (1953). Equations state
calculations fast computing machines. Journal Chemical Physics, 21, 1087{1091.
Metropolis, N., & Ulam, S. (1949). Monte Carlo method. Journal American Statistical
Assoc., 44(247), 335{341.
Murphy, K. P. (2002). Dynamic Bayesian Networks: Representation, Inference Learning. Ph.D.
thesis, University California, Berkeley.
Pressing, J., & Lawrence, P. (1993). Transcribe: comprehensive autotranscription program..
Proceedings International Computer Music Conference, pp. 343{345, Tokyo. Computer
Music Association.
Rabiner, L. R. (1989). tutorial hidden Markov models selected applications speech
recognation. Proc. IEEE, 77 (2), 257{286.
Raphael, C. (2001a). mixed graphical model rhythmic parsing. Proc. 17th Conf.
Uncertainty Artif. Int. Morgan Kaufmann.
Raphael, C. (2001b). probabilistic expert system automatic musical accompaniment. Journal
Computational Graphical Statistics, 10 (3), 467{512.
Roberts, G. O., & Rosenthal, J. S. (1998). Markov Chain Monte Carlo: practical implications
theoretical results. Canadian Journal Statistics, 26, 5{31.
Scheirer, E. D. (1998). Tempo beat analysis acoustic musical signals. Journal Acoustical
Society America, 103:1, 588{601.
Shumway, R. H., & Stoffer, D. S. (1982). approach time series smoothing forecasting
using em algorithm. J. Time Series Analysis, 3 (4), 253{264.
Tanizaki, H. (2001). Nonlinear non-Gaussian state-space modeling Monte Carlo techniques:
survey comparative study. Rao, C., & Shanbhag, D. (Eds.), Handbook Statistics,
Vol.21: Stochastic Processes: Modeling Simulation. North-Holland.
Thom, B. (2000). Unsupervised learning interactive jazz/blues improvisation. Proceedings
AAAI2000. AAAI Press.
Toiviainen, P. (1999). interactive midi accompanist. Computer Music Journal, 22:4, 63{75.
Vercoe, B., & Puckette, M. (1985). synthetic rehearsal: Training synthetic performer.
Proceedings ICMC, pp. 275{278, San Francisco. International Computer Music Association.
Vercoe, B. L., Gardner, W. G., & Scheirer, E. D. (1998). Structured audio: Creation, transmission,
rendering parametric sound representations. Proc. IEEE, 86:5, 922{940.

81


