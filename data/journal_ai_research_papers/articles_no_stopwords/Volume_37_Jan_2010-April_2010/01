journal artificial intelligence

submitted published

predicting performance ida
conditional distributions
uzi zahavi

zahaviu cs biu ac il

computer science department
bar ilan university israel

ariel felner

felner bgu ac il

department information systems engineering
deutsche telekom labs
ben gurion university israel

neil burch

burch cs ualberta ca

computing science department
university alberta canada

robert c holte

holte cs ualberta ca

computing science department
university alberta canada

abstract
korf reid edelkamp introduced formula predict number nodes ida
expand single iteration given consistent heuristic experimentally demonstrated could make accurate predictions addition requiring heuristic consistent formulas predictions accurate
levels brute force search tree heuristic values obey unconditional distribution defined used formula propose
formula works well without requirements e make accurate predictions ida performance inconsistent heuristics heuristic values
level obey unconditional distribution order achieve introduce
conditional distribution heuristic values generalization unconditional
heuristic distribution provide extensions formula handle individual
start states augmentation ida bidirectional pathmax bpmx technique propagating heuristic values inconsistent heuristics used experimental
demonstrate accuracy method variations

introduction overview
heuristic search hart nilsson raphael ida korf
guided cost function f n g n h n g n actual distance
start state state n h n heuristic function estimating cost n
nearest goal state heuristic h admissible h n dist n goal every state n
goal state goal dist n cost least cost path n h n
admissible e returns lower bound estimate optimal cost
guaranteed optimal path start state goal state one exists
c

ai access foundation rights reserved

fizahavi felner burch holte

important question ask many nodes expanded
solve given major advance answering question work done
korf reid edelkamp introduced formula predict number nodes ida
expand korf reid korf reid edelkamp papers formula
present predictions makes referred kre prior
kre standard method comparing two heuristic functions compare
average values preference given heuristic larger average korf
korf felner felner korf meshulam holte kre made substantial
improvement characterizing quality heuristic function distribution
values developed kre formula heuristic distribution
predict number nodes expanded ida searching specific heuristic
cost threshold finally compared predictions formula actual
number nodes expanded ida different thresholds several benchmark search
spaces showed gave virtually perfect predictions major advance
analysis search heuristics
despite impressive kre formula two main shortcomings first
kre assumes addition admissible given heuristic consistent
heuristic h consistent every pair states n h h n dist n
heuristic consistent heuristic values nodes children thus constrained similar heuristic value node heuristic inconsistent
consistent e pair nodes n h h n dist n inconsistency
allows nodes children heuristic values arbitrarily larger smaller
nodes heuristic value term inconsistency negative connotation
something avoided recent studies shown inconsistent heuristics easy
define many search applications produce substantial performance improvements
felner zahavi schaeffer holte zahavi felner schaeffer sturtevant
zahavi felner holte schaeffer reason important extend
kre formula accurately predict ida performance inconsistent heuristics
heuristics likely become increasingly important future applications
second shortcoming kre formula works well levels
search tree heuristic distribution follows equilibrium distribution defined
section holds sufficiently deep levels search tree
heuristic values converge equilibrium distribution addition hold
levels heuristic values set start states distributed according
equilibrium distribution however shown section kre
formula inaccurate depths practical interest single start states
large sets start states whose values distributed according equilibrium
distribution cases heuristic values levels search tree
actually examined ida obey equilibrium distribution applying kre
cases inaccurate predictions
main objective develop formula accurately predict number
nodes ida expand given cost threshold given heuristic set start
states including currently covered kre first extend kres idea
general definition graph case undirected graphs write consistency
definition h h n dist n



fipredicting performance ida conditional distributions

heuristic distribution unconditional conditional distribution
probability specific heuristic value constant kre conditioned
certain local properties search space conditional distribution provides
insights behavior heuristic values search informed
context search tree specific heuristic value produced
allows better study heuristic behavior
conditional distribution develop formula cdp conditional distribution prediction predicts ida performance set start states regardless
heuristic values distributed desired depth necessarily large
whether heuristic consistent cdp recursive structure information
number nodes propagated root leaves search tree
experiments cdps predictions least accurate kres cdp much
accurate inconsistent heuristics sets start states non equilibrium
heuristic distributions basic form cdp particularly accurate single start
states describe simple extension improves accuracy setting finally
adapt cdp make predictions ida augmented bidirectional pathmax
method bpmx felner et al inconsistent heuristics used bpmx
useful addition ida prunes many subtrees would otherwise explored
thereby substantially reducing number nodes ida expands
throughout provide experimental demonstrating accuracy
cdp scenarios two benchmark domains used kre
sliding tile puzzle rubiks cube
simplicity discussion assume edges cost
true many domains generalization ideas case variable edge
costs straightforward although practical implementation introduces additional
challenges briefly described section
organized follows section presents background material section
derives kre formula first principles discusses limitations section
notion conditional distribution heuristic values presented formula cdp
presented section section discusses subtle important way
experiments differ kres experimental presented sections
extension cdp formula better handle single start states presented section
section proposes technique cdp estimating upper lower bounds
number nodes ida expand given unconditional distribution section
presents extension cdp predicting performance ida bpmx applied
related work discussed section conclusions suggestions future work
given section preliminary version appeared zahavi felner burch
holte

background
two application domains used kre demonstrate accuracy formula
experiments use exactly domains section describe
well search different heuristic functions used
experiments


fizahavi felner burch holte

domains
two classic examples ai literature single agent pathfinding
rubiks cube sliding tile puzzle
rubiks cube

figure rubiks cube
rubiks cube invented erno rubik hungary standard version
consists cube figure different colored stickers exposed
squares sub cubes cubies movable cubies stable cubies
center face movable cubies divided eight corner cubies
three faces twelve edge cubies two faces corner cubies move
among corner positions edge cubies move among edge positions
one faces cube rotated degrees relative
rest cube possible moves state since twisting
face twice row redundant branching factor first move reduced
addition movements opposite faces independent example twisting
left face right face leads state performing moves
opposite order pruning redundant moves search tree asymptotic
branching factor korf
goal state squares side cube color puzzle
scrambled making number random moves task restore cube
original unscrambled state different reachable states
sliding tile puzzles
sliding tile puzzle consists square frame containing set numbered square tiles
empty position called blank legal operators slide tile
horizontally vertically adjacent blank blank position
rearrange tiles random initial configuration particular desired goal
configuration state space grows exponentially size number tiles increases
shown finding optimal solutions sliding tile npcomplete ratner warmuth two common versions sliding tile
puzzle puzzle puzzle puzzle contains


fipredicting performance ida conditional distributions






































figure puzzle puzzle goal states
reachable states puzzle contains reachable states goal states
puzzles shown figure
classic heuristic function sliding tile puzzles called manhattan distance computed counting number grid units tile displaced
goal position summing values tiles excluding blank since
tile must move least manhattan distance goal position move changes
location one tile one grid unit manhattan distance lower bound
minimum number moves needed solve instance
iterative deepening
iterative deepening ida korf performs series depth first searches increasing cost threshold time depth first search nodes n f n
expanded threshold initially set h start node goal
found current threshold search ends successfully otherwise ida proceeds
next iteration increasing minimum f value exceeded previous
iteration
pattern databases pdbs
powerful obtaining admissible heuristics create simplified version
abstraction given state space use exact distances abstract space
estimates distances original state space type abstractions use
sliding tile puzzles illustrated figure left side
figure shows puzzle state goal state right side shows corresponding
abstract states defined erasing numbers tiles except
estimate distance goal state puzzle calculate
exact distance abstract state corresponding abstract goal state
pattern database pdb lookup table stores distance abstract goal
every abstract state pattern culberson schaeffer pdb built
running breadth first search backwards abstract goal whole abstract
space spanned compute h state original space mapped
corresponding abstract state p distance goal p looked pdb
description assumes operators cost technique easily extended
cases operators different costs



fizahavi felner burch holte

pdb lookup

state

































































goal state

goal pattern



b

figure example regular lookups

example pdb puzzle tiles would contain entry
every possible way placing four tiles blank puzzle positions
pdb could implemented dimensional array p db array indexes
locations blank tiles respectively lookup state
shown figure would p db blank position tile
position tile position etc accessing pdb state
described referred regular lookup heuristic value returned
regular lookup referred regular heuristic value
pattern databases proven useful finding lower bounds combinatorial
puzzles korf culberson schaeffer korf felner felner korf
hanan felner et al furthermore proven useful
search e g multiple sequence alignment mcnaughton lu schaeffer szafron
zhou hansen edelkamp
geometric symmetries
common practice exploit special properties state space enable additional
heuristic evaluations particular additional pdb lookups performed given
single pdb example consider rubiks cube suppose pdb
positions cubies yellow face positions cubies dont
matter reflecting rotating puzzle enable similar lookups cubies
different color e g green red etc since puzzle perfectly symmetric respect
color thus symmetric lookups pdb different heuristic
values obtained lookups pdb heuristic values
admissible given state puzzle


fipredicting performance ida conditional distributions

another example consider sliding tile puzzle line symmetry main
diagonal assuming goal location blank upper left corner configuration tiles reflected main diagonal reflected configuration
shares attributes original one reflections usually used
pdbs sliding tile puzzle culberson schaeffer korf felner felner
et al looked pdb
methods creating inconsistent heuristics
consistent heuristics difference heuristic value neighboring nodes
constrained less equal cost connecting edge inconsistent
heuristics constraint difference heuristic values neighboring
nodes much larger cost edge connecting
kre formula designed work consistent heuristics therefore kre
papers report experiments done consistent heuristics contrast
formula cdp works types heuristics including inconsistent heuristics therefore
addition usual consistent heuristics regular pdb lookups
manhattan distance experiment inconsistent heuristics previously
described several methods producing inconsistent heuristics zahavi et al two
inconsistent heuristics used experiments random selection
heuristics dual evaluations
random selection heuristics well known method overcoming pitfalls
given heuristic employ several heuristics use maximum value holte
felner newton meshulam furcy example multiple heuristics
domain specific geometric symmetries ones described
geometric symmetries additional storage costs associated
extra evaluations even evaluations pdbs
although multiple heuristics improved heuristic value therefore
likely reduce number nodes expanded finding solution increases
time required calculate heuristic values nodes might increase
overall running time search instead available heuristics
every heuristic calculation one could instead choose consult one
selection made randomly systematically one
heuristic consulted node time per node virtually
one heuristic available even individual heuristics consistent
heuristic values actually used inconsistent different heuristics
consulted different nodes showed zahavi et al inconsistency
generally reduces number expanded nodes compared heuristic
nodes almost low maximum heuristics
computed every node rubiks cube randomly chose one
different lookups pdb arise lines symmetry
cube
dual evaluation permutation state spaces rubiks cube state
exists dual state sd located distance goal felner


fizahavi felner burch holte

et al zahavi felner holte schaeffer zahavi et al therefore
admissible heuristic applied sd admissible puzzles studied
permutation state spaces dual state puzzles
calculated reversing role locations objects regular state uses
set objects indexed current location dual state set
locations indexed objects contain pdbs dual lookup
look sd pdb performing regular pdb lookups states
generated search produces consistent values however values produced
performing dual lookup inconsistent identity objects
queried change dramatically two consecutive lookups due
diversity dual heuristic shown preferable regular heuristic zahavi
et al exact definition explanations dual lookup provided
original papers felner et al zahavi et al
important note three pdb lookups regular dual random consult
pdb thus need amount memory share overall
distribution heuristic values zahavi et al

kre formula limitations
section begins short derivation kre formula state spaces
state transitions cost kre describe generalized account
variable edge costs korf et al
kre formula
given state ida threshold kre aims predict n number nodes
ida expand uses start state complete search
ida threshold e searches depth terminate search goal
encountered written
n


x

ni





ni number nodes expanded ida level threshold
one way decompose ni product two terms
ni ni pex



ni number nodes level bf ssd brute force search tree e
tree created breadth first search without heuristic pruning depth rooted
start state pex percentage nodes level bf ssd
expanded ida threshold
kre ni written ni e without dependence start state
perfectly correct state spaces uniform branching factor b ni
cases simply bi state spaces non uniform regular branching structure


fipredicting performance ida conditional distributions

kre showed ni could computed exactly recurrence equations independent however base cases recurrences kre depend
ni instead ni reasonable strictly correct
conditions node expansion ida
understand pex treated kre necessary reflect conditions
required node expansion node n level bf ssd expanded ida
satisfies two conditions
f n g n h n must less equal edges unit cost
g n condition equivalent h n call nodes satisfy
condition potential nodes potential expanded
n must generated ida e parent level must expanded
ida
kre restricted analysis heuristics consistent proved case
second condition implied first condition words given
heuristic consistent nodes expanded ida level bf ssd threshold
exactly set potential nodes level observation allows equation
rewritten
ni ni pp ot en ial



pp ot en ial v defined percentage nodes level bf ssd whose
heuristic value less equal v
note although pp ot en ial di pex given heuristic consistent pp ot en ial overestimates pex heuristic inconsistent
sometimes large amount see section
approximating pp ot en ial v
kre use three different approximations pp ot en ial v kres theoretical analysis
pp ot en ial v approximated equilibrium distribution denote
peq v defined probability node chosen randomly uniformly
among nodes given depth brute force search tree heuristic value less
equal v limit large depth korf et al p kre proved
limit large

x
ni peq


would converge n given heuristic consistent final formula kre
formula therefore
see section discussion kre formula consistent heuristics



fizahavi felner burch holte

n


x

ni peq





kre contrasted equilibrium distribution overall distribution
defined probability state chosen randomly uniformly states
heuristic value less equal v p unlike equilibrium
distribution defined search tree overall distribution property
state space overall distribution directly computed pattern database
one pattern database used entries corresponds number
states original state space approximated complex settings
computing heuristic values large random sample states kre argued
rubiks cube overall distribution heuristic defined single pattern database
equilibrium distribution sliding tile puzzles two
distributions different
heuristic used kres experiments rubiks cube defined maximum
three pattern databases individual pattern database overall distribution
computed exactly kres experiments distributions combined approximate pp ot en ial v assuming values three pattern databases
independent
experiments sliding tile puzzles kre defined three types states
whether blank located corner position edge position interior
position approximated pp ot en ial v weighted combination overall distributions states type weights used level exact
percentages states different types level
experiments followed kre precisely use overall distribution individual rubiks cube pattern databases weighted overall distribution described
sliding tile puzzles simplicity reminder use phrase
unconditional heuristic distribution notation p v refer probability
node heuristic less equal v let exact context determine
distribution p v actually denotes whether equilibrium distribution overall
distribution approximation pp ot en ial pex likewise use
p v lower case p denote p v p v p p p v probability
state heuristic value exactly v according distribution p
limitations kre formula
kre formula equation two main shortcomings predictions
accurate given heuristic inconsistent even consistent heuristics
predictions inaccurate individual start states sets start states whose heuristic
values distributed according unconditional heuristic distribution p v
turn examine detail


fipredicting performance ida conditional distributions

consistent






expanded
generated
generated



inconsistent
r











n

figure consistent versus inconsistent heuristics
inconsistent heuristics
specifically mentioned kre papers one property required kre analysis
heuristic consistent necessary kre formula aims
count number potential nodes level bf ssd consistent heuristics
heuristic value neighboring states never changes change g value
illustrated left side figure number inside node heuristic
value implies f value nodes ancestor less equal
f value node e f monotone non decreasing along path search tree
therefore easy prove consistent heuristics ancestors potential
node potential nodes korf et al consequently ida expand
potential nodes bf ssd hence formula kre aims count
number potential nodes bf ssd used predict number nodes ida
expand given consistent heuristic
inconsistent heuristics reasoning apply heuristic values neighboring states differ much cost edge connects
thus f values along path search tree guaranteed monotonically
non decreasing therefore ancestors potential node guaranteed
potential nodes consequence potential node might never
generated example consider search tree right side figure numbers
inside node nodes heuristic value assume start node r
ida threshold node potential node f value less equal
potential nodes depth heuristic value consider
potential node n path node node potential node
f generated expanded therefore node n
never generated preventing ida expanding since kre formula counts
number potential nodes count node n thus overestimate number
expanded nodes inconsistent heuristic used
amount kre overestimates number nodes expanded ida
inconsistent heuristic large illustrate consider state space
rubiks cube pdb heuristic defined locations edge
cubies regular method looking heuristic value pdb produces consistent
heuristic discussed section two alternative pdb lookups produce inconsistent
unconditional distinguish conditional distribution introduce section



fizahavi felner burch holte









kre







regular







dual







random symmetry







table rubiks cube number nodes expanded ida regular dual
random symmetry pdb lookups different ida threshold corresponding kre predictions

heuristics dual evaluation random selection multiple heuristics
rubiks cube symmetries applied state create
way perform pdb lookup thus heuristics rubiks cube
pdb random symmetry lookup chooses one randomly
three lookups regular dual random symmetry consult pdb
distribution heuristic values p v therefore kre predict
ida expand number nodes regardless whether regular dual
random symmetry lookup done experimental table
substantially different number nodes actually expanded practice
methods
row table presents specific ida threshold
average random initial states generated making random
moves goal state kre column shows kre prediction
unconditional heuristic distribution last three columns table number
nodes ida expands performs regular dual random symmetry lookup
pdb kre prediction within actual number nodes expanded
ida uses regular consistent pdb lookup third column substantially
overestimates number nodes expanded ida uses dual random symmetry
inconsistent lookups pdb fourth fifth columns
sets start states whose heuristics values obey
unconditional heuristic distribution
explained kre used unconditional heuristic distribution p v
theoretical analysis proved use kre formula would give accurate predictions limit large depth fact accurate predictions occur soon
heuristic distribution depth interest closely approximates p v happens
large depths definition happen even shallow levels certain
circumstances reason kre able produce extremely accurate predictions
experiments unconditional heuristic distribution p v depths
start states experiments report average predictions performances


fipredicting performance ida conditional distributions

large number randomly drawn start states spaces used kres experiments
heuristic distribution large random set start states closely approximated
p v distribution used caused heuristic distributions levels closely
approximate p v
however set start states heuristic values distributed according
p v case non random sets start states single start state
kre expected make good predictions small depths words
cases unconditional heuristic distribution p v expected good
approximation pex
consider case single start state consistent heuristic distribution
heuristic values search tree close start state highly correlated
heuristic value start state therefore search trees
start states different heuristic values example great deal pruning likely
occur near top search tree start state large heuristic value resulting
fewer nodes expanded start state small heuristic value applying kre
two states produce prediction therefore inaccurate
least one uses unconditional heuristic distribution p v
cases
h






ida






kre






table set start states h value shown first column
regular pdb lookup ida threshold

table demonstrates phenomenon rubiks cube one regular edge pdb
lookup ida threshold ida column shows average number nodes
expanded start states heuristic value h given row kre
ignores heuristic values start states predicts nodes
expanded ida every start state row table shows
accurate prediction performance averaged large random sample start
states table see low start states small heuristic values
high ones large heuristic values
convergence heuristic distributions large depths
described kre make accurate predictions level nodes level
actually obey unconditional heuristic distribution p v increases distribution
heuristic values start converge p v rate convergence depends upon
state space believed fairly slow sliding tile puzzles faster


fizahavi felner burch holte

rubiks cube convergence occurs ida threshold reached kre
provide accurate predictions set start states including single start states
order experimentally test repeated kre rubiks cube experiment
addition large set random start states looked individual
performance two start states low heuristic value
maximum value heuristic used experiment kre used
heuristic takes maximum different pdbs one corner
cubies two edge cubies heuristic admissible consistent
billion random states sampled estimate p v maximum value
average value

kre



















multiple start states
ida
ratio



























single start state
ratio
















ratio








table rubiks cube max pdbs
table presents kre column presents kre prediction
multiple start states columns presents actual number states generated averaged
set random start states ida threshold columns copied kre
journal korf et al ratio columns table shows value predicted
kre formula divided actual number nodes generated ratio found
close multiple start states indicating kres predictions
accurate
two individual start states tested shown single start
state part table note states optimally solved depth
kre search depth run completion cases kre formula
accurate small thresholds accuracy prediction increased threshold
increased threshold kre prediction roughly factor small
large large improvement smaller thresholds
predictions become even accurate depth continues increase
reason predictions improve larger values deeper depths
heuristic distribution within single level converges unconditional heuristic distribution dashed dotted lines types figure shows distribution
heuristic values seen states moves away solid line
figure unconditional heuristic distribution x axis corresponds different
heuristic values axis shows percentage states specified depth
heuristic values less equal x value example depth includes


fipredicting performance ida conditional distributions




unconditional heuristic distribution
depth
depth
depth
depth




cumulative percentage

cumulative percentage



unconditional heuristic distribution
depth
depth
depth
depth































heuristic value









heuristic value

heuristic distributions

b heuristic distributions

figure convergence heuristic distributions

start state heuristic value seen leftmost curve depth
heuristic values seen second curve left figure
shows heuristic distribution successive depths converges unconditional
heuristic distribution rightmost curve figure depth shown heuristic distribution probably quite close unconditional heuristic distribution making
kre prediction quite accurate even single start state
figure b shows heuristic distributions nodes moves
away case unconditional heuristic distribution left
heuristic distributions shallow depths heuristic distribution depth
rightmost curve figure comparing parts b figure see
convergence unconditional heuristic distribution faster
explains kre prediction table accurate

conditional distribution cdp formula
present formula cdp conditional distribution prediction overcomes two shortcomings kre described previous section important feature
cdp extends unconditional heuristic distribution heuristic values p v
used kre conditional distribution
conditional distribution heuristic values
conditional distribution heuristic values denoted p v context context
represents local properties search tree neighborhood node influence
distribution heuristic values nodes children specifically pn v percentage
node ns children heuristic value less equal v define
p v context average pn v nodes n satisfy conditions defined




fizahavi felner burch holte

context p v context interpreted probability node heuristic
value less equal v produced node satisfying conditions specified
context expanded context empty denoted p v section
use p v context lower case p denote probability node heuristic value
equal v produced node
p satisfying conditions specified context
expanded obviously p v context vi p context
basic step model
conditioning context combination local properties search tree
including properties node e g heuristic value operator applied
generate node properties nodes ancestors search tree etc simplest
conditional distribution p v vp probability node heuristic value equal v
produced node value vp expanded call step model
value conditioned nodes one step away special circumstances
p v vp determined exactly analysis state space heuristic
general must approximated empirically sampling state space
sampling method p v vp represented entry v vp two dimensional
matrix hmax hmax hmax maximum possible heuristic value build
matrix first set values matrix randomly generate state
calculate heuristic value vp generate child state one
time calculate childs heuristic value v increment v vp repeat
process large number times order generate large sample finally divide
value cell matrix sum column cell belongs entry
v vp represents percentage children generated value v state
value vp expanded

vp

vp


v



























































v

consistent heuristic

b inconsistent heuristic

figure portion conditional distribution matrix rubiks cube consistent
inconsistent heuristics



fipredicting performance ida conditional distributions

figure shows bottom right corner two matrices edge pdb
rubiks cube left matrix shows p v vp regular consistent lookup
pdb right matrix b shows p v vp inconsistent heuristic created
dual lookup pdb matrix tridiagonal neighboring values
cannot differ example states heuristic value
children heuristics occur probabilities
respectively see column contrast matrix b tridiagonal column
example see time states heuristic value children
heuristic values
richer
ida expands node eliminates children operator pruning
example state spaces undirected operators studies
parent node would generated among nodes children ida would immediately
prune away distribution p v vp take account order take
consideration necessary extend context conditional probability include
heuristic value parent node expanded refer parent node
gp denote p v vp vgp call step model conditions
information ancestors two steps away p v vp vgp gives probability
node heuristic value equal v generated node expanded
heuristic value vp parent node expanded heuristic value
vgp estimated sampling way done estimate p v vp except
sample generates random state gp neighbors
neighbors except eliminated operator pruning naturally
sampling step model stored three dimensional array
context conditional distribution extended ways well
sliding tile puzzles kre conditions overall distribution type state
expanded type indicates blank corner edge interior
location experiments sliding tile puzzle extend p v vp vgp
type information p v vp tp vgp tgp gives probability node type
heuristic value equal v generated node expanded heuristic
value vp type tp expanded nodes parent heuristic value vgp type tgp
prediction formula cdp conditional distribution prediction
section use conditional distributions described develop cdp alternative kre formula predicting number nodes ida expand
given heuristic ida threshold set start states shown experimentally formula cdp overcomes limitations kre works well inconsistent
heuristics set start states arbitrary ida threshold
overall follows define ni v number nodes
ida generate level heuristic value equal v start state
ida threshold
pdi given ni v number nodes ida expand level
threshold v ni v n total number nodes expanded
complete iteration ida threshold levels quantity ultimately


fizahavi felner burch holte

p p
interested di di
v ni v summations v runs
nodes heuristic values range expanded level
ni v could calculated exactly formula would calculate n exactly
whether given heuristic consistent however general method efficiently calculating ni v exactly instead ni v estimated recursively
ni v conditional distribution exact details depend conditional
model used given subsections follow use ni v
denote approximation ni v section describe conditions
calculation fact exact therefore produces perfect predictions n
general case predictions may perfect estimates
present time analytical tools estimating accuracy
experimentally estimates often accurate
prediction basic step model
basic step conditional distribution p v vp used ni v estimated
recursively follows


ni v ni v

x

ni vp bvp p v vp



vp

bvp average branching factor nodes heuristic value vp estimated
sampling process estimates conditional distribution reasoning
behind equation ni vp bvp total number children ida generates
via nodes expands level heuristic value equal vp multiplied
p v vp get expected number children heuristic value v nodes
level expanded heuristic value less equal
hence summation includes vp values range restricting
vp less equal every recursive application formula
ensure even inconsistent heuristics node counted level
ancestors expanded ida base case recursion n v
v h values v
number nodes expanded ida given start state threshold
particular heuristic predicted follows
cdp

x
di
x

ni v



v

set start states given instead one start state calculation
identical except base case recursion defined start states
define n v equal k k states heuristic
value v rest formula remains substituted everywhere
general case equation branching factor depends context defines conditional distribution since step model context heuristic value v formally
allow branching factor depend practice branching factor usually
heuristic values



fipredicting performance ida conditional distributions

prediction richer
step conditional distribution p v vp vgp used define ni v vp
number nodes ida generate level heuristic value equal v
nodes level heuristic value vp start state ida
threshold ni v vp estimated recursively follows


ni v vp ni v vp

x

ni vp vgp bvp vgp p v vp vgp



vgp

bvp vgp average branching factor nodes heuristic value vp parent
heuristic value vgp base case step model level level
n v vp vp h number children start state
heuristic value v vp h step model number nodes expanded
ida given start state threshold particular heuristic predicted
follows
cdp

x
di
x
x
v

ni v vp



vp

set start states instead one base case n v vp
number children heuristic value v states heuristic value vp
analogous definitions ni cdp used definition context
example step model set state types one would define ni v
number nodes type ida generate level heuristic value
equal v estimate recursively follows


ni v ni v

x

x

vp

tp

ni vp tp bvp tp p v vp tp



model number nodes expanded ida given start state threshold
particular heuristic predicted follows
cdp

x
di x
x

ni v



v tt

prediction accuracy
accuracy predictions arbitrarily good arbitrarily bad depending
accuracy conditional model used following subsections examine
extreme cases
principle extending context never decrease accuracy predictions
additional information taken account however conditional model
estimated sampling extended context poorer predictions
fewer samples context explanation step model
accurate step model rows h h table section



fizahavi felner burch holte

perfect predictions
consider definition context includes heuristic value node expanded vp contexts defined contains sufficient information allow
operator pruning correctly accounted use notation v x refer
specific instance context v heuristic value node expanded
x instantiation information context e g state type
information last model general form predictive model
context
cdp

x
di
x
v

x

ni v x



x
v x
instance
context




ni v x

x

x

vp

xp
vp xp
instance
context

ni vp xp bvp xp p v x vp xp



bvp xp average branching factor operator pruning nodes satisfying
conditions context vp xp p v x vp xp average nodes n satisfying
conditions context vp xp pn v x percentage ns children operator
pruning satisfy conditions context v x
every context vp xp nodes n satisfying conditions defined vp xp
exactly branching factor bvp xp exactly value pn v x
contexts v x simple proof induction starting correctness base cases
n v x shows ni v x ni v x e prediction
method correctly calculates exactly many nodes satisfy conditions
context every level search tree follows cdp exactly
number nodes ida expand given start state ida threshold
practical setting predictions step model guaranteed
perfect reasoning following conditions hold
heuristic defined exact distance goal abstract state space
case single pattern database used
two states map abstract state x set
operators op opk apply
states map abstract state x operators op op opk
apply child op child op map abstract
state op x


fipredicting performance ida conditional distributions

define context node heuristic value abstract state maps
condition guarantees every context v x nodes satisfying conditions
v x exactly branching factor bv x true nodes n
n satisfy conditions context v x map abstract state
x condition requires exactly set operators apply
conditions together guarantee every context vp xp nodes
satisfying conditions vp xp exactly value pn v x v x
true nodes n n satisfy conditions context vp xp
map abstract state xp set operators applies operator
op creates child cases maps specific abstract state op xp therefore
percentage children map particular abstract state
n n
straightforward implementation prediction method setting associates
counter abstract state initialized number start states map
abstract state counter abstract state x updated value
adding operator op current value counter
abstract state op x computational complexity
number abstract states effective branching
factor abstract space complexity depends linearly contrast
typically exponential dependency number nodes ida expand
sufficiently large prediction arbitrarily faster compute search
example pdb puzzle positions tiles
blank roughly billion abstract states prediction start states
takes time required execute search
exact prediction setting two potential uses first determine
searching single pdb feasible example calculation might
even first iteration ida threshold h start take
year complete second use prediction compare actual performance
alternative method executed set start states e g taking maximum
set pdbs performance single pdb without actually execute
ida search single pdb
poor predictions
predictions made conditional model extremely inaccurate distribution
heuristic values independent information supplied context illustrate
example x sliding tile puzzle two heuristics pdb
locations tiles blank heuristic returns every state
given state blank goal position position even number
moves goal position heuristic value state taken pdb
states heuristic value search tree heuristic used level
therefore opposite one used level
step model situation clearly hopeless predicting heuristic
distribution levels pdb used sufficiently large
distribution level converges unconditional distribution


fizahavi felner burch holte

hope step model could make reasonably accurate predictions
pdb considered defines consistent heuristic therefore distribution heuristic values nodes children somewhat correlated heuristic
value nodes parent
tested x sliding tile puzzle small enough could
build step model states state space error introduced
sampling process test prediction accuracy model generated
solvable states random explained detail next section used
state start state combination ida threshold ida would actually
executed iteration threshold given state start state means
different number start states might used value num column
table indicates many start states used value first column
included table start states used
ida column shows average number nodes expanded ida start
states used prediction column shows number predicted
step model ratio column prediction divided ida one clearly see
improvement predictions increases even deepest depth
sample provided start states prediction factor smaller
true value course constant heuristic value alternate levels
something one would practice obtained similar essentially
reason puzzle switching one level next pattern
database tiles pattern database tiles see section
















ida














cdp
prediction ratio



























num














table x sliding tile puzzle alternating good heuristic

experimental setup
next two sections describe experimental obtained running ida
comparing number nodes expanded number predicted kre


fipredicting performance ida conditional distributions

cdp experimented two application domains used kre namely rubiks
cube section sliding tile puzzle section domain evaluated
accuracy two formulas consistent inconsistent heuristics set
solvable start states generated random
experiments reported start states used given ida threshold
subject special condition state used start state combination
threshold ida actually performs iteration threshold start
state example would use start state distance
goal h addition sliding tile puzzle start state would
used ida threshold h different parity contrast
experiments kre restrict choice start states way
start states used every ida threshold
difference start states chosen large impact number
nodes ida expands table illustrates puzzle manhattan
distance heuristic ida threshold first column nodes
column unrestricted shows number nodes ida expanded average
randomly generated solvable start states values column close
agreement corresponding table kre korf et al
number column shows many start states satisfy additional condition
remove start states violate condition ida expands substantially fewer
nodes average shown nodes column restricted difference
increases increases almost order magnitude difference
number nodes expanded two settings difference needs kept
mind making comparisons experimental reported kre
papers











unrestricted
nodes









restricted
number
nodes












table puzzle manhattan distance effect nodes expanded start states
randomly chosen subject condition



fizahavi felner burch holte

experimental rubiks cube
begin rubiks cube experiments heuristic used edge pdb
heuristic described section experimented consistent regular
lookup inconsistent random symmetry dual lookups pdb
cdp formula two used cdp cdp denote step step
respectively
outlined section conditional distribution tables built generating one billion states generated applying random moves goal state
computing neighbors incorporating heuristic information matrix representing one step model two step model generated
grandchildren used heuristic information
addition order get reliable samples added following two procedures
generating children grandchildren sampling used pruning
techniques operator ordering used main search see
description section use sequence operators
would generated main search done looking random
walk led initial state last operator random walk
basis operator pruning
order get reliable sample need entry table sufficiently
sampled entries table low frequency example states
heuristic value rare even sample billion states causing
table row generated small sample therefore enriched
entries artificially creating random states heuristic value
sampled entries sampled similar way one technique example
creating high probability random state heuristic value x
perform random walk length x random state heuristic value
rubiks cube consistent heuristics
table compares kre cdp cdp accuracy three prediction methods
compared regular lookups edge pdb row
averages set random states row presents ida iteration









ida







kre
prediction







ratio







cdp
prediction ratio













cdp
prediction ratio













table rubiks cube consistent heuristic


fipredicting performance ida conditional distributions

different threshold given first column second column ida presents
actual number nodes expanded ida threshold next columns report
predictions accuracy ratio prediction defined ratio
predicted number actual number expanded nodes reported
kre kre formula found accurate consistent heuristic
averaged large set random start states table shows cdp reasonably
accurate systematically underestimates one step model consider
nodes parent included among children elaborate
cdp predictions accurate slightly accurate kres
rubiks cube start states specific heuristic values
table presented section related discussion kre might
make accurate predictions start states restricted specific heuristic
value h particular example shown ida threshold kre predict
value exact value depends specific set start states used
ida threshold sufficiently large number nodes
independent start states table extends table include predictions cdp
shows versions cdp substantially outperform kre particular set
start states

h






ida






kre
prediction ratio











cdp
prediction ratio











cdp
prediction ratio











table different start state heuristic values h regular pdb
ida threshold

rubiks cube inconsistent heuristics
experiments repeated inconsistent heuristics dual randomsymmetry lookups performed edge pdb instead regular lookup thereby
creating inconsistent heuristic discussed section kre produces
prediction heuristics consistent inconsistent derived single pdb
overestimates inconsistent heuristics table shows cdp extremely accurate
prediction within actual number nodes expanded
step model used cdp systematically underestimates actual number
nodes expanded regular dual lookups see regular lookup table
dual lookup table understand consider happens node
right side figure expanded generates two children node n assuming


fizahavi felner burch holte

kre
prediction



ida





























cdp
ratio prediction ratio
dual























random symmetry
























cdp
prediction ratio




























table rubiks cube dual random symmetry inconsistent heuristics
operators inverses case rubiks cube copy parent r shown ms
left child figure child levels deeper r therefore f value
greater rs ida threshold child potential node
step model conclude generate potential child probability
whereas fact children remain operator pruning potential
nodes

r



n

figure step model may underestimate
reason step model underestimate number nodes expanded
random symmetry lookups done child copy r constrained
heuristic value r different symmetries could chosen
different occurrences r childs f value correlation f value r
explanation cdp underestimates apply
fact different copies state uncorrelated h values effect operator
pruning needs taken account reduces number children
done well within step model calculating branching factor
may advantages wider context step model
random symmetry heuristic minor case


fipredicting performance ida conditional distributions

experimental sliding tile puzzle
kre experiments sliding tile puzzle three state types used
whether blank corner edge interior location used state types
experiments used exact recurrence equations n v type dependent
version kre formula heuristic used manhattan distance md experimented step cdp includes type system recurrence equations
step cdp included performed poorly early versions experiments
puzzle conditional distribution p v vp tp vgp tgp needed cdp
typed unconditional distribution p v needed type dependent kre formula
computed enumerating states puzzle reachable goal
puzzle possible exhaustive enumeration entire state
space conditional distributions estimated generating ten billion reachable
states random uniform random sample used estimate p v kre
state sample used gp sampling method described section
p v vp tp vgp tgp latter however basic sampling method extended
even processing ten billion gp states entries dimensional
matrix missing sampled sufficiently correct generate
gp children grandchildren update matrix accordingly check
matrix already contains data gps great grandchildren generate
gps great grandchildren update corresponding entries matrix continues
long encounter contexts never seen introduces small
statistical bias sample guarantees sample contains required
data

h

states



























kre
ida
prediction
ratio
puzzle depth















puzzle depth











cdp
prediction ratio


























table sliding tile puzzles consistent heuristic md
prediction kre cdp puzzles shown table
format puzzle predictions made ida threshold


fizahavi felner burch holte

row corresponds group puzzle states heuristic
value h shown first column ida would actually used threshold
second column gives number states group clearly shown
ida column states higher initial heuristic values ida expanded smaller
number nodes trend reflected kre predictions since kre take
h account kre difference attributes different rows
different type distribution given group thus predicted number expanded
nodes kre similar rows around cdp formula takes heuristic
value start state account able predict number expanded nodes
much better kre bottom part table puzzle
ida threshold similar tendencies observed
inconsistent heuristics sliding tile puzzle
next experiment inconsistent heuristic puzzle defined two pdbs
one location blank tiles location
blank tiles create inconsistent heuristic one pdbs consulted
regular lookup choice pdb made systematically randomly
position blank different occurrences state guaranteed
lookup neighboring states guaranteed consult different pdbs
causes inconsistency presented table variety ida thresholds
threshold num column indicates many start states used
cdps predictions reasonably accurate much accurate
kres overestimate factor















num













ida













kre
prediction













ratio













cdp
prediction ratio

























table inconsistent heuristic puzzle
similar experiments conducted puzzle first pdb
location blank tiles location
blank tiles table shows ida thresholds recall
median solution length puzzle numbers shown averages


fipredicting performance ida conditional distributions

start states cdp predictions puzzle considerably worse
puzzle kre predictions degraded much reason
inaccuracy predictions discussed section much accurate
predictions produced context extended include heuristic value
pattern databases one search actually consults











ida









kre
prediction









ratio









cdp
prediction









ratio









table inconsistent heuristic puzzle

accurate predictions single start states
seen cdp works well base cases recursive calculation
ni v seeded large set start states matter heuristic values
distributed however actual number expanded nodes specific single start
state deviate number predicted cdp conditional distribution reflects
expected values nodes share context single start state
interest might behave differently average state context
consider rubiks cube state heuristic value cdp predicts ida
expand state ida threshold table shows
average start states heuristic value states expanded
examining individual start states showed actual number
expanded nodes ranged nodes
order predict number expanded nodes single start state propose
following enhancement cdp suppose want predict number expanded
nodes ida threshold start state first perform small initial search
depth r use states depth r seed base cases cdp formula
compute formula ida threshold r cause larger set nodes
used calculating ni v thereby improving accuracy cdps predictions
rubiks cube edge pdb heuristic
table shows four specific rubiks cube states heuristic value
regular edge pdb lookup ida threshold set chose
states least greatest number expanded nodes two states around
median first column shows actual number nodes ida expands state


fizahavi felner burch holte

next columns number expanded nodes predicted enhanced cdp
formula initial search performed depths r clearly
initial searches give much better predictions original cdp r
predicts states initial search depth predictions
accurate
h





ida





cdp r





cdp r





cdp r





cdp r





table single state

rubiks cube heuristic
section presented kre predictions two start states heuristic value
heuristic value rubiks cube heuristic
repeat experiments cdp tables initial
search depth r tables cdp able achieve substantially
better predictions kre cases initial search depth usually
improved cdp predictions










ida









kre









ratio









cdp r









ratio









cdp r









ratio









table pdb single start state
experiments puzzle single start states
performed experiments enhanced cdp formula states puzzle
consistent md heuristic use term trial refer pair single
start state given ida threshold trials included possible values
start states ida would actually perform search ida threshold
predictions made trial separately relative error predicted actual
trial calculated shown figure four curves
figure kre cdp enhanced cdp initial search depths r


fipredicting performance ida conditional distributions










ida








kre








ratio








cdp r








ratio








cdp r








ratio








table pdb single start state

cumulative percentage





kre
cdp
cdp radius
cdp radius

























predicted actual

figure relative error puzzle
x axis relative error axis percentage trials
prediction relative error x less example value kre
curve x means kre underestimated factor
trials rightmost point kre plot x indicates
trials kres prediction times actual number nodes expanded
contrast cdp much larger percentage highly accurate predictions
predictions within factor two actual number nodes expanded figure
clearly shows advantage enhanced cdp initial search depth
trials predictions within correct number

performance range given unconditional distribution
experiments used edge pdb rubiks cube illustrated fact number nodes ida expands given pdb vary tremendously
depending pdb used zahavi et al see clearly middle
three columns table data already seen tables namely
number nodes ida expands edge pdb used regular manner


fizahavi felner burch holte

dual lookups random symmetry lookups ida expands ten times fewer
nodes edge pdb consulted random symmetry lookups
consulted normal way
raises intriguing question range performance achieved
varying conditional distribution unconditional distribution fixed







correlation

cdp







regular








dual








random symmetry








cdp







table range ida performace edge rubiks cube pdb

upper limit
upper extreme nodes expanded occurs consistent
heuristic used ida expands potential nodes maximum
number nodes expanded conditional distribution parent
every potential node level potential node level exact calculation
number potential nodes brute force tree therefore theoretical upper bound
number nodes ida expand given unconditional distribution
already discussed one way estimate number potential nodes use
kre formula estimate upper bound number nodes ida could
expand denoted cdp table
alternatively number potential nodes approximated cdp formula
given conditional distribution consider equation summation consider
possible vp values nodes potential nodes level thus
nodes expanded ida level nodes generate
children level lets substitute vp hmax consider
nodes level even ones potential nodes
summation calculate number nodes heuristic v level even ones
actually generated ida parents potential nodes e
vp shown equation
ni v

hx
max

ni vp bvp p v vp



vp

note heuristic consistent vp values v v v need considered
summation nodes values vp smaller v larger v cannot
generate children heuristic value v



fipredicting performance ida conditional distributions

general prediction equation get

cdp

x
di
x

ni v



v

gives alternative method approximate number potential nodes
methods approximate upper bound practice however possible
number expanded nodes slightly exceed approximate bound due noise
small errors sampling calculations
lower limit
consistent heuristics values neighboring states highly correlated
extreme cases correlation heuristic values neighboring
nodes heuristic value child node statistically independent heuristic
value parent means regardless parents heuristic value vp heuristic
values children distributed according unconditional heuristic distribution
e p v vp p v
motivation estimated lower bound number nodes ida
could expand given unconditional distribution empirical observation
number nodes ida expands decreases correlation parents heuristic
value childrens heuristic values decreases
illustrated last row three middle columns table shows
correlation heuristic values neighboring states different types
lookups done edge pdb calculated pearsons correlation coefficient
defined n pairs x values according following equation

correlationxy

pn
pn
xi yi xi yi
p pn
p pn
pn
pn
n x xi n yi yi
n

pn





order calculate correlation random pairs xi yi neighboring states
generated heuristic values computed used equation bottom
row table shows number nodes expanded decreases correlation
neighboring heuristic values decreases leads us suggest number
nodes expanded reach minimum correlation zero
estimated lower bound calculated cdp formula p v vp p v
denote cdp step model would calculated following
equations
theory possible heuristic negative correlation parents heuristic value
childrens heuristic values e parents low heuristic values could tend children
large heuristic values vice versa believe unlikely occur practice



fizahavi felner burch holte



ni v

x

ni vp bvp p v



vp

cdp

di
x
x

ni v



v

seen comparing rightmost two columns table randomsymmetry use edge pdb within factor two estimated minimum
possible number nodes expanded pdb suggests substantially
improve upon performance one would use different pdb
table shows estimated upper lower bounds ida performance range
ida thresholds three different pdbs rubiks cube bounds calculated
random start states table shows according estimates inconsistent heuristics edge pdb outperform consistent heuristics
edge pdb probably cannot outperform consistent heuristics edge
pdb since estimated lower bound edge pdb larger estimated upper
bound edge pdb









edge pdb
cdp
cdp












edge pdb
cdp
cdp












edge pdb
cdp
cdp












table estimated bounds performance three rubiks cube pdbs

predicting performance ida bpmx
inconsistent heuristic heuristic value child much larger
parent happens state space undirected edges childs heuristic
value propagated back parent causes parents f value exceed
ida threshold entire search subtree rooted parent pruned without
generating remaining children propagation technique called bidirectional
pathmax bpmx felner et al zahavi et al shown effective
reducing search effort pruning subtrees would otherwise explored
modify cdp handle bpmx propagation since bpmx applies
state spaces undirected edges discussion section limited spaces


fipredicting performance ida conditional distributions

bidirectional pathmax bpmx
traditional pathmax mero propagates heuristic values parent children
applied state space admissibility preserved subtracting cost
connecting edge heuristic value basic insight bidirectional pathmax
bpmx edges undirected heuristic values propagate neighbors
includes child node parent process continue distance
direction bpmx illustrated figure left side figure shows
inconsistent heuristic values node two children consider left child
heuristic value since value admissible edges example cost
one immediate neighbors least moves away goal neighbors
least moves away left child generated heuristic value
h propagate parent right child preserve
admissibility propagation along path reduces h cost traversing path
h root h right child ida
bidirectional propagation may cause many nodes pruned would otherwise
expanded example suppose current ida threshold without propagation
h left child root node f g h right child
f g h would expanded propagation left child
increase parents h value resulting search node abandoned
without even generating right child












figure propagation values inconsistent heuristics

cdp overestimates bpmx applied
inconsistent heuristic used bpmx applied cdp overestimate
number expanded nodes count nodes subtrees bpmx
prunes section defined ni v number nodes ida
generate level heuristic value exactly equal v start state
ida threshold formula given estimating ni v equation


ni v

x

ni vp bvp p v vp

vp

calculating ni v ni vp formula assumes node
expanded children generated ni vp multiplied
branching factor bvp bpmx applied child may prune parent
rest children generated happens assumption children
expanded nodes generated would wrong example without bpmx


fizahavi felner burch holte

expanding root left tree figure children generated child
right expanded indeed cdp count two nodes case bpmx
applied root expanded child right generated therefore
expanded thus cdp counts two nodes overestimating number
nodes expanded following section modify equation correct
formula estimating ni v
let n node currently expanded assume n b children
consider order generated call order generation order
note bpmx applied probability child generated decreases
move generation order children appear late order
larger chance generated since previous children might
cause bpmx cutoff let pbx l probability child location l order
generated even bpmx applied definition extend equation
follows
bvp

ni v

x x
ni vp pbx l p v vp
vp



l

ni v calculated similar way equation except way count
total number children ida generates via nodes expands level
heuristic value equal vp idea iterate possible locations
generation order calculate probability node location l generated
practice however actual context pbx variables besides location l
includes ida threshold depth parent heuristic
value parent vp thus get final formula
bvp

ni v

x x
ni vp pbx l vp p v vp
vp



l

exactly equal equation special case pbx l l
happens bpmx used used consistent heuristic
calculating pbx
simplicity model assumes heuristic value propagated bpmx
one level tree means state pruned immediate
children descendants deeper levels make assumption another
reason besides simplicity description experiments rubiks cube
domains showed indeed almost pruning bpmx caused level bpmx
propagation generalized formula deeper bpmx propagations similarly
developed include complicated recursive terms low practical value
least state spaces heuristics studied
assume c child n location l generation order child c
generated n pruned l children appear c


fipredicting performance ida conditional distributions

generation order assume n level threshold since n
expanded h n bpmx h n increased cause bpmx pruning
child k h k case h k larger
used instead h n ida decide expand n additional children
generated therefore order child c location l generation order
generated l predecessors generation order must heuristics less
equal assuming heuristic value parent v probability

pbx l v

di
x

p h v l



h

sum probability relevant heuristic value raise sum
power l since l children appear c
experiments rubiks cube bpmx
repeated experiments rubiks cube edge pdb bpmx
activated since bpmx affects inconsistent heuristics dual random
symmetry heuristics tested heuristic tested ida thresholds
averaged set random states presented
table bpmx columns repeated table additional columns
bpmx column ida bpmx presents actual number
expanded nodes bpmx bpmx reduces number nodes expanded
dual reduction random symmetry making
unmodified cdp predictions high amount cdpbx
column
shows modifications introduced section greatly improve accuracy



ida





























bpmx
cdp

bpmx
ratio ida bpmx
cdpbx

dual























random symmetry

























ratio













table bpmx rubiks cube dual random symmetry



fizahavi felner burch holte

related work
previous work predicting ida performance properties heuristic falls
two main camps first bases analysis accuracy heuristic
second bases analysis done distribution heuristic values
next two subsections survey approaches
analysis heuristics accuracy
one common characterize heuristic focusing error heuristic
value deviation optimal cost first analysis line focusing effect
errors performance search done pohl many
papers line appeared since pohl gaschnig huyn dechter
pearl karp pearl pearl chenoweth davis mcdiarmid
provan sen bagchi zhang dinh russell su helmert roger

works usually assume abstract model space tree every node
exactly b children aim provide asymptotic estimation number expanded
nodes mainly differ model assumptions e g binary non binary trees
case derived worst case average case worst case analysis
showed correlation
heuristic errors search complexity
h n h n
found relative error
constant search complexity
h n
exponential length solution path absolute error h n h n
bounded constant search complexity linear pohl gaschnig three
main assumptions used pohl branching factor assumed
constant across inputs single goal state transpositions
search space assumptions hold case many standard
benchmark domains general search explore exponential
number states even assumption almost perfect heuristic e heuristic
whose error bounded small additive constant helmert roger
since difficult guarantee precise bounds magnitude errors produced
given heuristic probabilistic characterization magnitudes suggested huyn
et al pearl heuristics modeled random variables rvs relative
errors assumed independent identically distributed iid model model
attaining average polynomial complexity proved essentially equivalent
requiring values h n clustered near h n allowed deviation
logarithmic function h n
additional line conducted chenoweth davis instead
iid model suggested nc model places constraints
errors h model heuristic defined according heuristic values grow respect distance goal according error
predicted complexity polynomial whenever values h n
logarithmicaly clustered near h n h n arbitrary non negative
non decreasing function heuristics whose values grow slower distance
goal cause exponential complexity studies nc model showed replacing


fipredicting performance ida conditional distributions

heuristic h wh w often change complexity exponential
polynomial
works focused tree searches contrast sen et al presented
general technique extending analysis average case performance
search spaces trees search spaces directed acyclic graphs analytical expected complexity change exponential polynomial
heuristic estimates nodes become accurate restrictions placed
cost matrix recent line analyzing complexity
presented dinh et al presented worst average case analysis performance approximately accurate heuristics search
multiple solutions bounds presented proved dependent
heuristic accuracy distribution solutions
analysis heuristic distribution
discussed outset kre suggested alternative calculating time complexity ida multiple goal spaces korf reid korf
et al arguing heuristic accuracy difficult obtain suggested
deriving analysis unconditional distribution heuristic values easy
determine least approximately came method deriving
closed form formula ni number nodes level brute force search tree
method later formalized edelkamp b unlike work described
previous subsection provides big complexity analysis kres aim
exactly predict number nodes ida expand
kre correctly point operators cost ni must
defined number nodes reached path cost opposed
number nodes edges start state calculation ni
general setting studied detail ruml slightly different context ruml
solution involves conditional distribution edge costs bears
strong resemblance conditional distribution heuristic values
work kre insight pdb heuristics correlation
size pdb heuristic value distribution analysis limited
pdb heuristics done korf breyer korf prediction achieved
branching factor size pdb without knowing
actual heuristic distribution order derive heuristic distribution
size pdb assumed forward backward branching factors
abstract space equal abstract space negligible number cycles
since second assumption usually realistic model underestimates number
expanded nodes
kre formula developed predict performance ida
general applied long appropriate modifications made
computations ni p v korf et al holte hernadvolgyi breyer
korf challenge accounting effect pruning search
tree generates state previously reached path smaller equal
heuristic approximation h h h states search space



fizahavi felner burch holte

cost particularly challenging heuristic inconsistent case
first time generates state guaranteed reached via least cost
path state occur search tree indeed worst case
every state enumerate paths state decreasing order cost
thereby generating exactly search tree ida martelli general
pruning reduce ni especially large ways may hard capture
small set recurrence equations heuristic distribution entire search
tree taken maximum depth consistent heuristics overall distribution korf
et al since state occurs exactly search tree observed
true inconsistent heuristics imply overall distribution
used good effect level level basis use kre formula
accurate predictions performance puzzle two different consistent
heuristics used together exact calculation ni search tree breyer
korf

conclusions future work
historically heuristics characterized average kre introduced idea
characterizing heuristics unconditional heuristic distribution presented
formula predict number nodes expanded one iteration ida
unconditional heuristic distribution work presented takes another
step along line conditional distribution introduced prediction
formula cdp advance understanding properties heuristic affect
performance ida
cdp method advances kre improving predictions shallow depths
wider range sets start states inconsistent heuristics shown
use make accurate prediction single start state ida search
uses bpmx heuristic value propagation
course sophisticated methods preprocessing needed
special care must taken gathering data order get reliable sample
much easier calculate average heuristic calculate dimensional
matrix hand latter better characterizes heuristic
enables generating accurate predictions larger variety circumstances
future work address number issues yet clear attributes make
best context prediction influenced choice heuristic
attributes specific domain larger contexts parameters probably provide better prediction cost pre processing tradeoff needs
studied another direction aim extend analysis predict
performance search

acknowledgments
supported grant number israeli science
foundation isf ariel felner robert holte neil burch gratefully acknowledge
ongoing support work canadas natural sciences engineering


fipredicting performance ida conditional distributions

council nserc albertas informatics circle excellence icore
code rubiks cube implementation richard e korf
used seminal work domain korf thank anonymous reviewer
encouraged us widen experimental better explain
kre relation comments clearly improved strength
thanks sandra zilles careful checking details section

references
breyer korf r recent analyzing performance heuristic
search proceedings first international workshop search artificial
intelligence robotics held conjunction aaai pp
chenoweth v davis h w high performance search rapidly
growing heuristics proceedings twelfth international joint conference
artificial intelligence ijcai pp
culberson j c schaeffer j efficiently searching puzzle tech rep
department computer science university alberta
culberson j c schaeffer j pattern databases computational intelligence

dinh h russell su value good advice complexity
search accurate heuristics proceedings twenty second conference
artificial intelligence aaai pp
edelkamp pattern databases proceedings th european
conference ecp pp
edelkamp b prediction regular search tree growth spectral analysis
advances artificial intelligence joint german austrian conference ai
ki ogai pp
felner korf r e hanan additive pattern database heuristics journal
artificial intelligence
felner korf r e meshulam r holte r c compressed pattern databases
journal artificial intelligence
felner zahavi u schaeffer j holte r c dual lookups pattern
databases proceedings nineteenth international joint conference artificial intelligence ijcai pp
gaschnig j performance measurement analysis certain search
ph thesis carnegie mellon university
hart p e nilsson n j raphael b formal basis heuristic determination minimum cost paths ieee transactions systems science cybernetics
scc
helmert roger g good almost perfect proceedings
twenty third conference artificial intelligence aaai pp


fizahavi felner burch holte

holte r c felner newton j meshulam r furcy maximizing
multiple pattern databases speeds heuristic search artificial intelligence
holte r c hernadvolgyi steps towards automatic creation search
heuristics tech rep tr computing science department university alberta
huyn n dechter r pearl j probabilistic analysis complexity
artificial intelligence
karp r pearl j searching optimal path tree random costs
artificial intelligence
korf r e depth first iterative deepening optimal admissible tree search
artificial intelligence
korf r e finding optimal solutions rubiks cube pattern databases
proceedings fourteenth conference artificial intelligence aaai pp

korf r e analyzing performance pattern database heuristics proceedings
twenty second conference artificial intelligence aaai pp
korf r e felner disjoint pattern database heuristics artificial intelligence

korf r e reid complexity analysis admissible heuristic search
proceedings fifteenth conference artificial intelligence aaai pp

korf r e reid edelkamp time complexity iterative deepening
artificial intelligence
martelli complexity admissible search artificial intelligence
mcdiarmid c j h provan g expected cost analysis backtracking
non backtracking proceedings twelfth international joint
conference artificial intelligence ijcai pp
mcnaughton lu p schaeffer j szafron memory efficient heuristics
multiple sequence alignment proceedings eighteenth conference
artificial intelligence aaai pp
mero l heuristic search modifiable estimate artificial intelligence
pearl j heuristics intelligent search strategies computer solving
addison wesley
pohl heuristic search viewed path finding graph artificial intelligence

pohl practical theoretical considerations heuristic search
machine intelligence


fipredicting performance ida conditional distributions

ratner warmuth k finding shortest solution n n extension
puzzle intractable proceedings fifth conference artificial
intelligence aaai pp
ruml w adaptive tree search ph thesis harvard university
sen k bagchi zhang w average case analysis best first search
two representative directed acyclic graphs artificial intelligence
zahavi u felner burch n holte r c predicting performance
ida conditional distributions proceedings twenty third conference
artificial intelligence aaai pp
zahavi u felner holte r schaeffer j dual search permutation
state spaces proceedings twenty first conference artificial intelligence
aaai pp
zahavi u felner holte r c schaeffer j duality permutation state
spaces dual search artificial intelligence
zahavi u felner schaeffer j sturtevant n r inconsistent heuristics
proceedings twenty second conference artificial intelligence aaai
pp
zhou r hansen e space efficient memory heuristics proceedings
nineteenth conference artificial intelligence aaai pp




