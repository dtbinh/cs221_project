journal artificial intelligence

submitted published

training multilingual sportscaster
perceptual context learn language
david l chen
joohyun kim
raymond j mooney

dlcc cs utexas edu
scimitar cs utexas edu
mooney cs utexas edu

department computer science
university texas austin
university station c austin tx usa

abstract
present novel framework learning interpret generate language perceptual context supervision demonstrate capabilities developing system learns
sportscast simulated robot soccer games english korean without language specific
prior knowledge training employs ambiguous supervision consisting stream descriptive textual comments sequence events extracted simulation trace system
simultaneously establishes correspondences individual comments events
describe building translation model supports parsing generation
present novel learning events worth describing human evaluations
generated commentaries indicate reasonable quality cases even par
produced humans limited domain

introduction
current natural language processing nlp systems built statistical learning trained large annotated corpora however annotating sentences requisite parse
trees marcus santorini marcinkiewicz word senses ide jeronis semantic
roles kingsbury palmer marcus difficult expensive undertaking contrast
children acquire language exposure linguistic input context rich relevant
perceptual environment connecting words phrases objects events world
semantics language grounded perceptual experience harnad ideally machine
learning system would able acquire language similar manner without explicit human supervision step direction present system describe events simulated
soccer game learning sample language commentaries paired traces simulated
activity without language specific prior knowledge screenshot system generated
commentary shown figure
fair amount grounded language learning roy
bailey feldman narayanan lakoff barnard duygulu forsyth de freitas blei jordan yu ballard gold scassellati focus dealing
raw perceptual data rather language issues many systems aimed learn meanings words phrases rather interpreting entire sentences recent work dealt
fairly complex language data liang jordan klein branavan chen zettlemoyer
c

ai access foundation rights reserved

fic hen k im ooney

figure screenshot commentator system
barzilay address three alignment semantic parsing natural
language generation contrast work investigates build complete language learning
system parallel data perceptual context study simulated environment retains many important properties dynamic world multiple agents
actions avoiding many complexities robotics computer vision specifically
use robocup simulator chen foroughi heintz kapetanakis kostiadis kummeneje noda
obst riley steffens wang yin provides fairly detailed physical simulation
robot soccer several groups constructed robocup commentator systems andre
binsted tanaka ishii luke herzog rist provide textual natural language nl
transcript simulated game systems use manually developed templates
learning
commentator system learns semantically interpret generate language robocup
soccer domain observing going commentary game paired evolving simulator state exploiting existing techniques abstracting symbolic description activity
field detailed states physical simulator andre et al obtain pairing
natural language symbolic description perceptual context uttered
however training data highly ambiguous comment usually co occurs several events game integrate enhance existing methods learning semantic parsers
nl generators kate mooney wong mooney order learn understand
generate language ambiguous training data develop system
ambiguous training data learns events worth describing perform
strategic generation deciding say well say tactical generation
conciseness use terminology early work generation e g mckeown strategic tactical
generation commonly referred content selection surface realization respectively



fit raining ultilingual portscaster

evaluate system demonstrate language independence training generate
commentaries english korean experiments test data annotated evaluation purposes demonstrate system learns accurately semantically parse sentences generate
sentences decide events describe finally subjective human evaluation commentated game clips demonstrate limited domain system generates sportscasts
cases similar quality produced humans
three main contributions make first explore possibility
learning grounded language perceptual context form ambiguous parallel
data second investigate several different methods disambiguating data determined
combined score includes tactical strategic generation scores performed
best overall finally built complete system learns sportscast multiple languages
carefully verified automatic human evaluations system able perform
several tasks including disambiguating training data semantic parsing tactical strategic
generation language involved work restricted compared handcrafted commercial sportscasting systems goal demonstrate feasibility learning grounded
language system language specific prior knowledge
remainder structured follows section provides background previous work utilize extend build system section describes sportscasting
data collected train test section section present details
basic methods learning tactical strategic generation respectively initial experimental section discusses extensions basic system incorporate information
strategic generation process disambiguating training data section presents experimental initializing system data disambiguated recent method aligning
language facts may refer section discusses additions try detect superfluous sentences refer extracted event section presents human evaluation
automatically generated sportscasts section reviews related work section discusses future
work section presents conclusions

background
systems learning semantic parsers induce function maps natural language nl sentences
meaning representations mrs formal logical language existing work focused
learning supervised corpus sentence manually annotated correct mr
mooney zettlemoyer collins lu ng lee zettlemoyer jurcicek gasic
keizer mairesse thomson young human annotated corpora expensive
difficult produce limiting utility kate mooney introduced
extension one system k risp kate mooney learn ambiguous
training data requires little human annotation effort however system unable
generate language required sportscasting task thus enhanced another system
called wasp wong mooney capable language generation well semantic
parsing similar manner allow learn ambiguous supervision briefly describe
previous systems systems assume access formal deterministic
context free grammar cfg defines formal meaning representation language mrl since
mrls formal computer interpretable languages grammar usually easily available


fic hen k im ooney

krisp krisper
k risp kernel robust interpretation semantic parsing kate mooney uses
support vector machines svms string kernels build semantic parsers svms state ofthe art machine learning methods learn maximum margin separators prevent fitting
high dimensional data natural language text joachims extended
non linear separators non vector data exploiting kernels implicitly create even higher
dimensional space complex data nearly linearly separable shawe taylor cristianini
recently kernels strings trees effectively applied variety
text learning nlp lodhi saunders shawe taylor cristianini watkins zelenko
aone richardella collins bunescu mooney particular k risp uses
string kernel introduced lodhi et al classify substrings nl sentence
first k risp learns classifiers recognize word phrase nl sentence indicates
particular concept mrl introduced mr uses production rules
mrl grammar represent semantic concepts learns classifiers production
classify nl substrings indicative production semantically parsing
sentence classifier estimates probability production covering different substrings
sentence information used compositionally build complete mr
sentence given partial matching provided string kernels fitting prevention
provided svms k risp experimentally shown particularly robust noisy training
data kate mooney
k risper kate mooney extension k risp handles ambiguous training
data sentence annotated set potential mrs one correct
psuedocode method shown employs iterative analogous
expectation maximization em dempster laird rubin improves upon selection
correct nlmr pairs iteration first iteration lines assumes
mrs paired sentence correct trains k risp resulting noisy supervision
subsequent iterations lines k risper uses currently trained parser score
potential nlmr pair selects likely mr sentence retrains parser
resulting disambiguated supervised data manner k risper able learn type
weak supervision expected grounded language learner exposed sentences ambiguous
contexts however system previously tested artificially corrupted generated
data
wasp wasp
wasp word alignment semantic parsing wong mooney uses state art
statistical machine translation smt techniques brown cocke della pietra della pietra jelinek
lafferty mercer roossin yamada knight chiang learn semantic
parsers smt methods learn effective machine translators training parallel corpora consisting
human translations documents one alternative natural languages resulting
translators typically significantly effective manually developed systems smt
become dominant machine translation wong mooney adapted
methods learn translate nl mrl rather one nl another
first smt word alignment system giza och ney brown della pietra della
pietra mercer used acquire bilingual lexicon consisting nl substrings coupled


fit raining ultilingual portscaster

k risper
input sentences associated sets meaning representations r
output bestexamplesset set nl mr pairs
semanticmodel k risp semantic parser










main
initial training loop
sentence si
meaning representation mj r si
add si mj initialtrainingset
end
end
semanticmodel train initialtrainingset














iterative retraining
repeat
sentence si
meaning representation mj r si
mj score evaluate si mj semanticmodel
end
end
bestexampleset
set consistent examples mr
p
score maximized
semanticmodel rain bestexamplesset
convergence max iter reached
end main



function train trainingexamples
train k risp unambiguous trainingexamples

return trained k risp semantic parser
end function






function evaluate semanticmodel
use k risp semantic parser semanticmodel derivation meaning representation sentence

return parsing score
end function







fic hen k im ooney

translations target mrl formal languages mrls frequently contain many
purely syntactic tokens parentheses brackets difficult align words
nl consequently found much effective align words nl productions
mrl grammar used parse corresponding mr therefore giza used
produce n alignment words nl sentence sequence mrl
productions corresponding top left derivation corresponding mr
complete mrs formed combining nl substrings translations
grammatical framework called synchronous cfg scfg aho ullman forms
basis existing syntax smt yamada knight chiang scfg
right hand side production rule contains two strings case one nl
mrl derivations scfg simultaneously produce nl sentences corresponding mrs
bilingual lexicon acquired word alignments training data used construct set
scfg production rules probabilistic parser produced training maximum entropy
model em learn parameters scfg productions similar methods
used riezler prescher kuhn johnson zettlemoyer collins
translate novel nl sentence mr probabilistic chart parser stolcke used
probable synchronous derivation generates given nl corresponding mr
generated derivation returned
since scfgs symmetric used generate nl mr well parse nl
mr wong mooney allows learned grammar used parsing
generation elegant property important advantages shieber generation
system wasp uses noisy channel model brown et al
arg max pr e f arg max pr e pr f e
e



e

e refers nl string generated given input mr f pr e language model
pr f e parsing model provided wasps learned scfg generation task
sentence e e good sentence priori meaning input
mr language model use standard n gram model useful ranking candidate
generated sentences knight hatzivassiloglou

sportscasting data
train test system assembled human commentated soccer games robocup
simulation league www robocup org since focus language learning computer vision chose use simulated games instead real game video simplify extraction
perceptual information rocco robocup commentators incremental event recognition module andre et al manually developed symbolic representations game events
rule system automatically extract simulator traces extracted
events mainly involve actions ball kicking passing include
game information whether current playmode kickoff offside corner kick
events represented atomic formulas predicate logic timestamps logical facts
constitute requisite mrs manually developed simple cfg formal semantic
language details events detected complete grammar found appendix
nl portion data humans commentate games watching
simulator collected commentaries english korean english commentaries


fit raining ultilingual portscaster

total comments
total words
vocabulary size
avg words per comment

english dataset





korean dataset





table word statistics english korean datasets

number events

total

final
final
final
final











final
final
final
final











number comments
mrs correct mr
english dataset








korean dataset









events per comment
max average std dev






























table alignment statistics english korean datasets comments correct meaning representations associated essentially noise training
data english dataset korean dataset moreover average
possible events linked comment half links
incorrect

produced two different people korean commentaries produced single person
commentators typed comments text box recorded timestamp
construct final ambiguous training data paired comment events
occurred five seconds less comment made examples ambiguous training
data shown figure edges connect sentences events might refer english
translations korean commentaries included figure readers benefit
part actual data note use english words predicates constants
mrs human readability system treats arbitrary conceptual tokens must
learn connection english korean words
annotated total four games namely finals robocup simulation league
year word statistics data shown table
sentences fairly short due nature sportscasts data provides challenges form
synonyms e g pink pinkg pink goalie refer player polysemes
e g kick kicks toward goal refers kick event whereas kicks pink refers
pass event alignment statistics datasets shown table final almost
twice number events games went double overtime


fic hen k im ooney

natural language commentary

meaning representation
badpass purpleplayer
pinkplayer
turnover purpleplayer
pinkplayer
kick pinkplayer
pass pinkplayer pinkplayer
kick pinkplayer

purple goalie turns ball
pink
purple team sloppy today
pink passes pink
pink looks around teammate

kick pinkplayer
ballstopped
kick pinkplayer
pass pinkplayer pinkplayer
kick pinkplayer
pass pinkplayer pinkplayer

pink makes long pass pink

pink passes back pink

sample trace ambiguous english training data

natural language commentary

meaning representation


purple passes purple

kick purpleplayer


purple passes purple

kick purpleplayer


pink steals ball purple

steal pinkplayer


pink passes pink goalie

kick pinkplayer

pass purpleplayer purpleplayer

pass purpleplayer purpleplayer

turnover purpleplayer pinkplayer

playmode free kick r

b sample trace ambiguous korean training data

figure examples training data outgoing edges comments indicate
possibly associated meaning representations considered system bold links
indicate correct matches comments meaning representations



fit raining ultilingual portscaster

evaluation purposes gold standard matching produced examining comment manually selecting correct mr exists matching approximate
sometimes comments contain information present mrs example comment might describe location length pass mr captures participants
pass bold lines figure indicate annotated correct matches sample data notice sentences correct matches one fifth english data one tenth
korean data example sentence purple team sloppy today figure
cannot represented mrl consequently corresponding correct mr
another example korean sentence translation pink passes pink goalie figure b represented mrl correct match due incomplete
event detection free kick called pink passing pink goalie pass event
retrieved finally case sentence pink makes long pass pink figure correct mr falls outside second window game table shows
total number nl sentences number least one recent extracted event
could refer number actually refer one recent extracted
events maximum average standard deviation number recent events paired
comment given

learning tactical generation ambiguous supervision
existing systems capable solving parts sportscasting none
able perform whole task need system deal ambiguous supervision
k risper generate language wasp introduce three systems
overview differences existing systems systems present
shown table
three systems introduced extensions wasp underlying language
learner main need solve disambiguate training data
train wasp create language generator system uses different
disambiguation criteria determine best matching nl sentences mrs

wasper
first system extension wasp manner similar k risp extended create
k risper uses em retraining handle ambiguously annotated data resulting system
call wasper general system learns semantic parsers extended handle
ambiguous data long produce confidence levels given nlmr pairs given set
sentences set mrs associated sentence r disambiguate
data finding pairs r arg maxm p r although
probability used ranking relative potential parses would suffice pseudocode
wasper shown difference compared k risper pseudocode
use wasp semantic parser instead k risp parser produce wasp
language generator well desired final output task


fic hen k im ooney



underlying learner

k risp
k risper
wasp

svm
k risp
giza align words
mr tokens
learn probalistic scfg
wasp
first disambiguate
k risper
train wasp
wasp

wasper
k risper wasp

wasper g en

generate

disambiguation criteria



yes

ambiguous
data

yes


yes
yes

yes
yes

wasps parsing score
k risps parsing score

yes

yes

nist score
best nl given mr

n
k risps parsing score
n

table overview learning systems presented first three existing
systems introduce last three systems able learn ambiguous
training data acquire language generator differ disambiguate
training data

wasper
input sentences associated sets meaning representations r
output bestexamplesset set nl mr pairs
semanticmodel wasp semantic parser language generator
main


end main


function train trainingexamples
train wasp unambiguous trainingexamples

return trained wasp semantic parser language generator
end function







function evaluate semanticmodel

use wasp semantic parser semanticmodel derivation meaning representation sentence

return parsing score
end function




fit raining ultilingual portscaster

krisper wasp
k risp shown quite robust handling noisy training data kate mooney
important training noisy training data used initialize parser
k rispers first iteration however k risper cannot learn language generator necessary sportscasting task create system called k risper wasp
good disambiguating training data capable generation first use k risper
train ambiguous data produce disambiguated training set prediction
likely mr sentence unambiguous training set used train wasp
produce parser generator
wasper gen
k risper wasper criterion selecting best nlmr pairs retraining maximizing probability parsing sentence particular mr however
since wasper capable parsing generation could alternatively select best
nlmr pairs evaluating likely generate sentence particular mr thus
built another version wasper called wasper g en disambiguates training data
order maximize performance generation rather parsing pseudocode shown
wasper except evaluation function uses
generation score rather parsing score select best nlmr pairs
specifically nlmr pair scored computing nist score machine translation mt metric sentence best generated sentence lines
formally given set sentences set mrs associated sentence
r disambiguate data finding pairs r
arg maxm n ist argmaxs p r
nist measures precision translation terms proportion n grams shares
human translation doddington used evaluate nl generation another
popular mt metric bleu score papineni roukos ward zhu inadequate
purpose since comparing one short sentence another instead comparing whole
documents bleu score computes geometric mean n gram precision value n
means score matching n gram found every value n common
setting maximum n two sentences matching gram would
receive bleu score consequently bleu score unable distinguish quality
generated sentences since fairly short contrast nist uses additive score
avoids
experimental evaluation
section presents experimental robocup data four systems k risper wasper
k risper wasp wasper g en since aware existing systems could
learn semantically parse generate language ambiguous supervision perceptual context constructed lower upper baselines unmodified wasp since
natural way use generation score would use probability nl given mr p r
however initial experiments metric produce good tried changing wasp
maximize joint probability instead parsing probability however improve



fic hen k im ooney

wasper g en
input sentences associated sets meaning representations r
output bestexamplesset set nl mr pairs
semanticmodel wasp semantic parser language generator
main


end main


function train trainingexamples


end function





function evaluate semanticmodel
generatedsentence use wasp language generator semanticmodel produce
sentence meaning representation

return nist score generatedsentence
end function




wasp requires unambiguous training data randomly pick meaning sentence
set potential mrs serve lower baseline use wasp trained gold matching
consists correct nlmr pairs annotated human upper baseline represents upper bound systems could achieve disambiguated training data
perfectly
evaluate system three tasks matching parsing generation matching task
measures well systems disambiguate training data parsing generation tasks
measure well systems translate nl mr mr nl respectively
since four games total trained possible combinations one three
games matching measured performance training data since goal disambiguate data parsing generation tested games used training
averaged train test combinations evaluated matching parsing
f measure harmonic mean recall precision precision fraction systems
annotations correct recall fraction annotations gold standard
system correctly produces generation evaluated bleu scores roughly estimates well produced sentences match target sentences treat game
whole document avoid bleu score sentence level comparisons mentioned earlier increase number reference sentences mr
sentences test data corresponding equivalent mrs e g pass pinkplayer
pinkplayer occurs multiple times test data sentences matched mr
gold matchings used reference sentences mr
atching nl



mr

since handling ambiguous training data important aspect grounded language learning
first evaluate well systems pick correct nlmr pairs figure shows fmeasure identifying correct set pairs systems learning systems

















f measure

f measure

raining ultilingual portscaster















wasper
wasper gen
krisper
random matching



wasper
wasper gen
krisper
random matching









number training games





english


number training games



b korean













f measure

f measure

figure matching basic systems wasper g en performs best outperforming
existing system k risper datasets




wasp gold matching
krisper
krisper wasp
wasper
wasper gen
wasp random matching








wasp gold matching
krisper
krisper wasp
wasper
wasper gen
wasp random matching











number training games





english


number training games



b korean

figure semantic parsing basic systems largely mirrors
matching wasper g en performing best overall

perform significantly better random f measure english
korean data wasper g en best system wasper equals outperforms previous
system k risper well
emantic parsing
next present accuracy learned semantic parsers trained system
used parse produce mr sentence test set correct mr
gold standard matching parse considered correct matches gold standard
exactly parsing fairly difficult task usually one way describe
event example player passes player refer event player kicks
ball player thus accurate parsing requires learning different ways people describe

















bleu

bleu

c hen k im ooney







wasp gold matching
krisper wasp
wasper
wasper gen
wasp random matching




wasp gold matching
krisper wasp
wasper
wasper gen
wasp random matching










number training games





english


number training games



b korean

figure tactical generation basic systems relative performances
systems change wasper g en still best system

event synonymy limited verbs data pink pinkg pink goalie
refer player pink team since providing systems prior knowledge
learn different ways referring entity
parsing shown figure generally correlate well matching systems better disambiguating training data better parsing
supervised training data less noisy wasper g en best overall english korean data interesting note k risper relatively well english data
compared matching performance k risp robust noise wasp
kate mooney even though trained noisier set data wasper g en
still produced comparable parser
g eneration
third evaluation task generation wasp systems given mr test
set gold standard matching nl sentence asked generate nl description
quality generated sentence measured comparing gold standard bleu
scoring
task tolerant noise training data parsing system
needs learn one way accurately describe event property reflected
shown figure even baseline system wasp random matching fairly well
outperforming k risper wasp datasets wasper korean data number
event types fairly small relatively small number correct matchings required
perform task well long event type associated correct sentence pattern
often sentence pattern
two tasks wasper g en best system task one possible explanation wasper g ens superior performance stems disambiguation objective function
systems wasper k risper wasp use parsing scores attempt learn good translation model sentence pattern hand wasper g en tries learn good


fit raining ultilingual portscaster

translation model mr pattern thus wasper g en likely converge good
model fewer mr patterns sentence patterns however argued learning
good translation sentence pattern help producing varied commentaries
quality captured bleu score another possible advantage wasper g en
uses softer scoring function probabilities parsing particular sentence
mr sensitive noise training data wasper g en looks top generated
sentences mr even noise data top generated sentence remains relatively
constant moreover minor variations sentence change dramatically since
nist score allows partial matching

learning strategic generation
language generator alone enough produce sportscast addition tactical generation
deciding say something sportscaster must preform strategic generation
choosing say mckeown
developed novel method learning events describe event type e
predicate pass goal system uses training data estimate probability
mentioned sportscaster given gold standard nlmr matches probability
easy estimate however learner know correct matching instead system
must estimate probabilities ambiguous training data compare two basic methods
estimating probabilities
first method uses inferred nlmr matching produced language learning system
probability commenting event type ei estimated percentage events
type ei matched nl sentence
second method call iterative generation strategy learning igsl uses variant em treating matching assignments hidden variables initializing match
prior probability iterating improve probability estimates commenting event
type unlike first method igsl uses information mrs explicitly associated
sentence training shows pseudocode main loop alternates two
steps
calculating expected probability nlmr matching given current model
likely event commented line
update prior probability event type mentioned human commentator
matchings line
first iteration nlmr match assigned
probability inversely proportional
p
amount ambiguity associated sentence eevent pr e event example
sentence associated five possible mrs assign match probability prior
probability mentioning event type estimated average probability assigned
instances event type notice process guarantee proper probability since
mr associated multiple sentences thus limit probability one
subsequent iterations probabilities nlmr matchings updated according
priors assign match prior probability event type normalized across
associated mrs nl sentence update priors event type


fic hen k im ooney

iterative generation strategy learning
input event types e e en number occurrences event type otalcount ei
entire game trace sentences event types associated meaning representations event
output probabilities commenting event type p r ei
initialize pr ei
repeat

event type ei e

matchcount

sentence
p
pr e

p

probofmatch eevent e e
pr e
eevent







matchcount matchcount probofmatch
end
matchcount
pr ei min totalcount e
ensure proper probabilities

end
convergence max iter reached












b c de f g





c b c de f g



h h

c b c de f g




ij
k
j


figure example strategic generation component works every timestep
stochastically select event events occurring moment
decide whether verbalize selected event igsls estimated probability
commented upon

estimated probabilities matchings process repeated probabilities
converge pre specified number iterations occurred
generate sportscast use learned probabilities determine events describe
time step first determine events occurring time select one
randomly normalized probabilities avoid overly verbose want
make comment every time something happening especially event rarely commented
thus stochastically decide whether comment selected event probability
example process shown figure














f measure

f measure

raining ultilingual portscaster


inferred gold matching
igsl
inferred krisper
inferred wasper
inferred wasper gen
inferred random matching




inferred gold matching
igsl
inferred krisper
inferred wasper
inferred wasper gen
inferred random matching









number training games





english


number training games



b korean

figure strategic generation systems novel igsl performs
best almost par upper bound uses gold annotated matchings

event
ballstopped
kick
pass
turnover
badpass

occurrences






commented






igsl






inferred wasper g en






table top frequent events times commented probabilities
learned top english data

experimental evaluation
different methods learning strategic generation evaluated often events
describe test data coincide human decided describe first
inferred matchings produced k risper wasper wasper g en
well gold random matching establishing baselines presented figure
graph clear igsl outperforms learning inferred matchings actually
performs level close gold matching however important note
limiting potential learning gold matching predicates decide
whether talk event
english data probabilities learned igsl inferred matchings wasper g en five frequently occurring events shown table wasper g en learns
fairly good probabilities general well igsl frequent events
igsl uses occurrences events associated possible comments
training iterations rarely commented events ballstopped kick often occur without
comments uttered consequently igsl assigns low prior probabilities
lowers chances matched sentences hand wasper g en
use priors sometimes incorrectly matches comments thus inferred


fic hen k im ooney

matches wasper g en learning higher probabilities commenting rarely
commented events
methods use predicates mrs decide whether comment
perform quite well data collected particular igsl performs best use
strategic generation rest

strategic generation improve matching
section explore knowledge learned strategic generation used improve
accuracy matching sentences mrs previous section described several ways
learn strategic generation including igsl learns directly ambiguous training data
knowing events people tend talk help resolve ambiguities training
data events likely discussed likely matched
nl sentence disambiguating training data therefore section describes methods
integrate strategic generation scores table scoring nlmr pairs used
matching process
wasper gen igsl
wasper g en igsl extension wasper g en uses strategic generation scores
igsl wasper g en uses nist score pick best mr sentence finding mr
generates sentence closet actual nl sentence wasper g en igsl combines tactical
nist strategic igsl generation scores pick best nlmr pairs simply multiplies
nist score igsl score together form composite score score biases
selection matching pairs include events igsl determines priori likely
discussed helpful especially beginning wasp produce
particularly good language generator many instances generated sentences
possible mrs equally bad overlap target sentence even generation
produces perfectly good sentence generation score unreliable comparing
single sentence single reference often short well consequently often
difficult wasper g en distinguish among several mrs equal scores hand
event types different strategic generation scores default choosing
mr higher prior probability mentioned shows pseudocode
wasper g en igsl
variant wasper gen systems
although wasper g en uses nist score estimate goodness nlmr pairs could easily
use mt evaluation metric already discussed unsuitability bleu comparing short individual sentences since assigns zero many pairs however nist score
limitations example normalized may affect performance wasper g en igsl combined igsl score another limitation comes higher order
n grams commentaries domain often short frequently higher order
n gram matches generated sentences target nl sentences
meteor metric banerjee lavie designed resolve weaknesses
bleu nist metrics focused word word matches reference


fit raining ultilingual portscaster

wasper g en igsl
input sentences associated sets meaning representations r
output bestexamplesset set nl mr pairs
semanticmodel wasp semantic parser language generator
main


end main


function train trainingexamples


end function












function evaluate semanticmodel
call collect igsl scores
generatedsentence use wasp language generator semanticmodel produce
sentence meaning representation
tacticalgenerationscore nist score generatedsentence
strategicgenerationscore pr event type
return tacticalgenerationscore strategicgenerationscore
end function

sentence test sentence meteor first evaluates uni gram matches reference
test sentence determines well words ordered meteor seems
appropriate domain good generated sentences missing adjectives adverbs critical meaning sentence prevent higher order n gram matches
addition meteor normalized may combine effectively igsl scores range
experimental evaluation
evaluated systems wasper g en gsl nist meteor scoring
methodology section matching shown figure including
wasper g en best system previous section wasper g en igsl
nist meteor scoring clearly outperforms wasper g en indicates strategicgeneration information help disambiguate data different mt metrics produces
less noticeable effect clear winner english data however meteor seems
improve performance korean data
parsing shown figure previously noted parsing generally mirror
matching systems outperform wasper g en previously best system
english data clear advantage nist meteor
korean data gives slight edge meteor metric
tactical generation shown figure english korean
data systems come close performance wasper g en beat however
systems outperform k risper wasp wasper shown figure

















f measure

f measure

c hen k im ooney












wasper gen
wasper gen igsl
wasper gen igsl meteor



wasper gen
wasper gen igsl
wasper gen igsl meteor









number training games





english


number training games



b korean
















f measure

f measure

figure matching integrating strategic information improves previously best system wasper g en choice mt metric used however makes
less impact










wasp gold matching
wasper gen
wasper gen igsl
wasper gen igsl meteor



wasp gold matching
wasper gen
wasper gen igsl
wasper gen igsl meteor









number training games





english


number training games



b korean

figure semantic parsing similar matching integrating
strategic generation information improves performance


















bleu

bleu

raining ultilingual portscaster










wasp gold matching
wasper gen
wasper gen igsl
wasper gen igsl meteor



wasp gold matching
wasper gen
wasper gen igsl
wasper gen igsl meteor









number training games





english


number training games



b korean

figure tactical generation two systems come close performance
wasper g en beat however outperform systems
presented earlier shown figure

overall expected strategic information improves performance matching
semantic parsing tasks english korean datasets wasper g en igsl
variant meteor metric clearly outperform wasper g en utilize
strategic information however strategic information improve tactical generation
could due ceiling effect wasper g en already performs level near upper
baseline matching performance improved generation performance little room
grow

generative alignment model
recently liang et al developed generative model used match naturallanguage sentences facts corresponding database may refer one
evaluation domains used english robocup sportscasting data method solves
matching alignment data address tasks semantic parsing
language generation however generative model elegantly integrates simple strategic
tactical language generation order overall probable alignment sentences
events demonstrated improved matching performance english data generating
accurate nlmr pairs best system thus curious could
used improve systems perform semantic parsing generation
ran code korean data resulted much worse matching compared
best system seen table
simplest way utilizing use nlmr pairs produced method
supervised data wasp expected improved nlmr pairs english data resulted
improved semantic parsers seen table even korean dataset
training matchings produced system ended fairly well even though matching performance poor tactical generation matching produced marginal
improvement english dataset surprisingly large improvement korean data


fic hen k im ooney


liang et al
wasper
wasper g en
wasper g en gsl
wasper g en gsl eteor

english dataset
initialization initialized










korean dataset
initialization initialized










table matching f scores fold cross validation english korean
datasets systems run initialization initialized matchings produced
liang et al system


wasp
wasper
wasper g en
wasper g en gsl
wasper g en gsl eteor

english dataset
initialization initialized
n










korean dataset
initialization initialized
n










table semantic parsing f scores fold cross validation english
korean datasets systems run initialization initialized matchings
produced liang et al system


wasp
wasper
wasper g en
wasper g en gsl
wasper g en gsl eteor

english dataset
initialization initialized
n










korean dataset
initialization initialized
n










table tactical generation bleu score fold cross validation english
korean datasets systems run initialization initialized matchings
produced liang et al system

shown table overall alignments produced liang et al system resulted good
semantic parsers tactical generators
addition training wasp alignment utilize output better
starting point systems instead initializing iterative alignment methods
model trained ambiguous nlmr pairs initialized disambiguated
nlmr pairs produced liang et al system


fit raining ultilingual portscaster

initializing systems manner almost improved performance three
tasks tables moreover best systems exceed simply training wasp alignment cases except semantic parsing english data thus
combining liang et al alignment disambiguation techniques seems produce best
overall english data wasper initialization performs best matching generation slightly worse semantic parsing task compared wasp trained
liang et al alignment korean data systems better training wasp
alignment wasper g en gsl eteor initialization performs best matching
semantic parsing wasper g en initialization performs best generation
overall initializing systems alignment output liang et al generative model
improved performance expected starting cleaner set data led better initial semantic
parsers language generators led better end furthermore incorporating
semantic parser tactical generator able improve liang et al alignments
achieve even better cases

removing superfluous comments
far discussed handle ambiguity multiple possible mrs
nl sentence training methods assume nl sentence matches
exactly one potential mrs however comments superfluous sense
refer currently extracted event represented set potential mrs previously
shown tables one fifth english sentences one tenth korean sentences
superfluous sense
many reasons superfluous sentences occur naturally language
people talk current environment domain sportscasters often mention
past events general information particular teams players moreover depending
application chosen mrl may represent things people talk example
robocup mrl cannot represent information players actively engaged
ball finally even sentence represented chosen mrl errors perceptual
system incorrect estimation event occurred lead superfluous sentences
perceptual errors alleviated degree increasing size window used
capture potential mrs previous seconds experiments however comes
cost increased ambiguity associates mrs sentence
deal superfluous sentences eliminate lowest scoring nlmr
pairs e g lowest parsing scores wasper lowest nist scores wasper g en however
order set pruning threshold need automatically estimate amount superfluous
commentary absence supervised data notice looks similar
strategic generation estimating likely mr participates correct matching
opposed likely nl sentence participates correct matching approaches used
cannot applied first cannot use matches inferred existing systems estimate
fraction superfluous comments since current systems match every sentence mr
difficult develop similar igsl due imbalance nl sentences
mrs since many mrs examples events occurring without
commentaries vice versa


fic hen k im ooney

estimating superfluous rate internal cross validation
propose form internal e within training set cross validation estimate rate
superfluous comments used conjunction systems
chose implement k risper trains much faster systems makes
tractable train many different semantic parsers choose best one basic idea
use part ambiguous training data estimate accuracy semantic parser even though
know correct matchings assuming reasonable superfluous sentence rate know
time correct mr contained set mrs associated nl sentence
thus assume semantic parser parses nl sentence one mrs associated
better one parses mr set estimating
accuracy evaluate semantic parsers learned pruning thresholds pick
best one briefly summarized following steps
split training set internal training set internal validation set
train k risper n times internal training set n different threshold values eliminating lowest scoring nlmr pairs threshold retraining iteration

test n semantic parsers internal validation set determine parser able
parse largest number sentences one potential mrs
use threshold value produced best parser previous step train final parser
complete original training set
experiments
evaluated effect removing superfluous sentences three tasks matching parsing
generation present k risper k risper wasp matching
k risper responsible disambiguating training data
systems k risper wasps generation
k risper wasp since k risper cannot perform generation
matching shown figure demonstrate removing superfluous sentences
improve performance english korean although difference small absolute
terms parsing shown figure indicate removing superfluous sentences usually
improves accuracy k risper k risper wasp marginally observed
many times parsing consistent matching finally tactical generation shown figure suggest removing superfluous comments actually decreases
performance somewhat potential explanation generation less sensitive
noisy training data removing superfluous comments improves purity training data
removes potentially useful examples consequently system learn generate sentences removed data overall generation advantage
cleaner disambiguated training data apparently outweighed loss data

















f measure

f measure

raining ultilingual portscaster



















krisper
krisper superfluous comment removal



krisper
krisper superfluous comment removal





number training games





english


number training games



b korean
















f measure

f measure

figure matching comparing effects removing superfluous comments










krisper
krisper superfluous comment removal
krisper wasp
krisper wasp superfluous comment removal



krisper
krisper superfluous comment removal
krisper wasp
krisper wasp superfluous comment removal









number training games





english


number training games



b korean
















bleu

bleu

figure semantic parsing improved marginally superfluous comment removal

















krisper wasp
krisper wasp superfluous comment removal



krisper wasp
krisper wasp superfluous comment removal





number training games





english


number training games



b korean

figure tactical generation performance decreases removing superfluous comments



fic hen k im ooney

human subjective evaluation
best automatic evaluation generation imperfect approximation human assessment
moreover automatically evaluating quality entire generated sportscast even difficult consequently used amazons mechanical turk collect human judgements
produced sportscasts human judge shown three clips simulated game video one sitting video clips total clips use game segments minutes one
four games robocup finals game segments commentated
human system use igsl determine events comment
wasper g en best performing system tactical generation produce commentaries
make commentaries varied took top outputs wasper g en chose
one stochastically weighted scores system trained three games leaving game test segment extracted video clips accompanied
commentaries appear subtitles screen well audio produced automated text speech system videos shown random counter balanced order ensure
consistent bias toward segments shown earlier later asked judges score
commentaries following metrics

score






fluency
flawless
good
non native
disfluent
gibberish

semantic
correctness

usually
sometimes
rarely
never

sportscasting
ability
excellent
good
average
bad
terrible

fluency semantic correctness adequacy standard metrics human evaluations nl
translations generations fluency measures well commentaries structured including
syntax grammar semantic correctness indicates whether commentaries accurately describe
happening game finally sportscasting ability measures overall quality
sportscast includes whether sportscasts interesting flow well addition
metrics asked whether thought sportscast composed human
computer human
since mechanical turk recruits judges internet make sure judges
assigning ratings randomly thus addition asking rate video
asked count number goals video incorrect responses question caused
ratings discarded ensure judges faithfully watched entire clip
assigning ratings pruning average ratings original ratings
videos english data since difficult recruit korean judges
internet recruited person collected ratings average video
korean data table english korean data respectively
statistically significant shown boldface
surprisingly good english data across categories machine actually
scoring higher human average however differences statistically significant
sample video clips sound available web http www cs utexas edu users ml
clamp sportscasting



fit raining ultilingual portscaster

final
final
final
final
average

commentator
human
machine
human
machine
human
machine
human
machine
human
machine

fluency











semantic
correctness











sportscasting
ability











human











table human evaluation overall sportscasts english data bold numbers indicate statistical
significance

final
final
final
final
average

commentator
human
machine
human
machine
human
machine
human
machine
human
machine

fluency











semantic
correctness











sportscasting
ability











human











table human evaluation overall sportscasts korean data bold numbers indicate statistical
significance



fic hen k im ooney

unpaired test p nevertheless encouraging see machine
rated highly variance humans performance since two different
commentators notably compared machine humans performance final
quite good commentary included many details position players
types passes comments overall flow game hand
humans performance final quite bad human commentator
mechanical used sentence pattern repeatedly machine performance
even throughout although sometimes gets lucky example machine serendipitously said
beginning exciting match near start final clip simply
statement incorrectly learned correspond extracted mr actually unrelated
korean impressive human beats machine average
categories however largest difference scores category
moreover absolute scores indicate generated korean sportscast least acceptable
quality judges even mistakenly thought produced humans one third time
part reason worse performance compared english data korean commentaries fairly detailed included events extracted limited perceptual
system thus machine simply way competing limited expressing
information present extracted mrs
elicited comments human judges get qualitative evaluation overall
judges thought generated commentaries good accurately described actions
field picking top generated sentences added variability machine generated
sportscasts improved compared earlier experiments presented chen
mooney however machine still sometimes misses significant plays scoring
corner kicks plays happen much less frequently often coincide
many events e g shooting ball kickoffs co occur scoring thus machine
harder time learning infrequent events another issue concerns representation
many people complain long gaps sportscasts lack details event detector
concentrates ball possession positions elapsed time thus player holding onto
ball dribbling long time produce events detected simulated perceptual
system short pass backfield treated exactly long pass across
field near goal finally people desired colorful commentary background information
statistics analysis game fill voids somewhat orthogonal issue since
goal build play play commentator described events currently happening

related work
section review related work semantic parsing natural language generation
well grounded language learning
semantic parsing
mentioned section existing work semantic parser learners focused supervised
learning sentence annotated semantic meaning semantic parser learners additionally require syntactic annotations ge mooney prior syntactic knowledge target language ge mooney zettlemoyer collins since
world never provides direct feedback syntactic structure language learning methods


fit raining ultilingual portscaster

require syntactic annotation directly applicable grounded language learning therefore
methods learn semantic annotation critical learning language perceptual
context
use logic formulas mrs particular mrl use contains atomic
formulas equivalently represented frames slots systems use
transformation learning jurcicek et al markov logic meza ruiz riedel
lemon learn semantic parsers frames slots principle framework
used semantic parser learner long provides confidence scores parse
natural language generation
several existing systems sportscast robocup games andre et al given
game states provided robocup simulator extract game events generate real time
commentaries consider many practical issues timeliness coherence variability
emotion needed produce good sportscasts however systems hand built
generate language pre determined templates rules contrast concentrate
learning induce generation components ambiguous training data nevertheless augmenting system components systems could improve
final sportscasts produced
prior work learning lexicon elementary semantic expressions corresponding natural language realizations barzilay lee work uses multiple sequence
alignment datasets supply several verbalizations corresponding semantics extract
dictionary
duboue mckeown first propose learning strategic generation automatically data semantics associated texts system learns classifier
determines whether particular piece information included presentation
recent work learning strategic generation reinforcement learning
zaragoza li work involves game setting speaker must aid listener
reaching given destination avoiding obstacles game played repeatedly
optimal strategy conveys pertinent information minimizing number
messages consider different setting reinforcements available
strategic generation learner
addition work performing strategic generation collective task
barzilay lapata considering strategic generation decisions jointly captures
dependencies utterances creates consistent overall output consistent
humans perform task could potentially help system produce
better overall sportscasts
grounded language learning
one ambitious end end visually grounded scene description system vitra herzog wazinski comments traffic scenes soccer matches system first
transforms raw visual data geometrical representations next set rules extract spatial relations interesting motion events representations presumed intentions plans plan


fic hen k im ooney

interactions agents extracted domain specific knowledge however
since system hand coded cannot adapted easily domains
srihari burhans used captions accompanying photos help identify people
objects introduced idea visual semantics theory extracting visual information
constraints accompanying text example caption information system
determine spatial relationship entities mentioned likely size shape
object interest whether entity natural artificial however system
hand coded knowledge
siskind performed earliest work learning grounded word meanings
learning addresses ambiguous training referential uncertainty
semantic lexical acquisition address larger learning complete semantic
parsers language generators
several robotics computer vision researchers worked inferring grounded meanings
individual words short referring expressions visual perceptual context e g roy
bailey et al barnard et al yu ballard however complexity
natural language used existing work restrictive many systems use pre coded
knowledge language almost use static images learn language describing objects
relations cannot learn language describing actions sophisticated grammatical
formalism used learn syntax work finite state hidden markov model contrast
work exploits latest techniques statistical context free grammars syntax statistical
machine translation handle complexities natural language
recently gold scassellati built system called twig uses existing language knowledge help learn meaning words robot uses partial parses focus
attention possible meanings words playing game catch robot able
learn meaning well identity relations
variety work learning captions accompany pictures
videos satoh nakamura kanade berg berg edwards forsyth area
particular interest given large amount captioned images video available web
television satoh et al built system detect faces newscasts however use fairly
simple manually written rules determine entity picture language refers
berg et al used elaborate learning method cluster faces names
data estimate likelihood entity appearing picture given context
recent work video retrieval focused learning recognize events sports videos
connecting english words appearing accompanying closed captions fleischman
roy gupta mooney however work learns connection
individual words video events learn describe events full grammatical
sentences avoid difficult computer vision work uses simulated world
perception complex events participants much simpler
addition observing events passively work grounded language learning interactive environments computer video games gorniak roy
work players cooperate communicate order accomplish certain task
system learns map spoken instructions specific actions however relies existing statistical
parsers learn syntax semantics language perceptual environment
alone kerr cohen chang developed system learns grounded word meanings
nouns adjectives spatial prepositions human instructing perform tasks vir

fit raining ultilingual portscaster

tual world however system assumes existing syntactic parser prior knowledge verb
semantics unable learn experience
recently interest learning interpret english instructions describing use particular website perform computer tasks branavan et al lau
drews nichols systems learn predict correct computer action pressing
button choosing menu item typing text field etc corresponding step instructions instead parallel training data perceptual context systems utilize
direct matches words natural language instructions english words explicitly occurring menu items computer instructions order establish connection
language environment
one core subproblems work addresses matching sentences facts world
refer recent projects attempt align text english summaries american
football games database records contain statistics events game snyder
barzilay liang et al however snyder barzilay use supervised
requires annotating correct correspondences text semantic
representations hand liang et al developed unsupervised
generative model solve alignment demonstrated improved
matching sentences events robocup english sportscasting data however work
address semantic parsing language generation section presents showing
methods improve nlmr matches produced well use
learn parsers generators

future work
previously discussed limitations current system due inadequacies
perception events extracted robocup simulator language commentary
particularly korean data refers information events currently represented
extracted mrs example player dribbling ball captured perceptual system
event extractor could extended include information output representations
commentaries immediate actions happening field
refer statistics game background information analysis game
difficult obtain would simple augment potential mrs include events
current score number turnovers etc may difficult learn correctly
potentially would make commentaries much natural engaging
statements commentaries specifically refer pattern activity across several
recent events rather single event example one english commentaries
statement purple team sloppy today appears series turn overs team
simulated perception could extended extract patterns activity sloppiness
however assumes concepts predefined extracting many higher level
predicates would greatly increase ambiguity training data current system assumes
already concepts words needs learn perceive concepts represent
mrs however would interesting include whorfian style language
learning whorf unknown word sloppiness could actually cause
creation concept content words seem consistently correlate
perceived event system could collect examples recent activity word used try


fic hen k im ooney

learn higher level concept captures regularity situations example given
examples situations referred sloppy inductive logic programming system lavrac
dzeroski able detect pattern several recent turnovers
another shortcoming current system mr treated independently fails
exploit fact many mrs related example pass preceded kick
bad pass followed turnover natural way use graphical representation
represent entities events relationships
currently tactical strategic generation system loosely coupled however
conceptually much closely related solving one help solve
initializing system output liang et al uses generative model
includes strategic tactical components produced somewhat better however
interaction components loose tighter integration different
pieces could yield stronger tasks
obvious extension current work apply real robocup games rather
simulated ones recent work rozinat zickler veloso van der aalst mcmillen
analyzes games robocup small size league video overhead camera
symbolic event trace extracted real perceptual system methods could
applied real world games speech recognition accept spoken language input another
obvious extension
currently exploring extending learn interpret generate nl instructions navigating virtual environment system observe one person giving english
navigation instructions e g go hall turn left pass chair another person follows directions get chosen destination collecting examples sentences
paired actions executed together information local environment
system construct ambiguous supervised dataset language learning
could eventually lead virtual agents games educational simulations automatically
learn interpret generate natural language instructions

conclusion
presented end end system learns generate natural language sportscasts
simulated robocup soccer games training sample human commentaries paired automatically extracted game events learning semantically interpret generate language without
explicitly annotated training data demonstrated system learn language simply
observing linguistic descriptions ongoing events demonstrated systems language
independence successfully training produce sportscasts english korean
dealing ambiguous supervision inherent training environment critical issue
learning language perceptual context evaluated methods disambiguating
training data order learn semantic parsers language generators generation
evaluation metric criterion selecting best nlmr pairs produced better
semantic parsing scores initial training data noisy system learns
model strategic generation ambiguous training data estimating probability
event type evokes human commentary moreover strategic generation information
help disambiguate training data shown improve demonstrated
system initialized alignments produced different system achieve better


fit raining ultilingual portscaster

system alone finally experimental evaluation verified overall system
learns accurately parse generate comments generate sportscasts competitive
produced humans

acknowledgments
thank adam bossy work simulating perception robocup games
thank percy liang sharing software experimental us finally thank
anonymous reviewers jair editor lillian lee insightful comments
helped improve final presentation work funded nsf grant iis
x experiments run mastodon cluster provided nsf grant
eia

appendix details meaning representation language
table shows brief explanations different events detect simulated perception
event
playmode
ballstopped
turnover
kick
pass
badpass
defense
steal
block

description
signifies current play mode defined game
ball speed minimum threshold
current possessor ball last possessor different teams
player possession ball one time interval next
player gains possession ball different player team
pass player gaining possession ball different team
transfer one player opposing player penalty area
player possession ball one time interval another player
different team next time interval
transfer one player opposing goalie
table description different events detected

include context free grammar developed meaning representation language derivations start root symbol





















playmode playmode
ballstopped
turnover player player
kick player
pass player player
badpass player player
defense player player
steal player
block player



fic hen k im ooney

playmode
playmode
playmode
playmode
playmode
playmode
playmode
playmode
playmode
playmode
playmode
playmode
playmode
playmode
playmode
player
player
player
player
player
player
player
player
player
player
player
player
player
player
player
player
player
player
player
player
player
player








































kick l
kick r
kick l
kick r
play
offside l
offside r
free kick l
free kick r
corner kick l
corner kick r
goal kick l
goal kick r
goal l
goal r

pink
pink
pink
pink
pink
pink
pink
pink
pink
pink
pink
purple
purple
purple
purple
purple
purple
purple
purple
purple
purple
purple



fit raining ultilingual portscaster

references
aho v ullman j theory parsing translation compiling prentice
hall englewood cliffs nj
andre e binsted k tanaka ishii k luke herzog g rist three robocup
simulation league commentator systems ai magazine
bailey feldman j narayanan lakoff g modeling embodied lexical development proceedings nineteenth annual conference cognitive science society
banerjee lavie meteor automatic metric mt evaluation improved
correlation human judgments proceedings acl workshop intrinsic
extrinsic evaluation measures machine translation summarization pp
ann arbor michigan association computational linguistics
barnard k duygulu p forsyth de freitas n blei jordan matching
words pictures journal machine learning
barzilay r lapata collective content selection concept text generation
proceedings human language technology conference conference empirical
methods natural language processing hlt emnlp
barzilay r lee l bootstrapping lexical choice via multiple sequence alignment
proceedings conference empirical methods natural language processing
emnlp
berg l berg c edwards j forsyth whos picture advances
neural information processing systems nips
branavan chen h zettlemoyer l barzilay r reinforcement learning
mapping instructions actions proceedings joint conference th annual
meeting association computational linguistics th international joint
conference natural language processing asian federation natural language
processin acl ijcnlp
brown p f cocke j della pietra della pietra v j jelinek f lafferty j mercer
r l roossin p statistical machine translation computational
linguistics
brown p f della pietra v j della pietra mercer r l mathematics
statistical machine translation parameter estimation computational linguistics

bunescu r c mooney r j subsequence kernels relation extraction weiss
scholkopf b platt j eds advances neural information processing systems
nips vancouver bc
chen l mooney r j learning sportscast test grounded language acquisition proceedings th international conference machine learning icml
helsinki finland


fic hen k im ooney

chen foroughi e heintz f kapetanakis kostiadis k kummeneje j noda obst
riley p steffens wang yin x users manual robocup soccer server
manual soccer server version later available http sourceforge
net projects sserver
chiang hierarchical phrase model statistical machine translation proceedings nd annual meeting association computational linguistics acl pp ann arbor mi
collins ranking parsing tagging kernels discrete structures voted perceptron proceedings th annual meeting association
computational linguistics acl pp philadelphia pa
dempster p laird n rubin b maximum likelihood incomplete data
via em journal royal statistical society b
doddington g automatic evaluation machine translation quality n gram cooccurrence statistics proceedings arpa workshop human language technology
pp san diego ca
duboue p mckeown k r statistical acquisition content selection rules
natural language generation proceedings conference empirical methods
natural language processing emnlp pp
fleischman roy situated meaning sports video retrieval proceedings human language technologies conference north american chapter
association computational linguistics naacl hlt rochester ny
ge r mooney r j statistical semantic parser integrates syntax semantics
proceedings ninth conference computational natural language learning conll pp ann arbor mi
ge r mooney r j learning compositional semantic parser existing syntactic parser proceedings joint conference th annual meeting association computational linguistics th international joint conference natural
language processing asian federation natural language processin acl ijcnlp

gold k scassellati b robot uses existing vocabulary infer non visual word
meanings observation proceedings twenty second conference artificial
intelligence aaai
gorniak p roy speaking sidekick understanding situated speech
computer role playing games proceedings th conference artificial intelligence
interactive digital entertainment stanford ca
gupta mooney r closed captions train activity recognizers improve
video retrieval proceedings cvpr workshop visual contextual learning
annotated images videos vcl miami fl


fit raining ultilingual portscaster

harnad symbol grounding physica
herzog g wazinski p visual translator linking perceptions natural language
descriptions artificial intelligence review
ide n jeronis j introduction special issue word sense disambiguation
state art computational linguistics
joachims text categorization support vector machines learning many relevant
features proceedings tenth european conference machine learning ecml pp berlin springer verlag
jurcicek j gasic keizer mairesse f thomson b young transformationbased learning semantic parsing interspeech brighton uk
kate r j mooney r j string kernels learning semantic parsers proceedings st international conference computational linguistics th annual
meeting association computational linguistics coling acl pp
sydney australia
kate r j mooney r j learning language semantics ambiguous supervision
proceedings twenty second conference artificial intelligence aaai pp
vancouver canada
kerr w cohen p r chang h learning playing wubble world proceedings fourth artificial intelligence interactive digital entertainment conference
aiide palo alto ca
kingsbury p palmer marcus adding semantic annotation penn treebank
proceedings human language technology conference san diego ca
knight k hatzivassiloglou v two level many paths generation proceedings
rd annual meeting association computational linguistics acl pp
cambridge
lau drews c nichols j interpreting written instructions proceedings
twenty first international joint conference artificial intelligence ijcai
lavrac n dzeroski inductive logic programming techniques applications
ellis horwood
liang p jordan klein learning semantic correspondences less supervision proceedings joint conference th annual meeting association
computational linguistics th international joint conference natural language
processing asian federation natural language processin acl ijcnlp
lodhi h saunders c shawe taylor j cristianini n watkins c text classification
string kernels journal machine learning


fic hen k im ooney

lu w ng h lee w zettlemoyer l generative model parsing natural
language meaning representations proceedings conference empirical
methods natural language processing emnlp honolulu hi
marcus santorini b marcinkiewicz building large annotated corpus
english penn treebank computational linguistics
mckeown k r discourse strategies generating natural language text artificial intelligence
meza ruiz v riedel lemon spoken language understanding dialogue
systems layer markov logic network improving semantic accuracy proceedings
londial
mooney r j learning semantic parsing gelbukh ed computational linguistics intelligent text processing proceedings th international conference
cicling mexico city pp springer verlag berlin
och f j ney h systematic comparison statistical alignment
computational linguistics
papineni k roukos ward zhu w j bleu method automatic evaluation
machine translation proceedings th annual meeting association
computational linguistics acl pp philadelphia pa
riezler prescher kuhn j johnson lexicalized stochastic modeling
constraint grammars log linear measures em training proceedings
th annual meeting association computational linguistics acl pp
hong kong
roy learning visually grounded words syntax scene description task computer speech language
rozinat zickler veloso van der aalst w mcmillen c analyzing multiagent activity logs process mining techniques proceedings th international
symposium distributed autonomous robotic systems dars tsukuba japan
satoh nakamura kanade name naming detecting faces video
integration image natural language processing proceedings fifteenth
international joint conference artificial intelligence ijcai
shawe taylor j cristianini n kernel methods pattern analysis cambridge university press
shieber uniform architecture parsing generation proceedings
th international conference computational linguistics coling pp budapest hungary
siskind j computational study cross situational techniques learning word tomeaning mappings cognition


fit raining ultilingual portscaster

snyder b barzilay r database text alignment via structured multilabel classification proceedings twentieth international joint conference artificial intelligence
ijcai
srihari r k burhans visual semantics extracting visual information
text accompanying pictures proceedings twelfth national conference artificial
intelligence aaai
stolcke efficient probabilistic context free parsing computes prefix
probabilities computational linguistics
whorf b l language thought reality selected writings mit press
wong mooney r j learning semantic parsing statistical machine translation proceedings human language technology conference north american chapter
association computational linguistics annual meeting hlt naacl pp
york city ny
wong mooney r j generation inverting semantic parser uses statistical
machine translation proceedings human language technologies conference
north american chapter association computational linguistics naacl hlt pp rochester ny
yamada k knight k syntax statistical translation model proceedings
th annual meeting association computational linguistics acl pp
toulouse france
yu c ballard h integration grounding language learning objects
proceedings nineteenth national conference artificial intelligence aaai pp

zaragoza h li c h learning talk descriptive games proceedings
human language technology conference conference empirical methods
natural language processing hlt emnlp pp vancouver canada
zelenko aone c richardella kernel methods relation extraction journal
machine learning
zettlemoyer l collins learning map sentences logical form structured
classification probabilistic categorial grammars proceedings st conference
uncertainty artificial intelligence uai edinburgh scotland
zettlemoyer l collins online learning relaxed ccg grammars parsing
logical form proceedings joint conference empirical methods natural
language processing computational natural language learning emnlp conll
pp prague czech republic




