Journal Artificial Intelligence Research 38 (2010) 371-413

Submitted 2/10; published 7/10

Approximate Model-Based Diagnosis
Using Greedy Stochastic Search
Alexander Feldman

a.b.feldman@tudelft.nl

Delft University Technology
Mekelweg 4, 2628 CD, Delft, Netherlands

Gregory Provan

g.provan@cs.ucc.ie

University College Cork
College Road, Cork, Ireland

Arjan van Gemund

a.j.c.vangemund@tudelft.nl

Delft University Technology
Mekelweg 4, 2628 CD, Delft, Netherlands

Abstract
propose StochAstic Fault diagnosis AlgoRIthm, called Safari, trades
guarantees computing minimal diagnoses computational efficiency. empirically
demonstrate, using 74XXX ISCAS85 suites benchmark combinatorial circuits,
Safari achieves several orders-of-magnitude speedup two well-known deterministic algorithms, CDA HA , multiple-fault diagnoses; further, Safari compute
range multiple-fault diagnoses CDA HA cannot. prove Safari
optimal range propositional fault models, widely-used weak-fault
models (models ignorance abnormal behavior). discuss optimality Safari class strong-fault circuit models stuck-at failure modes. modeling
algorithm Markov chain, provide exact bounds minimality diagnosis computed. Safari displays strong anytime behavior, return diagnosis
non-trivial inference time.

1. Introduction
Model-Based Diagnosis (MBD) area artificial intelligence uses system model,
together observations system behavior, isolate sets faulty components (diagnoses) explain observed behavior according minimality criterion.
standard MBD formalization (Reiter, 1987) frames diagnostic problem terms set
logical clauses include mode-variables describing nominal fault status
system components; diagnostic status system computed given
observation systems sensors. MBD provides sound complete approach
enumerating multiple-fault diagnoses, exact algorithms guarantee finding diagnosis optimal respect number faulty components, probabilistic likelihood,
etc.
biggest challenge (and impediment industrial deployment) computational
complexity MBD problem. MBD problem determining exists diagnosis k faults NP-hard arbitrary propositional models consider
article (Bylander, Allemang, Tanner, & Josephson, 1991; Friedrich, Gottlob, & Nejdl,
1990). Computing set diagnoses harder still, since possibly exponenc
2010
AI Access Foundation. rights reserved.

fiFeldman, Provan, & van Gemund

tially many diagnoses. Since almost proposed MBD algorithms complete
exact, authors proposing possible trade-offs completeness faster
consistency checking employing methods BCP (Williams & Ragno, 2007),
complexity problem still remains major challenge MBD.
overcome complexity problem, propose novel approximation approach
multiple-fault diagnosis, based stochastic algorithm. Safari (StochAstic Fault diagnosis AlgoRIthm) sacrifices guarantees optimality, diagnostic systems
faults described terms arbitrary deviation nominal behavior, Safari
compute diagnoses several orders magnitude faster competing algorithms.
contributions follows. (1) paper introduces approximation algorithm
computing diagnoses within MBD framework, based greedy stochastic algorithm.
(2) show compute minimal-cardinality diagnoses weak fault models
polynomial time (calling incomplete SAT-solver implements Boolean Constraint
Propagation1 (BCP) only), general frameworks (such sub-class strong
fault models) amenable class algorithm. (3) model Safari search
Markov chain show performance optimality trade-offs algorithm makes.
(4) apply algorithm suite benchmark combinatorial circuits, demonstrating order-of-magnitude speedup two state-of-the-art deterministic algorithms, CDA
HA , multiple-fault diagnoses. (5) compare performance Safari
range Max-SAT algorithms benchmark problems. results indicate that,
whereas search complexity deterministic algorithms tested increases exponentially fault cardinality, search complexity stochastic algorithm appears
independent fault cardinality. Safari great practical significance,
compute large fraction minimal-cardinality diagnoses discrete systems large
complex diagnosed existing deterministic algorithms.

2. Technical Background
discussion continues formalizing MBD notions. paper uses traditional
diagnostic definitions (de Kleer & Williams, 1987), except use propositional logic
terms (conjunctions literals) instead sets failing components.
Central MBD, model artifact represented propositional formula
set variables. Discerning two subsets variables assumable observable 2
variables gives us diagnostic system.
Definition 1 (Diagnostic System). diagnostic system DS defined triple DS =
hSD, COMPS, OBSi, SD propositional theory set variables V , COMPS
V , OBS V , COMPS set assumables, OBS set observables.
Throughout paper assume OBS COMPS = SD 6|=.
propositional theories used system descriptions interest MBD. Diagnostic systems characterized restricted set models, restriction making problem
1. formulae Conjunctive Normal Form (CNF), BCP implemented unit resolution
rule.
2. MBD literature assumable variables referred component, failure-mode,
health variables. Observable variables called measurable, control variables.

372

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

computing diagnosis amenable algorithms one presented paper.
consider two main classes models.
Definition 2 (Weak-Fault Model). diagnostic system DS = hSD, COMPS, OBSi belongs
class WFM iff COMPS = {h1 , h2 , . . . , hn }, SD equivalent (h1 F1 ) (h2
F2 ) . . . (hn Fn ) COMPS V = , V set variables appearing
propositional formulae F1 , F2 , . . . , Fn .
Note conventional selection sign health variables h1 , h2 , . . . hn . Alternatively, negative literals, e.g., f1 , f2 , . . . , fn used express faults, case
weak-fault model form (f1 F1 ) . . . (fn Fn ). authors use ab
abnormal ok healthy.
Weak-fault models sometimes referred models ignorance abnormal
behavior (de Kleer, Mackworth, & Reiter, 1992), implicit fault systems. Alternatively,
model may specify faulty behavior components. following definition,
aim simplifying formalism throughout paper, adopt slightly restrictive
representation faults, allowing single fault-mode per assumable variable.
easily generalized introducing multi-valued logic suitable encodings (Hoos, 1999).
Definition 3 (Strong-Fault Model). diagnostic system DS = hSD, COMPS, OBSi belongs
class SFM iff SD equivalent (h1 F1,1 ) (h1 F1,2 ) . . . (hn Fn,1 )
(hn Fn,2 ) 1 i, j n, k {1, 2}, {hi } COMPS, F{j,k} propositional
formula, none hi appears Fj,k .
Membership testing WFM SFM classes performed efficiently many
cases, example, model represented explicitly Def. 2 Def. 3.
2.1 Running Example
use Boolean circuit shown Fig. 1 running example illustrating
notions algorithms paper. subtractor, shown there, consists seven
components: inverter, two or-gates, two xor-gates, two and-gates. expression
h (o i) models normative (healthy) behavior inverter, variables i,
o, h represent input, output health respectively. Similarly, and-gate modeled
h [o (i1 i2 )] or-gate h [o (i1 i2 )]. Finally, xor-gate specified
h [o (i1 i2 )].
propositional formulae copied gate Fig. 1 variables
renamed way properly connect circuit disambiguate assumables,
thus obtaining propositional formula Boolean subtractor, given by:
SDw = {h1 [i (y p)]} {h2 [d (x i)]} [h3 (j p)]
[h4 (m l j)] [h5 (b k)] [h6 (x l)]
[h7 (k p)]

(1)

strong-fault model Boolean circuit shown Fig. 1 constructed assigning
fault-modes different gate types. assume that, malfunctioning,
output xor-gate value one inputs, or-gate stuck-at-one,
373

fiFeldman, Provan, & van Gemund

x

p

h1

h3



j

h2



h5

b

h6

l

h4

h7



k

Figure 1: subtractor circuit
and-gate stuck-at-zero, inverter behaves buffer. gives us
following strong-fault model formula Boolean subtractor circuit:
SDs = SDw [h1 (i y)] [h2 (d x)] (h3 j)
(h4 m) (h5 b) [h6 (x l)] (h7 k)

(2)

models (SDs SDw ), set assumable variables COMPS = {h1 , h2 , . . . , h7 }
set observable variables OBS = {x, y, p, d, b}.
2.2 Diagnosis Minimal Diagnosis
traditional query MBD computes terms assumable variables explanations system description observation.
Definition 4 (Health Assignment). Given diagnostic system DS = hSD, COMPS, OBSi,
assignment variables COMPS defined health assignment.
health assignment conjunction propositional literals. cases convenient use set negative positive literals . two sets denoted
Lit () Lit + (), respectively.
example, nominal assignment 1 = h1 h2 . . . h7 . health
assignment 2 = h1 h2 h3 h4 h5 h6 h7 means two and-gates Fig. 1
malfunctioning. follows formal definition consistency-based diagnosis.
Definition 5 (Diagnosis). Given diagnostic system DS = hSD, COMPS, OBSi, observation , instantiation variables OBS, health assignment ,
diagnosis iff SD 6|=.
Traditionally, authors (de Kleer & Williams, 1987) arrive minimal diagnosis computing minimal hitting set minimal conflicts (broadly, minimal health assignments
incompatible system description observation), paper makes
use conflicts, hence equivalent, direct definition above.
total 96 possible diagnoses given SDw observation 1 = x p
b d. Example diagnoses 3 = h1 h2 . . . h7 4 = h1 h2 h3 . . . h7 .
Trivially, given weak-fault model, faulty health assignment (in example
374

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

= h1 . . . h7 ) diagnosis instantiation observable variables OBS
(cf. Def. 2).
analysis algorithm need opposite notion diagnosis, i.e., health
assignments inconsistent model observation. MBD literature
assignments usually called conflicts. Conflicts, however, necessarily instantiate
variables COMPS. paper always use full health instantiations, use
term conflict avoided prevent confusion.
MBD literature, range types preferred diagnosis proposed.
turns MBD problem optimization problem. following definition
consider common subset-ordering.
Definition 6 (Minimal Diagnosis). diagnosis defined minimal, diagnosis
exists Lit ( ) Lit ( ).
Consider weak-fault model SDw circuit shown Fig. 1 observation
2 = x p b d. example, two minimal diagnoses 5 =
h1 h2 h3 h4 h5 h6 h7 6 = h1 h2 . . . h5 h6 h7 . diagnosis
7 = h1 h2 h3 h4 h5 h6 h7 non-minimal negative literals 5 form
subset negative literals 7 .
Note set minimal diagnoses characterizes diagnoses weak-fault
model, hold general strong-fault models (de Kleer et al., 1992).
latter case, faulty components may exonerate other, resulting health
assignment containing proper superset negative literals another diagnosis
diagnosis. example, given SDs 3 = x p b d, follows
8 = h1 h2 h3 h4 . . . h7 diagnosis, 9 = h1 h2 h3 h4 . . . h7
diagnosis, despite fact negative literals 9 form superset
negative literals 8 .
Definition 7 (Number Minimal Diagnoses). Let set (SD ) contain minimal diagnoses system description SD observation . number minimal
diagnoses, denoted | (SD )|, defined cardinality (SD ).
Continuing running example, | (SDw 2 )| = 8 | (SDs 3 )| = 2. number
non-minimal diagnoses SDw 2 61.
Definition 8 (Cardinality Diagnosis). cardinality diagnosis, denoted ||,
defined number negative literals .
Diagnosis cardinality gives us another partial ordering: diagnosis defined minimal
cardinality iff minimizes number negative literals.
Definition 9 (Minimal-Cardinality Diagnosis). diagnosis defined minimalcardinality diagnosis exists | | < | |.
cardinality minimal-cardinality diagnosis computed system description SD
observation denoted MinCard (SD ). example model SDw
observation 4 = x p b d, follows MinCard (SDw 4 ) = 2. Note
case minimal diagnoses minimal-cardinality diagnoses.
375

fiFeldman, Provan, & van Gemund

minimal cardinality diagnosis minimal diagnosis, opposite need hold.
general case, minimal diagnoses minimal-cardinality diagnoses. Consider example SDw 2 given earlier section, two resulting
minimal diagnoses 5 6 . two, 5 minimal-cardinality diagnosis.
Definition 10 (Number Minimal-Cardinality Diagnoses). Let set (SD ) contain minimal-cardinality diagnoses system description SD observation .
number minimal-cardinality diagnoses, denoted | (SD )|, defined
cardinality (SD ).
Computing number minimal-cardinality diagnoses running example results
| (SDw 2 )| = 2, | (SDs 3 )| = 2, | (SDw 4 )| = 4.
2.3 Converting Propositional Formulae Clausal Form
approach related satisfiability, Safari uses SAT solver. SAT solvers commonly accept input Conjunctive Normal Form (CNF), although exist SAT
solvers work directly propositional formulae (Thiffault, Bacchus, & Walsh, 2004).
Converting propositional formula CNF done (Tseitin, 1983) without
(Forbus & de Kleer, 1993) introduction intermediate variables. cases important structural information lost, may lead performance degradation
checking formula consistent computing solution.
Lemma 1. fault-model SD = F1 F2 . . . Fn (SD WFM SD SFM)
n = |COMPS| component variables converted CNF time O(|COMPS|)
time converting largest subformula (1 n) CNF.
Proof (Sketch). conversion SD CNF done (1) converting subformula
CNF (2) concatenating resulting CNFs final CNF equivalent SD.
complexity (1) O(n) complexity (2) is, worst-case, O(2m ) < ,
largest number variables subformula . result, total time
converting SD dominated linear |COMPS|.
Lemma 1 useful cases subformula small. case many
practical situations SD composed small component models. case
experimental benchmark (cf. Sec. 6) model combinational circuit
conjunction fault models simple logic gates (x-bit and-gates, typically x < 10,
xor-gates, etc.). Ideally, Safari would use non-CNF SAT solver, practical reasons
constrained reasoning diagnostic models concise CNF encodings.
Consider, example, formula (x1 y1 ) (x2 y2 ) (xn yn ),
Disjunctive Normal Form3 (DNF) and, converted CNF, 2n clauses. Although
similar examples propositional formulae exponentially many clauses CNF
representations easy find, artificial rarely encountered MBD.
Furthermore, Boolean circuits tested performance Safari
show exponential blow-up converted CNF.
3. Note DNF formulae propositional formulae.

376

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

2.4 Complexity Diagnostic Inference
section discusses complexity problems interested, namely
problem computing single set minimal diagnoses, using two minimality
criteria, subset-minimality () cardinality-minimality (). assume input CNF
formula defined variable set V , = |COMPS| assumable (or fault)
variables. Table 1 introduces notation use define 4 types diagnosis.
Table 1: Summary definitions types diagnosis interest
Symbol

Diagnoses






1
1



Preference Criterion





(subset-minimality)
(cardinality-minimality)
(subset-minimality)
(cardinality-minimality)

complexity computing set diagnoses harder computing single
diagnosis, since number diagnoses is, worst case, exponential input size
(number components). problem bounded problem counting
number diagnoses. problem shown #co-NP -Complete (Hermann
& Pichler, 2007).
restrict clauses Horn definite Horn, reduce complexity
problems solving, expense decreased model expressiveness.
Horn-clause restriction, SD WFM, determining first minimal diagnosis exists
P . restriction, SD SFM, deciding first minimal diagnosis
exists NP-hard (Friedrich et al., 1990). cases (SD WFM, SFM) deciding
next diagnosis exists NP-hard.
diagnosis problems interest article intractable worst-case.
complexity closely-related problem, Propositional Abduction Problems (PAPs),
studied Eiter Gottlob (1995). show propositional PAP,
problem determining solution exists P2 -complete. Computing minimal diagnosis
search problem, hence difficult pose decision question proving
complexity results. Consequently, one note computing diagnosis minimal
respect / requires O(log |COMPS|) calls NP oracle (Eiter & Gottlob,
1995), asking oracle step diagnosis containing k faulty components
exists.
Results abduction problems indicate task approximate diagnosis intractable. Roth (1996) addressed problems abductive inference, approximating inference. Roth focuses counting number satisfying assignments
range AI problems, including instances PAPs. addition, Roth shows
approximating number satisfying assignments problems intractable.
Abdelbar (2004) studied complexity approximating Horn abduction problems,
showing even particular Horn restriction propositional problem interest,
approximation problem intractable. particular, abduction problem
costs assigned assumables (which used model preference-ordering ),
377

fiFeldman, Provan, & van Gemund

examined complexity finding Least Cost Proof (LCP) evidence
(OBS), cost proof taken sum costs hypotheses
must assumed order complete proof. problem shown
NP -hard approximate LCP within fixed ratio r cost optimal solution,
r < 0.
Safari approximates intractable problems denoted Table 1. show
WFM, Safari efficiently compute single diagnosis minimal using
satisfiability oracle. SD SFM, Safari generates sound possibly sub-optimal
diagnosis (or set diagnoses). referred papers indicating intractable
approximate, within fixed ratio, minimal diagnosis. following, adopt
stochastic approach cannot provide fixed-ratio guarantees. However, Safari trades
optimality efficiency compute diagnoses high likelihood.

3. Stochastic MBD Algorithm
section discuss algorithm computing multiple-fault diagnoses using stochastic search.
3.1 Simple Example (Continued)
Consider Boolean subtractor shown Fig. 1, weak-fault model SDw given (1),
observation 4 preceding section. four minimal diagnoses associated
SDw 4 are: 1 = h1 h2 h3 h4 h5 h6 h7 , 2 = h1 h2 h3 h4 h5 h6 h7 ,
3 = h1 h2 . . . h6 h7 , 4 = h1 h2 h3 . . . h6 h7 .
nave deterministic algorithm would check consistency 2|COMPS| possible health assignments diagnostic problem, 128 case running example.
Furthermore, deterministic algorithms first enumerate health assignments small
cardinality high priori probability, renders algorithms impractical
situations minimal diagnosis higher cardinality. performance
surprising even using state-of-the art MBD algorithms utilize, example conflict learning, partial compilation, considering bad worst-case complexity finding
minimal diagnoses (cf. Sec. 2.4).
follows, show two-step diagnostic process requires fewer consistency checks. first step involves finding random non-minimal diagnosis starting
point (cf. Sec. 3.2 details computing random SAT solutions equal likelihood).
second step attempts minimize fault cardinality diagnosis repeated
modification diagnosis.
first step find one random, possibly non-minimal diagnosis SDw 4 .
diagnosis obtain classical DPLL solver modifying two ways: (1)
determine instance satisfiable extract satisfying solution
(2) find random satisfiable solution every time solver invoked. modifications
trivial, DPLL solvers typically store current variable assignments easy
choose variable value randomly (according uniform distribution) instead
deterministically branching. latter modification may possibly harm DPLL
variable value selection heuristics, later paper see
378

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

concern type problems considering diagnostic systems typically
underconstrained.
subtractor example call DPLL solver SDw 4 input
consider random solution (and obviously diagnosis) 5 = h1 h2 h3 h4 h5
h6 h7 (|5 | = 4). second step stochastic algorithm, try minimize
5 repetitively choosing random negative literal, flipping value positive (thus
obtaining candidate smaller number faults), calling DPLL solver.
new candidate diagnosis, try improve newly discovered diagnosis,
otherwise mark attempt failure choose another negative literal.
constant number failures (two example), terminate search
store best diagnosis discovered far process.
changing sign h7 5 discover new health assignment
consistent SDw 4 , hence diagnosis discard it. Instead,
algorithm attempts changing h6 h6 5 , time successfully obtaining new
diagnosis 6 = h1 h2 h3 h4 h5 h6 h7 cardinality 3. Next algorithm
tries find diagnosis even smaller cardinality randomly choosing h1 h7
6 , respectively, trying change sign, attempts return inconsistency.
Hence climb aborted 6 stored current best diagnosis.
Repeating process another random initial DPLL solution, gives us new diagnosis 7 = h1 h2 h3 h4 h5 h6 h7 . Changing sign h7 , again, leads
inconsistency, next two flips (of h4 h2 ) lead double-fault diagnosis
8 = h1 h2 . . . h6 h7 . diagnosis 8 improved
minimal. Hence next two attempts improve 8 fail 8 stored result.
process illustrated Fig. 2, search 6 left 8 right.
Gates shown solid black suspected faulty health assignment
participate tested consistency, inconsistent candidates crossed-out.
Let us consider result. found two diagnoses: 6 8 , 6
minimal diagnosis. done price 11 calls DPLL subroutine.
suboptimal diagnosis 6 value cardinality near one minimal
diagnosis. Hence demonstrated way find approximation minimal
diagnoses, drastically reducing number consistency checks comparison
deterministic algorithm, sacrificing optimality. Next formalize experience
algorithm, behavior analyze extensively section follows.
Diagnosing strong-fault model known strictly difficult weak-fault
model (Friedrich et al., 1990). many diagnostic instances problem alleviated
fact exist, although without guarantee, continuities diagnostic search
space similar one weak-fault models. Let us discuss process finding
minimal diagnosis subtractors strong-fault model SDs observation 2 (both
Sec. 2.1).
six distinct diagnoses 9 , . . . , 14 SDs 2 shown Fig. 3.
9 10 minimal |9 | = |10 | = 3. visible Fig. 3 diagnoses
component variables h2 h5 false, h1 h7 true (healthy). Hence,
satisfying assignment SDs 2 would contain h1 h2 h5 h7 . Starting
maximal-cardinality diagnosis 14 , must flip variables h3 , h4 , h6 order
reach two minimal diagnoses. key insight that, shown Fig. 3, always
379

fiFeldman, Provan, & van Gemund

Figure 2: example stochastic diagnostic process
h2
9
13
14
h2
9
11
14

h5

h4

h6

h3

h1

h7

























h5

h4

h6

h3

h1

h7

























h2
10
12
14
h2
10
13
14

h5

h4

h6

h3

h1

h7

























h5

h4

h6

h3

h1

h7

























Figure 3: Diagnoses strong-fault model
possible flipping single literal time health faulty receiving another
consistent assignment (diagnosis).
follows formalize experience far stochastic algorithm
finding minimal diagnoses.
3.2 Greedy Stochastic Algorithm
Algorithm 1 shows pseudocode Safari.
380

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Algorithm 1 Safari: greedy stochastic hill climbing algorithm approximating
set minimal diagnoses
1: function Safari(DS, , M, N ) returns trie
inputs: DS = hSD, COMPS, OBSi, diagnostic system
, term, observation
, integer, climb restart limit
N , integer, number tries
local variables: SDcnf , CNF
m, n, integers
, , terms
R, set terms, result
2:
SDcnf WffToCNF(SD)
3:
n = 1, 2, . . . , N
4:
RandomDiagnosis(SDcnf , )
Get random SAT solution.
5:
m0
6:
<
7:
ImproveDiagnosis()
Flip unflipped health variable.

8:
SDcnf 6|=
Consistency check.
9:

10:
m0
11:
else
12:
mm+1
13:
end
14:
end
15:
unless IsSubsumed(R, )
16:
AddToTrie(R, )
17:
RemoveSubsumed(R, )
18:
end unless
19:
end
20:
return R
21: end function

Safari accepts two input parameters: N . N independent searches
start randomly generated starting points. algorithm tries improve
cardinality initial diagnoses (while preserving consistency) randomly flipping fault literals. change sign literal done one direction only: faulty
healthy. attempt find minimal diagnosis terminates unsuccessful attempts improve current diagnosis stored . Thus, increasing lead
better exploration search space and, possibly, diagnoses lower cardinality,
decreasing improve overall speed algorithm.
Safari uses number utility functions. WffToCNF converts propositional
formula SD CNF (cf. Sec 2.3). ImproveDiagnosis subroutine takes term
argument changes sign random negative literal . negative
literals, function returns original argument.
381

fiFeldman, Provan, & van Gemund

implementation RandomDiagnosis uses modified DPLL solver returning
random SAT solution SD . Consider original DPLL algorithm (Davis, Logemann,
& Loveland, 1962) without unit resolution rule. One show if, event
branching, algorithm chooses unassigned variables polarity equal
probability, DPLL algorithm equally likely compute satisfiable solution (if
exists). Note order variables assigned matter. course,
DPLL algorithm may end-up partial assignment, i.e., variables
dont care. problem partial assignment extended
full satisfiable assignment randomly choosing signs unassigned variables
uniform distribution. Taking consideration unit resolution rule,
change likelihood modified DPLL solver finding particular solution
changes order variables assigned. formal proof modified
DPLL solver computes SAT assignment equal probability beyond scope
paper, idea build probabilistic model progress DPLL solver.
probabilistic model balanced tree nodes iterate branching performing
unit resolution (assigning values zero unit clauses). branching probability
set equal leaf nodes (SAT solutions) equal depth, one show
equal likelihood arriving SAT solution. up-to-date SAT solvers based
DPLL, creating randomized DPLL solver computes satisfiable solution
equal probability difficult. course, random polarity decisions may effect negatively
branching heuristics (Marques-Silva, 1999) analysis beyond scope
paper.
Similar deterministic methods MBD, Safari uses SAT-based procedure
checking consistency SD. increase implementation efficiency Safari,
combine BCP-based LTMS engine (McAllester, 1990) full-fledged DPLL solver
two-stage consistency checking. Experimentation shows combining LTMS DPLL
way allows order-of-magnitude Safari speed-up compared pure DPLL,
soundness completeness properties consistency checking preserved.
implemented two-stage consistency checking follows. First, Safari calls
BCP-based LTMS (Forbus & de Kleer, 1993) check SD |=. result
UNSAT candidate diagnosis.4 LTMS result UNSAT,
means consistency candidate unknown call complete DPLL
engine needed. full DPLL checking use POSIT (Freeman, 1995) MiniSat
(Een & Sorensson, 2003).
Safari benefits two-stage SAT procedure typical MBD instance
involves many consistency checks (O(|COMPS|2 ) N = 1, = |COMPS|). SD
change search time small number assumption clauses
updated, incremental nature LTMS greatly improves search efficiency.
Even though DPLL running time per instance LTMS (DPLL performs
BCP unit propagation), DPLL construction expensive avoided
possible. DPLL initialization typically slow involves building data structures
clauses variables, counting literals, initializing conflict databases, etc.
hand, implementation LTMS incremental (does reinitialized
4. shown BCP consistency check SD returns UNSAT, formula
UNSAT (the opposite necessarily true).

382

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

consistency check) efficient maintains counters clause.
counter keeps number unassigned literals. Assigning value variable
requires decrementing clause counters. counter becomes zero,
contradiction handler signaled.
guarantee two diagnostic searches, starting random diagnoses,
would lead minimal diagnosis. prevent this, store generated
diagnoses trie R (Forbus & de Kleer, 1993), straightforward extract
resulting diagnoses recursively visiting nodes. diagnosis added trie R
function AddToTrie, iff subsuming diagnosis contained R (the IsSubsumed
subroutine checks condition). adding diagnosis resulting trie R,
diagnoses contained R subsumed removed call RemoveSubsumed.
3.3 Basic Properties Greedy Stochastic Search
continue topics completeness optimality, show Safari
sound, i.e., returns diagnoses only.
Lemma 2 (Soundness). Safari sound.
Proof (Sketch). consistency check line 8 Alg. 1 guarantees terms
holds SD 6|= added result set R. According Def. 5
terms diagnoses.
One key factors success proposed algorithm exploitation
continuity search-space diagnosis models, continuity mean
monotonically reduce cardinality non-minimal diagnosis. exploitation continuity property, Safari configured guarantee finding minimal
diagnosis weak fault models polynomial number calls satisfiability oracle.
hypothesis comes next well studied prior work (de Kleer et al., 1992),
determines conditions minimal diagnoses represent diagnoses
model observation. paper interested hypothesis computational
viewpoint: defines class models possible establish theoretical bound
optimality performance Safari.
Hypothesis 1 (Minimal Diagnosis Hypothesis). Let DS = hSD, COMPS, OBSi diagnostic system diagnosis arbitrary observation . Minimal Diagnosis Hypothesis (MDH) holds DS iff health assignment Lit () Lit ( ),
diagnosis.
easy show MDH holds weak-fault models. theories
SD 6 WFM MDH holds (e.g., one directly construct theory conjunction
terms MDH holds). Unfortunately, necessary condition known MDH
hold arbitrary SD. lemma comes next direct consequence MDH
weak-fault models.
Lemma 3. Given diagnostic system DS = hSD, COMPS, OBSi, SD WFM,
diagnosis observation , follows non-minimal iff another diagnosis
obtained changing sign exactly one negative literal .
383

fiFeldman, Provan, & van Gemund

Proof (Sketch). Def. 2 SD WFM, follows minimal diagnosis,
diagnosis obtained flipping one positive literal diagnosis. Applying
argument direction gives us statement.
Safari operates performing subset flips non-minimal diagnoses, attempting compute minimal diagnoses. next formalize notion flips, order characterize
Safari able compute minimal diagnosis.
Definition 11 (Subset Flip ). Given diagnostic system DS = hSD, COMPS, OBSi
health assignment non-empty set negative literals (Lit () 6= ), subset
flip turns one negative literals positive literal, i.e., creates health
assignment one positive literal.
next characterize flips based whether produce consistent models flip.
Definition 12 (Valid Subset Flip). Given diagnostic system DS = hSD, COMPS, OBSi,
observation , non-minimal diagnosis , valid flip exists perform
subset flip create SD 6|=.
Given notions, define continuity diagnosis search space terms literal
flipping.
Definition 13 (Continuity). system model SD observation satisfy continuity
property respect set diagnoses (SD), iff diagnosis k (SD)
exists sequence = h1 , 2 , , k1 , k , k+1 , , n i, =
1, 2, , n 1, possible go i+1 via valid subset flip, (SD ),
n (SD ).
definition allows trivial continuity cases model observation lead minimal diagnoses (no non-minimal diagnoses). see Sec. 6,
models observations diagnoses minimal rare practice (of course,
problems created artificially). Note Safari algorithm still works
theoretical properties preserved even case trivial continuity.
Given Def. 13, easily show following two lemmata:
Lemma 4. SD satisfies MDH, satisfies continuity property.
Proof. Follows directly Hypothesis 1 Def 13.
Lemma 5. SD WFM satisfies continuity property.
Proof (Sketch). straightforward show SD WFM SD satisfies MDH.
Lemma 4 follows SD satisfies continuous property.
greedy algorithm starts initial diagnosis randomly flips faulty assumable variables. use MDH property show that, starting non-minimal
diagnosis , greedy stochastic diagnosis algorithm monotonically reduce size
seed diagnosis obtain minimal diagnosis appropriately flipping fault
variable faulty healthy; view flipping search, search continuous diagnosis space.
384

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Proposition 1. Given diagnostic system DS = hSD, COMPS, OBSi, observation ,
SD WFM, Safari configured = |COMPS| N = 1 returns one minimal
diagnosis.
Proof. diagnosis improvement loop starts, worst case, health assignment
conjunction negative literals only. Necessarily, case, diagnosis
SD WFM. diagnosis subsumed would found
consistency checks (provided exists) set equal number literals
repetitions randomly choosing literal flip next. If,
trying negative literals , diagnosis, Lemma 3 follows
minimal diagnosis.
simple inductive argument, continue process obtain
minimal diagnosis.
Proposition 1 follows upper bound O(|COMPS|) consistency
checks finding single minimal diagnosis. practical cases, however,
interested finding approximation minimal-cardinality diagnoses. result
complexity optimally configured Safari algorithm becomes O(|COMPS|2 S),
number minimal-cardinality diagnoses given observation. Section 5
discusses detail computation multiple minimal-cardinality diagnoses.
number assumable variables system practical significance may exceed
thousands, rendering optimally configured Safari computationally expensive.
Sec 4 see computationally efficient configure < |COMPS|,
still possible find minimal diagnosis high probability.
simple show flip-based search algorithms complete continuous diagnosis search spaces given weak fault models, i.e., SD WFM, models follow
MDH, i.e., Lemma 3. formally characterize guarantee finding minimal diagnosis Safari terms continuous diagnosis space. Note sufficient,
necessary, condition; example, may configure Safari flip multiple literals
time circumvent problems getting trapped discontinuous diagnosis spaces.
Theorem 1. Given diagnostic system DS = hSD, COMPS, OBSi, starting diagnosis
, Safari configured = |COMPS| N = 1 guaranteed compute minimal
diagnosis diagnosis space continuous.
Proof. Given initial diagnosis , Safari attempts compute minimal diagnosis
performing subset flips. diagnosis space continuous, know exists
sequence valid flips leading minimal diagnosis. Hence Safari guaranteed find
minimal diagnosis .
Finally, show Safari provides strong probabilistic guarantee computing
minimal diagnoses.
Theorem 2. probability Safari, configured = |COMPS|, computing
minimal diagnoses diagnostic system DS = hSD, COMPS, OBSi observation
denoted Pr . Given continuous diagnosis space (SD, ), holds Pr 1
N .
385

fiFeldman, Provan, & van Gemund

Proof (Sketch). Since (1) search space continuous, (2) step non-zero
probability flipping unflipped literal, (3) polynomial upper bound
steps (|COMPS|) computing diagnosis, Safari compute non-minimal diagnosis
non-zero probability. Hence N , Safari compute minimal diagnoses.

3.4 Complexity Inference Using Greedy Stochastic Search
next look complexity Safari, stochastic approach computing sound
incomplete diagnoses. show primary determinant inference complexity consistency checking. Safari randomly computes partial assignment ,
checks extended create satisfying assignment consistency
check, i.e., checks consistency SD. solving satisfiability problem (SAT), NP-complete (Cook, 1971). show use incomplete
satisfiability checking reduce complexity, cost completeness guarantees.
following, call complexity consistency check, assume
components fail, i.e., = |COMPS|.
Lemma 6. Given diagnostic system DS = hSD, COMPS, OBSi SD WFM,
worst-case complexity finding minimal diagnosis O( 2 ), cost
consistency check.
Proof. upper bound succeeding consistency checks finding single
minimal diagnosis since maximum steps computing healthy
diagnosis. Safari performs consistency check flip step
algorithm must flip literals, total complexity O( 2 ).
practical cases, however, interested finding approximation minimal-cardinality diagnoses.

result complexity optimally configured Safari


||
algorithm becomes , || cardinality minimal-cardinality
diagnoses given observation (cf. Sec. 6.6).
complexity BCP well-known, allowing us get precise bounds
worst-case complexity computing one minimal-diagnosis Safari. follows
assume SD represented CNF (cf. Sec. 2.3).
Lemma 7. Given diagnostic system DS = hSD, COMPS, OBSi, SD WFM, SD
c clauses n variables, worst-case complexity WFM finding
minimal diagnosis O( 2 cn) using BCP consistency checks.5
Proof (Sketch). implementation BCP (Forbus & de Kleer, 1993) maintains total
c counters number unsatisfied literals clause. consistency check requires
decrementing counters n variables SD. gives us upper
bound O(cn) execution time BCP. Combining complexity BCP
Lemma 6 gives us desired result.
5. efficient implementations BCP exist (Zhang & Stickel, 1996).

386

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

4. Optimality Analysis (Single Diagnosis)
contrast deterministic algorithms, Safari algorithm absolute guarantee optimum solution (minimal diagnosis) found. provide
intuition behind performance Safari algorithm means approximate,
analytical model estimates probability reaching diagnostic solution specific
minimality.
4.1 Optimality Safari Weak-Fault Models
start considering single run algorithm without retries
assume existence one minimal diagnosis. Next, extend model
considering retries.
4.1.1 Basic Model
Consider diagnostic system DS = hSD, COMPS, OBSi SD WFM,
observation manifests one minimal diagnosis . argument
follows configure Safari = 1, N = 1, assume starting
solution trivial faulty diagnosis.
Safari randomly chooses faulty variable flips it, saying
success new candidate diagnosis, failure otherwise. Let k denote
number steps algorithm successfully traverses direction minimal
diagnosis cardinality ||. Thus k measures number variables whose values
flipped faulty healthy process climbing.
Let f (k) denote probability distribution function (pdf) k. following
derive probability p(k) successfully making transition k k + 1. diagnosis
step k k positive literals |COMPS| k negative literals. probability
next variable flip successful equals probability next negative positive
flip H k negative literals conflict negative literal belonging
diagnosis solution . Consequently, || k literals COMPS| || k literals
allowed flip, therefore success probability equals:
p (k) =

||
|COMPS| || k
=1
|COMPS| k
|COMPS| k

(3)

search process modeled terms Markov chain depicted Fig. 4,
k equals state algorithm. Running inconsistency modeled
transitions state denoted fail.
probability exactly attaining step k (and subsequently failing) given by:
f (k) = (1 p(k + 1))

k


p(i)

(4)

i=0

Substituting (3) (4) gives us pdf k:

k

||
||
1
f (k) =
|COMPS| k + 1
|COMPS|
i=0

387

(5)

fiFeldman, Provan, & van Gemund

k=0

1 p(0)

p(0)

k=1

1 p(1)

p(1)

k=2

1 p(2)

p(i)

k=i

p(n 1)

1 p(i + 1)

k=n

1

fail

Figure 4: Model Safari run = 1 single diagnosis (n = |COMPS| ||)

optimum goal state k = |COMPS| || failure probability term (5) correct
equals unity.
p independent k, f would geometrically distributed, implies
chance reaching goal state k = |COMPS||| slim. However, fact p decreases
k moves probability mass tail distribution, works favor
reaching higher-k solutions. instance, single-fault solutions (|| = 1) distribution
becomes uniform. Figure 5 shows pdf problem instances |COMPS| = 100
increasing fault cardinality ||. order decrease sampling noise, empirical f (k)
values Fig. 5 computed taking average 10 samples k.
0.1

0.1
|| = 1
|| = 5
|| = 10

0.08

|| = 1
|| = 5
|| = 10

0.08

f(k)

0.06

f(k)

0.06
0.04

0.04

0.02

0.02

0

0

20

40

60

80

100

k

0

0

20

40

60

80

100

k

Figure 5: Empirical (left) analytic (right) f (k) retries single diagnosis
next section show retries move probability mass towards
optimum, increasing tail distribution, needed (almost always) reaching
optimality.
4.1.2 Modeling Retries
section extend model account retries, profound effect
resulting pdf f . Again, consider transition step k k + 1,
algorithm spend = 1, . . . , retries exiting failure.
388

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

seen algorithm (cf. Alg. 1), variable flip produces inconsistency retry
executed incremented.
elementary combinatorics compute probability diagnosis
flipping different negative literals step k. Similar (3), stage k
|COMPS| k faulty literals chosen (as variable flips leading
inconsistency recorded attempted again, difference choosing
variables advance one another). probability advancing stage
k stage k + 1 becomes:
||
p (k) = 1


|COMPS|k


(6)

progress Safari modeled values > 1 Markov chain, similar
one shown Fig. 4 transition probability p replaced p . resulting
pdf number successful steps becomes:
#
"
k
||
||




(7)
1 |COMPS|i
f (k) = |COMPS|k+1


i=0



seen (5) restricted case (7) = 1.
retry effect shape pdf profound. Whereas single-fault solutions
shape = 0 uniform, = 1 probability mass already located
optimum k = |COMPS| ||. Fig. 6 plots f number problem instances
increasing . expected, effect extremely significant. Note case
real system, = |COMPS| pdf would consist single, unit probability spike
|COMPS| ||.
Although unable find analytic treatment transition model above,
graphs immediately show large probability moving k = |COMPS| ||
large. Hence, expect pdf considerable probability mass located
k = |COMPS| ||, depending relative |COMPS|.
4.2 Optimality Safari Strong-Fault Models
analysis seen WFM easy, starting non-minimal
diagnosis, reach subset minimal diagnosis. discussed detail below,
necessarily case strong-fault models. many practical cases, however,
strong-fault models exhibit, least partially, behavior similar MDH, thus allowing greedy
algorithms Safari achieve results close optimal values.
4.2.1 Partial Continuity Strong-Fault Stuck-At Models
follows restrict attention large subclass SFM, called SFSM
(Struss & Dressler, 1992).
Definition 14 (Strong-Fault Stuck-At Model). system DS = hSD, COMPS, OBSi belongs class SFSM iff SD equivalent (h1 F1 ) (h1 l1 ) (hn
Fn ) (hn ln ) 1 i, j n, {hi } COMPS, Fj propositional formula,
none hi appears Fj , lj positive negative literal Fj .
389

fiFeldman, Provan, & van Gemund

M=2

M=2

0.04

0.04
|| = 5
|| = 10

0.03
f(k)

f(k)

0.03

0.02

0.01

0

|| = 5
|| = 10

0.02

0.01

0

20

40

60

80

0

100

0

20

40

k
M=4

100

60

80

100

0.12
|| = 5
|| = 10

0.1

|| = 5
|| = 10

0.1
0.08
f(k)

0.08
f(k)

80

M=4

0.12

0.06

0.06

0.04

0.04

0.02

0.02

0

60
k

0

20

40

60

80

100

k

0

0

20

40
k

Figure 6: Empirical (left) analytic (right) f (k) multiple retries single diagnosis

MDH (cf. Hypothesis 1) hold SFSM models. Consider adder whose inputs
outputs zeroes, whose gate models stuck-at-1 faulty.
case, nominal assignment diagnosis, but, example, stuck-at-1 output gate
diagnosis (there contradiction zero output).
Many practical observations involving SFSM models, however, lead partial continuity. means groups diagnoses differ one literal, i.e.,
flip based search improve cardinality diagnosis. next formalize notion.
Definition 15 (Partial Continuity). system model SD observation satisfy
partial continuity property respect set (SD ), iff every diagnosis
satisfying Lit () \ Lit (i ) exists finite sequence valid subset
flips .
one extreme spectrum, SD satisfy partial continuity property
respect set diagnoses extreme, partial continuity
390

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

property satisfied respect singleton (consider, example, SD WFM
consists single faulty diagnosis).
Note continuous property trivally satisfied respect diagnosis
k (SD ), i.e., always exists sequence containing k ( = hk i).
interested non-trivial cases, || > 1.
Consider system SD observation satisfy partial continuity property
respect diagnosis k . say diagnoses flip sequence
contains k form continuous subspace. Alternatively, given diagnostic system SD
observation , continuous diagnostic subspace SD set diagnoses (SD)
property that, diagnosis , another diagnosis
|Lit ()| |Lit ()| = 1.
Unfortunately, general SFSM case, cannot derive bounds sizes
continuous subspaces, hence, optimality Safari. follows,
help examples, illustrate fact partial continuity depends
model observation express optimality Safari function
topologically-dependent property. Later, Sec. 6, collect empirical data continuous
subspaces leading near-optimal diagnoses exist class benchmark SFSM circuits.
first example illustrates notion discontinuity (lack partial continuity
respect diagnoses). show rare example model observation
leading set diagnoses contains diagnoses cardinality + q (q > 1),
diagnoses cardinality + 1, + 2, , + q 1.
Discontinuity Example Consider, example, Boolean circuit shown Fig. 7
modeled propositional formula:

[h1 (y x)] [h1 (y x)]
(8)
SDd =
[h2 (y x)] [h2 (y x)]
observation = x y. Note, SDd 6 SFSM. exactly two diagnoses
SDd : 15 = h1 h2 16 = h1 h2 . Note model cannot single
faults. 15 minimal, |15 | = 0, |16 | = 2, algorithm starts 16
possible reach minimal diagnosis 15 performing single flips. Similarly
construct models impose arbitrarily bad bound optimality Safari.
models, however, common see greedy algorithm performs
well wide class strong-fault models.
h1
x


h2

Figure 7: two inverters circuit
Obviously, continuity distribution cardinalities set diagnoses necessary (but sufficient) condition Safari progress. models impose arbitrary
difficulty Safari, leading suboptimal diagnoses cardinality.
391

fiFeldman, Provan, & van Gemund

Example Partial Continuity continue running example started Sec. 2.
First, create system description SDsa SFSM model. Let SDsa = SDw SDf ,
SDw given (1). second part SDsa , strong fault description SDf ,
specifies output faulty gate must stuck-at-1:
SDf = (h1 i) (h2 d) (h3 j) (h4 m)
(h5 b) (h6 l) (h7 k)

(9)

clear SDsa SFSM. next compute diagnoses SDsa 1 (1 = x
p b d). one minimal diagnosis SDsa 1 5 = h1 h2 h3 h7
(cf. Fig. 8). choose two literals h3 h4 5 change signs h3
h4 , create two new health assignments: 15 = h1 h2 h3 h4 h5 h6 h7
16 = h1 h2 h3 h4 h5 h6 h7 . checked 15 16
diagnoses, i.e., SDsa 1 15 6|= SDsa 1 16 6|=. Note 15 16
diagnoses weak-part model, i.e., {15 , 16 } (SDw 1 ). follows
MDH fact 5 minimal diagnosis SDw 1 . Furthermore, 15
diagnosis strong-fault stuck-at model (15 (SDsa 1 )) SDw 1 h3
lead contradictory value j strong-fault part SDf . similar argument
applies 16 : SDw 1 h4 contradict SDf . Equivalently, negating h3
5 , makes j stuck-at-1, results diagnosis, negating h4 5 , makes
stuck-at-1, results diagnosis, negating h3 h4 5 result
diagnosis (consider fact fault mode h4 sets only, impose
constraints j). argument extended similarly h5 , h6 , h7 . Hence,
assignment COMPS containing h1 h2 diagnosis SDsa 1 , matter
combination signs take h3 , h4 , h5 , h6 , h7 . Note health assignment
containing h4 diagnosis conditioned k = 1.
x=1
y=1
p=1

h2

d=0

h6

h1
i=1

l=0
h4

h3

m=0

j=1

h5

b=1

h7
k=1

Figure 8: Continuous subspace strong-fault, stuck-at-1 model subtractor
Consider alternative way computing set ambiguous diagnoses SDsa 1 . Given
SDsa 1 5 , compute consistent assignment internal variables (for example
propagation). exactly one assignment = j k l m,
SDsa 1 5 6|= (cf. Fig. 8). Note components h1 , h3 , h5 , h7 ,
change state component (healthy faulty) lead different output
value. example output j h3 or-gate 1 gate healthy
392

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

inputs 1 j would 1 stuck-at-1 or-gate (h3 ). result, diagnostic
reasoner determine components dashed region Fig. 8 healthy faulty
(stuck-at-1). Equivalently, one change signs h3 , h5 , h7 diagnosis 5
resulting assignments still diagnoses. call set components modeled
h1 , h3 , h5 , h7 ambiguity group. Clearly, Safari start diagnosis
17 = h1 h2 h3 h4 h5 h6 h7 (|17 | = 4) reach 5 (|5 | = 1)
performing valid subset flips.
make reasoning precise, restrict class SFSM models exclude malformed circuits ones disconnected inputs outputs, etc. Furthermore,
assume component exactly one output (the set component output variables denoted COUT). latter big restriction multi-output component
models replaced multiple components, single output.6
Definition 16 (Well-Formed Diagnostic System (Wfds)). diagnostic system DS =
hSD, COMPS, OBSi well-formed (DS Wfds) iff observation
diagnosis (SD ), exactly one assignment component outputs
COUT SD 6|=.
Consider SFSM model SD = (h1 F1 ) (h1 l1 ) (hn Fn ) (hn ln ).
denote COMPS set hi (1 n) respective li literals
negative (cf. Def. 14), i.e., COMPS set components whose failure modes stuckat-0. Similarly, use COMPS+ set component variables whose stuck-at li literals
positive (COMPS COMPS+ = COMPS, COMPS COMPS+ = ). Wfds,
observation diagnosis force output component either negative
positive value. denote set health variables whose respective component
outputs forced negative values G (DS, , ). Similarly, G+ (DS, , )
components whose outputs positive values. define notion
component ambiguity group.
Definition 17 (Component Ambiguity Group). Given system DS = hSD, COMPS, OBSi,
SD SFSM, SD Wfds, observation , diagnosis (SD), component
ambiguity group U(DS, , ), U COMPS, defined U(DS, , ) = {G (DS, , )
COMPS } {G+ (DS, , ) COMPS+ }.
Finally, show component ambiguity group leads continuous subspace.
general case cannot say much size component ambiguity groups.
experimentation, noticed difficult assign inputs SFSM
values generate small continuous subspaces (either SD |=, SD leads
large component ambiguity groups). course, possible consider adder,
multiplier, example, whose inputs zeroes whose gate models stuck-at-1
faulty, number inputs/circuit combinations small.
Proposition 2. diagnostic system SD, SD SFSM, SD Wfds, observation
entail continuous diagnostic subspaces.
6. multi-output Boolean function replaced composition single-output Boolean functions.

393

fiFeldman, Provan, & van Gemund

Proof. Def. 16 fact SD Wfds follows output values
subset components sign models stuck-at value. denote
set COMPS , COMPS COMPS. health assignment differs signs
components belonging COMPS diagnosis. set diagnoses SD
contains possible assignments assumables COMPS diagnoses form
continuous space (cf. Def. 17).
best illustrate Proposition 2, consider or-gate modeled h3 Fig. 8. output
1 either gate healthy one gates inputs 1, gate
stuck-at-1. situation, possible determine component healthy
faulty.
Clearly, |U(DS, , )| lower bound progress Safari stuck-at models.
shown Safari starts diagnosis maximum cardinality
given subspace, Safari guaranteed (for = |COMPS|) improve cardinality
least |U(DS, , )|. practice, Safari proceed even stuckat ambiguity groups one factor diagnostic uncertainty. stuck-at component
effectively disconnects inputs outputs, hence gates fan-in region
constrained. instance, continuing example, h5 , predecessors cone
h5 (components h3 , h4 , h5 , h6 , h7 ) constitute continuous health subspace.
Contrary component ambiguity group, set conditional health state
another component. thorough study stuck-at continuity outside scope
paper shall see Sec. 6, continuous subspaces justify Safari experiments
stuck-at models.
4.2.2 Performance Modeling Stuck-At Models
study optimality Safari strong-fault models, first define case
algorithm cannot improve non-minimal diagnosis changing sign
faulty literal. Note existence cases sufficient condition Safari
suboptimal, possible reach minimal diagnosis first changing sign
faulty literal, thus circumventing missing diagnosis.
preceding section know number invalid flips depend
k, i.e., determined observation vector fault modes. probability
Safari progress non-minimal diagnosis becomes
p(k) = 1

||+|X|

|COMPS|k


(10)

|X| number invalid flips. ratio number invalid flips |X|
|COMPS| call SFM density d. density gives average probability trying
invalid flip throughout diagnostic search. approximation probability
success Safari is:
p(k) = 1

||

|COMPS|k


394



(11)

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Plugging p (4) allows us predict f (k) SFM models assumptions
hold. pdf, measured implementation Safari generated (4)
(11) shown Fig. 9 different values density d.
= 4, |COMPS| = 100, || = 10

= 4, |COMPS| = 100, || = 10

0.12

0.12
d=0
= 0.1
= 0.25
= 0.5

0.1

0.08
f(k)

f(k)

0.08
0.06

0.06

0.04

0.04

0.02

0.02

0

0

20

40

60

d=0
= 0.1
= 0.25
= 0.5

0.1

80

100

k

0

0

20

40

60

80

100

k

Figure 9: Empirical (left) analytic (right) f (k) various diagnostic densities, multiple
retries single diagnosis

Fig. 9 visible increasing density leads shift probability
density length walk k left. effect, however, profound
even large values d, easily compensated increasing , discussed
preceding sections.
interesting note bounds computed SD (independent ),
bounds used improve performance Safari.
4.3 Validation
preceding sections illustrated progress Safari synthetic circuits
exposing specific behavior (diagnoses). remainder section plot pdf
greedy search one small benchmark circuits (for information
74181 model cf. Sec. 6).
progress Safari weak-fault model 74181 circuit shown Fig. 10.
chosen difficult observation leading minimal diagnosis cardinality 7 (left)
easy observation leading single fault diagnosis (right). plots show
probability mass shifts right increasing effect profound
smaller cardinality.
effect stuck-at-0 stuck-at-1 fault modes (SFM) probability
success Safari shown Fig. 11.
Obviously, case effect increasing smaller, although still depending
difficulty observation vector. Last, even small values , absolute
probability Safari finding minimal diagnosis sizeable, allowing use Safari
395

fiFeldman, Provan, & van Gemund

74181, || = 7

74181, || = 1

0.5

0.5
M=1

M=1

M=2

0.4

M=2

0.4

M=3
0.3

M=3
0.3

0.2

0.2

0.1

0.1

0

0

10

20

M=4

f(k)

f(k)

M=4

30
k

40

50

0
30

60

40

50
k

60

70

Figure 10: Empirical f (k) weak-fault model 74181 circuit observations
leading two different minimal-cardinality diagnoses various

74181, || = 6, S-A-0

74181, || = 6, S-A-1

0.2

0.2
M=1

0.15

M=4
0.1

0.05

0
20

M=2

0.15

M=3
f(k)

f(k)

M=1

M=2

M=3
M=4

0.1

0.05

30

40
k

50

60

0
10

20

30

40

50

60

k

Figure 11: Empirical f (k) stuck-at-0 stuck-at-1 strong-fault models 74181
circuit various

practical anytime algorithm always returns diagnosis, optimality
depends time allocated computation.

5. Optimality Analysis (Multiple Diagnoses)
preceding section described process computing one diagnosis Safari (N =
1). section discuss use Safari computing (or counting) minimalcardinality diagnoses (N > 1). rest section assume Safari
configured = |COMPS|.
396

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Consider system description SD (SD WFM) observation . number
minimal diagnoses | (SD )| exponential |COMPS|. Furthermore, practice, diagnosticians interested sampling set minimal-cardinality diagnoses
(SD ) (recall (SD ) (SD )) minimal-cardinality diagnoses
cover significant part posteriori diagnosis probability space (de Kleer, 1990).
follows, see Safari well suited task.
Theorem 3. probability Safari configured = |COMPS| computing minimal diagnosis cardinality || system |COMPS| component variables approaches
|COMPS||| |COMPS|/|| .
Proof (Sketch). Assume minimal diagnosis cardinality || exists. Proposition 1
follows Safari configured = |COMPS| guaranteed compute minimal
diagnoses. Starting faulty assignment, consider step k improving
diagnosis cardinality. state k contains one diagnosis, state k+1, Safari
either (1) flip literal belonging diagnosis (note literal may belong
one diagnosis) subsequently prevent Safari reaching diagnosis
(2) flip literal belonging diagnosis already invalidated (i.e., one
literals flipped earlier step).
probability solution cardinality || survives flip iteration k (i.e.,
invalidated) is:
p (k) = 1

|COMPS| || k
||
=
|COMPS| k
|COMPS| k

(12)

Similarly basic model (Sec. 4.1.1), probability diagnosis survives
returned algorithm:
|COMPS|||1



f (|COMPS| || 1) =

|COMPS|||1

p(i) =

i=0


i=0

|COMPS| ||
|COMPS|

(13)

Rewriting right hand side Eq. (13) gives us:
f (|COMPS| || 1) =

(|COMPS| ||)!
||!(|COMPS| ||)!
=
(|| + 1)(|| + 2) |COMPS|
|COMPS|!

(14)

Since
1
(|COMPS| ||)!
=
|COMPS|!
(|COMPS| || + 1)(|COMPS| || + 2) |COMPS|

(15)

holds
(|COMPS| ||)!
= |COMPS|||
|COMPS|!
|COMPS|/||
lim

(16)

result, small || relative |COMPS|,
f (|COMPS| || 1) = ||!|COMPS|||
gives us theorem.
397

(17)

fiFeldman, Provan, & van Gemund

distribution hi (||) cardinalities minimal diagnoses (SD ) depends
topology SD ; i.e., create SD hi (||). denote
cardinality distribution minimal diagnoses computed Safari h(||).
Theorem 3 gives us termination criterion Safari used enumerating
counting minimal-cardinality diagnoses. Instead running Safari
P fixed N ,
sufficient compute area output distribution function
h. value
P
converge single value, hence terminate Safari change
h
drops fixed threshold. Note Safari efficient enumerating minimalcardinality diagnoses, computed probability exponentially higher
probability computing minimal diagnoses higher-cardinality, shown
Theorem 3.
Corollary 1. Safari computes diagnoses equal cardinality equal probability.
Proof (Sketch). Theorem 3 follows probability success f Safari
computing diagnosis depends || actual composition .
corollary gives us simple termination criterion Safari cases
minimal diagnoses minimal-cardinality diagnoses; proven
case minimal-cardinality diagnoses computed probability.
see that, given input cardinality distribution hi (||), Safari produces
output distribution h(||) highly skewed right, due Theorem 3. facilitate
study Safari transforms hi (||) h(||) use Monte Carlo simulation
Safari. advantage Monte Carlo simulation much simpler analysing
run-time behavior Safari studying algorithm itself.
Algorithm 2 Monte Carlo simulation Safari
1: function SafariSimulate(, N ) returns cardinality distribution
inputs: , set minimal diagnoses
N , integer, number tries
local variables: hi , h, vectors, cardinality distributions
b, vector, fault distribution, n, i, c, integers
2:
hi CardinalityDistribution( )
3:
n 1, 2, . . . , N
4:
c 1, 2, . . . , |hi |
5:
b[c] c hi [c]
6:
end
7:
1, 2, . . . , | |

8:
c DiscreteInverseRandomValue Pb b
9:
b[c] b[c] c
10:
end
11:
h[c] h[c] + 1
12:
end
13:
return h
14: end function
398

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Algorithm 2 simulates diagnoses input set minimal diagnoses
reached Safari N tries. auxiliary subroutine CardinalityDistribution
computes input distribution hi iterating diagnoses . store input
cardinality distribution hi resulting cardinality distribution h vectors (note
vector sums lines 7 8 division vector scalar line 8).
outermost loop Alg. 2 (lines 3 12) simulates N runs Safari. done
computing updating auxiliary vector b, contains distribution
component variables according cardinalities diagnoses variables
belong to. Initially, b initialized number literals single faults position 1,
number literals double faults position 2 (for example three double
faults hi , b[2] = 6), etc. done lines 4 6 Alg. 2. assume diagnoses
share literals. restriction easily dropped counting assumables
input (the latter assumption change results section).
Lines 7 10 simulate process actual bit flipping Safari. step
simulation draws random literal probability distribution function (pdf ) Pb b ;
done DiscreteInverseRandomValue function line 8. bit flip
invalidates diagnosis set , i.e., diagnosis cardinality c cannot reached
Safari. diagnosis invalidated, vector b updated, example,
simulation invalidates quadruple fault, b[4] = b[4] 4 (line 9). Note number
iterations loop lines 7 10 equals number diagnoses . result
terminating loop, value integer variable c equal cardinality
last invalidated diagnosis. latter diagnosis Safari computes
run. remains update resulting pdf right cardinality (line 11).
simulation Alg. 2 links distribution actual diagnoses
distribution cardinalities diagnoses returned Safari. arbitrarily set, apply Alg. 2 range typical input distributions. results
simulation well results running Safari synthetic problems
input distributions shown Fig. 12.
Fig. 12 shows (1) Alg. 2 predicts actual behavior Safari (compare second
third column plots), (2) Safari computes diagnoses small cardinality
agreement Theorem 3. case output distribution steep
exponential cardinalities set input minimal diagnoses grow exponentially. Table 2 summarizes parameters exponential fits input cardinality
distributions shown Fig. 12 (a initial (zero) cardinality, decay constant,
R2 coefficient determination). seen Safari suited computing
multiple diagnoses small probability occurrence. next section provide
alternative argument leading similar conclusions.

6. Experimental Results
section discusses empirical results measured implementation Safari. order compare optimality performance Safari various diagnostic algorithms,
performed million diagnosis computations 64 dual-CPU nodes belonging cluster. node contains two 2.4 GHz AMD Opteron DP 250 processors
4 Gb RAM.
399

fiFeldman, Provan, & van Gemund

degenerate input

prediction (model)

0.5
0

1

h(||)

1

h(||)

h(||)

1

0.5
0

0

50
||

100

0

0.5
0

50
||

100

0
0

50
||

100

h(||)

h(||)

0.2
0.1

20

exponential input

10
||

0

h(||)

h(||)
20
||

40

0

prediction (model)
0.3

5

10

||

0.2
0.1
0

40

0.3

h(||)

h(||)

h(||)
0

20
||

SAFARI

0.4

0

0.5
0

0

reverse exponential input

0.2

20

1

0.5

40

10
||

SAFARI

0
20
||

0.1

prediction (model)

0
0

0.2

20

1

0.2

100

0
0

0.4

50
||

0.3

0
10
||

0

SAFARI

0.3

0.05

100

0.5

prediction (model)

0.1

50
||

SAFARI

h(||)

h(||)

h(||)

0.5

0

0

1

normal input

h(||)

100

1

0

h(||)

50
||

prediction (model)

1

0

0.5
0

uniform input

0

SAFARI

0.2
0.1

0

5
||

10

0

0

5
||

Figure 12: Predicted actual cardinality distributions
400

10

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Table 2: Fit coefficients exponential goodness fit cardinality distribution
Fig. 12




R2

576
423
69 470
385

0.44
0.34
4.26
0.33

1
0.99
1
0.95

Input Distribution
Uniform
Normal
Exponential
Reverse Exponential

default configuration Safari (when stated otherwise) = 8 N = 4;
is, Safari configured maximum number 8 retries giving
climb, total 4 attempts. provide precise average run-time optimality
performance data, stochastic algorithms (i.e., ones based SLS Max-SAT Safari)
repeatedly run 10 times model observation vector.
6.1 Implementation Notes Test Set Description
implemented Safari approximately 1 000 lines C code (excluding LTMS,
interface, DPLL code) part Lydia package.7
Traditionally, MBD algorithms tested diagnostic models digital circuits
ones included ISCAS85 benchmark suite (Brglez & Fujiwara, 1985).
models derived ISCAS85 large (from traditional diagnostic perspective),
considered four medium-sized circuits 74XXX family (Hansen, Yalcin,
& Hayes, 1999). order provide weak- strong-fault cases, translated
circuit weak, stuck-at-0 (S-A-0), stuck-at-1 (S-A-1) model. stuck-at
models, output faulty gate assumed constant (cf. Def. 14).
performance diagnostic algorithms depends various degrees observation
vectors (algorithm designers strive produce algorithms, performance
dependent observation vectors). Hence, performed experimentation
number different observations model. implemented algorithm
(Alg. 3) generates observations leading diagnoses different minimal-cardinality,
varying 1 nearly maximum respective circuits (for 74XXX models
maximum). experiments omit nominal scenarios trivial
viewpoint MBD.
Algorithm 3 uses number auxiliary functions. RandomInputs (line 3) assigns
uniformly distributed random values input (note generation
observation vectors partition observable variables OBS inputs outputs
use input/output information comes original 74XXX/ISCAS85
circuits simulation). Given healthy health assignment diagnostic system, ComputeNominalOutputs (line 4) performs simulation propagating input
assignment . result assignment contains values output variable
OUT.
7. Lydia, Safari, diagnostic benchmark downloaded http://fdir.org/lydia/.

401

fiFeldman, Provan, & van Gemund

Algorithm 3 Algorithm generation observation vectors
1: function MakeAlphas(DS, N, K) returns set observations
inputs: DS = hSD, COMPS, OBSi, diagnostic system
OBS = OUT, =
N , integer, number tries Safari
K, integer, maximal number diagnoses per cardinality
local variables: , , n , , terms
c, integer, best cardinality far
A, set terms (observation vectors), result
2:
k 1, 2, . . . , K
3:
RandomInputs(IN)
4:
ComputeNominalOutputs(DS, )
5:
c0
6:
v
7:
n Flip(, v)
8:
SmallestCardinalityDiagnosis(Safari(SD, n , |COMPS|, N ))
9:
|| > c
10:
c ||
11:
n
12:
end
13:
end
14:
end
15:
return
16: end function
loop lines 6 13 increases cardinality greedily flipping values
output variables. new candidate observation n , Alg. 3 uses diagnostic oracle
Safari compute minimal diagnosis cardinality c. Safari returns
one diagnosis (up N ), use SmallestCardinalityDiagnosis choose one
smallest cardinality. cardinality c diagnosis increases comparison
previous iteration, observation added list.
running Alg. 3 get K observations leading faults cardinality 1, 2, . . . , m,
cardinality MFMC diagnosis (Feldman, Provan, & van Gemund,
2008b) respective circuit. Alg. 3 clearly shows bootstrapping problem. order
create potentially difficult observations Safari, require Safari solve
difficult observations. Although seen Sec. 5 Safari heavily biased
towards generating diagnoses small cardinality, guarantee. alleviate
problem, generation observation vectors, configured Safari compute
subset-minimal diagnoses = |COMPS| N increased 20.
Table 3 provides overview fault diagnosis benchmark used experiments.
third fourth columns show number observable assumable variables,
characterize size circuits. next three columns show number observation
vectors tested weak, S-A-0, S-A-1 models. stuck-at
models, chosen weak-fault model observations consistent
402

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Table 3: overview 74XXX/ISCAS85 benchmark circuits
Name

Description

74182
74L85
74283
74181

4-bit
4-bit
4-bit
4-bit

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

27-channel interrupt controller
32-bit SEC circuit
8-bit ALU
32-bit SEC circuit
16-bit SEC/DEC
12-bit ALU
8-bit ALU
9-bit ALU
32-bit multiplier
32-bit adder

Variables
|OBS| |COMPS|

carry-lookahead generator
magnitude comparator
adder
ALU

Observations
Weak S-A-0 S-A-1

14
14
14
22

19
33
36
65

250
150
202
350

150
58
202
143

82
89
202
213

43
73
86
73
58
373
72
301
64
315

160
202
383
546
880
1 193
1 669
2 307
2 416
3 512

301
835
1 182
836
846
1 162
756
2 038
404
1 557

301
235
217
836
846
134
625
158
274
255

301
835
335
836
846
123
743
228
366
233

respective system descriptions (as strong-fault models often case SD |=,
considered scenarios).
6.2 Comparison Complete Algorithms
Table 4 shows results comparing Safari implementations two state-of-the-art
complete deterministic diagnostic algorithms: modification completeness CDA
(Williams & Ragno, 2007) HA (Feldman & van Gemund, 2006). Table 4 shows,
model algorithm, percentage tests diagnosis could
computed within cut-off time 1 minute.
visible three rightmost columns Table 4, Safari could find diagnoses observation vectors, performance two deterministic algorithms
(columns two seven) degraded increase model size cardinality
observation vector. Furthermore, observed degradation performance
CDA HA increased cardinality minimal-cardinality diagnoses,
performance Safari remained unaffected.
6.3 Comparison Algorithms Based ALLSAT Model Counting
compared performance Safari pure SAT-based approach,
uses blocking clauses avoiding duplicate diagnoses (Jin, Han, & Somenzi, 2005).
Although SAT encodings worked efficiently variety domains,
planning, weak health modeling makes diagnostic problem underconstrained
uninformed ALLSAT strategy (i.e., search exploiting continuity imposed
weak-fault modeling) quite inefficient, even small models.
403

fiFeldman, Provan, & van Gemund

Table 4: Comparison CDA , HA , Safari [% tests solved]
Name

Weak

CDA
S-A-0

74182
74L85
74283
74181

100
100
100
79.1

100
100
100
98.6

100
100
100
97.7

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

74.1
29
11.6
3.8
0
0
0
0
0
0

75.4
45.5
44.7
4.7
0
0
0
0
0
0

73.1
27.7
32.2
5.4
0
0
0
0
0
0

S-A-1

Weak

HA
S-A-0

S-A-1

Weak

100
100
100
100

100
100
100
100

100
100
100
100

100
100
100
100

100
100
100
100

100
100
100
100

100
100
100
100
100
100
100
100
100
100

100
100
100
100
100
100
100
100
100
100

100
100
100
100
100
100
100
100
100
100

71.1
24.1
12.4
10.8
6.1
5
1.1
1.1
3.5
3.9

94.7
77.9
62.2
10.6
6
64.2
3.8
8.2
5.1
7.8

69.1
25.9
41.5
12.2
6.5
44.7
2.2
5.7
3.3
12

Safari
S-A-0 S-A-1

substantiate claim, experimented state-of-the-art satisfiability
solver RelSat, version 2.02 (Bayardo & Pehoushek, 2000). Instead enumerating
solutions filtering minimal diagnoses only, performed model-counting, whose
relation MBD extensively studied (Kumar, 2002). possible solve
two smallest circuits, solver terminate larger models within
predetermined time 1 hour. results shown Table 5.
second column Table 5 shows model count returned RelSat, sample single-fault observations benchmark. third column reports time
model counting. slow performance relatively small diagnostic instances leads us
conclusion specialized solvers Safari better suited finding minimal
diagnoses off-the-shelf ALLSAT (model counting) implementations encode
inference properties similar encoded Safari.
used state-of-the-art, non-exact model counting method SampleCount
(Gomes, Hoffmann, Sabharwal, & Selman, 2007) compute lower bounds model
counts. results shown third fourth columns Table 5. Configured
default settings ( = 3.5, = 2, z = 20, cutoff 10 000 flips), SampleCount could
find lower bounds circuits larger c1355. Although performance SampleCount significantly better RelSAT, fact SampleCount computes lower
bounds scale large circuits prevent us building diagnosis algorithm
based approximate model counting.
satisfiability-based method diagnosing optimized version ISCAS85
used Smith, Veneris, Viglas (2004). recent paper (Smith, Veneris, Ali, &
Viglas, 2005), SAT-based approach replaced Quantified Boolean Formula
(QBF) solver computing multiple-fault diagnoses. methods report good absolute
404

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Table 5: Model count time counting
RelSat
Models
Time [s]

Name

SampleCount
Models
Time [s]

74182
74L85
74283
74181

3.9896 107
8.3861 1014
1.0326 1015
5.6283 1015

1
340
> 3 600
> 3 600

3.526359 106
7.412344 1013
3.050026 1014
1.538589 1027

0.2
0.3
0.3
1.1

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552












7.2045 1018
3.6731 1020
9.4737 1039
1.4668 1028
2.1704 1031
9.0845 1015
4.8611 1019
9.3551 1016
1.0300 1018
1.0049 1016

> 3 600
> 3 600
> 3 600
> 3 600
> 3 600
> 3 600
> 3 600
> 3 600
> 3 600
> 3 600

1.496602 1067
7.549183 1083
8.332702 10166
7.488300 10233







9.9
13.1
42.7
99.8







execution time single double-faults (and believe scale well higher
cardinalities), require modifications initial circuits (i.e., introduce cardinality
test constraints) suggest specialized heuristics SAT solvers order improve
search performance. Comparison performance Safari timings reported
papers would difficult due number reasons use different
optimized benchmark sets, trading-off memory speed, rewriting original circuits, etc.
6.4 Performance Greedy Stochastic Search
Table 6 shows absolute performance Safari (M = |COMPS|, N = 4). varies
millisecond small models, approx. 30 largest strong-fault
model. fast absolute times show Safari suitable on-line reasoning tasks,
autonomy depends speedy computation diagnoses.
model, minimum maximum time computing diagnosis
computed. values shown columns tmin tmax , respectively. small
range tmax tmin confirms theoretical results Safari insensitive fault
cardinalities diagnoses computes. performance CDA HA ,
hand, dependent fault cardinality quickly degrades increasing fault
cardinality.
6.5 Optimality Greedy Stochastic Search
results produced complete diagnostic methods (CDA HA ) know
exact cardinalities minimal-cardinality diagnoses observations.
considering observations, lead single double faults, evaluated
405

fiFeldman, Provan, & van Gemund

Table 6: Performance Safari [ms]
Weak
Name

tmin

S-A-0
tmax

74182
74L85
74283
74181

0.41
0.78
0.92
2.04

1.25
7.47
4.84
6.94

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

8.65
14.19
48.08
95.03
237.77
500.54
984.31
1 950.12
2 105.28
4 557.4

38.94
31.78
88.87
141.59
349.96
801.12
1 300.98
2 635.71
2 688.34
6 545.21

tmin
0.39
0.72
0.88
2.13

S-A-1
tmax
4.41
1.89
3.65
22.4

tmin
0.40
0.69
0.92
2.07

tmax
0.98
4.77
5.2
7.19

7.58
30.59
7.96
38.27
11.03
30.32
10.79
31.11
37.08
80.74
38.47
81.34
76.57
150.29
83.14
135.29
196.13
300.11
217.32
442.91
646.95 1 776.72
463.24
931.8
1 248.5
2 516.46
976.56 2 565.18
3 346.49 7 845.41 2 034.5
4 671.17
2 246.84 3 554.4 1 799.18 2 469.48
9 975.04 32 210.71 5 338.97 12 101.61

average optimality Safari. Table 7 shows optimality results greedy
search. second column Table 7 shows number observation vectors leading
single faults weak-fault model. third column shows average cardinality
Safari. second third column repeated S-A-0 S-A-1 models.
Table 7 shows that, SD WFM, average cardinality returned Safari
near-optimal single double faults. c1355 model shows worst-case
results single-fault observations, c499 difficult weak-fault model
computing double-fault diagnosis. results improved increasing N
discussed Sec. 4.
strong-fault models, results close optimal small models
quality diagnosis deteriorates c3540 bigger. surprising, considering
modest number retries number flips Safari configured.
6.6 Computing Multiple Minimal-Cardinality Diagnoses
next show results experiments supporting claims made Sec. 5. that,
first chosen observations could compute | (SD )|
deterministic algorithm CDA HA (mostly observations leading single double
faults). configured Safari = |COMPS| N = 10| (SD )|.
Finally, diagnoses computed Safari filtered minimal-cardinality
ones. results summarized Table 8.
Table 8 repeats columns weak, S-A-0, S-A-1 models data
columns interpreted follows. columns marked | | show
minimal maximal number minimal-cardinality diagnoses per model computed
deterministic algorithm. columns Mc show percentage minimal-cardinality
406

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Table 7: Optimality Safari [average cardinality]
Single Faults
S-A-0
S-A-1
# Card. # Card.

Name

Weak
# Card.

74182
74L85
74283
74181

50
50
50
50

1
1.04
1.08
1.19

37
18
34
36

1
1.02
1.59
2.81

40
40
46
46

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

58
84
50
84
52
29
8
14
13
27

1.19
1.49
1
1.66
1.05
1.03
1.01
1
1
1.01

52
53
39
82
49
39
23
9
13
11

1.06
1.49
1.1
1
2.91
1.77
2.5
3.54
28.83
17.37

37
84
40
84
52
28
16
12
12
18

1
1.03
1.88
2.6

Weak
# Card.

Double Faults
S-A-0
S-A-1
# Card. # Card.

50
50
50
50

2
2.12
2.2
2.25

38
17
45
36

1.04 82
1.01 115
1.05 50
1.02
6
4.79
2.06 13
3.74
5.4
7
28.68
1
23.38 16

2.46
3.27
2.01
2.15

2.12

2
2
2

80
34
34
7
2
24
1
3
1
4

2
2.06
2.41
3.61

18
35
42
43

2
2.07
2.6
3.16

2.25 48
3.01 115
2.14 35
2
18
3
3
2.78 15
4.9

3.7
1
27

18.5
6

2.15
2.03
2.07
2.07
3.17
3.27

3.8

27.53

Table 8: % minimal-cardinality diagnoses computed Safari
Weak
Mc

Name

| |

74182
74L85
74283
74181

1 25
1 78
1 48
1 133

100
99.2
97.9
97.4

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

1 99
1 22
2 646
5 2 770
2 1 447
1 76
1 384
1 235
1 154
1 490

94.2
78.5
99.9
79.4
96.6
100
81.5
97.7
100
93.1

S-A-0
Mc Mf

| |

0
2
3
1

12
14
1 16
1 16

100
100
93.8
88.6

0
0
0
4.07

1 20
1 49
1 29
1 57

100
99.7
84.9
96.7

0
0
4
6.36

1 40
1 15
1 160
2 648
2 579
1 20
1 153
1 24
1 73
4 236

89.7
96.3
96.9
95.7
85.2
97.1
88.8
81.7
78.1
90.8

0
6
0
0
1.85
0
7.98
7.04
5.1
13.55

1 18
1 16
1 210
2 347
2 374
1 181
1 171
1 30
1 101
1 168

97
94.8
97.5
95.2
82.3
89.7
78.2
93.4
82.1
78

0
0
0
0.52
1.24
0
7.27
8.24
1.22
12.1

7.14
1.51
0
1.02
2.61
2.34
8.52
1.74
13.1
2.17

| |

S-A-1
Mc Mf

Mf

diagnoses returned Safari (from minimal-cardinality diagnoses)
| (SD )| > 1. columns Mf show percentage observations Safari
could compute minimal-cardinality diagnosis.
407

fiFeldman, Provan, & van Gemund

results shown Table 8 show even moderate values N (N 27 770),
Safari capable computing significant portion minimal-cardinality diagnoses.
portion varies 78.5% 100% weak-fault models 78% 100%
strong-fault models. percentage cases Safari could reach minimalcardinality diagnosis limited (at 13.55%) mainly cases
exists one single-fault diagnosis. Note even cases Safari cannot
compute minimal-cardinality diagnoses, result Safari still useful.
example, subset-minimal diagnosis small cardinality differing one two literals
nevertheless brings useful diagnostic information (a discussion diagnostic metrics
beyond scope paper).
6.7 Experimentation Summary
applied Safari suite benchmark combinatorial circuits encoded using
weak-fault models stuck-at strong fault models, shown significant performance
improvements multiple-fault diagnoses, compared two state-of-the-art deterministic
algorithms, CDA HA . results indicate Safari shows least order-ofmagnitude speedup CDA HA multiple-fault diagnoses. Moreover, whereas
search complexity deterministic algorithms tested increases exponentially fault
cardinality, search complexity stochastic algorithm appears independent
fault cardinality.
compared performance Safari algorithm based MaxSAT, Safari shows least order-of-magnitude speedup computing diagnoses.
compared optimality Safari algorithm based SLS MaxSAT, Safari consistently computes diagnoses smaller cardinality whereas SLS
Max-SAT diagnostic algorithm often fails compute diagnosis.

7. Related Work
paper (1) generalizes Feldman, Provan, van Gemund (2008a), (2) introduces important theoretical results strong-fault models, (3) extends experimental results
there, (4) provides comprehensive optimality analysis Safari.
gross level, one classify types algorithms applied solve
MBD based search compilation. search algorithms take input diagnostic model observation, search diagnosis, may minimal
respect minimality criterion. Examples search algorithms include -based
algorithms, CDA (Williams & Ragno, 2007) hitting set algorithms (Reiter,
1987). Compilation algorithms pre-process diagnostic model form
efficient on-line diagnostic inference. Examples algorithms include ATMS
(de Kleer, 1986) prime-implicant methods (Kean & Tsiknis, 1993), DNNF (Darwiche, 1998), OBDD (Bryant, 1992). knowledge, approaches adopt
exact methods compute diagnoses; contrast, Safari adopts stochastic approach
computing diagnoses.
first glance, seems MBD could efficiently solved using encoding
SAT (Jin et al., 2005), constraint satisfaction (Freuder, Dechter, Ginsberg, Selman, &
Tsang, 1995) Bayesian network (Kask & Dechter, 1999) problem. However, one needs
408

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

take account increase formula size (over direct MBD encoding), addition
underconstrained nature MBD problems.
Safari close resemblance Max-SAT (Hoos & Stutzle, 2004) conducted extensive experimentation complete (partial weighted) SLS-based
Max-SAT. results experiments long, published separate technical report (Feldman, Provan, & van Gemund, 2009a). results show
although Max-SAT compute diagnoses many cases, performance MaxSAT degrades increasing circuit size cardinality injected faults.
particular, Safari outperforms Max-SAT least order-of-magnitude class
diagnostic problems considered. case SLS-based Max-SAT, optimality
Max-SAT-based inference significantly worse Safari.
show Safari exploits particular property MBD problems, called diagnostic
continuity, improves optimality Safari compared to, example, straightforward ALLSAT encodings (Jin et al., 2005). experimentally confirm favorable
performance optimality Safari. Although Safari close resemblance MaxSAT, Safari exploits specific landscape properties diagnostic problems, allow
(1) simple termination criteria (2) optimality bounds. Due hybrid nature
Safari (the use LTMS SAT), Safari avoids getting stuck local optima performs better Max-SAT based methods. Incorporating approaches Max-SAT,
particular SAPS (Hutter, Tompkins, & Hoos, 2002), future versions Safari may
help solving general abduction problems, may expose continuous
properties models considered.
Stochastic algorithms discussed framework constraint satisfaction
(Freuder et al., 1995) Bayesian network inference (Kask & Dechter, 1999). latter
two approaches used solving suitably translated MBD problems. often
case, though, encodings difficult search specialized ones.
MBD instance constraint optimization, particular constraints failure
variables. MBD developed algorithms exploit domain properties,
proposed approach differs significantly almost MBD algorithms appear
literature. advanced MBD algorithms deterministic, Safari borrows
SLS algorithms that, rather backtracking, may randomly flip variable assignments
determine satisfying assignment. Complete MBD algorithms typically make use
preferences, e.g., fault-mode probabilities, improve search efficiency; Safari uses
technique top stochastic search space diagnoses.
closely-related diagnostic approach Fijany, Vatan, Barrett, James, Williams,
Mackey (2003), map minimal-hitting set problem problem finding
assignment bounded weight satisfying monotone SAT problem, propose
use efficient SAT algorithms computing diagnoses. approach Fijany et al.
shown speedups comparison diagnosis algorithms; main drawback
number extra variables clauses must added SAT encoding,
even significant strong fault models multi-valued variables. contrast,
approach works directly given diagnosis model requires conversion another
representation.
work bears closest resemblance preference-based Cost-Based Abduction
(CBA) (Charniak & Shimony, 1994; Santos Jr., 1994). algorithmic work
409

fiFeldman, Provan, & van Gemund

area, primary paper adopts stochastic local search Abdelbar, Gheita,
Amer (2006). paper, present hybrid two-stage method based
Iterated Local Search (ILS) Repetitive Simulated Annealing (RSA). ILS stage
algorithm uses simple hill-climbing method (randomly flipping assumables)
local search phase, tabu search perturbation phase. RSA repeatedly applies
Simulated Annealing (SA), starting time random initial state. hybrid
method initially starts arbitrary state, greedily-chosen state. applies
ILS algorithm; algorithm fails find optimal solution fixed number
hill-climbing steps8 fixed number R repetitions perturbation-local
search cycle,9 ILS-based search terminated RSA algorithm run optimal
solution found.
work differs Abdelbar et al. (2006) several ways. First, initial
state generated using random SAT solution. hill-climbing phase use next
similar Abdelbar et al.; however, randomly restart hill-climbing
identify better diagnosis, rather applying tabu search simulated annealing.
approach simpler Abdelbar et al., case weak fault models
guaranteed optimal; future work plan compare approach
Abdelbar et al. strong fault models.
2009 Safari competed diagnostic algorithms NGDE (de Kleer, 2009)
RODON (Bunus, Isaksson, Frey, & Munker, 2009) synthetic track first
diagnostic competition DXC09 (Kurtoglu, Narasimhan, Poll, Garcia, Kuhn, de Kleer, van
Gemund, & Feldman, 2009). conditions DXC09 experiments
conducted similar ones described paper. CPU memory performance Safari order magnitude better competing algorithms despite
fact NGDE RODON performed better complete algorithms discussed
section. paper, addition computational metrics, informally
used minimality diagnosis optimality criterion. DXC09 organizers, however, defined utility metric approximates expected repair effort circuit
(Feldman, Provan, & van Gemund, 2009b). utility metric, Safari scored slightly
worse two competing algorithms, expected Safari trades
diagnostic precision computational efficiency. refer reader DXC papers
mentioned thorough analysis competition results.

8. Conclusion Future Work
described greedy stochastic algorithm computing diagnoses within modelbased diagnosis framework. shown subset-minimal diagnoses computed
optimally weak fault models important subset strong fault models,
almost minimal-cardinality diagnoses computed general fault models.
8. Hill-climbing proceeds follows: given current state cost f (s), neighbouring state
generated flipping randomly chosen assumable hypothesis. f (s ) better f (s),
becomes current state; otherwise, discarded. iterations elapse without change
current state, local search exits.
9. Perturbation-local search, starting current state cost f (s), randomly chooses
assumable variable h, applies tabu search identify better state flipping h based tabu
status.

410

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

argue Safari broad practical significance, compute significant fraction minimal-cardinality diagnoses systems large complex
diagnosed existing deterministic algorithms.
future work, plan experiment models combination weak strong
failure-mode descriptions. plan experimenting wider variety stochastic
methods, simulated annealing genetic search, using larger set benchmark
models. Last, plan apply algorithms wider class abduction constraint
optimization problems.

References
Abdelbar, A. M. (2004). Approximating cost-based abduction NP-hard. Artificial Intelligence, 159 (1-2), 231239.
Abdelbar, A. M., Gheita, S. H., & Amer, H. A. (2006). Exploring fitness landscape
run-time behaviour iterated local search algorithm cost-based abduction.
Experimental & Theoretical Artificial Intelligence, 18 (3), 365386.
Bayardo, R. J., & Pehoushek, J. D. (2000). Counting models using connected components.
Proc. AAAI00, pp. 157162.
Brglez, F., & Fujiwara, H. (1985). neutral netlist 10 combinational benchmark circuits
target translator fortran. Proc. ISCAS85, pp. 695698.
Bryant, R. E. (1992). Symbolic Boolean manipulation ordered binary-decision diagrams. ACM Computing Surveys, 24 (3), 293318.
Bunus, P., Isaksson, O., Frey, B., & Munker, B. (2009). RODON - model-based diagnosis
approach DX diagnostic competition. Proc. DX09, pp. 423430.
Bylander, T., Allemang, D., Tanner, M., & Josephson, J. (1991). computational complexity abduction. Artificial Intelligence, 49, 2560.
Charniak, E., & Shimony, S. E. (1994). Cost-based abduction MAP explanation. Artificial Intelligence, 66 (2), 345374.
Cook, S. A. (1971). complexity theorem-proving procedures. Proc. STOC71, pp.
151158.
Darwiche, A. (1998). Model-based diagnosis using structured system descriptions. Journal
Artificial Intelligence Research, 8, 165222.
Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem-proving.
Communications ACM, 5 (7), 394397.
de Kleer, J. (1986). assumption-based TMS. Artificial Intelligence, 28 (2), 127162.
de Kleer, J. (1990). Using crude probability estimates guide diagnosis. Artificial Intelligence, 45 (3), 381291.
de Kleer, J. (2009). Minimum cardinality candidate generation. Proc. DX09, pp. 397
402.
de Kleer, J., Mackworth, A., & Reiter, R. (1992). Characterizing diagnoses systems.
Artificial Intelligence, 56 (2-3), 197222.
411

fiFeldman, Provan, & van Gemund

de Kleer, J., & Williams, B. (1987). Diagnosing multiple faults. Artificial Intelligence,
32 (1), 97130.
Een, N., & Sorensson, N. (2003). extensible SAT-solver. Proc. SAT03, Vol. 2919
Lecture Notes Computer Science, pp. 502518. Springer.
Eiter, T., & Gottlob, G. (1995). complexity logic-based abduction. Journal
ACM, 42 (1), 342.
Feldman, A., Provan, G., & van Gemund, A. (2008a). Computing minimal diagnoses
greedy stochastic search. Proc. AAAI08, pp. 911918.
Feldman, A., Provan, G., & van Gemund, A. (2008b). Computing observation vectors
max-fault min-cardinality diagnoses. Proc. AAAI08, pp. 911918.
Feldman, A., Provan, G., & van Gemund, A. (2009a). family model-based diagnosis
algorithms based Max-SAT. Tech. rep. ES-2009-02, Delft University Technology.
Feldman, A., Provan, G., & van Gemund, A. (2009b). Lydia approach combinational
model-based diagnosis. Proc. DX09, pp. 403408.
Feldman, A., & van Gemund, A. (2006). two-step hierarchical algorithm model-based
diagnosis. Proc. AAAI06, pp. 827833.
Fijany, A., Vatan, F., Barrett, A., James, M., Williams, C., & Mackey, R. (2003). novel
model-based diagnosis engine: Theory applications. Proc. IEEE Aerospace03,
Vol. 2, pp. 901910.
Forbus, K., & de Kleer, J. (1993). Building Problem Solvers. MIT Press.
Freeman, J. W. (1995). Improvements Propositional Satisfiability Search Algorithms.
Ph.D. thesis, University Pennsylvania.
Freuder, E. C., Dechter, R., Ginsberg, M. L., Selman, B., & Tsang, E. P. K. (1995). Systematic versus stochastic constraint satisfaction. Proc. IJCAI95, Vol. 2, pp. 20272032.
Friedrich, G., Gottlob, G., & Nejdl, W. (1990). Physical impossibility instead fault
models. Proc. AAAI90, pp. 331336.
Gomes, C. P., Hoffmann, J., Sabharwal, A., & Selman, B. (2007). sampling model
counting. Proc. IJCAI07, pp. 22932299.
Hansen, M., Yalcin, H., & Hayes, J. (1999). Unveiling ISCAS-85 benchmarks: case
study reverse engineering. IEEE Design & Test, 16 (3), 7280.
Hermann, M., & Pichler, R. (2007). Counting complexity propositional abduction.
Proc. IJCAI07, pp. 417422.
Hoos, H. (1999). SAT-encodings, search space structure, local search performance.
Proc. IJCAI99, pp. 296303.
Hoos, H., & Stutzle, T. (2004). Stochastic Local Search: Foundations Applications.
Morgan Kaufmann Publishers Inc.
Hutter, F., Tompkins, D. A. D., & Hoos, H. H. (2002). Scaling probabilistic smoothing:
Efficient dynamic local search SAT. Proc. CP02, pp. 233248.
412

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Jin, H., Han, H., & Somenzi, F. (2005). Efficient conflict analysis finding satisfying
assignments Boolean circuit. Proc. TACAS05, pp. 287300.
Kask, K., & Dechter, R. (1999). Stochastic local search Bayesian networks. Proc.
AISTAT99, pp. 113122.
Kean, A., & Tsiknis, G. K. (1993). Clause management systems. Computational Intelligence,
9, 1140.
Kumar, T. K. S. (2002). model counting characterization diagnoses. Proc. DX02,
pp. 7076.
Kurtoglu, T., Narasimhan, S., Poll, S., Garcia, D., Kuhn, L., de Kleer, J., van Gemund, A.,
& Feldman, A. (2009). First international diagnosis competition - DXC09. Proc.
DX09, pp. 383396.
Marques-Silva, J. P. (1999). impact branching heuristics propositional satisfiability
algorithms. Proc. EPIA99, pp. 6274.
McAllester, D. A. (1990). Truth maintenance. Proc. AAAI90, Vol. 2, pp. 11091116.
Reiter, R. (1987). theory diagnosis first principles. Artificial Intelligence, 32 (1),
5795.
Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82 (1-2),
273302.
Santos Jr., E. (1994). linear constraint satisfaction approach cost-based abduction.
Artificial Intelligence, 65 (1), 128.
Smith, A., Veneris, A., Ali, M. F., & Viglas, A. (2005). Fault diagnosis logic debugging
using Boolean satisfiability. IEEE Transactions CAD Integrated Circuits
Systems, 24 (10), 16061621.
Smith, A., Veneris, A., & Viglas, A. (2004). Design diagnosis using Boolean satisfiability.
Proc. ASP-DAC04, pp. 218223.
Struss, P., & Dressler, O. (1992). Physical negation - integrating fault models General Diagnostic Engine. Readings Model-Based Diagnosis, pp. 153158. Morgan
Kaufmann Publishers Inc.
Thiffault, C., Bacchus, F., & Walsh, T. (2004). Solving non-clausal formulas DPLL
search. Proc. CP04, pp. 663678.
Tseitin, G. (1983). complexity proofs propositional logics. Siekmann, J., &
Wrightson, G. (Eds.), Automation Reasoning: Classical Papers Computational
Logic (19671970), Vol. 2. Springer-Verlag.
Williams, B., & Ragno, R. (2007). Conflict-directed A* role model-based embedded systems. Journal Discrete Applied Mathematics, 155 (12), 15621595.
Zhang, H., & Stickel, M. E. (1996). efficient algorithm unit propagation. Proc.
AI-MATH96, pp. 166169.

413


