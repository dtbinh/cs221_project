journal artificial intelligence

submitted published

cause identification aviation safety incident reports
via weakly supervised semantic lexicon construction
muhammad arshad ul abedin
vincent ng
latifur khan

arshad student utdallas edu
vince hlt utdallas edu
lkhan utdallas edu

department computer science
erik jonsson school engineering computer science
university texas dallas
w campbell road ms ec
richardson tx u

abstract
aviation safety reporting system collects voluntarily submitted reports aviation safety incidents facilitate work aiming reduce incidents effectively reduce incidents vital accurately identify incidents occurred
precisely given set possible causes shaping factors task cause identification involves identifying shaping factors responsible
incidents described report investigate two approaches cause identification
approaches exploit information provided semantic lexicon automatically constructed via thelen riloffs basilisk framework augmented linguistic
algorithmic modifications first labels report simple heuristic looks words phrases acquired semantic lexicon learning
process report second recasts cause identification text classification employing supervised transductive text classification
learn incident reports labeled shaping factors
label unseen reports experiments heuristic
learning given sufficient training data outperform baseline
system significantly

introduction
safety paramount importance comes aviation industry alone
incidents including fatal accidents casualties improve
aviation safety situation aviation safety reporting system asrs established
make safety incident data available researchers asrs collects voluntarily submitted reports aviation safety incidents written flight crews attendants controllers
related parties reports contain number fixed fields free text narrative describing incident however data grown quite large years
getting increasingly difficult impossible analyze reports human
means become necessary reports analyzed automated means
http asrs arc nasa gov
http www flightsafety gov
c

ai access foundation rights reserved

fiabedin ng khan

take full advantage data reduce safety incidents necessary extract
reports happened known possible
identify correlations incidents causes take fruitful measures
toward eliminating causes however fixed fields reports devoted
aspects happened incidents fixed field indicates
incidents causes instead reporter discusses report narrative thinks
caused incident along incident description thus cause incident
extracted analyzing free text narrative example report shown next
illustrate task
report descending lit encountered instrument meteorological conditions rime ice rain moderate chop turned
heading auto pilot direct lit attitude indicator remained
bank xchking noticed radio magnetic indicators degree
headings switched corrected course auto pilot flight
director kicked continued altitude select
auto pilot attempted engage radar vectors
descent feet noticed altitude feet
mean sea level stopped descent climbed feet mean sea
level air traffic control noted altitude deviation time noticed
thankful backup time flight director
cockpit occurred end hour crew day bad weather instrument lack crew rest first officer pilot flying
right seat hours rest due inability go sleep
night tired trip lit orl lit eaten
hours
posse et al identify important cause types shaping factors
influence occurrence aviation safety incident described asrs report
shaping factors contextual factors influenced reporters behavior
incident thus contributed occurrence incident factors
attributed humans e g pilot flight attendant psychological pressure
overly heavy taskload unprofessional attitude impacts performance
related surrounding environment e g physical environment snow
communication environment auditory interference detailed description
shaping factors found section
report incident influenced three shaping factors
namely physical environment concerns bad weather mentioned resource
deficiency concerns equipment duty cycle refers
physical exhaustion due long hours duty without adequate rest replenishment
three shaping factors indicated different words phrases report
instance bad weather condition expressed phrases rime ice rain
moderate chop details equipment appear sentence fragments
improve readability report preprocessed original form steps described
section



ficause identification via weakly supervised semantic lexicon construction

attitude indicator remained bank degree headings flight director
issue long hours duty illustrated sentence fragments hour
crew day tired trip goal cause identification task aviation
safety domain identify shaping factors contributed incident
described report lexical cues appearing report narrative
however mentioned earlier sheer data makes prohibitive
analyze reports manually identify associated shaping factors thus
focus automated cause identification asrs reports involves
automatically analyzing report narrative identifying responsible shaping factors
brings domain natural language processing nlp
since set texts e report narratives set possible labels
texts e shaping factors task naturally cast text classification
task however unlike topic text classification cause text classification
addressed extensively nlp community previous work causal analysis quite
different nature cause text classification task specifically previous
cause analysis works involve text classification focusing instead determining
existence causal relation two sentences events instance
work causal analysis question answering question may involve
cause event e g kaplan berry rogghe garcia khoo chan niu
girju focus finding causal relationship two sentence
components another example causal analysis equipment malfunction reports
attempted grishman ksiezyk whose work restricted analysis
reports related one specific piece equipment studied analyze cause effect
relations events leading malfunction described reports
cause identification aviation safety reports rather challenging
number factors specific asrs dataset first unlike many nlp
underlying corpus composed set well edited texts newspaper
reports reviews legal medical documents asrs reports mostly written
informal manner since edited except removing author identity
information reports tend contain spelling grammatical mistakes second
employ large amount domain specific acronyms abbreviations terminology third
incident described report may caused one shaping factor
thus reports multiple shaping factor labels making task challenging
binary classification even multi class instance one
label scarcity labeled data task coupled highly imbalanced
class distributions makes difficult acquire accurate classifier via supervised learning
previous work cause identification asrs reports done primarily
researchers nasa see posse et al knowledge involved manual
analysis reports specifically nasa brought together experts aviation safety
human factors linguistics english language participate series brainstorming
sessions generated collection seed keywords simple expressions template
expressions related shaping factor labeled reports shaping
factors looking related expressions report narrative however
recently work started processing blogs may grammatical blogs
typically full domain specific terminology



fiabedin ng khan

major weakness associated involves large amount human effort
identifying relevant keywords expressions yet resulting list keywords
expressions means exhaustive moreover evaluated
manually labeled reports small scale evaluation means satisfactory
judged current standard nlp one contributions
annotation asrs reports shaping factors serve standard
evaluation dataset different cause identification methods compared
investigate two alternative approaches cause identification
exploit information provided automatically constructed semantic lexicon
specifically view large amount human involvement nasas work
aim replace manual selection seed words bootstrapping
automatically constructs semantic lexicon specifically motivated thelen riloffs
basilisk framework learn semantic lexicon consists set words
phrases semantically related shaping factors follows starting small
set seed words phrases augment seeds iteration automatically
finding fixed number words phrases related seeds corpus adding
seed list importantly however propose four modifications
basilisk framework potentially improve quality generated lexicon
first linguistic modification addition parse features e g subjectverb verb object features basilisk employ features computed
robustly e g n grams remaining three algorithmic modifications
basilisk framework involving use probabilistic semantic similarity measure
use common word pool enforcement minimum support maximum
generality constraints words extraction patterns favors addition
frequently occurring content bearing words disfavors overly general extraction patterns
mentioned investigate two approaches cause identification exploit
automatically learned semantic lexicon first heuristic
motivated posse et al labels report shaping factor contains
least word phrase relevant shaping factor unlike posse et al
work relevant words phrases employed heuristic procedure
manually identified automatically acquire words phrases via semisupervised semantic lexicon learning procedure described second
machine learning somewhat orthogonal nasas instead
human identify seed words phrases relevant shaping factor
humans annotate small subset available incident reports shaping
factors apply machine learning train classifier automatically
label unseen report combinations n gram features words phrases
automatically acquired aforementioned semantic lexicon learning procedure
see acquire cause identifier support vector machines svms
shown effective topic text classification since small
number labeled reports attempt combine labeled unlabeled reports
transductive version svms
since approaches rely simple linguistic knowledge sources involve n grams
words phrases automatically acquired semantic lexicon learning procedure one may argue use simple features sufficient cause


ficause identification via weakly supervised semantic lexicon construction

identification important point means arguing
features sufficient cause identification however use simple features
relevant task motivated work performed nasa researchers
mentioned manually identified seed words phrases shaping
factor posse et al semantic lexicon learning procedure precisely aims learn
words phrases error analysis reveals simple linguistic features
sufficient learning cause identification sophisticated knowledge
sources needed improve performance one first attempts tackle cause
identification task believe use simple features good starting point
establishes baseline future studies domain specific
compared
evaluate aforementioned two approaches manually annotated asrs reports experiments number interesting first best performance
achieved heuristic label report basis presence
automatically acquired lexicon words phrases report achieving f measure
importantly method significantly surpasses performance
baseline system labels report basis presence small set manually
identified seed words phrases suggest employing automatically
acquired semantic lexicon relevant useful cause text classification
asrs reports second words phrases learned semantic lexicon used
features training svms classification improve performance
svm classifier trained solely n gram features amount
training data small however increase amount training data crossvalidation lexicon words phrases features addition unigrams
bigrams helps improve classifier performance statistically significantly particular
observed f measure svm classifiers combination
unigrams bigrams lexicon words phrases features confirm
words phrases learned semantic lexicon relevant valuable
features identifying responsible shaping factors nevertheless magnitude
improvement indicates still much room improvement may
achieved deeper semantic features
summary believe work automated cause identification makes five
primary contributions
instead manually analyzing incident reports identify
relevant shaping factors possible reduce amount human effort required
task manually analyzing small subset reports identifying
shaping factors rest reports automated methods
propose several modifications thelen riloffs semi supervised lexicon learning framework modified basilisk framework allows us
acquire semantic lexicon yields significantly better performance cause
identification original basilisk framework equally importantly none
modifications geared towards cause identification task hence
applicable generally semantic lexicon learning task fact addi

fiabedin ng khan

tional experiments suggest modified basilisk yields better accuracy original
basilisk bootstrapping general semantic categories
semantic lexicon learning useful cause identification asrs
reports particular words phrases learned semantic lexicon
profitably used improve heuristic learning
given sufficient training data cause identification addition
believe similar cause identification task causes described
text may useful learn semantic lexicon containing key words
phrases related different types possible causes use key words
phrases features machine learning
attempt deduce weaknesses approaches help direct future
performed analysis errors made best performing
system namely heuristic semantic lexicon learned
modified basilisk method randomly chosen subset test reports
manually annotated subset reports relevant shaping factors
set annotated reports made publicly available serve
standard evaluation set task future comparing
approaches cause identification
rest organized follows section discuss dataset
shaping factors reports preprocessed annotated section defines
baseline simply looks small set manually extracted seed words
phrases report narratives section describe semantic lexicon learning
procedure basilisk lexicon learning procedure thelen riloff
augmented modifications section discuss heuristic
learning approaches cause identification evaluate two approaches
section discuss related work section finally section summarize
conclusions discuss future work

dataset
dataset used aviation safety incident reports publicly available
website aviation safety reporting system used reports collected period january december report contains
free text narrative written reporter several fixed fields incident
time place incident environment information details aircrafts
involved reporting persons credentials details anomaly detector resolution
consequence incident description situation words
fixed fields report contain information happened
physical circumstances cover incident took place discussed
posse et al ferryman posse rosenthal srivastava statler
narrative report contains information shaping factors incident
available http asrs arc nasa gov search database html



ficause identification via weakly supervised semantic lexicon construction

reason decided analyze free text narrative report nlp techniques identify shaping factor incident may constructed
corpus task combining narratives reports
shaping factors
incidents described asrs reports happen variety reasons posse et al
focus shaping factors simply shapers following short description
shaping factors taken verbatim work posse et al
attitude indication unprofessional antagonistic attitude controller
flight crew member
communication environment interferences communications cockpit
noise auditory interference radio frequency congestion language barrier
duty cycle strong indication unusual working period e g long day flying
late night exceeding duty time regulations short inadequate rest
periods
familiarity indication lack factual knowledge unfamiliar company airport aircraft
illusion illusions include bright lights cause something blend black hole
white sloping terrain
physical environment unusual physical conditions could impair flying
make things difficult unusually hot cold temperatures inside cockpit
cluttered workspace visual interference bad weather turbulence
physical factors pilot ailment could impair flying make things difficult tired fatigued drugged incapacitated influenced alcohol
suffering vertigo illness dizziness hypoxia nausea loss sight loss hearing
preoccupation preoccupation distraction division attention creates
deficit performance preoccupied busy something else
distracted
pressure psychological pressure feeling intimidated pressured pressed
time low fuel
proficiency general deficit capabilities inexperience lack training
qualified current lack proficiency
resource deficiency absence insufficient number poor quality resource
overworked unavailable controller insufficient date chart equipment malfunction inoperative deferred missing equipment


fiabedin ng khan

taskload indicators heavy workload many tasks shorthanded crew
unexpected something sudden surprising expected
anything else could shaper shift change passenger discomfort disorientation
preprocessing
semantic lexicon learning cause identification need identify
part speech pos word text phrases chunks
sentences grammatical roles words governing words ideally
achieve high accuracies three tagging tasks would manually annotate section
asrs corpus appropriate annotations e g pos tags chunks train
appropriate taggers tag rest corpus however laborintensive task beyond scope therefore used publicly
available tools trained standard corpora three tasks inevitable
produce accurate automatic annotations corpus see
caused task
corpus first identify sentence boundaries tool mxterminator second run pos tagger crftagger phan b uses penn
treebank tag set marcus santorini marcinkiewicz sentences detected
mxterminator third run chunker crfchunker phan tagged
text identify different types phrases minipar parser lin run
sentences identify grammatical roles words however report text
preprocessed applying tools reasons described following paragraphs
reports asrs data set usually informally written domain
specific abbreviations acronyms general observed van delden gomez
posse et al ferryman et al narratives tend written
short abbreviated manner tend contain poor grammar text
converted upper case following example narrative report
taxiing ramp laf night made wrong turn
crossed rwy active time
sign indicate rwy xing clred directions xing acft field
time mention atis signs
construction ramp area ctlr didnt question
us brought sit crossed
active rwy commuter ops days hvy flying
reduced rest rwy signs busy last min commuter work changes contributed rwy
incursion hr day hr flt time
ftp ftp cis upenn edu pub adwait jmx trained wall street journal corpus



ficause identification via weakly supervised semantic lexicon construction

reports need preprocessing nlp techniques applied
since shelf tools e g pos tagger trained mixed case texts
example running crftagger trained wsj corpus correct cases
first two sentences yield following
taxiing nnp nnp dt ramp nnp laf nnp
night nn
made nnp dt wrong nnp turn nnp cc crossed vbd
rwy nnp cd dt active nnp dt time nn
seen tagger mislabels words taxiing made wrong
active proper nouns nnp instead tagging verb preposition verb
adjective adjective respectively occurs good feature detecting proper
nouns sentence case first character since words begin capital
letter tagger mistakes significant portion words nnp another reason
tagger performs poorly corpus lot abbreviations appear text
example xing hvy short crossing heavy since
likely known pos tagger trained standard well edited corpus would
identified unknown words likely tagged nouns instead verb
adjective respectively similar observed parsers chunkers
reason decided preprocess text expanding abbreviations
restoring cases words
expand acronyms abbreviations rely official list acronyms
abbreviations used asrs reports small number cases abbreviation
acronym may one expansion example arr may mean arrival
arrive cases arbitrarily chose one possibilities restore case
set english word lists place names person names applied text
identify known words word report text appeared word lists
converted lower case unknown words left uppercase
process aforementioned narrative follows
taxiing ramp laf night made wrong turn crossed
runway active time sign indicate
runway crossing cleared directions crossing
aircraft field time mention automatic terminal
information service signs construction ramp area
controller didnt question us brought situation
crossed active runway commuter operations days heavy flying
see http akama arc nasa gov asrsdbonline pdf asrs decode pdf
better option would disambiguate alternative expansions context e g
method followed banko brill however number ambiguities acronyms
abbreviations list small exact pos variations
word thus effect ambiguities performance nlp tools expected
minimal
http wordlist sourceforge net



fiabedin ng khan

reduced rest runway signs busy last minute commuter work
changes contributed runway incursion hour day hour flight time
ran pos tagger crftagger processed text observe
errors example tagged version aforementioned two sentences
taxiing vbg dt ramp nn laf nnp night nn
made vbn dt wrong jj turn nn cc crossed vbd runway nn cd
dt active jj dt time nn
sentences correctly tagged however case restoration method
arguably simplistic hence determine need perform fine grained case
restoration sought measure much would gain accurately restoring
case words sentences present heuristic method check
randomly picked sentences corpus first ran pos tagger
sentences case restored aforementioned heuristic case restoration
method manually corrected capitalization sentences ran
pos tagger case restored sentences tags thus generated compared
found agreement means likely gain much terms
pos tagging accuracy correctly case restored text heuristically case restored
text five differences words three nnps mislabeled nns
essentially effect outcomes therefore marginal utility
applying sophisticated case restoration methods seem enough justify
additional effort necessary limit preprocessing step expansion abbreviations acronyms followed heuristic case restoration procedure described
complete flow preprocessing shown figure
human annotation procedure
recall need reports labeled shaping factors training cause identification classifiers testing performance two approaches cause identification
additionally order learn semantic lexicon via bootstrapping need small set
seed words phrases related shaping factor starting point
performing language normalization performed two types annotations labeling
set reports shaping factors identifying set seed words phrases
reports annotation procedure described detail following sections
annotating reports shaping factors
nasa previously developed heuristic tackle cause identification
task posse et al evaluated manually annotated reports
far satisfactory far establishing strong baseline method concerned
thus decided annotate set reports evaluating automatic cause
identification methods
complete set reports chose random set reports
annotation subset divided two parts first part consisting reports


ficause identification via weakly supervised semantic lexicon construction

figure flow chart text preprocessing
annotated two persons one undergraduate student one graduate student
report asked answer following question
shaping factor responsible incident described report
annotators trained similar way labeled reports used
evaluation nasa researchers see posse et al specifically background
reading annotators referred works posse et al ferryman et al
describe shaping factors give examples words
phrases indicate influence shaping factors described incidents
definitions shapers repeated section following posse et al method
annotators explicitly instructed adhere definitions much possible
annotating reports shaping factors annotations completed
inter annotator agreement computed krippendorffs statistics
described artstein poesio measuring agreement set valued
items masi scoring metric passonneau observed inter annotator agreement
case found indicates reliable agreement
reports completely agreed annotations reports completely disagreed
reports partially agreed reports annotators asked discuss
discrepancies discussion found discrepancies could


fiabedin ng khan

primarily attributed vagueness descriptions shaping factors posse et
al interpreted differently two annotators
annotators agreed descriptions shapers interpreted
resolved differences annotation discussion remaining
reports annotated one annotators annotator asked
annotate subset reports reports cross verification purpose
inter annotator agreement case observed reports
annotated first annotator divided three sets training set reports
training cause identification classifiers held development set reports
parameter tuning test set reports evaluating performance
approaches cause identification distribution shaping factors training
development test sets shown second third fourth columns table
extracting seed words phrases
separate process first author went first reports annotators
worked selected words phrases relevant shaping factors
judgment whether word phrase relevant shaping factor careful
reading description shaping factors works posse et al
ferryman et al well example seed words selected nasa experts
shown two papers specific task case
report word phrase indicative
shaping factors identify assign appropriate
shaping factor
note seed words phrases chosen without regard shaping factor
annotation document picked possibility relevant
respective shaping factors number seed words phrases shaping
factor shown last column table see seed words phrases
manually selected training reports completeness
seed words phrases extracted reports appendix facilitate
topic annotated data used made available
http www utdallas edu maa asrs html
since gold standard compare list annotated
words phrases difficult directly compute precision however get rough
idea precision asked one annotators examine list identify
words phrases list believes correct disagreement
one word yields precision provides suggestive evidence
annotation fairly reliable manually identified words phrases
used baseline cause identification system see section served seeds
semantic lexicon learning procedure see section
fairly standard procedure nlp cross annotate subset data
complexity cost individual annotation high see works zaidan eisner piatko
kersey di eugenio jordan katz instance



ficause identification via weakly supervised semantic lexicon construction

table distribution shaping factors training test development sets
shaping factor
reports reports
reports
seed
training set
test set development words
test set
attitude




communication environment




duty cycle




familiarity




illusion









physical environment




physical factors




preoccupation




pressure




proficiency




resource deficiency




taskload




unexpected




total





baseline system cause identification
discussed introduction goal label incident reports
shaping factors caused incidents evaluate performance cause
identification methods need baseline uses amount training data
methods described performs reasonably well test set
given cause identification relatively investigated task standard
baseline adopted task fact knowledge related works
cause identification aviation safety domain conducted researchers
nasa see posse et al ferryman et al construct baseline
system motivated posse et al work specifically baseline takes input set
seed words phrases manually collected shaping factors see section
labels report occurrence heuristic seed word phrase found
report baseline annotates report shaping factor associated
seed example hour duty day seed phrase associated shaping
factor duty cycle occurrence heuristic label report contains
phrase hour duty daywith duty cycle simple attractive
need training evaluated easily searching
seed words narrative report labeled report potentially
labeled one shaping factors seed words phrases indeed
relevant respective shaping factors identify reports related
shaping factors high degree precision


fiabedin ng khan

semantic lexicon learning
described section baseline uses seed words phrases manually extracted
reports combination occurrence heuristic label reports
shaping factors however reports used evaluation may contain exactly
words phrases may contain different variations synonyms words
phrases semantically similar seed words phrases thus baseline
may able label reports correctly looking words phrases
seed words list
address potential propose use semantic lexicon learning learn words phrases semantically similar seed words phrases
reports corpus containing narratives reports weakly supervised bootstrapping may allow us learn large number useful words
phrases corpus would required huge amounts human effort
done manually first describe general bootstrapping section
section describe basilisk framework learning semantic lexicon
unannotated corpus thelen riloff finally section discuss
modifications basilisk framework
weakly supervised lexicon learning
mentioned earlier employ weakly supervised bootstrapping building
semantic lexicon use manually extracted seed words phrases
shaping factor described section create initial semantic lexicon
select words phrases unannotated reports semantically similar
words already appearing semantic lexicon reports corpus need
labeled shaping factors semantic similarity two words measured
features extracted corpus word process repeated iteratively
iteration certain number words added semantic lexicon
words augmented lexicon used seeds following iteration
process shown figure

figure flow chart lexicon learning procedure



ficause identification via weakly supervised semantic lexicon construction

basilisk framework
basilisk bootstrapping semantic lexicon induction semantic knowledge
instantiation aforementioned generic semantic lexicon learning framework thelen riloff basilisk framework works first identifying patterns
extracting noun phrases corpus appear one three syntactic roles
subject direct object prepositional phrase object example discussed thelen riloff sentence john arrested collaborated smith
murdered brown extraction patterns subject arrested extracts
john murdered object extracts brown collaborated pp object
extracts smith semantic category sk pattern pool constructed
patterns tend extract words sk measure tendency pattern pj
extract words sk r log f metric used defined
r log f pj

fj
log fj
nj



fj number distinct words sk pattern pj extracts nj
total number distinct words corpus pj extracts metric high
high precision patterns e patterns extract primarily words sk high recall
patterns e patterns extract large number words sk iteration
top patterns terms r log f scores put pattern pool sk
depleted patterns e patterns extracted words already semantic
lexicon considered step head nouns phrases extracted
resulting patterns pattern pool put word pool sk
next subset words word pool selected added seed words
list words word pool chosen relevant sk
specifically word wi word pool sk first avglog score calculated
defined follows

avglog wi sk

w
pi
x

log fj

j

w pi



w pi number patterns extract word wi pattern pj
extracts wi fj number words extracted pj belong sk
semantic category sk five words chosen highest avglog score
category sk
multi category learning thelen riloff experimented different scoring metrics reported achieved best performance calculating diff
score word given word word pool semantic category diff
score takes consideration score word gets categories returns
score words score semantic category relative categories
precisely diff score defined follows
dif f wi sk avglog wi sk max avglog wi sl
l k





fiabedin ng khan

sk semantic category wi evaluated thus diff score
high strong evidence wi belongs semantic category sk little evidence
belongs semantic categories semantic category diff score
calculated word categorys word pool top five words
highest diff score added lexicon category two additional checks
made stage word word pool added category
earlier iteration word discarded word found
one word pool added category highest score
completed semantic categories iteration ends next iteration
begins augmented lexicon
modifications basilisk framework
see later subsection analysis framework reveals
cases words selected basilisk may relevant ones reason
propose three algorithmic modifications basilisk framework semantic
similarity measure merging word pools one single pool assigning words
semantic categories imposing minimum support maximum generality criteria
patterns words added pattern pools word pools addition propose
one linguistic modification employ type feature computed
robust manner words phrases corpus namely n gram features
rest subsection discusses modifications
modification semantic similarity measure
seen section basilisk framework uses avglog scoring function measure
semantic similarity words diff score multi category learning uses
avglog function compute evidence word belonging semantic category
relative categories however closer examination avglog function shows
may able properly predict semantic similarity circumstances
understand reason let us first make following observations pattern pj occurs
times extracts words category sk times unlikely pj strongly
related sk similarly word wi occurs times extracted pattern pj
times pj small influence classification wi however avglog score
able take factors consideration precisely considers
absolute number semantic category members extracted patterns extract
word frequency extraction see case let us consider
word wi extracted three patterns p p p frequencies shown
table p p p extract five distinct seed words avglog score
word w would irrespective fact patterns actually extract word
seed words list tiny fraction occurrence corpus p extracts
seed word occurrence p time p pattern extracts w
often extracts lexicon word times appears text clearly
effectively assumes word belong one category reasonable
assumption specific task since shaping factors distinct meanings



ficause identification via weakly supervised semantic lexicon construction

patterns would suggest wi related semantic category yet gets
good score
table illustration avglog unrelated words may high
similarity score wi word appears corpus extracted
patterns p p p

patterns extract wi
number times wi extracted pattern pj
number times pattern pj occurs text
number times word category sk extracted pattern pj
number category words extracted pattern pj
log fj
avglog wi

p






p
p










keeping mind propose probabilistic metric semprob computes
probability word wi belongs semantic category sk given extracted
patterns p p pn specifically semprob calculated follows
semp rob wi sk p rob sk wi
x

p rob sk pj p rob pj wi



pj

words semprob assumes semantic category sk word wi
conditionally independent given pj pattern extracts wi probabilities
equation estimated maximum likelihood estimation corpus specifically
compute p rob pj wi divide number times pj extracts wi corpus
total number times wi appears corpus compute p rob sk pj divide
number times pj extracts word semantic category sk total number
times pj appears corpus given word wi given semantic category
sk sum products two quantities patterns extract wi
gives probability category sk given word wi method suffer
faced avglog since depends probability word extracted
patterns patterns probability extracting words category
example table semprob metric word wi illustrating
low probability wi belonging semantic category sk details given
table
modification common word pool
since compute eqn every word word pool categories
assign word semantic category probability highest change
framework one common word pool semantic categories


fiabedin ng khan

table illustration effectiveness semprob unrelated words get low similarity
score

patterns extract wi
number times wi extracted pattern pj
number times pattern pj occurs text
number times word category sk extracted pattern pj
p rob wi extracted pj
p rob pj extracts word sk
p rob wi extracted pj p rob pj extracts word sk
semp rob wi sk p rob wi belongs semantic category sk

p







p
p













still separate pattern pools different semantic categories words related
patterns pattern pools put common word pool allocated
probable semantic category separate word pools
semantic category add fixed number words category
iterations constraint may undesirably cause word added category
likely however since one word pool modification
constraint add fixed number words category
assign word likely category thus number words added
different categories may vary iteration
modification minimum support maximum generality
scenarios semprob metric produce undesirable
example consider infrequent word wi occurs entire corpus exactly
assume pattern pj extracts wi extracts words semantic category sk
probability according semprob probability wi belongs sk becomes
however sufficient evidence wi belongs sk cases
uncommon imposed minimum word frequency constraint words
put word pool words appear less certain number times
considered pattern appears infrequently corpus lead
consider infrequent pattern pj appears exactly twice corpus
extracts two words one words happen seed word
word probability belong category seed word pj
r log f value however since pj infrequent convey good evidence
membership semantic category allow pj put words
word pool therefore disallow low frequency patterns included
pattern pool adding constraint patterns put pattern pool must
minimum pattern frequency besides two constraints imposed frequency
occurrence words patterns employ two additional constraints first


ficause identification via weakly supervised semantic lexicon construction

maximum pattern generality constraint motivated rychly kilgarriff
remove consideration patterns general e patterns extract
many words imposing upper limit number distinct words pattern
added pattern pool extract second maximum word frequency
constraint since content bearing words likely lower frequency see davidov
rappoport impose upper limit maximum number times word
appears corpus four thresholds associated four frequency
constraints tuned automatically held development set
modification n gram patterns
addition parse tree subject verb verb object patterns already employed
basilisk employ n gram extraction patterns goal robustly capturing context words appear construct n gram extraction
patterns follows noun adjective x corpus create two n gram
patterns extracting x preceding n words hxi b hxi succeeding
n words example sentence solid line thunderstorms detected
bigram patterns thunderstorms would line hxi hxi detected
complete sentence approaching atl area solid line thunderstorms
detected vicinity airport words extracting bigram patterns
would
atl approaching hxi hxi area
area atl hxi hxi solid
solid area hxi hxi line
line solid hxi hxi thunderstorms
thunderstorms line hxi hxi detected
vicinity hxi hxi
airport hxi
addition constructing n gram patterns extracting words construct
n gram patterns extracting phrases first remove articles
possessive pronouns adjectives e g beginning phrases
corpus noun phrase adjective phrase x appears corpus
create two n gram patterns extracting x preceding n words hxi b
hxi succeeding n words example sentence last legs
approaching end hour duty day hour hard time flying day would
extract following phrases following bigram patterns
legs last hxi hxi approaching
end approaching hxi hxi


fiabedin ng khan

hour duty day end hxi hxi
hour hard time flying day day hxi
thus use three types patterns experiments bigram patterns extracting
words bigram patterns extracting phrases parse tree subject verb verbobject patterns patterns generated reports corpus generated
combining narratives unlabeled reports described section
see three types patterns beneficial use far performance
concerned section automatically select best subset
patterns use development set

semantic lexicon approaches cause identification
asrs reports
investigate heuristic learning cause identification exploit information provided automatically acquired semantic
lexicon section describes details two approaches
heuristic
heuristic operates essentially way baseline cause
identification system described section occurrence heuristic used label
report shaping factors difference words phrases used
occurrence heuristic baseline manually identified whereas
heuristic acquired modified basilisk procedure
learning
learning cause identification recast classification task note multi class multi labeled classification task
classes report labeled one class number approaches
proposed tackle multi class multi labeled classification tasks rest
section describe three existing approaches multi class multi labeled text classification explore experiments section provide overview
theory support vector machines svms underlying learning use
train classifiers employed three approaches section
three approaches multi class multi labeled text classification
one versus train one binary classifier shaping factor
sk determine whether report labeled sk specifically follow
one versus classification scheme given sk reports training set
contains sk set labels assigned annotator positive instances
binary classifier rest reports training set negative instances
training apply classifiers report test set independently
reports label report sk corresponding classifier classifies


ficause identification via weakly supervised semantic lexicon construction

report positive thus convert cause identification multi class multi labeled
document classification task
learning used principle train classifiers oneversus scheme use support vector machines training testing classifiers
primarily due successes text classification tasks classifier trained
two types features unigrams bigrams report narratives
words phrases semantic lexicon feature values tf idf values
shaping factor labeled data set reports substantially larger
set reports annotated nasa researchers see section arguably fairly
small machine learning perspective hence conceivable performance
svm classifiers would limited small size training data
investigate whether improve one versus transductive
svm version inductive svm described attempts improve
classifier performance combining labeled unlabeled data see section
overview transductive learning cause identification task unlabeled
reports test set serve unlabeled data transductive learning procedure
metalabeler second employ metalabeler tang rajan narayanan
classifying multi class multi labeled text data model first learned
predicts number labels instance may addition set binary classifier one possible label learned predict likelihood label
instance instance classified first model predicts k number
possible labels instance output second set classifiers k
labels chosen highest likelihood instance
implementation first model learned svmmulticlass
implementation multi class svm described crammer singer
second set classifiers set described section case
given instance x decision functions f x w x b classifiers
evaluated positive decision values sorted top k labels corresponding
highest values decision functions assigned instance
multiclass classifier set binary classifiers trained types
features one versus namely unigrams bigrams reports
words phrases semantic lexicon feature values
one versus namely tf idf values
ensembles pruned sets pruned sets read pfahringer holmes
multi class multi label text classification transformed multiclass single label text classification selecting subset label combinations
frequently occurring dataset assigning unique pseudo label chosen
label combination
first step choose label sets training step
label sets chosen meet minimum frequency requirement training
set minimum frequency constraint prunes away infrequently occurring label sets
frequency less p leaving label combinations frequent thus
implemented svmlight software package joachims
available http svmlight joachims org svm multiclass html



fiabedin ng khan

important training instances labeled pruned label sets
removed training set minimum cardinality parameter b used
reintroduce pruned instances back training set order minimize
information loss pruning process first label sets rejected instances
broken smaller subsets least size b subsets
frequency higher p reintroduced pruned training instances whose label
sets supersets newly accepted label sets reinstated training set
role parameter b case ensure many instances small
label sets put back cause average number labels reduce
resulting smaller number labels per instance classification time
next step learn classifiers selected label sets first accepted label
set assigned unique pseudo label thus transforming multi label classification single label classification ensemble classifiers learned
predict pseudo labels given instance multi class svm implementation metalabeler classifier ensemble trained different
random sample training data since label sets training classifiers
represent subset label combinations present original training data
test data may contain label combinations present training
data ensemble classifiers allows system generate label combinations
observed training time example let label combinations l l l l
present training data one classifier ensemble labels test instance
l l another classifier ensemble labels instance l l
instance may labeled l l l depending actual voting policy
effect classification time even combination present training data
classifiers ensemble built two types features one versusall namely unigrams bigrams reports words phrases
semantic lexicon learned modified basilisk framework
finally classifying instance classifiers assigns one pseudo label
instance pseudo labels mapped back original label combination
vote actual label counted normalized dividing number
classifiers order bring prediction possible label range
threshold used label prediction value
greater equal assigned instance scheme used make possible
assign label combinations unseen training time test instances
overview support vector machines
svms shown effective text classification joachims
describe two versions svms inductive svms learn classifier solely
labeled data transductive svms learn classifier labeled
unlabeled data
inductive svms given training set consisting data points belonging two classes
inductive svm aims separating hyperplane maximizes distance
separating hyperplane nearest data points nearest data points act
support vectors plane


ficause identification via weakly supervised semantic lexicon construction

formally let data set data points
xi ci xi rn ci



point xi represented n dimensional vector associated class label
ci inductive svm classifier attempts hyperplane w x b
maximum distance nearest data points opposite labels hyperplane would
middle two hyperplanes containing support vectors class

therefore
two hyperplanes wxb wxb distance w
desired separating hyperplane found solving following quadratic programming
optimization
minimize
subject


w

ci w xi b



however practice many classes linearly separable handle cases set
slack variables used represent misclassification point xi
becomes
x

w c

minimize



subject

ci w xi b



additional variables representing training errors c constant representing trade training error margin details found cortes
vapnik experiments use radial basis function rbf
kernel




every dot product replaced function k x x exp x x
addition c chosen cross validation training set
transductive svms transductive setting addition set labeled data
points exploit set unlabeled data points xi xi rn k
taken test set described joachims goal minimize
expected number classification errors test set expected error rate
defined vapnik follows
z
x

hl xi ci dp x c dp xk ck
r l
k


l hl hypothesis learned l b zero b
one otherwise labeling ci test data hyperplane maximizes
separations training testing positive negative instances found solving
following quadratic programming optimization modified version
eqn
x
x

j
w c
c
minimize



subject

j

ci w xi b

cj w xj b j j j k




fiabedin ng khan

similar inductive svm section use rbf kernel experiments
involving transductive svm

evaluation
goal evaluation study effectiveness two approaches cause identification namely semantic lexicon learning classification
testing performance approaches randomly chosen set reports
manually annotated shaping factors caused incidents described section start describing experimental setup section
followed baseline section performance two approaches
sections describe experiment increase amount
training data available classification investigate impacts
performance section perform analysis errors bestperforming section conduct additional experiments attempt
gain better insight cause identification task help direct future
section finally present summary major conclusions draw
experiments section
experimental setup
described section reports entire corpus manually
annotated incident reports shaping factors used first
manually extract initial seed words phrases semantic lexicon
learning procedure train classifiers identifying shaping factors associated
report remaining reports used reports test data reports
development data parameter tuning
evaluation metrics
mentioned section shaping factors report may labeled
one shaping factors evaluate performance cause
identification approaches well automatic annotations match human
annotations reports test set evaluation use precision recall
f measure computed described sebastiani specifically
shaping factor si let ni number reports test set
human annotator labeled si e number true si labeled reports test
set let pi number reports automatic labeling scheme ci
labeled si let tpi number reports ci labeled correctly si
shaping factor si following performance metrics
precisioni fraction reports really caused shaping factor si among
reports labeled si labeling scheme
p recisioni



tpi
pi

ficause identification via weakly supervised semantic lexicon construction

recalli percentage reports really caused shaping factor si labeled
labeling scheme shaping factor si
recalli

tpi
ni

thus obtain measure labeling schemes performance shaping
factors obtain overall performance labeling scheme sum counts
e ni pi tpi shaping factors compute micro averaged precision
recall f measure aggregated counts described sebastiani repeated
follows
p
tpi
p recision pi
pi
pi
tpi
recall pi
ni
p recision recall
f measure
p recision recall
thus labeling scheme one set overall scores reflecting performance
classes
statistical significance tests
determine whether labeling scheme better another apply two statistical
significance tests mcnemars test everitt dietterich stratified approximate randomization test noreen test whether difference performances really statistically significant mcnemars test compares two labeling schemes
basis errors e whether labeling schemes making mistakes stratified approximate randomization test compares labeling schemes
f measure tests extensively used machine learning nlp literature particular stratified approximate randomization standard significance test
employed organizers message understanding conferences determine
difference f measure scores achieved two information extraction systems significant see chinchor chinchor hirschman lewis since ultimately
concerned difference f measure scores two labeling schemes cause
identification discussion statistical significance rest section focused solely stratified approximate randomization test tests determine
significance level p
baseline system
recall use baseline heuristic method described section
occurrence heuristic used label report seed words phrases manually
extracted training reports shown experiment section
table reported terms precision p recall r f measure f last
two columns whether particular automatic labeling scheme significantly better


fiabedin ng khan

baseline respect mcnemars test mn stratified approximate randomization test ar statistical significance insignificance denoted x
x respectively evaluated reports test set baseline achieves
precision recall f measure
table report labeling performance different methods
feature set
p
r
f mn
ar
experiment baseline
heuristic seed words
n n
experiment semantic lexicon
lexicon modified basilisk

x
x
heuristic
lexicon original basilisk

x
x
experiment supervised one versus classification
unigrams

x
x
unigrams bigrams

x
x
svm
lexicon words

x
x
unigrams lexicon words

x
x
unigrams bigrams lexicon words
x
x
experiment transductive one versus classification
unigrams

x
x
unigrams bigrams

x
x
svm
lexicon modified basilisk

x
x
unigrams lexicon words

x
x
unigrams bigrams lexicon words
x
x
experiment metalabeler
unigrams

x
x
unigrams bigrams

x
x
svm
lexicon words

x
x
unigrams lexicon words

x
x
unigrams bigrams lexicon words
x
x
experiment ensembles pruned sets
unigrams

x
x
unigrams bigrams

x
x
svm
lexicon modified basilisk

x
x
unigrams lexicon words

x
x
unigrams bigrams lexicon words
x
x
experiment additional training data fold cross validation
unigrams

x
x
unigrams bigrams

x
x
svm
lexicon words

x
x
unigrams lexicon words

x
x
unigrams bigrams lexicon words
x
x



ficause identification via weakly supervised semantic lexicon construction

experiments semantic lexicon
recall semantic lexicon learning label report test set
occurrence heuristic combination semantic lexicon learned modified
basilisk framework described section showing
first describe tune parameters modified basilisk framework
parameters
modified basilisk framework five parameters tune first four thresholds resulting four frequency constraints involving minimum support
maximum generality see modification section specifically four
threshold parameters minimum frequency word inw maximum frequency word axw minimum frequency pattern inp
maximum number words extracted pattern axp addition recall
section three types patterns namely subject verb verb object patterns bigram patterns extracting words bigram patterns extracting phrases
fifth parameter pattern parameter determines subset
three types patterns use goal tune five parameters jointly
development set words want parameter combination yields
best f measure occurrence heuristic used label reports development set however maintain computational tractability need limit number
values parameter take specifically limit five different combinations four threshold parameters see table combination
subset three types patterns yields best f measure development set hence total number experiments need run number
non empty subsets three types patterns number combinations
first four parameters experiment indicates combination table
together bigram patterns extracting phrases yields best f measure
development set therefore chosen best parameter combination involving
five parameters
words phrases acquired first two iterations modified basilisk
parameter combination shown appendix b see
words acquired first two iterations eight categories reasons
unlike original basilisk framework modified basilisk employs common
word pool thus longer requiring five words must added category
bootstrapping iteration application minimum support words led
filtering infrequently extracted words two reasons together ensure
modified basilisk framework focuses learning high precision words category

semantic lexicon learned best parameter combination performance development set used label reports test set see
row experiment table modified basilisk achieves precision
recall f measure comparison baseline
method lower precision higher recall increased recall shows


fiabedin ng khan

table combinations four threshold parameters modified basilisk framework
combination
combination
combination
combination
combination
combination







inw






axw






inp






axp






reports covered expanded lexicon however learned lexicon contains
general words resulted drop precision overall higher fmeasure statistically significantly better baseline according
significance tests vindicates premise learning words phrases
relevant shaping factors help us identify shaping factors reports
original basilisk
better understand whether proposed linguistic algorithmic modifications
basilisk framework see section indeed beneficial cause identification
task repeated experiment described except replaced lexicon
generated modified basilisk framework one generated original
basilisk framework specifically implemented original basilisk framework
described thelen riloff one minor difference case
bigram patterns extracting phrases word pools described section populated
entire phrases instead head words done seed words list
extracted section contains words phrases hence would learn
entire phrases
parameter tune original basilisk framework pattern parameter
mentioned determines subset three types patterns use
therefore construct seven lexicons corresponding seven non empty subsets
three types patterns original basilisk framework determine
lexicon yields best performance development set experiment indicates
best development achieved bigram patterns extracting
phrases used applying corresponding semantic lexicon combination
occurrence heuristic classify reports test set observe precision
recall f measure see row experiment section
table lower precision higher recall indicates lexicon learned
words general e words appear many reports little
discriminative power words phrases acquired first two iterations
original basilisk shown appendix c seen original basilisk framework
adds lot words many relevant shaping factors
added semantically similar seed words shaping factor


ficause identification via weakly supervised semantic lexicon construction

hence although recall improves small amount precision drops significantly leading
precipitation f measure suggest proposed modifications
original basilisk framework indeed beneficial far cause identification task
concerned
experiments classification
recall classification cause identification train svm classifier
shaping factor sk determine whether report labeled sk desired
allows report test set potentially receive multiple labels since
resulting svm classifiers applied independently report investigate
effect different feature sets performance cause identification employ five
feature sets experiments unigrams unigrams bigrams lexicon
words unigrams lexicon words unigrams bigrams lexicon words
unigrams bigrams generated reports training set first
removing stop words ignoring case information semantic lexicon
one constructed modified basilisk framework showing
supervised transductive experiments first describe parameters associated
classification
parameters
svm classifier two parameters tune first parameter
percentage features use feature selection shown improve performance
text classification tasks yang pedersen employ information
gain ig one effective methods feature selection according yang
pedersens experimental since assume words semantic lexicon
relevant cause identification apply feature selection lexicon words
rather apply feature selection unigrams bigrams specifically
unigrams used features first five feature sets mentioned
beginning subsection select n unigrams highest ig
value n tuned development set unigrams bigrams used
features second fifth feature sets combine unigrams bigrams
one feature set select n unigrams bigrams highest ig
value n tuned development set experiments tested
values n
second parameter associated svm classifiers classification threshold
default svm sets classification threshold meaning every data point
classification value classified positive rest classified
negative however since svm classifier trained optimize classification accuracy
best classification threshold may cause identification task
goal optimize f measure parameterize classification threshold
allowing take one values
usual tune two parameters described jointly rather independently
words possible value combination percentages features


fiabedin ng khan

classification threshold compute f measure classifiers development set
classes choose value pair yields maximum f measure
get better idea two parameters impact performance
figure f measure changes development set vary values
two parameters experiment underlying svm classifiers employ
unigrams features see best f measure achieved employing
top unigrams classification threshold default parameter values
feature selection classification threshold yields f measure approximately
overall provide suggestive evidence parameters
large impact performance
f measure vs classification threshold
different percentages unigram features

top unigrams
top unigrams
top unigrams
top unigrams
top unigrams
top unigrams
top unigrams
top unigrams
top unigrams
top unigrams




f measure


















classification threshold







figure variation f measure different percentages unigram features classification thresholds used svm classification

supervised one versus classifiers discussions
supervised one versus classification five feature sets
described shown experiment section table see
feature sets unigrams unigrams lexicon words used achieve
best f measure scores respectively however even
best statistically indistinguishable baseline according
approximate randomization test significantly worse produced
recall supervised svm classifiers trained reports
training set



ficause identification via weakly supervised semantic lexicon construction

modified basilisk row experiment see appendix contains
statistical significance test obtained applying stratified approximate randomization test pair experiments table
fact indicate occurrence heuristic made effective use
learned semantic lexicon svm classifiers svm classifiers trained
lexicon words features row experiment produced significantly worse
f measure score occurrence heuristic due large
drops recall precision overall suggest supervised performs worse heuristic semantic lexicon task
hypothesize limited amount training data available svm learner contributed poor performance supervised test hypothesis
section
two additional observations worth mentioning first comparing rows
experiment see lexicon words useful cause identification
presence unigrams second comparing rows rows experiment
see bigrams hurts performance likely reason attributed
feature selection method since choose top n features bigram features
significantly outnumber unigram features thus potentially diminishing effect
latter one solution employ separate parameters selecting
unigrams bigrams decided choice would lead explosion
size parameter space
transductive one versus classifiers discussions
investigate whether useful exploit unlabeled data employ transductive svm
combine labeled unlabeled data essentially repeated experiments
supervised one versus classification except trained transductive
svm classifier labeled reports training set unlabeled
reports test set described section two parameters percentage
features used classification threshold tuned jointly maximize f measure
development set described supervised except transductive
svms used parameter tuning step trained training set labeled data
development set unlabeled data
transductive svm classifiers shown experiment section
table overall transductive significantly worse corresponding
experiment however conclusions draw transductive
slightly different drawn supervised first
bigrams significantly improves performance lexicon words absent comparing
rows experiment hurts performance lexicon words present
comparing rows second adding lexicon words unigram feature
set comparing rows significantly improves performance suggesting potential
usefulness lexicon features nevertheless experiments indicate
lexicon words features far adequate best performance
achieved lexicon words added unigrams features


fiabedin ng khan

additional supervised approaches
next present two additional supervised approaches namely metalabeler ensembles pruned sets section feature sets used
approaches used one versus method oneversus method approaches use svm underlying learning
classifier training
metalabeler parameter needs tuned metalabeler
percentage features use n selected classification performance f measure development set
metalabeler shown experiment section table interesting points first metalabeler
method much better precision methods second method
shows consistent performance improvement bigram features added seen
comparing first second fourth fifth rows metalabeler
third inclusion lexicon word features found improve performance
seen comparing first fourth second fifth rows metalabeler
two observations metalabeler properly take
advantage increasingly richer feature sets used experiments best
performance occurring types features used fifth row unfortunately
suffers poor recall fact prevents even matching let alone
surpassing f measure scores methods since method discards less
probable labels assigns labels documents precision much improved
recall suffers
ensembles pruned set among parameters ensembles pruned sets
number classifiers ensemble size sample
training data classifier ensemble trained chosen
ones used read et al namely respectively rest
parameters pruned set namely minimum cardinality b minimum
support p percentage features use n threshold label assignment
selected jointly classification performance f measure development
set values specific value b chosen possible
values p tested experiment threshold parameter chosen
values percentage features n chosen
values thus parameter combinations feature set
parameter combinations combination performance
development test set best terms f measure chosen running system
test set
pruned set shown experiment section table
see best performance combination unigram lexicon word features
better performance unigrams lexicon words individually however
performance degraded inclusion bigrams combination precision
much lower methods indicates selection label
sets training set reports may adequate


ficause identification via weakly supervised semantic lexicon construction

experiments additional training data
experiments somewhat surprising best performing supervised classification one versus performs significantly worse
modified basilisk hypothesize poor performance attributed scarcity labeled training data test hypothesis conducted
set experiments increased amount training data one versus
supervised classification applying cross validation specifically take
test set reports split five disjoint subsets equal size
construct training set merging tj j
original training set reports train svm classifier merged
training set test set ti done five folds compute
f measure entire test set words report set
experiments f measure scores averaged five folds experimented
five set features used supervised experiments section two
parameters percentage features used classification threshold tuned
exactly way supervised experiments
set experiments shown experiment section table
comparison experiment f measure increases uniformly significantly
provides empirical evidence performance supervised classifiers limited
amount data trained feature sets unigrams
lexicon words unigrams bigrams lexicon words achieve best
f measure scores respectively difference
statistically insignificant two turn significantly better
modified basilisk row experiment according approximate randomization
test addition except feature set lexicon words obtained
experiment significantly better baseline according approximate
randomization test overall suggest difficulty cause identification
task comparing rows experiments see f measure increases
number training reports increased
points deserve mentioning previous learning experiments lexicon words features yields worst set experiments
combining unigrams lexicon words still yields one best nevertheless
comparison experiment bigrams still improve performance
hurt performance statistical significance point view perhaps
importantly comparing rows experiment see augmenting unigrams
lexicon words yields significantly better performance indicates lexicon
words indeed useful features cause identification usefulness may
revealed small labeled training set used seen experiment learning attempt learn features important relevant given classification
task training examples see training examples
better able learn relevance features
poignant illustration phenomenon svm learner able use lexicon word
features effectively given large number training instances seen
clearly svm learning curves section indicates lexicon


fiabedin ng khan

words useful features sufficiently large training data however
lexicon words may still used effectively ways linguistic features even
training set small see experiment uses
lexicon words combination occurrence heuristic achieve performances
statistically significantly better baseline
error analysis lessons learned
order gain clearer insight cause identification help direct
future manually analyzed errors made best performing system e
heuristic semantic lexicon learned modified basilisk
framework randomly chosen report subset test set specifically
looked false negatives cases annotator labeled report shaping
factor system false positives cases system labeled
report shaping factor annotator false negative tried
determine system failed correctly label report false positive
tried determine system labeled report erroneously table shows
number false positives false negatives along reasons errors
discovered analysis following sections discuss errors reasons
detail note since shaping factor may indicated one keyword
single report one reason false negative positive error
thus sum frequencies different types false negative positive errors greater
total number false negatives positives
table error analysis details different reasons false positive false negative
errors
false negatives
sentence fragments bigger phrases
implicit causes cannot identified keywords
phrases learned
false positives
keyword general
keyword indicates concept appears report
contribute incident
wrongly learned keyword
keyword used negative context
keyword used hypothetical context









percentage















false negatives false negative error read report narrative identify
word phrase sentence fragment may indicate shaping factor
system missed analysis identified three reasons false negatives
follows


ficause identification via weakly supervised semantic lexicon construction

required sentence fragments larger phrase identified sentence
fragments bigger phrases e consist two phrases
example sentence fragment never dca consists
phrases never dca together convey meaning
reporter unfamiliar dca possible identify single
word phrase conveys meaning since framework learns
phrases possible learn sentence fragments
cause identifiable specific words phrases instances specific
word phrase sentence fragment could identified could pinpoint shaping
factors responsible incident example number reports including
report describe incidents miscommunication
pilot air traffic controller miscommunication must understood
following conversation human reading report easily understand
pilot claiming controller said one thing controller claiming
said something different detect kind scenario machine would need
generate complete model discourse identifies specific topic
conversation participants claims participant makes topic
fact claims contradictory fact contradiction arises
miscommunication preprocessed narrative report
shown appendix e
missing phrases cases necessary phrase missing semantic
lexicon learned modified basilisk framework phrases six
phrases infrequent considered modified basilisk framework due
minimum frequency criterion example phrase temperature flux
appears entire corpus hence considered system
two phrases verb phrases could learned focused
learning noun phrases adjective phrases four phrases
semantically similar seed word shaping factors example
phrase garbled transmission semantically similar seed word
shaping factor communication environment disturbance static radio
discipline congestion noise finally two phrases
learned system learned time put
word pool words higher scores selected instead
false positives case false positives looked report narrative
keyword found content determine indication shaping
factor incident described report incorrect different reasons
identified follows
general keywords observed large number false positives due
keywords general e keywords extracted learned
shaping factor may appear phrases related shaping
factor example keyword failure correct indicator resource deficiency
appears text complete electrical failure alternator failure etc
appears text failure follow air traffic control instructions


fiabedin ng khan

indicate resource deficiency shaping factor identified cases
caused keywords general
concept present contributing incident another frequently faced
sometimes concepts identified keywords present
report act shaper incident described report
example report reporter mentions flying solo
indication taskload incident due physical environments namely
snow foggy weather fact flying solo merely mentioned
part description overall situation preprocessed version report
given appendix e total observed cases
incorrectly learned words phrases six cases semantic lexicon learner learned incorrect words phrases related
shaping factors assigned example framework incorrectly learned word shaping factor resource deficiency thus
number reports mislabeled resource deficiency
negative context three cases keyword appeared
negative context typically signaled contextual valence shifter
hardly polanyi zaenen example keyword aircraft damage indicator resource deficiency appears report apparent
aircraft damage false positive
hypothetical context one case keyword appeared
hypothetical context reporter conjectures possible scenario
keyword single pilot indicator taskload appeared report
could happen pilot especially single pilot resulting false positive
lessons learned error analysis provides valuable insight nature
well hints one proceed order improve performance
system analyzing frequent errors present following lessons
learned analysis first useful learn high precision keywords
phrases general ones largest part false positive errors attributed
general keywords however high precision keywords phrases
likely low frequencies hence one would adapt learning methods
learn useful words phrases infrequent ones second one must take account
fact relevant portions text may larger phrases even going
clause sentences cannot identified learning words phrases n grams
reasonable size thus robust methods needed learn useful sentence
fragments useful sentence structures finally cases one cannot hope
identify methods look keywords phrases sentence fragments even sentence
structures e cases cause incident understood
discourse cases concept present description yet plays part
incident much deeper analysis simple bag anything needed
avoiding two types errors represent almost one third
errors analyzed subset former needs method distinguish relevant


ficause identification via weakly supervised semantic lexicon construction

sentences irrelevant ones example patwardhan riloff discuss relevant
sentence classifier trained small set seed patterns set documents
marked relevant irrelevant useful context latter
requires discourse analysis method discussed earlier model conversations
identify relations correctly shows though possible identify shaping
factors reports words phrases certain extent much deeper natural
language techniques needed accurately identify full range causes
additional analyses
section present outcomes number additional analyses performed
cause identification task approaches task section study
relative difficulties classifying different shaping factors sections
learning curves semantic lexicon learning
respectively e performances two approaches vary
provided different amounts training data finally section discuss
outcomes experiment conducted determine modifications basilisk
framework useful learning general semantic categories
per class
get insight classes difficult classify perform analysis
per class performance two labeling schemes best heuristic method e
occurrence heuristic lexicon learned modified basilisk framework see
first part table best learning method e fold svm classifiers
unigrams bigrams lexicon words features see second part table
conjunction table two classes stand prominently difficult classify
illusion taskload classes little representation training
test development sets small number seed words poor
performance approaches easily identifiable classes physical
environment physical factors resource deficiency preoccupation
labeling schemes f measures better general classes better
representation training testing development sets reasonable
number words phrases semantic lexicon believe difference
characteristics classes valuable insight helpful future work
lexicon learning curve
mentioned section used total seed words phrases
first glance number seeds may seem large far bootstrapping experiments
concerned however considering fact seeds distributed
shaping factors average words phrases per shaping factor
nevertheless would still interesting examine cause identification performance
affected reduce number seeds shaping factor used modified
basilisk bootstrapping process ran set experiments measure
cause identification performance uses semantic lexicon learned modified basilisk
given different number seed words parameters specific modified


fiabedin ng khan

table per class performance upper table shows per class performance
occurrence heuristic lexicon learned modified basilisk framework
lower table shows per class performance fold svm classifiers unigrams
bigrams lexicon words features

shaping factor
attitude
communication environment
duty cycle
familiarity
illusion

physical environment
physical factors
preoccupation
pressure
proficiency
resource deficiency
taskload
unexpected
overall

tp
















fn
















tn
















fp
















precision
















recall
















f measure
















shaping factor
attitude
communication environment
duty cycle
familiarity
illusion

physical environment
physical factors
preoccupation
pressure
proficiency
resource deficiency
taskload
unexpected
overall

tp
















fn
















tn
















fp
















precision
















recall
















f measure


















ficause identification via weakly supervised semantic lexicon construction

basilisk set described section specifically chose top
seed words phrases shaping factor terms frequency
entire corpus ran modified basilisk framework ten iterations
aforementioned parameters
note however shaping factors number manually selected
seed words phrases example illusion taskload unexpected
seed words phrases respectively whereas resource deficiency physical environment
respectively see last column table hence experiments
number seeds used shaping factor exceeds number manually
selected seeds shaper manually selected seeds used example since
unexpected three manually selected seeds used experiments
least three seeds used shaping factor
occurrence heuristic used lexicons thus generated evaluate
performance test set resulting learning curve terms f measure
test set reports shown figure addition since baseline
compare performance seed words baseline learning curve
corresponding reduced seed words set shown expected increasing
number seed words monotonically improves f measure however improvement
baseline particularly small fewer seven seed words used
highest improvement observed seven seed words phrases adding
seeds improves overall performance improvement baseline slowly
diminishes
lexicon learning curve




f measure






baseline
performance learned lexicon















number seeds









figure variation f measure different number seeds words per category



fiabedin ng khan

svm learning curve

f measure test set



f measure
















number training instances





figure variation f measure different number training reports

svm learning curve
discussed section hypothesize failure svm classifiers perform better baseline due scarcity training instances available
learner one may argue svm shown work well small datasets
natural question much smaller training set see
statistically significant drop cause identification performance answer question
plot learning curve one versus classification features
combination unigrams bigrams lexicon word features five fold cross validation
setting setting yields best performance table specifically
generated random subsets training sets sizes instances parameters namely percentage features classification threshold chosen
way original experiment described section f measure
evaluated entire test set curve shown figure data point
computed averaging five independent runs see
general trend performance improvement increase number training
instances addition trained training set see cause
identification system started perform statistically significantly worse system
trained available instances according stratified approximate
randomization test


ficause identification via weakly supervised semantic lexicon construction

general usefulness modifications basilisk
order test whether modifications made basilisk framework useful
lexicon learning general added two general categories shaping factors
bootstrapping experiments namely people equipment two categories
added firstly words phrases added categories would easy verify
e whether words phrases representing people equipment secondly
similar original context basilisk framework originally evaluated e learning words categories building event human location
time weapon terrorism reports two additional categories added
seed lexicon described section bootstrapped running original basilisk modified basilisk separately ten iterations parameters specific
basilisk frameworks set way described section seed
words two categories selected manner done thelen
riloff e phrases corpus sorted frequency five
frequent phrases belonging categories manually identified seed
words used two categories
people captain controller first officer rptr passenger
equipment aircraft airplane collision avoidance system ii engine auto pilot
order verify words phrases learned two frameworks correctly
belong assigned category first author computer science graduate student
affiliated went generated lexicons appendices f g
lexicons generated original basilisk modified basilisk respectively
facilitate analysis divide words phrases generated lexicon three
categories determined correct human judges
determined correct one judge determined incorrect
judges
lexicon generated original basilisk category people
words phrases determined correct judges determined
exactly one judges correct category equipment words
phrases correct according judges correct according exactly one
judges hand lexicon generated modified basilisk
category people words phrases determined correct
judges determined exactly one judges correct category
equipment words phrases correct according judges
correct according exactly one judges comparison clearly shows
modifications made basilisk framework specific particular
task rather modifications improved lexicon building performance general
summary conclusions
end section providing summary major conclusions draw
experiments


fiabedin ng khan

heuristic cause identification labels report occurrence heuristic combination words phrases automatically acquired
modified basilisk framework surpasses performance baseline system applies occurrence heuristic combination seed words
phrases manually identified training documents difference f measure
two systems statistically significant according mcnemars test
stratified approximate randomization test suggests words
phrases semantic lexicon learned via modified basilisk relevant effective
cause identification
adding learned lexicon words n gram feature set training svm
classifiers beneficial cause identification training set sufficiently
large exhibited statistically significant increase f measure provides
suggestive evidence words phrases semantic lexicon learned via
modified basilisk relevant useful features cause identification
used combination occurrence heuristic semantic lexicon learned
modified basilisk framework offers significantly better performance
cause identification task one obtained original basilisk framework additional experiments reveal modified basilisk useful
cause identification offers performance superior original basilisk
bootstrapping general semantic categories people equipment
among three multi class multi labeled text classification approaches experimented one versus works significantly better metalabeler pruned
sets cause identification transductive learning used combination
one versus significantly hurts performance suggesting unlabeled data cannot profitably exploited given fairly small amount labeled
data
best system achieves f measure around indicates cause
identification difficult task lot room improvement
provide directions future performed analysis errors made
best performing system particular found performance currently
limited part several factors first number cases
relevant text indicating responsible shaping factor may larger phrases
second indicators shaping factor may mentioned report without influencing incident described report finally cases
shaping factors cannot identified simply looking words phrases even
sentence fragments much deeper analysis required cases
increasing number seed words phrases employed modified basilisk improves cause identification performance marginal performance improvement
added seed diminishes successive additions words
seem suggest seed words unlikely improve much
current performance rather would promising start small number
high frequency seeds improve upon bootstrapping process


ficause identification via weakly supervised semantic lexicon construction

learning curve plotted one versus classification shows
cause identification performance increases number training instances
particular trained training set see resulting cause
identification system performs statistically significantly worse one trained
available instances
overall approaches rely automatically learned lexicon words phrases
adequate cause identification relevant task mentioned previously use motivated labor intensive procedure nasa
researchers employed manually identifying seed words phrases shaping factor posse et al work represents one first attempts tackle cause
identification task believe use simple features good starting point
establishes baseline future studies compared
main take home message though possible solve
set solve namely automated cause identification learning
relevant keywords sentence fragments suitable bag words
remains significant portion data remains unlabeled mislabeled
methods match performance level achieved topical text classification
tasks much deeper linguistic analysis relevant sentence detection discourse analysis
methods identifying disagreements disputes hostile attitudes needed
lesson cornerstone area

related work
section describe works related particular
discussion focuses causal analysis well approaches semantic lexicon construction text classification organized follows first discuss causal analysis
appeared different fields second discuss different semantic lexicon
learning third discuss works deal extraction pattern learning
fourth describe different unsupervised word clustering thesaurus
building finally include discussion related work multi class multi labeled text
classification
causal analysis major causality performed mainly fields
philosophy psychology field philosophy seminal works causality
conducted hume provides one influential definitions
cause object followed another objects similar first
followed objects similar second words first object
second never existed basis later much stronger
definitions causation e g lewis ganeri noordhof ramachandran
notable investigations causation field psychology include cheng
defines causation terms probabilistic contrast model griffiths tenenbaum
discuss learning cause effect relationships causal graphical
halpern pearl provide explanations causality means
structural equations governing random variables representing events although


fiabedin ng khan

works provide important background definitions contributing understanding
causality order identify causes naturally written text must turn nlp
field nlp little work cause identification similar
causality focuses mainly identifying causal relations two sentence
components instance girju describes method automatically discovering
lexico semantic patterns refer causation particular focuses explicit
intra sentential pattern hn p verb n p verb simple causative shows
patterns used improve performance system answering
cause effect type questions khoo et al use graphical pattern matching identify
causal relations medical article abstracts use hand crafted patterns
matched parse trees sentences subtrees parse tree match
patterns extracted causes effects similarly garcia uses hand crafted
extraction patterns identify causal relations sentences french language
limitation approaches focus identifying causal relations
sentence whereas reports multi sentence discourses
grishman ksiezyk use domain modeling discourse analysis causal inference cause effect relations events leading equipment malfunctions
short equipment failure reports specifically first apply syntactic analysis
produce parse trees sentences reports augmented context free
grammar apply semantic analysis map verbs syntactic relations
domain specific predicates relations noun phrases references components
domain model finally apply discourse analysis predicates construct
time graph showing temporal causal relationships elementary facts
temporal relations derived text structures words e g
etc order appearance text causal relations determined querying simulation model equipment built domain knowledge specifically
possible causal link posed query model test relation holds
overall method relies heavily domain model equipment studied
focuses one specific piece equipment
nasas identifying causes incidents report narratives
performed posse et al describe specific experiment
brought together experts manually analyze report narratives identify words
phrases expressions related shaping factors mentioned earlier later
work ferryman et al take manually extracted expressions ground truth
compare anomalies described reports shaping factors derived
applying expressions reports specifically attempt learn
expressions automatically rather focus finding possible correlations
shaping factors anomalies
semantic lexicon learning number semantic lexicon learning
follow iterative bootstrapping starting small number
semantically labeled seed words roark charniak propose method constructing semantic lexicons co occurrence statistics nouns conjunctions lists
appositives start small seed nouns list iteratively add similar words
list word similarity measured ratio many times word occur


ficause identification via weakly supervised semantic lexicon construction

together seed word number times word appear corpus
construction rank words log likelihood statistic dunning however
due general brevity reports co occurrences lists rather
corpus useful us use context similarities thelen riloff
describe basilisk framework learning semantic lexicon extraction patterns features apply weakly supervised bootstrapping
start small manually constructed seed lexicon iteratively add semantically
similar words described detail section basis
lexicon learning
number improvements basilisk framework generally bootstrapping approaches proposed basilisk framework number iterations
parameter chosen arbitrarily rather making arbitrary choice
yangarber proposes method detecting termination unsupervised semantic
pattern learning processes method requires documents must labeled
relevant irrelevant since information available corpus useful us curran murphy scholz suggest improvement traditional
bootstrapping methods discarding words contexts appear related
one category order minimize semantic drift enforce mutual exclusion
hand handle cases comparing conditional probabilities
different categories words belong zhang zhou huang wu
present bootstrapping graph mutual reinforcement bootstrapping gmr
hassan hassan emam modification basilisk method similar us
explore n grams capture context use different set pattern
word scoring formulas learning multiple categories simultaneously introduce
scoring system entropy pattern report better basilisk
muc dataset see sundheim
among non bootstrapping approaches ando presents method constructing semantic lexicons unannotated corpus set semantic classes set
seed words phrases semantic class uses spectral analysis improve
feature vectors projecting useful portions vectors subspace removing harmful portions vectors resultant feature vectors used
centroid classifier cosine similarity measure label words avancini
lavelli sebastiani zanoli take classification semantic lexicon
construction cast term meaning words phrases categorization task dual document categorization task similar bag word
model represent terms bag documents use variation adaptive
boosting adaboost h kr trained small seed lexicon
used classify noun terms corpus zero one semantic categories
learning extraction patterns semantic lexicon construction uses extraction patterns features present methods aim
improve extraction pattern collection process riloff describes autoslog ts
system learns extraction patterns untagged text however needs pre classified
corpus text classified relevant irrelevant mentioned earlier
access information phillips riloff present method boot

fiabedin ng khan

strapping learn role identifying nouns used learn important
extraction patterns role identifying expressions however focus mainly
identifying roles words events
patwardhan riloff provide another extraction pattern learning
relevant regions require documents pre classified relevant
irrelevant documents small set seed patterns classify sentences
documents relevant irrelevant sentences semantically appropriate extraction patterns learned semantic affinity metric separated primary
secondary patterns directly usable us due unavailability
documents pre classified relevant irrelevant categories
recently internet increasingly used natural language patwardhan riloff use autoslog ts system riloff learn domain specific
extraction patterns processing documents retrieved querying web selected
domain specific words web interesting promising enhancement
mentioned section intend extend work google corpus brants
franz
thesaurus building unsupervised word clustering another
area closely related semantic lexicon learning thesaurus building
building thesaurus requires discovering groups semantically similar words though
stops short assigning semantic class labels words thus shares
measuring semantic similarity grouping similar words semantic lexicon building
task discuss several approaches thesaurus building task
clustering used extensively thesaurus building mostly unsupervised nature ability handle large volumes data seminal work
direction pereira tishby lee present unsupervised method
soft clustering words distributions words different contexts generates overlapping word clusters grouping words contexts
appear baker mccallum use pereira et al distributional clustering technique perform feature space reduction supervised classification nave bayes
clusters features lin pantel present generating
collection sets semantically similar words concepts clustering method
unicon dependency relations features pantel lin present another
clustering clustering committee contextual features point wise
mutual information feature values compare better lin pantels
rohwer freitag present clustering automatic thesaurus building
process unannotated corpus propose information theoretic co clustering
groups together highly frequent words clusters similar part speech
category pursue additional process lexicon optimization grow lexicon
assigning less frequent words likely clusters
among non cluster methods davidov rappoport present unsupervised method discovering groups words similar meanings achieve
identifying high frequency words content words identifying symmetric
lexical relationship patterns applying graph clique set generate word
categories co occurrence information content words symmetric patterns


ficause identification via weakly supervised semantic lexicon construction

concentrating performance issues plague attempts build thesaurus
large corpus rychly kilgarriff present two methods improving performance
general context thesaurus building first method compare
word pairs context common second method use
heuristic removing contexts general e contexts
certain number distinct words adopted second method
see section applied partitioned sequential construction
process though thesaurus building usually require annotated corpus set
seed words phrases directly applicable task growing semantic
lexicon learn words specific semantic categories
method control words learned classes discovered
word groups belong may possible adapt method semantic lexicon
growing classifying word groups semantic classes seed words
phrases however method extended extract noun adjective phrases
multi class multi labeled text classification mentioned previously cause identification cast text classification multi class
multi labeled text classification since shaping factors total
document may labeled one shaping factors several
popular approaches solving multi class multi labeled text classification
first one approaches followed independently train binary
classifier class apply classifier test instance isolation
case underlying learner support vector machines joachims godbole
sarawagi suggest number improvements scheme namely including class
labels suggested preliminary set classifiers features removing negative examples
close classification hyperplane selectively removing classes
one versus others classifications scheme another notable method followed tsoumakas
vlahavas read et al treat unique set labels
label thus converting multi class single labeled one works
differ construction labels former called random
k labelsets rakel builds ensemble classifiers randomly sampling label sets
size k whereas latter adopts method filtering observed label sets minimum
support tang et al hand take different train one
classifier predicts number labels test instance would choose
many labels instance output another classifier ranks labels
likelihood instance works use svm underlying learner
addition approaches make assumption classes correlated high
degree however analysis dataset present evidence strong
correlation documents multiple labels test set unique
label sets seven frequency least five thus increasing number
labels would aggravate already imbalanced class distribution
among approaches mention two systems use probabilistic generative mccallum nigam propose system starts small set keywords
unlabeled documents learns nave bayes classifier bootstrapping process
keyword induced labels hierarchical shrinkage expectation maximization


fiabedin ng khan

held data set ueda saito present another generative model called parametric mixture treats multi labeled text parametric mixture words
relevant label work closely related latent dirichlet allocation blei
ng jordan generative usually assume document related
particular topic would high frequency words related topic
documents mostly devoted description event occurred cause
event mentioned briefly makes generative less suitable
task hand generative would likely generate related events
causes comprehensive review different approaches multi class
multi label text classification found work tsoumakas katakis

conclusions
investigated two approaches cause identification task goal
understand aviation safety incident happened via identification causes
shaping factors responsible incident approaches exploit information
provided semantic lexicon automatically constructed via thelen riloffs
basilisk framework augmented three algorithmic modifications namely
use probabilistic similarity measure use common word pool enforcement minimum support maximum generality constraints words extraction
patterns one linguistic modification use n gram extraction patterns
heuristic labels report employing occurrence heuristic
simply looks words phrases acquired semantic lexicon learning process report learning labels report employing inductive
transductive support vector machines learn reports labeled shaping factors experimental indicate heuristic
supervised learning given sufficient training data significantly outperform baseline motivated nasas work labels report simply
occurrence heuristic combination set manually identified seed words
phrases importantly heuristic indicate modifications original basilisk framework beneficial far cause identification
concerned learning indicates usefulness lexicon
words used combination unigrams features training svm
classifier overall set prove possible automate cause
identification task manually analyzing small number reports information thus generated train machine learning methods identify shaping factors
rest reports experiments able prove feasibility
usefulness learning semantic lexicon words features
nevertheless best system achieves f measure around indicates
cause identification difficult task lot room improvement
particular analysis errors made best system randomly chosen test
documents provides valuable insights task well directions future
experience current intend extend work
following directions first foremost plan extend handle text
fragments bigger phrases second order improve quality labeling


ficause identification via weakly supervised semantic lexicon construction

propose work improving lexicon learning performance different
semantic similarity measures instance would study performance
semantic similarities weighting functions suggested curran moens
context third plan use thoroughly normalized text better parsing
tagging well relevant region information ko park seo patwardhan
riloff fourth propose augment semantic lexicon specifically
google n grams corpus brants franz extract frequent n gram patterns
words fifth propose explore recent lexicon construction methods
unsupervised word clustering pantel ravichandran spectral analysis mutual
exclusion bootstrapping co clustering exploiting symmetric patterns finally order
handle shaping factors difficult identify words occurring
reports propose employ much deeper analysis text semantic level
taken step making annotated incident reports publicly available
hope stimulate investigated nlp
community

acknowledgments
authors would thank anonymous reviewers provided us comments
invaluable improving quality supported
part nasa grant nnx ac opinions findings conclusions recommendations expressed authors necessarily reflect
views official policies expressed implied nasa



fiabedin ng khan

appendix seed words
seed words manually extracted reports training set see
section details
shaping factor
attitude
communication
environment
duty cycle
familiarity
illusion

physical
environment

physical factors
preoccupation
pressure
proficiency

resource
deficiency

taskload
unexpected

seed words
get homeitis attitude inattentiveness get thereitis complacency overconfidence sarcastic inattention
disturbance static radio discipline congestion noise
hour duty day inadequate rest last legs heavy flying reduced
rest night flight hour day red eye ten leg day night
familiarization familiar first departure unfamiliar unfamiliarity familiar low time first landing
bright lights
noise abatement policy disoriented confused medical emergency
economic considerations disorientation drunk passenger confusion
cold clouds dark setting sun sun glare obscured visibility hazy
stratus birds fog bank solid overcast snow weather rime gust low
weather surface winds jet blast lightning sea gulls high ceilings
hot tailwind chop dark sea gull winds scattered high tailwinds extremely dark bright icing turbulence rpted wind
terrain bird strike crosswind thunderstorm glare reduced visibility high flying birds fog severe winter weather cloud ice
tired hypoxia tiredness tired fatigued disorientation fatigue rest
distracted preoccupied mental lapse busy distrs distraction
attention inattention absorbed
hurry running late pressure low fuel fuel considerations behind
schedule late peer pressure pressure rushing
mistakes mistaken hire inexperience forgotten less
hours newly rated training recent pilot inadvertently bad turn
misinterped
loose connection erratic blown overheated bang collapse idea
unavailable placarded crack service damage smoke inoperative failure leak deferred items communication failure loss
unreliable fdrs bump shaking master caution inadequately lighted unreadable disconnected malfunction shudder absence hazard inaccurate unflagged fire broken fluctuations
compressor stall deferral unusable wrong intermittently warning
discrepancies faulty deferred intermittent missing
single pilot solo
unexpected suddenly unforecast



ficause identification via weakly supervised semantic lexicon construction

appendix b sample lexicon words learned modified basilisk
semantic lexicon words learned modified basilisk framework
first two iterations
shaping factor
attitude
communication
environment
duty cycle
familiarity
illusion

physical
environment
physical factors
preoccupation

pressure
proficiency
resource
deficiency
taskload
unexpected

words

aligned fairly familiar
initial confusion minimum fuel emergency misunderstanding
weather emergency
trws conflict message cumulonimbus large cells numerous thunderstorms occasionally severe thunderstorm cells weather buildups
weather cell weather en route
first factor
adequate attention much attention close attention close enough
attention crew attention enough attention much attention proper
attention strict attention close attention

different amiss awry obviously wrong resulting loss seriously
wrong slight loss temporary loss terribly wrong wrong



fiabedin ng khan

appendix c sample lexicon words learned original basilisk
semantic lexicon words learned original basilisk framework first
two iterations
shaping factor
attitude

communication
environment

duty cycle

familiarity

illusion



physical
environment

physical factors

preoccupation

words
air traffic control security aileron yoke displacement anomalous vfr omni directional radio range information assured tfr
avoidance betrayal concern urgency forgetting air carrier x
magnified operational complacency unseen unknown
turbulence
noise bna runway plate lightspeed k
noise non noise overspd bell active noise clearance delivery
transmission left engine stall static emergency locator transmitter stuck trim elevator movement
plus layover different time frames back back continuous duty trips hour break minutes hour minute flight time
day pacific daylight time departure tpa flight xc departure
scheduled leg continuous duty
partial unfamiliarity perceived familiarity command familiarity command unfamiliarity blue panel indication light dispatch
work desks generally unfamiliar inexperience unfamiliarity
everyday past experience familiarity
nautical mile ssw point end feet side elmendorf required use mile downwind airspace e foxtrot
intersection lateral boundaries mile right
misinformation flight management system heading anomalies confusion conflict disoriented confused intense panic micro sleep
miss numerous times mistake inconvenience note closure
start terror
mht class celsius strato cumulus thur morning clouds underneath compacted snow ice fair weather cumulus next morning
weather puffy cumulus clouds thin scattered clouds well developed
cumulus clouds
hypoxia carbon monoxide minimum equipment list
basically tired cardiac distress indicating system internal
bleeding interrupted fuel flow oncoming seizure stress overload
upper respiratory
captain first officer attention terminal radar control facility distraction close enough attention consequently attention good enough attention lip service mind attention much
mind real attention real close attention
continued next page



ficause identification via weakly supervised semantic lexicon construction

shaping factor
pressure

proficiency

resource
deficiency

taskload

unexpected

words
minimum equipment list pressure consistent answer elevator pressure intense pressure part coordinated universal time repercussion right engine pressure significant pressure slow gear wheel
pressure
p school cl ground school basic flight training hard lesson
initial annual proficiency training occurrence strive rating
training several military flying clubs situation event time limited
simulator sessions
air traffic control loss altitude deviation loss apparently inoperative inoperative even reexamining intermittent inoperative known traffic conflict loss observed loss recently los
thankfully accurate
turboprop type aircraft aviat husky two place
tail dragger aircraft cessna type aircraft cessna model
type aircraft l lga mht flight mcdonnell douglas
md solo cross country flts solo cross country privileges
significant jolt approximately sec choppy aircraft consistently moderate contributing workload factor industry issue
severe rapid immediate real cushion



fiabedin ng khan

appendix additional stratified approximate randomization tests

mlw

olw

svm u

svm ub

svm l

svm ul

svm ubl

svmt u

svmt ub

svmt l

svmt ul

svmt ubl

svm u

svm ub

svm l

svm ul

svm ubl

methoda
sw
mlw
olw
svm u
svm ub
svm l
svm ul
svm ubl
svmt u
svmt ub
svmt l
svmt ul
svmt ubl
svm u
svm ub
svm l
svm ul
svm ubl

sw

ascertain statistical significance difference f measure scores
different report labeling methods performed stratified approximate randomization
test shuffles pairs experiments table
table shows method column statistically significantly better
method row level p statistical significance
insignificance denoted x x respectively

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x


legend sw occurrence heuristic seed words mlw occurrence heuristic modified
basilisk lexicon olw occurrence heuristic original basilisk lexicon svm u svm
unigrams svm ub svm unigrams bigrams svm l svm lexicon words svm ul
svm unigrams lexicon words svm ubl svm unigrams bigrams lexicon
words svmt u transductive svm unigrams svmt ub transductive svm unigrams
bigrams svmt l transductive svm lexicon words svmt ul transductive svm
unigrams lexicons svmt ubl transductive svm unigrams bigrams lexicon words
svm u fold svm unigrams svm ub fold svm unigrams bigrams svm l
fold svm lexicon words svm ul fold svm unigrams lexicon words svm ubl fold svm unigrams bigrams lexicon words



ficause identification via weakly supervised semantic lexicon construction

appendix e sample preprocessed reports
report acn
returning waukegan regional airport practice area located mile
w airport flying solo student pilot feet mean sea level visual
flight rules cloud area mile w airport obscured view ahead reduced
altitude proceed visual flight rules returned feet passing thin
cloud line area n containing fix references airport location shrouded
clouds fog ground level true lake michigan shoreline
e ground substantially snow covered although airspace airport
undoubtedly clear practice area orientation field lost
climbed feet increase overview without benefit returning feet
flew believed n airfield landfall airport must
however proceeding flew ord class b airspace coinciding
lost contacted waukegan tower realizing flown federal aviation
regulation directed contact ord frequency given
beginning ord vectored back waukegan airport frequency changed
tower control blessedly cleared land time lost hour minutes
hours
report acn
following event occurred repositioning taxi w side
side isp airport initially contacted longitude island tower asking permission repos
w side ops base operations office tower side controller
replied start taxi via taxiway w hold short runway read back
instructions stating start taxi via taxiway w holding short runway taxiing
aircraft taxiway w holding short runway performing run
controller asked able get around aircraft replied able
controller said use caution taxiing around aircraft cross runway
taxiing across runway noticed aircraft short final runway clear
runway aircraft touched controller came frequency
said instructed hold short runway replied cleared across
runway controller said call tower park replied roger call
park called talked controller minutes later said
instructed hold short runway told cleared across
runway feel pilots controllers need listen decipher
said acting



fiabedin ng khan

appendix f lexicon learned original basilisk categories people
equipment
following table shows words phrases learned original basilisk framework
categories people equipment see section
category
people

equipment

words
agreed judges correct abq tower procedure specialist acn reporter afsfo avp tower specialist air route
traffic control center specialist air traffic control facility reps
bdr tower specialist bhm control buf field operations officer
cae tower specialist chicago quality control dfw maintenance
manager flight service station dispatcher sfolm captain
sii program manager stearman pilot tlh supervisor bur local
controller casino manager cos air traffic control chief flight test
engineers local balloon repairman outbound captain first officer repair facility pilot shift boss spokesperson station management individual technician desk tower supervisor manager
identified one judge correct flight standards district
office orl maintenance supervisor controller verbatim freighter aircraft tower passenger
fatigue
agreed judges incorrect acn acn
aircraft b srm emb service manual non air
carrier aircraft rptr acn rptr acn rptr
acn rptr acn rptr acn rptr acn
cabin company aircraft center reliable resources
agreed judges correct collision avoidance system ii distance measuring equipment screen collision avoidance
system ii b collision avoidance system ii ehsi collision
avoidance system ii ivsi display collision avoidance system ii
missed point page collision avoidance system ii rr
continued next page



ficause identification via weakly supervised semantic lexicon construction

category

words
identified one judge correct collision avoidance system ii vsi overlay resolution advisory stopped aircraft collision avoidance system ii stop climb alert collision avoidance
system ii traffic climb advisory collision avoidance system ii traffic traffic aural warning collision avoidance system
ii mile circle collision avoidance system ii mile scale collision avoidance system ii mile scale collision avoidance system ii popup traffic collision avoidance system ii resolution
advisory alerts collision avoidance system ii resolution advisory
climb priority collision avoidance system ii resolution advisory
climb warning collision avoidance system ii resolution advisory
signals collision avoidance system ii resolution advisory zone
collision avoidance system ii resolution advisory traffic advisory
alert collision avoidance system ii resolution advisory traffic advisory alerts advisories collision avoidance system ii resolution
advisory altitude deviation collision avoidance system ii traffic
advisory resolution advisory alerts collision avoidance system ii windshear warning collision avoidance system ii advisory alert collision avoidance system ii advisory alert warning
collision avoidance system ii warning aircraft
agreed judges incorrect collision avoidance system ii oclock mile collision avoidance system ii resolution advisory climb command collision avoidance
system ii resolution advisory area collision avoidance system
ii resolution advisory climb descent collision avoidance system ii resolution advisory data tag collision avoidance system
ii resolution advisory descent collision avoidance system ii resolution advisory green band target collision avoidance system ii
resolution advisory increase climb collision avoidance system ii
resolution advisory maneuvering collision avoidance system ii
resolution advisory messages collision avoidance system ii resolution advisory recovery procedure collision avoidance system
ii resolution advisory requirement collision avoidance system ii
resolution advisory requiring climb collision avoidance system
ii resolution advisory resolution collision avoidance system ii
traffic advisory notification collision avoidance system ii traffic
advisory resolution advisory aircraft collision avoidance system
ii traffic advisory resolution advisory event collision avoidance
system ii action requirements collision avoidance system ii advice
collision avoidance system ii advisories instructions collision
avoidance system ii caution collision avoidance system ii quit



fiabedin ng khan

appendix g lexicon learned modified basilisk categories people
equipment
following table shows words phrases learned modified basilisk framework
categories people equipment see section
category
people

equipment

words
agreed judges correct first officer first officer first officer cp captain captain rptr captain trainee
co captain co pilot first officer first officer initial operating experience captain paxs pilot flying first officer
potomac controller rpting captain rpting first officer rpting pilot rptr captain rptr pilot zoa supervisor air
carrier pilot aircraft x pilot aircraft commander passenger analyst first officer baron pilot biplane pilot controller
facility person first observer flight attendant flight attendants
passenger flying captain forward observer passenger passenger crew passenger flight attendants right seat pilot second observer sic specialist student captain supervisor controller
tower controller tower operator training pilot
identified one judge correct rptr gate passenger
first officer
agreed judges incorrect departure departure
neither captain clrly
agreed judges correct auto pilot
auto pilot autoplts autoflt autothrottle
autothrottle auto pilot autothrottles autothrottles auto pilot autothrust auto pilot
auto pilot auto pilot b auto pilot autothrust auto pilot pms auto pilot throttles autopilot autothrottles cessna collision avoidance system
ii system engs aircraft abcd aircraft auto pilot
aircraft engine allowed aircraft automatic pilot automatic throttle
automatic throttles autopilot center auto pilot craft emergency
engine left auto pilot left hand engine parked plane right autopilot
identified one judge correct
engine maintenance aircraft later aircraft aircraft aircraft collision
avoidance system ii alert constant speed drive auto pilot
autothrottles wdb perf
agreed judges incorrect aircraft beginning aircraft
parallel normal aircraft person property persons property
aircraft time aircraft



ficause identification via weakly supervised semantic lexicon construction

references
ando r k semantic lexicon construction learning unlabeled data via
spectral analysis proceedings th conference computational natural
language learning pp
artstein r poesio inter coder agreement computational linguistics
computional linguistics
avancini h lavelli sebastiani f zanoli r automatic expansion
domain specific lexicons term categorization acm transactions speech
language processing tslp
baker l mccallum k distributional clustering words text classification proceedings st annual international acm sigir conference
development information retrieval pp
banko brill e mitigating paucity data exploring effect training corpus size classifier performance natural language processing
proceedings st international conference human language technology

blei ng jordan latent dirichlet allocation journal
machine learning
brants franz web gram version linguistic data consortium
philadelphia usa
cheng p w covariation causation causal power theory psychological
review
chinchor n statistical significance muc proceedings
th message understanding conference pp
chinchor n hirschman l lewis evaluating message understanding systems analysis third message understanding conference muc
computational linguistics
cortes c vapnik v support vector networks machine learning

crammer k singer algorithmic implementation multiclass kernelbased vector machines journal machine learning
curran j r moens improvements automatic thesaurus extraction
proceedings acl workshop unsupervised lexical acquisition pp

curran j r murphy scholz b minimising semantic drift mutual
exclusion bootstrapping proceedings th conference pacific association computational linguistics pp


fiabedin ng khan

davidov rappoport efficient unsupervised discovery word categories
symmetric patterns high frequency words proceedings st international conference computational linguistics th annual meeting
association computational linguistics pp
dietterich g approximate statistical tests comparing supervised classification learning neural computation
dunning accurate methods statistics surprise coincidence computational linguistics
everitt b analysis contingency tables chapman hall
ferryman posse c rosenthal l j srivastava n statler c
happened toward understanding human error automated
analyses incident reports ii tech rep nasa tp national
aeronautics space administration
ganeri j noordhof p ramachandran counterfactuals preemptive
causation analysis
garcia coatis nlp system locate expressions actions connected
causality links proceedings th european workshop knowledge
acquisition modeling mangement pp
girju r automatic detection causal relations question answering proceedings acl workshop multilingual summarization question
answering pp
godbole sarawagi discriminative methods multi labeled classification
proceedings th pacific asia conference knowledge discovery data
mining pp
griffiths l tenenbaum j b structure strength causal induction
cognitive psychology
grishman r ksiezyk causal temporal text analysis role
domain model proceedings th international conference computational
linguistics pp
halpern j pearl j causes explanations structural model
part causes british journal philosophy science
hassan h hassan emam unsupervised information extraction
graph mutual reinforcement proceedings conference empirical
methods natural language processing pp
hume original work published enquiry concerning human understanding oxford university press usa
hume original work published treatise human nature oxford
university press usa
joachims advances kernel methods support vector learning chap making
large scale svm learning practical mit press


ficause identification via weakly supervised semantic lexicon construction

joachims text categorization suport vector machines learning many
relevant features proceedings th european conference machine learning pp
joachims transductive inference text classification support vector
machines proceedings th international conference machine learning
pp
kaplan r berry rogghe g knowledge acquisition causal relationships
text knowledge acquisition
kersey c di eugenio b jordan p katz ksc pal peer learning agent
encourages students take initiative proceedings th workshop
innovative use nlp building educational applications pp
khoo c g chan niu extracting causal knowledge medical
database graphical patterns proceedings th annual meeting
association computational linguistics pp
ko park j seo j improving text categorization importance
sentences information processing management
krippendorff k content analysis introduction methodology sage publications inc
lewis causation journal philosophy
lin dependency evaluation minipar proceedings lrec
workshop evaluation parsing systems pp
lin pantel p induction semantic classes natural language text
proceedings th acm sigkdd international conference knowledge discovery data mining pp
marcus p santorini b marcinkiewicz building large annotated
corpus english penn treebank computational linguistics
special issue large corpora
mccallum nigam k text classification bootstrapping keywords
em shrinkage proceedings acl workshop unsupervised learning
natural language processing pp
noreen e w computer intensive methods testing hypotheses introduction wiley
pantel p lin discovering word senses text proceedings th
acm sigkdd international conference knowledge discovery data mining
pp
pantel p ravichandran automatically labeling semantic classes proceedings human language technology conference north american chapter
association computational linguistics pp
passonneau r computing reliability coreference annotation proceedings
fourth international conference language resources evaluation vol
pp


fiabedin ng khan

patwardhan riloff e learning domain specific information extraction patterns web proceedings coling acl workshop information
extraction beyond document pp
patwardhan riloff e effective information extraction semantic affinity
patterns relevant regions proceedings joint conference empirical methods natural language processing computational natural language
learning pp
pereira f c n tishby n lee l distributional clustering english words
proceedings st annual meeting association computational linguistics pp
phan x h crfchunker crf english phrase chunker http crfchunker
sourceforge net
phan x h b crftagger crf english pos tagger
sourceforge net

http crftagger

phillips w riloff e exploiting role identifying nouns expressions information extraction proceedings international conference recent advances
natural language processing
polanyi l zaenen contextual valence shifters computing attitude
affect text theory applications pp springer verlag
posse c matzke b anderson c brothers matzke ferryman
extracting information narratives application aviation safety reports
proceedings ieee aerospace conference pp
read j pfahringer b holmes g multi label classification ensembles
pruned sets proceedings th ieee international conference data
mining pp
riloff e automatically generating extraction patterns untagged text
proceedings th national conference artificial intelligence pp
roark b charniak e noun phrase co occurrence statistics semi automatic
semantic lexicon construction proceedings th international conference
computational linguistics pp
rohwer r freitag towards full automation lexicon construction
proceedings computational lexical semantics workshop hlt naacl
pp
rychly p kilgarriff efficient building distributional
thesaurus sketch engine developments proceedings acl
demo poster sessions pp
sebastiani f machine learning automated text categorization acm computing
surveys
sundheim b overview fourth message understanding evaluation
conference proceedings fourth message understanding conference pp



ficause identification via weakly supervised semantic lexicon construction

tang l rajan narayanan v k large scale multi label classification via
metalabeler proceedings international world wide web conference pp

thelen riloff e bootstrapping method learning semantic lexicons
extraction pattern contexts proceedings conference empirical
methods natural language processing pp
tsoumakas g katakis multi label classification overview international
journal data warehousing mining
tsoumakas g vlahavas p random k labelsets ensemble method
multilabel classification proceedings th european conference machine
learning vol lecture notes computer science pp
ueda n saito k parametric mixture multi labeled text advances
neural information processing systems pp
van delden gomez f retrieving nasa reports case study
natural language information retrieval data knowledge engineering

vapnik v n statistical learning theory wiley
yang pedersen j comparative study feature selection text categorization proceedings th international conference machine learning
pp
yangarber r counter training discovery semantic patterns proceedings
st annual meeting association computational linguistics pp

zaidan f eisner j piatko c annotator rationales improve machine learning text categorization proceedings human language technology conference north american chapter association computational
linguistics pp
zhang q zhou huang x wu l graph mutual reinforcement
bootstrapping information retrieval technology




