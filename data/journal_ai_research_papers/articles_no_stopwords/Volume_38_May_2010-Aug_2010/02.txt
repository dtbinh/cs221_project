Journal Articial Intelligence Research 38 (2010) 85-133

Submitted 05/09; published 05/10

BnB-ADOPT:
Asynchronous Branch-and-Bound DCOP Algorithm
William Yeoh

wyeoh@usc.edu

Computer Science Department,
University Southern California,
Los Angeles, CA 90089, USA

Ariel Felner

felner@bgu.ac.il

Information Systems Engineering,
Deutsche Telekom Labs,
Ben-Gurion University Negev,
Beer-Sheva, 85104, Israel

Sven Koenig

skoenig@usc.edu

Computer Science Department,
University Southern California,
Los Angeles, CA 90089, USA

Abstract
Distributed constraint optimization (DCOP) problems popular way formulating
solving agent-coordination problems. DCOP problem problem several agents coordinate values sum resulting constraint costs minimal. often
desirable solve DCOP problems memory-bounded asynchronous algorithms. introduce Branch-and-Bound ADOPT (BnB-ADOPT), memory-bounded asynchronous DCOP search
algorithm uses message-passing communication framework ADOPT (Modi, Shen,
Tambe, & Yokoo, 2005), well known memory-bounded asynchronous DCOP search algorithm,
changes search strategy ADOPT best-first search depth-first branch-and-bound
search. experimental results show BnB-ADOPT finds cost-minimal solutions one
order magnitude faster ADOPT variety large DCOP problems fast
NCBB, memory-bounded synchronous DCOP search algorithm, DCOP
problems. Additionally, often desirable find bounded-error solutions DCOP problems
within reasonable amount time since finding cost-minimal solutions NP-hard. existing bounded-error approximation mechanism allows users specify absolute error bound
solution cost relative error bound often intuitive. Thus, present two
new bounded-error approximation mechanisms allow relative error bounds implement
top BnB-ADOPT.

1. Introduction
distributed constraint optimization (DCOP) problem consists agents, responsible taking
(= assigning itself) value nite domain values. agents coordinate values,
subject constraints. Two agents constrained share constraint.
constraint associated constraint cost, depends values constrained agents.
(complete) solution assignment values agents, partial solution assignment
values subset agents. solution cost (partial complete) solution sum
constraint costs constraints resulting given assignment values agents. Solving
DCOP problem optimally means nding solution minimal solution cost NP-hard (Modi
et al., 2005).
Formulating agent-coordination problems constraint optimization (COP) problems, specic
type weighted constraint satisfaction problems (Schiex, Fargier, & Verfaillie, 1995; Bistarelli,

c
2010
AI Access Foundation. rights reserved.

fiYeoh, Felner & Koenig

a1

a2
a3

a1
a4

a2
a3

(a)

a4

a1
0
0
1
1
a2
0
0
1
1

a2
0
1
0
1
a3
0
1
0
1

Constraint Cost
5
8
20
3
Constraint Cost
5
4
3
3

(b)

a1
0
0
1
1
a2
0
0
1
1

a3
0
1
0
1
a4
0
1
0
1

Constraint Cost
5
10
20
3
Constraint Cost
3
8
10
3

(c)

Figure 1: Example DCOP Problem
Montanari, Rossi, Schiex, Verfaillie, & Fargier, 1999), general formulating
common constraint satisfaction problems (Dechter, 2003). Constraint satisfaction problems
constraints either satised unsatised. Solving constraint satisfaction problem
means nding solution constraints satised. example application
scheduling jobs job-shop, constraints express jobs performed
certain machines jobs performed jobs. could
potentially multiple solutions satisfy constraints. However, solutions might
desirable others. example, one might prefer solution shortest completion time.
Unfortunately, constraint satisfaction problems cannot capture preferences. However, COP
problems able using constraint costs represent preferences.
DCOP algorithms better suited compared COP algorithms problems naturally distributed. result, DCOP algorithms applied coordinating unmanned
aerial vehicles (Schurr, Okamoto, Maheswaran, Scerri, & Tambe, 2005), scheduling meetings (Maheswaran, Tambe, Bowring, Pearce, & Varakantham, 2004b; Petcu & Faltings, 2005b; Greenstadt,
Grosz, & Smith, 2007; Zivan, 2008; Yeoh, Varakantham, & Koenig, 2009), coordinating sensor networks (Lesser, Ortiz, & Tambe, 2003; Zhang, Xing, Wang, & Wittenburg, 2003; Modi et al., 2005;
Jain, Taylor, Tambe, & Yokoo, 2009; Stranders, Farinelli, Rogers, & Jennings, 2009; Zivan, Glinton,
& Sycara, 2009), synchronizing trac lights (Junges & Bazzan, 2008), planning truck routes (Ottens
& Faltings, 2008) managing power distribution networks (Kumar, Faltings, & Petcu, 2009).
common visualize DCOP problem constraint graph vertices
agents edges constraints. DCOP algorithms operate pseudo-tree,
spanning tree (completely connected) constraint graph property edges
constraint graph connect vertex one ancestor descendant vertices
constraint tree (Freuder & Quinn, 1985; Bayardo & Miranker, 1995). edge constraint
graph part pseudo-tree backedge. agent c pseudo-child agent
agent p agent c descendant agent agent p pseudo-tree constrained
via backedge. Similarly, agent p pseudo-parent agent agent c. Sibling subtrees represent
independent DCOP subproblems (since two agents dierent sibling subtrees share constraint).
Figure 1(a) shows constraint graph example DCOP problem four agents
take value 0 value 1, Figure 1(b) shows one possible pseudo-tree assignments
values agents a3 a4 independent DCOP subproblems (the dotted line backedge),
Figure 1(c) shows constraint costs. example DCOP problem, cost-minimal solution
results agents take value 1. minimal solution cost 12.
1.1 DCOP Algorithms
provide taxonomy DCOP algorithms. Figure 2 shows taxonomy. DCOP algorithms
divided two groups: complete incomplete DCOP algorithms. Complete DCOP algorithms nd cost-minimal solutions incomplete DCOP algorithms often faster typically
nd suboptimal solutions.
86

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

DCOP Algorithms

Incomplete Algorithms
e.g., DBA, DSA, MGM,
k-optimal algorithms

Complete Algorithms

Partially Centralized Algorithms
e.g., OptAPO

Fully Decentralized
Algorithms

Search Algorithms
e.g., SBB, ADOPT,
NCBB, AFB

Inference Algorithms
e.g., DPOP

Figure 2: Taxonomy DCOP Algorithms
1.1.1 Incomplete DCOP Algorithms
Incomplete DCOP algorithms typically use local search nd locally optimal solutions
thus potentially get trapped local minima. Nevertheless, since solving DCOP problems optimally
NP-hard, DCOP algorithms desirable large DCOP problems nding costminimal solutions might slow. DBA (Yokoo & Hirayama, 1996), DSA (Fitzpatrick & Meertens,
2003), MGM (Maheswaran, Pearce, & Tambe, 2004a) recent class k-optimal DCOP
algorithms (Pearce & Tambe, 2007; Bowring, Pearce, Portway, Jain, & Tambe, 2008; Greenstadt,
2009) examples incomplete DCOP algorithms.
1.1.2 Complete DCOP Algorithms
Complete DCOP algorithms generally divided two groups, namely partially centralized
fully decentralized DCOP algorithms.
Partially Centralized DCOP Algorithms
Partially centralized DCOP algorithms allow agents transfer constraint information
(= information regarding constraints involved in) central agent processing. OptAPO (Mailler & Lesser, 2004) example partially centralized DCOP algorithm
uses cooperative mediation, certain agents act mediators solve overlapping DCOP
subproblems centrally.
Fully Decentralized DCOP Algorithms
Fully decentralized DCOP algorithms central agents collect constraint information agents constrained them. Rather, every agent access
constraint information. Fully decentralized DCOP algorithms generally divided two
groups, namely DCOP inference search algorithms.
DCOP inference algorithms: DCOP inference algorithms typically use dynamic programming propagate aggregated constraint costs one agent another agent thus reduce
87

fiYeoh, Felner & Koenig

DCOP
Algorithm
SBB
ADOPT
NCBB
AFB
BnB-ADOPT

Search
Strategy
DFBnB
best-first
DFBnB
DFBnB
DFBnB

Agent
Operation
sequential & synchronous
concurrent & asynchronous
sequential & synchronous
concurrent & asynchronous
concurrent & asynchronous

Communication
point-to-point neighbors
point-to-point neighbors
point-to-point neighbors
broadcast agents
point-to-point neighbors

Agent
Ordering
chain
tree
tree
chain
tree

Table 1: Properties DCOP Search Algorithms

DCOP problem size one agent step. repeat procedure DCOP
problem size reduced one agent solution space (= space possible partial solutions) thus cannot reduced anymore. sole remaining agent sucient
knowledge nd cost-minimal solution. DPOP (Petcu & Faltings, 2005b) example
DCOP inference algorithm. number messages sent agents linear
number agents. However, memory requirements exponential induced
width DCOP problem. induced width depends number backedges
pseudo-tree. large number agents minus one constraint graph
fully connected every agent thus constrained every agent.
DCOP search algorithms: DCOP search algorithms use search strategies search
solution space nd cost-minimal solution. ADOPT (Modi et al., 2005) uses best-rst
search, SBB (Hirayama & Yokoo, 1997), NCBB (Chechetka & Sycara, 2006), AFB (Gershman, Meisels, & Zivan, 2009) new DCOP search algorithm, BnB-ADOPT, use
depth-rst branch-and-bound search. memory requirements polynomial
number agents. However, number messages sent agents exponential
number agents.
Therefore, groups fully decentralized DCOP algorithms desirable dierent
conditions tradeo space (memory requirements) time (number messages
sent).
1.2 Motivation
describe motivation behind work.
1.2.1 BnB-ADOPT
study DCOP search algorithms memory-bounded. property important applications, sensor networks, every agent/sensor xed amount
memory available. result, several DCOP search algorithms, SBB, ADOPT, NCBB
AFB, developed limitation mind. described earlier, memory requirements
polynomial number agents. Table 1 shows properties DCOP search algorithms well properties new DCOP search algorithm, BnB-ADOPT. describe
property detail justify properties BnB-ADOPT.
Search strategy: ADOPT uses best-rst search search solution space, SBB,
NCBB AFB use depth-rst branch-and-bound (DFBnB) search. Best-rst search repeatedly searches next best partial solution nds cost-minimal solution. next
best partial solution cost-minimal partial solution among partial solutions
yet found. Depth-rst branch-and-bound search starts nding complete (but

88

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

often suboptimal) solution stores solution cost upper bound. continues
search solution whose solution cost less upper bound. stores solution
cost solution upper bound, search proceeds longer nd
solution whose solution cost less upper bound.
centralized search, known search problems depth-bounded search trees
often solved faster depth-rst branch-and-bound search memory-bounded
best-rst search memory-bounded best-rst search algorithms, RBFS (Korf,
1993), need repeatedly reconstruct partial solutions purged memory. Depthrst branch-and-bound search algorithms memory-bounded suer
problem (Zhang & Korf, 1995). Since DCOP problems search problems depthbounded search trees, hypothesize depth-rst branch-and-bound search might faster
best-rst search. Therefore, decided BnB-ADOPT use depth-rst branchand-bound search.
Agent operation: Agents SBB NCBB operate sequentially. agents tokens
active agents remain idle. token-holding agents done, pass
tokens remain idle. hand, agents ADOPT AFB operate
concurrently (= times). Agents operate concurrently might able solve DCOP
problems faster agents operate sequentially since former agents perform
potentially useful computation instead wait agents. Therefore,
decided agents BnB-ADOPT operate concurrently. Agents SBB NCBB
operate synchronously. Communication agents often form messages.
Synchronous agents operate cycles (Modi et al., 2005). cycle time required
agent process incoming messages queue send outgoing messages,
processed receiving agents next cycle (see Section 6.1 details).
Therefore, agents wait last agent done sending messages start
new cycle. hand, asynchronous agents, agents ADOPT AFB,
able operate independently other, often increases robustness (Silaghi,
Landwehr, & Larrosa, 2004). example, synchronous agents aected single
communication link suers congestion small number asynchronous agents
aected. therefore decided agents BnB-ADOPT operate asynchronously.
Communication:
DCOP search algorithms SBB, ADOPT NCBB restrict
communication agents share constraints. restriction motivated applications
sensor networks communication restricted neighboring agents/sensors due
limited communication radius. Neighboring sensors share constraints since need
coordinate sense areas near them. DCOP search algorithms AFB
restriction allow agents broadcast messages agents. decided
agents BnB-ADOPT obey restrictions applications sensor networks
thus communicate neighboring agents.
Agent ordering: DCOP search algorithms mentioned start pre-processing
step arranges agents pseudo-tree. DCOP search algorithms SBB
AFB arrange agents chain, ADOPT NCBB arrange agents tree.
tree ordering capture independent DCOP subproblems (represented sibling subtrees)
chain ordering not. DCOP search algorithms operate trees thus
operate independent DCOP subproblems independently, DCOP search algorithms
operate chains not. Therefore, decided BnB-ADOPT arrange
agents tree.
ADOPT preferred properties mentioned except uses best-rst search.
therefore introduce BnB-ADOPT, memory-bounded asynchronous DCOP search algorithm
89

fiYeoh, Felner & Koenig

uses message passing communication framework ADOPT changes search strategy
ADOPT best-rst search depth-rst branch-and-bound search.
1.2.2 Bounded-Error Approximations
Solving DCOP problems optimally NP-hard, makes advantageous allow users trade
solution cost smaller runtime. desirable error resulting solution
cost bounded provide guarantees solution cost. ADOPT is, best knowledge,
DCOP search algorithm property. Absolute Error Mechanism allows users
specify absolute error bound solution cost, example, solution cost
10 larger minimal solution cost. However, often much desirable
specify relative error bound solution cost, example, solution cost
10 percent larger minimal solution cost or, equivalently, 1.1 times larger
minimal solution cost. cannot done Absolute Error Mechanism without knowing
minimal solution cost priori. Thus, propose two approximation mechanisms allow users
specify relative error bound solution cost, namely Relative Error Mechanism
Weighted Heuristics Mechanism, implement top BnB-ADOPT. approximation
mechanisms allow BnB-ADOPT nd solutions bounded errors faster cost-minimal
solutions.
1.3 Experimental Results
experimentally compare ADOPT, BnB-ADOPT NCBB three dierent DCOP problem
types, namely graph coloring problems, sensor network problems meeting scheduling problems.
results show BnB-ADOPT one order magnitude faster (measured number
non-concurrent constraint checks number cycles) ADOPT variety large
DCOP problems. BnB-ADOPT inferred faster SBB since ADOPT faster
SBB (Modi et al., 2005). BnB-ADOPT fast NCBB DCOP
problems. results suboptimal variants BnB-ADOPT show Weighted Heuristics
Mechanism dominates Absolute Error Mechanism Relative Error Mechanism.
1.4 Article Structure
article organized follows: formalize DCOP problems Section 2 describe
DCOP search algorithm, BnB-ADOPT, Section 3. describe approximation mechanisms
allow BnB-ADOPT nd solutions bounded error Section 4. outline correctness
completeness proofs BnB-ADOPT Section 5. Lastly, present experimental evaluations
Section 6 conclusions Section 7.

2. DCOP Problems
section, formally dene distributed constraint optimization (DCOP) problems describe
solution space.
2.1 Definition DCOP Problems
DCOP problem dened following elements:
nite set agents = {a1 , a2 , ..., };
set nite domains = {Dom(a1 ), Dom(a2 ), ..., Dom(an )}, Dom(ai ) domain
possible oating point values agent ai A;

90

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

a1









0

0





b



a2

a2



B

C

5







8

a3
10 14

a4
3

20

a3
8

8

13

a3

a4
10

3

3

25

a4
7

3

a3
8

23

a4
6

c



10





3





g

E
h



e

F
j

k

(a)

G
l



f

H
n




p

q

J
r



K


u

v

(b)

Figure 3: AND/OR Search Tree
set binary constraints F = {f1 , f2 , ..., fm }, constraint : Dom(ai1 )
Dom(ai2 ) R+ , species non-negative constraint cost function values
distinct agents ai1 ai2 share constraint.
denition assumes agent takes one value rather multiple values,
example, dierent value constraint involved in. DCOP problems
commonly formulated agent responsible assignments values
multiple variables. However, exist techniques reduce DCOP problems DCOP
problems (Burke & Brown, 2006). Thus, use terms agent variable interchangeably.
denition assumes constraints binary (= two agents) rather n-ary
(= n agents). One able extend BnB-ADOPT solve DCOP problems nary constraints using techniques proposed extend ADOPT solve DCOP
problems n-ary constraints (Modi et al., 2005). Additionally, assume messages sent
agents delayed nite amount time never lost.
2.2 Search Trees
solution space DCOP problems visualized search trees. Traditional search trees
or, synonymously, search trees (Marinescu & Dechter, 2009) assign values agents sequentially.
utilize fact values agents belong independent DCOP subproblems
assigned sequentially. AND/OR search trees based pseudo-trees remedy
issue (Marinescu & Dechter, 2009). Thus, use AND/OR search trees refer
search trees article. depth bounded (twice) number agents.
Figure 3(a) shows search tree based pseudo-tree Figure 1(b). Figure 3(b)
labels node search tree identier allow us refer nodes easily. Circular
nodes nodes (labeled upper-case letters) correspond agents. example,
agent node C agent a2 . Left branches nodes correspond agents taking value
0 right branches correspond agents taking value 1. Square nodes nodes
(labeled lower-case letters) correspond partial solutions root node
nodes. example, partial solution node f {(a1 , 1), (a2 , 1)}. subtree rooted
node represents DCOP subproblem assumes partial solution node.
example, subtree rooted node f represents DCOP subproblem assigning values
agents a3 a4 given {(a1 , 1), (a2 , 1)}. number independent DCOP subproblems
within DCOP subproblem indicated number branches exiting node.
example, two branches exiting node f , indicating two independent DCOP
subproblems, namely assigning values agents a3 a4 . numbers nodes
delta costs nodes. delta cost node dened sum
constraint costs constraints partial solution involve agent parent node.

91

fiYeoh, Felner & Koenig

example, partial solution node v {(a1 , 1), (a2 , 1), (a4 , 1)}. two constraints
partial solution, namely constraint agents a1 a2 , constraint cost 3,
constraint agents a2 a4 , constraint cost 3. Since parent
node node v node K agent a4 , delta cost node v 3, namely constraint cost
latter constraint. former constraint included since involve agent a4 .
solution cost partial solution node sum delta costs nodes
along branch root node node. example, solution cost partial
solution node v (= 6) sum delta costs nodes b, f v. example DCOP
problem, cost-minimal solution union partial solutions nodes v (all agents
take value 1). Thus, minimal solution cost (= 12) sum delta costs nodes b, f ,
v.

3. BnB-ADOPT
section, present Branch-and-Bound ADOPT (BnB-ADOPT). describe BnBADOPT modication ADOPT since approach requires readers in-depth
understanding ADOPT. Instead, give stand-alone description BnB-ADOPT requires
knowledge ADOPT, intention creating self-contained hopefully easy-to-read
description.
3.1 Search Strategies ADOPT BnB-ADOPT
rst describe centralized versions search strategies ADOPT BnB-ADOPT omit
technical details since described detail later sections.
3.1.1 Search Strategy ADOPT
ADOPT (Modi et al., 2005) popular DCOP search algorithm (Modi & Ali, 2004; Ali, Koenig,
& Tambe, 2005; Bowring, Tambe, & Yokoo, 2006; Davin & Modi, 2006; Pecora, Modi, & Scerri,
2006; Choxi & Modi, 2007; Silaghi & Yokoo, 2009; Matsui, Silaghi, Hirayama, Yokoo, & Matsuo,
2009) traverses search tree best-rst search order. describe simplied version
best-rst search. complete version found (Marinescu & Dechter, 2007). Bestrst search maintains list initially contains child nodes root node.
repeatedly performs following operations: expands node smallest solution
cost list removing node list adding grandchild nodes
node list. example DCOP problem, best-rst search expands nodes
search tree Figure 3 rst time following order, numbers parentheses
indicate solution costs partial solutions expanded nodes: (0), b (0), f (3), c (5),
v (6), (8), (8) (9).
Figure 4 shows simplied trace ADOPT example DCOP problem. ADOPT terminates
fteen steps minimal solution cost 12. numbers nodes delta costs
r
nodes. lower bound LBX
r optimistic estimate minimal solution cost.
smallest underestimated solution cost, solutions. underestimated solution cost
solution sum delta costs nodes solution whose parent node
root node whose grandparent node expanded. example, underestimated
solution cost solution {(a1 , 1), (a2 , 1), (a3 , 1), (a4 , 1)} 3 node b expanded nodes f ,
r
v expanded. upper bound U BX
r pessimistic estimate minimal solution
cost. solution cost solution smallest solution cost found far. ADOPT
r
r
terminates upper bound U BX
r larger lower bound LBX r . order
memory-bounded, ADOPT maintains one branch search tree (shaded grey gure)
root node currently expanded node thus needs repeatedly reconstruct nodes

92

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

LBrXr = 0









b





B

C



c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

r



K


u



v



0

0

a2

a2

5



J

a3

8
a4

10 14 3

a3
8

a1







8 13 10 3 25 7



a3

0
a2
8

10 14 3

=5
= infinity

0

a4

a3
8



3
a4

8 13 10 3 25 7

3

a1





20
a3

a4

a3

8 23 6 10 3



a3

0

0
a2
8

a4

10 14 3

a3





a3

0

8
a4

10 14 3

a3
8

8

3

a3

a1





8 23 6 10 3





a3



a3

0
a2
8

10 14 3

=8
= infinity

0

a4

a3

0

8

10 14 3

8

8





3

a3



a3
10 14 3

8

= 12
= infinity

0

0
a2

a3





a3

8

8 13 10 3 25 7

10 14 3

8





a3

0
a2
8

10 14 3

a3
8



a3

8 13 10 3 25 7

3
a4

3

a3

8 23 6 10 3





a3

3

8 13 10 3 25 7





a3

0

0
a2
8

a4

10 14 3

a3
8

10 14 3

8

a1





3

a3

8 13 10 3 25 7



a3

0
a2

10 14 3

8

20
a4

a3

8 13 10 3 25 7





0

0
a2

a3
10 14 3

8
a4

a3
8

20
a4

a3

8 13 10 3 25 7

3
a4

3

a3

3
a4

3

a3

a4

8 23 6 10 3

Step 15

Figure 4: Trace Simplied Memory-Bounded Best-First Search (Centralized ADOPT)

93

a4

8 23 6 10 3

= 12
= 12

0

a3

a4

8 23 6 10 3

Step 14

LBrXr
UBrXr

8
a4

3

a3

a2
5



a4

8 23 6 10 3

a2
5





3
a4

a1 UBrXr = infinity



Step 13


a3

LBrXr = 12

3
a4

8 13 10 3 25 7

Step 12

20
a4





20
a3

a4

a4

8 23 6 10 3

a2
5



a4

= 12
= infinity
0

8

3

a3

Step 11

LBrXr
UBrXr

a2

a3

3
a4

a1 UBrXr = infinity



8 23 6 10 3

0

a4

a3

LBrXr = 8

a3

a2
5



a4

20
a4



3
a4

8 13 10 3 25 7

a1

a4

8 23 6 10 3

0

a4



20



3

a3

a2
5



a4

=8
= infinity

a3

a4

3
a4

Step 8

LBrXr
UBrXr

0

a3

a3

a1 UBrXr = infinity



8 23 6 10 3

a2

a4



20
a4

8

20
a4

Step 10

LBrXr
UBrXr

8
a4

3

0

5



a4

8 23 6 10 3

a2
5





10 14 3

a3

LBrXr = 8

a3

a2

Step 9
a1

8
a4



3
a4

8 13 10 3 25 7

a1



3
a4

8 13 10 3 25 7





a3



20
a3

a4





20
a3

a4



0
a2

Step 5

a2

a3

a4

8 23 6 10 3

0

5



a4

8 23 6 10 3

0

a4

3

a3

a2

Step 7

a2
5





3

a3

a2
5



a4

3
a4

a1 UBrXr = infinity



a1 UBrXr = infinity



a3

8 13 10 3 25 7



3
a4

8 13 10 3 25 7

Step 6
LBrXr
UBrXr

20
a4

LBrXr = 8

3
a4

8 13 10 3 25 7



8



20
a3

a4





20
a3

a4

10 14 3

a3

Step 4

a2
5





8
a4

LBrXr = 8

=5
= infinity

a2

LBrXr = 8





a3

Step 2

LBrXr
UBrXr

0

5



a4

a1 UBrXr = infinity





0
a2

5



a4

8 23 6 10 3

a2

Step 3


3

a3

0
a2

Step 1

a2
5







3
a4

a1 UBrXr = infinity





20
a3

a4

Identifiers
LBrXr
UBrXr

LBrXr = 3

a1 UBrXr = infinity



fiYeoh, Felner & Koenig

LBrXr = 0









b





B

C



c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

r



K


u



v



0

0

a2

a2

5



J

a3

8
a4

10 14 3

a3
8

a1









a3

0
a2
8

10 14 3

=0
= infinity

0

a4

a3

8 13 10 3 25 7

8





3
a4

8 13 10 3 25 7

3

a1



20
a3

a4

a1





a3



a3





a3

8

8 13 10 3 25 7

8

10 14 3

a3

a1





8



a3

3

a3

8 23 6 10 3





a3
10 14 3

8

0
a2

10 14 3

8



a3

0
a2
8

a4

10 14 3

a3
8



a3

8 13 10 3 25 7

3
a4

3

a3

a4

8 13 10 3 25 7



3

a3

8 23 6 10 3





a3

8

10 14 3

8





0

0
a2

a3

8
a4

10 14 3

a3
8

20
a4

3

a3

a4

8 13 10 3 25 7

3

a3

a4

8 23 6 10 3



3
a4

3

a1 UBrXr = 18



20
a3

8 13 10 3 25 7

Step 9

a4

8 23 6 10 3

LBrXr = 12

0

a4

3

a3

a2



a2

a3

a4

Step 8

LBrXr = 12
UBrXr = 18

0

a4

3

a3

8 13 10 3 25 7

5



a4

8 23 6 10 3

a2
5



a4

20
a4

a1 UBrXr = 18



3

a3

a1



20
a4



0



20



a4

8 23 6 10 3

LBrXr = 0

=0
= 18
0

a4

3

a3

Step 5

LBrXr
UBrXr

8

a4

a2
5



a4

8 23 6 10 3

a2

a3

3

a3

8 13 10 3 25 7

Step 7

0

a3

3

0

a4

20
a4

a1 UBrXr = 18



a3

a2
5



a4

LBrXr = 3
UBrXr = 18

8
a4

8



3
a4

8 13 10 3 25 7

a1



3
a4

a2
5





10 14 3

a3



20
a3

a4

Step 6


8
a4

LBrXr = 0

=0
= infinity
0

a4



20
a3

a4

a3

Step 2

LBrXr
UBrXr

a2



0

8

10 14 3

=0
= 18

a2

a3



0
a2

Step 4

LBrXr
UBrXr

0

a4



0
a2
5



a4

8 23 6 10 3

0

5



a4

8 23 6 10 3

a2
5





3

a3

a2

Step 3




Step 1

a2
5







3
a4

a1 UBrXr = infinity



20
a3

a4

Identifiers
LBrXr
UBrXr

LBrXr = 0

a1 UBrXr = infinity



a3

8 23 6 10 3

Step 10





0
a2

5



a4

0
a2

a3
10 14 3

8
a4

a3
8

20
a4

a3

8 13 10 3 25 7

3
a4

3

a3

a4

8 23 6 10 3

Step 11

LBrXr = 12

a1 UBrXr = 12









0
a2

5





0
a2

a3
10 14 3

8
a4

a3
8

20
a4

a3

8 13 10 3 25 7

3
a4

3

a3

a4

8 23 6 10 3

Step 12

Figure 5: Trace Simplied Depth-First Branch-and-Bound Search (Centralized BnB-ADOPT)
purged memory. example, Step 3, ADOPT branch node f memory.
next node best-rst search expands node c, ADOPT discards branch node f
Step 4. Steps 6 7, needs reconstruct discarded branch node f order
expand node v Step 8.
3.1.2 Search Strategy BnB-ADOPT
describe simplied version depth-rst branch-and-bound search. complete version
r
r
found (Marinescu & Dechter, 2009). use denitions LBX
r U BX r
described earlier Figure 4. Depth-rst branch-and-bound search maintains stack initially
contains child nodes root node. expands node top

94

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

stack removing node stack performing following check. solution
r
cost node smaller upper bound U BX
r , prunes node repeats
operation. Otherwise, adds grandchild nodes node top stack
r
repeats operation. terminates upper bound U BX
r larger lower bound
r
LBX r . Depth-rst branch-and-bound search add grandchild nodes expanded
node (and child nodes root node) decreasing order solution costs
instead random order top stack. ordering ensures depth-rst branchand-bound search expands grandchild node smallest solution cost rst. use
improvement throughout article. example DCOP problem, depth-rst branch-andbound search expands nodes search tree following order, prunes
nodes brackets: (0), c (5), (8), j (13), g (15), [h (19)], (8), n (11), k (16), [m (18)], [l (21)],
b (0), f (3), v (6) (9). Figure 5 shows trace depth-rst branch-and-bound search
example DCOP problem. memory-bounded without repeatedly reconstruct nodes
purged memory expands nodes best-rst search expand,
node j Step 4. depth-rst branch-and-bound search terminates twelve steps
minimal solution cost 12, three steps fewer ADOPT.
3.2 Description BnB-ADOPT
provide incremental description BnB-ADOPT. First, provide notations key
terms BnB-ADOPT. Then, describe BnB-ADOPT updates bounds, adheres memory
limitations, performs depth-rst search performs branch-and-bound. Finally, introduce
enhanced nal version BnB-ADOPT show pseudocode trace example
DCOP problem.
3.2.1 Notation Key Terms
adopt following notation ADOPT describe BnB-ADOPT:
V alInit(a) Dom(a) initial value agent A;
CD(a) set child pseudo-child agents agent A;
C(a) CD(a) set child agents agent A;
pa(a) parent agent agent except root agent;
P (a) set ancestor agents (including parent agent) agent A;
SCP (a) P (a) set ancestor agents (including parent agent) agent
parent pseudo-parent agents agent one (or more) descendant agents;
CP (a) SCP (a) set ancestor agents (including parent agent) agent
parent pseudo-parent agents agent a.
adopt following key terms ADOPT describe BnB-ADOPT:
Context (X): context X agent set values ancestor agents agent
a. context X r root agent r always equal {}.

Delta cost (): delta cost X
(d) sum constraint costs constraints
involve agent one ancestor agents, assumption agent
takes value ancestor agents take values context X . search tree,


X
(a, d). example,
(d) delta cost node partial solution X
a2
{(a1 ,1)} (1) delta cost node f Figure 3.

95

fiYeoh, Felner & Koenig



Gamma cost (): gamma costs X
(d) X dened follows:



X
(d) := X (d) +



c
X
(a,d)

(1)

cC(a)

X
:=

min


{X
(d)}

dDom(a)

(2)


agents a, values contexts X . Thus, gamma cost X
(d) sum
constraint costs constraints involve agent one descendant agents (that
is, either agent one ancestor agents, agent one descendant
agents, descendant agent ancestor agent agent two descendant agents
agent a) minimized possible values descendant agents, assumption
agent takes value ancestor agents take values context X . search


(a, d).
tree, X
(d) gamma cost node partial solution X
a2

example, {(a1 ,1)} (1) gamma cost node f Figure 3. gamma cost X
sum
constraint costs constraints involve agent one descendant agents
minimized possible values agent descendant agents, assumption
ancestor agents agent take values context X . search tree,

gamma cost X
gamma cost node whose agent agent whose parent
a2
gamma cost node C
node partial solution X . example, {(a
1 ,1)}
Figure 3. Therefore, gamma cost node sum delta cost
gamma costs child nodes, gamma cost node minimum
gamma costs child nodes. example, gamma cost node f Figure 3
sum delta cost gamma costs nodes J K, gamma cost
node C Figure 3 minimum gamma costs nodes e f .
r
Solving DCOP problem optimally means determine X
r root agent r or, equivalently,
r
gamma cost root node since X r minimal solution cost. dicult
agents cache information allows determine cost-minimal solution.

3.2.2 Updating Bounds
Every agent BnB-ADOPT stores updates several bounds gamma costs, namely
a,c




lba,c
X (d), LBX (d), LBX , ubX (d), U BX (d) U BX values d, child agents c

contexts X , maintaining following bound property:

LBX


LBX
(d)
a,c
lbX (d)





X


X
(d)
c
X
(a,d)


U BX


(3)




(4)
(5)


U BX
(d)
a,c
ubX (d)

search tree,


LBX
U BX lower upper bounds, respectively, (on gamma cost)
node whose agent agent whose parent node partial solution X ;


LBX
(d) U BX (d) lower upper bounds, respectively, (on gamma cost)
node partial solution X (a, d);
a,c
lba,c
X (d) ubX (d) lower upper bounds, respectively, (on gamma cost)
node whose agent agent c whose parent node partial solution X (a, d).

96

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

a2
a2
a2
example, LB{(a
U B{(a
bounds node C Figure 3, LB{(a
(1)
1 ,1)}
1 ,1)}
1 ,1)}
a2 ,a3
a2 ,a3
a2
U B{(a1 ,1)} (1) bounds node f , lb{(a1 ,1)} (1) ub{(a1 ,1)} (1) bounds node J.
a3
a3
2 ,a3
2 ,a3
lba{(a
(1), uba{(a
(1), LB{(a
U B{(a
bounds node J, agent
1 ,1)}
1 ,1)}
1 ,1),(a2 ,1)}
1 ,1),(a2 ,1)}
a2 maintains rst two bounds agent a3 maintains last two bounds.
agent uses following update equations values d, child agents c
a,c
a,c
contexts X initialize bounds lba,c
X (d) ubX (d), heuristic values hX (d)
a,c
c
oating point numbers admissible thus satisfy 0 hX (d) X (a,d) :

a,c
lba,c
X (d) := hX (d)

uba,c
X (d)

:=

(6)
(7)

Agent uses repeatedly following update equations values d, child agents c,
contexts X contexts X c (= X (a, d)) tighten bounds:
a,c
c
lba,c
X (d) := max{lbX (d), LBX c }
a,c


LBX
lbX (d)
(d) := X (d) +

(8)
(9)

cC(a)

LBX
:=

uba,c
X (d) :=

U BX
(d)

:=


U BX
:=


min {LBX
(d)}
dDom(a)
c
min{uba,c
X (d), U BX c }


X
uba,c
(d) +
X (d)
cC(a)

min


{U BX
(d)}

dDom(a)

(10)
(11)
(12)
(13)

updates maintain bound property improve bounds monotonically, is,
lower bounds monotonically non-decreasing upper bounds monotonically nona


increasing.1 nite amount time, U BX
LBX agents contexts X .
r
r
BnB-ADOPT terminates termination condition U BX r LBX r root agent r
r
r
r
r
satised. Then, U BX
r LBX r bound property U BX r LBX r together imply
r
r
r
U BX r = X r = LBX r , DCOP problem solved optimally.
Figure 6 shows simplied trace updates (lower upper) bounds example
DCOP problem. assume updates proceed sequentially leaf agents root
agent. Due simplication, lower upper bounds node identical
gamma cost independent heuristic values. numbers nodes bounds.
Two agents maintain bounds nodes except root node. gure shows bounds
parent agent maintains rather bounds child agent maintains. example,
number node B bounds agent a1 rather agent a2 maintains. bounds
child agent maintains computed taking minimum bounds child
nodes node. Agents update bound node sum delta cost
bounds child nodes according update equations 9 12. update
bound node minimum bounds child nodes according update
equations 10 13. detailed description trace follows:
Step 1: Leaf agent a3 updates bounds nodes g, h, k, l, o, p,
delta costs according update equations 9 12 bounds nodes D, F , H
1. Leaf agents use update equations. Since child agents, sums child agents
(d) = U B (d) = (d) leaf agents a, values contexts X .
evaluate 0. example, LBX

Xa
Xa

97

fiYeoh, Felner & Koenig





0



0







b



0

0



0



B

C



0

0



0

c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

J
r



K


0



u



v



0

0
0

10 14 3

0
8

0
0

0

8 13 10 3 25 7

Identifiers

0
0
3

0

8 23 6 10 3

Step 1

18



18

10 14 3

3

8
8

30
3

7

8 13 10 3 25 7

12
3

3

6

3

8 23 6 10 3

Step 2

12
12

18







10

19

12









0

18



0

0

10
10 14 3

19
3

8
8

30
3

7

8 13 10 3 25 7

12
3

3

6

3

8 23 6 10 3

Step 3

Figure 6: Simplied Trace Updates (Lower Upper) Bounds
J minimum bounds child nodes according update equations 10
13. Similarly, leaf agent a4 updates bounds nodes i, j, m, n, q, r, u
v delta costs according update equations 9 12 bounds nodes
E, G, K minimum bounds child nodes according update
equations 10 13. bounds nodes K shown gure since
(yet) maintained agent a2 .
Step 2: Agent a2 updates bounds nodes K maintains bounds
nodes leaf agents a3 a4 maintain according update equations 8
11, bounds nodes c f sum delta costs bounds
child nodes according update equations 9 12 bounds nodes B
C minimum bounds child nodes according update equations 10
13. bounds nodes B C shown gure since (yet)
maintained agent a1 .
Step 3: Agent a1 updates bounds nodes B C maintains bounds
nodes agent a2 maintains according update equations 8 11,
bounds nodes b sum delta costs bounds child
nodes according update equations 9 12 bounds node minimum
bounds child nodes according update equations 10 13. Since
lower upper bounds node equal gamma cost, lower upper bounds
root node equal gamma cost, turn equal minimal solution
cost. propagation terminates three steps minimal solution cost 12.
3.2.3 Adhering Memory Limitations
description BnB-ADOPT far assumes memory limitations. However, BnB-ADOPT
memory-bounded DCOP search algorithm memory requirements per agent linear
number agents. describe BnB-ADOPT adheres memory limitations
using techniques introduced ADOPT apply BnB-ADOPT well.
simplied trace Figure 6 assumes every agent maintains bounds values d,
child agents c contexts X . number contexts exponential depth
agent pseudo-tree. example DCOP problem, agent a3 four dierent contexts
four dierent combinations values ancestor agents a1 a2 . agent cannot maintain
98

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

exponential number bounds due memory limitations. Therefore, every agent maintains
bounds one context given time. context stored variable X
agent a. size context linear number agents. number bounds
agent linear product domain cardinality number child agents.
Thus, memory requirements per agent linear number agents domain
cardinality magnitude bounds (and variables) constant agent.
3.2.4 Performing Depth-First Search
description BnB-ADOPT far applies ADOPT well. However, BnB-ADOPT uses
depth-rst branch-and-bound search ADOPT uses best-rst search. describe
BnB-ADOPT implements depth-rst search.
Agents BnB-ADOPT send messages similar ADOPT processes
dierently. send messages three dierent types, namely VALUE, COST TERMINATE
messages. start, every agent initializes context X , uses update equations 6, 9, 10, 7, 12

13 initialize bounds takes best value da := arg mindDom(a) {LBX
(d)}. sends
VALUE messages child agents COST message parent agent. repeatedly
waits incoming messages, processes them, possibly takes dierent value sends
VALUE messages child agents COST message parent agent. description
three message types agents process follows:
VALUE messages: agent context X value da sends VALUE messages
child agents desired context X (a, da ), context augmented
value. Leaf agents child agents thus send VALUE messages. VALUE
messages thus propagate contexts pseudo-tree.
agent receives VALUE message, checks whether context identical
desired context VALUE message. not, agent changes context
desired context VALUE message. either case, executes common program
(see below).
COST messages: agent sends COST messages parent agent identity


a, context X bounds LBX
U BX . root agent parent
agent thus send COST messages. COST messages thus propagate bounds
pseudo-tree.
agent receives COST message, checks whether context context
COST message compatible. Two contexts compatible agent takes dierent
values two contexts. are, agent uses update equations 8 13
bounds COST message improve bounds value message. either
case, executes common program (see below).
r
r
TERMINATE messages: termination condition U BX
r LBX r satised,
root agent r sends TERMINATE messages (without parameters) child agents
inform search complete terminates. agent receives
TERMINATE message, sends TERMINATE messages child agents terminates
well. Leaf agents child agents thus send TERMINATE messages.
TERMINATE messages thus propagate pseudo-tree agents terminate.

common program follows:
Context change: agent changed context X , executes following statements:
uses update equations 6, 9, 10, 7, 12 13 initialize bounds takes best

value da := arg mindDom(a) {LBX
(d)}. sends VALUE messages child agents
COST message parent agent.
99

fiYeoh, Felner & Koenig





0



0







b



0

0



5



B

C



0

0



5

c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

J
r



K


5



u



v



8

0

0

10 14 3

8

X

0

X

X

X

X

X X

X X

X X

X X

X X

X X





0

18



0

Identifiers

10

8
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

0





8

0



8

0



18



8

0



8

0



18

18







8

10

3

X X

X X

0

X
0

8 13 10 3

X

18



X

X

X

X

X X

X X

X X

X X





19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X





10

19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

3



18

0



18

3



18



18

0



18

3



18

X





10
10 14 3

X
3
8

20

3

X



X

X

0

0

0

0

X X

X X

X X

X X

X X

X X





X

20

X

X

X

X

0

X X

X X

X X

X X

X X

Cycle 6

3
0

0

0

X X 23 6 10 3





3
X

20

X

X

X

X

0

X X

X X

X X

X X

X X

12
0

6

3

X X 23 6 10 3

Cycle 8

12





18



18

12
12

X





3

X



Cycle 7



X

3

Cycle 5

3



X

8





0

18



X

0

Cycle 4

0



X
3

X

0

Cycle 2

0



X

0

Cycle 1

0



X

0

X

20

X

X

X

X

0

X X

X X

X X

X X

X X

12
0

6

3

X X 23 6 10 3

Cycle 9

Figure 7: Trace Updates Lower Bounds
context change: agent change context X , executes following




statements: U BX
LBX (d ) value , context agent augmented
value cannot completed solution whose solution cost smaller solution

cost best solution found far context X (= U BX
) agent thus takes


best value := arg mindDom(a) {LBX (d)}. sends VALUE messages child
agents COST message parent agent.
Assume context X agent change. nite amount time,




U BX
agent takes best value repeats
LBX (d ) value .


procedure. nite amount time, U BX
LBX (d) values d, implies





U BX LBX . agent takes every value U BX
LBX since LBX (d)

remains unchanged U BX monotonically non-increasing agent changes value
dierent value, prevents agent changing value back


U BX
LBX . BnB-ADOPT thus performs depth-rst search. Then, nite amount time,
r
r
r
r
r
r
r
U BX r LBX r bound property U BX
r LBX r together imply U BX r = X r = LBX r
root agent r, DCOP problem solved optimally.
Figures 7 8 show traces updates lower upper bounds, respectively,
example DCOP problem. BnB-ADOPT uses zero heuristic values. initial context every
100

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm





inf



inf







b



inf

inf



inf



B

C



inf

inf



inf

c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

J
r



inf



K


u



v



inf

inf
inf

10 14 3

8

X

inf

X

X

X

X

X X

X X

X X

X X

X X

X X





10

inf
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 2

18



18



18

inf



18

inf



18



18

inf



18

inf



18

18





inf

10

3

X X

X X

inf

X
inf

8 13 10 3

X

18



X

X

X

X

X X

X X

X X

X X





19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X





10

19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

18



18

inf



18

inf



18



18

inf



18

inf



18

X





10
10 14 3

X
3
8

inf

inf

X



X

X

inf

inf

inf

inf

X X

X X

X X

X X

X X

X X





X

inf

X

X

X

X

inf

X X

X X

X X

X X

X X

Cycle 6

inf
inf

inf

inf

X X 23 6 10 3





inf
X

inf

X

X

X

X

inf

X X

X X

X X

X X

X X

12
inf

6

3

X X 23 6 10 3

Cycle 8

12





18



18

12
12

X





inf

X



Cycle 7



X

3

Cycle 5

18



X

8





inf

18



X

inf

Cycle 4

18



X
3

X

inf

Cycle 1

18

X

inf





0

18



inf

Identifiers


X

inf

X

inf

X

X

X

X

inf

X X

X X

X X

X X

X X

12
inf

6

3

X X 23 6 10 3

Cycle 9

Figure 8: Trace Updates Upper Bounds
agent assigns value 0 ancestor agents agent. partition time cycles. Agents
maintain bounds one context given time. Nodes gures crossed
agent maintain bounds. nodes shaded partial solution equal
context agent parent node augmented value. example, agents
a1 , a3 a4 take value 0 Cycle 2, agent a2 takes value 1. context agent a1
{}, context agent a2 {(a1 , 0)} contexts agents a3 a4 {(a1 , 0), (a2 , 0)}.
description trace follows:
Cycle 1: Root agent a1 initializes context X a1 {}. initializes lower bounds
nodes B (= lbaX1a,a1 2 (0)) C (= lbaX1a,a1 2 (1)) 0 since uses zero heuristic values.
a1
updates lower bound node (= LBX
a1 (0)) sum delta cost (= 0)
lower bound node B (= 0) according update equations. updates lower bound
a1
node b (= LBX
a1 (1)) sum delta cost (= 0) lower bound node C (= 0)
a1
according update equations. updates lower bound node (= LBX
a1 )
minimum lower bound node (= 0) lower bound node b (= 0) according
update equations. initializes upper bounds nodes B C innity. updates
upper bounds nodes a, b innity according update equations. takes

101

fiYeoh, Felner & Koenig

best value. take either value 0 value 1 since lower bounds nodes
b 0. takes value 0 sends VALUE message child agent a2 .
Agent a2 initializes context X a2 {(a1 , 0)}. initializes lower bounds nodes D, E,
F G 0. updates lower bounds nodes c, B 5, 8 5, respectively.
initializes upper bounds nodes D, E, F G innity. updates upper bounds
nodes c, B innity. bounds node B agent a2 maintains shown
gures. takes best value 0, sends VALUE messages child agents a3
a4 sends COST message parent agent a1 .
Leaf agent a3 initializes context X a3 {(a1 , 0), (a2 , 0)}. updates lower bounds
nodes g h delta costs 10 14, respectively, since leaf agents child
agents. updates lower bound node 10. updates upper bounds nodes g
h delta costs 10 14, respectively, since leaf agents child agents.
updates upper bound node 10. bounds node leaf agent a3 maintains
shown gures. takes best value 0 sends COST message
parent agent a2 .
Leaf agent a4 initializes context X a4 {(a1 , 0), (a2 , 0)}. updates lower bounds
nodes j delta costs 3 8, respectively. updates lower bound node E
3. updates upper bounds nodes j delta costs 3 8, respectively.
updates upper bound node E 3. bounds node E leaf agent a4 maintains
shown gures. takes best value 0 sends COST message
parent agent a2 .
summary, following messages sent Cycle 1:
message (VALUE, {(a1 , 0)}) agent a1 agent a2 ;
message (VALUE, {(a1 , 0), (a2 , 0)}) agent a2 agent a3 ;
message (VALUE, {(a1 , 0), (a2 , 0)}) agent a2 agent a4 ;
message (COST, a2 , {(a1 , 0)}, 5, ) agent a2 agent a1 ;
message (COST, a3 , {(a1 , 0), (a2 , 0)}, 10, 10) agent a3 agent a2 ;
message (COST, a4 , {(a1 , 0), (a2 , 0)}, 3, 3) agent a4 agent a2 .
Cycle 2: Root agent a1 receives COST message sent child agent a2 Cycle 1. Since
context agent a1 (= {}) compatible context message (= {(a1 , 0)}),
improves bounds. updates bounds node B bounds message (= 5
innity, respectively). updates bounds nodes a, b A. change value
a1
a1
) = 5 value da1 = 0) still smaller
since lower bound node (= LBX
a1 (d
a1
upper bound node (= U BX a1 = ). sends VALUE message child agent
a2 .
Agent a2 receives VALUE message sent parent agent a1 Cycle 1. context
(= {(a1 , 0)}) remains unchanged since desired context message
(= {(a1 , 0)}). Agent a2 receives COST messages sent child agents a3 a4
Cycle 1. Since context agent a2 (= {(a1 , 0)}) compatible contexts
messages (= {(a1 , 0), (a2 , 0)}), improves bounds. updates bounds node
bounds rst message (= 10 10, respectively) bounds node E
bounds second message (= 3 3, respectively). updates bounds nodes c,
a2
a2
) = 18 value
B. changes value since lower bound node c (= LBX
a2 (d
a2
a2
= 0) longer smaller upper bound node B (= U BX a2 = 18). takes
best value 1, sends VALUE messages child agents a3 a4 sends COST message
parent agent a1 .

102

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Leaf agents a3 a4 receive VALUE messages sent parent agent a2 Cycle 1.
contexts (= {(a1 , 0), (a2 , 0)}) remain unchanged since desired
context message (= {(a1 , 0), (a2 , 0)}). send COST messages
parent agent a2 .
summary, messages sent Cycle 2 identical ones sent Cycle 1,
except messages sent agent a2 , follows:
message (VALUE, {(a1 , 0), (a2 , 1)}) agent a2 agent a3 ;
message (VALUE, {(a1 , 0), (a2 , 1)}) agent a2 agent a4 ;
message (COST, a2 , {(a1 , 0)}, 8, 18) agent a2 agent a1 .
VALUE messages dierent agent a2 changed value 0 1. COST
message dierent agent a2 changed bounds.
Cycles 3-9: messages sent Cycle 3 identical ones sent Cycle 2,
except messages sent agents a3 a4 , follows:
message (COST, a3 , {(a1 , 0), (a2 , 1)}, 8, 8) agent a3 agent a2 ;
message (COST, a4 , {(a1 , 0), (a2 , 1)}, 3, 3) agent a4 agent a2 .
COST messages dierent agents a3 a4 changed contexts.
termination condition holds nite amount time upper bound node
a1
a1
(= U BX
a1 = 12) larger lower bound node (= LBX a1 = 12). Root agent a1
sends TERMINATE messages child agents, TERMINATE messages propagate
pseudo-tree agents terminate. BnB-ADOPT terminates nine cycles
minimal solution cost 12.
3.2.5 Performing Branch-and-Bound
rene description BnB-ADOPT explaining agents implement branchand-bound search make BnB-ADOPT faster. Every agent BnB-ADOPT maintains

variable threshold HX
, initializes innity. threshold root agent always
remains innity. Every agent uses threshold pruning, meaning change
value earlier previously.
First change: agent change context X , previously executed following




statements: U BX
LBX (d ) value , agent took best value.
sent VALUE messages child agents COST message parent agent. Now,





HX
LBX (d ), agent takes best value. Thus, min{T HX , U BX }


LBX
(d
),


agent
takes


best
value

thus
potentially
changes

value,




earlier previously. min{T HX
,
U
B
}


pruning
quantity.

Xa
Second change: agent context X value da sends VALUE messages
child agents, previously contained desired context X (a, da ).




VALUE messages contain desired threshold min{T HX
, U BX } X (d )

a,c
c C(a)\c lbX (d ) child agent c. agent c receives VALUE message, sets
threshold desired threshold proceeds described earlier. desired



reaches
threshold set lower bound LBX
(d ) agent value
c
pruning quantity (and agent thus potentially changes value) lower bound LBX
c
agent c reaches desired threshold. property veried follows:

103

fiYeoh, Felner & Koenig



c




LBX
c min{T HX , U BX } X (d )




lba,c
X (d )

(14)

c C(a)\c








lba,c
X (d ) min{T HX , U BX } X (d )
a,c





min{T HX
, U BX } X (d ) lb (d )
X




lba,c
X (d )

(15)

c C(a)\c






lba,c
X (d )

(16)

c C(a)\c



a,c





min{T HX
, U BX } X (d ) + lb (d ) +
X







min{T HX
, U BX } X (d ) +




lba,c
X (d )

(17)

c C(a)\c



lba,c
X (d )

(18)

c C(a)




min{T HX
, U BX } LBX (d )

(19)

3.2.6 Enhancements
continue rene description BnB-ADOPT explaining number additional enhancements, introduced ADOPT.
Reduced contexts: agents use reduced contexts, subsets contexts
described previously. reduced context X1a agent contains values ancestor
agents p SCP (a), context X2a described previously contains values



ancestor agents p P (a). agents use reduced contexts since X
= X X (d) =
1
2
1

X2a (d) values d. Agents use reduced contexts need change
contexts thus initialize bounds less often receive VALUE messages since
contexts often identical desired contexts VALUE messages.
example DCOP problem, reduced context agent a4 contains values
agent a2 rather values agents a1 a2 . Therefore, following pairs nodes
search tree actually node: nodes q, nodes j r, nodes u,
nodes n v.
VALUE COST messages: agent sends VALUE messages child agents,
previously contained desired context desired threshold. desired context
context agent augmented value. agent receives VALUE message,
previously checked whether context identical desired context VALUE
message. not, agent changed context desired context
VALUE message. Agents update contexts dierently reduce size
VALUE messages. agent sends VALUE messages child pseudo-child agents
identity, value desired threshold, innity pseudo-child agents.
agent receives VALUE message, sets threshold desired threshold message
parent agent. checks whether value ancestor agent VALUE
message recent value ancestor agent context. is,
agent changes value ancestor agent context value ancestor agent
VALUE message. However, context agent contain values
parent pseudo-parent agents values ancestor agents parent
pseudo-parent agents one (or more) descendant agents, ancestor agents
constrained agent cannot send VALUE messages agent. However,
send VALUE messages pseudo-child agents, least one descendant agent
agent, information propagates pseudo-tree COST messages
reaches agent. agent receives COST message, checks whether
104

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

value ancestor agent context COST message recent
value ancestor agent context. is, agent changes value
ancestor agent context value ancestor agent context COST
message. example DCOP problem simple allow us illustrate propagation
information pseudo-tree. However, imagine new agent a5 child agent
agent a4 constrained agents a1 a4 . context agent a4 contains
value agent a1 agent a1 cannot send VALUE messages agent a4 . However, agent
a1 sends VALUE messages agent a5 . Agent a5 changes value agent a1 context
sends COST messages context agent a4 , changes value agent
a1 context well.
agents need determine whether value agent VALUE messages
contexts COST messages recent value agent contexts. Every
agent therefore maintains counter IDa increments whenever changes
value. Therefore, larger ID indicates recent value. values agents contexts
labeled IDs, VALUE messages contain identity sending agent,
value, ID desired threshold.
Bounds: Whenever agent changes context X , previously initialized bounds
took best value. (reduced) context child agent agent strict
subset (reduced) context agent since parent pseudo-parent agents
agent might (parent or) pseudo-parent agents child agent descendant
agents. context child agent c contain values agents whose values
changed context agent a, agent initialize lower bounds lba,c
X (d)
upper bounds uba,c
(d)

agent
c


values



takes


best
value.
Agents
Xa
use optimization need initialize bounds less often way.
example DCOP problem, agent a2 changes context {(a1 , 0)} {(a1 , 1)} (where
IDs omitted simplicity), initialize lower bounds lbaX2a,a2 4 (d) upper
bounds ubaX2a,a2 4 (d) child agent a4 values since context agent a4
contain value agent a1 .
Additionally, agent changes context due COST message child agent c
new context X compatible context COST message, agent
a,c
set lower bound lba,c
X (d) upper bound ubX (d) agent c value agent
COST message bounds COST message takes best value.
Agents use optimization bounds COST message informed
initialized bounds. example DCOP problem simple allow us illustrate
optimization. However, imagine new agent a5 child agent agent a4
constrained agents a1 a4 . Assume context agent a4 {(a1 , 0), (a2 , 0)}
(where IDs omitted simplicity) receives COST message agent
a5 context {(a1 , 1), (a4 , 0)}. Agent a4 changes context {(a1 , 1), (a2 , 0)}, sets
4 ,a5
4 ,a5
lower bound lba{(a
(0) upper bound uba{(a
(0) bounds
1 ,1),(a2 ,0)}
1 ,1),(a2 ,0)}
COST message initializes bounds takes best value.

3.2.7 Pseudocode
Figure 9 shows BnB-ADOPT pseudocode every agent. pseudocode index
variables context since context implicitly given variable X . uses
predicate Compatible(X, X ) = (a,d,ID)X,(a ,d ,ID )X (a =
= ) determines two
contexts X X compatible, is, agent takes two dierent values two contexts
[Lines 35, 44, 46, 48 51]. pseudocode uses procedure PriorityMerge(X, X )
executes X := {(a , , ID ) X | (a,d,ID)X (a = )} {(a , , ID ) X | (a,d,ID)X (a =

105

fiYeoh, Felner & Koenig

procedure Start()
[01]
X := {(p, ValInit(p), 0) | p SCP (a)};
[02]
IDa := 0;
[03]
forall c C(a), Dom(a)
[04]
InitChild(c, d);
[05]
InitSelf ();
[06]
Backtrack();
[07]
loop forever
[08]
(message queue empty)
[09]
while(message queue empty)
[10]
pop msg message queue;
[11]
Received(msg);
[12]
Backtrack();
procedure InitChild(c, d)
[13]
lba,c (d) := ha,c (d);
[14]
uba,c (d) := ;
procedure InitSelf ()

[15]
da := arg mindDom(a) { (d) + cC(a) lba,c (d)};


[16]
ID := ID + 1;
[17]
H := ;
procedure Backtrack()
[18]
forall Dom(a)
[19]
LB (d) := (d) + cC(a) lba,c (d);

[20]
UB (d) := (d) + cC(a) uba,c (d);

[21]
LB := mindDom(a) {LB (d)};
[22]
UB := mindDom(a) {UB (d)};
[23]
(LB (da ) min{T H , UB })
[24]
da := arg mindDom(a) {LB (d)} (choose previous da possible);
[25]
new da chosen
[26]
IDa := IDa + 1;
[27]
((a root UB LB ) termination message received)
[28]
Send(TERMINATE) c C(a);
[29]
terminate execution;


[30]
Send(VALUE, a, da , IDa , min{T H , UB } (da ) c C(a)\c lba,c (da )) c C(a);


[31]
Send(VALUE, a, , ID , ) c CD(a) \ C(a);
[32]
Send(COST, a, X , LB , UB ) pa(a) root;
procedure Received(VALUE, p, dp , IDp , H p )
[33]
X := X ;
[34]
PriorityMerge((p, dp , ID p ), X );
[35]
(!Compatible(X , X ))
[36]
forall c C(a), Dom(a)
[37]
(p SCP (c))
[38]
InitChild(c, d);
[39]
InitSelf ();
[40]
(p = pa(a))
[41]
H := H p ;
procedure Received(COST, c, X c , LB c , UB c )
[42]
X := X ;
[43]
PriorityMerge(X c , X );
[44]
(!Compatible(X , X ))
[45]
forall c C(a), Dom(a)
[46]
(!Compatible({(p, dp , ID p ) X | p SCP (c)},X ))
[47]
InitChild(c,d);
[48]
(Compatible(X c , X ))
[49]
lba,c (d) := max{lba,c (d), LB c } unique (a , d, ID) X c = a;
[50]
uba,c (d) := min{uba,c (d), UB c } unique (a , d, ID) X c = a;
[51]
(!Compatible(X , X ))
[52]
InitSelf ();
procedure Received(TERMINATE)
[53]
record termination message received;

Figure 9: Pseudocode BnB-ADOPT
ID ID )} {(a, d, ID) X | (a ,d ,ID )X (a = ID > ID )} thus replaces values

106

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

agents context X recent values, available, agents context X [Lines
34 43].
code identical every agent except variable self variable points
agent itself. start, BnB-ADOPT calls Start() every agent. agent receives
VALUE message ancestor agent, Received handler VALUE messages
called p ancestor agent, dp value ancestor agent, IDp
ID ancestor agent H p desired threshold agent ancestor agent
parent agent (and innity otherwise) [Line 11]. agent receives COST message
child agent, Received handler COST messages called c child
c
agent, X c context child agent, LB c lower bound LBX
c child agent
c
c
U B upper bound U BX c child agent [Line 11]. Finally, agent receives
TERMINATE message parent agent, Received handler TERMINATE
messages called without arguments [Line 11].
BnB-ADOPT uses message passing communication framework ADOPT
memory requirements. uses similar VALUE, COST TERMINATE messages,
similar strategy update context agent based VALUE messages ancestor
agents COST messages child agents, semantics bounds
update equations update bounds. BnB-ADOPT ADOPT use thresholds BnBADOPT uses thresholds pruning ADOPT uses reconstruct partial solutions
purged memory. Thus, BnB-ADOPT uses dierent threshold initialization [Line
17], dierent desired threshold calculation [Line 30] dierent termination condition [Line 27].
BnB-ADOPT diers ADOPT maintains IDs agents use indicate
recency values labels values agents contexts IDs.
3.2.8 Trace
Figures 10 11 show traces updates lower upper bounds, respectively,
example DCOP problem, Table 2 shows trace update variables. BnB-ADOPT
uses heuristic values haX1a,a1 2 (0) := 3, haX1a,a1 2 (1) := 6, haX2a,a2 3 (0) := 2, haX2a,a2 3 (1) := 2, haX2a,a2 4 (0) := 2
haX2a,a2 4 (1) := 2 contexts X a1 X a2 . heuristic values chosen hand. Every
agent assigns value ancestor agents initial context 0. partition time
cycles Figures 7 8 continue use conventions made context gures.
Cycle 1: Root agent a1 initializes context X a1 {} [Line 1]. initializes lower bounds
nodes B (= lbaX1a,a1 2 (0)) C (= lbaX1a,a1 2 (1)) heuristic values 3 6, respectively
a1
[Line 13]. updates lower bound node (= LBX
a1 (0)) sum delta cost
(= 0) lower bound node B (= 3) according update equations [Line 19].
a1
updates lower bound node b (= LBX
a1 (1)) sum delta cost (= 0)
lower bound node C (= 6) according update equations [Line 19]. updates
a1
lower bound node (= LBX
a1 ) minimum lower bound node (= 3)
lower bound node b (= 6) according update equations [Line 21]. initializes
upper bounds nodes B C innity [Line 14]. updates upper bounds nodes a,
b innity according update equations [Lines 20 22]. takes best
value 0 since lower bound node (= 3) smaller lower bound node b (= 6)
[Line 15], initializes ID IDa1 1 [Lines 2 16], initializes threshold H a1 innity
[Line 17] sends VALUE messages child agent a2 pseudo-child agent a3 [Lines 30
31].
Agent a2 initializes context X a2 {(a1 , 0, 0)} [Line 1]. initializes lower bounds
nodes D, E, F G heuristic value 2 [Line 13]. updates lower bounds nodes
c, B 9, 12 9, respectively [Lines 19 21]. initializes upper bounds
nodes D, E, F G innity [Line 14]. updates upper bounds nodes c, B
innity [Lines 20 22]. bounds node B agent a2 maintains shown
107

fiYeoh, Felner & Koenig

Cycle
X a1
da1
ID a1
H a1
LB a1 (0)
LB a1 (1)
LB a1
U B a1 (0)
U B a1 (1)
U B a1
lba1 ,a2 (0)
lba1 ,a2 (1)
uba1 ,a2 (0)
uba1 ,a2 (1)
X a2
da2
ID a2
H a2
LB a2 (0)
LB a2 (1)
LB a2
U B a2 (0)
U B a2 (1)
U B a2
lba2 ,a3 (0)
lba2 ,a3 (1)
uba2 ,a3 (0)
uba2 ,a3 (1)
lba2 ,a4 (0)
lba2 ,a4 (1)
uba2 ,a4 (0)
uba2 ,a4 (1)
X a3
da3
ID a3
H a3
LB a3 (0)
LB a3 (1)
LB a3
U B a3 (0)
U B a3 (1)
U B a3
X a4
da4
ID a4
H a4
LB a4 (0)
LB a4 (1)
LB a4
U B a4 (0)
U B a4 (1)
U B a4

1

2

3

4

5

6

7

8

9

0
1

3
6
3



3
6


(a1 , 0, 0)
0
1

9
12
9



2
2


2
2


(a1 , 0, 0)
(a2 , 0, 0)
0
1

10
14
10
10
14
10
(a2 , 0, 0)
0
1

3
8
3
3
8
3

0
1

9
6
6



9
6


(a1 , 0, 1)
1
2

18
12
12
18

18
10
2
10

3
2
3

(a1 , 0, 1)
(a2 , 0, 1)
0
1

10
14
10
10
14
10
(a2 , 0, 1)
0
1

3
8
3
3
8
3

0
1

12
6
6
18

18
12
6
18

(a1 , 0, 1)
1
2

18
12
12
18

18
10
2
10

3
2
3

(a1 , 0, 1)
(a2 , 1, 2)
0
2
8
8
13
8
8
13
8
(a2 , 1, 2)
1
2
8
10
3
3
10
3
3

0
1

12
6
6
18

18
12
6
18

(a1 , 0, 1)
0
3
18
18
19
18
18
19
18
10
8
10
8
3
3
3
3
(a1 , 0, 1)
(a2 , 1, 2)
0
2
8
8
13
8
8
13
8
(a2 , 1, 2)
1
2
8
10
3
3
10
3
3

1
2

18
6
6
18

18
18
6
18

(a1 , 0, 1)
0
3
18
18
19
18
18
19
18
10
8
10
8
3
3
3
3
(a1 , 0, 1)
(a2 , 0, 3)
0
3
10
10
14
10
10
14
10
(a2 , 0, 3)
0
3
3
3
8
3
3
8
3

1
2

18
6
6
18

18
18
6
18

(a1 , 1, 2)
1
4
18
25
8
8



2
2


3
3
3
3
(a1 , 1, 2)
(a2 , 0, 3)
1
4
10
25
7
7
25
7
7
(a2 , 0, 3)
0
3
3
3
8
3
3
8
3

1
2

18
8
8
18

18
18
8
18

(a1 , 1, 2)
1
4
18
30
8
8
30

30
7
2
7

3
3
3
3
(a1 , 1, 2)
(a2 , 1, 4)
1
5
12
23
6
6
23
6
6
(a2 , 1, 4)
1
4
13
10
3
3
10
3
3

1
2

18
8
8
18
30
18
18
8
18
30
(a1 , 1, 2)
1
4
18
30
12
12
30
12
12
7
6
7
6
3
3
3
3
(a1 , 1, 2)
(a2 , 1, 4)
1
5
12
23
6
6
23
6
6
(a2 , 1, 4)
1
4
13
10
3
3
10
3
3

1
2

18
12
12
18
12
12
18
12
18
12
(a1 , 1, 2)
1
4
18
30
12
12
30
12
12
7
6
7
6
3
3
3
3
(a1 , 1, 2)
(a2 , 1, 4)
1
5
6
23
6
6
23
6
6
(a2 , 1, 4)
1
4
3
10
3
3
10
3
3

Table 2: Trace Update Variables BnB-ADOPT

108

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm





3



6







b



3

6



9



B

C



3

6



9

c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

J
r



K


9



u



v



12

2

2

10 14 3

8

X

2

X

X

X

X

X X

X X

X X

X X

X X

X X





6

18



2

Identifiers

10

12
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

6





12

6



12

6



18



12

6



12

6



18

18







12

10

3

X X

X X

2

X
2

8 13 10 3

X

18



X

X

X

X

X X

X X

X X

X X





19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X





10

19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

8



18

6



18

8



18



18

6



18

8



18

X





X

X

X

X

X X

X X

X X

25
X

2

X X 25 7

8
3

3

8

X



2

3

X X

X X





X

30

X

X

X

X

7

X X

X X

X X

X X

X X

Cycle 6

8
3

2

3

X X 23 6 10 3



8
X

30

X

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 8

12





18



18

12
12

X







8

X



Cycle 7



X

3

Cycle 5

8



X

8





6

18



X

6

Cycle 4

6



X
3

X

2

Cycle 2

6



X

2

Cycle 1

6



X

6

X

30

X

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 9

Figure 10: Trace Update Lower Bounds BnB-ADOPT
gure. takes best value 0 [Line 15], initializes ID 1 [Lines 2 16],
initializes threshold innity [Line 17] sends VALUE messages child agents a3
a4 COST message parent agent a1 [Lines 30-32].
Leaf agent a3 initializes context X a3 {(a1 , 0, 0), (a2 , 0, 0)} [Line 1]. updates lower
bounds nodes g h delta costs 10 14, respectively, since leaf agents
child agents [Line 19]. updates lower bound node 10 [Line 21]. updates
upper bounds nodes g h delta costs 10 14, respectively, since leaf agents
child agents [Line 20]. updates upper bound node 10 [Line 22].
bounds node leaf agent a3 maintains shown gure. takes
best value 0 [Line 15], initializes ID 1 [Lines 2 16], initializes threshold innity
[Line 17] sends COST message parent agent a2 [Line 32].
Leaf agent a4 initializes (reduced) context X a4 {(a2 , 0, 0)} [Line 1]. updates lower
bounds nodes j delta costs 3 8, respectively [Line 19]. updates
lower bound node E 3 [Line 21]. updates upper bounds nodes j
delta costs 3 8, respectively [Line 20]. updates upper bound node E 3 [Line
22]. bounds node E leaf agent a4 maintains shown gure. takes

109

fiYeoh, Felner & Koenig





inf



inf







b



inf

inf



inf



B

C



inf

inf



inf

c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

J
r



inf



K


u



v



inf

inf
inf

10 14 3

8

X

inf

X

X

X

X

X X

X X

X X

X X

X X

X X

10





inf
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 2

18



18



18

inf



18

inf



18



18

inf



18

inf



18

18





inf

10

3

X X

X X

inf

X
inf

8 13 10 3

X

18



X

X

X

X

X X

X X

X X

X X





19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X

10





19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

18



18

inf



18

inf



18



18

inf



18

inf



18

X





X

X

X

X

X X

X X

X X

inf
X

inf

X X 25 7

inf
3

3

8

X



inf

3

X X

X X





X

30

X

X

X

X

7

X X

X X

X X

X X

X X

Cycle 6

inf
3

inf

3

X X 23 6 10 3

30

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 8

12





18



18

12
12

X





30
X

X





30

X



Cycle 7



X

3

Cycle 5

18



X

8





inf

18



X

inf

Cycle 4

18



X
3

X

inf

Cycle 1

18

X

inf





inf

18



inf

Identifiers


X

inf

X

30

X

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 9

Figure 11: Trace Update Upper Bounds BnB-ADOPT
best value 0 [Line 15], initializes ID 1 [Lines 2 16], initializes threshold
innity [Line 17] sends COST message parent agent a2 [Line 32].
summary, following messages sent Cycle 1:
message (VALUE, a1 , 0, 1, ) agent a1 agent a2 ;
message (VALUE, a1 , 0, 1, ) agent a1 agent a3 ;
message (VALUE, a2 , 0, 1, ) agent a2 agent a3 ;
message (VALUE, a2 , 0, 1, ) agent a2 agent a4 ;
message (COST, a2 , {(a1 , 0, 0)}, 9, ) agent a2 agent a1 ;
message (COST, a3 , {(a1 , 0, 0), (a2 , 0, 0)}, 10, 10) agent a3 agent a2 ;
message (COST, a4 , {(a2 , 0, 0)}, 3, 3) agent a4 agent a2 .
Cycle 2: Root agent a1 receives COST message sent child agent a2 Cycle 1. Since
context agent a1 (= {}) compatible context message (= {(a1 , 0, 0)}),
improves bounds. updates bounds node B bounds message (= 9
innity, respectively) [Lines 48-50]. updates bounds nodes a, b [Lines 18-22].
110

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

a1
a1
change value since lower bound node (= LBX
) = 9 value
a1 (d
a1
a1
a1
= 0) still smaller pruning quantity (= min{T HX a1 , U BX a1 } = min(, ) =
). sends VALUE messages child agent a2 pseudo-child agent a3 [Lines 30-31].

Agent a2 receives VALUE message sent parent agent a1 Cycle 1. updates
context {(a1 , 0, 0)} {(a1 , 0, 1)} since ID agent a1 context (= 0) smaller
ID message (= 1) [Line 34]. threshold (= ) remains unchanged since
desired threshold (= ) message. Agent a2 receives COST
messages sent child agents a3 a4 Cycle 1. Since context (= {(a1 , 0, 1)}) compatible contexts messages (= {(a1 , 0, 0), (a2 , 0, 0)} {(a2 , 0, 0)}, respectively),
improves bounds. updates bounds node bounds rst message
(= 10 10, respectively) bounds node E bounds second message (= 3
3, respectively) [Lines 48-50]. updates bounds nodes c, B [Lines 18-22].
a2
a2
) = 18 value da2 = 0)
changes value since lower bound node c (= LBX
a2 (d
a2
a2
longer smaller pruning quantity (= min{T HX a2 , U BX
a2 } = min(, 18) = 18).
takes best value 1 [Line 24], increments ID 2 [Lines 25-26], sends VALUE messages
child agents a3 a4 [Lines 30-31] sends COST message parent agent a1
[Line 32].
Leaf agent a3 receives VALUE messages sent parent agent a2 pseudo-parent
agent a1 Cycle 1. updates context {(a1 , 0, 0), (a2 , 0, 0)} {(a1 , 0, 1), (a2 , 0, 1)}
since IDs agents a1 a2 context (= 0 0, respectively) smaller
IDs messages (= 1 1, respectively) [Line 34]. threshold (= ) remains
unchanged since desired threshold (= ) message. bounds
reinitialized since context compatible previous context [Line 35]. sends
COST message parent agent a2 [Line 32].
Leaf agent a4 receives VALUE message sent parent agent a2 Cycle 1. updates
contexts {(a2 , 0, 0)} {(a2 , 0, 1)} since ID agent a2 context (= 0) smaller
ID message (= 1) [Line 34]. threshold (= ) remains unchanged since
desired threshold (= ) message. bounds reinitialized since
context compatible previous context [Line 35]. sends COST message
parent agent a2 [Line 32].
summary, messages sent Cycle 2 identical ones sent Cycle 1,
except messages sent agents a2 , a3 a4 , follows:
message (VALUE, a2 , 1, 2, 8) agent a2 agent a3 ;
message (VALUE, a2 , 1, 2, 8) agent a2 agent a4 ;
message (COST, a2 , {(a1 , 0, 1)}, 12, 18) agent a2 agent a1 .
message (COST, a3 , {(a1 , 0, 1), (a2 , 0, 1)}, 10, 10) agent a3 agent a2 ;
message (COST, a4 , {(a2 , 0, 1)}, 3, 3) agent a4 agent a2 .
VALUE messages dierent agent a2 changed value 0 1. COST
messages dierent agent a2 changed bounds context agents a3
a4 changed contexts.
Cycles 3-9: messages sent Cycle 3 identical ones sent Cycle 2,
except messages sent agents a3 a4 , follows:
message (COST, a3 , {(a1 , 0, 1), (a2 , 1, 2)}, 8, 8) agent a3 agent a2 ;
message (COST, a4 , {(a2 , 1, 2)}, 3, 3) agent a4 agent a2 .

111

fiYeoh, Felner & Koenig

COST messages dierent agents a3 a4 changed contexts.
termination conditions holds nite amount time upper bound node
a1
a1
(= U BX
a1 = 12) larger lower bound node (= LBX a1 = 12) [Line 27]. Root
agent a1 sends TERMINATE messages child agents [Line 28], TERMINATE
messages propagate pseudo-tree [Line 28] agents terminate. BnB-ADOPT
terminates nine cycles minimal solution cost 12.

4. Bounded-Error Approximations
section, present three approximation mechanisms allow BnB-ADOPT trade
solution cost smaller runtime. bound error solution cost user-dened
error bound. First, modify Absolute Error Mechanism ADOPT (Modi et al., 2005)
work BnB-ADOPT. approximation mechanism allows users specify absolute error
bound solution cost (for example, solution cost 10 larger
minimal solution cost). However, often much desirable specify relative error bound
solution cost (for example, solution cost 10 percent larger
minimal solution cost or, equivalently, 1.1 times larger minimal solution cost). cannot
done Absolute Error Mechanism without knowing minimal solution cost priori.
Thus, introduce two approximation mechanisms allow users specify relative error bound
solution cost, namely Relative Error Mechanism Weighted Heuristics Mechanism.
approximation mechanisms let root agent r (and root agent) maintain
limit limr . root agent uses limit way termination condition
r
r
approximation mechanisms updates dierently. termination condition U BX
r LBX r
r
r
Line 27 pseudocode BnB-ADOPT replaced U BX r lim . root agent updates
limit Lines 26 27 pseudocode, outside preceding statement.
4.1 Absolute Error Mechanism
Absolute Error Mechanism ADOPT requires user-dened absolute error bound 0 b <
species solution cost b larger minimal solution cost.
approximation mechanism easily modied BnB-ADOPT setting limit follows:
limr

:=

r
b + LBX
r

(20)

BnB-ADOPTAEM resulting variant BnB-ADOPT Absolute Error Mechanism.
BnB-ADOPTAEM terminates upper bound root node (which equal solution
cost solution smallest solution cost found far) larger limit (which
equal absolute error bound b plus lower bound root node, lower
bound minimal solution cost). BnB-ADOPTAEM terminates solution cost
equal upper bound root node although minimal solution cost could small
lower bound root node. thus terminates solution cost b larger
minimal solution cost. Figure 12 shows trace BnB-ADOPTAEM absolute error
bound b = 24 example DCOP problem. BnB-ADOPTAEM terminates three cycles
suboptimal solution cost 18, six cycles faster BnB-ADOPT.
4.2 Relative Error Mechanism
often much desirable specify relative error bound solution cost rather
absolute error bound. Fortunately, Absolute Error Mechanism BnB-ADOPT easily
changed Relative Error Mechanism setting limit follows. Relative Error
112

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm



3





lim 1 = 27

UB 1 = infinity



lim 1 = 30

UB 1 = infinity

6



6





3

6



9

6



12



3

6



9

6



12

9







2

12
2

10 14 3

8

X

X

18



2

2

X

X

X

X

X X

X X

X X

X X

X X

X X





10

12
3

10 14 3

8

X

X

2

2

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 1





6
6

18



lim 1 = 30

UB 1 = 18

12

10

3

X X

X X

2

X
2

8 13 10 3

Cycle 2

X

X

X

X

X

X X

X X

X X

X X

Cycle 3

Figure 12: Trace Update Lower Bounds BnB-ADOPTAEM b = 24


3





lim 1 = 9

UB 1 = infinity



lim 1 = 18

UB 1 = infinity

6



6





3

6



9

6



12



3

6



9

6



12

9







2

12
2

10 14 3

8

X

X

18



2

2

X

X

X

X

X X

X X

X X

X X

X X

X X





10

12
3

10 14 3

8

X

X

2

2

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 1

Cycle 2





6
6

18



lim 1 = 18

UB 1 = 18

12

10

3

X X

X X

2

X
2

8 13 10 3

X

X

X

X

X

X X

X X

X X

X X

Cycle 3

Figure 13: Trace Update Lower Bounds BnB-ADOPTREM p = 3
Mechanism requires user-dened relative error bound 1 p < species solution
cost p times larger minimal solution cost:
limr

r
:= p LBX
r

(21)

BnB-ADOPTREM resulting variant BnB-ADOPT Relative Error Mechanism.
BnB-ADOPTREM terminates upper bound root node (which equal solution
cost solution smallest solution cost found far) larger limit (which
equal relative error bound p times lower bound root node, lower
bound minimal solution cost). BnB-ADOPTREM terminates solution cost
equal upper bound root node although minimal solution cost could small
lower bound root node. thus terminates solution cost p times
larger minimal solution cost. Figure 13 shows trace BnB-ADOPTREM relative
error bound p = 3 example DCOP problem. BnB-ADOPTREM terminates three cycles
suboptimal solution cost 18, six cycles faster BnB-ADOPT.
4.3 Weighted Heuristics Mechanism
second way implementing relative error bound BnB-ADOPT since BnB-ADOPT
uses admissible heuristic values. common practice context A* trade solution
cost smaller runtime using weighted heuristic values (Pohl, 1973), derived
admissible heuristic values multiplying user-dened weight 1 w < .
resulting heuristic values inadmissible. A* longer guaranteed nd cost-minimal
solutions guaranteed terminate solution cost w times larger
minimal solution cost (Pohl, 1970). approximation mechanism easily modied
BnB-ADOPT setting limit follows:
limr

:=

113

r
LBX
r

(22)

fiYeoh, Felner & Koenig



9





lim 1 = 9

UB 1 = infinity



lim 1 = 17

lim 1 = 18

17 UBa1 = infinity



18 UBa1 = 18





9

18



17

18



20



9

18



17

18



20

17







6

20
6

10 14 3

8

X

X

21



6

6

X

X

X

X

X X

X X

X X

X X

X X

X X





10

20
6

10 14 3

8

X

X

6

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 1

Cycle 2





18

21



6

18

20

10

6

X X

X X

6

X
6

8 13 10 3

X

X

X

X

X

X X

X X

X X

X X

Cycle 3

Figure 14: Trace Update Lower Bounds BnB-ADOPTW HM w = 3
initializing lower bounds lba,c
X (d) follows:
lba,c
X (d)

:= w ha,c
X (d)

(23)

agents a, values d, child agents c contexts X . BnB-ADOPTW HM
resulting variant BnB-ADOPT Weighted Heuristics Mechanism. BnB-ADOPTW HM
terminates upper bound root node (which equal solution cost solution
smallest solution cost found far) larger limit (which equal lower
bound root node, lower bound w times minimal solution cost). BnBADOPTW HM terminates solution cost equal upper bound root node
although minimal solution cost could small lower bound root node divided
w. thus terminates solution cost w times larger minimal
solution cost. Figure 14 shows trace BnB-ADOPTW HM w = 3 example DCOP
problem. BnB-ADOPTW HM terminates three cycles suboptimal solution cost 18,
six cycles faster BnB-ADOPT.

5. Correctness Completeness
section, prove correctness completeness BnB-ADOPT suboptimal
variants. denitions, lemmata, theorems corollaries hold BnB-ADOPT suboptimal variants except mentioned otherwise. Therefore, agent uses following update
equation values d, child agents c contexts X initialize bounds lba,c
X (d):
a,c
lba,c
X (d) := w hX (d)

(24)

weight w oating point number satises 1 w < heuristic values
ha,c
X (d) oating point numbers satisfy
c
0 ha,c
X (d) X (a,d)

(25)

Messages sent end cycle received beginning cycle. largest
duration time message sent time processed, largest duration
cycle.
Lemma 1. two contexts X X arbitrary agent agree values ancestor


= X
agents p SCP (a) agent a, X
.
Proof. denition, X X (reduced) context contains values ancestor agents

sum constraint costs constraints
p SCP (a) agent a. gamma cost X
114

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

involve agent one descendant agents minimized possible values agent
descendant agents, assumption ancestor agents agent take values

thus depends values ancestor agents (including
context X. gamma cost X
parent agent) agent parent pseudo-parent agents agent one (or more)
descendant agents, is, values ancestor agents p SCP (a) agent a. Therefore,




= X
X
. Similarly, X = X .
Definition 1. Contexts correct IDs values agents contexts equal
IDs agents, implies values agents contexts equal
values agents.
Lemma 2. context X arbitrary agent change period time,


lower bounds lba,c
X (d), LBX (d) LBX monotonically non-decreasing upper
a,c


bounds ubX (d), U BX (d) U BX monotonically non-increasing period time
values Dom(a) child agents c C(a).

Proof. Since context X change, delta values X
(d) constant bounds
(once initialized) updated according update equations 8 13. Thus, lower bounds
monotonically non-decreasing upper bounds monotonically non-increasing.

Lemma 3. value arbitrary ancestor agent p SCP (a) arbitrary agent
change current time future time + |A| ( + ) + ,
value agent p ID context agent equal value agent p ID,
respectively, time time t.
Proof. Assume value arbitrary ancestor agent p SCP (a) arbitrary agent
change current time future time + |A| ( + ) + .
following two cases.
Case 1: agent p parent pseudo-parent agent agent a, sent VALUE message
agent value ID time + , is, cycle took
value time since duration cycle larger . (The
agents send VALUE messages end every cycle.) Agent receives VALUE message
time + since messages delivered nite delay . updates value
agent p ID context time + + since update done cycle
duration cycle larger . Thus, value agent p ID
context agent equal value agent p ID, respectively,
time time + + + + 2 since agent p change
value time time t.
Case 2: agent p parent pseudo-parent agent agent a, one pseudo-child
agents c descendant agent agent a. Agent p sent VALUE message agent c
value ID time + . Agent c receives VALUE message time + .
updates value agent p ID context sends COST message parent
agent pa(c) updated context time + + . (The agents send COST messages
end every cycle.) Agent pa(c) receives COST message time + 2 + .
updates value agent p ID context sends COST message parent
agent pa(pa(c)) updated context time + 2 ( + ). process continues
agent updates value agent p ID context time + n ( + ),
n |A| number messages chain messages. Thus, value agent p
ID context agent equal value agent p ID, respectively,
time time + n ( + ) + |A| ( + ) + since agent
p change value time time t.

115

fiYeoh, Felner & Koenig

Corollary 1. values ancestor agents p SCP (a) arbitrary agent
change current time future time + |A| ( + ) + , context
agent correct time time t.
c
c
c
Lemma 4. LBX
c w X c w U BX c times child agents c C(a) arbitrary
a,c
a,c
c
c
agent contexts X , lbX (d) w X
(a,d) w ubX (d) times context
X agent a, values Dom(a) child agents c C(a).

Proof. prove lemma induction number times agent changes context
a,c
updates bounds lba,c
X (d) ubX (d) arbitrary value arbitrary child agent c
agent initializes bounds. conclusion lemma holds agent context
X initializes bounds since
a,c
lba,c
X (d) = w hX (d)

(Eq. 24)

w

(Eq. 25)

c
X
(a,d)


= w uba,c
X (d)

(Eq. 7)

(unchanged new) context X agent (induction basis). assume lemma
holds agent changed context updated bounds number times (induction assumption). show holds agent changes context updates bounds one
time (induction step). following two cases (where split operations
receiving COST message two parts).
Case 1: conclusion lemma holds agent changes context X X
receiving VALUE COST message two contexts agree values
ancestor agents p SCP (c) since agent change bounds thus
(d) = lba,c
lba,c
X (d)
X
c
w X
(a,d)

(induction assumption)

c
w X
(a,d)
a,c
ubX (d)
c
X
(a,d)
c
X (a,d)

(Lemma 1)

=
uba,c
(d)
X

(premise case)

=

=

(premise case)
(induction assumption)
(Lemma 1)

receiving VALUE COST message (since contexts X X agree values
ancestor agents p SCP (c)).
Case 2: conclusion lemma holds agent updates bounds lba,c
X (d)
a,c
a,c
a,c


ubX (d) lbX (d) ubX (d), respectively, receiving COST message child
c
c
c
agent c bounds LBX
compatible context X
c U BX c context X
agent value since

116

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

a,ca (d) = max{lba,ca (d), LB c c }
lb
X
X
X
c
c
max{w X
(a,d) , w X c }

(Eq. 8)
(induction assumption premise lemma)

c
c
= max{w X
(a,d) , w X (a,d) }

=w
a,ca (d)
ub
X

(Lemma 1)

c
X
(a,d)

c
= min{uba,c
X (d), U BX c }
c
c
min{X
(a,d) , X c }

(Eq. 11)
(induction assumption premise lemma)

c
c
= min{X
(a,d) , X (a,d) }

=

(Lemma 1)

c
X
(a,d)

receiving COST message (since contexts X (a, d) X c agree values
ancestor agents p SCP (c)).
a,c
c
Thus, lba,c
X (d) w X (a,d) w ubX (d) times values Dom(a) child
agents c C(a).






Lemma 5. LBX
(d) w X (d) w U BX (d) LBX w X w U BX times

values Dom(a) context X arbitrary agent A.

Proof. prove lemma induction depth agent pseudo-tree. lemma
holds leaf agent pseudo-tree context X since


LBX
(d) = X (d)

(Eq. 9)


X
(d)

X (d)

X
(d)

(Eq. 1)
(Eq. 12)

=

U BX
(d) =
=

(Eq. 1)





values times. Thus, LBX
(d) = X (d) w X (d) = w U BX (d) values
times. Furthermore,


LBX
=

=


U BX


min


{LBX
(d)}

(Eq. 10)

dDom(a)

min


{X
(d)}

(see above)

dDom(a)


= X

= min

(Eq. 2)
(Eq. 13)


{U BX
(d)}
dDom(a)

=

min


{X
(d)}

(see above)

dDom(a)

= X


(Eq. 2)





times. Thus, LBX
= X w X = w U BX times (induction basis). assume
lemma holds agents depth pseudo-tree (induction assumption). show
holds agents depth 1 pseudo-tree time update
bounds (induction step). lemma holds agent context X since

117

fiYeoh, Felner & Koenig





LBX
(d) = X (d) +

lba,c
X (d)

(Eq. 9)

cC(a)




X
(d) +

c
w X
(a,d)

(induction assumption Lemma 4)

cC(a)

w X
(d)


U BX
(d) = X (d) +

(Eq. 1)



uba,c
X (d)

(Eq. 12)

cC(a)




X
(d) +

c
X
(a,d)

(induction assumption Lemma 4)

cC(a)

= X
(d)

(Eq. 1)




Thus, LBX
(d) w X (d) w U BX (d) times values Dom(a). Furthermore,


LBX
=



min


{LBX
(d)}

(Eq. 10)

dDom(a)

min


{w X
(d)}

(see above)

dDom(a)

=w

min


{X
(d)}

dDom(a)


= w X


U BX


=


(Eq. 2)


min {U BX
(d)}
dDom(a)

min

(Eq. 13)


{X
(d)}

(see above)

dDom(a)


= X


(Eq. 2)




Thus, LBX
w X w U BX times.

Definition 2. potential agent context X

LBX
(d)}.



dDom(a) {w


U BX
(d)

Lemma 6. context X arbitrary agent longer changes, potential
agent monotonically non-increasing decreases positive constant every time
agent changes value.


Proof. lower bounds LBX
(d) monotonically non-decreasing upper bounds U BX (d)
monotonically non-increasing values according Lemma 2 since context X
agent longer changes. Therefore, potential agent monotonically non-increasing.


Furthermore, agent changes value new value mindDom(a) {LBX
(d)} < LBX (d)

[Line 24]. Thus, lower bound LBX (d) must strictly increased time
agent changed value time changes value new value. Thus,
potential decreased positive constant, namely smallest possible increase

lower bound LBX
(d). Assume constraint costs, weights heuristic values integers.
Then, smallest possible increase bounded one possible values

LBX
(d) combinations constraint costs weighted heuristic values. similar statement
holds constraint costs, weights heuristic values oating point numbers since
transformed integers multiplying suciently large integer.

Lemma 7. agents change values nite number times.
118

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Proof. Assume lemma hold choose agent changes value
innite number times whose ancestor agents p SCP (a) change values nite
number times. Then, exists time ancestor agents change values
longer. exists (later) time agent longer changes context X according
Corollary 1. Every time agent changes value afterwards, potential decreases
positive constant according Lemma 6, towards minus innity. However, potential cannot


become negative since LBX
(d) w U BX (d) values according Lemma 5,
contradiction. Thus, agents change values nite number times.

Lemma 8. BnB-ADOPT suboptimal variants terminate earlier, U BX



LBX nite amount time agents contexts X .

Proof. prove lemma induction depth agent pseudo-tree. exists
time agent changes value longer according Lemma 7. exists (later)
time contexts agents correct longer change according Corollary 1. Let
X context agent point time agents a. exists (even later)
a,c




time bounds lba,c
X (d), LBX (d), LBX , ubX (d), U BX (d) U BX longer change

agents a, values child agents c since (1) lower bounds lba,c
X (d), LBX (d)
a,c



LBX monotonically non-decreasing upper bounds lbX (d), U BX (d) U BX

monotonically non-increasing agents a, values child agents c according Lemma






2, (2) LBX
(d) w X (d) w U BX (d) LBX w X w U BX agents
a,c
a,c
values according Lemma 5, (3) lbX (d) w ubX (d) agents a, values
child agents c according Lemma 4 (4) smallest possible increases lower bounds
smallest possible decreases upper bounds larger positive constant since
possible values bounds combinations constraint costs heuristic values,
explained detail proof Lemma 6. Consider rst COST message agent
sends time earliest time COST messages processed
receiving agents. lemma holds leaf agent pseudo-tree context X since


LBX
(d) = X (d)

= X
(d)

(Eq. 9)
(Eq. 1)



U BX
(d) = X (d)

= X
(d)

(Eq. 12)
(Eq. 1)

values considered time. Furthermore,

LBX
=

=


U BX


min


{LBX
(d)}

min


{X
(d)}

(Eq. 10)

dDom(a)

(see above)

dDom(a)


= X

= min

(Eq. 2)
(Eq. 13)


{U BX
(d)}
dDom(a)

=

min


{X
(d)}

(see above)

dDom(a)


= X


(Eq. 2)



considered time. Thus, U BX
= LBX considered time (induction basis).
assume lemma holds agents depth pseudo-tree considered time
(induction assumption). show holds agents depth 1 pseudotree considered time (induction step). agent context X

119

fiYeoh, Felner & Koenig



LBX
(d) = X (d) +



lba,c
X (d)

(Eq. 9)

c
max{lba,c
X (d), LBX c }

(Eq. 8)

cC(a)

= X
(d) +



cC(a)

X
(d) +



c
LBX
c

cC(a)




X
(d)

+



c
U BX
c

(induction assumption)

cC(a)

X
(d) +



c
min{uba,c
X (d), U BX c }

cC(a)

=


X
(d)

+



uba,c
X (d)

(Eq. 11)

cC(a)

= U BX
(d)

(Eq. 12)


value considered time since bounds longer change. Thus, U BX
(d)

(d)


value



considered
time.
Since
agent



change

value

LBX





considered time, must hold LBX
(d)
<
min{T
H
,
U
B
}
[Line
23]

LB

Xa
Xa
X (d) =

mindDom(a) {LBX
(d)}
[Line
24].

rst
disjunct
implies






min{T HX
, U BX } U BX

U BX
(d)

LBX (d)

(Eq. 13)
(see above)



< min{T HX
, U BX }

(rst disjunct)

value d, contradiction. second disjunct implies


U BX
U BX (d)

LBX
(d)

=

min

(Eq. 13)
(see above)


{LBX
(d)}

(second disjunct)

dDom(a)


= LBX


(Eq. 10)



value thus U BX
LBX .

Theorem 1. BnB-ADOPT suboptimal variants terminate nite amount time.


Proof. BnB-ADOPT suboptimal variants terminate earlier, U BX
LBX
nite amount time agents contexts X according Lemma 8.
r
r
r
r
particular, U BX
root agent r, limr = LBX
r LBX r lim
r BnB-ADOPT
r
r

b

0

BnB-ADOPT

limr = p LBX
BnB-ADOPTW HM , limr = b + LBX
r
r
AEM
p 1 BnB-ADOPTREM according Section 4. Thus, termination condition
r
r
r
r
U BX
suboptimal
r LBX r BnB-ADOPT termination condition U BX r lim
variants satised.
r
Theorem 2. BnB-ADOPT terminates minimal solution cost X
r.

120

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Proof. BnB-ADOPT terminates nite amount time according Theorem 1. solution
r
r
r
cost BnB-ADOPT upper bound U BX
r root agent r. U BX r LBX r upon termination
r
r
r
according termination condition. w U BX r w X r LBX r according Lemma 5.
r
r
r
Therefore, U BX
r = X r = LBX r since w = 1.
Theorem 3. BnB-ADOPTAEM terminates solution cost bounded
r
user-dened absolute error bound b plus minimal solution cost X
r.
Proof. BnB-ADOPTAEM terminates nite amount time according Theorem 1.
r
r
r
solution cost BnB-ADOPTAEM upper bound U BX
r root agent r. U BX r lim =
r
r
r
b + LBX r upon termination according termination condition. LBX r w X r according
r
r
Lemma 5. Therefore, U BX
r b + X r since w = 1.
Theorem 4. BnB-ADOPTREM terminates solution cost bounded
r
user-dened relative error bound p times minimal solution cost X
r.
Proof. BnB-ADOPTREM terminates nite amount time according Theorem 1.
r
r
r
solution cost BnB-ADOPTREM upper bound U BX
r root agent r. U BX r lim =
r
r
r
p LBX r upon termination according termination condition. LBX r w X r according
r
r
Lemma 5. Therefore, U BX
r p X r since w = 1.
Theorem 5. BnB-ADOPTW HM terminates solution cost bounded
r
user-dened weight w times minimal solution cost X
r.
Proof. BnB-ADOPTW HM terminates nite amount time according Theorem 1.
r
r
r
solution cost BnB-ADOPTW HM upper bound U BX
r root agent r. U BX r lim =
r
r
r
upon
termination
according


termination
condition.
LB

w


according

LBX
r
Xr
Xr
r
r
Lemma 5. Therefore, U BX

w


.
r
Xr

6. Experimental Evaluations
section, compare BnB-ADOPT two memory-bounded DCOP search algorithms
restrict communication agents share constraints, namely ADOPT NCBB.
compare three suboptimal variants BnB-ADOPT other. use distributed
DFS algorithm max-degree heuristic (Hamadi, Bessiere, & Quinqueton, 1998) used
ADOPT construct pseudo-trees. use DP2 (Ali et al., 2005) used ADOPT
pre-calculate heuristic values ADOPT BnB-ADOPT. DP2 solves relaxed version
given DCOP problem (where backedges ignored) dynamic programming based approach.
NCBB calculates heuristic values search rather pre-processing step.
6.1 Runtime Metrics
use two common runtime metrics, namely non-concurrent constraint checks (Meisels, Kaplansky,
Razgon, & Zivan, 2002) cycles (Modi et al., 2005).
Non-concurrent constraint checks (NCCCs): NCCCs weighted sum processing
communication time. Every agent maintains counter N CCC , initialized
0. agent assigns N CCC := N CCC + 1 every time performs constraint check
account time takes perform constraint check. assigns N CCC :=

max{N CCC , N CCC + t} every time receives message agent account

time takes wait agent send message (N CCC ) transmission time
message (t). use = 0 simulate fast communication = 1000 simulate
slow communication. number NCCCs largest counter value agent.

121

fiYeoh, Felner & Koenig

Sensors
1
3

2

Targets
5

6

7

8

9

4
10

11

12

13

Constraints

unit

Figure 15: Example: Allocating Targets

Figure 16: Example: Scheduling Meetings

NCCCs good runtime metric ratio processing communication time
estimated reliably.
Cycles: Cycles time slices. cycle time required agent process incoming
messages queue send outgoing messages, processed receiving
agents next cycle. Thus, number cycles indicates length longest chain
messages agents. Cycles good runtime metric communication time
much larger processing time. Cycles become better better runtime metric
future since communication time expected remain relatively stable
processing time expected decrease (Silaghi, Lass, Sultanik, Regli, Matsui, & Yokoo, 2008).
6.2 DCOP Problem Types
use three DCOP problem types experiments, namely graph coloring problems, sensor
network problems meeting scheduling problems.
Graph coloring: Graph coloring problems involve coloring vertices graph, taking
restrictions colors adjacent vertices account. agents vertices,
domains colors, constraints adjacent vertices. vary
number vertices 5 15, constraint density (= ratio number
constraints number agents) 2 (sparse graphs) 3 (dense graphs)
range constraint costs range 0 1 (small range) range 0 10,000 (large
range). agent always three possible values. average experimental results
50 DCOP problem instances randomly generated constraints randomly generated
integer constraint costs.
Sensor network: Sensor network problems involve assigning targets sensors sensor
network, taking restrictions availability sensors, restrictions number
sensors need track target priorities targets account.
agents targets, domains time slots tracked,
constraints adjacent targets (Maheswaran et al., 2004b). Figure 15 shows sensor
network targets located grid target surrounded four sensors,
needed track target. vary number targets 4 15.
always use 8 time slots. cost assigning time slot target assigned
adjacent target innity (to precise: 1,000,000) since sensor cannot track
targets time slot. cost targets tracked time
slot 100. costs range 0 100. average experimental results
50 DCOP problem instances randomly generated integer constraint costs.
Meeting scheduling: Meeting scheduling problems involve scheduling meetings
employees company, taking restrictions availability well priorities
account. agents meetings, domains time slots
held, constraints meetings share participants (Maheswaran et al.,
122

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Graph Coloring, Density = 2
Communication Cost = 0

Graph Coloring, Density = 2
Communication Cost = 1000

1.E+08
ADOPT
BnB-ADOPT
NCBB

1.E+04

NCCC

NCCC

1.E+05

1.E+03
1.E+02

ADOPT
BnB-ADOPT
NCBB

1.E+07
1.E+06
1.E+05

5

6

7

8

9

10

11

12

13

14

5

6

7

Number Vertices

8

9

(a)
Graph Coloring, Density = 2

12

13

14

Graph Coloring, Density = 3
Communication Cost = 0

1.E+06

ADOPT
BnB-ADOPT
NCBB

NCCC

1.E+05
Cycles

11

(b)

1.E+04

1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+04
1.E+03
1.E+02

1.E+02
5

6

7

8
9
10 11
Number Vertices

12

13

7

14

8

9

11

12

13

14

(d)

Graph Coloring, Density = 3
Communication Cost = 1000

1.E+09

10

Number Vertices

(c)

Graph Coloring, Density = 3
1.E+05

Cycles

ADOPT
BnB-ADOPT
NCBB

1.E+08
NCCC

10

Number Vertices

1.E+07
1.E+06
1.E+05

1.E+04
ADOPT
BnB-ADOPT
NCBB

1.E+03
1.E+02

7

8

9

10

11

12

13

14

7

8

9

10

11

12

13

14

Number Vertices

Number Vertices

(e)

(f)

Figure 17: Experimental Results Comparing ADOPT, BnB-ADOPT NCBB Graph Coloring
Problems Constraint Costs Ranging 0 10,000

2004b). Figure 16 shows hierarchical organization 4 units supervisor three
subordinates. example, supervisor 2 three subordinates 5, 6 7. unit,
assume possible meetings: one entire unit (e.g., 2, 5, 6, 7), two parent-child meetings
(e.g., 2, 5 2, 7) two sibling-sibling meetings (e.g., 5, 6 6, 7). vary number
meetings 5 (1 unit) 20 (4 units). always use 8 time slots. cost assigning
time slot meeting least one participant another meeting
time slot innity (to precise: 1,000,000) since person cannot attend
one meeting time. cost non-scheduled meeting 100. costs
range 0 100. average experimental results 50 DCOP problem instances
randomly generated integer constraint costs.

123

fiYeoh, Felner & Koenig

1.E+05

Graph Coloring, Density = 2
Communication Cost = 0

1.E+08
1.E+07
NCCC

NCCC

1.E+04

Graph Coloring, Density = 2
Communication Cost = 1000

1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+06
ADOPT
BnB-ADOPT
NCBB

1.E+05

1.E+01

1.E+04
0-1

0-10

0-100

0-1,000 0-10,000

0-1

Range Constraint Costs

0-10

0-100

0-1,000 0-10,000

Range Constraint Costs

(a)

(b)

Graph Coloring, Density = 2
1.E+06

1.E+04

Graph Coloring, Density = 3
Communication Cost = 0

NCCC

Cycles

1.E+05
1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+04
1.E+03

ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+01

1.E+01
0-1

0-10

0-100

0-1,000 0-10,000

0-1

Range Constraint Costs

(c)

1.E+09

0-100

0-1,000 0-10,000

(d)

Graph Coloring, Density = 3
Communication Cost = 1000

Graph Coloring, Density = 3
1.E+05

1.E+08

1.E+04
Cycles

NCCC

0-10

Range Constraint Costs

1.E+07
1.E+06

ADOPT
BnB-ADOPT
NCBB

1.E+05

1.E+03

ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+04

1.E+01
0-1

0-10

0-100

0-1,000 0-10,000

Range Constraint Costs

0-1

0-10

0-100

0-1,000 0-10,000

Range Constraint Costs

(e)

(f)

Figure 18: Experimental Results Comparing ADOPT, BnB-ADOPT NCBB Graph Coloring
Problems 10 Vertices

6.3 Experimental Results: Optimal DCOP Search Algorithms
rst compare BnB-ADOPT ADOPT NCBB. Figure 17 shows experimental results
graph coloring problems constraint costs ranging 0 10,000, varied
number vertices, Figure 18 shows experimental results graph coloring problems
10 vertices, varied range constraint costs. Figures 17(a-c) 18(a-c) show
results coloring sparse graphs, Figures 17(d-f) 18(d-f) show results coloring
dense graphs. y-axes log scale show runtimes NCCCs cycles. DCOP search
algorithms sparse graphs faster dense graphs because, example, larger
likelihood independent DCOP subproblems sparse graphs. BnB-ADOPT generally faster
NCBB sparse graphs dense graphs BnB-ADOPT allows agents send
messages parent agents pseudo-tree (along edges pseudo-tree) NCBB

124

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Sensor Network
Communication Cost = 1000

1.E+06

1.E+09

1.E+05

1.E+08
NCCC

NCCC

Sensor Network
Communication Cost = 0

1.E+04
1.E+03

ADOPT
BnB-ADOPT
NCBB

1.E+02

ADOPT
BnB-ADOPT
NCBB

1.E+07
1.E+06
1.E+05

1.E+01

1.E+04
4

5

6

4

7 8 9 10 11 12 13 14 15
Number Targets

5

6

(a)

(b)

Sensor Network

Meeting Scheduling
Communication Cost = 0

1.E+05

1.E+06
ADOPT
BnB-ADOPT
NCBB

1.E+05
NCCC

Cycles

1.E+04
1.E+03
1.E+02

1.E+04
ADOPT
BnB-ADOPT
NCBB

1.E+03

1.E+01

1.E+02
4

5

6

5

7 8 9 10 11 12 13 14 15
Number Targets

6

7

(c)

13

14

15

Meeting Scheduling
1.E+05

1.E+07

1.E+04
Cycles

1.E+08

1.E+06
ADOPT
BnB-ADOPT
NCBB

1.E+05

8
9 10 11 12
Number Meetings

(d)

Meeting Scheduling
Communication Cost = 1000

NCCC

7 8 9 10 11 12 13 14 15
Number Targets

1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+04

1.E+01
5

6

7

8
9 10 11 12
Number Meetings

13

14

15

(e)

5

6

7

8
9 10 11 12
Number Meetings

13

14

15

(f)

Figure 19: Experimental Results Comparing ADOPT, BnB-ADOPT NCBB Sensor Network
Meeting Scheduling Problems

allows agents send messages pseudo-parent agents (along backedges pseudotree). Thus, agents NCBB receive updates faster agents BnB-ADOPT. eect
prevalent dense graphs since backedges dense graphs. However, dierence
BnB-ADOPT NCBB becomes negligible communication slow.
Figure 17 shows BnB-ADOPT least half order magnitude faster ADOPT
number vertices small. speedup ADOPT increases number vertices
gets larger DCOP problems thus become complex. Similarly, Figure 18 shows
speedup ADOPT increases range constant costs increases DCOP problems
thus become complex. However, ADOPT faster BnB-ADOPT simple DCOP
problems. example, ADOPT requires fewer cycles BnB-ADOPT DCOP problems
constraint costs ranging 0 1. Figure 19 shows trend sensor network meeting
scheduling problems. reason behavior follows. ADOPT uses memory-bounded best125

fiYeoh, Felner & Koenig

Sensor Network
Communication Cost = 0

1.E+05

Sensor Network
Communication Cost = 1000

1.E+06

NCCC

NCCC

1.E+04
1.E+03
ADOPT

1.E+02

1.E+05
ADOPT

BnB-ADOPT

BnB-ADOPT

1.E+01

1.E+04
0.5

0.6

0.7
0.8
Weight

0.9

1

0.5

0.6

(a)

0.9

1

0.9

1

(b)

Sensor Network
1.E+03

Sensor Network
Unique Contexts Explored

1.E+02
No.
Contexts

Cycles

0.7
0.8
Weight

1.E+02
ADOPT

ADOPT
BnB-ADOPT

BnB-ADOPT

1.E+01

1.E+01
0.5

0.6

0.7
0.8
Weight

0.9

1

0.5

0.6

(c)

0.7
0.8
Weight

(d)
Sensor Network
Repeated Contexts Explored

No.
Contexts

1.E+03
1.E+02

ADOPT
BnB-ADOPT

1.E+01
1.E+00
0.5

0.6

0.7
0.8
Weight

0.9

1

(e)

Figure 20: Experimental Results Cause Speedup ADOPT BnB-ADOPT
rst search thus exploits heuristic values well needs repeatedly reconstruct partial
solutions purged memory, especially heuristic values poorly informed. BnBADOPT uses depth-rst branch-and-bound search thus exploit heuristic values
quite well repeatedly reconstruct partial solutions. ADOPT thus
faster BnB-ADOPT DCOP problems well informed heuristic values, simple
DCOP problems.
conrm intuition additional experiment sensor network problems four
targets dierent informedness heuristic values. use heuristic values cha,c
X (d) 0.5
c 1, ha,c
X (d) heuristic values calculated DP2, used now. Figures 20(a-c)
show number NCCCs dierent weights c. heuristic values well informed (large
weights), ADOPT indeed faster BnB-ADOPT. Since ADOPT relies heuristic
values BnB-ADOPT, speedup ADOPT much larger BnB-ADOPT
heuristic values get informed. Figures 20(d) 20(e) show number unique

126

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

(= dierent) repeated contexts per agent dierent weights c. heuristic values
well informed (large weights), agents ADOPT explore fewer unique contexts agents BnBADOPT since focused search. However, heuristic values poorly
informed (small weights), explore unique contexts. Agents ADOPT explore many
repeated contexts agents BnB-ADOPT since need reconstruct partial solutions
purged memory. Agents BnB-ADOPT explore repeated contexts even though
reconstruct partial solutions. reason behavior distributed nature
BnB-ADOPT. example, assume context agent {(a1 , 0), (a2 , 0)} next
context centralized variant BnB-ADOPT would {(a1 , 1), (a2 , 1)} (where IDs omitted
simplicity). agent updates context {(a1 , 1), (a2 , 0)} receives message
agent a1 takes value 1. agent updates context {(a1 , 1), (a2 , 1)}
receives message agent a2 takes value 1. Thus, agent explores intermediate
context {(a1 , 1), (a2 , 0)} centralized variant BnB-ADOPT would explore. counts
repeated context agent explores context intentionally future. Overall, BnB-ADOPT
tends faster ADOPT heuristic values poorly informed (small weights). Thus,
BnB-ADOPT great potential DCOP search algorithm since heuristic values often poorly
informed complex DCOP problems, DCOP problems large numbers agents, large
domains, large numbers constraints large ranges constraint costs.
6.4 Experimental Results: Suboptimal Variants BnB-ADOPT
compare three suboptimal variants BnB-ADOPT other. experimental
setup identical one optimal DCOP search algorithms, except follows: graph
coloring problems, number vertices 10, range constraint costs 0 10,000
constraint density 2; sensor network problems, number targets 9; meeting
scheduling problems, number meetings 10. measure runtimes cycles. (The results
NCCCs similar.) However, report normalized runtimes, is, runtimes divided
runtime nding cost-minimal solution BnB-ADOPT. Thus, normalized runtime
0.25 refers one quarter number cycles takes nd cost-minimal solution
BnB-ADOPT. Similarly, report normalized solution costs, is, solution costs divided
minimal solution costs. Thus, normalized solution cost 2.5 refers solution cost
two half times larger minimal solution cost. vary relative error bound (which
worst acceptable normalized solution cost) 1.0 4.0. relative error bound p
BnB-ADOPTREM w BnB-ADOPTW HM . pre-calculate minimal solution costs
set correct value b BnB-ADOPTAEM . example, minimal solution cost 100
relative error bound 2.5, p = 2.5 BnB-ADOPTREM , w = 2.5 BnB-ADOPTW HM
b = (2.5 1) 100 = 150 BnB-ADOPTAEM .
Figure 21(a-c) shows experimental results graph coloring problems. Figure 21(a) shows
normalized solution costs three suboptimal variants increase relative error
bound increases. However, solution costs remain much smaller error bound.
example, normalized solution costs three suboptimal variants less 1.3 (rather
3) relative error bound 3. normalized solution costs BnB-ADOPTAEM
usually larger normalized solution costs BnB-ADOPTREM relative error
r
r
bound. reason behavior BnB-ADOPTAEM terminates U BX
=
r lim
r
r
r
r
b + LBX r = (p 1) X r + LBX r , X r minimal solution cost. Thus, solution cost
r
r
r
BnB-ADOPTAEM U BX
r LBX r (p 1) X r larger minimal solution
r
r
r
cost. hand, BnB-ADOPTREM terminates U BX
r lim = p LBX r . Thus,
r
r
r
solution cost BnB-ADOPTREM U BX r LBX r (p 1) LBX r larger
minimal solution cost. absolute error bound BnB-ADOPTAEM thus smaller
r
r
absolute error bound BnB-ADOPTREM since X
r LBX r initially strictly greater
r
r
absolute error bound BnB-ADOPTREM since X r > LBX
r search.

127

fiYeoh, Felner & Koenig

Graph Coloring
Solution Cost BnB-ADOPT Variants

Graph Coloring
Computation Time BnB-ADOPT Variants
1.00
Normalized Runtimes
(Cycles)

Normalized Costs

1.35
1.30
1.25
1.20
1.15

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

1.10
1.05
1.00
1.00

1.50

2.00
2.50
3.00
Relative Error Bound

3.50

0.80

0.40
0.20
0.00
1.00

4.00

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60

1.50

2.00
2.50
3.00
Relative Error Bound

(a)
Graph Coloring
Performance BnB-ADOPT Variants

Sensor Network
Performance BnB-ADOPT Variants
1.00

0.80

Normalized Runtimes
(Cycles)

Normalized Runtimes
(Cycles)

4.00

(b)

1.00
Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60
0.40
0.20
0.00
1.00

3.50

1.05

1.10
1.15
1.20
Normalized Costs

1.25

1.30

0.80

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60
0.40
0.20
0.00
1.00

1.02

1.04

(c)

1.06
1.08
1.10
Normalized Costs

1.12

1.14

(d)
Meeting Scheduling
Performance BnB-ADOPT Variants
Normalized Runtimes
(Cycles)

1.00
0.80

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60
0.40
0.20
0.00
1.00

1.05

1.10
1.15
Normalized Costs

1.20

1.25

(e)

Figure 21: Experimental Results Comparing Suboptimal Variants BnB-ADOPT
Figure 21(b) shows normalized runtimes three suboptimal variants decrease
relative error bound increases. decrease almost 0 relative error bound 2.0.
Therefore, three suboptimal variants terminate almost immediately nding rst solution.
normalized runtimes BnB-ADOPTAEM usually smaller normalized runtimes
BnB-ADOPTREM relative error bound since BnB-ADOPTAEM terminate
suboptimal solution cost within absolute error bound yet within absolute error
bound BnB-ADOPTREM absolute error bound BnB-ADOPTAEM strictly greater
absolute error bound BnB-ADOPTREM . words, BnB-ADOPTAEM terminate
r
r
r
suboptimal solution cost (p 1) LBX
r < U BX r (p 1) X r BnB-ADOPTREM
not.
Figure 21(c) shows normalized runtimes needed achieve given normalized solution cost.
BnB-ADOPTW HM terminates faster BnB-ADOPTAEM , turn terminates faster
BnB-ADOPTREM . example, normalized runtime needed achieve normalized solu-

128

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

tion cost 1.05 0.18 BnB-ADOPTW HM , 0.30 BnB-ADOPTAEM 0.35 BnBADOPTREM . Thus, BnB-ADOPTW HM suboptimal variant BnB-ADOPT best
performance. Figures 21(d-e) show trend sensor network meeting scheduling problems.

7. Conclusions
article, introduced Branch-and-Bound ADOPT (BnB-ADOPT), memory-bounded
DCOP search algorithm. BnB-ADOPT uses message passing communication framework
ADOPT changes search strategy ADOPT best-rst search depth-rst branchand-bound search make ADOPT faster taking advantage fact DCOP problems
depth-bounded search trees. properties BnB-ADOPT similar ADOPT.
BnB-ADOPT allows agents operate concurrently (in order decrease runtime) asynchronously (in order increase robustness). BnB-ADOPT restricts communication agents
share constraints (in order restrictions applications sensor networks). Finally,
BnB-ADOPT orders agents pseudo-tree (in order take advantage independent DCOP
subproblems). experimental results showed BnB-ADOPT nds cost-minimal solutions
one order magnitude faster ADOPT variety large DCOP problems fast
NCBB DCOP problems. reason behavior following: Agents
NCBB operate sequentially thus often idle. ADOPT construct fewer partial solutions
BnB-ADOPT reconstruct partial solutions purged memory.
advantage ADOPT respect number constructed partial solutions decreases
disadvantage respect number reconstructed partial solutions increases heuristic
values become poorly informed. Thus, BnB-ADOPT great potential DCOP search
algorithm since heuristic values often poorly informed complex DCOP problems
DCOP problems large numbers agents, large domains, large numbers constraints large
ranges constraint costs.
investigated three approximation mechanisms trade solution cost BnBADOPT smaller runtime, namely Absolute Error Mechanism ADOPT (resulting
BnB-ADOPTAEM ), new Relative Error Mechanism (resulting BnB-ADOPTREM )
new Weighted Heuristics Mechanism (resulting BnB-ADOPTW HM ). two new approximation mechanisms allow users specify relative error bound, often meaningful
absolute error bound. Weighted Heuristics Mechanism dominated Absolute Error Mechanism Relative Error Mechanism experiments apply
DCOP search algorithms well since benet using heuristic values focus
searches (Yeoh, Koenig, & Sun, 2008b).
future, plan improve BnB-ADOPT following ways: First, would
reduce number sent messages handle lost messages. Second, would study
dierent pseudo-tree arrangements (Atlas & Decker, 2007; Sultanik, Lass, & Regli, 2009)
pre-processing techniques (Matsui et al., 2009) aect eciency BnB-ADOPT. Finally,
would compare BnB-ADOPT approximation mechanisms DCOP algorithms,
including OptAPO, DPOP variants (Petcu & Faltings, 2005a, 2006).

Acknowledgments
article extension two earlier publications (Yeoh, Felner, & Koenig, 2008a; Yeoh et al.,
2008b) contains additional expositions, examples proofs. thank Anton Chechetka
providing us implementation NCBB anonymous reviewers helpful
comments. research done Ariel Felner spent sabbatical University
Southern California, visiting Sven Koenig. research partly supported U.S. Army

129

fiYeoh, Felner & Koenig

Research Laboratory (ARL) U.S. Army Research Oce (ARO) award Sven Koenig
grant W911NF-08-1-0468, Oce Naval Research (ONR) award Sven Koenig grant
N00014-09-1-1031, National Science Foundation (NSF) award Sven Koenig grant
0413196 Israeli Science Foundation (ISF) award Ariel Felner grants 728/06
305/09. views conclusions contained document authors
interpreted representing ocial policies, either expressed implied, sponsoring
organizations, agencies, companies U.S. government.

References
Ali, S., Koenig, S., & Tambe, M. (2005). Preprocessing techniques accelerating DCOP
algorithm ADOPT. Proceedings International Joint Conference Autonomous
Agents Multiagent Systems (AAMAS), pp. 10411048.
Atlas, J., & Decker, K. (2007). complete distributed constraint optimization method nontraditional pseudotree arrangements. Proceedings International Joint Conference
Autonomous Agents Multiagent Systems (AAMAS), pp. 736743.
Bayardo, R., & Miranker, D. (1995). space-time trade-o solving constraint satisfaction problems. Proceedings International Joint Conference Articial Intelligence
(IJCAI), pp. 558562.
Bistarelli, S., Montanari, U., Rossi, F., Schiex, T., Verfaillie, G., & Fargier, H. (1999). Semiring-based
CSPs valued CSPs: Basic properties comparison. Constraints, 4 (3), 199240.
Bowring, E., Pearce, J., Portway, C., Jain, M., & Tambe, M. (2008). k-optimal distributed
constraint optimization algorithms: New bounds algorithms. Proceedings International Joint Conference Autonomous Agents Multiagent Systems (AAMAS), pp.
607614.
Bowring, E., Tambe, M., & Yokoo, M. (2006). Multiply-constrained distributed constraint optimization. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 14131420.
Burke, D., & Brown, K. (2006). Eciently handling complex local problems distributed constraint
optimisation. Proceedings European Conference Articial Intelligence (ECAI), pp.
701702.
Chechetka, A., & Sycara, K. (2006). No-commitment branch bound search distributed
constraint optimization. Proceedings International Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 14271429.
Choxi, H., & Modi, P. (2007). distributed constraint optimization approach wireless network
optimization. Proceedings AAAI-07 Workshop Conguration, pp. 18.
Davin, J., & Modi, P. (2006). Hierarchical variable ordering multiagent agreement problems.
Proceedings International Joint Conference Autonomous Agents Multiagent
Systems (AAMAS), pp. 14331435.
Dechter, R. (Ed.). (2003). Constraint Processing. Morgan Kaufmann.
Fitzpatrick, S., & Meertens, L. (2003). Distributed coordination anarchic optimization.
Lesser, V., Ortiz, C., & Tambe, M. (Eds.), Distributed Sensor Networks: Multiagent
Perspective, pp. 257295. Kluwer.
Freuder, E., & Quinn, M. (1985). Taking advantage stable sets variables constraint satisfaction problems. Proceedings International Joint Conference Articial Intelligence
(IJCAI), pp. 10761078.

130

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Gershman, A., Meisels, A., & Zivan, R. (2009). Asynchronous Forward-Bounding distributed
COPs. Journal Articial Intelligence Research, 34, 6188.
Greenstadt, R. (2009). overview privacy improvements k-optimal DCOP algorithms (extended abstract). Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 12791280.
Greenstadt, R., Grosz, B., & Smith, M. (2007). SSDPOP: Improving privacy DCOP
secret sharing. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 10981100.
Hamadi, Y., Bessiere, C., & Quinqueton, J. (1998). Distributed intelligent backtracking. Proceedings European Conference Articial Intelligence (ECAI), pp. 219223.
Hirayama, K., & Yokoo, M. (1997). Distributed partial constraint satisfaction problem. Proceedings International Conference Principles Practice Constraint Programming
(CP), pp. 222236.
Jain, M., Taylor, M., Tambe, M., & Yokoo, M. (2009). DCOPs meet real world: Exploring
unknown reward matrices applications mobile sensor networks. Proceedings
International Joint Conference Articial Intelligence (IJCAI), pp. 181186.
Junges, R., & Bazzan, A. (2008). Evaluating performance DCOP algorithms real world,
dynamic problem. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 599606.
Korf, R. (1993). Linear-space best-rst search. Articial Intelligence, 62 (1), 4178.
Kumar, A., Faltings, B., & Petcu, A. (2009). Distributed constraint optimization structured
resource constraints. Proceedings International Joint Conference Autonomous
Agents Multiagent Systems (AAMAS), pp. 923930.
Lesser, V., Ortiz, C., & Tambe, M. (Eds.). (2003). Distributed Sensor Networks: Multiagent
Perspective. Kluwer.
Maheswaran, R., Pearce, J., & Tambe, M. (2004a). Distributed algorithms DCOP: graphical game-based approach. Proceedings International Conference Parallel
Distributed Computing Systems (PDCS), pp. 432439.
Maheswaran, R., Tambe, M., Bowring, E., Pearce, J., & Varakantham, P. (2004b). Taking DCOP
real world: Ecient complete solutions distributed event scheduling. Proceedings
International Joint Conference Autonomous Agents Multiagent Systems (AAMAS),
pp. 310317.
Mailler, R., & Lesser, V. (2004). Solving distributed constraint optimization problems using cooperative mediation. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 438445.
Marinescu, R., & Dechter, R. (2007). Best-rst AND/OR search graphical models. Proceedings
AAAI Conference Articial Intelligence (AAAI), pp. 11711176.
Marinescu, R., & Dechter, R. (2009). AND/OR branch-and-bound search combinatorial optimization graphical models. Articial Intelligence, 173 (16-17), 14571491.
Matsui, T., Silaghi, M., Hirayama, K., Yokoo, M., & Matsuo, H. (2009). Directed soft arc consistency
pseudo trees. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 10651072.
Meisels, A., Kaplansky, E., Razgon, I., & Zivan, R. (2002). Comparing performance distributed
constraints processing algorithms. Proceedings Distributed Constraint Reasoning
Workshop, pp. 8693.

131

fiYeoh, Felner & Koenig

Modi, P., & Ali, S. (2004). Distributed constraint reasoning unreliable communication.
Zhang, W., & Sorge, V. (Eds.), Frontiers Articial Intelligence Applications, Vol. 112,
pp. 141150. IOS Press.
Modi, P., Shen, W.-M., Tambe, M., & Yokoo, M. (2005). ADOPT: Asynchronous distributed constraint optimization quality guarantees. Articial Intelligence, 161 (1-2), 149180.
Ottens, B., & Faltings, B. (2008). Coordinating agent plans distributed constraint optimization. Proceedings ICAPS-08 Workshop Multiagent Planning.
Pearce, J., & Tambe, M. (2007). Quality guarantees k-optimal solutions distributed constraint
optimization problems. Proceedings International Joint Conference Articial
Intelligence (IJCAI), pp. 14461451.
Pecora, F., Modi, P., & Scerri, P. (2006). Reasoning dynamically posting n-ary constraints
ADOPT. Proceedings Distributed Constraint Reasoning Workshop, pp. 5771.
Petcu, A., & Faltings, B. (2005a). Approximations distributed optimization. Proceedings
International Conference Principles Practice Constraint Programming (CP), pp.
802806.
Petcu, A., & Faltings, B. (2005b). scalable method multiagent constraint optimization.
Proceedings International Joint Conference Articial Intelligence (IJCAI), pp. 1413
1420.
Petcu, A., & Faltings, B. (2006). ODPOP: algorithm open/distributed constraint optimization. Proceedings National Conference Articial Intelligence (AAAI), pp. 703708.
Pohl, I. (1970). First results eect error heuristic search. Machine Intelligence, 5,
219236.
Pohl, I. (1973). avoidance (relative) catastrophe, heuristic competence, genuine dynamic
weighting computational issues heuristic problem solving. Proceedings International Joint Conference Articial Intelligence (IJCAI), pp. 1217.
Schiex, T., Fargier, H., & Verfaillie, G. (1995). Valued constraint satisfaction problems: Hard
easy problems. Proceedings International Joint Conference Articial Intelligence
(IJCAI), pp. 631637.
Schurr, N., Okamoto, S., Maheswaran, R., Scerri, P., & Tambe, M. (2005). Evolution teamwork
model. Sun, R. (Ed.), Cognition Multi-Agent Interaction: Cognitive Modeling
Social Simulation, pp. 307327. Cambridge University Press.
Silaghi, M., Landwehr, J., & Larrosa, J. (2004). Asynchronous branch & bound A* disWCSPs
heuristic function based consistency-maintenance. Zhang, W., & Sorge, V. (Eds.),
Frontiers Articial Intelligence Applications, Vol. 112, pp. 4962. IOS Press.
Silaghi, M., Lass, R., Sultanik, E., Regli, W., Matsui, T., & Yokoo, M. (2008). operation point
units distributed constraint solvers. Proceedings Distributed Constraint Reasoning
Workshop, pp. 116.
Silaghi, M., & Yokoo, M. (2009). ADOPT-ing: Unifying asynchronous distributed optimization
asynchronous backtracking. Autonomous Agents Multi-Agent Systems, 19 (2), 89123.
Stranders, R., Farinelli, A., Rogers, A., & Jennings, N. (2009). Decentralised coordination mobile
sensors using Max-Sum algorithm. Proceedings International Joint Conference
Articial Intelligence (IJCAI), pp. 299304.
Sultanik, E., Lass, R., & Regli, W. (2009). Dynamic conguration agent organizations.
Proceedings International Joint Conference Articial Intelligence (IJCAI), pp. 305
311.

132

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Yeoh, W., Felner, A., & Koenig, S. (2008a). BnB-ADOPT: asynchronous branch-and-bound
DCOP algorithm. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 591598.
Yeoh, W., Koenig, S., & Sun, X. (2008b). Trading solution cost smaller runtime DCOP
search algorithms (short paper). Proceedings International Joint Conference
Autonomous Agents Multiagent Systems (AAMAS), pp. 14451448.
Yeoh, W., Varakantham, P., & Koenig, S. (2009). Caching schemes DCOP search algorithms.
Proceedings International Joint Conference Autonomous Agents Multiagent
Systems (AAMAS), pp. 609616.
Yokoo, M., & Hirayama, K. (1996). Distributed breakout algorithm solving distributed constraint
satisfaction problems. Proceedings International Conference Multiagent Systems
(ICMAS), pp. 401408.
Zhang, W., & Korf, R. (1995). Performance linear-space search algorithms. Articial Intelligence,
79 (2), 241292.
Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2003). analysis application distributed
constraint satisfaction optimization algorithms sensor networks. Proceedings
International Joint Conference Autonomous Agents Multiagent Systems (AAMAS),
pp. 185192.
Zivan, R. (2008). Anytime local search distributed constraint optimization. Proceedings
AAAI Conference Articial Intelligence (AAAI), pp. 393398.
Zivan, R., Glinton, R., & Sycara, K. (2009). Distributed constraint optimization large teams
mobile sensing agents. Proceedings International Conference Intelligent Agent
Technology (IAT), pp. 347354.

133


