Journal Artificial Intelligence Research 27 (2006) 617-674

Submitted 07/06; published 12/06

Uncertainty Soft Temporal Constraint Problems: General
Framework Controllability Algorithms Fuzzy Case
Francesca Rossi
Kristen Brent Venable

FROSSI @ MATH . UNIPD .
KVENABLE @ MATH . UNIPD .

University Padova, Department Pure Applied Mathematics,
Via Trieste, 63 35121 PADOVA ITALY

Neil Yorke-Smith

NYSMITH @ AI . SRI . COM

SRI International,
333 Ravenswood Ave, Menlo Park, CA 94025 USA

Abstract
real-life temporal scenarios, uncertainty preferences often essential coexisting
aspects. present formalism quantitative temporal constraints preferences
uncertainty defined. show three classical notions controllability (that is, strong,
weak, dynamic), developed uncertain temporal problems, generalized handle preferences well. defining general framework, focus problems
preferences follow fuzzy approach, properties assure tractability.
problems, propose algorithms check presence controllability properties. particular, show setting dealing simultaneously preferences uncertainty
increase complexity controllability testing. develop dynamic execution algorithm,
polynomial complexity, produces temporal plans uncertainty optimal
respect fuzzy preferences.

1. Introduction
Current research temporal constraint reasoning, exposed difficulties real-life problems, found lacking expressiveness flexibility. rich application domains
often necessary simultaneously handle temporal constraints, preferences
uncertainty.
need seen many scheduling domains. motivation line research
described paper domain planning scheduling NASA space missions. NASA
tackled many scheduling problems temporal constraints used reasonable success, showing limitations lack capability deal uncertainty
preferences. example, Remote Agent (Rajan, Bernard, Dorais, Gamble, Kanefsky, Kurien,
Millar, Muscettola, Nayak, Rouquette, Smith, Taylor, & Tung, 2000; Muscettola, Morris, Pell, &
Smith, 1998) experiments, consisted placing AI system on-board plan execute
spacecraft activities, represents one interesting examples this. Remote Agent worked
high level goals specified, example, duration frequency time windows
within spacecraft take asteroid images used orbit determination
on-board navigator. Remote Agent dealt flexible time intervals uncontrollable events;
however, deal preferences: temporal constraints hard. benefit
adding preferences framework would allow planner handle uncontrollable events
time maximizing mission managers preferences.
c
2006
AI Access Foundation. rights reserved.

fiROSSI , V ENABLE ,& YORKE -S MITH

recent NASA application rovers domain (Dearden, Meuleau, Ramakrishnan,
Smith, & Washington, 2002; Bresina, Jonsson, Morris, & Rajan, 2005). NASA interested
generation optimal plans rovers designed explore planetary surface (e.g. Spirit
Opportunity Mars) (Bresina et al., 2005). Dearden et al. (2002) describe problem generating plans planetary rovers handle uncertainty time resources. approach
involves first constructing seed plan, incrementally adding contingent branches
plan order improve utility. Again, preferences could used embed utilities directly
temporal model.
third space application, used several times paper running example,
concerns planning fleets Earth Observing Satellites (EOS) (Frank, Jonsson, Morris, & Smith,
2001). planning problem involves multiple satellites, hundreds requests, constraints
serve request, resources instruments, recording devices, transmitters
ground stations. response requests placed scientists, image data acquired EOS.
data either downlinked real time recorded board playback later time.
Ground stations satellites available receive downlinked images. Different satellites
may able communicate subset resources, transmission rates differ
satellite satellite station station. Further, may different financial costs
associated using different communication resources. (Frank et al., 2001) EOS scheduling problem dealt using constraint-based interval representation. Candidate plans
represented variables constraints, reflect temporal relationship actions
constraints parameters states actions. Also, temporal constraints necessary
model duration ordering constraints associated data collection, recording, downlinking tasks. Solutions preferred based objectives (such maximizing number high
priority requests served, maximizing expected quality observations, minimizing
cost downlink operations). Uncertainty present due weather: specifically due duration
persistence cloud cover, since image quality obviously affected amount clouds
target. addition, events need observed may happen unpredictable
times uncertain durations (e.g. fires volcanic eruptions).
existing frameworks, Simple Temporal Problems Preferences (STPPs) (Khatib,
Morris, Morris, & Rossi, 2001), address lack expressiveness hard temporal constraints
adding preferences temporal framework, take account uncertainty. models, Simple Temporal Problems Uncertainty (STPUs) (Vidal & Fargier, 1999), account
contingent events, notion preferences. paper introduce framework
allows us handle preferences uncertainty Simple Temporal Problems.
proposed model, called Simple Temporal Problems Preferences Uncertainty (STPPUs),
merges two pre-existing models STPPs STPUs.
STPPU instance represents quantitative temporal problem preferences uncertainty
via set variables, representing starting ending times events (which controllable
agent not), set soft temporal constraints variables, includes interval containing allowed durations event allowed times events.
preference function associating element interval value specifies much
value preferred. soft constraints defined controllable uncontrollable
events. order clarify modeled STPPU, let us emphasize graduality
allowed terms preferences uncertainty. sense, uncertainty represented contingent STPPU constraints contingent STPU constraints:
618

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

durations assumed equally possible. addition expressing uncertainty, STPPUs, contingent constraints soft different preference levels associated different durations
contingent events.
problems, consider notions controllability similar defined STPUs,
used instead consistency presence uncertainty, adapt
handle preferences. notions, usually called strong, weak, dynamic controllability, refer
possibility controlling problem, is, executing agent assigning values
controllable variables, way optimal respect Nature decided,
decide, uncontrollable variables. word optimal crucial, since STPUs,
preferences, need care controllability, optimality. fact,
notions define paper directly correspond STPUs called strong, weak,
dynamic optimal controllability.
defining controllability notions proving properties, consider
restrictions shown make temporal problems preferences tractable
(Khatib et al., 2001; Rossi, Sperduti, Venable, Khatib, Morris, & Morris, 2002), i.e, semi-convex
preference functions totally ordered preferences combined idempotent operator.
context, controllability notions, give algorithms check whether
hold, show adding preferences make complexity testing
properties worse case without preferences. Moreover, dealing different levels
preferences, define testing algorithms refer possibility controlling problem
maintaining preference least certain level (called -controllability). Finally,
context dynamic controllability, consider execution dynamic optimal plans.
Parts content paper appeared (Venable & Yorke-Smith, 2003; Rossi, Venable, & Yorke-Smith, 2003; Yorke-Smith, Venable, & Rossi, 2003; Rossi, Venable, & Yorke-Smith,
2004). paper extends previous work least two directions. First, papers optimal controllability (strong dynamic) checked separately, check
optimal (strong dynamic) controllability and, hold, algorithm return
highest given problem -strong -dynamic controllable. Moreover, results
presented uniform technical environment, providing thorough theoretical study properties algorithms computational aspects, makes use several unpublished
proofs.
paper structured follows. Section 2 give background temporal constraints
preference uncertainty. Section 3 define formalism Simple Temporal
Problems preferences uncertainty and, Section 4, describe new notions
controllability. Algorithms test notions described respectively Section 5 Optimal
Strong Controllability, Section 6 Optimal Weak Controllability, Section 7 Optimal
Dynamic Controllability. Section 8 give general strategy using notions. Finally, Section 9, discuss related work, Section 10 summarize main results
point directions future developments. make paper readable, proofs
theorems contained Appendix.

2. Background
section give main notions temporal constraints (Dechter, Meiri, & Pearl, 1991)
framework Temporal Constraint Satisfaction Problems Preferences (TCSPPs) (Khatib

619

fiROSSI , V ENABLE ,& YORKE -S MITH

et al., 2001; Rossi et al., 2002), extend quantitative temporal constraints (Dechter et al., 1991)
semiring-based preferences (Bistarelli, Montanari, & Rossi, 1997). describe Simple
Temporal Problems Uncertainty (STPUs) (Vidal & Fargier, 1999; Morris, Muscettola, & Vidal,
2001), extend tractable subclass temporal constraints model agent-uncontrollable
contingent events, define corresponding notions controllability, introduced (Vidal
& Fargier, 1999).
2.1 Temporal Constraint Satisfaction Problems
One requirements temporal reasoning system planning scheduling problems
ability deal metric information; words, handle quantitative information
duration events (such take ten twenty minutes get home). Quantitative
temporal networks provide convenient formalism deal information. consider
instantaneous events variables problem, whose domains entire timeline.
variable may represent either beginning ending point event, neutral point
time. effective representation quantitative temporal networks, based constraints, within
framework Temporal Constraint Satisfaction Problems (TCSPs) (Dechter et al., 1991).
paper interested particular subclass TCSPs, known Simple Temporal
Problems (STPs) (Dechter et al., 1991). problem, constraint time-points X
Xj represented constraint graph edge X Xj , labeled single interval [aij , bij ]
represents constraint aij Xj Xi bij . Solving STP means finding assignment
values variables temporal constraints satisfied.
Whereas complexity general TCSP comes one interval
constraint, STPs solved polynomial time. Despite restriction single interval per
constraint, STPs shown valuable many practical applications. STPs
attracted attention literature.
STP associated directed weighted graph G = (V, Ed ), called distance
graph. set nodes constraint graph twice number edges:
binary constraint variables X Xj , distance graph edge Xi Xj
labeled weight bij , representing linear inequality X j Xi bij , well edge Xj Xi
labeled weight aij , representing linear inequality X Xj aij .
path Xi Xj distance graph Gd , say variables Xi0 = Xi , Xi1 , Xi2 , . . .
P
, Xik = Xj induces following path constraint: X j Xi kh=1 bih1 ih . intersection
induced path constraints yields inequality X j Xi dij , dij length shortest
path Xi Xj , length defined, i.e. negative cycles distance
graph. STP consistent distance graph negative cycles (Shostak, 1981;
Leiserson & Saxe, 1988). means enforcing path consistency, algorithm
PC-2, sufficient solving STPs (Dechter et al., 1991). follows given STP effectively specified another complete directed graph, called d-graph, edge Xi Xj
labeled shortest path length ij distance graph Gd .
(Dechter et al., 1991) shown consistent STP backtrack-free (that is, decomposable) relative constraints d-graph. Moreover, set temporal constraints
form [dji , dij ] minimal STP corresponding original STP possible find one
solutions using backtrack-free search simply assigns variable value
satisfies minimal network constraints compatibly previous assignments. Two specific solu-

620

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

tions (usually called latest earliest assignments) given L = {d01 , . . . , d0n }
SE = {d10 , . . . , dn0 }, assign variable respectively latest earliest possible time
(Dechter et al., 1991).
d-graph (and thus minimal network) STP found applying FloydWarshalls Pairs Shortest Path algorithm (Floyd, 1962) distance graph complexity
O(n3 ) n number variables. graph sparse, Bellman-Ford Single Source
Shortest Path algorithm used instead, complexity equal O(nE), E
number edges. refer (Dechter et al., 1991; Xu & Choueiry, 2003) details
efficient STP solving.
2.2 Temporal CSPs Preferences
Although expressive, TCSPs model hard temporal constraints. means constraints
satisfied, solutions constraint equally satisfying. However,
many real-life situations solutions preferred others and, thus, global problem
find way satisfy constraints optimally, according preferences specified.
address need, TCSP framework generalized (Khatib et al., 2001)
associate temporal constraint preference function specifies preference
distance allowed constraint. framework merges TCSPs semiring-based soft
constraints (Bistarelli et al., 1997).
Definition 1 (soft temporal constraint) soft temporal constraint 4-tuple h{X, }, I, A, f
consisting
set two variables {X, } integers, called scope constraint;
set disjoint intervals = {[a1 , b1 ], . . . , [an , bn ]}, ai , bi Z, ai bi
= 1, . . . , n;
set preferences A;
preference function f : A, mapping elements preference
values, taken set A.
Given assignment variables X , X = v x = vy , say assignment
satisfies constraint h{X, }, I, A, f iff exists [a , bi ] ai vy vx bi .
case, preference associated assignment constraint f (v vx ) = p.2
variables preference set STPP apparent, omit write
soft temporal constraint pair hI, f i.
Following soft constraint approach (Bistarelli et al., 1997), preference set carrier
algebraic structure known c-semiring. Informally c-semiring = hA, +, , 0, 1i
set equipped two operators satisfying proscribed properties (for details, see Bistarelli
et al., 1997)). additive operator + used induce ordering preference set A; given
two elements a, b A, b iff + b = a. multiplicative operator used combine
preferences.

621

fiROSSI , V ENABLE ,& YORKE -S MITH

Definition 2 (TCSPP) Given semiring = hA, +, , 0, 1i, Temporal Constraint Satisfaction
Problems Preferences (TCSPP) pair hV, Ci, V set variables C
set soft temporal constraint pairs variables V preferences A.2
Definition 3 (solution) Given TCSPP hV, Ci semiring S, solution complete assignment variables V . solution said satisfy constraint c C preference p
projection pair variables cs scope satisfies c preference p. write
pref (t, c) = p.2
solution global preference value, obtained combining, via operator,
preference levels solution satisfies constraints C.
Definition 4 (preference solution) Given TCSPP hV, Ci semiring S, preference
solution = hv1 , . . . , vn i, denoted val(t), computed cC pref (s, c).2
optimal solutions TCSPP solutions best global preference
value, best determined ordering values semiring.
Definition 5 (optimal solutions) Given TCSPP P = hV, Ci semiring S, solution
P optimal every solution 0 P , t0 6S t.2
Choosing specific semiring means selecting class preferences. example, semiring
SF CSP = h[0, 1], max, min, 0, 1i
allows one model so-called fuzzy preferences (Ruttkay, 1994; Schiex, 1992), associate
element allowed constraint preference 0 1 (with 0 worst
1 best preferences), gives complete assignment minimal among preferences selected constraints. optimal solutions solutions maximal
preference. Another example semiring CSP = h{f alse, true}, , , f alse, truei,
allows one model classical TCSPs, without preferences, general TCSPP framework.
paper refer fuzzy temporal constraints. However, absence preferences
temporal constraints always modelled using two elements 0 1
constraints. Thus preferences always coexists hard constraints.
special case occurs constraint TCSPP contains single interval. analogy
done case without preferences, problems called Simple Temporal Problems
Preferences (STPPs). class temporal problems interesting because, noted above,
STPs polynomially solvable general TCSPs NP-hard, computational effect
adding preferences STPs immediately obvious.
Example 1 Consider EOS example given Section 1. Figure 1 show STPP
models scenario three events scheduled satellite: start time (Ss)
ending time (Se) slewing procedure starting time (Is) image retrieval.
slewing activity example take 3 10 units time, ideally 3 5 units
time, shortest time possible otherwise. image taking start time 3
20 units time slewing initiated. third constraint, variables Se,
models fact better image taking start soon slewing stopped.2
622

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

11 1
0.9

0.8
0.7
0.6
0.5

3 4 5 6 7

8 9 10

Ss

Se

1

1 1 1
0.9

0.9
0.8

0.8

0.7

0.7

0.6

0.6
3

20


4 3 2 1

0 1 2 3

4

5

6

Figure 1: STPP Example 1.
following example, instead, consider STPP uses set-based semiring:
Sset = h(A), , , , Ai. Notice that, fuzzy semiring, multiplicative operator, i.e.,
intersection, idempotent, order induced additive operator, i.e., union, partial.
Example 2 Consider scenario three friends, Alice, Bob, Carol, want meet drink
dinner must decide time meet reserve dinner depending
long takes get restaurant. variables involved problem are: global
start time X0 , value 0 domain, start time drink (Ds), time
leave dinner (De), time arrival restaurant (Rs). meet, drink,
8 9:00pm leave dinner half hour. Moreover, depending
restaurant choose, take 20 40 minutes get dinner. Alice prefers
meet early dinner early, Carol. Bob prefers meet 8:30 go best
restaurant farthest. Thus, following two soft temporal constraints. first
constraint defined variable pair (X0 , Ds), interval [8:00,9:00] preference
function, fs , that, fs (8 : 00) = {Alice, Carol}, fs (8 : 30) = {Bob} fs (9 : 00) = .
second constraint binary constraint pair (De,Rs), interval [20, 40] preference
function fse , that, fse (20) = {Alice, Carol} fse (20) = fse (20) = {Bob}.
additional hard constraint variable pair (Ds, De), modeled
interval [30, 30] single preference equal {Alice, Carol, Bob}. optimal solution
(X0 = 0, Ds = 8 : 00, De = 8 : 30, Rs = 8 : 50), preference {Alice, Carol}. 2
Although TCSPPs STPPs NP-hard, (Khatib et al., 2001) tractable subclass
STPPs described. tractability assumptions are: semi-convexity preference functions,
idempotence combination operator semiring, totally ordered preference set.
preference function f soft temporal constraint hI, f semi-convex iff < + , set
{x I, f (x) y} forms interval. Notice semi-convex functions include linear, convex,
step functions. aggregation operator totally ordered set idempotent
min (Dubois & Prade, 1985), i.e. combination operator F CSP semiring.
tractability assumptions met, STPPs solved polynomial time. (Rossi
et al., 2002) two polynomial solvers tractable subclass STPPs proposed. One solver

623

fiROSSI , V ENABLE ,& YORKE -S MITH

based extension path consistency TCSPPs. second solver decomposes problem
solving set hard STPs.
2.3 Simple Temporal Problems Uncertainty
reasoning concerns activities agent performs interacting external world, uncertainty often unavoidable. TCSPs assume activities durations control
agent. Simple Temporal Problems Uncertainty (STPUs) (Vidal & Fargier, 1999) extend
STPs distinguishing contingent events, whose occurrence controlled exogenous factors
often referred Nature.
STPs, activity durations STPUs modelled intervals. start times activities assumed controlled agent (this brings loss generality). end times,
however, fall two classes: requirement (free Vidal & Fargier, 1999) contingent.
former, STPs, decided agent, agent control latter:
observe occurrence event; observation supposed known immediately
event. information known prior observation time-point nature respect
interval duration. Durations contingent links assumed independent.
STPU, variables thus divided two sets depending type time-points
represent.
Definition 6 (variables) variables STPU divided into:
executable time-points: points, b , whose time assigned executing agent;
contingent time-points: points, e , whose time assigned external world.2
distinction variables leads constraints divided two sets, requirement contingent, depending type variables constrain. Note STPs
constraints binary. Formally:
Definition 7 constraints STPU divided into:
requirement constraint (or link) r ij , generic time-points ti tj 1 , interval Iij =
[lij , uij ] lij (tj ) (ti ) uij (ti ) value assigned variable ti
contingent link ghk , executable point bh contingent point ek , interval Ihk =
[lij , uij ] contains possible durations contingent event represented b h
ek .2
formal definition STPU following:
Definition 8 (STPU) Simple Temporal Problem Uncertainty (STPU) 4-tuple N =
{Xe , Xc , Rr , Rc } that:
Xe = {b1 , . . . , bne }: set executable time-points;
Xc = {e1 , . . . , enc }: set contingent time-points;
1. general ti tj either contingent executable time-points.

624

fiU NCERTAINTY

Start
Cooking

SOFT TEMPORAL CONSTRAINT PROBLEMS

[20,40]
End
Cooking

[0,10]

requirement constr.

[30,60]

contingent constr.

Start
Dinner

contingent timepoint

End
Dinner

executable timepoint

Figure 2: STPU Example 3.
Rr = {ci1 j1 , . . . , ciC jC }: set C requirement constraints;
Rc = {gi1 j1 , . . . , giG jG }: set G contingent constraints.2
Example 3 example taken (Vidal & Fargier, 1999), describes scenario
modeled using STPU. Consider two activities Cooking dinner. Assume
dont want eat dinner cold. Also, assume control start cooking
dinner starts finish cooking dinner over.
STPU modeling example depicted Figure 2. two executable time-points {Startcooking, Start-dinner} two contingent time-points {End-cooking, End-dinner}. Moreover,
contingent constraint variables {Start-cooking, End-cooking} models uncontrollable duration
fixing dinner take anywhere 20 40 minutes; contingent constraint
variables {Start-dinner, End-dinner} models uncontrollable duration dinner last
30 60 minutes. Finally, requirement constraint variables {End-cooking, Startdinner} simply bounds 10 minutes time food ready
dinner starts.2
Assignments executable variables assignments contingent variables distinguished:
Definition 9 (control sequence) control sequence assignment executable time-points.
said partial assigns values proper subset executables, otherwise complete.2
Definition 10 (situation) situation set durations contingent constraints.
contingent constraints assigned duration said partial, otherwise complete.2
Definition 11 (schedule) schedule complete assignment time-points X e Xc .
schedule identifies control sequence, , consisting assignments executable
time-points, situation, , set durations identified assignments
contingent constraints. Sol(P ) denotes set schedules STPU.2
easy see situation corresponds STP. fact, durations
contingent constraints fixed, uncertainty problem, becomes
STP, called underlying STP. formalized notion projection.
Definition 12 (projection) projection P , corresponding situation , STP obtained
leaving requirement constraints unchanged replacing contingent constraint g hk

625

fiROSSI , V ENABLE ,& YORKE -S MITH

constraint h[hk , hk ]i, hk duration event represented g hk . P roj(P )
set projections STPU P .2
2.4 Controllability
clear order solve problem uncertainty possible situations must considered.
notion consistency defined STPs apply since requires existence single
schedule, sufficient case since situations equally possible.2
reason, (Vidal & Fargier, 1999), notion controllability introduced. Controllability
STPU is, sense, analogue consistency STP. Controllable means agent
means execute time-points control, subject constraints. notion
controllability expressed, terms ability agent find, given situation,
appropriate control sequence. ability identified strategy:
Definition 13 (strategy) strategy map : P roj(P ) Sol(P ), every projection P , S(P ) schedule induces durations contingent constraints.
Further, strategy viable if, every projection P , S(P ) solution P .2
write [S(P )]x indicate value assigned executable time-point x schedule
S(P ), [S(P )]<x history x S(P ), is, set durations contingent constraints occurred S(P ) execution x, i.e. partial solution far.
(Vidal & Fargier, 1999), three notions controllability introduced STPUs.
2.4.1 TRONG C ONTROLLABILITY
first notion is, name suggests, restrictive terms requirements
control sequence must satisfy.
Definition 14 (Strong Controllability) STPU P Strongly Controllable (SC) iff
execution strategy s.t. P P roj(P ), S(P ) solution P , [S(P1 )]x = [S(P2 )]x ,
P1 , P2 projections every executable time-point x.2
words, STPU strongly controllable fixed execution strategy works
situations. means fixed control sequence consistent possible
scenario world. Thus, notion strong controllability related conformant
planning. clearly strong requirement. Vidal Fargier (1999) suggest, SC may
relevant applications situation observable complete
control sequence must known beforehand (for example cases activities depend
control sequence, production planning area).
(Vidal & Fargier, 1999) polynomial time algorithm checking STPU strongly
controllable proposed. main idea rewrite STPU given input equivalent STP
executable variables. important notice, contents paper,
algorithm StronglyControllable takes input STPU P = {X e , Xc , Rr , Rc } returns
output STP defined variables Xe . STPU input strongly controllable iff derived
STP consistent. Moreover, every solution STP control sequence guarantees
2. Tsamardinos (2002) augmented STPUs include probability distributions possible situations;
paper implicitly assume uniform, independent distribution link.

626

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

strong controllability STPU. STP consistent, output StronglyControllable
minimal form.
(Vidal & Fargier, 1999) shown complexity StronglyControllable O(n 3 ),
n number variables.
2.4.2 W EAK C ONTROLLABILITY
hand, notion controllability fewest restrictions control sequences
Weak Controllability.
Definition 15 (Weak Controllability) STPU P said Weakly Controllable (WC) iff
P P roj(P ) strategy s.t. (P ) solution P .2
words, STPU weakly controllable viable global execution strategy:
exists least one schedule every situation. seen minimum requirement since,
property hold, situations way execute
controllable events consistent way. looks attractive since, STPU shown
WC, soon one knows situation, one pick apply control sequence
matches situation. Unfortunately (Vidal & Fargier, 1999) shown property
useful classical planning. Nonetheless, WC may relevant specific applications (as largescale warehouse scheduling) actual situation totally observable (possibly
before) execution starts, one wants know advance that, whatever situation,
always least one feasible control sequence.
(Vidal & Fargier, 1999) conjectured (Morris & Muscettola, 1999) proven
complexity checking weak controllability co-NP-hard. algorithm proposed
testing WC (Vidal & Fargier, 1999) based classical enumerative process lookahead
technique.
Strong Controllability implies Weak Controllability (Vidal & Fargier, 1999). Moreover,
STPU seen STP uncertainty ignored. enforcing path consistency removes
elements contingent intervals, elements belong solution. so,
possible conclude STPU weakly controllable.
Definition 16 (pseudo-controllability) STPU pseudo-controllable applying path consistency leaves intervals contingent constraints unchanged.2
Unfortunately, path consistency leaves contingent intervals untouched, cannot conclude STPU weakly controllable. is, WC implies pseudo-controllability
converse false. fact, weak controllability requires given possible combination durations contingent constraints STP corresponding projection must consistent.
Pseudo-controllability, instead, guarantees possible duration contingent constraint least one projection contains duration consistent STP.
2.4.3 DYNAMIC C ONTROLLABILITY
dynamic applications domains, planning, situation observed time. Thus
decisions made even situation remains partially unknown. Indeed distinction
Strong Dynamic Controllability equivalent conformant conditional planning. final notion controllability defined (Vidal & Fargier, 1999) address
627

fiROSSI , V ENABLE ,& YORKE -S MITH

Pseudocode DynamicallyControllable
1. input STPU W;
2. W pseudo-controllable write DC stop;
3. Select triangles ABC, C uncontrollable, C,
upper bound BC interval, v, non-negative.
4. Introduce tightenings required Precede case
waits required Unordered case.
5. possible regressions waits,
converting unconditional waits lower bounds.
introduce lower bounds provided general reduction.
6. steps 3 4 produce new (or tighter)
constraints, return true, otherwise go 2.
Figure 3: Algorithm DynamicallyControllable proposed (Morris et al., 2001) checking DC
STPU.
[x,y]



C

requirement constr.
contingent constr.
contingent timepoint

[p,q]

[u,v]

executable timepoint

B

Figure 4: triangular STPU.
case. give definition provided (Morris et al., 2001) equivalent
compact.
Definition 17 (Dynamic Controllability) STPU P Dynamically Controllable (DC) iff
strategy P1 , P2 P roj(P ) executable time-point x:
1. [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x ;
2. S(P1 ) solution P1 S(P2 ) solution P2 .2
words, STPU dynamically controllable exists viable strategy built,
step-by-step, depending observed events step. SC = DC DC =
WC. Dynamic Controllability, seen useful controllability notion practice,
one requires complicated algorithm. Surprisingly, Morris et al. (2001) Morris
Muscettola (2005) proved DC polynomial size STPU representation. Figure 3
pseudocode algorithm DynamicallyControllable shown.
paper extend notion dynamic controllability order deal preferences. algorithm propose test extended property require good (even
complete) understanding DynamicallyControllable algorithm. Thus, give
necessary details algorithm.
628

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

seen, algorithm based considerations triangles constraints.
triangle shown Figure 4 triangular STPU one contingent constraint, AC, two executable
time-points, B, contingent time-point C. Based sign u v, three different
cases occur:
Follow case (v < 0): B always follow C. STPU path consistent DC
since, given time C occurs A, definition path consistency, always
possible find consistent value B.
Precede case (u 0): B always precede happen simultaneously C.
STPU dynamically controllable v x u, interval [p, q] AB
replaced interval [y v, x u], sub-interval containing elements
[p, q] consistent element [x, y].
Unordered case (u < 0 v 0): B either follow precede C. ensure dynamic
controllability, B must wait either C occur first, = v units time go
A. words, either C occurs B executed first value consistent
Cs time, B safely executed units time execution. described
additional constraint expressed wait AB written < C, >,
= v. course x v raise lower bound AB, p, v
(Unconditional Unordered Reduction), case raise x x > p (General
Unordered reduction) .
shown waits propagated (in Morris et al., 2001, term regressedis used
) one constraint another: wait AB induces wait another constraint involving A,
e.g. AD, depending type constraint DB. particular, two possible ways
waits regressed.
Regression 1: assume AB constraint wait hC, ti. Then, DB
constraint (including AB itself) upper bound, w, possible deduce wait hC,
wi AD. Figure 5(a) shows type regression.
Regression 2: assume AB constraint wait hC, ti, 0. Then,
contingent constraint DB lower bound, z, B 6= C, possible
deduce wait hC, zi AD. Figure 5(b) shows type regression.
Assume simplicity without loss generality executed time 0. Then, B
executed wait C executed first. wait expires, B safely
executed time left interval. Figure 6 shows, possible consider Follow
Precede cases special cases Unordered. Follow case put dummy wait
end interval, meaning B must wait C executed case (Figure 6
(a)). Precede case, set wait expires first element interval meaning
B executed C element interval consistent C (Figure 6
(b)). Unordered case thus seen combination two previous states. part
interval wait seen Follow case (in fact, B must wait C wait
expires), second part including following wait seen Precede case (after
wait expired, B executed assignment B corresponds element
part interval AB consistent possible future value assigned C).
629

fiROSSI , V ENABLE ,& YORKE -S MITH

[x,y]


[x,y]
C

Contingent

<C,t>

<C,tw>

C



[u,v]

Contingent

<C,t>

<C,tz>

[p,q]



[u,v]

[p,q]

B

B



[z,w]

[z,w]

requirement constr.
contingent constr.
controllable timepoint

requirement constr.
contingent constr.
controllable timepoint

contingent timepoint

contingent timepoint

(a) Regression 1

(b) Regression 2

Figure 5: Regressions algorithm DynamicallyControllable.

Follow Case

wait C executed
wait

execute regardless C

Precede Case

wait

Unordered Case

wait fo C executed

execute regardless C

wait

Figure 6: resulting AB interval constraint three cases considered
DynamicallyControllable algorithm.

DynamicallyControllable algorithm applies rules triangles STPU
regresses possible waits. inconsistency found, requirement interval becomes
empty contingent interval squeezed, STPU DC algorithm returns STPU
constraints may waits satisfy, intervals contain elements appear
least one possible dynamic strategy. STPU given execution algorithm
dynamically assigns values executables according current situation.
pseudocode execution algorithm, DC-Execute, shown Figure 7. execution
algorithm observes, time goes by, occurrence contingent events accordingly
executes controllables. controllable B, execution triggered (1) live,
630

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Pseudocode DC-Execute
1. input STPU P ;
2. Perform initial propagation start time-point;
3. repeat
4. immediately execute executable time-points
reached upper bounds;
5. arbitrarily pick executable time-point x
live enabled yet executed, whose waits,
any, satisfied;
6. execute x;
7. propagate effect execution;
8. network execution complete return;
9. else advance current time,
propagating effect contingent time-points occur;
10. false;
Figure 7: Algorithm executes dynamic strategy STPU.
is, current time within bounds, (2) enabled, is, executables constrained
happen occurred, (3) waits imposed contingent time-points B
expired.
DC-Execute produces dynamically consistent schedule every STPU algorithm
DynamicallyControllable reports success (Morris et al., 2001). complexity algorithm
O(n3 r), n number variables r number elements interval. Since
polynomial complexity relies assumption bounded maximum interval size, Morris et al.
(2001) conclude DynamicallyControllable pseudo-polynomial. DC algorithm strong
polynomial complexity presented (Morris & Muscettola, 2005). new algorithm differs
previous one mainly manipulates distance graph rather constraint
graph STPU. complexity O(n 5 ). important notice purposes that,
distance graph produced output new algorithm, possible directly recover
intervals waits STPU produced output original algorithm described (Morris
et al., 2001).

3. Simple Temporal Problems Preferences Uncertainty (STPPUs)
Consider temporal problem would model naturally preferences addition hard
constraints, one features uncertainty. Neither STPP STPU adequate model
problem. Therefore propose call Simple Temporal Problems Preferences Uncertainty, STPPUs short.
Intuitively, STPPU STPP time-points partitioned two classes, requirement contingent, STPU. Since time-points controllable
agent, notion consistency STP(P) replaced controllability,
STPU. Every solution STPPU global preference value, STPP, seek
solution maximizes value, satisfying controllability requirements.

631

fiROSSI , V ENABLE ,& YORKE -S MITH

precisely, extend definitions given STPPs STPUs fit STPPUs
following way.
Definition 18 context preferences:
executable time-point variable, x , whose time assigned agent;
contingent time-point variable, e , whose time assigned external world;
soft requirement link rij , generic time-points ti tj 3 , pair hIij , fij i, Iij =
[lij , uij ] lij (tj ) (ti ) uij (ti ) value assigned variable ti ,
fij : Iij preference function mapping element interval element
preference set, A, semiring = hA, +, , 0, 1i;
soft contingent link ghk , executable point bh contingent point ek , pair hIhk , fhk
interval Ihk = [lhk , uhk ] contains possible durations contingent event
represented bh ek fhk : Ihk preference function maps element
interval element preference set A.2
types constraints, preference function represents preference agent
duration event distance two events. However, soft requirement
constraints agent control guided preferences choosing values
time-points, soft contingent constraints preference represents merely desire agent
possible outcomes Nature: control outcomes. noticed
STPPUs uncertainty modeled, STPUs, assuming complete ignorance
events likely happen. Thus, durations contingent events assumed equally
possible (or plausible) different levels plausibility allowed.
state formally definition STPPUs, combines preferences
definition STPP contingency definition STPU.
Definition 19 (STPPU) Simple Temporal Problem Preferences Uncertainty (STPPU)
tuple P = (Ne , Nc , Lr , Lc , S) where:
Ne set executable time-points;
Nc set contingent time-points;
= hA, +, , 0, 1i c-semiring;
Lr set soft requirement constraints S;
Lc set soft contingent constraints S.2
Note that, STPPs, STPPUs model hard constraints soft constraints
element interval mapped maximal element preference set. Further, without
loss generality, following assumptions made STPUs (Morris et al., 2001), assume
two contingent constraints end time-point.
3. Again, general ti tj either contingent executable time-points.

632

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

complete assignment time-points compute global preference,
STPPs. done according semiring-based soft constraint schema: first project
assignment soft constraint, obtaining element interval preference
associated element; combine preferences obtained constraints
multiplicative operator semiring. Given two assignments preference, best
chosen using additive operator. assignment optimal assignment
preference better semirings ordering.
following summarize definitions given STPUs, extending directly
STPPUs.
Definition 20 Given STPPU P :
schedule complete assignment time-points N e Nc ;
Sched(P) set schedules P ; Sol(P) set schedules P
consistent constraints P (see Definition 1, Section 2.2);
Given schedule P , situation (usually written ) set durations contingent constraints s;
Given schedule P , control sequence (usually written set assignments
executable time-points s;
T, schedule [T, ]x = []x 4 , x Ne , every contingent constraint,
ghk Lc , defined executable bh contingent time-point ek , [T, ]ek -[T, ]bh = hk ,
hk duration ghk ;
projection P corresponding situation STPP obtained P leaving
requirement constraints unchanged replacing contingent constraint g hk soft
constraint h[hk , hk ], f (hk )i, hk duration event represented g hk
, f (hk ) preference associated duration;
Given projection P indicate Sol(P ) set solutions P define
OptSol(P ) = {s Sol(P )| 6 s0 Sol(P ), pref (s0 ) > pref (s)}; set preferences totally ordered indicate opt(P ) preference optimal solution
P ;
Proj(P) set projections STPPU P;
strategy map : P roj(P ) Sched(P ) every projection P , s(P )
schedule includes ;
strategy viable , S(P ) solution P , is, satisfies soft temporal
constraints. Thus viable strategy mapping : P roj(P ) Sol(P ). case
indicate pref (S(P )) global preference associated schedule S(P ) STPP
P .2
4. Regarding notation, case hard constraints, given executable time-point x, write [S(P )]x
indicate value assigned x S(P ), [S(P )]<x indicate durations contingent events
finish prior x S(P ).

633

fiROSSI , V ENABLE ,& YORKE -S MITH

1

0.9
0.5

x=1

8=y

EC

SC
1

1

0.9

p=1

0.9

0.6

0.6

u=6

5=q

4=v

SA
requirement constr.

1

contingent constr.

0.6

contingent timepoint

0.8

EA

executable timepoint

s=2

5=t

Figure 8: Example STPPU Earth Observing Satellites domain.
Example 4 Consider example following scenario Earth Observing Satellites
domain (Frank et al., 2001) described Section 1. Suppose request observing region
interest received accepted. collect data, instrument must aimed
target images taken. might be, however, certain period time
window allocated observation, region interest covered clouds. earlier
cloud coverage ends better, since maximise quality quantity retrieved
data; coverage controllable.
Suppose time window reserved observation 1 8 units time
start counting time cloud occlusion region interest observable. Also, suppose,
order observation succeed, aiming procedure must start 5 units
starting time, ideally 3 units, actually begin least 1 time unit
weather becomes observable. Ideally aiming procedure start slightly cloud
coverage end. starts early, then, since instrument activated immediately
aimed, clouds might still occlude region image quality poor. hand,
waits long clouds disappeared precious time
occlusion wasted aiming instrument instead taking images. aiming procedure
controlled mission manager take anywhere 2 5 units time.
ideal duration 3 4 units, since short time 2 units would put instrument pressure,
long duration, 5 units, would waste energy.
scenario, rather tedious describe words, compactly represented STPPU
shown Figure 8 following features:
set executable time-points SC (Start Clouds), SA (Start Aiming), EA (End Aiming);
contingent time-point EC (End Clouds);
set soft requirement constraints {SC SA, SA EC, SA EA};
soft contingent constraint {SC EC};

634

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

fuzzy semiring SFCSP = h[0, 1], max, min, 0, 1i.
solution STPPU Figure 8 schedule = {SC = 0, SA = 2, EC = 5, EA = 7}.
situation associated projection contingent constraint, SC EC,
i.e. = 5, control sequence assignment executable time-points, i.e. =
{SC = 0, SA = 2, EA = 7}. global preference obtained considering preferences
associated projections constraints, pref(2) = 1 SC SA, pref(3) = 0.6
SA EC, pref(5) = 0.9 SA EA, pref(5) = 0.8 SC EC. preferences
must combined using multiplicative operator semiring, min,
global preference 0.6. Another solution 0 = {SC = 0, SA = 4, EC = 5, EA = 9}
global preference 0.8. Thus s0 better solution according semiring ordering since
max(0.6, 0.8) = 0.8.2

4. Controllability Preferences
consider possible extend notion controllability accommodate preferences. general interested ability agent execute time-points
control, subject constraints best possible way respect preferences.
transpires meaning best possible way depends types controllability
required. particular, concept optimality must reinterpreted due presence uncontrollable events. fact, distinction nature events induces difference
meaning preferences expressed them, mentioned previous section. scenario given certain level desirability, expressing much agent likes
situation. Then, agent often several choices events controls consistent
scenario. choices might preferable respect others. expressed
preferences requirement constraints information guide agent
choosing best possible actions take. Thus, concept optimality relative
specific scenario. final preference complete assignment overall value combines
much corresponding scenario desirable agent well agent reacted
scenario.
concepts controllability propose are, thus, based possibility
agent execute events control best possible way given actual situation. Acting optimal way seen lowering preference given uncontrollable
events.
4.1 Strong Controllability Preferences
start considering strongest notion controllability. extend notion, taking
account preferences, two ways, obtaining Optimal Strong Controllability -Strong Controllability, preference level. see, first notion corresponds stronger
requirement, since assumes existence fixed unique assignment executable timepoints optimal every projection. second notion requires fixed assignment
optimal projections maximum preference value greater ,
yield preference 6< cases.

635

fiROSSI , V ENABLE ,& YORKE -S MITH

Definition 21 (Optimal Strong Controllability) STPPU P Optimally Strongly Controllable
(OSC) iff viable execution strategy s.t.
1. [S(P1 )]x = [S(P2 )]x , P1 , P2 P roj(P ) every executable time-point x;
2. S(P ) OptSol(P ), P P roj(P ). 2
words, STPPU OSC fixed control sequence works possible
situations optimal them. definition, optimal means
assignment agent choose executable time-points could yield higher preference
situation. Since powerful restriction, mentioned before, instead look
reaching certain quality threshold:
Definition 22 (-Strong Controllability) STPPU P -Strongly Controllable (-SC),
preference, iff viable strategy s.t.
1. [S(P1 )]x = [S(P2 )]x , P1 , P2 P roj(P ) every executable time-point x;
2. S(P ) OptSol(P ),P P roj(P ) 6 s0 OptSol(P ) pref (s0 ) > ;
3. pref (S(P )) 6< otherwise.2
words, STPPU -SC fixed control sequence works situations results optimal schedules situations optimal preference level
projection > schedule preference smaller cases.
4.2 Weak Controllability Preferences
Secondly, extend similarly least restrictive notion controllability. Weak Controllability requires existence solution possible situation, possibly different one situation.
extend definition requiring existence optimal solution every situation.
Definition 23 (Optimal Weak Controllability) STPPU P Optimally Weakly Controllable
(OWC) iff P P roj(P ) strategy s.t. (P ) optimal solution P .2
words, STPPU OWC if, every situation, control sequence results
optimal schedule situation.
Optimal Weak Controllability STPPU equivalent Weak Controllability corresponding STPU obtained ignoring preferences, formally prove Section 6.
reason projection P least one solution must optimal solution.
Moreover, STPPU underlying STPU either WC not. Hence
make sense define notion -Weak Controllability.
4.3 Dynamic Controllability Preferences
Dynamic Controllability (DC) addresses ability agent execute schedule choosing
incrementally values assigned executable time-points, looking past.
preferences available, desirable agent acts way guaranteed
consistent possible future outcome way ensures absence regrets
w.r.t. preferences.
636

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Definition 24 (Optimal Dynamic Controllability) STPPU P Optimally Dynamically Controllable (ODC) iff viable strategy P 1 , P2 P roj(P ) executable
time-point x:
1. [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x ;
2. S(P1 ) OptSol(P1 ) S(P2 ) = OptSol(P2 ).2
words, STPPU ODC exists means extending current partial control
sequence complete control sequence future way resulting schedule
optimal. before, soften optimality requirement preference reaching
certain threshold.
Definition 25 (-Dynamic Controllability) STPPU P -Dynamically Controllable (-DC)
iff viable strategy P 1 , P2 P roj(P ) every executable time-point x:
1. [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x ;
2. S(P1 ) OptSol(P1 ) S(P2 ) OptSol(P2 ) 6 s1 OptSol(P1 ) pref (s1 ) >
6 s2 OptSol(P2 ) pref (s2 ) > ;
3. pref(S(P1 )) 6< pref(S(P2 )) 6< otherwise.2
words, STPPU -DC means extending current partial control
sequence complete sequence; optimality guaranteed situations preference
6> . projections resulting dynamic schedule preference smaller
.
4.4 Comparing Controllability Notions
consider relation among different notions controllability STPPUs.
Recall STPUs, SC = DC = W C (see Section 2). start giving similar
result holds definitions optimal controllability preferences. Intuitively,
single control sequence optimal situations, clearly executed
dynamically, assigning values control sequence current time reaches them.
Moreover if, whatever final situation be, know consistently assign values
executables, looking past assignments, never backtrack preferences,
clear every situation least optimal solution.
Theorem 1 STPPU P OSC, ODC; ODC, OWC.
Proofs theorems given appendix. opposite implications Theorem 1
hold general. fact sufficient recall hard constraints special case soft
constraints use known result STPUs (Morris et al., 2001).
examples consider following two, defined fuzzy semiring. Figure 9 shows
STPPU OWC ODC. is, fact, easy see assignment C,
projection STPPU consistently extended assignment B. However,
show Section 7 STPPU depicted ODC.
637

fiROSSI , V ENABLE ,& YORKE -S MITH

11 1
0.9

0.8
0.7
0.6
0.5

x=3 4

5 6



7

8

9 10=y

C

contingent

1
0.9

1 1 1
0.9

0.8

0.9
0.8

0.8

0.7

0.7

0.7

0.6

0.6

0.6
p=3 4 5

6 7=q

requirement constr.

u=4 3 2 1

B

contingent constr.

0 1

2

3

contingent timepoint
executable timepoint

Figure 9: STPPU OWC ODC.

1

1



2

C

1

2

1

3

B

1

requirement constr.
contingent constr.
contingent timepoint
executable timepoint

Figure 10: STPPU ODC OSC.

638

4

5

6=v

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Figure 10, instead, shows ODC STPPU OSC. B two executable timepoints C contingent time-point. two projections, say P 1 P2 , corresponding respectively point 1 point 2 AC interval. optimal preference level 1.
fact, hA = 0, C = 1, B = 2i solution P 1 preference 1 hA = 0, C = 2, B = 3i
solution P2 preference 1. STPPU ODC. fact, dynamic strategy
assigns B value 2, C occurs 1, value 3, C occurs 2 (assuming always assigned
0). However single value B optimal scenarios.
Similar results apply case -controllability, following formal treatment shows.
Theorem 2 given preference level , STPPU P -SC -DC.
Again, converse hold general. example consider STPPU shown
Figure 10 = 1. Assuming = 1, STPPU 1-DC but, shown above,
1-SC.
Another useful result controllability property holds given preference level, say ,
holds < , stated following theorem.
Theorem 3 Given STPPU P preference level , P -SC (resp. -DC), -SC
(resp. -DC), < .
Let us consider case preference set totally ordered. eliminate
uncertainty STPPU, regarding contingent time-points executables, obtain
STPP. STPP solved obtaining optimal preference value opt. preference level,
opt, useful relate optimal controllability -controllability. stated following
theorem, STPPU optimally strongly dynamically controllable satisfies
corresponding notion -controllability = opt.
Theorem 4 Given STPPU P defined c-semiring totally ordered preferences, let opt =
maxT Sol(P ) pref (T ). Then, P OSC (resp. ODC) iff opt-SC (resp. opt-DC).
OWC, formally prove Section 6 STPPU OWC iff STPU obtained
ignoring preference functions WC. relation min -controllability
controllability without preferences, recall considering elements intervals mapped
preference min coincides definition considering underlying STPU obtained
ignoring preference functions STPPU. Thus, min -X holds iff X holds, X either
SC DC.
Figure 11 summarize relationships holding among various controllability notions
preferences totally ordered. instead partially ordered, relationships
opt X min X, X controllability notion, make sense. fact,
partially ordered case, several optimal elements several minimal elements,
one.

5. Determining Optimal Strong Controllability -Strong Controllability
next sections give methods determine levels controllability hold STPPU.
Strong Controllability fits off-line scheduling allowed, sense fixed optimal
control sequence computed execution begins. approach reasonable planning
639

fiROSSI , V ENABLE ,& YORKE -S MITH

OSC


ODC

/ opt-SC

/ opt-DC

/ -SC


/ -DC

/ min -SC

/ min -DC



OWC

/ SC


/ DC


/ WC

Figure 11: Comparison controllability notions total orders. min smallest preference
constraint: opt min .
algorithm knowledge possible outcomes, agents preferences.
situation requires us find fixed way execute controllable events consistent
possible outcome uncontrollables give best possible final preference.
5.1 Algorithm Best-SC
algorithm described section checks whether STPPU OSC. OSC,
algorithm detect return highest preference level problem
-SC.
algorithms present paper rely following tractability assumptions,
inherited STPPs: (1) underlying semiring fuzzy semiring F CSP defined Section 2.2, (2) preference functions semi-convex, (3) set preferences [0, 1] discretized finite number elements according given granularity.
algorithm Best-SC based simple idea: preference level , finds
control sequences guarantee strong controllability projections optimal
preference , optimality optimal preference . Then, keeps
control sequences preference levels > .
pseudocode shown Figure 12. algorithm takes input STPPU P (line 1).
first step, lowest preference min computed. Notice that, efficiently, analytical
structure preference functions (semi-convexity) exploited.
line 3 STPU obtained P cutting preference level min considered.
STPU obtained applying function min -Cut(STPPU G) G=P 5 . general, result
-Cut(P ) STPU Q (i.e., temporal problem uncertainty preferences) defined
follows:
Q variables domains P;
every soft temporal constraint (requirement contingent) P variables X , Xj ,
say c = hI, f i, is, Q , simple temporal constraint variables defined
{x I|f (x) }.
Notice semi-convexity preference functions guarantees set {x I|f (x) }
forms interval. intervals Q contain durations requirement contingent events
local preference least .
5. Notice function -Cut applied STPPs STPPUs: first case output STP,
latter case STPU. Notice that, -Cut known concept fuzzy literature.

640

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Pseudocode Best-SC
1. input STPPU P ;
2. compute min ;
3. STPU Qmin min -Cut(P );
4. (StronglyControllable (Qmin ) inconsistent) write min -SC stop;
5. else {
6. STP P min StronglyControllable (Qmin );
7. preference min + 1;
8. bool OSCfalse, bool -SCfalse;
9. {
10.
STPU Q -Cut(P );
11.
(PC(Q ) inconsistent) OSCtrue;
12.
else {
13.
(StronglyControllable(PC(Q )) inconsistent) -SC true;
14.
else {
N
15.
STP P P 1
StronglyControllable(PC(Q )) ;

16.
(P inconsistent) { -SC true };
17.
else { + 1 };
18.
}
19.
}
20.
}while (OSC=false -SC=false);
21. (OSC=true) write P OSC;
22. (-SC=true) write P ( 1) -SC;
23. se =Earliest-Solution(P 1 ), sl =Latest-Solution(P 1 );
24. return P 1 , se , sl ;
25. };
Figure 12: Algorithm Best-SC: tests STPPU OSC finds highest
STPPU P -SC.

641

fiROSSI , V ENABLE ,& YORKE -S MITH

STPU Qmin obtained, algorithm checks strongly controllable. STP
obtained applying algorithm StronglyControllable (Vidal & Fargier, 1999) STPU Q min
consistent, then, according Theorem 3, hope higher preference, algorithm stop (line 4), reporting STPPU -SC 0 thus OSC well.
If, instead, inconsistency found, Best-SC stores resulting STP (lines 5-6) proceeds
moving next preference level min + 1 6 (line 7).
remaining part algorithm (lines 9-21), three steps performed preference
level considered:
Cut STPPU P obtain STPU Q (line 10);
Apply path consistency Q considering STP: PC(Q ) (line 11);
Apply strong controllability STPU PC(Q ) (line 13).
Let us consider last two steps detail.
Applying path consistency STPU Q means considering STP, is, treating contingent constraints requirement constraints. denote algorithm PC algorithm enforcing
path-consistency temporal network (see Section 2.1 Dechter et al., 1991). returns
minimal network leaving intervals values contained least one solution.
allows us identify situations, , correspond contingent durations locally
preference consistent least one control sequence elements Q .
words, applying path consistency Q leaves contingent intervals durations
belong situations corresponding projections optimal value least .
test gives inconsistency, means given STPU, seen STP, solution,
hence projections corresponding scenarios STPPU P optimal preference <
(line 11).
third last step applies StronglyControllable path-consistent STPU PC(Q ), reintroducing information uncertainty contingent constraints. Recall algorithm
rewrites contingent constraints terms constraints executable time-points.
STPU strongly controllable, StronglyControllable leave requirement intervals
elements identify control sequences consistent possible situation. case,
applying StronglyControllable PC(Q ) find, any, control sequences PC(Q )
consistent possible situation PC(Q ).
However, STPU PC(Q ) strongly controllable, control sequences found might
optimal scenarios optimal preference lower . order keep
control sequences guarantee optimal strong controllability preference levels ,
STP obtained StronglyControllable(PC(Q )) intersected corresponding STP found
previous step (at preference level 1), P 1 (line 15). recall given two
two STPs, P1 P2 , defined set variables, STP P3 = P1 P2
variables P1 P2 temporal constraint, c3ij = c1ij c2ij , intersection
corresponding intervals P1 P2 . intersection becomes empty constraint
STP obtained inconsistent, conclude control sequence guarantee
strong controllability optimality preference level and, time, preferences
6. writing min + 1 mean next preference level higher min defined terms granularity
preferences [0,1] interval.

642

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Table 1: table row corresponds preference level represents intervals
STPU Q obtained cutting STPPU Figure 8 level .
STPU

(SC EC)

(SC SA)

(SA EC)

Q0.5
Q0.6
Q0.7
Q0.8
Q0.9
Q1

[1, 8]
[1, 7]
[1, 6]
[1, 5]
[1, 4]
[1, 2]

[1, 5]
[1, 5]
[1, 5]
[1, 5]
[1, 5]
[1, 3]

[6, 4]
[6, 4]
[5, 2]
[4, 1]
[3, 0]
[2, 1]

Table 2: table row corresponds preference level represents intervals
STPU PC(Q ) obtained applying path consistency STPUs Table 1.
STPU
0.5

PC(Q )
PC(Q0.6 )
PC(Q0.7 )
PC(Q0.8 )
PC(Q0.9 )
PC(Q1 )

(SC EC)

(SC SA)

(SA EC)

[1, 8]
[1, 7]
[1, 6]
[1, 5]
[1, 4]
[1, 2]

[1, 5]
[1, 5]
[1, 5]
[1, 5]
[1, 5]
[2, 3]

[4, 4]
[4, 4]
[4, 2]
[4, 1]
[3, 0]
[2, 1]

< (line 16). If, instead, STP obtained consistent, algorithm Best-SC considers next
preference level, + 1, performs three steps again.
output algorithm STP, P 1 , obtained iteration previous one
causing execution stop (lines 23-24) two solutions, e sl . STP,
show shortly, contains control sequences guarantee -SC = 1.
1 highest preference level cutting gives consistent problem, STPPU
OSC. solutions provided algorithm respectively earliest, e , latest, sl ,
solutions P 1 . fact, proved (Dechter et al., 1991) mentioned Section 2.1, since
P 1 minimal, earliest (resp. latest) solution corresponds assigning variable
lower (resp. upper) bound interval constraint defined X0 variable.
indicated algorithm procedures Earliest-Solution Latest-Solution. Let us recall
every solution found P 1 without backtracking.
formally proving correctness algorithm Best-SC, give example.
Example 5 Consider STPPU described Example 4, depicted Figure 8. simplicity
focus triangular sub-problem variables SC, SA, EC. example, min = 0.5.
Table 1 shows STPUs Q obtained cutting problem preference level = 0.5, . . . , 1.
Table 2 shows result applying path consistency (line 11) STPUs shown
Table 1. seen, STPUs consistent. Finally, Table 3 shows STPs defined
executable variables, SC SA, obtained applying StronglyControllable
STPUs Table 2.

643

fiROSSI , V ENABLE ,& YORKE -S MITH

Table 3: table row corresponds preference level represents intervals
STP StronglyControllable PC(Q ) obtained applying strong controllability check
STPUs Table 2.
(SC SA)

STP
0.5

StronglyControllable(PC(Q ))
StronglyControllable(PC(Q0.6 ))
StronglyControllable(PC(Q0.7 ))
StronglyControllable(PC(Q0.8 ))
StronglyControllable(PC(Q0.9 ))
StronglyControllable(PC(Q1 ))

[4, 5]
[3, 5]
[4, 5]
[4, 5]
[4, 4]
[3, 3]

looking Tables 2 3 easy deduce Best-SC stop preference level
1. fact, looking carefully Table 3, see STP P 0.9 consists interval [4, 4]
constraint SC SA, StronglyControllable(PC(Q 1 )) consist interval [3, 3]
constraint. Obviously intersecting two gives inconsistency, causing condition
line 16 Figure 12 satisfied.
conclusion executing Best-SC example depicted Figure8 0.9-SC
OSC. Let us see correct. Without loss generality assume SC
assigned value 0. last line Table 3 observe value assigned
SA optimal scenarios optimal preference 1 (that EC assigned
1 2) 3. However, assigning 3 SA optimal EC happens 6, since scenario
optimal preference value 0.7 (e.g. SA assigned 5) case would global
preference 0.6 (given constraint SA EC) 7 .2
5.2 Properties Best-SC
prove algorithm Best-SC correctly identifies whether STPPU P OSC, and,
not, finds highest preference level P -SC. Let us first consider events
Best-SC stops.
Event 1. StronglyControllable(Q min ) inconsistent (line 4);
Event 2. PC(Q ) returns inconsistency (line 11);
Event 3. PC(Q ) consistent strongly controllable (line 13);
Event 4. PC(Q ) strongly controllable, however intersection STP obtained
StronglyControllable(PC(Q )) STP obtained previous preference level,
P 1 , inconsistent (line 16).
First notice algorithm terminates.
Theorem 5 Given STPPU P finite number preference levels, execution algorithm Best-SC P terminates.
7. Recall fuzzy semiring context global preference assignment computed taking minimum
preference assigned projections.

644

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Intuitively, either one termination events occur preference levels exhausted.
Next, let us show Best-DC sound complete algorithm checking STPPU
OSC finding highest preference level -SC.
said before, cutting STPPU P preference level gives STPU Q .
Moreover, every situation = {1 , . . . , l } Q seen situation P
fj (j ) , j. implies every projection P P roj(Q ), STP, corresponds projection P P roj(P ) STPP. situations Q , follows
write always P interpreted STP seen projection Q
STPP seen projection P . following lemmas state properties
relate solutions projections two contexts: without preferences.
Theorem 6 Consider STPPU P = hNe , Nc , Lr , Lc , SF CSP preference level , consider STPU Q = hNe , Nc , L0r , L0c obtained cutting P , STPU PC(Q )=hNe , Nc ,
L00r , L00c i. Then:
1. situation P , P P roj(PC(Q )) iff optP (P ) ;
2. every control sequence , solution = StronglyControllable(PC(Q ), iff P
Proj(PC (Q )), T, Sol(P ) pref (T, ) .
first part theorem states that, applying path consistency STPU Q , remove
situations cannot extended complete solutions Q , thus correspond projections optimal preference strictly less . second part lemma considers
STP obtained applying StronglyControllable path consistency. particular stated
solutions result, projections PC (Q ), solutions preference
least . Notice implies result optimal solutions projections P
optimal preference exactly . might optimal, however, projections
optimal preference strictly greater .
theorem, get following corollary, clarifies relation
STPU obtained cutting STPPU preference level , -SC STPPU.
Corollary 1 Consider STPPU P preference level assume , situation P ,
opt(P ) , P corresponding projection. Then, STPU PC(Q ), obtained
cutting P , applying path consistency, SC P -SC.
consider preference levels min , compute corresponding
STPs, say min , . . . , , STP identify assignments executable variables guaranteeing strong controllability optimality level. intersecting STPs keep
common solutions thus guarantee strong controllability optimality
situations P optimal preference smaller equal .
Theorem 7 Consider STPPU P , preference levels min , assume
corresponding STPs, min , . . . , obtained cutting P preference levels N
min , . . . , ,
enforcing strong controllability consistent. Then, Sol(P ), P = i=min ,..., ,
iff P P roj(P ): T, Sol(P ), opt(P ) , pref (T, ) = opt(P ), otherwise
pref (T, ) .
645

fiROSSI , V ENABLE ,& YORKE -S MITH

consider events Best-SC stop prove
strong controllability properties hold.
Theorem 8 execution algorithm Best-SC STPPU P stops due occurrence
Event 1 (line 4), P -SC 0.
case underlying STPU obtained STPPU ignoring preference
functions strongly controllable. Since cutting higher preferences give even smaller
intervals hope controllability level execution halt.
Theorem 9 execution algorithm Best-SC STPPU P stops due occurrence
Event 2 (line 11) preference level ,
1 = opt = maxT Sol(P ) pref (T );
P OSC control sequence solution STP P opt (returned algorithm) iff
optimal scenario P .
event occurs algorithm cuts STPPU given preference level STPU
obtained, seen STP, inconsistent. particular, means projection P roj(P )
optimal preference equal greater preference level. However, level
reached, previous level, assignments guaranteeing SC optimality
found. Moreover, previous level must highest preference solution
P , opt(P ). means opt(P )-SC established, Theorem 4 equivalent
OSC.
Theorem 10 execution algorithm Best-SC STPPU P stops due occurrence
Event 3 (line 13) Event 4 (line 16) preference level , P OSC ( 1)SC solution STP P 1 (returned algorithm) that, P P roj(P ):
T, Sol(P ), opt(P ) 1, pref (T, ) = opt(P ), otherwise pref (T, ) 1.
Intuitively, algorithm reaches stops line 13, projections P
optimal preference corresponding set situations SC. Notice exactly
situation considered Corollary 1. instead stops line 16, set situations SC,
none assignments guaranteeing SC situations optimal
situations preference levels . cases problem -SC. However, assuming
first level execution stopped problem 1-SC.
conclude section considering complexity Best-SC.
Theorem 11 Determining OSC highest preference level -SC STPPU n
variables ` preference levels achieved time O(n 3 `).
Notice cannot use binary search preference levels (in contrast algorithms
STPPs), since correctness procedure based intersection result obtained
given preference level, , obtained preference levels < .
theorem allows us conclude cost adding preferences, thus considerable expressive power, low. fact, complexity still polynomial grown
factor equal number preference levels.
646

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

6. Determining Optimal Weak Controllability
Optimal Weak Controllability least useful property practice property
adding preferences smallest impact terms expressiveness. OWC requires
existence optimal solution every possible scenario. equivalent requiring
existence solution every situation, stated following theorem.
Theorem 12 STPPU P OWC iff STPU Q, obtained simply ignoring preference functions constraints WC.
ignoring preference functions mean mapping soft constraint hI, f hard
constraint hIi defined variables. theorem allows us conclude that, check
OWC, enough apply algorithm WeaklyControllable proposed (Vidal & Ghallab, 1996)
described Section 2. If, instead, given scenario , find optimal
solution projection, STPP P roj(), using one solvers described (Rossi et al.,
2002).
Let us consider Example 4 again. Section 5 showed STPU obtained cutting
STPPU Figure 8 preference level min strongly controllable. Since SC implies WC,
conclude STPU weakly controllable and, thus, STPPU Figure 8 Optimally
Weakly Controllable.

7. Determining Optimal Dynamic Controllability -Dynamic Controllability
Optimal Dynamic Controllability (ODC) interesting useful property practice.
described Section 1, many industrial applications solved dynamic fashion,
making decisions response occurrences events execution plan.
true space application domains, planning mission handled decomposing
problem set scheduling subproblems, depend occurrence semipredictable, contingent events (Frank et al., 2001).
section describe algorithm tests whether STPPU P ODC and, ODC,
finds highest P -DC. algorithm presented bears similarities
Best-SC, sense decomposes problem STPUs corresponding different preference
levels performs bottom search dynamically controllable problems space.
Notice algorithm attractive practice, since output minimal form
problem assignments belonging least one optimal solution left domains
executable time-points. minimal form given input execution algorithm,
describe, assigns feasible values executable time-points dynamically
observing current situation (i.e., values contingent time-points occurred).
7.1 Necessary Sufficient Condition Testing ODC
define necessary sufficient condition ODC, defined intervals
STPPU. propose algorithm tests condition, show
sound complete algorithm testing ODC.
first claim that, given STPPU, dynamic controllability STPUs obtained
cutting STPPU applying PC every preference level necessary sufficient
condition optimal dynamic controllability given STPPU.
647

fiROSSI , V ENABLE ,& YORKE -S MITH

Theorem 13 Given STPPU P , consider preference level STPU Q , obtained
cutting P , consistent. STPU PC(Q ) DC P ODC -DC,
.
Unfortunately condition sufficient, since STPPU still ODC even
every preference level STPU obtained PC DC. example shown Figure 9
described below.
Example 6 Another potential application STPPUs scheduling aircraft analysis airborne
particles (Coggiola, Shi, & Young, 2000). example consider aircraft equipped
instruments Small Ice Detector Nevzorov probe, used discriminate liquid ice given types clouds. analysis important prediction
evolution precipitatory systems occurrence severity aircraft icing (Field,
Hogan, Brown, Illingworth, Choularton, Kaye, Hirst, & Greenaway, 2004). instruments need
uncertain amount time determine predominant state, liquid ice,
activated inside cloud.
example shown Figure 9 consider sensing event represented variables
C start time maneuver aircraft represented variable B. Due
instruments function, aircraft maneuver impact analysis. example constraint AC
represents duration sensing event preference function models fact
earlier predominant state determined better. Constraint AB models instead fact
maneuver start soon possible, example, due time constraints imposed
aircrafts fuel availability. Constraint BC models fact maneuver ideally start
sensing event ended.
Let us call P STPPU depicted Figure 9. order determine highest preference level
schedule P can, example use algorithm Chop-solver (Rossi et al., 2002).
highest preference level cutting functions gives consistent STP 1 (interval [3, 3]
AB, [3, 5] AC interval [0, 2] BC consistent STP). optimal solutions P , regarded
STPP, global preference 1.
Consider STPUs obtained cutting every preference level highest, 1,
lowest 0.5. minimum preference constraint P min = 0.5 and, easy see,
STPUs obtained cutting P applying PC preference levels 0.5 1
DC. However, P ODC. fact, dynamic assignment B belongs optimal
solution projections corresponding elements 3, 4 5 [x, y] 3. executing B 3
cause inconsistency C happens 10, since 10 3 = 7 doesnt belong [u, v].2
elaborate example find sufficient condition ODC. Consider intervals
AB, [p , q ], waits < C, > obtained applying DC checking algorithm preference
level . shown Table 4.
look first last intervals, resp., = 1 = 0.5, way assign
value B time induces preference 1 constraints AB BC, C occurs 3, 4
5, satisfies wait < C, 4 >, ensuring consistency C occurs 10. depends
fact intersection [p 1 , q 1 ], i.e., [3], sub interval [p 0.5 , q 0.5 ] satisfies
< C, 4 >, is, [4, 7], empty.
claim non-emptiness intersection, together DC STPUs
obtained cutting problem preference levels necessary sufficient condition
648

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Table 4: table row corresponds preference level represents corresponding
interval wait AB constraint STPPU shown Figure 9.


[p , q ]

wait

1
0.9
0.8
0.7
0.6
0.5

[3, 3]
[3, 4]
[3, 5]
[3, 6]
[3, 7]
[3, 7]

< C, 3 >
< C, 3 >
< C, 3 >
< C, 3 >
< C, 4 >

ODC. following section describe algorithm tests condition. Then,
Section 7.3, prove algorithm sound complete w.r.t. testing ODC
finding highest level -DC.
7.2 Algorithm Best-DC
algorithm Best-DC echoes Section 5s algorithm checking Optimal Strong Controllability.
done Best-SC, considers STPUs obtained cutting STPPU various preference
levels. preference level, first tests whether STPU obtained considering STP
path consistent. Then, checks path consistent STPU obtained dynamically controllable,
using algorithm proposed (Morris et al., 2001). Thus, control sequences guarantee
DC scenarios different optimal preferences found. next step select
sequences satisfy DC requirement optimal preference levels.
pseudocode given Figure 13. Algorithm Best-DC takes input STPPU P (line 1)
computes minimum preference, min , assigned constraint (line 2).
min known, STPU obtained cutting P min computed (line 3).
STPU seen STPPU P variables intervals constraints P
preferences. STPU, denoted Q min , given input algorithm
DynamicallyControllable. Qmin dynamically controllable, P ODC DC (for min , hence ), shown Theorem 13. algorithm detects
inconsistency halts (line 4). If, instead, Q min dynamically controllable, STPU
returned output DynamicallyControllable saved denoted P min (line 6). Notice
STPU minimal, sense intervals elements belonging
least one dynamic schedule (Morris et al., 2001). addition, since preferences,
elements requirement intervals, well belonging least one dynamic schedule,
part optimal schedules scenarios projection optimal preference equal
min 8 .
line 7 preference level updated next value ordering considered (according given preference granularity). line 8 two Boolean flags, ODC -DC
defined. Setting flag ODC true signal algorithm established problem ODC, setting flag -DC true signal algorithm found highest
preference level STPPU -DC.
8. fact, preference least min definition.

649

fiROSSI , V ENABLE ,& YORKE -S MITH

Pseudocode Best-DC
1. input STPPU P ;
2. compute min ;
3. STPU Qmin min -Cut(P );
4. (DynamicallyControllable(Q min ) inconsistent) write min -DC stop;
5. else {
6. STP P min DynamicallyControllable(Qmin );
7. preference min + 1;
8. bool ODC false, bool -DC false;
9. {
10.
STPU Q -Cut(P );
11.
(PC(Q ) inconsistent) ODC true;
12.
else {
13.
(DynamicallyControllable(PC(Q )) inconsistent) -DC true;
14.
else {
15.
STPU DynamicallyControllable(PC(Q ));
16.
if(Merge(P 1 , ) FAILS) { -DC true }
17.
else {
18.
STPU P Merge(P 1 , );
19.
+ 1;
20.
};
21.
};
22.
};
23. }while (ODC=false -DC=false);
24. (ODC=true) write P ODC;
25. (-DC=true) write P ( 1) -DC;
26. return STPPU F 1 resulting STPPU(P ,P 1 );
27. };
Figure 13: Algorithm tests STPPU ODC and, not, finds highest STPPU
P -DC.

650

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Pseudocode Merge
1. input (STPU , STPU +1 );
2. STPU P +1 ;
3. constraint AB, B executables, P +1
define interval [p0 , q 0 ] wait t0 ,
given { interval [p , q ], wait }
{ interval [p+1 , q +1 ], wait t+1 +1 }, follows:;
4. (t = p t+1 = p+1 ) (Precede - Precede)
5. p0 max(p , p+1 ), q 0 min(q , q +1 ), t0 max(t , t+1 );
6. (q 0 < p0 ) return FAILED;
7. (p < < q p+1 t+1 < q +1 ) (Unordered - Unordered Precede)
8. t0 max(t , t+1 ), q 0 min(q , q +1 );
9. (q 0 < t0 ) return FAILED;
10. output P +1 .
Figure 14: Algorithm Merge.
Lines 9-25 contain main loop algorithm. short, time loop executed,
cuts P current preference level looks cutting produced path consistent STPU
(seen STP). so, checks path consistent version STPU dynamically
controllable and, test passed, new STPU created merging current
results previous levels.
describe step detail. Line 10 cuts P current preference level . line 11
consistency STPU Q tested applying algorithm PC. PC returns inconsistency,
conclude P schedule preference (or greater).
next step check STPU PC(Q ) DC. Notice required preference
levels optimal level order P ODC, order P -DC
(Theorem 13). applying algorithm DynamicallyControllable detects PC(Q ) dynamically controllable, algorithm sets flag -DC true. If, instead, PC(Q ) dynamically
controllable resulting minimal STPU saved denoted (line 15).
line 16, output procedure Merge tested. procedure used combine
results preference 1 preference , applying STPU obtained
end previous iteration, P 1 , STPU . pseudocode Merge
shown Figure 14, describe detail shortly. inconsistency found, new
STPU obtained merging procedure denoted P (line 18) new preference level
considered (line 19).
Lines 24-27 take care output. Lines 24 25 write output P ODC or, not,
highest -DC. line 27 final STPPU, F , given output, obtained
STPU P 1 , is, STPU obtained last iteration cycle
completed success (i.e., reached line 20). Function Resulting STPPU restores
preferences intervals P 1 setting P . show
requirement constraints F contain elements corresponding dynamic schedules
always optimal, result P ODC, optimal scenarios corresponding
projections optimal preference guarantee global preference level least
others, result P -DC.
651

fiROSSI , V ENABLE ,& YORKE -S MITH

pseudocode procedure Merge given Figure 14. input consists two STPUs
defined set variables. describing Merge works, assume given
input two STPUs, +1 , obtained cutting two STPPUs preference levels + 1
applying, hypothesis success, PC DynamicallyControllable (line 1 Figure 14).
line 2, Merge initializes STPU given output . formally proven Theorem 14, due semi-convexity preference functions
P roj(T +1 ) P roj(T ). Notice Merge leaves contingent constraints unaltered. Thus,
projection optimal preference + 1 contained set projections P +1 .
Merge considers every requirement constraint defined two executables, say B,
respectively +1 . Since assuming algorithm DynamicallyControllable
applied STPUs, waits intervals. Figure 6 illustrates three
cases interval AB be. wait expires upper bound interval
(Figure 6 (a)), execution B must follow execution every contingent time-point
(Follow case). wait coincides lower bound interval (Figure 6 (b)),
execution B must precede contingent time-point (Precede case). Finally, shown
Figure 6 (c), wait within interval, B Unordered case least
contingent time-point, say C.
Merge considers case corresponding intervals +1 (line 3).
intervals respectively indicated [p , q ], wait , [p+1 , q +1 ], wait t+1 .
Merge obtains new interval [p0 , q 0 ] new wait t0 , replace old wait +1 .
Interval [p0 q 0 ] contain values projections AB constraint
optimal solution STPP corresponding situation +1 . Wait t0 wait
respected dynamic execution order guarantee solution obtained
optimal, projection corresponding final scenario preference + 1.
Due semi-convexity preference functions cannot case that:
AB Follow Precede case Unordered case +1 ;
AB Follow case Precede case +1 ;
AB Precede case Follow case +1 ;
means cases considered are:
AB Follow case +1 ;
AB Precede case +1 ;
AB Unordered case Precede Unordered case +1 ;
first two cases AB interval left T+1 . formal motivation
contained proof Theorem 14. However, informally, say AB interval
+1 already satisfies desired property.
lines 4 5 case AB Precede case STPUs examined. Here, B
always occur contingent time-point. values [p , q ] (resp. [p+1 , q +1 ])
assignments B consistent future occurrence C mapped preference (resp. + 1). Clearly intersection taken order lower

652

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

preference C occurs preference + 1. Line 6 considers event intersection empty. means common assignment B, given A,
optimal scenarios optimal preference scenarios optimal preference + 1.
lines 7 8 two scenarios considered: AB Unordered case
Precede case +1 AB Unordered case STPUs. Figure 15
shows second case. Merge takes union parts intervals preceding wait
intersection parts following wait. intuition underlying execution
B identifying element either [p , [ [p+1 , t+1 [ preceded execution
contingent time-points wait. means B executed,
contingent time-point C, time C executed, say C ,
associated preference, say fAC (tC ), constraint AC STPPU P known. propagation
information allow us identify elements [p , [ (resp. [p+1 , t+1 [)
preference fAC (tC ) thus optimal assignment B. means elements
interval [p , [ interval [p+1 , t+1 [ eligible chosen. example, f AC (tC ) =
might values B preference equal optimal case would
C occurred time fAC (tC ) > . since case know
preference C occurred, propagation step prune non-optimal choices B.
short, leaving elements allows flexibility propagation step. Moreover,
proven Theorem 14, p p+1 .
instead consider elements interval [t , q ], know identify assignments
B executed regardless C happen (however know happen
preference greater ). means must take intersection part
corresponding one, [t+1 , q +1 ], order guarantee consistency optimality
C occurs time preference = + 1. easy way see interval [t , q ]
may contain elements P mapped preference . elements optimal
scenarios C happens time associated preference = AC constraint;
however, cannot optimal scenarios C occurring time preference + 1.
Line 9 handles case two parts intervals, following waits,
empty intersection. case, optimality cannot guaranteed neither level + 1,
particular contingent events occur waits expire.
7.3 Properties Best-DC
show Best-DC sound complete algorithm testing ODC finding
highest preference level STPPU given input -DC. recall, more,
results follow rely tractability assumptions requiring semi-convex preference
functions fuzzy semiring h[0, 1], max, min, 0, 1i underlying structure.
Let us consider STPPU P STPUs +1 , defined previous section. Then,
STPU P +1 =Merge (T , +1 ) contingent constraints 9 requirement constraints defined merging procedure. start proving Merge sound
complete algorithm testing existence viable dynamic strategy, common
STPUs, optimal projections optimal preference equal either + 1.
9. recall projections coincide projections STPPU P optimal preference (see
Theorem 6), that, due semi-convexity preference functions, P roj(T +1 ) P roj(T ).

653

fiROSSI , V ENABLE ,& YORKE -S MITH

Interval AB
STPU +1

Interval AB
STPU

(a)
+1

+1

+1

p



q







p

q



Merged interval AB




p



(b)

+1

(c)

q

Figure 15: Merging two intervals Unordered case.
Theorem 14 Consider STPPU P STPUs, +1 , obtained cutting P respectively
level + 1 applying PC, without finding inconsistencies, DynamicallyControllable
success. Consider STPU P +1 = Merge(T , +1 ).
Then, Merge(T , +1 ) fail
P +1 dynamically controllable
viable dynamic strategy every projection P P roj(P +1 ),
opt(Pi ) = opt(Pi ) = + 1 P , pref (S(Pi )) = opt(Pi );
otherwise pref (S(Pi )) + 1.
following theorem extends result merging procedure two preference
levels, particular preference levels smaller equal given threshold .
Theorem 15 Consider STPPU P every preference level, , define STPU obtained
cutting P , applying PC DynamicallyControllable. Assume ,
DC. Consider STPU P :
P = Merge(Merge(. . . Merge(Merge(T min , min +1 ), min +2 ), . . . ), )
min minimum preference constraint P. Assume that, applied, Merge
always returned consistent STPU. Then, viable dynamic strategy S, P
P roj(P ), opt(Pi ) S(Pi ) optimal solution Pi , otherwise pref (S(Pi )) + 1.
Theorem 15 allows us prove main result. Informally, Best-DC applies Merge
lowest preference highest threshold , returned problem becomes inconsistent. projection STPPU optimal solution higher , then, using
Theorem 15, conclude STPPU ODC; otherwise -DC.
Let us start enumerating conditions Best-DC terminates:
654

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Event 1. Best-DC stops STPU obtained level min DC (line 4);
Event 2. Best-DC exits reached preference level STPU (seen
STP) path consistent (line 11);
Event 3. Best-DC stops reached preference level path consistent STPU dynamically controllable (line 13);
Event 4. Best-DC stops procedure Merge found inconsistency (line 16).
following theorem shows execution Best-DC always terminates.
Theorem 16 Given STPPU P, execution algorithm Best-DC P terminates.
Best-DC considers preference level, starting lowest moving time
one level according granularity preference set. stops either inconsistency
found levels, assumed finite, precessed.
ready prove soundness completeness Best-DC. split proof
three theorems, considering different terminating condition. first theorem considers
case underlying STPU obtained P , ignoring preferences, DC.
case output STPPU -DC level thus ODC.
Theorem 17 Given STPPU P input, Best-DC terminates line 4 iff 6 0 P
-DC.
next theorem considers case highest preference level reached success
merging procedure highest optimal preference projection P .
case, problem ODC.
Theorem 18 Given STPPU P input, Best-DC terminates line 11 iff P ODC.
last result considers case least projection optimal preference strictly higher highest reached success merging procedure. case
problem ODC Best-DC found highest level STPPU -DC.
Theorem 19 Given STPPU P input, Best-DC stops lines 13 16 preference level iff P
( 1)-DC ODC.
mentioned Section 2.3, (Morris & Muscettola, 2005), proven checking DC
STPU done O(n5 ), n number variables. revised algorithm processes distance graph STPU, rather constraint graph. maintains additional
information, form additional labeled edges correspond waits. main feature
new algorithm, noted earlier, strongly polynomial algorithm determining
dynamic controllability STPU. important context stress fact
output two algorithms, presented (Morris et al., 2001) (Morris & Muscettola, 2005),
essentially same. fact easy obtain, polynomial time O(n 2 ), constraint graph
waits produced DynamicallyControllable starting distance graph produced
new algorithm, vice versa.

655

fiROSSI , V ENABLE ,& YORKE -S MITH

Theorem 20 complexity determining ODC highest preference level -DC
STPPU n variables, bounded number preference levels ` time O(n 5 `).
complexity result given Theorem 20 unexpectedly good. fact, shows cost
adding considerable expressive power preferences STPUs factor equal
number different preference levels. implies solving optimization problem and,
time, controllability problem, remains P, number different preference levels
bounded.
7.4 Execution Algorithm
execution algorithm propose similar STPUs presented (Morris et al.,
2001), described Section 2 shown Figure 7. course execution algorithm
STPPUs take input STPPU Best-DC successfully applied.
line 2 Figure 7, algorithm performs initial propagation starting point. main
difference STPPU execution algorithm STPU algorithm (Morris et al., 2001)
definition propagation involves preferences.
Definition 26 (soft temporal propagation) Consider STPPU P variable P
value vY D(Y ). propagating assignment = v P , means:
constraints, cXY involving X already assigned value v X D(X):
replace interval cXY interval h[vY vX , vY vX ]i;
cut P preference level minX {fcXY (vY vX )}.2
call ODC-Execute algorithm DC-Execute propagation defined
Definition 26. Assume apply ODC-Execute ODC -DC STPPU P Best-DC
applied. If, given time , preference partial schedule ,
know P ODC -DC , Theorem 14 Theorem 15, execution
algorithm assigning values +1 . Assume contingent event occurs
lowers preference 2. propagated STPPU cut preference
level 2. on, execution algorithm assign values 2 and, Theorem 14
Theorem 15, new waits imposed assignments executables
optimal situation optimal preference 2. situations
assignments guarantee preference least 2.

8. Using Algorithms
Section 4.4 described relations notions controllability. general strategy,
given STPPU, first property consider OSC. holds, solution obtained feasible
optimal possible scenarios. However, OSC strong property holds infrequently.
STPPU OSC, still need control sequence execution begins,
Best-SC find best solution consistent possible future situations.
commonly, dynamic controllability useful. control sequence needs
known execution begins, ODC ideal. Notice that, results Section 4.4,
STPPU may OSC still ODC. If, however, STPPU even ODC,

656

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Best-DC give dynamic solution highest preference. Recall, shown
Section 4.4, given preference level , -SC implies -DC vice versa. Thus,
may given STPPU -SC -DC > . -SC means fixed
way assign values executables optimal situations optimal
preference give preference least cases. hand, -DC
implies solution obtained dynamically, ODC-Execute algorithm, optimal
situations best solution preference yield preference
cases. Thus, > , using dynamic strategy guarantee optimality situations
higher preference others.
last possibility check OWC. least allow executing agent know
advance situation solution. Moreover, situation revealed
execution begins, using solvers STPPs described (Rossi et al., 2002)
allow us find optimal assignment scenario.

9. Related Work
section survey work regard closely related ours. Temporal uncertainty
studied before, defined different ways according different contexts
used.
start considering work proposed Vila Godo (1994). propose Fuzzy Temporal Constraint Networks, STPs interval constraint mapped
possibility distribution. fact, handle temporal uncertainty using possibility theory (Zadeh,
1975), using term uncertainty describe vagueness temporal information available.
aim model statements called less hour ago, uncertainty
lack precise information temporal event. goal thus completely different
ours. fact, scenario agent must execute activities certain times,
activities constrained temporal relations uncertain events. goal find way
execute agents control way consistent whatever nature decides
future.
(Vila & Godo, 1994), instead, assume imprecise temporal information events
happened past. aim check information consistent, is,
contradictions implied study entailed set constraints. order model
imprecise knowledge, possibilities used. Every element interval mapped
value indicates possible event certain is. Thus, another major difference
approach consider preferences, possibilities. hand,
work presented allow express information possible probable value
contingent time-point. one lines research want pursue future.
Moreover, (Vila & Godo, 1994), concerned classical notion consistency
(consistency level) rather controllability.
Another work related way handle uncertainty Badaloni Giacomin (2000).
introduce Flexible Temporal Constraints soft constraints used express preferences
among feasible solutions prioritized constraints used express degree necessity
constraints satisfaction. particular, consider qualitative Allen-style temporal relations
associate relation preference. uncertainty deal time
occurrence event whether constraint belongs constraint problem.

657

fiROSSI , V ENABLE ,& YORKE -S MITH

model, information coming plausibility information coming preferences
mixed distinguishable solver. words, possible say whether
solution bad due poor preference relation due violating constraint
high priority. approach, instead, uncertainty preferences separated. compatibility
uncertain event change preference assignment executable.
robustness temporal uncertainty handled intrinsically different degrees controllability.
(Dubois, HadjAli, & Prade, 2003b) authors consider fuzziness uncertainty temporal reasoning introducing Fuzzy Allen Relations. precisely, present extension
Allen relational calculus, based fuzzy comparators expressing linguistic tolerance. Dubois
et al. (2003b) want handle situations information dates relative positions
intervals complete but, reason, interest describing precise manner. example, one wants speak terms approximate equality, proximity
rather terms precise equality. Secondly, want able deal available information pervaded imprecision, vagueness uncertainty. framework presented
restrict uncertainty event occur within range. hand, put
complete ignorance position, would equivalent, context (Dubois
et al., 2003b), setting 1 possibilities contingent events. Moreover, (Dubois et al.,
2003b) allow preferences address controllability. Instead, consider, similarly
(Vila & Godo, 1994), notions consistency entailment. first notion checked
computing transitive closure fuzzy temporal relations using inference rules appropriately
defined. second notion checked defining several patterns inference.
Another work addresses temporal uncertainty presented (Dubois, Fargier, &
Prade, 1995) (Dubois, Fargier, & Prade, 2003a). work preferences activities
ill-known durations classical job-shop scheduling problem handled using fuzzy
framework. three types constraints: precedence constraints, capacity constraints
due dates, release time constraints. order model unpredictable events use possibility theory. authors mention (Dubois et al., 1995), possibility distributions viewed
modeling uncertainty well preference (see Dubois, Fargier, & Prade, 1993). Everything depends whether variable X possibility distribution defined controllable
not. Thus Dubois et al. (1995) distinguish controllable uncontrollable variables. However allow specify preferences uncontrollable events. preference functions
contingent constraints would interpreted possibility distributions framework.
sense, work complementary theirs. assume constraint possibility distribution
contingent events always equal 1 allow representation information
less possible values; hand, allow specify preferences uncontrollable events. They, contrary, allow put possibility distributions contingent events,
preferences.
Finally, Dubois et al. (1995) show scheduling problem uncertain durations
formally expressed kind constraints problem involving call flexible
durations (i.e. durations fuzzy preferences). However interpretation quite different:
case flexible durations, fuzzy information comes specifications preferences
represents possible values assigned variable representing duration.
case imprecisely known durations, fuzzy information comes uncertainty real
value durations. formal correspondence two constraints close
authors distinguish among describing solving procedure. Further, problem
658

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

solve find starting times activities activities take place within
global feasibility window whatever actual values unpredictable durations be. Clearly
equivalent Optimal Strong Controllability. address problem dynamic
weak controllability preferences.

10. Summary Future Work
defined formalism model problems quantitative temporal constraints
preferences uncertainty, generalized formalism three classical notions
controllability (that is, strong, weak dynamic). focused tractable class
problems, developed algorithms check presence properties.
work advances state art temporal reasoning uncertainty since provides
way handle preferences context, select best solution (rather feasible one)
presence uncontrollable events. Moreover, shows computational properties
controllability checking algorithms change adding preferences. particular, dynamic
controllability still checked polynomial time considered class problems, producing dynamically temporal plans uncertainty optimal respect preferences.
Among future directions want pursue within line research, first deeper
study methods algorithms adding preferences different fuzzy ones. Notice
framework proposed able represent kind preference within
soft constraint framework. However, algorithms apply fuzzy preferences semiconvex functions. particular, would consider impact design complexity
algorithms uncontrollable events underlying preference structures
weighted probabilistic semiring. semirings characterized non-idempotent
multiplicative operators. problem applying constraint propagation (Bistarelli
et al., 1997), path-consistency, constraints. Thus search propagation techniques
adapted environment featuring uncertainty well. noticed
(Peintner & Pollack, 2005) algorithms finding optimal solutions STPs preferences
weighted semiring proposed. Another interesting class preferences utilitarian
ones. context preference represents utility goal maximize sum
utilities. preferences used temporal context without uncertainty example
(Morris, Morris, Khatib, Ramakrishnan, & Bachmann, 2004).
Recently, another approach handling temporal uncertainty introduced (Tsamardinos, 2002; Tsamardinos, Pollack, & Ramakrishnan, 2003a): Probabilistic Simple Temporal Problems (PSTPs); similar ideas presented (Lau, Ou, & Sim, 2005). PSTP framework,
rather bounding occurrence uncontrollable event within interval, STPUs,
probability distribution describing event likely occur defined entire set
reals. STPUs, way problem solved depends assumptions made regarding
knowledge uncontrollable variables. particular define Static Scheduling
Optimization Problem, equivalent finding execution satisfying SC STPUs,
Dynamic Scheduling Optimization Problem, equivalent finding dynamic execution strategy
context STPUs. framework, optimal means highest probability
satisfying constraints. Preferences considered framework. believe
would interesting add preferences approach. first step could consists keeping,
strategy, separately global preference probability success. way

659

fiROSSI , V ENABLE ,& YORKE -S MITH

could use existing frameworks handling two aspects. Then, order strategies
giving priority preferences, thus taking sense risky attitude, or, contrary,
giving priority probabilities, adopting cautious attitude. step direction
recently proposed (Morris, Morris, Khatib, & Yorke-Smith, 2005), where, however, authors,
rather actually extending notions consistency PSTPs handle preferences, consider
inducing preferences probabilities. contrast, approach preliminary advanced (Pini,
Rossi, & Venable, 2005).
focused attention non-disjunctive temporal problems, is,
one interval per constraint. would consider adding uncertainty Disjunctive Temporal Problems (Stergiou & Koubarakis, 2000), consider scenarios
preferences uncertainty. problems polynomial even without preferences uncertainty shown cost adding preferences small (Peintner & Pollack,
2004), hope hold environments uncertainty well. Surprisingly,
uncertainty Disjoint Temporal Problems considered yet, although easy see
allowing multiple intervals constraint form uncontrollability. We, thus, plan
start defining DTPUs (preliminary results Venable Yorke-Smith, 2005) merge
approach existing one DTPPs.
Extending Conditional Temporal Problems, framework proposed (Tsamardinos, Vidal, &
Pollack, 2003b), topic interest us. model Boolean formula attached
temporal variable. formulae represent conditions must satisfied order
execution events enabled. framework uncertainty temporal
variables executed. believe would interesting extend approach order
allow conditional preferences: allowing preference functions constraints different
shapes according truth values formulas, occurrence event
time. would provide additional gain expressiveness, allowing one express dynamic
aspect preferences change time.

Appendix
Theorem 1 STPPU P OSC, ODC; ODC, OWC.
Proof: Let us assume P OSC. viable execution strategy that, P 1 , P2
P roj(P ) every executable time-point x, [S(P 1 )]x = [S(P2 )]x S(P1 ) OptSol(P1 )
S(P2 ) OptSol(P2 ). Thus, particular, [S(P1 )]x = [S(P2 )]x every pair f projections
[S(P1 )]<x = [S(P2 )]<x . allows us conclude P OSC ODC
strategy witness OSC witness ODC.
Let us assume P ODC. Then, particular, viable dynamic strategy
P1 P roj(P ), S(P1 ) optimal solution P1 . clearly means every projection
least optimal solution. Thus P OWC. 2
Theorem 2 given preference level , STPPU P -SC -DC.
Proof: Assume P -SC. viable strategy that: [S(P 1 )]x = [S(P2 )]x ,
P1 , P2 P roj(P ) every executable time-point x, S(P ) optimal solution
projection P , optimal solution P preference > pref (S(P )) 6< ,
otherwise.
660

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Thus, [S(P1 )]x = [S(P2 )]x pairs projections, P 1 P2 [S(P1 )]<x =
[S(P2 )]<x . implies P -DC. 2
Theorem 3 Given STPPU P preference level , P -SC (resp. -DC), -SC
(resp. -DC), < .
Proof: P -SC viable strategy that: [S(P 1 )]x = [S(P2 )]x , P1 , P2
P roj(P ) every executable time-point x, S(P ) optimal solution P
optimal solution P preference > pref (S(P )) 6< , otherwise. But, course,
< set projections optimal solution preference > included
projections optimal solution preference > . Moreover, projections,
Pz , pref (S(Pz )) 6< implies pref (S(Pz )) 6< since > . Similarly -DC.2
Theorem 4 Given STPPU P , let opt = max Sol(P ) pref (T ). Then, P OSC (resp. ODC) iff
opt-SC (resp. opt-DC).
Proof: result comes directly fact P P roj(P ), opt(Pi ) opt,
always least projection, Pj , opt(Pj ) = opt.2
Theorem 5 Given STPPU P finite number preference levels, execution algorithm Best-SC P terminates.
Proof: Consider STPPU P optimal preference value opt = max Sol(P ) pref (T ), is,
highest preference assigned solutions. definition, Qopt+1 consistent.
means algorithm reaches level opt + 1 (that is, next preference level higher opt
granularity preferences) condition line 11 satisfied execution
halt. looking lines 9-20 see either one events cause execution
terminate occurs preference level incremented line 16. Since finite number
preference levels, allows us conclude algorithm terminate finite number
steps. 2
Theorem 6 Consider STPPU P = hNe , Nc , Lr , Lc , SF CSP preference level , consider STPU Q = hNe , Nc , L0r , L0c obtained cutting P , STPU PC(Q )=hNe , Nc ,
L00r , L00c i. Then:
1. situation P , P P roj(PC(Q )) iff optP (P ) ;
2. every control sequence , solution = StronglyControllable(PC(Q ) iff, P
Proj(PC (Q )), T, Sol(P ) pref (T, ) .
Proof: prove item theorem.
1. (): Consider situation P P roj(PC(Q )). Since PC(Q ) path consistent, consistent partial assignment (e.g. defined ) extended complete
consistent assignment, say T, PC(Q ). Moreover, T, Sol(P ), pref (T, ) ,
since preference functions semi-convex every interval PC(Q ) subinterval
corresponding one Q . Thus, opt(P ) P . (): Consider situation
opt(P ) . implies T, Sol(P ) pref (T, ) . Since
661

fiROSSI , V ENABLE ,& YORKE -S MITH

fuzzy semiring, happens iff min cij Lr Lc fij (T, ) cij ) . Thus must
fij (T, cij ) , cij Lr Lc thus (T, ) cij c0ij , c0ij L0r L0c .
implies P P roj(Q ). Moreover, since T, consistent solution P Q ,
P P roj(PC(Q )).
2. construction , Sol(T ) iff, P P roj(PC(Q )), T, Sol(P )
Sol(PC(Q )). Notice fact T, Sol(PC(Q )) implies pref (T, ) . 2
Corollary 1 Consider STPPU P preference level assume , situation P ,
opt(P ) , P corresponding projection. Then, STPU PC(Q ), obtained
cutting P , applying path consistency, SC P -SC.
Proof: item 1 Theorem 6 get P projection P opt(P )
iff P P roj(PC(Q )). Thus, complete assignments controllable contingent
variables P global preference iff PC(Q ) consistent, i.e., iff Q path consistent. Let
us assume PC(Q ) SC. item 2 Theorem 6, fixed assignment
controllable variables solution every projection P roj(PC(Q )) and, every
projection, gives global preference .
means either set projections common solution P every common
solution gives preference strictly lower . Thus, P -SC since requires existence
fixed assignment controllable variables must optimal solution projections
preference (Definition 22, Item 1 2) give preference
projections (Definition 22, Item 3).
Theorem 7 Consider STPPU P , preference levels min , assume
corresponding STPs, min , . . . , obtained cutting P preference levels N
min , . . . , ,


enforcing strong controllability consistent. Then, Sol(P ), P = i=min ,..., ,
iff P P roj(P ): T, Sol(P ), opt(P ) , pref (T, ) = opt(P ), otherwise
pref (T, ) .
Proof: (): Let us first recall given two STPs, P1 P2 , defined set variables,
STP P3 = P1 P2 variables P1 P2 temporal constraint c3ij =
c1ij c2ij , is, intervals P3 intersection corresponding intervals P 1
P2 . Given this, fact set projections P set projections
STPU obtained cutting P min , immediately derive Theorem 6
solution P satisfies condition. (): Let us consider control sequence P
6 Sol(P ). Then, j {min . . . } 6 Sol(T j ). Theorem 6 conclude
P opt(P ) = j T, optimal solution P . 2
Theorem 8 execution algorithm Best-SC STPPU P stops due occurrence
Event 1 (line 4), P -SC 0.
Proof: every preference level min , Q =-Cut(P ), =min -Cut(P )=Qmin . occurrence Event 1 implies Qmin strongly controllable. must
Q , min . thus P -SC min . Theorem 3 allows us conclude
> min . 2

662

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Theorem 9 execution algorithm Best-SC STPPU P stops due occurrence
Event 2 (line 11) preference level ,
1 = opt = maxT Sol(P ) pref (T );
P OSC control sequence solution STP P opt (returned algorithm) iff
optimal scenario P .
Proof: condition line 11 satisfied STPU Q , means schedules
P preference . However, condition satisfied previous preference
level, 1, means schedules preference 1. allows us conclude
1 optimal preference STPPU P seen STPP, is, 1 = opt =
maxT Sol(P ) pref (T ). Since assuming line 11 executed Best-SC level opt + 1,
conditions lines 13 16 must satisfied preference opt. means
level opt STP P opt (line 15) consistent. looking line 15, see STP P opt
satisfies hypothesis Theorem 7 preference min preference opt. allows us
conclude solution P opt optimal scenario P vice versa. Thus, P opt-SC
and, Theorem 4, OSC. 2
Theorem 10 execution algorithm Best-SC STPPU P stops due occurrence
Event 3 (line 13) Event 4 (line 16) preference level P OSC ( 1)SC solution STP P 1 (returned algorithm) that, P P roj(P ):
T, Sol(P ), opt(P ) 1, pref (T, ) = opt(P ), otherwise pref (T, ) 1.
Proof: Event 3 Event 4 occurs condition line 11 must satisfied preference level . means STPU PC(Q ) consistent thus schedules P
preference . Event 3 occurs, condition line 13 must satisfied. STPU obtained
cutting P preference level applying path consistency strongly controllable.
thus conclude, using Corollary 1, P OSC. However since algorithm executed
line 11 preference level , 1 must reached line 18. looking line 15
see STP P 1 satisfies hypothesis Theorem 7 preference min preference level
1. allows us conclude P 1-SC.
instead Event 4 occurs P inconsistent (by Theorem 7) means
common assignment executables optimal scenarios preference <
time preference equal . However since execution reached line
16 preference level , assume successfully completed loop preference
1 conclude P 1-SC.2
Theorem 11 Determining optimal strong controllability highest preference level -SC
STPPU n variables ` preference levels achieved O(n 3 `).
Proof: Notice first complexity procedure -Cut (lines 3 10) intersecting two
STPs (line 15) linear number constraints thus O(n 2 ). Assuming `
different preference levels, conclude complexity Best-SC bounded
applying ` times StronglyControllable, O(n 3 `) (see Section 2).2
Theorem 12 STPPU P OWC iff STPU Q, obtained simply ignoring preference functions constraints WC.
663

fiROSSI , V ENABLE ,& YORKE -S MITH

Proof: P OWC, every situation P exists control sequence
schedule T, consistent optimal projection P . every projection P P
corresponding projection Q, say Q , STP obtained P ignoring
preference functions. easy see Definition 1 Section 2.2 implies assignment
optimal solution P solution Q . STPU Q WC every projection
Q exists control sequence schedule , solution Q . Definition 1 Section 2.2 conclude corresponding STPP P least solution thus
must least optimal solution, solution solution higher
preference. 2
Theorem 13 Given STPPU P , consider preference level STPU Q , obtained
cutting P , consistent. STPU PC(Q ) DC P ODC -DC,
.
Proof: Assume preference level PC(Q ) DC. means
viable execution strategy : P roj(PC(Q )) Sol(PC(Q )) P1 , P2
P roj(Q ) executable x, [S(P1 )]<x = [S(P2 )]<x [S(P1 )]x = [S(P2 )]x .
Let us recall that, due semi-convexity preference functions, cutting STPPU
given preference level return smaller intervals constraints. Thus, every
projection P roj(Q ) (which STP) corresponds projection P roj(P )
STPP obtained STP restoring preference functions P.
Let us assume, contrary, P ODC and, thus, exists viable strategy
0
: P roj(P ) Sol(P ) P1 , P2 P roj(P ), [S 0 (P1 )]<x = [S 0 (P2 )]<x
[S 0 (P1 )]x = [S 0 (P2 )]x , pref (S 0 (Pi )) = opt(Pi ), = 1, 2. Consider, restriction
0 projections P roj(PC(Q )). Since pref (S 0 (P ) = opt(P ) every P , must
P P roj((PC(Q )), 0 (P ) Sol((PC(Q )). Thus restriction 0 satisfies
requirements strategy definition DC. contradiction fact
PC(Q ) DC. Thus P cannot ODC.
Theorem 6, P P roj(P ), P P roj(PC(Q )) iff opt(P ) . allows us
conclude P -DC. Finally, Theorem 3 allows conclude P -DC, .
2
Lemma 1 (useful proof Theorem 14) Consider STPU Q DynamicallyCo
ntrollable reported success Q. Consider constraint AB, B executables
execution always precedes B, defined interval [p, q] wait max 10 . Then,
exists viable dynamic strategy Q P roj(Q), [S(Qi )]B [S(Qi )]A tmax .
Proof: dynamic strategy produced algorithm DC-Execute shown Figure 7, Section 2. fact, line 5 stated executable B executed soon as, current
time, three following conditions satisfied: (1) B live, i.e. current time must lie lower upper bounds, (2) B enabled, i.e. variables must precede B
executed, (3) waits B satisfied. Let us denote current time ,
assume B live enabled . Thus, ([S(Q )]A ) [p, q]. third requirement satisfied
one two following scenarios: either last contingent time-point B
wait occurred thus B executed immediately, waits contingent
10. Notice tmax longest wait B must satisfy imposed contingent time-point C constraint AB.

664

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

time-points, among B wait, yet occurred expired .
cases must tmax + [S(Qi )A ]. Thus, ([S(Qi )]B = ) [S(Qi )]A tmax . 2
Theorem 14 Consider STPPU P STPUs, +1 , obtained cutting P respectively
level + 1 applying PC, without finding inconsistencies, DynamicallyControllable
success. Consider STPU P +1 = Merge(T , +1 ).
Then, Merge(T , +1 ) fail
P +1 dynamically controllable
viable dynamic strategy every projection P P roj(P +1 ),
opt(Pi ) = opt(Pi ) = + 1 P , pref (S(Pi )) = opt(Pi );
otherwise pref (S(Pi )) + 1.
Proof: following constructive proof which, assuming Merge failed, strategy
S, satisfying requirements theorem, defined.
First notice P roj(P +1 ) = P roj(T ). fact, line 2 Merge, P +1 initialized

. Merge changes requirement intervals leaving contingent intervals unaltered.
Furthermore, P roj(T +1 ) P roj(T ). seen using first claim Theorem 6
Section 5.
Let 0 00 viable dynamic execution strategies obtained running DC-Execute respectively +1 . Now, since P roj(T +1 ) P roj(T ), projections
mapped two, possibly different, schedules: one 0 one 00 . every projection
Pi P roj(P +1 ) every executable B, notice 00 [Pi ]<B exists equal
0 [Pi ]<B . thus define history B (which recall set durations contingent events finished prior B) new strategy S[Pi ]<B = 0 [Pi ]<B every
projection Pi P roj(P +1 ) . Notice 00 [Pi ]<B defined history B Pi contains
duration mapped preference exactly equal thus P cannot projection
+1 .
consider define depending case AB constraint
+1 .
Constraint AB Follow Unordered Follow +1 . cases, Merge
change interval AB, leaving .
Let us first analyze scenario AB Follow case STPUs.
case, execution B always follow contingent time point C
problems. Thus, every projection P P roj(P +1 ), S[P ]<B = . Since
problems dynamically controllable [p , q ] 6= [p+1 , q +1 ] 6= . Furthermore,
since path consistency enforced problems, constraints minimal
form (see Section 2), is, every value AB [p , q ] (resp. [p+1 , q +1 ])
situation (resp. +1 ) T, Sol(P ) AB = AB . Finally, since
P roj(T +1 ) P roj(T ), must [p+1 , q +1 ] [p , q ].
Next consider scenario AB Unordered case +1 . Let us start
proving that, case, must [p +1 , q +1 ] [p , ]. First, show
665

fiROSSI , V ENABLE ,& YORKE -S MITH

p+1 p . definition, p+1 situation P P roj(T +1 )
schedule T, Sol(P ) AB = p+1 . Since P roj(T +1 )
P roj(T ), p+1 [p , q ]. Next let us prove must > q +1 . Notice
wait induces partition situations two sets: that, every
contingent point C, AC < , contingent point C 0 , AC 0 .
first case, contingent events occurred expiration wait
B executed tA + (where tA execution time A). second
case safe execute B tA + . Given P roj(T +1 ) P roj(T ), B
constrained follow execution every contingent time-point +1 , must
projections +1 belong first set partition thus q+1 < .
cases is, hence, sufficient define new strategy follows: projections,
Pi , Pj P roj(P +1 ) [S(Pi )]<B = [S(Pj )]<B [S(Pi )]B = [S(Pj )]B =
[S 00 (Pi )]B [S 00 (Pi )]B exists, otherwise [S(Pi )]B = [S(Pj )]B = [S 0 (Pi )]B . assignment
guarantees identify projections constraints mapped preferences +1 [S 00 (Pi )]B
exists thus Pi P roj(T +1 ), otherwise projections P roj(T )
P roj(T +1 ).
Constraint AB Precede case +1 . B must precede contingent timepoint C. means assignment B corresponding value [p , q ] (resp.
[p+1 , q +1 ]) extended complete solution projection P roj(T ) (resp.
P roj(T +1 )). Interval [p0 , q 0 ] is, fact, obtained Merge, intersecting two intervals.
Since assuming Merge failed, intersection cannot empty (line 6
Figure 14). can, thus, example, define follows: pair projections
Pi , Pj P roj(P +1 ) [S(Pi )]<B = [S(Pj )]<B [S(Pi )]B (= [S(Pj )]B ) = p0 .
Constraint AB Unordered Unordered Precede +1 . First let us recall
result applying Merge interval [p 0 , q 0 ], p0 = p , q 0 = min(q , q +1 )
wait t0 = max(t , t+1 ). Since, hypothesis, Merge failed, must 0 q 0
(line 9, Figure 14.
Notice that, due semi-convexity preference functions, p p+1 . fact, B
executed tA + p (where tA time executed)
contingent time-points B wait occurred. Let us indicate x mlb

+1 ),
(resp. x+1
mlb ) maximum lower bound AC constraint (resp.

+1
B wait C. must p xmlb (resp. p+1 xmlb ). However due
semi-convexity preference functions x mlb x+1
mlb .
case define strategy follows. pair projections Pi , Pj
P roj(P +1 ), [S(Pi )]<B =[S(Pj )]<B [S(Pi )]B = [S(Pj )]B = max([S 00 (Pi )]B ,
[S 0 (Pi )]B ) whenever [S 00 (Pi )]B defined. Otherwise [S(Pi )]B =[S(Pj )]B = [S 0 (Pi )]B .
Lemma 1 max([S 00 (Pi )]B , [S 0 (Pi )]B ) t0 , hence [S(Pi )]B = ([S(Pj )]B )
[p0 , q 0 ].
Let us consider preferences induced constraints assignment. First
let us consider case max([S 00 (Pi )]B , [S 0 (Pi )]B ) = [S 00 (Pi )]B . Since 00
dynamic strategy +1 assignment identify projections preference + 1.
instead max([S 00 (Pi )]B , [S 0 (Pi )]B ) = [S 0 (Pi )]B , must [S 0 (Pi )]B > [S 00 (Pi )]B .
666

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

However know, Lemma 1 [S 00 (Pi )]B t+1 t0 [S 0 (Pi )]B t0 .
implies [S 0 (Pi )]B [p+1 , t0 ] thus assignment preference +
1. Finally, [S 00 (Pi )]B defined, noted above, Pi 6 P roj(T +1 ) thus
opt(Pi ) = (since Theorem 6 Section 5 P P roj(T ) opt(Pi )
). Thus, [S(Pi )]B =[S(Pj )]B = [S 0 (Pi )]B , which, assignment , identifies
preferences = opt(Pi ).
shown that, Merge fail, dynamic strategy (with
required additional properties) certifies P+1 dynamically controllable.
Assume, instead, Merge fails constraint. two cases
happen. first one AB Precede case +1 [p , q ] [p+1 , q +1 ]
= . proven (Morris et al., 2001), projection AB viable dynamic strategy
[p , q ] projection AB viable dynamic strategy +1 [p+1 , q +1 ].
dynamic viable strategies give optimal solutions projections optimal preference
equal . dynamic viable strategies +1 give optimal solutions projections
optimal preference equal + 1. Since projections +1 subset ,
[p , q ] [p+1 , q +1 ] = strategy either optimal projection
+1 vice-versa.
second case occurs Merge fails constraint AB either Unordered
case +1 Unordered case precede case +1 .
cases failure due fact [t , q ] [t+1 , q +1 ] = . must either q +1 <
q < t+1 . upper bound interval AB q +1 must least
contingent time-point C executing B q +1 either inconsistent
assignment C gives preference lower + 1. side, wait
constraint AB must least contingent time-point C 0 executing B
either inconsistent optimal future occurrences C.
way define viable dynamic strategy simultaneously optimal projections optimal
value equal optimal value + 1. 2
Lemma 2 (Useful proof Theorem 15) Consider strategies 0 , 00 defined
Theorem 14.
1. projection P +1 , Pi , pref (S(Pi )) pref (S 0 (Pi )) every projection, Pz ,
+1 , pref (S(Pz )) + 1;
2. constraint AB, [S(Pi )]B t0 .
Proof:
1. Obvious, since cases either [S(P )]B = [S 0 (Pi )]B [S(Pi )]B = [S 00 (Pi ) ]B
pref (S 00 (Pi )) pref (S 0 (Pi )) since every executable B [S 00 (Pi )]B +1 . Moreover,
every projection Pz +1 , every executable B, [S(Pz )]B = [S 00 (Pz )]B .
2. Derives directly fact either [S(P )]B = [S 0 (Pi )]B [S(Pi )]B = [S 00 (Pi )]B
Lemma 1 2.

667

fiROSSI , V ENABLE ,& YORKE -S MITH

Theorem 15 Consider STPPU P every preference level, , define STPU obtained
cutting P , applying PC DynamicallyControllable. Assume ,
DC. Consider STPU P :
P = Merge(Merge(. . . Merge(Merge(T min , min +1 ), min +2 ), . . . ), )
min minimum preference constraint P. Assume that, applied, Merge
always returned consistent STPU. Then, viable dynamic strategy S, P
P roj(P ), opt(Pi ) S(Pi ) optimal solution Pi , otherwise pref (S(Pi )) + 1.
Proof: prove theorem induction. First, notice that, construction P roj (T min ) =
P roj(P ). allows us conclude P roj(P ) = P roj(P ), since, every time Merge
applied, new STPU contingent constraints STPU given first argument.
Now, since min dynamically controllable viable dynamic strategies, say min
min (Pi ) optimal opt(Pi ) = min and, otherwise, pref (S(Pi )) min .
Consider P min +1 =Merge (T min ,T min +1 ). Theorem 14, know
strategy, min +1 , min +1 (Pi ) optimal solution Pi opt(Pi ) min + 1
pref (S(PI )) min + 1 otherwise.
Let us assume STPU P min +k , defined hypothesis, satisfies thesis
P min +k+1 , defined hypothesis, min + k + 1 , not. Notice
implies strategy, min +k , min +k (Pi ) optimal solution Pi
opt(Pi ) min + k pref (S(Pi )) min + k projections. Since min +
k + 1 , then, hypothesis min +k+1 DC. Moreover, construction,
P min +k+1 =Merge (P min +k ,T min +k+1 ), since Merge doesnt fail. Thus, using Theorem 14
using strategy min +k P min +k construction Theorem 14, Lemma 2,
obtain dynamic strategy, min +k+1 , every projection Pi , pref (S min +k+1 (Pi ))
pref (S min +k (Pi )) min +k+1 (Pj ) optimal solution projections P j
opt(Pj ) = min + k + 1 pref (S(Pj )) min + k + 1 projections.
allows us conclude min +k+1 (Ph ) optimal solution projections P h
opt(Ph ) min + k + 1. contradiction assumption P min +k+1 doesnt satisfy
thesis theorem. 2
Theorem 16 Given STPPU P, execution algorithm Best-DC P terminates.
Proof: assume preference set discretized finite number different
preferences. Best-DC starts lowest preference cuts level P. If, given level,
STPU obtained consistent dynamically controllable merging procedure fails,
Best-DC stops level. Assume, instead, that, moves preference ordering,
none events occur. However certain point cutting level higher
maximum preference function (or outside preference set) case
cutting problem give inconsistent STP.2
Theorem 17 Given STPPU P input, Best-DC terminates line 4 iff 6 0 P
-DC.
Proof: . Assume Best-DC terminates line 4. Then, STPU obtained cutting P
minimum preference, min , constraint DC. However cutting minimum
668

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

preference constraint preference level 0 gives STPU. Theorem 13
conclude P -DC 0 and, thus, ODC.
. Assume P -DC preferences 0. cutting P minimum preference
min cannot give dynamically controllable problem, otherwise, P would min -DC. Hence,
Best-DC exit line 4. 2
Theorem 18 Given STPPU P input, Best-DC terminates line 11 iff P ODC.
Proof: . Assume Best-DC terminates line 11 considering preference level . Then,
STPU Q obtained cutting STPPU P level path consistent. immediately conclude projection P P roj(Pi ) opt(Pi ) .
Since Best-DC terminate before, must assume preference 1,
tests (path consistency, dynamic controllability, Merge) successful.
consider STPU P 1 obtained end iteration corresponding preference
level 1. easy see P 1 satisfies hypothesis Theorem 15. allows us
conclude viable dynamic strategy every projection P ,
opt(Pi ) 1, S(Pi ) optimal solution Pi . However since know projections
P opt(Pi ) < , allows us conclude P ODC.
. P ODC viable strategy every pair projections, P , Pj
P roj(P ), executable B, [S(P )]<B = [S(Pj )]<B [S(Pi )]B = [S(Pj )]B
S(Pi ) optimal solution Pi S(Pj ) optimal solution Pj .
Theorem 17 know Best-DC cannot stop line 4.
Let us consider line 13 show Best-DC sets -DC true line P
cannot ODC. fact condition setting -DC true line 13 STPU obtained
cutting P preference level path consistent dynamically controllable. means
projections, e.g. Pj , P opt(Pj ) = . However, dynamic strategy
set projections. Thus, P cannot ODC.
Let us consider line 16, show that, P ODC Best-DC cannot set -DC true.
Best-DC sets -DC true Merge failed. Using Theorem 14, conclude
dynamic viable strategy every projection P , P , (remember P roj(P 1 ) =
P roj(P )) S(Pi ) optimal solution opt(Pi ) . However, know projections
P optimal preference equal (since assuming Best-DC stopping line 16
11). Thus, P cannot ODC.2
Theorem 19 Given STPPU P input, Best-DC stops lines 13 16 preference level iff P
( 1)-DC ODC.
Proof: . Assume Best-DC sets -DC true line 13, considering preference level
. Thus, STPU obtained cutting P level path consistent DC. However since
must first preference level happens, otherwise Best-DC would stopped
sooner, conclude iteration preference level 1 successful. Considering
P 1 using Theorem 15 conclude viable dynamic strategy that,
every projection P , Pi , opt(Pi ) 1 S(Pi ) optimal solution Pi
pref (S(Pi )) 1 otherwise. definition 1-dynamic controllability.
Best-DC terminates line 16, Theorem 15 Theorem 14 conclude that,
viable dynamic strategy every projection P , P , opt(Pi ) 1
669

fiROSSI , V ENABLE ,& YORKE -S MITH

S(Pi ) optimal solution Pi pref (S(Pi )) 1 otherwise, strategy
guaranteeing optimality projections optimal preference . Again, P 1-DC.
. P -DC, 0 Theorem 17, Best-DC stop line 4. P
-DC, ODC, 0 Theorem 18, Best-DC stop line 11.
Theorem 16, Best-DC always terminates, must stop line 13 16.2
Theorem 20 complexity determining ODC highest preference level -DC
STPPU n variables, bounded number preference levels l O(n 5 `).
Proof: Consider pseudocode algorithm Best-DC Figure 13.
complexity min -Cut(P ) line 3 O(n2 ), since every constraint must considered,
O(n2 ) constraints, constraint time finding interval
elements mapped preference min constant. complexity checking STPU obtained DC O(n5 ). Thus, lines 3 4, always performed, overall complexity
O(n5 ). Lines 7 8, clearly, take constant time.
Let us consider fixed preference level compute cost complete iteration .
(line 10) complexity -Cut(P ) O(n 2 );
(line 11) complexity applying PC testing path consistency O(n 3 ) (see Section 2.1,
(Dechter et al., 1991));
(line 13) complexity testing DC using DynamicallyControllable O(n 5 ), (see Section 2 Morris Muscettola, 2005);
(line 15) constant time;
(line 16-18) complexity Merge O(n 2 ), since O(n2 ) constraints must
considered constraint merging two intervals constant cost;
(line 19) constant time.
conclude complexity complete iteration given preference level O(n 5 ).
worst case, cycle performed ` times. can, thus, conclude total
complexity Best-DC O(n5 `) since complexity operations performed lines 24-27
constant. 2

References
Badaloni, S., & Giacomin, M. (2000). Flexible temporal constraints. 8th Conference Information Processing Management Uncertainty knowledge-Based System (IPMU 2000),
pp. 12621269.
Bistarelli, S., Montanari, U., & Rossi, F. (1997). Semiring-based constraint solving optimization. Journal ACM, 44(2), 201236.
Bresina, J., Jonsson, A., Morris, P., & Rajan, K. (2005). Activity planning mars exploration
rovers. 15th International Conference Automated Planning Scheduling (ICAPS
2005), pp. 4049.
670

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Coggiola, M., Shi, Z., & Young, S. (2000). Airborne deployment instrument real-time
analysis single aerosol particles. Aerosol Science Technology, 33, 2029.
Dearden, R., Meuleau, N., Ramakrishnan, S., Smith, D., & Washington, R. (2002). Contingency
planning planetary rovers. 3rd Intl. Workshop Planning Scheduling Space.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence,
49(1-3), 6195.
Dubois, D., Fargier, H., & Prade, H. (1993). Flexible constraint satisfaction problems application scheduling problems. Tech. rep. Report IRIT/93-30-R, I.R.I.T., Universite P.
Sabatier.
Dubois, D., Fargier, H., & Prade, H. (1995). Fuzzy constraints job shop-scheduling. Journal
Intelligent Manufacturing, 6, 215234.
Dubois, D., Fargier, H., & Prade, H. (2003a). Fuzzy scheduling: Modelling flexible constraints
vs. coping incomplete knowledge. European Journal Operational Research, 147,
231252.
Dubois, D., HadjAli, A., & Prade, H. (2003b). Fuzziness uncertainty temporal reasoning.
Journal Universal Computer Science, 9(9), 1168.
Dubois, D., & Prade, H. (1985). review fuzzy set aggregation connectives. Journal Information Science, 36(1-2), 85121.
Field, P., Hogan, R., Brown, P., Illingworth, A., Choularton, T., Kaye, P., Hirst, E., & Greenaway,
R. (2004). Simultaneous radar aircraft observations mixed-phase cloud 100m
scale. Quarterly Journal Royal Meteorological Society, 130, 18771904.
Floyd, R. W. (1962). Algorithm 97: Shortest path. Communication ACM, 36(6), 345.
Frank, J., Jonsson, A., Morris, R., & Smith, D. (2001). Planning scheduling fleets earth
observing satellites. 6th Intl. Symposium AI, Robotics, Automation Space (iSAIRAS01).
Khatib, L., Morris, P., Morris, R. A., & Rossi, F. (2001). Temporal constraint reasoning
preferences. Nebel, B. (Ed.), 17th International Joint Conference Artificial Intelligence,
(IJCAI 2001), pp. 322327. Morgan Kaufmann.
Lau, H. C., Ou, T., & Sim, M. (2005). Robust temporal constraint networks. Proc. 17th IEEE
Conf. Tools Artificial Intelligence (ICTAI05), pp. 8288 Hong Kong.
Leiserson, C. E., & Saxe, J. B. (1988). mixed-integer linear programming problem
efficiently solvable. Journal Algorithms, 9(1), 114128.
Morris, P., Morris, R., Khatib, L., Ramakrishnan, S., & Bachmann, A. (2004). Strategies global
optimization temporal preferences. Wallace, M. (Ed.), Proceeding 10th International Conference Principles Practice Constraint Programming (CP-04), Vol. 3258
Lecture Notes Computer Science, pp. 588603. Springer.
671

fiROSSI , V ENABLE ,& YORKE -S MITH

Morris, P. H., Muscettola, N., & Vidal, T. (2001). Dynamic control plans temporal uncertainty. Nebel, B. (Ed.), 17th International Joint Conference Artificial Intelligence
(IJCAI 2001), pp. 494502. Morgan Kaufmann.
Morris, P. H., & Muscettola, N. (1999). Managing temporal uncertainty waypoint controllability. Dean, T. (Ed.), 16th International Joint Conference Artificial Intelligence
(IJCAI99), pp. 12531258. Morgan Kaufmann.
Morris, P. H., & Muscettola, N. (2005). Temporal dynamic controllability revisited. 20th National
Conference Artificial Intelligence (AAAI 2005), pp. 11931198. AAAI Press / MIT
Press.
Morris, R. A., Morris, P. H., Khatib, L., & Yorke-Smith, N. (2005). Temporal planning preferences probabilities. ICAPS05 Workshop Constraint Programming Planning
Scheduling.
Muscettola, N., Morris, P. H., Pell, B., & Smith, B. D. (1998). Issues temporal reasoning
autonomous control systems. Agents, pp. 362368.
Peintner, B., & Pollack, M. E. (2004). Low-cost addition preferences DTPs TCSPs.
McGuinness, D. L., & Ferguson, G. (Eds.), 19th National Conference Artificial Intelligence, pp. 723728. AAAI Press / MIT Press.
Peintner, B., & Pollack, M. E. (2005). Anytime, complete algorithm finding utilitarian optimal
solutions STPPs. 20th National Conference Artificial Intelligence (AAAI 2005), pp.
443448. AAAI Press / MIT Press.
Pini, M. S., Rossi, F., & Venable, K. B. (2005). Possibility theory reasoning uncertain
soft constraints. Godo, L. (Ed.), 8th European Conference Symbolic Quantitative
Approaches Reasoning Uncertainty (ECSQARU 2005), Vol. 3571 LNCS, pp. 800
811. Springer.
Rajan, K., Bernard, D. E., Dorais, G., Gamble, E. B., Kanefsky, B., Kurien, J., Millar, W., Muscettola, N., Nayak, P. P., Rouquette, N. F., Smith, B. D., Taylor, W., & Tung, Y. W. (2000).
Remote Agent: autonomous control system new millennium. Horn, W. (Ed.),
14th European Conference Artificial Intelligence, ECAI 2000, pp. 726730. IOS Press.
Rossi, F., Sperduti, A., Venable, K., Khatib, L., Morris, P., & Morris, R. (2002). Learning solving soft temporal constraints: experimental study. Van Hentenryck, P. (Ed.), Principles
Practice Constraint Programming, 8th International Conference (CP 2002), Vol. 2470
LNCS, pp. 249263. Springer.
Rossi, F., Venable, K. B., & Yorke-Smith, N. (2004). Controllability soft temporal constraint
problems. 10th International Conference Principles Practice Constraint Programming (CP-04), Vol. 3258 LNCS, pp. 588603.
Rossi, F., Venable, K., & Yorke-Smith, N. (2003). Preferences uncertainty simple temporal problems. Proc. CP03 Workshop: Online-2003 (International Workshop Online
Constraints Solving - Handling Change Uncertainty).
672

fiU NCERTAINTY

SOFT TEMPORAL CONSTRAINT PROBLEMS

Ruttkay, Z. (1994). Fuzzy constraint satisfaction. Proceedings 1st IEEE Conference Evolutionary Computing, pp. 542547 Orlando.
Schiex, T. (1992). Possibilistic Constraint Satisfaction problems handle soft constraints?. Dubois, D., & Wellman, M. P. (Eds.), 8th Annual Conference Uncertainty
Artificial Intelligence (UAI92), pp. 268275. Morgan Kaufmann.
Shostak, R. E. (1981). Deciding linear inequalities computing loop residues. Journal
ACM, 28(4), 769779.
Stergiou, K., & Koubarakis, M. (2000). Backtracking algorithms disjunctions temporal constraints. Artificial Intelligence, 120(1), 81117.
Tsamardinos, I. (2002). probabilistic approach robust execution temporal plans uncertainty. Vlahavas, I. P., & Spyropoulos, C. D. (Eds.), Methods Applications Artificial
Intelligence, Second Hellenic Conference AI (SETN 2002), Vol. 2308 LNCS, pp. 97
108. Springer.
Tsamardinos, I., Pollack, M. E., & Ramakrishnan, S. (2003a). Assessing probability legal execution plans temporal uncertainty. Workshop Planning Uncertainty
Incomplete Information Thirteenth International Conference Automated Planning
Scheduling (ICAPS 2003).
Tsamardinos, I., Vidal, T., & Pollack, M. E. (2003b). CTP: new constraint-based formalism
conditional, temporal planning. Constraints, 8(4), 365388.
Venable, K., & Yorke-Smith, N. (2003). Simple Temporal Problems Preferences Uncertainty. Doctoral Consortium 13th International Conference Automated Planning
Scheduling (ICAPS 2003). AAAI Press.
Venable, K., & Yorke-Smith, N. (2005). Disjunctive temporal planning uncertainty. 19th
International Joint Conference Artificial Intelligence (IJCAI 2005), pp. 172122. Morgan
Kaufmann.
Vidal, T., & Fargier, H. (1999). Handling contingency temporal constraint networks: consistency controllabilities. Journal Experimental Theoretical Artificial Intelligence,
11(1), 2345.
Vidal, T., & Ghallab, M. (1996). Dealing uncertain durations temporal constraint networks
dedicated planning. Wahlster, W. (Ed.), 12th European Conference Artificial Intelligence (ECAI96), pp. 4854. John Wiley Sons.
Vila, L., & Godo, L. (1994). fuzzy temporal constraint networks. Mathware Soft Computing,
3, 315334.
Xu, L., & Choueiry, B. Y. (2003). new efficient algorithm solving simple temporal problem. 10th Intl. Symposium Temporal Representation Reasoning Fourth Intl.
Conf. Temporal Logic (TIME-ICTP03), pp. 212222.

673

fiROSSI , V ENABLE ,& YORKE -S MITH

Yorke-Smith, N., Venable, K. B., & Rossi, F. (2003). Temporal reasoning preferences uncertainty. Gottlob, G., & Walsh, T. (Eds.), 18th International Joint Conference Artificial
Intelligence (IJCAI03), pp. 13851386. Morgan Kaufmann.
Zadeh, L. A. (1975). Calculus fuzzy restrictions. Fuzzy Sets Applications Cognitive
Decision Processes, 140.

674


