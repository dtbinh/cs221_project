journal artificial intelligence

submitted published

cognitive principles robust multimodal interpretation
joyce chai
zahar prasov
shaolin qu

jchai cse msu edu
prasovza cse msu edu
qushaoli cse msu edu

department computer science engineering
michigan state university
east lansing mi usa

abstract
multimodal conversational interfaces provide natural means users communicate computer systems multiple modalities speech gesture
build eective multimodal interfaces automated interpretation user multimodal inputs
important inspired previous investigation cognitive status multimodal
human machine interaction developed greedy interpreting user
referring expressions e multimodal reference resolution incorporates
cognitive principles conversational implicature givenness hierarchy applies constraints sources e g temporal semantic contextual resolve
references empirical shown advantage eciently
resolving variety user references simplicity generality
potential improve robustness multimodal input interpretation

introduction
multimodal systems provide natural eective way users interact computers
multiple modalities speech gesture gaze since rst appearance
put system bolt number multimodal systems
built among systems combine speech pointing neal shapiro
stock gaze koons sparrell thorisson systems integrate speech
pen inputs e g drawn graphics cohen johnston mcgee oviatt pittman smith
chen clow wahlster systems combine multimodal inputs outputs
cassell bickmore billinghurst campbell chang vilhjalmsson yan systems
mobile environments oviatt systems engage users intelligent
conversation gustafson bell beskow boye carlson edlund granstrom house wiren
stent dowding gawron bratt moore earlier studies shown
multimodal interfaces enable users interact computers naturally eectively
oviatt b
one important aspect building multimodal systems multimodal interpretation
process identies meanings user inputs particular key element
multimodal interpretation known reference resolution process nds
proper referents referring expressions referring expression phrase
given user inputs likely speech inputs refer specic
entity entities referent entity e g specic object user refers
suppose user points house screen says much one
c

ai access foundation rights reserved

fichai prasov qu

case reference resolution must infer referent house assigned
referring expression one particularly addresses reference
resolution multimodal interpretation
multimodal conversation way users communicate system depends
available interaction channels situated context e g conversation focus visual
feedback dependencies form rich set constraints aspects e g
semantic temporal contextual correct interpretation attained
simultaneously considering constraints
previous studies shown user referring behavior multimodal conversation
occur randomly rather follows certain linguistic cognitive principles
human machine interaction earlier work shown strong correlations
cognitive status givenness hierarchy form referring expressions kehler
inspired early work developed greedy multimodal reference
resolution incorporates principles conversational implicature
givenness hierarchy applies constraints sources e g gesture conversation
context visual display empirical shown promise
eciently resolving variety user references one major advantage greedy
prior linguistic cognitive knowledge used guide
search prune search space constraint satisfaction simplicity
generality potential improve robustness interpretation
provide practical solution multimodal reference resolution chai prasov blaim
jin
following sections rst demonstrate dierent types referring behavior
observed studies briey introduce underlying cognitive principles
human human communication describe principles used computational model eciently resolve multimodal references finally present
experimental

multimodal reference resolution
previous work chai hong zhou b chai hong zhou prasov
multimodal conversational system developed users acquire real estate information
figure snapshot graphical user interface users interact interface
speech gesture table shows fragment conversation
fragment user exhibits dierent types referring behavior example
input u considered simple input type simple input one
referring expression spoken utterance one accompanying gesture multimodal
fusion combines information speech gesture likely resolve
refers second user input u accompanying gesture referring
expression explicitly used speech utterance time system needs
use conversation context infer object interest house mentioned
previous turn conversation third user input multiple referring
expressions multiple gestures types inputs considered complex inputs
first prototype system developed ibm j watson center p hong
zhou colleagues intelligent multimedia interaction group



fiminimizing conflicts heuristic repair method

figure snapshot multimodal conversational system

u

u

u


speech much cost
gesture point position screen
speech price k
graphics highlight house discussion
speech large
speech square feet
speech compare house one
gesture circle cirle put two consecutive circles screen
speech comparison
graphics table comparison

table fragment demonstrating interaction dierent types referring behavior
complex inputs dicult resolve need consider temporal relations
referring expressions gestures semantic constraints specied
referring expressions contextual constraints prior conversation
example case u system needs understand refers house
focus previous turn house one aligned
two consecutive gestures subtle variations constraints including
temporal ordering semantic compatibility gesture recognition lead
dierent interpretations
example see multimodal conversation way user interacts system dependent available input channels e g speech
gesture upon conversation goals state conversation
multimedia feedback system words rich context involves


fichai prasov qu

dependencies many dierent aspects established interaction interpreting
user inputs situated rich context example temporal relations
speech gesture important criteria determine information
two modalities combined focus attention prior conversation
shapes users refer objects thus inuences interpretation referring
expressions therefore need simultaneously consider temporal relations
referring expressions gestures semantic constraints specied referring expressions contextual constraints prior conversation
present ecient driven cognitive principles combine temporal
semantic contextual constraints multimodal reference resolution

related work
considerable eort devoted studying user multimodal behavior cohen
oviatt mechanisms interpret user multimodal inputs chai et al b
gustafson et al huls bos classen johnston cohen mcgee oviatt
pittman smith johnston johnston bangalore kehler koons
et al neal shapiro oviatt deangeli kuhn stent et al stock
wahlster wu oviatt zancanaro stock strapparava
multimodal reference resolution early work keeps track focus space
dialog grosz sidner display model capture objects visible
graphical display neal thielman dobes shapiro checks semantic
constraints type candidate objects referenced properties
reference resolution modied centering model multimodal reference resolution
introduced previous work zancanaro et al idea
centering movement turns segments discourse constructed
discourse entities appearing segment accessible current turn
used constrain referents referring expressions another introduced
use contextual factors multimodal reference resolution huls et al
salience value assigned instance contextual factors
determine referents multimodal referring expressions retrieves
salient referent satises semantic restrictions referring expressions
earlier approaches greedy nature largely dependent semantic
constraints constraints conversation context
resolve multimodal references two important issues first mechanism combine information sources modalities second capability obtain best interpretation among possible alternatives given set
temporal semantic contextual constraints section give brief introduction
three recent approaches address issues
multimodal fusion
approaches multimodal fusion johnston johnston bangalore although
focus dierent overall input interpretation provide eective solutions
reference resolution two major approaches multimodal fusion unication

fiminimizing conflicts heuristic repair method

approaches johnston nite state approaches johnston bangalore

unication identies referents referring expressions unifying
feature structures generated speech utterances gestures multimodal grammar johnston et al johnston multimodal grammar combines
temporal spatial constraints temporal constraints encode absolute temporal relations speech gesture johnston grammar rules predened
empirical studies multimodal interaction oviatt et al example one
rule indicates speech gesture combined speech overlaps
gesture follows gesture within certain time frame unication
process certain complex cases long satisfy predened multimodal
grammar speech utterance accompanied one gesture dierent
types johnston accommodate situations
described figure require adding dierent rules cope situation
specic user referring behavior exactly match existing integration rules
e g temporal relations unication would fail therefore references would
resolved
nite state applies nite state transducers multimodal parsing
understanding johnston bangalore unlike unication
chart parsing subject signicant computational complexity concerns johnston
bangalore nite state provides ecient tight coupling
multimodal understanding speech recognition multimodal contextfree grammar dened transform syntax multimodal inputs semantic
meanings domain specic semantics directly encoded grammar
grammars multi tape nite state automata constructed automata
used identifying semantics combined inputs rather absolute temporal
constraints unication relies temporal order
dierent modalities parsing stage gesture input gesture
tape e g pointing particular person combined speech expression
speech tape e g person considered referent expression
multi tape structure takes input speech
gesture incorporate conversation history consideration
decision list
identify potential referents previous work investigated givenness hierarchy
introduced later multimodal interaction kehler data collected
wizard oz experiments investigation suggests users tend tailor
expressions perceive systems beliefs concerning cognitive status
referents prominence e g highlight display tailored referring
expressions resolved high accuracy following decision list
object gestured choose object
otherwise currently selected object meets semantic type constraints imposed
referring expression choose object


fichai prasov qu

otherwise visible object semantically compatible choose
object
otherwise full np proper name used uniquely identify referent
studies chai prasov hong found decision list
following limitations
depending interface design ambiguities systems perspective could
occur example given interface one object e g house sometimes
created top another object e g town pointing gesture could
multiple potential objects furthermore given interface crowded objects
nger point could multiple objects dierent probabilities
decision list able handle ambiguous cases
user inputs simple consisting one referring expression
one gesture indicated decision list fact study chai et al
found user inputs complex consisting multiple referring
expressions multiple gestures referents referring expressions
could come dierent sources gesture inputs conversation context
temporal alignment speech gesture important determining
correct referent given expression decision list able handle
types complex inputs
nevertheless previous ndings kehler inspired work provided
basis described
optimization
recently probabilistic developed optimizing reference resolution
graph matching chai et al b graph matching information
gathered multiple input modalities conversation context represented
attributed relational graphs args tsai fu specically two graphs used
one graph represents referring expressions speech utterances e called referring
graph referring graph contains referring expressions used speech utterance
relations expressions node corresponds one referring expression
consists semantic temporal information extracted expression
edge represents semantic temporal relation two referring expressions
resulting graph fully connected undirected graph example shown
figure speech input compare house green house brown one
three nodes generated referring graph representing three referring expressions
node contains semantic temporal features related corresponding referring
expression include expressions semantic type house town etc number
potential referents type dependent features size price etc syntactic category
expression timestamp expression produced edge contains
features describing semantic temporal relations pair nodes semantic
features simply indicate whether two nodes share semantic type


fiminimizing conflicts heuristic repair method

figure reference resolution probabilistic graph matching

inferred utterance otherwise semantic type relation deemed
unknown temporal features indicate two expressions uttered rst
similarly another graph represents potential referents gathered gestures history visual display e called referent graph node referent graph
captures semantic temporal information potential referent together
selection probability selection probability particularly applied objects indicated gesture gesture pointing circle potentially introduce
ambiguity terms intended referents selection probability used indicate
likely object selected particular gesture selection probability
derived function distance location entity focus point
recognized gesture display referring graph edge referent
graph captures semantic temporal relations two potential referents
whether two referents share semantic type temporal order
two referents introduced discourse example since gesture input
consists two pointings referent graph figure b consists potential referents
two pointings objects rst dashed rectangle potential referents
selected rst pointing second dashed rectangle correspond
second pointing furthermore salient objects prior conversation included referent graph since could potential referents well e g
rightmost dashed rectangle figure b
given graph representations reference resolution becomes probabilistic graph matching gold rangarajan goal nd match
referring graph gs referent graph gc achieves maximum
compatibility e maximizes q gc gs described following equation
subscription gs refers speech referring expressions c gc refers candidate referents



fichai prasov qu

q gc gs


x n odesim x
x
p






x





n p x p n edgesim xy mn



p x matching probability referent node x referring node
overall compatibility q gc gs depends node compatibility n odesim
edge compatibility edgesim dened temporal semantic
constraints chai et al converges p x gives matching
probabilities referent node x referring node maximizes overall
compatibility function matching probabilities system able identify
probable referent x referring node specically referring expression
matches potential referent assigned referent probability match
exceeds empirically computed threshold threshold met referring
expression remains unresolved
theoretically provides solution maximizes overall satisfaction
semantic temporal contextual constraints however many optimization
approaches non polynomial relies expensive matching process
attempts every possible assignment order converge optimal interpretation
constraints however previous linguistic cognitive studies indicate
user language behavior occur randomly rather follows certain cognitive principles therefore question arises whether knowledge cognitive principles
used guide matching process reduce complexity

cognitive principles
motivated previous work kehler specically focus two principles conversational implicature givenness hierarchy
conversational implicature
grices conversational implicature theory indicates interpretation inference
utterance communication guided set four maxims grice among
four maxims maxim quantity maxim manner particularly useful
purpose
maxim quantity two components make contribution informative required current purposes exchange make
contribution informative required context multimodal conversation
maxim indicates users generally make unnecessary gestures speech
utterances especially true pen gestures since usually require special
eort user therefore pen gesture intentionally delivered user
information conveyed often crucial component used interpretation
grices maxim manner four components avoid obscurity expression
avoid ambiguity brief orderly maxim indicates users
intentionally make ambiguous references use expressions speech
gesture believe uniquely describe object interest listeners
case computer system understand expressions choose depend


fiminimizing conflicts heuristic repair method

status
expression form
f ocus


activated
n

f amiliar
n

u nique identif iable
n

ref erential
indef inite n

identif iable

figure givenness hierarchy

information mental current state conversation however
information users mental model might dierent information system
possesses information gap happens dierent ambiguities could occur
system point view fact ambiguities intentionally caused
human speakers rather systems incapability choosing among alternatives
given incomplete knowledge representation limited capability contextual inference
factors e g interface design issues therefore system anticipate
deliberate ambiguities users e g user utters house refer particular
house screen rather focus dealing types ambiguities
caused systems limitations e g gesture ambiguity due interface design
speech ambiguity due incorrect recognition
two maxims help positioning role gestures reference resolution
particular maxims put potential referents indicated gesture
important position described section
givenness hierarchy
givenness hierarchy proposed gundel et al explains dierent determiners
pronominal forms signal dierent information memory attention state e
cognitive status gundel hedberg zacharski figure six
cognitive statuses hierarchy example focus indicates highest attentional
state likely continue topic activated indicates entities short term
memory statuses associated forms referring expressions
hierarchy cognitive status implies statuses list example focus
implies activated familiar etc use particular expression form signals
associated cognitive status met signals lower statuses
met words given form used describe lower status used
refer higher status vice versa cognitive statuses necessary conditions


fichai prasov qu

appropriate use dierent forms referring expressions gundel et al found dierent
referring expressions almost exclusively correlate six statuses hierarchy
givenness hierarchy investigated earlier resolving pronouns demonstratives spoken dialog systems eckert strube byron
multimodal interaction kehler particular would extend previous work kehler investigate whether conversational implicature givenness hierarchy used resolve variety references simple complex
precise ambiguous furthermore decision list used kehler proposed data analysis implemented evaluated real time
system therefore second goal design implement ecient
incorporating cognitive principles empirically compare performance
optimization chai et al nite state johnston bangalore
decision list kehler

greedy
greedy makes choice looks best moment processing
makes locally optimal choice hope choice lead globally optimal solution simple ecient greedy used approximate
many optimization explore use conversational implicature
givenness hierarchy designing ecient greedy particular extend
decision list kehler utilize concepts two cognitive principles
following way
corresponding givenness hierarchy following hierarchy holds potential
referents f ocus v isible hierarchy indicates objects focus higher
status terms attention states objects visual display focus
corresponds cognitive statuses focus activated givenness hierarchy
visible corresponds statuses familiar uniquely identifiable note
givenness hierarchy ne grained terms dierent statuses application
may able distinguish dierence statuses e g focus
activated eectively use therefore focus visible introduced
group similar statuses respect application together since
need dierentiate objects mentioned recently e g
focus activated objects accessible graph display
domain model e g familiar unique identiable assign
dierent modied statuses e g focus visible
conversational implicature since pen gesture takes special effort deliver must convey certain useful information fact objects indicated
gesture highest attentional state since deliberately singled
user therefore combining derive modied hierarchy
gesture f ocus v isible others others corresponds indenite cases
givenness hierarchy modied hierarchy coincides processing order
kehlers decision list modied hierarchy guide greedy


fiminimizing conflicts heuristic repair method

search solutions next describe detail
related representations functions
representation
turn e receiving user input conversation use three vectors
represent rst three statuses modied hierarchy objects selected gesture
objects focus objects visible display follows
gesture vector g captures objects selected series gestures element gi
object potentially selected gesture elements gi gj j
gesture selects objects gi temporally precede gesture selects
gj gesture selects gj since one gesture could
multiple objects
focus vector f captures objects focus selected
gesture element represents object considered focus attention
previous turn conversation temporal precedence relation
elements consider corresponding objects simultaneously
accessible current turn conversation
captures objects visible display neither
display vector
selected gesture e g focus f temporal precedence relation elements elements simultaneously accessible
representations object domain interest belongs
one vectors others object vectors consists
following attributes
semantic type object example semantic type could house
town
attributes object domain dependent feature set attributes
associated semantic type example house object price size
year built etc attributes furthermore object visual properties
reect appearance object display color object icon
identier object object unique name
selection probability refers probability given object selected
depending interface design gesture could list potential referents
use selection probability indicate likelihood object selected
gesture calculation selection probability described later objects
focus vector display vector selection probabilities set n
n total number objects respective vector
currently user inactivity e seconds input speech gesture used
boundary decide interaction turn



fichai prasov qu

temporal information relative temporal ordering information corresponding gesture instead applying time stamps previous work chai et al
b use index gestures according order occurrences object selected rst gesture temporal information
would
addition vectors capture potential referents user input vector
represents referring expressions speech utterance r maintained
element e referring expression following information
identier potential referent indicated referring expression
example identier potential referent expression house number eight
house object identier eight
semantic type potential referents indicated expression example
semantic type referring expression house house
number potential referents indicated referring expression
utterance context example singular noun phrase refers one object
phrase three houses provides exact number referents e
type dependent features features associated potential referents
color price extracted referring expression
temporal ordering information indicating order referring expressions
uttered instead specic time stamp use
temporal ordering information utterance consists n consecutive referring
expressions temporal ordering information would
n
syntactic categories referring expressions currently referring
expression assign one six syntactic categories e g demonstrative
pronoun details explained later
four vectors updated user turn conversation current
user input system state e g shown screen identied
focus previous turn conversation

ow chart pseudo code shown figure
multimodal input particular turn conversation takes inputs
vector r referring expressions size k gesture vector g size focus
size l rst creates three matrices
vector f size n display vector
g j f j j capture scores matching referring expression
r object three vectors calculation matching score described later
note g f empty corresponding matrix e g f
empty


fiminimizing conflicts heuristic repair method

initializematchmatrix
j k g j match gi rj
n j k f j match rj
l j k j match di rj


yes

g empty


greedysortinggesture
index max index column

j index max g j largest among elements row
add mark g j
index max j complete finding best match view object
assignreferentsfrommatrix g


references resolved



yes

yes
f empty



return

greedysortingfocus
j k
rj resolved
cross column j f keep ones resolved
n
j f j largest among elements row
mark f j
assignreferentsfrommatrix f


references resolved



greedysortingdisplay
j k
rj resolved
cross column j
l
j j largest among elements row
mark j
assignreferentsfrommatrix


return

assignreferentsfrommatrix matrix x
k e expression ri column
ri indicates specific number n n elements
ith column x
assign n largest elements ri referents
else assign elements ri referents


figure greedy multimodal reference resolution



yes

return

fichai prasov qu

matching scores three matrices applies greedy
search guided modied hierarchy described earlier since gesture
highest status rst searches gesture matrix g keeps track
matching scores referring expressions objects gestures identies
highest multiple highest matching scores assigns possible objects
gestures expressions greedysortinggesture
referring expressions left resolved gestures processed
looks objects focus matrix f since focus next highest cognitive status greedysortingfocus still expressions resolved
looks objects display matrix greedysortingdisplay currently
focuses three statuses certainly still expressions
resolved steps consult proper name resolution
referring expressions resolved system output
next multimodal input system generate four vectors apply greedy

note greedysortinggesture use index max keep track column index
corresponds largest matching value incrementally processes
row matrix index max incrementally increase referring expressions gesture aligned according order occurrences
since objects focus matrix display matrix temporal precedence
relations greedysortingfocus greedysortingdisplay use constraint
reason call greedy nds best assignment
referring expression given cognitive status hierarchy words
makes best choice referring expression one time according
order occurrence utterance one imagine mistaken assignment
made expression aect assignment following expressions therefore
greedy may lead globally optimal solution nevertheless general
user behavior following guiding principles makes greedy useful
one major advantage greedy use modied hierarchy signicantly prune search space compared graph matching
given referring expressions n potential referents sources e g gesture
conversation context visual display nd solution mn
furthermore goes beyond simple precise inputs illustrated
decision list kehler scoring mechanism described later greedy
sorting process accommodate complex ambiguous user inputs
matching functions
important component matching score object
referring expression e use following equation calculate matching score
atch e



p p e compatibility e



g f

formula represents possible associated status object could
three potential values g representing gesture f focus display
function determined three components


fiminimizing conflicts heuristic repair method

rst p object selectivity component measures probability
object referent given status object e gesture focus
visual display
second p e likelihood status component measures likelihood
status potential referent given particular type referring expression
third compatibility e compatibility component measures
semantic temporal compatibility object referring expression
e
next explain three components detail
object selectivity
calculate p gesture use function takes consideration
distance object focus point gesture display chai et al
b
given object focus e selected gesture p f ocus n
n total number objects focus vector object neither
selected gesture focus visible screen p display
total number objects display vector currently
applied simplest uniform distribution objects focus graphical
display future intend incorporate recency conversation discourse
model p f ocus use visual prominence e g visual characteristics
model p display note discussed earlier section object
associated one three statuses words given object
one p gesture p f ocus p display non zero
likelihood status
motivated givenness hierarchy earlier work kehler form
referring expressions reect cognitive status referred entities users mental
model use likelihood status measure probability reected status given
particular type referring expression particular use data reported kehler
derive likelihood status potential referents given particular type
referring expression p e categorize referring expressions following six
categories
empty referring expression used utterance
pronouns
locative adverbs
demonstratives
denite noun phrases noun phrases denite article
full noun phrases types proper nouns


fichai prasov qu

p e
visible
focus
gesture
sum

empty





pronoun





locative





demonstratives





definite





full





table likelihood status referents given particular type expression
table shows estimated p e note original data provided kehler
zero count certain combination referring type referent status
zero counts zero probability table use smoothing
techniques distribute probability mass furthermore probability mass
assigned status others
compatibility measurement
term compatibility e measures compatibility object referring
expression e similar compatibility measurement earlier work chai et al
dened multiplication many factors following equation
compatibility e id e sem e



attrk e emp e



k

equation
id e captures compatibility identier name identier
name specied e indicates identier potential referent
expressed referring expression match identier true referent
particularly useful resolving proper nouns example referring
expression house number eight correct referent identier
number eight id e identities e dierent id e
identities e one unknown
sem e captures semantic type compatibility e indicates
semantic type potential referent expressed referring expression
match semantic type correct referent sem e semantic types
e dierent sem e unknown
attrk e captures type specic constraint concerning particular semantic feature
indicated subscript k constraint indicates expected features
potential referent expressed referring expression compatible
features associated true referent example referring expression
victorian house style feature victorian therefore object
possible referent style object victorian thus dene following
attrk e e feature k values feature k
equal otherwise attrk e


fiminimizing conflicts heuristic repair method

house
house house
town
town town
gesture input
speech input compare houses
time

figure example complex input

emp e captures temporal compatibility e consider temporal ordering speech gesture specically temporal
compatibility dened following
emp e exp orderindex orderindex e



order speech accompanying gestures occur important
deciding gestures aligned referring expressions
order accompanying gestures introduced discourse
consistent order corresponding referring expressions
uttered example suppose user input consists three gestures g g g
two referring expressions possible g align
g align note status object focus visible
emp e denition temporal compatibility dierent
function used previous work chai et al takes real time stamps
consideration section shows dierent performance dierent
temporal compatibility functions
example
figure shows example complex input involves multiple referring expressions
multiple gestures interface displays house icons top town icons
point circle could house town object example rst
gesture house town second gesture house
town third house town suppose input takes
place house highlighted screen previous turn conversation e
house focus furthermore eight objects visible screen
resolve referents expressions houses greedy takes
following steps
r created lengths respectively
four input vectors g f
represent six objects gesture vector one object focus eight objects
graphical display two referring expressions used utterance
gesture matrix g focus matrix f display matrix created
three matrixes initialized equation figure shows resulting
gesture matrix probability values p e come table dierence


fichai prasov qu

status
g

referring expression match

potential
referent

j



j houses



house



gesture
town





house





town





gesture
house





town





gesture

gesture matrix
status
f

potential
referent

referring expression match

focus

house

j



j houses



b focus matrix

figure gesture matrix focus matrix b processing example figure
cell referring expression match columns corresponds instantiation
matching function

compatibility values house objects gesture matrix mainly due
temporal ordering compatibilities
next greedysortinggesture procedure executed row gesture matrix nds largest legitimate value marks corresponding cell
legitimate means corresponding cell row
column column right corresponding cell
row values shown bold figure next starting
column checks referring expression whether exists
corresponding column objects assigned referring
expressions number constraints case since specic number
given referring expression houses three marked objects assigned
houses
houses still left resolved continues
execute greedysortingfocus focus matrix prior executing greedysortingfocus
shown figure b note since houses longer considered
corresponding column deleted focus matrix similar previous step
largest non zero match value marked shown bold figure b assigned
remaining referring expression
resulting display matrix shown point referring expressions resolved


fiminimizing conflicts heuristic repair method

adj n n
adj n
num adj n
adj one
num adj ones

empty expression
proper nouns
multiple expressions
total num

g

gest











g
one
pt











g
mult
pts











g
one
cir











g
mult
cirs











g
pts
cirs











total
num











table detailed description user referring behavior

evaluation
use data collected previous work chai et al evaluate greedy
questions addressed evaluation following
impact temporal alignment speech gesture performance greedy
role modeling cognitive status greedy
eective greedy compared graph matching
section
error sources contribute failure real time reference resolution
greedy compared nite state section
decision list section
experiment setup
evaluation data collected eleven subjects participated study
subjects asked interact system speech gestures
e g pointing circle accomplish tasks related real estate information seeking
rst task nd least expensive house populated town order
accomplish task user would rst nd town highest
population nd least expensive house town next task involved
obtaining description house located previous task next task
compare house located rst task houses particular
town terms price additionally least expensive house second town
determined another task nd expensive house particular town


fichai prasov qu

referring expression
one referring expression
multiple referring expressions
total num

g
gesture


c


g one
gesture

b
c


g multigesture
c
c
c


total
num





table summary user referring behavior
last task involved comparing resulting houses previous four tasks
last task previous four tasks may completely partially repeated
tasks designed users required explore interface acquire
types information
acoustic model subject trained individually minimize speech recognition errors study session videotaped capture audio video
screen movement including gestures system responses ibm viavoice speech
recognizer used process speech input
table provides detailed description referring behavior observed study
columns indicate whether gesture one gesture pointing circle multiple gestures involved multimodal input rows indicate type referring expressions
speech utterance table entry shows number particular combination
speech gesture inputs
table summarizes table terms whether gesture one gesture multiple
gestures shown columns whether referring expression one referring expression
multiple referring expressions shown rows involved input note
table intended input counted one input even input may split
turns system run time
table categorize user inputs following three categories
simple inputs one zero alignment inputs contain speech referring
expression gesture e g one referring expression zero gesture
e g referring expression one gesture e g
types inputs require conversation context visual context resolve
references one example type u table data total
inputs belong category marked table
simple inputs one one alignment inputs contain exactly one referring
expression one gesture e g types inputs resolved
mostly combining gesture speech multimodal fusion total
inputs belong category marked b table
complex inputs inputs contain one referring expression gesture corresponds entry g g g
g table one example type u table total


fiminimizing conflicts heuristic repair method

correctly resolved
simple one zero alignment
simple one one alignment
complex
total
accuracy

ordering






absolute






combined






table performance comparison dierent temporal compatibility functions
inputs belong category marked c table types inputs
particularly challenging resolve
section focus dierent performance evaluations three
types referring behaviors
temporal alignment speech gesture
multimodal interpretation align speech gesture temporal
information important question especially case complex inputs
multimodal input consists multiple referring expressions multiple gestures
evaluated dierent temporal compatibility functions greedy particular
compared following three functions
ordering temporal constraint equation
absolute temporal constraint dened following formula
emp e exp begint ime begint ime e



absolute timestamps potential referents e g indicated gesture
referring expressions used instead relative orders relevant entities
user input
combined temporal constraint combines two aforementioned constraints
giving equal weight determining compatibility score object
referring expression
shown table dierent temporal constraints aect processing complex inputs ordering temporal constraint worked slightly better
absolute temporal constraint fact temporal alignment speech gesture often one may aect interpretation previous studies found
gestures tend occur corresponding speech unit takes place oviatt et al
ndings suggest users tend tap screen rst start
speech utterance behavior observed simple command system oviatt
et al speech unit corresponds single gesture e simple inputs
work


fichai prasov qu

non overlap
overlap
total

speech first




gesture first




total




table overall temporal relations speech gesture

study found temporal alignment gesture corresponding
speech units still issue needs investigated order improve
robustness multimodal interpretation table shows percentage dierent
temporal relations observed study rows indicate whether overlap
speech referring expressions accompanied gestures columns indicate
whether speech precisely referring expressions gesture occurred rst
consistent previous ndings oviatt et al cases time
gestures occurred referring expressions uttered however cases
speech referring expressions uttered corresponding gesture occurred
among cases overlap referring expressions gesture
overlap
furthermore although multimodal behaviors sequential e non overlap
simultaneous e g overlap integration quite consistent course interaction oviatt coulston tomko xiao bunsford wesson carmichael
exceptions figure shows temporal alignments individual users study
user user user maintained consistent behavior user gesture
happened overlapped corresponding speech referring expressions user
gesture occurred ahead speech expressions without overlapping user
speech referring expressions occurred corresponding gestures without
overlap users exhibited varied temporal alignment speech
gesture interaction dicult system pre dened temporal
constraints anticipate accommodate dierent behaviors therefore
desirable mechanism automatically learn user behavior alignment
automatically adjust behavior
one potential introduce calibration process real human computer
interaction calibration process two tasks performed user rst
task user asked describe objects graph display speech
deictic gestures second task user asked respond system
questions speech deictic gestures reason users perform
two tasks identify whether dierence user initiated inputs
system initiated user responses tasks temporal relations
speech units corresponding gestures captured used real time
interaction


fiminimizing conflicts heuristic repair method

percentage occurance

non overlap speech first
overlap speech first

non overlap gesture first
overlap gesture first


































user index

figure temporal alignment behavior user study

correctly resolved
simple one zero alignment
simple one one alignment
complex
total

cognitive principles





without cognitive principles





table role cognitive principles greedy

role cognitive principles
examine role modeling cognitive status multimodal reference compared two congurations greedy rst conguration
matching score dened equation incorporates cognitive principles described
earlier second conguration uses matching score completely dependent compatibility referring expression gesture e section
without cognitive principles e p p e included equation

table shows comparison terms two congurations
cognitive principles outperforms use cognitive
principles performance dierence applies simple inputs
one one alignment complex inputs indicate modeling cognitive
status potentially improve reference resolution performance


fichai prasov qu

total num
total
simple one zero alignment
simple one one alignment
complex






graph matching
num









greedy
num









table performance comparison graph matching greedy


greedy versus graph matching
compared greedy graph matching terms
performance runtime table shows performance comparison overall greedy
performs comparably graph matching
compare runtime ran user times input
run times words user input run times
get average runtime measurement experiment done ultrasparc iii
server mhz bit
greedy graph matching function
calls process speech inputs e g parsing gesture inputs e g identify potentially
intended objects dierence specic implementations
regarding graph creation matching graph matching greedy
search greedy average time greedy
process simple inputs complex inputs milliseconds milliseconds
respectively average time graph matching process simple
complex inputs milliseconds milliseconds respectively
average greedy runs slightly faster graph matching
given current implementation although worst case graph matching
asymptotically complex
real time error analysis
understand bottleneck real time multimodal reference resolution examined
error cases failed provide correct referents
spoken dialog systems speech recognition major bottleneck although
trained users acoustic model individually speech recognition rate still
low inputs correctly recognized referring expressions among
inputs resolved correct referents fusing inputs multiple
modalities together sometimes compensate recognition errors oviatt
among inputs referring expressions incorrectly recognized
correctly assigned referents due mutual disambiguation mechanism reduce


fiminimizing conflicts heuristic repair method

recognition errors especially utilizing information modalities
important provide robust solution real time multimodal reference resolution
second source errors comes another common spoken dialog
systems namely vocabulary words example area vocabulary
additional semantic constraint expressed area captured therefore
system could identify whether house town referred user uttered
area important system capability acquire knowledge e g
vocabulary dynamically utilizing information modalities interaction
context furthermore errors came lack understanding spatial relations
house close red one superlatives expensive house
aligning visual features resolve spatial references desirable gorniak
roy
addition two main sources errors caused unsynchronized inputs
currently use idle status e seconds input speech gesture
boundary delimit interaction turn two types synchronization
observed rst type unsynchronized inputs user big pause
speech gesture comes underlying system implementation
system captures speech inputs gesture inputs two dierent servers
tcp ip protocol communication delay sometimes split one synchronized input
two separate turns inputs e g one turn speech input alone turn
gesture input alone better engineering mechanism synchronizing inputs desired
disuencies users accounted small number errors current incapable distinguishing disuent cases normal cases fortunately
disuent situations occur frequently study inputs disuency consistent previous ndings speech disuency rate lower
human machine conversation spontaneous speech brennan humancomputer conversation users tend speak carefully utterances tend short recent
ndings indicated gesture patterns could used additional source identify
dierent types speech disuencies human human conversation chen harper
quek limited cases found gesture patterns could indicators
speech disuencies occur example user says red
house point house green house still point house behavior
pointing house dierent speech description usually indicates repair furthermore gestures involve disuencies example repeatedly pointing object
gesture repetition failure identifying disuencies caused reference
resolution ideal mechanism identify disuencies
multimodal information
comparative evaluation two approaches
examine greedy compared nite state
section decision list section conducted comparative evaluation original nite state n best speech hypotheses maintained
speech tape data best speech hypothesis speech
input therefore manually updated incorrectly recognized words nite


fichai prasov qu

correctly resolved
simple inputs one one alighment
simple inputs zero one alighment
complex inputs
total

greedy





finite state





decision list





table performance comparison two approaches
state would penalized lack n best speech hypotheses
modied data used three approaches table shows comparison
shown table greedy correctly resolved inputs
nite state decision list major nite state
incorporate conversation context nite state transducer
contributes failure resolving simple inputs zero one alignment
complex inputs major decision list
described earlier lack capabilities process ambiguous gestures complex
inputs
note greedy obtain full semantic interpretation multimodal input rather specically reference
resolution uses information context gesture resolve speech referring expressions regard greedy dierent nite state
whose goal get full interpretation user inputs reference resolution
part process

conclusion
motivated earlier investigation cognitive status human machine interaction
describes greedy incorporates cognitive principles underlying human referring behavior resolve variety references human machine multimodal
interaction particular relies theories conversation implicature
givenness hierarchy eectively guide system searching potential referents empirical studies shown modeling form referring experssions
implication cognitive status achieve better
considers compatibility referring expressions potential referents
greedy eciently achieve comparable performance previous optimization
graph matching furthermore greedy handles
variety user inputs ranging precise ambiguous simple complex
outperforms nite state decision list experiments
simplicity generality potential improve robustness multimodal interpretation learned investigation prior
note corrected inputs direct correspondence recognized
words transcribed words maintain consistency timestamps



fiminimizing conflicts heuristic repair method

knowledge linguistic cognitive studies benecial designing ecient
practical enabling multimodal human machine communication

acknowledgments
work supported nsf career award iis authors would
thank anonymous reviewers valuable comments suggestions

references
bolt r put voice gesture graphics interface computer
graphics
brennan processes shape conversation implications computational linguistics proceedings th annual meeting acl pp
byron resolving pronominal reference abstract entities proceedings
th annual meeting acl pp
cassell j bickmore billinghurst campbell l chang k vilhjalmsson h
yan h embodiment conversational interfaces rea proceedings
chi pp
chai j hong p zhou prasov z optimization multimodal interpretation proceedings nd annual meeting association computational
linguistics acl pp
chai j prasov z blaim j jin r linguistic theories ecient multimodal
reference resolution empirical study proceedings th international
conference intelligent user interfaces iui pp
chai j prasov z hong p performance evaluation error analysis
multimodal reference resolution conversational system proceedings hltnaacl companion volumn pp
chai j hong p zhou x b probabilistic reference resolution multimodal user interfaces proceedings th international conference
intelligent user interfaces iui pp
chen l harper quek f gesture patterns speech repairs
proceedings international conference multimodal interfaces icmi pp

cohen p pragmatics referring modality communication computational linguistics
cohen p johnston mcgee oviatt pittman j smith chen l clow j
quickset multimodal interaction distributed applications proceedings
acm multimedia pp
eckert strube dialogue acts synchronising units anaphora resolution journal semantics vol pp


fichai prasov qu

gold rangarajan graduated assignment graph matching
ieee trans pattern analysis machine intelligence
gorniak p roy grounded semantic composition visual scenes journal
artificial intelligence
grice h p logic conversation cole p morgan j eds speech acts
pp york academic press
grosz b j sidner c attention intention structure discourse
computational linguistics
gundel j k hedberg n zacharski r cognitive status form
referring expressions discourse language
gustafson j bell l beskow j boye j carlson r edlund j granstrom b house
wiren adapt multimodal conversational dialogue system
apartment domain proceedings th international conference spoken
language processing icslp vol pp
huls c bos e classen w automatic referent resolution deictic
anaphoric expressions computational linguistics
johnston unication multimodal parsing proceedings colingacl pp
johnston bangalore finite state multimodal parsing understanding
proceedings coling pp
johnston cohen p mcgee oviatt pittman j smith unicationbased multimodal integration proceedings acl pp
kehler cognitive status form reference multimodal human computer
interaction proceedings aaai pp
koons b sparrell c j thorisson k r integrating simultaneous input
speech gaze hand gestures maybury ed intelligent multimedia
interfaces pp mit press
neal j g shapiro c intelligent multimedia interface technology sullivan
j tyler eds intelligent user interfaces pp acm york
neal j g thielman c dobes z h shapiro c natural language
integrated deictic graphic gestures maybury wahlster w eds
intelligent user interfaces pp ca morgan kaufmann press
oviatt coulston r tomko xiao b bunsford r wesson carmichael l
toward theory organized multimodal integration patterns humancomputer interaction proceedings fifth international conference multimodal
interfaces pp
oviatt deangeli kuhn k integration synchronization input
modes multimodal human computer interaction proceedings conference
human factors computing systems chi pp


fiminimizing conflicts heuristic repair method

oviatt l multimodal interfaces dynamic interactive maps proceedings
conference human factors computing systems chi pp
oviatt l multimodal system processing mobile environments proceedings
thirteenth annual acm symposium user interface software technology
uist pp
oviatt l b mutual disambiguation recognition errors multimodal architecture proceedings conference human factors computing systems
chi pp
stent dowding j gawron j bratt e moore r commandtalk
spoken dialog system proceedings acl pp
stock alfresco enjoying combination natural language processing
hypermedia information exploration maybury ed intelligent multimedia
interfaces pp mit press
tsai w h fu k error correcting isomorphism attributed relational
graphs pattern analysis ieee trans sys man cyb
wahlster w user discourse multimodal communication maybury wahlster w eds intelligent user interfaces pp acm press
wu l oviatt multimodal integration statistical view ieee transactions
multimedia
zancanaro stock strapparava c multimodal interaction information
access exploiting cohesion computational intelligence




