journal artificial intelligence

submitted published

resource allocation among agents mdp induced
preferences
dmitri dolgov

ddolgov ai stanford edu

technical department ai robotics group
toyota technical center
green road
ann arbor mi usa

edmund h durfee

durfee umich edu

electrical engineering computer science
university michigan
hayward st
ann arbor mi usa

abstract
allocating scarce resources among agents maximize global utility general computationally challenging focus resources enable agents execute
actions stochastic environments modeled markov decision processes mdps
value resource bundle defined expected value optimal mdp
policy realizable given resources present simultaneously solves
resource allocation policy optimization allows us avoid explicitly representing utilities exponentially many resource bundles leading drastic
often exponential reductions computational complexity use
context self interested agents design combinatorial auction allocating resources empirically demonstrate effectiveness showing
minutes optimally solve straightforward combinatorial
resource allocation technique would require agents enumerate resource
bundles auctioneer solve np complete input size

introduction
resource allocation ubiquitous many diverse fields
economics operations computer science applications ranging decentralized scheduling e g wellman walsh wurman mackie mason network routing e g feldmann gairing lucking monien rode transportation
logistics e g sheffi song regan bandwidth allocation e g mcmillan
mcafee mcmillan name core question resource allocation distribute set scarce resources among set agents cooperative
self interested way maximizes measure global utility social welfare
sum agents utilities one popular criteria
many domains agents utility obtaining set resources defined
agent accomplish resources example value vehicle
delivery agent defined additional revenue agent obtain
vehicle however figure best utilize resource set resources agent
c

ai access foundation rights reserved

fidolgov durfee

available
resources

available
actions

resource allocation



mdp

utility function
resources

best plan
payoff

figure dependency cycle formulate agents need
know resources get utility functions define
input resource allocation depend solutions


often must solve non trivial actions might long term nondeterministic effects therefore agents value set resources defined solution
formulate agent needs know
resources obtain leads cyclic dependencies depicted figure wherein
input resource allocation depends solution
vice versa unfortunately anything simplest domains neither resourceallocation solved closed form making impossible
obtain parameterized solutions
focus solving interdependent resource allocation
stochastic main question consider allocate resources
way maximizes social welfare agents utility function agent
defined markov decision process puterman whose action set parameterized
resources specifically focus non consumable resources
vehicles enable actions consumed action execution
briefly mention case consumable resources section refer work
dolgov detailed treatment
assume agents mdps weakly coupled meaning agents interact
resources resources allocated transition reward
functions mdps independent model weakly coupled mdps connected
via shared resources similar meuleau hauskrecht kim peshkin kaelbling
dean boutilier benazera brafman meuleau hansen
differs assume resources allocated prior actions
taken one shot allocation assumption limits somewhat
allows apply broadly non cooperative settings without
assumption game theoretic analysis agents interactions significantly
complex importantly allows us avoid state space explosion due including
resource information mdp states limits work finding
approximately optimal solutions non trivial
main presented thus
conditions optimally solves resource allocation policy optimization
simultaneously considering two together sidesteps dependency cycle


firesource allocation among agents mdp induced preferences

mentioned allows us avoid explicit representation utility functions
resource bundles leading exponential reduction complexity combinatorial
resource allocation flat utility functions empirically demonstrate resulting
scales well finding optimal solutions involving numerous agents
resources
viewed contributing dealing computational complexity resource allocation domains complex utility functions
linearly decomposable resources due effects substitutability
complementarity combinatorial allocation finding optimal allocation np complete often exponentially large space resource bundles rothkopf
pekec harstad previous approaches addressing complexity included
determining classes utility functions lead tractable surveyed
de vries vohra iterative resource allocation preference elicitation surveyed sandholm boutilier concise languages expressing
agents preferences sandholm nisan boutilier hoos boutilier
novelty respect explicitly embraces underlying processes define agents utility functions cases processes
modeled resource parameterized mdps use
mdp concise language agents utility functions importantly directly exploits structure drastically reduce computational
complexity simultaneously solving resource allocation
context cooperative agents viewed way solving
weakly coupled multiagent mdps agents transition reward functions independent space joint actions constrained example used
singh cohn meuleau et al perspective concept
resources viewed compact way representing interactions agents
similarly model used bererton gordon thrun however work
differs number assumptions moreover easily modified work
constraints joint actions modeled directly example
via sat formulas
non cooperative agents apply resource allocation mechanismdesign e g mas colell whinston green goal allocate
resources among agents way maximizes social welfare given
participating agent selfishly maximizing utility domains self interested
agents complex preferences exhibit combinatorial effects resources
combinatorial auctions e g de vries vohra often used resource allocation
generalized vickrey auction gva mackie mason varian extension vickrey clarke groves vcg mechanisms vickrey clarke groves
combinatorial auctions particularly attractive nice analytical
properties described section develop variant vcg auction
agents submit resource parameterized mdps bids auctioneer simultaneously solves resource allocation policy optimization thus retaining
compact representation agents preferences throughout process describe extensions mechanism distributing computation encoding mdp information
reduce revelation private information


fidolgov durfee

remainder proceeds follows brief review mdps
section present section model decision making agent resourceparameterized mdp capacity constraints analyze optimal policy
formulation resource parameterized capacity constrained mdp study properties present solution formulation np complete
mixed integer program
building blocks move multiagent setting present main
simultaneously allocating resources across agents
section design combinatorial auction allocating
resources among self interested agents describe distributed implementation
mechanism discuss techniques preserving information privacy section
analyze computational efficiency empirically demonstrating exponential reductions computational complexity compared straightforward combinatorial
resource allocation flat utility functions finally section conclude
discussion possible generalizations extensions conciseness
better readability proofs generalizations deferred appendices

markov decision processes
base model agents decision infinite horizon fully observable mdps
total expected discounted reward optimization criterion although
applicable classes mdps mdps average per step rewards
section introduces notation assumptions serves brief overview
basic mdp see example text puterman detailed discussion
material section
classical single agent unconstrained stationary fully observable mdp defined
tuple hs p ri
finite set states agent
finite set actions agent execute
p defines transition function probability agent
goes state upon execution action state p

p assume action corresponding transition matrix stochastic
p
r r defines reward function agent obtains reward r
executes action state assume rewards bounded
discrete time fully observable mdp time step agent observes current
state system chooses action according policy policy said
markovian history independent choice action depend history
states actions encountered past rather current state
time addition policy depend time called stationary
definition stationary policy markovian deterministic policy prescribes
execution action state randomized policy chooses actions
according probability distribution


firesource allocation among agents mdp induced preferences

following standard notation puterman refer different classes policies
xy x h specifies whether policy history dependent markovian
stationary r specifies whether policy randomized deterministic
e g class stationary deterministic policies labeled sd obviously hy
sy xr xd history dependent randomized policies hr stationary
deterministic policies sd least general respectively
stationary randomized policy thus mapping states probability distributions
actions defines probability action
executed state stationary deterministic policy viewed degenerate case
randomized policy one action state nonzero
probability executed
unconstrained discounted mdp goal policy maximizes
total expected discounted reward infinite time horizon

hx

u e
rt



discount factor unit reward time worth
agent reward time rt random reward agent receives time
whose distribution depends policy initial distribution state space

one important theory mdps states unconstrained discounted mdp total expected reward optimization criterion exists optimal policy stationary deterministic uniformly optimal
latter term means policy optimal distributions starting state
several commonly used ways finding optimal policy central
concept value function policy v r v expected
cumulative value reward agent would receive started state behaved
according policy given policy value every state unique solution
following system linear equations
x
x
v
r
p v






optimal policy handy consider optimal value function v r
v represents value state given agent behaves optimally
optimal value function satisfies following system nonlinear equations
h

x
v max r
p v






v

given optimal value function
optimal policy simply act greedily respect

v method tie breaking case multiple optimal actions
h


p
arg maxa r p v


otherwise
notation x exponent xy superscript
uniform optimality policies reason included component textbook mdp



fidolgov durfee

one possible ways solving optimal value function formulate
nonlinear system linear program lp optimization variables v
constraints
x
min
v


subject



v r

x

p v





arbitrary constant vector positive components
many including ones focus useful consider equivalent dual lp optimization variables x
constraints
xx
r x
max
x





subject
x
xx
x
x p









x



optimization variables x often called visitation frequencies occupation measure policy think initial probability distribution x
interpreted
p total expected number times action executed state
x x gives total expected flow state constraints
lp interpreted conservation flow states
optimal policy computed solution dual lp
x


p
x
p
non negativity guarantees x general appears
lead randomized policies however bounded lp n constraints basic
feasible solution e g bertsimas tsitsiklis definition
n non zero components strictly positive basic feasible solution lp
precisely nonzero components one state guarantees existence
optimal deterministic policy policy easily obtained lp solvers
e g simplex produce solutions map deterministic policies
furthermore mentioned unconstrained discounted mdps
exist policies uniformly optimal optimal initial distributions
dual lp yields uniformly optimal policies strictly positive used however
overloading objective function coefficients initial probability distribution
mdp earlier intentional explained shortly
note authors e g altman prefer opposite convention called dual
primal



firesource allocation among agents mdp induced preferences

solution x dual lp retains interpretation expected number times state
visited action executed initial probability distribution
used lp
main benefit dual lp manifested constrained mdps altman
kallenberg heyman sobel action addition producing
reward r incurs vector costs k r k k maximize expected reward subject constraints expected costs
constrained type arise many domains telecommunication applications e g ross chen ross varadarajan often desirable
maximize expected throughput subject conditions average delay
constraints imposed expected costs solved polynomial time
linear programming simply augmenting dual lp following linear
constraints
xx
k x bk
k k





bk upper bound expected cost type k resulting constrained mdp
differs standard unconstrained mdp particular deterministic policies
longer optimal uniformly optimal policies general exist
kallenberg
reason easily augmentable constraints dual lp
forms basis however constraints arise resource allocation
focus different linear constraints
leading different optimization different properties requiring different
solution techniques described detail section
conclude background section introducing simple unconstrained mdp
serve basis running example refer throughout rest

example consider simple delivery domain depicted figure agent
obtain rewards delivering furniture action delivering appliances action
delivering appliances produces higher rewards shown diagram
damage delivery vehicle agent delivers furniture damage vehicle
negligible whereas agent delivers appliances vehicle guaranteed function
reliably first year state state probability failure
per year vehicle serviced action resetting condition expense
lowering profits truck break state repaired action
significant negative impact profits assume discount factor
optimal value function v v v
corresponding optimal occupation measure assuming uniform following listing
non zero elements x x x maps
optimal policy dictates agent start delivering appliances action
state service vehicle first year action state fix
vehicle ever gets broken latter zero probability happening
policy agent starts state



fidolgov durfee

deliver furniture
p
r


initial

fix truck
p
r

deliver furniture
p
r

deliver appliances
p
r
service truck
p
r


nd year
deliver appliances
p
r
p
r


truck broken

figure unconstrained mdp example delivery domain transition probabilities p
rewards r shown diagram actions shown transition
state reward noop action corresponds
nothing change state produces zero reward

agent model resource parameterized mdp
section introduce model decision making agent describe
single agent stochastic policy optimization defines agents preferences
resources single agent formulated mdp whose
action set parameterized resources available agent stationary deterministic
policies optimal uniformly optimal policies general exist
finding optimal policies np complete finally present policyoptimization formulation mixed integer linear
program milp
model agents resource parameterized mdp follows agent set
actions potentially executable action requires certain combination
resources capture local constraints sets resources agent use use
concept capacities resource capacity costs associated
agent capacity constraints example delivery company needs vehicles loading
equipment resources allocated make deliveries execute actions however
equipment costs money requires manpower operate agents local capacity
costs therefore amount equipment agent acquire successfully utilize
constrained factors budget limited manpower agents local capacity
bounds two layer model capacities resources represented separately might
seem unnecessarily complex fold together impose constraints directly
resources separation becomes evident useful multiagent model
discussed section emphasize difference resources items
allocated among agents capacities define inherent limitations individual
agent combinations resources usefully possess
agents optimization choose subset available resources
violate capacity constraints best policy feasible bundle
resources yields highest utility words single agent analyzed


firesource allocation among agents mdp induced preferences

section constraints total resource amounts introduced
multiagent next section constraints due agents
capacity limits adding limited resource amounts single agent model would
simple matter since constraints handled simple pruning agents
action space note without capacity constraints single agent
would trivial would optimal agent simply take resources
potential use however presence capacity constraints face
similar cyclic dependency figure resource selection requires
knowing values resource bundles defined
ill defined resource bundle chosen section
focus single agent selecting optimal subset resources satisfies
agents capacity constraints assume agent value acquiring additional
resources exceed capacity bounds
resources model outlined non consumable e actions require
resources consume execution mentioned introduction
work focus non consumable resources briefly outline case
consumable resources section
model agents optimization n tuple hs p r c
b
hs p ri standard components mdp defined earlier section
set resources e g production equipment vehicle use
refer resource type
r function specifies resource requirements actions
defines much resource action needs executable e g
vehicle means action requires one vehicle
c set capacities agent e g c space money manpower
use c c refer capacity type
c r function specifies capacity costs resources c defines
much capacity c c unit resource requires e g vehicle money
defines monetary cost vehicle vehicle manpower means
two people required operate vehicle

b c r specifies upper bound capacities
b c gives upper bound
capacity c c e g
b money defines budget constraint

b manpower specifies size workforce
r initial probability distribution probability agent
starts state
goal policy yields highest expected reward conditions resource requirements policy exceed capacity bounds


fidolgov durfee

agent words solve following mathematical program
max u


subject
n
x
x

c max h

b c





c c



h heaviside step function nonnegative argument defined

z
h z
z
constraint interpreted follows argument h nonzero
thep
policy assigns nonzero probability action least one state thus
function
h serves indicator

us whether agent plans use
p tells
action policy max h tells us much resource
agent needs policy take max respect resource
used different actions therefore summed resources left hand
side gives us total requirements policy terms capacity c
greater bound
b c
following example illustrates single agent model
example let us augment example follows suppose agents needs obtain
truck perform delivery actions truck required service
repair actions deliver appliances agent needs acquire
forklift needs hire mechanic able repair vehicle noop
action requires resources maps model three resources truck forklift
mechanic ot om following action resource costs listing
non zero ones
ot ot ot ot om
moreover suppose resources truck ot forklift mechanic om
following capacity costs one capacity type money c c
ot c c om c
agent limited budget
b therefore acquire two
three resources means optimal solution unconstrained
example longer feasible

let us observe mdp model agents preferences presented
fully general discrete indivisible resources e non decreasing utility function
resource bundles represented via resource constrained mdp model described

formulation assumes stationary policy supported argument section



firesource allocation among agents mdp induced preferences

theorem consider finite set n indivisible resources oi n
n available units resource non decreasing utility function
defined resource bundles f n r exists resource constrained mdp
hs p r c
b resource set whose induced utility function
resource bundles f words every resource bundle z n
value optimal policy among whose resource requirements exceed z
call set z f z
f n r hs p r c
b
n
h

x


z n z max oi h
zi max u f z




z

proof see appendix

let us comment theorem establishes generality mdp preference model introduced section construction used proof little practical interest requires mdp exponentially large state action space indeed
advocate mapping arbitrary unstructured utility functions exponentially large
mdps general solution technique rather contention techniques apply domains utility functions induced stochastic decision making process
modeled mdp thus resulting well structured preferences resources
exploited drastically lower computational complexity resource allocation

properties single agent constrained mdp
section analyze constrained policy optimization namely
stationary deterministic policies optimal meaning
necessary consider randomized history dependent policies however solutions
general uniformly optimal optimal initial distribution
furthermore np hard unlike unconstrained mdps
solved polynomial time littman dean kaelbling
begin showing optimality stationary deterministic policies
following use hr refer class history dependent randomized policies
general policies sd hr refer class stationary deterministic
policies
theorem given mdp hs p r c
b resource capacity
hr
constraints exists policy
feasible solution exists
stationary deterministic policy sd sd feasible expected total reward
sd less
hr sd sd u sd u
proof see appendix

theorem surprising intuitively stationary deterministic
policies optimal history dependence increase utility policy


fidolgov durfee

randomization increase resource costs latter true including action policy incurs costs terms resources regardless
probability executing action expected number times action
executed true dealing non consumable resources property hold mdps consumable resources discuss detail
section
uniformly optimal policies exist constrained
well known another class constrained mdps constraints
imposed total expected costs proportional expected number
times corresponding actions executed discussed earlier section mdps
constraints arise example bounds imposed expected usage
consumable resources mentioned section solved
linear programming augmenting dual lp linear constraints expected
costs establish non consumable resources
capacity constraints
observation exist uniformly optimal solutions
words exist two constrained mdps differ initial conditions
hs p r c
b hs p r c
b policy
optimal simultaneously e two policies
optimal solutions respectively following holds
u u

u u



demonstrate observation example
example consider resource constrained example easy see
initial conditions agent starts state certainty
optimal policy states example
given initial conditions zero probability reaching state
noop assigned policy requires truck forklift however
agent starts state optimal policy fix truck execute
resort furniture delivery assign noop ao
never visited policy requires mechanic truck two policies
uniquely optimal corresponding initial conditions suboptimal initial
conditions demonstrates uniformly optimal policy exists example
intuition behind fact uniformly optimal policies general exist
constrained mdps since resource information part mdp state
space constraints imposed resource usage principle bellman optimality hold optimal actions different states cannot chosen independently
given constrained mdp possible construct equivalent unconstrained mdp
standard properties optimal solutions folding resource information
state space modeling resource constraints via transition function resulting
state space exponential number resources
analyze computational complexity optimization


firesource allocation among agents mdp induced preferences

theorem following decision np complete given instance mdp
hs p r c
b resources capacity constraints rational number
exist feasible policy whose expected total reward given less
proof see appendix

note complexity stems limited capacities agents
fact define resource requirements policy set resources
needed carry actions nonzero probability executed
however defined constraints expected resource requirements actions
low probability executed would lower resource requirements optimal policies
would randomized would equivalent knapsack continuously
divisible items solvable polynomial time via lp formulation mdps
linear constraints
milp solution
analyzed properties optimization present
formulation mixed integer linear program milp given established
np completeness previous section milp np complete reasonable
formulation allows us reap benefits vast selection efficient
tools see example text wolsey references therein
section rest assume resource requirements
actions binary e make assumption simplify
discussion limit generality briefly describe case
non binary resource costs appendix b completeness refer work
dolgov detailed discussion examples
let us rewrite occupation measure coordinates x adding constraints
standard lp occupancy coordinates noticing states
nonzero probability visited x zero nonzero simultaneously
x
x


x

h
h




total resource requirements policy simplified
follows
x

n
x
x

max h
x h

x










get following program x
xx
max
x r
x





subject
x
xx
x
x p


x



c h



x








x


x
b c

c c



x






fidolgov durfee

challenge solving mathematical program constraints nonlinear
due heaviside function h
linearize heaviside function augment original
variables
poptimization
x
p
set binary variables h

x
words indicator variable shows whether policy requires resource
rewrite resource constraints
x
c
b c
c c



linear synchronize x via following linear inequalities
x
x
x

x






p
p
x maxo x normalization constant upper bound argument h used bound x guaranteed
exist
p
max


since

discounted


example


use
x






p

x valid occupation measure mdp
x

discount factor
putting together finding optimal policies resource constraints formulated following milp
xx
max
x r
x





subject
x
xx
x
x p


x







c
b c

c c

x







x





x

x



x







illustrate milp construction example
example let us formulate milp constrained example recall three resources ot om truck forklift
mechanic one capacity type c c money actions following resource
requirements listing nonzero ones
ot ot ot ot om
p
p
instead single x resources different x x used
every resource leading uniform normalization potentially better numerical stability
milp solver



firesource allocation among agents mdp induced preferences

resources following capacity costs
ot c

c

om c

agent limited budget e capacity bound
b c
compute optimal policy arbitrary formulate
milp described binary variables ot om
express constraint capacity cost following inequality
ot om
constraints synchronizep
occupation measure x binary indicators
set x maxo combining
constraints get milp continuous binary variables
c constraints counting last two sets range constraints

mentioned earlier even though solving programs general np complete
task wide variety efficient tools therefore
one benefits formulating optimization milp allows
us make use highly efficient existing tools

multiagent resource allocation
consider multiagent resource allocation several agents
resource preferences agents defined constrained mdp model
described previous section reiterate main assumptions
weak coupling assume agents weakly coupled meuleau et al
e interact shared resources resources allocated agents transitions rewards independent assumption critical

one shot resource allocation resources distributed agents
start executing mdps reallocation resources mdp
phase assumption critical allowing reallocation resources
would violate weak coupling assumption
initial central control resources assume beginning
resource allocation phase resources controlled single authority
standard sell auction setting resources distributed
agents cooperative assumption weak coupling relaxed expense
increase complexity milp simultaneously performing policy optimization resource allocation applied consider joint state spaces interacting
agents self interested agents violation weakly coupled assumption would mean
agents would playing markov game shapley resources allocated would
significantly complicate strategic analysis agents bidding strategies initial resource
allocation



fidolgov durfee

among agents begin face designing computationallyefficient combinatorial exchange parkes kalagnanam eso
complicated outside scope work however many
ideas presented could potentially applicable domain well
binary resource costs assume agents resource costs binary
assumption limiting case non binary resources discussed
appendix b
formally input resource allocation consists following
set agents use refer agent
hs pm rm
bm collection weakly coupled single agent mdps
defined single agent model section simplicity without loss
generality assume agents state action spaces
transition reward functions pm rm initial conditions
well resource requirements capacity bounds

bm c r assume agents discount factor
assumption trivially relaxed
c sets resources capacities defined exactly single agent
model section
c r specifies capacity costs resources defined exactly
single agent model section
b r specifies upper bound amounts shared resources
defines additional bound multiagent
given goal design mechanism allocating resources
agents economically efficient way e way maximizes social welfare
agents one often used criteria mechanism design would
mechanism efficient computational standpoint
example suppose two delivery agents mdp capacity constraints
first agent exactly defined previously examples mdp
second agent almost first agent difference
gets slightly higher reward delivering appliances r whereas
r first agent suppose two trucks one forklift one
mechanic shared two agents bounds specified follows
b ot

b

b om

decide agent get forklift get
mechanic trucks plentiful example



firesource allocation among agents mdp induced preferences

combinatorial auctions
previously mentioned finding optimal resource allocation among
self interested agents complex valuations combinations resources arises
many different domains e g ferguson nikolaou sairamesh yemini wellman
et al often called combinatorial allocation natural widely
used mechanism solving combinatorial auction ca e g de vries
vohra ca agent submits set bids resource bundles
auctioneer decides resources agent get price
consider allocating among set agents set indivisible resources total quantity resource bounded b earlier
simplifying assumption actions resource requirements binary implies agents
interested bundles contain one unit particular resource
combinatorial auction agent submits bid bm
w specifying much
agent willing pay every bundle w w value um
w
cases possible express bids without enumerating bundles example
xor bidding language sandholm necessary consider bundles
strictly positive value subset bundle value
techniques often reduce complexity resource allocation
general avoid exponential blow number bids therefore describe
simplest combinatorial auction flat bids noted many concise
bidding languages exist special cases reduce number explicit bids
collecting bids auctioneer solves winner determination
wdp solution prescribes resources distributed among
utility um q
agents prices agent wins bundle w price qw
w
w
assuming risk neutral agents quasi linear utility functions thus optimal
bidding strategy agent depends auctioneer allocates resources sets
prices
vickrey clarke groves vcg mechanisms vickrey clarke groves
widely used family mechanisms certain attractive properties discussed detail instantiation vcg mechanism context
combinatorial auctions generalized vickrey auction gva mackie mason varian allocates resources sets prices follows given bids bm
w
agents auctioneer chooses allocation maximizes sum agents bids
np complete rothkopf et al expressed following inm indicator variables
teger program optimization variables zw
whether bundle w assigned agent nwo specifies whether bundle w
contains

related solving wdp e g sandholm use
integer program representative formulation class perform search
space binary decisions resource bundles



fidolgov durfee

x

max
z

x


zw
bw

mm ww

subject
x

zw






ww

x

x

mm

ww


zw
nwo b



first constraint says agent receive one bundle
second constraint ensures total amount resource assigned agents
exceed total amount available notice milp performs summation
exponentially large sets bundles w w outlined auction xor
bidding sets would typically smaller general still exponentially large
gva assigns resources according optimal solution ze sets payment
agent
x



qw
vm

zew
bw



vm
value participate auction optimal
value submit bids second term sum agents bids
solution ze wdp participating
gva number nice properties strategy proof meaning dominant

strategy every agent bid true value every bundle bm
w uw auction
economically efficient meaning allocates resources maximize social
welfare agents agents bid true values objective function
becomes social welfare finally gva satisfies participation constraint
meaning agent decreases utility participating auction
straightforward way implement gva mdp following
let agent enumerate resource bundles w satisfy local capacity
constraints defined
bm c sufficient mdp model implies free disposal
resources agents make assumption auctioneer
bundle w w agent would determine feasible action set w formulate
mdp w hs w pm w rm w pm w rm w transition
reward functions defined pruned action space w every agent would
solve w corresponding feasible bundle optimal policy
em w whose



expected discounted reward would define value bundle w uw u e
w
mechanism suffers two major complexity first agents
enumerate exponential number resource bundles compute value
solving corresponding possibly large mdp second auctioneer solve
np complete winner determination exponentially large input following
sections devoted tackling complexity

example consider two agent described example two trucks one
forklift services one mechanic auctioned straightforward
version combinatorial auction outlined agent would consider


firesource allocation among agents mdp induced preferences

possible resource bundles since resource requirements agents
binary neither agent going bid bundle contains two trucks every
resource bundle agent formulate solve corresponding mdp
compute utility bundle
example assume agents start state different initial conditions
would different expected rewards thus different utility functions value
null resource bundle agents would since action would able
execute noop hand value bundle ot om
contains resources would first agent second one
value bundle agent would value since
optimal policies initial conditions put require mechanic
agents submit bids auctioneer solve wdp via
integer program binary variables given
optimal way allocate resources would assign truck agents
forklift second agent mechanic neither two thus
agents would receive bundles respectively resulting social welfare
however least one agents non zero probability
starting state value resource bundles involving mechanic would change
drastically would optimal resource allocation social value

avoiding bundle enumeration
avoid enumerating resource bundles non zero value agent two things
required mechanism support concise bidding language allows
agent express preferences auctioneer compact manner ii
agents able good representation preferences language
simple way achieve model create auction agents submit
specifications resource parameterized mdps auctioneer bids language
compact given assumption agent formulate
mdp require additional computation agents however
changes communication protocol agents auctioneer similarly
concise bidding languages sandholm nisan boutilier hoos
boutilier simply moves burden solving valuation
agents auctioneer lead gains computational
efficiency mechanism implications information privacy issues
agents reveal local mdps auctioneer might want
nevertheless build idea increase efficiency solving
valuation winner determination keeping agents
mdp information private address ways maintaining information privacy next
section moment focus improving computational complexity agents
valuation auctioneers winner determination
question pose section follows given bid agent consists mdp resource information capacity bounds hs pm rm
bm
auctioneer formulate solve winner determination efficiently


fidolgov durfee

simply enumerating agents resource bundles solving standard integer
program exponential number binary variables
therefore goal auctioneer joint policy collection single agent
policies weak coupling assumption maximizes sum expected total
discounted rewards agents conditions agent assigned set
resources violates capacity bound
bm e agent assigned resources
carry ii total amounts resources assigned agents exceed
global resource bounds b e cannot allocate agents resources
available expressed following mathematical program
x
max
um




subject
x
x

c h

bm c


x

c c






h

x




b







obviously decision version np complete subsumes singleagent mdp capacity constraints np completeness shown section
moreover remains np complete even absence single agent capacity
constraints indeed global constraint amounts shared resources sufficient
make np complete shown straightforward reduction
knapsack similar one used single agent case section
linearize similarly single agent section yielding
following milp simply multiagent version recall assumption
section resource requirements binary
xxx
max
xm rm
x







subject
x
xx
xm
xm pm


x







c
bm c

c c




x



b





x

x





x

xm





xm









x maxo xm upper bound argument h
used normalization single agent case bound guaranteed exist
discounted mdps easy obtain
p

p



firesource allocation among agents mdp induced preferences

milp allows auctioneer solve wdp without enumerate
possible resource bundles compared standard wdp formulation
order binary variables binary variables
exponential reduction attained exploiting knowledge agents mdp
valuations simultaneously solving policy optimization resource allocation given worst case solution time milps exponential number
integer variables reduction significant impact worst case performance
mechanism average case running time reduced drastically demonstrated
experiments presented section
example apply mechanism discussed running example alternative straightforward combinatorial auction presented example winnerdetermination milp look follows continuous occupation measure variables xm binary variables
conservation flow constraints involve continuous
variables well c constraints
involve binary variables
capacity constraints agents exactly single agent case described
example global resource constraints
ot ot



om om

notice example one binary decision variable per resource per agent
yielding variables simple exponentially fewer
number binary variables straightforward ca formulation example
requires one binary variable per resource bundle per agent yielding variables
given milps np complete number integer variables
reduction variables noticeable even small one
lead drastic speedup larger domains

mechanism described instantiation gva well known
properties vcg mechanisms auction strategy proof agents incentive
lie auctioneer mdps attains socially optimal resource allocation
agent decreases utility participating auction
sum section agents submit mdp information auctioneer instead valuations resource bundles essentially
removed computational burden agents time significantly simplified auctioneers winner determination number integer variables
wdp reduced exponentially
distributing winner determination
unlike straightforward combinatorial auction implementation discussed earlier section agents shared computational burden auctioneer
mechanism section agents submit information auctioneer
idle waiting solution suggests potential improvements
computational efficiency indeed given complexity milps would beneficial


fidolgov durfee

exploit computational power agents offload computation
auctioneer back agents assume agents cost helping
would prefer outcome computed faster thus would distribute
computation winner determination common objective distributed algorithmic mechanism design feigenbaum shenker parkes shneidman

concreteness base section branch bound
method solving milps wolsey exactly techniques work
milp e g cutting planes perform search space lp
relaxations milp branch bound milps binary variables lp relaxations created choosing binary variable setting relaxing
integrality constraints binary variables solution lp relaxation happens integer valued provides lower bound value global solution
non integer solution provides upper bound current subproblem combined
lower bounds used prune search space
thus simple way auctioneer distribute branch bound
simply farm lp relaxations agents ask solve lps however
easy see mechanism strategy proof indeed agent tasked
performing computation determining optimal resource allocation
associated payments could benefit lying outcome computation
auctioneer common phenomenon distributed mechanism implementations
whenever wdp calculations offloaded agent participating auction
agent might able benefit sabotaging computation several methods
ensuring strategy proofness distributed implementation best
suited idea redundant computation parkes shneidman
multiple agents asked task disagreement
carefully punished discourage lying rest section demonstrate
easy implement case
basic idea simple let auctioneer distribute lp relaxations agents
check solutions solve agents return incorrect solutions
would make truthful computation weakly dominant strategy agents
nonzero punishment used achieve strong dominance strategy
auctioneer removes incentive agents lie yields exactly solution
centralized however order beneficial complexity
checking solution must significantly lower complexity solving
fortunately true lps
suppose auctioneer solve following lp written two
equivalent ways let us refer one left primal one right
observed parkes shneidman assumption bit controversial since desire
efficient computation implies nonzero cost computation agents cost helping
modeled nonetheless common assumption distributed mechanism implementations
describe one simple way distributing mechanism others possible
redundant computation discussed parkes shneidman context ex post nash
equilibria whereas interested dominant strategies high level idea similar



firesource allocation among agents mdp induced preferences

dual
min v

max rt x

subject



subject



ax

v r

x

strong duality property primal lp solution v dual
solution x v rt x furthermore given solution primal lp easy
compute solution dual complementary slackness vt rt b x b
b square invertible matrix composed columns correspond basic
variables solution
well known properties used auctioneer quickly check optimality
solutions returned agents suppose agent returns v solution
primal lp auctioneer calculate dual solution vt rt b check whether
rt x v thus expensive operation auctioneer perform
inversion b done sub cubic time matter fact
implementation perspective would efficient ask agents return
primal dual solutions since many popular compute process
solving lps
thus provided simple method allows us effectively distribute
winner determination maintaining strategy proofness mechanism
negligible computation overhead auctioneer
preserving information privacy
mechanism discussed far drawback requires agents
reveal complete information mdps auctioneer
exacerbated distributed wdp previous section since
agent reveal mdp information auctioneer information
spread agents via lp relaxations global milp
alleviate
let us note saying agents prefer reveal local information
implicitly assuming external factor affects agents utilities
captured agents mdps sensible way measure value information
changes ones decision making process outcomes since effect part
model fact contradicts weak coupling assumption cannot domainindependent manner define constitutes useful information bad
agent reveal much mdp modeling effects carefully analyzing
interesting task outside scope thus
purposes section content mechanism hides enough information
make impossible auctioneer agent uniquely determine transition
reward function agent fact information revealed agent map
infinitely many mdps agents many transformations possible
present one illustrate concept
stringent condition would require agents preferences resource bundles revealed
parkes set lower bar



fidolgov durfee

main idea modify previous mechanism agents
submit private information auctioneer encrypted form allows
auctioneer solve winner determination allow infer
agents original mdps
first note instead passing mdp auctioneer agent submit
equivalent lp question becomes agent transform lp
way auctioneer able solve able infer transition
reward functions originating mdp words reduces
following given lp l created mdp hs p r via need
transformation l l solution transformed lp l uniquely
map solution original lp l l reveal transition reward
functions original mdp p r simple change variables suffices
suppose agent mdp originated lp going ask agent solve
order maintain linearity keep simple solve
limit linear transformations consider linear invertible transformation
primal coordinates u f v linear invertible transformation dual coordinates
dx lp transformed applying f switching
dual applying equivalent lp coordinates
max rt
subject
f ad f




value optimal solution value optimal solution
given optimal solution easy compute solution
original x indeed perspective dual primal transformation f
equivalent linear transformation dual equality constraints ax given
f non singular effect solution objective function furthermore
dual transformation equivalent change variables modifies solution
value objective function
however transformations gives away indeed
agent able simply read set multiplicative constants transformation constraints therefore diagonal matrices positive
coefficients equivalent stretching coordinate system trivially deduced since map choosing negative multiplier xi
inverting axis pointless flips non negativity constraints yi
immediately revealing sign
let us demonstrate given mdp corresponding lp l
choose f impossible determine coefficients l
equivalently original transition reward functions p r agent
receives l knows l created mdp columns
constraint matrix original lp l must sum constant
x
x
aji
p

j





firesource allocation among agents mdp induced preferences


p
r


p
r






p
r


p
r


p
r


p
r

p
r


p
r


p
r






p
r


p
r




p
r


p
r






p
r


p
r

b

figure preserving privacy example two different mdps lead lp
constraint matrix

gives system nonlinear equations diagonal arbitrary f
total free parameters everything degenerate
cases easily handled appropriate choice f equations
hugely constrained infinitely many solutions matter fact
sacrificing free parameters choose f way
columns constraints l sum constant would
effect transforming l l corresponds another valid mdp therefore
given l infinitely many original mdps transformations f
map lp l
consider connection resource capacity costs agents occupation measures global wdp two things auctioneer
able determine value agents policy able maximize
social welfare ii determine resource requirements policies check
resource constraints question transformation affect
noted earlier transformation change objective function first
requirement holds hand change occupation measure xm
arbitrary multipliers however multiplicative factor xm effect usage
non consumable resources matters whether corresponding xm zero
step function h nullifies scaling effect thus second condition holds
example consider two state mdp depicted figure represents decisionmaking sales company two states corresponding possible market
conditions two actions two possible sales strategies market conditions state
much favorable state rewards actions higher
transitions two states correspond probabilities market conditions changing
rewards reflect expected profitability two states obtaining numbers
realistic scenario would require performing costly time consuming
company might want make information public
therefore company participate resource allocation mechanism described would want encrypt mdp submitting auctioneer



p
r

fidolgov durfee

mdp following reward function
r
following transition function




p




p











corresponds following conservation flow constraint matrix








submitting lp auctioneer agent applies following transformations






diag f

yielding following constraint matrix









f ad





however constraint matrix corresponds non transformed conservation
flow constraint different mdp shown figure b following
reward function
r

following transition function



p




p








therefore auctioneer receives constraint matrix way knowing whether agent mdp transition function transformed
mdp transition function transformed notice
dynamics two mdps vary significantly transition probabilities state
connectivity second mdp reveal information originating mdp
corresponding market dynamics

sum large extent maintain information privacy mechanism
allowing agents apply linear transformations original lps information
revealed mechanism consists agents resource costs capacity bounds

bm c sizes state action spaces latter hidden adding
dummy states actions mdp
revealed information used infer agents preferences resource requirements numeric policies revealed lack information transition
reward functions renders information worthless illustrated example
could multiple originating mdps different properties


firesource allocation among agents mdp induced preferences

experimental
section present empirical analysis computational complexity
resource allocation mechanism described section report computational complexity mechanism section agents submit
mdps auctioneer simultaneously solves resource allocation policyoptimization far additional speedup achieved distributing wdp
described section report empirical since well established
parallel programming literature parallel versions branch bound milp
solvers consistently achieve linear speedup eckstein phillips hart due
fact branch bound require little inter process communication
experiments implemented multiagent delivery
multiagent rover domain dolgov durfee agents operate
stochastic grid world delivery locations randomly placed throughout grid
delivery task requires set resources limited quantities resources
random delivery locations grid location set deliveries
accepts resource size requirements capacity cost delivery agent
bounded space hold resources limited capacity agents participate
auction bid delivery resources setting value resource depends
resources agent acquires deliveries make given
bundle resources agents policy optimization optimal delivery
plan exact parameters used experiments critical trends seen
presented sake reproducibility domain described
detail appendix c resource costs experiments presented
binary
computational complexity constrained optimization vary greatly
constraints tightened relaxed therefore first step analysis empirical
computational complexity mechanism investigate running time depends
capacity constraints agent bounds total amounts
resources shared agents common types constrained optimization
constraint satisfaction natural expect wdp milp
easy solve constrained capacity
resource bounds empirically verify varied local capacity constraint levels
meaning agents cannot use resources meaning agent capacity
use enough resources execute optimal unconstrained policy well global
constraint levels meant resources available agents
meant enough resources assign agent desired resource
bundle experiments part milp solver played cplex
pentium machine gb ram ram bottleneck due use
sparse matrix representations typical running time profile shown figure
easy constrained becomes difficult constraints
relaxed abruptly becomes easy capacity resource levels start
utopia
investigated randomly generated domains qualitatively



fidolgov durfee




local constraint level



sec











local constraints
















global constraints





global constraint level





figure running time mdp winner determination milp different levels global b
local b
constraints constraint levels fractions
utopian levels needed implement optimal unconstrained policies
involved agents operating grid shared
resource types data point shown average ten runs randomlygenerated

following experiments aim avoid easy regions constraint levels
therefore given complexity profiles set constraint levels local
capacity global resource bounds set discount factor
value chosen arbitrarily investigations effect value
running time milp revealed significant trends
begin comparing performance mdp auction section
performance straightforward ca flat preferences described section
summarized figure compares time takes solve
standard winner determination space resource bundles
time needed solve combined mdp wdp used mechanism
number resources increased agents grid despite fact
exponential worst case running time number integer
variables exponentially larger milp effect clearly
demonstrated figure furthermore comparison gives extremely optimistic
view performance standard ca take account additional
complexity valuation requires formulating solving large
number mdps one per resource bundle hand latter embedded
wdp mechanism thus including time solving valuation
comparison would magnify effect fact experiments time
required solve mdps valuation significantly greater
time solving resulting wdp milp however present quantitative
effect difference implementation iterating resource
bundles solving mdps done via straightforward implementation matlab


firesource allocation among agents mdp induced preferences

figure gains computation efficiency mdp wdp versus wdp straightforward ca implementation latter include time solving
mdps compute resource bundle values error bars standard
deviation ten runs
n










sec



















number agents





figure scaling mdp winner determination milp agents agents
operated grids shared types resources

milps solved highly optimized cplex code parallelization wdp
performed experiments
analyze performance larger infeasible
straightforward ca figure illustrates scaling effect number agents
participating auction increased point plot corresponds
single run experiment less ten runs performed every value
parameters solid line mean recall size wdp scales linearly


fidolgov durfee

n

n














sec

sec


























number resource types
















number resource types



b

n






sec


























number resource types



c



figure c scaling mdp winner determination milp
number resources three sets different grid sizes n
different numbers agents linear scale plot tail data
c

number agents graph therefore reflects rather standard scaling effect
np complete seen plot agents
resource types well within reach method average taking around
minutes
next analyze method scales number resource types figure
shows solution time function number resource types three different
sets number actions scaled linearly number
resource types action required constant number resources e number


firesource allocation among agents mdp induced preferences

n





sec













resources per action



figure complexity mdp winner determination milp function
number actions resource requirements

nonzero per action constant two regardless total number resource
types exhibit interesting trait wherein running time peaks
relatively low numbers resource types falls quickly increases much
slowly number resource types increases illustrated figure uses
linear scale due fact total number resource types
much higher number resources required action less contention
particular resource among agents one agents actions therefore
become relatively constrained solution time increases slowly
better illustrate effect ran set experiments inverse ones shown
figure kept total number resource types constant increased number
resource types required action shown figure running time
profile similar observed earlier varied local global constraints
total number resources per action low high overconstrained relatively easy solve complexity increases significantly
number resources required resource range total
number resource types
would expect actions resource requirements increased
total number resource types would scale gracefully
figure example figure illustrates running time number
resources required action scales linearly total number resources
complexity increase significantly faster however unreasonable assume
many domains number actions fact increase total
number resource types involved indeed natural assume total number
resource types increases becomes complicated number
tasks agent perform increases however resource requirements
action increase well delivery agent running example acquires ability


fidolgov durfee

n










sec


























number resource types



figure complexity actions resource requirements grow proportionally total
number resource types number resource types needed action
total number resource types

deliver pizza might need resources perform actions related activity
one would expect resource requirements delivering furniture appliances
change therefore believe many real applications method scale
gracefully total number resource types
experiments illustrate point domains agents preferences defined underlying markov decision processes resource allocation
mechanism developed lead significant computational advantages
shown figure method successfully applied large
argue well beyond reach combinatorial resource allocation mechanisms flat
preferences experiments figure even small combinatorial
resource allocation mechanisms flat preferences time consuming attempts empirically evaluate simpler mechanisms larger proved futile
instance method takes one minute solve standard
ca requires agents enumerate bundles auctioneer solve
np complete input size

generalizations extensions conclusions
many possible extensions generalizations work presented
briefly outline several
treatment focused resource allocation among
self interested agents apply cooperative mdps weaklyinteracting agents cooperative setting concept resources viewed
compact way model inter agent constraints inability include combinations joint actions policies weakly coupled mdps agents


firesource allocation among agents mdp induced preferences

independent transition reward functions certain combinations joint actions
feasible widely used model agents interactions e g singh cohn
model resource centric direct certainly possible example agents use sat formulas describe valid combinations joint actions case
easily handled via simple modifications single multiagent milps
indeed sat formula expressed set linear inequalities
binary variables multiagent case directly added
corresponding milp see case non binary resources appendix b milp
defined indicators instead used binary case
mentioned previously work extended handle consumable resources
used whenever agents execute actions fact conditions
considerably simplified domains kinds resources
important change redefine value particular resource bundle
agent difficulty given policy total use consumable resources
uncertain definition value resource bundle becomes ambiguous one
possibility define value bundle payoff best policy whose expected
resource usage exceed amounts resources bundle interpretation
would change mean amount resource consumed action
every time executed would make constraints linear occupation
measure would tremendously simplify wdp making polynomial
analogous used constrained mdps altman shwartz briefly
described earlier section information privacy handled similarly case
non consumable resources however given transformation dx resource cost
function scaled since total consumption consumable
resources proportional occupation measure additional benefit
hiding resource cost functions unlike case non consumable resources
revealed detailed treatment model consumable resources
presented work dolgov including discussion risk sensitive cases
value resource bundle defined payoff best policy whose probability
exceeding resource amounts bounded
work exploited structure agents preferences stems underlying
policy optimization however latter modeled flat mdps
enumerate possible states actions flat mdps scale well due
curse dimensionality bellman address wdp milp modified
work factored mdps boutilier dearden goldszmidt factored
resource allocation dolgov durfee dual alp
method solving factored mdps developed guestrin method allows us
exploit types structure resource allocation structure agents
preferences induced underlying mdps well structure mdps
resource allocation mechanism discussed assumed one shot allocation
resources static population agents interesting extension work would
consider system agents resources arrive depart dynamically
online mechanism design work parkes singh parkes singh yanovsky
combining mdp model utility functions dynamics online
could valuable thus appears worthwhile direction future work


fidolgov durfee

agent population static periodic allocation resources allowed techniques
phasing used solve resulting wu durfee
summarize presented variant combinatorial auction resource allocation among self interested agents whose valuations resource bundles
defined weakly coupled constrained mdps mechanism
exploits knowledge structure agents mdp preferences achieves
exponential reduction number integer decision variables turn leads
tremendous speedup straightforward implementation confirmed experimental mechanism implemented achieve reduction computational
complexity without sacrificing nice properties vcg mechanism optimal outcomes strategy proofness voluntary participation discussed distributed
implementation mechanism retains strategy proofness fact
lp solution easily verified reveal agents private mdp information
transformation agents mdps
believe solution described significantly
applicability combinatorial resource allocation mechanisms practical utility functions resource bundles defined sequential stochastic
decision making

acknowledgments
thank anonymous reviewers helpful comments well colleagues
satinder singh kang shin michael wellman demothenis teneketsis jianhui wu
jeffrey cox valuable discussions related work
material part upon work supported honeywell international
darpa ipto coordinators program air force laboratory
contract fa c views conclusions contained document authors interpreted representing official
policies expressed implied defense advanced projects agency
u government

appendix proofs
proof theorem
theorem consider finite set n indivisible resources oi n
n available units resource non decreasing utility function
defined resource bundles f n r exists resource constrained mdp
hs p r c
b resource set whose induced utility function
resource bundles f words every resource bundle z n
value optimal policy among whose resource requirements exceed z
call set z f z
f q n r hs p r c
b
h


n
x


z n z max oi h
zi max u f z






z

firesource allocation among agents mdp induced preferences












r f





















r f

r f




r






r f



figure creating mdp resources arbitrary non decreasing utility function
case shown three binary resources transitions deterministic

proof statement shown via straightforward construction mdp
exponential number one per resource bundle states actions present
reduction linear number actions exponential number states choice
due fact although reverse mapping requiring two states exponentially
many actions even straightforward mdp feels somewhat unnatural
given arbitrary non decreasing utility function f corresponding mdp
constructed follows illustrated figure n state space
mdp consists n states one state sz every resource bundle z n
plus sink state

action space mdp aij n j consists mn
actions actions per resource oi n plus additional action
transition function p deterministic defined follows action applicable every state leads sink state every action aij applicable
states sz zi j leads certainty states zi j



aij sz sz zi j zi j
p


otherwise
words aij applies states j units resource leads
state amount ith resource increases j
reward function r defined follows rewards state
action action produces rewards states

f z ao sz z n
r

otherwise
f simple transformation f compensates effects discounting
f z f z


p

zi



fidolgov durfee

p
words takes zi transitions get state sz contribution
total discounted reward exactly f z
resource requirements actions follows action require
resources every action aij requires j units resource oi
finally initial conditions sz meaning agent starts
state corresponds empty resource bundle state figure
capacity costs limits
b used set c
easy see mdp constructed given resource bundle z
policy feasible set z zero probability reaching state sz
z z component furthermore optimal policy set z
transition state sz since f z non decreasing use action thus obtaining
total discounted reward f z

proof theorem
theorem given mdp hs p r c
b resource capacity
constraints exists policy hr feasible solution exists
stationary deterministic policy sd sd feasible expected total reward
sd less
hr sd sd u sd u
proof let us label set actions non zero probability
executed according e

let us construct unconstrained mdp hs p r p r
restricted versions p r action domain limited
p
r r
p p r r
due well known property unconstrained infinite horizon mdps total
expected discounted reward optimization criterion guaranteed optimal
stationary deterministic solution e g theorem puterman label
sd
consider sd potential solution clearly sd feasible solution
actions come set includes actions uses non zero probability
means resource requirements sd greater
indeed
n
n
x
x


max h


sd max max h
aa



aa

aa



first inequality due fact h z z second equality
follows definition


firesource allocation among agents mdp induced preferences




r v u

c z


v u




c z



r




r



r







r



sm


mv u


om
om c zm

r



sm


r



figure reduction knapsack oper cmdp transitions deterministic

furthermore observe sd yields total reward additionally since sd uniformly optimal solution particular optimal
initial conditions constrained mdp therefore sd constitutes feasible
solution whose expected reward greater equal expected reward
feasible policy

proof theorem
theorem following decision np complete given instance mdp
hs p r c
b resources capacity constraints rational number
exist feasible policy whose expected total reward given less
proof shown theorem exists optimal policy
stationary deterministic therefore presence np obvious since
polynomial time guess stationary deterministic policy verify satisfies resource
constraints calculate expected total reward latter done solving
standard system linear markov equations values states
np completeness use reduction knapsack garey
johnson recall knapsack np complete asks
whether given set items z z cost c z value v z
exists subset z z total value items z less

c e
p constant vb
pthe total cost items greater another constant b
c z

b
c

v z

v
b


reduction

illustrated

figure


proceeds


zz
zz
follows
given instance knapsack z let us number items zi
notational convenience instance knapsack create
mdp states sm actions types resources
om single capacity c c
transition function states defined follows every state si
two transitions corresponding actions ai actions lead state
si probability state sm absorbing transitions lead back

reward cost functions defined follows want action ai
corresponds item zi knapsack contribute v zi total discounted


fidolgov durfee

reward hence set immediate reward every action ai v zi given
transition function implies state si reached exactly step ensures
action ai ever executed contribution total discounted reward
v zi v zi action produces reward zero states
resource requirements actions defined follows action ai
needs resource oi e ai oj j set cost resource oi
cost c zi item knapsack null action requires resources
order complete construction set initial distribution
agent starts state probability define decision parameter vb
upper bound single capacity
b b
c
essentially construction allows agent choose action ai every state si
choosing action ai equivalent putting item zi knapsack action
corresponds choice including zi knapsack therefore exists
policy expected payoff less vb uses
b b
c
shared resource exists solution original instance
knapsack


appendix b non binary resource requirements
describe milp formulation capacity constrained single agent optimization arbitrary resource costs r opposed binary costs
assumed main parts corresponding multiagent winnerdetermination non binary equivalent follows immediately
single agent milp
arbitrary resource costs obtain following non binary equivalent optimization occupation measure coordinates
max
x

xx


x r



subject
x
xx
x
x p


x







n
x

c max h
x
b c




c c



x



linearize sum max operators let us observe inequality
n
x


g ui max f z ui g u max f z u g un max f z un
zz

zz

zz

equivalent following system z n linear inequalities
g u f z u g u f z u g un f zn un


z z zn z



firesource allocation among agents mdp induced preferences

applying constraints express original system c nonlinear
constraints max
x

n
x

c max h
x
b c




c c



following system c constraints max removed
x

c ao h

x




x
b c

c c ao ao





notice way eliminating maximization exponentially increases number
constraints expansion enumerates possible actions resource
e enumerates policies resource used action used
action action etc however many resources used
actions cases constraints
q become redundant number
constraints reduced c c ao ao number actions
use resource
linearize heaviside function analogously case binary resource costs
section create binary indicator variable corresponds argument
h tie occupation measure x via linear inequalities difference
non binary resource costs instead
p indicators resources use indicators
actions h x indicator shows whether
action used policy expanding max represent
optimization following milp
max
x

xx


x r



subject
x
xx
x
x p


x







c ao ao
b c

c c ao ao





x

x x





x







p
x max x constant finite upper bound expected number
times action used
p exists discounted mdp example let
x since x x valid occupation measure
mdp discount factor
example let us formulate milp constrained example recall
three resources ot om truck forklift mechanic one capacity


fidolgov durfee

type c c money actions following resource requirements listing
nonzero ones
ot ot ot ot om
resources following capacity costs
ot c c om c
agent limited budget e capacity bound
b c
compute optimal policy arbitrary formulate
milp techniques described binary variables ai
express constraint capacity cost following system
c linear constraints







easy see constraints redundant fact action
requires small subset resources allows us prune many constraints
fact resource used byqmultiple actions ot therefore accordance
earlier discussion need ao constraints




four constraints corresponds case first resource ot used
different action
mentioned earlier set x constraints synchronize
occupation measure x binary indicators combining constraints
q
get milp continuous binary variables c ao
constraints counting last two sets range constraints

finally let us observe expanding resource action sets
represented binary resources domain contains mostly binary
requirements may effective expand non binary resource requirements
augmenting resource set use binary formulation section rather
directly applying general formulation described
create noop action resource costs zero drops
expressions



firesource allocation among agents mdp induced preferences

appendix c experimental setup
appendix details experimental domains constructed delivery
domain agents operating n n grid sharing resource types
used following parameters
resources enable agents carry delivery tasks resource
types delivery actions performing action requires random
subset resources number resources required action
important parameter whose effect complexity discussed section probability
task carried location e uniformly
distributed function action id actions lower ids
rewarding per definition reward function executed
fewer locations
n possible delivery locations randomly placed grid delivery
location assigned set delivery tasks executed single location
used multiple delivery tasks single task carried several
locations assignment tasks locations done randomly
agent actions drive four perpendicular directions
execute one delivery tasks drive actions movement intended
direction probability probability produce change location
movement actions incur negative reward amount depends size
agent agents movement penalty incurred agent
e distributed uniformly function
agents id
execution action corresponding delivery task location
task assigned produces reward moves agent random
location grid location chosen randomly generation thus
known agent transition deterministic induces topology nearby
remote locations attempting execution delivery task incorrect location
change state produces zero reward
agents bid delivery resources types cglob units
resource cglob global constraint level set experiments
described detail section one capacity type size size
requirements making deliveries type capacity limit agent
cloc cloc local constraint level set
experiments described detail section
initial location agent randomly selected uniform distribution
discount factor

references
altman e constrained markov decision processes total cost criteria occupation measures primal lp methods operations



fidolgov durfee

altman e shwartz adaptive control constrained markov chains criteria policies annals operations special issue markov decision
processes
altman e constrained markov decision processes chapman hall crc
bellman r adaptive control processes guided tour princeton university
press
benazera e brafman r meuleau n hansen e continuous resources stochastic domains proceedings nineteenth international
joint conference artificial intelligence ijcai pp
bererton c gordon g thrun auction mechanism design multi robot
coordination thrun saul l scholkopf b eds proceedings conference
neural information processing systems nips mit press
bertsimas tsitsiklis j n introduction linear optimization athena
scientific
boutilier c solving concisely expressed combinatorial auction proceedings eighteenth national conference artificial intelligence aaai
pp
boutilier c dearden r goldszmidt exploiting structure policy construction proceedings fourteenth international joint conference artificial
intelligence ijcai pp
boutilier c hoos h h bidding languages combinatorial auctions proceedings seventeenth international joint conference artificial intelligence
ijcai pp
clarke e h multipart pricing public goods public choice
de vries vohra r v combinatorial auctions survey informs journal
computing
dolgov integrated resource allocation stochastic multiagent
environments ph thesis computer science department university michigan
dolgov durfee e h optimal resource allocation policy formulation loosely coupled markov decision processes proceedings fourteenth
international conference automated scheduling icaps pp

dolgov durfee e h resource allocation among agents preferences
induced factored mdps proceedings fifth international joint conference
autonomous agents multiagent systems aamas hakodate japan
eckstein j phillips c hart w pico object oriented framework parallel
branch bound proceedings workshop inherently parallel
optimization feasibility applications
feigenbaum j shenker distributed algorithmic mechanism design recent
future directions proceedings sixths international workshop


firesource allocation among agents mdp induced preferences

discrete methods mobile computing communications pp
acm press york
feldmann r gairing lucking monien b rode selfish routing
non cooperative networks survey proceedings twenty eights international
symposium mathematical foundations computer science mfcs pp
springer verlag
ferguson nikolaou c sairamesh j yemini economic allocating resources computer systems clearwater ed market control
paradigm distributed resource allocation pp hong kong world
scientific
garey r johnson computers intractability guide theory
np completeness w h freeman co
groves incentives teams econometrica
guestrin c uncertainty complex structured environments
ph thesis computer science department stanford university
heyman p sobel j ii stochastic operations
mcgraw hill york
kallenberg l linear programming finite markovian control math
centrum amsterdam
littman l dean l kaelbling l p complexity solving markov
decision proceedings eleventh annual conference uncertainty
artificial intelligence uai pp montreal
mackie mason j k varian h generalized vickrey auctions tech rep
university michigan
mas colell whinston green j r microeconomic theory oxford
university press york
mcafee r p mcmillan j analyzing airwaves auction journal economic
perspectives
mcmillan j selling spectrum rights journal economic perspectives

meuleau n hauskrecht kim k e peshkin l kaelbling l dean boutilier
c solving large weakly coupled markov decision processes proceedings
fifteenth national conference artificial intelligence aaai pp

nisan n bidding allocation combinatorial auctions electronic commerce
parkes iterative combinatorial auctions achieving economic computational efficiency ph thesis department computer information science
university pennsylvania
parkes c kalagnanam j r eso achieving budget balance
vickrey payment schemes exchanges proc th international joint conference artificial intelligence ijcai pp


fidolgov durfee

parkes c shneidman j distributed implementations vickrey clarkegroves mechanisms proceedings third international joint conference
autonomous agents multi agent systems aamas pp
parkes c singh mdp online mechanism design
proceedings seventeenths annual conference neural information processing
systems nips
parkes c singh yanovsky approximately efficient online mechanism
design proceedings eighteenths annual conference neural information
processing systems nips
puterman l markov decision processes john wiley sons york
ross k chen b optimal scheduling interactive non interactive traffic
telecommunication systems ieee transactions automatic control
ross k varadarajan r markov decision processes sample path constraints communicating case operations
rothkopf h pekec harstad r computationally manageable combinational auctions management science
sandholm boutilier c preference elicitation combinatorial auctions
cramton shoham steinberg eds combinatorial auctions chap mit press
sandholm optimal winner determination combinatorial
auctions proceedings sixteenth international joint conference artificial
intelligence ijcai pp san francisco ca usa morgan kaufmann
publishers inc
sandholm optimal winner determination combinatorial auctions artificial intelligence
shapley l stochastic games proceedings national academy science usa

sheffi combinatorial auctions procurement transportation services
interfaces
singh cohn dynamically merge markov decision processes
jordan kearns j solla eds advances neural information
processing systems vol pp mit press
song j regan combinatorial auctions transportation service procurement carrier perspective transportation record
vickrey w counterspeculation auctions competitive sealed tenders journal
finance
wellman p walsh w e wurman p r mackie mason j k auction
protocols decentralized scheduling games economic behavior
wolsey l integer programming john wiley sons


firesource allocation among agents mdp induced preferences

wu j durfee e h automated resource driven mission phasing techniques
constrained agents proceedings fourth international joint conference
autonomous agents multiagent systems aamas pp




