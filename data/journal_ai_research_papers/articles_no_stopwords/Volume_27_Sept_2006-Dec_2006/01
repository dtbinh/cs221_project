Journal Artificial Intelligence Research 27 (2006) 25-53

Submitted 10/05; published 9/06

Generative Prior Knowledge Discriminative Classification
Arkady Epshteyn
Gerald DeJong

aepshtey@uiuc.edu
dejong@uiuc.edu

Department Computer Science
University Illinois Urbana-Champaign
201 N. Goodwin
Urbana, IL, 61801 USA

Abstract
present novel framework integrating prior knowledge discriminative classifiers. framework allows discriminative classifiers Support Vector Machines
(SVMs) utilize prior knowledge specified generative setting. dual objective
fitting data respecting prior knowledge formulated bilevel program,
solved (approximately) via iterative application second-order cone programming.
test approach, consider problem using WordNet (a semantic database
English language) improve low-sample classification accuracy newsgroup categorization. WordNet viewed approximate, readily available source background
knowledge, framework capable utilizing flexible way.

1. Introduction
SVM (Vapnik, 1995) classification accuracy many classification tasks often
competitive human subjects, number training examples required
achieve accuracy prohibitively large domains. Intelligent user interfaces,
example, must adopt behavior individual user limited amount
interaction order useful. Medical systems diagnosing rare diseases generalize
well seeing examples. natural language processing task performs
processing level n-grams phrases (which frequent translation systems)
cannot expect see sequence words sufficient number times even large
training corpora. Moreover, supervised classification methods rely manually labeled
data, expensive obtain. Thus, important improve classification
performance small datasets. classifiers competitive humans
ability generalize seeing examples. Various techniques
proposed address problem, active learning (Tong & Koller, 2000b; Campbell,
Cristianini, & Smola, 2000), hybrid generative-discriminative classification (Raina, Shen,
Ng, & McCallum, 2003), learning-to-learn extracting common information related
learning tasks (Thrun, 1995; Baxter, 2000; Fink, 2004), using prior knowledge.
work, concentrate improving small-sample classification accuracy
prior knowledge. prior knowledge proven useful classification (Scholkopf,
Simard, Vapnik, & Smola, 2002; Wu & Srihari, 2004; Fung, Mangasarian, & Shavlik, 2002;
Epshteyn & DeJong, 2005; Sun & DeJong, 2005), notoriously hard apply practice
mismatch form prior knowledge employed
classification algorithms (either prior probabilities explicit constraints hypothesis
c
2006
AI Access Foundation. rights reserved.

fiEpshteyn & DeJong

space classifier) domain theories articulated human experts.
unfortunate various ontologies domain theories available abundance,
considerable amount manual effort required incorporate existing prior knowledge
native learning bias chosen algorithm. would take apply
existing domain theory automatically classification task specifically
designed? work, take first steps towards answering question.
experiments, domain theory exemplified WordNet, linguistic
database semantic connections among English words (Miller, 1990). apply WordNet standard benchmark task newsgroup categorization. Conceptually, generative
model describes world works, discriminative model inextricably linked
specific classification task. Thus, reason believe generative interpretation
domain theory would seem natural generalize better across different
classification tasks. Section 2 present empirical evidence is, indeed,
case WordNet context newsgroup classification. reason, interpret
domain theory generative setting. However, many successful learning algorithms
(such support vector machines) discriminative. present framework allows
use generative prior discriminative classification setting.
algorithm assumes generative distribution data given
Bayesian framework: P rob(data|model) prior P rob0 (model) known. However,
instead performing Bayesian model averaging, assume single model
selected a-priori, observed data manifestation model (i.e.,
drawn according P rob(data|M )). goal learning algorithm estimate
. estimation performed two-player sequential game full information.
bottom (generative) player chooses Bayes-optimal discriminator function f (M )
probability distribution P rob(data|model = ) (without taking training data
account) given model . model chosen top (discriminative) player
way prior probability occurring, given P rob0 (M ), high, forces
bottom player minimize training-set error Bayes-optimal discriminator
f (M ). estimation procedure gives rise bilevel program. show that,
problem known NP-hard, approximation solved efficiently iterative
application second-order cone programming.
remaining issue construct generative prior P rob0 (model) automatically domain theory. describe solve problem Section 2,
argue generative setting appropriate capturing expert knowledge, employing WordNet illustrative example. Section 3, give necessary
preliminary information important known facts definitions. framework incorporating generative prior discriminative classification described detail Section
4. demonstrate efficacy approach experimentally presenting results
using WordNet newsgroup classification Section 5. theoretical explanation
improved generalization ability discriminative classifier constrained generative
prior knowledge appears Section 6. Section 7 describes related work. Section 8 concludes
paper outlines directions future research.
26

fiGenerative Prior Knowledge Discriminative Classification

2. Generative vs. Discriminative Interpretation Domain Knowledge
WordNet viewed network, nodes representing words links representing
relationships two words (such synonyms, hypernyms (is-a), meronyms (partof), etc.). important property WordNet semantic distance - length
(in links) shortest path two words. Semantic distance approximately
captures degree semantic relatedness two words. set experiment
evaluate usefulness WordNet task newsgroup categorization. posting
represented bag-of-words, binary feature representing presence
corresponding word. evaluation done pairwise classification tasks
following two settings:
1. generative framework assumes posting x = [x1 , .., xn ] generated
distinct probability distribution newsgroup. simplest version
Linear Discriminan Analysis (LDA) classifier posits x|(y = 1) N ( 1 , I)
x|(y = 1) N (2 , I) posting x given label {1, 1}, R(nn)
identity matrix. Classification done assigning probable label
x: y(x) = 1 P rob(x|1) > P rob(x| 1). well-known (e.g. see Duda, Hart, &
Stork, 2001) decision rule equivalent one given hyperplane
c1 , ..,
cn ] estimated via
(2 1 )T x 21 (T2 2 T1 1 ) > 0. means bi = [


1
maximum likelihood training data [x1 , y1 ], .., [xm , ym ] .

2. discriminative SVM classifier sets separating hyperplane directly minimize
number errors training data:
c1 , .., w
cn ], bb] = arg minw,b kwk s.t. yi (wT xi + b) 1, = 1, .., m.
[w
b = [w

experiment conducted learning-to-learn framework (Thrun, 1995; Baxter,
2000; Fink, 2004). first stage, classifier trained using training data
training task (e.g., classifying postings newsgroups atheism guns).
second stage, classifier generalized using WordNets semantic information.
third stage, generalized classifier applied different, test task (e.g., classifying
postings newsgroups atheism vs. mideast) without seeing data new
classification task. way classifier generalize setting use
original sample acquire information WordNet, exploit information
help label examples test sample. learning perform task,
system learns utilize classification knowledge implicit WordNet.
describe second third stages two classifiers detail:

1. intuitive interpret information embedded WordNet follows: title
newsgroup guns, words semantic distance
gun (e.g., artillery, shooter, ordnance distance two) provide
similar degree classification information. quantify intuition, let li,train =
j
1
n
[li,train
, .., li,train
, .., li,train
] vector semantic distances WordNet
feature word j label training task newsgroup {1, 2}. Define
1. standard LDA classifier assumes x|(y = 1) N (1 , ) x|(y = 1) N (2 , )
estimates covariance matrix well means 1 , 2 training data. experiments,
take = I.

27

fiEpshteyn & DeJong

1)Train: atheism vs. guns
2)Train: atheism vs. guns
3)Train: guns vs. mideast
Test: atheism vs. mideast
Test: guns vs. mideast
Test: atheism vs. mideast
1

1

0.9

1

0.9

0.9

0.8

0.8

0.8

0.7

0.7

0.7

0.6

0.6

0.6

0.5

0.5

0.5
0

200 400 600 800 1000 1200 1400 1600 1800

0

200 400 600 800 1000 1200 1400 1600 1800

0

200 400 600 800 1000 1200 1400 1600 1800

Legend:

Generative
Discriminative

Figure 2.1: Test set accuracy percentage versus number training points 3
different classification experiments. classification task, random test
set chosen full set articles 20 different ways. Error bars
based 95% confidence intervals.

P

(v) ,

c
j
j
=v
i,train
j
=v|
|j:li,train
j:l

, = 1, 2, | | denotes cardinality set. compresses

information bi based assumption words equidistant newsgroup
label equally likely appear posting newsgroup. test
performance compressed classifier new task semantic distances given
j
). Notice
li,test , generative distributions reconstructed via ji := (li,test
classifier trained tested task, applying function
equivalent averaging components means generative distribution
corresponding equivalence classes words equidistant label.
classifier tested different classification task, reconstruction process reassigns
averages based semantic distances new labels.
2. less intuitive interpret WordNet discriminative setting. One possible
interpretation coefficients w j separating hyperplane governed
semantic distances labels, captured compression function 0 (v, u) ,
P

cj

w
j
j
=u
=v,l
2,train
1,train
j
j
|j:l1,train
=v,l2,train
=u|
j:l

j
j
reconstructed via w j := 0 (l1,test
, l2,test
).

Note LDA generative classifier SVM discriminative classifier
hypothesis space separating hyperplanes. resulting test set classification
accuracy classifier classification tasks 20-newsgroup dataset
28

fiGenerative Prior Knowledge Discriminative Classification

(Blake & Merz, 1998) presented Figure 2.1. x-axis graph represents
size training task sample, y-axis - classifiers performance test
classification task. generative classifier consistently outperforms discriminative
classifier. converges much faster, two three tasks discriminative classifier
able use prior knowledge nearly effectively generative classifier even
seeing 90% available training data. generative classifier
consistent performance - note error bars much smaller
discriminative classifier. results clearly show potential using background
knowledge vehicle sharing information tasks. effective sharing
contingent appropriate task decomposition, supplied tuned generative
model.
evidence Figure 2.1 seemingly contradicts conventional wisdom discriminative training outperforms generative sufficiently large training samples. However,
experiment evaluates two frameworks context using ontology transfer
information learning tasks. never done before. experiment demonstrates interpretation semantic distance WordNet intuitive
generative classification setting, probably better reflects human intuitions
behind WordNet.
However, goal construct classifier performs well without seeing
examples test classification task. want classifier improves
behavior sees new labeled data test classification task. presents us
problem: one best-performing classifiers (and certainly best text
classification task according study Joachims, 1998) SVM, discriminative
classifier. Therefore, rest work, focus incorporating generative prior
knowledge discriminative classification framework support vector machines.

3. Preliminaries
observed constraints probability measure half-space
captured second-order cone constraints Gaussian distributions (see, e.g., tutorial
Lobo, Vandenberghe, Boyd, & Lebret, 1998). allows efficient processing
constraints within framework second-order cone programming (SOCP). intend
model prior knowledge elliptical distributions, family probability distributions
generalizes Gaussians. follows, give brief overview second-order
cone programming relationship constraints imposed Gaussian probability
distribution. note possible extend argument presented Lobo et
al. (1998) elliptical distributions.
Second-order cone program mathematical program form:
min v x

(3.1)

x

s.t. kAi x + bi k cTi x + di , = 1, ..., N

(3.2)

x Rn optimization variable v Rn , Ai R(ki xn) , bi Rki , ci Rn ,
di R problem parameters (kk represents usual L2 -norm paper). SOCPs
solved efficiently interior-point methods, described Lobo et al. (1998)
tutorial contains excellent overview theory applications SOCP.
29

fiEpshteyn & DeJong

use elliptical distribution model distribution data a-priori. Elliptical
distributions distributions ellipsoidally-shaped equiprobable contours. density
function n-variate elliptical distribution form f,,g (x) = c(det )1 g((x
)T 1 (x )), x Rn random variable, Rn location parameter,
R(nxn) positive definite (n n)-matrix representing scale parameter, function
g() density generator, c normalizing constant. use notation X E(, , g) denote random variable X elliptical distribution
parameters , , g. Choosing appropriate density generator functions g, Gaussian
distribution, Student-t distribution, Cauchy distribution, Laplace distribution,
logistic distribution seen special cases elliptical distribution. Using elliptical distribution relaxes restrictive assumptions user make
imposing Gaussian prior, keeping many desirable properties Gaussians, as:
1. X E(, , g), R(kn) , B Rk , AX + B E(A + B, AAT , g)
2. X E(, , g), E(X) = .
3. X E(, , g), V ar(X) = g , g constant depends
density generator g.
following proposition shows elliptical distributions, constraint P (w x+b
0) (i.e., probability X takes values half-space {w x + b 0} less
) equivalent second-order cone constraint 21 :
Proposition
3.1. X E(, , g), P rob(w x + b 0) 12 equivalent (w +
1/2
b)/g, w , g, constant depends g .
Proof. proof identical one given Lobo (1998) Lanckriet et al. (2001)
Gaussian distributions provided completeness:
Assume P rob(w x + b 0) .

(3.3)

Let u = w x+b. Let u denote mean u, denote variance. constraint
3.3 written
uu
u
(3.4)
P rob( ) .





properties elliptical distributions, u = w + b, = g 1/2 w , uu




)
E(0, 1, g). Thus, statement 3.4 expressed P robXE(0,1,g) (X w +b
1/2 w
k
gk

, equivalent w +b
1 (), (z) = P robXE(0,1,g) (X z).
1/2 w
k
gk

proposition follows g, = g 1 ().

Proposition 3.2. monotonically decreasing g, P robXE(,,g) (x) equivalent


1/2 (x ) g,c, , g,c,, = g 1 ( ||
c ) constant depends
g, c, , .
Proof. Follows directly definition P robXE(,,g) (x).
30

fiGenerative Prior Knowledge Discriminative Classification

4. Generative Prior via Bilevel Programming
deal binary classification task: classifier function f (x) maps
instances x Rn labels {1, 1}. generative setting, probability densities
P rob(x|y = 1; 1 ) P rob(x|y = 1; 2 ) parameterized = [1 , 2 ] provided (or
estimated data), along prior probabilities class labels (y = 1)
(y = 1), Bayes optimal decision rule given classifier
f (x|) = sign(P rob(x|y = 1; 1 )(y = 1) P rob(x|y = 1; 2 )(y = 1)),
sign(x) := 1 x 0 1 otherwise. LDA, instance, parameters 1
2 means two Gaussian distributions generating data given label.
Informally, approach incorporating prior knowledge straightforward: assume
two-level hierarchical generative probability distribution model. low-level probability
distribution data given label P rob(x|y; ) parameterized , which, turn,
known probability distribution P rob0 (). goal classifier estimate
values parameter vector training set labeled points [x 1 , y1 ]...[xm , ym ].
estimation performed two-player sequential game full information.
bottom (generative) player, given , selects Bayes optimal decision rule f (x|).
top (discriminative) player selects value high probability occurring
(according P rob0 ()) force bottom player select decision rule
minimizes discriminative error training set. give formal
specification training problem formulate bilevel program.
assumptions subsequently relaxed enforce tractability flexibility.
use elliptical distribution E(1 , 1 , g) model X|y = 1, another elliptical
distribution E(2 , 2 , g) model X|y = 1. parameters , , = 1, 2 known,
Bayes optimal decision rule restricted class linear classifiers 2 form
fw,b (x) = sign(w x + b) given f (x) minimizes probability error among
linear discriminants: P rob(error) = P rob(w x + b 0|y = 1)(y = 1) + P rob(w x + b
0|y = 1)(y = 1) = 12 (P robXE(1 ,1 ,g) (wT x + b 0) + P robXE(2 ,2 ,g) (wT x + b 0)),
assuming equal prior probabilities classes. model uncertainty
means elliptical distributions , = 1, 2 imposing elliptical prior distributions
locations means: E(ti , , g), = 1, 2. addition, ensure optimization
problem well-defined, maximize margin hyperplane subject imposed
generative probability constraints:
min kwk

(4.1)

1 ,2

s.t.yi (wT xi + b) 1, = 1, ..,

P robi E(ti ,i ,g) (i ) , = 1, 2

(4.2)
(4.3)




[w, b] solves min[P robXE(1 ,1 ,g) (w x + b 0) + P robXE(2 ,2 ,g) (w x + b 0)]
w,b

(4.4)
bilevel mathematical program (i.e., optimization problem
constraint region implicitly defined another optimization problem), strongly
2. decision rule restricted class classifiers H optimal probability error larger
classifier H (Tong & Koller, 2000a).

31

fiEpshteyn & DeJong

NP-hard even constraints objectives linear (Hansen, Jaumard,
& Savard, 1992). However, show possible solve reasonable approximation problem efficiently several iterations second-order cone programming.
First, relax second-level minimization (4.4) breaking two constraints:
P robXE(1 ,1 ,g) (wT x + b 0) P robXE(2 ,2 ,g) (wT x + b 0) . Thus, instead looking Bayes optimal decision boundary, algorithm looks decision
boundary low probability error, low error quantified choice .
Propositions 3.1 3.2 enable us rewrite optimization problem resulting
relaxation follows :
min kwk

(4.5)

1 ,2 ,w,b

s.t.yi (wT xi + b) 1, = 1, ..,




1/2
(i ti ) , = 1, 2
P robi E(ti ,i ,g) (i ) , = 1, 2

w 1 + b

P robXE(1 ,1 ,g) (wT x + b 0)
1/2
1 w

w 2 + b

P robXE(2 ,2 ,g) (wT x + b 0)
1/2
2 w

(4.6)
(4.7)
(4.8)

(4.9)

Notice form program depend generator function g
elliptical distribution - constants depend it. defines far system
willing deviate prior choice generative model, bounds
tail probabilities error (Type Type II) system tolerate assuming
chosen generative model correct. constants depend specific generator
g amount error user willing tolerate. experiments, select
values constants optimize performance. Unless user wants control
probability bounds constants, sufficient assume a-priori
probability distributions (both prior hyper-prior) elliptical, without making
commitments.
algorithm solves problem repeating following two steps:
1. Fix top-level optimization parameters 1 2 . step combines objectives maximizing margin classifier training data ensuring
decision boundary (approximately) Bayes optimal respect given
generative probability densities specified 1 , 2 .
2. Fix bottom-level optimization parameters w, b. Expand feasible region
program step 1 function 1 , 2 . step fixes decision boundary
pushes means generative distribution far away boundary
constraint (4.7) allow.
steps repeated convergence (in practice, convergence detected
optimization parameters change appreciably one iteration next).
step algorithm formulated second-order cone program:
32

fiGenerative Prior Knowledge Discriminative Classification

Step 1. Fix 1 2 . Removing unnecessary constraints mathematical
program pushing objective constraints, get following SOCP:
min

(4.10)

w,b

s.t. kwk

(4.11)

yi (wT xi + b) 1, = 1, ..,

(4.12)

wT

1+b


1/2
1 w

(4.13)

w 2 + b


1/2
2 w

(4.14)

Step 2. Fix w, b expand span feasible region, measured

w 1 +b .
1/2
1 w


w 2 +b
1/2
2 w



Removing unnecessary constraints, get:
w 2 + b w 1 + b


max
1/2
1 ,2 1/2
2 w
1 w



1/2
(i ti ) , = 1, 2
s.t.

(4.15)
(4.16)

behavior algorithm illustrated Figure 4.1.
following theorems state algorithm converges.
Theorem
4.1. Suppose
n
algorithm produces sequence iterates


(t) (t)
(t)
(t)
, quality iterate evaluated margin w(t) .
1 , 2 , w , b
t=0
evaluation function converges.
(t)

(t)

(t)

(t)

Proof. Let 1 , 2 values prior location parameters, w1 , b1
minimum error hyperplane algorithm finds end t-th step. end
(t+1) (t+1)
(t + 1)-st step, w1
, b1
still feasible region t-th step SOCP.
(t) )T

(t)
2 +b
1/2 (t)
w

2

true function f ( (w

(t) )T

(t)
1 +b
1/2 (t)
w

1

, (w

)=

(w(t) )T 2 +b(t)
1/2 (t)
2 w



(w(t) )T 1 +b(t)
1/2 (t)
1 w

monotonically increasing one arguments argument fixed,
(t+1) (t+1)
fixing 1 (or 2 ) fixes exactly one argument. solution 1
, 2
end
(t+1)

(t + 1)-st step
(t+1)

fixing 1

(t)


(t)
(w(t)
+b

) 2
1/2 (t)
2 w

< , f could increased

(t)

using value 2 beginning step ensures

(t) )T
(t)
(w
2 +b

1/2 (t)
2 w

, contradicts observation f maximized end
(t+1)

second step. contradiction reached


(t)
(w(t)
+b

) 1
1/2 (t)
1 w

< . Since

minimum error hyperplane previous
iteration feasible region start

(t)


must decrease monotonically one iteration
next iteration, objective w
next. Since bounded zero, algorithm converges.
33

fiEpshteyn & DeJong

1)

2)

5

5

4

4

3

3

2

2

1

1

0

0

1
1

0

1

2

3

4

5

1
1

0

1

2

3

3)
5

4

4

3

3

2

2

1

1

0

0

0

5

4)

5

1
1

4

1

2

3

4

5

1
1

0

1

2

3

4

5

Figure 4.1: Steps iterative (hard-margin) SOCP procedure:
(The region hyperprior probability larger shaded prior
distribution. covariance matrices represented equiprobable elliptical contours.
example, covariance matrices hyperprior prior distributions
multiples other. Data points two different classes represented diamonds
squares.)
1. Data, prior, hyperprior algorithm executed.
2. Hyperplane discriminator end step 1, iteration 1
3. Priors end step 2, iteration 1
4. Hyperplane discriminator end step 2, iteration 2
algorithm converges end step 2 problem (step 3 move
hyperplane).
addition convergence objective function, accumulation points
sequence iterates characterized following theorem:
n

(t) (t)
Theorem 4.2. accumulation points sequence 1 , 2 , w(t) , b(t) (i.e., limiting
points convergent subsequences) feasible descent directions original
optimization problem given (4.5)-(4.9).
Proof. See Appendix A.
34

fiGenerative Prior Knowledge Discriminative Classification

point feasible descent directions, sufficiently small step along
directional vector either increase objective function, leave unchanged, take
algorithm outside feasible region. set points feasible descent directions
subset set local minima. Hence, convergence point somewhat
weaker result convergence local minimum.
practice, observed rapid convergence usually within 2-4 iterations.
Finally, may want relax strict assumptions correctness prior/linear
separability data introducing slack variables optimization problem above.
results following program:
min

1 ,2 ,w,b,i ,1 ,2 ,1 ,2

kwk + C1


X

+ C2 (1 + 2 ) + C3 (1 + 2 )

(4.17)

i=1

s.t.yi (wT xi + b) 1 , = 1, ..,


1/2

(i ti ) + , = 1, 2


w 1 + b
1/2
1 w 1




w 2 + b
1/2
2 w 2

0, = 1, ..,
0, = 1, 2

0, = 1, 2

(4.18)
(4.19)
(4.20)
(4.21)
(4.22)
(4.23)
(4.24)

before, problem solved two-step iterative SOCP procedure.
Imposing generative prior soft constraints ensures that, amount training
data increases, data overwhelms prior algorithm converges maximummargin separating hyperplane.

5. Experiments
experiments designed demonstrate usefulness proposed approach
incorporation generative prior discriminative classification, address
broader question showing possible use existing domain theory aid
classification task specifically designed. order construct
generative prior, generative LDA classifier trained data training
classification task estimate Gaussian location parameters bi , = 1, 2, described
Section 2. compression function (v) subsequently computed (also described
j
Section 2), used set hyperprior parameters via ji := (li,test
), = 1, 2.
order apply domain theory effectively task specifically
designed, algorithm must able estimate confidence decomposition
domain theory respect new learning task. order model uncertainty
applicability WordNet newsgroup categorization, system estimated confidence
homogeneity equivalence classes semantic distances computing variance
35

fiEpshteyn & DeJong

0.85
Bilevel Gen/Discr

0.8
0.75
0.7
0.65
0.6
0.55
0.5
0.5

0.55

0.6

0.65 0.7
SVM

0.75

0.8

0.85

Figure 5.1: Performance bilevel discriminative classifier constrained generative
prior knowledge versus performance SVM. point represents unique
pair training/test tasks, 0.5% test task data used training.
results averaged 100 experiments.

P

random variable (v) follows: (v) ,

j:l

c
(ji (v))2
j
i,train=v
j
|j:li,tran
=v|

. hyperprior confidence

matrices , = 1, 2 reconstructed
respect test task semantic distances

j
(li,test
), k = j
. Identity matrices used
li,test , = 1, 2 follows: [i ]j,k :=
0, k 6= j
covariance matrices lower-level prior: 1 = 2 := I. rest parameters
set follows: := 0.2, := 0.01, C1 = C2 := 1, C3 := . constants
chosen manually optimize performance Experiment 1 (for training task: atheism
vs. guns, test task: guns vs. mideast, see Figure 5.2) without observing data
classification tasks.
resulting classifier evaluated different experimental setups (with different
pairs newsgroups chosen training test tasks) justify following
claims:
1. bilevel generative/discriminative classifier WordNet-derived prior knowledge good low-sample performance, showing feasibility automatically
interpreting knowledge embedded WordNet efficacy proposed
algorithm.
2. bilevel classifiers performance improves increasing training sample size.
3. Integrating generative prior discriminative classification framework results
better performance integrating prior directly generative
framework via Bayes rule.
36

fiGenerative Prior Knowledge Discriminative Classification

4. bilevel classifier outperforms state-of-the-art discriminative multitask classifier
proposed Evgeniou Pontil (2004) taking advantage WordNet domain
theory.
order evaluate low-sample performance proposed classifier, four newsgroups
20-newsgroup dataset selected experiments: atheism, guns, middle east,
auto. Using categories, thirty experimental setups created possible
ways assigning newsgroups training test tasks (with pair newsgroups assigned
task, constraint training test pairs cannot identical) 3 .
experiment, compared following two classifiers:
1. bilevel generative-discriminative classifier knowledge transfer functions
(v), (v), = 1, 2 learned labeled training data provided training task (using 90% available data task). resulting prior
subsequently introduced discriminative classification framework via approximate bilevel programming approach
2. vanilla SVM classifier minimizes regularized empirical risk:
min

w,b,i


X
i=1

+ C1 kwk2

s.t.yi (wT xi + b) 1 , = 1, ..,

(5.1)
(5.2)

classifiers trained 0.5% available data test classification
task4 , evaluated remaining 99.5% test task data. results, averaged
one hundred randomly selected datasets, presented Figure 5.1, shows
plot accuracy bilevel generative/discriminative classifier versus accuracy
SVM classifier, evaluated thirty experimental setups. points
lie 45o line, indicating improvement performance due incorporation prior
knowledge via bilevel programming framework. amount improvement ranges
10% 30%, improvements statistically significant 5%
level.
next experiment conducted evaluate effect increasing training data
(from test task) performance system. experiment, selected
three newsgroups (atheism, guns, middle east) generated six experimental setups
based possible ways splitting newsgroups unique training/test pairs.
addition classifiers 1 2 above, following classifiers evaluated:
3. state-of-the art multi-task classifier designed Evgeniou Pontil (2004).
classifier learns set related classification functions ft (x) = wtT x + bt classification tasks {training task, test task} given m(t) data points [x1t , y1t ], .., [xm(t)t , ym(t)t ]
3. Newsgroup articles preprocessed removing words could interpreted nouns
WordNet. preprocessing ensured one part WordNet domain theory exercised
resulted virtually reduction classification accuracy.
4. SeDuMi software (Sturm, 1999) used solve iterative SOCP programs.

37

fiEpshteyn & DeJong

task minimizing regularized empirical risk:
min

w0 ,wt ,bt ,it

X
X m(t)


i=1

+

C1 X
kwt w0 k2 + C1 kw0 k2
C2

s.t. yit (wtT xit + bt ) 1 , = 1, .., m(t),
0, = 1, .., m(t),

(5.3)
(5.4)
(5.5)

regularization constraint captures tradeoff final models w close
average model w0 large margin training data. 90%
training task data made available classifier. Constant C1 := 1 chosen,
C2 := 1000 selected set {.1, .5, 1, 2, 10, 1000, 105 , 1010 } optimize
classifiers performance Experiment 1 (for training task: atheism vs. guns,
test task: guns vs. mideast, see Figure 5.2) observing .05% test task data
(in addition training task data).
4. LDA classifier described Section 2 trained 90% test task data. Since
classifier bottom-level generative classifier used bilevel
algorithm, performance gives upper bound performance bottomlevel classifier trained generative fashion.
Figure 5.2 shows performance classifiers 1-3 function size training
data test task (evaluation done remaining test-task data). results
averaged one hundred randomly selected datasets. performance bilevel
classifier improves increasing training data discriminative portion
classifier aims minimize training error generative prior imposed
soft constraints. expected, performance curves classifiers converge
amount available training data increases. Even though constants used mathematical program selected single experimental setup, classifiers performance
reasonable wide range data sets across different experimental setups,
possible exception Experiment 4 (training task: guns vs. mideast, testing task: atheism
vs. mideast), means constructed elliptical priors much closer
experiments. Thus, prior imposed greater confidence
warranted, adversely affecting classifiers performance.
multi-task classifier 3 outperforms vanilla SVM generalizing data points
across classification tasks. However, take advantage prior knowledge,
classifier does. gain performance bilevel generative/discriminative classifier
due fact relationship classification tasks captured much
better WordNet simple linear averaging weight vectors.
constants involved bilevel classifier generative classifiers Bayesian priors, hard fair comparison classifiers constrained
generative priors two frameworks. Instead, generatively trained classifier 4
gives empirical upper bound performance achievable bottom-level classifier
trained generatively test task data. accuracy classifier shown
horizontal plots Figure 5.2. Since discriminative classification known
superior generative classification problem, SVM classifier outperforms
38

fiGenerative Prior Knowledge Discriminative Classification

1) Train:atheism vs. guns

2) Train:atheism vs. guns

3) Train:guns vs. mideast

Test:atheism vs. mideast

Test:guns vs. mideast

Test:atheism vs. guns

1

1

1

0.95

0.95

0.95

0.9

0.9

0.9

0.85

0.85

0.85

0.8

0.8

0.8

0.75

0.75

0.75

0.7

0.7

0.7

0.65

0.65

0.65

0.6

0.6

0.6

0.55

0.55
0

0

10 20 30 40 50 60 70 80 90 100

4) Train: guns vs. mideast

10

20

30

40

50

60

70

80

90

5) Train: atheism vs. mideast

0.55
0

1

1

1

0.95

0.95

0.9

0.9

0.9

0.85

0.85

0.85

0.8

0.8

0.8

0.75

0.75

0.75

0.7

0.7

0.7

0.65

0.65

0.65

0.6

0.6
0

10

20

30

40

50

60

70

80

90

30

40

50

60

70

80

90

Test:atheism vs. guns

0.95

0.55

20

6) Train: atheism vs. mideast

Test:guns vs. mideast

Test:atheism vs. mideast

10

0.6

0.55

0.55
0

10 20 30 40 50 60 70 80 90 100

0

10

20

30

40

50

60

70

80

90

Legend:

LDA,max performance
Bilevel Gen/Discr
SVM
Multitask SVM

Figure 5.2: Test set accuracy percentage versus number test task training points
two classifiers (SVM Bilevel Gen/Discr) tested six different classification
tasks. classification experiment, data set split randomly
training test sets 100 different ways. error bars based 95%
confidence intervals.

generative classifier given enough data four six experimental setups.
interesting, that, range training sample sizes, bilevel classifier constrained
generative prior outperforms SVM trained sample
generative classifier trained much larger sample four setups. means that,
unless prior knowledge outweighs effect learning, cannot enable LDA classifier
compete bilevel classifier problems.
Finally, set experiments performed determine effect varying mathematical program parameters generalization error. parameter
varied set values, rest parameters held fixed ( increased
maximum feasible value). evaluation done setup Experiment 1 (for
39

fiEpshteyn & DeJong

1) Accuracy function

2) Accuracy function

0.18

0.18

0.16

0.16

0.14

0.14

0.12

0.12

0.1

0.1

0.08

0.08

0.06

0.06

0.04

0.04

0.02

0.02

0

0
0

0.05

0.1

0.15

0.2

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

Figure 5.3: Plots test set accuracy percentage versus mathematical program parameter
values. classification task, random training set size 9 chosen
full set test task articles 100 different ways. Error bars based
95% confidence intervals. experiments performed training
task: atheism vs. guns, test task: guns vs. mideast.

training task:atheism vs. guns, test task: guns vs. mideast), training set size
9 points. results presented Figure 5.3. Increasing value equivalent
requiring hyperplane separator smaller error given prior. Decreasing
value equivalent increasing confidence hyperprior. actions
tighten constraints (i.e., decrease feasible region). good prior knowledge,
effect improving generalization performance small training samples
since prior imposed higher confidence. precisely observe
plots Figure 5.3.

6. Generalization Performance
algorithm generalize well low sample sizes? section, derive
theorem demonstrates convergence rate generalization error
constrained generative-discriminative classifier depends parameters mathematical program margin, would expected case large-margin
classification without prior. particular, show certainty generative prior knowledge increases, upper bound generalization error classifier
constrained prior decreases. increasing certainty prior, mean
either hyper-prior becomes peaked (i.e., confidence locations
prior means increases) desired upper bounds Type Type II probabilities
error classifier decrease (i.e., requirement lower-level discriminative
player choose restricted Bayes-optimal hyperplane strictly enforced).
argument proceeds bounding fat-shattering dimension classifier constrained prior knowledge. fat-shattering dimension large margin classifier
given following definition (Taylor & Bartlett, 1998):
Definition 6.1. set points = {x1 ...xm } -shattered set functions F
mapping domain X R real numbers r 1 , ..., rm that,
b {1, 1}m , function fb F b(fb (xi ) ri ) , = 1..m. say
40

fiGenerative Prior Knowledge Discriminative Classification

r 1 , ..., rm witness shattering. fat-shattering dimension F function
fatF () maps cardinality largest -shattered set S.
Specifically, consider class functions
F = {x w x : kxk R, kwk = 1,

(6.1)





wT (1 )
w 2
1/2


1/2
,




,
(


)
(


)



,



1
1
2
2 }.
1
2
1/2
1/2
1 w
2 w

following theorem bounds fat-shattering dimension classifier:

Theorem 6.2. Let F class a-priori constrained functions defined (6.1),
let min (P ) max (P ) denote minimum maximum eigenvalues matrix P ,
2
2
2 ))
,
respectively. set points -shattered F , |S| 4R ( (1
2
2

2

(1 )
(1 )
2 k (max (2 ))
, kt2ktk(
,
= max(1 , 2 ) 1 = min( min
) 2 = min( min
2
k2 k
k1 k
max (2 )) +kt2 k)
kt1 k2 (max (1 ))2
),
kt1 k((max (1 ))2 +kt1 k)

assuming 0, kti k kti k,

1 ,
2

= 1, 2.

Proof. See Appendix B.
following corollary follows directly Taylor Bartletts (1998)
Theorem 1.5 bounds classifiers generalization error based fat-shattering
dimension:
Corollary 6.3. Let G class real-valued functions. Then, probability least
1 independently generated examples z, classifier h = sgn(g) sgn(G)
2
margin least examples z, error h
(d

8m
)log(32m)
+
log(
))


=
f

(
).

G
=
F


class

functions
log( 8em
G
G


16
2

2

2

defined (6.1), dF 265R (4( 2 (1 ))) . G = F 0 usual class large margin
classifiers (without prior), result (Taylor & Bartlett, 1998) shows F 0
265R2
.
2
2

Notice bounds depend R
. However, bound classifier constrained
2
generative prior depends term 4( 2 (1 2 )). particular, increases, tightening constraints, bound decreases, ensuring, expected,
quicker convergence generalization error. Similarly, decreasing tightens
constraints decreases upper bound generalization error. > 12 ,
factor 4(2 (1 2 )) less 1 upper bound fat-shattering dimension dF
tighter usual bound no-prior case dF 0 .
Since controls amount deviation decision boundary Bayesoptimal hyperplane depends variance hyper-prior distribution, tightening
constraints corresponds increasing confidence prior. Note high
value represents high level user confidence generative elliptical model.
note two ways increasing tightness hyperprior constraint (4.7)
- one user-defined parameter , automatically
estimated covariance matrices , = 1, 2. matrices estimate extent
41

fiEpshteyn & DeJong

equivalence classes defined WordNet create appropriate decomposition domain
theory newsgroup categorization task. Thus, tight constraint (4.7) represents
high level user confidence means generative classification model (estimated
WordNet) good correspondence partition words imposed
semantic distance WordNet elliptical generative model data.
approaches zero approaches highest feasible value, solution bilevel
mathematical program reduces restricted Bayes optimal decision boundary computed
solely generative prior distributions, without using data.
Hence, shown that, prior imposed increasing level confidence
(which means elliptical generative model deemed good, estimates
means good, turn implies domain theory well-suited
classification task hand), convergence rate generalization error classifier
increases. Intuitively, precisely desired effect increased confidence prior
since benefit derived training data outweighed benefit derived
prior knowledge. low data samples, result improved accuracy assuming
domain theory good, plots Figure 5.3 show.

7. Related Work
number approaches combining generative discriminative models. Several focus deriving discriminative classifiers generative distributions (Tong
& Koller, 2000a; Tipping, 2001) learning parameters generative classifiers via
discriminative training methods (Greiner & Zhou, 2002; Roos, Wettig, Grunwald, Myllymaki, & Tirri, 2005). closest spirit approach Maximum Entropy
Discrimination framework (Jebara, 2004; Jaakkola, Meila, & Jebara, 1999), performs
discriminative estimation parameters generative model, taking account constraints fitting data respecting prior. One important difference
framework that, estimating parameters, maximum entropy discrimination minimizes distance generative model prior, subject satisfying
discriminative constraint training data classified correctly given margin.
framework, hand, maximizes margin training data subject
constraint generative model far prior. emphasis
maximizing margin allows us derive a-priori bounds generalization error
classifier based confidence prior (yet) available maximum entropy framework. Another difference approach performs classification
via single generative model, maximum entropy discrimination averages set
generative models weighted probabilities. similar distinction
maximum-a-posteriori Bayesian estimation repercussions tractability. Maximum entropy discrimination, however, general framework sense
allowing richer set behaviors based different priors.
Ng et al. (2003, 2001) explore relative advantages discriminative generative
classification propose hybrid approach improves classification accuracy
low-sample high-sample scenarios. Collins (2002) proposes use Viterbi
algorithm HMMs inferencing (which based generative assumptions), combined
discriminative learning algorithm HMM parameter estimation. research
42

fiGenerative Prior Knowledge Discriminative Classification

directions orthogonal work since explicitly consider question
integration prior knowledge learning problem.
context support vector classification, various forms prior knowledge
explored. Scholkopf et al. (2002) demonstrate integrate prior knowledge
invariance transformations importance local structure kernel function.
Fung et al. (2002) use domain knowledge form labeled polyhedral sets augment
training data. Wu Srihari (2004) allow domain experts specify confidence
examples label, varying effect example separating hyperplane
proportionately confidence. Epshteyn DeJong (2005) explore effects rotational constraints normal separating hyperplane. Sun DeJong (2005)
propose algorithm uses domain knowledge (such WordNet) identify relevant
features examples incorporate resulting information form soft constraints
hypothesis space SVM classifier. Mangasarian et al. (2004) suggest use prior
knowledge support vector regression. approaches, prior knowledge takes
form explicit constraints hypothesis space large-margin classifier.
work, emphasis generating constraints automatically domain knowledge
interpreted generative setting. demonstrate WordNet application,
generative interpretation background knowledge intuitive natural language
processing problems.
Second-order cone constraints applied extensively model probability constraints robust convex optimization (Lobo et al., 1998; Bhattacharyya, Pannagadatta, &
Smola, 2004) constraints distribution data minimax machines (Lanckriet
et al., 2001; Huang, King, Lyu, & Chan, 2004). work, far know, first one
models prior knowledge constraints. resulting optimization problem
connection Bayes optimal classification different approaches
mentioned above.
work related empirical Bayes estimation (Carlin & Louis, 2000). empirical Bayes estimation, hyper-prior parameters generative model estimated
using statistical estimation methods (usually maximum likelihood method moments)
marginal distribution data, approach learns parameters
discriminatively using training data.

8. Conclusions Future Work.
Since many sources domain knowledge (such WordNet) readily available, believe
significant benefit achieved developing algorithms automatically applying
information new classification problems. paper, argued generative paradigm interpreting background knowledge preferable discriminative
interpretation, presented novel algorithm enables discriminative classifiers
utilize generative prior knowledge. algorithm evaluated context complete system which, faced newsgroup classification task, able estimate
parameters needed construct generative prior domain theory, use
construction achieve improved performance new newsgroup classification tasks.
work, restricted hypothesis class linear classifiers. Extending
form prior distribution distributions elliptical and/or looking
43

fiEpshteyn & DeJong

Bayes-optimal classifiers restricted expressive class linear separators
may result improvement classification accuracy non linearly-separable domains.
However, obvious approximate expressive form prior knowledge
convex constraints. kernel trick may helpful handling nonlinear problems,
assuming possible represent optimization problem exclusively terms
dot products data points constraints. important issue requires
study.
demonstrated interpreting domain theory generative setting
intuitive produces good empirical results. However, usually multiple ways
interpreting domain theory. WordNet, instance, semantic distance
words one measure information contained domain theory. Other,
complicated, interpretations might, example, take account types links
path words (hypernyms, synonyms, meronyms, etc.) exploit commonsense observations WordNet words closer category label
likely informative words farther away. Comparing multiple ways
constructing generative prior domain theory and, ultimately, selecting one
interpretations automatically fruitful direction research.

Acknowledgments
authors thank anonymous reviewers valuable suggestions improving paper. material based upon work supported part National Science Foundation
Award NSF IIS 04-13161 part Information Processing Technology Office Defense Advanced Research Projects Agency award HR0011-05-1-0040.
opinions, findings, conclusions recommendations expressed publication
authors necessarily reflect views National Science
Foundation Defense Advanced Research Projects Agency.

Appendix A. Convergence Generative/Discriminative Algorithm
Let map H : Z Z determine algorithm that, given point (0) , generates se
quence (t) t=0 iterates iteration (t+1) = H((t) ). iterative algorithm
(t)

(t)

Section 4 generates sequence iterates (t) = [1 , 2 ] Z applying following
map H:
H = H 2 H1 :
(A.1)
step 1, H1 ([1 , 2 ]) = arg

min

[w,b]U ([1 ,2 ])

kwk ,

set U ([1 , 2 ]) defined constraints:


(A.2)
(A.3)

yi (w xi + b) 1 0, = 1, ..,

(A.4)

c1 (w, b; 2 , 2 ) 0


wT +b
.
conic constraints cs (w, b; , ) ,
k1/2 wk

(A.6)

c1 (w, b; 1 , 1 ) 0

44

(A.5)

fiGenerative Prior Knowledge Discriminative Classification

step 2, H2 (w, b) = arg

min

(1 ,2 )V

(c1 (w, b; 1 , 1 ) + c1 (w, b; 2 , 2 ))

(A.7)

set V given constraints
o(1 ; 1 , t1 ) 0

(A.8)

o(2 ; 2 , t2 ) 0

(A.9)



o(; , t) , 1/2 ( t) .
Notice H1 H2 functions minima optimization problems
(4.10)-(4.14) (4.15)-(4.16) unique. case Step 1 optimizes
strictly convex function convex set, Step 2 optimizes linear non-constant function
strictly convex set.
Convergence objective function ((t) ) , min[w,b]U ([(t) ,(t) ]) kwk algorithm
1
2
shown Theorem 4.1. Let denote set points map H
change value objective function, i.e. (H( )) = ( ).
show every accumulation point {(t) } lies . show every point
[1 , 2 ] augmented [w , b ] = H1 ([1 , 2 ]) point feasible descent
directions optimization problem (4.5)-(4.9), equivalently expressed as:
min kwk s.t.[1 , 2 ] V ; [w, b] U ([1 , 2 ])

1 ,2 ,w,b

(A.10)

order formally state result, need concepts duality theory.
Let constrained optimization problem given
min f (x) s.t. ci (x) 0, = 1, .., k
x

(A.11)

following conditions, known Karush-Kuhn-Tucker(KKT) conditions necessary
x local minimum:
Proposition A.1. x local minimum (A.11), 1 , .., k
P
1. f (x ) = ki=1 ci (x )
2. 0 {1, .., k}

3. ci (x ) 0 {1, .., k}
4. ci (x ) = 0 {1, .., k}
1 , .., k known Lagrange multipliers constraints c1 , .., ck .
following well-known result states KKT conditions sufficient x
point feasible descent directions:
Proposition A.2. 1 , .., k following conditions satisfied x :
P
1. f (x ) = ki=1 ci (x )
45

fiEpshteyn & DeJong

2. 0 {1, .., k}
x feasible descent directions problem (A.11)
Proof. (sketch) reproduce proof given textbook Fletcher (1987). proposition true P
feasible direction vector s, sT ci (x) 0 x


{1, .., k}. Hence, f (x ) = ki=1 sT ci (x ) 0, descent direction.
following lemma characterizes points set :

Lemma A.3. Let , let [w , b ] = H1 ( ) optimizer ( ), let
= [(A.4),1 , .., (A.4),m , (A.5) , (A.6) ] set Lagrange multipliers corresponding
constraints solution [w , b ]. Define 0 = H( ), let [w 0 , b0 ] optimizer
(0 ). 02 6= 2 , (A.6) = 0 . 01 6= 1 , (A.5) = 0 .
01 6= 1 02 6= 2 , (A.6) = (A.5) = 0 .
Proof. Consider case
02 6= 2

(A.12)

01 = 1

(A.13)


Since , kw0 k = kw k. Let 0 set Lagrange multipliers corresponding
constraints solution [w 0 , b0 ]. Since w still feasible optimization problem
given (0 ) (by argument Theorem 4.1) minimum problem
unique, happen
[w0 , b0 ] = [w , b ].
(A.14)
[w , b ] 0 must satisfy KKT conditions (0 ). (A.12) implies
c1 (w ; 02 , 2 ) > c1 (w ; 2 , 2 ) argument Theorem 4.1, means
that, KKT condition (4) (0 ),
0(A.6) = 0.

(A.15)

Therefore, KKT condition (1) (0 ) (A.15), [w, b, 1 , 2 ] = [w = w0 , b =
b0 , 1 = 01 , 2 ]
"
"
"
#
#
#



c1 (w,b ;1 ,1 )
c1 (w,b ;2 ,2 )
kwk
X

x


w
+ 0(A.5) c1 (ww
=
0(A.4),i
+ 0(A.6) c1 (ww
,
,b; , )
kwk
,b;2 ,2 )
1
1
yi
b

b

i=1

b

means KKT conditions (1),(2) optimization problem ( ) satisfied
0
point [w , b ] = . KKT condition (3) satisfied feasibility [w , b ]
KKT condition (4) satisfied condition (0 ) observations (A.13),
(A.14), (A.15).
proofs two cases (02 = 2 , 01 6= 1 02 6= 2 , 01 6= 1 )
analogous.
following theorem states points KKT points (i.e., points
KKT conditions satisfied) optimization problem given (A.10).
46

fiGenerative Prior Knowledge Discriminative Classification

Theorem A.4. let [w , b ] = H1 ( ), [w , b , 1 , 2 ] KKT point
optimization problem given (A.10).
Proof. Let 0 = H( ). Lemma A.3, consider case
02 6= 2 ,

(A.16)

01 = 1 (A.6) = 0 (by Lemma A.3).

(A.17)

(the proofs two cases similar).
KKT conditions H2 (w , b ), 1 = 01


(o(1 ; 1 , t))
c1 (w , b ; 1 , 1 )
= 0A.8
0A.8 0.
1
1

(A.18)

KKT conditions H1 ( ) (A.17), [w, b] = [w , b ]
"

kwk
w
kwk
b

#

=


X
i=1

(A.4),i



yi x
yi



+

(A.5)

"

c1 (w,b ;1 ,1 )
w
c1 (w ,b;1 ,1 )
b

#








(A.4),1
..
(A.4),m
(A.5)





0.


(A.19)

(A.16),(A.17),(A.18), (A.19), [w, b, 1 , 2 ] = [w , b , 1 = 01 , 2 ]


c1 (w,b ; ,1 )
kwk


kwk
1

x
w


w
kwk
w
,b; , )


c
(w
1
1
X
1
yi
b 0



+

=
kwk =
b

+


(A.5)
(A.4),i 0
0

c1 (w ,b ;1 ,1 )


1
i=1
1
kwk
0
0
0
2








c1 (w,b ;2 ,2 )
0
0
w

c1 (w ,b;2 ,2 )




0
0


+
,
b
0A.8 (A.5)
+ (A.6)
(o(
;
,t))
1 1
(A.6)




0


0
1
(o(2 ;2 ,t))
c1 (w ,b ;2 ,2 )
0
2

2

means KKT conditions (1),(2) optimization problem (A.10) satisfied
00
point [w , b , 1 , 2 ] = [(A.4),1 , .., (A.4),m , (A.5) , (A.6) , 0A.8 (A.5) , (A.6) ].
00

satisfies KKT conditions (3),(4) assumption (A.17) KKT conditions
H1 H2 .
order prove convergence properties iterates (t) , use following theorem
due Zangwill (1969):
Theorem A.5. Let map H : Z Z determine iterative algorithm via (t+1) =
H((t) ), let () denote objective function, let set points
map H change value objective function, i.e. (H()) = ().
Suppose
47

fiEpshteyn & DeJong

1. H uniformly compact Z, i.e. compact subset Z0 Z
H() Z0 Z.
2. H strictly monotonic Z , i.e. (H()) < ().
3. H closed Z , i.e. wi w H(wi ) , = H(w).
accumulation points sequence (t) lie .
following proposition shows minimization continuous function feasible
set continuous map functions argument forms closed function.
Proposition A.6. Given
1. real-valued continuous function f B,
2. point-to-set map U : 2B continuous respect Hausdorff metric:5
dist(X, ) , max(d(X, ), d(Y, X)), d(X, ) , maxxX minyY kx yk,
define function F : B
F (a) = arg min f (a, b0 ) = {b : f (a, b) < f (a, b0 ) b0 U (a)},
b0 U (a)

assuming minimum exists unique. Then, function F closed a.
Proof. proof minor modification one given Gunawardana Byrne
(2005). Let {a(t) } sequence
a(t) a, F (a(t) ) b

(A.20)

function F closed F (a) = b. Suppose case, i.e. b 6= F (a) =
arg minb0 U (a) f (a, b0 ). Therefore,
b = arg min f (b0 ) f (a, b) > f (a, b)
b0 U (a)

(A.21)

continuity f (, ) (A.20),
f (a(t) , F (a(t) )) f (a, b)

(A.22)

continuity U () (A.20),
dist(U (a(t) ), U (a)) 0 b(t) b b(t) U (at ), t.

(A.23)

(A.22), (A.23), (A.21) imply
K f (a(t) , F (a(t) )) > f (a(t) , b(t) ), > K

(A.24)

contradiction since assumption, F (a(t) ) = arg minb0 U (at ) f (b0 ) (A.24),
b(t) U (a(t) ).
5. point-to-set map U (a) maps point set points. U (a) continuous respect distance
metric dist iff a(t) implies dist(U (a(t) ), U (a)) 0.

48

fiGenerative Prior Knowledge Discriminative Classification

Proposition A.7. function H defined (A.1)-(A.7) closed.
Proof. Let {(t) } sequence (t) . Since iterates (t) lie
closed feasible region bounded constraints (4.6)-(4.9) boundary U ()
piecewise linear , boundary U ((t) ) converges uniformly boundary U ( )
(t) , implies Hausdorff distance boundaries converges
zero. Since Hausdorff distance convex sets equal Hausdorff distance
boundaries, dist(U ((t) ), U ( )) converges zero. Hence, proposition
A.6 implies H1 closed. proposition implies H2 closed. composition
closed functions closed, hence H closed.
prove main result Section:
Theorem 4.2. Let H function defined (A.1)-(A.7) determines generative/discriminative algorithm via (t+1) = H((t) ). accumulation points
sequence (t) augmented [w , b ] = H1 ( ) feasible descent directions
original optimization problem given (4.5)-(4.9).
Proof. proof verifying H satisfies properties Theorem A.5. Closedness
H shown Proposition A.7. Strict monotonicity ((t) ) shown Theorem
4.1. Since iterates (t) closed feasible region bounded constraints (4.6)(4.9), H uniformly compact Z. Since accumulation points lie ,
KKT points original optimization problem Theorem A.4, and, therefore,
feasible descent directions Proposition A.2.

Appendix B. Generalization Generative/Discriminative Classifier
need auxiliary results proving Theorem 6.2. first proposition bounds
angle rotation two vectors w1 , w2 distance angle
rotation vectors reference vector v sufficiently small:
Proposition B.1. Let kw1 k = kw2 k = kvk = 1. w1T v 0 w2T v 0,
1. w1T w2 22 1
p
2. kw1 w2 k 2 (1 2 )

Proof.

1. triangle inequality, arccos(w1T w2 ) arccos(w1T v) + arccos(w2T v) 2 arccos()
(since angle two vectors distance measure). Taking cosines
sides using trigonometric equalities yields w1T w2 22 1.
2. Expand kw1 w2 k2 = kw1 k2 + kw2 k2 2w1T w2 = 2(1 w1T w2 ). Since w1T w2 22 1
part 1, kw1 w2 k2 4(1 2 ).

next proposition bounds angle rotation two vectors
far away measured L2 -norm distance:
49

fiEpshteyn & DeJong

Proposition B.2. Let ktk = , k tk .

tT
ktkkk



2 2
(+ ) .

Proof. Expanding k tk2 = ktk2 + kk2 2tt using k tk2 2 , get
1 ktk
2 ( kk

kk
ktk

2

tT
ktkkk



+
ktkkk ). use triangle inequality ktk k tk kk
ktk + k tk + simplify.

following proposition used bound angle rotation normal
w separating hyperplane mean vector hyper-prior distribution:
wT
kwkkk
ktk2 2
ktk(+ktk) ).

Proposition B.3. Let
= min(,

0 k tk ktk.

wT
kwkktk

(22 1),

Proof. Follows directly Propositions B.1 (part 1) B.2.
prove Theorem 6.2, relies parts well-known proof fatshattering dimension bound large margin classifiers derived Taylor Bartlett
(1998).
Theorem 6.2. Let F class a-priori constrained functions defined 6.1,
let min (P ) max (P ) denote minimum maximum eigenvalues matrix P ,
2
2
2 ))
respectively. set points -shattered F , |S| 4R ( (1
,
2
2

2

(1 )
(1 )
2 k (max (2 ))
, kt2ktk(
,
) 2 = min( min
= max(1 , 2 ) 1 = min( min
2
k2 k
k1 k
max (2 )) +kt2 k)
kt1 k2 (max (1 ))2
),
kt1 k((max (1 ))2 +kt1 k)

assuming 0, kti k kti k,

1 ,
2

= 1, 2.



Proof. First, use inequality min (P ) kwk P 1/2 w max (P ) kwk relax
constraints
w 2
w 2


min (2 )
(B.1)
1/2
kwk
2 w



1/2

= max (2 ).
(B.2)
2 (2 t2 ) k2 t2 k
min (1
2 )



1/2
wT 1

constraints imposed second prior 1/2 , 1 (1 t1 ) relaxed

similar fashion produce:

2 w

wT (1 )
min (1 )
kwk

(B.3)

k1 t1 k max (1 )

(B.4)

Now, show assumptions made statement theorem hold,
2
2
2
P
P
every subset satisfies k (S S0 )k 4R ( 2(1 ) .
Assume -shattered F . argument used Taylor Bartlett (1998)
Lemma 1.2 shows that, definition fat-shattering, exists vector w 1

X
X
w1 (

(S S0 )) |S| .
(B.5)
50

fiGenerative Prior Knowledge Discriminative Classification

Similarly (reversing labeling S0 S1 S0 ), exists vector w2
X
X
w2 ( (S S0 )
) |S| .
(B.6)
Hence, (w1 w2 )(
implies

P



P

(S S0 )) 2 |S| , which, Cauchy-Schwartz inequality,

2 |S|
P
kw1 w2 k P
k (S S0 )k

(B.7)

constraints classifier represented B.1 B.2 imply Proposition B.3
w1T t2
w2T t2
2
2
kw1 kkt2 k (21 1) kw2 kkt2 k (22 1) . Now, applying Proposition B.1 (part 2)
simplifying, get
q
kw1 w2 k 4

12 (1 12 ).

Applying analysis constraints B.3 B.4, get
q
kw1 w2 k 4 22 (1 22 ).
Combining B.7, B.8, B.9, get
X

X
|S|



(S S0 ) p

2 2 (1 2 )

(B.8)

(B.9)

(B.10)

defined statement theorem.
Taylor Bartletts (1998) Lemma 1.3 proves, using probabilistic method,
satisfies
X
p
X


(B.11)

(S S0 ) |S|R.

Combining B.10 B.11 yields |S|

4R2 (2 (12 ))
.
2

References
Baxter, J. (2000). model inductive bias learning. Journal Artificial Intelligence
Research, 12, 149198.
Bhattacharyya, C., Pannagadatta, K. S., & Smola, A. (2004). second order cone programming formulation classifying missing data. NIPS.
Blake,
C.,
&
Merz,
C.
(1998).
20
newsgroups
http://people.csail.mit.edu/people/jrennie/20newsgroups/..

database,

Campbell, C., Cristianini, N., & Smola, A. (2000). Query learning large margin classifiers. Proceedings Seventeenth International Conference Machine Learning.
Carlin, B., & Louis, T. (2000). Bayes Empirical Bayes Methods Data Analysis.
Chapman Hall.
Collins, M. (2002). Discriminative training methods hidden markov models: Theory
experiments perceptron algorithms. Proceedings 2002 Conference
Empirical Methods Natural Language Processing.
51

fiEpshteyn & DeJong

Duda, R., Hart, P., & Stork, D. (2001). Pattern Classification. John Wiley. 2nd edition.
Epshteyn, A., & DeJong, G. (2005). Rotational prior knowledge svms. Proceedings
Sixteenth European Conference Machine Learning.
Evgeniou, T., & Pontil, M. (2004). Regularized multi-task learning. Proceedings
Tenth ACM SIGKDD International Conference Knowledge Discovery Data
Mining.
Fink, M. (2004). Object classification single example utilizing class relevance metrics.
Advances Neural Information Processing Systems.
Fletcher, R. (1987). Practical Methods Optimization. John Wiley Sons, West Sussex,
England.
Fung, G., Mangasarian, O., & Shavlik, J. (2002). Knowledge-based support vector machine
classifiers. Advances Neural Information Processing Systems.
Greiner, R., & Zhou, W. (2002). Structural extension logistic regression: Discriminative
parameter learning belief net classifiers. Proceedings Eighteenth National
Conference Artificial Intelligence.
Gunawardana, A., & Byrne, W. (2005). Convergence theorems generalized alternating
minimization procedures. Journal Machine Learning Research, 6, 20492073.
Hansen, P., Jaumard, B., & Savard, G. (1992). New branch-and-bound rules linear bilevel
programming. SIAM Journal Scientific Statistical Computing, 13, 11941217.
Huang, K., King, I., Lyu, M. R., & Chan, L. (2004). minimum error minimax probability
machine. Journal Machine Learning Research, 5, 12531286.
Jaakkola, T., Meila, M., & Jebara, T. (1999). Maximum entropy discrimination. Advances
Neural Information Processing Systems.
Jebara, T. (2004). Machine Learning: Discriminative Generative. Kluwer Academic
Publishers.
Joachims, T. (1998). Text categorization support vector machines: learning many
relevant features. Proceedings Tenth European Conference Machine Learning.
Lanckriet, G. R. G., Ghaoui, L. E., Bhattacharyya, C., & Jordan, M. I. (2001). Minimax
probability machine. Advances Neural Information Processing Systems.
Lobo, M. S., Vandenberghe, L., Boyd, S., & Lebret, H. (1998). Applications second-order
cone programming. Linear Algebra Applications, 284 (13), 193228.
Mangasarian, O., Shavlik, J., & Wild, E. (2004). Knowledge-based kernel approximation.
Journal Machine Learning Research.
Miller, G. (1990). WordNet: online lexical database. International Journal Lexicography, 3 (4).
Ng, A. Y., & Jordan, M. I. (2001). discriminative vs. generative classifiers: comparison
logistic regression naive bayes. Advances Neural Information Processing
Systems.
52

fiGenerative Prior Knowledge Discriminative Classification

Raina, R., Shen, Y., Ng, A. Y., & McCallum, A. (2003). Classification hybrid generative/discriminative models. Advances Neural Information Processing Systems.
Roos, T., Wettig, H., Grunwald, P., Myllymaki, P., & Tirri, H. (2005). discriminative
bayesian network classifiers logistic regression. Machine Learning, 59, 267296.
Scholkopf, B., Simard, P., Vapnik, V., & Smola, A. (2002). Prior knowledge support
vector kernels. Advances kernel methods - support vector learning.
Sturm, J. F. (1999). Using SeDuMi 1.02, MATLAB toolbox optimization symmetric cones. Optimization Methods Software, 11, 625653.
Sun, Q., & DeJong, G. (2005). Explanation-augmented svm: approach incorporating
domain knowledge svm learning. Proceedings Twenty Second International Conference Machine Learning.
Taylor, J. S., & Bartlett, P. (1998). Generalization performance support vector machines
pattern classifiers. Advances kernel methods: support vector learning.
Thrun, S. (1995). learning n-th thing easier learning first?. Advances
Neural Information Processing Systems.
Tipping, M. E. (2001). Sparse bayesian learning relevance vector machine. Journal
Machine Learning Research, 1, 211244.
Tong, S., & Koller, D. (2000a). Restricted bayes optimal classifiers. Proceedings
Seventeenth National Conference Artificial Intelligence.
Tong, S., & Koller, D. (2000b). Support vector machine active learning applications
text classification. Proceedings Seventeenth International Conference
Machine Learning.
Vapnik, V. (1995). Nature Statistical Learning Theory. Springer-Verlag.
Wu, X., & Srihari, R. (2004). Incorporating prior knowledge weighted margin support
vector machines. Proceedings Tenth ACM SIGKDD International Conference
Knowledge Discovery Data Mining.
Zangwill, W. (1969). Convergence conditions nonlinear programming algorithms. Management Science, 16, 113.

53


