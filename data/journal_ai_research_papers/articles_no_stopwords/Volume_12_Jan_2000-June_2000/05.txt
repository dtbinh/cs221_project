Journal Artificial Intelligence Research 12 (2000) 149198

Submitted 11/99; published 3/00

Model Inductive Bias Learning
Jonathan Baxter

J ONATHAN .BAXTER @ ANU . EDU . AU

Research School Information Sciences Engineering
Australian National University, Canberra 0200, Australia

Abstract
major problem machine learning inductive bias: choose learners hypothesis space large enough contain solution problem learnt, yet small
enough ensure reliable generalization reasonably-sized training sets. Typically bias
supplied hand skill insights experts. paper model automatically
learning bias investigated. central assumption model learner embedded
within environment related learning tasks. Within environment learner sample
multiple tasks, hence search hypothesis space contains good solutions
many problems environment. certain restrictions set hypothesis
spaces available learner, show hypothesis space performs well sufficiently
large number training tasks perform well learning novel tasks environment. Explicit bounds derived demonstrating learning multiple tasks within
environment related tasks potentially give much better generalization learning single
task.

1. Introduction
Often hardest problem machine learning task initial choice hypothesis space;
large enough contain solution problem hand, yet small enough ensure
good generalization small number examples (Mitchell, 1991). suitable bias
found, actual learning task often straightforward. Existing methods bias generally
require input human expert form heuristics domain knowledge (for example,
selection appropriate set features). Despite successes, methods
clearly limited accuracy reliability experts knowledge extent
knowledge transferred learner. Thus natural search methods
automatically learning bias.
paper introduce analyze formal model bias learning builds upon
PAC model machine learning variants (Vapnik, 1982; Valiant, 1984; Blumer,
Ehrenfeucht, Haussler, & Warmuth, 1989; Haussler, 1992). models typically take
training data
following general form: learner supplied hypothesis space
drawn independently according underlying distribution

. Based information contained , learners goal select hypothesis
minimizing measure
expected loss respect (for example, case squared loss
). models learners
bias represented choice ; contain good solution problem, then,
regardless much data learner receives, cannot learn.
course, best way bias learner supply containing single optimal hypothesis. finding hypothesis precisely original learning problem,



fifi
!"
#%$ '
&("

@



#

)

*
+
#
$
,/.1032 46587 + # 9;:<=?>
) *+ -

c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.





fiBAXTER

PAC model distinction bias learning ordinary learning. put differently,
PAC model model process inductive bias, simply takes hypothesis space
given proceeds there. overcome problem, paper assume instead
faced single learning task, learner embedded within environment
related learning tasks. learner supplied family hypothesis spaces
,
) appropriate entire environment.
goal find bias (i.e. hypothesis space
simple example problem handwritten character recognition. preprocessing stage
identifies removes (small) rotations, dilations translations image character
advantageous recognizing characters. set individual character recognition
problems viewed environment learning problems (that is, set problems
form distinguish characters, distinguish B characters,
on), preprocessor represents bias appropriate problems environment.
likely many currently unknown biases appropriate
environment. would able learn automatically.

DC

B

many examples learning problems viewed belonging environments related problems. example, individual face recognition problem belongs
(essentially infinite) set related learning problems (all individual face recognition problems); set individual spoken word recognition problems forms another large environment,
set fingerprint recognition problems, printed Chinese Japanese character recognition problems, stock price prediction problems on. Even medical diagnostic prognostic
problems, multitude diseases predicted pathology tests, constitute
environment related learning problems.
many cases environments normally modeled such; instead treated
single, multiple category learning problems. example, recognizing group faces would
normally viewed single learning problem multiple class labels (one face
group), multiple individual learning problems. However, reliable classifier
individual face group constructed easily combined produce
classifier whole group. Furthermore, viewing faces environment related
learning problems, results presented show bias learnt good
learning novel faces, claim cannot made traditional approach.
point goes heart model: concerned adjusting learners
bias performs better fixed set learning problems. process fact
ordinary learning richer hypothesis space components labelled bias
able varied. Instead, suppose learner faced (potentially infinite) stream
tasks, adjusting bias subset tasks improves learning performance
future, yet unseen tasks.
Bias appropriate problems environment must learnt sampling
many tasks. single task learnt bias extracted likely specific
task. rest paper, general theory bias learning developed based upon idea
learning multiple related tasks. Loosely speaking (formal results stated Section 2),
two main conclusions theory presented here:

E

Learning multiple related tasks reduces sampling burden required good generalization,
least number-of-examples-required-per-task basis.
150

fiA ODEL NDUCTIVE B IAS L EARNING

E

Bias learnt sufficiently many training tasks likely good learning novel
tasks drawn environment.

second point shows form meta-generalization possible bias learning. Ordinarily, say learner generalizes well if, seeing sufficiently many training examples,
produces hypothesis high probability perform well future examples
task. However, bias learner generalizes well if, seeing sufficiently many training tasks produces hypothesis space high probability contains good solutions novel tasks. Another
term used process Learning Learn (Thrun & Pratt, 1997).
main theorems stated agnostic setting (that is,
necessarily contain
hypothesis space solutions problems environment), give improved
bounds realizable case. sample complexity bounds appearing results stated
terms combinatorial parameters related complexity set hypothesis spaces
available bias learner. Boolean learning problems (pattern classification) parameters
bias learning analogue Vapnik-Chervonenkis dimension (Vapnik, 1982; Blumer et al.,
1989).
application general theory, problem learning appropriate set neuralnetwork features environment related tasks formulated bias learning problem.
case continuous neural-network features able prove upper bounds number
training tasks number examples training task required ensure set features
works well training tasks will, high probability, work well novel tasks drawn

environment. upper bound number tasks scales
measure complexity possible feature sets available learner, upper

number
bound number examples task scales
examples required learn task true set features (that is, correct bias) already
known, number tasks. Thus, case see number related tasks
learnt increases, number examples required task good generalization decays
minimum possible. Boolean neural-network feature maps able show matching
lower bound number examples required per task form.





F JILKMGONPQ

P

F HG
F JIR

G

1.1 Related Work
large body previous algorithmic experimental work machine learning
statistics literature addressing problems inductive bias learning improving generalization
multiple task learning. approaches seen special cases of, least
closely aligned with, model described here, others orthogonal. Without
completely exhaustive, section present overview main contributions. See Thrun
Pratt (1997, chapter 1) comprehensive treatment.

E

Hierarchical Bayes. earliest approaches bias learning come Hierarchical Bayesian
methods statistics (Berger, 1985; Good, 1980; Gelman, Carlin, Stern, & Rubim, 1995).
contrast Bayesian methodology, present paper takes essentially empirical
process approach modeling problem bias learning. However, model using mixture
hierarchical Bayesian information-theoretic ideas presented Baxter (1997a),
similar conclusions found here. empirical study showing utility
hierarchical Bayes approach domain containing large number related tasks given
Heskes (1998).
151

fiE

BAXTER

E

Early machine learning work. Rendell, Seshu, Tcheng (1987) VBMS Variable Bias
Management System introduced mechanism selecting amongst different learning
algorithms tackling new learning problem. STABB Shift Better Bias (Utgoff, 1986) another early scheme adjusting bias, unlike VBMS, STABB
primarily focussed searching bias applicable large problem domains. use
environment related tasks paper may interpreted environment
analogous tasks sense conclusions one task arrived analogy
(sufficiently many of) tasks. early discussion analogy context, see Russell (1989, S4.3), particular observation analogous problems
sampling burden per task reduced.
Metric-based approaches. metric used nearest-neighbour classification, vector
quantization determine nearest code-book vector, represents form inductive bias.
Using model present paper, extra assumptions tasks
environment (specifically, marginal input-space distributions identical
differ conditional probabilities assign class labels), shown
optimal metric distance measure use vector quantization onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998). metric
learnt sampling subset tasks environment, used
distance measure learning novel tasks drawn environment. Bounds
number tasks examples task required ensure good performance novel
tasks given Baxter Bartlett (1998), along experiment metric
successfully trained examples subset 400 Japanese characters used
fixed distance measure learning 2600 yet unseen characters.
similar approach described Thrun Mitchell (1995), Thrun (1996),
neural networks output trained match labels novel task, simultaneously
forced match gradient derivative information generated distance metric
trained previous, related tasks. Performance novel tasks improved substantially
use derivative information.

E

E

Note many adaptive metric techniques used machine learning,
focus exclusively adjusting metric fixed set problems rather learning
metric suitable learning novel, related tasks (bias learning).
Feature learning learning internal representations. adaptive metric techniques,
many approaches feature learning focus adapting features fixed task
rather learning features used novel tasks. One cases features
learnt subset tasks explicit aim using novel tasks
Intrator Edelman (1996) low-dimensional representation learnt set
multiple related image-recognition tasks used successfully learn novel tasks
kind. experiments reported Baxter (1995a, chapter 4) Baxter (1995b),
Baxter Bartlett (1998) nature.
Bias learning Inductive Logic Programming (ILP). Predicate invention refers process ILP whereby new predicates thought useful classification task hand
added learners domain knowledge. using new predicates background domain knowledge learning novel tasks, predicate invention may viewed form
152

fiA ODEL NDUCTIVE B IAS L EARNING

inductive bias learning. Preliminary results approach chess domain reported
Khan, Muggleton, Parson (1998).

E

E

Improving performance fixed reference task. Multi-task learning (Caruana, 1997)
trains extra neural network outputs match related tasks order improve generalization
performance fixed reference task. Although approach explicitly identify
extra bias generated related tasks way used learn novel tasks,
example exploiting bias provided set related tasks improve generalization
performance. similar approaches include Suddarth Kergosien (1990), Suddarth
Holden (1991), Abu-Mostafa (1993).

E

Bias computational complexity. paper consider inductive bias samplecomplexity perspective: learnt bias decrease number examples required
novel tasks good generalization? natural alternative line enquiry runningtime computational complexity learning algorithm may improved training
related tasks. early algorithms neural networks vein contained Sharkey
Sharkey (1993), Pratt (1992).
Reinforcement Learning. Many control tasks appropriately viewed elements sets
related tasks, learning navigate different goal states, learning set
complex motor control tasks. number papers reinforcement learning literature
proposed algorithms sharing information related tasks improve average
generalization performance across tasks Singh (1992), Ring (1995), learning bias
set tasks improve performance future tasks Sutton (1992), Thrun Schwartz
(1995).

1.2 Overview Paper
Section 2 bias learning model formally defined, main sample complexity results
given showing utility learning multiple related tasks feasibility bias learning.
results show sample complexity controlled size certain covering numbers
associated set hypothesis spaces available bias learner, much way
sample complexity learning Boolean functions controlled Vapnik-Chervonenkis
dimension (Vapnik, 1982; Blumer et al., 1989). results Section 2 upper bounds
sample complexity required good generalization learning multiple tasks learning
inductive bias.
general results Section 2 specialized case feature learning neural networks Section 3, algorithm training features gradient descent presented.
special case able show matching lower bounds sample complexity
multiple task learning. Section 4 present concluding remarks directions future
research. Many proofs quite lengthy moved appendices
interrupt flow main text.
following tables contain glossary mathematical symbols used paper.
153

fiBAXTER

Symbol



U

"

Description
Input Space
Output Space
Distribution
(learning task)
Loss function
Hypothesis Space
Hypothesis
Error hypothesis distribution
Training set
Learning Algorithm
Empirical error training set
Set learning tasks
Distribution learning tasks
Family hypothesis spaces
Loss hypothesis space environment
-sample
Empirical loss
Bias learning algorithm
Function induced
Set
Average

Set
Set
Function probability distributions
Set
Pseudo-metric
Pseudo-metric
Covering number
Capacity
Covering number
Capacity
Sequence hypotheses
Sequence distributions
Average loss
Average loss
Set feature maps
Output class composed feature maps
Hypothesis space associated
Loss function class associated
Covering number
Capacity
Pseudo-metric feature maps
Covering number

ST"

#
#
) * + #
V
#
)Y W *X #

Z

)\ *[
P]fi^_
W)*a`
\
V
#b
#
b
#b
#
2 b fifi # c 2 b
#
fifi #Rc b
#
fifi #Rc b
dQb c
bc
# c
fifi #=c b
b
b
TeA
e
e
cb
fA g
f[
e

h Jijfi e f [
e
k Jijfi e c
eA
cb
h Jijfi c b flg

c
Jijfi b
AP b

n
P
g)*
n
\
W)* `

p
psr q
pb
h Jijfi p b f +
pb
k Hijfi p b
pb
ft + 2 uvxw q qzy
h Jijfi f=t + 2 uv{w






U

#
fifi #=c

fifi c

154

qp

q qzy

q

Z

First Referenced
155
155
155
155
155
155
156
156
156
156
157
157
157
158
158
158
159
159
159
159
159
159
159
160
160
160
160
160
160
160
160
163
163
164
164
166
166
166
166
166
166
166
166

fiA ODEL NDUCTIVE B IAS L EARNING

hSymbol

Jijfi f + 2 uv{w8 Description
Covering number
k uv Jijfi

Capacity
}|
Neural network hypothesis space
~ 0
restricted vector
^_
Growth function

Vapnik-Chervonenkis dimension
~
restricted matrix
~ P]fi^_
restricted matrix
Growth function
f PQ
Dimension function
f
Upper dimension function
f c
Lower dimension function cof
n
= g
Optimal performance

f

#
/ #=c Metric
#
#Rc
Average
, ,
c
#
=
#
c

3
Set
/
. > 2c 5
Permutations integer pairs
\j
Permuted \
f `
U

Empirical
metric functions
W)* g
n
Optimal average error

First Referenced
166
166
167
172
172
172
173
173
173
173
173
173
175
179
179
180
182
182
182
185

2. Bias Learning Model
section bias learning model formally introduced. motivate definitions, first
describe main features ordinary (single-task) supervised learning models.
2.1 Single-Task Learning
Computational learning theory models supervised learning usually include following ingredients:

E

input space

E



Ss"
E loss function U$ "s"&D ,
probability distribution

E

hypothesis space

"

output space

,

,

set hypotheses functions

#$ &"

.

example, problem learn recognize images Marys face using neural network,
would set images (typically represented subset
component
pixel intensity), would set
, distribution would peaked images
different faces correct class labels. learners hypothesis space would class
neural networks mapping input space

. loss case would discrete loss:



"





U zfi $ L






155



]

(1)

fiBAXTER

U
U ] L: >

"

"

Using loss function allows us present unified treatment pattern recognition (
, above), real-valued function learning (e.g. regression)
usually
.
goal learner select hypothesis
minimum expected loss:

# CT

(2)
)* + # $ B U # fi= f QfiR
#
minimizing
course, learner know cannot search
)* + # . practice, learner samples repeatedly " according distribution
generate training set
$

fifi j
(3)
# CT . Hence, general
Based information contained learner produces hypothesis
V
learner simply map set training samples hypothesis space :
V $ DT" &

V
(stochastic learners treated assuming distribution-valued .)
#
Many algorithms seek minimize empirical loss , defined by:


W)* X # $ ^ U #
(4)


course, intelligent things data simply minimizing empirical
errorfor example one add regularisation terms avoid over-fitting.
However learner chooses hypothesis , uniform bound (over
)
probability large deviation

, bound learners genas function empirical loss training set
. Whether
eralization error
bound holds depends upon richness . conditions ensuring convergence

well understood; Boolean function learning (
, discrete
loss), convergence controlled VC-dimension1 :

) W * X #

)*+ #
) * + #

#
W) *X #

# C

) *+ #

) W *X #
" Bfi

suppose
probability distribution


6fifi fibe isanygenerated
^
times according . Let
f$ = . probabilityby atsampling
least : (over choice training set ),
# C satisfy

>
^
#
#

f


W
(5)
)* + )* X ffKO^ f K

Theorem 1. Let

Proofs result may found Vapnik (1982), Blumer et al. (1989),
reproduced here.

aJ3













1. VC dimension class Boolean functions
largest integer exists subset
restriction contains Boolean functions .

156



fiA ODEL NDUCTIVE B IAS L EARNING

)*+ #

) *+ #

) W *X #

Theorem 1 provides conditions deviation


actually small.
likely small, guarantee true error
governed choice . contains solution small error learner minimizes
error training set, high probability
small. However, bad choice
mean hope achieving small error. Thus, bias learner model2
represented choice hypothesis space .

)*+ #

2.2 Bias Learning Model
main extra assumption bias learning model introduced learner embedded environment related tasks, sample environment generate multiple
training sets belonging multiple different tasks. model ordinary (single-task)

. bias learning
learning, learning task represented distribution
model, environment learning problems represented pair
set
(i.e., set possible learning problems),
probability distributions
distribution . controls learning problems learner likely see3 . example,
learner face recognition environment, highly peaked face-recognition-type
problems, whereas learner character recognition environment peaked
character-recognition-type problems (here, introduction, view environments
sets individual classification problems, rather single, multiple class classification problems).
Recall last paragraph previous section learners bias represented
choice hypothesis space . enable learner learn bias, supply family
.
set hypothesis spaces
Putting together, formally learning learn bias learning problem consists of:



"

Z



" Z

Z



Z

Z

$

E

input space

E

loss function



output space

U$ "s"&D ,
E environment Z

distribution ,
E

hypothesis space family

"

(both separable metric spaces),

set probability distributions





U

U

C

assume loss function range
assume bounded.



D"

set functions



#%$ &"

Z



.

6 , equivalently, rescaling,

2. bias governed learner uses hypothesis space. example, circumstances
learner may choose use full power (a neural network example early-stopping). simplicity
paper abstract away features algorithm assume uses entire hypothesis space
.
3. domain -algebra subsets . suitable one purposes Borel -algebra
generated
topology weak convergence . assume separable metric spaces,
separable metric space Prohorov metric (which metrizes topology weak convergence) (Parthasarathy,
1967), problem existence measures
. See Appendix discussion,
particularly proof part 5 Lemma 32.













157








Q



fiBAXTER

define goal bias learner find hypothesis space
following loss:

C

minimizing

)*6[ $ = )*+ # f Z
(6)
= U # fi= f fi= f Z
Z
#
way )*[ small if, high -probability, contains good solution
Z
problem drawn random according . sense )*[ measures appropriate
Z
bias embodied environment .
Z
general learner know , able find minimizing )*[

Z

times according yield:
c


fifi .





E Sample ^ times S" according yield:
B

.
E resulting P training setshenceforth called P]fi^_ -sample generated
processare supplied learner. sequel, P]fi^_ -sample denoted
\ written matrix:






j

..
..
..
..
\ $
(7)
.
.
.
c
c
c c !. c
c
P]fi^_ -sample simply P training sets
fifia sampled P different learning tasks
c

, task selected according environmental probability distribution Z .
size training set kept primarily facilitate analysis.
'C .
Based information contained \ , learner must choose hypothesis space
\
directly. However, learner sample environment following way:

E

Sample

P

One way would learner find
defined by:

minimizing empirical loss ,

) W *a `

[

)
*
c



c





) W * ` $ P
3 R )W * X? #

(8)

)*6[

Note
simply average best possible empirical error achievable
training set , using function . biased estimate
. unbiased estimate
would require choosing minimal average error distributions
, defined
.
ordinary learning, likely intelligent things training data
minimizing (8). Denoting set
-samples
, general bias
learner map takes
-samples input produces hypothesis spaces

output:

\

V

P]fi^_


c c
R 3 #
) *+
P]fi^_

. c 2 5
V $

s"
&
'
c
158

Ss" . c 2 5

P

SC

(9)

fiA ODEL NDUCTIVE B IAS L EARNING

V

(as stated, deterministic bias learner, however trivial extend results stochastic
learners).
Note paper concerned sample complexity properties bias
learner ; discuss issues computability .
Since searching entire hypothesis spaces within family hypothesis spaces
, extra representational question model bias learning present
represented searched . defer
ordinary learning, family
discussion Section 2.5, main sample complexity results model bias learning
introduced. specific case learning set features suitable environment
related learning problems, see Section 3.
Regardless learner chooses hypothesis space , uniform bound (over

) probability large deviation

, compute
upper bound
, bound bias learners generalization error
.
view, question generalization within bias learning model becomes: many
tasks ( ) many examples task ( ) required ensure

close high probability, uniformly
? Or, informally, many tasks
many examples task required ensure hypothesis space good solutions
training tasks contain good solutions novel tasks drawn environment?
turns kind uniform convergence bias learning controlled size
certain function classes derived hypothesis space family , much way
VC-dimension hypothesis space
controls uniform convergence case Boolean
function learning (Theorem 1). size measures auxiliary definitions needed
state main theorem introduced following subsection.

V



V

V

V



C
P

) W *a`

) W *`

^

)*6[

) W *`

C

)*[
)*[



#%$ &D" , define #=b$ "&( 6
#b fi= $ U # 9fiR
(10)
hypothesis space hypothesis space family , define
bff$ B #=b$# CT j
(11)
c
#
# c , define #
fifi # c b$ DT" &( 6
sequence P hypotheses
fifi
c

#
fifi #Rc b

fifi c c $ P U #
(12)


db
#
#=c b . hypothesis space family , define
use denote
fifi
cb $ B #
fifi # c b$#
fifi # c CT j
(13)
2.3 Covering Numbers

Definition 1. hypothesis

Define

cb $ cb


159

(14)

fiBAXTER

#$ & "
b
b
P

"&( 6

#b

first part definition above, hypotheses
turned functions
mapping
composition loss function.
collection
functions original hypotheses come .
often called loss-function class.
case interested average loss across tasks, hypotheses
chosen fixed hypothesis space . motivates definition

. Finally,
collection
, restriction
belong single
hypothesis space
.

c
b

C

Definition 2.

#
# c b

C

, define

hypothesis space family



Te $ (
& 6
e $ 3 R )* + #

, define

db
#
fifi # c

P c
b

(15)

e $B
e $ C j

(16)
cb
e controls large P]fi^_ -sample \ must ensure
size

)W *a` )*6[ close uniformly C . size defined terms
certain covering
cb numbers, neede define measure distance
elements
elements .
n
fifi c sequence P probability distributions DT" .
Definition 3. Let
c
db b C b , define

flg dQb yb $ . 5 db

fifi c c ;: yb

fifi c c
(17)
f


f c c c
Z
e e C e , define
Similarly, distribution
>
f [ e
e $ e
;: e f Z
(18)
>
>
fg f [ pseudo-metrics cb e respectively.
easily verified
e f
Te Te
eDC e ,


Definition 4. -cover [ set
fifi
f [ Te e Ti ; . Note require Te contained
h

e f
e , measurable functions
. Let Jijfi [ denote size smallest
e
cover. Define capacity

k Jilfi e $
h Jilfi e f [
(19)
[
. h Jijfi cb f g defined similar
supremum probability measures
c
fg place f [ . Define capacity b by:
way, using
k Jijfi cb $ g h Jilfi cb fg
(20)
supremum sequences P probability measures S" .
R
.
4. pseudo-metric metric without condition
4

160

fiA ODEL NDUCTIVE B IAS L EARNING

2.4 Uniform Convergence Bias Learners
enough machinery state main theorem. theorem hypothesis space
family required permissible. Permissibility discussed detail Appendix D, note
weak measure-theoretic condition satisfied almost real-world hypothesis space
families. logarithms base .





"



Z

\
P]fi^_

"




Z
c

P
^

3fififiP










































P

k e






P
> > >
number examples ^ task satisfies
k cb






^!fi
Pffi > > fi"i $> #
C satisfy
probability least : (over P]fi^_ -sample \ ),
)*[ % )W *a` 9K

Theorem 2. Suppose
separable metric spaces let probability distribution , set distributions
. Suppose
-sample generated
sampling times according give
, sampling times
generate
,
. Let
permissible
hypothesis space family. number tasks satisfies





(21)

(22)

(23)

Proof. See Appendix A.

k Jijfi cb
P]fi^_

several important points note Theorem 2:

k J ijfi e

)* [
# Cs
)*O[

1. Provided capacities

finite, theorem shows bias
bound generalisation error

learner selects hypothesis spaces
terms
sufficiently large
-samples . bias learners find
exact value
involves finding smallest error hypothesis
training sets . upper bound
(found, example
gradient descent error function) still give upper bound
. See
Section 3.3.1 brief discussion achieved feature learning setting.

) W *a` W
)*aP `

) W *`

\



)

*
[
P

C

\

) W *a`

^


close uniformly
2. order learn bias (in sense
), number tasks number examples task
must
sufficiently large. intuitively reasonable bias learner must see
sufficiently many tasks confident nature environment, sufficiently
many examples task confident nature task.

C
Z
^

) W * `

3. learner found
small value
, use

learn novel tasks drawn according . One following theorem bounding
sample complexity required good generalisation learning (the proof
similar proof bound Theorem 2).



161

fiBAXTER



fifi


ilfi " ijfi
^

k ' b
^ >
) ( >
!
(24)
# CT satisfy
probability least %: ,
)*+ # % )W *X # K ij
k
capacity Jilfi appearing equation (24) defined analogous
#b fito=the:
f #b # b $ * fashion
capacities Definition 4 (we use pseudo-metric + +

# yb QfiR f fi= ). important thing note Theorem 3 number
ex-

Theorem 3. Let
training set generated sampling
according distribution . Let permissible hypothesis space.
&%
%
, number training examples satisfies

amples required good generalisation learning novel tasks proportional logarithm capacity learnt hypothesis space . contrast, learner
bias learning, reason select one hypothesis space

consequently would view candidate solution hypothesis
hypothesis spaces
. Thus, sample complexity proportional
capacity ,
, general considerably larger capacity
. learning learner learnt learn environment
individual
sense needs far smaller training sets learn novel tasks.

Z

C

C
b b

C

:_
W) *a` K
)*[
0
* $ 3 R ) * + # 1fi

W *a`
)

= )*+ #

4. learnt hypothesis space
small value
, Theorem 2 tells us
probability least
, expected value
novel task
less
. course, rule really bad performance tasks
. However, probability generating bad tasks bounded. particular,
note
expected value function
, Markovs
inequality, -/. ,



e

- #

0 *
2[
3

)
6
*
[

W
)*`

e

$ e

-


9 Ki


-







(with probability

%: ).

ijfi

5. Keeping accuracy confidence parameters
fixed, note number examples
required task good generalisation obeys

^ F P k ijfi cb
(25)
c
k Jilfi b increases sublinearly P , upper bound number
provided

examples required task decrease number tasks increases. shows
suitably constructed hypothesis space families possible share information
tasks. discussed Theorem 4 below.
162

fiA ODEL NDUCTIVE B IAS L EARNING

2.5 Choosing Hypothesis Space Family

) *[
P]fi^_
\



.

) W * `

)* [
C
P ^

Theorem 2 provides conditions

close, guarantee
actually small. governed choice . contains hypothesis
space small value
learner able find
minimizing error
sample (i.e., minimizing
), then, sufficiently large , Theorem 2 enthe
sures high probability
small. However, bad choice mean
hope finding small error. sense choice represents hyper-bias
learner.
Note sample complexity point view, optimal hypothesis space family choose
contains good solutions
one containing single, minimal hypothesis space
problems environment (or least set problems high -probability), more.
bias learning (because choice made hypothesis
spaces), output bias learning algorithm guaranteed good hypothesis space
environment, since hypothesis space minimal, learning problem within environment using require smallest possible number examples. However, scenario
analagous trivial scenario ordinary learning learning algorithm contains
single, optimal hypothesis problem learnt. case learning done,
bias learning done correct hypothesis space already known.
extreme, contains single hypothesis space consisting possible functions
bias learning impossible bias learner cannot produce
restricted hypothesis space output, hence cannot produce hypothesis space improved
sample complexity requirements yet unseen tasks.
Focussing two extremes highlights minimal requirements successful bias
must strictly smaller space
learning occur: hypothesis spaces
functions
, small skewed none contain good solutions
large majority problems environment.
may seem simply replaced problem selecting right bias (i.e., selecting
right hypothesis space ) equally difficult problem selecting right hyper-bias (i.e.,
right hypothesis space family ). However, many cases selecting right hyper-bias far
easier selecting right bias. example, Section 3 see feature selection
problem may viewed bias selection problem. Selecting right features extremely
difficult one knows little environment, intelligent trial-and-error typically best
one do. However, bias learning scenario, one specify set features
exist, find loosely parameterised set features (for example neural networks), learn
features sampling multiple related tasks.

)*[
)*[



W *a`
)







Z

& "





C

'&"



2.6 Learning Multiple Tasks

P

Z


may learner interested learning learn, wants learn fixed set
. previous section, assume learner starts
tasks environment
hypothesis space family , receives
-sample generated
distributions
. time, however, learner simply looking hypotheses
, contained hypothesis space , average generalization
error hypotheses minimal. Denoting
writing
,

P
#
fifi #Rc

P


c

P]fi^_

#
fifi #=c

163



\

P

n
c

fiBAXTER

c






) * g $ P
) *+ #
(26)
c


P U # fi= f fi=fi



empirical loss \
c


W)*a` $ P )W *X? #
(27)

c
P ^ U # 4 4

4

#
#=c , prove uniform bound
before, regardless learner chooses
fifi
g


#
# c perform
W
probability large deviation )* ` )*
fifi
well training sets \ high probability perform well future examples

error given by:

tasks.

n

fifi c P
^

"


\



P]fi^_

Theorem 4. Let
probability distributions
let
according . Let

sample generated sampling times
permissible hypothesis space family. number examples task satisfies

"

^

k
) ( cb






ffP >
5
^!fi
(28)
> #
C c satisfy
probability least : (over choice \ ),
(29)
)* g % )W *a` ffK
c
k b
(recall Definition 4 meaning Jilfi ).
Proof. Omitted (follow proof bound ^ Theorem 2).
bound ^ Theorem 4 virtually identical bound ^ Theorem 2, note
depends inversely number tasks P (assuming first part max
k cb
expression dominate one). Whether helps depends rate growth )
(
function P . following Lemma shows growth always small enough ensure
never worse learning multiple tasks (at least terms upper bound number
examples required per task).

,


k li b k H ilfi cb k li b
c

Lemma 5. hypothesis space family

164

(30)

fiA ODEL NDUCTIVE B IAS L EARNING


#
#
R
#
c
b
Proof. Let 6 denote set functions
fifi c
k Hijfi cb member
k Jijfi 6 .
!C (recall Definition 1).
87
b
c

6



hypothesis space


k
k

ilfi

b
H

j





Lemma 29 Appendix B,
6
right hand inequality follows.
n meaFor first inequality,
let probability measure " let
c
sure !<" obtained using first copy <"
cb flg product,#and
b C ignoring
b

elements product. Let
-cover
. Pick

c b C fg # # fifi # b fi:9
fifi;9 c b . construction,
let :9
fifi;9
flg # # fi3fi # b fi: 9
fi;fi 9 c b f + # fi: 9
b , establishes first inequality.
k ji b
k Jijfi cb P k ijfi b

(31)
keeping accuracy parameters fixed, plugging (31) (28), see upper
bound number examples required task never increases number tasks,
best decreases F NPQ . Although upper bound, provides strong hint
Lemma 5

learning multiple related tasks advantageous number examples required per task
basis. Section 3 shown feature learning types behavior possible,
decrease.
advantage
2.7 Dependence



F NPQ

Ni >

Ni

Theorems 2, 3 4 bounds sample complexity scale
. behavior
improved
empirical loss always guaranteed zero (i.e., realizable
case). behavior results interested relative deviation empirical
true loss, rather absolute deviation. Formal theorems along lines stated Appendix
A.3.

3. Feature Learning
use restricted feature sets nearly ubiquitous method encoding bias many areas
machine learning statistics, including classification, regression density estimation.
section show problem choosing set features environment
related tasks recast bias learning problem. Explicit bounds

calculated general feature classes Section 3.2. bounds applied problem
learning neural network feature set Section 3.3.

k e fiai3

k cb fiai3

3.1 Feature Learning Model
Consider following quote Vapnik (1996):
classical approach estimating multidimensional functional dependencies
based following belief:
Real-life problems exists small number strong features, simple
functions (say linear combinations) approximate well unknown function.
Therefore, necessary carefully choose low-dimensional feature space
use regular statistical techniques construct approximation.
165

fiBAXTER

q$ &


q














q
q
q

q
p
"
q C_o
pTr q $ B r q $ C p


p
r
$
$

C

(32)
q q j
problem carefully choosing right features q equivalent bias learning
C . Hence, provided
problem find right hypothesis space
k e
k cb learner embedded within
environment related tasks, capacities fiai fiai finite, Theorem 2 tells
us feature set q learnt rather carefully chosen. represents important
simplification, choosing set features often difficult part machine learning
problem.
k e
k cb
Section 3.2 give theorem bounding fiai fiai3 general feature classes.
theorem specialized neural network classes Section 3.3.
p
Note forced function class feature maps q , although
p
necessary. Indeed variants results follow obtained allowed vary
q .

general set strong features may viewed function
+< mapping input
(typically lower) dimensional space < . Let
set feature
space
=
maps (each may viewed set features
). must
>= <
carefully chosen quote. general, simple functions features may
represented class functions mapping < .
define hypothesis
?9
9
, hypothesis space family
space

3.2 Capacity Bounds General Feature Classes

fi= &
q


s"

s"
p
U
C p
q fi=
U
6 fiR & fi= U
b "
pb
b
p b r $ r q $ C p b q Co
pb
k Jilfi p b $
E h Jilfi p b f +
+
f
$ 9zCBfiR:
supremum probability measures <" , + :9fi;9 *GF
9 CBfi= f
CBfi= .
define capacity p ofb first define pseudo-metric f + 2 uvxw
pulling back H metric follows:
ft + 2 uv w q q $ u v 9 r q fi=;/: 9 r q QfiR f fi=
(33)



f=t
ft
easily verified + 2 uvxw pseudo-metric. Note + 2 uv w well defined suprep
b
mum integrand must measurable. guaranteed theh hypothesis space family
ft
p ib r q $ q C permissible (Lemma
32, part 4). define Jilfi + 2 uv{w8

pb
f


smallest -cover pseudo-metric space + 2 u v w -capacity (with respect )

k uv Jilfi $
h Jilfi f + 2 uv{w
+
supremum probability measures -" . state main theorem
A@
<

Notationally easier view feature maps mapping
, absorb loss function definition viewing 9

A@
:9 CB

via CB
. Previously latter function would
map <
denoted 9 follows drop subscript cause confusion.
class 9 belongs still denoted .
?9
9
definitions let
. Define capacity
usual way,

section.

166

fiA ODEL NDUCTIVE B IAS L EARNING

ii
K >

Theorem 6. Let
,



hypothesis space family equation (32).

k J ilfi cb
k Jijfi e

k H
p b c k u v Ji >
k uv Hilfi

ijfiai
fiai > .


(34)
(35)

Proof. See Appendix B.
3.3 Learning Neural Network Features

f

general, set features may viewed map (typically high-dimensional) input
=
much smaller dimensional space
( JLK
). section consider approximatspace
ing feature map one-hidden-layer neural network input nodes J output nodes
QP R

N
=
(Figure 1). denote set feature maps

R
bounded subset TS ( U number weights (parameters) first two layers).
set previous section.
feature N
,
J defined











f
|
| 2
fifi | 2 $ C

| 2 $ & 6 3fifi
b


|N 2 9 $ VWX B 4 # 4 KYB b
[Z
(36)

4


#
b
output
#
4 output
\^] node first hidden layer, CB
fifi_B

$
node parameters th feature V sigmoid squashing function V & 6 .
# $ &S , 3fifi U , computes
first layer hidden node






# 9 $ V WX

Z[
4 4 K
(37)






`
`
4



hidden nodes parameters. assume V Lipschitz. weight

fifi
`
`
vector entire feature map thus
P

fifi


fifi b
fifi b
_fi B

fi_fi B
b
_fi B =
_fi B = b




`
`
`
`
Uf
U
total number feature parameters U KffK J K .
p
arguments sake, assume simple functions features (the class previous
5

section) squashed affine maps using sigmoid function V (in keeping
P
neural network flavor features). Thus, setting feature weights generates
hypothesis space:

| $



=


N | 2 K


f $


C R
=
=

ed





R
=
bounded subset . set hypothesis spaces,
$ B | Q$ P C R
> k ; h?lmgnh > k h Hkporq .
5. Lipschitz exists constant g h j
Vcb

167

(38)

(39)

fiBAXTER

Multiple Output Classes
n

k

l

Feature
Map


Input

P

P

P]fi^_

Figure 1: Neural network feature learning. feature map implemented first two
hidden layers. output nodes correspond different tasks
sample . node network computes squashed linear function nodes
previous layer.

\


fifi



=
feature
hypothesis space family. restrictions output layer weights
P


weights , restriction Lipschitz squashing function needed obtain finite upper
bounds covering numbers Theorem 2.
Finding good set features environment
equivalent finding good hyP
, turn means finding good set feature map parameters .
pothesis space
Theorem 2, correct set features may learnt finding hypothesis space
small error sufficiently large
-sample . Specializing squared loss, present
framework empirical loss
(equation (8)) given

Z

| C

P]fi^_
\
\
c

>

=









b
b
(40)
)W *` | P
.tsu62 2w vwRvwv 2 s^x65 >y k ^ 4
{z VYb b
N | 2 4 9K f :< 4}|
Since sigmoid function V range 6 , restrict outputs " range.
|

3.3.1 LGORITHMS



F INDING



G OOD ET



F EATURES

Provided squashing function V differentiable, gradient descent (with small variation
P
backpropagation compute derivatives) used find feature weights minimizing (40)
(or least local minimum (40)). extra difficulty ordinary gradient
descent appearance definition
. solution perform gradient
P
= node feature weights .
descent output parameters


details see Baxter (1995b) Baxter (1995a, chapter 4), empirical results supporting
theoretical results presented given.

R

W * ` |
)

fifi
168

fiA ODEL NDUCTIVE B IAS L EARNING

3.3.2 AMPLE C OMPLEXITY B OUNDS

\
k J ijfi cb



N EURAL -N ETWORK F EATURE L EARNING

size ensuring resulting features good learning novel tasks
environment given Theorem 2. compute logarithm covering
numbers

.

k J ijfi e
| $aP C S5 hypothesis space family }| form
Theorem 7. Let 3~


=




| $ V b
N | 2 K
f $
= C =






| N | 2
N | 2 = neural network U weights mapping = .

P
feature weights output weights 3fi
fifi = bounded, squashing function V
U



Lipschitz, squared loss, output space " 6 (any bounded subset do),
exist constants =y (independent ilfi U J ) . ,
k Jijfi cb J KP}K U
(41)

k Jijfi e U Ri
(42)
(recall specialized squared loss here).
Proof. See Appendix B.
Noting neural network hypothesis space family
Theorem 2 gives following theorem.



permissible, plugging (41) (42)

|

|

Theorem 8. Let
hypothesis space family hypothesis space

set squashed linear maps composed neural network feature map, above. Suppose
number features J , total number feature weights W. Assume feature weights
-sample
output weights bounded, squashing function V Lipschitz. Let
generated environment
.

\

Z

P F > U K = R

P]fi^_

(43)



^!fi F > J K K U P K P R
| C satisfy
probability least :
)* [ }| )W * ` }| 9 K il
169

(44)

(45)

fiBAXTER

3.3.3 ISCUSSION



F K



NPQ

1. Keeping accuracy confidence parameters fixed, upper bound number
examples required task behaves J
U
. learner simply learning
fixed tasks (rather learning learn), upper bound applies (recall
Theorem 4).

P
^

F

P




upper bound
2. Note away feature map altogether U
becomes J , independent (apart less important term). terms
upper bound, learning tasks becomes hard learning one task. extreme,
fix output weights effectively J
number examples required
task decreases U
. Thus range behavior number examples required
decrease number
task possible: improvement
tasks increases (recall discussion end Section 2.6).

P



F NPQ

P

F NPQ

3. feature map learnt (which achieved using techniques outlined Baxter,
1995b; Baxter & Bartlett, 1998; Baxter, 1995a, chapter 4), output weights
estimated learn novel task. keeping accuracy parameters fixed, requires
J examples. Thus, number tasks learnt increases, upper bound
number examples required task decays minimum possible, J .

F

F

4. small number strong features assumption correct, J small. However,
typically little idea features are, confident neural
network capable implementing good feature set need large, implying
UJ .
J
U
decreases rapidly increasing UJ , least
terms upper bound number examples required per task, learning small feature
sets ideal application bias learning. However, upper bound number
tasks fare well scales U .

F K

NPQ

P

F


special case multi-task framework one marginal distribution input
~ task 3fifiP , varies tasks conditional
space
distribution output space " . example would multi-class problem face
l3fifiP; P number faces recognized
recognition, "

marginal distribution simply natural distribution images faces.
case, every example 4 havein addition sample 4 th tasks conditional
distribution " samples remaining P: conditional distributions " ,
view P training sets containing ^ examples one large training set multi-class
problem ^TP examples altogether. bound ^ Theorem 8 states ^TP
F P J K U , proportional total number parameters network, result would
3.3.4 C OMPARISON



RADITIONAL ULTIPLE -C LASS C LASSIFICATION

expect from6 (Haussler, 1992).
specialized traditional multiple-class, single task framework, Theorem 8 consistent bounds already known. However, already argued, problems face
recognition really single-task, multiple-class problems. appropriately viewed
6. example classified large margin naive parameter counting improved upon (Bartlett,
1998).

170

fiA ODEL NDUCTIVE B IAS L EARNING

P

P

(potentially infinite) collection distinct binary classification problems. case, goal
bias learning find single -output network classify subset faces
well. learn set features reliably used fixed preprocessing distinguishing single face faces. new thing provided Theorem 8: tells us
provided trained -output neural network sufficiently many examples sufficiently
many tasks, confident common feature map learnt tasks good
learning new, yet unseen task, provided new task drawn distribution
generated training tasks. addition, learning new task requires estimating J
output node parameters task, vastly easier problem estimating parameters
entire network, sample computational complexity perspective. Also, since
high confidence learnt features good learning novel tasks drawn
environment, features candidate study learn
nature environment. claim could made features learnt
small set tasks guarantee generalization novel tasks, likely features
would implement idiosyncrasies specific tasks, rather invariances apply across
tasks.

P

P

^

P

viewed bias (or feature) learning perspective, rather traditional -class
classification perspective, bound number examples required task takes
somewhat different meaning. tells us provided large (i.e., collecting examples
large number tasks), really need collect examples would
examples vs. J examples).
otherwise collect feature map already known ( J U
tells us burden imposed feature learning made negligibly small, least
viewed perspective sampling burden required task.

P

K NP

3.4 Learning Multiple Tasks Boolean Feature Maps



P



Ignoring accuracy confidence parameters , Theorem 8 shows number
examples required task learning tasks common neural-network feature map
J
U
bounded
, J number features U number
adjustable parameters feature map. Since
J examples required learn single task
true features known, shows upper bound number examples
required task decays (in order) minimum possible number tasks increases.
suggests learning multiple tasks advantageous, truly convincing need
)
prove lower bound form. Proving lower bounds real-valued setting (
complicated fact single example convey infinite amount information,
one typically make extra assumptions, targets
corrupted
noise process. Rather concern complications, section restrict
attention Boolean hypothesis space families (meaning hypothesis
maps

measure error discrete loss


otherwise).

F K

NPQ

F

P

C "

"

# C

U # 9fiR # } U # 9fiR
"
show sample complexity learning P tasks Boolean hypothesis space family
f= PQ (that is, give nearly matching upper
type parameter
controlled VC dimension
f PQ ). derive bounds f PQ hypothesis space
lower bounds involving

family considered previous section Lipschitz sigmoid function V replaced hard
threshold (linear threshold networks).
171

fiBAXTER

F

well bound number examples required per task good generalization across
tasks, Theorem 8 shows features performing well U
tasks generalize well
novel tasks, U number parameters feature map. Given many feature
learning problems U likely quite large (recall Note 4 Section 3.3.3), would useful
know
U
tasks fact necessary without restrictions environmental
distributions generating tasks. Unfortunately, yet able show lower
bound.
empirical evidence suggesting practice upper bound number
tasks may weak. example, Baxter Bartlett (1998) reported experiments
set neural network features learnt subset 400 Japanese characters turned
good enough classifying 2600 unseen characters, even though features contained
several hundred thousand parameters. Similar results may found Intrator Edelman (1996)
experiments reported Thrun (1996) Thrun Pratt (1997, chapter 8).
gap experiment theory may another example looseness inherent
general bounds, may analysis tightened. particular, bound
number tasks insensitive size class output functions (the class Section 3.1),
may looseness arisen.

ZF



p

3.4.1 U PPER L OWER B OUNDS
PACE FAMILIES



L EARNING TASKS



B OOLEAN H YPOTHESIS


fifi C ~ 0

~ 0 $ B #
fifi # $# CT j
~
~
Clearly 0 . 0 say shatters . growth function defined
^_ $ 0 L / ~ 0
size largest set shattered :
Vapnik-Chervonenkis dimension
= $ ^ $ ^_ j

First recall concepts theory Boolean function learning. Let
class
.
set binary vectors obtainable
Boolean functions
applying functions :



important result theory learning Boolean functions Sauers Lemma (Sauer, 1972),
make use.
Lemma 9 (Sauers Lemma). Boolean function class

positive integers

^



f ,

^
^_ ^ f


.

generalize concepts learning

P

172

tasks Boolean hypothesis space family.

fiA ODEL NDUCTIVE B IAS L EARNING

Definition 5. Let
input space
matrices,



^ matrices
Denote P
. bec 2 a5 Boolean hypothesis
. c 2 space
5 family.
C
C
~



, define set (binary)
.

#



#



$z#
# c CT
_~ $
..
..
..

.
.
.
#=c c
#Rc c




~ }$ ~
P]fi^_
P . fi^ . , define
P]fi^_ $ L ~

c ~ c




]
P


_
^
%


Note
matrix
. say shatters
c

f PQ $ ^ $ P]fi^_ j
Define

Define

Lemma 10.

.

P
.



let

f $ =

f $ =
f f
f PQ f P f
#

f K f
P
Proof. first inequality trivial definitions. get second term maximum
C = f construct matrix
second
inequality, choose
c
.
2
5

f
C
whose rows length shattered . clearly
shatters .

first term maximum take sequence
fifi . 5 shattered (the hypothesis

space consisting union hypothesis spaces ), distribute elements equally
among rows (throw away leftovers). set matrices
#


#





$
#
C
..
..

..


.
.
.
#
c
#
c

















c

f
~ size .
^ NP subset
c .c 5
Lemma 11.
^
P]fi^_ f= PQ ?
173







fiBAXTER

P P]fi^_ P9^_

fifi c
#

#>
^
f PQ = P f QP

P

#
fifi #Rc

Proof. Observe ,
collection Boolean
obtained first choosing functions

functions sequences
, applying
first examples,
second examples on.
definition
,
, hence result follows Lemma 9 applied
.

C

^

k cb fiai3

P]fi ^_


one follows proof Theorem 4 (in particular proof Theorem 18 Appendix
A) clear .
,
may replaced
Boolean
E
case. Making replacement Theorem 18, using choices
discussion

following Theorem 26, obtain following bound probability large deviation
empirical true performance Boolean setting.

n
fifi c P
let \


P]fi^_
^


. Let B
0
* \ $=d C c $ )* g )W a* ` ffK ij P]fi ^_ ) : > P9^_N

(46)
Corollary 13. conditions Theorem 12, number examples ^ task


probability distributions
Theorem 12. Let

-sample generated sampling times
according
permissible Boolean hypothesis space family. %
,

satisfies

^ > f PQ K P
!

probability least : (over choice \ ),
)* g % )W *a` ffK



C c

(47)
satisfy
(48)

Proof. Applying Theorem 12, require

P]fi ^_ ) : > P9^_N

satisfied

^!fi > f PQ f ^ PQ K P

fiM ,
used Lemma 11. Now,
^ K K Ifi



f PQNi > , (49) satisfied
^!fiI ^ . setting IL
^!fi > f PQ K P
174

(49)

fiA ODEL NDUCTIVE B IAS L EARNING

Corollary 13 shows algorithm learning
requires

P

tasks using hypothesis space family

^ F > =f PQ K P R

c





(50)

\

P

examples task ensure high probability average true error hypotheses
selects
within average empirical error sample . give
theorem showing learning algorithm required produce hypotheses whose average
true error within best possible error (achievable using
) arbitrary sequence
distributions
, within
factor number examples equation (50)
necessary.

sequence
probability distributions
, define






fifi c

= g c




n
c P
g c $ R )* g

c P






contains least two
Pbe3afi Boolean
hypothesis space family
fifi let V c learning algorithm taking input P]fi^_c -samples
c
.
2
5


C
\ ( producing output P hypotheses #
#=c C .
%i%MN % %MN ,
^ % > f PQ KM:i > P : 3
!



c
n

fifi probability least (over
exist distributions
\
random choice ),
g)* V c J\ . = g c ffK

Theorem 14. Let
functions.

Proof. See Appendix C

Ni3
f PQ

3.4.2 L INEAR HRESHOLD N ETWORKS

P
f PQ

factor, sample complexity
Theorems 13 14 show within constants
learning tasks using Boolean hypothesis space family controlled complexity parameter
. section derive bounds
hypothesis space families constructed
thresholded linear combinations Boolean feature maps. Specifically, assume
form given (39), (38), (37) (36), squashing function V replaced hard
threshold:


V
otherwise

$ :

Rfi





Ry

dont restrict range feature output layer weights. Note case
proof Theorem 8 carry constants Theorem 7 depend
Lipschitz bound V .



f U

Theorem 15. Let hypothesis space family form given (39), (38), (37) (36),
hard threshold sigmoid function V . Recall parameters , J input dimension,
number hidden nodes feature map number features (output nodes feature map)
175

fiBAXTER

$ U f K]K J U K (the number adjustable parameters feature
f PQ U K J K J K U Kz
P
>
Proof. Recall
. c 2 for5 eachM | P ~ C TS , | $ &( = denotes feature map parameters P .
C


, let
denote matrix
|

6
|

.
.

.
|M .. c
. . | .. c
~ set binary P ^ matrices obtainable composing thresholded linear
Note
| ~

respectively. Let U
map). Then,

functions elements
, restriction function must applied
element row (but functions may differ rows). slight abuse notation,
define

P]fi^_ $


~


| ~ $aP C









. c 2 5
C
Fix
. Sauers
Lemma, node first hidden layer feature map computes

f 5 functions P9^ input vectors . Thus,
^TPQNb . K
^TPQN f K
distinct functions input output first hidden layer
P9^ points . Fixing first hidden layer
U b
parameters, node second layer of. b the5
feature map computes ^TPQN K functions image produced output
U =

first hidden layer. Thus second hidden layer computes ^TPQN K
functions output first hidden layer P9^ points . So, total,
b .
5 ^TP = . b
5

^
P
P]fi^_ f KR U K

| ~ , number functions computable row | ~
Now, possible matrix


=
thresholded linear combination output feature map ^_N J K . Hence,
c . =
5 obtainable applying linear threshold functions
number binary sign assignments
. Thus,
rows ^_N J K
b.
5
c .
5
.b
5
P]fi^_ f ^TKP U ^TKP = P ^TKP =
J
$

q convex function, hence IfiGfi . ,
IK U GY
K

J
q J K U K J K U K JRq JIffK U q HGffK q
b
b
U
=
=}
K

K








J


J IK U G]Kc
G
U K , G f K P J K shows
Substituting
c .=
5
U

^

P

K

K






P]fi^_ K J P K
(51)
U

J

176

fiA ODEL NDUCTIVE B IAS L EARNING

Hence,

^TP J K U K





K
K

(52)
. P
J
> U K P J K
P]fi^_% c definition f PQ^ . . , observe . >


U KN U K P J K J K U K shows
> . Setting ^TP J K

U K .
(52) satisfied ^ U NP}K J K > J K
f
U
Theorem 16. Let Theorem 15 following extra restrictions: , J
f
.
J
f PQ U P K J K



f
f
Proof. bound apply Lemma 10. present setting contains
f
U
three-layer linear-threshold networks input nodes, hidden nodes first hidden layer, J
^

U

hidden nodes second hidden layer one output node. Theorem 13 Bartlett (1993),


=
lf U K U J : K3fi

f
restrictions stated greater U N . Hence
f Ufi

U

N.

f :

J

J choose feature weight assignment feature map
J
identity J components input vector insensitive setting reminaing
components. Hence generate J
points
whose image feature map
J
shattered linear threshold output node,
.

K

f ] K

Combining Theorem 15 Corrolary 13 shows

^!fi F > U P K J K K P
examples task suffice learning P tasks using linear threshold hypothesis space family,
combining Theorem 16 Theorem 14 shows

^ > U P K J K K P
learning algorithm fail set P tasks.
4. Conclusion
problem inductive bias one broad significance machine learning. paper
introduced formal model inductive bias learning applies learner able
sample multiple related tasks. proved provided certain covering numbers computed
set hypothesis spaces available bias learner finite, hypothesis space
contains good solutions sufficiently many training tasks likely contain good solutions
novel tasks drawn environment.
specific case learning set features, showed number examples
J
U
required task -task training set obeys
, J number

P

^ F K

177

NPQ

^

fiBAXTER

features U measure complexity feature class. showed bound
essentially tight Boolean feature maps constructed linear threshold networks. addition,
proved number tasks required ensure good performance features novel
tasks U . showed good set features may found gradient
descent.
model paper represents first step towards formal model hierarchical approaches
learning. modelling learners uncertainty concerning environment probabilistic terms,
shown learning occur simultaneously base levellearn tasks
handand meta-levellearn bias transferred novel tasks. technical
perspective, assumption tasks distributed probabilstically allows performance guarantees proved. practical perspective, many problem domains
viewed probabilistically distributed sets related tasks. example, speech recognition
may decomposed along many different axes: words, speakers, accents, etc. Face recognition
represents potentially infinite domain related tasks. Medical diagnosis prognosis problems
using pathology tests yet another example. domains benefit
tackled bias learning approach.
Natural avenues enquiry include:

E

F



Alternative constructions . Although widely applicable, specific example feature
learning via gradient descent represents one possible way generating searching
hypothesis space family . would interesting investigate alternative methods,
including decision tree approaches, approaches Inductive Logic Programming (Khan
et al., 1998), whether general learning techniques boosting applied
bias learning setting.

E





Algorithms automatically determining hypothesis space family . model
structure
fixed apriori represents hyper-bias bias learner. would
interesting see extent structure learnt.

E

E



Algorithms automatically determining task relatedness. ordinary learning usually little doubt whether individual example belongs learning task not.
analogous question bias learning whether individual learning task belongs
given set related tasks, contrast ordinary learning, always
clear-cut answer. examples discussed here, speech
face recognition, task-relatedness question, cases medical
problems clear. Grouping large subset tasks together related tasks could
clearly detrimental impact bias-learning multi-task learning, emprical evidence support (Caruana, 1997). Thus, algorithms automatically determining
task-relatedness potentially useful avenue research. context, see Silver
Mercer (1996), Thrun OSullivan (1996). Note question task relatedness
clearly meaningful relative particular hypothesis space family (for example,
possible collections tasks related contains every possible hypothesis space).





Extended hierarchies. extension two-level approach arbitrarily deep hierarchies,
see Langford (1999). interesting question extent hierarchy
inferred data. somewhat related question automatic induction
structure graphical models.
178

fiA ODEL NDUCTIVE B IAS L EARNING

Acknowledgements
work supported various times Australian Postgraduate Award, Shell Australia Postgraduate Fellowship, U.K Engineering Physical Sciences Research Council grants
K70366 K70373, Australian Postdoctoral Fellowship. Along way, many people
contributed helpful comments suggestions improvement including Martin Anthony,
Peter Bartlett, Rich Caruana, John Langford, Stuart Russell, John Shawe-Taylor, Sebastian Thrun
several anonymous referees.

Appendix A. Uniform Convergence Results
Theorem 2 provides bound (uniform ) probability large deviation
?1
?p

. obtain general result, follow Haussler (1992) introduce
following parameterized class metrics :



8c


" _"e


. main theorem uniform bound probability large values
"1 ?1
?p

?E"
?1


. Theorem 2 follow corollary,

, rather

?E"
better bounds realizable case
(Appendix A.3).
p



Lemma 17. following three properties

3.

easily established:

E

1.
2.




n

L


p E
,

"1 E?"1 _


,



E

,

" E ?

}





" ^_p _


.




ease exposition dealing explicitly hypothesis spaces
Q!
3 j}
containing functions
, constructing loss functions Q mapping
_
_
A3 j}
Q
. However, general view



loss function
+
j}
Q function abstract set (
)
ignore particular construction

terms loss function . remainder section, unless otherwise stated,
j}
. considerably
hypothesis spaces sets functions mapping
_



convenient transpose notation C
-samples, writing
training sets columns
instead rows:


... . .. ...

(Equation 9 prior discussion),

fiff
. Recalling definition






transposition lives
. following definition generalizes quantities



,
new setting.

Definition 6. Let
functions mapping

.
, let orsetssimply
map
denote















?







?











































179







j}





fiBAXTER

. Let !"# denote set functions. Given
$ % & elements

, (or equivalently element
writing
rows), define




'

(recall equation
, define(8)). Similarly, product probability measure ( *) +)
-,#.0/ (

(recall equation (26)). 21
(not necessarily form 345 ),
define
1 %, . / 1 (
, define
(recall equation (17)). class functions mapping
6 57 98;:=?< > @7
7
supremum product probability measures
>
size smallest 7 -cover (recall Definition 4).




5









































?"

















?















































j}

































j}



























following theorem main result rest uniform convergence results
paper derived.

BA C






EDF @G
JI G
( 9) H)
GQP
+R 6 @G ST VU < G W (53)


permissible class functions mapping
Theorem 18. Let


j}








. Let
generated
independent trials





according


product
probability
measure
.


,
,


K ML








N8;:#<





p ?
?

'



'























following immediate corollary use later.

YX[Z U]\ G H^ _&` R 6bac gd fe G ih

Corollary 19. conditions Theorem 18,


!





K L










j8;:#<















p ?"
?

'



'

'



(54)

GP g


(55)

A.1 Proof Theorem 18
proof via double symmetrization argument kind given chapter 2 Pollard (1984).
borrowed ideas proof Theorem 3 Haussler (1992).
180

fiA ODEL NDUCTIVE B IAS L EARNING

A.1.1 F IRST YMMETRIZATION





, let







..
..
..
.
.
k .







extra piece notation:
bottom half, viz:













top half

l
..
..
..
.
.
l .















following lemma first symmetrization trick. relate probability large deviation
empirical estimate loss true loss probability large deviation
two independent empirical estimates loss.



mI G





Lemma 20. Let permissible set functions


j

!
.
probability measure


K L











N8;:#<



po

GP
N8;:#< rq


cFn



,

p ?
? 1
'






YD K L










p

?






?


j}

let

)



ts G P








(56)

q
rq ts G uo G
q G zD
0w
q uo G
q uo G

Proof. Note first permissibility guarantees measurability suprema
p
" ?
? 1






(Lemma 32 part 5). triangle inequality
,

" ?

"





?
?

?

,
. Thus,







]q
K &v

Vo ts G
xw
K v





















Q"





?









?












""

?




"

?









? 1
? 1





(57)



Chebyshevs
inequality, fixed ,


K v











Q ?
?



{I G
K L













-DF @G







? 1




gives result.








?









r



G


|R




?




?"





? 1




GD P

_

. Substituting last expression right hand side (57)

181

fiBAXTER

A.1.2 ECOND YMMETRIZATION
second symmetrization trick bounds probability large deviation two empirical
estimates loss (i.e. right hand side (56)) computing probability large deviation elements randomly permuted first second sample. following
definition introduces appropriate permutation group purpose.

}
~









~ ~ ~
~

~ H} , let

F l
.. . . . ..
. l .

" permissible set functions
Lemma 21. Let
mapping
let 3W
(as statement Theorem 18). Fix
ST -cover , 1 +
'
1

rows
G
. Then,
K L ~ H} j8:#O < ]q ; ; ts G P
K v ~ H} q

ts GR (58)

'
~ H} chosen uniformly random.
q ; ; ts G (if
Proof. Fix ~ } let

G ST . Without loss
~ already done). Choose






3 . Now,
generality assume form


' ffu

fiff





' ffu



' ffp q



' ffu q



' ffp q

ts

' ffu q

ts
q q







Definition 7. integers
, let
denote set permutations

>
>




&
sequence pairs integers



,

































, either


.
















j}




















p







"

?






























?








Q



p









>











j





"



?




?










>




















182








cp




















?










'

?


















j









?
















j





















?




8













'





















?










?














fiA ODEL NDUCTIVE B IAS L EARNING



p

Hence, triangle inequality

,

q
q ts
q ; ;
]q


q G | R construction
G |R . Thus,
(59) implies
rq ts
v ~ H} xw
v ~ H} xw


p





>
"







>



?





?
?
?
?



>




c ?
?
c ?



?


'





p ?



?


'


" ?
?









?

>
>

"





q
q ts
(59)
ts G assumption,
GD
q GRy



?




?












'







"



?












?
















gives (58).



,be function written form
{3
K Mv ~ b} ]q ts GR YD VU < G
(60)
~ H} chosen uniformly random.


Proof. ~ f} ,
q

ts





p




q ts


(61)








ffu

, , let
simplify notation denote
fiff
fiff . pair ,


lff independent random variable










fiff
probability



lff

fiff probability . (61),
K Mv ~ H} q GR




l




fiffYl
K ~ H} q

ts GR

' ffp


' ffp



fiff +
K
fiff GR

' ffu

ffu


0 bounded ranges


, HoFor zero-mean independent random variables
effdings inequality (Devroye, Gyorfi, & Lugosi, 1996)


K \
h YD VU < D3


'



#
bound probability term right hand side (58).





Lemma 22. Let
.














>







j









?


?












j





































?


>











?






j}



Q"





























"







?












?








j





















































183



'

















fiBAXTER


fiff


fiff
,

fiff+ YD VU < G
ffu
fiffV
K l
fiff GR

ffp
fiff


' ffp

ffu

Let

ffp
fiff .
fiff ,
ffu
fiff
fiff . Hence,

VU < G
' ffu
'
lff ffu

lff YD VU < G


R . Hence
giving value
minimized setting
K v ~ f} q ts GR YD VU < G


Noting range












j











?


























j





e





Dj















j

















e




































j

j



"j



?


























required.



21 22 give:
K L ~ H} j8:#O < ]q ; ; ts G P
YD > @G ST
VU <W G
) ;) )
empirical distribution
Note
simply (




(recall Definition 3). Hence,
puts point mass


N8;:=< q G P
K L ~ H}

YD 6 @G ST VU <W G
Now, random choice ,
fiff independently (but identically) distributed ~
)
ever swaps
fiff
(so ~ swaps
fiff drawn according another component
drawn according distribution). Thus integrate respect choice
~ write
j8;:#< q G P
K L

YD 6 @G ST VU <W G
A.1.3 P UTTING


fixed




OGETHER


, Lemmas





"

?






?










'









G



>



















e



e





e



_



j





























"

?




?




























j



















p

?






?








Applying Lemma 20 expression gives Theorem 18.
184









j



fiA ODEL NDUCTIVE B IAS L EARNING

A.2 Proof Theorem 2

) ;)

(

Another piece notation required proof. hypothesis space



measures
, let



?






& o&

' ]'=





?








) ;)
K (
(



probability



?

another empirical
Note used ? rather ? indicate

?1
estimate
.
_
C
generated se -sampling process, addition
sample



although supplied learner.
quence probability measures,






means
notion used
following Lemma,

n
probability generating sequence measures environment

C _
-sample according
holds.

(

(

Lemma 23.



K L (










1




! f N8:#<





K L ( 8;:# <
! 8;:#<
K L







" ?




! x
p

"1 ?"
?





?}1






G P Dg





















"1 ?p
?1





Proof. Follows directly triangle inequality





G P Dg







(62)



(63)

G P g


.

treat two inequalities Lemma 23 separately.

A.2.1 NEQUALITY (62)





following Lemma replace supremum
8 .
Lemma 24.


K ML (











inequality (62) supremum

f j8;:#<
QG P


f N8;:#/ <
K \ (


















p ?"
?









185









p ?Ep
?

'



'



Gh

(64)

fiBAXTER


(
-&




8;:#<

p





G
jI 7

n

7

?E"
?
Proof. Suppose
. Let satisfy


?

?"
?"

. definition
,

equality. Suppose first


"
?"
?E"
exists 5
. Hence property (3)






" ?"
?E"




metric,
, exists

. Pick arbitrary
?
?
?
?
?E"
satisfying inequality. definition,

,



' .
?
?


(by assumption), compatibility
ordering




p1 ?"
?
'


p


'
reals,
, say. triangle inequality ,





7

u



G



7




G G g





G g


Thus

7 g G g 7 7 satisfying inequality
G


found. Choosing
shows exists

.

instead,
, identical argument run role (
interchanged. Thus cases,
8:# <
G w

G
p1 ?p
?



p1 ?"
?

'
?








'



'

Qc" ?p
?E"
p1 ?"
?














"1 ?p
?












'





"1 ?"
?





?"







8

Qp1 ?"
?

'





'





'







completes proof Lemma.
_
nature C
sampling process,


;8 :#/ <


j8;:=/ <
, / K \

3
AY

K \ (
















p ?"
?

'





'

Gh

'

p G h ( (65)
H permissible assumed

permissibility (Lemma 32, Appendix D). Hence
satisfies conditions Corollary 19
G g g Corollary
combining Lemma 24, Equation (65) substituting G
















GQ

?
?



































19 gives following Lemma sample size required ensure (62) holds.

+X[Z U L G f^ _&` 6 @G g G P
f j8;:#<



Lemma 25.



K L (


)



























p ?"
?




'
)








)
g

G
G
4



+X[Z U L G ^ _&` 6 @G g 4 G P

A.2.2 NEQUALITY (63)














!



G P Dg


f )



?


Note ?




, i.e expectation

distributed according . bound left-hand-side (63) apply Corollary

19
, replaced , replaced , replaced

respectively,
replaced replaced . Note
permissible whenever (Lemma 32).
Thus,

)





















?



186



g

(66)

fiA ODEL NDUCTIVE B IAS L EARNING

inequality (63) satisfied.
Now, putting together Lemma 23, Lemma 25 Equation 66, proved following

general version Theorem 2.

[I G g
YX[Z U L G ^ _&` 6 @G g G P
6 @G 0 P

[
X
Z
U
L
g

G ^ _&`
G

! j8;:#<
K L
GP g

7m
get Theorem 2, observe




7
7 |R
Setting G
maximizing G
gives
. Substituting G
p

_
-sample genTheorem 26. Let permissible hypothesis space family let C
n










erated environment
.

,





?

















p1 ?"
?1
'


































!





















?
?
1






?












7 ED


{5



.


Theorem 26 gives Theorem 2.

7
G

A.3 Realizable Case

7


7


G G
G
G
G 0 G 7
G
JI G g ,

Corollary 27. conditions Theorem 26, 7
X[Z U L G G 7 ^ _&` 6 G g 7 G G 7 P
6 G 7 P


[
X
Z
U
L
g

G G 7 ^ _&`
G G 7

G
! N8;:#<
K L
7P g
G


bounds particularly useful know
, set G
G ).
(which maximizes G




7

Theorem 2 sample complexity
scales
. improved

?"



?
?Ep





instead requiring
, require ?












?




. see this, observe ?






"1 ?"
?}1







, setting
Theorem 26 treating constant
gives:





_







$





$







_





?1



















3 z b
composition two function classes note



write
r




form given (32), written



r























Recalling Definition 6,






$


?p





Appendix B. Proof Theorem 6










?p









$



























_



_

_







187





_









_







define

fiBAXTER

bt z . Thus, setting b 0


(67)
6 .
following two Lemmas enable us bound 57






Lemma 28. Let
form

. 7 7
,
6 57 7
6 57 6 57

=

)
7




Proof. Fix measure

let minimum size -cover
.

6

$
)


$
)

5
7



definition
b let
measure
defined

) set in.



is6 measurable).
~ -algebra
( measurable


7
F


57 . Let

Let

. definition again,
6
6
9 andsize -cover
. Note

minimum
57 57 Lemma





7
7




shown
-cover
. So, given
choose
proved
1 H 1 7 1 V 1 7 . Now,
1 1 1 1 1 1
1 1
7 7
line follows
first line follows triangle inequality second






F









facts:
1
1 1
1 . Thus
7 7 -cover 1 1
result follows.
(Definition 6), following Lemma.
Recalling definition {
Lemma 29.
6 57 M3 6 57



. Let
) )
Proof. Fix product probability measure
(
/
7 -covers . let % . Given %
{& , choose 93 o&

7 . Now,





/
.
,
93

'


'

(



' o&


7

-
'
result follows.
Thus 7 -cover 93



,









j}



j}









































1





L



























c












'









































C

























C



E

















:











































_































1



















j

1

:



































































!









'

























E























188

































>















fiA ODEL NDUCTIVE B IAS L EARNING

B.1 Bounding

6 @7






j

6 7 7 e 6 @7 6 / 7 e
Lemma 29,
6 @7 6 57
/ 57
6

Using similar techniques used prove Lemmas 28 29,
satisfy
6 / 57 6 7
Lemma 28,


































:















(68)







(69)


shown





(70)

Equations (67), (68), (69) (70) together imply inequality (34).

6

6
@7 hypothesis space
wish prove 57


x

family form

|
f4 . Note f corresponds
,
) '#

, defined
probability measure induces probability measure
zz -, ) )
~ -algebra
. Note
1 bounded, positive functions

arbitrary set ,
3 3 1 +8 :#3< 1
(71)






#




#






. Let f
Let probability measure space probability measures





. Then,
two elements corresponding hypothesis spaces


-, '= '# )
, 8; :#< ) (by (71) above)


) )
, , 8:#<




8;:#< guaranteed
permissibility (Lemma 32 part 4, ApThe measurability



|


have,
pendix D).
f
(72)
> 57
> 7 = M| e
^

B.2 Bounding

























/












? 1

























j









































1

















? 1





? 1





1



















? 1

















_













_





















gives inequality (35).
189















? 1

_





























fiBAXTER

B.3 Proof Theorem 7
order prove bounds Theorem 7 apply Theorem 6 neural network
hypothesis space family equation (39). case structure




G

G @G G G
0







~
'
bounded

subset
Lipschitz squashing function ~ . feature class

set one hidden layer neural networks inputs, hidden nodes, outputs, ~
squashing function weights
fiff bounded subset . Lipschitz
restriction ~ bounded restrictions weights ensure Lipschitz
b



classes. Hence exists
1 , 1
1 W 1



1 1 norm
,
case. loss function squared loss.
, hence 1 probability measures

) onNow, (recall assumed
output space
),
1 -, l
1
)
YD, 1 )
(73)

)
)
1 -

marginal distribution
derived . Similarly,
)
probability measures
,


1 YD&, 1 )
(74)
Define
6 7 e 98;:#o < > 7 ) e

supremum probability measures (the Borel subsets of)
,

)
)
7
7
e






size


smallest
-cover



metric.
Similarly
set,
>
6 7 e 98;:#o < > 7 ) e
supremum probability measures . Equations (73) (74) imply
6 57 6 7D
(75)
6 @7 6 7
D&
(76)

Applying Theorem 11 Haussler (1992), find







7

6 7!
6 D&7 7 "
w











_





j}



























m/

_









_



j}






>

_



























_


















































_


























































j}









m/





j}































































































Substituting two expressions (75) (76) applying Theorem 6 yields Theorem
7.
190

fiA ODEL NDUCTIVE B IAS L EARNING

Appendix C. Proof Theorem 14
proof follows similar argument one presented Anthony Bartlett (1999)
ordinary Boolean function learning.
First need technical Lemma.

,

G
# #
K #




K # # 0 # # %$ G 'R & '( ) +/ *-. , n 1n 0
,
# denote number occurences random sequence # # # .
Proof. Let


function viewed decision rule, i.e. based observations # , tries guess














whether probability
Bayes

Dis # WD , and.
# optimal
rule isD otherwise.
# decision
estimator: # #
Hence,
K # 2$ G K # G


K # G
KD # G







half probability binomial
random variable least WD .
Sluds inequality (Slud, 1977),
K # 3$ G K


G









Lemma 30. Let random variable uniformly distributed




>
. Let
i.i.d.
-valued random variables G
>{



. function mapping
,






















1

&



























^

















"





























$





&







"



^















^





























"





&

"







n





















j

. Tates inequality (Tate, 1953) states
normal
,

K






'4









65 n

)

1





! shattered , . row 7 let
set
Let 7

)
) )
distributions

contained
9

8


)



)
fiff









th;: row ofD 7 , f ,
8

. Let
.
)
;
)

<< achieved sequence







Note (
, optimal error _


fiff )

fiff
,
always contains sequence shatters 7 . optimal error

<_ 6< )

3$ =

'

' ffu
Combining last two inequalities completes proof.













+


>

C





_



>

3














C








1







C















3



>
'















C





_

>



C



_













?











G





5

191







1

>

C





1







fiBAXTER








,
p _ 6< <










(77)


fiff 3$

fiff

-sample , let element
fiff array
?=
..
..
>
..
.
.
.=
equal number occurrences
fiff .
) ;) uniformly random , generate Now, select (

@ (the output learning algorithm) have:
sample using ( ,


fiff 2$

lff C B ) />

fiff 2$

lff >
B ) /> = )
fiff 2$
fiff
lff

' ffu
) probability generating configuration >
fiff -sampling
/>
process sum possible configurations. Lemma 30,
)
lff 2$
fiff
fiff ER DF 'G ) * /. H , nn JI
,
?

C _





'







































C _



























































fiff 3$




K




C













































j}

j}

1



B )
























C

R'&


/>




(



)

1






























?

@




_



? = R

' ffp
M/ L /n . L
n


K






















H
) * /. , n n IJ
,





(78)


, (78)

G









192

DF

G

1

=K *-K, , 0

_ <6< G





(79)


. Plugging (77) shows


K (



C _

-valued random variable , G














lff 3$

G
O/ L /n . L
(
)

G NR &
= K *-K, , n 0






Jensens inequality. Since
implies:











C

















hence



































5















C





G


fiA ODEL NDUCTIVE B IAS L EARNING

(

(



@

(

Since inequality holds random choice , must hold specific choice

algorithm
sequence distributions
. Hence learning

K

?



@




Setting

Assuming equality (80), get











G 7




G



e



(80)

_ <6< 7 g




_

g







@

?





e



K



G g



ensures

_ << G



_









(81)

7g



Solving (79) , substituting expressions G shows (81) satisfied
provided
& g7 0 ^ _&` g g
(82)
g
R ( R since G |R G g ), assuming
Setting
g7 somefor
YD , (82) becomes

(83)

^'_&`
R right hand side (83) approximately maximized
Subject constraint
QPSR & , point value, exceeds
CDF D&D 7 . Thus, , 7 g

R
D&D e
(84)
7
G













!









C







1












e










j

!



C

1





















C









!



C





Q



>

>





^













<6< 7 g
_
contains least two
g
obtain -dependence Theorem 14 observe assumption
)UT two distributions
functions
, hence exists
3$
. Let
)



)T

7

8
concentrated



;: 7 . Let ( 9)
b) ( -) H) product distributions

V
)
98 generated ,T @ . Note

. ( one (
learning algorithm
chooses wrong hypothesis ,

_ 6< < 7
K




















?

@













{









?





_











'






























_

















193



























_





fiBAXTER

(

(

( ( generate
/ n
_ << 7 NR & ( ) /*X. W W n 0


Now, choose uniformly random
cording , Lemma 30 shows

K (
g
least









?



@






_

























c





1





-sample

ac-





r





_





JI g |R . Combining two constraints
X[Z U finishes proof.


C _



7 7 f^ _&` g g


provided





(85)


: (84) (with





P ) (85), using


Appendix D. Measurability
order Theorems 2 18 hold full generality impose constraint called
permissibility hypothesis space family . Permissibility introduced Pollard (1984)
ordinary hypothesis classes . definition similar Dudleys image admissible
Suslin (Dudley, 1984). extending definition cover hypothesis space families.
Throughout section assume functions map (the complete separable metric
j}
. Let denote Borel -algebra topological space . Section
space)
2.2, view , set probability measures , topological space equipping
topology weak convergence. -algebra generated topology.
following two definitions taken (with minor modifications) Pollard (1984).







~





j}



~

-valued functions indexed set
Definition 8. set
r

j}





Definition 9. set
1.











_



Zff

Q







permissible indexed set







exists function



analytic subset Polish7 space ,


~


2. function
-algebra









j}

indexing



\[]Y .
analytic subset Polish space




measurable respect product


simply continuous image Borel subset
another Polish space . analytic subsets Polish space include Borel sets.
important projections analytic sets analytic, measured complete
measure space whereas projections Borel sets necessarily Borel, hence cannot
measured Borel measure. details see Dudley (1989), section 13.2.
Lemma 31.

2|









j}

permissible








permissible.

Proof. Omitted.
define permissibility hypothesis space families.
7. topological space called Polish metrizable complete separable metric space.

194

fiA ODEL NDUCTIVE B IAS L EARNING

W







Definition 10. hypothesis space family
permissible exist sets





analytic subsets Polish spaces respectively, function


measurable respect

,

^_[`Y \[`Y
ba



fe hg





_}E






Zff







dc






,



j}

@



Let
analytic subset Polish space. Let
measure space

denote analytic subsets . following three facts analytic sets taken
Pollard (1984), appendix C.

fe hg


(a)

@
(b)









complete

@



e




.

e ]
[ .
, projection onto

~

contains product -algebra

(c) set





@



4

@



)




.








Recall Definition 2 definition . following Lemma assume
_
n
_ complete
completed respect probability measure ,
respect environmental measure .





Lemma 32. permissible hypothesis space family ,
1. permissible.


f permissible.
3.
permissible
.

8
#
:
<
'# measurable .
4.
5. measurable
.
6. permissible.
simply set
Proof. absorbed loss function hypotheses ,
"
-fold products
. Thus (1) follows Lemma 31. (2) (3)
2. G







/

/



/





















immediate definitions. permissible , (4) proved
identical argument used Measurable Suprema section Pollard (1984), appendix
C.


j}


j}
, function
defined
(5), note Borel-measurable








Borel measurable Kechris (1995, chapter 17). Now, permissibility




,

measurable
automatically implies permissibility

/
(4).
r



j}
appropriate way. prove (6),
let indexed




j}
1
_

}

E





_E



. Fubinis theorem
define




j}
E






-measurable function. Let
defined

1_}E
indexes
appropriate way
permissible, provided
.

-measurable. analyticity becomes important. Let
shown




1_}E _E
. property (b) analytic sets,
.


contains

1
E



1
E








set
projection
onto
, property (c)
n

analytic.

assumed complete,
measurable, property (a). Thus
measurable function permissibility
follows.

)

kj .

0

)




;[m ;[fiff
qp )

'#on ) ) r[fiY
G
c c )
)
p


)

G





W

lj .
)





4

195

c

c

f '# f
@










)



c

fiBAXTER

References
Abu-Mostafa, Y. (1993). method learning hints. Hanson, S. J., Cowan, J. D., & Giles,
C. L. (Eds.), Advances Neural Information Processing Systems 5, pp. 7380 San Mateo,
CA. Morgan Kaufmann.
Anthony, M., & Bartlett, P. L. (1999). Neural Network Learning: Theoretical Foundations. Cambridge University Press, Cambridge, UK.
Bartlett, P. L. (1993). Lower bounds VC-dimension multi-layer threshold networks.
Proccedings Sixth ACM Conference Computational Learning Theory, pp. 44150
New York. ACM Press. Summary appeared Neural Computation, 5, no. 3.
Bartlett, P. L. (1998). sample complexity pattern classification neural networks:
size weights important size network. IEEE Transactions
Information Theory, 44(2), 525536.
Baxter, J. (1995a). Learning Internal Representations. Ph.D. thesis, Department Mathematics Statistics, Flinders University South Australia. Copy available
http://wwwsyseng.anu.edu.au/ jon/papers/thesis.ps.gz.



Baxter, J. (1995b). Learning internal representations. Proceedings Eighth International
Conference Computational Learning Theory, pp. 311320. ACM Press. Copy available
http://wwwsyseng.anu.edu.au/ jon/papers/colt95.ps.gz.



Baxter, J. (1997a). Bayesian/information theoretic model learning learn via multiple task
sampling. Machine Learning, 28, 740.
Baxter, J. (1997b). canonical distortion measure vector quantization function approximation. Proceedings Fourteenth International Conference Machine Learning,
pp. 3947. Morgan Kaufmann.
Baxter, J., & Bartlett, P. L. (1998). canonical distortion measure feature space 1-NN
classification. Advances Neural Information Processing Systems 10, pp. 245251. MIT
Press.
Berger, J. O. (1985). Statistical Decision Theory Bayesian Analysis. Springer-Verlag, New
York.
Blumer, A., Ehrenfeucht, A., Haussler, D., & Warmuth, M. K. (1989). Learnability vapnikchervonenkis dimension. Journal ACM, 36, 929965.
Caruana, R. (1997). Multitask learning. Machine Learning, 28, 4170.
Devroye, L., Gyorfi, L., & Lugosi, G. (1996). Probabilistic Theory Pattern Recognition.
Springer, New York.
Dudley, R. M. (1984). Course Empirical Processes, Vol. 1097 Lecture Notes Mathematics, pp. 2142. Springer-Verlag.
Dudley, R. M. (1989). Real Analysis Probability. Wadsworth & Brooks/Cole, California.
196

fiA ODEL NDUCTIVE B IAS L EARNING

Gelman, A., Carlin, J. B., Stern, H. S., & Rubim, D. B. (Eds.). (1995). Bayesian Data Analysis.
Chapman Hall.
Good, I. J. (1980). history hierarchical Bayesian methodology. Bernardo, J. M.,
Groot, M. H. D., Lindley, D. V., & Smith, A. F. M. (Eds.), Bayesian Statistics II. University
Press, Valencia.
Haussler, D. (1992). Decision theoretic generalizations pac model neural net
learning applications. Information Computation, 100, 78150.
Heskes, T. (1998). Solving huge number similar tasks: combination multi-task learning
hierarchical Bayesian approach. Shavlik, J. (Ed.), Proceedings 15th International
Conference Machine Learning (ICML 98), pp. 233241. Morgan Kaufmann.
Intrator, N., & Edelman, S. (1996). make low-dimensional representation suitable
diverse tasks. Connection Science, 8.
Kechris, A. S. (1995). Classical Descriptive Set Theory. Springer-Verlag, New York.
Khan, K., Muggleton, S., & Parson, R. (1998). Repeat learning using predicate invention. Page,
C. D. (Ed.), Proceedings 8th International Workshop Inductive Logic Programming
(ILP-98), LNAI 1446, pp. 65174. Springer-Verlag.
Langford, J. C. (1999). Staged learning. Tech. rep., CMU, School Computer Science.
http://www.cs.cmu.edu/ jcl/research/ltol/staged latest.ps.



Mitchell, T. M. (1991). need biases learning generalisations. Dietterich, T. G., &
Shavlik, J. (Eds.), Readings Machine Learning. Morgan Kaufmann.
Parthasarathy, K. R. (1967). Probabiliity Measures Metric Spaces. Academic Press, London.
Pollard, D. (1984). Convergence Stochastic Processes. Springer-Verlag, New York.
Pratt, L. Y. (1992). Discriminability-based transfer neural networks. Hanson, S. J.,
Cowan, J. D., & Giles, C. L. (Eds.), Advances Neural Information Processing Systems 5,
pp. 204211. Morgan Kaufmann.
Rendell, L., Seshu, R., & Tcheng, D. (1987). Layered concept learning dynamically-variable
bias management. Proceedings Tenth International Joint Conference Artificial
Intelligence (IJCAI 87), pp. 308314. IJCAI , Inc.
Ring, M. B. (1995). Continual Learning Reinforcement Environments. R. Oldenbourg Verlag.
Russell, S. (1989). Use Knowledge Analogy Induction. Morgan Kaufmann.
Sauer, N. (1972). density families sets. Journal Combinatorial Theory A, 13,
145168.
Sharkey, N. E., & Sharkey, A. J. C. (1993). Adaptive generalisation transfer knowledge.
Artificial Intelligence Review, 7, 313328.
197

fiBAXTER

Silver, D. L., & Mercer, R. E. (1996). parallel transfer task knowledge using dynamic
learning rates based measure relatedness. Connection Science, 8, 277294.
Singh, S. (1992). Transfer learning composing solutions elemental sequential tasks. Machine Learning, 8, 323339.
Slud, E. (1977). Distribution inequalities binomial law. Annals Probability, 4, 404412.
Suddarth, S. C., & Holden, A. D. C. (1991). Symolic-neural systems use hints developing complex systems. International Journal Man-Machine Studies, 35, 291311.
Suddarth, S. C., & Kergosien, Y. L. (1990). Rule-injection hints means improving network performance learning time. Proceedings EURASIP Workshop Neural
Networks Portugal. EURASIP.
Sutton, R. (1992). Adapting bias gradient descent: incremental version delta-bar-delta.
Proceedings Tenth National Conference Artificial Intelligence, pp. 171176. MIT
Press.
Tate, R. F. (1953). double inequality normal distribution. Annals Mathematical
Statistics, 24, 132134.
Thrun, S. (1996). learning n-th thing easier learning first?. Advances Neural
Information Processing Systems 8, pp. 640646. MIT Press.
Thrun, S., & Mitchell, T. M. (1995). Learning one thing. Proceedings International
Joint Conference Artificial Intelligence, pp. 12171223. Morgan Kaufmann.
Thrun, S., & OSullivan, J. (1996). Discovering structure multiple learning tasks: TC algorithm. Saitta, L. (Ed.), Proceedings 13th International Conference Machine
Learning (ICML 96), pp. 489497. Morgen Kaufmann.
Thrun, S., & Pratt, L. (Eds.). (1997). Learning Learn. Kluwer Academic.
Thrun, S., & Schwartz, A. (1995). Finding structure reinforcement learning. Tesauro, G.,
Touretzky, D., & Leen, T. (Eds.), Advances Neural Information Processing Systems, Vol. 7,
pp. 385392. MIT Press.
Utgoff, P. E. (1986). Shift bias inductive concept learning. Machine Learning: Artificial
Intelligence Approach, pp. 107147. Morgan Kaufmann.
Valiant, L. G. (1984). theory learnable. Comm. ACM, 27, 11341142.
Vapnik, V. N. (1982). Estimation Dependences Based Empirical Data. Springer-Verlag, New
York.
Vapnik, V. N. (1996). Nature Statistical Learning Theory. Springer Verlag, New York.

198


