Journal Artificial Intelligence Research 12 (2000) 339{386

Submitted 12/99; published 6/00

Reasonable Forced Goal Orderings Use
Agenda-Driven Planning Algorithm

jana koehler@ch.schindler.com

Jana Koehler
Schindler Lifts, Ltd.
R & Technology Management
6031 Ebikon, Switzerland
Jorg Hoffmann
Institute Computer Science
Albert Ludwigs University
Georges-Kohler-Allee, Geb. 52
79110 Freiburg, Germany

hoffmann@informatik.uni-freiburg.de

Abstract

paper addresses problem computing goal orderings, one
longstanding issues AI planning. makes two new contributions. First, formally
defines discusses two different goal orderings, called reasonable
forced ordering. orderings defined simple STRIPS operators well
complex ADL operators supporting negation conditional effects. complexity
orderings investigated practical relevance discussed. Secondly, two
different methods compute reasonable goal orderings developed. One
based planning graphs, investigates set actions directly. Finally,
shown ordering relations, derived given set goals
G , used compute so-called goal agenda divides G ordered set
subgoals. planner then, principle, use goal agenda plan increasing
sets subgoals. lead exponential complexity reduction, solution
complex planning problem found solving easier subproblems. Since polynomial
overhead caused goal agenda computation, potential exists dramatically speed
planning algorithms demonstrate empirical evaluation, use
method IPP planner.
1. Introduction

effectively plan interdependent subgoals focus AI planning
research long time. Starting early work ABSTRIPS (Sacerdoti, 1974)
conjunctive-goal planning problems (Chapman, 1987), quite number approaches
presented complexity problems studied. today,
planners made progress solving bigger planning instances scalability
classical planning systems still problem.
paper, focus following problem: Given set conjunctive goals,
define detect ordering relation subsets original goal set? arrive
ordering relation subsets, first focus atomic facts contained
goal set. formally define two closely related ordering relations atomic goals,
c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiKoehler & Hoffmann
call reasonable forced ordering, study complexity. turns
hard decide.
Consequently, introduce two ecient methods used approximate
reasonable goal orderings. definitions first given simple STRIPS domains,
desired theoretical properties easily proven. Afterwards, extend definitions
ADL operators (Pednault, 1989) handling conditional effects negative preconditions,
discuss invest effort trying find forced orderings.
show set ordering relations atomic goals used divide
goal set disjunct subsets, subsets ordered respect
other. resulting sequence subsets comprises so-called goal agenda,
used control agenda-driven planning algorithm.
method, called Goal Agenda Manager, implemented context IPP
planning system, show potential exponentially reducing computation times
certain planning domains.
paper organized follows: Section 2 introduces motivates reasonable
forced goal orderings. Starting simple STRIPS operators, formally defined,
complexity investigated. Section 3, present two methods, compute approximation reasonable ordering discuss orderings
practical point view. section concludes extension definitions ADL
operators conditional effects. Section 4 shows planning system benefit
ordering information computing goal agenda guides planner. define
subsets goals ordered respect discuss goal
agenda affect theoretical properties, particular completeness planning
algorithm. Section 5 contains empirical evaluation work, showing results
obtained using goal agenda IPP. Section 6 summarize approach light
related work. paper concludes outlook possible future research directions
Section 7.
2. Ordering Relations Atomic Goals

start, investigate simple STRIPS domains allowing sets atoms
describe states, preconditions, add delete lists operators.
Definition 1 (State) set ground atoms denoted P . state 2 2
P

subset ground atoms.

Note states assumed complete, i.e., always know atom p whether
p 2 p 62 holds. assume operator schemata ground, i.e.,
talk actions.
Definition 2 (Strips Action) STRIPS action usual form
pre(o) ! ADD add(o) DEL del(o)
pre(o) preconditions o, add(o) Add list del(o) Delete
list action, set ground atoms. assume del(o) \ add(o) = ;.
result applying STRIPS action state defined usual:
340

fiOn Reasonable Forced Goal Orderings

Result(s; o) :=



(s [ add(o)) n del(o) pre(o)
otherwise



pre(o) holds, action said applicable s. result applying
sequence one action state recursively defined
Result(s; ho1 ; : : : ;

i) := Result(Result(s; ho1 ; : : : ; 1 i); ):
Definition 3 (Planning Problem) planning problem (O; ; G ) triple
set actions, (the initial state) G (the goals) sets ground atoms.
plan P ordered sequence actions. actions plan taken certain
action set O, denote writing P .
n

n

n

Note define plan sequence actions, sequence parallel steps,
done graphplan (Blum & Furst, 1997), example. makes subsequent
theoretical investigation readable. results directly carry parallel plans.
Given two atomic goals B , various ways define ordering relation
imagined. First, one distinguish domain-specific domainindependent goal ordering relations. although domain-specific orderings
effective, need redeveloped single domain. Therefore, one particular
interested domain-independent ordering relations broader range applicability.
Secondly, following Hullem et al. (1999), one distinguish goal selection goal
achievement order. first ordering determines order planner works
various atomic goals, second one determines order, solution
plan achieves goals. paper, compute ordering latter type.
agenda-driven planning approach propose later paper, orderings
coincide anyway. goals achieved first plan planner
works first.
following scenario motivates achievement order goals possibly
defined. Given two atomic goals B , solution plan exists, let us assume
planner achieved goal A, i.e., arrived state s( : ) ,
holds, B hold yet. Now, exists plan executable s( : )
achieves B without ever deleting A, solution found. plan
found, two possible reasons exist:
1. problem unsolvable|achieving first leads planner deadlock situation. Thus, planner forced achieve B simultaneously A.
2. existing solution plans destroy temporarily order achieve B .
then, achieved first. Instead, seems reasonable achieve
B simultaneously sake shorter solution plans.
first situation, ordering \B simultaneously A" forced inherent properties planning domain. second situation, ordering \B
simultaneously A" appears reasonable order avoid non-optimal plans. Consequently, define two goal orderings, called forced reasonable ordering.
sake clarity, first give basic definitions.
A;

B

A;

341

B

fiKoehler & Hoffmann
Definition 4 (Reachable State) Let (O; ; G ) planning problem let P

set ground atoms occur problem. say state P reachable, iff
exists sequence ho1 ; : : : ; actions = Result(I ; ho1 ; : : : ; i)
holds.
n

n

Definition 5 (Generic State s( : ) ) Let (O; ; G ) planning problem. s( :
A;

B

A;

B

)

denote reachable state achieved, B false,
i.e., B 62 s( : ) sequence actions ho1 ; : : : ; s( : ) =
Result(I ; ho1 ; : : : ; i), 2 add(o ).
A;

n

B

n

A;

B

n

One imagine s( : ) state incomplete information.
states represents satisfy j= A; :B , atoms p 2 P p 6= A; B
adopt arbitrary truth values.
Definition 6 (Reduced Action Set ) Let (O; ; G ) planning problem, let
A;

B



2 G atomic goal. denote set actions delete A,
i.e., = fo 2 j 62 del(o)g.




prepared define exactly mean forced reasonable goal orderings.
Definition 7 (Forced Ordering ) Let (O; ; G ) planning problem, let A; B 2
G two atomic goals. say forced ordering B A, written
f

B A,
f

: :9 P : B 2 Result(s( : ) ; P )
Definition 7 satisfied, plan achieving B must achieve B
simultaneously A, otherwise encounter deadlock, rendering
problem unsolvable.
Definition 8 (Reasonable Ordering ) Let (O; ; G ) planning problem, let
A; B 2 G two atomic goals. say reasonable ordering B

8 s(

:

A;

B

)

A;

B

r

A, written B A,
r

8 s( : ) : :9 P OA : B 2 Result(s( : ) ; P OA )
Definition 8 gives B meaning if, goal achieved,
A;

B

A;

B

r

plan anymore achieves B without|at least temporarily|destroying A, B
goal prior A.
remark obviously B implies B A, vice versa. make
slightly less obvious observation point: formulae Definitions 7 8 use
universal quantification states s( : ) . planning problem
state all, formulae satisfied goals B get ordered, i.e., B
B follow, respectively. case, however, much information gained
goal ordering B , sequence actions achieve B prior
simultaneously A|A cannot achieved B still false. Thus
case, ordering relations B B trivial sense reasonable
planner would invest much effort considering goals B ordered way
round anyway.
r

f

A;

B

f

r

f

r

342

fiOn Reasonable Forced Goal Orderings
Definition 9 (Trivial Ordering Relation) Let (O; ; G ) planning problem, let
A; B 2 G two atomic goals. ordering relation B
state s( : ) .
A;



f

B called
r

trivial iff

B

paper, usually consider forced reasonable goal orderings non-trivial
orderings make distinction explicit so.
Definitions 7 8 seem deliver promising candidates achievement order.
Unfortunately, hard test: turns corresponding decision
problems PSPACE hard.
Theorem 1 Let F ORDER denote following problem:

Given two atomic facts B , well action set initial state ,
B hold ?
f

Deciding F ORDER PSPACE-hard.

Proof: proof proceeds polynomially reducing

PLANSAT (Bylander, 1994)|the
decision problem whether exists solution plan given arbitrary STRIPS
planning instance|to problem deciding F ORDER.

Let , G , denote initial state, goal state, action set arbitrary
STRIPS instance. Let A, B , C new atomic facts contained instance
far. build new action set initial state F ORDER instance setting

8
<
O0 := [ :

o1
o2




G

9
! ADD fAg DEL fC g; =
! ADD DEL fAg; ;
! ADD fB g DEL ;

= fC g
= fAg
=G



0 := fC g
definitions, reaching B equivalent solving original problem.
way round, unreachability B A|forced ordering B A|is equivalent
unsolvability original problem. order prove this, consider following:
way achieving applying 1 0 . Consequently, state s( : )
fAg, cf. Definition 5. Thus starting assumption B valid, apply
following equivalences:
f



A;

B

f

B
f

,
,
,
,

8 s( : ) : :9 P O0 : B 2 Result(s( : ) ; P O0 )
cf. Definition 7
0
0
:9 P : B 2 Result(fAg; P )
fAg reachable state s( : )
:9 P : G Result(I ; P )
definition 0
solution plan exists ; G given
A;

B

A;

B

A;

343

B

fiKoehler & Hoffmann
Thus, complement PLANSAT polynomially reduced F ORDER. PSPACE
= co-PSPACE, done.
Theorem 2 Let R ORDER denote following problem:

Given two atomic facts B , well action set initial state ,
B hold ?
Deciding R ORDER PSPACE-hard.
r

Proof: proof proceeds polynomially reducing PLANSAT R ORDER.

Let , G , initial state, goal state, action set arbitrary
STRIPS planning instance. Let A, B , C , new atomic facts contained
instance far. define new action set O0 setting
8
9
1 = fC g
! ADD fA; Dg DEL fC g; =
<
O0 := [ : 2 = fA; Dg ! ADD DEL fDg;
;
=G
! ADD fB g DEL ;



G

new initial state

0 := fC g

proof Theorem 1, intention behind definitions make solvability
original problem equivalent reachability B A. reasonable orderings,
reachability concerned actions delete A, need safety
condition D.
Precisely, way achieve applying 1 0, i.e., per Definition 5
state s( : ) fA; Dg. action new operator set O0 deletes A,
following sequence equivalences.


A;

B

B
8 s( : ) :9 P OA0 : B 2 Result(s( : ); P OA0 )
:9 P OA0 : B 2 Result(fA; Dg; P OA0 )
r

,
,
, :9 P O0 : B 2 Result(fA; Dg; P O0 )
, :9 P G Result(I ; P )
, solution plan exists ; G ;
A;

B

A;

B

cf. Definition

fA; Dg reachable state s( : )
action 0 deletes
definition 0
A;

B

Thus, complement PLANSAT polynomially reduced R ORDER.
PSPACE = co-PSPACE, done.
Consequently, finding reasonable forced ordering relations atomic goals
already hard original planning problem appears unlikely planner
gain advantage that. possible way dilemma define new
ordering relations, decided polynomial time are, ideally, sucient
existence reasonable forced goal orderings. following, introduce two
orderings.
344

8

fiOn Reasonable Forced Goal Orderings
3. Computation Goal Orderings

section,
1. define goal ordering , computed using graphplan's exclusivity
information facts. prove ordering sucient
decided polynomial time (the subscript \e" stands \ecient").
2. define goal ordering , computed based heuristic method
much faster computation based graphplan, delivers powerful
goal ordering information (the subscript \h" stands \heuristic").
3. discuss currently available benchmark planning domains contain forced orderings, i.e., fail providing problem decomposition them.
4. show orderings extended handle expressive ADL operators.
e

r

h

f

3.1 Reasonable Goal Orderings based graphplan

goal ordering always computed specific planning problem involving initial
state , goal set G fA; B g, set ground actions. order develop
ecient computational method, proceed two steps now:
1. compute knowledge generic state s( : ) .
2. define relation investigate theoretical properties. particular,
prove implies .
A;

B

e

e

r

state s( : ) represents states reachable ,
achieved, B hold. Given information s( : ) , one derive
additional knowledge it. particular, possible determine subset atoms F,
one definitely knows F \ s( : ) = ; must hold. One method determine F
obtained via computation invariants, i.e., logical formulae hold reachable
states, cf. (Fox & Long, 1998). determined invariants, one assumes
holds, B not, computes logical implications. Another possibility
simply use graphplan (Blum & Furst, 1997). Starting O, planning graph
built graph leveled time step. proposition level time
step represents set states, superset states reachable
applying actions O. atoms, marked mutually exclusive (Blum
& Furst, 1997) level never hold state satisfying A. Thus, cannot
hold s( : ) . denote set F |the False set respect returned
1
graphplan.
F
:= fp j p exclusive graph leveled offg
(1)
Note planning graph grown given O, used
determine F sets atomic goals 2 G .
A;

B

A;

A;

A;

B

B


GP

B


GP



GP

1. assume reader familiar graphplan, planning system well known
planning research community. Otherwise, (Blum & Furst, 1997) provide necessary background.

345

fiKoehler & Hoffmann

\ = ; holds states
using actions O.
Lemma 1



FGP





satisfying 2 reachable


proof follows immediately definitions \level-off" \two propositions
mutual exclusive" given (Blum & Furst, 1997).
provide simple test sucient existence reasonable ordering
B two atomic goals B .
Definition 10 (Ecient Ordering ) Let (O; ; G fA; B g) planning problem.
r

e

Let F



GP

False set A. ordering B holds
e

8 2 : B 2 add(o) ) pre(o) \ F 6= ;

GP



means, B ordered reduced action set contains actions,
either B add lists do, require precondition
contained False set. preconditions never hold state satisfying
thus, actions never applicable.
Theorem 3
B A)B
e

r

Proof: Assume B 6 A, i.e., B 2 Result(s( : ) ; P OA ) reachable state s( :
r

A;

B

A;

B

)

2 s( : ) , B 62 s( : ) , Plan P OA = ho1 ; : : : ; 2 1 n.
62 del(o ) (Definition 6),
2 Result(s( : ) ; ho1 ; : : : ; i) 0 n
and, Lemma 1,
F
\ Result(s( : ) ; ho1 ; : : : ; i) = ; 0 n
(2)
Furthermore, B 62 s( : ) , B 2 Result(s( : ) ; ho1 ; : : : ; i), must
step makes B true, i.e.,
91 k n : B 62 Result(s( : ); ho1 ; : : : ; 1i) ^ B 2 Result(s( : ); ho1 ; : : : ; i)
step, obviously B 2 add(o ) consequently, definition
B A, pre(o ) \ F 6= ;. Now, must applicable state
executed (otherwise would add anything state), preconditions
must hold, i.e., pre(o ) Result(s( : ) ; ho1 ; : : : ; 1 i). immediately leads F \
Result(s( : ) ; ho1 ; : : : ; 1 i) 6= ;, contradiction Equation (2).
Quite obviously, ordering decided polynomial time.
A;

B

A;

n

B







A;



B



A;

GP

A;



B

B

A;

A;

n

B

k

B

A;

B

k

k

e


GP

k

k

k

k

A;

B

A;


GP

k

B

k

e

Theorem 4 Let E ORDER denote following problem:

Given two atomic facts B , well initial state action set O,

B hold ?
e

Then, E ORDER decided polynomial time:
346

E ORDER

2 P.

fiOn Reasonable Forced Goal Orderings
Proof: begin with, need show computing F

takes polynomial time.
results (Blum & Furst, 1997), follows directly building planning graph
polynomial jIj, jOj, l t, l maximal length precondition, add
delete list action, number time steps built. Taking l parameter
input size, remains show planning graph levels polynomial
number time steps. Now, planning graph leveled time steps
+ 1 neither set facts number exclusion relations change.
two subsequent time steps, set facts increase|facts already occuring
graph remain there|and number exclusions decrease|non-exclusive facts
non-exclusive subsequent layers. Thus, maximal number time steps
built graph leveled dominated maximal number changes
occur two subsequent layers, dominated maximal number
facts plus maximal number exclusion relations. maximal number facts
O(jIj + jOj l), maximal number exclusions O((jIj + jOj l)2 ), square
maximal number facts.
computed F polynomial time, testing B involves looking actions
O, rejecting either
delete A, decidable time O(l),
precondition, element F , decidable time O(l (jIj + jOj l)).
Thus additional runtime test, O(jOj l (jIj + jOj l)).

GP


GP

e


GP

Let us consider following example, illustrates computation using
common representational variant blocks world actions stack, unstack,
pickup, putdown blocks:
e

pickup(?ob)

clear(?ob) on-table(?ob) arm-empty()

! ADD holding(?ob)

DEL clear(?ob) on-table(?ob) arm-empty().

putdown(?ob)
holding(?ob)

! ADD clear(?ob) arm-empty() on-table(?ob)
DEL holding(?ob).

stack(?ob,?underob)

clear(?underob) holding(?ob)

unstack(?ob,?underob)

! ADD arm-empty() clear(?ob) on(?ob,?underob)
DEL clear(?underob) holding(?ob).

on(?ob,?underob) clear(?ob) arm-empty()

! ADD holding(?ob) clear(?underob)

DEL on(?ob,?underob) clear(?ob) arm-empty().

Given simple task stacking three blocks:
initial state: on-table(a) on-table(b) on-table(c)
goal state: on(a,b) on(b,c)
347

fiKoehler & Hoffmann
reasonable ordering two atomic goals? Intuitively, blocks world
domain possesses natural goal ordering, namely planner start building
tower bottom top way round.2
Let us first investigate whether relation on(a; b) on(b; c) holds. Vividly speaking,
asks whether still possible stack block b on(b; c) achieved.
first step, run graphplan find atoms exclusive on(b; c)
planning graph, corresponds problem, leveled off. result
e

(

)

b;c

FGP

= fclear(c), on-table(b), holding(c), holding(b), on(a,c), on(c,b), on(b,a)g

One observes immediately atoms never true state satisfies

on(b; c).

Secondly, remove ground actions delete on(b; c) (in case, action
( ).
ready test on(a; b) on(b; c) holds. action, add
on(a; b) stack(a,b). preconditions holding(a) clear(b), neither
member F ( ) . test fails get on(a; b) 6 on(b; c).
next step, test whether on(b; c) on(a; b) holds. graphplan returns
following False set:

unstack(b,c) satisfies condition) obtain reduced action set

b;c

e

b;c

e

GP

e

(

)

a;b

FGP

= fclear(b), on-table(a), holding(b), holding(a), on(a,c), on(c,b), on(b,a)g

action unstack(a,b) contained ( ) deletes on(a; b).
action adds on(b; c) stack(b,c). needs preconditions clear(c)
holding(b). second precondition holding(b) contained set false facts,
i.e., holding(b) 2 F ( ) thus, conclude on(b; c) on(a; b). Altogether,
on(a; b) 6 on(b; c) on(b; c) on(a; b), correctly ects intuition b
needs stacked onto c stacked onto b.
Although appears impose strict conditions domain order derive
reasonable goal ordering, succeeds finding reasonable goal orderings available test
domains orderings exists. example, tyreworld, bulldozer problems,
shopping problem (Russel & Norvig, 1995), fridgeworld, glass domain,
tower hanoi domain, link-world, woodshop. disadvantage
computational resources requires, since building planning graphs, theoretically
polynomial, quite time- memory-consuming thing do.3
Therefore, next section presents fast heuristic computation goal orderings,
analyzes domain actions directly need build planning graphs anymore.
a;b

a;b

e

GP

e

e

e

2. Note goals specify block c go, leave planner.
3. recent implementations planning graphs, example developed STAN (Fox &
Long, 1999) IPP 4.0 (Koehler, 1999) build graphs explicitly anymore orders
magnitude faster original graphplan implementation, still computation planning
graph takes almost time needed determine e relations.

348

fiOn Reasonable Forced Goal Orderings
3.2 Reasonable Goal Orderings derived Fast Heuristic Method

One analyze available actions directly using method call Direct Analysis
(DA). determines initial value F computing intersection delete lists
actions contain add list, defined following equation.


FDA

\

:=


2O 2
;

( )

del(o)

(3)

add

atoms set false state achieved:
deleted state description independently action used add A.
short example, let us consider two actions

! ADD fAg DEL fC; Dg
! ADD fA; C g DEL fDg
atom deleted actions, thus element initially
contained F .
However, Equation (3) says added atoms F
deleted. say anything whether might possible reestablish atoms
F . One easily imagine actions exist, leave true,
time add atoms. case, reachable states atoms
F hold.
Now, goal derive ordering relation easily computed,
ideally, relation, sucient relation. Therefore, want make
sure atoms F really false state achieved.
arrive approximation atoms remain false performing fixpoint reduction
F set, removing atoms achievable following sense.

DA


DA


DA


DA

e

r



DA



DA

Definition 11 (Achievable Atoms) atom p achievable state given
action set (written A(s; p; O))
p2s

_ 9 2 : p 2 add(o) ^ 8 p0 2 pre(o) : A(s; p0; O)

definition says atom p achievable state holds s,
exists action domain, adds p whose preconditions achievable
s. necessary condition existence plan P state
p holds.
Lemma 2 9 P : p 2 Result(s; P ) ) A(s; p; O)
Proof: atom p must either already contained state s, added

step P . second case, preconditions need established
P way. Thus p preconditions step, adds it, achievable
sense Definition 11.
349

fiKoehler & Hoffmann
two obvious diculties Definition 11: First, p 2 must tested.
complete knowledge state s, cause problems. case,
however, generic state s( : ) cannot decide whether arbitrary
atom contained not. Secondly, observe infinite regression preconditions,
must tested achievability.
first problem, turns good heuristic simply assume p 62 s,
i.e., test performed all. second problem, order avoid infinite
looping \achievable"-test, one needs terminate regression preconditions
particular level. point question far regress? quick approximation
simply decides \achievable" first recursive call.
A;

B

Definition 12 (Possibly Achievable Atoms) atom p possibly achievable given
action set (written pA(p; O))
9 2 : p 2 add(o) ^ 8 p0 2 pre(o) :

9 o0 2 : p0 2 add(o0 )

holds, i.e., action adds p preconditions add effects
actions O.

assumption justified none atoms p contained state s,
possibly achievable necessary condition achievable.
Lemma 3 Let state p 62 8o 2 : p 2 add(o) ) pre(o) \ = ;

holds.

A(s; p; O) ) pA(p; O)
Proof: A(s; p; O) p 62 s, know step 2 O, p 2 add(o),

8 p0 2 pre(o) A(s; p0; O). know pre(o) \ = ;, p0 2 pre(o)
must achiever o0 2 : p0 2 add(o0 ).

condition facts p must contained state seems
rather rigid. Nevertheless, condition possibly achievable delivers good results
benchmark domains easy decide. use test

perform fixpoint reduction set F
decide whether atomic goal B ordered A.

DA

fixpoint reduction, depicted Figure 1 below, uses approximative test pA(f; )
remove facts F achieved. finds facts certain
restrictions, see below. side effect fixpoint algorithm, obtain set
actions method assumes applicable state s( : ) . order B
iff cannot possibly achieved using actions.

DA

A;

350

B

fiOn Reasonable Forced Goal Orderings
:= F
:= n fo j F \ pre(o) 6= ;g
fixpoint reached := false
:fixpoint reached
fixpoint reached := true
f 2 F
pA(f; )


F := F n g
:= n fo j F \ pre(o) 6= ;g
fixpoint reached := false
F



DA




endif
endfor
endwhile
return F ,

Figure 1: Quick, heuristic fixpoint reduction set F .

DA

computation checks whether atoms F , initially set F , possibly
achievable using actions, delete require atoms
F precondition. Achievable atoms removed F , gets updated
accordingly. one iteration, F change, fixpoint reached, i.e., F
decrease increase|the final sets F false facts
applicable actions returned.
Let us illustrate fixpoint computation short example consisting empty
initial state, goals fA; B g, following set actions


DA

op1:
op2:
op3: f C g
op4: f g

!
!
!
!

ADD f g
ADD fA, C g
ADD f g
ADD f B g

DEL f C, g
DEL f g

assuming achieved, obtain F = F = fDg initial
value False set, since atom op1 op2 delete adding A.
Figure 2 illustrates hypothetical planning process. Starting empty initial state
trying achieve first, get two different states s( : ) holds.
atom hold thus states, action applicable
requires precondition. excludes op4 , yielding initial action set
= fop1; op2; op3g. Now, op4 action add B . Therefore, used
action set see B still achieved, would find case.
Consequently, without performing fixpoint computation, would order B A.
seen Figure 2, would reasonable ordering: plan
hop3 ;op4i achieves B state s( : ) = Result(I ;op2) without destroying A.
fixpoint computation works us around problem follows: action op3, add precondition op4 without deleting A. checking
pA(D; ) first iteration, fixpoint procedure finds action. checks


DA

A;



A;

351

B

B

fiKoehler & Hoffmann
whether preconditions op3 achievable sense added another action. case since precondition C added op2. Thus,
removed F , becomes empty now. action op4 put back set ,
becomes identical action set . set, turn, identical
original action set action deletes A. fixpoint process terminates B
ordered achieved using action op4. correctly ects
fact exists plan state s( : ) = Result(I ; hop2i) = fC; Ag
state satisfies B without destroying A.


A;

B

0/

Deadlock

op1

op2



C,
op3
C, A,

holds state satisfying

op4
C, A, D, B

plan B

Figure 2: example illustrating need fixpoint computation.
already pointed out, intention behind fixpoint procedure following:
Starting state s( : ) , want know facts become true without
destroying A, consequently, actions become applicable. first step,
actions use facts F applicable, facts
deleted state description added. However, actions may make facts
F true, want remove facts F . manage find facts
made true without destroying A, final set F contain
facts hold state reachable s( : ) without destroying A. case,
final action set contain actions applied s( : ) ,
safely use action set determine whether another goal B still achieved
not.
However, use approximative test pA(f; O) f 2 F find
fact current F set achievable, may facts achievable without
destroying A, remain set F . could exclude actions set
safely applied s( : ). certain restrictions, however,
prove happen. order so, need impose restriction
particular state s( : ) , achieved goal A: none preconditions
actions, add facts contained F , occur state s( : ) , fixpoint
procedure remove facts F achievable without destroying A.
use property fixpoint procedure later show heuristic ordering relation
approximates reasonable orderings.
A;

B



DA


DA


DA

A;

B

A;

A;

A;

B

B


DA

A;



DA

352

B

B

fiOn Reasonable Forced Goal Orderings
Lemma 4 Let (O; ; G ) planning problem, let 2 G atomic goal. Let
s( : ) reachable state achieved. Let P OA = ho1 ; : : : ;
sequence actions destroying A. Let F set facts returned
fixpoint computation depicted Figure 1.
A;

n

B

8f 2 F


DA

: 8o 2 : f 2 add(o) ) pre(o) \ s( : ) = ;


A;

()

B

fact F holds state reached applying P OA , i.e.,
Result(s( : ) ; P OA ) \ F = ;
A;

B

Proof:

Let F denote state fact action sets, respectively, j iterations
algorithm depicted Figure 1. F decreases computation,


F F j . Let s0 ; : : : ; denote sequence states encountered
executing P OA = ho1 ; : : : ; s( : ) , i.e., s0 = s( : ) = Result(s 1 ; ho i)
0 n. assume action applicable state 1 , i.e., pre(o ) 1 .
Otherwise, cause state transition, skip P OA . Obviously,
= Result(s( : ) ; P OA ), need show \ F = ;. proof proceeds
induction length n P OA .
n = 0: P OA = hi = s0 = s( : ) . facts F deleted state
description added, \ F = ;. F = F0 F F0 ,
proposition follows immediately.
n ! n + 1: P OA = ho1 ; : : : ; ; +1 i. induction hypothesis, know
\ F = ; 0 n. need show +1 \SF = ;.
Let j step fixpoint iteration F \ =0 becomes empty, i.e., j
denotes iteration intersection states ; n F empty
first time. iteration exists, intersections \ F n
empty.
action ; 1 n + 1 applicable state 1 , i.e., pre(o ) 1 ,
thus pre(o ) \ F = ; actions P OA . Therefore, actions contained
, set contains actions whose intersection F empty.
Let us focus facts state +1 . facts achieved executing P OA
s( : ) . words, plan s( : ) facts.
seen, plan consists actions . Applying Lemma 2 facts p 2 +1
using s( : ) P OA (= P Oj ), know facts p achievable using actions
.
j

j

n

j

n

A;

B

A;



B















n

A;

n

B

n

A;


DA

B

n

n





DA

DA

n



n

j



;:::;n





j















j



j

j

n

A;

B

A;

B

n

j

A;

B

j

: A(s( : ) ; p; )
show facts f 2 +1 interested in, namely F facts
added +1 still contained F , possibly achievable using actions
. Let f fact f 2 +1 , f 2 F . apply Lemma 3 using s( : ) , f ,

8p 2

+1

n

A;

B

j

n

n

j

j

n

j

353

A;

B

fiKoehler & Hoffmann

O. apply Lemma 3 obviously f 62 s( : ) , 8o 2 : f 2 add(o) )
pre(o) \ s( : ) = ; prerequisite (). A(s( : ) ; p; ), arrive
8f 2 +1 \ F : pA(f; O)
A;

j

A;

B

A;

n

B

j

B

j

j

j

remains proven facts f removed F
fixpoint computation. argumentation above, sucient show
facts f 2 +1 \ F get tested pA(f; ) iteration j +1 fixpoint computation.
tests succeed lead +1 \ F+1 = ;, yielding, desired, +1 \ F = ;.
Remember F+1 F . two cases, need consider:
1. j = 0: intersections \ F0 initially empty, i.e., \ F = ; 0 n.
case, facts f 2 +1 \ F tested pA(f; O0 ) iteration j + 1 = 1
fixpoint computation.
2. j > 0: case, least one intersections \ F became empty iteration
j definition j , i.e., least one fact removed F iteration.
Therefore, fixpoint reached yet, computation performs
least one iteration, namely iteration j + 1. facts F tested
iteration, particular facts f 2 +1 \ F .
observations, induction complete proposition proven.
already said, simply order B A, possibly achievable
using action set resulted fixpoint computation. ordering relation
(where h stands \heuristic") obtained way approximates reasonable goal
ordering .
Definition 13 (Heuristic Ordering ) Let (O; ; G fA; B g) planning problem.
n

j

j

n

n

j

j



n





DA


DA



j

j

n

j

h

r

Let set actions obtained performing fixpoint computation
shown Figure 1.
ordering B holds
:pA(B; O)
h

h

reached particular state s( : ) assumptions made
fixpoint computation test pA(B; ) justified, possibly achievable sucient condition non-existence plan B
temporarily destroy A.
Theorem 5 Let (O; ; G ) planning problem, let A; B 2 G two atomic goals. Let
A;

B

s( : ) reachable state achieved, B still false, i.e., B 62
s( : ) . Let F sets facts actions, respectively, derived
fixpoint computation shown Figure 1.
A;

B

A;

B

8f 2 F [ fB g : 8o 2 : f 2 add(o) ) pre(o) \ s(


DA





:pA(B; O) ) :9P OA :

:

A;

B

B 2 Result(s( : ) ; P OA )

354

A;

B

)

=;

()

fiOn Reasonable Forced Goal Orderings
Proof: Assume plan P OA = ho1 ; : : : ; destroy A,
n

achieves B , i.e., B 2 Result(s( : ) ; ho1 ; : : : ; i). restriction ()
facts F , Lemma 4 applied action sequence ho1 ; : : : ; 1 yielding
Result(s( : ) ; ho1 ; : : : ; 1 i) \ F = ;. Consequently, either
applicable Result(s( : ) ; ho1 ; : : : ; 1i),
preconditions contained Result(s( : ); ho1 ; : : : ; 1 i), yielding pre(o ) \

F = ;.
first case, simply skip effects. second case,
2 follows. Thus, plan constructed actions achieves B
s( : ) . Applying Lemma 2 leads us A(s( : ) ; B; ). B 62 s( : ) .
know, () respect B , , 8o 2 : B 2 add(o) )
pre(o) \ s( : ) = ; holds. Therefore, apply Lemma 3 arrive pA(B; ),
contradiction.
return blocks world example show computation proceeds.
Let us first investigate whether on(a; b) on(b; c) holds. initial value F ( )
obtained delete list stack(b,c) action, one adds
goal.
A;

n

B





DA

A;

B





A;



B

A;



B







A;

B

A;

B

A;

B



A;

B

h

b;c

h

DA

= fclear(c); holding(b)g
Intuitively, immediately clear neither facts ever hold state
on(b; c) true: b c, c clear gripper cannot hold b.
turns fixpoint computation respects intuition leaves set F ( )
unchanged, yielding F = fclear(c); holding(b)g. repeat fixpoint process
detail here, reconstructed Figure 1 details necessary
understanding correct ordering relations derived. short, facts
achievers reduced action set, need preconditions
achiever available. example, holding(b) achieved either unstack
pickup action. either need b stand another block stand table.
actions achieve facts need holding(b) true thus excluded
reduced action set.
finishing fixpoint computation, planner tests pA(on(a; b); ),
contains actions except delete on(b; c) use clear(c) holding(b)
precondition. finds action stack(a,b) adds on(a; b). preconditions
action holding(a) clear(b). conditions added actions
pickup(a) unstack(a,b), respectively, contained : neither
needs c clear b gripper. Thus, test finds fact, on(a; b)
possibly achievable using actions , ordering derived, i.e., on(a; b) 6
on(b; c) follows.
Now, way round, on(b; c) on(a; b) tested. initial value F ( )
obtained single action stack(a,b)
( )
= fclear(b); holding(a)g
F
(

)

b;c

FDA

b;c
DA

h

a;b

h

DA

a;b
DA

355

fiKoehler & Hoffmann
Again, fixpoint computation cause changes, resulting F = fclear(b);
holding(a)g. process tests whether pA(on(b; c); ) holds, contains
actions except delete on(a; b) use clear(b) holding(a)
precondition. action add on(b; c) stack(b,c). action needs
preconditions facts holding(b) clear(c). process finds crucial
condition achieving first fact violated: action achieve holding(b)
clear(b) precondition, b must clear first gripper hold it.
Since clear(b) element F , none actions achieving holding(b) contained
O. Consequently, test pA(on(b; c); ) fails obtain ordering on(b; c)
on(a; b). makes sense gripper cannot grasp b stack onto c anymore,
on(a; b) achieved.
h

3.3 Forced Goal Orderings Invertible Planning Problems

far, introduced two easily computable ordering relations
approximate reasonable goal ordering . One might wonder invest
effort trying find forced goal orderings. two reasons that:
h

e

r

1. already seen Section 2, forced goal ordering reasonable
goal ordering, i.e., method approximates latter used crude
approximation former.
2. Many benchmark planning problems invertible certain sense. problems
contain forced orderings anyway.
section, elaborate detail second argument. results bit
general necessary point. want make use later show
Agenda-Driven planning algorithm propose complete respect certain class
planning problems. proceed formally defining class planning problems, show
problems contain forced orderings, identify sucient criterion
membership problem class. Finally, demonstrate many benchmark
planning problems fact satisfy criterion. start, introduce notion
deadlock planning problem.
Definition 14 (Deadlock) Let (O; ; G ) planning problem. reachable state
called deadlock iff sequence actions leads goal, i.e., iff
0
0
= Result(I ; P ) :9 P : G Result(s; P ).

class planning problems interested class problems

deadlock-free. Naturally, problem called deadlock-free none reachable states

deadlock sense Definition 14.
Non-trivial forced goal orderings imply existence deadlocks (remember
ordering B B called trivial iff state s( : ) all).
f

r

A;

B

Lemma 5 Let (O; ; G ) planning problem, let A; B 2 G two atomic goals.
non-trivial forced ordering B B , exists deadlock
state problem.
f

356

fiOn Reasonable Forced Goal Orderings
Proof: Recalling Definition 9 assuming non-triviality , know
least one state s( : ) made true, B still false. Definition 7,
know plan state achieves B . particular,
possible achieve goals starting s( : ) . Thus, state := s( : ) must
deadlock.
f

A;

B

A;

B

A;

B

investigate deadlocks detail discuss commonly
used benchmark problems contain them, i.e., deadlock-free. Lemma 5,
know domains contain non-trivial forced goal orderings
either|so much point trying find them. care trivial goal
orderings. orderings force reasonable planning algorithm consider goals
correct order.
existence deadlocks depends structural properties planning problem:
must action sequences, which, executed, lead states goals
cannot reached anymore. sequences must undesired effects, cannot
inverted sequence actions O. Changing perspective, one obtains hint
sucient condition non-existence deadlocks might defined. Assume
planning problem effects action sequence domain
inverted executing certain sequence actions. invertible planning
problem, particular possible get back initial state reachable state.
Therefore, problem solvable, contain deadlocks: state,
one reach goals going back initial state first, execute arbitrary
solution thereafter. formally define notion invertible planning problems,
turn argumentation proof.
Definition 15 (Invertible Planning Problem) Let (O; ; G ) planning problem,
let denote states reachable actions O. problem called

invertible

8 : 8 PO : 9 PO :

Result(Result(s; P ); P

O) =

Theorem 6 Let (O; ; G ) invertible planning problem, solution exists.
(O; ; G ) contain deadlocks.

Proof: Let = Result(I ; P ) arbitrary reachable state. problem invert-

ible, know sequence actions P Result(s; P ) = holds.
problem solvable, solution plan P starting achieving
G Result(I ; P ). Together, obtain G Result(Result(s; P ); P ). Therefore,
concatenation P P solution plan executable consequently,
deadlock.










know invertible planning problems, solvable, contain deadlocks
consequently, contain (non-trivial) forced goal orderings. see next
that, matter fact, benchmark planning problems invertible. arrive
sucient condition invertibility notion inverse actions.
357

fiKoehler & Hoffmann
Definition 16 (Inverse Action) Given action set containing action
form pre(o) ! add(o) del(o). action 2 called inverse
form pre(o) ! add(o) del(o) satisfies following conditions
1. pre(o) pre(o) [ add(o) n del(o)
2. add(o) = del(o)
3. del(o) = add(o)

certain conditions, applying inverse action leads back state one started
from.
Lemma 6 Let state action, applicable s. del(o) pre(o)

\ add(o) = ; hold, action inverse sense Definition 16
applicable Result(s; hoi) Result(Result(s; hoi); hoi) = follows.

Proof: applicable s, pre(o) s. atoms add(o) added,

atoms del(o) removed s, altogether

Result(s; hoi) (pre(o) [ add(o)) n del(o) pre(o)

Thus, applicable Result(s; hoi).
Furthermore, Result(s; hoi) = [ add(o) n del(o)
Result(Result(s; hoi); hoi)
= Result(s [ add(o) n del(o); hoi)
= (s [ add(o) n del(o)) [ add(o) n del(o)
= (s [ add(o) n del(o)) [ del(o) n add(o)
(cf. Definition 16)
= [ add(o) n add(o)
(because del(o) pre(o) s)
=
(because \ add(o) = ;)
Lemma 6 states two prerequisites: (1) inclusion operator's delete list preconditions (2) empty intersection operator's add list state
applicable. planning problem called invertible meets prerequisites
inverse action.
Theorem 7 Given planning problem (O; ; G ) set ground actions satisfying

del(o) pre(o) pre(o) ) add(o) \ = ; actions reachable states s.
inverse action 2 action 2 O, problem invertible.

Proof: Let reachable state, let P = ho1 ; : : : sequence actions.

need show existence sequence P



n

Result(Result(s; P ); P ) =
358

( )

fiOn Reasonable Forced Goal Orderings
holds. define P := ho ; : : : ; o1 i, prove ( ) induction n.

n = 0: Here, P = P = hi, Result(Result(s; hi); hi) = obvious.
n ! n + 1: P = ho1 ; : : : ; ; +1 i. induction hypothesis know
Result(Result(s; ho1 ; : : : ; i); ho ; : : : ; o1 i) = s. make following bit readable,
let s0 denote s0 := Result(s; ho1 ; : : : ; i).
n

n

n

n

n

n

Result(Result(s; ho1 ; : : : ; +1 i); ho +1 ; : : : ; o1 i)
Result(Result(s0 ; ho +1 i); ho +1 ; : : : ; o1 i)
Result(Result(Result(s0 ; ho +1 i); ho +1 i); ho ; : : : ; o1 i)
Result(s0 ; ho ; : : : ; o1 i)

n

n

=
=
=
=

n

n

n

n

n

n

(cf. Lemma 6 s0 +1 )
(per induction)
n

Altogether, know invertible problems, solvable, contain forced
orderings. know problems, inverse action action
O, invertible following Theorem 7. Theorem 7 requires del(o) pre(o) hold
action o, pre(o) ) add(o) \ = ; hold actions reachable states s.
see conditions, (a) inclusion delete list precondition list, (b)
empty intersection action's add list reachable states applicable,
(c) existence inverse actions, hold currently used benchmark domains.4
Concerning condition (a) actions delete facts require preconditions, one finds phenomenon domains commonly used planning
community, least known authors. something seems
hold reasonable logical problem formulation. authors even postulate
assumption algorithms work, cf. (Fox & Long, 1998).
Similarly case conditions (b) (c): One usually finds inverse actions
benchmark domains. Also, action's preconditions usually imply|by state invariants|
add effects false. example blocks world, stack unstack
actions invert other, action's add effects exclusive preconditions|
former contained union False constructed preconditions, see
Section 3.1. Similarly domains deal logistics problems, example logistics,
trains, ferry, gripper etc., one often find inverse pairs actions preconditions
always excluding add effects. Sometimes, two different ground instances
operator schema yield inverse pair. example, gripper, two ground instances
move(roomA, roomB)
at-robby(roomA)

! ADD at-robby(roomB) DEL at-robby(roomA).


4. order avoid reasoning reachable states condition (b), one could postulate
action add effects negative preconditions, cf. (Jonsson, Haslum, & Backstrom, 2000).
is, however, commonly used typical planning benchmark problems.

359

fiKoehler & Hoffmann
move(roomB, roomA)
at-robby(roomB)

! ADD at-robby(roomA) DEL at-robby(roomB).

move(?from,?to) operator schema invert other. Similarly, towers hanoi,
single move operator schema, inverse instance found
ground instance schema, add effects always false
preconditions true.
rarely, non-invertible actions found benchmark domains.
occur, role domain often quite limited example operators cuss
ate Russel's Tyreworld.
cuss

! DEL annoyed().

ate(?x:wheel)

have(pump) not-in ated(?x) intact(?x)

! ADD ated(?x) DEL not-in ated(?x).

Obviously, much point defining something decuss de ate
operator. formally speaking, none ground actions operators destroys
goal precondition action domain. Therefore, matter
effects cannot inverted. particular, forced goal ordering derived
wrt. actions. 5
importance inverse actions real-world domains discussed
Nayak Williams (1997), describe planner BURTON controlling Cassini
spacecraft. contrast domains, problems example used
Barrett et al. (1994) almost never contain inverse actions. Consequently, domains
plenty forced goal orderings could discovered used planner avoid deadlock
situations. widespread, although perhaps unconscious use invertible problems
benchmarking current phenomenon related STRIPS descending planning systems.
one anonymous reviewers pointed us, quite number non-invertible planning
problems proposed planning literature, e.g., register assignment
problem (Nilsson, 1980), robot crossing road problem (Sanborn & Hendler, 1988),
instances manufacturing problems (Regli, Gupta, & Nau, 1995), Yale Shooting
problem (McDermott & Hanks, 1987). problems, i.e., problems
invertible, one could|in spirit argument 1 beginning section|
simply use approximate forced orderings one interested finding least
those. precisely, methods might detect forced orderings|as
reasonable|but might find more, necessarily forced, orderings.
one interested finding forced orderings, possible way go.
example, simple blocks world modification blocks cannot unstacked anymore
stacked|which forces planner build stacks bottom up|both
still capable finding correct goal orderings.
e

h

e

h

e

h

5. cuss operator, way, one known authors deletes fact using
precondition. one know could removed domain description
without changing anything.

360

fiOn Reasonable Forced Goal Orderings
3.4 Extension Goal Orderings ADL Actions

orderings, introduced far, easily extended deal
ground ADL actions conditional effects using negation instead delete lists.
actions following syntactic structure:
: 0 (o) = pre0 (o) ! eff+
0 (o); eff0 (o)
1 (o) = pre1 (o) ! eff+
1 (o); eff1 (o)
..
.
(o) = pre (o) ! eff+ (o); eff (o)
unconditional elements action summarized 0 (o): precondition
action denoted pre0 (o), unconditional positive negative effects
eff+0 (o) eff0 (o), respectively. conditional effect (o) consists effect
condition (antecedent) pre (o), positive negative effects eff+ (o) eff (o).
Additionally, denote (o) set unconditional conditional effects,
i.e., (o) = f0 (o); 1 (o); : : : ; (o)g.
computation immediately carries ADL actions extension
planning graphs used, handle conditional effects, e.g., IPP (Koehler, Nebel,
Hoffmann, & Dimopoulos, 1997) SGP (Anderson & Weld, 1998). One simply takes
set exclusive facts returned systems determine set F . test
Definition 10, decides whether ordering B two atomic goals
B , extended ADL follows.
n

n

n

n









n

e



GP

e

Definition 17 (Ordering ADL) Let (O; ; G fA; B g) planning problem.
e

False set A. ordering B holds

Let F



e

GP

8 2 O; (o) 2 (o) : B 2 eff+(o) ^ 62 (o) ) (pre (o) [ pre0(o)) \ F 6= ;







GP



Here, (o) denotes negative effects implied conditions (o).


(o) :=




eff0 (o) [
eff0 (o)





pre

j (o) prei (o) effj (o) 6= 0

i=0

Thus, B ordered (unconditional conditional) effects add B either
imply effect deletes A, need conditions cannot made true together
A. Note effect requires conditions pre (o) [ pre0 (o) satisfied,
impossible state holds non-empty intersection
F
.
computation requires little adaptation effort. order obtain
set F , need investigate conditional effects well. action
conditional unconditional effect, determine atoms negated
it, matter effect used achieve A. obtain atoms intersecting
appropriate sets (o).
\
(o)
D(o) :=





GP

h


DA



+
2 effi (o)

361



fiKoehler & Hoffmann
exactly facts always deleted achieving A, matter
effect use.
intersection sets D(o) actions yields desired set F . Let us
consider following small example clarify computation.
0 (o) = fU g
! fW g f:X g;
1 (o) = fV; W g ! fAg f:X g;
2 (o) = fW g
! fU g f:Y g

DA

obtain D1 (o) = f:X g [ f:Y g = f:X; :Y g, precondition 2 (o)
implied first conditional effect 1 (o). 1 (o) effect achieve A,
get D(o) = D1 (o) = f:X; :Y g.
obtain smaller set D(o), add unconditional positive effect
action.
0 (o) = fU g
! fW; Ag f:X g;
1 (o) = fV; W g ! fAg f:X g;
2 (o) = fW g
! fU g f:Y g
case, need intersect sets D0 (o) = f:X g D1 (o) = f:X; :Y g,
yielding D(o) = f:X g. ects fact that, achieving via unconditional
effect o, X gets removed state.
fixpoint computation requires adapt computation . First, repeat
steps case simple STRIPS actions consider unconditional negative
effects intersection preconditions False set:

:= n fo j 2 eff0 (o) _ F \ pre0(o) 6= ;g

DA

Then, additionally remove action conditional effects either imply
deletion impossible effect condition.

:= red(O ) = fred(o)jo 2 Og
Here, red function red(o) : 7! o0
(o0 ) = (o) n f (o) j 2 (o) _ pre (o) \ F
k

k


DA

k

6= ;g

Finally, need redefine Definition 12, expresses conditions
fact believed possibly achievable given certain set operators O.
Definition 18 (Possibly Achievable Atoms ADL) atom p possibly achievable given action set (written pA(p; O))

9 2 O; 2 (o) : p 2 eff+(o) ^
8 p0 2 (pre (o) [ pre0(o)) : 9 o0 2 O; 0 2 (o0) : p0 2 eff+0 (o0 )










holds, i.e., positive effect p conditions preconditions
made true effects reduced action set.
362

fiOn Reasonable Forced Goal Orderings
process, decides whether atomic goal B heuristically ordered another
goal (i.e., whether B holds) proceeds exactly way described
Section 3.2: False set F reduced fixpoint computation, remains
unchanged, employs updated routines computing deciding pA(f; O).
result, B ordered (B A) possibly achievable
pA(B; ) using action set results fixpoint.
h


DA

h

4. Use Goal Orderings Planning

determined ordering relations hold pairs atomic goals
given goal set, question make use planning. Several
proposals made literature, see Section 6 detailed discussion.
paper, propose novel approach extracts explicit ordering subsets
goal set|called goal agenda. planner, case IPP, run successively
planning subproblems represented agenda.
4.1 Goal Agenda

first step one take computing goal agenda perform so-called goal
2 G atomic goals must examined
order find whether ordering relation B , B A, both, none holds
them. ordering relation , arbitrary definition used.
experiments, relation always either .
determined ordering relations hold atomic goals, want
split goal set smaller sets based relations, want order
smaller sets, based relations. precisely, goal sequence
goal sets G1 ; : : : ; G
[
G =G
analysis. goal analysis, pair A; B

e

h

n

n







=1

G



\G =;
j

6= j; 1 i; j n. want sequence goal sets respect ordering
relations derived atomic goals. make explicit, first
introduce simple representation detected atomic orderings: goal graph G.
G := (V; E )

V := G

E := f(A; B ) 2 G G j B g
Now, desired properties, sequence goal sets possess, easily
stated:
363

fiKoehler & Hoffmann

Goals A; B lie cycle G belong set, i.e., A; B 2 G .
G contains path goal goal B , vice versa, ordered
B , i.e., 2 G B 2 G < j .




j

properties appear reasonable goal-set sequence respecting
atomic orderings. introduce simple algorithmic method produce
sequence goal sets meets requirements.
First all, transitive closure G computed. done cubic
time size goal set (Warshall, 1962). Then, node transitive
closure, ingoing edges outgoing edges counted. disconnected nodes
= = 0 moved separate set goals G-sep containing
atomic goals, participate relation. nodes A, degree
d(A) =
determined difference number ingoing edges
number outgoing edges. Nodes identical degree merged one set.
sets ordered increasing degree yield desired sequence goal sets.
problem remaining set G-sep. non-empty, clear place
put it.
Let us consider small example process. Figure 3 depicts left goal
graph, results goal set G = fA; B; C; D; E g ordering relations
B; B C B D, transitive closure right.












B

B
C

C






E

E

Figure 3: left, goal graph depicting relations atomic subgoals.
right, transitive closure graph.
Figure 4, number in- outgoing edges goal, corresponding degrees,
resulting goal-set sequence shown.
0
0

E



0
3

1

2

B2

0

2
0

-3
{A}

C

-1
{B}

2
{C,D}

G-sep
E



Figure 4: left, number in- outgoing edges node. right,
degree nodes merged sets goals degree.
node E becomes member G-sep set remains unordered.
dicult verify resulting goal sequence respects atomic goal orderings:
364

fiOn Reasonable Forced Goal Orderings

Nodes occurring cycle graph isomorphic in- outgoing edges

transitive closure graph. particular, degree get
merged set G .
Say graph, path B , vice versa. Then,
transitive closure graph, edge node
B path to, additionally edge B , i.e., > B
follows. Similarly, ingoing edge B node path
A, additionally, edge B , gives us B > . Altogether,
d(A) =
<B
<B
B = d(B ) thus, degree
smaller degree B required, gets ordered B .
Note nothing said argumentation set unordered goals, Gsep. set could, principle, inserted anywhere sequence resulting
sequence still respecting atomic orderings. possible heuristic may use goal set
first sequence, apparently problem reach goals
goals set achieved. Another heuristic could put set end
neither problem reach goal set goals. decided
deal problem sophisticated way trying derive ordering relation
G-sep goal sets G already derived. order
so, need extend definitions goal orderings sets goals.
























4.2 Extension Goal Orderings Goal Sets

Given set atomic goals, always problem exponentially many
subsets compared order derive reasonable goal ordering
goal sets. consideration possible subsets question,
result exponential overhead. partial goal agenda obtained far
offers one possible answer. suggests taking set G-sep trying order
respect goal sets emerging goal graph.
Given planning problem (O; I; G ) two subsets atomic goals fA1 ; : : : ; g G
fB1 ; : : : ; B g G , definition sets atomic goals straightforward.
sake simplicity, consider STRIPS actions here. definitions
directly extended ADL.
define ordering , extends sets, begin defining set F f 1 n g
atoms, exclusive least one atomic goal planning graph
generated (O; I; G ):
F f 1 n g := fp j p exclusive least one graph leveled g
set 1 n g obtained accordingly removing actions delete
least one , i.e., 1 n g = fo 2 j 8 2 f1; : : : ; ng : 62 del(o)g.
Definition 19 (Ordering Goal Sets) Let (O; I; G ) planning problem
n

e

k

h

;:::;A

E

e

GP



;:::;A



GP

;:::;A





;:::;A

fA1 ; : : : ; g G fB1 ; : : : ; B g G . Let 1 ng False set fA1 ; : : : ; g.
ordering fB1 ; : : : ; B g fA1 ; : : : g holds
9 j 2 f1; : : : ; kg : 8 2 1 ng : B 2 add(o) ) pre(o) \ 1 ng 6= ;:
E

;:::;A

n

k

k

E

n

GP

n

;:::;A

;:::;A

j

365

GP

fiKoehler & Hoffmann
similar way, extended . , sets F determined
based Equation (3). set 1 n g simply union individual sets:
f 1 n g := [ F
F
(4)


H

h



DA

;:::;A

DA

;:::;A



DA

DA



fixpoint computation entered

:= n fo 2 j 9 2 f1; : : : ; ng : 2 del(o) _ 1 ng \ pre(o) 6= ;g (5)
recomputation iteration fixpoint algorithm Figure 1 done
;:::;A



DA

accordingly. Apart this, algorithm remains unchanged.

Definition 20 (Ordering ) Let (O; I; G ) planning problem fA1 ; : : : ; g

fB1 ; : : : ; B g G . Let set actions obtained performing
fixpoint computation shown Figure 1, modified handle sets facts defined
Equations (4) (5). ordering fB1 ; : : : ; B g fA1 ; : : : ; g holds
9 j 2 f1; : : : ; kg : :pA(B ; O)

G

H

n

k

H

k

n

j

given goal sets undergo goal analysis, i.e., pair sets checked
ordering relation . derived relation defines edge graph
subgoal sets nodes. transitive closure determined before, degree
node computed. graph contains disconnected nodes, total ordering
subsets goals results ordering nodes based degree. ordering
defines goal agenda. case disconnected nodes, default heuristic
adding corresponding goals last goal set agenda.
E

H

4.3 Agenda-Driven Planning Algorithm

Given planning problem (O; ; G ), let us assume goal agenda G1 ; G2 ; : : : ; G
k entries returned analysis. entry contains subset G G .
basic idea agenda-driven planning algorithm first feed planner
original initial state I1 := goals G1 := G1 , execute solution plan P
, yielding new initial state I2 = Result(I1; P ). Then, new planning problem
initialized (O; I2 ; G2 ). solving problem, want goals G2 true,
want goals G1 remain true, set G2 := G1 [ G2 . continuous
merging successive entries agenda yields sequence incrementally growing
goal sets planner, namely
[
G := G
k







j

j

=1

little detail, agenda-driven planning algorithm implemented IPP works
follows. First, IPP called problem (O; ; G1 ) returns plan P1 ,
achieves subgoal set G1 . P1 sequence parallel sets actions, returned
IPP similarly graphplan. Given plan, resulting state R(I ; P1 ) = I2
366

fiOn Reasonable Forced Goal Orderings
computed based operational semantics planning actions.6 case set
STRIPS actions, one simply adds ADD effects deletes DEL effects
state description order obtain resulting state, following Result function
Definition 2. STRIPS, Result function coincides directly R function.
case set parallel ADL actions, one needs consider possible linearizations
parallel action set deal conditional effects separately.
linearization, different resulting state obtained, satisfy
goals. obtain new initial state I2 , one takes intersection resulting states
possible linearization actions parallel set. means compute n!
linearizations parallel action set n actions time step. Since n usually
small (more 5 6 ADL actions per time step rare), practical costs
computation neglectible.
way, given solution subproblem (O; ; G ), one calculates new initial
state +1 runs planner subsequent planning problem (O; +1 ; G +1 )
planning problem (O; ; G ) solved.
plan solving original planning problem (O; ; G ) obtained taking
sequence subplans P1 ; P2 ; : : : ; P . One could argue planning increasing goal
sets lead highly non-optimal plans. IPP still uses \no-ops first" strategy
achieve goals, originally introduced graphplan system (Blum & Furst,
1997). Employing strategy, graphplan algorithm, short, first tries achieve
goals simply keeping true, possible. Since goals G1 ; G2 ; : : : ; G already
satisfied initial state +1 , starting planner tries achieve G +1 ,
strategy ensures goals destroyed re-established solution
found otherwise. no-ops first strategy merely graphplan feature,
reasonable planning strategy preserve goals already true initial state
whenever possible.
soundness agenda-driven planning algorithm obvious G = G
sequence sound subplans yielding state transition initial state
state satisfying G .
completeness approach less obvious holds planner cannot
make wrong decisions finally reaching goals. precisely, approach
complete problems contain deadlocks introduced Definition 14.








k



k

k







k

Theorem 8 Given solvable planning problem (O; I; G ), goal agenda G1 ; G2 ; : : : G

k

G G +1 G = G . Running complete planner agenda-driven manner
described yield solution problem deadlock-free.




k

Proof: Let us assume planner find solution step agenda-driven

algorithm, i.e., solution found subproblem (O; ; G ). planner assumed
complete subproblem, implies unsolvability (O; ; G ). problem
solvable, neither problem (O; ; G ) solvable, since G G holds. Therefore,
goals cannot reached . Furthermore, reachable state|it reached
executing partial solution plans P1 ; : : : ; P 1 initial state. Consequently,
must deadlock state sense Definition 14, contradiction.


















6. See (Koehler et al., 1997) exact definition R, want repeat here.

367



fiKoehler & Hoffmann
result states feasibility approach: shown, benchmark
problems currently investigated contain inverse actions, therefore invertible
(Theorem 7), deadlock-free (Theorem 6). Thus, Theorem 8,
approach preserves completeness domains.
However general case, completeness cannot guaranteed. following example
illustrates situation assumption s( : ) 6j= p (assuming preconditions
achieving actions contained state reached, cf. derivation
ordering Section 3) wrong yields goal ordering plan
found anymore although problem solvable.
Given initial state fC; Dg goals fA; B g, planner following set
ground STRIPS actions :
A;

B

h

op1:
op2:
op3:
op4:

fC g
fDg
fE g
g

!
!
!
!

ADD fB g DEL fDg
ADD fE g
ADD g
ADD fAg

analysis return ordering B B added op1,
precondition C effect actions. Thus concludes C
reachable state holds. example, C holds reachable
states. assumption s( : ) 6j= C made test pA(B; ) wrong. Thus, B
reached A. hand, B holds, even forced ordering
B . testing B , ordering remains undetected,
method discover precondition F op4 achievable state
B holds: obtain F = fDg, excludes op2 , op3 op4
remain set usable actions. Thus, op4 considered legal achiever A, op3
considered legal achiever precondition F . could detect right ordering
regressed action chain op4, op3, op2 found that,
F set B , actions must excluded .
Consequently, goal agenda fB g; fAg fed planner, solves first
subproblem using op1, fails achieving state fB; C g since
inverse action op1 cannot re-established way.
h

A;

B

r

f

h

B
DA

5. Empirical Results

implemented methods approximate so-called Goal Agenda Manager
(GAM) IPP planning system (Koehler et al., 1997). GAM activated
set ground actions determined either uses approximate
reasonable goal ordering. calls IPP planning algorithm entry
goal agenda outputs solution plan concatenation solution plans
found entry agenda.7
r

e

h

7. source code GAM, based IPP 3.3, collection domains
draw subsequent examples downloaded http://www.informatik.uni-freiburg.de/~
koehler/ipp/gam.html. experiments performed SPARC 1/170.

368

fiOn Reasonable Forced Goal Orderings
empirical evaluation performed uses IPP domain collection, contains 48 domains 500 planning problems. domains,
able derive goal ordering information 10 domains. domains indeed pose constraints ordering planner achieve set goals.
domains, goal orderings could derived, found either single goal
achieved, example manhattan, movie, molgen, montlake domains
goals achieved order, example logistics, gripper, ferry
domains. found benchmark domain, natural goal ordering existed,
method failed detect it. matter fact, looking goal ordering seems
natural, one usually finds ordering reasonable sense Definition 8, see
example blocks world, woodshop, tyreworld domains. method finds almost
reasonable orderings, indicates approximation techniques
appropriate detecting ordering information.
e

h

following, first compare techniques terms runtime
number goal agenda entries generated. take closer look agendas
generated selected domains investigate uence performance
IPP planning system. exact definition domains downloaded
IPP webpage, give name domain name particular
planning problem well number (ground) actions domain contains,
parameter nicely characterizes size domain usually diculty
handle it.
e

h

examples, times shown compute goal agenda contain effort
parse instantiate operators, i.e., compute set actions. Times parsing
instantiation listed explicitly, are, test examples used here,
usually close zero uence performance planner significant
way.
5.1 Comparison
h

e

begin comparison summary results obtained different representational variants blocks world. bw large bw large examples originate
SATPLAN test suite (Kautz & Selman, 1996) added larger examples
bw large e bw large g. parcplan example comes (El-Kholy & Richards, 1996)
uses multiple grippers limited space table. stack n examples use
graphplan blocks world representation simply require stack n blocks other,
table initial state.
two methods return exactly ordering relations across blocks world
problems. Figure 5 confirms, computation based planning graphs
much time-consuming. hits computational border domain contains
10000 actions. computation much faster scales larger action
sets.
e

h

369

fiKoehler & Hoffmann
problem
bw large
bw large b
bw large c
bw large
bw large e
bw large f
bw large g
parcplan
stack 20
stack 40
stack 60
stack 80

#actions #agenda entries CPU( ) CPU( )
162
1
0.69
0.07
242
5
1.45
0.11
450
7
4.85
0.22
722
11
14.18
0.35
722
11
12.95
0.35
1250
6
44.93
0.58
1800
9
97.11
0.88
1960
4
25.84
1.47
800
19
6.91
0.36
3200
39
160.00
1.74
7200
59
840.42
4.85
12800
79
11.38
e

h

Figure 5: Comparison blocks world problems. #actions shows number
actions set O, planner tries construct plan. #agenda
entries says many goal subsets detected ordered GAM.
Column 4 5 display CPU time required methods
compute agenda provided set O. dash always mean
IPP ran memory 1 Gbyte machine.
e

h

Figure 6 Figure 7 show results domains, method
able detect reasonable orderings. Figure 6 lists domains, methods
return goal agendas. tyreworld, hanoi, fridgeworld domains originate
UCPOP (Penberthy & Weld, 1992), link-repeat domain found (Veloso
& Blythe, 1994). performance results coincide shown Figure 5. Figure 7
shows picture terms runtime performance, domains different
agendas returned .
woodshop scheduling domains contain actions conditional effects,
domains use STRIPS operators. computation fails derive goal
orderings scheduling world problems (of display largest problem
sched6) wood1 problem. explanation behavior found
different treatment conditional effects methods. IPP find limited
form mutex relations conditional effects building planning graph.
goal, achieved conditional effect, often exclusive large
number facts graph. Thus, F sets small sometimes even empty
consequently, actions excluded performing reachability
analysis thus, reasonable orderings may remain undetected. Direct analysis investigates
conditional effects detail therefore able derive much larger F sets.
behavior method STRIPS domains bulldozer, glassworld,
shopping world caused phenomenon. domains, one derive much
larger F sets using planning graphs turn sets exclude actions. Since direct
analysis finds smaller empty F sets, finds less relations. woodshop domain
e

h

e

h

h

370

fiOn Reasonable Forced Goal Orderings
#actions #agenda entries CPU( ) CPU( )
26
6
0.05
0.01
59
6
0.20
0.03
108
6
0.45
0.06
173
6
0.84
0.10
254
6
1.56
0.15
899
6
16.29
0.64
48
3
0.05
0.02
90
4
0.10
0.04
150
5
0.19
0.08
231
6
0.35
0.12
336
7
0.63
0.19
779
2
0.77
0.55
31
2
0.19
0.01
31
2
0.21
0.01

domain
tyreworld

problem
fixit1
fixit2
fixit3
fixit4
fixit5
fixit10
hanoi
hanoi3
hanoi4
hanoi5
hanoi6
hanoi7
fridgeworld fridge
link-repeat link10
link30

e

h

Figure 6: Comparison benchmark domains, return
identical agendas.
e

h

domain
bulldozer
glassworld

problem
bull
glass1
glass2
glass3
shoppingworld shop
scheduling
sched6
woodshop
wood1
wood2
wood3

#actions #agenda entries CPU( ) CPU( )
61
2/1
0.09
0.03
26
2/1
0.02
0.01
114
2/1
0.19
0.09
122
2/1
0.22
0.09
81
2/1
0.07
0.02
104
1/4
01.0
0.12
15
1/3
0.03
0.01
15
6/5
0.03
0.01
43
6/5
0.14
0.06
e

h

Figure 7: Domains return different goal agendas, give
form n1 =n2 . number slash says many entries contained
agenda computed , number following slash says many
entries contained agenda computed . #agenda entries=1 means
agenda contains single entry, namely original goal set,
ordering derived.
e

h

e

h

shows results differ within domain, depending specific
planning problem. problem wood2 varies problem wood1 sense one
goal slightly different|an object needs put different shape|and two
goals present. goal orderings derived pairs old
371

fiKoehler & Hoffmann
goals wood1, lots relations derived mixed pairs old new goals
wood2, yielding detailed goal agenda. problem wood3 contains additional objects
many goals, successfully ordered.
subsequent experiments, decided solely use heuristic ordering
computation less costly computation cases, yielding
comparable agendas cases. three domains investigate closely,
namely blocks world, tyreworld hanoi domains, agendas derived methods
are, fact, exactly same.
e

h

e

h

5.2 uence Goal Orderings Performance IPP Interaction
RIFO

section, analyze uence goal agenda performance IPP
combine another domain analysis method, called RIFO (Nebel, Dimopoulos, &
Koehler, 1997). RIFO family heuristics enables IPP exclude irrelevant actions
initial facts planning problem. effectively combined GAM,
IPP plans subset goals original goal set, likely
subset relevant actions needed find plan. precisely,
obtain one subproblem entry agenda, and, subproblem,
use RIFO preprocessing planning IPP. configuration, GAM reduces
search space IPP decreasing number subgoals planner achieve
moment, RIFO reduces search space dramatically selecting
actions relevant goal subset.
5.2.1 Blocks World

Figure 8 illustrates parcplan problem (El-Kholy & Richards, 1996) detail. Seven
robot arms used order 10 blocks 3 stacks 5 possible positions table.

1

11

14

24

23

13

23

12

22

32

11

21

31

1

2

3

32
12

31

22

24

14

13
21

2

3

4

5

Figure 8: parcplan problem limited space table, seven robot arms,
several stacks.
goal agenda derived IPP orders blocks horizontal layers:
1:
2:
3:
4:

on-table(21, t2) ^ on-table(11, t1)
on-table(31, t3) ^ on(22, 21) ^ on(12, 11)
on(32, 31) ^ on(13, 12) ^ on(23, 22)
on(14, 13) ^ on(24, 23)
372

fiOn Reasonable Forced Goal Orderings
optimal plan 20 actions solving problem found IPP using GAM 14 s,
spends one second computing goal agenda, almost 13 seconds build
planning graphs, 0.01 second search plan. 70 actions tried
find solution. Without goal analysis, IPP needs approx. 47 searches 52893
actions 26 seconds.
RIFO (Nebel et al., 1997) fails detecting subset relevant actions original
goal set considered, succeeds selecting relevant actions subproblems
stated agenda. reduces runtime less 8 1 spent
goal agenda, almost 6 spent removal irrelevant actions initial facts, less
1 spent building planning graphs. previously, almost time spent
planning.
Figure 9 shows IPP SATPLAN blocks world examples (Kautz & Selman,
1996), bw large.e example taken (Dimopoulos, Nebel, & Koehler, 1997), two
large examples bw large.f (containing 25 blocks requiring build 6 stacks
goal state) bw large.g 30 blocks/8 stacks.
SATPLAN
bw large.a
bw large.b
bw large.c
bw large.d
bw large.e
bw large.f
bw large.g

# actions plan length IPP +G +G+R +G+R+L
162
12 (12)
0.70 0.74
0.58
0.34
242
22 (18) 26.71 0.86
0.55
0.52
450
48
- 7.34
2.42
2.58
722
54
- 11.62
3.74
3.81
722
52
- 11.14
3.99
3.97
1250
90
16.01
1800
84
- 117.56
28.71

Figure 9: Performance extended SATPLAN blocks world test suite. second
column shows number ground actions domain, third column
shows plan length, i.e., number actions contained plan, generated
GAM parentheses plan length generated IPP without GAM given
IPP without GAM able solve corresponding problem. +G means
IPP using GAM, +G+R means IPP uses GAM RIFO, +G+R+L
means subgoals set agenda arbitrarily linearized.
runtimes cover whole planning process starting parsing operator
domain file, performing GAM RIFO analysis (if active),
searching graph plan found.
IPP 3.3 without GAM solve bw large.a bw large.b problems. Using
goal agenda, plans become slightly longer, performance increasing dramatically.
Plan length growing blocks accidentally put positions cut
goals still ahead agenda thus, additional actions need added
plan remove blocks wrong positions. speed-up possible
RIFO additionally used, reduces size planning graphs dramatically.
Finally, goals belong subset agenda linearized based

373

fiKoehler & Hoffmann
heuristic assumption analysis found reasonable goal orderings, goals
achievable order. option, problems solved almost instantly.
reader may wonder point use linearization agenda entries
extra option investigate further. two reasons that. First,
linearization negative side effects domains investigated.
example, yields much longer plans logistics domain variants.
linearizing single entry agenda logistics problem contains, packages get
transported goal position one one. course, takes much planning
steps simultaneously transporting packages coinciding destinations.
Secondly, effects linearization somewhat unpredictible, even domains
usually tends yield good results. GAM recognise interactions goals. Consider blocks world problem four blocks A, B , C D.
Say B positioned C initially, blocks table, goal
on(A; B ) on(C; D). agenda problem comprise single entry
containing goals. fact, reasonable goal ordering here. Nevertheless,
stacking onto B immedeatly bad idea, planner needs move C achieve
on(C; D). aware this, GAM might linearize single agenda entry
on(A; B ) front, makes problem harder actually is. Thus, runtime
advantages linearization sometimes yields blocks world less seen
cases \good luck".
Figure 10 shows IPP stack n problems. IPP without domain analysis
handle 12 blocks less 5 minutes, 13 blocks 15 minutes
needed. Using GAM, 40 blocks stacked less 5 minutes. Using GAM
RIFO, 5 minutes limit extended 80 blocks, stack100 solved 11.5 min
11.3 min spent analysis methods 0.2 min needed building
planning graphs extracting plan.
time

600
450

IPP

IPP+G
IPP+G+R

300
150

10

20

Figure 10:

IPP

30

40

50

60

70

80

90

100 blocks

3.3 simple, huge stacking problem.

Figure 11 shows sharing overall problem-solving time GAM, RIFO
IPP search algorithm blocks world problems. Similar results obtained
tyreworld. GAM takes 3 16 %, RIFO takes 75 96 %,
search effort reduced approx. 1 %. overall problem solving time clearly
determined RIFO, search effort becomes marginal factor determination
performance. indicates speed-up possible improving
374

fiOn Reasonable Forced Goal Orderings
performance GAM RIFO. indicates even hardest planning problems
become easy structured decomposed right way.
problem
stack 20
stack 40
stack 60
stack 80
parcplan

# actions
800
3200
7200
12800
1960

GAM
RIFO
0.31 = 16 % 1.44 = 75 %
1.57 = 7 % 18.77 = 90 %
4.40 = 4 % 93.10 = 94 %
9.60 = 3 % 283.60 = 96 %
0.86 = 12 % 5.52 = 76 %

search algorithm
0.13 = 7 %
0.51 = 2 %
1.15 = 1 %
2.33 = 1 %
0.83 = 11 %

Figure 11: Distribution problem-solving time blocks world examples GAM,
RIFO, search algorithm, comprises time build search
planning graph. remaining fraction total problem-solving time,
shown table, spent parsing instantiating operators.

5.2.2 Tyreworld

tyreworld problem, originally formulated Stuart Russell, asks planner find
replace tire. easily solved IPP within milliseconds. problem
becomes much harder number tires increasing, cf. Figure 12.
Tires
1
2
3
4
5
6
7
8
9
10
Figure 12:

# actions
IPP
+G+R
+G+R+L
Search Space
26
0.10 (12/19) 0.15 (14/19) 0.16 (17/19)
1298/88
59
17.47 (18/30) 0.41 (24/32) 0.32 (30/34) 1290182/210
108
2.87 (32/44) 0.63 (41/46)
-/366
173
1.12 (52/60)
-/565
254
1.93 (63/73)
-/807
353
3.42 (73/85)
-/1092
464
4.81 (84/98)
-/1420
593
8.07 (95/121)
-/1791
738
11.27 (106/124)
-/ 2205
899
16.89 (118/136)
-/2662
Tyreworld. numbers parentheses show time steps, followed
number actions generated plan. last column compares
search spaces. number slash shows \number actions tried"
parameter plain IPP planning algorithm, number following
slash shows \number actions tried" IPP using GAM, RIFO,
linearization entries agenda. dash means \number
actions tried" unknown IPP failed solving corresponding
planning problem.

IPP

375

fiKoehler & Hoffmann
IPP able solve problem 1 2 tires. Using GAM RIFO, 3
tires handled. Solution length GAM slightly increasing, caused
super uous jack-up jack-down actions. short, explained follows.
wheel needs mounted hub, expressed on(?r, ?h) goal. mount
wheel, hub must jacked up. mounting, nuts done up. Then, hub
needs jacked again, order tighten nuts achieving tight(?n, ?h) goal.
Now, GAM puts goals one entry preceeding tight goals. Thus, solving
entry containing goals, hub jacked up, wheel put on, hub
immediatly jacked order replace next wheel. Afterwards, solving
tight goals, hub must jacked up|and down|one time
nuts. Solving problem manner, planner inserts one super uous jack-up,
one super uous jack-down action wheel. precisely, super uous actions
inserted one wheel, namely wheel last mounted solving
goals. mounting wheel, goals achieved, planner proceeds
next agenda entry wheel still jacked up. Then, trying achieve
tight goals, IPP recognizes shortest plan (in terms number parallel steps)
results nuts first done hub already jacked up. Thus, hub
jacked one time, achieving corresponding goal, jacked one
time, achieving tight goal.
case 3 tires, following goal subsets identified ordered:

1:
2:
3:
4:
5:
6:
7:

ated(r3), ated(r2), ated(r1)
on(r3, hub3), on(r1, hub1), on(r2, hub2)
tight(n2, hub2), tight(n3, hub3), tight(n1, hub1)
in(w3, boot), in(pump, boot), in(w1, boot), in(w2, boot)
in(jack, boot)
in(wrench, boot)
closed(boot)

hardest subproblem agenda achieve on(r ; hub ) goals entry 2,
i.e., mount ated spare wheels various hubs. Trying generate maximum parallelized plan impossible IPP 3 tires. since goals completely
independent other, linearization perfectly work. resulting
plans become slightly longer due way tight goals achieved using
-L option. noticed earlier one wheel (the one last mounted
solving goals) super uous jack-up jack-down actions need inserted
plan. Linearizing agenda entries, super uous jack-up jack-down actions must
likely inserted wheels, yielding plans two steps longer. reason
tight goal might first linearization. likely,
tight goal corresponding hub still jacked up, planner needs
insert one super uous jack-down action here. Later, must jack hub again, yielding
another super uous action. Using +G+R+L case 10 tires, 2662 actions need
tried plan 136 actions found, takes 0.08 s. GAM requires 0.55 s,
RIFO requires 14.42 s, 1.74 consumed generate planning graphs, 0.08
spent compute initial states subproblems. remaining 0.02 consumed
parsing instantiating.


376



fiOn Reasonable Forced Goal Orderings
5.2.3 Tower Hanoi

surprising result obtained tower hanoi domain. domain, stack discs
moved one peg third peg auxiliary second peg them,
never larger disc put onto smaller disc. case three discs d1, d2, d3
increasing size, goals stated on(d3,peg3), on(d2,d3), on(d1,d2). GAM returns
following agenda, correctly ects ordering largest disc needs
put goal position first.
1: on(d3,peg3)
2: on(d2,d3)
3: on(d1,d2)

goal agenda leads partition subproblems corresponds recursive
formulation problem solving algorithm, i.e., solve problem n discs,
planner first solve problem n 1 discs, etc. first entry, plan 4
actions (time steps 0 3 below) generated, achieves goal on(d3,peg3).8
plan 2 actions (time steps 4 5) achieves goals on(d3,peg3) on(d2,d3)
on(d3,peg3) holding already initial state. Finally, one-step plan (time step 6)
generated moves third disc two discs already goal
position.
time
time
time
time

step
step
step
step

0:
1:
2:
3:

move(d1,d2,peg3)
move(d2,d3,peg2)
move(d1,peg3,d2)
move(d3,peg1,peg3)

time step 4: move(d1,d2,peg1)
time step 5: move(d2,peg2,d3)
time step 6: move(d1,peg1,d2)

Surprisingly, IPP able benefit information, runtime IPP using
GAM exploding dramatically increasing numbers discs, see Figure 13.
discs #actions IPP IPP +G
UCPOP
UCPOP subproblems
2
21 0.02
0.02 0.12 (27)
0.06 (17) + 0.02 (6)
3
48 0.08
0.07 8.00 (2291) 0.18 (48) + 0.06 (13) + 0.01 (6)
4
90 0.33
0.25
5
150 1.57
3.10
6
231 9.71
88.45
7
336 69.44 2339.94
Figure 13: Runtimes IPP without goal agenda hanoi problems compared UCPOP without agenda UCPOP agenda subproblems using
ZLIFO ibf control strategy.
8. move action takes first argument disc moved, second disc moved,
third argument disc peg moved.

377

fiKoehler & Hoffmann
able provide explanation phenomenon, division
subproblems causes much larger search space planner although solution
plans result. RIFO cannot improve situation selects actions relevant.
tower hanoi domain one found IPP's performance deteriorated GAM. currently see way one tell advance whether IPP
gain advantage using GAM not. overhead caused goal analysis
small, \inadequate" split goals subgoal sets lead
search, see Section 6.
However case, phenomenon seems specific IPP. simulated
information provided GAM UCPOP obtained quite different picture.
fifth column Figure 13 shows runtime UCPOP using ZLIFO (Pollack, Joslin,
& Paolucci, 1997) ibf control strategy number explored partial plans
parentheses. UCPOP solve problem 2 3 discs. last column
figure, show runtime number explored partial plans, result
UCPOP run subproblems result agenda. exactly
subproblems IPP solve, performance UCPOP improves
significantly. Instead taking 8 exploring 2291 partial plans, UCPOP takes
0.18+0.06+0.01=0.25 explores 48+13+6=67 plans. Unfortunately, problems
subproblems 3 discs remain beyond performance UCPOP.
performance improvement independent search strategies used UCPOP.
example, ibf control used without ZLIFO, number explored partial plans
reduced 78606 2209 case problem 3 discs. Runtime improves
65 seconds 2 seconds. Similarly, using bf control without ZLIFO
number explored partial plans reduces 1554 873.
Knoblock (1994) reports improvement performance Prodigy planner
(Fink & Veloso, 1994) using abstraction hierarchy generated domain
alpine module, provides essence information goal agenda.9
6. Summary Comparison Related Work

Many related approaches developed provide planner ability
decompose planning problem giving kind goal ordering information. Subsequently, discuss important review work light
approaches.
method introduces preprocessing approach, derives total ordering
subsets goals performing static, heuristic analysis planning problem hand.
approach works domains described STRIPS ADL operators based
polynomial-time algorithms. purpose method provide planner
search control, i.e., opt deriving goal achievement order successively call
planner totally ordered subsets goals.
method preserves soundness planning system, completeness
case planning domain contain deadlocks. argue
9. However, find goal ordering information, alpine requires represent tower hanoi domain
involving several operators, cf. (Knoblock, 1991).

378

fiOn Reasonable Forced Goal Orderings
benchmark domains quite often possess property, supported
authors (Williams & Nayak, 1997).
computation requires polynomial time, methods
incomplete sense detect reasonable goal orderings general
case. complexity deciding existence forced reasonable goal orderings
proven PSPACE-hard Section 2 therefore, trading completeness
eciency seems acceptable solution. complexity results relate found
Bylander (1992) proves PSPACE-completeness serial decomposability (Korf,
1987). Given set subgoals, serial decomposability means previously satisfied subgoals need violated later solution path, i.e., subgoal
achieved, remains valid goal reached. purpose method derive
constraints make orderings explicit serial decomposability set
goals found, i.e., consider complementary problem, ected
complexity proofs.
many cases, found goal agenda manager significantly improve
performance IPP planning system, found least one domain, namely
tower hanoi, dramatic decrease performance observed although IPP
still generates optimal plan processing ordered goals agenda.
far, complexity results Backstrom Jonsson (1995) predicted planning
abstraction hierarchies exponentially less ecient, exponentially longer
plans generated.
idea analyze effects preconditions operators derive ordering
constraints based interaction operators found variety approaches.
analyze harmful interactions operators method studying delete
effects, approaches described (Dawsson & Siklossy, 1977; Korf, 1985; Knoblock,
1994) concentrate positive interactions operators. successful matching
effects preconditions forms basis learn macro-operators, see (Dawsson & Siklossy,
1977; Korf, 1985).
alpine system (Knoblock, 1994) learns abstraction hierarchies Prodigy
planner (Fink & Veloso, 1994). approach based ordering preconditions
effects operator, i.e., effects operator must abstraction
hierarchy preconditions must placed lower level effects.
introduces ordering possible subgoals domain, orthogonal
ordering compute: alpine, subgoal ordered subgoal B
enables B , i.e., must possibly achieved first order achieve B . method
orders B cannot achieved without necessarily destroying B . result
alpine GAM set binary constraints. case alpine, constraints
computed atoms domain, GAM restricts analysis
goals only. approaches represent binary constraints graph structure. alpine
merges atomic goals together belong strongly connected component graph.
GAM merges sets goals together identical degree. compute
topological sorting sets consistent constraints. resulting goal
orderings quite similar examples Knoblock (1994) demonstrate, GAM
approximates reasonable goal orderings domains alpine fails finding abstraction
hierarchies. Two examples (Knoblock, 1991) tower hanoi domain using
h

e

379

fiKoehler & Hoffmann
one move operator blocks world. domains, alpine cannot detect
orderings investigates operator schemata, set ground actions,
therefore cannot distinguish orderings different instantiations
literal. Although alpine could modified handle ground actions, significantly
increase amount computation requires. GAM hand, handles large sets
ground actions ecient way, particular direct analysis used.10
analysis, quite similar alpine, performed framework
HTN planning, described Tsuneto et al. (1998). approach analyzes external
conditions methods, cannot achieved decomposing method further.
means, conditions established decomposition methods,
precede method using external condition. Two strategies determine
decomposition order methods defined empirically compared. lies main
difference approaches described far: Instead trying automatically
construct decomposition orderings, predefined fixed domains
problems.
Harmful interactions among operators studied Smith Peot (1993) Etzioni
(1993). threat operator precondition p occurs instantiation
effects inconsistent p (Smith & Peot, 1993). knowledge
threats used control plan-space planner. contrast state-space planner
IPP, computing explicit ordering goals prevent presence threats
partial plan order goals processed determine order
actions occur plan. notion forced reasonable goal orderings
comparable threat threat still potential resolved
adding binding ordering constraints plans. contrast this, forced
reasonable goal ordering persists bindings enforces specific ordering
subgoals.
Given planning problem, static (Etzioni, 1993) computes backchaining tree
goals form AND/OR graph, subsequently analyzes occurrence
goal interactions necessarily occur. analysis much complicated
ours, static deal uninstantiated operators axioms,
describe properties legal states. result analysis goal ordering rules,
order goals certain conditions satisfied state. main difference GAM,
generates explicit goal orderings independently specific state. need
extract conditions specific state satisfy considers generic state
s( : ) analysis, represents states satisfying A, B . GAM, static
incomplete sense cannot detect existing goal interactions. problem
GAM deciding reasonable orderings PSPACE-hard, proven
paper. problem static compute necessary effects operator
given state. Etzioni (1993) conjectures Nebel Backstrom (1994) prove,
A;

B

10. Abstraction hierarchies general goal orderings compute. cannot serve
purpose providing planner goal ordering information, allow generate plans
different levels refinement, see (Bacchus & Yang, 1994). Two approaches generating
abstraction hierarchies based numerical criticality values found (Sacerdoti, 1974; Bundy,
Giunchiglia, Sebastiani, & Walsh, 1996).

380

fiOn Reasonable Forced Goal Orderings
problem computationally intractable therefore, polynomial-time analysis method
must incomplete.
Last, least quite number approaches late Eighties,
focused directly subgoal orderings. fall two categories: approaches
described (Drummond & Currie, 1989; Hertzberg & Horz, 1989) focus detection
con icts caused goal interdependencies guide partial-order planner search.
investigate approaches detail extract explicit
goal orderings preprocess planning do. works described (Irani & Cheng,
1987; Cheng & Irani, 1989; Joslin & Roach, 1990) implement preprocessing approaches,
perform structural analysis planning task determine appropriate goal
ordering planning starts. Irani Cheng (1987) compute relation
pairs goals, which|roughly speaking|orders goal goal B B must
achieved achieved. formalism rather complicated theoretical
properties relation investigated. (Cheng & Irani, 1989), approach
extended sets goals ordered respect other. exact
properties formalism remain unclear. (Joslin & Roach, 1990), graph-theoretical
approach described generates graph atoms given domain description
nodes draws arc node node B operator exists takes
precondition B effect. assuming operators inverse
counterparts, identifying connected components graph proposed means
order goals. approach unlikely scale size problem spaces today's planners
consider completely outdated terms terminology.
Finally, one wonder reasonable forced goal orderings relate others
defined literature. one attempt know ordering
relation explicitly defined properties studied, see (Hullem et al., 1999).
paper, notion necessary goal orderings introduced, must true
minimal solution plans (Kambhampati, 1995).11 approach extends operator graphs
(Smith & Peot, 1993) orders goal based three criteria called goal subsumption, goal
clobbering, precondition violation. Goal subsumption < B holds every solution plan
achieving goal B state achieves goal state s0 preceding s, plan
achieving one goals G n fAg deletes A. Goal clobbering holds solution plan
deletes B thus, < B . Precondition violation holds solution B results
deadlock cannot reached anymore, i.e., < B . composite
criterion defined tests three criteria simultaneously.12 goal necessarily
ordered B satisfies composite criterion.
remark precondition violation seems equivalent forced orderings
introduced, goal clobbering appears similar reasonable orderings.
possible us verify conjecture authors (Hullem et al., 1999) give
exact formal definitions. nothing similar goal subsumption argue
criterion rarely satisfied natural problems: goal achieved every
11. plan minimal contains subplan solution plan. remark minimality
mean shortest plans least number actions considered. fact, minimal
plans highly non-optimal long action truly super uous.
12. Here, authors precise mean this. argue means
two goals ordered satisfy least one criteria.

381

fiKoehler & Hoffmann
solution goal B anyway, goal removed goal set without
changing planning task.
authors report able detect necessary orderings artificial
domains , cf. (Barrett & Weld, 1994), fail typical benchmark domains
blocks world tyreworld. reason seems operator graphs
represent possible instantiations operator schemes. authors claim,
makes operator graph analysis ecient. However, heuristic ordering
introduced paper takes almost computation time, succeeds finding
goal orderings domains.




h

7. Outlook

Three promising avenues future research following:
First, one imagine goal ordering information used search
process, i.e., ordering original goal set, goals emerge
search. major challenge seems balance effort computing goal
ordering information savings result search process. One
easily imagine ordering goal sets ever generated become quite costly
investment without yielding major benefit planner.
Secondly, refinement goal agenda additional subgoals another interesting future line work. first investigation using so-called intermediate goals (these
facts planner must make true achieve original goal)
explored inside GAM results reported (Koehler & Hoffmann, 1998). Earlier
work addressing task learning intermediate goals found (Ruby & Kibler,
1989), problem focus AI planning research since then.
third line work addresses interaction GAM forward-searching planning system. seen GAM preserves correctness planner,
preserves completeness least deadlock-free planning domains.
seen, however, solution plans using GAM get longer, i.e., GAM preserve optimality planner. Recently, planning systems deliver plans
guaranteed optimality demonstrated impressive performance terms runtime
plan length, e.g., HSP, first mentioned (Bonet, Loerincs, & Geffner, 1997),
GRT (Refanidis & Vlahavas, 1999), particular (Hoffmann, 2000). systems
heuristic-search planners searching forward state space non-admissible,
informative heuristics.
planning system developed one authors awarded \Group
Distinguished Performance Planning System" Schindler Award
best performing planning system Miconic 10 Elevator domain (ADL track)
AIPS 2000 planning competition. integration goal agenda techniques
planner one factors enabled excellent behavior competition:
crucial scaling blocks world problems 50 blocks, helped factor 2
schedule Miconic 10, never slowed algorithm.
Forward state-space search quite natural framework driven goal agenda:
Simply let planner solve subproblem, start next search state
last search ended. Even appealing, heuristic forward-search planners deeper
382

fiOn Reasonable Forced Goal Orderings
kind interaction GAM example graphplan-style planners. addition
smaller problems facing using goal agenda, heuristics
uenced employ techniques estimating goal distance state.
using goal agenda, different goal sets result stage planning process
therefore, goal-distance estimate different, too. Currently heuristic device
inside search algorithm developed, knows driven
goal agenda, access complete set goals. information
used prune unpromising branches search space discovers
currently achieved goals probably destroyed reachieved later on.
References

Allen, J. (Ed.), AIPS-98 (1998). Proceedings 4th International Conference Artificial Intelligence Planning Systems. AAAI Press, Menlo Park.
Anderson, C., & Weld, D. (1998). Conditional effects Graphplan. Allen (Allen, 1998),
pp. 44{53.
Bacchus, F., & Yang, Q. (1994). Downward refinement eciency hierarchical
problem solving. Artificial Intelligence, 71, 43{100.
Backstrom, C., & Jonsson, P. (1995). Planning abstraction hierarchies exponentially less ecient. Mellish (Mellish, 1995), pp. 1599{1604.
Barrett, A., & Weld, D. (1994). Partial-order planning: Evaluating possible eciency gains.
Artificial Intelligence, 67, 71{112.
Blum, A., & Furst, M. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90 (1{2), 279{298.
Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism planning. Proceedings 14th National Conference American
Association Artificial Intelligence, pp. 714{719.
Bundy, A., Giunchiglia, F., Sebastiani, R., & Walsh, T. (1996). Computing abstraction
hierarchies numerical simulation. Weld, & Clancey (Weld & Clancey, 1996), pp.
523{529.
Bylander, T. (1992). Complexity results serial decomposability. Proceedings
10th National Conference American Association Artificial Intelligence, pp.
729{734 San Jose, CA. MIT Press.
Bylander, T. (1994). computational complexity propositional STRIPS planning.
Artificial Intelligence, 69, 165{204.
Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32 (3), 333{377.
Cheng, J., & Irani, K. (1989). Ordering problem subgoals. Sridharan (Sridharan, 1989),
pp. 931{936.
383

fiKoehler & Hoffmann
Dawsson, C., & Siklossy, L. (1977). role preprocessing problem solving systems.
Proceedings 5th International Joint Conference Artificial Intelligence, pp.
465{471 Cambridge, MA.
Dimopoulos, Y., Nebel, B., & Koehler, J. (1997). Encoding planning problems nonmonotonic logic programs. Steel (Steel, 1997), pp. 169{181.
Drummond, M., & Currie, K. (1989). Goal ordering partially ordered plans. Sridharan
(Sridharan, 1989), pp. 960{965.
El-Kholy, A., & Richards, B. (1996). Temporal resource reasoning planning:
parcPLAN approch. Wahlster, W. (Ed.), Proceedings 12th European Conference Artificial Intelligence, pp. 614{618. John Wiley & Sons, Chichester, New
York.
Etzioni, O. (1993). Acquiring search-control knowledge via static analysis. Artificial Intelligence, 62, 255{301.
Fink, E., & Veloso, M. (1994). Prodigy planning algorithm. Technical report CMU-94-123,
Carnegie Mellon University.
Fox, M., & Long, D. (1998). automatic inference state invariants TIM. Journal
Artificial Intelligence Research, 9, 367{421.
Fox, M., & Long, D. (1999). Ecient implementation plan graph STAN. Journal
Artificial Intelligence Research, 10, 87{115.
Hertzberg, J., & Horz, A. (1989). Towards theory con ict detection resolution
nonlinear plans. Sridharan (Sridharan, 1989), pp. 937{942.
Hoffmann, J. (2000). heuristic domain independent planning use enforced
hill-climbing algorithm. 12th International Symposium Methods Intelligent
Systems.
Hullem, J., Munoz-Avila, H., & Weberskirch, F. (1999). Extracting goal orderings
improve partial-order Graphplan-based planning. Technical report, University
Kaiserslautern.
Irani, K., & Cheng, J. (1987). Subgoal ordering goal augmentation heuristic problem solving. McDermott, D. (Ed.), Proceedings 10th International Joint
Conference Artificial Intelligence, pp. 1018{1024 Milan, Italy. Morgan Kaufmann.
Jonsson, P., Haslum, P., & Backstrom, C. (2000). Towards ecient universal planning:
randomized approach. Artificial Intelligence, 117 (1), 1{29.
Joslin, D., & Roach, J. (1990). theoretical analysis conjunctive-goal problems. Artificial
Intelligence, 41, 97{106.
Kambhampati, S. (1995). Admissible pruning strategies based plan minimality planspace planning. Mellish (Mellish, 1995), pp. 1627{1633.
384

fiOn Reasonable Forced Goal Orderings
Kautz, H., & Selman, B. (1996). Pushing envelope: Planning, propositional logic,
stochastic search. Weld, & Clancey (Weld & Clancey, 1996), pp. 1194{1201.
Knoblock, C. (1991). Automatically Generating Abstractions Problem Solving. Ph.D.
thesis, Carnegie Mellon University.
Knoblock, C. (1994). Automatically generating abstractions planning. Artificial Intelligence, 68 (2), 243{302.
Koehler, J. (1999). Handling conditional effects negative goals IPP. Technical report 128, University Freiburg, Institute Computer Science. available
http://www.informatik.uni-freiburg.de/~ koehler/ipp.html.
Koehler, J., & Hoffmann, J. (1998). Planning goal agendas. Technical report
110, University Freiburg. available http://www.informatik.uni-freiburg.de/~
koehler/ipp.html.
Koehler, J., Nebel, B., Hoffmann, J., & Dimopoulos, Y. (1997). Extending planning graphs
ADL subset. Steel (Steel, 1997), pp. 273{285.
Korf, R. (1985). Macro-operators: weak method learning. Artificial Intelligence, 26,
35{77.
Korf, R. (1987). Planning search: quantitative approach. Artificial Intelligence, 33,
65{88.
McDermott, D., & Hanks, S. (1987). Nonmonotonic logic temporal projection. Artificial
Intelligence, 33, 379{412.
Mellish, C. (Ed.), IJCAI-95 (1995). Proceedings 14th International Joint Conference
Artificial Intelligence. Morgan Kaufmann, San Francisco, CA.
Nebel, B., & Backstrom, C. (1994). computational complexity temporal projection, planning, plan validation. Journal Artificial Intelligence, 66 (1), 125{160.
Nebel, B., Dimopoulos, Y., & Koehler, J. (1997). Ignoring irrelevant facts operators
plan generation. Steel (Steel, 1997), pp. 338{350.
Nilsson, N. (1980). Principles Artificial Intelligence. Tioga Publishing Company, Palo
Alto.
Pednault, E. (1989). ADL: Exploring middle ground STRIPS Situation
Calculus. Brachman, R., Levesque, H., & Reiter, R. (Eds.), Proceedings 1st
International Conference Principles Knowledge Representation Reasoning,
pp. 324{332 Toronto, Canada. Morgan Kaufmann.
Penberthy, J., & Weld, D. (1992). UCPOP: sound, complete, partial order planner
ADL. Nebel, B., Swartout, W., & Rich, C. (Eds.), Proceedings 3rd
International Conference Principles Knowledge Representation Reasoning,
pp. 103{113. Morgan Kaufmann, San Mateo.
385

fiKoehler & Hoffmann
Pollack, M., Joslin, D., & Paolucci, M. (1997). Selection strategies partial-order planning.
Journal Artificial Intelligence Research, 6, 223{262.
Refanidis, I., & Vlahavas, I. (1999). GRT: domain independent heuristic STRIPS
worlds based greedy regression tables. Proceedings 5th European Conference Planning, pp. 346{358.
Regli, W., Gupta, S., & Nau, D. (1995). AI planning versus manufactoring-operation
planning: case study. Mellish (Mellish, 1995), pp. 1670{1676.
Ruby, D., & Kibler, D. (1989). Learning subgoal sequences planning. Sridharan
(Sridharan, 1989), pp. 609{615.
Russel, S., & Norvig, P. (1995). Artificial Intelligence - modern Approach. Prentice Hall.
Sacerdoti, E. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence,
5, 115{135.
Sanborn, J., & Hendler, J. (1988). Near-term event projection dynamic simulation
robot cross road? Proceedings 2nd Conference AI
Simulation.
Smith, D., & Peot, M. (1993). Postponing threats partial-order planning. Proceedings
11th National Conference American Association Artificial Intelligence,
pp. 500{506. AAAI Press, MIT Press.
Sridharan, N. (Ed.), IJCAI-89 (1989). Proceedings 11th International Joint Conference Artificial Intelligence, Detroit, MI. Morgan Kaufmann.
Steel, S. (Ed.), ECP-97 (1997). Proceedings 4th European Conference Planning,
Vol. 1348 LNAI. Springer.
Tsuneto, R., Hendler, J., & Nau, D. S. (1998). Analyzing external conditions improve
eciency HTN planning. Allen (Allen, 1998), pp. 913{920.
Veloso, M., & Blythe, J. (1994). Linkability: Examining causal link commitments partialorder planning. Hammond, K. (Ed.), Proceedings 2nd International Conference Artificial Intelligence Planning Systems, pp. 170{175. AAAI Press, Menlo
Park.
Warshall, J. (1962). theorem boolean matrices. Journal ACM, 9 (1), 11{12.
Weld, D., & Clancey, B. (Eds.)., AAAI-96 (1996). Proceedings 14th National Conference American Association Artificial Intelligence. AAAI Press.
Williams, B., & Nayak, R. (1997). reactive planner model-based executive.
Proceedings 15th International Joint Conference Artificial Intelligence, pp.
1178{1185. Morgan Kaufmann, San Francisco, CA.

386


