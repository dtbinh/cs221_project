Journal Artificial Intelligence Research 12 (2000) 134

Submitted 7/99; published 2/00

Planning Graph (Dynamic) CSP:
Exploiting EBL, DDB CSP Search Techniques Graphplan
Subbarao Kambhampati

RAO @ ASU . EDU

Department Computer Science Engineering
Arizona State University, Tempe AZ 85287-5406

Abstract
paper reviews connections Graphplans planning-graph dynamic
constraint satisfaction problem motivates need adapting CSP search techniques
Graphplan algorithm. describes explanation based learning, dependency directed backtracking, dynamic variable ordering, forward checking, sticky values random-restart search
strategies adapted Graphplan. Empirical results provided demonstrate
augmentations improve Graphplans performance significantly (up 1000x speedups)on several
benchmark problems. Special attention paid explanation-based learning dependency
directed backtracking techniques empirically found useful improving
performance Graphplan.

1. Introduction
Graphplan (Blum & Furst, 1997) currently one efficient algorithms solving classical planning problems. Four five competing systems recent AIPS-98 planning competition based Graphplan algorithm (McDermott, 1998). Extending efficiency
Graphplan algorithm thus seems worth-while activity. (Kambhampati, Parker, &
Lambrecht, 1997), provided reconstruction Graphplan algorithm explicate links
previous work classical planning constraint satisfaction. One specific link discussed
connection process searching Graphplans planning graph, solving dynamic constraint satisfaction problem (DCSP) (Mittal & Falkenhainer, 1990). Seen DCSP
perspective, standard backward search proposed Blum Furst (1997) lacks variety ingredients thought make efficient CSP search mechanisms (Frost & Dechter, 1994;
Bayardo & Schrag, 1997). include forward checking, dynamic variable ordering, dependency directed backtracking explanation-based learning (Tsang, 1993; Kambhampati, 1998).
(Kambhampati et al., 1997), suggested would beneficial study impact
extensions effectiveness Graphplans backward search.
paper, describe experiences adding variety CSP search techniques improve Graphplan backward searchincluding explanation-based learning (EBL) dependencydirected backtracking capabilities (DDB), Dynamic variable ordering, Forward checking, sticky
values, random-restart search strategies. these, addition EBL DDB capabilities
turned empirically useful. EBL DDB based explaining failures
leaf-nodes search tree, propagating explanations upwards search
tree (Kambhampati, 1998). DDB involves using propagation failure explanations support
intelligent backtracking, EBL involves storing interior-node failure explanations, pruning
future search nodes. Graphplan use weak form failure-driven learning calls mem-

c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiK AMBHAMPATI

oization. shall see paper, Graphplans brand learning quite limited
explicit analysis reasons failure. Instead explanation failure search node
taken constraints search node. explained (Kambhampati, 1998),
eliminates opportunities dependency directed backtracking, adversely effects
utility stored memos.
Adding full-fledged EBL DDB capabilities effect gives Graphplan ability
intelligent backtracking, ability learn generalized memos likely
applicable situations. Technically, involves generalizing conflict-directed backjumping
(Prosser, 1993), specialized version EBL/DDB strategy applicable binary CSP problems1
work context dynamic constraint satisfaction problems (as discussed (Kambhampati, 1998)). Empirically, EBL/DDB capabilities improve Graphplans search efficiency quite
dramaticallygiving rise 1000x speedups, allowing Graphplan easily solve several
problems hither-to hard unsolvable. particular, report experiments
bench-mark problems described Kautz Selman (1996), well 4 domains,
used recent AIPS planning competition (McDermott, 1998).
discuss utility issues involved storing using memos, point Graphplan
memoization strategy seen conservative form CSP no-good learning.
conservative strategy keeps storage retrieval costs no-goods usual bane no-good
learning strategiesunder control, loses learning opportunities. present use
sticky values way recouping losses. Empirical studies show sticky
values lead 2-4x improvement EBL.
addition EBL DDB, investigated utility forward checking dynamic
variable ordering, isolation concert EBL DDB. empirical studies show
capabilities typically lead additional 2-4x speedup EBL/DDB,
competitive EBL/DDB.
Finally, consider utility EBL/DDB strategies context random-restart search
strategies (Gomes, Selman, & Kautz, 1998) recently shown good solving hard combinatorial problems, including planning problems. results show EBL/DDB
strategies retain advantages even context random-restart strategies. Specifically,
EBL/DDB strategies enable Graphplan use backtrack limits effectivelyallowing
achieve higher solvability rates, optimal plans significantly smaller backtrack
restart limits.
paper organized follows. next section, provide background viewing
Graphplans backward search (dynamic) constraint satisfaction problem, review
opportunities view presents. Section 3, discuss inefficiencies backtracking
learning methods used normal Graphplan motivate need EBL/DDB capabilities.
Section 4 describes EBL DDB added Graphplan. Section 5 presents empirical studies
demonstrating usefulness augmentations. Section 7 investigates utility forward
checking dynamic variable ordering strategies Graphplan. Section 8 investigates utility
EBL/DDB strategies context random-restart search. Section 9 discusses related work
Section 10 presents conclusions directions work.
1. Binary CSP problems problems initial constraints pairs variables.

2

fiP LANNING G RAPH

Action list
Level k-1

Proposition list
Level k-1

Action list
Level k

Proposition List
Level k

G1 ; ; G4 ; P1 P6
Domains: G1 : fA1 g; G2 : fA2 gG3 : fA3 gG4 : fA4 g
P1 : fA5 gP2 : fA6 ; A11 gP3 : fA7 gP4 : fA8 ; A9 g
P5 : fA10 gP6 : fA10 g
Constraints (normal):P1 = A5 ) P4 6= A9
P2 = A6 ) P4 6= A8
P2 = A11 ) P3 6= A7
Constraints (Activity): G1 = A1 ) ActivefP1 ; P2 ; P3 g
G2 = A2 ) ActivefP4 g
G3 = A3 ) ActivefP5 g
G4 = A4 ) ActivefP1 ; P6 g
Init State: ActivefG1 ; G2 ; G3 ; G4 g

P1
A6

A1

X
A7
A8

P3

11

A2

G2
G3

P4
P5

10

G1

P2

A9

X

CSP

Variables:

A5

X



A3

G4

P6
A4

(a) Planning Graph

(b) DCSP

Figure 1: planning graph DCSP corresponding

2. Review Graphplan Algorithm Connections DCSP
2.1 Review Graphplan Algorithm
Graphplan algorithm (Blum & Furst, 1997) seen disjunctive version forward
state space planners (Kambhampati et al., 1997; Kambhampati, 1997). consists two interleaved
phases forward phase, data structure called planning-graph incrementally extended,
backward phase planning-graph searched extract valid plan. planninggraph consists two alternating structures, called proposition lists action lists. Figure 1 shows
partial planning-graph structure. start initial state zeroth level proposition list.
Given k level planning graph, extension structure level k + 1 involves introducing
actions whose preconditions present k th level proposition list. addition actions
given domain model, consider set dummy persist actions, one condition
k th level proposition list. persist-C action C precondition C effect.
actions introduced, proposition list level k + 1 constructed union
effects introduced actions. Planning-graph maintains dependency links
actions level k + 1 preconditions level k proposition list effects level k + 1
proposition list. planning-graph construction involves computation propagation
mutex constraints. propagation starts level 1, actions statically interfering
(i.e., preconditions effects inconsistent) labeled mutex. Mutexes
propagated level forward using two simple rules: two propositions level k
marked mutex actions level k support one proposition mutex actions
support second proposition. Two actions level k + 1 mutex statically interfering
one propositions (preconditions) supporting first action mutually exclusive
one propositions supporting second action.
search phase k level planning-graph involves checking see sub-graph
planning-graph corresponds valid solution problem. involves starting
propositions corresponding goals level k (if goals present,
present pair marked mutually exclusive, search abandoned right away,
planning-grap grown another level). goal propositions, select action
3

fiK AMBHAMPATI

G1 ; ; G4 ; P1 P6
G1 : fA1 g; G2 : fA2 gG3 : fA3 gG4 : fA4 g
P1 : fA5 gP2 : fA6 ; A11 gP3 : fA7 gP4 : fA8 ; A9 g
P5 : fA10 gP6 : fA10 g
Constraints (normal):P1 = A5 ) P4 6= A9
P2 = A6 ) P4 6= A8
P2 = A11 ) P3 6= A7
Constraints (Activity): G1 = A1 ) ActivefP1 ; P2 ; P3 g
G2 = A2 ) ActivefP4 g
G3 = A3 ) ActivefP5 g
G4 = A4 ) ActivefP1 ; P6 g
Init State: ActivefG1 ; G2 ; G3 ; G4 g

G1 ; ; G4 ; P1 P6
G1 : fA1 ; ?g; G2 : fA2 ; ?gG3 : fA3 ; ?gG4 : fA4 ; ?g
P1 : fA5 ; ?gP2 : fA6 ; A11 ; ?gP3 : fA7 ; ?gP4 : fA8 ; A9 ; ?g
P5 : fA10 ; ?gP6 : fA10 ; ?g
Constraints (normal):P1 = A5 ) P4 6= A9
P2 = A6 ) P4 6= A8
P2 = A11 ) P3 6= A7
Constraints (Activity): G1 = A1 ) P1 6=? ^P2 6=? ^P3 6=?
G2 = A2 ) P4 6=?
G3 = A3 ) P5 6=?
G4 = A4 ) P1 6=? ^P6 6=?
Init State: G1 6=? ^G2 6=? ^G3 6=? ^G4 6=?

Variables:

Variables:

Domains:

Domains:

(a) DCSP

(b) CSP

Figure 2: Compiling DCSP standard CSP
level k action list supports it, two actions selected supporting two
different goals mutually exclusive (if are, backtrack try change selection
actions). point, recursively call search process k , 1 level planning-graph,
preconditions actions selected level k goals k , 1 level search.
search succeeds reach level 0 (corresponding initial state).
Consider (partial) planning graph shown Figure 3 Graphplan may generated
search solution. G1 G4 top level goals want satisfy,
A1 A4 actions support goals planning graph. specific actionprecondition dependencies shown straight line connections. actions A5 A11
left-most level support conditions P1 P6 planning-graph. Notice conditions P2
P4 level k , 1 supported two actions each. x-marked connections
actions A5 ; A9 , A6 ; A8 A7 ; A11 denote action pairs mutually exclusive. (Notice
given mutually exclusive relations alone, Graphplan cannot derive mutual exclusion
relations proposition level P1 P6 .)
2.2 Connections Graphplan CSP
Graphplan algorithm described bears little resemblance previous classical planning
algorithms. (Kambhampati et al., 1997), explicate number important links
Graphplan algorithm previous work planning constraint satisfaction communities.
Specifically, show planning-graph length k thought (to first approximation)
disjunctive (unioned) version k -level search tree generated forward state-space refinement,
action lists corresponding union actions appearing k th level, proposition
lists corresponding union states appearing k th level. mutex constraints
seen providing (partial) information subsets proposition list actually
correspond legal states corresponding forward state-space search. process searching
planning graph extract valid plan seen dynamic constraint satisfaction
problem. Since last link relevant work described paper, review
below.
dynamic constraint satisfaction problem (DCSP) (Mittal & Falkenhainer, 1990) generalization constraint satisfaction problem (Tsang, 1993), specified set variables,
4

fiP LANNING G RAPH



CSP

activity flags variables, domains variables, constraints legal variablevalue combinations. DCSP, initially subset variables active, objective
find assignments active variables consistent constraints among variables. addition, DCSP specification contains set activity constraints. activity
constraint form: variable x takes value vx , variables y; z; w::: become
active.
correspondence planning-graph DCSP clear. Specifically, propositions various levels correspond DCSP variables2 , actions supporting correspond variable domains. three types constraints: action mutex
constraints, fact (proposition) mutex constraints subgoal activation constraints.
Since actions modeled values rather variables, action mutex constraints
modeled indirectly constraints propositions. two actions a1 a2 marked mutex
planning graph, every pair propositions p11 p12 a1
one possible supporting actions p11 a2 one possible supporting actions
p12 , constraint:

: (p11 = a1 ^ p12 = a2 )
Fact mutex constraints modeled constraints prohibit simultaneous activation
two facts. Specifically, two propositions p11 p12 marked mutex planning graph,
constraint:

: (Active(p11 ) ^ Active(p12 ))

Subgoal activation constraints implicitly specified action preconditions: supporting
active proposition p action makes propositions previous level corresponding
preconditions active.
Finally, propositions corresponding goals problem active beginning. Figure 1 shows dynamic constraint satisfaction problem corresponding example
planning-graph discussed.
2.2.1 OLVING



DCSP

two ways solving DCSP problem. first, direct, approach (Mittal & Falkenhainer,
1990) involves starting initially active variables, finding satisfying assignment
them. assignment may activate new variables, newly activated variables
assigned second epoch. process continues reach epoch new
variables activated (which implies success), unable give satisfying assignment
activated variables given epoch. latter case, backtrack previous epoch
try find alternative satisfying assignment variables (backtracking further,
assignment possible). backward search process used Graphplan algorithm (Blum &
Furst, 1997) seen solving DCSP corresponding planning graph direct
fashion.
second approach solving DCSP first compile standard CSP, use
standard CSP algorithms. compilation process quite straightforward illustrated
2. Note literal appearing different levels corresponds different DCSP variables. Thus, strictly speaking, literal p proposition list level converted DCSP variable pi . keep matters simple,
example Figure 1 contains syntactically different literals different levels graph.

5

fiK AMBHAMPATI

Figure 2. main idea introduce new null value (denoted ?) domains
DCSP variables. model inactive DCSP variable CSP variable
takes value ?. constraint particular variable P active modeled P 6=?. Thus,
activity constraint form

G1 = A1 ) ActivefP1 ; P2 ; P3 g
compiled standard CSP constraint

G1 = A1 ) P1 6=? ^P2 6=? ^P3 6=?
worth noting activation constraints concerned ensuring
propositions preconditions selected action take non-? values. thus allow
possibility propositions become active (take non-? values) even though
strictly supporting preconditions selected action. Although lead inoptimal
plans, mutex constraints ensure unsound plans produced (Kautz & Selman,
1999). avoid unnecessary activation variables, need add constraints effect
unless one actions needing variable precondition selected value
variable earlier (higher) level, variable must ? value. constraints
typically going high arity (as wind mentioning large number variables
previous level), may thus harder handle search.
Finally, mutex constraint two propositions

: (Active(p11 ) ^ Active(p12 ))
compiled

: (p11 6=? ^p12 6=?) :

Since action mutex constraints already standard CSP form, compilation,
activity constraints converted standard constraints thus entire CSP
standard CSP. solved standard CSP search techniques (Tsang, 1993).3
direct method advantage closely mirrors Graphplans planning graph
structure backward search. this, possible implement approach
plan graph structure without explicitly representing constraints. Furthermore, discuss Section 6, distinct advantages adopting DCSP view implementing
EBL/DDB Graphplan. compilation CSP requires plan graph first converted
extensional CSP. however allow use standard algorithms, well supports nondirectional search (in one follow epoch-by-epoch approach assigning
variables).4 Since main aim illustrate utility CSP search techniques context
Graphplan algorithm, adopt direct solution method DCSP. study
tradeoffs offered technique compiling planning graph CSP, reader referred
(Do & Kambhampati, 2000).
3. possible compile CSP problem propositional satisfiability problem (i.e., CSP problem
boolean variables). accomplished compiling every CSP variable P domain fv1 ; v2 ; ; vn g
n boolean variables form P-is-v1 P-is-vn . Every constraint form P
vj ^ ) compiled
P-is-vj ^ ) . essentially done BLACKBOX system (Kautz & Selman, 1999).
4. Compilation CSP strict requirement non-directional search. (Zimmerman & Kambhampati,
1999), describe technique allows backward search Graphplan non-directional, see discussion
Section 10.

=

6

fiP LANNING G RAPH



CSP

2.3 Interpreting Mutex Propagation CSP View
Viewing planning graph constraint satisfaction problem helps put mutex propagation
clearer perspective (see (Kambhampati et al., 1997)). Specifically, way Graphplan constructs planning graph, winds enforcing partial directed 1-consistency partial directed
2-consistency (Tsang, 1993). partial 1-consistency ensured graph building procedure
introduces action level l actions preconditions present proposition
list level l , 1 mutually exclusive. Partial 2-consistency ensured mutual
exclusion propagation procedure.
particular, Graphplan planning graph construction implicitly derives no-good5 constraints form:

:Active(Pmi ) (or Pmi 6=?)

simply removed (or put into) level i, mutex
case Pm
constraints form:




: Active(Pmi ) ^ Active(Pni )

Pmi 6=? ^Pni 6=?)

(

P marked mutually exclusive.
case Pm
n
procedures directed use reachability analysis enforcing consistency, partial enforce either full 1-consistency full 2-consistency.
Lack full 1-consistency verified fact appearance goal level k
necessarily mean goal actually achievable level k (i.e., solution CSP
assigns non- ? value goal level). Similarly, lack full 2-consistency verified fact appearance pair goals level k imply plan
achieving goals level.
another, somewhat less obvious, way consistency enforcement used
Graphplan partial (and conservative)it concentrates whether single goal variable
pair goal variables simultaneously non- ? values (be active) solution. may
goal non- ? value, non- ? values feasible. Similarly, may
pair goals achievable, necessarily achievable every possible pair actions
respective domains.
interpretation mutex propagation procedure Graphplan brings fore several possible
extensions worth considering Graphplan:
1. Explore utility directional consistency enforcement procedures based solely
reachability analysis. Kambhampati et. al. (1997) argue extending analysis using
relevance information, et. al. (2000) provide empirical analysis effectiveness
consistency enforcement relevance information.
2. Explore utility enforcing higher level consistency. pointed (Kambhampati
et al., 1997; Kambhampati, 1998), memoization strategies seen failure-driven
procedures incrementally enforce partial higher level consistency.
5. Normally, CSP literature, no-good seen compound assignment part feasible
6 ? ^Pni 6 ? correspond conjunction nogoods
solution. view, mutex constraints form Pm


Pni .
form Pm au ^ Pn av au av values domains Pm

=

=

=

7

=

fiK AMBHAMPATI

3. Consider relaxing focus non- ? values alone, allow derivation no-goods
form

Pmi = au ^ Pni = av

guaranteed winning idea number derived no-goods increase
quite dramatically. particular, assuming l levels planning graph,
average goals per level, average actions supporting goal, maximum
number Graphplan style pair-wise mutexes (l m2 ) 2-size no-goods
type discussed (l (m (d + 1))2 ). consider similar issue context
Graphplan memoization strategy Section 6.

3. Inefficiencies Graphplans Backward Search
motivate need EBL DDB, shall first review details Graphplans backward
search, pinpoint inefficiencies. shall base discussion example planning
graph Figure 3 (which reproduced convenience Figure 1). Assuming G1 G4
top level goals problem interested solving, start level k , select
actions support goals G1 G4 . keep matters simple, shall assume search
assigns conditions (variables) level top bottom (i.e., G1 first, G2
on). Further, choice actions (values) support condition,
consider top actions first. Since one choice conditions level,
none actions mutually exclusive other, select actions A1 ; A2 ; A3
A4 supporting conditions level k . make sure preconditions
A1 ; A2 ; A3 ; A4 satisfied level k , 1. thus subgoal conditions P1 P6 level
k , 1, recursively start action selection them. select action A5 P1 . P2 ,
two supporting actions, using convention, select A6 first. P3 , A7
choice. get selecting support P4 , choice. Suppose
select A8 first. find choice infeasible A8 mutually exclusive A6
already chosen. So, backtrack choose A9 , find mutually exclusive
previously selected action, A5 . stymied choices P4 . So,
backtrack undo choices previous conditions. Graphplan uses chronological
backtracking approach, whereby, first tries see P3 re-assigned, P2 on.
Notice first indication inefficiency failure assign P4 nothing
assignment P3 , yet, chronological backtracking try re-assign P3 vain hope
averting failure. lead large amount wasted effort case P3
indeed choices.
turns out, find P3 choices backtrack it. P2 another
choice A11 . try continue search forward value P2 , hit impasse P3
since value P3 , A7 mutex A11 . point, backtrack P3 , continue
backtracking P2 P1 , remaining choices. backtrack
P1 , need go back level k try re-assign goals level. done,
Graphplan search algorithm makes memo signifying fact failed satisfy goals
P1 P6 level, hope search ever subgoals set goals
future, scuttle right away help remembered memo. second
indication inefficiency remembering subgoals P1 P6 even though see
problem lies trying assign P1 ; P2 ; P3 P4 simultaneously, nothing
8

fiP LANNING G RAPH

Action list
Level k-1

Proposition list
Level k-1



CSP

Action list
Level k

Proposition List
Level k

A5
P1
A6

X

A1

X
A7
A8

P2
A2

P3

G3
A3

P5
10

G2

P4

A9

X

G1

G4

P6
A4

11

Figure 3: running example used illustrate EBL/DDB Graphplan
subgoals. remember fP1 ; P2 ; P3 ; P4 g memo fP1 P6 g,
remembered memo would general, would much better chance useful
future.
memo stored, backtracking continues level k chronological
fashion, trying reassign G4 ; G3 ; G2 G1 order. see third indication inefficiency caused chronological backtracking G3 really role failure encountered
assigning P3 P4 since spawns condition P5 level k , 1. Yet, backtracking
scheme Graphplan considers reassigning G3 . somewhat subtle point reassigning
G4 going avert failure either. Although G4 requires P1 one conditions taking
part failure, P1 required G1 unless G1 gets reassigned, considering
assignments G4 going avert failure.
example, continue backtracking G2 G1 too, since alternative supports, finally memoize fG1 ; G2 ; G3 ; G4 g level. point backward search
fails, Graphplan extends planning graph another level re-initiating backward
search extended graph.

4. Improving Backward Search EBL DDB
describe Graphplans backward search augmented full fledged EBL
DDB capabilities eliminate inefficiencies pointed previous section. Informally,
EBL/DDB strategies involve explanation failures leaf nodes, regression propagation
leaf node failure explanations compute interior node failure explanations, along lines described (Kambhampati, 1998). specific extensions propose backward search

9

fiK AMBHAMPATI

essentially seen adapting conflict-directed backjumping strategy (Prosser, 1993), generalizing work dynamic constraint satisfaction problems.
algorithm shown pseudo-code form Figure 4. contains two mutually recursive
procedures find-plan assign-goals. former called level
planning-graph. calls assign-goals assign values required conditions
level. assign-goals picks condition, selects value it, recursively calls
remaining conditions. invoked empty set conditions assigned, calls
find-plan initiate search next (previous) level.
order illustrate EBL/DDB capabilities added, lets retrace previous example,
pick point assign P4 level k , 1, assigned P1 ; P2
P3 . try assign value A8 P4, violate mutex constraint A6 A8.
explanation failure search node set constraints False derived.
complete explanation failure thus stated as:

P2 = A6 ^ P4 = A8 ^ (P2 = A6 ) P4 6= A8 )
this, part P2 = A6 ) P4 6= A8 stripped explanation since mutual
exclusion relation hold long solving particular problem particular
actions. Further, take cue conflict directed backjumping algorithm (Prosser,
1993), represent remaining explanation compactly terms conflict sets. Specifically,
whenever search reaches condition c (and find assignment it), conflict
set initialized fcg. Whenever one possible assignments c inconsistent (mutually
exclusive) current assignment previous variable c0 , add c0 conflict set c.
current example, start fP4 g conflict set P4 , expand adding P2
find A8 cannot assigned P4 choice A6 support P2 . Informally,
conflict set representation seen incrementally maintained (partial) explanation
failure, indicating conflict current value P2 one possible
values P4 (Kambhampati, 1998).
consider second possible value P4 , viz., A9 , find mutually exclusive
A5 currently supporting P1 . Following practice, add P1 conflict set
P4 . point, choices P4 , backtrack P4 , passing
conflict set P4 , viz., fP1 ; P2 ; P4 g reason failure. essence, conflict set
shorthand notation following complete failure explanation (Kambhampati, 1998):6
[(

P4 = A8 ) _ (P4 = A9 )] ^ (P1 = A5 ) P4 6= A9 ) ^ (P2 = A6 ) P4 6= A8 ) ^ P1 = A5 ^ P2 = A6

worth noting point P4 revisited future different assignments
preceding variables, conflict set re-initialized fP4 g considering assignments it.
first advantage conflict set allows transparent way supporting dependency directed backtracking (Kambhampati, 1998). current example, failed assign
P4 , start backtracking. need chronological fashion however.
6. strip first (disjunctive) clause since present graph structure, next two implicative clauses
since part mutual exclusion relations change problem. conflict set representation keeps condition (variable) names last two clauses denoting, essence, current
assignments variables P1 P2 causing failure assign P4 .

10

fiP LANNING G RAPH



CSP

Find-Plan(G:goals, pg : plan graph, k : level)
k = 0, Return empty subplan P success.
memo G,
Fail, return conflict set
Call Assign-goals(G; pg; k; ;).
Assign-goals fails returns conflict set ,
Store memo
Regress actions selected level k + 1 get R
Fail return R conflict set
Assign-goals succeeds, returns k -level subplan P ,
Return P success
Assign-goals(G:goals, pg : plan graph, k : level, A: actions)
G = ;
Let U union preconditions actions
Call Find-plan(U; pg; k , 1)
Find-plan fails returns conflict set R,
Fail return R
Find-plan succeeds returns subplan P length k , 1
Succeed return k length subplan P
Else ;;(G 6= ;)
Select goal g 2 G
Let cs
fgg, Ag set actions level k pg support g
L1:
Ag = ;, Fail return cs conflict set
Ag ,
Else, pick action 2 Ag , set Ag
mutually exclusive action b 2
Let l goal b selected support
cs [ flg
Set cs
Goto L1
Else (a mutually exclusive action A)
Call Assign-goals(G , fg g; pg; k; [ fag)
call fails returns conflict set C
g 2 C
Set cs = cs [ C ;conflict set absorption
Goto L1
Else ;(g 62 C )
Fail return C conflict set
;dependency directed backjumping

Figure 4: pseudo-code description Graphplan backward search enhanced EBL/DDB capabilities. backward search level k planning-graph pg initiated call
Find-Plan(G; pg; k), G set top level goals problem.
11

fiK AMBHAMPATI

Instead, jump back recent variable (condition) taking part conflict set P4
case P2 . so, avoiding considering alternatives P3 , thus avoiding
one inefficiencies standard backward search. easy see backjumping
sound since P3 causing failure P4 thus re-assigning wont avert failure.
Continuing along, whenever search backtracks condition c, backtrack conflict
absorbed current conflict set c. example, absorb fP1 ; P2 ; P4 g conflict
set P2 , currently fP2 g (making fP1 ; P2 ; P4 g new conflict set P2 ). assign
A11 , remaining value, P2 . Next try assign P3 find value A7
mutex A11 . Thus, set conflict set P3 fP3 ; P2 g backtrack conflict
set. backtracking reaches P2 , conflict set absorbed current conflict set
P2 (as described earlier), giving rise fP1 ; P2 ; P3 ; P4 g current combined failure reason
P2 . step illustrates conflict set condition incrementally expanded collect
reasons failure various possible values condition.
point, P2 choices, backtrack P2 current conflict set,
fP1 ; P2 ; P3 ; P4 g. P1 , first absorb conflict set fP1 ; P2 ; P3 ; P4 g P1 current conflict
set, re-initiate backtracking since P1 choices.
Now, reached end current level (k , 1). backtracking P1 must
involve undoing assignments conditions k th level. however,
two steps: memoization regression.
4.1 Memoization
backtrack first assigned variable given level, store conflict set
variable memo level. store conflict set fP1 ; P2 ; P3 ; P4 g P1 memo
level. Notice memo store shorter (and thus general) one stored
normal Graphplan, include P5 P6 , anything
failure7
4.2 Regression
backtrack level k , 1 level k , need convert conflict set (the first
assigned variable in) level k , 1 refers conditions level k . conversion
process involves regressing conflict set actions selected k th level (Kambhampati,
1998). essence, regression step computes (smallest) set conditions (variables)
kth level whose supporting actions spawned (activated, DCSP terms) conditions (variables)
conflict set level k , 1. current case, conflict set fP1 ; P2 ; P3 ; P4 g.
see P2 , P3 required condition G1 level k , condition P4 required
condition G2 .
case condition P1 , G1 G4 responsible it, supporting
actions needed P1 . cases two heuristics computing regression: (1) Prefer
choices help conflict set regress smaller set conditions (2) still choice
multiple conditions level k , pick one assigned earlier. motivation first rule keep failure explanations compact (and thus general) possible,
7. current example, memo includes conditions P4 (which farthest gone
level), even always necessary. verify P3 would memo set A11
one supporters P2 .

12

fiP LANNING G RAPH



CSP

motivation second rule support deeper dependency directed backtracking.
important note heuristics aimed improving performance EBL/DDB
affect soundness completeness approach.
current example, first rules applies, since P1 already required G1 ,
requiring P2 P3 . Even case (i.e., G1 required P1 ), still would
selected G1 G4 regression P1 , since G1 assigned earlier search.
result regressing fP1 ; P2 ; P3 ; P4 g actions k th level thus fG1 ; G2 g. start
backtracking level k conflict set. jump back G2 right away, since
recent variable named conflict set. avoids inefficiency re-considering
choices G3 G4 , done normal backward search. G2 , backtrack conflict set
absorbed, backtracking continues since choices. procedure
repeated G1 . point, end leveland memoize fG1 ; G2 g
memo level k . Since levels backtrack to, Graphplan called
extend planning-graph one level.
Notice memos based EBL analysis capture failures may require significant
amount search rediscover. example, able discover fG1 ; G2 g failing
goal set despite fact mutex relations choices goals G1
G2 .
4.3 Using Memos
end section, couple observations regarding use stored memos.
standard Graphplan, memos level stored level-specific hash table. Whenever
backward search reaches level k set conditions satisfied, consults hash table
see exact set conditions stored memo. Search terminated exact hit
occurs. Since EBL analysis allows us store compact memos, likely complete goal
set level k going exactly match stored memo. likely stored
memo subset goal set level k (which sufficient declare goal set failure).
words, memo checking routine Graphplan needs modified checks
see subset current goal set stored memo. naive way
involves enumerating subsets current goal set checking
hash table, turns costly. One needs efficient data structures, setenumeration trees (Rymon, 1992). Indeed, Koehler co-workers (Koehler, Nebel, Hoffman,
& Dimopoulos, 1997) developed data structure called UB-Trees storing memos.
UB-Tree structures seen specialized version set-enumeration trees,
efficiently check subset current goal set stored memo.
second observation regarding memos often serve failure explanation
themselves. Suppose level k , find goal set level subsumes
stored memo . use failure explanation level, regress
back previous level. process provide us valuable opportunities
back jumping levels k . allows us learn new compact memos levels. Note
none would possible normal memos stored Graphplan,
way memo declare goal set level k failing memo exactly equal goal
set. case regression get us goals level k + 1, buy us
backjumping learning power (Kambhampati, 1998).

13

fiK AMBHAMPATI

5. Empirical Evaluation Effectiveness EBL/DDB
seen way EBL DDB capabilities added backward search maintaining updating conflict-sets. noted EBL DDB capabilities avoid variety
inefficiencies standard Graphplan backward search. augmentations soundness completeness preserving follows corresponding properties conflict-directed
backjumping (Kambhampati, 1998). remaining (million-dollar) question whether capabilities make difference practice. present set empirical results answer
question.
implemented EBL/DDB approach described previous section top Graphplan
implementation Lisp.8 changes needed code add EBL/DDB capability relatively minor two functions needed non-trivial changes9 . added UB-Tree subset
memo checking code described (Koehler et al., 1997). ran several comparative experiments
benchmark problems (Kautz & Selman, 1996), well four domains.
specific domains included blocks world, rocket world, logistics domain, gripper domain, ferry
domain, traveling salesperson domain, towers hanoi. domains, including
blocks world, logistics domain gripper domain used recent AI Planning
Systems competition. specifications problems well domains publicly available.
Table 1 shows statistics times taken number backtracks made normal Graphplan, Graphplan EBL/DDB capabilities.10
5.1 Run-Time Improvement
first thing note EBL/DDB techniques offer quite dramatic speedups 1.6x
blocks world way 120x logistics domain (the Att-log-a problem unsolvable
normal Graphplan 40 hours cpu time!). note number backtracks
reduces significantly consistently EBL/DDB. Given lengh runs, time
Lisp spends garbage collection becomes important issue. thus report cumulative time
(including cpu time garbage collection time) Graphplan EBL/DDB, separate
cpu time cumulative time plain Graphplan (in cases total time spent
large enough garbage collection time significant fraction). Specifically, two
entrys column corresponding total time normal Graphplan. first entry
cpu time spent, second entry parenthesis cumulative time (cpu time garbage
collection time) spent. speedup computed respect cumulative time Graphplan
EBL/DDB cpu time plain Graphplan. 11 reported speedups thus seen
conservative estimates.
8. original lisp implementation Graphplan done Mark Peot. implementation subsequently
improved David Smith.
9. Assign-goals find-plan
10. earlier versions paper, including paper presented IJCAI (Kambhampati, 1999) reported
experiments Sun SPARC Ultra 1 running Allegro Common Lisp 4.3. Linux machine run-time statistics
seem approximately 2.7x faster Sparc machine.
11. interesting note percentage time spent garbage collection highly problem dependent.
example, case Att-log-a, 30 minutes 41 hours (or 1% cumulative time) spent
garbage collection, case Tower-6, 3.1 hours 4.8 hours (or 65% cumulative
time) spent garbage collection!

14

fiProblem

Speedup
1.7x
1.8x
24x
17x
>1215x
11x
90x
>10x
42x
>40x
50x
37x
>25x
90x
>58x

Table 1: Empirical performance EBL/DDB. Unless otherwise noted, times cpu minutes Pentium-III 500 MHZ machine
256meg RA running Linux allegro common lisp 5, compiled speed. Tt total time, Mt time used checking
memos Btks number backtracks done search. times Graphplan EBL/DDB include cpu
garbage collection time, cpu time separated total time case normal Graphplan. numbers
parentheses next problem names list number time steps number actions respectively solution. AvLn
AvFM denote average memo length average number failures detected per stored memo respectively.

CSP

AvFM
1.26
1.13
3.2
3.22
4.9
2.2
2.3
2.4
5
-



Normal Graphplan
Tt. Mt.
# Btks AvLn
5.3 0.22
5181K
11.3
4.15 0.05
2823K 11.83
19.43 11.7
8128K
23.9
14.1
7.7 10434K
23.8
>40.5hr (>41hr)
32
1.1
.39
2802K
14.9
215(272)
17.8
>8.2hr(>16hr)
7.23 1.27 19070K
20.9
>1.7hr (>4.8hr)
22.3
22(29)
11 33357K
24.5
42(144)
24 53233K
25
>5hr(>18.4hr)
89(93) 56.7 68648K
13
>12hr (>14.5hr)
-

P LANNING G RAPH

15

Huge-Fact (18/18)
BW-Large-B (18/18)
Rocket-ext-a (7/36)
Rocket-ext-b (7/36)
Att-log-a(11/79)
Gripper-6 (11/17)
Gripper-8 (15/23)
Gripper-10(19/29)
Tower-5 (31/31)
Tower-6 (63/63)
Ferry-41 (27/27)
Ferry-5 (31/31)
Ferry-6(39/39)
Tsp-10 (10/10)
Tsp-12(12/12)

Graphplan EBL/DDB
Tt
Mt
# Btks AvLn AvFM
3.08 0.28
2004K
9.52
2.52
2.27 0.11
798K 10.15
3.32
.8
.34
764K
8.5
82
.8
.43
569K
7.5
101
1.97
.89
2186K
8.21 46.18
0.1 0.03
201K
6.9
6.2
2.4
.93
4426K
9
7.64
47.9 18.2 61373K 11.05
8.3
.17 0.02
277K
6.7
2.7
2.53 0.22
4098K
7.9
2.8
.44 0.13
723K
7.9
2.54
1.13
.41
1993K
8.8
2.53
11.62
5.3 18318K
10.9
2.6
.99 0.23
2232K
6.9
12
12.4 2.65 21482K
7.9
15.2

fiK AMBHAMPATI

5.2 Reduction Memo Length
results highlight fact speedups offered EBL/DDB problem/domain
dependent quite meager blocks world problems, quite dramatic many
domains including rocket world, logistics, ferry, gripper, TSP Hanoi domains. statistics
memos, shown Table 1 shed light reasons variation. particular interest
average length stored memos (given columns labeled AvLn). general,
expect EBL analysis reduces length stored memos, conditions part
failure explanation stored memo. However, advantage depends
likelihood small subset goals given level actually taking part failure.
likelihood turn depends amount inter-dependencies goals given
level. table, note average length reduces quite dramatically rocket world
logistics12 , reduction much less pronounced blocks world. variation
traced back larger degree inter-dependency goals given level blocks
world problems.
reduction average memo length correlated perfectly speedups offered EBL
corresponding problems. Let put perspective. fact average length
memos Rocket-ext-a problem 8.5 EBL 24 without
EBL, shows essence
,
normal Graphplan re-discovering 8-sized failure embedded 24
8 possible ways worst
case 24 sized goal set storing new memo time (incurring increased backtracking
matching costs)! thus wonder normal Graphplan performs badly compared
Graphplan EBL/DDB.
5.3 Utility Stored Memos
statistics Table 1 show increased utility memos stored Graphplan
EBL/DDB. Since EBL/DDB store general (smaller) memos normal Graphplan,
should, theory, generate fewer memos use often. columns labeled AvFM
give ratio number failures discovered use memos number memos
generated first place. seen measure average utility stored
memos. note utility consistently higher EBL/DDB. example, Rocketext-b, see average EBL/DDB generated memo used discover failures 101
times, number 3.2 memos generated normal Graphplan.13
5.4 Relative Utility EBL vs. DDB
statistics Table 1, see even though EBL make significant improvements
run-time, significant fraction run time EBL (as well normal Graphplan) spent
memo checking. raises possibility overall savings mostly DDB part
EBL part (i.e, part involving storing checking memos) fact net drain
(Kambhampati, Katukam, & Qu, 1997). see true, ran problems EBL (i.e.,
memo-checking) disabled. DDB capability well standard Graphplan memoization
12. case Att-log-a, took memo statistics interrupting search 6 hours
13. statistics Att-log-aseem suggest memo usage bad normal Graphplan. However,
noted Att-log-a solved normal Graphplan begin with. improved usage factor may due
mostly fact search went considerably longer time, giving Graphplan opportunity use
memos.

16

fiP LANNING G RAPH

Problem
Att-log-a
Tower-6
Rocket-ext-a
Gripper-8
TSP-10
Huge-Fct

EBL+DDB
Btks
Time
2186K 1.95
4098K 2.37
764K
.83
4426K 2.43
2238K
1.1
2004K 3.21



CSP

DDB
Btks
Time
115421K 235
97395K
121
3764K
17.18
5426K
4.71
4308K
2.3
2465K
3.83

Speedup
120x
51x
21x
1.94x
2.09x
1.19x

Table 2: Utility storing using EBL memos DDB
strategies left in.14 results shown Table 2, demonstrate ability store
smaller memos (as afforded EBL) quite helpfulgiving rise 120x speedup DDB alone
Att-log-a problem, 50x speedup Tower-6 problem. course, results show
DDB important capability itself. Indeed, Att-log-aand tower-6 could even solved
standard Graphplan, DDB, problems become solvable. summary, results
show EBL DDB net positive utility.
5.5 Utility Memoization
Another minor, well-recognized, point brought statistics Table 1
memo checking sometimes significant fraction run-time standard Graphplan.
example, case Rocket-ext-a, standard Graphplan takes 19.4 minutes 11.7 minutes,
half time, spent memo checking (in hash tables)! raises possibility
disable memoization, perhaps well version EBL/DDB.
see case, ran problems memoization disabled. results show
general disabling memo-checking leads worsened performance. came across
cases disablement reduces overall run-time, run-time still much higher
get EBL/DDB. example, case Rocket-ext-a, disable memo
checking completely, Graphplan takes 16.5 minutes, lower 19.4 minutes taken
standard Graphplan, still much higher .8 minutes taken version Graphplan
EBL/DDB capabilities added. add DDB capability, still disabling memochecking, run time becomes 2.4 minutes, still 3 times higher afforded
EBL capability.
5.6 C vs. Lisp Question
Given existing implementations Graphplan done C many optimizations,
one nagging doubt whether dramatic speedups due EBL/DDB somehow dependent
moderately optimized Lisp implementation used experiments. Thankfully,
EBL/DDB techniques described paper (re)implemented Maria Fox
Derek Long STAN system. STAN highly optimized implementation Graphplan
fared well recent AIPS planning competition. found EBL/DDB resulted
similar dramatic speedups system (Fox, 1998; Fox & Long, 1999). example,
14. considered removing memoization completely, results even poorer.

17

fiK AMBHAMPATI

unable solve Att-log-a plain Graphplan, could solve easily EBL/DDB
added.
Finally, worth pointing even EBL/DDB capabilities, unable solve
larger problems AT&T benchmarks, bw-large-c Att-log-b. however
indictment EBL/DDB since knowledge planners solved
problems used either local search strategies GSAT, randomized re-start strategies,
used additional domain-specific knowledge pre-processing. least,
aware existing implementations Graphplan solve problems.

6. Utility Graphplan Memos
One important issue using EBL managing costs storage matching. Indeed, discussed (Kambhampati, 1998), naive implementations EBL/DDB known lose gains
made pruning power matching storage costs. Consequently, several techniques
invented reduce costs selective learning well selective forgetting.
interesting see costs prominent issue EBL/DDB Graphplan.
think mostly two characteristics Graphplan memoization strategy:
1. Graphplans memoization strategy provides compact representation no-goods,
well selective strategy remembering no-goods. Seen DCSP, remembers
subsets activated variables satisfying assignment. Seen CSP (c.f.
Figure 2), Graphplan remembers no-goods form

P1i 6=? ^P2i 6=? Pmi 6=?
(where superscripts correspond level planning graph proposition
belongs), normal EBL implementations learn no-goods form

P1i = a1 ^ P2j = a2 Pmk =
Suppose planning graph contains n propositions divided l levels, proposition
P level j actions supporting it. CSP compilation planning graph
n variables, + 1 values (the extra one ?). normal EBL implementation
CSP learn, worst case, (d + 2)n no-goods.15 contrast, Graphplan
n
remembers l 2 l memos16 dramatic reduction. reduction result two
factors:
(a) individual memo stored Graphplan corresponds exponentially large set
normal no-goods (the memo

P1i 6=? ^P2i 6=? Pmi 6=?
shorthand notation conjunction dm no-goods corresponding possible
i)
non- ? assignments P1i Pm

15. variable v may either present no-good, present one
possibilities n variables.
16. level, nl propositions either occurs memo occur

+1

18

+ 1 possible assignmentsgiving

fiP LANNING G RAPH



CSP

(b) Memos subsume no-goods made proposition variables planning graph level.
2. matching cost reduced fact considerably fewer no-goods ever
learned, fact Graphplan stores no-goods (memos) separately level,
consults memos stored level j , backwards search level j ,
discussion throws light so-called EBL utility problem
critical Graphplan EBL done normal CSPs.
6.1 Scenarios Memoization Conservative Avoid Rediscovery
Failures
discussion raises possibility Graphplan (even EBL/DDB) memoization
conservative may losing useful learning opportunities
required syntactic form. Specifically, Graphplan learn memo form

P1i 6=? ^P2i 6=? Pmi 6=?;
must case dm possible assignments propositional variables must
no-good. Even one no-good, Graphplan avoids learning memo, thus
potentially repeating failing searches later time (although loss made extent
learning several memos lower level).
P
Consider example following scenario: set variables P1i Pm
n
level assigned backward search. Suppose search found legal partial asi , domain P contains k values fv1 vk g.
signment variables P1i Pm

,1

trying assign variables Pm Pni , suppose repeatedly fail backtrack variable
Pmi , re-assigning eventually settling value v7. point backtracking
higher level variables (P P ) re-assigning
occurs, time backtrack Pm

1
them. point, would useful remember no-goods effect none
going work backtracking repeated.
first 6 values Pm
no-goods take form:

Pmi = vj ^ Pmi +1 6=? ^Pmi +2 6=? Pni 6=?
tried found lead failure
j ranges 1 6, values Pm

assigning later variables. Unfortunately, no-goods syntactic form memos
memoization procedure cannot remember them. search thus forced rediscover
failures.
6.2 Sticky Values Partial Antidote
One way staying standard memoization, avoiding rediscovery failing search
paths, case example above, use sticky values heuristic (Frost
& Dechter, 1994; Kambhampati, 1998). involves remembering current value variable
skipping DDB, trying value first search comes back
variable. heuristic motivated fact skip variable DDB,
means variable current assignment contributed failure caused
19

fiK AMBHAMPATI

backtrackingso makes sense restore value upon re-visit. example above,
backtracked it, tries
heuristic remember v7 current value Pm
first value re-visited. variation technique re-arrange fold
domain variable values precede current value sent back
domain, values tried previously untried values found
fail. makes assumption values led failure likely again.
becomes fv7 ; v8 vk ; v1 ; v2 v6 g.
example above, heuristic folds domain Pm
Notice heuristics make sense employ DDB, otherwise never
skip variable backtracking.
implemented sticky value heuristics top EBL/DDB Graphplan. statistics
Table 3 show results experiments extension. seen, sticky values
approach able give 4.6x additional speedup EBL/DDB depending problem.
Further, folding heuristic dominates simple version terms number backtracks,
difference quite small terms run-time.

7. Forward Checking & Dynamic Variable Ordering
DDB EBL considered look-back techniques analyze failures looking
back past variables may played part failures. different class
techniques known look-forward techniques improving search. Prominent among
latter forward checking dynamic variable ordering. Supporting forward checking involves
filtering conflicting actions domains remaining goals, soon particular
goal assigned. example Figure 1, forward checking filter A9 domain P4
soon P1 assigned A5 . Dynamic variable ordering (DVO) involves selecting assignment
goal least number remaining establishers.17 DVO combined forward checking, variables ordered according live domain sizes (where live domain
comprised values domain yet pruned forward checking). experiments18 show techniques bring reasonable, albeit non-dramatic, improvements
Graphplans performance. Table 4 shows statistics benchmark problems, dynamic variable ordering alone, forward checking dynamic variable ordering. note
backtracks reduce 3.6x case dynamic variable ordering, 5x
case dynamic variable ordering forward checking, speedups time somewhat smaller,
ranging 1.1x 4.8x. Times perhaps improved efficient implementation forward checking.19 results seem suggest amount optimization
going make dynamic variable ordering forward checking competitive EBL/DDB
problems. one thing, several problems, including Att-log-a, Tsp-12, Ferry-6 etc.
could solved even forward checking dynamic variable ordering. Second,
even problems could solved, reduction backtracks provided EBL/DDB far
greater provided FC/DVO strategies. example, Tsp-10, FC/DVO strategies
17. experimented variation heuristic, known Brelaz heuristic (Gomes et al., 1998),
ties among variables sized live-domains broken picking variables take part
number constraints. variation however lead appreciable improvement performance.
18. study forward checking dynamic variable ordering initiated Dan Weld.
19. current implementation physically removes pruned values variable forward checking phase,
restores values backtracks. better implementations, including use in/out flags values well
use indexed arrays (c.f. (Bacchus & van Run, 1995))

20

fi21

EBL/DDB+Sticky
Btks
Speedup
372K
2.2x(2.05x)
172K
4.6x(3.3x)
56212K 1.29x(1.09x)
18151K .99x(1.01x)
20948K 1.26x(1.02x)
1144K
2x(1.91x)

EBL/DDB+Sticky+Fold
Time
Btks
Speedup
.33
347K
2.4x (2.2x)
.177
169K
4.5x(3.36x)
40.8 54975K 1.17x(1.12x)
11.87 18151K .97x(1.01x)
10.18 20948K 1.22x(1.02x)
.67
781K
2.9x(2.8x)

Table 3: Utility using sticky values along EBL/DDB.

CSP

Time
.37
.18
36.9
11.75
9.86
.95



Rocket-ext-a(7/36)
Rocket-ext-b(7/36)
Gripper-10(39/39)
Ferry-6
TSP-12(12/12)
Att-log-a(11/79)

Plain EBL/DDB
Time
Btks
.8
764K
.8
569K
47.95 61373K
11.62 18318K
12.44 21482K
1.95
2186K

P LANNING G RAPH

Problem

fiK AMBHAMPATI

Problem
Huge-fact (18/18)
BW-Large-B (18/18)
Rocket-ext-a (7/36)
Rocket-ext-b (7/36)
Att-log-a(11/79)
Gripper-6(11/17)
Tsp-10(10/10)
Tower-6(63/63)

GP
5.3(5181K)
4.15(2823K)
19.43(8128K)
14.1(10434K)
>10hr
1.1(2802K)
89(69974K)
>10hr

GP+DVO
2.26 (1411K)
3.14(1416K)
14.9(5252K)
7.91(4382K)
>10hr
.65(1107K)
78(37654K)
>10hr

Speedup
2.3x(3.6x)
1.3x(2x)
1.3x(1.5x)
1.8x(2.4x)
1.7x(2.5x)
1.14x(1.9x)
-

GP+DVO+FC
3.59 (1024K)
4.78(949K)
14.5(1877K)
6(1490K)
>10hr.
.73 (740K)
81(14697K)
>10hr.

Speedup
1.47x(5x)
.86(3x)
1.3x(4.3x)
2.4x(7x)
1.5x(3.7x)
1.09x(4.8x)

Table 4: Impact forward checking dynamic variable ordering routines Graphplan. Times
cpu minutes measured 500 MHZ Pentium-III running Linux Franz
Allegro Common Lisp 5. numbers parentheses next times number
backtracks. speedup columns report two factorsthe first speedup time,
second speedup terms number backtracks. FC DVO tend
reduce number backtracks, reduction always seem show
time savings.

reduce number backtracks 69974K 14697K, 4.8x improvement. However, pales
comparison 2232K backtracks (or 31x improvement) given EBL/DDB (see entry
Table 1). Notice results say variable ordering strategies make dramatic
difference Graphplans backward search (or DCSP compilation planning graph);
make claims utility FC DVO CSP compilation planning graph.
7.1 Complementing EBL/DDB Forward Checking Dynamic Variable Ordering
Although forward checking dynamic variable ordering approaches found particularly effective isolation Graphplans backward search, thought would interesting
revisit context Graphplan enhanced EBL/DDB strategies. Part original reasoning underlying expectation goal (variable) ordering significant
effect Graphplan performance based fact failing goal sets stored in-toto
memos (Blum & Furst, 1997, pp. 290). reason longer holds use EBL/DDB.
more, exists difference opinion whether forward checking
DDB fruitfully co-exist. results (Prosser, 1993) suggest domain-filteringsuch
one afforded forward checking, degrades intelligent backtracking. recent work
(Frost & Dechter, 1994; Bayardo & Schrag, 1997) however seems suggest however best CSP
algorithms capabilities.
adding plain DVO capability top EBL/DDB presents difficulties, adding forward
checking require changes algorithm Figure 4. difficulty arises
failure may occurred combined effect forward checking backtracking.
example, suppose four variables v1 v4 considered assignment
order. Suppose v3 domain f1; 2; 3g, v3 cannot 1 v1 a, cannot 2 v2
b. Suppose v4s domain contains d, constraint saying v4 cant
22

fiP LANNING G RAPH

Problem
Huge-fct
BW-Large-B
Rocket-ext-a
Rocket-ext-b
Att-log-a
Tower-6
TSP-10

EBL
Time(btks)
3.08(2004K)
2.27(798K)
.8(764K)
.8(569K)
1.97(2186K)
2.53(4098K)
.99(2232K)



CSP

EBL+DVO
Time(btks)
Speedup
1.51(745K)
2x(2.68x)
1.81(514K)
1.25x(1.6x)
.4(242K)
2x(3.2x)
.29(151K)
2.75x(3.76x)
2.59(1109K) .76x(1.97x)
3.78(3396K)
.67x(1.2x)
1.27(1793K) .77x(1.24x)

EBL+FC+DVO
Time(Btks)
Speedup
2.57(404K)
1.2x(5x)
2.98(333K) .76x(2.39x)
.73(273K)
1.09x(2.8x)
.72(195K)
1.1x(2.9x)
3.98(1134K) .5x(1.92x)
2.09(636K)
1.2x(6.4x)
1.34(828K)
.73x(2.7x)

Table 5: Effect complementing EBL/DDB dynamic variable ordering forward checking
strategies. speedup columns report two factorsthe first speedup time,
second speedup terms number backtracks. FC DVO tend
reduce number backtracks, reduction always seem show
time savings.

v1 v3 3. Suppose using forward checking, assigned v1 ; v2
values b. Forward checking prunes 1 2 v3 domain, leaving value 3.
point, try assign v4 fail. use algorithm Figure 4, conflict set v4
would fv4 ; v3 ; v1 g, constraint violated v1 = ^ v3 = 3 ^ v4 = d. However
sufficient since failure v4 may occurred forward checking stripped
value 2 domain v3 . problem handled pushing v1 v2 , variables
whose assignment stripped values v3 , v3 conflict set.20 Specifically, conflict
set every variable v initialized fv g begin with, whenever v loses value
forward checking respect assignment v 0 , v 0 added conflict set v . Whenever
future variable (such v4 ) conflicts v3 , add conflict set v3 (rather v3 )
conflict set v4 . Specifically line
Set cs = cs [ f l g
procedure Figure 4 replaced line
Set cs = cs [ Conflict-set(l)
incorporated changes implementation, support support forward checking, dynamic variable ordering well EBL Graphplan. Table 5 shows performance version experimental test suite. seen numbers, number
backtracks reduced 3.7x case EBL+DVO, 5x case
EBL+FC+DVO. cpu time improvements somewhat lower. got 2.7x speedup
20. Notice possible values stripped v3 domain may impact
failure assign v4 . example, perhaps another constraint says v4 cant v3 b,
case, strictly speaking, assignment v2 cannot really blamed failure v4 . leads
non-minimal explanations, reason expect strict minimization explanations pre-requisite
effectiveness EBL/DDB; see (Kambhampati, 1998)

23

fiK AMBHAMPATI

EBL+DVO, 1.2x speedup EBL+FC+DVO, several cases, cpu times increase FC DVO. again, attribute overheads forward checking (and
lesser extent, dynamic variable ordering). importantly, comparing results
Tables 4 5, see EBL/DDB capabilities able bring significant speedups
even Graphplan implementation using FC DVO.

8. EBL/DDB & Randomized Search
Recent years seen increased use randomized search strategies planning. include
purely local search strategies (Gerevini, 1999; Selman, Levesque, & Mitchell, 1992) well
hybrid strategies introduce random restart scheme top systematic search strategy
(Gomes et al., 1998). BLACKBOX planning system (Kautz & Selman, 1999) supports variety
random restart strategies top SAT compilation planning graph, empirical
studies show strategies can, probabilistically speaking, scale much better purely
systematic search strategies.
wanted investigate (and much) EBL & DDB techniques help Graphplan
even presence newer search strategies. EBL DDB techniques little
applicability purely local search strategies, could theory help random restart systematic
search strategies. Random restart strategies motivated attempt exploit heavytail distribution (Gomes et al., 1998) solution nodes search trees many problems.
Intuitively, problems non-trivial percentage easy find solutions
well hard find solutions, makes sense restart search find
spending much effort solution. restarting way, hope (probabilistically) hit
easier-to-find solutions.
implemented random-restart strategy top Graphplan making following simple
modifications backward search:
1. keep track number times backward search backtracks one level
plan graph previous level (a level closer goal state), whenever number
exceeds given limit (called backtrack limit), search restarted (by going back last
level plan graph), assuming number restarts exceeded given
limit. search process two restarts referred epoch.
2. supporting actions (values) proposition variable considered randomized
order. randomization ensures search restarted, look
values variable different order.21
Notice random-restart strategy still allows application EBL DDB strategies, since
given epoch, behavior search identical standard backward
search algorithm. Indeed, backtrack limit number restarts made larger
larger, whole search becomes identical standard backward search.
21. Reordering values variable doesnt make whole lot sense BLACKBOX based SAT encodings
thus boolean variables. Thus, randomization BLACKBOX done order goals
considered assignment. typically tends clash built-in goal ordering strategies (such DVO
SAT-Z (Li & Anbulagan, 1997)), get around conflict breaking ties among variables randomly.
avoid clashes, decided randomize Graphplan reordering values variable. picked inter-level
backtracks natural parameter characterizing difficulty problem Graphplans backward search.

24

fiProblem

%sol
2%
11%
54%
13%
94%
0%
0%
3%
2%
2%
58%
90%
100%

Normal Graphplan
Length
Time Av. MFSL
19(103)
.21
.3K(3.7K)
17.6(100.5) 1.29
3.7K(41K)
25.6(136)
3
4K(78K)
18(97.5)
3
31K(361K)
22.1(119.3)
31
33K(489K)
.2K(4K)
2.6K(53K)
28(156)
4
5K(111K)
26.5(135)
.75
.4K(8K)
29(152)
4
3.7K(111K)
21.24(87.3)
2
.2K(4K)
21.3(85)
8.1
2.3K(43K)
15.3(62.5)
45
35K(403K)

Table 6: Effect EBL/DDB random-restart Graphplan. Time measured cpu minutes Allegro Common Lisp 5.0 running
Linux 500MHZ Pentium machine. numbers next problem names number steps actions shortest
plans reported problems literature. R/B/L parameters second column refer limits number
restarts, number backtracks number levels plan graph expanded. statistics averaged
multiple runs (typically 100 50). MFSL column gives average number memo-based failures per searched level
plan graph. numbers parentheses total number memo-based failures averaged runs. Plan lengths
averaged successful runs.

CSP

Graphplan EBL/DDB
Length
Time Av. MFSL
14(82)
.41
4.6K(28K)
11.3(69.5)
.72
17.8K(59K)
11.3(69.5)
.72
17.8K(59K)
11(68.5)
2.38 73K(220K)
11(68.5)
2.38 73K(220K)
18.1(101)
1.62
8K(93K)
17.3(98)
11.4 69K(717K)
20.1(109)
15.3 74K(896K)
22.85(124) 2.77
8K(145K)
19.9(110)
14
71K(848K)
7.76(35.8)
1.3
29K(109K)
7(34.1)
1.32 38K(115K)
7(34.2)
1.21 35K(105K)



%sol
99%
100%
100%
100%
100%
17%
60%
100%
55%
100%
100%
100%
100%

P LANNING G RAPH

25

Att-log-a(11/54)
Att-log-a(11/54)
Att-log-a(11/54)
Att-log-a(11/54)
Att-log-a(11/54)
Att-log-b(13/47)
Att-log-b(13/47)
Att-log-b(13/47)
Att-log-c(13/65)
Att-log-c(13/65)
Rocket-ext-a(7/34)
Rocket-ext-a(7/34)
Rocket-ext-a(7/34)

Parameters
R/B/L
5/50/20
10/100/20
10/100/30
20/200/20
20/200/30
5/50/20
10/100/20
10/100/30
5/50/30
10/100/30
10/100/30
20/200/30
40/400/30

fiK AMBHAMPATI

check intuitions effectiveness EBL/DDB randomized search indeed correct, conducted empirical investigation comparing performance random search
standard Graphplan well Graphplan EBL/DDB capabilities. Since search randomized, problem solved multiple number times (100 times cases), runtime, plan length statistics averaged runs. experiments conducted
given backtrack limit, given restart limit, well limit number levels
planning graph extended. last one needed randomized search, solution may
missed first level appears, leading prolonged extension planning graph
(inoptimal) solution found later level. limit number levels expanded,
probability finding solution increases, time, cpu time spent searching
graph increases.
implemented random restart search, first thing noticed improvement
solvability horizon (as expected, given results (Gomes et al., 1998)). Table 6 shows
results. One important point note results table talk average plan
lengths cpu times. needed due randomization potentially run produce
different outcome (plan). Secondly, Graphplan systematic search guarantees shortest
plans (measured number steps), randomized search guarantee.
particular, randomized version might consider particular planning graph barren
solutions, based simply fact solution could found within confines given
backtrack limit number restarts.
Graphplan, without EBL/DDB, likely solve larger problems randomized
search strategies. example, logistics domain, Att-log-a problem solvable
(within 24 hours real time) EBL systematic search. randomization added,
implementation able solve Att-log-b Att-log-c quite frequently. limits
number restarts, backtracks levels increased, likelihood finding solution well
average length solution found improves. example, Graphplan EBL/DDB able
solve Att-log-b every trial 10 restarts, 100 backtracks 30 levels limits (although
plans quite inoptimal).
next, perhaps interesting, question wanted investigate whether EBL
DDB continue useful Graphplan uses randomized search. first blush,
seems importantafter even Graphplan standard search may
luck able find solutions quickly presence randomization. thought
however suggests EBL DDB may still able help Graphplan. Specifically,
help Graphplan using given backtrack limit judicious fashion. elaborate, suppose
random restart search conducted 100 backtracks 10 restarts. EBL
DDB, Graphplan able pinpoint cause failure accurately without EBL
DDB. means search backtracks, chance backtrack
(or similar) reasons reduced. turn gives search chance
catching success one number epochs allowed. addition
direct benefit able use stored memos across epochs cut search.
seen data Table 6, given set limits number restarts, number
backtracks, number levels expanded, Graphplan EBL/DDB able get higher
percentage solvability well significantly shorter length solutions (both terms levels
terms actions). get comparable results standard Graphplan, significantly
increase input parameters (restarts, backtracks levels expanded), turn led dra26

fiP LANNING G RAPH



CSP

matic increases average run time. example, Att-log-a problem, 5 restarts
50 backtracks, 20 levels limit, Graphplan able solve problem 99% time,
average plan length 14 steps 82 actions. contrast, without EBL/DDB, Graphplan
able solve problem 2% cases, average plan length 19 steps 103
actions. double restarts backtracks, EBL/DDB version goes 100% solvability
average plan length 11.33 steps 69.53 actions. standard Graphplan goes 11%
solvability plan length 17.6 steps 100 actions. increase number levels 30,
standard Graphplan solves 54% problems average plan length 25.6 steps
136 actions. takes 20 restarts 200 backtracks, well 30-level limit standard
Graphplan able cross 90% solvability. time, average run time 31 minutes,
average plan length 22 steps 119 actions. contrast 99% solvability 0.4 minutes 14 step 82 action plans provided Graphplan EBL 5 restarts
50 backtracks significant! Similar results observed problems, logistics
(Att-log-b, Att-log-c) domains (Rocket-ext-a, Rocket-ext-b).
results show Graphplan EBL/DDB able generate reuse memos effectively across different restart epochs. Specifically, numbers columns titled Av. MFSL
give average number memo-based failures per search level.22 note cases,
average number memo-based failures significantly higher Graphplan EBL
normal Graphplan. shows EBL/DDB analysis helping Graphplan reduce wasted effort
significantly, thus reap better benefits given backtrack restart limits.

9. Related Work
original implementation Graphplan, Blum Furst experimented variation
memoization strategy called subset memoization. strategy, keep memo generation
techniques same, change way memos used, declaring failure stored memo
found subset current goal set. Since complete subset checking costly,
experimented partial subset memoization subsets length n n , 1
considered n sized goal set.
mentioned earlier, Koehler co-workers (Koehler et al., 1997) re-visited
subset memoization strategy, developed effective solution complete subset checking
involves storing memos data structure called UB-Tree, instead hash tables.
results experiments subset memoization mixed, indicating subset memoization seem improve cpu time performance significantly. reason quite
easy understand improved memo checking time UB-Tree data structure,
still generating storing old long memos. contrast, EBL/DDB extension
described supports dependency directed backtracking, reducing average length
stored memos, increases utility significantly, thus offering dramatic speedups.
verify main source power EBL/DDB-Graphplan EBL/DDB part
UB-Tree based memo checking, re-ran experiments EBL/DDB turned off,
22. Notice number search levels may different (and smaller than) number planning graph levels,
Graphplan initiates search none goals pair-wise mutex other. Att-log-a,
Att-log-b Att-log-c, happens starting level 9. Rocket-ext-a happens starting level 5. numbers
parentheses total number memo based failures. divide number average number levels
search conducted get Av. MFSL statistic.

27

fiK AMBHAMPATI

Problem
Huge-Fact
BW-Large-b
Rocket-ext-a
Rocket-ext-b
Att-log-a

Tt
3.20
2.74
19.2
7.36
> 12hrs

Mt
1
0.18
16.7
4.77
-

#Btks
2497K
1309K
6188K
7546K
-

EBL x"
1.04x
1.21x
24x
9.2x
>120x

#Gen
24243
11708
62419
61666
-

#Fail
33628
15011
269499
265579
-

AvFM
1.38
1.28
4.3
4.3
-

AvLn
11.07
11.48
24.32
24.28
-

Table 7: Performance subset memoization UB-Tree data structure (without EBL/DDB).
Tt total cpu time Mt time taken checking memos. #Btks
number backtracks. EBLx amount speedup offered EBL/DDB subset
memoization #Gen lists number memos generated (and stored), #Fail lists
number memo-based failures, AvFM average number failures identified per
generated memo AvLn average length stored memos.

subset memo checking UB-Tree data structure still enabled. results shown
Table 7. columns labeled AvFM show expected subset memoization improve
utility stored memos normal Graphplan (since uses memo scenarios
normal Graphplan can). However, note subset memoization
dramatic impact performance Graphplan, EBL/DDB capability significantly
enhance savings offered subset memoization.
(Kambhampati, 1998), describe general principles underlying EBL/DDB techniques
sketch extended dynamic constraint satisfaction problems. development
paper seen application ideas there. Readers needing background
EBL/DDB thus encouraged review paper. related work includes previous attempts applying EBL/DDB planning algorithms, work UCPOP+EBL system
(Kambhampati et al., 1997). One interesting contrast ease EBL/DDB added
Graphplan compared UCPOP system. Part difference comes fact
search Graphplan ultimately propositional dynamic CSP, UCPOPs search
variablized problem-solving search.
mentioned Section 2, Graphplan planning graph compiled normal CSP
representation, rather dynamic CSP representation. used dynamic CSP representation corresponds quite directly backward search used Graphplan. saw
model provides clearer picture mutex propagation memoization strategies, helps us
unearth sources strength Graphplan memoization strategyincluding fact
memos conservative form no-good learning obviate need no-good
management strategies large extent.
dynamic CSP model may account peculiarities results
empirical studies. example, widely believed CSP literature forward checking
dynamic variable ordering either critical as, perhaps even critical than, EBL/DDB
strategies (Bacchus & van Run, 1995; Frost & Dechter, 1994). results however show
Graphplan, uses dynamic CSP model search, DVO FC largely ineffective
compared EBL/DDB standard Graphplan. extent, may due fact

28

fiP LANNING G RAPH



CSP

Graphplan already primitive form EBL built memoization strategy. fact, Blum
& Furst (1997) argue memoization minimal action set selection (an action set
considered minimal possible remove action set still support
goals actions selected), ordering goals little effect (especially
earlier levels contain solution).
Another reason ineffectiveness dynamic variable ordering heuristic may
differences CSP DCSP problems. DCSP, main aim
quickly find assignment current level variables, rather find assignment
current level likely activate fewer easier assign variables, whose assignment
turn leads fewer easier assign variables on. general heuristic picking
variable smallest (live) domain necessarily make sense DCSP, since variable
two actions supporting may actually much harder handle another many
actions supporting it, actions supporting first one eventually lead activation
many harder assign new variables. may thus worth considering ordering strategies
customized dynamic CSP modelse.g. orderings based number
(and difficulty) variables get activated given variable (or value) choice.
recently experimented value-ordering heuristic picks value assigned variable using distance estimates variables activated choice
(Kambhampati & Nigenda, 2000). planning graph provides variety ways obtaining
distance estimates. simplest idea would say distance proposition p level
p enters planning graph first time. distance estimate used
rank variables values. Variables ranked simply terms distancesthe
variables highest distance chosen first (akin fail-first principle). Value ordering
bit trickierfor given variable, need pick action whose precondition set lowest
distance. distance precondition set computed distance individual
preconditions several ways:





Maximum distances individual propositions making preconditions.
Sum distances individual propositions making preconditions.
first level set propositions making preconditions present
non-mutex.

(Kambhampati & Nigenda, 2000), evaluate goal value ordering strategies based
ideas, show lead quite impressive (upto 4 orders magnitude
tests) speedups solution-bearing planning graphs. relate distances computed
planning graph distance transforms computed planners HSP (Bonet, Loerincs, &
Geffner, 1999) UNPOP (McDermott, 1999). idea using planning graph basis
computing heuristic distance metrics investigated context state-space search
(Nguyen & Kambhampati, 2000). interesting finding paper even one
using state-space instead CSP-style solution extraction, EBL still useful lazy demanddriven approach discovering n-ary mutexes improve informedness heuristic.
Specifically, Long & Kambhampati describe method limited run Graphplans backward search, armed EBL/DDB used pre-processing stage explicate memos (n-ary
mutexes) used significantly improve effectiveness heuristic
state-search.
29

fiK AMBHAMPATI

general importance EBL & DDB CSP SAT problems well recognized. Indeed,
one best systematic solvers propositional satisfiability problems RELSAT (Bayardo &
Schrag, 1997), uses EBL, DDB, forward checking. randomized version RELSAT
one solvers supported BLACKBOX system (Kautz & Selman, 1999), compiles
planning graph SAT encoding, ships various solvers. BLACKBOX thus offers
way indirectly comparing Dynamic CSP static CSP models solving planning
graph. discussed Section 2.2, main differences BLACKBOX needs compile
planning graph extensional SAT representation. makes harder BLACKBOX
exploit results searches previous levels (as Graphplan stored memos),
leads memory blowups. latter particularly problematic techniques
condensing planning graphs, bi-level representation discussed (Fox & Long, 1999;
Smith & Weld, 1999) effective compile planning graph SAT.
flip side, BLACKBOX allows non-directional search, opportunity exploit existing SAT
solvers, rather develop customized solvers planning graph. present, clear
whether either approaches dominates other. informal experiments, found
certain problems, Att-log-x, easier solve non-directional search offered
BLACKBOX, others, Gripper-x, easier solve Graphplan backward
search. results recent AIPS planning competition inconclusive respect
(McDermott, 1998).
main rationale focusing dynamic CSP model planning graph due
closeness Graphplans backward search, Gelle (1998) argues keeping activity constraints
distinct value constraints several advantages terms modularity representation.
Graphplan, advantage becomes apparent activation constraints known
priori, posted dynamically search,. case several extensions
Graphplan algorithm handle conditional effects (Kambhampati et al., 1997; Anderson, Smith,
& Weld, 1998; Koehler et al., 1997), incomplete initial states (Weld, Anderson, & Smith, 1998).
Although EBL DDB strategies try exploit symmetry search space improve
search performance, go far enough many cases. example, Gripper domain,
real difficulty search gets lost combinatorics deciding hand used
pick ball transfer next rooma decision completely irrelevant
quality solution (or search failures, matter). EBL/DDB allow Graphplan
cut search bit, allowing transfer 10 balls one room another,
come beyond 10 balls. two possible ways scaling further. first
variablize memos, realize certain types failures would occurred irrespective
actual identity hand used. Variablization, called generalization part
EBL methods (Kambhampati, 1998; Kambhampati et al., 1997). Another way scaling
situations would recognize symmetry inherent problem abstract
resources search. (Srivastava & Kambhampati, 1999), describe type resource
abstraction approach Graphplan.

10. Conclusion Future work
paper, traced connections Graphplan planning graph CSP, motivated need exploiting CSP techniques improve performance Graphplan backward search. adapted evaluated several CSP search techniques contest Graph-

30

fiP LANNING G RAPH



CSP

plan. included EBL, DDB, forward checking, dynamic variable ordering, sticky values,
random-restart search. empirical studies show EBL/DDB particularly useful dramatically speeding Graphplans backward search (by tp 1000x instances). speedups
improved (by 8x) addition forward checking, dynamic variable ordering sticky values top EBL/DDB. showed EBL/DDB techniques equally
effective helping Graphplan, even random-restart search strategies used.
secondary contribution paper clear description connections
Graphplan planning graph, (dynamic) constraint satisfaction problem. connections
help us understand unique properties Graphplan memoization strategy, viewed
CSP standpoint (see Section 9).
several possible ways extending work. first would support
use learned memos across problems (or specification problem changes,
case replanning). Blum & Furst (1997) suggest promising future direction,
EBL framework described makes extension feasible. discussed (Kambhampati,
1998; Schiex & Verfaillie, 1993), supporting inter-problem usage involves contextualizing
learned no-goods. particular, since soundness memos depends initial state
problem (given operators change problem problem), inter-problem usage
memos supported tagging learned memo specific initial state literals
supported memo. Memos used corresponding level new problem
long initial state justification holds new problem. initial state justification
memos computed incrementally procedure first justifies propagated mutex
relations terms initial state, justifies individual memos terms justifications
mutexes memos derived.
success EBL/DDB approaches Graphplan part due high degree redundancy planning graph structure. example, propositions (actions) level l
planning graph superset propositions (actions) level l , 1, mutexes (memos)
level l subset mutexes (memos) level l , 1). EBL/DDB techniques help
Graphplan exploit redundancy avoiding previous failures, exploitation redundancy pushed further. Indeed, search Graphplan planning graph size l
almost re-play search planning graph size l , 1 (with additional
choices). (Zimmerman & Kambhampati, 1999), present complementary technique called
explanation-guided backward search attempts exploit deja vu property Graphplans backward search. technique involves keeping track elaborate trace search
level l (along failure information), termed pilot explanation level l, using
pilot explanation guide search level l , 1. way EBL/DDB help process
significantly reduce size pilot explanations need maintained. Preliminary
results technique shows complements EBL/DDB provides significant
savings search.
Acknowledgements
research supported part NSF young investigator award (NYI) IRI-9457634, ARPA/Rome
Laboratory planning initiative grant F30602-95-C-0247, Army AASERT grant DAAH04-96-10247, AFOSR grant F20602-98-1-0182 NSF grant IRI-9801676. thank Maria Fox Derek
Long taking time implement experiment EBL/DDB STAN system.

31

fiK AMBHAMPATI

would thank them, well Terry Zimmerman, Biplav Srivastava, Dan Weld, Avrim
Blum Steve Minton comments previous drafts paper. Special thanks due
Dan Weld, hosted University Washington Summer 1997, spent time discussing
connections CSP Graphplan. Finally, thank Mark Peot David Smith
clean Lisp implementation Graphplan algorithm, served basis extensions.

References
Anderson, C., Smith, D., & Weld, D. (1998). Conditional effects graphplan. Proc. AI Planning
Systems Conference.
Bacchus, F., & van Run, P. (1995). Dynamic variable ordering CSPs. Proc. Principles
Practice Constraint Programming (CP-95). Published Lecture Notes Artificial Intelligence, No. 976. Springer Verlag.
Bayardo, R., & Schrag, R. (1997). Using CSP look-back techniques solve real-world sat instances. Proc. AAAI-97.
Blum, A., & Furst, M. (1997). Fast planning planning graph analysis. Artificial Intelligence,
90(1-2).
Bonet, B., Loerincs, G., & Geffner, H. (1999). robust fast action selection mechanism
planning. Proc. AAAI-97.
Do, B., & Kambhampati, S. (2000). Solving planning graph compiling CSP. Proc. 5th
International Conference AI Planning Scheduling.
Do, B., Srivastava, B., & Kambhampati, S. (2000). Investigating effect relevance reachability constraints sat encodings planning. Proc. 5th International Conference
AI Planning Scheduling.
Fox, M. (1998). Private correspondence..
Fox, M., & Long, D. (1999). Efficient implementation plan graph. Journal Artificial Intelligence Research, 10.
Frost, D., & Dechter, R. (1994). search best constraint satisfactions earch. Proc. AAAI94.
Gelle, E. (1998). generation locally consistent solution spaces mixed dynamic constraint problems. Ph.D. thesis, Ingenieure informaticienne EPFL de nationalite Suisse, Lausanne, Switzerland.
Gerevini, A. (1999). Fast planning greedy planning graphs. Proc. AAAI-99.
Gomes, C., Selman, B., & Kautz, H. (1998). Boosting combinatorial search randomization.
Proc. AAAI-98, pp. 431437.
Kambhampati, S. (1997). Challenges bridging plan synthesis paradigms. Proc. IJCAI-97.

32

fiP LANNING G RAPH



CSP

Kambhampati, S. (1998). relations intelligent backtracking explanation-based
learning planning constraint satisfaction. Artifical Intelligence, 105(1-2).
Kambhampati, S. (1999). Improving graphplans search ebl & ddb techniques. Proc. IJCAI99.
Kambhampati, S., Katukam, S., & Qu, Y. (1997). Failure driven dynamic search control partial
order planners: explanation-based approach. Artificial Intelligence, 88(1-2), 253215.
Kambhampati, S., & Nigenda, R. (2000). Distance-based goal ordering heuristics graphplan.
Proc. 5th International Conference AI Planning Scheduling.
Kambhampati, S., Parker, E., & Lambrecht, E. (1997). Understanding extending graphplan.
Proceedings 4th European Conference Planning. URL: rakaposhi.eas.asu.edu/ewspgraphplan.ps.
Kautz, H., & Selman, B. (1996). Pushing envelope: Plannng, propositional logic stochastic
search. Proc. AAAI-96.
Kautz, H., & Selman, B. (1999). Blackbox: Unifying sat-based graph-based planning. Proc.
IJCAI-99.
Koehler, J., Nebel, B., Hoffman, J., & Dimopoulos, Y. (1997). Extending planning graphs adl
subset. Tech. rep. 88, Albert Ludwigs University.
Li, C., & Anbulagan (1997). Heuristics based unit propagation satisfiability problems.
Proc. IJCAI-97.
McDermott,
D.
(1998).
Aips-98
planning
ftp.cs.yale.edu/pub/mcdermott/aipscomp-results.html.

competition

results.

McDermott, D. (1999). Using regression graphs control search planning. Aritificial Intelligence, 109(1-2), 111160.
Mittal, S., & Falkenhainer, B. (1990). Dynamic constraint satisfaction problems. Proc. AAAI-90.
Nguyen, X., & Kambhampati, S. (2000). Extracting effective admissible state-space heuristics
planning graph. Tech. rep. ASU CSE TR 00-03, Arizona State University.
Prosser, P. (1993). Domain filtering degrade intelligent backtracking search. Proc. IJCAI-93.
Rymon, R. (1992). Set enumeration trees. Proc. KRR-92.
Schiex, T., & Verfaillie, G. (1993). Nogood recording static dynamic constraint satisfaction
problems. Proc. 5th intl. conference tools artificial intelligence.
Selman, B., Levesque, H., & Mitchell, D. (1992). GSAT: new method solving hard satisfiability
problems. Proc. AAAI-92.
Smith, D., & Weld, D. (1999). Temporal planning mutual exclusion reasoning. Proc.
IJCAI-99.
33

fiK AMBHAMPATI

Srivastava, B., & Kambhampati, S. (1999). Scaling planning teasing resource scheduling.
Proc. European Conference Planning.
Tsang, E. (1993). Foundations Constraint Satisfaction. Academic Press, San Diego, California.
Weld, D., Anderson, C., & Smith, D. (1998). Extending graphplan handle uncertainty & sensing
actions. Proc. AAAI-98.
Zimmerman, T., & Kambhampati, S. (1999). Exploiting symmetry plan-graph via
explanation-guided search. Proc. AAAI-99.

34


