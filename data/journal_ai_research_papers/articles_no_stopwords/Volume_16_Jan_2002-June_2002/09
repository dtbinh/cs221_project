Journal Artificial Intelligence Research 16 (2002) 359-387

Submitted 12/01; published 6/02

Collective Intelligence, Data Routing Braess' Paradox

David H. Wolpert

NASA Ames Research Center, Mailstop 269-2
Moffett Field, CA 94035

Kagan Tumer

NASA Ames Research Center, Mailstop 269-3
Moffett Field, CA 94035

dhw@ptolemy.arc.nasa.gov
kagan@ptolemy.arc.nasa.gov

Abstract

consider problem designing utility functions utility-maximizing
agents multi-agent system (MAS) work synergistically maximize global
utility. particular problem domain explore control network routing
placing agents routers network. Conventional approaches task
agents use Ideal Shortest Path routing Algorithm (ISPA). demonstrate
many cases, due side-effects one agent's actions another agent's performance,
agents use ISPA's suboptimal far global aggregate cost concerned, even
used route infinitesimally small amounts trac. utility
functions individual agents \aligned" global utility, intuitively
speaking. particular example present instance Braess' paradox
adding new links network whose agents use ISPA results decrease
overall throughput. demonstrate load-balancing, agents'
decisions collectively made optimize global cost incurred trac currently
routed, suboptimal far global cost averaged across time concerned.
due \side-effects", case current routing decision future trac.
mathematics Collective Intelligence (COIN) concerned precisely issue
avoiding deleterious side-effects multi-agent systems, time space.
present key concepts mathematics use derive algorithm
whose ideal version better performance agents use
ISPA, even infinitesimal limit. present experiments verifying this,
showing machine-learning-based version COIN algorithm costs
imprecisely estimated via empirical means (a version potentially applicable real
world) outperforms ISPA, despite access less information
ISPA. particular, COIN algorithm almost always avoids Braess' paradox.
1. Introduction

long history AI research design distributed computational systems,
stretching Distributed AI (Huhns, 1987) current work multi-agent systems
(MAS's) (Claus & Boutilier, 1998; Hu & Wellman, 1998a; Jennings, Sycara, & Wooldridge,
1998; Sandholm, Larson, Anderson, Shehory, & Tohme, 1998; Sycara, 1998).
individual agents system personal utility functions trying
maximize `world utility' rates possible dynamic histories
overall system, MAS constitutes `collective'. paper particularly
concerned agents use machine learning techniques (e.g., Reinforcement Learning

c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiWolpert & Tumer
(RL) Kaelbing, Littman, & Moore, 1996; Sutton & Barto, 1998; Sutton, 1988; Watkins &
Dayan, 1992) try maximize utilities.
field Collective Intelligence (COIN) concerned central design problem
collectives (Wolpert, Tumer, & Frank, 1999; Wolpert & Tumer, 1999): How, without
detailed modeling overall system, one set utility functions individual
agents COIN overall dynamics reliably robustly achieves large values
provided world utility? words, leverage assumption
learners individually fairly good do, collective whole
perform well? 1
example question looms large problem optimize
ow certain entities (e.g., information packets, cars) sources destinations across
network routing nodes. concerned version problem
\optimization" consists minimizing aggregate cost incurred entities owing
destinations, agent controls routing decisions node
network. problem underlies distributed control large array real-world
domains, including internet routing, voice/video communication, trac ows, etc.
COIN perspective, problem reduces question goals one ought
provide router's agent agent's self-interestedly pursuing utility
results maximal throughput entire system (\incentive engineering").
paper investigate application recently developed COIN techniques,
routing domain. work concerning COINs, techniques designed
broadly applicable, particular designed routing domain.
Accordingly, performance domain serves good preliminary indication
general usefulness.
ground discussion, concentrate telecommunications data routing
problem entities routed packets. Currently, many real-world algorithms
problem based Shortest Path Algorithm (SPA). algorithm
routing node network controlled agent maintains \routing table"
\shortest paths" (i.e., sequences links minimal total incurred costs) node
possible destination nodes net. moment agent satisfies
routing requests particular destination node sending packets
associated shortest path. Many Ideal SPA (ISPA) algorithms exist eciently computing
shortest path agent-to-agent path-cost communication available costs
traversing agent's node unvarying time, e.g., Dijkstra's Algorithm (Ahuja,
Magnanti, & Orlin, 1993; Bertsekas & Gallager, 1992; Deo & Pang, 1984; Dijkstra, 1959).
non-infinitesimal amount trac routed particular destination
moment agent, agent's sending trac single path
result minimal cost, matter single path chosen. However must
choose single path trac, routing decisions agents
fixed, tautologically using ISPA agent chooses best path, far
trac routing concerned. Accordingly, limit routing infinitesimally
1. lack detailed modeling ensures face problems \brittleness" sometimes
accompany mismatch real world assumptions concerning built non-adaptive,
\hard-wired" agents large MAS's. turn, lack modeling causes us concentrate
adaptive, RL-based agents.

360

fiCollective Intelligence, Data Routing Braess' Paradox
small amount trac, agents' strategies \background", ISPA
optimal (least aggregate incurred cost) routing strategy trac associated
single agent considered individually.
One might hope generally, agent must allot trac single
path agents' trac decisions fixed, choosing path via
ISPA would choice minimizes total incurred cost trac across net,
least limit infinitesimally little trac. case though, using
SPA agent concerned deleterious side-effects actions
costs trac routed agents (Korilis, Lazar, & Orda, 1997a; Wolpert et al.,
1999). problem made worse agents allowed change
decisions response agent's decision. extreme case, elaborated below,
agents try minimize personal costs via ISPA's, agents would
actually receive higher cost would case alternative set strategies.
instance famous Tragedy Commons (TOC) (Hardin, 1968).
Deleterious side-effects need restricted extend space; extend
time. Indeed, consider algorithm agents given moment make
routing decisions optimize global cost incurred trac currently routed,
algorithm often called \load-balancing" (LB) (Heusse, Snyers, Guerin, & Kuntz, 1998).
definition, LB avoids deleterious side-effects space result TOC
costs incurred trac currently routed. However, due side-effects
time, even conventional LB suboptimal far global cost averaged across
time concerned. Intuitively, one would use \load-balancing time" ensure
truly optimal performance. even one could somehow construct distributed protocol
governing agents caused implement LB, still one would
gotten theme act perfectly coordinated fashion. diculties make
appropriate domain investigate well COIN techniques work practice.
Real-world SPA's (RSPA) work applying ISPA estimated costs traversing
path every agent. Typically estimates error agent-to-agent
communication instantaneous, therefore routing tables may based
date information. generally though, even communication instantaneous,
cost traverse agent's node may different time packet arrives
node. Accordingly, general performance RSPA's bounded
associated ISPA. paper wish investigate topics, rather
highlight issue side-effects. Accordingly \rig game" experimental
comparisons favor SPA, using ISPA's rather RSPA's.
general, even without side-effects, determining optimal solution ow problem
(e.g., determining loads link need maximize throughput
non-cooperative data network) nontractable (Ahuja et al., 1993; Orda, Rom, & Sidi,
1993b). Therefore, concern providing good solutions avoid
diculties ISPA side-effects. aim present algorithms
find best possible (perfectly load-balanced time) solution. Previous work
using machine learning improve routing sometimes resulted better performance
(non-idealized) SPA's (Littman & Boyan, 1993; Boyan & Littman, 1994; Stone, 2000;
Marbach, Mihatsch, Schulte, & Tsisiklis, 1998). work grappled
central COIN design problem however.
361

fiWolpert & Tumer
Section 2 discuss SPA's deficiencies particular manifestations
Braess' paradox. Then, Section 3 present theory collective intelligence,
approach promises overcome deficiencies. discuss routing model
use experiments, show theory COINs applied
model provide alternative shortest path algorithms Section 3. Section 5
present simulation results model comparing ISPA COINs. results
demonstrate networks running ISPA, per packet costs much 32
% higher networks running algorithms based COIN theory. particular, even
though access imprecise estimates costs (a handicap hold
ISPA), COIN-based algorithm almost always avoids Braess' paradox, stark contrast
ISPA. cost incurred ISPA's presumably lower bound
SPA privy instantaneous communication, implication COINs
outperform real-world SPA's. conclude techniques field collective
intelligence highly effective designing utility functions members MAS
ensure work coordinated ecient manner optimize overall performance.
2. Suboptimality Shortest Path Routing Braess Paradox

section first demonstrate suboptimality SPA multiple
agents making simultaneous routing decisions, agent knows ahead time
other's choice, therefore know ahead time exactly costs be.
demonstrate suboptimality hold even one agent making
decision, knows decisions others previously made. Next present
Braess' paradox, particularly pointed instance effects (for discussion
Braess' paradox SPA routing, see Bass, 1992; Cohen & Kelly, 1990; Cohen & Jeffries,
1997; Hogg, 1995; Glance & Hogg, 1995; Korilis, Lazar, & Orda, 1999).

2.1 Suboptimality SPA
Perhaps simplest example individual greed part agents lead
collective detriment occurs two agents determine shortest path
shared link limited capacity, second option slightly
less preferable. case, using common link degrades performance
parties, since due limited capacity performance link quickly fall
second option.
precisely, consider case shared link cost given x3
traversed x packets, router optional second link destination
cost trac x traverse second link 2x. Acting alone, single
packet send, would send packet shared link (cost 1).
However so, incur larger cost (cost 8) used
second choices (cost 4). Without knowing ahead time
(information conventionally contained routing tables), agents necessarily
mistaken cost estimates therefore make incorrect routing decisions. this, even
limit differentially small packets, use SPA lead wrong routing decision.
362

fiCollective Intelligence, Data Routing Braess' Paradox
2.2 Suboptimality ISPA
analyze situation routers may know loads
acting optimize delays experienced packets alone. Consider network
shown Figure 1. Two source routers X send one packet time, X
sending either intermediate router B , sending either B C . type
network may arise many different topologies subnetwork. Accordingly, diculties
associated network apply many complex topologies.


JJ
J





JJ

J



B

JJ




JJ


J




C

JJ

X

JJ


J















Figure 1: Independent decisions source
Let xA , xB , yB , yC , packet quantities particular fixed time t, A, B ,
C , originating X , indicated. t, source one packet send.
variables binary, xA + xB = yB + yC = 1. Vi (zi ) cost,
per packet, single instant t, router i, total number packets
instant router zi . total cost incurred packets time t, G(~x; ~y),
equals xA VA (xA ) + (xB + yB )VB (xB + yB ) + (yC )VC (yC ).
ISPA, X chooses xA xB = 1 minimize cost incurred
X's packet alone, gX (~x) xA VA (xA ) + xB VB (xB + yB ). ISPA ignores
yB VB (xB + yB ) term, i.e., ignores \side effects" X 's decision. Real-world SPA's
typically try approximate X choose either B according whether
VA (0) VB (yB ) smaller, two values estimated via pings, example.
right thing point view minimizing global cost course
instead X minimize G(~x; ~y), precisely, components G(~x; ~y)
depend X . Writing case, X ought act minimize xA VA (xA ) + (xB +
yB )VB (xB + yB ). Due constraint xA + xB = 1, means sending iff
VA (1) < (yB + 1)VB (yB + 1) yB VB (yB ), differs ISPA result X
concerned full cost going router B , portion cost
packet receives.
context example, G-minimizing algorithm constitutes \load-balancing"
(LB). Note long sgn[VA (0) VB (yB ) yB VB0 (yB )] 6= sgn[VA (0) VB (yB )], even
limit infinitesimally small trac (so xA + xB equals infinitesimal ),
ISPA LB still disagree. LB considers side-effects current routing decisions
trac currently routed. However consider side-effects routing
decisions future trac, even LB may optimize global cost averaged across time,
363

fiWolpert & Tumer
depending details system. However use \effect sets" COINs
account even delayed side-effects2 .

2.3 Braess' Paradox
Let us conclude section illustration Braess' paradox (Bass, 1992; Cohen
& Kelly, 1990; Cohen & Jeffries, 1997; Glance & Hogg, 1995; Hogg, 1995; Korilis, Lazar,
& Orda, 1997b; Korilis et al., 1999), phenomenon dramatically underscores
ineciency ISPA. apparent \paradox" perhaps best illustrated
highway trac example first given Bass (Bass, 1992): two highways connecting
towns D. cost associated traversing either highway (either terms tolls,
delays) V1 + V2 , illustrated Net Figure 2. x = 1 (a single traveler)
either path, total accrued cost 61 units. hand, six travelers split equally
among two paths, incur cost 83 units get destinations. Now,
suppose new highway built connecting two branches, shown Net B Figure 2.
Further, note cost associated taking highway particularly high (in
fact load higher 1, highway lower cost highway
system). benefit highway illustrated dramatically reduced cost incurred
single traveler: taking short-cut, one traveler traverse network
cost 31 units (2 V1 + V3 ). Adding new road seemingly reduced traversal cost
dramatically.

V2

V1

"y
bDb
"
"
bb
y"
"
byV1

V2


bb
"yV2
"
bb ""
b"
yS

V1

Net
Figure 2: Hex network V1 = 10x ;

"ybDb
"
"
bb
"y"
byV1

V3





yb
"yV2
bb
"
bb"yS""
V2

Net B
= 50 + x ;

V3

= 10 + x

However consider happens six travelers highways net B.
agent uses ISPA, equilibrium three possible paths contains two
travelers.3 Due overlaps paths however, results traveler incurring
cost 92 units, higher incurred new highway
built. net effect adding new road increase cost incurred every traveler.
phenomenon known Braess' paradox.
2. detailed discussion proof suboptimality LB shown appendix A. Since LB
used current systems hard imagine ever used, experiments consider it;
discussed pedagogical reasons.
3. mind Nash equilibrium problem, traveler (or equivalently,
router) gain advantage changing strategies.

364

fiCollective Intelligence, Data Routing Braess' Paradox
3. Mathematics Collective Intelligence

One common solution types side-effect problems particular agents
network (e.g., \network manager" Korilis, Lazar, & Orda, 1995) dictate certain
choices agents. solution incur major brittleness scaling problems
however. Another kind approach, avoids problems centralized manager,
provide agents extra incentives induce take actions
undesirable strict SPA sense. incentive form \taxes"
\tolls" added costs associated traversing particular links discourage
use links. schemes tolls superimposed agents' goals
special case general approach replacing goal agent new
goal. new goals specifically tailored collectively met system
maximizes throughput. priori, agent's goal need particular relation
SPA-type cost incurred agent's packets. Intuitively, approach, provide
agent goal \aligned" global objective, separate concern
goal's relation SPA-type cost incurred trac routed agent.
section, summarize salient aspects Collective Intelligences (COIN) (Wolpert,
Wheeler, & Tumer, 2000; Wolpert & Tumer, 1999). paper consider systems
consist set agents, connected network, evolving across set discrete, consecutive time steps, 2 f0; 1; :::g. Without loss generality, let relevant characteristics
agent time | including internal parameters time well externally
visible actions | encapsulated Euclidean vector ;t components ;t;i .
call \state" agent time t, let ;t state agents time t,
state agent across time.
World utility, G( ), function state agents across time.
agent uses Machine Learning (ML) algorithm \try increase" private
utility, write private utility g ( ), generally, allow utility
vary time, g; ( ).
assume encompasses physically relevant variables, dynamics
system deterministic (though course imprecisely known anyone trying
control system). Note means characteristics agent = 0
affects ensuing dynamics system must included ;0 . ML-based
agents, includes particular algorithmic specification private utility, typically
physical form computer code (the mathematics generalized beyond
ML-based agents, elaborated Wolpert & Tumer, 1999).
focus case goal, COIN designers, maximize world utility
proper selection private utility functions. Intuitively, idea choose
private utilities aligned world utility, property
relatively easy us configure agent associated private
utility
P
achieves large value. paper, utilities consider form Rt ( ;t )
P
reward functions Rt (simply Rt ( ;t ) non-time-varying utilities). on,
consider world utilities whose associated set fRt g time-translations
one another. particular, shown below, overall network throughput expressible
way.
365

fiWolpert & Tumer
need formal definition concept private utilities \aligned"
Constructing formalization subtle exercise. example, consider systems
world utility sum private utilities individual agents. might
seem reasonable candidate example \aligned" utilities. However systems
examples general class systems \weakly trivial". well-known
weakly trivial systems individual agent greedily trying maximize
utility lead tragedy commons (Hardin, 1968; Crowe, 1969) actually
minimize G.
particular, case private
utilities independent
P
P
time G = g . Evidently, minimum, G = g sucient ensure
\aligned" utilities; alternative formalization concept needed.
Note simple network discussed Section 2.1, utilities weakly trivial,
since G(~x; ~y) = gX (~x) + gy (~y ). provides another perspective suboptimality
ISPA network.
G.

careful alternative formalization notion aligned utilities concept
\factored" systems. system factored time following holds
agent individually: change time state alone, propagated across
time, result increased value g; ( ) results increase
G( ) (Wolpert & Tumer, 1999).
factored system, side-effects change 's = state increases
private utility cannot decrease world utility. restrictions though effects
change private utilities agents and/or times. particular, don't
preclude agent's algorithm two different times \working cross-purposes"
other, long moments agent working improve G. game-theoretic
terms, factored systems optimal global behavior corresponds agents' always
private utility Nash equilibrium (Fudenberg & Tirole, 1991). sense,
tragedy commons factored system. trivial example, system
factored g; = G 8, system conventionally called `team game'.

Furthermore, system factored respect private utilities fg; g, want
agent state time induces high value associated private
utility possible (given initial states agents). Assume ML-based
able achieve fairly large values private utilities likely set time
, i.e., assume given private utility g; , rest components ;
set 's algorithm way achieve relatively high value g; .
problem becomes determining fg; g agents best able achieve high
g (subject other's actions) causing dynamics factored G
fg; g.

Define effect set agent-time pair (; ) , C(eff
; ) ( ), set agents
0 ;t forward dynamics system non-zero partial derivative
respect state agent = . Intuitively, (; )'s effect set set states
agents 0 ;t would affected change state agent time .
Next, set agents (0 ; t), define CL ( ) \virtual" vector formed
clamping components vector delineated arbitrary fixed value,
366

fiCollective Intelligence, Data Routing Braess' Paradox
paper set 0. 4 operation creates new state vector (e.g., worldline)
clamped components worldline (e.g., one player's action particular time
step) \zeroed" (e.g., removed system).
value wonderful life utility (WLU short) defined as:
W LU ( )

G( )

G(CL ( )):

(1)

particular, interested WLU effect set agent-time pair (; ).
WLU difference actual world utility virtual world utility
agent-time pairs affected (; ) clamped zero state
rest left unchanged.
Since clamping ~0, loosely view (; )'s effect set WLU analogous
change world utility would arisen (; ) \had never existed", hence
name utility - cf. Frank Capra movie. Note however, CL purely
\fictional", counter-factual operator, produces new without taking account
system's dynamics. sequence states agent-time pairs clamped
constructing WLU need consistent dynamical laws system.
dynamics-independence crucial strength WLU. means evaluate
WLU try infer system would evolved agent 's state
set ~0 time system evolved there. long know , extending
time, , function G, know value WLU.
mentioned above, regardless system dynamics, g; = G 8 means
system factored time .

Theorem: Regardless system dynamics, setting
factored system time .

g;

=

W LUC eff

(; )

8 results

Proof: second term, G(CLC eff ( )) is, definition, independent ; . Therefore
(; )

change (; ) component affect first term, G( ). Therefore
effect change value world utility effect
value wonderful life utility. QED.
Since factoredness distinguish team game wonderful life utilities,
need means deciding use choice fg; g. determine
this, note since agent operating large system, may experience diculty
discerning effects actions G G sensitively depends agents
system. Therefore may diculty learning past experience
achieve high g; g; = G. particular, routing large networks, private
rewards given world reward functions means provide router
reward time step need provide full throughput entire network
step. usually infeasible practice. Even weren't though, using
private utilities would mean routers face dicult task trying discern
4. choice clamping parameter used associated COIN affect performance. However
within wide ranges, doesn't affect whether COIN outperforms alternatives team games.

367

fiWolpert & Tumer
effect actions rewards, therefore would likely unable learn
best routing strategies.
problem mitigated using effect set WLU private utility, since
subtraction clamped term removes much \noise" activity agents,
leaving underlying \signal" agent question affects utility (this
reasoning formalized concept \learnability" Wolpert & Tumer, 1999). Accordingly, one would expect setting private utilities WLU's ought result better
performance g; = G 8; . primary theoretical consideration
leverage COIN techniques investigated paper.
practice, sometimes able estimate \primary", prominent
portion effect set. Technically, associated WLU effect set WLU,
therefore exactly factored. However assuming associated WLU close enough
factored, would expect advantage learnability WLU still
result better performance would using g; = G 8; (see Wolpert et al., 2000;
Wolpert & Tumer, 1999). Indeed, sake improving learnability, sometimes
elect exclude certain agent-time pairs estimate effect set (; ), even
sure affected ; . case expect
changes G due varying ; \mediated" agent-time pairs
relatively insignificant, therefore effectively constitute noise learning process,
effect learnability important effect factoredness.
4. Collective Intelligence Network Routing

section, use theory summarized Section 3 derive individual goals
router, form private utility functions maximized appropriate choice
routing decisions. routers tried achieve maximizations using algorithms
require limited knowledge state network (in particular knowledge
readily available routers common real data networks). simulations
router used Memory Based (MB) machine learning algorithm (nearest neighbor) make
routing decisions. precisely, potential routing decision, routers look
past state closely closely matches current state (e.g., load).
assign "estimated" utility value potential routing decision select action
highest estimated utility value. call algorithm MB COIN5 .

4.1 Model Description
apply COIN formalism network routing model, must formally describe
set deterministically evolving vectors ;t . model used paper,
time step trac router set pairs integer-valued trac amounts
associated ultimate destination tags. time step t, router r sums
integer-valued components current trac time step (one component
5. Relatively minor details algorithm concerning exploration/exploitation issues along \steering" parameter discussed end section.

368

fiCollective Intelligence, Data Routing Braess' Paradox
ultimate destination) get instantaneous load. write load as:
zr (t)



X


xr;d (t);

index runs ultimate destinations, xr;d (t) total trac time
going r towards d. instantaneous load time evaluated, router
sends trac next downstream routers, manner governed underlying
routing algorithm. indicate \next routers" writing:


xr;d (t)

=

X
r0

xr;d;r0 (t);

r0 next router trac (r; d), i.e., first stop path followed
router r ultimate destination d. routed trac goes next
downstream routers, cycle repeats itself, trac reaches destinations.
simulations, simplicity, trac introduced system (at
source routers) beginning successive disjoint waves L consecutive time steps
each6 . use (t) indicate either integer-valued wave number associated time
set times wave, context indicates.
real network, cost traversing router depends \after-effects" recent
instantaneous loads, well current instantaneous load. simulate effect,
use time-averaged values load router rather instantaneous load determine
cost packet incurs traversing router. formally, define router's
windowed load, Zr (t), running average router's load value window
previous W timesteps (W always set integer multiple L):
Zr (t)

W1


X
t0 =t W +1

zr (t0 )

=

X


Xr;d (t);

value Xr;d (t) set
Xr;d (t)

=

1


X

W 0
=t W +1

xr;d (t0 )):

Intuitively, large enough W , using window determine costs across routers
means typically costs change substantially time scales significantly
larger individual routing decisions. Formally, windowed load
argument load-to-cost function, V (), provides cost accrued time
packet traversing router timestep. is, time t, cost
packet traverse router r given V (Zr (t))7 . Note model, costs
accrued routers, links. note simplicity physically
instantiate cost temporal delay crossing router. Different routers different
6. L always chosen minimal number necessary trac reach destination
next wave trac initiated.
7. introduce \dummy routers" denoted V0 () = 0 help translating mathematics
simulations. Omitting effect simulations.

369

fiWolpert & Tumer
V (), ect fact real networks differences router software hardware
(response time, queue length, processing speed etc). simplicity, W
routers however. definitions, world utility given
G( )

=
=

X
t;r
X
t;r;d

=

X
t;r;d

=

X
t;r;d

zr (t) Vr (Zr (t))
xr;d (t)Vr (Zr (t))
0

xr;d (t)Vr @
xr;d (t)Vr

1


X

X

W 0
=t W +1 d0

X
d0

1

xr;d0 (t0 )A

!

Xr;d0 (t)

(2)

:

equation G explicitly demonstrates
that, claimed above, representation
P
express G( ) sum rewards, Rt ( ;t ), R( ;t ) written function
pair (r; d)-indexed vectors:
Rt (xr;d (t); Xr;d (t))

=

X
r;d

xr;d (t)Vr

X
d0

!

Xr;d0 (t)

:

claimed, Rt temporal translations one another.
Given model, components ;t must identified values
xr;d;r0 (t) 8 r; d; r 0 t, since x's set actions agents take. Since
arguments G must components , include Xr;d (t) 8r; d; components
;t . Formally, routing based ML agents, internal parameters ML agents
must included . parameters affect routing,
turn affected it. evolve deterministically, since includes routing
variables, must contain internal parameters agents. won't need
explicitly delineate variables however, mostly phrase discussion
though internal parameters.
values fxr;d;r0 (t 1)g 8r; d; r0 specify values fxr;d (t)g 8r; directly. Therefore, concert fxr;d (t0 < t)g, set fXr;d (t)g directly. Moreover
simulations decisions fxr;d;r0 (t)g 8r; d; r0 fixed routing
algorithms times
P
given fixed function fxr;d (t)g fZr (t) = d0 Xr;d0 (t)g. point
fact map set fxr;d;r0 (t 1); Xr;d0 (t)g 8r; d; r0 full set fxr;d;r0 (t)g 8r; d; r0 ,
fxr;d (t)g. Accordingly, xr;d;r0 undergo deterministic evolution. Since
values across time set values Xr;d (t) across time, see entire set
components ;t undergo deterministic evolution representation, required.
evaluating wonderful life utility need group components ;t
disjoint agents . two types agent, types indexed
router-destination pairs. agent index (r; d), first agent type variable
Xr;d (t), second agent type Euclidean vector components indexed r 0 ,
(xr;d )r0 (t). setting \actions" concerned setting states agents
second type. Accordingly, learners associated agents second
370

fiCollective Intelligence, Data Routing Braess' Paradox
type. Unless explicitly indicated otherwise, implicitly second
type agent mind whenever refer \agent" use symbol .

4.2 ISPA Routing COIN Routing
Based COIN formalism presented Section 3 model described above,
present ISPA COIN-based routing algorithms. time step t, ISPA access
windowed loads time step 1 (i.e., access Zr (t 1) 8r), assumes
values remain times t. Note large window sizes
times close t, assumption arbitrarily accurate. Using assumption,
ISPA, router sends packets along path calculates minimize costs
accumulated packets.
COIN-based routing algorithms, contrast, direct access
Zr . evaluate WLU agent (r; d) time , algorithm must
estimate (primary members the) associated effect set. means determining
components ; will, dynamics system, changed altering
components vector xr;d( ).
first approximation, ignore effects trac changing xr;d;r0 ( ) may
\mediated" learning algorithms running system. is,
ignore changes arise due effects changing xr;d;r0 ( ) rewards,
changes induce changes future training sets, turn get mapped
changes fxr;d;r0 (t)g (and therefore fXr;d (t)g) via learning algorithms running
agents.
another approximation, ignore effects mediated routing algorithms'
observations state network. is, ignore changes fxr00 ;d0 ;r000 (t)g
varying xr;d ( ) may cause due associated changes state network perceived
(r00 ; d0 )'s routing algorithm, changes turn cause algorithm modify routing
decisions accordingly. consider behavior routing algorithms
(potentially) directly affected xr;d ( ) (potentially) route packets
that, time , passed r way d. particular ignore effects
xr;d ( ) fxr00 ;d0 =
6 d;r000 (t)g.
Since packets routed wave arrive destinations end wave,
approximations mean xr00 ;d00 ;r000 (t) estimate xr;d ( )'s
effect set wave . ones are, potentially, directly
affected fxr;d;r0 (t)g \chaining together" sequence xr00 ;d00 ;r000 (t) get
packets xr;d (t) ultimate destination. Due wave nature simulations
though, xr00 ;d00 ;r000 (t) within 's wave affected xr;d ( ) d00 = d.
reasons coding simplicity, concern whether < within
given wave exclude xr00 ;d00 ;r000 (t) accordingly. words, within 's
wave treated equally.
one set members xr;d ( )'s effect set fxr00 ;d;r000 (t) 8r00; d; r000 ; 2 ( )g. Note
members relatively unaffected xr;d ( ) (e.g., r00 far
net away r). simplicity, try determine exclude
them. keeping xr00 ;d;r000 (t < ), inclusion extra agents estimate
effect set hurt learnability, general hurt factoredness. Therefore
371

fiWolpert & Tumer
delay quickly learners determine optimal policies, won't affect
quality (for G) policies finally arrived at. Note trying determine
whether particular xr00 ;d;r000 (t 2 ( )) included xr;d ( )'s effect set would
mean, part, determining whether packets routed (r; d) would reached r00
(r; d) made routing decision different one actually made. would
non-trivial exercise, general.
contrast case xr00 ;d0 ;r000 (t), Xr00 ;d0 (t) future 's
wave affected xr;d (t) excluded approximations
far. particular, Xr00 ;d (t) either r00 = r r00 one hop away r
1
directly affected xr;d (t), 2 [W
i=0 ( + iL)) (cf. definition X variables).
simplicity, restrict consideration Xr00 ;d variables router
r, r00 = r.
final estimate effect set clearly rather poor | presumably results better
presented would accrue use accurate effect set. However it's
worth bearing mind \self-stabilizing" nature choice effect sets,
used conjunction effect set WLU's. nature mediated learning
algorithms. one assigns utility function two agents, reward one
agent gets determined part one does. modifies
behavior try increase reward, first agent modifying behavior
way dependent agent does. words, two agents given
WLU estimated other's effect set, ipso facto
other's effect set.
Using estimate effect set, WLU (; ) given difference
total cost accrued 's wave agents network cost accrued
agents agents sharing 's destination \erased." precisely, agent
destination following effect set WLU's, g; :
g; ( )=

=

G( )
X
t;r0 ;d0


=

G(CLC eff ( ))
(; )

xr0 ;d0 (t) Vr0
Vr0

X
d00

X
d0

!

X

Xr0 ;d0 (t)

[ Xr0 ;d00 (t) (1

t;r0 ;d0

(t

2[

xr0 ;d0 (t)(1

W 1
i=0 (

(t

2 ( ))I (d0 = d))

+ iL))I (d00 = d)) ]

!

0
1
X
X
X
X
@
xr0 ;d0 (t) Vr0 (
Xr0 ;d00 (t))
xr0 ;d0 (t) Vr0 (
Xr0 ;d00 (t))A
d0
d00
d0 6=d
d00 6=d
t2( ) r0
0
1
X
X X
X
X
@
+
xr0 ;d0 (t) [Vr0 (
Xr0 ;d00 (t)) Vr0 (
Xr0 ;d00 (t))]A
(3)
0
0
00
00
W
1
r



=
6

t2[
( +iL)
X X

i=1

(:) indicator function equals 1 argument true, 0 otherwise.
allow learner receive feedback concerning actions wave immediately
following wave rather wait W L time steps, approximate second
sum last equality, one times following 's wave, zero. another
way view resultant expression, rather approximation effect
372

fiCollective Intelligence, Data Routing Braess' Paradox
set WLU. view exact WLU approximation effect set,
approximation ignores effects future windowed loads clamping current trac
level. Regardless view adopt, presumably better performance could achieved
implement approximation.
Given approximation, WLU becomes wave-indexed time-translation-invariant
WL \reward function" (WLR):
g; ( ;t2( ) )

X

X

t2( );r0

d0

=

X
d0 6=d

xr0 ;d0 (t) Vr0 (

xr0 ;d0 (t) Vr0 (

X
d00

X

d00 6=d

Xr0 ;d00 (t))
1

Xr0 ;d00 (t))A :

(4)

Notice trac going router r0 6= r destination d0 6= affects value
WLR agent (r; d). ects fact WLR takes account side-effects
(r; d)'s actions agents. Note r0 -indexed term contributing
WLR computed associated router r0 separately, information available
router. Subsequently terms propagated network ,
much way routing tables updates propagated.
Given choice private utility, must next specify COIN-based routing
algorithm collects initial data (in conjunction utility) used
guide initial routing decisions every agent one routing option must
make. experiments data collected preliminary running ISPA.
preliminary stage, routing decisions made using ISPA, resulting
actions \scored" using WLR given Equation 3. use ISPA generate
routing decisions initial data since likely practice kind SPA
routing algorithm running prior \turning on" COIN algorithm. Alternately
one generate initial data's routing decisions routers make random
decisions, implement sequence decisions \sweeps" across grid
possible set actions. data collected stage provides us initial
input-output training sets used machine learning algorithm agent:
router-destination agent, inputs identified windowed loads outgoing links,
associated WLR values destination question outputs.
sucient initial data collected using ISPA, system switches using
COIN algorithm make subsequent routing decisions. stage, agent routes
packets along link estimates (based training set) would provide best
WLR. perform estimation, MB COIN makes use single-nearest-neighbor
algorithm learner. algorithm simply guesses output would ensue
candidate input output element training set
nearest neighbor (in input space) candidate input.8 words,
learner finds training set input-output pair whose input value (loads outgoing links)
8. simple learning algorithm, use demonstrate potential practical
feasibility COIN-based routing algorithm. performance presumably improved
sophisticated learning algorithms (e.g., Q-learning Sutton & Barto, 1998; Watkins & Dayan, 1992)
used.

373

fiWolpert & Tumer
closest would result potential routing decision. learner
assigns WLR associated training data pair estimate WLR
would result said routing decision. WLR values used choose among
potential routing decisions. input-output data generated algorithm
adding training set generated.
routing algorithm, routers estimate routing decisions (as
ected loads individual time steps) affect WLR values (based
many agents' loads). possible calculate exactly routing decisions affect
routers' WLR's if, unlike MB COIN, full knowledge loads
agents system. way similar ISPA, router evaluate exact
WLR value would ensue candidate actions, assumption
windowed loads routers one wave future
now. call algorithm directly maximizing WLR (an algorithm call full
knowledge COIN, FK COIN).
Note assumption behind FK COIN, action chooses wave ( )
maximizes WLR maximize world reward. words, WL reward
perfectly factored respect (wave-indexed) world reward, even though associated
utilities related way (due inaccuracy estimate effect set). Due
factoredness, FK COIN equivalent load balancing world rewards. Since
LB general results inferior performance compared LB time, since FK
COIN equivalent LB, one might expect performance suboptimal. Intuitively,
suboptimality ects fact one choose action regard
effect current reward, concern reward future waves.
language COIN framework, suboptimality viewed restatement
fact inexactly estimated effect set, system perfectly factored.
learning algorithm MB COIN described extraordinarily crude. addition, associated scheme choosing action purely exploitative, exploration
whatsoever. Rather choose particular sophisticated scheme tune
fit simulations, emulated using sophisticated algorithms general.
modifying MB COIN algorithm occasionally FK COIN determine
router's action rather purely greedy learner outlined above. steering parameter discussed Section 5.5 determines often routing decision based
MB COIN opposed FK COIN.
5. Simulation Results

practice, dicult implement either FK COIN LB. section use
experiments investigate behavior algorithms conceivably used practice.
precisely, based model routing algorithms discussed above, performed simulations compare performance ISPA MB COIN across variety
networks, varying size five eighteen routers. cases trac inserted
network regular, non-stochastic manner sources. results report
averaged 20 runs. report error bars lower 0:05.
Sections 5.1 - 5.4 analyze trac patterns four networks ISPA suffers
Braess' paradox. contrast, MB COIN almost never falls prey paradox
374

fiCollective Intelligence, Data Routing Braess' Paradox
networks (or networks investigated MB COIN significantly
susceptible Braess' paradox). Section 5.5 discuss effect MB
COIN's performance \steering" parameter determines intelligence
MB COIN.9

5.1 Bootes Network
first network type investigate shown Figure 3. many senses trivial
network, Net A, sources even choices make. loads introduced sources change time listed Tables 1 2, along
performances algorithms.


@D@

V1

@
@@yV2

@@
AA
@y@V0
AyV0
AAy
@yS1
S2

y@D
@

V1

@@

@yV2
@@
AA
yV3 AyV0
@yV0
@@y

S1
S2 Ay

Net

Net B
Figure 3: Bootes Network

Loads (S1 ; S2 ) Net
1,1

B
2,1

B
2,2

B
4,2

B

ISPA MB COIN
6.35
6.35
8.35
5.93
8.07
8.07
10.40
7.88
9.55
9.55
10.88
9.71
10.41
10.41
11.55
10.41

Table 1: Average Per Packet Cost BOOTES2 networks V1 = 10 + log(1 + x) ;
4x2 ; V3 = log(1 + x) .

V2

=

MB COIN results identical ISPA results absence additional
link (Network A). However, Braess' paradox arises ISPA, addition
new link network B degrades performance ISPA six eight trac
regimes load-to-cost functions investigated. MB COIN hand
9. Sections 5.1 - 5.4, steering parameter set 0.5.

375

fiWolpert & Tumer

Loads (S1 ; S2 ) Net ISPA MB COIN
1,1
30.35
30.35
B 20.35
20.35
2,2
35.55
35.55
B 40.55
34.99
4,2
41.07
41.07
B 50.47
44.13
6,3
44.63
44.63
B 51.40
44.63
Table 2: Average Per Packet Cost BOOTES4 network
10x ; V3 = log(1 + x) .

V1

= 50 + log(1 + x) ;

V2

=

hurt addition new link once, manages gainfully exploit seven times.
behavior analyzed infinitesimally, MB COIN either uses additional
link eciently chooses ignore seven cases. Moreover, MB COIN's
performance additional link always better ISPA's. example, adding
new link causes degradation performance much 30 % (loads = f2; 1g)
ISPA, whereas load vector MB COIN performance improves 7 %.

5.2 Hex Network
section revisit network first discussed Section 2.1 (redrawn Figure 4
include dummy agents). Table 3 give full results load-to-delay functions
discussed section. use load-to-cost functions qualitatively similar
discussed Section 2.1, incorporate non-linearities better represent
real router characteristics. load-to-cost function associated results reported
Table 4.

V2
V0
V1

"y
bDb
"
"
bb
y"
"
byV1

yV0

bb
"yV2
"
bb ""
b"
yS
Net

V2
V0
V1

"ybDb
"
"
bb
"y"
byV1

Vy3 yV0
yb
"yV2
bb
"
bb"yS""

Figure 4: Hex network

Net B

network demonstrates addition new link may beneficial
low trac cases, leads bottlenecks higher trac regimes. ISPA although
376

fiCollective Intelligence, Data Routing Braess' Paradox
per packet cost loads 1 2 drop drastically new link added, per
packet cost increases higher loads. MB COIN hand uses new
link eciently. Notice MB COIN's performance slightly worse
ISPA absence additional link. caused MB COIN use
learner estimate WLU values potential actions whereas ISPA simply
direct access information needs (costs link).
Load Net ISPA MB COIN
1
55.50
55.56
B 31.00
31.00
2
61.00
61.10
B 52.00
51.69
3
66.50
66.65
B 73.00
64.45
4
72.00
72.25
B 87.37
73.41
Table 3: Average Per Packet Cost HEX network V1 = 50+ x ;
.

V2

= 10x ;

V3

= 10+ x

Load Net ISPA MB COIN
1
55.41
55.44
B 20.69
20.69
2
60.69
60.80
B 41.10
41.10
3
65.92
66.10
B 61.39
59.19
4
71.10
71.41
B 81.61
69.88
Table 4: Average Per Packet Cost HEX network
10x ; V3 = log(1 + x) .

V1

= 50 + log(1 + x) ;

V2

=

5.3 Butter Network
next network investigate shown Figure 5. extension simple
network discussed Section 5.1. doubled size network
three sources route packets two destinations (packets originating
S1 go D1 , packets originating S2 S3 go D2 ). Initially two halves
network minimal contact, addition extra link two sources
two two halves network share common router potential shortest path.
377

fiWolpert & Tumer



TT

yD2

TT


TTy
TTy

V1
V2


V3

yV1
V0 Ty
V0 Ty

@@
@yS3
S1 Ty
S2
D1



TT

yD2

TT


TTy
TTy

V1
V2


V3


V0 Ty V3 V0 Ty
y@V1

@
S2 Ty @yS3
S1
D1

Net

Net B
Figure 5: Butter Network

Table 5 presents two sets results: first present results uniform trac
three sources, results asymmetric trac. first case, Braess'
paradox apparent ISPA: adding new link beneficial network low
load levels average per packet cost reduced nearly 20%, deleterious
higher levels. MB COIN, hand, provides benefits added link
low trac levels, without suffering deleterious effects higher load levels.
Loads (S1 ; S2 ; S3 ) Net ISPA MB COIN
1,1,1
112.1
112.7
B
92.1
92.3
2,2,2
123.3
124.0
B 133.3
122.5
4,4,4
144.8
142.6
B 156.5
142.3
3,2,1

81.8
82.5
B
99.5
81.0
6,4,2

96.0
94.1
B 105.3
94.0
9,6,3
105.5
98.2
B 106.7
98.8
Table 5: Average Per Packet Cost BUTTERFLY network V1 = 50+ log(1+ x) ;
10x ; V3 = log(1 + x).

V2

=

asymmetric trac patterns, added link causes drop performance
ISPA, especially low overall trac levels. true MB COIN. Notice
high, asymmetric trac regime, ISPA performs significantly worse
MB COIN even without added link, showing bottleneck occurs right side
network alone (similar Braess' paradox observed Section 5.1).
378

fiCollective Intelligence, Data Routing Braess' Paradox
5.4 Ray Network
networks trac regimes discussed far sources routers
one routing option. final network investigate larger network
number routers multiply options significantly higher previous
networks. Figure 6 shows initial network (Net A) \augmented" network (Net
B), new links added. original network relatively choices
routers, packets directed toward destinations along \conduits." new
links added augmented networks provide new choices (crossing patterns)
could beneficial certain original conduits experience large costs.

V2
V0
V1

bDb1 ""y
bDb2
"y
"
"
b"
b
y" V1 y"" bbyV1 bbyV2
"
V0
yV0
yV0
yV
yV
V2
JJ


JJ 2

1
J

J

J%
yV3
V3 J
e

ee
%
%
e


%
S1
S2
Net

V2
V0
V1

"ybDb1 ""ybDb2
"
"
"b
b
"yc" V1 "y" bbyV1 b#byV2
yVc3 cy yV0 V0 #y#V3 yV0
Vc2cyc ##yV#2
yV
JJ

c # JJ

1
J
#c#c J

V3 J
e
ye #yV3 V3cy %J%
yV3
%
e

%
e

S2
S1

Figure 6: Ray network

Net B

Table 6 shows simulation results networks (S1 S2 send packets D1
D2 respectively). low load levels ISPA MB COIN use new links
effectively, although MB COIN performs slightly worse. mainly caused
diculty encountered simple learner (single nearest neighbor algorithm) quickly
learning trac patterns large network. Unlike ISPA however, MB COIN
avoids Braess' paradox cases except high trac regime. Moreover, even
there, effect significantly milder encountered ISPA.

5.5 Steering MB COIN
final aspect COIN-based routing investigate impact choice
value steering parameter. parameter controls amount exploration
algorithm performs determines \intelligence" MB COIN estimating
surface directly calculated FK COIN. Figures 7 - 8, FK COIN results
correspond setting steering parameter MB COIN 1:0. provides
upper bound performance achieved though MB COIN.
HEX network (Figure 7), performance worst setting MB COIN,
corresponds steering, comparable ISPA. contrast, moderate steering
379

fiWolpert & Tumer

Loads S1 andS2 ) Net ISPA MB COIN
2,2
143.6
143.7
B 124.4
126.9
3,3
154.6
154.9
B 165.5
151.0
4,4
165.4
166.0
B 197.7
165.6
6,6
186.7
187.4
B 205.1
191.6
Table 6: Average Per Packet Cost RAY network
10x ; V3 = 10 + log(1 + x).

= 50 + log(1 + x) ;

V2

=

180

80

Per Packet Delay

Per Packet Delay

85

V1

ISPA
FK COIN
MB COIN

75
70
65

ISPA
FK COIN
MB COIN

170
160
150
140

0

0.1 0.2 0.3 0.4
Steering Parameter

0.5

0

0.1 0.2 0.3 0.4
Steering Parameter

0.5

Figure 7: Impact steering Hex4 (left) Ray4 (right) networks.
(0.5) results similar FK COIN, learner information
work (arising extra parts input space represented training
set due occasional use FK COIN), bridges gap suboptimal
algorithm susceptible Braess' paradox one eciently avoids paradox.
RAY network (Figure 7), value steering parameter critical.
steering all, MB COIN performs poorly network | even worse
ISPA. surprising many routing choices affect
performance, simple memory-based learner needs proper \seeding" able
perform well. Even minimal steering though, MB COIN quickly outperforms
ISPA.
Finally, Butter Bootes networks (Figure 8) MB COIN needs
little steering perform well. Although Butter network performance
MB COIN improves slightly information, significantly better ISPA
across board.
380

fi105

Per Packet Delay

Per Packet Delay

Collective Intelligence, Data Routing Braess' Paradox

ISPA
FK COIN
MB COIN

100

95

40
ISPA
FK COIN
MB COIN
35

90
0

0.1 0.2 0.3 0.4
Steering Parameter

0.5

0

0.1 0.2 0.3 0.4
Steering Parameter

0.5

Figure 8: Impact steering Butter y4 (left) Bootes4 (right) networks.
6. Conclusion

Effective routing network fundamental problem many fields, including data
communications transportation. Using shortest path algorithm (SPA)
routers determine router's decisions popular approach problem. However
certain circumstances suffers number undesirable effects. One effect
Braess' paradox, pattern introduced trac network, increasing
capacity network results lower overall throughput, due harmful sideeffects decisions made router trac rest system. Even
theoretical load-balancing algorithm, addresses effects produce
decisions optimal single moment time, still suffer side-effects
result sub-optimal performance. effects extend across time
(i.e., affects performance later) well space.
Collective Intelligence approach novel way controlling distributed systems
avoid deleterious side-effects routing decisions. central idea learning
algorithms control autonomous agents constitute overall distributed system.
Collective Intelligence (COIN), central issue determine personal
objectives assigned autonomous agents. One wants choose
goals greedy pursuit goals associated learning algorithms leads
desirable behavior overall system. paper summarized mathematics
designing goals derived routing algorithm based mathematics.
ran computer simulations compare COIN-based algorithm ideal SPA
(whose performance upper-bounds real-world SPA's) routing. COIN-based algorithm severely handicapped. estimation \effect sets" used algorithm
exceedingly crude. addition, learning algorithms agents particularly
unsophisticated, therefore able effectively maximize individual performances. contrast, ideal SPA access information concerning state
system (real-world-implementable) COIN did, information real-world
SPA could access.
381

fiWolpert & Tumer
Despite biases favor ideal SPA, experiments ideal SPA induced
average costs much 32 % higher COIN-based algorithm. Furthermore
COIN-based algorithm almost always avoided Braess' paradox seriously diminished
performance SPA.
techniques successfully employed many other, non-routing
domains, coordination autonomous rovers (Tumer, Agogino, & Wolpert, 2002),
combinatorial optimization, \congestion games" (Wolpert & Tumer, 2001), control
data-upload planet (Wolpert, Sill, & Tumer, 2001). conclude results
techniques field collective intelligence highly effective designing
utility functions members MAS ensure work coordinated
ecient manner optimize overall performance. currently investigating extensions
COIN algorithm involve novel goals agents, goals \learnable" learning algorithms. expanding simulations larger networks
using commercial event driven simulator. Future work focus making approximation current trac levels affect future windowed loads (Equation 3).
involve investigating better estimates effect sets, particular including
agents destination one's effect set, generally using
\fine-grained" representation agents, example including packet's originating
source, allow fine-grained effect set (and resultant WLU).
Acknowledgments

authors thank Joe Sill reviewers helpful comments.
Appendix A. Suboptimality Load-Balancing

appendix present existence proof suboptimality Load-Balancing
(LB) explicitly constructing situation conventional LB suboptimal.
Consider system discrete time, source agent X consideration
must route one packet (fixed) destination time step. Presume
trac source agent X enters agents X sends to,
trac coming X sole source costs associated X 's outbound links. Let
(t) number times agent sent packet link W time steps
preceding t, take s(t) = A; B mean router uses link B , respectively,
time t. Model queue backups cost send packet link
time CA (S (t)=W ), cost router instead send packet
link B CB (1 (t)=W ), simplicity assume CA (:) CB (:)
monotonically increasing functions arguments.
Restrict attention agents work s(t) = iff (t) k realvalued threshold k. LB algorithm choose s(t) = iff CA (S (t)=W ) CB (1
(t)=W ). LB algorithm's behavior indistinguishable kind threshold
algorithm, k set CA (k=W ) = CB (1 k=W ). (We implicitly assume CA (:)
CB (:) chosen solution exists 1 < k < W 1.) question
382

fiCollective Intelligence, Data Routing Braess' Paradox
k optimize total averaged cost across time, particular k
kLB , k LB uses.
go one time step next, routing decision made W time steps
ago drops computation (t), routing decision made newly
included. general, (t + 1) = (t) + 1 router used time used link B
time W time steps past. hand, (t + 1) = (t) 1 router
used B used W time steps ago, (t + 1) = (t) routing decision
made routing decision W time steps ago. general, (t)
change -1, 0, +1 go one time step next.
Consider cases 1 < k < W 1, eventually router must choose A,
subsequent time router switches B . time s(t 1) =
s(t ) = B . implies (t 1) k; (t ) > k. Define value (t 1) k .
Note (t ) = k + 1, k 1 < k k.
time t0 , (t0 ) = k + 1, s(t0 + 1) = B , possible next values
(t0 + 1) = k (t0 + 1) = k + 1, depending old decision s(t W ) gets
dropped window. Similarly, (t0 ) = k , s(t0 + 1) = A, possible
next values (t0 + 1) = k (t0 + 1) = k + 1, depending old decision
dropped. see (t0 ) 2 fk ; k + 1g, stays forever.
means relationship k k , interval W
consecutive time steps subsequent , number packets sent along router X
must 2 (k 1; k +1]. (Note possible send k +1 packets along A, k 1
packets. Therefore number sent along B must 2 [W (k + 1); W (k 1)).
time packet sent along cost incurred cost link average trac
level (t)=W , CA (S (t)=W ). Similarly, time link B chosen, cost incurred
CB (1 (t)=W ). Since (t) 2 fk ; k + 1g, CA (:) CB (:) monotonically
increasing, cost sending packet link 2 (CA ((k 1)=W ); CA ((k + 1)=W ],
sending link B contained [CB (1 (k +1)=W ); CB (1 (k 1)=W )).
know choice must average frequency (across time)

k =W (k + 1)=W . Similarly, B average frequency (1 (k + 1)=W )
1 k =W . Accordingly, average cost bounded






k+1
k
k 1
k + 1
CA
+ 1
CB 1
;
(5)
W

W

W

W

first term provides maximum possible average cost using link A,
second term independently provides maximum possible average cost using link
B . Note actual cost lower since two frequencies bound, one
one B , cannot values indicated. k 1 < k k since
+1 , upper bound bounded
1 kW1 = 1 + W2 kW
k+1
W



CA

k+1
W



+



1+

2

k+1

W

W





CB

1+

2

k+1

W

W



:

(6)

optimal k result average cost lower minimum k
upper bound average cost, given Equation 6. average cost optimal
k bounded minimum k upper bound. Lable argmin
Equation 6 k'.
383

fiWolpert & Tumer
Since values k besides kLB result behavior equivalent LB,
suce simply test k' = kLB . Instead let us evaluate lower bounds similar
fashion evaluated upper bounds. Using average frequencies discussed above,
average cost bounded by:






k 1
1
k
k+1
k
CA
+ 1
CB 1
;
(7)
W

W

W

W

W

first term provides minimum possible average cost using link A,
second term provides minimum possible average cost using link B . Again,
k 1 < k k , term Equation 7 bounded
1

k
W



CA

1

k



W

+



1

2
W

1

k
W





CB

1

2

1

k

W



particular bound holds average cost LB algorithm:





kLB 1
kLB 1
2 kLB 1
2 kLB
CA
+ 1
CB 1
W

W

W

W

W

(8)

:

W

W

1



;

(9)

kLB satisfies CA (kLB =W ) = CB (1 kLB =W ).
appropriate choice CA (:) CB (:), ensure lower bound
cost LB algorithm (Equation 9 evaluated k = kLB ) higher upper
bound average cost incurred optimal algorithm (the minimum k Equation 6). is, best possible average cost achieved load balancing worse
worst average cost could arise optimal routing strategy.
establishes LB engage optimal routing.

Example: Let CA (x) = x2 CB (x) = x. Balancing loads B | setting

2
C
pA (S (t)=W ) = CB (1 (t)=W ) | results (S (t)=W ) = 1 (t)=W , leading kLB =W =
5 1 = :618. W = 1000, associated lower bound average cost (Equation 9)
2
(:618)3 + (:998 :618)2 = :380. hand, CA CB given above, Eq 6
k+1 2
( k+1 )3 + (1 + 2
) . Differentiating respect k setting result
W

k0
W

W

1
3

W

1

p28+48=W

zero leads
=
. window size W = 1000, yields
W +
6
k 0 =W = :548, different result kLB . Plugging Equation 6, upper bound
cost k0 (:549)3 + (1:002 :549)2 = :371, less :380.
References

Ahuja, R. K., Magnanti, T. L., & Orlin, J. B. (1993). Network Flows. Prentice Hall, New
Jersey.
Bass, T. (1992). Road ruin. Discover, 13 (5), 56{61.
Bertsekas, D., & Gallager, R. (1992). Data Networks. Prentice Hall, Englewood Cliffs, NJ.
Bonabeau, E., Henaux, F., Guerin, S., Snyders, D., Kuntz, P., & Theraulaz, G. (1999a).
Routing telecommunications networks \smart" and-like agents. (pre-print).
Bonabeau, E., Sobkowski, A., Theraulaz, G., & Deneubourg, J.-L. (1999b). Adaptive task
allocation inspired model division labor social insects. (pre-print).
384

fiCollective Intelligence, Data Routing Braess' Paradox
Boyan, J. A., & Littman, M. (1994). Packet routing dynamically changing networks:
reinforcement learning approach. Advances Neural Information Processing
Systems - 6, pp. 671{678. Morgan Kaufman.
Choi, S. P. M., & Yeung., D. Y. (1996). Predictive Q-routing: memory based reinforcement
learning approach adaptive trac control. Touretzky, D. S., Mozer, M. C., &
Hasselmo, M. E. (Eds.), Advances Neural Information Processing Systems - 8, pp.
945{951. MIT Press.
Claus, C., & Boutilier, C. (1998). dynamics reinforcement learning cooperative
multiagent systems. Proceedings Fifteenth National Conference Artificial
Intelligence, pp. 746{752, Madison, WI.
Cohen, J. E., & Jeffries, C. (1997). Congestion resulting increased capacity singleserver queueing networks. IEEE/ACM Transactions Networking, 5 (2), 305{310.
Cohen, J. E., & Kelly, F. P. (1990). paradox congestion queuing network. Journal
Applied Probability, 27, 730{734.
Crowe, B. L. (1969). tragedy commons revisited. Science, 166, 1103{1107.
Deo, N., & Pang, C. (1984). Shortest path algorithms: Taxonomy annotation. Networks,
14, 275{323.
Dijkstra, E. (1959). note two problems connection graphs. Numeriche Mathematics, 1 (269-171).
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press, Cambridge, MA.
Glance, N. S. (1993). Dynamics Expectations. Ph.D. thesis, Stanford University.
Glance, N. S., & Hogg, T. (1995). Dilemmas computational societies. Lesser, V.
(Ed.), Proc. 1st International Conference Multi-Agent Systems (ICMAS95),
pp. 117{124, Menlo Park, CA. AAAI Press.
Hardin, G. (1968). tragedy commons. Science, 162, 1243{1248.
Heusse, M., Snyers, D., Guerin, S., & Kuntz, P. (1998). Adaptive agent-driven routing
load balancing communication networks. Advances Complex Systems, 1,
237{254.
Hogg, T. (1995). Social dilemmas computational ecosystems. Proceedings
Fourteenth International Joint Conference Artificial Intelligence, pp. 711{716, San
Mateo, CA. Morgan Kaufmann.
Hu, J., & Wellman, M. P. (1998a). Multiagent reinforcement learning: Theoretical framework algorithm. Proceedings Fifteenth International Conference
Machine Learning, pp. 242{250.
Hu, J., & Wellman, M. P. (1998b). Online learning agents dynamic multiagent system. Proceedings Second International Conference Autonomous
Agents, pp. 239{246.
Huberman, B. A., & Hogg, T. (1988). behavior computational ecologies.
Ecology Computation, pp. 77{115. North-Holland.
385

fiWolpert & Tumer
Huberman, B. A., & Lukose, R. M. (1997). Social dilemmas internet congestion. Science,
277 (5325), 535{537.
Huberman, B. A., & Hogg, T. (1993). emergence computational ecologies. Nadel,
L., & Stein, D. (Eds.), 1992 Lectures Complex Systems, Vol. V SFI Studies
Sciences Complexity, pp. 185{205. Addison-Wesley, Reading, MA.
Huhns, M. E. (Ed.). (1987). Distributed Artificial Intelligence. Pittman, London.
Jennings, N. R., Sycara, K., & Wooldridge, M. (1998). roadmap agent research
development. Autonomous Agents Multi-Agent Systems, 1, 7{38.
Kaelbing, L. P., Littman, M. L., & Moore, A. W. (1996). Reinforcement learning: survey.
Journal Artificial Intelligence Research, 4, 237{285.
Kelly, F. P. (1996). Modeling communication networks, present future. Philosophical
Trends Royal Society London A, 354, 437{463.
Korilis, Y. A., Lazar, A. A., & Orda, A. (1995). Architecting noncooperative networks.
IEEE Journal Selected Areas Communications, 13 (8), 1241{1251.
Korilis, Y. A., Lazar, A. A., & Orda, A. (1997a). Achieving network optima using Stackelberg routing strategies. IEEE/ACM Transactions Networking, 5 (1), 161{173.
Korilis, Y. A., Lazar, A. A., & Orda, A. (1997b). Capacity allocation noncooperative
routing. IEEE Transactions Automatic Control, 42 (3), 309{325.
Korilis, Y. A., Lazar, A. A., & Orda, A. (1999). Avoiding Braess paradox noncooperative networks. Journal Applied Probability, 36, 211{222.
Kumar, S., & Miikkulainen, R. (1997). Dual reinforcement Q-routing: on-line adaptive
routing algorithm. Artificial Neural Networks Engineering, Vol. 7, pp. 231{238.
ASME Press.
Littman, M. L., & Boyan, J. (1993). distributed reinforcement learning scheme network
routing. Proceedings 1993 International Workshop Applications Neural
Networks Telecommunications, pp. 45{51.
Marbach, P., Mihatsch, O., Schulte, M., & Tsisiklis, J. (1998). Reinforcement learning
call admission control routing integrated service networks. Advances
Neural Information Processing Systems - 10, pp. 922{928. MIT Press.
Orda, A., Rom, R., & Shimkin, N. (1993a). Competitive routing multiuse communication
networks. IEEE/ACM Transactions Networking, 1 (5), 510{521.
Orda, A., Rom, R., & Sidi, M. (1993b). Minimum delay routing stochastic networks.
IEEE/ACM Transactions Networking, 1 (2), 187{198.
Sandholm, T., Larson, K., Anderson, M., Shehory, O., & Tohme, F. (1998). Anytime coalition structure generation worst case guarantees. Proceedings Fifteenth
National Conference Artificial Intelligence, pp. 46{53.
Sandholm, T., & Lesser, V. R. (1995). Issues automated negotiations electronic commerce: extending contract net protocol. Proceedings Second International
Conference Multi-Agent Systems, pp. 328{335. AAAI Press.
386

fiCollective Intelligence, Data Routing Braess' Paradox
Schaerf, A., Shoham, Y., & Tennenholtz, M. (1995). Adaptive load balancing: study
multi-agent learning. Journal Artificial Intelligence Research, 162, 475{500.
Shenker, S. J. (1995). Making greed work networks: game-theoretic analysis switch
service disciplines. IEEE Transactions Networking, 3 (6), 819{831.
Stone, P. (2000). TPOT-RL applied network routing. Proceedings Seventeenth
International Machine Learning Conference, pp. 935{942. Morgan Kauffman.
Subramanian, D., Druschel, P., & Chen, J. (1997). Ants reinforcement learning: case
study routing dynamic networks. Proceedings Fifteenth International
Conference Artificial Intelligence, pp. 832{838.
Sutton, R. S. (1988). Learning predict methods temporal differences. Machine
Learning, 3, 9{44.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,
Cambridge, MA.
Sycara, K. (1998). Multiagent systems. AI Magazine, 19 (2), 79{92.
Tumer, K., Agogino, A., & Wolpert, D. (2002). Learning sequences actions collectives
autonomous agents. Proceedings First International Joint Conference
Autonomous Agents Multi-Agent Systems, Bologna, Italy.
Tumer, K., & Wolpert, D. H. (2000). Collective intelligence Braess' paradox.
Proceedings Seventeenth National Conference Artificial Intelligence, pp. 104{
109, Austin, TX.
Watkins, C., & Dayan, P. (1992). Q-learning. Machine Learning, 8 (3/4), 279{292.
Wolpert, D. H., Kirshner, S., Merz, C. J., & Tumer, K. (2000). Adaptivity agent-based
routing data networks. Proceedings fourth International Conference
Autonomous Agents, pp. 396{403.
Wolpert, D. H., Sill, J., & Tumer, K. (2001). Reinforcement learning distributed domains:
Beyond team games. Proceedings Seventeenth International Joint Conference
Artificial Intelligence, pp. 819{824, Seattle, WA.
Wolpert, D. H., & Tumer, K. (1999). Introduction Collective Intelligence. Tech.
rep. NASA-ARC-IC-99-63, NASA Ames Research Center. URL:http://ic.arc.nasa.gov/ic/projects/coin pubs.html. appear Handbook Agent Technology,
Ed. J. M. Bradshaw, AAAI/MIT Press.
Wolpert, D. H., & Tumer, K. (2001). Optimal payoff functions members collectives.
Advances Complex Systems, 4 (2/3), 265{279.
Wolpert, D. H., Tumer, K., & Frank, J. (1999). Using collective intelligence route internet
trac. Advances Neural Information Processing Systems - 11, pp. 952{958. MIT
Press.
Wolpert, D. H., Wheeler, K., & Tumer, K. (2000). Collective intelligence control
distributed dynamical systems. Europhysics Letters, 49 (6).

387


