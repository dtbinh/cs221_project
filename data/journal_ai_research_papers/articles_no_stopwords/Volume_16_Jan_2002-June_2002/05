Journal Artificial Intelligence Research 16 (2002) 209-257

Submitted 5/01; published 4/02

Structured Knowledge Representation Image Retrieval
Eugenio Di Sciascio
Francesco M. Donini
Marina Mongiello

disciascio@poliba.it
donini@poliba.it
mongiello@poliba.it

Dipartimento di Elettrotecnica ed Elettronica, Politecnico di Bari
Via David, 200 70125 BARI Italy

Abstract
propose structured approach problem retrieval images content
present description logic devised semantic indexing retrieval
images containing complex objects.
approaches do, start low-level features extracted image analysis
detect characterize regions image. However, contrast feature-based approaches, provide syntax describe segmented regions basic objects complex
objects compositions basic ones. introduce companion extensional semantics defining reasoning services, retrieval, classification, subsumption.
services used exact approximate matching, using similarity measures.
Using logical approach formal specification, implemented complete clientserver image retrieval system, allows user pose queries sketch queries
example. set experiments carried testbed images assess
retrieval capabilities system comparison expert users ranking. Results
presented adopting well-established measure quality borrowed textual information
retrieval.

1. Introduction
Image retrieval problem selecting, repository images, images fulfilling maximum extent criterion specified end user. paper,
concentrate content-based image retrieval, criteria express properties
appearance image itself, i.e., pictorial characteristics.
research field till concentrated devising suitable techniques
extracting relevant cues aid image analysis algorithms. Current systems result
effective specified properties so-called low-level characteristics, color
distribution, texture. example, systems IBMs QBIC1 easily retrieve,
among others, stamps containing picture brown horse green field, asked
retrieve images stamps brown central area greenish background.
Nevertheless, present systems fail treating correctly high-level characteristics
image as, retrieve stamps galloping horse. First all, systems cannot
even allow user specify queries, lack language expressing highlevel features. Usually, overcome help examples: retrieve images similar
one. However, examples quite ambiguous interpret: features
1. See e.g., http://wwwqbic.almaden.ibm.com/cgi-bin/stamps-demo
c
2002
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiDi Sciascio, Donini & Mongiello

example appear retrieved images? ambiguity produces lot
false positives, one experience.
Even relevant features pointed example, system cannot tell whether
pointed color distribution, interpretation all, galloping
brown horse produces color distribution similar running brown fox
galloping white horse. aspect, image retrieval faces problems object
recognition, central problem robotics artificial vision. effective
solution overcoming problem associate query significant keywords,
match keywords attached way images repository. ambiguities
image understanding transferred text understanding, brown portrait
Crazy Horse famous Indian chief could considered relevant.
Resorting human experts specify expected output retrieval algorithm can,
opinion, worsen ambiguities, since makes correctness approach
depend subjective perception image retrieval system do.
needed formal, high-level specification image retrieval task. need motivates
research report here.
1.1 Contributions Paper
approach problem image retrieval knowledge representation perspective,
particular, refer framework already successfully applied Woods
Schmolze (1992) conceptual modeling semantic data models databases (Calvanese,
Lenzerini, & Nardi, 1998). consider image retrieval knowledge representation
problem, distinguish following aspects:
Interface: user given simple visual language specify (by sketch example)
geometric composition basic shapes, call description. composite shape
description intuitively stands set images (all containing given shapes
relative positions); used either query, index relevant class
images, given meaningful name.
Syntax semantics: system internal syntax represent users
queries descriptions, syntax given extensional semantics terms sets
retrievable images. contrast existing image retrieval systems, semantics
compositional, sense adding details sketch may restrict set
retrievable images. Syntax semantics constitute Semantic Data Model,
relative position, orientation size shape component given explicit notation geometric transformation. extensional semantics allows us define
hierarchy composite shape descriptions, based set containment interpretations descriptions. Coherently, recognition shape description image
defined interpretation satisfying description.
Algorithms complexity: based semantics, prove subsumption
descriptions carried terms recognition. devise exact
approximate algorithms composite shapes recognition image, correct
respect semantics. Ideally, computational complexity problem retrieval
known, algorithms optimal reference computational
complexity problems. Presently, solved problem exact retrieval,
210

fiStructured Knowledge Representation Image Retrieval

propose algorithm approximate retrieval which, although probably non-optimal,
correct.
Experiments: study complexity problem ongoing, syntax,
semantics, sub-optimal algorithms obtained far already sufficient provide
formal specification prototype system experimental verification approach.
prototype used carry set experiments test database images,
allowed us verify effectiveness proposed approach comparison
expert users ranking.
believe knowledge representation approach brings several benefits research
image retrieval. First all, separates problem finding intuitive semantics
query languages image retrieval problem implementing correct algorithm
given semantics. Secondly, problem image retrieval semantically formalized, results techniques Computational Geometry exploited assessing
computational complexity formalized retrieval problem, devising efficient
algorithms, mostly approximate image retrieval problem. much
spirit finite model theory used study complexity query answering relational databases (Chandra & Harel, 1980). Third, language borrows
object modeling Computer Graphics hierarchical organization classes images
(Foley, van Dam, Feiner, & Hughes, 1996). This, addition interpretation composite shapes one immediately visualize, opens logical approach retrieval
images 3D-objects constructed geometric language (Paquet & Rioux, 1998),
still explored. Fourth, logical formalization, although simple, allows extensions
natural logic, disjunction (OR) components. Although alternative
components complex shape difficult shown sketch, could used
specify moving (i.e., non-rigid) parts composite shape. exemplifies
logical approach shed light extensions syntax suitable for, e.g., video sequence
retrieval.
1.2 Outline Paper
rest paper organized follows. next section, review related work
image retrieval. Section 3 describe formal language, first syntax,
semantics, start proving basic properties. following section, analyze
reasoning problems semantic relations among them, devise algorithms
solve them. Section 5 illustrate architecture system
propose examples pointing distinguishing aspects approach. Section 6
present set experiments assess retrieval capabilities system. Last section
draws conclusions proposes directions future work.

2. Related Work
Content-Based Image Retrieval (CBIR) recently become widely investigated research
area. Several systems approaches proposed; briefly report
significant examples categorize three main research directions.
211

fiDi Sciascio, Donini & Mongiello

2.1 Feature-based Approaches
Largest part research CBIR focused low-level features color, texture,
shape, extracted using image processing algorithms used characterize
image feature space subsequent indexing similarity retrieval.
way problem retrieving images homogeneous content substituted
problem retrieving images visually close target one (Hirata & Kato, 1992; Niblak
et al., 1993; Picard & Kabir, 1993; Jacobs, Finkelstein, & Salesin, 1995; Flickner et al.,
1995; Bach, Fuller, Gupta, Hampapur, Horowitz, Humphrey, Jain, & Shu, 1996; Celentano
& Di Sciascio, 1998; Cox, Miller, Minka, & Papathomas, 2000; Gevers & Smeulders, 2000).
Among various projects, particularly interesting QBIC system (Niblak et al.,
1993; Flickner et al., 1995), often cited ancestor CBIR systems,
allows queries performed shape, texture, color, example sketch using
target media images shots within videos. system currently embedded
tool commercial product, Ultimedia Manager. Later versions introduced
automated foreground/background segmentation scheme. indexing image
made principal shape, aid heuristics. evident limitation:
images main shape, objects often composed various parts.
researchers, rather concentrating main shape, typically assumed located central part picture, proposed index regions images;
focus retrieval similar images, similar regions within
image. Examples idea VisualSeek (Smith & Chang, 1996), NETRA (Ma
& Manjunath, 1997) Blobworld (Carson, Thomas, Belongie, Hellerstein, & Malik,
1999). problem although systems index regions, lack higher
level description images. Hence, able describe hence query
single region time image.
order improve retrieval performances, much attention paid recent
years relevance feedback. Relevance feedback mechanism, widely used textual
information systems, allows improving retrieval effectiveness incorporating
user query-retrieval loop. Depending initial query system retrieves set
documents user mark either relevant irrelevant. system, based
user preferences, refines initial query retrieving new set documents
closer users information need.
issue particularly relevant feature-based approaches, one hand, user
lacks language express powerful way information need,
hand, deciding whether image relevant takes glance. Examples systems
using relevance feedback include MARS (Rui, Huang, & Mehrotra, 1997), DrawSearch
(Di Sciascio & Mongiello, 1999) PicHunter (Cox et al., 2000).
2.2 Approaches Based Spatial Constraints
type approach problem image retrieval concentrates finding similarity images terms spatial relations among objects them. Usually emphasis
relative positions objects, considered symbolic images icons,
identified single point 2D-space. Information content visual appearance images normally neglected.
212

fiStructured Knowledge Representation Image Retrieval

Chang, Shi, Yan (1983) present modeling type images terms
2D-strings, strings accounting position icons along one two
planar dimensions. approach retrieval images basically reverts simpler string
matching.
Gudivada Raghavan (1995) consider objects symbolic image associated
vertexes weighted graph. Edges i.e., lines connecting centroids pair
objects represent spatial relationships among objects associated
weight depending slope. symbolic image represented edge list. Given
edge lists query database image, similarity function computes degree
closeness two lists measure matching two spatial-graphs.
similarity measure depends number edges comparison
orientation slope edges two spatial-graphs. algorithm robust
respect scale translation variants sense assigns highest similarity
image scale translation variant query image. extended algorithm
includes rotational variants original images.
recent papers topic include Gudivada (1998) El-Kwae
Kabuka (1999), basically propose extensions strings approach efficient
retrieval subsets icons. Gudivada (1998) defines R-strings, logical representation
image. representation provides geometry-based approach iconic indexing
based spatial relationships iconic objects image individuated
centroid coordinates. Translation, rotation scale variant images variants generated arbitrary composition three geometric transformations considered.
approach deal object shapes, basic image features,
considers sequence names objects. concatenation objects
based euclidean distance domain objects image starting reference
point. similarity database query image obtained spatial
similarity algorithm measures degree similarity query database
image comparing similarity R-strings. algorithm recognizes rotation, scale translation variants image subimages, subsets
domain objects. constraint limiting practical use approach assumption
image contain one instance icon object.
El-Kwae Kabuka (1999) propose extension spatial-graph approach,
includes topological directional constraints. topological extension
objects obviously useful determining differences images
might considered similar directional algorithm considers locations
objects term centroids. similarity algorithm propose extends
graph-matching one previously described Gudivada Raghavan (1995). similarity
two images based three factors: number common objects, directional
topological spatial constraint objects. similarity measure includes
number objects, number common objects function determines
topological difference corresponding objects pairs query database
image. algorithm retains properties original approach, including invariance
scaling, rotation translation able recognize multiple rotation variants.
213

fiDi Sciascio, Donini & Mongiello

2.3 Logic-based Structured Approaches
reference previous work Vision Artificial Intelligence, use structural
descriptions objects recognition images dated back Minskys
frames, work Brooks (1981). idea associate parts object (and
generally scene) regions image segmented into. hierarchical
organization knowledge used recognition object first proposed
Marr (1982). Reiter Mackworth (1989) proposed formalism reason maps
sketched diagrams. approach, possible relative positions lines fixed
highly qualitative (touching, intersecting).
Structured descriptions three-dimensional images already present languages
virtual reality VRML (Hartman & Wernecke, 1996) hierarchical object modeling. However, semantics languages operational, effort made
automatically classify objects respect structure appearance.
Meghini, Sebastiani, Straccia (2001) proposed formalism integrating Description
Logics image text retrieval, Haarslev, Lutz, Moeller (1998) integrate
Description Logics spatial reasoning. extensions approach described
Moeller, Neumann, Wessel (1999). proposals build clean integration
Description Logics concrete domains Baader Hanschke (1991). However, neither
formalisms used build complex shapes nesting simple shapes.
Moreover, proposal Haarslev et al. (1998) based logic spatial relations
named RCC8, enough specifying meaningful relations map,
qualitative specify relative sizes positions regions complex shape.
Hacid Rigotti (1999) description logics concrete domains
basis logical framework image databases aimed reasoning query containment.
Unfortunately, proposed formalism cannot consider geometric transformations neither
determine specific arrangements shapes.
similar approach proposal Ardizzone, Chella, Gaglio (1997),
parts complex shape described description logic. However, composition shapes consider positions, hence reasoning cannot take positions
account.
Relative position parts complex shape expressed constraint relational
calculus work Bertino Catania (1998). However, reasoning queries
(containment emptiness) considered approach. Aiello (2001) proposes
multi-modal logic, provides formalism expressing topological properties
defining distance measure among patterns.
Spatial relation parts medical tomographic images considered Tagare,
Vos, Jaffe, Duncan (1995). There, medical images formed intersection
image plane object. image plane changes, different parts object
considered. Besides, metric arrangements formulated expressing arrangements
terms Voronoi diagram parts. approach limited medical image
databases provide geometrical constraints.
Compositions parts image considered work Sanfeliu Fu
(1983) character recognition. However, recognizing characters, line compositions
closed, sense one looks specified lines, more. Instead
214

fiStructured Knowledge Representation Image Retrieval

framework, shape F composed three lines, subsumed shape something unacceptable recognizing characters. Apart different task, approach
make use extensional semantics composite shapes, hence reasoning
possible.
logic-based multimedia retrieval system proposed Fuhr, Govert, Rolleke
(1998); method, based object-oriented logic, supports aggregated objects
oriented towards high-level semantic indexing, neglects low-level features
characterize images parts them.
field computation theories recognition, mention two approaches
resemblance own: Biedermans structural decomposition geometric constraints proposed Ullman, described Edelmann (1999). Unfortunately, neither
appears suitable realistic image retrieval: structural decomposition approach
consider geometric constraints shapes, approach based geometric constraints consider possibility defining structural decomposition
shapes, hence reasoning them.
Starting reasonable assumption recognition object scene
eased previous knowledge context, work Pirri Finzi (1999),
recognition task, interpretation image, takes advantage information
cognitive agent environment, representation data
high-level formalism.

3. Syntax Semantics
section present formalism dealing definition composite shape descriptions, semantics, properties distinguish approach previous
ones.
remark formalism deals image features, shape, color, texture,
independent way features extracted actual images. interested
reader, algorithms used compute image features implementation
formalism presented Appendix.
3.1 Syntax
main syntactic objects basic shapes, position shapes, composite shape descriptions, transformations. take account features typically
determine visual appearance image, namely color texture.
Basic shapes denoted letter B, edge contour e(B) characterizing
them. assume e(B) described single, closed 2D-curve space whose origin
coincides centroid B. Examples basic shapes circle, rectangle,
contours e(circle) = , e(rectangle) =
, complete, rough contour
e.g., one ship basic shape. make language compositional,
consider external contour region. example, region contained
another, , contour outer region external rectangle.
possible transformations simple ones present drawing tool:
rotation (around centroid shape), scaling translation. globally denote
215

fiDi Sciascio, Donini & Mongiello

Figure 1: graphical interface query sketch.
rotation-translation-scaling transformation . Recall transformations composed sequences 1 . . . n , form mathematical group.
basic building block syntax basic shape component hc, t, , Bi,
represents region color c, texture t, edge contour (e(B)). (e(B))
denote pointwise transformation whole contour B. example, could
specify place contour e(B) upper left corner image, scaled 1/2
rotated 45 degrees clockwise.
Composite shape descriptions conjunctions basic shape components one
color texture denoted
C = hc1 , t1 , 1 , B1 u u hcn , tn , n , Bn
expect end users system actually define composite shapes
syntax; internal representation composite shape. system
maintain user draws help graphic tool complex shape
dragging, rotating scaling basic shapes chosen either palette, existing
images (see Figure 1).
example, composite shape lighted-candle could defined
lighted-candle = hc1 , t1 , 1 , rectanglei u hc2 , t2 , 2 , circlei
216

fiStructured Knowledge Representation Image Retrieval

1 , 2 placing circle flame top candle, textures colors defined
accordingly intuition.
remark that, best knowledge, logic present first one
combining shapes explicit transformations one language.
previous paper (Di Sciascio, Donini, & Mongiello, 2000) presented formalism
including nested composite shapes, done hierarchical object modeling (Foley et al.,
1996, Ch.7). However, nested composite shapes always flattened composing
transformations. Hence paper focus two levels: basic shapes compositions
basic shapes. Also, simplify presentation semantics, following
section present color texture features, take account
Section 4.2 on.
3.2 Semantics
consider extensional semantics, syntactic expressions interpreted
subsets domain. setting, domain interpretation set images ,
shapes components interpreted subsets . Hence, image database
domain interpretation, complex shape C subset domain
images retrieved database C viewed query.
approach quite different previous logical approaches image retrieval
view image database set facts, logical assertions, e.g., one based
Description Logics Meghini et al. (2001). setting, image retrieval amounts
logical inference. However, observe usually Domain Closure Assumption (Reiter,
1980) made image databases: regions ones seen
images themselves. allows one consider problem image retrieval simple
model checking check given structure satisfies description2 .
Formally, interpretation pair (I, ), set images,
mapping shapes components subsets . identify image
set regions {r1 , . . . ,rn } segmented (excluding background, discuss
end section). region r comes edge contour e(r). image
belongs interpretation basic shape component h, BiI contains
region whose contour matches (e(B)). formulae,
h, BiI = {I | r : e(r) = (e(B))}

(1)

definition exact recognition shape components images, due
presence strict equality comparison contours; extended
approximate recognition follows. Recall characteristic function f set
function whose value either 1 0; fS (x) = 1 x S, fS (x) = 0 otherwise. consider
characteristic function set defined Formula (1). Let image;
belongs h, BiI , characteristic function computed value 1, otherwise
value 0. keep number symbols low, use expression h, BiI
2. Obviously, Domain Closure Assumption regions valid artificial vision, dealing twodimensional images three-dimensional shapes (and scenes), solid shapes surfaces
hidden images. outside scope retrieval problem.

217

fiDi Sciascio, Donini & Mongiello

denote characteristic function (with argument (I) distinguish set).


h, Bi (I) =

(

1 r : e(r) = (e(B))
0
otherwise

reformulate function order make return real number range [0, 1]
usual fuzzy logic (Zadeh, 1965). Let sim(, ) similarity measure pairs
contours range [0, 1] real numbers (where 1 perfect matching). use sim(, )
instead equality compare edge contours. Moreover, existential quantification
replaced maximum possible regions I. Then, characteristic function
approximate recognition image basic component, is:
h, BiI (I) = max{sim(e(r), (e(B)))}
rI

Note sim depends translations, rotation scaling, since looking regions
whose contour matches e(B), reference position size specified .
interpretation basic shapes, instead, includes translation-rotation-scaling invariant recognition, commonly used single-shape Image Retrieval. define
interpretation basic shape
B = {I | r : e(r) = (e(B))}
approximate counterpart function
B (I) = max max{sim(e(r), (e(B)))}


rI

maximization possible transformations max effectively computed
using similarity measure simss invariant reference translation-rotationscaling (see Section 4.2). Similarity color texture added weighted sum
Section 4.2. way, basic shape B used query retrieve images
B . Therefore, approach generalizes usual approaches
single-shape retrieval, Blobworld (Carson et al., 1999).
Composite shape descriptions interpreted sets images contain components composite shape. Components anywhere image, long
described arrangement relative other. Let C composite shape
description h1 , B1 u u hn , Bn i. exact matching, interpretation intersection
sets interpreting component shape:
C = {I | : ni=1 h( ), Bi iI }

(2)

Observe require shape components C transformed image regions
using transformation . preserves arrangement shape components
relative given allowing C include every image
containing group regions right arrangement, wholly displaced .
clarify formula, consider Figure 2: shape C composed two basic shapes
B1 B2 , suitably arranged transformations 1 2 . Suppose
contains image I. Then, C exists transformation ,
218

fiStructured Knowledge Representation Image Retrieval

Figure 2: example application Formula (2).
globally brings C I, is, 1 brings rectangle B1 rectangle recognized
I, 2 brings circle B2 circle recognized I, arranged according
C. Note could contain shapes, included C.
formally define recognition shape image.
Definition 1 (Recognition) shape description C recognized image
every interpretation (I, ) , C . interpretation (I, ) satisfies
composite shape description C exists image C recognized
I. composite shape description satisfiable exists interpretation satisfying it.
Observe shape descriptions could unsatisfiable: two components define overlapping
regions, image segmented way satisfies components. course,
composite shape descriptions built using graphical tool, unsatisfiability easily
avoided, assume descriptions always satisfiable. Anyway, unsatisfiable shape
descriptions could easily detected, syntactic form, since unsatisfiability
arise overlapping regions (see Proposition 4).
Observe set-based semantics implies intuitive interpretation conjunction u one could easily prove u commutative idempotent.
approximate matching, modify definition (2), following fuzzy interpretation
u minimum, existential maximum:
n

C (I) = max {min {h( ), Bi iI (I)}}


i=1

(3)

Observe interpretation composite shape descriptions strictly requires presence components. fact, measure image belongs interpreta219

fiDi Sciascio, Donini & Mongiello

tion composite shape description C dominated least similar shape component
(the one minimum similarity). Hence, basic shape component dissimilar
every region I, brings near 03 measure C (I). strict
than, e.g., Gudivada & Raghavans (1995) El-Kwae & Kabukas (1999) approaches,
non-appearing component decrease similarity value C (I),
still threshold.
Although requirement may seem strict one, captures way details used
refine query: dominant shapes used first, and, retrieved set still
large, user adds details restrict results. refinement process,
happen images match new details, pop enlarging set
results user trying restrict. formalize refinement process
following definition.
Proposition 1 (Downward refinement) Let C composite shape description,
.
let refinement C, = C u h 0 , B 0 i. every interpretation I, shapes
interpreted (2), C ; shapes interpreted (3), every
image holds (I) C (I).
Proof. (2), claim follows fact considers intersection
components one C , plus set h( 0 ), B 0 iI . (3), claim analogously
follows fact (I) computes minimum superset values considered C (I).

property makes language fully compositional. Namely, let C composite shape description; consider meaning C used query
set images potentially retrieved using C. least, meaning perceived end user system. Downward refinement ensures meaning
C obtained starting one component, progressively adding
components order. remark frameworks cited (Gudivada &
Raghavan, 1995; El-Kwae & Kabuka, 1999) property hold. illustrate
problem Figure 3. Starting shape description C, may retrieve (among many
others) two images I1 , I2 , C (I1 ) C (I2 ) threshold t,
another image I3 set C (I3 ) < t. order selective, try adding details, obtain shape description D. Using D, may still
retrieve I2 , discard I1 . However, I3 partially matches new details D.
Downward refinement holds, (I3 ) C (I3 ) < t, I3 cannot pop up. contrast,
Downward refinement hold (as Gudivada & Raghavans approach)
DI (I3 ) > > C (I3 ) matched details raise similarity sum weighted
components. case, meaning sketch cannot defined terms
components.
Downward refinement property linking syntax semantics. Thanks extensional semantics, extended even meaningful semantic relation, namely,
3. exactly 0, since every shape matches every one low similarity measure. Similarity
often computed inverse distance. Similarity 0 would correspond infinite distance.
Nevertheless, recognition algorithm force similarity 0 threshold.

220

fiStructured Knowledge Representation Image Retrieval

Figure 3: Downward refinement: thin arrows denote non-zero similarity approximate
recognition. thick arrow denotes refinement.

221

fiDi Sciascio, Donini & Mongiello

Figure 4: example subsumption hierarchy shapes (thick arrows), images
shapes recognized (thin arrows).

subsumption. borrow definition Description Logics (Donini, Lenzerini, Nardi,
& Schaerf, 1996), fuzzy extensions (Yen, 1991; Straccia, 2001).
Definition 2 (Subsumption) description C subsumes description every
interpretation I, C . (3) used, C subsumes every interpretation
image , (I) C (I).
Subsumption takes account fact description might contain syntactic variant
another, without user system explicitly knowing fact. notion
subsumption extends downward refinement. enables hierarchy shape descriptions, description another C subsumed C. C
used queries, subsumption hierarchy makes easy detect query containment.
Containment used speed retrieval: images retrieved using query
immediately retrieved C used query, without recomputing similarities.
query containment important standard databases (Ullman, 1988), becomes
even important image retrieval setting, since recognition specific features
image computationally demanding.
Figure 4 illustrates example subsumption hierarchy basic composite shapes
(thick arrows denote subsumption shapes), two images shapes
recognized (thin arrows).
Although consider background, could added framework
special basic component hc, t, , backgroundi property region b satisfies
222

fiStructured Knowledge Representation Image Retrieval

background simply colors textures match, check edge contours.
Also, one background could added; case background regions
overlap, matching background regions considered regions
basic shapes recognized subtracted background regions.

4. Reasoning Retrieval
envisage several reasoning services carried logic image retrieval:
1. shape recognition: Given image shape description D, decide recognized I.
2. image retrieval: given database images shape description D, retrieve
images recognized.
3. image classification: given image collection descriptions 1 , . . . , Dn , find
descriptions recognized I. practice, classified finding
specific descriptions (with reference subsumption) satisfies. Observe
classification way preprocessing recognition.
4. description subsumption (and classification): given (new) description collection descriptions D1 , . . . , Dn , decide whether subsumes (or subsumed by)
Di , = 1, . . . , n.
services 12 standard image retrieval system, services 34 less obvious,
briefly discuss below.
process image retrieval quite expensive, systems usually perform off-line
processing data, amortizing cost several queries answered on-line.
example, document retrieval systems web4 , images text, use spiders
crawl web extract relevant features (e.g., color distributions textures
images, keywords texts), used classify documents. Then, answering
process uses classified, extracted features documents original data.
system adapt setting composite shapes, too. system, new
image inserted database immediately segmented classified accordance
basic shapes compose it, composite descriptions satisfies (Service 3).
query undergoes classification, reference queries already answered
(Service 4). basic shapes present, faster system answer new
queries based shapes.
formally, given query (shape description) D, exists collection descriptions D1 , . . . , Dn images database already classified reference
D1 , . . . , Dn , may suffice classify reference D1 , . . . , Dn find (most
of) images satisfying D. usual way classification Description
Logics amounts semantic indexing help query answering (Nebel, 1990).
example, answer query asking images containing arch, system may
classify arch find subsumes threePortalsGate (see Figure 4). Then, system
4. e.g., Altavista, QBIC, NETRA, Blobworld, Yahoo (for textual documents).

223

fiDi Sciascio, Donini & Mongiello

include answer images ancient Roman gates recognized,
without recomputing whether images contain arch not.
problem computing subsumption descriptions reduced recognition
next section, algorithm exact recognition given. Then, extend
algorithm realistic approximate recognition, reconsidering color texture.
4.1 Exact Reasoning Images Descriptions
start reformulation (2), suited computational purposes.
Theorem 2 (Recognition mapping) Let C = h1 , B1 u u hn , Bn composite
shape description, let image, segmented regions {r 1 , . . . ,rm }. C
recognized iff exists transformation injective mapping j : {1, . . . , n}
{1, . . . , m} = 1, . . . , n
e(rj(i) ) = (i (e(Bi )))
Proof. (2), C recognized iff
[I

n
\

h( ), Bi iI ] equivalent [

i=1

n
^

h( ), Bi iI ]

i=1

Expanding h( ), Bi iI definition (1) yields
[

n
^

r I.e(r) = (i (e(Bi )))]

i=1

since regions {r1 , . . . ,rm } equivalent
[


n _
^

e(rj ) = (i (e(Bi )))]

i=1 j=1

Making explicit disjunction j conjunctions i, arrange conjunctive formula matrix:




(e(r1 ) = (1 (e(B1 ))) e(rm ) = (1 (e(B1 )))) )


..
.
..

.

.
..
(e(r1 ) = (n (e(Bn ))) e(rm ) = (n (e(Bn )))) )

(4)

note two properties matrix equalities:
1. given transformation, one region among r1 , . . . ,rm equal
component. means row, one disjunct true given
.
2. given transformation, region match one component. means
column, one equality true given .
224

fiStructured Knowledge Representation Image Retrieval

observe properties imply regions different shapes, since
equality contours depends translation, rotation, scaling. use equality
represent true overlap, equal shape.
Properties 12 imply formula true iff injective function
mapping component one region matches with. ease comparison
formulae use symbol j mapping j : {1, . . . , n} {1, . . . , m}. Hence,
Formula (4) rewritten claim:
[j : {1..n} {1..m}

n
^

e(rj(i) ) = (i (e(Bi )))]

(5)

i=1

Hence, even previous section semantics composite shape derived
semantics components, computing whether image contains composite shape
one focus groups regions, one group rj(1) , . . . , rj(n) possible mapping j.
Observe j injective implies n, one would expect. proposition
leaves open one j must chosen first. fact, follows
show optimal choice exact recognition mix decisions j .
approximate recognition considered, however, exchanging quantifiers harmless.
fact, change order approximations made. return
issue next section, discuss one devise algorithms approximate
recognition.
Subsumption simple logic shape descriptions relies composition
contours basic shapes. Intuitively, actually decide subsumed C, check
sketch associated seen image would retrieved using C
query. logical perspective, existentially quantified regions semantics
shape descriptions (1) skolemized prototypical contours. Formal definitions
follow.
Definition 3 (Prototypical image) Let B basic shape. prototypical image
I(B) = {e(B)}. Let C = h1 , B1 u u hn , Bn composite shape description.
prototypical image I(C) = {1 (e(B1 )), . . . , n (e(Bn ))}.
practice, composite shape description one builds prototypical image applying stated transformations components (and color/texture fillings, present).
Recall envisage prototypical image built directly user,
help drawing tool, basic shapes colors palette items. system
keep track transformations corresponding users actions, use
building (internal) shape descriptions stored previous syntax. feature
makes proposal different query-by-sketch retrieval systems, precisely
sketches logical meaning. So, properties description/sketches
proved, containment query sketches stated formal way, algorithms
containment checking proved correct reference semantics.
Prototypical images important properties. first satisfy (in
sense Definition 1) shape description exemplify intuition would suggest.
225

fiDi Sciascio, Donini & Mongiello

Proposition 3 every composite shape description D, satisfiable interpretation hI, {I(D)}i satisfies D.
Proof. Theorem 2, using identical transformation identity mapping
j.

shape description satisfiable overlapping regions I(D). Since
obvious specified drawing tool, give following proposition
sake completeness.
Proposition 4 shape description satisfiable iff prototypical image I(D) contains
overlapping regions.
turn subsumption. Observe B1 B2 basic shapes, either
equivalent (each one subsumes other) neither two subsumes other.
adopt segmented regions invariant representation, (e.g. Fourier transforms
contour) deciding equivalence basic shapes, recognizing whether basic shape
appears image, call algorithm computing similarity shapes.
usual image recognizers allowing tolerance matching
shapes. Therefore, framework extends retrieval shapes made single
component, effective systems already available.
consider composite shape descriptions, prove main property prototypical images, namely, fact subsumption shape descriptions
decided checking subsumer recognized sketch subsumee.
Theorem 5 composite shape description C subsumes description C
recognized prototypical image I(D).
Proof. Let C = h1 , B1 u u hn , Bn i, let = h1 , A1 u u hm , i. Recall
I(D) defined I(D) = {1 (e(A1 )), . . . , (e(Am ))}. ease reading, sketch
idea proof Figure 5.
If. Suppose C recognized I(D), is, I(D) C every interpretation (I, )
I(D) . Then, Theorem 2 exists transformation suitable
injective function j {1, . . . , n} {1, . . . , m}
e(rj(k) ) = k (e(Bk ))

k = 1, . . . , n

Since I(D) prototypical image D, substitute region basic
shape comes from:
j(k) (e(Aj(k) )) = k (e(Bk ))

k = 1, . . . , n

(6)

suppose recognized image J = {s1 , . . . ,sp }, J . prove
C recognized J. fact, recognized J exists transformation
another injective mapping q {1, . . . , m} {1, . . . , p} selecting J regions
{sq(1) , . . . , sq(m) }
e(sq(h) ) = h (e(Ah ))
226

h = 1, . . . ,

(7)

fiStructured Knowledge Representation Image Retrieval

(prototypical image of) C





































































prototypical image I(D)



image J
Figure 5: sketch If-proof Theorem 5
composing q j is, selecting regions J satisfying components
used recognize C one obtains
e(sq(j(k)) ) = j(k) (e(Aj(k) ))

k = 1, . . . , n

(8)

Then, substituting equals equals (6), one finally gets
e(sq(j(k)) ) = k (e(Bk ))

k = 1, . . . , n

proves C recognized J, using transformation components,
q(j()) injective mapping {1, . . . , n} {1, . . . , p}. Since J generic image,
follows C . Since (I, ) generic too, C subsumes D.
if. reverse direction easier: suppose C subsumes D. definition,
amounts C every collection images I. every contains I(D),
I(D) Proposition 3. Therefore, I(D) C , is, C recognized I(D).

property allows us compute subsumption recognition, concentrate
complex shape recognition, using Theorem 2. concern decide whether
exists transformation matching j properties stated Theorem 2.
turns exact recognition, quadratic upper bound attained
possible transformations try.

227

fiDi Sciascio, Donini & Mongiello

Theorem 6 Let C = h1 , B1 u u hn , Bn composite shape description, let
image, segmented regions {r1 , . . . ,rm }. Then, m(m 1) exact
matches n basic shapes regions. Moreover, possible match
verified checking matching n pairs contours.
Proof. transformation matching exactly basic components regions
exact match centroids. Hence concentrate centroids. correspondence
centroid basic component centroid region yields two constraints
. rigid motion scaling, hence four degrees freedom (two
degrees translations, one rotation, one uniform scaling). Hence, exact
match exists centroids basic components centroids
regions, completely determined transformation two centroids
basic shapes two centroids regions.
Fixing pair basic components B1 , B2 , let p1 , p2 denote centroids. Also,
let rj(1) , rj(2) regions correspond B1 , B2 , let vj(1) , vj(2) , denote
centroids. one transformation solving point equations (each one mapping
point another)
(
(1 (p1 )) = vj(1)
(2 (p2 )) = vj(2)
Hence, m(m 1) transformations. second claim,
matching centroids found, one checks edge contours basic components
regions coincide, i.e., (1 (e(B1 ))) = e(rj(1) ), (2 (e(B2 ))) = e(rj(2) ),
k = 3, . . . , n (k (e(Bk )) coincides contour region e(rj(k) ).
Recalling Formula (5) proof Theorem 2, means eliminate
outer quantifier (5) using computed , conclude C recognized iff:
j : {1..n} {1..m}

n
^

e(rj(i) ) = (i (e(Bi )))

i=1

Observe that, prune search, found above, one
check k = 3, . . . , n (k (centr(Bk ))) coincides centroid region rj ,
checking contours.
Based Theorem 6, devise following algorithm:
Algorithm Recognize (C,I);
input composite shape description C = h1 , B1 u u hn , Bn i,
image I, segmented regions r1 , . . . ,rm
output True C recognized I, False otherwise
begin
(1) compute centroids v1 , . . . ,vm r1 , . . . ,rm
(2) compute centroids p1 , . . . ,pn components C
(3) i, h {1, . . . , m} < h
compute transformation (p1 ) = vi (p2 ) = vh ;
228

fiStructured Knowledge Representation Image Retrieval

every k {1, . . . , n}
(k (e(Bk ))) coincides (for j) region rj
return True
endfor
return False
end
correctness Recognize (C,I) follows directly Theorems 2 6. Regarding
time complexity, step (1) requires compute centroids segmented regions. Several
methods computing centroids well known literature (Jahne, Haubecker, &
Geibler, 1999). Hence, abstract detail, assume exists function
f (Nh , Nv ) bounds complexity computing one centroid, Nh , Nv
horizontal vertical dimensions (number pixels). report Appendix
compute centroids, concentrate complexity terms n, m, f (N h , Nv ).
Theorem 7 Let C = h1 , B1 u u hn , Bn composite shape description, let
image Nh Nv pixels, segmented regions {r1 , . . . ,rm }. Moreover, let f (Nh , Nv )
function bounding complexity computing centroid one region. C
recognized time O(m f (Nh , Nv ) + n + m2 n Nh Nv ).
Proof. assumptions, Step (1) performed time O(mf (Nh , Nv )). Instead,
Step (2) accomplished extracting n translation vectors transformations 1 , . . . ,n components C. Therefore, requires O(n) time. Finally,
innermost check Step (3) checking whether transformed basic shape region
coincide performed O(Nh Nv ), using suitable marking pixels
region belong to. Hence, obtain claim.

Since subsumption two shape descriptions C reduced recognizing C I(D), upper bound holds checking subsumption composite
shape descriptions, simplification Step (1) accomplished without
feature-level image processing.
4.2 Approximate Recognition
algorithm proposed previous section assumes exact recognition. Since
target retrieval real images, approximate recognition needed. start reconsidering proof Theorem 2, particular matrix equalities (4). Using
semantics approximate recognition (3), expanded formula evaluating C (I)
becomes following:

max min




max{sim(e(r1 ), (1 (e(B1 )))),



..
.
max{sim(e(r1 ), (n (e(Bn ))),



. . . , sim(e(rm ), (1 (e(B1 ))))) }

..
..
.
.
...,

sim(e(rm ), (n (e(Bn ))))

}




Properties 12 stated exact recognition reformulated hypotheses
sim, follows.
229

fiDi Sciascio, Donini & Mongiello

1. given transformation, assume one region among r 1 , . . . ,rm
maximally similar component. assumption justified supposing
negation: two regions maximally similar component,
maximal value low one, lowering overall value
external minimization. means maximizing row, assume
maximal value given one index among 1, . . . , m.
2. given transformation, assume region yield maximal similarity
one component. Again, rationale assumption region
yields maximal similarity two components two different rows, value
low one, propagates along overall minimum. means
minimizing maxima rows, consider different region row.
remark approximate case assumptions imply regions
different shapes, since sim similarity measure 1 true overlap,
equal shapes different pose. assumptions state sim
function near plain equality.
assumptions imply focus injective mappings {1..n}
{1..m} approximate recognition, yielding formula
max


n

min{sim(e(rj(i) ), (i (e(Bi ))))}

max

j:{1..n}{1..m} i=1

choices j two maxima independent, hence consider groups
regions first:
max

n

j:{1..n}{1..m}

max min{sim(e(rj(i) ), (i (e(Bi ))))}


i=1

(9)

Differently exact recognition, choice injective mapping j directly
lead transformation , since depends similarity transformed shapes
computed, is, choice depends sim.
giving definition sim, reconsider image features (color, texture)
skipped theoretical part ease presentation semantics. introduce weighted sums similarity measure, weights set user according
importance features recognition.
Let sim(r, hc, t, , Bi) similarity measure takes region r (with color c(r)
texture t(r)) component hc, t, , Bi range [0, 1] real numbers (where 1
perfect matching). note color texture similarities depend transformations, hence introduction change Assumptions 12 above. Accordingly,
Formula (9) becomes
max

j:{1..n}{1..m}

n

max min{sim(rj(i) , hc, t, ( ), Bi i)}


i=1

(10)

formula suggests groups regions image might resemble
components, select groups present higher similarity. artificially
constructed examples shapes C resemble other, may generate
exponential number groups tested. However, assume realistic
230

fiStructured Knowledge Representation Image Retrieval

images similarity shapes selective enough yield small number
possible groups try. recall Gudivadas approach (Gudivada, 1998)
even stricter assumption made, namely, basic component C appear
twice, region matches one component C. Hence approach
extends Gudivadas one, aspect besides fact consider shape,
scale, rotation, color texture component.
spite assumptions made, finding algorithm computing best
Formula (10) proved us difficult task. problem continuous
spectrum searched, best may unique. observed
single points matched instead regions components
problem simplifies Point Pattern Matching Computational Geometry. However, even
recent results research area complete, cannot directly applied
problem. Cardoze Schulman (1998) solve nearly-exact point matching
efficient randomized methods, without scaling. observe best match
difficult problem nearly-exact match. Chew, Goodrich, Huttenlocher,
Kedem, Kleinberg, Kravets (1997) propose method best match shapes,
analyze rigid motions without scaling.
Therefore, adopt heuristics evaluate formula. First all,
decompose sim(r, hc, t, , Bi) sum six weighted contributions.
Three contributions independent pose: color, texture shape. values color texture similarity denoted simcolor (c(r), c) simtexture (t(r), t),
respectively. Similarity shapes (rotation-translation-scale invariant) denoted
simshape (e(r), e(B)). feature, pair (region, component) compute
similarity measure explained Appendix. Then, assign similarities
feature say, color worst similarity group. yields pessimistic estimate
Formula (10); however, estimate Downward Refinement property holds (see
next Theorem 8).
three contributions depend pose, try evaluate pose
region selected group similar pose specified corresponding
component sketch. particular, simscale (e(r), (e(B)) represents similar scale
region transformed component, simrotation (e(r), (e(B)) denotes
e(r) (e(B) similarly (or not) rotated reference arrangement
components. Finally, simspatial (e(r), (e(B)) denotes measure coincident
centroids region transformed component.
summary, get following form overall similarity region
component:
sim(r, hc, t, , Bi) = simspatial (e(r), (e(B)) +
simshape (e(r), e(B)) +
simcolor (c(r), c) +
simrotation (e(r), (e(B)) +
simscale (e(r), (e(B)) +
simtexture (t(r), t)
231

fiDi Sciascio, Donini & Mongiello

coefficients , , , , , weight relevance feature overall similarity
computation. Obviously, impose + + + + + = 1, coefficients greater
equal 0. actual values given coefficients implemented system
reported Table 2 Section 6.
difficulties computing best , compute maximum
possible s. Instead, evaluate whether rigid transformation scaling
1 (e(B1 )), . . . , n (e(Bn )) rj(1) , . . . , rj(n) , similarities simspatial , simscale ,
simrotation . transformation iff similarities 1. not, lower
similarities are, less rigid transformation match components
regions. Hence, instead Formula (10) evaluate following simpler formula:
max

n

min{sim(rj(i) , hc, t, , Bi i)}

j:{1..n}{1..m} i=1

(11)

interpreting pose similarities different way. describe detail estimate
pose similarities.
Let C = hc1 , t1 , 1 , B1 i) u u hcn , tn , n , Bn i), let j injective function
{1..n} {1..m}, matches components regions {rj(1) , . . . , rj(n) } respectively.
4.2.1 Spatial Similarity
given component say, component 1 compute angles
components seen 1. Formally, let i1h
c counter-clockwise-oriented angle
vertex centroid component 1, formed lines linking centroid
centroids component h. n(n 1)/2 angles.
Then, compute correspondent angles region rj(1) , namely, angles j(i)j(1)j(h)

vertex centroid rj(1) , formed lines linking centroid
centroids regions rj(i) rj(h) respectively. pictorial representation angles
given Figure 6.
let difference spatial (e(rj(1) ), 1 (e(B1 )) maximal absolute difference
correspondent angles:
spatial (e(rj(1) ), 1 (e(B1 )) =

max

i,h=2,...,n,i6=h

|}
{|i1h

c j(i)j(1)j(h)

compute analogous measure components 2,. . . ,n, select maximum
differences:
n

spatial [j] = max{spatial (e(rj(i) ), (e(Bi ))}
i=1

(12)

argument j highlights fact measure depends mapping
j. Finally, transform maximal difference perfect matching yields 0
minimal similarity perfect matching yields 1 help function described Appendix. minimal similarity assigned every
simspatial (e(rj(i) ), (e(Bi )), = 1, . . . , n.
Intuitively, estimate measures difference arrangement centroids
composite shape group regions. exists transformation bringing
components regions exactly, every difference 0, simspatial raises 1 every
232

fiStructured Knowledge Representation Image Retrieval

f2

214

f3

f2

213

f1

f1

f3

215

f2

314

f1

f3

315

f4

415

f4

f4

f5

f5

R2

R3

f5

R2

R3

R2

R3

215
214
213
315

R1
R4

314

R4

R5

R1

R1
R4

R5

415

R5

Figure 6: Representation angles used computing spatial similarity component 1
region rj(1) .

233

fiDi Sciascio, Donini & Mongiello

R1

f1

51u

51h
41h
31h
21h

f2

u

R2

h

41u

31u

F5

21u

R5
R3

f3
R4

f4

Figure 7: Representation angles used computing rotation similarity component 1
region rj(1) .

component. arrangement scattered reference arrangement,
higher maximum difference. reason use maximum differences
similarity pair component-region clear prove later
measure obeys Downward Refinement property.
4.2.2 Rotation Similarity
every basic shape one imagine unit vector origin centroid oriented
horizontally right (as seen palette). shape used component
say, component 1 vector rotated according 1 . Let ~h denote
rotated vector. = 2, . . . , n let c~ counter-clockwise-oriented angle vertex
i1h
centroid component 1, formed ~h line linking centroid component

1 centroid component i.
region rj(1) , analogous ~u ~h constructed finding rotation phase
cross-correlation attains maximum value (see Appendix). Then, = 2, . . . , n
let j(i)j(1)~
u line
u angles vertex centroid rj(1) , formed ~
linking centroid rj(1) centroid rj(i) . Figure 7 clarifies angles
computing.
let difference rotation (e(rj(1) ), 1 (e(B1 )) maximal absolute difference
correspondent angles:
rotation (e(rj(1) ), 1 (e(B1 )) = max {| c~ j(i)j(1)~
u |}
i=2,...,n
i1h

one orientation rj(1) cross-correlation yields maximum
e.g., square four orientations compute maximal difference
orientations, take best difference (the minimal one).
234

fiStructured Knowledge Representation Image Retrieval



mi

Ri

Mi

Dj
dj
Rj
fj

Figure 8: Sizes distances scale similarity computation component 1 region
rj(1) .

repeat process components 2 n, select maximum
differences:
n

rotation [j] = max{rotation (e(rj(i) ), (e(Bi ))}
i=1

(13)

Finally, spatial similarity, transform rotation [j] minimal similarity
help . minimal similarity assigned every simrotation (e(rj(i) ), (e(Bi )),
= 1, . . . , n.
Observe differences drop 0 perfect match, hence
similarity raises 1. region rotated reference
regions match component, higher rotational differences. Again, fact
use worst difference compute rotational similarities exploited
proof Downward Refinement.
4.2.3 Scale Similarity
concentrate component 1 ease presentation. Let 1 size
component 1, computed mean distance centroid points contour.
Moreover, = 2, . . . , n, let d1i distance centroid component 1
centroid component i. image, let Mj(1) size region rj(i) , let
Dj(1)j(i) distance centroids regions j(1) j(i). Figure 8 pictures
quantities computing.
define difference scale e(rj(1) ) 1 (e(B1 ) as:
)
(

min{Mj(1) /Dj(1)j(i) , m1 /d1i }

scale (e(rj(1) ), 1 (e(B1 )) = max 1

i=2,...,n
max{Mj(1) /Dj(1)j(i) , m1 /d1i }
235

fiDi Sciascio, Donini & Mongiello

repeat process components 2 n, select maximum differences:
n

scale [j] = max{scale (e(rj(i) ), (e(Bi ))}
i=1

(14)

Finally, similarities, transform scale [j] minimal similarity
help . minimal similarity assigned every simscale (e(rj(i) ), (e(Bi )),
= 1, . . . , n.
4.2.4 Discussion Pose Similarities
Using worst difference evaluating pose similarities components may appear
somewhat drastic choice. However, guided choice goal preserving
Downward Refinement property, even abandon exact recognition
previous section.
Theorem 8 Let C composite shape description, let refinement C,
.
is, = C uhc0 , t0 , 0 , B 0 i. every image I, segmented regions r1 , . . . ,rm , C (I)
DI (I) computed (11) using similarities defined above, holds (I) C (I).
Proof. Every injective function j used map components C extended
function j 0 letting j 0 (n + 1) {1, . . . , m} suitable region index range
j. Since (I) computed extended mappings, sufficient show
values computed Formula (11) increase reference values computed
C.
Let j1 mapping maximum value C (I) reached. Every extension

j10 j1 leads minimum value minn+1
i=1 Formula (11) lower C (I). fact,
pose differences (12), (13), (14), computed maximums strictly greater set
values, hence pose similarities either value, lower one. Regarding
color, texture, shape similarities, adding another component worsen values
components C, since assign components worst similarity group.
consider another injective mapping j2 yields non-maximum value v2 < C (I)
Formula (11). Using argument pose differences (12), (13), (14), every
extension j20 leads minimum value v20 v2 . Since v2 < C (I), every extension
every mapping j different j1 yields value less C (I). completes
proof.

5. Prototype System
order substantiate ideas developed prototype system, written C++.
system client-server application working MS-Windows environment.
client side avails graphical user interface allows one carry
operations necessary query knowledge base, including canvas query sketch
composition using basic shapes module query example using new existing
images queries. client allows user insert new shape descriptions images
knowledge base. client logical structure shown Figure 9. made
three main modules: sketch, communication configuration.
236

fiStructured Knowledge Representation Image Retrieval

Figure 9: Architecture prototype system.

237

fiDi Sciascio, Donini & Mongiello

Figure 10: process reclassification images new description inserted: a)
insertion description (No. 9); b) insertion.

communication module manages communication server side, using
simple application-level protocol. configuration module allows one modify
parameters relative preview images shapes transferred server
placed cache managed FCFS policy efficient display. sketch module
allows user trace basic shapes palette items, properly insert modify
varying scale rotation factor. available shapes may basic ones
ellipse, circle, rectangle, polygons obtained composing basic shapes complex
shapes defined previous sessions application inserted knowledge
base, shapes extracted segmented images.
system keeps track transformations corresponding users actions,
uses building (internal) shape descriptions stored previously described
syntax. color texture drawn shapes set according user requirements, client interface provides color palette possibility open images
JPEG format texture content. user load images local disk
transmit server populate knowledge base. Finally, user define
new objects endowing textual description insert knowledge
base.
server side, shown Figure 9, composed concurrent threads
manage server-side graphical interface, connections communications
client applications carry processing required client side. Obviously,
238

fiStructured Knowledge Representation Image Retrieval

Figure 11: query retrieved set images.

239

fiDi Sciascio, Donini & Mongiello

server carries tasks related insertion images knowledge base,
including segmentation, feature extraction region indexing, allows one properly
set various parameters involved. end, server three main subcomponents:
1. image features extractor contains image segmentation module region
data extraction one;
2. image classifier composed classifier module module used
image reclassification;
3. database management system.
feature extractor segments processes images extract relevant features
detected region, characterize images knowledge base. Image segmentation carried algorithm starts extraction relevant edges
carries region growing procedure basically merges smaller regions larger
ones according similarity terms color texture. Detected regions obviously
comply minimal heuristics. region associated description
relevant features.
classifier manages graph used represent hierarchically organizes
shape descriptions: basic shapes, complex ones obtained combining elementary shapes and/or applying transformations (rotation, scaling translation).
basic shapes parents, top hierarchy. Images,
inserted knowledge base segmentation process, linked descriptions
structure depending specific descriptions able satisfy.
classifier module invoked new description inserted
system new query posed. classifier carries search process hierarchy
find exact position new description (a simple complex one)
inserted: position determined considering descriptions new description
subsumed by. position found, image reclassifier compares
images available database determine satisfy it; images
verify recognition algorithm tied D. stage considers images
tied descriptions direct ancestors D, outlined Figure 10.
usual Description Logics, query process consists description insertion,
query Q new description treated prototypical images: query
Q system considered new description added hierarchical data
structure; images connected either Q descriptions query
hierarchical structure returned retrieved images.
database management module simply keeps track images and/or pointers
images.
Using system straightforward task. logon user draw sketch
canvas combining available basic shapes, enrich query color texture
content. query posed server obtain images ranked according
similarity. Figure 11 shows query sketch two circles retrieved
set. system correctly retrieves pictures cars two circles recognized
relative positions sketch represent wheels, snow man
black buttons.
240

fiStructured Knowledge Representation Image Retrieval

Figure 12: Downward refinement (contd.): detailed query, picturing car,
retrieved set images.

241

fiDi Sciascio, Donini & Mongiello

Figure 13: Subsumption example: increasing number objects query leads
correct reduction retrieved set.
242

fiStructured Knowledge Representation Image Retrieval

introduction details restricts retrieved set: adding chassis
previous sketch makes query precise, well retrieval results, shown
Figure 12. example points expect user use system. He/she
start generic query objects. number images retrieved set
still large, he/she increase number details obtaining downward refinement.
Notice presence regions/objects included query obviously accepted lack region explicitly introduced query. idea
underlying approach enormous amount available images,
current stage research technology system always ensure complete recognition; yet believe focus reducing false positives, accepting without
much concern higher ratio false negatives. basically means increasing precision,
even cost possibly lower recall. words believe preferable
user looking image containing yellow car, e.g., using sketch Figure 12,
he/she receives result query limited subset images containing almost sure
yellow car, large amount images containing cars, several images
cars all.
Subsumption another distinguishing feature system. Figure 13 shows queries
composed basic shapes obtained segmentation image picturing
aircrafts, i.e., aircraft basic shape system. Here, better emphasize
example, shape position contribute similarity value. process
subsumption clearly highlighted: query single aircraft retrieves images
one aircraft, one aircraft. Adding aircrafts graphical
query correctly reduces retrieved set. example points system
able correctly deal presence one instance object images,
possible approaches Gudivada Raghavan (1995) Gudivada
(1998). negative side noticed system recognize
presence third aircraft (indeed strange one, B2-Spirit) second image
Figure 13-b), segmented considered part background.
ability system retrieve complex objects images several
different objects, main shapes, anyway seen Figure 14.
real image directly submitted query. Notice case system carry
segmentation process fly, detect composing shapes.

6. Experiments Results
order assess performance proposed approach system implementing
it, carried extensive set experiments test dataset images.
well known evaluating performances image retrieval system difficult
lack ground truth measures. ease possibility comparison, adopted
approach first proposed Gudivada Raghavan (1995). experimental framework
hence largely based one proposed there, relies comparison system
performances versus judgement human experts.
noticed work test images iconic images,
classified terms spatial relationships icons; experiments images
243

fiDi Sciascio, Donini & Mongiello

Figure 14: query example retrieved images.

244

fiStructured Knowledge Representation Image Retrieval

Figure 15: sample images used experiments.

245

fiDi Sciascio, Donini & Mongiello

real classification carried image features, including color, texture,
shape, scale, orientation spatial relationships.
test data set consists collection 93 images; sample shown
Figure 15, complete set available URL:
http://www-ictserv.poliba.it/disciascio/jair images.htm.
Images acquired using digital camera, combining 18 objects, either simple
objects (i.e., single shape) composite ones, variable size color. images
size 1080 720 pixels, 24 bits/pixel. noticed actually
18 different objects, considered similar variants object, e.g., two
pens different color, single test object.
selected test data set 31 images used queries. query set formed
two logical groupings.
first one (namely queries 1 15 queries 27, 30 31) primary
objective testing performance system using query single objects composed
various shapes. is, assessing ability system detect retrieve images
containing object, objects similar query.
query images second group (remaining images test data set) pictured
two objects chosen assess ability system detect
retrieve images according spatial relationships existing objects query.
Obviously difference queries containing single objects composed several
shapes, queries containing two objects, cognitive one: system
queries composite shapes. However, observed performances changed
two groupings.
separately asked five volunteers classify decreasing order, according
judgment, 93 images based similarity image selected query
set. volunteers never used system briefly instructed
rank orderings based degree conformance database images
query images. allowed group images considered equivalent,
query, discard images judged wholly dissimilar query.
obtained five classifications, univocal, created final ranking
merging previous similarity rankings according minimum ranking criterion.
final ranking image respect query determined minimum one
among five available.
example consider classification Query nr.1, shown Table 1.
Notice images grouped together cell given relevance.
Image 2 ranked third position users 1,4, 5, users 2 3 ranked
fourth position, finally ranked position four. Notice image 24
criterion leads withdrawal ranked images. approach limits weight
images badly classified single users final ranking.
submitted set 31 queries system, whose knowledge base
loaded 93 images test set.
behavior system obviously depends configuration parameters,
determine relevance various features involved similarity computation.
configuration parameters fed system experimentally determined test bed
246

fiStructured Knowledge Representation Image Retrieval

user
1
2
3
4
5
final

1st
1
1
1
1
1
1

2nd
44, 88
44, 88
44, 88
44, 88
44, 88
44, 88

ranking
3rd
2, 3, 68, 80
3, 68, 80
3, 68, 80
2, 3, 68, 80
2, 3, 68, 80
3, 68, 80

4th
26
2, 26
2, 26
26
24 26
2, 26

5th
24

24

Table 1: Users rankings query nr.1
Parameter
Fourier descriptors threshold
Circular symmetry threshold
Spatial similarity threshold
Symmetry maxima threshold
Spatial similarity weight
Spatial similarity sensitivity f x
spatial similarity sensitivity f
shape similarity weight
shape similarity sensitivity f x
shape similarity sensitivity f
color similarity weight
color similarity sensitivity f x
color similarity sensitivity f
rotation similarity weight
rotation similarity sensitivity f x
rotation similarity sensitivity f
texture similarity weight
texture similarity sensitivity f x
texture similarity sensitivity f
scale similarity weight
scale similarity sensitivity f x
scale similarity sensitivity f
global similarity threshold

Value
0.98
0.99
0.30
0.10
0.30
90.0
0.40
0.30
0.005
0.20
0.11
110.0
0.40
0.11
90.0
0.40
0.07
110.0
0.40
0.11
0.50
0.40
0.70

Table 2: Configuration parameters, grouped feature type.

approximately 500 images starting test phase. shown Table 2.
parameters reported described Appendix. Notice that, dealing welldefined objects, gave higher relevance shape spatial features reduced
relevance scale, rotation, color texture.
resulting classification gave us called system-provided ranking.
adopted Rnorm quality measure retrieval effectiveness. Rnorm first
introduced LIVE-Project (Bollmann, Jochum, Reiner, Weissmann, & Zuse, 1985)
evaluation textual information retrieval systems used
experiments referenced paper Gudivada Raghavan. make paper
self-contained recall Rnorm defined.
Let G finite set images user-defined preference relation complete
transitive. Let usr rank ordering G induced user preference relation.
Also, let sys system-provided ranking. formulation Rnorm is:
Rnorm (sys ) =

1
S+
(1 +
)
+
2
Smax

+ number image pairs better image ranked system
ahead worse one; number pairs worse image ranked ahead
+
better one Smax
maximum possible number + . noticed
calculation + , , max based ranking image pairs sys relative
ranking corresponding image pairs usr .
247

fiDi Sciascio, Donini & Mongiello

Query nr.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
Average Rnorm

Image nr.
1
2
3
4
5
6
7
10
11
12
13
14
15
18
20
25
26
27
28
31
33
34
35
36
37
39
41
42
50
78
79

Rnorm
0.92
0.92
0.93
0.95
0.99
0.94
0.93
0.93
0.95
0.74
0.60
0.84
0.83
0.99
0.91
0.89
0.80
1.00
0.74
1.00
1.00
0.99
0.91
0.89
1.00
0.99
0.93
0.98
1.00
0.88
1.00
0.92

Table 3: Rnorm values. (indicates single-object queries)

Rnorm values range [0,1]; value 1 corresponds system-provided
ordering database images either identical one provided human
experts higher degree resolution, lower values correspond proportional
disagreement two.
Table 3 shows results query final average Rnorm =0.92. Taking closer
look results, first group queries (single compound objects) average value
Rnorm =0.90, Rnorm =0.94 second grouping (various compound objects).
(The complete set result users ranking system ranking available online
appendix).
comparison, average Rnorm resulted 0.98 system presented Gudivada
Raghavan (1995), 24 iconic images used queries database
images, similarity computed spatial relationships icons. remark
system works real images computes similarity several image features,
believe results prove ability system catch good extent
users information need, make refined distinctions images searching
composite shapes. Furthermore, algorithm able correctly deal presence
one instance object images, possible approaches
(Gudivada, 1998). noteworthy that, though parameters setting
object several experiments, cannot considered optimal yet, believe
room improvement system performance, pointed
following paragraph.
Obviously system fail segmentation provide accurate enough
results. Figure 16 shows results Query 11, one worst R norm .
system retrieve images users considered relevant,
248

fiStructured Knowledge Representation Image Retrieval

Figure 16: Query results query 11, lowest Rnorm =0.60.
important wrongly confused sugar-drop wrist-watch, resulted
false positive. matter fact various images sweet-drops resulted properly
segmented. Nevertheless, highly relevant images successfully retrieved wrongly
retrieved one slightly selection threshold.
Another observation made human users, comparing query
single object, much driven color feature, including
spatial positioning. appeared various queries clearly visible using
example results Query 11. users selected highest relevance class images
color sugar-drop, gave lower ranking images (with sugar-drops)
closer spatial relationships different colors. observation may significant
related field object recognition.
final comment. reference system behavior terms retrieval time,
carry systematic testing, depends several variables: number images
database, number objects query, important depth hierarchy
- search time decreases basic shapes available. Limiting analysis
database loaded 93 test images, system required average 12 secs
answer query, machine Celeron 400 MHz CPU 128 MB RAM running
client server.
249

fiDi Sciascio, Donini & Mongiello

7. Conclusion
proposed Knowledge Representation approach Image Retrieval. started
observation current sketch-based image retrieval systems lack compositional
query language is, able handle queries made several shapes,
position, orientation size shapes relative meaningful.
recover this, proposed language describe composite shapes, gave
extensional semantics queries, terms sets retrieved images. cope
realistic setting beginning, generalized semantics fuzzy membership
image description. composition shapes made possible explicit
use language geometric transformations (translation-rotation-scale),
borrow form hierarchical object modeling Computer Graphics. believe
distinguishing feature approach, significantly extends standard invariant
recognition single shapes image retrieval. extensional semantics allows us
properly define subsumption (i.e., containment) queries.
Borrowing Structured Knowledge Representation, particular Description Logics, stored shape descriptions subsumption hierarchy. hierarchy
provides semantic index images database. logical semantics allowed us
define reasoning services: recognition shape arrangement image,
classification image reference hierarchy descriptions, subsumption
descriptions. tasks aside, speed up, main one, Image
Retrieval.
proved subsumption simple logic reduced recognition,
gave polynomial-time algorithm perform exact recognition. Then, realistic application setting extended algorithm approximate recognition, weighting
shape features (orientation, size, position), color texture.
Using logical approach formal specification, built prototype system using
state-of-the-art technology, set experiments assess efficacy proposal, fine tune parameters weights show approximate retrieval.
results experiments, although exhaustive, show approach catch
good extent users information need make refined distinctions images
searching composite shapes.
believe proposal opens least three directions future research. First,
language describing composite shapes could enriched either logicoriented connectives e.g., alternative components corresponding compositions sequences shape arrangements, cope objects internal movements video sequence retrieval. Second, techniques Computational Geometry could
used optimize algorithms approximate retrieval, study complexity recognition problem composite shapes might prove theoretical optimality
algorithms. Finally, large-scale experiments might prove useful understanding
relative importance attributed end users various features composite shape.
Acknowledgements
wish thank former students G. Gallo, M. Benedetti L. Allegretti
useful comments implementations, Marco Aiello comments earlier draft,
250

fiStructured Knowledge Representation Image Retrieval

Dino Guaragnella discussions Fourier transforms, anonymous referee
constructive criticism helped us improving paper.
research supported European Union, POP Regione Puglia sottomisura 7.4.1 (SFIDA 3), Italian Ministry Education, University Research
(MIUR, ex-MURST) projects CLUSTER22 subcluster Monitoraggio ambiente e territorio, workpackage: Sistema informativo per il collocamento dei prodotti ortofrutticoli
pugliesi Italian National Council Research (CNR), projects LAICO, DeMAnD,
Metodi di Ragionamento Automatico nella modellazione ed analisi di dominio.

Appendix A.
appendix briefly revise methods used extraction image features.
describe smoothing function way compute similarity image
features introduced Section 4.2.
A.1 Extraction Image Features
order deal objects image, segmentation required obtain partition
image. Several segmentation algorithms proposed literature;
approach depend particular segmentation algorithm adopted. anyway
obvious better segmentation, better system work. system
used simple algorithm merges edge detection region growing.
Illustration technique beyond scope paper; limit
description image features computation, assume successful segmentation.


make description self-contained start defining generic color image { (x, y) | 1
x Nh , 1 Nv }, Nh , Nv horizontal vertical dimensions, respectively,


(x, y) three-components tuple (R, G, B). assume image
partitioned regions (ri ), = 1, . . . , satisfying following properties:
I=



(ri ), = 1, 2, . . . ,

{1, 2, . . . , m}, ri nonempty connected set
ri rj = iff 6= j
region satisfies heuristic physical requirements.
characterize region ri following attributes: shape, position, size, orientation, color texture.
Shape. Given connected region point moving along boundary generates complex
function defined as: z(t) = x(t) + jy(t), = 1, . . . , Nb , Nb number boundary
sample points. Following approach proposed Rui, She, Huang (1996) define
Discrete Fourier Transform (DFT) z(t) as:
Z(k) =

Nb
X

z(t)e

j 2tk
N
b

t=1

k = 1, . . . , Nb .
251

= (k)ej(k)

fiDi Sciascio, Donini & Mongiello

order address spatial discretization problem compute Fast Fourier
Transform(FFT) boundary z(t); use first (2Nc + 1) FFT coefficients form
dense, non-uniform set points boundary as:
zdense (t) =

Nc
X

Z(k)e

j 2tk
N
b

k=Nc

= 1, . . . , Ndense .
interpolate samples obtain uniformly spaced samples zunif (t), =
0, . . . , Nunif . compute FFT zunif (t) obtaining Fourier coefficients Zunif (k),
k = Nc , . . . , Nc . shape-feature region hence characterized vector 2N c +1
complex coefficients.
Position Size. Position determined region centroid computed via moment
invariants (Pratt, 1991). Size computed mean distance region centroid
points contour.
Orientation. order quantify orientation region r use
Fourier representation, stores orientation information phase values.
obviously deal special cases shape region one symmetry, e.g., rectangle circle. Rotational similarity reference shape B
given region ri obtained finding maximum values via cross-correlation:
C(t) =

2N
Xc
2
1
ZB (k)Zri (k) ej 2Nc kn 0, . . . , 2Nc
2Nc + 1 k=0

Color. Color information region ri stored, quantization 112 values
color space, mean RGB value within region:
Rri =

X

R(p)

G ri =

X

G(p)

B ri =

pri

pri

X

B(p)

pri

Texture. extract texture information region ri method based
work Pok Liu (1999). Following approach, extract texture features
convolving original grey level image I(x, y) bank Gabor filters,
following impulse response:
h(x, y) =

2
2
1
x +y
2 2
ej2(U x+V y)

e
2 2

(U, V ) represents filter location frequency-domain, central frequency, scale factor, orientation, defined as:
=

p

U2 + V 2

= arctan U/V

processing allows extract 24-components feature vector, characterizes
textured region.
252

fiStructured Knowledge Representation Image Retrieval

A.2 Functions Computing Similarities
Smoothing function . similarity measures, use function (x, f x, f y).
role function change distance x (in 0 corresponds perfect matching)
similarity measure (in value 1 corresponds perfect matching),
smooth changes quantity x, depending two parameters f x, f y.
(x, f x, f y) =


x

f +"(1 f y) cos( 2f x )

fy 1

arctan[

(xf x)(1f y)
]
f xf



#

0 x < f x
x > f x

f x > 0 0 < f < 1.

input data approximate recognition algorithm shape description D,
containing n components hck , tk , k , Bk image segmented regions r1 , . . . ,rm .
algorithm provides measure approximate recognition I.
first step algorithm Section 4.2 considers regions image
segmented n components shape description finds
groups n regions rj(k) satisfying higher shape similarity shape components
D. purpose compute shape similarity, based Fourier representation
previously introduced, vector complex coefficients. measure denoted sim ss
invariant respect rotation, scale translation computed cosine
distance two vectors. similarity gives measure range [0,1] assuming
higher similarity simss = 1 perfect matching.
Given vectors X complex coefficients describing respectively shape
region ri shape component Bk , X = (x1 , . . . , x2Nc ) = (y1 , . . . , y2Nc )
P2Nc

l=1 xl yl
simss (Bk , ri ) = qP
P2Nc 2
2Nc 2
l=1 xl
l=1 yl

Shape Similarity. quantity simshape measures similarity shapes
composite shape description regions segmented image.
n

simshape = (max[1 simss (Bk , rj(k) )], f xshape , f yshape )
k=1

Color Similarity. quantity simcolor measures similarity terms color
appearance regions corresponding shapes composite shape description. following formula, color (k).R denotes difference red color
component k-th component region rj(k) , similarly
green blue color components.
color(k) =

q

[color (k).R]2 + [color (k).G]2 + [color (k).B]2

function takes maximum differences obtain similarity:
n

simcolor = (max{color (k)}, f xcolor , f ycolor )
k=1

253

fiDi Sciascio, Donini & Mongiello

Texture Similarity. Finally, simtexture measures similarity texture
features components corresponding regions.
texture (k) denotes sum differences texture components k-th
component region rj(k) dividing standard deviation elements.
n

simtexture = (max texture (k), f xtexture , f ytexture )
k=1

References
Aiello, M. (2001). Computing spatial similarity games. Esposito, F. (Ed.), Proceedings Eighth Conference Italian Association Artificial Intelligence
(AI*IA99), No. 2175 Lecture Notes Artificial Intelligence, pp. 99110. SpringerVerlag.
Ardizzone, E., Chella, A., & Gaglio, S. (1997). Hybrid computation reasoning
artificial vision. Cantoni, V., Levialdi, S., & Roberto, V. (Eds.), Artificial Vision,
pp. 193221. Academic Press.
Baader, F., & Hanschke, P. (1991). schema integrating concrete domains concept
languages. Proceedings Twelfth International Joint Conference Artificial
Intelligence (IJCAI91), pp. 452457, Sydney.
Bach, R., Fuller, C., Gupta, A., Hampapur, A., Horowitz, B., Humphrey, R., Jain, R.,
& Shu, C. (1996). Virage image search engine: open framework image
management. Storage Retrieval Image Video Databases, Vol. 2670, pp.
7687. SPIE.
Bertino, E., & Catania, B. (1998). constraint-based approach shape management
multimedia databases. MultiMedia Systems, 6, 216.
Bollmann, P., Jochum, F., Reiner, U., Weissmann, V., & Zuse, H. (1985). LIVEProject-Retrieval experiments based evaluation viewpoints. Proceedings
8th Annual International ACM SIGIR Conference Research Developement
Information Retrieval (SIGIR 85), pp. 213214. ACM, New York.
Brooks, R. (1981). Symbolic reasoning among 3-D models 2-D images. Artificial
Intelligence, 17, 285348.
Calvanese, D., Lenzerini, M., & Nardi, D. (1998). Description logics conceptual data
modeling. Chomicki, J., & Saake, G. (Eds.), Logics Databases Information
Systems, pp. 229264. Kluwer Academic Publisher.
Cardoze, D., & Schulman, L. (1998). Pattern matching spatial point sets. Proceedings Thirtyninth Annual Symposium Foundations Computer Science
(FOCS98), pp. 156165, Palo Alto, CA.
Carson, C., Thomas, M., Belongie, S., Hellerstein, J. M., & Malik, J. (1999). Blobworld:
system region-based image indexing retrieval. Huijsmans, D., & Smeulders,
A. (Eds.), Lecture Notes Computer Science, Vol. 1614, pp. 509516. Springer-Verlag.
Celentano, A., & Di Sciascio, E. (1998). Features integration relevance feedback analysis
image similarity evaluation. Journal Electronic Imaging, 7 (2), 308317.
254

fiStructured Knowledge Representation Image Retrieval

Chandra, A., & Harel, D. (1980). Computable queries relational databases. Journal
Computer System Sciences, 21, 156178.
Chang, S., Shi, Q., & Yan, C. (1983). Iconic indexing 2D strings. IEEE Transactions
Pattern Analysis Machine Intelligence, 9 (3), 413428.
Chew, L., Goodrich, M., Huttenlocher, D., Kedem, K., Kleinberg, J., & Kravets, D. (1997).
Geometric pattern matching euclidean motion. Computational Geometry, 7,
113124.
Cox, I., Miller, M., Minka, T., & Papathomas, T. (2000). bayesian image retrieval
system, PicHunter. IEEE Transactions Image Processing, 9 (1), 2037.
Di Sciascio, E., Donini, F. M., & Mongiello, M. (2000). Description logic image
retrieval. Lamma, E., & Mello, P. (Eds.), AI*IA 99: Advances Artificial Intelligence, No. 1792 Lecture Notes Artificial Intelligence, pp. 1324. Springer-Verlag.
Di Sciascio, E., & Mongiello, M. (1999). Query sketch relevance feedback contentbased image retrieval web. Journal Visual Languages Computing,
10 (6), 565584.
Donini, F., Lenzerini, M., Nardi, D., & Schaerf, A. (1996). Reasoning description logics.
Brewka, G. (Ed.), Foundations Knowledge Representation, pp. 191236. CSLIPublications.
Edelmann, S. (1999). Representation Recognition Vision. MIT Press.
El-Kwae, E., & Kabuka, M. (1999). Content-based retrieval spatial similarity image
databases. ACM Transactions Information Systems, 17, 174198.
Flickner, M., Sawhney, H., Niblak, W., Ashley, J., Huang, Q., Dom, B., Gorkani, M., Hafner,
J., Lee, D., Petkovic, D., Steele, D., & Yanker, P. (1995). Query image video
content: QBIC system. IEEE Computer, 28 (9), 2331.
Foley, J., van Dam, A., Feiner, S., & Hughes, J. (1996). Computer Graphics. Addison
Wesley Publ. Co., Reading, Massachussetts.
Fuhr, N., Govert, N., & Rolleke, T. (1998). DOLORES: system logic-based retrieval
multimedia objects. Proceedings 21st Annual International ACM SIGIR
Conference Research Developement Information Retrieval (SIGIR 98), pp.
257265, Melbourne, Australia.
Gevers, T., & Smeulders, A. (2000). Pictoseek: Combining color shape invariant features
image retrieval. IEEE Transactions Image Processing, 9 (1), 102119.
Gudivada, V. (1998). R-string: geometry-based representation efficient effective
retrieval images spatial similarity. IEEE Transactions Knowledge Data
Engineering, 10 (3), 504512.
Gudivada, V., & Raghavan, J. (1995). Design evaluation algorithms image
retrieval spatial similarity. ACM Transactions Information Systems, 13 (2),
115144.
Haarslev, V., Lutz, C., & Moeller, R. (1998). Foundations spatioterminological reasoning description logics. Proceedings Sixth International Conference
Principles Knowledge Representation Reasoning (KR98), pp. 112123.
255

fiDi Sciascio, Donini & Mongiello

Hacid, M.-S., & Rigotti, C. (1999). Representing reasoning conceptual queries
image databases. Proceedings Twelfth International Symposium Methodologies Intelligent Systems (ISMIS99), No. 1609 Lecture Notes Artificial
Intelligence, pp. 340348, Warsaw, Poland. Springer-Verlag.
Hartman, J., & Wernecke, J. (1996). VRML 2.0 Handbook. Addison-Wesley.
Hirata, K., & Kato, T. (1992). Query visual example. Pirotte, A., Delobel, C., &
Gottlob, G. (Eds.), Advances Database Technology Proc. 3rd Int. Conf. Extending Database Technology, EDBT, Vol. 580 Lecture Notes Computer Science, pp.
5671. Springer-Verlag.
Jacobs, C., Finkelstein, A., & Salesin, D. (1995). Fast multiresolution image querying.
Proceedings 22nd Annual Conference Computer Graphics Interactive
Techniques (SIGGRAPH 95), pp. 277286.
Jahne, B., Haubecker, H., & Geibler, P. (1999). Handbook Computer Vision Applications. Academic Press.
Ma, W., & Manjunath, B. (1997). NETRA: toolbox navigating large image database.
Proceedings IEEE International Conference Image Processing (ICIP 97),
Vol. 1, pp. 568571, Santa Barbara.
Marr, D. (1982). Vision. W.H. Freeman Co., Oxford.
Meghini, C., Sebastiani, F., & Straccia, U. (2001). model multimedia information
retrieval. Journal ACM, 48 (5), 909970.
Moeller, R., Neumann, B., & Wessel, M. (1999). Towards computer vision description
logics: recent progress. Proceedings IEEE Integration Speech
Image Understanding, pp. 101115.
Nebel, B. (1990). Reasoning Revision Hybrid Representation Systems. No. 422
Lecture Notes Artificial Intelligence. Springer-Verlag.
Niblak, W., Barder, R., Equitz, W., Flickner, M., Glasman, E., Petkovic, D., Yanker, P.,
& Faloustos, C. (1993). QBIC project: Querying images content using color,
texture, shape. Storage Retrieval Still Image Video Databases,
Vol. 1980, pp. 173182. SPIE.
Paquet, E., & Rioux, M. (1998). content-based search engine VRML databases.
Proceedings IEEE International Conference Computer Vision Pattern
Recognition (CVPR98), pp. 541546, Santa Barbara, CA.
Picard, R., & Kabir, T. (1993). Finding similar patterns large image databases.
Proceedings IEEE International Conference Acoustics Speech Signal
Processing (ICASSP 93), pp. 161164, Minneapolis, MN.
Pirri, F., & Finzi, A. (1999). approach perception theory actions: part 1.
Linkoping Electronic Articles Computer Information Science, No. 41. Linkoping University Electronic Press.
Pok, G., & Liu, J. (1999). Texture classification two-level hybrid scheme. Storage
Retrieval Image Video Databases VII, Vol. 3656, pp. 614622. SPIE.
256

fiStructured Knowledge Representation Image Retrieval

Pratt, W. (1991). Digital Image Processing. J. Wiley & Sons Inc., Englewood Cliffs, NJ.
Reiter, R., & Mackworth, A. (1989). logical framework depiction image interpretation. Artificial Intelligence, 41 (2), 125155.
Reiter, R. (1980). Equality domain closure first-order databases. Journal
ACM, 27 (2), 235249.
Rui, Y., Huang, T., & Mehrotra, S. (1997). Content-based image retrieval relevance
feedback MARS. Proceedings IEEE International Conference Image
Processing (ICIP 97), pp. 815818.
Rui, Y., She, A., & Huang, T. (1996). Modified Fourier descriptors shape representation
- practical approach. Proceedings 1st Workshop Image Databases
Multimedia Search, Amsterdam.
Sanfeliu, A., & Fu, K. (1983). distance measure attributed relational graphs
pattern recognition. IEEE Transactions Systems, Man, Cybernetics, 13 (3),
353362.
Smith, J., & Chang, S. (1996). VisualSEEK: fully automated content-based image query
system. Proceedings fourth ACM International Conference Multimedia
(Multimedia96), pp. 8798.
Straccia, U. (2001). Reasoning within fuzzy description logics. Journal Artificial Intelligence Research, 14, 137166.
Tagare, H., Vos, F., Jaffe, C., & Duncan, J. (1995). Arrangement: spatial relation
parts evaluating similarity tomographic section. IEEE Transactions Pattern
Analysis Machine Intelligence, 17 (9), 880893.
Ullman, J. D. (1988). Principles Database Knowledge Base Systems, Vol. 1. Computer
Science Press, Potomac, Maryland.
Woods, W. A., & Schmolze, J. G. (1992). KL-ONE family. Lehmann, F. W. (Ed.),
Semantic Networks Artificial Intelligence, pp. 133178. Pergamon Press. Published
special issue Computers & Mathematics Applications, Volume 23, Number
29.
Yen, J. (1991). Generalizing term subsumption languages Fuzzy logic. Proceedings
Twelfth International Joint Conference Artificial Intelligence (IJCAI91), pp.
472477.
Zadeh, L. (1965). Fuzzy sets. Information Control, 8, 338353.

257


