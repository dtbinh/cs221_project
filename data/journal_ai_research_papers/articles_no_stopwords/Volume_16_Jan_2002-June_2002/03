Journal Artificial Intelligence Research 16 (2002) 135-166

Submitted 7/01; published 2/02

Improving Eciency Inductive Logic Programming
Use Query Packs
hendrik.blockeel@cs.kuleuven.ac.be

Hendrik Blockeel

Katholieke Universiteit Leuven, Department Computer Science
Celestijnenlaan 200A, B-3001 Leuven, Belgium

luc.dehaspe@pharmadm.com

Luc Dehaspe
PharmaDM, Ambachtenlaan 54D, B-3001 Leuven, Belgium

Bart Demoen
Gerda Janssens
Jan Ramon

bart.demoen@cs.kuleuven.ac.be
gerda.janssens@cs.kuleuven.ac.be
jan.ramon@cs.kuleuven.ac.be

Katholieke Universiteit Leuven, Department Computer Science
Celestijnenlaan 200A, B-3001 Leuven, Belgium

henk.vandecasteele@pharmadm.com

Henk Vandecasteele

PharmaDM, Ambachtenlaan 54D, B-3001 Leuven, Belgium

Abstract

Inductive logic programming, relational learning, powerful paradigm machine
learning data mining. However, order ILP become practically useful,
eciency ILP systems must improve substantially. end, notion query pack
introduced: structures sets similar queries. Furthermore, mechanism described
executing query packs. complexity analysis shows considerable eciency
improvements achieved use query pack execution mechanism.
claim supported empirical results obtained incorporating support query
pack execution two existing learning systems.
1. Introduction

Many data mining algorithms employ extent generate-and-test approach: large
amounts partial complete hypotheses generated evaluated data
mining process. evaluation usually involves testing hypothesis large data set,
process typically linear size data set. Examples data mining
algorithms Apriori (Agrawal et al., 1996), decision tree algorithms (Quinlan, 1993a;
Breiman et al., 1984), algorithms inducing decision rules (Clark & Niblett, 1989), etc.
Even though search hypothesis space seldom exhaustive practical
situations, clever branch-and-bound greedy search strategies employed, number hypotheses generated evaluated approaches may still huge.
especially true complex hypothesis space used, often case inductive
logic programming (ILP), sheer size hypothesis space important
contribution high computational complexity ILP approaches. computational complexity reduced, however, exploiting fact many
similarities hypotheses.

c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
ILP systems build hypothesis one clause time. search single clause
concerned rest paper, word \hypothesis"
usually refer single clause. clause search space typically structured
lattice. clauses close one another lattice similar, computations
involved evaluating similar well. words, many computations
performed evaluating one clause (which boils executing query
consisting body clause) performed evaluating
next clause. Storing certain intermediate results computation later use could
solution (e.g., tabling XSB Prolog engine, Chen & Warren, 1996), may
infeasible practice memory requirements. becomes feasible
search reorganised intermediate results always used shortly
computed; achieved extent rearranging computations.
best way removing redundancy, however, seems re-implement execution
strategy queries way much computation possible effectively
shared.
paper discuss strategy executing sets queries, organised so-called
query packs, avoids redundant computations. strategy presented adaptation standard Prolog execution mechanism. adapted execution mechanism
implemented ilProlog, Prolog system dedicated inductive logic programming. Several inductive logic programming systems re-implemented make use
dedicated engine, using new implementations obtained experimental
results showing cases speed-up order magnitude. Thus,
work significantly contributes applicability inductive logic programming real
world data mining tasks. addition, believe may contribute state art
query optimisation relational databases. Indeed, latter field lot
work optimisation individual queries relatively small sets queries, much
less optimisation large groups similar queries, understandably
get much attention advent data mining. Optimisation groups queries
relational databases seems interesting research area now, believe techniques
similar ones proposed might relevant area.
remainder paper structured follows. Section 2 precisely describe
ILP problem setting work set. Section 3 define notion
query pack indicate would executed standard Prolog interpreter
computational redundancy causes. describe execution mechanism
query packs makes possible avoid redundant computations would arise
queries pack run separately, show implemented making
small significant extensions WAM, standard Prolog execution mechanism.
Section 4 describe query pack execution strategy incorporated two
existing inductive logic programming algorithms (Tilde Warmr). Section 5
present experimental results illustrate speed-up systems achieve
using query pack execution mechanism. Section 6 discuss related work
Section 7 present conclusions directions future work.

136

fiImproving Efficiency ILP Query Packs
2. Inductive Logic Programming

Inductive logic programming (Muggleton & De Raedt, 1994) situated intersection
machine learning data mining one hand, logic programming
hand. shares former fields goal finding patterns data, patterns
used build predictive models gain insight data. logic programming
shares use clausal first order logic representation language data
hypotheses. remainder text use basic notions logic
programming, literals, conjunctive queries, variable substitutions. use
Prolog notation throughout paper. introduction Prolog logic programming
see Bratko (1990).
Inductive logic programming used many different purposes, problem
statements found ILP papers consequently vary. article consider so-called
learning interpretations setting (De Raedt & Dzeroski, 1994; De Raedt, 1997).
argued elsewhere setting, slightly less powerful standard
ILP setting (it problems with, e.g., learning recursive predicates), sucient
practical purposes scales better (Blockeel et al., 1999).
formulate learning task way covers number different problem
statements. specifically, consider problem detecting set conjunctive
queries instantiations certain variables query succeeds. variables
called key variables, grounding substitution called key instantiation.
intuition example learning task uniquely identified single key
instantiation.
link ILP systems learn clauses follows. search performed
ILP system directed regularly evaluating candidate clauses. Let us denote
candidate clause Head(X )
Body (X; ) X represents vector variables
appearing head clause represents additional variables occur
body. assume head single literal list examples given,
example form Head(X ) substitution grounds X . Examples
may labelled (e.g., positive negative), essential setting.
example represented fact Head(X ) learning definite Horn clauses,
consider tuple X. notations used paper.
Intuitively, positive negative examples given, one wants find clause
covers many positive examples possible, covering negatives.
Whether single example Head(X ) covered clause determined
running query ? Body(X; ). words, evaluating clause boils
running number queries consisting body clause. simplicity notation,
often denote conjunctive query conjunction (without ? symbol).
less typical ILP settings, ILP algorithm search Horn clauses
rather general clauses, e.g., Claudien (De Raedt & Dehaspe, 1997) frequent
patterns expressed conjunctive queries, e.g., Warmr(Dehaspe & Toivonen,
1999). settings handled approach well: needed mapping
hypotheses queries allow evaluate hypotheses. mapping
defined De Raedt Dehaspe (1997) Claudien; Warmr trivial.

137

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
Given set queries set examples E , main task determine
queries Q 2 cover examples e 2 E . formalise using notion result
set:

Definition 1 (Result set) result set set queries deductive database
key K example set E ,
RS (S; K; D; E )

= f(K; i)jQi 2 K 2 E Qi succeeds Dg

Similar learning interpretations setting defined (De Raedt, 1997),
problem setting stated as:

Given: set conjunctive queries , deductive database D, tuple K variables
occur query S, example set E
Find: result set RS (S; K; D; E ); i.e., find query Q ground
instantiations K K 2 E Q succeeds D.
Example 1 Assume ILP system learning definition grandfather/2 wants evaluate following hypotheses:

grandfather(X,Y) :- parent(X,Z), parent(Z,Y), male(X).
grandfather(X,Y) :- parent(X,Z), parent(Z,Y), female(X).

Examples form grandfather(gf ,gc) gf gc constants; hence
example uniquely identified ground substitution tuple (X; ).
problem setting set Prolog queries equals f(?- parent(X,Z), parent(Z,Y),
male(X)), (?- parent(X,Z), parent(Z,Y), female(X))g key K equals (X; ).
Given query Qi 2 , finding tuples (x; y) ((x; y); i) 2 R (with R result
set defined above) equivalent finding grandfather(x,y) facts
example set predicted clause grandfather(X,Y) :- Qi .

generality problem setting follows fact known
queries succeed examples, statistics heuristics typical ILP systems
use readily obtained this. examples:






discovery frequent patterns (Dehaspe & Toivonen, 1999): query Qi
number key instantiations succeeds needs counted, i.e.,
f req (Qi ) = jfK j(K; i) 2 Rgj R result set.
induction Horn clauses (Muggleton, 1995; Quinlan, 1993b): accuracy
clause H :- Qi (defined number examples body head hold,
divided number examples body holds) computed
jfKj(K;i)2R^Dj=Hgj R result set.
jfKj(K;i)2Rgj
induction first order classification regression trees (Kramer, 1996; Blockeel &
De Raedt, 1998; Blockeel et al., 1998): class entropy variance examples
covered (or covered) query computed probability distribution
target variable; computing distribution involves simple counts similar
ones above.

138

fiImproving Efficiency ILP Query Packs
transforming grandfather/2 clauses
grandfather((X,Y)),I) :- parent(X,Z), parent(Z,Y), male(X), = 1.
grandfather((X,Y)),I) :- parent(X,Z), parent(Z,Y), female(X), = 2.

result set clearly computed collecting grounding 's K 2 E
answers query ?- grandfather(K,I) . Section 3 queries literal
= end another goal side-effects results collecting result set.
practice, natural compute result set using double loop: one examples
one queries one choice outer loop. \examples
outer loop" \queries outer loop" used data mining systems;
context decision trees, see instance Quinlan (1993a) Mehta et al. (1996).
shall see redundancy removal approach propose uses \examples
outer loop" strategy. approaches however, given query key instantiation,
interested whether query succeeds key instantiation. implies
particular query succeeded example, execution stopped.
words: computing result set defined boils evaluating
query example, interested existence success
evaluation. Computing one solution one query one example unnecessary.
3. Query Packs

simplicity, make abstraction existence keys following examples.
relevant here, query interested whether succeeds not,
finding answer substitutions.
Given following set queries
p(X),
p(X),
p(X),
p(X),
p(X),

= 1.
q(X,a),
q(X,b),
q(X,Y),
q(X,Y),

= 2.
= 3.
t(X), = 4.
t(X), r(Y,1), = 5.

choose evaluate separately. Since interested one { first {
success query, would evaluate Prolog queries
once((p(X),
once((p(X),
once((p(X),
once((p(X),
once((p(X),

= 1)).
q(X,a), = 2)).
q(X,b), = 3)).
q(X,Y), t(X), = 4)).
q(X,Y), t(X), r(Y,1), = 5)).

wrapper once/1 pruning primitive prevents unnecessary search
solutions. definition Prolog simply
once(Goal) :- call(Goal), !.

139

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
alternative way evaluate queries consists merging one (nested)
disjunction in:
p(X), (I=1

;

q(X,a), I=2

;

q(X,b), I=3

;

q(X,Y), t(X), (I=4

;

r(Y,1), I=5)).

set queries evaluated whole: success one branch
disjunctive query corresponds success corresponding individual query.
Compared evaluation individual queries, disjunctive query
advantage disadvantage:
+ queries prefix p(X), evaluated individual
query, disjunctive query, goal p(X) evaluated once; depending
evaluation cost p/1, lead arbitrary performance gains.
usual Prolog pruning primitives powerful enough prevent unnecessary backtracking branch disjunctive query succeeded;
explained Example 2.

Example 2 example literals

contribute discussion:

= left out,



p(X), q(X).
p(X), r(X).

Evaluating queries separately means evaluating
once((p(X), q(X))).
once((p(X), r(X))).

equivalently
p(X), q(X), !.
p(X), r(X), !.

corresponding disjunctive query
p(X), (q(X) ; r(X)).

try place pruning primitive disjunctive query: !/0 end
branch results
p(X), (q(X), ! ; r(X), !)

scope first cut clearly large: goal q(X) succeeded, cut
prevent entering second branch. means adding cut disjunctive
query leads wrong result.
Using once/1 disjunctive query results
p(X), (once(q(X)) ; once(r(X)))

140

fiImproving Efficiency ILP Query Packs
results correct query. However, branches still executed every
binding goal p(X) produces, even branches succeeded already.

combination advantage disjunctive query advantage
individual query pruning (once cut) results notion query pack. Syntactically, query pack looks disjunctive query ; control construct
replaced new control construct denoted or. query pack corresponding
disjunctive query
p(X), (I=1



q(X,a), I=2



q(X,b), I=3



q(X,Y), t(X), (I=4



r(Y,1), I=5))

query pack represented tree Figure 1. query pack Q
tree literals conjunctions literals nodes. path root leaf
node represents conjunctive query Q member Q, denoted Q 2 Q.
construct implicit branching points.
p(X)
I=1

q(X,a),
I=2

q(X,b),
I=3

q(X,c),
I=4
I=5

q(X,Y), t(X)
r(Y,1),
I=6

r(Y,2),
I=7

Figure 1: query pack.
intended procedural behaviour construct branch succeeded, effectively pruned away pack evaluation query pack
current example. pruning must recursive, i.e., branches subtree
query pack succeeded, whole subtree must pruned. Evaluation
query pack terminates subtrees pruned remaining
queries fail example.
semantics construct ecient implementation subject
rest section. however clear already case
answers query needed, pruning cannot performed disjunctive query
already sucient, i.e., query packs useful single success per query suces.

3.1 Ecient Execution Query Packs
Section 3.1.2, meta-interpreter given defines behaviour query packs.
practice meta-interpreter useful, many cases meta-interpreter
causes overhead use query packs compensate for. Indeed, previously
reported results (Demoen et al., 1999; Blockeel, 1998) indicate overhead involved
high-level Prolog implementation destroys eciency gain obtained redundancy
reduction. Moreover discussed Section 3.1.2, meta-interpreter
desired time-complexity. shows desired procedural semantics

141

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
implemented Prolog itself, desired performance Prolog lacks
appropriate primitives.
conclusion changes needed level Prolog engine itself.
requires extension WAM (Warren Abstract Machine) underlying
abstract machine Prolog implementations. extended WAM provides
operator discussed above: permanently removes branches pack
need investigated anymore. extended WAM become basis new Prolog
engine dedicated inductive logic programming, called ilProlog. section continues
introduction basic terminology query packs explains high level
query pack execution works. Next meta-interpreter query pack execution
given finally changes needed WAM clarified.
3.1.1 Principles Query Packs (Execution)

discuss query pack execution detail, note following two points: (1)
pack execution, pruning branch must survive backtracking; (2) executing
pack interested variable instantiations, whether member
pack succeeds not. previous description interested binding
variable I. Since branch bind one value { query number { collect
values practice side effect denoted Section 3.2 report success.
starting point query pack execution mechanism usual Prolog execution
query Q given Prolog program P . backtracking Prolog generate
solutions Q giving possible instantiations Q succeeds P .
query pack consists conjunction literals set alternatives,
alternative query pack. Note leaves query packs empty set
alternatives. query pack Q, conj (Q) denotes conjunction children(Q)
denotes set alternatives. set queries represented so-called root query
pack. every query pack Q, path query packs starting root query
pack Qroot ending query pack itself, namely < Qroot , Q1 , ..., Qn , Q >.
query packs path predecessors Q. Every query pack set dependent
queries, dependent queries(Q). Let < Qroot , Qi1 , ..., Qin , Q > path Q,
dependent queries(Q) = fconj (Qroot ) ^ conj (Qi1 ) ^ : : : ^ conj (Qin ) ^ conj (Q) ^ conj (Qj1 ) ^
: : : ^ conj (Qjm ) ^ conj (Ql ) j < Q; Qj1 , ..., Qjm , Ql > path Q leaf Ql g. Note
dependent queries(Qroot ) actually members query pack described
earlier.

Qroot root tree. conj (Qroot )
Qroot ) contains 4 query packs correspond trees

Example 3 query pack Figure 1,
p(X ). set children(

rooted 4 sons root tree. Suppose query packs named (from
left right) Q1 , Q2 , Q3 , Q4 . conj (Q2 ) equals (q(X; a); = 2), children(Q2 )
equals empty set, conj (Q4 ) equals (q(X; ); t(X )), dependent queries(Q4 ) equals
f(p(X ); q(X; ); t(X ); = 4), (p(X ); q(X; ); t(X ); r(Y; 1); = 5)g.

Execution root query pack Qroot aims finding queries set
dependent queries(Qroot ) succeed. query pack executed ors usual
disjunctions, backtracking occurs queries already succeeded many

142

fiImproving Efficiency ILP Query Packs
0
1
2
3
4
5
6
7
8
9
10
11

execute qp( pack Q, substitution ) f
( next solution( conj (Q))

f

Qchild children(Q)

f
g

g

( execute qp( Qchild , ) == success)
children(Q)
children(Q) n fQchild g

( children(Q) empty set) return(success)

return(fail)

g

Figure 2: query pack execution algorithm.
successes detected. avoid this, case soon query succeeds,
corresponding part query pack longer considered backtracking. approach realises reporting success queries (and query packs)
predecessors query pack. (non-root) query pack Q safely removed
queries depend (i.e., queries dependent queries(Q)) succeeded once.
leaf Q (empty set children), success conj (Q) sucient remove it.
non-leaf Q, wait dependent queries report success equivalently
query packs children(Q) report success.
start evaluation root query pack, set children every query
pack contains alternatives given query pack. execution, query
packs removed children sets thus values children(Q) change
accordingly. due backtracking query pack executed again, might case
fewer alternatives considered.
execution query pack Q defined algorithm execute qp(Q; ) (Figure
2) imposes additional control usual Prolog execution.
usual Prolog execution backtracking behaviour modelled loop
(line 1) generates possible solutions conjunction query pack.
solutions found, fail returned backtracking occur level
calling query pack.
additional control manages children(Q). solution , necessary
children Q executed. important notice initial set children
query pack changed destructively execution algorithm. Firstly,
leaf reached, success returned (line 8) corresponding child removed
query pack (line 6). Secondly, query pack initially several children, finally
ends empty set children (line 6), query pack removed (line 8).
fact children destructively removed, implies due backtracking
query pack executed different , alternatives
initially there, executed more. Moreover, returning success

143

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
qp(1)
ch(1)

ch(3)
ch(2)

b qp(2)
ch(1)

f

q(4)

g qp(3)
ch(1)

ch(3)
ch(2)

c q(1)

q(2)

ch(3)
ch(2)

e q(3)

h q(5)

q(6)

j

q(7)

Figure 3: Query pack numbers qp(i), Query numbers q(i) Child numbers ch(i)
example.
backtracking current query pack conjunction conj (Q) stopped: branches
reported success.
3.1.2 Meta-interpreter Query Packs

first implementation query pack execution algorithm meta-interpreter
meta execute qp(Q). meta-interpreter uses following labelling representation
query pack:

Query pack number non-leaf query packs tree numbered, depth
first, left right (qp(i)).

Query number leaf numbered, left right. original queries
numbered sequentially, numbers leaves correspond (q(i)).

Child number non-leaf query pack N children, children numbered
1 N sequentially (ch(i)).

Consider query pack a, (b, (c e) f g, (h j)). Note
atoms example could general arbitrary conjunctions non-ground terms.
labelling shown Figure 3.
labelled query pack Q represented Prolog term follows (with Qf
father Q):



leaf

Q represented term (c; leaf (qpnbf; chnb; qnb)) c conj (Q),
query pack number Qf , chnb child number Q w.r.t. Qf , qnb
query number Q.



non-leaf Q represented term (c; or(cs; qpnbf; qpnb; chnb; totcs) c
conj (Q), cs list children(Q), qpnbf query pack number Qf , qpnb query
pack number Q, chnb child number Q w.r.t. Qf , totcs total number
children(Q)). query pack number father root query pack
assumed zero.

qpnbf

144

fiImproving Efficiency ILP Query Packs
example Figure 3 following representation (as Prolog term):
(a, or([(b,or([(c,leaf(2,1,1)),(d,leaf(2,2,2)),(e,leaf(2,3,3))],1,2,1,3)),
(f,leaf(1,2,4)),
(g,or([(h,leaf(3,1,5)),(i,leaf(3,2,6)),(j,leaf(3,3,7))],1,3,3,3))],
0,1,1,3))

execution meta-interpreter, solved/2 facts asserted. fact
solved(qpnb, chnb) denotes child number chnb query pack number

succeeded. facts asserted reaching leaf children
query pack succeeded. meta-interpreter executes children
solved/2 fact asserted.
Note time-complexity meta-interpreter yet desired. Execution
query pack always dependent number original children, instead
number remaining (as yet unsuccessful) children.
qpnb

run QueryPack(Q) :preprocess(Q, Qlabeled, 0, 1, 1, 1, , ),
% code preprocessing given Appendix
retractall(solved( , )),
meta execute qp(Qlabeled),
solved(0, ), !.
meta execute qp((A,B)) :- !,
call(A),
meta execute qp(B).
meta execute qp(or(Cs, QpNbF, QpNb, ChildNb, TotCs)) :!, % 'or' corresponds non-leaf query pack
handlechildren(Cs, QpNb, 1),
solved(QpNb, 0, TotCs),
assert(solved(QpNbF,ChildNb)).
meta execute qp(leaf(QpNbF, ChildNb , QueryNb)) :!, % 'leaf' corresponds end query
write(succeed(QueryNb)), nl,
assert(solved(QpNbF,ChildNb)).
handlechildren([], , ).
handlechildren([C| ], QpNb, ChildNb) :not(solved(QpNb,ChildNb)),
once(meta execute qp(C)), fail.
handlechildren([ |Cs], QpNb, ChildNb) :ChildNb1 ChildNb + 1,
handlechildren(Cs, QpNb, ChildNb1).
solved(QpNb, ChildNb, TotCs) :(ChildNb = TotCs -> true
;
ChildNb1 ChildNb + 1,
solved(QpNb, ChildNb1),
solved(QpNb, ChildNb1, TotCs)
).

145

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
3.1.3 WAM Extensions

fully exploit potential query pack (shared computation avoidance unnecessary backtracking) changes made level Prolog engine itself.
explanation assumes WAM-based Prolog engine (At-Kaci, 1991) short explanation
execution disjunction Prolog given first, becomes easy see
newly introduced WAM.
Assume body clause executed a, (b,c ; ; e). Assume
predicates several clauses. moment execution reached first
clause c, choice point stack looks Figure 4(a): choice points
activation a, disjunction itself, b c. choice points linked together
backtracking easily pop top one. choice point contains pointer
next alternative tried: disjunction choice point, alternative pointer
shown. points beginning second branch disjunction.
alternatives b c exhausted, second branch entered becomes
active: situation shown Figure 4(b). point, alternative
disjunction choice point refers last alternative branch disjunction. Finally,
e entered, disjunction choice point already popped.
a, (b, c ; ; e)

a, (b, c ; ; e)

a, (b, c ; ; e)







;

;

e

b



c

(a) Choice points
entering c.

(b) Choice points
entering d.

(c) Choice points
entering e.

Figure 4: Illustration execution disjunction WAM.
goal produces new solution, branches disjunction must tried
again. exactly want avoid query packs: branch succeeded once,
never re-entered. therefore adapt disjunction choice point become
or-choice point set point data structure contains references
alternative disjunction. data structure named pack table. Figure
5(a) shows state execution reached c: similar Figure 4(a).
or-choice point contains information first branch executed.
execution proceeds, two possibilities: either first branch succeeds fails.
describe failing situation first branch explain happens success

146

fiImproving Efficiency ILP Query Packs
second branch. first branch solution, backtracking updates alternative
or-choice point, point next branch pack table. situation
second branch entered shown 5(b) similar 4(b). Suppose
branch goal succeeds: entry pack table or-alternatives
adapted erasing second alternative branch, backtracking occurs, next
alternative branch or-choice point taken. shown 5(c).
produces new solution or-disjunction entered again, pack table
longer contain second alternative branch never re-entered. pack
table actually arranged way entries really removed instead erased
cause overhead later.
a, (b, c e)

a, (b, c e)

a, (b, c e)













b



e

c

(a) choice points
entering c.

(b) choice points
entering (the first
branch succeed).

(c) choice points
entering e (d succeeded).

Figure 5: Illustration execution pack disjunction WAM.
Two issues must explained: first, pack table alternatives must
constructed runtime every time query pack entered evaluation. done
emitting necessary instructions beginning code query pack.
example, show code query pack a, (b,c e) Figure 6.
Finally, example clear moment alternatives ordisjunction succeeded, stop producing solutions. computation
stopped. general - nested query packs - means one pack table entry
next higher or-node erased recursive way. recursive removal
entries pack tables, done instruction query pack prune.
implemented schema ilProlog. Section 5 presents measurements
ilProlog.

3.2 Using Query Packs
Figure 7 shows algorithm makes use pack execution mechanism compute
result set R defined problem statement. set queries typically

147

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
construct pack table @1, @2, @3
call
query pack try
@1: call b
call c
query pack prune
@2: call
query pack prune
@3: call e
query pack prune

Figure 6: Abstract machine code a, (b,c e) .
set refinements given query, i.e., correspond whole hypothesis
space. query pack Q containing queries , derived pack Q0 constructed
adding report success/2 literal leaf pack; (procedural) task
report success(K,i) simply add (K; i) result set R. Obviously specific
ILP system interested result set could provide report success/2
predicate thus avoid overhead explicitly building result set.1
1 evaluate(set examples E , pack Q, key K ) f
2
Q0 Q;
3
q
1;
4
leaf Q0 f
5
add report success(K, q) right conjunction leaf
6
increment q
7
g
8
C
(evaluate pack(K ) :- Q0 );
9
compile load(C);
10
example e E f
11
evaluate pack(e);
12
g
13 g
Figure 7: Using query packs compute result set.
Note algorithm Figure 7 follows strategy running queries
single example moving next example: could called \examples
outer loop" strategy, opposed \queries outer loop" strategy used ILP
1. current implementation result set implemented bit-matrix indexed queries
examples. implementation practically feasible (on typical computers time writing) even
number queries pack multiplied number examples billion, bound
holds current ILP applications.

148

fiImproving Efficiency ILP Query Packs
systems. \examples outer loop" strategy important advantages processing
large data sets, mainly due ability process eciently without data
main memory time (Mehta et al., 1996; Blockeel et al., 1999).

3.3 Computational Complexity
estimate speedup factor achieved using query pack execution two
steps: first consider one-level packs, extend results towards deeper packs.
Lower upper bounds speedup factor achieved executing
one-level pack instead separate queries obtained follows. pack containing
n queries qi = (a; bi ), let Ti time needed compute first answer substitution
qi any, obtain failure otherwise. Let ti part Ti spent within
t0i part Ti spent bi . Ts = (ti + t0i ) Tp = max(ti ) + t0i Ts
representing total time needed executing queries separately Tp total time
needed executing pack. Introducing c = ti = t0i , roughly represents
ratio computational complexity shared part non-shared part,

0
c+1
Ts
ti +
ti
=
= maxi ti
(1)
0
Tp
maxi ti + ti
+1
t0

P

P

P

P P

P
P

P



defining K ratio maximal ti average ti , i.e.

rewrite Equation (1)

Since

P

ti
n

Pmaxt =nt


K

=

Ts
Tp

=



c+1

K
nc

(2)

+1

max ti Pi ti know 1 K n, leads following bounds:
1

Ts
Tp



c+1

c
n

+1

< min(c + 1; n)

(3)

Thus speedup factor bounded branching factor n
ratio c computational complexity shared part computational complexity
non-shared part; maximal speedup attained max ti ' ti =n (or,
K ' 1), words ti queries approximately equal.
multi-level packs, estimate eciency gain follows. Given query qi ,
let Ti defined (the total time finding 1 answer qi obtaining failure).
Instead ti t0i , define ti;l time spent level l pack solving qi ;
counting root level 0 denoting depth pack Ti = dl=0 ti;l .
define Ti;l time spent level l deeper: Ti;l = dj=l ti;j depth
pack. (Thus Ti = Ti;0 .). assume constant branching factor b pack.
Finally, define tl = ti;l =n n = bd . simplicity, formulae implicitly
assume always ranges 1 n n number queries, unless explicitly

P

P

P

149

P

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
specified otherwise.
Tp

= max ti;0


X
+


i;1

= max ti;0


X
+ (max
b

j =1

2

Gj

i;1

XT

+

2

Gj

i;2

)

(4)

j = 1 : : : b index child root Gj set indexes
queries belonging child. define K0 = maxi ti;0 =t0 define K1 smallest
number maxi2Gj ti;1 K1 tj;1 tj;1 = i2Gj ti;1 =b. Note 1 K0 ; K1 b.
follows
b
b
max ti;1 K1 tj;1 = K1 bt1
(5)
i2Gj
j =1
j =1

P

X

X

allows us rewrite Equation (4)
Tp

K0t0 + K1 bt1 +

XT


(6)

i;2

equality holds maxi2Gj ti;1 equal Gj . reasoning continued
till lowest level pack, yielding
Tp

K0t0 + bK1t1 + b2K2 t2 + + bd

finally
Tp

K0 t0 + bK1 t1 + b2 K2t2 + + bd



1K

1 td 1

1K

+



1 td 1

Xt

i;d

(7)



+ bd td

(8)

Kl 1 b. simplify comparison Ts assuming
8l : Kl = 1; Kl dropped inequality becomes equality (because
maxima must equal):
Tp

= t0 + bt1 + b2 t2 + + bd 1 td

1

+ bd td

(9)

1

+ bd td

(10)

Note Ts
Ts

= bd t0 + bd t1 + bd t2 + + bd td

clear, then, speedup governed bd tk terms compare
bk tk terms. (In worst case, Kk = b, latter become bk+1 tk .) therefore
introduce Rl;m follows:

bm tk
(11)
Rl;m = km=l k

k =l b tk

P
P

R coecients always 1 (if tm dominates) bm l (if tl strongly dominates);
tl equal, Rl;m approximately l.
Further, similar c previous analysis, define

P =0 b
c = P

= +1 b
l

l
k


k l

150

k

k

k

k

(12)

fiImproving Efficiency ILP Query Packs
algebra gives

Ts
Tp

=

bd l cl R0;l + Rl+1;d
cl + 1

(13)

needs hold l. interpret follows: certain level l, cl roughly
ects speedup gained fact part till level l needs executed
once; R factors ect speedup obtained within parts pack
mechanism.
inequality holds l, hence find best lower bound speedup factor maximizing right hand side. Note cl increases bd l decreases
monotonically l. clear point cl becomes much larger 1,
speedup factor roughly bd l obtained. hand, cl smaller 1,
behaviour bd l cl crucial. Now,
bd l cl

tl + 1 tl 1 + + b1l t0
= 1 b
:
td + b td 1 + + bd 1l 1 tl+1

conclusion similar one-level pack. l, cl >> 1, i.e.,
upper part pack (up till level l) computations take place expensive
dominate computations level l (even taking account latter
performed bd l times often), speedup bd l expected. cl << 1,
usually case l except near d, speedup roughly
estimated tl =td . maximum factors determine actual speedup.
4. Adapting ILP Algorithms Use Query Packs

section discuss execution method included ILP algorithms, illustrate detail two existing ILP algorithms. Experimental
results concerning actual eciency improvements yields presented next section.

4.1 Refinement Single Rule
Many systems inductive logic programming use algorithm consists repeatedly
refining clauses. systems could principle rewritten make use query
pack evaluation mechanism thus achieve significant eciency gain. first show
concrete algorithm decision tree induction, discuss general case.
4.1.1 Induction Decision Trees

first algorithm discuss Tilde (Blockeel & De Raedt, 1998), algorithm
builds first-order decision trees. first-order decision tree, nodes contain literals
together conjunction literals nodes node (i.e., path
root node) form query run example decide
subtree sorted into. building tree, literal (or conjunction
literals) put one node chosen follows: given query corresponding path
root node, generate refinements query (a refinement query

151

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
formed adding one literals query); evaluate refinements
relevant subset data,2 computing, e.g., information gain (Quinlan, 1993a) yielded
refinement; choose best refinement; put literals added
original clause form refinement node.
point clear lot computational redundancy exists refinement
evaluated separately. Indeed refinements contain exactly literals except
added single refinement step. Organising refinements one query pack,
obtain query pack essentially one level (the root immediately branches
leaves). Tilde's lookahead facility used (Blockeel & De Raedt, 1997), refinements
form lattice query pack may contain multiple (though usually few) levels.
Note root packs may consist conjunction many literals, giving
pack broom-like form. literals root pack, greater benefit
query pack execution expected be.

Example 4 Assume node currently refined following query associated

it: ?- circle(A,C),leftof(A,C,D),above(A,D,E), i.e., node covers examples
circle left object yet another object.
query pack generated refinement could instance

circle(A,C), leftof(A,C,D), above(A,D,E),

triangle(A,F)
circle(A,H)
small(A,I)
large(A,J)
in(A,E,K)
in(A,D,L)
in(A,C,M)
above(A,E,N)
above(A,D,O)
above(A,C,P)
leftof(A,E,Q)
leftof(A,D,R)
leftof(A,C,S)

evaluating pack, backtracking root pack (the \stick"
broom) happen once, instead refinement. words:
evaluating queries one one, query Prolog engine needs search
objects C , E fulfilling constraint circle(A,C), leftof(A,C,D),
above(A,D,E); executing pack search done once.
4.1.2 Algorithms Based Rule Refinement

mentioned, ILP algorithm consists repeatedly refining clauses could principle rewritten make use query pack evaluation mechanism thus achieve
significant eciency gain. Consider, e.g., rule induction system performing search
refinement lattice, Progol (Muggleton, 1995). Since imposes certain order clauses considered refinement, hard reorganise
computation level. However, taking one node list open nodes
producing refinements, evaluation refinements involves executing
them; replaced pack execution, case positive eciency gain
guaranteed. principle one could perform several levels refinement stage,
2. I.e., subset original data set parent query succeeded; or, decision tree
context: examples sorted node refined.

152

fiImproving Efficiency ILP Query Packs
adding refinements 's queue; part eciency lost,
pack execution mechanism exploited larger extent. two effects
dominant depend application: first-level refinements would
refined anyway point search, clearly gain
executing two-level pack; otherwise may loss eciency. instance,
executing two-level pack takes x times much time one-level pack, bring
eciency gain least x first level refinements would afterwards refined
themselves.

4.2 Level-wise Frequent Pattern Discovery
alternative family data mining algorithms scans refinement lattice breadthfirst manner queries whose frequency exceeds user-defined threshold. bestknown instance level-wise algorithms Apriori method finding frequent
item-sets (Agrawal et al., 1996). Warmr (Dehaspe & Toivonen, 1999) ILP variant
attribute-value based Apriori.
Query packs Warmr correspond hash-trees item-sets Apriori: used
store subgraph total refinement lattice level n. paths root
level n 1 subgraph correspond frequent patterns. paths root
leaves depth n correspond candidates whose frequency computed.
hash-trees Apriori, query packs Warmr exploit massive similarity
candidates make evaluation ecient. Essentially Warmr algorithm starts
empty query pack iterates pack evaluation pack extension (see
Figure 8). latter achieved adding potentially frequent refinements3 leaves
pack, i.e., adding another level total refinement lattice.
5. Experiments

goal experimental evaluation empirically investigate actual speedups
obtained re-implementing ILP systems use pack execution
mechanism. moment re-implementations exist Tilde Warmr
systems, hence used experiments. re-implementations
available within ACE data mining tool, available academic use upon request.4
attempt quantify (a) speedup packs w.r.t. separate execution queries (thus
validating complexity analysis), (b) total speedup yield
ILP system.
data sets used experiments following:



Mutagenesis data set : ILP benchmark data set, introduced ILP community Srinivasan et al. (1995), consists structural descriptions 230
molecules classified mutagenic not. Next standard Mutagenesis data set, consider versions example occurs n times;

3. Refinements found specialisations infrequent queries cannot frequent themselves,
pruned consequently.
4. See http://www.cs.kuleuven.ac.be/~dtai/ACE/.

153

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele

circle(A,B)

triangle(A,B)

leftof(A,B,C) above(A,B,C) leftof(A,B,C)

EXPAND

circle(A,B)

leftof(A,B,C)

triangle(A,B)

above(A,B,C)

leftof(A,B,C)

circle(A,C)triangle(A,C) circle(A,C)triangle(A,C) circle(A,C)triangle(A,C)
EVALUATE
circle(A,B) triangle(A,B)
above(A,B,C)

leftof(A,B,C)

triangle(A,C) circle(A,C)triangle(A,C)

circle(A,B)

EXPAND

above(A,B,C)
triangle(A,C)

triangle(A,B)
leftof(A,B,C)

circle(A,C)

triangle(A,C)

leftof(A,C,D) leftof(A,C,D) above(A,C,D) leftof(A,C,D)

Figure 8: sequence 4 query packs Warmr. Refinement left query
pack results 3-level pack right. Removal queries found infrequent
pack evaluation results bottom left pack. Finally, another level
added second query expansion step produce bottom right pack.
iteration expansion evaluation continues pack empty.
allows us easily generate data sets larger size average example
query complexity constant equal original data set.



Bongard data sets : introduced ILP De Raedt Van Laer (1995), so-called
\Bongard problems" simplified version problems used Bongard (1970)
research pattern recognition. number drawings shown containing
number elementary geometrical figures; drawings classified according
relations hold figures them. use Bongard problem generator
create data sets varying size.

experiments run SUN workstations: Sparc Ultra-60 360 MHz
Tilde, Sparc Ultra-10 333 Mhz Warmr. Tilde Warmr run
default settings, except mentioned differently.

5.1 Tilde
consider three different ways Tilde run ilProlog implementation:
1. packs: normal implementation Tilde described Blockeel De Raedt
(1998), queries generated one one evaluated relevant
examples. Since queries represented terms, evaluation query involves
meta-call Prolog.

154

fiImproving Efficiency ILP Query Packs
2. Disjoint execution packs: query pack executed queries pack
put beside one another; i.e., common parts shared queries.
computational redundancy executing pack executing
queries one another; main difference case queries
compiled.
3. Packed execution packs: compiled query pack executed queries share
much possible.
interesting information obtained comparing (a) actual query evaluation time settings 2 3: gives view eciency gain obtained
removal redundant computation (we abbreviate exec tables);
(b) total execution time settings 1 3: provides indication
much gained implementing packs ILP system, taking effects account (re-implementation computation heuristics via bit matrix, use compiled
queries instead meta-calls, etc.), words: net effect whole
re-implementation (indicated net tables).
first experiment used Bongard problems, varying (1) size data sets;
(2) complexity target hypothesis; (3) Tilde's lookahead parameter.
complexity target hypothesis small, medium, none. latter case
examples random, causes Tilde grow ever larger trees attempt find
good hypothesis; size final tree typically depends size data
set. lookahead parameter used control number levels pack contains;
lookahead n, packs depth n + 1 generated.
Table 1 gives overview results Bongard problems. total induction
time reported, well (for pack-based execution mechanisms) time needed
pack compilation pack execution. Note total time includes pack
compilation execution, computations directly related packs
(e.g., computation heuristics bitmatrix). results interpreted
follows.
First all, table shows significant speedups obtained using pack
mechanism; net speedups factor 5.5 obtained, execution
75 times faster compared disjoint execution.
observation complex target hypotheses greater speedups
obtained. explained broom-like form packs Tilde. Complex
target hypotheses correspond deep trees, refinement node lower level
tree yields pack long clause branching, accordance
previous analysis yield speedup closer branching factor b case
lookahead 0 (and generally, closer bl+1 lookahead l, although latter
much harder achieve). Note maximum branching factor occurring pack
included table column bf .
Finally, deeper packs yield higher speedups, effect larger complex
theories. understandable considering following. Let us call clause
refined c. lookahead l, conjunctions l + 1 literals added clause.
cases first l + 1 literals may fail immediately, causes branch
pack almost execution time, cutting away bl queries. Remember

155

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
LA

bf

0
1
2
3

16
24
18
21

0
1
2
3

16
24
18
21

0
1
2
3

19
24
18
21

0
1
2
3

19
21
15
18

0
1
2
3

22
24
27
18

0
1
2
3

25
24
27
27

0
1
2
3

28
24
24
30

0
1
2
3

31
36
33
33

0
1
2
3

31
39
39
42

original

0.74
2.44
7.49
29.9

1.82
5.72
17.2
69.8

3.69
11.4
34.7
142

1.01
3.26
6.36
27.2

3.16
8.38
38.5
124

6.35
18.14
119
384

4.74
16.32
87.5
373

12.7
65.1
430
1934

25.3
154
1185
4256

disjoint
packed
comp exec total comp
Simple target hypothesis
1007 examples
0.62
0.14
0.13
0.49
0.05
1.64
0.35
0.45
1.09
0.14
4.07
0.8
1.57
2.15
0.27
16.52
3.65
7.26
7.18
1.26
2473 examples
1.43
0.17
0.34
1.13
0.07
3.34
0.34
1.17
2.24
0.11
8.45
0.78
3.95
4.4
0.27
33.0
3.57
17.5
13.7
1.13
4981 examples
2.72
0.29
0.67
2.16
0.12
6.22
0.35
2.41
4.17
0.13
16.0
0.74
8.14
8.24
0.25
62.4
3.61
36.5
24.9
1.09
Medium complexity target hypothesis
1031 examples
0.93
0.29
0.18
0.66
0.11
2.8
0.98
0.56
1.66
0.35
3.47
0.68
1.22
1.95
0.25
14.6
3.75
5.75
6.71
1.20
2520 examples
2.82
0.89
0.62
1.91
0.3
5.88
1.5
1.86
3.3
0.44
29.8
13.14 9.52
10.3
2.44
58.02
10.3
28.6
23.9
3.00
5058 examples
5.41
1.47
1.3
3.73
0.56
12.98
3.2
4.15
7.5
0.93
93.2
38.1
31.0
35.3
9.09
275
108
89.1
106
25.9
target hypothesis
1194 examples
6.65
3.34
0.94
3.93
0.98
21.29
10.97 2.24 11.65 3.41
130
82.3
13.8
54.7
20.4
519
316
61.1
220
74.9
2986 examples
16.5
7.04
2.68
9.8
2.16
83.7
42.9
10.7
42.47
11.2
606
396
84
211.3
82.58
2592
1610
375
946
332
6013 examples
30.3
11.8
5.53
18.3
3.53
198
91.2
33.4
99.9
22.0
1733
1076
358
504
197
6932
4441 1091 2006
695
total

speedup

exec

net

exec

0.07

1.51

1.86

0.11

2.24

4.09

0.16

3.48

9.81

0.28

4.17

25.9

0.16

1.61

2.13

0.3

2.55

3.9

0.39

3.92

10.1

0.69

5.11

25.4

0.32

1.71

2.09

0.63

2.74

3.83

0.88

4.21

9.25

1.45

5.69

25.1

0.07

1.53

2.57

0.14

1.96

4

0.15

3.26

8.13

0.27

4.06

21.3

0.24

1.65

2.58

0.41

2.54

4.54

0.6

3.73

15.9

1.11

5.21

25.7

0.53

1.70

2.45

0.91

2.42

4.56

1.7

3.36

18.2

2.83

3.62

31.5

0.20

1.21

4.70

0.31

1.40

7.23

0.57

1.60

24.1

1.34

1.70

45.6

0.56

1.30

4.79

1.14

1.53

9.39

2.57

2.03

32.6

6.58

2.04

57.0

1.27

1.38

4.35

3.13

1.54

10.7

9

2.35

39.8

14.5

2.12

75.4

Table 1: Timings Tilde runs Bongard data sets. LA = lookahead setting; bf =
maximum branching factor. Reported times (in seconds) total time needed
build tree, time spent compilation respectively execution packs.

156

fiImproving Efficiency ILP Query Packs
LA original
0
1
2

31.5
194.99
2193

0
1
2

27.6
38.02
638

disjoint
packed
total comp exec total comp
Regression, 230 examples
52.9 1.96 25.5 45.5 1.02
248 55.9 109 107 12.6
{
{
{
891
192
Classification, 230 examples
27.3 1.83 4.71 25.4 1.13
40.3 7.55 9.09 30.6 3.11
{
{
{
149 74.3

Table 2: Timings Tilde runs Mutagenesis.
ended prematurely.

exec

speedup ratio
net
exec

19.25 0.69
16.6 1.82
32.0 2.46

1.33
6.53
{

3.42
3.65
6.16

1.38
2.49
{

1.09
1.24
4.2

table indicates run

according analysis, speedup limit approximate bl complexity
clause c dominates complexity rest pack; \early failing branches"
pack cause actual situation approximate closer ideal case.
run experiments Mutagenesis data set (Table 2), regression
classification setting. Here, query packs much larger Bongard data set
(there higher branching factor); lookahead 2 largest packs 20000
queries. large packs significant amount time spent compiling pack,
even clear net speedups obtained.5 comparison execution times turned
infeasible disjoint execution setting pack structures consumed much
memory.

5.2 Warmr
5.2.1 Used Implementations

Warmr consider following implementations:
1. packs: normal implementation Warmr, queries generated,
examples queries evaluated one one.
2. packs: implementation first queries one level generated
put pack, pack evaluated example.
5.2.2 Datasets

Mutagenesis used Mutagenesis dataset 230 molecules, example
repeated 10 times make accurate timings possible better idea
effect larger datasets. used three different language biases. 'small' language
5. one case, relatively small pack, system became slower. timings indicate
due compilation time, changes implementation relatively
simple problem compensated faster execution packs.

157

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele

Level
1
2
3
4
5
6
7
8
9

small

Mutagenesis

medium

large

Queries Frequent Queries Frequent Queries Frequent
8
5
37
26
45
31
60
14
481
48
1071
211
86
24
688
114
3874
1586
132
31
699
253
37
21
697
533
29
18
1534
1149
23
15
{
{
17
12
{
{
4
4
{
{

Table 3: Number queries Mutagenesis experiment Warmr.
bias chosen generate limited number refinements (i.e., relatively
small branching factor search lattice); allows us generate query packs
relatively deep narrow. 'medium' 'large' use broader shallow packs.
Table 3 summarises number queries number frequent queries found
level different languages.

Bongard use Bongard-6013 experiments

Warmr system
construct theory hence existence simple theory expected make much
difference.
5.2.3 Results

Tables 4, 5 6 execution times Warmr Mutagenesis given, maximal
search depth varying 3 large language 9 levels small language. Here,
'total' total execution time 'exec' time needed test queries
examples. Table 7 execution times Warmr Bongard given.
5.2.4 Discussion

execution time Warmr large component used evaluate queries.
caused fact Warmr needs lot administrative work.
particular, theta-subsumption tests done queries check wether query
equivalent another candidate, query specialisation infrequent one.
propositional case (the Apriori algorithm), tests simple,
first order case require exponential time size queries. course,
using larger datasets, relative contribution administrative costs decrease
proportionally. observed deeper levels, costs less setting
using packs. One causes fact no-packs version uses memory
packs setting (and hence causes proportionally memory management).
again, important numbers speedup factors execution
queries. Speedup factors query execution always increase increasing depth

158

fiImproving Efficiency ILP Query Packs

Level
1
2
3
4
5
6
7
8
9

packs
packs ilProlog
total
exec
total
exec
0.35
0.23
0.18
0.15
6.27
5.60
4.56
4.12
36.93
31.49 14.01
9.87
117.33 84.45
45.14
16.27
215.95 104.36 129.37
20.78
336.35 111.28 249.41
22.39
569.14 115.80 497.86
24.63
902.72 120.99 831.30
25.98
1268.16 119.60 1148.23
32.28

speedup ratio
net
exec
1.94 1.53
1.38 1.36
2.64 3.19
2.60 5.19
1.67 5.02
1.35 4.97
1.14 4.70
1.09 4.66
1.10 3.71

Table 4: Results Warmr Mutagenesis dataset using small language.

Level
1
2
3
4
5
6

packs
packs ilProlog
total
exec
total
exec
2.58
2.27
2.16
2.09
112.98
42.32
34.35
13.39
735.19 128.67 262.83
34.70
4162.15 287.72 1476.06
54.10
17476.98 444.44 6870.16
73.11
65138.72 866.85 25921.73
104.81

speedup ratio
net
exec
1.19 1.09
3.29 3.16
2.80 3.71
2.82 5.32
2.54 6.08
2.51 8.27

Table 5: Results Warmr Mutagenesis dataset using medium language.

Level
1
2
3

packs
packs ilProlog
total
exec
total
exec
2.82
2.42
2.28
2.11
408.85
102.38 102.29
50.67
27054.33 1417.76 3380.19
370.44

speedup ratio
net
exec
1.24 1.15
4.00 2.02
8.00 3.83

Table 6: Results Warmr Mutagenesis dataset using large language.

159

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
Level
1
2
3
4
5
6
7
8
9
10

packs
total
exec
0.24
0.22
0.83
0.75
3.28
2.82
11.56 9.31
38.34 28.11
75.51 46.97
135.64 71.60
186.23 84.93
210.82 88.97
216.61 89.38
Table 7:

packs ilProlog
total
exec
0.24
0.23
0.77
0.68
2.34
1.92
6.08
4.28
16.20
8.15
36.57
12.22
68.96
15.59
102.46
17.82
120.76
18.52
125.84
18.88

Warmr

speedup ratio
net
exec
1.00 0.96
1.08 1.10
1.40 1.47
1.90 2.18
2.37 3.45
2.06 3.84
1.97 4.59
1.82 4.77
1.75 4.80
1.72 4.73

results Bongard.

packs, contrast Tilde larger packs yielded higher speedups. first sight
found surprising; however becomes less following observation made.
refining pack new pack adding level, Warmr prunes away branches
lead infrequent queries. thus two effects adding level pack:
one widening pack lowest level (at least first levels, new
pack typically leaves previous one), second narrowing
pack whole (because pruning). Since speedup obtained using packs largely
depends branching factor pack, speedup factors expected decrease
narrowing effect stronger widening-at-the-bottom effect.
seen, e.g, small-mutagenesis experiment, deepest levels queries
becoming less frequent. mutagenesis experiment medium size language,
query execution speedup factors larger number queries increases much faster.
mutagenesis experiment large language, total speedup large,
language generates many queries time-consuming part becomes
administration storage memory. packs version much faster stores
queries trees, requiring significantly less memory.

5.3 Comparison Engines
Implementing new special-purpose Prolog engine, different already existing ones,
carries risk: given level sophistication popular Prolog engines, useful check
whether new engine performs comparably existing engines, least
tasks consideration here. eciency gain obtained query pack execution
offset less ecient implementation engine itself.
Originally Tilde Warmr systems implemented MasterProLog.
attempt allow run platforms, parts systems reimplemented kind \generic" Prolog implementations specific Prolog engines (SICStus, ilProlog) easily derived (the low level standardisation
Prolog made necessary). Given situation, two questions answered:

160

fiImproving Efficiency ILP Query Packs
Data set
LA
Bongard-1194 0
Bongard-2986 0
Bongard-6013 0
Bongard-1007 0
Bongard-2473 0
Bongard-4981 0
Bongard-1007 2
Bongard-2473 2
Bongard-4981 2
Table 8:

MasterProLog ilProlog(original) ilProlog(packs)
7.8
17.8
35
0.77
2.07
4.1
7.1
17.7
38

4.74
12.7
25
0.74
1.82
3.7
7.5
17.2
35

3.93
9.8
18
0.49
1.13
2.2
2.2
4.4
8.2

compared engines (times seconds) several data sets
lookahead settings.

ilProlog

(a) move MasterProLog Prolog engines uence performance
negative way; (b) performance loss, any, reduce performance improvements due use packs?
Tilde Warmr tuned fast execution MasterProLog ilProlog SICStus, makes comparison latter unfair; therefore
report former 2 engines. Table 8 shows results. confirm
ilProlog competitive state-of-the-art Prolog engines.

5.4 Summary Experimental Results
experiments confirm (a) query pack execution much ecient
executing many highly similar queries separately; (b) existing ILP systems (we use Tilde
Warmr examples) use mechanism advantage, achieving significant
speedups; c) although new Prolog engine needed achieve this, current state
development engine respect execution speed compete
state-of-the-art engines. Further, experiments consistent complexity
analysis execution time packs.
6. Related Work

re-implementation Tilde related work Mehta et al. (1996)
first describe \examples outer loop" strategy decision tree induction.
query pack execution mechanism, described Prolog execution point view,
seen first-order counterpart Apriori's mechanism counting item-sets
(Agrawal et al., 1996).
lines work eciency improvements ILP involves stochastic methods
trade certain amount optimality eciency by, e.g., evaluating clauses
sample data set instead full data set (Srinivasan, 1999), exploring clause
search space random fashion (Srinivasan, 2000), stochastically testing whether

161

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
query succeeds example (Sebag & Rouveirol, 1997). first entirely
orthogonal query pack execution easily combined it.
idea optimising sets queries instead individual queries existed
database community. typical context considered earlier research
multi-query optimisation (e.g., Sellis, 1988) database system needs
handle disjunctions conjunctive queries, server may receive many queries
different clients brief time interval. several queries expected compute
intermediary relations, may ecient materialise relations
instead recomputed query. Data mining provides sense new
context multi-query optimisation, multi-query optimisation approach
time easier (the similarities among queries systematic, one need
look them) promising (given huge number queries may
generated once).
Tsur et al. (1998) describe algorithm ecient execution so-called query ocks
context. query pack execution mechanism, query ock execution mechanism inspired extent Apriori set deductive database setting.
main difference query packs query ocks described Tsur et al.
(1998) query packs hierarchically structured queries pack
structurally less similar queries ock. (A ock represented single query
placeholders constants, equal set queries obtained
instantiating placeholders constants. Flocks could used applications
consider here.)
Dekeyser Paredaens (2001) describe work multi-query optimisation context
relational databases. consider tree-like structures multiple queries
combined; main difference trees rooted one single table
queries select tuples, whereas queries correspond joins multiple tables. Further,
Dekeyser Paredaens define cost measure trees well operators map trees
onto semantically equivalent (but less costly) trees, whereas considered
creation packs ecient top-down execution mechanism them. Combining
approaches seems interesting topic research.
Finally, optimisation techniques ILP proposed exploit results
program analysis (Santos Costa et al., 2000; Blockeel et al., 2000) propositional
data mining technology (Blockeel et al., 1999). complementary pack
execution optimisation. Especially approach Blockeel et al. (1999) easily
combined pack mechanism. techniques discussed Santos Costa et al.
(2000) Blockeel et al. (2000) involve optimisations single query execution,
extent upgraded pack setting. future work.
7. Conclusions

lot redundancy computations performed ILP systems.
paper identified source redundancy proposed method avoiding it:
execution query packs. discussed query pack execution incorporated
ILP systems. query pack execution mechanism implemented new
Prolog system called ilProlog dedicated data mining tasks, two ILP systems

162

fiImproving Efficiency ILP Query Packs
re-implemented make use mechanism. experimentally evaluated
re-implementations, results experiments confirm large speedups
may obtained way. conjecture query pack execution mechanism
incorporated ILP systems similar speedups expected.
problem setting query pack execution introduced general,
allows technique used kind task many queries executed
data, long queries organised hierarchy.
Future work includes improvements ilProlog engine implementation techniques increase suitability engine handle large data sets.
best case one might hope combine techniques known database optimisation
program analysis pack execution mechanism improve speed
ILP systems.

Acknowledgements
Hendrik Blockeel post-doctoral fellow Fund Scientific Research (FWO)
Flanders. Jan Ramon funded Flemish Institute Promotion Scientific
Research Industry (IWT). Henk Vandecasteele funded part FWO project
G.0246.99, \Query languages database mining". authors thank Luc De Raedt
uence work, Ashwin Srinivasan suggesting term \query packs",
anonymous reviewers useful comments, Kurt Driessens proofreading
text. work motivated part Esprit project 28623, Aladin.
Appendix A. Preparing Query Meta-interpreter

Note following preprocessor assumes pack form a, (b, (c
e) f g, (h j)) already transformed form , or([(b,
or([c,d,e])), f, (g, or([h,i,j]))]).
preprocess((A,B),(A,NewB),PrevNode,NodeNr0,LeafNr0,BranchNr,NodeNr1,LeafNr1):- !,
preprocess(B,NewB,PrevNode,NodeNr0,LeafNr0,BranchNr,NodeNr1,LeafNr1).
preprocess(or(Querys),or(NQuerys,PrevNode,NodeNr0,BranchNr,Length),
PrevNode,NodeNr0,LeafNr0,BranchNr, NodeNr1,LeafNr1):- !,
NodeNr2 NodeNr0 + 1,
preprocessbranches(Querys,NQuerys,NodeNr0,NodeNr2,LeafNr0,
1,NodeNr1,LeafNr1,Length).
preprocess(A,(A,leaf(PrevNode,BranchNr,LeafNr0)),
PrevNode,NodeNr0,LeafNr0, BranchNr,NodeNr0,LeafNr1):LeafNr1 LeafNr0 + 1.
preprocessbranches([],[], ,NodeNr,LeafNr,BranchNr, NodeNr,LeafNr,BranchNr).
preprocessbranches([QueryjQuerys],[NewQueryjNewQuerys],PrevNode,
NodeNr0,LeafNr0,BranchNr, NodeNr1,LeafNr1,Length):preprocess(Query,NewQuery,
PrevNode,NodeNr0,LeafNr0,BranchNr, NodeNr2,LeafNr2),
BranchNr1 BranchNr + 1,
preprocessbranches(Querys,NewQuerys, PrevNode,
NodeNr2,LeafNr2,BranchNr1, NodeNr1,LeafNr1,Length).

163

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele

References

Agrawal, R., Mannila, H., Srikant, R., Toivonen, H., & Verkamo, A. (1996). Fast discovery
association rules. Fayyad, U., Piatetsky-Shapiro, G., Smyth, P., & Uthurusamy,
R. (Eds.), Advances Knowledge Discovery Data Mining, pp. 307{328. MIT
Press.
At-Kaci, H. (1991). Warren's Abstract Machine: Tutorial Reconstruction. MIT
Press, Cambridge, Massachusetts.
http://www.isg.sfu.ca/~hak/documents/wam.html.
Blockeel, H. (1998). Top-down induction first order logical decision trees. Ph.D. thesis,
Department Computer Science, Katholieke Universiteit Leuven.
http://www.cs.kuleuven.ac.be/~ml/PS/blockeel98:phd.ps.gz.
Blockeel, H., & De Raedt, L. (1997). Lookahead discretization ILP. Proceedings
Seventh International Workshop Inductive Logic Programming, Vol. 1297
Lecture Notes Artificial Intelligence, pp. 77{85. Springer-Verlag.
Blockeel, H., & De Raedt, L. (1998). Top-down induction first order logical decision trees.
Artificial Intelligence, 101 (1-2), 285{297.
Blockeel, H., De Raedt, L., Jacobs, N., & Demoen, B. (1999). Scaling inductive logic programming learning interpretations. Data Mining Knowledge Discovery,
3 (1), 59{93.
Blockeel, H., De Raedt, L., & Ramon, J. (1998). Top-down induction clustering trees.
Proceedings 15th International Conference Machine Learning, pp. 55{63.
http://www.cs.kuleuven.ac.be/~ml/PS/ML98-56.ps.
Blockeel, H., Demoen, B., Janssens, G., Vandecasteele, H., & Van Laer, W. (2000). Two
advanced transformations improving eciency ILP system. 10th
International Conference Inductive Logic Programming, Work-in-Progress Reports,
pp. 43{59, London, UK.
Bongard, M. (1970). Pattern Recognition. Spartan Books.
Bratko, I. (1990). Prolog Programming Artificial Intelligence. Addison-Wesley, Wokingham, England. 2nd Edition.
Breiman, L., Friedman, J., Olshen, R., & Stone, C. (1984). Classification Regression
Trees. Wadsworth, Belmont.
Chen, W., & Warren, D. S. (1996). Tabled evaluation delaying general logic programs. Journal ACM, 43 (1), 20{74. http://www.cs.sunysb.edu/~sbprolog.
Clark, P., & Niblett, T. (1989). CN2 algorithm. Machine Learning, 3 (4), 261{284.
De Raedt, L. (1997). Logical settings concept learning. Artificial Intelligence, 95, 187{
201.
De Raedt, L., & Dehaspe, L. (1997). Clausal discovery. Machine Learning, 26, 99{146.

164

fiImproving Efficiency ILP Query Packs
De Raedt, L., & Dzeroski, S. (1994). First order jk-clausal theories PAC-learnable.
Artificial Intelligence, 70, 375{392.
De Raedt, L., & Van Laer, W. (1995). Inductive constraint logic. Jantke, K. P., Shinohara, T., & Zeugmann, T. (Eds.), Proceedings Sixth International Workshop
Algorithmic Learning Theory, Vol. 997 Lecture Notes Artificial Intelligence, pp.
80{94. Springer-Verlag.
Dehaspe, L., & Toivonen, H. (1999). Discovery frequent datalog patterns. Data Mining
Knowledge Discovery, 3 (1), 7{36.
Dekeyser, S., & Paredaens, J. (2001). Query pack trees multi query optimization. Tech.
rep. 01-04, University Antwerp. ftp://wins.uia.ac.be/pub/dekeyser/qpt.ps.
Demoen, B., Janssens, G., & Vandecasteele, H. (1999). Executing query flocks ILP.
Etalle, S. (Ed.), Proceedings Eleventh Benelux Workshop Logic Programming,
pp. 1{14, Maastricht, Netherlands. 14 pages.
Kramer, S. (1996). Structural regression trees. Proceedings Thirteenth National
Conference Artificial Intelligence, pp. 812{819, Cambridge/Menlo Park. AAAI
Press/MIT Press.
Mehta, M., Agrawal, R., & Rissanen, J. (1996). SLIQ: fast scalable classifier data
mining. Proceedings Fifth International Conference Extending Database
Technology.
Muggleton, S. (1995). Inverse entailment Progol. New Generation Computing, Special
issue Inductive Logic Programming, 13 (3-4), 245{286.
Muggleton, S., & De Raedt, L. (1994). Inductive logic programming : Theory methods.
Journal Logic Programming, 19,20, 629{679.
Quinlan, J. R. (1993a). C4.5: Programs Machine Learning. Morgan Kaufmann series
machine learning. Morgan Kaufmann.
Quinlan, J. (1993b). FOIL: midterm report. Brazdil, P. (Ed.), Proceedings 6th
European Conference Machine Learning, Lecture Notes Artificial Intelligence.
Springer-Verlag.
Santos Costa, V., Srinivasan, A., & Camacho, R. (2000). note two simple transformations improving eciency ILP system. Proceedings Tenth
International Conference Inductive Logic Programming, Vol. 1866 Lecture Notes
Artificial Intelligence, pp. 225{242. Springer-Verlag.
Sebag, M., & Rouveirol, C. (1997). Tractable Induction Classification First-Order
Logic via Stochastic Matching. Proceedings 15th International Joint Conference Artificial Intelligence. Morgan Kaufmann.
Sellis, T. (1988). Multiple-query optimization. ACM Transactions Database Systems,
13 (1), 23{52.
Srinivasan, A. (1999). study two sampling methods analysing large datasets
ILP. Data Mining Knowledge Discovery, 3 (1), 95{123.
Srinivasan, A. (2000). study two probabilistic methods searching large spaces
ILP. Tech. rep. PRG-TR-16-00, Oxford University Computing Laboratory.

165

fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
Srinivasan, A., Muggleton, S., & King, R. (1995). Comparing use background knowledge inductive logic programming systems. De Raedt, L. (Ed.), Proceedings
Fifth International Workshop Inductive Logic Programming.
Tsur, D., Ullman, J., Abiteboul, S., Clifton, C., Motwani, R., Nestorov, S., & Rosenthal, A.
(1998). Query ocks: generalization association-rule mining. Proceedings
ACM SIGMOD International Conference Management Data (SIGMOD-98),
Vol. 27,2 ACM SIGMOD Record, pp. 1{12, New York. ACM Press.

166


