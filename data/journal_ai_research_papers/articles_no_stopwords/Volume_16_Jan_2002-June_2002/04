Journal Artificial Intelligence Research 16 (2002) 167-207

Submitted 3/01; published 3/02

Learning Geometrically-Constrained Hidden Markov Models
Robot Navigation: Bridging Topological-Geometrical Gap
Hagit Shatkay

hagit.shatkay@celera.com

Informatics Research Group,
Celera Genomics, Rockville, MD 20850

Leslie Pack Kaelbling

Artificial Intelligence Laboratory
Massachusetts Institute Technology, Cambridge, 02139

lpk@ai.mit.edu

come place streets marked.
windows lighted mostly they're darked.
place could sprain elbow chin!
dare stay out? dare go in?...
go in, turn left right...
right-and-three-quarters? or, maybe, quite?...
Simple it's not, I'm afraid find,
mind-maker-upper make mind.

Oh, Places You'll Go, Dr. Seuss.

Abstract
Hidden Markov models (hmms) partially observable Markov decision processes
(pomdps) provide useful tools modeling dynamical systems. particularly
useful representing topology environments road networks oce
buildings, typical robot navigation planning. work presented
describes formal framework incorporating readily available odometric information geometrical constraints models algorithm learns
them. taking advantage information, learning hmms/pomdps made
generate better solutions require fewer iterations, robust face
data reduction. Experimental results, obtained simulated real robot
data, demonstrate effectiveness approach.

1 Introduction

work concerned robots need perform tasks structured environments.
robot moving environment suffers two main limitations: noisy sensors prevent
confidently knowing is, noisy effectors prevent knowing
certainty actions take it. concentrate structured environments,
turn characterized two main properties: environments consist vast uneventful uninteresting areas, interspersed relatively interesting positions
situations. Consider instance robot delivering bagel oce building. interesting
situations doors intersections building hallways, well various
c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiShatkay & Kaelbling

positions bagel might respect robot's arm (e.g., robot holding
bagel, puts down, etc.) aspects environment, desk positions
oces, inconsequential bagel delivery task.
natural way represent combination environment robot's interactions
it, probabilistic automaton, states represent interesting situations,
edges states represent actions leading one situation another. Probability
distributions transitions possible observations robot may perceive
situation model robot's noisy effectors sensors, respectively.
models formally known pomdp (partially observable Markov decision process) models, proven useful robot planning acting inherent world uncertainty (Simmons & Koenig, 1995; Nourbakhsh, Powers, & Birchfield, 1995; Cassandra, Kaelbling, & Kurien, 1996).
Despite much work using models, task learning directly automatically
data widely addressed. Research concerning immediate topic date
consists mostly work done Simmons Koenig (1996b). assumption underlying
work human provides rather accurate topological model states
connections, exact probability distributions learned top model,
using version Baum-Welch algorithm (Rabiner, 1989). Another interesting approach
acquisition topological models Thrun Bucken (1996a,1996b; Thrun, 1999),
focused extracting deterministic topological maps previously acquired geometricalgrid-based maps, latter learned directly data. discussion
related research geometrical topological approaches, probabilistic
deterministic versions, given next section.
work reported first successful attempt aware learn purely probabilistictopological models, directly completely recorded data, without using previous humanprovided grid-based models. based using weak geometric information, recorded
robot, help learn topology environment, represent probabilistic
model. Therefore, directly bridges historically perceived gap topological
geometrical information, addresses claim presented Thrun's work (1999)
main shortcoming topological approach failure utilize inherent geometry
learnt environment.
robots equipped wheel encoders enable odometer record change
robot's position moves environment. data typically noisy
inaccurate. oors environment rarely smooth, wheels robot
always aligned neither motors, mechanics imperfect, resulting slippage
drift. effects accumulate, mark initial position robot,
try estimate current position based summing long sequence odometric recordings,
resulting estimate incorrect. is, raw recorded odometric information
effective tool, itself, determining absolute location robot
environment.
approach aimed determining absolute locations, idea underlying
weak odometric information, despite noise inaccuracy, still provides geometrical cues
help distinguish different states, well identify revisitation
state. Hence, information enhances ability learn topological models. However,
168

fiLearning Geometrically-Constrained HMMs

use geometrical information requires careful treatment geometrical constraints
directional data. demonstrate existing models algorithms extended
take advantage noisy odometric data geometrical constraints. geometrical
information directly incorporated probabilistic topological framework, producing
significant improvement standard Baum-Welch algorithm, without need humanprovided model.
rest paper organized follows: Section 2 provides survey previous work
area learning maps robot navigation, brie refers earlier work learning
automata; Section 3 presents formal framework work; Section 4 presents main
aspects iterative learning algorithm, Section 5 describes strategies selecting
initial point iterative process begins; Section 6 presents experimental results
obtained simulated real robot data traditionally hard-to-learn environments.
experiments demonstrate algorithm indeed converges better models fewer
iterations standard Baum-Welch method, robust face data reduction.

2 Approaches Learning Maps Models

work presented lies intersection theoretical area learning computational models|in particular, learning automata data sequences|and applied area
map acquisition robot navigation. concentrate surveying work latter
area, pointing distinction approach predecessors. brie review
results automata computational learning theory. comprehensive review
theoretical results given Shatkay (1999).

2.1 Modeling Environments Robot Navigation

context maps models robot navigation, distinction usually made two
principal kinds maps: geometric topological. Geometric maps describe environment
collection objects occupied positions space, geometric relationships among
them. topological framework less concerned geometrical positions, models
world collection states connectivity, is, states reachable
states actions lead one state next.
draw additional distinction, world-centric1 maps provide \objective"
description environment independent agent using map, robot-centric models
capture interaction particular \subjective" agent environment.
learning map, agent needs take account noisy sensors actuators try
obtain objectively correct map agents could use well. Similarly, agents
using map need compensate limitations order assess position
according map. learning model captures interaction, agent acquiring
model one using it. Hence, noisy sensors actuators specific agent
ected model. different model likely needed different agents.
related work described below, especially within geometrical framework, centered
around learning objective maps world rather agent-specific models. shall point
survey work concerned latter kind models.
work focuses acquiring purely topological models, less concerned learning
geometrical relationships locations objects, objective maps, although geometrical
1. thank Sebastian Thrun terminology.

169

fiShatkay & Kaelbling

relationships serve aid acquisition process. concept state used
topological framework general concept geometrical location, since state
include information battery level, arm position etc. information,
great importance planning, non-geometrical nature therefore cannot readily
captured purely geometrical framework. following sections provide survey work
done within geometrical framework within topological framework, well
combinations two approaches.

2.2 Geometric Maps

Geometric maps provide description environment terms objects placed
positions. example, grid-based maps instance geometric approach.
grid-based map, environment modeled grid (an array), position
grid either vacant occupied object (binary values placed array).
approach refined ect uncertainty world, grid cells
contain occupancy probabilities rather binary values. lot work done
learning grid-based maps robot navigation use sonar readings
interpretation, Moravec Elfes others (Moravec & Elfes, 1985; Moravec, 1988; Elfes,
1989; Asada, 1991).
underlying assumption learning maps robot tell (or find out)
grid obtains sonar reading indicating object, therefore
place object correctly grid. similar localization assumption, requiring robot
identify geometrical location, underlies geometric mapping techniques Leonard
et al. (1991), Smith et al. (1991), Thrun et al. (1998b) Dissanayake et al. (2001), even
explicit grid part model. Explicit localization hard satisfy.
Leonard et al. (1991) Smith et al. (1991) address issue use geometrical
beacons estimate location robot. known Kalman filter method,
Gaussian probability distribution used model robot's possible current location, based
observations collected current point, (without allowing refinement previous
position estimates based later observations). Research area recently extended
two directions: Leonard Feder (2000) partition task learning one large map
learning multiple smaller map-sections, thus addressing issue computational eciency.
Dissanayake et al. (2001) conduct theoretical study approach show convergence
properties. latter may lead computational eciency identifying cases
steady-state solution readily obtained, accordingly bounding number steps required
algorithms reach useful solution cases.
Work Thrun et al. (1998a) uses similar probabilistic approach obtaining grid-based maps.
work refined (Thrun et al., 1998b) first learn location significant landmarks
environment fill details complete geometrical grid, based laser range
scans. latter work extends approach Smith et al. , using observations obtained
location visited, order derive probability distribution
possible locations. achieve this, authors use forward-backward procedure similar
one used Baum-Welch algorithm (Rabiner, 1989), order determine possible
locations observed data. approach resembles use forwardbackward estimation procedure, probabilistic basis, aiming obtaining maximum
likelihood map environment. still significantly differs initial
assumptions final results. data assumed provided learner includes
170

fiLearning Geometrically-Constrained HMMs

motion model perceptual model robot. consist transition
observation probabilities within grid. components learnt algorithm,
although grid context coarser-grained, topological framework. end result
algorithm probabilistic grid-based map, probabilistic topological model,
explained next section.
addition concerned locations, rather richer notion state,
fundamental drawback geometrical maps fine granularity high accuracy. Geometrical maps, particularly grid-based ones, tend give accurate detailed picture
environment. cases necessary robot know exact location terms
metric coordinates, metric maps indeed best choice. However, many planning tasks
require fine granularity accurate measurements, better facilitated
abstract representation world. example, robot needs deliver bagel
oce oce b, needs map depicting relative location respect
b, passageways two oces, perhaps landmarks help orient
gets lost. reasonably well-operating low-level obstacle avoidance mechanism
help bypass ower pots chairs might encounter way, objects
need part environment map. driver traveling cities needs
know neither longitude latitude coordinates globe, location specific
houses along way, robot need know exact location within building
exact location various items environment, order get one point
another. Hence, effort obtaining detailed maps usually justified. addition
maps large, makes planning|even though planning polynomial
size map|inecient.

2.3 Topological Maps Models

alternative detailed geometric maps abstract topological maps.
maps specify topology important landmarks situations (states), routes transitions (arcs) them. concerned less physical location landmarks,
topological relationships situations. Typically, less complex
support much ecient planning metric maps. Topological maps built lowerlevel abstractions allow robot move along arcs (perhaps wall- road-following),
recognize properties locations, distinguish significant locations states;
exible allowing general notion state, possibly including information
non-geometrical aspects robot's situation.
two typical strategies deriving topological maps: one learn topological
map directly; first learn geometric map, derive topological model
process analysis.
nice example second approach provided Thrun Bucken (1996a, 1996b; Thrun,
1999), use occupancy-grid techniques build initial map. strategy appropriate
primary cues decomposition abstraction map geometric. However,
many cases, nodes topological map defined terms sensory data (e.g.,
labels door whether robot holding bagel). Learning geometric map first
relies odometric abilities robot; weak space large,
dicult derive consistent map.

171

fiShatkay & Kaelbling

contrast, work concentrates learning topological model directly, assuming abstraction robot's perception action abilities already done. abstractions
manually encoded lower level robot navigational software, described
Section 6. Work Pierce Kuipers (1997) discusses automatic method extracting
abstract states features raw perceptual information.
Kuipers Byun (1991) provide strategy learning deterministic topological maps. works
well domains noise robot's perception action abstracted
away, learning single visits nodes traversals arcs. strong underlying assumption
strategies, building map, current state reliably identified
based local information, based distance traversed previous well-identified
state. methods unable handle situations long sequences actions
observations necessary disambiguate robot's state.
Mataric (1990) provides alternative approach learning deterministic topological maps,
represented distributed graphs. learning process relies assumption
current state distinguished states based local information includes
compass sonar readings. Uncertainty modeled probability distributions.
Instead, matching current readings already existing states required exact,
thresholds tolerated error set empirically. Another difference work presented
here, learn complete probabilistic topology environment, Mataric's
work overall topology graph assumed advance linear list, additional
edges added learning process. probability distribution associated
edges, mechanism choosing edge take determined part goal seeking
process, part model itself.
Engelson McDermott (1992) learn \diktiometric" maps (topological maps metric relations nodes) experience. uncertainty model use interval-based rather
probabilistic, learned representation deterministic. Ad hoc routines handle problems resulting failures uncertainty representation.
prefer learn combined model world robot's interaction world;
allows robust planning takes account likelihood error sensing action.
work closely related Koenig Simmons (1996b, 1996a), learn pomdp
models (stochastic topological models) robot hallway environment. recognize
diculty learning good model without initial information; solve problem
using human-provided topological map, together constraints structure
model. modified version Baum-Welch algorithm learns parameters
model. developed incremental version Baum-Welch used on-line.
models contain weak metric information, representing hallways chains one-meter
segments allowing learning algorithm select probable chain length.
method effective, results large models size proportional hallways' length,
strongly depends quality human-provided initial model.

2.4 Learning Automata Data

Informally speaking, automaton consists set states set transitions lead
one state another. context work, automaton states correspond
states modeled environments, transitions, state changes due actions
performed environment. transition automaton tagged symbol
172

fiLearning Geometrically-Constrained HMMs

input alphabet, , corresponding action input system caused state
transition. Classical automata theory (e.g., Hopcroft & Ullman, 1979) distinguishes
deterministic non-deterministic automata. If, alphabet symbol ff, single
edge tagged it, going state, automaton deterministic. Otherwise,
transition states uniquely determined input symbol automaton
non-deterministic. augment transition edge non-deterministic automaton
probability taking given certain input, ff, resulting automaton called probabilistic.
basic problem learning finite deterministic automata given data roughly
described follows: Given set positive set negative example strings,
respectively, alphabet , fixed number states k, construct minimal deterministic
finite automaton k states accepts accept . problem
shown np-complete (Gold, 1978). Despite hardness, positive results
shown possible various special settings. Angluin (1987) showed oracle
answer membership queries provide counterexamples conjectures automaton,
polynomial time learning algorithm positive negative examples. Rivest
Schapire (1987, 1989), provide several effective methods, various settings, learn
deterministic automata correct high probability. work deals
learning noise-free data, Basye, Dean Kaelbling (1995) presented several algorithms
that, high probability, learn input-output deterministic automata, data observed
learner corrupted various forms noise.
cases, learned automaton deterministic rather probabilistic. basic
learning problem probabilistic context find automaton assigns
distribution true one data sequences, using training data , generated
true automaton. Another form learning problem finding probabilistic
automaton assigns maximum likelihood training data ; is, automaton
maximizes Pr(S j).
Abe Warmuth (1992) show finding probabilistic automaton 2 states, even
small error respect true model allowed probability (the probably
approximately correct, PAC, learning model), cannot done polynomial time polynomial number examples, unless np = rp. work arises broadly accepted
conjecture, yet proven, learning hidden Markov Models hard even
pac sense. two ways address hardness: one restrict class
probabilistic models learned, learn unrestricted hidden Markov models
good practical results pac guarantees quality result.
Work Ron et al. (1994, 1995, 1998) pursues first approach, learning restricted classes
automata, namely, acyclic probabilistic finite automata, probabilistic finite sux automata.
classes useful various applications related natural language processing,
learned polynomial time within pac framework.
second approach, one predominantly taken work, learn model
member complete unrestricted class hidden Markov models. weak guarantees
exist goodness model, learning procedure may directed obtain
practically good results. approach based guessing automaton (model), using
iterative procedure make automaton fit better training data. One algorithm
commonly used purpose Baum-Welch algorithm (Baum, Petrie, Soules, & Weiss,
1970), presented detail Rabiner (1989). iterative updates model
173

fiShatkay & Kaelbling

based gathering sucient statistics data given current automaton,
update procedure guaranteed converge model locally maximizes likelihood
function Pr(datajmodel). Since maximum local, model might close enough
true automaton data generated, challenging problem find
ways force algorithm converging higher-likelihood maxima, least make
converge faster, facilitating multiple guesses initial models, thus raising probability
converging higher-likelihood maxima. approach one taken work
presented here.
assume, throughout paper, number states model learning
known. strong assumption since methods learning number
states. Regularization methods deciding number states model parameters,
discussed, instance, Vapnik's book (1995). address issue here.
rest work describes approach learning topological models. use noisy
odometric information readily available robots. geometrical information
typically used topological mapping methods. demonstrate topological model
algorithm used learn extended directly incorporate weak odometric
information. show so, avoid use human-provided priori
models still learn stochastic environment models eciently effectively.

3 Models Assumptions
section describes formal framework work. starts introducing classic
hidden Markov model. model extended accommodate noisy odometric information
nave form, ignoring information robot's heading orientation, later
adapted accommodate heading information.
concentrate describing models algorithms learning hmms, rather
pomdps. means robot decisions make regarding next action
every state; one action executed state. experiments, human operator gave action command associated state robot gathering data.
Note action necessarily one every state, e.g., robot told
always turn right state 1 move forward state 2. However, state one action taken. extension complete pomdps, implemented,
learning hmm possible actions; straightforward although notationally
cumbersome, thus limit discussion hmms.

3.1 HMMs { Basics
hidden Markov model consists states, transitions, observations probabilistic behavior,
formally defined tuple = hS; O; A; B; i, satisfying following conditions:

= fs0 ; : : : ; sN ,1 g finite set N states.
= fo0 ; : : : ; oM ,1g finite set possible observation values.
174

fiLearning Geometrically-Constrained HMMs

stochastic transition matrix, Ai;j = Pr(qt+1 = sj jqt = si), 0 i; j N ,1.
NX
,1
qt state time t. every state si ,

j =0

Ai;j = 1.

Ai;j holds transition probability state si state sj .
B stochastic observation matrix, Bj;k = Pr(vt = ok jqt = sj ), 0 j N , 1;
MX
,1
0 k , 1. vt observation recorded time t. every state sj ,
Bj;k = 1.
Bj;k holds probability observing ok state sj .

k=0

stochastic initial distribution vector, = Pr(q0 = si), 0 N , 1.

NX
,1
i=0

= 1.

holds probability state si time 0, starting record observations.
model corresponds world whose actual state given time t, qt 2 , hidden
directly observable, observable aspects state, vt 2 O, detected
recorded state visited time t. agent moves one hidden state
next according probability distribution encoded matrix A. observed information
state governed probability matrix B . Although work concerned
discrete observations, extension continuous observations straightforward
well addressed work hidden Markov models (Liporace, 1982; Juang, 1985).
Simply stated, problem learning hmm \reverse engineering" hidden Markov
model stochastic system sampled data, generated system. formalize
learning task Section 4.1. next section extends hmms account geometric
information.

3.2 Adding Odometry Hidden Markov Models

world composed finite set states. fundamental distinction
framework term state term location. state robot
directly correspond location. state may include information, robot's
battery level orientation location. robot standing entrance oce 101
facing right different state robot standing place facing left; similarly,
robot standing bagel arm different state robot
position without bagel.
dynamics world described state-transition distributions specify probability making transitions one state next result certain action.
finite set observations perceived state; relative frequency
observation described probability distribution depends current state.
model, observations multi-dimensional; observation vector values,
chosen finite domain. is, factorize observation associated state
several components. instance, demonstrated Section 6.1, view observation
recorded robot standing oce environment consisting three components,
corresponding three cardinal directions: front, left right. example, observation vector thus 3-dimensional. assumed vector's components conditionally
independent, given state.
175

fiShatkay & Kaelbling

addition components, state assumed associated position
metric space. Whenever state transition made, robot records odometry vector,
estimates position current state relative previous one. time assume odometry vector consists readings along x coordinates global coordinate system, readings corrupted independent normal noise. latter
independence assumption strict one, relaxed introducing complete covariance matrix, although done work. Section 3.3 extend odometry vector include information heading robot, drop global coordinate
framework.
Note odometric relationship characterizes transition rather state and,
described below, receives different treatment observations associated
states.
two important assumptions underlying treatment odometric relations
states: First, inherent \true" odometric relation position every
two states world; second, robot moves one state next,
normal, 0-mean noise around correct expected odometric reading along odometric
dimension. noise ects two kinds odometric error sources:

{ lack precision discretization real world states (e.g. rather

large area robot stand regarded \the doorway AI
lab").
{ lack precision odometric measures recorded robot, due slippage,
friction, disalignment wheels, imprecision measuring instruments, etc.

formally introduce odometric information hidden Markov model framework,
define augmented hidden Markov model tuple = hS; O; A; B; R; i, where:

= fs0 ; : : : ; sN ,1 g finite set N states.
= Qli=1 Oi finite set observation vectors length l. ith element

observation vector chosen finite set Oi .
stochastic transition matrix, Ai;j = Pr(qt+1 = sj jqt = si), 0 i; j N , 1.
NX
,1
qt state time t. every state si , Ai;j = 1.
j =0

Ai;j holds transition probability state si state sj .
B array l stochastic observation matrices, Bi;j;k = Pr(Vt [i] = ok jqt = sj );
1 l; 0 j N , 1; ok 2 Oi ; Vt observation vector time t; Vt [i] ith

component.
Bi;j;k holds probability observing ok along ith component observation
vector, state sj .
R relation matrix, specifying pair states, si sj , mean variance
D-dimensional2 odometric relation them. (Ri;j [m]) mean mth

2. time consider 2, corresponding (x; y) readings.

176

fiLearning Geometrically-Constrained HMMs

component relation si sj 2 (Ri;j [m]), variance. Furthermore,
R geometrically consistent: component m, relation (a; b) = (Ra;b [m])
must directed metric, satisfying following properties states a, b, c:
def

m(a; a) = 0;
m(a; b) = ,m(b; a) (anti-symmetry);
m(a; c) = (a; b) + m(b; c) (additivity ) :
representation odometric relations ects two assumptions, previously stated,
regarding nature odometric information. \true" odometric relation
position every two states represented mean. noise around correct
expected odometric relation, accounting lack precision real-world
discretization inaccuracy measurement, represented variance.

stochastic initial probability vector describing distribution initial state.
simplicity assumed form h0; : : : ; 0; 1; 0; : : : ; 0i, implying
one designated initial state, si , robot always started.

model extends standard hidden Markov model described Section 3.1 two ways:
facilitates observations factored components, represented vectors.
components assumed conditionally independent given
state. factorization, together conditional independence assumption, allows
simple calculation probability complete observation vector
probabilities components. therefore results fewer probabilistic parameters
learnt model view observation vector, consisting possible
combination component-values single \atomic" observation.

introduces odometric relation matrix R constraints components. Using
R constraints it, explained Section 4, proven useful learning
model parameters, demonstrated Section 6.

3.3 Handling Directional Data

extend model accommodate directional changes addition positional
changes. two issues stemming directional changes moving environment: need non-traditional distributions model directional changes, need
correct cumulative rotational error severely interferes location estimation
within global coordinate framework. detailed discussion two problems
solution given earlier paper authors (Shatkay & Kaelbling, 1998). sake
completeness, brie review two issues here.
3.3.1 Circular Distributions

robot's change direction moves environment expressed terms
angular change respect original heading. Since angular measures inherently circular, treating \normally distributed", using standard procedures obtaining
sucient statistics data adequate. trivial example, average
177

fiShatkay & Kaelbling


1

<x 1, y1>
<x 2, y2>
<x 3, y3>
1

173 0
179

0

-1

3

2

3
1

x

-1

Figure 1: Simple average two angles, depicted

vectors unit circle. average angle
formed dashed vector.

Figure 2: Directional data represented angles
vectors unit circle.

two angular readings, 173 ,179 , using simple average obtain angle ,3 ,
far intuitive 180 , illustrated Figure 1.
address circularity issue, use von Mises distribution, circular version
normal distribution, model change heading two states, explained below.
collection changes heading within two dimensional space represented terms
either Cartesian polar coordinates. Using Cartesian system, n changes headings
recorded sequence 2-dimensional vectors, (hx1 ; y1 i; : : : hxn ; yn i), unit circle,
shown Figure 2. changes represented corresponding angles
radii center unit circle X axis, (1 ; : : : ; n ), respectively.
relationship two representations is:
xi = cos(i ); yi = sin(i ) ; (1 n) :
vector mean n points, hx; yi, calculated as:
Pn cos( )
Pn sin( )

:

=1
i=1
x=

=
;
n
n

(1)

Using polar coordinates, express mean vector terms angle, , length, a,
(except case x = = 0):

= arctan( xy );

= (x2 + 2 ) :
1
2

angle mean angle, length measure (between 0 1)
concentrated sample angles around . closer 1, concentrated
sample around mean, corresponds smaller sample variance.
Intuitively, satisfactory circular version normal distribution would mean
maximum likelihood estimate average angle calculated above. way
analogous Gauss' derivation Normal distribution, von Mises developed circular
version (Gumbel, Greenwood, & Durand, 1953; Mardia, 1972), defined follows:
Definition: circular random variable, , 0 2, said von Mises
distribution parameters , 0 2 > 0, probability density
178

fiLearning Geometrically-Constrained HMMs

function is:

f;() = 2I1 () e cos(,) ;
0

I0 () modified Bessel function first kind order 0:

I0 () =

1 1 1
X
2r
2 ( 2 ) :
r
!
r=0

(2)

parameters correspond distribution's mean concentration respectively.
circular-normal distributions exist, von Mises desirable estimation
procedure alluded earlier: Given set heading samples, angles 1 ; : : : n , von Mises
distribution, maximum likelihood estimate is:

= arctan( xy ) ;

y, x defined Equation 1.
maximum likelihood estimate concentration parameter, , satisfies:
n
I1 () = max[ 1 X
I0 ()
n i=1 cos(i , ); 0] ;

I1 modified Bessel function first kind order 1:

I1 () =

1
X

1 ( 1 )2r+1 :
r=0 r!(r + 1)! 2

(3)

information estimation procedure beyond scope paper
found elsewhere (Gumbel et al., 1953; Mardia, 1972).
conclude, assume change heading von Mises-distributed, around mean
concentration parameter . assumption ected model learning procedures
explained later Section 4.2.3. change heading h (a; b); (a; b)i pair
states (a; b) completes set parameters included relation matrix R
introduced earlier Section 3.2.
3.3.2 Cumulative Rotational Error

tend think environment consisting landmarks fixed global coordinate
system corridors transitions connecting landmarks. idea underlies typical
maps constructed used everyday life. However, view environment may
problematic robots involved.
Conceptually, robot two levels operates; abstract level, centers
corridors, follows walls avoids obstacles, physical level motors
turn wheels robot moves. physical level many inaccuracies manifest
themselves: wheels unaligned resulting drift right
left, one motor slightly faster another resulting similar drifts, obstacle
one wheels cause robot rotate around slightly, uneven oors may cause
179

fiShatkay & Kaelbling



- actual position
- recorded position

Figure 3: robot moving along solid arrow, correcting drift direction dashed
arrow. dotted arrow marks recorded change position.

robot slip certain direction. addition, measuring instrumentation odometric
information may accurate itself. abstract level, corrective actions
constantly executed overcome physical drift drag. example, left wheel
misaligned drags robot leftwards, corrective action moving right constantly
taken higher level keep robot centered corridor.
phenomena described significant effect odometry recorded robot,
data interpreted respect one global framework. example, consider robot
depicted Figure 3. drifts left , moving one state next,
corrects moving right order maintain centered corridor.
Let us assume states 5 meters apart along center corridor, center
corridor aligned axis global coordinate system. robot steps back
forth corridor one state next. Whenever robot reaches state,
odometry reading changes hx; y; along hX; Y; headingi dimensions, respectively.
robot proceeds, deviation respect X axis becomes severe. Thus,
going several transitions, odometric changes recorded every pair
states, taken respect global coordinate system, become larger larger. Similar
problems inconsistent odometric changes recorded pairs states arise along
odometric dimensions. especially severe inconsistencies arise respect
heading, since lead mistakenly switching movement along X
axes, well confusion forwards backwards movement (when deviation
heading around 90 180 respectively).
early work (Shatkay & Kaelbling, 1997) assumed perpendicularity corridors,
taken advantage robot collected data. Odometric readings recorded
respect global coordinate system, robot could re-align origin
turn. trajectory odometry recorded perpendicularity assumption
robot Ramona, along x axes given Figure 4. sequence shown recorded
robot drove repeatedly around loop corridors. details data
gathering process provided Section 6. contrast, Figure 5 shows trajectory another
sequence odometric readings recorded Ramona, driving corridors, without
using perpendicularity assumption. data collected latter setting subjected
cumulative rotational error.
180

fiLearning Geometrically-Constrained HMMs
3000
1200

2500
1000

2000
800

1500

600

1000

400

200

500
200

400

600

800

1000

-2500 -2000 -1500 -1000 -500

Figure 4: Sequence gathered Ramona, perpendicularity assumed.

500

1000

Figure 5: Sequence gathered Ramona, per-

pendicularity assumed.

data handled state-relative coordinate systems (Shatkay & Kaelbling, 1998).
latter implies state si coordinate system, shown Figure 6:
origin anchored si , axis aligned robot's heading state (denoted
bold arrows figure), X axis perpendicular it. contrast global
coordinate system anchored initial starting state. Within global coordinate
system, relations recorded may vary greatly among multiple instances transition
pair states. using state-relative system, recorded learned
relationship pair states, hsi ; sj i, reliable, despite fact based
multiple transitions recorded si sj .
state-relative coordinate systems, geometric relation stored Rij , (which introduced Section 3.2), expressed pair states, si sj , respect
coordinate system associated state si. Accordingly, constraints imposed x
components relation matrix must specified respect explicit coordinate
system used, explained below.
Given pair states b, denote hx;yi (a; b) vector h(Ra;b [x]); (Ra;b [y])i. Let
us define Tab transformation maps hxa ; ya point represented respect
coordinate system state a, point represented respect coordinate
system state b, hxb ; yb i.
explicitly, let ab mean change heading state state b. Applying Tab
vector h xyaa results vector h xybb follows:

* +

* + *

xb
x
x cos(ab ) , ya sin(ab )
= Tab =
yb
ya
xa sin(ab ) + ya cos(ab )

+

:

consistency constraints within framework must restated as:

hx;yi(a; a) = h0; 0i;
hx;yi(a; b) = ,Tba[hx;yi(b; a)] (anti-symmetry);
hx;yi(a; c) = hx;yi (a; b) + Tba[hx;yi (b; c)] (additivity).
181

fiShatkay & Kaelbling


x
Sj
Si





x

Figure 6: robot state Si , faces -axis direction; relation Si ,Sj wrt Si 's coordinate
system.

consistency constraints ones need enforced learning algorithm
constructs hmm. important note transformation
constitute set additional parameters need learnt. Rather, calculated terms
heading-change parameter, , already integral part relation matrix
defined Sections 3.2 3.3.1.
introduced basic formal model use representing environments
robot's interaction them. following section state learning problem
describe basic algorithm learning model data.

4 Learning HMMs Odometric Information

section formalizes learning problem hmms, discusses odometric information
incorporated learning algorithm. overview complete algorithm provided
Appendix paper.

4.1 Learning Problem

learning problem hidden Markov models generally stated follows: Given
experience sequence E, find hidden Markov model could generated sequence
\useful" \close original" according criterion. explicit common statistical
approach look model maximizes likelihood data sequence E given
model. Formally stated, maximizes Pr(Ej). However, given complicated landscape
typical likelihood functions multi-parameter domain, obtaining maximum likelihood
model feasible. studied practical methods, particular well-known BaumWelch algorithm (Rabiner (1989) references therein) guarantee local-maximum
likelihood model.
Another way evaluating quality learned model comparing true model.
note stochastic models (such hmms) induce probability distribution observation sequences given length. Kullback-Leibler (Kullback & Leibler, 1951) divergence
learned distribution true one commonly used measure estimating good
182

fiLearning Geometrically-Constrained HMMs

learned model is. Obtaining model minimizes measure possible learning goal.
culprit practice, learn model data, \ground
truth" model compare learned model with. Still, evaluate learning algorithms
measuring well perform data obtained known models. reasonable expect algorithm learns well data generated model have,
perform well data generated unknown model, assuming models indeed form
suitable representation true generating process. discuss Kullback-Leibler (kl)
divergence detail Section 6.2 context evaluating experimental results.
summarize, learning problem address work obtaining model
attempting (locally) maximize likelihood, evaluating results based
kl-divergence respect true underlying distribution, distribution
available.

4.2 Learning Algorithm

learning algorithm starts initial model 0 given experience sequence E;
returns revised model , (locally) maximizes likelihood P (Ej). experience
sequence E length ; element, Et , 0 (T , 1), pair hrt ; Vt i, rt
observed relation vector along x, dimensions, states qt,1 qt , Vt
observation vector time t.
algorithm extends standard Baum-Welch algorithm deal relational information factored observation sets. Baum-Welch algorithm expectationmaximization (em) algorithm (Dempster, Laird, & Rubin, 1977); alternates
E-step computing state-occupation state-transition probabilities, ,
time sequence given E current model ,
M-step finding new model, , maximizes P (Ej; ; ),
providing monotone convergence likelihood function P (Ej) local maximum.
However, extension introduces additional component, namely, relation matrix R.
viewed two kinds observations: state observations (as ordinary hmm |
distinction observe integer vectors rather integers) transition observations (the odometry relations states). latter must satisfy geometrical constraints.
Hence, extension standard update formulae, described below, required.
4.2.1 State-Occupation Probabilities

Following Rabiner (1989), first compute forward (ff) backward (fi ) matrices. fft (i)
denotes probability density value observing E0 Et qt = si , given ; fit (i)
probability density observing Et+1 ET ,1 given qt = si . Formally:
fft (i) = Pr(E0 ; : : : ; Et ; qt = sij) ;
fit (i) = Pr(Et+1 ; : : : ; ET ,1 jqt = si ; ) :
measurements continuous (as case R), matrices contain
probability density values rather probabilities.
forward procedure calculating matrix initialized
(
b = 1
ff0 (i) = 00 otherwise
;
183

fiShatkay & Kaelbling

continued 0 < , 1
fft (j ) =

NX
,1
i=0

fft,1 (i)Ai;j f (rt jRi;j )bjt :

(4)

expression f (rt jRi;j ) denotes density point rt according distribution represented
means variances entry i; j Q
relation matrix R, bjt probability
j
observing vector vt state sj ; is, bt = li=0 Bi;j;vt[i] .
backward procedure calculating matrix initialized fiT ,1 (j )=1, continued
0 t<T , 1
NX
,1
fit (i) = fit+1 (j )Ai;j f (rt+1 jRi;j )bjt+1 :
(5)
j =0

Given , compute given time point state-occupation statetransition probabilities, . state-occupation probabilities, (i), representing
probability state si time given experience sequence current model,
computed follows:
:
(6)
(i) = Pr(qt = si jE; ) = PNff,t1(i)fit (i)
j =0 fft (j )fit (j )
Similarly, (i; j ), state-transition probabilities state state j time given
experience sequence current model, computed as:
(i; j ) = Pr(qt = si ; qt+1 = sj jE; )
fft (i)Ai;j bjt+1 f (rt+1 jRi;j )fit+1 (j )
:
(7)
=
NX
,1 NX
,1
i=0 j =0

fft (i)Ai;j bjt+1 f (rt+1 jRi;j )fit+1 (j )

essentially formulae appearing Rabiner's tutorial (Rabiner, 1989),
take account density odometric relations.
next phase algorithm, goal find new model, , maximizes likelihood conditioned current transition observation probabilities, Pr(Ej; ; ). Usually,
simply done using maximum-likelihood estimation probability distributions
B computing expected transition observation frequencies. model must
compute new relation matrix, R, constraint remain geometrically consistent.
rest section use notation v denote reestimated value, v
denotes current value.
4.2.2 Updating Transition Observation Parameters

B matrices straightforwardly reestimated. Ai;j expected number
transitions si sj divided expected number transitions si , B i;j;k
expected number times ok observed along ith dimension state sj , divided
expected number times sj :
PT ,1
PT ,2 (i; j )


=0
; B i;j;k = t=0PT[V,t1[i]=ok ] (j ) :
(8)
Ai;j = PT ,2
t=0 (i)
t=0 (i)
expression c denotes indicator function value 1 condition c true 0 otherwise.
184

fiLearning Geometrically-Constrained HMMs
7.5
P

Q

5

P

2.5

-8

-6

-4

-2

2

4

6

8

-2.5
-5

-6

-4

-2

2

4

6
-7.5

Q

Figure 7: Examples two sets normally distributed points constrained means, 1 2
dimensions.

4.2.3 Updating Relation Parameters

reestimating relation matrix, R, geometrical constraints induce interdependencies
among optimal mean estimates well optimal variance estimates mean
estimates. Parameter estimation form constraints almost untreated mainstream statistics (Bartels, 1984) found previous existing solutions estimation
problem addressed here. illustration issues involved estimation constraints
consider following estimation problem 2 normal means:
Example 4.1 data consists two sample sets points P = fp1; p2 ; : : : ; pn g Q =
fq1; q2 ; : : : ; qk g, independently drawn two distinct normal distributions means P ; Q
variances P2 ; Q2 , respectively. asked find maximum likelihood estimates
two distribution parameters. Moreover, told means two distributions
related, Q = ,P , illustrated Figure 7. latter constraint, task
simple (DeGroot, 1986), have:
Pn p
Pn
; 2 = i=1 (pi , P )2 ;
P = i=1
P
n
n

similarly Q Q2 . However, constraint P = ,Q requires finding single mean, ,
setting one negated value, ,. Intuitively, choosing maximum
likelihood single mean, concentrated sample effect,
varied sample \submissive." Thus, overall sample deviation means
would minimized likelihood data maximized. Therefore, mutual
dependence estimation mean estimation variance.
Since samples independently drawn, joint likelihood function is:
,(pi ,P )2

n
P

f (P; QjP ; Q; P2 ; Q2 ) = e p
i=1 2P
2 2



Yk e
j =1

,(qj ,Q )2
Q

p

2 2

2Q

:

taking derivatives joint log-likelihood function, respect P , P Q,
equating 0, using constraint Q = ,P , obtain following set mutual
equations maximum likelihood estimators:
P
P
(Q2 ni=1 pi) , (P2 kj=1 qj )
P =
; Q = ,P ;
nQ2 + kP2
Pk (q + )2
Pn (p , )2

P

=1
2
2
P =
; Q = j =1 j P :

n

k

185

fiShatkay & Kaelbling

substituting expressions P Q expression P , obtain cubic equation cumbersome, still solvable (in simple case). solution provides maximum likelihood estimate mean variance constraint Q = ,P :
2
proceed actual update relation matrix constraints. clarity,
initially discuss first two geometrical constraints, discuss additivity constraint
Section 4.3. Recall concentrate enforcement global constraints, appropriate
perpendicularity assumption, although idea applied case staterelative constraints.
Zero distances states trivially enforced, setting diagonal
entries R matrix 0, small variance.
Anti-symmetry within global coordinate system enforced using data recorded along
transition state sj si well state si sj reestimating (Ri;j ).
demonstrated Example 4.1, variance taken account, leading following
set mutual equations:



mi;j

=

( mi;j )2 =

PT ,2

rt[m]t (i;j ) , rt [m]t(j;i)
(
(
i;j )2
j;i )2

PT ,2 t(mi;j) + t(mj;i)
t=0 (i;j )2 (j;i )2
PT ,2[ (i; j )(r [m] , )2 ]
t=0
PT ,2 t(i; j ) i;j :
t=0
t=0

;

(9)
(10)

x dimensions, (m = x; y), amounts complicated still solvable cubic
equation. However, general case, accounting orientation robot,
complete additivity enforced, obtain closed form reestimation
formulae.
avoid hardships, use lag-behind update rule; yet-unupdated estimate
variance used calculating new estimate mean, new mean estimate
used update variance, using Equation 10.3 Thus, mean updated using variance
parameter lags behind update process, reestimation Equation (9) needs
use rather follows: PT ,2 h rt [m]t (i;j) rt [m]t (j;i)
2 , j;i
)2
t=0
:
(11)
mi;j = PT ,2(hi;jt ()i;j) ((j;i
)
t=0

)2 + (j;i
)2
i;j

(

shown (Shatkay, 1999), lag-behind policy instance generalized em (McLachlan & Krishnan, 1997). latter guarantees monotone convergence local maximum
likelihood function, even \maximization" step increases rather strictly maximizes expected likelihood data given current model.
Similarly, reestimation formula von Mises mean () concentration () parameters
heading change states si sj solution equations:

0 TX
1
,
BB [sin(rt [])(t (i; j )i;j , t(j; i)j;i)] CC

CC
= arctan B
B@ TX
,

[cos(rt [])(t (i; j )i;j + (j; i)j;i )]
2

i;j

=0

2

t=0

3. similar approach, termed one step late update, taken others applying em highly non-linear optimization problems (McLachlan & Krishnan, 1997).

186

fiLearning Geometrically-Constrained HMMs

I1 [i;j ]
= max
I0 [i;j ]

" PT ,

#
2
(i; j ) cos(rt [] , i;j )]
t=0 [tP
; 0
,2 (i; j )
t=0

;

(12)

I0 I1 modified Bessel functions defined Equations 2 3 Section 3.3.1.
Again, avoid need solve mutual equations, take advantage lag-behind strategy, updating mean using current estimates concentration parameters, i;j ; j;i,
follows:
PT ,2[sin(r [])( (i; j ) , (j; i) )] !


i;j
j;i
i;j = arctan PTt=0
(13)
,2 [cos(r [])( (i; j ) + (j; i) )] ;


i;j
j;i
t=0
calculating new concentration parameters based newly updated mean,
solution Equation 12, use lookup-tables.
possible alternative lag-behind approach update mean though assumption j;i = i;j holds. assumption, variance terms Equation 9 cancel out,
mean update independent variance again. variances updated
stated Equation 10, without assuming constraints them. approach taken
earlier stages work (Shatkay & Kaelbling, 1997, 1998). lag-behind strategy
superior, according experiments, due instance generalized em.

4.3 Enforcing Additivity

Note additivity constraint directly implies two geometrical constraints4 . Thus,
enforcing results complete geometrical consistency. present method directly
enforcing additivity reestimation procedure along x dimensions.
heading dimension describe complete geometrical consistency achieved
projection anti-symmetric estimates onto geometrically-consistent space. before,
simplify presentation, focus case global coordinate systems. basic
idea applies state-relative coordinate systems, relationship used recover mean
ij individual state coordinates complex.
4.3.1 Additivity x, dimensions

main observation underlying approach additivity constraint result
fact states embedded geometrical space. is, assuming N states,
s0; : : : ; sN ,1, points X , axes, x0 ; : : : ; xN ,1 , y0 ; : : : ; yN ,1 , 0 ; : : : ; N ,1,
respectively, state, si , associated coordinates hxi ; yi ; i. Assuming
one global coordinate system, mean odometric relation state si state sj
expressed as: hxj , xi ; yj , yi ; j , i.
maximization phase em iteration, rather try maximize respect
N 2 odometric relation vectors, hXij , Yij , ij i, reparameterize problem. Specifically,
express odometric relation function two N state positions, maximize
respect unconstrained, N state positions. instance, X dimension, rather
search N 2 maximum likelihood estimates xij , use maximization step find
N 1-dimensional points, x0 ; : : : ; xN ,1 . calculate xij = xj , xi . Moreover, since
interested finding best relationships xi xj , fix one
4. f(a; a)= (a; a) + (a; a)g ) ((a; a)=0) ; f((a; a)=0) ; ((a; a)= (a; b)+(b; a))g ) ((a; b) = ,(b; a)).

187

fiShatkay & Kaelbling

xi 's 0 (e.g. x0 = 0), find optimal estimates remaining N , 1 state positions.
variance reestimation remains before, lag-behind policy used eliminate
interdependency update mean variance parameters.
4.3.2 Additive Heading Estimation

Unfortunately, reparameterization described feasible estimation changes
heading, due von Mises distribution assumption heading measures. reparameterizing ij j , trying maximize likelihood function respect
parameters, obtain set N,1 trigonometric equations terms form cos(j ) sin(i )
enable simple solution.
alternative, possible use anti-symmetric reestimation procedure described
earlier, followed perpendicular projection operator, mapping resulting headings vector
h00 ; : : : ; ij ; : : : ; N ,1;N ,1i, 0 i; j N ,1, satisfy additivity, onto vector
headings within additive linear vector space. Simple orthogonal projection satisfactory
within setting, since simply looks additive vector closest non-additive one.
procedure ignores fact entries non-additive vector based
lot observations, therefore reliable, other, less reliable ones, based
hardly data all. Intuitively, would keep estimates well accounted
intact, adapt less reliable estimates meet additivity constraint. precisely,
heading-change estimates states better accounted others,
sense transitions
states higher expected counts transition
P
states (higher (i; j )). would project non-additive heading
estimates vector onto subspace additive vector space, vectors
values non-additive
P vector entries well-accounted for, is,
highest values (i; j ). diculty latter subspace linear vector
space (for instance, satisfy closure scalar multiplication), projection
operator linear spaces cannot applied directly. Still, set vectors form
ane vector space, project onto using algebraic technique, explained below.5
Definition
Rn n-dimensional ane space vectors va2A, set vectors:
def
, va = fua , va jua 2 Ag linear space.
Hence, pick vector ane space, va 2A, define translation Ta : ! V ,
V linear space, V = , va . translation trivially extended vector
v0 2 Rn , defining Ta (v0 ) = v0 , va . order project vector v 2 Rn onto A, apply
translation Ta v project Ta (v) onto V , results vector P (Ta (v)) V .
applying inverse transform Ta,1 it, obtain projection v A, demonstrated
Figure 8. linear space figure two dimensional vector space fhx; yij = ,xg,
ane space fhx; yij = ,x + 4g. transform Ta consists subtracting vector
h0; 4i. solid arrow corresponds direct projection vector v onto point P (v)
ane space. dotted arrows represent projection via translation v Ta (v),
projection latter onto linear vector space, inverse translation result,
P (Ta (v)), onto ane space.
1

1

1

5. Many thanks John Hughes introducing us technique.

188

fiLearning Geometrically-Constrained HMMs

6
<x,-x+4>
4
P(v)

v

2

-2

2

-2

4
Ta (v)
P(Ta (v))

<x,-x>

-4

Figure 8: Projecting v onto ane vector space fhx; yij = ,x + 4g.
Although procedure preserving additivity headings formally proven preserve monotone convergence likelihood function towards local maximum, extensive
experiments consisting hundreds runs shown monotone convergence preserved.

5 Choosing Initial Model

Typically, instances Baum-Welch algorithm, initial model picked uniformly
random space possible models, perhaps trying multiple initial models find different local likelihood maxima. alternative approach reported (Shatkay & Kaelbling,
1997) based clustering accumulated odometric information using simple k-means
algorithm (Duda & Hart, 1973), taking clusters states observations
recorded, obtain state observation counts estimate model parameters.
perpendicularity assumed collecting data, shown Figure 4, k-means
algorithm assigns cluster (state) odometric readings recorded close locations,
leading reasonable initial models. However, assumption dropped, illustrated
Figure 5, cumulative rotational error distorts odometric location recorded within
global coordinate system, location assigned state multiple visits
varies greatly would recognized \the same" simple location-based clustering
algorithm. overcome this, developed alternative initialization heuristics, call
tag-based initialization. based directly recorded relations states, rather
states' absolute location. clarity, description consists mostly illustrative
example, concentrates case global consistency constraints enforced.
Given sequence observations odometric readings E, begin clustering odometric
readings buckets. number buckets number distinct state transitions
recorded sequence. goal stage bucket contain odometric
readings close along three dimensions.
achieve this, start fixing predetermined, small standard deviation value along x,
y, dimensions. Denote standard deviation values x ; ; respectively, (typically
x = ). first odometric reading assigned bucket 0 mean bucket
set value reading. rest process subsequent odometric
readings examined. next reading within 1:5 standard deviations along
three dimensions mean existing non-empty bucket, add bucket
189

fiShatkay & Kaelbling

< 2, 94, 92 >
< -4, 102, 91 >

<1994, 0, 88 >
< 1998, -5, 90 >

< 3, -93, 86 >
< -2, -106, 91 >

< -1999, -1, 94 >
< -2003, 7, 87 >

1:

2:

3:

4:

<-1, 98, 91.5>

<1996, -2.5, 89>

<0.5, -99.5, 88.5>

<-2001, 3, 90.5>

3

4

1

2

Figure 9: bucket assignment example sequence.
update bucket mean accordingly. not, assign empty bucket set mean
bucket reading.
Intuitively, using heuristic resulting buckets tightly concentrated
mean. note clustering algorithms (Duda & Hart, 1973) could used
bucketing stage.
Example 5.1 would learn 4-state model sequence odometric readings,
hx; y; follows:
h2 94 92i; h1994 0 88i; h3 , 93 86i; h,1999 1 94i;
h,4 102 91i; h1998 , 5 90i; h,2 , 106 91i; h,2003 7 87i :
first stage place readings buckets. Suppose standard deviation constant
20. placement shown Figure 9. mean value associated bucket shown
well.
2
next stage algorithm state-tagging phase, odometric reading,
rt , assigned pair states, si; sj , denoting origin state (from transition took
place) destination state (to transition led), respectively. conjunction,
mean entries, ij , relation matrix, R, populated.

Example 5.1 (cont.) Returning sequence above, process demonstrated Figure 10. assume data recording starts state 0, odometric change
self transitions 0, small standard deviation (we use 20 well).
shown part figure.
Since first element sequence, h2 94 92i, two standard deviations away
mean [0][0] entry relation row state 0 populated, pick 1
next state populate mean [0][1] mean bucket 1,
h2 94 92i belongs. maintain geometrical consistency mean [1][0] set ,[0][1],
shown part B figure. populated 2 off-diagonal entries, state
sequence h0; 1i. entry [0][1] matrix becomes associated bucket 1,
information recorded helping tagging future odometric readings belonging
bucket.
next odometric reading, h1994 0 88i, standard deviations populated mean
row 1 (where 1 current believed state). Hence, pick new state 2, set mean
[1][2] 2|the mean bucket 2|to reading belongs (Figure 10 C). entry
[1][2] recorded associated bucket 2. preserve anti-symmetry additivity, [2][1]
set ,[1][2]. [0][2] set sum [0][1] + [1][2], [2][0] set ,[0][2].
190

fiLearning Geometrically-Constrained HMMs

0
0

1

B
2

3

0

<0,0,0>

1

0
1

<0,0,0>

<0,0,0>

2

2

3

<-1,
<0,0,0> 98,
91.5>
< 1,
-98,
-91.5>

<0,0,0>

<0,0,0>

2
3

<0,0,0>

3

1

<0,0,0>

S: 0

S: 0. 1
Bucket(R[0][1]) = 1

C
0
0
1
2

1


2

3

0

<-1,
<1995,
95.5,
<0,0,0> 98,
91.5> -179.5>
<1996,
< 1,
-98,
<0,0,0> -2.5,
-91.5>
89>

0
1

<-1995, <-1996,
-95.5,
2.5,
<0,0,0>
179.5> -89>

3

2
3

<0,0,0>

S: 0, 1, 2

1

2

3

<-1,
<1995, <1995.5,
95.5,
-4,
<0,0,0> 98,
91.5> -179.5> -91>
<1996, <1996.5,
< 1,
-98,
-102,
<0,0,0> -2.5,
-91.5>
89>
177.5>
<-1995, <-1996,
< 0.5,
-95.5,
2.5,
<0,0,0> -99.5,
179.5> -89>
88.5>
<-1995.5, <-1996.5, <-0.5,
99.5, <0,0,0>
4,
102,
-177.5> -88.5>
91>

S: 0,1,2,3
Bucket(R[2][3]) = 3

Bucket(R[1][2]) = 2

S: 0,1,2,3,0
Bucket(R[3][0]) = 4
,..., S:0, 1, 2, 3, 0, 1, 2, 3, 0

Figure 10: Populating odometric relation matrix creating state tagging sequence.
Similarly, [2][3] updated mean bucket 3, causing setting [3][2], [1][3],
[0][3], [3][1], [3][0]. Bucket 3 associated [2][3].
stage odometric table fully populated, shown part Figure 10. state
sequence point is: h0; 1; 2; 3i. next reading, h,1999 ,1 94i, within one standard
deviation [3][0] therefore next state 0. Entry [3][0] associated bucket 4,
(the bucket reading assigned), state sequence becomes: h0; 1; 2; 3; 0i.
next reading, bucket 1, associated relation state 0 tagged
bucket 1, namely, state 1. repeating last two readings, final state transition
sequence becomes h0; 1; 2; 3; 0; 1; 2; 3; 0i:
2
Note process described illustration simplified. general case,
need take account rotational error data, use state-relative coordinate
systems, therefore populate entries transformed anti-symmetry additivity
constraints:
hx;yi(a; b) = ,Tba [hx;yi(b; a)] ;
hx;yi(a; c) = hx;yi(a; b) + Tba [hx;yi(b; c)],
defined Section 3.3.2.
191

fiShatkay & Kaelbling

possible end tagging algorithm, rows columns relation
matrix still unpopulated. happens little data learn
number states provided algorithm large respect actual model.
cases either \trim" model, using number populated rows number
states, pick random odometric readings populate rest table, improving
estimates later. Note first approach suggests method learning number states
model given, starting gross over-estimate number, truncating number populated rows odometric table initialization performed.
state-transition sequence obtained, rest initialization algorithm
k-means based initialization, deriving state-transition counts state-transition
sequence, assigning observations states assumption state sequence
correct, obtaining state-transition observation probabilities. initialization phase
incur much computational overhead, equivalent time-wise performing one
additional iteration em procedure.

6 Experiments Results

goal work described far use odometry improve learning topological
models, using fewer iterations less data. tested algorithm simple robotnavigation world. experiments consist running algorithm data obtained
simulated model data gathered mobile robot, Ramona. amount
data gathered Ramona used proof concept sucient statistical
analysis. latter, use data obtained simulated model. gathered data
used algorithms without perpendicularity assumption (see Section 3.3.2),
results provided settings.

6.1 Robot Domain

robot used experiments, Ramona, modified RWI B21 robot. cylindrical
synchro-drive base, 24 ultrasonic sensors 24 infrared sensors, situated evenly around
circumference. infrared sensors used mostly short-range obstacle avoidance.
ultrasonic sensors longer ranged, used obtaining (noisy) observations
environment. experiments described here, robot follows prescribed path
corridors oce environment department. Thus, decision-making
involved, hmm sucient model, rather complete pomdp.
Low-level software6 provides level abstraction allows robot move hallways
intersection intersection turn ninety degrees left right. software
uses sonar data distinguish doors, openings, intersections along path, stop
robot's current action whenever landmark detected. stop|either due
natural termination action due landmark detection|is considered robot
\state".
stop, ultrasonic data interpretation allows robot perceive, three
cardinal directions, (front, left right), whether open space, door, wall,
something unknown.
Encoders robot's wheels allow estimate pose (position orientation) respect pose previous intersection. recording sonar-based observations
6. low-level software written maintained James Kurien.

192

fiLearning Geometrically-Constrained HMMs
3

5

4

6

7

8
9

2

12
13

10
11

9
8

23

42

6 7
22 20
21

43
0
19

10

5
4

1

3

2 1
41

14 15
16

18
17

24
25

38
36
37

35
34
40

11

26 27

30 31

12

0
16

15

14

29
28

39

33
32

13

Figure 11: True model corridors Ramona traversed. Arrows represent prescribed path direction.

Figure 12: True model prescribed path
simulated hallway environment.

odometric information, robot goes execute next prescribed action.
action command issued manually human operator. course, action performance perception routines subject error. path Ramona followed consists
4 connected corridors building, include 17 states, shown Figure 11.
simulation, manually generated hmm representing prescribed path robot
complete oce environment department, consisting 44 states,
associated transition, observation, odometric distributions. transition probabilities
ect action failure rate 5 , 10%. is, probability moving
current state correct next state environment, predetermined action
0:85 0:95. probability self transition typically 0:05 0:15.
small probability (typically smaller 0:02) sometimes assigned transitions.
experience real robot proves reasonable transition model, since
typically robot moves next state correctly, error occurs
significant frequency move all, due sonar interpretation indicating
barrier actually none. action command repeated robot usually
performs action correctly, moving expected next state. observation distribution
typically assigns probabilities 0:85 , 0:95 true observation perceived
robot state, probabilities 0:05 , 0:15 observations might
perceived. example, door actually perceived, door typically assigned
probability 0:85,0:9, wall assigned probability 0:09,0:1 open space assigned
probability 0:01 perceived. standard deviation around odometric readings
5% mean.
Figure 12 shows hmm corresponding simulated hallway environment. Observations
orientation omitted figure clarity. Nodes correspond states
environment, directed edges correspond corridors; arrows point direction
corridors traversed. interpretation figures provided
following section.
193

fiShatkay & Kaelbling

6.2 Evaluation Method

number different ways evaluating results model-learning algorithm.
None completely satisfactory, give insight utility results.
domain, transitions observations usually take place, therefore
likely others. Furthermore, relational information gives us rough estimate
metric locations states. get qualitative sense plausibility learnt
model, extract essential map learnt model, consisting states,
likely transitions metric measures associated them, ask whether map
corresponds essential map underlying true world.
Figures 11 12 essential versions true models, Figures 15 17, shown
later, essential versions representative learnt ones (obtained sequences gathered
perpendicularity assumption). Black dots represent physical locations states,
state assigned unique number. Multiple state numbers associated single
location typically correspond different orientations robot location. larger
black circle represents initial state. Solid arrows represent likely non-self transitions
states. Dashed arrows represent transitions probability 0:2
higher. Typically, due predetermined path taken, connectivity
modeled environment low, therefore transitions represented dashed arrows
almost likely likely ones. Note length arrows, within plot,
significant represents length corridors, drawn scale.
important note figures provide complete representation models.
First, lack observation orientation information. stress fact figures
serve visual aid plot true model. looking good topological
model rather geometrical model. figures provide geometrical embedding
topological model. However, even geometry, described relation matrix,
different, topology, described transition observation matrices, still valid.
Traditionally, simulation experiments, learnt model quantitatively compared
actual model generated data. models induces probability distribution
strings observations; asymmetric Kullback-Leibler divergence (Kullback & Leibler,
1951) two distributions measure good learnt model respect
true model. Given true probability distribution P = fp1 ; :::; pn g learnt one
Q = fq1; :::; qn g, kl divergence Q respect P is:

D(P jjQ) =

def

n
X
i=1

pi log2 pqi :


report results terms sampled version kl divergence, described Juang
Rabiner (1985). based generating sequences sucient length (5 sequences 1000
observations case) according distribution induced true model, comparing
log-likelihood according learnt model true model log-likelihood. total
difference log-likelihood divided total number observations, accumulated
sequences, giving number roughly measures difference log-likelihood
per observation. Formally stated, let M1 true model M2 learnt one. generating
K sequences S1 ; : : : ; SK , length , true model, M1 , sampled kl-divergence,
Ds is:
K
X
[log(Pr(Si jM1 )) , log(Pr(Si jM2 ))]

=1
Ds(M1 jjM2 ) =
:
KT
194

fiLearning Geometrically-Constrained HMMs
1000
1200

500
1000

800

-1500 -1250 -1000 -750

-500

-250

600

-500
400

-1000
200

200

400

600

800

-1500

1000

Figure 13: Sequence gathered Ramona,
perpendicularity assumed.

Figure 14: Sequence generated simulator, perpendicularity assumed.

ignore odometric information applying kl measure, thus allowing comparison
purely topological models learnt without odometry.

6.3 Results within Global Framework

let Ramona go around path depicted Figure 11 collect sequence
300 observations, assuming perpendicularity environment, is, every turning
point angle turn 90 . Thus turn Ramona realigns odometric readings
initial X axes. Figure 13 plots sequence metric coordinates, gathered
way, accumulating consecutive odometric readings, projected hx; yi. applied
learning algorithm data 30 times. 10 runs started k-means-based
initial model, 10 started tag-based initial model, 10 started random initial
model. addition ran standard Baum-Welch algorithm, ignoring odometric
information, 10 times. (Note non-determinism even using biased initial
models, since k-means clustering starts random seeds, low7 random noise added
data algorithms avoid numerical instabilities, thus multiple runs give multiple
results). report results obtained using tag-based method,
appropriate initialization method general case. results contrasted
obtained odometric information used all. comparison four settings
reader referred complete report work (Shatkay, 1999).
Figure 15 shows essential representations typical learnt models starting tag-based
initial model. geometry learnt model strongly corresponds true environment, states' positions learnt correctly. Although figure
show it, learnt observation distributions state usually match well true
observations.
demonstrate effect odometry quality learnt topological model, contrast
plotted models learnt using odometry representative topological model learnt without
7. random number -1cm 1cm added recorded distances typically several meters
long.

195

fiShatkay & Kaelbling
3

4

5

6

3

4

5

6

7

8

7

8

5

9

0

7

9

22

12
8
1
10
10

9
11

16

2

15
3
11
11

13
14

16

11

12

16

12
15

0

14
14

0

mona traversed.

6

4

13

Figure 15: Learnt model corridors Ra15

13

Figure 16: topology model learnt
without use odometry.

use odometric information. Figure 16 shows topology typical model learnt without
use odometric information. case, arcs represent topological relationships,
length meaningful. initial state shown bold circle. clear
topology learnt match characteristic loop topology true environment.

obtaining statistically sucient information, generated 5 data sequences, length
1000, using Monte Carlo sampling hidden Markov model whose projection shown
Figure 12. One sequences depicted Figure 14. figure demonstrates
noise model used simulation indeed compatible noise pattern associated
real robot data. used four different settings learning algorithm:

starting biased, tag-based, initial model using odometric information;
starting biased, k-means-based, initial model using odometric information;
starting initial model picked uniformly random, using odometric information;
starting random initial model without using odometric information (standard BaumWelch).

sequence four algorithmic settings ran algorithm 10 times.
keep discussion focused, concentrate first last settings
reader referred extensive report (Shatkay, 1999) complete discussion.
experiments, N set 44, \correct" number states; generalization, necessary use cross-validation regularization methods select model
complexity. Section 5 suggests one possible heuristic obtaining estimate number
states.
Figure 17 shows essential version one learnt model, obtained sequence shown
Figure 14, using tag-based initialization. note learnt model completely
196

fiLearning Geometrically-Constrained HMMs
26
14

15
16 27

13
12

25
33
24
23

7

8

6

22

9
0

32 31 21

5
29 17
18
28

34

2 1
4 3

20
19 30

11
10

35 36

43 42

37
41

38
39

40

Figure 17: Learnt model simulated hallway environment.
accurate respect true model. However, obvious correspondence
groups states learnt true models, transitions (as well
observations, shown) learnt correctly. quality geometry
learnt model simulated large environment varies, geometrical results
uniformly good case learning smaller environment real robot data.
environment gets large, global relations remote states, ected
geometrical consistency constraints, become harder learn. Still, topology
learnt model demonstrated statistical experiments good.
Table 1 lists kl divergence true learnt model, well number
runs convergence reached, 5 sequences setting
uses odometric information tag-based initialization learning algorithm
use odometric information, averaged 10 runs per sequence. stress kl
divergence measure calculated based new data sequences generated true
model, described Section 6.2. 5 sequences models learnt
participate testing process.
kl divergence respect true model models learnt using odometry, 5-6
times smaller models learnt without odometric data. standard deviation around
means 0.2 kl distances models learnt odometry 1.5 noodometry setting. check significance results used simple two-sample t-test.
models learnt using odometric information statistically significantly (p 0:0005) lower
average kl divergence others.

Seq. #
kl
Odo Iter #

kl
Odo Iter #

1
0.981
16.70
6.351
124.1

2
1.290
20.90
4.863
126.0

3
1.115
22.30
5.926
113.0

4
1.241
12.70
6.261
107.4

5
1.241
27.50
4.802
122.9

Table 1: Average results two learning settings five training sequences.
197

fiShatkay & Kaelbling

addition, number iterations required convergence learning using odometric
information roughly 4-5 times smaller required ignoring information.
Again, t-test verifies significance result.
three initialization settings, models learnt topologically somewhat inferior (and
high statistical significance), terms kl divergence, learnt without
enforcing additivity, reported earlier papers (Shatkay & Kaelbling, 1997, 1998). likely
result strong constraints enforced learning process, prevent
algorithm searching better areas learning-space, restrict reach poor local
maxima. geometry looks superior cases, significantly better. However,
seems less variability quality geometrical models across multiple runs
additivity enforced.
details extensive comparison different initialization methods
beyond scope paper, point studies small large models
show large models long data sequences involved, random initialization often
results lower KL-divergence tag-based initialization.
strong bias tag-based initialization, lead peaked models compared
less-peaked distributions associated true model. Random initialization leads atter
models. KL-divergence strongly penalizes models much peaked
true ones, randomly initialized models often closer, terms measure, true
models peaked ones learnt initial models. learning small models,
sucient training data available, tag-based initialization results models
clearly superior random ones. Again, reader referred complete report
work (Shatkay, 1999) comparative study initialization methods various
settings.

6.4 Results within Relative Framework

applied algorithm described Section 4.3, extended accommodate state-relative
constraints (as listed Section 3.3.2). data used gathered robot
environment, generated simulated model (Figures 11, 12).
However, data generated without assuming perpendicularity. means x
coordinates realigned turn global x axes, rather,
recorded \as-is." evaluation methods stay described above.
Figure 18 shows projection odometric readings Ramona recorded along
x dimensions, traversing environment. obtaining statistically sucient
information, generated 5 data sequences, length 800, using Monte Carlo sampling
hidden Markov model whose projection shown Figure 12. One sequences
depicted Figure 19.
Figure 20 shows typical model obtained applying algorithm enforcing complete
geometrical consistency, robot data shown Figure 18, using tag-based initialization.
note rectangular geometry environment preserved, although state 0
participate loop. explained observing corresponding area true
environment depicted Figure 11, consisting 4 states clustered bottom left
corner (0, 14, 15 16). Due relatively large number states close together
area true environment, recognized ever returned particularly
state 0 loop. Therefore, one transition recorded state 0 state
198

fiLearning Geometrically-Constrained HMMs
3000

1500

2500

1000

2000

500

1500

-1500

-1000

-500

500

1000

-500

500

-1000

-1500

-2500 -2000 -1500 -1000 -500

500

1000

Figure 18: Sequence gathered Ramona,

Figure 19: Sequence generated simula-

perpendicularity assumed.

tor, perpendicularity assumed.
15

14

16

1
13

12

2

11

3
4
0

5

10

6
7
9

8

Figure 20: Learnt model corridors Ramona traversed. Initialization tag-based.
1 according expected transition counts calculated algorithm. projecting
angles maintain additivity, (as described Section 4.3.2), angle state 0 1
therefore compromised, allowing geometrical consistency maintain rectangular geometry
among regularly visited states.
purpose quantitatively evaluating learning algorithm list Table 2 kl
divergence true learnt model, well number iterations convergence reached, 5 simulation sequences with/without odometric information,
averaged 10 runs per sequence. table demonstrates kl divergence respect true model models learnt using odometric data, 8 times smaller
models learnt without it. check significance results use simple
two-sample t-test. models learnt using odometric information highly statistically significantly (p 0:0005) lower average kl divergence others. addition, number
199

fiShatkay & Kaelbling

Seq. #
kl
Odo Iter #

kl
Odo Iter #

1
2
3
4
5
1.46 1.18 1.20 1.02 1.22
11.8 36.8 30.7 24.6 33.3
6.91 9.93 10.03 9.54 12.43
113.3 113.1 102.0 104.2 112.5

Table 2: Average results 2 learning settings 5 training sequences.
iterations required convergence learning using odometric information smaller
required ignoring information. Again, t-test verifies significance (p < 0:005)
result.
important point number iterations, although much lower, automatically imply algorithm runs less time non-odometric Baum-Welch.
major bottleneck caused need compute within forward-backward calculations,
described Section 4.2.1, values normal von-Mises densities. require calculation exponent terms rather simple multiplications, slowing
iteration, current nave implementation. However, solve augmenting
program look-up tables obtaining relevant values rather calculating them.
addition, take advantage symmetry relations table cut
amount calculation required. possible use fact many odometric relations remain unchanged (particularly later iterations algorithm) one iteration
next, therefore values cached shared iterations rather
recalculated iteration.

6.5 Reducing Amount Data
Learning hmms obviously requires visiting states transitioning multiple times,
gather sucient data robust statistical estimation. Intuitively, exploiting odometric data
help reduce number visits needed obtaining reliable model.
examine uence reduction length data sequences quality learnt
models, took one 5 sequences used prefixes length 100 800 (the complete
sequence), increments 100, training sequences. ran two algorithmic settings
8 prefix sequences, 10 times repeatedly. used kl-divergence described
evaluate resulting models respect true model. prefix
length averaged kl-divergence 10 runs.
plot Figure 21 depicts average kl-divergence function sequence length
two settings. demonstrates that, terms kl divergence, algorithm,
uses odometric information, robust face data reduction, (down 200 data
points). contrast, learning without use odometry quickly deteriorates amount
data reduced.
note data sequence twice \wide" odometry used
not; is, information element sequence odometry data
recorded. However, effort recording additional odometric information negligible,
well rewarded fact fewer observations less exploration required
obtaining data sequence sucient adequate learning.
200

fiLearning Geometrically-Constrained HMMs
50

40

30

Odometry

KL
20

10
Odometry Used
0

200

400
Seq. Length

600

800

Figure 21: Average kl divergence function sequence length.

7 Conclusions
Odometric information, often readily available robotics domain, makes possible
learn hidden Markov models eciently effectively, using shorter training sequences.
importantly, contrast traditional perception viewing topological
geometric models two distinct types entities, shown odometric information
directly incorporated traditional topological hmm model, maintaining
convergence reestimation algorithm local maximum likelihood function.
method uses odometric information two ways. first choose initial model,
based odometric information. iterative procedure, extends Baum-Welch
algorithm, used learn topological model environment learning
additional set constrained geometric parameters. additional set constrained parameters constitutes extension basic hmm/pomdp model transitions observations.
Even though primarily interested underlying topological model (transition
observation probabilities), experiments demonstrate use odometric relations
reduce number iterations amount data required algorithm, improve
resulting model.
initialization procedure enforcement additivity constraint relatively
small models prove helpful topologically geometrically. extensive study (Shatkay,
1999) shows long data sequences, generated large models, enforcing antisymmetry rather additivity, leads better topological models.
cases, initialization always good, additivity may over-constrain learning
unfavorable area. Learning large models may benefit enforcing anti-symmetry
first iterations, complete additivity later iterations. Alternatively, may use
algorithm, enforcing additivity, learn separate models small portions environment,
combining later one complete model. similar idea combining small modelfragments complete map environments applied, context geometrical
maps, recent work Leonard Feder (2000).
201

fiShatkay & Kaelbling

work presented demonstrates domain-specific information constraints
enforced part statistical estimation process, resulting better models, requiring
shorter data sequences. strongly believe idea applied domains
robotics. particular, acquisition hmms use molecular biology may greatly benefit
exploiting geometrical (and other) constraints molecular structures. Similarly, temporal
constraints may exploited domains pomdps appropriate decision-support,
air-trac control medicine.

Acknowledgments
thank Sebastian Thrun insightful comments throughout work, John Hughes Luis Ortiz
helpful advice, Anthony Cassandra code generating random distributions, Bill Smart
sustaining Ramona Jim Kurien providing low level code driving her. presentation
paper benefited comments made anonymous referees grateful.
work done authors Computer Science department Brown University,
supported DARPA/Rome Labs Planning Initiative grant F30602-95-1-0020, NSF grants
IRI-9453383 IRI-9312395, Brown University Graduate Research Fellowship.

202

fiLearning Geometrically-Constrained HMMs

Appendix A. Overview Odometric Learning Algorithm
algorithm takes input experience sequence E = hr; V i, consisting odometric
sequence r observation sequence V , defined beginning Section 4.2.
number states assumed given.
Learn Odometric HMM(E)
1 Initialize matrices A; B; R
(See Section 5)
2 max change 1
3 ( max change > )
4 Calculate Forward probabilities,
(Equation 4)
5
Calculate Backward probabilities,
(Equation 5)
6
Calculate state-occupation probabilities, (Equation 6)
7
Calculate State-transition probabilities, ; (Equation 7)
8
Old A; Old B B
9
Reestimate (A)
(Equation 8, left)
10
B Reestimate (B )
(Equation 8, right)
11
R Reestimate (R )
(Equations 12 13)
x

x

12
hR ; R Reestimate(R ; R ) (Equations 10 11)
13
max change MAX(Get Max Change(A; Old );
Get Max Change(B; Old B ))
equations referenced Step 12 correspond updates perpendicularity assumption, global framework used. See (Shatkay, 1999) update formulae within
state-relative framework.
additivity enforced, step 11 followed projection reestimated R onto additive
ane space, described Section 4.3.2. addition, step 12 substituted procedure
described Section 4.3.1. reader referred (Shatkay, 1999) detail.
Get Max Change function takes two matrices returns maximal element-wise
absolute difference them. constant set denote margin error changes
parameters. change parameters \small enough", model regarded
\unchanged".

203

fiShatkay & Kaelbling

References
Abe, N., & Warmuth, M. K. (1992). computational complexity approximating distributions probabilistic automata. Machine Learning, 9 (2), 205{260.
Angluin, D. (1987). Learning regular sets queries counterexamples. Information
Computation, 75, 87{106.
Asada, M. (1991). Map building mobile robot sensory data. Iyengar, S. S., &
Elfes, A. (Eds.), Autonomous Mobile Robots, pp. 312{322. IEEE Computer Society Press.
Bartels, R. (1984). Estimation bidirectional mixture von Mises distributions. Biometrics,
40, 777{784.
Basye, K., Dean, T., & Kaelbling, L. P. (1995). Learning dynamics: System identification
perceptually challenged agents. Artificial Intelligence, 72 (1).
Baum, L. E., Petrie, T., Soules, G., & Weiss, N. (1970). maximization technique occurring
statistical analysis probabilistic functions Markov chains. Annals
Mathematical Statistics, 41 (1), 164{171.
Cassandra, A. R., Kaelbling, L. P., & Kurien, J. A. (1996). Acting uncertainty: Discrete
Bayesian models mobile-robot navigation. Proceedings IEEE/RSJ International
Conference Intelligent Robots Systems.
DeGroot, M. H. (1986). Probability Statistics (2nd edition). Addison-Wesley.
Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood incomplete
data via EM algorithm. Journal Royal Statistical Society, 39 (1), 1{38.
Dissanayake, G., Newman, P., Clark, S., Durrant-Whyte, H. F., & Csorba, M. (2001). solution
simultaneous localization map building (SLAM) problem. IEEE Transactions
Robotics Automation, 17 (3).
Duda, R. O., & Hart, P. E. (1973). Unsupervised Learning Clustering, chap. 6. John Wiley
Sons.
Elfes, A. (1989). Using occupancy grids mobile robot perception navigation. Computer,
Special Issue Autonomous Intelligent Machines, 22 (6), 46{57.
Engelson, S. P., & McDermott, D. V. (1992). Error correction mobile robot map learning.
Proceedings IEEE International Conference Robotics Automation, pp.
2555{2560, Nice, France.
Gold, E. M. (1978). Complexity automaton identification given data. Information
Control, 37, 302{320.
Gumbel, E. G., Greenwood, J. A., & Durand, D. (1953). circular normal distribution:
Theory tables. American Statistical Society Journal, 48, 131{152.
Hopcroft, J. E., & Ullman, J. D. (1979). Introduction Automata Theory, Languages,
Computation. Addison & Wesley.
204

fiLearning Geometrically-Constrained HMMs

Juang, B. H. (1985). Maximum likelihood estimation mixture multivariate stochastic observations Markov chains. AT&T Technical Journal, 64 (6).
Juang, B. H., & Rabiner, L. R. (1985). probabilistic distance measure hidden Markov
models. AT&T Technical Journal, 64 (2), 391{408.
Koenig, S., & Simmons, R. G. (1996a). Passive distance learning robot navigation.
Proceedings Thirteenth International Conference Machine Learning, pp. 266{
274.
Koenig, S., & Simmons, R. G. (1996b). Unsupervised learning probabilistic models robot
navigation. Proceedings IEEE International Conference Robotics Automation.
Kuipers, B., & Byun, Y.-T. (1991). robot exploration mapping strategy based semantic hierarchy spatial representations. Journal Robotics Autonomous Systems,
8, 47{63.
Kullback, S., & Leibler, R. A. (1951). information suciency. Annals Mathematical
Statistics, 22 (1), 79{86.
Leonard, J., Durrant-Whyte, H. F., & Cox, I. J. (1991). Dynamic map building autonomous mobile robot. Iyengar, S. S., & Elfes, A. (Eds.), Autonomous Mobile Robots,
pp. 331{338. IEEE Computer Society Press.
Leonard, J. J., & Feder, H. J. S. (2000). computationally ecient method large-scale concurrent mapping localization. Hollerbach, J., & Kodischek, D. (Eds.), Proceedings
Ninth International Symposium Robotics Research.
Liporace, L. A. (1982). Maximum likelihood estimation multivariate observations Markov
sources. IEEE Transactions Information Theory, 28 (5).
Mardia, K. V. (1972). Statistics Directional Data. Academic Press.
Mataric, M. J. (1990). distributed model mobile robot environment-learning navigation. Master's thesis, MIT, Artificial Intelligence Laboratory.
McLachlan, G. J., & Krishnan, T. (1997). EM Algorithm Extensions. John Wiley &
Sons.
Moravec, H. P. (1988). Sensor fusion certainty grids mobile robots. AI Magazine, 9 (2),
61{74.
Moravec, H. P., & Elfes, A. (1985). High resolution maps wide angle sonar. Proceedings
International Conference Robotics Automation, pp. 116{121.
Nourbakhsh, I., Powers, R., & Birchfield, S. (1995). Dervish: oce-navigating robot. AI
Magazine, 16 (1), 53{60.
Pierce, D., & Kuipers, B. (1997). Map learning uninterpreted sensors effectors. Artificial Intelligence, 92 (1-2), 169{227.
205

fiShatkay & Kaelbling

Rabiner, L. R. (1989). tutorial hidden Markov models selected applications speech
recognition. Proceedings IEEE, 77 (2), 257{285.
Rivest, R. L., & Schapire, R. E. (1987). Diversity based inference finite automata.
Proceedings IEEE Twenty Eighth Annual Symposium Foundations Computer
Science, pp. 78{87, Los Angeles, California.
Rivest, R. L., & Schapire, R. E. (1989). Inference finite automata using homing sequences.
Proceedings Twenty First Annual Symposium Theory Computing, pp. 411{420,
Seattle, Washington.
Ron, D., Singer, Y., & Tishbi, N. (1994). Learning probabilistic automata variable memory length. Proceedings Seventh Annual Workshop Computational Learning
Theory, pp. 35{46.
Ron, D., Singer, Y., & Tishbi, N. (1995). learnability usage acyclic probabilistic
finite automata. Proceedings Eighth Annual Workshop Computational Learning
Theory, pp. 31{40.
Ron, D., Singer, Y., & Tishby, N. (1998). learnability usage acyclic probabilistic
finite automata. Journal Computer Systems Science, 56 (2).
Shatkay, H. (1999). Learning Models Robot Navigation. Ph.D. thesis, Department Computer Science, Brown University, Providence, RI.
Shatkay, H., & Kaelbling, L. P. (1997). Learning topological maps weak local odometric
information. Proceedings Fifteenth International Joint Conference Artificial
Intelligence, Nagoya, Japan.
Shatkay, H., & Kaelbling, L. P. (1998). Heading right direction. Proceedings
Fifteenth International Conference Machine Learning, Madison, Wisconsin.
Simmons, R. G., & Koenig, S. (1995). Probabilistic navigation partially observable environments. Proceedings International Joint Conference Artificial Intelligence.
Smith, R., Self, M., & Cheeseman, P. (1991). stochastic map uncertain spatial relationships. Iyengar, S. S., & Elfes, A. (Eds.), Autonomous Mobile Robots, pp. 323{330. IEEE
Computer Society Press.
Thrun, S. (1999). Learning metric-topological maps indoor mobile robot navigation. AI
Journal, 1, 21{71.
Thrun, S., & Bucken, A. (1996a). Integrating grid-based topological maps mobile robot
navigation. Proceedings Thirteenth National Conference Artificial Intelligence,
pp. 944{950.
Thrun, S., & Bucken, A. (1996b). Learning maps indoor mobile robot navigation. Tech. rep.
CMU-CS-96-121, School Computer Science, Carnegie Mellon University, Pittsburgh,
PA.
Thrun, S., Burgard, W., & Fox, D. (1998a). probabilistic approach concurrent map acquisition localization mobile robots. Machine Learning, 31, 29{53.
206

fiLearning Geometrically-Constrained HMMs

Thrun, S., Gutmann, J.-S., Fox, D., Burgard, W., & Kuipers, B. J. (1998b). Integrating topological metric maps mobile robot navigation: statistical approach. Proceedings
Fifteenth National Conference Artificial Intelligence, pp. 989{995.
Vapnik, V. N. (1995). Nature Statistical Learning Theory. Springer.

207


