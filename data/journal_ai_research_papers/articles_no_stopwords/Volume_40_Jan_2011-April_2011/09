Journal Artificial Intelligence Research 40 (2011) 353-373

Submitted 07/10; published 01/11

Clause-Learning Algorithms Many Restarts
Bounded-Width Resolution
Albert Atserias

atserias@lsi.upc.edu

Universitat Politecnica de Catalunya
Barcelona, Spain

Johannes Klaus Fichte

fichte@kr.tuwien.ac.at

Vienna University Technology
Vienna, Austria

Marc Thurley

marc.thurley@googlemail.com

University California Berkeley
Berkeley, USA

Abstract
offer new understanding aspects practical SAT-solvers based
DPLL unit-clause propagation, clause-learning, restarts. analyzing
concrete algorithm claim faithful practical solvers do. particular,
making new decision restart, solver repeatedly applies unit-resolution
rule saturation, leaves component mercy non-determinism except
internal randomness. prove perhaps surprising fact that, although
solver explicitly designed it, high probability ends behaving width-k
resolution O(n2k+2 ) conflicts restarts, n number
variables. words, width-k resolution thought O(n2k+2 ) restarts
unit-resolution rule learning.

1. Introduction
discovery method introduce practically feasible clause learning non-chronological backtracking DPLL-based solvers layed foundation sometimes called
modern SAT-solving (Silva & Sakallah, 1996; Bayardo & Schrag, 1997). methods
set ground new effective implementations (Moskewicz, Madigan, Zhao, Zhang, &
Malik, 2001) spawned tremendous gains efficiency SAT-solvers many
practical applications. great somewhat unexpected success seemed contradict
widely assumed intractability SAT, time uncovered need
formal understanding capabilities limitations underlying methods.
Several different approaches suggested literature developing rigorous understanding. Among find proof-complexity approach, captures
power SAT-solvers terms propositional proof systems (Beame, Kautz, & Sabharwal, 2003, 2004; Hertel, Bacchus, Pitassi, & Gelder, 2008; Pipatsrisawat & Darwiche,
2009), rewriting approach, provides useful handle reason
properties underlying algorithms correctness (Nieuwenhuis, Oliveras, &
Tinelli, 2006). approaches, SAT-solvers viewed algorithms search
proofs underlying proof system propositional logic. view mind,
illuminating understand proof system underlying modern solvers always
c
2011
AI Access Foundation. rights reserved.

fiAtserias, Fichte, & Thurley

subsystem resolution (Beame et al., 2003). particular, means performance never beat resolution lower bounds, time provides many
explicit examples SAT-solvers require exponential time. Complementing
result idealized SAT-solver relies non-determinism apply techniques
best possible way able perform good general resolution (weak forms
statement first established Beame et al., 2003, 2004; Hertel et al., 2008,
current form Pipatsrisawat & Darwiche, 2009). Beame et al. (2004) put it,
negative proof complexity results uncover examples inherent intractability even
perfect choice strategies, positive proof complexity results give hope finding
good choice strategy.
work add new perspective kind rigorous result. try avoid
non-deterministic choices components abstract solver still get positive proof
complexity results. main finding concrete family SAT-solvers
rely non-determinism besides mild randomness least powerful bounded-width
resolution. precise proof-complexity result unit-propagation rule
standard learning scheme considered state-of-the-art solvers, totally random decision strategy needs O(k 2 ln(kn)n2k+1 ) conflicts deterministic restarts
detect unsatisfiability CNF formula n variables width-k resolution
refutation, probability least 1/2. Remarkably, analysis provide exact expression upper bound holds values n k particular bound
get asymptotic. Another remarkable feature analysis insensitive
whether algorithm implements non-chronological backtracking heuristic-based decisions provided restarts often enough, provided performs totally random decisions
often enough. details given Section 2.
result nice theoretical consequences, shall sketch briefly.
First, although explicitly designed purpose, SAT-solvers able solve instances 2-SAT polynomial time since every unsatisfiable 2-CNF formula resolution
refutation width two. strongly, result interpreted showing widthk resolution simulated O(k 2 ln(kn)n2k+1 ) rounds unit-clause propagation.
knowledge, tight connection width-k resolution repeated application
width-one methods unknown before. Another consequence SAT-solvers
able solve formulas bounded branch-width (and hence bounded treewidth) polynomial time. elaborate later paper. Finally, partial automatizability
results Ben-Sasson Wigderson (1999), follows SAT-solvers able solve
formulas polynomial-size tree-like resolution proofs quasipolynomial time,
formulas polynomial-size general resolution proofs subexponential time.
Concerning techniques, perhaps surprising proof main result
proceed showing width-k refutation learned algorithm.
know produced proof much larger width. thing show
every width-k clause refutation absorbed algorithm, means
behaves learned, even though might not. particular, literal
complement absorbed, algorithm correctly declares formula
unsatisfiable. sort analysis main technical contribution paper.
354

fiClause-Learning Algorithms

1.1 Related Work
first attempt compare power SAT-solvers power resolution
proof system made Beame et al. (2003, 2004). main positive result
work clause learning specific learning scheme without restarts
provide exponentially shorter proofs proper refinements resolution tree,
regular, positive resolution. Furthermore, show modification standard
solver allow multiple assignments variable would able simulate general
resolution efficiently, assuming ideal decision strategy. Following work showed
requirement multiple assignments variable technical issue
avoided given CNF formula pre-processed appropriately (Hertel et al., 2008).
work avoid two maneuvers introducing concept clause-absorption
help us analyze standard algorithms directly.
Interestingly, clauses logical consequences input formulas, concept
clause-absorption turns dual concept 1-empowerment introduced
independently Pipatsrisawat Darwiche (2009)1 . used 1-empowerment show
SAT-solvers without conceptual modification operation able simulate
general resolution efficiently, assuming ideal decision strategy. comparison,
goal settles weaker simulation result, bounded-width resolution instead general
resolution, rely non-determinism ideal decision. show
totally random decision strategy good enough purpose, provided restart often
enough. complete point, worth noting non-automatizability results
Alekhnovich Razborov (2008) indicate cannot expect efficient simulation
general resolution completely avoid non-determinism time.
fact concepts discovered independently adds confidence belief
play role subsequent studies power SAT-solvers. Indeed,
techniques recently extended show SAT-solvers totally random decision
strategy able efficiently simulate local consistency techniques general constraint
satisfaction problems (Jeavons & Petke, 2010).
1.2 Organization
Section 2 introduce basic notation define algorithm analyze.
discuss dependence results choice learning scheme, restart policy
decision strategy used algorithm. Section 3 starts elementary
facts runs algorithm, continues key definitions absorption
beneficial rounds, analysis running time algorithm. Section 4
contains discussion consequences, including implications formulas bounded
treewidth.

2. Clause Learning Algorithms
section define algorithm discuss choice components.
start preliminary definitions.
1. Note that, originally, weaker version 1-empowerment introduced Pipatsrisawat Darwiche
(2008).

355

fiAtserias, Fichte, & Thurley

2.1 Preliminaries
Let V = {v1 , . . . , vn } fixed set propositional variables. literal propositional
variable x negation x. use notation x0 x x1 x. Note xa
defined way assignment x = satisfies it. {0, 1}, use
1 a, literal ` = xa use ` x1a . clause set literals,
formula conjunctive normal form (CNF-formula) set clauses. width
clause number literals it. following, formulas set
variables V every clause contains literals variables V .
two clauses = {x, `1 , . . . , `r } B = {x, `01 , . . . , `0s } define resolvent
B x Res(A, B, x) = {`1 , . . . , `r , `01 , . . . , `0s }. variable resolve on, x,
implicit simply write Res(A, B). clause may contain literal negation. Note
resolvent Res(A, B, x) B x still well-defined case. resolution
refutation CNF formula F sequence clauses C1 , . . . , Cm Cm =
clause Ci sequence either belongs F resolvent previous clauses
sequence. length refutation number clauses sequence.
clause C, variable x, truth value {0, 1}, restriction C x =
constant 1 literal xa belongs C, C \ {x1a } otherwise. write C|x=a
restriction C x = a.
partial assignment sequence assignments (x1 = a1 , . . . , xr = ar )
variables distinct. Let partial assignment. say satisfies literal xa
contains x = a. say falsifies contains x = 1 a. C clause, let
C| result applying restrictions x1 = a1 , . . . , xr = ar C. Clearly order
matter. say satisfies C satisfies least one literals; i.e.,
C| = 1. say falsifies C falsifies literals; i.e., C| = . set
clauses, let D| denote result applying restriction clause D,
removing resulting 1s. call D| residual set clauses.
2.2 Definition Algorithm
state sequence assignments (x1 = a1 , . . . , xr = ar ) variables

distinct assignments marked decisions. use notation xi = ai
denote assignment xi = ai decision assignment. case xi called
decision variable. rest assignments called implied assignments. use
denote states. empty state one without assignments. Define decision level
assignment xi = ai number decision assignments (x1 = a1 , . . . , xi = ai ).
convenient, identify state underlying partial assignment
decision marks ignored.
2.2.1 Operation
algorithm maintains current state current set clauses D. four
modes operation DEFAULT, CONFLICT, UNIT, DECISION. algorithm starts
DEFAULT mode empty state current state given CNF formula
current set clauses:
356

fiClause-Learning Algorithms

DEFAULT. sets variables satisfies clauses D, stop output
SAT together current state S. Otherwise, D|S contains empty clause,
move CONFLICT mode. Otherwise, D|S contains unit clause, move UNIT
mode. Finally, control reaches point, move DECISION mode.
CONFLICT. Apply learning scheme add new clause C D. C empty
clause, stop output UNSAT. Otherwise, apply restart policy decide whether
continue restart DEFAULT mode current initialized
empty state. case continue further, repeatedly remove assignments
tail long C|S = , go UNIT mode.
UNIT. unit clause {xa } D|S , add x = go back DEFAULT
mode.


DECISION. Apply decision strategy determine decision x = added
go back DEFAULT mode.

guarantee correctness termination, learning scheme always add clause C
logical consequence D, C|S = holds time added,
contains one variable maximum decision level. hard see
properties prevent clause learned twice, since number clauses
variables finite, implies termination. Clauses characteristics
always exist include asserting clauses (Zhang, Madigan, Moskewicz, & Malik,
2001) discussed Section 2.3.3.
well-known DPLL-procedure precursor algorithm where, CONFLICT
mode, learning scheme never adds new clause, restart policy dictate
restart all, assignments removed tail latest decision


assignment, say x = a, replaced x = 1 a. say DPLL-procedure
backtracks latest decision. contrast, modern SAT-solvers implement learning
schemes backtrack literal, determined learned clause, necessarily latest decision. called non-chronological backtracking. Besides learning
schemes non-chronological backtracking, modern SAT-solvers implement restart
policies appropriate decision strategies. discuss choice components
algorithm Section 2.3.
2.2.2 Runs Algorithm
Consider run algorithm started DEFAULT mode empty state initial
set clauses D, either clause falsified variables set. run called
complete round started represent sequence states S0 , . . . , Sm
algorithm goes through, S0 empty state Sm state
either variables set, falsified clause found. generally, round
initial segment S0 , . . . , Sr complete round state either D|Sr contains
empty clause D|Sr contain unit clause. D|Sr contains empty clause
say round conclusive. round conclusive call inconclusive.
357

fiAtserias, Fichte, & Thurley

term inconclusive means reflect fact clause learned round.
particular, (complete) round ends satisfying assignment inconclusive2 .
round S0 , . . . , Sr , note {1, . . . , r}, state Si extends Si1 exactly

one assignment form xi = ai xi = ai depending whether UNIT DECISION
executed iteration; mode assigns variables. lead
confusion, identify round last state interpreted partial assignment.
particular, say round satisfies clause C C|Sr = 1, falsifies
C|Sr = .
2.3 Restart Policy, Learning Scheme, Decision Strategy
following discuss choice learning scheme, restart policy
decision strategy used algorithm. discussion particularly focus
dependence results choice.
2.3.1 Restart Policy
restart policy determines whether restart search clause learned.
important characteristic need restart policy dictate
restarts often enough. particular, analysis work equally well aggressive restart policies, one dictates restart every conflict,
less aggressive strategy allows bounded number conflicts restarts.
fact analysis insensitive follow monotonicity property
performance algorithm prove Lemma 5. precisely,
follow monotonicity lemma decide use policy allows c > 1
conflicts restart, upper bound number required restarts
decrease (or stay same). upper bound number conflicts would
appear multiplied factor c, even though truth might even decrease
well. simplicity exposition, rest paper assume restart
policy dictates restart every conflict.
2.3.2 Decision Strategy
decision strategy determines variable assigned next, value. Again,
important characteristic need decision strategy
allow round totally random decisions often enough. Here, totally random decision
defined follows: current state algorithm S, choose variable x
uniformly random among variables V appear S, value
{0, 1} uniformly random independently choice x. Thus, analysis
actually applies decision strategy allows bounded number rounds
heuristic-based decisions totally random ones. precisely, allow say c > 1
rounds non-random decisions random ones, number required restarts
conflicts would appear multiplied factor c. follow
2. Let us note definitions round, conclusive round inconclusive round differ slightly
given conference version paper (Atserias, Fichte, & Thurley, 2009). current
definitions make concepts robust.

358

fiClause-Learning Algorithms

monotonicity lemma referred above. said, simplicity exposition assume
following every decision totally random.
2.3.3 Learning Scheme
learning scheme determines clause added set clauses
conflict occurs. Let S0 , . . . , Sr conclusive round started set clauses

ends falsifying clause D. Let xi = ai xi = ai i-th assignment
round. annotate Si clause Ai reverse induction {1, . . . , r}:
1. Let Ar+1 clause falsified Sr .


2. r xi = ai decision, let Ai = Ai+1 .
3. r xi = ai implied, let Bi clause Bi |Si1
unit clause {xai }, let Ai = Res(Ai+1 , Bi , xi ) clauses resolvable
xi , let Ai = Ai+1 otherwise.
quite clear construction Ai resolution proof clauses
D. fact, resolution proof linear even trivial sense Beame et al.
(2004). call clause Ai conflict clause. denotes maximum decision level
assignments Sr , conflict clause called asserting clause contains exactly
one variable decision level d. Asserting clauses, originally defined Zhang et al. (2001),
capture properties conflict clauses learned virtually modern SAT-solver.
brevity, describe two concrete learning schemes detail. schemes see
work Zhang et al. (2001).
Decision learning scheme adds clause A1 current set clauses
conflict. hard check A1 asserting clause. Furthermore, every literal
A1 negation decision literal Sr ; important later on.
1UIP learning scheme, stands 1st Unique Implication Point, one adds
clause Ai r maximal subject condition Ai asserting
clause.
following assume, tacitly, algorithm employs asserting
learning scheme, is, one whose learned clauses always asserting, except
empty clause.
2.3.4 Clause Bookkeeping
mentioned analysis relies crucially assumption learned
clauses never removed current set clauses. However, practical SAT-solvers
periodically delete learned clauses save memory avoid overhead
introduce. Thus interesting question whether results made work
without assumption. respect, strong proof-complexity results Nordstrom
(2009) showing every small-width resolution refutation made work
small clause-space seems indicate assumption similar indeed needed.
Another remark worth making point concerns width learned clauses.
Since goal show algorithm simulate small-width resolution, seems
natural ask whether restrict learning scheme learn clauses small width
359

fiAtserias, Fichte, & Thurley

only. mentioned introduction, analysis seem allow it. Moreover,
recent results Ben-Sasson Johannsen (2010) show that, general, learning short
clauses provably weaker scheme learning arbitrarily long clauses. Thus,
examples Ben-Sasson Johannsen (2010) small-width resolution
refutations therefore show keeping long clauses actually required
case, conceivable might.

3. Analysis Algorithm
section analyze running time algorithm. this,
however, introduce key technical concepts absorption beneficial
rounds, study important properties.
3.1 Runs Algorithm
Let R R0 rounds, let C clause. say R0 subsumes R if, decision
marks, every assignment R appears R0 . say R R0 agree C
restrictions R R0 variables C equal: every variable C either unassigned
both, assigned value both. say R branches C decision
variables R variables C. Note properties agree C branches C
depend set variables C. define clauses simplify notation
later on.
prove two rather technical lemmas. goal show inconclusive rounds
robust respect order assignments made. example, first
lemma shows inconclusive round subsumes round agrees
decisions. fact need slightly stronger claim involves rounds two
different sets clauses.
Lemma 1. Let D0 sets clauses D0 , let C clause, let R0
inconclusive round started D0 . Then, every round R started branches
C agrees R0 C, holds R0 subsumes R.
Proof. Let R = (S0 , . . . , Sr ). induction i, prove every {0, . . . , r}, every
assignment Si made R0 . = 0 nothing prove since S0 = . Let

> 0 assume every assignment Si1 made R0 . Let x = x =
last assignment Si . Since R R0 agree C R branches C, every decision

assignment made R made R0 . takes care case x = a. Suppose
last assignment x = Si implied. means exists clause
A|Si1 = {xa }. Since D0 every assignment made Si1
made R0 , necessarily x = appears R0 R0 inconclusive cannot leave
unit clauses unset.
next lemma shows universal quantifier conclusion previous
lemma void. addition, round chosen inconclusive.
Lemma 2. Let D0 sets clauses D0 , let C clause, let R0
inconclusive round started D0 . Then, exists inconclusive round R started
branches C agrees R0 C, R0 subsumes R.
360

fiClause-Learning Algorithms

Proof. Let R0 = (T0 , . . . , Tt ). Define {0, . . . , t} set indices i-th

assignment R0 assigns variable C. I, let xi = ai xi = ai i-th
assignment R0 .
construct round R = (S0 , . . . , Ss ) started inductively. Associated
Sj set Ij indices xi left unassigned Sj . Recall S0
empty state definition. Hence I0 = I. define following process:
1. Sj falsifies clause sets variables V set = j stop.
2. Otherwise, unit clause {xa } D|Sj let Sj+1 Sj plus x = a.
3. Otherwise, Ij non-empty, let minimum element Ij , let Sj+1

obtained adding decision xi = ai Sj .
none cases applies set = j stop process.
construction R valid round started D. Let us see R0 subsumes R: let
set literals made true decisions R. construction, R R0 agree
hence R0 subsumes R Lemma 1. Furthermore, R inconclusive: D0
R0 inconclusive, D|R0 contain empty clause, R0 subsumes
R, D|R contain empty clause. Further, every variable C belongs
V R inconclusive, process stops = . Together fact R0
subsumes R, shows R R0 agree C. Note finally R branches C
construction.
3.2 Absorption
One key feature definition round inconclusive, residual set
clauses contain unit clauses and, particular, closed unit propagation.
means inconclusive round R started D, clause R
falsifies literals one, R must satisfy remaining literal, hence
well. Besides D, clauses may property, important enough
deserve definition:
Definition 3 (Absorption). Let set clauses, let non-empty clause let
xa literal A. say absorbs xa every inconclusive round started
falsifies \ {xa } assigns x a. say absorbs absorbs every
literal A.
Naturally, absorbs xa say absorbed xa .
Intuitively, one way think absorbed clauses learned implicitly. rest
section devoted make intuition precise. now, let us note
inconclusive rounds started D, every clause absorbed. agrees
given intuition since absence inconclusive rounds means unit-clause propagation
applied produces empty clause. section show notion
clause-absorption tightly connected concept 1-empowerment independently
introduced Pipatsrisawat Darwiche (2009).
361

fiAtserias, Fichte, & Thurley

3.2.1 Properties Absorption
continue, let us discuss key properties absorption. argued already
every clause absorbed D. give example showing may absorb
clauses. Let set consisting three clauses
b

bc

b e.

example, clause c belong absorbed since every inconclusive round sets = 0 must set c = 1 unit-propagation, every inconclusive
round sets c = 0 must set = 1 unit-propagation. may absorb
clauses saw, note every non-empty clause absorbed logical
consequence D. write |= C, every satisfying assignment satisfies C.
Lemma 4. Let set clauses let C non-empty clause. absorbs C,
|= C.
Proof. Let full assignment satisfies clauses D. want show
satisfies C well. Let R = (S0 , . . . , Sr ) complete round algorithm started
sets decision variables set S. induction {0, . . . , r},
show Si follow R stopped conflict therefore
Sr = S. particular R inconclusive, falsifies literals C one, must
satisfy remaining one C absorbed. Since R sets variables C Sr = S,
means satisfies C.
remains show Si every i. = 0 nothing show since

S0 = . Fix > 0 assume Si1 S. Let x = x = last assignment

Si . case x = taken care assumption decision variables R set
S. Suppose last assignment x = implied. means exists
clause A|Si1 = {xa }. Since satisfies Si1 S, necessarily x
set S.
Next, let us see converse lemma hold; namely, see
every implied clause absorbed. previous example, instance, note
bde consequence (resolve first third clause a) absorbed


(consider inconclusive round = 0, e = 0).
One interesting property illustrated example C resolvent
two absorbed clauses B, C absorbed literal `, ` appears
B. example above, absorb b e b, b appears
clauses b b e D, whose resolvent precisely b e.
prove general fact next section objects study non-absorbed
resolvents absorbed clauses.
Next show three key monotonicity properties clause-absorption, first
one motivated definition.
Lemma 5. Let E sets clauses let B non-empty clauses.
following hold:
1. belongs D, absorbs A,
362

fiClause-Learning Algorithms

2. B absorbs A, absorbs B,
3. E absorbs A, E absorbs A.
Proof. prove 1. assume contradiction literal ` inconclusive
round S0 , . . . , Sr started falsifies A\{`} satisfy A. round
inconclusive, cannot A|Sr = , means A|Sr = {`}, contradiction
definition round.
proof 2. let ` literal B define B 0 = B \ {`}. consider two
different cases. `
/ B 0 and, absorbed D, inconclusive
round falsifies B 0 . Thus B absorbed case. ` A, let A0 = \ {`} let
S0 , . . . , Sr inconclusive round started falsifies B 0 . falsifies A0
satisfies absorption. Thus satisfies B, B absorbed case well.
remains prove 3. Let ` literal A0 = \ {`}. Let R0
inconclusive round started E falsifies A0 . Lemma 2, inconclusive
round R started falsifies A0 subsumed R0 . absorbed
D, see R (and hence R0 ) satisfies A.
3.2.2 Absorption Empowerment
next goal show absorption empowerment dual notions. assignments , write every assignment . Let us reproduce
definition 1-empowerment work Pipatsrisawat Darwiche (2009), slightly
adapted better suit notation terminology.
Definition 6 (1-Empowerment Pipatsrisawat & Darwiche, 2009). Let set
clauses, let C non-empty clause let xa literal C. Let assignment
sets = 1 b every literal b C \ {xa }. say C 1-empowering via xa
respect D, following three conditions met:
1. C logical consequence D; i.e. |= C,
2. repeated applications unit-clause propagation D| yield empty clause,
3. repeated applications unit-clause propagation D| assign x a.
say xa empowering literal C. say C 1-empowering
1-empowering via literal C.
preliminary version definition given Pipatsrisawat Darwiche (2008)
second three conditions required.
definition absorption, see non-empty clause absorbed
set clauses D, inconclusive round R started literal xa
R falsifies \ {xa } satisfy {xa }. logical consequence
D, witnesses precisely fact 1-empowering via xa . show
converse true:
Lemma 7. Let set clauses, let C non-empty clause |= C,
let xa literal C. Then, C 1-empowering via xa respect
absorb C xa .
363

fiAtserias, Fichte, & Thurley

Proof. Let C 0 = C\{xa }. Assume first absorb C xa . Let R = (S0 , . . . , Sr )
inconclusive round started witnessing fact, i.e. Sr falsifies C 0
assign x = a. particular Sr . Furthermore, every unit clause {y b } D|
= b Sr , R inconclusive round. straightforward induction,
see every obtained repeated applications unit-clause propagation
D| satisfies Sr . directly implies conditions 2. 3. definition
1-empowerment. Condition 1. met assumption.
converse, assume C 1-empowering via xa respect D.
show inconclusive round started falsifies C 0 assign
x = a. Let R = (S0 , . . . , Sr ) round started every decision assignment
chosen falsify literal C 0 , that, among rounds property, assigns
many literals C 0 possible. Clearly maximal round exists since one
make decision meets property.
shall show R round seek. {0, . . . , r}, let
maximal assignment Si , let obtained repeated applications
unit-clause propagation D|i , let subset assignments
Si . particular Si . shall prove, induction i, Si hence
Si = .
base case = 0 trivial since S0 = . Assume > 0 Si1 i1 .
i-th assignment Si decision assignment, construction falsifies literal
C 0 hence belongs . belongs , required.
i-th assignment Si implied distinguish two cases: whether belongs
not. implied assignment , , required.
implied assignment , = i1 hence = i1 . then, since
Si1 i1 induction hypothesis i1 i1 , unit clause responsible
definition Si appears process forming i1 hence process forming
. Therefore assignment .
completes induction shows, particular, Sr = r . point 2.
definition 1-empowerment, R inconclusive. Furthermore, point 3. definition
1-empowerment, Sr assign x = a. remains show Sr falsifies C 0 . First
note that, maximality R fact R inconclusive, every literal C 0
assigned R. Moreover, since decision assignments R chosen falsify
literals C 0 , suffices show implied assignments R satisfy literal
C 0 . Thus, suppose contradiction = b implied assigned R
b literal C 0 . Let {0, . . . , r} {y b } unit-clause D|Si . Since
Si Sr r assigned 1 b , unit-clause {y b } D|Si appears
empty clause closure unit-clause propagation D| ; contradicts point 2.
definition 1-empowerment completes proof.

Let us note point condition 1. definition 1-empowerment
dropped, hypothesis |= C dropped Lemma 7. would
make 1-empowerment absorption literally dual other.
364

fiClause-Learning Algorithms

3.3 Beneficial Rounds
shall study key situation explains algorithm possibly simulate
resolution proofs. Consider resolvent C = Res(A, B) two absorbed clauses B
itself, however, absorbed. goal study A, B C look
case. start showing C absorbed literal ` C, `
appears B. property held key discovering concept clauseabsorption relevance simulation resolution proofs. similar connection
clause learning observed Pipatsrisawat Darwiche (2008), pointed
condition literal C appears B known merge
resolution (Andrews, 1968).
Lemma 8. Let set clauses, let B two resolvable clauses absorbed
D, let C = Res(A, B). ` literal C absorb C `, `
appears B.
Proof. Let C = Res(A, B, y), let A0 = \ {y} B 0 = B \ {y}. Let
` = xa literal C assume absorb C `. exists
inconclusive round R falsifies C \ {xa } set x a. Since ` belongs C
C = A0 B 0 ` belongs B, both. belongs both,
done. Otherwise, assume without loss generality belongs
B. case R falsifies B \ {y}, since B absorbed, set 0 R. R
falsifies \ {xa }, since absorbed, x set R. contradicts choice
R x set a.
continue showing situation interest, always exist beneficial
round algorithm predicts eventual absorption.
Definition 9 (Beneficial Round). Let set clauses, let non-empty clause,
let xa literal A, let R inconclusive round started D. say R
beneficial xa falsifies \ {xa }, branches \ {xa }, leaves x unassigned,

yields conclusive round extended decision x = . conclusive round obtained

extending R x = called beneficial xa . say R beneficial
beneficial literal A.
words, round started beneficial xa witness
absorb xa , minimal property, yet yields conflict
x set wrong value. Thus, informally, beneficial round witness
almost absorbs xa .
Lemma 10. Let set clauses, let B two resolvable clauses
absorbed D, let C = Res(A, B). C non-empty absorbed D,
round started beneficial C.
Proof. identify literal xa C able build beneficial round C
xa .
Let C = Res(A, B, y), let A0 = \ {y} B 0 = B \ {y}. C
non-empty absorbed D, literal xa C inconclusive round R0
365

fiAtserias, Fichte, & Thurley

started falsifies C 0 = C \ {xa } set x a. x assigned
R0 since otherwise would falsify C, C = A0 B 0 absorbs
B, would satisfied R0 . shows x unassigned R0 .
Let R inconclusive round started obtained applying Lemma 2
C 0 given inconclusive round R0 . claim R beneficial C xa :
round R falsifies C 0 , agrees R0 C 0 . R branches C 0 and, R0 subsumes
R, leaves x unassigned. Finally, note R R0 agree \ {y} B \ {y}.

Hence extending round R decision x = yields conclusive round; otherwise
would satisfied since B absorbed D.
3.4 Main Technical Lemma
start analyzing number complete rounds takes resolvent
two absorbed clauses absorbed function width. However, trivial
first determine number complete rounds takes sufficient prerequisite
absorption occurs: beneficial round.
Lemma 11. Let set clauses, let B two resolvable clauses
absorbed non-empty resolvent C = Res(A, B). Let n total
number variables D, k width C. every 1, let R0 , . . . , Rt1 denote
consecutive complete rounds algorithm started D, let D0 , . . . , Dt1
denote intermediate sets clauses. Then, probability none Ri beneficial
k
C none Di absorbs C et/(4n ) .
Proof. Let R0 , . . . , Rt1 denote consecutive complete rounds algorithm started
D, let D0 , . . . , Dt1 intermediate sets clauses. particular D0 =
Ri round started Di . every {0, . . . , 1} let Ri event Ri
beneficial let Di event Di absorb C. want compute
upper bound joint probability events. Note
"t1
# t1 "
# t1 "
#
j1
j1

\


\
\

Pr
Ri =
Pr Rj Dj
Ri
Pr Rj Dj
Ri
(1)
i=0

j=0

i=0

j=0

i=0

Hence, shall give appropriate upper bounds factors right hand side
inequality. this, let us first bound Pr Rj | Dj , Rj1 , Dj1 , . . . , R0 , D0
below. conditions Dj , Rj1 , Dj1 , . . . , R0 , D0 , Lemma 10 implies
inconclusive round R started Dj beneficial C xa C.
probability Rj beneficial C bounded probability Rj
beneficial C xa . therefore bound latter below.
First let us compute lower bound probability first k 1 decisions

decision strategy chosen falsify C \ {xa } k-th choice x = a. probability
choices made least






k1
k2
1
1
(k 1)!
1


k.
k
k
2n
2(n 1)
2(n k + 2)
2(n k + 1)
2 n
4n
Note round started Dj follows choices may even able
decisions corresponding assignments may implied. However,
366

fiClause-Learning Algorithms



decision x = made, round following choices perform decisions
agree R C \ {xa } therefore stay subsumed R every new decision,

Lemma 1. particular, right decision x = inconclusive, falsify
C \ {xa }, leave x unset. Lemma 1 performed assignments

R order, therefore addition x = make conclusive. follows
probability round beneficial C xa bigger.
Consequently, probability Rj conditional Dj , Rj1 , Dj1 , . . . , R0 , D0 bounded
1 4n1k . Therefore, equation (1)
Pr

"t1
\
i=0

#
Ri



1
k
1 k
et/(4n )
4n

second inequality used fact 1 + x ex every real number x.
3.5 Bounds
tools given above, able prove main result paper:
simulation width-k resolution algorithm. shall first give proof
algorithm employing Decision learning scheme. proof easier
instructive, get slightly better bounds special case. Afterwards,
see result asserting learning schemes general.
3.5.1 Decision Scheme
fact makes Decision easier analyze that, learning scheme,
occurrence beneficial round immediately yields absorption next step. Indeed,
R beneficial C, branches C, means clause learned
complete round subset C. particular means next set clauses
absorb subset C, hence C well Lemma 5. obtain following result
direct consequence Lemma 11.
Lemma 12. Let set clauses, let B two resolvable clauses
absorbed non-empty resolvent C = Res(A, B). Let n total
number variables k width C. Then, 1, using Decision
learning scheme, probability C absorbed current set clauses
k
restarts et/(4n ) .
Proof. Let R0 , . . . , Rt1 denote consecutive complete rounds algorithm started
D, let D0 , . . . , Dt intermediate sets clauses. particular D0 =
Ri round started Di . every {0, . . . , 1} let Ri event
Ri beneficial C let Di event Di absorb C. one
Ri beneficial C, Di+1 absorbs C. see this, note R branches
C, clause Ci learned Ri satisfies Ci C. Hence Di+1 absorbs Ci C
Lemma 5. Further, Dt absorbs C, one Di absorbs Lemma
5. Hence,
probability C absorbed Dt bounded Pr[ t1
i=0 Ri Di ].
k)
t/(4n
Lemma 11 implies bounded e
.
367

fiAtserias, Fichte, & Thurley

Theorem 13. Let F set clauses n variables resolution refutation
width k length m. probability least 1/2, algorithm started F , using
Decision learning scheme, learns empty clause 4m ln(4m)nk conflicts
restarts.
Proof. resolution refutation must terminate application resolution rule
form Res(x, x). show ` = x ` = x, probability
{`} absorbed current set clauses 4m ln(4m)nk restarts 1/4.
Thus, {x} {x} absorbed probability least 1/2. case,
straightforward every complete round algorithm conclusive. particular,
round make decision conclusive, case empty
clause learned.
Let C1 , C2 , . . . , Cr = {`} resolution proof {`} included width-k
resolution refutation F . particular r m1 every Ci non-empty width
k. Let D0 , D1 , . . . , Ds sequence clause-sets produced algorithm
= rt = d4 ln(4r)nk e. every {0, . . . , r}, let Ei event every
clause initial segment C1 , . . . , Ci absorbed Dit , let E negation. Note
Pr[ E0 ] = 1 vacuously hence Pr[ E 0 ] = 0. > 0, bound probability
Ei hold conditional Ei1 cases. Let pi = Pr[ E | Ei1 ] probability.
Ci clause F , pi = 0 Lemma 5. Ci derived two previous clauses,
k
pi et/(4n ) Lemma 12, 1/(4r) choice t.
law total probability gives






Pr E = Pr E | Ei1 Pr [Ei1 ] + Pr E | E i1 Pr E i1




Pr E | Ei1 + Pr E i1 .



P
Adding {1, . . . , r}, together Pr E 0 = 0, gives Pr E r ri=1 pi
r
1
4r = 4 . Since probability Cr absorbed Drt bounded Pr[ E r ],
proof follows.
3.5.2 Asserting Learning Schemes General
shall study algorithm applying arbitrary asserting learning scheme.
analysis bit complex Decision scheme since general clause
learned complete round R cannot assumed subset decisions R.
Therefore show resolvent eventually absorbed little detour.
note proof overcome similar difficulties as, inspired by3 , proof
Proposition 2 work Pipatsrisawat Darwiche (2009).
need preparation. Let C clause set clauses. Let WC,D
denote set literals ` C exists inconclusive round started
beneficial C `. Let u`,C,D denote number variables left unassigned
inconclusive round started beneficial C `. round
exists, define u`,C,D = 0. Note number well-defined, follows easily
3. thank anonymous reviewer pointing original proof Proposition 2 work
Pipatsrisawat Darwiche (2009) contained error corrected version paper
webpage. proof affected error.

368

fiClause-Learning Algorithms

Lemma 1 every inconclusive round started beneficial C ` leaves
number variables unassigned. Further, define
uC,D =

X

u`,C,D .

`WC,D

Note C absorbed D, WC,D = . Moreover, hypothesis
Lemma 10, converse true. Analogously, C absorbed D, uC,D = 0
and, hypothesis Lemma 10, converse true.
Lemma 14. Let D0 sets clauses D0 . Let B two resolvable
clauses absorbed D, let C = Res(A, B). Then, WC,D0 WC,D u`,C,D0
u`,C,D ` WC,D .
Proof. WC,D0 = , nothing shown. Otherwise, xa WC,D0 , start
showing xa belongs WC,D . Let R0 inconclusive round started D0
beneficial C `. Application Lemma 2 R0 C \{xa } yields inconclusive round
R started following properties: R0 subsumes R, agree C \ {xa },
R branches C \ {xa }. show R beneficial C xa , remains

prove extending R x = yields conclusive round. Let R round defined
extension. Let C = Res(A, B, y). R falsifies B \ {y} \ {y}.
absorption, R cannot inconclusive, otherwise, would satisfied R .
proves WC,D0 WC,D .
Now, show u`,C,D0 u`,C,D every ` WC,D . ` belong WC,D0
nothing shown since u`,C,D0 = 0 case. Otherwise, let R0 R inconclusive
rounds beneficial C ` R0 started D0 R started D.
Lemma 1, R0 subsumes R, finishes proof.
Lemma 15. Let set clauses, let B two resolvable clauses
absorbed D, let C = Res(A, B). Let R conclusive round started let
D0 obtained adding asserting clause learned R. C empty
R beneficial C ` C, u`,C,D0 < u`,C,D uC,D0 < uC,D .
Proof. Lemma 14 already know uC,D0 uC,D u`,C,D0 u`,C,D . Therefore,
suffices demonstrate that, presence R, second inequality strict.
hypothesis, R beneficial C `. Let C 0 asserting clause learned R.
Let R unique inconclusive round contained R beneficial C `;
round contain last decision made R. Lemma 1, number
assignments made two rounds started beneficial C `
same. Hence, number variables left unassigned R equals u`,C,D , u`,C,D 1
since least one variable unset.
u`,C,D0 = 0 already u`,C,D0 < u`,C,D . Therefore, assume u`,C,D0 1.
particular, exists inconclusive round R0 started D0 beneficial C
`. Lemma 1 round R0 subsumes R . definition asserting clauses, C 0 |R
unit clause, since C 0 belongs D0 , absorbed D0 hence R0 satisfies C 0 .
proves R0 sets least one variable R therefore u`,C,D0 < u`,C,D .
369

fiAtserias, Fichte, & Thurley

two technical lemmas hand ready state prove analogue
Lemma 12 arbitrary asserting learning schemes.
Lemma 16. Let set clauses, let B two resolvable clauses
absorbed non-empty resolvent C = Res(A, B). Let n total
number variables let k width C. Then, 1, using arbitrary
asserting learning scheme, probability C absorbed current set clauses
k
kn restarts kn et/(4n ) .
Proof. Let b = uC,D , = bt, let D0 , . . . , Ds sequence sets clauses
produced algorithm, starting D0 = D. every {0, . . . , b}, let Xi = uC,Dit
let Ei event Xi b i.
bound probability C absorbed Dbt above. Since
event implies Xb 6= 0, suffices bound Pr[ E b ]. Note Pr[ E0 ] = 1 vacuously
hence Pr[ E 0 ] = 0. > 0, bound probability Ei hold. law
total probability gives






Pr E = Pr E | Ei1 Pr [Ei1 ] + Pr E | E i1 Pr E i1




Pr E | Ei1 + Pr E i1 .
Let pi = Pr[ E | Ei1 ] note Pr[ E | Xi1 < b + 1 ] = 0. Hence pi
Pr[ E | Xi1 = b + 1 ]. Consider sequence D(i1)t+1 , . . . , Dit sets clauses
corresponding complete rounds algorithm. Conditional Xi1 = b + 1,
event E implies Xi = Xi1 6= 0 hence none sets clauses absorbs
C. Furthermore, Lemma 15, none corresponding rounds beneficial C. Thus,
k
Lemma 11, pi et/(4n ) . Adding {1, . . . , r}, together



Pb
k
Pr E 0 = 0, gives Pr E b i=1 pi b et/(4n ) . Lemma follows necessarily
b kn.
able prove main theorem.
Theorem 17. Let F set clauses n variables resolution refutation width
k length m. probability least 1/2, algorithm started F , using arbitrary asserting learning scheme, learns empty clause 4km ln(4knm)nk+1
conflicts restarts.
Proof. proof analogous proof Theorem 13 Lemma 16 playing role
Lemma 12, choosing = d4 ln(4m kn)nk e now.

4. Consequences

total number clauses width k n variables bounded 2k nk ,
2nk every n k. Therefore, F n variables resolution refutation width
k, may assume length 4nk following estimate

k

k
k
X
X
n 1
n

1+2
n = 1 + 2n
4nk .
2

n1
i=0

i=1

obtain following consequence Theorem 17.
370

fiClause-Learning Algorithms

Corollary 18. Let F set clauses n variables resolution refutation
width k. probability least 1/2, algorithm started F , using arbitrary
asserting learning scheme, learns empty clause 16k(k + 1) ln(16kn)n2k+1
conflicts restarts.
application Corollary 18 that, even though explicitly defined
purpose, algorithm used decide satisfiability CNF formulas treewidth
k time O(k 2 log(kn)n2k+3 ). follows known fact every unsatisfiable formula treewidth k resolution refutation width k + 1
(Alekhnovich & Razborov, 2002; Dalmau, Kolaitis, & Vardi, 2002; Atserias & Dalmau,
2008).
interested producing satisfying assignment exists, proceed
self-reducibility: assign variables one time, running algorithm log2 (n) + 1 times
assignment detect current partial assignment cannot extended
further, case choose complementary value variable. use
fact F treewidth k, F |x=a treewidth k.
analysis, note since run algorithm correct probability least
1/2, new assignment correct probability least
1 2(log2 (n)+1) = 1

1
.
2n

means iterations correct probability least (1
running time algorithm O(k 2 (log(kn))2 n2k+4 ).

1 n
2n )



1
2.



Acknowledgments
thank Martin Grohe suggesting problem comparing power SAT-solvers
bounded-width resolution. thank Knot Pipatsrisawat Adnan Darwiche
pointing connection 1-empowering absorption. Thanks
Peter Jeavons comments conference version paper, anonymous
referees detailed comments.
first author supported part CYCIT TIN2007-68005-C04-03. second
author supported part European Research Council (ERC), Grant 239962.
third author supported part fellowship within Postdoc-Programme
German Academic Exchange Service (DAAD). preliminary version paper appeared
Proceedings 12th International Conference Theory Applications
Satisfiability Testing, SAT09 (Atserias et al., 2009).

References
Alekhnovich, M., & Razborov, A. A. (2002). Satisfiability, branch-width Tseitin tautologies. Proceedings 43rd Symposium Foundations Computer Science
(FOCS 2002), pp. 593603. IEEE Computer Society.
Alekhnovich, M., & Razborov, A. A. (2008). Resolution automatizable unless W[P]
tractable. SIAM J. Comput., 38 (4), 13471363.
371

fiAtserias, Fichte, & Thurley

Andrews, P. B. (1968). Resolution merging. J. ACM, 15 (3), 367381.
Atserias, A., & Dalmau, V. (2008). combinatorial characterization resolution width.
J. Comput. Syst. Sci., 74 (3), 323334.
Atserias, A., Fichte, J. K., & Thurley, M. (2009). Clause-learning algorithms many
restarts bounded-width resolution. Kullmann, O. (Ed.), Proceedings 12th
International Conference Theory Applications Satisfiability Testing (SAT),
Vol. 5584 Lecture Notes Computer Science, pp. 114127. Springer.
Bayardo, R. J., & Schrag, R. C. (1997). Using CSP look-back techniques solve real-world
SAT instances. Proceedings Fourtheenth National Conference Artificial
Intelligence (AAAI97), pp. 203208.
Beame, P., Kautz, H. A., & Sabharwal, A. (2003). Understanding power clause
learning. Gottlob, G., & Walsh, T. (Eds.), Proceedings Eighteenth International Joint Conference Artificial Intelligence (IJCAI-03), pp. 11941201. Morgan
Kaufmann.
Beame, P., Kautz, H. A., & Sabharwal, A. (2004). Towards understanding harnessing
potential clause learning. J. Artif. Intell. Res. (JAIR), 22, 319351.
Ben-Sasson, E., & Johannsen, J. (2010). Lower bounds width-restricted clause learning
small width formulas. Strichman, O., & Szeider, S. (Eds.), Proceedings 13th
International Conference Theory Applications Satisfiability Testing (SAT),
Vol. 6175 Lecture Notes Computer Science, pp. 1629. Springer.
Ben-Sasson, E., & Wigderson, A. (1999). Short proofs narrow - resolution made simple.
Proceedings Thirty-First Annual ACM Symposium Theory Computing
(STOC 1999), pp. 517526.
Dalmau, V., Kolaitis, P. G., & Vardi, M. Y. (2002). Constraint satisfaction, bounded
treewidth, finite-variable logics. CP 02: Proceedings 8th International
Conference Principles Practice Constraint Programming, pp. 310326, London, UK. Springer-Verlag.
Fox, D., & Gomes, C. P. (Eds.). (2008). Proceedings Twenty-Third AAAI Conference
Artificial Intelligence, AAAI 2008, Chicago, Illinois, USA, July 13-17, 2008. AAAI
Press.
Hertel, P., Bacchus, F., Pitassi, T., & Gelder, A. V. (2008). Clause learning effectively
p-simulate general propositional resolution.. Fox, & Gomes (Fox & Gomes, 2008),
pp. 283290.
Jeavons, P., & Petke, J. (2010). Local consistency sat-solvers. Proceedings
16th International Conference Principles Practice Constraint Programming
- CP 2010, Vol. 6308 Lecture Notes Computer Science, pp. 398413. Springer.
Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering efficient SAT solver. Proceedings 38th Design Automation Conference
(DAC01).
Nieuwenhuis, R., Oliveras, A., & Tinelli, C. (2006). Solving SAT SAT Modulo Theories: abstract DavisPutnamLogemannLoveland procedure DPLL(T).
Journal ACM, 53 (6), 937977.
372

fiClause-Learning Algorithms

Nordstrom, J. (2009). Narrow proofs may spacious: Separating space width
resolution. SIAM J. Comput., 39 (1), 59121.
Pipatsrisawat, K., & Darwiche, A. (2008). new clause learning scheme efficient unsatisfiability proofs.. Fox, & Gomes (Fox & Gomes, 2008), pp. 14811484.
Pipatsrisawat, K., & Darwiche, A. (2009). power clause-learning SAT solvers
restarts. Gent, I. P. (Ed.), Proceedings 15th International Conference
Principles Practice Constraint Programming - CP 2009, Vol. 5732 Lecture
Notes Computer Science, pp. 654668. Springer.
Silva, J. P. M., & Sakallah, K. A. (1996). Grasp - new search algorithm satisfiability.
Proceedings IEEE/ACM International Conference Computer-Aided Design,
pp. 220227.
Zhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Efficient conflict driven
learning boolean satisfiability solver. International Conference ComputerAided Design (ICCAD01), pp. 279285.

373


