Journal Artificial Intelligence Research 40 (2011) 677-700

Submitted 09/10; published 03/11

Identifying Aspects Web-Search Queries
Fei Wu
Jayant Madhavan
Alon Halevy

wufei@google.com
jayant@google.com
halevy@google.com

Google Inc, 1600 Amphitheatre Pkwy,
Mountain View, CA 94043 USA

Abstract
Many web-search queries serve beginning exploration unknown space
information, rather looking specic web page. answer queries eectively, search engine attempt organize space relevant information
way facilitates exploration.
describe Aspector system computes aspects given query.
aspect set search queries together represent distinct information need relevant
original search query. serve eective means explore space, Aspector
computes aspects orthogonal high combined coverage.
Aspector combines two sources information compute aspects. discover
candidate aspects analyzing query logs, cluster eliminate redundancies.
use mass-collaboration knowledge base (e.g., Wikipedia) compute candidate
aspects queries occur less frequently group together aspects likely
semantically related. present user study indicates aspects
compute rated favorably three competing alternatives related searches
proposed Google, cluster labels assigned Clusty search engine, navigational
searches proposed Bing.

1. Introduction
Web-search engines today predominantly answer queries simple ranked list results.
method successful, relies assumption users information need satised single page Web. However, several studies (Broder,
2002; Rose & Levinson, 2004) alluded fact many user queries merely
beginning exploration unknown space information. queries likely
better served users provided summary relevant information space
means conveniently exploring it. paraphrase, rather nding needle
haystack, queries would benet summarizing haystack (Rajaraman,
2008). Several commercial attempts recently made provide better answers
queries, including systmes Carrot2, Clusty, Kosmix, Yahoo!Glue.
paper describes Aspector system addresses following problem: given
exploratory search query q, compute set aspects enables convenient exploration
Web content relevant q. dene aspect set search
queries together represent distinct information need relevant original search
query, similar Wangs denition Latent Query Aspect (Wang, Chakrabarti, & Punera,
2009). example, consider queries Table 1 potential aspects.
aspect covers dierent kind information together span large amount
c
2011
AI Access Foundation. rights reserved.

fiWu, Madhavan, & Halevy

vietnam travel
travel guides
packages / agencies
visa
blogs / forums
travel advisories
weather
cities (Hanoi / Saigon /...)

kobe bryant
statistics
pictures / photos
videos / youtube
shoes
injury reports
girlfriend
trade rumors

Table 1: Potential aspects queries vietnam travel kobe bryant.

relevant information search engine users might interested in. Two simple ways
search engine utilize aspects oer related searches categorize search
results aspects relevant to. Aspects form basis various
mashup-like interfaces, e.g., aspect pictures trigger inclusion images,
weather trigger weather report gadget. Computing aspects queries seen
rst step towards mining knowledge base, called database user intentions (Battelle,
2005). knowledge base timely culture-sensitive expression peoples interests.
Inferring knowledge base entities serve basis eective presentation
information, therefore signicant ramications search, advertising
information dissemination.
Aspector computes aspects query q using search-engine query log, augmented
information knowledge base created mass-collaboration (Wikipedia). Given
query q, related queries extracted query log candidate aspects.
logs excellent mirror users interests, result noisy redundant
aspects, e.g., top related queries vietnam travel include vietnam visa vietnam travel
visa. Furthermore, query logs limited utility generating aspects less popular
queries, e.g., much fewer related queries laos travel vietnam travel.
describe following algorithmic innovations address challenges. First, show
redundant candidate aspects removed using search results. Second, apply
class-based label propagation bipartite graph compute high-quality aspects even
long tail less popular queries. Finally, show knowledge bases used
group candidate aspects categories represent single information need. believe
solution demonstrates interesting interplay query logs knowledge
bases yet investigated research literature.
describe detailed experimental evaluation Aspector. compare aspects
generated Aspector three possible competing approaches related searches
proposed Google.com, cluster labels proposed Clusty.com, navigational searches
proposed Bing.com. Related searches navigational searches typically generated analysis query logs. Cluster labels generated grouping search
results original query extracting labels documents within cluster.
show aspects diverse three systems. show
aspects span larger space information expose results
original query, additional results considered highly relevant users.
678

fiIdentifying Aspects Web-Search Queries

user study nds results Aspector preferred related searches, cluster
labels navigational searches means exploration.
Section 2 denes problem computing aspects, Section 3 considers potential alternative approaches. Section 4 describes generation candidate aspects, Section 5
describes Aspector selects aspects candidates. Section 6 describes experimental evaluation,and Section 7 describes related work. Section 8 concludes.

2. Problem Definition
begin dening scope problem address.
Queries: assume queries sequence keywords, typical searchengine interfaces. techniques meant apply arbitrary queries. focus
exploratory queries, specically, assume either entity names (e.g.,
country Vietnam) entity property name (e.g., Vietnam travel). Thus,
interested computing aspects entities general context particular
property.
paper handle problem segmenting entity property names
queries (previous work, Bergsma & Wang, 2007; Tan & Peng, 2008, addressed
problem). question identifying exploratory queries query stream
beyond scope paper.
Aspects: aspect query q meant describe particular sense q corresponding information need. Specically, aspect represented collection
search queries related q. Given q, compute set aspects a1 , . . . , , along
scores p(ai |q) used rank them.
Since aspects collections search queries, compare aspects based search
results retrieved queries constitute them. Aspects meant capture diverse
dimensions along organize exploration entire space information
relevant query. Hence, set aspects computed query
following properties:
Orthogonality: given two aspects, a1 a2 , search results a1 a2
dierent other.
Coverage: search results provided aspects oer good overview
relevant space information.
Thus, two sets aspects computed query compared based
pairwise orthogonality constituent aspects combined coverage
aspects. evaluation aspects inherently subjective, typical area web
search. Hence, present user studies aspects computed dierent approaches
qualitatively rated large number independent users. note
compare dierent approaches computing aspects, focus dierent ways
presented users.

3. Alternative Approaches
describe Aspector generates aspects, briey mention two strawman
approaches problem explain insucient needs.
679

fiWu, Madhavan, & Halevy

Class

NBA Player

University

Wikipedia
birth date
position
birth place
college
nationality height(ft)
draft year
draft
career start height(in)
name
city
established
website
country
type
campus
state
undergrad
motto

Query Log
injury
pictures
nba
wallpaper
bio
salary
shoes
girlfriend
stats
biography
library basketball
football
athletics
alumni admissions
tuition
baseball
jobs
bookstore

Table 2: Two classes attributes Wikipedia dierent classlevel aspects computed query log.

3.1 Community-Created Knowledge Bases
Knowledge bases, especially created large community contributors,
rich source information popular entities. cover wide spectrum user
interests potentially used organize information relevant search queries.
particular, properties Infoboxes Wikipedia articles potentially used
candidate aspects. Wikipedia contains 3,500 classes 1 million entities
class average 10 attributes. Wikipedia column Table 2 shows
attributes two example classes. Freebase another community-created KB
1,500 classes.
Binary relationships recorded knowledge base fall signicantly short providing
good set aspects query. example, consider properties associated
Cambodia Wikipedia Infobox capital, flag, population, GDP, etc. None
words appear top-10 frequent queries contain word cambodia. addition,
knowledge base limited describing well dened entities. example, Cambodia
entity knowledge base, Cambodia Travel not. However, queries Web cover
much well dened entities.
underlying reason knowledge bases fall short constructors choose
attributes based traditional design principles, good aspects follow
principles. example, turns cambodia travel good aspect vietnam travel,
many people consider side trip Cambodia visiting Vietnam. However,
designing knowledge base, Cambodia would never attribute Vietnam.
Instead, knowledge base would assert Vietnam Cambodia neighbors,
include rule states X next Y, X travel may aspect
travel. Unfortunately, coming rules specifying precise preconditions
formidable task highly dependent instances applies to. example,
pakistan travel aspect india travel, even though two countries neighbors.
680

fiIdentifying Aspects Web-Search Queries

3.2 Web Documents
Another approach nding aspects cluster documents Web relevant
query q, assign extract labels cluster (Blei, Ng, & Jordan, 2003; Zeng,
He, Chen, Ma, & Ma, 2004). show experiments, main disadvantage
coverage resulting aspects may low approach considers
documents returned response original query. practice, users conduct
data exploration sessions queries, queries sessions lead
interesting aspects might found among results original query.
Furthermore, challenging generate succinct names aspects
cluster.

4. Generating Candidate Aspects
Aspector generates candidate aspects query logs. Query logs reective
broad range user interests, less eective generating aspects infrequent
queries. rst describe generate instance-level aspects, augment
class-based aspect propagation using knowledge base.
4.1 Instance-Level Candidate Aspects
Given query q, start considering query renements super-strings
candidate aspect.
4.1.1 Query Refinements
query qj renement q, user poses qj q performing single search
task. Query logs mined identify popular renements individual queries. Search
engines typically use popular renements basis proposing related searches.
process renements follows: rst, query log segmented sessions representing sequences queries issued user single search task. Suppose fs (q, qj )
number sessions query qj occurs q, estimate renement
score pr qj normalizing fs (q, qj ) possible renements, i.e.,
fs (q, qj )
pr (qj |q) =
fs (q, qi )
Observe proposing related searches based query renements is, principle,
optimized towards goal helping users nd single page containing specic answer
(rather helping user explore space). example, top 10 renements
query NBA player yao ming includes 6 NBA players kobe bryant
michael jordan. Though related, renements necessarily best aspects
query.
4.1.2 Query Super-Strings
query qj super-string q includes q sub-string. example, vietnam
travel package super-string vietnam travel. Unlike renement, super-string qj need
681

fiWu, Madhavan, & Halevy

belong session q. fact, random selection 10 popular queries,
found average overlap 1.7 top 10 renements
top 10 super-strings. sense, super-strings explicitly related queries
renements implicitly related.
Super-strings assigned scores similar pr above, mimicking super-string
pseudo-renement, i.e., assume imaginary session q preceded superstring qj . Suppose f (qj ) number occurrences qj query logs, estimate
super-string score pss (qj |q) 1 :
pss (qj |q) =

f (qj )

f (q) + f (qi )

Aspector considers renements super-strings q candidate aspects
assigns single instance-level aspect score. candidate aspect qj , assign
score pinst follows:
pinst (qj |q) = max(pr (qj |q), pss (qj |q))
given q, normalize pinst (qj |q)s add 1.
4.2 Class-Based Aspect Propagation
Query-log analysis ineective generating instance-level candidate aspects less frequent queries. example, generate good candidate aspects vietnam travel,
laos travel. However, recommend aspects common travel
many countries Laos. use variation label-propagation algorithm named
Adsorption (Baluja, Seth, Sivakumar, Jing, Yagnik, Kumar, Ravichandran, & Aly, 2008).
rst apply query segmentation extract entity e (laos example)
property p (travel) query q. Next, use knowledge base (e.g., Wikipedia
Infobox) identify class, classes, C e (e.g., country south-east asian country
laos). construct directed bipartite graph G = (V, E, ) shown Figure 1.
nodes left instance-level query nodes laos travel, right
class-level nodes country travel. E denotes set edges, : E R
denotes nonnegative weight function. set weights edges instance nodes
class nodes 1, weights edges class nodes instance nodes K,
design parameter controlling relative-importance two factors. goal

compute p(qj |q), aspect distribution node q.
Following work Baluja et al. (2008), nodes aspect distribution iteratively
updated linear combination neighbors, converge (this algorithm
shown equivalent performing random walk graph). Since use Wikipedia
Infobox knowledge base, instance belongs single class, two iterations
guaranteed achieve convergence. rst iteration computes class-level aspects
follows:
1
pinst (qj |q)
pclass (qj |q) =
|C| qC
1. use conservative lower bound estimate. corresponding upper bound pss (qj |q) =
exceed 1.

682

f (qj )
f (q)



fiIdentifying Aspects Web-Search Queries

Instances

Classes

vietnam travel
southeast asia travel
laos travel
country travel
canada travel

...

...

Figure 1: bipartite graph class-based aspect propagation.
second iteration smoothes aspect distribution instance node q pclass (qj |q)
follows,
pinst (qj |q) + K pclass (qj |q)
(1)
1+K
Section 6 tested eect K performance Aspector. experiments found following variation computing class-level aspects leads
slightly better results:
p(qj |q) =

pclass (qj |q) =

1
I(pinst (qj |q) > 0))
|C| qC

where, I(pinst (qj |q) > 0)) = 1 pinst (qj |q) > 0, 0 otherwise.
Table 2 shows examples top class-level aspects derived two classes compares
corresponding top attributes Wikipedia infobox. see
two sets aspects little overlap, illustrates community created
schemata fall signicantly short providing good set aspects search queries.

5. Selecting Aspects
section describes Aspector prunes set candidate aspects, groups them,
eventually ranks ordered list subset selected.
5.1 Eliminating Duplicate Aspects
often case generated aspect list contains similar candidates may
considered redundant. example, top candidate aspects query vietnam travel
include vietnam travel package, vietnam travel packages vietnam travel deal,
represent either identical similar user intents. particular, note set
web documents returned aspects search engine likely
similar.
remove redundant aspects, compute similarity matrix, {sim(ai , aj )},
every pair candidate aspects cluster based similarity.
5.1.1 Computing Aspect Similarity
Since aspects contain words, estimating similarity based simple comparison words unlikely accurate. Therefore, enrich representation
683

fiWu, Madhavan, & Halevy

aspect considering top m2 search results returned posing aspect search
query. consistent goal enabling orthogonal exploration aspects
similar top results unlikely orthogonal.
Let Di top web pages retrieved aspect ai . estimate similarity ai
aj similarity corresponding sets Di Dj . compute sim(Di , Dj ),
rst compute similarity dsim given pair web pages {di Di , dj Dj }.
use standard cosine distance TF/IDF word-vectors two
documents. computational eciency, consider head snippet
web page instead entire text contents3 .
sim(Di , Dj ) potentially estimated averaging similarities dsim(di , dj )
pairs web pages, experiment dataset, found better instead compute
average highest similarity web page. di Di , assign score:
sim(di , Dj ) = maxk dsim(di , dk ). Likewise, assign sim(Di , dj ) = maxk dsim(dk , dj ).
nal aspect similarity computed as:




sim(ai , aj ) = sim(Di , Dj ) =

sim(di , Dj )

2|Di |

+

j

sim(dj , Di )
2|Dj |

could alternatively treat Di one single document concatenating {di
Di } estimate sim(qi , qj ) corresponding dsim(Di , Dj ). computationally
ecient, quality aspects poorer.
5.1.2 Clustering Aspects
principle, apply clustering algorithm, K-means spectral clustering,
resulting aspect similarity matrix. However, algorithms often require pre-setting
number desired clusters, dicult context. addition, number
clusters varies signicantly one query another. Note appropriate
number clusters necessarily number resulting aspects show
user.
instead apply graph-partition algorithm clustering. algorithm proceeds
creating graph nodes aspects, ai , edge connecting nodes
ai aj sim(ai , aj ) > , pre-dened threshold. connected sub
graphs treated cluster. choose label cluster aspect ak
highest p(ak |q) cluster (Formula 1).
design parameter easier set pretty stable dierent queries,
shown experiments. note similar algorithms star-clustering (Aslam,
Pelekov, & Rus, 2004) used.
5.2 Grouping Aspects Vertical Category
many cases, even eliminating redundant aspects, nd left
aspects seemingly dierent, semantically grouped single category.
example, query vietnam travel, top non-redundant candidate aspects
2. use = 8 experiments performs well. Larger might achieve slightly better performance cost heavier computation.
3. tired using whole document web page, slightly better performance.

684

fiIdentifying Aspects Web-Search Queries

ho chi minh city, hanoi da nang. dierent cities, principle
likely represent single information need nding information cities
Vietnam. Further, given budget xed number aspects presented
user, might make sense overwhelm list aspects denoting cities
Vietnam. Instead, single aspect named Cities presented.
community-created knowledge bases leveraged Aspector
tries identify sets related aspects consulting Wikipedia Infobox system4 .
nds multiple aspects contain dierent entities belong class Wikipedia,
creates aggregate aspect (with label class) groups together.
encounter two challenges looking Wikipedia classes entities.
First, entity appear dierent synonymous tokens. example, nyu
common acronym new york university. Currently use redirect pages Wikipedia
infer synonyms. Redirect pages Wikipedia point synonym terms principal
article. result, aspect nyu query yale university grouped harvard
university oxford university5 . Second, token refer multiple entities
belong dierent classes lead bad grouping decisions. example, HIStory
FOOD names music albums Wikipedia, history food
aspects query vietnam. simple lookup tokens Wikipedia might lead
erroneously grouping single album group. Aspector uses disambiguation
pages Wikipedia identify tokens likely multiple senses. Infobox
class retrieved entities disambiguation pages. conservative
method improved via collaborative classication (Meesookho, Narayanan, &
Raghavendra, 2002). example, earth, moon venus aspects mars. Since
ambiguous based Wikipedia, current Aspector would treat
individual aspects. However, possible group together single planet aspect,
given three candidates planet one possible type.
5.3 Selecting Aspects
nal step Aspector selecting aspects. note absolute ranking
aspects important context, expect search results
aspects spread screen rather presented single list. However,
still need select top-k aspects present. selection top-k aspects based
original goals increasing coverage guaranteeing orthogonality.
Aspector uses score aspect, p(ai |q), measure coverage. achieve
balance coverage orthogonality, Aspector uses greedy algorithm
selects aspects ratio score p(ai |q) similarity aspects already
selected aspects. algorithm produces ranked list aspects, G.

4. ontologies Freebase Yago used.
5. trick used constructing bipartite graph Section 4.2 well.

685

fiWu, Madhavan, & Halevy

Input: Set = {ai }
Output: Set G

// Label aspects clusters de-duplication.
// Ranked list aspects.

Initialization: G = ;
a0 = argmaxai p(ai |q);
move a0 G;
(S = )
ai
set sim(ai , G) = maxaj G sim(ai , aj );
p(ai |q)
;
anext = argmaxai Sim(a
,G)
move anext G;
Algorithm 1: Aspector selects top-k aspects balancing coverage orthogonality.
Observe set similarity sim(ai , G) maximum similarity ai
aspects already G. termination, Aspector returns top n aspects ranked order
(in experiments used n = 8). experiments indicate balancing coverage
orthoganality leads better selection aspects simply using coverage.

6. Experiments
section evaluate system Aspector particular, answer following
questions.
Quality aspects: compare results Aspector three potential
competing systems related searches proposed Google (henceforth Grs), cluster labels
assigned Clusty search engine (Ccl), navigational searches proposed Bing
(Bns). better support exploration dierent parts space relevant information,
aspects query orthogonal other. Aspects increase
coverage, i.e., reveal information already available original query,
still relevant it. Using combination search result analysis user
study, show aspects less similar (and hence orthogonal)
(Section 6.3), aspects able increase coverage (Section 6.4), aspects
overall rated favorably Grs, Ccl, Bns (Section 6.5).
Contributions dierent components: Aspector generates instance-level
aspects performs class-based aspect propagation, eliminates duplicates, groups
remaining ones using knowledge base. show instance-level class-level aspects
tend dierent, best results obtained judiciously combining
(Section 6.6). show clustering algorithm able stably eliminate
duplicate aspects crossing dierent domains, grouping aspects positive
impact quality aspects (Section 6.7).
6.1 Experimental Setting
compute candidate aspects query logs, used three months worth anonymized
search logs Google.com. used snapshot English version (2008.07.24)
Wikipedia Infobox serve knowledge base. Unless otherwise mentioned, used
686

fiIdentifying Aspects Web-Search Queries

K = 0.1 class-based aspect propagation (Equation 1). describe test suite
user study.
Test Queries: focus queries entity names entity name
property name. construct test suite contains 6 sets queries: entity
names Wikipedia classes Country, NBA player, Company, Mountain, University,
one entity-property queries form Country travel. construct mix
popular rare queries, six sets select 5 queries occur frequently
query stream, 5 relatively uncommon, 5 chosen randomly class
(as long appear query logs). Thus, total 90 test queries.
experiment used random subset test queries.
User Study: part experimental analysis, performed user studies using
Amazon Mechanical Turk (Amt) system. Amt, requesters (like us) post tasks pay
anonymous registered workers respond them. Tasks structured sequence
questions workers expected respond per instructions provided
requester. example, compare two algorithms compute aspects, design
sequence tasks query two lists aspects (computed
algorithm) shown. worker rate whether one list better
similar. Amt ensures worker respond task once.
Since, workers user study completely unknown requester, less
chance bias. Amt shown eective ecient way collect data
various research purposes (Snow, OConnor, Jurafsky, & Ng, 2008; Su, Pavlov, Chow, &
Baker, 2007). experiments, used default qualication requirement workers
requires worker HIT approval rate (%) greater equal 95.
6.2 Points Comparison
Grs considered representative current approaches based mining
renements super-strings query logs. likely Grs performs
instance-level analysis attempt identify distinct user information needs.
Ccl clusters result pages assigns human-understandable labels cluster.
notably, clusters determined purely results original query,
attempt enable exploration results retrieved query. Further,
likely cluster labels extracted analysis contents result pages
(web documents). note clustering hierarchical, experiments
considered top-level labels.
Bns provides navigation searches (right Related searches result pages)
help users better explore information space. Bings goal closest spirit,
technique applies narrow set domains. note Bns sometimes
provides generic aspects (e.g., videos, images), consider those.
note neither Grs Ccl designed explicit goal computing
aspects help explore information space relevant query. However,
viewed close alternatives terms results may produce, therefore oer
two points comparison.
Table 3 shows aspects, related searches, cluster labels, navigational searches
obtained four systems example queries. rest section,
687

fiWu, Madhavan, & Halevy

Query

Mount Shasta

Yale University

Grs
volcano
national park
climbing
vortex
camping
hotels
attractions
lodging
harvard university
athletics
press
brown university
stanford university
columbia university
cornell university
duke university

Ccl
photos
hotels
real estate
weed
wilderness, california
climbing
weather, forecast
ski
school
department
library
images
publications
admissions
laboratory
alumni

Bns
image
weather
real estate
hotels
lodging
rentals
reference/wikipedia
admissions
jobs
bookstore
alumni
library
reference/wikipedia
images

Aspector
resort
weather
high school
real estate
hiking
pictures (photos)
map
ski area
press
art gallery
athletics
harvard (oxford, stanford,...)
jobs
bookstore
admissions
tuition

Table 3: Sample output Grs, Ccl, Bns, Aspector.
rst show aspects Aspector average orthogonal, increase coverage,
rated better overall Grs, Ccl Bns.
6.3 Orthogonality Aspects
establish orthogonality aspects, measure inter-aspect similarity less
similar aspects are, orthogonal are. rst describe compute
inter-aspect similarity, report values query set Aspector, Grs,
Ccl, Bns.
Section 5, used TF/IDF-based word vectors estimate aspect similarity. Using
measure establish orthogonality bias evaluation favor Aspector.
Hence, use alternate measure aspect similarity employs topic model (Blei
et al., 2003). Briey, topic models built learning probability distribution
words documents topics might underlie document. Given text fragment,
topic model used predict probability distribution topics relevant
fragment. example, text company page Google Inc., might result
topic distribution search engine, 0.15, online business, 0.08, . . .. use topic
model developed internally Google (henceforth TMG). Given two text fragments t1
t2 , compute topic similarity tsim(t1 , t2 ) cosine distance
topic distribution vectors T1 T2 .
Since aspects contain words, extend augmenting aspect
corresponding top search results (as Section 5). Given aspects a1 a2 , let D1
D2 respective top web search results. compare D1 D2 using TMG
estimate aspect similarity. Specically, compute average inter-document similarity.
sim(a1 , a2 ) =

1
k2


di D1 ,dj D2

688

tsim(di , dj )

(2)

fiIdentifying Aspects Web-Search Queries

Normalized Inter-aspect Similarity

Aspect Similarity Comparison
0.06

0.04

0.02

0

Aspector

BNS

CCL

GRS

Figure 2: results Aspector orthogonal Grs, Ccl, Bns.

Given A, set n aspects, determine inter-aspect similarity (asim) average
pair-wise aspect similarity.
asim(A) =


2
sim(ai , aj )
n(n 1) ,a


j

order make sense magnitude asim, normalize using average intraaspect similarity isim(A) obtained comparing aspect itself.
isim(A) =

1
sim(ai , ai )
|A|


Note, sim(ai , ai ) ususally equal 1 based equation 2. result normalized
inter-aspect similarity nsim.
nsim(A) =

asim(A)
isim(A)

Thus, aspects identical, nsim(A) = 1, entirely orthogonal
nsim(A) = 0.
query, retrieved number aspects (at 8) system,
Figure 2 shows average normalized inter-aspect similarity results output
system.
clearly seen, Aspector least normalized inter-aspect similarity
hence orthogonal aspects. improvement Bns (45%) likely due
grouping related aspects vertical category. improvement Grs (90%)
likely due inclusion class-based aspects grouping related aspects
vertical category. improvement Ccl (60%) likely space labels
restricted results returned original query.
689

fiWu, Madhavan, & Halevy

Urls Aspector Covered Google.com
Top1_All

Top1_Popular

Top8_All

Top8_Popular

0.5


e
r
e
vo
c 0.4
Ls
R
U
r 0.3

ct
e
p


f 0.2

n

tic
0.1
ra
F

0

0

100

200

300

400

500

# top urls Google.com

Figure 3: Fraction top web pages retrieved aspects top 500 pages
retrieved original search query.

6.4 Increase Coverage
validate increase coverage interested answering two questions: (1)
aspects enable users reach information original query? (2)
additional information relevant user query?
6.4.1 Information
show aspects reach information, compare web pages retrieved
using aspects computed Aspector retrieved original search
query. Given, query q computed aspects A, let DN set top N web pages
retrieved Google query q. Let Dki collection top k web pages retrieved
Google aspect ai A, let Dka union Dki s. measure
fractional overlap DN Dka , i.e.,

|Dka DN |
|Dka | .

Figure 3 shows average fractional overlap Dka DN k = 1 k = 8
dierent values N (x-axis). results averaged two sets queries:
(1) 90 queries, (2) subset 30 popular queries, 10 aspects computed
query. results clearly indicate, even considering top 500 search
engine results, k = 1, 45% web pages D1a retrieved.
words, 55% web pages retrieved using aspects even top 500 (note
|D1a | 10). overlap even lower 33% considering k = 8. shows
aspects clearly able retrieve new information.
order isolate potential eects due rare queries search engines
typically propose related searches, separately consider subset popular queries.
Interestingly, nd overlaps even smaller hence aspects able
retrieve even information. likely potentially diverse
information Web popular entities.
690

fiIdentifying Aspects Web-Search Queries

Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative Resp.
Cov. Covered

N

N
274 26
274 26
238 8
258 8
269 53
223 43
280 48
228 40
309 31
235 25
242 38
282 38
1612 204
1500 180



28
25
33
31
34
26
177

Url Ratings
Cov. Covered
N

N
2
28 2
0
27 0
0
27 0
2
26 1
0
26 0
2
30 2
6
164 5

Table 4: User responses indicating whether pages retrieved aspects relevant
query.

6.4.2 Relevant Information
establish information retrieved aspects fact relevant users
information needs, conducted Amt user study. query q, considered
top 10 aspects aspect consider top retrieved web page, i.e., D1a .
constructed list aspect-based results LA contained 4 results (selected random
D1a ), 2 overlapped D500 2 overlap D500 . Users
asked evaluate results (a) relevant, (b) irrelevant original
query q. order place results context, showed LA alongside LG , top
5 regular search engine results (these rated, context).
considered 90 test queries responses 10 users case. detailed
results shown Table 4. columns N indicate whether web pages
deemed relevant not. Covered Covered columns separately consider
web pages LA covered D500 not. Cumulative
Responses columns aggregate responses users, Url Ratings columns
aggregate ratings users separately web page LA . seen,
total 177 web pages covered, deemed relevant
majority users.
results indicate overall, vast majority additional web pages retrieved
aspects deemed relevant majority users. addition, ratio relevant
not-relevant results covered not-covered web pages.
indicates additional information relevant, likely relevant
covered information.
Note coverage results establish aspects likely span much
information space alternate schemes rely analyzing results
original query, e.g., cluster labels Clusty.
6.5 Comprehensive Performance Comparison
compare overall performance Aspector Grs, Ccl, Bns conducting
user study using Amt. separately compared Aspector
systems. case, selected random subset around 30 queries original
691

fiWu, Madhavan, & Halevy

set 90 queries. ltered queries dont return aspects systems.
query, two lists (at most) 8 aspects generated, one using Aspector
using Grs, Ccl Bns, presented Amt rater
following instructions:
query represents start session explore information topic
(presumably related query). user query, display two lists related
queries and/or properties. want compare two lists query identify
two lists enables better subsequent exploration information.
lists query presented side-by-side, user could rate one better
other, simply rate same. raters informed
source list side-by-side positioning lists randomly selected.
collected responses 15 raters query.
Tables 5, 6 7 summarize results user study. Cumulative Responses
columns aggregate responses raters queries. F, E, columns
indicate ratings favor Aspector, even ratings, Aspector (and favor
Grs Ccl) respectively. Query Ratings columns aggregate ratings
raters query, F indicating raters rated Aspector favor
systems (respectively E A).
seen Table 5, Aspector clearly outperforms Grs. improvements
likely due increased orthogonality grouping aspects vertical
category. clear Table 6, Aspector signicantly outperforms Ccl,
likely due increased coverage.
ascertain statistical signicance evaluation, comparison, performed standard paired t-test. individual query, considered total number
F responses responses. comparison Grs, mean perquery dierence (F-A) 10.7, i.e., average 10.7 total 15 evaluators rated
Aspector better. dierence statistically signicant two-tailed pvalue less 0.0001. comparison Ccl, mean dierence 13.1
signicant p-value less 0.0001.
Bns produces aspects small number domains. set context comparison measured breadth Bns. chose top 100 Wikipedia Infobox classes,
selected 15 entities (5 popular, 5 less common, 5 randomly) class
section 5.3. Bns provided aspects 17.6% entities. particular, Bns provided
aspects 29.4% popular entities 9.8% less common entities. Bns
provided aspects entities 48 classes, including scientist, magazine
airport. second limitation Bns provides aspects entity queries.
Hence, Bns provide aspects queries vietnam travel, seattle coee
boston rentals. third limitation Bns provides class-level aspects, though aspects may dier slightly one instance another. example,
Bns misses aspect starbucks seattle, turkey slap turkey, number
change kobe bryant.
90 queries, 41 obtain aspects Bns. Table 7 shows
Aspector Bns rated comparably w.r.t. limited set queries. advantages
Aspector come fact judiciously balances instance-level class-level
aspects. interesting point raters familiar particular
692

fiIdentifying Aspects Web-Search Queries

Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative
F
E
60
7
54
17
68
5
51
14
59
11
58
15
350 69

Resp.

8
3
2
10
5
1
29

Query Ratings
F
E

4
0
1
5
0
0
5
0
0
4
0
1
5
0
0
5
0
0
28 0
2

Table 5: User responses comparing Aspector Grs.
Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative
F
E
57
8
62
5
69
3
56
1
62
3
53
7
359 27

Resp.

9
0
2
12
8
7
38

Query Ratings
F
E

4
1
0
5
0
0
5
0
0
5
0
0
5
0
0
5
0
0
29 1
0

Table 6: User responses comparing Aspector Ccl.
instance, tend prefer class-level aspects. experiment, observation
sometimes gives Bns advantage.
6.6 Instance-Level Versus Class-Level Aspects
Recall Aspector balances class-level instance-level aspects given
query. Consider, example, class NBA players. 1365 players identied
Wikipedia. able identify 8 candidate instance-level aspects
126 (9.2%). 953 (69.8%) players, unable infer instance-level
aspects. However 54 class-level aspects appear least 5 instances,
Domain
country
nba player
company
university
mountain
Total

Cumulative
F
E
65
29
52
12
20
2
92
9
6
6
235 58

Resp.

56
71
53
19
18
217

Query Ratings
F
E

5
1
4
3
0
6
0
0
5
8
0
0
1
0
1
17 1
16

Table 7: User responses comparing Aspector Bns. Note result
ltering 54% testing queries Bns provides aspects, case users
always rate Aspector better.

693

fiWu, Madhavan, & Halevy

Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative
F
E
12
17
12
11
10
14
12
13
17
9
10
14
73
78

Resp.

46
52
51
50
49
51
299

Query Ratings
F
E

0
0
5
0
0
5
0
0
5
0
0
5
1
0
4
0
0
5
1
0
29

Table 8: User responses comparing Aspector K = 0 K = 1.

thus giving us potentially larger pool good candidate aspects. balancing two
sources aspects, Aspector able successfully compute reasonable aspects even
less frequent queries.
compared extent class-based aspect propagation contributes
quality aspects generated. this, performed Amt user study. considered dierent values parameter K Formula 1: 0, 0.1, 1, 10, 100,
indicating progressively higher contribution class-level aspects. Aspect lists generated subset 30 queries (5 set) value K. compared two
aspect lists time, performed three sets experiments comparing (1) K = 0
K = 1 (Table 8), (2) K = 0.1 K = 10 (Table 9), K = 1 K = 100 (Table 10).
experiment used set 30 queries users asked pick
two sets aspects preferred query (same task description Section 5).
Responses collected 15 users case. Note ensure signicant dierences aspect lists compared, experiments consider consecutive K
values (e.g., 0 0.1). earlier experiment consecutive K values used,
found many queries subtle dierence hence large numbers users rated
lists comparable. number queries fewer Table 9 Table 10, since
remaining ones resulted aspect lists K values surprising
since, larger K values result increased inuence set class-based aspects.
nd aspect lists K = 1 rated signicantly better K = 0
(the mean per-query dierence (F-A) 7.53 signicant two-sided p-value less
1E-9). lists K = 10 preferred K = 0.1 (though
smaller (F-A) 2.4 p value 0.008), lists K = 100 K = 1
rated (the mean (F-A) 0.3 insignicant p value 0.8).
seem indicate clearly class-based aspects helpful improving user
experience.
However, note results might marginally over-state importance classbased aspects. users perception aspects dependent upon users
interest familiarity entity question entity, though popular,
familiar participant study, likely select class-based aspects.
hand, found universally well known entities, company
microsoft, lists instance-based aspects always preferred.
694

fiIdentifying Aspects Web-Search Queries

Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative
F
E
11
15
21
23
19
21
17
24
22
26
13
11
103
120

Resp.

34
16
35
34
27
21
167

Query Ratings
F
E

0
0
4
2
1
1
1
0
4
1
0
4
2
0
3
1
0
2
7
1
18

Table 9: User responses comparing Aspector K = 0.1 K = 10.
Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative
F
E
3
8
16
18
5
12
33
29
14
20
21
23
92
110

Resp.

4
11
28
13
11
31
98

Query Ratings
F
E

0
0
1
2
0
1
0
0
3
4
0
1
1
1
1
2
0
3
9
1
10

Table 10: User responses comparing Aspector K = 1 K = 100.
6.7 Eliminating Grouping Aspects
consider impact content-based clustering used identify duplicate
aspects, vertical-category-based clustering groups aspects belonging
category.
6.7.1 Duplicate Elimination
computing candidate aspects query logs, possible nd multiple aspects
dierent names, semantically same. aspects eliminated order summary cover distinct axes. explained Section 5.1,
Aspector applies graph partitioning algorithm single parameter,
similarity threshold . conjecture similarity threshold intuitive set
stable across dierent domains.
test hypothesis, randomly selected 5 queries 5 domains.
query, took top 30 aspects candidates manually created gold-standard
correct aspect clustering results. computed aspect lists queries dierent
values threshold compared results gold-standard.
use F-Measure (F ) evaluate clustering results. particular, view
clustering series decisions, one N (N 1)/2 pairs aspects.
Figure 4 plots F values dierent values threshold test
domains. found case best performance threshold values 0.25
0.4. results indicate clustering performance respect pretty stable
across domains. Hence, experiments, set single value = 0.35.
695

fiWu, Madhavan, & Halevy

Mountain

NBA_Player

Country

University

Company

0.9
0.8

F-Measure

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Similarity threshold

Figure 4: F-Measure aspect clustering dierent values similarity threshold .
domain, best performance around 0.35.

Domain
company
university
mountain
Total

Cumulative
F
E
25
14
18
7
6
3
49
24

Resp.

6
5
6
17

Query Ratings
F
E

3
0
0
2
0
0
0
1
0
5
1
0

Table 11: User responses comparing Aspector vertical-category grouping without. F, E, responses favor, even, grouping.

6.7.2 Vertical-Category Based Grouping
addition duplicates, observed often multiple aspects might belong
vertical category. Rather represent separate aspect, summarize
aspects presenting single group. Note grouping eliminate
aspects, simply lists single aspect. 6 90 queries
dataset, Aspector able group aspects vertical category.
before, deployed Amt user study 6 test queries results
shown Table 11, F indicating number responses favor vertical grouping
(with E dened accordingly). seen, aspect lists grouping
favored comparison ones without grouping.
Currently, Aspector groups aspects vertical category
corresponding disambiguation pages Wikipedia. conservative solution avoids potential errors ambiguity exists, misses opportunities. example,
query mount bachelor, mount hood mount baker appear separate aspects since
disambiguation pages entities. Rening grouping condition rich topic
future work.
696

fiIdentifying Aspects Web-Search Queries

7. Related Work
discuss work related area search-result organization query-log
mining.
7.1 Search Result Organization
Several works considered better organize search results. Agrawal, Gollapudi,
Halverson, Ieong (2009) classify queries documents categories return search
results considering document relevance diversity results. contrast, Aspector computes ne grained aspects instead abstract categories exploratory
queries necessary ambiguous. commercial systems Kosmix Yahoo!Glue categorize information based type format (e.g. photo, video,
news map) retrieve top results category. Though dierent types often
approximate aspects, represent rich set semantically dierent groups
information sensitive instance-specic aspects. Carrot2 search engine
applies text clustering techniques returned search pages extracts keywords summarize cluster. Similar works done Bekkerman, Zilberstein, Allan (2007),
Blei et al. (2003), Crabtree, Andreae, Gao (2006), Wang, Blei, Heckerman
(2008). Multi-faceted search (Yee, Swearingen, Li, & Hearst, 2003) organizes collections
based set category hierarchies corresponds dierent facet. However category hierarchies requires heavy human eort construction maintenance.
Correlator system Yahoo! performs semantic tagging documents enable
mining related entities query. algorithms dont necessary discover clusters
correspond Web users search interests, dicult generate informative
cluster labels documents. use query logs complements document-based
approaches, reects searchers intentions rather intentions publishers.
Wang Zhai (2007) proposed organize search results based query logs.
represent query pseudo-document enriched clickthrough information
pick top-k similar current query, cluster aspects. Then,
classify resulting page corresponding aspect similarity. contrast,
generate aspects based idea query renements dont require aspect
current query similar clickthrough. example, query vietnam travel visa
important aspect vietnam travel, wont click-through properties.
7.2 Query-Log Mining
several eorts mine query logs interesting artifacts. Pasca Durme
(2007) extract relevant attributes classes entities query logs rather
Web documents done Bellare et al. (2006). main goal works create
knowledge base entities, hence results appropriately compared
Wikipedia Freebase.
Query renement suggestion analyze query logs predict next probable
query following current query (Cucerzan & White, 2007; Jones, Rey, Madani, & Greiner,
2006; Kraft & Zien, 2004; Velez, Wiess, Sheldon, & Giord, 1997). Hence, goal
help users nd single result page rather help navigating body relevant
697

fiWu, Madhavan, & Halevy

information. Bonchi, Castillo, Donato, Gionis (2008) proposed decompose query
small set queries whose union corresponds approximately original
query. However, experiments illustrated, constraint union resulting
pages correspond approximately original query signicantly limits available
body information expose user.
Wang et al. (2009) mine set global latent query aspects, dynamically select
top k aspects given query q help better navigate information space.
ways similar Aspector, two key dierences. First, discover
set global latent query aspect via maximizing target function, aspect
set aims apply many classes (important) queries. contrast, Aspector applies
class-based label propagation identify aspects. Therefore, aspects tend
ne-grained query(class)-specic. Second, selecting k aspects
query q, Wang et al. apply another optimization function tries cover many
original (frequent) query renements q. works ne popular queries
less popular queries query renements. experiments show
classes, long tail less popular queries.

8. Conclusions
described Aspector system computing aspects web-search queries. Aspects
intended oer axes along space information relevant query
organized, therefore enable search engines assist user exploring space.
Aspector generates candidate aspects query logs balances aspects
common classes entities vs. specic particular instances. Aspector
eliminates duplicate aspects groups related aspects using reference ontology.
contrast purely knowledge-based approach, Aspectors results much broader
include aspects interest specic instances. contrast approach based
solely clustering results query, Aspector include aspects
represented directly querys answer.
set weights edges instances classes uniformly computing
class-based aspects. future direction compute better informed weighting functions
based available temporal, spatial contextual constraints. Another future work
allow multi-class memberships based ontologies besides Wikipedia Infobox.
incorporate aspects mainstream search engine need address two challenges. First, need reliably identify query stream queries benet
summarization approach. works (Miwa & Kando, 2007; White & Roth, 2009)
conducted area, much needs investigated. Second, done
Kosmix, need dynamically generate eective visualizations aspects.

References
Agrawal, R., Gollapudi, S., Halverson, A., & Ieong, S. (2009). Diversifying Search Results.
WSDM.
Aslam, J. A., Pelekov, E., & Rus, D. (2004). star clustering algorithm static
dynamic information organization. Journal Graph Algorithms Applicatins.
698

fiIdentifying Aspects Web-Search Queries

Baluja, S., Seth, R., Sivakumar, D., Jing, Y., Yagnik, J., Kumar, S., Ravichandran, D., &
Aly, M. (2008). Video suggestion discovery youtube: Taking random walks
view graph. WWW.
Battelle, J. (2005). Search: Google Rivals Rewrote Rules Business
Transformed Culture. Portfolio Hardcover.
Bekkerman, R., Zilberstein, S., & Allan, J. (2007). Web Page Clustering using Heuristic
Search Web Graph. IJCAI.
Bellare, K., Talukdar, P. P., Kumaran, G., Pereira, F., Liberman, M., McCallum, A., &
Dredze, M. (2006). Lightly-Supervised Attribute Extraction. NIPS.
Bergsma, S., & Wang, Q. I. (2007). Learning Noun Phrase Query Segmentation. EMNLPCoNLL.
Blei, D., Ng, A., & Jordan, M. (2003). Latent Dirichlet allocation. Journal Machine
Learning Research.
Bonchi, F., Castillo, C., Donato, D., & Gionis, A. (2008). Topical query decomposition.
KDD.
Broder, A. (2002). taxonomy web search. SIGIR Forum, 36 (2).
Crabtree, D., Andreae, P., & Gao, X. (2006). Query Directed Web Page Clustering. WI.
Cucerzan, S., & White, R. W. (2007). Query Suggestion based User Landing Pages.
SIGIR.
Jones, R., Rey, B., Madani, O., & Greiner, W. (2006). Generating query substitutions.
WWW.
Kraft, R., & Zien, J. (2004). Mining anchor text query renement. WWW.
Meesookho, C., Narayanan, S., & Raghavendra, C. S. (2002). Collaborative classication
applications sensor networks. SAMSP-Workshop.
Miwa, M., & Kando, N. (2007). Methodology capturing exploratory search processes.
CHI-Workshop.
Pasca, M., & Durme, B. V. (2007). Seek Get: Extraction Class
Attributes Query Logs. IJCAI.
Rajaraman, A. (2008).
Searching needle exploring haystack?.
http://anand.typepad.com/datawocky/2008/06/.



Rose, D. E., & Levinson, D. (2004). Understanding User Goals Web Search. WWW.
Snow, R., OConnor, B., Jurafsky, D., & Ng, A. Y. (2008). Cheap fast - good?
evaluating non-expert annotations natural language tasks. EMNLP.
Su, Q., Pavlov, D., Chow, J.-H., & Baker, W. C. (2007). Internet-scale collection humanreviewed data. WWW.
Tan, B., & Peng, F. (2008). Unsupervised query segmentation using generative language
models wikipedia. WWW.
Velez, B., Wiess, R., Sheldon, M., & Giord, D. (1997). Fast eective query renement.
SIGIR.
699

fiWu, Madhavan, & Halevy

Wang, C., Blei, D., & Heckerman, D. (2008). Continuous time dynamic topic models.
UAI.
Wang, X., Chakrabarti, D., & Punera, K. (2009). Mining Broad Latent Query Aspects
Search Sessions. KDD.
Wang, X., & Zhai, C. (2007). Learn Web Search Logs Organize Search Results.
SIGIR.
White, R. W., & Roth, R. A. (2009). Exploratory Search: Beyond Query-Response
Paradigm. Morgan Claypool Publishers.
Yee, K.-P., Swearingen, K., Li, K., & Hearst, M. (2003). Faceted metadata image search
browsing. CHI.
Zeng, H.-J., He, Q.-C., Chen, Z., Ma, W.-Y., & Ma, J. (2004). Learning cluster web
search results. SIGIR.

700


