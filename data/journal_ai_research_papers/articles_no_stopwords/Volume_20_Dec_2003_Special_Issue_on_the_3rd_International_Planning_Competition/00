Journal Artificial Intelligence Research 20 (2003) 1-59

Submitted 3/03; published 12/03

3rd International Planning Competition: Results
Analysis
Derek Long
Maria Fox

derek.long@cis.strath.ac.uk
maria.fox@cis.strath.ac.uk

Department Computer Information Sciences
University Strathclyde, Glasgow, UK

Abstract
paper reports outcome third series biennial international planning competitions, held association International Conference AI Planning
Scheduling (AIPS) 2002. addition describing domains, planners
objectives competition, paper includes analysis results. results
analysed several perspectives, order address questions comparative
performance planners, comparative difficulty domains, degree agreement
planners relative difficulty individual problem instances question well planners scale relative one another increasingly difficult problems.
paper addresses questions statistical analysis raw results
competition, order determine results considered adequately supported data. paper concludes discussion challenges future
competition series.

1. Introduction
Beginning 1998 international planning community held biennial event support direct comparison planning systems changing collection benchmark
planning problems. benefits series events significant: five
years, planning systems developed capable solving large complex
problems, using richly expressive domain models meeting advanced demands
structure quality solutions. competition series inspired many advances
planning research community well increasingly empirical methodology
growing interest application planners real problems.
paper describe structure, objectives outcomes third competition,
took place Toulouse 2002. competition colocated AI Planning
Scheduling (AIPS) conference. conference brief report presented
results achieved participating planners. begin presenting overview
main results presented conference, showing number problems attempted
solved planner identifying competition prize-winners. previous
years competition resulted collection large data set comprising data points
several different domains. certain comparative understanding obtained
examining data individual domains, conclusions drawn basis cannot
generalised across domains. One goals paper try reveal
insights cross boundaries domains allow general questions
answered. include: planners reveal consistent, stable performance
c
2003
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiLong & Fox

across domains? benefit obtained exploiting hand-coded control knowledge?
general agreement makes planning problem hard? particular
planning approaches best suited particular kinds problem domains?
accepted scientific methodology addressing questions frame precise
hypotheses prior collection data sets order control extraneous
variables might distort reality respect questions. date
practice planning community respect competitions.
third competition proceeded, previous years, collecting data prior detailed
consideration specific questions wished answer. community yet
agreed primary role competition provide carefully crafted platform
scientific investigation planners: indeed, main roles far motivate
researchers field, identify new research goals thereby push forward research
horizons, publicise progress wider community. However, competitions
winners natural tendancy draw conclusions competition data
sets state art. conclusions scientifically supported
misleading even erroneous. Therefore argument trying combine
two objectives, although admittedly tension might make
difficult combine successfully.
way planning competitions currently conducted,
analyses describe paper post hoc. conducted analyses
data collected competition period: run experiments
competition participants felt important data
submitted competition comprise evidence judged.
identified number analyses think provide interesting information
planning community and, following sections, explore theme
rigorous way possible within constraints data disposal.
difficult work fixed data set collected without precise experimental
questions mind, unable test many hypotheses occurred us
analyses data inappropriate incomplete. However, despite
limitations data set believe able pose answer
important questions comparative performances revealed competition.
phrase objectives analyses terms null alternative hyptheses
standard approach applying statistical tests. approach partly
inspired earlier work Howe Dahlman (2002). work raised standard
evaluation planners done compels planning community
decide whether future planning competitions conducted way supports
goals scientific investigation progress field.
rest paper organised follows. begin discussing context
competition series general form third competition, including
domains, competitors specific challenges raised. briefly summarise
results competition embarking detailed post hoc analysis competition results. analysis investigates relative performances planners, relative
difficulties problem sets used relative scaling behaviours competitors
across domains levels. provide appendix present summaries
competing planners details domains used.
2

fiThe 3rd International Planning Competition

2. International Planning Competition Series
first event held conjunction fourth international Artificial Intelligence
Planning Scheduling conference (AIPS98). organised Drew McDermott,
together committee senior members research community (McDermott,
2000). event took time organise, evolving agreement form
event, kinds planning systems compared, basis comparison
on. final event became direct comparison 5 strips-based planners, two
planners attempting extended adl-based language (McDermott, 2000; Long,
2000). systems included three Graphplan-based systems, one forward heuristic search
system one planning-as-satisfiability satsolver planner. important outcome
first competition adoption pddl (McDermott & AIPS98 Planning
Competition Committee, 1998) common representation language planning.
Although opportunity offered competitors hand-code control knowledge
planners, fact planners fully-automated ran problem
instances without priming. entire event staged conference period
four days, involving intensive sessions generating checking solutions
attempting evaluate results. One idea tried, turned
problematic practice, score planners performances using function
attempted take account time taken generate plan, length plan
relative performance competitors problems. example,
planner produced plan faster competitors would rewarded based
much faster average problem. attempt score planners
using one-dimensional measure proved difficult, counter-intuitive results certain
cases. end abandoned favour two dimensions: length plan time
taken produce it. decision indicates that, even five systems relatively
small set problems, impossible make unequivocal decisions system
best. Nevertheless, community (and did) learn much data gathered,
offering variety interpretations data, ultimately inspired improve
every way possible.
second competition, chaired Fahiem Bacchus, 17 planners competed.
increase participation ambitions larger scale testing required event
spread much longer period. fact, testing spread couple months,
one final test carried conference site (AIPS00 Breckenridge).
second competition formal split systems, small number
using hand-coded control knowledge others fully-automated.
split strips adl capable systems. larger number competitors included
wider range approaches: well Graphplan-based systems, forward heuristic search
satsolver, several planners based model-checking approaches using
bdds, one using planning-by-rewriting. Again, proved difficult compare planners
unequivocally, several important observations could made: advantages handcoded control rules domains could seen clearly (as would expected), although
remained important question difficulty generating writing
rules. fully-automated planners, forward heuristic search approach proved
particularly successful, dominating performance domains. Pure Graphplan-based
3

fiLong & Fox

planning seemed reached zenith first two competitions longer
appeared competitive.
third competition (and recent time writing) held association
AIPS02 Toulouse. Fourteen planners participated. primary objective
competition help push forward research temporal resource-intensive
planning. Extensions made pddl support modelling temporal numeric
domain features. resulted pddl2.1 language (Fox & Long, 2003). extensive
changes pddl2.1 ambitious objectives competition help account
fact fewer people participated 2002 2000. again, real testing
gathering data took place two months prior conference. Although initial
results presented conference, detailed analysis took place conference
itself. rest paper examines objectives third competition, results
future challenges series.

3. Overview: Third International Planning Competition
organisers Third International Planning Competition chose address several
new challenges believe important ambitions planning community: management problems metric constraints numerically valued variables,
temporal planning (including managing concurrency scheduling activities)
construction plans subject specified optimisation criteria simple count
numbers steps.
Setting goals obvious implications potential competitors terms
extended expressive power additional problem-solving required manage extensions. order control extent competitors would required handle
extensions successfully, constructed variants, levels, domains
used competition. domains included strips level, numeric
level (using strips metric variables only), simpletime level actions
duration metric values domain full temporal level, time,
using durative actions durations determined context usage (so duration
depends parameter values action name). simpletime
time levels involve numeric resources time. address combination
introduced additional domain variants, discuss below. four levels
corresponds particular degree expressive power pddl2.1, different
challenges posed versions domain level.
secondary goal assess relative effort generating encoding control
rules planners. Unfortunately, failed find way usefully quantify effort.
discuss question following sections.
3.1 Problem Domains
problem domains selected competitions been, become, benchmark
domains used much community empirical evaluation. domains
used often chosen probe specific detail performance.
sometimes meant domains representative general features planning
4

fiThe 3rd International Planning Competition

inappropriate use widespread testing. description domains
used competitions far found Appendix A.
third competition, eight families domains used, broadly divided
transportation domains (Depots, DriverLog ZenoTravel), applications-inspired domains
(Rovers Satellite) small collection others (Settlers, FreeCell UM-Translog2).
briefly summarise collection describe detail Appendix A.
Depots domain combines transportation style problem Logistics
well-known Blocks domain. Logistics domain exhibits high degree parallelism,
since separate vehicles utilised concurrently. contrast, Blocks domain
characterised significant goal interaction. intention
discover whether successes planners domains separately could
brought together problems combined.
DriverLog problem involves transportation, twist vehicles
must supplied driver move.
Zeno-travel Another transportation problem, inspired domain used testing
zeno planner developed Pemberthy Weld (1994), people must
embark onto planes, fly locations debark, planes consuming
fuel different rates according speed travel.
Satellite domain inspired problem scheduling satellite observations. problems involve satellites collecting storing data using different
instruments observe selection targets.
Rovers domain motivated 2003 Mars Exploration Rover (MER)
missions planned 2009 Mars Science Laboratory (MSL) mission. objective
use collection mobile rovers traverse waypoints planet,
carrying variety data-collection missions transmitting data back
lander. problem includes constraints visibility lander various
locations ability individual rovers traverse particular pairs
waypoints.
Settlers domain revolves around management resources, measured using
metric valued variables. Products must manufactured raw materials used
manufacture transportation materials. New raw materials
generated mining gathering. objective construct variety structures
various specified locations.
UM-Translog-2 domain pddl2.1 encoding new variant UMTranslog (Wu & Nau, 2002) domain. generated us Dan Wu
University Maryland. essentially transportation domain, one
significantly complex previous transportation benchmarks. fact,
domain introduced late competition little data collected.
therefore discussed paper.
5

fiLong & Fox

reused Freecell domain second competition. domain presented
serious challenge participants 2000 interested see whether planning
technology surpassed challenge intervening two years. Although domain
produced interesting data attempt precisely measure extent
2002 performance surpassed 2000.
domain (other Settlers, Freecell UM-Translog-2) presented
competitors least four different levels previously identified: strips, numeric
simpletime time. problems presented levels comprised distinct
tracks competitors able choose tracks wished compete.
addition four main tracks included two additional tracks, intended
explore particular ideas. tracks necessitate use additional expressive
power simply allowed existing expressiveness combined produce interesting
planning challenges. example, hardnumeric track consisted problems
Satellite domain logical goals. Plans evaluated metric based
amount data recorded rather determining whether specified logical goal
achieved. challenge planners respond plan metric include
actions would acquire data. complex track consisted problems combined
temporal numeric features. challenge reason resource consumption
parallel managing temporal constraints. total, defveloped 26 domains, 20
problem instances domain (a few, unintentially, ended 16 22 instances).
domains additional 20 instances large problems intended
hand-coded planners. total nearly 1000 problem instances solved,
half intended primarily fully-automated planners.
3.2 Competitors
population competing planning systems changed three competitions.
systems competed system appeared three competitions. part, reflection speed development planning systems, revealing
extent technology 1998 surpassed 2002.
reflection growing interest series, encouraged competitors
come forward, work involved taking part discouraged previous
competitors repeating effort. Entering competition involves generating interesting efficient approaches solving planning problem: demands
ability construct system respond robustly reliably confronted
previously unseen challenges, including domains amongst used
development system. must sufficiently well-engineered performance
dominated poor programming rather real algorithmic effort solving
problem (careless choice data structure undermine opportunity show
clever new planning algorithm). systems use hand-coded rules guide
planning system additional demand: time required read understand
domains sufficiently construct sensible control knowledge encode test
knowledge achieve good performance. time-table testing relatively
compressed (the entire problem suite generated delivered competitors
two month period testing carried remotely single machine), using
6

fiThe 3rd International Planning Competition

hand-coded controls forced find time analyse domains, hypothesise test
rules intense sessions.
Details competing systems found Appendix B. summarise, many
fully-automated planners use relaxed plan heuristics guide heuristic search.
lpg (Gerevini, Saetti, & Serina, 2003) uses local search improve candidate plan structures formed Graphplan-style plan graph. Several planners (mips, sapa)
extend use relaxed plan heuristics include numeric features. vhpop partialorder planner, demonstrating partial-order planning competitive
recently fashionable heuristic forward state-space search planners. various reasons,
several planners generated small collections results, disregarded
analysis.
competitors used one version planner, one
parameter setting. attempt enforce use unique versions, left
competitors ensure informed variations used. Multiple versions
ff, mips lpg used. submitted almost data version optimised
speed performance. small subset data submitted version optimised
quality, showing alternative criteria performance evaluated.
analyses report used data generated optimised
speed exclusively. mips offered data two variants, using slightly different parameter
settings. analyses use data one variant (mips) exclusively, except case
Satellite hardnumeric problems used data variant
(mips.plain). lpg submitted data three versions: one based earliest plan produced,
one based best plan produced longer time span third represented
compromise speed quality. fact, since results version
optimised quality generated within minutes most, chose use data
exclusively analyses follow. borne mind reviewing
results comparative speed performance planners. performance lpg relies
certain parameter settings. cases, parameters used lpg automatically
set, cases parameters set hand. paper, appearing
issue, Gerevini, Saetti Serena (2003) give new results experiment testing
planner parameters set automatically. general observe significant
difference performance lpg respect data provided competition.
three hand-coded planners competed represent two alternative approaches
planning: forward state-space search using control rules prune bad choices promote
good choices, hierarchical task network (htn) planning.
508 problems available fully-automated planners mips
planner attempt them. 904 problems available hand-coded
planners shop2 planner attempt these, solving almost
solving problems overall. tlplan talplanner planners
solved problems attempted. planners attempted problems
equipped handle. particular, sapa attempt strips problems, although
capable solving them.
Although planning competitions great source data stateof-the-art planners encouragement catalyst progress field,
lively exciting competition events. means must winners.
7

fiLong & Fox

Planner

LPG
MIPS
SHOP2
Sapa
SemSyn
Simplanner
Stella
TALPlanner
TLPlan
TP4
TPSYS
VHPOP

Solved
237 (+70)
372
331
899
80
11
91
50
610
894
26
14
122

Attempted
284 (+76)
428
508
904
122
144
122
102
610
894
204
120
224

Success Ratio
83% (85%)
87%
65%
99%
66%
8%
75%
49%
100%
100%
13%
12%
54%

Tracks entered
S, N, HN
S, N, HN, ST,
S, N, HN, ST, T, C
S, N, HN, ST, T, C
T, C
S, N


S, ST,
S, N, HN, ST, T, C
N, ST, T, C
ST,
S, ST

Figure 1: Table showing problems attempted solved planners third
IPC. Tracks S: strips, N: numeric, HN: hardnumeric, ST: simpletime, T:
time C: complex. Note attempted 76 additional problems intended
handcoded planners solved 70 successfully. IxTeT solved
9 problems plans accepted validator attempted 10
problems producing plans could validated due differences
plan syntax used IxTeT defined pddl2.1.

8

fiThe 3rd International Planning Competition

choice winners left organisers must treated caution. summarising
results AIPS conference Toulouse, presented table results form
shown Figure 1, together selection graphs showing relative performance
planners terms speed quality plans several problem sets. hard
synthesise comprehensive view short time final data collection
presentation (a matter couple days, conference), initial assessments
based rather crude evaluation evidence. chose award prize lpg
best performer fully-automated planners: solved problems fullyautomated planners, showing excellent performance time tracks. awarded
prize mips solved second problems widest coverage
fully-automated planners. clear produced exceptional performance
numeric level problems could well judged worthy prize that. chose
acknowledge great difficulty newcomers competition building system
sufficiently robust compete, especially team programmers
researchers support effort. reason awarded prize vhpop best
newcomer, creditable performance strips simpletime problems.
Turning hand-coded planners, awarded prize best performance tlplan,
tackled almost problems available, solved attempted
produced plans high quality dramatic speed. rewarded shop2
fact attempted every problem produced plans planner.
quality plans consistently good performance highly competitive.
talplanner performed outstandingly, often producing highest quality plans
tremendously efficiently, coverage restricted strips time
tracks. selecting prize winners chose emphasise breadth coverage, particularly
new challenges handling numeric temporal planning problems. Competitions
demand degree spectacle selection winners, measured evaluation
planners takes time. paper present various analyses data collected
competition leave community judge final rankings planners.
3.3 Additional Challenges
hardnumeric complex problems used competition easily fit
analysis conducted across results. problems raise interesting special
challenges planners. discuss challenges, presenting data below.
challenges explored one two problem sets, generalisations
performance planners based data collected inappropriate.
not, therefore, perform statistical analysis data, but, instead, present relevant
data simple graphical form.
3.3.1 hardnumeric Satellite Problems
hardnumeric Satellite problem instances contained logical goals almost
trivial. example, cases problems involved simply ensuring
satellites target specific observation site end plan. However, plan metric
used evaluate plans far informative: plans evaluated according
data collected satellites execution. Simply satisfying explicit
9

fiLong & Fox

Satellite-HardNumeric
6000
TLPlan (20 solved)
SHOP2 (20 solved)
MIPS (20 solved)
(Speed) (20 solved)

5000

Quality

4000

3000

2000

1000

0
0

2

4

6

8
10
12
Problem number

14

16

18

20

Figure 2: Plan quality Satellite hardnumeric problems. High values better
quality plans: quality amount data collected.

goals would generate correct plan, worthless one terms plan metric.
fully-automated planners, mips tackled problems. tlplan shop2
hand-coded planners attempted problems. instructive compare
qualities plans produced four planners problem set. Figure 2
shows quality plans produced hand-coded planners significantly
higher quality plans generated fully-automated planners. Indeed,
generates plans satisfy logical goals minimise plan size required
achieve that, lead data collection. careful adjustments, mips
able generate plans collect data, clearly rather limited
result. closeness results generated tlplan shop2 suggest
solving data collection problem level close optimal, applying similar
heuristic approaches problem generating similar locally optimal solutions.
domain clearly highlights advantage hand-coded planners exploitation
knowledge human domain-engineer bring bear.
3.3.2 Complex Satellite Domain
addition hardnumeric Satellite domain, complex Satellite domain
considered. complexity domain arises fact combines temporal
actions, durations dependent parameters action, management
numerically measured resources (in case, data store available acquired data).
problem quality similar knapsack problem, data
packed limited stores appropriate satellites. combined temporal
optimisation problem, involves ensuring satellites efficiently deployed,
10

fiThe 3rd International Planning Competition

Satellite-Complex
2000
MIPS (8 solved)
TLPlan (20 solved)
SHOP2 (20 solved)
Sapa (16 solved)
LPG (Quality) (20 solved)

1800
1600
1400
Quality

1200
1000
800
600
400
200
0
0

2

4

6

8
10
12
Problem number

14

16

18

20

Figure 3: Plan quality Satellite complex problems. Low values represent better
plans, since quality measures makespan, minimised.

moving targets capturing data according capabilities, current
aspects available store. seen Figure 3, planners fullyautomated hand-coded produced plans quite widely varying quality (lower values
better, here, since quality measured makespan). general, tlplan produced
best quality plans, although lpg produced high quality plans smaller
problems. seen problems 13, 16, 19 20, particularly, fully-automated
planners occasionally produced plans quality diverging significantly optimal
(we actually know optimal values problems,
obviously consider best value produced upper bound optimal value).
3.3.3 Settlers Domain
Settlers domain based resource-management computer games, resources
must accumulated used construct new resource centres, new specialised
production capabilities. interesting problem domain highlights
pddl2.1 family languages offer convenient way name objects
created execution plan. version used competition, overcame
problem selection names available outset initially
committed role. object constructed, unallocated name used
name it, assigning name properties new object marking name
used. important problem approach creates current planners
initial grounding actions involves creating possible ways names
could assigned objects used various roles within plan. leads
significant explosion size domain encoding. interesting observe
11

fiLong & Fox

6 20 problems solved (fully-automated) planner,
solved one problem. clear domain remains challenge planning
technology, future development pddl2.1 necessary
review way object construction modelled.

4. Analysis Competition Performance
One important roles competition identify state art field,
terms variety measures, attempt answer broad questions
landscape research area. course, competition cannot last word
state art. might state art planning systems prevented,
whatever reason, taking part competition. However, competition
provide useful insights capabilities modern planning systems.
Planning performance measured terms speed solution problems
number quality solutions found. metrics might identified.
different planning architectures heuristic evaluation functions well
different kinds domains problems. state art represented specific
exemplars architectures heuristic functions interesting explore
suitability different architectures use different domains, scaling behaviour
particular approaches, comparative performance different planning systems, etc.
address issues following sections.
perform three collections analyses ascertain comparative performance based
consideration raw speed quality data, extent domain influenced planner
behaviour scaling behaviour planners. first collection comparison
planners based raw competition performance. analyse data
point view consumer interested ranking planners according speed
plan quality. experiments aimed answering coarse level questions
form: planner buy? asking questions trying arrive
general basis comparison. course, investigation question constrained
metrics used competition. Furthermore, trade-off one makes time
quality depends context planner might deployed. Therefore,
cannot combine judgements relative speed relative plan quality performance
determine unequivocally planner buy. take basic assumption potential
users domain-independent planning technology interested primarily broad coverage
good behaviour across wide variety domains, rather restricted coverage
spectacular behaviour domains. raw performance analyses
based mainly Wilcoxon rank-sum matched-pairs test (see Appendix C), explained
below. advantage test non-parametric, meaning rely
assumptions shapes properties underlying population distributions.
robust outliers.
second collection experiments concerned identifying whether
domains significantly easier (or harder). perform experiments
levels problems used competition determine whether agreement
amongst planners difficulty problems. part, assists us going
explore scalability issues allows us determine whether problem
12

fiThe 3rd International Planning Competition

set presented competition contained interesting challenges. third collection
experiments compares way planners scale problem sets agree
problem difficulty.
4.1 Raw Performance Analysis
perform pairwise comparisons planners ascertain whether consistent
pattern identified relative speed plan quality. focus first comparing
fully-automated planners and, separately, hand-coded planners. perform
additional set analyses try determine raw performance benefit obtained
use hand-coded control knowledge. this, perform Wilcoxon test pairs
crossing boundary fully-automated hand-coded planner groupings.
conclusion improvement obtained significant, say
control rules yield improvement performance. cannot account price,
terms effort encode rules, must paid obtain improvement.
understanding involved writing useful control knowledge still anecdotal
remains important challenge community quantify precisely. One
important consequence use hand-crafted control knowledge speak
planner performance blurs distinction planning system
control rules produced support performance domain.
planner performs well impossible separate contributions planning
system, architecture system (and extent contributes ease
expressing good control rules) sophistication control rules
used. attempt distinguish planner control rules analysis
follows, least one competitor observed results would significantly
worse less time prepare, while, given time, results could
improved concentrating optimisation plan metrics rather simply
makespans. observation helps highlight fact that, planners exploiting handcoded control knowledge, competition format seen highly constrained
basis evaluation performance.
summarise, present hypotheses exploring section:
Null Hypothesis: basis pairwise distinction
performances planners terms either time taken plan quality
(according specified problem metrics) plans produced.
Alternative Hypothesis: planners partially ordered terms
time performances and, separately, quality performances.
4.2 Analytic Framework
perform pairwise comparisons, planners fully-automated hand-coded
groups, problems main four problem levels used competition.
include analyses complex hardnumeric tracks resulted
data points meaningful statistical conclusions drawn. perform
Wilcoxon rank-sum matched-pairs tests identify whether number times one planner
performed better indicates significant difference performance
13

fiLong & Fox

two. performed pairwise comparisons performances tracks
use results construct partial orderings speed quality performances
planners tracks. use 0.001 significance level wish
extrapolate collections pairwise comparisons infer confidence, p = 0.05
level, transitive relationships planners. strips track,
largest, perform 15 pairwise comparisons confidence level 951/15 = 0.003
required transitive picture. use confidence level 0.001, resulting
slightly conservative analysis.
use sufficiently large samples T-distribution, used Wilcoxon test,
approximately normal. therefore quote Z-values indicate significance
differences mean performances paired planners. compare
pairs planners: cases superiority planner another clear
examination raw data statistical testing obviated.
Wilcoxon test tells us one planner performs consistently better another
whether consistency statistically significant. tell us much better
one planner another. could little difference performance
perhaps discrepancy accounted mere implementation differences.
consistency difference occurs determines whether statistically
significant discrepancy performances planners. One planner perform
consistently better another even though wins time. example,
comparison B, planner might win frequently B
faster solving subset problems set even though much slower solving
another subset problems. Provided subset B sufficiently large
greater number wins due emerge significant. example, set 10
problems ranked according differences performance, first 7 problems
ranking last 3 B, obtain score 28 B score 27.
case significant difference emerges regardless magnitude difference
B last three problems (see Appendix C). rank-sum approach
benefit allowing large numbers small wins outweigh small numbers large wins.
desirable large win problems indication overall better
performance. interested trying measure consistency domain-independent
behaviour therefore comparing consistency performance across domains given
planners perform differently within domains.
size win need indicate complexity underlying problem
allow us make judgements scalability. Essentially test reveals
consistent patterns performance across range problems. consider
interest knowing one planner significantly consistently better another
helps us make objective judgement two planners performing better
across varied problem set. variability performances consistent
pattern emerges, hard perhaps impossible make judgement objectively.
cases, comparison using Wilcoxon test lead statistically
significant conclusions, proportion wins one planners higher
consistent null hypothesis equal performance. tested using Z-test
proportion (see Appendix C). test yields significant result report it,
14

fiThe 3rd International Planning Competition

described below. test less informative Wilcoxon test take
account wins distributed problem set.
performing pairwise comparisons must deal cases planner
solve problem. assign infinitely bad speed planner cases, ensuring
maximum possible benefit given planners solving problems, even slowly.
methodology valid Wilcoxon test based rank effect simply
push unsolved cases extreme ranking. case quality perform
initial collection tests using infinitely bad quality unsolved problems.
somewhat difficult decide means compare true quality result
infinitely bad quality assigned planner produced solution. conclusion
comparison may informative enough, addition perform Wilcoxon
test cases planners produced plan. refer cases
double hits.
4.3 Results Analysis
results performing Wilcoxon tests, order compare speed performance fully-automated planners, shown Figure 4. results similar tests
compare plan quality presented Figures 5 6. double hits data presented
Figure 6. corresponding tests hand-coded planners shown Figures 7
8.
tables rows corresponding four problem levels competition
gathered sufficient data analysis. are: strips, numeric, simpletime time.
many results fully-automated planners strips domains
split two rows, creating five rows tables. comparisons plan quality
report strips results using sequential plan length concurrent plan length separately.
data rows interpreted following way. cell, representing pair
planners compared, presents Z-value corresponding p-value identified
Wilcoxon statistical table. order planners names title cell
significant: first planner named one favoured comparison. Underneath
cell entry indicating size sample used. sample consists
problems least one planners compared produced solution:
results different sample sizes different comparisons. p-value
greater 0.001 difference mean performances obtained competing
planners statistically significant concluded planner column
significantly out-performing competitor. p-value greater 0.001 difference
significant, terms transitive view interested, null
hypothesis planners performing roughly equally cannot rejected. indicate
absence significance p < 0.001 level use bold font.
Wilcoxon test tells us significant difference mean behaviour
identify planner producing greater proportion wins cases
mean behaviour insignificantly different. Therefore, Wilcoxon tests reports
significant difference pair planners report Z-value
proportion (see Appendix C), significant, provide missing information.
15

fiLong & Fox

Strips

FF-LPG
6.2
?
120

LPG-MIPS
5.3
?
118

LPG-Sim
1.9
0.06
118

Sim-MIPS
1.9 (3.1)
0.06 (?)
114

MIPS-VHPOP
3.4
?
98

VHPOP-Stella
0.11
0.92
59

Strips

Sim-Stella
7.2
?
83

LPG-VHPOP
7
?
117

FF-MIPS
8.9
?
117

FF-Sim
7.8
?
117

MIPS-Stella
4.7
?
80

Sim-VHPOP
4.3
?
108

FF-LPG
3.5
?
93

LPG-MIPS
3.8
?
86

Simple
Time

LPG-MIPS
5
?
100

MIPS-VHPOP
2
0.04
68

VHPOP-TP4
5.9
?
54

LPG-TP4
8.4
?
100

MIPS-TPSYS
5.9
?
47

TP4-TPSYS
2.6
< 0.01
14

Time

LPG-Sapa
3.3
?
95

MIPS-Sapa
0.72
0.67
72

LPG-MIPS
3.4
?
96

MIPS-TP4
5.1
?
36

Sapa-TP4
5.2
?
38

Numeric

FF-MIPS
8
?
85

Figure 4: Table showing results statistical tests comparison speeds planners.
Bolded results significant p = 0.001 level. cell
represents pair planners compared. presents Z-value corresponding p-value identified Wilcoxon statistical table. order
planners names title cell significant: first planner named
one favoured comparison. Underneath cell entry indicating
size sample used. ? indicates result less 0.001.

16

fiThe 3rd International Planning Competition

Strips
(Seq)

LPG-FF
0.21
0.84
120

LPG-MIPS
6.9
?
118

LPG-Sim
7.6
?
118

MIPS-Sim
0.38
0.7
114

Strips
(Seq)

Sim-Stella
5.6
?
83

LPG-VHPOP
7.7
?
117

FF-MIPS
7.2
?
117

FF-Sim
8.5
?
117

LPG-FF

MIPS-VHPOP
1.3
0.21
98

VHPOP-Stella
2.1 (3.3)
0.04 (?)
59

MIPS-Stella
5
?
80

Sim-VHPOP
0.45
0.65
108

Strips
(Conc)

6
?
120

LPG-MIPS
5.3
?
118

LPG-Sim
8.6
?
118

MIPS-Sim
2.4 (4.1)
0.01 (?)
114

MIPS-VHPOP
0.69
0.49
98

VHPOP-Stella
0.93
0.35
59

Strips
(Conc)

Sim-Stella
2.1
0.03
83

LPG-VHPOP
5.2
?
117

FF-MIPS
1.4
0.16
117

FF-Sim
8.5
?
117

MIPS-Stella
3.7
?
80

VHPOP-Sim
0.13
0.90
108

Numeric

LPG-FF
3 (4.5)
< 0.01 (?)
93

LPG-MIPS
6.1
?
86

FF-MIPS
3.5
?
85

Simple
Time

LPG-MIPS
8.7
?
100

MIPS-VHPOP
2.4 (3.5)
0.01 (?)
68

VHPOP-TP4
5.4
?
54

LPG-TP4
8.6
?
100

MIPS-TPSYS
5.6
?
47

TP4-TPSYS
2.7
< 0.01
14

LPG-Sapa
6.7
?
95

Sapa-MIPS
0.029
0.99
72

LPG-MIPS
6.6
?
96

LPG-TP4
6.6
?
57

MIPS-TP4

Time

5
?
36

Sapa-TP4
5.2
?
38

Figure 5: Table results statistical tests comparisons plan quality across problems
solved least one planner pair. Bolded results
significant p = 0.001 level. ? indicates result less 0.001.

17

fiLong & Fox

Strips
(Seq)

LPG-FF
0.24
0.83
114

LPG-MIPS
4.3
?
85

LPG-Sim
5.9
?
90

MIPS-Sim
1.4
0.16
63

VHPOP-MIPS
2.9
< 0.01
56

VHPOP-Stella
4.7
?
39

Strips
(Seq)

Sim-Stella
1.8
0.08
49

LPG-VHPOP
3.6
?
68

FF-MIPS
4.6
?
86

FF-Sim
7.1
?
91

MIPS-Stella
3.1
< 0.01
44

VHPOP-Sim
5.2
?
51

Strips
(Conc)

LPG-FF
6.5
?
114

LPG-MIPS
1.5
0.14
85

LPG-Sim
7.5
?
90

MIPS-Sim
6.3
?
63

VHPOP-MIPS
3.9
?
56

VHPOP-Stella
2.7
< 0.01
39

Strips
(Conc)

Stella-Sim
6
?
49

VHPOP-LPG
3
< 0.01
68

MIPS-FF
4.8
?
86

FF-Sim
7.1
?
91

MIPS-Stella
0.24
0.83
44

VHPOP-Sim
6.1
?
51

LPG-FF
3.8
?
69

LPG-MIPS
3.2
?
46

MIPS-FF
4.2
?
50

Simple
Time

LPG-MIPS
6.6
?
58

MIPS-VHPOP
2.9 (3.8)
< 0.01 (?)
44

TP4-VHPOP
3.4
?
15

LPG-TP4
1.3
0.19
15

TPSYS-MIPS
0.61
0.54
10

TP4-TPSYS
1.8
0.07
10

Time

LPG-Sapa
4.7
?
62

MIPS-Sapa
1.6
0.09
50

LPG-MIPS
4.2
?
55

LPG-TP4
1.9
0.06
5

TP4-MIPS
1.1
0.27
5

TP4-Sapa
1.3
0.19
5

Numeric

Figure 6: Table showing results statistical tests comparisons quality plans
pairs planners considering problems solved planners.
cell represents pair planners compared. presents Z-value
corresponding p-value identified Wilcoxon statistical table. order
planners names title cell significant: first planner named
one favoured comparison. Underneath cell entry indicating
size sample used. ? indicates result less 0.001.

18

fiThe 3rd International Planning Competition

Small Problems
Strips

Numeric

TL-TAL
6.8
?
102

TAL-SHOP2
0.028
0.99
102

Large Problems
TL-SHOP2
7.2
?
102

TL-SHOP2
6.5
?
102

TAL-TL
5.6
?
98

TAL-SHOP2
8.5
?
98

TL-SHOP2
8.2
?
98

TL-SHOP2
7.9
?
98

Simple
Time

TL-TAL
8.7
?
102

SHOP2-TAL
0.61
0.34
102

TL-SHOP2
7
?
102

TL-TAL
0.77
0.44
98

TAL-SHOP2
6.4
?
98

TL-SHOP2
8.4
?
98

Time

TL-TAL
8.8
?
102

TAL-SHOP2
0.2
0.84
102

TL-SHOP2
7.8
?
102

TL-TAL
3.1
?
98

TAL-SHOP2
7.3
?
98

TL-SHOP2
8
?
98

Figure 7: Table showing results statistical tests comparison speeds handcoded planners. ? indicates result less 0.001.

Small Problems

Large Problems

Strips
(Seq)

TL-TAL
2.3
0.01
102

TAL-SHOP2
2
0.04
102

TL-SHOP2
5.3
?
102

TAL-TL
0.89
0.38
98

TAL-SHOP2
4.4
?
98

TL-SHOP2
3.6
?
98

Strips
(Conc)

TAL-TL
8.6
?
102

TAL-SHOP2
4.3
?
102

SHOP2-TL
7
?
102

TAL-TL
8.6
?
98

TAL-SHOP2
7
?
98

SHOP2-TL
7.7
?
98

Numeric

TL-SHOP2
0.18
0.86
102
TL-TAL

Simple
Time

1
0.32
102
TL-TAL
4
?

Time
102

TL-SHOP2
0.15
0.88
98
TAL-SHOP2
4.5
?
102

TL-SHOP2
5.3
?
102

TAL-TL
0.76
0.44
98

TAL-SHOP2
5.5
?
98

TL-SHOP2
5.4
?

SHOP2-TAL
0.26
0.80
102

TL-SHOP2
3.9
?
102

TL-TAL
2.3
0.01
98

TAL-SHOP2
0.54
0.58
98

TL-SHOP2
5.7
?
98

Figure 8: Table showing results statistical tests comparative quality plans produced
hand-coded planners. table shows results problems solved least
one planners results restricted problems solved insignificantly different, since hand-coded planners solved almost problems
attempted. ? indicates result less 0.001.

19

fiLong & Fox

Z-value proportion, p-value, appear brackets following
Wilcoxon result.
4.4 Interpretation
results show null hypothesis rejected. Therefore, adopt alternative hypothesis discuss resulting partial orders inferred data.
data presented Figures 4 8 interpreted terms partial orderings
speed quality performances fully-automated hand-coded planners
four problem levels. done, level, simply putting ordering
pairs planners B Wilcoxon value pair reported
sub-column associated significant 0.001 level. results
shown Figures 9 12. figures sub-graphs associated
four problem levels identified. presence arrow graph indicates
statistically significant ordering exists. absence arrow B indicates
statistically significant relationship B found corresponding
problem level therefore transitive ordering depend relationship.
4.4.1 Partial orderings based speed
Figure 9 describes speed comparisons made fully-automated
planners according Wilcoxon test. observed significantly consistently faster fully-automated planners strips numeric levels (the
significance arrows figure sufficient support transitive reasoning).
Indeed, strips numeric levels interesting linear ordering ff,
lpg, mips vhpop (three prize-winners amongst fully-automated
planners) maintained lpg, mips vhpop simpletime level. Despite observation simplanner faster, significant proportion strips
problems mips, significant Wilcoxon relationship
four prize-winners comprise spine performance around planners
competing levels clustered. relationship breaks time level lpg, mips, sapa tp4 participated. data set seen mips
sapa indistinguishable, respect Wilcoxon test, lpg significantly
consistently faster both.
comparing hand-coded planners competition used collection small problems collection large problems problem level. large problems
beyond capabilities fully-automated planners. Interestingly, handcoded planners behaved differently small large problem collections.
marked Figure 10, strips level, performances tlplan
talplanner inverted small large problem sets. small simpletime
time problems tlplan consistently faster either talplanner shop2,
talplanner shop2 statistically indistinguishable data sets. tlplan
consistently faster talplanner, turn consistently faster shop2,
large time problems.
20

fiThe 3rd International Planning Competition

numeric
LPG



VHPOP

MIPS

SIMPLANNER

TP4

simple time
TPSYS

STELLA

strips

key:



B

consistently faster B.



B

faster B significant number
times.

SAPA
LPG

TP4
MIPS

time

Figure 9: partial order fully-automated planners terms relative speed
performances.

TAL
TL
SHOP2
strips (small)

TL
SHOP2

TAL

TL

SHOP 2
TAL

strips (large)

simple time (large)
TAL
TL
TL
numeric(small,large)

TAL

SHOP2

SHOP2
time (large)

simple time, time (small)

Figure 10: partial order hand-coded planners terms relative speed
performances.

21

fiLong & Fox

4.4.2 Partial orderings based quality
construction partial order quality performance strips level
fully-automated planners shown Figure 11. interpret figures depicting quality
performance noted that, problem levels except strips, specific quality
metrics provided plan quality must measured terms metrics.
strips level metrics provided quality measure plan length either
sequential concurrent. figures labelled arrows strips graphs
denote whether relationship exists terms sequential concurrent ordering,
both. ordering sequential concurrent quality arrow left
unlabelled. observed two planners might ordered one direction
sequential length concurrent length.
indicated above, comparison quality performance made difficult one
two planners compared solved many problems (this problem
arises fully-automated planners hand-coded planners failed solve
problems proportion unsolved problems affect tests). Using
infinite quality measure unsolved problems Wilcoxon test concludes planner
solving problems overall better quality words, one interested
overall solution quality one choose planner solves problems even
if, cases, produces worse quality plans competitor. However,
want understand relationship two planners double hits case.
notice consideration problems sometimes inverts relationship detected
first test. example, Figure 11 observed that, simpletime
level, vhpop consistently produced better quality plans tp4 across whole problem
set but, double hits considered, tp4 produced consistently better plans
vhpop. suggests tp4 solving problems higher quality solutions,
price pays search find solutions high solves much smaller
set problems planners, vhpop. depict results using dotted
arrows graphs. Finally, arise Wilcoxon test detects significant
relationship two planners, difference proportion problems
solved two planners significant. indicate resulting weaker relationship using
dashed arrow.
Figure 11 shows lpg emerges fully-automated planner consistently producing
highest quality plans problem levels. relationship mips
complex because, whilst produced plans better sequential quality mips,
mips produced better quality concurrent plans considering double hits.
reason apparent discrepancy mips post-processes sequential plans
partially ordered plans exploiting available concurrency problem,
exploit. However, fails solve larger subset problems ff, giving
advantage quality overall.
strips problems simplanner solves problems stella hence
seen performing consistently higher sequential-plan quality level. double
hits considered stella outperforms simplanner concurrent-plan quality. Also,
double hits considered, seen vhpop consistently outperforms stella
22

fiThe 3rd International Planning Competition

LPG



MIPS


numeric
conc

LPG

MIPS

TPSYS

seq

LPG
conc

VHPOP

SIMPLANNER

TP4

simple time
MIPS

conc

SAPA

seq
conc

VHPOP

seq

TP4

LPG
MIPS

time

STELLA

key:

B consistently better
B.with confidence
least 99.9%.



seq

strips



B produces better plans
significantly often
B.



B

consistently better
B double.
hits considered.

Figure 11: fully-automated planners depicted terms relative quality performances.

strips (small)

seq
TL

TAL

conc

SHOP2

conc

TL

conc
seq

conc
TAL

SHOP2

seq

strips (large)
TL

SHOP2

TL

TAL

TAL
SHOP2
simple time (small, large)

time (small)

Figure 12: hand-coded planners depicted terms relative quality performances.

23

fiLong & Fox

sequential-plan quality simplanner cases. Interestingly, vhpop stella
Wilcoxon proportion test relationship problems considered.
mips outperforms vhpop tpsys simpletime problems, vhpop consistently better tp4. double hits considered tp4 outperforms vhpop
demonstrating tp4 produces better quality solutions problems solves.
Given available data seems tp4 tpsys performing significantly differently, may data set small draw conclusion confidence.
time data set significant consistent pattern relative performances
sapa mips. lpg consistently produces better quality plans.
fully-automated planners find speed comparisons
observed hold planners compared terms quality. Figure 12 shows
quality comparisons performed three competing hand-coded planners.
shows that, small strips problems tlplan consistently outperformed shop2 terms
sequential plan quality. small problems talplanner produces shorter makespan
plans tlplan shop2 shop2 produces shorter makespan plans
tlplan. tlplan produces sequential strips plans use post-processing
step introduce parallelism. result certain outperformed makespan
comparison planners capable producing parallel plans.
significant relationships emerged numeric problems. talplanner
compete numeric problems. significant Wilcoxon result established.
simpletime problems (both small large) quality performances tlplan
talplanner indistinguishable, consistently better shop2.
time problems tlplan emerges consistently better talplanner shop2.
4.4.3 Cross-boundary partial orderings
performed final collection comparisons try better understand advantages
obtained use hand-coded rather fully-automated planners, terms
speed quality. compare best-performing fully-automated planner
best-performing hand-coded planner categories: tlplan speed,
levels, lpg talplanner strips level, shop2 numeric level
tlplan remaining problem levels, quality.
tables Figures 14 15 show results tests. Figure 13 summarises
conclusions. observed tlplan consistently faster problem
levels participated, demonstrating control knowledge
exploited tlplan giving real speed advantage. remains seen exactly
case, given several strips domains control knowledge
usually described encoded appears prune additional states
already pruned ff-style heuristic measure used. reason added value
interesting question community consider trying evaluate advantages
disadvantages hand-coded approach.
observed talplanner produces consistently better concurrent plans
lpg strips level. Again, result needs explained in-depth
analysis control information exploited talplanner. simpletime
level lpg produces plans consistently better quality tlplan.
24

fiThe 3rd International Planning Competition

TL

LPG



levels (speed)

simple time (quality)
Key:

TAL

conc

TL



B

consistently faster/better quality B

Notes:
significant quality difference TLplan STRIPS level.
significant difference SHOP2 LPG numeric level.
significant difference TLPlan LPG time level.

LPG

strips (quality)

Figure 13: comparison best fully-automated planners best
hand-coded planners problem level.

Strips

TLPlan-FF
6.7
< 0.001
102

Numeric

SHOP2-LPG
8.2
< 0.001
102

SimpleTime

TLPlan-LPG
8.6
< 0.001
102

Time

TLPlan-LPG
8.7
< 0.001
102

TAL-LPG
7.8
< 0.001
102

TAL-VHPOP
8.5
< 0.001
102

Figure 14: Table results comparisons fully-automated hand-coded planners
terms speed. cell represents pair planners compared.
presents Z-value corresponding p-value identified Wilcoxon
statistical table. order planners names title cell
significant: first planner named one favoured comparison.
Underneath cell entry indicating size sample used.

25

fiLong & Fox

Problems solved least one

Problems solved

Strips
(Seq)

TLPlan-FF
0.57
0.57
102

LPG-TAL
1.8 (3.9)
0.08 (< 0.001)
102

TAL-VHPOP
2.9
< 0.01
102

FF-TLPlan
0.35
0.72
97

LPG-TAL
2.4 (4.2)
0.01 (< 0.001)
99

VHPOP-TAL
4.9
< 0.001
67

Strips
(Conc)

TLPlan-FF
0.57
0.57
102

TAL-LPG
5.9
< 0.001
102

TAL-VHPOP
6.4
< 0.001
102

FF-TLPlan
0.35
0.72
97

TAL-LPG
5.6
< 0.001
99

TAL-VHPOP
2.6
< 0.01
67

Numeric

SHOP2-LPG
1.9
0.06
102

LPG-SHOP2
1.6
0.11
83

Simple
Time

LPG-TLPlan
3.9
< 0.001
102

LPG-TLPlan
4.3
< 0.001
100

Time

TLPlan-LPG
0.093
0.92
102

LPG-TLPlan
1.6
0.11
93

Figure 15: Table results comparisons plan quality fully-automated
hand-coded planners.

interesting observe hand-coding control information appear lead
consistent improvement plan quality across data sets. seem lead
speed advantage must indicate that, general, control rules provide basis
efficient pruning weak general heuristic measures. Wilcoxon test
measure extent speed advantage obtained, measure extent
quality advantage obtained using fully-automated planner preference.
trade-offs need close analysis, interesting see fact
uniform advantage obtained hand-coded planners, least smaller problems
formed common foundation testing. course, development hand-coded
control knowledge prioritise different aspects solutions generated possible
development control rules might support construction heavily
optimised plans.

5. Tests Magnitude
complement Wilcoxon tests perform additional analyses identify whether,
given two planners compared, magnitude difference performance
two planners statistically significant. perform paired t-tests (see Appendix C)
using subset pairs planners. focus attention pairs consistent significant differences identified, consider meaningful
compare magnitude results planners consistent domination exhibited.
restrict attention planners were, according Wilcoxon tests,
26

fiThe 3rd International Planning Competition

impressive performers competition levels. perform separate tests
speed quality.
investigating magnitude differences performances meaningful
include problems solved one planners compared. Using
infinite time quality measures would result magnitude value would grossly
distort true picture. magnitude tests therefore consider double hits.
price pay give undesirable emphasis smaller easier
problems since ones frequently solved planners.
borne mind interpreting data.
hypotheses considered section are:
Null Hypothesis: consistent magnitude difference performances planners.
Alternative Hypothesis: Planners demonstrate significant differences consistency performance demonstrate corresponding magnitudes
differences performances.
5.1 Analytic Framework
t-tests performed using normalised performances two planners.
find magnitude difference performances two planners, p1 p2 ,
collection problem instances. example, given collection n problems, find
pairs results p1ri p2ri obtained instances = 1 = n. case normalise
values dividing mean pair. process establishes
range performances 0 2, 1 standing equal performance.
t-test results t-value representing difference mean normalised performances
two planners. perform 2-tailed tests p < 0.05 interested
individual results rather extrapolated partial orderings based magnitude.
want consider magnitude information relevant individual consistency
results.
5.2 Results Analysis
tables Figures 16 20 organised follows. Tables Figures 16, 18 20
contain speed results found fully-automated, hand-coded mixed pairs respectively. Tables Figures 17, 19 20 contain quality results three
groups. table row five competition levels (although empty
rows omitted). columns represent pairs planners compared.
cell five pieces data reported: mean normalised performance
planner; t-value computed degrees freedom used (which derived
number double hits level) resulting p-value. positive t-value means
magnitude difference favour planner identified second cell. negative
t-value favour planner identified first. resulting t-value indicates
difference magnitude significant p=0.05 level use bold font.
speed quality tests, average performance smaller 1 favourable
planner. interpretation value represents average proportion
27

fiLong & Fox

strips

numeric

simpletime

time

0.4
LPG 1.6
-12.26,113
< 0.001
0.23
LPG 1.77
-16.04,68
< 0.001
LPG 1.03
MIPS 0.97
0.35,57
0.73
LPG 1.25
MIPS 0.75
2.64,54
0.008

MIPS 1.21
LPG 0.79
2.69,84
0.007
MIPS 0.8
LPG 1.2
-1.84,45
0.06
MIPS 0.85
VHPOP 1.15
-1.43,43
0.15
LPG 1.16
Sapa 0.84
1.81,61
0.07

0.22
MIPS 1.78
-21.30,85
< 0.001

LPG 0.76
VHPOP 1.24
-2.82,67
0.005

LPG 1.28
Sim 0.72
3.73,89
< 0.001

Sim 0.26
VHPOP 1.74
-15.19,50
< 0.001

MIPS 0.77
Sapa 1.23
-3.41,49
< 0.001

Figure 16: Magnitude comparisons fully-automated planners terms speed.
strips (seq)

strips (conc)

numeric

simpletime

time

MIPS 1.05
LPG 0.95
5.61,84
< 0.001
1.18
LPG 0.82
9.70,113
< 0.001
1.17
LPG 0.83
6.00,68
< 0.001
LPG 0.86
MIPS 1.14
-7.98,57
< 0.001
LPG 0.9
MIPS 1.1
-3.44,54
< 0.001

0.95
MIPS 1.05
-5.39,85
< 0.001
1.13
MIPS 0.87
6.81,85
< 0.001
1.01
MIPS 0.99
0.14,49
0.89
MIPS 0.93
VHPOP 1.07
-3.97,43
< 0.001
LPG 0.86
Sapa 1.14
-4.99,61
< 0.001

LPG 0.98
VHPOP 1.02
-2.73,67
0.006
LPG 0.7
Sim 1.3
-12.95,89
< 0.001
MIPS 1.2
LPG 0.8
4.25,45
< 0.001

LPG 0.91
Sim 1.09
-7.21,89
< 0.001
Sim 1.33
VHPOP 0.67
14.37,50
< 0.001

Sim 1.08
VHPOP 0.92
6.01,50
< 0.001

Figure 17: Magnitude comparisons fully-automated planners terms quality.

mean performances pair planners test set. Thus, average performance
0.66 planner (which compare average performance 1.34
planner pair considered) means first planner is, average, twice
fast second.
5.3 Interpretation
results demonstrate null hypothesis rejected almost pairwisecomparisons planners Wilcoxon test shows significant consistent performance difference. cases null hypothesis cannot rejected,
implying consistent performance difference pair planners translate
statistical significance mean relative performances.
28

fiThe 3rd International Planning Competition

strips

numeric

simpletime

time

Small Problems
TLPlan 0.52
TLPlan 0.61
TAL 1.48
SHOP2 1.39
-12.98,101
-8.32,101
< 0.001
< 0.001
TLPlan 0.7
SHOP2 1.3
-6.21,101
< 0.001
TLPlan 0.43
TLPlan 0.67
TAL 1.57
SHOP2 1.33
-21.34,101
-7.79,101
< 0.001
< 0.001
TLPlan 0.44
TLPlan 0.59
TAL 1.56
SHOP2 1.41
-25.00,101
-10.14,101
< 0.001
< 0.001

TLPlan 1.32
TAL 0.68
7.74,97
< 0.001
TLPlan 0.31
SHOP2 1.69
-19.22,92
< 0.001
TLPlan 0.32
SHOP2 1.68
-24.27,97
< 0.001
TLPlan 0.82
TAL 1.18
-5.75,97
< 0.001

Large Problems
TLPlan 0.39
TAL 0.24
SHOP2 1.61
SHOP2 1.76
-17.41,97
-26.04,97
< 0.001
< 0.001

TAL 0.48
SHOP2 1.52
-11.28,97
< 0.001
TLPlan 0.31
SHOP2 1.69
-23.75,95
< 0.001

TAL 0.46
SHOP2 1.54
-12.81,95
< 0.001

Figure 18: Magnitude comparisons hand-coded planners terms speed.
Small Problems
strips (seq)

strips (conc)

simpletime

time

TLPlan 0.96
SHOP2 1.04
-5.48,101
< 0.001
TLPlan 1.38
TAL 0.62
21.10,101
< 0.001
TLPlan 0.89
SHOP2 1.11
-7.66,101
< 0.001
TLPlan 0.9
TAL 1.1
-4.39,101
< 0.001

TLPlan 1.27
SHOP2 0.73
11.81,101
< 0.001
TAL 0.93
SHOP2 1.07
-3.82,101
< 0.001
TLPlan 0.94
SHOP2 1.06
-4.08,101
< 0.001

TAL 0.88
SHOP2 1.12
-5.15,101
< 0.001

TLPlan 0.96
SHOP2 1.04
-3.82,97
< 0.001
TLPlan 1.7
TAL 0.3
48.66,97
< 0.001
TLPlan 0.85
SHOP2 1.15
-6.85,97
< 0.001
TLPlan 0.88
SHOP2 1.12
-6.46,95
< 0.001

Large Problems
TAL 0.98
SHOP2 1.02
-2.13,97
0.033
TLPlan 1.5
TAL 0.75
SHOP2 0.5
SHOP2 1.25
16.58,97
-8.94,97
< 0.001
< 0.001
TAL 0.87
SHOP2 1.13
-4.80,97
< 0.001

Figure 19: Magnitude comparisons hand-coded planners terms quality.
Speed
strips

simpletime

time

TLPlan 0.55
1.45
-7.60,96
< 0.001
LPG 1.9
TLPlan 0.1
38.14,99
< 0.001
LPG 1.9
TLPlan 0.1
26.85,92
< 0.001

Quality
Seq
Conc
TLPlan 1
TAL 1.04
TAL 0.84 TLPlan 1.23
1
LPG 0.96
LPG 1.16
LPG 0.77
0.54,96
3.89,98
-7.16,98
12.54,98
0.589
< 0.001
< 0.001
< 0.001
LPG 0.94
TLPlan 1.06
-3.89,99
< 0.001

Figure 20: Comparisons fully-automated hand-coded planners terms
speed quality.

29

fiLong & Fox

shown tables 16 20, reassuring consistency emerged results
Wilcoxon tests. is: significant consistency differences identified two
planners using Wilcoxon test, t-test magnitude generally reveals significant
magnitude difference well.

6. Dependence Performance Domain
consider important quantify difficulty problems used competition
provides basis deeper understanding relative planner performance.
explore investigate whether domains used uniformly
considered easy, hard, amongst fully-automated hand-coded planners.
investigate whether, might expected case, strips problems generally
considered easier problems numeric temporal levels.
two questions lead two related investigations based bootstrapping techniques.
analyses show different planners experienced different domains levels difficult,
within fully-automated hand-coded categories.
first competition, 1998, reported (Long, 2000) planner solved
problem 25,000 ground actions 10,000 ground actions
marked limit beyond planner performance markedly unreliable. ground
action formed replacing action schema parameters objects correct types
selected problem instance. static preconditions preconditions whose
truth ascertained entirely initial state used filter ground
actions, plausibly applicable counted. Relevant ground
actions found applying reachability analysis initial state regression
analysis goals order identify subset ground actions could actually
play useful role plan. seems plausible number ground actions could
offer guide difficulty problems. fact, brief survey largest problems
third competition, Figure 21, reveals action counts vary widely across
domains. encouraging observe size problems solved
reasonable reliability, least domains, grown significantly, despite fact
still typical planners ground action set prior planning. interest
observe size problems measured action counts strong indication
difficulty problems Rovers Satellite domains amongst found
harder many planners, despite small action counts.
summarise, hypotheses explored section are:
Null Hypothesis: domains used competition equally challenging planners levels.
Alternative Hypothesis: Domain/level combinations distinguished
terms relative difficulty posed different planners.
ease comparison results presented Sections 7 8 observe that,
section, specifically concerned cross-domain analysis whether
planners agreed domain/level combinations hard.
30

fiThe 3rd International Planning Competition

Domain
Depots
DriverLog
ZenoTravel
Rovers
Satellite
FreeCell
Settlers

Largest Ground Action Count
332,064
31,140
32,780
7,364
4,437
112,600
5,884

Largest Relevant Action Count
22,924
15,696
32,780
3,976
4,437
25,418
4,503

Figure 21: Counts ground action instances (generated using FF).

6.1 Analytic Framework
order explore two questions, used planners discover hard domains
levels were. planner, domain problem level plot number problem
instances left solve time milliseconds. results curve, area
taken measure difficulty experienced planner solving
problems given domain given problem level. order keep area
curve finite use cut-off time thirty minutes. extended cut-off time (fifteen
minutes used competition) results higher penalty paid planner
fails solve problems.
experiment used address first question, null hypothesis
planner finds problems specific level equally difficult across domains. test
constructed, using bootstrapping technique, ten thousand samples twenty values
collection timings obtained domains appropriate level. values
selected random performances planners competing domains, one
value collection randomly selected problems. example, problem one
chosen DriverLog, problem two Depots, problem three Rovers, problem
four Depots, etc., value associated problem one would produced
problem planner selected random competed DriverLog.
Similarly, value associated problem two would chosen planner
competed Depots, on. collection 20 values plotted number
problem instances left solve time, above. resulted sampling
distribution level-specific areas. Using bootstrap samples check whether
area calculated particular planner-domain-level combination lies extremes
distribution, not. lies first 2.5% distribution reject null
hypothesis grounds planner found problems level, domain,
significantly easy. lies top 2.5% distribution reject null
hypothesis conclude problems significantly hard planner.
testing relative hardness problem levels within domain (the second question),
perform similar experiments which, planner, bootstrapped samples
obtained sampling timings problem levels within domains. resulted
new sampling distribution level-independent area statistic. null hypothesis,
domain/level combination indicator difficulty, tested seeing whether
31

fiLong & Fox

Depots
DriverLog
ZenoTravel
Rovers
Satellite
FreeCell
Settlers

strips
[6]
1/3
0/1
3/0
2/1
4/0
1/2


Level-dependent
numeric simpletime
[3]
[3]
1/0
0/1
2/0
1/0
2/0
1/0
0/1
0/1
0/2
1/0


0/2


time
[3]
0/1
2/0
1/0
1/1
1/0



strips
[6]
2/2
1/0
4/0
3/1
4/0
2/2


Level independent
numeric simpletime
[3]
[3]
1/1
0/1
0/0
1/0
2/0
0/0
0/2
0/1
0/2
2/0


0/2


time
[3]
0/1
1/0
0/1
0/1
1/0



Figure 22: Comparisons performance domains fully-automated planners.

areas computed planner-domain-level combinations extreme respect
new sampling distribution.
6.2 Results Analysis
Figures 22 25 report results two experiments described above. Figures 22
23 describe level-specific level-independent comparisons made using
fully-automated planners hand-coded planners respectively. table handcoded planners divided two parts: first five rows correspond small
problems, latter five rows large problems. performance hand-coded
planners large problems measured using bootstrapped samples taken
large problem collection.
tables organised follows: rows correspond domains, labelled,
columns levels considered number planners used. number
planners varies columns different planners participated different
domain levels. example, planners participated strips level
others. planners produced little data justify statistical analysis
included tests. Thus, eleven fully-automated planners competition
seven produced enough data analysis experiments.
cells tables contain two integer values separated diagonal. value
left diagonal indicates number planners found problems
corresponding domain level significantly easy. value right indicates
number found problems significantly hard. Thus, seen Figure 22
six fully-automated planners participated strips level Depots
domain, one found problems easy three found hard. two
planners areas calculated using method explained found
sufficiently extreme rejection null hypothesis. Broadly speaking (we discuss
interpretation data detail below) four left-hand columns tell us whether
problems particular domain level easy hard relative problems
level; four right-hand columns tell us whether easy hard relative
problems. addition, rows allow us compare domains relative difficulty:
example, none planners found ZenoTravel hard level relative
problems level, whilst Depots Rovers found hard least one
competitor levels.
32

fiThe 3rd International Planning Competition

Depots
DriverLog
ZenoTravel
Rovers
Satellite
Depots (large)
DriverLog (large)
ZenoTravel (large)
Rovers (large)
Satellite (large)

strips
[3]
2/0
0/0
3/0
0/2
2/1
2/0
0/1
3/0
1/1
1/0

Level-dependent
numeric simpletime
[2]
[3]
2/0
1/0
2/0
0/0
1/0
3/0
0/1
0/3
0/1
2/1
2/0
2/0
1/0
0/1
1/0
3/0
0/0
1/1
0/1
2/0

time
[3]
3/0
3/0
3/0
0/2
0/1
3/0
1/1
3/0
1/0
0/2

strips
[3]
3/0
3/0
3/0
1/0
2/0
2/0
0/0
3/0
2/0
1/0

Level-independent
numeric simpletime
[2]
[3]
2/0
3/0
1/0
2/0
1/0
3/0
0/1
0/1
0/0
2/1
1/0
2/0
0/0
0/1
1/0
3/0
0/0
2/0
0/1
2/0

time
[3]
3/0
0/0
2/0
0/2
0/1
2/0
0/1
3/0
0/0
0/1

Figure 23: Comparisons performance domains using hand-coded planners.
level-independent tests reported exactly way right-hand halves
Figures 22 (for fully-automated comparison) 23 (for hand-coded comparison).
tables tell us whether problems particular domain level easy hard
relative problems domains irrespective level.
data presented Figures 24 25 show planners found domain-level
combinations easy hard discussed reference tables Figures 22 23.
information might contribute understanding planning approaches
likely suited kinds problems, although analysis would needed
pursue question.
tables organised follows. row individual planners,
indicating domain-level combinations found easy hard corresponding planner. Associated categorization combination easy hard
p-value indicating statistical significance finding. presented
findings significant 5% level. two-tailed test (we
priori knowledge help us determine whether problem would easy hard)
critical value easy end 0.025. hard end critical value 0.975. Figure 24
shows findings fully-automated planners. Figure 25 shows information
respect hand-coded planners.
6.3 Interpretation
results allow us reject null hypothesis cases, others.
able determine significant differences relative hardness domains determined
specific planners, evidence lack consistency judgements
different planners. example, domain/level combinations found
hard certain planners others.
tables Figures 22 23 allow us determine domains presented
interesting challenges planners participating competition. Although
difficult draw firm conclusions data really indicative, interesting
patterns emerge. example, level-specific data Figure 22 shows none
fully-automated planners found ZenoTravel problems, levels, significantly hard
comparison problems drawn domains level. Satellite
33

fiLong & Fox



LPG

MIPS

Sapa
Simplanner
Stella
VHPOP

Easy
Depots Numeric
Depots Strips
FreeCell Strips
Rovers Strips
Satellite HardNumeric
Satellite Strips
ZenoTravel Numeric
ZenoTravel Strips
Rovers Strips
Satellite SimpleTime
Satellite Strips
DriverLog HardNumeric
DriverLog SimpleTime
DriverLog Strips
DriverLog Time
FreeCell Strips
Satellite HardNumeric
ZenoTravel Numeric
ZenoTravel Strips
Satellite Time
Depots Strips
ZenoTravel Strips
Satellite Strips
ZenoTravel Strips
Rovers Strips
Satellite SimpleTime
Satellite Strips

0.015
0.012
0.017
0
0
0.0007
0.0026
0.0015
0.0007
0.019
0.0001
0.0046
0.0094
0.0088
0.0093
0
0
0.01
0.0021
0.0017
0.0003
0.013
0.016
0
0
0.0006
0.0004

Hard
Rovers Numeric
Settlers Numeric

1
1

Satellite Numeric
ZenoTravel Time

1
0.98

Depots Numeric
Rovers Numeric
Rovers Time
Satellite Complex
Satellite Numeric
Settlers Numeric

0.99
0.98
0.98
0.98
1
1

Depots Time
Rovers Strips
Depots Strips
FreeCell Strips
Depots SimpleTime
Depots Strips
FreeCell Strips
Rovers SimpleTime

Figure 24: Easy/hard boundaries fully-automated planners.

34

1
1
1
1
1
1
1
0.98

fiThe 3rd International Planning Competition

SHOP2

TALPlanner

TLPlan

Easy
Depots Numeric
Depots SimpleTime
Depots Strips
Depots Time
Depots HC SimpleTime
Depots HC Strips
Depots HC Time
DriverLog HardNumeric
DriverLog SimpleTime
DriverLog Strips
Satellite SimpleTime
Satellite Strips
Satellite HC SimpleTime
Satellite HC Strips
ZenoTravel Numeric
ZenoTravel SimpleTime
ZenoTravel Strips
ZenoTravel Time
ZenoTravel HC Numeric
ZenoTravel HC SimpleTime
ZenoTravel HC Strips
ZenoTravel HC Time
Depots SimpleTime
Depots Strips
Depots Time
Depots HC SimpleTime
Depots HC Strips
DriverLog Strips
Rovers Strips
Rovers HC SimpleTime
Rovers HC Strips
ZenoTravel SimpleTime
ZenoTravel Strips
ZenoTravel HC SimpleTime
ZenoTravel HC Strips
ZenoTravel HC Time
Depots Numeric
Depots SimpleTime
Depots Strips
Depots Time
Depots HC Numeric
Depots HC Time
DriverLog HardNumeric
DriverLog Numeric
DriverLog SimpleTime
DriverLog Strips
Rovers HC SimpleTime
Rovers HC Strips
Satellite SimpleTime
Satellite Strips
Satellite HC SimpleTime
ZenoTravel SimpleTime
ZenoTravel Strips
ZenoTravel Time
ZenoTravel HC SimpleTime
ZenoTravel HC Strips
ZenoTravel HC Time

0.0031
0.0057
0.0001
0.0088
0.0001
0
0.0006
0.015
0.015
0.019
0
0
0
0
0.0018
0.0003
0.0001
0.0043
0.0001
0
0
0.0001
0
0
0.013
0.0029
0
0
0.0026
0.0009
0
0
0
0
0
0.017
0.0009
0.01
0.0009
0.0003
0
0.0084
0.0051
0.0083
0.02
0.0009
0.0037
0.013
0
0
0.0001
0
0
0.0014
0
0
0

Hard
Rovers Numeric
Rovers Time

DriverLog HC SimpleTime
DriverLog HC Time
Rovers SimpleTime
Rovers Time
Satellite SimpleTime
Satellite Time
Satellite HC Time

Satellite HardNumeric
Satellite HC Complex
Satellite HC Numeric

1
1

1
1
0.99
1
0.98
1
1

1
1
1

Figure 25: Easy/hard boundaries hand-coded planners. Note: HC indicates larger
problems used hand-coded planners.

35

fiLong & Fox

strips problems significantly easy, comparison strips problems,
majority participating planners, hard them. hand
Satellite numeric problems found challenging relative numeric
problems. Figure 23 shows hand-coded planners found ZenoTravel problems easy
levels, comparison problems similar levels, remains true
large problem instances. Depots problems easy hand-coded planners.
consider level-independent picture right-hand halves Figures 22
23 observe ZenoTravel emerges significantly easy fully-automated
planners, across levels, comparison problems irrespective level.
pattern broken one full-automated planner (lpg) finding problems hard
time problem level. Satellite domain similarly easy fully-automated
planners, levels except numeric. noted number planners finding
strips problems easy level-independent comparisons surprisingly high.
interpretation problems population whole much harder,
performance strips problems pushed extremes performance
problems. hand-coded planners found Depots ZenoTravel problems
uniformly easy levels.
Considering fully-automated hand-coded planners, DriverLog,
Rovers Satellite domains present varied picture, suggesting problems
domains presented greatest challenges overall. hand-coded planners
found simpletime Rovers problems significantly hard relative simpletime
problems, one found problems amongst hardest solve
overall. Interestingly, perceived difficulty small Rovers problems persist
large problems.
interesting comparison made results analysis strips
domains work Hoffmann (2003b) analysing topologies strips adl
versions common planning benchmark domains. Hoffmann examines behaviour
h+ function, measuring relaxed distances states state spaces
problems, order determine whether function offers reliable guide navigate
state space search plans. According Hoffmanns analysis, strips
versions Depots, DriverLog Rovers local minima function
arbitrarily wide plateaus (sequences states equal values h+ ). features
make problem instances domains hard planners relying h+ (or approximations it) guide search. includes fully-automated planners
competition. However, interestingly, several fully-automated planners found
one three domains easy strips level (although cases
found hard). Hoffmann points out, potential hardness domain
mean collections problem instances domain hard.
observations seem suggest competition collections posed instances tended
towards easy end spectrum. unintentional demonstrates
difficult obtain good spread challenges, particularly generating problems automatically. Satellite ZenoTravel domains have, contrast, constant-bounded
plateaus therefore h+ function reliable guide navigating state space
domains. Interestingly, analysis fully-automated planners found
domains either easy neither easy hard strips level.
36

fiThe 3rd International Planning Competition

7. Scaling Issues
Section 6 addressed issue relative difficulty problems without considering question whether planners agree difficulty specific problems. results
section allow us conclude overall consensus
competition domains levels found hard, allow us determine
planners agreed disagreed particular domains levels. order look
relative scaling behaviour planners need identify extent agreement.
examine scaling behaviour necessary scale measures
performance way meaningful planners comparison. analysis
described section therefore seeks establish statistical evidence agreement.
order evaluate scaling behaviour first explore whether competing planners
agree makes problem, within particular domain level, hard. Although
might seem straightforward ensure problem set consists increasingly difficult
problems (for example, generating instances increasing size) fact straightforward achieve this. appears problem size difficulty strongly correlated,
whether size taken measure number objects, number relations even
number characters problem description. Although coarse relationship
observed large instances take time parse ground small instances
sometimes present difficult challenges large instances. indicates
factors size appear important determining whether planners solve
individual instances.
summary, hypotheses explored section are:
Null Hypothesis: planners differ judgements
individual problem instances hard within given domain/level combination.
Alternative Hypothesis: planners demonstrate significant agreement
relative difficulties problem instances within given domain/level combination.
section specifically concerned within-domain/level analysis
whether planners agree relative difficulty problem instances within given
domain/level combination.
7.1 Analytic Framework
discussed Section 6, use planners judges determine
difficult individual problems were. Given competing planners proceeded
first grounding problem instance searching problem space using
variation theme relaxed distance estimate, seems little reason believe
planners would strongly diverge. particular instance, family instances,
proved difficult one planner might expected collection would
challenging competitors. avoid distracted impact hand-coded
control rules separate judgements fully-automated planners
hand-coded planners. domain/level combination hypothesis planners
37

fiLong & Fox

Fully
Automated
Depots
DriverLog
ZenoTravel
Rovers
Satellite
FreeCell
Settlers

Strips

Numeric

F21,110 = 5.3
F19,100 = 17.1
F19,100 = 21.7
F19,80 = 4.54
F19,100 = 7.36
F19,100 = 6.21

F21,44 = 5.48
F19,40 = 17.4
F19,40 = 14
F18,38 = 9.47
F15,48 = 1.74

HardNumeric

SimpleTime

Time

F19,20 = 11.8

F21,66 = 1.77
F19,60 = 4.44
F19,60 = 9.4
F19,60 = 4.25
F19,60 = 3.6

HardNumeric

SimpleTime

Time

Complex

F21,44 = 4.54
F19,40 = 5.34
F19,40 = 5.54
F19,40 = 28.3
F19,40 = 5

F21,44 = 6.21
F19,40 = 6.52
F19,40 = 4.22
F19,40 = 18
F19,40 = 20.6

F19,20 = 51.3

F19,40 = 4.05

F20,63
F19,60
F17,36
F19,40
F19,60

= 2.14
= 4.63
= 12.1
= 6.92
= 4.19

Complex

F19,60 = 3.78

F5,6 = 1.6

Hand-Coded
(Small)
Depots
DriverLog
ZenoTravel
Rovers
Satellite
Hand-Coded
(Large)
Depots
DriverLog
ZenoTravel
Rovers
Satellite

Strips

Numeric

F21,44 = 2.49
F19,40 = 2.58
F19,40 = 2.93
F19,40 = 4.5
F19,40 = 7.25

F21,22 = 2.19
F19,20 = 3.73
F19,20 = 8.3
F19,20 = 36.5
F19,20 = 38.7

Strips

Numeric

F21,44
F19,40
F19,40
F19,40
F15,32

= 11.4
= 61.4
= 3.14
= 17.2
= 20.8

F21,22
F19,20
F19,20
F19,20
F15,16

= 3.76
= 57.3
= 1.47
= 29.9
= 33.5

F19,20 = 6.45

F19,20 = 9.4
HardNumeric

F19,20 = 66.4

SimpleTime
F21,44 = 13.8
F19,40 = 91.6
F19,40 = 3.54
F19,40 = 33
F15,32 = 43.7

Time
F21,44
F19,40
F19,40
F19,40
F15,32

= 10.8
= 80.5
= 3.37
= 49.4
= 88.5

Complex

F15,16 = 152

Figure 26: F-values multiple judgments rank correlation tests.

tend agree relative difficulties problems presented within domain
level.
explore extent agreement exists perform rank correlation tests
agreement multiple judgements (Kanji, 1999) (we refer test MRC).
experiment judges planners subjects problem instances.
perform distinct MRC domain/level combination, showing case
planners ranked instances domain level. therefore perform 25 MRCs
fully-automated planners (there 25 distinct domain/level pairs fullyautomated planners competed), 23 hand-coded planners small problems (the
hand-coded planners compete Freecell strips Settlers numeric domains)
22 hand-coded planners large problems (amongst
Satellite hardnumeric instances). results tests shown Figure 26.
test n planners rank k problem instances order time taken solve.
Unsolved problems create difficulties pushed top end ranking.
MRC determines whether independent rankings made n planners agree.
test statistic follows F-distribution (k 1, k(n 1)) degrees freedom determining
whether critical value exceeded.
7.2 Results Analysis
cells Figure 26 report F values obtained (and degrees freedom used).
almost cases critical value exceeded null hypothesis non-agreement
could rejected least 0.05 level. cases (those reported bold
38

fiThe 3rd International Planning Competition

font) critical value exceeded statistical evidence therefore found
agreement planners difficulty instances corresponding
domain level. interesting note problematic cases within
numeric level, fully-automated hand-coded planners. Furthermore, case
comes closest critical boundary (the small Depots numeric problems,
hand coded table, F-value 2.19) within numeric level.
7.3 Interpretation
results support rejection null hypothesis almost cases. therefore
adopt alternative hypothesis, observing many cases planners
agree relative difficulties problem instances within given domain/level combination.
competition observed talplanner disadvantage respect
hand-coded planners, terms comparative speed, running small
problems. probably java virtual machine start-up time becomes
significant relative actual solution time small instances. see effects startup time tables. Note that, domain/level combinations talplanner
competed (strips, simpletime time) see low level agreement amongst
hand-coded planners small problems (except case Rover domain).
talplanner disagrees planners ranking
actual problems, problems small enough variability
setup time throws noise ranking obscures true picture relative problem
difficulty. set large problems see anomaly removed
problems sufficiently challenging java startup time becomes insignificant
high level agreement ranking obtained. Interestingly, hand-coded planners
show consistently high level agreement ranking Rovers problems. fact
emerge fully-automated set may due larger number
judges fully-automated category.

8. Relative Scaling Behaviours
MRCs described Section 7 demonstrate planners agree, expected,
relative difficulty problem instances within domain/level combinations.
cases possible go explore domain level specific scaling behaviour
planners, go investigate section. cannot explore
scaling behaviour planners across domains because, discussed Section 6,
seem much across-the-board agreement concerning relative hardness
domains would unlikely see agreement multiple judgments across
domain boundaries.
ideal basis explore scaling behaviour would collection
problems canonical scaling difficulty compare performance
planners scaled progressively harder problems within collection. Unfortunately, many factors contribute making problems hard affect planners
uniformly. result, canonical measurement problem difficulty many domains. Instead, must determine relative difficulty problems using planners
39

fiLong & Fox

judges. means consider relative scaling behaviours
planners planners agree underlying ordering difficulty problems.
Thus, begin identifying appropriate sets problems given pair
planners agree relative hardness problems according analysis Section 7 proceed compare way planners pair scales
problems increase difficulty. first stage analysis considers order
two planners place problems within set, second stage examines
performance varies two planners progress problem
problem.
hypotheses explored section are:
Null Hypothesis: planners agree difficulty problems
given domain/level combination, exhibit scaling behaviour.
Alternative Hypothesis: planners agree difficulty
problems given domain/level combination, demonstrate different scaling behaviours, better scaling performance identified
data set.
section concerned question scaling behaviour within problem sets
specific domain/level combinations already determined agreement,
identified Section 7.
8.1 Analytic Framework
order test different scaling properties planners make pairwise comparisons
performance using domains planners agreed difficulty
problems. is, use domain comparison planners found hard,
found easy neither found hard easy.
rank problems order difficulty use results obtained bootstrapping experiment described Section 6. rankings level dependent, looked
scaling within four problem levels recorded results separately.
attempt combine results single overall conclusion scaling recognize different planners scale better problem levels others,
single planner therefore emerge scaling best overall.
compare two planners agreed difficulty least two domains.
gives us, case comparison made, data set 30 points.
planners agree least two domains conclude insufficient agreement constitutes problem difficulty
possible measure relative scaling behaviours meaningful way.
perform comparison two planners rank problems data set
order agreed difficulty rank differences performances
planners problems. explore whether ranking differences correlated ranking problems according difficulty. use ranks
cannot make assumptions shapes underlying problem distributions
functions truly describe performances planners compared,
results robust respect factors.
40

fiThe 3rd International Planning Competition


strips

LPG
MIPS
Sapa
VHPOP

LPG
numeric

0.36

N

J

strips
0.87
J

N
J

MIPS
numeric simple time
timeN
0.93
0.52
0.51
0.61

N

J
J

Sapa
time

N
0.58
J

VHPOP
strips simple
time
N
0.93
0.44 J 0.48

J
N

N

Figure 27: Table showing correlation values, fully-automated planners, problem
N
difficulty difference time performance, indicating scaling behaviour.
means one pairs planners produce data comparison
J
may drawn.
means insufficient agreement
planners difficulty domains ranking problems order
carry comparison.

Given two planners, p1 p2 , positive correlation rankings differences values p1 p2 problem difficulty ranking means
difference performance p1 p2 (that is, performance p1 minus performance
p2 ) increasing problems become difficult. curve p1 increasing
faster p2 scales better p1 . negative correlation means p1 scales better
p2 . zero (or near-zero) correlation means scaling behaviour two planners
insignificantly different. use Spearmans rank correlation test (see Appendix C)
identify critical value required confidence 0.05 level.
restrict attention planners solved problems overall two
categories. Thus, fully-automated planners compared ff, lpg, mips, vhpop
sapa. consider pairs hand coded planners. perform
cross-category tests evident raw data hand coded planners exhibit
better scaling behaviour fully-automated planners.
8.2 Results Analysis
table Figure 27 shows significant scaling differences found pairs
fully-automated planners levels. Figure 28 shows relative scaling
hand coded planners. sets tests, two planners could compared
levels competed, domains agreed either easy,
hard, neither easy hard. report results planner indexed row
one showing superior scaling behaviour. planners compete
N
tracks indicate symbol denoting incomparable. significant
difference scaling found indicate zero correlation. agreement
J
found support comparison use symbol
denoting disagreement. avoid
duplication data, place entries positive correlations cell corresponding
row planner favoured comparison omit corresponding negative
correlation cell row column planners reversed.
41

fiLong & Fox

TLPlan
strips time
TLPlan
SHOP2
TALPlanner

strips
0.77

0

0

0.86

SHOP2
numeric simple
time
0.93
0.85

N

0.46

time
0.83

TALPlanner
strips simple time
time
0
0.25
0

0.76

Figure 28: Table showing correlation values, hand-coded planners, problem
N
difficulty difference time performance, indicating scaling behaviour.
means one pairs planners produce data comparison
may drawn.

8.3 Interpretation
almost cases comparison could performed, significant difference
scaling behaviour found, supporting rejection null hypothesis.
used domains agreement relative
difficulty problems necessary restrict conclusions domaindependent. However, restricted collection data points disposal
must careful generalise picture. basis analyses
believe make tentative judgements planners scaling pairwise
comparisons within four competition levels.
fully-automated planners observed informally high degree consistency scaling behaviours particular planners across problem
levels competed. Although cannot draw overall conclusions data
set high level confidence observe exhibits best scaling behaviour
levels competed lpg exhibits best scaling behaviour temporal levels. remembered perform single-domain comparisons,
although might interesting point view exploring domain-specific scaling behaviour might produce interesting results. felt results would
interesting curiosities rather anything could support general conclusions.
hand coded planners show high degree cross-level consistency.
observed informally tlplan scales much better shop2 across levels, whereas
scales marginally better talplanner strips domains significantly
level. talplanner scales better shop2 levels
competed. seen shop2 scaling well relative competitors, although
remembered quality plans produced shop2 superior
domains.
Formally tables allow us draw specific conclusions relative scaling
behaviours specific pairs planners, within specific problem levels, 0.05 level.

9. Conclusions
3rd International Planning Competition focussed issue temporal planning
numeric resource handling. competition structured around two categories:
42

fiThe 3rd International Planning Competition

fully-automated hand-coded planning systems, four main problem levels: strips,
numeric, simpletime time. eight domains, one intended
hand coded planners (the um-translog domain), two solely
fully-automated planners (the FreeCell Settlers domains). Fourteen competitors took
part, eleven fully-automated track three hand coded track. domain
description language used pddl2.1, extension pddl standard designed
modelling temporal resource-intensive domains. pddl2.1 described another paper
issue (Fox & Long, 2003).
collected data set five half thousand data points distributed
domains levels. initial plotting points, terms relative time
quality performances planners different domains, revealed number
interesting patterns. suggest characteristics relative performances
competitors within competition domains. patterns presented discussed
AIPS conference final competition events co-located. However,
patterns, indicating relative performances across domains
showing perceived difficulty competition domain/level combinations, invisible data presented way. paper presents results detailed
statistical analyses competition data, aimed identifying deeper patterns.
paper explores three experimental themes. first theme aimed answering
question: planner buy? question concerned planner
emerges strongest overall performer, rather produced best results
particular domain/level combination, asked point view
speed quality criteria. answer performed comparisons, based
Wilcoxon rank-sum matched-pairs test, enabling construction partial orders
competing planners terms time quality performances four levels
competition. partial orders concluded that, potential user
interested good behaviour across broad range temporal numeric problems
lpg, amongst fully-automated planners, tlplan, amongst hand-coded
planners, best choices. course, specialised coverage required speed
solution paramount choices might made.
second theme considers dependence planner performance domain structure. interested exploring extent competing planners agree
domain/level combinations hard easy. analysis
performed addressing first issues statistical complement theoretical
analysis domain topologies carried Hoffmann (2003b). considered
competition domains four levels used competition, whilst Hoffmann considers
strips subset competition domains (he considers adl domains,
use competition). interesting note findings
broadly consistent conclusions.
third theme considered scaling behaviour competing planners. considered two related issues: extent competing planners agreed relative
difficulty problem instances within domain/level combinations extent
planners scaled similarly domain/level combinations agreement. intentions pursuing first issue provide objective scale
43

fiLong & Fox

would support efforts investigate relative scaling behaviours planners. found relatively little agreement perceived difficulty problems within
domain/level combinations able perform restricted comparison relative
scaling behaviour. However, consider results obtained make interesting
contribution deeper comparison planner performances available raw
domain-specific data.
many questions would interesting able answer.
Amongst questions extent hand-coding domain knowledge
really benefits planner amount (and value) effort involved encoding
knowledge. pressing question community one competition
series might well-suited try answer. However, order pursue future
competitions necessary carefully design controlled experiments aimed exploring precise hypotheses. restricted paper post hoc analysis
competition data, clearly restricted kinds questions
able ask answer. However, hope results methodologies
presented interest planning community help
encourage scientific evaluation performance field.

Acknowledgements
would thank competitors 3rd International Planning Competition
contributing time enthusiasm event report providing
data made paper possible. would thank Adele Howe
contributed invaluable advice, comments huge support made possible
paper go far could hoped. would thank David
Smith undertaking unenviable task coordinating editing special issue
Journal Artificial Intelligence Research immense patience, good
humour generous support. Finally, would thank Martha Pollack first
proposed idea publishing assembled work special issue Journal
Artifical Intelligence Research. whole-hearted commitment project
vital successful conclusion.

44

fiThe 3rd International Planning Competition

Appendix A. Problem Domains
A.1 First International Planning Competition
first competition used following domains:
Logistics transportation problem involving aircraft trucks, trucks constrained movement within cities aircraft constrained movement
(inter-city) airports. domain allows considerable parallelism.
Mystery transportation domain vehicles limited capacity consuming limited stocks fuel.
MPrime variant Mystery domain possible pipe fuel
locations order allow vehicles different movement options.
Grid problem single robot moves locations grid shaped
map. Locations may locked keys must collected gain access
locations. objectives problem instances involve transporting
keys particular locations.
Gripper simple domain, originally designed demonstrate limitations
Graphplan, collection identical balls must transported robot
two grippers one room adjacent room.
Movie simple domain intended explore use conditional effects. collection
snacks must assembled prior rewinding video watching movie.
Assembly complex adl domain challenging use quantified conditional
effects.
A.2 Second International Planning Competition
second competition introduced several new domains:
Blocks classic blocks-world problem, encoded without explicit reference
gripper. domain significant goal interaction.
Job-Schedule problem involving machining parts. problem exercises
adl features involving conditional quantified effects, although less complex Assembly domain.
Freecell classic solitaire card game widely available computer
game. encoding strips domain represents larger problem
previous benchmarks includes awkward addition encoded set integers.
Miconics Elevator domain inspired problem planning efficient call sequence elevator car travelling floors large building.
several variants, complex including numeric preconditions
well purely logical constraints. adl version offered complex preconditions
involving several different connectives strips version offered relatively simple
transportation problem.
45

fiLong & Fox

addition, Logistics domain reused provide calibration performance
comparison first competition.
A.3 Third International Planning Competition
A.3.1 Depots Domain
domain consists actions load unload trucks, using hoists available
fixed locations. loads crates stacked unstacked onto fixed set
pallets locations. trucks hold crates particular order,
act table Blocks domain, allowing crates reordered.
domain devised foremost intention testing strips planners.
second competition demonstrated Logistics domain longer serious
challenge, that, planners using hand-coded controls, Blocks domain
solved. fully-automated planners Blocks domain still represents challenge, although second competition showed planners solve quite large problems
(up twenty blocks) reasonably efficient plans within minutes. However, performance vary widely problems range prove unsolvable
planners. wanted see whether performance achieved
domains could successfully brought together one domain. interested
see fully-automated planners, interaction problems creates
additional family choice points addition appear transportation
block-tower-construction sub-problems. interested see handcoded planners rules sub-problems obviously well-understood,
obvious whether rules combined single collection without
problems interaction.
metric version domain adds weight attributes crates weight capacities trucks. addition, trucks consume fuel travels plans must
minimise fuel use. Fuel use constant dependent locations. Fuel consumed lifting crates, tradeoff considered crates must restacked
location. Either truck brought act table complex lifting
stacking performed using locally available pallets transfer space.
temporal versions allow concurrent activities trucks hoists (at
locations). full temporal variant makes time driving dependent truck
distance locations, makes time load unload crate dependent
weight crate power hoist. objective minimise
make-span (the overall duration plan).
A.3.2 DriverLog Domain
domain drivers walk locations trucks drive
locations. Walking requires traversal different paths used driving,
always one intermediate location footpath two road junctions.
trucks loaded unloaded packages (with without driver present)
objective transport packages locations, ending subset
packages, trucks drivers specified destinations.
46

fiThe 3rd International Planning Competition

domain produced explore power strips solutions transportation
problems transportation involves sub-problem acquiring driver. problem
one offers significant opportunity concurrency use drivers vehicles,
interested see temporal variants handled.
metric variant domain adds costs walking driving problem instances required planner optimise linear combination total walking
cost total driving cost.
full temporal variant makes time spent driving walking locations dependent path traversed, durations dependent actions
(as simple temporal version). variants plan quality depends
make-span.
additional variant, hard numeric variant, complicates cost driving
making dependent load carried: additional package added truck
increases fuel consumption rate truck current value, making consumption increase quadratic function load.
A.3.3 Zeno-Travel Domain
domain actions embark disembark passengers onto aircraft fly
two alternative speeds locations. strips variant rather uninteresting
two speeds offer meaningful alternatives. metric variant
planes consume fuel different rates according speed travel (two alternatives)
distances locations vary. Problem instances require plans minimise
linear combination time fuel use.
temporal versions closer original zeno problem. involve durations
different means travel different levels fuel consumption. contrast
original zeno problem fuel consumption described continuous function,
discrete step functions applied end points durative actions. fact
fuel aircraft cannot affected multiple different concurrent actions
value relevant satisfying precondition actions could begin
continuous consumption replenishment fuel means discrete model fuel use
sufficient, demanding less expressive power planners use model.
A.3.4 Satellite Domain
satellite domain developed following discussions David E. Smith Jeremy
Franks nasa Ames Research Center. intended first model satellite
observation scheduling problem. full problem involves using one satellites
make observations, collecting data downlinking data ground station.
satellites equipped different (possibly overlapping) collections instruments,
different characteristics terms appropriate calibration targets, data productions,
energy consumption requirements warming cooling down. satellites
pointed different targets slewing different attitudes.
constraints targets accessible different satellites due occlusion
slewing capabilities. Instruments generate data must stored satellite
subsequently downlinked window communication opportunity opens
47

fiLong & Fox

ground station. Communication windows fixed. Data takes time downlink
could impossible downlink entire satellite store given time frame, downlinks
must scheduled around storage capacity, production data observations
opportunities downlink data arise. real problem additional
difficulties management energy use solar power maintenance operational temperatures periods shadow. order make problem
accessible planners competition (given time scales encoding domain,
writing problem generator testing competing planners) several important features
real problem simplified. Perhaps important real problem
targets visible particular time-windows, although elimination
problem downlinking data significant simplification. Representing windows
opportunity possible pddl2.1, entirely straight-forward remains
area need development. Management power temperature
simplified away.
strips version problem involves deciding efficient covering
observations given satellite capabilities. interesting combinatorial problem
satellites assumed free operate concurrently (in Graphplan-style parallel
activity), otherwise problem offers interesting choice points. strips version
based earlier Satellite domain contributed Patrik Haslum.
metric version problem introduces data capacities satellites fuel
use slewing targets. plans expected minimize fuel use obtaining
data. problem combines constrained bin-packing problem (getting data
limited stores satellites, subject constraints certain satellites
equipped obtain certain data) kind route planning problem (finding fuel-efficient
paths targets considering combined costs fuel consumption
satellites).
temporal versions introduce duration make concurrency important. full
temporal problem includes different slew times different pairs targets.
problems involve minimising make-span times data acquisition. complex
version domain combines temporal metric features planners
required manage problem storing different sized data blocks limited capacity
satellite data stores.
variant Satellite domain, called hardnumeric version, represents
important departure traditional planning problems: logical goals describing
intended final state trivial (either empty simple final positions
satellites), metric plans declared evaluated quantity
data collected. problem interesting null (or nearly null) plan solve
instances, quality plans zero. produce good plan
necessary ensure satellites used collect data this, turn, requires
planner constructs reasonable data collection goals. hard problem
current planners particularly fully-automated planning systems. Nevertheless,
realistic demand many problems planner might required face:
uncommon specific final state less important effects actions
carried reaching it.
48

fiThe 3rd International Planning Competition

A.3.5 Rovers Domain
Rovers domain constructed simplified representation problem
confronts nasa Mars Exploration Rover missions launched 2003, Mars Science
Laboratory mission planned 2009 similar missions expected part
ESA AURORA project. strips version problem involves planning several
rovers, equipped different, possibly overlapping, sets equipment traverse
planet surface. rovers must travel waypoints gathering data transmitting
back lander. traversal complicated fact certain rovers restricted
travelling certain terrain types makes particular routes impassable
rovers. Data transmission constrained visibility lander
waypoints.
metric version domain introduces energy cost associated actions
action allowing rovers recharge, provided sun. problems sought
solutions minimised numbers recharges, use energy required
efficient possible.
metric temporal variant domain involves energy time management,
although instances require planners optimise total duration. demand implies
need efficient energy use, since recharging action consumes considerable
amount time and, model, requires recharging rover remain one place
period recharging. opportunity careful division labour
rovers makes temporal variants complex interesting problems.
A.3.6 Settlers Domain
domain exists metric problem. problem inspired multitude
computer games involve managing resources, accumulating raw resources slowly
combining advanced processing plants structures
achieve sophisticated objectives. problem proposed Patrik Haslum.
interesting difficulty problem presents problem involves constructing new objects resources. easily represented pddl2.1. fact,
way capture domain pddl2.1 name objects could constructed give attribute indicating whether actually
constructed. leads cumbersome encoding and, moreover, represents particular problem planners ground actions prior planning, since multitude
potential objects must considered process, leading huge collection actions.
Many actions uninterestingly different, since specific choice names
objects created solving instance clearly irrelevant, alternative
constructed considered planning process.
A.3.7 UM-Translog-2 Domain
UM-Translog-2 (Wu & Nau, 2002) domain used hand-coded planners
incomplete set results collected due time constraints conclusion
testing period. domain significant challenge size
seen useful benchmark problem fully-automated planners challenges
grounding searching domain many action schemas.
49

fiLong & Fox

Appendix B. Competitors
B.1 Fully Automated Planners
eleven competitors category, representing least four distinct planning paradigms (forward search, model-checking, local search partial order planning).
Fully-automated planners accept pddl2.1 specifications domain, initial state
goal compute solutions solely basis specifications. additional control
knowledge guidance supplied. Fully-automated planners therefore depend sophisticated search control heuristics efficient storage alternative search branches.
popular current approach search control make use variants relaxed plan
idea originally proposed McDermott (1996) subsequently exploited Bonet
Geffner (1997) Hoffmann (2000).
IxTeT (Laborie & Ghallab, 1995) entered fully-automated planner, retrospect
might better classified hand-coded planner. ability hand-code
domain representations might alleviated problems arose making
competition domains accessible IxTeT. IxTeT currently accept domains
problems pddl format, necessary translate competition domains
representation language. automatic translator pddl IxTeT
input language yet exists clear translation automated.
Furthermore, plan representation IxTeT general insisted upon
use competition advantage given need automate
plan validation process. fact, several plans produced IxTeT could validated.
combination difficulties made impossible offer real insights
performance IxTeT competition domains. Nevertheless, pleased
attempt made enter IxTeT: important competition cause
fracture members research community interested entering
long-established alternative planning technology cannot easily
reengineered meet assumptions underlying competition.
B.1.1
extremely successful influential planner since 2000 (Hoffmann & Nebel,
2000). based forward state space search using relaxed plans give heuristic guidance
choice possible steps space. Hoffmann extended original
system (Hoffmann, 2003a) include treatment metric domains relaxing metric
dimensions problem well logical dimensions.
B.1.2 IxTeT
IxTeT (Laborie & Ghallab, 1995) well known one first planners
reason time resource intensive domains. version participated parts
competition reimplementation original system described Ghallab
Laruelle (Ghallab & Laruelle, 1994). mentioned above, IxTeT experienced number
difficulties competition making difficult evaluate performance. However, seen
broader context planning research application IxTeT made many important
contributions development temporal resource-intensive planning approaches
50

fiThe 3rd International Planning Competition

and, powerful plan representation language, suited certain applications
simplified plan representation used competition inadequate.
B.1.3 LPG
lpg (Gerevini et al., 2003) based local-search strategy applied plan graphs (Blum
& Furst, 1995). approach generalised accommodate metric
temporal structure, making powerful flexible planner. use local search
allows planner configured trade-off time plan quality. Indeed, planner
exhibits time behaviour sense plans reported found and,
search allowed run longer, better quality plans might discovered.
B.1.4 MIPS
mips (Edelkamp, 2003) uses variety techniques, core model-checker
based ordered binary decision diagrams (obdds), used generate reachable
states. planner uses powerful technique compress state representations order
make obdds compact. Exhaustive search state space impractical
large problems mips uses heuristic evaluation function based relaxed plans order
restrict space explored states. mips tackles concurrency temporal planning
lifting partial orders totally ordered plans produced forward search.
mips extended manage metric quantities, using relaxation heuristic
predict behaviours metric quantities.
B.1.5 SAPA
sapa (Do & Kambhampati, 2003) forward search planner using relaxed temporal
plan heuristic (based use relaxed tgp-style (Smith & Weld, 1999) plan graph)
guide search. heuristic supplemented heuristic estimate resource
usage allowing planner handle metric quantities. Temporal structure managed
using delayed effects, that, durative action executed, end effects queued
event queue, pending application time advanced point
triggered. focus sapa development management metric
temporal structure. sapa attempt compete strips simpletime problems,
performed well complex problems.
B.1.6 SEMSYN
semsyn (Parker, 1999) Graphplan-based planner, extensions handle metric
adl features. general, Graphplan-based approaches have, exception lpg,
proven unequal challenge scaling meet latest sets benchmark problems.
suggests search strategy Graphplan must abandoned large problems
solved, underlying plan graph structure need source
scaling problems (in fact ff, vhpop, sapa lpg use plan graph structures
planning process).
51

fiLong & Fox

B.1.7 SIMPLANNER
simplanner (Onainda, Sapena, Sebastia, & Marzal, 2001) forward search planner
using relaxed plan heuristic. heuristic evaluation uses separate relaxed plans
top level goals, combining identify useful first action apply
current state. variant idea relaxed plans appears represent reinforcement
notion helpful actions developed ff, actions selected first
layer relaxed Graphplan-style plan favoured appropriate candidates next
step plan.
B.1.8 STELLA
stella (Sebastia, Onainda, & Marzal, 2001) uses forward heuristic search architecture,
modification plans built using landmarks (Porteous, Sebastia, &
Hoffmann, 2001). idea identify key states path plan planning
begins use stepping stones progress initial state
goal state.
B.1.9 TP4
tp4 (Haslum & Geffner, 2001) development hsp (Bonet et al., 1997) planning
approach, one first current generation rather successful heuristic
state-space search planners based relaxed plan heuristics. tp4 extends use
heuristic manage temporal plan structure. planner intended find optimal
plans (although, minor technical reasons, plans produces slightly suboptimal), using admissible heuristic, requires far greater search effort
planners constructing plans merely heuristically good.
B.1.10 TPSYS
tpsys (Garrido, Onainda, & Barber, 2001; Garrido, Fox, & Long, 2002) temporal
planner based Graphplan. technical differences tpsys tgp (Smith
& Weld, 1999), central use temporal plan graph similar, using graph
represent passage time, actions associated durations.
Graphplan-based approaches, search machinery appears scale badly.
B.1.11 VHPOP
Partial order planners suffered period unfashionable, supplanted Graphplan and, recently, relaxed-plan-based heuristic state-space search planners. vhpop (Younes & Simmons, 2003) represents interesting indication partial order
planning far defunct. particular, partial order framework offers powerful way handle temporal constraints. vhpop simple temporal network used
manage temporal constraints end points durative actions allows
planner successfully treat concurrency features temporal plan structure.
Within framework partial-order planner, vhpop makes use plan graph distance
estimates guide search.
52

fiThe 3rd International Planning Competition

B.2 Hand-coded Planners
three entrants category planners requiring hand-coded control knowledge. 2000 competition teams competing planners allowed
time reformulate domain descriptions include domain-specific control knowledge.
results show, control knowledge dramatically improve planner performance. However, difficult assess cost-effectiveness hand-coding control knowledge. Fahiem
Bacchus (2001) observed need quantify time effort required identify
encode useful control knowledge order better able judge trade-off
fully-automated hand-coded approaches. However, difficult measure
effort involved. principle possible bound time allowed domain
reformulation, differences team sizes experience team members
become important comparing achieved different participants.
third competition, it, explore factors, impossible
make judgements relative effectiveness solutions problems offered
hand-coded planning systems. remains important open issue
future competitions address.
B.2.1 SHOP2
shop2 (Nau, Au, Ilghami, Kuter, Murdoch, Wu, & Yaman, 2003) Hierarchical Task
Network (htn) planner. htn planners, shop2 allows tasks subtasks
partially ordered. Thus plans may interleave subtasks different tasks
expansion tasks. However, unlike htn planners, shop2 generates steps
plan order steps later executed therefore
maintain representation current state stage planning process.
makes much easier incorporate substantial expressive power htns used
shop2. example, might include axioms, mixed symbolic numeric computation,
even calls external programs.
B.2.2 TALPLANNER
successful hand-coded planners 2000, talplanner (Kvarnstrom &
Magnusson, 2003) uses temporal action logic language describing planning domains
uses control rules guide planner making intelligent choices constructing
plans forward search idea originally developed tlplan. rules act
prune away search branches predicted (by human encoding rules) lead
solutions. Using idea, possible arrive collection rules that,
examination given state, guide planner choose actions effectively
virtually search required all.
B.2.3 TLPLAN
tlplan (Bacchus & Kabanza, 2000) uses temporal logic language support
construction control rules guide plan search. tlplan preceded talplanner
use idea. tlplan adopts slightly different approach management tem53

fiLong & Fox

poral structure talplanner, capable handling metric quantities.
extensions tlplan allow handle time described Bacchus Ady (2001).

54

fiThe 3rd International Planning Competition

Appendix C. Statistical Techniques
analysis conducted paper makes use several standard statistical tests.
Wilcoxon matched-pairs rank-sum test, proportion test, matched-pairs t-test,
Spearmans rank correlation test rank correlation test agreement multiple
judgements. benefit readers unfamiliar tests, briefly
summarise here. appendix constructed using Gopal K. Kanjis 100 Statistical
Tests (1999).
C.1 Proportion Test
test known binomial distribution test. test used consider
proportion sample particular qualitative observation made.
example, proportion rolls die come 6. test examines far
expected proportion observed proportion, given assumed probability
observation. use paper, adopt null hypothesis two planners
win equal likelihood test proportion observed wins one planner
hypothesis. deviation observed proportion expected proportion
sufficiently high, null hypothesis rejected.
C.2 t-test
t-test parametric test: founded assumption underlying population samples drawn nearly normally distributed. reasonably
robust failures assumption, treated caution true distribution deviates normal. test considers means two samples tests
null hypothesis two samples drawn populations mean.
Variants available according known variance underlying populations. t-test conservative version Z-test, relies effect
confirmed Central Limit Theorem that, large samples, sampling ditribution
mean normal. t-test applied smaller samples, compensating
distortion distribution creates. paper, use variant
t-test observations drawn matched pairs: element pair test
result conducted close identical circumstances, different test subject (in
case, different planner).
n pairs observations, di difference pair mean
difference, variance, s, differences given by:
2

=

n
X
(di d)2
i=1

n1

x1 x2 means samples two populations,
statistic is:
x1 x2

t=
s/ n
n 1 degrees freedom.
55

fiLong & Fox

C.3 Wilcoxon Matched-Pairs Rank-Sum Test
use ranks releases statistical tests parametric assumptions underlying
distributions replacing actual observed values rank within ordered set
observed values. Wilcoxon matched-pairs test analogous matched-pairs t-test,
uses sum ranks values associated two test subjects.
pairs ordered according absolute values differences sum
ranks positive values compared sum ranks negative
values. two subjects exhibit particular pattern relative behaviours
positive negative values distributed roughly evenly ranks
thus rank-sums approximately equal. distortion rank-sums
indicates one subject consistently superior performance other.
test defined follows. Given collection n pairs data items, differences
pairs found ranked according absolute magnitude. sum
ranks formed negative positive differences separately. smaller
two rank sums. sufficiently large samples following value approximately
normally distributed:
n(n + 1)/4)
p
n(n + 1)(2n + 1)/24
C.4 Spearmans Rank Correlation Test
test correlation sequence pairs values. Using ranks eliminates
sensitivity correlation test function linking pairs values. particular,
standard correlation test used find linear relations test pairs, rank
correlation test restricted way.
Given n pairs observations, (xi , yi ), xi values assigned rank value and,
separately, yi values assigned rank. pair (xi , yi ), corresponding
difference, di xi yi ranks found. value R is:
R=

n
X

d2i

i=1

large samples test statistic then:
Z=

6R n(n2 1)

n(n + 1) n 1

approximately normally distributed.
C.5 Rank Correlation Test Agreement Multiple Judgements
tests significance correlation n series rank numbers, assigned
n judges K subjects. n judges give rank numbers K subjects compute:
S=

nK(K 2 1)
12
56

fiThe 3rd International Planning Competition

SD , sum squares differences subjects mean ranks overall
mean rank. Let:
D1 =

SD
D1
D2
, D2 = D1 , S12 =
, S22 =
n
K 1
K(n 1)

test statistic is:
F =

S12
S22

follows F distribution K 1, K(n 1) degrees freedom.

57

fiLong & Fox

References
Bacchus, F. (2001). AIPS00 planning competition. AI Magazine, 22(3), 4756.
Bacchus, F., & Ady, M. (2001). Planning resources concurrency: forward chaining approach. Proceedings IJCAI-01, pp. 417424.
Bacchus, F., & Kabanza, F. (2000). Using temporal logic express search control knowledge
planning. Artificial Intelligence, 116(1-2), 123191.
Blum, A., & Furst, M. (1995). Fast Planning Plan-graph Analysis. Proceedings
IJCAI-95.
Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism
planning. Proceedings AAAI-97, pp. 714719. AAAI/MIT Press.
Do, M. B., & Kambhampati, S. (2003). Sapa: scalable, multi-objective, heuristic, metric,
temporal planner. Journal Artificial Intelligence Research, issue.
Edelkamp, S. (2003). Taming numbers durations model-checking integrated
planning system. Journal Artificial Intelligence Research, issue.
Fox, M., & Long, D. (2003). pddl2.1: extension pddl expressing temporal
planning domains. Journal Artificial Intelligence Research, issue.
Garrido, A., Fox, M., & Long, D. (2002). Temporal planning PDDL2.1. Proceedings
ECAI-02.
Garrido, A., Onainda, E., & Barber, F. (2001). Time-optimal planning temporal problems. Proceedings ECP-01.
Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local search
temporal action graphs LPG. Journal Artificial Intelligence Research, issue.
Ghallab, M., & Laruelle, H. (1994). Representation control IxTeT, temporal
planner. Proceedings AIPS-94.
Haslum, P., & Geffner, H. (2001). Heuristic planning time resources. Proceedings
ECP-01, Toledo.
Hoffmann, J. (2003a). Metric-FF planning system: Translating ignoring delete lists
numerical state variables. Journal Artificial Intelligence Research, issue.
Hoffmann, J. (2003b). ignoring delete-lists works: local search topology planning
benchmarks. Tech. rep. 185, Institut fur Informatik, Albert-Ludwigs Universitat,
Freiburg.
Hoffmann, J., & Nebel, B. (2000). planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Howe, A., & Dahlman, E. (2002). critical assessment benchmark comparison planning. Journal Artificial Intelligence Research, 17, 133.
Kanji, G. (1999). 100 Statistical Tests. Sage Publications.
Kvarnstrom, J., & Magnusson, M. (2003). Talplanner 3rd international planning
competition: Extensions control rules. Journal Artificial Intelligence Research,
issue.
58

fiThe 3rd International Planning Competition

Laborie, P., & Ghallab, M. (1995). Planning sharable resource constraints. Proceedings IJCAI-95. Morgan Kaufmann.
Long, D. (2000). AIPS98 Planning Competition: Competitors perspective. AI Magazine, 21 (2).
McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine, 21 (2).
McDermott, D., & AIPS98 Planning Competition Committee (1998). PDDLthe planning domain definition language. Tech. rep., Available at: www.cs.yale.edu/homes/dvm.
McDermott, D. (1996). heuristic estimator means ends analysis planning.
Proceedings AIPS-96, pp. 142149. AAAI Press.
Nau, D., Au, T.-C., Ilghami, O., Kuter, U., Murdoch, J., Wu, D., & Yaman, F. (2003).
SHOP2: HTN planning environment. Journal Artificial Intelligence Research,
issue.
Onainda, E., Sapena, O., Sebastia, L., & Marzal, E. (2001). SimPlanner: executionmonitoring system replanning dynamic worlds. Proceedings EPIA-01.
Parker, E. (1999). Making graphplan goal-directed. Proceedings ECP-99, pp. 333346.
Penberthy, J., & Weld, D. (1994). Temporal planning continuous change. Proceedings
AAAI-94. AAAI/MIT Press.
Porteous, J., Sebastia, L., & Hoffmann, J. (2001). extraction, ordering, usage
landmarks planning. Proceedings ECP-01.
Sebastia, L., Onainda, E., & Marzal, E. (2001). SteLLa: optimal sequential parallel
planner. Proceedings EPIA-01.
Smith, D. E., & Weld, D. S. (1999). Temporal planning mutual exclusion reasoning.
Proceedings IJCAI-99, pp. 326337.
Wu, D., & Nau, D. (2002). um-translog-2: planning domain designed AIPS-02. Tech.
rep. CS-TR-4402, University Maryland.
Younes, H., & Simmons, R. (2003). vhpop: Versatile heuristic partial order planner. Journal
Artificial Intelligence Research, issue.

59


