Journal Artificial Intelligence Research 31 (2008) 431-472

Submitted 11/2007; published 3/2008

First Order Decision Diagrams Relational MDPs
Chenggang Wang
Saket Joshi
Roni Khardon

cwan@cs.tufts.edu
sjoshi01@cs.tufts.edu
roni@cs.tufts.edu

Department Computer Science, Tufts University
161 College Avenue, Medford, 02155, USA

Abstract
Markov decision processes capture sequential decision making uncertainty,
agent must choose actions optimize long term reward. paper studies efficient reasoning mechanisms Relational Markov Decision Processes (RMDP)
world states internal relational structure naturally described terms
objects relations among them. Two contributions presented. First, paper
develops First Order Decision Diagrams (FODD), new compact representation functions relational structures, together set operators combine FODDs,
novel reduction techniques keep representation small. Second, paper shows
FODDs used develop solutions RMDPs, reasoning performed
abstract level resulting optimal policy independent domain size (number
objects) instantiation. particular, variant value iteration algorithm developed using special operations FODDs, algorithm shown converge
optimal policy.

1. Introduction
Many real-world problems cast sequential decision making uncertainty.
Consider simple example logistics domain agent delivers boxes. agent
take three types actions: load box truck, unload box truck,
drive truck city. However effects actions may perfectly predictable.
example gripper may slippery load actions may succeed, navigation
module may reliable may end wrong location. uncertainty
compounds already complex problem planning course action achieve
goals maximize rewards.
Markov Decision Processes (MDP) become standard model sequential decision making uncertainty (Boutilier, Dean, & Hanks, 1999). models provide
general framework artificial intelligence (AI) planning, agent achieve
maintain well-defined goal. MDPs model agent interacting world.
agent fully observe state world takes actions change state.
that, agent tries optimize measure long term reward obtain
using actions.
classical representation algorithms MDPs (Puterman, 1994) require enumeration state space. complex situations specify state space
terms set propositional variables called state attributes. state attributes
together determine world state. Consider simple logistics problem
c
2008
AI Access Foundation. rights reserved.

fiWang, Joshi, & Khardon

one box one truck. state attributes truck Paris (TP), box
Paris (BP), box Boston (BB), etc. let state space represented n binary
state attributes total number states would 2n . problems, however,
domain dynamics resulting solutions simple structure described
compactly using state attributes, previous work known propositionally factored approach developed suite algorithms take advantage structure
avoid state enumeration. example, one use dynamic Bayesian networks, decision trees, algebraic decision diagrams concisely represent MDP model.
line work showed substantial speedup propositionally factored domains (Boutilier,
Dearden, & Goldszmidt, 1995; Boutilier, Dean, & Goldszmidt, 2000; Hoey, St-Aubin, Hu,
& Boutilier, 1999).
logistics example presented small. realistic problem
large number objects corresponding relations among them. Consider problem
four trucks, three boxes, goal box Paris,
matter box Paris. propositionally factored approach, need
one propositional variable every possible instantiation relations domain,
e.g., box 1 Paris, box 2 Paris, box 1 truck 1, box 2 truck 1, on,
action space expands way. goal becomes ground disjunction
different instances stating box 1 Paris, box 2 Paris, box 3 Paris, box 4
Paris. Thus get large MDP time lose structure implicit
relations potential benefits structure terms computation.
main motivation behind relational first order MDPs (RMDP). 1 first
order representation MDPs describe domain objects relations among them,
use quantification specifying objectives. logistics example, introduce three predicates capture relations among domain objects, i.e., Bin(Box, City),
in(T ruck, City), On(Box, ruck) obvious meaning. three parameterized actions, i.e., load(Box, ruck), unload(Box, ruck), drive(T ruck, City).
domain dynamics, reward, solutions described compactly abstractly using
relational notation. example, define goal using existential quantification,
i.e., b, Bin(b, P aris). Using goal one identify abstract policy, optimal
every possible instance domain. Intuitively 0 steps go,
agent rewarded box Paris. one step go
box Paris yet, agent take one action help achieve goal.
box (say b1 ) truck (say t1 ) truck Paris, agent execute
action unload(b1 , t1 ), may make Bin(b1 , P aris) true, thus goal achieved.
two steps go, box truck Paris, agent
take unload action twice (to increase probability successful unloading
box), box truck Paris, agent first take action
drive followed unload. preferred plan depend success probability
different actions. goal paper develop efficient solutions problems
using relational approach, performs general reasoning solving problems
propositionalize domain. result complexity algorithms
1. Sanner Boutilier (2005) make distinction first order MDPs utilize full power
first order logic describe problem relational MDPs less expressive. follow
calling language RMDP.

432

fiFirst Order Decision Diagrams Relational MDPs

change number domain objects changes. solutions obtained good
domain size (even infinite ones) simultaneously. abstraction
possible within propositional approach.
Several approaches solving RMDPs developed last years. Much
work devoted developing techniques approximate RMDP solutions using
different representation languages algorithms (Guestrin, Koller, Gearhart, & Kanodia,
2003a; Fern, Yoon, & Givan, 2003; Gretton & Thiebaux, 2004; Sanner & Boutilier, 2005,
2006). example, Dzeroski, De Raedt, Driessens (2001) Driessens, Ramon,
Gartner (2006) use reinforcement learning techniques relational representations. Fern,
Yoon, Givan (2006) Gretton Thiebaux (2004) use inductive learning methods
learn value map policy solutions simulations small instances. Sanner
Boutilier (2005, 2006) develop approach approximate value iteration need
propositionalize domain. represent value functions linear combination
first order basis functions obtain weights lifting propositional approximate
linear programming techniques (Schuurmans & Patrascu, 2001; Guestrin, Koller, Par, &
Venktaraman, 2003b) handle first order case.
work exact solutions symbolic dynamic programming
(SDP) (Boutilier, Reiter, & Price, 2001), relational Bellman algorithm (ReBel) (Kersting, Otterlo, & De Raedt, 2004), first order value iteration (FOVIA) (Gromann,
Holldobler, & Skvortsova, 2002; Hoolldobler, Karabaev, & Skvortsova, 2006).
working implementation SDP hard keep state formulas consistent
manageable size context situation calculus. Compared SDP, ReBel
FOVIA provide practical solutions. use restricted languages represent
RMDPs, reasoning formulas easier perform. paper develop
representation combines strong points approaches.
work inspired successful application Algebraic Decision Diagrams (ADD)
(Bryant, 1986; McMillan, 1993; Bahar, Frohm, Gaona, Hachtel, Macii, Pardo, & Somenzi,
1993) solving propositionally factored MDPs POMDPs (Hoey et al., 1999; St-Aubin,
Hoey, & Boutilier, 2000; Hansen & Feng, 2000; Feng & Hansen, 2002). intuition
behind idea ADD representation allows information sharing, e.g., sharing
value states belong abstract state, algorithms consider
many states together need resort state enumeration. sufficient
regularity model, ADDs compact, allowing problems represented
solved efficiently. provide generalization approach lifting ADDs
handle relational structure adapting MDP algorithms. main difficulty lifting
propositional solution, relational domains transition function specifies
set schemas conditional probabilities. propositional solution uses concrete
conditional probability calculate regression function. possible
schemas. One way around problem first ground domain problem hand
perform reasoning (see example Sanghai, Domingos, & Weld, 2005).
However allow solutions abstracting domains problems.
SDP, ReBel, FOVIA, constructions perform general reasoning.
First order decision trees even decision diagrams already considered
literature (Blockeel & De Raedt, 1998; Groote & Tveretina, 2003) several semantics
diagrams possible. Blockeel De Raedt (1998) lift propositional decision
433

fiWang, Joshi, & Khardon

trees handle relational structure context learning relational datasets.
Groote Tveretina (2003) provide notation first order Binary Decision Diagrams
(BDD) capture formulas Skolemized conjunctive normal form provide
theorem proving algorithm based representation. paper investigates
approaches identifies approach Groote Tveretina (2003) better suited
operations value iteration algorithm. Therefore adapt extend
approach handle RMDPs. particular, First Order Decision Diagrams (FODD)
defined modifying first order BDDs capture existential quantification well realvalued functions use aggregation different valuations diagram.
allows us capture MDP value functions using algebraic diagrams natural way.
provide additional reduction transformations algebraic diagrams help keep
size small, allow use background knowledge reductions. develop
appropriate representations algorithms showing value iteration performed
using FODDs. core algorithm introduce novel diagram-based algorithm
goal regression where, given diagram representing current value function,
node diagram replaced small diagram capturing truth value
action. offers modular efficient form regression accounts potential
effects action simultaneously. show version abstract value iteration
correct hence converges optimal value function policy.
summarize, contributions paper follows. paper identifies
multiple path semantics (extending Groote & Tveretina, 2003) useful representation
RMDPs contrasts single path semantics Blockeel De Raedt (1998).
paper develops FODDs algorithms manipulate general
context RMDPs. paper develops novel weak reduction operations first order
decision diagrams shows relevance solving relational MDPs. Finally paper
presents version relational value iteration algorithm using FODDs shows
correct thus converges optimal value function policy. relational
value iteration developed specified previous work (Boutilier et al., 2001),
knowledge first detailed proof correctness convergence algorithm.
section briefly summarized research background, motivation, approach. rest paper organized follows. Section 2 provides background
MDPs RMDPs. Section 3 introduces syntax semantics First Order Decision Diagrams (FODD), Section 4 develops reduction operators FODDs. Sections
5 6 present representation RMDPs using FODDs, relational value iteration
algorithm, proof correctness convergence. last two sections conclude
paper discussion results future work.

2. Relational Markov Decision Processes
assume familiarity standard notions MDPs value iteration (see example
Bellman, 1957; Puterman, 1994). following introduce notions.
introduce relational MDPs discuss previous work solving them.
Markov Decision Processes (MDPs) provide mathematical model sequential optimization problems stochastic actions. MDP characterized state space
S, action space A, state transition function P r(sj |si , a) denoting probability
434

fiFirst Order Decision Diagrams Relational MDPs

transition state sj given state si action a, immediate reward function r(s),
specifying immediate utility state s. solution MDP optimal
policy maximizes expected discounted total reward defined Bellman equation:
V (s) = maxaA [r(s) +

X

P r(s0 |s, a)V (s0 )]

s0

V represents optimal state-value function. value iteration algorithm (VI)
uses Bellman equation iteratively refine estimate value function:
Vn+1 (s) = maxaA [r(s) +

X

P r(s0 |s, a)Vn (s0 )]

(1)

s0

Vn (s) represents current estimate value function Vn+1 (s) next
estimate. initialize process V0 reward function, Vn captures optimal
value function n steps go. discussed algorithm
known converge optimal value function.
Boutilier et al. (2001) used situation calculus formalize first order MDPs
structured form value iteration algorithm. One useful restrictions introduced
work stochastic actions specified randomized choice among deterministic alternatives. example, action unload logistics example succeed
fail. Therefore two alternatives action: unloadS (unload success)
unloadF (unload failure). formulation algorithms support number action
alternatives. randomness domain captured random choice specifying
action alternative (unloadS unloadF ) gets executed agent attempts
action (unload). choice determined state-dependent probability distribution
characterizing dynamics world. way one separate regression
effects action alternatives, deterministic, probabilistic choice
action. considerably simplifies reasoning required since need perform
probabilistic goal regression directly. work RMDPs used assumption, use assumption well. Sanner Boutilier (2007) investigate model
going beyond assumption.
Thus relational MDPs specified set predicates domain, set
probabilistic actions domain, reward function. probabilistic action,
specify deterministic action alternatives effects, probabilistic choice
among alternatives. relational MDP captures family MDPs generated
choosing instantiation state space. Thus logistics example corresponds
possible instantiations 2 boxes 3 boxes on. get concrete
MDP choosing instantiation.2 Yet algorithms attempt solve entire
MDP family simultaneously.
Boutilier et al. (2001) introduce case notation represent probabilities rewards
compactly. expression = case[1 , t1 ; ; n , tn ], logical formula,
equivalent (1 (t = t1 )) (n (t = tn )). words, equals ti
2. One could define single MDP including possible instances time, e.g. include
states 2 boxes, states 3 boxes infinite number boxes. obviously
subsets states form separate MDPs disjoint. thus prefer view RMDP
family MDPs.

435

fiWang, Joshi, & Khardon

true. general, constrained steps VI algorithm require
disjoint partition state space. case, exactly one
true state. denotes abstract state whose member states
value probability reward. example, reward function logistics
domain, discussed illustrated right side Figure 1, captured
case[b, Bin(b, P aris), 10; b, Bin(b, P aris), 0]. following notation
operations function defined case expressions. operators defined
taking cross product partitions adding multiplying case values.
case[i , ti : n] case[j , vj : j m] = case[i j , ti + vj : n, j m]
case[i , ti : n] case[j , vj : j m] = case[i j , ti vj : n, j m].
iteration VI algorithm, value stochastic action A(~x) parameterized
free variables ~x determined following manner:
QA(~x) (s) = rCase(s) [ j (pCase(nj (~x), s) Regr(nj (~x), vCase(do(nj (~x), s))))] (2)
rCase(s) vCase(s) denote reward value functions case notation, n j (~x)
denotes possible outcomes action A(~x), pCase(nj (~x), s) choice probabilities nj (~x). Note replace sum possible next states s0 standard
value iteration (Equation 1) finite sum action alternatives j (reflected j
Equation 2), since different next states arise different action alternatives.
Regr, capturing goal regression, determines states one must action
order reach particular state action. Figure 1 illustrates regression
b, Bin(b, P aris) reward function R action alternative unloadS(b , ).
b, Bin(b, P aris) true action unloadS(b , ) true box
b truck truck Paris. Notice reward function R partitions
state space two regions abstract states, may include infinite
number complete world states (e.g., infinite number domain objects).
notice get another set abstract states regression step.
way first order regression ensures work abstract states never need
propositionalize domain.
regression, get parameterized Q-function accounts possible
instances action. need maximize action parameters Q-function
get maximum value could achieved using instance action.
illustrate step, consider logistics example two boxes b 1 b2 ,
b1 truck t1 , Paris (that is, On(b1 , t1 ) in(t1 , P aris)), b2
Boston (Bin(b2 , Boston)). action schema unload(b , ), instantiate b
b1 t1 respectively, help us achieve goal; instantiate b
b2 t1 respectively, effect. Therefore need perform
maximization action parameters get best instance action. Yet, must
perform maximization generically, without knowledge actual state. SDP,
done several steps. First, add existential quantifiers action parameters (which
leads non disjoint partitions). sort abstract states Q A(~x) value
decreasing order include negated conditions first n abstract states
formula (n + 1)th , ensuring mutual exclusion. Notice step leads complex
436

fiFirst Order Decision Diagrams Relational MDPs

R
b , Bin ( b , Paris )

b , Bin ( b , Paris )

10

b , Bin ( b , Paris )
0

( b *, *)
Tin ( *, Paris )

Figure 1: example illustrating regression action alternative unloadS(b , ).

description resulting state partitions SDP. process performed every
action separately. call step object maximization denote obj-max(Q A(~x) ).
Finally, get next value function maximize Q-functions different
actions. three steps provide one iteration VI algorithm repeats
update convergence.
solutions ReBel (Kersting et al., 2004) FOVIA (Gromann et al., 2002;
Hoolldobler et al., 2006) follow outline use simpler logical language representing RMDPs. abstract state ReBel captured using existentially quantified
conjunction. FOVIA (Gromann et al., 2002; Hoolldobler et al., 2006) complex
representation allowing conjunction must hold state set conjunctions
must violated. important feature ReBel use decision list (Rivest,
1987) style representations value functions policies. decision list gives us
implicit maximization operator since rules higher list evaluated first. result
object maximization step simple ReBel. state partition represented
implicitly negation rules it, explicitly conjunction rule.
hand, regression ReBel requires one enumerate possible matches
subset conjunctive goal (or state partition) action effects, reason
separately. step potentially improved.
following section introduce new representation First Order Decision Diagrams (FODD). FODDs allow sharing parts partitions, leading space time
saving. importantly value iteration algorithm based FODDs simple
regression simple object maximization.
437

fiWang, Joshi, & Khardon

3. First Order Decision Diagrams
decision diagram graphical representation functions propositional (Boolean)
variables. function represented labeled rooted directed acyclic graph
non-leaf node labeled propositional variable exactly two children.
outgoing edges marked values true false. Leaves labeled numerical
values. Given assignment truth values propositional variables, traverse
graph node follow outgoing edge corresponding truth value.
gives mapping assignment leaf diagram turn
value. leaves marked values {0, 1} interpret graph
representing Boolean function propositional variables. Equivalently, graph
seen representing logical expression satisfied 1 leaf
reached. case {0, 1} leaves known Binary Decision Diagrams (BDDs)
case numerical leaves (or general algebraic expressions) known Algebraic
Decision Diagrams (ADDs). Decision Diagrams particularly interesting impose
order propositional variables require node labels respect order
every path diagram; case known Ordered Decision Diagrams (ODD).
case every function unique canonical representation serves normal form
function. property means propositional theorem proving easy ODD
representations. example, formula contradictory fact evident
represent BDD, since normal form contradiction single leaf valued
0. property together efficient manipulation algorithms ODD representations
led successful applications, e.g., VLSI design verification (Bryant, 1992;
McMillan, 1993; Bahar et al., 1993) well MDPs (Hoey et al., 1999; St-Aubin et al.,
2000). following generalize representation relational problems.
3.1 Syntax First Order Decision Diagrams
various ways generalize ADDs capture relational structure. One could
use closed open formulas nodes, latter case must interpret
quantification variables. process developing ideas paper
considered several possibilities including explicit quantifiers lead
useful solutions. therefore focus following syntactic definition
explicit quantifiers.
representation, assume fixed set predicates constant symbols,
enumerable set variables. allow using equality pair terms
(constants variables).
Definition 1 First Order Decision Diagram
1. First Order Decision Diagram (FODD) labeled rooted directed acyclic graph,
non-leaf node exactly two children. outgoing edges marked
values true false.
2. non-leaf node labeled with: atom P (t1 , . . . , tn ) equality t1 = t2
ti variable constant.
3. Leaves labeled numerical values.
438

fiFirst Order Decision Diagrams Relational MDPs

p (x)
q (x)
1

h (y)

0 1

0

Figure 2: simple FODD.

Figure 2 shows FODD binary leaves. Left going edges represent true branches.
simplify diagrams paper draw multiple copies leaves 0 1 (and
occasionally values small sub-diagrams) represent node
FODD.
use following notation: node n, nt denotes true branch n, nf
false branch n; na outgoing edge n, true false.
edge e, source(e) node edge e issues from, target(e) node edge e
points to. Let e1 e2 two edges, e1 = sibling(e2 ) iff source(e1 ) = source(e2 ).
following slightly abuse notation let na mean either edge
sub-FODD edge points to. use na target(e1 ) interchangeably
n = source(e1 ) true false depending whether e1 lies
true false branch n.
3.2 Semantics First Order Decision Diagrams
use FODD represent function assigns values states relational MDP.
example, logistics domain, might want assign values different states
way box Paris, state assigned value 19;
box Paris box truck Paris raining, state
assigned value 6.3, on.3 question define semantics FODDs
order intended meaning.
semantics first order formulas given relative interpretations. interpretation domain elements, mapping constants domain elements and,
predicate, relation domain elements specifies predicate
true. MDP context, state captured interpretation. example
logistics domain, state includes objects boxes, trucks, cities, relations
among them, box 1 truck 1 (On(b1 , t1 )), box 2 Paris (Bin(b2 , P aris))
on. one way define meaning FODD B interpretation I.
following discuss two possibilities.
3.2.1 Semantics Based Single Path
semantics relational decision trees given Blockeel De Raedt (1998)
adapted FODDs. semantics define unique path followed traversing
3. result regression logistics domain cf. Figure 19(l).

439

fiWang, Joshi, & Khardon

B relative I. variables existential node evaluated relative path
leading it.
particular, reach node variables seen
path new. Consider node n label l(n) path leading
root, let C conjunction labels nodes exited true
branch path. node n evaluate ~x, C l(n), ~x includes
variables C l(n). formula satisfied follow true branch.
Otherwise follow false branch. process defines unique path root
leaf value.
example, evaluate diagram Figure 2 interpretation 1
domain {1, 2, 3} true atoms {p(1), q(2), h(3)} follow
true branch root since x, p(x) satisfied, follow false branch q(x)
since x, p(x) q(x) satisfied. Since leaf labeled 0 say B
satisfy I. attractive approach, partitions set interpretations
mutually exclusive sets used create abstract state partitions MDP
context. However, reasons discuss later, semantics leads various complications
value iteration algorithm, therefore used paper.
3.2.2 Semantics Based Multiple Paths
second alternative builds work Groote Tveretina (2003) defined semantics based multiple paths. Following work, define semantics first relative
variable valuation . Given FODD B variables ~x interpretation I, valuation
maps variable ~x domain element I. done, node predicate
evaluates either true false traverse single path leaf. value
leaf denoted MAPB (I, ).
Different valuations may give different values; recall use FODDs represent
function states, state must assigned single value. Therefore, next
define
MAPB (I) = aggregate {MAPB (I, )}
aggregation function. is, consider possible valuations ,
valuation calculate MAPB (I, ). aggregate values. special
case Groote Tveretina (2003) leaf labels {0, 1} variables universally
quantified; easily captured formulation using minimum aggregation
function. paper use maximum aggregation function. corresponds
existential quantification binary case (if valuation leading value 1,
value assigned 1) gives useful maximization value functions
general case. therefore define:
MAPB (I) = max{MAPB (I, )}.


Using definition B assigns every unique value v = MAPB (I) B defines function
interpretations real values. later refer function map B.
Consider evaluating diagram Figure 2 interpretation I1 given
true atoms {p(1), q(2), h(3)}. valuation x mapped 2
440

fiFirst Order Decision Diagrams Relational MDPs

mapped 3 denoted {x/2, y/3} leads leaf value 1 maximum 1. leaf
labels {0,1}, interpret diagram logical formula. MAP B (I) = 1,
example, say satisfies B MAPB (I) = 0 say falsifies
B.
define node formulas (NF) edge formulas (EF) recursively follows. node
n labeled l(n) incoming edges e1 , . . . , ek , node formula NF(n) = (i EF(ei )).
edge formula true outgoing edge n EF(nt ) = NF(n) l(n). edge formula
false outgoing edge n EF(nf ) = NF(n) l(n). formulas,
variables existentially quantified, capture conditions node edge
reached.
3.3 Basic Reduction FODDs
Groote Tveretina (2003) define several operators reduce diagram normal
form. total order node labels assumed. describe operators briefly
give main properties.
(R1) Neglect operator: children node p FODD lead node q
remove p link parents p q directly.
(R2) Join operator: two nodes p, q label point two
children join p q (remove q link qs parents p).
(R3) Merge operator: node child label parent point
directly grandchild.
(R4) Sort operator: node p parent q label ordering violated (l(p) >
l(q)) reorder nodes locally using two copies p q labels
nodes violate ordering.
Define FODD reduced none four operators applied.
following:
Theorem 1 (Groote & Tveretina, 2003)
(1) Let {Neglect, Join, Merge, Sort} operator O(B) result applying
FODD B, B, I, , MAPB (I, ) = MAPO(B) (I, ).
(2) B1 , B2 reduced satisfy , MAPB1 (I, ) = MAPB2 (I, ) identical.
Property (1) gives soundness, property (2) shows reducing FODD gives normal
form. However, holds maps identical every condition
stronger normal equivalence. normal form suffices Groote Tveretina
(2003) use provide theorem prover first order logic, strong
enough purposes. Figure 3 shows two pairs reduced FODDs (with respect R1R4) MAPB1 (I) = MAPB2 (I) , MAPB1 (I, ) 6= MAPB2 (I, ). case
although maps FODDs reduced form. Consider
first pair part (a) figure. interpretation p(a) false p(b)
true substitution {x/a, y/b} leads value 0 B1 B2 always evaluates
1. diagrams equivalent. interpretation, p(c) true object
441

fiWang, Joshi, & Khardon

B1

B2

p (x)

(a)

1

1

p (y)
0

1

p (x, y)
(b)

p (y, z)
1

p (x, y)

0

p (z, x)

0

1

0

0

Figure 3: Examples illustrating weakness normal form.

c MAPB1 (I) = 1 substitution {x/c}; p(c) false object c
MAPB1 (I) = 1 substitution {x/c, y/c}. Thus map always 1
B1 well. Section 4.2 show additional reduction operators
developed, B1 first pair reduced 1. Thus diagrams (a) form
reduction. However, reductions resolve second pair given part (b)
figure. Notice functions capture path two edges labeled p graph
(we change order two nodes rename variables) diagrams evaluate
1 interpretation path. Even though B1 B2 logically
equivalent, cannot reduced form using R1-R4 new operators.
identify unique minimal syntactic form one may consider possible renamings
variables sorted diagrams produce, expensive operation.
discussion normal form conjunctions uses operation given Garriga,
Khardon, De Raedt (2007).
3.4 Combining FODDs
Given two algebraic diagrams may need add corresponding functions, take
maximum use binary operation, op, values represented functions. adopt solution propositional case (Bryant, 1986) form
procedure Apply(B1 ,B2 ,op) B1 B2 algebraic diagrams. Let p q
roots B1 B2 respectively. procedure chooses new root label (the lower
among labels p, q) recursively combines corresponding sub-diagrams, according
relation two labels (, =, ). order make sure result
reduced propositional sense one use dynamic programming avoid generating
nodes either neglect join operators ((R1) (R2) above) would applicable.
Figure 4 illustrates process. example, assume predicate ordering
p1 p2 , parameter ordering x1 x2 . Non-leaf nodes annotated numbers
numerical leaves underlined identification execution trace. example,
442

fiFirst Order Decision Diagrams Relational MDPs

1
p1 (x1)
2
p2 (x1)
10



3
p2 (x2)
9

0

0

1+3
p1 (x1)
=

2+3
p2 (x1)

0+3

10+3
p2 (x2)
19

10

p2 (x2)
9

0

Figure 4: simple example adding two FODDs.

top level call adds functions corresponding nodes 1 3. Since p1 (x1 )
smaller label picked label root result. must add
left right child node 1 node 3. calls performed recursively. easy
see size result may product sizes input diagrams. However,
much pruning occur shared variables pruning made possible weak
reductions presented later.
Since interpretation fixed valuation FODD propositional,
following lemma. later refer property correctness Apply.
Lemma 1 Let C = Apply(A, B, op), , MAPA (I, ) op MAPB (I, ) =
MAPC (I, ).
Proof: First introduce terminology. Let #nodes(X) refer set nodes
FODD X. Let root nodes B Aroot Broot respectively. Let
FODDs rooted Aroott , Arootf , Broott , Brootf , Croott , Crootf Al , Ar , B l , B r ,
C l C r respectively.
proof induction n = |#nodes(A)| + |#nodes(B)|. lemma true
n = 2, case Aroot Broot single leaves operation
operation two real numbers. inductive step need
consider two cases.
Case 1: Aroot = Broot . Since root nodes equal, valuation reaches Al ,
reach B l reaches Ar , reach B r . Also,
definition Apply, case C l = Apply(Al , B l , op) C r = Apply(Ar , B r , op). Therefore statement lemma true MAPAl (I, ) op MAPB l (I, ) = MAPC l (I, )
MAPAr (I, ) op MAPB r (I, ) = MAPC r (I, ) I. Now, since |#nodes(Al ) +
#nodes(B l )| < n |#nodes(Ar ) + #nodes(B r )| < n, guaranteed induction
hypothesis.
Case 2: Aroot 6= Broot . Without loss generality let us assume Aroot Broot .
definition Apply, C l = Apply(Al , B, op) C r = Apply(Ar , B, op). Therefore
statement lemma true MAPAl (I, ) op MAPB (I, ) = MAPC l (I, )
MAPAr (I, ) op MAPB (I, ) = MAPC r (I, ) I. guaranteed
induction hypothesis.
2
443

fiWang, Joshi, & Khardon

3.5 Order Labels
syntax FODDs allows two types objects: constants variables.
argument predicate constant variable. assume complete ordering
predicates, constants, variables. ordering two labels given
following rules.
1. P (x1 , ..., xn ) P 0 (x01 , ..., x0m ) P P 0
2. P (x1 , ..., xn ) P (x01 , ..., x0n ) exists xj = x0j j < i,
type(xi ) type(x0i ) (where type constant variable) type(xi ) = type(x0i )
xi x0i .
predicate order set arbitrarily appears useful assign equality
predicate first predicate ordering equalities top
diagrams. reductions often encounter situations one side equality
completely removed leading substantial space savings. may useful
order argument types constant variables. ordering may helpful
reductions. Intuitively, variable appearing lower diagram bound
value constant appears it. heuristic guidelines best
ordering may well problem dependent. later introduce forms arguments:
predicate parameters action parameters. ordering discussed Section 6.

4. Additional Reduction Operators
context, especially algebraic FODDs, may want reduce diagrams further.
distinguish strong reductions preserve MAPB (I, ) weak reductions
preserve MAPB (I). Theorem 1 shows R1-R4 given strong reductions. details relational VI algorithm directly depend reductions
used. Readers interested RMDP details skip Section 5 read
independently (except reductions illustrated examples).
reduction operators incorporate existing knowledge relationships
predicates domain. denote background knowledge B. example
Blocks World may know block block clear:
x, y, [on(x, y) clear(y)].
following define conditions reduction operators, two types
conditions: reachability condition value condition. name reachability
conditions starting P (for Path Condition) reduction operator number.
name conditions values starting V reduction operator number.
4.1 (R5) Strong Reduction Implied Branches
Consider node n whenever n reached true branch followed.
case remove n connect parents directly true branch. first
present condition, followed lemma regarding operator.
(P5) : B |= ~x, [NF(n) l(n)] ~x variables EF(nt ).
444

fiFirst Order Decision Diagrams Relational MDPs

Let R5(n) denote operator removes node n connects parents directly
true branch. Notice generalization R3. easy see
following lemma true:
Lemma 2 Let B FODD, n node condition P5 holds, B 0 result
R5(n). interpretation valuation MAP B (I, ) =
MAPB 0 (I, ).
similar reduction formulated false branch, i.e., B |= ~x, [NF(n)
l(n)] whenever node n reached false branch followed. case
remove n connect parents directly false branch.
Implied branches may simply result equalities along path. example (x =
y) p(x) p(y) may prune p(y) (x = y) p(x) known true. Implied
branches may result background knowledge. example Blocks World
on(x, y) guaranteed true reach node labeled clear(y)
remove clear(y) connect parent clear(y)f .
4.2 (R7) Weak Reduction Removing Dominated Edges
Consider two edges e1 e2 FODD whose formulas satisfy follow
e2 using valuation follow e1 using possibly different valuation.
e1 gives better value e2 intuitively e2 never determines value diagram
therefore redundant. formalize reduction operator R7. 4
Let p = source(e1 ), q = source(e2 ), e1 = pa , e2 = qb , b true
false. first present conditions operator follow
definition operator.
(P7.1) : B |= [~x, EF(e2 )] [~y , EF(e1 )] ~x variables EF(e2 ) ~y
variables EF(e1 ).
(P7.2) : B |= ~u, [[w,
~ EF(e2 )] [~v , EF(e1 )]] ~u variables appear
target(e1 ) target(e2 ), ~v variables appear EF(e1 ) ~u,
w
~ variables appear EF(e2 ) ~u. condition requires
every valuation 1 reaches e2 valuation 2 reaches e1 1
2 agree variables appear target(e1 ) target(e2 ).
(P7.3) : B |= ~r, [[~s, EF(e2 )] [~t, EF(e1 )]] ~r variables appear
target(e1 ) target(sibling(e2 )), ~t variables appear EF(e1 ) ~r,
~s variables appear EF(e2 ) ~r. condition requires
every valuation 1 reaches e2 valuation 2 reaches e1 1
2 agree variables appear target(e1 ) target(sibling(e2 )).
(V7.1) : min(target(e1 )) max(target(e2 )) min(target(e1 )) minimum leaf
value target(e1 ), max(target(e2 )) maximum leaf value target(e2 ). case
regardless valuation know better follow e1 e2 .
(V7.2) : min(target(e1 )) max(target(sibling(e2 ))).
(V7.3) : leaves = target(e1 ) target(e2 ) non-negative values, denoted
0. case fixed valuation better follow e1 instead e2 .
4. use R7 skip notation R6 consistency earlier versions paper. See
discussion Section 4.2.1.

445

fiWang, Joshi, & Khardon

(V7.4) : leaves G = target(e1 ) target(sibling(e2 )) non-negative values.
define operators R7-replace(b, e1 , e2 ) replacing target(e2 ) constant b
0 min(target(e1 )) (we may write R7-replace(e1 , e2 ) b = 0),
R7-drop(e1 , e2 ) dropping node q = source(e2 ) connecting parents
target(sibling(e2 )).
need one safety condition guarantee reduction correct:
(S1) : NF(source(e1 )) sub-FODD target(e1 ) remain
R7-replace R7-drop. condition says must harm value promised
target(e1 ). words, must guarantee p = source(e1 ) reachable
sub-FODD target(e1 ) modified replacing branch 0.
condition violated q sub-FODD pa , p sub-FODD qb .
holds cases, p q unrelated (one descendant
other), q sub-FODD pa , p sub-FODD qb , a, b
negations a, b.
Lemma 3 Let B FODD, e1 e2 edges conditions P7.1, V7.1, S1
hold, B 0 result R7-replace(b, e1 , e2 ), 0 b min(target(e1 )),
interpretation MAPB (I) = MAPB 0 (I).
Proof: Consider valuation 1 reaches target(e2 ). according P7.1,
another valuation reaching target(e1 ) V7.1 gives higher value. Therefore, MAPB (I) never determined target(e2 ) replace target(e2 )
constant 0 min(target(e1 )) without changing map.
2
Lemma 4 Let B FODD, e1 e2 edges conditions P7.2, V7.3, S1
hold, B 0 result R7-replace(b, e1 , e2 ), 0 b min(target(e1 )),
interpretation MAPB (I) = MAPB 0 (I).
Proof: Consider valuation 1 reaches target(e2 ). P7.2 another
valuation 2 reaching target(e1 ) 1 2 agree variables appear
target(e1 ) target(e2 ). Therefore, V7.3 achieves higher value (otherwise,
must branch = target(e1 ) target(e2 ) negative value). Therefore according
maximum aggregation value MAPB (I) never determined target(e2 ),
replace constant described above.
2
Note conditions previous two lemmas comparable since P7.2
P7.1 V7.1 V7.3. Intuitively relax conditions values, need
strengthen conditions reachability. subtraction operation = target(e 1 )
target(e2 ) propositional, test V7.3 implicitly assumes common variables operands P7.1 check this. Figure 5 illustrates
reachability condition P7.1 together V7.3, i.e., combining weaker portions conditions Lemma 3 Lemma 4, cannot guarantee replace
branch constant. Consider interpretation domain {1, 2, 3, 4} relations {h(1, 2), q(3, 4), p(2)}. addition assume domain knowledge B = [x, y, h(x, y)
z, w, q(z, w)]. P7.1 V7.3 hold e1 = [q(x, y)]t e2 = [h(z, y)t ].
MAPB1 (I) = 3 MAPB2 (I) = 0. therefore possible replace h(z, y)t 0.
446

fiFirst Order Decision Diagrams Relational MDPs

q(x,y)
p(y)

q(x,y)

h(z,y)
0 p(y) 0

5

3

3
B1

0

p(y)
5

0

0
B2

Figure 5: example illustrating subtraction condition R7.

10

B1

B2

p(x)

p(x)

q(y)
7

10

p(y)

20

h(y)

9 20

h(y)
0

0

Figure 6: example illustrating condition removing node R7.

Sometimes drop node q completely R7-drop. Intuitively,
remove node, must guarantee gain extra value. conditions
R7-replace guarantee lose value. remove node
q, valuation supposed reach e2 may reach better value e2 sibling.
would change map, illustrated Figure 6. Notice conditions P7.1
V7.1 hold e1 = [p(x)]t e2 = [p(y)]t replace [p(y)]t constant.
Consider interpretation domain {1, 2} relations {q(1), p(2), h(2)}.
MAPB1 (I) = 10 via valuation {x/2} MAPB2 (I) = 20 via valuation {x/1, y/2}. Thus
removing p(y) correct.
Therefore need additional condition guarantee gain extra value
node dropping. condition stated as: valuation 1 reaches e2
thus redirected reach value v1 sibling(e2 ) q removed,
valuation 2 reaches leaf value v2 v1 . However, condition complex
test practice. following identify two stronger conditions.
Lemma 5 Let B FODD, e1 e2 edges condition V7.2 hold addition
conditions replacing target(e2 ) constant, B 0 result R7-drop(e1 , e2 ),
interpretation MAPB (I) = MAPB 0 (I).
Proof: Consider valuation reaching target(e2 ). true value dominated
another valuation reaching target(e1 ). remove q = source(e2 ) valuation
reach target(sibling(e2 )) V7.2 value produced smaller value
target(e1 ). map preserved.
2
447

fiWang, Joshi, & Khardon

Lemma 6 Let B FODD, e1 e2 edges P7.3 V7.4 hold addition
conditions replacing target(e2 ) constant, B 0 result R7-drop(e1 , e2 ),
interpretation MAPB (I) = MAPB 0 (I).
Proof: Consider valuation 1 reaching target(e2 ). value dominated
another valuation reaching target(e1 ). remove q = source(e2 ) valuation
reach target(sibling(e2 )) conditions P7.3 V7.4, valuation 2
reach leaf greater value target(e1 )(otherwise branch G leading
negative value). maximum aggregation map changed.
2
summarize P7.1 V7.1 S1 hold P7.2 V7.3 S1 hold
replace target(e2 ) constant. replace V7.2 P7.3 V7.4 hold
drop q = source(e2 ) completely.
following provide detailed analysis applicability variants R7.
4.2.1 R6: Special Case R7
special case R7 p = q, i.e., e1 e2 siblings. context R7
considered focus single node n instead two edges. Assuming e 1 = nt
e2 = nf , rewrite conditions R7 follows.
(P7.1) : B |= [~x, NF(n)] [~x, ~y , EF(nt )]. condition requires n reachable
nt reachable.
(P7.2) : B |= ~r, [~v , NF(n)] [~v , w,
~ EF(nt )] ~r variables appear
nt nf , ~v variables appear NF(n) ~r, w
~ variables
l(n) ~r ~v .
(P7.3) : B |= ~u, [~v , NF(n)] [~v , w,
~ EF(nt )] ~u variables appear
nt (since sibling(e2 ) = e1 ), ~v variables appear NF(n) ~u, w
~
variables l(n) ~u ~v .
(V7.1) : min(nt ) max(nf ).
(V7.2) : nt constant.
(V7.3) : leaves diagram = nt nf non-negative values.
Conditions S1 V7.4 always true. previously analyzed special case
separate reduction operator named R6 (Wang, Joshi, & Khardon, 2007).
special case, may still useful check separately applying generalized
case R7, provides large reductions seems occur frequently example domains.
important special case R6 occurs l(n) equality t1 =
variable occur FODD node n. case, condition P7.1
holds since choose value y. enforce equality subdiagram nt . Therefore V7.1 holds remove node n connecting parents
nt substituting t1 diagram nt . (Note may need make copies
nodes this.) Section 4.4 introduce elaborate reduction handle
equalities taking maximum left right children.
4.2.2 Application Order
cases several instances R7 applicable. turns order
apply important. following, first example shows order affects
448

fiFirst Order Decision Diagrams Relational MDPs

p(x1,y1)
q(x3)

p(x1,y1)
q(x3)
10

p(x2,y2)

q(x2)
6

0 5
(a)

p(x1,y1)

10

0

q(x2)
6

q(x2) 0

q(x3)
10

0

(b)

0

q(x3)

p(x2,y2)
0 q(x2)
5
(d)

(c)

p(x1,y1)

p(x1,y1)
10

0

0

0

q(x3)
10

p(x2,y2)
0

0

0

(e)

Figure 7: example illustrating effect application order R7.

number steps needed reduce diagram. second example shows
order affects final result.
Consider FODD Figure 7(a). R7 applicable edges e1 = [p(x1 , y1 )]t
e2 = [p(x2 , y2 )]t , e01 = [q(x3 )]t e02 = [q(x2 )]t . reduce top
manner, i.e., first apply R7 pair [p(x1 , y1 )]t [p(x2 , y2 )]t , get FODD
Figure 7(b), apply R7 [q(x3 )]t [q(x2 )]t , get
FODD Figure 7(c). However, apply R7 first [q(x3 )]t [q(x2 )]t thus getting
Figure 7(d), R7 cannot applied [p(x1 , y1 )]t [p(x2 , y2 )]t [p(x1 , y1 )]t
[p(x2 , y2 )]t negative leaves. case, diagram still reduced.
reduce comparing [q(x3 )]t [q(x2 )]t right part FODD. first
remove q(x2 ) get FODD shown Figure 7(e), use neglect operator
remove p(x2 , y2 ). see example applying one instance R7 may render
instances applicable may introduce possibilities reductions general
must apply reductions sequentially. Wang (2007) develops conditions
several instances R7 applied simultaneously.
One might hope repeated application R7 lead unique reduced result
true. fact, final result depends choice operators order
application. Consider Figure 8(a). R7 applicable edges e1 = [p(x)]t e2 = [p(y)]t ,
e01 = [q(x)]t e02 = [q(y)]t . reduce top manner, i.e., first apply
R7 pair [p(x)]t [p(y)]t , get FODD Figure 8(b), cannot
reduced using existing reduction operators (including operator R8 introduced below).
However, apply R7 first [q(x)]t [q(y)]t get Figure 8(c).
apply R7 e1 = [p(x)]t e2 = [p(y)]t get final result Figure 8(d),
clearly compact Figure 8(b). interesting first example seems
449

fiWang, Joshi, & Khardon

p(x)
10

p(x)
10

p(y)

10 q(x)
10

10 q(y)
1

q(y)
1

0

0

(a)

(b)

p(x)
10

q(x)

p(x)
10 q(x)

p(y)

10 0

10 q(x)
10 0

(d)

(c)

Figure 8: example illustrating final result R7 reductions order dependent.
suggest applying R7 top manner (since takes fewer steps), second
seems suggest opposite (since final result compact). research
needed develop useful heuristics guide choice reductions application
order general develop complete set reductions.
Note could consider generalizing R7. Figure 8(b), reach [q(y)]
clearly reach [p(x)]t [q(x)]t . Since [p(x)]t [q(x)]t give better values, safely replace [q(y)]t 0, thus obtaining final result Figure 8(d). theory generalize P7.1 B |= [~x, EF(e2 )] [y~1 , EF(e11 )] [y~n , EF(e1n )]
~x variables EF(e2 ) y~i variables EF(e1i ) 1 n, generalize
corresponding value condition V7.1 [1, n], min(target(e1i )) max(target(e2 )).
generalize reachability value conditions similarly. However resulting
conditions expensive test practice.
4.2.3 Relaxation Reachability Conditions
conditions P7.2 P7.3 sufficient, necessary guarantee correct reductions. Sometimes valuations need agree smaller set variables
intersection variables. see this, consider example shown Figure 9,
B > 0 intersection {x, y, z}. However, guarantee B > 0 need
agree either {x, y} {x, z}. Intuitively agree variable x avoid
situation two paths p(x, y) q(x) p(x, y) q(x) h(z) co-exist. order
prevent co-existence two paths p(x, y) h(z) p(x, y) q(x) h(z), either
z well. change example little bit replace
450

fiFirst Order Decision Diagrams Relational MDPs

h(z) h(z, v), two minimal sets variables different size, one {x, y},
{x, z, v}. result cannot identify minimum set variables
subtraction must either choose intersection heuristically identify minimal set,
example, using greedy procedure.



B

p(x, y)

p(x, y)

q(x)
3

h(z)
2 3

q(x)
2

1 2

h(z)
3

h(z)
1

1

Figure 9: example illustrating minimal set variables subtraction
unique.
4.3 (R8) Weak Reduction Unification
Consider FODD B. Let ~v denote variables, let ~x ~y disjoint subsets ~v ,
cardinality. define operator R8(B, ~x, ~y ) replacing variables
~x corresponding variables ~y . denote resulting FODD B{~x/~y }
result variables ~v \~x. following condition correctness R8:
(V8) : leaves B{~x/~y } B non negative.
Lemma 7 Let B FODD, B 0 result R8(B, ~x, ~y ) V8 holds,
interpretation MAPB (I) = MAPB 0 (I).
Proof: Consider valuation 1 ~v B. V8, B{~x/~y } gives better value
valuation. Therefore lose value operator. gain
extra value. Consider valuation 2 variables B 0 reaching leaf node value
v, construct valuation 3 ~v B variables ~x taking corresponding
value ~y , reach leaf node B value. Therefore map
changed unification.
2
Figure 10 illustrates cases R8 applicable R7 not. apply
R8 {x1 /x2 } get FODD shown Figure 10(b). Since (b) (a) 0, (b) becomes
result reduction. Note unify way, i.e.,{x2 /x1 }, get
Figure 10(c), isomorphic Figure 10(b), cannot reduce original FODD
result, (c) (a) 6 0. phenomenon happens since subtraction operation
(implemented Apply) used reductions propositional therefore sensitive
variable names.
4.4 (R9) Equality Reduction
Consider FODD B equality node n labeled = x. Sometimes drop n
connect parents sub-FODD result taking maximum left
451

fiWang, Joshi, & Khardon

p(x2)
p(x1)
p(x2)

0

x1 / x2

q(x2)
10

q(x2) 0
10
(a)

0

0

0
(b)

x2/ x1

p(x1)
q(x1)
10

0

0
(c)

Figure 10: example illustrating R8.

right children n. reduction applicable B satisfy following
condition.
(E9.1) : equality node n labeled = x least one x variable
appears neither nf node formula n. simplify description
reduction procedure below, assume x variable.
Additionally make following assumption domain.
(D9.1) : domain contains one object.
assumption guarantees valuations reaching right child equality
nodes exist. fact needed proving correctness Equality reduction operator.
First describe reduction procedure R9(n). Let Bn denote FODD rooted
node n FODD B. extract copy Bnt (and name Bnt -copy), copy
Bnf (Bnf -copy) B. Bnt -copy, rename variable x produce diagram
Bn0 -copy. Let Bn0 = Apply(Bn0 -copy, Bnf -copy, max). Finally drop node n B
connect parents root Bn0 obtain final result B 0 . example shown
Figure 11.
Informally, extracting parts FODD rooted node n, one x =
(and renaming x part) one x 6= t. condition E9.1
assumption D9.1 guarantee regardless value t, valuations reaching
parts. Since definition MAP, maximize valuations, case
maximize diagram structure itself. calculating function
maximum two functions corresponding two children n (using
Apply) replacing old sub-diagram rooted node n new combined diagram.
Theorem 9 proves affect map B.
One concern implementation simply replace old sub-diagram
new sub-diagram, may result diagram strong reductions applicable.
problem semantically, avoid need strong reductions
using Apply implicitly performs strong reductions R1(neglect) R2(join) follows.
452

fiFirst Order Decision Diagrams Relational MDPs

Let Ba denote FODD resulting replacing node n B 0, Bb
FODD resulting replacing node n 1 leaves node n 0,
final result B 0 = Ba Bb0 Bb0 = Bb Bn0 . correctness Apply two
forms calculating B 0 give map.

b=x
0

p(y)
q(x)

x=y
p(y)
5

q(x)

10

q(x)

q(x)
10

p(x)
0

10

(b)

0

(a)

(c)
b=x

q(x)
5

0

0
(d)

0

p(x)
q(x)

10

q(x)
5

0

(e)

Figure 11: example equality reduction. (a) FODD reduction.
node x = satisfies condition E9.1 variable y. (b) Bnt -copy (nt extracted).
(c) Bnt -copy renamed produce Bn0 -copy. (d) Bnf -copy. (e) Final result
node n replaced apply(Bn0 -copy, Bnf -copy, max)
following prove node n equality condition E9.1 holds B
perform equality reduction R9 without changing map interpretation
satisfying D9.1. start properties FODDs defined above, e.g., B , Bb , Bb0 . Let
n denote set valuations reaching node n let denote set valuations
reaching node n B. basic definition MAP following:
Claim
(a)
(b)
(c)
(d)

1 interpretation I,
, MAPBa (I, ) = MAPB (I, ).
n , MAPBa (I, ) = 0.
, MAPBb (I, ) = 0.
n , MAPBb (I, ) = 1.

Claim 1 definition MAP, have,
Claim 2 interpretation I,
(a) , MAPBb0 (I, ) = 0.
(b) n , MAPBb0 (I, ) = MAPBn0 (I, ).
Claim 1, Claim 2, definition MAP have,

453

fiWang, Joshi, & Khardon

Claim 3 interpretation I,
(a) , MAPB 0 (I, ) = MAPB (I, ).
(b) n , MAPB 0 (I, ) = MAPBn0 (I, ).
Next prove main property reduction stating valuations reaching
node n B, old sub-FODD rooted n new (combined) sub-FODD produce
map.
Lemma 8 Let n set valuations reaching node n FODD B. interpretation satisfying D9.1, maxn MAPBn (I, ) = maxn MAPBn0 (I, ).
Proof: condition E9.1, variable x appear N F (n) hence value
n constrained. therefore partition valuations n disjoint
sets, n = { | valuation variables x}, variables
x fixed value x take value domain I. Assumption
D9.1 guarantees every contains least one valuation reaching Bnt least one
valuation reaching Bnf B. Note valuation reaches Bnt = x satisfied
thus MAPBnt (I, ) = MAPBn0 -copy (I, ). Since x appear Bnf

MAPBn0 -copy (I, ) constant . Therefore correctness
f
Apply max MAPBn (I, ) = max MAPBn0 (I, ).
Finally, definition MAP, maxn MAPBn (I, ) = max max MAPBn (I, )
= max max MAPBn0 (I, ) = maxn MAPBn (I, ).
2
Lemma 9 Let B FODD, n node condition E9.1 holds, B 0 result
R9(n), interpretation satisfying D9.1, MAP B (I) = MAPB 0 (I).
Proof: Let X = maxm MAPB 0 (I, ) = maxn MAPB 0 (I, ). definition MAP, MAPB 0 (I) = max(X, ). However, Claim 3, X = maxm MAPB (I, )
Claim 3 Lemma 8, = maxn MAPBn0 (I, ) = maxn MAPBn (I, ). Thus
2
max(X, ) = MAPB (I) = MAPB 0 (I).
Lemma 9 guarantees correctness, applying practice may important
avoid violations sorting order (which would require expensive re-sorting
diagram). x variables sometimes replace new variable
name resulting diagram sorted. However always possible.
violation unavoidable, tradeoff performing reduction sorting
diagram ignoring potential reduction.
summarize, section introduced several new reductions compress diagrams significantly. first (R5) generic strong reduction removes implied
branches diagram. three (R7, R8, R9) weak reductions alter
overall map diagram alter map specific valuations. three
reductions complementary since capture different opportunities space saving.

5. Decision Diagrams MDPs
section show FODDs used capture RMDP. therefore use
FODDs represent domain dynamics deterministic action alternatives, probabilistic choice action alternatives, reward function, value functions.
454

fiFirst Order Decision Diagrams Relational MDPs

5.1 Example Domain
first give concrete formulation logistics problem discussed introduction. example follows exactly details given Boutilier et al. (2001), used
illustrate constructions MDPs. domain includes boxes, trucks cities,
predicates Bin(Box, City), in(T ruck, City), On(Box, ruck). Following
Boutilier et al. (2001), assume On(b, t) Bin(b, c) mutually exclusive,
box truck city vice versa. is, background knowledge includes
statements b, c, t, On(b, t) Bin(b, c) b, c, t, Bin(b, c) On(b, t). reward
function, capturing planning goal, awards reward 10 formula b, Bin(b, P aris)
true, box Paris. Thus reward allowed include constants
need completely ground.
domain includes 3 actions load, unload, drive. Actions effect
preconditions met. Actions fail probability. attempting
load, successful version loadS executed probability 0.99, unsuccessful version loadF (effectively no-operation) probability 0.01. drive action executed
deterministically. attempting unload, probabilities depend whether raining not. raining successful version unloadS executed probability
0.9, unloadF probability 0.1. raining unloadS executed probability
0.7, unloadF probability 0.3.
5.2 Domain Dynamics
follow Boutilier et al. (2001) specify stochastic actions randomized choice
among deterministic alternatives. domain dynamics defined truth value diagrams (TVDs). every action schema A(~a) predicate schema p(~x) TVD
(A(~a), p(~x)) FODD {0, 1} leaves. TVD gives truth value p(~x)
next state A(~a) performed current state. call ~a action parameters, ~x predicate parameters. variables allowed TVD;
reasoning behind restriction explained Section 6.2. restriction sometimes sidestepped introducing action parameters instead variables.
truth value TVD valid fix valuation parameters.
TVD simultaneously captures truth values instances p(~x) next state.
Notice TVDs different predicates separate. safely done even
action coordinated effects (not conditionally independent) since action alternatives
deterministic.
Since allow action parameters predicate parameters, effects action
restricted predicates action arguments TVD expressive
simple STRIPS based schemas. example, TVDs easily express universal effects
action. see note p(~x) true ~x action A(~a) TVD
(A(~a), p(~x)) captured leaf valued 1. universal conditional effects
captured similarly. hand, since explicit universal quantifiers,
TVDs cannot capture universal preconditions.
domain, TVD predicate p(~x) defined generically Figure 12.
idea predicate true true undone action
false brought action. TVDs logistics domain
455

fiWang, Joshi, & Khardon

p( x )
bring


undo
0

0

1

Figure 12: template TVD

Bin (B, C)
1

(B, T)

(B, t*)

B= b*

T= t*
0

Tin (t*, C)
1

0

B= b*

B= b*

Bin (B, C)
0

1

C= c*
1

0
(b)

Bin (B, c*)
1

Tin (T, c*)

(c)

C c*
0

(d)

T= t*
C= c*

1
(e)

1

0

1

Tin (T, C)
T= t*

B= b*
T= t*

Tin( t*, C)

0
(a)

(B, T)

0

rain
0.7

Bin (b, Paris)

0.9

10

(f)

0
(g)

Figure 13: FODDs logistics domain: TVDs, action choice, reward function. (a)(b) TVDs Bin(B, C) On(B, ) action choice
unloadS(b , ). (c)(d) TVDs Bin(B, C) On(B, ) action
choice loadS(b , , c ). Note c must action parameter (d)
valid TVD. (e) TVD in(T, C) action choice driveS(t , c ).
(f) probability FODD action choice unloadS(b , ). (g) reward
function.

456

fiFirst Order Decision Diagrams Relational MDPs

running example given Figure 13. TVDs omitted figure
trivial sense predicate affected action. order simplify
presentation give TVDs generic form sort diagrams using
order proposed Section 3.5; TVDs consistent ordering Bin =
rain. Notice TVDs capture implicit assumption usually taken
planning-based domains preconditions action satisfied
action effect.
Notice utilize multiple path semantics maximum aggregation. predicate true true according one paths specified get disjunction
conditions free. use single path semantics Blockeel De Raedt
(1998) corresponding notion TVD significantly complicated since single
path must capture possibilities predicate become true. capture that, must
test sequentially different conditions take union substitutions
different tests turn requires additional annotation FODDs appropriate
semantics. Similarly operation would require union substitutions, thus complicating representation. explain issues detail Section 6.3
introduce first order value iteration algorithm.
5.3 Probabilistic Action Choice
One consider modeling arbitrary conditions described formulas state
control natures probabilistic choice action. multiple path semantics makes
hard specify mutually exclusive conditions using existentially quantified variables
way specify distribution. therefore restrict conditions either propositional
depend directly action parameters. condition interpretation follows
exactly one path (since variables thus empty valuation) thus
aggregation function interact probabilities assigned. diagram showing
action choice unloadS logistics example given Figure 13. example,
condition propositional. condition depend action parameters,
example, assume result affected whether box big not,
diagram Figure 14 specifying action choice probability.
Big(b*)
rain

0.9

0.7 0.9

Figure 14: example showing choice probability depend action parameters.
Note probability usually depends current state. depend arbitrary properties state (with restriction stated above), e.g., rain big(b ),
shown Figure 14. allow arbitrary conditions depend predicates arguments restricted action parameters dependence complex. However,
allow free variables probability choice diagram. example, cannot
model probabilistic choice unloadS(b , ) depends boxes truck ,
457

fiWang, Joshi, & Khardon

e.g., b, On(b, ) b 6= b : 0.2; otherwise, 0.7. write FODD capture
condition, semantics FODD means path 0.7 selected max aggregation distribution cannot modeled way. clearly restriction,
conditions based action arguments still give substantial modeling power.
5.4 Reward Value Functions
Reward value functions represented directly using algebraic FODDs. reward
function logistics domain example given Figure 13.

6. Value Iteration FODDs
Following Boutilier et al. (2001) define first order value iteration algorithm follows:
given reward function R action model input, set V0 = R, n = 0 repeat
procedure Rel-greedy termination:
Procedure 1 Rel-greedy
1. action type A(~x), compute:
A(~
x)

QV n

= R [ j (prob(Aj (~x)) Regr(Vn , Aj (~x)))]

(3)

A(~
x)

2. QA
Vn = obj-max(QVn ).
3. Vn+1 = maxA QA
Vn .
notation steps procedure discussed Section 2 except
work FODDs instead case statements. Note since reward function
depend actions, move object maximization step forward adding
reward function. I.e., first
A(~
x)

TV n

= j (prob(Aj (~x)) Regr(Vn , Aj (~x))),

followed
A(~
x)

QA
Vn = R obj-max(TVn ).
Later see object maximization step makes reductions possible; therefore moving step forward get savings computation. compute
updated value function way comprehensive example value iteration given
later Section 6.8.
(Puterman, 1994). case
Value iteration terminates kVi+1 Vi k (1)
2
need test values achieved two diagrams within (1)
2 .
formulations goal based planning problems use absorbing state zero
additional reward goal reached. handle formulation
one non-zero leaf R. case, replace Equation 3
A(~
x)

QV n

= max(R, j (prob(Aj (~x)) Regr(Vn , Aj (~x))).

see correct, note due discounting max value always R. R
satisfied state care action (max would R) R 0
state get value discounted future reward.
458

fiFirst Order Decision Diagrams Relational MDPs

Note goal based domains, i.e., one non-zero
leaf. mean cannot disjunctive goals, means must
value goal condition equally.
6.1 Regressing Deterministic Action Alternatives
first describe calculation Regr(Vn , Aj (~x)) using simple idea call block replacement. proceed discuss obtain result efficiently.
Consider Vn nodes FODD. node take copy corresponding TVD, predicate parameters renamed correspond
nodes arguments action parameters unmodified. BR-regress(V n , A(~x)) FODD
resulting replacing node Vn corresponding TVD, outgoing edges
connected 0, 1 leaves TVD.
Recall RMDP represents family concrete MDPs generated choosing
concrete instantiation state space (typically represented number objects
types). formal properties algorithms hold concrete instantiation.
Fix concrete instantiation state space. Let denote state resulting
executing action A(~x) state s. Notice Vn BR-regress(Vn , A(~x)) exactly
variables. following lemma:
Lemma 10 Let valuation variables Vn (and thus variables
BR-regress(Vn , A(~x))). MAPVn (s, ) = MAPBRregress(Vn ,A(~x)) (s, ).
Proof: Consider paths P, P followed valuation two diagrams.
definition TVDs, sub-paths P applied guarantee corresponding nodes
P take truth values s. P, P reach leaf value
obtained.
2
naive implementation block replacement may efficient. use block
replacement regression resulting FODD necessarily reduced moreover,
since different blocks sorted start result even sorted. Reducing
sorting results may expensive operation. Instead calculate result
follows. FODD Vn traverse BR-regress(Vn , A(~x)) using postorder traversal
terms blocks combine blocks. step combine 3 FODDs
parent block yet processed (so TVD binary leaves)
two children processed (so general FODDs). call parent
Bn , true branch child Bt false branch child Bf represent
combination [Bn Bt ] [(1 Bn ) Bf ].
Lemma 11 Let B FODD Bt Bf FODDs, Bn FODD {0, 1}
leaves. Let B result using Apply calculate diagram [Bn Bt ][(1 Bn )Bf ].
interpretation valuation MAPB (I, ) = MAPB (I, ).
Proof: true since fixing valuation effectively ground FODD
paths mutually exclusive. words FODD becomes propositional clearly
combination using propositional Apply correct.
2
high-level description algorithm calculate BR-regress(V n , A(~x)) block
combination follows:
459

fiWang, Joshi, & Khardon

Procedure 2 Block Combination BR-regress(Vn , A(~x))
1. Perform topological sort Vn nodes (see example Cormen, Leiserson, Rivest,
& Stein, 2001).
2. reverse order, non-leaf node n (its children Bt Bf already
processed), let Bn copy corresponding TVD, calculate [Bn Bt ] [(1
Bn ) Bf ].
3. Return FODD corresponding root.
Notice different blocks share variables cannot perform weak reductions
process. However, perform strong reductions intermediate steps since
change map valuation. process completed perform
combination weak strong reductions since change map
regressed value function.
Blue (b)

(B, T)
1

Big(t)
On(b,t)
0

0

B= b*

Big(t)
(b, t)

T= t*

1
(a)

Blue (b)

0

Bin (B, c)
Tin (T, c)

0

b= b*
t= t*

0

1
(b)

Bin (b, c)
Tin (t, c)
1

0
(c)

Figure 15: example illustrating variables allowed TVDs.
explain cannot variables TVDs example illustrated Figure 15. Suppose value function defined Figure 15(a), saying
blue block big truck block truck
value 1 assigned. Figure 15(b) gives TVD On(B, ) action loadS,
c variable instead action parameter. Figure 15(c) gives result
block replacement. Consider interpretation domain {b1 , t1 , c1 , c2 } relations
{Blue(b1 ), Big(t1 ), Bin(b1 , c1 ), in(t1 , c1 )}. action loadS(b1 , t1 ) reach
state = {Blue(b1 ), Big(t1 ), On(b1 , t1 ), in(t1 , c1 )}, gives us value 0. Figure 15(c) b = b1 , = t1 evaluated gives value 1 valuation {b/b1 , c/c2 , t/t1 }.
choice c/c2 makes sure precondition violated. making c action parameter, applying action must explicitly choose valuation leads correct
value function. Object maximization turns action parameters variables allows us
choose argument maximize value.
460

fiFirst Order Decision Diagrams Relational MDPs

6.2 Regressing Probabilistic Actions
regress probabilistic action must regress deterministic alternatives combine choice probability Equation 3. discussed Section 2, due
restriction RMDP model explicitly specifies finite number deterministic
action alternatives, replace potentially infinite sum Equation 1 finite
sum Equation 3. done correctly every state result Equation 3
correct. following specify done FODDs.
Recall prob(Aj (~x)) restricted include action parameters cannot include variables. therefore calculate prob(Aj (~x))Regr(Vn , Aj (~x)) step (1) directly
using Apply. However, different regression results independent functions
sum j (prob(Aj (~x)) Regr(Vn , Aj (~x))) must standardize apart different regression results adding functions (note action parameters still considered
constants stage). holds addition reward function. need
standardize apart complicates diagrams often introduces structure
reduced. performing operations first use propositional Apply procedure
follow weak strong reductions.

V0

ASucc(x*)
q (x)

p (x)
10

p (A)
5

1

A=x*

0

q (A)
1

(a)

0
(b)
q (x2)

q (x1)
p (x1) 2.5
x1= x*

q (x2)
+

p (x2) 2.5
5

q (x1)
5

0



q (x1)
p (x1)

0

x1= x*
q (x1)

0
(c)

7.5

Figure 16: example illustrating need standardize apart.
Figure 16 illustrates need standardize apart different action outcomes. Action
succeed (denoted ASucc) fail (denoted AF ail, effectively no-operation),
chosen probability 0.5. Part (a) gives value function V 0 . Part (b) gives
TVD P (A) action choice ASucc(x ). TVDs trivial. Part
(c) shows part result adding two outcomes standardizing apart
(to simplify presentation diagrams sorted). Consider interpretation
domain {1, 2} relations {q(1), p(2)}. seen (c), choosing x = 1, i.e.
461

fiWang, Joshi, & Khardon

action A(1), valuation x1 = 1, x2 = 2 gives value 7.5 action (without
considering discount factor). Obviously standardize apart (i.e x 1 = x2 ),
leaf value 7.5 get wrong value. Intuitively contribution
ASucc value comes bring portion diagram AF ails
contribution uses bindings undo portion two portions refer
different objects. Standardizing apart allows us capture simultaneously.
Lemma 10 11 discussion far have:
Lemma 12 Consider concrete instantiation RMDP. Let Vn value function
corresponding MDP, let A(~x) probabilistic action domain.
A(~
x)
QVn calculated Equation 3 correct. is, state s, MAPQA(~x) (s)
Vn

expected value executing A(~x) receiving terminal value V n .
6.3 Observations Single Path Semantics

Section 5.2 suggested single path semantics Blockeel De Raedt (1998)
support value iteration well multiple path semantics. explanation
regression, use example illustrate this. Suppose value function
defined Figure 17(a), saying red block big city value 1
assigned. Figure 17(b) gives result block replacement action unloadS(b , ).
However correct. Consider interpretation domain {b 1 , b2 , t1 , c1 }
relations {Red(b2 ), Blue(b1 ), Big(c1 ), Bin(b1 , c1 ), in(t1 , c1 ), On(b2 , t1 )}. Note use
single path semantics. follow true branch root since b, c, Bin(b, c) true
{b/b1 , c/c1 }. follow false branch Red(b) since b, c, Bin(b, c) Red(b)
satisfied. Therefore get value 0. Clearly, get value 1 instead
{b/b2 , c/c1 }, impossible achieve value Figure 17(b) single
path semantics. reason block replacement fails top node decides true
branch based one instance predicate really need true instances
predicate filter true leaf TVD.
correct problem, want capture instances true
undone instances made true one path. Figure 17(c) gives one
possible way it. means variable renaming, stands union operator,
takes union substitutions. treated edge operations. Note
coordinated operation, i.e., instead taking union substitutions
b0 b00 , c0 c00 separately need take union substitutions (b0 , c0 )
(b00 , c00 ). approach may possible clearly leads complicated diagrams.
Similar complications arise context object maximization. Finally use
representation procedures need handle edge marking unions
substitutions approach look promising.
6.4 Object Maximization
Notice since handling different probabilistic alternatives action
separately must keep action parameters fixed regression process
added step 1 algorithm. step 2 maximize choice action
parameters. mentioned get maximization free. simply rename
462

fiFirst Order Decision Diagrams Relational MDPs

Bin(b ,c )

Bin(b , c )

Bin(b, c)

b =b*

Red(b)

Bin(b ,c )

On(b , t*)

b =b*

Tin(t*,c )

Big(c)
0

1
(a)

Red(b )
Big(c )
1

Red(b )

On(b ,t*)
0

1

0

On(b ,t*)
Tin(t*,c )

Tin(t*,c ) (b,c)
(b ,c )
(b,c)
(b ,c )
(b ,c )

Big(c )
0

b =b*

(b,c)
(b ,c )

0

Red(b)
Big(c)

(b)

1

0

(c)

Figure 17: example illustrating union or.

action parameters using new variable names (to avoid repetition iterations)
consider variables. aggregation semantics provides maximization
definition selects best instance action. Since constants turned
variables additional reduction typically possible stage. combination weak
strong reductions used. discussion following lemma:
Lemma 13 Consider concrete instantiation RMDP. Let Vn value function
corresponding MDP, let A(~x) probabilistic action domain.
QA
Vn calculated object maximization step 2 algorithm correct. is,
state s, MAPQA (s) maximum expected values achievable executing
Vn
instance A(~x) receiving terminal value Vn .
potential criticism object maximization essentially adding
variables diagram thus future evaluation diagram state becomes
expensive (since substitutions need considered). However, true
diagram remains unchanged object maximization. fact, illustrated
example given below, variables may pruned diagram process
reduction. Thus long final value function compact evaluation efficient
hidden cost.
6.5 Maximizing Actions
maximization Vn+1 = maxA QA
n+1 step (3) combines independent functions. Therefore must first standardize apart different diagrams, follow
propositional Apply procedure finally follow weak strong reductions.
clearly maintains correctness concrete instantiation state space.
463

fiWang, Joshi, & Khardon

6.6 Order Argument Types
resume discussion ordering argument types extend predicate
action parameters. above, structure suggested operations
algorithm. Section 3.5 already suggested order constants variables.
Action parameters special constants object maximization become
variables object maximization. Thus position allow behave
variables. therefore order constants action parameters.
Note predicate parameters exist inside TVDs, replaced domain
constants variables regression. Thus need decide relative
order predicate parameters action parameters. put action parameters
predicate parameters latter replaced constant get order
violation, order useful. hand, put predicate parameters
action parameters instantiations predicate parameters possible.
Notice substituting predicate parameter variable, action parameters
still need larger variable (as TVD). Therefore, order
action parameters variables.
summarize, ordering: constants variables (predicate parameters case
TVDs) action parameters, suggested heuristic considerations orders maximize potential reductions, avoid need re-sorting diagrams.
Finally, note want maintain diagram sorted times, need
maintain variant versions TVD capturing possible ordering replacements
predicate parameters. Consider TVD Figure 18(a). rename predicate parameters
X x2 x1 respectively, x1 x2 , resulting sub-FODD
shown Figure 18(b) violates order. solve problem define another
TVD corresponding case substitution X substitution ,
shown Figure 18(c). case replacing X x2 x1 , use TVD
Figure 18(c) instead one Figure 18(a).

On(X, Y)

On(x2, x1)

On(X, Y)

p(X)

p(x2)

p(Y)

p(x1)

p(Y)
1

0
(a)

1

p(X)
0

(b)

1

0
(c)

Figure 18: example illustrating necessity maintain multiple TVDs.

6.7 Convergence Complexity
Since step Procedure 1 correct following theorem:

464

fiFirst Order Decision Diagrams Relational MDPs

Theorem 2 Consider concrete instantiation RMDP. Let Vn value function
corresponding MDP n steps go. value Vn+1 calculated
Procedure 1 correctly captures value function n + 1 steps go.
is, state s, MAPVn+1 (s) maximum expected value achievable n + 1
steps.
Note RMDPs problems require infinite number state partitions.
Thus cannot converge V finite number steps. However, since algorithm
implements VI exactly, standard results approximating optimal value functions
policies still hold. particular following standard result (Puterman, 1994) holds
algorithm, stopping criterion guarantees approximating optimal value functions
policies.
Theorem 3 Let V optimal value function let Vk value function calculated
relational VI algorithm.
(1) r(s) kVn V k n
(2) kVn+1 Vn k

(1)
2

2M
)
log( (1)

log 1

.

kVn+1 V k .

algorithm maintains compact diagrams, reduction diagrams guaranteed domains. Therefore provide trivial upper bounds terms
worst case time complexity. Notice first every time use Apply procedure
size output diagram may large product size inputs.
must consider size FODD giving regressed value function. Block
replacement O(N ) N size current value function, sorted
sorting may require exponential time space worst case. example,
Bryant (1986) illustrates ordering may affect size diagram. function
2n arguments, function x1 x2 + x3 x4 + + x2n1 x2n requires diagram
2n + 2 nodes, function x1 xn+1 + x2 xn+2 + + xn x2n requires 2n+1 nodes.
Notice two functions differ permutation arguments.
x1 x2 + x3 x4 + + x2n1 x2n result block replacement clearly sorting
requires exponential time space. true block combination procedure
method calculating result, simply output exponential
size. case heuristics change variable ordering, propositional ADDs
(Bryant, 1992), would probably useful.
Assuming TVDs, reward function, probabilities size C, action
action alternatives, current value function Vn N nodes, worst case
space expansion regression Apply operations, overall size result
2
time complexity one iteration O(C (N +1) ). However note
worst case analysis take reductions account. method
guaranteed always work efficiently, alternative grounding MDP
unmanageable number states deal with, despite high worst case complexity
method provides potential improvement. next example illustrates, reductions
substantially decrease diagram size therefore save considerable time computation.
465

fiWang, Joshi, & Khardon

6.8 Comprehensive Example Value Iteration
Figure 19 traces steps application value iteration logistics domain.
TVDs, action choice probabilities, reward function domain given Figure 13. simplify presentation, continue using predicate ordering Bin =
rain introduced earlier.5
Given V0 = R shown Figure 19(a), Figure 19(b) gives result regression
V0 unloadS(b , ) block replacement, denoted Regr(V0 , unloadS(b , )).
Figure 19(c) gives result multiplying Regr(V0 , unloadS(b , )) choice
probability unloadS P r(unloadS(b , )).
Figure 19(d) gives result P r(unloadF (b , )) Regr(V0 , unloadF (b , )). Notice diagram simpler since unloadF change state TVDs
trivial.
Figure 19(e) gives unreduced result adding two outcomes unload(b , ), i.e.,
result adding [P r(unloadS(b , ))Regr(V0 , unloadS(b , ))] [P r(unloadF (b , ))
Regr(V0 , unloadF (b , ))]. Note first standardize apart diagrams unloadS(b , )
unloadF (b , ) respectively renaming b b1 b2 . Action parameters b
stage considered constants change them. note
recursive part Apply (addition ) performed reductions, i.e., removing node
rain children lead value 10.
Figure 19(e), apply R6 node Bin(b2 , P aris) left branch.
conditions
P7.1: [b1 , Bin(b1 , P aris)] [b1 , b2 , Bin(b1 , P aris) Bin(b2 , P aris)],
V7.1: min(Bin(b2 , P aris)t ) = 10 max(Bin(b2 , P aris)f ) = 9,
V7.2: Bin(b2 , P aris)t constant
hold. According Lemma 3 Lemma 5 drop node Bin(b2 , P aris) connect
parent Bin(b1 , P aris) true branch. Figure 19(f ) gives result reduction.
Next, consider true child Bin(b2 , P aris) true child root.
conditions
P7.1: [b1 , b2 , Bin(b1 , P aris) Bin(b2 , P aris)] [b1 , Bin(b1 , P aris)],
V7.1: min(Bin(b1 , P aris)t ) = 10 max(Bin(b2 , P aris)t ) = 10,
V7.2: min(Bin(b1 , P aris)t ) = 10 max(Bin(b2 , P aris)f ) = 9
hold. According Lemma 3 Lemma 5, drop node Bin(b2 , P aris)
connect parent Bin(b1 , P aris) Bin(b2 , P aris)f . Figure 19(g) gives result
unload(b ,t )
reduction get fully reduced diagram. TV0
.
next step perform object maximization maximize action parameters
b get best instance action unload. Note b
become variables, perform one reduction: drop equality
right branch R9. Figure 19(h) gives result object maximization, i.e.,
unload(b ,t )
obj-max(TV0
). Note renamed action parameters avoid
repetition iterations.
unload(b ,t )
Figure 19(i) gives reduced result multiplying Figure 19(h), obj-max(TV0
),
= 0.9, adding reward function. result Qunload
.
1
5. details change substantially use order suggested Section 3.5 (where equality
first).

466

fiFirst Order Decision Diagrams Relational MDPs

Bin (b, Paris)

V0

10

Bin (b, Paris)
10

b= b*

b= b*
(b, t*)

Tin (t*, Paris)

Tin (t*, Paris)

10

0

7

9

1

3

(d)

(c)

Bin (b1, Paris)
10

0

rain

0

rain

(b)

Bin (b2, Paris)

Bin (b, Paris)

(b, t*)

0
(a)

Bin (b, Paris)

Bin (b1, Paris)
10

Bin (b2, Paris)

Bin (b2, Paris)

rain
b1= b*
9
(b1, t*)

7

Tin (t*, Paris)
10

rain

b1= b*

b1= b*
(b1, t*)

(b1, t*)

3 1 7

(b1, t*)

Tin (t*, Paris)

Tin (t*, Paris)
0

rain

b1= b*

10

Tin (t*, Paris)

rain

9

3 1 7

9

(e)

(f)

Bin (b1, Paris)
10

Bin (b1, Paris)

b1= b*
(b1, t*)

7

Q1unload

(b1, t1)

10

0

6.3 8.1
(h)

V1

6.3 8.1
(l)

0

Bin (b, Paris)

0

19

Tin (t, Paris)

(b, t*)

1

Tin (t*, Paris)

rain

Q

(i)

b= b*

(b, t)

Tin (t, Paris)

(j)

0

(k)

Bin (b, Paris)

Bin (b, Paris)
19

0

drive
1

rain

9
(g)

19

Tin (t, Paris)

9

7

Bin (b, Paris)

(b, t)

19

rain
0

Q1load

Bin (b, Paris)

Tin (t1, Paris)

Tin (t*, Paris)
rain

0

rain

Tin (t, Paris)

t= t*
0

0

On(b, t)

Tin (t, Paris)
0

rain
6.3 8.1

0

rain
6.3 8.1



b=b*

19



0



0

1
=

Tin (t, Paris)
0

rain
6.3 8.1
(n)

(m)

Figure 19: example value iteration Logistics Domain.

467

fiWang, Joshi, & Khardon

calculate Qload
Q1drive way results shown Figure 19(j)
1
Figure 19(k) respectively. drive TVDs trivial calculation
relatively simple. load, potential loading box already Paris dropped
diagram reduction operators process object maximization.
Figure 19(l) gives V1 , result maximizing Qunload
, Qload
Qdrive
.
1
1
1
standardized apart diagrams, maximized them, reduced
result. case diagram unload dominates actions. Therefore Q unload
1
becomes V1 , value function first iteration.
start second iteration, i.e., computing V2 V1 . Figure 19(m) gives
result block replacement regression V 1 action alternative unloadS(b , ).
Note sorted TVD on(B, ) obeys ordering chosen.
However, diagram resulting block replacement sorted.
address use block combination algorithm combine blocks bottom
up. Figure 19(n) illustrates combine blocks in(t, P aris), TVD,
two children, processed general FODDs. combine
in(t, P aris) two children, On(b, t)t processed. Since On(b, t)f = 0,
combine On(b, t) two children next step block combination.
Continuing process get sorted representation Regr(V1 , unloadS(b , )).
6.9 Extracting Optimal Policies
one way represent policies FODDs. simply note
policy represented implicitly set regressed value functions. value
iteration terminates, perform one iteration compute set Q-functions
using Equation 3.
Then, given state s, compute maximizing action follows:
1. Q-function QA(~x) , compute MAPQA(~x) (s), ~x considered variables.
2. maximum map obtained, record action name action parameters (from
valuation) obtain maximizing action.
clearly implements policy represented value function. alternative
approach represents policy explicitly developed context policy
iteration algorithm (Wang & Khardon, 2007).

7. Discussion
ADDs used successfully solve propositional factored MDPs. work gives one
proposal lifting ideas RMDPs. general steps similar, technical
details significantly involved propositional case. decision diagram
representation combines strong points SDP ReBel approaches RMDP.
one hand get simple regression algorithms directly manipulating diagrams.
hand get object maximization free ReBel. get space saving
since different state partitions share structure diagrams. possible disadvantage
compared ReBel reasoning required reduction operators might complex.
468

fiFirst Order Decision Diagrams Relational MDPs

terms expressiveness, approach easily capture probabilistic STRIPS style
formulations ReBel, allowing flexibility since use FODDs capture
rewards transitions. example, representation capture universal effects
actions. hand, limited SDP since cannot use arbitrary
formulas rewards, transitions, probabilistic choice. example cannot express
universal quantification using maximum aggregation, cannot used reward
functions action preconditions. approach capture grid-world RL domains
state based reward (which propositional) factored form since reward
described function location.
contrasting single path semantics multiple path semantics see
interesting tension choice representation task. multiple path method
directly support state partitions, makes awkward specify distributions
policies (since values actions must specified leaves). However,
semantics simplifies many steps easily supporting disjunction maximization
valuations crucial value iteration likely lead significant saving
space time.
implementation empirical evaluation progress. precise choice
reduction operators application crucial obtain effective system, since
general tradeoff run time needed reductions size resulting
FODDs. apply complex reduction operators get maximally reduced FODDs,
takes longer perform reasoning required. optimization still open issue
theoretically empirically. Additionally, implementation easily incorporate
idea approximation combining leaves similar values control size
FODDs (St-Aubin et al., 2000). gives simple way trading efficiency
accuracy value functions.
many open issues concerning current representation. results
FODDs give first step toward complete generalization ADDs. Crucially
yet semantically appropriate normal form important simplifying reasoning.
one define normal form (cf., Garriga et al., 2007, treatment conjunctions)
clear calculated incrementally using local operations ADDs.
would interesting investigate conditions guarantee normal form useful set
reduction operators FODDs.
Another possible improvement representation modified allow
compression. example allow edges rename variables traversed
compress isomorphic sub-FODDs illustrated Figure 17(c). Another
interesting possibility copy operator evaluates several copies predicate (with
different variables) node illustrated Figure 20. constructs
usable one must modify FODD MDP algorithmic steps handle diagrams
new syntactic notation.

8. Conclusion
paper makes two main contributions. First, introduce FODDs, generalization
ADDs, relational domains may useful various applications. developed
calculus FODDs reduction operators minimize size many open
469

fiWang, Joshi, & Khardon

p (x) p (y)

p (x)
q (x)

0

q (x)

p (y) 0

f (y) 0

f (y) 0
2

0

2

1

1

Figure 20: Example illustrating copy operator.

issues regarding best choice operators reductions. second contribution
developing FODD-based value iteration algorithm RMDPs potential
significant improvement previous approaches. algorithm performs general
relational probabilistic reasoning without ever grounding domains proved
converge abstract optimal value function solution exists.

References
Bahar, R. I., Frohm, E. A., Gaona, C. M., Hachtel, G. D., Macii, E., Pardo, A., & Somenzi,
F. (1993). Algebraic decision diagrams applications. Proceedings
International Conference Computer-Aided Design, pp. 188191.
Bellman, R. E. (1957). Dynamic programming. Princeton University Press.
Blockeel, H., & De Raedt, L. (1998). Top induction first order logical decision trees.
Artificial Intelligence, 101, 285297.
Boutilier, C., Dean, T., & Goldszmidt, M. (2000). Stochastic dynamic programming
factored representations. Artificial Intelligence, 121(1), 49107.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,
11, 194.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Proceedings International Joint Conference Artificial Intelligence,
pp. 11041111.
Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic dynamic programming first-order
MDPs. Proceedings International Joint Conference Artificial Intelligence,
pp. 690700.
Bryant, R. E. (1986). Graph-based algorithms boolean function manipulation. IEEE
Transactions Computers, C-35 (8), 677691.
Bryant, R. E. (1992). Symbolic boolean manipulation ordered binary decision diagrams. ACM Computing Surveys, 24 (3), 293318.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms. MIT Press.
470

fiFirst Order Decision Diagrams Relational MDPs

Driessens, K., Ramon, J., & Gartner, T. (2006). Graph kernels gaussian processes
relational reinforcement learning. Machine Learning, 64 (1-3), 91119.
Dzeroski, S., De Raedt, L., & Driessens, K. (2001). Relational reinforcement learning.
Machine Learning, 43, 752.
Feng, Z., & Hansen, E. A. (2002). Symbolic heuristic search factored Markov Decision
Processes. Proceedings National Conference Artificial Intelligence, pp.
455460.
Fern, A., Yoon, S., & Givan, R. (2003). Approximate policy iteration policy language
bias. International Conference Neural Information Processing Systems.
Fern, A., Yoon, S., & Givan, R. (2006). Approximate policy iteration policy language
bias: Solving relational Markov Decision Processes. Journal Artificial Intelligence
Research, 25, 75118.
Garriga, G., Khardon, R., & De Raedt, L. (2007). mining closed sets multi-relational
data. Proceedings International Joint Conference Artificial Intelligence,
pp. 804809.
Gretton, C., & Thiebaux, S. (2004). Exploiting first-order regression inductive policy
selection. Proceedings Conference Uncertainty Artificial Intelligence,
pp. 217225.
Groote, J. F., & Tveretina, O. (2003). Binary decision diagrams first-order predicate
logic. Journal Logic Algebraic Programming, 57, 122.
Gromann, A., Holldobler, S., & Skvortsova, O. (2002). Symbolic dynamic programming
within fluent calculus. Proceedings IASTED International Conference
Artificial Computational Intelligence.
Guestrin, C., Koller, D., Gearhart, C., & Kanodia, N. (2003a). Generalizing plans new
environments relational MDPs. Proceedings International Joint Conference
Artificial Intelligence, pp. 10031010.
Guestrin, C., Koller, D., Par, R., & Venktaraman, S. (2003b). Efficient solution algorithms
factored MDPs. Journal Artificial Intelligence Research, 19, 399468.
Hansen, E. A., & Feng, Z. (2000). Dynamic programming POMDPs using factored
state representation. Proceedings International Conference Artificial
Intelligence Planning Systems, pp. 130139.
Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planning using decision diagrams. Proceedings Conference Uncertainty Artificial
Intelligence, pp. 279288.
Hoolldobler, S., Karabaev, E., & Skvortsova, O. (2006). FluCaP: heuristic search planner
first-order MDPs. Journal Artificial Intelligence Research, 27, 419439.
Kersting, K., Otterlo, M. V., & De Raedt, L. (2004). Bellman goes relational. Proceedings
International Conference Machine Learning.
McMillan, K. L. (1993). Symbolic model checking. Kluwer Academic Publishers.
471

fiWang, Joshi, & Khardon

Puterman, M. L. (1994). Markov decision processes: Discrete stochastic dynamic programming. Wiley.
Rivest, R. L. (1987). Learning decision lists. Machine Learning, 2 (3), 229246.
Sanghai, S., Domingos, P., & Weld, D. (2005). Relational dynamic bayesian networks.
Journal Artificial Intelligence Research, 24, 759797.
Sanner, S., & Boutilier, C. (2005). Approximate linear programming first-order MDPs.
Proceedings Conference Uncertainty Artificial Intelligence.
Sanner, S., & Boutilier, C. (2006). Practical linear value-approximation techniques firstorder MDPs. Proceedings Conference Uncertainty Artificial Intelligence.
Sanner, S., & Boutilier, C. (2007). Approximate solution techniques factored first-order
MDPs. Proceedings International Conference Automated Planning
Scheduling.
Schuurmans, D., & Patrascu, R. (2001). Direct value approximation factored MDPs.
International Conference Neural Information Processing Systems, pp. 15791586.
St-Aubin, R., Hoey, J., & Boutilier, C. (2000). APRICODD: Approximate policy construction using decision diagrams. International Conference Neural Information
Processing Systems, pp. 10891095.
Wang, C. (2007). First order Markov Decision Processes. Tech. rep. TR-2007-4, Computer
Science Department, Tufts University.
Wang, C., Joshi, S., & Khardon, R. (2007). First order decision diagrams relational
MDPs. Proceedings International Joint Conference Artificial Intelligence,
pp. 10951100.
Wang, C., & Khardon, R. (2007). Policy iteration relational MDPs. Proceedings
Conference Uncertainty Artificial Intelligence.

472


