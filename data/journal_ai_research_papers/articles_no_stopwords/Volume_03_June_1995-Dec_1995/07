Journal Artificial Intelligence Research 3 (1995) 373-382

Submitted 7/95; published 12/95

Statistical Feature Combination
Evaluation Game Positions
Michael Buro

NEC Research Institute
4 Independence Way
Princeton NJ 08540 U.S.A.

mic@research.nj.nec.com

Abstract

article describes application three well{known statistical methods field
game{tree search: using large number classified Othello positions, feature weights
evaluation functions game{phase{independent meaning estimated means
logistic regression, Fisher's linear discriminant, quadratic discriminant function
normally distributed features. Thereafter, playing strengths compared means
tournaments resulting versions world{class Othello program.
application, logistic regression | used first time context game
playing | leads better results approaches.

1. Introduction

Programs playing games chess, draughts, Othello use evaluation functions estimate
players' winning chances positions leaves game{trees. values
propagated root according NegaMax principle order choose move
root position leads highest score. Normally, evaluation functions combine
features measure properties position correlated winning chance,
material chess mobility Othello. popular quickly computable linear feature
combinations. early days game programming, feature weights chosen
intuitively improved manual hill{climbing process programmer's patience
gave out. technique laborious. Samuel (1959,1967) first describe method
automatic improvement evaluation function parameters. Since many approaches
investigated. Two main strategies distinguished:

Move adaptation: Evaluation function parameters tuned maximize frequency
searches yield moves occur lists moves belonging training
positions. idea get program mimic experts' moves.

Value adaptation: Given set labelled example positions, parameters determined

evaluation function fits specific model. instance, evaluation functions
constructed way predict final game result.

move adaptation, proposed instance Marsland (1985), v.d. Meulen (1989),
Mysliwietz (1994), linear feature combination two degrees freedom: multiplied positive constant constant added without changing move
decision. evaluation function depends game phase, positions different
phases compared (for example within framework selective extensions opening
book play), constants must chosen suitably. evaluation functions optimized
c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBuro

move adaptation moment global interpretation, solution problem
obvious. Schaeffer et al. (1992) presented ad hoc game{specific approach.
respect, value adaptation promising. Here, evaluations different
phases comparable example position labels phase{independent meaning.
Mitchell (1984) labelled Othello positions occurring game final game result
form disc differential tried approximate values using linear
combination features. Since regression used determine weights,
possible investigate features' statistical relevance. Another statistical approach
value adaptation used Lee & Mahajan (1988): example positions classified
win loss side move | assuming features multivariate normal |
quadratic discriminant function used predict winning probability. technique
ensures desired comparability applies games without win degrees, i.e.
know wins, draws, losses.
Besides classical approaches heavily rely given feature sets, recent
years artificial neural networks (ANNs) trained evaluating game positions.
instance, Moriarty & Miikkulainen (1993) used genetic algorithms evolve topology
weights ANNs order learn Othello concepts means tournaments
fixed programs. discovering concept mobility, best 1{ply ANN{player
able win 70% games 3{ply brute{force program used evaluation
function without mobility features. important contribution field
Tesauro (1992,1994,1995). Using temporal difference learning (Sutton, 1988) updating
weights, ANNs learned evaluate backgammon positions master level means
self{play. Tesauro conjectured stochastic nature backgammon responsible
success approach. Though several researchers obtained encouraging preliminary
results applying Tesauro's learning procedure deterministic games, work yet
led strong tournament programs tactical games Awari, draughts, Othello,
chess, allow deep searches powerful quickly computable evaluation
functions known. might due tactics games knowledgeable
slower evaluation functions necessarily accurate relatively simple
faster evaluation functions conjunction deeper searches.
follows, three well{known statistical models | namely quadratic discrimination function normally distributed features, Fisher's linear discriminant, logistic
regression | described evaluation game positions context value
adaptation. Thereafter, shown example positions parameter estimation
generated. Finally, playing strengths three versions world{class Othello program1
| LOGISTELLO | equipped resulting evaluation functions compared order
determine strongest tournament player. turns quadratic feature combinations necessarily lead stronger programs linear combinations, logistic
regression gives best results application.

2. Statistical Feature Combination

formal basis statistical feature combination position evaluation stated
follows:
1. Since appearance October 1993 twelve 14 international tournaments played.

374

fiStatistical Feature Combination


set positions evaluate.
:
! fL; Wg classifies positions loss win player move,
assuming optimal play sides. Draws handled manner
outlined Section 4.
X1; : : :; X :
! IR features.
evaluation position ! 2
x = (X1; : : :; X )(!) conditional winning probability
n

n

V ( ! ) = P (Y

= W j (X1; : : :; X ) = x) =: P (W j x):
n

N classified example positions !1; : : :; ! 2
available
N

x = (X1; : : :; X )(! ) = (! ).


n







following subsections models express P (W j x) function linear quadratic feature combinations brie introduced way sucient practical
purposes. Good introductions theoretical details given instance Duda
& Hart (1973), Hand (1981), Agresti (1990), McCullagh & Nelder (1989). Fisher's
classical method logistic regression used model P (W j x) first time;
quadratic discriminant function used Lee & Mahajan (1988), however, without
considering Fisher's discriminant first.

2.1 Discriminant Functions Normally Distributed Features
Bayes' rule gives

j W )P (W )
= p(x j pW(x))P (W ) = p(x j W p)P(x(W
) + p(x j L)P (L)
,1

= 1 + pp((xxj jWL))PP ((LW)) ;
p(x j C ) features' conditional density function P (C ) priori probability
class C 2 fL; Wg. case priori probablities equal, features
multivariate normally distributed within class, i.e.
P (W j x )

p(x j C ) = (2 ), 2j j,1 2 exp
n=

C

=

n

, 21 (x , ),1(x , )0
C

C

C

mean vector covariance matrix C 2 fW ; Lg, follows
1
P (W j x) =
;
1 + exp(,f (x))
f following quadratic discriminant function:
C

f (x)



C

n



= , 21 x ,W1 , ,L 1 x0 + L ,L 1 , W ,W1 x0 +


1 ,1 0 , ,1 0 + log jW j , log jL j :
W
W
L
L
W
L
2

375

fiBuro

1.0

...........................................................
....................
............
..........
........
.
.
.
.
..
.......
.....
....
.....
....
....
.
.
...
....
.....
....
...
....
.
.
...
....
........................
...............................
......
.....
......
.
....
.... ....
....
....
.... ...... .....
....
...
.
.
.
.
.
......
...
..
....
.
.
.
.
.
.
....
.
.
.
........
....
.
.
.....
....
.
.
.
.
.
.
.
.
.
.....
.. ......
... ............
.
.
.
.
.
.
.
.....
.
......
.................
....
.....
.
.
.
.
.
.
.
.
.
.
.
.......
.......
................
....
.
.
.
.
......
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
........
....
...............
...........................................................................................................................................
........................................................................................................................................................................

0.5
0.0

L

x

W

Figure 1: Conditional densities winning probability
covariance matrices equal (=), expression simplified linear function:
f (x) = (W , L ),1 fx , (L + W )=2g0:
Interestingly, function solution problem finding linear transformation
maximizes ratio squared sample mean distance sum within{class
sample variances transformation. Therefore, good separator properties even
features normally distributed. called Fisher's linear discriminant. Figure 1
illustrates relation conditional densities winning probability.
maximum likelihood (ML) parameter estimates
1 Xx
^ =
C

jI j
C

^ = jI1 j

2C



X

C

C





2C



(x , ^ )0(x , ^ )


C



C



= j = C g. covariance matrices equal,
X X
^ = jI j 1+ jI j
(x , ^ )0(x , ^ ):
W
L 2fL Wg 2 C
C





C

;



C



C



2.2 Logistic Regression

logistic regression conditional winning probability P (W j x) depends linear
combination x . Here, X1 1 assumed order able model constant offsets.
simple approach P (W j x) = xfi using parameter column vector unusable
xfi 2 [0;1] cannot guaranteed generally. requirement fulfilled means
link{function g : (0;1) ! IR according g (P (W j x)) = xfi . Figure 2 shows typical
nonlinear relation winning probability one feature. Since probability
usually monotone increasing function features, g satisfy lim !0+ g (x) = ,1
lim !1, g (x) = +1. link{function g (t) = logit(t) := log(t=(1 , t))
properties. Using g = logit, since g ,1(x) = f1 + exp(,x)g,1 , follows
1
P (W j x) =
1 + exp(,xfi ) :


x

x

376

fiStatistical Feature Combination

Hence, winning probability shape discriminant analysis. logistic
regression require features multivariate normal; even use
discrete features possible.
parameter vector estimated using ML approach. Unfortunately,
case necessary solve system nonlinear equations. follows, known
solving approach brie described (cf. Agresti, 1990; McCullagh & Nelder, 1989).
order ensure convergence iterative algorithm given below, necessary
slightly
variable
P generalize model: observed value random
,1
=

,



:


!
f
0
;
1
g

mean

=
f
1
+
exp(
,
x

)
g
=1
stochastically independent. definition includes old model (n = 1 2 f0; 1g).
likelihood function L(fi), probability density, measures likely
see realization stochastically independent random variables , true
parameter vector. order maximize L, suces consider log(L):


n



j

i;j

i;j











log(L(fi)) = log


N

=1
XX


=

n

j

=1



(1 , )ni ,yi


N

=1

yx


ij




,

j



X
N

=1

X
N

=
h

=1





log + (n , ) log(1 , )



log 1 + exp

n







X
n

j

=1



x
ij

j






:

function twice differentiable, strictly concave rare border cases,
unique maximum location 0 < < n (cf. Wedderburn, 1976)
iteratively found using Newton{Raphson method follows:
( +1)
fi^
= (X 0( )X ),1 X 0( ) z ( )
















(N n){matrix X built x ,



( ) = diag[n ^ ( )(1 , ^( ))]; ^( ) = 1 + exp ,















n







n



j

^ ( )
, n ^ ( )
(
)
z = log
+
:
1 , ^ ( ) n ^ ( )(1 , ^ ( ))

=1

x fi^( )


ij

o,1

j







X











1.0
P (W j x) 0.5

0.0















.....................................
.......................................
.............
..........
.........
.......
.
.
.
.
.
.
....
.....
.....
.....
....
....
.
.
.
.
..
....
...
....
....
...
.
.
.
...
....
....
....
....
....
.
.
.
.
....
.....
......
.....
.......
.........
.
.
.
.
.
.
.
.
....
...................
..................................................................

x

Figure 2: Typical shape winning probability
377

;



fiBuro

Starting ^ (0) = (y +1=2)=(n +1), ML estimate fi^ may usually computed high
accuracy within steps since method quadratically convergent relatively robust
respect choice starting vector. Unfortunately, = 0
= n estimates might converge. original model approximated,
instance, setting n = 100 = 1 99, depending whether position
question lost won.
















3. Generation Classification Example Positions
Value adaptation requires labelled example positions. Here, problems arise. First
all, nontrivial games endgame positions classified correctly won,
drawn, lost; opening midgame positions optimal play reach due
lack game knowledge time constraints. Furthermore, example positions
contain significant feature variance since otherwise discrimination possible. Hence,
problematic use high level games | might first idea | since good
players programs know relevant features try maximize game.
Therefore, features tend constant time statistical methods would
assign small weights them. final diculty, estimating parameters accurately
different game phases requires many positions.
pragmatic \solution" problems indicated Figure 3: period
two years, 60,000 Othello games2 played early versions LOGISTELLO
- urd-anovic's program REV.3 Feature variance ensured examining openings
Igor
length seven led mostly unbalanced starting positions. Since early program
versions used 5{10 minutes thinking time, games, though well
played time, error free. cases even big mistakes occurred
which, example, one side fell corner losing trap4 caused lack look{ahead.
without errors, reasonable weight estimation principal features (such corner
possession Othello) possible explained above. Following Lee & Mahajan (1988),
positions classified final game results. approach problematic
classification reliability decreases endgame opening phase due player
mistakes. reduce effect, early outcome searches performed solving Othello
positions 20 moves game end. Furthermore, time time game database
searched \obvious" errors using new program versions longer searches correct
games. Since process many lines play repeated, misclassification
rate reduced propagating game results leaves root
game{tree, built games according NegaMax principle.
way classification position depends examined successors
therefore reliable.
proposed classification method relatively fast allows us label many positions
reasonable time (on average 42 new positions 10{20 minutes). addition
2. game file obtained via anonymous ftp.
(ftp.uni-paderborn.de/unix/othello/misc/database.zip)
3. brief description programs given help pages Internet Othello Server.
(telnet faust.uni-paderborn.de 5000)
4. implications compared losing material nothing chess.

378

fiStatistical Feature Combination

....................................................
.....................
............
............
.......
......
........
...
......
..
...
...
..
...
......
....
....
.......
.
.
.
.
.
..........
..........
.
................
.
.
.
.
.
.
.
.
.
.
.
.
.....................................................

.............
..........

.......
......
......
......
.......
.......
......
.......
..........
.........
...................
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.........................

Database consisting
ca. 60,000 games

L
W
L
W

W x
W
x L xD x
W
x xW x

..........
..... ...........
....
.....
......
....
......
....
..... ....
...................
..... ........
.
..
.
..
.
..
... ...
..... ......
............
......
.... ......
...
...
.
.
.
....
..
...
...
....
....
.
...
.........
.... ...
.
... ...
............

.......
.... ......
.
..
................

........................................................
....................
............
..........
........
........
.....
.....
...
....
..
..
..
..
....
....
.......
.....
......
.
.
.
.
.
.
............
...
..................................................................................

.............
..........

.........
.... ...
.
... ...
..... ...
..
.... .... ......
...
...
.
.
...
...
...
...
...
....
....

Game tree

.......
.
......
......
......
......
.......
.....
.........
........
...............
..........
............................................

2.5 Million
classified positions

Figure 3: classification process
ensuring accurate parameter estimation even different game phases (which indicated
small parameter confidence intervals), method enabled us develop new pattern
features Othello based estimating winning probability conditioned upon occurrence
sub{configurations, edge diagonal instances, board.5

4. Parameter Estimation Playing Strength Comparison

Although 5% example positions labelled drawn, decided
use parameter estimation since positions give exact information
feature balancing. natural way handle drawn positions within statistical evaluation
framework considered define winning probability 1=2 case.
extension logistic regression parameters easily determined setting = n =2
case draw. Alternatively, doubling lost positions incorporating drawn
positions lost leads estimate log likelihood
functions equal constant factor. latter technique used fitting
models.
Previous experiments showed parameters depend game phase,
disc count adequate measure Othello. example positions grouped according number discs board, adjacent groups used parameter
estimation order smooth data ensure almost equal numbers lost
positions.
success Othello program BILL described Lee & Mahajan (1990) shows
Othello table{based features quite effective. instance, important edge
structure quickly evaluated adding four pre{computed edge evaluations
stored table. 13 features used LOGISTELLO table{based. fall
two groups: first group pattern instances including horizontal, vertical,
diagonal lines board evaluated second group two mobility measures
computed.5
parameter estimation three described models, tournaments players QUAD (which uses quadratic discriminant function normally distributed features),




5. Details given Buro (1994). postscript file thesis obtained via anonymous ftp.

379

fiBuro

Pairing
LOG , QUAD
FISHER , QUAD
LOG , FISHER
LOG , FISHER
LOG , QUAD
FISHER , QUAD
LOG , QUAD

Time per game
Result
Winning
(Minutes)
(Win,Draw,Loss) Percentage
30 , 30
30 , 30
30 , 30
30 , 36
30 , 38
30 , 38
30 , 45

116 , 15 , 69
112 , 15 , 73
93 , 35 , 72
86 , 24 , 90
93 , 33 , 74
84 , 30 , 86
88 , 26 , 86

61.8%
59.8%
55.3%
49.0%
54.8%
49.5%
50.5%

Table 1: Tournament results
FISHER, LOG played order determine best tournament player. Starting
100 nearly even opening positions 14 discs (i.e. move 11) LOGISTELLO's opening book, game return game colours reversed played.6

opening midgame phase program versions performed usual iterative deepening NegaScout searches (Reinefeld, 1983) selective corner quiescence search extension.
Endgame positions 22 empty squares solved win{draw{loss searches.
pattern learning tournaments, facility think opponent's time turned order speed tournaments run parallel
seven SUN SPARC{10 workstations.
Applying conservative statistical test5 seen results listed Table 1
stating winning percentage greater 59% statistically significant 5% level.
first two results show clear advantage linear combinations normal tournament
conditions (30 minutes per player per game). Furthermore, since LOG outperforms FISHER
features would seem even approximately normally distributed. lies
advantage logistic regression: even discrete features castling status chess
parity Othello used.
tournaments played time weaker players FISHER
QUAD order determine time factors lead equal playing strength.
shown Table 1 FISHER reaches LOG's strength given 20% time,
QUAD needs 50% time compete LOG. LOGISTELLO's optimized
implementation, search speed using quadratic combination still 20%
slower linear combination. Thus, giving QUAD 25% time (1=(1 ,
0:2) = 1:25) balances total number nodes searched game. even
timing, LOG stronger QUAD, FISHER still compete it. all,
quadratic combination slower linear combination,
better discrimination properties. Indeed, look estimated covariance matrices
6. LOG's 11{ply evaluation positions lies range [,0:4; +0:4] corresponds winning
probabilities range [0:4; 0:6]. nearly even starting positions used compare
programs similar playing strength since clear positions colour determines winner
winning percentage would 50% even one player stronger. 100 starting positions six
always led game pairs balanced score.

380

fiStatistical Feature Combination

class revealed almost equal, therefore better evaluation quality
Fisher's linear discriminant could expected.

5. Discussion

paper three statistical approaches modelling evaluation functions game{
phase{independent meaning presented compared empirically using world{
class Othello program. Quadratic feature combinations necessarily lead stronger
programs linear combinations since evaluation speed drop significantly.
course, effect depends number features used evaluation speed:
features used takes long time evaluate them, playing strength
differences cannot explained different speeds case evaluation times
almost equal. case, using quadratic combinations covariance matrices
compared; (almost) equal, quadratic terms omitted
Fisher's linear discriminant used. Therefore, motivations Lee & Mahajan (1988)
need refinement, since existing feature correlation necessarily justify use
nonlinear combinations. Generally, possibly accurate nonlinear feature combinations
(such ANNs) compared simpler faster approaches practice, since
use always guarantee greater playing strength.
Besides linear regression discriminant analysis, logistic regression proven
suitable tool construction evaluation functions global interpretation.
drawback, parameter estimation system nonlinear equations solved,
compensated higher quality evaluation function comparison
approaches, since application parameters determined
once. current tournament version LOGISTELLO uses feature weights estimated
means logistic regression profits comparability evaluations different
game phases ensured use value adaptation. result possible
perform selective searches values different game phases compared;
moreover, values opening compared even late midgame values order
find promising move alternatives program's opening book (Buro 1994,1995).
sense, value comparability cornerstone LOGISTELLO's strength.

Acknowledgements
wish thank wife Karen competently answering many statistical questions.
- urd-anovic many fruitful discussions led
thank colleague Igor
considerable improvements Othello programs. Furthermore, grateful Colin
Springer, Richard E. Korf, anonymous referees useful suggestions earlier
versions paper, helped improve presentation contents.

References

Agresti, A. (1990). Categorical Data Analysis. Wiley.
Buro, M. (1994). Techniken fur die Bewertung von Spielsituationen anhand von Beispielen.
Ph.D. thesis, University Paderborn, Germany.
(ftp.uni-paderborn.de/unix/othello/ps-files/mics_dis.ps.gz)

381

fiBuro

Buro, M. (1995). L'apprentissage des ouvertures chez Logistello. Magazine de la Federation
Francaise d'Othello FFORUM 37, 18{20.
Duda, R., Hart, P. (1973). Pattern Classification Scene Analysis. Wiley.
Hand, D.J. (1981). Discrimination Classification. Wiley.
Lee, K.F., Mahajan, S. (1988). Pattern Classification Approach Evaluation Function
Learning. Artificial Intelligence 36, 1{25.
Lee, K.F., Mahajan, S. (1990). Development World Class Othello Program. Artificial
Intelligence 43, 21{36.
Marsland, T.A. (1985). Evaluation Function Factors. ICCA Journal 8(2).
McCullagh, P., Nelder, J.A. (1989). Generalized Linear Models. Chapman & Hall.
van den Meulen, M. (1989). Weight Assesment Evaluation Functions. In: D.F. Beal
(Editor), Advances Computer Chess 5, Elsevier Science Publishers.
Mitchell, D.H. (1984). Using Features Evaluate Positions Experts' Novices' Othello
Games. Master Thesis, Northwestern University, Evanston Illinois U.S.A.
Moriarty, D., Miikkulainen, R. (1993). Evolving Complex Othello Strategies Using Marker{
Based Genetic Encoding Neural Networks. Tech. rep. AI93{206, Department
Computer Sciences, University Texas Austin.
Mysliwietz, P. (1994). Konstruktion und Optimierung von Bewertungsfunktionen beim
Schach. Ph.D. thesis, University Paderborn, Germany.
Reinefeld, A. (1983). Improvement Scout Tree Search Algorithm. ICCA Journal
6(4), 4{14.
Samuel, A.L. (1959). Studies Machine Learning Using Game Checkers. IBM
Journal Research Development 3, 210{229.
Samuel, A.L. (1967). Studies Machine Learning Using Game Checkers II.
IBM Journal Research Development 11, 601{617.
Schaeffer, J., Culberson, J., Treloar, N., Knight, B., Lu, P., Szafron, D. (1992). World
Championship Caliber Checkers Program. Artificial Intelligence 53, 273{289.
Sutton, R.S. (1988). Learning Predict Methods Temporal Differences. Machine
Learning 3, 9{44.
Tesauro, G. (1992). Practical Issues Temporal Difference Learning. Machine Learning 8,
257{277.
Tesauro, G. (1994). TD{Gammon, Self{Teaching Backgammon Program, Achieves
Master{Level Play. Neural Computation 6, 215{219.
Tesauro, G. (1995). Temporal Difference Learning TD{Gammon. Communications
ACM 38(3), 58{68.
Wedderburn, R.W.M. (1976). Existence Uniqueness Maximum Likelihood
Estimates Certain Generalized Linear Models. Biometrika 63, 27{32.
382


