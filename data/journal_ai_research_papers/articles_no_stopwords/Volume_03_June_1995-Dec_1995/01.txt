Journal Artificial Intelligence Research 3 (1995) 25-52

Submitted 8/94; published 6/95

FLECS: Planning Flexible Commitment Strategy
Manuela Veloso
Peter Stone

Department Computer Science, Carnegie Mellon University
Pittsburgh, PA 15213-3891 USA

veloso@cs.cmu.edu
pstone@cs.cmu.edu

Abstract
evidence least-commitment planners eciently handle planning
problems involve dicult goal interactions. evidence led common belief
delayed-commitment \best" possible planning strategy. However, recently
found evidence eager-commitment planners handle variety planning problems
eciently, particular dicult operator choices. Resigned futility
trying find universally successful planning strategy, devised planner
used study domains problems best planning strategies.
article introduce new planning algorithm, flecs, uses FLExible
Commitment Strategy respect plan-step orderings. able use strategy
delayed-commitment eager-commitment. combination delayed eager
operator-ordering commitments allows flecs take advantage benefits explicitly
using simulated execution state reasoning planning constraints. flecs vary
commitment strategy across different problems domains, course
single planning problem. flecs represents novel contribution planning
explicitly provides choice commitment strategy use planning. flecs
provides framework investigate mapping planning domains problems
ecient planning strategies.

1. Introduction
General-purpose planning long history research Artificial Intelligence. Several
different planning algorithms developed ranging pioneering GPS (Ernst
& Newell, 1969) variety recent algorithms SNLP (McAllester & Rosenblitt,
1991) family. basic level, purpose planning find sequence
actions change initial state state satisfies goal statement. Planners use
actions provided domain representations try achieve goal. However
different planners use different means end.
Faced variety different planning algorithms, planning researchers, including authors, increasingly curious compare different planning methodologies. Although general-purpose planning known undecidable (Chapman, 1987),
common belief least-commitment planning \best," i.e., efficient planning strategy planning problems. belief based evidence
least-commitment planners eciently handle planning problems involve dicult
plan step interactions (Barrett & Weld, 1994; Kambhampati, 1994; Minton, Bresina, &
Drummond, 1991). Delayed commitments, particular step orderings, allow plan

c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiVeloso & Stone

steps remain unordered interactions visible.1 similar situations, eagercommitment planners may encounter severe eciency problems early commitments
incorrect orderings.
Recently engaged investigation sorts planning problems would
handled eciently planning strategies. Since planning driven heuristics,
identified different sets heuristics correspond different planning methods.
designed sets planning domains problems test different planning strategies.
studying impact different strategies different kinds planning problems,
came across evidence eager-commitment planners eciently handle variety
planning problems, particular dicult operator choices (Stone, Veloso,
& Blythe, 1994). up-to-date state allows make informed planning choices,
particularly terms operator alternatives available. similar situations, delayedcommitment planners may need backtrack incorrect operator choices (Veloso &
Blythe, 1994). came believe planner consistently better others
across different domains problems.
Resigned futility trying find universally successful planning strategy,
felt need study domains problems best suited planning
methods.2 order so, devised implemented planner use
operator-ordering commitment strategy along continuum between, one extreme
delayed commitment, other, eager commitment. planner completely
exible along one dimension planning heuristics: operator-ordering commitments.
main contribution paper completely describe planning algorithm
put forth tool studying mapping heuristics domains problems.
Rather risking possibility planner might get overlooked
relegated \architecture" section future paper, present flecs underlying
philosophy contribution right.
continuum heuristics explored planning algorithm lies
operator-ordering commitment strategies delayed-commitment eager-commitment
backward-chaining planners, situate within broad range planning
problem solving methods. One possible planning strategy search possible states
reached initial state find one satisfies goal. method,
called progression forward-chaining, impractical. often many
accessible states world eciently search complete state space. alternative, several planners constrain search using regression, backward-chaining.
Rather considering possible actions could executed initial state
searching recursively forward state space, search backwards goal.
search driven set actions directly achieve goal.
two main ways performing backward-chaining. Several planners regression searching space possible plans. Planners, noah, tweak, snlp,
1. Least-commitment planners really delay commitments plan step orderings variable bindings.
Throughout article use term delayed commitment contrast eager commitment
context step orderings.
2. Similar concerns regarding different constraint satisfaction algorithms led recently design
Multi-Tac architecture (Minton, 1993). system investigates given problem find
combination heuristics collection available ones solve problem ecient way.

26

fiflecs: Planning Flexible Commitment Strategy

descendants (Chapman, 1987; McAllester & Rosenblitt, 1991; McDermott, 1978;
Sacerdoti, 1977; Tate, 1977; Wilkins, 1984) plan-space planners use delayedcommitment strategy. particular, delay decision ordering operators long
possible. Consequently, planner reasons initial state set
constraints regressed goal. hand, planners gps,
strips, prodigy family (Carbonell, Knoblock, & Minton, 1990; Fikes & Nilsson,
1971; Rosenbloom, Newell, & Laird, 1990) use eager-commitment strategy.3 use
backward-chaining select plan steps relevant goals. eager-commitment planners make explicit use internal representation state world (their internal
state) order operators possible reason updated version
state. trade risk eager commitment benefits using explicit
updated planning state.
article introduce planning algorithm, flecs, uses FLExible Commitment Strategy respect operator orderings. flecs designed provide us
planning researchers framework investigate mapping domains
problems ecient planning strategies. algorithm represents novel contribution
planning introduces explicitly choice commitment strategy.
ability change commitment strategy makes useful studying tradeoffs
delayed eager commitments. flecs descendant prodigy4.0 current
implementation directly top prodigy4.0. extends prodigy4.0 reasoning
explicitly ordering alternatives ability change commitment
strategy across different problems domains, course single
planning problem.4
article gradually introduces flecs. Section 2 gives top-level view algorithm
describes different ways flecs makes use uniquely specified state
world. Section 3 introduces concepts used flecs algorithm. provide
annotated example illustrate details planning concepts defined. Section 4
presents flecs's planning algorithm full detail explains algorithm step step.
discuss different heuristics guide flecs's choices, particular exible choice
commitment strategy. analyze advantages disadvantages delayed eager
plan step ordering commitments. Section 5 shows specific examples planning domains
problems devised, support need use flecs's exible commitment
strategy. performed empirical analysis planning performance domains.
corresponding empirical results demonstrate tradeoffs discussed show evidence
exible commitment necessary. Finally Section 6 draws conclusions work.
3. Planners prodigy family include prodigy2.0 (Minton, Knoblock, Kuokka, Gil, Joseph, & Carbonell, 1989), NoLimit (Veloso, 1989), prodigy4.0 (Carbonell, Blythe, Etzioni, Gil, Joseph, Kahn,
Knoblock, Minton, Perez, Reilly, Veloso, & Wang, 1992). NoLimit prodigy4.0, opposed
prodigy2.0, require linearity assumption goal independence search spaces
complete (Fink & Veloso, 1994). control commitment choices opposed
earlier total-order planners.
4. found needed new name algorithm flecs represents significant change
philosophy implementation prodigy4.0.

27

fiVeloso & Stone

2. Top-Level View flecs
prodigy4.0 flecs differ significantly state-of-the-art planning systems

search solution planning problem combining backward-chaining (or
regression) simulation plan execution (Fink & Veloso, 1994). back-chaining,
commit total-ordering plan steps make use uniquely specified
world state. planners maintain internal representation state update
simulating execution operators found relevant goal backward-chaining. Note
simulating execution planning differs interleaving planning execution,
since option \un-simulating," rolling back, must remain open. Interleaved planning
execution generally done separate modules planning, monitoring, executing,
replanning (Ambros-Ingerson & Steel, 1988). flecs either delay eagerly carry
plan simulation. way, planning algorithm exibility
able delay operator-ordering commitments able use effects previously
selected operators help determine goals plan next operators
use achieve goals. short, emulate delayed-commitment planners
eager-commitment planners.
Table 1 shows top-level view flecs algorithm.
1. Initialize.
2. Terminate goal statement satisfied.
3. Compute pending goals applicable operators.
Pending goals yet-to-be-achieved preconditions operators
selected plan.
Applicable operators preconditions satisfied
current state.
5. Choose subgoal apply: (backtrack point)
subgoal, go step 6.
apply, go step 7.
6. Select pending goal (no backtrack point) operator achieve (backtrack point); go step 3.
7. Change state specified applicable operator (backtrack point); go step 2.
Table 1: top-level view flecs. step numbers made correspond
step numbers detailed version algorithm presented Table 2
(Section 4), refines steps adds additional necessary step 4.
terms used table fully described along detailed version
algorithm Section 4. section focus two main characteristics algorithm,
namely use internal state exibility respect commitment strategies.
28

fiflecs: Planning Flexible Commitment Strategy

2.1 Use Simulated Planning State
flecs uses internal state least four purposes. First, terminates every goal

given problem satisfied current version state (the current state):
point, complete plan (the sequence operators transformed initial state
current state) created planning process stop. Second, every
cycle, algorithm uses internal state determine goals need planned
already achieved following means-ends analysis strategy. Unlike
planners analyze possible effects operators may
changed initial state, flecs simply checks particular goal true current
state.5 Third, planner uses state determine operators may applied:
i.e., whose preconditions true state. Fourth, flecs use state
choose operator bindings likely achieve particular goal
minimum planning effort (Blythe & Veloso, 1992). summary, reference
algorithm Table 1, flecs uses state determine:






goal statement satisfied (step 2);
goals still need achieved (step 3);
operators applicable (step 3);
operators try first planning (step 6).

planners keep internal state, four steps require considerable
planning effort even attempted all. contrast, flecs perform
steps sub-quadratic time. Furthermore, planners particular
methods choosing among possible operators achieve goal. particular use
state shown provide significant eciency gains prodigy4.0 (Veloso & Blythe,
1994).
Since flecs use state, makes big difference whether chooses
change state (apply operator) given time. advantage applying operator
informed planning results four steps. However,
choice apply operator involves commitment order operator operators yet applied. commitment temporary since plan
found operator position, operator \un-applied" simply
changing internal state back previous status. One may argue requirement operators applied explicit order opens possibility exponential
backtracking. However argument vacuous, planning undecidable (Chapman,
1987). Due use state, flecs reduce likelihood requiring backtracking
operator choice point. doing, may increase likelihood backtracking
operator-ordering choice point. However, exibility able come
either side tradeoff.
5. Note since goal state fully instantiated, matching accomplished
constant time goal using hash table literals.

29

fiVeloso & Stone

2.2 Choice Commitment Strategies

order control tradeoff eager delayed state changes, flecs
toggle determines whether algorithm prefers subgoaling applying operator
step 5. option flecs considers first may affect path search space
consequently planning eciency. ability accommodate different types
search novel part algorithm. significance lies difference
subgoaling applying.
difference subgoaling applying illustrated Figure 1. Subgoaling
best understood regressing one goal, backward chaining, using means-ends
analysis. includes choices goal plan operator achieve goal.
seen Section 2.1, choices affected flecs's internal state. Thus,
subgoaling without ever updating internal state (applying operator) lead
uninformed planning decisions. hand, subgoaling extensively, flecs
select large set operators appear plan deciding order
apply them. flecs takes account con icts, \threats," among operators
orders appropriately applying them.
x




C

z

G



x



x




z

C




G



C



z

G

Subgoaling

Applying

Operator achieves precondition
operator true state C.

preconditions operator x true state C.
Applying x changes state C.

Figure 1: diagram (Fink & Veloso, 1994) illustrates difference subgoaling applying. search node consisting \head-plan" \tailplan." head-plan contains operators already applied
changed initial state \I" current state \C." tail-plan consists
operators selected achieve goals goal statement \G"
operators selected achieve preconditions operators,
etc. figure shows planner could either subgoal apply given
search node.
Applying operator flecs's way changing current internal state
future subgoaling decisions informed. However, applying operator commitment (temporary since backtracking possible) operator executed
30

fiflecs: Planning Flexible Commitment Strategy

other. essential tradeoff eagerly subgoaling eagerly
applying: eagerly subgoaling delays ordering commitments (delayed commitment),
eagerly applying facilitates informed subgoaling (eager commitment).
flecs switch (toggle) change behavior eager subgoaling
eager applying vice versa time. feature significant improvement flecs prodigy4.0 predecessors. Since saw evidence neither delayed-commitment eager-commitment search strategies consistently effective (Stone et al., 1994), felt need provide flecs toggle. Thus, flecs
combine advantages delayed commitments eager commitments.6

3. Illustrative Example

section present example illustrates detail planning situations
arise general planning problem. Although planning may well understood
general, past descriptions planning algorithms directly addressed
situations full detail. flecs algorithm designed handle situations.
order describe flecs completely, need define several variables
maintained algorithm proceeds. Since much easier understand algorithm
one familiar concepts variables denote, present annotated
example Figures 2 9 formally presenting flecs. recommend
following variables functions C , G , P , O, A, a, c change throughout
annotated example, according definitions:
C represents current internal state planner. uses summarized
Section 2.1.
G set goals subgoals planner aiming achieve.
goals fringe subgoal tree. Goals G may goals
yet planned for, goals achieved (perhaps trivially) yet
used operator needs one preconditions (i.e., operator
applied yet).
P set pending goals: goals G may need planned current
state.
stands set instantiated operators selected achieve goals
subgoals.
set applicable operators: operators whose preconditions satisfied
current state needed current state achieve goal.
goal G, a(G) set ancestor goal sets { sequences goals
caused G become member G . Trivially, goal ancestor
preconditions operator selected achieve goal. a(G) set sets
G different sets ancestors. concept become clearer
example.
6. Section 5 discuss different heuristics guide choice discuss view toggle
perfect focus learning.

31

fiVeloso & Stone

operator O, c(O) set goals selected achieve { causes.
Applying establishes member c(O). illustrated below, functions
c needed determine goals pending operators
applicable. analogous causal links used determine threats
planners (Chapman, 1987; McAllester & Rosenblitt, 1991).

sequence planning decisions example (Figure 2 Figure 9) designed illustrate uses flecs's variables functions. recommend
becoming familiar spending time carefully tracing values returning definitions throughout example. Note figures show
tail-plan mention applied operators state changes text. Goals
circles: solid circles true dashed circles true current
state. Operators boxes arrows pointing goals \produce,"
i.e., goals operators selected achieve (their causes). turn,
preconditions operators goals arrows pointing operators
\consume" them. Operators applicable current state appear bold boxes.
Changes functions c underlined captions.
present example. Figure 2 shows initial planning situation,
consider planning problem three literals goal statement, G1 , G2, G3 , i.e.,
G = fG1; G2; G3g. one literal initial state, G7, i.e., C = fG7g. none
goals true initial state, P = G . operators selected, i.e., = ;,
therefore operators applicable, i.e., = ;. point, since
top-level goals, none goals ancestors: a(G1) = a(G2) = a(G3) = ;.
applicable operators, next step must subgoal one pending goals.

C = fG7g
G = fG1; G2; G3g
O=;
P = fG1; G2; G3g
A=;

G

G

G

1

2

3

Figure 2: example: initial specification planning situation.
Figure 3 shows planning situation flecs subgoals G1 G2 . Suppose
operator O1 , preconditions G6 G7 , selected achieve G1, O2 chosen
achieve G2 indicated below. Note operators' preconditions replace
causes set fringe goals G ; since G7 true current state, included
set pending goals P . G1 cause O1, c(O1) = fG1g; similarly,
32

fiflecs: Planning Flexible Commitment Strategy

c(O2) = fG2g. new goals nonempty ancestor sets: a(G6) = a(G7) = ffG1gg,
a(G4) = ffG2gg. still applicable operators: O1 cannot applied
G6 62 C O2 cannot applied G4 62 C . Therefore, flecs subgoals again.

C = fG7g
G = fG3; G6; G7; G4g
= fO1; O2g
P = fG3; G6; G4g
A=;
G

G

G

7

6

4





1

2

G

G

G

1

2

3

Figure 3: Resulting planning situation subgoaling G1 G2 .
Figure 4 shows planning situation flecs subgoals G3 . Suppose
operator selected achieve G3 preconditions G4 G5 . c(O3) = fG3 g,
a(G5) = ffG3gg. causes operators O1 O2 change, c(O1) = fG1g
c(O2) = fG2g previous step. Similarly, a(G6 ) a(G7) remain unchanged.
However, G4 two sets ancestor goals: a(G4) = ffG2g; fG3gg. understand
need keep ancestor sets, consider possibility G2 could achieved
unexpectedly side-effect unrelated operator instead achieved O2
planned for. case, G4 would remain pending goal since would needed
achieve G3. Again, since applicable operators, flecs must subgoal one
pending goals, i.e., G6, G4, G5.

C = fG7g
G = fG6; G7; G4; G5g
= fO1; O2; O3g
P = fG6; G4; G5g
A=;
G

7

G

G

G

6

4

5







1

2

3

Figure 4: Resulting planning situation subgoaling G3 .
33

G

G

G

1

2

3

fiVeloso & Stone

Figure 5 shows planning situation flecs subgoals G4 . Suppose O4
| operator precondition G7 | selected achieve G4 . Since G7 true
current state, O4 first applicable operator. Note necessarily ordered
O2 O3 since cause precondition operators. usual, cause
new operator stored: c(O4) = fG4 g. addition, ancestors G7 must augmented
include two new ancestor sets: a(G7) = ffG1g; fG4; G2g; fG4; G3gg. Although
applicable operator, let us assume flecs chooses delay commitment
order O4 first step plan subgoals pending goal.

C = fG7g
G = fG6; G7; G5g
= fO1; O2; O3; O4g
P = fG6; G5g
= fO4g
G

7

G



4

G

G

6

4

5







G

1

G

2

G

3

1

2

3

Figure 5: Resulting planning situation subgoaling G4 .
Figure 6 shows planning situation flecs subgoals G5 . Suppose operator O4 achieve G5 selected so. need update
causes operator ancestors precondition: c(O4) = fG4; G5g
a(G7) = ffG1g; fG4; G2g, fG4; G3g; fG5; G3gg. rather subgoaling last remaining pending goal (G6), let us apply O4 . Note decision corresponds early
commitment terms ordering operators O1 , O4, operators later selected
achieve G6 unordered current planning constraints. flecs changes
delayed-commitment strategy eager-commitment strategy.
C = fG7g
G = fG6; G7g
G
6
G

= fO1; O2; O3; O4g
1
1
P = fG6g
= fO4g
G

7



4

G

G

4

5





2

3

G

G

Figure 6: Resulting planning situation subgoaling G5 .
34

2

3

fiflecs: Planning Flexible Commitment Strategy

Figure 7 shows planning situation flecs applied O4 . Since operator O4
applied order achieve goals G4 G5, true current state
back fringe goal tree, i.e., C G . Notice stay G
eventually \consumed" O2 O3. However, since true
current state, pending goals. Since G7 precondition
one selected operator, a(G7) = ffG1gg before. O2 O3 applicable
preconditions true current state thanks O4. Let us assume
flecs maintains eager-commitment strategy continues applying applicable operators. flecs orders O2 O3, since O3 deletes precondition O2 (effects
shown).
C = fG7; G4; G5g
G = fG6; G7; G4; G5g
G
= fO1; O2; O3g

6
G
1
1
P = fG6g
= fO2; O3g
G

7

G

G

4

5





2

3

G

G

2

3

Figure 7: Resulting planning situation applying O4 Figure 6.
Figure 8 shows planning situation flecs applied O2. Suppose that, although
selected so, operator O2 achieves G1 side-effect. Perhaps O2
conditional effect visible planner, perhaps O1 simply looked
promising O2 operator achieve G1 time selected.

C = fG7; G4; G5; G1; G2g
G = fG6; G7; G4; G5; G2g
= fO1; O3g
P=;
= fO3g
G

7

G

G

G

6



1

G

4

5

G



3

G

1

2

3

Figure 8: Resulting planning situation applying O2 Figure 7.
35

fiVeloso & Stone

case, G1 C planning done longer needed: G6 longer
pending goal, since sole ancestor already C . fortuitous achievement goal
reason need use functions c adjust sets pending goals
P applicable operators A: would wasted effort flecs plan achieve G6.
Note G6 precondition O3 well O1, would pending goal since
would still relevant achieving G3 . point, ancestors G4 must
reset: a(G4) = ffG3gg. Since pending goals, flecs must apply
last remaining applicable operator, O3.
Figure 9 shows final planning situation flecs applied O3 . point
top level goals true current state. Despite fact planning
tree remains, flecs recognizes work done terminates.
final plan O4, O2, O3 , sequence operators applied head-plan (not
shown) corresponding steps Figures 7, 8, 9. posteriori algorithm (Veloso,
Perez, & Carbonell, 1990) convert sequence partially ordered plan capturing
dependencies: O4 ; fO2; O3g.

C = fG7; G4; G5; G1; G2; G3g
G = fG6; G7; G2; G3g
= fO1g
P=;
A=;
G

G

6



1

G

G

7

G

1

2

3

Figure 9: Final planning situation applying O3 Figure 8.

4. FLECS: Detailed Description
Aside variables functions introduced preceding section, need
define four things presenting complete algorithm. First, Initial State
Goal Statement corresponding ground literals problem definition. Second, given operator O, pre(O), add(O), del(O) instantiated preconditions,
add-list, delete-list respectively. flecs takes values straight domain representation, may include disjunctions, negations, existentially universally quantified preconditions effects, conditional effects (Carbonell et al., 1992).
conditional effects, add(O) del(O) determined dynamically, using state
time applied. Third, \relevant instantiated operators could achieve G"
(step 6) instantiated operators (operators fully-specified bindings)
36

fiflecs: Planning Flexible Commitment Strategy

G 2 add(O) G positive goal G 2 del(O) G negative goal. Fourth, toggle
variable determines avor search, described later.

4.1 Planning Algorithm
present flecs planning algorithm full detail Table 2.7 examining algorithm, notice fringe goals G , selected operators O, ancestor function a(G),
cause function c(O), current state C maintained incrementally.
hand, pending goals P , applicable operators A, toggle recomputed every
pass algorithm.
Step 1 initializes variables. beginning planning process,
goals G goal statement, current state C initial
state, since operators yet selected, empty. ancestor function
cause function c initialized constant function maps everything ;.
practice, domain set goals domain c set operators
appear problem. However, since goals operators
determined algorithm first called, must initialize functions
unrestricted domains.
Step 2 termination condition. called time new operator
applied. algorithm terminates successfully every goal G goal statement true,
satisfied, current state C , i.e., G 2 C .
step 3, sets pending goals applicable operators computed based
current state. Pending goals goals planner may need plan for. Initially,
pending goals fringe goals currently true true
initial state.8 applicable operators selected operators whose preconditions
true state.
Then, step 4 computes pending goals P applicable operators active
current state. pending goal active long fringe subgoal tree
still needs planned for. goal longer active every one ancestor sets
least one goal already achieved: purposes goal
selected longer exist (as case G6 Figure 8). applicable operator
active current state long would achieve goal still useful plan.
applicable operator longer active causes either true current
state longer active.
Step 5 novel part algorithm. allows exible search strategy
within single planning algorithm. Since step, flecs yet terminated,
must either active pending goals active applicable operators, i.e., P must
non-empty. However, one other, choice
made. If, hand, P non-empty, either proceed
step 6 step 7. sake completeness, must keep options open;
option flecs considers first may affect amount search required. changing
7. detail algorithm allows reader carefully study re-implement flecs.
8. Since planner cannot backtrack beyond initial state, must keep goals initial state
pending goals sake completeness.

37

fiVeloso & Stone

1. Initialize:
C : current state
a. G = Goal Statement.
G : fringe goals
b. C = Initial State.
P : pending goals
c. = ;.

: instantiated operators
d. 8G:a(G) = ;.

: applicable operators
e. 8O:c(O) = ;.
a: ancestor goal sets
c: causes
2. Terminate Goal Statement C .
3. Compute applicable operators pending goals P :
a. P = fG 2 G j G 62 C _ G 2 Initial Stateg.
b. = fA 2 j pre(A) Cg.
4. Adjust P contain active members:
a. P = P , fP 2 P j 8S 2 a(P ):9G 2 s.t. G 2 Cg.
b. = , fA 2 j 8G 2 c(A):[(G 2 C ) _ (8S 2 a(G):9G 2 s.t. G 2 C )]g.
5. Subgoal Apply:
a. Set reset toggle sub app, i.e. Set default delayed eager commitment.
b. = ;, go step 6.
c. P = ;, go step 7.
d. Choose apply subgoal (backtrack point):
toggle = sub ^ P 6 C , subgoal first: go step 6.
toggle = app, apply first: go step 7.
6. Choose goal P P (not backtrack point).
Choose goal true Current State using means-ends analysis.
a. Get set R relevant instantiated operators could achieve P .
b. R = ;
i. P = P , fP g.
ii. P = ; fail (i.e., backtrack).
iii. Go step 6.
c. Choose operator R (backtrack point).
Choose operator minimum conspiracy number, i.e. operator
appears achievable least amount planning.
d. = [ fOg.
e. G = (G , fP g) [ pre(O).
f. c(O) = c(O) [ fP g.
g. 8G 2 pre(O):a(G) = a(G) [ ffP g [ j 2 a(P )g.
h. Go step 3.
7. Choose operator (backtrack point interactions).
Use heuristic find operators fewer interactions { similar one used
SABA heuristic.
a. Apply A: C = (C [ add(A)) , del(A)
b. = , fAg.
c. 8G 2 pre(A):a(G) = a(G) , fS 2 a(G) j \ c(A) 6= ;g.
d. G = (G [ c(A)) , fG 2 pre(A) j a(G) = ;g.
e. c(A) = ;.
f. Go step 2.
0

Table 2: full description flecs.
38

0

fiflecs: Planning Flexible Commitment Strategy

value toggle, done pass loop, flecs change
type search works problem.
pass body algorithm visits either step 6 step 7.
subgoaling (step 6), active pending goal P chosen P . Note unlike
corresponding choice step 7, choice subgoals backtrack point. However,
operators could achieve goal, another goal chosen (step 6b).
Means-ends analysis used heuristic prefer subgoaling goals currently
true. Next, operator chosen could achieve chosen goal (step 6c).
either new operator existing one Figure 6 (O4, already
selected achieve G4, selected achieve G5). choice operator backtrack
point. Unless heuristic provided, minimum conspiracy number heuristic
used determine operator tried first (Blythe & Veloso, 1992). short,
heuristic selects instantiated operator appears achievable least
amount planning.
returning top loop, affected variables updated. First,
added using set union operator never appears twice (step 6d).
Second, O's preconditions added G , P removed (step 6e): P
operator selected achieve it, longer fringe subgoal tree. Third,
cause augmented include P (step 6f). Fourth, ancestor sets O's preconditions
augmented include sets goals comprised P ancestors (step 6g).
explained Figure 4, ancestor sets must included. Finally, since state
changed all, termination condition cannot met. algorithm returns step 3.
applying operator (step 7), applicable operator chosen A.
heuristic analyzes applicable operators used choose best possible operator. One heuristic analyzes interactions operators identifying
negative threats, similarly saba heuristic (Stone et al., 1994). short,
heuristic prefers operators delete preconditions of, whose effects
deleted by, operators. choice applicable operator backtrack point
orderings interacting applicable operators considered. Different orderings
completely independent operators need considered. Completely independent operators interactions neither among ancestor
sets. Since application one operator make difference application
another, need consider one ordering operators.
chosen, promptly applied (step 7a). application involves changing
current state prescribed A. Note conditional effects, expanded
point. Next, relevant variables updated. First, updating involves removing
set selected operators (step 7b). Second, ancestors A's preconditions
ancestor sets include (step 7c): need
planning. Figure 7 shows example precondition (G7) still
ancestor remaining. Third, since applied, preconditions goals
reason longer fringe, causes (step 7d):
unachieved must re-achieved. Fourth, case ever selected operator
achieve goal, c(A) reset ; (step 7e). Finally, since current state
altered, algorithm returns step 2 termination condition checked.
39

fiVeloso & Stone

4.2 Discussion: Backtracking, Heuristics, Properties
One pay close attention placement backtrack points algorithm.
particular, three: subgoal/apply choice step 5, choice operator
achieve goal step 6, choice applicable operator step 7. However,
choice goal subgoal step 6, backtrack point prodigy
algorithm, backtrack point here. flecs need backtrack point
choice apply apply operator given time left open step 5
significantly different orders applying applicable operators considered step 7.
explained previous subsection, different orderings completely independent operators considered. Nevertheless, orderings could lead solution
considered. Therefore, backtracking choice subgoal would cause redundant
search. elimination backtrack point significant improvement flecs
previous implementations, namely NoLimit prodigy4.0. Note new backtrack
points added offset eliminated backtrack point.
flecs's explicit failure point step 6 occurs algorithm chosen
subgoal, none pending goals relevant operators. failures
implicit. is, backtrack point, choices unsuccessfully tried
algorithm backtracks. presented, algorithm terminates unsuccessfully
entire search space exhausted. causes failure, goal loops,
state loops, depth bounds, time limits, incorporated manner
prodigy4.0 (Carbonell et al., 1992).
choice point, heuristic determine branch try (first).
step 6, goal chosen using means-ends analysis, operator minimum
conspiracy number chosen achieve goal. step 7, choice mechanism
saba heuristic used determine applicable operator try first. step 5,
toggle, changed time, determines whether default commitment
strategy eager subgoaling eager applying. Note pending goals
true Current State (or pending goals), planner may apply
applicable operator regardless value toggle. Similarly, applicable
operators, planner must subgoal even toggle indicates prefer applying. toggle
new variable guide heuristic search existing choice point branching factor
two: represent addition new backtrack point. discussed throughout,
provides flecs ability change commitment strategy. suggested
name, toggle one two values: sub app indicating eager subgoaling eager
applying respectively.
describe domain-independent heuristic could used guide changes
value toggle. heuristic allow eager commitments reason
believe need backtrack resulting operator linearization.
case, setting toggle app increase planning eciency converting
partially-ordered set operators sequence leads single possible state,
used guide subsequent planning. process equivalent starting new
smaller planning problem previous choices embedded state.
situation described similar arises alpine system
constructs ecient abstraction hierarchies (Knoblock, 1994). alpine guarantee
40

fiflecs: Planning Flexible Commitment Strategy

planning hierarchically using generated abstraction hierarchies lead backtracking across refinement spaces. Figure 10 illustrates flecs use abstraction
planning information control value toggle. toggle changes app particular abstract planning step completely refined abstraction hierarchies preserve
alpine's ordered monotonicity property, need backtrack
resulting operator ordering. toggle change back sub, flecs continue
planning updated state information.
Abstraction level
1. Begin
toggle=sub.
S0

3. Continue planning:
toggle=sub.

Build partial
order plan
first step
abstract plan

S0

5. Continue
done...

S1
2. Set toggle=app.
Commit ordering
compute new state.

S1

S2
4. another
step abstract
plan, commit again:
toggle=app.

Figure 10: Using abstraction information guide changes toggle.
abstraction-driven heuristic one method exploiting choice point. Similarly,
minimum conspiracy number heuristic saba heuristic ways
guide choices instantiated operator applicable operator respectively.
heuristics used always changed, claim ones provide
defaults best possible: heuristic work time.
planning algorithm present sound complete searches entire
search space, using technique iterative deepening (Korf, 1985). flecs sound
terminates reached goal statement result applying
operators. is, application operator sequence returned final plan
entirely simulated time planner terminates. Thus preconditions
operator true time operator executed, operators
executed, goal statement satisfied. Consequently, flecs sound.
Since step algorithm prunes search space, flecs iteratively
increasing depth bound complete: solution planning problem, flecs
find one. insure property, need show flecs consider possible
operators may achieve goal well orderings interacting applicable operators.
flecs maintaining backtracking points choice operator (step 6c)
points operator ordering could affected: choice applicable
operator (step 7) choice whether subgoal apply (step 5d). Selecting
41

fiVeloso & Stone

\apply" commits ordering operators currently applicable least
one currently applicable operators. Note completeness achieved even without
maintaining choice goals subgoal backtrack point (step 6), since regardless
order operators chosen, applied according possible
interactions (i.e., similarly resolving negative threats). Thus flecs's search space
significantly reduced prodigy4.0, still preserving completeness. (See
Appendix formal proofs flecs's soundness completeness.)

5. Empirical Analysis Heuristics Control Commitment Strategy

seen, flecs introduces notion exible choice point delayed
eager operator-ordering commitments. appreciate need exibility, consider
two extreme heuristics: always eagerly subgoaling (delaying commitment) always
eagerly applying (eager commitment). former heuristic chooses subgoal long
least one active pending goal (Subgoal Always Applying saba);
latter chooses apply long active applicable operators (Subgoal
eVery Try Apply savta). section show empirical results demonstrate
extremes lead highly sub-optimal search particular domains.
Indeed, believe single domain-independent search heuristic perform well
domains (Stone et al., 1994). reason equipped flecs
ability use either extreme domain-independent heuristic moderate
heuristic \in between" two: every iteration algorithm,
opportunity change eagerly subgoaling eagerly applying vice versa. One could
define different heuristics guide choice, one could leave choice user
interactively.
exibility search method provides algorithm ability search sensibly wide variety domains. algorithm exible susceptible
coming across domains cannot handle eciently (Barrett & Weld, 1994; Veloso &
Blythe, 1994; Kambhampati, 1994). flecs's exibility makes possible study
heuristics work best situations. addition, exible choice perfect learning
opportunity. Since single search method solve planning problems, use
learning techniques help us determine experience search strategies try.
illustrate need different search strategies, provide one real world situation
eagerly subgoaling leads directly optimal solution, one eagerly
applying so, one intermediate policy best. examples
intended exhaustive demonstration flecs's capabilities. Rather, examples
intended illustrate need consider problems traditional goal ordering
problems motivate potential impact flecs.

5.1 Eagerly Subgoaling Better

First, consider class tasks following true: operators initially
executable, must performed specific order operator deletes
preconditions operators supposed executed earlier. instance,
suppose single paint brush several objects need painted
different colors. paint brush washed fairly well, never comes completely
42

fiflecs: Planning Flexible Commitment Strategy

clean. reason, ever use lighter paint darker paint, darker
paint show painted object whole project ruined. Perhaps
shade red darker shade green. paint chair red seat
green legs, better paint legs first.
Consider range colors ordered light dark: white, yellow, green, : : : ,
black. Initially, could paint object color. However, start painting
something black, paint used. order represent situation
planner, created domain operators shown Table 3.
Operator:
preconds:
adds:
deletes:

paint-white <obj>

(usable white)
(white <obj>)

paint-yellow <obj>

(usable yellow)
(yellow <obj>)
(usable white)






..
.

paint-black <obj>

(usable black)
(black <obj>)
(usable white)
(usable yellow)
..
.
(usable brown)

Table 3: Example domain delayed step-ordering commitment results ecient
planning.
Assume colors usable initial state. Since painting object certain
color deletes precondition painting object lighter color, since precondition cannot re-achieved (no operator adds predicate \usable"), colors must
used specific order.
painting domain real-world interpretation artificial domain Dm 1 introduced (Barrett & Weld, 1994). operators Dm 1 look like:
Operator:
preconds: g
adds: fG g
deletes: jj < ig
Since operator deletes preconditions operators numerically it,
operators applied increasing numerical order. Thus, A1 corresponds
operator paint-white, A2 corresponds paint-yellow, etc. used domain
experiments, run SPARC station. generated random problems
one fifteen goals: ten problems number goals. used
150 problems test extreme heuristics. get data points, averaged
results ten problems number goals. raw data
contained online appendix. graph average time flecs took solve
problems versus number goals.
shown (Stone et al., 1994),9 eagerly applying leads exponential behavior (as
function number goals) domain, eagerly subgoaling, using






j

9. began study new planning algorithm | named flecs| prodigy4.0. consider
version prodigy used (Stone et al., 1994) preliminary implementation flecs.

43

fiVeloso & Stone

operator choice heuristic study, leads approximately linear behavior
backtracking. problem eagerly applying that, example, goal G7
solved G4, flecs immediately apply A7 backtrack
unsuccessfully tries apply A4 . Eagerly subgoaling allows flecs build set
operators need apply order appropriately selecting
application order avoids con icts threats. Figure 11 shows graphic comparison
two different behaviors.
Eager Subgoaling
Eager Applying

Time: msec

2500
2000
1500
1000
500
0
0

2

4

6
8
10 12
Number Goals

14

16

Figure 11: flecs's performance different heuristics domains Dm 1. Eager subgoaling applying correspond delayed commitments eager commitments
respectively.

5.2 Eagerly Applying Better

Next, consider class tasks following true: several operators could
used achieve goal, operator used once. use similar
example, suppose trying paint different parts single object different colors.
However, suppose using multiple brushes never come clean:
use brush one color, never safely use again. instance, painted
green parts using brush1, would need use brush2 (or brush besides brush1)
paint red parts. Table 4 represents operators new domain.
Operator:

paint-with-brush1

<parts> <color>
preconds: (unused brush1)
adds: (painted <parts> <color>)
deletes: (unused brush1)

: : : paint-with-brush8

<parts> <color>
(unused brush8)
(painted <parts> <color>)
(unused brush8)

Table 4: Example domain eager step-ordering commitment use state
results ecient planning.
Note operator used color, since deletes precondition,
used once. capture essential features domain artificial
domain called D1 -use-once. operators D1-use-once look like:
44

fiflecs: Planning Flexible Commitment Strategy


g
f< g >g
g

Operator:
preconds:
adds:
deletes:







operator achieve goal, since operator deletes precondition,
used once. operator corresponds painting different brush.
domain, better eagerly apply eagerly subgoal. Eagerly
subgoaling causes flecs select operator achieve goals.
deterministic method selecting operators (such minimum conspiracy number
order appearance domain specification tie-breaker), selects operator A1
achieve two different goals. However, since could apply A1 once, would need
backtrack select different operator one goals. shown Figure 12, eagerly
applying outperforms eagerly subgoaling case. generated results
way results previous subsection.
Eager Subgoaling
Eager Applying

Time: msec

5000
4000
3000
2000
1000
0
0

2

4

6
8
10 12
Number Goals

14

16

Figure 12: flecs's performance different heuristics domains D1-use-once.

5.3 Intermediate Heuristic

always possible find good solutions either always eagerly subgoaling,
first example, always eagerly applying, second, would need
include variable toggle flecs: could simply eager-subgoal mode
eager-apply mode. However, cases neither alternatives suces.
Instead, need eagerly subgoal portions search eagerly apply
others. One heuristic changing commitment strategy abstraction-driven
method described Section 4.2. present domain use form
heuristic.
time consider class tasks following true: top-level goals take
least three operators achieve, one irreversible, executed limited
number times, restricts bindings operators. One representative
class one-way rocket domain introduced (Veloso & Carbonell, 1993).
sake consistency, however, present representative class domains
painting context. Suppose painting walls rollers. paint wall
45

fiVeloso & Stone

need first \ready" wall, purpose example means decide
wall needs painted designate color roller paint wall. Next
must fill selected roller appropriately colored paint. paint
wall. Unfortunately, limited supply rollers never become clean
filled paint, must clean selected paint wall.
reason, must ready walls want paint roller
fill roller paint. reader familiar one-way rocket domain,
\fill-roller" operator analogous \move-rocket" operator domain:
executed due limited supply fuel, must executed
fully loaded. Table 5 shows possible set operators painting domain.
Operator:

designate-roller

fill-roller

paint-wall

<wall> <roller> <color> <roller> <color> <wall> <roller> <color>
preconds: (clean <roller>)
(clean <roller>)
(ready
(needs-painting <wall>)
(chosen
<wall> <roller> <color>)
<roller> <color>) (filled-with-paint
<roller> <color>)
adds: (ready
(filled-with-paint
(painted <wall> <color>)
<wall> <roller> <color>) <roller> <color>)
(chosen <roller> <color>)
deletes:
(clean <roller>)
(ready
<wall> <roller> <color>)
(needs-painting <wall>)

Table 5: Example domain exibility commitments results ecient planning.
given domain representation, flecs dicult time apparently simple problems uses search strategy throughout entire search.
example, consider problem five walls two rollers (equivalent problem
one-way rocket domain five objects two destinations):
Initial State
(needs-painting wallA)
(needs-painting wallB)
(needs-painting wallC)
(needs-painting wallD)
(needs-painting wallE)
(clean roller1)
(clean roller2)

Goal Statement
(painted wallA red)
(painted wallB red)
(painted wallC red)
(painted wallD green)
(painted wallE green)

46

Optimal Solution
<Designate-Roller wallA roller1 red>
<Designate-Roller wallB roller1 red>
<Designate-Roller wallC roller1 red>
<Fill-Roller roller1 red>
<Paint-Wall wallA roller1 red>
<Paint-Wall wallB roller1 red>
<Paint-Wall wallC roller1 red>
<Designate-Roller wallD roller2 green>
<Designate-Roller wallE roller2 green>
<Fill-Roller roller2 green>
<Paint-Wall wallD roller2 green>
<Paint-Wall wallE roller2 green>

fiflecs: Planning Flexible Commitment Strategy

flecs directly find solution always eagerly subgoaling always
eagerly applying. search eciently, must subgoal considered walls
need painted color; must apply applicable operators
continuing. explicit information domain telling use one roller red
one roller green.10 reason, flecs eagerly subgoals, initially selects
roller paint walls. extensively backtracks finding correct
bindings. flecs realize \ready" walls going
painted color filling roller. Thus, flecs eagerly applies
operators, tries filling roller soon one wall \readied." Note planning
variables would solve problem since planner would still need make
binding selections subgoaling beyond \paint-wall," hence facing problems.
flecs tries solve problem using either strategy described,
succeed reasonable amount time. Since flecs complete, would certainly
succeed eventually, eventually long time away dealing NP-hard
problem: neither commitment strategies leads solution problem
500 seconds search time. lost. changing value toggle
appropriate times, flecs easily find solution problem. fact,
4 seconds toggle manually changed appropriate times.
time(sec) solution
eager applying
500

eager subgoaling
500

variable strategy
4
yes
flecs eagerly subgoals decided paint wallA, wallB, wallC
roller1, begin eagerly applying. three walls painted red, flecs
begin subgoaling without danger preparing walls wrong
roller: roller2 still clean. example change state allows
minimum conspiracy number heuristic select correct instantiated operator.
general heuristic toggle set sub walls need
painted color considered. toggle set app
applicable operators applied. toggle set back sub
process continues. way, flecs need little backtracking
quickly reach solution. heuristic corresponds using abstraction hierarchy
deal separately interactions different colors different walls.

6. Conclusion

presented planner intended studying correspondence planning problems search heuristics suited problems. flecs
ability eagerly subgoal, thus delaying operator-ordering commitments; eagerly apply,
thus maximizing advantages maintaining internal state; exibly interleave
two strategies. Thus operate point continuum operator-ordering
heuristics { one important dimension planning.
10. problem common planning often syntactically correct way restrict bindings
domain representation maintaining intended exibility generality domain.

47

fiVeloso & Stone

paper, explained advantages disadvantages delayed eager
commitments. presented flecs algorithm full detail, carefully motivating
concepts illustrating clear examples. discussed different heuristics
guide flecs choice points discussed properties. showed examples
specific planning tasks corresponding empirical results support position
general-purpose planner must able use exible commitment strategy. Although
planning problems solvable complete planners, flecs may solve
problems eciently planners ability change
commitment strategy may fall worst case unique commitment strategy.
flecs provides framework study characteristics different planning strategies
mapping planning domains problems. flecs represents view
domain-independent planning strategy uniformly ecient across different domains problems. flecs addresses particular operator-ordering choice
exible planning decision. allows combination delayed eager operator-ordering
commitments take advantage benefits explicitly using simulated execution
state reasoning planning constraints.
currently continuing work understanding tradeoffs among different
planning strategies along different dimensions. plan study effects eager versus
delayed commitments point operator instantiations. investigating
effects combining real execution flecs. Finally, plan use machine learning
techniques flecs's choice points gain possibly automated understanding
mapping ecient planning methods planning domains problems.

Appendix A. Proofs
prove flecs sound iterative deepening complete. Consider
flecs algorithm presented Table 2. planning problem determined
initial state, goal statement, set operators available domain. plan
(totally-ordered) sequence instantiated operators. returned plan generated
flecs planning problem sequence applied operators upon termination.
solution planning problem plan whose operators applied problem's
initial state reach state satisfies Goal Statement. justified solution
solution subsequence operators solution solution. flecs
terminates successfully termination condition met (step 2).

Theorem 1.

flecs sound.
show flecs algorithm sound; is, algorithm terminates suc-

cessfully, returned plan indeed solution given planning problem.
Assume flecs terminates successfully = O1 ; O2; :::On returned
plan. flecs applies operator preconditions operator satisfied
Current State C (step 7). Hence, construction, operators O1 ; O2; : : :Ok
k < n applied, preconditions operator Ok+1 satisfied C .
point termination, Current State C satisfies Goal Statement (step 2). C
reached initial state applying operators . Therefore solution.
QED.
48

fiflecs: Planning Flexible Commitment Strategy

Theorem 2.

flecs iterative deepening complete.

Recall completeness, informally, means solution particular
problem, algorithm find it. show flecs's search space complete
flecs's search algorithm complete long explores branches search
space, example using iterative deepening (Korf, 1985).11 Iterative deepening involves
searching bound number search steps may performed
particular search path suspended expansion; solution found
particular depth bound, search repeated larger depth bound.
planning problem, assume = O1; O2; :::On justified solution.
show flecs searches iterative deepening, find solution.
flecs algorithm four choice points. Three choice points backtrack
points: choice subgoaling applying (step 5d), choice operator
use achieve goal (step 6c), choice applicable operator apply
(step 7). One choice point backtrack point: choice goal subgoal
(step 6).
prove completeness, must show backtrack point, possible
choice lead flecs towards finding plan , matter choices flecs makes
non-backtrack choice point. flecs explores branches search space
searching iterative deepening, must eventually find unless finds
solution (of length n) first.
proof involves constructing oracles tell flecs choices make
backtrack points find . matter choices makes choice
point, finds solution plan .
Consider point search operators O1; O2; O3; : : :; Ok k (and
others) already applied. let oracles backtrack points
operate follows.
choice subgoaling applying (step 5d), first oracle makes flecs choose
apply Ok+1 applicable (i.e., A); otherwise makes flecs subgoal.
flecs chooses apply (Ok+1 2 A), reaches another choice point, namely choice
operator apply (step 7). Another oracle makes flecs select precisely step Ok+1 .
flecs chooses subgoal (Ok+1 62 A), let flecs choose goal P
set pending goals P (step 6). Since step 6 backtrack point, cannot
oracle determine choice point. Instead show that, independently
choice made point, flecs still find solution . find solution
consequence construction next oracle controls final choice point
(below). oracle guarantees P selected must either member goal
statement precondition operator .
final choice point selection operator achieve P (step 6c). third
oracle makes flecs choose operator achieve P . Since solution
planning problem since P either member Goal Statement precondition
operator , must operator achieves P .
one operator, one chosen. Since operators selected,
11. opposed breadth first search, iterative deepening harm eciency. combines eciency
searching depth first completeness searching breadth first.

49

fiVeloso & Stone

condition pending goals Goal Statement preconditions
operators maintained.
three oracles lead flecs justified solution . Since justified, every
operator necessary achieve either goal goal statement precondition another operator. Consequently, since third oracle chooses operators
, every operator eventually chosen applied prescribed
first two oracles. every operator applied, termination condition
met (since solution) flecs terminate successfully. QED.

Acknowledgements
would recognize particular contributions Jim Blythe Eugene Fink
research. Jim Blythe highly responsible current implementation prodigy4.0
upon flecs based. Eugene Fink helped formalization algorithms
proofs. thank Eugene Fink, Karen Haigh, Gary Pelton, Alicia Perez, Xuemei Wang,
anonymous reviewers comments article.
research sponsored Wright Laboratory, Aeronautical Systems Center, Air
Force Materiel Command, USAF, Advanced Research Projects Agency (ARPA)
grant number F33615-93-1-1330. views conclusions contained document authors interpreted necessarily representing
ocial policies endorsements, either expressed implied, Wright Laboratory
U. S. Government.

References

Ambros-Ingerson, J., & Steel, S. (1988). Integrating planning, execution, monitoring.
Proceedings Seventh National Conference Artificial Intelligence, pp. 83{88
St. Paul, MN.
Barrett, A., & Weld, D. S. (1994). Partial-order planning: Evaluating possible eciency
gains. Artificial Intelligence, 67, 71{112.
Blythe, J., & Veloso, M. M. (1992). analysis search techniques totally-ordered
nonlinear planner. Proceedings First International Conference AI Planning Systems, pp. 13{19 College Park, MD.
Carbonell, J. G., Blythe, J., Etzioni, O., Gil, Y., Joseph, R., Kahn, D., Knoblock, C.,
Minton, S., Perez, A., Reilly, S., Veloso, M., & Wang, X. (1992). PRODIGY4.0:
manual tutorial. Tech. rep. CMU-CS-92-150, Department Computer Science,
Carnegie Mellon University.
Carbonell, J. G., Knoblock, C. A., & Minton, S. (1990). Prodigy: integrated architecture planning learning. VanLehn, K. (Ed.), Architectures Intelligence.
Erlbaum, Hillsdale, NJ. Technical Report CMU-CS-89-189.
Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32, 333{378.
50

fiflecs: Planning Flexible Commitment Strategy

Ernst, G. W., & Newell, A. (1969). GPS: Case Study Generality Problem Solving.
ACM Monograph Series. Academic Press, New York, NY.
Fikes, R. E., & Nilsson, N. J. (1971). Strips: new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189{208.
Fink, E., & Veloso, M. (1994). PRODIGY planning algorithm. Technical report CMU-CS94-123, School Computer Science, Carnegie Mellon University.
Kambhampati, S. (1994). Desing tradeoffs partial order (plan space) planning. Proceedings Second International Conference AI Planning Systems, AIPS-94,
pp. 92{97 Chicago, IL.
Knoblock, C. A. (1994). Automatically generating abstractions planning. Artificial
Intelligence, 68.
Korf, R. E. (1985). Depth-first iterative-deepening: optimal admissible tree search.
Artificial Intelligence, 27 (1), 97{109.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings
Ninth National Conference Artificial Intelligence, pp. 634{639.
McDermott, D. V. (1978). Planning acting. Cognitive Science, 2-2, 71{109.
Minton, S. (1993). Integrating heuristics constraint satisfaction problems: case study.
Proceedings Eleventh National Conference Artificial Intelligence, pp. 120{
126.
Minton, S., Bresina, J., & Drummond, M. (1991). Commitment strategies planning:
comparative analysis. Proceedings Twelfth International Joint Conference
Artificial Intelligence, pp. 259{265.
Minton, S., Knoblock, C. A., Kuokka, D. R., Gil, Y., Joseph, R. L., & Carbonell, J. G.
(1989). prodigy 2.0: manual tutorial. Technical report CMU-CS-89-146,
School Computer Science, Carnegie Mellon University.
Rosenbloom, P. S., Newell, A., & Laird, J. E. (1990). Towards knowledge level
SOAR: role architecture use knowledge. VanLehn, K. (Ed.),
Architectures Intelligence. Erlbaum, Hillsdale, NJ.
Sacerdoti, E. D. (1977). Structure Plans Behavior. American Elsevier, New York.
Stone, P., Veloso, M., & Blythe, J. (1994). need different domain-independent
heuristics. Proceedings Second International Conference AI Planning
Systems, pp. 164{169.
Tate, A. (1977). Generating project networks. Proceedings Fifth International
Joint Conference Artificial Intelligence, pp. 888{900.
51

fiVeloso & Stone

Veloso, M., & Blythe, J. (1994). Linkability: Examining causal link commitments partialorder planning. Proceedings Second International Conference AI Planning
Systems, pp. 170{175.
Veloso, M. M. (1989). Nonlinear problem solving using intelligent casual-commitment.
Technical report CMU-CS-89-210, School Computer Science, Carnegie Mellon University.
Veloso, M. M., & Carbonell, J. G. (1993). Derivational analogy prodigy: Automating
case acquisition, storage, utilization. Machine Learning, 10, 249{278.
Veloso, M. M., Perez, M. A., & Carbonell, J. G. (1990). Nonlinear planning parallel
resource allocation. Proceedings DARPA Workshop Innovative Approaches
Planning, Scheduling, Control, pp. 207{212 San Diego, CA. Morgan Kaufmann.
Wilkins, D. E. (1984). Domain-independent planning: Representation plan generation.
Artificial Intelligence, 22, 269{301.

52


