Journal Artificial Intelligence Research 3 (1995) 187-222

Submitted 5/95; published 10/95

Learning Membership Functions
Function-Based Object Recognition System
Kevin Woods

woods@bigpine.csee.usf.edu

Computer Science & Engineering
University South Florida
Tampa, FL 33620-5399

Diane Cook

cook@centauri.uta.edu

Computer Science & Engineering
University Texas Arlington
Arlington, TX 76019

Lawrence Hall
Kevin Bowyer

hall@waterfall.csee.usf.edu
kwb@bigpine.csee.usf.edu

Computer Science & Engineering
University South Florida
Tampa, FL 33620-5399

Louise Stark

stark@napa.eng.uop.edu

Electrical Computer Engineering
University Pacific
Stockton, CA 95211

Abstract

Functionality-based recognition systems recognize objects category level reasoning well objects support expected function. systems naturally
associate \measure goodness" \membership value" recognized object.
measure goodness result combining individual measures, membership values,
potentially many primitive evaluations different properties object's shape.
membership function used compute membership value evaluating primitive
particular physical property object. previous versions recognition system known Gruff, membership function primitive evaluations
hand-crafted system designer. paper, provide learning component
Gruff system, called Omlet, automatically learns membership functions given
set example objects labeled desired category measure. learning algorithm
generally applicable problem low-level membership values combined
and-or tree structure give final overall membership value.

1. Introduction
computer vision (CV) application involving recognition detection \objects", descriptions types objects recognized required. Object descriptions
explicitly supplied human \expert". Alternatively, machine learning techniques
used derive descriptions example objects.
advantages learning object descriptions examples rather
direct specification expert. Specifically, may dicult person

c 1995 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiWoods, Cook, Hall, Bowyer, & Stark

provide CV system accurate description object general enough
cover possible variations visual appearance different instances object.
example, two tumors medical images look exactly same. Similarly, would
cumbersome human provide CV system ranges possible values
different physical aspects chairs (i.e., possible surface areas
seating surface chair? seating surface supported?). Considerable
\tweaking" object description parameters may required human expert
order achieve satisfactory system performance. Machine learning techniques
used generate concepts consistent observed examples. examples
learning systems include C4.5 (Quinlan, 1992), AQ (Michalski, 1983). System
performance affected ratio number training examples number
features used describe examples, accuracy examples represent
\real-world" objects CV system may encounter.
function-based object recognition system example CV system
machine learning techniques useful development object descriptions.
function-based object recognition system recognizes object classifying one
generic object categories describe function object might serve
(Bogoni & Bajcsy, 1993; Brand, 1993; Di Manzo, Trucco, Giunchiglia, & Ricci, 1989; Kise,
Hattori, Kitahashi, & Fukunaga, 1993; Rivlin, Rosenfeld, & Perlis, 1993; Stark & Bowyer,
1991, 1994; Sutton, Stark, & Bowyer, 1993; Vaina & Jaulent, 1991). object category
defined terms functionality required object belongs category.
example, object category might defined as:
straight back chair ::= provides sittable surface & provides stability &
provides back support
indicating object classified straight back chair degree
satisfies conjunction three functional properties.
functional properties defined terms primitive evaluations
different aspects object's shape. example, candidate surfaces may checked
provides sittable surface evaluating whether appropriate width, depth
height support plane. many cases, unique ideal value
given aspect object's shape, instead range values considered
equivalent terms \goodness". example, anything 0.45 0.55 meters
might equally acceptable height seating surface. However, particular shape
measurement becomes small large, evaluation measure reduced.
Fuzzy set theory provides mathematical framework handling \goodness fit"
concept. case, fuzzy membership function transforms physical measurement (i.e.,
height object's surface ground) membership value interval [0,1].
membership value, evaluation measure, denotes degree object (or
portion object) fits primitive physical concept (i.e., well height
surface matches seating surface height typical chairs). Thus, separate measure
goodness produced primitive evaluation. measures combined
produce final aggregate measure goodness object.
Gruff system (Stark & Bowyer, 1991) function-based object recognition system
utilizes fuzzy logic, manner described, evaluate 3-D shapes. previous
188

fiLearning Membership Functions Object Recognition

versions Gruff, fuzzy membership functions embedded system
collectively hand-crafted refined produce best results large set example
shapes. membership functions ideal candidates learned examples using
machine learning approach.
paper, present method automatically learning collection fuzzy
membership functions set labeled example shapes. Due system constraints
imposed Gruff, general-purpose machine learning algorithms, neural networks,
genetic algorithms, decision trees, readily applicable. Thus, new special-purpose
learning component, called Omlet, developed. Omlet tested synthetic
data two different object categories (chairs cups), data collected
human evaluations physical chairs. Results presented show (a) learning
membership functions way provides level recognition performance equivalent
obtained \hand-tweaked" Gruff, (b) learning method compatible
human interpretation shapes. approach generally applicable
system set primitive evaluation measures combined produce
overall measure goodness final result.
paper organized follows. Section 2 discusses related work, justifies need develop special-purpose learning component. Section 3 introduces
Gruff object recognition system. Section 4 presents new learning component, called
Omlet. point, state material Section 3 previously
published, presented facilitate understanding new learning component. Although Omlet specifically \tailored" add-on learning component
Gruff system, applies data structure used systems.
general, Omlet described system learning context fuzzy
And/Or categorization tree. point reader questions concerning Gruff's
object recognition paradigm references provided. Section 5 describes experimental design data sets utilized. Section 6 documents experimental results
gives analysis them. Finally, Section 7 summary paper given
conclusions drawn.

2. Related Work
two ways learning might used ease construction systems
Gruff. first rules (or proof tree) make Gruff could built
inductive learning system. C4.5, decision tree learner (Quinlan, 1992), good example
class learning systems. However, types inductive classification systems
cannot adequately replace functionality Gruff/Omlet system. Omlet allows
examples less perfect membership class used training.
direct way accomplish system C4.5. decision-tree based system
would probably require different trees trained parent child categories.
functional concepts (provides sittable surface, example) would get lost training
process individual features chair directly used. could train series
trees learn functional concepts individually, train decision tree combine
results. approach parameters membership functions learned
paper would learned implicitly construction decision tree functional
189

fiWoods, Cook, Hall, Bowyer, & Stark

concept resulting rules. Replacing Gruff/Omlet decision tree
general-purpose rule learner possible, would require extensive work preserve
idea functional object recognition.
Omlet aimed second area Gruff-like system could benefit
learning, tuning membership functions. knowledge primitive might
sittable surface. Given measurements specific surface object specific orientation, necessary develop representation acceptable bounds measurements
determine whether surface area sittable.
Techniques areas machine learning used represent learn
probabilistic fuzzy membership functions. example, belief networks provide mechanism representing probabilistic relationships features domain. Individual
feature probabilities combined generate probability complex concept
propagating belief values constraints network. Adaptive probabilistic networks kind belief nets learn individual probability values distributions using gradient descent (Pearl, 1988; Cooper & Herskovits, 1992; Spiegelhalter, Dawid,
Lauritzen, & Cowell, 1993). structure belief nets update algorithms
similar approaches found Omlet. However, Omlet incorporates symbolic theorem proving, feature fundamental performing function-based object recognition,
well value propagation.
Similar research performed learn fuzzy membership functions using adaptive techniques genetic algorithms classifier systems (Parido & Bonelli, 1993;
Valenzuela-Rendon, 1991). Much work used learn individual membership functions cannot handle combinations input. again, little work
directed learning fuzzy memberships context rule-based system. Additional refinement techniques reinforcement learning (Mahadevan & Connell, 1991;
Watkins, 1989), neural networks, statistical learning techniques used
refine confidence values.
project represents new direction computer vision machine learning research; namely, integration machine learning computer vision methods learn
fuzzy membership functions function-based object recognition system. Although learning functions rule-based context novel effort, similar research performed area refining certainty factors intelligent rule bases. example,
Mahoney Mooney (1993) Lacher et al. (1992) use backpropagation algorithms
adjust certainty factors existing rules order improve classification given set
training examples. contrast Omlet's approach, systems refine values
represent measure belief given result adjusted according combination
functions certainty factors. Omlet's measures represent degrees fuzzy membership
object class, refinement method propagates error And/Or tree.
work Wilkins (1994) focuses revising probabilistic rules classification expert system. Probabilistic weights applied rule, indicating strength
evidence supplied rule. However, refinements rule occur form
modifying applicability rule generalizing, specializing, deleting adding
rules, instead automatically refining weight rule. authors avoid automatic
refinement weights resulting rule base may interpretable experts.
190

fiLearning Membership Functions Object Recognition

Towell Shavlik (1993) convert set rules representation suitable
neural net, train network re-extract refined rules. initial network
set chain rules. extracted rules necessarily clear
functional meaning approach aims preserving.
several new approaches learning tuning fuzzy rules (Ishibuchi, Nozaki,
& Yamamoto, 1993; Berenji & Khedkar, 1992; Jang, 1993; Jang & Sun, 1995) use
genetic algorithms specialized kinds neural networks, making use reinforcement
learning. approaches might provide alternative way learn membership values
provided initial functional rules given fuzzy rules. However, modifications
learning approaches would needed normally work domains without rule
chaining hierarchies rules Gruff/Omlet.

3. Gruff Object Recognition System
Gruff acronym stands Generic Representation Using Form Function (Stark
& Bowyer, 1991). Gruff recognition system takes 3-D shape description input,
reasons whether shape could belong object categories known
Gruff, outputs interpretation category object could belong.
\interpretation" specified orientation labeling parts shape
identified satisfying functional properties. See Figure 1 example
interpretation.
GRUFF Input

GRUFF Output

Provides
Sittable
Surface

Provides
Stable
Support

Figure 1: Gruff interpretation 3-D shape category conventional chair. Elements shape labeled functional property provide.

191

fiWoods, Cook, Hall, Bowyer, & Stark

3.1 Knowledge Primitives

Gruff's reasoning shape performed using \low level" procedural knowledge
implemented set knowledge primitives . knowledge primitive represents
primitive physical property concerning shape, physics, causation. knowledge
primitive takes (specified portions a) 3-D shape description input, along
values parameters primitive, returns evaluation measure 0
1. evaluation measure represents well shape element satisfies particular
invocation primitive.
knowledge primitives used Gruff recognize chairs (Stark & Bowyer, 1991,
1994; Sutton et al., 1993):
1. relative orientation (normal one, normal two, range parameters)
primitive determines angle normals two surfaces (normal one normal two) falls within desired range.
2. dimensions ( shape element, dimension type, range parameters )
primitive used determine dimension (e.g. width depth)
surface lies within specified range.
3. proximity ( proximity type, shape element one, shape element two )
primitive used check qualitative relations shape elements,
, close .
4. clearance ( object description, clearance volume )
primitive used check specified volume unobstructed free space
location relative particular part shape.
5. stability ( shape, orientation, applied force )
primitive used check given shape stable placed
supporting plane given orientation (possibly zero) force applied.
first two knowledge primitives include four range parameters: z 1 (stands
1st zero point), n1 (1st normal point), n2 (2nd normal point), z 2 (2nd zero point).
parameters used define trapezoidal fuzzy membership function, Figure 2,
calculating evaluation measure invocation primitive. last three
knowledge primitives range parameters. return evaluation measure
1 0 depending whether primitive physical property satisfied.
Trapezoidal membership functions ect desire name (categorize) objects
manner compatible human naming. typically non-trivial range
\ideal" value many physical properties related functionality. example,
unique value mean sittable surface area population chairs, value
one would rate perfect \1.0" sittability. Reasonable deviations
result decrease sittability. sittable surface area falls outside ideal
range (i.e., z 1 n1, n2 z 2 Figure 2), evaluation measure
reduced, indicating surface provides less perfect (but still functional) sittable
192

fiLearning Membership Functions Object Recognition

1.0
Evaluation
Measure

0.0

z1 = least

z2 = greatest
n1 = low ideal n2 = high ideal

Physical Measurement Particular Property

Figure 2: Fuzzy membership function returns evaluation measure primitive physical
property.

area. Finally, area falls outside range values (less z 1, greater
z 2 Figure 2), surface longer function sittable portion chair,
evaluation measure 0 returned.

3.2 Category Definition Tree

Gruff's knowledge different object categories implemented category definition

tree , leaves represent invocations knowledge primitives. category
definition tree chair category illustrated Figure 3.
node category definition tree may two subtrees. One subtree gives
definition category terms list functional properties. chair example,
object must satisfy functional properties stability provides sittable surface order
considered member category conventional chair. functional property
may defined terms multiple primitives. evaluation measures individual
primitives combined (in manner discussed shortly) determine well
functional properties satisfied. functional property measures
combined arrive overall evaluation measure category node.
subtree defines subcategory. subcategory specialization parent
(or superordinate) category, thus provides detailed elaboration definition
parent. subcategory node subtree functional properties required
addition parent category. example, Figure 3, subcategory
straightback chair specialization conventional chair additional functional
requirement provides back support. overall evaluation measure subcategory node
combination parent category evaluation measure evaluation measure
associated additional functional properties. Figure 3, overall measure
subcategory straightback chair combination measures conventional
193

fiWoods, Cook, Hall, Bowyer, & Stark

Name: CHAIR
Node
(SUB)CATEGORY
Type:
Funtional Subcategory
Definition
Trees

Name: CONVENTIONAL
CHAIR
Node
Type:(SUB)CATEGORY

Name:

Node
Type:(SUB)CATEGORY

Funtional Subcategory
Definition
Trees

Name: PROVIDES
SITTABLE SURFACE
Node
FUNCTIONAL
Type:
PROPERTY

PROVIDES
Name:
STABLE SUPPORT
Node
FUNCTIONAL
Type:
PROPERTY

Name:
Node
Type:

Funtional Subcategory
Definition
Trees
Name: PROVIDES
STABLE SUPPORT
Node
FUNCTIONAL
Type:
PROPERTY

Name: STRAIGHTBACK
CHAIR
Node
Type:(SUB)CATEGORY
Funtional Subcategory
Definition
Trees

PROVIDES
BACK SUPPORT
FUNCTIONAL
PROPERTY

LOUNGE
CHAIR

PROVIDES
Name:
LOUNGING SITTABLE SURFACE
Node
Type:

RECLINER

Node
Type: (SUB)CATEGORY
Funtional
Definition

Subcategory
Trees

FUNCTIONAL
PROPERTY
Name: PROVIDES
LOUNGING BACK SUPPORT
Node
FUNCTIONAL
Type:
PROPERTY

Name: ARMCHAIR

Name:

Name: PROVIDES
LOUNGING ARM SUPPORT
Node
Type:

FUNCTIONAL
PROPERTY

Node
Type:(SUB)CATEGORY
Funtional Subcategory
Definition
Trees

Name: PROVIDES
ARM SUPPORT
Node
Type:

FUNCTIONAL
PROPERTY

Figure 3: Category definition tree basic level category chair.
chair node provides back support subtree. Note subcategory measurements
contribute cumulative measure parent category. may multiple levels
subcategories, conventional chair, straightback chair, armchair Figure 3.
Category nodes associated functional properties (such root node
chair Figure 3) associated evaluation measures. nodes used
set control structure function-based definition. However, provide
category definition since object member subcategory automatically
member predecessor categories. example, Figure 3, object belongs
subcategory straightback chair belongs categories conventional chair
chair. superordinate category furniture could added chair category (Stark
& Bowyer, 1994).
194

fiLearning Membership Functions Object Recognition

3.3 Combination Evidence

evaluation measures returned primitive invocations functional property
node combined using T-norm:

(a; b) = b
b measures combined. T-norm commonly referred
probabilistic (Pand) function (Bonissone & Decker, 1986). immediate parent
category node directly receives associated measure combining measures
functional property nodes using T-norm.
example, functional property provides sittable surface defined six primitives. simplicity, we'll denote evaluation measures returned six primitives
p1 p6. functional property stability defined single primitive,
returns evaluation measure (p7). determine overall evaluation measure
shape category conventional chair compute
conventional chair ::= provides sittable surface Pand stability


provides sittable surface ::= p1 Pand p2 Pand p3 Pand p4 Pand p5 Pand p6


stability := p7

Since definition (sub)category conjunction required functional properties, cumulative measure dominated \weakest link" individual
primitive evaluation measures, property Pand function. So, evaluation measure
0 one primitive physical property result cumulative evaluation measure
0. evaluation measure 1 indicates primitive physical property
ideally satisfied, shape may belong object category. final result depends
evaluation primitive physical properties.
would seem category could simply defined knowledge primitives without using notion functional properties. functional property level
introduced representation hierarchy two reasons. First, subgroupings
functional properties intuitively follow levels named categorization typical human
concepts function. Secondly, functional property evaluations result labeling
functional elements object (i.e., portions structure) fulfill
functional requirement.
Since subcategory definition represents increasingly specialized definition, evidence belonging subcategory result increased measure object
belonging subcategory opposed parent category. combination
functional property measurement subcategory node, a, parent node's
evaluation measure, b, computed using T-conorm:

(a; b) = + b , b
195

fiWoods, Cook, Hall, Bowyer, & Stark

T-conorm commonly referred probabilistic (Por) function (Bonissone
& Decker, 1986). T-conorm used combine measures subcategory node,
final subcategory evaluation measure actually computed as:

(

> T;
Esubcategory = 0S;(a; b); ifotherwise
:
user defined threshold. Thus, functional property measurement
subcategory node, a, must greater minimum order shape receive
non-zero evaluation measure subcategory. purposes work, value
= 0 assumed, indicating shape assigned subcategory long
non-zero evidence meets additional functional requirements associated
subcategory. practice, final classification decision might require much stronger
evidence, say = 0:7, shape assigned subcategory.
example, determine overall evaluation measure shape category
straightback chair, first compute overall evaluation measure category conventional chair, previously described. functional property provides back support defined 8 primitives. Denoting measurements returned 8 primitives p8
p15, overall evaluation measure (assuming measure provides back support > )
category straightback chair computed as:
straightback chair ::= conventional chair Por provides back support

provides back support ::= p8 Pand p9 Pand p10 Pand p11 Pand p12
Pand p13 Pand p14 Pand p15

object function straightback chair definition function
conventional chair. T-conorm give object higher evaluation measure
subcategory straightback chair since evidence addition \minimal"
amount evidence required shape belong parent category conventional
chair. Thus, Gruff performs recognition shape selecting (sub)category
highest overall evaluation measure. correspond specific applicable
subcategory. One exception occurs parent category evaluation measure
1 non-zero evidence supporting subcategory functional requirements.
case, T-conorm assigns evaluation measure 1 category
subcategory.
particular T-norm/T-conorm pair utilized paper chosen among
representative T-norm/T-conorm possibilities (including non-probabilistic formulations) described Bonissone Decker (1986) analyzing performance conjunction
Gruff across set example shapes (Stark, Hall, & Bowyer, 1993a).

4. OMLET Learning System

section, describe Omlet learning (sub)system. Omlet learns fuzzy membership functions, located leaves And/Or categorization tree, sets
196

fiLearning Membership Functions Object Recognition

training examples. Omlet works together Gruff automatically learn object
category definitions use definitions recognize new objects.
training mode, Omlet uses examples learn fuzzy ranges primitive
measurements. training example consists object description coupled
desired overall evaluation measure. testing mode, Omlet uses previously learned
ranges act function-based object recognition system. Knowledge primitives form
building blocks Omlet system, rules make representation language.
rules, fixed, derived Gruff's category definition tree. indicate
1) knowledge primitives combined define functional properties, 2)
functional properties combined give function-based definition object
category.
Given training example, Omlet uses rules construct general proof tree
example's given object category. proof tree simply data structure mimics
way Gruff combines primitive evaluation measures. proof tree maintains
primitive ranges modified learning algorithm. example proof tree
generated rules define object conventional chair category shown
Figure 4. proof trees contain knowledge primitives defined using
range parameters. knowledge primitives return 0/1 measures,
primitive membership function learn. training example must satisfy
\binary", necessary, functional properties return evaluation measures 1
order example member given category. example, Figure 4,
left branch top Pand node represents functional property provides stable support.
functional property defined single knowledge primitive range
parameters. Therefore, input Pand node fixed always return 1.
Omlet obtain overall evaluation measure example object, physical
measurements shape elements object input primitive fuzzy membership functions leaves proof tree. output leaf node represents
evaluation measure individual functional property. evaluation measures
combined internal nodes tree using probabilistic T-norm/T-conorm
combiners described Section 2.3. overall evaluation measure input example
output root node (see Figure 4).
Input Omlet consists set goals specific examples object (sub)categories.
goal includes example's (sub)category, elements 3-D shape fulfill
functional properties, overall desired evaluation measure greater 0
(otherwise object example object category). Figure 5 shows example
goal conventional chair object.
Using training examples, Omlet attempts learn ranges used trapezoidal
membership functions associated knowledge primitive definitions (see Figure 2).
training example presented, Omlet attempts prove via rule base
object member specified category. Here, check make sure physical
elements object listed goal satisfy binary, necessary, functional properties.
So, conventional chair training example, Omlet checks given orientation
stable, given seating surface accessible (clearance front above) meets
minimum width depth ratio. necessary functional properties satisfied,
proof tree constructed. actual overall evaluation measure calculated
197

fiWoods, Cook, Hall, Bowyer, & Stark

Rules Conventional Chair

Conventional Chair
Evaluation Measure
= 0.572
PAND

(conventional_chair ?a ?b ?c) ::=
(provides_sittable_surface ?a ?b ?c) PAND
(provides_stable_support ?a)
(provides_sittable_surface ?a ?b ?c) ::=
(dimensions AREA range_parameters ?b) PAND
(WIDTH/DEPTH 1.0 ?b) PAND
(dimensions CONTIGOUS SURFACE range_parameters ?b) PAND
(dimensions HEIGHT range_parameters ?b) PAND
(clearance ?a ?b) PAND
(clearance IN_FRONT ?a ?c)
(provides_stable_support ?a) ::=
(stability SELF ?a)

1.0
0.572

Binary functional property
"provides stable support"
fixed always return 1

?b
?c

PAND

?a

0.763

1.0

Height = 0.67

0.750
Contiguous
Surface = 1.0

Area = 0.116

Knowledge primitives ranges used
compute evaluation measures functional
property "provides sittable surface".

Figure 4: simplified proof tree constructed learning example category
conventional chair. ?a, ?b, ?c symbols rules represent physical
aspects shape used rules. orientation shape, face
sittable surface, front edge sittable surface substituted
?a, ?b, ?c, respectively. way Omlet knows elements
shape \measured" evaluated knowledge primitives.
198

fiLearning Membership Functions Object Recognition

( conventional_chair mchair.00.orientation2 mchair.00.face2 mchair.00.edge1-8 )

Object Category

Object Orientation

Sittable Surface

Front Edge
Sittable Surface

0.9808

Desired
Evaluation
Measure

Functional Properties

Figure 5: Training goal input Omlet conventional chair object.
manner described above. actual evaluation measure suciently different
desired evaluation measure, primitive fuzzy membership functions
included definition need adjusted.
Primitive membership functions adjusted propagating overall error
training sample nodes proof tree way attempts give
leaf node (i.e., range) portion error. range parameters (z 1, n1, n2,
z 2) define fuzzy membership trapezoids adjusted attempt
reduce total error examples training set. next subsections provide
details Omlet learning algorithm. First, discuss method calculating
error value propagating proof tree. Next, present method
making initial estimates parameters membership function. describe error
propagation first utilized initialization phase. describe
Omlet makes adjustments membership functions attempt reduce error
entire training set. last subsection describes general learning paradigm
provides theoretical justification implementation.

4.1 Error Propagation

error training example defined difference desired evaluation
measure actual evaluation measure computed current state Omlet
system. fraction error (defined \learning rate") propagated proof
tree Pand Por nodes. Error propagation Pand Por nodes
handled differently. error three element Pand node E , three
elements receive portion error equal cube root E (i.e., inverse
Pand function). Por node, full amount error, rather equal share,
propagated link. rationale treatment error become clear
Section 4.4.
noted desired evaluation measure fed root tree
propagated leaves, error directly computable since actual
projected desired values always known node. actual values node
computed physical measurements object shape fed leaf
199

fiWoods, Cook, Hall, Bowyer, & Stark

Desired = 0.6
PAND
Actual = 0.35

Desired = .795

Desired = .754

PAND

PAND

Actual = .612

Actual = .571

Actual = .85

Actual = .72

Desired = .959

Desired = .829

Actual = .81

Actual = .85

Actual = .83

Desired = .891 Desired = .911 Desired = .931

Figure 6: Example error propagation Pand tree. Actual values found
overall evaluation measure computed object. Desired values
propagated tree, error computed Desired , Actual.
nodes combined produce overall evaluation measure root. projected
desired values proof tree obtained propagating desired evaluation measure
root node leaves. example, given two input Pand node
actual inputs a1 a2, actual output a1 a2 (from T-norm section
2.3). desired output node D, compute desired inputs
node d1 d2 solving following set equations:

a1 a2 , d1 d2 = ,


a1 , d1 = a2 , d2

(1)

(2)
first equation computes error Pand node1, second equation assures
equal portions error assigned input. Figure 6 shows example
desired values computed via Equations 1 2 every node proof tree. figure,
known desired overall measure = 0:6 top Pand node, actual
measure = 0:35 computed Pand actual node inputs, a1 = 0:612
a2 = 0:571. Using Equations 1 2, easily compute two unknown desired
inputs d1 d2 top Pand node (which desired outputs bottom
1. equivalent simpler equation d1 d2 = could substituted here.
200

fiLearning Membership Functions Object Recognition

two Pand nodes) 0:795 0:754, respectively. three inputs Pand node,
solve set three linear equations derive desired inputs.
three inputs Pand node, divide set inputs recursively groups
two three solve set two three linear equations, respectively.
Since Por nodes used combine single parent category measure single
aggregate measure subcategory's functional properties, never
2 inputs type node. Therefore, full amount error propagated
Por node simply solving independent equations:
a2 + d1 , a2 d1 =
(3)

a1 + d2 , a1 d2 =
(4)
Eventually, portion overall error propagated ranges defined
trapezoid membership functions. error reaches individual ranges
training example, input primitive membership function (i.e., x axis value)
desired primitive evaluation measure (the axis value) define point
lie somewhere trapezoid. note leg trapezoid point belongs
to, based side normal portion range [n1,n2] x value lies.
set desired points leg used make adjustments trapezoid
attempt reduce error. Omlet collects desired points leg
membership function propagating error training examples
proof trees. trapezoid/range parameters (z 1,n1,n2,z 2) adjusted end
training epoch. Training continues fixed number epochs satisfactory
level performance, defined minimal classification error rate averaged training
set, achieved.

4.2 Initial Estimate Measurement Functions

Omlet's learning algorithm begins making reasonable initial estimates fuzzy trape-

zoid membership functions physical measurements. accomplished assigning actual values 0 membership functions training example propagating errors (which case would equal desired evaluation measures)
ranges leaf nodes proof trees. collections desired
points, make initial estimate trapezoidal membership function.
important stage place edges constructed normal range (the n1 n2
range parameters) somewhere within actual normal range. learning algorithm
make adjustments n1 n2 points subsequent training epochs. Additionally,
Omlet may set minimum maximum limits values range parameters
(more shortly).
training example desired evaluation measure 1 considered \perfect"
example object given category. Perfect training examples desirable
training set primitive measurements perfect examples known fall
range [n1,n2]. example, conventional chair training example desired
evaluation measure 1, know membership functions proof
tree (see Figure 4) must return values 1. result Pand function
greater minimum input.
201

fiWoods, Cook, Hall, Bowyer, & Stark

Omlet examines set desired points propagated range
definition tree determines \limit" points. defined follows.
two desired points values (memberships) 1, least segment normal
range [n1,n2] known. n1 range parameter set minimum x value desired
points values 1. Similarly, n2 parameter set maximum x value
desired points values 1. Note one desired point found
n1 n2 set value, membership function initially triangular.
Since portion normal range known correct, upper limit set
n1 value lower limit set n2 value assure known segment
normal range reduced subsequent training. Since training examples
desired membership values greater 0, know x input values must lie
z 1 z 2. Omlet uses minimum maximum x values set
desired points set limits z 1 z 2 range parameters. z 1 range parameter
never permitted increase minimum x value training. Similarly, z 2
value may never decrease maximum x value set desired points. Figure 7
shows range parameters (limit points) Omlet sets initialization phase given
set 10 examples.
p4

p5

p6

1.0
p3
p7

p8

p2
p9
0.0

p1
Maximum
z1 value
Allowed

Maximum
n1 value
Allowed

Minimum
n2 value
Allowed

p10
Minimum
z2 value
Allowed

Figure 7: Range parameter limits may set initializing range parameters.
limits range parameters serve several purposes. First, limits assure
perfect training examples assigned evaluation measures less 1,
training examples evaluation measures greater 0. importantly,
limiting changes made range parameters, better approximations
desired membership functions learned. subsequent learning, error
propagated proof tree assumption equal amounts error come
input node. assumption always valid, way
directly determine portion error belongs input. error propagated
membership function would cause change one range parameters
(z 1,n1,n2,z 2) moves parameter past set limit, portion overall error
assumed caused membership function correctly estimated.
202

fiLearning Membership Functions Object Recognition

occurs parameter set equal limit, effectively reducing degree
changes membership function would compensate overall error.
allow learning algorithm find good solution case different membership
functions contribute different amounts error.
segment normal range known membership function, initialization range parameters straight-forward. n1 n2 values already
set. z 1 value set simply making left leg trapezoid pass
point (n1,1.0) point set desired points minimum x value.
Similarly, z 2 value set making right leg trapezoid pass point
(n2,1.0) desired point maximum x value. points
left (right) n1 (n2) point, membership function assumed one-legged
(as CONTIGUOUS SURFACE Figure 4) parameters n1 z 1 (n2 z 2)
extended large negative (positive) value permitted change
training.
portion normal range membership function determined,
attempt fit trapezoid set desired points. First, two desired points
maximum values found. assume normal range lies somewhere
them. best-fit trapezoid determined varying n1 n2 range parameters
assumed normal range, selecting normal range [n1,n2] produces lowest
error set desired points. error sum absolute values
difference desired value actual value found point. z 1
(z 2) range parameter set manner before, left (right) trapezoid
leg forced pass desired point minimum (maximum) x value.
n1 value varied leftmost point assumed normal range rightmost
point small increments. different value n1, n2 value varied n1
rightmost point assumed normal range small increments. So, simply
testing range possible trapezoids (with degree accuracy, number trapezoids
tested, defined increments n1 n2 varied) normal range
[n1,n2] somewhere within assumed normal range. select set range
parameters minimize total error set training examples. use
best-fit trapezoid approach helpful, initial way accurately associate
error given trapezoid.

4.3 Adjusting Membership Functions

make adjustments membership trapezoid, leg trapezoid fit set
desired points using least squares line fit. Recall every training epoch
set desired points leg trapezoid. new z 1 (z 2) value
trapezoid set point left (right) leg intersects 0. new n1 (n2)
value set midway old n1 (n2) value value left (right)
leg fitted line intersects = 1. new n1 n2 values directly set
fitted trapezoid legs intersect 1 overestimating normal range [n1,n2]
eliminate desired points used least squares line fit
trapezoid leg. Desired points normal [n1,n2] range definition fall
leg trapezoid, used adjusting trapezoid legs. Therefore,
normal range overestimated, points truly belong trapezoid leg used
203

fiWoods, Cook, Hall, Bowyer, & Stark

adjust leg. gradually moving normal points n1 n2, Omlet better able
converge appropriate solution. new range parameter values (z 1,n1,n2,z 2)
determined, Omlet checks make sure none lie outside limits
may set initialization phase. Restrictions new range parameters
assure membership functions remain trapezoidal (or triangular n1 = n2). First,
z 1 must less equal n1. Similarly z 2 must greater equal n2.
z 1 (z 2) greater (less) n1 (n2) z 1 (z 2) set equal n1 (n2). Also, n1 must
less equal n2. case single point set desired
points trapezoid leg, leg defined normal point leg (n1 left
leg n2 right leg) single desired point.
training data may provide target points portion trapezoid
ranges. Omlet capable detecting situation observing slope
fitted line, adjusting membership function appropriately. slope left
trapezoid leg positive slope right leg negative.
slope fitted trapezoid leg nearly horizontal (close 0.0), sign slope
opposite expected, normal point leg moved (again, n1
left leg n2 right leg) outward. adjustment allows Omlet learn
one-legged membership functions, handle (as well possible) situations
enough training data available.
method escaping local minima empirically found useful. Normally Omlet
allow trapezoid leg change change causes increase total error
training set. So, possible zero, one trapezoid legs range
get adjusted epoch. learning slows suciently, Omlet temporarily
allow trapezoid leg changes cause increase overall error hopes escaping
possible local minima. precisely, total training set error one epoch decreases
less specified threshold, range changes cause increase overall error
permitted next training epoch.

4.4 Training Approach

order learn various subcategories defined category definition tree,
utilize machine learning approach based assumption human learning
known one disjunct per lesson (Lehn, 1990). Perhaps easiest understand
mechanics learning approach explain one-disjunct-per-lesson assumption
terminology cognitive science. Since many terms machine learning
derived cognitive sciences, dicult show similarities
algorithm characterization human learning. examine
computational characteristics learning algorithm support choice
approach.
4.4.1 One Disjunct Per Lesson

Van Lehn (1990) tells us effective way teaching complicated concepts
build simple subconcepts, opposed \all-at-once" approach.
purposes, disjunct considered one simple subconcepts. lesson consists
uninterrupted sequence demonstrations, examples, exercises. length
lesson varies. Thus, might expect human better understand concept
204

fiLearning Membership Functions Object Recognition

armchair presenting series lessons, introduces single new subconcept
builds upon previous subconcepts. example, first lesson teaches concept
conventional chair requires stable sittable surface correct orientation.
learn constitutes straightback chair, build upon concept conventional
chair introducing subconcept back support second lesson. So, second
lesson broadens notion chairs, general. Finally, third lesson builds upon
understanding straightback chair introducing subconcept arm support.
contrast, all-at-once approach may try explain armchair provides stable
sittable surface correct orientation back arm support. Here,
trying teach three subconcepts one time, show three subconcepts
together form complex concept armchair. Indeed, Van Lehn (1990) cites
laboratory studies indicate learning task dicult
one disjunct (subconcept) taught per lesson.
chosen utilize machine learning algorithm underpinnings similar
Van Lehn's one-disjunct-per-lesson assumption. case, concepts subconcepts
represented categories subcategories. lesson algorithm consists
numerous epochs training examples one (sub)category. Thus, lesson
viewed uninterrupted sequence positive examples \teach" functional
requirements single (sub)category. length, number training epochs,
lessons may vary depending subcategory learned. learn ranges
category definition tree, begin learning simplest concepts first. learn
additional complex subconcepts building upon notion simple concept. example simplified proof tree Figure 8, parent category conventional
chair learned attempting learn subcategory (specialization) straightback
chair. Since subcategory straightback chair parent category, learned
attempting learn even complex subcategory armchair. remainder
subsection discusses implementation finer detail.
implementation standpoint, simplest concepts functional properties
associated categories directly linked root node category
definition tree provides sittable surface provides stable support category
conventional chair. first lesson, use positive examples \first level" (or
parent) categories learn membership functions associated categories.
first level categories learned, membership functions \frozen"
permitted change subsequent lessons.
second lesson, membership functions \second level" categories
(i.e., subcategories first level categories definition tree) learned.
Figure 8, membership functions belong node provides back support subcategory straightback chair. learned \simple" functional concept associated
parent category, values computed parent category node assumed
reasonably accurate. example, actual values proof tree computed
straightback chair training example, actual values emanating parent category
node conventional chair accurate since concepts associated node
already learned. is, evaluation measures functional properties
provides sittable surface provides stable support straightback chair example assumed correct. implies membership functions making functional
205

fiWoods, Cook, Hall, Bowyer, & Stark

arm_chair
POR
Example subcategory
learned
parent category

provides_arm_support
PAND

straight_back_chair
POR

...
Example
"parent category"

conventional_chair
PAND

provides_back_support
PAND

...

...

Figure 8: Simplified proof tree armchair object.

requirement subtree (i.e., provides back support) responsible entire error
subcategory training example. (This explains Equations 3 4 used propagate
error Por nodes.) Hence, error propagated modifiable leaves
functional requirement node Pand subtree learning continues before.
lessons continue parent category learned subcategories learned, subcategories learned. freezing parent category
membership functions learned, applying one-subconceptper-lesson strategy. Figure 8 learning straightback chair, membership functions branch frozen armchair subcategory learned modifying
membership functions provides arm support branch proof tree.
Omlet begins learning evaluating rule base order determine subcategory
dependencies assigns (sub)category definition tree level learning
hierarchy. example, Omlet determines category conventional chair parent category membership functions learned immediately (level 1). However,
evaluation measure subcategory straightback chair dependent parent
category conventional chair. straightback chair subcategory assigned learning
level 2. Subcategory armchair dependent parent category straightback chair,
therefore assigned learning level 3.
206

fiLearning Membership Functions Object Recognition

4.4.2 Practical Justification

order understand taken one-disjunct-per-lesson approach rather
all-at-once approach, let's make observations concerning accurately blame
assignment error determined typical training example.
Recall error propagation proof tree involves projecting desired node input
values known node output value. Consider Pand node known desired output
0.9, two unknown inputs. know inputs must least 0.9.
means inputs Pand node fall within relatively small range [0.9,1.0].
However, desired output two input Por node 0.9, sure
inputs fall range [0,0.9]. known output Pand Por node
low, say 0.1, opposite effect. is, unknown inputs
Por node would lie relatively small range [0.0,0.1], unknown inputs
Pand node would fall somewhere much larger range [0.1,1.0]. observations
suggest blame assignment error propagated Pand node
reasonable accuracy examples relatively good, say 0.7 above. However,
high evaluation measures, error value cannot reliably propagated Por
node.
Since subcategory evaluation measure computed Por parent category
evaluation measure combination additional functional requirements, Por
nodes proof tree two inputs. Por nodes (in proof trees) least 1
connecting node consists parent (or general) category whose membership
calculation involves Pand connectives. structure proof trees permits
membership functions contribute evaluation measure parent category
accurately learned prior learning defined additional functional requirements
subcategories. is, determine one inputs Por node
attempt propagate error node. one input desired output
Por node known, calculation unknown input trivial. Thus, learning
approach eliminates reliability problems associated propagating blame assignment
error Por nodes. verified Section 6 experimental results
subcategories straightback chair armchair.
mechanics learning algorithm suggests Omlet's performance depends
accurately blame assignment propagated Pand nodes proof tree.
Earlier, observed blame assignment less reliably propagated Pand nodes
\bad" training examples. surprisingly, suggests quality training
data effect system performance. mean \bad" examples
object (sub)category cannot, not, included training set. Since
use least squares line fit adjust fuzzy membership functions, use \bad"
training examples (for blame may inaccurately distributed among
fuzzy membership functions) dramatically affect overall reliability
learned system parameters. Rather, desirable train system examples
that, part, good examples labeled object category. However,
unreasonable might expect machine (or human matter) better
learn constitutes chair observing good examples chairs.
207

fiWoods, Cook, Hall, Bowyer, & Stark

5. Experimental Setup
Upon reading rule base, knowledge primitive measurements training examples, training example goals, Omlet begins learning membership functions
level 1 categories. first learning epoch used make initial estimates
membership functions, Omlet iterates 1000 additional training epochs.
learning rate 0.15 used 1000 training epochs, 15 percent actual error training example propagated adjustable ranges epoch.
1000 training epochs, best range parameters (those resulted lowest
overall error) level 1 categories restored frozen. 1000 training epochs
repeated level 2 categories, followed level 3 categories,
ranges category definition tree learned2.
performance task Omlet system evaluated well trained system
recognizes objects used training phase. One measurement system
performance error observed test examples. error test example
computed absolute value difference desired actual evaluation
measures. Training/Test sets configured two ways: random partitioning labeled
data training test sets, leave-one-out testing. first case, given
size training set, 10 train/test set pairs created randomly partitioning labeled
data. error single test set average error test examples. results
given size training set reported average error 10 partitions. leave-oneout testing, one example data set used test remaining samples form
training set. repeated using example data test set, results
reported average error test examples. average error per example versus
training set size plotted training sets 10, 20, 30, ... , N-1 samples. point
N-1 training examples represents leave-one-out test results.

5.1 Test Gruff Chair Database

evaluations Gruff (Stark & Bowyer, 1991), large database 3-D shapes
specified polyhedral boundary representations built up. Figure 9 shows 52 chair
shapes. number 52 shapes belong one category function
one stable orientation. results total 110 training examples.
78 labeled instances category conventional chair. 28 instances
additionally satisfy function straightback chair, 4 instances satisfy function
armchair. shape, evaluation measure shape's membership
different object categories, computed Gruff hand-crafted functions
primitive evaluation measures. set shapes evaluation measures make
first set training examples.
first set experiments help determine well Omlet learns set membership functions minimize overall error, closely learned membership
functions approximate original functions hand-crafted expert Gruff.
question great practical importance vision researchers whether machine learning
2. preliminary experiments, Omlet converged low overall error level categories
anywhere 200 900 training epochs. Hence decision train 1000 epochs per category
level. learning rate determined empirically.

208

fiLearning Membership Functions Object Recognition

Figure 9: 52 object chair database.
technique derive set system parameters equivalent hand-crafted results
system designer. so, manual effort system construction could greatly eased.
learning task formulated duplicating Gruff measures, training
data experiments effectively \noiseless". (Noiseless sense desired
evaluation measures used input Omlet derived manner
set hand-crafted fuzzy membership functions.)

5.2 Test Synthetic Cup Database

definition recognition cups task visited frequently machine
learning research (Mitchell, Keller, & Kedar-Cabelli, 1986; Winston, Binford, Katz, &
Lowry, 1983). Winston (1983) observes, hard tell vision systems cups
look like. much easier talk purpose function cup.
convey description cup providing functional definition. particular, cup
described object hold liquid, stable, liftable, used
drink liquids. physical identification made using functional definition.
particular, synthetic set objects created here, functional properties
broken 19 knowledge primitives, 17 range parameters.
generated database 200 synthetic cup examples, measurements
knowledge primitives randomly distributed. Hand-crafted range parameters
(z 1,n1,n2,z 2) supplied 17 ranges cup functional definition. generate
209

fiWoods, Cook, Hall, Bowyer, & Stark

cup example, primitive measurement randomly selected range. Approximately
80% time primitive measurement randomly chosen n1 n2.
20% time measurement randomly chosen outside n1 n2, inside
z 1 z 2. cup generator program provides us capability create large
number cup examples without time-consuming process creating actual 3-D CAD
models example.

5.3 Learning Human Evaluation Measures

object recognition important test system real objects, possible, number
reasons. First, see whether system approximate human judgment. Second,
important observe system performance presence noise, real-world data
inevitably contain. Finally, using real-world data alleviate need completely
hand-craft system synthetic data. actually useful guide scenario
\vision system engineer" gives system set human-labeled examples,
lets system learn parameters. test Omlet, used set 37 actual
objects human ratings well might serve chair. Figure 10 shows
objects used experiments.

Figure 10: examples chair objects used human evaluation tests.
order determine well Omlet learn recognize set real chair-like
objects, objects collected together single room object placed
orientation would likely recognized chair. actual chairs,
simply orientation chair would typically used. metal trash
210

fiLearning Membership Functions Object Recognition

would \upside down" orientation, etc. group 32 undergraduate
students Artificial Intelligence class given following instructions:
asked rate thirty-seven objects according degree
\chair-ness" ected 3-D shape. purposes, \chair-ness"
measures object could used chair. consider
3-D shape making rating. assume object made
appropriate materials, factor ratings.
consider suitability object shape orientation
see it, rather orientation. Examples factors
consider rating \chair-ness" shape height, width, depth, area,
relative orientation apparent stability.
asked rate shape requirements three different
aspects \chair-ness". first aspect solely ability provide stable
seating surface. second aspect solely ability provide back support
compatible seating surface. third aspect solely ability
provide arm support compatible seat back. aspect
judged independently scale 1 5, 1 means ability
provide required function 5 means seems ideal provide
desired function. may mark halfway two numbers wish.
ratings aspect \chair-ness" averaged, normalized rounded
nearest multiple 0.02 result values range [0,1]. overall evaluation
measures objects conventional chair category taken normalized
evaluation measures first aspect \chair-ness", object's ability provide
stable seating surface. Overall evaluation measures categories straightback chair
armchair computed using probabilistic T-conorm combine three aspects
\chair-ness" manner described Subsection 3.3. Hence, comfortable, sturdy
chair would value close 1 \chair-ness", upside-down trash
considerably lower value (approx. 0.5).
objects rated, measurements taken primitives
describing chair Gruff system. measurements required
Omlet rules, clearance ground, area sittable surface,
height sittable surface, etc. Complete Omlet examples describing objects
created, including aggregate evaluation measure objects categories
conventional chair, straightback chair, armchair. resulted 37 objects
conventional chair category, 22 objects straightback chair category (15 objects
back support all), 12 objects armchair category (10 objects
back support arm support). least two sources noise
experimental data: 1) human evaluations, 2) actual measurements
physical properties objects. example, standard deviations normalized
human evaluations 37 objects conventional chair category 0.12,
12%, average. results leave-one-out testing 37 real-world objects
presented next section.
211

fiWoods, Cook, Hall, Bowyer, & Stark

6. Experimental Results

least four factors may affect performance Omlet system: 1)
number training epochs, 2) number training samples category, 3)
number ranges learned category, 4) quality training data
category. Histograms desired evaluation measures training data used
convey concept training set \quality". shown Figure 11 Gruff
chair data. height histogram bin number training samples desired
evaluation measures fall within particular range. So, histogram \good" set
training data would skewed towards higher evaluation measures. Similarly,
histogram representing \bad" training data would skewed towards lower evaluation
measures.

Figure 11: Histograms desired evaluation measures Gruff chair training sets.
histogram parent category, conventional chair cup, represents
distribution overall desired evaluation measures (which goal measures
examples data set provided input Omlet). However, histograms subcategories, straightback chair armchair, represent distributions desired
evaluation measures associated additional functional requirements defined
212

fiLearning Membership Functions Object Recognition

subcategory. example, histogram straightback chair category represents
quality provides back support portion straightback chair examples data
set, overall desired evaluation measures. Recall ranges associated
parent category conventional chair frozen (and presumably accurate)
learning begins category straightback chair. So, Omlet uses straightback chair
examples learn ranges associated provides back support functional property.
Thus, learning ranges category straightback chair, want observe
quality back supports training examples. Similarly, want observe
quality arm supports armchair examples, overall desired evaluation
measures.
A) Effect Training Time GRUFF Objects

B) Effect Training Time Synthetic Cups

Training 77 GRUFF
Labeled Conventional Chairs

Training 200
Synthetic Cups

Training 27 GRUFF
Labeled Straightback Chairs

C) Effect Training Time Real Objects

Training 36 Human
Labeled Conventional Chairs

Training 21 Human
Labeled Straightback Chairs

Figure 12: Average training sample error versus number training epochs A) Gruff
chair objects, B) synthetic cups, C) real chair objects. plots
single leave-one-out test run.
Figure 12 shows examples average training sample error plotted function
number training epochs three data sets (Gruff objects, synthetic
cups, real objects). plots, see 1000 training epochs
sucient categories three data sets. Training could likely
213

fiWoods, Cook, Hall, Bowyer, & Stark

stopped 400 epochs categories without degradation system
performance. Since number training epochs categories,
shown sucient, eliminate factor possible cause different
levels performance among categories. experiments addition described
Section 5 run examine effect performance factors.

6.1 Gruff Chair Database

Figure 13: Omlet results test samples Gruff chair database.
Figure 13 shows plot average error per sample versus training set size examples conventional chair category, separate plot examples
straightback chair category. Since 28 straightback chair examples, 3 different training set sizes (6,12,18) evaluated addition leave-one-out testing.
78 conventional chair examples used train ranges associated conventional chair category ranges straightback chair category trained.
testing done subcategory armchair since four training samples
available. plot shows increasing number training samples generally leads
reduction average error. 20 training examples used,
actual evaluation measures test examples within approximately 1% desired
evaluation measures conventional chair straightback chair categories.
note errors overall evaluation measures found categories
different learning levels directly comparable. So, plot error rate
straightback chair category directly comparable plot conventional
chair category (Figure 13). example, consider object desired overall evaluation measure 0.85 category conventional chair. Omlet computes actual
214

fiLearning Membership Functions Object Recognition

evaluation measure 0.86, error example 0.01. Let's assume provides back support portion object desired evaluation measure 0.75.
overall desired evaluation measure example category straightback chair would
0.9625 (Por 0.85 0.75). Now, suppose Omlet finds actual evaluation measure back support object 0.76, error 0.01. case,
actual overall evaluation measure example category straightback chair would
0.9664 (Por 0.86 0.76). result, error 0.01 attributed provides back support portion object manifested much smaller error 0.0039
overall evaluation measure object.
original range parameters (z 1,n1,n2,z 2) hand-crafted expert three
ranges conventional chair definition (see Figure 4) are:
AREA (0.057599 0.135 0.22 0.546699)
CONTIGUOUS SURFACE (0.0 1.0 1.0 1.0)
HEIGHT (0.275 0.4 0.6 1.1)
range values used Gruff determine desired evaluation measures
goals provided Omlet. typical example range parameters learned
Omlet is:
AREA (0.057599 0.135002 0.219992 0.546706)
CONTIGUOUS SURFACE (7.45591e-06 0.999995 10000 10000)
HEIGHT (0.275 0.400002 0.6 1.10009)
Omlet able determine CONTIGUOUS SURFACE range one-legged

membership function, n2 z 2 values (i.e., leg exist) set
arbitrarily large values. results show Omlet system capable using
labeled examples automatically determine range parameters similar
would hand-crafted expert. facilitate construction
object category definitions.
Figure 13, see number training samples indeed affect
error rate test samples. 20 training samples, error rates
conventional chair straightback chair categories begin level off. So,
number training samples becomes less factor affecting system performance
sucient number used. constitutes sucient number training samples
category may depend number ranges learned quality training
data. 3 ranges must learned category conventional chair, 5
ranges must learned category straightback chair. histograms desired
evaluation measures Gruff conventional chairs back supports Gruff
straightback chairs Figure 11 B, respectively, ect quality training
data used leave-one-out tests.
isolate effect quality training data additional experiments utilizing two separate data sets Gruff conventional chair examples. number
215

fiWoods, Cook, Hall, Bowyer, & Stark

training epochs, number training samples, number ranges learned
identical data set. One data set 38 \bad" examples contains conventional chair examples desired evaluation measures less 0.6. second data set
\good" examples created selecting 38 remaining conventional chair examples.
histograms desired evaluation measures examples used \good"
\bad" data sets shown Figure 11 C D, respectively. Leave-one-out testing (37
training examples) resulted average error 0.0001 examples \good"
data set, 0.1869 examples \bad" data set. Thus, would seem
quality training data considerable effect performance learning
algorithm.
Using set 38 \good" conventional chair examples train Omlet, average
error found using 38 \bad" examples test drops 0.013 (compared average
error 0.1869 37 \bad" examples used train). closer examination
results reveals one \bad" example contributes relatively high error 0.5
average. single example excluded test results, average error
remaining 37 \bad" examples 0.00067. 38 \bad" examples used train
Omlet, average error found using 38 \good" examples test 0.242.
results indicate Omlet inherently biased produce accurate test results
\good" examples since able achieve low error rate \bad" examples
\good" training data used. Rather, results emphasize importance
controlling quality data used train Omlet.

6.2 Synthetic Cups Database

Figure 14: Omlet results test samples Gruff cup database.
216

fiLearning Membership Functions Object Recognition

Figure 14 shows plot average error per sample versus training set size examples
randomly generated cup category. before, Omlet's performance generally
improves number training samples increased. comparison error plots
conventional chair data cup data reveals average error
cups higher number training samples, error rate decreases
erratically. comparison error rates two categories valid since
level learning hierarchy. before, two performance
factors could cause different error rates. considerably
ranges need learned cup category Gruff conventional chair
category (17 versus 3). Also, Figure 15 A, see data set created
cup generator program poor quality. Thus, due random nature synthetic
cup generator program, system trained shapes that, average,
good examples cups. Regardless poor training data, 150 training
samples used, actual evaluation measures cup test examples within
approximately 4% desired evaluation measures. light \bad" set shapes
used training examples large number ranges must learned, higher
average error cups seems reasonable.

Figure 15: Histograms desired evaluation measures synthetic cup training sets.
additional test, generated set 78 synthetic cups manner
(see Section 5.2). However, required distribution desired evaluation
measures synthetic cups similar distribution Gruff conventional
chair examples (shown Figure 11 A). Figure 15 B shows histogram desired evaluation measures examples second synthetic cup data set. Since number
training epochs, number training examples, quality training data
first test using Gruff conventional chair examples, experiment
isolates effect number ranges must learned. Performing leave-one-out
test (77 training examples), average error per sample found approximately
0.08. Figure 13, leave-one-out results 78 Gruff conventional chair examples
217

fiWoods, Cook, Hall, Bowyer, & Stark

(Sub)Category
Conventional
Chair
Straightback
Chair
Armchair

Number
Average Desired Average Error
Training Samples Evaluation Measure per Sample
36
0.8447
0.0715373
21

0.9927

0.0066456

11

0.9973

0.0022430

Table 1: Leave-one-out test results real-object database evaluation measures derived human ratings objects.

show average error less 0.01 per sample. Thus, would seem number
ranges learned affects system performance considerably.
Finally, created set 200 synthetic cups similar distribution Gruff
conventional chair examples. histogram desired evaluation measures examples
third synthetic cup data set would look similar histograms Figure 11 A,
Figure 15 B. Performing leave-one-out test (199 training examples), average error per
sample found approximately 0.023. Compared error rate original 200
synthetic cups (approximately 0.04), note \better" training data improved
system performance considerably. Compared error rate 78 synthetic cup data
set (approximately 0.08), similar quality, see increased number training
samples significantly improved system performance. error rate third synthetic
cup data set 200 examples still higher error rate Gruff data set
78 conventional chair objects (less 0.01), similar quality distribution.
Consider Gruff data set used 77 training examples learn 3 ranges
conventional chair category, synthetic cup data set, used 199 training
examples learn 17 ranges cup category.

6.3 Chair Database Human Evaluation

Leave-one-out test results real-object database evaluation measures derived
human ratings objects listed Table 1. Recall error rates
directly comparable among three categories. actual evaluation measures
conventional chairs objects within approximately 7% human evaluation measures.
average error 6% greater average error Gruff data
similar number training samples. histogram Figure 16 shows data set
real conventional chair objects contains mostly \good" examples. Thus, higher average
error probably attributed \noise" associated real-object evaluation
measures. Considering average standard deviation 12% human evaluations
conventional chair objects, 7% average error per sample Omlet results
seem unreasonable. actual evaluation measures real-object straightback chairs
armchairs differ average less 1% desired measures. before,
conventional chair examples used train ranges associated conventional
218

fiLearning Membership Functions Object Recognition

chair category ranges straightback chair category trained.
histograms desired evaluation measures back support real straightback
chair objects arm support real armchair objects shown Figure 16 B
C, respectively.

Figure 16: Histograms desired evaluation measures real-object training sets.

7. Summary Discussion

presented system (Omlet) uses labeled training examples learn fuzzy
membership functions embedded function-based object recognition system. fuzzy
membership functions used provide evaluation measures determine well
shape fits functional description object category. Omlet system example
using machine learning techniques aid development computer vision system.
shown possible accurately automatically learn system parameters
would otherwise provided human expert. Omlet may used aid
construction object categories Gruff object recognition system.
expert need concentrate \hand-tweaking" range parameters improve
system performance, rather providing good set example objects \show"
Omlet. intuitively appealing deriving descriptions objects would
219

fiWoods, Cook, Hall, Bowyer, & Stark

Gruff recognize providing examples object category. Additionally,
able demonstrate performance learning algorithm affected
number quality training examples.
possible learning approach described paper applied
systems measurements (or values) combined tree structure.
cases covered approach, except case 2 leaves leading directly Por
node. However, generalization method treating Por nodes may developed
handle situation. tree structure CV system composed entirely
probabilistic probabilistic nodes, used combine measurements.
possible similar approach applicable tree structures types
nodes (T-norms T-conorms) used.
Omlet system make easier adapt Gruff system new object
domains. Early versions Gruff performed object recognition starting complete
3-D shape descriptions (Stark & Bowyer, 1991, 1994; Sutton et al., 1993) rather
real sensory data. task reliably extracting accurate object shape descriptions
normal intensity images beyond current state art computer vision. Although
work in, example, binocular stereo, steadily progressing, accurate models object
shape readily extracted range imagery. Whereas normal imagery pixel
value represents intensity ected light, range imagery pixel value represents
distance point scene. version Gruff developed attempts
recognize object functionality shape model extracted single range
image (Stark, Hoover, Goldgof, & Bowyer, 1993b). major diculty is, course,
single range image yield complete model 3-D shape object.
\back half" object shape unseen (Hoover, Goldgof, & Bowyer, 1995).
accumulation complete 3-D shape model sequence range images topic
current research. problem solved, conceivable Omlet training
example might consist sequence range images along operator annotations
identify portions images correspond functionally important parts
object (seating surface, back support surface, etc.).

Acknowledgements
research supported Air Force Oce Scientific Research grant F49620-92-J0223 National Science Foundation grant IRI-91-20895.

References
Berenji, H., & Khedkar, P. (1992). \Learning Tuning Fuzzy Logic Controllers
Reinforcements". IEEE Transactions Neural Networks, 3, 724{740.
Bogoni, L., & Bajcsy (1993). \An Active Approach Characterization Recognition
Functionality Functional Properties". AAAI-93 Workshop Reasoning
Function, pp. 201{202 Washington, D.C.
220

fiLearning Membership Functions Object Recognition

Bonissone, P. P., & Decker, K. S. (1986). \Selecting Uncertainty Calculi Granularity:
Experiment Trading-off Precision Complexity". Kanal, L., & Lemmer, J.
(Eds.), Uncertainty Artificial Intelligence, pp. 217{247. North-Holland Publishing
Company.
Brand, M. (1993). \Vision Systems See Terms Function". AAAI-93 Workshop
Reasoning Function, pp. 17{22 Washington, D.C.
Cooper, G., & Herskovits, E. (1992). \A Bayesian Method Induction Probabalistic
Networks Data". Machine Learning, 9, 309{347.
Di Manzo, M., Trucco, E., Giunchiglia, F., & Ricci, F. (1989). \FUR: Understanding
FUnctional Reasoning". International Journal Intelligent Systems, 4, 431{457.
Hoover, A., Goldgof, D., & Bowyer, K. (1995). Extracting valid boundary representation
segmented range image. IEEE Transactions Pattern Analysis Machine
Intelligence. Accepted appear.
Ishibuchi, H., Nozaki, K., & Yamamoto, N. (1993). \Selecting Fuzzy Rules Genetic
Algorithm Classification Problems". 2nd IEEE International Conference
Fuzzy Systems, pp. 1119{1124.
Jang, J. S. R. (1993). \ANFIS: Adaptive-Network-based Fuzzy Inference Systems". IEEE
Transactions Systems, Man Cybernetics, 23 (3), 665{685.
Jang, J. S. R., & Sun, C. T. (1995). \Neuro-Fuzzy Modeling Control". Proceedings
IEEE, 378{406.
Kise, K., Hattori, H., Kitahashi, T., & Fukunaga, K. (1993). \Representing Recognizing
Simple Hand-tools Based Functions". Asian Conference Computer
Vision, pp. 656{659 Osaka, Japan.
Lehn, K. V. (1990). Mind Bugs: Origins Procedural Misconceptions. MIT Press,
Cambridge, Massachusetts.
Mahadevan, S., & Connell, J. (1991). \Automatic Programming Behavoir-Based Robots
Using Reinforcement Learning". AAAI, pp. 768{773.
Michalski, R. S. (1983). \A theory methodology inductive learning". Michalski,
R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), Machine Learning: Artificial
Intelligence Approach. Tioga Publishing Company, Palo Alto, CA.
Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). \Explanation-Based Generalization: Unifying View". Machine Learning, 1, 47{80.
Parido, A., & Bonelli, P. (1993). \A New Approach Fuzzy Classifier Systems".
Proceedings Fifth International Conference Genetic Algorithms, pp. 223{
230.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible
Inference. Morgan Kaufmann.
221

fiWoods, Cook, Hall, Bowyer, & Stark

Quinlan, J. R. (1992). C4.5: Programs Machine Learning. Morgan Kaufmann.
Rivlin, E., Rosenfeld, A., & Perlis, D. (1993). \Recognition Object Functionality
Goal-Directed Robotics". AAAI-93 Workshop Reasoning Function, pp.
126{130 Washington, D.C.
Spiegelhalter, D., Dawid, P., Lauritzen, S., & Cowell, R. (1993). \Bayesian Analysis
Expert Systems". Statistical Science, 8, 219{282.
Stark, L., & Bowyer, K. W. (1991). \Achieving generalized object recognition
reasoning association function structure". IEEE Transactions Pattern
Analysis Machine Intelligence, 3 (10), 1097{1104.
Stark, L., & Bowyer, K. W. (1994). \Function-based recognition multiple object categories". Image Understanding, 59 (10), 1{21.
Stark, L., Hall, L. O., & Bowyer, K. W. (1993a). \An investigation methods combining
functional evidence 3-D object recognition". Int. J. Pattern Recognition
Artificial Intelligence, 7 (3), 573{594.
Stark, L., Hoover, A. W., Goldgof, D. B., & Bowyer, K. W. (1993b). \Function-based
recognition incomplete knowledge shape". IEEE Workshop Qualitative
Vision, pp. 11{22 New York, New York.
Sutton, M., Stark, L., & Bowyer, K. W. (1993). \Function-based generic recognition
multiple object categories". Jain, A. K., & Flynn, P. J. (Eds.), Three-dimensional
Object Recognition Systems, pp. 447{470. Elsevier Science Publishers.
Vaina, L., & Jaulent, M. (1991). \Object structure action requirements: compatibility
model functional recognition". Int. J. Intelligent Systems, 6, 313{336.
Valenzuela-Rendon, M. (1991). \The Fuzzy Classifier System: Classifier System Continuously Varying Variables". Proceedings Fourth International Conference
Genetic Algorithms, pp. 346{353.
Watkins, C. J. (1989). Models Delayed Reinforcement Learning. Ph.D. thesis, Cambridge
University.
Winston, P. H., Binford, T. O., Katz, B., & Lowry, M. (1983). \Learning physical descriptions functional definitions, examples, precedents". National Conference
Artificial Intelligence, 433{439.

222


