journal artificial intelligence

submitted published

technical recommendation study combining
multiple information sources
chumki basu

cbasu cs rutgers edu

haym hirsh

hirsh cs rutgers edu

department computer science rutgers university frelinghuysen road
piscataway nj
telcordia technologies inc south street
morristown nj
department computer science rutgers university frelinghuysen road
piscataway nj

william w cohen

wcohen whizbang com

craig nevill manning

nevill cs rutgers edu

whizbang labs whizbang labs east henry street
pittsburgh pa

department computer science rutgers university frelinghuysen road
piscataway nj

abstract

growing need manage exploit proliferation online data sources opening opportunities bringing people closer resources need instance
consider recommendation service researchers receive daily pointers
journal papers fields interest survey known approaches
technical recommendation ask extended deal
multiple information sources specifically focus variant
recommending conference submissions reviewing committee members
offers us testbed try different approaches whirl information integration system able implement different recommendation derived
information retrieval principles use novel autonomous procedure gathering
reviewer interest information web evaluate compare
methods preference data provided members aaai conference
reviewing committee along data actual submissions

introduction
define recommendation follows
given representation interests relevant papers

fact replace papers definition name artifact
choice yet another instantiation recommendation
makes recommendation interesting


fibasu hirsh cohen nevill manning

ability automatically filter large set papers
aligned one interests advantages growing number
publications many online dicult keep latest even
within one field timeliness information becoming critical
desirable reach target audience minimal latency although
straightforward finding relevant papers may look close matches
person interests content less clear represent
interests researchers contents papers
another feature sets recommendation apart variant
must dealt regular basis numerous conference chairs conferences
offer venue large number fairly specific papers must distributed smaller
number reviewers within tight timeframe even scope
constrained degree topic conference organizers reviewers still must
expend great deal time effort begin reviewing process
would suggest real value finding ways automating filtering process
would make less burdensome potential consumers
consider recommending focused sets technical papers use
conference reviewing platform explore series questions relating recommendation process interest ai community
recently since proposed challenge task ijcai geller focus
conference reviewing turns natural choice since obtain data
set papers e conference submissions obtain information
preferences set reviewers submissions following section discuss related work addresses conference reviewing consider
work area recommender systems e g recommending articles newsgroup
readers recommending web web site visitors contribute task
however focus varying sources information data representations
thereby allowing us formulate different recommendation recombine sources computing similarity indeed difference
performance vary amount source data compared baseline
single source information data representations compare
recommendation collaborative filtering
random assignment papers reviewers apply methods experimental data
involving reviewer preferences conference abstracts aaai conference

know recommendation
already know recommending papers reviewers generally
arbitrary researcher trying selective choosing papers ultimately reach consumer relevance interests expertise however finding
papers conference reviewers necessarily complex task since papers may
assigned reviewers criteria instance reviewer load balancing
con ict resolution reviewer author aliations may two criteria addition
data obtained permission aaai aaai reviewers appropriate
authors submitted papers



fitechnical recommendation study combining multiple information sources

reviewer reviewing preferences may uenced considerations
readability novelty example preference novelty may lead reviewer choose
simply relevant interests
methods suited address latter issues number reasons first
confidentiality purposes lack information related author identity aliation
submitted conference papers secondly since constraint satisfaction main
concern primarily interested finding best papers person without
regard whether multiple people receive incorporate
criteria selection procedure way represent novelty
respect consumer thereby means recognizing
finally methods distinguish notion interest expertise
respect reviewers general recommendation researcher
may want retrieve papers areas outside expertise case separate
representation would needed
previous work area assigning conference papers reviewers approached
one content information retrieval dumais nielsen used
data provided members reviewing committee hypertext conference reviewers submitted abstracts papers interests
provided complete relevance assessments papers submitted conference
information retrieval method known latent semantic indexing lsi compared reviewer abstracts submissions ranking submissions
least similar reviewer noticed performance
metric evaluates number relevant articles returned top
could achieve average improvement automated methods compared
random assignment articles reviewers
encouraging believe widespread availability online
resources introduces opportunities exploring issues reviewers
asked supply interest information process gleaning reviewer interest
data automated simple methods well retrieving relevant papers
approximation reviewer interests automatic collection reviewer
interest information web effectively removes reviewer loop
novel aspect
yarowsky florian attempted similar task acl conference however primary focus classification assignment every exactly
one six conference committees used papers submitted acl
conference electronic form requested committee members provide representative papers number papers returned members insucient
augmented collection papers downloaded online sources used
content retrieval within context vector space model salton one
routing strategies main first computed centroid reviewer
representative papers computed centroid committee
sum reviewer centroids classified assigned committee
computing cosine similarity committee centroids choosing one
highest rank amongst approaches experimented naive bayes classifier
assessment similarity reviewing committee members authors cited


fibasu hirsh cohen nevill manning

papers system performance relative human judges
task evaluated actual assignments provided program chair conference extrapolated automated methods could effective human judges
especially cases judges may less experienced
dealing large conferences several hundred papers covering variety areas information load even greater conference organizers reviewers
alike cases getting evaluative relevance judgments submitted even accepted papers reviewers feasible example aaai conference
reviewers even state preferences papers potentially
review instead stop scanning list soon filled quota
bids papers expressed interest reviewing therefore focus building
extensible framework recommendation defining process whereby systematically incorporate information formulating recommendation
purpose generating better recommendations
content information retrieval known content filtering popular
recommendation method consider systems recommend web syskill
webert pazzani billsus number systems webwatcher
fab content filtering mainly part hybrid
involves collaborative filtering whereas content filtering looks contents
artifact e g words web page collaborative filtering consider
opinions minded people respect artifacts collaborative filtering
used recommend netnews articles konstan miller maltz herlocker gordon
riedl movies hill stead rosenstein furnas basu hirsh cohen
music cohen fan shardanand maes even jokes gupta
digiovanni narita goldberg since content collaborative methods
use data orthogonal one another opportunities come hybrid
approaches use combinations data work movie recommendation
provides another example design hybrid system hybrid systems exploit data
multiple sources expectation better compensating
limiting factor data sparseness associated single source
current study would identify different sources information describe
papers reviewers expectation individual pieces along
knowledge combine make difference recommendations
although share common goal combining data multiple sources
hybrid recommendation approaches develop strictly contentbased evaluative purposes compare
applying collaborative filtering methods set reviewer preferences

representing papers reviewers
recommendation represent entity variety information
sources enumerate different combinations sources evaluate effectiveness combinations ranked retrieval methods recommendation
two types entities papers consumers reviewers
case entity represent salient features entity sequence


fitechnical recommendation study combining multiple information sources

one information sources addition need another type information
source relates reviewer namely reviewers actual preferences
papers begin discussion choice information sources
choices data typically used assign papers reviewers
usually provided explicitly papers authors choices rely implicit
knowledge mined semi structured data available web

information sources

experiments compilation submitted abstracts obtained
aaai aaai conference papers submitted conference
aaai gave us collection papers use experiments abstracts
accepted papers abstracts papers rejected whose authors
granted aaai permission provide abstract work excluded
papers authored authors
submission obtained title abstract set user assigned keywords
prespecified list therefore associated set three information sources provided papers authors although one may consider
body another source information available reviewers
us use source

reviewer information sources

far seen example entity represented
multiple information sources mainly composed distinct units title
abstract etc however another case may want multiply represent
entity consider trying automatically compose representation reviewer interests
may try first go reviewer home page may decide look
around reviewer papers sources offer different point view
reviewer interests therefore considered separate unit focus
sources reviewer entry level home page papers referenced
home page substitute asking reviewer provide interest information
believe home online papers credible information sources since
likely fair number conference reviewers stated interests
sources since one information sources abstract
decided represent reviewer abstract interests case home
entire text reviewers entry level home page taken abstract
reviewer interests case postscript files define abstract first
words extracted
extracted information web pre existing utilities
reviewers home fed names aliations members review
committee ahoy home page finding engine shakes langheinrich etzioni
ahoy returned least one match supplied url starting point
w mir http service retrieves files contents web sites used
http ahoy cs washington edu
http www math uio janl w mir



fibasu hirsh cohen nevill manning

w mir download html files postscript files accessible entry level
home page residing site since person papers may directly
available one site additionally retrieved cross references sites
contained postscript files w mir postscript files converted
ascii prescript nevill manning reed witten
postscript files retrieved reviewer treated uniformly although would
desirable attempt future work make attempt determine
timeliness especially respect reviewer current interests
distinguish journal papers conference papers even lecture notes
reason attempt detailed analysis contents
files e g automatically extract titles abstracts etc instead rely heuristics
looking first n words approximate abstract although detailed
analysis likely valuable recommendation process immediate goal
obtain gross sense usability sources semi structured information

reviewer preferences
evaluate queries need ground truth set data specifying
papers reviewer selected suitable review information
evaluate different approaches perform making choices note
approximation full set abstracts reviewer might liked
reviewing process requires reviewer minimum quota papers
quota reached reviewer need look papers
view optimistically yielding close approximation reviewer full set
preferences would since reviewers able peruse abstracts keywords often
attempt inspect least subset papers labeled keywords areas
knowledgeable
experiments ground truth comes actual preferences stated
aaai reviewers gave aaai permission release preference information papers considered work point data ects
reviewers initial preferences reviewing data papers
reviewers actually received following aaai reviewer assignment process
course one potential limitation data portion data
may representative entire data conference example
preference data approximately half reviewers predicting preferences
collection papers whose distribution skewed towards accepted papers
issue whether aaai researchers representative much larger community
researchers large ask similar question user populations
conferences well however consider acceptable limitations resulting
use conference reviewing platform recommendation
moment focus postscript convenience reason limit
one file format main constraint able extract words document



fitechnical recommendation study combining multiple information sources

recommendation methodology

section examine collaborative content methods recommendation methods allow us explore use different subsets data described
previous section

recommending reviewer information sources

following sections outline content recommendation framework uses
data describing papers well data describing reviewers make recommendations reviewer preference data used evaluation purposes input
recommendation process
order locate papers closely match reviewer interest data rely ad hoc
similarity metrics commonly used information retrieval community describe
methods section whirl brief reviewer compare
given reviewer representation appropriate information source
comparisons implemented query returns rank ordered list
papers consequently compute precision top n proportion papers
returned actually preferred reviewer query final score
query average value computed subset reviewers
larger set reviewers gave us permission
recommendation take different reviewer information sources
inputs since data plotted along two dimensions let reviewer set
information sources describing reviewers set information sources describing
papers construct reviewer matrix entry matrix
score measuring effectiveness respective sources reviewer
compute similarity reviewers papers performing ranked retrieval
instance given reviewer representations described construct
matrix gives us possible evaluations scores refer matrix
recommendation sources matrix
conceptually extend recommendation sources matrix along dimension
considering combinations rows columns refer augmented matrix
source combinations matrix define recommendation
combination method procedure applied one rows columns source
combinations matrix introduces another dimension comparison combination
method consider looking replicates source combinations matrix
pose following questions experimental analysis


j

recommendation incorporate information lead better performance
method combining data used make difference
whirl

queries use whirl system specifically designed informationintegration tasks cohen b cohen hirsh tasks often necessary manipulate general way information obtained many heterogeneous online


fibasu hirsh cohen nevill manning

sources potentially data organization terminology particular
whirl makes possible integrate information decomposed represented
clean modular way example would information home
postscript papers represented separately information integration tool
resolve sources information
whirl conventional dbms extended use ad hoc similarity metrics
developed information retrieval community metrics reason
pieces text culled heterogeneous sources similarity values rather
strict equality whirl computes similarity vector space representation
model text salton text object represented vector term weights
terms stemmed porter porter
tfidf weighting scheme similarity two vectors computed cosine
similarity metric answers query presented rank ordering generated
tuples tuples similar pairs attribute fields appearing first
example whirl pose following query
select reviewer name id
reviewer
reviewer descriptor sim abstract

query return list reviewer names ids papers whose abstracts
similar reviewer interest descriptor rather returning tuples
descriptor abstract fields identical would performed traditional
database join query returns name id pairs tuples whose fields contain
similar terms ordered according decreasing value similarity advantage
ad hoc joins without requiring textual fields identical one another important
text comes multiple sources thereby may use different terminology
important perspective comparing relative importance different fields
one another ecient way
use whirl data must stored form whirl relations
data constructed two relations one representing different information sources
conference submission form relation containing id abstract keywords
title every reviewer form reviewer relation contains single tuple
attributes representing reviewer name representation reviewer
interests example reviewer home page
far discussed use whirl formulate queries involving single
information source reviewers papers however advantage whirl
lies simplicity extend queries incorporate multiple sources primary advantage whirl work ease
measure impact conjunctive queries incorporating data multiple sources
form conjunctive queries adding multiple conditions clause
select reviewer name id
reviewer
reviewer descriptor sim abstract
reviewer descriptor sim keywords


fitechnical recommendation study combining multiple information sources

whirl clause contains multiple conditions similarity scores
individual conjuncts combined taking product though
independent probabilities since similarity scores independent probabilities
use convenient way combine scores albeit one offers straightforward
combination previously studied cohen
query whirl would assign score ects similarity submitted
abstract reviewer descriptor well similarity submitted
keywords reviewer descriptor
combining information sources query expansion

mean recommendation combine data multiple information sources means enumerating information sources used possible
inputs defining way use sources compute similarity
instance suppose look reviewer source sources given collection
reviewers papers decide whether likely interest reviewer
compute similarity reviewer source sources
combine two similarity scores alternatively compute single similarity score
first combining two sources single representation computing
similarity respect reviewer source
idea combining two sources single representation implemeted
appending terms sources information retrieval terms relevant sources
often appended baseline representation query process query
reformulation usually referred query expansion since methods bear
resemblance query expansion make analogy expansion methods
described following sections course prior knowledge
relevance sources sense differ information retrieval
implementation query expansion
compare relative performance recommendation
multiple dimensions along compare differentiate
methods used combine data compute similarity differentiate information sources used comparison
words set inputs one method query expansion perform
better another want compare merit single source consider
two groups include given source input
exclude source simply count number times
include source outperform exclude determine relative
merit source
concatenation method

one way add information data source append terms appearing
source original whirl query type query single
whirl conjunct textual fields appearing conjunct grow
addition terms call method queryconcat


fibasu hirsh cohen nevill manning

suppose example start base query previous section
compares reviewer descriptors abstracts suppose want compare
reviewer descriptors abstracts keywords one
way use queryconcat method form field representing
union words appearing abstract keywords fields
substitute original query let descriptor abstract keywords
query
select reviewer name id
reviewer
reviewer descriptor sim descriptor

similarly replace descriptor clause represent different
combinations fields abstract keywords title union
operator
conjunction method

previously stated important motivation whirl ability execute
conjunctive queries use combine information sources recommendation process type query instead adding terms particular text field
add conjuncts original refer method reformulating queries
queryconjunct
enumerate query combinations considered queryconjunct follows
sources queryconcat begin queries
select reviewer name id
reviewer


replacing body clause following
reviewer descriptor sim abstract
k reviewer descriptor sim keywords
reviewer descriptor sim title
ak reviewer descriptor sim abstract
reviewer descriptor sim keywords
reviewer descriptor sim abstract
reviewer descriptor sim title
kt reviewer descriptor sim keywords
reviewer descriptor sim title
akt reviewer descriptor sim abstract
reviewer descriptor sim keywords
reviewer descriptor sim title

assign labels abstract k keywords title queries identify
sources used use labels comparable fashion queryconcat
method representing information sources concatenated together


fitechnical recommendation study combining multiple information sources

queries vary source data used represent
reviewers first variant accounts case reviewer descriptor contains
words reviewer home page second accounts case descriptor
contains union first words extracted postscript file obtained
reviewer web
decided try yet another combination see whether representations
reviewers would improve performance simplicity chose test hypothesis
expanded conjunctive query involving single extra conjunct constructed
reviewer table contains two attributes papers consisting abstracts
reviewer postscript papers homepage consisting reviewer home page
ran queries additional conjunct appearing
clause
reviewer homepage sim keywords

chose use keywords descriptor intuitions
keywords reviewer homepage would greater number words common

recommending reviewer preferences

since evaluations reviewers common set papers one
recommending papers would take information use collaborative
filtering note actual conference reviewing collaborative filtering
method assigning papers may practical although benefit
preferences set reviewers study information generally
available reviewers making selections thereby making
dicult base predictions preferences others nevertheless worthwhile
measure impact reviewer preferences purpose recommending papers
recommendation methodology collaborative filtering approaches implemented follows reviewer presented recommended online
manner presented reviewer tells system relevant assigned rating said rated
positively relevant assigned rating said rated
negatively let rating r p represent rating assigned p
reviewer r relevant reviewer provides single relevant
positive example order condition future recommendations since know
papers liked reviewers simulate process data
experiment two collaborative filtering knn hill et al
cohen fan extended direct bayes cohen fan let p p p
represent papers previously rated reviewer trials
knn uses following distance metric locate reviewers r closest
current reviewer respect papers already rated




dist r r jrating r p rating r p j jrating r p rating r p j




compute score arbitrary p respect ratings
k closest reviewers r r follows
k



fibasu hirsh cohen nevill manning

score p rating r p rating r p
k

according methodology highest scoring presented
reviewer next recommendation
extended direct bayes viewed ad hoc extension direct bayesian recommendation define r p p represent laplace corrected estimate
prior probability reviewer give p positive rating r p p
thought measuring relatedness two papers consider arbitrary
trial let p p p represent papers rated positively
reviewer previous trials consider arbitrary trial
use following scoring function rank p


j

j



j



score p r p p r p p


subtrahend expression represents probability p related
p assuming p independent




evaluation methodology

following sections evaluate performance recommendation
collaborative filtering compute recommendations reviewer run
positive examples use feedback reviewer list recommendations
measure precision top n gives us proportion items returned
top n given reviewer actually preferred reviewer although
possible use evaluation metrics compute precision different levels papers
returned since well suited conference reviewing task since reviewer may get
list papers review would simulate recommending top
papers returned methods computing precision measure percentage
papers list would matched reviewer preferences metric
commonly used literature instance dumais nielsen mostly used
measure e number relevant articles top reporting
since constituted reasonable reviewer load additionally report precision
top knn set k experiments
recommendation seen choice query expansion method
crossed choice input data sources methods queryconjunct
queryconcat ran queries detailed previous section resulted
runs per reviewer per method run returned ordered list ids run
measure precision top n n n discussion
refer run abstracts reviewer papers p run similarly h runs
reviewer home page finally ph runs combine sources information
extra conjunct report represent precision values averaged
across reviewers order us compare performance across different information
sources need evaluation population reviewers
reviewers provided preference data home papers available online
therefore performed set runs reviewers randomly chosen set


fitechnical recommendation study combining multiple information sources

source
p top
h top
ph top
p top
h top
ph top









k















ak















kt







akt







table average precision scores top top papers returned queryconjunct
reviewers home papers available online report averaged
across reviewers
mentioned earlier reviewer choices may uenced variety factors
ranging person curiosity readability many factors dicult
model furthermore human judges may assign papers reviewers according criteria
relevance contents reviewer interests individual opinions
may vary therefore highly unlikely proposed methods achieve
precision unfortunately given nature able get
assessment human judges would done task nevertheless
evaluate recommendation framework built content information retrieval
principles compare relative performance reasonable baseline approaches


number questions would keep mind analyze
course experiments vary amount information input
method query expansion used one questions
would answer set suited task
hand ask whether choice inputs measurable differences
performance tabulation provides basis analyzing contentbased presented table table baseline method
compare random assignment method assigns reviewer random
collection papers method expect precision words
means select papers randomly average reviewer would
fewer papers selected
table table replicates source combinations matrix discussed
earlier since ran two trials top n papers returned table actually
concatenated representation matrices top top experiments
first three rows table table report precision figures top
papers returned queryconjunct method queryconcat method respectively


fibasu hirsh cohen nevill manning

precision top top

compare dat
x




queryconjunct method
















queryconcat method





figure comparison two query methods
similarly top papers returned bottom three rows
tables since view rows representing reviewer sources used query
columns representing sources measure impact adding data
two ways reading across row across groups columns representing n information
sources gauge vary data included queries
similarly reading column gauge differences
reviewer data included queries
given information say performance recommendation
used different methods query expansion compare relative
performance two methods queryconjunct queryconcat values listed
table table note cases performance methods exceeds
random selection accuracies factor times better figure
record information data point every query uses two sources
information since methods differ combine data two sources
meaningless plot points refer queries single source figure
x axis represents queries expanded queryconcat method axis represents
queries expanded queryconjunct method point falls x line
two methods yielded performance query information
sources points fall area x line mark queries
queryconjunct higher precision queryconcat data reveal almost
cases queryconjunct higher precision queryconcat thereby making queryconjunct
dominant two query expansion methods preferred method two
task hand
expectation increase source data notice increase
precision specifically note queryconjunct query uses
information submission majority cases performs statistically significantly


fitechnical recommendation study combining multiple information sources

source
p top
h top
ph top
p top
h top
ph top









k















ak















kt







akt







table average precision scores top top papers returned queryconcat
better queries use less information case performs statistically significantly worse
note adding information lead monotonically better
notice queryconjunct case top papers returned hkt indistinguishable hakt note pht performs better though statistically
significantly better phkt similar cases queryconcat explain gaps indeed gaps e true statistical differences
may consider explanation adding information may increasing amount
noise representations consider example keywords fixed list
often poor match real subject matter special cases use
keywords source could lead degradation retrieval performance
analogous analysis sources examine column
table table measure effect adding information reviewer representation queryconjunct majority time queries incorporating
information ph entries perform statistically significantly better single source
queries p h entries
far illustrated move across groups columns blocks
rows source combinations matrix adding sources queries
improvement significant gains realize focusing
queryconjunct every reviewer source consider queries contained data
single source lowest precision pair queries
corresponding query row matrix made use sources
report resulting improvement precision table top
note best case gain improvement precision going
single source multi source query top gain improvement
comparisons two queries qi qj made two tailed sign test specifically
consider set rij reviewers r precision qi r precision qj r estimate
probability
pij p rob precision qi r precision qj r j r rij
consider difference statistically significant one reject confidence null
hypothesis pij generated j rij j independent ips fair coin



fibasu hirsh cohen nevill manning

single source queries improvement adding two sources
pt top

ha top

phk top

pt top

ha top

phk top


table comparision single source vs multi source queries
methods

top top
knn

extendeddirectbayes

table average precision scores top top papers returned collaborative filtering methods
support intuitions incorporating information
queries quality retrieval improves since different
source single source queries row table note impact
given source dependent reviewer representation use
still come assessment sources significant conference reviewing task queryconjunct present series figures figure figure
illustrate impact source plotting precision values queries exclude
source along x axis precision values queries include source along
axis n n point falls x line queries
exactly performance choice source irrelevant points fall
area x line mark queries higher precision compared
query counterparts contain source
simply counting number times queries include source outperform
queries include source one way ranking sources
decreasing order importance case queries include abstract source
papers home page source reviewers highest rates success
compared information sources papers reviewers respectively
natural question ask whether trends noticed queryconjunct
hold queryconcat answer means queryconcat
give us definitive answer question whether information really better
noticed query performance linked reviewer
sources linked query expansion method


fitechnical recommendation study combining multiple information sources

precision top top

dat
x





queries abstract
















queries without abstract





figure role abstract information source

precision top top

k dat
x




queries keywords

















queries without keywords





figure role keywords information source



fibasu hirsh cohen nevill manning

precision top top

dat
x





queries titles
















queries without titles





figure role title information source

precision top top

p dat
x




queries reviewer papers

















queries without reviewer papers





figure role papers information source



fitechnical recommendation study combining multiple information sources

precision top top

h dat
x



queries reviewer homepages


















queries without reviewer homepages





figure role homepage information source
table collaborative filtering runs report averages
precision values computed top n n n papers returned
reviewer recommendation lists since stop recommending
exhausted set positive examples reviewer reviewer recommendation lists
varying lengths cases size list less n still compute
precision top n assuming remaining items incorrect predictions methods
collaborative filtering exceed random selection significant margin
top papers returned collaborative recommendation methods competitive best performance queryconcat already interesting observation
since methods differ method different data make recommendations state use queryconjunct information
sources recommend papers average almost four papers coincide reviewer
preferences compared random selection collaborative filtering queryconcat
method yields papers interest reviewers
summary learned experiments found within
context peer reviewing papers make recommendation process less
people intensive recommendation systems require users provide samples
preferences used extrapolate future behaviors collaborative
methods go even preference information across multiple users predict
preferences single user automatically collecting reviewer interest information
web sources precomputing similarities profiles content
require less input reviewers furthermore content retrieval methods
exceed performance collaborative methods task
believe recommendation framework provides extensible way
formulating queries provides control information content queries
control much information include queries
incorporate information data become available evaluate data


fibasu hirsh cohen nevill manning

sources combinations effective thereby fine tuning query formulation
process

related work query reformulation

since work expanding queries whirl viewed type query
reformulation review related work information retrieval community
topic salton describes process query reformulation moving
given query towards relevant items away nonrelevant ones context
vector space model retrieval means given query expression form
salton
q q q qt

q number representing weight assigned term want
arrive query expression




q q q qt








weights adjusted terms introduced vector
representation terms effectively removed reducing respective
weights
harman describes operational procedure underlying process merging document query vectors specifically means query terms
original query appearing relevant documents added initial query
expression expansion occurs positive negative weights depending
whether terms appears relevant non relevant document
description assumes relevance judgments documents
system return practically speaking type information hard come
therefore people seeking compensate lack information expanding
queries variety techniques use thesauri relevance feedback
latter case query reformulation part iterative interactive process whereby
users presented retrieval asked supply feedback regarding
relative importance
comparing methods query reformulation make couple
observations first query reformulation driven knowledge precomputed
data colection given entities papers abstracts keywords
titles make sense vary amount information queries
equivalent table collection table lookup run time determine
formulations promising
note way construct queries queryconjunct method combines
aspects boolean vector space query formulation hybrid case boolean queries relevance feedback lead query expressions
consisting term conjuncts salton
term term term
notice replace term vector expression
query expression formulated according queryconjunct method


j



k





fitechnical recommendation study combining multiple information sources

conclusions

shown collect information reviewers automatically
web use part recommendation framework route papers
reviewers treat one decomposing reviewer interest
contents information sources combining information sources
different query formulations experiments compared two ways formulating
queries content information retrieval one collaborative
found recommendation conjunctive queries outperforms
approaches looked different subsets information sources
case optimal found information
generally lead better performance
practical setting recommendation method choice likely depend
number factors ranging availability information ease use one
hand framework provides exible alternative simple keyword searches
less intrusive alternative collaborative methods hand methods
assume obtain data reliable accurate timely
optimistic web provide credible information sources used
successfully recommendation process

acknowledgments

extend thanks aaai aaai reviewers aaai authors members
rutgers machine learning group reviewers
inputs work
note following property respective companies listed
whirl labs lsi telcordia technologies inc

references

basu c hirsh h cohen w recommendation classification social
content information recommendation proceedings aaai
cohen w integration heterogeneous databases without common domains
queries textual similarity proceedings acm sigmod
cohen w b whirl information integration ieee intelligent
systems ieee press
cohen w fan w web collaborative filtering recommending music crawling web proceedings www
cohen w hirsh h joins generalize text classification whirl
proceedings kdd
dillon desper j automatic relevance feedback boolean retrieval systems
journal documentation


fibasu hirsh cohen nevill manning

dumais nielsen j automating assignment submitted manuscripts
reviewers proceedings acm sigir
geller j challenge ijcai prove value ai ai
proceedings ijcai
gupta digiovanni narita h goldberg k jester lineartime collaborative filtering applied jokes workshop recommender
systems acm sigir
harman relevance feedback revisited proceedings acm sigir
hill w stead l rosenstein furnas g recommending evaluating
choices virtual community use proceedings chi
konstan j miller b maltz herlocker l gordon l riedl j grouplens
applying collaborative filtering usenet news vol
nevill manning c reed witten extracting text postscript software
practice experience
pazzani billsus learning revising user profiles identification
interesting web sites machine learning
porter sux stripping program
salton g automatic text processing addison wesley
salton g improving retrieval performance relevance feedback readings
information retrieval
shakes j langheinrich etzioni dynamic reference sifting case study
homepage domain proceedings www
shardanand u maes p social information filtering automating
word mouth proceedings chi
yarowsky florian r taking load conference chairs towards
digital routing assistant proceedings joint sigdat conference
empirical methods nlp large corpora




