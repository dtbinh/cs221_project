Journal Artificial Intelligence Research 34 (2009) 61-88

Submitted 04/08; published 02/09

Asynchronous Forward Bounding Distributed COPs
Amir Gershman
Amnon Meisels
Roie Zivan

AMIRGER @ CS . BGU . AC . IL
@ CS . BGU . AC . IL
ZIVANR @ CS . BGU . AC . IL

Department Computer Science,
Ben-Gurion University Negev,
Beer-Sheva, 84-105, Israel

Abstract
new search algorithm solving distributed constraint optimization problems (DisCOPs)
presented. Agents assign variables sequentially compute bounds partial assignments
asynchronously. asynchronous bounds computation based propagation partial
assignments. asynchronous forward-bounding algorithm (AFB) distributed optimization
search algorithm keeps one consistent partial assignment times. algorithm described detail correctness proven. Experimental evaluation shows AFB outperforms
synchronous branch bound many orders magnitude, produces phase transition
tightness problem increases. analogous effect phase transition
observed local consistency maintenance applied MaxCSPs. AFB algorithm
enhanced addition backjumping mechanism, resulting AFB-BJ algorithm.
Distributed backjumping based accumulated information bounds values processing concurrently queue candidate goals next move back. AFB-BJ algorithm
compared experimentally DisCOP algorithms (ADOPT, DPOP, OptAPO) shown
efficient algorithm DisCOPs.

1. Introduction
Distributed Constraint Optimization Problem (DisCOP) general framework distributed
problem solving wide range applications Multi-Agent Systems generated
significant interest researchers (Modi, Shen, Tambe, & Yokoo, 2005; Zhang, Xing, Wang, &
Wittenburg, 2005; Petcu & Faltings, 2005a; Mailler & Lesser, 2004; Ali, Koenig, & Tambe, 2005;
Silaghi & Yokoo, 2006). DisCOPs composed agents, holding one variables.
variable domain possible value assignments. Constraints among variables (possibly
held different agents) assign costs combinations value assignments. Agents assign values
variables communicate other, attempting generate solution globally
optimal respect costs constraints (Modi et al., 2005; Petcu & Faltings, 2004).
wide scope motivation research DisCOP, since distributed COPs
elegant model many every day combinatorial problems distributed nature. Take
example large hospital composed many wards. ward constructs weekly timetable
assigning nurses shifts. construction weekly timetable involves solving constraint
optimization problem ward. nurses every ward qualified work
Emergency Room. Hospital regulations require certain number qualified nurses (e.g.
Emergency Room) shift. imposes constraints among timetables different wards
generates complex Distributed COP (Solotorevsky, Gudes, & Meisels, 1996).
c
2009
AI Access Foundation. rights reserved.

fiG ERSHMAN , EISELS , & Z IVAN

Another example sensor networks tracking problem (Zhang, Xing, Wang, & Wittenburg,
2003; Zhang et al., 2005), task assign sensors tracking targets,
maximal number targets tracked sensor collection. solved using
DisCOP model.
DisCOP modeling solve problems log based reconciliation (Chong & Hamadi,
2006), copies data base exist several physical locations. Users perform actions
data base copies, user local copy. actions cause data base change,
initially copies identical, later actions change longer
identical. Logs user actions kept. problem merge logs, single log
keeps many actions possible. always possible keep local logs intact,
since actions constrained actions (for example reconcile deletion
item database later print update it).
DisCOPs represent real life problems cannot solved centrally several
reasons, among lack autonomy, single point failure privacy agents.
hospital wards example, wards want maintain degree autonomy local problems
involving constraints every single nurse. sensor example, sensors small
memory computing power therefore cannot solve problem centralized fashion.
database example, centralization possible, issues network bottleneck, computing
power single point failure encourage looking distributed solution.
present paper proposes new distributed search algorithm DisCOPs, Asynchronous
Forward-Bounding (AFB). AFB algorithm agents assign variables generate partial
solution sequentially. innovation proposed algorithm lies propagating partial solutions asynchronously. Propagation partial solutions enables asynchronous updating bounds
cost, early detection need backtrack, hence algorithms name AFB. form
propagating bounds asynchronously turns generate efficient form concurrent
computation participating agents. efficient algorithms use asynchronous
assignment processes, especially hard instances DisCOPs.
overall framework AFB algorithm based Branch Bound scheme. Agents
extend partial solution long lower bound cost exceed global bound,
cost best solution found far. proposed AFB algorithm, state
search process represented data structure called Current Partial Assignment (CPA). CPA
starts empty initializing agent records assignments sends next agent.
cost CPA sum costs constraints includes. Besides current assignment
cost, agents maintain CPA lower bound updated according information
receive yet unassigned agents. agent receives CPA, adds assignments
local variables partial assignment received CPA, assignment lower bound
smaller current global upper bound found. Otherwise, backtracks sending
CPA former agent revise assignment.
agent succeeds extend assignment CPA sends forward copies updated
CPA, requesting unassigned agents compute lower bound estimations cost partial
assignment. assigning agent receive estimations asynchronously time use
update lower bound CPA.
Gathering updated lower bounds future assigning agents, may enable agent discover
lower bound CPA sent forward higher current upper bound (i.e. inconsistent). discovery triggers creation new CPA copy CPA sent
forward. agent resumes search trying replace inconsistent assignment. time
62

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

stamp mechanism proposed Nguyen, Sam-Hroud, Faltings (2004) used Meisels
Zivan (2007) used agents determine updated CPA discard obsolete CPAs.
concurrency AFB algorithm achieved fact forward-bounding performed concurrently asynchronously agents. form asynchronicity similar
employed Asynchronous Forward-Checking (AFC) algorithm distributed constraint
satisfaction problems (DisCSPs) (Meisels & Zivan, 2006; Meseguer & Jimenez, 2000). AFB
enhanced backjumping (Zivan & Meisels, 2007), resulting algorithm performs concurrently distributed forward bounding backjumping prunes search space DisCOPs
efficiently. demonstrated extensive experimental evaluation Section 6 AF B
demonstrates phase transition randomly generated DisCOPs (Larrosa & Schiex, 2004).
extensive evaluation includes comparisons performance AF B best DisCOP
search algorithms. include asynchronous branch bound ADOPT (Modi et al., 2005),
well algorithms based principles - DPOP (Petcu & Faltings, 2005a) uses
two passes pseudo-tree Opt AP O,that divides DisCOP sub-problems (Mailler &
Lesser, 2004).
plan paper follows. Distributed Constraint Optimization presented Section 2. Section 3, AF B algorithm full details presented. Section 4 version
AF B algorithm enhanced conflict directed backjumping (CBJ) presented. correctness proof AF B algorithm presented Section 5. Section 6 extensive empirical
evaluation AF B algorithm presented. AF B compared state art DisCOP
algorithms, ADOP AF B include centralization problems data
DP OP Opt AP (Petcu & Faltings, 2005a; Mailler & Lesser, 2004), based
different principles. Conclusions presented Section 7.

2. Distributed Constraint Optimization
Formally, DisCOP tuple < A, X , D, R >. finite set agents A1 , A2 , ..., . X
finite set variables X1 ,X2 ,...,Xm . variable held single agent (an agent may hold
one variable). set domains D1 , D2 ,...,Dm . domain Di contains finite set
values assigned variable Xi . R set relations (constraints). constraint
C R defines none-negative cost every possible value combination set variables,
form C : Di1 Di2 . . . Dik R+ {0}. binary constraint refers exactly two
variables form Cij : Di Dj R+ {0}. binary DisCOP DisCOP
constraints binary. assignment (or label) pair including variable, value
variables domain. partial assignment (PA) set assignments, variable
appears once. vars(PA) set variables appear PA, vars(P A) = {Xi |
Di (Xi , a) P A}. constraint C R form C : Di1 Di2 . . . Dik R+ {0}
applicable PA Xi1 , Xi2 , . . . , Xik vars(P A). cost partial assignment PA
sum applicable constraints PA assignments PA. full assignment partial
assignment includes variables (vars(P A) = X ). goal find full assignment
minimal cost.
paper, assume agent owns single variable, use term agent
variable interchangeably, assume agent Ai holds variable Xi (Modi et al., 2005; Petcu &
Faltings, 2005a; Mailler & Lesser, 2004). assume constraints binary
delay delivering message finite (Yokoo, 2000a; Modi et al., 2005). Furthermore, assume
static final order agents, known agents participating search process (Yokoo,
63

fiG ERSHMAN , EISELS , & Z IVAN

Figure 1: example DisCOP. variable two values R B, constraints
form shown table left.

2000a). assumptions commonly used DisCSP DisCOP algorithms (Yokoo, 2000a;
Modi et al., 2005).
Example 1 example DisCOP presented figure 1. 4 variables, variable
held different agent. domains variables contain exactly two values R B.
Lines variables represent (binary) constraints. cost constraints shown
table left. partial assignment {(X1 , R)} cost zero, since constraint
applicable it. partial assignment {(X1 , R), (X4 , R)} cost zero, since
constraint applicable it. partial assignment {(X1 , R), (X2 , R)} cost two, due
constraint C1,2 . partial assignment {(X1 , R), (X2 , R), (X3 , B)} cost four, due
constraints C1,2 , C2,3 , C1,3 . One solution {(X1 , R), (X2 , B), (X3 , R), (X4 , R)}
cost five. solution since full assignment lower cost.

3. Asynchronous Forward Bounding
AFB algorithm single up-to-date current partial assignment passed among agents.
Agents assign variables hold up-to-date CPA.
CPA unique message passed agents, carries partial assignment
agents attempt extend complete optimal solution assigning variables
it. CPA carries accumulated cost constraints assignments contains,
well unique time-stamp.
Due asynchronous nature algorithm, multiple CPAs may present instant,
however single CPA includes update date partial assignment. CPA
highest timestamp.
one agent performs assignment single CPA time. Copies CPA
sent forward concurrently processed multiple agents. unassigned agent computes
lower bound cost assigning value variable, sends bound back agent
64

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

performed assignment. assigning agent uses bounds prune sub-spaces
search-space contain full assignment cost lower best full assignment
found far. total order among agents assumed (A1 assumed first agent order,
assumed last).
detail, every agent adds assignment CPA sends forward copies CPA,
messages term FB CPA, agents whose assignments yet CPA. agent
receiving FB CPA message computes lower bound cost increment caused adding
assignment variable. estimated cost sent back agent sent FB CPA
message via FB ESTIMATE messages. computation bound detailed section 3.1.
Notice possible assigning agent already sent CPA forward time
estimations received. estimations indicate CPA exceeds bound, agent
generate new CPA, different local assignment (and higher timestamp associated
it) continue search new CPA. timestamping mechanism insures
obsolete CPA (eventually) discarded regardless current location. timestamp
mechanism described section 3.3.
3.1 AFB - Computing Lower Bound Estimation Cost Increment
computation lower bound cost increment caused adding assignment
agents local variable done follows.
Denote cost((i, v), (j, u)) cost assigning Ai = v Aj = u. agent Ai
value domain v Di , denote minimal cost assignment (i,v) incurred
agent Aj hj (v) = minuDj (cost((i, v), (j, u))). define h(v), total cost assigning
value v, sum hj (v) j > i. Intuitively, h(v) lower bound cost
constraints involving assignment Ai = v agents Aj j > i. Note
bound computed per agent, since independent assignments higher priority
agents.
agent Ai , receives F B CP message, compute every v Di
cost increment assigning v value, i.e. sum cost v assignments
included CP A, h(v). sum these, denoted f (v). lowest calculated f (v)
among values v Di chosen lower bound estimation cost increment agent
Ai .
Figure 2 presents constraint network. Large ovals represent variables small circles represent values. presented constraint network, A1 already assigned value v1 A2 , A3 , A4
unassigned. Let us assume cost every constraint one. cost v3 increase
one due constraint current assignment thus f (v3 ) = 1. Since v4 constrained
v8 v9 , assigning value trigger cost increment A4 performs assignment.
Therefore h(v4 ) = 1 admissible lower bound cost constraints value
lower priority agents. Since v4 conflict assignments CPA, f (v4 ) = 1
well. f (v5 ) = 3 assignment conflicts assignment CPA addition
conflicts values two remaining agents.
Since h(v) takes account constraints Ai lower priority agents (Aj s.t. j > i),
unassigned lower priority agents need estimate cost constraints Ai . Therefore,
estimations accumulated summed agent initiated forward
bounding process compute lower bound cost complete assignment extended
CPA.
65

fiG ERSHMAN , EISELS , & Z IVAN

Figure 2: simple DisCOP, demonstration
formally define:
Definition 1 CPA current partial assignment, containing assignments made agents
A1 , . . . , Ai1 .
Let us define notions past, local future costs definitions 2, 3 4.
Definition 2 PC (Past-Cost) added cost assignments made higher priority agents
CPA (the costs incurred agents A1 , . . . , Ai1 .
Definition 3 LC(v) (Local-Cost) cost incurred CPA Ai would assign value v
add CPA. Therefore,
X
LC(v) =
cost((i, v), (j, w))
(Aj ,w)CP

Definition 4 FC(v) (Future-Cost) sum lower bounds cost increments caused
agents Ai+1 , . . . , CPA additional assignment Ai = v.
X
F C(v) =
minwDj (f (w)), s.t Ai = v added CP
j>i

definitions allow us compute lower bound cost full assignment
extended CPA, use bound order prune parts search space. agent
(Ai ) receives CPA, question, lower bound would extended
assignment Ai = v. PC LC(v) known agent, FC(v) computed
time, requesting future agents (lower priority agents) compute lower bounds
send back Ai . sum PC + LC(v) + FC(v) composes lower bound, used
prune search spaces. happen agent knows full assignment already
66

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

found cost lower sum, therefore exploring search-space would lead
better cost solutions.
Thus, asynchronous forward bounding enables agents early detection partial assignments
cannot extended complete assignments cost smaller known upper bound,
initiate backtracks early possible.
3.2 AFB - Algorithm Description
AFB algorithm run agents DisCOP. agent first calls procedure
init responds messages receives ERM E message. algorithm
presented Figure 3.1. computation bounds, time-stamping mechanism
shown, explained text.
initialization, agent updates B cost best full assignment found far
since assignment found, set infinity (line 1). first agent (A1 ) creates
empty CPA begins search process calling assign CPA (lines 3-4), order find
value assignment variable.
agent receiving CPA (when received CPA MSG), first makes sure relevant. time
stamp mechanism used determine relevance CPA explained Section 3.3.
CPAs time-stamp reveals date CPA, message discarded.
case, agent processing message already received message implying
assignment agent higher priority itself, changed.
message discarded, agent saves received PA local CPA variable (line 7). Then,
agent checks received PA (without assignment variable) exceed
allowed cost B (lines 8-10). exceed bound, tries assign value
variable (or replace existing assignment case one already) calling assign CPA (line
13). bound exceeded, backtrack initiated (line 11) CPA sent higher
priority agent, since cost already high (even without assignment variable).
Procedure assign CPA attempts find value assignment, current agent, within
bounds current CPA. First, estimates related prior assignments cleared (line 19). Next,
agent attempts assign every value domain already try. CPA arrived
without assignment variable, tries every value domain. Otherwise, search
value continued value following last assigned value. assigned value must
sum cost CPA lower bound cost increment caused
assignment exceed upper bound B (lines 20-22). value found,
assignment higher priority agent must altered, backtrack called (line 23).
Otherwise, agent assigns selected value CPA.
agent last agent (An ), complete assignment reached, accumulated cost lower B, broadcasted agents (line 27). broadcast inform
agents new bound cost full assignment, cause update upper
bound B.
agent holding CPA (An ) continues search, updating bound B, calling
assign CPA (line 29). current value picked call, since CPAs cost
assignment equal B, procedure requires cost lower B.
agent continue search, testing values, backtracking case lead
improvement.
67

fiG ERSHMAN , EISELS , & Z IVAN

procedure init:
1. B
2. (Ai = A1 )
3.
generate CP A()
4.
assign CP A()
received (FB CPA, Aj , P A)
5. f estimation based received P A.
6. send (F B EST IM E, f , P A, Ai ) Aj
received (CPA MSG, P A)
7. CP P
8. empCP P
9. empCP contains assignment Ai , remove
10. (T empCP A.cost B)
11.
backtrack()
12. else
13. assign CP A()
received (FB ESTIMATE, estimate, P , Aj )
14. save estimate
15. ( CPA.cost + saved estimates) B )
16. assign CP A()
received (NEW SOLUTION, P A)
17. B CP P
18. B P A.cost
procedure assign CPA:
19. clear estimations
20. CP contains assignment Ai = w, remove
21. iterate (from last assigned value) Di found
v Di s.t. CP A.cost + f (v) < B
22. value exists
23.
backtrack()
24. else
25.
assign Ai = v
26. CP full assignment
27.
broadcast (NEW SOLUTION, CPA )
28.
B CP A.cost
29.
assign CP A()
30. else
31.
send(CPA MSG, CPA) Ai+1
32.
forall j >
33.
send(FB CPA, Ai , CPA) Aj
procedure backtrack:
34. clear estimates
35. (Ai = A1 )
36.
broadcast(TERMINATE)
37. else
38.
send(CPA MSG, CPA) Ai1

Figure 3: procedures AFB Algorithm

68

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

agent holding CPA last agent (line 30), CPA sent forward
next unassigned agent, additional value assignment (line 31). Concurrently, forward bounding
requests (i.e. FB CPA messages) sent lower priority agents (lines 32-33).
Agent receiving forward bounding request (when received FB CPA) agent Aj ,
uses time-stamp mechanism ignore irrelevant messages. message relevant,
agent computes estimate (lower bound) cost incurred lowest cost assignment
variable (line 5). exact computation estimation described Section 3.1 (it
minimal f (v) v Di ). estimation attached message sent back
sender, FB ESTIMATE message.
agent receiving bound estimation (when received FB ESTIMATE) lower priority
agent Aj (in response forward bounding message) ignores estimate already
abandoned partial assignment (identified using time-stamp mechanism). Otherwise, saves
estimate (line 14) checks new estimate causes current partial assignment exceed
bound B (line 15). case, agent calls assign CP (line 16) order change
value assignment (or backtrack case valid assignment cannot found).
call backtrack made whenever current agent cannot find valid value (i.e.
bound B). case, agent clears saved estimates, sends CPA backwards
agent Ai1 (line 38). agent first agent (nowhere backtrack to), terminate broadcast
ends search process agents (line 36). algorithm reports optimal solution
cost B, full assignment cost B CP A.
3.3 Time-Stamp Mechanism
mentioned previously, AFB uses time-stamp mechanism (Nguyen et al., 2004; Meisels &
Zivan, 2007) determine relevance CPA. requirements mechanism
given two messages two different partial assignments, must determine one
obsolete. obsolete partial assignment one abandoned search process
one assigned agents changed assignment. requirement accomplished
time-stamping mechanism following way. agent keeps local running-assignment
counter. Whenever performs assignment increments local counter. Whenever sends
message containing assignment, agent copies current counter onto message.
message holds vector containing counters agents passed through. i-th element
vector corresponds Ai counter. vector fact time-stamp. lexicographical
comparison two vectors reveal time-stamp up-to-date.
agent saves copy knows up-to-date time-stamp. receiving
new message newer time-stamp, agent updates local saved latest time-stamp.
Suppose agent Ai receives message time-stamp lexicographically smaller
locally saved latest, comparing first 1 elements vector. means
message based combination assignments already abandoned message
discarded. messages time-stamp first 1 elemental equal greater
locally saved best time-stamp message processed further.
vectors counters might appear require lot space, number assignments
grow exponentially number agents. However, agent (Ai ) resets local counter
zero time assignments higher priority agents altered, counters remain small
(log size value domain), mechanism remain correct.
69

fiG ERSHMAN , EISELS , & Z IVAN

3.4 AFB - Example Run
Suppose run AFB DisCOP figure 1. X1 create empty CPA, assign first value
R pass CPA X2 . CPA travel X2 , X3 finally X4 , agent
assigning first value (R) along way finally X4 full assignment
total accumulated cost 8. cost broadcasted agents (line 27 figure 3.1)
new upper bound (instead infinity). Next, X4 call assign CP procedure (line 29).
call result new assignment X4 , value B, since resulting full assignment
cost 7. cause another broadcast update upper bound another
call assign CP A. next call, X4 empty domain forced backtrack
CPA X3 . CPA contains assignments X1 = X2 = X3 = R, total accumulated cost
6 upper bound. Therefore X3 call assign CP (line 13). Examining
remaining values, X3 explores assignment B result CPA cost 4
(line 21), current upper bound B. CPA sent X4 (line 31). X4 calls
assign CP procedure (line 13). value R result CPA cost 6, better
upper bound B 7, therefore broadcasted (line 27). next value, B, explored
X4 results CPA cost 5, broadcasted. CPA sent backwards X3 .
X3 values try, backtracks CPA, X2 . X2 assigns next value, B,
sends CPA X3 . addition X2 sends copies CPA FB CPA messages X3
X4 (line 33). X3 receives FB CPA, computes estimation 3 (because X3
R would increase CPAs cost 3 B would increase 4), sends
information back X2 (line 6). Suppose X4 receives F B CP A, replies
estimation 1. CPA explores sub-search X2 = B (passing X3
X4 ), estimations arrive X2 . X2 saves estimations adds up. leads
discovery backtrack needed, since CPAs cost 1 (because X1 = R, X2 = B)
additional estimations 4 results sum equal upper bound B (line 15). Therefore,
X2 abandons assignment attempts assign next value (calling assign CP - line 16).
Since X2 values, call results backtrack (line 23). CPA sent backtrack
higher timestamp value CPA previously sent forward X2 , former CPA
would eventually discarded.
3.5 Discussion - Concurrency, Robustness, Privacy Asynchronicity
point time run AFB, single most-up-to-date CPA system.
agent adds assignment holds it, assignments performed sequentially. One
might think would necessarily result poor performance, search process try
take advantage existing multiple computational resources available it. concurrency
AFB comes use forward-bounding mechanism. CPA held one
agent, many copies sent forward, collection agents compute concurrently lower
bounds CPA. CPA advances next agent, process repeats,
unassigned agents constantly kept working, either receive CPA,
need compute bounds partial assignment.
degree asynchronicity similar employed Asynchronous Forward-Checking
AFC algorithm DisCSPs (Meseguer & Jimenez, 2000; Meisels & Zivan, 2006). AFC performs
similar process agents receive forward-checking messages agents performed assignments. unassigned agents perform forward-checking (checking least
one value consistent previous assignments). AFB agents compute lower
70

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

bound local cost increment due assignments made previous agents. Due
similarity named algorithm Asynchronous Forward-Bounding.
AFBs approach quite different used asynchronous assignments algorithms
ADOPT ABT (Modi et al., 2005; Bessiere, Maestre, Brito, & Meseguer, 2005).
algorithms search process attempts perform assignments concurrently collection
agents. Since many agents assigning variables simultaneously, probability
must handled algorithm, current agents view assignments made agents
incorrect. due fact agents concurrently alter assignments. algorithm
must able deal uncertainty.
search process performs assignments asynchronously may expected save time
since agents need wait assignments past agents reach them, done sequentially assigning algorithm. However, asynchronously assigning algorithms must deal
inconsistencies caused message delay. example, several higher priority agents change
assignments messages received (the others delayed) computation
performed based inconsistent agent view. type scenario, computation based inconsistent partial assignment, completely avoided sequentially assigning
algorithms.
One variation AFB algorithm agents sent FB-CPA messages, send
messages subset target agents direct constraint sending
agent. may useful communication agents limited (agents may communicate agents direct conflict) would keep algorithm correct.
change may two effects. First, less agents return bounds sending agents.
bounds significant (greater zero) since take account constraints assignments previous agents (which may conflicted with) constraints
receiving agent agents lower priority (constraint unassigned agents). Receiving less
lower bounds would invalidate correctness algorithm may cause search process needlessly explore sub-spaces could discovered dead-ends. Second,
detection obsolete CPAs may delayed since less agents receive higher timestamp (which
FB-CPA may contain). mechanism would remain correct since eventually another FB-CPA
CPA would reach agent receive FB-CPA, however may take
time single cycle messages (in words, time travel time
single message two agents). AFB algorithm intentionally presented algorithm sends FB messages unassigned agents, since constraint communication
agents assumed. case constraints exist, one attempts reduce number
messages sent algorithm, variation explored.
Privacy considered one main motivations solving problems distributively. common model distributed search algorithms DisCSPs DisCOPs enables assignments
Nogoods passed among agents (Yokoo, Ishida, Durfee, & Kuwabara, 1992; Yokoo, 2000b;
Bessiere et al., 2005; Modi et al., 2005; Zivan & Meisels, 2006; Meisels & Zivan, 2007). AF B follows model proposed Yokoo, sending assignments forward bounds partial assignments
(N ogoods) backwards. additional privacy drawback AF B fact agents learn
assignments non neighboring agents via CPAs receive neighbors.
problem easily solved AF B simple use encryption. every pair neighboring
agents share encryption key, agent would able learn assignments
neighbors receives CPA. use limited encryption DisCOP algorithms
recently proposed DP OP (Greenstadt, Grosz, & Smith, 2007).
71

fiG ERSHMAN , EISELS , & Z IVAN

If, due privacy, constraints partially known two constrained agents,
part constraint known constrained agents, bound computation
mechanism must adjusted AFB. type constraints discussed DisCSP algorithms (Brito, Meisels, Meseguer, & Zivan, 2008). best knowledge, DisCOP solver
far handled constraints. remains interesting possible extension AFB part
future work.
Robustness another important aspect distributed search algorithm. assumed
messages delivered order sent messages lost. However
message passing susceptible losses corruption data, AFB may terminate (if, say,
CPA message lost). possible local data held agents corrupt (due
mechanical failure example). solution would build self-stabilizing algorithm.
Self stabilization distributed systems (Dijkstra, 1974) ability system respond
transient failures eventually reaching maintaining legal state. self stabilizing version
shown simple DFS algorithm DisCSPs (Collin, Dechter, & Katz, 1999). Based
self-stabilizing DFS algorithm, self-stabilizing version DPOP developed (Petcu &
Faltings, 2005b). However self-stabilizing DisCSP/DisCOP solvers best
authors knowledge. Clearly, thorough study robustness self-stabilization
required DisCOP algorithms.
conclude, AFB algorithm includes concurrent computation multiple agents, without
deal uncertainty comes asynchronous assignments. agent
receives message containing partial assignment knows certainty given partial assignment one supposed receive, result network delay inconsistency.
Therefore, AFB concurrent computation certainty working consistent partial assignments. results much better performance hard instances random DisCOPs,
demonstrated empirical evaluation section 6.

4. AFB CBJ
centralized distributed CSPs backjumping accomplished maintaining data
structures allow agent deduce latest agent (in order assignments
made) whose changed assignment could possibly lead solution. agent
found, assignments following agents unmade search process backjumps
agent (Prosser, 1993).
similar process designed branch bound based solvers COPs DisCOPs.
Consider sequence assignments agents A1 , A2 , A3 , A4 , A5 A5 determined
none possible value assignments lead full assignment cost lower cost
best full assignment found far. Clearly, A5 must backtrack.
chronological backtracking, search process would simply return previous agent,
namely A4 , change assignment. However, A5 sometimes determine value
change A4 would suffice reach full assignment lower cost. Intuitively, A5 safely
backjump A3 , compute lower bound cost full assignment extended
assignments A1 , A2 A3 , show bound greater equal cost best
full assignment found far. intuitive basis backjumping added AFB.
formally, let us consider scenario Ai decides backtrack, cost
best full assignment found far B (e.g. upper bound current state search).
current partial assignment includes assignments agents A1 , ..., Ai1 .
72

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

Definition 5 CPA[1..k] set assignments made agents A1 , . . . , Ak current partial
assignment. define CP A[1..0] = {}.
Definition 6 FA[k] set full assignments, include assignments appearing
CPA[1..k]. words, set contains full assignments extended
assignments appearing CPA[1..k]. Naturally, FA[0] set possible full assignments.
backtrack, instead simply backtracking previous agent, Ai performs following
actions: computes lower bound cost full assignment FA[i-2]. bound
smaller B, backtracks Ai1 would chronological backtracking. However,
bound greater equal B, backtracking Ai1 would little good. value
change Ai1 alone could result full assignment cost lower B. result, Ai knows
safely backjump Ai2 . may possible Ai backjump even further, depending
lower bound cost full assignment
FA[i-3]. bound smaller B, backjumps Ai2 . Otherwise, knows safely
backjump Ai3 . Similar checks made necessity backjump further.
backjumping procedure relies computation lower bounds sets full assignments (FA[k]). Next, show Ai compute lower bounds. Let us define
notions past, local future costs definitions 7, 8 9.
Definition 7 PC (Past-Costs) vector size n+1, k-th element (0 k n)
equal cost CPA[1..k].
Definition 8 LC(v) (Local-Costs) vector size n + 1 computed Ai held it,
k-th element (0 k n)
X
LC(v)[k] =
cost(Ai = v, Aj = vj )
(Aj ,vj )CP s.t jk

Since CPA held Ai includes assignments A1 , . . . , Ai1 ,
j i, LC(v)[i 1] = LC(v)[j]
Intuitively, LC(v)[i] accumulated cost value v Ai , respect assignments
CPA[1..i].
Definition 9 FCj (v) (Future-Costs) vector size n+1, k-th element (0 k n)
contains lower bound cost assigning value Aj respect partial assignment CPA[1..k]. Assume structure held agent Ai . k CPA[1..k] contains
assignment Ai = v, k < value v Ai irrelevant appear CPA[1..k].
vectors provide additive lower bounds full assignments start current
CPA k, FA[k]. PC[k] isPthe exact cost first k assignments, LC(v)[k] exact cost
assignment Ai = v, j>i F Cj (v)[k] lower bound assignments Ai+1 , ..., .
Therefore, sum
X
FALB(v)[k] = LC(v)[k] + P C[k] +
F Cj (v)[k]
j>i

73

fiG ERSHMAN , EISELS , & Z IVAN

Figure 4: example DisCOP
Full Assignment Lower Bound cost full assignment extended CPA[1..k]
Ai = v.
FA[k] contains full assignments extended CPA[1..k], limited assignments
Ai = v. go FALB(v)[k], possible values v Di produce lower
bound assignment FA[k].
Definition 10 FALB[k] = minvDi (F ALB(v)[k]).
FALB[k] lower bound cost full assignment extended CPA[1..k].
distributed branch bound algorithm, bound computed Ai . PC - cost
previous agents sent along value assignment messages Ai . LC(v) - cost
assigning v Ai computed Ai . Ai requests agents ordered it, Aj (j > i),
compute FCj send results back Ai . part already existing AFB mechanism
forward bounding.
AFB algorithm (Gershman, Meisels, & Zivan, 2007) Ai already requests unassigned
agents compute lower bounds CPA send back results. additional bounds
needed backjumping easily added existing AFB framework.
4.1 Backjumping Example
demonstrate backjumping possibility, consider DisCOP Figure 4 (again, large ovals
represent variables small circles represent values). Let us assume search begins
A1 assigning value sending CP forward A2 . A2 , A3 , A4 , A5 assign
value get full assignment cost 12. search continues, fully
exploring sub-space A1 = a, A2 = a, best assignment found A1 = a, A2 =
a, A3 = b, A4 = a, A5 = b total cost B=6. Assume A3 holding CP
receiving future agent (A4 A5 ). A3 exhausted value domain must
backtrack. computes:
F ALB(a)[1] = P C[1] + LC(a)[1] + (F C4 (a)[1] + F C5 (a)[1])
74

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

= 0 + 2 + (3 + 2) = 7
F ALB(b)[1] = P C[1] + LC(b)[1] + (F C4 (b)[1] + F C5 (b)[1])
= 0 + 1 + (3 + 2) = 6
F ALB[1] = min(F ALB(a)[1], F LAB(b)[1]) = 6
F ALB[1] B, therefore A3 knows full assignment extended {A1 = a} would cost
least 6. full assignment cost already discovered, need explore
rest sub-space, safely backjump search process back A1 , change
value b. Backtracking A2 leaves search process within {A1 = a} sub-space,
A3 knows cannot lead full assignment lower cost.
4.2 AFB-BJ Algorithm
AFB-BJ algorithm run agents DisCOP. agent first calls procedure init responds messages receives TERMINATE message. algorithm
presented figures 5 6. pure AFB, timestamping mechanism used messages.
timestamping mechanism used AFB used AFB-BJ determine messages relevant obsolete. simplicity choose omit pseudo-code detailing calculation LC, PC, FC FALB, described Section 4.1.
algorithm starts agent calling init awaiting messages termination.
first, agent updates B cost best full assignment found far since
assignment found, set infinity (line 1). first agent (A1 ) creates empty
CPA begins search process calling assign CPA (lines 3-4), order find value
assignment variable.
agent receiving CPA (when received CPA MSG), checks time-stamp associated
it. date CP discarded. message discarded, agent saves
received PA local CPA variable (line 7). case CPA received higher priority
agent, estimations future agents F Cj longer relevant discarded,
domain values must reordered updated cost (lines 9-11). Then, agent attempts
assign next value calling assign CPA (line 16) backtrack needed (line 14).
Procedure assign CPA attempts find value assignment, current agent. assigned
value must sum cost CPA lower bound cost increment
caused assignment exceed upper bound B (lines 23). value found,
assignment higher priority agent must altered, backtrack called (line 25).
full assignment found better best full assignment known far,
broadcast agents (line 29). succeeding assign value, CPA sent forward
next unassigned agent (line 33). Concurrently, forward bounding requests (i.e. FB CPA messages)
sent lower priority agents (lines 34-35).
agent receiving bound estimation (when received FB ESTIMATE) lower priority
agent Aj (in response forward bounding message) ignores estimate already
abandoned partial assignment (identified using time-stamp mechanism). Otherwise, saves
estimate (line 17) checks new estimate causes current partial assignment exceed
bound B (line 18). case, agent calls assign CP (line 19) order change
value assignment (or backtrack case valid assignment cannot found).
75

fiG ERSHMAN , EISELS , & Z IVAN

procedure init:
1. B
2. (Ai = A1 )
3.
generate CP A()
4.
assign CP A()
received (FB CPA, Aj , P A)
5. V estimation vector PA[1..k] (0 k n)
6. send (F B EST IM E, V , P A, Ai ) Aj
received (CPA MSG, P A, Aj )
7. CP P
8. empCP P
9. (j = 1)
10. j re-initialize F Cj (v)
11. reorder domain values v Di LC(v)[i] (from low high)
12. (T empCP contains assignment Ai ) remove
13. (T empCP A.cost B)
14. backtrack()
15. else
16. assign CP A()
received (FB ESTIMATE, V , P , Aj )
17. F Cj (v) V
18. ( FALB(v)[i] B )
19. assign CP A()
received (NEW SOLUTION, P A)
20. B CP P
21. B P A.cost
Figure 5: Initialization message handling procedures AFB-BJ Algorithm

call backtrack made whenever current agent cannot find valid value (i.e.
bound B). case, agent calls backtrackTo() compute agent CPA
sent, backtracks search process (by sending CPA) back agent.
agent first agent (nowhere backtrack to), terminate broadcast ends search process
agents (line 37). algorithm reports optimal solution cost B,
full assignment corresponding cost B CP A.
function backtrackTo computes agent CPA sent. kernel
backjumping (BJ) mechanism. goes candidates, j 1 1, looking
first agent finds chance reaching full assignment lower cost
B. FALB(v)[j-1] lower bound cost full assignment extended CPA[1..j-1],
PC[j]-PC[j-1] cost added CPA Aj assignment. Since Aj picked lowest cost
value domain (its domain ordered line 11), addition two components
76

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

procedure assign CPA:
22. CP contains assignment Ai = w, remove
23. iterate (from last assigned value) Di first value satisfying
v Di s.t. CP A.cost + f (v) < B
24. value exists
25.
backtrack()
26. else
27.
assign Ai = v
28.
CP full assignment
29.
broadcast (NEW SOLUTION, CPA )
30.
B CP A.cost
31.
assign CP A()
32.
else
33.
send(CPA MSG, CPA, Ai ) Ai+1
34.
forall j >
35.
send(FB CPA, Ai , CPA) Aj
procedure backtrack:
36. (Ai = A1 )
37.
broadcast(TERMINATE)
38. else
39.
j backtrackTo()
40.
remove assignments Aj+1 , .., Ai CP
41.
send(CPA MSG, CPA, Ai ) Aj
function backtrackTo:
42. j = 1 downto 1
43.
foreach v Di
44.
( FALB(v)[j-1] + (PC[j] - PC[j-1]) < B )
45.
return j
46. broadcast(TERMINATE)
Figure 6: assigning backtracking procedures AFB-BJ Algorithm.
produces accurate lower bound cost full assignment extended CPA[1..j-1].
safely added FALB since adds lower bound cost increment
agent FALB include lower bound.
Example 2 example presented section 4.1, A3 computed FALB(b)[1] added
past costs partial assignments (cost incurred A1 ), local cost A3 , lower
bound cost increment future agents (A4 A5 ). sum safely add cost
added A2 know A2 picked lowest cost assignment.
addition helps tighten FALB reduce search. combined bound smaller
B, surely combination assignments made Aj following agent could
raise cost, already high. case even backjumping back A1 prove
helpful, search process terminated (line 46).
77

fiG ERSHMAN , EISELS , & Z IVAN

5. Correctness AFB
order prove correctness AF B two claims must established. First, algorithm
terminates second algorithm terminates global upper bound B cost
optimal solution. prove termination one show AF B algorithm never goes
endless loop. prove last statement enough show partial assignment
cannot generated once.
Lemma 1 AF B algorithm never generates two identical CPAs.
Assume negation Ai highest priority agent (first order assignments)
generates CPA second time. lets consider possible events immediately
preceded creation.
Case 1 - Ai received CPA message lower priority agent. Let us denote agent Aj ,
j > i. Ai received message, executed lines 7-13 (see Figure 3.1). procedure
backtrack line 14 executed since know Ai generated CPA, procedure would
so. Therefore line 16 executed, procedure assign CPA invoked. Ai executed
lines 22-24. Line 25 executed since invoking backtrack procedure could lead
creation CPA. Therefore, line 24 value described line 23 found exist.
Line 23 searches value Ai remaining value domain, exploring value previously
attempted current set assignments higher priority agents. Since assumed Ai
highest priority agent generates CPA second time, combination higher
priority assignments repeat itself. Therefore, since Ai received current set higher
priority assignments Ai re-pick local value, set high priority assignments
repeat itself, therefore Ai cannot pick value would generate CPA
second time.
Case 2 - Ai received CPA message higher priority agent. Let us denote agent
Aj , j < i. Since assumed Ai highest priority agent generates CPA
second time, combination higher priority assignments repeat itself. Therefore
value Ai would assign next would generate unique CPA, one could generated
before.
Case 3 - Ai received CPA message itself. cannot since Ai never sends
message itself.
Case 4 - Ai received FB ESTIMATE message Aj . j > since FB ESTIMATE
sent response FB CPA messages. sent (line 34) agents lower priority
Ai . Since message caused creation CPA, condition line 19 must
evaluated true, procedure assign CPA line 19 invoked. Similar case 1, lines 22-24
executed line 25 not. Similar case 1, value found line 23. value
repeat value previously picked current set higher priority agent assignments.
time agent received current set higher priority agent assignments due
assumption Ai first generate CPA twice.
Case 5 - procedure init invoked. cannot since CPAs previously generated, CPA generated must unique.
events could immediately preceded creation second identical CPA,
therefore impossible event occur. completes proof lemma.
Termination follows immediately Lemma 1.

78

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

Next, one needs prove upon termination complete assignment, corresponding
optimal solution, B CP (see Figure 3.1). one point termination
AF B algorithm, procedure backtrack. So, one needs prove search partial
assignment lead solution lower cost B discarded. Let us consider possible
cases agent discards CPA, changes value skips value let us show
cannot be. Skipping changing value done inside procedure assign CPA
lines 22-24. v value skipped over, condition line 23 holds
CP A.cost + f (v) B. Since B B CP A, CP A.cost + f (v) B B CP
means v could possibly lead solution cost lower B CP termination. Let
us consider possible cases value changed. occurs inside procedure
assign CPA. Let us consider possible cases procedure invoked result
value change.
Case 1 - invoking assign CPA init procedure (line 4). solution could lost since
first assignment performed, part search space skipped
assignment.
Case 2 - invoking assign CPA inside assign CPA procedure (line 31). happens
new best (so far) solution found. obviously changing assignment would lose
solution since saved broadcasted new current solution. discarded
better solution later found.
Case 3 - invoking assign CPA following received FB ESTIMATE message (line 19).
current partial assignment safely discarded, knowing solution lost since
condition line 18 indicated current partial assignment lower bound exceeds
best solution found far.
Case 4 - invoking assign CPA following received CPA MSG message (line 16) Aj
j > i. means CPA returned backtrack fully exploring current sub-space,
therefore changing current assignment would lead potential solution lost.
Case 5 - invoking assign CPA following received CPA MSG message (line 16) Aj
j < i. means CPA received higher priority agent. Ai yet pick
assignment, assignment make lose potential solutions.
Therefore, value skipped change CPA lead loss
potential solution. remaining event may lead solution skipped
CPA discarded. done time-stamping mechanism occurs
agent knows existence up-to-date CPA. CPA created agent
changed assignment calling assign CPA. showed case better solution
lost, therefore safe discard CPA.
conclusion, event value skipped changed CPA discarded, possible better solution lost. Therefore termination, AFB algorithm reports best solution
possible. completes correctness proof AF B algorithm.
order prove correctness AFB-BJ algorithm first prove correctness proposed backjumping method show combination AFB violate AFBs
correctness proven.
order prove correctness backjumping method one need show none
agents assignments algorithm backjumps over, lead solution lower
cost current upper bound. condition performing backjumping agent Aj
(line 44) lower bound cost full assignment extended assignments
79

fiG ERSHMAN , EISELS , & Z IVAN

Figure 7: Total non-concurrent computational steps AFB, ADOPT SBB low density
(p1 =0.4) Max-DisCSP

A1 , .., Aj1 assignment cost Aj exceeds global upper bound B. Since Aj picked
lowest cost value remaining domain (as domain ordered), extending assignments
A1 , .., Aj1 must lead cost greater equal B. Therefore, backjumping back Aj1
cannot discard potentially lower cost solutions. completes correctness proof
AFB-BJ backjumping (function backtrackTo) method.
Assuming correctness AFB, order prove correctness composite algorithm
AFB-BJ enough prove consistency lower bounds computed agents AFBBJ. lower bounds computed AFB-BJ include FC, LC PC described section 4. PC
contained CPA, updated agent receives adds assignment (not
shown code). LC(v) computed current agent Ai whenever assigns v value
assignment. FCj computed Aj line 5 (in figure 5), sent back Ai line 6. Ai
receives saves line 17. lower bounds contained inside vectors correct
PC exactly calculated holding CPA, LC exactly calculated current
agent Ai , bounds FCj bounds computed AFB proven
correct lower bounds assignment Aj . FCj bounds accurate based
current partial assignment since timestamp mechanism prevents processing bounds
based obsolete CPA. Whenever CPA altered higher priority agent, previous
bounds cleared (line 10 figure 5). completes correctness proof AF B BJ.

6. Experimental Evaluation
experiments performed simulator agents simulated threads
communicate message passing. Distributed Optimization problems used
presented experiments random Max-DisCSPs. network constraints,
experiments, generated randomly selecting probability p1 constraint among pair
variables probability p2 , occurrence violation (a non zero cost) among two
assignments values constrained pair variables. uniform random constraints networks
n variables, values domain, constraints density p1 tightness p2 commonly
used experimental evaluations CSP algorithms (cf. (Prosser, 1996)). Max-CSPs commonly
used experimental evaluations constraint optimization problems (COPs) (Larrosa & Schiex,
80

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

Figure 8: Total number messages sent AFB, ADOPT SBB low density (p1 =0.4) MaxDisCSP

(a)

(b)

Figure 9: (a) Number none-concurrent steps performed ADOPT, AFB, AFB-minC AFBBJ high density Max-DisCSP (p1 = 0.7). (b) closer look p2 > 0.9

2004). experimental evaluations DisCOPs include graph coloring problems (Modi et al.,
2005; Zhang et al., 2005), subclass Max-DisCSP.
order evaluate performance distributed algorithms, two independent measures
performance used - run time, form non-concurrent steps computation (Zivan &
Meisels, 2006b), communication load, form total number messages sent (Lynch,
1997; Yokoo, 2000a).
first set experiments, performance AF B compared two algorithms.
synchronous B&B algorithm (SBB) (Hirayama & Yokoo, 1997) asynchronous distributed optimization algorithm (ADOP ) (Modi et al., 2005). Figure 7 presents average runtime number non-concurrent computation steps, randomly generated Max-DisCSPs
n = 10 agents, domain size = 10, constraint tightness p1 = 0.4. Figure 8 compares
81

fiG ERSHMAN , EISELS , & Z IVAN

(a)

(b)

Figure 10: (a) Number messages sent ADOPT, AFB, AFB-minC AFB-BJ high density
Max-DisCSP (p1 = 0.7). (b) closer look p2 > 0.9

algorithms problems total number messages sent. figures
clear ADOPT outperforms basic algorithm SBB, accordance past experimental evaluation two algorithms (Modi et al., 2005). clear AFB outperforms
ADOPT large margin tight (high p2 ) problems. true measures.
second set experiments includes ADOPT algorithm three versions AFB algorithm: AFB, AFB-minC - variation AFB includes dynamic ordering values based
minimal cost (of current CPA), AFB-BJ composite backjumping forwardbounding algorithm. AFB-BJ uses value ordering heuristic AFB-minC. selected order show improved performance AFB-BJ indeed arise backjumping feature value ordering heuristic.
Figure 9 presents average run-time number non-concurrent computation steps,
algorithms: ADOPT, AFB, AFB-minC AFB-BJ, Max-DisCSPs n = 10 agents,
domain size = 10, constraint density p1 = 0.7. Asynchronous optimization (ADOPT)
much slower standard version AFB. clear figure, value ordering
heuristic greatly improves AFBs performance. added backjumping improves performance
much further. RHS figure provides zoom section graph
p2 = 0.9 p2 = 0.98. tight problems, ADOPT terminate reasonable
amount time terminated manually (and thus missing graph).
tightness values higher p2 > 0.9 AFB variants demonstrate phase
transition. phase transition behavior AFB algorithms similar lookahead algorithms centralized Max-CSPs (Larrosa & Meseguer, 1996; Larrosa & Schiex, 2004).
explanation phase transition problem difficulty increase exponentially
tightness point. problem becomes over-constrained many
combinations produce highest cost possible combinations fact equal quality,
easily pruned intelligent search.
82

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

Figure 11: Number Non-Concurrent Constraint Checks (NCCCs) performed several DisCOP
solvers high density Max-DisCSP (p1 = 0.7) linear scale (top) logarithmic scale (bottom)

Figure 10 presents total number messages sent algorithms. results
measurement closely match results run-time, measured non-concurrent steps.
83

fiG ERSHMAN , EISELS , & Z IVAN

Figure 12: Number Non-Concurrent Constraint Checks (NCCCs) performed several DisCOP
solvers low density MaxDisCSP (p1 = 0.4) logarithmic scale

see ADOPT exponentially rapid growth messages. explanation
growth simple. Following message agent receives ADOPT, several VALUE messages
sent lower priority agents, single COST message sent higher priority agent (Modi
et al., 2005). average, least two messages sent every message received, therefore
total number messages system increases exponentially time.
third batch experiments, includes comparison two additional DisCOP solvers DPOP (Petcu & Faltings, 2005a) OptAPO (Mailler & Lesser, 2004). DPOP performs
linear number computational steps, step performs exponential number computations. number messages DPOP linear (2n) number agents. Similar ADOPT,
DPOP uses pseudo-tree ordering agents use ordering
algorithms. OptAPO performs partial centralization problem, agents solve
part problem charge of. Therefore, algorithms, evaluation measures
use number (non-concurrent) computational steps inappropriate, since steps
exponentially time consuming. reason, performance algorithms must evaluated different metric. canonical choice number non-concurrent constraint checks
(N CCCs). implementation independent measure includes computations performed within
every single step (Zivan & Meisels, 2006b, 2006a, 2006). number messages sent
good measure case, since DPOP sends exponentially large messages (but linear
number them) algorithms send exponential amount messages
linear size. Thus present results using N CCCs metric. repeat experimental setup previous experiment randomly generated problems, report total
number non-concurrent constraint checks (NCCCs) figure 11. results presented
logarithmic linear scales.
experiment OptAPO, SBB ADOPT terminate reasonable time
harder problem instances therefore partially absent graphs. computation
84

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

DPOP composed agent sending message containing subtrees optimal cost
every possible combination higher priority constrained agents. given constraint density
size message agent sends would effected changing constraint tightness. Therefore, computation performed agent unaffected changing constraint
tightness (p2 ). DPOPs run time expected remain roughly tightness values
experiment. problems low constraint tightness DPOPs performance poor
compared rest algorithms. However, problem tightness increases gap
DPOPs run time rest algorithms narrows, p2 = 0.9 DPOP OptAPO
SBB roughly run time. p2 = 0.99 DPOP outperforms ADOPT, OptAPO SBB
(which terminate). AFB variants outperform DPOP whole range constraint
tightness orders magnitude. OptAPO appears perform slightly better SBB
AFB clearly outperforms orders magnitude. AFB variations produce phase
transition reported previous experiments, AF B BJ comes best performing
algorithm solving random DisCOPs.
results similar experiment low density (p1 = 0.4) Max-DisCSPs presented
figure 12 (notice logarithmic scale). high density problems, DPOP performance unaffected problem tightness, producing roughly similar results tightness values.
low tightness values, OptAPO AFB vastly superior DPOP OptAPO slightly outperforms AFB. tightness increases, OptAPO increases exponentially run-time become
worst performing algorithm. AFB outperforms DPOP tightness values except p2 = 0.9.

7. Conclusions
Asynchronous Forward-Bounding algorithm (AF B) uses asynchronous concurrent constraint propagation top distributed Branch Bound scheme. forward-bounding
protocol AF B maintains local consistency, prevents exploration dead-ends searchspace. run-time network load AFB evaluated asynchronous simulator
randomly generated ax DisCSP s. results evaluation revealed phase-transition
AF Bs performance, tightness problems increased beyond point.
DisCOP solver reported display behavior. similar phase-transition previously
reported centralized COP solvers, part work Larrosa et. al. (Larrosa & Meseguer,
1996; Larrosa & Schiex, 2004). phase-transition observed reported occur
COP solvers, enforce strong enough form local consistency (Larrosa & Meseguer, 1996;
Larrosa & Schiex, 2004). therefore attribute behavior AFB concurrent enforcement
local consistency.
AF B extended. One extension include value ordering heuristic. good ordering heuristic minimum-cost heuristic, values lower cost due assignments
higher priority agents selected first. named version algorithm AFB-minC.
experiments, use heuristic substantially improved performance AF B.
extension AF B enhanced backjumping mechanism. adding small
amount information bounding messages, agents detect lower bound
current partial assignment large (i.e. state inconsistent backtracking required)
able check whether backtracking previous agent indeed help reduce
lower bound resulting partial assignment consistent. Otherwise, search process
backtracks even further. resulting algorithm, AFB-BJ, performs significantly better
versions AFB. comparing AFB-minC AFB-BJ, shown backjumping
85

fiG ERSHMAN , EISELS , & Z IVAN

indeed affect performance, improvement standard AF B result
addition ordering heuristic.
AF B algorithm compared two algorithms based branch & bound
mechanism distributed form - ADOPT SBB (Yokoo, 2000b; Modi et al., 2005).
experimental evaluation clearly demonstrates substantial difference performance
algorithms. Asynchronous distributed optimization (ADOP ) outperforms SBB, AF B outperforms ADOP large margin measures performance. best knowledge evaluation ADOP increasingly tighter problems. experimental
evaluations measured ADOP scalability (by increasing number variables) increasing difficulty (tightness) problems fixed size. exponential growth number
messages ADOP apparent Figures 8 10(a). Outperforming AF B two
extended versions AF B, AFB-minC AFB-BJ, AFB-BJ best performance.
proposed value ordering heuristic improves performance, adding backjumping
mechanism top that, performance even enhanced.
Although AF B ADOP perform concurrent computation nature concurrency used
different. Concurrency ADOP achieved performing asynchronous assignments. algorithm agent picks value assignment free change
time. Multiple agents may change assignments concurrently. Asynchronous assignments
introduce degree uncertainty regard consistency current partial assignment known agent. fact, scenarios agent may base computation
inconsistent partial assignment, combination assignments performed higher
priority agents aware others most-up-to-date assignment.
Two algorithms used comparisons AF B - ADOP DP OP - use
pseudo-tree ordering agents, allows independent subproblems solved concurrently.
good pseudo-tree ordering problematic find (it NP-hard find optimal ordering),
sometimes even best ordering good enough, due structure specific problem. Overall, orderings become less useful dealing problems high constraint
density.
order evaluate performance AFB, compared tested two
additional DisCOP algorithms. DPOP OptAPO use branch bound find
optimal solution. DPOP algorithm delivers possible partial assignments pseudo-tree
performs exponential number constraints checks two passes pseudo-tree (Petcu
& Faltings, 2005a). OptAPO partitions DisCOP sub-problems, solved mediator
sub-problem (Mailler & Lesser, 2004). performance algorithms expected
different algorithms use branch & bound search. fact, performance DPOP
randomly generated DisCOPs independent tightness problems. results
extensive empirical evaluations algorithms random DisCOPs described section 6
conclusive. AFB algorithm best performing DisCOP algorithm randomly
generated DisCOPs measures performance. performs less non-concurrent constraints
checks sends smaller number messages.
essence, idea behind AF B summed follows - run sequential assignment
optimization process concurrently run parallel many additional processes check consistency partial assignment. main search process slow. point time one
agent holds current partial assignment order extend it. Concurrency achieved via
forward bounding, performed concurrently.
86

fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP

results experimental evaluation show adding concurrent maintenance bounds
sequential assignment process results efficient optimization algorithm (AF B). algorithm outperforms concurrent algorithms hard instances random DisCOPs.

References
Ali, S. M., Koenig, S., & Tambe, M. (2005). Preprocessing techniques accelerating DCOP
algorithm ADOPT.. AAMAS, pp. 10411048.
Bessiere, C., Maestre, A., Brito, I., & Meseguer, P. (2005). Asynchronous Backtracking without
adding links: new member ABT Family. Artificial Intelligence, 161:1-2, 724.
Brito, I., Meisels, A., Meseguer, P., & Zivan, R. (2008). Distributed Constraint Satisfaction
Partially Known Constraints. Constraints, press.
Chong, Y., & Hamadi, Y. (2006). Distributed Log-based Reconciliation. Proc. ECAI-06, pp.
108113.
Collin, Z., Dechter, R., & Katz, S. (1999). Self-Stabilizing Distributed Constraint Satisfaction.
Chicago Journal Theoretical Computer Science, 5.
Dijkstra, E. W. (1974). Self-stabilizing systems spite distributed control. Commun. ACM,
17(11), 643644.
Gershman, A., Meisels, A., & Zivan, R. (2007). Asynchronous Forward-Bounding Backjumping. Distributed Constraints Reasonning workshop, IJCAI-2007 Hyderabad, India.
Greenstadt, R., Grosz, B., & Smith, M. D. (2007). SSDPOP: improving privacy DCOP
secret sharing. AAMAS 07: Proceedings 6th international joint conference
Autonomous agents multiagent systems, pp. 13 New York, NY, USA. ACM.
Hirayama, K., & Yokoo, M. (1997). Distributed Partial Constraint Satisfaction Problem.. CP,
pp. 222236.
Larrosa, J., & Meseguer, P. (1996). Phase transition MAX-CSP. Proc. ECAI-96 Budapest.
Larrosa, J., & Schiex, T. (2004). Solving Weighted CSP Maintaining Arc Consistency.. Artificial
Intelligence, 159, 126.
Lynch, N. A. (1997). Distributed Algorithms. Morgan Kaufmann Series.
Mailler, R., & Lesser, V. (2004). Solving Distributed Constraint Optimization Problems Using
Cooperative Mediation. Proceedings Third International Joint Conference Autonomous Agents MultiAgent Systems (AAMAS04), pp. 438445. ACM.
Meisels, A., & Zivan, R. (2006). Asynchronous Forward-checking Distributed CSPs. Constraints, 16, 132156.
Meisels, A., & Zivan, R. (2007). Asynchronous Forward-checking Distributed CSPs. Constraints, 12(1).
Meseguer, P., & Jimenez, M. A. (2000). Distributed Forward Checking. Proc. CP-2000 Workshop
Distributed Constraint Satisfaction Singapore.
Modi, P. J., Shen, W., Tambe, M., & Yokoo, M. (2005). ADOPT: asynchronous distributed constraints optimization quality guarantees. Artificial Intelligence, 161:1-2, 149180.
87

fiG ERSHMAN , EISELS , & Z IVAN

Nguyen, T., Sam-Hroud, D., & Faltings, B. (2004). Dynamic Distributed Backjumping. Proc.
5th workshop distributed constraints reasoning DCR-04 Toronto.
Petcu,

A., & Faltings, B. (2004).
value ordering heuristic distributed resource allocation.
Proc. CSCLP04, Lausanne, Switzerland
http://liawww.epfl.ch/Publications/Archive/Petcu2004.pdf.

Petcu, A., & Faltings, B. (2005a). Scalable Method Multiagent Constraint Optimization..
Proc. IJCAI-05, pp. 266271.
Petcu, A., & Faltings, B. (2005b). S-DPOP: Superstabilizing, Fault-containing Multiagent Combinatorial Optimization. Proceedings National Conference Artificial Intelligence,
AAAI-05, pp. 449454.
Prosser, P. (1993). Hybrid Algorithms Constraint Satisfaction Problem. Computational
Intelligence, 9, 268299.
Prosser, P. (1996). Empirical Study Phase Transitions Binary Constraint Satisfaction Problems. Artificial Intelligence, 81, 81109.
Silaghi, M. C., & Yokoo, M. (2006). Nogood based asynchronous distributed optimization
(ADOPT-ng).. Proc. AAMAS06, pp. 13891396.
Solotorevsky, G., Gudes, E., & Meisels, A. (1996). Modeling Solving Distributed Constraint
Satisfaction Problems (DCSPs). Constraint Processing-96, pp. 5612 New Hamphshire.
Yokoo, M. (2000a). Algorithms Distributed Constraint Satisfaction: Review. Autonomous
Agents & Multi-Agent Sys., 3, 185207.
Yokoo, M. (2000b). Distributed Constraint Satisfaction Problems. Springer Verlag.
Yokoo, M., Ishida, T., Durfee, E., & Kuwabara, K. (1992). Distributed Constraint Satisfaction
Formalizing Distributed Problem Solving. IEEE Intern. Conf. Distrb. Comp. Sys., pp. 614
621.
Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2003). analysis application distributed
constraint satisfaction optimization algorithms sensor networks. Proc. 2nd Intern.
Joint Conf. Autonomous Agents & Multi-Agent Systems (AAMAS-03), pp. 185192 Melbourne, Australia.
Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2005). Distributed stochastic search distributed breakout: properties, comparishon applications constraints optimization problems sensor networks. Artificial Intelligence, 161:1-2, 5588.
Zivan, R., & Meisels, A. (2006). Dynamic Ordering Asynchronous Backtracking DisCSPs.
Constraints, 11, 179197.
Zivan, R., & Meisels, A. (2007). Conflict directed Backjumping MaxCSPs. IJCAI-2007
Hyderabad, India.
Zivan, R., & Meisels, A. (2006a). Concurrent search distributed CSPs.. Artif. Intell., 170(4-5),
440461.
Zivan, R., & Meisels, A. (2006b). Message delay DisCSP search algorithms. Annals Mathematics Artificial Intelligence, 46(4), 415439.

88


