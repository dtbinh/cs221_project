Journal Artificial Intelligence Research 25 (2006) 529-576

Submitted 4/05; published 4/06

Asynchronous Partial Overlay: New Algorithm Solving
Distributed Constraint Satisfaction Problems
Roger Mailler

mailler@ai.sri.com

SRI International
333 Ravenswood Dr
Menlo Park, CA 94025 USA

Victor R. Lesser

lesser@cs.umass.edu

University Massachusetts, Department Computer Science
140 Governors Drive
Amherst, 01003 USA

Abstract
Distributed Constraint Satisfaction (DCSP) long considered important
problem multi-agent systems research. many real-world problems
represented constraint satisfaction problems often present
distributed form. article, present new complete, distributed algorithm called
asynchronous partial overlay (APO) solving DCSPs based cooperative mediation process. primary ideas behind algorithm agents, acting
mediator, centralize small, relevant portions DCSP, centralized subproblems overlap, agents increase size subproblems along critical paths
within DCSP problem solving unfolds. present empirical evidence shows
APO outperforms known, complete DCSP techniques.

1. Introduction
Distributed constraint satisfaction problem become useful representation
used describe number problems multi-agent systems including distributed
resource allocation (Conry, Kuwabara, Lesser, & Meyer, 1991) distributed scheduling
(Sycara, Roth, Sadeh, & Fox, 1991). researchers cooperative multi-agent systems
focused developing methods solving problems based one key assumption. Particularly, agents involved problem solving process autonomous.
means agents willing exchange information directly relevant
shared problem retain ability refuse solution obviously conflicts
internal goal.
researchers believe focus agent autonomy precludes use centralization forces agents reveal internal constraints goals
may, reasons privacy pure computational complexity, impossible achieve.
Several algorithms developed explicit purpose allowing agents
retain autonomy even involved shared problem exhibits
interdependencies. Probably best known algorithms fit description
found work Yokoo et al. form distributed breakout (DBA) (Yokoo &
Hirayama, 1996), asynchronous backtracking (ABT) (Yokoo, Durfee, Ishida, & Kuwabara,
1992), asynchronous weak-commitment (AWC) (Yokoo & Hirayama, 2000).
c
2006
AI Access Foundation. rights reserved.

fiMailler & Lesser

Unfortunately, common drawback algorithms effort
provide agents complete privacy, algorithms prevent agents
making informed decisions global effects changing local allocation, schedule, value, etc. example, AWC, agents try value wait another agent
tell work nogood message. this, agents never
learn true reason another agent set agents unable accept value,
learn value combination values doesnt work.
addition, techniques suffer complete distribution control. words, agent makes decisions based incomplete often inaccurate
view world. result leads unnecessary thrashing problem
solving agents trying adapt behavior agents,
turn trying adapt them. Pathologically, behavior counter-productive
convergence protocol(Fernandez, Bejar, Krishnamachari, Gomes, & Selman, 2003).
iterative trial error approach discovering implicit implied constraints
within problem causes agents pass exponential number messages actually reveals great deal information agents constraints domain values
(Yokoo, Suzuki, & Hirayama, 2002). fact, order complete, agents using AWC
willing reveal shared constraints domain values. key thing
note statement AWC still allows agents retain autonomy
even forced reveal information variables constraints form
global constraint network.
paper, present cooperative mediation based DCSP protocol, called Asynchronous Partial Overlay (APO). Cooperative mediation represents new methodology
lies somewhere centralized distributed problem solving uses
dynamically constructed, partial centralization. allows cooperative mediation based
algorithms, APO, utilize speed current state-of-the-art centralized solvers
taking advantage opportunities parallelism dynamically identifying relevant
problem structure.
APO works agents asynchronously take role mediator. agent
acts mediator, computes solution portion overall problem recommends value changes agents involved mediation session. If, result
recommendations, causes conflicts agents outside session, links
preventing repeating mistake future sessions.
AWC, APO provides agents great deal autonomy allowing anyone
take mediator notice undesirable state current
solution shared problem. adding autonomy, agents ignore
recommendations changing local solution made agents. similar
way AWC, APO sound complete agents willing reveal
domains constraints shared variables allows agents obscure
states, domains, constraints strictly local variables.
rest article, present formalization DCSP problem (section
2). section 3, describe underlying assumptions motivation work.
present APO algorithm (section 4.1) give example protocols
execution simple 3-coloring problem (section 4.2). go give proofs
soundness completeness algorithm (section 4.3). section 5, present
530

fiAsynchronous Partial Overlay: New Algorithm DCSP

results extensive testing compares APO AWC within distributed graph
coloring domain complete compatibility version SensorDCSP domain (Bejar,
Krishnamachari, Gomes, & Selman, 2001) across variety metrics including number
cycles, messages, bytes transmitted, serial runtime. cases, show
APO significantly outperforms AWC (Yokoo, 1995; Hirayama & Yokoo, 2000). Section
6 summarizes article discusses future research directions.

2. Distributed Constraint Satisfaction
Constraint Satisfaction Problem (CSP) consists following:

set n variables V = {x1 , . . . , xn }.

discrete, finite domains variables = {D1 , . . . , Dn }.

set constraints R = {R1 , . . . , Rm } Ri (di1 , . . . , dij ) predicate
Cartesian product Di1 Dij returns true iff value assignments
variables satisfies constraint.

problem find assignment = {d1 , . . . , dn |di Di }
constraints R satisfied. CSP shown NP-complete, making form
search necessity.
distributed case, DCSP, using variable-based decomposition, agent assigned one variables along constraints variables. goal
agent, local perspective, ensure constraints variables
satisfied. Clearly, agents goal independent goals agents
system. fact, simplest cases, goals agents strongly
interrelated. example, order one agent satisfy local constraints, another
agent, potentially directly related constraint, may change value
variable.
article, sake clarity, restrict case agent
assigned single variable given knowledge constraints variable.
Since agent assigned single variable, refer agent name
variable manages. Also, restrict considering binary constraints
form Ri (di1 , di2 ). Since APO uses centralization core, easy
see algorithm would work restrictions removed. point
discussed part algorithm description section 4.1.4.
Throughout article, use term constraint graph refer graph formed
representing variables nodes constraints edges. Also, variables neighbors
variables shares constraints.
531

fiMailler & Lesser

3. Assumptions Motivation
3.1 Assumptions
following assumptions made environments agents
protocol designed:
1. Agents situated, autonomous, computing entities. such, capable
sensing environment, making local decisions based model intentionality, acting decisions. Agents rationally resource bounded.
result, agents must communicate gain information others state,
intentions, decisions, etc.
2. Agents within multi-agent system share one joint goals. paper,
goal Boolean nature stemming DCSP formulation.
3. work focuses cooperative problem solving, agents cooperative.
necessarily imply share state, intentions, etc.
agents, are, degree, willing exchange information solve joint
goals. imply change intentions, state, decisions
based demands another agent. Agents still maintain autonomy
ability refuse revise decisions agents based local state,
intentions, decisions, etc.
4. agent capability computing solutions joint goal based
potentially limited rationality. follows naturally ability agents
make decisions, i.e., every agent capable computing solution
portion joint goal based desires.
3.2 Motivation Mediation-Based Problem Solving
Websters dictionary defines act mediating follows:
Mediate: 1. act intermediary; especially work opposing sides
order resolve (as dispute) bring (as settlement). 2. bring
about, influence, transmit acting intermediate controlling agent
mechanism. (Merriam-Webster, 1995)
definition, mediation implies degree centralizing shared problem
order group individuals derive conflict free solution. Clearly situations
participants willing (cooperative), mediation powerful paradigm solving
disputes. rather strange, considering this, little done looking
mediation cooperative method solving DCSPs.
Probably, earliest mediation-based approach solving conflicts amongst agents
airspace management application(Cammarata, McArthur, & Steeb, 1983). work
investigates using various conflict resolution strategies deconflict airspace distributed
air traffic control system. author proposes method solving disputes
involved agents elect leader solve problem. elected, leader becomes
532

fiAsynchronous Partial Overlay: New Algorithm DCSP

S1

S2

{1,2}

{1,2}

Figure 1: simple distributed problem two variables.
responsible recognizing dispute, devising plan correct it, acting
plan. Various election schemes tested, unfortunately, leader authority
modify actions order resolve conflicts. obviously leads situations
plan suboptimal.
(Hayden, Carrick, & Yang, 1999), authors describe mediation one number possible coordination mechanisms. work, mediator acts intermediary
agents act coordinate behavior. intermediary, mediator routes messages, provides directory services, etc. provides loose coupling
agents, since need know mediator. mediator act
coordinate agents behavior tight interdependencies.
research work mediation-based problem solving involved settling disputes
competitive semi-competitive agents. Probably one best examples
using mediation manner found PERSUADER system(Sycara, 1988).
PERSUADER designed settle conflicts adversarial parties involved
labor dispute. PERSUADER uses case-based reasoning suggest concessions order
converge satisfactory solution. Another example using mediation way
found system called Designer Fabricator Interpreter (DFI) (Werkman, 1990).
DFI, mediation used resolve conflicts one series problem solving steps.
Whenever first step fails, case iterative negotiation, mediator agent steps
tries convince agents relax constraints. fails, mediator mandates
final solution.
may several reasons mediation deeply explored
cooperative problem solving method. First, researchers focused strongly using
distributed computing way exploiting concurrency distribute computation
needed solve hard problems (Rao & Kumar, 1993). this, even partially
and/or temporarily centralizing sections problem viewed contradictory
central goal. Second, researchers often claimed part power
distributed methods lies ability techniques solve problems naturally
distributed. example, supply chain problems generally central monitoring
authority. Again, directly sharing reasons particular choice made form
constraint seem contradict use distributed methods. Lastly, researchers often
claim reasons privacy security problem solved distributed
fashion. Clearly, sharing information solve problem compromises agents ability
private and/or violates security manner.
Although, parallelism, natural distribution, security, privacy, may seem good
justifications entirely distributed problem solving, actuality, whenever problem
interdependencies distributed problem solvers, degree centralization
information sharing must take place order derive conflict-free solution.
533

fiMailler & Lesser

Consider, simple example, problem figure 1. figure, two problem
solvers, one variable, share common goal different value one
another. agents two allowable values: {1, 2}. Now, order solve
problem, agent must individually decide different value
agent. this, least, one agent must transmit value other.
this, removes half privacy (by revealing one possible values), eliminates
security (because agent could make send values telling
value good), partially centralizes problem solving (agent S2 compute
solutions based solution S1 presented decide problem solved agent
S1 relies S2 solve it.) even simple example, achieving totally distributed
problem solving impossible.
fact, look details current approaches solving DCSPs,
observe significant amount centralization occurring. approaches
perform centralization incrementally problem solving unfolds attempt
restrict amount internal information shared. Unfortunately, problems
interdependencies among problem solvers, revealing agents information (such
potential values variables) unavoidable. fact, solutions derived
one agents conceals information regarding shared constraint
variable based incomplete information therefore may always sound.
follows then, since cannot avoid amount centralization, mediation
natural method solving problems contain interdependencies among distributed
problem solvers.

4. Asynchronous Partial Overlay
cooperative mediation based protocol, key ideas behind creation APO
algorithm
Using mediation, agents solve subproblems DCSP using internal search.
local subproblems overlap allow rapid convergence
problem solving.
Agents should, time, increase size subproblem work along
critical paths within CSP. increases overlap agents ensures
completeness search.
4.1 Algorithm
Figures 2, 3, 4, 5, 6 present basic APO algorithm. algorithm works constructing good list maintaining structure called agent view. agent view
holds names, values, domains, constraints variables agent linked.
good list holds names variables known connected owner
path constraint graph.
problem solving unfolds, agent tries solve subproblem centralized within good list determine unsolvable indicates entire global
problem over-constrained. this, agents take role mediator attempt
534

fiAsynchronous Partial Overlay: New Algorithm DCSP

procedure initialize
di random Di ;
pi sizeof (neighbors) + 1;
mi true;
mediate false;
add xi good list;
send (init, (xi , pi , di , mi , Di , Ci )) neighbors;
initList neighbors;
end initialize;
received (init, (xj , pj , dj , mj , Dj , Cj ))
Add (xj , pj , dj , mj , Dj , Cj ) agent view;
xj neighbor xk good list
add xj good list;
/ good list
add xl agent view xl
connected good list;
pi sizeof (good list);
end if;
xj
/ initList
send (init, (xi , pi , di , mi , Di , Ci )) xj ;
else
remove xj initList;
check agent view;
end do;
Figure 2: APO procedures initialization linking.

change values variables within mediation session achieve satisfied
subsystem. cannot achieved without causing violation agents outside
session, mediator links agents assuming somehow related
mediators variable. process continues one agents finds unsatisfiable
subsystem, conflicts removed.
order facilitate problem solving process, agent dynamic priority
based size good list (if two agents sized good list
tie broken using lexicographical ordering names). Priorities used
agents decide mediates session conflicts arises. Priority ordering
important two reasons. First, priorities ensure agent knowledge
gets make decisions. improves efficiency algorithm decreasing
effects myopic decision making. Second, priorities improve effectiveness
mediation process lower priority agents expect higher priority agents mediate.
improves likelihood lower priority agents available mediation
request sent.
535

fiMailler & Lesser

received (ok?, (xj , pj , dj , mj ))
update agent view (xj , pj , dj , mj );
check agent view;
end do;
procedure check agent view
initList 6= mediate 6=false
return;
m0i hasConf lict(xi );
m0i j (pj > pi mj = = true)
(d0i Di ) (d0i agent view conflict)
di conflicts exclusively lower priority neighbors
di d0i ;
send (ok?, (xi , pi , di , mi )) xj agent view;
else
mediate;
else mi 6= m0i
mi m0i ;
send (ok?, (xi , pi , di , mi )) xj agent view;
end if;
end check agent view;

Figure 3: procedures local resolution, updating agent view
good list.

4.1.1 Initialization (Figure 2)
startup, agents provided value (they pick randomly one isnt
assigned) constraints variable. Initialization proceeds
agents send init message neighbors. initialization message includes
variables name (xi ), priority (pi ), current value(di ), agents desire mediate (mi ),
domain (Di ), constraints (Ci ). array initList records names agents
initialization messages sent to, reason become immediately
apparent.
agent receives initialization message (either initialization
later link request), records information agent view adds
variable good list can. variable added good list
neighbor another variable already good list. ensures graph created
variables good list always remains connected, focuses agents internal
problem solving variables knows interdependency with. initList
checked see message link request response link request.
agent initList, means message response, agent removes
536

fiAsynchronous Partial Overlay: New Algorithm DCSP

procedure mediate
pref erences ;
counter 0;
xj good list
send (evaluate?, (xi , pi )) xj ;
counter ++;
end do;
mediate true;
end mediate;
receive (wait!, (xj , pj ))
update agent view (xj , pj );
counter - -;
counter == 0 choose solution;
end do;
receive (evaluate!, (xj , pj , labeled Dj ))
record (xj , labeled Dj ) preferences;
update agent view (xj , pj );
counter - -;
counter == 0 choose solution;
end do;
Figure 4: procedures mediating APO session.
name initList nothing further. agent initList
means request, response init generated sent.
important note agents contained good list subset
agents contained agent view. done maintain integrity good list
allow links bidirectional. understand point, consider case
single agent repeatedly mediated extended local subproblem long
path constraint graph. so, links agents may limited
view therefore unaware indirect connection mediator. order
link bidirectional, receiver link request store name
requester agent view, cannot add good list path
identified. seen section 4.3, bi-directionality links important ensure
protocols soundness.
4.1.2 Checking agent view (Figure 3)
initialization messages received, agents execute check agent view
procedure (at end figure 2). procedure, current agent view (which contains
assigned, known variable values) checked identify conflicts variable
owned agent neighbors. If, check (called hasConflict
537

fiMailler & Lesser

procedure choose solution
select solution using Branch Bound search that:
1. satisfies constraints agents good list
2. minimizes violations agents outside session
satisfies constraints
broadcast solution;
xj agent view
xj pref erences
d0j violates xk xk
/ agent view
send (init, (xi , pi , di , mi , Di , Ci )) xk ;
add xk initList;
end if;
send (accept!, (d0j , xi , pi , di , mi )) xj ;
update agent view xj
else
send (ok?, (xi , pi , di , mi )) xj ;
end if;
end do;
mediate false;
check agent view;
end choose solution;
Figure 5: procedure choosing solution APO mediation.
figure), agent finds conflict one neighbors told
higher priority agent want mediate, assumes role mediator.
agent tell higher priority agent wants mediate flag
mentioned previous section. Whenever agent checks agent view recomputes
value flag based whether existing conflicts neighbors.
flag set true indicates agent wishes mediate given
opportunity. mechanism acts two-phase commit protocol, commonly seen
database systems, ensures protocol live-lock dead-lock free.
agent becomes mediator, first attempts rectify conflict(s)
neighbors changing variable. simple, effective technique prevents
mediation sessions occurring unnecessarily, stabilizes system saves messages time. mediator finds value removes conflict, makes change
sends ok? message agents agent view. cannot find nonconflicting value, starts mediation session. ok? message similar init
message, contains information priority, current value, etc. variable.
4.1.3 Mediation (Figures 4, 5, 6)
complex certainly interesting part protocol mediation.
previously mentioned section, agent decides mediate conflict
538

fiAsynchronous Partial Overlay: New Algorithm DCSP

received (evaluate?, (xj , pj ))
mj true;
mediate == true k (pk > pj mk = = true)
send (wait!, (xi , pi ));
else
mediate true;
label Di names agents
would violated setting di d;
send (evaluate!, (xi , pi , labeled Di ));
end if;
end do;
received (accept!, (d, xj , pj , dj , mj ))
di d;
mediate false;
send (ok?, (xi , pi , di , mi )) xj agent view;
update agent view (xj , pj , dj , mj );
check agent view;
end do;
Figure 6: Procedures receiving APO session.

one neighbors expecting session request higher priority
agent. mediation starts mediator sending evaluate? messages
agents good list. purpose message two-fold. First, informs
receiving agent mediation begin tries obtain lock
agent. lock, referred mediate figures, prevents agent engaging
two sessions simultaneously local value change course
session. second purpose message obtain information agent
effects making change local value. key point. obtaining
information, mediator gains information variables constraints outside
local view without directly immediately link agents. allows
mediator understand greater impact decision used determine
extend view makes final decision.
agent receives mediation request, responds either wait!
evaluate! message. wait message indicates requester agent
currently involved session expecting request agent higher priority
requester, fact could itself. agent available, labels
domain elements names agents would conflict
asked take value. information returned evaluate! message.
size evaluate! message strongly related number variables
size agents domain. cases either extremely large, number
techniques used reduce overall size message. example techniques
539

fiMailler & Lesser

include standard message compression, limiting domain elements returned
ones actually create conflict simply sending relevant value/variable pairs
mediator actually labeling. fact means largest evaluate! message
ever actually needed polynomial number agents (O(V )). implementation,
graph coloring, largest possible evaluate! message O(|D | + |V |).
noted agents need return names
privacy security reasons. effects completeness algorithm,
completeness relies one agents eventually centralizing entire
problem worst case. mentioned section 3.2, whenever agent attempts
completely hide information shared variable constraint distributed problem,
completeness necessarily effected.
mediator received either wait! evaluate! message agents
sent request to, chooses solution. mediator determines received
responses using counter variable set size good list
evaluate? messages first sent. mediator receives either wait!
evaluate! message, decrements counter. reaches 0, agents
replied.
Agents sent wait! message dropped mediation agents
sent evaluate! message labeled domains specified message recorded
used search process. mediator uses current values along
labeled domains received evaluate! messages conduct centralized search.
Currently, solutions generated using Branch Bound search (Freuder & Wallace,
1992) constraints good list must satisfied number outside
conflicts minimized. similar min-conflict heuristic (Minton,
Johnston, Philips, & Laird, 1992). Notice although search takes variables
constraints good list consideration, solution generates may adhere
variable values agents dropped session. variables
actually considered outside session impact able change
values calculated part min-conflict heuristic. causes search consider
current values dropped variables weak-constraints final solution.
addition, domain variables good list ordered
variables current value first element. causes search use current
value assignments first path search tree tendency minimize
changes made current assignments. heuristics, combined together,
form lock key mechanism simultaneously exploits work previously
done mediators acts minimize number changes assignments.
presented section 5, simple feed-forward mechanisms, combined
limited centralization needed solve problems, account considerable improvements
algorithms runtime performance.
satisfying assignments found search, mediator announces
problem unsatisfiable algorithm terminates. solution chosen,
accept! messages sent agents session, who, turn, adopt proposed
answer.
mediator sends ok messages agents agent view,
whatever reason session. simply keeps agents agent views up540

fiAsynchronous Partial Overlay: New Algorithm DCSP

to-date, important determining solution reached. Lastly, using
information provided evaluate! messages, mediator sends init messages
agent outside agent view, caused conflict choosing
solution. linking step extends mediators view along paths likely
critical solving problem identifying over-constrained condition. step
ensures completeness protocol.
Although termination detection explicitly part APO protocol, technique
similar (Wellman & Walsh, 1999) could easily added detect quiescence amongst
agents.
4.1.4 Multiple Variables n-ary Constraints
Removing restrictions presented section 2 fairly straightforward process.
APO uses linking part problem solving process, working n-ary constraints
simply involves linking n agents within constraint initialization
post-mediation linking needs occur. Priorities scheme identical
used binary constraints.
Removing single agent per variable restriction difficult fact
one strengths approach. using spanning tree algorithm initialization,
agents quickly identify interdependencies internal variables
use create separate good lists disconnected components
internal constraint graph. essence, startup, agents would treat
decomposed problems separate problem, using separate flag, priority,
good list, etc. problem solving unfolds, agent discovers connections
internal variables (through external constraints), decomposed problems could
merged together utilize single structure information.
technique advantages able ensure consistency dependent internal variables attempting mediate (because local checking
mediation), allows agent handle independent variables separate problems.
Using situation aware technique one shown yield best results
previous work(Mammen & Lesser, 1998). addition, technique allows agents
hide variables strictly internal. pre-computation decomposed
problems, agents construct constraints encapsulate subproblems
n-ary constraints n number variables external links. derived constraints sent part init message whenever agent receives
link request one external variables.
4.2 Example
Consider 3-coloring problem presented figure 7. problem, 8 agents,
variable 12 edges constraints them. 3-coloring
problem, variable assigned one three available colors {Black, Red,
Blue}. goal find assignment colors variables two
variables, connected edge, color.
example, four constraints violation: (ND0,ND1), (ND1,ND3), (ND2,ND4),
(ND6,ND7). Following algorithm, upon startup agent adds
541

fiMailler & Lesser

Figure 7: example 3-coloring problem 8 nodes 12 edges.
good list sends init message neighbors. Upon receiving messages,
agents add neighbors good list able identify
shared constraint themselves.
startup completed, agents checks agent view.
agents, except ND5, find conflicts. ND0 (priority 3) waits ND1
mediate (priority 5). ND6 ND7, priority 4, wait ND4 (priority 5, tie
ND3 broken using lexicographical ordering). ND1, equal number agents
good list, lower lexicographical order, waits ND4 start mediation. ND3,
knowing highest priority amongst neighbors, first checks see resolve
conflict changing value, case, cannot. ND3 starts session
involves ND1, ND5, ND6, ND7. sends evaluate? message. ND4
highest priority amongst neighbors, unable resolve conflict locally,
starts session sending evaluate? messages ND1, ND2, ND6, ND7.
agents mediation receives evaluate? message, first
check see expecting mediation higher priority agent. case,
ND1, ND6, ND7 expecting ND4 tell ND3 wait. label
domain elements names variables would conflict
result adopting value. information sent evaluate! message.
following labeled domains agents sent ND4:
ND1 - Black causes conflicts; Red conflicts ND0 ND3; Blue conflicts
ND2 ND4
ND2 - Black causes conflicts; Red conflicts ND0 ND3; Blue conflicts
ND4
ND6 - Black conflicts ND7; Red conflicts ND3; Blue conflicts ND4
ND7 - Black conflicts ND6; Red conflicts ND3; Blue conflicts ND4

542

fiAsynchronous Partial Overlay: New Algorithm DCSP

Figure 8: state sample problem ND3 leads first mediation.
following responses sent ND3:
ND1 - wait!
ND5 - Black causes conflicts; Red conflicts ND3; Blue causes conflicts
ND6 - wait!
ND7 - wait!
responses received, mediators, ND3 ND4, conduct branch
bound searches attempt find satisfying assignment subproblems
minimizes amount conflict would created outside mediation. either
cannot find least one satisfying assignment, broadcasts solution cannot
found.
example, ND3, limited information has, computes satisfying
solution changes color remain consistent would changed
colors ND6 ND7. Since told ND6 ND7 wait, changes color,
sends accept ! message ND5 ok? messages ND1, ND6 ND7.
information, ND4 finds solution thinks solve subproblem without
creating outside conflicts. changes color red, ND7 blue, ND1 black
leaving problem state shown figure 8.
ND1, ND4, ND5, ND6 ND7 inform agents agent view new
values, check conflicts. time, ND1, ND3, ND6 notice values
conflict. ND3, highest priority, becomes mediator mediates session
ND1, ND5, ND6, ND7. Following protocol, ND3 sends evaluate?
messages receiving agents label respond. following labeled domains
returned:
ND1 - Black conflicts ND3; Red conflicts ND0 ND4; Blue conflicts
ND2
543

fiMailler & Lesser

Figure 9: final solution ND2 leads second mediation.
ND5 - Black conflicts ND3; Red causes conflicts; Blue causes conflicts
ND6 - Black conflicts ND3; Red conflicts ND4; Blue conflicts ND7
ND7 - Black conflicts ND3 ND6; Red conflicts ND4; Blue causes
conflicts
ND3, receiving messages, conducts search finds solution solves
subproblem. chooses change color red. ND1, ND3, ND5, ND6, ND7
check agent view find conflicts. Since, point, none agents
conflict, problem solved (see figure 9).
4.3 Soundness Completeness
section show APO algorithm sound complete.
proofs, assumed communications reliable, meaning message sent
xi xj xj receive message finite amount time. assume
xi sends message m1 sends message m2 xj , m1 received
m2 . Lastly, assume centralized solver used algorithm sound
complete. prove soundness completeness, helps principal
lemmas established.
Lemma 1 Links bidirectional. i.e. xi xj agent view eventually xj
xi agent view.
Proof:
Assume xi xj agent view xi agent view xj .
order xi xj agent view, xi must received init message
point xj . two cases.
Case 1: xj initList xi . case, xi must sent xj init message
first, meaning xj received init message therefore xi agent view,
contradiction.
544

fiAsynchronous Partial Overlay: New Algorithm DCSP

Case 2: xj initList xi . case, xi receives init message
xj , responds init message. means reliable communication
assumption holds, eventually xj receive xi init message add xi agent view.
contradiction.
Lemma 2 agent xi linked xj xj changes value, xi eventually
informed change update agent view.
Proof:
Assume xi value agent view xj incorrect. would mean
point xj altered value without informing xi . two cases:
Case 1: xj know needed send xi update. i.e. xi xj
agent view. Contradicts lemma 1.
Case 2: xj inform agents agent view changes value.
clear code cannot happen. Agents change values
check agent view, choose solution, accept! procedures. cases, informs
agents within agent view either sending ok? accept!
message change value occurred. contradiction.
Lemma 3 xi conflict one neighbors, expect mediation
another higher priority agent agent view, currently session,
act mediator.
Proof:
Directly procedure check agent view.
Lemma 4 xi mediates session solution, constraints
agents involved mediation satisfied.
Proof:
Assume two agents xj xk (either could xi ),
mediated xi mediation conflict xj xk .
two ways could happened.
Case 1: One agents must value xi assign
part mediation.
Assume xj and/or xk value xi assign. know since xi
mediated session including xj xk , xi receive wait! message
either xj xk . means could mediating. means
must set mediate flags true xi sent evaluate?
message. Since times agent change value mediate flag
false, mediating, told mediator, xj and/or xk could
changed values xi told to, contradicts assumption.
Case 2: xi assigned value caused conflict one another.
Lets assume xi assigned conflicting values. means xi chose
solution take account constraints xj xk . But, know
xi chooses satisfying solutions include constraints
agents good list. leads contradiction.
545

fiMailler & Lesser

lemma important says mediator successfully concluded
session, conflicts exist constraints outside
mediation. viewed mediator pushing constraint violations outside
view. addition, mediators get information violations
pushed establish links agents, time, gain context.
important point considering completeness algorithm.
Theorem 1 APO algorithm sound. i.e. reaches stable state either
found answer solution exists.
Proof:
order sound, agents stop reached answer.
condition would stop without found answer one
agents expecting mediation request higher priority agent
send it. words, protocol deadlocked.
Lets say 3 agents, xi , xj , xk pi < pj pk < pj (i could equal k)
xk conflict xj . two cases xj would mediate session
included xi , xi expecting to:
Case 1: xi mj = true agent view actual value false.
Assume xi mj = true agent view true value mj = false.
would mean point xj changed value mj false without informing
xi . one place xj changes value mj , check agent view
procedure (see figure 3). Note procedure, whenever flag changes value
true false, agent sends ok message agents agent view. Since
lemma 1 know xi agent view xj , xi must received message
saying mj = false, contradicting assumption.
Case 2: xj believes xi mediating xi believe be.
i.e. xj thinks mi = true pi > pj .
previous case, know xj believes mi = true must
case. need show pi < pj . Lets say p0i priority xj believes
xi assume xj believes p0i > pj when, fact pi < pj . means
point xi sent message xj informing current priority p0i . Since
know priorities increase time (the good list gets larger), know
p0i pi (xj always correct value underestimates priority xi ). Since pj > pi
pi p0i pj > p0i contradicts assumption.
important point considering algorithm behaves. proof
says agents always either know underestimate true value neighbors
priorities. this, agents attempt mediate fact sometimes,
shouldnt. side effect attempt, however, correct priorities
exchanged mistake doesnt get repeated. important thing mention
case priority values become equal. case, tie broken using
alphabetical order names agents. ensures always way
break ties.
Definition 1 Oscillation condition occurs subset V 0 V agents
infinitely cycling allowable values without reaching solution. words,
agents live-locked
546

fiAsynchronous Partial Overlay: New Algorithm DCSP

definition, order considered part oscillation, agent within
subset must changing value (if stable, oscillating) must connected
members subset constraint (otherwise, actually part
oscillation).
Theorem 2 APO algorithm complete. i.e. solution exists, algorithm
find it. solution exist, report fact.
Proof:
solution exist whenever problem over-constrained. problem
over-constrained, algorithm eventually produce good list variables
within associated constraints lead solution. Since subset variables
unsatisfiable, entire problem unsatisfiable, therefore, solution possible.
algorithm terminates failure condition reached.
Since shown Theorem 1 whenever algorithm reaches stable
state, problem solved finds subset variables unsatisfiable terminates, need show reaches one two states finite
time. way agents reach stable state one
agents system oscillation.
two cases consider, easy case single agent oscillating
(|V 0 | = 1) case one agent oscillating (|V 0 | > 1).
Case 1: agent xi caught infinite loop agents
stable.
Lets assume xi infinite processing loop. means matter
changes value to, conflict one neighbors, changed
value something doesnt conflict neighbors, would solution
stop. changes value conflict xj higher priority it,
xj mediate xi , contradicting assumption agents stable.
xi changes value conflict lower priority agent, lemma 3,
act mediator neighbors. Since assumed agents
stable state, agents xi good list participate session
lemma 4, agent xi conflicts removed. means xi
stable state contradicting assumption infinite loop.
Case 2: Two agents oscillation.
Lets say set agents V 0 V oscillation. consider
agent xi within V 0 . know conditions xi changes value
solve conflicts (a contradiction x wouldnt
considered part oscillation), mediator, receiver mediation
agent V 0 . interesting case agent acts mediator.
Consider case xi mediator call set agents mediating
Vi . know according definition 1 mediation, least one
conflict must created remain otherwise oscillation would stop problem
would solved. fact, know remaining conflicts must contain
agent set V 0 Vi lemma 4. know violated constraint
member Vi , xi link agent part constraints
547

fiMailler & Lesser

member Vi . next time xi mediates, set Vi include members
number agents set V 0 Vi reduced. fact, whenever xi mediates set
V 0 Vi reduced (assuming told wait! one agents.
case, takes longer reduce set, proof still holds). Eventually, O(|V | 2 )
mediations, xi within V 0 must Vi = V 0 (every agent within set must
mediated |V 0 | times order happen). agent mediates push
violations outside set V 0 solve subproblem lemma 4. Either
conditions contradicts oscillation assumption. Therefore, algorithm complete.
QED
fairly clear that, domains exponential, algorithms worsecase runtime exponential. space complexity algorithm is, however, polynomial,
agents retain names, priorities, values, constraints agents.

5. Evaluation
great deal testing evaluation conducted APO algorithm. Almost
exclusively, test done comparing APO algorithm currently fastest
known, complete algorithm solving DCSPs called Asynchronous Weak Commitment
(AWC) protocol. section describe AWC protocol (section 5.1),
describe distributed 3-coloring domain present results extensive testing done
domain (section 5.2). testing compares two algorithms across variety
metrics, including cycle time, number messages, serial runtime.
Next, describe tracking domain (section 5.3) present results testing
domain well. domain, modified core search algorithm APO
take advantage polynomial complexity problem. variant called, APOFlow, described.
5.1 Asynchronous Weak Commitment (AWC) Protocol
AWC protocol (Yokoo, 1995) one first algorithms used solving DCSPs.
APO algorithm, AWC based variable decomposition. Also, APO, AWC
assigns agent priority value dynamically changes. AWC, however, uses
weak-commitment heuristic (Yokoo, 1994) assign priorities values
gets name.
Upon startup, agents selects value variable sends ok? messages
neighbors (agents shares constraint with). message includes variables
value priority (they start 0).
agent receives ok? message, updates agent view checks
nogood list violated nogoods. nogood composed set nogood pairs
describe combination agents values lead unsatisfiable condition. Initially, nogoods agents nogood list constraints variable.
checking nogood list, agents check violations higher priority nogoods. priority nogood defined priority lowest priority variable
nogood. value greater priority agents variable, nogood
higher priority. Based results check, one three things happen:
548

fiAsynchronous Partial Overlay: New Algorithm DCSP

1. higher priority nogoods violated, agent nothing.
2. higher priority nogoods violated repaired
simply changing agents variable value, agent changes value sends
ok? messages agents agent view. multiple possible
satisfying values, agent chooses one minimizes number violated
lower priority nogoods.
3. violated higher priority nogoods cannot repaired changing
value variable, agent generates new nogood. nogood
previously generated nogood, nothing. Otherwise, sends
new nogood every agent variable contained nogood raises
priority value variable. Finally, changes variable value one causes
least amount conflict sends ok? messages.
Upon receiving nogood message another agent, agent adds nogood
nogood list rechecks nogood violations. new nogood includes names
agents agent view links them. linking step essential
completeness search(Yokoo et al., 1992), causes agents communicate
nogoods ok? messages agents direct neighbors constraint
graph. overall effect increase messages reduction amount
privacy provided agents communicate potential domain values
information constraints exchange ok? nogood messages
larger number agents.
One recent advances AWC protocol addition resolventbased nogood learning (Hirayama & Yokoo, 2000) adaptation classical nogood
learning methods (Ginsberg, 1993; Cha & Iwana, 1996; Frost & Dechter, 1994).
resolvent method used whenever agent finds needs generate new
nogood. Agents generate new nogoods domain values violation
least one higher priority nogood already nogood list. resolvent method
works selecting one higher priority nogoods domain values
aggregating together new nogood. almost identical resolvent
propositional logic referred resolvent-based learning. AWC
protocol used testing incorporates resolvent-based nogood learning.
5.2 Distributed Graph Coloring
Following directly definition CSP, graph coloring problem, known
k-colorability problem, consists following:
set n variables V = {x1 , . . . , xn }.
set possible colors variables = {D1 , . . . , Dn } Di
exactly k allowable colors.
set constraints R = {R1 , . . . , Rm } Ri (di , dj ) predicate implements equals relationship. predicate returns true iff value assigned
xi differs value assigned xj .
549

fiMailler & Lesser

100

APO
AWC

Cycles

80

60

40

20

0
10

20

30

40

50

60

70

80

90

100

Variables

Figure 10: Comparison number cycles needed solve satisfiable, low-density 3coloring problems various sizes AWC APO.

problem find assignment = {d1 , . . . , dn |di Di }
constraints R satisfied. general CSP, graph coloring shown
NP-complete values k > 2.
test APO algorithm, implemented AWC APO algorithms conducted experiments distributed 3-coloring domain. distributed 3-coloring problem 3-coloring problem n variables binary constraints agent
given single variable. conducted 3 sets graph coloring based experiments compare
algorithms computation communication costs.
5.2.1 Satisfiable Graphs
first set experiments, created solvable graph instances = 2.0n (lowdensity), = 2.3n (medium-density), = 2.7n (high-density) according method
presented (Minton et al., 1992). Generating graphs way involves partitioning
variables k equal-sized groups. Edges added selecting two groups
random adding edge random member group. method ensures
resulting graphs satisfiable, tests limited likely easier
subset possible graphs. tests done traditionally used
researchers DCSPs.
particular values chosen represent three major regions
within phase-transition 3-colorability (Culberson & Gent, 2001). phase transition
CSP defined based order parameter, case average node degree
d. transition occurs point random graphs created order value
yield half satisfiable half unsatisfiable instances. Values order parameter
550

fiAsynchronous Partial Overlay: New Algorithm DCSP

200

APO
AWC

Cycles

150

100

50

0
10

20

30

40

50

60

70

80

90

100

Variables

Figure 11: Comparison number cycles needed solve satisfiable, medium-density
3-coloring problems various sizes AWC APO.

lower transition point (more 50% instance satisfiable) referred
left transition. opposite true values right.
Phase transitions important strongly correlated overall difficulty finding solution graph (Cheeseman, Kanefsky, & Taylor, 1991; Monasson,
Zecchina, Kirkpatrick, Selman, & Troyansky, 1999; Culberson & Gent, 2001). Within
phase transition, randomly created instances typically difficult solve. Interestingly,
problems right left phase transitions tend much easier.
3-colorability, value = 2.0 left phase transition. region,
randomly created graphs likely satisfiable usually easy find solve.
= 2.3, middle phase transition graph 50% chance
satisfiable usually hard solve. = 2.7n, right phase transition,
graphs likely unsatisfiable and, again, easier solve.
number papers (Yokoo & Hirayama, 2000, 1996; Hirayama & Yokoo, 2000)
reported = 2.7n within critical phase transition 3-colorability. seems
caused misinterpretation previous work area(Cheeseman et al.,
1991). Although Cheeseman, Kanefsky, Taylor reported = 2.7n within
critical region 3-colorability, using reduced graphs analysis.
reduced graph one trivially colorable nodes non-relevant edges
removed. example, one easily remove node two edges
3-coloring problem always trivially colored. Additionally, nodes
possess unique domain element neighbors easily removed.
later work, Culberson Gent identified critical region approximately
= 2.3 therefore included tests(Culberson & Gent, 2001). One note,
however, phase transitions typically done completely random graphs
551

fiMailler & Lesser



2.0

2.3

2.7

Nodes
15
30
45
60
75
90
Overall
15
30
45
60
75
90
Overall
15
30
45
60
75
90
Overall

APO
Mean
17.82
27.07
39.97
53.24
59.83
80.75

APO
StDev
8.15
17.11
25.79
32.32
35.35
54.30

AWC
Mean
17.38
24.62
43.76
69.96
80.32
82.92

AWC
StDev
12.70
19.23
30.98
49.03
103.76
61.01

15.04
34.01
47.72
92.73
114.02
160.88

5.55
16.81
26.58
72.46
75.84
125.12

20.49
41.30
109.99
135.60
185.84
189.04

11.27
29.58
74.85
146.57
119.94
91.27

13.83
27.28
42.47
52.15
64.54
87.14

3.56
10.10
18.01
23.12
26.26
42.82

20.29
39.99
62.92
86.89
104.09
127.04

10.32
24.08
35.23
43.69
46.62
64.97

p(AW C AP O)
0.77
0.27
0.34
0.01
0.07
0.81
0.01
0.00
0.04
0.00
0.01
0.00
0.07
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

Table 1: Comparison number cycles needed solve satisfiable 3-coloring problems
various sizes densities AWC APO.

552

fiAsynchronous Partial Overlay: New Algorithm DCSP

APO

140

AWC
120

Cycles

100
80
60
40
20
0
10

20

30

40

50

60

70

80

90

100

Variables

Figure 12: Comparison number cycles needed solve satisfiable, high-density
3-coloring problems various sizes AWC APO.

definition involves satisfiable unsatisfiable instances,
hard apply phase-tranisition results graphs created using technique described
beginning section generates satisfiable instances. detailed
phase transition analysis done graph generation technique fact,
believe graphs tend easier randomly created satisfiable ones
size order.
evaluate relative strengths weakness approaches, measured
number cycles number messages used course solving
problems. cycle, incoming messages delivered, agent allowed
process information, messages created processing
added outgoing queue delivered beginning next cycle. actual
execution time given one agent cycle varies according amount work
needed process incoming messages. random seeds used create
graph instance variable instantiation saved used algorithms
fairness.
comparison AWC APO, randomly generated 10 graphs size
n = 15, 30, 45, 60, 75, 90 = 2.0n, 2.3n, 2.7n instance generated 10 initial
variable assignments. Therefore, combination n m, ran 100 trials making
total 1800 trials. results experiment seen figures 10 15
table 1. mention results testing AWC obtained
experiments agree previous results (Hirayama & Yokoo, 2000) verifying correctness
implementation.
first glance, figure 10 appears indicate satisfiable low-density graph instances, AWC APO perform almost identically terms cycles completion. Look553

fiMailler & Lesser

APO

AWC

Nodes
15
30
45
60
75
90
15
30
45
60
75
90

% Links
Mean
32.93
17.24
11.97
9.30
7.42
6.51
55.76
32.89
27.00
26.47
21.99
20.11

% Links
StDev
3.52
2.59
1.84
1.30
0.95
0.96
12.31
8.88
7.89
9.12
7.67
7.89

% Central
Mean
60.53
42.53
33.27
29.00
24.60
24.93
79.73
60.97
56.49
56.98
53.19
50.38

% Central
StDev
9.12
8.06
6.61
7.31
6.73
6.16
11.45
10.98
11.57
14.23
13.29
13.78

Table 2: Link statistics satisfiable, low-density problems.

APO

AWC

Nodes
15
30
45
60
75
90
15
30
45
60
75
90

% Links
Mean
37.46
21.24
14.90
12.85
11.17
10.07
63.19
42.84
52.05
43.69
47.77
44.04

% Links
StDev
3.45
2.85
2.27
2.99
2.45
3.10
12.06
11.83
13.52
14.59
14.10
10.84

% Central
Mean
67.60
51.37
43.67
42.98
43.76
40.47
83.56
72.20
80.67
74.93
79.41
77.98

% Central
StDev
8.26
9.32
11.40
13.06
12.69
14.55
8.96
12.09
11.24
14.56
12.18
10.52

Table 3: Link statistics satisfiable, medium-density problems.

554

fiAsynchronous Partial Overlay: New Algorithm DCSP

APO

AWC

Nodes
15
30
45
60
75
90
15
30
45
60
75
90

% Links
Mean
43.28
24.29
18.07
13.86
11.85
10.86
78.87
58.03
54.06
53.01
49.63
47.72

% Links
StDev
2.86
2.61
2.06
1.77
1.57
1.85
12.29
11.66
13.44
12.77
11.36
13.81

% Central
Mean
74.53
59.30
52.62
47.78
46.37
50.73
93.60
86.27
82.67
83.47
81.91
80.32

% Central
StDev
8.34
9.75
10.21
11.32
11.32
14.48
7.75
9.54
13.34
11.04
9.93
15.06

Table 4: Link statistics satisfiable, high-density problems.
ing associated table (Table 1), however, reveals overall, pairwise T-test
indicates 99% confidence, APO outperforms AWC graphs.
density, average degree, graph increases, difference becomes
apparent. Figures 11 12 show APO begins scale much efficiently
AWC. attributed ability APO rapidly identify strong interdependencies variables derive solutions using centralized search
partial subproblem.
Tables 2 4, partially verify statement. see, average, less
50% possible number links (n (n 1)) used APO solving problems (%
Links column). addition, maximum amount centralization (% Central column)
occuring within single agent (i.e. number agents agent view) remains fairly
low. highest degree centralization occurs small, high-density graphs. Intuitively,
makes lot sense graphs, single node likely high
degree start. Combine fact dynamic priority ordering
result large amounts central problem solving.
profound differences algorithms seen figures 13, 14, 15
table 5. APO uses least order magnitude less messages AWC. Table 6 shows
message savings lead large savings number bytes transmitted
well. Even though APO uses twice many bytes per message AWC (the messages
optimized all), total amount information passed around significantly
less almost every case.
Again, looking linking structure AWC produces gives insights
uses many messages APO. agents communicate
agents linked whenever value changes, large number changes
occur single cycle, AWC tremendous amount thrashing behavior. APO,
hand, avoids problem process mediating implicitly creates
555

fiMailler & Lesser



2.0

2.3

2.7

Nodes
15
30
45
60
75
90
Overall
15
30
45
60
75
90
Overall
15
30
45
60
75
90
Overall

APO
Mean
361.50
1117.15
2078.72
3387.13
4304.22
6742.14

APO
StDev
179.57
844.33
1552.98
2084.69
2651.15
4482.54

AWC
Mean
882.19
2431.71
6926.86
18504.17
21219.01
33125.57

AWC
StDev
967.21
3182.51
7395.22
22281.59
22714.98
39766.56

379.15
1640.08
3299.05
8773.16
14368.87
25826.74

188.69
931.22
2155.45
9613.84
12066.32
29172.66

1205.50
6325.21
44191.89
70104.74
178683.02
201145.37

923.85
6914.79
44693.33
69050.66
173493.21
143236.26

433.64
1623.89
3859.99
5838.36
9507.60
16455.59

164.12
787.59
1921.51
3140.53
4486.04
10679.92

1667.71
9014.02
28964.43
66857.87
116016.71
196239.22

1301.03
8104.34
22900.89
53221.05
82857.63
163722.90

p(AW C AP O)
0.00
0.00
0.00
0.00
0.00
0.00
0.01
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

Table 5: Comparison number messages needed solve satisfiable 3-coloring problems various sizes densities AWC APO.

556

fiAsynchronous Partial Overlay: New Algorithm DCSP



2.0

2.3

2.7

Nodes
15
30
45
60
75
90
Overall
15
30
45
60
75
90
Overall
15
30
45
60
75
90
Overall

APO
Mean
10560.76
32314.97
59895.10
97126.79
123565.94
192265.35

APO
StDev
4909.09
23138.55
42740.82
57428.70
73493.72
123384.05

AWC
Mean
11590.38
32409.93
95061.77
259529.42
294502.71
466084.60

AWC
StDev
13765.19
45336.65
106391.51
326087.70
328696.59
581963.72

11370.13
47539.20
95098.49
247417.78
401618.24
712035.13

4951.75
25486.74
59312.25
262844.89
327990.65
782835.83

16260.19
88946.59
644007.01
1018059.11
2626178.31
2935211.45

13237.31
101077.04
675192.26
1029273.23
2606377.80
2138087.17

13415.51
48542.24
112541.02
170174.55
272391.95
465571.42

4280.15
21331.96
52729.10
85705.12
122177.07
288265.82

22393.61
125072.76
405535.81
945039.32
1641250.63
2793725.78

18578.25
116518.80
327349.47
773937.60
1204185.34
2397839.47

p(AW C AP O)
0.49
0.98
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

Table 6: Comparison number bytes transmitted APO AWC satisfiable
graph instances various sizes density.

557

fiMailler & Lesser

35000

APO
AWC

30000

Messages

25000
20000
15000
10000
5000
0
10

20

30

40

50

60

70

80

90

100

Variables

Figure 13: Comparison number messages needed solve satisfiable, low-density
3-coloring problems various sizes AWC APO.

250000

APO
AWC

Messages

200000

150000

100000

50000

0
10

20

30

40

50

60

70

80

90

100

Variables

Figure 14: Comparison number messages needed solve satisfiable, mediumdensity 3-coloring problems various sizes AWC APO.

regions stability problem landscape mediator decides solution.
addition, APO uses partial centralization solve problems, avoids use
large number messages discover implied constraints trial error.
558

fiAsynchronous Partial Overlay: New Algorithm DCSP

200000

APO
AWC

Messages

150000

100000

50000

0
10

20

30

40

50

60

70

80

90

100

Variables

Figure 15: Comparison number messages needed solve satisfiable, high-density
3-coloring problems various sizes AWC APO.

% Satisfiable

1
0.8
0.6
0.4
0.2
0
1.8

2

2.2

2.4

2.6

2.8

Density

Figure 16: Phase transition curve 60 node randomly generated graphs used testing.

see next two experiments, high degree centralization caused
unfocused linking degrades AWCs performance even solving randomly
generated, possibly unsatisfiable, graph instances.
559

fiMailler & Lesser

800

APO

700

AWC

Cycles

600
500
400
300
200
100
0
1.8

2

2.2

2.4

2.6

2.8

Density

Figure 17: Number cycles needed solve completely random 60 variable problems
various density using AWC APO.

Density
1.8
2.0
2.1
2.3
2.5
2.7
2.9
Overall

APO
Mean
49.88
88.77
116.79
116.41
56.21
27.62
17.74

APO
StDev
41.98
83.79
107.21
264.65
45.12
25.66
13.69

% APO
Solved
100
100
100
100
100
100
100

AWC
Mean
52.51
189.42
377.54
660.65
640.66
537.99
476.20

AWC
StDev
77.06
237.17
364.55
362.80
335.65
324.87
271.63

% AWC
Solved
100
96
80
55
65
83
92

p(AW C AP O)
0.62
0.00
0.00
0.00
0.00
0.00
0.00
0.00

Table 7: Number cycles needed solve completely random 60 variable problems
various density using AWC APO.

560

fiAsynchronous Partial Overlay: New Algorithm DCSP

1.4e+06

APO
AWC

1.2e+06

Messages

1e+06
800000
600000
400000
200000
0
1.8

2

2.2

2.4

2.6

2.8

Density

Figure 18: Number messages needed solve completely random 60 variable problems
various density using AWC APO.

5.2.2 Random Graphs
second set experiments, generated completely random 60 node graphs
average degrees = 1.8 2.9. series conducted test completeness
algorithms, verify correctness implementations, study effects
phase transition performance. value d, generated 200 random
graphs single set initial values. Graphs generate randomly choosing
two nodes connecting them. edge already existed, another pair chosen.
phase transition curve instances seen figure 16.
total, 1400 graphs generated tested. Due time constraints, stopped
execution AWC 1000 cycles completed (APO never reached 1000).
results experiments shown figures 17 18 tables 7 8.
graphs, APO significantly outperforms AWC simplest problems
(see figure 17). results directly attributed AWCs poor performance
unsatisfiable problem instances (Fernandez et al., 2003). fact, region
phase transition, AWC unable complete 45% graphs within 1000 cycles.
addition, solve problems, AWC uses least order magnitude
messages APO. results seen figure 18. looking table 9, easy
see occurs. AWC high degree linking centralization. fact,
= 2.9 graphs, AWC reaches average 93% centralization 75% complete
inter-agent linking.
contrast this, APO loose linking throughout entire phase transition
centralizes average around 50% entire problem. results encouraging reinforce idea partial overlays extending along critical paths yields
improvements convergence solutions.
561

fiMailler & Lesser

Density
1.8
2.0
2.1
2.3
2.5
2.7
2.9
Overall

APO
Mean
2822.61
7508.33
12642.68
15614.37
8219.74
4196.58
2736.20

APO
StDev
3040.39
9577.86
16193.56
15761.90
7415.76
4201.80
2286.39

AWC
Mean
12741.58
126658.29
356993.39
882813.45
1080277.25
1047001.18
1000217.83

AWC
StDev
47165.70
269976.18
444899.21
566715.73
661909.63
738367.27
699199.90

p(AW C AP O)
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

Table 8: Number messages needed solve completely random 60 variable problems
various density using AWC APO.

APO

AWC

Density
1.8
2.0
2.1
2.3
2.5
2.7
2.9
1.8
2.0
2.1
2.3
2.5
2.7
2.9

% Links
Mean
8.09
10.93
13.31
15.56
14.37
13.19
13.12
16.28
34.34
46.52
64.13
70.06
72.95
75.19

% Links
StDev
1.50
3.28
4.49
4.94
3.74
3.32
2.70
6.58
13.44
13.95
11.43
10.51
10.65
9.62

% Central
Mean
26.19
36.92
46.68
55.91
53.86
47.33
45.26
41.08
65.00
75.24
86.06
89.46
91.71
92.78

% Central
StDev
6.94
13.77
15.86
18.18
18.25
19.59
17.55
12.42
14.41
10.66
5.61
4.55
3.80
5.63

Table 9: Link statistics 60 node random problems.
5.2.3 Runtime Tests
third set experiments, directly compared serial runtime performance
AWC APO. Serial runtime measured using following formula:

serialtime =

cycles
X

X

i=0 aagents

562

time(a, i)

fiSeconds

Asynchronous Partial Overlay: New Algorithm DCSP

23900
14160
8390
4970
2940
1740
1030
610
360
210
120
70
40
20
10

APO
AWC
Backtracking

15

25

35

45

55

65

Nodes

Seconds

Figure 19: Comparison number seconds needed solve random, low-density 3coloring problems various sizes AWC, APO, centralized Backtracking.

92350
51680
28920
16180
9050
5060
2830
1580
880
490
270
150
80
40
20
10

APO
AWC
Backtracking

15

25

35

45

55

65

Nodes

Figure 20: Comparison number seconds needed solve random, medium-density
3-coloring problems various sizes AWC, APO, centralized Backtracking.

563

fiSeconds

Mailler & Lesser

3620
2360
1540
1000
650
420
270
170
110
70
40
20
10

APO
AWC
Backtracking

15

25

35

45

55

65

Nodes

Figure 21: Comparison number seconds needed solve random, high-density 3coloring problems various sizes AWC, APO, centralized Backtracking.


2.0

2.3

2.7

Nodes
15
30
45
60
15
30
45
60
15
30
45
60

APO
Mean
0.26
0.78
1.27
2.02
0.18
0.98
2.19
10.51
0.09
0.40
0.66
5.47

APO
StDev
0.21
0.66
1.18
1.74
0.23
0.88
2.26
12.97
0.06
0.39
0.63
5.44

AWC
Mean
2.72
10.52
257.88
890.12
3.96
112.95
1236.27
32616.24
3.51
61.43
460.56
4239.16

AWC
StDev
4.40
18.99
1252.25
4288.43
3.23
144.24
1777.51
62111.52
2.90
59.77
690.98
4114.30

BT
Mean
0.02
1.65
245.14
27183.64
0.03
0.86
150.73
92173.71
0.02
0.29
35.58
2997.04

BT
StDev
0.02
4.14
587.31
56053.26
0.01
1.07
241.02
222327.59
0.01
0.36
57.75
4379.97

Table 10: Comparison number seconds needed solve random 3-coloring problems
various sizes densities using AWC, APO, centralized Backtracking.

564

fiAsynchronous Partial Overlay: New Algorithm DCSP

total accumulated runtime needed solve problem one
agent allowed process time.
experiments, generated random graphs, time varying size
density graph. generated 25 graphs values n = 15, 30, 45, 60
densities = 2.0, 2.3, 2.7, total 300 test cases. show performance
difference APO AWC caused speed central solver, ran
centralized backtracking algorithm graph instances. Although, APO uses
branch bound algorithm, backtracking algorithm used test provides best
case lower bound runtime APOs internal solver.
programs used test run identical 2.4GHz Pentium 4
768 Mbytes RAM. machines entirely dedicated tests
minimal amount interference competing processes. addition, computational cost
assigned message passing simulator passes messages cycles.
algorithms were, however, penalized amount time took process messages.
Although realize specific implementation algorithm greatly effect
runtime performance, every possible effort made optimize AWC implementation
used experiments effort fair.
results test series seen figures 19, 20, 21. note
scale used graphs logarithmic. looking results, two
things become apparent. Obviously, first APO outperforms AWC
every case. Second, APO actually outperforms centralized solver graphs larger
45 nodes. indicates two things. First, solver currently APO
poor second APOs runtime performance direct result speed
centralized solver using. fact, tests show improved performance
APO AWC caused APOs ability take advantage problems structure.
replace centralized solver used tests state-of-the-art
solver, would expect two things. first would expect serial runtime
APO algorithm decrease simply speedup caused centralized solver.
second, importantly, centralized solver would always outperform
APO. current CSP solvers take advantage problem structure unlike
solver used tests. way making claim APO improves
centralized solver. simply stating APO outperforms AWC reasons
speed current internal solver.
5.3 Tracking Domain
test APOs adaptability various centralized solvers, created implementation
complete-compatibility version SensorDCSP formulation (Bejar et al., 2001;
Krishnamachari, Bejar, & Wicker, 2002; Fernandez et al., 2003). domain,
number sensors number targets randomly placed within environment.
range restrictions, sensors within distance dist see
target. goal find assignment sensors targets target
three sensors tracking it.
Following directly definition CSP, SensorDCSP problem consists
following:
565

fiMailler & Lesser

Figure 22: example tracking problem. 30 targets (labeled
name) 224 sensors (black dots). Lines connecting sensors targets indicate sensor assigned tracking target.

566

fiAsynchronous Partial Overlay: New Algorithm DCSP

set n targets = {T1 , . . . , Tn }.
set possible sensors see targets = {D 1 , . . . , Dn }.
set constraints R = {R1 , . . . , Rm } Ri (ai , aj ) predicate implements intersects relationship. predicate returns true iff sensors
assigned Ti elements common sensors assigned Tj .
problem find assignment = {a1 , . . . , } constraints
R satisfied ai set |Dci | sensors Di c = min(|Di |, 3).
indicates target requires 3 sensors, enough available, sensors,
less 3.
Since, implementation, sensors compatible one another,
overall complexity problem polynomial, using reduction feasible flow
bipartite graph(Krishnamachari, 2002). this, centralized solver used
APO agents changed modified version Ford-Fulkerson maximum flow
algorithm (Ford & Fulkerson, 1962; Cormen, Leiserson, & Rivest, 1999),
proven run polynomial time.
example tracking problem seen figure 22. example,
224 sensors (black dots) placed ordered pattern environment.
30 targets (labeled names) randomly placed startup. lines
connecting sensors targets indicate sensor assigned target. Note
instance problem satisfiable.
5.3.1 Modifying APO Tracking Domain
tracking domain closely related general CSP formulation,
changes made either AWC APO tests. did, however, decide test
adaptability APO new centralized problem solver. this, changed
centralized problem solver Ford Fulkerson max-flow algorithm figure 23. FordFulkerson works repeatedly finding paths remaining capacity residual
flow network augmenting flows along paths. algorithm terminates
additional paths found. detailed explanation algorithm well proof
optimality found (Cormen et al., 1999).
mapping bipartite graphs max-flow, SensorDCSP problem easily
mapped max-flow. figures 24 25 see mapping simple sensor
allocation problem max-flow problem. Notice capacity flow
sensors targets 1. ensures sensor cannot used
single target. Also, notice capacity targets 3. fact, value
min(|Di |, 3).
use algorithm within APO, mediator simply translates problem
network flow graph G using following rules whenever runs choose solution
procedure figure 5:
1. Add nodes G.
2. Ti add node Ti edge (Ti , t) capacity min(|Di |, 3) G.
567

fiMailler & Lesser

Ford-Fulkerson (G, s, t)
edge (u, v) E[G]
f [u, v] 0;
f [v, u] 0;
end do;
exists path p
residual network Gf
cf (p) min{cf (u, v) : (u, v) p};
edge (u, v) p
f [u, v] f [u, v] + cf (p);
f [v, u] f [u, v];
end do;
end do;
end Ford-Fulkerson;
Figure 23: Ford-Fulkerson maximum flow algorithm.

S1

S2

T1

S3

S4
T2
S5

S6

Figure 24: simple sensor target allocation problem.
3. unique sensor Si domains Ti , add node Si , edge (s, Si )
capacity 1, edge (Si , Ti ) capacity 1 G.

568

fiAsynchronous Partial Overlay: New Algorithm DCSP

S1
1

1
S2

1
1

S3

1
1
1

T1

3




1

1
3

S4
1
S5

1
1

T2

1
S6

Figure 25: flow network simple target allocation problem figure 24.
executes Ford-Fulkerson algorithm. algorithm finishes, mediator
checks residual capacity edges targets t. edges
residual flow, problem unsatisfiable. Otherwise, assignment derived
finding (Si , Ti ) edges flow 1.
One nicest characteristics Ford-Fulkerson algorithm works regardless order paths residual network chosen. implementation,
used breadth-first search which, addition identifying paths residual network, minimized cost path. Cost sense refers amount external
conflict created sensor assigned target. modification maintains
min-conflict heuristic integral part extending mediators local view.
5.3.2 Results
test APO AWC domain, ran test series used 200f 200f
environment 224 sensors placed ordered grid-based pattern. chose place
sensors ordered fashion reduce variance obtained within results. ran
test series varied sensor target ratio 10:1 3.8:1 (22 59 targets)
increments 0.2 across spectrum mostly satisfiable mostly unsatisfiable
instances (see figure 26). conducted 250 trial runs random target placement
values get good statistical sampling.
total, 6750 test cases used. comparison, measured number messages
cycles taken algorithms find solution. random seeds used
place targets saved, APO AWC tested using identical problem
569

fiMailler & Lesser

0.9
0.8

% Satisfiable

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
20

25

30

35

40

45

50

55

60

Targets

Figure 26: Phase transition curve 224 sensor environment used testing.

APO
AWC

Cycles

20

15

10

5

0
20

25

30

35

40

45

50

55

60

Targets

Figure 27: Number cycles needed solve random target configurations field 224
sensors using AWC APO.

instances. correctness algorithms verified cross-checking solutions
(satisfiable/unsatisfiable) obtained tests, matched identically.
seen figure 27 28 tables 11 12, APO outperforms AWC
simplest cases. Part reason minimum 3 cycles takes APO
finish mediation session. problems sparsely connected interdependencies,
cost tends dominate. All-in-all, T-tests indicate, APO significantly better
AWC terms cycles completion number messages used problems
domain.
570

fiAsynchronous Partial Overlay: New Algorithm DCSP

Targets
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
39
40
41
43
45
47
49
51
53
56
59
Overall

APO
Mean
6.36
6.65
7.12
6.55
6.80
7.09
7.38
7.10
7.55
7.18
6.88
7.62
7.47
7.56
8.08
7.48
7.55
6.45
7.45
5.96
4.80
5.15
4.53
3.52
4.12
3.14
3.28

APO
StDev
2.33
3.39
4.72
3.24
4.28
5.02
5.88
4.89
5.99
6.11
6.31
7.59
7.81
7.49
9.89
8.38
10.87
10.54
13.11
7.79
7.25
8.31
5.90
2.00
5.82
0.59
2.26

AWC
Mean
5.88
7.32
8.83
7.15
9.65
10.85
11.05
9.24
13.15
12.42
11.73
12.32
15.88
14.74
15.70
20.70
16.12
15.74
17.56
16.10
17.61
18.52
15.33
14.34
13.13
10.45
7.46

AWC
StDev
6.61
10.55
19.96
10.56
15.78
19.89
15.89
13.76
25.58
22.22
18.21
24.04
28.82
29.01
25.46
39.63
26.43
21.66
30.98
22.91
28.50
30.27
25.28
22.60
22.55
20.81
10.47

p(AW C AP O)
0.29
0.36
0.18
0.39
0.01
0.00
0.00
0.02
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

Table 11: Number cycles needed solve random target configurations field 224
sensors using AWC APO.

571

fiMailler & Lesser

Targets
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
39
40
41
43
45
47
49
51
53
56
59
Overall

APO
Mean
78.28
89.52
105.53
102.92
116.36
128.58
149.23
145.72
167.50
169.30
174.32
212.59
218.74
221.93
258.41
258.95
303.64
293.24
342.33
274.39
277.26
311.91
303.66
269.37
333.42
296.36
339.21

APO
StDev
32.58
54.01
90.36
57.18
86.58
98.63
144.81
93.24
144.27
152.83
152.89
237.60
246.18
230.44
354.13
342.97
501.10
649.42
724.64
267.95
414.19
405.1
299.13
110.57
390.08
45.54
202.98

AWC
Mean
95.68
133.12
184.19
149.18
245.99
263.32
279.49
231.98
378.89
404.40
362.63
410.05
811.58
613.64
671.00
947.95
815.32
884.32
912.65
1279.97
1334.38
1471.82
1487.65
1571.46
1804.47
1895.23
1765.18

AWC
StDev
133.53
237.74
616.36
298.85
566.03
587.30
493.05
335.98
874.99
997.82
570.41
923.25
2243.79
1422.33
1333.50
2116.98
1373.29
1407.99
1517.10
2194.84
2470.13
2172.13
2503.62
2157.52
2815.94
3731.98
3676.16

p(AW C AP O)
0.04
0.00
0.04
0.02
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

Table 12: Number messages needed solve random target configurations targets
field 224 sensors using AWC APO.

572

fiAsynchronous Partial Overlay: New Algorithm DCSP

APO

Messages

2000

AWC

1500

1000

500

0
20

25

30

35

40

45

50

55

60

Targets

Figure 28: Number messages needed solve random target configurations targets
field 224 sensors using AWC APO.

6. Conclusions Future Directions
article, presented new complete, distributed constraint satisfaction protocol
called Asynchronous Partial Overlay (APO). AWC, APO allows agents retain
autonomy obscure completely hide internal variables constraints. addition, agents refuse solutions posed mediator, instead taking
mediator reason unhappy proposed solution.
presented example execution simple problem (section 4.2) proved
soundness completeness algorithm (section 4.3). extensive empirical
testing 10,250 graph instances graph coloring tracking domain,
showed APO significantly outperforms currently best known distributed constraint
satisfaction algorithm, AWC (Yokoo, 1995). tests shown APO better
AWC terms cycles completion, message usage, runtime performance.
shown runtime characteristics directly attributed speed
centralized solver.
APOs performance enhancements attributed number things. First,
APO exhibits hill-climbing nature early search becomes focused
controlled time goes on. hill-climbing techniques often leads satisfiable
solution early search. Second, using partial overlaying information
agents use decision making, APO exploits work previously done
mediators. forms lock key mechanism promotes solution stability.
Lastly, importantly, APO uses dynamic, partial centralization, agents
work smaller, highly relevant portions overall problem. identifying areas
decomposability, search space greatly reduced which, cases, improves
efficiency centralized search algorithm.
vast number improvements planned APO future. Probably
important improve centralized solver uses. article, inefficient
solver chosen show strengths distributed portions APO. expect
573

fiMailler & Lesser

additional improvements algorithms runtime performance obtained
using faster centralized search engine. addition, modern solvers often use methods
graph reductions, unit propagation backbone guided search. conceivable
information gained centralized search engine could used prune domains
variables consistency reasons variables centralized subproblem
relevance reasons. expect focus efforts agents additionally
reducing search time communications usage algorithm.
Along improvements selective use memory recording nogoods.
Unlike AWC uses nogoods ensure complete search, APOs completeness relies
one agents centralizing entire problem worst case. key
difference, APO improved simply remembering small, powerful subset
nogoods discovers mediation session session. would allow algorithm
improve future search exploiting work done previously.
clear APO, cooperative mediation methodology
whole, opens new areas future exploration new questions answered
distributed problem solving. believe work shows great deal promise
addressing vast number problems represents bridge centralized
distributed problem solving techniques.

Acknowledgments
Special thanks Bryan Horling design implementation Farm simulation
environment experiment run Shlomo Zilberstein, Bart Selman,
Neil Immerman, Jose Vidal making numerous suggestions development
work. Lastly, authors would thank JAIR reviewers helpful
feedback suggestions Carlos Ansotegui Jean-Charles Regin lengthy
discussion final revision article.
effort represented paper sponsored Defense Advanced Research Projects Agency (DARPA) Air Force Research Laboratory, Air Force Materiel
Command, USAF, agreement number F30602-99-2-0525. views conclusions
contained herein authors interpreted necessarily representing official policies endorsements, either expressed implied, Defense
Advanced Research Projects Agency (DARPA), Air Force Research Laboratory, U.S.
Government. U.S. Government authorized reproduce distribute reprints
Governmental purposes notwithstanding copyright annotation thereon.

References
Bejar, R., Krishnamachari, B., Gomes, C., & Selman, B. (2001). Distributed constraint
satisfaction wireless sensor tracking system. Workshop Distributed Constraint Reasoning, International Joint Conference Artificial Intelligence, Seattle,
Washington.
Cammarata, S., McArthur, D., & Steeb, R. (1983). Strategies cooperation distributed
problem solving. Proceedings 8th International Joint Conference Artificial
574

fiAsynchronous Partial Overlay: New Algorithm DCSP

Intelligence (IJCAI-83), Vol. 2, pp. 767770.
Cha, B., & Iwana, K. (1996). Adding new clauses faster local search. Proceedings
Thirteenth National Conference Artificial Intelligence (AAAI), pp. 332337.
Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are.
Proceedings 12th International Joint Conference Artificial Intelligence
(IJCAI-91), pp. 331337.
Conry, S. E., Kuwabara, K., Lesser, V. R., & Meyer, R. A. (1991). Multistage negotiation
distributed constraint satisfaction. IEEE Transactions Systems, Man,
Cybernetics, 21 (6).
Cormen, T. H., Leiserson, C. E., & Rivest, R. L. (1999). Introduction Algorithms.
McGraw-Hill.
Culberson, J., & Gent, I. (2001). Frozen development graph coloring. Theoretical Computer Science, 265 (12), 227264.
Fernandez, C., Bejar, R., Krishnamachari, B., Gomes, C., & Selman, B. (2003). Distributed
Sensor Networks: Multiagent Perspective, chap. Communication Computation
Distributed CSP Algorithms, pp. 299317. Kluwer Academic Publishers.
Ford, L. R., & Fulkerson, D. (1962). Flows Networks. Princeton University Press.
Freuder, E. C., & Wallace, R. J. (1992). Partial constraint satisfaction. Artificial Intelligence, 58 (13), 2170.
Frost, D., & Dechter, R. (1994). Dead-end driven learning. Proceedings Twelfth
Natioanl Conference Artificial Intelligence, pp. 294300.
Ginsberg, M. L. (1993). Dynamic backtracking. Journal Artificial Intelligence Research,
1, 2546.
Hayden, S., Carrick, C., & Yang, Q. (1999). Architectural design patterns multi-agent
coordination. Proceedings International Conference Agent Systems, Seattle, WA.
Hirayama, K., & Yokoo, M. (2000). effect nogood learning distributed constraint
satisfaction. 20th International Conference Distributed Computing Systems
(ICDCS), pp. 169177.
Krishnamachari, B., Bejar, R., & Wicker, S. (2002). Distributed problem solving
boundaries self-configuration multi-hop wireless networks. Hawaii International Conference System Sciences (HICSS-35).
Krishnamachari, B. (2002). Phase Transitions, Structure, Compleixty Wireless Networks. Ph.D. thesis, Cornell University, Ithaca, NY.
Mammen, D. L., & Lesser, V. R. (1998). Problem Structure Subproblem Sharing
Multi-Agent Systems. Third International Conference Multi-Agent Systems, 174
181.
Merriam-Webster (Ed.). (1995). Merriam-Webster Dictionary (Home Office edition). Springfield, IL.
575

fiMailler & Lesser

Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1992). Minimizing conflicts:
heuristic repair method constraint satisfaction scheduling problems. Artificial
Intelligence, 58 (1-3), 161205.
Monasson, R., Zecchina, R., Kirkpatrick, S., Selman, B., & Troyansky, L. (1999). Determining computational complexity characteristic phase transitions. Nature, 400,
133137.
Rao, V. N., & Kumar, V. (1993). efficiency parallel backtracking. IEEE Transactions Parallel Distributed Systems, 4 (4), 427437.
Sycara, K., Roth, S., Sadeh, N., & Fox, M. (1991). Distributed constrained heuristic search.
IEEE Transactions Systems, Man, Cybernetics, 21 (6), 14461461.
Sycara, K. (1988). Resolving goal conflicts via negotiation. Proceedings Seventh
National Conference Artificial Intelligence, pp. 245250.
Wellman, M., & Walsh, W. (1999). Distributed quiescence detection multiagent negotiation. AAAI-99 Workshop Negotiation: Settling Conflicts Identifying
Opportunities.
Werkman, K. J. (1990). Knowledge-based model negotiation using shared perspectives.
Proceedings 10th International Workshop Distributed Artificial intelligence,
Bandera, TX.
Yokoo, M. (1994). Weak-commitment search solving constraint satisfaction problems.
Proceedings 12th National Conference Artificial Intelligence (AAAI-94);
Vol. 1, pp. 313318, Seattle, WA, USA. AAAI Press, 1994.
Yokoo, M. (1995). Asynchronous weak-commitment search solving distributed constraint
satisfaction problems.. Proceedings First International Conference Principles Practice Constraint Programming (CP-95), Lecture Notes Computer
Science 976, pp. 88102. Springer-Verlag.
Yokoo, M., Durfee, E. H., Ishida, T., & Kuwabara, K. (1992). Distributed constraint satisfaction formalizing distributed problem solving. International Conference
Distributed Computing Systems, pp. 614621.
Yokoo, M., & Hirayama, K. (1996). Distributed breakout algorithm solving distributed
constraint satisfaction problems.. International Conference Multi-Agent Systems
(ICMAS).
Yokoo, M., & Hirayama, K. (2000). Algorithms distributed constraint satisfaction:
review. Autonomous Agents Multi-Agent Systems, 3 (2), 198212.
Yokoo, M., Suzuki, K., & Hirayama, K. (2002). Secure distributed constraint satisfaction: Reaching agreement without revealing private information. Proceeding
Eighth International Conference Principles Practice Constraint Programming (CP).

576


