Journal Artificial Intelligence Research 25 (2006) 457-502

Submitted 11/05; published 4/06

Continuation Method Nash Equilibria Structured
Games
Ben Blum

bblum@cs.berkeley.edu

University California, Berkeley
Department Electrical Engineering Computer Science
Berkeley, CA 94720

Christian R. Shelton

cshelton@cs.ucr.edu

University California, Riverside
Department Computer Science Engineering
Riverside, CA 92521

Daphne Koller

koller@cs.stanford.edu

Stanford University
Department Computer Science
Stanford, CA 94305

Abstract
Structured game representations recently attracted interest models multiagent artificial intelligence scenarios, rational behavior commonly characterized
Nash equilibria. paper presents efficient, exact algorithms computing Nash equilibria structured game representations, including graphical games multi-agent
influence diagrams (MAIDs). algorithms derived continuation method
normal-form extensive-form games due Govindan Wilson; follow trajectory space perturbed games equilibria, exploiting game structure
fast computation Jacobian payoff function. theoretically
guaranteed find least one equilibrium game, may find more. approach
provides first efficient algorithm computing exact equilibria graphical games
arbitrary topology, first algorithm exploit fine-grained structural properties
MAIDs. Experimental results presented demonstrating effectiveness algorithms comparing predecessors. running time graphical game
algorithm similar to, often better than, running time previous approximate
algorithms. algorithm MAIDs effectively solve games much larger
solvable previous methods.

1. Introduction
attempting reason interactions multiple agents, artificial intelligence
community recently developed interest game theory, tool economics. Game
theory general mathematical formalism representation complex multiagent scenarios, called games, agents choose actions receive payoffs
depend outcome game. number new game representations
introduced past years exploit structure represent games efficiently.
representations inspired graphical models probabilistic reasoning
artificial intelligence literature, include graphical games (Kearns, Littman, & Singh,
c
2006
AI Access Foundation. rights reserved.

fiBlum, Shelton, & Koller

2001), multi-agent influence diagrams (MAIDs) (Koller & Milch, 2001), G nets (La Mura,
2000), action-graph games (Bhat & Leyton-Brown, 2004).
goal describe rational behavior game. game theory, description
behavior agents game referred strategy profile: joint assignment
strategies agent. basic criterion look strategy profile
optimal agent, taken individually: agent able improve utility
changing strategy. fundamental game theoretic notion Nash equilibrium (Nash,
1951) satisfies criterion precisely. Nash equilibrium strategy profile
agent improve payoff deviating unilaterally changing strategy
agents hold fixed. types game theoretic solutions,
Nash equilibrium fundamental often agreed minimum solution
requirement.
Computing equilibria difficult several reasons. First, game representations
grow quite large. However, many games would interested
solving require full generality description leads large representation
size. structured game representations introduced AI exploit structural properties
games represent compactly. Typically, structure involves locality
interaction agents concerned behavior subset agents.
One would hope compact representations might lead efficient computation equilibria would possible standard game-theoretic solution algorithms
(such described McKelvey & McLennan, 1996). Unfortunately, even compact representations, games quite hard solve; present result showing finding
Nash equilibria beyond single trivial one NP-hard types structured games
consider.
paper, describe set algorithms computing equilibria structured
games perform quite well, empirically. algorithms family continuation
methods. begin solution trivial perturbed game, track solution
perturbation incrementally undone, following trajectory space equilibria
perturbed games equilibrium original game found. algorithms
based recent work Govindan Wilson (2002, 2003, 2004) (GW hereafter),
applies standard game representations (normal-form extensive-form).
algorithms GW great interest computational game theory community
right; Nudelman et al. (2004) tested leading algorithms
found them, certain cases, effective available. However,
algorithms unstructured games, infeasible large games.
show game structure exploited perform key computational step
algorithms GW, give alternative presentation work.
methods address graphical games MAIDs. Several recent papers
presented methods finding equilibria graphical games. Many proposed algorithms (Kearns et al., 2001; Littman, Kearns, & Singh, 2002; Vickrey & Koller, 2002; Ortiz
& Kearns, 2003) focused finding approximate equilibria, agent may
fact small incentive deviate. sorts algorithms problematic:
approximations must crude reasonable running times, guarantee
exact equilibrium neighborhood approximate one. Algorithms find
exact equilibria restricted narrow class games (Kearns et al., 2001).
458

fiA Continuation Method Nash Equilibria Structured Games

present first efficient algorithm finding exact equilibria graphical games arbitrary structure. present experimental results showing running time
algorithm similar to, often better than, running time previous approximate
algorithms. Moreover, algorithm capable using approximate algorithms starting
points finding exact equilibria.
literature MAIDs limited. algorithm Koller Milch (2001)
takes advantage certain coarse-grained structure MAIDs, otherwise falls
back generating solving standard extensive-form games. Methods related types
structured games (La Mura, 2000) limited coarse-grained structure,
currently unimplemented. Approximate approaches MAIDs (Vickrey, 2002) come
without implementation details timing results. provide first exact algorithm
take advantage fine-grained structure MAIDs. present experimental results
demonstrating algorithm solve MAIDs significantly outside scope
previous methods.
1.1 Outline Guide Background Material
results require background several distinct areas, including game theory, continuation
methods, representations graphical games, representation inference Bayesian
networks. Clearly, outside scope paper provide detailed review
topics. attempted provide, topics, sufficient background
allow results understood.
begin overview game theory Section 2, describing strategy representations payoffs normal-form games (single-move games) extensive-form
games (games multiple moves time). concepts utilized paper
presented section, thorough treatment available standard
text Fudenberg Tirole (1991). Section 3 introduce two structured game
representations addressed paper: graphical games (derived normal-form games)
MAIDs (derived extensive-form games). Section 4 give result complexity computing equilibria graphical games MAIDs, proof deferred
Appendix B. next outline continuation methods, general scheme algorithms
use compute equilibria, Section 5. Continuation methods form broad computational
framework, presentation therefore necessarily limited scope; Watson (2000)
provides thorough grounding. Section 6 describe particulars applying
continuation methods normal-form games extensive-form games. presentation
new, methods exactly GW.
Section 7, present main contribution: exploiting structure perform
algorithms GW efficiently graphical games MAIDs. show Bayesian
network inference MAIDs used perform key computational step GW
algorithm efficiently, taking advantage finer-grained structure previously possible.
algorithm utilizes, subroutine, clique tree inference algorithm Bayesian
networks. Although present clique tree method full, describe
properties method allow used within algorithm; provide
enough detail allow implementation algorithm using standard clique tree
package black box. comprehensive introduction inference Bayesian
459

fiBlum, Shelton, & Koller

networks, refer reader reference Cowell, Dawid, Lauritzen, Spiegelhalter
(1999). Section 8, present running-time results variety graphical games
MAIDs. conclude Section 9.

2. Game Theory
begin briefly reviewing concepts game theory used paper, referring
text Fudenberg Tirole (1991) good introduction. use notation
employed GW. readers familiar game theory may wish skip directly
table notation Appendix A.
game defines interaction set N = {n1 , n2 , . . . , n|N | } agents. agent
n N set n available strategies, strategy determines agents behavior
game. precise definition set n depends
Q game representation,
discuss below. strategy profile = (n1 , n2 , . . . , n|N | ) nN n defines strategy
n n agent n N . Given strategy profile , game defines expected
payoff Gn () agent n N . use n refer set strategy profiles
agents N \ {n} (agents n) n n refer one profile;
generalize notation n,n0 set strategy profiles two agents.
strategy profile, n0 n strategy agent n, (n0 , n ) new strategy
profile n deviates play n0 , agents act according .
solution game prescription strategy profile agents. paper,
use Nash equilibria solution concept strategy profiles agent
profit deviating unilaterally. agent knew others playing according
equilibrium profile (and would change behavior), would incentive
deviate. Using notation outlined here, define Nash equilibrium
strategy profile that, n N strategies n0 n ,
Gn (n , n ) Gn (n0 , n ).
define notion approximate equilibrium, agents incentive deviate small. -equilibrium strategy profile agent
improve expected payoff unilaterally deviating .
words, n N strategies n0 n , Gn (n0 , n ) Gn (n , n ) .
Unfortunately, finding -equilibrium necessarily step toward finding exact
equilibrium: fact -equilibrium guarantee existence exact
equilibrium neighborhood .
2.1 Normal-Form Games
normal-form game defines simultaneous-move multi-agent scenario. agent independently selects action receives payoff depends actions selected
agents. precisely, let G normal-form game set N agents.
agent n N hasQ
discrete action set payoff array Gn entries every
action profile = nN is, joint actions = (an1 , an2 , . . . , an|N | )
agents. use refer joint actions agents N \ {n}.
460

fiA Continuation Method Nash Equilibria Structured Games

2.1.1 Strategy Representation
agents restricted choosing actions deterministically, equilibrium guaranteed exist. If, however, agents allowed independently randomize actions,
seminal result game theory (Nash, 1951) guarantees existence mixed strategy
equilibrium. mixed strategy n probability distribution .
strategy set n therefore defined probability simplex mixed
strategies. support mixed strategy set actions non-zero
probability. strategy n agent n said pure strategy single
action support pure strategies correspond
exactly deterministic actions
Q
. set mixed strategy profiles nN n , product simplices. mixed
strategy single agent represented vector probabilities, one
action. notational simplicity later on, concatenate allPthese vectors regard
mixed strategy profile single m-vector, = nN |An |. vector
indexed actions nN , action , probability agent
n plays action a. (Note that, notational convenience, every action associated
particular agent; different agents cannot take action.)
2.1.2 Payoffs
mixed strategy profile induces joint distribution action profiles, compute
expectation payoffs respect distribution. let Gn () represent
expected payoff agent n agents behave according strategy profile .
calculate value
X

Gn () =
Gn (a)
ak .
(1)
aA

kN

general case (a fully mixed strategy profile, every ), sum includes
every entry game array Gn , exponentially large number agents.
2.2 Extensive-Form Games
extensive-form game represented tree. game proceeds sequentially
root. non-leaf node tree corresponds choice either agent
nature; outgoing branches represent possible actions taken node.
natures choice nodes, game definition includes probability distribution
outgoing branches (these points game something happens randomly
world large). leaf z Z tree outcome, associated
vector payoffs G(z), Gn (z) denotes payoff agent n leaf z. choices
agents nature dictate path tree followed.
choice nodes belonging agent partitioned information sets;
information set set states among agent cannot distinguish. Thus, agents
strategy must dictate behavior nodes information set. set
agent ns information sets denoted , set actions available information
set denoted A(i). define agent history Hn (y) node tree
agent n sequence containing pairs (i, a) information sets belonging n
traversed path root (excluding information set
461

fiBlum, Shelton, & Koller

0.7

a2

0.8

0.7

b2

b1

0.6

a1 a2

(0, 2)

0.9

a1

0.3

b1

0.2

0.1

0.4

1.0

a3 a4

(1, 4)

(6, 7)

0.3

b2

0.0

0.5

a5 a6

(6, 0)

(3, 3)

0.5

a7 a8

(1, 7)

(8, 0)

(2, 6)

Figure 1: simple 2-agent extensive-form game.
contained), action selected n one. Since actions unique information
sets (the action cant taken two different information sets), omit
information sets represent history ordered tuple actions only. Two nodes
agent-n history paths used reach indistinguishable n,
although paths may differ ways, natures decisions decisions
agents. make common assumption perfect recall : agent forget
information known choices made previous decisions. precisely, two nodes
y, 0 information set agent n, Hn (y) = Hn (y 0 ).
Example 1. game tree shown Figure 1, two agents, Alice Bob. Alice
first chooses actions a1 a2 , Bob next chooses b1 b2 , Alice chooses
two set {a01 , a02 , . . . , a08 } (which pair depends Bobs choice). Information
sets indicated nodes connected dashed lines. Bob unaware Alices actions,
nodes information set. Alice aware bottom level
initial action Bobs action, nodes distinct information set.
Edges labeled probability agent whose action follow it;
note actions taken nodes information set must probability
distribution associated them. eight possible outcomes game,
labeled pair payoffs Alice Bob, respectively.

2.2.1 Strategy Representation
Unlike case normal-form games, several quite different choices strategy
representation extensive-form games. One convenient formulation terms behavior
strategies. behavior profile b assigns information set distribution
462

fiA Continuation Method Nash Equilibria Structured Games

actions A(i). probability agent n takes action information set
written b(a|i). node i, write b(a|y) abbreviation
b(a|i).
methods primarily employ variant sequence form representation (Koller &
Megiddo, 1992; von Stengel, 1996; Romanovskii, 1962), built upon behavior
strategy representation. sequence form, strategy n agent n represented
realization plan, vector real values. value, realization probability,
realization plan corresponds distinct history (or sequence) Hn (y) agent n has,
nodes game tree. sequences may partial records ns
behavior game proper prefixes larger sequences. strategy representation
employed GW (and ourselves) equivalent sequence form representation
restricted terminal sequences: agent-n histories least one leaf node.
shall henceforth refer modified strategy representation simply sequence form,
sake simplicity.
agent n, then, consider realization plan n vector realization
probabilities terminal sequences. outcome z, (Hn (z)), abbreviated n (z),
probability agent ns choices allow realization outcome z
Q words,
product agent ns behavior probabilities along history Hn (z), (i,a)Hn (z) b(a|i).
Several different outcomes may associated terminal sequence,
agent n may fewer realization probabilities leaves tree. set
realization plans agent n therefore subset IR`n , `n , number distinct
terminal sequences agent n, number leaves tree.
Example 2. example above, Alice eight terminal sequences, one
a01 , a02 , . . . , a08 four information sets bottom level. history one
last action (a1 , a03 ). realization probability (a1 , a03 ) equal b(a1 )b(a03 |a1 , b2 ) =
0.1 0.6 = 0.06. Bob two last actions, whose realization probabilities exactly
behavior probabilities.
realization probabilities non-zero, realization plans behavior strategies
one-to-one correspondence. (When probabilities zero, many possible behavior strategy profiles might correspond realization plan, described Koller
& Megiddo, 1992; affect work presented here.)
Q behavior strategy
profile b, easily calculate realization probability n (z) = (i,a)Hn (z) b(a|i).
understand reverse transformation, note map behavior strategies
full realization plans defined non-terminal sequences
(as originally defined
Q
Koller & Megiddo, 1992) defining n (h) = (i,a)h b(a|i); intuitively, n (h)
probability agent ns choices allow realization partial sequence h. Using
observation, compute behavior strategy extended realization plan: (partial) sequence (h, a) extends sequence h one action, namely action information set
belonging agent n, compute b(a|i) = nn(h,a)
(h) . extended realization
probabilities computed terminal realization probabilities recursive
procedure starting leaves tree working upward: atPinformation set
agent-n history h (determined uniquely perfect recall), n (h) = aA(i) n (h, a).
several different information sets agent-n history h, n (h)
computed multiple ways. order (terminal) realization plan valid,
463

fiBlum, Shelton, & Koller

must satisfy constraint choices information sets agent-n history h must
give rise value n (h). formally, partial sequence h,

P constraints
P pairs information sets i1 i2 Hn (i1 ) = Hn (i2 ) = h,

(h,
a)
=
aA(i1 ) n
aA(i2 ) n (h, a). game tree Example 1, consider Alices
realization probability (a1 ). expressed either (a1 , a01 ) + (a1 , a02 ) =
0.1 0.2 + 0.1 0.8 (a1 , a03 ) + (a1 , a04 ) = 0.1 0.6 + 0.1 0.4, two sums must
same.
recursively defining realization probability sum realization probabilities longer sequences, constraints expressed terms terminal realization
probabilities; fact, constraints linear probabilities. several
constraints: probabilities must nonnegative, and, agent n, n () = 1,
(the empty sequence) agent-n history first information set agent n
encounters. latter constraint simply enforces probabilities sum one. Together,
linear constraints define convex polytope legal terminal realization plans.
2.2.2 Payoffs
agents play according , payoff agent n extensive-form game
X

Gn () =
Gn (z)
k (z) ,
(2)
zZ

kN

augmented N include nature notational convenience.
simply expected sum payoffs leaves. agent
Q k, k (z)
product probabilities controlled n along path z; thus, kN k (z)
multiplication probabilities along path z, precisely probability
z occurring. Importantly, expression similar multi-linear form payoff
normal-form game, using realization plans rather mixed strategies.
Extensive-form games expressed (inefficiently) normal-form games,
guaranteed equilibrium mixed strategies. extensive-form game
satisfying perfect recall, mixed strategy profile represented payoff-equivalent
behavior profile, hence realization plan (Kuhn, 1953).

3. Structured Game Representations
artificial intelligence community recently introduced structured representations
exploit independence relations games order represent compactly.
methods address two representations: graphical games (Kearns et al., 2001),
structured class normal-form games, MAIDs (Koller & Milch, 2001), structured
class extensive-form games.
3.1 Graphical Games
size payoff arrays required describe normal-form game grows exponentially
number agents. order avoid blow-up, Kearns et al. (2001) introduced
framework graphical games, structured representation inspired probabilistic graphical models. Graphical games capture local structure multi-agent interactions,
464

fiA Continuation Method Nash Equilibria Structured Games

allowing compact representation scenarios agents payoff affected
small subset agents. Examples interactions structure occurs include agents interact along organization hierarchies agents interact according
geographic proximity.
graphical game similar definition normal-form game, representation
augmented inclusion interaction graph node agent.
original definition assumed undirected graph, easily generalizes directed graphs.
edge agent n0 agent n graph indicates agent ns payoffs depend
action agent n0 . precisely, define Famn set agents consisting
n parents graph. Agent ns payoff function Gn array indexed
actions agents Famn . Thus, description game exponential
in-degree graph total number agents. case, use
fn Afn refer strategy profiles action profiles, respectively, agents
Famn \ {n}.
Example 3. Suppose 2L landowners along road running north south deciding
whether build factory, residential neighborhood, shopping mall plots.
plots laid along road 2-by-L grid; half agents east side
(e1 , . . . , eL ) half west side (w1 , . . . , wL ). agents payoff depends
builds neighbors north, south, across road build.
example, agent wants build residential neighborhood next factory. agents
payoff matrix indexed actions four agents (fewer ends road)
34 entries, opposed full 32L entries required equivalent normal form
game. (This example due Vickrey & Koller, 2002.)
3.2 Multi-Agent Influence Diagrams
description length extensive-form games grow exponentially number agents. many situations, large tree represented compactly.
Multi-agent influence diagrams (MAIDs) (Koller & Milch, 2001) allow structured representation games involving time information extending influence diagrams (Howard
& Matheson, 1984) multi-agent case.
MAIDs influence diagrams derive much syntax semantics
Bayesian network framework. MAID compactly represents certain type extensiveform game much way Bayesian network compactly represents joint
probability distribution. thorough treatment Bayesian networks, refer
reader reference Cowell et al. (1999).
3.2.1 MAID Representation
Bayesian network, MAID defines directed acyclic graph whose nodes correspond
random variables. random variables partitioned sets: set X chance
variables whose values chosen nature, represented graph ovals;
agent n, set Dn decision variables whose values chosen agent n, represented
rectangles; agent n, set Un utility variables, represented diamonds.
Chance decision variables have, domains, finite sets possible actions.
refer domain random variable V dom(V ). chance decision variable
465

fiBlum, Shelton, & Koller

V , graph defines parent set PaV variables whose values choice V
depend. Utility variables finite sets real payoff values domains,
permitted children graph; represent components agents
payoffs, game state.
game definition supplies chance variable X conditional probability
distribution (CPD) P (X|PaX ), conditioned values parent variables X.
semantics chance variable identical semantics random variable
Bayesian network; CPD specifies probability action dom(X)
selected nature, given actions taken Xs parents. game definition supplies
utility function utility node U . utility function maps instantiation
pa dom(PaU ) deterministically real value U (pa). notational algorithmic
convenience, regard utility function CPD P (U |PaU ) which,
pa dom(PaU ), value U (pa) probability 1 P (U |pa) values
probability 0 (the domain U simply finite set possible utility values).
end game, agent ns total payoff sum utility received Uni Un
(here index variable). Note component Uni agent ns payoff depends
subset variables MAID; idea compactly decompose payoff
additive pieces.
3.2.2 Strategy Representation
counterpart CPD decision node decision rule. decision rule
decision variable Dni Dn function, specified n, mapping instantiation
pa dom(PaDni ) probability distribution possible actions dom(Dni ).
decision rule identical form conditional probability distribution, refer
using notation P (Dni |PaDni ). semantics chance node, decision
rule specifies probability agent n take particular action dom(Dni ),
seen actions taken Dni parents. assignment decision rules Dni Dn
comprises strategy agent n. agent n chooses strategy, ns behavior Dni
depends actions taken Dni parents. PaDni therefore regarded
set nodes whose values visible n makes choice Dni . Agent ns choice
strategy may well take nodes account; actual game play, nodes
except PaDni invisible n.
Example 4. extensive-form game considered Example 1 represented
MAID shown Figure 2(a). Alice Bob initial decision make without
information previous actions; Alice another decision make
aware Bobs action own. Alice Bob one utility node
(the two condensed single node graph, sake brevity), whose payoff
structure wholly general (dependent every action game) thus whose possible
values exactly values payoff vectors extensive-form game.
Example 5. Figure 2(b) shows complicated MAID somewhat realistic
scenario. Here, three landowners along road deciding whether build store
house. payoff depends happens adjacent along road.
decision proceeds two stages: planning stage building stage. second
466

fiA Continuation Method Nash Equilibria Structured Games


P1

P2

B

P3

E1

E2

C1



C2

B1

AB

C3

B2

R1

L2

(a)

B3

R2

L3

(b)

Figure 2: (a) simple MAID equivalent extensive form game Figure 1. (b)
two-stage road game three agents.

landowner, instance, two decision variables P2 B2 . receives certain
penalty utility node C2 builds opposite planned build.
planning, learns something neighbor left planned.
chance node E1 represents noisy espionage; transmits action taken P1 .
learning value E1 , may second landowners interests deviate
plan, even means incurring penalty. interest start trend
distinguishes previous builders subsequent builders follow: utility
node L2 rewards building opposite built B1 , utility node
R2 rewards third landowner builds thing B3 .
Note MAID exhibits perfect recall, choice made planning stage
visible agent makes next choice building stage.
3.2.3 Payoffs
particular strategy profile is, tuple strategies players
decision nodes CPDs specified. Since chance utility nodes endowed CPDs
already, MAID therefore induces fully-specified Bayesian network B variables
V = X U directed graph MAID. chain rule Bayesian
networks,QB induces joint probability distribution P variables V
P (V) = V V P (V |PaV ), CPDs chance utility variables given MAID
definition CPDs decision variables given . game G represented
MAID, expected payoff agent n receives expectation ns utility
node values respect distribution:
X
Gn () =
EP [Uni ]
Uni Un

=

X

X

Uni Un udom(Uni )

467

u P (u).

fiBlum, Shelton, & Koller

show Section 7 related expectations calculated efficiently
using Bayesian network inference algorithms, giving substantial performance increase
calculation payoffs extensive-form game.
3.2.4 Extensive Form Strategy Representations MAIDs
MAID provides compact definition extensive-form game. note that, although
correspondence MAIDs extensive form games provides intuition
MAIDs, details mapping relevant remainder discussion.
therefore briefly review construction, referring work Koller Milch
(2001) details.
game tree associated MAID full, balanced tree, path corresponding complete assignment chance decision nodes network.
node tree corresponds either chance node decision node one
players, outgoing branch possible action node. nodes
depth tree correspond MAID node. assume nodes
along path tree ordered consistently ordering implied directed
edges MAID, MAID node X parent MAID node , tree
branches X branches . information sets tree nodes associated
decision node Dni correspond assignments parents PaDni : tree nodes
corresponding Dni assignment PaDni single information set.
note that, construction, assignment PaDni determined earlier tree,
partition information sets well-defined. example, simple MAID
Figure 2(a) expands much larger game tree saw earlier Figure 1.
Translating opposite direction, extensive-form games MAIDs,
always natural. game tree unbalanced, cannot simply reverse
process. However, care, possible construct MAID larger
given extensive-form game, may exponentially smaller number agents.
details fairly technical, omit interest brevity.
Despite fact MAID typically much compact equivalent
extensive-form game, strategy representations two turn equivalent
equal size. decision rule decision variable Dni assigns distribution actions
joint assignment PaDni , behavior strategy assigns distribution actions
information set extensive form game discussed above, assignment
parents Dni information set. strategy profile MAID set decision
rules every decision variable therefore equivalent set behavior strategies
every information set, simply behavior profile.
make assumption perfect recall, then, since MAID strategies simply
behavior strategies, represent sequence form. Perfect recall requires
agent forget anything learned course game. MAID
formalism, perfect recall assumption equivalent following constraint: agent
n two decision nodes Dni Dnj , second occurring first,
parents Dni (the information n aware making decision Dni ) Dni must
parents Dnj . implies agent ns final decision node Dnd has, parents, ns
previous decision nodes parents. joint assignment Dnd PaDnd precisely
468

fiA Continuation Method Nash Equilibria Structured Games

determines agent ns sequence information sets actions leading outcome
game agent-n history outcome.
realization probability particular sequence computed multiplying
behavior strategy probabilities actions sequence. MAIDs, sequence corresponds joint assignment Dnd PaDnd , behavior strategy probabilities
sequence entries consistent assignment decision rules agent n.
therefore derive agent ns realization probabilities multiplying
together, conditional probability distributions, decision rules agent ns decision nodes sequence multiplying conditional probability distributions,
entries whose assignments consistent multiplied. Conversely,
given realization plan, derive behavior strategies hence decision rules
according method outlined extensive-form games.
simple MAID example Figure 2(a), terminal sequences
equivalent extensive-form game. road example Figure 2(b), agent 2 8
terminal sequences; one joint assignment final decision node (B2 )
parents (E1 P2 ). associated realization probabilities given multiplying
decision rules P2 B2 .

4. Computational Complexity
developing algorithms compute equilibria efficiently, question naturally arises
well one expect algorithms perform. complexity computing
Nash equilibria studied time. Gilboa Zemel (1989) first showed
NP-hard find one Nash equilibrium normal-form game,
Conitzer Sandholm (2003) recently utilized simpler reduction arrive result
several others vein. recent hardness results pertain restricted
subclasses normal-form games (e.g., Chu & Halpern, 2001; Codenotti & Stefankovic,
2005). However, results apply 2-agent normal-form games. true
proving certain subclass class problems NP-hard proves entire
class NP-hard (because NP-hardness measure worst-case complexity),
proof might tell us little complexity problems outside subclass.
issue particularly apparent problem computing equilibria, games
grow along two distinct axes: number agents, number actions per agent.
hardness results Conitzer Sandholm (2003) apply number actions
per agent increases. 2-agent normal-form games (fully connected) graphical
games, results apply graphical games.
However, interested hardness graphical games number
agents increases, rather number actions per agent. graphical games
large numbers agents capture structure games
graphical game representation designed. order prove results
asymptotic hardness computing equilibria along interesting (in setting)
axis representation size, require different reduction. proof, number
previous hardness proofs games (e.g., Chu & Halpern, 2001; Conitzer & Sandholm, 2003;
Codenotti & Stefankovic, 2005), reduces 3SAT equilibrium computation. However,
previous proofs, variables 3SAT instances mapped actions (or sets actions)
469

fiBlum, Shelton, & Koller

game 2 players, whereas reduction mapped agents. Although
differing approach, reduction much spirit reduction appearing
work Conitzer Sandholm (2003), many corollaries main result
follow (in form adapted graphical games).
Theorem 6. constant 5, k 2, problem deciding whether
graphical game family size k actions per player
one Nash equilibrium NP-hard.
Proof. Deferred Appendix B.
reduction, games one equilibria least one pure
strategy equilibrium. immediately gives us
Corollary 7. NP-hard determine whether graphical game one Nash
equilibrium discretized strategies even coarsest possible granularity.
Finally, graphical games represented (trivial) MAIDs,
agent single parentless decision node single utility node, agents
utility node has, parents, decision nodes graphical game family agent,
obtain following corollary.
Corollary 8. NP-hard determine whether MAID constant family size least
6 one Nash equilibrium.

5. Continuation Methods
Continuation methods form basis algorithms solving structured game representations. begin high-level overview continuation methods,
referring reader work Watson (2000) detailed discussion.
Continuation methods work solving simpler perturbed problem tracing
solution magnitude perturbation decreases, converging solution
original problem. precisely, let scalar parameterizing continuum
perturbed problems. = 0, perturbed problem original one; = 1,
perturbed problem one solution known. Let w represent vector
real values solution. perturbed problem defined , characterize
solutions equation F (w, ) = 0, F real-valued vector function
dimension w (so 0 vector zeros). function F w solution
problem perturbed F (w, ) = 0.
continuation method traces solutions along level set solution pairs (w, )
satisfying F (w, ) = 0. Specifically, solution pair (w, ), would trace
solution nearby solution. Differential changes w must cancel
F remains equal 0.
(w, ) changes direction unit vector u, F change
direction


F u, F Jacobian F (which written w F F ).
want find direction u F remains unchanged, i.e., equal 0. Thus, need
solve matrix equation


dw
w F F
=0.
(3)

470

fiA Continuation Method Nash Equilibria Structured Games

Equivalently, changes dw along path must obey w F dw = F d. Rather
inverting matrix w F solving equation, use adjoint adj(w F ),
still defined w F null space rank 1. adjoint matrix cofactors:
element (i, j) (1)i+j times determinant sub-matrix row
column j removed. inverse defined, adj(w F ) = det(w F )[w F ]1 .
practice, therefore set dw = adj(w F ) F = det(w F ). Jacobian
[w F F ] null-space rank 1 everywhere, curve uniquely defined.
function F constructed curve starting = 1 guaranteed
cross = 0, point corresponding value w solution original
problem. continuation method begins known solution = 1 . null-space
Jacobian F current solution (w, ) defines direction, along solution
moved small amount. Jacobian recalculated process repeats,
tracing curve = 0. cost step computation least cubic
size w, due required matrix operations. However, Jacobian may
general much difficult compute. Watson (2000) provides simple examples
continuation methods.

6. Continuation Methods Games
review work GW applying continuation method task finding equilibria games. provide continuation methods normal-form
extensive-form games. algorithms form basis extension structured
games, described next section. continuation methods perturb game giving agents fixed bonuses, scaled , actions, independently whatever
else happens game. bonuses large enough (and unique), dominate
original game structure, agents need consider opponents actions.
thus unique pure-strategy equilibrium easily determined bonuses = 1.
continuation method used follow path space equilibrium
profiles resulting perturbed game, decreasing zero; point,
corresponding strategy profile equilibrium original game.
6.1 Continuation Method Normal-Form Games
make intuition precise, beginning normal-form games.
6.1.1 Perturbations
perturbation vector b vector values chosen random, one action
game. bonus ba given agent n owning action playing a, independently
whatever else happens game. Applying perturbation target game G gives
us new game, denote G b, which, , ,
(G b)n (a, t) = Gn (a, t) + ba . b made sufficiently large, G b unique
equilibrium, agent plays pure strategy ba maximal.
471

fiBlum, Shelton, & Koller

6.1.2 Characterization Equilibria
order apply Equation (3), need characterize equilibria perturbed games
zeros function F . Using structure theorem Kohlberg Mertens (1986), GW
show continuation method path deriving equilibrium characterization
leads convergence perturbation vectors except set measure zero.
present equilibrium characterization here; proofs characterization
methods convergence given Govindan Wilson (2003).
first define auxiliary vector function V G (), indexed actions, payoffs
agent deviating play single action. call V G deviation function.
element VaG () corresponding single action a, owned agent n, payoff
agent n deviates mixed strategy profile playing pure strategy
action a:
X

(4)
VaG () =
Gn (a, t)
tk .
tAn

kN \{n}

viewed component agent ns payoff derives action a,
strategy profile . Since bonuses given actions independently ,
effect bonuses V G independent . VaG measures payoff deviating
playing a, bonuses given precisely deviation, V Gb () = V G () + b.
utilize retraction operator R : IRm defined Gul, Pearce, Stachetti (1993), maps arbitrary m-vector w point space mixed
strategies nearest w Euclidean distance. Given operator, equilibrium
characterization follows.
Lemma 9. (Gul et al., 1993) strategy profile G, = R(V G () + ) iff
equilibrium.
Although omit proof, give intuition result true.
Suppose fully-mixed equilibrium; is, every action non-zero probability.
single agent n, VaG () must actions , n
incentive deviate play single one them. Let Vn vector entries
V G () corresponding actions n, let n defined similarly. Vn scalar multiple
1, all-ones vector, simplex n ns mixed strategies defined 1T x = 1,
Vn orthogonal n . V G () therefore orthogonal , retracting + V G () onto
gives precisely . reverse direction, fully-mixed strategy profile satisfying
= R(V G () + ), V G () must orthogonal polytope mixed strategies.
Then, agent, every pure strategy payoff. Therefore, fact
equilibrium. little care must taken dealing actions support.
refer Gul et al. (1993) details.
According Lemma 9, define equilibrium solution equation
= R( + V G ()). hand, = R(w) w IRm ,
equivalent condition w = R(w) + V G (R(w)); equilibrium iff condition
satisfied, easily verified. therefore search point w IRm
satisfies equality, case R(w) guaranteed equilibrium.
form continuation equation

F (w, ) = w R(w) V G (R (w)) + b .
(5)
472

fiA Continuation Method Nash Equilibria Structured Games

V G + b deviation function perturbed game G b, F (w, )
zero R(w) equilibrium G b. = 0 game unperturbed,
F (w, 0) = 0 iff R(w) equilibrium G.
6.1.3 Computation
expensive step continuation method calculation Jacobian w F ,
required computation maintains constraint Equation (3). Here,
w F = (I + V G )R, identity matrix. hard part
calculation V G . pure strategies a0 An0 , n0 6= n, value
location (a, a0 ) V G () equal expected payoff agent n plays
pure strategy a, agent n0 plays pure strategy a0 , agents act according
strategy profile :

X
Gn (a, t)
tk
a0
tAn
kN \{n}
X

0
=
Gn (a, , t)
tk .

G
Va,a
0 () =

tAn,n0

(6)

kN \{n,n0 }

G () = 0.
a0 , Va,a
0

Computing Equation
(6) requires large number multiplications; sum
Q
space An,n0 = kN \{n,n0 } Ai , exponentially large number agents.
6.2 Continuation Method Extensive-Form Games
method applies extensive-form games, using sequence form strategy representation.
6.2.1 Perturbations
normal-form games, game perturbed bonus vector b. Agent n owning
sequence h paid additional bonus bh playing h, independently whatever else
happens game. Applying perturbation gives us new game G b which,
z Z, (G b)n (z) = Gn (z) + bHn (z) .
bonuses large enough unique, GW show perturbed
game unique pure-strategy equilibrium (one realization probabilities
0 1). However, calculating simple case normal-form games.
Behavior strategies must calculated leaves upward recursive procedure,
step agent owns node question chooses action results
sequence largest bonus. Since actions recursively
determined, action node question determines outcome. realization
plans derived behavior profile method outlined Section 2.2.1.
473

fiBlum, Shelton, & Koller

6.2.2 Characterization Equilibria
more, first define vector function capturing benefit deviating given
strategy profile, indexed sequences:
X

k (z),
(7)
VhG () =
Gn (z)
zZh

kN \{n}

Zh set leaves consistent sequence h. interpretation
V G natural case normal-form games, possible agent
play one sequence exclusion others; possible actions partially
determined actions agents. case, VhG () regarded
portion payoff agent n receives playing sequence h, unscaled agent ns
probability playing sequence. normal-form games, vector bonuses
added directly V G , V Gb = V G + b.
retraction operator R realization plans defined way normalform strategies: takes general vector projects onto nearest point valid
region realization plans. constraints defining space linear, discussed
Section 2.2.1 . therefore express constraint matrix C C = 0
valid profiles . addition, probabilities must greater equal zero.
calculate w, must find minimizing (w )T (w ), (squared) Euclidean distance
w , subject C = 0 0. quadratic program (QP),
solved efficiently using standard methods. Jacobian retraction easily
computable set active constraints.
equilibrium characterization realization plans surprisingly similar
mixed strategies normal-form games; GW show that, before, equilibria
characterized = R( + V G ()), R retraction sequence form
V G deviation function. continuation equation F takes exactly form
well.
6.2.3 Computation
key property reduced sequence-form strategy representation deviation function multi-linear function extensive-form parameters, shown
Equation (7). elements Jacobian V G thus general structure. particular, element corresponding sequence h agent n sequence h0
agent n0

X
Gn (z)
k (z)
h0
zZh
kN \{n}
X

=
Gn (z)
k (z)

G
Vh,h
0 () =

zZh,h0

(8)

kN \{n,n0 }

Zh,h0 set leaves consistent sequences h (for agent n)
h0 (for agent n0 ). Zh,h0 empty set (and hence V G = 0) h h0 incompatible.
Equation (8) precisely analogous Equation (6) normal-form games. sum
outcomes utility outcome multiplied strategy probabilities
474

fiA Continuation Method Nash Equilibria Structured Games


3
2


1

Figure 3: abstract diagram path. horizontal axis represents vertical
axis represents space strategy profiles (actually multidimensional).
algorithm starts right = 1 follows dynamical system
= 0 point 1, found equilibrium original game.
continue trace path find equilibria labeled 2 3.

agents. Note sum leaves tree, may exponentially
numerous number agents.
One additional subtlety, must addressed method equilibrium computation extensive-form games, relates zero-probability actions. actions induce
probability zero entire trajectories tree, possibly leading equilibria based
unrealizable threats. Additionally, information sets occur zero probability,
agents behave arbitrarily without disturbing equilibrium criterion, resulting continuum equilibria possible bifurcation continuation path. prevents
methods converging. therefore constrain realization probabilities greater
equal small > 0. is, fact, requirement GWs equilibrium
characterization hold. algorithm thus looks -perfect equilibrium (Fudenberg
& Tirole, 1991): strategy profile component constrained ,
agents strategy best response among satisfying constraint. Note
entirely different -equilibrium. -perfect equilibrium always exists,
long large make set legal strategies empty. -perfect equilibrium interpreted equilibrium perturbed game agents small
probability choosing unintended action. limit -perfect equilibria approaches
0 perfect equilibrium (Fudenberg & Tirole, 1991): refinement basic notion
Nash equilibrium. approaches 0, equilibria found GWs algorithm therefore
converge exact perfect equilibrium, continuity variation continuation
method path. small enough, perfect equilibrium vicinity
found -perfect equilibrium, easily found local search.
475

fiBlum, Shelton, & Koller

6.3 Path Properties
case normal-form games, GW show, using structure theorem Kohlberg
Mertens (1986), path algorithm one-manifold without boundary
probability one choices b. provide analogous structure theorem
guarantees property extensive-form games. Figure 3(a) shows abstract
representation path followed continuation method. GW show path
must cross = 0 hyperplane least once, yielding equilibrium. fact, path
may cross multiple times, yielding many equilibria single run. path must
eventually continue = side, find odd number equilibria run
completion.
normal-form extensive-form games, path piece-wise polynomial,
piece corresponding different support set strategy profile. pieces
called support cells. path smooth cell boundaries due discontinuities
Jacobian retraction operator, hence w F , support changes. Care
must taken step boundaries exactly following path; point,
Jacobian new support calculated path traced
new support cell.
case two agents, path piece-wise linear and, rather taking steps,
algorithm jump corner corner along path. algorithm applied
two-agent game particular bonus vector used (in single entry nonzero), steps support cell support cell algorithm takes identical
pivots Lemke-Howson algorithm (Lemke & Howson, 1964) two-agent generalsum games, two algorithms find precisely set solutions (Govindan &
Wilson, 2002). Thus, continuation method strict generalization LemkeHowson algorithm allows different perturbation rays games two
agents.
process described detail pseudo-code algorithm, presented
Figure 4.
6.4 Computational Issues
Guarantees convergence apply long stay path defined dynamical system continuation method. However, computational purposes, discrete
steps must taken. result, error inevitably accumulates path traced,
F becomes slightly non-zero. GW use several simple techniques combat problem.
adopt techniques, introduce one own: employ adaptive step
size, taking smaller steps error accumulates quickly larger ones not.
F nearly linear (as is, example, actions support
current strategy profile), technique speeds computation significantly.
GW use two different techniques remove error accumulated. Suppose
point (w, ) wish minimize magnitude F (w, ) = w V G (R(w)) +
b+R(w). two values might change: w, b. change first without
affecting guarantee convergence, every steps run local Newton method
search w minimizing |F (w, )|. search decrease error sufficiently,
perform GW call wobble: change perturbation vector (wobble
476

fiA Continuation Method Nash Equilibria Structured Games

continuation path) make current solution consistent. set b = [w V G (R(w))
R(w)]/, equilibrium characterization equation immediately satisfied. Changing
perturbation vector invalidates theoretical guarantees convergence. However,
nonetheless attractive option immediately reduces error zero.
local Newton method wobbles described detail Govindan
Wilson (2003).
techniques potentially send algorithm cycle, practice
occasionally do. However, necessary keeping algorithm path.
algorithm cycles, random restarts decrease step size improve convergence.
sophisticated path-following algorithms might used, general could improve
success rate execution time algorithm.
6.5 Iterated Polymatrix Approximation
perturbed games may large number equilibria, path
may wind back forth number them, continuation algorithm
take trace way back solution original game. speed
algorithm using initialization procedure based iterated polymatrix approximation
(IPA) algorithm GW. polymatrix game normal-form game payoffs
agent n equal sum payoffs set two-agent games, involving
n another agent. polymatrix games linear combination two-agent
normal-form games, reduce linear complementarity problem solved
quickly using Lemke-Howson algorithm (Lemke & Howson, 1964).
agent n N polymatrix game, payoff array matrix B n indexed
n
actions agent n agent; actions a0 An0 , Ba,a
0
0
0
0
payoff n receives playing game agent n , n plays . Agent
ns
payoffs receives games agent,
P total
Ppayoff sum
n
n0 6=n
aAn ,a0 An0 a0 Ba,a0 . Given normal-form game G strategy profile ,
construct polymatrix game P whose payoff function Jacobian
Gs setting
G
n
(9)
Ba,a
0 = Va,a0 () .
game P linearization G around : Jacobian everywhere. GW
show equilibrium G equilibrium P . follows
equation V G () = V G () /(|N | 1), holds . see
holds, consider single element indexed :
X
X
X

(V G () )a =
a0
Gn (a, a0 , t)
tk
n0 N \{n} a0 An0

=

X

X

n0 N \{n}

tAn

kN \{n,n0 }

tAn,n0

Gn (a, t)



tk

kN \{n}

G

= (|N | 1)V ()a .
equilibrium characterization equation therefore written

= R + V G () (|N | 1) .
477

fiBlum, Shelton, & Koller

G P value V , thus equilibrium characterization
function. satisfies one satisfies other.
define mapping p : p() equilibrium P (specifically,
first equilibrium found Lemke-Howson algorithm). p() = ,
equilibrium G. IPA procedure Govindan Wilson (2004) aims find
fixed point. begins randomly chosen strategy profile , calculates p()
running Lemke-Howson algorithm; adjusts toward p() using approximate
derivative estimate p built past two iterations. p() sufficiently
close, terminates approximate equilibrium.
IPA guaranteed converge. However, practice, quickly moves near
good solution. possible point calculate perturbed game close
original game (essentially, one differs amount Gs polymatrix
approximation differs G) found approximate equilibrium fact
exact equilibrium. continuation method run starting point
find exact equilibrium original game. continuation method guaranteed
converge starting point. However, practice always found
converge, long IPA configured search high quality equilibrium approximations.
Although theoretical results required quality, IPA refine starting
point continuation method fails. results show IPA quick-start
substantially reduces overall running time algorithm.
fact use approximate algorithm quick-start ours,
without guarantees convergence. Given approximate equilibrium , inverse
image R defined set linear constraints. let w := V G () + ,
use standard QP methods retract w nearest point w0 satisfying
constraints, let b := w0 w. = R(w0 ) = R(V G () + + b),
continuation method path. Alternatively, choose b wobbling, case
set b := [w V G (R(w)) R(w)]/.

7. Exploiting Structure
algorithms continuation method foundation game representation,
calculation V G Step 2(b)i pseudo-code Figure 4 different
consumes time. normal-form (in worst case) extensiveform games, requires exponential time number agents. However, show
section, using structured representation graphical game MAID,
effectively exploit structure game drastically reduce computational
time required.
7.1 Graphical Games
Since graphical game normal-form game, definition deviation function
V G Equation (4) same: VaG () payoff agent n deviating
play deterministically. However, due structure graphical game, choice
strategy agent outside family n affect agent n0 payoff.
observation allows us compute payoff locally.
478

fiA Continuation Method Nash Equilibria Structured Games

input game G:
1. Set = 1, choose initial b either quick-start procedure (e.g., IPA) randomizing. Set
w = V G () + b + .
2. greater (negative) threshold (i.e., still good chance picking
another equilibrium):
(a) Initialize current support cell: set steps counter number steps take
crossing cell, depending current amount error. F linear nearly linear (if,
example, strategy profile nearly pure, 2 agents), set steps = 1
cross entire cell.
(b) steps 1:
i. Compute V G ().
ii. Set w F (w, ) = (V G () + I)R(w) (we already know F = b). Set dw =
adj(w F ) b = det(w F ). satisfy Equation (3).
iii. Set equal distance wed go direction dw reach next support
boundary. scale dw /steps.
iv. change signs course step, record equilibrium point
0.
v. Set w := w + dw(/steps) := + d(/steps).
vi. sufficient error accumulated, use local Newton method find w minimizing
|F (w, )|. reduce error enough, increase steps, thereby decreasing step
size. already increased steps, perform wobble reassign b.
vii. Set steps := steps 1.

Figure 4: Pseudo-code cont algorithm.
7.1.1 Jacobian Graphical Games
begin definition V G normal-form games (modified slightly account
local payoff arrays). Recall Afn set action profiles agents Famn
n, let AFamn set action profiles agents Famn .
divide sum full action profiles two sets, switching
normal-form version Gn graphical game version Gn , follows:
X

VaG () =
Gn (a, t)
tk
tAn

=

X
uAfn

kN \{n}

Gn (a, u)



uk

X



v j .

(10)

kFamn \{n} vAFamn jN \Famn

Note latter sum product simply sum probability distribution, hence
always equal 1 due constraints . thus eliminated without
changing value V G takes valid strategy profiles. However, partial derivatives
respect strategies agents Famn non-zero, enter computation V G .
Suppose wish compute row Jacobian matrix corresponding action
agent n. must compute entries action a0 agent n0 N . trivial
G = 0, since appear anywhere expression
case n0 = n Va,a
0

VaG (). next compute entries action a0 agent n0 Famn .
479

fiBlum, Shelton, & Koller

case,
G
Va,a
0 () =

X


Gn (a, u)
a0
f

=

Gn (a, u)

uAfn

=

X


a0





v j

(11)

uk 1

kFamn \{n}



Gn (a, a0 , t)

tAfn,n0

X

vAFamn jN \Famn

kFamn \{n}

uAn

X

uk

kFamn

n0 Famn .

tk ,

(12)

\{n,n0 }

next compute entry single action a0 agent n0
/ Famn . derivative
Equation (11) takes different form case; variable question second
summation, first,
X

X


G
Va,a
v j
Gn (a, u)
uk
0 () =
a0
f
=

X

Gn (a, u)

=

X



uk

Gn (a, u)

uAfn



X

vAFamn

kFamn \{n}

uAfn

vAFamn jN \Famn

kFamn \{n}

uAn

uk 1,


a0



v j

jN \Famn

n0 6 Famn .

(13)

kFamn \{n}

Notice calculation depend a0 ; therefore, action
agent Famn . need compute elements row.
copy value columns actions belonging agents Famn .
7.1.2 Computational Complexity
Due graphical game structure, computation V G () takes time exponential
maximal family size game, hence takes time polynomial number
agents family size constant. particular, methods lead following
theorem complexity continuation method graphical games.
Theorem 10. time complexity computing Jacobian deviation function
V G () graphical game O(f df |N | + d2 |N |2 ), f maximal family size
maximal number actions per agent.
Proof. Consider single row Jacobian, corresponding single action owned
single agent n. d(f 1) entries row actions owned
G
members Famn . one action a0 , computation Jacobian element Va,a
0
f
2
according Equation (12) takes time O(d ). total cost entries therefore
O((f 1)df 1 ). d(|N | f ) entries actions owned non-familyG a0 same. calculated time
members. value Va,a
0
f
1
O(d ), copied across row time d(|N | f ). all, computational cost
row O(f df 1 + d|N |). d|N | rows, total computational
cost O(|N |f df + d2 |N |2 ).
480

fiA Continuation Method Nash Equilibria Structured Games

P1

P2

P3

B1

B2

B3


B

(a)

(b)

Figure 5: strategic relevance graphs MAIDs (a) Figure 2(a) (b) Figure 2(b).

iteration algorithm calculates V G () once; therefore proved
single iteration takes time polynomial |N | f constant (in fact, matrix operations make
complexity cubic |N |). However, normal-form games, theoretical
results many steps continuation method required convergence.
7.2 MAIDs
graphical games, exploitation structure straightforward. turn
difficult problem exploiting structure MAIDs. take advantage two
distinct sets structural properties. first, coarse-grained structural measure known
strategic relevance (Koller & Milch, 2001), used previous computational
methods. decomposing MAID according strategic relevance relations,
exploit finer-grained structure using extensive-form continuation method GW
solve components equivalent extensive-form game. next two sections,
describe two kinds structure.
7.2.1 Strategic Relevance
Intuitively, decision node Dni strategically relevant another decision node Dnj 0 agent
n0 , order optimize decision rule Dnj 0 , needs know agent ns decision rule
Dni . relevance relation induces directed graph known relevance graph,
decision nodes appear edge node Dnj 0 node Dni present iff Dni
strategically relevant Dnj 0 . event relevance graph acyclic, decision
rules optimized sequentially reverse topological order; children
node Dni decision rules set, decision rule Dni optimized
without regard nodes.
cycles exist relevance graph, however, steps must taken. Within
strongly connected component (SCC), set nodes directed path
two nodes exists relevance graph, decision rules cannot optimized sequentially
linear ordering nodes SCC, node must optimized one
481

fiBlum, Shelton, & Koller

children, impossible. Koller Milch (2001) show MAID
decomposed SCCs, solved individually.
example, relevance graph MAID Figure 2(a), shown Figure 5(a),
one SCC consisting B, another consisting A0 . MAID, would
first optimize decision rule A0 , optimal decision rule A0 rely
decision rules B makes decision A0 , Alice already knows
actions taken B, need know decision rules led them.
would turn A0 chance node CPD specified optimized decision
rule optimize decision rules A0 B. relevance graph Figure 2(b),
shown Figure 5(b), forms single strongly connected component.
computational method Koller Milch (2001) stops strategic relevance:
SCC converted equivalent extensive-form game solved using standard
methods. algorithm viewed augmentation method: MAID
decomposed SCCs, solve SCCs using methods, taking
advantage finer-grained MAID structure within find equilibria efficiently.
MAIDs test algorithms (including road MAID Figure 2b)
strongly connected relevance graphs, cannot decomposed (see Figure 5b
Figure 10).
7.2.2 Jacobian MAIDs
MAID equivalent extensive-form game, deviation function V G
one defined Equation (8). Now, however, compute payoffs make
Jacobian V G efficiently. Consider payoff Gn (z) agent n outcome z.
outcome z simply assignment x variables MAID. realization
probability n (z) product
Q probabilities decisions agent n
assignment x, product kN k (z) realization probabilities simply joint
probabilityPof assignment.
expected payoff agent n receive strategy
Q
profile , zZ Gn (z) kN k (z), therefore expectation Gn (z). expectation
respect distribution P defined Bayesian network B whose structure
MAID, decision node CPDs determined .
entries V G strictly expected payoffs, however. Equation (8)
rewritten
Q
X Gn (z)
kN k (z)
G
Vh,h0 () =
.
(14)
n (z)n0 (z)
zZh,h0

expectation quantity Gn (z)/[n (z)n0 (z)]. payoff Gn (z) sum agent
ns utility nodes. Due linearity expectation, perform computation separately
agent ns utility nodes, simply add separate contributions.
therefore restrict attention computing contribution single utility
node Un agent n. Furthermore, value n (z) depends values
set nodes n consisting ns decision nodes parents. Thus, instead
computing probabilities assignments variables, need compute
marginal joint distribution Un , n , n0 . distribution,
compute contribution Un expectation Equation (14) every pair terminal
sequences belonging agents n n0 .
482

fiA Continuation Method Nash Equilibria Structured Games

P1

P2

P3

E1

E2

C1

C2

B1

C3

B2

R1

L2

P1 E1
B1 B2

E1 P2
B1 B2

P2 E2
B2 B3

E2 P3
B2 B3

B3

R2

L3

(a)

(b)

Figure 6: (a) two-stage road MAID three agents shown divided cliques.
four cliques surrounded dashed line, three decision nodes
chance node. (b) resultant clique tree.

7.2.3 Using Bayesian Network Inference
analysis reduces required computations significantly. Rather computing
separate expectation every pair sequences h, h0 , might first seemed
necessary, need compute one marginal joint distribution variables {Un }
n n0 every pair agents n, n0 . marginal joint distribution one defined
Bayesian network B . Naively, computation requires execute Bayesian
network inference |N |2 times: ordered pair agents n, n0 . fact,
exploit structure MAID perform computation much efficiently.
basis method standard clique tree algorithm Lauritzen Spiegelhalter
(1998). clique tree algorithm fairly complex, detailed presentation outside
scope paper. choose treat algorithm black box, describing
properties relevant understanding used within
computation. note details suffice allow method implemented
using one many off-the-shelf implementations clique tree algorithm. reader
wishing understand clique tree algorithm derivation detail referred
reference Cowell et al. (1999) complete description.
clique tree Bayesian network B data structure defined undirected
tree set nodes C. node Ci C corresponds subset variables
B, typically called clique. clique tree satisfies certain important properties.
must family preserving: node X B, exists clique Ci C
(X PaX ) Ci . satisfies separation requirement: C2 lies unique path
C1 C3 , then, joint distribution defined B, variables C1 must
conditionally independent C3 given C2 .
division 3-agent road MAID cliques shown Figure 7.2.3(a).
MAID 4 cliques. Notice every family contained clique (including families
chance nodes utility nodes). clique tree MAID shown Figure 7.2.3(b).
483

fiBlum, Shelton, & Koller

clique maintains data structure called potential, table entry
joint assignment variables clique. table sort generally called
factor. Inference algorithms typically use two basic operations factors: factor product,
factor marginalization. F G two factors (possibly overlapping) sets
variables X , respectively, define product FG new factor
X . entry FG particular assignment variables X
product entries F G corresponding restriction assignment X
, respectively. notion multiplication corresponds way conditional
probability distributions multiplied. marginalize, sum, variable X
factor F X way
Pwe would sum variable joint
probability distribution. result factor XP
F variables X\{X}.
entry particular assignment variables X F equal sum entries
F compatible assignment one value X.
factor entry every joint assignment variables, size
potential Ci exponential |Ci |. clique tree inference algorithm proceeds
passing messages, factors, one clique another tree. messages
used update potential receiving clique factor multiplication.
process messages sent directions edge tree,
tree said calibrated ; point, potential every clique Ci contains precisely
joint distribution variables Ci according B (for details, refer
reference Cowell et al., 1999).
use clique tree algorithm perform inference B . Consider final
decision node agent n. Due perfect recall assumption, ns previous decisions
parents parents decision node. family preservation
property therefore implies n fully contained clique. implies
family utility node contained clique. expectation Equation (14)
thus requires computation joint distribution three cliques tree: one
containing PaUn , one containing n , one containing n0 . need compute
joint distribution every pair agents n, n0 .
first key insight reduce problem one computing joint marginal distribution pairs cliques tree. Assume computed PB (Ci , Cj )
every pair cliques Ci , Cj . Now, consider triple cliques Ci , Cj , Ck . two
cases: either one cliques path two, not. first
case, assume without loss generality Cj path Ci Ck . case,
separation requirement, PB (Ci , Cj , Ck ) = PB (Ci , Cj )PB (Cj , Ck )/PB (Cj ).
second case, exists unique clique C lies path pair
cliques. Again, separation property, C renders cliques conditionally
independent, compute
PB (Ci , Cj , Ck ) =

X PB (Ci , C )PB (Cj , C )PB (Ck , C )
PB (C )2

C

.

(15)

Thus, reduced problem one computing marginals pairs
cliques calibrated clique-tree. use dynamic programming execute process
efficiently. construct table contains PB (Ci , Cj ) pair cliques Ci , Cj .
construct table order length path Ci Cj . base case Ci
484

fiA Continuation Method Nash Equilibria Structured Games

Cj adjacent tree. case, PB (Ci , Cj ) = PB (Ci )PB (Cj )/PB (Ci
Cj ). probability expressions numerator simply clique potentials
calibrated tree. denominator obtained marginalizing either two
cliques. fact, expression computed byproduct calibration process,
marginalization required. cliques Ci Cj adjacent, let Ck
node adjacent Cj path Ci Cj . clique Ck one step closer
Ci , so, construction, already computed P (Ci , Ck ). apply
separation property again:

PB (Ci , Cj ) =

X PB (Ci , Ck )PB (Ck , Cj )
PB (Ck )

Ck

.

(16)

7.2.4 Computational Complexity
Theorem 11. computation V G () performed time O(`2 d3 + u|N |d4 ),
` number cliques clique tree G, size largest clique
(the number entries potential), |N | number agents, u total
number utility nodes game.
Proof. cost calibrating clique tree B O(`d). cost computing
Equation (16) single pair cliques O(d3 ), must compute factor
variables three cliques summing out. must perform computation O(`2 )
times, pair cliques, total cost O(`2 d3 ). compute marginal
joint probabilities triples cliques PaUni , n , n0 every utility node Uni every
agent n0 n. u(|N | 1) triples. Computing factor
variables three cliques may first require computing factor variables four
cliques, cost O(d4 ). Given factor, computing expected value utility
node takes time O(d3 ), affect asymptotic running time. total cost
computing marginal joint probabilities expected utilities therefore O(u|N |d4 ),
total cost computing V G () O(`2 d3 + u|N |d4 ).

method, shown single iteration continuation method
accomplished time exponential induced width graph number
variables largest clique clique tree. induced width optimal clique
tree one smallest maximal clique called treewidth network.
Although finding optimal clique tree is, itself, NP-hard problem, good heuristic
algorithms known (Cowell et al., 1999). games interactions agents
highly structured (the road MAID, example), size largest clique
constant even number agents grows. case, complexity computing
Jacobian grows quadratically number cliques, hence number
agents. Note matrix adjoint operation takes time cubic m, least
|N |, single step along path actually cubic computational cost.
485

fiBlum, Shelton, & Koller

1800

400
cont
IPA+cont
VK

1600
1400

300

1200

250
seconds

seconds

cont
IPA+cont
VK

350

1000
800

200
150

600

100

400

50

200
0
0

20

40
60
# agents

80

0

100

10

15

(a)

20

25
30
# agents

35

40

45

(b)

4

7

x 10

0.01
Cumulative

6

0.009

Terminating run

0.008

5

0.007
seconds/iteration

# iterations

cont
cubic fit

4
3

0.006
0.005
0.004
0.003

2

0.002
1
0.001
0

10

15

20
# agents

0
5

25

(c)

10

15
20
# agents

25

(d)

Figure 7: Results 2-by-L road game rock-paper-scissors payoffs: (a) running time.
Results road game random payoffs: (b) running time; (c) number
iterations cont; (d) average time per iteration cont.

8. Results
performed run-time tests algorithms wide variety graphical games
MAIDs. Tests performed Intel Xeon processor running 3 GHz 2
GB RAM, although memory never taxed calculations.
8.1 Graphical Games
graphical games, compared two versions algorithm: cont, simple continuation method, IPA+cont, continuation method IPA initialization. tested
hybrid equilibrium refinement algorithm Vickrey Koller (2002) (VK hereafter)
486

fiA Continuation Method Nash Equilibria Structured Games

4

600

5
cont
IPA+cont
VK

500

Cumulative

4.5

Terminating run

4
3.5
# iterations

400
seconds

x 10

300

200

3
2.5
2
1.5
1

100

0.5
0

5

10

15

20

25
30
# agents

35

40

0

45

5

10

15

(a)

20
25
# agents

30

35

40

(b)
4

250

6

x 10

cont

Cumulative

IPA+cont

5

200

Terminating run

VK

# iterations

seconds

4
150

100

3

2
50

0

1

5

10

15

20
# agents

25

30

35

0

(c)

10

15

20
# agents

25

(d)

Figure 8: Results ring game random payoffs: (a) running time; (b) number
iterations cont. Results L-by-L grid game random payoffs: (c) running
time; (d) number iterations cont.

comparison, parameters used. VK algorithm returns
-equilibria; exact methods exist comparable own.
algorithms run two classes games defined Vickrey Koller (2002)
two additional classes. road game Example 3, denoting situation
agents must build land plots along road, played 2-by-L grid; agent three
actions, payoffs depend actions (grid) neighbors. Following VK,
ran algorithm road games additive rock-paper-scissors payoffs: agents
payoffs sum payoffs independent rock-paper-scissors games
neighbors. game is, fact, polymatrix game, hence easy solve using
methods. order test algorithms typical examples, experimented
487

fiBlum, Shelton, & Koller

road games entries payoff matrix agent chosen uniformly
random [0, 1]. experimented ring graph three actions per
agent random payoffs. Finally, order test games increasing treewidth,
experimented grid games random payoffs. defined manner
road games, except game graph L-by-L grid.
class games, chose set game sizes run on. each, selected
(randomly cases payoffs random) set 20 test games solve.
solved game using cont, IPA+cont, VK. cont, started different
random perturbation vector time recorded time number iterations
necessary reach first equilibrium. IPA+cont, started different initial
strategy profile IPA time recorded total time IPA cont reach
first equilibrium.
equilibria found algorithm error 1012 , essentially machine
precision. hybrid refinement algorithm VK found -equilibria average error
104 road games rock-paper-scissors payoffs, 0.01 road games grid
games random payoffs, 0.03 ring games random payoffs, although
equilibria error high 0.05 road games 0.1 ring games.
smaller games, algorithms always converged equilibrium. larger
games, cont IPA detected entered cycle terminated without finding
equilibrium. maintaining hash table support cells passed
already, cont IPA able detect entered support cell
second time. Although sure sign entered cycle, strong
indicator. potential cycles detected, algorithms restarted new
random initialization values. Note cycles execution cont never arise
algorithm stray path dictated theory GW, random
restarts reflect failure follow path accurately.
equilibrium eventually found, cumulative time random
restarts recorded. error bars running time graphs show variance due
number random restarts required, choices initialization values, and, random
games, choice game.
Random restarts required 29% games tested. average, 2.2 restarts
necessary games. Note figure skewed larger games,
occasionally required many restarts; largest games sometimes required 8 9 restarts.
large graphical games (10 random road games 8 random ring games), IPA
converge 10 restarts; cases record results IPA+cont. cont
always found equilibrium within 10 restarts. results shown Figures 7(a,b,c,d)
Figures 8(a,b,c).
random roads, plotted number iterations time per iteration
cont Figures 7(c,d). number iterations varies based game
perturbation vector chosen. However, time per iteration almost exactly cubic,
predicted. note that, IPA used quick-start, cont invariably converged
immediately (within second) time spent IPA algorithm.
road games, methods efficient smaller games, become costly. Due polymatrix nature rock-paper-scissors road games,
IPA+cont algorithm solves immediately Lemke-Howson algorithm,
488

fiA Continuation Method Nash Equilibria Structured Games

therefore significantly less expensive VK. random ring games, algorithms
efficient VK smaller games (up 2030 agents), IPA+cont performing considerably better cont. However, road games, running time
algorithms grows rapidly VK, larger games, become
impractical. Nevertheless, algorithms performed well games 45 agents
3 actions per agent, previously intractable exact algorithms.
L-by-L grid games, algorithm performed much better VK algorithm (see Figures 8(c,d)), without IPA quick-start. reflects fact running-time
complexity algorithms depend treewidth graph.

# equilibria

80
60
40
20
0
20
10

15

8
10

6
5

# players

4
2
# runs

Figure 9: number unique equilibria found function size game
number runs algorithm, averaged ten random ring games.

examined number equilibria found IPA+cont algorithm. ran
IPA+cont ring graphical game differing numbers agents. number
agents, fixed 10 random games, ran algorithm 10 times game, recorded
cumulative number unique equilibria found. average number equilibria found
10 games number agents plotted figure 9. small games (with
presumably small number equilibria), number equilibria found quickly saturated.
large games, almost linear increase number equilibria found
subsequent random restart, implying run algorithm produced new
set solutions.
8.2 MAIDs
previous computational method MAIDs (Koller & Milch, 2001) stopped strategic
relevance: SCC converted equivalent extensive-form game solved using
standard methods. algorithm takes advantage structure game already decomposed according strategic relevance. test cases therefore
selected relevance graphs consisting single strongly connected component.
489

fiBlum, Shelton, & Koller



NA

B

AB

NB

C

BC
(a)



B

C

(b)

Figure 10: (a) chain game (b) strategic relevance graph case three
agents (A, B, C).

order ascertain much difference enhancements made, compared
results MAID algorithm, MAID cont, achieved converting game
extensive-form running EF cont, extensive-form version cont specified
GW, Gambit (McKelvey, McLennan, & Turocy, 2004), standard game theory software
package. time required conversion extensive form included results.
ran algorithms two classes games, varying sizes. first,
refer chain game, alternates decision chance nodes (see Figure 10).
decision node belongs different agent. agent two utility nodes,
connected decision node neighbors (except end agents,
one utility node single neighbor). three actions decision node.
probability tables payoff matrices chosen uniformly random. second
class two-stage road building game Example 5, shown Figure 2(b).
class, chose payoffs carefully, hand, ensure non-trivial mixed strategy equilibria.
ran chain games sizes 2 21, road games sizes
2 9. size, randomly selected 20 perturbation vectors 20 games (all
20 road games same, since payoffs set hand, 20 chain games
payoffs randomly assigned). tested algorithms games, initialized
perturbation vectors, averaged across test cases. timing results appear
Figures 11(a,b). error bars reflect variance due choice game (in chain
games), choice perturbation vector, number random restarts required.
cases, graphical game tests, MAID cont failed find equilibrium, terminating early detected entered cycle. cases,
restarted new perturbation vector successfully terminated.
equilibrium eventually found, cumulative time random restarts
recorded. course test runs, two chain games required random restart.
size 7. algorithms failed frequently road games; spike
road games size 8 reflects fact games size required, average, 1.2
490

fiA Continuation Method Nash Equilibria Structured Games

200

900
cont
EF cont
gambit

180

800

160

cont
EF cont
gambit

700

140

600
seconds

seconds

120
100

500
400

80
300

60

200

40

100

20
0
2

4

6

8

10

12
14
# agents

16

18

20

0
2

22

3

4

5

(a)

6
# agents

7

8

9

7

8

9

(b)

1000

0.4
cont
cubic fit

900

0.35

800
0.3
seconds/iteration

# iterations

700
600
500
400

0.25
0.2
0.15

300
0.1
200
0.05

100
0
2

3

4

5

6
# agents

7

8

0
2

9

(c)

3

4

5

6
# agents

(d)

Figure 11: Results MAIDs: (a) Running times chain MAID. Results two-stage
road MAID: (b) running time; (c) number iterations; (d) time per iteration.

random restarts equilibrium found. Strangely, MAID cont much
successful road game size 9, succeeding without random restarts two
cases.
tested Gambit EF cont smaller games, time memory
requirements testing larger ones beyond means. results show that,
EF cont faster algorithm Gambit extensive-form games, inadequate
larger MAIDs able solve MAID cont. surprising;
road game size 9 26 decision chance nodes, equivalent extensive-form game
tree 226 67 million outcome nodes. MAIDs size, Bayesian network
inference techniques used become necessary.
491

fiBlum, Shelton, & Koller

MAIDs, realization probabilities constrained least 104 (i.e.,
found -perfect equilibria = 104 ). accuracy equilibria within 1012 ,
machine precision.
graphical games, recorded number iterations convergence well
time per iteration MAID cont. results appear Figures 11(c,d). time
per iteration fit well cubic curve, accordance theoretical predictions.
variance primarily due execution retraction operator, whose running time
depends number strategies support.

9. Discussion Conclusions
described two adaptations continuation method algorithms GW,
purpose accelerated execution structured games. results show
algorithms represent significant advances state art equilibrium computation
graphical games MAIDs.
9.1 Related Work Graphical Games
last years, several papers addressed issue finding equilibria structured games. graphical games, exact algorithms proposed far apply games
interaction structure undirected tree, agent two
possible actions. Kearns et al. (2001) provide exponential-time algorithm compute
exact equilibria game, Littman et al. (2002) provide polynomial-time
algorithm compute single exact equilibrium. limited set games,
algorithms may preferable own, since come running-time guarantees.
However, yet tested whether algorithms are, fact, efficient practice. Moreover, methods applicable fully general games, results indicate
perform well.
effort focused computation -equilibria general graphical
games. number algorithms recently proposed task.
use discretized space mixed strategies: probabilities must selected grid
simplex, made arbitrarily fine. computational reasons, however,
grid must typically quite coarse, number grid points consider grows
exponentially number actions per agent. methods (implicitly
explicitly) define equilibrium set constraints discretized strategy space,
use constraint solving method: Kearns et al. (2001) use tree-propagation
algorithm (KLS); Vickrey Koller (2002) use standard CSP variable elimination methods
(VK1); Ortiz Kearns (2003) use arc-consistency constraint propagation followed
search (OK). Vickrey Koller (2002) propose gradient ascent algorithm (VK2),
provide hybrid refinement method can, computation, reduce
equilibrium error.
exact methods, KLS algorithm restricted tree-structured games,
comes without experimental running time results (although guaranteed run
polynomial time). Kearns et al. (2001) give suggestion working non-tree graph
constructing junction tree passing messages therein. However, necessary
computations clear potentially expensive.
492

fiA Continuation Method Nash Equilibria Structured Games

VK1 algorithm applicable graphical games arbitrary topology,
number actions per agent. takes time exponential treewidth graph.
treewidth constant, scales linearly number agents; however,
results show quickly becomes infeasible treewidth expands (as grid
game).
methods come complexity guarantees, depend treewidth
graph. others (OK VK2, well algorithm) insensitive treewidth
single iteration takes time polynomial size game representation (and
hence exponential maximum degree graph). However, require
unknown number iterations converge. Corollary 7 shows that, general, computation
equilibria discretized strategies games fixed degree hard. Thus, lack
complexity guarantees methods surprising.
Nonetheless, experimental results OK seem promising indicate that,
average, relatively iterations required convergence. Results indicate OK
capable solving grid games least 100 agents (although cases
large 0.2, much better random fully mixed strategy profile). However,
running time results provided.
VK2 exhibits strong experimental results. Vickrey Koller (2002) successfully found -equilibria games 400 agents, errors 2% maximal
payoff.
main drawback algorithms compute -equilibria. equilibrium may sufficient certain applications: utility functions
approximate, agent certainly might satisfied -best response; make
assumption slightly costly agents change minds, agent might
need incentive greater deviate. However, -equilibria bring set
problems. primary one guarantee exact equilibrium
neighborhood -equilibrium. make difficult find -equilibria
small values ; attempts refine given -equilibrium may fail. lack nearby
Nash equilibrium implies certain instability. agent unsatisfied
-equilibrium, play may deviate quite far it. Finally, -equilibria numerous
Nash equilibria (uncountably so, general). exacerbates difficulty agent
faces choosing equilibrium play.
algorithms computing -equilibria frequently faster own, especially
approximations crude games 50 agents. However,
exact equilibria found algorithms satisfying solutions, results
show performance algorithm comparable approximate methods
cases. Surprisingly, many games, running time results show
fastest available, particularly case games large treewidth, grid
game test cases. Furthermore, since use approximate equilibrium
starting point algorithm, advances approximate methods complement
method. hybrid algorithm Vickrey Koller (2002) turns unsuited
purpose, tends remove pure strategies support,
interesting see whether methods (including listed above) might
effective. remains seen small must methods reliably refine
approximate equilibrium.
493

fiBlum, Shelton, & Koller

9.2 Related Work MAIDs
Koller Milch (2001) (KM) define notion dependence agents decisions
(s-relevance), provide algorithm decompose solve MAIDs based
fairly coarse independence structure. algorithm able exploit finer-grained
structure, resolving open problem left KM. general, method automatically exploit structure obtained decomposing game relevance
components, methods best regarded complement KM; decomposition according s-relevance, algorithm applied find equilibria
efficiently decomposed problems. Running time results indicate methods
significantly faster previous standard algorithms extensive-form games.
unsurprising, since game representation test cases exponentially larger
number players converted extensive-form.
Vickrey (2002) proposes approximate hill-climbing algorithm MAIDs takes
advantage sort fine-grained structure do: Bayesian network inference
employed calculate expected utility one component score function single
iteration. constraint-satisfaction approach proposed. However, proposals
never implemented, hard determine quality equilibria would find
quickly would find them.
La Mura (2000) proposes continuation method finding one equilibria
G net, representation similar MAIDs. proposal exploits
limited set structural properties (a strict subset exploited KM).
proposal never implemented, several issues regarding non-converging paths
seem unresolved.
algorithm therefore first able exploit finer-grained structure
MAID. Moreover, algorithm, applied conjunction decomposition method
KM, able take advantage full known independence structure MAID.
potential drawback requirement strategies -perturbed. However, decreasing
incurs additional computational cost, although limits imposed machine
precision. Perfect equilibria highly desirable refinement Nash equilibria, defined
limit sequence -perturbed equilibria goes zero therefore
computed effectively algorithm little additional computational cost.
sense, use perturbed strategies advantageous. implemented
local search algorithm find exact perfect equilibrium neighborhood found
-perturbed equilibrium, although straightforward so.
9.3 Conclusion Work
presented two related algorithms computing exact equilibria structured
games. algorithms based methods GW, perform key computational
steps methods much efficiently exploiting game structure. approach
yields first exact algorithm take advantage structure general graphical games
first algorithm take full advantage independence structure MAID.
algorithms capable computing exact equilibria games large numbers
agents, previously intractable exact methods.
494

fiA Continuation Method Nash Equilibria Structured Games

algorithms come without theoretical running time bounds, noticed certain interesting trends. graphical game MAID version algorithm,
iteration executes time polynomial number agents, examined
number iterations required convergence. adaptive step size technique decreases
number random restarts required find equilibrium, increases number
iterations required cross support cell larger games. adaptive step size
disabled, noticed number iterations required, averaged across games
random payoffs, seems grow approximately linearly. Intuitively, makes sense
number iterations least linear: starting pure strategy profile,
linear number actions (in number agents) must enter support order us
reach general strategy profile. support boundary requires least one iteration
algorithm. somewhat surprising, however, number iterations required
grow quickly. interesting open problem analyze number
iterations required convergence.
large games, tendency algorithm cycle increases. phenomenon
attributed, partially, cumulative effect wobbling: great number
wobbles, possible path altered sufficiently pass
equilibrium. noticed games seem intrinsically harder
others, requiring many random restarts convergence. large games,
overall running time algorithm therefore quite unpredictable.
algorithms might improved number ways. importantly, continuation method would profit greatly sophisticated path-following methods;
number cases, cont MAID cont failed find equilibrium strayed
far path. Better path-following techniques might greatly increase reliability
algorithms, particularly obviated need wobbles, negate GWs
theoretical guarantee convergence continuation method.
number theoretical questions algorithms GW
remain unresolved. Nothing known worst-case average-case running time
IPA, theoretical bounds exist number iterations required cont.
interesting speculate choice perturbation ray might affect execution
algorithm. algorithm directed toward particular equilibria interest
either careful selection perturbation ray change continuation
method? way selecting perturbation rays equilibria found?
way selecting perturbation ray speed execution time?
Several improvements might made MAID cont. adapted IPA use
MAIDs, possible so, making use generalized Lemke algorithm
Koller, Megiddo, von Stengel (1996) solve intermediate linearized MAIDs.
computation V G might accelerated using variant all-pairs clique tree
algorithm computes potentials pairs sepsets sets variables shared
adjacent cliques rather pairs cliques.
work suggests several interesting avenues research. fact,
initial publication results (Blum, Shelton, & Koller, 2003), least one
application techniques already developed: Bhat Leyton-Brown (2004)
shown adaptation cont used efficiently solve new class structured games called action-graph games (a generalization local effect games presented
495

fiBlum, Shelton, & Koller

Leyton-Brown & Tennenholtz, 2003). believe games, structured
representations, show great promise enablers new applications game theory.
several advantages unstructured counterparts: well-suited games
large number agents, determined fewer parameters, making feasible
human researchers fully specify meaningful way, built-in structure
makes intuitive medium frame structured, real-world scenarios.
However, avoid computational intractability general problem, new class
structured games requires new algorithm equilibrium computation. hypothesize
cont IPA excellent starting point addressing need.

Acknowledgments. work supported ONR MURI Grant N00014-00-1-0637,
Air Force contract F30602-00-2-0598 DARPAs TASK program. Special
thanks Robert Wilson, kindly taking time guide us details
work Srihari Govindan, David Vickrey, aiding us testing algorithms
alongside his. thank anonymous referees helpful comments.
496

fiA Continuation Method Nash Equilibria Structured Games

Appendix A. Table Notation
Notation games
N
set agents
n
strategy agent n
n
strategy space agent n

strategy profile

space strategy profiles
n
strategy profile restricted agents n
n
space strategy profiles agents n
(n , n ) strategy profile agent n plays strategy n agents act
according n
Gn ()
expected payoff agent n strategy profile
G
V ()
vector deviation function
R
retraction operator mapping points closest valid strategy profile
F
continuation method objective function

scale factor perturbation continuation method
w
free variable continuation method
Notation normal-form games

action agent n

set available actions agent n

action profile

set action profiles

action profile restricted agents n

space action profiles agents n
Notation extensive-form games
z
leaf node game tree (outcome)
Z
set outcomes

information set

set information sets agent n
A(i)
set actions available information set
Hn (y)
sequence (history) agent n determined node
Zh
set outcomes consistent sequence (history) h
b(a|i)
probability behavior profile b agent n choose action
n (z)
realization probability outcome z agent n
Notation graphical games
Famn
set agent n agent ns parents
f
n
strategy profiles agents Famn n
f

space action profiles agents Famn n
Notation MAIDs
Dni
decision node index belonging agent n
Uni
utility node index belonging agent n
PaX
parents node X
dom(S) joint domain variables set
497

fiBlum, Shelton, & Koller

C1

C2



C3


b


b

c

b
c

c

Figure 12: Reduction 3SAT instance (a b c) (a b c) (a b c)
graphical game.

Appendix B. Proof Theorem 6
Proof. proof reduction 3SAT. given 3SAT instance, construct
graphical game whose equilibria encode satisfying assignments variables.
Let C = {c1 , c2 , . . . , cm } clauses 3SAT instance question, let V =
{v1 , v1 , v2 , v2 , . . . , vn , vn } set literals. variable appears one clause,
immediately assigned satisfy clause; therefore, assume variables
appear least two clauses.
construct (undirected) graphical game. clause, ci , create
agent Ci connected Ci1 Ci+1 (except C1 Cm , one clause
neighbor). create agents Vi` literal ` ci (there 3). If,
example, ci clause (v1 v2 ), agents Viv1 Viv2 . connect
Ci . every variable v, group agents Viv Vjv connect line,
way connected clauses other. order unimportant.
Clause agents 5 neighbors (two clauses either side three
literals) literal agents 3 neighbors (two literals either side
one clause). completely specifies game topology. example, Figure 12 shows
graphical game corresponding 3SAT problem (abc)(abc)(abc).
define actions payoff structure. agent interpreted
Boolean variable, two actions, true false, correspond Boolean
values true false. Intuitively, clause Ci plays true, satisfied. agent
Viv plays true, v non-negated variable, v assigned true. Vjv
plays true, v assigned false.
payoff matrix clause agent Ci designed ensure one clause
unsatisfied, entire 3SAT instance marked unsatisfied. best expressed
pseudo-code, follows:
Ci
clause neighbors play false
1 playing false
payoff
0 playing true
else least one Ci literals plays true (Ci satisfied)
498

fiA Continuation Method Nash Equilibria Structured Games


payoff

2
2

playing false
playing true

else
(Ci unsatisfied)

1 playing false
payoff
0 playing true
end
payoff matrix literal agent Vi` designed encourage agreement
literals along line variable v(`) associated `. described
pseudo-code follows:
parent
clause Ci plays false
1 playing consistently false assignment v(`)
payoff
0 playing opposite
else Vi` sliteral neighbors play consistently single assignment v(`)
2 playing consistently neighbors
payoff
0 playing opposite
else

2 playing consistently false assignment v(`)
payoff
0 playing opposite
end
formula satisfying assignment, pure equilibrium
literal consistent assignment clauses play true; fact,
agents receive higher payoffs case equilibrium, satisfying
assignments correspond equilibria maximum social welfare.
parent clauses play false, clearly equilibrium non-negated literals
must play false negated literals must play true. trivial equilibrium.
remains show trivial equilibrium equilibrium unsatisfiable formulas, i.e. non-trivial equilibrium used construct satisfying assignment.
first prove two simple claims.
Claim 11.1. Nash equilibrium, either clauses play true probability one
clauses play false probability one.
Proof. case advantageous clause choose true false, neighbor
clause takes action false, fact disadvantageous so. Thus, clause
non-zero probability playing false equilibrium, neighbors, consequently
clauses, must play false probability one. Therefore, possible equilibria
clauses playing false clauses playing true.
follows immediately claim every non-trivial equilibrium clauses
playing true probability one.
Claim 11.2. non-trivial Nash equilibrium, line literals variable
v, literals play pure strategies must choose consistently single
assignment v.
499

fiBlum, Shelton, & Koller

Proof. Since equilibrium non-trivial, clauses play true. Suppose one
literals, V ` , employs pure strategy corresponding false assignment v. suffices
show fact literals line must pure strategies corresponding false
0
0
assignment v. Consider neighbor V ` V ` . Either V ` neighbors (one
V ` ) play consistently false assignment v, case V ` must play
consistently false assignment v, neighbors play inconsistently, case
0
else clause V ` payoff matrix applies V ` must, again, play consistently
false assignment v. may proceed way line manner.
literals line must therefore pure strategies consistent false assignment
v, contradicting literals.

Suppose non-trivial equilibrium. Claim 11.1, clauses must play
true probability 1. literals pure strategies, clear
equilibrium corresponds satisfying assignment: literals must consistent
assignment Claim 11.2, clauses must satisfied. subtleties arise
consider mixed strategy equilibria.
Note first clause, payoff choosing true choosing false case satisfying assignment literals, less case
unsatisfying assignment. Therefore, unsatisfying assignment non-zero
probability, clause must play false.
Consider single clause Ci , assumed choosing true equilibrium. mixed
strategies Ci literals induce distribution joint
Ci plays true,
W actions.
`
joint action non-zero probability must satisfy ` Vi . literal Vi` mixed
strategy, consider happen change strategy either one possible
pure strategies (true false). joint actions non-zero probability

ones remain subset originals, still satisfy
W removed,
` . Essentially, value ` affect satisfiability C , assigned
V

`
arbitrarily.
Thus, literal line certain variable mixed strategy, assign
variable either true false (and give literal line corresponding
pure strategy) without making clauses connected literals unsatisfied.
fact, literals line pure strategies consistent
other: indeed literals pure strategies, assign variable according
them. Claim 11.2, always case.

observe briefly constructed graphical game finite number
equilibria, even peculiarities 3SAT instance give rise equilibria mixed
strategies. clauses play false, one equilibrium. clauses play true,
remove graph trim payoff matrices literals
accordingly. line literals case generic graphical game, finite set
equilibria. equilibria original game must subset direct product
finite sets.
500

fiA Continuation Method Nash Equilibria Structured Games

References
Bhat, N. A. R., & Leyton-Brown, K. (2004). Computing Nash equilibria action-graph
games. Proceedings Twentieth International Conference Uncertainty
Artificial Intelligence.
Blum, B., Shelton, C., & Koller, D. (2003). continuation method Nash equilibria
structured games. Proceedings Eighteenth International Joint Conference
Artificial Intelligence, pp. 757764.
Chu, F., & Halpern, J. (2001). np-completeness finding optimal strategy
games common payoff. International Journal Game Theory, 30, 99106.
Codenotti, B., & Stefankovic, D. (2005). computational complexity nash equilibria
(0,1) bimatrix games. Information Processing Letters, 94, 145150.
Conitzer, V., & Sandholm, T. (2003). Complexity results Nash equilibria. Proceedings Eighteenth International Joint Conference Artificial Intelligence,
pp. 765771.
Cowell, R. G., Dawid, A. P., Lauritzen, S. L., & Spiegelhalter, D. J. (1999). Probabilistic
Networks Expert Systems. Springer-Verlag.
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.
Gilboa, I., & Zemel, E. (1989). Nash correlated equilibria: complexity considerations. Games Economic Behavior, 1, 8093.
Govindan, S., & Wilson, R. (2002). Structure theorems game trees. Proceedings
National Academy Sciences, 99 (13), 90779080.
Govindan, S., & Wilson, R. (2003). global Newton method compute Nash equilibria.
Journal Economic Theory, 110, 6586.
Govindan, S., & Wilson, R. (2004). Computing Nash equilibria iterated polymatrix
approximation. Journal Economic Dynamics Control, 28, 12291241.
Gul, F., Pearce, D., & Stachetti, E. (1993). bound proportion pure strategy
equilibria generic games. Mathematics Operations Research, 18, 548552.
Howard, R. A., & Matheson, J. E. (1984). Influence diagrams. Howard, R. A., & Matheson, J. E. (Eds.), Readings Principles Applications Decision Analysis,
Vol. 2, pp. 719762. Strategic Decision Group. article dated 1981.
Kearns, M., Littman, M. L., & Singh, S. (2001). Graphical models game theory.
Proceedings Seventeenth International Conference Uncertainty Artificial
Intelligence, pp. 253260.
Kohlberg, E., & Mertens, J.-F. (1986). strategic stability equilibria. Econometrica,
54 (5), 10031038.
Koller, D., & Megiddo, N. (1992). complexity two-person zero-sum games extensive
form. Games Economic Bahavior, 4, 528552.
Koller, D., Megiddo, N., & von Stengel, B. (1996). Efficient computation equilibria
extensive two-person games. Games Economic Behavior, 14, 247259.
501

fiBlum, Shelton, & Koller

Koller, D., & Milch, B. (2001). Multi-agent influence diagrams representing solving
games. Proceedings Seventeenth International Joint Conference Artificial
Intelligence, pp. 10271034.
Kuhn, H. W. (1953). Extensive games problem information. Contributions
Theory Games II, eds. H. W. Kuhn A. W. Tucker, Vol. 28, pp. 193216.
Princeton University Press, Princeton, NJ.
La Mura, P. (2000). Game networks. Proceedings Sixteenth International Conference Uncertainty Artificial Intelligence, pp. 335342.
Lauritzen, S. L., & Spiegelhalter, D. J. (1998). Local computations probabilities
graphical structures application expert systems. Journal Royal
Statistical Society, B 50 (2), 157224.
Lemke, C. E., & Howson, Jr., J. T. (1964). Equilibrium points bimatrix games. Journal
Society Applied Mathematics, 12 (2), 413423.
Leyton-Brown, K., & Tennenholtz, M. (2003). Local-effect games. Proceedings
Eighteenth International Joint Conference Artificial Intelligence, pp. 772777.
Littman, M. L., Kearns, M., & Singh, S. (2002). efficient exact algorithm singly
connected graphical games. Advances Neural Information Processing Systems
14, Vol. 2, pp. 817823.
McKelvey, R. D., & McLennan, A. (1996). Computation equilibria finite games.
Handbook Computational Economics, Vol. 1, pp. 87142. Elsevier Science.
McKelvey, R. D., McLennan, A. M., & Turocy, T. L. (2004). Gambit: Software tools
game theory, version 0.97.07.. http://econweb.tamu.edu/gambit.
Nash, J. (1951). Non-cooperative games. Annals Mathematics, 52 (2), 286295.
Nudelman, E., Wortman, J., Shoham, Y., & Leyton-Brown, K. (2004). Run GAMUT:
comprehensive approach evaluating game-theoretic algorithms. Third International Conference Autonomous Agents Multi-Agent Systems.
Ortiz, L. E., & Kearns, M. (2003). Nash propagation loopy graphical games. Advances
Neural Information Processing Systems 15, Vol. 1, pp. 793800.
Romanovskii, I. (1962). Reduction game complete memory matrix game.
Doklady Akademii Nauk, SSSR 144, 6264. [English translation: Soviet Mathematics
3, pages 678681].
Vickrey, D. (2002). Multiagent algorithms solving structured games. Undergraduate
honors thesis, Stanford University.
Vickrey, D., & Koller, D. (2002). Multi-agent algorithms solving graphical games.
Proceedings Eighteenth National Conference Artificial Intelligence (AAAI),
pp. 345351.
von Stengel, B. (1996). Efficient computation behavior strategies. Games Economic
Behavior, 14, 220246.
Watson, L. T. (2000). Theory globally convergent probability-one homotopies nonlinear programming. SIAM Journal Optimization, 11 (3), 761780.

502


