journal artificial intelligence

submitted published

finding approximate pomdp solutions belief
compression
nicholas roy

nickroy mit edu

massachusetts institute technology
computer science artificial intelligence laboratory
cambridge

geoffrey gordon

ggordon cs cmu edu

carnegie mellon university school computer science
pittsburgh pa

sebastian thrun

thrun stanford edu

stanford university computer science department
stanford ca

abstract
standard value function approaches finding policies partially observable markov
decision processes pomdps generally considered intractable large
intractability large extent consequence computing
exact optimal policy entire belief space however real world pomdp
computing optimal policy full belief space often unnecessary
good control even complicated policy classes beliefs experienced
controller often lie near structured low dimensional subspace embedded
high dimensional belief space finding good approximation optimal value function
subspace much easier computing full value function
introduce method solving large scale pomdps reducing dimensionality belief space use exponential family principal components analysis collins dasgupta schapire represent sparse high dimensional belief spaces
small sets learned features belief state plan terms
low dimensional belief features low dimensional space
policies pomdp orders magnitude larger
handled conventional techniques
demonstrate use synthetic mobile robot
navigation tasks

introduction
decision making one central artificial intelligence robotics
robots deployed world accomplish specific tasks real world
difficult place actactions serious consequences figure depicts
mobile robot pearl designed operate environment shown figure b
longwood retirement facility pittsburgh real world environments longwood
characterized uncertainty sensors cameras range finders noisy
entire world observable large number state estimation techniques
explicitly recognize impossibility correctly identifying true state world
gutmann burgard fox konolige olson gutmann fox kanazawa
c

ai access foundation rights reserved

firoy gordon thrun

koller russell isard blake probabilistic techniques track
location robot state estimators kalman filter leonard durrantwhyte markov localization fox burgard thrun thrun fox burgard
dellaert provide possibly factored boyen koller distribution
possible states world instead single possibly incorrect state estimate



figure

b

planner mobile robot pearl shown must able navigate
reliably real environments longwood oakmont retirement facility
shown b white areas map free space black pixels
obstacles grey areas regions map uncertainty notice
large open spaces many symmetries lead ambiguity robots
position map resolution per pixel

contrast controllers motion planners dialogue systems etc rarely model
notions uncertainty state estimate full probability distribution
controller often uses heuristic extract single best state distributions
mean mode planners compensate inevitable estimation errors robust control chen bagnell schneider deployed systems incorporate
full probabilistic state estimate although likely state method
simple used successfully real applications nourbakhsh powers
birchfield substantial control errors distribution possible
states uncertain single state estimate wrong planner likely choose
unreasonable action
figure illustrates difference conventional controllers model
uncertainty figure robot must navigate bottom right corner top
left limited range sensing noisy dead reckoning impoverished
purposes example sensing dead reckoning artificially poor
phenomenon would occur naturally larger scale environments



fifinding approximate pomdp solutions belief compression

sensor data cause robots state estimate become quite uncertain strays
far environmental structures use localize left figure
example trajectory motion planner knowledge uncertainty
state estimate mechanism taking uncertainty account robots
trajectory diverges desired path robot incorrectly believes arrived
goal shown state estimates reflect high uncertainty
robot position right figure b example trajectory controller
model positional uncertainty take action keep uncertainty small following
walls arrive reliably goal

goal

goal

measured path

measured path
true path
true path

start

start

conventional controller

figure

b robust controller

two possible trajectories navigation longwood oakmont environment robot limited range sensing poor dead reckoning
odometry trajectory conventional motion planner uses
single state estimate minimizes travel distance b trajectory
robust controller state uncertainty minimize travel
distance uncertainty

controller figure b derived representation called partially observable markov decision process pomdp pomdps technique making decisions
probabilistic estimates state world rather absolute knowledge
true state pomdp uses priori model world together history
actions taken observations received order infer probability distribution
belief possible states world controller chooses actions upon
current belief maximize reward expects receive time
advantage pomdps decision making resulting policies
handle uncertainty well pomdp process take advantage actions
implicitly reduce uncertainty even specification e g reward function
explicitly reward actions disadvantage pomdps finding
optimal policy computationally intractable existing techniques finding exact optimal


firoy gordon thrun

plans pomdps typically cannot handle hundred states
hauskrecht zhang zhang involving real physical
systems cannot expressed compactly would deploy robots plan
thousands possible states world e g map grid cells thousands possible
observations e g laser range measurements actions e g velocities
describe finding approximate solutions realworld pomdps arises insight exact pomdp policies use
unnecessarily complex high dimensional representations beliefs controller
expect experience finding low dimensional representations process
becomes much tractable
first describe low dimensional representations beliefs realworld pomdps use variant common dimensionality reduction technique
called principal components analysis particular variant use modifies loss
function pca order better model data probability distributions
low dimensional representations describe plan low dimensional space
conclude experimental robot control tasks

partially observable markov decision processes
partially observable markov decision process pomdp model deciding
act accessible stochastic environment known transition model russell
norvig pg pomdp described following









set states
set actions
set observations z z z z z
set transition probabilities si sj p sj si
set observation probabilities zi sj p zi sj
set rewards r r
discount factor
initial belief p

transition probabilities describe state evolves actions represent markov assumption next state depends current unobservable
state action independent preceding unobserved states actions
reward function describes objective control discount factor used
ensure reasonable behaviour face unlimited time optimal policy known
exist discounted case bounded immediate reward howard

pomdp policies often computed value function belief space
value function v b given policy defined long term expected reward
controller receive starting belief b executing policy horizon time
may infinite optimal pomdp policy maximizes value function
value function pomdp policy finite horizon described piecewise linear function space beliefs many compute value function
iteratively evaluating refining current value function estimate


fifinding approximate pomdp solutions belief compression

refinements improve expected reward policy belief figure
shows belief space three state belief space two dimensional
shaded simplex point simplex corresponds particular belief threedimensional vector corners simplex represent beliefs state
known certainty value function shown figure b gives long term
expected reward policy starting belief simplex























































belief space
figure













b value function

belief space three state two dimensional shaded
simplex b value function defined belief space purposes
visualization set beliefs constitutes belief space shown
projected onto xy plane b value function rises along
positive z axis point belief space corresponds specific
distribution value function point gives expected reward
policy starting belief belief space therefore value
function one fewer dimension total number states


process evaluating refining value function core solving
pomdps considered intractable value function defined space
beliefs continuous high dimensional belief space one fewer
dimension number states model navigation map
thousands possible states computing value function optimization
continuous space many thousands dimensions feasible existing

however careful consideration real world suggests possible
finding approximate value functions examine beliefs navigating mobile
robot encounters beliefs share common attributes beliefs typically
small number modes particular shape modes fairly generic modes
move change variance ways modes change relatively
constrained fact even real world navigation large belief spaces
beliefs degrees freedom
figure illustrates idea shows typical belief mobile robot might
experience navigating nursing home environment figure b visualize
distribution sample set poses called particles according distribution


firoy gordon thrun

plot particles map distribution unimodal probability mass
mostly concentrated small area figure b shows different kind belief
probability mass spread wide area multiple modes locations
particles bear little relationship map would difficult sequence
actions observations would belief

particles


common belief

figure

b unlikely belief

two example probability distributions robot pose small black dots
particles drawn distribution discrete grid positions left
distribution robots location relatively certain kind compact
unimodal distribution common robot navigation right
different implausible distribution right hand distribution sufficiently
unlikely afford ignore even unable distinguish
belief belief fail identify optimal action
quality controller unaffected

real world beliefs degrees freedom concentrated near
low dimensional subset high dimensional belief spacethat beliefs experienced
controller lie near structured low dimensional surface embedded belief
space surface representation belief state terms
small set bases features one benefit representation need
plan terms small set features finding value functions low dimensional
spaces typically easier finding value functions high dimensional spaces
two potential disadvantages sort representation first
contains approximation longer finding complete optimal pomdp policy
instead suggested figure trying representations belief
rich enough allow good control sufficiently parsimonious make


fifinding approximate pomdp solutions belief compression

tractable second disadvantage technical one
making nonlinear transformation belief space pomdp
assume convex value function longer work discuss detail
section
conventional
path planner

pomdp

tractable
robust

figure

intractable
robust

useful planner lies somewhere continuum mdp style
approximations full pomdp solution

dimensionality reduction
order low dimensional representation beliefs use statistical dimensionality reduction cox cox search projection
original high dimensional representation beliefs lower dimensional compact representation search low dimensional surface embedded
high dimensional belief space passes near sample beliefs consider
evolution beliefs pomdp trajectory inside belief space assumption trajectories large real world pomdps lie near low dimensional
surface embedded belief space figure depicts example low dimensional surface
embedded belief space three state pomdp described previous section


















figure













one dimensional surface black line embedded two dimensional belief space
gray triangle black dot represents single belief probability distribution
experienced controller beliefs lie near low dimensional surface

ideally dimensionality reduction involves information lossall aspects data
recovered equally well low dimensional representation highdimensional one practice though see use lossy representations
belief representations may allow original data beliefs
recovered without error still get good control see finding
representations probability distributions require careful trade


firoy gordon thrun

preserving important aspects distributions dimensions possible
measure quality representation penalizing reconstruction errors
loss function collins et al loss function provides quantitative way
measure errors representing data different loss functions different
low dimensional representations
principal components analysis
one common forms dimensionality reduction principal components analysis joliffe given set data pca finds linear lower dimensional representation data variance reconstructed data preserved intuitively
pca finds low dimensional hyperplane project data onto
hyperplane variance data changed little possible transformation
preserves variance seems appealing maximally preserve ability distinguish beliefs far apart euclidean norm see however
euclidean norm appropriate way measure distance beliefs
goal preserve ability choose good actions
first assume data set n beliefs b bn b belief bi
b high dimensional belief space write beliefs column vectors
matrix b b bn b r n use pca compute low dimensional
representation beliefs factoring b matrices u b
b u b



equation u r l corresponds matrix bases span low dimensional
space l dimensions b rnl represents data low dimensional space
geometric perspective u comprises set bases span hyperplane b
high dimensional space b b co ordinates data hyperplane
hyperplane dimensionality l exists contains data exactly pca surface given dimensionality best preserves variance data projecting
data onto hyperplane reconstructing minimizing change variance original data b reconstruction u b equivalent minimizing
sum squared error loss
l b u b kb u b k f



pca performance
figure shows toy use evaluate success pca finding
low dimensional representations abstract model two dimensional state space
one dimension position along one two circular corridors one binary variable
determines corridor states inclusive correspond one corridor
states correspond reward known position
different corridor therefore agent needs discover corridor move
many descriptions pca factorization u sv u v column orthonormal
diagonal could enforce similar constraint identifying b v case columns u
would orthonormal b would orthogonal



fifinding approximate pomdp solutions belief compression

appropriate position declare arrived goal goal declared
system resets regardless whether agent actually goal agent
actions left right sense corridor declare goal observation
transition probabilities given discretized von mises distributions mardia jupp
shatkay kaelbling exponential family distribution defined
von mises distribution wrapped analog gaussian accounts fact
two ends corridor connected sum two von mises variates
another von mises variate product two von mises likelihoods
scaled von mises likelihood guarantee true belief distribution
von mises distribution corridor action observation
instance consists states actions observations
actions move controller left right von mises noise action
returns observation uniquely correctly identifies half maze
agent top half bottom half observations returned actions
identify current state modulo probability observation von mises
distribution mean equal true state modulo observations
indicate approximately agent horizontally
max prob
obs


max prob
obs


max prob
obs



















reward









max prob
obs


observation top
action prob

reward

observation bottom
action prob



figure toy maze states

maze interesting relatively large pomdp standards states
contains particular kind uncertaintythe agent must use action point
uniquely identify half maze remaining actions observations
contain information corridor agent large
solved conventional pomdp value iteration structured heuristic
policies perform poorly
collected data set beliefs assessed performance pca beliefs
data collected hand coded controller alternating
random exploration actions mdp solution taking current state
maximum likelihood state belief figure shows sample beliefs data
set notice beliefs essentially two discretized von mises distributions
different weights one half maze starting belief state
left distribution figure equal probability top bottom corridors
position along corridor following discretized von mises distribution concentration
parameter meaning p state falls e maximum value move
way around corridor likely state


firoy gordon thrun

sample belief

sample belief














































state

probability




probability

probability

sample belief




















state










state

sample belief



probability








figure












state

sample beliefs toy sample set different noncontiguous points time left belief initial belief state

figure examines performance pca representing beliefs data set
computing average error original beliefs b reconstructions u b
figure see average squared error squared l compared number
bases figure b see average kullbach leibler kl divergence
kl divergence belief b reconstruction r u b low dimensional
representation b given
kl b k r


x

b si ln





b si
r si





minimizing squared l error explicit objective pca kl divergence
appropriate measure much two probability distributions differ
unfortunately pca performs poorly representing probability distributions despite
fact probability distributions collected data set degrees
freedom reconstruction error remains relatively high somewhere
basis functions examine reconstruction sample belief see
kinds errors pca making figure shows sample belief solid line
reconstruction dotted line notice reconstructed belief strange
artifacts contains ringing multiple small modes negative regions
pca purely geometric process notion original data probability
distributions therefore free generate reconstructions data contain
negative numbers sum
use popular implementation pca golub reinsche golub reinsch
available gnu scientific library galassi davies theiler gough jungman booth
rossi
note computing kl divergence reconstruction original belief
shift reconstruction non negative rescale sum



fifinding approximate pomdp solutions belief compression

average l error vs number bases

average kl divergence vs number bases




average kl divergence


average l error





















number bases







average squared l error
figure







number bases





b average kl divergence

average error original sample set b reconstructions u b
squared l error explicitly minimized pca b kl divergence
error bars represent standard deviation mean error
beliefs
example belief reconstruction


original belief
reconstructed belief



probability






















state

figure example belief reconstruction bases

notice pca process making significant errors lowprobability regions belief particularly unfortunate real world probability distributions tend characterized compact masses probability surrounded
large regions zero probability e g figure therefore need modify
pca ensure reconstructions probability distributions improve representation sparse probability distributions reducing errors made low probability
events
question answered loss functions available instead sum
squared errors equation would loss function better reflects
need represent probability distributions


firoy gordon thrun

exponential family pca
conventional view pca geometric one finding low dimensional projection
minimizes squared error loss alternate view probabilistic one
data consist samples drawn probability distribution pca
finding parameters generative distribution maximize likelihood
data squared error loss function corresponds assumption data
generated gaussian distribution collins et al demonstrated pca
generalized range loss functions modeling data different exponential
families probability distributions gaussian binomial poisson
exponential family distribution corresponds different loss function variant
pca collins et al refer generalization pca arbitrary exponential
family data likelihood exponential family pca e pca
e pca model represents reconstructed data low dimensional weight
vector b basis matrix u link function f
b f u b



e pca model uses different link function derived data
likelihood model corresponding error distribution loss function link
function mapping data space another space data
linearly represented
link function f mechanism e pca generalizes dimensionality reduction non linear example identity link function corresponds
gaussian errors reduces e pca regular pca sigmoid link function
corresponds bernoulli errors produces kind logistic pca valued data
nonlinear link functions correspond non gaussian exponential families
distributions
parameters e pca model maximizing log likelihood
data model shown collins et al equivalent
minimizing generalized bregman divergence
bf b k u b f u b b u b f b



low dimensional high dimensional representations solve
convex optimization techniques f convex function whose derivative f
f convex dual f ignore f purpose minimizing equation
since value b fixed relationship pca e pca link
functions reminiscent relationship linear regression generalized linear
mccullagh nelder
apply e pca belief compression need choose link function accurately reflects fact beliefs probability distributions choose link
function
f u b eu b

p u b
p
hard verify f u b
e f b b ln b b equation
becomes
x
x
bf b k u b
eu b b u b b ln b
b



fifinding approximate pomdp solutions belief compression

write b f u b equation becomes
bf b k u b b ln b b ln b

x

b

x

b u kl b k b

u kl unnormalized kl divergence thus choosing exponential link function corresponds minimizing unnormalized kl divergence original
belief reconstruction loss function intuitively reasonable choice measuring error reconstructing probability distribution exponential link function
corresponds poisson error model component reconstructed belief
choice loss link functions two advantages first exponential link
function constrains low dimensional representation eu b positive second error
model predicts variance belief component proportional expected
value since pca makes significant errors close wish increase penalty
errors small probabilities error model accomplishes
compute loss bi ignoring terms depend data b

l b u b

b
x



eu bi bi u bi



introduction link function raises question instead complex
machinery e pca could choose non linear function project data
space linear use conventional pca difficulty
course identifying function general good link functions e pca
related good nonlinear functions application regular pca
might appear reasonable use pca low dimensional representation log
beliefs rather use e pca exponential link function representation
beliefs directly performs poorly surface locally
well approximated log projection e pca viewed minimizing weighted
least squares chooses distance metric appropriately local conventional
pca log beliefs performs poorly situations beliefs contain extremely
small zero probability entries
p
chosen link function eu b eu b would arrived normalized kl divergence
perhaps even intuitively reasonable way measure error reconstructing
probability distribution complicated link function would made difficult
derive newton equations following impossible experimented
resulting found produces qualitatively similar described
normalized kl divergence one advantage allow us get away
one fewer basis function since unnormalized kl divergence e pca optimization
must learn basis explicitly represent normalization constant
e pca related lee seungs non negative matrix factorization one nmf loss
functions presented lee seung penalizes kl divergence matrix
reconstruction equation nmf loss incorporate link function
e pca loss another nmf loss function presented lee seung penalizes squared
error constrains factors nonnegative resulting model example gl
generalization e pca described gordon



firoy gordon thrun

finding e pca parameters
conventional pca guaranteed converge unique answer independent initialization general e pca property loss function
may multiple distinct local minima however finding best b given
b u convex convex optimization well studied unique global
solutions rockafellar similarly finding best u given b b
convex possible local minima joint space u b highly constrained
finding u b require solving general non convex optimization
gordon describes fast newtons method computing u b
summarize related iteratively reweighted least squares
popular generalized linear regression mccullagh nelder order
use newtons method minimize equation need derivative respect u
b

u b

l b u b
e

b u b

u
u
u
e u b b b b

e u b b b




u b


l b u b
e

b u b
b
b
b
u e u b u b


u e

u b

b





set right hand side equation zero iteratively compute bj
column b newtons method let us set q bj u e u bj bj linearize
bj roots q gives
j th

bjnew bj
bjnew bj



q bj
q bj

u e u bj bj
q bj




note equation formulation newtons method finding roots q typically
written
f xn
xn xn


f xn
need expression q
q
bj





u e u bj bj
bj

u e u bj
bj

u dj u






fifinding approximate pomdp solutions belief compression

define dj terms diag operator returns diagonal matrix



dj diag eu bj




b




diag b



b





combining equation equation get
u dj u bjnew bj u bj eu bj



u dj u bjnew u dj u bj u dj dj bj eu bj
u dj u bj dj bj eu bj




weighted least squares solved standard linear algebra
techniques order ensure solution numerically well conditioned typically
add regularizer divisor
bjnew

u dj u bj dj bj eu bj
u dj u il





il l l identity matrix similarly compute u computing ui
ith row u
ui b bi eui b di di b


uinew
bdi b il
e pca
automatically finding good low dimensional representation
b high dimensional belief set b given table optimization
iterated termination condition reached finite number iterations
minimum error achieved
steps raise one issue although solving row u column b
separately convex optimization solving two matrices simultaneously
therefore subject potential local minima experiments
expect need ways address local
minimum order scale even complicated domains
bases u found finding low dimensional representation highdimensional belief convex compute best answer iterating equation recovering full dimensional belief b low dimensional representation b
straightforward
x eu b

definition pca explicitly factor data u b many
presentations three part representation pca contains singular values


firoy gordon thrun

collect set sample beliefs high dimensional belief space
assemble samples data matrix b b b b
choose appropriate loss function l b u b
fix initial estimate b u randomly



column bj b
compute bjnew current u estimate equation




row ui u



compute uinew b estimate equation

l b u b

table

e pca finding low dimensional representation pomdp
including gordons newtons method

decomposition u b orthonormal use two part representation
b f u b quantity e pca decomposition corresponds
singular values pca u b general orthonormal
desired though possible orthonormalize u additional step optimization
conventional pca adjust b accordingly

e pca performance
loss function equation iterative optimization procedure described
equation equation low dimensional factorization look
well dimensionality reduction procedure performs pomdp examples
toy
recall figure unable good representations data
fewer bases even though domain knowledge indicated data
degrees freedom horizontal position mode along corridor concentration
mode probability top bottom corridor examining one
sample beliefs figure saw representation worst lowprobability regions take data set toy example use e pca
low dimensional representation compare performance pca e pca
figure shows e pca substantially efficient representing data
see kl divergence falling close bases additionally squared l
error bases need bases perfect reconstruction rather
since must include constant basis function small amount reconstruction


fifinding approximate pomdp solutions belief compression

error bases remains stopped optimization procedure fully
converged

average kl divergence vs number bases e pca

example belief reconstruction bases











probability

average kl divergence















number bases





reconstruction performance

probability

probability














state

e
e
e
e









state







c belief reconstruction near
peak

figure



example belief reconstruction bases
e
original belief
reconstructed belief
e

original belief
reconstructed belief





b example belief reconstruction

example belief reconstruction bases












original belief
reconstructed belief




state





belief reconstruction lowprobability region

average kl divergence original sample set reconstructions kl divergence bases error bars represent
standard deviation mean beliefs b example
belief figure reconstruction bases reconstruction
shows small errors peak mode shown reconstruction
bases original belief reconstruction indistinguishable naked eye c fine detail original belief
reconstruction two parts state space although reconstruction
perfect low probability area see error approximately




firoy gordon thrun

figure b shows e pca reconstruction example belief figure
see many artifacts present pca reconstruction absent
bases see e pca reconstruction already substantially better pca
bases although small errors peaks e g figure c
two modes bases e pca reconstruction indistinguishable naked eye
original belief kind accuracy bases typical
data set
robot beliefs
although performance e pca finding good representations abstract
compelling would ideally able use real world
robot navigation figure figures two
robot navigation performed physically realistic simulation although
artificially limited sensing dead reckoning collected sample set beliefs
moving robot around environment heuristic controller computed
low dimensional belief space b according table full state space
discretized resolution per pixel total states
figure shows sample belief figure b reconstruction bases
figure c see average reconstruction performance e pca
measured average kl divergence sample belief reconstruction
comparison performance pca e pca plotted e pca error falls
bases suggesting bases sufficient good reconstruction
substantial reduction allowing us represent beliefs
parameters rather parameters notice many states lie regions
outside map states never receive probability mass
removed removing states would trivial operation e pca correctly
able automatically
figure similar shown different environment sample set
beliefs collected heuristic controller low dimensional belief space
b computed e pca full state space resolution
per pixel example belief shown figure reconstruction
bases shown figure b reconstruction performance measured
average kl divergence shown figure c error falls close around
bases minimal improvement thereafter

computing pomdp policies
exponential family principal components analysis model gives us way
low dimensional representation beliefs occur particular
two real world navigation tried proved effective
finding low dimensional representations showing reductions states
states bases dimensional belief space allow much
tractable computation value function able solve much
larger pomdps could solved previously


fifinding approximate pomdp solutions belief compression

kl divergence sampled beliefs reconstructions

particles form
bimodal distribution



e pca
pca



kl divergence



original belief


























number bases

c reconstruction performance

b reconstruction

figure

sample belief robot navigation task b reconstruction
belief learned e pca representation bases c average
kl divergence sample beliefs reconstructions
number bases used notice e pca error falls close bases
whereas conventional pca much worse reconstruction error even bases
improving rapidly

kl divergence sampled beliefs reconstructions


kl divergence









sample belief

figure

b reconstruction










number bases

c average
performance







reconstruction

sample belief navigation longwood cf figure b
reconstruction learned e pca representation bases c
average kl divergence sample beliefs reconstructions
number bases used

unfortunately longer use conventional pomdp value iteration
optimal policy given low dimensional set belief space features pomdp value iteration depends fact value function convex belief space


firoy gordon thrun

compute non linear transformation beliefs recover coordinates
low dimensional belief surface lose convexity value function compare figure figure see value function cannot expressed
supremum set hyperplanes low dimensional belief space
instead pomdp value iteration build low dimensional discrete
belief space mdp use mdp value iteration since know form
value function turn function approximation gordon proved
fitted value iteration guaranteed bounded error approximation
possibly discounted mdps value function long use combination
function approximator averager averagers function approximators
non expansions max norm exaggerate errors training data
experiments use regular grids well irregular variable resolution grids
nearest neighbour discretization represented set low dimensional beliefs
b
b b b b b

approximations averagers averagers include linear interpolation knearest neighbours local weighted averaging focus detail exact
mechanism discretizing low dimensional space outside scope
resolution regular grid cases chosen empirically section
describe specific variable resolution discretization scheme worked well empirically
reader consult munos moore zhou hansen
sophisticated representations
fitted value iteration uses following update rule compute step
lookahead value function v step lookahead value function v


b
x
v bi max r bi
bi bj v bj



j

r approximate reward transition functions dynamics
pomdp e pca finite set low dimensional belief samples
b function approximator note described
require discounting following sections describe
compute model parameters r
computing reward function
original reward function r represents immediate reward taking action
state cannot know given low dimensional high dimensional belief
immediate reward compute expected reward therefore
represent reward expected value immediate reward full model
current belief
r b eb r







x




r si b si



fifinding approximate pomdp solutions belief compression

equation requires us recover high dimensional belief b low dimensional
representation b shown equation
many reward function r effect giving low immediate
reward belief states high entropy many planner
driven towards beliefs centred high reward states low uncertainty
property intuitively desirable beliefs robot worry
immediate bad outcome
computing transition function
computing low dimensional transition function p bj bi simple
computing low dimensional reward function r need consider pairs lowdimensional beliefs bi bj original high dimensional belief space transition
prior belief bi posterior belief bj described bayes filter equation
bj z


x

sk bi sk



k

action selected z observation saw original pomdp
transition probability distribution original pomdp observation probability
distribution
equation describes deterministic transition conditioned upon prior belief
action observation transition posterior bj stochastic observation known transition bi bj occurs specific z
generated probability transition probability generating observation
z separate full transition process deterministic transition b
belief acting sensing stochastic transition b j full posterior
ba


x

sj bi sj



j

bj z ba



equations describe transitions high dimensional beliefs
original pomdp high dimensional transitions compute transitions low dimensional approximate belief space mdp figure depicts process
figure shows start low dimensional belief bi bi reconstruct
high dimensional belief b according equation apply action
observation z described equation equation belief
b b compress low dimensional representation b iterating
equation finally since b may member sample b low dimensional
belief states map b nearby bj b according function approximator
function approximator grid last step means replacing b
prototypical bj shares grid cell generally function approximator may
represent b combination several states putting weight w bj b bj
example approximator k nearest neighbour w bj b k closest k


firoy gordon thrun


bi


b


bj
lowdimensional

action


b

ba

b

highdimensional

observation
z

figure process computing single transition probability

samples b case replace transition bi b several transitions
bi bj scale probability one w bj b
transition bi b ba b b bj assign probability
p z j

p z ba w bj b



w bj b


x

p z sl ba sl



l

total transition probability bi bj sum observations z p z j
step table performs computation shares work computation
bi bj different posterior beliefs bj reachable prior belief
bi action
computing value function
reward transition functions computed previous sections use
value iteration compute value function belief space mdp full
given table

solving large pomdps
section present application finding policies large
pomdps
toy
first tested e pca belief features regular grid representation version
toy described earlier ensure needed small set belief
samples bi made goal region larger used coarser discretization
underlying state space states instead allow us compute low dimensional
model quickly
figure shows comparison policies different e pca
approximately twice well maximum likelihood heuristic heuristic guesses
corridor correct half time amdp heuristic
augmented mdp reported roy thrun controller attempts


fifinding approximate pomdp solutions belief compression

generate discrete low dimensional belief space b e pca cf table
compute low dimensional reward function r
b b
recover b b
b compute r b

p

r si b si

compute low dimensional transition function
bi b
bj bi bj
b recover bi bi
c observation z


compute bj bayes filter equation b

e

compute b bj iterating equation

f

bj w bj b
add p z j equation bi bj

g

compute value function b

b bi b v bi
c


change

e

bi b


p b
v bi maxa r bi j bi bj v bj

change change v bi v bi
f change

table value iteration e pca pomdp

policy lowest entropy belief reaching goal
controller poorly unable distinguish unimodal belief
knows corridor position within corridor bimodal
belief knows position corridor figure averaged
trials
noted sufficiently small conventional pca fares
reasonably well next sections see pca representation
poorly compared e pca


firoy gordon thrun

average reward vs number bases


e pca
pca

average reward






mdp heuristic





amdp heuristic








number bases

figure

comparison policy performance different numbers bases
trials regular grid discretization policy performance given total
reward accumulated trials

robot navigation
tested e pca pomdp simulated robot navigation two
example environments wean hall corridor shown figure longwood retirement facility shown figure b model parameters given robot navigation
see fox et al
evaluated policy relatively simple depicted figure set
robots initial belief may one two locations corridor
objective get within goal state grid cell
controller received reward arriving goal state taking goal
action reward given incorrectly taking action non goal state
reward motion states used example
states along corridor actions forward backward motion
figure shows sample robot trajectory e pca policy basis functions
notice robot drives past goal lab door order verify orientation
returning goal robot know true position cannot know
fact passing goal robot started end corridor
orientation would become apparent way goal
figure shows average policy performance three different techniques
maximum likelihood heuristic could distinguish orientations therefore approximately time declared goal wrong place evaluated policy
learned best bases conventional pca policy performed substantially
better maximum likelihood heuristic controller incorrectly declare robot arrived goal however representation could detect
robot goal chose sub optimal respect e pca
policy motion actions regularly e pca outperformed techniques example able model belief accurately contrast figure
pca sufficient representation perform well better e pca


fifinding approximate pomdp solutions belief compression

true position

goal state
final estimated
position

true start state

figure

goal position

start position

example robot trajectory policy learned basis functions
left start conditions goal right robot
trajectory notice robot drives past goal lab door localize
returning goal

policy perfomance mobile robot navigation


average reward















figure

ml heuristic

pca

e pca

comparison policy performance e pca conventional pca
maximum likelihood heuristic trials

figure shows second example navigation simulation notice initial
belief bi modal good policy take actions disambiguate
modes proceeding goal sample set beliefs computed
low dimensional belief space b figure b shows average kl divergence
original reconstructed beliefs improvement kl divergence error measure
slowed substantially around bases therefore used bases represent belief
space
figure c shows example execution policy computed e pca
reward parameters previous navigation example robot
parameters maximum laser range high motion model variance first
action policy chose turn robot around move closer nearest wall
effect eliminating second distribution mode right robot
followed essentially coastal trajectory left hand wall order stay localized
although uncertainty direction became relatively pronounced see
uncertainty eventually resolved top image robot moved
goal


firoy gordon thrun

kl divergence sampled beliefs reconstructions



true hidden start


kl divergence

goal








start distribution modes

initial distribution










number bases







b reconstruction performance

positional accuracy goal


distance goal metres













c complete trajectory

figure






e pca

amdp

mdp

policy performance

sample navigation longwood cf figure
involves multi modal distributions c average kl divergence
sample beliefs reconstructions number bases used
samples beliefs navigating mobile robot environment comparison policy performance e pca conventional mdp amdp
heuristic

interesting note policy contains similar coastal attribute
heuristic policies e g entropy heuristic amdp cassandra kaelbling
kurien roy thrun however unlike heuristics e pca representation able reach goal accurately get closer goal
representation successful able accurately represent beliefs
effects actions beliefs


fifinding approximate pomdp solutions belief compression

finding people

original belief

b reconstruction pca

c reconstruction e pca

figure

performance pca e pca sample belief map
grid cells resolution sample belief b pca reconstruction
bases c e pca reconstruction bases

addition synthetic robot navigation described
previous sections tested complicated pomdp
finding person object moving around environment
motivated nursebot domain residents experiencing cognitive decline
sometimes become disoriented start wander order make better use
health care providers time would use robot pearl figure
residents quickly assume person adversarial
state space much larger previous robot navigation cross product persons position robots position however
assume simplicity robots position known therefore belief distribution persons position transitions person state feature
modelled brownian motion fixed known velocity persons
motion random independent robot position person moving avoid
captured robot different transition model would required assume
position person unobservable robot close enough see
person robot line sight person maximum range usually
metres observation model false negatives false positives reward
function maximal person robot location


firoy gordon thrun

figure shows example probability distribution occur
shown robots position grey dots particles drawn distribution
person could environment distribution initially uniform
reachable areas inside black walls robot receives sensor data
probability mass extinguished within sensor range robot robot
moves around probability mass extinguished focusing distribution
remaining places person however probability distribution starts
recover mass places robot visits leaves particle filter
visualized particles leaking areas previously emptied
collected set belief samples heuristic controller given driving
robot maximum likelihood location person used e pca good
low dimensional representation beliefs figure b shows reconstruction
example belief figure conventional pca bases figure
reinforce idea pca performs poorly representing probability distributions figure c shows reconstruction e pca bases qualitatively better
representation original belief
recall section use function approximator representing value
function preceding examples used regular grid low dimensional surface
performed well finding good policies however finding people empirically requires finer resolution representation would computationally tractable
regular grid therefore turn different function approximator nearestneighbour variable resolution representation add low dimensional belief states
model periodically evaluating model grid cell splitting gridcell smaller discrete cells statistic predicted model disagrees
statistic computed experience number different statistics suggested
testing model data real world munos moore
reduction reward variance value function disagreement opted instead
simpler criterion transition probability disagreement examine policy computed
fixed representation policy computed incrementally refined
representation note fully explored effect different variable resolution representations value function e g k nearest neighbour interpolations
described hauskrecht experiments beyond scope
focus utility e pca decomposition variable resolution
representation value function shown scale effectively beyond tens
dimensions best munos moore
shares many attributes robot navigation see
figure figures generates spatial distributions higher
complexity somewhat surprising e pca able good representation
beliefs bases indeed average kl divergence generally higher
robot navigation task regardless able good controllers
example pca performs poorly even large number
bases
figure shows example trajectory heuristic control strategy driving
robot maximum likelihood location person time step open circle
robot position starting far right solid black circle position


fifinding approximate pomdp solutions belief compression

figure



b

c



e

f

example suboptimal person finding policy grey particles drawn
distribution person might initially uniformly distributed black dot true unobservable position person
open circle observable position robot robots poor
action selection person able escape previously explored areas

person unobservable robot within range person starts
room corridor moves corridor robot
moved far end corridor b robot returns search inside room c
person moves unobserved previously searched corridor e although
deliberately chosen example heuristic performs poorly person
following unlikely adversarial trajectory times solid black circle remains
regions high probability robots belief accurately reflects possibility
person slip past heuristic control way take possibility
account
policy found low dimensional belief space described previous
sections able much better controller sample trajectory controller


firoy gordon thrun

figure



b

c



e

f

policy computed e pca representation initial conditions
panel figure notice unlike previous figure
strategy ensures probability mass located one place allowing
robot person significantly higher probability

shown figure robot travels right position corridor
part way corridor b returns explore room c
example persons starting position different one given
previous examplethe e pca policy would person point starting
initial conditions previous example exploring room eliminating
possibility person inside room e policy reduced possible
locations person left hand end corridor able
person reliably location
note figures target person worst case start position
planner person start position figure figure
policy would found person panel similarly person started


fifinding approximate pomdp solutions belief compression

end corridor figure policy shown figure would found
person panel b
performance different policies

average actions person








fully observable policy




figure

closest

densest

mdp

pca

e pca refined e pca

comparison policies person finding simple environment
baseline fully observable e cheating solution solid line epca policy fixed variable resolution discretization refined e pca
discretization additional belief samples added pca
policy approximately times worse best e pca policy

figure shows quantitative comparison performance e pca
number heuristic controllers simulation comparing average time
person different controllers solid line depicts baseline performance
controller access true state person times e fully
observable lower bound best possible performance travel time case
solely function distance person searching necessary performed
course realizable controller reality controllers
closest robot driven nearest state non zero probability
densest robot driven location probability mass
visible
mdp robot driven maximum likelihood state
pca controller found pca representation fixed discretization
low dimensional surface
e pca e pca controller fixed discretization low dimensional surface
compute value function
refined e pca e pca controller incrementally refined variable resolution
discretization surface computing value function
performance best e pca controller surprisingly close theoretical best
performance terms time person demonstrates need
careful choice discretization belief space computing value function


firoy gordon thrun

initial variable resolution representation proved poor function approximator however iteratively refined variable resolution discretization able improve
performance substantially controller conventional pca representation
case computed fixed discretization low dimensional representation
bases grid points quality belief representation pca poor
investigate complex policy approximators

discussion
experiments demonstrate e pca scale finding low dimensional surfaces embedded high dimensional spaces
time complexity
iterative therefore simple expression total running time
available data set b samples dimensionality n computing surface size
l iteration b nl b l nl step newtons
dominated set matrix multiplies final step inverting l l
matrix l u step consists b iterations iteration nl
multiplies l inversion v step consists n iterations iteration
b l multiplies l inversion leading total complexity given
figure shows time compute e pca bases sample beliefs
states implementation used java colt ghz athlon
cpu ram shown computation times conventional pca
decomposition small state space e pca decomposition faster
pca small number bases implementation pca computes
full decomposition l n l reduced dimensionality n full
dimensionality
exponential family pca running time


time secs





conventional pca sec




figure









number bases





time compute e pca representations different discretizations
state space



fifinding approximate pomdp solutions belief compression

far dominant term running time time compute
e pca bases bases found low dimensional space
discretized running time required value iteration converge policy
described order ms
sample belief collection
example addressed used standard sample size
sample beliefs additionally used hand coded heuristic controllers sample beliefs
model practice found sample beliefs collected semi random controller sufficient example however may able improve overall
performance future iterating phases building
belief space representation e collecting beliefs generating low dimensional
representation computing good controller initial set beliefs
collected used build initial set bases corresponding policy continue
evaluate error representation e g k l divergence current belief
low dimensional representation initial representation learned
beliefs representation may fit beliefs detect situation
noticing representation poor job representing beliefs validation
techniques cross validation may useful determining enough beliefs
acquired
model selection
one open questions addressed far choosing appropriate
number bases representation unless specific information
true number degrees freedom belief space toy example
section difficult identify appropriate dimensionality underlying surface
control one common examine eigenvalues decomposition
recovered orthonormalization step table
assumes particular link function capable expressing surface
data lies eigenvalues conventional pca often used determine
appropriate dimensionality underlying surface certainly reconstruction
lossless use many bases non zero eigenvalues
unfortunately recall description e pca section generate
set singular values eigenvalues non linear projection introduced link
function causes eigenvalues u matrix uninformative contribution
basis representation instead eigenvalues choose appropriate
surface dimensionality use reconstruction quality figure reconstruction
quality estimate appropriate dimensionality common choice pca
dimensionality reduction techniques tenenbaum de silva langford one
alternate choice would evaluate reward policies computed different dimensionalities choose compact representation achieves highest reward
essentially control error rather reconstruction quality determine dimensionality


firoy gordon thrun

recall discussion section dimensionality reduction
represent beliefs pomdps specific kind structure particular e pca
representation useful representing beliefs relatively sparse
small number degrees freedom however e pca unable good lowdimensional representations pomdp exhibit kind structure
beliefs cannot represented lying low dimensional hyperplane linked
full belief space via appropriate link function one additional
know priori whether specific pomdp appropriate structure unlikely
general technique determine usefulness e pca
take advantage model selection techniques determine whether e pca
usefully low dimensional representation specific pomdp example
kl divergence set sample beliefs reconstructions large even
large number bases may right structure

related work
many attempts made use reachability analysis constrain set beliefs
washington hauskrecht zhou hansen pineau gordon
thrun reachable set beliefs relatively small forward search
set perfectly reasonable policy computed beliefs course optimal although relatively rare real world able
enumerate reachable beliefs reachability analysis used
success heuristic guiding search methods especially focusing computation
finding function approximators washington hansen
still remains compute low dimensional representation given finite
set representative beliefs discretization belief space explored
number times regular grid discretization lovejoy regular variable
resolution approaches zhou hansen non regular variable resolution representations brafman hauskrecht vein state abstraction boutilier
poole explored take advantage factored state spaces particular
interest hansen feng perform state abstraction
absence prior factorization far however approaches fallen
victim curse dimensionality failed scale dozen
states
value directed pomdp compression poupart boutilier
dimensionality reduction technique closer spirit technique
computes low dimensional representation pomdp directly model
parameters r finding krylov subspace reward function belief
propagation krylov subspace vector matrix smallest subspace
contains vector closed multiplication matrix pomdps
authors use smallest subspace contains immediate reward vector closed
set linear functions defined state transitions observation model
major advantage optimizes correct criterion value directed
compression distinguish beliefs different value major
disadvantage krylov subspace constrained linear


fifinding approximate pomdp solutions belief compression

pca instead e pca realize much compression
poupart boutilier method take advantage regularities
transition matrices z reward function r unfortunately
seen beliefs unlikely lie low dimensional hyperplane reported
section indicate linear compression scale size wish
address
possibly promising approaches finding approximate value functions
point methods instead optimizing value function entire
belief space specific beliefs cheng described method backing
value function specific belief points procedure called point dynamic
programming pb dp pb dp steps interleaved standard backups
full value iteration zhang zhang improved method choosing witness
points backup belief points iteratively increasing number points
essential idea point backups significantly cheaper full backup steps
indeed described zhang zhang performs hansens exact
policy search method order magnitude small however need
periodic backups across full belief space still limits applicability
small abstract
recently pineau et al abandoned full value function backups
favour point backups point value iteration pbvi
backing discrete belief points backup operator polynomial instead
exponential value iteration even importantly complexity
value function remains constant pbvi uses fundamentally different finding
pomdp policies still remains constrained curse dimensionality large state
spaces however applied successfully least order magnitude
larger predecessors another example used make
large pomdps tractable
e pca possible technique non linear dimensionality reduction
exists large body work containing different techniques self organizing maps kohonen generative topographic mapping bishop svensen williams
stochastic neighbour embedding hinton roweis two successful
emerge recently isomap tenenbaum et al locally linear embedding roweis saul isomap extends pca methods non linear
surfaces geodesic distances distance metric data samples rather
euclidean distances locally linear embedding lle considered local alternative
global reduction isomap represents point weighted combination neighbours operates two phases computing weights k nearest
neighbours high dimensional point reconstructing data lowdimensional co ordinate frame weights however contain
explicit kind data e g probability distributions attempting
model one interesting line however may extend
different loss functions manner pca extended e pca


firoy gordon thrun

conclusion
partially observable markov decision processes considered intractable finding
good controllers real world domains particular best date
finding approximate value function full belief space scaled beyond
hundred states pineau et al however demonstrated real world
pomdps contain structured belief spaces finding structure
able solve pomdps order magnitude larger solved conventional
value iteration techniques additionally able solve different kinds pomdps
simple highly structured synthetic robot navigation
factored belief space relatively complicated probability distributions
used structure related principal components analysis
loss function specifically chosen representing probability distributions real
world pomdps able solve characterized sparse distributions
exponential family pca particularly effective compressing data
exist pomdp structure
dimensionality reduction technique work well however question
investigation related dimensionality reduction techniques e g isomap locallylinear embedding tenenbaum et al roweis saul hinton applied
number interesting possibilities extending order
improve efficiency increase domain applicability loss function
chose dimensionality reduction reconstruction error
l b u b e u b b u b



cf equation minimizing reconstruction error allow near optimal policies
learned however would ideally compact representation
minimizes control errors could possibly better approximated taking advantage
transition probability structure example dimensionality reduction minimizes
prediction errors would correspond loss function
l b u b e u b b u b kb n b n k



b n l n matrix first n column vectors b b n
l n matrix n column vectors v starting second vector
effect finding representation allows bt predicted bt
caveat b must arranged action plan address issue
future work
another shortcoming described work contains
assumption beliefs described low dimensional representation
however relatively easy construct example generates beliefs
lie two distinct low dimensional surfaces current formulation would make
apparent dimensionality beliefs appear much higher set beliefs sampled
one surface alone
work largely motivated finding better representations beliefs
solving large pomdps policy search methods meuleau


fifinding approximate pomdp solutions belief compression

peshkin kim kaelbling hierarchical methods pineau gordon thrun
b able solve large pomdps interesting note controllers
e pca representations often essentially independent policy complexity
strongly dependent belief complexity whereas policy search hierarchical
methods strongly dependent policy complexity largely independent belief
space complexity seems likely progress solving large pomdps general lie
combination approaches
e pca finds low dimensional representation b full belief space b
sampled data demonstrated reliance sampled data obstacle
real world furthermore sampled beliefs could asset
large generating tracking beliefs considerably easier
may however preferable try compute low dimensional representation
directly model parameters poupart boutilier use notion krylov
subspace subspace computed may correspond exactly
conventional pca seen instances pca poor job finding
low dimensional representations likely explanation real world beliefs
lie low dimensional planes instead curved surfaces
extremely useful would one finds subset belief space closed
transition observation function constrained planes

acknowledgements
thanks tom mitchell leslie kaelbling reid simmons drew bagnell aaron courville
mike montemerlo joelle pineau useful comments insight work nicholas
roy funded national science foundation itr grant iis geoffrey gordon funded afrl contract f c darpas mica program
afrl contract f darpas coabs program

references
bagnell j schneider j autonomous helicopter control reinforcement
learning policy search methods proceedings ieee international conference
robotics automation icra pp seoul south korea ieee press
bishop c svensen williams c gtm generative topographic mapping
neural computation
boutilier c poole computing optimal policies partially observable
markov decision processes compact representations proceedings th
national conference artificial intelligence aaai pp
boyen x koller tractable inference complex stochastic processes
proceedings th annual conference uncertainty ai uai pp
madison wisconsin
brafman r heuristic variable grid solution method pomdps kuipers
b k webber b eds proceedings th national conference artificial
intelligence aaai pp providence ri


firoy gordon thrun

cassandra r kaelbling l kurien j acting uncertainty discrete bayesian mobile robot navigation proceedings ieee rsj
international conference intelligent robots systems
chen b robust h control springer verlag
cheng h partially observable markov decision processes ph
thesis university british columbia vancouver canada
collins dasgupta schapire r generalization principal components
analysis exponential family dietterich g becker ghahramani z
eds advances neural information processing systems nips cambridge
mit press
cox cox multidimensional scaling chapman hall london
fox burgard w thrun markov localization mobile robots dynamic
environments journal artificial intelligence
galassi davies j theiler j gough b jungman g booth rossi
f
gnu scientific library reference manual rd edition edition
http www gnu org software gsl
golub g reinsch c singular value decomposition least squares solutions
numerische mathematik pp
gordon g stable function approximation dynamic programming prieditis
russell eds proceedings international conference machine
learning icml pp san francisco ca morgan kaufmann
gordon g generalized linear becker thrun obermayer k
eds advances neural information processing systems nips mit press
gutmann j burgard w fox konolige k experimental comparison
localization methods proceedings ieee rsj international conference
intelligent robots systems victoria canada
gutmann j fox experimental comparison localization methods
continued proceedings ieee rsj international conference intelligent
robots systems lausanne switzerland
hansen e feng z dynamic programming pomdps factored state
representation proceedings fifth international conference artificial
intelligence scheduling aips breckenridge co
hansen e solving pomdps searching policy space proceedings
th conference uncertainty artifical intelligence uai pp madison
wi
hauskrecht value function approximations partially observable markov
decision processes journal artificial intelligence
hinton g roweis stochastic neighbor embedding becker thrun
obermayer k eds advances neural information processing systems
nips mit press


fifinding approximate pomdp solutions belief compression

howard r dynamic programming markov processes mit
isard blake condensation conditional density propagation
visual tracking international journal computer vision
joliffe principal component analysis springer verlag
kanazawa k koller russell stochastic simulation dynamic
probabilistic networks proceedings th annual conference uncertainty
ai uai pp montreal canada
kohonen self organized formation topologically correct feature maps biological cybernetics
lee seung h learning parts objects non negative matrix
factorization nature
leonard j durrant whyte h mobile robot localization tracking geometric
beacons ieee transactions robotics automation
lovejoy w computationally feasible bounds partially observable markov
decison processes operations
mardia k v jupp p e directional statistics nd edition wiley chichester
ny
mccullagh p nelder j generalized linear nd edition chapman
hall london
meuleau n peshkin l kim k e kaelbling l p learning finite state controllers partially observable environments laskey k b prade h eds
proceedings fifteenth international conference uncertainty artificial intelligence pp stockholm sweden morgan kaufmann
munos r moore variable resolution discretization high accuracy solutions optimal control dean ed proceedings th international joint conference artificial intelligence ijcai pp stockholm
sweden morgan kaufmann
munos r moore variable resolution discretization optimal control machine learning
nourbakhsh powers r birchfield dervish office navigating robot
ai magazine
olson c f probabilistic self localization mobile robots ieee transactions
robotics automation
pineau j gordon g thrun point value iteration anytime
pomdps proceedings th international joint conference
artificial intelligence ijcai acapulco mexico
pineau j gordon g thrun b policy contingent abstraction robust robot
control meek c kjlruff u eds proceedings th annual conference
uncertainty artificial intelligence uai acapulco mexico


firoy gordon thrun

poupart p boutilier c value directed compression pomdps becker
thrun obermayer k eds advances neural information processing
systems nips vancouver canada mit press
rockafellar r convex analysis princeton university press jersey
roweis saul l nonlinear dimensionality reduction locally linear embedding science
roweis saul l k hinton g e global coordination local linear
dietterich g becker ghahramani z eds advances
neural information processing systems vol cambridge mit press
roy n thrun coastal navigation mobile robots solla todd
k leen muller k r eds advances neural processing systems nips
pp denver co mit press
russell norvig p artificial intelligence modern prentice hall
shatkay h kaelbling l p learning geometrically constrained hidden markov
robot navigation bridging geometrical topological gap journal ai

tenenbaum j b de silva v langford j c global geometric framework
nonlinear dimensionality reduction science
thrun fox burgard w dellaert f robust monte carlo localization
mobile robots artificial intelligence
washington r bi pomdp bounded incremental partially observable markovmodel proceedings th european conference ecp
zhang n l zhang w speeding convergence value iteration partially observable markov decision processes journal artificial intelligence

zhou r hansen e improved grid approximation
pomdps nebel b ed proceedings th international joint conference artificial intelligence ijcai pp seattle washington morgan
kaufmann




