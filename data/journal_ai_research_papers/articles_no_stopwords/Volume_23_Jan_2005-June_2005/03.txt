Journal Artificial Intelligence Research 23 (2005) 587-623

Submitted 7/04; published 5/05

Improved Search Algorithm
Optimal Multiple-Sequence Alignment
Stefan Schroedl

stefan.schroedl@gmx.de

848 14th St
San Francisco CA 94114
+1 (415) 522-1148

Abstract
Multiple sequence alignment (MSA) ubiquitous problem computational biology.
Although NP -hard find optimal solution arbitrary number sequences,
due importance problem researchers trying push limits exact
algorithms further. Since MSA cast classical path finding problem, attracting growing number AI researchers interested heuristic search algorithms
challenge actual practical relevance.
paper, first review two previous, complementary lines research. Based
Hirschbergs algorithm, Dynamic Programming needs O(kN k1 ) space store
search frontier nodes needed reconstruct solution path, k sequences
length N . Best first search, hand, advantage bounding search
space explored using heuristic. However, necessary maintain
explored nodes final solution order prevent search re-expanding
higher cost. Earlier approaches reduce Closed list either incompatible
pruning methods Open list, must retain least boundary Closed
list.
article, present algorithm attempts combining respective
advantages; uses heuristic pruning search space, reduces
maximum Open Closed size O(kN k1 ), Dynamic Programming.
underlying idea conduct series searches successively increasing upper bounds,
using DP ordering key Open priority queue. suitable choice
thresholds, practice, running time four times expected.
experiments show algorithm outperforms one currently
successful algorithms optimal multiple sequence alignments, Partial Expansion ,
time memory. Moreover, apply refined heuristic based optimal alignments
pairs sequences, larger subsets. idea new; however,
make practically relevant show equally important bound heuristic
computation appropriately, overhead obliterate possible gain.
Furthermore, discuss number improvements time space efficiency
regard practical implementations.
algorithm, used conjunction higher-dimensional heuristics, able calculate first time optimal alignment almost problems Reference 1
benchmark database BAliBASE .

1. Introduction: Multiple Sequence Alignment
multiple sequence alignment problem (MSA) computational biology consists aligning several sequences, e.g. related genes different organisms, order reveal simic
2005
AI Access Foundation. rights reserved.

fiSchroedl

larities differences across group. Either DNA directly compared,
underlying alphabet consists set {C,G,A,T} four standard nucleotide bases
cytosine, guanine, adenine thymine; compare proteins, case
comprises twenty amino acids.
Roughly speaking, try write sequences one
columns matching letters maximized; thereby gaps (denoted additional
letter ) may inserted either order shift remaining characters
better corresponding positions. Different letters column interpreted
caused point mutations course evolution substituted one amino
acid another one; gaps seen insertions deletions (since direction
change often known, collectively referred indels). Presumably,
alignment fewest mismatches indels constitutes biologically plausible
explanation.
host applications MSA within computational biology; e.g., determining evolutionary relationship species, detecting functionally active sites
tend preserved best across homologous sequences, predicting threedimensional protein structure.
Formally, one associates cost alignment tries find (mathematically)
optimal alignment, i.e., one minimum cost. designing cost function,
computational efficiency biological meaning taken account.
widely-used definition sum-of-pairs cost function. First, given symmetric
(|| + 1)2 matrix containing penalties (scores) substituting letter another one
(or gap). simplest case, could one mismatch zero match,
biologically relevant scores developed. Dayhoff, Schwartz, Orcutt
(1978) proposed model molecular evolution estimate exchange
probabilities amino acids different amounts evolutionary divergence; gives rise
so-called PAM matrices, PAM250 generally widely used; Jones,
Taylor, Thornton (1992) refined statistics based larger body experimental
data. Based substitution matrix, sum-of-pairs cost alignment defined
sum penalties letter pairs corresponding column positions.
pairwise alignment conveniently depicted path two opposite
corners two-dimensional grid (Needleman Wunsch, 1981): one sequence placed
horizontal axis left right, one vertical axis top
bottom. gap either string, path moves diagonally right; gap
vertical (horizontal) string represented horizontal (vertical) move right (down),
since letter consumed one strings. alignment graph directed
acyclic, (non-border) vertex incoming edges left, top, top-left
adjacent vertices, outgoing edges right, bottom, bottom-right vertices.
Pairwise alignment readily generalized simultaneous alignment multiple
sequences, considering higher-dimensional lattices. example, alignment three
sequences visualized path cube. Fig. 1 illustrates example strings
ABCB, BCD, DB. shows computation sum-of-pairs cost, hypothetical
substitution matrix. real example (problem 2trx BAliBASE , see Sec. 7.3) given
Fig. 2.
588

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

Alignment:

Substitution matrix:

B C _ B
_ B C _
_ _ _ B

B C _
0 2 4 2 3
B
1 3 3 3
C
2 2 3

1 3
_
0

Cost: 6+7+8+7+7 = 35

end



C

B

B



B



C

B

start

Figure 1: Fictitious alignment problem: Column representation, cost matrix, threedimensional visualization alignment path cube.

number improvements integrated sum-of-pairs cost, associating
weights sequences, using different substitution matrices sequences varying
evolutionary distance. major issue multiple sequence alignment algorithms
ability handle gaps. Gap penalties made dependent neighbor letters.
Moreover, found (Altschul, 1989) assigning fixed score indel
sometimes produce biologically plausible alignment. Since insertion
sequence x letters likely x separate insertions single letter, gap cost
functions introduced depend length gap. useful approximation
affine gap costs, distinguish opening extension gap charge
+ b x gap length x, appropriate b. Another frequently used modification
waive penalties gaps beginning end sequence.
Technically, order deal affine gap costs longer identify nodes
search graph lattice vertices, since cost associated edge depends
preceding edge path. Therefore, suitable store lattice edges priority
589

fiSchroedl

1thx
1grx
1erv
2trcP

_aeqpvlvyfwaswcgpcqlmsplinlaantysdrlkvvkleidpnpttvkkyk______vegvpal
__mqtvi__fgrsgcpysvrakdlaeklsnerdd_fqyqyvdiraegitkedlqqkagkpvetvp__
agdklvvvdfsatwcgpckmikpffhslsekysn_viflevdvddcqdvasece______vksmptf
_kvttivvniyedgvrgcdalnssleclaaeypm_vkfckira_sntgagdrfs______sdvlptl

1thx
1grx
1erv
2trcP

rlvkgeqildstegvis__kdkllsf_ldthln_________
qifvdqqhiggytdfaawvken_____lda____________
qffkkgqkvgefsgan___kek_____leatine__lv____
lvykggelisnfisvaeqfaedffaadvesflneygllper_

Figure 2: Alignment problem 2trx BAliBASE , computed algorithm settings
described Sec. 7.3.



B

C




g = 53

cost(_,C)=3
gap penalty = 4
g = 60

B


cost(A,_)=3
gap penalty = 4
g = 60

cost(A,C)=4
gap penalty = 0
g = 57



Figure 3: Example computing path costs affine gap function; substitution matrix
Fig. 1 gap opening penalty 4 used.

queue, let transition costs u v, v w sum-of-pairs substitution costs
using one character sequence gap, plus incurred gap penalties
v w followed u v. representation adopted program MSA (Gupta,
Kececioglu, & Schaeffer, 1995). Note state space representation grows
factor 2k . example successor costs calculated, cost matrix
Fig. 1 gap opening penalty 4, shown Fig. 3.
convenience terminology sequel still refer nodes dealing
search algorithm.
590

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

2. Overview
Wang Jiang (1994) shown optimal multiple sequence alignment problem
NP -hard; therefore, cannot hope achieve efficient algorithm arbitrary number
sequences. consequence, alignment tools widely used practice sacrifice
sound theoretical basis exact algorithms, heuristic nature (Chan, Wong, &
Chiu, 1992). wide variety techniques developed. Progressive methods build
alignment gradually, starting closest sequences successively adding
distant ones. Iterative strategies refine initial alignment sequence
improvement steps.
Despite limitation moderate number sequences, however, research
exact algorithms still going on, trying push practical boundaries further. still
form building block heuristic techniques, incorporating existing tools
could improve them. example, algorithm iteratively aligning two groups sequences
time could three more, better avoid local minima. Moreover,
theoretically important gold standard available evaluation comparison,
even problems.
Since MSA cast minimum-cost path finding problem, turns
amenable heuristic search algorithms developed AI community; actually
among currently best approaches. Therefore, many researchers area
often used puzzles games past study heuristic search algorithms, recently
rising interest MSA testbed practical relevance, e.g., (Korf, 1999;
Korf & Zhang, 2000; Yoshizumi, Miura, & Ishida, 2000; Zhou & Hansen, 2003b); study
led major improvements general search techniques.
pointed definition MSA problem given
one; competes attempts formalizing biological meaning, often
imprecise depends type question biologist investigator pursuing. E.g.,
paper concerned global alignment methods, find alignment
entire sequences. Local methods, contrast, geared towards finding maximally similar
partial sequences, possibly ignoring remainder.
next section, briefly review previous approaches, based dynamic programming incorporating lower upper bounds. Sec. 4, describe new algorithm
combines extends ideas, allows reduce storage Closed
nodes partially recomputing solution path end (Sec. 5). Moreover, turns
algorithms iterative deepening strategy transferred find good balance
computation improved heuristics main search (Sec. 6), issue
previously major obstacle practical application. Sec. 7 presents
experimental comparison Partial Expansion (Yoshizumi, Miura, & Ishida, 2000),
one currently successful approaches. solve two problems
Reference 1 widely used benchmark database BAliBASE (Thompson, Plewniak, &
Poch, 1999). best knowledge, achieved previously
exact algorithm.
591

fiSchroedl

3. Previous Work
number exact algorithms developed previously compute alignments
moderate number sequences. mostly constrained available
memory, required computation time, both. roughly
group two categories: based dynamic programming paradigm,
proceed primarily breadth-first fashion; best-first search, utilizing lower upper
bounds prune search space. recent research, including new algorithm
introduced Sec. 4, attempts beneficially combine approaches.
3.1 Dijkstras Algorithm Dynamic Programming
Dijkstra (1959) presented general algorithm finding shortest (resp. minimum cost)
path directed graph. uses priority queue (heap) store nodes v together
shortest found distance start node (i.e., top-left corner grid) v
(also called g-value v). Starting priority queue, step,
edge minimum g-value removed priority queue; expansion consists
generating successors (vertices right and/or below) reachable one step,
computing respective g-value adding edge cost previous g-value,
inserting turn priority queue case newly found distance smaller
previous g-value. time node expanded, g-value guaranteed
minimal path cost start node, g (v) = d(s, v). procedure runs
priority queue becomes empty, target node (the bottom-right corner grid)
reached; g-value constitutes optimal solution cost g (t) = d(s, t)
alignment problem. order trace back path corresponding cost, move
backwards start node choosing predecessors minimum cost. nodes either
stored fixed matrix structure corresponding grid, dynamically
generated; latter case, explicitly store node backtrack-pointer
optimal parent.
integer edge costs, priority queue implemented bucket array pointing
doubly linked lists (Dial, 1969), operations performed constant time
(To precise, DeleteMin-operation needs pointer runs different
g-values once; however, neglect comparison number expansions).
expand vertex, 2k 1 successor vertices generated, since
choice introducing gap sequence. Thus, Dijkstras algorithm solve
multiple sequence alignment problem O(2k N k ) time O(N k ) space k sequences
length N .
means reduce number nodes stored path reconstruction
associating counter node maintains number children whose
backtrack-pointer refers (Gupta et al., 1995). Since node expanded
once, number referring backtrack-pointers decrease, namely,
whenever cheaper path one children found. nodes reference count goes
zero, whether immediately expansion later loses child,
deleted good. way, keep nodes memory least one
descendant currently priority queue. Moreover, auxiliary data structures vertices
592

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

coordinates efficiently stored tries (prefix trees); equipped
reference counters well freed accordingly longer used edge.
complexity Dijkstras algorithm holds dynamic programming (DP);
differs former one scans nodes fixed order known
beforehand (hence, contrary name exploration scheme actually static).
exact order scan vary (e.g., row-wise column-wise), long compatible
topological ordering graph (e.g., two sequences cells left, top,
diagonally top-left explored prior cell). One particular ordering
antidiagonals, diagonals running upper-right lower-left. calculation
antidiagonal node merely amounts summing k coordinates.
Hirschberg (1975) noticed order determine cost optimal alignment g (t), would necessary store whole matrix; instead, proceeding
e.g. rows suffices keep track k time, deleting row soon
next one completed. reduces space requirement one dimension
O(N k ) O(kN k1 ). order recover solution path end, re-computation
lost cell values needed. Divide-and-conquer -strategy applies algorithm twice
half grid each, forward backward direction, meeting fixed
middle row. adding corresponding forward backward distances middle
row finding minimum, one cell lying optimal path recovered.
cell essentially splits problem two smaller subproblems, one upper left
corner it, one lower right corner; recursively solved
using method. two dimensions, computation time doubled,
overhead reduces even higher dimensions.
FastLSA algorithm (Davidson, 2001) refines Hirschbergs algorithm exploiting additionally available memory store one node optimal path,
thereby reducing number re-computations.
3.2 Algorithms Utilizing Bounds
Dijkstras algorithm dynamic programming viewed variants breadthfirst search, achieve best first search expand nodes v order estimate
(lower bound) total cost path passing v. Rather using
g-value Dijkstras algorithm, use f (v) := g(v) + h(v) heap key,
h(v) lower bound cost optimal path v t. h indeed admissible,
first solution found guaranteed optimal (Hart, Nilsson, & Raphael, 1968).
classical best-first search algorithm, algorithm, well known artificial
intelligence community. context, priority queue maintaining generated nodes
often called Open list, nodes already expanded
removed constitute Closed list. Fig. 4 schematically depicts snapshot
two-dimensional alignment problem, nodes f -value larger current
fmin expanded. Since accuracy heuristic decreases distance
goal, typical onion-shaped distribution results, bulk located closer
start node, tapering towards higher levels.
algorithm significantly reduce total number expanded generated
nodes; therefore, higher dimensions clearly superior dynamic programming. How593

fiSchroedl



ax
um


ia


er
et

Closed
Open
Possible back leak

Le

ls

(a
n

tid

ia
go

na
ls)

X

Start
X X
X
X
X
X

X
X
X
X
X
End

Figure 4: Snapshot best-first search pairwise alignment (schematically).

ever, contrast Hirschberg algorithm, still stores explored nodes
Closed list. Apart keeping track solution path, necessary prevent
search leaking back, following sense.
heuristic h called consistent h(x) h(x0 )+c(x, x0 ), node x child x0 .
consistent heuristic ensures (as case Dijkstras algorithm) time node
expanded, g-value optimal, hence never expanded again. However, try
delete Closed nodes, topologically smaller nodes Open
higher f -value; expanded later stage, lead re-generation
node non-optimal g-value, since first instantiation longer available
duplicate checking. Fig. 4, nodes might subject spurious re-expansion
marked X.
Researchers tried avoid leaks, retaining basic search scheme.
Korf proposed store list forbidden operators node, place parents
deleted node Open f -value infinity (Korf, 1999; Korf & Zhang, 2000). However,
Zhou Hansen (2003a) remark, hard combine algorithm techniques
reduction Open list, moreover storage operators lets size
nodes grow exponentially number sequences. algorithm, keep
track kernel Closed list, defined set nodes
Closed nodes parents; otherwise Closed node said boundary. key
idea boundary nodes maintained, since shield kernel
re-expansions. algorithm gets close memory limit nodes
kernel deleted; backtrack pointer children changed parents
594

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

deleted nodes, become relay nodes them. final reconstruction
optimal solution path, algorithm called recursively relay node bridge
gap missing edges.
addition Closed list, Open list grow rapidly sequence alignment
problems. Particularly, since original algorithm expansion node generates
children once, whose f -value larger optimal cost g (t) kept
heap end, waste much available space.
upper bound U optimal solution cost g (t) known, nodes v
f (v) > U pruned right away; idea used several articles (Spouge, 1989; Gupta
et al., 1995). One successful approaches Yoshizumi et al.s (2000) Partial
Expansion (PEA ). node stores additional value F , minimum
f -value yet ungenerated children. step, node minimum
F -value expanded, children f = F generated. algorithm
clearly generates nodes f value larger optimal cost, cannot
avoided altogether. However, overhead computation time considerable:
straightforward implementation, want maintain nodes constant size, generating
one edge requires determining f -values successors, interior node
eventually fully expanded computation time order square
number successors, grows O(2k ) number sequences k.
remedy, paper proposed relax condition generating children
f F + C, small C.
alternative general search strategy uses linear space iterative
deepening (IDA ) (Korf, 1985). basic algorithm conducts depth-first search
pre-determined threshold f -value. search, keeps track smallest
f -value generated successor larger threshold. solution found,
provides increased threshold used next search iteration.
Wah Shang (1995) suggested liberal schemes determining next threshold dynamically order minimize number recomputations. IDA efficient
tree structured search spaces. However, difficult detect duplicate expansions without additional memory; Therefore, unfortunately applicable lattice-structured
graphs sequence alignment problem due combinatorially explosive number
paths two given nodes.
different line research tries restrict search space breadth-first approaches incorporating bounds. Ukkonen (1985) presented algorithm pairwise
alignment problem particularly efficient similar sequences; computation time
scales O(dm), optimal solution cost. First consider problem deciding
whether solution exists whose cost less upper threshold U . restrict
evaluation DP matrix band diagonals minimum number
indels required reach diagonal, times minimum indel cost, exceed U .
general, starting minimum U value, successively double G test
returns solution; increase computation time due recomputations
bounded factor 2.
Another approach multiple sequence alignment make use lower bounds h
. key idea following: Since nodes f -value lower g (t)
expanded anyway order guarantee optimality, might well explore
595

fiSchroedl

reasonable order, Dijkstras algorithm DP, knew optimal
cost. Even slightly higher upper bounds still help pruning. Spouge (1989) proposed
bound DP vertices v g(v) + h(v) smaller upper bound g (t).
Linear Bounded Diagonal Alignment (LBD-Align) (Davidson, 2001) uses upper
bound order reduce computation time memory solving pairwise alignment
problem dynamic programming. algorithm calculates DP matrix one antidiagonal time, starting top left corner, working towards bottom-right.
would check bound every expansion, LBD-Align checks
top bottom cell diagonal. e.g. top cell diagonal pruned,
remaining cells row pruned well, since reachable
it; means pruning frontier next row shifted one. Thus,
pruning overhead reduced quadratic linear amount terms
sequence length.
3.3 Obtaining Heuristic Bounds
assumed lower upper bounds, without specifying derive them.
Obtaining inaccurate upper bound g (t) fairly easy, since use cost
valid path lattice. Better estimates e.g. available heuristic linear-time
alignment programs FASTA BLAST (Altschul, Gish, Miller, Myers, & Lipman,
1990), standard method database searches. Davidson (2001) employed
local beam search scheme.
Gusfield (1993) proposed approximation called star-alignment.
sequences aligned, one consensus sequence chosen sum pairwise
alignment costs rest sequences minimal. Using best sequence
center, ones aligned using gap, always gap rule. Gusfield
showed cost optimal alignment greater equal cost star
alignment, divided (2 2/k).
use heuristic estimates, lower bounds k-alignment often based
optimal alignments subsets < k sequences. general, vertex v k-space,
looking lower bound path v target corner t. Consider first
case = 2. cost path is, definition, sum edge costs,
edge cost turn sum pairwise (replacement gap) penalties. multiple
sequence alignment induces pairwise alignment sequences j, simply copying
rows j ignoring columns rows. pairwise alignments
visualized projection alignment onto faces, cf. Fig. 1.
interchange summation order, sum-of-pairs cost sum pairwise
alignment costs respective paths projected face, cannot smaller
optimal pairwise path cost. Thus, construct admissible heuristic hpair
computing, pairwise alignment cell pairwise problem,
cheapest path cost goal node.
optimal solutions pairwise alignment problems needed lower bound h
values usually computed prior main search preprocessing step (Ikeda & Imai,
1994). end, suffices apply ordinary DP procedure; however, since time
interested lowest cost path v t, runs backward direction,
596

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

proceeding lower right corner upper left, expanding possible parents
vertex step.
Let U upper bound cost optimal multiple sequence alignment G.
sum optimal alignment costs Lij = d(sij , tij ) pairwise subproblems i, j
{1, . . . , k}, < j, call L, lower bound G. Carrillo Lipman (1988) pointed
additivity sum-of-pairs cost function, pairwise alignment induced
optimal multiple sequence alignment = U L larger
respective optimal pairwise alignment. bound used restrict number
values computed preprocessing stage stored
calculation heuristic: pair sequences i, j, nodes v feasible
path start node si,j goal node ti,j exists total cost
Li,j + . optimize storage requirements, combine results two
searches. First, forward pass determines relevant node v minimum distance
d(sij , v) start node. subsequent backward pass uses distance exact
heuristic stores distance d(v, tij ) target node nodes
d(sij , v) + d(v, tij ) d(s, t) + 1 .
Still, larger alignment problems required storage size extensive.
program MSA (Gupta et al., 1995) allows user adjust values CarrilloLipman bound individually pair sequences. makes possible generate
least heuristic alignments time memory doesnt allow complete solution;
moreover, recorded search -bound actually reached.
negative case, optimality found solution still guaranteed; otherwise, user
try run program slightly increased bounds.
general idea precomputing simplified problems storing solutions use
heuristic explored name pattern databases (Culberson & Schaeffer,
1998). However, approaches implicitly assume computational cost
amortized many search instances target. contrast, case MSA,
heuristics instance-specific, strike balance. discuss
greater depth Sec. 6.2.

4. Iterative-Deepening Dynamic Programming
seen, fixed search order dynamic programming several advantages pure best-first selection.
Since Closed nodes never reached search, safe
delete useless ones (those part shortest path current Open
1. slight technical complication arises affine gap costs: recall DP implementations usually charge
gap opening penalty g-value edge e starting gap, edge e0 ending gap
carries extra penalty all. However, since sum pairs heuristics h computed backward
direction, using algorithm would assign penalty path instead e0 .
means heuristic f = g + h would longer guaranteed lower bound, since
contains penalty twice. remedy, necessary make computation symmetric charging
beginning end gap half cost each. case beginning end
sequences handled conveniently starting search dummy diagonal edge
((1, . . . , 1), (0, . . . , 0)), defining target edge dummy diagonal edge ((N, . . . , N ), (N +
1, . . . , N + 1)), similar arrows shown Fig. 1.

597

fiSchroedl

nodes) apply path compression schemes, Hirschberg algorithm.
sophisticated schemes avoiding back leaks required, abovementioned methods core set maintenance dummy node insertion Open.
Besides size Closed list, memory requirement Open list determined maximum number nodes open simultaneously
time algorithm running. f -value used key
priority queue, Open list usually contains nodes f -values range
(fmin , fmin + ); set nodes generally spread across search space,
since g (and accordingly h = (f g)) vary arbitrarily 0 fmin + .
opposed that, DP proceeds along levels antidiagonals rows, iteration
k levels maintained time, hence size
Open list controlled effectively. Fig. 4, pairwise alignment partitioned antidiagonals: maximum number open nodes two adjacent
levels four, total amounts seventeen2 .
practical purposes, running time measured terms
number node expansions, one take account execution time
needed expansion. arranging exploration order edges
head node (or generally, sharing common coordinate prefix)
dealt one other, much computation cached, edge
generation sped significantly. come back point Sec. 6.
remaining issue static exploration scheme consists adequately bounding
search space using h-values. known minimal terms number node
expansions. knew cost g (t) cheapest solution path beforehand, could
simply proceed level level grid, however immediately prune generated edges
e whenever f (e) > g (t). would ensure generate edges would
generated algorithm , well. upper threshold would additionally help
reduce size Closed list, since node pruned children lie beyond
threshold; additionally, node child parent, give rise
propagating chain ancestor deletions.
propose apply search scheme carries series searches successively larger thresholds, solution found (or run memory patience).
use upper bound parallels IDA algorithm.
resulting algorithm, refer Iterative-Deepening Dynamic Programming (IDDP), sketched Fig. 5. outer loop initializes threshold
lower bound (e.g., h(s)), and, unless solution found, increases upper bound.
manner IDA algorithm, order make sure least one additional edge explored iteration threshold increased correspondingly
least minimum cost fringe edge exceeded previous threshold.
fringe increment maintained variable minNextThresh, initially estimated
upper bound, repeatedly decreased course following expansions.
2. Contrary figure might suggest, open two nodes per level pairwise
alignments, set nodes worse fmin contains holes.

598

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

procedure IDDP(Edge startEdge, Edge targetEdge, int lowerBound, int upperBound)
int thresh = lowerBound
{Outer loop: Iterative deepening phases}
(thresh upperBound)
Heap h = {(startEdge, 0)}
int minNextThresh = upperBound
{Inner loop: Bounded dynamic programming}
(not h.IsEmpty())
Edge e = h.DeleteMin() {Find remove edge minimum level}
(e == targetEdge)
{Optimal alignment found}
return TraceBackPath(startEdge, targetEdge)
end
Expand(e, thresh, minNextThresh)
end
int threshIncr = ComputeThreshIncr() {Compute search threshold next iteration, see text}
thresh = max(thresh + threshIncr, minNextThresh)
end
print(No alignment cost upperBound found)

Figure 5: Algorithm Iterative-Deepening Dynamic Programming.
step inner loop, select remove node priority queue
whose level minimal. explained later Sec. 6, favorable break ties according
lexicographic order target nodes. Since total number possible levels
comparatively small known advance, priority queue implemented using
array linked lists (Dial, 1969); provides constant time operations insertion
deletion.
expansion edge e partial (Fig. 6). child edge might already exist
earlier expansion edge head vertex; test decrease
g-value. Otherwise, generate new edge, temporarily sake calculating f -value; is, f -value exceeds search threshold current iteration,
memory immediately reclaimed. Moreover, case fringe threshold minNextThresh updated. practical implementation, prune unnecessary accesses
partial alignments inside calculation heuristic e.GetH() soon search
threshold already reached.
relaxation child edge within threshold performed subprocedure
UpdateEdge (cf. Fig. 7). similar corresponding relaxation step , updating
childs g- f values, parent pointers, inserting Open, already
contained. However, contrast best-first search, inserted heap according
antidiagonal level head vertex. Note event former parent loses
last child, propagation deletions (Fig. 8) ensure Closed nodes
continue stored belong solution path. Edge deletions ensue
deletion dependent vertex coordinate data structures (not shown pseudocode).
situation gives rise deletions immediately expansion
node children pointing back (the children might either reachable cheaply
different nodes, f -value might exceed threshold).
599

fiSchroedl

procedure Expand(Edge e, int thresh, int minNextThresh)
Edge child Succ(e)
{Retrieve child tentatively generate yet existing, set boolean variable created
accordingly}
int newG = e.GetG() + GapCost(e, child)
+ child.GetCost()
int newF = newG + child.GetH()
(newF thresh newG < child.GetG())
{Shorter path current best found, estimate within threshold}
child.SetG(newG)
UpdateEdge(e, child, h) {Update search structures}
else (newF > thresh)
minNextThresh =
min(minNextThresh, newF)
{Record minimum pruned edges}
(created)
Delete(child) {Make sure promising edges stored}
end
end
end
(e.ref == 0)
DeleteRec(e) {No promising children could inserted heap}
end

Figure 6: Edge expansion IDDP.
procedure UpdateEdge(Edge parent, Edge child, Heap h)
parent.ref++
child.GetBacktrack().ref
(child.GetBacktrack().ref == 0)
DeleteRec(child.GetBacktrack()) {The former parent lost last child becomes useless}
end
child.SetBacktrack(parent)
(not h.Contains(child))
h.Insert(child, child.GetHead().GetLevel())
end

Figure 7: Edge relaxation IDDP.

correctness algorithm shown analogously soundness proof .
threshold smaller g (t), DP search terminate without encountering
solution; otherwise, nodes pruned cannot part optimal path.
invariant holds always node level lies optimal path
Open list. Therefore, algorithm terminates heap runs empty,
best found solution indeed optimal.
iterative deepening strategy results overhead computation time due reexpansions, trying restrict overhead much possible. precisely,
600

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

procedure DeleteRec(Edge e)
(e.GetBacktrack() 6= nil)
e.GetBacktrack().ref
(e.GetBacktrack().ref == 0)
DeleteRec(e.GetBacktrack())
end
end
Delete(e)

Figure 8: Recursive deletion edges longer part solution path.
procedure TraceBack(Edge startEdge, Edge e)
(e == startEdge)
return {End recursion}
end
(e.GetBackTrack().GetTarget() 6= e.GetSource())
{Relay node: recursive path reconstruction}
IDDP( e.GetBackTrack(), e, e.GetF(), e.GetF())
end
OutputEdge(e)
TraceBack(startEdge, e.GetBackTrack())

Figure 9: Divide-and-Conquer solution reconstruction reverse order.
want minimize ratio
=

nIDDP
,
nA

nIDDP nA denote number expansions IDDP , respectively. One
way (Wah & Shang, 1995) choose threshold sequence 1 , 2 , . . .
number expansions ni stage satisfies
ni = rni1 ,
fixed ratio r. choose r small, number re-expansions hence
computation time grow rapidly, choose big, threshold
last iteration exceed optimal solution cost significantly, explore many
irrelevant edges. Suppose n0 rp < nA n0 rp+1 . algorithm performs p + 1
iterations. worst case, overshoot maximal finds optimal solution
previous threshold, nA = n0 rp + 1. total number expansions
P
r(r p+1 1)
r2

n0 p+1
, ratio becomes approximately r1
. setting
i=0 r = n0
r1
derivative expression zero, find optimal value r 2; number
expansions double one search stage next. achieve doubling,
expand four times many nodes .
Wah Shangs (1995) scheme, dynamically adjust threshold using runtime information. Procedure ComputeThreshIncr stores sequence expansion numbers
thresholds previous search stages, uses curve fitting extrapolation
(in first iterations without sufficient data available, small default threshold
applied). found distribution nodes n() f -value smaller equal
601

fiSchroedl

threshold modeled accurately according exponential approach
n() = B .
Consequently, order attempt double number expansions, choose next
threshold according
1
i+1 = +
.
log2 B

5. Sparse Representation Solution Paths
search progresses along antidiagonals, fear back leaks,
free prune Closed nodes. Similarly Zhou Hansens (2003a) work, however,
want delete lazily incrementally forced algorithm
approaching computers memory limit.
deleting edge e, backtrack-pointers child edges refer
redirected respective predecessor e, whose reference count increased accordingly.
resulting sparse solution path representation, backtrack pointers point
optimal ancestors.
termination main search, trace back pointers starting goal
edge; outlined Procedure TraceBack (Fig. 9), prints solution path
reverse order. Whenever edge e points back ancestor e0 direct
parent, apply auxiliary search start edge e0 goal edge e order reconstruct
missing links optimal solution path. search threshold fixed
known solution cost; moreover, auxiliary search prune edges cannot
ancestors e coordinate greater corresponding coordinate
e. Since shortest distance e e0 known, stop first path
found cost. improve efficiency auxiliary search even further,
heuristic could recomputed suit new target. Therefore, cost restoring
solution path usually marginal compared main search.
edges going prune, order? simplicity, assume
moment Closed list consists single solution path. According Hirschberg
approach, would keep one edge, preferably lying near center search
space (e.g., longest anti-diagonal), order minimize complexity two
auxiliary searches. additional available space allowing store three relay edges,
would divide search space four subspaces equal size (e.g., additionally
storing antidiagonals half-way middle antidiagonal start node resp.
target node). extension, order incrementally save space diminishing
resources would first keep every level, every fourth, on,
start edge, target edge, one edge half-way path would left.
Since general Closed list contains multiple solution paths (more precisely, tree
solution paths), would density relay edges
them. case k sequences, edge reaching level l head node originate
tail node level l 1, . . . , l k. Thus, every solution path passes
level, deleting every level could result leaving one path completely intact,
extinguishing another totally. Thus, better consider contiguous bands k
602

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

procedure SparsifyClosed()
(int sparse = 1 blog2 N c)
(UsedMemory() > maxMemory exists {Edge e Open | e.GetLastSparse() <
sparse})
Edge pred = e.GetBacktrack()
{Trace back solution path}
(pred 6= nil e.GetLastSparse() < sparse)
e.SetLastSparse(sparse) {Mark avoid repeated trace-back}
(bpred.GetHead().GetLevel() / kc mod 2sparse 6= 0)
{pred lies prunable band: redirect pointer}
e.SetBacktrack(pred.GetBacktrack())
e.GetBacktrack().ref++
pred.ref
(pred.ref == 0)
{e last remaining edge referring pred}
DeleteRec(pred)
end
else
{Not prunable band: continue traversal}
e = e.GetBacktrack()
end
pred = e.GetBacktrack()
end
end
end

Figure 10: Sparsification Closed list restricted memory.

levels each, instead individual levels. Bands size cannot skipped path.
total number antidiagonals alignment problem k sequences length N
k N 1; thus, decrease density blog2 N c steps.
technical implementation issue concerns ability enumerate edges reference given prunable edge, without explicitly storing list. However,
reference counting method described ensures Closed edge reached
following path bottom-up edge Open. procedure sketched Fig. 10.
variable sparse denotes interval level bands maintained
memory. inner loop, paths Open nodes traversed backward direction;
edge e0 falls prunable band, pointer successor e path
redirected respective backtrack pointer. e last edge referencing e0 ,
latter one deleted, path traversal continues start edge. Open
nodes visited memory bound still exceeded, outer loop tries
double number prunable bands increasing sparse.
Procedure SparsifyClosed called regularly search, e.g., expansion.
However, naive version described would incur huge overhead computation
time, particularly algorithms memory consumption close limit. Therefore, optimizations necessary. First, avoid tracing back solution path
(or lower) sparse interval recording edge interval
603

fiSchroedl

traversed last time (initially zero); increased variable sparse
anything left pruning. worst case, edge inspected blog2 N c
times. Secondly, would inefficient actually inspect Open node inner
loop, find solution path traversed previously, higher
sparse value; however, appropriate bookkeeping strategy possible reduce
time search overhead O(k).

6. Use Improved Heuristics
seen, estimator hpair , sum optimal pairwise goal distances, gives
lower bound actual path length. However, powerful heuristics
conceivable. computation require resources, trade-off prove
worthwhile; tighter estimator is, smaller space main search
needs explore.
6.1 Beyond Pairwise Alignments
Kobayashi Imai (1998) suggested generalize hpair considering optimal solutions
subproblems size > 2. proved following heuristics admissible
informed pairwise estimate.
hall,m sum m-dimensional optimal costs, divided

k2
m2 .

hone,m splits sequences two sets sizes k m; heuristic sum
optimal cost first subset, plus second one, plus sum
2-dimensional optimal costs pairs sequences different subsets. Usually,
chosen close k/2.
improved heuristics reduce main search effort orders magnitudes.
However, contrast pairwise sub-alignments, time space resources devoted compute store higher-dimensional heuristics general longer negligible compared
main search. Kobayashi Imai (1998) noticed even case = 3
triples sequences, impractical compute entire subheuristic hall,m . one
reduction, show suffices restrict oneself nodes path cost
exceed optimal path cost subproblem
!

=

X
k2
U
d(si1 ,...,im , ti1 ,...,im );
m2
,...,i
1



threshold seen generalization Carrillo-Lipman bound. However,
still
incur excessive overhead space computation time computation
k

lower-dimensional subproblems. drawback requires upper bound
U , whose accuracy algorithms efficiency hinges. could improve bound
applying sophisticated heuristic methods, seems counterintuitive spend
time would rather use calculate exact solution. spite
advantages main search, expensiveness heuristic calculation appears
major obstacle.
604

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

McNaughton, Lu, Schaeffer, Szafron (2002) suggested partition heuristic
(hyper-) cubes using hierarchical oct-tree data structure; contrast full cells,
empty cells retain values surface. main search tries use one
them, interior values recomputed demand. Still, work assumes
node entire heuristic calculated least using dynamic programming.
see one cause dilemma implicit assumption complete computation
necessary. bound refers worst-case, generally include many
nodes actually required main search. However, since dealing
heuristic, actually afford miss values occasionally; might
slow main search, cannot compromise optimality final solution.
Therefore, propose generate heuristics much smaller bound . Whenever
attempt retrieve value m-dimensional subheuristic
fails main

search, simply revert replacing sum 2 optimal pairwise goal distances
covers.
believe IDDP algorithm lends well make productive use higherdimensional heuristics. Firstly importantly, strategy searching adaptively
increasing thresholds transferred -bound well; addressed
detail next section.
Secondly, far practical implementation concerned, important take
account higher-dimensional heuristic affects number node expansions,
time complexity. time dominated number accesses subalignments. k sequences, worst case edge 2k 1 successors, leading
total
!
k
k
(2 1)

evaluations hall,m . One possible improvement enumerate edges emerging
given vertex lexicographic order, store partial sums heuristics prefix subsets
sequences later re-use. way, allow cache linear size, number
accesses reduced
!
i=k
X
i1
;
2
m1
i=m
correspondingly, quadratic cache need
i=k
X
i=m

!

2



i2
m2

evaluations. instance, aligning 12 sequences using hall,3 , linear cache reduces
evaluations 37 percent within one expansion.
mentioned above, contrast , IDDP gives us freedom choose
particular expansion order edges within given level. Therefore, sort edges
lexicographically according target nodes, much cached prefix information
shared additionally across consecutively expanded edges. higher dimension
subalignments, larger savings. experiments, experienced speedups
eighty percent heuristic evaluation.
605

fiSchroedl

Execution time [s]

100

Main search
Heuristic
Total time

10

1

0.1
0

10

20

30 40 50 60 70
Heuristic miss ratio r [%]

80

90

100

Figure 11: Trade-off heuristic main search: Execution times problem 1tvxA
function heuristic miss ratio.

6.2 Trade-Off Computation Heuristic Main Search
seen, control size precomputed sub-alignments choosing
bound f -values edges generated beyond respective optimal
solution cost. obviously trade-off auxiliary main searches.
instructive consider heuristic miss ratio r, i.e., fraction calculations
heuristic h main search requested entry partial MSA
precomputed. optimum main search achieved heuristic
computed every requested edge (r = 0). Going beyond point generate
unnecessarily large heuristic containing many entries never actually used.
hand, free allocate less effort heuristic, resulting r > 0
consequently decreasing performance main search. Generally, dependence
S-shaped form, exemplified Fig. 11 case problem 1tvxA BAliBASE
(cf. next section). Here, execution time one iteration main search fixed
threshold 45 lower bound shown, includes optimal solution.
Fig. 11 illustrates overall time trade-off auxiliary main search, fix
different levels. minimum total execution time, sum auxiliary
main search, attained r = 0.15 (5.86 seconds). plot corresponding
memory usage trade-off similar shape.
Unfortunately, general know advance right amount auxiliary search.
mentioned above, choosing according Carrillo-Lipman bound ensure
606

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

Execution time [s]

100

10

1

0.1
0

10

20

30

40
50
60
70
Heuristic miss ratio r [%]

80

90

100

Figure 12: Time last iteration main search problem 1tvxA function
heuristic miss ratio.

every requested sub-alignment cost precomputed; however, general
considerably overestimate necessary size heuristic.
remedy, algorithm IDDP gives us opportunity recompute heuristic
threshold iteration main search. way, adaptively strike balance
two.
currently experienced miss rate r rises threshold, suspend
current search, recompute pairwise alignments increased threshold ,
resume main search improved heuristics.
main search, accurately predict auxiliary computation time
space threshold using exponential fitting. Due lower dimensionality,
generally increase less steeply; however, constant factor might higher
k
heuristic, due combinatorial number
alignment problems solved.
doubling scheme explained bound overhead within constant
factor effort last iteration. way, limiting heuristic
computation time fixed fraction main search, ensure expected
upper bound overall execution time stays within constant factor search
time would required using pairwise heuristic.
knew exact relation , r, speedup main search, ideal
strategy would double heuristic whenever expected computation time smaller
time saved main search. However, illustrated Fig. 12, dependence
complex simple exponential growth, varies search depth specifics
problem. Either would need elaborate model search space,
607

fiSchroedl

algorithm would conduct exploratory searches order estimate relation.
leave issue future work, restrict simplified, conservative
heuristic: hypothesize main search made twice fast heuristic
doubling miss rate r rises 25 percent; experiments, found
assumption almost always true. event, since effective branching factor
main search reduced improved heuristic, ignore history main search
times exponential extrapolation procedure subsequent iterations.

7. Experimental Results
following, compare IDDP one currently successful approaches,
Partial Expansion . empirically explore benefit higher-dimensional heuristics;
finally, show feasibility means benchmark database BAliBASE .
7.1 Comparison Partial Expansion
first series evaluations, ran IDDP set sequences chosen
Yoshizumi et al. (2000) (elongation factors EF-TU EF-1 various species,
high degree similarity). work, substitution costs chosen according
PAM-250 matrix. applied heuristic sum optimal pairwise goal distances.
expansion numbers completely match results, however, since applied
biologically realistic affine gap costs: gaps length x charged 8+8x, except
beginning end sequence, penalty 8 x.
following experiments run RedHat Linux 7.3 Intel XeonT
CPU 3.06 GHz, main memory 2 Gigabytes; used gcc 2.96 compiler.
total space consumption search algorithm determined peak number
Open Closed edges entire running time. Table 1 Fig. 13 give values
series successively larger sets input sequences (with sequences numbered
defined Yoshizumi et al., 2000) 1 4, 1 5, . . ., 1 12.
implementation, basic algorithm could carried 9
sequences, exhausting computers main memory.
Confirming results Yoshizumi et al. (2000), Partial Expansion requires
one percent space. Interestingly, iteration peak total numbers
nodes held memory, nodes actually closed except problem 6. might
explained high degree similarity sequences example. Recall
PEA closes node successors f -value
optimal solution cost; span lower bound small, node least
one bad successor exceeds difference.
IDDP reduces memory requirements factor 6. diagram
shows maximum size Open list alone. sequences, difference
two dominated linear length store solution path.
problem size increases, however, proportion Closed list total memory drops
12 percent 12 sequences. total number expansions (including
search stages) slightly higher PEA ; however, due optimizations made possible
control expansion order, execution time 12 sequences reduced
third.
608

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

Num
Exp

Time
[sec]

Max
Open

Max
Open +
Closed

626
1599
3267
10781
116261
246955


0.01
0.05
0.25
1.94
49.32
318.58

7805
32178
124541
666098
9314734
35869671

8432
33778
127809
676880
9430996
36116627

3
4
5
6
7
8
9
10
11
12

448
716
2610
6304
23270
330946
780399
5453418
20887627
36078736

PEA
0.01
0.01
0.05
0.33
2.63
87.24
457.98
7203.17
62173.78
237640.14

442
626
1598
3328
10874
118277
249279
1569815
5620926
9265949

442
626
1598
3331
10874
118277
249279
1569815
5620926
9265949

3
4
5
6
7
8
9
10
11
12

496
1367
6776
12770
26026
362779
570898
4419297
21774869
36202456

IDDP
0.01
0.02
0.14
0.59
2.46
73.62
250.48
4101.96
43708.14
158987.80

4
9
171
414
889
13620
21506
160240
860880
1417151

434
443
501
972
1749
19512
30009
192395
997163
1616480

4
5
6
7
8
9

Table 1: Algorithm comparison varying number input sequences (elongation factors
EF-TU EF-1).

Since PEA prune edges, maximum space usage always total number
edges f -value smaller g (t) (call edges relevant edges, since
inspected admissible algorithm). IDDP, hand, Open list
comprise k adjacent levels edges (not counting possible threshold
overshoot, would contribute factor 2). Thus, improvement IDDP
PEA tend increase overall number levels (which sum
609

fiSchroedl

1e+08
1e+07

Edges memory

1e+06
100000
10000
1000
100
A* max open+closed
PEA* max open+closed
IDDP max open+closed
IDDP max open

10
1
3

4

5

6

7
8
9
Number sequences

10

11

12

Figure 13: Memory requirements , IDDP, PEA (elongation factors EF-TU
EF-1).

string lengths), divided number sequences; words, average
sequence length.
Moreover, ratio depends well heuristic suits particular problem.
Fig. 14 shows distribution edges f value smaller equal g (t),
case 9 example sequences. problem quite extreme bulk edges
concentrated small level band 1050 1150. example
even distribution, Fig. 15 depicts situation problem 1cpt Reference 1
benchmark set BAliBASE (Thompson et al., 1999) heuristic hall,3 . case,
proportion overall 19492675 relevant edges maximal among 4 adjacent
levels amounts 0.2 percent. maximum Open size IDDP 7196,
total number edges generated PEA 327259, improvement factor
45.
7.2 Multidimensional Heuristics
set sequences, compared different improved heuristics order get
impression respective potential. Specifically, ran IDDP heuristics hpair ,
hall,3 , hall,4 , hone,k/2 various thresholds . Fig. 16 shows total execution time
computing heuristics, performing main search. case, manually
selected value minimized time. seen times hone,k/2
lie little bit hpair ; sequences (less six), computation
heuristics hall,3 hall,4 dominates overall time. increasing dimensions, how610

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

0.016

Open edges / sum open edges [%]

0.014
0.012
0.01
0.008
0.006
0.004
0.002
0
0

500

1000

1500

2000
Level

2500

3000

3500

4000

Figure 14: Distribution relevant edges levels (elongation factors EF-TU EF-1);
compare schematic projection Fig. 4.

ever, investment starts yield growing returns, hall,3 fastest algorithm,
requiring 5 percent time hpair 12 sequences.
far memory concerned, Fig. 17 reveals maximum size Open
Closed list, chosen values, similar hpair hone,k/2 one hand,
hall,3 hall,4 hand.
12 sequences, hone,6 saves 60 percent edges, hall,3 needs 2.6
percent hall,4 0.4 percent space required pairwise heuristic. Using
IDDP, never ran main memory; even larger test sets could aligned, range
shown diagrams limited patience wait results two
days.
Based experienced burden computing heuristic, Kobayashi Imai (1998)
concluded hone,m preferred hall,m . quite agree judgment. see heuristic hall,m able reduce search space main search
considerably stronger hone,m , beneficial appropriate
amount heuristic computation.
7.3 Benchmark Database BAliBASE
BAliBASE (Thompson et al., 1999) widely used database manually-refined multiple
sequence alignments specifically designed evaluation comparison multiple sequence alignment programs. alignments classified 8 reference sets. Reference 1
contains alignments six equidistant sequences. sequences sim611

fiSchroedl

Open edges / sum open edges [%]

0.00012

0.0001

8e-05

6e-05

4e-05

2e-05

0
0

200

400

600

800
Level

1000

1200

1400

1600

Figure 15: Distribution relevant edges levels, problem 1cpt BAliBASE .
ilar length; grouped 9 classes, indexed sequence length percentage
identical amino acids columns. Note many problems indeed much harder elongation factor examples previous section; despite
consisting fewer sequences, dissimilarities much pronounced.
applied algorithm Reference 1, substitution costs according PET91
matrix (Jones et al., 1992) affine gap costs 9x+8, except leading trailing gaps,
gap opening penalty charged. instances, precomputed pairwise
sub-alignments fixed bound 300 optimal solution; optimal solution
found within bound cases, effort generally marginal compared
overall computation. problems involving three sequences, heuristic
hall,3 applied.
82 alignment problems Reference 1, algorithm could solve 2
problems (namely, 1pamA gal4 ) computer. Detailed results listed Tables 2
10.
Thompson, Plewniak, Poch (1999) compared number widely used heuristic
alignment tools using so-called SP -score; software calculates percentage
correctly aligned pairs within biologically significant motifs. found programs perform equally well sequences medium high amino acid
identity; differences occurred case distant sequences less
25 percent identity, so-called twilight zone. Particularly challenging
group short sequences. subgroup, three highest scoring programs PRRP,
CLUSTALX, SAGA, respective median scores 0.560, 0.687, 0.529.
medium score alignments found experiments amounts 0.558; hence,
good PRRP, beaten CLUSTALX. focused exper612

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

1e+06
100000
10000

Total time [sec]

1000
100
10
1
0.1
2-fold heuristic
div-conq heuristic
3-fold heuristic
4-fold heuristic

0.01
0.001
2

4

6

8
10
Number sequences

12

14

Figure 16: Comparison execution times (including calculation heuristics), elongation
factors EF-TU EF-1.

iments algorithmic feasibility rather solution quality, would worthwhile
attempt improve alignments found program using refined
penalty functions. CLUSTALX, example, uses different PAM matrices depending
evolutionary distance sequences; moreover, assigns weights sequences (based
phylogenetic tree), gap penalties made position-specific. improvements easily integrated basic sum-of-pairs cost function, could
attempt compute optimal alignment respect metrics. leave line
research future work.
Fig. 18 shows maximum number edges stored Open
search, dependence search threshold final iteration. better comparability,
included problems diagram consist 5 sequences. logarithmic
scale emphasizes growth fits exponential curve quite well. Roughly speaking,
increase cost threshold 50 leads ten-fold increase space requirements.
relation similarly applicable number expansions (Fig. 19).
Fig. 20 depicts proportion maximum Open list size combined
maximum size Open Closed. clearly visible due pruning edges
outside possible solution paths, Closed list contributes less less overall
space requirements difficult problems become.
Finally, estimate reduction size Open list compared relevant
edges ratio maximum Open size last iteration IDDP total
number expansions stage, equal number edges f -value
less equal threshold. Considering possible overshoot IDDP, algorithm PEA
613

fiSchroedl

Maximum size open + closed

1e+07

1e+06

100000

10000

1000

2-fold heuristic
div-conq heuristic
3-fold heuristic
4-fold heuristic

100
2

4

6

8
10
Number sequences

12

14

Figure 17: Combined maximum size Open Closed, different heuristics (elongation
factors EF-TU EF-1).

1e+07
1e+06

Max open

100000
10000
1000
100
10

Short
Medium length
Long

1
0

50

100
150
200
Threshold - Lower bound

250

300

Figure 18: Maximum size Open list, dependent final search threshold (BAliBASE ).

614

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

1e+08
1e+07

Expansions

1e+06
100000
10000
1000
100

Short
Medium length
Long

10
0

50

100
150
200
Threshold - Lower bound

250

300

Figure 19: Number expansions final search iteration (BAliBASE ).

80

Max open/ Max open + closed [%]

70
60
50
40
30
20
10

Short
Medium length
Long

0
0

50

100
150
200
Threshold - Lower bound

250

300

Figure 20: Maximum number Open edges, divided combined maximum Open
Closed (BAliBASE ).

615

fiSchroedl

5

Short
Medium length
Long

Max Open / Expansions [%]

4

3

2

1

0
0

50

100
150
200
Threshold - Lower bound

250

300

Figure 21: Percentage reduction Open size (BAliBASE ).
would expand least half nodes. proportion ranges 0.5 5 percent
(cf. Fig. 21). considerable scatter indicates dependence individual problem properties; however, slight average decrease noticed difficult problems.

616

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

8. Conclusion Discussion
presented new search algorithm optimal multiple sequence alignment
combines effective use heuristic bound best-first search ability
dynamic programming approach reduce maximum size Open Closed lists
one order magnitude sequence length. algorithm performs series
searches successively increasing bounds explore search space DP order;
thresholds chosen adaptively expected overhead recomputations
bounded constant factor.
demonstrated algorithm outperform one currently
successful algorithms optimal multiple sequence alignments, Partial Expansion ,
terms computation time memory consumption. Moreover, iterative-deepening
strategy alleviates use partially computed higher-dimensional heuristics. best
knowledge, algorithm first one able solve standard benchmark
alignment problems BAliBASE biologically realistic cost function including affine
gap costs without end gap penalties. quality alignment range
best heuristic programs; concentrated algorithmic feasibility, deem
worthwhile incorporate refined cost metrics better results; study
question future work.
Recently, learned related approaches developed simultaneously independently Zhou Hansen (2003b, 2004). SweepA explores search graph according
layers partial order, still uses f -value selecting nodes within one layer.
Breadth-First Heuristic Search implicitly defines layers graph uniform costs
according breadth-first traversal. algorithms incorporate upper bounds
optimal solution cost pruning; however, idea adaptive threshold determination
limit re-expansion overhead constant factor described. Moreover,
consider flexible use additional memory minimize divide-and-conquer solution
reconstruction phase.
Although described algorithm entirely within framework MSA problem,
straightforward transfer domain state space graph directed
acyclic. Natural candidates include applications ordering imposed
time space coordinates, e.g., finding likely path Markov model.
Two BAliBASE benchmark problems could still solved algorithm
within computers main memory limit. Future work include integration
techniques exploiting secondary memory. expect level-wise exploration scheme
algorithm lends naturally external search algorithms, another currently
active research topic Artificial Intelligence theoretical computer science.

Acknowledgments
author would thank reviewers article whose comments helped
significantly improving it.

617

fiSchroedl

Appendix

Table 2: Results BAliBASE Reference 1, group short sequences low amino acid
identity. columns denote: number aligned sequences; upper
bound precomputing optimal solutions partial problems last iteration
main search; g (t) optimal solution cost; h(s) lower bound solution cost,
using heuristics; #Exp total number expansions iterations main
search; #Op peak number edges Open list course search;
#Op+Cl peak combined number edges either Open Closed list
search; #Heu peak number subalignment edge costs stored heuristic;
Time: total running time including auxiliary main search, seconds; Mem
peak total memory usage face alignments, heuristic, main search,
KB.
1aboA
1idy
1r69
1tvxA
1ubi
1wit
2trx


5
5
4
4
4
5
4


57
50
20
44
30
69
20

g (t)
9006
8165
6215
5532
7395
14287
7918

h(s)
8898
8075
6183
5488
7357
14176
7899

#Exp
3413786
1732008
634844
1263849
1614286
6231378
63692

#Op
104613
74865
19938
24226
26315
209061
3502

#Op+Cl
176126
121404
41719
48633
54059
351582
5790

#Heu
1654547
970933
88802
476622
289599
2442098
127490

Time
331.029
167.867
22.517
52.860
62.133
578.907
4.572

Mem
15568
10893
3568
5278
5448
27273
1861

Table 3: Short sequences, medium similarity.
1aab
1fjlA
1hfh
1hpi
1csy
1pfc
1tgxA
1ycc
3cyr
451c


4
6
5
4
5
5
4
4
4
5


20
20
30
20
30
30
20
20
48
49

g (t)
6002
13673
16556
5858
14077
15341
4891
8926
8480
11440

h(s)
5984
13625
16504
5835
14026
15277
4856
8903
8431
11333

#Exp
263
900
137914
1560
52718
118543
18987
54049
583260
1213162

#Op
12
106
4852
83
3872
6477
543
1118
13422
38004

618

#Op+Cl
83
155
8465
164
5613
8905
1080
2010
25806
54115

#Heu
4404
19573
70471
5269
56191
55887
5507
77156
193690
583363

Time
0.572
0.985
14.077
0.679
6.165
11.850
1.196
3.780
22.592
111.675

Mem
691
1589
2882
656
2252
2478
649
1644
3076
6529

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

Table 4: Short sequences, high similarity.

5
5
4
5
4
5
5
5
5
5

1aho
1csp
1dox
1fkj
1fmb
1krn
1plc
2fxb
2mhr
9rnt


20
20
20
20
20
20
20
20
20
20

g (t)
8251
8434
7416
13554
7571
9752
12177
6950
14317
12382

h(s)
8187
8427
7405
13515
7568
9747
12152
6950
14306
12367

#Exp
30200
90
782
2621
172
101
454
88
256
350

#Op
2255
2
50
140
4
1
25
2
4
19

#Op+Cl
3074
78
186
222
108
87
103
71
121
108

#Heu
10971
3528
8406
10925
1804
6244
10641
1432
7853
6100

Time
3.175
0.569
0.652
0.945
0.540
0.623
0.728
0.534
0.668
0.695

Mem
1042
784
823
1511
788
1035
1415
617
1558
1250

Table 5: Medium-length sequences, low similarity.

1bbt3
1sbp
1havA
1uky
2hsdA
2pia
3grs
kinase


5
5
5
4
4
4
4
5


160
200
200
94
96
161
126
200

g (t)
30598
42925
31600
18046
21707
22755
20222
45985

h(s)
30277
42512
31234
17915
21604
22616
20061
45520

#Exp
902725789
2144000052
2488806444
179802791
65580608
97669470
107682032
2446667393

#Op
11134608
6839269
10891271
659435
293357
789446
640391
13931051

#Op+Cl
15739188
11882990
16321376
1281339
668926
1673807
1396982
19688961

#Heu
23821767
65341855
58639851
15233338
12497761
25718770
24104710
32422084

Time
43860.175
106907.000
132576.000
7006.560
2646.880
4310.030
4267.880
125170.460

Mem
927735
735053
927735
106184
67788
142318
130425
927734

Table 6: Medium-length sequences, medium similarity.

1ad2
1aym3
1gdoA
1ldg
1mrj
1pgtA
1pii
1ton
2cba


4
4
4
4
4
4
4
5
5


20
20
58
20
20
50
20
102
160

g (t)
16852
19007
20696
25764
20790
17442
20837
32564
40196

h(s)
16843
18978
20613
25736
20751
17398
20825
32428
39914

#Exp
379
466536
10795040
446123
252601
1870204
25256
13571887
60545205

#Op
16
4801
57110
4981
4067
19200
584
351174
1037828

619

#Op+Cl
221
8914
102615
9052
7380
32476
1414
526102
1595955

#Heu
27887
83634
1265777
169038
33942
485947
116670
11549908
19186631

Time
0.959
15.386
363.549
16.115
8.694
73.066
3.089
1373.180
2904.651

Mem
2186
3163
12028
4484
2905
5869
3338
58704
140712

fiSchroedl

Table 7: Medium-length sequences, high similarity.

5
4
5
4
5
4
4
5
4
5

1amk
1ar5A
1ezm
1led
1ppn
1pysA
1thm
1tis
1zin
5ptp


20
20
20
20
20
20
20
20
20
20

g (t)
31473
15209
37396
18795
27203
19242
21470
35444
16562
29776

h(s)
31453
15186
37381
18760
27159
19215
21460
35395
16546
29735

#Exp
447
3985
613
93220
18517
10810
361
31996
771
6558

#Op
7
128
4
2956
489
190
2
448
23
309

#Op+Cl
259
356
324
4951
864
801
293
915
225
539

#Heu
13120
22220
15751
39962
20209
14344
8090
42716
6619
37883

Time
0.825
1.066
0.836
3.761
2.545
1.200
0.682
4.409
0.654
1.767

Mem
3366
1755
3900
2564
2991
2224
2469
4122
1767
3600

Table 8: Long sequences, low similarity.

1ajsA
1cpt
1lvl
1ped
2myr
4enl


4
4
4
3
4
3


160
160
160
50
200
50

g (t)
38382
39745
43997
15351
43414
16146

h(s)
38173
39628
43775
15207
43084
16011

#Exp
318460012
873548
537914936
2566052
3740017645
5169296

#Op
1126697
5260
1335670
7986
7596730
9650

#Op+Cl
2310632
12954
2706940
27718
45488908
30991

#Heu
27102589
10494564
37491416
0
118747184
0

Time
9827.233
223.926
16473.420
20.035
136874.980
41.716

#Heu
18464119
96176
101816849
12801019
1476154
6040375
31318364
5962640
3585721
75819994
38368530
22622910

Time
6815.760
7.829
8795.000
843.402
334.475
348.134
2251.190
505.778
463.962
32965.522
15972.000
733.202

Mem
208951
32119
255123
4447
927735
5589

Table 9: Long sequences, medium similarity.

1ac5
1adj
1bgl
1dlc
1eft
1fieA
1gowA
1pkm
1sesA
2ack
arp
glg


4
4
4
4
4
4
4
4
5
5
5
5


92
20
243
106
56
86
166
89
58
250
143
160

g (t)
37147
32815
78366
47430
31377
53321
38784
36356
57670
76937
54939
74282

h(s)
37020
32785
78215
47337
31301
53241
38632
36256
57557
76466
54696
74059

#Exp
169779871
207072
188429118
14993317
9379999
6905957
45590739
11197890
4755983
994225856
182635167
9251905

#Op
732333
3106
857008
65288
42620
46779
275256
75144
96014
8077412
1291185
87916

620

#Op+Cl
1513853
5145
1744149
126608
72502
90937
544800
140472
136677
12436928
2160263
120180

Mem
124877
4595
291618
43158
13115
26884
99537
27244
27452
765715
193364
72148

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

Table 10: Long sequences, high similarity.

1ad3
1gpb
1gtr
1lcf
1rthA
1taq
3pmg
actin


4
5
5
6
5
5
4
5


20
54
60
160
128
250
51
53

g (t)
33641
101296
55242
149249
69296
133723
42193
48924

h(s)
33604
101231
55133
148854
69133
133321
42133
48826

#Exp
104627
1232707
2037633
181810148
14891538
1693501628
1036943
824295

621

#Op
2218
62184
54496
3235312
71081
9384718
8511
35283

#Op+Cl
3461
98476
91656
3824010
105082
17298456
15540
53009

#Heu
34539
2702949
1916127
28614215
24587882
145223167
777639
777058

Time
4.196
178.610
226.791
15363.051
1721.070
5713.240
50.796
96.147

Mem
3968
25698
18050
294688
70569
1170673
8133
11198

fiSchroedl

References
Altschul, S., Gish, W., Miller, W., Myers, E., & Lipman, D. (1990). Basic local alignment
search tool. Journal Molecular Biology, 215, 403410.
Altschul, S. F. (1989). Gap costs multiple sequence alignment. Journal Theoretical
Biology, 138, 297309.
Carrillo, H., & Lipman, D. (1988). multiple sequence alignment problem biology.
SIAM Journal Applied Mathematics, 5 (48), 10731082.
Chan, S. C., Wong, A. K. C., & Chiu, D. K. Y. (1992). survey multiple sequence
comparison techniques. Bulletin Mathematical Biology, 54 (4), 563598.
Culberson, J. C., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence,
14 (4), 318334.
Davidson, A. (2001). fast pruning algorithm optimal sequence alignment. Proceedings 2nd IEEE International Symposium Bioinformatics Bioengineering
(BIBE2001), pp. 4956.
Dayhoff, M. O., Schwartz, R. M., & Orcutt, B. C. (1978). model evolutionary change
proteins. Dayhoff, M. O. (Ed.), Atlas Protein Sequence Structure, pp.
345352, Washington, D.C. National Biomedical Research Foundation.
Dial, R. B. (1969). Shortest-path forest topological ordering. Comm. ACM, 12 (11),
632633.
Dijkstra, E. W. (1959). note two problems connection graphs.. Numerische
Mathematik, 1, 269271.
Gupta, S., Kececioglu, J., & Schaeffer, A. (1995). Improving practical space time
efficiency shortest-paths approach sum-of-pairs multiple sequence alignment.
J. Computational Biology, 2 (3), 459472.
Gusfield, D. (1993). Efficient methods multiple sequence alignment guaranteed
error bounds. Bull. Math. Biol., 55 (1), 141154.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination
minimum path cost. IEEE Trans. Systems Science Cybernetics, 4, 100107.
Hirschberg, D. S. (1975). linear space algorithm computing maximal common subsequences. Comm. ACM, 6 (18), 341343.
Ikeda, T., & Imai, H. (1994). Fast A* algorithms multiple sequence alignment.
Proceedings Genome Informatics Workshop, pp. 9099.
Jones, D. T., Taylor, W. R., & Thornton, J. M. (1992). rapid generation mutation
data matrices protein sequences. CABIOS, 3, 275282.
Kobayashi, H., & Imai, H. (1998). Improvement A* algorithm multiple sequence
alignment. Miyano, S., & Takagi, T. (Eds.), Genome Informatics, pp. 120130,
Tokyo. Universal Academy Press.
Korf, R. E. (1985). Depth-first iterative-deepening: optimal admissible tree search.
Artificial Intelligence, 27 (1), 97109.
622

fiAn Improved Search Algorithm Optimal Multiple-Sequence Alignment

Korf, R. E. (1999). Divide-and-conquer bidirectional search: First results. Proceedings
Sixteenth International Conference Artificial Intelligence (IJCAI-99), pp.
11811189, Stockholm, Sweden.
Korf, R. E., & Zhang, W. (2000). Divide-and-conquer frontier search applied optimal
sequence alignment. Proceedings Eighteenth National Conference Artificial
Intelligence (AAAI-00), pp. 210216.
McNaughton, M., Lu, P., Schaeffer, J., & Szafron, D. (2002). Memory-efficient A* heuristics
multiple sequence alignment. Proceedings Eighteenth National Conference
Artificial Intelligence (AAAI-02), Edmonton, Alberta, Canada.
Spouge, J. L. (1989). Speeding dynamic programming algorithms finding optimal
lattice paths. SIAM J. Applied Mathematics, 49 (5), 15521566.
Thompson, J. D., Plewniak, F., & Poch, O. (1999). comprehensive comparison multiple
sequence alignment programs. Nucleic Acids Res., 13 (27), 26822690.
Ukkonen, E. (1985). Algorithms approximate string matching. Information Control,
64, 110118.
Wah, B. W., & Shang, Y. (1995). comparison class IDA* search algorithms.
International Journal Tools Artificial Intelligence, 3 (4), 493523.
Wang, L., & Jiang, T. (1994). complexity multiple sequence alignment. Journal
Computational Biology, 1, 337348.
Yoshizumi, T., Miura, T., & Ishida, T. (2000). A* partial expansion large branching
factor problems. AAAI/IAAI, pp. 923929.
Zhou, R., & Hansen, E. A. (2003a). Sparse-memory graph search. 18th International
Joint Conference Artificial Intelligence (IJCAI-03), Acapulco, Mexico.
Zhou, R., & Hansen, E. A. (2003b). Sweep A*: Space-efficient heuristic search partiallyordered graphs. 15th IEEE International Conference Tools Artificial Intelligence, Sacramento, CA.
Zhou, R., & Hansen, E. A. (2004). Breadth-first heuristic search. Fourteenth International Conference Automated Planning Scheduling (ICAPS-04), Whistler, BC,
Canada.

623


