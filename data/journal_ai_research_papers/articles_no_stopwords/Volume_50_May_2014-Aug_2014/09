Journal Artificial Intelligence Research 50 (2014) 369-407

Submitted 10/13; published 6/14

HC-Search: Learning Framework Search-based
Structured Prediction
Janardhan Rao Doppa

doppa@eecs.oregonstate.edu

School EECS, Oregon State University
Corvallis, 97331-5501, USA

Alan Fern

afern@eecs.oregonstate.edu

School EECS, Oregon State University
Corvallis, 97331-5501, USA

Prasad Tadepalli

tadepall@eecs.oregonstate.edu

School EECS, Oregon State University
Corvallis, 97331-5501, USA

Abstract
Structured prediction problem learning function maps structured inputs
structured outputs. Prototypical examples structured prediction include part-ofspeech tagging semantic segmentation images. Inspired recent successes
search-based structured prediction, introduce new framework structured prediction
called HC-Search. Given structured input, framework uses search procedure guided
learned heuristic H uncover high quality candidate outputs employs
separate learned cost function C select final prediction among outputs.
overall loss prediction architecture decomposes loss due H leading
high quality outputs, loss due C selecting best among generated
outputs. Guided decomposition, minimize overall loss greedy stage-wise
manner first training H quickly uncover high quality outputs via imitation learning,
training C correctly rank outputs generated via H according true
losses. Importantly, training procedure sensitive particular loss function
interest time-bound allowed predictions. Experiments several benchmark
domains show approach significantly outperforms several state-of-the-art methods.

1. Introduction
consider problem structured prediction, predictor must produce
structured output given structured input. example, Part-Of-Speech (POS) tagging, structured input sequence words structured output corresponds
POS tags words. Image scene labeling another example, structured
input image structured output semantic labeling image regions.
Structured prediction tasks arise several domains ranging natural
language processing (e.g., named entity recognition, coreference resolution, semantic
parsing) computer vision (e.g., multi-object tracking activity recognition videos)
speech (e.g., text-to-speech mapping speech recognition) compuational biology
(e.g., protein secondary structure prediction gene prediction).
Viewed traditional classification problem, set possible classes structured
prediction exponential size input. Thus, problem producing
c
2014
AI Access Foundation. rights reserved.

fiDoppa, Fern, & Tadepalli

output combinatorial nature, introduces non-trivial choice selecting
computational framework producing outputs. Importantly, framework needs
balance two conflicting criteria: 1) must flexible enough allow complex
accurate structured predictors learned, 2) must support inference outputs
within computational time constraints application. One core research
challenges structured prediction achieve balance criteria.
standard approach structured prediction learn cost function C(x, y)
scoring potential structured output given structured input x. Given cost
function new input x, output computation involves solving so-called Argmin
problem, find minimum cost output given input.
= arg minyY(x) C(x, y)

(1)

example, approaches Conditional Random Fields (CRFs) (Lafferty, McCallum,
& Pereira, 2001), Max-Margin Markov Networks (Taskar, Guestrin, & Koller, 2003)
Structured SVMs (Tsochantaridis, Hofmann, Joachims, & Altun, 2004) represent cost
function linear model template features x y. Unfortunately, exactly
solving Argmin problem often intractable. Efficient solutions exist limited
cases dependency structure among features forms tree. cases, one
forced simplify features allow tractable inference, detrimental
prediction accuracy. Alternatively, heuristic optimization method used
loopy belief propagation variational inference. methods shown
success practice, difficult characterize solutions predict
likely work well new problem.
inspired recent successes output-space search approaches (Doppa, Fern,
& Tadepalli, 2012; Wick, Rohanimanesh, Bellare, Culotta, & McCallum, 2011), place
restrictions form cost function. methods learn use cost
function conduct search space complete outputs via search procedure
(e.g., greedy search), return least cost output uncovered search
prediction. search procedure needs able efficiently evaluate cost
function specific input-output pairs, generally straightforward even
corresponding Argmin problem intractable. Thus, methods free increase
complexity cost function without considering impact inference complexity.
approaches achieved state-of-the-art performance number
benchmark problems, primary contribution paper highlight fundamental
deficiency share. particular, prior work uses single cost function serve
dual roles both: 1) guiding search toward good outputs, 2) scoring generated
outputs order select best one. Serving dual roles often means cost
function needs make unclear tradeoffs, increasing difficulty learning. Indeed,
traditional AI search literature, roles typically served different functions,
mainly heuristic function guiding search, cost/evaluation function (often part
problem definition) selecting final output.
paper, study new framework structured prediction called HC-Search
closely follows traditional search literature. key idea learn distinct functions
roles: 1) heuristic function H guide search generate set
high-quality candidate outputs, 2) cost function C score outputs generated
370

fiHC-Search: Learning Framework Search-based Structured Prediction

heuristic H. Given structured input, predictions made using H guide
search strategy (e.g., greedy search beam search) time bound generate set
candidate outputs returning generated output least cost according C.
move HC-Search might appear relatively small, significant
implications terms theory practice. First, regret HC-Search
approach decomposed loss due H leading high quality outputs,
loss due C selecting best among generated outputs. decomposition
helps us target training minimize losses individually greedy stagewise manner. Second, show, performance approaches single
function arbitrarily bad compared HC-Search worst case.
Finally, show practice HC-Search performs significantly better single
cost function search state-of-the-art approaches structured prediction.
effectiveness HC-Search approach particular problem depends critically
on: 1) quality search space complete outputs used, quality
defined expected depth target outputs (zero loss outputs) located, 2)
ability learn heuristic function effectively guiding search generate highquality candidate outputs, 3) accuracy learned cost function selecting
best output among candidate outputs generated heuristic function. work,
assume availability efficient search space complete outputs provide
effective training regime learning heuristic function cost function within
HC-Search framework.

1.1 Summary Contributions
main contributions work follows: 1) introduce HC-Search framework, two different functions learned serve purposes search heuristic
cost function search literature; 2) analyze representational power
computational complexity learning within HC-Search framework; 3) identify
novel decomposition overall regret HC-Search approach terms generation
loss, loss due heuristic generating high-quality candidate outputs, selection
loss, loss due cost function selecting best among generated outputs; 4)
Guided decomposition, propose stage-wise approach learning heuristic
cost functions based imitation learning; 5) empirically evaluate HC-Search
approach number benchmarks, comparing state-of-the-art methods analyzing different dimensions framework.
remainder paper proceeds follows. Section 2, introduce problem
setup, give high-level overview framework, analyze complexity HC-Search
learning problem. describe approaches heuristic cost function learning
Section 3. Section 4 presents experimental results followed engineering methodology applying framework new problems Section 5. Finally, Sections 6 7
discuss related work future directions.
371

fiDoppa, Fern, & Tadepalli

2. HC-Search Framework
section, first state formal problem setup describe specifics
search spaces search strategies investigate work. Next, give
high-level overview HC-Search framework along learning objective.
2.1 Problem Setup
structured prediction problem specifies space structured inputs X , space structured outputs Y, non-negative loss function L : X 7 <+ L(x, 0 , )
loss associated labeling particular input x output 0 true output . provided training set input-output pairs {(x, )} drawn
unknown target distribution D. goal return function/predictor structured inputs outputs whose predicted outputs low expected loss respect
distribution D. Since algorithms learning heuristic cost functions
input-output pairs, standard structured prediction, assume availability
feature function : X 7 <n computes n dimensional feature vector
pair. Importantly, employ two different feature functions H C heuristic
cost function noting serving two different roles: heuristic making
local decisions guide search towards high-quality outputs cost function
making global decisions scoring candidate outputs generated heuristic
framework.
2.2 Search Spaces Search Strategies
overview basic search concepts context search-based framework below.
2.2.1 Search Spaces
approach based search space complete outputs, assume
given. Every state search space complete outputs consists input-output
pair (x, y), representing possibility predicting output structured input
x. search space defined terms two functions: 1) initial state function
I(x) returns initial state input x, 2) successor function
search state (x, y), S((x, y)) returns set next states {(x, y1 ), , (x, yk )}
share input x parent. example, sequence labeling problem,
part-of-speech tagging, (x, y) sequence words corresponding part-of-speech
(POS) labels. successors (x, y) might correspond ways changing one
output labels y, so-called flipbit space. Figure 1 provides illustration
flipbit search space handwriting recognition task.
Search Space Quality. effectiveness HC-Search framework depends
quality search space used. quality search space turn
understood terms expected amount search needed uncover correct output
. search procedures, time required find target output grow
function depth target. Thus, one way quantify expected amount
search, independently specific search strategy, considering expected depth
target outputs . particular, given input-output pair (x, ), target depth
372

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 1: example Flipbit search space handwriting recognition problem.
search state consists complete input-output pair complete output
every state differs parent exactly one label. highlighted
state corresponds one true output smallest depth,
equal number errors initial state.

373

fiDoppa, Fern, & Tadepalli

defined minimum depth find state corresponding target
output (d = 5 example flipbit space shown Figure 1). Clearly according
definition, expected target depth flipbit space equal expected number
errors output corresponding initial state.
variety search spaces, flipbit space, Limited Discrepancy Search
(LDS) space (Doppa et al., 2012), defined based hand-designed proposal
distributions (Wick et al., 2011) used past research. work applies
space, focus LDS space experiment, shown
effectively uncover high-quality outputs relatively shallow search depths (Doppa et al.,
2012).
LDS space defined terms recurrent classifier h uses next input
token, e.g. word, output tokens small preceding window, e.g. POS labels,
predict next output token. initial state LDS space consists input
x paired output recurrent classifier h x. One problem recurrent
classifiers recurrent classifier makes mistake, effects get propagated
down-stream tokens. LDS space designed prevent error propagation
immediately correcting mistakes made continuing recurrent classifier.
Since know mistakes made correct them, possible
corrections, called discrepancies, considered. Hence successors state (x, y)
LDS space consist results running recurrent classifier changing exactly
one label, i.e., introducing single new discrepancy, somewhere current output
sequence preserving previously introduced discrepancies. previous work,
LDS space shown effective uncovering high-quality outputs relatively
shallow search depths, one would expect good recurrent classifier (Doppa et al.,
2012). Appendix contains details examples LDS space employ
work.
2.2.2 Search Strategies
Recall HC-Search framework, role search procedure uncover highquality outputs. consider uninformed informed search strategies. However,
uninformed search procedures depth bounded breadth-first search practical
high-quality outputs exist small depths even feasible,
good choice dont use search time bound intelligent way
make predictions. structured prediction problems, informed search strategies
take heuristic functions account, greedy search best-first search better
choice, noting effectiveness depends quality search heuristic H. Prior
work (Doppa et al., 2012; Wick et al., 2011) shown greedy search (hill climbing
based heuristic value) works quite well number structured prediction tasks
used effective search space. Thus, work, focus empirical work
HC-Search framework using greedy search, though approach applies widely.
2.3 HC-Search Approach
approach parameterized search space complete outputs (e.g., LDS
space), heuristic search strategy (e.g., greedy search), learned heuristic function
374

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 2: high level overview HC-Search framework. Given structured input x
search space definition , first instantiate search space complete
outputs. search node space consists complete input-output pair.
Next, run search procedure (e.g., greedy search) guided heuristic
function H time bound . highlighted nodes correspond search
trajectory traversed search procedure, case greedy search.
scores nodes correspond cost values, different heuristic scores (not shown figure). return least cost output
uncovered search prediction input x.

H : X 7 <, learned cost function C : X 7 <. Given input x
prediction time bound , HC-Search makes predictions follows. traverses search
space starting I(x) using search procedure guided heuristic function H
time bound exceeded. cost function C applied find return least-cost
output generated search prediction input x. Figure 2 gives
high-level overview HC-Search framework.
formally, let YH (x) set candidate outputs generated using heuristic H
given input x. output returned HC-Search least cost output
set according C, i.e.,
= arg minyYH (x) C(x, y)
375

fiDoppa, Fern, & Tadepalli

Figure 3: example illustrates C-Search suffer arbitrarily large loss compared HC-Search.

expected loss HC-Search approach E(H, C) given heuristic H C
defined
E (H, C) = E(x,y )D L (x, y, )
(2)
goal learn heuristic function H corresponding cost function C minimize
expected loss respective spaces H C, i.e.,
(H , C ) = arg min(H,C)HC E (H, C)

(3)

contrast framework, existing approaches output space search (Doppa et al.,
2012; Wick et al., 2011) use single function (say C) serve dual purpose heuristic
cost function. raises question whether HC-Search, uses two different functions, strictly powerful terms achievable losses. following
proposition shows expected loss HC-Search arbitrarily smaller
restricting using single function C.
Proposition 1. Let H C functions function space.
learning problems, minC E(C, C) min(H,C) E(H, C). Moreover exist learning problems
minC E(C, C) arbitrarily larger (i.e. worse) min(H,C) E(H, C).
Proof. first part proposition follows fact first minimization
subset choices considered second.
see second part, consider problem single training instance search
space shown Figure 3. search procedure greedy search either guided
H HC-Search, C one function used. L(n) (n) represents
true loss feature vector node n respectively. cost heuristic functions
linear functions (n). Node 7 corresponds lowest-loss output greedy search
must follow trajectory highlighted nodes order reach output. First consider
HC-Search. highlighted path followed heuristic H needs satisfy
following constraints: H(3)<H(2), H(7)<H(6), weights wH = [1, 1, 1] result
376

fiHC-Search: Learning Framework Search-based Structured Prediction

heuristic satisfies constraints. Given heuristic function, order return node
7 final output, cost function must satisfy following constraints: C(7)<C(1),
C(7)<C(2), C(7)<C(3), C(7)<C(6), weights wC = [1, 1, 0] solve problem.
Thus see HC-Search achieve zero loss problem.
consider case single function C used heuristic cost
function. order generate loss zero, function C must satisfy combined
set constraints placed heuristic cost function. However,
verified set weights satisfies C(3)<C(2) C(7)<C(1),
hence, single function C space achieve loss zero.
scaling losses constant factors make loss suffered arbitrarily high.
Thus, see potential representational advantages following HCSearch framework. follows, consider implications added expressiveness
terms worst-case time complexity learning.
2.4 Learning Complexity
consider feasibility efficient, optimal learning simplest setting greedy
search using linear heuristic cost functions represented weight vectors wH
wC respectively. particular, consider HC-Search Consistency Problem,
input training set structured examples, must decide whether
exists wH wC HC-Search using greedy search achieve zero loss
training set. first note, problem shown NP-Hard appealing
results learning beam search (Xu, Fern, & Yoon, 2009a). particular, results
imply trivial cases, simply determining whether linear
heuristic wH uncovers zero loss search node NP-Hard. Since HC-Search
return zero loss outputs heuristic able uncover them, see problem
hard.
prove stronger result provides insight HC-Search framework. particular, show even easy learn heuristic uncovers
zero loss outputs, consistency problem still hard. shows, worst case
hardness learning problem simply result hardness discovering
good outputs. Rather problem additionally complicated potential interaction
H C. Intuitively, learning H worst case ambiguity
many small loss outputs generate,
able find effective C return best one. formalized following
theorem, whose proof Appendix.
Theorem 1. HC-Search Consistency Problem greedy search linear heuristic
cost functions NP-Hard even restrict problems possible
heuristic functions uncover zero loss output.

3. Learning Approach
complexity result suggests that, general, learning optimal (H , C ) pair
impractical due potential interdependence. section, develop greedy
377

fiDoppa, Fern, & Tadepalli

stage-wise learning approach first learns H corresponding C. approach
motivated observing decomposition expected loss components due H
C. Below, first describe decomposition staged learning approach
motivates. Next describe approaches learning heuristic cost functions.
3.1 Loss Decomposition Staged Learning
heuristic H cost function C, expected loss E (H, C) decomposed
two parts: 1) generation loss H , due H generating high-quality outputs,
2) selection loss C|H , additional loss (conditional H) due C selecting
best loss output
best loss output generated heuristic. Formally, let yH
set YH (x), i.e.,

yH
= arg minyYH (x) L(x, y, )

express decomposition follows:


E (H, C) = E(x,y )D L (x, yH
, ) + E(x,y )D L (x, y, ) L (x, yH
, y)
|
{z
}
|
{z
}
H

(4)

C|H

Note given labeled data, straightforward estimate generation
selection loss, useful diagnosing HC-Search framework. example, one
observes system high generation loss, little payoff working
improve cost function. empirical evaluation illustrate
decomposition useful understanding results learning.
addition useful diagnosis, decomposition motivates learning approach targets minimizing errors separately. particular, optimize
overall error HC-Search approach greedy stage-wise manner. first train
heuristic H order optimize generation loss component H train cost
function C optimize selection loss C|H conditioned H.
H arg minHH H
C arg minCC C|H
Note approach greedy sense H learned without considering
proof Theorem 1 hinges coupling,
implications learning C.
found practice, learning H independently C effective strategy.
follows, first describe generic approach heuristic function learning
applicable wide range search spaces search strategies, explain
cost function learning algorithm.
3.2 Heuristic Function Learning
generally, learning heuristic viewed Reinforcement Learning (RL) problem heuristic viewed policy guiding search actions rewards
378

fiHC-Search: Learning Framework Search-based Structured Prediction

received uncovering high quality outputs (Zhang & Dietterich, 1995). fact,
approach explored structured prediction case greedy search (Wick,
Rohanimanesh, Singh, & McCallum, 2009) shown effective given carefully
designed reward function action space. viable approach, general purpose
RL quite sensitive algorithm parameters specific definition reward
function actions, make designing effective learner quite challenging. Indeed, recent work (Jiang, Teichert, Daume III, & Eisner, 2012), shown generic RL
algorithms struggle structured prediction problems, even significant effort
put forth designer. Hence, work, follow approach based imitation
learning, makes stronger assumptions, nevertheless effective
easy apply across variety problems.
Algorithm 1 Heuristic Function Learning via Exact Imitation
Input: = Training examples, (I, S) = Search space definition, L = Loss function, =
Rank-based search procedure, max = search time bound
Output: H, heuristic function
1: Initialize set ranking examples R =
2: training example (x, )
3:
s0 = I(x) // initial state search tree
4:
M0 = {s0 } // set open nodes internal memory search procedure
5:
search step = 1 max
6:
Select state(s) expand: Nt =Select(A, L, Mt1 )
7:
Expand every state Nt using successor function S: Ct =Expand(Nt , S)
8:
Prune states update internal memory state search procedure:
Mt =Prune(A, L, Mt1 Ct \ Nt )
9:
Generate ranking examples Rt imitate search step
10:
Add ranking examples Rt R: R = R Rt // aggregation training data
11:
end
12: end
13: H =Rank-Learner(R) // learn heuristic function ranking examples
14: return learned heuristic function H
heuristic learning approach based observation many structured
prediction problems, quickly generate high-quality outputs guiding
search procedure using true loss function L heuristic. Obviously
done training data know . suggests formulating heuristic
learning problem framework imitation learning attempting learn heuristic
mimics search decisions made true loss function training examples.
learned heuristic need approximate true loss function uniformly output
space, need make distinctions important guiding search.
main assumptions made approach are: 1) true loss function provide effective
heuristic guidance search procedure, worth imitating, 2)
learn imitate search decisions sufficiently well.
imitation learning approach similar prior work learning single cost functions
output-space search (Doppa et al., 2012). However, key distinction learning
379

fiDoppa, Fern, & Tadepalli

focused making distinctions necessary uncovering good outputs (the purpose
heuristic) hence requires different formulation. prior work, order
avoid need approximate loss function arbitrarily closely, restrict
rank-based search strategies. search strategy called rank-based makes
search decisions comparing relative values search nodes (their ranks) assigned
heuristic, rather sensitive absolute values heuristic. common
search procedures greedy search, beam search, best-first search fall
category.
3.2.1 Imitating Search Behavior
Given search space complete outputs S, rank-based search procedure A,
search time bound , learning procedure generates imitation training data
training example (x, ) follows. run search procedure time bound
input x using heuristic equal true loss function, i.e. H(x, y) = L(x, y, ).
search process observe pairwise ranking decisions made using
oracle heuristic record sufficient (see below) replicating search.
state (x, y1 ) smaller loss (x, y2 ), ranking example generated
form constraint H(x, y1 )<H(x, y2 ). Ties broken using fixed arbitrator1 .
aggregate set ranking examples collected training examples given
learning algorithm learn weights heuristic function.
learn function H hypothesis space H consistent
ranking examples, learned heuristic guaranteed replicate oracle-guided
search training data. Further, given assumptions base learning algorithm
(e.g. PAC), generic imitation learning results used give generalization guarantees
performance search new examples (Khardon, 1999; Fern, Yoon, & Givan, 2006;
Syed & Schapire, 2010; Ross & Bagnell, 2010). experiments show, simple
approach described above, performs extremely well problems.
Algorithm 1 describes approach heuristic function learning via exact imitation
search guided loss function. applicable wide-range search spaces, search
procedures loss functions. learning algorithm takes input: 1) = {(x, )},
set training examples structured prediction problem (e.g., handwriting recognition);
2) = (I, S), search space complete outputs (e.g., LDS space), initial
state function successor function; 3) L, task loss function defined
complete outputs (e.g., hamming loss); 4) A, rank-based search procedure (e.g., greedy
search); 5) max , search time bound (e.g., number search steps).
algorithmic description Algorithm 1 assumes search procedure
described terms three steps executed repeatedly open list search
nodes: 1) selection, 2) expansion 3) pruning. execution, search procedure
selects one open nodes internal memory expansion (step 6) based
heuristic value, expands selected nodes generate candidate set (step 7).
retains subset open nodes expansion internal memory
prunes away remaining ones (step 8) based heuristic value. example,
1. LDS Space employed work, implemented arbitrator breaks ties
based position discrepancy (prefers earlier discrepancies).

380

fiHC-Search: Learning Framework Search-based Structured Prediction

greedy search maintains best node, best-first beam search retains best b
nodes fixed beam-width b, pure best first search pruning.
Algorithm 1 loops training example collects set ranking constraints. Specifically, example (x, ), search procedure run time bound
max using true loss function L heuristic (steps 2-12). search step
set pairwise ranking examples generated sufficient allowing search step
imitated (step 9) described detail below. constraints
aggregated across search steps training examples, given rank-learning
algorithm (e.g., Perceptron SVM-Rank) learn weights heuristic function
(step 13).
important step heuristic function learning algorithm generation
ranking examples imitate step search procedure (step 9). follows,
give generic description sufficient pairwise decisions imitate search,
illustrate greedy search simple example.
3.2.2 Sufficient Pairwise Decisions
noted need collect learn imitate sufficient pairwise
decisions encountered search. say set constraints sufficient
structured training example (x, ), heuristic function consistent
constraints causes search follow trajectory open lists encountered
search. precise specification constraints depends actual search procedure
used. rank-based search procedures, sufficient constraints
categorized two types:
1. Selection constraints, ensure search node(s) internal memory
state expanded next search step (are) ranked better
nodes.
2. Pruning constraints, ensure internal memory state (set search nodes)
search procedure preserved every search step. specifically,
constraints involve ranking every search node internal memory state better
(lower H-value) pruned.
Below, illustrate constraints concretely greedy search noting similar
formulations rank-based search procedures straightforward (See (Doppa, Fern,
& Tadepalli, 2014a) beam search formulation).
3.2.3 Constraints Greedy Search
basic rank-based search procedure. given input x, traverses
search space selecting next state successor current state looks best
according heuristic function H. particular, si search state step i, greedy
search selects si+1 = arg minsS(si ) H(s), s0 = I(x). greedy search, internal
memory state search procedure step consists best open (unexpanded)
node si .
381

fiDoppa, Fern, & Tadepalli

Figure 4: example search tree illustrates greedy search loss function.
node represents complete input-output pair evaluated using loss
function. highlighted nodes correspond trajectory greedy search
guided loss function.

Let (x, yi ) correspond input-output pair associated state si . Since greedy
search maintains single open node si internal memory every search step i,
selection constraints. Let Ci+1 candidate set expanding state si ,
i.e., Ci+1 = S(si ). Let si+1 best node candidate set Ci+1 evaluated
loss function, i.e., si+1 = arg minsCi+1 L(s). greedy search prunes nodes
candidate set si+1 , pruning constraints need ensure si+1 ranked better
nodes Ci+1 . Therefore, include one ranking constraint every
node (x, y) Ci+1 \ (x, yi+1 ) H(x, yi+1 ) < H(x, y).
illustrate ranking constraints example. Figure 4 shows
example search tree depth two associated losses every search node.
highlighted nodes correspond trajectory greedy search loss function
learner imitate. first search step, {H(3) < H(2), H(3) < H(4)} pruning
constraints. Similarly, {H(10) < H(8), H(10) < H(9)} form pruning constraints
second search step. Therefore, aggregate set constraints needed imitate greedy
search behavior shown Figure 4 are:
{H(3) < H(2), H(3) < H(4), H(10) < H(8), H(10) < H(9)}.
3.3 Cost Function Learning
Given learned heuristic H, want learn cost function correctly ranks
potential outputs generated search procedure guided H. formally, let YH (x)
set candidate outputs generated search procedure guided heuristic H
given input x, lbest loss best output among outputs evaluated
true loss function L, i.e., lbest = minyYH (x) L(x, y, ). exact learning scenario,
goal find parameters cost function C every training example
382

fiHC-Search: Learning Framework Search-based Structured Prediction

(x, ), loss minimum cost output equals lbest , i.e., L(x, y, ) = lbest ,
= arg minyYH (x) C(x, y). practice, exact learning isnt possible, goal
find cost function average loss training data predicted output
using cost function minimized.
Algorithm 2 Cost Function Learning via Cross Validation
Input: = Training examples, = Search space definition, L = Loss function, =
Search procedure, max = search time bound
Output: C, cost function
1: Divide training set k folds D1 , D2 , , Dk
2: // Learn k different heuristics H1 , , Hk
3: = 1 k
4:
Ti = j6=i Dj // training data heuristic Hi
5:
Hi = Learn-Heuristic(Ti , , L, A, max ) // heuristic learning via Algorithm 1
6: end
7: // Generate ranking examples cost function training
8: Intialize set ranking examples R =
9: = 1 k
10:
training example (x, ) Di
11:
Generate outputs running search procedure heuristic Hi time
bound max : YHi (x) = Generate-Outputs(x, , A, Hi , max )
12:
Compute set best loss outputs: Ybest = {y YHi (x)|L(x, y, ) = lbest },
lbest = minyYH (x) L(x, y, )

13:
pair outputs (ybest , y) Ybest YHi (x) \ Ybest
14:
Add ranking example C(x, ybest ) < C(x, y) R
15:
end
16:
end
17: end
18: // Train cost function ranking examples
19: C = Rank-Learner(R)
20: return learned cost function C
formulate cost function training problem instance rank learning problem
(Agarwal & Roth, 2005). specifically, want best loss outputs YH (x)
ranked better non-best loss outputs according cost function,
bi-partite ranking problem. Let Ybest set best loss outputs YH (x), i.e.,
Ybest = {y YH (x)|L(x, y, ) = lbest }. generate one ranking example every pair
outputs (ybest , y) Ybest YH (x) \ Ybest , requiring C(x, ybest )<C(x, y). search
procedure able generate target output (i.e., lbest = 0), similar
standard learning CRFs SVM-Struct, results much simpler rank-learning
problem (cost function needs rank correct output incorrect outputs
generated search). set best loss outputs Ybest large, bi-partite
ranking may result highly over-constrained problem. cases, one could relax
problem attempting learn cost function ranks least one output Ybest higher
non-best loss outputs. easily implemented online-learning
383

fiDoppa, Fern, & Tadepalli

framework follows. error (i.e., best cost output according current
weights
/ Ybest ), weights updated ensure best cost output ybest Ybest
according current weights ranked better outputs YH (x) \ Ybest .
important note theory practice, distribution outputs
generated learned heuristic H testing data may slightly different
one training data. Thus, train C training examples used train H, C
necessarily optimized test distribution. mitigate effect, train
cost function via cross validation (see Algorithm 2) training cost function
data, used train heuristic. training methodology commonly
used Re-ranking style algorithms (Collins, 2000) among others.
Algorithm 2 describes approach cost function training via cross validation.
four main steps algorithm. First, divide training data k folds.
Second, learn k different heuristics, heuristic Hi learned using data
folds excluding ith fold (Steps 3-6). Third, generate ranking examples
cost function learning described using heuristic Hi data
trained (Steps 9-17). Finally, give aggregate set ranking examples R rank
learner (e.g., Perceptron, SVM-Rank) learn cost function C (Step 19).
3.4 Rank Learner
section, describe specifics rank learner used learn
heuristic cost functions aggregate sets ranking examples produced
algorithms. use off-the-shelf rank-learning algorithm (e.g., Perceptron,
SVM-Rank) base learner train heuristic function set ranking
examples R. specific implementation employed online Passive-Aggressive
(PA) algorithm (Crammer, Dekel, Keshet, Shalev-Shwartz, & Singer, 2006) base
learner. Training conducted 50 iterations experiments.
PA online large-margin algorithm, makes several passes training
examples R, updates weights whenever encounters ranking error. Recall
ranking example form H(x, y1 ) < H(x, y2 ) heuristic training C(x, y1 ) <
C(x, y2 ) cost function training, x structured input target output ,
y1 y2 potential outputs x L(x, y1 , ) < L(x, y2 , ). Let >0
difference losses two outputs involved ranking example.
experimented PA variants use margin scaling (margin scaled ) slack
scaling (errors weighted ) (Tsochantaridis, Joachims, Hofmann, & Altun, 2005). Since
margin scaling performed slightly better slack scaling, report results PA
variant employs margin scaling. give full details margin scaling
update.
Let wt current weights linear ranking function.
ranking error
cycling training data, i.e., wt (x, y2 ) wt (x, y1 ) < , new
weights wt+1 corrects error obtained using following equation.
wt+1 = wt + ((x, y2 ) (x, y1 ))
384

fiHC-Search: Learning Framework Search-based Structured Prediction

learning rate given
wt (x, y1 ) wt (x, y2 ) +
=
k(x, y2 ) (x, y1 )k2





specific update previously used cost-sensitive multiclass classification
(Crammer et al., 2006) (See Equation 51) structured output problems (Keshet,
Shalev-Shwartz, Singer, & Chazan, 2005) (See Equation 7).

4. Experiments Results
section empirically investigate HC-Search approach compare
state-of-the-art structured prediction.
4.1 Datasets
evaluate approach following four structured prediction problems including
three benchmark sequence labeling problems 2D image labeling problem.
Handwriting Recognition (HW). input sequence binary-segmented
handwritten letters output corresponding character sequence [a z]+ .
dataset contains roughly 6600 examples divided 10 folds (Taskar et al.,
2003). consider two different variants task work Hal Daume
III, Langford, Marcu (2009). HW-Small version, use one fold training
remaining 9 folds testing, vice-versa HW-Large.
NETtalk Stress. text-to-speech mapping problem, task
assign one 5 stress labels letter word. 1000 training
words 1000 test words standard dataset. use sliding window size
3 observational features.
NETtalk Phoneme. similar NETtalk Stress except task
assign one 51 phoneme labels letter word.
Scene labeling. data set contains 700 images outdoor scenes (Vogel &
Schiele, 2007). image divided patches placing regular grid size
1010 entire image, patch takes one 9 semantic labels (sky,
water, grass, trunks, foliage, field, rocks, flowers, sand ). Simple appearance features
including color, texture position used represent patch. Training
performed 600 images, remaining 100 images used testing.
4.2 Experimental Setup
HC-Search experiments, use Limited Discrepancy Space (LDS) exactly
described work Doppa et al. (2012) search space structured outputs.
Prior work HC-Search shown greedy search works quite well structured prediction tasks, particularly using LDS space (Doppa et al., 2012). Hence,
consider greedy search experiments. would point experiments shown using beam search best first search produce similar results.
385

fiDoppa, Fern, & Tadepalli

training testing set search time bound 25 search steps domains
except scene labeling, much larger search space uses = 150.
found using values larger produce noticeable improvement.
extremely small values , performance tends worse, increases quickly
made larger. show results full spectrum time bounds later.
domains, learn linear heuristic cost functions second order features unless otherwise noted. case, feature vector measures features neighboring label pairs
triples along features structured input. measure error Hamming
loss unless otherwise noted.
4.3 Comparison State-of-the-Art
compare results HC-Search approach structured prediction algorithms including CRFs (Lafferty et al., 2001), SVM-Struct (Tsochantaridis et al., 2004),
Searn (Hal Daume III et al., 2009), Cascades (Weiss & Taskar, 2010) C-Search,
identical HC-Search except uses single-function output space search
(Doppa et al., 2012). show performance Recurrent, simple
recurrent classifier trained exactly work Doppa et al. (2012). top section
Table 1 shows error rates different algorithms. scene labeling
possible run CRFs, SVM-Struct, Cascades due complicated grid structure
outputs (hence - table). report best published results CRFs,
SVM-Struct, Searn. Cascades trained using implementation (Weiss, 2014) provided authors, used sequence labeling problems Hamming loss.
would point results cascades differ appear
work Doppa, Fern, Tadepalli (2013) obtained using updated2 version
cascades training code. Across benchmarks, see results HC-Search comparable significantly better state-of-the-art including C-Search, uses single
function heuristic function cost function. results scene labeling
domain significant improving error rate 27.05 19.71. results
show HC-Search state-of-the-art approach across problems learning
separate heuristic cost functions significantly improve output-space search.
4.4 Higher-Order Features
One advantages approach compared many frameworks structured prediction ability use expressive feature spaces without paying huge computational
price. bottom part Table 1 shows results using third-order features (compared
second-order above) HC-Search, C-Search Cascades. Note practical
run methods using third-order features due substantial increase inference
time. overall error HC-Search higher-order features slightly improved compared
using second-order features across benchmarks still better error-rates
C-Search Cascades third-order features, exception Cascades
HW-Large. fact, HC-Search using second-order features still outperforming
third-order results methods three five domains.
2. Personal communication author

386

fiHC-Search: Learning Framework Search-based Structured Prediction

Algorithms
HW-Small

HW-Large

Datasets
Stress Phoneme

Scene labeling

HC-Search
C-Search
CRF
SVM-Struct
Recurrent
Searn
Cascades

a. Comparison state-of-the-art
12.81
03.23
17.58
16.91
17.03
07.16
21.07
20.81
19.97
13.11
21.48
21.09
19.64
12.49
22.01
21.70
34.33
25.13
27.18
26.42
17.88
09.42
23.85
22.74
13.02
03.22
20.41
17.56

19.71
27.05
43.36
37.69
-

HC-Search
C-Search
Cascades

b. Results Third-Order Features
10.04
02.21
16.32
14.29
14.15
04.76
19.36
18.19
10.82
02.16
19.51
17.41

18.25
25.79
-

Table 1: Error rates different structured prediction algorithms.
4.5 Loss Decomposition Analysis
examine HC-Search C-Search terms loss decomposition (see Equation 4) generation loss H selection loss C|H . quantities
easily measured HC-Search C-Search keeping track best loss output
generated search (guided either heuristic cost function C-Search)
across testing examples. Table 2 shows results, giving overall error HC
decomposition across benchmarks HC-Search C-Search.
first see generation loss H similar C-Search HC-Search across
benchmarks exception scene labeling, HC-Search generates slightly better
outputs. shows least LDS search space difference performance
C-Search HC-Search cannot explained C-Search generating lower quality
outputs. Rather, difference two methods reflected difference
selection loss C|H , meaning C-Search effective ranking outputs
generated search compared HC-Search. result clearly shows advantage
separating roles C H understandable light training mechanism
C-Search. approach, cost function trained satisfy constraints related
generation loss selection loss. turns many generation
loss constraints, hypothesize biases C-Search toward low generation loss
expense selection loss.
results show methods selection loss C|H contributes significantly overall error compared H . shows approaches
able uncover high-quality outputs, unable correctly rank generated
outputs according losses. suggests first avenue improving results
HC-Search would improve cost function learning component, e.g. using
non-linear cost functions.
387

fiDoppa, Fern, & Tadepalli

4.6 Ablation Study
futher demonstrate two separate functions (heuristic cost function)
HC-Search lead accurate predictions compared using single function
C-Search, perform ablation experiments. study, take learned
heuristic function H cost function C HC-Search framwork, use one
make predictions. example, HH-Search corresponds configuration
use function H heuristic cost function. Similarly, CC-Search corresponds
configuration use function C heuristic cost function.
Table 2b shows results ablation experiments. make several interesting observations results. First, overall error HC-Search significantly
better HH-Search CC-Search. Second, selection loss HH-Search
increases compared HC-Search. understandable H trained
score candidate outputs generated search. Third, generation
loss CC-Search increases compared HC-Search behavior significant
(increases 11.24 compared 5.82) scene labeling task. results provide
evidence importance separating training heuristic cost
functions.
HW-Small
C|H
H

Stress
C|H
H

HC

03.2
07.1

a. HC-Search vs. C-Search
00.7 02.7 17.5 02.7 14.7
00.9 06.2 21.0 03.0 18.0

16.9
20.8

03.4
04.1

13.4
16.6

19.7
27.0

05.8
07.8

13.8
19.2

07.9
06.6

b. Results Ablation study
00.7 7.2
22.5 02.7 19.7
01.7 04.9 19.1 03.2 15.8

22.1
21.6

03.4
04.3

18.7
17.3

32.1
25.3

07.8
11.2

24.3
14.0

c. Results heuristic function training via DAgger
08.1 03.1 00.4 02.6 17.2 02.2 15.0 16.8 03.0
09.9 05.1 00.8 03.6 20.3 02.8 17.1 19.0 03.9

13.8
14.7

18.0
24.2

03.7
05.9

14.3
18.3

11.7

16.3

00.3

16.0

Datasets
Error

HC

HC-Search
C-Search

12.8
17.5

04.7
04.9

08.0
12.6

HH-Search
CC-Search

18.4
16.2

04.7
05.3

13.7
10.9

HC-Search
C-Search

12.0
15.1

03.9
04.6

HC

HW-Large
C|H
H

HC

Phoneme
C|H
H

HC

Scene
C|H
H

d. Results Oracle Heuristic
LC-Search
(Oracle H)

10.1

00.2

09.9

03.0

00.5

02.5

14.1

00.2

13.9

12.2

00.5

Table 2: HC-Search: Error decomposition heuristic cost function.
4.7 Results Heuristic Training via DAgger
heuristic learning approach follows simplest approach imitation learning, exact
imitation, learner attempts exactly imitate observed expert trajectories
(here imitate search oracle heuristic). experiments show exact
imitation performs quite well, known exact imitation certain deficiencies
general. particular, functions trained via exact imitation prone error propagation (Kaariainen, 2006; Ross & Bagnell, 2010), errors made test time change
distribution decisions encountered future compared training distribution.
address problem, sophisticated imitation learning algorithms developed, state-of-the-art approach DAgger (Ross, Gordon, & Bagnell, 2011).
388

fiHC-Search: Learning Framework Search-based Structured Prediction

consider whether DAgger improve heuristic learning turn overall
accuarcy.
DAgger iterative algorithm, iteration adds imitation data aggregated data set. first iteration follows exact imitation approach, data
collected observing expert trajectory (or number them). iteration
imitation function (here heuristic) learned current data. Successive iterations
generate trajectories following mixture expert suggestions (in case ranking decisions) suggestions recently learned imitation function. decision point
along trajectory added aggregate data set labeling expert decision.
way, later iterations allow DAgger learn states visited possibly erroneous learned functions correct mistakes using expert input. Ross et al. (2011)
show iterations DAgger using learned policy without mixing
expert policy performs well across diverse domains. Therefore, use
approach DAgger experiments. experiments run 5 iterations DAgger,
noting noticable improvement observed 5 iterations.
Table 2c shows results HC-Search C-Search obtained training DAgger. HC-Search, generation loss (H ) improved slightly sequence labeling
problems little room improvement, DAgger leads significant improvement generation loss challenging problem scene labeling.
see overall error HC-Search scene labeling reduces due improvement
generation loss showing cost function able leverage better outputs produced
heuristic. Similarly, overall error C-Search improved DAgger across
board see significant improvements handwiriting scene labeling
domains. interesting note unlike HC-Search, improvement C-Search
mostly due improvement selection loss (C|H ) except scene labeling task,
due improvement generation loss selection loss.
results show improving heuristic learning able improve overall
performance. clear whether improvement, perhaps due future
advances imitation learning, would yet lead overall improvement. is,
may possible improve generation loss, clear cost function
able exploit improvments. help evaluate ran experiment
gave HC-Search true loss function use heuristic (an oracle heuristic), i.e.,
H(x, y) = L(x, y, ), training cost function testing. provides
assessment much better might able could improve heuristic
learning. results Table 2, label LC-Search (Oracle H) show
using oracle heuristic, H negligible might expect smaller observed
HC-Search. shows may possible improve heuristic learning
via better imitation.
see oracle results overall error HC better
HC-Search, HW-Small Scene labeling tasks, selection error C|H got slightly
worse.. indicates cost function learner able leverage, varying degrees, better outputs produced oracle heuristic. suggests improving
heuristic learner order reduce generation loss could viable way
reducing overall loss HC-Search, even without altering current cost learner. However, saw much less room improve heuristic learner
389

fiDoppa, Fern, & Tadepalli

data sets hence potential gains less directly trying improve cost
learner.
4.8 Results Training Different Time bounds

Train

trained HC-Search different time bounds (i.e., number greedy search steps)
see overall loss, generation loss selection loss vary increase training
time bound. general, time bound increases, generation loss monotonically
decrease, since strictly outputs encountered. hand difficulty
cost function learning increase time bound grows since must learn distinguish larger set candidate outputs. Thus, degree overall
error decreases (or grows) time bound depends combination much
generation loss decreases whether cost function learner able accurately
distinguish improved outputs.
Figure 5 shows performance HC-Search full spectrum time bounds.
Qualitatively, see generation loss, due heuristic, decreases remarkably
fast benchmarks improves little initial decrease. see
cost function learner achieves relatively stable selection loss short time, though
increase bit time cases. combined effect see overall
error HC improves quickly increase time bound improvement tends
small beyond certain time bound. Also, cases (e.g., phoneme prediction
scene labeling) performance tends get slightly worse large time bounds,
happens increase selection loss counteracted decreased generation
loss.
Loss Function
Hamming
VC

Test
Hamming
VC
1757
4658
1769
4620

Table 3: Results training non-hamming loss functions.

4.9 Results Training Non-Hamming Loss functions
One advantages HC-Search compared many approaches structured
prediction sensitive loss function used training. trained HCSearch different loss functions handwriting domain verify true
practice not. used hamming loss (uniform misclassification cost 1 characters)
Vowel-Consonant (VC) loss (different misclassification costs vowels consonants)
experiment. VC loss, used misclassification costs 4 2 vowels
consonants respectively. Training done 5 folds remaining 5 folds used
testing. Table 4.8 shows results training testing two loss functions.
report cumulative loss testing examples. see, testing
loss function, training loss function gives slightly better performance
training using different loss function. shows HC-Search learning approach
390

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 5: HC-Search results training different time bounds. training time
bound (i.e., no. greedy search steps) x-axis error y-axis.
three curves graph corresponding overall loss HC , generation loss H
selection loss C|H .

391

fiDoppa, Fern, & Tadepalli

sensitive loss function. However, result may hold generally much
depends problem structure, loss function ability cost function
capture loss.
4.10 Discussion Efficiency HC-Search Approach
HC-Search framework, basic computational elements include generating candidate
states given state; computing heuristic function features via H cost function
features via C candidate states; computing heuristic cost scores via
learned heuristic cost function pair (H, C). computational time generating
candidate states depends employed search space = (I, S), initial
state function successor function. example, generation candidates
efficient Flipbit space compared LDS space (involves running
recurrent classifier every action specified successor function S). Therefore,
efficiency overall approach depends size candidate set
greatly improved generating fewer candidate states (e.g., via pruning) parallelizing
computation. done preliminary work direction introducing sparse
versions LDS Flipbit search spaces pruning actions based recurrent
classifier scores (as specified prunining parameter k). simple pruning strategy
resulted 10-fold speedup little loss accuracy across several benchmark
problems (Doppa et al., 2014a). However, work needs done learning pruning
rules improve efficiency HC-Search approach.

5. Engineering Methodology Applying HC-Search
section, describe engineering methodology applying HC-Search framework new problems. high-level, methodology involves selecting effective
time-bounded search architecture (search space, search procedure, search time-bound),
leveraging loss decomposition terms generation selection loss training
debugging heuristic cost functions. describe steps detail.
5.1 Selection Time-bounded Search Architecture
time-bounded search architecture instantiated selecting search space, search
strategy, search time-bound. mentioned before, effectiveness HC-Search
depends critically quality search space (i.e., search depth target
outputs found) employed. fact, prior work empirically demonstrated performance gap search architectures Flipbit space LDS
space grows difference target depths increase (Doppa et al., 2014a).
Therefore, important select/design high-quality search space problem
hand.
exists greedy predictor structured prediction problem, one could leverage define appropriate variant LDS space. Fortunately, greedy
predictors several problems natural language processing, computer vision, relational
networks, planning preferences. example, transition-based parsers dependency parsing (Nivre, 2008; Goldberg & Elhadad, 2010); greedy classifiers co-reference
392

fiHC-Search: Learning Framework Search-based Structured Prediction

resolution (Chang, Samdani, & Roth, 2013; Stoyanov & Eisner, 2012) event extraction
(Li, Ji, & Huang, 2013); sequential labelers boundary detection objects images
(Payet & Todorovic, 2013); iterative classifiers collective inference relational networks
(Sen, Namata, Bilgic, Getoor, Gallagher, & Eliassi-Rad, 2008; Doppa, Yu, Tadepalli, &
Getoor, 2009, 2010); classifier chains multi-label prediction (Read, Pfahringer, Holmes,
& Frank, 2011); greedy planners planning preferences (Xu, Fern, & Yoon,
2010). general, designing high-quality search spaces key research topic
work needs done direction. Learning search operators (macro actions)
transformation rules Transformation-based Learning (TBL) (Brill, 1995) optimize
search space one many possibilities. Sometimes problem structure help
designing effective search spaces. example, multi-label prediction problems,
outputs binary vectors small number active labels (highly sparse).
simple flipbit space initialized null vector effective (Doppa, Yu,
Ma, Fern, & Tadepalli, 2014b).
picking search space, need select appropriate search procedure
search time-bound. effectiveness search architecture measured performing
oracle search (true loss function used heuristic cost function) training
data. one could perform oracle search (LL-Search) different search procedures (e.g.,
greedy beam search) different time-bounds select search procedure
effective. see benefit beam search problems considered,
expect change harder problems non-Hamming loss functions (e.g.,
B-Cubed score co-reference resolution). search space redundant,
fix search time-bound value performance search architecture
stagnates. Otherwise, one allow slack search procedure recover
errors. experiments, found (size structured output)
reasonable value time-bound (Figure 5 provides justification choice).
5.2 Training Debugging
training procedure involves learning heuristic H cost function C optimize
performance selected time-bounded search architecture training data.
Following staged learning approach, one could start learning heuristic via exact
imitation oracle search. that, learned heuristic H evaluated
measuring generation loss (HL-Search configuration). performance HLSearch configuration acceptable respect performance LL-Search,
move cost function learning part. Otherwise, try improve heuristic either
employing sophisticated imitation learning algorithms (e.g., DAgger), enriching
feature function H , employing powerful rank learner. Similarly, learning
cost function C conditioned learned heuristic, measure selection loss.
selection loss high, try improve cost function either adding
expressive features C employing powerful rank learner.

6. Comparison Related Work
described earlier, majority structured prediction work focused use
exact inference computing outputs tractable, approximate inference
393

fiDoppa, Fern, & Tadepalli

techniques, loopy belief propagation relaxation methods, not. Learning focused tuning cost function parameters order optimize various
objective functions, differ among learning algorithms (Lafferty et al., 2001; Taskar
et al., 2003; Tsochantaridis et al., 2004; McAllester, Hazan, & Keshet, 2010).
approximate cost function learning approaches employ inference routine
training. example, piece-wise training (Sutton & McCallum, 2009), Decomposed
Learning (Samdani & Roth, 2012) special case pseudo-max training (Sontag, Meshi,
Jaakkola, & Globerson, 2010) fall category. training approaches
efficient, still need inference algorithm make predictions testing.
cases, one could employ Constrained Conditional Models (CCM) framework
(Chang, Ratinov, & Roth, 2012) declarative (global) constraints make predictions using learned cost function. CCM framework relies Integer Linear
Programming (ILP) inference method (Roth & tau Yih, 2005). recent work attempted integrate (approximate) inference cost function learning principled
manner (Meshi, Sontag, Jaakkola, & Globerson, 2010; Stoyanov, Ropson, & Eisner, 2011;
Hazan & Urtasun, 2012; Domke, 2013). Researchers worked using higher-order
features CRFs context sequence labeling pattern sparsity assumption
(Ye, Lee, Chieu, & Wu, 2009; Qian, Jiang, Zhang, Huang, & Wu, 2009). However,
approaches applicable graphical models sparsity assumption
hold.
alternative approach addressing inference complexity cascade training (Felzenszwalb & McAllester, 2007; Weiss & Taskar, 2010; Weiss, Sapp, & Taskar, 2010),
efficient inference achieved performing multiple runs inference coarse level
fine level abstraction. approaches shown good success, place
restrictions form cost functions facilitate cascading. Another potential drawback cascades approaches either ignore loss
function problem (e.g. assuming Hamming loss) require loss function
decomposable way supports loss augmented inference. approach sensitive
loss function makes minimal assumptions it, requiring
blackbox evaluate potential output.
Classifier-based structured prediction algorithms avoid directly solving Argmin problem assuming structured outputs generated making series discrete
decisions. approach attempts learn recurrent classifier given input
x iteratively applied order generate series decisions producing target
output y. Simple training methods (e.g. Dietterich, Hild, & Bakiri, 1995) shown
good success positive theoretical guarantees (Syed & Schapire, 2010;
Ross & Bagnell, 2010). However, recurrent classifiers prone error propagation
(Kaariainen, 2006; Ross & Bagnell, 2010). Recent work, e.g. SEARN (Hal Daume III
et al., 2009), SMiLe (Ross & Bagnell, 2010), DAgger (Ross et al., 2011), attempts
address issue using sophisticated training techniques shown state-of-theart structured-prediction results. However, approaches use classifiers produce
structured outputs single sequence greedy decisions. Unfortunately, many
problems, decisions difficult predict greedy classifier, crucial
good performance. contrast, approach leverages recurrent classifiers define good
394

fiHC-Search: Learning Framework Search-based Structured Prediction

quality search spaces complete outputs, allows decision making comparing
multiple complete outputs choosing best.
non-greedy methods learn scoring function search space
partial structured outputs (DaumeIII & Marcu, 2005; Daume III, 2006; Xu, Fern, & Yoon,
2009b; Huang, Fayong, & Guo, 2012; Yu, Huang, Mi, & Zhao, 2013). methods
perform online training, differ way search errors defined
weights updated errors occur. Unfortunately, training scoring function
difficult hard evaluate states partial outputs theoretical
guarantees learned scoring function (e.g., convergence generalization results)
rely strong assumptions (Xu et al., 2009b).
work closely related output space search approaches (Doppa et al.,
2012; Wick et al., 2011), use single cost function serve search heuristic
score candidate outputs. Serving dual roles often means cost
function needs make unclear tradeoffs, increasing difficulty learning. HCSearch approach overcomes deficiency learning two different functions, heuristic
function guide search generate high-quality candidate outputs, cost function
rank candidate outputs. Additionally, error decomposition HC-Search terms
heuristic error cost function error allows human designers learning system
diagnose failures take corrective measures.
approach related Re-Ranking (Collins, 2002), uses generative
model propose k-best list outputs, ranked separate ranking
function. contrast, rather restricting generative model producing potential
outputs, approach leverages generic search efficient search spaces guided
learned heuristic function minimal representational restrictions, employs
learned cost function rank candidate outputs. Recent work generating multiple
diverse solutions probabilistic framework considered another way producing
candidate outputs. representative set approaches line work diverse Mbest (Batra, Yadollahpour, Guzman-Rivera, & Shakhnarovich, 2012), M-best modes (Park
& Ramanan, 2011; Chen, Kolmogorov, Zhu, Metaxas, & Lampert, 2013) Determinantal
Point Processes (Kulesza & Taskar, 2012).
general area speedup learning studied planning search community
related work (Fern, 2010). problems, cost function typically known
objective learn control knowledge (i.e., heuristic function) directing search
algorithm low-cost terminal node search space. example, STAGE (Boyan &
Moore, 2000) learns evaluation function states improve performance
search, value state corresponds performance local search algorithm
starting state, (Zhang & Dietterich, 1995) use Reinforcement Learning (RL)
methods learn heuristics job shop scheduling goal minimizing duration
schedule. Unlike problems planning combinatorial optimization,
cost function given structured prediction problems. Therefore, HC-Search
approach learns cost function score structured outputs along heuristic
function guide search towards low cost outputs.
395

fiDoppa, Fern, & Tadepalli

7. Summary Future Work
introduced HC-Search framework structured prediction whose principal feature
separation cost function search heuristic. showed framework
yields significantly superior performance state-of-the-art results, allows informative error analysis diagnostics.
investigation showed main source error existing output-space approaches including approach (HC-Search) inability cost function correctly rank candidate outputs produced output generation process. analysis
suggests learning powerful cost functions, e.g., Regression trees (Mohan, Chen,
& Weinberger, 2011), eye towards anytime performance (Grubb & Bagnell, 2012;
Xu, Weinberger, & Chapelle, 2012) would productive. results suggested
room improve overall performance better heuristic learning. Thus, another
direction pursue heuristic function learning speed process generating
high-quality outputs (Fern, 2010).
Future work includes applying framework challenging problems natural language processing (e.g., co-reference resolution, dependency parsing, semantic
parsing) computer vision (e.g., object detection biological images Lam, Doppa, Hu,
Todorovic, Dietterich, Reft, & Daly, 2013, multi-object tracking complex sports
videos Chen, Fern, & Todorovic, 2014). effectiveness HC-Search approach depends
quality search space, therefore, work needs done learning
optimize search spaces leveraging problem structure. Similarly, studying pruning
techniques improve efficiency learning inference another useful
direction.
Acknowledgements
authors would thank anonymous reviewers Jason Eisner, associate
editor, comments feedback. first author would thank Tom
Dietterich encouragement support throughout work. work supported part NSF grants IIS 1219258, IIS 1018490 part Defense Advanced
Research Projects Agency (DARPA) Air Force Research Laboratory (AFRL)
Contract No. FA8750-13-2-0033. opinions, findings conclusions recommendations expressed material author(s) necessarily reflect
views NSF, DARPA, Air Force Research Laboratory (AFRL),
US government. preliminary version article published AAAI-2013 (Doppa
et al., 2013)

Appendix A. Limited Discrepancy Search (LDS) Space
Limited Discrepancy Search (LDS) space (Doppa et al., 2012, 2014a) defined terms
learned recurrent classifier h. Thus, start describing recurrent classifier
explain key idea behind LDS space. simplicity, explain main ideas using
sequence labeling problem (handwriting recognition task) noting generalize
non-sequence labeling problems (for full details see Doppa et al., 2012, 2014a).
396

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 6: Illustration recurrent classifier handwriting recognition problem. classifier predicts labels left-to-right order. makes labeling decision
position greedily based character image predicted label
previous position (shown dotted box). particular example,
classifier makes mistake first position error propagates
positions leading bad output.

A.1 Recurrent Classifier
sequence labeling problem, recurrent classifier produces label position
sequence, based input position predicted labels previous positions
(Dietterich et al., 1995). learned classifier accurate, number incorrect
labeling decisions relatively small. However, even small number errors
propagate cause poor outputs.
Figure 6 illustrates recurrent classifier handwriting recognition example.
classifier predicts labels left-to-right order. makes labeling decision
position greedily based character image predicted label previous
position (shown dotted box). particular example, classifier makes
mistake first position error propagates leading bad output (5
errors).
A.2 Limited Discrepancy Search (LDS)
LDS originally introduced context problem solving using heuristic search
(Harvey & Ginsberg, 1995). key idea behind LDS realize classifier
prediction corrected small number critical errors, much better output
397

fiDoppa, Fern, & Tadepalli

(a)

(b)

Figure 7: Illustration Limited Discrepancy Search (LDS) handwriting recognition
problem. given discrepancy set D, generate unique output
running recurrent classifier changes D. (a) LDS one
discrepancy. introduce discrepancy first position label (shown
red) run classifier, able correct two subsequent labels. (b)
LDS two discrepancies. introduce additional discrepancy fifth
position label c (shown red) run classifier, recover target
output struct.

would produced. LDS conducts (shallow) search space possible corrections
hope finding output better original.
Given classifier h sequence length , discrepancy pair (i, l)
{1, . . . , } index sequence position l label, generally different
prediction classifier position i. set discrepancies D,
generate unique output h[D](x) running classifier changes D.
discrepancies viewed overriding prediction h particular positions,
possibly correcting errors, introducing new errors. one extreme, empty,
get original output produced greedy classifier (see Figure 6).
extreme, specifies label position, output influenced h
completely specified discrepancy set. Figure 7 illustrates LDS
handwriting example. introduce discrepancy first position label
(shown red) run classifier, able correct two subsequent labels (see
Figure 7(a)). introduce additional discrepancy fifth position label c (shown
red) run classifier, recover target output struct (see Figure 7(b)).
398

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 8: example Limited Discrepancy Search (LDS) space handwriting recognition
problem. highlighted state corresponds one true output
smallest depth.

practice, h reasonably accurate, primarily interested small
discrepancy sets relative length sequence. problem know
corrections made thus LDS conducts search discrepancy
sets, usually small large sets.

A.3 LDS Space
Given recurrent classifier h, define corresponding limited-discrepancy search space
complete outputs follows. state search space represented (x, D)
x input sequence discrepancy set. view state (x, D) equivalent
input-output state (x, h[D](x)). initial state function simply returns (x, )
corresponds original output recurrent classifier. successor function
state (x, D) returns set states form (x, D0 ), D0 D,
additional discrepancy. way, path LDS search space starts
output generated recurrent classifier traverses sequence outputs
differ original number discrepancies. Given reasonably accurate h,
expect high-quality outputs generated relatively shallow depths
search space hence generated quickly.
399

fiDoppa, Fern, & Tadepalli

Figure 8 illustrates3 limited-discrepancy search space. state consists
input x, discrepancy set output produced running classifier
specified discrepancy set, i.e., h[D](x). root node empty discrepancy set. Nodes
level one contain discrepancy sets size one. highlighted state corresponds
smallest depth state containing target output.

Appendix B. Hardness Proof HC-Search Consistency Problem
Theorem 2. HC-Search Consistency Problem greedy search linear heuristic
cost functions NP-Hard even restrict problems possible
heuristic functions uncover zero loss output.
Proof. reduce Minimum Disagreement problem linear binary classifiers,
proven NP-complete work Hoffgen, Simon, Horn (1995).
one statement problem given input set N , p-dimensional vectors
= {x1 , . . . , xN } positive integer k. problem decide whether
p-dimensional real-valued weight vector w w xi < 0 k
vectors.
first sketch high-level idea proof. Given instance Minimum Disagreement, construct HC-Search consistency problem single structured
training example. search space corresponding training example designed
single node n loss zero nodes loss
1. linear heuristic functions greedy search paths terminate n ,
generating set nodes/outputs path there. search space designed
possible path initial node n corresponds selecting k fewer
vectors , denote . traversing path, set nodes
generated (and hence must scored C), say N , includes feature vectors corresponding
along negation feature vectors . define
n assigned zero vector, cost node 0 weight vector.
order achieve zero loss given path consideration, must weight
vector wC wC x 0 x N . construction equivalent
wC x < 0 x . possible found solution Minimum
Disagreement problem since |T | k. remaining details show construct
space setting heuristic weights generate paths corresponding
possible way paths end n . completeness describe
construction below.
search node space n tuple (i, m, t) 1 N ,
0 k, one 5 node types set {d, s+ , , x+ , x }.
viewed indexing example xi effectively codes many instances
selected mistakes hence put . Finally, encodes type
search node following meanings become clear
construction: (decision), s+ (positive selection), (negative selection), x+ (positive
instance), x (negative instance). search space constructed example xi
3. may clear example, allow over-riding discrepancies provide opportunity recover search errors.

400

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 9: example search space = {x1 , x2 , x3 } k = 1. greedy paths
terminate zero loss node n path selects one instance
include mistake set .

considered order choice made whether count mistake (put
) not. choice made decision nodes, form (i, m, d),
indicating decision made example already
examples selected . decision node < k two children (i, m, )
(i, m, s+ ), respectively correspond selecting xi mistake set not.
Later show features assigned nodes allow heuristic make
selection desired.
selection node single node child. particular, positive selection node
(i, m, s+ ) positive instance node (i, m, x+ ) child, negative selection nodes
(i, m, ) negative instance node (i, m, x ) child. instance node
effectively implements process putting xi become clear
feature vectors described below. arriving either positive negative instance
node, consideration xi complete must move decision next
example xi+1 . Thus, positive instance node (i, m, x+ ) single child decision node
401

fiDoppa, Fern, & Tadepalli

(i + 1, m, d), negative instance node single child decision node (i + 1, + 1, d),
noting number mistakes incremented negative nodes.
final details search space structure ensure k mistakes
allowed force search paths terminate n . particular, decision
node (i, m, d) = k, know mistakes allowed hence
decisions allowed. Thus, node form path n
goes positive instance nodes (i, m, x+ ), . . . , (N, m, x+ ), reflects none
{xi , . . . , xN } . Figure 9 shows example search space construction.
Given search space, polynomial size (since k N ), one verify
set k fewer instances path root n goes
negative instance nodes instances positive instance nodes
instances . Further, possible path goes either positive negative
instance node instance k negative nodes. Thus direct
correspondence paths mistake sets .
describe assign features node way allows
heuristic function select path effectively construct set . node
u feature vector (u) = (x, s, b). component x p-dimensional feature vector
correspond one xi . component N -dimensional vector
si {1, 1} implement selection instances. Finally b binary value
equal 1 non-instance nodes 0 positive negative instance nodes.
mapping nodes feature vectors follows. decision node (i, m, d),
zeros, except b = 1. positive selection node (i, m, s+ ) zeros except si = 1
b = 1. Negative selection nodes similar except si = 1. positive instance
node (i, m, x+ ) feature vector (xi , 0, 0) negative instance nodes (i, m, x )
feature vector (xi , 0, 0). Finally feature vector n zeros.
key idea note heuristic function effectively select positive
negative selection node setting weight si positive negative respectively.
particular, set negative selection nodes visited (and hence negative instance nodes)
correspond first k fewer negative weight values component feature
vector. Thus, heuristic select set negative nodes wants go through,
k. path three types nodes encountered
cost function must rank. First, control nodes (decision selection nodes)
b = 1. Next positive instance nodes feature
vector (xi , 0, 0) k negative instance nodes feature vectors (xi , 0, 0).
cost function easily rank n higher control nodes setting weight
b negative. find heuristic weights x component allows n
ranked highest solution original minimum disagreement problem.
solution disagreement problem easy see
solution HC-Search consistency problem selecting heuristic spans
proper set .

References
Agarwal, S., & Roth, D. (2005). Learnability Bipartite Ranking Functions. Proceedings
International Conference Learning Theory (COLT), pp. 1631.
402

fiHC-Search: Learning Framework Search-based Structured Prediction

Batra, D., Yadollahpour, P., Guzman-Rivera, A., & Shakhnarovich, G. (2012). Diverse MBest Solutions Markov Random Fields. Proceedings European Conference
Computer Vision (ECCV), pp. 116.
Boyan, J. A., & Moore, A. W. (2000). Learning Evaluation Functions Improve Optimization Local Search. Journal Machine Learning Research (JMLR), 1, 77112.
Brill, E. (1995). Transformation-Based Error-Driven Learning Natural Language Processing: Case Study Part-of-Speech Tagging. Computational Linguistics, 21 (4),
543565.
Chang, K.-W., Samdani, R., & Roth, D. (2013). Constrained Latent Variable Model
Coreference Resolution. Proceedings Conference Empirical Methods
Natural Language Processing (EMNLP), pp. 601612.
Chang, M.-W., Ratinov, L.-A., & Roth, D. (2012). Structured Learning Constrained
Conditional Models. Machine Learning Journal (MLJ), 88 (3), 399431.
Chen, C., Kolmogorov, V., Zhu, Y., Metaxas, D., & Lampert, C. H. (2013). Computing
Probable Modes Graphical Model. Proceedings International
Conference Artificial Intelligence Statistics (AISTATS).
Chen, S., Fern, A., & Todorovic, S. (2014). Multi-Object Tracking via Constrained Sequential Labeling. appear Proceedings IEEE Conference Computer Vision
Pattern Recognition (CVPR).
Collins, M. (2000). Discriminative Reranking Natural Language Parsing. Proceedings
International Conference Machine Learning (ICML), pp. 175182.
Collins, M. (2002). Ranking Algorithms Named Entity Extraction: Boosting
Voted Perceptron. ACL.
Crammer, K., Dekel, O., Keshet, J., Shalev-Shwartz, S., & Singer, Y. (2006). Online PassiveAggressive Algorithms. Journal Machine Learning Research (JMLR), 7, 551585.
Daume III, H. (2006). Practical Structured Learning Techniques Natural Language
Processing. Ph.D. thesis, University Southern California, Los Angeles, CA.
DaumeIII, H., & Marcu, D. (2005). Learning Search Optimization: Approximate Large
margin methods Structured Prediction. ICML.
Dietterich, T. G., Hild, H., & Bakiri, G. (1995). Comparison ID3 Backpropagation
English Text-to-Speech Mapping. Machine Learning Journal (MLJ), 18 (1), 5180.
Domke, J. (2013). Structured Learning via Logistic Regression. Proceedings Advances
Neural Information Processing Systems (NIPS), pp. 647655.
Doppa, J. R., Fern, A., & Tadepalli, P. (2012). Output Space Search Structured Prediction. Proceedings International Conference Machine Learning (ICML).
Doppa, J. R., Fern, A., & Tadepalli, P. (2013). HC-Search: Learning Heuristics Cost
Functions Structured Prediction. Proceedings AAAI Conference Artificial
Intelligence (AAAI).
Doppa, J. R., Fern, A., & Tadepalli, P. (2014a). Structured Prediction via Output Space
Search. Journal Machine Learning Research (JMLR), 15, 13171350.
403

fiDoppa, Fern, & Tadepalli

Doppa, J. R., Yu, J., Ma, C., Fern, A., & Tadepalli, P. (2014b). HC-Search Multi-Label
Prediction: Empirical Study. appear Proceedings AAAI Conference
Artificial Intelligence (AAAI).
Doppa, J. R., Yu, J., Tadepalli, P., & Getoor, L. (2009). Chance-Constrained Programs
Link Prediction. Proceedings NIPS Workshop Analyzing Networks
Learning Graphs.
Doppa, J. R., Yu, J., Tadepalli, P., & Getoor, L. (2010). Learning Algorithms Link
Prediction based Chance Constraints. Proceedings European Conference
Machine Learning (ECML), pp. 344360.
Felzenszwalb, P. F., & McAllester, D. A. (2007). Generalized A* Architecture. Journal
Artificial Intelligence Research (JAIR), 29, 153190.
Fern, A. (2010). Speedup Learning. Encyclopedia Machine Learning, pp. 907911.
Fern, A., Yoon, S. W., & Givan, R. (2006). Approximate Policy Iteration Policy
Language Bias: Solving Relational Markov Decision Processes. Journal Artificial
Intelligence Research (JAIR), 25, 75118.
Goldberg, Y., & Elhadad, M. (2010). Efficient Algorithm Easy-First Non-Directional
Dependency Parsing. Proceedings Human Language Technologies: Conference
North American Chapter Association Computational Linguistic (HLTNAACL), pp. 742750.
Grubb, A., & Bagnell, D. (2012). SpeedBoost: Anytime Prediction Uniform NearOptimality. Journal Machine Learning Research - Proceedings Track, 22, 458466.
Hal Daume III, Langford, J., & Marcu, D. (2009). Search-based Structured Prediction.
Machine Learning Journal (MLJ), 75 (3), 297325.
Harvey, W. D., & Ginsberg, M. L. (1995). Limited Discrepancy Search. Proceedings
International Joint Conference Artificial Intelligence (IJCAI), pp. 607615.
Hazan, T., & Urtasun, R. (2012). Efficient Learning Structured Predictors General
Graphical Models. CoRR, abs/1210.2346.
Hoffgen, K.-U., Simon, H.-U., & Horn, K. S. V. (1995). Robust Trainability Single
Neurons. Journal Computer System Sciences, 50 (1), 114125.
Huang, L., Fayong, S., & Guo, Y. (2012). Structured Perceptron Inexact Search.
Proceedings Human Language Technology Conference North American
Chapter Association Computational Linguistics (HLT-NAACL), pp. 142
151.
Jiang, J., Teichert, A., Daume III, H., & Eisner, J. (2012). Learned Prioritization
Trading Accuracy Speed. Proceedings Advances Neural Information
Processing (NIPS).
Kaariainen, M. (2006). Lower Bounds Reductions. Atomic Learning Workshop.
Keshet, J., Shalev-Shwartz, S., Singer, Y., & Chazan, D. (2005). Phoneme Alignment based
Discriminative Learning. Proceedings Annual Conference International
Speech Communication Association (Interspeech), pp. 29612964.
404

fiHC-Search: Learning Framework Search-based Structured Prediction

Khardon, R. (1999). Learning Take Actions. Machine Learning Journal (MLJ), 35 (1),
5790.
Kulesza, A., & Taskar, B. (2012). Determinantal Point Processes Machine Learning.
Foundations Trends Machine Learning, 5 (2-3), 123286.
Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional Random Fields: Probabilistic
Models Segmenting Labeling Sequence Data. Proceedings International
Conference Machine Learning (ICML), pp. 282289.
Lam, M., Doppa, J. R., Hu, X., Todorovic, S., Dietterich, T., Reft, A., & Daly, M. (2013).
Learning Detect Basal Tubules Nematocysts SEM Images. ICCV Workshop
Computer Vision Accelerated Biosciences (CVAB). IEEE.
Li, Q., Ji, H., & Huang, L. (2013). Joint Event Extraction via Structured Prediction
Global Features. Proceedings 51st Annual Meeting Association
Computational Linguistics (ACL), pp. 7382.
McAllester, D. A., Hazan, T., & Keshet, J. (2010). Direct Loss Minimization Structured
Prediction. Proceedings Advances Neural Information Processing Systems
(NIPS), pp. 15941602.
Meshi, O., Sontag, D., Jaakkola, T., & Globerson, A. (2010). Learning Efficiently
Approximate Inference via Dual Losses. Proceedings International Conference
Machine Learning (ICML), pp. 783790.
Mohan, A., Chen, Z., & Weinberger, K. Q. (2011). Web-Search Ranking Initialized
Gradient Boosted Regression trees. Journal Machine Learning Research - Proceedings Track, 14, 7789.
Nivre, J. (2008). Algorithms Deterministic Incremental Dependency Parsing. Computational Linguistics, 34 (4), 513553.
Park, D., & Ramanan, D. (2011). N-Best Maximal Decoders Part Models. Proccedings
IEEE International Conference Computer Vision (ICCV), pp. 26272634.
Payet, N., & Todorovic, S. (2013). SLEDGE: Sequential Labeling Image Edges
Boundary Detection. International Journal Computer Vision (IJCV), 104 (1), 15
37.
Qian, X., Jiang, X., Zhang, Q., Huang, X., & Wu, L. (2009). Sparse Higher Order Conditional Random Fields Improved Sequence Labeling. Proceedings International
Conference Machine Learning (ICML).
Read, J., Pfahringer, B., Holmes, G., & Frank, E. (2011). Classifier Chains Multi-Label
Classification. Machine Learning, 85 (3), 333359.
Ross, S., & Bagnell, D. (2010). Efficient Reductions Imitation Learning. Journal
Machine Learning Research - Proceedings Track, 9, 661668.
Ross, S., Gordon, G. J., & Bagnell, D. (2011). Reduction Imitation Learning
Structured Prediction No-Regret Online Learning. Journal Machine Learning
Research - Proceedings Track, 15, 627635.
405

fiDoppa, Fern, & Tadepalli

Roth, D., & tau Yih, W. (2005). Integer Linear Programming Inference Conditional
Random Fields. Proceedings International Conference Machine Learning
(ICML), pp. 736743.
Samdani, R., & Roth, D. (2012). Efficient Decomposed Learning Structured Prediction.
Proceedings International Conference Machine Learning (ICML).
Sen, P., Namata, G., Bilgic, M., Getoor, L., Gallagher, B., & Eliassi-Rad, T. (2008). Collective Classification Network Data. AI Magazine, 29 (3), 93106.
Sontag, D., Meshi, O., Jaakkola, T., & Globerson, A. (2010). data means less inference:
pseudo-max approach structured learning. Proceedings Advances Neural
Information Processing Systems (NIPS), pp. 21812189.
Stoyanov, V., & Eisner, J. (2012). Easy-first Coreference Resolution. Proceedings
International Conference Computational Linguistics (COLING), pp. 25192534.
Stoyanov, V., Ropson, A., & Eisner, J. (2011). Empirical Risk Minimization Graphical
Model Parameters Given Approximate Inference, Decoding, Model Structure.
Proceedings International Conference Artificial Intelligence Statistics
(AISTATS), pp. 725733.
Sutton, C. A., & McCallum, A. (2009). Piecewise Training Structured Prediction.
Machine Learning Journal (MLJ), 77 (2-3), 165194.
Syed, U., & Schapire, R. (2010). Reduction Apprenticeship Learning Classification. Proceedings Advances Neural Information Processing Systems (NIPS),
pp. 22532261.
Taskar, B., Guestrin, C., & Koller, D. (2003). Max-Margin Markov Networks. Proceedings
Advances Neural Information Processing Systems (NIPS).
Tsochantaridis, I., Hofmann, T., Joachims, T., & Altun, Y. (2004). Support Vector Machine Learning Interdependent Structured Output Spaces. Proceedings
International Conference Machine Learning (ICML).
Tsochantaridis, I., Joachims, T., Hofmann, T., & Altun, Y. (2005). Large Margin Methods
Structured Interdependent Output Variables. Journal Machine Learning
Research (JMLR), 6, 14531484.
Vogel, J., & Schiele, B. (2007). Semantic Modeling Natural Scenes Content-Based
Image Retrieval. International Journal Computer Vision (IJCV), 72 (2), 133157.
Weiss, D. (2014). Structured Prediction Cascades code. http://code.google.com/p/
structured-cascades/.
Weiss, D., Sapp, B., & Taskar, B. (2010). Sidestepping Intractable Inference Structured
Ensemble Cascades. Proceedings Advances Neural Information Processing
Systems (NIPS), pp. 24152423.
Weiss, D., & Taskar, B. (2010). Structured Prediction Cascades. Journal Machine
Learning Research - Proceedings Track, 9, 916923.
Wick, M. L., Rohanimanesh, K., Bellare, K., Culotta, A., & McCallum, A. (2011). SampleRank: Training Factor Graphs Atomic Gradients. Proceedings International
Conference Machine Learning (ICML).
406

fiHC-Search: Learning Framework Search-based Structured Prediction

Wick, M. L., Rohanimanesh, K., Singh, S., & McCallum, A. (2009). Training Factor Graphs
Reinforcement Learning Efficient MAP Inference. Proceedings Advances
Neural Information Processing Systems (NIPS), pp. 20442052.
Xu, Y., Fern, A., & Yoon, S. (2009a). Learning Linear Ranking Functions Beam Search
Application planning. Journal Machine Learning Research, 10, 1571
1610.
Xu, Y., Fern, A., & Yoon, S. W. (2009b). Learning Linear Ranking Functions Beam
Search Application Planning. Journal Machine Learning Research (JMLR),
10, 15711610.
Xu, Y., Fern, A., & Yoon, S. W. (2010). Iterative Learning Weighted Rule Sets
Greedy Search. Proceedings International Conference Automated Planning
Systems (ICAPS), pp. 201208.
Xu, Z., Weinberger, K., & Chapelle, O. (2012). Greedy Miser: Learning Test-time
Budgets. Proceedings International Conference Machine Learning (ICML).
Ye, N., Lee, W. S., Chieu, H. L., & Wu, D. (2009). Conditional Random Fields
High-Order Features Sequence Labeling. Proceedings Advances Neural
Information Processing Systems (NIPS), pp. 21962204.
Yu, H., Huang, L., Mi, H., & Zhao, K. (2013). Max-Violation Perceptron Forced
Decoding Scalable MT Training. Proceedings Empirical Methods Natural
Language Processing (EMNLP), pp. 11121123.
Zhang, W., & Dietterich, T. G. (1995). Reinforcement Learning Approach job-shop
Scheduling. Proceedings International Joint Conference Artificial Intelligence
(IJCAI), pp. 11141120.

407


