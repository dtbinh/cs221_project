Journal Artificial Intelligence Research 50 (2014) 923970

Submitted 06/14; published 08/14

Belief Tracking Planning Sensing: Width,
Complexity Approximations
Blai Bonet

bonet@ldc.usb.ve

Departamento de Computacion
Universidad Simon Bolvar
Caracas, Venezuela

Hector Geffner

hector.geffner@upf.edu

ICREA & Universitat Pompeu Fabra
Roc Boronat 138
08018 Barcelona, Spain

Abstract
consider problem belief tracking planning setting states valuations set variables partially observable, beliefs stand sets
states possible. problem intractable worst case,
recently shown deterministic conformant contingent problems, belief tracking exponential width parameter often bounded small. work,
extend results two ways. First, introduce width notion applies
non-deterministic problems well, develop factored belief tracking algorithm exponential problem width, show applies existing benchmarks. Second,
introduce meaningful, powerful, sound approximation scheme, beam tracking,
exponential smaller parameter, problem causal width, much broader applicability. illustrate value algorithm large instances problems
Battleship, Minesweeper, Wumpus, yields state-of-the-art performance
real-time.

1. Introduction
Planning incomplete information formulated search problem belief space
two issues need addressed: keeping track beliefs, searching goal
belief (Bonet & Geffner, 2000). two tasks intractable worst case
compact representations, approach adopted recent conformant
contingent planners beliefs handled using SAT, regression techniques, logical
normal forms CNF, DNF, OBDDs, search goal beliefs guided
domain-independent heuristics (Bertoli, Cimatti, Roveri, & Traverso, 2001; Hoffmann &
Brafman, 2006; Bryce, Kambhampati, & Smith, 2006; To, Pontelli, & Son, 2011; Shani &
Brafman, 2011; Brafman & Shani, 2012).
Recently, complexity belief tracking deterministic conformant contingent
planning shown exponential problem width parameter often
bounded small (Palacios & Geffner, 2009; Albore, Palacios, & Geffner, 2009).
bound follows family translations developed compiling planning problems
beliefs planning problems states. translations exponential problem
c
2014
AI Access Foundation. rights reserved.

fiBonet & Geffner

width, deterministic conformant problems result problems solved
classical planners.
difficulty extending results Palacios, Albore, Geffner nondeterministic setting consequence special role played initial situation
deterministic problems. case, uncertainty, particular, uncertainty
observations, action preconditions, goals, one matters
complete planner, result uncertainty initial situation. nondeterministic setting, hand, uncertainty produced dynamically result
application non-deterministic actions. Moreover, uncertain initial situation
always modeled fully known initial situation dummy non-deterministic
action, opposite transformation simple. Indeed, non-deterministic effects
compiled deterministic effects conditional value hidden variables,
number hidden variables required must grow planning horizon
(Weld, Anderson, & Smith, 1998; Albore, Ramirez, & Geffner, 2010).
aim work study computational complexity belief tracking
terms novel width parameters apply deterministic non-deterministic
planning problems, formulation practical approximate belief tracking algorithms
efficient effective even problems large width. achieve
considering two decomposition schemes belief tracking, three algorithms based
decompositions. precisely, introduce:
1. width notion planning close correspondence notion introduced
Palacios, Albore, Geffner applies non-deterministic problems
well.
2. first belief tracking algorithm, factored belief tracking, sound complete
deterministic non-deterministic problems P , runs time space
exponential problem width w(P ). algorithm based decomposition
problem P projected subproblems PX , one every goal precondition
variable X, one including variables relevant X.
3. second belief tracking algorithm, causal belief tracking, based alternative
decomposition scheme, subproblems PX defined every goal, precondition,
observable variable X, one including variables causally relevant
X. algorithm sound complete large meaningful class problems,
still time exponential problem width, space exponential
causal width problem often much smaller.
4. final belief tracking algorithm, beam tracking sound incomplete approximation causal belief tracking, often practical enough, even problems
large widths, runs time space exponential problem causal
width.
power last algorithm, beam tracking, shown empirically large
instances problems Minesweeper, Battleship, Wumpus, state-of-the924

fiBelief Tracking Planning Sensing

art performance obtained real-time combining belief tracking algorithm
simple heuristics action selection.1
organization paper follows structure, preceded overview
relevant notation background, followed description experiments,
discussion related work, summary. paper integrates results two conference
papers (Bonet & Geffner, 2012b, 2013), providing proofs additional details. work
related proposals tractable forms belief tracking logical probabilistic
frameworks (Doucet, Freitas, Murphy, & Russell, 2000; Amir & Russell, 2003), yet
two key differences. One start exact account used determine
certainty whether goal achieved action applicable. second
belief tracking accounts planning complete formulas. order
sound complete planner, beliefs observations, action preconditions,
goals required. important observations, action preconditions,
goals given, structure actions, sensors, goals exploited
track beliefs efficiently. observation implicit lazy belief tracking
schemes planning incomplete information appeal SAT-solvers (Hoffmann &
Brafman, 2006) regression (Shani & Brafman, 2011). Well say related work
Section 12.

2. Model
model planning sensing simple extension model conformant
planning goal achieved certainty spite uncertainty initial
situation action effects (Goldman & Boddy, 1996; Smith & Weld, 1998). model
conformant planning characterized tuple = hS, S0 , SG , A, F
finite state space,
S0 non-empty set possible initial states, S0 S,
SG non-empty set goal states, SG S,
set actions A(s) denoting sets actions applicable S,
F non-deterministic state-transition function F (a, s) denotes nonempty set possible successor states follow action s, A(s).
solution conformant model action sequence maps possible initial state
goal state. precisely, = ha0 , . . . , an1 conformant plan possible
sequence states s0 , s1 , . . . , sn s0 S0 si+1 F (ai , si ), = 0, . . . , n 1,
action ai applicable si sn goal state.
Conformant planning cast path finding problem beliefs, defined
sets states deemed possible time point (Bonet & Geffner, 2000).
initial belief b0 S0 , belief ba results action belief state b is:
ba = {s0 | b s0 F (a, s)} ,

(1)

1. real-time animation algorithm several instances Minesweeper seen https:
//www.youtube.com/watch?v=U98ow4n87RA, source code graphical interfaces
obtained http://code.google.com/p/belief-tracking.

925

fiBonet & Geffner

action applicable b applicable state b. formulation,
conformant plan action sequence maps initial belief b0 goal belief bG ;
i.e., set goal states.
Contingent planning planning sensing planning uncertainty
feedback. model contingent planning model conformant planning extended
sensor model. sensor model function O(s, a) mapping state-action pairs
observations tokens o. expression O(s, a) means token possible
observation true state system last action done.
observed token provides partial information true possibly hidden system
state token may possible different states. two different tokens o1
o2 belong O(s, a), means either one observed
last action. Sensing deterministic noiseless O(s, a) contains one token, else
non-deterministic noisy. contingent model similar POMDPs (Kaelbling,
Littman, & Cassandra, 1999) uncertainty encoded sets states rather
probability distributions.
Executions contingent setting sequences ha0 , o0 , a1 , o1 , . . .i pairs actions
ai observations oi . b = bi belief state action ai applied oi
token observed, belief ba action = ai given (1),
belief bi+1 = boa follows observing token is:
boa = {s | ba O(s, a)} .

(2)

execution ha0 , o0 , a1 , o1 , . . .i possible starting initial belief b0 , action
ai applicable belief bi (i.e., ai A(s) bi ), 0, belief bi
empty.
off-line contingent planning, action selection strategy sought ensures
possible executions end goal belief. on-line contingent planning, action
selection strategy sought ensures single execution results
interaction real system simulator, ends goal belief. cases,
action selection strategy expressed partial function beliefs, called policy,
(b) action belief b. function partial
defined initial belief b0 non-goal beliefs b; namely,
reached b0 off-line planning, reached
b0 on-line planning.

3. Language
Syntactically, conformant problems expressed compact form set
state variables, convenience assume multi-valued.2 precisely,
conformant planning problem tuple P = hV, I, A, Gi V stands problem
variables X, one finite discrete domain DX , set clauses
V -literals defining initial situation, set actions, G set V -literals
defining goal. Every action precondition P re(a) given set V -literals,
2. Multi-valued variables compiled boolean variables compilation affects syntactic
structure problem. principle, structure could recovered boolean encodings
would result complex formulation.

926

fiBelief Tracking Planning Sensing

set conditional effects C E1 | . . . |En C Ei sets (conjunctions)
V -literals. conditional effect non-deterministic n > 1; else n = 1 effect
deterministic.
problem P = hV, I, A, Gi defines conformant model S(P ) = hS, S0 , SG , A, F i,
set possible valuations variables V , S0 SG sets valuations
satisfy G respectively, A(s) set operators whose preconditions true
s, F (a, s) non-deterministic transition function results collecting
successor states may follow selecting one head Ei conditional
effect C E1 | . . . |En whose body C true s.3
Contingent problems described extending syntactic description conformant problems compact encoding sensor model. this, assume set
V 0 observable multi-valued variables , necessarily disjoint state variables
V (i.e., state variables may observable), formulas Wa (Y = y) state
variables, action possible value observable variable .
formula Wa (Y = y) implicitly encodes states observation literal =
possible last action executed. formulas Wa (Y = y) different
values DY must logically exhaustive, every state-action pair must give rise
observation = y. addition, formulas Wa (Y = y) different values
logically exclusive, every state-action pair gives rise single observation =
sensing deterministic. state variable X observable, Wa (X = x)
formula X = x.
contingent problem P tuple P = hV, I, A, G, V 0 , W defines contingent
model made conformant model hS, S0 , SG , A, F determined first four
components P , sensor model O(a, s) determined last two components,
O(a, s) iff valuation observable variables V 0 =
true formula Wa (Y = y) W true DY .
standard language representing contingent problems compact form featuring incomplete information, non-deterministic actions sensors. two
distinctive features relation similar languages use multi-valued variables,
distinction state observable variables.
illustration, X encodes position agent, encodes position
object seen agent X = , observable variable
Z {Y es, N o} encoding whether
object seen agent
W
W not, defined
formulas Wa (Z = es) = lD (X = lY = l), Wa (Z = N o) = lD (X = lY = l),
set possible locations action. deterministic
sensor. non-deterministic sensor could used if, example, agent cannot detect
0
presence
W object certain locations l . this, suffices push
disjunct lD0 (X = l) formulas characterizing Wa (Z = es) Wa (Z = N o),
two observations Z = es Z = N would possible agent
position l D0 .
Since conformant problem hV, I, A, Gi expressed contingent problem
hV, I, A, G, V 0 , W one (dummy) observable variable Z, Z
/ V domain
3. conditional effects must consistent sense explained below.

927

fiBonet & Geffner

DZ = {>}, observation model Wa (Z = >) = true every action a, focus
general contingent problem.
Likewise, convenience, variable boolean, often represent literals
= true = f alse . Similarly, variable observable, unless stated
otherwise, assume observation model deterministic formula
Wa (Y = f alse) becomes complement formula Wa (Y = true).

4. Belief Tracking Problem Flat Belief Tracking Algorithm
execution problem P = hV, I, A, G, V 0 , W sequence ha0 , o0 , a1 , o1 , . . .i
actions ai observations oi ai observation oi full
valuation observation variables V 0 . execution ha0 , o0 , . . . , , possible
problem P non-empty belief state b0 , generates sequence beliefs b0 , . . . , bn
preconditions action ai true belief bi , belief states
bi empty. problem belief tracking contingent planning problem
determining execution possible final belief state achieves goal:
Definition 1. Belief tracking planning (BTP) problem determining whether
execution ha0 , o0 , a1 , o1 , . . .i planning problem P = hV, I, A, G, V 0 , W possible,
so, whether resulting belief state makes goal G true.
complete planner needs solve problem determining actions applicable given execution, observations may result, whether goal
achieved. machinery develop aimed slightly general
belief tracking problem generalized executions: executions ha0 , o0 , a1 , o1 , . . .i
observations oi partial rather full valuations observable variables. Moreover, suffices consider generalized executions observations
valuations single observable variable. observations oi represented
observation literals `i :
Definition 2. Generalized belief tracking planning (GBTP) problem determining whether generalized execution ha0 , `0 , a1 , `1 , . . .i planning problem P =
hV, I, A, G, V 0 , W possible, so, whether achieves given goal, precondition,
observation literal.
Given procedure deciding GBTP, simple decide BTP execution
calling procedure deciding GBTP generalized execution 0 replaces
observation oi sequence observation literals true oi separated
NO-OP actions (actions effects).
Proposition 3. BTP polynomial-time reducible GBTP.
interest belief tracking planning, find convenient focus
generalized problem, none belief update equations algorithms sensitive
distinction. simplicity, however, talk belief tracking, make
explicit distinctions BTP GBTP, normal generalized
executions, needed.
928

fiBelief Tracking Planning Sensing

plain solution belief tracking problem given updates expressed
Eqs. 1 2, belief states explicitly represented sets states, states full
valuations state variables, actions, transition function, observations
obtained syntactic representation problem:
Definition 4. flat belief tracking algorithm execution ha0 , o0 , a1 , o1 , . . .i
problem P , starts belief b0 contains states satisfy initial situation,
setting next belief state bi+1 boa using (1) (2) b = bi , = ai , = oi .
complexity flat belief tracking exponential number state variables. Yet,
often state variables add complexity tracking beliefs. Syntactically,
happens state variable X initially known, variables causally
relevant X (see below) initially known well, neither X variable
causally relevant X appears head non-deterministic effect. say
variables determined value every reachable belief known, fully
predicted preceding actions preceding values. example, variable
encodes position agent Wumpus game determined, initial
value known effect actions variable deterministic depends
previous value.
Formally, define set variables determined problem
largest set state variables X problem initially known every
state variable X 0 causally relevant X belongs set. set variables
easily identifiable low polynomial time. complexity flat belief tracking
expressed follows:
Theorem 5. Flat belief tracking exponential |VU |, VU = V \ VK VK
set state variables determined problem.
Given result, first question arises bad naive approach flat belief
tracking. Interestingly, following result decision problem shows flat belief
tracking bad worst case:
Theorem 6. BTP GBTP Turing complete class PNP .
is, BTP GBTP decided polynomial time using oracle NP (SAT,
example), every decision problem decided polynomial time
oracle, decided polynomial time oracle BTP GBTP.
complexity class PNP includes classes NP coNP, contained PSPACE
(Sipser, 2006).

5. Structure Width
possible improve complexity flat belief tracking specific problem
exploiting structure problem. introducing graph captures
structure, convenient make explicit assumptions restrict
generality approach make definitions simpler. First, assume
formula encoding initial situation contains positive negative literals; i.e., unit
clauses only. restrictive assumption since set clauses encoded
929

fiBonet & Geffner

help dummy observations. Second, assume non-deterministic effects
involve one variable heads. Again, always achieved adding extra
variables effects. example, non-deterministic effect X Z | Z
action replaced deterministic effects X W Z X W Z,
along non-deterministic effect true W | W , W new random boolean
variable initially unknown changes randomly. Third, assume problem
consistent, meaning initial situation logically consistent initial
belief state b0 empty, effects action consistent
heads deterministic conditional effects applicable reachable state s, along
choice heads non-deterministic conditional effects applicable
s, jointly consistent.4 Last, assume every observable variable relevant
variable appearing precondition goal, notion relevance spelled
below. Observable variables dont comply condition eliminated
problem relevant information loss.
5.1 Relevance Width
variable X, whether state variable, observable variable, both, immediate
causes X defined follows:
Definition 7. variable X immediate cause variable problem P , written
X Ca(Y ), iff X 6= , either X occurs body C conditional effect C
E1 | |En occurs head Ei , 1 n, observable variable X
occurs formula Wa (Y = y) DY action a.
Basically, X immediate cause uncertainty X may affect
uncertainty directly, variables. X necessarily immediate
cause X appears precondition action affects , preconditions
must known certainty, hence, propagate uncertainty. notion
causal relevance given transitive closure immediate cause relation:
Definition 8. X causally relevant P X = , X Ca(Y ), X causally
relevant variable Z causally relevant .
order test whether given literal Z = z known certain execution
ha0 , a1 , . . . , ai actions conformant setting, possible show one
progress state variables X causally relevant Z:
Proposition 9. Belief tracking deterministic non-deterministic conformant setting exponential maximum number non-determined variables causally
relevant variable appearing action precondition goal.
bound closely related bound obtained Palacios Geffner
deterministic setting. Indeed, refer number non-determined state variables
4. semantic point view, means state s0 possible successor state
action applicable s, i.e. s0 F (a, s), iff every literal X = x true s0 , X = x head
deterministic non-deterministic conditional effect action whose body true s, X = x
true s, effect action X = x0 head, x0 6= x, whose body
true s.

930

fiBelief Tracking Planning Sensing

causally relevant X, conformant width X, set width P
maximum conformant width variables X appear action preconditions
goals, Proposition 9 simply says belief tracking non-deterministic conformant
problem exponential problem width. width notion, however, exactly
equivalent notion Palacios Geffner used deterministic setting
defined variables rather literals. say distinction
below. general, however, two accounts yield similar widths deterministic
benchmarks.
contingent setting, variables whose uncertainty may affect variable
Z causally relevant Z. situation similar one arising
Bayesian networks (Pearl, 1988), relevance flows causally, direction
arrows, evidentially, observations direction arrows.
Definition 10. X evidentially relevant P X observable variable
causally relevant X.
notion relevance captures transitive closure (directional) causal evidential relations:
Definition 11. X relevant X causally evidentially relevant , X
relevant variable Z relevant .
Thus, variable X = W1 relevant variable = Wn iff chain variables
Wi , 1 n 1, variable Wi causally evidentially relevant next
variable Wi+1 chain. example, X causally relevant Z,
observable variable, relevant Z evidentially relevant X X
causally relevant Z.
Bayesian networks, relevance relations understood graph-theoretically.
Thus, directed edge Z stands Z immediate cause , X
causally relevant X 0 directed path X X 0 , X evidentially
relevant X 0 X observable variable, directed path X 0
X. terms Bayesian networks, relevance relation takes transitive closure
causal evidential relationships, encodes potential dependency given
may observed, using information certain variables observed (are
observable). Unlike Bayesian networks, means however relevance relation
symmetric. Namely, cause X relevant , automatically
relevant X causally relevant observable variable Z, may
itself. context variable set variables problem relevant
X:
Definition 12. context variable X, Ctx(X), denotes set state variables
problem relevant X.
width variable defined number state variables context
determined:
Definition 13. width variable X, w(X), |Ctx(X) VU |, VU = V \ VK
VK set state variables determined.
931

fiBonet & Geffner

width problem then:
Definition 14. width w(P ) conformant contingent problem P , whether deterministic not, maxX w(X) X ranges variables appear goal
action precondition P .
relation width complexity expressed as:
Theorem 15. Belief tracking P exponential w(P ).
proof theorem follows results algorithm
achieves complexity bound presented. significance theorem belief
tracking planning domains width bounded constant becomes polynomial
number problem variables. see examples below. complexity bound
similar ones obtained deterministic conformant contingent problems (Palacios
& Geffner, 2009; Albore et al., 2009). main difference new account applies
non-deterministic problems well. new account simpler general,
see, slightly less tight deterministic domains.

6. Examples
illustrate definitions benchmark domains, starting DET-Ring
(Cimatti, Roveri, & Bertoli, 2004). domain, ring n rooms
agent move forward backward along ring. room window
opened, closed, locked closed. Initially, status windows
known agent know initial location. domain agent
means obtaining information status windows position,
goal windows locked. plan deterministic conformant problem
repeat n times actions (close, lock, f wd), skipping last f wd action. Alternatively,
action f wd replaced action bwd throughout plan. state variables
problem encode agent location Loc {1, . . . , n}, status window,
W (i) {open, closed, locked}, = 1, . . . , n. location variable Loc (causally) relevant
window variable W (i), window variable W (i) relevant Loc W (k)
k 6= i, W (i) causally relevant observable variable. None variables
determined largest contexts window variables W (i) include two
variables, W (i) Loc. result width domain 2, independent
number state variables W (i) grows number rooms n. causal
graph problem, directed edge X means X immediate cause
shown Figure 1a.
NON-DET-Ring variation domain actions f wd bwd
agent non-deterministic effect status windows locked,
capturing possibility external events open close unlocked windows.
non-determinism effect causal graph variables. result,
change effect contexts domain width remains bounded equal
2 number rooms n.
last version domain considered Cimatti et al. NON-DET-Ring-Key,
key required lock windows. initial position key known,
932

fiBelief Tracking Planning Sensing

Loc

Loc

W (1)

W (2)



W (n)

W (1)

(a) DET-Ring

W (2)

KLoc



W (n)

H

(b) CONT-NON-DET-Ring-Key

Figure 1: Causal graphs problems DET-Ring (left) CONT-NON-DET-Ring-Key
(right). latter, variable H observable tells us whether key held
not. arc X denotes X immediate cause . graphs, variables
preconditions goals underlined yellow colored, observable variables
enclosed blue circle.
yet agent tries collect key room key there, agent
key. conformant plan problem repeat actions pick f wd, n
times, skipping last f wd action, following plan DET-Ring. NON-DETRing-Key, additional state variable, KLoc {1, . . . , n, hand}, represents
key location. agent location Loc relevant KLoc relevant window
variable W (i). result, size contexts Ctx(W (i)) problem width
increase 1. width however remains bounded value 3 independently
number rooms n.5
presence partial observability, analysis similar necessary
consider relevance relationships arise due presence observable variables.
example, one express agent always observe whether holding
key not, boolean observable variable H (deterministic) observation
model Wa (H = true) given KLoc = hand, actions a. new relevance
relation among state variables arises adding observable variable
Loc KLoc, causally relevant H. Before, Loc relevant KLoc
way around. Yet affect domain width remains 3
n. causal graph resulting domain shown Figure 1b.

7. Factored Belief Tracking
Belief tracking problem P exponential width w(P ) P . algorithm
achieves bound exploits relevance relations encoded variable contexts
decomposing beliefs. particular, variable relevant variable,
problem width 1, beliefs variable maintained separately.
belief decomposition obtained projecting problem P smaller problems PS
set state variables P . Semantically, projected problems PS capture
dynamics problem P expressed subset state variables. Syntactically,
projected problems PS defined means logical notion projection.
5. problem encoded making holding key precondition rather condition
locking windows. encoding, variable KLoc longer relevant window
variables W (i) according definitions, KLoc = hand must known certainty,
hence uncertainty windows variables W (i) affected uncertainty KLoc.
result encoding, domain width reduces 2.

933

fiBonet & Geffner

logical projection formula F subset variables refers formula F 0
defined variables S, valuations satisfy F 0 exactly
extended valuations satisfy F (Darwiche & Marquis, 2002). Likewise,
projection conditional effect C E 1 | |E n conditional effect CS ES1 | |ESn
body C effects E replaced logical projections CS ESi
respectively.
Definition 16. projection problem P = hV, I, A, G, V 0 , W set variables
V problem PS = hVS , , , GS , VS0 , WS VS S, GS
initial goal formulas G logically projected variables S,
preconditions conditional effects projected S, VS0 V 0 , WS set
formulas Wa (Y = y) W logically projected variables S.
notion projected planning problem used setting
classical planning introducing class admissible heuristics known pattern databases
(Edelkamp, 2001). use richer contingent setting decomposing belief
tracking problem P belief tracking problem smaller problems PS obtained
P projecting away state variables P .
defining target subproblems PS decomposition, notice variables
state observable variables P S, belong VS0
VS , meaning observable variables projected problem PS .
Moreover, formulas variables WS become Wa (Y = y) = true
DY , meaning problem PS , observations = possible
y, regardless state last action done. observations thus completely
irrelevant PS effect. case, P PS share set actions
set observations even actions observations PS may
defined smaller set state variables.
target subproblems PS defined terms set state variables
relevant precondition goal variables. Recall assume observable
variable problem relevant action precondition goal, else variable
could safely removed.
Definition 17. projection problem P variable X, denoted PX ,
projection PS P set variables = Ctx(X), Ctx(X) context
X P ; i.e., set state variables P relevant X.
Two basic properties projected problems PX are:
Proposition 18. variable X appears goal precondition, number state
variables PX determined bounded w(P ).
Proposition 19. execution ha0 , o0 , a1 , o1 , . . .i possible P , possible
PX state variable X P .
b belief results execution P , call bX belief
results execution projected problem PX . completeness
decomposition global belief b P expressed terms local beliefs bX
subproblems PX . treat beliefs b bX relations database
934

fiBelief Tracking Planning Sensing

state variables beliefs columns possible combination values
(states local states) rows. projection b, set variables thus
represents combination values variables possible b,
join bX
nbY represents combination values x sets variables
two beliefs bX x coincide variables X
. example, b contains valuations (states) X = 1, = 1 X = 2, = 2,
projection {X} b contain valuations X = 1 X = 2. Likewise, b0 contains
= 1, Z = 1 = 1, Z = 2, join b
n b0 contain X = 1, = 1, Z = 1
X = 1, = 1, Z = 2.
Theorem 20. state variable X, let b bX beliefs result execution
possible P PX . Then,
X bX = X b .

(3)

Equation 3 states literal X = x possible true global belief b iff
possible belief bX results execution projected problem
PX . exactly type completeness needed planning variable
X involved action precondition goal. stronger form completeness
formulas, expressed


nX bX = b ,

(4)


n stands join operation X ranges precondition goal variables
problem, needed, actually necessarily true, even state
variables appear context Ctx(X). example, value boolean variable
Z initially unknown, variables X initially false, action conditional
effects Z X Z Z results belief b two states, corresponding
terms Z X Z X . X precondition goal variables
relevant other, projected problem PX contain variables
X Z, projected problem PY contain variables Z. belief
bX resulting execution action PX include local states
corresponding terms Z X Z X, belief PY include
local states corresponding terms Z Z . Clearly, projection b
bX (bY ) variable X (Y ) coincide dictated (3), join two local
beliefs bX yield global belief b would correspond (4); indeed,
formula X false latter former. (3), prove
inductively size execution that:
Theorem 21. 1) execution possible P iff possible subproblems
PX X precondition goal variable P . 2) execution precondition
goal variable X, X = x (resp. X 6= x) true b iff X = x (resp. X 6= x) true
bX , b bX beliefs result executing P PX respectively.
Since plain belief tracking projected problem PX exponential size
PX , bounded w(P ) determined variables excluded, follows that:
935

fiBonet & Geffner

Theorem 22. Flat belief tracking projected problems PX X
precondition goal variable P , provides sound complete factored algorithm
belief tracking P time space exponential width P .
call algorithm, factored belief tracking. order check whether precondition
goal literal X = x true execution, factored belief tracking checks whether
X = x true belief bX results execution subproblem PX .
execution possible action precondition X = x true bX results
empty belief subproblem. Theorem 22 thus says factored belief tracking
sound complete algorithm BTP time space complexity exponential
problem width. Indeed, since every observable variable relevant precondition
goal variable X assumption, every direct cause Z relevant X
evidentially relevant X. Thus, formula Wa (Y = y) evaluated bX
determine whether observation = necessary, possible impossible applying
action a. Thus, factored belief tracking solves generalized BTP problem.
illustration Theorem 22, let us go back DET-Ring problems P whose
structure analyzed before. theorem implies order check whether given
possible execution achieves goal P , sufficient check whether goal literal
W (i) = locked, 1 n, achieved execution subproblem PW (i) . Thus,
factored belief tracking P done O(n2 ) time since n subproblems
PW (i) , one involving 2 variables: W (i) constant-size domain Loc
domain size n.
exact situation arises non-deterministic conformant problem NON-DET
Ring whose causal graph one DET-Ring. hand, NONDET-Ring-Key, subproblems must keep track KLoc variable encoding key
location, thus belief update operation requires O(n3 ) time, still much better
flat belief tracking P requires time exponential n. complexity
results applies problem longer conformant agent observe whether
holding key not.
experimental figures domains shown Table 1, factored belief
tracking used combination simple heuristics. experiments run
Xeon Woodcrest 5140 CPU running 2.33 GHz 8 GB RAM. planner
KACMBP Cimatti et al. uses OBDD-based belief representation cardinality
heuristics, solve problems n = 20 rooms, producing plans 206
steps slightly 1,000 seconds NON-DET-Ring-Key. Conformant planners
T0 (Palacios & Geffner, 2009) cannot used problem non-deterministic.
Tables 1a 1b show scalability factored belief tracking algorithm context
greedy best-first search P
heuristic h(b), similar one used Albore, Ramirez,
Geffner (2011), h(b) = ni=1 h(bi ), bi belief factor projected
problem goal variable W (i) representing status ith window, h(bi )
representing fraction states bi goal W (i) = locked false. displayed
tables, resulting planner scales polynomially, NON-DET-Ring-Key
100 rooms, produces plan 1, 111 actions 783.1 seconds. contingent
version problem agent detects key room, CONT-DETRing-Key, policy greedy cardinality heuristic h(b) = maxni=1 |bi | used instead,
936

fiBelief Tracking Planning Sensing

n

steps

exp.

time

n

steps

exp.

time

n

avg. steps

avg. time

10
20
30
40
50
60
70
80
90
100

68
138
208
277
345
415
476
545
610
679

355
705
1,055
1,400
1,740
2,090
2,395
2,740
3,065
3,410

< 0.1
0.1
0.9
3.1
8.3
18.6
34.5
62.8
106.4
171.0

10
20
30
40
50
60
70
80
90
100

118
198
278
488
438
468
543
616
682
1,111

770
1,220
1,670
3,210
2,570
2,660
3,080
3,480
3,880
7,220

< 0.1
0.8
4.2
15.2
34.4
52.2
100.6
172.9
285.6
783.1

10
20
30
40
50
60
70
80
90
100

326.8 4.3
1, 036.0 13.5
2, 068.0 26.5
3, 462.9 47.2
5, 130.7 71.0
7, 070.9 100.9
9, 334.1 127.6
11, 724.0 162.2
14, 617.4 204.6
17, 891.2 252.3

0.0
0.1
0.5
1.8
4.4
9.3
17.5
30.6
50.0
79.0

(a) DET-Ring-Key

(b) NON-DET-Ring-Key

(c) CONT-DET-Ring-Key

Table 1: Results conformant contingent Ring problems obtained combining factored belief tracking simple heuristics. data point panel (c) contingent
problem average (and sample standard deviation) 1,000 random instances. Times
seconds. column exp. contains number expansions.

ties broken randomly, bi belief factor goal variable W (i).
seen Table 1c, resulting planner runs polynomial time solve problems
100 rooms. Thus, heuristic policy weak, long executions result,
belief tracking problem efficient scales well.

8. Causal Belief Tracking
Factored belief tracking exponential problem width. many problems, however,
width may high method usable practice. illustration,
consider problem P state variables X1 , . . . , Xn+1 , observable variables O1 , . . . ,
Oi true iff Xi = Xi+1 . sensors thus Wa (Oi = true) = (Xi = Xi+1 )
Wa (Oi = f alse) = (Xi 6= Xi+1 ) actions 1 n. Let us assume
actions problem may affect Xi variables introduce
causal relations among them, state variables appear preconditions
goals. causal graph problem shown Figure 2. width n + 1
state variables interact. Indeed, variable Xi relevant variable Xk ,
relevance flowing Xi Xi+1 , vice versa, variables causally relevant
observable variable Oi evidentially relevant both. result
problem P projected problems PXi coincide denote problem,
contexts state variables include state variables.
focus different decomposition belief tracking maps problem P
smaller subproblems PXc whose size bounded number state variables
causally relevant given precondition, goal, observation variable. new width
measure called causal width problem. problem shown Figure 2
width n + 1 causal width 2. explore belief tracking algorithms
exponential problem causal width analyze conditions
937

fiBonet & Geffner

X1

X2

X3



Xn

O1

O2

O3





Xn+1

Figure 2: Causal graph 2-layer network example state variables X1 , . . . , Xn+1
observable variables O1 , . . . , On+1 . immediate causes observable Oi
variables Xi Xi+1 . Precondition goal variables appear underlined
yellow box, observable variables appear within blue circle. Since Xi variables
relevant other, width problem n + 1. hand, since
two variables causally relevant precondition, goal, observable variable,
causal width problem 2.
complete. this, first generalize make explicit decomposition underlying
factored belief tracking algorithm:
Definition 23. decomposition problem P pair = hT, Bi, set
variables X appearing P , called target variables decomposition, B
collection beams B(X) associated target variable made
state variables P .
decomposition = hT, Bi maps P set subproblems PXD , one variable
X , corresponds projections P state variables beam B(X).
decomposition underlies factored belief tracking is:
Definition 24. factored decomposition F = hTF , BF P decomposition
target variables TF given state variables X appearing action preconditions goals,
beams BF (X) given state variables relevant X.
Factored belief tracking flat belief tracking applied subproblems determined
factored decomposition. algorithms introduce next based different
decomposition:
Definition 25. causal decomposition C = hTC , BC P decomposition
target variables TC given observable variables state variables appearing
action precondition goals, beams BC (X) given state variables
causally relevant X.
causal decomposition determines larger number subproblems, subproblems
generated observable variables, subproblems smaller beams
BC (X), contain state variables causally relevant X opposed
variables relevant X. causal width problem given size
largest beam causal decomposition, discounting variables determined
problem:
Definition 26. causal width variable X problem P , wc (X), number
state variables causally relevant X determined. causal width
938

fiBelief Tracking Planning Sensing

P maxX wc (X), X ranges target variables causal decomposition
P .
first simplest belief tracking algorithm defined causal decomposition
call Decoupled Causal Belief Tracking, runs time space
exponential problem causal width:
Definition 27. Decoupled causal belief tracking (Decoupled CBT) flat belief tracking
applied independently problems PXC determined causal decomposition
C = hTC , BC P . subproblem PXC problem P projected variables
BC (X) X TC ; i.e., PXC = PBC (X) .
Since causal width never greater width often much smaller, Decoupled
CBT runs much faster factored belief tracking general. This, however, comes
price express using expression b denoting projection (the states
the) belief b variables S.
Theorem 28. Decoupled CBT runs time space exponential wc (P ),
sound complete. is, target variable X causal decomposition,
b bX beliefs resulting execution P PXC respectively,
bX BC (X) b necessarily true, bX BC (X) b not.
One reason incompleteness beliefs bX associated different target
variables X assumed independent Decoupled CBT may
true. Indeed, causal decomposition problem may give rise beam BC (Y )
involving variable X, second beam BC (Z) involving variable X another
variable X 0 . variable observed, X = x may become false,
observation Z may lead X 0 = x0 becoming false well. Yet, Decoupled CBT,
inference cannot captured information flow across beams. factored
decomposition situation cannot happen variable X 0 relevant variable
X hence beams contain X necessarily contain X 0 (X 0 relevant X
causally relevant Z evidentially relevant X).
causal decomposition, beams kept small closing relevance
relation, result, beliefs beams longer independent. However,
regarding beliefs tables relations, consistency relation among local beliefs
causal decomposition enforced means join operation. resulting
algorithm Coupled Causal Belief Tracking, abbreviated simply Causal Belief Tracking:
Definition 29. Causal Belief Tracking (CBT) belief tracking algorithm operates
causal decomposition C = hTC , BC setting beliefs b0X time 0 beam
BC (X) projection BC (X) initial belief, X TC , successive beliefs
bi+1
X as:
bi+1
n{(biY )oa : TC relevant X}
(5)
X = BC (X)
= ai = oi action observation time execution,
(biY )oa boa Eqs. 1-2 b = biY .
CBT, beliefs tracked independently subproblems PXC
causal decomposition; rather, beliefs first progressed filtered independently,
939

fiBonet & Geffner

merged projected back onto beams, making consistent
other. progression filtering local beliefs causal decomposition performed time space exponential problem causal width, full consistency
operation captured join-project operation (5) requires time worst case
exponential problem width:
Theorem 30. CBT space exponential causal width problem, time
exponential width.
CBT sound incomplete. However, range problem CBT complete,
unlike Decoupled CBT, large meaningful enough, includes example three
domains considered experiments below: Battleship, Minesweeper
Wumpus. express completeness conditions CBT introducing notion
memory variables:
Definition 31. state variable X memory variable problem P value X k
variable X time point k execution determined uniquely observation
value X X time point i, k, actions execution, initial
belief state problem.
example, static variables memory variables change thus
knowing value time point determines value point. Determined
variables (Section 4) memory variables since value X k variables
determined initial belief actions done time k. Likewise, variables
permutation domains actions permute values variables (Amir & Russell,
2003), memory variables. three sufficient conditions state variable
memory variable easy check. problem said causally
decomposable following condition holds:
Definition 32. problem P causally decomposable every pair beams BC (X)
BC (X 0 ) causal decomposition P non-empty intersection, X 0
observation variable, either 1) variables intersection memory variables,
2) variable W causal decomposition relevant X X 0
whose causal beam BC (W ) contains BC (X) BC (X 0 ).
problem causally decomposable, filtering implemented updates
CBT using Equation 5 suffices completeness:
Theorem 33. Causal belief tracking always sound complete causally decomposable problems.
importance result many meaningful domains whose problem
instances causally decomposable; particular, domains variables appear
two different beams static (this include Minesweeper), domains variables
appear two different beams either static determined (this includes Wumpus,
non-static variable agent location determined), domains
hidden non-static state variables appear one beam (this includes Battleship
hidden non-static variables appear intersection beams), cases
well. Sect. 11.4, present variation Wumpus monster moves
non-deterministically grid instance causally-decomposable
problem.
940

fiBelief Tracking Planning Sensing

9. Approximation: Beam Tracking
causal belief tracking algorithm shows possible track beliefs planning
sound complete manner large meaningful class problems, considering
beliefs subproblems smaller factored decomposition.
algorithm, however, space exponential causal width problem,
time exponential problem width. global consistency operation
enforced (5). Beam tracking final belief tracking algorithm consider:
replaces global consistency operation local consistency operation
performed polynomial time. Beam tracking thus approximation causal belief
tracking aimed efficient effective rather complete.
Definition 34. Beam tracking belief tracking algorithm operates causal
decomposition C = hTC , BC i, setting beliefs b0X time 0 projection initial
belief beam X TC , setting successive beliefs bi+1
X two steps. First,


set progressed filtered belief ba b = bX , = ai = oi ,
ai oi action observation time execution. Then, local form
consistency enforced upon beliefs means following updates fixed
point reached:
i+1
(6)
bi+1
nbi+1
)
X = BC (X) (bX
refers target variable causal decomposition BC (Y )
BC (X) non-empty.
filtering represented iterative update Eq. 6 defines form relational
arc consistency (Dechter & Beek, 1997) equality constraints among beams sharing
common variables enforced polynomial time space size beams. Beam
tracking remains sound complete. causally decomposable problems, however,
incompleteness sole result replacing global local consistency.

10. Extensions, Modeling, Width
testing beam tracking algorithm empirically, present two simple extensions
language contingent planning useful modeling, briefly discuss
modeling choices affect causal width problem. first extension allows
use defined variables preconditions goals; second extension allows use
state constraints restricting possible value combination subsets variables.
10.1 Defined Variables
variable Z domain DZ defined function subset state variables
problem, function belief variables. example, boolean variable
Z defined true two variables X equal, third variable W
known true. Defined variables Z function set SZ state variables
function belief variables, handled action preconditions
goals introducing beam decomposition includes variables SZ
along variables relevant causally relevant them, according whether
decomposition factored causal. width causal width problem follow
941

fiBonet & Geffner

then, before, size largest beam factored causal decompositions
determined variables excluded.
10.2 State Constraints
State constraints used restrict value combinations given subsets state variables. game Battleship, example, modeled state variables associated
cells grid representing whether cell part ship, size
ship cell belongs (if any), relative position cell within ship
cell belongs (if any), whether ship placed vertically horizontally. state variables, however, independent, indeed, ship size 10
horizontally placed cell (0, 0), cells (0, i), {0, 1, . . . , 9} must belong (the
same) ship.
Formally, state constraint represented formula C state variables
encoded means dummy observable variable always observed
true, observed true states C holds; i.e., model
Wa (Y = true) = C every action a. implementation, however, pays treat
constraints C relations (the set valuations satisfy C), include
joins beliefs include variables C. causal belief tracking
effect completeness complexity algorithm, beam tracking,
changing update (6)
i+1
n C1
n
n Cn )
n bi+1
bi+1

X = BC (X) (bX

(7)

C1 , . . . , Cn state constraints whose variables included BC (X) BC (Y ),
makes local consistency stronger effect complexity algorithm. Moreover, one pair beams state constraint, state constraints
increase causal width problem constant factor 2 most, yet
effective causal width problem change, beams associated
dummy observables introduced constraints redundant ignored.
later case, using beam tracking, constraints Ci need stored
extensional form relations handled intentionally boolean functions
test whether assignment join two beams satisfies constraint.
10.3 Modeling Width
complexity belief tracking algorithms function width causal width
problem, turns depends way problem encoded. Often small
changes encoding drastic effect resulting widths. example,
Wumpus problem (Russell & Norvig, 2009), natural define conditions
stench signal received setting observation model to:

W
W
Wa (stench = true) = c (pos = c) c0 wumpc0
pos encodes agent position, c ranges possible cells, c0 ranges cells
adjacent c, wumpc0 denotes presence wumpus c0 . encoding,
however, results beam observable variable stench includes wumpc
942

fiBelief Tracking Planning Sensing

szx,y

hitx,y

waterx,y

nhitsx,y

ancx,y

hzx,y

Figure 3: Causal graph fragment Battleship. Circled variables observable
others state variables. problem one type variable cell (x, y)
grid. Causal width problem 5.
variables, hence whose size grows grid size. better alternative results
beams bounded causal width exploit fact position agent pos
determined. Taking advantage this, observable variable stench replaced
observable variables stenchc , one cell grid, sensors characterized
model:
Wa (stenchc = true) = (pos = c)

W

c0

wumpc0 .

beams stenchc variables contain four wumpc0 variables, one cell
c0 adjacent c. way, causal width Wumpus problem becomes bounded
independent grid size, number wumpus pits (see below).
idea
W generalized automated. observation model form Wa (Z =
z) = x (x) (x), (x) formula constructed determined variables,
replaced observation models Wa (Zx = z) = (x) (x) expanding
number observable variables. Likewise, multiple observation models Wai (Z = z) =
one observable variable Z different actions {ai }iR conveniently replaced
observation models Wai (Zi = z) = , R different observable variables Zi ,
different formulas involve different variables. alternatives domain encoding
difference bounded unbounded causal width, hence, whether
complexity beam tracking grow polynomially exponentially.

11. Experiments
tested beam tracking large instances Battleship, Minesweeper, Wumpus, combination simple heuristics action selection make use computed beliefs. width problems bounded, hence, neither factored
causal belief tracking used except small instances. hand,
domains small bounded causal widths encodings provided, hence
beam tracking runs efficiently time space. Exact belief tracking
domains difficult (Kaye, 2000; Scott, Stege, & Rooij, 2011), sizes
instances considered much larger used contingent planning. Moreover,
domains full contingent solutions. thus compare on-line
planner relies handcrafted heuristics two reported solvers rely belief
tracking algorithms tailored domains. consider non-deterministic version
Wumpus domain. results obtained Xeon Woodcrest 5140 CPU
running 2.33 GHz 8GB RAM.
943

fiBonet & Geffner

11.1 Battleship
Battleship popular two-player guessing game. standard version consists four
ships length 2, 3, 4 5 units secretly placed 10-by-10 grid, ship
adjacent diagonally adjacent another. task sink ships firing torpedos
specific cells. fired torpedo, told whether torpedo hits water ship.
ship sunk cells hit. problem encoded 6 state variables
per cell (x, y):6 hitx,y tells torpedo fired cell, szx,y tells size
ship occupying cell (0 ship), hzx,y tells ship placed horizontally
vertically (true ship), nhitsx,y tells number hits ship (0
ship), ancx,y tells relative position ship cell (0 ship).
single observable boolean variable water deterministic sensor model given
Wf ire(x,y) (waterx,y = true) = (szx,y = 0). action model complex firing
torpedo (x, y) may cause change variables associated cells (x0 , 0 ).
Indeed, denotes maximum size ship (5 standard game), f ire(x, y)
includes conditional effects variables referring cells (x0 , 0 ) vertical
horizontal distance units. goal problem achieve equality
nhitsx,y = szx,y cells may contain ship. State constraints used
constraining sets state variables described above. encoding, causal beams
never contain 5 variables, even though problem width bounded
grows grid size. Figure 3 shows fragment causal graph Battleship.
Table 2 shows results two policies: random policy fires non-fired cell
random, greedy policy fires non-fired cell likely contain ship.
Approximations probabilities obtained beliefs maintained beam
tracking.7 difference performance two policies shows beliefs
informative. Moreover, 10 10 game, agent fires 40.0 6.9 torpedos
average, matching quite closely average results Silver Veness (2010)
obtained combination UCT (Kocsis & Szepesvari, 2006) action selection,
particle filter (Doucet et al., 2000) hand-tuned domain belief tracking.
approach, however, involves 65,000 simulation per action result order 2 seconds
per game 10 10 instances, greedy approach takes 0.0096 seconds per game.
11.2 Minesweeper
objective Minesweeper clear rectangular minefield without detonating mine.
play either opens flags cell. first case, cell contains mine, game
terminated; otherwise integer counting number mines surrounding cell
revealed. initial configuration minesweeper consists n minefield k
randomly-placed mines. three standard difficulty levels game
made 8 8, 16 16 16 30 boards 10, 40 99 mines respectively.
6. rich encoding allows accommodate observation ship fully sunk.
experiments, however, observation used order compare results reported
Silver Veness (2010).
7. Probabilities events defined variables beam obtained ratio number states
beam satisfy event total number states beam.

944

fiBelief Tracking Planning Sensing

avg. time per
dim

policy

#ships

#torpedos

decision

game

10 10
20 20
30 30
40 40

greedy
greedy
greedy
greedy

4
8
12
16

40.0 6.9
163.1 32.1
389.4 73.4
723.8 129.2

2.4e-4
6.6e-4
1.2e-3
2.1e-3

9.6e-3
1.0e-1
4.9e-1
1.5

10 10
20 20
30 30
40 40

random
random
random
random

4
8
12
16

94.2 5.9
387.1 13.6
879.5 22.3
1,572.8 31.3

5.7e-5
7.4e-5
8.5e-5
9.5e-5

5.3e-3
2.8e-2
7.4e-2
1.4e-1

Table 2: Results Battleship. table contains results greedy random
policies described text. 10 10 board, 4 ships sizes 2, 3, 4 5.
size board increased n, number ships size gets multiplied
n. Average sample standard deviation number torpedos required sunk
ships, calculated 10,000 random instances board, shown. Average times
seconds.

problem encoded 3mn boolean state variables minex,y , openedx,y
f laggedx,y denote presence/absence mine cell (x, y) whether cell
opened flagged, mn observable variables obsx,y domain = {0, . . . , 9}.
two type actions open(x, y) f lag(x, y) first precondition effect f laggedx,y openedx,y , second precondition minex,y
effect f laggedx,y . sensor model given formulas specify integer
agent receives opening cell terms status minex0 ,y0 variables
surrounding cells. formulas are:
Wopen(x,y) (obsx,y = 9) = minex,y ,
Wopen(x,y) (obsx,y = k) = minex,y

W

tN (x,y,k) ,

0 k < 9 ,

Wopen(x,y) (obsx0 ,y0 = k) = true ,

(x0 , 0 ) 6= (x, y) 0 k 9 ,

Wf lag(x,y) (obsx0 ,y0 = k) = true ,

(x0 , 0 ) 0 k 9 ,

N (x, y, k) terms 8 cell variables minex0 ,y0 surrounding cell (x, y)
make exactly k literals true. initial situation, variables openedx,y
f laggedx,y false minex,y unknown. goal problem get disjunction f laggedx,y openedx,y cell (x, y) without triggering explosion.
beams result factored decomposition contain 3mn state variables, making beams identical resulting unbounded width 3mn. causal
width, hand, 9 causal beams openedx,y f laggedx,y identical
contain 3 variables, beams obsx,y contain 9 minex0 ,y0 variables
cells (x0 , 0 ) surround cell (x, y) along variable minex,y . Figure 4
contains fragment causal graph Minesweeper.
945

fiBonet & Geffner

minex0 ,y0

minex,y

f laggedx,y

openedx,y

obsx,y
Figure 4: Sketch causal graph Minesweeper. observable variables obsx,y
state variables minex,y , f laggedx,y openedx,y cell (x, y). cell (x0 , 0 )
represents one adjacent cells (x, y). Since 8 cells, causal width
problem 9.
avg. time per
dim

#mines

density

%win

#guess

decision

game

88
16 16
16 30
32 64

10
40
99
320

15.6%
15.6%
20.6%
15.6%

83.4
79.8
35.9
80.3

606
670
2,476
672

8.3e-3
1.2e-2
1.1e-2
1.3e-2

0.21
1.42
2.86
2.89

Table 3: Results Minesweeper. table contains results three standard levels
game plus larger instance. Average results 1,000 runs shown. Average
times seconds.

Table 3 shows results three standard levels game much larger
instance. Battleship, greedy policy used action selection makes use beliefs
computed beam tracking, flagging opening cell certain content, else
selecting cell lowest probability containing mine opening it,
probabilities approximated beliefs beams indicated before. Despite
complexity game, NP-complete checking consistency (Kaye, 2000) coNPcomplete inference (Scott et al., 2011), beam tracking scales well solves difficult
games quickly. Moreover, results shown table competitive recently
reported Lin, Buffet, Lee, Teytaud (2012), obtained combination
UCT action selection, domain-specific CSP solver tracking beliefs. success
ratios report are: 80.2 0.48% 8 8 instances 10 mines, 74.4 0.5%
16 16 instances 40 mines, 38.7 1.8% 16 30 instances 99
mines. authors report times.
11.3 Wumpus
Wumpus game (Russell & Norvig, 2009) consists maze agent
moves around looking gold avoiding hidden pits wumpus monsters.
Initially, agent know positions gold, pits wumpuses, senses
glitter cell gold, senses stench breeze adjacent
cell wumpus pit respectively. n instance described known state
variables position orientation agent, hidden boolean variables
cell tell whether pit, wumpus, nothing cell. One
946

fiBelief Tracking Planning Sensing

heading
gold-pos

pos

pitx0 ,y0

wumpx0 ,y0

glitter

deadx0 ,y0

breezex,y

stenchx,y

Figure 5: Fragment causal graph Wumpus. observable variables
breezex,y , stenchx,y deadx,y , state variables heading, pos, pitx,y wumpx,y ,
(x, y) ranging grid cells. Cells (x0 , 0 ) stand cells adjacent (x, y).
causal width problem 4 4 cells, state variables heading
pos determined.
hidden state variable stores position gold. observable variables boolean:
glitter, breezex,y , stenchx,y deadx,y , (x, y) ranging different cells.
actions move forward, rotate right left, grab gold. causal width
encoding 4 problem width grows n. Figure 5 shows fragment
causal graph Wumpus. size causal beams breeze stench
variables bounded 4 cell 4 neighbors heading
position variables agent determined.
Table 4 shows results different grid sizes number pits wumpus,
agent selects actions greedy policy based heuristic returns length
minimum-length safe path nearest cell may contain gold. beliefs
computed beam tracking used determine cells safe (known contain
wumpus pit) may contain gold. aware tested
scalable solver Wumpus making comparison, exception recent
LW1 planner built work (Bonet & Geffner, 2014). figures table
show clearly beam tracking computes beliefs effectively efficiently domain.
instance, 30 30 instances 32 pits 32 wumpus solved successfully 89%
time, less 4.4 seconds average. Moreover, unsolved instances
actually shown unsolvable sense agent could reach unvisited
cell safe manner. proved unsolved instance calling SAT solver
propositional theory encodes game literals learned agent
execution.
11.4 Non-Deterministic Moving Wumpus
order evaluate beam tracking complex non-deterministic domain (the NONDET-Ring-Key domain Section 7 small width), designed non-deterministic
variant Wumpus domain. Moving Wumpus one wumpus grid
wumpus moves around non-deterministically everytime agent moves.
grid still contains hidden pits hidden gold, order make game safer
agent, wumpus sensor enhanced detect position wumpus
(euclidean) distance less 3 agent (else safe strategy escaping
death general).
947

fiBonet & Geffner

avg. time per
dim

#pits/#wumpus

%density

#decisions

%win

decision

game

55
10 10
15 15
20 20
25 25
30 30
35 35
40 40
45 45
50 50

1/1
2/2
4/4
8/8
16 / 16
32 / 32
64 / 64
128 / 128
256 / 256
512 / 512

8.0
4.0
3.5
4.0
5.1
7.1
10.4
16.0
25.2
40.9

22,863
75,507
165,263
295,305
559,595
937,674
2,206,905
4,471,168
6,026,625
7,492,503

93.6
98.3
97.9
97.8
94.0
89.0
54.3
7.3
0.8
0.1

3.8e-4
9.6e-4
1.6e-3
2.4e-3
3.8e-3
4.7e-3
3.7e-3
2.8e-3
8.6e-3
1.3e-2

8.7e-3
7.2e-2
2.6e-1
7.2e-1
2.1
4.4
8.2
12.7
51.8
100.4

Table 4: Results Wumpus. size, performed 1,000 runs. table shows
total number density pits wumpus grid, total number decisions
across runs, percentage runs agent found gold, average
time seconds per decision game.

Moving Wumpus causally decomposable thus incompleteness beam tracking
domain due replacement full consistency among beams done
CBT weaker efficient (relational) arc consistency done beam tracking.
see this, observe variable memory variable position
wumpus WLoc. However, two beams causal decomposition
contain variable: beam WLoc beam observable variable
tells position wumpus, former beam contained latter beam.8
Experimental results beam tracking domain presented Table 5
policy obtained using AOT lookahead algorithm based AO* (Bonet & Geffner, 2012a)
builds lookahead tree depth 10 using 50 expansions, heuristic function
measures distance agent position closest unvisited cell.
algorithm evaluated different instances grids nn n = 4, 6, 8, . . . , 20,
number pits equal (n 4)/2. grid size, performed 1,000
evaluations different initial configurations wumpus, pits gold randomly
placed. instance game may turn unsolvable gold isolated
agent pits, agent finds position safe movement,
agent exceeded maximum number actions (set 3 times number
cells grid).

8. Indeed, general version problem involves wumpuses move non-deterministically
grid. version causally decomposable beams positions wumpuses
(one wumpus) contained beam observable variable. general case,
problem would causal width equal m.

948

fiBelief Tracking Planning Sensing

avg. time per
dim

#pits

%density

#decisions

%win

decision

game

44
66
88
10 10
12 12
14 14
16 16
18 18
20 20

0
1
2
3
4
5
6
7
8

0.0
2.7
3.1
3.0
2.7
2.5
2.3
2.1
2.0

13,770
30,666
54,528
85,635
123,921
159,977
231,307
309,919
362,816

97.6
95.0
94.8
93.0
93.6
93.4
91.7
90.0
90.8

3.5e-2
1.6e-1
4.1e-1
8.5e-1
1.3
2.2
3.1
4.1
5.3

4.9e-1
5.1
22.7
73.5
173.4
352.4
722.0
1,282.3
1,942.8

Table 5: Results Non-Deterministic Moving Wumpus domain. grid size,
averages 1,000 runs shown. table shows total number density pits
grid, total number decisions across runs, percentage runs
agent found gold, average time seconds per decision game.

12. Related Work
formulation paper closely related recent translation-based approaches
conformant contingent planning compile beliefs away (Palacios & Geffner, 2009;
Albore et al., 2009). translations, however, assume problems deterministic.
account yields similar widths deterministic benchmarks,
simpler, defined multi-valued variables, general,
handles non-deterministic actions. Yet account less tight deterministic problems. illustration, = {x1 xn } actions ai ,
conditional effect xi G, = 1, . . . , n, conformant problem goal G width
1 Palacios Geffners account, width n ours. relevance account based
literals indeed finer one based variables difficult
generalize non-deterministic settings. difference seem practical
effects benchmarks disjunctions initial situation exclusive
implicitly encode possible values set multi-valued variables. Another important
difference approaches complete translations always exponential
problem width, complexity bound worst case; i.e., variables contexts
highly correlated, actual complexity factored belief tracking much lower.
notion width appears Bayesian networks inference exponential
width network (Pearl, 1988). Three differences pointed
relation notion width 1) exploit knowledge certain variables
observable, 2) determine use knowledge certain variables
determined, 3) make use distinction action conditions preconditions planning. example, problem agent go n doors
whose status, open closed, observed agent near door,
width smaller n modeled dynamic Bayesian network, door
variables affect agent location variable. setting, however, problem width
949

fiBonet & Geffner

1 status door need known agent open, close
walk door.
causal decomposition resulting causal belief tracking algorithms similarly related ideas variable splitting renaming graphical models,
variable X appearing different factors replaced different variables Xi , one per
factor (Choi & Darwiche, 2006; Ramirez & Geffner, 2007), problem width
reduced. Then, equality constraints relating Xi variables must enforced.
Approximate belief tracking algorithms dynamic bayesian networks POMDPs
appealed idea decomposing global beliefs variables local beliefs subsets variables (Boyen & Koller, 1998; Shani, Poupart, Brafman, & Shimony,
2008). key difference causal belief tracking algorithm provide
conditions type decomposition remains sound complete.
hand, deal uncertainty represented sets states, probability
distributions.
number logical schemes representing tracking beliefs used
developed contingent planning, appealing OBDDs, CNF, DNF representations
(Bertoli et al., 2001; Bryce et al., 2006; et al., 2011), relevance considerations (Tran,
Nguyen, Son, & Pontelli, 2013), lazy SAT regression techniques (Hoffmann & Brafman, 2005; Rintanen, 2008; Shani & Brafman, 2011). None approaches, however,
tried domains considered paper instances similar size.
Indeed, causal width domains bounds complexity beam tracking, similar bound known schemes unlike beam tracking complete.
Moreover, principle schemes handle non-determinism naturally,
methods based SAT not. K-replanner (Bonet & Geffner, 2011)
based efficient effective belief tracking method polynomial
fully general cannot deal non-deterministic actions. follow LW1 planner
(Bonet & Geffner, 2014) shares features K-replanner complete width-1
problems.
experimental perspective, several comments questions order
relation beam tracking algorithms used belief tracking contingent
planners existing benchmarks. First all, practically benchmarks used
far contingent planning easy belief tracking point view. Indeed,
quadratic linear time representation beliefs CLG LW1 respectively,
shown adequate problems, including Wumpus problems above.
exception Minesweeper, belief tracking provably NP-hard
linear approximation LW1 turns much weaker beam tracking, failing
solve without guessing instances beam tracking solve
way (Bonet & Geffner, 2014). means that, whether width problems
low high, effective width 1, cases, beam tracking cannot help
computationally, actually, may degrade performance (except Minesweeper), beam
tracking exponential problem causal width, lower width general
usually higher 1. effective width problem P minimum non-negative
integer value contingent translation Xi (P ) (Palacios & Geffner, 2009; Albore
et al., 2009) solution. effective width problem never greater width
much smaller width causal width. example,
950

fiBelief Tracking Planning Sensing

avg. time per
dim

#mines

%density

%succ

%failure

%aborted

decision

game

88
16 16
30 16

10
40
99

15.6
15.6
20.6

93.0
94.0
65.0

7.0
6.0
6.0

0.0
0.0
29.0

0.8
4.9
12.4

56.3
1,268.4
5,998.6

Table 6: Comparison SDR on-line planner Minesweeper instances. SDR fed
random hidden states solutions (action sequences) computed beam tracking
guessing. planner task check applicability actions given
solution whether goal holds. instance size, SDR tested 100 different
random problems. column failure indicates number times SDR able
verify correct solution, column aborted indicates number times
SDR terminated early due bug. Times seconds. Beam tracking takes
seconds solving instances (see Table 3).

problem actions ai conditional effects map valuations vi set variables
X1 , . . . , Xn goal literal = y, width causal width smaller
n variables Xi causally relevant . Yet effective width
problem may 1 values Xi variables observed directly
inferred observations, also, goal achieved without using
actions all. sense, notion effective width provides lower bound
number state variables whose uncertainty must tracked jointly order make
problem solvable, notions width, characterized syntactically, provides upper
bound number state variables whose uncertainty must tracked jointly
solution would missed. gap two bounds large indeed,
obtaining syntactic characterizations former open problem.
related question various belief tracking algorithms used contingent planning regression, OBDDs, CNF, DNF, scale domains.
general comparison complete exponential algorithms incomplete polynomial algorithms beam tracking (over domains bounded causal width) would
fair, would still interesting find easy cases algorithms scale polynomially exponentially. Performing tests, however,
simple, requires getting code planners would
follow fixed common policy instance, thus leaving planning component aside.
Moreover, even fixing policy instance, enough, planners
off-line hence track beliefs many possible executions one,
case on-line planners.
purpose illustration performed test one difficult
domains, Minesweeper, supplying on-line planner SDR (Shani & Brafman, 2011)
execution computed beam tracking along hidden initial state
execution. setting, on-line planner SDR planning, rather
tracking beliefs problem verify goal achievement preconditions
given applicable action time point. Minesweeper instances solved
951

fiBonet & Geffner

beam tracking without guessing; i.e., pure inference first fixed choice. Table 6
shows results SDR tracks beliefs using form regression (Rintanen, 2008;
Shani & Brafman, 2011). Two observations made comparing results
table Table 3 beam tracking. First, SDR takes 56.3, 1,268.4
5,998.6 seconds average verifying solutions 8 8, 16 16 30 16 instances
respectively, beam tracking takes 0.21, 1.42 2.86 seconds finding solutions
following greedy policy. Since finding solutions expensive verifying
one must least identify applicable actions time point difference
performance turns several orders magnitude, growing grid size.
addition, regression mechanism SDR fails verify correct solutions several cases
aborts failure large number cases large instances. case,
performance gap surprising: belief tracking Minesweeper NP-hard, thus
complete algorithms regression run exponential time worst case,
beam tracking remains polynomial causal width domain bounded.
challenging problems, gap performance beam tracking complete belief
tracking algorithms similar. Beam tracking useful causal width
problem bounded large, trading principled way completeness
tractability.

13. Summary
Effective belief tracking crucial planning incomplete information sensing.
problem intractable general, shown elsewhere belief tracking deterministic problems exponential width parameter often bounded
small. work, introduced related formulation applies nondeterministic problems well. factored belief tracking algorithm results set
projected problems whose size bounded problem width. beliefs goals
preconditions obtained directly beliefs projected problems
maintained independently. developed different decomposition
scheme belief tracking algorithm maintains beliefs smaller projections,
provided conditions algorithm complete. Causal belief tracking
space exponential problem causal width remains time exponential problem width, global consistency beliefs smaller projections need
enforced. Finally, beam tracking sound incomplete approximation causal belief
tracking global consistency replaced local powerful form consistency.
Beam tracking runs time space exponential problem causal width
often much smaller problem width. tested beam tracking large
instances Battleship, Minesweeper, Wumpus, combination simple heuristics
action selection, performance compares well state-of-the-art solvers
using orders-of-magnitude less time. future, would explore extensions
proposed framework belief tracking POMDPs, belief states sets
states probability distributions, particle-based algorithms provide common
approximation (Doucet et al., 2000).
952

fiBelief Tracking Planning Sensing

Acknowledgments
thank Gabriel Detoni Java Tewnta framework (http://code.google.com/p/
tewnta) implementing client/server games graphical interface developed graphical interfaces Battleship, Minesweeper Wumpus. Thanks
James Biagioni wumpuslite JAVA simulator (http://www.cs.uic.edu/~jbiagion/
wumpuslite.html) adapted run experiments Wumpus, Guy Shani
help running SDR. Hector Geffner partially supported EU FP7 Grant# 270019
(Spacebook) MICINN CSD2010-00034 (Simulpast).

Appendix A. Proofs
Formal results needed stated propositions theorems
main text article appear form lemmas.
A.1 Complexity Flat Belief Tracking
Let us first formally define decision problems BTP GBTP. BTP language
BTP = {hP, : P contingent problem, possible execution, b |= G}
P = hV, I, A, G, V 0 , W i, = ha0 , o0 , . . . , , execution, b belief
results execution initial belief state. GBTP BTP except
consists triplets hP, , `i P contingent problem, possible generalized
execution, ` goal, precondition observation literal, b |= `.
Observe BTP GBTP respectively include tuples hP, hP, , `i
problem empty initial belief state, due two complementary literals appearing unit clauses I, since case every execution trivially possible b
trivially entails literal `.
Proposition 3. BTP polynomial-time reducible GBTP.
Proof. idea map normal execution generalized execution results
replacing pair ha, oi sequence ha, `1 , noopa , `2 , . . . , noopa , `|V 0 |
`1 , . . . , `|V 0 | observation literals made true o, one observable variable
V 0 , noopa action requires nothing nothing whose sensor
model Wnoopa (`) = Wa (`) observation literal `.
Formally, given instance hP, BTP, reduction must generate polynomial
time instance hP 0 , 0 , `i GBTP hP, BTP iff hP 0 , 0 , `i GBTP.
problem P 0 problem P extended actions noopa , new boolean
variable Xgoal denotes achievement goal G P , new action agoal
precondition G effect Xgoal , new dummy observable variable domain
{>} models Wa (Y = >) = true actions a. hand, generalized
execution 0 hm , agoal , = >i ` = Xgoal . Clearly, reduction works polynomial
time hP, BTP iff hP 0 , 0 , `i GBTP.
Theorem 5. Flat belief tracking exponential |VU |, VU = V \ VK VK
set state variables V determined.
953

fiBonet & Geffner

Proof. described Definition 4, flat belief tracking consists explicit representation
beliefs set states, savings space time obtained noting
variables VK determined.
explicit representation beliefs, belief tracking problem gets trivially solved
checking whether execution = ha0 , o0 , . . . , , possible literal `
true reduces computing belief bn+1 results checking whether
bn+1 empty whether every state satisfies `. time complexity algorithm
time needed compute initial belief b0 plus (n + 1) multiplied time needed
compute bi+1 bi plus time needed check validity `. Among times,
last easiest calculate linear size bn+1 . thus need bound
first two times. begin proof showing flat belief tracking done
time exponential |V | reduce exponential dependency |V | |VU |.
computing b0 enough generate possible states (valuations variables)
filter satisfy clauses I. total time thus spent
|V | |I| 2O(|V |) since 2O(|V |) valuations, |I| clauses, clause
|V | literals.9
time compute bi+1 bi consists time check preconditions
hold b, times compute ba b boa ba b = bi , = ai
= oi . preconditions easily verified iterating states b. time
bounded |V | 2O(|V |) since contains |V | preconditions b contains
2O(|V |) states. precondition satisfied state b, execution
possible.
belief ba computed b iterating state b,
possible state s0 ba , checking whether s0 F (a, s). two nested
iterations require time 2O(|V |) 2O(|V |) = 2O(|V |) . test s0 F (a, s) performed
time exponential |V | follows. Let Ci E1i | |Eni , 1 m,
collection conditional effects action trigger state s. s0 F (a, s),
s0 result applying one head conditional effect s. Since
problem |V | variables, among heads |V | heads map
s0 rest (if any) subsumed first. subsets heads size
|V | enumerated 2O(|V |) time, subset checking whether gets
mapped s0 requires O(|V |) time. Therefore, checking s0 F (a, s) requires 2O(|V |) time
well computing ba b.
ba obtained, boa calculated removing (filtering) ba states
comply observation o. state ba observation literal
` compatible o, state belongs boa iff |= Wa (`). latter test
performed time linear |Wa (`)|, size formula Wa (`). Hence, since
|V 0 | observation literals compatible o, boa computed ba time O(|ba |
|V 0 | |Wa |) |Wa | = max` |Wa (`)| max ranges observation literals `.
boa empty ba non-empty, execution possible.
9. calculation, implicitly assume variable domains constant size. Otherwise,
domains size n linear input size, number valuations bounded 2O(|V | log n)
instead 2O(|V |) . either case, number valuations still exponential number variables
well resulting complexity flat belief tracking.

954

fiBelief Tracking Planning Sensing

times weighed in, see flat belief tracking done time
exponential |V |.
reduce exponent |V | |VU |. direct since determined
variable valuation across states reachable belief. Hence, variables
contribute increase number states reachable beliefs. Likewise,
subsets heads size |VU | need considered computing belief ba b.
Hence, computations done time space exponential |VU |.
Theorem 6. BTP GBTP Turing complete class PNP .
Proof. Proposition 3, BTP polynomial-time reducible GBTP, thus enough
show hardness BTP inclusion GBTP.
class PNP set decisions problems decided (deterministic)
polynomial time using oracle SAT. show BTP hard class,
enough show UNSAT reduced polynomial time BTP since every
call NP oracle replaced call BTP oracle. hand,
show GBTP belongs PNP , enough show algorithm
complement GBTP (since PNP closed complementation) runs polynomial
time makes calls oracle SAT.
Hardness. Let = {C1 , . . . , Cm } CNF theory boolean variables X1 , . . . , Xn .
need construct polynomial time contingent problem P = hV, I, A, G, V 0 , W
execution hP, BTP iff unsatisfiable. variables
problem P boolean given V = {X1 , . . . , Xn , Q} V 0 = {Z1 , . . . , Zm }.
empty set clauses G = {Q = true}. actions a1 , . . . , , empty
preconditions conditional effects, sensor model Wai (Zi = true) = Ci Q
Wai (Zj = true) = f alse j 6= i. Finally, execution = ha1 , o1 , . . . , , om
oi V 0 -valuation makes Zi true Zj false j 6= i.
Note initial belief contains 2n+1 V -valuations, half satisfying
Q half Q. first observation o1 received, valuations
satisfy clause C1 Q preserved. Thus, inductively, observation oi
received, valuations satisfy clauses {C1 , C2 , . . . , Ci } Q preserved.
Therefore, b set valuations satisfy Q hence non-empty (i.e.,
possible execution). Thus, b |= G iff valuations Q gone iff unsatisfiable.
Inclusion. complement GBTP consists tuples hP, , `i b0 non-empty
either non-executable b 6|= `. Since consists unit clauses, b0 6= iff
contains pair complementary literals. Assume = ha0 , `0 , a1 , `1 , . . . , , `n i,
literals `i observation literals, let bi belief action ai
applied; i.e., bi = boa b = bi1 , = ai1 = `i1 . Then, possible iff
bi non-empty action ai applicable bi . Assume established
prefix = ha0 , `0 , . . . , ai1 , `i1 possible, checking whether i+1 possible
involves two operations: 1) checking precondition literal ai holds bi1
2) checking whether least one state bai complies `i , b = bi1 .
first check done calling SAT oracle CNF theory i1 ,
time-indexed propositions state-variable literals actions, encodes possible
state trajectories fixed valuation actions. time horizon theory
955

fiBonet & Geffner

= 0, . . . , 1, theory built way satisfiable iff state
time (i.e., bi1 ) satisfy least one precondition ai . theory
polynomial size built polynomial time. Likewise, second check
performed calling SAT oracle CNF theory i1 property
satisfiable iff state bi1 complies observation `i .
Hence, algorithm decides complement GBTP works building theories
= 0, . . . , n. stage t, ACCEPTs input satisfiable
unsatisfiable. If, end, algorithm accepted yet, builds another theory
n+1 , instead checking whether precondition action ai doesnt
hold, checks whether input literal ` doesnt hold. n+1 satisfiable, ACCEPTs
since belief b satisfy `, else REJECTs hP, , `i GBTP.
A.2 Factored Belief Tracking
following, state (valuation variables) subset variables, write
s|S denote valuation restricted variables S, called projection
S. general, use symbols s, primed versions denote states,
symbols u, v primed versions denote projected states (restrictions
partial valuations).
Proposition 9. Belief tracking deterministic non-deterministic conformant setting exponential maximum number non-determined variables causally
relevant variable appearing action precondition goal.
Proof. proposition special case Theorem 15 (and Theorem 33).
Theorem 15. Belief tracking P exponential w(P ).
Proof. conformant setting, observable variables hence evidential
relevance relation empty relevant relation equals causally relevant relation.
Therefore, context variable X equals set variables causally relevant
X, theorem establish Proposition 9 conformant setting.
general setting, theorem shown constructing algorithm belief
tracking whose time complexity exponential w(P ). definition analysis
algorithm done series claims terminate Theorem 22 below.
Proposition 18. variable X appears goal precondition, number state
variables PX determined bounded w(P ).
Proof. number state variables PX |Ctx(X)| number state variables
determined PX |Ctx(X) VU |. definition width, quantity
less equal w(P ) X goal precondition variable.
establish two fundamental lemmas progression actions projection observable models. following, say subset variable causally
closed variable X variable causally relevant X, S.
Likewise, causal closure variable Z minimum (with respect set inclusion)
subset variables causally closed includes Z.
956

fiBelief Tracking Planning Sensing

Lemma 1 (Factored Progression). Consider consistent problem P . Let state,
action applicable s. Then, causally-closed subset variables:
1) every u0 , u0 FS (a, s|S ) s0 F (a, s) u0 = s0 |S ,
2) every s0 , s0 F (a, s) s0 |S FS (a, s|S )
FS transition function projected problem PS . Therefore, F (a, s) =
FS (a, s|S ) every state applicable, F (a, U ) = FS (a, U ) every
set U valuations applicable.
Proof. Part 1. Let u0 element FS (a, s|S ) let HS = {ESi }m
i=1 collection
heads conditional effects CSi ESi trigger s|S result u0 .
fixed {1, . . . , m}, know s|S |= CSi . ESi 6= then, definition causally
relevant relation, V ars(C ) thus CSi = C . Therefore, |= C effect
triggers applied s. show effect affects variable
triggers applied s. Indeed, conditional effect C F affects
variable triggers, |= C thus s|S |= CS FS HS . Finally, effects
trigger affect variables problems P PS . Since P
consistent, set effects {E }m
i=1 contained set H heads effects
trigger applied s. Therefore, u0 projection state s0
results applying effects H s; i.e., u0 = s0 |S .
Part 2. Let s0 element F (a, s) let H = {E }m
i=1 collection heads
conditional effects C E trigger result s0 . fixed {1, . . . , m},
know |= C thus s|S |= C |S . Therefore, effects CSi ESi trigger
applied s|S PS . show effect affects variable
triggers applied s|S PS . Indeed, let us suppose projected conditional
effect CS FS affects variable triggers s|S . Then, V ars(F ) thus
V ars(C) S, since causally closed, CS = C. Therefore, |= C effect
triggers applied s. Finally, since effects trigger affect
variables problems P PS , s0 |S result applying
0
projected effects {ESi }m
i=1 s|S ; i.e., |S FS (a, s|S ).
Lemma 2 (Observational Closure). every variable X, action a, observation literal
` = Z = z, Wa (`)S either Wa (`) true, = Ctx(X).
Proof. Let {X1 , . . . , Xn } variables Wa (`). definition relevant relation,
Z relevant Xi vice versa. Hence, Z Xi belongs S, Z
Xi belongs well. Therefore, Wa (`)S either Wa (`) true.
following results obtained induction length executions.
noted before, loss generality consider generalized executions instead
executions. However, easier consider even general executions correspond
finite sequences alphabet {ha, `i : A, ` Lits(V 0 )}
set actions Lits(V 0 ) set observation literals. type executions
general require interleaving actions observations; i.e.,
execution may contain multiple actions observations sequence. example,
957

fiBonet & Geffner

execution ha0 , a1 , ha2 , `2 i, ha3 , `3 i, . . .i indicates initial belief needs
progressed actions a0 a1 , filtered formula Wa2 (`2 ), filtered
formula Wa3 (`3 ), on. case normal generalized executions,
direct mapping generalized executions new type executions.
one execution, b denotes belief results applying initial
belief, b = b , ba ba,` denote beliefs result executions
0 = h, ai 0 = h, ha, `ii respectively. Therefore, making induction
length executions prove claim, need show claim initial belief
corresponds empty execution, beliefs form ba ba,` b = b .
next definition lemma make precise notion decomposable belief
plays fundamental role results. Intuitively, belief b decomposable
every pair states s, b, state w b agrees variables
subset agrees variables subset (where certain
subsets variables); symbols, w b w|S = s|S w|T = t|T .
Definition Lemma 3 (Decomposability). belief state b decomposable iff
every variable X, observation literal ` = Z = z, action a, subset V ars(Wa (`))
causally closed Ctx(X) = , holds:


s, s, b = w w b w|Ctx(X) = s|Ctx(X) w|T = t|T .
turns every reachable belief decomposable.
Proof. Let b reachable belief. Then, execution b = b .
proof induction length . empty, claim holds since contains
unit clauses Ctx(X) = .
Assume beliefs reachable executions length less equal
n decomposable, consider execution 0 length n + 1 augments
execution length n. following, b denotes belief b , res(a, s) denotes
state results applying deterministic action state s.
Case: 0 = h, a0 i. Let X, `, statement lemma, = Ctx(X),
let s0 , t0 two states ba0 . Therefore, two determinizations a1 a2
a0 s0 = res(a1 , s) t0 = res(a2 , t) s, b. Apply inductive hypothesis
obtain w b w|S = s|S w|T = t|T . Since disjoint
causally closed, determinization10 a3 a0 res(a1 , s)|S = res(a3 , w)|S
res(a2 , t)|T = res(a3 , w)|T . sought w0 ba0 thus w0 = res(a3 , w).
Case: 0 = h, ha0 , `0 ii. before, let X, `, statement lemma,
0 0
let `0 = Z 0 = z 0 , let s0 , t0 two states ba ,` . consider two subcases whether
V ars(Wa0 (`0 )) not, = Ctx(X):
Subcase: V ars(Wa0 (`0 )) S. Since, s0 , t0 b, apply inductive hypothesis get w0 b
0 0
w0 |S = s0 |S w0 |T = t0 |T . Then, w0 ba ,` w0 |S = s0 |S |= Wa0 (`0 )S =
Wa0 (`0 ).
10. existence determinization granted second assumption planning problem
fact sets variables disjoint.

958

fiBelief Tracking Planning Sensing

Subcase: V ars(Wa0 (`0 )) * S. Lemma 2, V ars(Wa0 (`0 )) = . Let 0 minimal
causally-closed subset variables includes V ars(Wa0 (`0 )). Observe 0 =
since belongs intersection, Z 0 relevant , relevant X, thus
Z 0 relevant X contradicting V ars(Wa0 (`0 )) = . Apply inductive hypothesis
using 0 get w0 b w0 |S = s0 |S w0 |T 0 = t0 |T 0 . w0
0 0
looking 0 thus w0 |T = t0 |T , w0 ba ,` since
w0 |T 0 = t0 |T 0 |= Wa0 (`0 )T 0 = Wa0 (`0 ).
last technical lemma, giving proofs Theorems 20 22, establish
existence partial valuations projection filtered beliefs following:
Lemma 4 (Factored Filtering). Let X variable, = Ctx(X), b reachable belief,
action, ` = Z=z observation literal. ba,` non-empty u
u b u |= Wa (`)S , u ba,` .
Proof. Assume ba,` non-empty let u S-valuation satisfies antecedent lemma. Wa (`)S = Wa (`), u |= Wa (`) u ba,` .
Wa (`)S 6= Wa (`) Lemma 2, V ars(Wa (`)) = . Let minimal
causally-closed subset variables includes V ars(Wa (`)). Note
Z evidentially relevant relevant X, thus Z relevant X
V ars(Wa (`)) S. Therefore, = . Let ba,` b apply Lemma 3 get
w b w|S = u w|T = t|T . Hence, w|T |= Wa (`)T = Wa (`), w ba,`
u ba,` .
Theorem 20. state variable X, let b bX beliefs result execution
possible P PX . Then, X bX = X b.
Proof. Let execution possible P PX . prove
general result bX = b = Ctx(X); general X
X bX = X b = X b. proof induction length . empty
execution, result follows readily since contains unit clauses. Assume
claim holds executions length n, let 0 execution length n + 1
augments execution length n possible P PX . Further, let b
bX beliefs result P PX respectively. Then, inductive
hypothesis bX = b.
Case: 0 = h, ai. need show bX,a = ba . following, FS denotes
transition function PX . forward inclusion given


1
u0 bX,a = u u bX u0 FS (a, u)


2
= us u bX u0 FS (a, u) b s|S = u


3
= uss0 u bX u0 FS (a, u) b s|S = u s0 F (a, s) s0 |S = u0


4
= ss0 b s0 F (a, s) s0 |S = u0

6
5
= s0 s0 ba s0 |S = u0 = u0 ba
959

fiBonet & Geffner

1 definition bX,a , 2 inductive hypothesis, 3 Lemma 1, 5
6 definitions ba ba respectively. backward inclusion

2


1
s0 |S ba = b s0 F (a, s) = b s0 F (a, s) s0 |S FS (a, s|S )

4
3
= s|S bX s0 |S FS (a, s|S ) = s0 |S bX,a
1 definition ba , 2 Lemma 1, 3 inductive hypothesis, 4
definition bX,a . Therefore, bX,a = ba .
a,`
Case: 0 = h, ha, `ii. need show ba,`
X = b . forward inclusion
1

2

3

a,`
u ba,`
X = u bX u |= Wa (`)S = u b u |= Wa (`)S = u b

1 definition ba,`
X , 2 inductive hypothesis, 3 Lemma 4.
backward inclusion
1

2

3

s|S ba,` = b |= Wa (`) = s|S bX s|S |= Wa (`)S = s|S ba,`
X .
1 definition ba,` , 2 inductive hypothesis, 3 definition
a,`
a,`
ba,`
X . Therefore, bX = b .
Theorem 21. 1) execution possible P iff possible subproblems
PX X precondition goal variable P . 2) execution precondition
goal variable X, X = x (resp. X 6= x) true b iff X = x (resp. X 6= x) true
bX , b bX beliefs result executing P PX respectively.
Proof. Part 1. proof induction length executions. base case
induction empty execution possible P PX . Assume
claim holds executions length n, let b bX beliefs result
P subproblem PX respectively. Let 0 execution length
n + 1 augments . following, F denotes collection precondition goal
variables P , = Ctx(X) X F.
Case: 0 = h, ai. First, assume 0 possible P . need show 0 possible
PX X F. assumption, literal ` P re(a) b, |= `.
Let ` literal P re(a)S u bX X F. Then, V ars(`) and, inductive
hypothesis Theorem 20 (since applicable P PX ) applied , u = s|S
b. Therefore, u |= ` applicable bX .
Now, assume 0 possible PX X F. need show 0
possible P . ` = X = x precondition a, ` P re(a)S ` holds
state u bX . b then, inductive hypothesis Theorem 20 applied ,
u bX s|S = u. Thus, |= ` applicable b.
Case: 0 = h, ha, `ii. First, assume 0 possible P ; i.e., ba,` non-empty. need
show ba,`
X non-empty well X F.
1

2

3

ba,` = b |= Wa (`) = s|S bX s|S |= Wa (`)S = s|S ba,`
X
960

fiBelief Tracking Planning Sensing

1 definition ba,` , 2 inductive hypothesis Theorem 20, 3
a,`
definition ba,`
X . Hence, bX non-empty.
Finally, assume 0 possible PX ; i.e., ba,`
X non-empty X F.
a,`
need show b non-empty. Let X F Wa (`)S = Wa (`)
= Ctx(X); exists fourth assumption problem P Lemma 2.



1
2
u ba,`
X = u bX u |= Wa (`)S = u bX u |= Wa (`)S b u = s|S


3
= u bX |= Wa (`) b u = s|S

5


4
= |= Wa (`) b = ba,`
1 definition ba,`
X , 2 inductive hypothesis Theorem 20, 3
Wa (`)S = Wa (`), 5 definition ba,` . Hence, ba,` non-empty.
Part 2. Let possible execution P , hence, part 1, possible PX .
Let b bX beliefs result P PX respectively. Theorem 20,
X bX = X b. Therefore, X = x (or X 6= x) holds bX iff holds b.
Theorem 22. Flat belief tracking projected problems PX X
precondition goal variable P , provides sound complete factored algorithm
belief tracking P time space exponential width P .
Proof. direct Theorem 21. Let execution b bX,
beliefs result executing P PX respectively. Then, possible P iff
possible PX . Therefore, flat belief tracking subproblems PX tells whether
possible P . Furthermore, precondition goal variable X, X = x holds
b iff holds bX, . Thus, flat belief tracking subproblems PX sufficient
determine action applicable goal belief reached.
Theorem 5, flat belief tracking subproblem PX exponential |Ctx(X) VU |.
Therefore, flat belief tracking subproblems PX (simultaneously) exponential
maxX |Ctx(X) VU | max ranges precondition goal variables X.
latter expression one defines w(P ).
Proposition 19. execution ha0 , o0 , a1 , o1 , . . .i possible P , possible
PX state variable X P .
Proof. X precondition goal variable, claim follows Theorem 21. So,
assume X state variable appear precondition goal. show
using induction length (generalized) execution possible P
possible PX . base case empty executions direct. Consider
execution 0 length n + 1 extends execution length n. Let b bX
result applying execution P PX respectively, let = Ctx(X).
Case: 0 = h, ai. Let ` = = precondition P re(a)S = Ctx(Y ). Then,
Ctx(Y ) Ctx(X) relevant X. Lemma 5 (below), bX .
961

fiBonet & Geffner

hand, Theorem 21, |= ` every . Therefore, ` holds state
bX , applicable bX , 0 possible PX .
Case: 0 = h, ha, `ii. Wa (`)S = true, ba,`
X = bX non-empty inductive
hypothesis thus 0 possible PX . Wa (`)S 6= true ` = Z = z, Z
relevant X. Since assumption precondition goal variable Z
relevant , difficult show X relevant . Thus, Ctx(X) Ctx(Y )
bX Lemma 5. Since 0 possible P ba,`
non-empty Theorem 21,
0 possible P .
ba,`

non-empty


X
X
A.3 Causal Belief Tracking
Lemma 5 (Soundness Causally-Closed Decompositions). Let = hT, Bi decomposition whose beams causally closed, let PXD subproblem corresponding
projection P variables B(X) X . target variable X , b
bX beliefs resulting execution P PXD respectively, bX B(X) b.
Proof. proof induction length executions. empty execution,
claims holds since contains unit clauses. Let 0 execution length 0
augments . following, b bX denote beliefs P PXD resulting
execution , denotes B(X).
Case: 0 = h, ai. Let u0 ba . Then, b u0 F (a, s).
Lemma 1, u0 FS (a, s|S ). Thus, since s|S bX inductive hypothesis, u0 bX,a .
Case: 0 = h, ha, `ii. Let s|S ba,` . b |= Wa (`). inductive
hypothesis, s|S |= Wa (`)S s|S bX . Thus, s|S ba,`
X .
Theorem 28. Decoupled CBT runs time space exponential wc (P ),
sound complete. is, target variable X causal decomposition,
b bX beliefs resulting execution P PXC respectively,
bX BC (X) b necessarily true, bX BC (X) b not.
Proof. Soundness follows directly Lemma 5. bounds time space
direct size beam BC (X) bounded causal width wc (P ).
Theorem 30. CBT space exponential causal width problem, time
exponential width.
Proof. CBT maintains beliefs beams causal decomposition whose size
bounded causal width problem. join-project operation CBT
performed across time, considering one valuation time, without need first
compute store full joint. done recursively iterating beliefs
(bY )oa participate join (5), combining partial valuations belief,
storing projection resulting belief bi+1
X . number valuations join
O(w(P
))
(5) bounded 2
variable Z BC (Y ), relevant X, relevant
X thus Z Ctx(X).
962

fiBelief Tracking Planning Sensing

remains show Theorem 33 (stated below). proof straightforward
split two parts. first part reformulates CBT algorithm called Wide
(Causal) Belief Tracking (WBT), CBT performs join operation
beliefs variables problem variables relevant
X, shows soundness completeness WBT. second part, show
CBT simply WBT applied subproblem PCtx(X) associated variable X
factored decomposition F , use soundness completeness factored
decomposition finish proof. first part proof consists Lemmas 68,
second part consists Lemma 9 Theorem 33.
WBT works causal decomposition C = hTC , BC CBT. beliefs time
0 WBT CBT: initial belief projected causal
beams BC (X) X TC . Beliefs later times associated executions 0
augment executions . denote belief variable X TC execution
bX, , update equations WBT are:
bX,h,ai = BC (X)
n{FT (a, bY, ) : TC } ,
bX,h,ha,`ii = BC (X)
n{F ilter(Wa(`)T , bY, ) : TC }

(8)
(9)

= BC (Y ) beam , FT (a, U ) set uU FT (a, u), F ilter(, U )
set {u U : u |= }. equations essentially equation (5) CBT,
progression filtering separated, except join performed
target variables instead joining target variables relevant X.
following basic facts joins, projections filtering easily shown
used proofs. (We include proofs here.) statements, sets
U Ui refer sets valuations, refers collection subset variables, refers
subset variables Si = V ars(Ui ), refers logical formula. facts are:
BF1. U
n{S U : S},
BF2. collection {Ui }iI ,


n{Si
n{Ui : I} : I} =
n{Ui : I},

BF3. F ilter(, U ) F ilter(S , U ).
Definition Lemma 6. decomposition = hT, Bi factors set U V -valuations
iff U =
n{B(X) U : X }.
decomposition = hT, Bi preserves transitions set U V -valuations iff
pair variables X, , Z B(X) B(Y ), either i) Z known U (i.e.,
u[Z] = u0 [Z] u, u0 U ), ii) B(X) B(Y ) B(W ) variable W ,
iii) every action a, transition function FS (a, ) 1-1 variable Z U ,
causal closure Z.
Let = hT, Bi decomposition V = XT B(X) B(X) causally
closed X , U set V -valuations, V -formula. following
claims hold:
1. factors U ,
F (a, U )
n{B(X)F (a, U ) : X } =
n{FB(X)(a, B(X)U ) : X } .
963

fiBonet & Geffner

2. factors preserves transitions U ,
F (a, U ) =
n{B(X)F (a, U ) : X } =
n{FB(X)(a, B(X)U ) : X } .
3. factors U X B(X) = ,
F ilter(, U ) =
n{B(X)F ilter(, U ) : X } =
n{F ilter(B(X), B(X)U ) : X } .
Proof. Part 1. containment direct BF1, equality follows directly
B(X) F (a, U ) = FB(X) (a, B(X) U ) Lemma 1.
Part 2. second equality forward inclusion first equality
Part 1. thus need show F (a, U )
n{B(X) F (a, U ) : X }. Let
u0 element right-hand side expression X . Then, u0 |B(X)
B(X) F (a, U ) (by Lemma 1) uX B(X) U u0 |B(X) FB(X) (a, uX ).
claim {uX }XT consistent collection valuations. Indeed, not,
valuations uX , uY variable Z uX [Z] 6= uY [Z]. Clearly, Z known
U . B(X) B(Y ) B(W ) W , exchange uX uY
uW |B(X) uW |B(Y ) respectively. Otherwise, see function FS (a, ),
causal closure Z, 1-1 Z, contradicting assumptions. Therefore,
valuation u u|B(X) = uX X (i.e., u
n{B(X) U : X }) thus,
assumption, u U . Finally, since B(X) F (a, u) = FB(X) (a, u|B(X) ) = FB(X) (a, uX )
Lemma 1, u0 |B(X) B(X) F (a, u) u0 F (a, U ).
Part 3. First, observe BF1 BF3 imply chain containments
F ilter(, U )
n{B(X)F ilter(, U ) : X }
n{F ilter(B(X), B(X)U ) : X } .
finish showing equality holds proving last subset contained
first. Let u0 element last subset. u0 belongs
n{B(X) U : X }
U since factors U . thus need show u0 |= . direct
since assumption X B(X) = , thus u0 |B(X) |= B(X) = .
Lemma 7 (Soundness WBT). WBT sound. is, C = hTC , BC causal
decomposition problem P , {bX }XTC local beliefs time i, b global
belief time i, b
n{bX : X TC } BC (X) b bX X TC .
Proof. really need proof first claim b
n{bX : X TC } second
follows directly observing bX belief variables BC (X).
proof first claim induction length executions. base
case empty execution easily verified. Assume claims hold executions
length n let 0 execution length n + 1 augments execution
length n. Observe C factors U =
n{bY, : TC } BF2, b U inductive
hypothesis.
Case: 0 = h, ai.


n{bX,

1

0

: X TC } =
n{BC (X)
n{FBC (Y )(a, bY, ) : TC } : X TC }
964

fiBelief Tracking Planning Sensing

2


n{BC (X)
n{FBC (Y )(a, BC (Y )U ) : TC } : X TC }
3

4

F (a, U ) F (a, b ) = b 0
1 Eq. 8, 2 bY, BC (Y ) U , 3 part 1 Lemma 6, 4
inductive hypothesis.
Case: 0 = h, ha, `ii.


n{bX,

9

0

: X TC } =
n{BC (X)
n{F ilter(Wa(`)BC (Y ), bY, ) : TC } : X TC }
10




n{B

C (X)


n{F ilter(Wa(`)B

C (Y

) , BC (Y ) U )

: TC } : X TC }

12

11

= F ilter(Wa (`), U ) F ilter(Wa (`), b ) = b 0
9 Eq. 9,
inductive hypothesis.

10

bY, BC (Y ) U ,

11

part 3 Lemma 6,

12



Lemma 8 (Completeness WBT). Let C = hTC , BC causal decomposition
problem P . C preserves transitions every reachable belief state, WBT complete.
is, {bX }XTC local beliefs time i, b global belief time i,
b=o
n{bX : X TC } BC (X) b = bX X TC .
Proof. proof induction length executions. base case
empty execution easily verified since contains unit clauses. Assume claims
hold executions length n let 0 execution length n + 1 augments
execution length n. Observe C factors U =
n{bY, : TC } BF2,
inductive hypothesis implies b = U bY, = BC (Y ) U . proof first claim
b=o
n{bX : X TC } exactly proof Lemma 7 except containments
replaced equalities, either using part 2 Lemma 6 inductive hypothesis.
second claim, make similar induction (in tandem first induction).
Again, base case induction easily verified. inductive step,
Case: 0 = h, ai.
1

2

bX, 0 = BC (X)
n{FBC (Y )(a, bY, ) : TC } = BC (X)
n{FBC (Y )(a, BC (Y )U ) : TC }
3

4

= BC (X) F (a, U ) = BC (X) F (a, b ) = BC (X) b 0
1 Eq. 8, 2 4 inductive hypothesis, 3 part 2 Lemma 6.
Case: 0 = h, ha, `ii.
5

bX, 0 = BC (X)
n{F ilter(Wa(`)BC (Y ), bY, ) : TC }
6

= BC (X)
n{F ilter(Wa(`)BC (Y ), BC (Y )U ) : TC }
7

8

= BC (X) F ilter(Wa (`), U ) = BC (X) F ilter(Wa (`), b ) = BC (X) b 0
5 Eq. 9, 6 8 inductive hypothesis, 7 part 3 Lemma 6.
965

fiBonet & Geffner

following lemma shows tracking CBT variable X equivalent
tracking WBT subproblem PX factored decomposition (i.e.,
PX = PBF (X) factored decomposition F = hTF , BF i).
Lemma 9. Let F = hTF , BF C = hTC , BC factored causal decompositions
W
problem P . execution X TC state variable, bC
X = bX
C
bX denotes local belief variable X computed CBT problem
P , bW
X denotes local belief variable X computed WBT
subproblem PBF (X) .
Proof sketch. simple tedious proof, provide sketch. Let CX =
hTX , BX causal decomposition subproblem PBF (X) X TF (i.e.,
causal decomposition subproblem associated variable X TF factored
decomposition). beams participate join CBT beams
variables TC relevant X; variables appear TX well. TX
variables however: observable variables relevant X. Yet, since
state variables PBF (X) relevant X, projected formulas Wa (Y = y)BF (X)
variables equal true. Hence, beams variables
empty set variables contain empty valuation. Therefore, beams
removed join defines WBT problem PBF (X) without altering value.
resulting join WBT PBF (X) contain beams variables TC
relevant X.
fact observed, proof consists simple induction length
executions. induction left exercise.
Theorem 33. Causal belief tracking always sound. complete causally decomposable problems.
Proof. Let F = hTF , BF C = hTC , BC factored causal decompositions
problem P , CX = hTX , BX causal decomposition subproblem PBF (X)
X TF (notice X state variable TF comprised such). Further, let
W
execution, let bC
X bX local beliefs variable X computed
CBT problem P WBT problem PBF (X) respectively, let bFX local belief
variable X computed factored belief tracking problem P , let b
(global) belief problem P .
observable variable relevant X, BC (X) = BF (X) CBT X equal
factored belief tracking X sound complete Theorem 20.
observable variables relevant X, first notice
W
F
bC
X = bX BC (X) bX = BC (X) b

(10)

Lemma 9, soundness WBT (cf. Lemma 7), soundness completeness FBT (cf. Theorem 20). Therefore, CBT sound.
causal decomposition CX preserves transitions every reachable belief state
problem PBF (X) , containment (10) equality CBT complete well.
thus finish proof showing decomposition CX causally-decomposable
problems decomposition preserves transitions reachable belief PBF (X) .
966

fiBelief Tracking Planning Sensing

Let X TC variable, let bX reachable belief problem PBF (X) , let X 0
two variables TX (the target variables causal decomposition problem
PBF (X) ), let Z variable BC (X 0 ) BC (X 00 ). show either 1) Z
known bX , 2) BC (X 0 ) BC (X 00 ) BC (W ) variable W TX , 3) every
action a, transition function FS (a, ) 1-1 variable Z bX causal
closure Z. case, causal decomposition CX preserves transitions every
reachable belief problem PBF (X) .
X 00

consider two cases:
Case: X 0 X 00 observable. First, apply causal-decomposability P conclude
either variable W TC relevant X 0 X 00 BC (W ) BC (X 0 )
BC (X 00 ), Z memory variable. former case, W relevant X thus
belongs TX . latter case, show either Z known bX transition
function FS (a, ) 1-1 Z bX , causal closure Z action
applicable bX .
Indeed, proof contradiction let us suppose Z known bX
transition function 1-1. Then, two valuations s1 , s2 bX two
progressions s01 FX (a, s1 ) s02 FX (a, s2 ) s1 [Z] 6= s2 [Z] s01 [Z] = s02 [Z].
Therefore, observing value Z state s01 knowing initial belief
actions execution h, ai (where execution leads bX ), one cannot infer
value Z bX two different values compatible
observation, namely s1 [Z] s2 [Z]. Hence, Z memory variable contradicting
assumed causal-decomposability P .
Case: X 0 X 00 observables. divide case two subcases
whether variables X 0 X 00 causal ancestors X not. affirmative
subcase, BC (X 0 ) BC (X 00 ) BC (X). negative subcase, assume without loss
generality X 0 causal ancestor X. Then, observable variable
X 0 causal ancestor relevant X. Hence, BC (Y ) BC (X 0 )
implies Z BC (Y ) BC (X 00 ) case reduced previous case.

References
Albore, A., Palacios, H., & Geffner, H. (2009). translation-based approach contingent
planning. Proc. 21st Int. Joint Conf. Artificial Intelligence, pp. 16231628,
Pasadena, California.
Albore, A., Ramirez, M., & Geffner, H. (2010). Compiling uncertainty away nondeterministic conformant planning. Proc. 19th European Conf. Artificial Intelligence, pp. 465470, Lisbon, Portugal.
Albore, A., Ramirez, M., & Geffner, H. (2011). Effective heuristics belief tracking
planning incomplete information. Proc. 21st Int. Conf. Automated
Planning Scheduling, pp. 29, Freiburg, Germany.
Amir, E., & Russell, S. (2003). Logical filtering. Proc. 18th Int. Joint Conf. Artificial
Intelligence, pp. 7582, Acapulco, Mexico.
967

fiBonet & Geffner

Bertoli, P., Cimatti, A., Roveri, M., & Traverso, P. (2001). Planning nondeterministic domains partial observability via symbolic model checking. Nebel, B.
(Ed.), Proc. 17th Int. Joint Conf. Artificial Intelligence, pp. 473478, Seattle, WA.
Morgan Kaufmann.
Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic search
belief space. Chien, S., Kambhampati, S., & Knoblock, C. (Eds.), Proc. 5th
Int. Conf. Artificial Intelligence Planning Systems, pp. 5261, Breckenridge, CO.
AAAI Press.
Bonet, B., & Geffner, H. (2011). Planning partial observability classical replanning:
Theory experiments. Proc. 22nd Int. Joint Conf. Artificial Intelligence, pp.
19361941, Barcelona, Spain.
Bonet, B., & Geffner, H. (2012a). Action selection MDPs: Anytime AO* vs. UCT.
Proc. 26th AAAI Conf. Artificial Intelligence, pp. 17491755, Toronto, Canada.
Bonet, B., & Geffner, H. (2012b). Width complexity belief tracking nondeterministic conformant contingent planning. Proc. 26th AAAI Conf.
Artificial Intelligence, pp. 17561762, Toronto, Canada.
Bonet, B., & Geffner, H. (2013). Causal belief decomposition planning sensing:
Completeness results practical approximation. Proc. 23rd Int. Joint Conf.
Artificial Intelligence, pp. 22752281, Beijing, China.
Bonet, B., & Geffner, H. (2014). Flexible scalable partially observable planning
linear translations. Proc. 28th AAAI Conf. Artificial Intelligence, pp. 22352241,
Quebec City, Canada.
Boyen, X., & Koller, D. (1998). Tractable inference complex stochastic processes.
Cooper, G., & Moral, S. (Eds.), Proc. 14th Conf. Uncertainty Artificial Intelligence, pp. 3342, Madison, WI. Morgan Kaufmann.
Brafman, R. I., & Shani, G. (2012). Replanning domains partial information
sensing actions. Journal Artificial Intelligence Research, 1 (45), 565600.
Bryce, D., Kambhampati, S., & Smith, D. E. (2006). Planning graph heuristics belief
space search. Journal Artificial Intelligence Research, 26, 3599.
Choi, A., & Darwiche, A. (2006). edge deletion semantics belief propagation
practical impact approximation quality. Proc. 21st Nat. Conf. Artificial
Intelligence, pp. 11071114.
Cimatti, A., Roveri, M., & Bertoli, P. (2004). Conformant planning via symbolic model
checking heuristic search. Artificial Intelligence, 159, 127206.
Darwiche, A., & Marquis, P. (2002). knowledge compilation map. Journal Artificial
Intelligence Research, 17, 229264.
Dechter, R., & Beek, P. V. (1997). Local global relational consistency. Theoretical
Computer Science, 173 (1), 283308.
Doucet, A., Freitas, N. D., Murphy, K., & Russell, S. (2000). Rao-blackwellised particle filtering dynamic bayesian networks. Proc. 16th Conf. Uncertainty Artificial
Intelligence, pp. 176183.
968

fiBelief Tracking Planning Sensing

Edelkamp, S. (2001). Planning pattern databases. Cesta, A. (Ed.), Proc. 6th
European Conf. Planning, pp. 1324, Toledo, Spain. Springer: LNCS.
Goldman, R. P., & Boddy, M. S. (1996). Expressive planning explicit knowledge.
Drabble, B. (Ed.), Proc. 3rd Int. Conf. Artificial Intelligence Planning Systems,
pp. 110117, Edinburgh, Scotland. AAAI Press.
Hoffmann, J., & Brafman, R. I. (2005). Contingent planning via heuristic forward search
implicit belief states. Biundo, S., Myers, K., & Rajan, K. (Eds.), Proc. 15th
Int. Conf. Automated Planning Scheduling, pp. 7180, Monterey, CA. Morgan
Kaufmann.
Hoffmann, J., & Brafman, R. I. (2006). Conformant planning via heuristic forward search:
new approach. Artificial Intelligence, 170, 507541.
Kaelbling, L. P., Littman, M., & Cassandra, A. R. (1999). Planning acting partially
observable stochastic domains. Artificial Intelligence, 101, 99134.
Kaye, R. (2000). Minesweeper NP-Complete. Mathematical Intelligencer, 22 (2), 915.
Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. Proc. 17th
European Conf. Machine Learning, pp. 282293. Springer.
Lin, W., Buffet, O., Lee, C., & Teytaud, O. (2012). Optimistic heuristics Minesweeper.
Proc. Int. Computer Symposium (ICS-12). http://hal.inria.fr/docs/
00/75/05/77/PDF/mines3.pdf.
Palacios, H., & Geffner, H. (2009). Compiling uncertainty away conformant planning
problems bounded width. Journal Artificial Intelligence Research, 35, 623
675.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. Morgan Kaufmann.
Ramirez, M., & Geffner, H. (2007). Structural relaxations variable renaming
compilation solving MinCostSAT. Proc. 13th Int. Conf. Principles
Practice Constraint Programming, pp. 605619. Springer.
Rintanen, J. (2008). Regression classical nondeterministic planning. Ghallab,
M., Spyropoulos, C. D., Fakotakis, N., & Avouris, N. M. (Eds.), Proc. 18th European
Conf. Artificial Intelligence, pp. 568572, Patras, Greece.
Russell, S., & Norvig, P. (2009). Artificial Intelligence: Modern Approach (3rd edition).
Prentice Hall.
Scott, A., Stege, U., & Rooij, I. V. (2011). Minesweeper may NP-Complete
Hard nonetheless. Science+Business Media, LLC, 33 (4), 517.
Shani, G., & Brafman, R. I. (2011). Replanning domains partial information
sensing actions. Proc. 22nd Int. Joint Conf. Artificial Intelligence, pp. 2021
2026, Barcelona, Spain.
Shani, G., Poupart, P., Brafman, R. I., & Shimony, S. (2008). Efficient ADD operations
point-based algorithms. Rintanen, J., Nebel, B., & J. C. Beck, E. A. H. (Eds.),
Proc. 18th Int. Conf. Automated Planning Scheduling, pp. 330337, Sydney,
Australia.
969

fiBonet & Geffner

Silver, D., & Veness, J. (2010). Monte-Carlo planning large POMDPs. Proc. 24th
Annual Conf. Advances Neural Information Processing Systems, pp. 21642172.
Sipser, M. (2006). Introduction Theory Computation (2nd edition). Thomson Course
Technology, Boston, MA.
Smith, D., & Weld, D. (1998). Conformant graphplan. Mostow, J., & Rich, C. (Eds.),
Proc. 15th Nat. Conf. Artificial Intelligence, pp. 889896, Madison, WI. AAAI
Press / MIT Press.
To, S. T., Pontelli, E., & Son, T. C. (2011). effectiveness CNF DNF representations contingent planning. Proc. 22nd Int. Joint Conf. Artificial Intelligence,
pp. 20332038, Barcelona, Spain.
Tran, V., Nguyen, K., Son, T. C., & Pontelli, E. (2013). conformant planner based
approximation: CpA(H). ACM Trans. Intelligent Systems Technology, 4 (2),
36.
Weld, D., Anderson, C., & Smith, D. (1998). Extending Graphplan handle uncertainty
sensing actions. Proc. 15th Nat. Conf. Artificial Intelligence, pp. 897904.
AAAI Press.

970


