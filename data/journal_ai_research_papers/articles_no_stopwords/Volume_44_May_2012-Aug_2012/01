Journal Artificial Intelligence Research 44 (2012) 97-140

Submitted 2/2012; published 5/2012

Solving Limited Memory Influence Diagrams
Denis Deratani Maua
Cassio Polpo de Campos
Marco Zaffalon

denis@idsia.ch
cassio@idsia.ch
zaffalon@idsia.ch

Istituto Dalle Molle di Studi sullIntelligenza Artificiale (IDSIA)
Galleria 2, Manno, 6928 Switzerland

Abstract
present new algorithm exactly solving decision making problems represented
influence diagrams. require usual assumptions forgetting regularity;
allows us solve problems simultaneous decisions limited information.
algorithm empirically shown outperform state-of-the-art algorithm randomly
generated problems 150 variables 1064 solutions. show problems
NP-hard even underlying graph structure problem low treewidth
variables take bounded number states, admit provably good
approximation variables take arbitrary number states.

1. Introduction
Influence diagrams (Howard & Matheson, 1984) graphical models aimed representation problems decision making uncertainty. Traditionally, designed
handle situations involving single, non-forgetful decision maker. Limited memory influence diagrams (hereafter LIMIDs) generalizations influence diagrams allow
decision making limited information, case simultaneous decisions, bounded
memory controllers non-communicating cooperative agents (Zhang, Qi, & Poole, 1994;
Lauritzen & Nilsson, 2001; Poupart & Boutilier, 2003; Detwarasiti & Shachter, 2005).
precisely, LIMIDs relax regularity forgetting assumptions influence diagrams,
namely, complete temporal ordering decision variables,
disclosed information (i.e., decisions observations made) remembered considered
future decisions. assumptions might hard meet applications, might lead exponential growth size policies, consequently
intractability.
Solving (limited memory) influence diagram refers finding optimal plan action,
is, combination decision rules, policies, associate possible observation
action. Optimality understood maximizing expected utility. task
empirically theoretically shown hard (de Campos & Ji, 2008). fact,
show solving LIMID NP-hard even admit singly connected diagrams
bounded number states per variable,1 devising algorithm produces
provably good approximate solutions within fixed factor unlike exist even
diagrams low treewidth.
1. diagram singly connected underlying (undirected) graph contains cycles.
2012 AI Access Foundation. rights reserved.

fiMaua, de Campos, & Zaffalon

Lauritzen Nilsson (2001) shown LIMIDS satisfy certain graphstructural conditions (which forgetting regularity imply) solved exactly
dynamic programming procedure complexity exponential treewidth. Hence,
solving LIMIDs computationally similar performing probabilistic inference
Bayesian networks (Koller & Friedman, 2009). fact, single policy updating (SPU)
algorithm Lauritzen Nilsson (2001) performs local search space policies
step performs probabilistic inference evaluate candidate solution.
However, many problems fail meet conditions necessary SPU achieving optimality, cases SPU might converge local optimum much inferior
actual (global) optimum. circumvent problem, de Campos Ji (2008) formulated
credal reformulation (CR) algorithm maps LIMID mixed integer linear
programming problem. showed CR algorithm able solve small problems exactly obtain good approximations medium-sized problems relaxing
integrality constraints.
show paper LIMIDs solved exactly variable elimination
scheme simultaneously propagates sets (partial) solutions. Although algorithm
runs exponential time worst case (which expected, problem
NP-hard), show many problem instances possible obtain optimal
solution efficiently pruning solutions Pareto-dominated others. heart
algorithms efficiency property moment variable elimination
local Pareto dominance implies global Pareto dominance, is, partial solution
Pareto-dominated another partial solution cannot part optimal solution,
hence safely discarded. show experimentally pruning Paretodominated local solutions enormously save computational resources, enable us
compute exact solutions much bigger problems previous algorithms. fact,
algorithm orders magnitude faster CR algorithm randomly generated
diagrams containing 150 variables 1064 strategies.
paper organized follows. Section 2 describes LIMID formalism presents
new results complexity solving LIMID. variable elimination algorithm
computing exact solutions presented Section 3, evaluated Section 4. last,
Sections 5 6 contain related work final discussion. improve readability,
proofs supporting results given appendix.

2. Limited Memory Influence Diagrams
section, describe LIMID formalism, state complexity solving LIMID
instance, show LIMID transformed equivalent (in terms
maximum expected utility) diagram whose utilities nonnegative decision variables
parents. LIMIDs input algorithm next section. start
example decision problem limited information, use throughout
rest paper illustrate motivate concepts. Although example (which
essentially team coordination problem) rather simple, easily extended
account realistic scenarios.
98

fiSolving LIMIDs

2.1 Fire Dispatching Problem
particular fire station contains group firefighters divided three units. fire
dispatcher decides units dispatch reported accident. dispatched
unit costs -1 utile, units dispatched cost utiles. case fire, higher
number dispatched teams higher chances minimum damage (which implies
saving lives preventing third-party financial losses). make things simple, consider
accident handled either appropriately, case say success,
inappropriately, case say failure. Ideally, dispatcher wants
maximize chance success minimizing number dispatched teams (and
hence cost operation). successful operation rewarded 7/2 utiles,
failure gets zero utiles.
2.2 Variables Domains
formalism (limited memory) influence diagrams, quantities events
interest represented three distinct types variables nodes.2 Chance variables
represent events decision maker control, outcomes tests
consequences actions. Decision variables represent options available decision
maker. Finally, value variables represent additive parcels utility associated state
world. set variables considered relevant problem denoted U.
variable X U associated domain X , finite non-empty set
values X assume. elements X called states. assume existence
empty domain , {}, contains single element
domain. Decision chance variables assumed domains different
empty domain, whereas value variables always associated empty domain.
fire dispatching problem, represent act dispatching
unit decision variable Ti ; hence three decision variables T1 , T2 , T3
domains T1 = T2 = T3 = {a, w}, stands act means unit
dispatched, w stands wait means unit dispatched. outcome
incident assignment units represented binary chance variable
domain = {s, f } (representing success failure, respectively), evaluated
value variable V (which associated ). individual costs per unit
dispatched, modeled three value variables V1 , V2 V3 . set relevant
variables problem U = {T1 , V1 , T2 , V2 , T3 , V3 , O, V }.
domain x set variables x = {X1 , . . . , Xn } U given Cartesian
product X1 Xn variable domains. Thus, element u U defines
state world, is, realization actions events interest. x
sets variables x U, x element domain x , write
xy denote projection x onto smaller domain , is, xy contains
components x compatible variables y. convention,
x , . cylindrical extension x set x , {x x : xy = y}.
Often, write X1 Xn denote set {X1 , . . . , Xn } and, clear context,
X denote singleton {X}. instance, x = {T1 , O} = {T1 }, x =
2. make distinction node graphical representation decision problem
corresponding variable.

99

fiMaua, de Campos, & Zaffalon

{(a, s), (w, s), (a, f ), (w, f )}. Also, x = (w, s) x xy = w xO = s.
cylindrical extension x given sx = {(a, s), (w, s)}.
2.3 Operations Real-Valued Functions
operations real-valued functions need defined. Let f g functions
domains x , respectively. product f g defined function
domain xy (f g)(w) = f (wx )g(wy ) w domain. Sum functions
defined analogously: (f + g)(w) = f (wx ) + g(wy ). Notice product sum
functions associative commutative, product distributes sum, is,
f g = gf , f + g = gP+ f , f (g + h) = f g + f h. f function x , U,
sum-marginalP f returns
w
P function x\y element
P
domain ( f )(w) = xwx f (x). Notice x = , f = f . Also,
sum-marginal operation
inherits
commutativity
P
P P
P Pand associativity addition real
numbers, hence xy f = x\y f = y\x x f .
{fxy }yy set containing functions fxy domain x , one element ,

write fxy denote function w xy satisfies fxy (w) = fxw (wx ).
instance, X two binary-valued variables domains X = {x1 , x2 }



= {y 1 , 2 }, fX1 fX2 two functions X fX1 (x1 ) = 1/2,
y2
y2
y1

fX (x2 ) = 1/2, fX (x1 ) = 0 fX (x2 ) = 1, function fX





fX
(x2 , 1 ) = fX1 (x2 ) = 1/2 ,




fX
(x2 , 2 ) = fX2 (x2 ) = 1 .


fX
(x1 , 1 ) = fX1 (x1 ) , = 1/2




fX
(x1 , 2 ) = fX2 (x1 ) , = 0

clear context, write 1 denote function returns one
values domain 0 denote function returns always zero. x x ,
indicator function Ix returns one x = x zero otherwise.
f g functions domain x k real number, expressions f g
f = k denote f (x) g(x) f (x) = k, respectively, x x (e.g.,

previous example fX1 = 1/2). Finally, function domain containing
single element (e.g., empty domain) identified real number returns.
2.4 Definition
LIMID L consists direct acyclic graph (DAG) set variables U annotated
variable types (decision, chance value), together collection (conditional)
probability mass functions (one per chance variable) utility functions (one per value
variable). value nodes graph assumed children. precise
meaning arcs varies according type node point. Arcs entering
chance value nodes denote stochastic functional dependency, respectively; arcs
entering decision nodes describe information awareness time decision made.
variable X U, denote paX set parents X, is, set
nodes arc pointing X. Similarly, let chX denote set
children X (i.e., nodes arc X), faX , paX {X} denote
family. let C, V partition U sets chance, decision value
variables, respectively. chance variable C C associated set {p
C : paC }
100

fiSolving LIMIDs

V1

V2

V3

T1

T2

T3

uV1 (a) = uV2 (a) = uV3 (a) = 1
uV1 (w) = uV2 (w) = uV3 (w) = 0



pTO1 ,T2 ,T3 (s, t1 , t2 , t3 ) = I(a,a,a)
uV (s) = 7/2
uV (f ) = 0

V
Figure 1: LIMID representing fire dispatching problem.
(conditional) probability mass functions p
C quantifying decision makers beliefs
states x C conditional state parents (if C parents, single
probability mass function assigned). Using notation introduced previous section,
equivalently represent set probability mass functions associated variable C
pa
function pC C . assume chance variable X C stochastically independent
non-descendant non-parents given parents. value variable V V associated
real-valued utility function uV paV , quantifies (additive) contribution
states parents overall utility. Thus, thePoverall utility state x CD
given sum utility functions, is, u(x) = V V uV (xpaV ).
2.5 LIMID Fire Dispatching Problem
Figure 1 depicts LIMID fire dispatching problem. graph, chance, decision
value variables represented ovals, rectangles diamonds, respectively.
value variables V1 , V2 V3 associated utility functions uV1 , uV2 uV3 , respectively,
representing cost per unit dispatched. utility outcome quantified
function uV associated value variable V . chance variable associated
function pTO1 ,T2 ,T3 quantifies conditional probabilities P (O = o|T1 = tT1 , T2 =
tT2 , T3 = tT3 ) success (o = s) failure (o = f ) given joint decision T1 ,T2 ,T3 .
According model figure, dispatching three units results certain success,
whereas dispatching less three units leads failure.
2.6 Policies Strategies
decision variable least one parent, policy specifies action
possible state configuration parents, is, : paD .
parents, state . set policies variable denoted
. instance, policy T1 first unit running example state T1 .
space policies T1 given T1 = {a, w}.
Let , DD denote space possible combination policies. element
= (D )DD said strategy L. Given policy state paD , let

p
denote probability mass function conditional paD = pD = ID () .
parents, pD = ID unconditional probability mass function .
101

fiMaua, de Campos, & Zaffalon

pa

simplify notation, sometimes write pD irrespective whether parent.
pa
one-to-one correspondence functions pD policies
paD
specifying policy equivalent specifying pD vice-versa. denote
pa
set functions pD obtained way PD . So, instance, PT1 = {Ia , Iw }.
strategy induces joint probability mass function variables C
pa pa
ps ,
pC C
pD ,
(1)
CC

DD

associated expected utility
Es [L] ,

X

ps

CD

X

uV .

(2)

V V

Notice two sums Eq. (2) different semantics. outer (leftmost) sum
denotes sum-marginal
set variables C D, whereas inner (rightmost) denotes
overall utility function V V paV results sum functions uV .
fire dispatching problem, eight possible strategies consisting decision
act wait units, example, = (T1 , T2 , T3 ) = (a, w, a) possible
strategy. policy T1 = dispatches unit T1 induces probability mass function
pT1 = Ia T1 . Likewise, policy T2 = w induces function pT2 = Iw , policy
T3 = induces pT3 = Ia . strategy = (a, w, a) induces joint probability
mass function x O,T1 ,T2 ,T3
T1 ,T2 ,T3
ps (x) = pO
(x)pT1 (xT1 )pT2 (xT2 )pT3 (xT3 ) ,

expected utility
X
Es [L] =
ps [uV1 + uV2 + uV3 + uV ]
O,T1 ,T2 ,T3

=

X

h

ps (x) uV1 (xT1 ) + uV2 (xT2 ) + uV3 (xT3 ) + uV (xO ) = 2 .

xO,T1 ,T2 ,T3

optimal strategy = (a, a, a) dispatches units, hand,
expected utility Es [L] = 1/2.
2.7 Theoretical Complexity
treewidth graph measures resemblance tree given number
vertices largest clique corresponding triangulated moral graph minus one
(Bodlaender, 1996). Bayesian networks, complexity solving LIMID strongly
affected treewidth. Given LIMID L treewidth , evaluate expected
utility given strategy time space exponential (Koller & Friedman,
2009). Hence, bounded constant, computing Es [L] takes (at most) polynomial
time input size.
primary task LIMID find strategy maximal expected utility,
is, find
Es [L] Es [L]
102

s.

(3)

fiSolving LIMIDs

value Es [L] called maximum expected utility L denoted MEU[L].
real problems, enumerating strategies prohibitively costly. fact,
computing MEU bounded treewidth diagrams NP-hard (de Campos & Ji, 2008),
and, following result implies, remains NP-hard even simpler LIMIDs.
Theorem 1. Given singly connected LIMID treewidth equal two, variables three states, deciding whether strategy expected utility
greater given k NP-complete.
proof, based reduction partition problem (Garey & Johnson, 1979),
given appendix.
usual assumptions complexity theory, problem NP-hard solve
best available options (i) trying devise algorithm runs efficiently
many instances exponential worst-case complexity, (ii) trying develop
approximation algorithm instances provides polynomial time solution
provably within certain range optimal solution. Section 3, take option (i),
present algorithm efficiently computes optimal solutions many LIMIDs,
runs exponential time many others. following state result suggests
alternative (ii) likely unfeasible, even consider diagrams bounded
treewidth.
Given > 1, -approximation algorithm (for solving LIMID) obtains strategy

MEU[L]
Es [L] .
(4)

set = 1/(1 ), 0 < < 1, -approximation algorithm finds solution
whose induced relative error , is,
MEU[L] Es [L]
.
MEU[L]

(5)

following result indicates provably good approximation algorithms exist
unless P=NP.
Theorem 2. Given singly connected LIMID L bounded treewidth, (unless P=NP)
polynomial time -approximation algorithm, 1 < < 2 ,
number numerical parameters (i.e., probabilities utilities) required specify L.
defer proof appendix. result asserts algorithm finds
solutions LIMIDs polynomial time cannot guarantee relative error smaller
1 2 , even set inputs restricted LIMIDs bounded treewidth. Hence,
polynomial-time algorithm LIMIDs must eventually produce poor solutions,
relative error close one large models. exception treewidth
number states per variable bounded. cases, shown constructively
early work (Maua, de Campos, & Zaffalon, 2011) -approximation
algorithm runs polynomial time.
103

fiMaua, de Campos, & Zaffalon

2.8 Constraining LIMIDs Nonnegative Utilities
principle, utilities associated value variables LIMID take real
value. complicates ordering functions use algorithm
devise here. Fortunately, easily efficiently transform LIMID L
equivalent LIMID L0 utilities nonnegative whose optimal strategies
optimal strategies L. Moreover, obtaining Es [L] Es [L0 ] strategy
straightforward.
Let L LIMID let k denote smallest utility value associated
value variables, is, V V follows k uV , V
uV (x) = k x paV . following transformation generates new LIMID L0
whose value variables associated nonnegative values.
Transformation 3. value variable V V, substitute associated utility function
uV new utility function u0V = uV k.
transformation shifts utility functions uV 0, makes uV (x) = 0
least one V x paV . Since affects value variables, strategy L (the
LIMID transformation) valid strategy L0 (the transformed LIMID).
expected utilities strategy L L0 related according following
result.
Proposition 4. strategy s, Es [L] = Es [L0 ] + k|V|.
Proof. expected utility respect L0 given
Es [L0 ] =

X

=

X
x

V

=

X

X

ps (x)

x

X

u0V (xpaV )

V

X
ps (x)
[uV (xpaV ) k]
ps (x)

x

uV (xpaV ) k|V|

X

ps (x)

x

V

= Es [L] k|V| ,
last step follows

P

x ps (x)

= 1.

optimal strategy L satisfies Es [L] Es [L] s, hence Proposition 4
ensures Es [L] = Es [L0 ]+k|V| Es [L0 ]+k|V| = Es [L], implies
optimal strategy L0 . Similarly, optimal strategy L0 ,
proposition Es [L0 ] = Es [L] k|V| Es [L] k|V| = Es [L0 ] s, therefore
optimal L. following corollary summarizes results.
Corollary 5. strategy L0 optimal strategy optimal
strategy L.
104

fiSolving LIMIDs

Consider running example more. smallest utility value k = 1.
utilities associated value variables transformed LIMID L0 given
u0V (s) = 9/2

u0V (f ) = 1

u0V1 (a) = 0

u0V1 (w) = 1

u0V2 (a) = 0

u0V2 (w) = 1

u0V3 (a) = 0

u0V3 (w) = 1 .

strategy = (a, w, a) expected utility Es [L0 ] = Es [L] k|V| = 2 (1)4 = 2.
optimal strategy = (a, a, a) obtains Es [L0 ] = 9/2.
rest paper, consider LIMIDs nonnegative utilities, due
Proposition 4 incur loss generality.
2.9 Decision Nodes Many Parents Versus Parentless Decision Nodes
policy decision variable parents corresponds choice one states.
Hence, space policies nodes contains number policies polynomial
input. hand, cardinality space policies decision nodes
many parents exponential number states parents. see this, consider
ten-state decision variable D. parents space policies contains 10
4
policies. However, four ternary parent nodes, space contains 103 = 1081
policies.
One might wonder whether LIMIDs whose decision nodes many parents
difficult solve LIMIDs parentless decision nodes. show that,
least theoretical perspective, case, LIMID
efficiently mapped MEU-equivalent LIMID decision nodes parents.
show optimal strategy original diagram produced
optimal strategy transformed diagram. particularly relevant algorithms
search space policies, case algorithm devise here, allow
us, without loss generality, focus LIMIDs whose decision nodes parents.
formally describing transformation showing produces diagram
equal MEU, let us first give idea works. end, consider
LIMID L decision node least one parent (e.g., diagram Figure 2(a)),
let 1 , . . . , denote configurations paD . policy maps configuration
pa
decision . function pD associated policy seen

set probability mass functions pT1 , . . . , pTm pTi = p
= ID ( ) , is,
function pTi represents choice state fixed configuration parents.
Recall policy associated parentless variable simply choice state.
transformation replaces decision variable decision variables T1 , . . . , Tm
chance variables X1 , . . . , Xm policy Ti corresponds decision (i )
original variables policy (see diagram Figure 2(b)). chain X1 Xm chance
variables responsible making policy Ti active parents assume
configuration , occurs , either blocking allowing information
flow according value parents D. Thus, parents act selector
105

fiMaua, de Campos, & Zaffalon

paD

paD


X1

X2

chD

T1

T2



(a)

Xm

chD

Tm
(b)

Figure 2: piece diagram (a) (b) Transformation 6.

decides probability mass functions pTi associated decision nodes T1 , . . . , Tm
going used, transformed diagram acts original one. probability
X
,Ti ,paD
mass functions pXi1
set ensure Xi = Ti paD = Xi = Xi1

otherwise.
Transformation 6. Consider LIMID L decision node least one parent,
let 1 , . . . , denote configurations paD . Remove add = |paD |
chance nodes X1 , . . . , Xm decision nodes T1 , . . . , Tm domains Xi = Ti =
(for = 1, . . . , m). Add arc every parent X1 , . . . , Xm , arc
every Xi Xi+1 , < m, arc every Ti Xi , = 1, . . . , m. Add arc
Xm child D. Associate X1 function


xpaD = 1 xX1 = xT1
1,
,pa
pX11 (x) = 0,
xpaD = 1 xX1 6= xT1


1/m xpaD 6= 1 .
node Xi , = 2, . . . , m, associate function


1, (xpaD 6=



0, (xpaD 6=
X
,Ti ,paD

pXi1
(x)
=

pa


1, (x
=



0, (xpaD =







xXi
xXi
xXi
xXi

= xXi1 )
6= xXi1 )
= xTi )
6= xTi ) .

pa

Finally, functions pX X child X substituted Xm domain,
without altering numerical values.
Figure 2 depicts decision node many parents (on left) new sub-diagram
generated Transformation 6 (on right). difficult see treewidth
transformed diagram increased three, subgraph containing
new nodes, parents children triangulated contains cliques
|paD {Xi , Xi1 , Di }| variables.3 Also, transformation two different
decision variables affect different parts, hence transforming diagram diagram
parentless decisions increase treewidth three. following
result states optimality strategies preserved transformation.
3. Since treewidth given size largest clique triangulated moral graph minus one, |paD |
lower bound treewidth original graph.

106

fiSolving LIMIDs

Proposition 7. Let L0 result applying Transformation 6 decision variable
LIMID L, s0 denote strategy L0 , T1 , . . . , Tm denote corresponding
policies T1 , . . . , Tm s0 . Let policy ( ) = Ti
paD . Finally, let strategy L obtained substituting T1 , . . . , Tm s0
(and keeping remaining policies). optimal strategy L
s0 optimal strategy L0 .
proof appendix. decision variable original LIMID,
transformed model contains chance variables specifying m|D |3 values, decision
nodes |D | states. treewidth original diagram bounded,
bounded transformation takes polynomial time.4 example ten-state
decision variable four ternary parents, transformation replaces decision variable
34 = 81 decision variables whose space policies contain 10 elements each, besides
81 chance variables. combined space policies, is, T1 T81 contains
1081 elements, total search space still (doubly) exponential input.
However, algorithms take advantage smaller local policy spaces reach better
solutions, particularly true algorithm devise later on.
rest paper assume without loss generality decision nodes
parents utilities nonnegative.

3. Solving LIMIDs
section, describe new algorithm solving LIMIDs exactly propagating
multiple non-dominated solutions. start defining basic algebraic structure
algorithm, given framework valuation algebra. show
framework alone, similar one used SPU, might lead poor accuracy. thus
extend framework sets valuations attempt improve accuracy increasing
complexity. Efficiency obtained pruning sets cardinality kept small
possible without affecting accuracy.
3.1 Valuation Algebra
basic ingredients algorithmic framework representing handling information LIMIDs called valuations, encode information (probabilities, utilities
policies) elements domain. valuation associated subset
variables U, called scope. concretely, valuation scope x pair (p, u)
nonnegative real-valued functions p u domain x ; refer p u
probability utility part, respectively, . Often, write x make explicit
scope x valuation . x U, denoted set possible
valuations
scope x x . set possible valuations thus given , xU x . set
closed two basic operations combination marginalization. Combination
represents aggregation information defined follows.
Definition 8. = (p, u) = (q, v) valuations scopes x y, respectively,
combination valuation (pq, pv + qu) scope x y.
4. treewidth bounded output algorithm, is, optimal strategy, might
take space exponential input.

107

fiMaua, de Campos, & Zaffalon

Marginalization, hand, acts coarsening information:
Definition 9. = (p, u) valuationP
scope
P x, set variables
x, marginal valuation ( x\y p, x\y u) scope y. case, say
z , x \ eliminated , denote z .
Notice definitions combination marginalization slightly differ previous works influence diagrams (e.g., Lauritzen & Nilsson, 2001), usually require
division utility part probability part. removal division operation
turns important feature discuss maximality valuations later on,
otherwise definition equivalent valuations division, sense one
could easily reformulate message-passing algorithms SPU using definition.
terms computational complexity, combining two valuations scopes
x y, respectively, requires 3|xy | multiplications |xy | additions numbers;
computing , x, costs |xy | operations addition. words, cost
combining marginalizing valuation exponential cardinality scope (and
linear cardinality domain). Hence, wish work valuations whose
scope small possible. following result shows framework respects
necessary conditions computing efficiently valuations (in sense keeping
scope valuations obtained combinations marginalizations valuations
minimal).
Proposition 10. system (, U, , ) satisfies following three axioms (weak)
labeled valuation algebra (Shenoy & Shafer, 1990; Kohlas, 2003).
(A1) Combination commutative associative, is, 1 , 2 , 3

1 2 = 2 1 ,
1 (2 3 ) = (1 2 ) 3 .
(A2) Marginalization transitive, is, z z x z

(x
=
z )
z .

(A3) Marginalization distributes combination, is, x x ,
x z x
(x )z = x yyz .
Proof. (A1) follows directly commutativity, associativity distributivity product
sum real-valued functions, (A2) follows directly commutativity summarginal operation. show (A3), consider two valuations (p, u) (q, v) scopes
x y, respectively, set z x z x y. definition ,



X
X
[(p, u) (q, v)]z =
pq,
(pv + qu) .
xy\z

108

xy\z

fiSolving LIMIDs

Since x \ z = \ z, p u functions x , follows



X
X
X
X
X

q
v+u
q, p
(pv + qu) = p
pq,
xy\z

y\z

xy\z

y\z

y\z



X X
v ,
= (p, u)
q,
y\z

y\z

equals (p, y) (q, v)yz .
following result Kohlas (2003, Section 2.2) direct consequence (A3)
shall use prove correctness algorithm.
Lemma 11. x x , , z z x = , (x )z = x z
.
primary goal valuation algebra computation marginal valuations
form = (1 ) . Let {X1 , . . . , Xn } set variables appearing
scopes 1 , . . . , . marginal computed efficiently variable elimination
procedure5 receives set = {1 , . . . , } permutation variables
(1)
(k )
X1 , . . . , Xn , = 1, . . . , n replaces valuations , . . . , whose scope contains


(1)
(k ) (Xi )
variable (Xi ) marginal =
. Algorithm 1 describes
procedure. algorithm returns valuation j k , j , . . . , k n ,
equals Axioms (A1)(A3) (Kohlas, 2003, Section 4.1).
Algorithm 1 VariableElimination(x,,)
Input: permutation variables x = {X1 , . . . , Xn } set valuations =
{1 , . . . , } subsets x
Output: marginal valuation (1 )
1: Let 0
2: 1 n
(1)
(k)
3:
Let , . . . , denote valuations i1 whose scope contains (Xi )


(1)
(k) (Xi )
4:
Compute =
(1)

(k)

Let i1 {i } \ {i , . . . , }
6: end
7: return combination valuations n

5:

complexity variable elimination procedure given size largest
valuation generated loop. valuation might size exponential
size valuations 1 , . . . , given input, but, discuss later on, certain
conditions size bounded procedure takes time polynomial
input.
5. Variable elimination algorithms known literature fusion algorithms (Shenoy & Shafer,
1990) bucket elimination (Dechter, 1999).

109

fiMaua, de Campos, & Zaffalon

3.2 Computing Expected Utilities
use valuation algebra framework introduced compute expected utility
given strategy using variable elimination. Let = (D )DD strategy LIMID
L whose expected utility want compute, permutation variables
C D. assume decision nodes L parents (otherwise need first
apply Transformation 6), strategy simply configuration .
procedure Algorithm 2 computes expected utility induced strategy s.
pa
procedure calls variable elimination set contains valuation C = (pC C , 0)
chance variable, valuation V = (1, uV ) value variable, valuation
= (ID , 0) decision variable. following result.
Algorithm 2 ExpectedUtility(L, , s)
Input: LIMID L whose decision nodes parents, permutation variables
C D, strategy = (D )DD
Output: expected utility
1: Let
2: C C
pa
3:
Add C = (pC C , 0)
4: end
5: V V
6:
Add V = (1, uV )
7: end
8:
9:
Add = (ID , 0)
10: end
11: Let VariableElimination(C D, , )
12: return utility part

Proposition 12. procedure described Algorithm (2) returns expected utility
strategy s.
Proof. Let output Variable Elimination Algorithm. According Axioms
(A1)(A3), = ,
"
# "
# "
#
pa



=
pC C , 0
(ID , 0)
(1, uV ) .
CC

DD

V V

Let p u denote probability
. definition
P utility part, respectively,
Q
pa
combination, = (ps , ps V V uV ), ps = PXCD pX X (1). Since
ps isP
probability
P distribution C D, follows p = xCD ps (x) = 1. Finally,
u = CD ps V V uV , equals Es [L] (2).
Consider LIMID fire dispatching problem (Figure 1) strategy =
(a, w, a) whose expected utility want compute using procedure above. assume
110

fiSolving LIMIDs

utilities nonnegative (i.e., already applied Transformation 3). According procedure Algorithm 2, first generate set = {O = (pTO1 ,T2 ,T3 , 0), V1 =
(1, u0V1 ), V2 = (1, u0V2 ), V3 = (1, u0V3 ), V = (1, u0v ), T1 = (Ia , 0), T2 = (Iw , 0), T2 =
(Ia , 0)}. X1 = O, X2 = T1 , X3 = T2 , X4 = T3 , let permutation variables
(Xi ) = Xi = 1, . . . , 4. variable elimination algorithm
input produces valuations
1 = (V )O

2 = (V1 T1 1 )T1

3 = (V2 T2 2 )T2

4 = (V3 T3 3 )T3

loop, outputs valuation = 4 = (1, 2). Similarly, compute
expected utility optimal strategy = (a, a, a) run variable elimination
= {O = (pTO1 ,T2 ,T3 , 0), V1 = (1, u0V1 ), V2 = (1, u0V2 ), V3 = (1, u0V3 ), V = (1, u0v ), T1 =
(Ia , 0), T2 = (Ia , 0), T2 = (Ia , 0)}, outputs = (1, 9/2).
general, described procedure take time exponential input. However,
L bounded treewidth shown exists permutation
procedure takes time polynomial input. (e.g., Koller & Friedman, 2009,
Section 23.4.3). Hence, space strategies sufficiently small, find optimal
strategy simply ranking strategies according expected utilities. However,
expect feasible realistic diagram space strategies increases
exponentially number decision nodes (assuming parents), even
diagrams bounded treewidth bounded number states per variable.
3.3 Local Search Algorithms
first attempt design fast algorithm solve LIMIDs, one might suggest local
search scheme starts random solution repeatedly explores neighborhood
order find solution higher expected utility. treewidth diagram
bounded, expected utility neighbor solution efficiently computed,
complexity algorithm given size neighborhood. possible approach
define neighborhood solution strategies obtained changing
single policy, gives local search space polynomial input. Algorithm 3
describes greedy procedure step looks new policy improves
current best solution. algorithm guaranteed find strategy locally
optimal neighborhood, is, cannot improved changing one
policies. Lauritzen Nilsson (2001) stated sufficient conditions diagram
satisfy order guarantee solution produced local search procedure
(globally) optimal. Unfortunately, following example shows, conditions
violated even structurally simple chain diagrams, cases local search
procedure might output local optima poor accuracy.
Consider LIMID running example, suppose start strategy s0 =
(a, w, a), expected utility 2. first step might try improve policy
T1 , producing strategy = (w, w, a) whose expected utility 3. Since higher
expected utility initial solution, set sbest update highest
expected utility found. Next, try search better policy T2 , generate
strategy = (w, a, a). strategy expected utility 2, less
111

fiMaua, de Campos, & Zaffalon

Algorithm 3 GreedyPolicySearch(L, , s0 )
Input: LIMID L, permutation variables C D, initial strategy
s0 = (D )DD
Output: locally optimum strategy sbest
1: Let sbest s0 Esbest [L] ExpectedUtility(L, , s0 )
2: repeat
3:
Generate new candidate strategy replacing single policy sbest
4:
Compute Es [L] ExpectedUtility(L, , s)
5:
Es [L] > Esbest [L]
6:
Set sbest Esbest [L] Es [L]
7:
end
8: current solution cannot improved way
9: return sbest

X0

D1

D2

X1

X2

Dn



Xn

R

Figure 3: chain structure diagram n decision variables.
expected utility best solution found far. Finally, look better policy T3 ,
leads us strategy = (w, w, w), whose expected utility 4. Since better
current best solution set sbest update associated expected utility.
Since change single policy improve strategy, algorithm halts
solution whose expected utility 4 maximum expected utility 9/2 achieved
strategy = (a, a, a) (more 10% relative error), or, terms original diagram
(by means Proposition 4), expected utility zero maximum expected utility
1/2.
procedure described similar SPU algorithm,
illustrates pitfalls local search. fact, SPU output local optimum
(but would start uniform policy every decision variable). Note solution
obtained greedy local search example degrades ratio utility
success (achieved strategy (a, a, a)) utility failure increases. instance,
utility success increased u0V (s) = 10 utility failure remained
same, is, u0V (f ) = 0, algorithm would reach solution whose expected utility
4, error 60% relative maximum expected utility 10. Moreover, cases
SPU performs poorly rare. instance, plots Figure 4 show SPUs relative
performance chain diagrams one Figure 3. diagram generated
independently sampling conditional distribution associated chance node
symmetric Dirichlet distribution parameter 1/m, number variable
states. maximum expected utility diagram computed using algorithm
devise here, took less 3 seconds diagram experiment.
(blue) point plots Figure 4 depict relative error SPU given
diagram. (red) line indicates third quartile fixed configuration. di112

fiSolving LIMIDs

0.6

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Relative error

0.5
0.4
0.3
0.2
0.1
0
10
20
30
40
50
Number decision nodes

10
20
30
40
50
Number states per variable

Figure 4: Relative performance SPU randomly generated chain diagrams. (blue)
circle depicts experiment (red) line depicts third quartile.
agrams left hand-side plot obtained number states fixed 15,
diagrams right number decision variables fixed ten.
example, see third quartile line right-hand side plot 25%
chain diagrams 20 states ten decision variables, SPU returned strategy
(MEU[L] Es [L])/ MEU[L] 0.1. Also, cases SPU obtains 70%
relative error. hand, see majority cases solution
returned SPU achieved relative error less 10%. all, experiments
show local search effective many cases, may produce poor results.
3.4 Ordered Valuations
exploit redundancy computation expected utility neighboring
strategies decide whether candidate solution improves current solution without
run variable elimination completely? instance, evaluating quality
new candidate strategy differs current best strategy policy
associated T1 , insight inspecting two valuations 2 produced
variable elimination example Section 3.2 using two different strategies? Fortunately,
answer yes, show need concept ordered valuations.
Let us define partial order (i.e., reflexive, antisymmetric transitive relation)
, set possible valuations, follows.
Definition 13. two valuations = (p, u) = (q, v) , say
dominates (conversely, say dominated ), write ,
equal scope, p q, u v.
scope x, deciding whether dominates costs 2|x | operations
comparison numbers. following result shows algebra valuations
monotonic respect dominance.
Proposition 14. system (, U, , , ) satisfies following two additional axioms
ordered valuation algebra (Haenni, 2004).
113

fiMaua, de Campos, & Zaffalon

(A4) Combination monotonic respect dominance, is,
x x (x ) (x ) .
(A5) Marginalization monotonic respect dominance, is,

x x
x x .

Proof. (A4). Consider two valuations (px , ux ) (qx , vx ) scope x (px , ux )
(qx , vx ), two valuations (py , uy ) (qy , vy ) scope satisfying (py , uy ) (qy , vy ).
definition , px qx , ux vx , py qy uy vy . Since
functions nonnegative, follows px py qx qy , px uy qx vy py ux qy vx .
Hence, (px , ux ) (py , uy ) = (px py , px uy + py ux ) (qx qy , qx vy + qy vx ) = (qx , vx ) (qy , vy ).
(A5). Let subset x. follows monotonicity respect addition
real numbers



X
X
X
X
(px , ux )y =
px ,
ux
qx ,
vx = (qx , vx )y .
x\y

x\y

x\y

x\y

Hence, result follows.
Axioms (A4) (A5) assert combination marginalization preserve partial
ordering valuations. allow us detect suboptimal strategies early
variable elimination procedure. Consider comparing strategies = (w, w, w) s0 =
(w, a, w) LIMID running example. third iteration loop (i.e.,
= 3), variable elimination procedure produces valuations s3 = (ps3 , us3 )
0
0
0
s3 = (ps3 , us3 ) strategies s0 , respectively,
ps3 (a) = 1 ,

ps3 (w) = 1 ,

us3 (a) = 3 ,

us3 (w) = 3 ,

0

ps3 (w) = 1 ,

0

0

us3 (w) = 2 .

ps3 (a) = 1 ,

0

us3 (a) = 2 ,
0

0

0

Thus, s3 s3 . Since s4 = (sT3 V3 s3 )T3 s4 = (sT3 V3 s3 )T3 , know
0
Axioms (A4) (A5) s4 s4 , hence Es0 [L] Es [L]. Therefore,
need continue execution variable elimination s0 , expected value cannot
higher s.
Unfortunately, suboptimal solutions always produce valuations dominated optimal one variable elimination. example, consider strategies
= (a, w, a) = (a, a, a). third step, variable elimination generates valuations



s3 = (ps3 , us3 ) s3 = (ps3 , us3 )
ps3 (a) = 1 ,

ps3 (w) = 1 ,

us3 (a) = 2 ,

us3 (w) = 2 ,




ps3 (w) = 1 ,



us3 (w) = 1 .

ps3 (a) = 1 ,



us3 (a) = 9/2 ,
114

fiSolving LIMIDs



Thus, even though optimal strategy, s3 6 s3 .
algorithm devise later exploits fact suboptimal solutions
early detected eliminated search space. suboptimal solutions
might eliminated variable elimination, algorithm runs exponential time
worst case, expected, problem NP-hard. Fortunately,
experiments random problems suggest situations frequent.
3.5 Sets Valuations
multiple runs variable elimination different inputs elimination ordering (i.e., permutation variables) represented sets framework
algorithm devise later on. instance, might consider set 3 valuations
3 produced variable elimination third iteration loop every possible
strategy. Due monotonicity combination marginalization respect ,
immediately halt computation valuations 3 dominated
other, is, remove dominated valuations 3 . formalized
concept maximal valuations operator max:
Definition 15. Given finite set valuations , say maximal
holds . operator max returns set max()
maximal valuations .
x set valuations scope x, set maximal valuations max(x )
obtained m2 comparisons , (, ) x x .
valuations set x scope x, say x scope
x. extend combination marginalization sets valuations follows.
Definition 16. x two sets valuations ,
x , {x : x x , }
denotes set obtained combinations valuation x valuation .
Definition 17. x x set valuations scope x x,


x , {x : x x }

denote set valuations obtained element-wise marginalization valuations y.
checked sets valuations combination marginalization defined
element-wise satisfy axioms (A1)(A3), therefore form valuation algebra. Hence,
Lemma 11 applies sets valuations marginalization combination defined
above.
Lemma 18. x x two sets valuations scope x y,
respectively, z set variables z z x = , (x )z =
x yz .
Proof. result follows element-wise application Lemma 11 (x )z
(x )z .
115

fiMaua, de Campos, & Zaffalon

3.6 Solving LIMIDs Exactly
ready describe MultiplePolicyUpdating (MPU) algorithm,
solves arbitrary LIMIDs exactly. algorithm assumes decision nodes
variables, utilities nonnegative, hence Transformations 6 3
applied running algorithm case assumptions fail.
Consider LIMID L permutation variables C D, let n = |C D|.
pa
algorithm initialized generating set S0 contains singleton {(pC C , 0)}
chance variable C, singleton {(1, uV )} value variable V set
valuations {(pD , 0)}, contains one element (pD , 0) per policy , decision
variable D. set-valued variable elimination performed sets valuations
S0 , dominated valuations discarded set marginalization. Finally,
optimal solution obtained utility part single maximal valuation
set combination sets valuations Sn obtained variable elimination.
procedure detailed Algorithm 4.
Algorithm 4 MultiplePolicyUpdating(L, )
Input: LIMID L permutation variables C
Output: maximum expected utility
1: Let S0
2: C C
pa
3:
Add singleton {(pC C , 0)} S0
4: end
5: V V
6:
Add singleton {(1, uV )} S0
7: end
8:
9:
Add set {(Id , 0) : } S0
10: end
11: 1 n
(1)
(k)
12:
Let , . . . , denote
whose
h sets Si1
scope contains (Xi )

(1)
(k) (Xi )
13:
Compute = max
(1)

(k)

Let Si Si1 {i } \ {i , . . . , }
15: end
16: Let denote set combination sets Sn
17: return utility part u (p, u) max(S)

14:

Since variables eliminated end loop, valuations sets
empty scope probability utility parts identified
numbers. Hence, algorithm outputs expected utility (i.e., real number) line 17.
Let us illustrate algorithm example. more, consider LIMID L
fire dispatching problem applying Transformation 3 assume elimination
ordering variables used example Section 3.2. start empty set
116

fiSolving LIMIDs

S0 . chance variable, add set
= {(pTO1 ,T2 ,T3 , 0)}
S0 . add sets
V1 = {(1, u0V1 )} ,

V2 = {(1, u0V2 )} ,

V3 = {(1, u0V3 )} ,

V = {(1, u0V )}

S0 due value variables V1 , V2 , V3 V , respectively. decision variable T1
causes set
T1 = {(Ia , 0), (Iw , 0)}
scope T1 included S0 , similarly, variables T2 T3 , is, add
sets
T2 = {(Ia , 0), (Iw , 0)} ,

T3 = {(Ia , 0), (Iw , 0)} ,

scopes T2 T3 , respectively, S0 , obtaining S0 = {O , V1 , V2 , V3 , V , T1 , T2 , T3 }.
first iteration (i = 1) variable elimination loop (lines 1115),


1 = max [V ]O = {(p1 , u1 )} ,
p1 u1 functions T1 ,T2 ,T3 p1 = 1 u1 (a, a, a) = 9/2,
u1 (x) = 1 x 6= (a, a, a). Note 1 singleton since singletons
involved computation. second iteration


w
2 = max [V1 T1 1 ]T1 = {(pa2 , ua2 ), (pw
2 , u2 )} ,
w

w

pa2 , ua2 , pw
2 , u2 functions T2 ,T3 p2 = p2 = 1, u2 (a, a) = 9/2,

w
u2 (x) = 1 x 6= (a, a), u2 = 2. Note labeled functions
according policies T1 generated them. allows us easily extract
optimal strategy end algorithm.
third iteration need compute


3 = max [V2 T2 2 ]T2
(a,a)

= max({(p3
(a,a)

= {(p3
(a,a)

(a,a)

(a,w)

(a,a)

, u3

(a,a)

(a,w)

), (p3

(w,w)

(a,w)

, u3

(w,w)

, u3

), (p3

, u3

(a,w)

(w,w)

(w,w)

(w,w)

), (p3

(w,w)

, u3

)})

)} ,
(a,a)

p3 , u3 , p3
, u3
, p3
, u3
functions T3 p3
=
(a,w)
(w,w)
(a,a)
(a,a)
(a,w)
(w,w)
p3
= p3
= 1, u3 (a) = 9/2, u3 (w) = 1, u3
= 2, u3
= 3. Note
valuation associated policies T2 = w T2 = appear 3
(a,w) (a,w)
generate valuation equal (p3
, u3
). implies strategies (a, w, w)
(w, a, w) expected utility, strategies (a, w, a) (w, a, a).
117

fiMaua, de Campos, & Zaffalon

last iteration, generate set


4 = max [V3 T3 3 ]T3
(a,a,a)

(a,a,a)

= max({(p4

, u4

(a,a,a)

(a,a,a)

= {(p4

, u4

(a,a,a)

(a,a,a)

(w,w,a)

), (p4

(w,w,a)

, u4

(a,a,w)

), (p4

(a,a,w)

, u4

(w,w,w)

), (p4

(w,w,w)

, u4

)})

)} ,
(w,w,a)

(w,w,a)

(a,a,w)

(a,a,w)

(w,w,w)

(w,w,w)

p4
, u4
, p4
, u4
, p4
, u4
, p4
, u4
functions
(a,a,a)
(w,w,a)
(a,a,w)
(w,w,w)
(a,a,a)
empty set p4
= p4
= p4
= p4
= 1, u4
= 9/2,
(w,w,a)
(a,a,w)
(w,w,w)
u4
= 3, u4
= 2, u4
= 4.
(a,a,a)
Finally, S4 = {4 }, algorithm returns u4
= 9/2,
expected utility optimal strategy (a, a, a). one see, optimal strategy
easily recovered labeling valuations corresponding policies.
Differently message-passing algorithms obtain approximate solutions
LIMIDs (repeatedly) propagating single valuation (e.g., SPU algorithm),
MPU algorithm computes exact solutions propagating several maximal valuations
correspond partial combinations local decision rules. efficiency algorithm
handling propagation many valuations derives early removal valuations
performed max operation propagation step.
Consider set L , {s : }, given
"

#


=

pa

pC C , 0



"


CC

#


DD

(Id , 0)

#!

"


(1, uV )

V V

functions Id consistent policies s. difficult see
#

"


L =


pa
pC C , 0

CC



#


{(Id , 0) : }

#!

"


{(1, uV )}

V V

DD




=

"



X

.

X S0

Hence, Proposition 12 L valuation probability part
one utility part equal expected utility strategy . Since relation
induces strict (linear) order L , MEU diagram equals utility part
(single) valuation max(L ).
N variable elimination procedure propagation
step responsible
Nfor obtaining max( Sn ) = max(L ) efficiently distributing
max X S0 X , allows significant reduction cardinalities
sets scopes valuations produced.
formally prove correctness algorithm. start showing max
distributes marginalization combination:
Lemma 19. (Distributivity maximality). x x two finite sets
ordered valuations z x, following holds.
118

fiSolving LIMIDs

(i) max(x max(y )) = max(x );
(ii) max(max(x )z ) = max(z
x ).
Proof. Part (i) shown Fargier, Rollon, Wilson (2010, Lemma 1(iv)).
use similar proof show part (ii) holds. First, show max(z
x )
z
z
max(max(x ) ). Assume, show contradiction, element x max(z
x ),
x x , element max(max(x )z ). definition max(x ),
z
z
z
x max(x ) x x . Hence, (A5) implies z
x x , x x
z
z
z
z
follows z
/ max(max(x )z )
x = x , therefore x max(x ) . Since x
z max(max(x )z ) z
x z . contradicts initial assumpz
tion since z x .
Let us show max(xz ) max(max(x )z ). Assume contradiction
z
z
z max(max(x )z ) \ max(z
x ). Since z x , z max(x )
z
z z . shown max(x ) max(max(x )z ), hence z = z
z max(z
x ), contradiction.
iteration propagation step, combination sets current pool
sets Si produces set maximal valuations initial factorization marginalized
Xi+1 , . . . , Xn :
Lemma 20. {0, 1, . . . , n}, follows

{X1 ,...,Xi }






max

,
= max
S0

Si

i, Si collection sets valuations generated i-th iteration
propagation step MPU.
Proof. induction i. basis (i = 0) follows trivially.
Assume result holds i, is,



{X1 ,...,Xi }




max

.
= max
Si

S0

eliminating Xi+1 sides applying max operation get

{X1 ,...,Xi } Xi+1

Xi+1







max max



= max max
.




S0

Si

119

fiMaua, de Campos, & Zaffalon

Applying Lemma 19(ii) sides (A2) left-hand side yields


{X1 ,...,Xi+1 }
Xi+1




max


= max

S0

Si



= max

Xi+1











Bi+1

Si \Bi+1



= max



Xi+1


max






Bi+1

Si \Bi+1


= max








Si \Bi+1


= max




,

Si+1

passage first second identity follows element-wise application
(A1) Lemma 11, third follows second Lemma 19(i), last two
follow definitions Si+1 , respectively.
able show correctness algorithm solving LIMIDs exactly.
Theorem 21. Given LIMID L, MPU outputs MEU[L].

N
Proof. algorithm returns utility part valuation (p, u) max
, which,

n
N

Lemma 20 = n, equals max

. definition S0 , valuation
S0

N

S0 satisfies
"
=

#

CC


pa
pC C , 0

"


#


DD

(Id , 0)

"

#


(1, uV ) ,

V V

combination decisions (d)
N , corresponds strategy ,
exactly one valuation
S0 strategy . Hence, Propo
N
sition 12, set
contains pair (1, Es [L]) every strategy inducing
S0
distinct expected utility. Moreover, since functions empty scope correspond

N
numbers, relation specifies total ordering valuations
,
S0
strategy associated (p, u). Since
implies single maximal
element.
Let

N

(p, u) max

, follows maximality Es [L] Es [L] s,
S0
hence u = MEU[L].
120

fiSolving LIMIDs

3.7 Complexity Analysis
variable elimination, complexity algorithm depends permutation given input. time complexity algorithm given cost creating
sets valuations initialization step plus overall cost combination
marginalization operations performed propagation step. Regarding initialization step, loops chance value variables generate singletons, thus take time
linear input. Since decision nodes parents, set added due decision variable contains , |D | valuations. Let , maxDD cardinality
largest domain decision variable. initialization loop decision variables
takes O(|D|) time, polynomial input. Let us analyze propagation
step. running time propagating (sets of) valuations exponential maximum
number variables scope valuations generated loop step.
number depends permutation chosen best case equal treewidth
diagram plus one. Although finding optimal permutation (i.e., one leads
minimum maximum number variables per scope) NP-hard task, generate
permutations using standard heuristics variable elimination Bayesian networks,
minimizing number fill-ins cardinality domain neighbor
set, empirically shown produce good elimination orderings (Jensen &
Nielsen, 2007; Koller & Friedman, 2009).
Consider permutation induces maximum number variables per scope
, diagram bounded number states per variable . cost
combination marginalization bounded constant, complexity depends
number operations performed. Moreover, case .
Let denote cardinality largest set , = 1, . . . , n. Thus, computing
requires |U |1 operations combination (because
maximum number
N
sets might need combine compute Bi propagation step)
operations marginalization. worst case, equal |D| O(|D| ), is,
sets associated decision variables combined without discarding valuation.
Hence, worst-case complexity propagation step exponential number
decision variables, even width elimination ordering number states per
variable bounded. Note however pessimistic scenario and, average,
removal non-maximal elements greatly reduces complexity, experiments
Section 4 show.
3.8 Reverse Topological Ordering
valuations used MPU specify twice many numbers cardinality domain
associated scope. possible decrease number numerical parameters per
valuation algorithm needs handle factor two constraining elimination
variables follow reverse topological ordering according diagram, is,
requiring variable processed descendants processed.
following result shows, reverse topological ordering produces valuations whose
probability part equals one coordinates.

121

fiMaua, de Campos, & Zaffalon



B

V1



C

E

V2

F

Figure 5: LIMID reverse topological ordering increases treewidth.

Proposition 22. defines reverse topological ordering variables C D,
= 1, . . . , n valuations probability part p = 1, 1 function
always returns unity.
Proof. show result induction i. Regarding basis, reverse
topological ordering X1 variable containing value nodes children. Hence,
paX
B1 = {X1 } {{(1, uV )} : V chX1 }, definition X1 equals {(pX1 1 , 0)}
paX

paX

X1 chance node, {(pX1 1 , 0) : pX1 1 PX1 } decision node. follows
P
paX P
paX P
1 = max({( X1 pX1 1 , X1 pX1 1 V chX uV )}). Since paX , p
X1
1
1
P
paX
1
probability mass function X1 , p =
= 1. Assume
X1 pX1
N
inductive hypothesis


result
holds

1,
.
.
.
,


1,

let

,
x
Bi \S0 .
N
= max([ Bi S0 ] x ). inductive hypothesis valuations set Bi \ S0
probability part p = 1. Hence, definition combination, valuations x
contain probability part equal one. reverse topological ordering implies
time variable Xi processed propagation step, children
paX
processed. Hence, element Bi S0 set Xi , equals {(pXi , 0)} Xi
paX

paX

chance node, {(pXi , 0) : pXi PXi } Xi decision node, {(1, uXi )}
value node. Thus, = max(Xi x ). case Xi value node
immediate, since valuation result combination two valuations
probability part equal one. Xi value node


X


paX X paX
paX
= max
pXi ,
pXi ux : (pXi , 0) faXi , (1, ux ) x
Xi

Xi



X


paX
paX
= max 1,
pXi ux : (pXi , 0) Xi , (1, ux ) x ,
Xi

since p
Xi probability mass function paX .


result states assume reverse topological elimination ordering, MPU
needs care utility part valuations. Unfortunately, constraining
elimination order might increase complexity algorithm, following example
shows.
Consider LIMID Figure 5, variables assumed binary (we omit
specification probabilities utilities relevant matter).
122

fiSolving LIMIDs

initialization, S0 = {A , B , C , , E , F , V1 , V2 }. Using reverse
topological elimination ordering implies first eliminate E, generates
set


1 = max [E , V1 V2 ]E = {(1, u1 )} ,

whose single element (1, u1 ) scope {A, C, D, F } size 24 = 16. Eliminating variables
ordering F, C, B, A, D, E, hand, generates following sets.


1 = max [F V2 C ]F = {(p1 , u1 )} ,


2 = max [C E 1 ]C = {(p2 , u2 )} ,

n

(d) (d)
3 = max [B ]B = (p3 , u3 ) : ,

n

(d) (d)
4 = max [A V1 3 ]A = (p4 , u4 ) : ,
n


(d) (d)
5 = max [2 4 ]D = (p5 , u5 ) : ,
n


(d)
=
(1,
u
)
:



.
6 = max E

5
6
scopes valuations 1 , 2 , 3 , 4 , 5 6 are, respectively, {E, C}, {D, E},
{D, A}, {E, D}, {E} {}. one see, largest valuation generated using ordering
F, C, B, A, D, E contains two variables scope therefore size 22 = 4.
four-fold decrease size compared size set 1 generated using reverse
topological ordering.
Notice however even though using reverse topological ordering might increase
size valuations generated variable elimination, necessarily results
higher complexity MPU. overall complexity algorithm
depends size largest valuation generated cardinality
generated sets, possible reverse topological ordering induces significantly
smaller sets, produces valuations whose probability parts always equal one,
might increase number dominated elements.

4. Experiments
evaluate performance algorithm random LIMIDs generated following
way. LIMID parameterized number decision nodes , |D|, number
chance nodes c , |C|, maximum cardinality domain family chance
variable C , maxC |faC |, maximum cardinality domain family
decision variable , maxD |faD |. set number value nodes v + 2.
variable Xi , = 1, . . . , c + + v, sample Xi contain 2 4 states.
repeatedly add arc decision node children value node
parents (so decision node least one value node children).
step guarantees decisions relevant computation MEU. Finally,
repeatedly add arc neither makes domain variable greater given
bounds makes treewidth 10, arcs added without exceeding
123

fiMaua, de Campos, & Zaffalon

bounds.6 Note generates diagrams decision chance variables
log2 1 log2 C 1 parents, respectively. DAG obtained,
randomly sample probability mass functions utility functions associated chance
value variables, respectively.
compare MPU CR algorithm de Campos Ji (2008) 1620 LIMIDs
randomly generated described procedure parameters 5 50, 8 c 50,
8 64 16 C 64. MPU implemented C++ tested
computer CR.7 Table 1 contrasts running times algorithm (averages
standard deviation) different configurations randomly generated LIMIDs. row
contains percentage solved diagrams (SCR SMPU ) time performance (TCR
TMPU ) algorithms N diagrams randomly generated using parameters
d, c, v, , C . fixed parameter configuration, MPU outperforms CR
orders magnitude (line 12 contains case average running time
CR lower MPUs, note case CR solve one instance, whereas
MPU solved 86% instances). Also, CR unable solve diagrams
50 variables, whereas MPU could solve diagrams containing 150 variables
32. algorithms failed solve diagrams = 64. diagram
consider unsolved algorithm algorithm able reach exact solution
within limit 12 hours. all, MPU appears scale well number nodes
(i.e., d, c v) poorly domain cardinality family decision variables
(i.e., ).
good succinct measure hardness solving LIMID total number
strategies ||, represents size search space brute-force approach. ||
loosely interpreted total number alternatives (over decision variables)
problem instance. Figure 6 depicts running time number strategies
log-log scale two algorithms test set random diagrams.
algorithm, solved instances shown, covers approximately 96% cases
MPU, 68% CR. note MPU solved cases CR solved (but
opposite). Again, see MPU orders magnitude faster CR. Within limit
12 hours, MPU able compute diagrams containing 1064 strategies, whereas
CR solved diagrams 1025 strategies.
reduction complexity obtained removal non-maximal valuations
propagation step checked Figure 7, shows maximum cardinality
set generated propagation step contrast number strategies.
diagram (a point figure) solved MPU, cardinality sets remains bounded
106 vary number strategies (which equals largest cardinality
propagated set worst case valuation discarded). shows
worst-case analysis Section 3.7 pessimistic.
6. Since current algorithms checking whether treewidth graph exceeds fixed k slow
k 5 (Bodlaender, 1996), resort greedy heuristic resulted diagrams whose actual
treewidth ranged 5 10.
7. used CR implementation available http://www.idsia.ch/~cassio/id2mip/ CPLEX
(http://www.ilog.com) mixed integer programming solver. implementation MPU
downloaded http://www.idsia.ch/~cassio/mpu/.

124

fiSolving LIMIDs

N



c

v



C

SCR (%)

TCR (s)

SMPU (%)

TMPU (s)

60
60
60
60
60
60
60
60
30
30
60
30
30
60
60
90
30
60
30
30
60
60
30
60
60
60
60
30
60
30
30
30
30

5
5
5
10
10
10
10
10
10
10
10
10
10
10
20
20
20
20
20
20
20
10
10
20
20
20
30
30
30
30
30
50
50

8
8
8
8
8
8
28
28
28
28
28
28
28
28
8
8
8
8
8
8
8
78
78
58
58
58
38
38
38
88
88
48
48

7
7
7
12
12
12
12
12
12
12
12
12
12
12
22
22
22
22
22
22
22
12
12
22
22
22
32
32
32
32
32
52
52

12
16
8
12
16
8
12
16
16
32
32
32
64
8
12
16
16
32
32
64
8
16
32
12
16
8
12
16
8
12
8
12
8

16
16
16
16
16
16
16
16
64
16
32
64
64
16
16
16
64
32
64
64
16
16
16
16
16
16
16
16
16
16
16
16
16

100
100
100
98
93
100
96
83
10
93
0
3
0
100
93
38
30
0
0
0
100
60
70
50
11
96
28
0
96
0
60
0
10

6 45
9 43
6 51
15 53
107 273
0.4 0.2
1175 6126
3340 8966
2838 1493
1070 2461

73 0

13
2687 7564
5443 10070
9660 10303



7 20
5944 9920
3820 8127
6455 9344
11895 12662
849 4098
3416 4827

2261 6572

3448 5837

5014 2974

100
100
100
100
100
100
100
100
96
100
93
86
0
100
100
98
100
78
76
0
100
100
100
100
100
100
98
100
100
100
100
96
100

0.006 0.01
0.02 0.05
0.002 0.01
0.02 0.02
103 786
0.007 0.01
0.05 0.08
0.2 0.2
47 142
0.2 0.4
905 2847
2440 7606

0.01 0.007
155 1196
270 1822
29 84
938 1417
1592 3402

0.02 0.008
0.5 0.5
0.6 1
522 4011
2 11
0.07 0.04
35 214
2 10
0.1 0.03
230 1027
0.2 0.1
1753 7405
0.5 0.09

Table 1: Performance MPU CR randomly generated LIMIDs (numbers
rounded down).

125

fiMaua, de Campos, & Zaffalon

105

MPU
CR

Running time (s)

104
103
102
101
100
101
102
101

1020
1040
1060
Number strategies (||)

Maximum set cardinality (maxi |i |)

Figure 6: Running time MPU CR randomly generated LIMIDs.
106
105
104
103
102
101
100
101

1020
1040
1060
Number strategies (||)

Figure 7: Maximum number valuations set propagation step MPU.

5. Related Work
Influence diagrams introduced Howard Matheson (1984) concise language
specification utility-based decision problems. substantial literature
formalizes influence diagrams develop algorithms premises forgetting
regularity (Cooper, 1988; Qi & Poole, 1995; Shachter & Peot, 1992). point
interested reader works Jensen Nielsen (2007) Koller Friedman (2009).
Zhang et al. (1994) studied families LIMIDs could solved dynamic programming, LIMIDs respecting forgetting regularity. SPU algorithm
Lauritzen Nilsson (2001) solves cases polynomial time diagram
126

fiSolving LIMIDs

bounded treewidth. best knowledge, attempt (globally) solve arbitrary LIMIDs exactly without recurring exhaustive search space strategies
CR algorithm de Campos Ji (2008) compare algorithm.
Shenoy Shafer (1990) introduced framework valuation algebras, states
basic algebraic requirements efficient computation valuations. recently,
Haenni (2004) incorporated partially ordered preferences algebra enable approximate computation. Fargier et al. (2010) extended framework preference
degree structure order capture common algebraic structure optimization problems based partial order. algebra develop Section 3 partly casted
framework.
PFU framework Pralet, Verfaillie, Schiex (2007) subsumes many formalisms
probabilistic reasoning, constraint satisfaction decision making. comes
decision problems framework geared towards sequential decision making
equivalent assumptions non-forgetting, although authors mention possibility
extending limited information decision scenarios.
variable elimination algorithm develop conceptually close message
passing algorithm Dubus, Gonzales, Perny (2009). algorithm, however,
handle uncertainty target primarily obtention Pareto-efficient solutions
specific class multi-objective optimization problems.
close relation maximum posteriori (MAP) inference Bayesian
networks LIMIDs whose decision variables parents. sense, algorithm de Campos (2011), solves MAP propagating Pareto efficient probability
potentials join tree, relates ours.

6. Conclusion
Solving limited memory influence diagrams hard task. complexity results
presented show problem NP-hard even diagrams bounded treewidth
number states per variable, obtaining provably good approximations
polynomial time unlikely number states small.
Despite theoretical hardness problem, developed algorithm
spite exponential worst-case complexity performed empirically well large set
randomly generated problems. algorithms efficiency based early removal
suboptimal solutions, helps algorithm drastically reduce search space.
Designing good heuristics elimination orderings algorithm seems
complex task standard variable elimination algorithms (e.g., belief
updating Bayesian networks), second component, cardinality
set, together domain cardinalities wish minimize. fact, preliminary
experimentation shown favoring set cardinality expense domain cardinality
might good approach. Unlike standard variable elimination, given elimination
ordering LIMID, seem possible determine true complexity
MPU advance (i.e., prior running algorithm). open question whether
MPUs complexity estimated beforehand, heuristics finding elimination
orderings perform better.
127

fiMaua, de Campos, & Zaffalon

Acknowledgments
work partially supported Swiss National Science Foundation (SNSF)
grants no. 200020 134759/1, 200020 137680/1 200020 132252, Hasler Foundation grant
no. 10030, Canton Ticino Computational Life Sciences Project. thank
reviewers pointing us related work making number comments helped
us improve readability paper. short version paper appeared NIPS
11 (Maua & de Campos, 2011).

Appendix A. Missing Proofs
section contains long proofs supporting results left main part
text improve readability.
following two lemmas used proof Theorem 1 later on.
Lemma 23. 2 real number nonnegative integer 2 + 2(i+3) <

2+2 .
Proof. Since 2 22 , 2 + 2(i+3) = 2 + 22 2i1 2 (1 + 2i1 ),

sufficient show 1 + 2i1 < 22 . Binomial Theorem


(1 + 2

i1 2i

)

=

2
X
2
k=0

k

(2i1 )k .

k = 0, . . . , 2i ,

2
2i (2i 1) (2i k + 1)
=
(2i )k .
k
k!
Hence,


(1 + 2

i1 2i

)



2
2

X
X
X
k i1 k
k

(2 ) (2
) =
2
2k = 2 ,
k=0

2i

therefore 1 + 2i1 < 2

k=0

k=0

.
4

Lemma 24. 0 x 1/2 2x1 + 2x1 2x .
Proof. obtain result approximating functions left- right-hand side
inequalities truncated Taylor expansions f (x) g(x), respectively,
4
showing 2x1 + 2x1 f (x) g(x) 2x . n-th order Taylor expansion
left-hand side around zero given
Tn (x) = 1 +

n/2
X
[ln(2)]2k
k=1

(2k)!

x2k .

Clearly, series converges hence 2x1 + 2x1 = limn Tn (x). Moreover,
n, residual Rn (x) = 2x1 + 2x1 Tn (x) positive terms sum
128

fiSolving LIMIDs

non negative. Thus,
f (x) = T2 (x) = 1 +

[ln(2)]2 2
x 2x1 + 2x1 .
2

similar fashion, apply variable change = x4 right-hand side
obtain Taylor expansion around zero, given
Tn0 (y) = 1 +
=1+

n
X
[ln(2)]k
k=1
n
X
k=1

k!

yk

[ln(2)]k 4k
x ,
k!

converges positive residual. Hence,
4

2x = lim Tn0 (x)
n

= 1 + x4 ln(2) + x2 ln(2)


X
[ln(2)]k1
k=2

1 + x4 ln(2) + x2 ln(2)


X
k=2

= 1 + x4 ln(2) +

[ln(2)]2
32

1

k!
!

!
x4k2

24k1

x2 = g(x) .

inequality obtained noticing [ln(2)]k1 /k! < 1/2, x 1/2 ln(2)
geometric series

X
k=2

1
24k1




1 X 1 k
1
ln(2)
1 X 1 k
< 7
= 6 <
.
= 7
4
2
2
2
2
2
32
k=0

k=0

Finally, since x2 1/4 < 15 ln(2)/32


ln(2)
2
g(x) = 1 + x ln(2) x +
32


15
ln(2)
2
< 1 + x ln(2)
ln(2) +
32
32
2
[ln(2)] 2
=1+
x = f (x) .
2
2

4

Hence, 2x g(x) f (x) 2x1 + 2x1 result holds.
following result shows solving LIMIDs NP-hard even assume bounded
treewidth number states per variable.
129

fiMaua, de Campos, & Zaffalon

X0

D1

D2

X1

X2

Dn



Xn

R

Figure 8: LIMID used solve partition problem Proof Theorem 1.

Proof Theorem 1. Given strategy s, deciding whether Es [L] > k done polynomial time (Koller & Friedman, 2009), problem NP. Hardness shown using
reduction partition problem, NP-complete (Garey & Johnson, 1979)
stated follows. PGiven set
P n positive integers a1 , . . . , , set
= {1, . . . , n} iI ai = iA\I ai ? assume n > 3.
P
P
Let = 21 iA ai . even partition subset achieves iI ai = a.
solve partition, consider rescaled problem (dividing every element
a),
P
vP
= ai /a 2 elements look partition
iI vi = 1 (because
v
=
2).
iA
Consider following LIMID topology Figure 8. n binary decision
nodes labeled D1 , . . . , Dn . decision Di take states d1 d2 . chain
chance nodes n + 1 ternary variables X0 , X1 , . . . , Xn states x, y, z.
arc Xn single value node R. notational purposes, specify function
f domain {x, y, z} triple (f (x), f (y), f (z)). value node associated
utility function uR = (0, 0, 1). = 1, . . . , n, chance node Xi associated set
conditional probability mass functions given
d1 ,x
= (ti , 0, 1 ti ),
pX


d2 ,x
= (1, 0, 0),
pX


pdX1i,y = (0, 1, 0),

pdX2i,y = (0, ti , 1 ti ),

pdX1i,z = (0, 0, 1),

pdX2i,z = (0, 0, 1),
DX

ti [0, 1] (we specify variables later on). Note pXii i1 (w) = 0 every
w faXi wXi 6= wXi1 wXi 6= z. Finally, define pX0 = (1/3, 1/3, 1/3).
Given strategy = (D1 , . . . , Dn ), let , {i : Di = d1 } index set policies
Di () = d1 .
Es [L] =

X

pX0

CD

n


!
DX
pXii i1 pDi

i=1


=

X

X

pX0


Xn

uR

n



Xi1

pXii

i=1

CD\{Xn }

Let
ps , pX0

n


Xi1

pXii

i=1

130

pDi

pDi uR .

fiSolving LIMIDs


X

pXn ,

n


pX0

Xi1

pXii

i=1

CD\{Xn }

X

pDi =

ps .

CD\{Xn }
Xn1

w CD wXn = x (i.e., w xCD ) follows pXnn
0 wXn1 = x. wXn1

(wfaXn ) 6=


Xn2
= x pXn1
(wfaXn1 ) 6= 0
n1
DX
Also, {1, . . . , n}, pXii i1 (wfaXi )

wXn2 = x recursively.
equals ti 1 otherwise. Hence,
( Q
1
ti , wXi = x = 1, . . . , n 1
ps (w) = 3 iI
0,
otherwise,


n

1Y
ti .
ps (w) =
3
CD

X

pXn (x) =

iI

wx

Likewise, holds w CD
( Q
ps (w) =

1
3

iA\I ti ,

0,

wXi = = 1, . . . , n 1
otherwise,

therefore
pXn (x) =

n
1
ti .
3
iA\I

Since pXn probability mass function Xn , pXn (z) = 1 pXn (x) pXn (y),
X
pXn uR
Es [L] =
Xn

= 1 pXn (x) pXn (y)
1Y
1
=1
ti
ti .
3
3
iI

iA\I

Let us assume initially ti = 2vi . reduction original problem
way polynomial, use upper bound outcome
reduction obtain later. difficult
see
P
P Es [L] concave function
v1 , . . . , vn achieves maximum iI vi = iA\I vi = 1. Since strategy
defines partition vice-versa, even partition MEU[L] =
1 1/3(1/2 + 1/2) = 2/3.
show reduction encodes numbers ti time space polynomial
b, number bits used encode original problem. part close analogy
last part proof hardness MAP Bayesian networks de Campos
(2011, Theorem 10).
setting ti represent 2vi 6b + 3 bits precision (rounding necessary),
is, choosing ti 2vi ti < 2vi + , 0 < 2(6b+3) ,
131

fiMaua, de Campos, & Zaffalon

2vi ti < 2vi + 2(6b+3) , implies (by using Lemma 23 = vi 2
6b
= 6b) 2vi ti < 2vi +2 .
Assume even partition exists. Then8
P

6b
6b
5b
ti < 22 n iI vi = 21+2 n 21+2 ,
iI



6b n

< 22

P

iA\I

vi

6b n

= 21+2

5b

21+2

,

iA\I



5b


22
1 1+25b
5b
2
+ 21+2
=1
.
MEU[L] > 1
3
3

(6)

5b

Let r equal 22
encoded 5b + 3 bits precision (and rounded up), is,
5b
5b
2
2
(5b+3)
2
r<2
+2
, implies (by Lemma 24 = 25b 2 = 5b)

5b
5b
5b
15b
4b
22
r < 22 +2
= 22
< 22 .
(7)
reduction done verifying whether MEU[L] > 1 r/3. already know
even partition associated strategy obtains expected utility greater
1 r/3, Equality (6) fact r rounded up. Let us consider
case even partition exist. want show case MEU[L]
4b
1 22 /3, Inequality (7) implies MEU[L] < 1 r/3. Since even
partition, strategy induces
partition
P
P that, integer c different
zero, iI ai = ac iA\I ai = a+c, original numbers
ai positive integers add 2a. follows


ti +
ti = 2c/a1 + 2c/a1 .
iI

iA\I

right-hand side equality function c {a, . . . , a}\{0}, symmetric
respect y-axis (i.e., f (c) = f (c)) monotonically increasing c > 0.
Therefore, obtains minimum c = 1. Hence,


ti +
ti 21/a1 + 21/a1 .
iI

iA\I

Since n > 3 implies 2 (because numbers ai positive integers),
Lemma 24
4
21/a1 + 21/a1 21/a .
number ai encoded least log2 ai bits, therefore b log2 (a1 ) + +
log2 (an ) = log2 (a1 ). latter greater equal log2 (a1 + + ),
hence greater log2 a. Thus, 2b , implies a4 24b
4
4b
therefore 1/a4 24b 21/a 22 . Hence,
4b

21/a1 + 21/a1 22

.

8. Since number bits used encode partition problem must greater equal n,
n/2b n/b 1, hence 2(j+1)b n < 2jb , j > 0.

132

fiSolving LIMIDs

Thus, even partition exist


4b

22
1
ti 1
MEU[L] = 1
ti +
< 1 r/3 .
3
3
iI

iA\I

summarize, built LIMID L polynomial time since ti specified
DX
using O(b) bits n functions pXii i1 , encoding 18 numbers (which
either 1, 0 ti ), 2n + 2 variables bounded number states. shown
one-to-one correspondence partitions original problem
strategies L, given rational r = f (b) encoded O(b) bits existence
even partition equivalent MEU[L] > 1 r/3.
following lemma used proof Theorem 2. similar result shown
Park Darwiche (2004, Lemma 9).
Lemma 25. x 1 follows x + 1/2 > 1/ ln(1 + 1/x).
Proof. Let f (x) = ln(1 + 1/x) 1/(x + 1/2).
f 0 (x) =

x2

1
1
+ 2
,
+ x x + x + 1/4

strictly negative x 1 since x2 +x < x2 +x+1/4. Hence, f (x) monotonically
decreasing function x 1. limx f (x) = 0, f (x) strictly positive [1, ).
Thus, result follows ln(1 + 1/x) > 1/(x + 1/2), since x 1.
show approximately solving LIMIDs bounded treewidth given
minimum performance NP-hard.
Proof Theorem 2. show fixed 0 < < 1 existence polynomial

time 2 -approximation algorithm solving LIMID would imply existence
polynomial time algorithm CNF-SAT problem, known impossible
unless P=NP (Garey & Johnson, 1979). similar reduction used Park
Darwiche (2004, Theorem 8) show analogous inapproximability result maximum
posteriori inference Bayesian networks. Notice 1 < < 2 0 < < 1

= 2 , hence existence -approximation algorithm implies existence

2 -approximation, suffices desired result show latter cannot
true (unless P=NP).
clause disjunction literals, literal either boolean variable
negation. say clause satisfied if, given assignment truth values
variables, least one literals evaluates 1. Thus, decide truth-value
assignment satisfies clause time linear number variables. CNF-SAT
problem defined follows. Given set clauses C1 , . . . , Cm (subsets ) boolean
variables X1 , . . . , Xn , assignment truth values variables satisfies
clauses?
positive integer q specify later on, consider LIMID obtained follows
(the topology depicted Figure 9). boolean variable Xi add q binary
133

fiMaua, de Campos, & Zaffalon

B1
Dn1

Sn1

Dn2

Bq
Dnq

Sn2

.
.
.
D11



B2

.
.
.

S11

D12

Snq

.
.
.
D1q

S12

S01

U

S1q
S0q

S02

Figure 9: Graph structure LIMID used proof Theorem 2.

decision variables Di1 , . . . , Diq q chance variables Si1 , . . . , Siq domain {0, 1, . . . , m}.
Additionally, q clause selector variables S01 , . . . , S0q taking values {1, 2, . . . , m},
q binary variables B 1 , . . . , B q , value node U B q parent. illustrated
Figure 9, LIMID consists q replicas polytree-shaped diagram variables
D1j , . . . , Dnj , S0j , . . . , Snj , B j , probability mass functions variables B 1 , . . . , B q
chosen make expected utility equal product expected utilities
replica. replicas (i.e., j {1, . . . , q}), variable Dij (i = 1, . . . , n)
represents assignment truth value Xi parents. selector variables
S0j represent choice clause process, is, S0j = k denotes clause Ck
processed, summing S0j process clauses. variable Sij , =
j
1, . . . , n j = 1, . . . , q, Dij Si1
parents. variables B j Snj and,
j > 1, B j1 parents. j, assign uniform probabilities S0j , is, pS j , 1/m.
0

j = 1, . . . , q, set probabilities associated variables S1j , . . . , Snj Ck
clause selected S0j Sij set zero Ck satisfied Di
j
D1 , . . . , Di1 , Sij = Si1
otherwise. Formally, x {S j ,Dj ,S j }




1,




j j

1,
p ji i1 (x) ,
Si
1,




0,



i1

j

j

xSi = xSi1 = 0 ;
j

j

xSi = 0 xSi1 = k 1 Xi = xDi satisfies Ck ;
j

j

xSi = xSi1 = k 1 Xi = xDi satisfy Ck ;
otherwise.

Notice S1j first case never occurs since S0j takes values {1, . . . , m}.
j
joint state configuration x S0j , . . . , Snj , D1j , . . . , Dnj xS0 = k {1, . . . , m} (i.e.,
j
clause Ck processed) xSn = 0, follows
!
n
j

Dij Si1
pS j
p j
pDj (x)
0

i=1

Si



equals 1/m 0 < n clause Ck satisfied Xi = xDi
j
X1 = xD1 , . . . , Xi1 = xDi1 , variables S1j , . . . , Si1
assume value k (i.e.,
134

fiSolving LIMIDs

j

j

j

j

xS1 = = xSi1 = k), xSi = = xSn = 0. Otherwise, equals 0. Hence,
(partial) strategy sj = (Dj , . . . , Dnj ) x = 0
1




j
psS j (x)
n

X

,

j ,...,S j

pS j

0

n1

0

n

i=1

j
Dij Si1

p

Sij



SAT (sj )
pD j
(x)
=
,




j
D1j ,...,Dn

SAT (sj ) denotes number clauses satisfied truth-value assignment
j

Sn B
X1 , . . . , Xn according sj . variable B j associated function pB
j
x faBj ,

j
B j = xB j1 xSn

= 0;
1, x
j j1
j
j
pSBnj B (x) = 1, xB = 0 xSn 6= 0 ;


0, otherwise;

j1



0

B 1 assume xB = 1. Hence, joint state configuration x
B 1 , . . . , B q , Sn1 , . . . , Snq

q
1
B 1 = = xB q = 1 xSn

= = xSn = 0;
1, x
j j1
1
q
1

pSBnj B (x) = 1, xB = = xB = 0 xSn 6= 0;


j=1
0, otherwise.




q


Finally, set utility functionu associated U return 1 B q = 1 0
j j1
Q
1
q
1
otherwise. way, u qj=1 pSBnj B
(x) equals 1 xB = = xB = 1 xSn =
q

= xSn = 0 zero otherwise. Thus, strategy = (s1 , . . . , sq ), sj =
Dj , . . . , Dnj , follows
1

Es [L] =

X

u

CD

=

q


u

B 1 ,...,B q
1 ,...,S q
Sn
n

=

=

j1

pS j

0

j=1

X

X

j

pSBnj B
q


j

pSBnj B

u

B 1 ,...,B q j=1
1 ,...,S q
Sn
n
q

j
psS j (0) =
n
j=1

i=1

j1

j=1

q


n


p

j
Dij Si1

Sij

X



pS j

j
S0j ,...,Sn1
j
j
D1 ,...,Dn
j

Sn B
pB
j

j1

pD j

0

n

i=1

p

j
Dij Si1

Sij

pD j


j

psS j

n

q
1
SAT (sj ) .
mq
j=1

instance CNF-SAT problem satisfiable optimum strategy
SAT (sj ) = j, MEU[L] = 1. hand, instance
135

fiMaua, de Campos, & Zaffalon

satisfiable, j strategy SAT (sj ) 1, hence
MEU[L] (m 1)q /mq . given 0 < < 1, let q positive integer chosen

1/2 > mq /(m + 1)q . show later q obtained polynomial

input. CNF-SAT instance satisfiable, 2 -approximation algorithm
MEU[L] returns value Es [L]
q


m1 q
MEU[L]

>
,
Es [L]
>
m+1

2
rightmost strict inequality follows m/(m + 1) > (m 1)/m.
hand, CNF-SAT instance satisfiable, approximation returns


m1 q
Es [L] MEU[L]
.



Hence, use 2 -approximation algorithm solve CNF-SAT checking whether
output E[L] > (m1)q /mq . Since q positive integers, test bound (m1)q /mq
obtained polynomnial time.
remains show reduction polynomial input. LIMID contains
q(2n + 2) + 1 variables, requiring specification 2(m + 1)2 numbers
{0, 1/m, 1}. , number numerical parameters L, polynomially bounded
q(m + 1)2 (4n + 4) + 2. Therefore, suffices show q polynomial n.
definition, q obeys


1 q
2

1+
> 2[q(m+1) (4n+4)+2] ,

equivalent


1
q ln 1 +




> q [(m + 1)2 (4n + 4) + 2] ln 2

[(m + 1)2 (4n + 4) + 2]

ln 2
1
ln 1 +
! 1
1
[(m + 1)2 (4n + 4) + 2]

ln 2
1
ln 1 +

q 1 >

q>

Since (by Lemma 25) + 1/2 > 1/ ln(1 + 1/m) 2 > ln(2), suffices choose q

1
q > (2m + 1)[(m + 1)2 (4n + 4) + 2] 1 .
2+1



words, q polynomially bounded 1 4n 1 . Therefore, MEU[L]

approximated polynomial time ratio greater 2 solve
CNF-SAT polynomial time.
next result show Transformation 6 preserves expected utility strategies,
strategies easily mapped back forward original transformed
diagrams.
136

fiSolving LIMIDs

paD = j

X1

X2

T1

T2



Xj1

Xj

Xj+1

Tj1

Tj

Tj+1



Xm

chD

Tm

Figure 10: Reasoning proof Transformation 6.

,pa

X

,T ,pa

Proof Proposition 7. looking definition functions pX11 pXii1 ,
= 2, . . . , m, see paD selects j , is, conditional paD = j ,
variable Xj independent Xj1 = 1, . . . , m, 6= j, variable Xi
independent Ti . words,


Pr(Xj |Xj1 , Tj , paD = j ) = Pr(Xj |Tj , paD = j ) , pXjj .
and, 6= j,
X

Pr(Xi |Xi1 , Ti , paD = j ) = Pr(Xi |Xi1 , paD = j ) , pXii1 .
visualize situation removing arc Xj1 Xj arcs
Ti Xi 6= j diagram Figure 2(b) (the arcs leaving paD removed
conditioning value paD ), results diagram Figure 10. Note
principle case j = 1 deserves special attention, X1 depend
Xi variable, function associated X1 slightly differ others.
Nevertheless, similar reasoning applied. omit case j = 1
sake simplicity.
follows previous reasoning


pXjm , Pr(Xm |paD = j )

X
X


X
=
(pX1 pT1 )(pXjj pTj )
pXii1 pTi
T1 ,...,Tm X1 ,...,Xm1

=

X

pTj

Tj

X

i=2,i6=j


pXjj




X

i=j+1

Xj ,...,Xm1

X

pXi1


X1 ,...,Xj1

|
=

X
Tj

pTj

X
Xj ,...,Xm1



pXjj




X

pXii1 .

i=j+1

137

pX1

j1


X

pXi1


i=2

X




pTi

T1 ,...,Tm \Tj i=1,i6=j

{z

=1

}

fiMaua, de Campos, & Zaffalon

X

paD = j , function pXi1
6= j equals indicator function IXi =Xi1 ,



design, pXjj = IXj =Tj . thus

pXjm

=

X

X

pTj

Tj




IXj =Tj

IXi =Xi1 .

i=j+1

Xj ,...,Xm1

term outer sum Tj , inner sum Xj , . . . , Xm1 differs zero
Tj = Xj = Xj+1 = = Xm , case equals one. Hence,
X

pXjm =
pTj IXm =Tj
Tj

= pTj .
pa

consider strategy s0 = (T1 , . . . , Tm , . . . ) L0 , let pXmD function

equals pXjm every value j paD . Let policy original decision
variable L ( j ) = Tj j, strategy L obtained
substituting policies T1 , . . . , Tm s0 . Finally, let pT1 , . . . , pTm distributions
pa
induced policies T1 , . . . , Tm s0 , pD distribution induced .
paD
Since value j paD pXm ( j ) = pTj , since design Xm = ,
pa
pa
follows pXmD = pD . Hence, combination policies T1 , . . . , Tm L0
derive corresponding policy L. converse true: policy
pa
pa
generate T1 , . . . , Tm pXmD = pD (simply choose Ti = ( j ) i). Thus,
one-to-one correspondence policies T1 , . . . , Tm policies ,
pa
pa
one-to-one correspondence induced functions pXmD pD .
remains show combination policies T1 , . . . , Tm corresponding policy
induce expected utility. Let C 0 D0 denote, respectively, set chance
decision variables L0 , C set chance decision variables L.
Also, given strategy L, let

pa
p0s ,
pX X .
CD\{D}
pa

Note function independent choice policy , ps = p0s pD .
Given strategy s0 L0
X
X
Es0 [L0 ] =
ps0
uV
C 0 D0

=

X

V V

p0s

,pa
pX11

C 0 D0




X
,T ,pa
pXii1

i=2




!
pTi

=

p0s

X

uV

V V

CD\{D}

X X
C 0 \C D0 \D

X

X

CD\{D} Xm

pa

pXmD p0s

X




X

pXii1

i=2

{z

|
=

,paD

pX11

uV

V V

i=1

!
X

X

P
paD
= Xm pXm

uV

V V

138

,Ti ,paD




pTi

i=1

}

fiSolving LIMIDs

=

X

X

pa

pD p0s

X

ps

CD

X

uV

V V

CD\{D}

=

X

uV

V V

= Es [L] ,
strategy L obtained s0 substituting T1 , . . . , Tm corresponding policy .

References
Bodlaender, H. L. (1996). linear-time algorithm finding tree-decompositions small
treewidth. SIAM Journal Computing, 25 (6), 13051317.
Cooper, G. F. (1988). method using belief networks influence diagrams. Fourth
Workshop Uncertainty Artificial Intelligence.
de Campos, C. P. (2011). New results MAP problem Bayesian networks.
Proceedings 22nd International Joint Conference Artificial Intelligence, pp.
21002106.
de Campos, C. P., & Ji, Q. (2008). Strategy selection influence diagrams using imprecise probabilities. Proceedings 24th Conference Uncertainty Artificial
Intelligence, pp. 121128.
Dechter, R. (1999). Bucket elimination: unifying framework reasoning. Artificial
Intelligence, 113 (1-2), 4185.
Detwarasiti, A., & Shachter, R. D. (2005). Influence diagrams team decision analysis.
Decision Analysis, 2, 207228.
Dubus, J.-P., Gonzales, C., & Perny, P. (2009). Multiobjective optimization using GAI
models. Proceedings 21st International Joint Conference Artificial Intelligence, pp. 19021907.
Fargier, H., Rollon, E., & Wilson, N. (2010). Enabling local computation partially
ordered preferences. Constraints, 15, 516539.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W. H. Freeman.
Haenni, R. (2004). Ordered valuation algebras: generic framework approximating
inference. International Journal Approximate Reasoning, 37 (1), 141.
Howard, R. A., & Matheson, J. E. (1984). Influence diagrams. Readings Principles
Applications Decision Analysis, pp. 721762. Strategic Decisions Group.
Jensen, F. V., & Nielsen, T. D. (2007). Bayesian Networks Decision Graphs (2nd
edition). Information Science Statistics. Springer.
Kohlas, J. (2003). Information Algebras: Generic Structures Inference. Springer-Verlag,
New York, USA.
139

fiMaua, de Campos, & Zaffalon

Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles Techniques. MIT Press.
Lauritzen, S. L., & Nilsson, D. (2001). Representing solving decision problems
limited information. Management Science, 47, 12351251.
Maua, D. D., & de Campos, C. P. (2011). Solving decision problems limited information. Advances Neural Information Processing Systems 24, pp. 603611.
Maua, D. D., de Campos, C. P., & Zaffalon, M. (2011). Solving limited memory influence
diagrams. ArXiv:1109.1754v2 [cs.AI].
Park, J. D., & Darwiche, A. (2004). Complexity results approximation strategies
MAP explanations. Journal Artificial Intelligence Research, 21, 101133.
Poupart, P., & Boutilier, C. (2003). Bounded finite state controllers. Advances Neural
Information Processing Systems 16 (NIPS).
Pralet, C., Verfaillie, G., & Schiex, T. (2007). algebraic graphical model decision
uncertainties, feasibilities, utilities. Journal Artificial Intelligence Research, 29,
421489.
Qi, R., & Poole, D. (1995). new method influence diagram evaluation. Computational
Intelligence, 11, 498528.
Shachter, R. D., & Peot, M. A. (1992). Decision making using probabilistic inference methods. Proceedings 8th Conference Uncertainty Artificial Intelligence,
pp. 276283.
Shenoy, P., & Shafer, G. (1990). Axioms probability belief-function propagation.
Proceedings 4th Conference Uncertainty Artificial Intelligence, pp.
169198.
Zhang, N. L., Qi, R., & Poole, D. (1994). computational theory decision networks.
International Journal Approximate Reasoning, 11 (2), 83158.

140


