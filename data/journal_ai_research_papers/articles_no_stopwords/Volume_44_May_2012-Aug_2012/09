Journal Artificial Intelligence Research 44 (2012) 423-453

Submitted 10/11; published 07/12

Modelling Observation Correlations Active Exploration
Robust Object Detection
Javier Velez
Garrett Hemann
Albert S. Huang

VELEZJ MIT.EDU
GHEMANN ALUM.MIT.EDU
ASHUANG MIT.EDU

MIT Computer Science Artificial Intelligence Laboratory
Cambridge, MA, USA

Ingmar Posner

INGMAR ROBOTS.OX.AC.UK

Mobile Robotics Group
Dept. Engineering Science, Oxford University
Oxford, UK

Nicholas Roy

NICKROY CSAIL.MIT.EDU

MIT Computer Science Artificial Intelligence Laboratory
Cambridge, MA, USA

Abstract
Today, mobile robots expected carry increasingly complex tasks multifarious, realworld environments. Often, tasks require certain semantic understanding workspace.
Consider, example, spoken instructions human collaborator referring objects interest; robot must able accurately detect objects correctly understand instructions.
However, existing object detection, competent, perfect. particular, performance
detection algorithms commonly sensitive position sensor relative objects
scene.
paper presents online planning algorithm learns explicit model spatial
dependence object detection generates plans maximize expected performance
detection, extension overall plan performance. Crucially, learned sensor model
incorporates spatial correlations measurements, capturing fact successive measurements taken nearby locations independent. show sensor
model incorporated efficient forward search algorithm information space
detected objects, allowing robot generate motion plans efficiently. investigate performance approach addressing tasks door text detection indoor environments
demonstrate significant improvement detection performance task execution alternative methods simulated real robot experiments.

1. Introduction
Years steady progress mapping navigation techniques mobile robots made
possible autonomous agents construct accurate geometric topological maps relatively
complex environments robustly navigate within (e.g., Newman, Sibley, Smith, Cummins, Harrison, Mei, Posner, Shade, Schroeter, Murphy, Churchill, Cole, & Reid, 2009). Lately,
mobile robots begun perform high-level tasks following natural language
instructions interaction particular object, requiring relatively sophisticated interpretation agent workspace. recent literature therefore focuses augmenting
c
2012
AI Access Foundation. rights reserved.

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

(a)

(b)

Figure 1: traditional geometric environment map (a) represented simple two dimensional
occupancy grid regions free-space (cyan) (red) useful navigation
localization, (b) geometric map augmented semantic information
identity, structure location objects world allowing richer interactions
agent workspace.

metric maps higher-order semantic information location identity objects
workspace (see Fig. 1).
end, advances vision- laser-based object detection recognition
leveraged extract semantic information raw sensor data (e.g., Posner, Cummins, &
Newman, 2009; Douillard, Fox, & Ramos, 2008; Martinez-Mozos, Stachniss, & Burgard, 2005;
Anguelov, Koller, Parker, & Thrun, 2004). Commonly, output detection system
accepted prima facie, possibly threshold estimated sensor error. consequence
directly using results object detector quality resulting map strongly
depends shortcomings object detector. Vision-based object detection, example,
oftentimes plagued significant performance degradation caused variety factors including
change aspect compared encountered training data, changes illumination and,
course, occlusion (e.g., Coates & Ng, 2010; Mittal & Davis, 2008). aspect occlusions
addressed naturally mobile robot: robot choose location sensors carefully
acquiring data performing object detection, thereby improving robustness
detection process specifically counteracting known detector issues. Rather placing burden providing perfect detections detector itself, robot act improve perception.
Rarely, however, ability mobile robot actually exploited building semantic map.
paper, present online planning algorithm robot motion explicitly incorporates model performance object detector. primarily address problem
context robot exploring unknown environment goal building map accurately
labeled location semantic objects interest here, particular, consider doors
textual signs. However, approach applied problem robot must plan
trajectories depend location objects landmarks interest environment.
show planning approach weighs benefit increasing confidence potential
semantic entity cost taking detour succession suitable vantage point.
Fig. 2 gives cartoon illustration problem, robot encounters possible new object
424

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

(a)

(b)

(c)

Figure 2: conceptual illustration (a) robot viewpoint x following original
trajectory (bold line) towards goal (red star), (b) perception field particular
object detector centered around object hypothesis, (c) alternative path (bold
dash-dotted line) along informative route. Cell shadings indicate relative value
observations taken cell terms mutual information. Lighter values
indicate lower mutual information therefore desirable vantage points. challenge
learning mutual information varies spatially, capturing
mutual information cell changes new measurement.

executing path goal. Based expected information available possible vantage
points, robot may decide original path provided accurate model object,
may choose modify path reduce possibility errors object model.
make two primary contributions paper. Firstly, describe new sensor model
uses mixture Gaussian Processes model performance object detection system function robots relative position detected features learn
online model sensor measurements spatially correlated. Typical estimation planning algorithms assume sensor measurements conditionally independent given
knowledge robots position, assumption clearly incorrect properties environment introduce strong correlation sensor measurements. Rather estimate
possible hidden variables capture full sensor model preserve conditional independence,
explicitly model spatial correlation measurements use correlation model estimate mutual information measurements taken different locations. use
mutual information bias random sampling strategy trajectory generation
evaluate expected cost sampled trajectory. Secondly, show incorporate
learned sensor model forward search process using Posterior Belief Distribution (PBD)
algorithm (He, Brunskill, & Roy, 2010, 2011) perform computationally efficient deep trajectory
planning. PBD approximation allows us compute expected costs sensing trajectories
without explicitly integrating possible sensor measurements.
work first result actively controlling sensor improve accuracy,
previous work largely ignored motion cost typically assumed observations conditionally independent given sensor position. Inspired recent progress forward search
planning uncertainty, demonstrate system allows us efficiently find robust observation plans. paper builds previous work presented ICAPS 2011 (Velez, Hemann,
Huang, Posner, & Roy, 2011) provides several substantial extensions. Specifically, describe
significantly richer sensor model, extend approach improved planning algorithm ad425

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

dress additional object interest human-readable text. demonstrate overall approach
using real robot well simulation studies.
exposition begins problem formulation planning trajectories improve object
detection Section 2. Section 3 describe specific sensor model characterize
sensor models using mutual information. Section 4 gives two different approaches learning
sensor models vary spatially, observations correlated spatially. describe
planning algorithm sensor model incorporated system Section 5.
follow description implementation efficient planning using sensor models
Section 6. Section 7 describes object detectors used results. Section 8 shows simulation
results approach improves object detection compared approaches Section 9
shows performance system real world trials. Sections 10 11 conclude
discussion related work future directions.

2. Problem Formulation
Consider robot following particular trajectory towards goal environment objects
interest unknown locations, example, rescue robot looking people first-responder
scenario. Traditionally, object detector used waypoints along trajectory
detection either accepted map rejected based simple detector thresholds. However,
lack introspection approach regarding confidence object detector
quality data gathered lead unnecessary acceptance spurious detections.
systems simply discard lower confidence detections way improve estimate
further, targeted measurements. contrast, would robot modify motion
minimize total travel cost cost errors deciding whether add newly observed
objects map.
Let us represent robot point x R2 SO(2), SO(2) denotes special orthogonal group representing orientation R2 represents location 2D euclidean space. Without
loss generality, express robot trajectory set waypoints x0:K , associated
motion cost cmot (x0:K ) sum total travel waypoints x0 xk . robot
prior map environment planning path pre-specified goal, computing
minimum cost path x0:K well-understood motion planning problem.
robot moves, receives output object detector gives rise belief
whether detected object truly exists location indicated1 . model presence
ith object location (ui , vi ) random variable yi {object, no-object}. system
runs, object detector fire give rise objects Yi given locations system
must reason qualify either genuine objects false firings object
detector.
Let us define decision action ai {accept, reject}, detected object either accepted
map (the detection determined correspond real object) rejected (the detection
determined spurious). Let us define cost dec : {{accept, reject}{object, no-object}} 7
R correct incorrect accept reject decision. cannot know true cost decisions
{ai } ultimately know true state objects environment. therefore
1. assume robot knows location, sufficiently well-calibrated camera determine location
object map. work, uncertainty whether object specific type present
given location (u, v).

426

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

infer distribution state object p(y) generate plan minimize expected
cost E[dec ] individual decision actions given distribution objects.
formulate planning problem choosing plan , comprised sequence waypoints
decision actions, 7 {x0:K a0:Q } path length k Q hypothesized objects
minimize total travel cost along trajectory expected costs decision actions
end trajectory, optimal plan given

= arg min cmot (x0:K ) + cdet (x0:K , a) ,
(1)
x0:K ,a



cdet (x0:K , a) = Ey|x0:K[dec (a, y)],

(2)

Ey|x0:K [] denotes expectation respect robots knowledge regarding object,
y, executed path x0:K . number hypothesized objects, Q, number possible objects detector fired traversing entire trajectory known beforehand.
Note planning problem computing often formulated partially observable
Markov decision process POMDP (Sondik, 1971; Kaelbling, Littman, & Cassandra, 1998),
POMDP representation grow combinatorial complexity presence multiple
detections. Furthermore, POMDP solutions assume stationary Markov model parameters;
sensor model non-stationary explicitly non-Markov want represent
environmental features needed support non-Markov sensor model. Since approach
uses sensor model adapts successive observation, new POMDP model would
need constructed solved observation. Lastly, explicit POMDP model would
require plan take account possible observations robot might encounter carries
motion trajectory. precisely, expected cost plan must computed respect possible observations objects, rather object distributions. avoid
resulting computational complexity using forward search algorithm similar forward search
approximation techniques solving POMDPs (Ross, Pineau, Paquet, & Chaib-draa, 2008),
known scale well presence complex representations. avoid explicitly computing observation distribution planning use approximation technique
known Posterior Belief Distribution (PBD) algorithm, adapted sensor model.

3. Sensor Model Object Detection
order compute expected cost decision actions, must estimate probability objects existing world given observations might see executing motion plan.
therefore require probabilistic model object detector allows us infer distribution object given measurements, p(y|z). know sensor characteristics vary
robot moves around object interactions environment, hence make
relationship explicit writing posterior p(y|z, x) include viewpoint x.
Furthermore, measurement, z, taken particular viewpoint x consists output
object detector, assumed real number indicating confidence detector
object exists. distribution range confidence measurements dependent
particular object detector captured random variable Z defined continuous
range [zmin , zmax ]. every waypoint x posterior distribution expressed
p(y|z, x) = R

p(z|y, x)p(y)
,
yY p(z|y, x)p(y)
427

(3)

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

(a)

(b)

(c)

Figure 3: Different graphical models representing observation function. (a) naive Bayes
approximation assumes every observation z conditionally independent given
knowledge object y. (b) true model assumes observations independent given knowledge environment object y. (c) model
employed here, correlations approximated way mixture model
input space waypoints {x R2 SO(2)} (Equ. 9).

p(z|y, x) denotes likelihood, every possible state , observing particular
detector confidence x. (The expression would seem require p(y|x), independent
waypoint measurement z received.)
3.1 Observation Model
Observations z directly produced physical device, camera, often treated
conditionally independent given state robot (see Fig. 3a). However, observations
independent given knowledge current state, fact independent given
state environment shown Fig. 3(b). one (or both) variables
unknown, measurements longer first-order Markov fact correlated.
seen intuitively noting robot stationary, aimed static scene,
would expect response object detector successive images independent.
anticipate observations object detector extremely correlated, expectation
new information would gained handful images.
correct observation model maintain history observations. waypoints
visited, knowledge regarding object integrated recursively. Let K denote trajectory
K waypoint-observation pairs obtained sequence K = {(x1 , z 1 ), (x2 , z 2 ), . . . , (xK , z K )}.
Knowledge gained step along trajectory integrated posterior distribution


K

K = (xK , z K ) K1 ,

(4)

K

(5)

K

K

p(y|z , x , ) p(y|z , x ,
=

K1

),

p(z K |y, xK , K1 )p(y|T K1 )
,
p(z K |xK , K1 )

(6)

z K K th observation, depends current waypoint
history measurements waypoints K1 . denominator Equ. 6 serves moderate
428

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

influence measurement likelihood posterior based correlations existing
observations taken along trajectory.
difficulty model Equ. 6 sensor model p(z K |y, xK , K1 ) difficult
arrive at, depending history measurements. Furthermore, K arbitrarily
large, need model predicts observations given infinite history observations.
describe new sensor model Section 4.
3.2 Perception Fields
developing new sensor model, first need way examine sensor model
captures effect measurements posterior belief object y, use reduction
uncertainty relative current belief next observation. Given waypoint xK
trajectory K1 visited thus far, reduction uncertainty captured mutual information
object state observation Z K received xK
I(Y, Z K ; xK , K1 ) =
H(Y ; K1 ) H(Y |Z K ; xK , K1 ),

(7)

H(Y ; K1 ) H(Y |Z K ; xK , K1 ) denote entropy conditional entropy, respectively (we drop xK entropy since distribution independent robot
xK without corresponding observation Z K ). Thus, H(Y ; K1 ) expresses certainty current belief whether object exists given trajectory thus far, unswayed
new measurements. every time step, term constant every waypoint considered
therefore disregarded. conditional entropy Equ. 7 expanded terms posterior state hidden variable given previous trajectory K1 additional
measurement taken xK , p(y|z K , xK , K1 ) (c.f. Equs. 6 9), likelihood z K taking
particular value conditioned trajectory thus far whether object viewed xK
present not, p(z K |xK , K1 ),
H(Y |Z K ; xZK , K1 ) =



p(z|xK , K1 )H(Y |z, xK , K1 ) ,

(8)

z

|z, xK , K1 ) computed using sensor model p(y|z K , xK , K1 ) given Equ. 6,

H(Y
function belief traversing waypoint-observation trajectory K .
expected reduction uncertainty given conditional entropy values waypoints
robots workspace form perception field2 particular object hypothesis (see Fig. 2(b)).
use perception field induces sensor model two ways: firstly bias search
informative path, secondly part evaluation expected cost path.

4. Correlation Models
described previously, conventional first-order Markov sensor models correctly represent
effect successive observations implicitly correlated unmodelled environmental
2. reduction position uncertainty robot observations across environment sometimes known
sensor uncertainty field (Takeda & Latombe, 1992) active localization. Since application object detection,
use term perception field avoid confusion localization problem, concepts otherwise
identical.

429

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

variables. images used object detector conditionally independent correlated
environment . robot position scene stationary, probability
individual pixel values successive images strongly correlated shared environmental
representation robot position, varying sensor noise. Subsequently, object detector
responses strongly correlated. However, correctly representing observations way
requires environmental model sufficient capture image generation process, intractable
computational modeling burden. Image-based object detectors detectors
exhibit dependence environment. object detector utilizes properties
environment (geometric otherwise) generate detections cannot priori treated producing
conditionally independent observations given state robot. Correctly representing
full generative model object detection takes account environmental properties used
detector frequently intractable task.
overcome difficulty, approximate real process object detection simplistic
model images correlated. replace influence environment correlations observations convex combination fully independent model
depend history observations, correlated observation model depend
history observations. treat whether particular observation correlated previous
observation random variable. new posterior belief state world computed

K
p(z K |y, xK , K1 ) = p(z K K1 )p(zind
|y, xK )
K
+ (1 p(z K K1 ))p(zcorr
|y, xK , K1 ),

(9)

marginalized whether observation z K actually independent
previous observation not. use notation B represent event independent
B. Factorizing likelihood way (Equ. 9) allow us capture intuition
repeated observations similar waypoints add little robots knowledge state
world treated correlated. Observations afield, however, become
increasingly independent; less correlating effect.
order complete sensor model uses factorization Equ. 9, need construct model independent correlated likelihoods well model probability
particular detection independent previous detections. following sections describe
two different approaches modeling likelihood functions probability independent
detections.
4.1 Static Disc Model
first sensor model called static disc sensor model, coarse, assuming
measurements drawn according either learned first-order Markov model according
nearest previous observation.
K |y, xK approximated using histogramThe distribution independent detections zind
based detector performance labeled training data. is, training data collected placing
robot waypoint grid around training object facing object. robot collects
series images waypoint, generates histogram object detection confidences
waypoint collected images, histogram gives probability measurement z K specific (relative) waypoint xK . contrast, correlated detection model assumes
430

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

(a) Perception Field Observations

(b) Perception Field One Observation, Disc Model

Figure 4: Perception field possible door using static disc sensor model. unknown
object center (blue) looking towards right. Brighter regions correspond
waypoints likely result higher confidence posterior beliefs. Observations
taken robot denoted location (magenta) oriented point sensor
directly object.

measurements fully correlated always equal closest (in x) previously seen observation. described Equ. 9 treat probability observation independence mixing
parameter, disc express truncated linear function Euclidean distance, d,
two viewpoints. distribution normalized respect maximum distance dmax , beyond
observations treated fully independent. Thus,

K
K1
dmax < dmax
(10)
p(z

) = disc =
1
dmax
words, information gained taking additional measurements waypoint
information content observations increases linearly distance previous ones.
reference Equ. 6, model results belief update,


K |y, xK )
p(zind
K
p(y|T ) = disc
+ (1disc ) p(y|T K1 ).
(11)
K |xK )
p(zind
431

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Fig. 4 shows two example perception fields object detector trained doors (see Section 7
training process). Fig. 4(a), see highly informative measurements directly
front door, 8m 10m. Fig. 4(b), see change perception field
observation. mixture parameter static disc model, disc , dmax value
empirically chosen 3 meters.
4.2 Dynamic Time-Varying Correlation Model
static disc model shown previous section allow sensor model change
according data actively seen trajectory. purpose introducing correlation
model capture effect environment object detector. object detectors
response individual object appearances captured dependence (for example, door
detector may different behavior detecting highly reflective glass doors versus solid oak
doors). However, static disc model assumes fixed correlation model sensor model
objects particular class, regardless changes detectors response across individual
instances object class. previous model assumes strong (truncated)
linear relationship probability two observations correlated distance
two observations. would relax assumption order better model broad
range object detectors. second sensor model solves aforementioned issues
static disc model, allows time-varying correlations observations taken
object. sensor models make use factorization Equ. 9, differ models
K |y, xK ) p(z K |y, xK , K1 ) well structure
used detection likelihoods p(zind
corr
p(z K K1 ).
would mechanism learning correlation measurements
depend potentially infinite number previous measurements, use Gaussian
Process (GP) model independent correlated sensor models. Gaussian process
collection random variables, finite number joint Gaussian distribution,
completely specified mean function covariance function (Rasmussen & Williams, 2006).
use GP regression likelihood models always use zero mean function 0
Squared Exponential (SE) variance function following structure:
0 (scaleI)1 (xx0 )/2

SE(x, x0 ) = sigma e(xx )

.

(12)

use notation SEi (X; ) mean kernel SEi function X parameterized
.
4.2.1 NDEPENDENT C ORRELATED L IKELIHOOD ODELS
order model independent observations use Gaussian Process, GP ind , zero mean function squared-exponential covariance function described above. kernel parameters, ind ,
learned training data pairs waypoints x observations z described section 4.2.3.
GP takes input particular waypoint x predicts detector output z waypoint.
Letting train set labeled waypoint-observation pairs used GP ind , observation model
independent observation becomes
K
K
zind
|y, xK , K1 = zind
|y, xK

GP ind (0, SEind (T train , xK ; ind )).
432

(13)

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

see model depends solely training data provide prediction.
Similar independent model use Gaussian Process, GP corr , zero mean function learned SE kernel correlated observation model (Equ. 14) trained model nonindependent observations object detector. kernel parameters, corr , learned
training data described Section 4.2.3. Let corr-train set waypoint-observations pairs
used train GP corr . But, GP corr uses training data learn kernel parameters makes
predictions data acquired current trajectory K1 far, results
following correlated observation model:
K
zcorr
|y, xK , K1 GP corr (0, SEcorr (T K1 , xK ; corr )).

(14)

Unlike independent model GP predicts using training data (Equ. 13), correlated
model GPs predictions based solely data observations taken current object rather
K |y, xK , K1 using
observation histories objects. Predicting likelihood zcorr
GP regression marginalizing previous trajectory observations results
normal distribution,
K
2
zcorr
|y, xK , K1 N (corr,K , corr,K
).

(15)

choice model independent correlated observations using GPs results
overall observation model simplifying mixture two Gaussian distributions,
2
).
z K |y, xK , K1 N (obs , obs

(16)

4.2.2 IXTURE PARAMETER P ROXY NDEPENDENCE
reason factor likelihood independent model correlated model capture intuition nearby observations correlated therefore less informative,
require baseline model observations remaining robot waypoints. model
probability observation independent (p(z K K1 ) Equ. 9) treating
time-varying spatial mixture parameter . mixing parameter chosen function
variance correlation model estimate,
2

p(z K
K1 ) = p(z K
K1 |xK , K1 ) = (xK , K1 ) = 1 ecorr,K .

(17)

using SE kernel function GP corr , know variance prediction
corr,K function input space distance independent actual prediction value
(Rasmussen & Williams, 2006). Note GP corr function current trajectory
world, K1 , current waypoint xK function training data corr-train .
variance estimate GP corr function distance waypoints
observations taken far particular object, encodes intuition observations
similar waypoints correlated. fact, current waypoint approaches previous
K |y, xK , K1 approaches 0, 1, means
observation waypoints, variance zcorr
trust correlated observation model independent model. Similarly, distance
current waypoint previous observation waypoint becomes large, 0
trust independent observation model almost exclusively. words, little information
gained taking additional measurements waypoint information content
observations increases distance previous ones.
433

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

shown Fig. 3(c), remove add dependency previous waypoints
current observation z K . use pair GPs model spatial time-varying properties
correlations observation sequence object detector.

(a) Learned perception field first
observation.

(b) Learned perception field third
observation.

Figure 5: Learned perception field door detector (a) first observation (b) third observation. (b), previous observations (shown magenta) shift expect
informative vantage points be. panels, unknown object centered
origin facing right. Brighter regions correspond waypoints likely result
higher confidence posterior beliefs. Observations taken robot denoted
location (magenta) oriented point sensor directly object.

4.2.3 RAINING ENSOR ODELS
dynamic time-varying observation model consist mixture two Gaussians (see Equ. 16),
modeled using two Gaussian Processes, GP ind GP corr , every object hypothesis. Gaussian Process maps locations, x, resulting object detection score
z. Every object detector system observation model. independent observation likelihood GPs trained using available training data. labeled tuple
(z, x, = {object, no-object}) used independent sample fed independent GP corresponding labeled object state ({object, no-object}). training
samples used learn SE kernel independent GP models. way learn
model detector output likelihood cases object truly existed not, assuming independent observations. two GPs shared across objects constant
measurements.
correlated observation model GPs learned SE kernel use
different data. SE kernel trained data object since trying
learn model correlated detections. split training data set subsets cor434

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

(a) Learned perception field first
observation.

(b) Learned perception field third
observation.

Figure 6: Learned perception field text detector (a) first observation (b) third observation. (b), previous observations (shown magenta) shift expect
informative vantage points be. panels, unknown object centered
origin facing right. Brighter regions correspond waypoints likely result
higher confidence posterior beliefs. Observations taken robot denoted
location (magenta) oriented point sensor directly object.

respond objects. SE kernel parameters chosen maximal likelihood
parameters set subsets. However, kernel parameters learned, correlated model GPs initially devoid data. two correlated model GPs instantiated
per-object basis shared across objects. Samples added runtime
robot actively observes detector outputs world. such, correlated model GPs track
current set waypoints observed particular object, whereas independent model GPs
track training samples since treated independent.
Using learned dynamic time-varying sensor model derived initial perception field
door shown Fig. 5(a). Fig. 5(b) shows perception field several observations
taken around door. Notice expected amount information significantly
decreased around observed points farther waypoints may still yield useful observations.
initial perception field shows areas high expected information gain observation
according training samples particular object detector. Since previous
observations, initial perception field shows use learned independent Gaussian Process
object detector.
derived perception field text sign shown Fig. 6(a). Experimentally, truncated
text perception field waypoints aspect 45 degrees object
435

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

computational efficiency, given detector fire viewing signs obtuse
angles training data. Fig. 6(b) shows perception field several observations
taken around object. Notice text detector significantly different perception
field door detector, initial shape well response observations. see
door detector peaks within perception field, signifying regions relatively high
information gain. text detector, hand, smooth perception field
drops mainly function depth.

5. Planning Perceive
Given sensor model described previous section, describe planning algorithm
trades necessity gaining additional information object hypothesis
operational cost obtaining information. particular, object first detected, new
path original goal planned based total cost function includes motion
cost cmot along path value measurements waypoints along path expressed
reduction expected cost decision actions. Recall cost function consists two
terms: motion cost cmot (x0:K ) decision cost cdet (x0:K , a), optimal plan
given Equ. 1, reproduce here:

= arg min cmot (x0:K ) + cdet (x0:K , a) ,
x0:K ,a



cdet (x0:K , a) = Ey|x0:K[dec (a, y)],

Ey|x0:K [] denotes expectation respect robots knowledge regarding object,
executed path x0:K .
5.1 Motion cost
path cost, cmot (x0:K ), encompasses operational considerations power expended
time taken moving along particular trajectory typically proportional length
trajectory.
5.2 Decision Cost
decision cost, cdet (x0:K , a), captures expected cost accepting (or rejecting)
potential object detection, captures expected yield information observations
along path x0:K . trajectory affects cost decision actions terms changing
expectation, rather decision actions themselves, effect allowing algorithm decide
observations needed.
Note decision actions treated independently independently
robot motion, allows us compute expected decision costs efficiently.
take advantage efficiency move minimization decision actions directly inside
cost function. Abusing notation cdec ,
cdet (x0:K ) = arg min cdet (x0:K , a)

(18)



= arg min Ey|x0:K[dec (a, y)].


436

(19)

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Next, write plan terms x0:K .

= arg min cmot (x0:K ) + cdet (x0:K ) .

(20)

x0:K

dec (accept, ) dec (reject, ) costs associated declaring object exists
not, respectively, measuring z xK following traversal waypoint-observation trajectory
K1 . costs include penalties imposed accepting true positive detection
accepting false positive detection, respectively, chosen user system
reflect value/penalty decision particular domain.
expectation inside Equ. 19 relies model conditioned trajectory x0:K ;
seen Fig. 3(c), x0:K correlated z K . planning, actual z K
received cannot known ahead time, evaluate expectation exactly, must
taken respect object state received observations,
Ey|x0:K [
(a, y)] =

Z dec
K
K1
p(z|x ,
)Ey|z,x0:K1 [dec (a, y)] ,

(21)

z

p(z|xK , K1 ) denotes probability obtaining particular detector confidence value
observing object x given previous trajectory K1 , computed akin
posterior Equ. 6. Section 6.2 show efficiently approximate expectation
observation sequence treating belief normally distributed.
planning process proceeds searching sequences x0:K , evaluating paths approximating expectations respect observation sequences object state.
paths lowest decision cost tend leading lowest posterior entropy,
avoiding large penalty false positives negatives.
5.3 Multiple Objects
formally define vantage point relative object y, vy RM , vector dimensional feature space describing configuration robot relative potential object.
define mapping F : R2 SO(2) 7 RM robot waypoint x corresponding vantage point vy = F (x, y). principle, vantage point need restricted spatial
coordinates may incorporate additional information as, example, degree occlusion experienced image contrast (for appearance based detector). work, however,
range, r, aspect, , relative object robot oriented directly face object
considered vy R SO(2) (see Fig. 2a). important note system must
able accurately compute vantage point; paper stereo camera used estimate
distance orientation potential object. planning approach described far
extended planning environment Q object hypotheses considering modified cost
function simply adds cost object. augment dec (a, y) dec (a, y, i)
able provide different decision costs different object types (or even different object instances). augmentation allows us specify relative importance different objects types
algorithm. work consider objects existence independent objects
hence individual object perception fields additive particular waypoint x. restrict
waypoints correspond robot facing particular hypothesized object.
437

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Given prior information object locations, hypothesize many objects
world. initially let Q = 0 run object detector robot motion.
image processed object detector, system judges whether detection belongs object hypothesis already considered (e.g., using distance
hypothesized object detection). detector determines probability object
new location threshold belong hypothesis objects,
number object hypotheses Q increased robot replans. detection determined
correspond particular object hypothesis, system updates belief replans.
5.4 Multi-Step Planning
simple approach planning considers every possible trajectory goal weights
cost taking trajectory, choosing minimum cost trajectory plan. simple
algorithm scales approximately exponentially length planning horizon thus
rapidly becomes intractable observations considered. adopt roadmap scheme
fixed number waypoints sampled every time new waypoint added
current trajectory. graph built sampled poses, straight-line edges
samples.
sampling scheme biased towards waypoints likely lead useful observations
using perception field (see Section 3.2). Due correlations individual observations
made trajectory waypoints, perception field changes new observations added.
particular, correlation model imposed work (Equs. 17 9 dynamic time-varying
model Equ. 11 static disc model) forces
lim

# obs. xK

I(Y, Z K ; xK , K1 ) 0,

considering measurements waypoints already visited. words, robot
prefer observe putative object different waypoints taking repeated measurements
place.
Algorithm R EPLAN N N EW ETECTION (Fig. 7) summarizes planned-waypoints approach
sampling evaluating trajectories balance increased confidence motion costs.
algorithm uses Posterior Belief Distribution framework able quickly sample trajectories
many observations, selects best current plan according cost
metric.
Figure 8 details stages algorithm example run single door detected
going towards goal.

6. Efficient Perception Field Computation
planning algorithm needs calculate perception field deep planning horizons (T 1).
variant algorithm uses static disc sensor model must evaluate expected
change belief every potential future waypoint, must carry belief thought
level search tree future trajectories xK+1:K+T . However, using dynamic
time-varying sensor model treat belief normally distributed. normal
distribution approximation, limit infinite number observations, mean normal
distribution converge either 0 1 (depending whether object present not),
438

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Algorithm R EPLAN N N EW ETECTION
Input: object detection z vantage point x
// Step 1: Update Belief
2: using static disc sensor model
3:
dmin = arg min |x xi |
1:

4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:

disc =

xi K1
dmin
dM AX
K |y,T K )
disc p(z
p(z K |T K )

Equ 10

+ (1disc ) p(y|T K1 )

p(y)
else
N (corr,K , corr,K ) PREDICT(GP corr , x)
2
1 ecorr,K
n n1 + Kn (zn W (n1 ))
n (n1 + Gn bn GTn )1
// Step 2: Sample Trajectories
{}
sampling time remains
traj {}
using static disc sensor model
y0
= 1
Pi COMPUTE - PERCEPTION - FIELD(yi1 )
xi Pi // sample vantage point
p(yi ) Ez 0 [p(z 0 |xi , K1 , yi1 )p(yi1 )]
traj traj xi
else
00 n
00 n
GP 0corr GP corr
= 1
i1
Pi COMPUTE - PERCEPTION - FIELD(0i1 , 0i1 , GP corr
)
xi Pi // sample vantage point
z 0 PREDICT(GP i1
corr , GP ind , xi )
0
GP icorr UPDATE - SENSOR - MODEL(GP i1
corr , xi , z )
0i 0i1 + Kn (zn 0 W (0i1 ))
0i (0i1 + Gn bn GTn )1
traj traj xi
traj



35: EXECUTE - TRAJECTORY

Equ 11

Equ 17
Equs 25, 27 28

Equ 8

Equs 8 32
Equs 9, 13, 14 17
Equs 25, 27 28

arg min COST(t0 )
t0

Figure 7: waypoint planning algorithm samples trajectories using perception field,
chooses trajectories balance increasing robots confidence object
minimizing trajectory costs (Equ. 1).

439

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

(a) Initially, robot (blue
triangle) goal (red star)
detections fired
yet, potential objects
reasoned about.

(b) detector fires,
robot starts reasoning
potential object.
system creates initial
perception field training
data potential object
plans path take
detections.

(c) two detections (magenta) belief high
enough system confident door truly exists
world continues
towards goal. Shown
resulting perception field
two taken observations.

Figure 8: sample run system, initially empty set objects reasoned
(a), door detector firing causing new door object hypothesis perception field
created (b). system plans executes path goal allows
take advantageous observations hypothesized door. two observations,
system continues towards goal since belief whether door exists
increase expected reward improving confidence
object model justified additional cost (c). Brighter regions perception
fields correspond waypoints likely result higher confidence posterior beliefs.
Observations taken robot denoted location (magenta) oriented
point sensor directly object. belief whether door truly exists
denoted green bar.

small variance. Additionally, expected cost decision depend variance
distribution: smaller covariance normal posterior, less likely probability
decision error. Finally, posterior covariance normal depend sensor
model, observation itself. result, know sensor model information gain
measurement, predict posterior covariance, hence expected cost
decision action, without knowing exact observation sequence itself. approximation
binomial measurement function known Posterior Belief Distribution (PBD) algorithm (He
et al., 2011), used efficiently compute resulting belief time steps. sketch
general idea behind PBD below, use compute expected entropy reduction
belief future observations.
440

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

6.1 Belief
reality, object either exists exists world (denoted ). Labeled training
data output object detector form (z, x, = {object, no-object}), pair
detector output particular waypoint knowledge whether object exists not.
order use labeled samples train sensor model (a model object detector),
keep track belief whether object exists not. Equs. 22 23 show independent
correlated observation model likelihood given using likelihood given . marginalize
belief independent correlated observations models (Equs. 13 14)
get
K
K
p(zind
|, xK , K1 ) = p(zind
|object, xK , K1 )
K
+ (1 ) p(zind
|no-object, xK , K1 )

(22)

K
K
p(zcorr
|, xK , K1 ) = p(zcorr
|object, xK , K1 )
K
+ (1 ) p(zcorr
|no-object, xK , K1 ),

(23)

likelihood modeled GP similar Equ. 13 14 independent
correlated models respectively.
Noting write likelihood z terms using (Equs. 22 23),
similarly rewrite Equ. 9 terms likelihoods based
K
p(z K |, xK , K1 ) = p(z K K1 )p(zind
|, xK , K1 )
K
+ (1 p(z K K1 ))p(zcorr
|, xK , K1 ).

(24)

6.2 Posterior Belief Distribution
PBD algorithm allows us estimate expected information gain particular waypoint
without integrating potential observations z. begin framing problem Exponential Family Kalman Filter (efKF) formulation (He et al., 2011) treat state
trying estimate, exponential family observation model,
n = n1 N (n , n )

(25)

zn = exp(zn n bn (n ) + n (zn )).

(26)

Given single observation canonical link function W mapping state observation
parameter , posterior mean variance belief computed as,
n = n1 + Kn (zn W (n1 ))
n = (n1 + Gn bn GT )1

(27)
(28)

n

Kn = n1 Gn (Gn n1 GTn + bn
zn = n bn

n fifi
Gn =
n

1

(bn zn )
.

n =n1

441

1 1

)

(29)
(30)
(31)

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

GP
object
Text GP ind
no-object
Text GP ind
object
Text GP corr
no-object
Text GP corr
object
Door GP ind
no-object
Door GP ind
object
Door GP corr
no-object
Door GP corr

SE kernel
5.5
16.2
4.2
4.6
0.52
54.3
0.002
9303

SE kernel l
0.15
0.23
0.14
0.09
0.58
0.49
0.17
0.31

Table 1: learned GP parameters. Note kernel scale door text differ
correlated observation GPs.

particular importance us fact posterior covariance closed form solution,
independent posterior mean (He et al., 2011), require integrating
possible observations Z. compute posterior covariance observations
future

X
n+T = (n1 +
Gi bi GTi )1 .
(32)
i=1

Rather marginalize potential future observations every future waypoint,
compute variance belief observations simply multiplying
variance observations future waypoints. Given perception field
function variance belief (since entropy normal distribution function
variance), quickly compute field deep observation trajectories. efficient
computation allows planning algorithm sample potential observation trajectories many
observations (T 1), thereby increasing effective search depth algorithm improving
plans.

7. Objects: Doors Signs
system general agnostic type detector employed even sensing modality
used. constraint formed need able define vantage points (see Section
5.3) compute perception field (see Section 3.2). work, chose test approach
two different vision-based object detectors: first leverages parts-based object detector
Felzenszwalb, Mcallester, Ramanan (2008) trained find doors; second detector aims
spot human-readable text world commonly found signs. use text-spotting
inspired work Posner, Corke, Newman (2010) authors kindly provided us
C++ software library latest incarnation text-spotting engine, provides
detection parsing facilities individual words natural scene images.
door detector trained approximately 1400 positive 2000 negative examples
manually labeled images collected large range indoor areas excluding testing
environment. Performance images testing environment low due false positives
triggered visual structures present training images. detector could re-trained
442

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.8
0.31 0.06
0.44 0.07
67.08 2.23
50

G REEDY=0.6
0.60 0.07
0.62 0.07
41.95 0.88
50

P LANNEDdisc
0.75 0.06
0.80 0.06
54.98 3.04
50

RTBSS
0.45 0.06
0.58 0.07
47.57 0.19
50

Table 2: Simulation performance single door scenario, standard error values.

improve performance, problem recurs new environments encountered.
examples used train sensor models door detector.
text detector trained exactly described Posner et al. (2010). dynamic timevarying sensor model determined using approximately 1800 positive 2000 negative examples manually labeled images collected indoor office environment excluding
testing environment. used text detector localize text environment,
actually use contents text itself.
mixture parameter dynamic time-varying sensor model, scale factor
chosen maximum likelihood estimator using training data detector system.
learned scaling values door = 6.5 text = 5.4. Table 1 shows learned GP parameters
door text detectors.

8. Simulation Results
first assessed planning approach using learned models simulated environment.
simulation environment consisted robot navigating occupancy map, object
detections triggered according learned observation model. simulated false positives
placing non-object perceptual features probabilistically triggered object detections using
learned model false-alarms. processing delay incurred actual object detector
simulated (the door detector requires approximately 4.5 seconds process spatially decimated
512x384 pixel image text detector requires 8 seconds process full 1024x768 pixel
image).
8.1 Comparison Algorithms
simulation trials compared algorithm two algorithms. G REEDY
algorithm selected best waypoint according perception field potential object belief object exceeded threshold . Second, compared algorithm
RTBSS online POMDP algorithm (Paquet, Tobin, & Chaib-draa, 2005). RTBSS algorithm
could use full sensor model Markov assumption utilized independent part model. One could augment state space include entire history
detections therefore use full sensor model, however large state space would render
POMDP intractable practice. chose maximum depth equal algorithm
modeled world using resolution 2.5 meters RTBSS algorithm. denote
algorithm using static disc sensor model P LANNEDdisc , dynamic time-varying sensor
model P LANNED.
443

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.8
0.64 0.03
0.63 0.02
153.32 4.37
50

G REEDY=0.6
0.54 0.03
0.57 0.03
121.35 1.32
50

P LANNEDdisc
0.53 0.05
0.76 0.03
138.21 7.12
50

RTBSS
0.70 0.03
0.66 0.03
160.74 6.08
50

Table 3: Simulation performance multiple door scenario, standard error values.

(a) small simulation environment used doors
containing single object (blue) two non-object
(black).

(b) multiple object simulation environment used
doors containing 4 objects (blue) 6 nonobjects (black).

Figure 9: simulation environments static disc sensor model door detector.
8.2 Static Disc Sensor Model Simulations
First, tested P LANNEDdisc algorithm small simulation environment one door
object shown Fig. 9(a). Table 2 shows simulation results static disc model door
detector. Overall, explicitly planning waypoints resulted significantly higher performance.
P LANNEDdisc algorithm performed better RTBSS terms precision recall, likely
algorithm sampled continuous-space waypoints RTBSS algorithm fixed
discrete representation, RTBSS paths shorter.
evaluated P LANNEDdisc algorithm larger, complex scenario containing four
doors six non-door objects. Fig. 9(b) shows multiple door simulation environment. Table 3
shows simulation results multi-door scenario. P LANNEDdisc algorithm resulted
second shortest paths G REEDY=0.6 superior detection performance. P LANNEDdisc
resulted significantly shorter paths RTBSS given operating point ROC
curve.
8.3 Dynamic Time-Varying Sensor Model Simulations
tested P LANNED algorithm small simulation single text sign
complex simulation environment two signs shown Figs. 10 11. Table 4 shows results
20 trials using text detector sensor model single object simulation. text signs,
444

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
0.37 0.10
0.47 0.12
35.32 1.08
20

P LANNED
0.24 0.06
0.47 0.12
20.40 0.74
20

RTBSS
0.20 0.06
0.40 0.11
18.43 0.43
20

Table 4: Simulation performance single sign scenario, standard error values.

see deep trajectory planning help much (compare G REEDY strategy
Planned strategy planning horizon 5). information text detector
spread smoothly (see perception field Fig. 6(a)) hence greedy strategy best
thing do. However, planner took account cost resulted lower precision-recall
performance much shorter path length. saw correlation sensor model allowed
planned algorithm perform better RTBSS. belief updates predicted RTBSS
overconfident hence RTBSS algorithm resulted shorter path lengths worse precision-recall
performance planned-waypoints algorithm.

Figure 10: small simulation environment used text signs containing single object (blue)
single non-object (black).

Next, evaluated P LANNED algorithm complex scenario containing two objects
two non-objects shown Fig. 11. Table 5 shows simulation results multiple-object
scenario. P LANNED algorithm resulted best precision-recall performance short path
length. RTBSS resulted short path length, lack correlation model
became overconfident belief, performing significantly worse planned-waypoints algorithm terms precision-recall.
Fig. 11 shows density trajectories traversed algorithm simulations
run. Brighter spots denote places simulated robot frequented simulation runs.
see P LANNED algorithm kept robot close shortest path cost
function, RTBSS. However, P LANNED algorithm decided spread detections apart
correlation model employed whereas RTBSS over-valued information gained
nearby observations. G REEDY algorithm take account motion cost
taking observation saw widespread set trajectories waypoints visited
simulations.
445

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
0.23 0.06
0.28 0.08
66.72 1.39
20

P LANNED
0.93 0.05
0.72 0.07
33.80 1.00
20

RTBSS
0.54 0.11
0.43 0.09
23.32 0.63
20

Table 5: Simulation performance multiple signs scenario, standard error values.

(a) G REEDY Trajectories

(b) P LANNED Trajectories

(c) RTBSS Trajectories

Figure 11: multiple object simulation environment used text containing 2 objects (blue)
2 non-objects (red). Shown density paths taken different algorithms
simulation trials. planned approach results narrower space paths
G REEDY avoiding nearby (correlated) observations.

8.4 Time Improvements PBD
ran comparison updating perception field using PBD algorithm (see Section
6.2) update requires computing expectation possible detector outputs.
created histogram potential detector values either 100 10 bins used sampled
compute expected mutual information gain (the perception field) detector
output bins. Table 6 shows results computing perception field 100 times. PBD algorithm
allowed us efficiently calculate perception field since explicitly iterate
possible detector values could use Equ. 32.
Updating perception field time-consuming part algorithm since must
updated reasoning future observations planning. total run-time
determined many trajectories sampled using perception field depth
future trajectories, could tuned particular scenario application.
paper let planning algorithm sample evaluate trajectories amount time
running object detector single image passed.
446

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

min
avg
max

100 bins z
4.17s
4.58s
4.97s

10 bins z
1.17s
1.20s
1.22s

PBD
0.85s
0.85s
0.87s

Table 6: Timing results computing perception field using either PBD algorithm, explicitly enumerating potential detector values z computing expectation
values.

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.8
0.53 0.14
0.60 0.14
153.86 33.34
10

P LANNEDdisc
0.7 0.15
0.7 0.15
91.68 15.56
10

Table 7: Results door real-world trials using robot wheelchair, standard error values.

(a) Trajectory executed actual robot wheelchair using planned-waypoints
G robot discovers one true door (cyan). Near goal,
detects two possible doors (red dots), detours inspect them, (correctly) decides doors.

(b) Robotic wheelchair
platform

Figure 12: Real world trial door detector using robotic wheelchair platform

9. Results Real World Trials
Finally, validated results P LANNEDdisc P LANNED algorithms robot wheelchair
platform (Fig. 12(b)). autonomous wheelchair equipped onboard laser range scanners,
primarily used obstacle sensing navigation, Point Grey Bumblebee2 color stereo camera,
quad-core laptop main processing unit. stereo camera used accurately
determine vantage point particular detection. door textual signs planar,
447

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

fit plane detection bounding box 3D points stereo camera determine
orientation possible object given detection.
door text real world trials, robot started particular location orientation.
robot given goal position nominal trajectory would bring past
one true object (a door text sign), near several fixtures trigger object detections.
Initially, system object hypothesis detector run continuously moved
towards goal shortest path. object detector fired, system started reasoning
object hypothesis corresponding detections. robot deviated shortest
path take observations certain object hypothesis determined cost function. Finally,
robot reached goal trial ended. object hypothesis accepted belief
greater 0.5. cost incorrect decision set 16 times cost meter
path length, cost correct decision set negative incorrect decision.
trials capped 20 minutes done real office environment without special
accommodations realistic possible.
Fig. 12(a) shows location door trials. robot always started start location
(marked S) given goal location (G). single door could
seen path start goal. Near goal set windows light
fixtures often caused door detector fire. Fig. 12(a) illustrates trajectory executed
single trial P LANNEDdisc algorithm, Table 7 summarizes results trials
doors. G REEDY=0.8 chosen baseline comparison since best performing
existing algorithms according Table 3. P LANNEDdisc algorithm resulted significantly
shorter trajectories maintaining comparable precision recall. doors detected substantial uncertainty, algorithm planned advantageous waypoints increase confidence
ignored far away detections high motion cost. interesting see Fig. 12(a)
algorithm deviated take observations false detections near goal location, ultimately
correctly deciding object hypothesis fact doors.
similarly conducted experiment using P LANNED algorithm G REEDY=0.7
robotic wheelchair platform text detection algorithm. robot given nominal
trajectory brought past single textual sign (a poster office number placed
common location poster notifications). trials run daytime hours allow
artificial well natural lighting common environmental changes people
walking robot. Table 8 summarizes results 5 real-world trials algorithms.
see G REEDY algorithm outperformed P LANNED terms precision (consistent
simulation results) much longer path lengths. P LANNED algorithm balanced
cost gaining new observations travel time resulted much shorter trajectories.
large path-length associated greedy algorithm came two sources: first, greedy
algorithm take path cost account deciding next observation take, second
greedy algorithm kept taking pictures object hypothesis belief certain
threshold included sporadic object detections caused lights temporary environment
noise.
Lastly, ran small set 3 trials using P LANNED algorithm looking text signs
completely different environment previous trial. ran trials night
people walking by. Table 9 shows results. Even different environment, algorithms
behaved similarly, G REEDY algorithm outperforming P LANNED algorithm cost
much longer paths.
448

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
1 0
1 0
102.77 7.21
5

P LANNED
0.70 0.09
0.80 0.09
34.86 5.29
5

Table 8: Results text real-world trials using robot wheelchair.
Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
1 0
1 0
39.2047 2.76
3

P LANNED
0.33 0.33
1 0
17.5351 4.35
3

Table 9: Results small text real-world trials different location using robot wheelchair.

10. Related Work
problem planning motion trajectories mobile sensor explored number
domains including planning, sensor placement, active vision robot exploration.
general formulation partially observable Markov decision process (Sondik, 1971). Exact
solutions POMDPs computationally intractable, recent progress led approximate
solvers find good policies many large, real-world problems (Pineau, Gordon, & Thrun,
2006; Smith & Simmons, 2005; Kurniawati, Hsu, & Lee, 2008; Kurniawati, Du, Hsu, & Lee, 2010).
However, complexity representing even approximate POMDP solution led forward
search strategies solving POMDPs (Ross et al., 2008; Prentice & Roy, 2009; et al., 2010).
Eidenberger Scharinger (2010) formulate problem choosing sensor locations active
perception POMDP similar spirit formulation. However, explicitly model
underlying physics object generation, model uncertainty object location rather
object type, unable plan one step future, therefore work
similar G REEDY strategies described previous sections. approach inspired
forward search POMDP algorithms, incorporates complex model approximates
correlations observations.
contrast POMDP models active sensing, controls community sensor placement community developed information-theoretic models, goal minimize
norm posterior belief, entropy. objective function depend motion costs vehicle, sub-modular (Krause & Guestrin, 2007). consequence, greedy
strategies choose next-most valuable measurement shown boundedly close
optimal, challenge generate model predicts next-best measurement
(Guestrin, Krause, & Singh, 2005; Krause, Leskovec, Guestrin, VanBriesen, & Faloutsos, 2008).
terms image processing object recognition, Denzler Brown (2002) Sommerlade
Reid (2010) showed information-theoretic planning could used tune camera parameters improve object recognition performance applied multi-camera systems, although
use exhaustive search camera parameters rapidly becomes unwieldy. Lastly, Sridharan, Wyatt, Dearden (2008) showed formulating information-theoretic problem
decision-theoretic POMDP, true multi-step policies improve performance computer
449

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

vision system terms processing time. However, previous algorithms use models
sequential decision making costs actions independent (or negligible), leading
submodular objective function limited improvement greedy strategies.
considerable work view point selection active vision briefly
review here. relevant pieces work include Arbel Ferrie (1999)
recently Laporte Arbel (2006) use Bayesian approach model detections related
ours, searches next-best viewpoint, rather computing full plan. work
Deinzer, Denzler, Niemann (2003) perhaps similar viewpoint
selection problem framed using reinforcement learning, authors neglect costs
camera movement identify absence costs limitation work. Similarly,
system Mittal Davis (2008) learns model object occlusion uses simulated annealing
solve optimal plan; contribution learn predictive model good viewpoints.
work Borotschnig, Paletta, Prantl, Pinz (2000) uses appearance-based object detection
system plan viewpoints minimize number observations required achieve certain
recognition rate, account correlations different observations.
field object localization search seen recent advancements. use
object object relations seems promising direction shown works Aydemir, Sjoo,
Folkesson, Pronobis, Jensfelt (2011) Joho, Senk, Burgard (2011). approach differs
system uses spatial relations single object multiple observations rather
different objects. works Joho et al. (2011) Aydemir, Gobelbecker, Pronobis,
Sjoo, Jensfelt (2011) model environment achieve good results, whereas system
models correlation observations lieu modeling full environment. idea
attention seems powerful tool visual search (Tsotsos, 1992) systems
due Meger, Forssen, Lai, Helmer, McCann, Southey, Baumann, Little, Lowe (2008)
Andreopoulos, H., Janssen, Hasler, Tsotsos, Korner (2011) exhibiting excellent results. Rather
using attention, system utilizes mutual information minimizes cost taking
observations. useful note system minimizes single cost function
encodes information path costs, Ye Tsotsos (1999) formalized approach
maximizes probability localizing object minimizes cost.
robot exploration, goal generate robot trajectories learn accurate
complete map minimum travel cost, costs motion must incorporated. Bourgault,
Makarenko, Williams, Grocholsky, Whyte (2002) developed full exploration planner
incorporated explicit trade-off motion plans map entropy. Stachniss, Grisetti,
Burgard (2005) described planner minimized total expected cost, performed search
next-best action. address computational challenge, Kollar Roy (2008) used
reinforcement learning learn model expected cost next viewpoint
exploration, minimize total expected cost complete trajectory.
contribution work existing work primarily describe planning model
incorporates action costs detection errors, specifically give approximate
observation model captures dynamic correlations successive measurements
still allows forward-search planning operate, leading efficient multi-step search improve
object detection.
450

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

11. Conclusion Future Work
Previous work planned sensing largely ignored motion costs planned trajectories used
simplified sensor models strong independence assumptions. paper, presented sensor model approximates correlation observations made similar vantage points,
efficient planning algorithm balances moving highly informative vantage points
motion cost taking detours. fully model effects entire environment
sensor intractable endeavor. sensor model simplifies environment interactions treating
correlations entire history sensor readings. placed emphasis spatial
relations model correlations new sensor readings history previous sensor
readings. properties Gaussian Processes, sensor model allows efficient
deep trajectory sampling utilizing Posterior Belief Distribution framework. tested algorithm two different object detectors (doors signs) found better detector dependent
observation trajectories comparable strategies.
system presented planned deviations particular shortest-path trajectory
goal order detect localize objects spotted once. future aim
incorporate large scale spatial model object likely encountered
them. Next generation systems deal novel objects exists
prior object detector detector must created fly. goal create
end-to-end online adaptive semantic mapping solution works arbitrary objects
environments.

References
Andreopoulos, A., H., W., Janssen, H., Hasler, S., Tsotsos, J., & Korner, E. (2011). Active 3d object
localization using asimo. IEEE Transactions Robotics, 27(1), 4764.
Anguelov, D., Koller, D., Parker, E., & Thrun, S. (2004). Detecting modeling doors mobile
robots. Proc. ICRA.
Arbel, T., & Ferrie, F. P. (1999). Viewpoint selection navigation entropy maps. Proc.
ICCV, Kerkyra, Greece.
Aydemir, A., Sjoo, K., Folkesson, J., Pronobis, A., & Jensfelt, P. (2011). Search real world:
Active visual object search based spatial relations. Proc. ICRA.
Aydemir, A., Gobelbecker, M., Pronobis, A., Sjoo, K., & Jensfelt, P. (2011). Plan-based object
search exploration using semantic spatial knowledge real world. Proc. ECMR,
Orebro, Sweden.
Borotschnig, H., Paletta, L., Prantl, M., & Pinz, A. (2000). Appearance-based active object recognition. Image Vision Computing, 18(9), 715727.
Bourgault, F., Makarenko, A. A., Williams, S. B., Grocholsky, B., & Whyte, D. H. F. (2002). Information based adaptive robotic exploration. Proc. IROS, EPFL, Lausanne.
Coates, A., & Ng, A. Y. (2010). Multi-camera object detection robotics. Proc. ICRA.
Deinzer, F., Denzler, J., & Niemann, H. (2003). Viewpoint selection - planning optimal sequences
views object recognition. Proc. ICCV. Springer.
451

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Denzler, J., & Brown, C. M. (2002). Information theoretic sensor data selection active object
recognition state estimation. IEEE Trans. Pattern Analysis Machine Intelligence,
24(2), 145157.
Douillard, B., Fox, D., & Ramos, F. (2008). Laser vision based outdoor object mapping.
Proc. RSS.
Eidenberger, R., & Scharinger, J. (2010). Active perception scene modeling planning
probabilistic 6d object poses. Proc. IROS.
Felzenszwalb, P., Mcallester, D., & Ramanan, D. (2008). discriminatively trained, multiscale,
deformable part model. Proc. CVPR.
Guestrin, C., Krause, A., & Singh, A. (2005). Near-optimal sensor placements Gaussian Processes. Proc. ICML.
He, R., Brunskill, E., & Roy, N. (2010). PUMA: Planning uncertainty macro-actions.
Proc. AAAI, Atlanta, GA.
He, R., Brunskill, E., & Roy, N. (2011). Efficient planning uncertainty macro-actions.
Journal Artificial Intelligence Research, 40, 523570.
Joho, D., Senk, M., & Burgard, W. (2011). Learning search heuristics finding objects structured environments. Robotics Autonomous Systems, 59(5), 319328.
Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning acting partially observable
stochastic domains. Artificial Intelligence, 101, 99134.
Kollar, T., & Roy, N. (2008). Trajectory optimization using reinforcement learning map exploration. International Journal Robotics Research, 27(2), 175197.
Krause, A., & Guestrin, C. (2007). Near-optimal observation selection using submodular functions.
Proc. AAAI.
Krause, A., Leskovec, J., Guestrin, C., VanBriesen, J., & Faloutsos, C. (2008). Efficient sensor
placement optimization securing large water distribution networks. Journal Water Resources Planning Management, 134, 516.
Kurniawati, H., Du, Y., Hsu, D., & Lee, W. (2010). Motion planning uncertainty robotic
tasks long time horizons. International Journal Robotics Research, 30(3).
Kurniawati, H., Hsu, D., & Lee, W. (2008). SARSOP: Efficient point-based POMDP planning
approximating optimally reachable belief spaces. Proc. RSS.
Laporte, C., & Arbel, T. (2006). Efficient discriminant viewpoint selection active bayesian
recognition. International Journal Computer Vision, 68(3), 267287.
Martinez-Mozos, O., Stachniss, C., & Burgard, W. (2005). Supervised Learning Places
Range Data using Adaboost. Proc. ICRA.
Meger, D., Forssen, P., Lai, K., Helmer, S., McCann, S., Southey, T., Baumann, M., Little, J., &
Lowe, D. (2008). Curious george: attentive semantic robot. Robotics Autonomous
Systems, 56(6), 503511.
Mittal, A., & Davis, L. (2008). general method sensor planning multi-sensor systems:
Extens ion random occlusion. International Journal Computer Vision, 76, 3152.
452

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Newman, P., Sibley, G., Smith, M., Cummins, M., Harrison, A., Mei, C., Posner, I., Shade, R.,
Schroeter, D., Murphy, L., Churchill, W., Cole, D., & Reid, I. (2009). Navigating, recognising describing urban spaces vision laser. International Journal Robotics
Research, 28(11-12).
Paquet, S., Tobin, L., & Chaib-draa, B. (2005). Real-time decision making large POMDPs.
18th Canadian Conference Artificial Intelligence.
Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based approximations large
POMDPs. Journal Artificial Intelligence Research, 27, 335380.
Posner, I., Corke, P., & Newman, P. (2010). Using text-spotting query world. Proc. IROS.
Posner, I., Cummins, M., & Newman, P. (2009). generative framework fast urban labeling
using spatial temporal context. Autonomous Robots, 26(2), 153170.
Prentice, S., & Roy, N. (2009). belief roadmap: Efficient planning belief space factoring
covariance. International Journal Robotics Research, 8(11-12), 14481465.
Rasmussen, C. E., & Williams, C. K. I. (2006). Gaussian Processes Machine Learning. MIT
Press.
Ross, S., Pineau, J., Paquet, S., & Chaib-draa, B. (2008). Online planning algorithms POMDPs.
Journal Artificial Intelligence Research, 32(1), 663704.
Smith, T., & Simmons, R. (2005). Point-based POMDP algorithms: Improved analysis implementation. Proc. UAI.
Sommerlade, E., & Reid, I. (2010). Probabilistic surveillance multiple active cameras. Proc.
ICRA.
Sondik, E. J. (1971). Optimal Control Partially Observable Markov Processes. Ph.D. thesis,
Stanford University.
Sridharan, M., Wyatt, J., & Dearden, R. (2008). HiPPo: Hierarchical POMDPs planning information processing sensing actions robot. Proc. ICAPS.
Stachniss, C., Grisetti, G., & Burgard, W. (2005). Information gain-based exploration using RaoBlackwellized particle filters. Proc. RSS, Cambridge, MA, USA.
Takeda, H., & Latombe, J. (1992). Sensory uncertainty field mobile robot navigation. Proc.
ICRA.
Tsotsos, J. K. (1992). relative complexity active vs. passive visual search. International
Journal Computer Vision, 7(2), 127141.
Velez, J., Hemann, G., Huang, A., Posner, I., & Roy, N. (2011). Planning perceive: Exploiting
mobility robust object detection. Proc. ICAPS, Freiburg, Germany.
Ye, Y., & Tsotsos, J. (1999). Sensor planning 3d object search. Computer Vision Image
Understanding, 73(2), 145168.

453


