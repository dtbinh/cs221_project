Journal Artificial Intelligence Research 44 (2012) 397-421

Submitted 01/12; published 06/12

Semantic Similarity Measures Applied Ontology
Human-Like Interaction
Esperanza Albacete
Javier Calle
Elena Castro
Dolores Cuadra

EALBACET@INF.UC3M.ES
FCALLE@INF.UC3M.ES
ECASTRO@INF.UC3M.ES
DCUADRA@INF.UC3M.ES

Computer Science Department, Carlos III University,
Madrid 28911, Spain

Abstract
focus paper calculation similarity two concepts ontology
Human-Like Interaction system. order facilitate calculation, similarity function
proposed based five dimensions (sort, compositional, essential, restrictive descriptive)
constituting structure ontological knowledge. paper includes proposal computing
similarity function dimension knowledge. Later on, similarity values obtained
weighted aggregated obtain global similarity measure. order calculate weights
associated dimension, four training methods proposed. training methods
differ element fit: user, concepts pairs concepts, hybrid approach.
evaluating proposal, knowledge base fed WordNet extended using
knowledge editing toolkit (Cognos). evaluation proposal carried
comparison system responses given human test subjects, providing
measure soundness procedure revealing ways proposal may
improved.

1. Introduction
main purpose ontology human-like interaction system unify representation
concept, relating appropriate terms, well concepts
shares semantic relation. Furthermore, ontological component able
perform certain inferential processes, calculation semantic similarity
concepts. subject similarity continues widely studied fields
literature computer science, artificial intelligence, psychology linguistics. Good similarity
measures necessary several techniques fields including information retrieval,
clustering, data-mining, sense disambiguation, ontology translation automatic schema
matching. present paper focuses study semantic similarity concepts
ontology framework natural interaction.
principal benefit gained procedure ability substitute one concept
another based calculation similarity two, given specific circumstances.
users perspective, procedure allows use synonyms (terms related single
concept) concept case user familiar original concept itself.
Moreover, semantic similarity offers possibility build explanations clarifying concept
user based similar concepts, thereby enhancing communicative effectiveness.
2012 AI Access Foundation. rights reserved.

fiALBACETE, CALLE, CASTRO & CUADRA

hand, system may able understand previously-unknown concept,
long user able relate similar concepts previously known system.
way, system learn new concepts automatically enrich ontology improve
future interactions.
first task study develop semantic similarity measure takes account
particular ontological dimensions described earlier study (Calle, Castro & Cuadra, 2008).
approach, conceptualization comprises seven ontological dimensions: semiotic, sort,
compositional, essential, restrictive, descriptive, comparative. first three dimensions
previously applied related works, stated Section 2. Essential, restrictive
descriptive dimensions part nature concept, influence human judgment
similarity detailed Section 3. seventh one, comparative dimension, derived
previous dimensions charge calculating degree similarity
ontological concepts.
second goal present article evaluate quality mechanism developed
calculation similarities two concepts ontology specially
designed human-like interaction system (Calle F., 2004). achieve this, several
experiments designed performed here. experiments
consequent evaluation semantic similarity measure carried out, however,
necessary implement similarity dimensions defined conceptual model feed
database large number concepts.
briefly outline content follows paper, Section 2 reviews literature
similarity measures ontologies methods available evaluation. Section 3,
approach similarity measures applied ontological model based several dimensions
proposed. Section 4, detailed explanation provided experiments designed test
proposal, well results obtained execution. Section 5 discusses limitations
encountered study. Finally, Section 6 presents conclusions future research.

2. Related Work
present section paper two main objectives. First, aims provide overview
different types approaches available comparison concepts ontologies and,
doing, identify foundations desired similarity measure may modeled,
taking account seven dimensions described previous study (Calle et al., 2008).
Secondly, aims select best way evaluate results yielded desired similarity
measure according studies regarding similarity metrics assessment.
Basically two types methods exist comparison terms graph-based ontology:
edge-based methods using graph edges types data source node-based methods
using graph nodes properties main data source. simplest intuitive
similarity measure, former method based mainly counting number edges
path two terms graph (Rada, Mili, Bicknell & Blettner, 1989). Within edgebased method, two general approaches exist: firstly, distance approach selects either
shortest path average paths (when one path exists) secondly common
398

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

path approach calculates similarity directly length path lowest common
ancestor two terms root node (Wu & Palmer, 1994). past years,
variety edge-based methods defined (Resnik, 1995; Leacock & Chodorow, 1998).
edge-based methods grounded two basic assumptions: firstly, nodes links
uniformly distributed ontology, is, terms depth
specificity (Budanitsky, 1999) and, secondly, edges level ontology indicate
semantic distance terms. However, suppositions rarely true
majority ontologies. reason, several strategies proposed response
fact. One example strategy weighting edges according hierarchical
depth use node density link type (Richardson, Smeaton & Murphy, 1994).
Nevertheless, strategies solve aforementioned problems due fact terms
depth necessarily specificity edges level
necessarily represent semantic distance.
second, node-based, method relies comparison properties terms
involved related terms themselves, ancestors descendants.
commonly used concept methods information content (IC), providing measure
specific informative term is. IC term c quantified negative
log-likelihood, IC = -log p(c), p(c) probability occurrence c specific
corpus, generally estimated annotation frequency. Another approach employed
obtain IC based number children term ontological structure (Seco,
Veale & Hayes, 2004). concept IC applied common ancestors two terms
order quantify information share and, thereby, measure semantic similarity.
way, two main approaches exist. first informative common ancestor (MICA)
technique common ancestor highest IC considered (Resnik, 1995).
second disjoint common ancestor (DCA) technique disjoint common
ancestors considered (the common ancestors subsume common
ancestor). one definition (Lin, 1998), similarity two concepts using node-based
method expressed ratio amount information needed state
commonality two concepts information needed fully describe them.
Moreover, similarity measure hierarchical ontologies called ontology structure-based
similarity (OSS) defined (Schickel-Zuber, 2007) whose major ingredient
computation a-priori score concept c, (APS(c)), shares similarities IC
(i.e., calculated topology structure ontology reflecting
information contained within concepts).
Additionally, several hybrid methods defined attempt improve
results techniques defined above. work Jiang Conrath, (1997), example,
combined model defined derived edge-based notion adding information
content decision factor. link strength two concepts defined difference
information content them.
aim collecting different methods approaches, SimPack, generic Java
library similarity measures use ontologies, created (Bernstein, Kaufmann,
399

fiALBACETE, CALLE, CASTRO & CUADRA

Kiefer & Brki, 2005) includes implementation ontology-based similarity methods
(including edge-based node-based measures). important note majority
techniques described define semantic similarity concepts applied
hierarchical ontologies whose structure takes account one two dimensions
graph. example, WordNet (Fellbaum, 1998) consists ontological graph
100,000 concepts whose edges model is_a part_of relationships. Perl module
(Pedersen, Patwardhan & Michelizzi, 2004) implemented lexical database
variety semantic similarity measures. Another example application Gene Ontology
(Department Genetics, Stanford University School Medicine, California, USA., 2000), one
important ontologies within bioinformatics community, 20,000 concepts
modeling is_a part_of relationships graph. Thus, none
techniques described section supposed appropriate dealing
two dimensions similarity, nevertheless useful attempt define
dimensions present studys ontological model.
second aim present section review assessment techniques ontological
similarity functions used earlier studies. gold standard established majority
experimental evaluations similarity (Resnik, 1999; Jiang & Conrath, 1997; Altintas, Karsligil,
& Coskun, 2005; Schickel-Zuber, 2007; Bernstein et al., 2005) based experiment
described Miller Charles study (1991) become benchmark determining
similarity words natural language processing research. experiment relies
similarity assessments made 38 university students provided 30 name pairs chosen
priori cover high, intermediate low levels similarity asked assess
similarity meaning scale 0 (no similarity) 4 (perfect synonymy). average
scored values represents good estimation degree similarity two terms.
certain evaluations based human judgment (Inkpen, 2007; Bernstein et al., 2005),
variations number participants way administer questionnaire
introduced. one studies (Bernstein et al., 2005), website containing survey tool
designed perform evaluation. Web experiment, subjects asked assess
similarity 73 pairs concepts scale 1 (no similarity) 5 (identical). Finally,
subjects given possibility adding comments assessment. evaluate
quality similarity measures, results compared test subjects assessments
using corrected Spearman rank correlation coefficient.
concluded human reasoning one widely-used methods
comparison performing validation similarity measure. reason,
methodology used experimentation section present study. Since
difficult run user-based evaluation complicated ontologies, example, Gene
Ontology (Lord, Stevens, Brass & Goble, 2003), deemed necessary find
model ontology elements test subjects could understand. Therefore,
ontological module implemented, must populated sufficiently good coverage
domain knowledge, is, enough knowledge meet system requirements.

400

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

3. Theoretical Approach
conceptual model grounding present study (Calle et al., 2008) distributes ontological
knowledge seven different dimensions. semiotic dimension represents relationship
concepts, terms language. example, shown Figure 1, concept
WordNets synset 3082979 corresponds machine able perform calculations
automatically, one terms associated concept computer. terms
related concept computing machine, computing device, data processor,
electronic computer information processing system, linked concept
corresponds English language (synset 6947032).

Figure 1: Example semiotic dimension representation

sort dimension represents is_a relationship concepts, relates concept
concepts models polytree structure. instance, shown Figure 2, terms
node, server web site related concepts instances computer.

Figure 2: Sort dimension example

essential dimension represents general taxonomy concepts. taxonomy
located nodes top polytree represented sort dimension. Therefore,
relations included design already observed sort dimension. since
organize knowledge higher abstraction level (they discriminative)
taken account separately, adding extra value similarity measure.
design crucial attaining good similarity measures, determines usefulness
dimension. essential dimension WordNet (Princeton Univ., 2011), example,
classifies concepts four main linguistic categories (verb, noun, adjective, adverb).
approach adequate linguistic interaction domain, may weaker general
interaction domain. proposal includes essential design inspired previous (Calle et al.,
2008) related works (Gee, 1999; Miller, 1995) refined preliminary
experimentation. design departs three main categories (abstract, actions entities)
develops main classes concepts, shown Figure 3. Finally, added
proposal aimed general interaction domains, could improved suited specific
domains particular interaction systems.

401

fiALBACETE, CALLE, CASTRO & CUADRA

concept
[05835747]

.

.

abstract

action

entity

[05854150]

[06320569]

[00001740]

attribute

circumstance

sui generis

[00024264]

[14512817]

[90000001]

place

time

role

language

[08513718]

[00028270]

[00722061]

[06282651]

activity

environment

[00407535]

[08567235]

.

domain

.

interactive

static

active

[01946439]

[01564315]

[00524481]

[05999266]

unidirectional
comm. agent

communicative
agent

[90000002]

[02956371]

human

mechanical

[02743391]

[02891236]

user

Interaction
system

[10741590]

reactive

cyclic

[02105176]

[00675701]

[05661996]

Figure 3: Essential dimension taxonomy

compositional dimension represents part-whole relationship concepts.
way, concept relationships collection concepts part it.
Figure 4 shows concepts part computer, example hard disk,
RAM ALU.
computer
[03082979]

hard disk

RAM

ALU

[03492542]

[04052757]

[02995345]



Figure 4: Compositional dimension example

restrictive dimension shown Figure 5 describes compatibility concepts
related action rest. example, action compute related
concepts computer, calculator laptop, among others.

402

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

computer
[03082979]

Action concept:
compute

calculator
[02938886]

[00637259]

laptop
[03642806]

Figure 5: Restrictive dimension example

descriptive dimension shown Figure 6 charge relationships three
kinds concepts: generic concept (entity, abstract entity action), attribute likely
characterize concept, domain (of values) attribute defined. Notice
could several available domains given attribute, domain could
numeric (magnitudes regarding unit) enumerated (a concept composed set
named values concepts). example, instance generic concept hard
disk value numeric domain information bytes attribute concept
storage capacity.
Generic concept:
hard disk

Attribute concept:
storage capacity

Domain concept:
Information bytes

[03492542]

[13562133]

[13626013]

Figure 6: Descriptive dimension example

Finally, comparative dimension derived previous dimensions responsible
calculating real time degree similarity ontological concepts. paper,
fact, focuses precisely similarity calculation. Finally, reasons efficiency,
frequently requested similarities buffered, is, stored calculated, periodically
updated retrieved necessary.

4. Proposal
paper proposes evaluates similarity measure based combination individual
similarity measures according dimensions explained (see Section 3).
combination produced training across numerous observations affect weight
dimension contributes final decision. Training performed according
different criteria. one hand, different human subjects support judgments different
combinations dimensions. hand, nature concept determines
relevant dimension comparison. example, comparing concept scanner
concept printer, sort dimension could influential, since types
computer peripherals; however restrictive dimension could influential
related different actions. opposite may happen concepts teacher tutorial

403

fiALBACETE, CALLE, CASTRO & CUADRA

related similar actions according restrictive dimension,
teaching, sort dimension little influence case.
following step describe similarity measure adapted described ontological
dimensions except semiotic dimension. Yet approach, similarity
semiotic dimension, similarity terms frequently described edit distance
Levenshtein distance (1966), is, number changes necessary turn one string
another string. decision leave dimension apart supported preliminary studies
measure yields average error rate 50% cases 80%.
Furthermore, every concept study, accuracy provided dimension lower
dimensions (the semiotic dimension never produced best
prediction), dimension never ranked first tested separately.
reason, estimated cannot contribute positively results (at least, cannot
properly adapted). Last least, preliminary experimentation training including
dimension, observed weight tended zero, drawback
slowing convergence weights rest dimensions. However, work,
evolution similarity measure (supported knowledge dimension)
incorporated global measure similarity.
4.1 Inference Mechanisms
sub-section describes method used calculate degree similarity two
given concepts ontology. Since ontological knowledge structured different
dimensions, similarity measure based dimensions. Therefore, partial
similarity calculations made sort, essential, compositional, restrictive
description dimensions described previously. resulting overall similarity two
concepts obtained calculation weighted average five partial similarities

Ss, Sc, Se, Sr Sd similarity measures according sort, compositional,
essential, restrictive description dimensions, respectively. values w1, w2, w3, w4 w5
represent weights assigned dimension resulting total similarity
two concepts value 0 (completely different concepts) 1 (the two
concepts same).
following sections describe detail procedures developed calculation
partial similarities.
4.1.1 SIMILARITY ACCORDING SORT DIMENSION
sort dimension represents is_a relationship concepts. dimension
polytree structure, allowing concept descendant one concept. Similarity
dimension often calculated proportional intersection list predecessors
404

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

compared concepts regarding total size lists. define measure, variation
edge-counting technique concretely, conceptual similarity measure defined
work Wu Palmer (1994) employed. Given two concepts, C1 C2,
measure defined

N1 N2 number ancestors C1 C2, N3 number common
ancestors C1 C2 (in advantageous tree several found polytree).
4.1.2 SIMILARITY ACCORDING COMPOSITIONAL DIMENSION
compositional dimension represents part-whole relationship concepts.
reason, appropriate way calculate similarity two concepts based
dimension comparison parts (or ingredients) concepts. Furthermore,
calculation must take account fact concept may consist required
optional concepts. detail important calculating similarity since greater weight must
given required ingredients appearing concepts, lower weight given
optional ingredients. resulting similarity two concepts, C1 C2, terms
compositional dimension obtained applying formula:

N1 number common components arising intersection
components concept C1 components concept C2 type required; N2
number common components arising intersection components C2
required components C1; N3 number required components C1 C2
common; N4 total number common components (both required optional)
two concepts; M1 M2 represent number required components concepts C1
C2, respectively. Finally, M3 M4 indicate total number components C1 C2 have.
4.1.3 SIMILARITY ACCORDING ESSENTIAL DIMENSION
essential dimension contains set abstract concepts define generic types
concepts (such action, entity, abstract, circumstance attribute). generic classification
frequently influences human speakers estimating similarity. works similarity
calculation posed concepts comparable included category
WordNets taxonomy (RiTa.WordNet, 2008). approach endows critical value
dimension, omitting rest classification. proposed
dimension contribute similarity estimation (albeit certain weight
could different rest), concepts observed design essential
dimension may influence similarity estimation.

405

fiALBACETE, CALLE, CASTRO & CUADRA

method calculating similarity two concepts C1 C2 essential
dimension based intersection essential ancestors (ancestors within subset
essential concepts). formalized follows:

Card(E1) Card(E2) are, respectively, total number essential ancestors
concepts C1 C2, Card(E1 E2) indicates number common essential ancestors.
4.1.4 SIMILARITY ACCORDING RESTRICTIVE DIMENSION
restrictive dimension defined concept representing action another
concept representing entity. Similarity dimension calculated different way
depending type concepts compared. reason, two different similarity
measures exist dimension: comparing two actions comparing two entities. Similarity
two concepts representing entity based action concepts
entities common. formula used calculation similarity comparing
two entities, C1 C2, defined

M1 M2 number common actions positive negative
restrictive relationship entities C1 C2, respectively. values N1, N2, N3 N4
represent, respectively, total number actions positive relationship entity
C1, negative relationship C1, positive relationship entity C2, negative
relationship C2.
regards similarity two concepts representing action, calculated based
set concepts defined actions, similar higher number
restricted concepts common. formula calculate similarity two action
concepts (C1, C2) particular sign (positive negative) defined

N3 number common entities shared two actions, N1 N2
total number entities restrictive relationship C1 C2, respectively.
4.1.5 SIMILARITY ACCORDING DESCRIPTIVE DIMENSION
description dimension represents relationship concept, attribute value
concrete domain. Similarity dimension calculated differently depending type
concepts compared, is, entities, attributes domains. pairs concepts (C1, C2)
representing entity, applicable formula defined

406

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

N1 number common attributes without default value assigned, N2
number common attributes whose value entities assigned
default, N3 number common attributes value one
assigned default. terms M1 M2 correspond total number attributes
related concepts C1 C2, respectively.
concepts (C1, C2) attributes, formula apply defined

N3 number common values attributes, N1, N2 total number
possible values attributes C1 C2, respectively.
Finally, concepts compared (C1, C2) represent domains, similarity according
dimension calculated based amount common attributes (for domains
apply) number values shared domains.

N3 number common attributes shared domains (C1, C2), N1, N2
total number attributes associated them. Finally, M3 number common values
defined domains, M1, M2 total number values two domains.
Finally, concepts compared (C1, C2) may values belonging domain, either
enumerated numeric type. operating domains, necessary define previously
correspondence them. Numeric domains related function (typically,
lineal proportion). Relating enumerated domain numeric domain achieved
assigning enumerated value fuzzy label numeric domain. Finally,
correspondence two enumerated domains always involves intermediate numeric
domain (with correspondence defined two domains). values
comparable, formula measure similarity defined follows:

Cinf Csup are, respectively, lower limit upper limit within range
values, C1 C2 correspondent numeric comparable values.
4.2 Preliminary Experimentation
testing proposal, preliminary experiments performed refine
obtain first perspective validity. experiments instructed set
similarity measures obtained total 20 pairs concepts evaluated 17 human subjects.
dataset described Section 5.1.
407

fiALBACETE, CALLE, CASTRO & CUADRA

Specifically, individual influence dimension similarity tested thorough set
experiments involving separately. Since combination them,
need training either. Figure 7 shows box plot represents error measures produced
individually dimension.
100

Error (%)

80
60
40
20
0
Sort

Compositional

Essential

Restrictive

Descriptive

Figure 7: Performance isolated dimensions Ontology

Figure 8 shows series twenty pairs, every dimension produced better prediction
others least once. fact, essential dimension provided best response almost half
cases, descriptive dimension best one case.
Restrictive
10%

Descriptive
5%

Sort
30%

Compositiona
l
15%

Essential
40%

Figure 8: Cases dimension ranked first

fact lead conclusion essential design appropriate,
descriptive dimension weak. analysis found latter lacked sufficient
knowledge, improved line evaluation (more knowledge added).
Despite improvement, since analysis introduction knowledge performed
manually (in contrast dimensions, knowledge obtained WordNet),
could still enhanced would improve individual results dimension. Besides,
result definitive, since weights may different interaction domains,
volume knowledge base important too. useful consequence one
408

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

five ontological dimensions contribute similarity function, supporting
hypothesis adequate combination may yield better results
individual approaches.
4.3 Weights Training Methods
Assigning proper weight dimension crucial achieving good results. Since
human test subject usually give relevance five dimensions similarity,
basic training program regarding weights associated dimension developed.
program based reinforcement learning technique (specifically variant Q learning
algorithm) implemented order determine, several iterations,
appropriate value weights applied dimension (previously defined Section 4.1)
minimize error formula result human judgment. Therefore, input
training algorithm set similarity judgments made human test subjects.
algorithm follows next steps:
a) initial step, five weights w1, w2, w3, w4 w5 applied dimension
(see formula Section 4.1) initialized 1.
b) iteration training algorithm, results dimension similarity
calculated according formulas described Sections 4.1.1 4.1.5.
Subsequently, five new weights calculated according next criteria:
1.
2.
3. Failure meet conditions 1) 2),
parameter ranged 1 5 (one dimension),
represents individual score represents similarity value 0 10 one
pair concepts scored one participant.
stands increase
weight (for dimension i) current iteration,
represents increase
previous iteration. max(Simi) min(Simi) represent maximum
minimum similarity individual values, respectively. Finally, stands learning rate.
training focused different points view, tested evaluated.
Firstly, pair-oriented training implemented order individually adjust weights
20 concept pairs, independently specific user. weights adjusted
individually pairs concepts, taking one user per iteration. way,
iteration, new array refined weights obtained used evaluating similarity.
test consists calculating similarity (with array weights) comparing
human assessment.
Since degree significance assigned dimension may depend subjectivity
testers, particular interest make adjustment weights based user.
409

fiALBACETE, CALLE, CASTRO & CUADRA

experiment, training weights performed user consisted
20 iterations (one pair concepts). iteration training algorithm, absolute
error committed relation corresponding pair calculated. running training
17 users, average absolute errors iterations calculated.
third method designed order address shortcomings pair-oriented
training. indicated storing array weights possible pair
concepts medium sized ontology requires unusually extensive physical resources. Besides,
significant coverage thus defined knowledge would require far much training. short,
realistic develop method high number combinations concepts.
However, preliminary experimentation checked weights applied pair
likely applied combinations two concepts. Therefore,
new training method (feature-oriented) proposed slightly modifying pair-oriented one.
feature-oriented method, array weights stored concept instead
pair concepts (which solve problems storage extent training). time
one concept compared other, array weights reviewed refined.
similarity calculation given pair based aggregation arrays concepts.
Finally, observed method showed different behavior depending pair
concepts compared: method achieving worst results average best
specific pairs. Subsequently, hybrid method proposed developed,
combining feature-oriented user-oriented trainings, aiming profit advantages
method. training similar focused user, iteration
array weights refined different degree, taking account array stored
particular concept. Therefore, particular dimension usually relevant concept,
adaptation user dimension strengthened.

5. Evaluation
conceptual model ontology defined, weights training methods
proposed, next step study evaluate proposal. present section describes
experiments run evaluating proposal, design results obtained
discussion. knowledge base supported relational database management system
Oracle 11g, logic ontology component (including inference mechanisms)
implemented Java. knowledge bases designed satisfy specific purposes within
research project. initial knowledge load obtained large lexical database
WordNet (Fellbaum, 1998) including existing concepts (synsets), terms relationships
(corresponding sort compositional dimensions). Since proposed ontological model
defines relationships concepts (essential, restrictive descriptive), necessary
add knowledge. Cognos.Onto tool enables knowledge edition management
specific model. tool belongs larger toolkit, Cognos (Calle et al., 2011) already used
several research projects. toolkit seeks ease interaction corpus analysis, annotation,
implementation management, diverse yet integrated tools aimed specific type
knowledge (pragmatic, NLP related, ontological etc.).
410

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

5.1 Experimental Design Preparation
First all, necessary choose Interaction Domain define entire
experiment. concepts involved subset whole knowledge base, restricted
specific domain. participants chosen order constitute good coverage
focused domain. Finally, additional knowledge fed experts interaction domain
related projects research framed (as test subjects
participant experiments).
methodology chosen evaluate proposed similarity measure based Millers
benchmark (Miller & Charles, 1991). Experiments designed determine whether
result attained application similarity function pair concepts reliable
or, words, result falls within acceptable range compared similarity
judgments made human test subjects.
begin experimental phase study, initial loading concepts must first made
proposed ontology. reason, WordNets synsets (Princeton Univ., 2011) taken
concepts, together corresponding semiotics, sort compositional relationships.
Knowledge domain experts responsible populating remaining dimensions
ontological model (i.e., essential, restrictive descriptive) subset 350 concepts,
selected relevance interaction domain.
chosen domain labeled computer science teaching interaction domain within
Spanish academic socio-cultural environment. area knowledge familiar test
subjects selected heterogeneous domain (different roles, ages,
genders). perform evaluation, test designed test subject rate
similarity pairs concepts. set pairs meet basic criterion: least two
pairs included explore proposed dimensions, one clear incidence
dimension another one without (or little impact).
total number twenty-one test subjects available, four outliers left
apart. discarded checking judgment responses
uniform rest sample. participant scores follow normal distribution
removing outliers. reason, sample size calculated test statistical
significance result least ten subjects ensure 99% confidence. Therefore,
sample size seventeen participants sufficient ensure data representative.The
seventeen subjects experts interaction domain (technical education), specifically
five technical students, seven researchers five lecturers. ages ranged 20 50
distributed follows: seven subjects 20-30 year-old range, six 30-40
year-old range remaining four 40-50 year-old range. regard gender,
slightly half female (9) rest male (8). chosen interaction
domain applied research project THUBAN (TIN2008-02711). participant
provided test containing set twenty pairs concepts domain. Since
observations follow normal distribution, determined minimum significant sample
size would sixteen 99% confidence. Therefore, set twenty pairs concepts provides
significant results. However, larger domain, size dataset may different attain
411

fiALBACETE, CALLE, CASTRO & CUADRA

statistically significant results. coherence components system
proposal integrated, similarity measures ranged zero (no similarity) ten
(absolutely identical, concept). addition, pairs, subjects asked
justify score, indicating specific parameters similarity took account
making decision.After obtaining individual survey results, average total human
assessments pair concepts calculated.Table 1 shows 20 pairs concepts
included test right pair, range (difference maximum
minimum scores), standard deviation average rating assigned users.
Pair ID

Pair concepts

Range

Standard
deviation

Average
similarity

0

Reading lamp Personal computer

6

1.76

2.71

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

Laptop Server computer
Teacher Tutorial
Meeting room Laboratory
Server computer Microwave
Office Laboratory
Screen Blackboard
Stapler Folder
Plug Power strip
Office Meeting room
Pencil CD marker
Associate professor Teaching Assistant
Associate professor Bachelor
write papers program
give lecture teach
Keyboard Mouse
Fridge Microwave
Hard disk drive Pendrive
Scanner Printer
Poster Blackboard

6
7
8
8
9
7
7
4
6
3
5
8
7
6
5
7
3
8
6

1.62
1.92
2.15
2.02
2.25
1.83
2.19
1.21
1.69
0.99
1.34
2.53
2.15
1.60
1.41
1.77
0.94
1.89
1.82

6.47
5.06
4.35
2.24
5.76
6.12
3.94
8.29
6.29
7.29
8.06
5.18
4.53
7.76
7.35
5.35
8.47
5.94
4.24

Table 1: Pairs concepts average similarity

methods subject iteration order (either analyzed pair human judge),
alter result training. order avoid effect endow significance
results, preliminary experiments minimum number repetitions (with different
order) determined reduce stochastic gain significance (close 275), consequently
decided program 300 repetitions different order method. graphs
tables, error rates pairs (identified pair_id) numbered 0 19, iterations
numbered 1 20.
5.2 Experiments
section presents results obtained execution experiments corresponding
four weight adjustment algorithms described Section 4.3. experiments
412

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

performed subset ontological knowledge stored acquired computer science
teaching domain. first experiment performed pair-oriented training and, order
evaluate results training, average absolute error calculated (for pair)
similarity based human judgment result obtained applying
similarity measure proposed according following formula:

corresponds index iterate human judge specific pair
concepts n number test subjects. Finally, errorpairId represents absolute error
human judgment pair result obtained training algorithm
iteration. Table 2 shows absolute errors calculated experiment pair
concepts, well average error which, 18.5% comes slightly closer scores
provided human subjects.
Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 15.2 14.8 38.3 18.6 19.4 18.1 17.6 18.8 20.2 15.4 13.4 18.0 22.5 19.6 15.2 13.0 15.3 20.9 17.1 19.0 18.5

Table 2: Pair-oriented training error rate

noted eleven cases, error rate less average, eight cases
error rate around average, one pair (#2) shows excessive error rate requires
analysis discussion (see subsection 5.3). Figure 9 shows comparison trend
lines regarding error rate accumulated pair-oriented training algorithm
accumulated error similarity function without weights training.

Figure 9: Accumulated average error pair-oriented training

second place, absolute error obtained pair feature-oriented training
shown Table 3. results, compared obtained pair-oriented training,
show slightly worse performance (with mean error rate 20,2%). However,
recalled method advantages (realistic storage training extent).
413

fiALBACETE, CALLE, CASTRO & CUADRA

Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 15.0 14.9 38.2 18.4 30.3 22.7 17.5 18.5 20.1 21.6 13.4 24.9 21.2 19.2 15.2 13.0 14.4 20.6 16.8 25.4 20.2

Table 3: Feature-oriented training error rate

third experiment executed user-oriented training. order evaluate results
experiment, average absolute error calculated (for human judge)
similarity based human judgment 20 pairs concepts result
obtained applying similarity measure proposed. way, error average
calculated follows:

corresponds index iterate pair concepts specific user, n
number pairs concepts errorpairId represents absolute error human
judgment pair result training algorithm iteration.
case, average error rate achieved 23.9%, even worse featureoriented training. absolute error rate obtained iteration shown Table 4.
Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 18.6 14.1 40.7 17.9 30.8 16.8 22.9 17.5 37.1 17.1 34.6 35.8 24.3 21.5 31.2 13.6 13.9 27.4 22.3 20.8 23.9

Table 4: User-oriented training error rate

Figure 10 shows comparison trend lines correspondent error rate accumulated
user-oriented training algorithm accumulated error without weight training.
observed, user-oriented training trend line follows downward curve 20
iterations reaches error rate 23.9%. Comparing trend lines, concluded
training decreases accumulated error adapts calculated similarities subjects
judgments, yet would desirable improve adaptation (since still far featureoriented training).

Figure 10: Accumulated average error user-oriented training

414

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

observed, user-oriented feature-oriented training methods able
improve similarities calculation, becoming noteworthy approaches. Consequently,
found interest explore method combines them. new hybrid method
departs user-oriented approach, takes account weights vector obtained
feature-oriented training described section 4.3. shown Table 5, user error rate
successfully reduced 21.2% respect user-oriented training. However,
method degrades performance achieved feature alone method.
Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 16.0 14.3 39.0 16.9 29.4 17.3 22.2 17.4 25.1 18.5 21.5 29.6 22.0 19.9 22.8 13.2 13.1 23.8 19.2 22.8 21.2

Table 5: User-feature hybrid training error rate

5.3 Discussion Results Obtained
Among results, concept pair 2 (teacher-tutorial) scored error rate 38%
average similarity assigned users (see Table 1) 5.06. latter value significantly high
considering fact first concept refers person second static entity.
Reviewing participant responses question, however, understood test subjects
gave higher score sole feature concepts common, activity teaching.
Analyzing results outlier, appears algorithm tendency gradually
increase weight restrictive dimension, longer training necessary adapt
weight vector relevant dimension restrictive one. Using training algorithm
faster convergence would ensure good result pair, could adversely affect
results. However, convergence guaranteed larger number users.
Figure 11 shows comparison absolute error obtained four experiments
performed work (pair-oriented, user-oriented, feature-oriented hybrid trainings)
pair, average results method. first experiment performed, pairoriented training, achieves best average error rate, 18.5%, although pair
mentioned error exceeded 38%. However, experiment major limitation:
trained weight vector pair concepts possible cannot stored due large number
combinations existing concepts ontology. shortcoming mitigated
development feature-oriented training, achieving error rate 20.2%, figure
slightly worse pair-oriented training error. Nevertheless, result
fully reflect impact training test pairs include concepts appear
experiment. calculation average error restricted pairs
concepts repeated one pair, error amounts 22.8%.
case, experiment important advantage since implementation realistic
applied large ontologies.
user-oriented training aimed adapting weights subject order
confirm assumption every test subject assigns value dimensions.
Although error rate achieved (23.9%) satisfactory either pair feature415

fiALBACETE, CALLE, CASTRO & CUADRA

oriented trainings, figure included sub-section 5.2 training shows decreasing
trend line which, compared trend line without training, allows conclusion
user-oriented experiment able adapt individual judgment. reason,
improvement attempted user-training result combination
feature-oriented experiment.

Figure 11: Comparison experiment results

hybrid training detailed Section 5.2 achieved 21.2% error rate, reduces
user-oriented training, balances performance user-oriented method
(reduces standard deviation). Taking account feature-oriented training method depends
experience features knowledge base might lack experience,
response obtained could satisfactory cases. fact, calculating error
produced feature-oriented method dataset (not restricted repeated pairs)
result amounted 22.8%. sum, feature-oriented method provides better results
enough knowledge available. last results presented Figure 11 concern experiment
observing sort dimension (which frequent method calculating similarities).
average error rate 24.1%, higher four methods discussed.
addition, observed error rate experiment is, several cases, far
average error. Figure 12 shows boxplot comparing performance four training methods
proposed sort dimension formula.
416

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

100

Error (%)

80
60
40
20
0
Pair

Feature

User

Hybrid

Sort

Figure 12: Performance training method

seen, regarding error predictions, sort dimension obtains higher
maximum (although lower minimum), higher median (except user training) higher
deviation rest. graph, concluded error rate achieved
sort dimension method (used previous studies similarity) greater error rate
achieved feature training method. order check statistically, null hypothesis
formulated (the average error methods) alternative hypothesis, (the
average error feature-oriented method lower sort dimension method error).
measure discrepancy calculated sample twenty measures error (one per
pair) result (-1.78) found outside acceptance range (-1.64, +), therefore
null hypothesis rejected alternative accepted significance level 0.05.
Consequently, considered true error shown feature-oriented method lower
error produced sort dimension method.
Finally, Figure 13 shows average final weights four experiments. shows
relevance taken experiments dimension, yet cannot extrapolated
interaction domains. dependent set pairs chosen experiment, results
show five dimensions taken account, diverse weights.
Descriptive
14%

Sort 26%

Restrictive
12%

Compositional
22%

Essential 26%

Figure 13: Average weights ontological dimensions

417

fiALBACETE, CALLE, CASTRO & CUADRA

6. Conclusions Perspective Future Research
paper defines similarity measure multi-dimensional knowledge model ontology
type, specifically ontology aimed supporting Human-Like Interaction. proposed
measure based five dimensions ontological knowledge: sort, compositional, essential,
restrictive descriptive. five weighted aggregated order obtain
global similarity measure. equations applied dimension general used
ontologies observe dimensions, yet observing
aggregating similarity result proposed enhanced accuracy.
solution presents another challenge, form weights calculation. fact,
person decides similarity concepts unwittingly makes dimensions
prevail others. criteria may diverse, work focused studying
dependence weights nature concepts, either pairs (pair training method)
individually (feature training method), described Section 4.3. work explores
influence past behavior users perform concept pair evaluations (and
ultimately, user owns device usually interacts it). Following line, userdependent training proposed, finally hybrid one (merging feature user benefits)
included too. evaluated compared order ascertain one
performs better, obtaining best results pair-oriented training.
order evaluate performance proposed similarity measure, results
recorded compared taken human test subjects. evaluation technique
applied several studies similarity measures considered gold standard.
experimental phase, four training algorithms developed according different
perspectives. Thus, phase included pair-oriented, feature-oriented, user-oriented
hybrid experiment. every case, error rate calculated respect human subject
assessments. best results corresponded pair-oriented method achieved error
rate 18.5%. Since implementation experiment realistic large ontologies,
feature-oriented experiment required despite slightly worsening results previous
experiment, concretely, producing error rate 20.2%. However, feature-oriented
experiment big advantage able applied easily large ontologies.
Moreover, user-oriented training aimed adapt weights subject order
confirm assumption every test subject assigns value dimensions.
experiment highest error rate algorithms (23.9%), demonstrated,
error rate follows decreasing trend line while, training done, error rate follows
asymptotic tendency. addition this, experiment shows slightly better results
taking account sort dimension (which average error rate 24.1%
maximum 60.4%). reason, concluded user-oriented experiment able
adapt individual judgment (although adaptation slow). Finally, hybrid
experiment combines feature-oriented user-oriented training and, error rate
21.2%, nevertheless manages reduce error user-oriented training, well
balancing error atypical cases common rest experiments.

418

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

Since hybrid experiment manages balance results experiments,
currently, improved hybrid algorithm developed. algorithm calculation
weights iteration affected depending error produced feature
experiment pair concepts corresponding iteration.
performance training methods proposed closely related available extent
knowledge. reason, authors currently working mechanisms increasing
quality completeness ontological knowledge. manual acquisition new
knowledge expert requires great deal resources would desirable develop
advanced mechanism learn new concepts relations. challenge attain
knowledge acquisition human-like interaction human subjects. Therefore,
lifetime system, knowledge bases would enriched interacting users.
Finally, refinement similarities formulation interesting line work, especially
semiotic dimension reintroducing influence global similarity calculation.

Acknowledgments
development approach construction part LaBDA-Interactor HumanLike Interaction System, part research projects SemAnts (TSI-020110-2009-419)
THUBAN (TIN2008-02711) CADOOH (TSI-020302-2011-21), supported Spanish
Ministry Industry, Tourism Commerce Spanish Ministry Education,
respectively. Besides, knowledge bases populated using COGNOS toolkit developed
research project MA2VICMR (S2009/TIC-1542) supported Regional
Government Madrid.

References
Altintas, E., Karsligil, E., & Coskun, V. (2005). new semantic similarity measure evaluated
word sense disambiguation. Procs. 15th NODALIDA conference. Joensuu.
Bernstein, A., Kaufmann, E., Kiefer, C., & Brki, C. (2005). SimPack: Generic Java Library
Similarity Measures Ontologies. Zurich: Technical report.
Budanitsky, A. (1999). Lexical semantic relatedness application natural language
processing. University Toronto. Technical report.
Calle, F. (2004). Interaccin Natural mediante procesamiento intencional: Modelo de Hilos en
dilogos. Thesis, (PhD). Politecnic University Madrid.
Calle, F. J., Albacete, E., Snchez, E., del Valle, D., Rivero, J., & Cuadra, D. (2009). Cognos:
Natural Interaction Knowledge Management Toolkit. International Conference
Applications Natural Language Information Systems (NLDB 2009) (pp. 303-304).
Saarbrken, Germany: Lecture Notes Computer Science.
Calle, F., Castro, E., & Cuadra, D. (2008). Ontological dimensions applied Natural Interaction.
Procs. First International Workshop Ontologies Interactive Systems , 91-96 .

419

fiALBACETE, CALLE, CASTRO & CUADRA

Department Genetics, Stanford University School Medicine, California, USA. (2000). Gene
ontology: tool unification biology. Gene Ontology Consortium. Nature
genetics Vol. 25, No. 1. , 25-29.
Fellbaum, C. (1998). WordNet: Electronic Lexical Database. Cambridge, UK: MIT Press.
Gee, J.P. (1999). Introduction Discourse Analysis. Routledge.
Inkpen, D. (2007). Semantic similarity knowledge applications. STUDIA UNIV. BABESBOLYAI, INFORMATICA, Volume LII, , 11-22.
Jiang, J. J., & Conrath, D. W. (1997). Semantic Similarity Based Corpus Statistics Lexical
Taxonomy. International Conference Research Computational Linguistics. Taiwan.
COGNOS Toolkit. (2011). Retrieved July 2011,
http://labda.inf.uc3m.es/doku.php?id=es:labda_lineas:cognos
RiTa.WordNet: WordNet library Java/Processing. (2008). [Online]. Available:
http://www.rednoise.org/rita/wordnet/documentation/
Leacock, C., & Chodorow, M. (1998). Combining Local Context WordNet Similarity
Word Sense Identification. Electronic Lexical Database , 265-283.
Levenshtein, V. I. (1966). Binary codes capable correcting deletions, insertions reversals.
Soviet Physics Doklady vol 10 , 707-710.
Lin, D. (1998). Information-Theoretic Definition Similarity. Proceedings 15th
International Conf. Machine Learning, (pp. 296-304). Madison, Wisconsin USA.
Lord, P. W., Stevens, R. D., Brass, A., & Goble, C. A. (2003). Investigating semantic similarity
measures across Gene Ontology: relationship sequence annotation.
Bioinformatics , 1275-1283.
Miller, G. A., & Charles, W. G. (1991). Contextual correlates semantic similarity. Language
Cognitive Processes , 1-28.
Miller, G. A. (1995). WordNet: Lexical Database English. Communications ACM vol
38 ,No. 11: 39-41.
Pedersen, T., Patwardhan, S., & Michelizzi, J. (2004). WordNet:: Similarity measuring
relatedness concepts. Demonstration Papers HLT-NAACL 2004 (pp. 38-41). Boston,
Massachusetts, USA: Association Computational Linguistics
Princeton Univ. (February 3, 2011). WordNet: lexical database English. Obtenido de
WordNet: lexical database English: http://wordnet.princeton.edu/
Rada, R., Mili, H., Bicknell, E., & Blettner, M. (1989). Development application metric
semantic nets. IEEE Trans. Systems, Man, Cybernetics. 19. , 17-30.
Resnik, P. (1999). Semantic Similarity Taxonomy: Information-Based Measure
Application Problems Ambiguity Natural Language. Journal Artificial
Intelligence Research , 95-130.
Resnik, P. (1995). Using information content evaluate semantic similarity taxonomy.
IJCAI'95 Proceedings 14th international joint conference Artificial intelligence
(pp 448-453). San Francisco, USA: Morgan Kaufmann Publishers Inc.
420

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

Richardson, R., Smeaton, A. F., & Murphy, J. (1994). Using WordNet Knowledge Base
Measuring Semantic Similarity Words. Proceedings AICS Conference.
Dublin, Ireland: Technical Report.
Schickel-Zuber, V. (2007). OSS: semantic similarity function based hierarchical ontologies.
IJCAI'07 Proceedings 20th international joint conference Artifical intelligence
(pp. 551-556). San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.
Seco, N., Veale, T., & Hayes, J. (2004). Intrinsic Information Content Metric Semantic
Similarity WordNet. ECAI'2004, 16th European Conference Artificial
Intelligence, (pp. 1089-1090). Valencia, Spain .
Wu, Z., & Palmer, M. (1994). Verb semantics lexical selection. ACL'94 Proceedings
32nd annual meeting Association Computational Linguistics (pp. 133-138).
Stroudsburg, USA: Association Computational Linguistics.

421


