Journal Artificial Intelligence Research 44 (2012) 709-755

Submitted 04/12; published 08/12

Online Speedup Learning Optimal Planning
Carmel Domshlak
Erez Karpas

DCARMEL @ IE . TECHNION . AC . IL
KARPASE @ TECHNION . AC . IL

Faculty Industrial Engineering Management
Technion - Israel Institute Technology
Haifa, 32000, Israel

Shaul Markovitch

SHAULM @ CS . TECHNION . AC . IL

Faculty Computer Science
Technion - Israel Institute Technology
Haifa, 32000, Israel

Abstract
Domain-independent planning one foundational areas field Artificial Intelligence. description planning task consists initial world state, goal, set actions
modifying world state. objective find sequence actions, is, plan,
transforms initial world state goal state. optimal planning, interested finding plan, one cheapest plans. prominent approach optimal planning
days heuristic state-space search, guided admissible heuristic functions. Numerous admissible
heuristics developed, strengths weaknesses, well known
single best heuristic optimal planning general. Thus, heuristic
choose given planning task difficult question. difficulty avoided combining
several heuristics, requires computing numerous heuristic estimates state,
tradeoff time spent time saved combined advantages
different heuristics might high. present novel method reduces cost combining admissible heuristics optimal planning, maintaining benefits. Using idealized
search space model, formulate decision rule choosing best heuristic compute
state. present active online learning approach learning classifier decision
rule target concept, employ learned classifier decide heuristic compute
state. evaluate technique empirically, show substantially outperforms
standard method combining several heuristics via pointwise maximum.

1. Introduction
center problem intelligent autonomous behavior task selecting actions
take next. Planning AI best conceived model-based approach automated action
selection (Geffner, 2010). models represent current situation, goals, possible actions.
Planning-specific languages used describe models concisely. main challenge
planning computational, planning languages lead intractable problems worst
case. However, using rigorous search-guidance tools often allows efficient solving interesting
problem instances.
classical planning, concerned synthesis plans constituting goal-achieving
sequences deterministic actions, significant algorithmic progress achieved last
two decades. turn, progress classical planning translated advances involved
planning languages, allowing uncertainty feedback (Yoon, Fern, & Givan, 2007; Palacios
c
2012
AI Access Foundation. rights reserved.

fiD OMSHLAK , K ARPAS , & ARKOVITCH

& Geffner, 2009; Keyder & Geffner, 2009; Brafman & Shani, 2012). optimal planning,
objective find plan, find one cheapest plans.
prominent approach domain-independent planning, optimal planning particular,
state-space heuristic search. natural view planning task search problem,
use heuristic search algorithm solve it. Recent advances automatic construction heuristics
domain-independent planning established many heuristics choose from,
strengths weaknesses. However, wealth heuristics leads new question: given
specific planning task, heuristic choose?
paper, propose selective max online learning approach combines
strengths several heuristic functions, leading speedup optimal heuristic-search planning.
high level, selective max seen hyper-heuristic (Burke, Kendall, Newall, Hart, Ross,
& Schulenburg, 2003) heuristic choosing among heuristics. based seemingly trivial observation that, state, one heuristic best state.
principle, possible compute several heuristics state, choose one according values provide. However, heuristic computation domain-independent planning
typically expensive, thus computing several heuristic estimates state takes long time.
Selective max works predicting state heuristic yield best heuristic
estimate, computes heuristic.
always clear decide best heuristic state is, first
analyze idealized model search space describe choose best heuristic
state order minimize overall search time. describe online active learning
procedure uses decision rule formulated idealized model. procedure constitutes
essence selective max.
experimental evaluation, conducted using three state-of-the-art heuristics
domain-independent planning, shows selective max effective combining several
heuristics optimal search. Furthermore, results show using selective max results
speedup baseline heuristic combination method, selective max robust different parameter settings. claims supported selective max runnerup ex-aequo last International Planning Competition, IPC-2011 (Garca-Olaya, Jimenez, &
Linares Lopez, 2011).
paper expands conference version (Domshlak, Karpas, & Markovitch, 2010)
several ways. First, improve expand presentation selective max decision rule.
Second, explain handle non-uniform action costs principled way. Third, empirical
evaluation greatly extended, includes results IPC-2011, well controlled
experiments three different heuristics, exploration parameters selective
max affect performance.

2. Previous Work
Selective max speedup learning system. general, speedup learning concerned improving performance problem solving system experience. computational difficulty
domain-independent planning led many researchers use speedup learning techniques order
improve performance planning systems; survey many these, see work
Minton (1994), Zimmerman Kambhampati (2003), Fern, Khardon, Tadepalli (2011).
710

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Speedup learning systems divided along several dimensions (Zimmerman & Kambhampati, 2003; Fern, 2010). Arguably important dimension phase learning takes
place. offline, inter-problem, speedup learner analyzes problem solvers performance
different problem instances attempt formulate rule would improve
performance would generalize well future problem instances. Offline learning
applied extensively domain-independent planning, varying degrees success (Fern et al.,
2011). However, one major drawback offline learning need training examples
case, planning tasks domains interest.
Learning take place online, problem solving. online, intra-problem,
speedup learner invoked problem solver concrete problem instance solver
working on, attempts learn online, objective improving solvers performance
specific problem instance solved. general, online learners assumed pretrained other, previously seen problem instances; information rely
collected process solving concrete problem instance called for. Online
learning shown extremely helpful propositional satisfiability (SAT) general
constraint satisfaction (CSP) solving, nogood learning clause learning among
essential components state-of-the-art solver (Schiex & Verfaillie, 1993; Marques-Silva
& Sakallah, 1996; Bayardo Jr. & Schrag, 1997). Thus, indirectly, SAT- CSP-based domainindependent planners already benefit online learning techniques (Kautz & Selman, 1992;
Rintanen, Heljanko, & Niemela, 2006). However, best knowledge, work first
application online learning optimal heuristic-search planning.

3. Background
domain-independent planning task (or planning task, short) consists description
initial state, goal, set available operators. Several formalisms describing planning tasks
use, including STRIPS (Fikes & Nilsson, 1971), ADL (Pednault, 1989), SAS+ (Backstrom
& Klein, 1991; Backstrom & Nebel, 1995). describe SAS+ formalism, one used
Fast Downward planner (Helmert, 2006), top implemented evaluated
selective max. Nothing, however, precludes using selective max context formalisms.
SAS+ planning task given 4-tuple = hV, A, s0 , Gi. V = {v1 , . . . , vn } set state
variables, associated finite domain dom(vi ). complete assignment V called
state. s0 specified state called initial state, goal G partial assignment V .
finite set actions. action given pair hpre(a), eff(a)i partial assignments V
called preconditions effects, respectively. action associated cost C(a) R0+ .
action applicable state iff |= pre(a). Applying changes value state
variable v eff(a)[v] eff(a)[v] specified. resulting state denoted sJaK. denote
state obtained sequential application (respectively applicable) actions a1 , . . . , ak
starting state sJha1 , . . . , ak iK. action sequence plan s0 Jha1 , . . . , ak iK |= G.
optimal planning, interested finding one
Pthe cheapest plans, cost plan
ha1 , . . . , ak sum constituent action costs ki=1 C(ai ).
SAS+ planning task = hV, A, s0 , Gi easily seen state-space search problem
whose states simply complete assignments variables V , transitions uniquely determined actions A. initial goal states defined initial state goal .
optimal solution state-space search problem found using search algorithm
711

fiD OMSHLAK , K ARPAS , & ARKOVITCH

admissible heuristic h. heuristic evaluation function h assigns estimate distance
closest goal state state evaluates. length cheapest path state
goal denoted h (s), h called admissible never overestimates true goal distance
is, h(s) h (s) state s. works expanding states order increasing
f (s) := g(s) + h(s), g(s) cost cheapest path initial state known
far.

4. Selective Max Decision Rule
Many admissible heuristics proposed domain-independent planning; vary
cheap compute yet accurate, accurate yet expensive compute. general,
accurate heuristic is, fewer states would expanded using it.
accuracy heuristic functions varies different planning tasks, even different states
task, may able produce robust optimal planner combining several admissible heuristics. Presumably, heuristic accurate, is, provides higher estimates,
different regions search space. simplest best-known way using point-wise maximum heuristics use state. Given n admissible heuristics,
h1 , . . . , hn , new heuristic, maxh , defined maxh (s) := max1in hi (s). easy see
maxh (s) hi (s) state heuristic hi . Thus search using maxh expected
expand fewer states using individual heuristic.PHowever, denote time needed
compute hi ti , time needed compute maxh ni=1 ti .
mentioned previously, selective max form hyper-heuristic (Burke et al., 2003)
chooses heuristic compute state. view selective max decision rule dr,
given set heuristics h1 , . . . , hn state s, chooses heuristic compute
state. One natural candidate decision rule heuristic yields highest,
is, accurate, estimate:
drmax ({h1 , . . . , hn }, s) := hargmax1in hi (s) .
Using decision rule yields heuristic accurate maxh , still computing
one heuristic per state time targmax1in hi (s) .
analysis, however, take account different computation times different heuristics. instance, let h1 h2 pair admissible heuristics h2 h1 .
priori, seems using h2 always preferred using h1 former
cause expand fewer states. However, suppose given planning task, expands 1000
states guided h1 100 states guided h2 . computing h1 state
takes 10 ms, computing h2 state takes 1000 ms, switching h1 h2 increases
overall search time. Using maxh h1 h2 makes things worse, h2 h1 ,
thus computing maximum simply wastes time spent computing h1 . possible,
however, computing h2 carefully chosen states, computing h1 states,
would result expanding 100 states, reducing overall search time compared
running h2 .
example shows, even given knowledge heuristics estimates advance,
clear heuristic computed state objective minimize overall
search time. Therefore, begin formulating decision rule choosing one two
heuristics, respect idealized state-space model. Selective max operates online
712

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

s0


f2 = c

f1 = c
sg

Figure 1: illustration idealized search space model f -contours two admissible
heuristics

active learning procedure, attempting predict outcome decision rule choose
heuristic compute state.
4.1 Decision Rule Perfect Knowledge
formulate decision rule choosing two given admissible heuristics, h1 h2 ,
compute state idealized search space model. order formulate decision
rule, make following assumptions:
search space tree single goal, constant branching factor b, uniform cost
actions. idealized search space model used past analyze behavior
(Pearl, 1984).
time ti required computing heuristic hi independent state evaluated;
w.l.o.g. assume t2 t1 .
heuristics consistent. heuristic h said consistent obeys triangle
inequality: two states s, s0 , h(s) h(s0 ) + k(s, s0 ), k(s, s0 ) optimal cost
reaching s0 s.
have: (i) perfect knowledge structure search tree, particular
cost optimal solution c , (ii) perfect knowledge heuristic estimates
state, (iii) perfect tie-breaking mechanism.
Obviously, none assumptions holds typical search problems, later examine
individual influence framework.
Adopting standard notation, let g(s) cost cheapest path s0 s. Defining
maxh (s) = max(h1 (s), h2 (s)), use notation f1 (s) = g(s) + h1 (s), f2 (s) = g(s) +
h2 (s), maxf (s) = g(s) + maxh (s). algorithm consistent heuristic h expands
states increasing order f = g + h (Pearl, 1984). particular, every state f (s) <
h (I) = c surely expanded , every state f (s) > c surely
713

fiD OMSHLAK , K ARPAS , & ARKOVITCH

expanded . states f (s) = c might might expanded , depending
tie-breaking rule used. perfect tie-breaking assumption, states
f (s) = c expanded lie along optimal plan.
Let us consider states satisfying f1 (s) = c (the dotted line Fig. 1) satisfying
f2 (s) = c (the solid line Fig. 1). states f1 = c f2 = c contours
surely expanded h1 h2 , respectively. states contours
(the grid-marked region Fig. 1), is, states SE = {s | maxf (s) < c },
surely expanded using maxh (Pearl, 1984, Thm. 4, p. 79).
objective minimizing search time, note optimal decision state
SE compute heuristic all, since states surely expanded anyway.
Assuming still must choose one heuristics, would choose compute cheaper
heuristic h1 . Another easy case f1 (s) c . states, computing h1 (s) suffices
ensure surely expanded, using perfect tie-breaking rule, expanded
unless must be. h1 cheaper compute h2 , h1 preferred, regardless
heuristic estimate h2 state s.
Let us consider optimal decision states, is, f1 (s) < c
f2 (s) c . fact, enough consider shallowest states; Figure 1,
states part f2 = c contour separates grid-marked line-marked
areas. Since f1 (s) f2 (s) based g(s), h2 (s) > h1 (s), is, h2
accurate state h1 . interested solely reducing state expansions, h2
would obviously right heuristic compute s. However, objective reducing
actual search time, h2 may actually wrong choice might much expensive
compute h1 .
Let us consider effects two alternatives. compute h2 (s),
surely expanded, f2 (s) = c , thus whether expands depends tiebreaking. before, assuming perfect tie-breaking, thus expanded unless
must be. Computing h2 would cost us t2 time.
contrast, compute h1 (s), surely expanded f1 (s) < c . Note
computing h2 computing h2 one descendants s0 clearly sub-optimal
strategy pay cost computing h2 , yet pruning limited search
sub-tree rooted s0 . Therefore, choices really either computing h2 s, computing h1
states sub-tree rooted lie f1 = c contour. Suppose need
expand l complete levels state space reach f1 = c contour. Thus, need
generate order bl states, invest bl t1 time calculating h1 states lie
f1 = c contour.
Considering two options, optimal decision state thus compute h2 iff t2 < bl t1 ,
express differently, l > logb ( tt12 ). special case, heuristics take time
compute, decision rule reduces l > 0, is, optimal choice simply accurate
heuristic state s.
Putting cases together yields decision rule dropt , below, ls
depth go f1 (s) = c :
714

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING



h1 , f1 (s) < c , f2 (s) < c



h , f (s) c
1
1
.
dropt ({h1 , h2 }, s) :=

h1 , f1 (s) < c , f2 (s) c , ls logb ( tt12 )



h , f (s) < c , f (s) c , l > log ( t2 )
2
1
2

b t1
4.2 Decision Rule without Perfect Knowledge
idealized model makes several assumptions, appear problematic
meet practice. examine assumptions closely, needed, suggest
pragmatic compromises.
First, model assumes search space forms tree single goal state,
heuristics question consistent, perfect tie-breaking rule. Although
first assumption hold planning tasks, second assumption satisfied
many state-of-the-art heuristics (Karpas & Domshlak, 2009; Helmert & Domshlak, 2009; Bonet
& Helmert, 2010), third assumption realistic, prevent us using
decision rule suggested model.
idealized model assumes branching factor heuristic computation
times constant across search states. application decision rule planning
practice, deal assumption adopting average branching factor heuristic
computation times, estimated random sample search states.
Finally, decision rule dropt requires unrealistic knowledge heuristic estimates,
well optimal plan cost c depth ls go state f1 (s) = c .
obviously knowledge practice, must use approximation decision
rule.
first approximation make ignore trivial cases require knowledge c ;
cases either surely expanded, h1 enough prune s. Instead, apply
reasoning complicated case states, resulting following decision rule:
(
h1 , ls logb ( tt12 )
drapp1 ({h1 , h2 }, s) :=
.
h2 , ls > logb ( tt21 )
next step somehow estimate depth go ls number layers need
expand tree f1 reaches c . order derive useful decision rule, assume ls
positive correlation h (s) = h2 (s) h1 (s); is, h1 h2 close, ls low,
h1 yields much lower estimate h2 , implying h1 accurate s,
depth go f1 (s) = c large. approximation uses simplest correlation
linear one h (s) ls , hyper-parameter controlling slope.
Recall idealized model, actions unit cost, thus cost-to-go depthto-go same. However, planning tasks, notably, planning tasks 2008
International Planning Competition, feature non-uniform action costs. Therefore, decision rule
converts heuristic estimates cost-to-go heuristic estimates depth-to-go dividing
cost-to-go estimate average action cost. modifying estimate depthto-go, ls , average action cost, denote c. Plugging
715

fiD OMSHLAK , K ARPAS , & ARKOVITCH

decision rule yields:
(
h1 ,
drapp2 ({h1 , h2 }, s) :=
h2 ,

h (s) c logb ( tt12 )
.
h (s) > c logb ( tt21 )

Given b, t1 , t2 , c, quantity c logb (t2 /t1 ) becomes fixed, follows denote
simply threshold .
Note linear correlation h (s) ls occurs simple cases. first
case h1 value remains constant subtree rooted s, is, additive error
h1 increases 1 level s. case, f1 increases 1 expanded level
sub-tree (because h1 remains same, g increases 1), take expanding exactly
h (s) = h2 (s) h1 (s) levels reach f1 = c contour. second case
absolute error h1 remains constant, is, h1 increases 1 level expanded, f1
increases 2. case, need expand h (s)/2 levels. generalized
case estimate h1 increases constant additive factor c, results h (s)/(c+1)
levels expanded.
Furthermore, empirical evidence support conclusion exponential
growth search effort function heuristic error, even assumptions made
model hold. particular, experiments Helmert Roger (2008) IPC benchmarks
heuristics small constant additive errors show number expanded nodes
typically grows exponentially (still small additive) error increases.
Finally, remark decision rule always chooses admissible heuristic,
resulting heuristic estimate always admissible. Thus, even chosen heuristic
correct one according dropt , result loss optimality solution,
possible increase search time.

5. Online Learning Decision Rule
decision rule drapp2 still requires knowledge h1 h2 , use binary
label state. compute value decision rule paying computation
time heuristics, t1 + t2 , and, importantly, use binary classifier predict
value decision rule unknown state. Note use classifier online,
problem solving process, time spent learning classification counted time spent
problem solving. Furthermore, active learning, choose pay label
state, payment computation time. Therefore refer setting active
online learning.
follows, provide general overview selective max procedure, describe
several alternatives components. decision rule states expensive
heuristic h2 computed search state h2 (s) h1 (s) > . decision rule
serves binary target concept, corresponds set states expensive
heuristic h2 significantly accurate cheaper heuristic h1 states where, according model, reduction expanded states computing h2 outweighs extra time
needed compute it. Selective max uses binary classifier predict value decision
rule. several steps building classifier:
716

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

evaluate(s)
hh, conf idencei := CLASSIFY(s, model)
(conf idence > )
return h(s)
else
label := h1
h2 (s) h1 (s) > c logb (t2 /t1 ) label := h2
update model hs, labeli
return max(h1 (s), h2 (s))
Figure 2: selective max state evaluation procedure
1. Training Example Collection: first need collect training examples,
representative entire search space. Several state-space sampling methods discussed
Section 5.1.
2. Labeling Training Examples: training examples collected, first used
estimate average branching factor b, average heuristic computation times t1 t2 ,
average action cost c. b, t1 , t2 , c estimated, use estimate
threshold = c logb (t2 /t1 ) decision rule.
generate label training example calculating h (s) = h2 (s) h1 (s),
comparing decision threshold: h (s) > , label h2 , otherwise
h1 . t1 > t2 simply switch heuristics decision always whether
compute expensive heuristic; default compute cheaper heuristic,
unless classifier says otherwise.
3. Feature Extraction: obtained set training examples, must decide
features characterize example. Since target concept based heuristic values,
features represent information heuristics derived typically
problem description current state.
several feature-construction techniques characterizing states planning tasks
proposed previous literature (Yoon, Fern, & Givan, 2008; de la Rosa, Jimenez, &
Borrajo, 2008), designed inter-problem learning, is, learning
different planning tasks already solved offline. However, approach,
concerned one problem, online setting, thus techniques
applicable. implementation, use simplest features possible, taking
state variable feature. empirical evaluation demonstrates, even elementary
features suffice selective max perform well.
4. Learning: set labeled training examples, represented vector
features, train binary classifier. Several different choices classifier discussed
Section 5.2.
completing steps described above, binary classifier used
predict value decision rule. However, classifier likely perfect accuracy,
717

fiD OMSHLAK , K ARPAS , & ARKOVITCH

consult confidence classifier associates classification. resulting state
evaluation procedure selective max depicted Figure 2. every state evaluated
search algorithm, use classifier decide heuristic compute. classification
confidence exceeds confidence threshold , parameter selective max, indicated
heuristic computed s. Otherwise, conclude enough information make
selective decision s, compute regular maximum h1 (s) h2 (s). However,
use opportunity improve quality prediction states similar s, update
classifier generating label based h2 (s)h1 (s) learning newly labeled example.
decisions dedicate computation time obtain label new example constitute
active part learning procedure. possible update estimates b, t1 , t2 , c,
change threshold accordingly. However, would result concept trying
learn constantly changing phenomenon known concept drift usually affects
learning adversely. Therefore, update threshold .
5.1 State-Space Sampling
initial state-space sample serves two purposes. First, used estimate branching factor
b, heuristic computation times t1 t2 , average action cost c, compute
threshold = c logb (t2 /t1 ), used specify concept. concept specified,
state-space sample provides us set examples classifier initially
trained. Therefore, important initial state-space sample representative
states evaluated search. number states initial sample controlled
parameter N .
One option use first N states search. However, method biased towards
states closer initial state, therefore likely represent search space well. Thus,
discuss three sophisticated state-space sampling procedures, based
performing random walks, probes, initial state. details sampling
procedures vary, probe terminates pre-set depth limit.
first sampling procedure, refer biased probes, uses inverse heuristic
selection bias choosing next state go probe. Specifically, probability
choosing state successor random walk continue proportional
1/ maxh (s). biases sample towards states lower heuristic estimates,
likely expanded search.
second sampling procedure similar first one, except chooses successor
uniformly, thus refer unbiased probes. sampling procedures add
generated states (that is, states along probe well siblings) statespace sample, terminate collecting N training examples. depth limit
random walks sampling schemes, set estimate goal depth;
discuss goal depth estimate later.
third state-space sampling procedure, referred PDB sampling, proposed
Haslum, Botea, Helmert, Bonet, Koenig (2007). procedure uses unbiased probes,
adds last state reached probe state-space sample. depth
probe determined individually, drawing random depth binomial distribution around
estimated goal depth.
718

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Note three sampling procedures rely estimate minimum goal depth.
actions unit cost, minimum goal depth h (s0 ), thus use
heuristic estimate it. evaluation, used twice heuristic estimate initial state,
2 maxh (s0 ), goal depth estimate. However, non-uniform action costs, goal depth
cost longer measured units. seems could divide heuristicbased estimate average action cost c, recall use state-space sample order
obtain estimate estimate c, thus creating circular dependency. Although possible
estimate c taking average cost actions problem description, reason
assume actions equally likely used. Another option modify
state-space sampling procedures, place cost limit, rather depth limit, probe.
However, would pose problem presence 0-cost actions. case, probe
reaches cost limit yet possible 0-cost action apply, clear whether probe
terminate. Therefore, keep using depth-limited probes attempt estimate depth
cheapest goal. compute heuristic estimate initial state, use number
actions heuristic estimate based goal depth estimate.
possible every heuristic, use empirical evaluation monotonically-relaxed plan
heuristic. heuristic, known heuristic (Hoffmann & Nebel, 2001), provide
information: first use heuristic find relaxed plan initial state, use
number actions relaxed plan goal depth estimate.
5.2 Classifier
last decision made choice classifier. Although many classifiers used here,
several requirements must met due particular setup. First, training classification must fast, performed time-constrained problem solving. Second,
classifier must incremental support active learning. achieved allowing online
updates learned model. Finally, classifier provide us meaningful measure
confidence predictions.
several classifiers meet requirements, found Naive Bayes classifier provide
good balance speed accuracy. One note Naive Bayes classifier
assumes strong conditional independence features. Although fully
realistic assumption planning tasks, using SAS+ task formulation contrast classical
STRIPS formulations helps lot: instead many highly dependent binary variables,
much smaller set less dependent ones.
Although, empirical evaluation demonstrate, Naive Bayes appears
suitable classifier use selective max, classifiers used. obvious
choice replacement classifier would different Bayesian classifier. One classifier
AODE (Webb, Boughton, & Wang, 2005), extension Naive Bayes, somewhat relaxes
assumption independence features, typically accurate Naive
Bayes. However, added accuracy comes cost increased training classification time.
Decision trees another popular type classifier allows even faster classification.
decision tree induction algorithms incremental, Incremental Tree Inducer
(ITI) algorithm (Utgoff, Berkman, & Clouse, 1997) supports incremental updating decision trees
tree restructuring, freely available implementation C. evaluation, used
ITI incremental mode, incorporated every example tree immediately,
719

fiD OMSHLAK , K ARPAS , & ARKOVITCH

tree likely used many classifications pairs consecutive updates training
examples active learning. classification confidence ITI classifier obtained
frequency examples leaf node classification came.
different family possible classifiers k-Nearest Neighbors (kNN) (Cover & Hart, 1967).
order use kNN, need distance metric examples, which, features,
simply states. choice features, opt simplicity use Euclidean distance
metric. kNN enjoys fast learning time suffers slow classification time.
classification confidence obtained simple (unweighted) vote k nearest neighbors.
Another question related choice classifier feature selection. planning tasks,
number variables, accordingly, features, 2000 (for example, task 35
AIRPORT domain 2558 variables). performance Naive Bayes kNN likely
improved using feature selection, poses problem initial sample considered.
Since feature selection done right initial sample obtained,
based initial sample. could cause problem since features might appear
irrelevant according initial sample, yet turn relevant active learning
used low-confidence states encountered. Therefore, use feature selection
empirical evaluation selective max.
5.3 Extension Multiple Heuristics
point, discussed choose heuristic compute state
two heuristics choose from. given two heuristics, decision
rule presented Section 4 inapplicable, extending handle two heuristics
straightforward. However, extending selective max use two heuristics straightforward simply compare heuristics pair-wise manner, use voting rule choose
heuristic compute.
many possible voting rules, go simplest one, compares
every pair heuristics, chooses winner vote, weighted confidence pairwise decision. overall winner simply heuristic highest total confidence
pairwise comparisons, ties broken favor cheaper-to-compute heuristic. Although
requires quadratic number classifiers, training classification time (at least Naive
Bayes) appear much lower overall time spent heuristic computations, thus
overhead induced learning classification likely remain relatively low reasonable
heuristic ensembles.

6. Experimental Evaluation
evaluate selective max empirically, implemented top open-source Fast Downward
planner (Helmert, 2006). empirical evaluation divided three parts. First, examine performance selective max using last International Planning Competition, IPC-2011,
benchmark. Selective max runner-up ex-aequo IPC-2011, tying 2nd place
version Fast Downward using abstraction merge-and-shrink heuristic (Nissim, Hoffmann, & Helmert, 2011), losing sequential portfolio combining heuristics used
runners-up (Helmert, Roger, & Karpas, 2011). Second, present series controlled parametric
experiments, examine behavior selective max different settings. Finally,
720

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Parameter


N
Sampling method
Classifier

Default value
1
0.6
1000
Biased probes
Naive Bayes

Meaning
heuristic difference bias
confidence threshold
initial sample size
state-space sampling method
classifier type

Table 1: Parameters selmax entry IPC-2011.
compare selective max simulated sequential portfolio, using heuristics selective
max.
6.1 Performance Evaluation: Results IPC-2011
IPC-2011 experiments (Garca-Olaya et al., 2011) run IPC organizers,
machines, time limit 30 minutes memory limit 6 GB per planning task.
competition included new domains, none participants seen before, thus
precluding participants using offline learning approaches.
Although many planners participated sequential optimal track IPC-2011, report
results relevant selective max. selective max entry IPC-2011 called selmax,
consisted selective max uniform action cost partitioning version hLA (Karpas &
Domshlak, 2009) hLM-CUT (Helmert & Domshlak, 2009) heuristics. parameters used
selective max IPC-2011 reported Table 1. Additionally, heuristics selmax used
entered individually BJOLP (hLA ) lmcut (hLM-CUT ), report results three
planners. comparison selective max regular maximum hLA hLM-CUT
would interesting, entry IPC-2011, thus report it.
controlled experiments, compare selective max regular maximum, well
baseline combination methods.
Figure 3 shows anytime profile three planners IPC-2011 tasks, plotting number tasks solved different timeouts, time limit 30 minutes. Additionally, Table
2 shows number tasks solved domain IPC-2011, 30 minutes, includes
number problems solved winner, Fast Downward Stone Soup 1 (FDSS-1), reference.
results show, selective max solves problems individual heuristics
uses. Furthermore, anytime profile selective max dominates heuristics,
range 214 seconds full 30 minute timeout. behavior anytime plot
shorter timeouts due overhead selective max, consists obtaining initial statespace sample, well learning classification. However, appears selective max quickly
compensates relatively slow start.
6.2 Controlled Experiments
series controlled experiments, attempted evaluate impact different parameters
selective max. controlled following independent variables:
Heuristics: used three state-of-the-art admissible heuristics: hLA (Karpas & Domshlak,
2009), hLM-CUT (Helmert & Domshlak, 2009), hLM-CUT+ (Bonet & Helmert, 2010). None
721

fiD OMSHLAK , K ARPAS , & ARKOVITCH

160

Solved Instances

140

120

100

80

BJOLP
lmcut
selmax

60
0

200

400

600

800
1000
Timeout (seconds)

1200

1400

1600

1800

Figure 3: IPC-2011 anytime performance. line shows number problems IPC-2011
solved BJOLP, lmcut, selmax planners, respectively, different timeouts.
Domain
barman
elevators
floortile
nomystery
openstacks
parcprinter
parking
pegsol
scanalyzer
sokoban
tidybot
transport
visitall
woodworking
TOTAL

BJOLP
4
14
2
20
14
11
3
17
6
20
14
7
10
9
151

lmcut
4
18
7
15
16
13
2
18
12
20
14
6
10
12
167

selmax
4
18
7
20
14
13
4
17
10
20
14
6
10
12
169

FDSS-1
4
18
7
20
16
14
7
19
14
20
14
7
13
12
185

Table 2: Number planning tasks solved IPC 2011 domain BJOLP, lmcut,
selmax planners. best result 3 planners bold. number problems
solved Fast Downward Stone Soup 1 (FDSS-1) domain included
reference.

722

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

base heuristics yields better search performance others across planning
domains. heuristics, hLA typically fastest compute least accurate,
hLM-CUT expensive compute accurate, hLM-CUT+ expensive compute accurate.1 data gathered experiments,
hLM-CUT takes average 4.5 time per state hLA , hLM-CUT+ takes 53 time
per state hLA . evaluate selective max possible subsets two
three heuristics.
admissible heuristics SAS+ planning competitive
three (for example, Helmert, Haslum, & Hoffmann, 2007; Nissim et al., 2011; Katz &
Domshlak, 2010), based expensive offline preprocessing, followed fast
online per-state computation. contrast, hLA , hLM-CUT hLM-CUT+ perform
computation online, thus better exploited selective max.
Additionally, empirically examine effectiveness selective max deciding whether
compute heuristic value all. done combining accurate heuristic,
hLM-CUT+ , blind heuristic.
Heuristic difference bias : hyper-parameter controls tradeoff computation time heuristic accuracy. Setting = 0 sets threshold 0, forcing decision
rule always choose accurate heuristic. Increasing increases threshold, forcing decision rule choose accurate heuristic h2 value much higher
h1 . evaluate selective max values 0.1, 0.5, 1, 1.5, 2, 3, 4, 5.
Confidence threshold : confidence threshold controls active learning part selective max. Setting = 0.5 turns active learning completely, chosen heuristic
always comes confidence least 0.5. Setting = 1 would mean using active learning almost always, essentially reducing selective max regular point-wise maximization.
evaluate selective max values 0.51, 0.6, 0.7, 0.8, 0.9, 0.99.
Initial sample size N : initial sample size N important parameter,
used train initial classifier active learning done,
source estimates branching factor, average action cost, heuristic computation
times. thus affects threshold : Increasing N increases accuracy initial
classifier various aforementioned estimates, increases preprocessing
time. evaluate selective max values N 10, 100, 1000.
Sampling method: sampling method used obtain initial state-space sample important affects initial sample, thus accuracy threshold
initial classifier. evaluate selective max three different sampling methods,
P
described Section 5.1: biased probes (selPh ), unbiased probes (selU
h ), sampling
method Haslum et al. (2007) (selPDB
h ).
Classifier: choice classifier important. Naive Bayes classifier comB
bines fast learning classification (selN
h ). sophisticated variant Naive
Bayes called AODE (Webb et al., 2005) considered (selAODE
). AODE
h
1. course, three heuristics computable polynomial time SAS+ description planning task.

723

fiD OMSHLAK , K ARPAS , & ARKOVITCH

Parameter
Heuristics


N
Sampling method
Classifier

Default value
hLA / hLM-CUT
1
0.6
100
PDB (Haslum et al., 2007)
Naive Bayes

Meaning
heuristics used
heuristic difference bias
confidence threshold
initial sample size
state-space sampling method
classifier type

Table 3: Default parameters selh .
accurate Naive Bayes, higher classification learning times, well increased memory overhead. Another possible choice using incremental decision trees (Utgoff et al., 1997), offer even faster classification, expensive learning

tree structure needs changed (selIT
h ). consider kNN classifiers (Cover & Hart,
1967), offer faster learning Naive Bayes, usually expensive classificaN
tion, especially k grows larger (selkN
, k = 3, 5).
h
Table 3 describes default values independent variables.
subsequent experiments, vary one independent variables, keeping rest default
values. experiments, search planning task instance limited 30
minutes2 3 GB memory. search times include time needed translating
planning task PDDL SAS+ building Fast Downward data structures,
common planners, tangential issues considered study. search
times include learning classification time selective max.
Heuristics
begin varying set heuristics use. every possible choice two
heuristics uniform action cost partitioning version hLA (which simply refer
hLA ), hLM-CUT hLM-CUT+ , compare selective max methods heuristic
combination, well individual heuristics. compare selective max (selh )
regular maximum (maxh ), well planner chooses heuristic compute
state randomly (rndh ). clear whether random choice favor
expensive accurate heuristic cheaper less accurate one, simply use
uniform random choice.
experiment conducted 31 domains conditional effects axioms
(which none heuristics used support) International Planning Competitions
19982008. domains vary difficulty number tasks, normalize
score planner domain 0 1. Normalizing number
problems domain good idea, always possible generate number
effectively unsolvable problems domain, fraction solved problems
approach zero. Therefore, normalize number problems solved domain
number problems domain solved least one planners.
measure normalized coverage undesirable property introducing
2. search given single core 3GHz Intel E8400 CPU machine.

724

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Heuristic

hLA

hLM-CUT

hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost

0.89 (175)
0.98 (345)
0.80 (136)

0.83 (136)
0.96 (343)
0.94 (160)

0.81 (132)
0.94 (336)
0.86 (146)

TOTAL

0.91 (656)

0.92 (639)

0.89 (614)

(a) Individual Heuristics
Domains
High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

maxh
0.90 (164)
0.97 (345)
0.92 (156)
0.94 (665)

rndh
0.74 (123)
0.95 (342)
0.79 (138)
0.85 (603)

selh
0.93 (174)
0.97 (346)
0.93 (157)
0.95 (677)

hLA / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

0.84 (149)
0.93 (335)
0.85 (144)
0.89 (628)

0.68 (115)
0.88 (327)
0.71 (122)
0.78 (564)

0.90 (164)
0.96 (342)
0.86 (145)
0.92 (651)

hLM-CUT / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

0.80 (131)
0.94 (336)
0.87 (147)
0.89 (614)

0.75 (122)
0.93 (335)
0.86 (145)
0.87 (602)

0.80 (130)
0.97 (344)
0.93 (156)
0.91 (630)

hLA / hLM-CUT / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

0.84 (149)
0.93 (335)
0.85 (144)
0.89 (628)

0.69 (116)
0.90 (332)
0.75 (130)
0.81 (578)

0.87 (154)
0.97 (345)
0.89 (150)
0.92 (649)

Heuristics
hLA / hLM-CUT

(b) Combinations two heuristics

Table 4: Average normalized coverage, total coverage parentheses, broken groups
domains unit cost actions high variance coverage, domains unit cost
actions low variance coverage, domains non-uniform action costs. Table
(a) shows results individual heuristics, table (b) shows results
maximum (maxh ), random choice (rndh ), selective max (selh ) combinations
set heuristics listed major row.

new planner could change normalized coverage planners, believe
best reflects performance nonetheless. overall performance measure, list
average normalized coverage score across domains. Using normalized coverage means
domains equal weight aggregate score. Additionally, list domain
number problems solved planner (in parentheses next domain
name), planner list number problems solved parentheses.
Tables 4 5 summarize results experiment. divided domains
experiment 3 sets: domains non-uniform action costs, domains unit action
costs exhibited high variance number problems solved different
725

fiD OMSHLAK , K ARPAS , & ARKOVITCH

Heuristics

Domains

hLA

hLM-CUT

hLA / hLM-CUT

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

3.23
3.48
13.23
4.82

2.8
1.14
1.01
1.4

hLA / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

4.01
4.55
13.66
5.85

hLM-CUT / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

hLA / hLM-CUT / hLM-CUT+

hLM-CUT+

maxh

rndh

selh

1.0
1.0
1.0
1.0

3.88
2.14
3.99
2.93

1.46
1.2
1.17
1.25

1.77
1.01
1.0
1.16

1.0
1.0
1.0
1.0

3.17
2.38
3.85
2.9

2.16
1.85
1.72
1.89

2.29
1.58
1.32
1.66

1.01
1.01
1.03
1.01

1.0
1.0
1.0
1.0

1.7
1.29
1.18
1.35

1.24
1.19
1.16
1.2

High variance unit cost
Low variance unit cost
Non-uniform cost

4.06
4.65
15.2

3.81
1.59
1.37

1.78
1.02
1.03

1.0
1.0
1.0

3.61
2.05
2.74

2.1
1.57
1.49

TOTAL

6.1

1.91

1.18

1.0

2.56

1.67

Table 5: Geometric mean ratio expansions relative maxh , broken groups domains unit cost actions high variance coverage, domains unit cost actions
low variance coverage, domains non-uniform action costs.

planners, domains unit action costs exhibited low variance number
problems solved different planners. make distinction conducted
following experiments, examine effects parameters selective
max, unit cost action domains exhibited high variance. Tables 4 5
summarize results three sets domains, well domains combined.
Detailed, per-domain results relegated Appendix A.
Table 4 lists normalized coverage score, averaged across domains, total number
problems solved parentheses. Table 4a lists individual heuristic,
Table 4b every combination method every set two heuristics. Table 5 shows
accurate heuristic combination methods is. Since, given set base
heuristics, maxh accurate heuristic possible, accuracy evaluated relative
maxh . evaluate heuristics accuracy task number states expanded
using heuristic, divided number states expanded using maxh .
compute geometric mean domain tasks solved planners
accuracy ratio, list geometric mean numbers. row lists
results combination two three heuristics; combinations two heuristics,
leave cell representing heuristic combination empty.
Looking results individual heuristics first, see accurate heuristic
(hLM-CUT+ ) well overall, least accurate heuristic (hLA ) solved
tasks total, hLM-CUT wins terms normalized coverage. However, looking
results individual domains, see best heuristic use varies, indicating
combining different heuristics could indeed practical value.
turn attention empirical results combinations possible subsets
two heuristics. results clearly demonstrate one heuristic
used, selective max always better regular maximum random choice, terms
normalized coverage absolute number problems solved. Furthermore, poor
performance rndh , coverage accuracy, demonstrates decision rule
726

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

700

650

Solved Instances

600

550

500

450

400
maxh

350

rndh
selh

300
200

400

600

800
1000
Timeout (seconds)

1200

1400

1600

1800

Figure 4: hLA / hLM-CUT / hLM-CUT+ anytime profile. line shows number problems
IPC 1998 2006 solved maximum (maxh ), random choice (rndh ), selective
max (selh ) combination methods hLA , hLM-CUT , hLM-CUT+ heuristics,
different timeouts.

classifier used selective max important success, computing one
heuristic state randomly insufficient, say least.
compared individual heuristics, selective max least well
individual heuristics uses, combinations except hLM-CUT hLM-CUT+ .
likely hLM-CUT hLM-CUT+ based similar procedure,
thus heuristic estimates highly correlated. see hinders selective max,
consider extreme case two heuristics correlation 1.0 (that is, yield
heuristic values), selective max offer benefit. Finally, remark
best planner experiment selective max combination hLA hLM-CUT .
results based 30 minute time limit, which, commonly used
IPC, arbitrary, number tasks solved 30 minutes tell complete
tale. Here, examine anytime profile different heuristic combination methods,
plotting number tasks solved different timeouts, timeout 30 minutes.
Figure 4 shows plot three combination methods three heuristics used.
figure shows, advantage selh baseline combination methods even
greater shorter timeouts. indicates advantage selh maxh even
727

fiD OMSHLAK , K ARPAS , & ARKOVITCH

Heuristics
hLA / hLM-CUT

Overhead
12%

hLA / hLM-CUT+

15%

hLM-CUT / hLM-CUT+

9%

hLA / hLM-CUT / hLM-CUT+

10%

Table 6: Selective max overhead. row lists average percentage time spent learning
classification, total time taken selective max, set heuristics.

greater evident results 30 minutes, selh indeed effective
minimizing search time. Since anytime plots combinations pairs heuristics
similar, omit sake brevity.
Finally, present overhead statistics using selective max proportion time spent
learning classification, including time spent obtaining initial state-space sample, total solution time. Table 6 presents average overhead selective max
combinations two heuristics. Detailed, per-domain results
presented Table 18 Appendix A. results show, selective max incur noticeable overhead, still relatively low. worth mentioning overhead
varies significantly different domains.
performed empirical evaluation using selective max accurate heuristic
alongside blind heuristic. blind heuristic returns 0 goal states, cost
cheapest action non-goal states. experiment, chose accurate
heuristic, hLM-CUT+ . compare performance using hLM-CUT+ alone,
using selective max hLM-CUT+ blind heuristic. blind heuristic returns
constant value non-goal states, decision rule selective max uses combine
heuristic h blind heuristic hb simply h(s) + hb , is, compute h
predicted value h greater constant threshold. Recall that,
h(s) + g(s) < c , computing h simply waste time, pruned.
Therefore, makes sense compute h(s) h(s) c g(s). Note
threshold computing h depends g(s), thus constant. shows
constant threshold computing h(s) best possible decision rule. Unfortunately,
selective max decision rule based approximation fails capture subtleties
case.
Table 7 shows normalized coverage using hLM-CUT+ , using selective max
hLM-CUT+ blind heuristic. results show, selective max little effect
domains, though harm performance some, one domain OPENSTACKS
actually performs better single heuristic. Table 8 shows average expansions ratio,
using number states expanded hLM-CUT+ baseline; note using blind
heuristic never increases heuristic accuracy. results show, selective max chooses
use blind heuristic quite often, expanding average twice many states
hLM-CUT+ alone.
728

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

coverage

hLM-CUT+

selh

airport (31)
freecell (13)
logistics00 (17)
mprime (24)
mystery (17)
pipesworld-tankage (9)
satellite (9)
zenotravel (12)

1.00 (31)
1.00 (13)
1.00 (17)
1.00 (24)
1.00 (17)
1.00 (9)
1.00 (9)
1.00 (12)

1.00 (31)
1.00 (13)
1.00 (17)
1.00 (24)
1.00 (17)
1.00 (9)
1.00 (9)
1.00 (12)

blocks (27)
depot (7)
driverlog (14)
grid (2)
gripper (6)
logistics98 (6)
miconic (140)
pathways (5)
pipesworld-notankage (17)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (9)

1.00 (27)
1.00 (7)
1.00 (14)
1.00 (2)
1.00 (6)
1.00 (6)
1.00 (140)
1.00 (5)
1.00 (17)
1.00 (48)
1.00 (7)
1.00 (27)
1.00 (15)
1.00 (6)
1.00 (9)

1.00 (27)
1.00 (7)
1.00 (14)
1.00 (2)
1.00 (6)
1.00 (6)
0.86 (121)
1.00 (5)
1.00 (17)
1.00 (48)
1.00 (7)
1.00 (27)
0.93 (14)
1.00 (6)
1.00 (9)

elevators-opt08-strips (18)
openstacks-opt08-strips (19)
parcprinter-08-strips (21)
pegsol-08-strips (27)
scanalyzer-08-strips (13)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (14)

1.00 (18)
0.89 (17)
1.00 (21)
1.00 (27)
1.00 (13)
1.00 (25)
1.00 (11)
1.00 (14)

0.83 (15)
1.00 (19)
1.00 (21)
1.00 (27)
0.77 (10)
1.00 (25)
1.00 (11)
0.93 (13)

TOTAL

1.00 (614)

0.98 (589)

Table 7: Normalized coverage hLM-CUT+ selective max combining hLM-CUT+ blind
heuristic. Domains grouped domains unit cost actions high variance
coverage, domains unit cost actions low variance coverage, domains
non-uniform action costs, respectively.

729

fiD OMSHLAK , K ARPAS , & ARKOVITCH

expansions

hLM-CUT+

selh

airport (31)
freecell (13)
logistics00 (17)
mprime (24)
mystery (18)
pipesworld-tankage (9)
satellite (9)
zenotravel (12)

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.0
3.13
1.02
1.22
3.2
4.23
3.11
2.37

blocks (27)
depot (7)
driverlog (14)
grid (2)
gripper (6)
logistics98 (6)
miconic (121)
pathways (5)
pipesworld-notankage (17)
psr-small (48)
rovers (7)
schedule (27)
storage (14)
tpp (6)
trucks-strips (9)

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.92
1.36
1.15
7.67
1.0
1.18
14.24
1.0
1.27
2.12
1.56
1.21
5.11
1.6
1.01

elevators-opt08-strips (15)
openstacks-opt08-strips (17)
parcprinter-08-strips (21)
pegsol-08-strips (27)
scanalyzer-08-strips (10)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (13)

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

13.41
1.08
1.24
1.01
4.87
1.0
5.86
46.97

GEOMETRIC MEAN

1.0

2.3

Table 8: Average ratio expanded states baseline hLM-CUT+ selective max
combining hLM-CUT+ blind heuristic. Domains grouped domains
unit cost actions high variance coverage, domains unit cost actions low
variance coverage, domains non-uniform action costs, respectively.

730

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

experiments varied heuristics selective max uses. following
experiments, fix set heuristics, examine impact parameters selective max performance. still need evaluate 20 different configurations selective
max, focus eight selected domains: AIRPORT, FREECELL, LOGISTICS 00, MPRIME, MYS TERY , PIPESWORLD - TANKAGE, SATELLITE , ZENOTRAVEL. eight domains
highest observed variance number tasks solved across different planners, unit
action cost domains used. domains chosen order reduce computation time
required experiments manageable quantity. excluded domains non-uniform
action costs, use different method estimating goal depth state-space
sampling method, one parameters examine. Below, focus one parameter
selective max time, present total number tasks solved eight chosen domains,
different values parameter. Detailed, per-domain results parameter appear
Appendix A.
hyper-parameter
Figure 5a plots total number problems solved, different values .
results show, selective max fairly robust respect value , unless large
value chosen, making difficult selective max choose accurate
heuristic.
Detailed, per-domain results appear Table 19 Appendix A, well Figure 6.
results show complex picture, seems cutoff value
domain, increasing past value impairs performance. one exception
PIPESWORLD - TANKAGE domain, setting = 5 helps.
confidence threshold
Figure 5b plots total number problems solved, different values , Detailed,
per-domain results appear Table 20 Appendix A. results indicate selective
max robust values , unless set low value, causing selective max
behave regular point-wise maximum.
initial sample size N
Figure 5c plots total number problems solved different values N .
x-axis logscale. Detailed, per-domain results appear Table 21 Appendix A.
results show, default value N = 100 best (of three values tried), although
selective max still fairly robust respect choice parameter.
sampling method
Figure 7 shows total number problems solved using different methods initial
state-space sampling. Detailed, per-domain results appear Table 22 Appendix A.
results demonstrate, choice sampling method notably affect performance
selective max. However, detailed results show, effect evident FREE CELL domain. remark default sampling method, PDB, performs worse
others. Indeed using probe based sampling methods, selective max outperforms
using hLA alone. However, difference due FREECELL domain,
state certainty would generalize across domains.
731

fiSolved Instances

OMSHLAK , K ARPAS , & ARKOVITCH

174
172
170
168
166
0

0.5

1

1.5

2

2.5


3

3.5

4

4.5

5

0.8

0.85

0.9

0.95

1

Solved Instances

(a) Hyper-parameter

174
172
170
168
166
0.5

0.55

0.6

0.65

0.7

0.75


Solved Instances

(b) Confidence threshold

174
172
170
168
166
10

100


1000

(c) Initial Sample Size N
Figure 5: Number problems solved selective max different values (a) hyperparameter (b) confidence threshold , (c) initial sample size N .

732

fiSolved Instances

NLINE PEEDUP L EARNING PTIMAL P LANNING

50
45
40
35
30
25
20
15
10
5

airport
freecell
logistics00
mprime
mystery
pw-tankage
satellite
zenotravel
0

1

2

3

4

5



Figure 6: Number problems solved selective domain different values .

180
160

Solved Instances

140
120
100
80
60
40
20
0

PDB
174

Probe
178
Sampling Method

UnbiasedProbe
180

Figure 7: Number problems solved selective max different sampling methods.

733

fiD OMSHLAK , K ARPAS , & ARKOVITCH

180
160

Solved Instances

140
120
100
80
60
40
20
0
NB
174

AODE
168

ITI
156
Classifier

3NN
158

5NN
161

Figure 8: Number problems solved selective max different classifiers.
classifier
Figure 8 shows total number problems solved using different classifiers. Detailed,
per-domain results appear Table 23 Appendix A. Naive Bayes appears best
classifier use selective max, although AODE performs quite well. Even though
kNN enjoys fast learning, classifier used mostly classification, expected,
kNN well. However, increased accuracy k = 5 seems pay
faster classification k = 3.
6.3 Comparison Sequential Portfolios
Sequential portfolio solvers optimal planning another approach exploiting merits
different heuristic functions, successful practice, Fast Downward
Stone Soup sequential portfolio (Helmert et al., 2011) winning sequential optimal track IPC2011. sequential portfolio utilizes different solvers running sequentially, prespecified time limit. one solver fails find solution allotted time limit, sequential
portfolio terminates it, moves next solver. However, sequential portfolio solver
needs know time allowance problem trying solve beforehand, setting known
contract anytime (Russell & Zilberstein, 1991). contrast, selective max used
interruptible anytime manner, time limit need known advance.
Here, compare selective max sequential portfolios heuristics.
exact time took search using heuristic alone solve problem,
determine whether sequential portfolio assigns heuristic time limit able
solve problem. Using data, simulate results two types sequential portfolio
planners. first setting, assume time limit known advance, simulate
results contract portfolio giving equal share time heuristics. second setting,
simulate interruptible anytime portfolio using binary exponential backoff time limits: starting
734

fi700

700

650

650
Solved Instances

Solved Instances

NLINE PEEDUP L EARNING PTIMAL P LANNING

600
550
500

selh
portctr

450

600
550
500

selh
portctr

450

portint

portint

400

400
200

400

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

200

700

700

650

650

600
550
500

selh
portctr

450

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

hLA / hLM-CUT+
(b)

Solved Instances

Solved Instances

hLA / hLM-CUT
(a)

400

600
550
500

selh
portctr

450

portint

portint

400

400
200

400

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

200

hLM-CUT / hLM-CUT+
(c)

400

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

hLA / hLM-CUT / hLM-CUT+
(d)

Figure 9: Anytime profiles sequential portfolios selective max. plot shows number problems solved selective max (selh ), simulated contract anytime portfolio
(portctr ), simulated interruptible portfolio (portint ) using (a) hLA hLM-CUT (b)
hLA hLM-CUT+ (c) hLM-CUT hLM-CUT+ , (d) hLA , hLM-CUT , hLM-CUT+ .

time limit 1 second heuristic, increase time limit factor 2 none
heuristics able guide solve planning problem. several possible
orderings heuristics here, use de facto best ordering problem. denote
contract anytime portfolio portctr , interruptible anytime portfolio portint .
Figure 9 shows number problems solved different time limits selective max,
contract anytime sequential portfolio, interruptible anytime sequential portfolio.
results show, contract anytime sequential portfolio almost always outperforms selective
max. hand, sequential portfolio know time limit advance,
performance deteriorates significantly. best heuristic combination selective max, hLA
hLM-CUT , outperforms interruptible anytime portfolio using heuristics,
735

fiD OMSHLAK , K ARPAS , & ARKOVITCH

selective max combination hLM-CUT hLM-CUT+ . combinations heuristics,
interruptible anytime portfolio performs better selective max.

7. Discussion
Learning planning active field since early days planning (Fikes, Hart,
& Nilsson, 1972), recently receiving growing attention community. However, despite
early work (Rendell, 1983), relatively little work dealt learning state-space search
guided distance-estimating heuristics, one prominent approaches planning
days. works direction devoted learning macro-actions (see, example,
Finkelstein & Markovitch, 1998; Botea, Enzenberger, Muller, & Schaeffer, 2005; Coles & Smith,
2007). Recently, learning heuristic search planning received attention: Yoon et al.
(2008) suggested learning (inadmissible) heuristic functions based upon features extracted
relaxed plans. Arfaee, Zilles, Holte (2010) attempted learn almost admissible heuristic
estimate using neural network. Perhaps closely related work Thayer,
Dionne, Ruml (2011), learn correct errors heuristic estimates online. Thayer et al. attempt improve accuracy single given heuristic, selective max attempts choose one
several given heuristics state. two works differ technically point. importantly, however, none aforementioned approaches guarantee resulting heuristic
admissible, thus optimal solution found. contrast, focus optimal planning, aware previous work deals learning optimal
heuristic search.
experimental evaluation demonstrates selective max effective method
combining arbitrary admissible heuristics baseline point-wise maximization. advantageous selective maxs ability exploit pairs heuristics, one guaranteed always
least accurate other. example, hLA heuristic used two action
cost partitioning schemes: uniform optimal (Karpas & Domshlak, 2009). heuristic induced
optimal action cost partitioning least accurate one induced uniform action
cost partitioning, takes much longer compute. Selective max might used learn
worth spending extra time compute optimal cost partitioning, not.
contrast, max-based combination two heuristics would simply waste time spent
computing uniform action cost partitioning.
controlled parametric experiments demonstrate right choice classifier
sampling method initial state-space sample important. parameters
selective max appear affect performance much, long set reasonable
values. implies selective max could improved using faster, accurate, classifiers,
developing sampling methods represent state-space well.
Finally, remark Fast Downward Autotune entry sequential optimal track
2011 edition International Planning Competition, used ParamILS (Hutter, Hoos,
Leyton-Brown, & Stutzle, 2009) choose best configuration Fast Downward planner,
chose use selective-max combine hLM-CUT hmax (Bonet, Loerincs, & Geffner, 1997).
provides evidence selective max practically valuable method combining
heuristics optimal planning.
736

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

coverage

hLA

hLM-CUT

hLM-CUT+

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

TOTAL

0.91 (656)

0.92 (639)

0.89 (614)

Table 9: Detailed per-domain results individual heuristic. Normalized coverage
shown, number problems solved shown parentheses. Domains grouped
domains unit cost actions high variance coverage, domains unit
cost actions low variance coverage, domains non-uniform action costs,
respectively.

Acknowledgments
work partly supported Israel Science Foundation (ISF) grant 1045/12.

Appendix A. Detailed Results Empirical Evaluation
appendix, present detailed per-domain, results experiments described Section 6.
Table 9 shows normalized coverage number problems solved domain,
individual heuristics. normalized coverage score planner X domain number
problems domain solved planner X, divided number problems domain
solved least one planner. Tables 10 17 give results combinations two
heuristics. Tables 10, 12, 14, 16 list normalized coverage individual heuristics used,
combination using selective max (selh ), regular maximum (maxh ), random choice
heuristic state (rndh ) 30 minutes. Tables 11, 13, 15, 17 give geometric
mean ratio expanded states relative maxh domain, problems solved
configurations. number tasks solved planners listed parentheses next
domain. final row gives geometric mean geometric means domain.
737

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

hLA

hLM-CUT

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.91 (30)
0.71 (41)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.85 (28)
0.28 (16)
0.95 (20)
0.75 (18)
0.76 (13)
0.85 (11)
0.70 (7)
0.77 (10)

0.91 (30)
0.84 (49)
1.00 (21)
1.00 (24)
1.00 (17)
0.92 (12)
0.80 (8)
1.00 (13)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
0.80 (4)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

1.00 (22)
0.90 (18)
0.82 (18)
0.96 (27)
0.94 (15)
0.97 (29)
0.92 (11)
0.84 (16)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.44 (7)
1.00 (30)
0.92 (11)
0.68 (13)

1.00 (22)
0.90 (18)
0.82 (18)
0.96 (27)
0.94 (15)
0.97 (29)
0.92 (11)
0.89 (17)

TOTAL

0.91 (656)

0.92 (639)

0.94 (665)

0.85 (603)

0.95 (677)

Table 10: Detailed per-domain normalized coverage using hLA hLM-CUT . line shows
normalized coverage domain, number problems solved shown
parentheses. Domains grouped domains unit cost actions high variance
coverage, domains unit cost actions low variance coverage, domains
non-uniform action costs, respectively.

738

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

expansions

hLA

hLM-CUT

maxh

rndh

selh

airport (28)
freecell (15)
logistics00 (20)
mprime (18)
mystery (14)
pipesworld-tankage (11)
satellite (7)
zenotravel (10)

2.88
1.01
1.0
6.34
7.9
1.61
6.27
7.98

1.12
529.61
1.0
1.89
1.15
2.35
1.26
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.61
116.96
1.0
4.2
5.19
1.62
2.32
3.3

2.2
2.14
1.0
1.52
1.17
1.12
1.09
2.02

blocks (27)
depot (7)
driverlog (13)
grid (2)
gripper (7)
logistics98 (6)
miconic (141)
pathways (4)
pipesworld-notankage (17)
psr-small (49)
rovers (7)
schedule (30)
storage (15)
tpp (6)
trucks-strips (9)

7.4
3.45
7.2
2.15
1.0
7.74
1.0
39.65
2.01
1.27
2.18
1.15
2.16
1.74
46.11

1.0
1.32
1.09
1.73
1.04
1.0
1.0
1.0
2.16
1.0
1.31
1.0
1.0
1.0
1.02

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

2.2
1.91
2.89
1.57
1.02
2.69
1.0
17.91
1.97
1.11
1.77
1.03
1.45
1.42
12.12

1.61
1.3
1.24
1.83
1.0
1.08
1.0
1.0
1.36
1.15
1.09
1.15
1.56
1.0
1.01

elevators-opt08-strips (17)
openstacks-opt08-strips (18)
parcprinter-08-strips (15)
pegsol-08-strips (27)
scanalyzer-08-strips (7)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (12)

21.51
1.17
24.13
3.72
69.2
15.74
12.09
31.6

1.03
1.0
1.0
1.01
1.0
1.07
1.01
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

5.99
1.03
9.34
1.8
21.47
1.33
3.79
5.68

1.37
1.15
1.0
1.01
1.14
1.04
1.44
1.28

GEOMETRIC MEAN

4.82

1.4

1.0

2.93

1.25

Table 11: Detailed per-domain expansions relative maxh using hLA hLM-CUT . row
shows geometric mean ratio expanded nodes relative maxh . Domains
grouped domains unit cost actions high variance coverage, domains
unit cost actions low variance coverage, domains non-uniform action
costs, respectively.

739

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

hLA

hLM-CUT+

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.94 (31)
0.53 (31)
0.76 (16)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.85 (28)
0.26 (15)
0.95 (20)
0.67 (16)
0.71 (12)
0.62 (8)
0.70 (7)
0.69 (9)

0.91 (30)
0.71 (41)
1.00 (21)
1.00 (24)
1.00 (17)
0.69 (9)
1.00 (10)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.71 (5)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.93 (26)
0.86 (6)
0.93 (13)
0.67 (2)
0.86 (6)
0.83 (5)
0.99 (140)
0.80 (4)
0.83 (15)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.70 (7)

0.93 (26)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.82 (18)
0.80 (16)
0.95 (21)
0.96 (27)
0.81 (13)
0.77 (23)
0.92 (11)
0.79 (15)

0.59 (13)
0.85 (17)
0.55 (12)
0.96 (27)
0.38 (6)
0.83 (25)
0.92 (11)
0.58 (11)

0.73 (16)
0.85 (17)
1.00 (22)
0.96 (27)
0.81 (13)
0.80 (24)
0.92 (11)
0.79 (15)

TOTAL

0.91 (656)

0.89 (614)

0.89 (628)

0.78 (564)

0.92 (651)

Table 12: Detailed per-domain normalized coverage using hLA hLM-CUT+ . line shows
normalized coverage domain, number problems solved shown
parentheses. Domains grouped domains unit cost actions high variance
coverage, domains unit cost actions low variance coverage, domains
non-uniform action costs, respectively.

740

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

expansions

hLA

hLM-CUT+

maxh

rndh

selh

airport (28)
freecell (13)
logistics00 (16)
mprime (16)
mystery (13)
pipesworld-tankage (8)
satellite (7)
zenotravel (9)

3.05
1.22
1.0
8.45
7.76
2.17
19.26
6.62

1.0
47.57
1.0
1.23
1.11
1.42
1.03
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.43
10.54
1.0
5.2
4.77
1.48
5.94
3.09

2.81
2.05
1.0
1.57
1.7
1.86
4.12
4.04

blocks (26)
depot (6)
driverlog (13)
grid (2)
gripper (5)
logistics98 (5)
miconic (140)
pathways (4)
pipesworld-notankage (15)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (7)

6.97
21.8
11.11
5.04
1.0
6.1
1.0
40.56
3.08
1.31
2.75
1.09
2.29
2.72
46.09

1.0
1.0
1.01
1.01
1.0
1.0
1.0
1.0
1.12
1.0
1.01
1.0
1.0
1.0
1.01

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

2.15
5.46
3.71
2.14
1.0
2.14
1.0
18.03
1.75
1.14
1.81
1.0
1.53
1.88
12.02

4.28
3.96
2.56
4.74
1.0
3.79
1.0
1.0
2.46
1.27
1.45
1.09
2.16
1.17
1.01

elevators-opt08-strips (13)
openstacks-opt08-strips (16)
parcprinter-08-strips (12)
pegsol-08-strips (27)
scanalyzer-08-strips (6)
sokoban-opt08-strips (21)
transport-opt08-strips (11)
woodworking-opt08-strips (11)

28.6
1.17
24.87
4.92
23.07
15.66
15.34
53.27

1.01
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

7.1
1.03
9.23
2.15
6.88
1.33
4.26
8.53

7.46
1.09
1.19
1.0
1.43
1.01
2.84
1.91

GEOMETRIC MEAN

5.85

1.16

1.0

2.9

1.89

Table 13: Detailed per-domain expansions relative maxh using hLA hLM-CUT+ . row
shows geometric mean ratio expanded nodes relative maxh . Domains
grouped domains unit cost actions high variance coverage, domains
unit cost actions low variance coverage, domains non-uniform action
costs, respectively.

741

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.94 (31)
0.22 (13)
0.76 (16)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.82 (27)
0.21 (12)
0.95 (20)
0.88 (21)
0.88 (15)
0.62 (8)
0.70 (7)
0.92 (12)

0.85 (28)
0.22 (13)
0.95 (20)
1.00 (24)
0.94 (16)
0.69 (9)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.89 (16)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.79 (15)

0.82 (18)
0.95 (19)
0.82 (18)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.95 (21)
0.95 (19)
0.91 (20)
0.96 (27)
0.94 (15)
0.83 (25)
0.92 (11)
0.95 (18)

TOTAL

0.92 (639)

0.89 (614)

0.89 (614)

0.87 (602)

0.91 (630)

Table 14: Detailed per-domain normalized coverage using hLM-CUT hLM-CUT+ . line shows
normalized coverage domain, number problems solved shown
parentheses. Domains grouped domains unit cost actions high variance
coverage, domains unit cost actions low variance coverage, domains
non-uniform action costs, respectively.

742

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

expansions

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (26)
freecell (12)
logistics00 (16)
mprime (21)
mystery (16)
pipesworld-tankage (8)
satellite (7)
zenotravel (12)

1.16
9.55
1.0
2.2
1.69
3.09
3.66
1.61

1.0
1.0
1.0
1.01
1.01
1.01
0.98
1.09

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.04
4.37
1.0
1.84
1.52
1.75
2.39
1.3

1.16
1.26
1.0
1.0
1.32
1.61
1.51
1.22

blocks (27)
depot (7)
driverlog (13)
grid (2)
gripper (6)
logistics98 (6)
miconic (140)
pathways (5)
pipesworld-notankage (16)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (9)

1.02
7.53
1.71
4.03
1.05
1.08
1.0
1.22
3.49
1.03
1.66
1.0
1.07
1.56
1.32

1.0
1.0
1.02
1.0
1.0
1.05
1.0
1.02
1.01
1.0
1.01
1.0
1.0
1.0
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.01
4.07
1.36
1.9
1.03
1.06
1.0
1.13
1.9
1.02
1.28
1.0
1.03
1.16
1.14

1.02
1.25
1.49
1.28
1.05
1.06
1.0
1.22
1.4
1.03
1.3
1.0
1.07
1.56
1.26

elevators-opt08-strips (18)
openstacks-opt08-strips (17)
parcprinter-08-strips (17)
pegsol-08-strips (27)
scanalyzer-08-strips (13)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (13)

1.75
1.0
1.71
1.33
1.22
1.04
1.29
1.45

1.09
1.0
1.0
1.01
1.02
1.04
1.01
1.06

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.4
1.0
1.37
1.15
1.14
1.01
1.15
1.26

1.72
1.0
1.0
1.2
1.13
1.03
1.26
1.12

GEOMETRIC MEAN

1.66

1.01

1.0

1.35

1.2

Table 15: Detailed per-domain expansions relative maxh using hLM-CUT hLM-CUT+ .
row shows geometric mean ratio expanded nodes relative maxh . Domains
grouped domains unit cost actions high variance coverage, domains
unit cost actions low variance coverage, domains non-uniform action
costs, respectively.

743

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

hLA

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.94 (31)
0.53 (31)
0.76 (16)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.79 (26)
0.26 (15)
0.95 (20)
0.75 (18)
0.71 (12)
0.69 (9)
0.70 (7)
0.69 (9)

0.91 (30)
0.57 (33)
0.95 (20)
0.96 (23)
1.00 (17)
0.85 (11)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.71 (5)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
0.93 (13)
0.67 (2)
0.86 (6)
0.83 (5)
0.99 (140)
0.80 (4)
0.83 (15)
0.98 (48)
0.88 (7)
0.93 (28)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.82 (18)
0.80 (16)
0.95 (21)
0.96 (27)
0.81 (13)
0.77 (23)
0.92 (11)
0.79 (15)

0.64 (14)
0.90 (18)
0.59 (13)
0.96 (27)
0.38 (6)
0.90 (27)
0.92 (11)
0.74 (14)

0.95 (21)
0.80 (16)
0.86 (19)
0.96 (27)
0.94 (15)
0.87 (26)
0.92 (11)
0.79 (15)

TOTAL

0.91 (656)

0.92 (639)

0.89 (614)

0.89 (628)

0.81 (578)

0.92 (649)

Table 16: Detailed per-domain normalized coverage using hLA , hLM-CUT hLM-CUT+ . line
shows normalized coverage domain, number problems solved
shown parentheses. Domains grouped domains unit cost actions high
variance coverage, domains unit cost actions low variance coverage,
domains non-uniform action costs, respectively.

744

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

expansions

hLA

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (26)
freecell (13)
logistics00 (16)
mprime (18)
mystery (13)
pipesworld-tankage (9)
satellite (7)
zenotravel (9)

2.29
1.22
1.0
9.21
7.85
2.68
18.81
7.26

1.16
417.8
1.0
2.74
1.41
5.08
3.78
1.23

1.0
47.65
1.0
1.21
1.13
1.38
1.01
1.1

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.04
45.83
1.0
4.26
4.48
2.27
4.53
3.07

1.71
6.73
1.0
1.99
1.43
1.93
2.45
2.45

blocks (27)
depot (7)
driverlog (13)
grid (2)
gripper (5)
logistics98 (5)
miconic (140)
pathways (4)
pipesworld-notankage (15)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (9)

7.59
19.63
11.36
5.04
1.0
6.43
1.0
40.63
3.09
1.31
2.77
1.09
2.3
2.73
60.39

1.02
7.53
1.73
4.06
1.06
1.08
1.0
1.02
4.29
1.03
1.67
1.0
1.07
1.56
1.33

1.0
1.01
1.03
1.01
1.0
1.05
1.0
1.0
1.13
1.0
1.01
1.0
1.01
1.0
1.01

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.58
5.22
2.79
2.15
1.02
1.79
1.0
7.76
2.35
1.1
1.78
0.99
1.33
1.91
6.05

1.67
2.46
2.03
4.91
1.0
1.58
1.0
1.0
2.53
1.24
1.38
1.09
1.58
1.41
1.33

elevators-opt08-strips (14)
openstacks-opt08-strips (16)
parcprinter-08-strips (13)
pegsol-08-strips (27)
scanalyzer-08-strips (6)
sokoban-opt08-strips (21)
transport-opt08-strips (11)
woodworking-opt08-strips (11)

33.16
1.17
45.31
4.94
24.13
16.43
15.5
53.33

1.65
1.0
2.02
1.34
1.5
1.03
1.29
1.37

1.1
1.0
1.0
1.01
1.05
1.05
1.01
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

4.65
1.03
5.91
1.69
5.5
1.14
2.66
4.02

2.9
1.07
1.0
1.26
1.87
1.13
1.82
1.63

GEOMETRIC MEAN

6.1

1.91

1.18

1.0

2.56

1.67

Table 17: Detailed per-domain expansions relative maxh using hLA , hLM-CUT hLM-CUT+ .
row shows geometric mean ratio expanded nodes relative maxh .
Domains grouped domains unit cost actions high variance coverage,
domains unit cost actions low variance coverage, domains nonuniform action costs, respectively.

745

fiD OMSHLAK , K ARPAS , & ARKOVITCH

overhead

hLA /hLM-CUT

hLA /hLM-CUT+

hLM-CUT /hLM-CUT+

Three

airport (28)
freecell (13)
logistics00 (20)
mprime (23)
mystery (17)
pipesworld-tankage (9)
satellite (7)
zenotravel (12)
blocks (26)
depot (7)
driverlog (13)
grid (2)
gripper (7)
logistics98 (6)
miconic (141)
pathways (5)
pipesworld-notankage (17)
psr-small (49)
rovers (7)
schedule (30)
storage (15)
tpp (6)
trucks-strips (9)
elevators-opt08-strips (16)
openstacks-opt08-strips (16)
parcprinter-08-strips (18)
pegsol-08-strips (27)
scanalyzer-08-strips (13)
sokoban-opt08-strips (24)
transport-opt08-strips (11)
woodworking-opt08-strips (14)

4%
4%
8%
7%
3%
11%
14%
15%
21%
45%
29%
26%
13%
15%
1%
5%
22%
8%
15%
13%
18%
2%
3%
32%
15%
2%
9%
2%
5%
12%
5%

7%
8%
7%
7%
3%
11%
18%
35%
35%
29%
45%
17%
13%
31%
4%
1%
17%
11%
24%
13%
12%
1%
2%
75%
9%
6%
2%
4%
2%
23%
5%

1%
13%
2%
6%
8%
10%
10%
26%
2%
14%
26%
1%
5%
6%
3%
4%
20%
3%
26%
5%
2%
2%
12%
8%
10%
1%
28%
10%
14%
7%
2%

9%
1%
6%
3%
2%
5%
8%
21%
5%
10%
21%
6%
22%
5%
4%
7%
22%
12%
19%
24%
10%
3%
7%
9%
23%
5%
15%
1%
7%
3%
4%

AVERAGE

12%

15%

9%

10%

Table 18: Selective max overhead. row lists average percentage time spent learning
classification, total time taken selective max, domain,
set heuristics. Domains grouped domains unit cost actions high
variance coverage, domains unit cost actions low variance coverage,
domains non-uniform action costs, respectively.

746

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

sel=0.1
h
30
49
21
24
17
12
8
13
174

sel=0.5
h
30
49
21
24
17
12
8
13
174

sel=1
h
30
49
21
24
17
12
8
13
174

sel=1.5
h
30
49
21
24
17
12
8
13
174

sel=2
h
30
49
21
22
17
12
7
12
170

sel=3
h
30
49
21
23
16
12
7
11
169

sel=4
h
30
49
21
21
15
13
7
10
166

sel=5
h
30
49
21
21
15
13
7
10
166

Table 19: Number problems solved selective max domain varying values
hyper-parameter

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

sel=0.51
h
30
48
21
24
17
12
8
13
173

sel=0.6
h
30
49
21
24
17
12
8
13
174

sel=0.7
h
30
49
21
24
17
12
8
13
174

sel=0.8
h
30
49
21
24
17
12
8
13
174

sel=0.9
h
30
49
21
24
17
12
8
13
174

sel=0.99
h
30
49
21
24
17
12
8
13
174

Table 20: Number problems solved selective max domain varying values
confidence threshold

Table 18 lists average overhead selective max domain, combination
two heuristics.
Tables 19, 20, 21, 22 23 list number problems solved domain, various
values , , N , sampling method classifier, respectively.

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

=10
selN
h
30
47
21
24
17
12
8
13
172

=100
selN
h
30
49
21
24
17
12
8
13
174

=1000
selN
h
30
46
21
24
17
12
8
13
171

Table 21: Number problems solved selective max domain varying values
initial Sample Size N

747

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

selPDB
h
30
49
21
24
17
12
8
13
174

selP
h
30
53
21
24
17
12
8
13
178

P
selU
h
30
55
21
24
17
12
8
13
180

Table 22: Number problems solved selective max domain different sampling
methods. PDB sampling method Haslum et al. (2007), P biased probes
sampling method, U P unbiased probes sampling method.

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

B
selN
h
30
49
21
24
17
12
8
13
174

selAODE
h
25
49
20
24
17
12
8
13
168


selIT
h
30
34
20
24
17
12
7
12
156

N
sel3N
h
30
35
20
24
17
12
7
13
158

N
sel5N
h
28
46
20
23
17
10
6
11
161

Table 23: Number problems solved selective max domain different classifiers

748

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
0.84 (49)
1.00 (21)
1.00 (24)
1.00 (17)
0.92 (12)
0.80 (8)
1.00 (13)

0.91 (30)
0.91 (53)
0.95 (20)
0.96 (23)
1.12 (19)
0.92 (12)
0.70 (7)
0.92 (12)

0.91 (30)
0.93 (54)
1.00 (21)
0.96 (23)
1.24 (21)
1.00 (13)
0.70 (7)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

1.00 (22)
0.90 (18)
0.82 (18)
0.96 (27)
0.94 (15)
0.97 (29)
0.92 (11)
0.89 (17)

0.82 (18)
0.90 (18)
0.82 (18)
0.96 (27)
0.81 (13)
0.97 (29)
0.92 (11)
0.84 (16)

0.86 (19)
0.95 (19)
0.82 (18)
0.96 (27)
1.00 (16)
0.97 (29)
1.00 (12)
0.89 (17)

TOTAL

0.95 (677)

0.94 (672)

0.96 (685)

Table 24: Detailed coverage portfolio using hLA / hLM-CUT . Number problems solved selective max (selh ), simulated interruptible portfolio (portint ), simulated contract
anytime portfolio (portctr ) domain using heuristics hLA / hLM-CUT . Domains
grouped domains unit cost actions high variance coverage, domains
unit cost actions low variance coverage, domains non-uniform action
costs, respectively.

749

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
0.71 (41)
1.00 (21)
1.00 (24)
1.00 (17)
0.69 (9)
1.00 (10)
0.92 (12)

0.91 (30)
0.91 (53)
0.95 (20)
1.00 (24)
1.12 (19)
0.92 (12)
0.80 (8)
0.85 (11)

0.91 (30)
0.93 (54)
1.00 (21)
1.00 (24)
1.18 (20)
1.00 (13)
0.80 (8)
0.85 (11)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.93 (26)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

0.93 (26)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.70 (7)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.80 (8)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.73 (16)
0.85 (17)
1.00 (22)
0.96 (27)
0.81 (13)
0.80 (24)
0.92 (11)
0.79 (15)

0.82 (18)
0.85 (17)
1.00 (22)
0.96 (27)
0.75 (12)
0.83 (25)
0.92 (11)
0.79 (15)

0.82 (18)
0.85 (17)
1.00 (22)
0.96 (27)
0.94 (15)
0.83 (25)
1.00 (12)
0.79 (15)

TOTAL

0.92 (651)

0.93 (666)

0.94 (676)

Table 25: Detailed coverage portfolio using hLA / hLM-CUT+ . Number problems solved selective max (selh ), simulated interruptible portfolio (portint ), simulated contract
anytime portfolio (portctr ) domain using heuristics hLA / hLM-CUT+ . Domains
grouped domains unit cost actions high variance coverage, domains
unit cost actions low variance coverage, domains non-uniform action
costs, respectively.

750

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.85 (28)
0.22 (13)
0.95 (20)
1.00 (24)
0.94 (16)
0.69 (9)
0.80 (8)
0.92 (12)

0.88 (29)
0.24 (14)
0.95 (20)
1.00 (24)
1.18 (20)
0.69 (9)
0.80 (8)
0.92 (12)

0.88 (29)
0.26 (15)
0.95 (20)
1.00 (24)
1.24 (21)
0.85 (11)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.89 (16)
1.00 (49)
0.88 (7)
0.93 (28)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.95 (21)
0.95 (19)
0.91 (20)
0.96 (27)
0.94 (15)
0.83 (25)
0.92 (11)
0.95 (18)

0.82 (18)
0.90 (18)
1.00 (22)
0.96 (27)
0.81 (13)
0.93 (28)
0.92 (11)
0.79 (15)

0.86 (19)
0.95 (19)
1.00 (22)
0.96 (27)
0.94 (15)
0.93 (28)
0.92 (11)
0.84 (16)

TOTAL

0.91 (630)

0.90 (625)

0.93 (640)

Table 26: Detailed coverage portfolio using hLM-CUT / hLM-CUT+ . Number problems solved
selective max (selh ), simulated interruptible portfolio (portint ), simulated
contract anytime portfolio (portctr ) domain using heuristics hLM-CUT / hLM-CUT+ .
Domains grouped domains unit cost actions high variance coverage,
domains unit cost actions low variance coverage, domains nonuniform action costs, respectively.

751

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
0.57 (33)
0.95 (20)
0.96 (23)
1.00 (17)
0.85 (11)
0.80 (8)
0.92 (12)

0.91 (30)
0.91 (53)
0.95 (20)
1.00 (24)
1.18 (20)
0.92 (12)
0.80 (8)
0.92 (12)

0.91 (30)
0.93 (54)
1.00 (21)
1.00 (24)
1.18 (20)
0.92 (12)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.95 (21)
0.80 (16)
0.86 (19)
0.96 (27)
0.94 (15)
0.87 (26)
0.92 (11)
0.79 (15)

0.82 (18)
0.90 (18)
1.00 (22)
0.96 (27)
0.81 (13)
0.97 (29)
0.92 (11)
0.84 (16)

0.86 (19)
0.95 (19)
1.00 (22)
0.96 (27)
0.81 (13)
0.97 (29)
0.92 (11)
0.89 (17)

TOTAL

0.92 (649)

0.95 (679)

0.95 (684)

Table 27: Detailed coverage portfolio using hLA / hLM-CUT / hLM-CUT+ . Number problems
solved selective max (selh ), simulated interruptible portfolio (portint ), simulated contract anytime portfolio (portctr ) domain using heuristics hLA / hLM-CUT
/ hLM-CUT+ . Domains grouped domains unit cost actions high variance
coverage, domains unit cost actions low variance coverage, domains
non-uniform action costs, respectively.

Tables 24, 25, 26 27 list normalized coverage domain selective max,
simulated contract interruptible sequential portfolios.

References
Arfaee, S. J., Zilles, S., & Holte, R. C. (2010). Bootstrap learning heuristic functions. Felner,
A., & Sturtevant, N. (Eds.), Proceedings Third Annual Symposium Combinatorial
Search (SoCS 2010), pp. 5260. AAAI Press.
Backstrom, C., & Klein, I. (1991). Planning polynomial time: SAS-PUBS class. Computational Intelligence, 7(3), 181197.
Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational Intelligence, 11(4), 625655.
Bayardo Jr., R. J., & Schrag, R. (1997). Using CSP look-back techniques solve real-world SAT
instances. Kuipers, B., & Webber, B. L. (Eds.), Proceedings Fourteenth National
Conference Artificial Intelligence (AAAI 1997), pp. 203208. AAAI Press.
752

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Bonet, B., & Helmert, M. (2010). Strengthening landmark heuristics via hitting sets. Coelho,
H., Studer, R., & Wooldridge, M. (Eds.), Proceedings 19th European Conference
Artificial Intelligence (ECAI 2010), pp. 329334. IOS Press.
Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism
planning. Kuipers, B., & Webber, B. L. (Eds.), Proceedings Fourteenth National
Conference Artificial Intelligence (AAAI 1997), pp. 714719. AAAI Press.
Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI planning
automatically learned macro-operators. Journal Artificial Intelligence Research, 24,
581621.
Brafman, R., & Shani, G. (2012). multi-path compilation approach contingent planning.
Hoffmann, J., & Selman, B. (Eds.), Proceedings Twenty-Sixth AAAI Conference
Artificial Intelligence (AAAI 2012), pp. 915. AAAI Press.
Burke, E., Kendall, G., Newall, J., Hart, E., Ross, P., & Schulenburg, S. (2003). Hyper-Heuristics:
Emerging Direction Modern Search Technology. Handbook Metaheuristics, International Series Operations Research & Management Science, chap. 16, pp. 457474.
Coles, A., & Smith, A. (2007). Marvin: heuristic search planner online macro-action learning. Journal Artificial Intelligence Research, 28, 119156.
Cover, T. M., & Hart, P. E. (1967). Nearest neighbor pattern classification. IEEE Transactions
Information Theory, 13(1), 21 27.
de la Rosa, T., Jimenez, S., & Borrajo, D. (2008). Learning relational decision trees guiding
heuristic planning. Rintanen, J., Nebel, B., Beck, J. C., & Hansen, E. (Eds.), Proceedings
Eighteenth International Conference Automated Planning Scheduling (ICAPS
2008), pp. 6067. AAAI Press.
Domshlak, C., Karpas, E., & Markovitch, S. (2010). max max: Online learning
speeding optimal planning. Fox, M., & Poole, D. (Eds.), Proceedings TwentyFourth AAAI Conference Artificial Intelligence (AAAI 2010), pp. 10711076. AAAI Press.
Fern, A. (2010). Speedup learning. Sammut, C., & Webb, G. I. (Eds.), Encyclopedia Machine
Learning, pp. 907911. Springer.
Fern, A., Khardon, R., & Tadepalli, P. (2011). first learning track international planning
competition. Machine Learning, 84(1-2), 81107.
Fikes, R. E., Hart, P. E., & Nilsson, N. J. (1972). Learning executing generalized robot plans.
Artificial Intelligence, 3, 251288.
Fikes, R. E., & Nilsson, N. J. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189208.
Finkelstein, L., & Markovitch, S. (1998). selective macro-learning algorithm application
NxN sliding-tile puzzle. Journal Artificial Intelligence Research, 8, 223263.
Garca-Olaya, A., Jimenez, S., & Linares Lopez, C. (2011). 2011 international planning competition. Tech. rep., Universidad Carlos III de Madrid. http://hdl.handle.net/10016/11710.
Geffner, H. (2010). model-based approach autonomous behavior: personal view. Fox,
M., & Poole, D. (Eds.), Proceedings Twenty-Fourth AAAI Conference Artificial
Intelligence (AAAI 2010), pp. 17091712. AAAI Press.
753

fiD OMSHLAK , K ARPAS , & ARKOVITCH

Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independent construction pattern database heuristics cost-optimal planning. Holte, R. C., & Howe, A. E.
(Eds.), Proceedings Twenty-Second AAAI Conference Artificial Intelligence (AAAI
2007), pp. 10071012. AAAI Press.
Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence Research, 26, 191246.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whats difference anyway?. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings
Nineteenth International Conference Automated Planning Scheduling (ICAPS
2009), pp. 162169. AAAI Press.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics optimal sequential planning. Boddy, M., Fox, M., & Thiebaux, S. (Eds.), Proceedings Seventeenth
International Conference Automated Planning Scheduling (ICAPS 2007), pp. 176
183. AAAI Press.
Helmert, M., & Roger, G. (2008). good almost perfect?. Fox, D., & Gomes, C. P. (Eds.),
Proceedings Twenty-Third AAAI Conference Artificial Intelligence (AAAI 2008), pp.
944949. AAAI Press.
Helmert, M., Roger, G., & Karpas, E. (2011). Fast Downward Stone Soup: baseline building
planner portfolios. ICAPS 2011 Workshop Planning Learning, pp. 2835.
Hoffmann, J., & Nebel, B. (2001). planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research, 14, 253302.
Hutter, F., Hoos, H. H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: automatic algorithm
configuration framework. Journal Artificial Intelligence Research, 36, 267306.
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. Boutilier, C.
(Ed.), Proceedings 21st International Joint Conference Artificial Intelligence (IJCAI 2009), pp. 17281733.
Katz, M., & Domshlak, C. (2010). Implicit abstraction heuristics. Journal Artificial Intelligence
Research, 39, 51126.
Kautz, H., & Selman, B. (1992). Planning satisfiability. Neumann, B. (Ed.), Proceedings
10th European Conference Artificial Intelligence (ECAI 1992), pp. 359363. John Wiley
Sons.
Keyder, E., & Geffner, H. (2009). Soft goals compiled away. Journal Artificial Intelligence
Research, 36, 547556.
Marques-Silva, J. P., & Sakallah, K. A. (1996). GRASP - new search algorithm satisfiability.
Proceedings 1996 IEEE/ACM International Conference Computer-Aided Design
(ICCAD 1996), pp. 220227.
Minton, S. (1994). Machine Learning Methods Planning. Morgan Kaufmann Publishers Inc.
Nissim, R., Hoffmann, J., & Helmert, M. (2011). Computing perfect heuristics polynomial time:
bisimulation merge-and-shrink abstraction optimal planning. Walsh, T. (Ed.),
Proceedings 22nd International Joint Conference Artificial Intelligence (IJCAI11),
pp. 19831990. AAAI Press/IJCAI.
754

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Palacios, H., & Geffner, H. (2009). Compiling uncertainty away conformant planning problems
bounded width. Journal Artificial Intelligence Research, 35, 623675.
Pearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving. AddisonWesley.
Pednault, E. P. D. (1989). ADL: Exploring middle ground STRIPS situation
calculus. Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), Proceedings First
International Conference Principles Knowledge Representation Reasoning (KR
1989), pp. 324332. Morgan Kaufmann.
Rendell, L. A. (1983). new basis state-space learning systems successful implementation. Artificial Intelligence, 20(4), 369392.
Rintanen, J., Heljanko, K., & Niemela, I. (2006). Planning satisfiability: Parallel plans algorithms plan search. Artificial Intelligence, 170(1213), 10311080.
Russell, S. J., & Zilberstein, S. (1991). Composing real-time systems. Mylopoulos, J., & Reiter,
R. (Eds.), Proceedings 12th International Joint Conference Artificial Intelligence
(IJCAI 1991), pp. 212217. Morgan Kaufmann.
Schiex, T., & Verfaillie, G. (1993). Nogood recording static dynamic constraint satisfaction
problems. Journal Artificial Intelligence Research, 3, 4855.
Thayer, J. T., Dionne, A. J., & Ruml, W. (2011). Learning inadmissible heuristics search.
Bacchus, F., Domshlak, C., Edelkamp, S., & Helmert, M. (Eds.), Proceedings TwentyFirst International Conference Automated Planning Scheduling (ICAPS 2011), pp.
250257. AAAI Press.
Utgoff, P. E., Berkman, N. C., & Clouse, J. A. (1997). Decision tree induction based efficient
tree restructuring. Machine Learning, 29(1), 544.
Webb, G. I., Boughton, J. R., & Wang, Z. (2005). naive Bayes: Aggregating one-dependence
estimators. Machine Learning, 58(1), 524.
Yoon, S., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning. Boddy,
M., Fox, M., & Thiebaux, S. (Eds.), Proceedings Seventeenth International Conference
Automated Planning Scheduling (ICAPS 2007), pp. 352359. AAAI Press.
Yoon, S., Fern, A., & Givan, R. (2008). Learning control knowledge forward search planning.
Journal Machine Learning Research, 9, 683718.
Zimmerman, T., & Kambhampati, S. (2003). Learning-assisted automated planning: looking back,
taking stock, going forward. AI Magazine, 24, 7396.

755


