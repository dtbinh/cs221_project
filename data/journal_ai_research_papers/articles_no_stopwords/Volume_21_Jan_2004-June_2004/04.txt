Journal Arti cial Intelligence Research 21 (2004) 631-670

Submitted 9/03 published 6/04

PHA*: Finding Shortest Path A* Unknown
Physical Environment
Ariel Felner

Department Information Systems Engineering,
Ben-Gurion University Negev, Beer-Sheva, 85104, Israel

Roni Stern
Asaph Ben-Yair
Sarit Kraus
Nathan Netanyahu

Department Computer Science, Bar-Ilan University
Ramat-Gan, Israel, 52900

felner@bgumail.bgu.ac.il
sternr2@cs.biu.ac.il
benyaya@cs.biu.ac.il
sarit@cs.biu.ac.il
nathan@cs.biu.ac.il

Abstract
address problem nding shortest path two points unknown
real physical environment, traveling agent must move around environment
explore unknown territory. introduce Physical-A* algorithm (PHA*) solving
problem. PHA* expands mandatory nodes A* would expand returns
shortest path two points. However, due physical nature
problem, complexity algorithm measured traveling eort moving
agent number generated nodes, standard A*. PHA* presented
two-level algorithm, high level, A*, chooses next node expanded
low level directs agent node order explore it. present
number variations high-level low-level procedures evaluate
performance theoretically experimentally. show travel cost best
variation fairly close optimal travel cost, assuming mandatory nodes
A* known advance. generalize algorithm multi-agent case,
number cooperative agents designed solve problem. Speci cally, provide
experimental implementation system. noted problem
addressed navigation problem, rather problem nding shortest
path two points future usage.

1. Introduction
paper address problem nding shortest path two points
unknown real physical environment, mobile agent must travel around
environment explore unknown territories. Search spaces path- nding problems
commonly represented graphs, states associated search space
represented graph nodes, transition states captured graph edges.
Graphs represent dierent environments, road maps, games, communication
networks. Moving one node graph another done applying logical
operators manipulate current state actual agent move one
node another. sliding-tile puzzle Rubik's Cube (Korf, 1999) examples
c 2004 AI Access Foundation. rights reserved.

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

rst type, road map example second type. Graphs search problems
divided following three classes:

Fully known graphs: nodes edges graph stored com-

puter, graph fully known. input problems usually
complete graph represented adjacency matrix adjacency list.
relevant problem case would nd, example, shortest path
road map nodes edges known advance.

large graphs: Graphs due storage time limitations completely known cannot fully stored storage device. Many graphs
search problems exponential number nodes. example, 24-tile puzzle problem 1025 states cannot completely stored current machines.
input problems usually speci ed general structure state
search space, dierent operators, initial state, set goal states.
small portions graphs visited search algorithms
stored memory.

Small, partially known graphs: third class contains graphs represent
partially known physical environment. example, mobile agent unknown
area without map full knowledge environment. Given enough
time, however, agent fully explore environment since large.
Due partial knowledge, small portion graph given input.

class fully-known graphs, classical algorithms, Dijkstra's single-source
shortest-path algorithm (Dijkstra, 1959) Bellman-Ford algorithm (Bellman, 1958),
used nd optimal path two nodes. algorithms assume
node graph accessed algorithm constant time. assumption
valid since nodes edges graph known advance stored
computer's memory. Thus time complexity algorithms measured
number nodes edges process course search.
second class graphs algorithms usually ecient, since
number nodes graph large (usually exponential). Also, small
portion graph stored memory given time. A* algorithm (Hart, Nilsson, & Raphael, 1968) linear space versions, e.g., IDA* (Korf, 1985) RBFS (Korf,
1993), common methods nding shortest paths large graphs. A* keeps
open list nodes generated yet expanded, chooses
promising node (the best node) expansion. node expanded moved
open list closed list, neighbors generated put open
list. search terminates goal node chosen expansion open
list empty. cost function A* f (n) = g(n) + h(n) g(n) distance
traveled initial state n, h(n) heuristic estimate cost node
n goal. h(n) never overestimates actual cost node n goal, say
h(n) admissible. using admissible heuristic h(n), A* proved
admissible, complete, optimally eective (Dechter & Pearl, 1985). words,
heuristic, A* guaranteed always return shortest path. Furthermore,
632

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

algorithm claiming return optimal path must expand least nodes
expanded A* given heuristic.
A* expansion cycle carried constant time. takes constant
amount time retrieve node open list, generate neighbors.
latter involves applying domain-speci c operators expanded node. Thus time
complexity A* measured terms number generated nodes.1
paper deal nding shortest path graphs third class, i.e.,
small, partially known graphs correspond real physical environment. Unlike
graphs two classes, constant number computer operations done
node expansion, cannot assume, type graphs, visiting node takes
constant time. Many nodes edges graph known advance.
Therefore, expand node known advance, mobile agent must rst travel
node order explore learn neighbors. cost search
case cost moving agent physical environment, i.e., proportional
distance traveled agent. ecient algorithm would therefore minimize
distance traveled agent optimal path found. Note since small graphs
considered here, omit actual computation time focus travel
time agent. paper introduce Physical-A* algorithm (PHA*) solving
problem. PHA* expands mandatory nodes A* would expand returns
shortest path two points. However, complexity algorithm
measured traveling eort moving agent. order minimize traveling
shown, PHA* designed minimize traveling eort agent
intelligently choosing next assignment traveling agent. described below, many
times agent chooses rst move nearby nodes even though immediately
contribute proceeding A*.
Unlike ordinary navigation tasks (Cucka, Netanyahu, & Rosenfeld, 1996 Korf, 1990
Stentz, 1994 Shmoulian & Rimon, 1998), purpose agent reach goal
node soon possible, rather explore graph manner shortest
path retrieved future usage. hand, problem ordinary
exploration problem (Bender, Fernandez, Ron, Sahai, & Vadhan, 1998), entire
graph explored order mapped out. Following two motivating
examples real world applications problem:

Example 1: division troops ordered reach speci c location. coordinates location known. Navigating entire division unknown
hostile territory reaching destination unreasonable inecient. common case team scouts search best path division
pass through. scouts explore terrain report best path division
move along order reach destination ecient manner.

1. fact, A*, open list stored priority queue, would take logarithmic time
retrieve best node. However, many problems, sliding tile puzzles Rubik's Cube,
simple rst-in rst-out queue suces (Korf, 1993ff Taylor & Korf, 1993ff Korf, 1997). Likewise,
linear space versions, IDA* RBFS (which based depth-rst search), assumption
takes constant time per node valid. assume number neighbors
bounded.

633

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

Example 2: Computer systems connected networks on- o-line
dierent times, throughput seriously degraded due busy communication channels. Therefore, many networks cannot represented xed, fully
known graphs. Transferring large amounts data (e.g., multimedia les)
two computers network often time consuming, since data may
routed many communication channels computer systems reaching
destination. Finding optimal path computer systems could
improve transfer time large les. Since network may fully known,
nding optimal path two nodes requires exploration network.
ecient elegant solution might send small packets (operating scouts)
explore network return optimal path, given network stable
least short period time. Assuming computer system network
recognized neighboring systems, faced problem nding
optimal path real physical environment.2

general, would worthwhile search optimal path following
conditions hold:
Preliminary search (with usage scouts) possible cheap.
optimal path required future usage.
Often one might settle suboptimal path. However, path needed
considerable trac volume, e.g., path traveled large number times
path traveled simultaneously large number agents, nding
optimal path essential. paper focus solving problem.
paper organized follows. Section 2 provides speci c formulation
problem question. Section 3 discusses related work, Section 4 presents
PHA* algorithm single mobile agent. Several (enhanced) variations introduced
discussed domain, followed extensive empirical results demonstrate
superiority enhanced variants pursued. Section 5 provide analysis
PHA* overall evaluation performance. Section 6, provide number
generalizations multi-agent case, number traveling agents available
solving problem. Experimental results schemes presented discussed.
Section 7 contains concluding remarks discusses future research. preliminary version
paper appeared earlier (Felner, Stern, & Kraus, 2002).
2. research concerned high-level, abstract graphs intend provide new
applicable routing algorithm. Current routing technologies maintain large databases store best
paths node node, broadcast changes network, update paths necessary, thus
making essentially network graph fully known. Also, network domains one create
destroy packages thus necessarily given number agents. algorithm
may relevant future network architectures routing technologies, routers use
databases. far-fetched view, example, rapid growth Internet.
thus conceivable future storing paths would become infeasible.

634

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

2. Problem Specication
mentioned general terms, problem nd shortest path two
nodes unknown undirected graph. speci cally, assume weighted graph,
node represented 2-dimensional coordinate (i.e., location real
world), weight edge Euclidean distance two nodes.
input problem consists coordinates initial goal nodes.
nodes assumed known advance. agent assumed located
start node. task nd shortest path (unknown) graph
initial node goal node future usage. order accomplish that, agent
required traverse graph explore relevant parts leading desired solution.
agent allowed visit nodes travel one node another via existing edges.
assume node v visited search agent, neighboring
nodes discovered, well edges connecting v. assumption
unreasonable, considering, e.g., (trac) signs road intersection often indicate
neighboring destinations lengths corresponding road segments connect
locations. Even without road signs, scouts reach new location,
look around, observe neighboring locations, assess distances current
location. general, assumption neighboring nodes discovered instantly
fairly common search problems algorithms.3
Since goal search nd best path goal, clear { given
admissible heuristic { agent must expand nodes expanded A*, A*
optimally eective (Dechter & Pearl, 1985). Let C length shortest path
initial node goal node. A* expand nodes, that, f (n) =
g(n) + h(n) < C nodes f (n) = C . refer nodes
(set mandatory) A* nodes. stated above, agent must visit A* nodes
order nd shortest path. However, may need visit additional nodes.
make following fundamental observations respect problem question:
First, even set A* nodes known advance, agent may need visit
additional nodes traversing related portions graph.
shortest path two A* nodes may include graph nodes
belong A* nodes, i.e., f value greater C . Given A* nodes,
nding shortest path visits { confused
shortest path origin node goal node { could considered
solving traveling salesman problem (TSP) respect set A* nodes.
Note TSP solution may include nodes belong A* nodes.
Second, agent know A* nodes advance. nodes added
open list expanded search progresses. Thus agent cannot
use solution TSP, since TSP assumes nodes visited provided
input.
3. are, however, domains assumption may hold. domains, node becomes
fully known agent reaches physically. work restrict
assumption. domains addressed part future work.

635

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

cases, order A* nodes expanded dierent
order visited according TSP solution. Thus minimal
path traversing A* nodes cannot used.
Third, node added open list agent cannot know whether
belongs A* nodes, since C known search concluded. Consider
node n open list, head open list. Suppose
agent physically located near node. decide whether
slightly extend path visit node n skip n continue node
head open list. n turned belong A* nodes, visiting
may prove bene cial. (This n might reach head open
list agent physically located far away it, visiting n
point incur signi cant travel cost.) However, turns n
belong A* nodes, (small) detour visiting proven useless.
Intuitively, however, decision never visit would result bad strategy.
Thus agent may visit nodes belong A* nodes future
expected bene ts. actual decision whether visit n depend
distance agent's location n (at time decision)
agent's estimate whether n belongs set A* nodes.
following sections present PHA* algorithm ecient exploration
graph, order nd shortest path two given nodes single traveling
agent, well multiple agents. study dierent heuristics direct agent
make intelligent decision, attempt achieve small overall travel cost.

3. Related Work
Much research devoted guiding mobile agent exploring new unknown
environments order study map out. work dierent,
sense explores merely necessary regions graph order retrieve
shortest path two nodes entire graph. literature
area deals physical mobile robot moves real environment. published
research focuses usually issue assisting robot recognize physical objects
environment. refer reader (Bender et al., 1998), contains extensive
survey various related approaches state art techniques.
Another class algorithms navigation algorithms. navigation problem concerned
navigating mobile agent goal fast possible, necessarily via shortest
(optimal) path. navigator always proceed towards goal, ignoring whether
trail traversed thus far lies shortest path. Deviations optimal path
neglected since navigation problem reconsidered every move respect
new source node, i.e., current position agent. navigation algorithm halts
mobile agent reaches goal. path passed usually lacks importance usually
optimal. problem, hand, nd optimal path goal node
future usage. Even agent nds path goal node, search continues
636

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

shortest path goal found. Next, describe briey work done
navigation partially known graphs.
(Cucka et al., 1996) introduced navigation algorithms sensory-based environments automated robots moving room. used depth rst search
(DFS)-based navigation algorithms, use heuristic function choosing next node
agent go to.
Real-Time-A* (RTA*) (Korf, 1990) sophisticated version, Learning RealTime-A* (LRTA*), algorithms nding paths two nodes graph.
However, deal large graphs assume constraint time
computation move retrieve given constant time. Thus limited
search performed, node best cost search frontier picked.
problem solver moves one step along path node. search continues
new state problem solver. merit node n (in RTA* LRTA*)
f (n) = g(n) + h(n), similarly A*. Unlike A*, though, g(n) actual distance node
n current state problem solver, rather original initial state.
dierence RTA* LRTA* search terminated, LRTA*
stores heuristic estimation value node visited problem solver.
method successor nodes chosen dierent two variations. Korf (Korf,
1990) proves large number runs, run start node selected
random, stored value node visited LRTA* problem solver converges
optimal distance goal. RTA* LRTA* signi cantly dierent
approach, assume node expanded computer's memory
without agent physically visit node. (Also, algorithms designed
large graphs.) Furthermore, RTA* nd optimal path goal. trivial
version LRTA* could used solve problem, e.g., limiting search depth
one level, every node visited agent could physically expanded. However,
variant competitive approach, perform simple
hill-climbing procedure. addition, order attain optimal path, LRTA*
select many start nodes random. relevant case, given
one initial node.
MARTA* (Knight, 1993) multi-agent version RTA*. MARTA* every agent runs
RTA* independently. Kitamura et al. (Kitamura, Teranishi, & Tatsumi, 1996) modi ed MARTA* using coordination strategies based attraction repulsion.
strategies employed tie-breaking situations. using repulsion strategy,
idea spread agents, agent intends maximize distance
others. Again, path provided algorithm optimal also, agents
need physically visit node order expand it. work inspired algorithms
presented paper, far handling multi-agent mutual decision concerned.
Life-long planing A* (LPA*) (Koenig & Likhachev, 2002b) remarkable algorithm
generalizes A* handle dynamically changing graph. LPA* activated every time
graph changed order nd current shortest path given start
goal nodes. utilizes fact much old data explored previous runs
LPA* still valid current run. A* special case LPA* entire graph
explored yet.
637

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

D*-lite (Koenig & Likhachev, 2002a) applies LPA* case mobile robot needs
nd shortest path unknown environment environment changes
dynamically (i.e., edges added deleted times). LPA*, start
node identical runs. D*-lite, however, robot moves along path
calculates new shortest path current location. D*-lite modi es LPA*
old data previous runs eciently used case start node
changed according new location robot. D*-Lite actually simpli ed version
previous algorithm D* Stenz (Stentz, 1994).
main dierence algorithms approach they, too, expand
node computer's memory without requiring mobile agent physically visit
node. Indeed, following every move robot D* Lite, changes graph
provided immediately robot need physically visit nodes order gather
rsthand information. task agent, context D*, repeatedly
determine shortest path current location robot goal location
edge costs graph changes robot moves. D* lite nd path
returns it. simply navigation algorithm guides agent goal node
based previous new information terrain.
agent operating real world must often choose maximizing expected
utility (according current knowledge \world") learning
environment, attempt improve future gains. problem known tradeo exploitation exploration reinforcement learning (Kaelbling & Moore,
1996). Argamon et al. (Argamon-Engelson, Kraus, & Sina, 1998, 1999) address tradeo exploration exploitation agent moves repeatedly two
locations. propose utility-based on-line exploration algorithm takes
account cost attempting improve currently best route known
estimate potential bene ts future task repetitions. expected utility
exploration positive, agent takes actions improve route otherwise,
continues using known path. authors compare utility-based on-line exploration
heuristic backtracking search algorithm exhaustively searches graph
starting perform task, randomized interleaved exploration algorithm.
assume agent knows path two nodes, make
assumption.
Argamon et al. suggest larger number times task repeated,
merit interleaved exploration diminishes. agent required move
back forth two nodes large number times, need decide
on-line whether exploit explore instead, shortest path found soon
possible. Thus good search algorithm may prove useful. respect work
complements Argamon et al., provides ecient search algorithms situations
optimal path needed advance. contrast, applying techniques Argamon et
al. situations yields poor results demonstrated experiments.
Roadmap-A* (Shmoulian & Rimon, 1998) sophisticated single agent navigation
algorithm. chooses navigate node assumed close goal node.
algorithm supervised high-level procedure called A" (Pearl & Kim, 1982). Instead
always selecting best node open list, A" allows search agent choose
set \good nodes". set called focal set. focal set nodes
638

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

open list whose f value greater value best node ".
focal nodes determined, local search performed navigate agent
one nodes, believed close goal node. role high-level
phase prevent navigating agent going wrong direction considering
path traveled thus far.
Roadmap-A*, " pre-speci ed constant, determines trade-o
local search A*. example, A0 A* A1 local search, choosing
iteration node believed close goal node. algorithm
halts goal node reached, thus " > 0 optimal path might
known. paradigm Roadmap-A* similar ours, sense node known
agent explores it. fact, trivial case " = 0, Roadmap-A*
similar approach simple heuristic \shortest-known path" (presented
Subsection 4.1 below). comments basic dierence RoadmapA*
PHA* provided Section 5.
summary, listed algorithms navigation algorithms, i.e.,
necessarily require agent physically visit node order expand it,
necessarily return optimal path goal node. Thus inherently solve dierent
problem one pursued paper.

4. PHA* Single Agent

turn description PHA* algorithm, focusing rst case
single mobile agent available.
Nodes environment divided explored unexplored nodes. Exploring
node means physically visiting node agent, learning location
location neighbors. new algorithm PHA* activates essentially A*
environment. However, order expand node A*, node must rst explored
agent order obtain relevant data associated (i.e., neighboring nodes
incident edges). Throughout discussion paper treat PHA* twolevel algorithm. Although principle PHA* could viewed one-level algorithm
(see discussion Subsection 4.2), nd two-level presentation
well-structured better understood conceptually. two-level framework consists
high-level low-level routine. high level (which invokes low level various
stages PHA*), acts essentially regular A* search algorithm. chooses
cycle node open list expansion. heuristic function h(n) used
Euclidean distance n goal node. (This heuristic admissible course,
de nition.) node chosen high level explored agent,
low level, navigation algorithm, activated navigate agent node
explore it. node explored low level expandable high
level. chosen node already explored, neighbors already known,
readily expandable high level without need send agent visit
node. pseudo-code high level given below.

639

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

.
.
.
.
.
.
.

g

high-level(open-list) f
(open-list empty) f
target = best node open-list
target unexplored
f
explore(target) low level







g

g

expand(target)

4.1 Low-Level Algorithms

high-level algorithm, A*, chooses expand node smallest f value
open list, regardless whether agent already visited node. chosen
node visited agent, low level instructs agent visit node.
call node target node low level. order reach target node,
must use navigation algorithm. implemented number navigation variants
low level. rst describe simple algorithms use known information
graph. present ecient algorithms, explore graph
navigation provide new information high level. assume
agent current node needs navigate target node.
4.1.1 Simple Navigation Algorithms

Tree path: every best- rst search, A* spans nodes generates

tree called search tree. Every known node node search tree.
trivial way move one node search tree.
tree-path algorithm instructs agent move current node target
node shortest path search tree. words,
agent walk tree current node reaches ancestor
target node, walk node target node. trivial
algorithm, presented mainly comparison purposes.

Shortest known path: nodes search tree already

explored agent, incident edges known. search tree
nodes plus additional edges explored nodes viewed subgraph
fully known. nodes subgraph connected
part search tree. Using subgraph, calculate shortest path
target node via known nodes edges. mentioned above, nding shortest
path known graph done easily, agent simply computes shortest
path target node travels along path.4

Aerial path: Assuming agent able move freely environment

restricted edges graph, simply move agent

4. navigation algorithm similar local A* search Roadmap-A* trivial case
" = 0. Roadmap-A*, shortest path target node determined known graph
agent moves along path.

640

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

current node target node via straight line connecting nodes.
method may relevant search agents highly mobile, explore
environment agents restricted travel along edges. Note
length due \aerial path" never greater length due \shortest
known path".
4.1.2 DFS-Based Navigation Algorithms

simple navigation algorithms described above, exploration new nodes done
high-level algorithm. Thus low level add new knowledge
graph, sense inecient. propose intelligent navigation
approaches nding path target pass trough unexplored nodes.
approaches provide following advantages: paths currently known
agent may much longer paths explored yet. may
prove ecient navigate unknown parts graph seem lead
better path target. important advantage navigating
unknown parts graph, agent might visit new nodes explored
explore y. may save need travel back nodes
later time, selected expansion high-level algorithm.
advantages suggest use DFS-based navigation low level.
DFS-based navigation algorithm, search agent moves neighboring node,
visited, typical DFS manner. algorithm backtracks upon reaching deadend search continues reaches target. one neighbor,
use heuristic evaluate neighbor likely lead faster target,
visit node rst. experimented following DFS-based navigation
algorithms proposed (Cucka et al., 1996):

Positional DFS (P-DFS): DFS-based navigation algorithm sorts neighbors

according Euclidean distance target node, choosing node
minimum distance target node rst.

Directional DFS (D-DFS): DFS-based navigation algorithm sorts neigh-

bors according direction edges current node v.
rst chooses node u dierence angle line segments
(v u) (v t) smallest, denotes target node. words,
nodes prioritized directional dierence target node,
giving priority nodes dier least.

A*DFS: A*DFS improved version P-DFS. step agent chooses

neighbor w minimizes sum distances current node v
w w target node t. call A*DFS since uses cost function
similar A*, i.e., f (n) = g(n) + h(n).5 Note, however, cost
function used locally nd path current node target node.

5. generalized version navigating cost function similar A* called \robotic A*" (RA*),
proposed (Cucka et al., 1996)ff node w either neighbor (of v) already visited
node.

641

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

dierent high-level A* uses cost function nd path
input initial state input goal state.
R
1

2


C

0000000000
T1111111111
0000000000
1111111111
11111111111
00000000000
0000000000
1111111111
00000000000
11111111111
0000000000D
1111111111
00000000000
11111111111
00000000000
11111111111
00000000000
11111111111

P

Figure 1: Illustration various low-level navigation algorithms.
Figure 1 illustrates navigation algorithms listed above. Let R denote source
node, suppose search agent currently node C , high-level
procedure chooses expand node . squared nodes already visited
agent, i.e., already explored. nodes edges connecting
comprise tree spanned high-level A* search. Since yet explored,
low-level procedure navigate target node . tree path navigate
along path C ; 1 ; R ; 2 ; , whereas shortest known path navigate along
path C ; 1 ; 2 ; . Note since node yet explored, path C via
known point. aerial path go directly C . Using one
DFS-based navigations, agent move via P , D, depending, respectively,
whether P-DFS, D-DFS, A*DFS used. bene DFS-based algorithms
explore new nodes navigation (nodes P , D,
example), revisit nodes, high-level procedure expand
later stage.

4.2 Enhanced PHA*
4.2.1 PHA* One-Level Procedure

mentioned previous subsection, PHA* presented principle one-level
algorithm. done follows. Whenever best node open list known
(i.e., explored), expansion cycle A* takes place background,
new best node determined. Upon arriving node, agent makes navigation
decision follows:
best node open list one current node's neighbors, agent
moves node.
Otherwise, agent moves neighboring node minimizes relevant
heuristic function (among variants proposed previous subsection).
642

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

heuristics would valid heuristic function one-level
algorithm. (The latter confused heuristic function associated
A* expansion cycle.) example, agent node v, using A*DFS
visit neighbor w minimizes sum distances current node v
w w best current node open list.
compact one-level presentation notwithstanding, prefer { reasons clarity
{ use two-level formulation PHA*. believe clear distinction
high-level A* low-level navigation procedure provides overall framework
well-structured conceptually clearly understood. addition, twolevel framework lends naturally two enhancements presented following
subsections.
enhancements draw basic principle navigation might proceed
necessarily best node, dierent node fairly close current
location agent. (The idea long run would prove bene cial.)
principle realized two main scenarios: (1) navigating best node,
agent might choose rst visit nearby neighbor, (2) procedure might choose
ignore best node open list select instead dierent node open list
close agent's location. context two-level framework,
rst scenario corresponds low-level enhancement (see I-A*DFS below), second
scenario corresponds high-level enhancement (see WinA*, subsection 4.2.3).
reasons, choose stick proposed two-level approach
PHA*.
4.2.2 Improved Low Level: I-A*DFS

DFS-based navigation algorithms explore new nodes traverse graph, thereby
avoiding future navigations nodes selected later expansion high
level. bene cial, seen experimental results next
subsection, take approach much further.
Suppose agent navigating target node. Along way, may pass near
nodes small f value without visiting them, path
target node according navigation algorithm. counter-productive, since nodes
small f values likely chosen expansion high level near future.
Visiting nodes agent nearby, may save lot traveling eort future.
order motivate agent visit nodes, want identify arti cially
decrease cost value (without changing value nodes).
incorporate notion, introduce Improved A*DFS (I-A*DFS) variant.
basic concept navigating target, low level select next node
visit considering approximate distance target node's f
value. way target, I-A*DFS tend visit, one hand, nodes
small f value, avoid visiting, hand, nodes completely track.
Let n denote, respectively, target node neighboring node
currently evaluated. Also, let f (:) denote f value node provided high-level
A*, let c1 , c2 denote constants speci ed. used following heuristic function
selecting next node I-A*DFS:
643

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu


c2
(

DFS(
n
)
1 ; c1 ff((Tn))
n 2 OPEN
h(n) =
(1)

DFS(n)
otherwise:
neighbor n open list, h(n) value due A*DFS remains intact. If,

however, neighboring node open list, I-A*DFS considers goodness
f value. node's h(n) adjusted according product term decreases
node's f value (i.e., node small f value assigned smaller heuristic)6 .
Speci cally, goodness f measured ratio f (T )=f (n). target node
smallest f value among nodes open list (for otherwise would
selected expansion high level) therefore 0 < f (T )=f (n) < 1. f (T )=f (n)
close 1, f (n) close f (T ). case, highly probable node n
visited A* next steps. Thus want assign higher priority node
visited agent, decreasing heuristic value. If, however, f (n) >> f (T )
(i.e., f (T )=f (n) ! 0), highly unlikely node n selected anytime soon
high level A*. interest raise node's priority, case,
A*DFS heuristic retained, nodes open list.
expression provided (1) meets requirements. f (n) f (T ),
term 1 ; f (T )=f (n) becomes small, overall h value node decreases.
provides agent option visit nodes open list
small f values, even though A*DFS heuristic best. If,
hand, f (n) >> f (T ), term 1 ; f (T )=f (n) approach 1, negligible eect
h(n). main reason multiplying A*DFS heuristic 1 ; f (T )=f (n) (and
f (n)=f (T ), example) leave intact cost value node relatively large
f value, continue compete (in local heuristic sense) nodes
open list. free parameters, c1 c2 , aect qualitatively
performance I-A*DFS, merely add module's overall exibility.
experimented various constants c1 c2 , attempt determine
optimal performance. extensive empirical studies shown c1 = 0:25
c2 = 2:5 produced best performance. experiments demonstrated
using I-A*DFS yielded better results obtained navigation algorithms
listed Subsection 4.1.2.
Figure 2 illustrates dierence A*DFS I-A*DFS. numeric values
nodes indicate order expanded A*. Suppose agent
currently located node C node 1 target. A*DFS navigate
target via node 5, since node best f (= g + h) value scenario described.
node 1, agent travel back side graph, node 2
selected (by high level) expanded next. agent go back node 3
eventually reach goal via node 4. I-A*DFS, hand, navigate
C node 1 via node 2 although node 2 assumed shortest path
node 1, smaller f value node 5. Thus I-A*DFS chooses visit node 2 rst.
Incorporating principle saves considerable amount travel cost. agent
located node 1 next node expanded node 2, high level
6. Since A*DFS(.) f (:) measure distances graph, represent, essentially, scale.
Thus combined directly.

644

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

R

5
1

C

3

2
4

A*DFS
I-A*DFS

G

Figure 2: example A*DFS versus I-A*DFS navigation.
expand immediately, explored agent, thus
readily available. Thus agent travel directly node 1 node 3 avoid
navigating back forth opposite sides graph.
4.2.3 Improved High-Level: WinA*

A* expands nodes open list best- rst order according f value.
order optimal complexity expanding node O(1). However, real
physical environment, node expansion requires agent perform costly tasks,
always ecient expand current best node. Consider, example, nearby node
best node open list, whose f value suciently small,
high probability would selected expansion A* next iterations.
intelligent agent choose explore node rst, even though currently
best node open list.

R
4
8

5
6

7

9

G
Figure 3: example illustrating disadvantage A*.
principle illustrated, example, subgraph Figure 3
contains two node clusters. numeric label node associated f value.
agent visiting nodes best- rst order (i.e., order A* expands them),
travel back forth one cluster other. much better approach
645

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

would explore nodes one cluster move cluster, thereby
traveling one cluster other.
order incorporate capability algorithm, generalized A*
call Window A* (WinA*). A* chooses expand node lowest f value,
WinA* creates set (i.e., window) k nodes smallest f values chooses
one node set expansion7 . window uses principle A" (Pearl
& Kim, 1982) mentioned before. constructing window select
node expansion. objective minimize traveling eort agent,
reduce, necessarily, number expanded nodes. Thus rather selecting
nodes small f value, choose nodes suciently close
location agent. experimented large number combinations,
concluded best way capturing two aspects simply taking
product. Thus order nodes window cost function

c(n) = f (n) dist(curr n)
n node evaluated, f (n) f value, dist(curr n) distance n
current location agent. choose expand node smallest cost c.
(It sensible combine f (n) dist(curr n) manner, expressed
distance units.) Note node small f value chosen
expansion, f value relative nodes open list tend decrease
time. f value newly generated nodes monotonically increasing,
heuristic used consistent admissible. property reduces chance
starvation. (At least encountered phenomenon experiments.)
intention demonstrate combining two factors, manner
favors nearby nodes small f value, indeed yields enhanced performance.
tried many functions combine two factors (e.g. weighted sum) choose
paper discuss product, c(n) = f (n) dist(curr n), since provided best
results.
Combining modi ed high-level variant low-level navigation creates
technical diculties, due fact longer expand nodes open list
best- rst order. Recall standard A* expands node generating neighbors
putting node closed list. node v closed list, shortest
path source node v known. Hence, goal expanded found
shortest path it, search terminate. However, WinA* node may
expanded although exists another node smaller f value
expanded yet. words, node v expanded, necessarily imply
best path v found. Expanding node smaller f value might
discover better path. Thus search cannot simply terminate goal node
chosen expansion.
problem solved splitting standard node expansion stage two phases:
7. related algorithm derived, k-best rst search (KBFS) (Felner, Kraus, & Korf, 2003),
window size k determined open list, window nodes expanded
stage. neighbors nodes generated added open list,
new iteration begins.

646

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

1. Node expansion. Expanding node means visiting node, generating
neighbors, adding open list. stage takes place immediately
node chosen high level.
2. Node closing. Closing node means removing open list putting
closed list. takes place nodes smaller f value
explored. ensures, essentially, node placed closed
list best path source node found (See Section 5
comments). Thus search continue, even goal node
expanded, placed closed list. goal node placed
closed list, search terminate.
Following pseudo-code WinA*. Note standard expansion divided
according two phases. end cycle, algorithm attempts
close many nodes possible.
WinA*() f
.
(goal closed-list) f
.
target = node window minimizes (node) dist(current node)
.
target unexplored
.
explore(target) low level
.
expand(target)
.
(best node (with minimal f value) open-list expanded)
.
close(best node)
.
g





f





g

4.3 Experimental Results

Figure 4: 20-node Delaunay graph.
experimented Delaunay graphs (Okabe, Boots, & Sugihara, 1992),
derived Delaunay triangulations. latter computed set planar point
patterns, generated Poisson point process (Okabe et al., 1992). Points distributed
647

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

random unit square, using uniform probability density function. Delaunay
triangulation planar point pattern constructed creating line segment
pair points (u v), exists circle passing u v encloses
point. triangulation characterized, sense, one
point joined line segment nearest neighbors points.
(We refer type Delaunay graphs regular Delaunay graphs.) used
Qhull software package (Barber, Dobkin, & Huhdanpaa, 1993) construct Delaunay
triangulations (i.e., Delaunay graphs) sets points generated random
unit square. Figure 4 illustrates 20-node Delaunay graph.
principle, characteristic whereby node connected neighbors seems
suitable representing real road maps, main object research.
practice, however, additional characteristics accommodated capture adequately real road map. Thus pursued sparse dense Delaunay graphs
obtained regular Delaunay graphs random deletion addition
edges, respectively. (See Appendix detailed discussion.)
4.3.1 Low Level Experimental Results
90
Tree path
Shrtest known path
Aerial path
P-DFS
D-DFS
A*DFS
I-A*DFS

80
70

Search cost

60
50
40
30
20
10
0
500

1000

1500
2000
2500
3000
Number nodes graph

3500

4000

Figure 5: Search cost versus number nodes regular Delaunay graphs various
low-level algorithms.
Figure 5 displays traveling distance (or search cost) agent function
number nodes Delaunay graph (i.e., 500, 1000, 2000, 4000 nodes).
graphs depicted correspond various low-level algorithms PHA* tested on.
Every data point (here experiments) corresponds average 250
dierent pairs initial goal nodes, picked random. average optimal
path observed 0.55.8 gure clearly demonstrates higher eciency
involved algorithms. particular, I-A*DFS consistently superior
algorithms graph sizes. graph size 4000, example, outperformed
8. Note closeness average optimal path observed (i.e., 0.55) expected arc length
random graph dened set points (i.e., 0.521) (Ghosh, 1951).

648

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

simple algorithm factor 10, outperformed basic A*DFS
factor 2. Note search cost increases number nodes grows,
i.e., domain becomes denser connected. attributed fact
number nodes grows, number nodes closed list I-A*DFS
procedure visit.
relative performance various algorithms considered remained
sparse dense Delaunay graphs (see Appendix A).
4.3.2 Experimental Results WinA*
6
500 nodes
1000 nodes
2000 nodes

5.5
5

Search cost

4.5
4
3.5
3
2.5
2
1.5
0

10

20

30

40
50
Window size

60

70

80

Figure 6: Search cost WinA* versus window size various sizes regular Delaunay
graphs.
experiments show using WinA* high-level procedure PHA* leads
signi cant improvement eciency algorithm. Figure 6 presents average
distance traveled search agent optimal path found, function
window size. I-A*DFS employed low-level algorithm. results shown
Figure 6 indicate using window size larger 1 (which corresponds standard
A*) signi cantly improves algorithm's performance various graph sizes
experimented with. Also, found optimal size window tends
vary size graph. Based empirical observations, setting optimal
window size (1=50) times number nodes graph seemed provide
good approximation. (For example, best window sizes observed 500- 2000-node
graphs 10 40, respectively.) Note window size becomes larger (i.e.,
number candidate nodes increases), algorithm tends select nodes large
f value, results performance degradation. Additional results sparse dense
Delaunay graphs presented Appendix A.
rst glance, improvement WinA* standard A* (for high level) seems
somewhat modest, exceed 30%. due fact I-A*DFS explores
many nearby nodes, already powerful begin with. WinA* I-A*DFS
designed assign high priority nearby nodes. dierent stages
PHA* algorithm, sense \compete" type improvement.
649

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

Indeed, using navigating algorithms, improvement WinA* relative
standard A* much signi cant. However, dealing real physical agents |
let alone humans | even 30%-time reduction WinA* (relative I-A*DFS)
viewed signi cant. Similar results obtained sparse dense Delaunay graphs
(see Appendix A).

5. Analysis PHA*
Analyzing performance PHA*, distinguish following three parameters:
(1) Cost returned path, (2) shortest possible path agent travel, (3) cost
actual path traveled agent. Subsection 5.1 argue path reported
PHA* (for future use) optimal. addition, present Subsection 5.2 extensive
empirical study compares (2) (3). Finally, provide Subsection 5.3
brief discussion PHA*'s underlying methodology overall performance.

5.1 Optimality Solution

Recall A* expands nodes best- rst order according f value. heuristic
function, h(n), admissible, f (n) = g(n)+ h(n) lower bound path goal
via node n. well-known, paradigm, goal node selected
expansion, A* found optimal path (Hart et al., 1968 Karp & Pearl, 1983 Dechter
& Pearl, 1985). Put dierently, upon goal expansion f (goal) = c, nodes
estimated paths f (n) < c already expanded length optimal
path goal c (Karp & Pearl, 1983 Dechter & Pearl, 1985).
PHA* supervised high level, activates admissible A*. (Recall
h(n) Euclidean distance n goal, i.e., admissible.) design
algorithm, high level terminates goal node selected expansion. Thus
properties admissible A*, nodes smaller f value must already
expanded, f value goal optimal. Note holds enhanced
PHA* WinA* (see Subsection 4.2.3). Although WinA* necessarily expand
nodes according best f value, designed remove node open list
smallest f value among nodes list. algorithm halts
goal node expanded removed open list, implying f value
smallest list. Thus enhanced PHA* variant compatible
admissible A* paradigm, path returns optimal. basic theoretical result
paper follows.
Theorem: PHA* enhanced versions return optimal path start
node goal.

5.2 Performance Evaluation PHA*
demonstrated above, complex algorithmic schemes provided dramatic improvement search time. interest assess, least extent, performance
best navigation variant, i.e., WinA* (for high level) conjunction I-A*DFS
(for low level).
650

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

graph
size
30
50
75
100
150
200
250
300

closed
nodes
11.32
15.45
17.93
20.32
24.12
28.43
31.57
35.78

jTSP j
0

0.62
0.74
0.77
0.85
0.91
0.99
1.02
1.05

PHA* ratio
0.80
0.94
0.97
1.10
1.27
1.42
1.48
1.51

1.29
1.27
1.22
1.29
1.39
1.43
1.45
1.44

Table 1: Comparison shortest paths nodes closed list actual paths
obtained PHA*.
agent's task visit essentially nodes expanded A*.
nodes comprise set nodes closed list algorithm terminates.
general, invoking A* subgraph induced nodes, source
goal states heuristic function, exhibit behavior yield
open closed lists. Thus given static graph, set nodes A* visit
xed. Ideally, would agent visit set closed nodes along shortest
possible path. course infeasible, since nodes known advance,
rather determined y. However, order evaluate algorithm's performance,
compare output shortest possible path travels
nodes. computation latter carried o-line, i.e., set (closed)
nodes known.
Speci cally, computed shortest possible path case respect
complete graph corresponding set closed nodes. weight w(ni nj ) associated
edge (ni nj ) (in complete graph) set length shortest path
ni nj (in original Delaunay graph instance). Finding shortest path
travels via given set nodes known traveling salesman problem (TSP),
notorious exponential running time. conventional TSP path travels
nodes returns start node. However, interested path
travels nodes without returning start node. denote path
TSP distinguish conventional TSP tour. TSP tour actually TSP tour
without last edge. view exponential nature problem, used
simple branch-and-bound tree search compute desired paths. However, solving
problem optimally feasible relatively small graph sizes.
Table 1 provides comparison PHA* shortest path travels
closed nodes various small sized graphs. table indicates PHA*
algorithm quite ecient small graphs. Speci cally, average travel cost (due
PHA*) greater shortest possible path (passing closed
0

0

651

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

nodes) 45%. graphs 200 nodes less, number closed
nodes observed smaller 30. average cost cases computed 50
random instances. graphs sizes greater 200, average cost computed
5 instances only.
order evaluate, however, performance PHA* graphs larger size (where
optimal path could computed reasonable amount time), employed
lower-bound approximation cost TSP . Speci cally, computed minimum
spanning tree (MST) complete graph (de ned set closed nodes). Let jTSP j
jMSTj denote, respectively, costs associated desired path minimum
spanning tree.
0

0

Claim:

0:5 jTSP j < jMSTj jTSP j:
0

0

Proof: claim follows basic graph theory (Cormen, Leiserson, Rivest, & Stein,

2001). Speci cally, inequality right hand side stems fact TSP
spanning tree complete graph. Thus cost minimum spanning tree must
smaller (or equal to) jTSP j.
prove inequality left hand side, note triangular inequality
holds respect de ned complete graph. (That is, three nodes, ni ,
nj , nk , w(nj nk ) w(ni nj ) + w(nj nk ).) easily shown, based fact
triangular inequality holds respect original Delaunay graphs
de nition edge weight complete graph. Thus construct tour goes
twice around MST use triangular inequality shortcut edges.
Hence
2 jMSTj jTSPj > jTSP j
0

0

0

inequality left hand side follows. 2
Given infeasible computation jTSP j, claim suggests jMSTj, instead,
reasonably good approximation. Speci cally, inequality right hand side implies
travel cost agent performing PHA* is, say, c jMSTj, travel cost
PHA* greater c jTSP j. Given merely lower bound, PHA*
expected perform better practice.
Table 2 provides comparison PHA* MST lower bound shortest
path described above. average cost entered graph size computed
250 randomly generated instances. table indicates that, average, cost
PHA* 2.74 times best possible path graph sizes 8000 nodes
corresponding sets closed nodes 460 nodes.
0

0

5.3 Discussion

repeatedly noted, algorithm returns optimal solution must expand
least nodes expanded A*. Drawing basic premise, PHA*
algorithm designed visit set \mandatory" nodes eciently possible.
rationale visiting nearby nodes (whose f value necessarily smallest)
nodes likely expanded next iterations. contrast,
652

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

graph
size
400
500
1000
2000
4000
8000

closed
nodes
40.27
43.00
62.72
131.56
233.26
460.66

jMSTj

approx.
1.05
1.15
1.42
2.01
2.52
3.45

PHA* ratio
1.91
1.97
3.03
4.89
6.76
9.44

1.82
1.87
2.13
2.43
2.69
2.74

Table 2: Comparison lower bounds shortest paths nodes closed list
actual paths obtained PHA*.
bene enhanced variation context navigation algorithm
presume return optimal solution.
Reconsider Roadmap-A*, example. A" activated prevent local navigation phase going wrong direction. However, since algorithm designed
return optimal solution, deviate stage promising route
visit nearby node may expanded later on. Put dierently, notion
set mandatory nodes agent visit. Furthermore, soon agent
reaches goal, search halts. conclusion, although PHA* Roadmap-A*
two-level navigation schemes, objectives dierent solve essentially
dierent problems.
Based properties admissible A* design algorithm,
argued (enhanced) PHA* returns path (for future use) optimal. addition,
absence theoretically known bound actual cost PHA*, run
extensive empirical study, comparing observed costs best possible costs
computed o-line. Given agent lacks priori information set mandatory
nodes, highly unlikely exists on-line PHA*-like algorithm performs
eciently o-line version. extensive empirical study demonstrates, nevertheless,
actual cost associated PHA* order magnitude optimal
cost computed o-line.

6. MAPHA*: Multi-Agent PHA*
section generalize techniques discussed previous sections multiagent case, number agents cooperate order nd shortest path. call
resulting algorithm Multi-Agent Physical A* (MAPHA*).
would divide traveling eort agents ecient way
possible. measure eciency multi-agent case using two dierent criteria.
rst overall global time needed solve problem. second total
amount fuel consumed agents search. requirement
minimize cost moving agents time important, considering fuel
653

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

cost mobilizing agents cost function choice. case, may wise
move agents agents remain idle. However, task nd best
path goal, soon possible, idle agents seem wasteful, better utilize
time exploration graph. case, available agents
moving times. introduce two algorithms two perspectives, namely
fuel-ecient algorithm time-ecient algorithm. Note single agent case
two criteria coincide.
assume agent communicate freely agents share
data time. Thus information gathered one agent available known
agents. framework obtained using model centralized
supervisor moves agents according complete knowledge gathered
them. reasonable assumption since many cases dispatcher
centralized controller gathers information agents instructs
accordingly. Another possible model complete knowledge-sharing agent
broadcasts new data graph agents. Future research may
address restrictive communication model, limiting communication range
inducing communication errors.
assume search terminates, soon goal node expanded
moved closed list. objective minimize travel eort point,
care moving agents pre-speci ed location (e.g.,
goal vertex start node), desired shortest path identi ed. convention
accordance many algorithms neglect report time spent \reset"
system (e.g., garbage collection), desired solution arrived at.
main idea MAPHA* algorithm similar PHA* single
agent. use two-level framework. high level chooses nodes expand,
low level navigates agents nodes. studied multi-agent
case enhanced techniques only, i.e., WinA* high level I-A*DFS
low level. problem deal assign dierent agents
explore eciently dierent nodes.

6.1 MAPHA*: Fuel-E cient Algorithm

simplicity, assume amount fuel consumed agent equal
traveling distance search. Since purpose algorithm case
minimize amount fuel consumed agents, regardless overall search time,
bene moving one agent time. moving
one agent, agent might gain new knowledge graph would allow
agents make informed intelligent moves.
beginning, agents situated source node. Then, case
single agent, high level de nes window unexplored nodes open list
potential candidates expansion. pair (a n), agent n
node window, compute allocation cost function
c(a n) = f (n) dist(a n)
f (n) f value node n dist(a n) denotes distance location
agent node n. select agent target node minimize allocation
654

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

function. case tie-breaking (e.g., beginning search agents
located initial state), pick randomly one agent relevant candidates.
stage, low-level algorithm navigates selected agent target node selected
window order explore node. single-agent case, additional
knowledge graph obtained navigation many unexplored
nodes visited traveling agent. selected agent reaches target
new cycle activated high- low-level procedures.9 Following pseudo-code
fuel ecient algorithm.
fuel-efficient algorithm() f
.
(goal closed-list) f
.
agent
.
select node window minimizes
.
best = agent minimizes ( i) dist( )
.
best unexplored
.
explore( best ) low level using best
.
expand( best )
.
(best node open-list expanded)
.
close(best node)
.
g








n



n

n

n



fn

n

f (n) dist(ai n)



g

6.2 MAPHA*: Time-E cient Algorithm

time-ecient algorithm similar described fuel-ecient algorithm
one basic modi cation. Instead moving one agent high-level cycle,
move available agents since care time spent
agents fuel consumption. idle agent save time.
Every moving agent help gather knowledge environment
additional cost, clock ticks away regardless time measured globally.
cannot use allocation function used fuel-ecient
algorithm, agents located initially node, fuel-ecient allocation
function choose node agents. main idea time-ecient
strategy agents move simultaneously. Thus ensure ecient performance
need distribute much possible. Suppose p available agents k
nodes window. would distribute p agents k nodes eciently
possible. brute-force approach randomly distribute agents nodes.
However, provide eective distribution, incorporate following three criteria
distribution formula time-ecient procedure:
1. Since f values neighboring nodes somewhat correlated other,
nodes small f value likely generate new nodes small f
9. implemented complex variant, whenever new unexplored node reached,
new high-level cycle activated. Results obtained signicantly dierent, omit
details variant simplicity. See (Stern, 2001) comprehensive description.

655

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

values nodes large f value. Therefore, distribution favor
assigning agent node small f value.
2. Another attribute taken consideration distance target
node agent. would assign agent one nodes
manner, expected travel distance agent (for assignment)
minimized. words, agent assigned, preferably, relatively closeby node.
3. order expand entire window prevent \starvation", would
distribution function raise priority nodes assigned small number
agents. Thus keep track number agents assigned
node give preference nodes small number assignments.
Note rst third criteria may contradict, i.e, rst criterion prefer
nodes small f value third criterion favor nodes large f value,
small number agents assigned them.
found taking product values associated three criteria
gives good distribution function suitable load balancing criteria.
Speci cally, agent allocation procedure iterates agents picks,
agent, node minimizes following allocation function:
alloc(agent node) = f (node) dist(agent node) (count(node) + 1)
dist(node agent) Euclidean distance node agent, f (node)
node's f value, count(node) counter keeps track number agents
already assigned explore node. count(node) initially set 0
incremented every time agent assigned node. Thus load balancing
three factors kept throughout distribution process. beginning
search agents located start node, initial allocation
dierent nodes determined, essentially, count factor. (Without factor,
product f (n) dist(agent n) would returned node n agents.)
search progresses, agents move dierent locations get assigned step
nodes closer location small f value. Thus product
three factors creates good distribution (of agents) dierent parts
graph.
Consider, example, case illustrated Figure 7. Suppose 100 agents
located node x, window consists three nodes a, b, c located
equal distance x. Suppose f (a) = 2, f (b) = 4 and, f (c) = 8.
numbers agents assigned nodes, using allocation procedure,
57, 29, 17, respectively. good balance various requirements.
tried many variations distribution procedure found
performed well long three requirements met. See (Stern, 2001)
discussion agent distribution.
before, agent navigates assigned target using enhanced low-level algorithm, I-A*DFS. Another high-level iteration begins soon rst agent reaches
656

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

x


b

f(a)=2

c
f(c)=8

f(b)=4

Figure 7: example agent distribution according proposed allocation procedure.
target node.10 Note computation time window agent
distribution/allocation neglected, since care travel time
agents. Following pseudo code time-ecient algorithm.
time-efficient algorithm() f
.
(goal closed-list) f
.
free agent
.
select window node minimizes dist(
.
move agents agent reaches node
.
expand nodes currently visited agent
.
(best node open-list expanded)
.
close(best node)
.
g






n

n) f (n) (count(n +1))



g

6.3 Experimental Results

experiments performed multi-agent case conducted Delaunay
graphs 500, 1000, 2000, 4000, 8000 nodes. Additional results sparse
dense Delaunay graphs provided Appendix A.
6.3.1 MAPHA*: Results Fuel-Efficient Algorithm

provide results fuel-ecient algorithm Subsection 6.1. fuel consumption reported total fuel consumed agents. (As before, graphs
generated unit square, average optimal path observed 0.55.)
Figure 8 presents costs fuel-ecient algorithm function number
agents various sizes regular Delaunay graphs. (Results sparse graphs, well
graphs edges added random, presented Appendix A.) gure clearly
10. observed new iteration begins, almost every agent assigned node
assigned previous iteration. Typically agent's location becomes
closer \its" target node, criteria change. Thus practice, agents
go complete (original) tasks, agent reached target assigned new
goal node. See (Stern, 2001) detailed discussion.

657

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

6.5
500 nodes
1000 nodes
2000 nodes
4000 nodes

6
5.5

Fuel consumption

5
4.5
4
3.5
3
2.5
2
1.5
1

2

3

4

5
6
Number agents

7

8

9

Figure 8: Fuel consumption function number agents various sizes regular
Delaunay graphs.
demonstrates agents added, overall fuel consumption decreases
point adding agents tends increase overall consumption. Thus
optimal number agents exists graphs. phenomenon due fact
A* usually characterized small number search regions. Therefore, small
number agents suces cover regions. number agents increases, fuel
consumption goes up. phenomenon explained follows. large number agents
increases likelihood nearby agent assigned speci c node,
case relatively little exploration graph takes place. Assigning, hand,
distant agent node would result larger degree graph exploration,
essential, long run, ecient navigation (especially I-A*DFS employed). Thus
large number agents navigating small graph (which search regions), would
result excessive fuel consumption. See (Stern, 2001) detailed explanation
phenomenon.
optimal number agents increases number nodes graph increases.
optimal number agents graph 500 nodes 2, number increases
7 graph size 4000. stems fact larger graphs search
regions thus agents needed explore them.
described before, one agent allowed move experiment, point
time. measured total amount fuel consumed
agents. interest nd whether work uniformly distributed among
agents, whether large portion work carried small number agents.
Table 3 presents distribution work among agents 14 agents
active Delaunay graphs size 8000. graph instance, sorted agents
decreasing order fuel consumption. table shows relative fuel consumption
agents 3, 7, 14 activated agents.
general, remark overall work uniformly distributed, quite
balanced. example, 14 agents activated, 40% work done 4
658

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

Agent No. 3 agents %] 7 agents %] 14 agents %]
1
42.03
28.34
16.01
2
33.54
19.32
13.21
3
24.43
16.23
11.41
4
12.76
10.31
5
9.02
6.64
6
7.86
5.48
7
6.48
5.08
8
4.54
9
4.10
10
3.59
11
3.20
12
3.02
13
2.81
14
2.70
Table 3: Work distribution among multiple agents running fuel-ecient algorithm
Delaunay graphs size 8000.
agents. similar tendency observed graphs sizes, well sparse
dense Delaunay graphs (see Appendix A).
order improve eciency fuel-ecient algorithm make overall
work distribution balanced, several improvements might suggested. example,
currently agents positioned initially source node. might consider
rst spread agents number directions invoke algorithm.
Notwithstanding additional overhead may incurred spreading agents,
technique result balanced work distribution reduced overall fuel
consumption.
6.3.2 MAPHA*: Results Time-Efficient Algorithm

subsection report results time-ecient algorithm Subsection 6.2.
explained, main objective conclude task fast possible,
fuel consumption concern, agents always moving, i.e., none
idle point time. overall search time case
maximal distance either agent travels shortest path goal node found.
Figure 9 shows search time obtained time-ecient algorithm function
number agents, various regular Delaunay graphs. Note search time
never smaller time takes travel along shortest path goal.
results indicate, adding agents always ecient since measure overall
time elapsed goal found. makes algorithm interesting
ecient fact add agents, search time converges asymptotically
659

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

10
500 nodes
1000 nodes
2000 nodes
4000 nodes
8000 nodes

9
8

Search time

7
6
5
4
3
2
1
0
0

2

4

6
8
Number agents

10

12

14

Figure 9: Time consumption function number agents, various regular
Delaunay graphs.
length shortest path. Recall average length observed shortest path
approximately 0.55. Indeed, large number agents tend nd optimal path
within time frame approaches limit. overall time 2.3
single agent, reduced 0.7 14 agents graphs 500 nodes example.
Using proposed agent allocation procedure, note asymptotically paths
initial state traveled breadth- rst search manner. say
suciently large team agents likely produce single agent travel along
actual shortest path little deviation it. Similar results time- ecient
algorithm obtained types graphs (see Appendix A).

6.4 Combined Requirements Fuel Time

distinction time-ecient algorithm fuel-ecient algorithm
reasonable, may suitable many practical situations. Practical considerations
time fuel resources may suggest combined approach, one described below.
Consider, example, commander operating constraint fuel consumption
restriction number troops assigned certain task.
order complete task fast possible, commander may want use maximal
possible number agents without exceeding fuel consumption limit.
essence, seek generalize MAPHA*, agents minimize cost
function combination time fuel consumption. suggest general cost
function takes account requirements measures. objective
activate MAPHA*, minimize cost function. Speci cally, suggest
following linear combination:

Ctotal = wt time + wf fuel
wt wf (normalized) weights attached, respectively, time fuel
consumption (i.e., 0:0 wt wf 1:0 wt + wf = 1:0). Ctotal calculated globally, i.e.,
660

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

measure amount time beginning task optimal path
found, total amount fuel consumed agents. multiply
quantities corresponding weights report combined cost.
wt wf prespeci ed user. wt = 0, time cost
fuel-ecient algorithm appropriate one use. wf = 0, fuel cost,
use time-ecient algorithm. Otherwise, neither wt wf 0,
use dierent algorithm minimize Ctotal.
suggest two algorithms general case.
Simple combined algorithm.
algorithm actually identical time-ecient algorithm. number
participating agents parameter provided user. iteration
high level participating agents move according allocation function
time-ecient algorithm. Given formulation total cost, Ctotal, would
determine optimal number agents, wt wf . Note
trivial case wf = 0, adding agents always valuable, since
consume resources, reduce time cost. However, wf increases,
large number agents may increase total cost.
Improved combined algorithm.
main limitation simple combined algorithm even though cost
incurred fuel consumption, agents always moving. improved combined algorithm addresses problem suggests moving agents
simultaneously. Using formalization, rst determine p, i.e., number
agents participate task. Given p, determine m, i.e., number agents actually distributed nodes selected window (by
high level). remaining p ; agents stay idle. Note simple
combined algorithm p coincide. use mechanism time-ecient
allocation function, except algorithm chooses (out p) agents
minimize allocation function. time-ecient algorithm, rst
determine size window, i.e., number nodes open list
expanded. Then, invoke allocation function. Whereas
time-ecient case allocation terminates agents assigned nodes,
allocation stops agents selected. selected agents best
agents expansion cycle since minimize allocation function.

6.5 Results Combined Algorithm

provide experimental results combined algorithm introduced
previous subsection. results Tables 4 5 obtained Delaunay graphs
size 2000 table entry represents average 250 problem instances.
column, bold face number smallest total cost corresponding wt =wf ratio.
minimal costs determine optimal number agents given wt =wf ratio.
Table 4 provides total costs simple combined algorithm function
number agents various wt =wf ratios. leftmost column corresponds case
661

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

wt
wf

1.0
0.0

# agents
1
4.82
2
2.58
3
1.74
4
1.44
5
1.24
6
1.11
7
1.03
8
0.97
9
0.93
10
0.89
11
0.85
12
0.84
13
0.84
14
0.82

0.9
0.1

0.8
0.2

4.82
2.84
2.09
1.87
1.73
1.67

4.82
3.10
2.44
2.30
2.23

1.65
1.68
1.70
1.70
1.77
1.84
1.88

2.33
2.42
2.50
2.56
2.70
2.84
2.94

2.22
1.64 2.26

0.7
0.3

0.6
0.4

0.5
0.5

0.4
0.6

4.82 4.82 4.82 4.82
3.36 3.61 3.87 4.13
2.79 3.14 3.49 3.84
2.73 3.16 3.60 4.03
2.72 3.22 3.71 4.21
2.78 3.33 3.89 4.44
2.88 3.49 4.11 4.73
3.01 3.69 4.37 5.05
3.17 3.91 4.66 5.40
3.31 4.11 4.92 5.72
3.41 4.26 5.11 5.96
3.63 4.56 5.49 6.42
3.84 4.84 5.85 6.85
4.01 5.07 6.13 7.19

0.3
0.7

0.2
0.8

0.1
0.9

0.0
1.0

4.82 4.82 4.82
4.39 4.65 4.91
4.18 4.53 4.88
4.46 4.89 5.32
4.70 5.20 5.69
5.00 5.55 6.11
5.34 5.96 6.58
5.73 6.41 7.09
6.15 6.89 7.64
6.53 7.33 8.14
6.81 7.67 8.52
7.35 8.27 9.20
7.85 8.85 9.86
8.26 9.32 10.38

4.82

5.16
5.23
5.75
6.19
6.66
7.19
7.77
8.38
8.95
9.37
10.13
10.86
11.44

Table 4: Ctotal simple combined algorithm function number agents,
various ratio wt =wf ratios.

662

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

time matters. Thus entries identical values obtained timeecient algorithm. fuel consumption becomes signi cant, longer bene cial
increase number agents thus optimal number agents decreases.
wt = wf = 0:5, Ctotal = 0:5 time + 0:5 fuel, optimal number agents obtained
three, total cost 3.49. critical fuel consumption becomes,
bene cial use smaller number agents. rightmost column corresponds
extreme case, wf = 1:0, i.e., fuel consumption matters. Note
entries column dier counterpart costs obtained fuel-ecient
algorithm. dierence stems fact that, context simple combined
algorithm, picking p agents means moving simultaneously, whereas
case fuel-ecient algorithm employed one agent (out p) allowed
move times. Note fuel-ecient algorithm essentially special case
improved combined algorithm = 1.
Table 5 provides total costs improved combined algorithm function
number agents various wt =wf ratios. number participating agents p = 14
(i.e., 14 available agents could move simultaneously). row corresponds
dierent m, i.e., actual number moving agents. (Clearly, 1 p = 14.)
before, column bold face number smallest total cost corresponding
wt =wf ratio. minimal costs determine optimal number moving agents
given wt =wf ratio.
top entry rightmost column identical cost obtained fuelecient algorithm, 14 agents. case wf = 1, one agent allowed
move point time. bottom entry leftmost column identical cost
obtained time-ecient algorithm, 14 agents. case wt = 1,
14 participating agents moving times.
signi cant fuel consumption becomes, less bene cial move many
agents. Thus optimal number moving agents decreases. example, wt = wf =
0:5, optimal number moving agents obtained three, total cost 3.23.
fuel consumption becomes crucial, would bene cial move smaller number
participating agents.
Comparing results simple combined algorithm improved
combined algorithm reveals wt =wf ratio number
moving agents (which equal number participating agents simple
combined case) improved combined algorithm usually performs better.
pick moving agents larger sample. Also, appears optimal number
moving agents smaller improved combined algorithm. algorithm,
moving agents picked clever manner cycle thus better utilized.
Additional experiments conducted graph sizes, well sparse
dense Delaunay graphs. results obtained cases rather consistent. Future
work attempt predict advance best number agents.

7. Conclusions Future Work
addressed problem nding shortest path goal node unknown
graphs represent physical environments. presented two-level algorithm,
663

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

wt
wf

1.0
0.0

# agents
1
4.02
2
2.26
3
1.61
4
1.31
5
1.13
6
1.00
7
0.92
8
0.85
9
0.82
10
0.79
11
0.77
12
0.76
13
0.75
14
0.75

0.9
0.1

0.8
0.2

0.7
0.3

4.02
2.49
1.94
1.70
1.58
1.49
1.47

4.02
2.72
2.26
2.09
2.03

4.02
2.94
2.58
2.49

2.48

1.99 2.49
2.02 2.57

1.45 2.05 2.65
1.47
1.50
1.54
1.59
1.64
1.72

2.12
2.21
2.31
2.42
2.54
2.69

2.77
2.92
3.07
3.25
3.44
3.67

0.6
0.4

0.5
0.5

0.4
0.6

0.3
0.7

4.02 4.02 4.02 4.02
3.17 3.40 3.62 3.85
2.91 3.23 3.55 3.88
2.88 3.27 3.67 4.06
2.93 3.38 3.83 4.28
2.99 3.49 3.98 4.48
3.13 3.68 4.23 4.78
3.25 3.85 4.44 5.04
3.43 4.08 4.73 5.39
3.63 4.34 5.05 5.76
3.84 4.61 5.38 6.15
4.09 4.92 5.75 6.58
4.33 5.23 6.13 7.02
4.64 5.61 6.59 7.56

0.2
0.8

0.1
0.9

0.0
1.0

4.02 4.02 4.02
4.08
4.20
4.45
4.73
4.98
5.33
5.64
6.04
6.47
6.92
7.41
7.92
8.53

4.30 4.53
4.52 4.84
4.84 5.24
5.18 5.63
5.48 5.98
5.88 6.43
6.24 6.84
6.69 7.34
7.18 7.89
7.69 8.46
8.25 9.08
8.82 9.71
9.51 10.48

Table 5: Total costs improved combined algorithm function number
moving agents (out 14 participating agents), various wt =wf values.

664

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

PHA*, environments single search agent, MAPHA* algorithm
multiple-agents. experimented several variations Delaunay graphs, containing 8000 nodes. enhanced single agent algorithm yielded signi cantly better
results ones obtained simpler variants. results fuel-ecient
algorithm show using agents bene cial extent.
agents initially located source node consume fuel
move make. reason, bene using optimal number agents
opposed one agent modest. results time-ecient algorithm
encouraging, since search time converges quickly optimum number
search agents increases. introduced cost function combines time
consumption fuel consumption, presented two algorithms paradigm.
results show combination exists optimal number agents
tends increase weight time cost increases.
Future work pursued along following directions:
assumed upon reaching node, agent learn locations
neighbors. many domains model may valid, location
node known agent actually visits it. model
suggested (Shmoulian & Rimon, 1998). research done order
implement algorithms, context model.
used traveling agents solve shortest path problem. similar mechanism might used solving known graph problems, minimum
spanning tree, traveling salesman problem, problem requires
consideration node visited next.
proposed two algorithms combining time consumption fuel consumption. algorithms assume number agents determined priori. Future
work try theoretically determine optimal number agents given constraints. Also, future work done see whether changing number
would increase eciency algorithm. Also, assumed agents
consume fuel move, measured total performance
time task. Thus idle agents consume resources. However,
think model idle agents consume resources (e.g., time energy).
assumed centralized model, agents share knowledge
times. Future work assume communication paradigms. particular,
interested model communication
agents. model known ant-robotics model (Wagner & Bruckstein, 2000
Yanovski, Wagner, & Bruckstein, 2001). model, information spread
agents pheromones, i.e., data written agent node. agents
read pheromones reaching nodes. currently working
towards applying MAPHA* algorithm model. believe
increase size data allowed written node,
agent able write complete knowledge node environment.
challenge applying A* model lies fact since A* maintains
global open list, data opposite sides graph inuence behavior
665

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

algorithm. Thus need knowledge sharing system large
possible. purpose, believe new type communication agents
introduced. Agents type try increase search frontier
rather move around environment spread recent data available.

Acknowledgments
preliminary version paper appeared Proceedings First International Joint
Conference Autonomous Agents Multi-Agent Systems, 2002 (Felner et al., 2002).
work carried rst author Bar-Ilan University. material
based upon work supported part NSF grant #0222914 ISF grant
#8008.

Appendix A. Additional Experimental Results
mentioned Subsection 4.3, node regular Delaunay graph connected
neighbors. property may always apply real road map. example,
nearby geographic locations may always connected road segment, due
existence obstacles mountain river. addition, distant locations often
connected highways. capture additional characteristics, considered so-called sparse dense Delaunay graphs. Instances variants easily
obtained regular Delaunay graphs random deletion addition edges, respectively. Speci cally, generated sparse Delaunay graph instances deleting roughly
60% edges random. Likewise, dense instances generated introducing 400
edges random. (A new edge created selecting random pair nodes.)
run algorithms presented main body paper
Delaunay graph variants. results obtained presented here.
expected, sparse graph, often agent runs deadends. Indeed, algorithms required additional travel eort nd optimal path
edges removed. However, ratio travel cost two algorithms
seems remain (for various Delaunay graph types), I-A*DFS exhibits
superior performance graph instances. See Figures 10(a), (b). behavior proved
consistent experiments, single agent multi-agent environment.
Also, Figures 11(a), (b) exhibit similar behavior search cost WinA* versus window
size sparse Delaunay graphs dense Delaunay graphs, respectively, observed
regular Delaunay graphs (see Figure 6).
Figures 12(a), (b) present costs fuel-ecient algorithm function
number agents various sizes sparse dense Delaunay graphs, respectively.
overall fuel consumption recorded sparse Delaunay graphs larger fuel
consumption recorded counterpart regular graphs (see Figure 8) factor
1.5. graphs simulating highways (i.e., dense graphs) fuel consumption
decreases relative sparse regular Delaunay graphs.
Note optimal number agents navigating sparse graph increases, since
agents need backtrack often case. Thus agents assist
666

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

100

45
Tree path
Shrtest known path
Aerial path
P-DFS
D-DFS
A*DFS
I-A*DFS

90
80

35
30

60

Search cost

Search cost

70

Tree path
Shrtest known path
Aerial path
P-DFS
D-DFS
A*DFS
I-A*DFS

40

50
40

25
20
15

30

10

20

5

10
0
500

1000

1500
2000
2500
3000
Number nodes graph

3500

0
500

4000

1000

1500
2000
2500
3000
Number nodes graph

3500

4000

(a)
(b)
Figure 10: Search cost versus number nodes of: (a) Sparse Delaunay graphs, (b)
dense Delaunay graphs various low-level algorithms.

7

5
500 nodes
1000 nodes
2000 nodes

6.5

500 nodes
1000 nodes
2000 nodes

4.5

6
4

5

Search cost

Search cost

5.5

4.5
4
3.5

3.5

3

2.5

3
2
2.5
2

1.5
0

10

20

30

40
50
Window size

60

70

80

0

10

20

30

40
50
Window size

60

(a)
(b)
Figure 11: Search cost WinA* versus window size various sizes of: (a) Sparse Delaunay
graphs, (b) dense Delaunay graphs.

667

70

80

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

7.5

3
500 nodes
1000 nodes
2000 nodes
4000 nodes

7
6.5

2.6
2.4
Fuel consumption

6
Fuel consumption

500 nodes
1000 nodes
2000 nodes
4000 nodes

2.8

5.5
5
4.5

2.2
2
1.8

4

1.6

3.5

1.4

3

1.2

2.5

1
1

2

3

4

5
6
Number agents

7

8

9

1

2

3

4

5
6
Number agents

7

8

9

(a)
(b)
Figure 12: Fuel consumption function number agents various sizes of: (a)
Sparse Delaunay graphs, (b) dense Delaunay graphs.
search. hand, adding random edges graphs causes opposite eect,
i.e., less fuel consumed optimal number agents reduced. explained
fact new edges add connections nodes, i.e., many "shortcuts"
created search carried faster smaller number agents.
11

4.5
500 nodes
1000 nodes
2000 nodes
4000 nodes
8000 nodes

10
9

3.5

8
7

3
Search time

Search time

500 nodes
1000 nodes
2000 nodes
4000 nodes
8000 nodes

4

6
5

2.5
2

4
3

1.5

2
1

1
0

0.5
1

2

3

4

5
6
Number agents

7

8

9

1

2

3

4

5
6
Number agents

7

(a)
(b)
Figure 13: Time consumption function number agents various sizes of: (a)
Sparse Delaunay graphs, (b) dense Delaunay graphs.
Figures 13(a), (b) present costs time-ecient algorithm function
number agents various sizes sparse dense Delaunay graphs, respectively.
results con rm tendency observed regular Delaunay graphs (see
668

8

9

fiPHA*: Finding Shortest Path A* Unknown Physical Environment

Figure 9), namely number agents grows, overall cost converges
length optimal path.

References
Argamon-Engelson, S., Kraus, S., & Sina, S. (1998). Utility-based on-line exploration
repeated navigation embedded graph. Articial Intelligence, 101(1-2), 967{984.
Argamon-Engelson, S., Kraus, S., & Sina, S. (1999). Interleaved vs. priori exploration
repeated navigation partially-known graph. International Journal Pattern
Recognition Articial Intelligence, 13(7), 963{968.
Barber, C. B., Dobkin, D. P., & Huhdanpaa, H. (1993). Quickhull algorithm convex
hull. Tech. rep., Geometry Center Technical Report GCG53, University Minnesota.
Bellman, R. (1958). routing problem. Quarterly Applied Mathematics, 16 (1), 87{90.
Bender, M. A., Fernandez, A., Ron, D., Sahai, A., & Vadhan, S. P. (1998). power
pebble: Exploring mapping directed graphs. Proceedings Thirtieth
Annual ACM Symposium Theory Computing, pp. 269{278, Dallas, Texas.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms. MIT Press, Cambridge, Massachusetts. 2nd edition.
Cucka, P., Netanyahu, N. S., & Rosenfeld, A. (1996). Learning navigation: Goal nding
graphs. International Journal Pattern Recognition Articial Intelligence,
10(5), 429{446.
Dechter, R., & Pearl, J. (1985). Generalized best- rst search strategies optimality
A*. Journal Association Computing Machinery, 32(3), 505{536.
Dijkstra, E. W. (1959). note two problems connexion graphs. Numerische
Mathematik, 1, 269{271.
Felner, A., Kraus, S., & Korf, R. E. (2003). KBFS: K-best rst search. Annals Mathematics Articial Intelligence, press.
Felner, A., Stern, R., & Kraus, S. (2002). PHA*: Performing A* unknown physical environments. Proceedings First International Joint Conference Autonomous
Agents Multi-Agent Systems, pp. 240{247, Bologna, Italy.
Ghosh, B. (1951). Random distances within rectangle two rectangles. Bulletin
Culcutta Mathematical Society, 43, 17{24.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination minimum cost paths. IEEE Transactions Systems Science Cybernetics,
SCC-4(2), 100{107.
Kaelbling, L. P., & Moore, A. W. (1996). Reinforcement learning: survey. Journal
Articial Intelligence Research, 4, 237{285.
Karp, R., & Pearl, J. (1983). Searching optimal path tree random costs.
Articial Intelligence, 21(1-2), 99{116.
669

fiFelner, Stern, Ben-Yair, Kraus, & Netanyahu

Kitamura, Y., Teranishi, K., & Tatsumi, S. (1996). Organizational strategies multiagent real-time search. Proceedings Second International Conference
Multi-Agent Systems, 409{416.
Knight, K. (1993). many reactive agents better deliberative ones?.
Proceedings Thirteenth International Joint Conference Articial Intelligence,
pp. 432{437, Chamb$ery, France.
Koenig, S., & Likhachev, M. (2002a). D* lite. Proceedings Eighteenth National
Conference Articial Intelligence (AAAI), pp. 476{483, Edmonton, Canada.
Koenig, S., & Likhachev, M. (2002b). Incremental A*. Advances Neural Information
Processing Systems 14 (NIPS). MIT Press, Cambridge, MA.
Korf, R. E. (1985). Depth- rst iterative-deepening: optimal admissible tree search.
Articial Intelligence, 27(1), 97{109.
Korf, R. E. (1990). Real-time heuristic search. Articial Intelligence, 42(3), 189{211.
Korf, R. E. (1993). Linear-space best- rst search. Articial Intelligence, 62(1), 41{78.
Korf, R. E. (1997). Finding optimal solutions Rubik's Cube using pattern databases.
Proceedings Fourteenth National Conference Articial Intelligence, pp.
700{705, Providence, Rhode Island.
Korf, R. E. (1999). Sliding-tile puzzles Rubik's Cube AI research. IEEE Intelligent
Systems, 14, 8{12.
Okabe, A., Boots, B., & Sugihara, K. (1992). Spatial Tessellations, Concepts, Applications Voronoi Diagrams. Wiley, Chichester, UK.
Pearl, J., & Kim, J. H. (1982). Studies semi-admissible heursitics. IEEE Transactions
Pattern Analysis Machine Intelligence, 4, 392{400.
Shmoulian, L., & Rimon, E. (1998). Roadmap-A*: algorithm minimizing travel eort
sensor based mobile robot navigation. Proceedings IEEE International
Conference Robotics Automation, pp. 356{362, Leuven, Belgium.
Stentz, A. (1994). Optimal ecient path planning partially-known environments.
Proceedings IEEE International Conference Robotics Automation,
pp. 3310{3317, San Diego, CA.
Stern, R. (2001). Optimal Path Search Unknown Physical Enviroments. M.Sc.
Thesis, Department Computer Science, Bar-Ilan University, Israel available
http://www.cs.biu.ac.il/felner.
Taylor, L., & Korf, R. (1993). Pruning duplicate nodes depth- rst search. Proceedings
Eleventh National Conference Articial Intelligence, pp. 756{761, Washington, D.C.
Wagner, A., & Bruckstein, A. M. (2000). ANTS: Agents, networks, trees, subgraphs.
Future Generation Computer Systems Journal, 16(8), 915{926.
Yanovski, V., Wagner, I. A., & Bruckstein, A. M. (2001). Vertex-ant-walk: robust method
ecient exploration faulty graphs. Annals Mathematics Articial Intelligence, 31(1-4), 99{112.
670


