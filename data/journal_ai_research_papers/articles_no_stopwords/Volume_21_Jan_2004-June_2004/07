Journal Artificial Intelligence Research 21 (2004) 393-428

Submitted 07/03; published 03/04

Personalized System Conversational Recommendations
Cynthia A. Thompson

cindi@cs.utah.edu

School Computing
University Utah
50 Central Campus Drive, Rm. 3190
Salt Lake City, UT 84112 USA

Mehmet H. Goker

mgoker@kaidara.com

Kaidara Software Inc.
330 Distel Circle, Suite 150
Los Altos, CA 94022 USA

Pat Langley

langley@isle.org

Institute Study Learning Expertise
2164 Staunton Court
Palo Alto, CA 94306 USA

Abstract
Searching making decisions information becoming increasingly difficult amount information number choices increases. Recommendation
systems help users find items interest particular type, movies restaurants, still somewhat awkward use. solution take advantage
complementary strengths personalized recommendation systems dialogue systems,
creating personalized aides. present system Adaptive Place Advisor
treats item selection interactive, conversational process, program inquiring item attributes user responding. Individual, long-term user preferences
unobtrusively obtained course normal recommendation dialogues used
direct future conversations user. present novel user model influences item search questions asked conversation. demonstrate
effectiveness system significantly reducing time number interactions
required find satisfactory item, compared control group users interacting
non-adaptive version system.

1. Introduction Motivation
Recommendation systems help users find select items (e.g., books, movies, restaurants)
huge number available web electronic information sources (Burke,
1999; Resnick & Varian, 1997; Burke, Hammond, & Young, 1996). Given large set
items description users needs, present user small set items
well suited description. Recent work recommendation systems includes
intelligent aides filtering choosing web sites (Eliassi-Rad & Shavlik, 2001), news
stories (Ardissono, Goy, Console, & Torre, 2001), TV listings (Cotter & Smyth, 2000),
information.
users systems often diverse, conflicting needs. Differences personal
preferences, social educational backgrounds, private professional interests
pervasive. result, seems desirable personalized intelligent systems
c
2004
AI Access Foundation. rights reserved.

fiThompson, Goker, & Langley

process, filter, display available information manner suits individual
using them. need personalization led development systems adapt
changing behavior based inferred characteristics user
interacting (Ardissono & Goy, 2000; Ferrario, Waters, & Smyth, 2000; Fiechter
& Rogers, 2000; Langley, 1999; Rich, 1979).
ability computers converse users natural language would arguably
increase usefulness flexibility even further. Research practical dialogue systems,
still infancy, matured tremendously recent years (Allen, Byron, Dzikovska,
Ferguson, Galescu, & Stent, 2001; Dybkjr, Hasida, & Traum, 2000; Maier, Mast, &
Luperfoy, 1996). Todays dialogue systems typically focus helping users complete
specific task, planning, information search, event management, diagnosis.
paper, describe personalized conversational recommendation system designed help users choose item large set basic type. goal
support conversations become efficient individual users time.
system, Adaptive Place Advisor, aims help users select destination (in
case, restaurants) meets preferences.
Adaptive Place Advisor makes three novel contributions. knowledge,
first personalized spoken dialogue system recommendation, one
conversational natural language interfaces includes personalized, long-term user
model. Second, introduces novel model acquiring, utilizing, representing user
models. Third, used demonstrate reduction number system-user interactions conversation time needed find satisfactory item.
combination dialogue systems personalized recommendation addresses weaknesses approaches. dialogue systems react similarly user interacting
them, store information gained one conversation use future.
Thus, interactions tend tedious repetitive. adding personalized, long-term
user model, quality interactions improve drastically. time,
collecting user preferences recommendation systems often requires form filling
explicit statements preferences users part, difficult time consuming. Collecting preferences course dialogue lets user begin task
item search immediately.
interaction conversation personalized recommendation affected choices acquisition, utilization, representation user models.
Adaptive Place Advisor learns information users unobtrusively, course
normal conversation whose purpose find satisfactory item. system stores
information use future conversations individual. acquisition
utilization occur items presented chosen user,
search items. Finally, systems representation models goes
beyond item preferences include preferences item characteristics particular values characteristics. believe ideas extend types
preferences types conversations.
paper, describe work Adaptive Place Advisor. begin
introducing personalized conversational recommendation systems, presenting
design decisions along way. Section 3 describe system detail,

394

fiPersonalized Conversational Recommendation

Section 4 present experimental evaluation. Sections 5 6 discuss related
future work, respectively, Section 7 conclude summarize paper.

2. Personalized Conversational Recommendation Systems
research goals two-fold. First, want improve interaction quality
recommendation systems utility results returned making user adaptive
conversational. Second, want improve dialogue system performance means
personalization. such, goals user modeling differ commonly assumed
recommendation systems, improving accuracy related measures precision
recall. goals differ previous work user modeling dialogue
systems (Haller & McRoy, 1998; Kobsa & Wahlster, 1989; Carberry, 1990; Kass, 1991),
emphasizes ability track users goals dialogue progresses,
typically maintain models across multiple conversations.
hypothesis improvements efficiency effectiveness achieved
using unobtrusively obtained user model help direct systems conversational search
items recommend. approach assumes large database items
choose, reasonably large number attributes needed describe
items. Simpler techniques might suffice situations database small
items easy describe.
2.1 Personalization
Personalized user adaptive systems obtain preferences interactions users,
keep summaries preferences user model, utilize model generate
customized information behavior. goal customization increase
quality appropriateness interaction result(s) generated
user.
user models stored personalized systems represent stereotypical users (Chin,
1989; Rich, 1979) individuals, hand-crafted learned (e.g., questionnaires, ratings, usage traces), contain information behavior
previously selected items, preferences regarding item characteristics (such location
price), properties users (such age occupation) (Kobsa & Wahlster,
1989; Rich, 1979). Also, systems store user models duration one interaction user (Carberry, Chu-Carroll, & Elzer, 1999; Smith & Hipp, 1994), whereas
others store long term (Rogers, Fiechter, & Langley, 1999; Billsus & Pazzani,
1998).
approach learn probabilistic, long-term, individual user models contain
information preferences items item characteristics. chose learned models
due difficulty devising stereotypes reasonable initial models new domain
encountered. chose probabilistic models flexibility: single user
exhibit variable behavior preferences relative rather absolute. Long-term
models important allow influence across multiple conversations. Also, already
noticed, different users different preferences, chose individual models. Finally,
preferences items item characteristics needed influence conversations
retrieval.
395

fiThompson, Goker, & Langley

decision made learn models, another design decision relates method
system collects preferences subsequent input learning algorithm(s).
distinguish two approaches. direct feedback approach places
burden user soliciting preference information directly. example, system
might ask user complete form asks classify weight interests using
variety categories item characteristics. recent study (McNee, Lam, Konstan,
& Riedl, 2003) showed forcing user provide ratings items (movies,
case) choose, rather system chooses, actually lead
better accuracy rates better user loyalty. However, users irritated need
complete long questionnaires even begin enjoy given service,
study context dialogue system involved simpler interaction.
Another, slightly less obtrusive, form direct feedback encourages user provide
feedback continues use particular service.
second approach acquiring user models, one taken Adaptive
Place Advisor, infer user preferences unobtrusively, examining normal online behavior (Fiechter & Rogers, 2000; Rafter, Bradley, & Smyth, 2000). feel unobtrusive
collection preferences advantageous, requires less effort user. Also, users
often cannot articulate preferences clearly learn domain.
possible disadvantage unobtrusive approaches users may trust understand
systems actions change one interaction next. could
addressed letting user view modify user model (Kay & Thomas, 2000).
Systems typically take one two approaches preference determination. Contentbased methods recommend items similar ones user liked past (Segal &
Kephart, 1999; Pazzani, Muramatsu, & Billsus, 1996; Lang, 1995). contrast, collaborative
methods select recommend items users similar current user liked
previous interactions (Cotter & Smyth, 2000; Billsus & Pazzani, 1998; Konstan, Miller,
Maltz, Herlocker, Gordon, & Riedl, 1997; Shardanand & Maes, 1995). collaborative
filtering bases recommendations previous selections users, suitable
new one-off items users uncommon preferences. content-based approach,
hand, uses item description recommendation, therefore
prone problems. However, content-based techniques tend prefer attribute
values users preferred past, though allow new combinations
values. feel benefits content-based approach outweigh disadvantages;
discuss methods overcoming disadvantages combining two techniques
Section 6.3.
Ultimately, personalization one utilize learned user profile search
for, identify, present relevant information right user right way right
time. User models utilized recommendation systems content processing
selection (information filtering), navigation support web browsers (Pazzani et al., 1996),
choice modality style presentation interaction (Brusilovsky & Maybury,
2002). Adaptive Place Advisor adapts information filtering interaction
behavior, since relevant application since majority
interaction natural language.

396

fiPersonalized Conversational Recommendation

2.2 Conversational Recommendation
goal recommendation systems help users find items interest, thus
must eliminate choices consideration keeping others. achieve this,
must either know determine interests current user, present items
satisfy interests.
One widely used approaches information acquisition recommendation
systems use simple form (usually single query box) user fills in. Coupled
this, common presentation format ranked list approach. scheme,
system presents usually long list results, ordered predicted relevance
user. combined technique information acquisition form presentation
list originated information retrieval, used help find documents
reports library research. basic method, refer ranked list
approach, general, however, underlies simpler search engines
World Wide Web, used regularly many different selection tasks.
contrast, Adaptive Place Advisor supports conversations mode
interaction. approach, one conversational participant, call inquirer,
asks second participant, call advisor, assistance selecting item.
example, inquirer deciding restaurant dinner, conversation
may proceed follows:
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.

Inquirer: think eat tonight?
Advisor: type food would like?
Inquirer: types there?
Advisor: say things Chinese, Indian, Mediterranean.
Inquirer: Oh, maybe cheap Indian place.
Advisor: kind parking would like?
Inquirer: dont care, long Palo Alto.
Advisor: Im sorry, dont know restaurants that, would search
price?
Inquirer: No, think Id Chinese instead.
Advisor: Mandarin Gourmet 420 Ramona sound?1
Inquirer: No, else have?
Advisor: Jing-Jing Szechwan Hunan Gourmet 443 Emerson Street?
Inquirer: Sure, sounds fine.

refer systems mimic approach recommendation conversational
recommendation systems.
interaction supported conversational recommendation systems quite different
found ranked list approach. important distinction
interaction takes form sequence questions, designed eliminate items
consideration. Answering questions plays similar role giving keywords
form, aim remove alternatives rather rank results list.
1. system support exact sample dialogue. example, point conversation
displays information restaurant screen asks one sound?
similar question.

397

fiThompson, Goker, & Langley

conversational process help inquirer better understand desires, since
thinking possible questions answers may clarify goals ways keyword entry
encourage. addition, conversation support user variability letting
user control item attribute choices conversation. Finally, inquirer never
hears complete item choices remain. avoids presenting
long list items lets user narrow choices iterative, manageable
fashion.
dialogues seem better recommendations must delivered speech rather
visually, example engaged inquirer driving. seem
ideal, independent modality, tasks destination selection help-desk support
(Goker & Roth-Berghofer, 1999; Aha & Breslow, 1997), user needs converge
items. hand, keyword entry ranked list methods seem
appropriate situations user prefers provide requirements once,
situations information presented visually, situations user
may want examine many options.
eliminating options, conversational recommendation systems ultimately direct
users suitable solution. However, conversation become tiring quality
first result returned may acceptable user. interactions
friend knows concerns directed produce better results
stranger, dialogues conversational advisor become efficient
effective time. goals user modeling include improvement subjective
quality effectiveness results (found items) conversation leads
results. example, several conversations inquirer above, new
interaction may proceed follows, question parking eliminated
item presentation order changed:
1.
2.
3.
4.
5.
6.
7.

Inquirer:
Advisor:
Inquirer:
Advisor:
Inquirer:
Advisor:
Inquirer:

think eat tonight?
type food would like?
Oh, maybe Chinese place.2
city prefer?
something Palo Alto?
Jing-Jing Szechuan Gourmet 443 Emerson sound?
Sure, sounds fine.

turn next design choices concerning management conversations.
2.3 Conversation via Dialogue Management
Dialogue systems carry conversations users natural language, whether spoken
typed. main tasks performed dialogue systems language interpretation, language
generation, dialogue management. Natural language interpretation generation
topics onto discuss here; two introductory texts,
see Allen (1995) Jurafsky Martin (2000). enable focus user modeling,
system allows moderately complex user utterances pre-coded set system
utterances, discussed Section 3.3.
2. response shows Inquirer learned use system efficiently well.

398

fiPersonalized Conversational Recommendation

simplest dialogue managers based finite-state automata states
correspond questions arcs correspond actions depend user-provided
response (Stent, Dowding, Gawron, Bratt, & Moore, 1999; Winograd & Flores, 1986).
systems support called fixed- system-initiative conversations,
one participants controls actions, whether system helping user
user asking questions system. Next complexity frame- template-based
systems questions asked answered order (Bobrow et al., 1977).
Next, true mixed-initiative systems allow either dialogue participant contribute
interaction knowledge permits (Allen, 1999; Haller & McRoy, 1998; Pieraccini,
Levin, & Eckert, 1997). Thus, conversational focus change time due
users (or systems) initiative change. Finally, different approaches support
sophisticated dialogues include plan-based systems (Allen et al., 1995; Cohen & Perrault,
1979) systems using models rational interaction (Sadek, Bretier, & Panaget, 1997).
allow reasonably complex conversations keeping system design straightforward, chose frame-based approach dialogue management. Thus, Adaptive Place Advisor allows conversational flexibility fully system-initiative
paradigm would allow. Users fill attributes addition suggested system. However, cannot force system transition new subtasks,
system negotiate users determine participant take
initiative.
2.4 Interactive Constraint-Satisfaction Search
Constraint-satisfaction problems provide general framework defining problems interest many areas artificial intelligence, scheduling satisfiability (Kumar,
1992). general form, constraint-satisfaction problems involve set variables
whose domains finite discrete, along set constraints defined
subset variables limit value combinations variables take.
goal find assignment values variables satisfies given constraints.
Cucchiara, Lamma, Mello, Milano (1997) define class interactive constraintsatisfaction problems involve three extensions standard formulation. First,
include constraint acquisition stage user incrementally add new
constraints problem solved. Second, variables domain include
defined undefined portion, user add new values defined portion
constraint acquisition. Third, allow incremental update partial solution
based domain constraint updates.
framework encompass item search portion conversations managed
Adaptive Place Advisor; include item presentation portion.
setting, constraints simply attribute-value specifications, cuisine = Chinese.
Place Advisors search fully general framework,
incorporate notion undefined portions domains. However, acquire
constraints via users specifications conversation incrementally updates
solutions response.

399

fiThompson, Goker, & Langley

System Output
(Voice)

Prompts

User Input
(Voice)

Speech Generator

Speech Recognizer

System Operators
Values

User Operators
Values
Domain
Model

Dialogue Manager

Conversation History

User
Models

Initial Query

Recognition
Grammars

Results,
Attribute Information

User Modeling
System

Updated Query

Retrieval Engine

Item
Database

Figure 1: Components Adaptive Place Advisor interactions.

3. Adaptive Place Advisor
section, first present overview Adaptive Place Advisors functioning,
follow details components.3 system carries number tasks
support personalized interaction user; particular, it:










utilizes user model initialize probabilistic item description expanded query,
generates context-appropriate utterances,
understands users responses,
refines expanded query explicit requirements (constraints) obtained
user conversation,
retrieves items matching explicitly specified part query database,
calculates similarity retrieved items query,
selects next attribute constrained relaxed conversation
number highly similar items acceptable,
presents suitable items number items acceptable,
acquires updates user model based interactions.

responsibilities tasks distributed among various modules system,
shown Figure 1. Dialogue Manager generates, interprets, processes conversations; updates expanded query user interaction. Retrieval Engine
case-based reasoning system (Aamodt & Plaza, 1994) uses expanded query
retrieve items database measure similarity users preferences.
User Modeling System generates initial (probabilistic) query updates longterm user model based conversation history. Speech Recognizer Speech
Generator handle users input control systems output, respectively.
3. discussed Section 5.2, approach destination advice draws earlier analysis
task Elio Haddadi (1998, 1999).

400

fiPersonalized Conversational Recommendation

find items recommend user, Place Advisor carries augmented
interactive constraint-satisfaction search. goal entire conversation present
item acceptable user. constraint-satisfaction portion,
system carries conversation find small set items. search
phase, two situations determine systems search operators thus questions. First,
under-constrained specification means many items match constraints,
system must obtain information user. Second, matching items,
system must relax constraint, thus allowing items contain domain value
relaxed attribute.4 system ends search phase small number items
match constraints highly similar (based similarity threshold) users
preferences. Item presentation (in similarity order) begins point, similarity
computation used rank items satisfy constraints.
search item presentation process influenced User Modeling System
thus personalized. main mechanism personalization expanded
query, probabilistic representation users preferences, long-term (over many
conversations) short-term (within conversation). often refer
query, always refers constraints explicitly implicitly specified
user. Thus, query expanded beyond explicit (short-term) constraints
using (long-term) constraints implicit user model. sense, initial query
represents constraints system thinks user probably want. system
incrementally refines query course conversation user, setting
explicit, firm constraints user verifies disconfirms assumptions. long
term, User Modeling System updates user model based users responses
attributes items offered conversation.
Retrieval Engine searches database items match explicit constraints
query. computes similarity retrieved items users preferences
reflected expanded part query. Depending number highly similar results, Retrieval Engine determines attribute constrained
relaxed.
sum, system directs conversation manner similar frame-based system,
retrieves ranks items using case-based reasoning paradigm, adapts weights
similarity calculation based past conversations user, thereby personalizing
future retrievals conversations. section, present details Adaptive
Place Advisors architecture. describing user model, elaborate
Retrieval Engine Dialogue Manager. Finally, discuss system updates
user model user interacts it.
3.1 User Model
focus personalized conversation suggests fine-grained model user preferences,
emphasizing questions user prefers answer responses tends give,
addition preferences entire items. describe model detail.
later sections, describe influences item ranking question ordering,
4. constraints later modified, system lets user later specify value, even
one caused over-constrained situation.

401

fiThompson, Goker, & Langley

Table 1: Example user model.
User Name

Homer

Attributes

wi

Cuisine

0.4

Values probabilities
Italian

French

Turkish

Chinese

German

English

0.35

0.2

0.25

0.1

0.1

0.0

0.2

one

two

three

four

five

0.3

0.3

0.1

0.1

...

...

0.2
...

Parking

0.1

Price Range

Item Nbr.
Accept/Present

Valet

Street

Lot

0.5

0.4

0.1

0815

5372

7638

...

6399

23 / 25

10 / 19

33 / 36

...

12 / 23

turn determine quickly system stop asking questions start presenting
items. general, user may tend to:





answer questions attributes often others,
provide attribute values often others,
choose items often others,
provide certain combinations values often independent distribution
would predict,
accept either large small amounts value item diversity.

tendencies influenced users preferences, turn captured
user model. Attribute preferences represent relative importance user places
attributes (e.g., cuisine vs. price) selecting item. Preferred values show users
bias towards certain item characteristics (e.g., Italian restaurants vs. French restaurants).
Item preferences reflected users bias certain item, independent
characteristics. Combination preferences represent constraints combined occurrence
item characteristics (e.g., accepts restaurants San Francisco valet
parking). Diversity preferences model time needs pass item
characteristic suggested users tolerance unseen values items. Item
preferences related single items, whereas attribute, value, combination preferences
applicable search items general. Diversity preferences relate
items search.
Currently, Adaptive Place Advisor models preferences user may
attributes, values, items, combination diversity preferences.
former easily captured either probability distributions counts, illustrated
Table 1. Place Advisor maintains probability distribution represent attribute
preferences independent probability distributions represent preferences attributes set values. attribute preferences, system uses domain knowledge
initialize weights; example, price usually considered important park-

402

fiPersonalized Conversational Recommendation

ing. absence information, case value preferences, system
begins uniform distribution.
system represents item preferences ratio number times item
accepted number times presented; initialized assuming
items presented accepted large percentage (nine ten, 90%)
time. may cause updates (see below) small effect undesirable
items suggested once, effect quickly discounting alternatives
early learning process. turn encourages user explore alternatives,
allowing system learn additional items. sum, item preferences represent
probability user accepting particular item presented, rather
representing probability distribution items.
3.2 Retrieval Engine
place, user model affects behavior system Retrieval
Engine, interacts database retrieve items, any, satisfy currently agreed upon constraints. module interacts query determine
similar items users preferences determine best ordering
attributes constraining relaxing, appropriate. types interactions
user model support goal quickly narrowing search satisfactory item.
Similar way human advisor bases assumptions regarding inquirer
previous interactions, system uses cumulative experience, reflected user model,
basis computation. Retrieval Engine represents users preferences
requirements expanded query, partial, probabilistic item specification determined
conversation user model. query initialized user model,
thus contains preference-based probabilities attributes values user
yet explicitly specified along users item preferences. course
conversation, system updates query reflect values user specifies.
attribute, sets probability value agreed upon conversation 1.0,
probabilities zero. example, user says Chinese Italian,
system sets value probabilities Chinese Italian 1.0, cuisine
probabilities zero. equivalent disjunction probabilistic queries, one
value combination specified user.5
first main aspect Retrieval Engine personalized item ranking
technique. Unlike typical case-based similarity computation, retrieves items beyond
match query exactly, computation used system restricts retrieved
items desirable user. system filters items included
current case base according characteristics explicitly specified user sorts
remaining items according similarity items user liked past.
Thus, Engine first queries database retrieve items match current
constraints exactly.6 Then, Place Advisor uses probability distributions
query compute likely user choose item. system calculates
5. user study described Section 4, users specified disjunctive query.
6. attributes user selected one value, assume supplied value would
acceptable.

403

fiThompson, Goker, & Langley

similarity current query, Q, item, using
Sim(Q, I) = RI

n
X

wj P (Vj ) ,

j=1

RI users item preference ratio item I, n number attributes, wj
weight attribute j Q, Vj value attribute j I, P (Vj )
value preference (probability Q) value. Similarity formula based
user model search state. Thus, unconstrained attribute, estimates
probability user accept items value attribute.
system calculates similarity item, compares items similarity constant
similarity threshold, retains items exceed threshold.
second main personalized aspect Retrieval Engine ranking attributes
under- over-constrained situations. helps assure user likely
respond informatively systems questions under-constrained situations,
allow suggested attribute relaxed over-constrained situations.
situations, one option order attributes randomly, technique used
simple dialogue systems. Another option use conditional entropy measure select
attributes (see Section 6.1). third rank attributes order desirability
user, reflected user model, take option.
addition using long term user model rank attributes, system uses
attribute weights reflected query. see see later querys
attribute weights, initialized user model, influenced conversation. over-constrained situation, attribute ranking order highest lowest,
under-constrained situation, reverse.7 Using attribute weights rather
conditional entropy avoids pitfalls arise continuously changing value
distribution data (new restaurants, restaurants going business, etc.).
affect attribute rankings, users may confused resulting variability.
even worse, would reflect users preferences. Further, every question
high information gain high relevance user selecting destination (e.g., parking
options may high score asked user decided
cuisine location.)
summary, user model influences item retrieval, item ranking, attribute ranking, turn influence systems utterances conversation.
3.3 Conversing User
converses user, Dialogue Manager uses results Retrieval Engines
functions. system uses frame containing simple list constraints support
interactive constraint-satisfaction search (see Jurafsky et al. 1994 Dowding et al. 1993
similar formulation). usual type system, user respond
system request fill constraint ignoring attribute specifying value
7. CBR systems necessarily use weighting factors similarity computation
question ordering. However, application area, correct make assumption
attributes importance impact similarity computation.

404

fiPersonalized Conversational Recommendation

Table 2: Speech acts supported Adaptive Place Advisor.
System Speech Acts
Attempt-Constrain
Suggest-Relax
Recommend-Item
Quit-Start-Mod
Provide-Values
Clarify

Asks question obtain value attribute.
Asks question remove values attribute.
Recommends item satisfies constraints.
States matching items remain asks whether
modify search, start over, quit.
Lists small set values attribute.
Asks clarifying question.

User Speech Acts
Provide-Constrain
Accept
Reject
Provide-Relax
Start-Over
Quit
Query-Values

Provides value attribute.
Accepts relaxation suggestion item generated system.
Rejects systems proposed attribute, relaxation attempt, item.
Provides attribute value removal.
Indicates desire reinitialize constraints begin again.
Indicates desire stop conversation.
Asks information possible values attribute.

Table 3: Dialogue State.
Variable

Description

Constrained
Rejected
Fixed
Constrain
Relax
Query
Number-of-Items

Attributes whose values specified.
Attributes whose value user declined provide.
Constrained attributes user indicated relaxed.
next attribute constrain, any.
next attribute relax, any.
Probability model desired item constraints.
Number database items matching query exceeding
similarity threshold.
matching items ranked similarity order.
Items user rejected.
users recently uttered speech act.
systems recently uttered speech act.

Ranked-Items
Rejected-Items
User-Move
System-Act

different one(s) instead (Goddeau et al., 1996; Ward & Issar, 1996). speech acts
supported listed Table 2.
two main phases dialogue, interactive constraint-satisfaction portion
item presentation portion. constraint-satisfaction portion divided
over- under-constrained situations. dialogue state (Table 3) determines
systems utterance range responses expected point. system updates
dialogue states variables appropriate throughout conversation.

405

fiThompson, Goker, & Langley

Table 4: Sample Conversation.
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.

Inquirer:
Advisor:
Inquirer:
Advisor:
Inquirer:
Advisor:
Inquirer:
Advisor:
price?
Inquirer:
Advisor:
Inquirer:
Advisor:
Inquirer:

think eat tonight?
type food would like?
types there?
say things Chinese, Indian, Mediterranean.
Oh, maybe cheap Indian place.
kind parking would like?
dont care, long Palo Alto.
Im sorry, dont know restaurants that, would search
No, think Id Chinese instead.
Mandarin Gourmet 420 Ramona sound?
No, else have?
Jing-Jing Szechwan Hunan Gourmet 443 Emerson Street?
Sure, sounds fine.

detail, systems speech act (or move) interactive constraint-satisfaction determined Number-of-Items dialogue state variable. Further, speech
act determines speech recognition grammar employ interpret users next
utterance. common situation many items (more small threshold, three) match current constraints.8 situation, system makes
Attempt-Constrain move, asks user fill value attribute.
move, responded appropriately user, would reduce number items
considered satisfactory user. attribute Constrain one ranked
highest Retrieval Engine already Constrained Rejected.
first sample conversation, repeated Table 4, utterances 2 6 illustrate AttemptConstrains system.
One user response Attempt-Constrain Provide-Constrain,
provides value specified attribute additional attributes, utterances 5
7. second possible response Reject, user indicates disinterest
dislike attribute, first part utterance 7. illustrated
examples, user combine one move single utterance.
second situation, over-constrained query, occurs items
satisfy agreed upon constraints similar enough users preferences,
thus Retrieval Engine returns empty set (Number-of-Items = 0). case,
system performs Suggest-Relax move informs user situation asks
would relax given constraint. attribute Relax chosen Retrieval
Engines highest ranked attribute9 already Fixed. illustrated
utterance 8 conversation Table 4. utterance 9 conversation, user
respond rejecting (Reject) systems suggestion accept (Accept).
former case, attribute Fixed system try relax again.
8. discuss number items matching constraints, refer items remain
similarity filtering discussed Section 3.2.
9. Recall Section 3.2 actually lowest ranking attribute user model.

406

fiPersonalized Conversational Recommendation

combination either speech acts, user specify attributes
relax addition to, instead of, system-suggested attribute (Provide-Relax).
items satisfy constraints, system ends interactive search
begins suggest items user (Recommend-Item) order similarity,
utterances 10 12 above. user either accept reject item. user
accepts item (Accept), system ends conversation, reached goal
state. user rejects item (Reject), system presents alternative,
remain. Note three meanings Reject speech acts user,
two meanings Accept speech acts, since user accept AttemptConstrain providing explicit value attribute constrained.
three special situations covered above. first query
over-constrained, user Fixed attributes could relaxed. second
user rejected items match constraints. two situations,
system informs user situation, asks whether would quit, start
over, modify search (Quit-Start-Mod), reacts accordingly. third special
situation Number-of-Items exceeds presentation threshold, attributes
Constrained Rejected. case, Place Advisor begins present
items user.
support spoken natural language input output, use speech recognition package Nuance Communications, Inc. package lets us write different
recognition grammar situations described use human-recorded
prompts (rather text-to-speech). string words recognized system
parsed using recognition grammars wrote, used users without
adaptation. Future work could include personalized recognition grammars well personalized information preferences. grammars use semantic tags fill slot:
besides slots attribute, define slots rejection acceptance systems
suggestions. complex domains, sophisticated parsing methods may required, simple scheme gives user reasonably diverse set utterance options.
Nuance modules generate response user requests help (Query-Values)
Provide-Values speech act, enter clarification dialogues confidence
recognized utterance given threshold (Clarify). currently simple
interactions system provides examples answers recently uttered
prompt, asks user repeat themselves.
Finally, item presentation portion dialogue only, system displays
restaurant information (name, address, phone number) screen, outputs
spoken prompt one? chose presentation modality due
reluctance use text-to-speech generation large number prompts would
record produce spoken language restaurant. However, note
user still responds spoken reply, feel presentation mode
substantially influenced user-modeling behavior Place Advisor.
system-user interaction affects subsequent rounds database retrieval similarity calculation via updates expanded query. Table 5 shows effects relevant
speech acts query, turn used similarity calculation described
Section 3.2. table, shortened names system moves
sake brevity.
407

fiThompson, Goker, & Langley

Table 5: effects speech acts query. Key: Constrain = AttemptConstrain, Relax = Suggest-Relax, Recommend = Recommend-Item.
System-Move

User-Move

Effect Query

Constrain

ProvideConstrain

Constrain
Relax
Recommend
Relax
Recommend



Reject
Reject
Reject
Accept
Accept
Provide-Relax
Start-Over

Set probabilities provided values one.
Set probability values constrained attributes
zero. attribute rejected previously, reset
attribute probability user model.
Drop attribute setting probability zero.
effect; Dialogue Manager selects next attribute.
Update item preference counts (see Section 3.4).
Reset value probabilities attribute user model.
Update item preference counts (see Section 3.4).
Reset value probabilities attribute user model.
Initialize user model.

3.4 Updating User Model
main contribution addition personalization conversational recommendation model. user model (Section 3.1) represents personalization,
Adaptive Place Advisor must update appropriately. adaptive recommendation systems (Smyth & Cotter, 1999; Linden, Hanks, & Lesh, 1997; Pazzani et al.,
1996; Lang, 1995) require user provide direct feedback generate user model,
basic approach unobtrusively derive user preferences. Thus, system
introduce unnecessary interactions, learns interactions needed support
item recommendation. describe system gathers item, attribute, value
preferences. described fully below, system modifies feature value weights
(Fiechter & Rogers, 2000; Zhang & Yang, 1998; Bonzano, Cunningham, & Smyth, 1997;
Wettschereck & Aha, 1995) latter two, increases counts ratio
accepted presented items.
determining points dialogue update user model,
considered several factors. wanted enable system acquire information quickly,
discourage making erroneous assumptions. thought users might
explore search space constraining attributes, decided
system update value preferences user-specified constraint. However,
instead chose allow model updates item suggestion, learning process
might slow. choices described are, feel, good tradeoff
extremes.
three circumstances chose user model update (1) users
Accept speech acts Suggest-Relax situation, (2) users Accept speech
acts Recommend-Item situation, (3) users Reject speech act
Recommend-Item speech act system. First, assume user accepts
item, indicating: (1) preference item itself, (2) preferences attributes

408

fiPersonalized Conversational Recommendation

constrained find item, (3) preferences values provided
attributes. Thus, user accepts item presented system, probabilities
appropriate item, attributes, values increased. item preference,
system simply adds one presentation acceptance counts. attribute
value preferences, system increases probability appropriate weight small
amount proportional current weight, renormalizes weights. Thus attribute
value preferences biased measures avoid zero counts values user
never chooses, typical type probabilistic representation.
Second, user rejects item presented system, assume
dislike particular item. assume anything characteristics
item, since user specified characteristics. Therefore, rejected
items system simply adds one presentation count.
third situation system updates user model when, query
become over-constrained, presents attribute relaxation user accepts
relaxation. situation, assume that, matching item,
user would satisfied it, since characteristics specified conversation
far satisfactory. Therefore, relaxation occurs, system increases
attribute preferences constrained attributes increases value preferences
user-specified values, manner similar Accept situation RecommendItem. enables Adaptive Place Advisor quickly make inferences
users preferences.

4. System Evaluation
stated earlier, believe user modeling increases effectiveness efficiency
conversations system time. test hypothesis, carried
experiment version Adaptive Place Advisor recommends restaurants
San Francisco Bay Area. system describes items using seven attributes: cuisine,
rating, price, location, reservations, parking options, payment options. attributes
values, cuisine location dozens. approximately 1900 items
database.
asked several users, Bay Area, interact system help
decide go eat. users given external guidance instructions
types restaurants select, look choose
might actually patronize. experimenter present interactions,
filmed, help needed except rare occasions subject repeatedly
tried words included speech recognition grammar.
4.1 Experimental Variables
test hypothesis benefits personalization Adaptive Place Advisor, controlled two independent variables: presence user modeling
number times user interacted system. First, anticipated
users might improve interactions Place Advisor time, divided
subjects experimental modeling group control group. 13 subjects
modeling group interacted version system updated user model
409

fiThompson, Goker, & Langley

described Section 3.4. 11 subjects control group interacted version
update model, selected attributes items default
distribution described Section 3.1. Naturally, users unaware assigned
group. Second, since predicted systems interactions would improve time,
gained experience user, observed behavior successive points along
learning curve. particular, subject interacted system around 15
successive sessions. tried separate subjects sessions several hours,
always possible. However, general subjects use system actually
help decide eat either day near future; provide
constraints telling system knew restaurants Bay
Area.
determine versions efficiency recommending items, measured several
conversational variables. One average number interactions needed find
restaurant accepted user. defined interaction cycle started
system providing prompt ended systems recognition users utterance
response, even response answer question posed prompt.
measured time taken conversation. began start transaction
button pushed ended system printed Done (after user accepted
item quit).
collected two statistics depended whether user modeling
effect. First number system rejections, is, number times
system either obtain recognition result confidence low.
either case system asked user repeat himself. Since measure
recognition quality effects personalization, omitted count
interactions. second, serious problem speech misrecognition error
system assigned utterance different meaning user intended.
Effectiveness, thus subjective quality results, somewhat difficult
quantify. wanted know users degree satisfaction systems behavior.
One indication rejection rate: proportion attributes
system asked subject care (Rejects Attempt-Constrain situations).
second measure hit rate: percentage conversations first item
presented acceptable user. Finally, administered questionnaire users
study get subjective evaluations.
4.2 Experimental Results
results experiment generally supported hypothesis respect efficiency.
provide figures show average values users particular group, error
bars showing 95% confidence intervals. x axis always shows progression users
interactions system time: point nth conversation completed
either finding acceptable restaurant quitting.
Figure 2 shows that, modeling group, average number interactions required
find acceptable restaurant decreased 8.7 5.5, whereas control group
quantity actually increased 7.6 10.3. used linear regression characterize
trend group compared resulting lines. slope modeling line

410

fi4

6

8

Number interactions
10
12
14
16

Personalized Conversational Recommendation

2

Modeling

0

Control

0

1

2

3

4

5

6

7

8

9

10

11 12 13 14 15
Conversation number

Figure 2: Average number interactions per conversation.
differed significantly (p = 0.017) control line, former smaller
latter, expected.
difference interaction times (Figure 3) even dramatic. modeling
group, quantity started 181 seconds ended 96 seconds, whereas control
group, started 132 seconds ended 152 seconds. used linear regression
characterize trends group time found significant difference
(p = 0.011) two curves, slope modeling subjects smaller
control subjects. note measures include
time system initialization (which could 10% total dialogue time).
instead used start time first system utterance dialogue, difference
two conditions would even clearer.
speech recognizer rejected 28 percent interactions study. Rejections
slow conversation introduce errors. misrecognition rate much
lower occurred seven percent interactions experiment. feel
rates acceptable, expanding number supported utterances
could reduce first number further, potentially increasing second.
common recognition error, Adaptive Place Advisor inserted extra constraints
user intend.
results effectiveness ambiguous. Figure 4 plots rejection rate
function number sessions. decrease rejection rate time would mean that,
system gains experience user, asks fewer features irrelevant
user. However, dependent variable found significant difference (p = 0.515)
regression slopes two conditions and, indeed, rejection rate
neither group appears decrease experience. negative results may due
rarity rejection speech acts experiment. Six people never rejected constraint

411

fi50

100

Time per conversation
150
200
250

Thompson, Goker, & Langley

Modeling

0

Control

0

1

2

3

4

5

6

7

8

9

10

11 12 13 14 15
Conversation number

Figure 3: Average time per conversation.
average person used 0.53 Reject speech acts Attempt-Constrain
per conversation (standard deviation = 0.61).
Figure 5 shows results hit rate, indicate suggestion accuracy stayed
stable time modeling group decreased control group. One explanation latter, expect, control users became less satisfied
Place Advisors suggestions time thus carried exploration
item presentation time. However, concerned difference
two groups. Unfortunately, slopes two regression lines significantly
different (p = 0.1354) case.
analyzed questionnaire presented subjects experiment. first
six questions (see Appendix A) check boxes assigned numerical values, none
revealed significant difference two groups. second part
questionnaire contained open-ended questions users experience
Adaptive Place Advisor. general, subjects groups liked system
said would use fairly often given opportunity.
4.3 Discussion
summary, experiment showed Adaptive Place Advisor improved
efficiency conversations subjects gained experience time,
improvement due systems update user models rather subjects
learning interact system. conclusion due significan differences
user modeling control groups, number interactions time
per conversation. significance holds even face large error bars small
sample size. turn implies differences large system could make
substantial difference users.
412

fiNumber rejections
1.5
2
2.5

Personalized Conversational Recommendation

Modeling

0

0.5

1

Control

0

1

2

3

4

5

6

7

8

9

10

11 12 13 14 15
Conversation number

Figure 4: Rejection rate modeling control groups.
results effectiveness ambiguous, trends right direction
significant differences modeling control groups. Subjects
conditions generally liked system, found significant differences along
dimension. larger study may needed determine whether differences occur.
user studies warranted investigate source differences
two groups. One plausible explanation items presented sooner, average,
user modeling group control group. measured value (i.e.,
average number interactions first item presentation) current study
found decrease user modeling group (from 4.7 3.9) increased
control group (from 4.5 5.8). reasonably large difference difference
slope two regression lines statistically significant (p=0.165). larger study
may needed obtain significant difference. general, however, interaction
user model order questions asked, turn influences
number items matching point conversation. turn determines
soon items presented conversation. Therefore, items presented often
user modeling group, largest influence user model due item accepts
rejects.

5. Related Research
Previous research related topics roughly broken three areas, first
focusing personalized recommendation systems, second conversational interfaces,
third adaptive dialogue systems. restrict discussion
strongly related work.

413

fiHit rate
1.5

Thompson, Goker, & Langley

Modeling

0.0

0.5

1

Control

0

1

2

3

4

5

6

7

8

9

10

11 12 13 14 15
Conversation number

Figure 5: Hit rate modeling control groups.
5.1 Personalized Recommendation Systems
Although research personalized recommendation systems become widespread
recent years, basic idea traced back Rich (1979), discussed
work conversational interfaces. Langley (1999) gives thorough review recent
research topic adaptive interfaces personalization.
Several adaptive interfaces attempt collect user information unobtrusively.
interesting example Casper project (Rafter et al., 2000), online recruitment
service. project investigates methods translate click read-time data
accurate relevancy information, given raw data inherently noisy. Similarly,
Goecks Shavlik (2000) describe technique learning web preferences observing
users browsing behavior. Another example Adaptive Route Advisor (Rogers
et al., 1999), recommends driving routes specified destination. system
collects preferences attributes number turns driving time basis
users selections modifications systems proposed routes.
Adaptive Place Advisor uses constraint-based interaction search
items, interaction approach item search. alternative taken
candidate/critique, tweaking, approach. Tweaking systems, Find
suite (Burke, 1999), typically require user begin interaction filling values
predetermined attributes. present item, point user
opportunity change search parameters try find desirable item. Eaton,
Freuder, Wallace (1997) take similar approach Matchmaking system.
addition, exploit constraint satisfaction manage search. Neither Find
suite Matchmaking system, however, learns user models. related system
include learning component Shearin Lieberman (2001), learns
attribute preferences unobtrusively. tweaking valid method, appropriate,
414

fiPersonalized Conversational Recommendation

feel, environment speech interaction mode, since presenting
user options would somewhat cumbersome. Even though current system
presents options search constrained, limits number items presented.
Even full speech version seem onerous.
5.2 Conversational Interfaces
considerable ongoing work area conversational systems, evidenced
general surveys Dybkjr et al. (2000) Maier et al. (1996). Zukerman
Litman (2001) give thorough overview user modeling dialogue systems. Rich
(1979) reported one earliest (typewritten) conversational interfaces, focused
book recommendation. beginning interaction, system asked several
questions place user stereotype group, thereby initializing user model.
conversation progressed, model adjusted, system using ratings
represent uncertainty. However, language understanding capabilities system
limited, mostly allowing yes/no user answers. recently, dialogue systems utilize
models users beliefs intentions aid dialogue management understanding,
though typically systems maintain models course single conversation
(Kobsa & Wahlster, 1989).
noted Section 2.3, important distinction whether one conversational
participant keeps initiative, whether initiative switch participants.
Two ambitious mixed-initiative systems planning tasks Trains (Allen et al., 1995)
recent Trips (Allen et al., 2001). Place Advisor, programs interact user progressively construct solution, though knowledge structures
partial plans rather constraints, search involves operators plan modification rather database contraction expansion. Trains Trips lack
mechanism user modeling, underlying systems considerably mature
evaluated extensively.
Smith Hipp (1994) describe another related mixed-initiative system limited
user modeling, case conversational interface circuit diagnosis. system
aims construct plan set constraints, rather proof tree. central
speech act, requests knowledge user would aid proof process,
invoked program detects missing axiom needs reasoning.
heuristic plays role system Place Advisors heuristic
selecting attributes constrain item selection. interface infers user knowledge
course single conversation, long term approach.
respect dialogue management, several previous systems used method
similar frame-based search. particular, Seneff et al. (1998) Dowding et al.
(1993) developed conversational interfaces give advice air travel. Place
Advisor, systems ask user questions reduce number candidates, treating
flight selection interactive construction database queries. However, question
sequence typically fixed advance, despite clear differences among individuals
domain. Also, systems usually require constraints specified item
presentation begins.

415

fiThompson, Goker, & Langley

alternative technique selecting questions ask information elicitation presented Raskutti Zukerman (1997). overall system necessitates
system recognize plans user attempting carry out. system must
decide best complete plans. insufficient information available plan
formation, system enters information seeking subdialogue similar constraintsatisfaction portion dialogues. system decide question ask based
domain knowledge based potential informativeness question.
Another approach dialogue management conversational case-based reasoning
(Aha, Breslow & Munoz-Avila, 2001), relies interactions user retrieve
cases (items) recommend actions correct problem. speech acts
basic flow control much common Adaptive Place Advisor,
process answering questions increasingly constrains available answers. One significant
difference approach generates several questions items, respectively, time,
user selects question answer item closest needs,
respectively.
Finally, approach draws alternative analysis item recommendation, described Elio Haddadi (1998, 1999). main distinctions work
approach include personalization, distinguish search
task space discourse space, combine two,
place greater emphasis user intentions. Keeping distinction task
discourse space personalized system would unnecessarily complicate decisions
perform user model updates utilize model.
5.3 Adaptive Dialogue Systems
Finally, another body recent work describes use machine learning forms
adaptation improve dialogue systems.10 Researchers area develop systems
learn user preferences, improve task completion, adapt dialogue strategies
individual conversation.
closest work pursues goal learning user preferences. Carberry et al.
(1999) report one example consultation dialogues, take different approach.
system acquires value preferences analyzing users explicit statements
preferences acceptance rejection systems proposals. uses discrete
preference values instead fine-grained probability model. Also, system
use preferences item search item presentation time help evaluate
whether better alternatives exist. Finally, evaluation based subjects judgements
quality systems hypotheses recommendations, characteristics
actual user interactions. could, however, incorporate item search ideas,
allowing near misses user-specified constraints actual items.
Another system focuses user preferences interactive travel assistant (Linden
et al., 1997) carries conversations via graphical interface. system asks
questions goal narrowing available candidates, using speech acts similar
ours, aims satisfy user interactions possible. approach
10. work adaptation speech recognition grammars (e.g., Stolcke et al., 2000), related, addresses different problem uses different learning techniques, discuss here.

416

fiPersonalized Conversational Recommendation

minimizing number interactions use candidate/critique approach.
users responses, system infers model represented weights attributes price
travel time. Unlike Adaptive Place Advisor, carry profiles
future conversations, one envision version so.
Several authors use reinforcement learning techniques improve probability
process task completion conversation. example, Singh et al. (2002) use
approach determine systems level initiative amount confirmation
user utterances. goal optimize, users, percentage dialogues
given task successfully completed. system leverages learned information
interacting users, rather personalizing information. Also, Levin,
Pieraccini, Eckert (2000) use reinforcement learning determine question
ask point information seeking search, demonstrate utility
approach real users.
Finally, number systems adapt dialogue management strategy course
conversation based user responses dialogue characteristics. example,
Litman Pan (2002) use set learned rules decide whether user difficulty
achieving task, modify level system initiative confirmation accordingly.
Maloor Chai (2000) present help-desk application first classifies user
novice, moderate, expert based responses prompts. adjusts complexity
system utterances, jargon, complexity path taken achieve goals.
Horvitz Paek (2001) apply user modeling dialogue system uses evidence
current context conversation update Bayesian network. network
influences spoken language recognition hypothesis causes appropriate adjustments
systems level initiative. Chu-Carroll (2000) describes system adapts
language generation initiative strategies individual user within single dialogue.
Also, Jameson et al. (1994) use Bayesian networks system take role
either buyer seller transaction, changes inquiry sales strategy
based beliefs inferred participants utterances.

6. Directions Future Work
results date Adaptive Place Advisor promising much remains
done. section, discuss ways make search model flexible,
expand conversational model, enrich user model learning technique.
consider extensive evaluations system.
6.1 Search Model
respect search mechanism, first plan investigate alternative techniques
using item similarity values determine return, example cutting
items point similarity drops steeply, instead current use
threshold. note work Cohen, Schapire, Singer (1999)
learning rank instances could apply nicely work, augmenting current
item ranking scheme. Additionally, plan develop version system generates
alternative items values over-constrained situation (Qu & Beale, 1999). One way
would use preferences estimate strength stated constraint,
417

fiThompson, Goker, & Langley

merge preference-based similarity metric traditional domain-specific
similarity metric (Pieraccini et al., 1997). plan evaluate effect making
even stronger assumptions user preferences. example, system certain
enough value preference, may ask question associated
attribute.
final improvement search mechanism concerns techniques ranking attributes constraining relaxing. attribute constraint ranking, implemented yet evaluated conditional entropy measure (Goker & Thompson, 2000).
system selects attribute constrain determining attribute highest
conditional entropy among unconstrained attributes. scheme would useful
ranking attributes relax. Therefore, system simply determines size case
base would result attribute relaxed, ranks case bases smallest
largest, orders attributes accordingly, excluding attributes that, relaxed,
would still result empty case base. plan investigate combination
user model information gain, well alternative attribute ranking techniques one used Abella, Brown, Buntschuh (1996). Another option
add personalization otherwise adapt variable selection techniques used
constraint-satisfaction solvers.
6.2 Conversational Model
plan progress towards complex dialogues complex constraints. First,
plan increase number speech acts available user. example, add
confirmation dialogues improve current clarification dialogues, thus allowing
types adaptation strategies, Singh et al. (2002). longer term investigation,
plan extend adaptation techniques handle complex travel planning dialogues
(Seneff, Lau, & Polifroni, 1999; Walker & Hirschman, 2000). may require additions
user model, preferences regarding language dialogue style, including
initiative, system verbosity, vocabulary. turn need appropriately
acquired utilized system. general, insights already gained
utilizing acquiring user preferences different junctures dialogue search
process prove useful supporting personalization tasks.
6.3 User Model
improve user model, first plan add types preferences. discussed
Section 3.1, combination diversity preferences capture complex user behavior
current model, plan incorporate next version
system. Combination preferences help better predict either values acceptable
attributes, based previously provided constraints. Place Advisor model
value combination preferences learning association rules (Agrawal, Imielinski, & Swami,
1993) extending Bayesian network, either would influence query,
turn influencing similarity calculation case base. preferences
acceptable attribute combinations, system learn conditional probabilities based
past interactions use influence attribute ranking.

418

fiPersonalized Conversational Recommendation

drifting preferences likely cause problems item selection applications might ones news updates, model could extended handle
within-user diversity. One way capture users desired time interval suggestion particular item value. calculate determining
mean time interval users explicit selection rejection value (value diversity
preferences) item (item diversity preferences). incorporate diversity
preferences similarity calculation Section 3.2 extending RI P (Vj )
equation incorporate time effects. define RD (I) PD (Vj ) as:
1

RD (I) = RI

1+

PD (Vj ) = P (Vj )

ekI (ttI tID )
1

,
1+
current time, tI tV time item value last selected,
tID tV time differences user wants item
value suggested again. RD PD form sigmoid function kI kV
determine curves slope. One empirical question whether users attribute
diversity preferences. hypothesize diversity preferences differ value
attribute, implicitly overrides attribute diversity. example, user
may different preferences frequency expensive restaurants versus
cheap ones suggested, may care often questions price asked.
plan investigate hypothesis.
improvements might add user modeling technique. example, system may learn quickly updates user model dialogue situations
current three. Also, using collaborative user models initialize individual
models could speed learning process. explicit combination collaborative
individual user models (Melville, Mooney, & Nagarajan, 2002; Jameson & Wittig, 2001)
viable direction explore.
ekV (ttV tV )

6.4 Evaluation
Finally, planning carry larger user study. must verify
differences study due task difficulty differences since control
difficulty finding particular item. particular, different values
constraints may result number matching items. even though two
users answered number questions, number matching items one
user may small enough system begin presenting them, user
may need answer additional questions first. support expanded evaluation,
implemented version system recommends movies, let us draw
broader user base. help us measure user satisfaction easily, Walker
et al. (1998) noted efficiency important consideration,
users might tend prefer predictable interfaces.

419

fiThompson, Goker, & Langley

7. Conclusions
paper, described intelligent adaptive conversational assistant designed help
people select item. Overall, made significant inroads methods unobtrusively
acquiring individual, long term user model recommendation conversations.
expanded previous work adaptive recommendation systems conversational, dialogue systems user adaptive. long-term goal
develop even powerful methods, capable adapting users needs, goals,
preferences multiple conversations. leveraged feedback conversation recommendation, feedback likely present tasks
planning scheduling.
two key problems addressed research design adaptive recommendation systems conversations interaction mode, addition personalization dialogue systems, starting dialogues recommendation. Thus, unlike
many recommendation systems accept keywords produce ranked list, one
carries conversation user progressively narrow options. solving
problems, introduced novel approach acquisition, use, representation
user models. Unlike many adaptive interfaces, system constructs utilizes
user models include information beyond complete item preferences. key
support personalization conversations. used relatively simple model dialogue
focus issues involved personalization. described experimental results
showing promise technique, demonstrating reduction number
interactions conversation time users interacting adaptive system
compared control group.
course, still several open questions opportunities improvement.
user model, conversational model, search models functional plan improve
further. extending conversational approach items
destinations, books movies, plan link system assistants
Adaptive Route Advisor (Rogers et al., 1999). goal additions
provide new functionality make Adaptive Place Advisor attractive
users, test generality approach adaptive recommendation.
turn, bring us closer truly flexible computational aides carry natural
dialogues humans.

Acknowledgments
research carried first author Center Study
Language Information, Stanford University, authors DaimlerChrysler Research Technology Center Palo Alto, California. thank Renee Elio,
Afsaneh Haddadi, Jeff Shrager initial conception design Adaptive
Place Advisor, Cynthia Kuo Zhao-Ping Tang help implementation effort,
Stanley Peters enlightening discussions design conversational interfaces.
Robert Mertens Dana Dahlstrom crucial carrying user studies.

420

fiPersonalized Conversational Recommendation

Appendix A. Questionnaire
1. think interaction system,
0
1
talk

much

2

3

4
5
right
amount
talking

6

7

8

enough
talking

2. easy find restaurant liked?
0
1

easy

2

4

easy

3. system deliver restaurants liked?
0
yes

1

2

4


4. Please rate interaction system scale standard humancomputer-interaction person person conversation via telephone.
0
1
2
humancomputer
interaction

3

4

5

6
phone
conversation

5. think APA useful system?
0
yes

1

2

3

4


6. think conversation significantly distracting similar conversation real person?
0


1

2

3

4
yes

421

fiThompson, Goker, & Langley

References
Aamodt, A., & Plaza, E. (1994). Case-based reasoning: Foundational issues, methodological
variations, system approaches. Artificial Intelligence Communications, 7, 3959.
Abella, A., Brown, M. K., & Buntschuh, B. (1996). Development principles dialog-based
interfaces. Proceedings ECAI-96 Spoken Dialog Processing Workshop, pp.
17. Budapest, Hungary.
Agrawal, R., Imielinski, T., & Swami, A. (1993). Mining association rules sets
items large databases. Buneman, P., & Jajodia, S. (Eds.), Proceedings
1993 ACM SIGMOD International Conference Management Data, pp. 207216.
Washington, D.C. ACM Press.
Aha, D., & Breslow, L. (1997). Refining conversational case libraries. Proceedings
Second International Conference Case-Based Reasoning, pp. 267278. Providence,
RI. Springer Verlag.
Aha, D., Breslow, L., & Munoz Avila, H. M. (2001). Conversational case-based reasoning.
Applied Intelligence, 14, 932.
Allen, J. (1999). Mixed-initiative interaction. IEEE Intelligent Systems, September/October,
1416.
Allen, J., Byron, D., Dzikovska, M., Ferguson, G., Galescu, L., & Stent, A. (2001). Towards
conversational human-computer interaction. AI Magazine, 22, 2737.
Allen, J., Schubert, L., Ferguson, G., Heeman, P., Hwang, C. H., Kato, T., Light, M.,
Martin, N., Miller, B., Poesio, M., & Traum, D. (1995). TRAINS project:
case study building conversational planning agent. Journal Experimental
Theoretical AI, 7, 748.
Allen, J. F. (1995). Natural language understanding (second edition). Benjamin/Cummings,
Menlo Park, CA.
Ardissono, L., & Goy, A. (2000). Tailoring interaction users web stores. User
Modeling User-Adapted Interaction, 10, 251303.
Ardissono, L., Goy, A., Console, L., & Torre, I. (2001). adaptive system personalized access news. AI Communications, 14, 129147.
Billsus, D., & Pazzani, M. (1998). Learning collaborative information filters. Proceedings
Fifteenth International Conference Machine Learning, pp. 4654. Madison,
WI. Morgan Kaufmann.
Bobrow, D., Kaplan, R., Kay, M., Norman, D., Thompson, H., & Winograd, T. (1977).
Gus, frame driven dialog system. Artificial Intelligence, 8, 155173.

422

fiPersonalized Conversational Recommendation

Bonzano, A., Cunningham, P., & Smyth, B. (1997). Using introspective learning improve
retrieval CBR: case study air traffic control. Proceedings Second International Conference Case-Based Reasoning, pp. 413424. Providence, RI. Springer
Verlag.
Brusilovsky, P., & Maybury, M. (2002). Introduction special section adaptive web.
Communications ACM, 45, 3033.
Burke, R. (1999). Wasabi personal shopper: case-based recommender system.
Proceedings Sixteenth National Conference Artificial Intelligence, pp. 844
849. Orlando, FL. AAAI Press.
Burke, R., Hammond, K., & Young, B. (1996). Knowledge-based navigation complex
information spaces. Proceedings Thirteenth National Conference Artificial
Intelligence, pp. 462468. Portland, OR. AAAI Press.
Carberry, S. (1990). Plan recognition natural language dialogue. MIT Press, Cambridge,
MA.
Carberry, S., Chu-Carroll, J., & Elzer, S. (1999). Constructing utilizing model
user preferences collaborative consultation dialogues. Computational Intelligence
Journal, 15, 185217.
Chin, D. (1989). KNOME: Modeling user knows UC. Kobsa, A., & Wahlster,
W. (Eds.), User models dialog systems, pp. 74107. Springer Verlag, Berlin.
Chu-Carroll, J. (2000). MIMIC: adaptive mixed initiative spoken dialogue system
information queries. Proceedings Sixth Conference Applied Natural Language Processing, pp. 97104. Seattle, WA. AAAI Press.
Cohen, P. R., & Perrault, C. (1979). Elements plan-based theory speech acts.
Cognitive Science, 3, 177212.
Cohen, W., Schapire, R., & Singer, Y. (1999). Learning order things. Journal Artificial
Intelligence Research, 10, 243270.
Cotter, P., & Smyth, B. (2000). PTV: Intelligent personalized TV guides. Proceedings
Twelfth Innovative Applications Artificial Intelligence Conference, pp. 957964.
Austin, TX. AAAI Press.
Cucchiara, R., Lamma, E., Mello, P., & Milano, M. (1997). Interactive constraint satisfaction. Tech. rep. DEIS-LIA-97-00, University Bologna.
Dowding, J., Gawron, J., Appelt, D., Bear, J., Cherny, L., Moore, R., & Moran, D. (1993).
Gemini: natural language system spoken-language understanding. Proceedings Thirty-first Annual Meeting Association Computational Linguistics, pp. 5461. Columbus, OH. Association Computational Linguistics.
Dybkjr, L., Hasida, K., & Traum, D. (Eds.). (2000). Proceedings 1st SIGdial
Workshop Discourse Dialogue, Hong Kong. Association Computational
Linguistics.
423

fiThompson, Goker, & Langley

Eaton, P., Freuder, E., & Wallace, R. (1997). Constraint-based agents: Assistance, cooperation, compromise. Proceedings CP97 Workshop Constraint Reasoning
Internet. Schloss Hagenberg, Austria.
Eliassi-Rad, T., & Shavlik, J. (2001). system building intelligent agents learn
retrieve extract information. User Modeling User-Adapted Interaction, 13,
3588.
Elio, R., & Haddadi, A. (1998). Dialog management adaptive database assistant.
Tech. rep. 98-3, Daimler-Benz research Technology Center, Palo Alto, CA.
Elio, R., & Haddadi, A. (1999). abstract task models conversation policies.
Proceedings Agents99 Workshop Specifying Implementing Conversation
Policies. Seattle, WA.
Ferrario, M., Waters, K., & Smyth, B. (2000). Collaborative maintenance ULYSSES.
Proceedings International Conference Adaptive Hypermedia Adaptive
Web-based Systems, pp. 301304. Trento, Italy.
Fiechter, C., & Rogers, S. (2000). Learning subjective functions large margins.
Proceedings Seventeenth International Conference Machine Learning, pp.
287294. Stanford University, CA. Morgan Kaufmann.
Goddeau, D., Meng, H., Polifroni, J., Seneff, S., & Busayapongchai, S. (1996). form-based
dialogue manager spoken language applications. Proceedings Fourth International Conference Spoken Language Processing, Vol. 2, pp. 701704. Philadelphia, PA.
Goecks, J., & Shavlik, J. (2000). Learning users interests unobtrusively observing
normal behavior. Proceedings 2000 International Conference Intelligent
User Interfaces, pp. 129132. New Orleans, LA. ACM Press.
Goker, M., & Roth-Berghofer, T. (1999). development utilization case-based
help-desk support system HOMER. Engineering Applications Artificial Intelligence,
12, 665680.
Goker, M., & Thompson, C. (2000). Personalized, conversational case-based recommendation. Proceedings Fifth European Workshop Case-Based Reasoning, pp.
99111. Trento Italy. Springer Verlag.
Haller, S., & McRoy, S. (1998). Preface special issue computational models mixedinitiative interaction. User Modeling User-Adapted Interaction, 8, 167170.
Horvitz, E., & Paek, T. (2001). Harnessing models users goals mediate clarification dialog spoken language systems. Proceedings Eighth International
Conference User Modeling, pp. 201210. Sonthofen, Germany. Springer.
Jameson, A., Kipper, B., Ndiaye, A., Schafer, R., Simons, J., Weis, T., & Zimmermann,
D. (1994). Cooperating noncooperative: dialog system PRACMA.
424

fiPersonalized Conversational Recommendation

Proceedings KI-94: Advances Artificial Intelligence, pp. 106117. Seattle, WA.
Morgan Kaufmann.
Jameson, A., & Wittig, F. (2001). Leveraging data users general learning individual user models. Proceedings Seventeenth International Joint
Conference Artificial Intelligence, pp. 11851192. Seattle, WA. Morgan Kaufmann.
Jurafsky, D., & Martin, J. (2000). Speech language processing. Prentice Hall.
Jurafsky, D., Wooters, C., Tajchman, G., Segal, J., Stolcke, A., Fosler, E., & Morgan, N.
(1994). Berkeley restaurant project. Proceedings International Conference Spoken Language Processing, pp. 21392142. Yokohama, Japan.
Kass, R. (1991). Building user model implicitly cooperative advisory dialog. User
Modeling User-Adapted Interaction, 3, 203258.
Kay, J., & Thomas, R. C. (2000). Personal usability based upon scrutable, dynamic,
individual user model. Proceedings Australasian Computer Human Interfaces
Conference, pp. 292298.
Kobsa, A., & Wahlster, W. (Eds.). (1989). User models dialog systems. Springer, New
York.
Konstan, J., Miller, B., Maltz, D., Herlocker, J., Gordon, L., & Riedl, J. (1997). Grouplens:
Applying collaborative filtering usenet news. Communications ACM, 40,
7787.
Kumar, V. (1992). Algorithms constraint-satisfaction problems: survey. AI
Magazine, 13, 3244.
Lang, K. (1995). NewsWeeder: Learning filter netnews. Proceedings Twelfth
International Conference Machine Learning, pp. 331339. San Francisco, CA. Morgan Kaufmann.
Langley, P. (1999). User modeling adaptive interfaces. Proceedings Seventh
International Conference User Modeling, pp. 357370. Banff, Alberta. Springer.
Levin, E., Pieraccini, R., & Eckert, W. (2000). stochastic model human-machine
interaction learning dialog strategies. IEEE Transactions Speech Audio
Processing, 8, 1123.
Linden, G., Hanks, S., & Lesh, N. (1997). Interactive assessment user preference models:
automated travel assistant. Proceedings Sixth International Conference
User Modeling, pp. 6778. Chia Laguna, Sardinia. Springer.
Litman, D., & Pan, S. (2002). Designing evaluating adaptive spoken dialogue system.
User Modeling User-Adapted Interaction, 12, 111137.
Maier, E., Mast, M., & Luperfoy, S. (Eds.). (1996). Proceedings ECAI96 workshop
Dialogue processing spoken language systems, Budapest, Hungary. Springer Verlag.
425

fiThompson, Goker, & Langley

Maloor, P., & Chai, J. (2000). Dynamic user level utility measurement adaptive
dialog help-desk system. Proceedings 1st SIGdial Workshop Discourse
Dialogue, pp. 94101 Hong Kong. Association Computational Linguistics.
McNee, S., Lam, S., Konstan, J., & Riedl, J. (2003). Interfaces eliciting new user preferences recommender systems. Proceedings Ninth International Conference
User Modeling, pp. 178188. Johnstown, PA. Springer.
Melville, P., Mooney, R., & Nagarajan, R. (2002). Content-boosted collaborative filtering
improved recommendations. Proceedings Eighteenth National Conference
Artificial Intelligence, pp. 187192. Edmonton, Canada. AAAI Press.
Pazzani, M., Muramatsu, J., & Billsus, D. (1996). Syskill & Webert: Identifying interesting web sites. Proceedings Thirteenth National Conference Artificial
Intelligence, pp. 5461. Portland, OR. AAAI Press.
Pieraccini, R., Levin, E., & Eckert, W. (1997). AMICA: AT&T mixed initiative
conversational architecture. Proceedings European Conference Speech
Communication Technology, pp. 18751878. Rhodes, Greece.
Qu, Y., & Beale, S. (1999). constraint-based model cooperative response generation
information dialogues. Proceedings Sixteenth National Conference
Artificial Intelligence, pp. 148155. Orlando, FL. AAAI Press.
Rafter, R., Bradley, K., & Smyth, B. (2000). Personalized retrieval online recruitment
services. Proceedings Twenty-second Annual Colloquium Information
Retrieval. Cambridge, UK.
Raskutti, B., & Zukerman, I. (1997). Generating queries replies informationseeking interactions. International Journal Human Computer Studies, 47, 689734.
Resnick, P., & Varian, H. (1997). Recommender systems. Communications ACM,
40 (3), 5658.
Rich, E. (1979). User modeling via stereotypes. Cognitive Science, 3, 329354.
Rogers, S., Fiechter, C., & Langley, P. (1999). adaptive interactive agent route
advice. Proceedings Third International Conference Autonomous Agents,
pp. 198205. Seattle, WA. ACM Press.
Sadek, M., Bretier, P., & Panaget, F. (1997). ARTIMIS: Natural dialogue meets rational
agency. Proceedings Fifteenth International Joint Conference Artificial
Intelligence, pp. 10301035. Nagoya, Japan. Morgan Kaufmann.
Segal, R., & Kephart, J. (1999). Mailcat: intelligent assistant organizing e-mail.
Proceedings Third International Conference Autonomous Agents, pp. 276
282. Seattle, WA. ACM Press.

426

fiPersonalized Conversational Recommendation

Seneff, S., Hurley, E., Lau, R., Pao, C., Schmid, P., & Zue, V. (1996). Galaxy-II:
reference architecture conversational system development. Proceedings
International Conference Spoken Language Processing, pp. 931934. Sydney, Australia.
Seneff, S., Lau, R., & Polifroni, J. (1999). Organization, communication, control
Galaxy-II conversational system. Proceedings Eurospeech 1999, pp. 12711274.
Budapest, Hungary.
Shardanand, U., & Maes, P. (1995). Social information filtering: Algorithms automating
word mouth. Proceedings Conference Human Factors Computing
Systems, pp. 210217. Denver, CO. ACM Press.
Shearin, S., & Lieberman, H. (2001). Intelligent profiling example. Proceedings
International Conference Intelligent User Interfaces, pp. 145152. Santa Fe, NM.
ACM Press.
Singh, S., Litman, D., Kearns, M., & Walker, M. (2002). Optimizing dialogue management reinforcement learning: Experiments NJFun system. Journal
Artificial Intelligence Research, 16, 105133.
Smith, R., & Hipp, D. (1994). Spoken natural language dialog systems: practical approach.
Oxford University Press, New York, NY.
Smyth, B., & Cotter, P. (1999). Surfing digital wave, generating personalized TV listings
using collaborative, case-based recommendation. Proceedings Third International Conference Case-Based Reasoning, pp. 561571. Monastery, Germany.
Springer Verlag.
Stent, A., Dowding, J., Gawron, J., Bratt, E., & Moore, R. (1999). CommandTalk
spoken dialogue system. Proceedings Thirty-seventh Annual Meeting
Association Computational Linguistics, pp. 183190. College Park, MD. Association Computational Linguistics.
Stolcke, A., Ries, K., Coccaro, N., Shriberg, E., Bates, R., Jurafsky, D., Taylor, P., Martin,
R., Ess-Dykema, C. V., & Meteer, M. (2000). Dialog act modeling automatic
tagging recognition conversational speech. Computational Linguistics, 26, 339
373.
Walker, M., Fromer, J., Fabbrizio, G., Mestel, C., & Hindle, D. (1998). say?:
Evaluating spoken language interface email. Proceedings ACM CHI 98
Conference Human Factors Computing Systems, pp. 582589. Los Angeles, CA.
ACM Press.
Walker, M., & Hirschman, L. (2000). Evaluation DARPA communicator spoken dialogue
systems. Proceedings Second International Conference Language Resources
Evaluation. Athens, Greece.

427

fiThompson, Goker, & Langley

Ward, W., & Issar, S. (1996). Recent improvements CMU spoken language understanding system. Proceedings ARPA Human Language Technology Workshop,
pp. 213216.
Wettschereck, D., & Aha, D. (1995). Weighting features. Proceedings First International Conference Case-Based Reasoning, pp. 347358. Sesimbra, Portugal.
Springer Verlag.
Winograd, T., & Flores, F. (1986). Understanding computers cognition: new foundation design. Ablex Publishing, Northwood, NJ.
Zhang, Z., & Yang, Q. (1998). Towards lifetime maintenance case base indexes
continual case based reasoning. Proceedings 1998 International Conference
AI Methodologies, Systems Applications, pp. 489500. Bulgaria. Springer.
Zukerman, I., & Litman, D. (2001). Natural language processing user modeling: Synergies limitations. User Modeling User-Adapted Interaction, 11, 129158.

428


