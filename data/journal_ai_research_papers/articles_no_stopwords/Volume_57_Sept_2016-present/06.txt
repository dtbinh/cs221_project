Journal Artificial Intelligence Research 57 (2016) 273-306

Submitted 11/15; published 10/16

Effective Heuristics Suboptimal Best-First Search
Christopher Wilt
Wheeler Ruml

wilt cs.unh.edu
ruml cs.unh.edu

Department Computer Science
University New Hampshire
Durham, NH 03824 USA

Abstract
Suboptimal heuristic search algorithms weighted A* greedy best-first search
widely used solve problems guaranteed optimal solutions expensive
obtain. algorithms crucially rely heuristic function guide search.
However, research building heuristics addresses optimal solving. paper,
illustrate established wisdom constructing heuristics optimal search fail
considering suboptimal search. consider behavior greedy best-first search
detail test several hypotheses predicting heuristic effective
it. results suggest predictive characteristic heuristics goal distance rank
correlation (GDRC), robust measure whether orders nodes according distance
goal. demonstrate GDRC used automatically construct abstractionbased heuristics greedy best-first search effective built
methods oriented toward optimal search. results reinforce point suboptimal
search deserves sustained attention specialized methods own.

1. Introduction
A* best-first search expands nodes order f (n) f (n) = g(n) + h(n).
optimal solutions provided A* (Hart, Nilsson, & Raphael, 1968)
desirable, time memory often prevent application algorithm. A* fails
either insufficient time memory, practitioners sometimes turn bounded
suboptimal algorithms may return optimal solution, return solution
guaranteed certain factor expensive optimal
solution.
well-known likely Weighted A* (Pohl, 1970), best-first
search expands nodes f order, f (n) = g(n) + w h(n) : w (1, ). Variants
Weighted A* used wide variety applications, including domain-independent
planning (Helmert, 2006; Richter & Westphal, 2010) robotics (Likhachev, Gordon, &
Thrun, 2003; Likhachev & Ferguson, 2009). Weighted A* component number
anytime algorithms. example, Anytime Restarting Weighted A* (Richter, Thayer,
& Ruml, 2009) Anytime Repairing A* (Likhachev et al., 2003) use Weighted A*.
Anytime Nonparametric A* (van den Berg, Shah, Huang, & Goldberg, 2011) doesnt use
Weighted A* per se, rather limiting case, greedy best-first search (Doran & Michie,
1966), best-first search h(n). anytime algorithms have, built in, implicit
assumption Weighted A* high weight greedy best-first search find
solution faster A* Weighted A* small weight.
c
2016
AI Access Foundation. rights reserved.

fiWilt & Ruml

many popular heuristic search benchmark domains (e.g., sliding tile puzzles, grid path
planning, Towers Hanoi, TopSpin, robot motion planning traveling salesman
problem) increasing weight lead faster search, weight becomes
large Weighted A* expansion order greedy best-first search,
results fastest search. first contribution paper provide illustrations
how, domains, greedy best-first search performs worse Weighted A*,
sometimes even worse A*.
show failure greedy best-first search merely mathematical curiosity, occurring hand crafted counterexamples, rather phenomenon
occur real domains, including variants popular single-agent heuristic benchmarks.
second contribution empirically characterize conditions occurs, knowledge
important anyone using suboptimal search. important first step
predictive theoretical understanding behavior suboptimal heuristic search.
root cause failure greedy best-first search ultimately traced back
heuristic, used guide greedy best-first search goal. A*,
number well-documented techniques constructing effective heuristic.
revisit guidelines context greedy best-first search. third contribution
show that, one follows well-established guidelines creating quality heuristic
A*, results poor. present several examples following A* wisdom
constructing heuristic leads slower results greedy best-first search. use
examples understand requirements greedy best-first search places
heuristic.
fourth contribution quantitative metric assessing greedy heuristic, goal
distance rank correlation (GDRC). GDRC used predict whether greedy
best-first search likely perform well. GDRC used compare different
heuristics domain, allowing us make informed decisions
heuristic select variety choices, case abstraction-based
heuristics pattern databases. quantitative metric used automatically
construct heuristic greedy best-first search iteratively refining abstraction
measuring good candidate heuristic is. show iteratively refining
abstraction using simple hill-climbing search guided GDRC yield heuristics
powerful built traditional methods oriented toward optimal search.
work increases understanding greedy best-first search, one popular scaleable heuristic search techniques. generally, suggests techniques
developed optimal search necessarily appropriate suboptimal search. Suboptimal search markedly different optimal search, deserves theory
methods.

2. Conundrum: Ineffective Weighted A*
starting point investigation heuristics suboptional search begins
curious empirical observation: although weighted A* one popular way
speeding heuristic search, increasing weight Weighted A* always work.
order get better grasp question increasing weight ineffective,
first need empirical data.
274

fiEffective Heuristics Suboptimal Best-First Search

Domain
Dynamic Robot
Hanoi (14)
Pancake (40)
11 Tiles (unit)
Grid
TopSpin (3)
TopSpin (4)
11 Tiles (inverse)
City Navigation 3 3
City Navigation 4 4
City Navigation 5 5

Average Solution
Length
187.45
86.92
38.56
36.03
2927.40
8.52
10.04
37.95
15.62
14.38
13.99

Total
States
20,480,000
268,435,456
8 1047
239,500,800
1,560,000
479,001,600
479,001,600
239,500,800
22,500
22,500
22,500

Branching
Factor
0-240
6
40
1-3
0-3
12
12
1-3
3-8
3-10
3-12

Unit-cost

Yes
Yes
Yes
Yes
Yes
Yes





Table 1: Domain Attributes benchmark domains considered
2.1 Benchmark Domains
consider six standard benchmark domains: sliding tile puzzle, Towers Hanoi
puzzle, grid path planning, pancake problem, TopSpin, dynamic robot navigation.
selected domains represent wide variety interesting heuristic
search features, branching factor, state space size, solution length. Since
would compare A*, forced use somewhat smaller puzzles
possible solve using state art suboptimal searches. requirement problem
size problem solvable A*, Weighted A*, greedy best-first search
main memory (eight gigabytes). Basic statistics domain variants
summarized Table 1.
sliding tile 11 puzzle (3 4), used random instances Manhattan
distance heuristic. used 11 puzzle, rather 15 puzzle two reasons. First,
optimally solving 15 puzzles using A* without running memory requires significant
resources (At least 27 gigabytes, significantly eight gigabyte limit, according
Burns et al., 2012). addition that, consider sliding tile puzzle non-unit
cost functions. non-unit problems significantly difficult solve
unit-cost variants. non-unit version sliding tile puzzle consider uses inverse
cost function, cost moving tile n 1/n. Manhattan distance heuristic,
weighted appropriately, admissible consistent cost function.
Towers Hanoi, considered 14-disk-4 peg problem, used two disjoint pattern
databases, one bottom 12 disks, one top two disks (Korf & Felner,
2002). pancake problem, used gap heuristic (Helmert, 2010). grid path
planning, used maps 2000x1200 cells, 35% cells blocked, using
Manhattan distance heuristic four way movement. TopSpin puzzle, objective
sort circular permutation iteratively reversing continuous subsequence fixed
size. example TopSpin puzzle Figure 1. considered problem 12
disks turnstile would turn either three four disks, denoted TopSpin(3)
TopSpin(4). heuristic, used pattern database 6 contiguous disks present,
275

fiWilt & Ruml

Figure 1: 20 disk TopSpin puzzle.
remaining 6 disks abstracted. dynamic robot navigation problem, used
200x200 world, 32 headings 16 speeds. dynamic robot navigation, objective
navigate robot one location heading another location heading,
respecting dynamics robot. robot able change direction speed
instantaneously, combinations heading/speed reached given
state. addition that, states domain represent dead ends. example,
state robot moving full speed directly towards obstacle produce
children, robot crash matter control action applied.
objective minimize total travel time; actions cost.
introduce new domain call City Navigation, designed simulate navigation
using system similar American interstate highways air transportation networks.
domain, cities scattered randomly 100x100 square, connected random
tour guarantees possible get city city. city
connected nc nearest neighbors. links cities cost Euclidean distance
+ 2. city contains collection locations, randomly scattered throughout city
(which 1x1 square). Locations city connected random tour,
place connected nearest np places. Links places cost true distance
multiplied random number 1 1.1. Within city special
nexus node contains connections city. goal navigate
randomly selected start location randomly selected end location. example,
might want go Location 3 City 4 Location 23 City 1. citys nexus
node Location 0, reach goal example problem must navigate
Location 3 Location 0 City 4, find path City 4 City 1, path
Location 0 City 1 Location 23 City 1. example instance type
seen Figure 2. circles left part figure locations, connected
locations. nexus node, Location 0, connected nexus nodes neighboring
276

fiEffective Heuristics Suboptimal Best-First Search

Figure 2: city navigation problem np = nc = 3, 15 cities 15 locations
city.

cities. right part figure shows entire world, cities shrunk
circle.
City Navigation instances classified np nc . consider problems varying
numbers connections, always 150 cities 150 places city. Since
location within city global position, heuristic direct Euclidean distance.
domain, solutions vary length, straightforward manipulate accuracy
heuristic. domain bears similarity IPC Logistics domain
locations within cities connected roads, special airport locations used
travel cities.
2.2 Results
Figures 3 4 show number expansions required A*, greedy best-first search,
Weighted A* weights 1.1, 1.2, 2.5, 5, 10, 20. plots allow us compare
greedy best-first search Weighted A* A*, determine whether increasing
weight speeds search, slows search.
Looking plots Figure 3, easy see increase weight
number expansions goes down, Figure 4, opposite true.
domains, increasing weight initially speeds search, A* relaxed Weighted
A*, Weighted A* transforms greedy best-first search, number nodes
required solve problem increases. two domains, TopSpin turnstile
size 4 City Navigation 3 3, number nodes expanded greedy best-first search
higher number nodes expanded A*. Explaining phenomenon central
goal paper.
277

fiWilt & Ruml

600000

300000

200000

100000

16000

8000

0

0

0

A* 1.1 1.2 2.5 5 10 20 G

A* 1.1 1.2 2.5 5 10 20 G

Dynamic Robot

A* 1.1 1.2 2.5 5 10 20 G

TopSpin(3)

Unit Tile

1e+06

500000

Total Nodes Expanded

800

Total Nodes Expanded

Total Nodes expanded

Total Nodes Expanded

Total Nodes Expanded

Total Nodes Expanded

1.2e+06

40 Pancake Problem

Grid Navigation

14 disk Hanoi

40000

20000

0

0

A* 1.1 1.2 2.5 5 10 20 G

400

0

A* 1.1 1.2 2.5 5 10 20 G

A* 1.1 1.2 2.5 5

10 20 G

Figure 3: Domains increasing weight speeds search. Numbers denote Weighted
A* run specific weight, G denotes greedy best-first search.

3. Characteristics Effective Heuristics
established increasing weight Weighted A* always speed
search, situations actually slow search. fact A*
sometimes faster greedy best-first search sometimes slower greedy best-first
search suggests heuristics work well A* poorly greedy best-first search,
heuristics work well greedy best-first search A*. Thus,
question precisely driving difference, algorithm, A* greedy
best-first search, needs heuristic.
first review literature suggestions make good heuristic
A*. mind, apply A* rules constructing effective heuristic
greedy best-first search. leads us observations effective heuristics greedy
best-first search distinct common recommendations building good
heuristic A*.
3.1 Effective Heuristics A*
Much literature constitutes good heuristic centers well
heuristic works A*. finding optimal solutions using A*, first important
278

fiEffective Heuristics Suboptimal Best-First Search

Inverse Tile

TopSpin(4)

Total Nodes Expanded

Total Nodes Expanded

160000

80000

0

16000

8000

0

A* 1.1 1.2 2.5 5 10 20 G

A* 1.1 1.2 2.5 5 10 20 G
City Navigation 4 4

City Navigation 3 3

4000

Total Nodes Expanded

Total Nodes Expanded

3000

2000

0

2000

1000

0

A* 1.1 1.2 2.5 5

10 20 G

A* 1.1 1.2 2.5 5

10 20 G

Figure 4: Domains increasing weight slows search. Numbers denote
Weighted A* specified weight, G denotes greedy best-first search.

requirement heuristic admissible, meaning nodes n, h (n) true
cheapest path n goal greater equal h(n). heuristic
admissible, A* degenerates (no star) guaranteed find shortest
path.
generally believed consistency important, due fact inadmissible heuristics lead exponential number re-expansions (Martelli, 1977).
situation, however, rarely arises practice Felner et. al. (2011) argue
inconsistency generally much problem generally believed.
widespread rule making good heuristic A* is: dominance good (Nilsson, 1980; Pearl, 1984). heuristic h1 said dominate h2 n G : h1 (n) h2 (n).
makes sense, due admissibility, larger values closer h . Furthermore
A* must expand every node n encounters f (n) less cost optimal
solution, large h often reduces expansions. Dominance represents current gold standard comparing two heuristics. practice, heuristics often informally evaluated
279

fiWilt & Ruml

average value value initial state benchmark set. either
case, general idea remains same: bigger heuristics better.
ignore effects tie breaking well effects duplicate states, A*
last iteration IDA* expand number nodes. allows us apply
formula Korf, Reid, Edelkamp (2001). predict number nodes
IDA* expand cost bound c is:
E(N, c, P ) =

c
X

Ni P (c i)

i=0

function P (h) KRE equation represents equilibrium heuristic distribution,
probability node chosen randomly uniformly among nodes
given depth brute-force search tree heuristic value less equal h (Korf
et al., 2001). quantity tends decrease h gets larger, depending nodes
space distributed. dominance relation transfers KRE equation,
meaning heuristic h1 dominates different heuristic h2 , KRE equations predicts
expected expansions using h1 less equal expected expansions
using h2 .
considering pattern database (PDB) heuristics, Korfs conjecture (1997) lend

insight performance IDA*, tells us expect 1+log(m)
= n
amount memory PDB question takes up, amount time
expect IDA* search consume, n constant (Korf, 2007). willing
apply results regarding IDA* A* equation tells us expect larger
pattern databases provide faster search A*. summarize, prevailing wisdom
regarding heuristics bigger better, terms average heuristic value
pattern database size.
3.2 Behavior Greedy Best-First Search
shall see, advice regarding heuristics helpful considering
A*. happens apply wisdom greedy best-first search? answer
question taking detailed look behavior greedy best-first search three
benchmark problems: Towers Hanoi, TopSpin puzzle, sliding tile
puzzle.
3.2.1 Towers Hanoi
first domain consider Towers Hanoi. successful heuristic
optimally solving 4 peg Towers Hanoi problems disjoint pattern databases (Korf &
Felner, 2002). Disjoint pattern databases boost heuristic value providing information
disks top puzzle. example, consider 12-disk puzzle, split
two disjoint pattern databases: eight disks bottom pattern database, four disks
top pattern database. A*, best results achieved using full
disjoint pattern database. greedy best-first search, however, faster search results
use disjoint pattern database, instead use 8 disk pattern database.
exact numbers presented Unit rows Table 2. problems randomly
generated Towers Hanoi states, goal get disks onto first peg.
280

fiEffective Heuristics Suboptimal Best-First Search

Cost
Unit
Square
Rev Square

Heuristic
8/4 PDB
8/0 PDB
8/4 PDB
8/0 PDB
8/4 PDB
8/0 PDB

A* Exp
2,153,558
4,618,913
239,653
329,761
3,412,080
9,896,145

Greedy Exp
36,023
771
4,663
892
559,250
730

Table 2: Average number nodes expanded solve 51 12-disk Towers Hanoi problems.
30

25

25

20

Minimum h

Minimum h

20

15

15

10

10

5
00

5
200

400
600
Expansions

800

1000

00

5000 10000 15000 20000 25000 30000 35000
Expansions

Figure 5: minimum h value open search progresses, using different pattern
databases (single left, two disjoint additive ones right).

theory A* corroborates empirical evidence observed here: disjoint pattern database dominates single pattern database, absent unusual effects tiebreaking, surprise disjoint pattern database results faster A* search.
reason different behaviour A* greedy best-first search simple.
greedy best-first search using single pattern database, possible follow heuristic
directly goal, h value head open list monotonically decrease.
see this, note every combination bottom disks h value, possible
arrangements disks top share h value. disks top
always moved around independently bottom disks are. Consequently,
always possible arrange top disks next move bottom disks
done, disturbing bottom disks, thus leaving h constant. Eventually,
h decreases progress made putting bottom disks problem
order. process repeats h = 0, point greedy best-first search simply
considers possible configurations top disks goal found.
phenomenon seen left pane Figure 5, minimum h value
open list monotonically decreases number expansions search done
281

fiWilt & Ruml

h = 10

h=9
Figure 6: Two Towers Hanoi states, one near goal (top) one far goal
(bottom).

increases. heuristic created single pattern database creates extremely effective
gradient greedy best-first search algorithm follow two reasons. First,
local minima all, global minimum goal is. context, define
minimum region space n , every path n goal node
least one node n h(n ) > h(n). Second, exactly 256 states associated
configuration bottom 8 disks. means every 256 expansions, h
guaranteed decrease. practice, state lower h tends found much faster.
right pane Figure 5, heuristic disjoint pattern database. see
h value head open list fluctuates substantially using disjoint
pattern database, indicating greedy best-first searchs policy follow small h much
less successful. states bottom disks near goal
paired poor arrangement disks top assigned large heuristic
values, delays expansion nodes. illustrated Figure 6. top
state significantly closer goal, despite higher h value bottom state.
ignore top disks completely, top state h = 1 compared bottom
states h = 9, correctly conveys fact top state significantly closer
goal. disjoint PDB causes substantial confusion greedy best-first search,
prior making progress 8 bottom disks, greedy best-first search
considers states top 4 disks closer destination. bottom state
expanded, produce children lower heuristic values explored
ever considering top state, state explored first. Eventually,
descendants bottom state h 9 explored, point top state
expanded, causes h value head open list go down.
summarize, disjoint pattern database makes gradient difficult
greedy best-first search follow nodes small h one
reason: near goal bottom pattern database returning small value,
particularly near goal, top disks arranged target peg.
suggests following observation regarding heuristics greedy best-first search:
282

fiEffective Heuristics Suboptimal Best-First Search

Observation 1. else equal, greedy best-first search tends work well
possible reach goal every node via path h monotonically decreases along
path.
may seem self-evident, example illustrated conflicts
common wisdom heuristic construction. important note observation
makes comment relative magnitude heuristic, greedy best-first
completely irrelevant; matters relative ordering nodes ordered
using heuristic.
Another way view phenomenon analogy Sussman Anomaly (Sussman,
1975). Sussman anomaly occurs one must undo subgoal prior able
reach global goal. context Towers Hanoi problems, goal get
disks target peg, solving problem may involve
undoing subgoals putting top disks target peg. presence top
pattern database encourages greedy best-first searches privilege states subgoals
eventually undone accomplished.
Korf (1987) discusses different kinds subgoals, different kinds heuristic
searches able leverage subgoals. Greedy best-first search uses heuristic create
subgoals, attempting follow h goal. example, unit-cost domain, first
subgoal find node h = h(root) 1. heuristic follows Observation 1,
subgoals form perfect serialization, subgoals achieved one another.
heuristic deviates Observation 1, subgoals induced heuristic cannot
serialized.
Another important factor is, course, number distinct nodes heuristic
level one encounters prior finding better node. Consider, example, one worst
heuristics, h = 0. Technically, heuristic follows Observation 1 paths
contain nodes h = 0, one plateau contains nodes entire space,
obviously undesirable. Hoffmann (2005) discusses general idea using term maximal
bench exit distance, again, idea domains quantity
small, greedy best-first search Enforced Hill Climbing method perform well,
finding nodes lower h straightforward.
effects exacerbated cost disks top increased relative
cost disks bottom. define cost moving disk
proportional disks size, get Square cost metric, cost moving disk
n n2 . could imagine tower stacked reverse, requiring larger
disks always top smaller disks, case get Reverse Square cost
function. either case, expect number expansions greedy best-first
search require lower using bottom pattern database,
indeed effect observe Table 2. However, top disks heavier disks
bottom, greedy best-first search suffers even considered unit
cost problem, expanding order magnitude nodes. pattern
database information top disks returning values substantially
larger bottom pattern database, due fact top pattern database
considers expensive operators. situation reversed, however, top
pattern database uses lowest cost operators, top pattern databases contribution
h much smaller proportion total expansions. Since greedy best-first search
283

fiWilt & Ruml

1400

1800

Greedy Search Disjoint PDB

Greedy Search Disjoint PDB

1600

1200

1400
1200

800

Minimum h

Minimum h

1000

1000

600

800
600

400

400
200
0
0

200
1000

2000
3000
Expansions

4000

0
0

5000

100000

200000

300000 400000
Expansions

500000

600000

700000

Figure 7: minimum h value open searches using disjoint pattern databases
different cost functions (square left, reverse square right).

performs best top pattern database isnt even present, naturally performs better
contribution top pattern database smaller.
phenomenon vividly illustrated execution times Figure 7. left
figure, disks top pattern database much cheaper move disks
bottom pattern database, therefore contributing much smaller proportion
total value h. right part figure, disks top pattern database
much expensive move disks bottom pattern database,
top pattern database makes much larger contribution h, causing substantially
confusion.
Hoffmann (2005) notes success heuristic many domains attributable fact h+ heuristic produces heuristic local minima.
heuristic local minima precisely matches Observation 1, always
possible reach goal via path h monotonically decreases.
3.2.2 TopSpin
considered TopSpin 12 disks turnstile flipped 4 disks using pattern
databases contained 5, 6, 7, 8 12 total disks.
Korfs conjecture predicts larger pattern databases useful
A*, therefore considered stronger heuristics, indeed, PDB
becomes larger, number expansions done A* dramatically decreases.
seen Figure 8. box plot (Tukey, 1977) labeled either A* G (for greedy
best-first search), number, denoting number disks PDB tracks.
box denotes middle 50% data, top box upper quartile,
bottom box bottom quartile, height box interquartile
range. horizontal line middle box represents median. grey stripe
indicates 95% confidence interval mean. circles denote points
1.5 times interquartile range away either first quartile third
284

fiEffective Heuristics Suboptimal Best-First Search

4/12 TopSpin Different PDB's

Expansions

60000

30000

A*5 G5 A*6 G 6 A*7 G7 A*8 G 8

Figure 8: TopSpin puzzle different heuristics. followed number denotes
number disks PDB heuristic. G followed number denotes
greedy best-first search number disks PDB heuristic.

quartile, whiskers represent range non-outlier data. move left
right, PDB heuristic tracks disks, gets substantially better A*.
reductions greedy best-first search terms expansions, gains
nowhere near impressive compared A*.
reason greedy best-first search perform better given larger
heuristic that, larger heuristic, states h = 0 may still quite far
goal. example, consider TopSpin state represented follows, denotes
abstracted disk:
State 1: 0 1 2 3 4 5
turnstile swaps orientation 4 disks, configurations
putting abstracted disks order requires moving disk abstracted, as:
State 2: 0 1 2 3 4 5 6 7 8 9 11 10
TopSpin state, abstraction process takes largest N disks converts
abstracted disks, abstracted disks treated same, State 2 would
abstracted State 1, means abstracts state goal, making
heuristic 0. wanted expand State 2, could one children
State 3, whose heuristic still 0:
State 3: 0 1 2 3 4 5 6 7 10 11 9 8
Consider different child, example child obtained rotating middle 4 disks:
285

fiWilt & Ruml

State 4: 0 1 2 3 7 6 5 4 8 9 10 11
abstracts into:
State 5: 0 1 2 3 5 4
heuristic State 4 0, State 4 abstracts State 5. State 5
abstract state different State 1 (the abstracted goal) heuristic State
4 0.
abstract disks 6-11, still abstract state before, heuristic
still 0. Moving disk abstracted increase heuristic, moving
abstracted disks leave heuristic 0. Unfortunately, transforming State 2
goal cannot done without moving least one disks whose index 0
5, turnstile size 4.
means subgraph consisting nodes h = 0 TopSpin
problem disconnected. Thus, greedy best-first search encounters state h = 0,
state could h = 0 state connected goal via h = 0 states,
would desirable, state could h = 0 state connected goal via
paths contain least one h 6= 0 nodes, would undesirable. case,
greedy best-first search first expand h = 0 nodes connected first h = 0
node (which hypothesis connected goal node via paths containing h = 0
nodes), return expanding nodes h = 1, looking find different
h = 0 node.
abstraction controls number size h = 0 regions. example,
abstract 6 disks, two strongly connected regions h = 0 nodes, containing
360 nodes. instead abstract 5 disks, 12 strongly connected h = 0 regions,
10 nodes. heuristic abstracts 6 disks, 50% chance
given h = 0 node connected goal via h = 0 nodes, greedy
best-first search entered correct h = 0 region, finding goal node largely
chance. heuristic abstracts 5 disks, probability given h = 0
node connected goal via h = 0 nodes lower. correct h = 0 region
found, however, much easier find goal, region contains 10
nodes, compared 360 nodes. Empirically, see two effects roughly
cancel one another out, total number expansions done greedy best-first
search remains roughly constant matter heuristic used. brings us
next observation.
Observation 2. else equal, nodes h = 0 connected goal nodes
via paths contain h = 0 nodes.
One view important specific case Observation 1. Interestingly, types
heuristics, delete-relaxation heuristics used domain-independent planning,
obey observation implicitly never allowing non-goal states h values 0.
One obvious way make heuristic satisfy recommendation change
heuristic non-goal states minimum cost operator
domain cost . this, simply restate recommendation substituting
0, arrive similar result.
286

fiEffective Heuristics Suboptimal Best-First Search


8



9



10

3
7
11

4


1

9


6


3

11

Figure 9: Different tile abstractions. denotes tile abstracted..
Abstraction
Outer L (Figure 9 left)
Checker (Figure 9 right)
Outer L Missing 3
Outer L Missing 3 7
Instance Specific
GDRC Generated
Average 6-tile PDB
Worst 6-tile PDB

Greedy Exp
258
11,583
3,006
20,267
8,530
427
17,641
193,849

A* Exp
1,251,260
1,423,378
DNF
DNF
480,250
1,197,789
1,609,995
2,168,785

Table 3: Average number expansions required Greedy best-first search A* solve
3 4 tile instances different pattern databases. DNF denotes least one
instance would require 8GB solve.

3.2.3 Sliding Tiles
sliding tile puzzle one commonly used benchmark domains heuristic
search. such, domain one best understood. Pattern database heuristics
shown strongest heuristics domain, strongest
heuristics quite time (Korf & Taylor, 1996; Felner, Korf, Meshulam, & Holte,
2007). use 11 puzzle (4 3) case study smaller size puzzle
allows creating testing hundreds different pattern databases. central problem
constructing pattern database sliding tile puzzle selecting good abstraction.
abstraction keeps outer L, shown left part Figure 9,
extremely effective greedy best-first search, greedy best-first search
put abstracted tiles proper places, remains find goal,
easy using even completely uninformed search remaining puzzle,
6!2 = 360 states h = 0 h = 0 states form connected subgraph.
analogous heuristic directing search algorithm follow process outlined
Parberry (1995), large sliding tile puzzles solved first solving outer L,
treating remaining problem smaller sliding tile puzzle.
Compare happens greedy best-first search run checkerboard
abstraction, shown right part Figure 9. greedy best-first search identified node h = 0, high chance remaining abstracted tiles
configured properly, least one non-abstracted tiles
moved. effect seen Table 3, average number expansions required A* comparable either abstraction, average number expansions
required greedy best-first search larger two orders magnitude.
287

fiWilt & Ruml

sheer size PDB important greedy best-first search
A*. Table 3, see weaken pattern database removing 3
7 tiles, number expansions required increases factor 10 greedy best-first
search. A* using PDB 3 tile missing, 3 instances unsolvable within 8
GB memory (approximately 25 million nodes Java implementation).
3 7 tile missing, A* unable solve 16 instances within limit.
worth noting even without 3 tile, outer L abstraction still effective
greedy best-first search compared checkerboard abstraction.
underlying reason behind inefficiency greedy best-first search using certain
pattern databases fact less useful pattern databases nodes h = 0
nowhere near goal. provides evidence favor Observation 2;
greedy best-first search concentrates efforts finding expanding nodes low h
value, nodes are, reality, near goal, clearly causes problems
algorithm. A* uses f , g contributes f , A* able eliminate
states consideration (not expand them) high g value helps give
node high f value, causes A* relegate node back expansion
queue.
checkerboard pattern database helps make clear another problem facing
greedy best-first search heuristics. algorithm discovers node h = 0,
node connected goal via h = 0 nodes, algorithm eventually run
h = 0 nodes expand, begin expanding nodes h = 1. expanding
h = 1 nodes, greedy best-first search either find h = 0 nodes examine goals,
eventually exhaust h = 1 nodes well, forced consider h = 2
nodes. natural question ask far algorithm back
able find goal. leads us next observation.

Observation 3. else equal, greedy best-first search tends work well
difference minimum h value nodes local minimum minimum
h allow search escape local minimum reach goal low.

phenomenon clearly illustrated considering instance-specific pattern databases
(Holte, Grajkowskic, & Tanner, 2005). instance-specific pattern database, tiles
start closest goals abstracted first, leaving tiles furthest
away goals represented pattern database. helps maximize
heuristic values states near root, due consistency
undesirable side effect making states required included path goal
high heuristic values well. Raising heuristic value initial state helpful
A* search, evidenced reduction number expansions A* using instancespecific abstractions size, shown Table 3. Unfortunately, approach
still powerful greedy best-first search simpler outer L abstraction, even
smaller variant missing 3. instance-specific pattern databases
use patterns difficult greedy best-first search use effectively, similar
problems encountered using checkerboard abstraction.
288

fiEffective Heuristics Suboptimal Best-First Search

Domain

Greedy
Works

Greedy
Fails

Towers Hanoi
Grid
Pancake
Dynamic Robot
Unit Tiles
TopSpin(3)
TopSpin(4)
Inverse Tiles
City Nav 3 3
City Nav 4 4

Heuristic
% Error
29.47
25.11
2.41
15.66
33.37
25.95
32.86
29.49
44.51
37.41

h(n)-h (n)
Correlation
(Pearson)
0.9652
0.9967
0.9621
0.9998
0.7064
0.5855
0.2827
0.6722
0.5688
0.7077

h(n)-h (n)
Correlation
(Spearman)
0.9433
0.9958
0.9593
0.9983
0.7065
0.4598
0.3196
0.6584
0.6132
0.7518

h(n)-h (n)
Correlation
(Kendall)
0.8306
0.9527
0.9198
0.9869
0.5505
0.4158
0.2736
0.4877
0.4675
0.6238

Table 4: Average % error correlation h(n) h (n)

4. Predicting Effectiveness Greedy Heuristics
previous section, saw common wisdom regarding effective heuristics
optimal search carry suboptimal search. Instead, examples motivated
three general observations regarding greedy best-first search looks heuristic.
qualitative observations perhaps helpful heuristics heuristic design,
useful simple, quantitative metric evaluating comparing heuristics.
begin considering two intuitively reasonable quantitative metrics, percent
error h, correlation h h . metrics, show
metric cannot used predict whether greedy best-first search perform
worse Weighted A*. consider measure search distance go called .
(n) h change graph making edges cost 1. find
correlation h used predict greedy best-first search
perform poorly.
4.1 Percent Error h(n)
first metric consider perhaps intuitive measure heuristic performance:
percent error h. define percent error heuristic h (n)h(n)
. Since greedy
h (n)
best-first search increases importance heuristic, reasonable conclude
heuristic large amount error, relying upon heavily, greedy best-first
search does, going lead fast search.
Table 4, average percent error heuristic domains
considered. Surprisingly, average percentage error bears little relation whether
greedy best-search poor choice. Towers Hanoi, unit tiles, TopSpin(3),
three domains greedy best-first search effective, much heuristic
error domains greedy best-first search works poorly. leads us conclude
cannot measure average heuristic percent error use predict whether
increasing weight speed slow search.
289

fiWilt & Ruml

see intuitively makes sense, note greedy best-first search really
requires nodes get put h (n) order heuristic. exact magnitude,
therefore error, heuristic unimportant, magnitude huge effect
average percent error. seen consider heuristic h(n) = h R(n) : R R+
large tiny R, always guide greedy best-first search directly
optimal goal, exhibiting arbitrarily high average percent error heuristic
R increases decreases away 1.
4.2 h h Correlation
next metric consider correlation h h . considering
percent error h metric, noted greedy best-first search run time linear
solution length optimal solution nodes h (n) order. One way
quantify observation measure correlation two values.
three different ways.
well known correlation coefficient Pearsons correlation coefficient r,
measures well relationship h(n) h (n) modeled using linear
function. relationship would mean weighting heuristic appropriately
reduce error heuristic, could reasonably expected lead faster
search. addition, relationship h(n) h (n) linear function,
order preserved: putting nodes order h(n) put nodes order
h (n), leads effective greedy best-first search. domain, calculated
Pearsons correlation coefficient h (n) h(n), results second
column Table 4.
Another reasonable way measure heuristic correlation use rank correlation.
Rank correlation measures well one permutation (or order) respects another permutation (or order). context search, use ask similar order one
gets putting nodes h order order one gets putting nodes h order. Rank
correlation coefficients useful less sensitive outliers, able
detect relationships linear.
Spearmans rank correlation coefficient () best known rank correlation coefficient.
Pearsons r ranked variables. means smallest N heuristic
values mapped 0, largest n heuristic values mapped N . done
h h , point simply calculate Persons r using rankings.
context greedy best-first search, Spearmans rank correlation coefficient high,
means h(n) h (n) put nodes close order. Expanding
nodes h (n) order leads greedy best-first search running time linear solution
length, reasonable conclude strong Spearmans rank correlation coefficient
h (n) h(n) would lead effective greedy best-first search. domain,
calculate Spearmans rank correlation coefficient h (n) h(n),
results third column Table 4.
natural metric measuring relationship achieved using Kendalls
(1938). Kendalls another rank correlation coefficient, measures amount
concordance two rankings. Concordance rankings two
elements agree. context greedy best-first search, concordant pair pair
290

fiEffective Heuristics Suboptimal Best-First Search

nodes h(n1 ) > h(n2 ) h (n1 ) > h (n2 ) h(n1 ) < h(n2 ) h (n1 ) < h (n2 ).
Kendalls proportion pairwise comparisons concordant. h puts nodes
h order, pairwise comparisons concordant, Kendalls 1. h puts
nodes reverse h order, comparisons discordant, Kendalls -1.
sorting nodes h puts nodes random order, expect half comparisons
concordant half comparisons discordant.
Kendalls understood context bubble sort. Kendall distance
number swaps bubble sort would order change one list
other. case, number swaps bubble sort would rearranging list
nodes sorted h list sorted h . Kendalls calculated normalizing
Kendall distance, done dividing N (N 1)/2. 1
Since rank correlation coefficients, related, argue
natural statistic. Consider question: given open list containing n
nodes, likely node smallest h front open
list, given nodes ordered h? use predict node will,
average, middle list h h completely unrelated, closer
front open list stronger (h, h ) correlation is. reason
assume nodes open list random selection nodes, tells us often
random comparison correct. use therefore predict far back node
minimum h is. natural interpretation, making natural
statistic. worth nothing generally related one another, one
used predict (Gibbons, 1985). relationship means practice,
generally possible use either metric.
Returning Table 4, results lead us reject correlation h h
metric predicting well greedy best-first search work. three correlation
coefficients, examples domains greedy best-first search fails high
h(n)-h (n) correlations, examples domains greedy best-first search works well
poor h(n)-h (n) correlations. example, TopSpin(3), Kendalls
.42, lower Inverse Tiles City Navigation problems
consider.
4.3 h Correlation
strategy greedy best-first search discover goal quickly expanding nodes
small h(n) values. nodes small h(n) far away goal reasonable
believe greedy best-first search would perform poorly. denote (n) count
edges node n nearest goal, distance measured summing
cost edges path, rather counting edges path.
(n) equivalent h (n) modify graph edges cost 1. Looking
plot h(n) vs h (n) left half Figure 10, see City Navigation
4 4 reasonable relationship h(n) h (n), nodes low
h(n) tend small h (n) values. denote distance nearest goal terms
1. Malte Helmert noted (personal communication) Kendalls , described, ideal metric
use sequences contain ties. integer-valued heuristics, especially, ties may common.
One way account ties rankings use Kendalls -b statistic (Kendall & Gibbons, 1990)
instead (also known -a). Kendalls -b accounts ties rankings.

291

fiWilt & Ruml

h vs h* City Navigation 4 4

h vs d* City Navigation 4 4
18

120

d*

h*

12

60

6
0
0

80

160

h

40

80

h

Figure 10: Plot h(n) vs h (n), h(n) vs (n) City Navigation 4 4
Domain

Greedy
Works

Greedy
Fails

Towers Hanoi
Grid
Pancake
Dynamic Robot
Unit Tiles
TopSpin(3)
TopSpin(4)
Inverse Tiles
City Nav 3 3
City Nav 4 4

h(n)-d (n)
Correlation
(Pearson)
0.9652
0.9967
0.9621
0.9998
0.7064
0.5855
0.2827
0.5281
0.0246
0.0853

h(n)-d (n)
Correlation
(Spearman)
0.9433
0.9958
0.9593
0.9983
0.7065
0.4598
0.3196
0.5173
-0.0338
0.1581

h(n)-d (n)
Correlation
(Kendall)
0.8306
0.9527
0.9198
0.9869
0.5505
0.4158
0.2736
0.3752
-0.0267
0.1192

Table 5: Correlation h(n) (n)

number edges state space graph (n). right half Figure 10 shows
plot h(n) vs (n). clearly see City Navigation 4 4 domain,
almost relationship h(n) (n), meaning nodes receive small
h(n) value found distance away goal, could explain greedy
best-first search works poorly domain, despite fact h(n) h (n)
closely related.
nodes small h(n) values likely small (n) values (and
nodes therefore close goal, terms expansions away) expanding nodes
small h(n) values quickly lead goal. converse reasonable. nodes
small h(n) value uniform distribution (n) values (and thus many
nodes far away goal terms expansions away), expanding nodes
quickly lead goal.
292

fiEffective Heuristics Suboptimal Best-First Search

7.0
6.5

log(Expansions)

6.0
5.5
5.0
4.5
4.0
3.5
3.0
2.5
0.0

0.1

0.2

0.3

0.4
GDRC

0.5

0.6

0.7

0.8

Figure 11: Average log expansions done greedy best-first search different heuristics, plotted according GDRC.

domain, quantify concept calculating Pearsons correlation coefficient, Spearmans rank correlation coefficient, Kendalls (n) h(n).
Looking Table 5, see that, using Kendalls Pearsons r, finally
able separate domains greedy best-first search performs well domains greedy best-first search performs poorly. Kendalls , draw
line approximately 0.4 used separate domains greedy best-first
search works well domains greedy best-first search works poorly. Likewise,
Pearsons r, draw line approximately .55. call type metric
Goal Distance Rank Correlation (GDRC) and, unless otherwise noted, compute using
Kendalls .
correlation (n) h(n) connects three observations, although
connection mathematical necessity (as counterexamples constructed).
Note heuristic obeys Observation 1 produce paths h monotonically
decreases goal. Consider nodes along path goal. hypothesis, h
monotonically decrease along path. Now, consider one nodes goal end
path. Since h monotonically decreases along path, nodes goal end
path low h, near end path, low
value. little else said nodes general, restriction improves
heuristics GDRC compared situation nodes low allowed
high h values. similar argument used show following Observation 2
helps produce heuristic high GDRC.
Observation 3 discusses nodes local minimum, difference h nodes
local minimum, nodes edge local minimum. assume
order escape local minimum one must go one nodes edge
293

fiWilt & Ruml

local minimum, know nodes local minimum must higher
nodes edge local minimum, know h lower
(because node local minimum). means h ranking incorrectly
orders nodes local minimum compared nodes edge local
minimum, clear problem producing high GDRC. nodes local minimum
low get goal high h node, relationship
observation GDRC weaker. Consider personal transportation
example. action as, call taxi might result reaching states near goal
one step, high cost. heuristic recognizes cost action, node
correctly high h, close goal measured
call taxi path. situation clearly causes problems domains attempting
follow Observation 3, believe domains kind attribute are, practice,
quite uncommon. example, none example domains exhibit trait.
4.4 Comparing Heuristics
quantitative metric, GDRC used compare different heuristics
domain. test effectiveness, ran experiments Towers Hanoi
problem using 17 different disjoint non-disjoint pattern databases. considered
pattern databases 3 8 disks, well selection pairings PDBs
total number disks less equal 12. pattern database,
calculated GDRC heuristic produced PDB. Figure 11 plot,
PDB, GDRC PDB X axis average log number
expansions required greedy best-first search solve 51 random 12-disk Towers Hanoi
problems axis. see figure, GDRC roughly
0.4, greedy best-first search performs poorly, GDRC increases, average
number expansions done greedy best-first search decreases. suggests
possible use GDRC directly compare heuristics one another.
see similar behavior different domain left part Figure 12.
dot represents one 462 possible disjoint 5/6 pattern databases (one 6 tile PDB
one 5 tile PDB disjoint) 3 4 sliding tile puzzle inverse costs.
axis log average expansions required solve 100 random instances.
X axis GDRC. Since using non-unit problem, h same,
calculate correlation h h . right part Figure 12,
correlation X axis.
see, GDRC rank correlation h h yield useful
information well greedy best-first search likely work.
domains tested, correlation h neatly predicts
greedy best-first search performs worse Weighted A* (or A*). perfect, however.
consider heuristic h(n) = h (n), measure correlation h(n)
h (n) perfect, relationship h(n) (n) heuristic could
arbitrarily poor. heuristic approaches truth, h(n)-h (n) correlations
approach 1, allows Weighted A* scale gracefully, greedy best-first search
linear run time, matter correlation h(n) (n) is.
situation, looking solely correlation h(n) (n) determine whether
294

fi5.0

5.0

4.5

4.5

4.0

4.0
Log10(expansions)

Log10(expansions)

Effective Heuristics Suboptimal Best-First Search

3.5
3.0

3.5
3.0

2.5

2.5

2.0

2.0

1.5
0.35

0.40

0.45

GDRC

0.50

0.55

1.5
0.45

0.60

0.50

0.55

0.60
0.65
0.70
0.75
GDRC (with h* instead d*)

0.80

0.85

Figure 12: Average log expansions done greedy best-first search
possible 462 5/6 disjoint PDB heuristics, plotted GDRC (left)
correlation h(n) h (n)
Domain

City Nav 5 5

Heuristic h(n)-h (n)
% Error Correlation
(Pearson)
31.19
0.9533

h(n)-h (n)
Correlation
(Spearman)
0.9466

h(n)-d (n)
Correlation
(Pearson)
0.0933

h(n)-d (n)
Correlation
(Spearman)
0.0718

Table 6: Average % error, correlation h(n) h (n), correlation
h(n) (n) City Nav 5 5

greedy best-first search faster Weighted A* may produce incorrect
answer.
seen City Navigation 5 5 domain. City Navigation 5 5 similar
City Navigation problems consider, except cities places
better connected, allowing direct routes taken. Since routes direct,
thus shorter, heuristic accurate. Table 6 shows various correlations
percent error h(n) City Navigation 5 5. Figure 13 shows increase
weight, despite weak correlation h(n) (n), catastrophe:
greedy best-first search expands roughly number nodes Weighted A*
best weight speed. occurs extreme strength heuristic,
correlates h (n) .95, extremely strong correlation.
next question correlation matters more: h (n) (n). Clearly, perfect
correlation h (n) h(n) (n) h(n) lead fast greedy best-first
search, leads us conclusion order greedy best-first search
effective, nodes small h(n) get expanded required least one virtue:
either close goal measured terms remaining search distance
(small (n)) close goal measured terms remaining cost (small h (n)).
295

fiWilt & Ruml

City Navigation 5 5

Total Nodes Expanded

3000

2000

1000

0

A* 1.1 1.2 2.5 5

10 20 G

Figure 13: Expansions done A*, Weighted A*, greedy best-first search City
Navigation 5 5

seen empirically two correlations break down, (n) correlation allows
greedy best-first search survive longer: tested domains (n)-h(n)
.58, greedy best-first search well, whereas seen domains h (n)h(n) correlation high .70 (or .75, depending correlation metric
used) greedy best-first search performs poorly.
importance correlation h(n) (n) reflects importance
node ordering greedy best-first search. optimal search, search cannot terminate
solution found, rather solution known optimal
paths pruned. larger heuristic values, sooner nodes
pruned. means optimal search, heuristic size paramount importance:
bigger better. greedy best-first search, heuristic used guide search
solution, relative magnitude heuristic (or error heuristic) bearing
performance search, saw considered percent error h.
common researchers say A*s heuristic guides search, discussion
reveals language reserved suboptimal search.
heuristics able satisfy needs A* greedy best-first search
simultaneously. example, dynamic robot navigation heuristic works extremely well
A* greedy best-first search, big, therefore good A*,
good differentiating nodes near goal far away goal,
helping greedy best-first search.

5. Building Heuristic Searching GDRC
shown Haslum, Botea, Helmert, Bonet, Koenig (2007), given metric assessing quality heuristic, use metric automatically construct effective
abstraction-based heuristics simply searching space abstractions. many domains, heuristic constructed initially abstracting everything, slowly refining
296

fiEffective Heuristics Suboptimal Best-First Search

abstraction construct heuristic. Haslum et al. (2007) concerned
optimal search hence use pruning power evaluate heuristics, focus greedy bestfirst search suggests GDRC might serve useful metric. example, TopSpin
problem, begin heuristic abstracts disks. consider PDBs
devised abstracting everything except one disk, measure GDRC
pattern database. GDRC effectively estimated breadth-first search
backwards goal (we used 10,000 nodes 12 disk problem) establish values
nodes, h value looked pattern database. sample 10%
nodes generated way, used sample calculate estimate Kendalls
. elected sample 10%, nodes, sample size taken provided
confidence interval sufficiently small tell better. Last, take PDB
highest value incumbent PDB. process repeats either PDBs
worse GDRC previous best PDB, PDB reached desired
size. reason allow algorithm possibly terminate early cover case
GDRC decreasing larger PDBs. increasing size PDB decreases GDRC,
likely increasing size PDB degrade GDRC even more,
elect terminate. full algorithm detailed Algorithm 1. simple
hill-climbing search appears effective, sophisticated search strategy could certainly
employed instead.
5.1 TopSpin
Algorithm 1 Hill Climbing PDB Builder
1: AllTokens = {Tokens problem abstracted}
2: RemainingTokens = AllT okens
3: BestPDB = build PDB abstracting AllT okens
4: BestTau = 0
5: function tryPDB(tokens)
6:
pdb = build PDB abstracting AllT okens \ tokens
7:
allNodes = nodes discovered breadth first search backwards goal state(s)
8:
sample = randomly sample 10% nodes allNodes
9:
return calcTau(sample, pdb)
10: BestP DB.size < Max Allowed Size
11:
LocalBestPDB, LocalBestTau, LocalBestToken = (N one, BestT au, N one)
12:
CurrentToken RemainingT okens
13:
CurrentTau, CurrentPDB = tryPDB(Ref inedT okens {token})
14:
CurrentT au > LocalBestT au
15:
set local best variables current
16:
LocalBestP DB 6= None
17:
set best variables local best variables
18:
RemainingTokens = RemainingT okens \ LocalBestT okens
19:
else
20:
Break
21: return BestPDB
297

fiWilt & Ruml

PDB
Contiguous
Big Operators
Random

Greedy Exp
411.19
961.11
2,386.81

A* Exp
10,607.45
411.27
26,017.25

Avg. Value
52.35
94.37
47.99

Table 7: Expansions solve TopSpin problem stripe cost function using different
PDBs

used generate unit-cost TopSpin pattern databases, hill-climbing GDRC
always produced PDBs abstracted disks connected one another,
refined disks connected one another. prevents abstraction
creating regions h = 0, goal nowhere near h = 0 nodes, per
Observation 2.
unit-cost TopSpin problems, abstractions disks connected
one another work well greedy best-first search A*. change cost
function moving even disk costs 1 moving odd disk costs 10, get
stripe cost function, called costs striped across problem.
effective PDBs A* keep many odd disks possible, moving
odd disks much expensive moving even disk. use big
operator pattern database greedy best-first search, algorithm align high
cost odd disks, great difficulty escaping resulting local minimum.
use hill climbing GDRC build heuristic, end contiguous heuristic
keeps abstracted refined disks connected one another. Table 7 provides
results various pattern databases solving suite instances. see
importance creating good pattern database consider Random row
table, contains average number expansions 20 different randomly selected
6 disk pattern databases.
5.2 Towers Hanoi
already infer Figure 11 that, greedily select PDB best
collection PDBs, would select best one. certainly possible
use hill-climbing search incrementally construct PDB. creating PDB
heuristic Towers Hanoi, one maps full size problem onto abstracted version
problem removing disks larger problem, re-indexing
remaining disks map disks smaller problem. technique,
critical component terms performance disks abstracted.
define mapping selection disks abstract. example,
consider 12 disk problem using 8 disk PDB, must select 4 12 total disks
abstract. Figure 14 + glyphs represent randomly selected abstraction,
heuristic produced. see, abstractions produced extremely poor
quality heuristics measured GDRC average number expansions done
greedy best-first search solving problems using heuristic. heuristics fared
significantly better terms GDRC average expansions greedy best-first
298

fiEffective Heuristics Suboptimal Best-First Search

Analysis
heuristics generated different Hanoi PDB mappings
8
7

Log expansions

6
5
4
3
2
0.2

Randomly selected mappings
Best Mapping
Hill Climbing Mappings
0.0

0.2

0.4
GDRC

0.6

0.8

1.0

Figure 14: Expansions using different Towers Hanoi PDB abstractions.
search. examine plot Figure 14 see several clusters
heuristics. heuristics GDRC 0 clustered together, requiring
greedy best-first search expand 107 108 nodes. heuristics
worst heuristics, largest disk abstracted. next cluster heuristics
GDRC 0.4 0.5 require greedy best-first search expand 106.5
107 nodes. heuristics largest disk abstracted, second
largest disk abstracted. abstractions produce poor quality heuristics,
heuristics represent significant improvement heuristics largest
disk abstracted. color Figure 14 represents mapping different largest
abstracted disk, blue X glyph representing best pattern database
smallest disks abstracted. see plot, definite overall trend
mappings product heuristics higher GDRC tend fare better overall
terms average total expansions used greedy best-first search.
hill climbing algorithm selected heuristic contained disks 0, 1, 2, 4, 5, 6,
7, 8 (skipping 3 disk). example hill climbing algorithm selected
heuristic seen green circles line Figure 14 starting
abstraction abstracted largest disk. hill climbing algorithm climbed hill
leading reasonable, albeit effective, heuristic. Despite failing find
optimal heuristic, selected heuristic quite reasonable nonetheless, falling
86th 75th percentile overall, significant improvement automated approach.
5.3 City Navigation
addition building pattern database heuristics using hill climbing GDRC,
possible build portal-style heuristic hill climbing GDRC. Using city navigation
domain, defined portal heuristic (Goldenberg, Felner, Sturtevant, & Schaeffer, 2010)
selecting number nodes portal nodes (we used number nodes
299

fiWilt & Ruml

Heuristic
Random Portals
Nexus Portals
Hill Climbed Portals

Average GDRC
0.44
0.76
0.60

Average greedy best-first search expansions
2200
488
1117

Table 8: Expansions GDRC using different ways select portal nodes

cities, 150), calculating true distance every node closest portal node.
heuristic two nodes true distance portals associated
node minus distance node portal. event quantity
negative, 0 used. heuristic highly accurate across long distances uses
true distance portals, obviously less accurate comparing
two nodes share portal. constructing portal heuristics, critical
difference effective portal heuristic poor quality portal heuristic
selection nodes portals. allowed algorithm automate process
hill climbing GDRC. algorithm initialized random array nodes
portals. step, algorithm iterates indexes array portals,
considering moving location currently serving portal different location.
implementation, considered two times number cities, 300 different
random places. assessed GRDC new heuristic using sample 100,000
randomly selected pairs places. moving city new location improved GDRC,
kept portal array new place, otherwise, discarded change GDRC
inferior incumbent. reach end array, restart
beginning. reach point position array,
aspects array remain unchanged since last time modified index,
algorithm terminates, returning array portals use heuristic.
Results experiment shown Table 8. average GDRC GDRC
one obtains selecting 100,000 random pairs start end nodes calculating
GDRC using nodes. average greedy best-first search expansions average
number expansions needed solve City Navigation problem random start
goal.
considered three different methods selecting portal nodes. first
completely randomize selection portal nodes, unsurprisingly resulted
lowest GRDC highest number expansions. successful method
selecting portal nodes identify nexus nodes, use nodes portals.
Unsurprisingly, method led highest GDRC, fewest number expansions.
result demonstrates usefulness GDRC identifying quality heuristic
greedy best-first search. Last, automatic algorithm finding portal nodes performed
significantly better random, still trailing hand-selected portals. believe
better search strategy may able better capture potential performance gain
offered high GDRC heuristics.
300

fiEffective Heuristics Suboptimal Best-First Search

5.4 Sliding Tile Puzzle
compare GDRC-generated PDBs instance-specific PDBs sliding
tile puzzle (Holte et al., 2005). domain, order get accurate estimate
, increase number nodes expanded going backwards 10,000
1,500,000. Following hill climbing procedure, algorithm selected pattern database
tracked 1, 3, 4, 7, 8, 11 tiles. results using PDB shown Table
3. abstraction strong outer L abstraction, fourth best
PDB minimizing average number expansions done greedy best-first search
462 possible 6-tile pattern databases. automatically constructed PDB
two orders magnitude faster number expansions one would expect
using average 6-tile PDB, three orders magnitude faster worst 6-tile
PDB greedy best-first search. GDRC-generated PDB works substantially better
greedy best-first search state-of-the-art instance-specific PDBs, requiring one
twentieth expansions. One additional advantage GDRC-generated PDB
instance-specific PDBs fact GDRC produces single PDB, unlike instance
specific PDBs, produce new PDB every problem.
summary, results show GDRC useful predicting relative quality
heuristics greedy best-first search. showed possible leverage
quantitative metric automatically construct heuristic greedy best-first search,
automatically created heuristics extraordinarily effective greedy best-first
search.

6. Related Work
metric, GDRC predicts heuristics high rank correlation
work well. general, objective h approximate h , , one alternative way
find quality heuristic leverage fact try construct heuristic directly
mimics , generally referred d. Indeed, approach generally quite successful
(as opposed relying exclusively h), handily outperforming h many situations (Wilt
& Ruml, 2014).
Gaschnig (1977) describes predict worst case number nodes expanded
A*, discusses weighting heuristic affect worst case final node
expansion count. predictions, however, two limitations. First, predictions
assume search space tree, graph, case many applications
heuristic search. addition that, worst case predictions depend amount
error present heuristic, error measured relative deviation h (n).
A*, criterion makes certain amount sense, greedy best-first search,
seen relative deviation h (n) cannot used predict greedy
best-first search perform poorly. Gaschnig points increasing weight ad
infinitium may decrease performance, precisely phenomenon documented
Section 2.
Chenoweth Davis (1991) show heuristic rapidly growing logarithmic cluster, greedy best-first search done polynomial time. heuristic
rapidly growing logarithmic cluster if, every node n, h(n) within logarithmic
factor monotonic function f h (n), f grows least fast function
301

fiWilt & Ruml

g(x) = x. aware heuristics proven rapidly growing
logarithmic cluster.
number works consider question predicting search algorithm performance
(Korf et al., 2001; Pearl, 1984; Helmert & Roger, 2008), although subject attracting
far attention determining many nodes expanded optimal
search algorithm. saw Section 3, behavior optional search general
predict behavior GBRS. Lelis, Zilles, Holte (2011) empirical analysis
suboptimal search algorithms, predicting number nodes would expanded
Weighted IDA*, clear methods predict greedy best-first search
behavior, thus tell us increasing weight far detrimental.
Korf (1993) provides early discussion increasing weight may actually
bad, showing recursive best first search iterative deepening A* used
weight large, expansions actually increase. paper early example
exploring weight interacts expansion count, something central
work.
Hoffmann (2005) discusses heuristic (Hoffmann & Nebel, 2001) effective way solve many planning benchmarks used conjunction enforced
hill climbing. paper shows many benchmark problems, heuristic small
bounded-size plateaus, implying breadth-first search part enforced hill climbing algorithm bounded, means problems solved quickly, sometimes linear time. Although enforced hill climbing kind greedy best-first search,
behaviour different greedy best-first search promising path turns
local minimum. Greedy best-first search considers nodes search
space, possibly allowing disparate nodes compete one another expansion.
Enforced hill climbing limits consideration nodes near local minimum (with
nearness measured edge count), means algorithm cares
heuristic performs small local region space. Hoffmann (2011) extends
concept, describing process automatically proving domain small local
minima.
Xu, Fern, Yoon (2009) discuss constructing heuristics suboptimal heuristic
search, algorithm consider beam search. Beam searches inadmissibly
prune nodes save space time, function ultimately used rank
nodes, make decision whether keep one node. function
Xu et al. create used rank nodes, input function requires variety
features state function, created using training data trial search runs.
approach creating heuristic hill-climbing GDRC require training
instances, require information states themselves. Hill-climbing
GDRC does, however, limitation automatic generation heuristics
works appropriate search space defined, abstraction-based
heuristics.

7. Conclusion
Suboptimal heuristic searches rely heavily heuristic node evaluation function.
first showed greedy best-first search sometimes perform worse A*,
302

fiEffective Heuristics Suboptimal Best-First Search

although many domains general trend larger weight heuristics
Weighted A* leads faster search, domains larger weight leads
slower search. long understood greedy best-first search bounds
performance, given poor heuristic, greedy best-first search could well expand
entire state space, never terminate state space infinite. work shows
poor performance theoretical curiosity, behavior occur
practice.
considered characteristics effective heuristics greedy best-first search.
showed several examples conventional guidelines building heuristics A*
actually harm performance greedy best-first search. used experience
develop alternative observations desiderata heuristics use greedy bestfirst search. first every node, path goal
decreases h. second, important special case first, nodes h = 0
connected goal via nodes h = 0. third observation nodes
require including high h nodes solution high h
value possible.
showed domains greedy best-first search effective share
common trait heuristic function: true distance node goal, defined
(n), correlates well h(n). information important anyone running
suboptimal search interest speed, allows identify whether
assumption weighting speeds search true not, critical knowledge
deciding algorithm use.
Finally, showed goal distance rank correlation (GDRC) used compare
different heuristics greedy best-first search, demonstrated used
automatically construct effective abstraction heuristics greedy best-first search.
Recent work shown search algorithms explicitly designed suboptimal
setting outperform methods weighted A*, simple unprincipled derivative
optimal search (Thayer & Ruml, 2011; Thayer, Benton, & Helmert, 2012; Stern,
Puzis, & Felner, 2011). results indicate holds true heuristic functions
well: suboptimal search deserves specialized methods. Given importance
suboptimal methods solving large problems quickly, hope investigation spurs
analysis suboptimal search algorithms heuristic functions rely on.

8. Acknowledgments
gratefully acknowledge support NSF (award 1150068). Preliminary expositions
results published Wilt Ruml (2012, 2015).

References
Burns, E. A., Hatem, M., Leighton, M. J., & Ruml, W. (2012). Implementing fast heuristic
search code. Proceedings Fifth Symposium Combinatorial Search.
Chenoweth, S. V., & Davis, H. W. (1991). High-performance A* search using rapidly
growing heuristics. Proceedings Twelfth International Joint Conference
Articial Intelligence, pp. 198203.
303

fiWilt & Ruml

Doran, J. E., & Michie, D. (1966). Experiments graph traverser program.
Proceedings Royal Society London. Series A, Mathematical Physical
Sciences, pp. 235259.
Felner, A., Korf, R. E., Meshulam, R., & Holte, R. C. (2007). Compressed pattern databases.
Journal Artificial Intelligence Research (JAIR), 30, 213247.
Felner, A., Zahavi, U., Holte, R., Schaeffer, J., Sturtevant, N. R., & Zhang, Z. (2011).
Inconsistent heuristics theory practice. Artificial Intelligence, 175 (9-10), 1570
1603.
Gaschnig, J. (1977). Exactly good heuristics?: Toward realistic predictive theory
best-first search. Proceedings Fifth International Joint Conference
Articial Intelligence, pp. 434441.
Gibbons, J. D. (1985). Nonparametric Statistical Inference. Marcel Decker, Inc.
Goldenberg, M., Felner, A., Sturtevant, N., & Schaeffer, J. (2010). Portal-based truedistance heuristics path finding. Proceedings Third Symposium Combinatorial Search.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination minimum cost paths. IEEE Transactions Systems Science Cybernetics,
SSC-4 (2), 100107.
Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independent
construction pattern database heuristics cost-optimal planning. Proceedings
AAAI-07, pp. 10071012.
Helmert, M. (2006). fast downward planning system. Journal Artificial Intelligence
Research, 26, 191246.
Helmert, M. (2010). Landmark heuristics pancake problem. Proceedings
Third Symposium Combinatorial Search.
Helmert, M., & Roger, G. (2008). good almost perfect?. Proceedings
Twenty-Third AAAI Conference Artificial Intelligence (AAAI-2008), pp. 944949.
Hoffmann, J. (2005). Ignoring delete lists works: Local search topology planning
benchmarks. Journal Artifial Intelligence Research, 24, 685758.
Hoffmann, J. (2011). Analyzing search topology without running search: connection causal graphs h+ . Journal Artificial Intelligence Research, 41,
155229.
Hoffmann, J., & Nebel, B. (2001). planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Holte, R., Grajkowskic, J., & Tanner, B. (2005). Hierachical heuristic search revisitied.
Symposium Abstracton Reformulation Approximation, pp. 121133.
Kendall, M. G. (1938). new measure rank correlation. Biometrika, 30 (1/2), 8193.
Kendall, M., & Gibbons, J. D. (1990). Rank Correlation Methods (Fifth edition). Edward
Arnold.
304

fiEffective Heuristics Suboptimal Best-First Search

Korf, R., & Felner, A. (2002). Disjoint pattern database heuristics. Artificial Intelligence,
134, 922.
Korf, R. E. (1987). Planning search: quantitative approach. Artificial Intelligence,
33 (1), 6588.
Korf, R. E. (1993). Linear-space best-first search. Artificial Intelligence, 62, 4178.
Korf, R. E. (1997). Finding optimal solutions Rubiks cube using pattern databases.
Proceedings Fourteenth National Conference Artificial Intelligence, AAAI97,
pp. 700705. AAAI Press.
Korf, R. E. (2007). Analyzing performance pattern database heuristics. Proceedings
22nd National Conference Artificial Intelligence, AAAI07, pp. 11641170.
AAAI Press.
Korf, R. E., Reid, M., & Edelkamp, S. (2001). Time complexity iterative-deepening-A*.
Artificial Intelligence, 129, 199218.
Korf, R. E., & Taylor, L. A. (1996). Finding optimal solutions twenty-four puzzle.
AAAI, Vol. 2, pp. 12021207.
Lelis, L., Zilles, S., & Holte, R. C. (2011). Improved prediction IDA*s performance via
epsilon-truncation. Proceedings Fourth Symposium Combinatorial Search.
Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Anytime A* provable bounds
sub-optimality. Proceedings Seventeenth Annual Conference Neural
Information Processing Systems.
Likhachev, M., & Ferguson, D. (2009). Planning long dynamically feasible maneuvers
autonomous vehicles. International Journal Robotic Research, 28 (8), 933945.
Martelli, A. (1977). complexity admissible search algorithms. Artificial Intelligence, 8 (1), 113.
Nilsson, N. J. (1980). Principles Artificial Intelligence. Tioga Publishing Co.
Parberry, I. (1995). real-time algorithm (n2 -1)-puzzle. Information Processing
Letters, 56 (1), 2328.
Pearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving.
Addison-Wesley.
Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence,
1, 193204.
Richter, S., Thayer, J. T., & Ruml, W. (2009). joy forgetting: Faster anytime search
via restarting. Proceedings Twentieth International Conference Automated
Planning Scheduling.
Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime
planning landmarks. Journal Artifial Intelligence Research, 39, 127177.
Stern, R. T., Puzis, R., & Felner, A. (2011). Potential search: bounded-cost search
algorithm. Proceedings 21st International Conference Automated Planning
Scheduling, ICAPS.
305

fiWilt & Ruml

Sussman, G. J. (1975). Computer Model Skill Acquisition. New York: New American
Elsevier.
Thayer, J. T., Benton, J., & Helmert, M. (2012). Better parameter-free anytime search
minimizing time solutions. Proceedings Fifth Annual Symposium
Combinatorial Search, SOCS 2012.
Thayer, J. T., & Ruml, W. (2011). Bounded suboptimal search: direct approach using inadmissible estimates. Proceedings Twenty Sixth International Joint
Conference Articial Intelligence (IJCAI-11), pp. 674679.
Tukey, J. W. (1977). Exploratory Data Analysis. Addison-Wesley, Reading, MA.
van den Berg, J., Shah, R., Huang, A., & Goldberg, K. Y. (2011). Anytime nonparametric
A*. Proceedings Twenty Fifth National Conference Articial Intelligence.
Wilt, C., & Ruml, W. (2012). weighted A* fail?. Proceedings Fifth
Symposium Combinatorial Search.
Wilt, C., & Ruml, W. (2014). Speedy versus greedy search. Proceedings Seventh
Symposium Combinatorial Search.
Wilt, C., & Ruml, W. (2015). Building heuristic greedy search. Proceedings
Eighth Symposium Combinatorial Search.
Xu, Y., Fern, A., & Yoon, S. (2009). Learning linear ranking functions beam search
application planning. Journal Machine Learning Research, 10, 15711610.

306


