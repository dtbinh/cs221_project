journal artificial intelligence

submitted published

learning symbolic stochastic domains
hanna pasula
luke zettlemoyer
leslie pack kaelbling

pasula csail mit edu
lsz csail mit edu
lpk csail mit edu

mit csail
cambridge

abstract
article work towards goal developing agents learn act
complex worlds develop probabilistic relational rule representation
compactly noisy nondeterministic action effects rules
effectively learned experiments simple domains simulated
blocks world realistic physics demonstrate learning allows
agents effectively model world dynamics

introduction
one goals artificial intelligence build systems act complex environments effectively humans perform everyday human tasks making breakfast
unpacking putting away contents office many tasks involve manipulating objects pile things put objects boxes drawers arrange
shelves requires understanding world works depending
objects pile arranged made pile sometimes slips falls
pulling drawer usually opens sometimes drawer sticks moving box
typically break items inside
building agents perform common tasks challenging work
developing rule representation agents use
model learn effects acting environment learning allows agents
adapt environments without requiring humans hand craft something
humans notoriously bad especially numeric parametrization required
representation use probabilistic relational includes additional logical
concepts present supervised learning uses representation language
build model action effects given set example action executions optimizing
tradeoff maximizing likelihood examples minimizing complexity
current hypothesis effectively selects relational model structure
set model parameters language relational concepts together provide
compact yet highly accurate description action effects
agent hopes act real world must integrated system perceives
environment understands commands motors effect changes unfortunately
current state art reasoning learning perception locomotion
manipulation far removed human level abilities cannot yet contemplate
c

ai access foundation rights reserved

fipasula zettlemoyer pack kaelbling

figure three dimensional blocks world simulation world consists table several cubes
roughly uniform density varying size robotic gripper moved
simulated motors

working actual domain interest instead choose work domains
almost ridiculously simplified proxies
one popular proxy used since beginning work ai fikes
nilsson world stacking blocks typically formalized version
logic predicates b clear describe relationships blocks
one another blocks neatly stacked dont fall jumbles
article present work context slightly less ridiculous version blocks
world one constructed three dimensional rigid body dynamics simulator ode
example world configuration shown figure simulated blocks
world blocks vary size colour piles tidy may sometimes fall
gripper works medium sized blocks unreliable even
capable enabling effective behavior domain must handle noisy
nondeterministic nature nontrivial dynamics able handle
domains similar characteristics
one strategy formulating learn worlds dynamics
use different courses action goals may change
time another strategy assume fixed goal reward function learn
policy optimizes reward function worlds complexity imagining
would impossible establish advance appropriate reaction every possible
situation addition expect agent overall control architecture
hierarchical individual level hierarchy changing goals
reasons learn model world dynamics use make plans
achieve goals hand
begin describing assumptions underlie modeling decisions
describe syntax semantics modeling language give
reasonable alternative advocated brooks working real world
natural complexity solving almost ridiculously simplified proxies
interest



filearning symbolic stochastic world dynamics

learning language validate introduce simple
provide empirical demonstrating utility learned
showing plan finally survey relevant previous work
draw conclusions

structured stochastic worlds
agent introduced novel world must best possible explanation
worlds dynamics within space possible represent defined
agents representation language ideal language would able compactly model
every action effect agent might encounter others extra modeling capacity
wasted complicate learning since agent consider larger space
possible likely overfit experience choosing good representation
language provides strong bias learn language
languages used describe deterministic
least surface first order abstract particular identities objects describing effects actions terms properties relations among
objects accomplish letting action take arguments representing
arguments variables representational capacity crucial reasons compactness generalization usually grossly inefficient describe behavior
individual objects
much original work probabilistic uses formalism markov decision processes represents states world individually atomically puterman recently propositional factored representations dynamics
employed boyen koller guestrin koller parr venkataraman
first order representations developed including probabilistic rules blum langford equivalence classes draper hanks weld situation calculus
boutilier reiter price representations make easy
articulate take direct advantage two useful assumptions world dynamics
frame assumption states agent takes action world anything
explicitly changed stays outcome assumption states
action affects world small number distinct ways possible effect causes
set changes world happen together single outcome
take point departure probabilistic first order representations world
dynamics representations traditionally applied domains logistics
traditional abstract blocks world idealized symbolic abstractions
underlying domain goal learn realistic worlds requires
us adapt modeling language accommodate additional uncertainty complexity

allowing rules refer objects mentioned argument list action
relaxing frame assumption allowing unmodeled noise changes world
extending language allowing complex forms quantification construction concepts


fipasula zettlemoyer pack kaelbling

action parameterization traditional representations action dynamics objects
whose properties may changed action must named argument
list action instead define actions parameters describe
objects free parameters action example block picked
object currently held block placed however actions change
properties objects ones parameter list
way determining objects affected
introduce use deictic references identify objects deictic references agre
chapman identify objects relative agent action performed
example refer objects thing block picked
currently held object table block accidentally falls onto use deictic
references mechanism adding logical variables much
way benson
modeling noise complex domains actions affect world variety ways
must learn model circumstances reasonable effects
behavior unusual situations complicates dynamics makes
learning difficult actions executed physical world
guaranteed small number simple effects may violate
outcomes assumption blocks world happen example stack
knocked develop simple noise mechanism allows us partially model
action effects ignoring ones rare complicated model explicitly
language extension traditional symbolic domains rules constructed
predefined set observable predicates however sometimes useful define additional
predicates whose truth values computed predefined ones
found essential modeling certain advanced domains edelkamp
hoffman
traditional blocks worlds example usual set predicates contains clear
inhand working realistic noisy blocks world found
predicates would sufficient allow agent learn accurate model
example would difficult state putting block tall stack likely cause
stack topple without concept stack height state attempting
pick block clear usually picks block top stack without
way describing block top stack
could simply add additional predicates seem useful perceptual
language hand engineering appropriate language every time tackle
difficult time consuming error prone state art representations
pddl edelkamp hoffman use concept language define predicates
concepts terms previous simpler ones concepts
learned much predicates invented ilp khan muggleton parson
see traditional blocks world predicates including inhand clear
well useful concepts height easily defined terms given simple
concept language yoon fern givan


filearning symbolic stochastic world dynamics

state action representation
goal learn model state transition dynamics world need
able represent set possible states world set possible
actions agent take represent components subset
relatively standard first order logic equality representation states actions
ground inference learning
begin defining primitive language includes set constants c set
predicates set functions three types functions traditional
functions range objects discrete valued functions range predefined
discrete set values integer valued functions range finite subset
integers primitives observed directly world work
assume environment completely observable agent able
perceive unambiguous correct description current state constants
c assumed intrinsic meaning viewed meaningless markers
assigned perceptual system described detail
state representation
states describe possible different configurations properties relations
objects state describes particular configuration values
objects world individual objects denoted constants
limit number objects world configuration though current
formalism mechanism creation deletion objects
world dynamics
formally state descriptions conjunctive sentences form




tg c









tg c

x arity predicate function x c set c cn constants g x
set length lists elements x indicates predicates may
optionally negated indicates functions assigned value
range manner states list truth values possible groundings
predicates functions terms sentence gives complete specification
vocabulary properties interrelations c objects present
world note predicate function arguments constants never
terms made function symbols descriptions finite given finite
language
rest section describe two approaches denoting objects
constants c illustrate example conjunctive state sentences
intrinsic constants
first state descriptions refers objects intrinsic constants
intrinsic constant associated particular object consistently used denote
strong ultimately indefensible assumption one highest priorities future
work extend case environment partially observable



fipasula zettlemoyer pack kaelbling

object constants useful perceptual system unique way
identify perceived objects independent attributes relations one another
example internet software agent might access universal identifiers
distinguish objects perceives
example let us consider representing states simple blocks world
language contains predicates clear inhand inhand nil block table
integer valued function height objects world include blocks block block b
table table gripper blocks blocks table block
nothing clear gripper hold one block empty sentence
inhand nil block block b block b table block b block
block table table block table block b table table
block block block b block b table table table block

table block b block block block block b block table clear block
clear block b clear table inhand block inhand block b
inhand table height block height block b height table
represents blocks world gripper holds nothing two blocks single
stack table block block top stack block b block
table table
encoding sentence contains meaningful information objects
identities used learning world dynamics
skolem constants
alternatively states denote objects skolem constants skolem constants
arbitrary identifiers associated objects world inherent
meaning beyond used state description constants useful
perceptual system way assigning meaningful identifiers objects
observes example consider robot might build state description room
finds assume robot observe objects present
properties relationships however naming objects
reason choose particular name specific object instead creates
arbitrary identifiers skolem constants uses build state
skolem constants rewrite sentence
inhand nil c c c c c c
c c c c c c c c
c c c c table c table c
table c block c block c block c clear c
clear c clear c inhand c inhand c
inhand c height c height c height c
perceptual system describes table two blocks arbitrary
constants c c c
skolem constants interpreted skolemizations existential variables



filearning symbolic stochastic world dynamics

perspective states world isomorphic interpretations
logical language since might many interpretations satisfy particular statespecification sentence interpretations permutation
objects constants refer occurs objects distinguishable
properties relations objects
techniques develop generally applicable representing
learning dynamics worlds intrinsic constants skolem constants
highlight cases true presented see
use skolem constants perceptually plausible forces us
create learning abstract object identity aggressively previous
work improve quality learned
action representation
actions represented positive literals whose predicates drawn special set
whose terms drawn set constants c associated world
action executed
example simulated blocks world contains pickup action picking
blocks puton action putting blocks action literal pickup block
could represent action gripper attempts pickup block block
state represented sentence

world dynamics representation
learning probabilistic transition dynamics world viewed
conditional probability distribution pr represent
dynamics rules constructed basic logic described section
logical variables abstract identities particular objects world
section begin describing traditional representation deterministic world
dynamics next present probabilistic case finally extend ways
mentioned section permitting rules refer objects mentioned
action description adding noise extending language allow
construction concepts
dynamic rule action z form
x x z x x
meaning vector terms x context holds
current time step taking action z x cause formula hold terms
next step action z x must contain every xi x constrain
conjunctions literals constructed primitive predicates terms xi x
functions applied terms set equal value range addition
allowed contain literals constructed integer valued functions term related
integer range greater less predicates
say rule covers state action exists substitution
mapping variables x c note may fewer variables x constants


fipasula zettlemoyer pack kaelbling

c x z x substitution constants
variables applied context x grounds entailed
state applied rule action z x makes equal action
given rule covers say subsequent state
first rule directly specifies x holds next step may
incomplete specification state use frame assumption fill rest
x





l x

tg c pos x







l x

tg c funct x

l stands literal predicate function argument
list pos set literals negations ignored funct set
ground functions extracted equality assignments say
every literal would needed make complete description state
included x retrieved associated truth value equality assignment

general set rules action require contexts
mutually exclusive given state action pair covered one rule
covered none assume nothing changes example consider
small set rules picking blocks
pickup x inhand nil x block height
inhand x x clear
pickup x inhand nil x table
inhand x x
top line rule shows action followed context next line describes
effects outcome according two rules executing pickup x changes
world hand empty x exact set changes depends
whether table block height nine less
probabilistic rules
deterministic dynamics rules described allow generalization objects
exploitation frame assumption well suited use highly
stochastic domains order apply domains extend
describe probability distribution resulting states pr probabilistic strips
operators blum langford model agents actions affect world around
describing actions alter properties relationships objects
world rule specifies small number simple action outcomessets changes
occur tandem
without restriction would need define method choosing possibly conflicting predictions different covering rules simplest way would involve picking one
rules perhaps specific one one confident rule confidence scores
would estimated



filearning symbolic stochastic world dynamics

see probabilistic rules form


p

x
x x z x

p

n n x



p pn positive numbers summing representing probability distribution n formulas describing subsequent state
given state action compute coverage deterministic
case however given covering substitution x probabilistic rules longer predict
unique successor state instead n used construct state
single deterministic case n possible subsequent
states occur associated probability pi
probability rule r assigns moving state state action
taken pr r calculated

p r

x

p r

r



x

p r p r



r

p r pi outcome distribution p r deterministic
distribution assigns mass relevant p r
state would constructed given rule outcome say
outcome covers
general possible representation subsequent state covered
one rules outcomes case probability occurring
sum probabilities relevant outcomes consider rule painting blocks

paint x inhand x block x




painted x wet
change

rule used model transition caused action paint initial
state contains wet painted one possible successor state one
change occurs wet painted remain true outcomes describe
one successor state must sum probabilities recover states total
probability
set rules specifies complete conditional probability distribution pr
following way current state action covered exactly one rule
distribution subsequent states prescribed rule predicted
probability


fipasula zettlemoyer pack kaelbling

example probabilistic set rules picking blocks might look follows
pickup x inhand nil x block height




inhand x x clear
change

pickup x inhand nil x table




inhand x x
change

top line rule still shows action followed context bracket surrounds
outcomes distribution outcomes
small chance occur
deictic reference
standard relational representations action dynamics variable denoting object
whose properties may changed action must named argument
list action awkwardness even deterministic situations example abstract action picking block must take two arguments pickup x
x block picked block picked
relationship encoded added condition x rules context condition restrict applicability rule exists guarantee bound
appropriate object restriction adopted means given
grounding action variables rule bound necessary
search substitutions would allow rule cover state however complicate many cases ground instances operator considered
even though eventually rejected due violations preconditions
example would reject instances violating x relation context
complex domains requirement even awkward depending
circumstances taking action may affect different varied sets objects blocks worlds
block may several others pickup action may affect properties
blocks model without additional mechanism referring objects
might increase even vary number arguments pickup takes
handle gracefully extend rule formalism include deictic references
objects rule may augmented list deictic references deictic
reference consists variable vi restriction set literals define
vi respect variables x action vj j
restrictions supposed pick single unique object notif pick
several nonethe rule fails apply handle pickup action described
action would single argument pickup x rule would contain deictic
variable v constraint x v
use rules deictic references must extend procedure computing rule
coverage ensure deictic references resolved deictic variables
may bound simply starting bindings x working sequentially
deictic variables restrictions determine unique bindings point


filearning symbolic stochastic world dynamics

binding deictic variable unique fails refer rule fails cover
stateaction pair
formulation means extra variables need included action specification reduces number operator instances yet requirement
unique designation substitution still quickly discovered testing coverage
example denote red block table v assuming
one table one block would use following deictic references
v table v
v color v red block v v v
several tables world rule semantics first
reference would fail similarly second reference would fail number red blocks
unique table represented v one
give action oriented example denoting block top block
touched touch z action would use following deictic reference
v v z block v
set deictic probabilistic rules picking blocks might look follows
pickup x

n

inhand z table z



empty context




inhand nil inhand z
change

pickup x

n

block x



inhand nil height




inhand x x clear
change

pickup x

n

table x



inhand nil

inhand x x

change
top line rule shows action followed deictic variables
variable annotated restriction next line context outcomes
distribution follow first rule applies situations something
gripper states probability action cause gripped
object fall table nothing change otherwise second rule applies
situations object picked another block states
probability success third rule applies situations object
picked table describes slightly higher success probability note
different objects affected depending state world


fipasula zettlemoyer pack kaelbling

adding noise
probability type seen thus far ones small set possible
outcomes sufficiently flexible handle noise real world may
large number possible outcomes highly unlikely reasonably hard model
example configurations may tall stack blocks topples
would inappropriate model outcomes impossible dont space
inclination model individual outcome
allow rule representation account noise definition noise able represent outcomes whose probability havent quantified
thus allowing noise lose precision true probability distribution
next states
handle noise must change rules two ways first rule
additional noise outcome noise associated probability p noise r
set outcome probabilities must sum include p noise r well
p r p n r however noise associated list literals
since declining model detail happens world cases
second create additional default rule empty context two outcomes empty outcome combination frame assumption
situations nothing changes noise outcome modeling situations rule allows noise occur situations specific rule applies
probability assigned noise outcome default rule specifies kind background
noise level
since explicitly modeling effects noise longer calculate
transition probability pr r equation lack required distribution
p r noise outcome instead substitute worst case constant bound
pmin p noise r allows us bound transition probability
p r pmin p noise r

x

p r p r

r

p r



intuitively pmin assigns small amount probability mass every possible next state
note take value higher true minimum approximation
however ensure probability model remains well defined pmin times number
possible states exceed
way create partial model allows us ignore unlikely overly complex
state transitions still learning acting effectively
since rules include noise deictic references call noisy deictic rules
ndrs rather stochastic world set ndrs picking blocks might


p noise r could modeled well defined probability distribution describing noise
world would give us full distribution next states premise
might difficult specify distributionin domain would ensure
distribution assign probability worlds impossible worlds blocks
floating midair long events unlikely enough would want consider
reasonable model directly



filearning symbolic stochastic world dynamics

look follows
pickup x

n

inhand z table z



empty context


inhand nil inhand z
change


noise
pickup x

n

block x



inhand nil height




inhand x x clear

change


noise
n

pickup x

table x



inhand nil


inhand x x
change


noise
default rule
change

noise
format rules section except rule
includes explicit noise outcome first three rules similar old versions
difference model noise final rule default rule states
rule applies probability observing change
together rules provide complete example type rule set learn
section however written fixed modeling language functions
predicates next section describes concepts used extend language
concept definitions
addition observed primitive predicates often useful background
knowledge defines additional predicates whose truth values computed
observations found essential modeling certain
domains edelkamp hoffman
background knowledge consists definitions additional concept predicates
functions work express concept definitions concept language
includes conjunction existential quantification universal quantification transitive closure counting quantification used defining concepts inhand x
block x x transitive closure included language via kleene star
operator defines concepts x x finally counting included special quantifier returns number objects formula
true useful defining integer valued functions height x x


fipasula zettlemoyer pack kaelbling

defined concepts enable us simplify context deictic variable definitions well restrict ways cannot described simple conjunctions
note however need track concept values outcomes since
computed primitives therefore rule contexts use language
enriched concepts outcomes contain primitives
example deictic noisy rule attempting pick block x side
side background knowledge necessary primitive predicates
table

pickup x




topstack x


z z

table




inhand nil height


z


z


change



noise

clear x

x

inhand x block x x
inhand nil inhand
x

x



topstack x clear x x
height x x

rule complicated example rules given thus far deals
situation block picked x middle stack deictic variable
identifies unique block top stack deictic variable zthe object
deictic variable tthe table might expected gripper succeeds
lifting high probability
concept definitions include clear x defined exists object
x inhand x defined x block object inhand nil defined
exists object hand x defined transitive
closure x topstack x defined x clear height x
defined number objects x chain ons explained
concepts used context deictic variable definitions
outcomes track primitive predicates fact appears outcomes since
value table predicates never changes
action
combine set concept definitions set rules define action model
best action represent rule set ndrs comparison purposes
experiments involve rule sets use simpler representations without
noise deictic references moreover rule sets differ whether allowed
contain constants rules presented far contained none neither
context outcomes reasonable setup states contain skolem
constants constants inherent meaning names assigned
general repeated however states intrinsic constants perfectly
acceptable include constants action constants used
uniquely identify objects world
develop learning next section assume general
constants allowed action model simple restrictions within


filearning symbolic stochastic world dynamics

ensure learned contain
section learning action restricted free constants provides
useful bias improve generalization training small data sets

learning action
defined rule action describe may constructed
learning attempts return action model best explains set
example actions formally takes training set e
example triple searches action model maximizes
likelihood action effects seen e subject penalty complexity
finding involves two distinct defining set concept predicates
constructing rule set r language contains predicates together
directly observable primitive predicates section first discuss second
rule set learning assuming fixed set predicates provided learner
present simple discovers useful concept predicates
learning rule sets
learning rule sets general np hard zettlemoyer pasula kaelbling
address greedy search structure search
hierarchically identifying two self contained subproblems outcome learning
subproblem general rule set search parameter estimation subproblem
outcome learning thus overall involves three levels greedy search
outermost level learnrules searches space rule sets often
constructing rules altering existing ones middle level induceoutcomes
given incomplete rule consisting context action set deictic references fills
rest rule innermost level learnparameters takes slightly
complete rule lacking distribution outcomes finds distribution
optimizes likelihood examples covered rule present three
levels starting inside subroutine described one
depends since three subroutines attempt maximize scoring metric
begin introducing metric
scoring metric
greedy search must judge parts search space desirable
done help scoring metric rule sets
r

x

log p r

e

x

p en r



rr

r rule governing transition occurring performed
scaling parameter p en r complexity penalty applied rule r thus r
favors rule sets maximize likelihood bound data penalizes rule sets
overly complex
ideally p would likelihood example however rules noise outcomes
cannot assign exact likelihood case use lower bound defined equa

fipasula zettlemoyer pack kaelbling

tion instead p en r defined simply total number literals r chose
penalty simplicity performed worse penalty
term tested informal experiments scaling parameter set experiments could set cross validation hold dataset
principled technique metric puts pressure model explain examples
non noise outcomes increases p opposing pressure complexity via
p en r
assume state action pair covered one rule
finite set examples enforced simply ensuring examples stateaction pair covered one rule rewrite metric terms rules rather
examples give
r

x

x

rr

er

log p r p en r



er set examples covered r thus rules contribution r
calculated independently others
learning parameters
first described section learnparameters takes incomplete
rule r consisting action set deictic references context set outcomes
learns distribution p maximizes rs score examples er covered
since procedure allowed alter number literals rule therefore
cannot affect complexity penalty term optimal distribution simply one
maximizes log likelihood er case rules noise outcomes
log p r

x

l

er







log pmin p noise r

x

x

p r p r



r

er

non noise outcome p r one covers zero otherwise
case rules without noise outcomes sum slightly simpler
pmin p noise r term missing
every example covered unique outcome ls maximum expressed
closed form let set examples covered outcome e add
lagrange multiplier enforce constraint p r distributions must sum
get


l

x
er



x
e

log


x

p r p r

x

r



e log p r


x

p r





p r

filearning symbolic stochastic world dynamics

partial derivative l respect p r e p r
e p r e e thus parameters estimated
calculating percentage examples outcome covers
however seen section possible example covered
one outcome indeed noise outcome covers examples
case situation sum examples cannot rewritten
simple sum terms representing different outcomes containing single
relevant probability probabilities overlapping outcomes remain tied together
general closed form solution exists estimating maximum likelihood parameters
nonlinear programming fortunately instance well studied
maximizing concave function log likelihood presented equation probability simplex several gradient ascent known bertsekas
since function concave guaranteed converge global maximum
learnparameters uses conditional gradient method works iteration
moving along parameter axis maximal partial derivative step sizes
chosen armijo rule parameters
search converges improvement l small less chose
easy implement converged quickly experiments
tried however found method converges slowly one
many nonlinear optimization methods constrained newtons method
could directly applied
inducing outcomes
given learnparameters learning distribution outcomes
consider taking incomplete rule r consisting context action
perhaps set deictic references finding optimal way fill rest
rulethat set outcomes n associated distribution p
maximize score
r

x

log p r p eno r

er

er set examples covered r p eno r total number literals
outcomes r r factor scoring metric equation due
rule r without aspects p en r fixed purposes subroutine
number literals context
general outcome induction np hard zettlemoyer pasula kaelbling induceoutcomes uses greedy search restricted subset possible outcome sets
proper training examples outcome set proper every outcome
covers least one training example two operators described move
space immediate moves improve rule score set
outcomes considers induceoutcomes calls learnparameters supply best p
initial set outcomes created example writing set
atoms changed truth values action creating outcome
describe every set changes observed way


fipasula zettlemoyer pack kaelbling

e
e
e
e






c h c h c h c
h c c h c h c
h c h c c c
h c h c h c h c


h c
h c
c c
change
b

figure possible training data learning set outcomes b initial set
outcomes would created data picking smallest
outcome describes change

example consider coins domain coins world contains n coins
showing heads tails action flip coupled takes arguments
flips coins half time heads otherwise tails set training
data learning outcomes two coins might look part figure h c
stands heads c c stands heads c part example
flip coupled suppose suggested rule flip coupled
context deictic references given data initial set outcomes four
entries part b figure
rule contained variables abstract action arguments deictic
references induceoutcomes would introduce variables appropriate places
outcome set variable introduction achieved applying inverse action
substitution examples set changes computing initial set outcomes
given deictic reference c red c found refer c red
coin example set outcomes would contain c wherever currently contains c
finally disallow use constants rules variables become way
outcomes refer objects whose properties changed changes containing
constant referred variable cannot expressed corresponding
example covered noise outcome
outcome search operators

induceoutcomes uses two search operators first add operator picks
pair non contradictory outcomes set creates outcome
conjunction example might pick combine adding
outcome h c h c set second remove operator drops
outcome set outcomes dropped overlapping
outcomes every example cover otherwise outcome set would remain proper
course outcome set contains noise outcome every outcome
dropped since examples covered noise outcome whenever operator
adds removes outcome learnparameters called optimal distribution
thus induceoutcomes introduces variables aggressively wherever possible intuition
corresponding objects would better described constant become apparent
training example



filearning symbolic stochastic world dynamics

outcome set used calculate maximum log likelihood
data respect outcome set
sometimes learnparameters return zero probabilities outcomes
outcomes removed outcome set since contribute nothing
likelihood add complexity optimization improves efficiency
search
outcomes figure dropped since covers e
covered outcome created conjoining
existing ones h c h c covers e e e thus added
dropped adding dropping creates outcome
set optimal set outcomes training examples figure
notice outcome equal union sets literals change
training examples covers fact ensures every proper outcome made
merging outcomes initial outcome set induceoutcomes theory
set outcomes
learning rules
know fill incomplete rules describe learnrules outermost
level learning takes set examples e fixed language
primitive derived predicates performs greedy search space rule
sets precisely searches space proper rule sets rule set r
defined proper respect data set e includes one rule
applicable every example e e change occurs include
rules applicable examples
search proceeds described pseudocode figure starts rule set
contains default rule every step takes current rule set applies
search operators obtain set rule sets selects rule set r
maximizes scoring metric r defined equation ties r broken
randomly
begin explaining search initialized go describe
operators used finish working simple example shows learnrules
action
rule set search initialization

learnrules initialized proper rule set initialize
set noisy default rule treats action effects training set
noise search progresses search operators introduce rules explain action
effects explicitly chose initial starting point simplicity worked
well informal experiments another strategy would start specific rule
set describing detail examples bottom methods advantage
data driven help search reach good parts search space
easily however several search operators used
presented guided training examples already
desirable property moreover bottom method bad complexity properties


fipasula zettlemoyer pack kaelbling

learnruleset e
inputs
training examples e
computation
initialize rule set r contain default rule
better rules sets found
search operator
create rule sets ro r e
rule set r ro
score improves r r
update best rule set r r
output
final rule set r

figure learnruleset pseudocode performs greedy search space
rule sets step set search operators propose set rule sets
highest scoring rule set selected used next iteration

situations large data set described relatively simple set rules
case interested
rule set search operators

rule set search learnrules repeatedly finds applies operator
increase score current rule set
search operators work creating rule set rules usually
altering existing rule integrating rules rule set way
ensures rule set remains proper rule creation involves picking action z
set deictic references context calling induceoutcomes
learning complete rule filling pi rule covers
examples attempt abandoned since adding rule cannot help scoring
metric integration rule set involves adding rules removing
old rules cover examples increase number examples
covered default rule
search operators
search operator takes input rule set r set training examples e
creates set rule sets ro evaluated greedy search loop eleven
search operators first describe complex operator explainexamples followed
simple one droprules present remaining nine operators
share common computational framework outlined figure
together operators provide many different ways moving space
possible rule sets adapted learn different types rule sets
example without constants restricting set search operators used


filearning symbolic stochastic world dynamics

operatortemplate r e
inputs
rule set r
training examples e
computation
repeatedly select rule r r
create copy input rule set r r
create set rules n making changes r
rule r n covers examples
estimate outcomes r induceoutcomes
add r r remove rules r cover
examples r covers
recompute set examples default rule r
covers parameters default rule
add r return rule sets ro
output
set rules sets ro

figure operatortemplate pseudocode basic framework used
six different search operators operator repeatedly selects rule uses make n
rules integrates rules original rule set create rule set

explainexamples takes input training set e rule set r creates
alternative rule sets contain additional rules modeling training examples
covered default rule r figure shows pseudocode
considers training example e covered default
rule r executes three step procedure first step builds large
specific rule r describes example second step attempts trim rule
generalize maximize score still ensuring covers e
third step creates rule set r copying r integrating
rule r rule set
illustration let us consider steps explainexamples might
applied training example b pickup b
background knowledge defined rule section constants
allowed
step builds rule r creates variable x represent object b
action action substitution becomes x b action r
set pickup x context r set conjunction inhand nil inhand x
clear x height x x x x x topstack x x step
explainexamples attempts create deictic references name constants
whose properties changed example already action substitution case changed literal b b substitution
c deictic variable created restricted extended


fipasula zettlemoyer pack kaelbling

explainexamples r e
inputs
rule set r
training set e
computation
example e covered default rule r
step create rule r
step create action context r
create variables represent arguments
use create action substitution
set rs action
set rs context conjunction boolean equality literals
formed variables available functions predicates
primitive derived entailed
step create deictic references r
collect set constants c whose properties changed

c c
create variable v extend map v c
create conjunction literals containing v formed
available variables functions predicates entailed
create deictic reference variable v restriction
uniquely refers c add r
step complete rule
call induceoutcomes create rules outcomes
step trim literals r
create rule set r containing r default rule
greedily trim literals r ensuring r still covers filling
outcomes induceoutcomes r score stops improving
step create rule set containing r
create rule set r r
add r r remove rules r cover examples r covers
recompute set examples default rule r covers parameters
default rule
add r return rule sets ro
output
set rule sets ro

figure explainexamples pseudocode attempts augment rule set
rules covering examples currently handled default rule



filearning symbolic stochastic world dynamics

x b finally step outcome set created assuming
examples context applies nine ten end x lifted
rest falling onto table resulting rule r looks follows


inhand clear x table

pickup x x topstack x


topstack height
inhand nil inhand x clear x table x height x x x
x
x topstack x x

x

noise

falls table outcome modeled noise since absence constants
rule way referring table
step explainexamples trims rule remove literals true
training examples x x table redundant ones
inhand clear perhaps one heights give


pickup x x
inhand nil
clear x height x

x

noise

rules context describes starting example concisely explain examples
consider dropping remaining literals thereby generalizing rule
applies examples different starting states however generalizations
necessarily improve score smaller contexts might end
creating outcomes describe examples penalty term
guaranteed improve change likelihood term depend whether
examples higher likelihood rule default rule
whether old examples higher likelihood old distribution
one quite frequently need cover examples
give rule distribution closer random usually
lead decrease likelihood large overcome improvement
penalty given likelihood penalty trade
let us assume case predicate dropped without worsening
likelihood rule integrated rule set
droprules cycles rules current rule set removes one
turn set returns set rule sets one missing different rule
remaining operators create rule sets input rule set r repeatedly
choosing rule r r making changes create one rules
rules integrated r explainexamples create rule set r
figure shows general pseudocode done operators vary
way select rules changes make variations described


fipasula zettlemoyer pack kaelbling

operator note operators deal deictic
references constants applicable action model representation allows
features
droplits selects every rule r r n times n number literals
context r words selects r literal context
creates rule r removing literal rs context n figure
simply set containing r
example pickup rule created explainexamples would selected three times
inhand nil clear x one height x would create
three rules different literal missing three singleton n sets
three candidate rule sets r since newly created r generalizations r
certain cover rs examples r removed
r
changes suggested droplits therefore exactly suggested trimming search explainexamples one crucial difference
droplits attempts integrate rule full rule set instead making quick comparison default rule step explainexamples
explainexamples used trimming search relatively cheap local
heuristic allowing decide rule size droplits uses search globally
space rule sets comparing contributions conflicting rules
droprefs operator used deictic references permitted selects
rule r r deictic reference r creates rule r
removing deictic reference r n set containing r
applying operator pickup rule would selected reference
describing one rule set would returned one containing rule
without
generalizeequality selects rule r r twice equality literal context
create two rules one equality replaced one
replaced rule integrated rule set r
resulting two r returned generalized rules certain cover
rs examples r contain r
context pickup rule contains one equality literal height x generalizeequality attempt replace literal height x height x
domain containing two blocks would likely yield interesting
generalizations
changeranges selects rule r r n times equality inequality literal
context n total number values range literal
time selects r creates rule r replacing numeric value chosen
equality another possible value range note quite possible
rules cover examples abandoned
remaining rules integrated copies rule set usual


filearning symbolic stochastic world dynamics

thus f ranges n changerange would applied rule containing inequality f construct rule sets replaced
integers n
pickup rule contains one equality literal height x two block domain
example drawn height take values
rule selected thrice rules created containing
equalities since rule constrains x something rule containing
height x never cover examples certainly abandoned
splitonlits selects rule r r n times n number literals
absent rules context deictic references set absent literals
obtained applying available functions predicatesboth primitive
derivedto terms present rule removing literals already present
rule resulting set constructs set rules case
predicate inequality literals creates one rule positive version
literal inserted context one negative version
case equality literals constructs rule every possible value equality could
take case rules cover examples dropped remaining
rules corresponding one literal placed n integrated
rule set simultaneously
note newly created rules cover examples
start covered original rule others examples
split
list literals may added pickup rule consists inhand x
inhand table x table clear x x x height
possible applications topstack literals make
interesting examples adding context create rules
cover examples abandoned cover set
examples original rule rejected likelihood
worse penalty however illustrate process attempting add
height predicate creation three rules height n
context one n rules would added rule set

addlits selects rule r r n times n number predicate
literals absent rules context deictic references reflects fact literal may considered positive negative form
constructs rule literal inserting literal earliest place
rule variables well defined literal contains deictic
variables context otherwise restriction last
deictic variable mentioned literal v v deictic variables v
appears first v v would inserted restriction v resulting
rule integrated rule set
list literals may added pickup rule much splitonlits
without height process lead anything interesting


fipasula zettlemoyer pack kaelbling

example reason illustration inhand would
chosen twice inhand added context case since
context already contains inhand nil adding inhand redundant adding
inhand produce contradiction neither rule seriously considered
addrefs operator used deictic references permitted selects
rule r r n times n number literals constructed
available predicates variables r variable v case
creates deictic reference v current literal define restriction
adds deictic reference antecendent r construct rule
integrated rule set
supposing v variable list literals would constructed
pickup rule consists inhand v clear v v x x v table v v
v v v possible applications topstack
mirror used create deictic references v table v
useful reference allows rule describe falls table outcomes
explicitly operator likely accepted point search
raiseconstants operator used constants permitted selects
rule r r n times n number constants among arguments rs
action constant c constructs rule creating variable
replacing every occurrence c integrates rule rule
set
splitvariables operator used constants permitted selects
rule r r n times n number variables among arguments rs
action variable v goes examples covered rule r
collects constants v binds creates rule constants
replacing every occurrence v constant rules corresponding one
variable v combined set n integrated old rule set together
found operators consistently used learning
set operators heuristic complete sense every rule set
constructed initial rule setalthough course guarantee
scoring metric lead greedy search global maximum
learnruless search strategy one large drawback set learned rules
guaranteed proper training set testing data test examples
could covered one rule happens employ alternative
rule selection semantics return default rule model situation way
essentially saying dont know happen however
significant problematic test examples added future training
set used learn better given sufficiently large training set failures
rare



filearning symbolic stochastic world dynamics

e

b

b
b

puton b

b
b

puton b

b
b

b

e

r

r

puton x



inhand
table
empty
context


x


noise

r

puton x

n

inhand
clear x
n
x

b

b

e

b

puton x



inhand
z z x
empty
context
z

noise

b

b
puton b

b b

b
b b

figure three training examples three blocks world example paired initial
rule explainexamples might create model example agent trying
put block b onto block b

example rule set learning

example consider learnruleset might learn set rules model three
training examples figure given settings complexity penalty noise bound
later used experiments pmin pmin low
three block domain since different states use consistency
initialization rule set contains default rule changes occur
examples modeled noise since examples include change default rule
noise probability describe path greedy search takes
first round search explainexamples operator suggests adding
rules describe examples general explainexamples tries construct rules
compact cover many examples assign relatively high probability
covered example latter means noise outcomes avoided whenever
possible one reasonable set rules suggested shown right hand side
figure notice r deterministic high probability relatively compact
e unique initial state explainexamples take advantage meanwhile


fipasula zettlemoyer pack kaelbling

e e starting state rules explaining must cover
others examples thus noise outcomes unavoidable rules since lack
necessary deictic references deictic variables created describe objects
whose state changes example explained
consider adding one rules guarantee
constitute improvement since high complexity penalty would make rule
look bad high pmin would make default rule look good determine
best move compares scores rule sets containing
proposed rules score initial rule set containing default rule let us
calculate scores example starting rule set consisting rule r
covers e e default rule rd covers remaining example
therefore noise probability use equation let rules
complexity number literals body case r three get
r rd

x

log p r

e

x

p en r

rr

log pmin log pmin log pmin p en r p en rd
log log log


rule set containing r score similar calculations
rule sets containing r r scores respectively since
initial rule set score rule sets improvements one
containing r best picked greedy search rule set


puton x inhand table
empty context


x


noise
default
rule
change

noise

notice training examples covered non default rule situation
default rule cover examples probability assigned noise
outcome
next step search decide altering existing rule introducing another rule describe example currently covered default rule since
default rule covers examples altering single rule rule set option
operators likely score highly get rid noise outcome
rule means referring block x e
appropriate operator therefore addrefs introduce deictic reference describing block course increases size rule complexity


filearning symbolic stochastic world dynamics

addition means rule longer applies e leaving example
handled default rule however rule set raises probabilities
examples enough compensate increase complexity ends
score clear improvement highest score
obtainable step alters rule set get
puton x



inhand table z z x



empty context

z


default
rule
change

noise

default rule covers e explainexamples something work
adding r get rid noise yield much improved score
biggest improvement made rule set becomes
puton x



inhand table z z x



empty context

z




puton x inhand
clear x

x
default
rule
change

noise

note rule could added earlier e covered
first rule added r specialized thus adding r rule set containing r
would knocked r caused examples e e explained noise
default rule would reduced overall score however possible rule
knock another yet improve score requires complicated set
examples
learning continues search attempts apply rule altering operators
current rules make bigger without changing likelihood lead
creation noise outcomes dropping rule add noise probability
default rule lower score since extra examples explained
operator improve score search stops rule set seems
reasonable rule set domain one rule covers happens try puton
clear block one describes try puton block another block
ideally would first rule generalize blocks something
instead notice would need examples containing higher stacks


fipasula zettlemoyer pack kaelbling

different versions
making small variations learnruleset learn different types
rule sets important evaluating
explore effects constants rules evaluate three different versions
rule learning propositional relational deictic propositional rule learning explainexamples creates initial trimmed rules constants never introduces variables
none search operators introduce variables used thus learned rules
guaranteed propositionalthey cannot generalize across identities specific
objects relational rule learning variables allowed rule action arguments
search operators allowed introduce deictic references explainexamples creates
rules constants name objects long constants already
variable action argument list mapped finally deictic rule learning
constants allowed see deictic learning provides strong bias
improve generalization
demonstrate addition noise deictic references better
rules learn action enhancements
done changing minor ways disallow noise set rule noise
probability zero means must constrain outcome sets contain
outcome every example change observed rules cannot express
changes abandoned disallow deictic references disable operators
introduce explainexamples create empty deictic reference set
learning concepts
contexts deictic references ndrs make use concept predicates functions well primitive ones concepts specified hand learned
rather simple learnconcepts uses learnruleset subprocedure
testing concept usefulness works constructing increasingly complex concepts running learnruleset checking concepts appear learned
rules first set created applying operators figure literals built
original language subsequent sets concepts constructed literals
proved useful latest run concepts tried
true false across examples discarded search ends none
concepts prove useful
example consider predicate topstack simple blocks world could
discovered follows first round learning literal x x used define
predicate n true stacked
assuming predicate appears learned rules used second
round learning define among others z z n z z clear z ensuring
z clear predicate true z highest block stack
containing z notion topstack used determining happen
gripper tries pick z descends likely grasp
block top stack instead
since concept language quite rich overfitting e g learning concepts
used identify individual examples serious handle


filearning symbolic stochastic world dynamics

p x n qy p
p x x n qy p
p x x n qy p
p x x n p
p x x n p
p x p x n p p
p x p x x n p p
p x p x x n p p
p x x p x x n p p
p x x p x x n p p
p x x p x x n p p
p x x p x x n p p
f x c n f c
f x c n f c
f x c n f c
figure operators used invent predicate n operator takes input one
literals listed left ps represent old predicates f represents old function
q refer c numerical constant operator takes literal
returns concept definition operators applied literals used
rules rule set create predicates

expected way introducing penalty term c r create scoring metric
r r c r
c r number distinct concepts used rule set r scaling
parameter metric used learnruleset avoids overfitting favoring
rule sets use fewer derived predicates note fact cannot factored
rule matter since factoring used induceoutcomes
learnparameters neither change number concepts used relevant
rule outcomes contain primitive predicates
discussion
rule set learning challenge addressed section complicated need learn
structure rules numeric parameters associated outcome distributions
definitions derived predicates modeling language learnconcepts


fipasula zettlemoyer pack kaelbling

conceptually simple performs simultaneous learning effectively
see experiments section
large number possible search operators might cause concern overall
computational complexity learnruleset although expensive set search operators designed control complexity attempting
keep number rules current set small possible
step search number rule sets considered depends
current set rules explainexamples operator creates rule sets
number examples covered default rule since search starts rule set
containing default rule initially equal number training examples
however explainexamples designed introduce rules cover many examples
practice grows small quickly operators create rm rule sets
r number rules current set depends specific operator
example could number literals dropped context
rule droplits operator although large r stays small practice
search starts default rule complexity penalty favors small rule
sets
ensure score increases search step guaranteed converge usually local optimum however guarantee
quickly get practice found converged quickly
test domains learnruleset never took steps
learnconcepts outer loop never cycled times entire never took
six hours run single processor although significant effort made
cache intermediate computations final implementation
spite realize scale complex domains
eventually become prohibitively expensive plan handle developing learn concepts rules rule parameters online manner
directed search operators however leave complex
future work


experiments section involve learning complex actions
true dynamics level relational rules available evaluation
instead learned evaluated executing actions
many possible ways plan work explore mdp
mdp puterman tuple r set possible states
set possible actions distribution encodes transition dynamics
world finally r reward signal maps every state real value
policy plan possibly stochastic mapping states actions expected
amount reward achieved executing starting called value
p

defined v e
r si si states reached
time discount factor favors immediate rewards goal
mdp policy achieve reward time


filearning symbolic stochastic world dynamics

optimal policy found solving set bellman equations
v r

x

v





application action set state set defined world
modeling rule set r defines transition model reward function r defined
hand
large domains difficult solve bellman
equations exactly approximation implemented simple planner
sparse sampling kearns mansour ng given state creates tree
states predefined depth branching factor sampling forward transition
model computes value node bellman equation selects action
highest value
adapt handle noisy outcomes predict next state
estimating value unknown next state fraction value staying
state e sample forward stayed state scale
value obtain scaling factor depth branching factor
four
scaling method guess value unknown next state might
noisy rules partial way compute value explicitly
future would explore methods learn associate values noise
outcomes example value outcome tower blocks falls
different goal build tall stack blocks goal put
blocks table
solve hard combinatorial allow
us choose actions maximize relatively simple reward functions see
next section enough distinguish good poor ones moreover
development first order techniques active field aips

evaluation
section demonstrate rule learning robust variety lownoise domains works intrinsically noisy simulated blocks world
domain begin describing test domains report series experiments
domains
experiments performed involve learning rules domains briefly
described following sections
slippery gripper
slippery gripper domain inspired work draper et al abstract
symbolic blocks world simulated robotic arm used move blocks
around table nozzle used paint blocks painting block
might cause gripper become wet makes likely fail
manipulate blocks successfully fortunately wet gripper dried


fipasula zettlemoyer pack kaelbling

pickup x x clear x
inhand nil block x block wet



pickup x x clear x
inhand nil block x block wet




inhand x clear x inhand nil


x clear


x table x
change

inhand x clear x inhand nil


x clear


x table x
change

pickup x x clear x
inhand nil block x table wet
pickup x x clear x
inhand nil block x table wet







inhand x clear x inhand nil
x
change



inhand x clear x inhand nil
x
change




inhand nil clear inhand x





x clear x

puton x clear inhand x
x table clear x inhand nil

block

inhand x


change


puton x table inhand x



painted x
painted x wet
change



wet
change

paint x block x

dry context

x table clear x inhand nil
inhand x
change


figure eight relational rules model slippery gripper domain

figure shows set rules model domain individual states represent
world objects intrinsic constants experimental data generated sampling
rules section explore learning section compare
number training examples scaled single complex world
trucks drivers
trucks drivers logistics domain adapted aips international
competition aips four types constants trucks drivers locations
objects trucks drivers objects locations locations
connected paths links drivers board trucks exit trucks drive trucks
locations linked drivers walk without truck locations
connected paths finally objects loaded unloaded trucks
set rules shown figure actions simple rules succeed
fail change world however walk action interesting twist drivers
try walk one location another succeed time


filearning symbolic stochastic world dynamics

load l

l l



l
change

unload l

l



l
change

board l

l l empty



l driving empty
change

disembark l

l driving



driving l empty
change

drive f l l

driving f l link f l l



l f l
change


l f l

walk f l l

f l path f l l
pick x path f l x
x f l

figure six rules encode world dynamics trucks drivers domain
time arrive randomly chosen location connected path
origin location
representation presented cannot encode action efficiently best rule
set rule origin location outcomes every location origin
linked extending representation allow actions walk represented
single rule interesting area future work
slippery gripper domain individual states represent world objects intrinsic
constants experimental data generated sampling rules trucks
drivers dynamics difficult learn see section learned
enough training data
simulated blocks world
validate rule extensions section presents experiments rigid
body simulated physics blocks world section describes logical interface
simulated world description extra complexities inherent learning dynamics
world presented section
define interface symbolic representation use describe
action dynamics physical domain simulated blocks world perceptual
system produces states contain skolem constants logical language includes
binary predicate x defined x exerts downward force obtained
querying internal state simulator unary typing predicates table block
actuation system translates actions sequences motor commands simulator
actions execute regardless state world define two actions
parameters allow agent specify objects intends manipulate
pickup x action centers gripper x lowers hits something grasps
raises gripper analogously puton x action centers gripper x lowers
encounters pressure opens raises


fipasula zettlemoyer pack kaelbling

simulator sidestepping difficult pixels predicates
occurs whenever agent map domain observations internal representation
primitive predicates defined terms internal state simulation simpler
cleaner observations real world would make domain completely
observable prerequisite learning choosing set
predicates observe important make rule learning easy
hard difficulty making choice magnified richer settings limited
language described balances extremes providing would difficult
derive means providing predicates inhand clear
learned
experiments
section describes two sets experiments first compare learning deictic
relational propositional rules slippery gripper trucks drivers data
domains modeled rules contain intrinsic constants noisy
thus allow us explore effect deictic references constants rules directly
describe set experiments learns rules model data simulated
blocks world data inherently noisy contains skolem constants
focus evaluating full performing ablation studies demonstrate
deictic references noise outcomes concepts required effective learning
experiments use examples e generated randomly constructing
state randomly picking arguments action executing action
state generate distribution used construct biased guarantee
approximately half examples chance change state method
data generation designed ensure learning data
representative entire model learn thus experiments
ignore agent would face generate data exploring world
learning rule sets noise
know model used generate data evaluate model respect
set similarly generated test examples e calculating average variational distance
true model p estimate p
v p p

x
p e p e
e ee

variational distance suitable measure clearly favors similar distributions
yet well defined zero probability event observed happen
non noisy rule learned sparse data many outcomes

comparisons performed four actions first two paint pickup
slippery gripper domain second two drive walk
trucks drivers domain action presents different challenges learning paint
simple action one outcome lead successor state
described section pickup complex action must represented


filearning symbolic stochastic world dynamics

paint action



pickup action


propositional
relational
deictic

variational distance

variational distance


















training set size


training set size

walk action



drive action


propositional
relational
deictic

variational distance

variational distance



propositional
relational
deictic









propositional
relational
deictic






training set size


training set size

figure variational distance function number training examples propositional relational deictic rules averaged ten trials
experiment test set size examples

one rule drive simple action four arguments finally walk
complicated action uses path connectivity world noise model lost
pedestrians slippery gripper actions performed world four blocks
trucks driver actions performed world two trucks two drivers two
objects four locations
compare three versions deictic includes full rules language allow constants relational allows variables constants
deictic references propositional constants variables figure
shows relational learning consistently outperforms propositional learning
implies variable abstractions useful cases except walk action
deictic learner outperforms relational learner implies forcing
rules contain variables preventing overfitting learning better
walk action interesting deictic learner cannot actually
represent optimal rule requires noise model complex deictic learner
quickly learns best rule relational propositional learners eventually


fipasula zettlemoyer pack kaelbling

learning simulated blocksworld


learned concepts
hand engineered concepts
without noise outcomes
restricted language

total reward
















training set size







figure performance action model variants function number training
examples data points averaged five trials three
rule sets learned different training data sets comparison average reward
performing actions reward obtained human directed
gripper averaged

learn better rule sets use constants accurately model walkers
moving random locations
experiments see variable abstraction helps learn less data
deictic rules abstract aggressively perform best long
represent model learned next section consider deictic
rules since working domain simulated perception
access objects identities names skolem constants
learning blocks world simulator
final experiment demonstrates noise outcomes complicated concepts
necessary learn good action blocks world simulator
true model known evaluate learned model plan
estimating average reward gets reward function used simulated blocks
world average height blocks world breadth depth
search sampling planner four learning set pmin

tested four action model variants varying training set size
shown figure curve labeled learned concepts represents full
presented performance approaches obtained human expert
comparable labeled hand engineered concepts


filearning symbolic stochastic world dynamics

concept learning instead provided hand coded versions concepts
clear inhand inhand nil topstack height concept learner discovered
well useful predicates e g p x clear x
call onclear could action outperformed hand engineered ones
slightly small training sets domains less well studied blocks world might
less obvious useful concepts concept discovery technique presented
prove helpful
remaining two model variants obtained rewards comparable reward
nothing planner attempt act experiments
poor job one variant used full set predefined concepts rules
could noise outcomes requirement explain every action effect led
significant overfitting decrease performance rule set given
traditional blocks world language include topstack height
allowed learn rules noise outcomes tried full language variant noise
outcomes allowed deictic references resulting rule sets contained
noisy rules planner attempt act poor performance
ablated versions representation shows three extensions
essential modeling simulated blocks world domain
human agent commanding gripper solve received average
total reward theoretical maximum due unexpected action
outcomes thus nd rules performing near human levels suggesting
representation reasonable one suggests
approximations learning bounds limiting performance traditional rules
face challenge modeling transitions seen data much larger
hypothesis space consider learning surprising generalize poorly
consistently performed ndrs
informally report ndr execute significantly faster
traditional ones one standard desktop pc learning ndrs takes minutes learning
traditional rules take hours noisy deictic action generally
compact traditional ones contain fewer rules fewer outcomes
much faster well
get better feel types rules learned two interesting rules produced
full

pickup x

onclear x z z
table



inhand nil size x

z
x


x z

rule applies empty gripper asked pick small block x sits
top another block gripper grabs high probability



fipasula zettlemoyer pack kaelbling


puton x

topstack x z inhand z
table

size














z
z
z x
noise

rule applies gripper asked put contents z block x
inside stack topped small block placing things small block chancy
reasonable probability z fall table small probability
follow

discussion
developed probabilistic action model representation rich enough
used learn physically simulated blocks world
first step towards defining representations enable learning
complex worlds
related work
learning deterministic action well studied work
area shen simon gil wang focused incrementally
learning operators interacting simulated worlds however work
assumes learned completely deterministic
oates cohen earliest work learning probabilistic operators rules factored apply parallel however representation
strictly propositional allows rule contain single outcome
previous work developed learning probabilistic relational operators pasula zettlemoyer kaelbling unfortunately neither probabilistic
robust enough learn complex noisy environments simulated
blocks world
one previous system comes close goal trail learner benson
trail learns extended version horn clauses noisy environments applying inductive logic programming ilp learning techniques robust noise trail
introduced deictic references name objects functional relationships
arguments actions deictic references exists unique quantification
semantics generalization bensons original work moreover trail continuous actions real valued fluents allows represent complex
date including knowledge required pilot realistic flight simulator however rules trail learns limited probabilistic representation
represent possible transition distributions trail include mechanisms
learning predicates


filearning symbolic stochastic world dynamics

work action model learning used different versions greedy search
rule structure learning closely related inspired learning version
spaces mitchell later ilp work lavrac dzeroski
explore first time way moving space rule sets
noise rule initial rule set found works well
practice avoiding need hand selected initial rule set allowing
learn significantly complex environments
far know work learning action explored learning concepts
ilp literature recent work assche vens blockeel dzeroski shown
adding concept learning decision tree learning improves classification
performance
outside action learning exists much related learning probabilistic
relational logical structure complete discussion beyond scope
present highlights work learns representations
relational extension bayesian networks comprehensive example see work getoor
work extends ilp incorporating probabilistic dependencies
example see wide range techniques presented kersting additionally
recent work learning markov logic networks richardson domingos kok
domingos log linear features defined first order
logical formulae action action model learning
designed represent action effects special case general approaches listed
discussed section tailoring representation match
model learnt simplify learning
finally let us consider work related ndr action model representation
relevant ppddl representation language probabilistic operators
domains younes littman ndr representation partially
inspired ppddl operators includes restrictions make easier learn extensions noise outcomes required effectively model simulated blocks
world future could extended learn full ppddl
rules ppddl examples see papers recent
competitions could adapted improve simple presented section
general sense ndrs related probabilistic relational representations
designed model dependencies across time examples see work relational
dynamic bayesian networks sanghai domingos weld specialization prms logical hidden markov kersting raedt raiko
come ilp tradition approaches make different set modeling
assumptions closely tied representations ndr
extend
future ongoing work
remains much done context learning probabilistic rules
first likely work applied additional domains
realistic robotic applications dialogue systems representation need
adapted search operators adjusted accordingly possible changes mentioned


fipasula zettlemoyer pack kaelbling

article include allowing rules apply parallel different rules could apply
different aspects state extending outcomes include quantifiers actions
walk trucks drivers domain section could described
single rule significant change intend pursue expanding
handle partial observability possibly incorporating techniques work
deterministic learning amir hope make changes make
rules easier associating values noise outcomes help planner
decide whether avoided
second direction involves development learn probabilistic operators incremental online manner similar learning setup
deterministic case shen simon gil wang potential
scale larger domains make applicable even situations
difficult obtain set training examples contains reasonable sampling worlds
likely relevant agent line work require development
techniques effectively exploring world learning model much done
reinforcement learning longer term would online learn
operators concept predicates useful primitive predicates motor
actions

acknowledgments
material upon work supported part defense advanced
projects agency darpa department interior nbc acquisition
services division contract nbchd part darpa grant
hr

references
agre p chapman pengi implementation theory activity
proceedings sixth national conference artificial intelligence aaai
aips international competition http www dur ac uk p long competition html
aips international competition http www ldc usb bonet ipc
amir e learning partially observable deterministic action proceedings
nineteenth international joint conference artificial intelligence ijcai
assche v vens c blockeel h dzeroski random forest
relational learning proceedings icml workshop statistical relational
learning connections fields
benson learning action reactive autonomous agents ph thesis
stanford university
bertsekas p nonlinear programming athena scientific
blum langford j probabilistic graphplan framework
proceedings fifth european conference ecp


filearning symbolic stochastic world dynamics

boutilier c reiter r price b symbolic dynamic programming first order
mdps proceedings seventeenth international joint conference artificial
intelligence ijcai
boyen x koller tractable inference complex stochastic processes
proceedings fourteenth annual conference uncertainty ai uai
brooks r intelligence without representation artificial intelligence
draper hanks weld probabilistic information gathering
contingent execution proceedings second international conference
ai systems aips
edelkamp hoffman j pddl language classical part th
international competition technical report albert ludwigs universitat
freiburg germany
fikes r e nilsson n j strips application theorem
proving solving artificial intelligence
getoor l learning statistical relational data ph thesis stanford
gil efficient domain independent experimentation proceedings tenth
international conference machine learning icml
gil learning experimentation incremental refinement incomplete domains proceedings eleventh international conference machine
learning icml
guestrin c koller parr r venkataraman efficient solution
factored mdps journal artificial intelligence jair
kearns mansour ng sparse sampling near optimal
large markov decision processes machine learning ml
kersting k inductive logic programming statistical relational
learning ios press
kersting k raedt l raiko logical hidden markov journal
artificial intelligence jair
khan k muggleton parson r repeat learning predicate invention
international workshop inductive logic programming ilp
kok domingos p learning structure markov logic networks proceedings twenty second international conference machine learning icml
lavrac n dzeroski inductive logic programming techniques applications ellis horwood
mitchell generalization search artificial intelligence
oates cohen p r searching operators context dependent
probabilistic effects proceedings thirteenth national conference
artificial intelligence aaai
ode open dynamics engine toolkit http opende sourceforge net


fipasula zettlemoyer pack kaelbling

pasula h zettlemoyer l kaelbling l learning probabilistic relational rules proceedings fourteenth international conference automated
scheduling icaps
puterman l markov decision processes john wiley sons york
richardson domingos p markov logic networks machine learning ml

sanghai domingos p weld relational dynamic bayesian networks
journal artificial intelligence jair
shen w simon h rule creation rule learning environmental exploration proceedings eleventh international joint conference
artificial intelligence ijcai
wang x learning observation practice incremental operator acquisition proceedings twelfth international conference
machine learning icml
yoon fern givan r inductive policy selection first order markov
decision processes proceedings eighteenth conference uncertainty
artificial intelligence uai
younes h l littman l ppddl extension pddl expressing
domains probabilistic effects school computer science carnegie
mellon university technical report cmu cs
zettlemoyer l pasula h kaelbling l learning probabilistic relational rules mit tech report




