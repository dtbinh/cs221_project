Journal Artificial Intelligence Research 9 (1998) 37-97

Submitted 2/98; published 9/98

Divide-and-Conquer Subgoal-Ordering Algorithm
Speeding Logic Inference
Oleg Ledeniov
Shaul Markovitch

olleg@cs.technion.ac.il
shaulm@cs.technion.ac.il

Computer Science Department
Technion { Israel Institute Technology
Haifa 32000, Israel

Abstract

common view programs combination logic control: logic part
defines program must do, control part { it. Logic Programming paradigm developed intention separating logic control.
Recently, extensive research conducted automatic generation control
logic programs. works considered issue automatic generation
control improving eciency logic programs. paper present novel algorithm automatic finding lowest-cost subgoal orderings. algorithm works using
divide-and-conquer strategy. given set subgoals partitioned smaller sets,
based co-occurrence free variables. subsets ordered recursively merged,
yielding provably optimal order. experimentally demonstrate utility algorithm testing several domains, discuss possibilities cooperation
existing methods.

1. Introduction
common view programs combination logic control (Kowalski, 1979).
logic part defines program must do, control part { it. Traditional
programming languages require programmers supply components. Logic
Programming paradigm developed intention separating logic
control (Lloyd, 1987). goal paradigm programmer specifies logic
without bothering control, supplied interpreter.
Initially, practical logic programming languages, Prolog (Clocksin & Mellish, 1987; Sterling & Shapiro, 1994), include means automatic generation
control. result, Prolog programmer implicitly define control order
clauses subgoals within clauses. Recently, extensive research conducted
automatic generation control logic programs. major part research concerned control affects correctness termination logic programs (De Schreye
& Decorte, 1994; Somogyi, Henderson, & Conway, 1996b; Cortesi, Le Charlier, & Rossi,
1997). works consider issue automatic generation control
improving eciency logic programs. Finding good ordering leads ecient
execution requires deep understanding logic inference mechanism. Hence, many
cases, expert programmers able generate ecient programs. problem intensifies recent development field inductive logic programming (Muggleton
c 1998 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiLedeniov & Markovitch

& De Raedt, 1994). There, logic programs automatically induced learning.
learning algorithms commonly built aim speeding induction process
without considering eciency resulting programs.
goal research described paper design algorithms automatically find ecient orderings subgoal sequences. Several researchers explored
problem automatic reordering subgoals logic programs (Warren, 1981; Naish, 1985b;
Smith & Genesereth, 1985; Natarajan, 1987; Markovitch & Scott, 1989). general subgoal ordering problem known NP-hard (Ullman, 1982; Ullman & Vardi, 1988).
Smith Genesereth (1985) Markovitch Scott (1989) present search algorithms
finding optimal orderings. algorithms general carry exponential costs
non-trivial sets subgoals. Natarajan (1987) describes ecient algorithm special
case subgoals set share free variables.
paper present novel algorithm subgoal ordering. call two subgoals
share free variable dependent. Unlike Natarajan's approach, handle
subgoal sets completely independent, algorithm deal subgoal
set, making maximal use existing dependencies acceleration ordering
process. worst case algorithm { Smith Genesereth { exponential.
Still, practical cases, algorithm exploits subgoal dependencies finds optimal
orderings polynomial time.
start analysis ordering problem demonstrate importance
examples. show compute cost given ordering based
cost number solutions individual subgoals. describe algorithm
Natarajan algorithm Smith Genesereth show two
combined algorithm ecient general two.
show drawbacks combined algorithm introduce new algorithm, avoids
drawbacks. call Divide-and-Conquer algorithm (dac algorithm). prove
correctness algorithm, discuss complexity compare combined
algorithm. dac algorithm assumes knowledge cost number solutions
subgoals. knowledge obtained machine learning techniques
employed Markovitch Scott (1989). Finally, test utility algorithm
running set experiments artificial real domains.
dac algorithm subgoal ordering combined many existing methods
logic programming, program transformation, compilation, termination control,
correctness verification, others. discuss possibilities combinations
concluding section.
Section 2 states ordering problem. Section 3 describes existing ordering algorithms
combination. Section 4 presents new algorithm. Section 5 discusses
acquisition control knowledge. Section 6 contains experimental results. Section 7
contains discussion practical issues, comparison works conclusions.

2. Background: Automatic Ordering Subgoals
start describing conventions assumptions accepted paper.
demonstrate importance subgoal ordering discuss validity. Finally, present
classification ordering methods discuss related work.
38

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

2.1 Conventions Assumptions

constant, function predicate symbols programs begin lower case letters,
capital letters reserved variables. Braces used denote unordered sets
(e.g., fa; b; cg), angle brackets used ordered sequences (e.g., ha; b; ci). Parallel
lines (k) denote concatenations ordered sequences subgoals. speaking
abstract subgoals (and named predicates concrete programs), denote separate
subgoals capital letters (A; B : : :), ordered sequences subgoals capitalized vectors
~ O~ : : :), sets subgoals calligraphic capitals (B; : : :). (S ) denotes set
(B;
permutations .
assume programs work written pure Prolog, i.e., without cut
operators, meta-logical extra-logical predicates. Alternatively, assume
pure Prolog sub-sequences subgoals subject ordering. example, given rule
form
B1 ; B2; B3; !; B4; B5; B6:
final part fB4 ; B5; B6g ordered (without affecting solution set).
work focus upon task finding solutions set subgoals.

2.2 Ordering Subgoals Logic Programs
logic program set clauses:



B1 ; B2 ; : : :; Bn :

(n 0)

A; B1 ; : : :; Bn literals (predicates arguments). use clause
proving goal matches A, must prove B -s hold simultaneously,
consistent bindings free variables. solution set variable bindings.
solution set goal bag solutions created program.
computation rule defines subgoal proved next. Prolog, computation rule always selects leftmost subgoal goal. subgoal fails, backtracking
performed { proof previous subgoal re-entered generate another solution.
detailed definition logic inference process, see Lloyd (1987).

Theorem 1 solution set set subgoals depend order

execution.

Proof: looking solutions, solution set depend

computation rule chosen (Theorems 9.2 10.3 Lloyd, 1987). Since transposition
subgoals ordered sequence regarded change computation rule (the
subgoals selected different order), transposition change solution
set.
2
theorem implies may reorder subgoals proof derivation. Yet
eciency derivation strongly depends chosen order subgoals. following
example illustrates two different orders lead large difference execution
eciency.
39

fiLedeniov & Markovitch

parent(abraham,isaac).
parent(sarah,isaac).
parent(abraham,ishmael).
parent(isaac,esav).
parent(isaac,jakov).

... parent clauses ...

male(abraham).
male(isaac).
male(ishmael).
male(jakov).
male(esav).

... male clauses ...

brother(X,Y)
male(X), parent(W,X), parent(W,Y), X=/=Y.
father(X,Y)
male(X), parent(X,Y).
uncle(X,Y)
parent(Z,Y), brother(X,Z).

... rules relations ...

Figure 1: small fragment Biblical database describing family relationships.

Example 1
Consider Biblical family database one listed Figure 1 (a similar database
appears book Sterling & Shapiro, 1994). body rule defining
uncle-nephew (or uncle-niece) relation ordered two ways:
1. uncle(X,Y) brother(X,Z), parent(Z,Y).
2. uncle(X,Y) parent(Z,Y), brother(X,Z).
prove goal uncle(ishmael,Y) using first version rule, interpreter
first look Ishmael's siblings (and find Isaac) siblings' children (Esav
Jacov). left part Figure 2 shows associated proof tree total 10
nodes. use second version rule, interpreter create parentchild pairs available database, test parent whether (or she)
Ishmael's sibling. right part Figure 2 shows associated proof tree total
4(N , 2) + 6 2 + 2 = 4N + 6 nodes, N number parent-child pairs
database. tree contains two success branches N , 2 failure branches; figure
show one example each. two versions rule yield identical solution
sets, first version leads much smaller tree faster execution.
Note result true given mode (bound,free) head literal;
mode (free,bound), uncle(X,jacov), outcome contrary: second
version rule yields smaller tree.

2.3 Categories Subgoal Ordering Methods

Assume current conjunctive goal (the current resolvent) fA1; A2g. Assume
use rule \A1 A11; A12:" reduce A1 . According Theorem 1, produced
resolvent, fA11 ; A12; A2g, executed order. call ordering methods
allow permutation resolvent interleaving ordering methods, since permit
40

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

uncle(X,Y)

brother(X,Z), parent(Z,Y). uncle(X,Y)

uncle(ishmael,Y)

uncle(ishmael,Y)

parent(Z,Y), brother(ishmael,Z)

brother(ishmael,Z), parent(Z,Y)

Z=adam,
Y=cain

male(ishmael), parent(W,ishmael), parent(W,Z),
ishmael =/= Z, parent(Z,Y)

brother(ishmael,adam)
parent(W,ishmael), parent(W,Z),
ishmael =/= Z, parent(Z,Y)
W=abraham
parent(abraham,Z), ishmael=/=Z, parent(Z,Y)
Z=ishmael
Z=isaac
ishmael =/= ishmael,
parent(ishmael,Y)

isaac =/= ishmael,
parent(isaac,Y)

parent(Z,Y), brother(X,Z).

Z=isaac,
Y=jacov


parent-child
pairs

male(ishmael), parent(W,ishmael),
parent(W,adam), ishmael =/= adam
parent(W,ishmael), parent(W,adam),
ishmael =/= adam
W=abraham
parent(abraham,adam), ishmael =/=adam

parent(isaac,Y)
Y=esav
Y=jacov

brother(ishmael,isaac)

male(ishmael), parent(W,ishmael),
parent(W,isaac), ishmael=/=isaac
parent(W,ishmael), parent(W,isaac),
ishmael =/= isaac
W=abraham
parent(abraham,isaac), ishmael=/=isaac
ishmael =/= isaac

Figure 2: Two proof trees obtained different orderings single rule Example 1.
interleaving subgoals different rule bodies. ordering performed
rule bodies using reduction, method non-interleaving.
example, interleaving methods consider 6 permutations resolvent, noninterleaving methods consider two orderings: hA11 ; A12; A2i hA12; A11; A2i.
Interleaving ordering methods deal significantly possible orderings noninterleaving methods. means find ecient orderings.
hand, space possible orderings may become prohibitively large, requiring
many computational resources.
Subgoal ordering take place various stages proof process. divide
subgoal ordering methods static, semi-dynamic dynamic.

Static ordering: rule bodies ordered execution starts. ordering takes place execution.

Semi-dynamic ordering: Whenever rule selected reduction, body
ordered. order subgoals change reduction takes place.

Dynamic ordering: ordering decision made inference step.
Static methods add overhead execution time. However, optimal ordering
rule often depends particular binding variable, known
run-time. instance, Example 1 saw first ordering rule better
proving goal uncle(ishmael,Y). yet, goal uncle(X,jacov),
second ordering yields ecient execution. handle cases statically,
must compute optimal ordering possible binding.
41

fiLedeniov & Markovitch

Obviously, static ordering non-interleaving. dynamic method
exible, since use updated knowledge variable bindings, carries
largest runtime overhead, since invoked several times use rule body.
semi-dynamic method compromise two: powerful
static method, dynamically propose different orderings different instances
rule; carries less overhead dynamic method, invoked
use rule body.
total time proving goal sum ordering time inference time.
Interleaving dynamic methods best potential reducing inference time,
may significantly augment ordering time. Static methods devote time
ordering (it done off-line), limited potential reducing inference time.
algorithms described paper used categories ordering methods,
although experiments described Section 6 implemented semi-dynamic,
non-interleaving ordering methods: reduction, rule body ordered added
left end resolvent, leftmost literal resolvent selected
next reduction step.

2.4 Related Work

problem computational ineciency logic inference subject extensive
research. obvious aspect ineciency possible non-termination
proof. Several researchers developed compile-time run-time techniques detect
avoid infinite computations (De Schreye & Decorte, 1994). certain success
achieved providing advanced control employment co-routining interpredicate synchronization purposes (Clark & McCabe, 1979; Porto, 1984; Naish, 1984).
Also, infinite computations avoided pruning infinite branches contain
solutions (Vasak & Potter, 1985; Smith, Genesereth, & Ginsberg, 1986; Bol, Apt, & Klop,
1991). NAIL! system (Morris, 1988) subgoals automatically reordered avoid
nontermination.
Still, even proof finite, desirable make ecient. Several
researchers studied problem clause ordering (Smith, 1989; Cohen, 1990; Etzioni,
1991; Laird, 1992; Mooney & Zelle, 1993; Greiner & Orponen, 1996). looking
solutions goal, eciency depend clause order (assuming
cuts). Indeed, predicate clauses, argument bindings
clauses produce solutions times t1 ; t2 : : :tm , solutions predicate
bindings obtained time t1 + t2 + : : : + tm , regardless order
clauses applied. Different clause orderings correspond different orders
branches selected proof tree; traverse entire tree, number
traversal steps depend order branch selection, though order
solutions found depend it.
Subgoal ordering, demonstrated Example 1, significantly affect eciency proving goal. two major approaches subgoal ordering. first
approach uses various heuristics order subgoals, example:

Choose subgoal whose predicate smallest number matching clauses (Minker,
1978).

42

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Prefer subgoal constants (Minker, 1978).
Choose subgoal largest size, size defined number
occurrences predicate symbols, function symbols, variables (Nie & Plaisted,
1990).

Choose subgoal largest mass, mass subgoal depends
frequency arguments sub-arguments entire goal (Nie & Plaisted,
1990).

Choose subgoal least number solutions (Warren, 1981; Nie & Plaisted,
1990).

Apply \tests" \generators" (Naish, 1985a).
Prefer calls fail quickly (Naish, 1985b).
heuristic methods usually execute quickly, may yield suboptimal orderings.
second approach, adopted paper, aims finding optimal orderings (Smith & Genesereth, 1985; Natarajan, 1987; Markovitch & Scott, 1989). Natarajan
proposed ecient way order special sort subgoal set (where subgoals independent), Smith Genesereth proposed general, inecient algorithm.
following section build unifying framework dealing subgoal ordering
describe variations Natarajan's Smith Genesereth's algorithms. show
two combined increased eciency.

3. Algorithms Subgoal Ordering Logic Programs
goal work presented order subgoals speeding logic programs.
section starts analysis cost executing sequence subgoals. resulting
formula basis subsequent ordering algorithms. discuss dependence
subgoals present existing ordering algorithms independent dependent sets
subgoals. Finally, combine algorithms general ecient one.

3.1 Cost Executing Sequence Subgoals

subsection analyze cost executing sequence subgoals. analysis
builds mainly work Smith Genesereth (1985).
Let = fA1; A2; : : :Ak g set subgoals b binding. denote Sols(S )
solution set , define Sols(;) = f;g. denote Ai jb Ai whose variables
bound according b (Ai j; = Ai ). Finally, denote Cost(Ai jb ) amount
resources needed proving Ai jb . Cost(Ai jb ) ect time complexity proving
Ai binding b. example, number unification steps natural measure
complexity logic programs (Itai & Makowsky, 1987).
obtain cost finding solutions ordered sequence subgoals

S~ = hA1; A2; A3; : : :Ani;
43

(1)

fiLedeniov & Markovitch

note proof-tree A1 traversed once, tree A2 traversed
solution generated A1 , tree A3 { solution fA1; A2g, etc.
Consequently, total cost proving Equation 1

Cost(hA1; : : :An i) = Cost(A1) +
=

X

Cost(A2jb) + : : : +

b2Sols(fA1 g)

n
X

X

Cost(An jb ) =

b2Sols(fA1 ;:::An,1 g)

X

Cost(Aijb):
i=1 b2Sols(fA1 ;:::Ai,1 g)

(2)

compute Equation 2 one must know cost solution set subgoal
binding. reduce amount information needed, derive equivalent
formula, uses average cost average number solutions.

Definition: Let B set subgoals, subgoal. Define cost(A)jB average
cost solutions B nsols(A)jB average number solutions
solutions B:
8
>
P (A); Cost(Ajb) B = ;
< Cost
B
cost(A)jB = > b2Sols
; B=
6 ;; Sols(B) =6 ;
j
Sols(B)j
: undefined;
B 6= ;; Sols(B) = ;
( )

8
>
j;
B=;
< jPSols(fAgj)Sols
(
f

j
g
)
j
b
B
nsols(A)jB = > b2SolsjSols
; B=
6 ;; Sols(B) 6= ;
: undefined; (B)j
B 6= ;; Sols(B) = ;
( )

first definition, follows that:

X

Cost(Aijb ) = jSols(fA1; : : :Ai,1 g)j cost(Ai)jfA ;:::Ai, g :
1

b2Sols(fA1 ;:::Ai,1 g)

1

(3)

apply second definition recursively, obtain

jSols(fA1; : : :Aig)j =
=
=

X

jSols(fAijbg)j
b2Sols(fA1 ;:::Ai,1 g)
jSols(fA1; : : :Ai,1 g)j nsols(Ai)jfA1;:::Ai,1g
Yi
: : : = nsols(Aj )jfA1:::Aj,1 g:
j =1

(4)

Note defined Sols(;) = f;g; thus, equations hold = 1. Incorporation
Equations 3 4 Equation 2 yields

Cost(hA1; A2; : : :An i) =

20i,1
n
X
4@
i=1

j =1

1
3
nsols(Aj )jfA :::Aj, gA cost(Ai )jfA :::Ai, g5 :
1

44

1

1

1

(5)

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

subgoal Ai , average cost multiplied total number solutions
preceding subgoals. define average cost number solutions every
continuous sub-sequence Equation 1: 8k1 ; k2; 1 k1 k2 n,
cost(hA1; : : :Ak i)j; , cost(hA1; : : :Ak ,1 i)j;
(6)
cost(hAk ; : : :Ak i)jfA ;:::Ak , g =
20 nsols(hA1; : : :Ak ,1 i)1j;
3
1

2

2

1

1

1

1

=

k
i,1
X
4@
2

i=k1

j =k1

1

nsols(Aj )jfA ;:::Aj, g cost(Ai )jfA ;:::Ai, g 5
1

1

1

1

k

nsols(hA1; : : :Ak i)j;
nsols(hAk ; : : :Ak i)jfA ;:::Ak , g =
=
nsols(Ai)jfA ;:::Ai, g
nsols(hA1; : : :Ak ,1 i)j; i=k
1

2

2

1

1

1

1

2

1

1

(7)

1

values cost(Ai ) nsols(Ai ) depend position Ai ordered sequence. example, assume want find Abraham's sons, using domain
Example 1. unordered conjunctive goal fmale(Y),parent(abraham,Y)g. Let
N males database (two them, Isaac Ishmael, Abraham's sons):
nsols(male(Y))j; = N
nsols(parent(abraham,Y))j; = 2
nsols(male(Y))jfparent(abraham,Y)g = 1 nsols(parent(abraham,Y))jfmale(Y)g = 2=N
Note nsols(hmale(Y),parent(abraham,Y)i) = 2 = nsols(hparent(abraham,Y),male(Y)i),
exactly Theorem 1 predicts.
defined cost sequence subgoals, define objective
ordering algorithms:

Definition: Let set subgoals. Define (S ) set permutations
. O~ 2 (S ) minimal ordering (denoted Min(O~ ; )), cost according
Equation 5 minimal possible permutations :
Min(O~ ; ) () 8OS0 2 (S ) : Cost(O~ ) Cost(OS0 ):
total execution time sum time spent ordering,
inference time spent interpreter ordered sequence. paper focus
upon developing algorithms minimizing inference time. Elsewhere (Ledeniov &
Markovitch, 1998a, 1998b) present algorithms attempt reduce total execution
time.
values cost number solutions obtained various ways: exact
computation, estimation bounds, learning. Let us assume moment
exists mechanism returns average cost number solutions
subgoal time . Section 5 show control knowledge obtained
inductive learning.

3.2 Ordering Independent Sets Subgoals

general subgoal ordering problem NP-hard (Ullman & Vardi, 1988). However,
special case ordering performed eciently: subgoals
45

fiLedeniov & Markovitch

given set independent, i.e. share free variables. section begins
definition subgoal dependence related concepts. show ordering algorithm
independent sets prove correctness.
3.2.1 Dependence Subgoals

Definition: Let B sets subgoals (B called binding set ). pair
subgoals directly dependent B, share free variable bound
subgoal B.
pair subgoals indirectly dependent respect B exists third
subgoal directly dependent one B, dependent (directly
indirectly) one B. pair subgoals independent B
dependent B (either directly indirectly). subgoal independent
B independent members B.
Two subsets S1 S2 mutually independent binding set B
every pair subgoals (A1; A2), A1 2 S1 A2 2 S2, independent B.
entire set called independent binding set B subgoal pairs
independent B, called dependent otherwise. dependent set subgoals
called indivisible subgoal pairs dependent B, divisible otherwise.
divisibility partition B, DPart(S ; B), partition subsets
mutually independent indivisible B, except one subset contains
subgoals independent B. easy show DPart(S ; B) unique.
example, let S0 = fa; b(X ); c(Y ); d(X; ); e(Z ); f (Z; V ); h(W )g. respect
S0 empty binding set, pair fb(X ); d(X; )g directly dependent, fb(X ); c(Y )g
indirectly dependent fb(X ); e(Z )g independent. represent set subgoals

graph, subgoals vertices directly dependent subgoals connected
edges, dependence equivalent connectivity indivisible subsets equivalent
connected components size greater 1. divisibility partition partition
graph connected components, \lonely" vertices collected together,
special component. Figure 3 shows example graph set S0
empty binding set. whole set divisible four mutually independent subsets.
subsets fe(Z ); f (Z; V )g fb(X ); c(Y ); d(X; )g indivisible. Elements
divisibility partition DPart(S0 ; ;) shown dotted lines.
subgoal independent set, average cost number solutions
depend position within ordered sequence:
P
Cost(Ajb) jSols(B)j Cost(A)
=
= Cost(A);
cost(A)jB = b2Sols(B)
jSols(B)j
jSols(B)j

P

b2Sols(B) jSols(fAjbg)j

= jSols(B)j jSols(fAg)j = jSols(fAg)j:
jSols(B)j
case omit binding information write cost(Ai ) instead cost(Ai)jfA :::Ai, g ,
nsols(Ai ) instead nsols(Ai )jfA :::Ai, g.
practice, program rule bodies rarely feature independent sets literals. example
following clause, states children candy:
nsols(A)jB =

jSols(B)j

1

1

1

46

1

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

fa,

b(X), c(Y), d(X,Y), e(Z), f(Z,V), h(W)


h(W)

b(X)

e(Z)
f(Z,V)

g)

c(Y)

d(X,Y)

Figure 3: example graph representing set subgoals. Directly dependent subgoals

connected edges. Independent subgoals indivisible subsets equivalent
connected components (surrounded dashed lines). divisibility partition (under
empty binding set) shown dotted lines.
likes(X,Y)

child(X), candy(Y).

often, independent rule bodies appear written
program text, variables bound (initially dependent) rule bodies,
result clause head unification. example, rule
father(X,Y)

male(X), parent(X,Y).

used reduce father(abraham,W), X bound abraham, rule body
becomes independent. Rule bodies often become independent substitutions performed course inference process.
3.2.2 Algorithm Ordering Independent Sets Sorting

Let S~ ordered sub-sequence subgoals, B set subgoals. denote
~
cn(S~ )jB = nsols(S)~jB , 1 :
cost(S )jB
name \cn" ects participation cost nsols definition. subsequence S~ independent subgoals, binding information (jB ) omitted.
Together, average cost, average number solutions, cn value subgoal
called control values subgoal.
independent sets, exists ecient ordering algorithm, listed Figure 4.
complexity algorithm O(n( + log n)): O(n ) obtain control values n
subgoals, O(n log n) perform sorting (Knuth, 1973). enable division,
must define cost cost(Ai ) always positive. define cost number
unifications performed, always cost(Ai ) 1, reasonable assumption
predicates rule body subgoals defined program. (In case, least one
unification performed subgoal). Similar algorithms proposed Simon
Kadane (1975) Natarajan (1987).
Example 2 Let set independent subgoals fp; q; rg, following control values:
47

fiLedeniov & Markovitch

Algorithm 1
Let = fA1; A2; : : :An g set subgoals.
(Ai ),1
Sort using cn(Ai ) = nsols
cost(Ai ) key Ai , return result.
Figure 4: algorithm ordering subgoals sorting.
p q
r
cost 10 20
5
nsols 1 5
0:1
cn
0 0:2 ,0:18
compute costs possible orderings, using Equation 5:

Cost(hp; q; ri) = 10 + 1 20 + 1 5 5 = 55
Cost(hp; r; q i) = 10 + 1 5 + 1 0:1 20 = 17
Cost(hq; p; ri) = 20 + 5 10 + 5 1 5 = 95
Cost(hq; r; pi) = 20 + 5 5 + 5 0:1 10 = 50
Cost(hr; p; q i) = 5 + 0:1 10 + 0:1 1 20 = 8
Cost(hr; q; pi) = 5 + 0:1 20 + 0:1 5 10 = 12
minimal ordering hr; p; q i, exactly ordering found much
quickly Algorithm 1 set fp; q; rg: r smallest cn value, ,0:18,
goes p cn(p) = 0, finally q cn(q ) = 0:2.
Note sorting algorithm ects well-known principle: best implementations generate-and-test programs obtained tests placed early possible
rule body generations late possible (Naish, 1985a). course,
cheap tests come first, expensive ones come last. one looks
cn measure, one quickly realizes tests put front (because nsols < 1,
cn < 0), generator subgoals move towards end (nsols > 1, cn > 0).
weakness \test-first" principle fact every subgoal easily
tagged test generator. one subgoal nsols < 1 another one nsols > 1,
order obvious even without looking costs (because cn values
different signs). subgoals nsols < 1, nsols > 1,
decision simple. Sorting cn correctly handle possible cases.
3.2.3 Correctness Proof Sorting Algorithm Independent Sets

saw Algorithm 1 found minimal ordering Example 2. going
prove Algorithm 1 always finds minimal ordering independent sets. First
show important lemma used discussion. lemma states
48

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

substitution sub-sequence cheaper permutation makes entire sequence
cheaper.

Lemma 1
Let S~ = A~ kB~ kC~ , S~ 0 = A~ kB~ 0 kC~ , B~ B~ 0 permutations one another, A~
either empty nsols(A~ ) > 0.

Cost(S~ ) < Cost(S~ 0 ) () cost(B~ )jA~ < cost(B~ 0 )jA~ ;
Cost(S~ ) = Cost(S~ 0 ) () cost(B~ )jA~ = cost(B~ 0 )jA~ :

Proof: A~ C~ empty,
Cost(S~ ) , Cost(S~ 0 ) = Cost(A~ kB~ kC~ ) , Cost(A~ kB~ 0 kC~ ) =


(5)
= cost(A~ )j; + nsols(A~ )j; cost(B~ )jA~ + nsols(A~ kB~ )j; cost(C~ )jA~ kB~ ,
~

cost(A)j; + nsols(A~ )j; cost(B~ 0 )jA~ + nsols(A~ kB~ 0 )j; cost(C~ )jA~ kB~ 0 :

Theorem 1, B~ B~ 0 produce solution sets. Hence, third terms
parentheses equal,





Cost(S~ ) , Cost(S~ 0) = nsols(A~ )j; cost(B~ )jA~ , cost(B~ 0 )jA~ :
Since nsols(A~ ) > 0, sign Cost(S~ ) , Cost(S~ 0 ) coincides sign cost(B~ )jA~ ,
cost(B~ 0 )jA~ .
A~ C~ empty, proof similar.
2
Definition: Let S~ = A~ kB~ 1kC~ kB~ 2kD~ ordered sequence subgoals (A~, C~ D~ may
empty sequences). respect S~ , pair hB~ 1 ; B~ 2i

cn-ordered, cn(B~ 1)jA~ cn(B~ 2)jA~[B~ [C~
1

cn-inverted, cn(B~ 1)jA~ > cn(B~ 2)jA~[B~ [C~
1

show two adjacent mutually independent sequences subgoals minimal
ordering must cn-ordered.

Lemma 2
Let S~ = A~ kB~ 1 kB~ 2 kC~ , S~ 0 = A~ kB~ 2 kB~ 1 kC~ , B~ 1 , B~ 2 mutually independent A~ .
Let A~ either empty nsols(A~ ) > 0.

Cost(S~ ) < Cost(S~ 0) () cn(B~ 1)jA~ < cn(B~ 2)jA~ ;
Cost(S~ ) = Cost(S~ 0) () cn(B~ 1)jA~ = cn(B~ 2)jA~ :
49

fiLedeniov & Markovitch

Proof:
Cost(S~ ) < Cost(S~ 0) Lemma
() 1 cost(B~ 1kB~ 2)jA~ < cost(B~ 2kB~ 1)jA~
() cost(B~ 1)jA~ + nsols(B~ 1)jA~ cost(B~ 2)jA~[B~ <
cost(B~ 2 )jA~ + nsols(B~ 2 )jA~ cost(B~ 1 )jA~[B~
indep.fB~ 1 ; B~ 2g
()
cost(B~ 1 )jA~ + nsols(B~ 1 )jA~ cost(B~ 2 )jA~ <
cost(B~ 2 )jA~ + nsols(B~ 2 )jA~ cost(B~ 1 )jA~
() nsols(B~ 1)jA~ cost(B~ 2)jA~ , cost(B~ 2)jA~ <
nsols(B~ 2 )jA~ cost(B~ 1 )jA~ , cost(B~ 1 )jA~
cost(B~ )jA~ >0 nsols(B~ 1 )jA~ , 1 nsols(B~ 2 )jA~ , 1
()
<
cost(B~ 1 )jA~
cost(B~ 2 )jA~
() cn(B~ 1)jA~ < cn(B~ 2)jA~
1
2

Cost(S~ ) = Cost(S~ 0)

()

cn(B~ 1 )jA~ = cn(B~ 2)jA~ | similar.

2

independent set, subgoal pairs independent, particular adjacent pairs.
So, minimal ordering independent set, adjacent subgoal pairs must cnordered; otherwise, cost sequence reduced transposition pair.
conclusion expressed following theorem.

Theorem 2
Let independent set. Let S~ ordering . S~ minimal iff subgoals
S~ sorted non-decreasing order cn values.

Proof:

1. Let S~ minimal ordering . S~ contains cn-inverted adjacent pair subgoals,
transposition pair reduces cost S~ (Lemma 2), contradicting
minimality S~ .

2. Let S~ ordering , whose subgoals sorted non-decreasing order
cn. Let S~ 0 minimal ordering . According item 1, S~ 0 sorted
cn. possible difference two sequences internal ordering
sub-sequences equal cn values. ordering sub-sequence
S~ transformed ordering counterpart sub-sequence S~ 0
finite number transpositions adjacent subgoals. Lemma 2, transpositions
adjacent independent subgoals equal cn values cannot change cost
sequence. Therefore, Cost(S~ ) = Cost(S~ 0), S~ minimal ordering (since S~ 0
minimal).
2

Corollary 1 Algorithm 1 finds minimal ordering independent set subgoals.
50

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

3.3 Ordering Dependent Sets Subgoals

Algorithm 1 guarantee finding minimal ordering given set subgoals
dependent, following proposition shows.

Proposition 1 given set subgoals dependent, then:
1. result Algorithm 1 always defined.
2. Even result defined, always minimal ordering set.

Proof: claims proved counter-examples.
1. show set subgoals cannot ordered sorting.
program:
Control values:
a(X )j; a(X )jfb(X )g b(X )j; b(X )jfa(X )g
a(c1).
b(c1).
cost
2
2
2
2
a(c2).
b(c2).
nsols
2
1
2
1
1
1
cn
0
0
2
2

set fa(X), b(X)g two possible orderings, ha(X ); b(X )i hb(X ); a(X )i.
orderings minimal cost, though neither one sorted cn: ordering
cn = 12 first subgoal, cn = 0 second one. Sorting cn
impossible here: transpose subgoals, cn values changed,
pair becomes cn-inverted again.
2. show set subgoals ordered sorting, sorted ordering
minimal.
program:
Control values:
a(X )j; a(X )jfb(X )g b(X )j; b(X )jfa(X )g
a(c1).
cost
2
2
8
2
a(c1).
2
2
1
1
nsols
b(c1).
1
1
cn
0
0
b(c2)
a(c1), a(c2).
2
2
Let unordered set subgoals fa(X), b(X)g. ordering hb(X ); a(X )i sorted
cn, ha(X ); b(X )i not. ha(X ); b(X )i cheaper hb(X ); a(X )i:
cost(ha(X ); b(X )i) = 2 + 2 2 = 6

cost(hb(X ); a(X )i) = 8 + 1 2 = 10

2
Since sorting cannot guarantee minimal ordering dependent subgoals, consider alternative ordering algorithms. simplest algorithm checks every possible permutation set returns one minimal cost. listing algorithm
shown Figure 5.
algorithm runs O( n!) time, time takes compute control
values one subgoal, n number subgoals.
following observation help reduce ordering time expense additional space. Ordered sequences constructed incrementally, adding subgoals
51

fiLedeniov & Markovitch

Algorithm 2
permutation subgoals, find cost according Equation 5.
Store currently cheapest permutation update cheaper
one found.
Finally, return cheapest permutation.

Figure 5: algorithm subgoal ordering exhaustive check permutations.

Algorithm 3
Order(S )
let P0 f;g; n jSj
loop kn= 1 tofi n

Pk0 nP~ kB fifi P~fi 2 Pk,1; B h2 n P~
io
~ P~ 0 ) ) Cost(P~ ) Cost(P~ 0 )
Pk P~ 2 Pk0 fifi 8P~ 0 2 Pk0 ; permutation(P;
Return single member Pn .
Figure 6: ordering algorithm checks permutations ordered prefixes.
right ends ordered prefixes. Lemma 1, cheaper permutation prefix exists,
prefix cannot belong minimal ordering. ordering algorithm build
prefixes increasing lengths, step adding right end prefix one
subgoals appear already, subset keeping cheapest
permutation (if several permutations equal cost, one chosen).
listing algorithm shown Figure 6. step k, Pk0 stores set prefixes
step k , 1 extended every subgoal appearing already. Pk Pk0 ,
Pk subset subgoals represented cheapest permutation. Obviously,
jPk j = (nk) (one prefix kept every subset size k). prefix length k , 1,
n , (k , 1) possible continuations length k. size Pk0 follows:
!
k
n!
n
jPk0 j = (k,n1)(n,(k,1)) = (n , (k ,n1))!(
k , 1)! (n,(k,1)) = k (n , k)!(k , 1)! = k (k ):
prefix, compute cost time. permutation test completed
O(n) time, using, example, trie structure (Aho et al., 1987), subgoals
prefixes sorted lexicographically. step k takes O((n + ) k (nk )) time,
52

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

whole algorithm runs
n
X

k=1

O((n + ) k (nk )) = O(n (n + )

n
X
n
k=1

(k )) = O(n (n + ) 2n ):

= O(n), makes O(n2 2n ).
Smith Genesereth (1985) Natarajan (1987) point minimal ordered
sequence every adjacent pair subgoals must satisfy adjacency restriction.
general form restriction notation says two adjacent subgoals Ak
Ak+1 minimal ordering hA1; A2 : : :Ani must satisfy
cost(hAk ; Ak+1i)jfA :::Ak, g cost(hAk+1 ; Ak i)jfA :::Ak, g:
1

1

1

1

(8)

restriction follows immediately Lemma 1. However, help find
locally minimal ordering, i.e., ordering cannot improved transpositions
adjacent subgoals. possible adjacent subgoal pairs satisfy Equation 8,
ordering still minimal. following example illustrates statement.

Example 3 Let unordered set fp(X ); q(X ); r(X )g, predicates defined
following program:

p(c1):
q (c1):
r(c1):
p(c2) f: q (c2):
r(c1):
q (c3) f:
f fails 50 unifications.
ordering hp(X ); q (X ); r(X )i satisfies adjacency restriction (Equation 8):
cost(q (X ); r(X ))jp(X ) = 5
cost(p(X ); q (X ))j; = 55
cost(q (X ); p(X ))j; = 107
cost(r(X ); q (X ))jp(X ) = 8
minimal:

cost(hp(X ); q(X ); r(X )i) = 57
cost(hr(X ); p(X ); q (X )i) = 12

find globally minimal ordering, seems beneficial combine prefix algorithm
adjacency restriction: prefix satisfy adjacency restriction,
cheaper permutation prefix. adjacency test performed faster
permutation test, since must consider two last subgoals prefix. Nevertheless, number prefixes remaining step Algorithm 3
reduced: prefix rejected due violation adjacency restriction, would
rejected permutation test. Furthermore, adjacency restriction test
fail, still perform permutation test avoid local minima (as
Example 3). adjacency test succeeds least half cases: examine
prefix hA1 ; : : :Ak ; B1; B2 i, shall examine hA1; : : :Ak ; B2 ; B1i, adjacency test
cannot fail both. Consequently, addition adjacency test halve total
running time ordering algorithm, leaving O(n2 2n ) worst case.
53

fiLedeniov & Markovitch

Smith Genesereth propose performing best-first search space ordered
prefixes, preferring prefixes lower cost. best-first search combined
permutation test adjacency restriction. addition, subgoals
prefix independent binding, sorted, sorted result
concatenated prefix. Lemma 1 Corollary 1, produces cheapest
completion prefix. perform completion, need perform
adjacency permutation test: complete sequence minimal, never chosen
cheapest prefix; even added list prefixes, never extracted
therefrom. resulting algorithm shown Figure 7.

Algorithm 4
Order(S )

let prefix-list ;, prefix ;, rest
loop empty(rest)
Independent(restjprefix)

let completion prefixkSort-by-cn(restjprefix)
Insert-By-Cost(completion, prefix-list)
else
loop subgoal 2 rest
let extension prefixksubgoal
Adjacency-Restriction-Test(extension)
Permutation-Test(extension)

Insert-By-Cost(extension, prefix-list)
prefix Cheapest(prefix-list)
Remove-from-list(prefix, prefix-list)
rest Snprefix
Return prefix

Figure 7: algorithm subgoal ordering, incorporating ideas earlier researchers.
advantage using best-first search avoids expanding prefixes whose cost
higher cost minimal ordering. policy used algorithm may,
however, suboptimal even harmful. often happens best completion
cheaper prefix much expensive best completion expensive prefix.
number solutions large, better place subgoals high costs closer
beginning ordering reduce number times cost multiplied.
example, let set fa(X ); b(X )g, cost(a(X )) = 10, cost(b(X )) = nsols(a(X ))
= nsols(b(X )) = 2. minimal ordering starts expensive prefix:
Cost(ha(X ); b(X )i) = 10 + 2 2 = 14
54

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Cost(hb(X ); a(X )i) = 2 + 2 10 = 22
many prefixes whose cost higher cost minimal ordering,
best-first search saves time. number prefixes small, using best-first
search increase total time, due need perform insertion prefix
priority queue, according cost.
sample run Algorithm 4 shown later (in Section 4.7).

4. Divide-and-Conquer Subgoal Ordering Algorithm

Algorithm 1 presented Section 3.2 ecient, applicable entire
set subgoals independent. Algorithm 3 handle dependent set subgoals
inecient. Algorithm 4, combination two, exploit independence subgoals better eciency. However, obtained benefit quite limited. section,
present Divide-and-Conquer (dac) algorithm, able exploit subgoal independence elaborate way. algorithm divides set subgoals smaller
subsets, orders subsets recursively combines results.

4.1 Divisibility Trees Subgoal Sets

subsection define structure represents ways breaking subgoal
set independent parts. algorithm work traversing structure.
Definition: Let B sets subgoals. divisibility tree B, DTree(S ; B),
AND-OR tree defined follows:
8 leaf(S ; B)
, independent B
>
>

>
<
DTree(S ; B) = > OR(S ; B; fDTree(S n fBi g; B [ fBi g) j Bi 2 Sg) , indivisible B
>
: AND(S ; B; fDTree(Si; B) j Si 2 DPart(S ; B)g) , divisible B

node N tree DTree(S0; B0) associated set subgoals (N ) S0
associated binding set B(N ) B0. root node, (N ) = S0, B(N ) = B0 .
binding set root specified explicitly, assume empty. AND-nodes
OR-nodes define sets children.

(N ) independent B(N ), N leaf.
(N ) indivisible B(N ), N OR-node. subgoal Bi (N )
defines child node whose set subgoals (N ) n fBi g binding set
B(N ) [ fBi g. call Bi binder generated child. Note binding
set every node divisibility tree union binders indivisible
ancestors root's binding set.

(N ) divisible B(N ), N AND-node. subset Si
divisibility partition DPart(S (N ); B(N )) defines child node associated set
subgoals Si binding set B(N ). Divisibility partition defined Section 3.2.1.
55

fiLedeniov & Markovitch

= {a, b, c(X), d(X), e(X)}
n1 S(n1)
B(n1) =

S(n2) = {a, b}
B(n2) =

n2

S(n3) = {c(X), d(X), e(X)}

n3 B(n3) =

S(n4) = {d(X), e(X)}
S(n6) = {c(X), d(X)}
n5
n6 B(n6) = {e(X)}
B(n4) = {c(X)} n4
S(n5) = {c(X), e(X)}
B(n5) = {d(X)}

Figure 8: divisibility tree fa; b; c(X ); d(X ); e(X )g empty initial binding set. set
associated node n1 divisible, represented AND-node. children
correspond divisibility subsets { one independent, (n2) = fa; bg, one indivisible, (n3) = fc(X ); d(X ); e(X )g. n3 OR-node, whose children correspond
three subgoals (each subgoal serves binder one children). sets (n2),
(n4), (n5) (n6) independent respective binding sets,
nodes leaves. assumed subgoals c(X ), d(X ) e(X ) bind X
result proof.

easy show divisibility tree set subgoals unique order
children node. Figure 8 shows divisibility tree set fa; b; c(X ); d(X ); e(X )g
empty initial binding set. associated sets binding sets written next
nodes.
following lemma expresses important property divisibility trees: subgoals
node independent rest subgoals binding set node.

Lemma 3 Let S0 set subgoals. every node N DTree(S0; ;), every
subgoal 2 (N ), every subgoal 2 S0 n (S (N ) [B(N )), independent
B(N ).
Proof: induction depth N divisibility tree.
Inductive base: N root node, S0 n (N ) empty, exists.
Inductive hypothesis: lemma holds , parent node N .
Inductive step: Let 2 (N ), 2 S0 n (S (N ) [ B(N )). 2 (M ),
lemma holds, thus either independent B(M ), 2 (M ).
independent B(M ), independent B(N ),
since B(M ) B(N ). Otherwise, dependent B(M ), 2 (M ).
56

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

AND-node, dependent B(M ),
belong element DPart(S (M ); B(M )), 2 (N ) {

contradiction.
OR-node 2 (M ) n (N ), must binder N .
B(N ) = B(M ) [ fY g 2 B(N ) { contradiction again.
2
lemma relates subgoal independence inside divisibility trees. shall sometimes
need argue independence inside ordered sequences subgoals. following
corollary provides necessary connecting link.

Corollary 2 Let S0 set subgoals, N node divisibility tree S0, S~
ordering S0, S~ = S~1 kS~2, B(N ) S~1 (N ) S~2 . (N ) mutually
independent S~2 n (N ) S~1.
Proof: Let 2 (N ), 2 S~2 n (N ). independent B(N ),
preceding lemma. Since B(N ) S~1 , independent S~1. Every subgoal
(N ) independent every subgoal S~2 nS (N ) S~1; therefore, (N ) S~2 nS (N )
mutually independent S~1 .

2

4.2 Valid Orderings Divisibility Trees

aim ordering algorithm find minimal ordering given set subgoals.
construct orderings following divide-and-conquer policy: larger sets split
smaller ones, orderings smaller sets combined produce ordering
larger set. implement policy, perform post-order traversal divisibility
tree corresponding given set subgoals empty initial binding set.
orderings child nodes combined produce ordering parent node, inner
order subgoals changed: smaller orderings consistent larger orderings.

Definition: Let G sets subgoals. ordering O~ G G ordering
O~ consistent (denoted Cons(O~ G; O~ )), order subgoals G O~ G
O~ same.

divide-and-conquer process described seems analogous Merge Sort (Knuth,
1973). There, set numbers split two (or more) subsets, subset independently ordered sequence consistent global order, sequences
merged. possible use similar method subgoal ordering? Assume set
subgoals partitioned two mutually independent subsets, B. build
algorithm that, given A, produces ordering consistent minimal ordering
[ B, independently B? Unfortunately, answer negative. ordering may
consistent minimal ordering [ B1 time consistent
minimal ordering [ B2 B1 6= B2.
example, let = fa1(X ); a2(X )g, B1 = fbg, B2 = fdg control values
specified Figure 9. single minimal ordering [ B1 ha2(X ); b; a1(X )i,
single minimal ordering A[B2 hd; a1(X ); a2(X )i. ordering consistent
minimal global orderings.
57

fiLedeniov & Markovitch

program:
a1(c1).
a1(c1).
a2(c1).
a2(c1).
a2(c2)

b
b
d.

a1(X).
d.

a1(c2).

control values:
a1(X )j; a1(X )jfa2(X )g a2(X )j; a2(X )jfa1(X )g b
cost
2
2
5
3
5 1
nsols
2
2
2
2
3 1

Cost(b; a1(X ); a2(X )) = 5 + 3 2 + 3 2 3 = 29
Cost(b; a2(X ); a1(X )) = 5 + 3 5 + 3 2 2 = 32
Cost(a1(X ); b; a2(X )) = 2 + 2 5 + 2 3 3 = 30
Cost(a1(X ); a2(X ); b) = 2 + 2 3 + 2 2 5 = 28
Cost(a2(X ); b; a1(X )) = 5 + 2 5 + 2 3 2 = 27
Cost(a2(X ); a1(X ); b) = 5 + 2 2 + 2 2 5 = 29

Cost(d; a1(X ); a2(X )) = 1 + 1 2 + 1 2 3 = 9
Cost(d; a2(X ); a1(X )) = 1 + 1 5 + 1 2 2 = 10
Cost(a1(X ); d; a2(X )) = 2 + 2 1 + 2 1 3 = 10
Cost(a1(X ); a2(X ); d) = 2 + 2 3 + 2 2 1 = 12
Cost(a2(X ); d; a1(X )) = 5 + 2 1 + 2 1 2 = 11
Cost(a2(X ); a1(X ); d) = 5 + 2 2 + 2 2 1 = 13

Figure 9: show small program control values defines. compute costs
permutations sets fb; a1(X ); a2(X )g fd; a1(X ); a2(X )g. Different orderings
fa1(X ); a2(X )g consistent minimal orderings sets.
Since, unlike case Merge Sort, cannot always identify single ordering
subset consistent minimal ordering whole set, algorithm deal
sets candidate orderings. requirement set contain least
one local ordering consistent global minimal ordering, local ordering exists
(\local" ordering ordering set node, \global" ordering ordering
set root). set called valid. following definition defines valid
sets formally, together several concepts.
Definition: Let S0 set subgoals N node divisibility tree S0.
Recall (S ) denotes set permutations .
1. O~ 2 (S0) binder-consistent O~ N 2 (S (N )) (denoted BCN (O~ N ; O~ )),
consistent, subgoals B(N ) appear O~ subgoals O~ N :
BCN (O~ N ; O~ ) () 9O~ B 2 (B(N )) : Cons(O~ B kO~ N ; O~ ):
O~ 2 (S0) binder-consistent node N (denoted BCN (O~ )), binderconsistent ordering (N ):
BCN (O~ ) () 9O~ N 2 (S (N )) : BCN (O~ N ; O~ ):
2. O~ N 2 (S (N )) min-consistent O~ 2 (S0) (denoted MCN;S (O~ N ; O~ )),
binder-consistent, O~ minimal:
MCN;S (O~ N ; O~ ) () BCN (O~ N ; O~ ) ^ Min(O~ ; S0):
O~ N 2 (S (N )) min-consistent (denoted MCN;S (O~ N )), min-consistent
ordering S0:
MCN;S (O~ N ) () 9O~ 2 (S0) : MCN;S (O~ N ; O~ ):
0

0

0

0

0

58

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

3. ordering O~ N 2 (S (N )) MC-contradicting, min-consistent:
MCCN;S (O~ N ) () :MCN;S (O~ N ):
0

0

4. Two orderings O~ 1; O~ 2 2 (S (N )) MC-equivalent, one min-consistent
iff one is:
MCEN;S (O~ 1; O~ 2) () [MCN;S (O~ 1) () MCN;S (O~ 2)]:
0

0

0

5. set orderings CN (S (N )) valid, CN contains min-consistent ordering
(when least one min-consistent ordering (N ) exists):

V alidN;S (CN ) () [9O~ N0 2 (S (N )) : MCN;S (O~ N0 )] ! [9O~ N 2 CN : MCN;S (O~ N )]:
0

0

0

important property valid sets valid set orderings root

DTree(S0; ;) must contain minimal ordering S0. Indeed, root (N ) = S0,
consistency becomes identity. Also, B(N ) = ;, binder-consistency becomes

consistency, min-consistency becomes minimality. Since always exists minimal
ordering S0 , valid set orderings root must contain minimal ordering S0.

4.3 Outline Divide-and-Conquer Algorithm

propose algorithm based producing valid sets orderings. node
divisibility tree produces valid set associated set subgoals, passes
parent node. valid set root node found, compare costs
members, return cheapest one.
set orderings produced algorithm node N called candidate set
N . members called candidate orderings N , simply candidates. find
candidate set N , first consider set possible orderings (N )
consistent candidates N 's children. set called consistency set N .
Given candidate sets N 's children, consistency set N defined uniquely.
candidate set N usually unique.
Definition: Let N node divisibility tree S0. consistency set N , denoted
ConsSet(N ), candidate set N , denoted CandSet(N ), defined recursively:

N leaf, consistency set contains permutations (N ):
ConsSet(N ) = (S (N )):

N AND-node, child nodes N1; N2; : : :Nk , define consistency
set N set possible orderings (N ) consistent candidates
N1; N2; : : :Nk :


n

ConsSet(N ) = O~ N 2 (S (N )) fifi 8i (1 k); 9O~ 2 CandSet(Ni) : Cons(O~ ; O~ N ) :
59

fiLedeniov & Markovitch

N OR-node, child node corresponding every binder 2 (N )

NA , consistency set N obtained adding binders first elements
candidates children:

n

ConsSet(N ) = AkO~ fifi 2 (N ); O~ 2 CandSet(NA) :

candidate set N set orderings produced removing MC-contradicting

MC-equivalent orderings consistency set N , keeping least
one representative group MC-equivalent orderings:
CandSet(N ) ConsSet(N );
~ON 2 (ConsSet(N ) n CandSet(N )) ) MCCN;S (O~ N ) _
h 0

9O~ N 2 CandSet(N ) : MCEN;S (O~ N ; O~ N0 ) :
0

0

(In words, ordering rejected, either MC-contradicting, MCequivalent ordering, rejected.)
two kinds orderings removed ConsSet(N ) retaining validity: MC-contradicting MC-equivalent orderings. Removal MCcontradicting ordering cannot change number min-consistent orderings set;
remove MC-equivalent ordering, even min-consistent, minconsistent ordering retained set. exists min-consistent ordering set
node, candidate set must contain min-consistent ordering, therefore
candidate set valid.
Note algorithm treats OR-node, binder child always
placed first subgoal produced ordering node. higher levels inner
order subgoals ordering change (consistency preserved). Therefore,
algorithm produce binder-consistent orderings. explains choice
names \binder" \binding set": subgoals B(N ) bind common variables
(N ), since stand left global ordering algorithm
produces. particular, (N ) independent B(N ), subgoals B(N )
bind shared free variables (N ).
implement DPart function, use Union-Find data structure (Cormen,
Leiserson, & Rivest, 1991, Chapter 22), subgoals elements, indivisible sets
groups. beginning, every subgoal constitutes group itself. Whenever
discover two subgoals share free variable bound subgoals binding set,
unite groups one. complete procedure, need way determine
variables bound given binding set. Section 7.1 contains discussion
problem proposes practical solutions. Finally, collect indivisible
subgoals separate group. operations implemented O(nff(n; n)) amortized time, ff(n; n) inverse Ackermann function, considered O(1)
values n appear realistic logic programs. Thus, whole process
finding divisibility partition n subgoals performed O(n) average time.
formal listing ordering algorithm discussed shown Figure 10.
algorithm specify explicitly candidate sets created consistency sets. complete algorithm, must provide three filtering procedures
60

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Algorithm 5
Order(S0)

RootCandSet

CandidateSet(S0 ; ;)

Return cheapest member RootCandSet

CandidateSet(S ; B)
case (S B)

independent:
let ConsSetN (S )
let CandSetN ValidLeafFilter(ConsSetN )
divisible:
let fS1; S2; : : : Sk g DPart(S ; B)
loop = 1 k
let Ci CandidateSet
(Si ; B)
n~

let ConsSetN
2 (S (N )) j 8i = 1 : : :k; 9O~ 2 Ci : Cons(O~ i; O~ N )
let CandSetN ValidANDFilter(ConsSetN ; fS1; : : : Sk g; fC1; : : : Ck g)
indivisible:
loop 2
let C (A) CandidateSet
n ~ ~ (S n foAg; B [ fAg)
0
let C (A)
ASkOA j OA 2 C (A)
0
let ConsSetN
A2S C (A)
let CandSetN ValidORFilter(ConsSetN )
Return CandSetN

Figure 10: skeleton dac ordering algorithm. type node divisibility tree,

consistency set created refined validity filters. produced candidate
set root valid; hence, cheapest member minimal ordering given
set.

{ ValidLeafFilter , ValidANDFilter ValidORFilter . Trivially, define
null filters return sets receive unchanged. case candidate
set every node contain permutations subgoals, surely valid.
will, however, greatly increase ordering time. intention reduce sizes
candidate sets far possible, keeping valid.
following two subsections discuss filtering procedures. Section 4.4 discusses detection MC-contradicting orderings, Section 4.5 discusses detection MCequivalent orderings. Finally, Section 4.6 present complete ordering algorithm,
incorporating filters skeleton Algorithm 5.
61

fiLedeniov & Markovitch

4.4 Detection MC-Contradicting Orderings

subsection show sucient conditions ordering MC-contradicting.
orderings safely discarded, leaving set orderings valid, reducing
size. subsection divided three parts, one type node divisibility
tree.
4.4.1 Detection MC-Contradicting Orderings Leaves

following lemma shows subgoals min-consistent ordering leaf node must
sorted cn.

Lemma 4
Let S0 set subgoals, N leaf divisibility tree S0. Let O~ N ordering
(N ). subgoals O~ N sorted cn B(N ), O~ N MC-contradicting.
Proof: Let O~ ordering S0, binder-consistent O~ N . show O~ cannot
minimal ordering S0, thus O~ N min-consistent.
O~ N sorted cn, i.e., contains adjacent cn-inverted pair subgoals hA1; A2i.

(Recall pair cn-inverted first element larger cn value second
one { Section 3.2.3). Since O~ consistent O~ N , write O~ = X~ kA1 kY~ kA2kZ~ ,
X~ , Y~ Z~ (possibly empty) sequences subgoals. Since O~ binder-consistent
O~ N , B(N ) X~ .
Y~ empty, A1 A2 adjacent O~ . Since B(N ) X~ , A1 A2
independent X~ . Therefore, cost whole ordered sequence reduced
transposing A1 A2 , according Lemma 2 (they adjacent, independent
cn-inverted).
Y~ empty, subgoal Y~ belongs (N ), since otherwise would appear
O~ N A1 A2 . Corollary 2, Y~ mutually independent A1 A2
X~ .

cn(Y~ )jX~ < cn(A1)jX~ then, Lemma 2, transposition Y~ A1 produces
ordering lower cost.
Otherwise, cn(Y~ )jX~ cn(A1)jX~ . Since pair hA1; A2i cn-inverted, cn(A1)jX~ >
cn(A2)jX~ . Hence, cn(Y~ )jX~ > cn(A2)jX~ , transposition Y~ A2 reduces
cost, Lemma 2.
either case, way reduce cost O~ . Therefore, O~ cannot minimal,
O~ N MC-contradicting.
2
4.4.2 Detection MC-Contradicting Orderings AND-nodes

Every member consistency set AND-node consistent combination
candidates child nodes. k child nodes, child Ni sizes
subgoal candidate sets jS (Ni)j = ni jCandSet(Ni)j = ci , total
number possible consistent orderings c1 c2 : : :ck (nn+!nn +!::::::+nnk !k )! . Fortunately,
orderings MC-contradicting discarded candidate set.
1

2

1

62

2

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

following lemma states forbidden insert subgoals two cn-inverted
sub-sequences. insertion takes place, ordering MC-contradicting
safely discarded.

Lemma 5
Let S0 set subgoals, N node divisibility tree S0 , O~ ordering
S0, binder-consistent ordering O~ N (N ).
O~ N contains adjacent cn-inverted pair sub-sequences hA~ 1 ; A~ 2i, A~ 1 A~ 2 appear

O~ mixed subgoals, A~ 1 A~ 2 adjacent O~ , O~
minimal.

Proof: Let O~ ordering S0, binder-consistent O~ N :
O~ = X~ kA~ 1kY~ kA~ 2kZ~ ;
Y~ empty. subgoal Y~ belongs (N ), since otherwise would stand
O~ N A~ 1 A~ 2 . O~ binder-consistent O~ N ; therefore, B(N ) X~ .
Corollary 2, Y~ must mutually independent A~ 1 A~ 2 X~ , Lemma 2
transposition Y~ either A~ 1 A~ 2 reduces cost { exactly proof
Lemma 4.
2

pair adjacent subgoals hAi ; Ai+1i cn-inverted, previous lemma
attempt insert subgoals inside results non-minimal global ordering. Thereupon
may join Ai Ai+1 block Ai;i+1 , participate larger block.
formal recursive definition block follows. convenience, consider separate
subgoals blocks length 1.

Definition:

1. sub-sequence A~ ordered sequence subgoals block either single
subgoal, A~ = A~ 1 kA~ 2, hA~ 1; A~ 2i cn-inverted pair blocks.
2. block maximal (max-block) sub-sequence larger block.
3. Let N node divisibility tree, descendant N , O~ N 2 (S (N ))
O~ 2 (S (M )) two consistent orderings nodes. block A~ O~
violated O~ N two adjacent subgoals A~ adjacent O~ N (in
words, alien subgoals inserted subgoals block).
4. Let N node, descendant, O~ N 2 (S (N )) O~ 2 (S (M )) two
consistent orderings nodes. O~ called projection O~ N .
shall usually speak projection ordering child node.
concept max-block similar maximal indivisible block introduced Simon
Kadane (1975) context satisficing search. following corollary presents
result Lemma 5 convenient way.

Corollary 3 Let N node divisibility tree, one children, O~ N

ordering N , O~ projection O~ N . O~ contains block
violated O~ N , O~ N MC-contradicting.
63

fiLedeniov & Markovitch

Proof: Let A~ smallest block O~ violated O~ N . According definition
block, A~ = A~ 1 kA~ 2 , A~ 1 A~ 2 violated O~ N , pair hA~ 1; A~ 2i

cn-inverted. Let O~ ordering root node binder-consistent O~ N . O~
violates A~ , since O~ N violates A~ . show O~ N MC-contradicting, must prove
O~ minimal.
A~1 A~ 2 violated O~ , adjacent O~ , O~
minimal, Lemma 5.
Otherwise, A~ 1 A~2 violated O~ . Without loss generality, let A~1. Let A~0
smallest sub-block A~ 1 violated O~ . According definition block,
A~ 0 = A~01 kA~ 02 , pair hA~ 01; A~ 02i cn-inverted, A~ 1 A~ 2 violated
adjacent O~ . Lemma 5, O~ minimal.
2
example, control values subgoals shown Figure 9, ha1(X ); a2(X )i
block, since cn(a1(X ))j; = 2,2 1 = 12 , cn(a2(X ))jfa1(X )g = 2,3 1 = 13 . one see
figure, insertion b inside block results non-minimal ordering.
already noted above, consistency set AND-node large.
many orderings, however, blocks projections violated, discard
orderings MC-contradicting. remaining orderings, block projection
violated, ordering represented sequence max-blocks
projections. projection, max-blocks stand cn-ascending order (otherwise,
adjacent cn-inverted pair blocks, larger block formed, contradicts
maximality). following lemma states, parent AND-node blocks
must ordered cn values; otherwise, ordering MC-contradicting.
Lemma 6 ordering AND-node contains adjacent cn-inverted pair maxblocks projections children, ordering MC-contradicting.
Proof: blocks violated binder-consistent global ordering, global
ordering minimal Corollary 3. blocks violated, proof similar
proof Lemma 4.
2
two sucient conditions detection MC-contradicting orderings expressed
Corollary 3 Lemma 6 allow us reduce size candidate set significantly.
Assume, example, set current node N split two mutually independent subsets whose candidates ha1; a2i hb1; b2i (one candidate child).
six possible orderings (N ), shown Figure 11. Assume ha1; a2i
hb1; b2i blocks, cn(ha1; a2i)jB(N ) < cn(hb1; b2i)jB(N ). six consistent orderings,
four (2{5) rejected due block violation, one remaining two (number 6)
puts blocks wrong order. So, one ordering (number 1) left candidate set N . Even neither ha1; a2i hb1; b2i blocks, Lemma 6 dictates unique
interleaving elements (max-blocks), assuming cn(a1 )jB(N ) 6= cn(a2 )jB(N )[fa g
6= cn(b1)jB(N ) 6= cn(b2)jB(N )[fb g.
1

1

4.4.3 Detection MC-Contradicting Orderings OR-nodes

following lemma states block cheaper permutation, ordering
MC-contradicting (and discarded candidate set).
64

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

1.

a1 a2

b1 b2

2.

a1 a2

b1 b2

3.

a1 a2

4.

b1 b2

a1 a2

b1 b2

5.

a1 a2

b1 b2

6.

a1 a2

b1 b2

Figure 11: possible ways combine ha1, a2 hb1, b2i

Lemma 7 Let N node divisibility tree S~0, O~ N 2 (S~(N )). Let A~ leading
block O~ N : O~ N = A~ kR~ . permutation A~ , A~ 0 , cost(A~ 0 )jB(N ) <
cost(A~ )jB(N ), O~ N MC-contradicting.
Proof: Let O~ 2 (S~0) binder-consistent O~ N . A~ violated O~ , O~ cannot

minimal (Corollary 3). Otherwise, A~ occupies continuous segment O~ ,
replacement cheaper permutation reduces cost global ordering (Lemma 1).
Thus, O~ cannot minimal.
2
check done leading blocks OR-nodes:

Every ordering leaf node rejected due Lemma 4 must

sorted cn. Consequently, contains cn-inverted adjacent pair subgoals,
block size 2 formed.

Every ordering AND-node rejected due Corollary 3
Lemma 6 must blocks unbroken cn-ascending order. Consequently,
new blocks cannot formed either.

OR-nodes, new blocks formed add binder first element
ordering, cn value binder greater subsequent block.
new blocks start binder, must perform permutation test
leading max-block ordering.

4.5 Detection MC-Equivalent Orderings

previous subsection presented sucient conditions detecting MC-contradicting
orderings. subsection specify sucient conditions identifying MC-equivalent
orderings. Recall two orderings node MC-equivalent minimal consistency
one implies minimal consistency other. Finding sucient conditions
allow us eliminate orderings without loss validity candidate set. start
defining specialization MC-equivalence relation: blockwise equivalence.
show orderings whose max-blocks sorted cn blockwise-equivalent,
therefore MC-equivalent.
65

fiLedeniov & Markovitch

Definition: Let S0 set subgoals N node divisibility tree S0. Let
O~ 1 O~ 2 two orderings (N ) equal number max-blocks. Let O~
ordering S0 , binder-consistent O~ 1, blocks O~ 1 violated.
O~ jOO~~ ordering obtained replacing O~ every max-block O~ 1 max2

block O~ 2, preserving order max-blocks (the i-th max-block O~ 1 replaced
i-th max-block O~ 2).
O~ 1 O~ 2 blockwise-equivalent following condition holds: O~ 1 min-consistent
O~ iff O~ 2 min-consistent O~ jOO~~ .
easily seen, two orderings blockwise-equivalent, MCequivalent. show transposition adjacent, mutually independent cn-equal
max-blocks ordering node produces blockwise-equivalent ordering. proof
following lemma found Appendix A.
1

2
1

Lemma 8
Let S0 set subgoals, N node divisibility tree S0, O~ N = Q~ kA~ 1 kA~ 2kR~
ordering (N ), A~ 1 A~ 2 max-blocks, mutually independent cn-equal
bindings B(N ) [ Q~ . O~ N blockwise-equivalent O~ N0 = Q~ kA~ 2 kA~ 1kR~ .
Corollary 4 sorted cn orderings leaf node blockwise-equivalent.
example, (N ) = fA; B; C; Dg, cn(A)jB(N ) = 0:1, cn(B )jB(N ) = cn(C )jB(N ) = 0:3,
cn(D)jB(N ) = 0:5, orderings hA; B; C; Di hA; C; B; Di blockwise-equivalent,
remove candidate set one (but both).

Corollary 5 orderings AND-node, blocks projections violated

adjacent max-blocks different children projections cn-ordered, blockwiseequivalent.

~ B;
~ C~ ; D~
example, candidates children A~ kB~ C~ kD~ , A;
max-blocks, cn(A~ )jB(N ) = 0:1, cn(B~ )jB(N )[A~ = cn(C~ )jB(N ) = 0:3 cn(D~ )jB(N )[C~ = 0:5,
orderings A~ kB~ kC~ kD~ A~ kC~ kB~ kD~ blockwise-equivalent, remove
candidate set one (but both).
prove Corollaries 4 5, note case one mentioned
orderings obtained finite number transpositions adjacent,
mutually independent cn-equal max-blocks. According Lemma 8, transposition yields blockwise-equivalent ordering. easy show blockwise equivalence
transitive.
following corollary states subgoals within block permuted, provided
cost block changed.

Corollary 6 orderings node, identical cost-preserving permutations subgoals inside blocks, blockwise-equivalent.

proof corollary follows immediately Lemma 1. example, set
fa(X ); b(X )g, control values first counter-example Proposition 1,
66

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Node Set
MC-contradicting
Leaf Independent Subgoals sorted cn
| Lemma 4
Contains violated blocks
Divisible
| Corollary 3
Max-blocks sorted cn
| Lemma 6
leading max-block
Indivisible cheaper permutation
| Lemma 7

blockwise-equivalent
Subgoals sorted cn
| Corollary 4
Max-blocks violated,
sorted cn
| Corollary 5
Cost-preserving permutations
blocks
| Corollary 6

Table 1: Summary sucient conditions detection MC-contradicting blockwiseequivalent orderings.

i.e. cn(a(X )j;) = cn(b(X )j;) = 12 , cn(a(X )jfb(X )g) = cn(b(X )jfa(X )g) = 0,
possible orderings, ha(X ); b(X )i hb(X ); a(X )i, two subgoals united block,
blocks equal cost. global ordering containing block ha(X ); b(X )i,
replace block hb(X ); a(X )i without changing total cost. Therefore
ha(X ); b(X )i blockwise-equivalent hb(X ); a(X )i.
sucient condition expressed Corollary 6 checked OR-nodes,
since leaves AND-nodes new blocks created, argued Section 4.4.3.

4.6 Revised Ordering Algorithm

two preceding subsections saw several sucient conditions MC-contradiction
MC-equivalence, summarized Table 1. results permit us close gaps
Algorithm 5 providing necessary validity filters. filter tests sucient
conditions MC-contradiction MC-equivalence every ordering consistency
set. sucient conditions hold, ordering rejected. formal listing
procedures shown Figure 12.
generate-and-test approach described served us well methodological
purposes, obviously practical computational limitations. example,
independent set size n, algorithm creates n! orderings, rejects n! , 1
keeps one. process takes O(n! n) time produces ordering
sorted cn. result could obtained O(n log n) time, single
sorting. So, instead uncontrolled creation orderings selective rejection, want
perform selective creation orderings. words, want revise algorithm
deal directly candidate sets, instead generating large consistency sets. revised
algorithm produces candidate set node N follows:
N leaf, subgoals (N ) sorted cn bindings B(N ),
produced ordering sole candidate N .
N AND-node, combination children's candidates candidate N created, max-blocks children's candidates ordered
67

fiLedeniov & Markovitch

ValidLeafFilter(ConsSetN )
let CandSetN ;
loop O~ N 2 ConsSetN

O~ N sorted cn
O~ N0 2 CandSetN sorted cn
CandSetN CandSetN [ fO~ N g
Return CandSetN

ValidANDFilter(ConsSetN ; fS1; : : : Sk g; fC1; : : : Ck g)
let CandSetN ;
loop O~ N 2 ConsSetN

loop = 1 k
let O~ projection O~ N Si
8i O~ 2 Ci
max-blocks O~ -s violated O~ N ,
max-blocks O~ -s ordered cn O~ N ,
O~ N0 2 CandSetN consistent O~ i-s,
CandSetN CandSetN [ fO~ N g
Return CandSetN

ValidORFilter(ConsSetN )
let CandSetN ;
loop O~ N 2 ConsSetN

O~ N start block cheaper permutation,
O~ N0 2 CandSetN , identical O~ N
cost-preserving permutations blocks,
CandSetN CandSetN [ fO~ N g
Return CandSetN

Figure 12: three filter procedures convert consistency set candidate set. Together
Algorithm 5, form complete ordering algorithm. eciency
algorithm improved, shall see Algorithm 6.

cn. candidate produced merging: moving parallel candidates
children extracting max-blocks minimal cn.

N OR-node, candidate child ordering N created
adding binder left end child candidate. results creation
block cheaper permutation, ordering rejected; otherwise,
added candidate set. suces check leading max-block.
68

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Note revised algorithm include test cost-preserving permutations
blocks different orderings (expressed Corollary 6), high expense
test.
revised algorithm described contains manipulations blocks. purpose, need easy ecient way detect blocks orderings. Since
permit block violation (by Corollary 3), unite subgoals max-block
one entity, treat ordinary subgoal. procedure joining subgoals
blocks called folding, resulting sequence max-blocks { folded sequence.
subgoals folded block, need unfold block back separate
subgoals: upper levels tree, subgoals joined block, unless
block violated. unfolding operation carried returning
cheapest ordering set (of root node). candidate sets nodes
defined sets folded orderings.
already stated, new blocks created candidates OR-nodes,
binder added first element ordering, cn value binder
greater cn value first max-block child projection. Therefore,
revised algorithm build new blocks start binder: max-blocks
rest ordering remain child's candidate. First try make block
binder first max-block child's candidate. cn-ordered,
stop folding. cn-inverted, unite larger block, try
unite second max-block child's candidate, on. produced
folded ordering contains maximal blocks: first block maximal, since could
expand right, blocks maximal, since maximal
child's candidate.
Lemma 7 states ordering whose leading max-block cheaper permutation
MC-contradicting. One way detect block exhaustively test permutations, computing comparing costs. procedure expensive. Instead,
revised algorithm employ adjacency restriction test (Equation 8). test
applied every pair adjacent subgoals block, adjacent pair cheaper
transposition, whole block cheaper permutation, Lemma 1. Since blocks
created concatenation smaller blocks, suces test adjacency restriction
points blocks joined (for adjacent pairs subgoals, tests
performed lower levels, smaller blocks formed). adjacency restriction test guarantee detection not-cheapest permutations (as shown
Example 3), detects blocks many cases, works linear time.
final version dac subgoal ordering algorithm presented Figure 13.
complete correctness proof Algorithm 6 found Appendix B.

4.7 Sample Run Comparison Ordering Algorithms
illustrate work dac algorithm, using subgoal set shown Figure 8,
S0 = fa; b; c(X ); d(X ); e(X )g. proving c(X ), d(X ) e(X ), assume X
bound. Let control values subgoals shown Table 2. column c(free)
contains control values subgoal c(X ) X yet bound preceding
subgoals (i.e., binding set contain d(X ) e(X )). column c(bound)
69

fiLedeniov & Markovitch

Algorithm 6 : Divide-and-Conquer Algorithm
Order(S0)
let RootCandSet CandidateSet(S0 ; ;)
Return Unfold(the cheapest element RootCandSet)
CandidateSet(S ; B)
let fS1; S2; : : : Sk g DPart(S ; B)
case

k = 1, shared-vars(S1) = ; (S independent B):
Return fSort-by-cn(S ; B)g
k = 1, shared-vars(S1) =6 ; (S indivisible B):
loop 2
let C (A) CandidateSet
(S fin fAg; B [ fAog)
n
0
~
let C (A)
Fold
(AkOA ; B) fifi O~ 2 C (A)

Return A2S C 0(A)
k > 1 (S divisible B):
loop = 1 k
let Cin CandidateSet(Si ; B)
Return Merge(fO~ 1; O~ 2; : : : O~ k g; B)

fifi

O~ 1 2 C1; O~ 2 2 C2; : : : O~ k 2 Ck

Merge(fO~ 1; O~ 2; : : : O~ k g; B)

let min-cn-candidate O~ minimizes cn(first-max-block(O~ ))jB , 1 k
let min-cn-block first-max-block(min-cn-candidate)
remove-first-max-block(min-cn-candidate)
Return min-cn-blockkMerge(fO~ 1; O~ 2; : : : O~ k g; B [ min-cn-block)

Fold(hA1; A2 : : :Ak i; B)
k 1 cn(A1)jB cn(A2)jBkA
Return hA1; A2 : : :Ak

1

else
last subgoal A1 first subgoal A2 satisfy adjacency restriction

let A0 block(A1 ; A2)
Return Fold(hA0 ; A3 : : :Ak i; B)
else Return ;

Figure 13: revised version dac algorithm. candidate sets built selectively,

without explicit creation consistency sets. Candidate sets contain folded orderings,
unfolding performed returned global ordering. code
Unfold Sort-by-cn procedures listed, due straightforwardness.
merging procedure recursively extracts given folded orderings max-blocks
minimal cn. folding procedure joins two leading blocks larger one,
long cn-inverted.
70

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm


b c(free) c(bound) d(free) d(bound) e(free) e(bound)
cost
10 5
5
5
10
5
20
10
nsols 0.8 2
2
0.5
4
1
0.4
0.1
cn
-0.02 0.2 0.2
-0.1
0.3
0
-0.03
-0.09
Table 2: Control values sample runs ordering algorithms.
contains cost values c(X ) d(X ) e(X ) already bound X . example,
cost(c(X ))jfa;d(X )g = cost(c(bound)) = 5. dac algorithm traverses divisibility tree
S0 follows. (The names nodes Figure 8.)
1. root divisibility tree, n1, empty binding set B(n1) = ;,
associated subgoal set (n1) = fa; b; c(X ); d(X ); e(X )g. set (n1) partitioned two subsets B(n1): one independent { fa; bg, one indivisible {
fc(X ); d(X ); e(X )g. two subsets correspond two child nodes ANDnode n1: n2 n3, empty binding sets.
2. (n2) independent B(n2). Therefore, n2 leaf, sole candidate
ordering obtained sorting subgoals cn B(n2). cn(a)j; = ,0:02,
cn(b)j; = 0:2, thus CandSet(n2) = fha; big.
3. (n3) indivisible B(n3). Therefore, n3 OR-node, three children
created { one subgoal (n3) serving binder.

Binder c(X ) yields child node n4 associated set (n4) = fd(X ); e(X )g
binding set B(n4) = fc(X )g. (n4) independent B(n4). There-

fore, n4 leaf, sole candidate obtained sorting subgoals
cn:
cn(d(X ))jfc(X)g = 0; cn(e(X ))jfc(X )g = ,0:09;
thus, candidate n4 he(X ); d(X )i.
Binder d(X ) yields child node n5 associated set (n5) = fc(X ); e(X )g
binding set B(n5) = fd(X )g. (n5) independent B(n5),
sorting cn produces candidate hc(X ); e(X )i.
Binder e(X ) yields child node n6 associated set (n6) = fc(X ); d(X )g
binding set B(n6) = fe(X )g. (n6) independent B(n6),
sorting cn produces candidate hc(X ); d(X )i.
4. add binder corresponding child's candidate obtain three orderings OR-node n3: hc(X ); e(X ); d(X )i, hd(X ); c(X ); e(X )i, he(X ); c(X ); d(X )i.
5. perform folding orderings check violations adjacency
restriction, order determine whether block cheaper permutation.
71

fiLedeniov & Markovitch

First, perform folding hc(X ); e(X ); d(X )i. pair hc(X ); e(X )i
cn-inverted: cn(c(X ))j; = 0:2, cn(e(X ))jfc(X )g = ,0:09. thus unite
block. block pass adjacency restriction test (Equation 8):
cost(hc(X ); e(X )i)j; = 5 + 2 10 = 25;
cost(he(X ); c(X )i)j; = 20 + 0:4 5 = 22:

Therefore, ordering MC-contradicting discarded.
perform folding hd(X ); c(X ); e(X )i. cn(d(X ))j; = 0:3, cn(c(X ))jfd(X )g =
,0:1, pair cn-inverted, unite block. block
pass adjacency restriction test:
cost(hd(X ); c(X )i)j; = 10 + 4 5 = 30;
cost(hc(X ); d(X )i)j; = 5 + 2 5 = 15:

ordering rejected too, even folding finished. continue
folding process, shall see subgoal e(X ) must added
block, since cn(hd(X ); c(X )i)j; = 4030:5,1 = 0:0333, cn(e(X ))jhd(X );c(X )i =
,0:09.
perform folding he(X ); c(X ); d(X )i. cn(e(X ))j; = ,0:03, cn(c(X ))jfe(X)g
= ,0:1, pair cn-inverted, form block ec(X ) = he(X ); c(X )i,
passes adjacency restriction test:
cost(he(X ); c(X )i)j; = 20 + 0:4 5 = 22;
cost(hc(X ); e(X )i)j; = 5 + 2 10 = 25:

compute control values new block:
cost(ec(X ))j; = 20 + 0:4 5 = 22
nsols(ec(X ))j; = 0:4 0:5 = 0:2
cn(ec(X ))j; = 0:222, 1 = ,0:0363636
cn(d(X ))jfec(X )g = 0, thus pair hec(X ); d(X )i cn-ordered, folding
needed, add folded candidate hec(X ); d(X )i candidate set
n3.

6. perform merging candidate set n2, fha; big, candidate set
n3, fhec(X ); d(X )ig. resulting sequence max-blocks must sorted cn.

cn(a) = ,0:02; cn(b) = 0:2; cn(ec(X ))j; = ,0:0363636; cn(d(X ))jfec(X )g = 0:
merged ordering, hec(X ); a; d(X ); bi, added candidate set n1.
7. compare costs candidates n1, output cheapest one. case,
one candidate, hec(X ); a; d(X ); bi. algorithm returns candidate
unfolded, he(X ); c(X ); a; d(X ); bi.
72

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Extension/Completion
Cost
h ai
10
hbi
5
hc(X )i
5
hd(X )i
10
he(X )i
20
hbi
hb; ai
adjacency restriction test fails
hb; c(X )i
5 + 2 5 = 15
hb; d(X )i
5 + 2 10 = 25
hb; e(X )i
adjacency restriction test fails
hc(X )i
hc(X ); e(X ); a; d(X ); bi
5 + 2(10 + 0:1(10 + 0:8(5 + 1 5))) = 28:6
hai
ha; bi
10 + 0:8 5 = 14
ha; c(X )i
10 + 0:8 5 = 14
ha; d(X )i
10 + 0:8 10 = 18
ha; e(X )i
adjacency restriction test fails
hd(X )i
hd(X ); c(X ); e(X ); a; bi 10 + 4(5 + 0:5(10 + 0:1(10 + 0:8 5))) = 52:8
ha; bi
ha; b; c(X )i
14 + 0:8 2 5 = 22
ha; b; d(X )i
14 + 0:8 2 10 = 30
ha; b; e(X )i
adjacency restriction test fails
ha; c(X )i
ha; c(X ); e(X ); d(X ); bi
14 + 0:8 2(10 + 0:1(5 + 1 5)) = 31:6
hb; c(X )i
hb; c(X ); e(X ); a; d(X )i
15 + 2 2(10 + 0:1(10 + 0:8 5)) = 60:6
ha; d(X )i
ha; d(X ); c(X ); e(X ); bi
18 + 0:8 4(5 + 0:5(10 + 0:1 5)) = 50:8
he(X )i
he(X ); c(X ); a; d(X ); bi 20 + 0:4(5 + 0:5(10 + 0:8(5 + 1 5))) = 25:6
ha; b; c(X )i
ha; b; c(X ); e(X ); d(X )i
22 + 0:8 2 2(10 + 0:1 5) = 55:6
hb; d(X )i
hb; d(X ); c(X ); e(X ); ai
25 + 2 4(5 + 0:5(10 + 0:1 10)) = 109
he(X ); c(X ); a; d(X ); bi complete ordering

;

Cheapest prefix

Table 3: trace sample run Algorithm 4 set Figure 8. left column shows
cheapest prefix extracted list step, middle column { extensions
completions added list, right column { associated costs.

comparison, show task performed Algorithm 4.
algorithm maintains list prefixes, sorted cost values, initially contains
empty sequence. step algorithm extracts list cheapest element,
adds list extensions completions prefix. Extensions created
set remaining subgoals dependent, appending remaining subgoals
end prefix. Completions created set remaining subgoals
independent, sorting appending entire resulting sequence prefix.
extension added list adjacency restriction test succeeds two
last subgoals. make list operations faster, implement heap structure
(Cormen et al., 1991).
trace Algorithm 4 set S0 shown Table 3. left column shows
cheapest prefix extracted list step, middle column { extensions
completions added list, right column { associated costs.
looks dac algorithm orders given set S0 eciently Algorithm 4.
compare several discrete measurements show this. example, Algorithm 6
73

fiLedeniov & Markovitch

p2(X2,X5,X7,X9)
p1(X1,X2,X3,X4)
p5(X4,X8,X9,X10)
p3(X1,X5,X6,X8)
p4(X6,X3,X7,X10)

Figure 14: example worst case ordering. variables initially free, every

subset subgoals indivisible binding rest subgoals, overall
complexity ordering Algorithm 6 O(n!).

performs 4 sorting sessions, one 2 elements, Algorithm 4 performs 5 sortings
2 elements, 3 sortings 3 elements. adjacency restriction tested 3
times Algorithm 6, 11 times Algorithm 4. Algorithm 6 creates totally 8 different
ordered sub-sequences, total length 22, Algorithm 4 creates 24 ordered prefixes,
total length 55.

4.8 Complexity Analysis

Algorithm 4 Algorithm 6 find minimal ordering, sort independent
subsets subgoals whenever possible. Algorithm 6, however, offers several advantages due
divide-and-conquer strategy.
Let n number subgoals initial set. convenience, assume
time computing control values one subgoal O(1); otherwise, time
, complexities must multiplied . worst case complexity
Algorithm 6 O(n!). Figure 14 shows example case n = 5. set
every two subgoals share variable appear subgoals. Thus,
subgoals cannot bind it. set root indivisible, matter binder
chosen, sets children indivisible. So, child root, must select
every remaining subgoal binder, on. overall complexity execution
O(n!). indeed worst-case complexity: presence AND-nodes tree
reduce it.
Note even n small, complex rule body (n2 ) free variables
improbable practical programs. Also, worst-case complexity reduced
O(n2 2n ), move divisibility trees divisibility graphs (DAGs),
identical nodes divisibility tree (same subgoal set, binding set) represented
single vertex. equivalence test tree nodes performed eciently
help trie structures (Aho et al., 1987), subgoals sorted lexicographically.
Let n subgoals, v shared variables appearing subgoals.
already noted Section 4.3, partition subgoals subsets performed
74

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

O(n) average time, using Union-Find data structure (Cormen et al., 1991, Chapter 22).

worst possible case, AND-nodes divisibility tree, apart
root node (whose set divisible dependent set size independent set
size n , m). overall complexity dac algorithm case
(n; m; v ) = O(n)
| divisibility partition
+ O((nQ, m) log(n , m))
| ordering independent subgoals
k
+ O(( i=0
ordering dependent subgoals
Q (,m1(,mi)), i))log(m , k)) |
+ O(m Q ki=0
| folding
,1 (m , i))
+ O(n ki=0
| merging
k maximal possible number bindings performed remaining subset
independent. assume every subgoal binds free variables (which happens
frequently practical logic programs), k = minfv; , 1g; otherwise k = , 1.
k equal maximal number OR-nodes path root leaf
divisibility tree. Therefore, height divisibility tree limited k + 1. Actually,
tree shallower, since binders bind one shared variable each.
means number shared variables decrease 1 ORnode. simplify formula several common cases, k small
abovementioned assumption holds (every subgoal binds free variables
proof terminates).
v < n: (n; m; v) = O(n mv + n log n)
v n: (n; m; v) = O(n mm,1 + n log n)
v ' n: (n; m; v) = O(nv+1 log n)
v ' n: (n; m; v) = O(n m! + n log n)
Generally, small number v shared variables, complexity algorithm
roughly bounded O(nv+1 log n). particular, subgoals independent (v = 0),
complexity O(n log n). practical cases, number shared free variables
rule body relatively small, every subgoal binds free variables; therefore,
algorithm polynomial complexity. Note even rule body program
text contains many free variables, usually become bound rule head
unification performed (i.e., start ordering instantiated body).

5. Learning Control Knowledge Ordering

ordering algorithms described previous sections assume availability correct
values average cost number solutions various predicates various argument
bindings. section discuss control knowledge obtained learning.
Instead static exploration program text (Debray & Lin, 1993; Etzioni, 1993),
adopt approach Markovitch Scott (1989) learn control knowledge
collecting statistics literals proved past. learning
performed on-line off-line. latter case, ordering system first works
training set queries, collecting statistics. training set built
75

fiLedeniov & Markovitch

distribution user queries seen past. assume distribution queries
received system change significantly time; hence, past distribution
directs system learn relevant knowledge future queries.
proving queries, learning component accumulates information control values (average cost number solutions) various literals. Storing separate
value literal practical, two reasons. first large space required
approach. second lack generalization: ordering algorithm quite
likely encounter literals seen before, whose control values
unknown. Recall transformed Equation 2 Equation 5, moved
control values single literals average control values sets literals. obtain
precise averages sets, still needed control values individual literals. Here,
take different approach, learning using control values general
classes literals. estimated cost (nsols) value class defined average
real cost (nsols) value examples class proved past.
refined classes, smaller variance real control values inside
class, precise cost nsols estimations classes assign members, better orderings obtain. One easy way define classes modes
binding patterns (Debray & Warren, 1988; Ullman & Vardi, 1988): argument denote whether free bound. example, predicate father
possible classes father(free,free), father(bound,free), father(free,bound)
father(bound,bound). Now, receive literal (for example, father(abraham,X)),
easily determine binding pattern (in case, father(bound,free)) retrieve control information stored class. course, find binding pattern
subgoal given binding set, need method determine variables
bound subgoals binding set. problem arose DPart computation
(Section 4.3). shall discuss practical ways solve problem Section 7.1.
purpose class definition use regression trees { type decision tree
classifies continuous numeric values discrete classes (Breiman et al., 1984;
Quinlan, 1986). Two separate regression trees stored every program predicate,
one cost values, one nsols. tests tree nodes defined
various ways. use test \is argument bound?", classes literals
defined regression trees coincide classes defined binding patterns.
apply sophisticated tests, syntactic (e.g., \is third argument term
functor f?") semantic (e.g., \is third argument female?"), leads
refined classes better estimations. possible regression tree estimating
number solutions predicate father shown Figure 15.
Semantic tests arguments require logic inference (in example Figure 15
{ invoking predicate female first argument literal). Therefore, must
ecient possible. Otherwise retrieval control values take much time.
problem ecient learning control values considered elsewhere (Ledeniov
& Markovitch, 1998a).
Several researchers applied machine learning techniques accelerating logic inference
(Cohen, 1990; Dejong & Mooney, 1986; Langley, 1985; Markovitch & Scott, 1993; Minton,
1988; Mitchell, Keller, & Kedar-Cabelli, 1986; Mooney & Zelle, 1993; Prieditis & Mostow,
1987). works used explanation-based learning generalized caching tech76

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Average: 3.1416
Test: bound(arg1)?

yes



Average: 0.3
Test: female(arg1)?

yes
Average: 0.0

Average: 5
Test: bound(arg2)?



yes

Average: 0.5
Test: bound(arg2)?

Average: 0.98

yes



Average: 0.0001

Average: 1.0


Average: 50

Figure 15: regression tree estimates number solutions father(arg1,arg2).
niques avoid repeated computation. Others utilized acquired knowledge problem clause selection. None works, however, dealt problem subgoal
reordering.

6. Experimentation
test effectiveness ordering algorithm, experimented various
domains, compared performance ordering algorithms. experiments
performed randomly created artificial domains. tested performance
system several real domains.

6.1 Experimental Methodology
experiments described consist training session, followed testing session.
Training testing sets queries randomly drawn fixed distribution.
training session collect control knowledge literal classes. testing session
prove queries testing set using different ordering algorithms, compare
performance using various measurements.
goal ordering reduce time spent Prolog interpreter
proves queries testing set. time sum time spent ordering
procedure (ordering time) time spent interpreter (inference time). Since
CPU time known sensitive irrelevant factors hardware, software
programming quality, show two alternative discrete measurements: total
number clause unifications, total number clause reductions performed.
number reductions ects size proof tree.
experimentation used new version lassy system (Markovitch & Scott,
1989), using regression trees learning, ordering algorithms discussed
paper.
77

fiLedeniov & Markovitch

6.2 Experiments Artificial Domains

order ensure statistical significance results comparing different ordering
algorithms, experimented many different domains. purpose, created
set 100 artificial domains, small fixed set predicates, random
number clauses predicate, random rule lengths. Predicates
rule bodies, arguments rule heads bodies randomly drawn fixed
distributions. domain training testing sets (these two sets
intersect).
training examples fed system learning phase, better
estimations control values produces. hand, learning time must limited, seeing certain number training examples, new examples bring
much new information, additional learning becomes wasteful. experimentally
built learning curve shows dependence quality control knowledge
amount training. curve suggests control values learned
approximately 400 literals, significant improvement quality ordering
new training examples. Therefore, subsequent experiments stopped training
600 cost values learned. training time always small: one learned cost
value corresponds complete proof literal. Thus, every predicate program
four clauses define it, 600 cost values learned 2400 unifications,
small time.
control values learned means regression trees (Section 5), simple
syntactic tests checked whether argument bound whether argument term certain functor (the list functors created automatically
domain loaded). However, shall see, even simple tests succeeded
making good estimations control values.
tested following ordering methods:
Random: subgoals permuted randomly control knowledge
used.
Algorithm 3: Building ordered prefixes. prefixes permutation
one another, cheapest one retained.
Algorithm 3a: Algorithm 3, best-first search method used define
next processed prefix. similar algorithm used lassy system Markovitch
Scott (1989).
Algorithm 3b: Algorithm 3a, adjacency restriction test added.
similar algorithm described Smith Genesereth (1985).
Algorithm 4: Algorithm 3b, whenever subgoals
prefix independent (under binding prefix), sorted result
appended prefix one unit.
Algorithm 6: dac algorithm.
experiments always used Bubble-Sort algorithm sort literals independent sets. algorithm easy implement, known ecient small
78

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Ordering
Method
Random
Algorithm 3
Algorithm 3.a
Algorithm 3.b
Algorithm 4
Algorithm 6

Unifications Reductions Ordering Inference Total Ord.Time
Time
Time Time Reductions
86052.06
27741.52
8.1910
27.385 35.576 0.00029
2600.32
911.04 504.648
1.208 505.856 0.55
2829.00
978.59 347.313
1.178 348.491 0.35
2525.34
881.12 203.497
1.137 204.634 0.23
2822.27
976.02
40.284
1.191 41.475 0.04
2623.82
914.67
2.3620
1.102 3.464 0.0025

Table 4: effect ordering tree sizes CPU time (mean results 100 artificial
domains).

sets, elements already ordered, nearly ordered. practice, programmers
order program rules optimally, sorting stops early.
Since non-deterministic nature random method introduces additional noise,
performed artificial domain 20 experiments method, table
presents average values measurements.
Table 4 shows obtained results 100 domains: rows correspond ordering
methods used, columns measurements taken. rightmost column shows
ratio ordering time number reductions performed, ects
average ordering time one rule body. inference time measured separately,
set difference total time ordering time.
Several observations made:
1. Using dac ordering algorithm helps reduce total time proving testing
set queries factor 10, compared random ordering. inference time
reduced factor 25.
2. deterministic ordering methods similar number unifications reductions,
similar inference time, predictable, since find minimal orderings.
Small uctuations values explained fact rules
several minimal orderings existing control knowledge, different ordering
algorithms select different minimal orderings. Since control knowledge
absolutely precise, real execution costs orderings may different,
leads differences. random ordering method builds much larger trees,
larger inference time.
3. compare performance deterministic algorithms (3 { 6), see
dac algorithm performs much better algorithms build ordered
prefixes. latter ones, ordering expensive, smaller inference time
cannot compensate increase ordering time. Algorithm 4, combination
several ideas previous researchers, total time comparable time
random method (though still greater).
79

fiLedeniov & Markovitch

4. may seem strange simple random ordering method larger ordering time
sophisticated Algorithm 6. explain this, note random method
creates much larger proof trees (on average), therefore number ordered rules
increases, even cheap operations, random ordering rule, sum
considerable time. average time spent ordering one rule shown
last column Table 4; value small random method.

6.3 Experiments Real Domains

tested ordering algorithm real domains obtained various sources.
domains allow us compare orderings performed algorithm orderings performed human programmers.
following domains used:
Moral-reasoner: Taken Machine Learning Repository University
California, Irvine1 . domain qualitatively simulates moral reasoning: whether
person considered guilty, given various aspects character
crime performed.
Depth-first planner: Program 14.11 book \The Art Prolog" (Sterling
& Shapiro, 1994). program implements simple planner blocks world.
Biblical Family Database: database similar described Example 1.
Appletalk: domain describing physical layout local computer network
(Markovitch, 1989).
Benchmark: Prolog benchmark taken CMU Artificial Intelligence Repository2. predicate names informative: example program
manual ordering dicult.
Slow reverse: Another benchmark program source.
Geography: benchmark program CMU Repository. domain
contains many geographical facts countries.
Table 5 shows results obtained. ordering used dac algorithm, literal
classes defined binding patterns. seen dac algorithm able speed
logic inference real domains well. Note Slow Reverse domain
programmer's ordering already optimal; thus, applying ordering algorithm
reduce tree sizes. Still, overhead ordering significant.

7. Discussion

concluding section discuss several issues concerning practical implementation
dac algorithm several ways increase eciency. survey
related areas logic programming propose use dac algorithm there.
1. URL: http://www.ics.uci.edu/~mlearn/MLRepository.html
2. URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/ai-repository/ai/html/air.html

80

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Domain

Without ordering
ordering
Gain ratio
unifications seconds unifications seconds (time/time)
Moral-reasoner
352180 98.39
87020 23.53
4.2
Depth-first planner
10225 19.01
9927 18.16
1.05
Biblical Family
347827 112.68
120701 46.08
2.5
Appletalk
5036167 1246.30
640092 221.73
5.6
Benchmark
62012 554.31
46012 395.04
1.4
Slow reverse
6291 10.33
6291 11.92
0.9
Geography
428480 141.47
226628 82.76
1.7
Table 5: Experiments real domains.

7.1 Practical Issues

subsection would address several issues related implementation
applications dac algorithm.
computation DPart function (Section 3.2.1) requires procedure computing set variables bound given binding set subgoals. procedure
needed computing control values (Section 5). several possible ways
implement procedure. example:
1. easiest way assume every subgoal binds variables appearing
arguments. simplistic assumption sucient many domains, especially
database-oriented ones. However, appropriate logic programs used
manipulate complex data structures containing free variables (such difference
lists). assumption used experiments described Section 6.
2. dialects Prolog logic languages support mode declarations provided
user (Somogyi et al., 1996b). declarations available, easy
infer binding status variable upon exiting subgoal.
3. Even user supply enough mode declarations, often
inferred structure program means static analysis (Debray &
Warren, 1988). Note, however, pointed Somogyi et al. (1996b),
no-one yet demonstrated mode inference algorithm guaranteed find
accurate mode information every predicate program.
4. learn sets variables bound classes subgoals using methods similar
described Section 5 learning control values.
Several researchers advocate user declarations available (permitted) modes.
declarations elegantly incorporated algorithm prune branches violate
available modes. fix binder OR-node, compute set variables
become bound it. results violation available mode one
subgoals corresponding child, whole subtree child pruned. Note
detect violations even mode subgoal partially unknown
81

fiLedeniov & Markovitch

CandidateSet(S ; B)
let fS1; S2; : : : Sk g DPart(S ; B)
case

:::
k = 1, shared-vars(S1) 6= ; (S indivisible B):
loop 2
B [ fAg violate available modes
subgoal n fAg

let C (A) CandidateSet
(S fin fAg; B [ fAog)
n
0
let C (A)
Fold(AkO~ A; B) fifi O~ 2 C (A)
else let
C 0(A) ; (don't enter branch)

Return A2S C 0 (A)

Figure 16: Changes Algorithm 6 make use available mode declarations.
rest algorithm remains unchanged.

moment. example, available modes require first argument
unbound, binding argument OR-node binder trigger pruning,
even binding status arguments yet known. Figure 16 shows
Algorithm 6 changed order incorporate declarations available modes.
correctness requirement treated similar manner: candidate ordering
rejected whenever see violates requirement.
experiments described Section 6 performed Prolog interpreter.
possible combine dac algorithm Prolog compiler? several ways
achieve goal. One way allow compiler insert code on-line learning.
compiled code contain procedures accumulating control values dac
algorithm. Alternatively, off-line learning implemented, training part
compilation process.
Another method combining algorithm existing Prolog compilers use
program transformation, process transformed program standard
compiler. Elsewhere (Ledeniov & Markovitch, 1998a) describe method classifying
orderings produced dac algorithm. rule build classification tree,
classes different orderings rule body, tests applied
rule head arguments. type tests described Section 5 learning
control values. Figure 17 shows two examples trees.
Given classification tree, write set Prolog rules, rule
head original rule, body built tests path
tree root leaf node followed ordering leaf. example, second
tree Figure 17 yields following set rules:
82

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

classification tree rule
uncle(X,Y) Example 1.

nonvar(Y) ?
yes



[parent(Z,Y),brother(Z,X)]
[brother(Z,X),parent(Z,Y)]
nonvar(X) ?
yes

possible classification tree rule
head(X,Y)

male(X) ?

p1(X), p2(Y), p3(X,Y).

yes
[p1(X),p3(X,Y),p2(Y)]



nonvar(Y) ?



yes



[p2(Y),p3(X,Y),p1(X)]

[p1(X),p2(Y),p3(X,Y)]

[p3(X,Y),p1(X),p2(Y)]

Figure 17: Examples classification trees learn rule body orderings.

head(X,Y)
head(X,Y)
head(X,Y)
head(X,Y)

nonvar(X), male(X), p1(X), p3(X,Y), p2(Y).
nonvar(X), not(male(X)), p1(X), p2(Y), p3(X,Y).
var(X), nonvar(Y), p2(Y), p3(X,Y), p1(X).
var(X), var(Y), p3(X,Y), p1(X), p2(Y).

Table 4 see dac algorithm helped reduce inference
time factor 25, total time reduced factor 10. difference
caused additional computation ordering procedure. danger
benefit obtained ordering outweighed cost ordering process.
manifestation so-called utility problem (Minton, 1988; Markovitch & Scott,
1993). systems strongly-moded (such Mercury { Somogyi et al., 1996b)
employ dac algorithm statically compilation time one available modes,
thus reducing run-time ordering time zero. mode-based approach performs
syntactic tests subgoal arguments. classification tree method, described above,
generalization mode-based approach, allowing semantic tests well.
Due insucient learning experience lack meaningful semantic tests, quite
possible classification trees contain leaves large degrees error. cases
still need perform ordering dynamically. reduce harmfulness utility
problem case dynamic ordering, use cost-sensitive variation dac
algorithm (Ledeniov & Markovitch, 1998a, 1998b). modified algorithm deals
problem explicit reasoning economy control process. algorithm
anytime, is, stopped moment return currently best ordering
(Boddy & Dean, 1989). learn resource-investment function compute expected
return speedup time additional control time. function used determine
stopping condition anytime procedure. implemented framework
found indeed succeeded reducing ordering time, without significant increase
inference time.
83

fiLedeniov & Markovitch

7.2 Relationship Works

work described paper continuation line research initiated Smith
Genesereth (1985) continued Natarajan (1987) Markovitch Scott (1989).
line research aims finding ecient ordering set subgoals.
search minimal-cost ordering based cost analysis utilizes available information
cost number-of-solutions individual subgoals.
Smith Genesereth (1985) performed exhaustive search space
permutations given set subgoals, using adjacency restriction reduce
size search space (Equation 8). restriction applied pairs adjacent
subgoals global ordering entire set. applied independent set
subgoals, adjacency restriction easily transformed sorting restriction:
subgoals minimal ordering must sorted cn values. Natarajan (1987) arrived
conclusion presented ecient ordering algorithm independent sets.
dac algorithm uses subgoal dependence break set smaller subsets. Independent subsets sorted. Dependent subsets recursively ordered, resulting
orderings merged using generalization adjacency restriction manipulates
blocks subgoals. Therefore dac algorithm generalization algorithms.
last decade, significant research effort went static analysis (SA)
logic programs. three types SA exploited dac algorithm
reduce ordering time.
major part SA research deals program termination (De Schreye & Decorte,
1994). dac algorithm solves termination problem, special case eciency
problem (it always finds terminating ordering, orderings exist). learning,
set limits computation resources available subgoal execution. subgoal
non-terminating (in certain mode), learning module associate high cost
particular mode. Consequently, dac algorithm allow orderings
mode subgoal. Nevertheless, use static termination analysis
mandatory proper operation dac algorithm, exploit analysis
increase eciency learning process ordering process.
learning, limit set computation resources devoted execution
subgoal must high, increase reliability cost estimation. However,
high limit lead significant increase learning time many subgoals
non-terminating. termination information obtained SA available, use
avoid entering infinite branches proof trees. ordering, termination information
serve reduce size space orderings searched algorithm. termination
information comes form allowed modes (Somogyi et al., 1996b), orderings
violate modes filtered out, modified algorithm shown Figure 16.
termination information comes form partial order subgoals, orderings
violate partial order filtered similar manner.
second type SA research combined dac algorithm correctness analysis, program tested specifications given user.
folon environment (Henrard & Le Charlier, 1992) designed support
methodology logic program construction aims reconciling declarative semantics ecient implementation (Deville, 1990). construction process starts
84

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

specification, converts logic description finally, Prolog program.
rules program correct respect initial specification, system performs transformations reordering literals clause, adding type checking
literals on. De Boeck Le Charlier (1990) mention reordering,
specify ordering algorithm different simple generate-and-test method. Cortesi,
Le Charlier, Rossi (1997) present analyzer verifying correctness Prolog
program relative specification provides list input/output annotations
arguments parameters used establish program termination. Again,
ordering algorithm given explicitly. purpose dac algorithm complementary
purpose folon, could serve auxiliary aid make resulting Prolog
program ecient.
Recently, Mercury language developed University Melbourne (Somogyi
et al., 1996a, 1996b). Mercury strongly typed strongly moded language. Type
mode declarations supplied programmer (though recent releases
Mercury system already support partial inference types modes { Somogyi et al.,
1996a). compiler checks mode declarations predicates satisfied;
necessary, reorders subgoals rule body ensure mode correctness (and rejects
program neither ordering satisfies mode declaration constraints). compiler
performs reordering, consider eciency issue. often happens
several orderings rule body satisfy mode declaration constraints: cases
Mercury compiler could call static version dac algorithm select
ecient ordering. Another alternative augment dac algorithm mode declaration
checks, shown Figure 16.
Note Mercury purely declarative logic programming language, therefore
suitable subgoal reordering Prolog. non-logical constructs
could destroy declarative semantics give logic programs power; Mercury
even I/O declarative.
third type relevant SA cost analysis logic programs (Debray & Lin,
1993; Braem et al., 1994; Debray et al., 1997). Cortesi et al. (1997) describe cost formula
similar Equation 5 select lowest-cost ordering. However, used generate-andtest approach sometimes prohibitively expensive. Static analysis cost
number solutions used obtain control values, instead learning them.
eciency logic programs increased methods program transformation (Pettorossi & Proietti, 1994, 1996). One popular approaches
\rules+strategies" approach, consists starting initial program
applying one elementary transformation rules. Transformation strategies metarules prescribe suitable sequences applications transformation rules.
One possible transformation rules goal rearrangement rule transforms
program transposing two adjacent subgoals rule body. Obviously, ordering
rule body transformed ordering finite number
transpositions. Thus, static subgoal ordering considered special case program
transformation goal rearrangement rule used. hand, dynamic
semi-dynamic ordering methods cannot represented simple transformation rules,
since make use run-time information (expressed bindings rule body subgoals
85

fiLedeniov & Markovitch

obtain unifications rule heads), may order rule body differently
different circumstances.
program transformation technique called compiling control (Bruynooghe, De Schreye,
& Krekels, 1989; Pettorossi & Proietti, 1994) follows approach different
trying improve control strategy logic programs. Instead enhancing naive
Prolog evaluator using better (and often complex) computation rule, program
transformed derived program behaves naive evaluator exactly
initial program would behave enhanced evaluator. forms compiling control
first translate initial program standard representation (for example,
unfolding tree), complex computation rule used, new program
constructed representation, naive computation rule mind.
Reordering rule body subgoals regarded moving complex computation
rule selects subgoals order dictated ordering algorithm. case
dac algorithm, computation rule may complex simple use compiling
control methods. Nevertheless, easily incorporated special compiling control
method. Section 7.1 described method program rewriting first builds
classification trees based orderings performed past, uses
classification trees constructing clauses derived program. derived program
eciently executed naive computation rule Prolog. technique
fact kind compiling control. important property use knowledge collected
experience (the orderings made past).
One transformation method significantly benefit dac algorithm
unfolding (Tamaki & Sato, 1984). unfolding process subgoals replaced
associated rule bodies. Even initial rules ordered optimally human
programmer static ordering procedure, resulting combined sequence may far
optimal. Therefore could advantageous use dac algorithm reordering
unfolded rule. rules become longer, potential benefit ordering grows.
danger high complexity ordering procedure overcome using
cost-sensitive version dac algorithm (Section 7.1).

7.3 Conclusions
work study problem subgoal ordering logic programs. present
theoretical base practical implementation ideas, show empirical results
confirm theoretical predictions. combine ideas Smith Genesereth (1985),
Simon Kadane (1975) Natarajan (1987) novel algorithm ordering
conjunctive goals. algorithm aimed minimizing time logic interpreter
spends proof given conjunctive goal.
main algorithm described paper dac algorithm (Algorithm 6, Section 4.6). works dividing sets subgoals smaller sets, producing candidate
sets orderings smaller sets, combining candidate sets obtain orderings
larger sets. prove algorithm finds minimal ordering given set
subgoals, show eciency practical assumptions. algorithm
employed statically (to reorder rule bodies program text execution
86

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

starts), semi-dynamically (to reorder rule body reduction performed)
dynamically (to reorder resolvent every reduction subgoal rule body).
Several researchers (Minker, 1978; Warren, 1981; Naish, 1985a, 1985b; Nie & Plaisted,
1990) proposed various heuristics subgoal ordering. Though fast, methods
guarantee finding minimal-cost orderings. algorithm provably finds minimal-cost
ordering, though ordering may take time heuristic methods.
future seems promising incorporate heuristics dac algorithm. example,
heuristics used grade binders OR-nodes: rather exhaustively trying
subgoals binders, could try one, several binders, thus reducing ordering
time. Also, current version ordering algorithm suitable finding
solutions conjunctive goal. would extend problem finding one
solution, fixed number solutions.
Another interesting issue research adaptation dac algorithm
interleaving ordering methods (Section 2.3). There, subgoals rule body added
ordered resolvent, seems wasteful start complete ordering process;
use information stored existing ordering resolvent. Perhaps whole
divisibility tree resolvent stored, nodes updated subgoals
rule body added resolvent.
ordering algorithm needs control knowledge work. control knowledge
average cost number solutions literals, learned training
collecting statistics. make assumption distribution queries received
system change time; thus, training set based distribution
seen past, system learns relevant knowledge future queries. consider
issue learning control values thoroughly another paper (Ledeniov & Markovitch,
1998a), together issues concerning dac algorithm (such minimizing
total time, instead minimizing inference time only).
Ullman Vardi (1988) showed problem ordering subgoals obtain termination inherently exponential time. problem work substantially
harder: must find order whose execution terminates finite time, one
terminates minimal finite time. impossible find ecient algorithm
cases. dac algorithm, however, ecient practical cases, graph
representing subgoal dependence (Figure 3) sparsely connected.
implemented dac algorithm tested artificial real domains.
experiments show speedup factor 10 compared random ordering,
13 compared alternative ordering algorithms.
dac algorithm useful many practical applications. Formal hardware
verification become extremely important semiconductor industry. model
checking currently widely used technique, generally agreed coping
increasing complexity VLSI design requires methods based theorem proving.
main obstacle preventing use automatic theorem proving high computational
demands. dac algorithm may used speeding logic inference, making use
automatic theorem provers practical.
Logic gained increasing popularity representation common-sense knowledge.
several advantages, including exibility well-understood semantics. Indeed,
CYC project (Lenat, 1995) recently moved frame-based representation logic87

fiLedeniov & Markovitch

based representation. However, large scale knowledge bases likely present
significant eciency problems inference engines. Using automatic subgoal ordering
techniques, described here, may help solve problems.
issue subgoal ordering obtains new significance development Inductive Logic Programming (Lavrac & Dzeroski, 1994; Muggleton & De Raedt, 1994). Systems
using approach, FOIL (Quinlan & Cameron-Jones, 1995), try build correct
programs fast possible, without considering eciency produced programs.
Combining dac algorithm Inductive Logic Programming techniques
synthesis logic programs (such deductive constructive approaches)
looks promising direction.

Appendix A. Proof Lemma 8

appendix present proof lemma omitted main text
paper reasons compactness. prove show two auxiliary lemmas.

Lemma 9

Let A~ 1 A~ 2 two ordered sequences subgoals, B set subgoals. value
cn(A~ 1kA~2)jB lies values cn(A~ 1)jB cn(A~ 2)jB[A~ .
1

Proof:

Denote c1 = cost(A~1 )jB
n1 = nsols(A~1)jB
cn1 = cn(A~1)jB
c2 = cost(A~2 )jB[A~ n2 = nsols(A~2)jB[A~ cn2 = cn(A~2)jB;[A~
c1;2 = cost(A~1 kA~ 2)jB n1;2 = nsols(A~ 1kA~ 2 )jB cn1;2 = cn(A~ 1 kA~ 2)jB
cn = n1;2 , 1 = n1 n2 , 1 = (n1 , 1) + n1 (n2 , 1) =
1

1;2

1

1

c1;2

c1;2
c1;2
n
n
1 ,1
2 ,1
c
+n c
= 1 c1 c 1 2 c2 = c1 cn1 +c n1 c2cn2 = cc1 cn1 + nc1 c2 cn2
1;2
1;2
1;2
1;2
n
c
1 c2
1
So, cn1;2 always lies cn1 cn2 (because c1;2 c1;2 positive
1). exactly, point cn1;2 divides segment [cn1; cn2] ratio

sum

(cn1;2 , cn1 ) : (cn2 , cn1;2 ) = n1 c2 : c1:

words, cn1;2 weighted average cn1 cn2 . Note c1 amount
resources spent proof-tree B~ 1 , n1 c2 { resources spent tree B~ 2 ,
c1;2 sum. So, time (relatively) dedicate proof B~ 1 , closer
cn1;2 cn1. conclusion generalized larger number components
concatenation (the proof induction):
cost(A~ 1 )jB
cn(A~ 1 kA~ 2 k : : : A~ k )jB =
cn(A~ 1 )jB +
cost(A~ 1 kA~ 2 k : : : A~ k )jB
nsols(A~ 1 )jB cost(A~ 2 )jB[A~ 1
+
cn(A~ 2 )jB[A~ 1 + : : : +
cost(A~ 1 kA~ 2k : : : A~ k )jB
nsols(A~ 1 kA~ 2 k : : : A~ k,1)jB cost(A~ k )jB[A~ 1 [:::A~ k,1
+
cn(A~ k )jB[A~ 1 [:::A~ k,1
cost(A~ 1kA~ 2 k : : : A~ k )jB
88

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

2

Lemma 10
Let S0 set subgoals N node divisibility tree S0. Let O~ N =
Q~ kA~ 1kA~2 kR~ ordering (N ), A~ 1 A~ 2 cn-equal max-blocks: cn(A~ 1 )jB(N )[Q~ =
cn(A~ 2)jB(N )[Q~ [A~ .
Let ancestor N O~ ordering (M ) consistent O~ N ,
1

A~ 1 A~ 2 violated. either A~ 1 A~ 2 max-blocks O~
max-blocks stand cn-equal them, A~ 1 A~ 2 belong
max-block O~ , O~ MC-contradicting.
Proof: induction distance N . = N , A~1 A~2
max-blocks, lemma holds. Let 6= N , let 0 child whose
0
descendant N . inductive hypothesis, lemma holds N 0 . Let O~
0
0
~
~
~
~
projection OM . A1 A2 violated OM , since violated
O~ .
A~ 1 A~2 max-blocks O~ M0 , inductive hypothesis maxblocks stand cn-equal them. OR-node, new
subgoals enter A~ 1 A~ 2 . AND-node, insertion new

subgoals possible, violates blocks, places max-blocks ordered cn,
O~ MC-contradicting, Corollary 3 Lemma 6. So, O~ MCcontradicting, new max-blocks inserted A~ 1 A~ 2 must cn-equal
both.
Assume A~ 1 A~ 2 max-blocks O~ . Without loss generality,
let A~ 1 member larger max-block O~ . show A~ 2 must participate
max-block.
Since A~ 1 joined larger block, must exist another block, B~ , adjacent A~ 1,
pair cn-inverted. Let B~ stand left A~ 1 (in opposite case,
~ A~ 1i cn-inverted, i.e.,
proof similar): O~ = X~ kB~ kA~ 1kY~ kA~ 2 kZ~ . pair hB;
~
~
~
~
cn(B )jB(M )[X~ > cn(A1)jB(M )[X~ [B~ . Lemma 9, cn(B kA1)jB(M )[X~ > cn(A~ 1)jB(M )[X~ [B~ ,
must add block B~ kA~ 1 blocks Y~ , cn-equal
A~ 1 . Also, cn(A~ 1)jB(M )[X~ [B~ = cn(A~ 2 )jB(M )[X~ [B~ [A~ , A~ 2 must added
block. Thus, A~ 1 A~ 2 belong max-block O~ .
A~1 A~ 2 belong max-block O~ M0 , block either violated
O~ , not. former case, O~ MC-contradicting, Corollary 3.
latter case, A~ 1 A~ 2 belong max-block O~ .
O~ M0 MC-contradicting, O~ MC-contradicting (the proof easy). 2
1

prove Lemma 8:

Lemma 8
Let S0 set subgoals, N node divisibility tree S0 O~ N = Q~ kA~ 1 kA~ 2kR~
89

fiLedeniov & Markovitch

ordering (N ), A~ 1 A~ 2 max-blocks, mutually independent
cn-equal bindings B(N ) [ Q~ . O~ N blockwise-equivalent O~ N0 =
Q~ kA~ 2kA~1 kR~ .

Proof:

Let S~ minimal ordering S0 binder-consistent O~ N . Corollary 3, S~
~0
violate blocks O~ N , particular A~ 1 A~ 2 : S~ = X~ kA~ 1kY~ kA~ 2 kZ~ . Let S~ 0 = S~ jOO~ NN =
X~ kA~ 2 kY~ kA~ 1 kZ~ . must show S~ 0 minimal, implies blockwise equivalence
O~ N O~ N0 .
Y~ empty, Cost(S~ ) = Cost(S~ 0 ) Lemma 2 (A~ 1 A~ 2 adjacent, mutually
independent cn-equal; thus, transposition change cost).
Y~ empty, Corollary 2 Y~ mutually independent A~ 1 A~ 2
(S~ binder-consistent O~ N , therefore B(N ) X~ , consequently Y~ \ B(N ) = ;).
Y~ divided several blocks, one cn-equal A~ 1 A~ 2: since S~
minimal, O~ N cannot MC-contradicting, claim follows Lemma 10.
Lemma 9, cn(Y~ )jX~ = cn(A~ 1 )jX~ = cn(A~ 2)jX~ . Lemma 2:

Cost(S~ ) = Cost(X~ kA~ 1kY~ kA~ 2kZ~ )
= Cost(X~ kA~ 1kA~ 2 kY~ kZ~ )
= Cost(X~ kA~ 2kA~ 1 kY~ kZ~ )
= Cost(X~ kA~ 2kY~ kA~ 1kZ~ )

=
=
=
=

== swap(Y; A2)
== swap(A1; A2 )
== swap(A1; )
Cost(S~ 0 )

Minimality S~ 0 implies blockwise equivalence O~ N O~ N0 .

2

Appendix B. Correctness dac Algorithm

section show dac algorithm correct, i.e., given set subgoals S0,
returns minimal ordering. suces show candidate set root node
DTree(S0; ;) valid. case, follows definition valid sets, must
contain minimal ordering. algorithm returns one cheapest candidates
root. Therefore, candidate set root valid, dac algorithm must return
minimal ordering S0.
start defining strong validity sets orderings. prove strong
validity implies validity. Finally, use induction prove theorem, showing
candidate set produced node divisibility tree strongly valid.
Definition: Let S0 set subgoals, N node divisibility tree S0. set
CN (S (N )) strongly valid, every ordering (S (N )) nCN either MC-contradicting
blockwise-equivalent member CN , unless ordering (N ) min-consistent.

StronglyV alidN;S (CN ) ()
[9O~ N0 2 (S (N )) : MCN;S (O~ N0 )] ! [O~ N 2 (S (N )) n CN ! MCCN;S (O~ N )_
(9O~ N00 2 CN ^ MCEN;S (O~ N ; O~ N00 ))]
0

0

0

0

Lemma 11 strongly valid set orderings valid.
90

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Proof: Let S0 set subgoals, N node divisibility tree S0, C (N )
strongly valid set orderings N .
min-consistent ordering N , C (N ) valid, definition
valid set (Section 4.2).
Otherwise, exists least one minimal ordering S0, binder-consistent N .
Every ordering (S (N )) n C (N ) either MC-contradicting blockwise-equivalent
member C (N ). prove C (N ) valid, must show contains
ordering O~ N , binder-consistent minimal ordering S~ S0 .
Let S~ 0 minimal ordering S0, binder-consistent N . Let O~ N0 projection
S~ 0 N . O~ N0 2 C (N ), done (O~ N = O~ N0 , S~ = S~ 0). Otherwise, O~ N0 2 (S (N )) n
C (N ). O~ N0 cannot MC-contradicting (it min-consistent S~ 0), therefore must
blockwise-equivalent O~ N00 2 C (N ). Blocks O~ N0 violated S~ 0, since S~ 0
~ 00
minimal (Corollary 3). Therefore substitution S~ 00 = S~ 0jOO~ N0 well defined. S~ 00 minimal,
N
since S~ 0 minimal O~ N0 O~ N00 blockwise-equivalent. S~ 00 binder-consistent
O~ N00 , since S~ 0 binder-consistent O~ N0 . Thereupon S~ 00 O~ N00 satisfy requirements
validity (O~ N = O~ N00 , S~ = S~ 00).
2
Theorem 3
Let S0 set subgoals. node N divisibility tree S0, Algorithm 6
creates strongly valid candidate set orderings.

Proof: induction height N 's subtree.
Inductive base: N leaf node, means (N ) independent B(N ).

candidate set N contains one element, whose subgoals sorted cn.
orderings belong (S (N )) n CandSet(N ) either sorted cn,
hence MC-contradicting (Lemma 4), sorted cn, hence blockwiseequivalent candidate (Corollary 4). Consequently, CandSet(N ) strongly
valid.
Inductive hypothesis: children N , Algorithm 6 produces strongly valid candidate sets.
Inductive step: internal node divisibility tree either AND-node ORnode.
1. N AND-node. Let N1; N2; : : :Nk children N . First show
ConsSet(N ) strongly valid.
Let O~ N 2 (S (N )) n ConsSet(N ). 1 k, let O~ projection
O~ N Ni. set projections fO~ 1; O~ 2; : : : O~ k g belong one three
following types, regard O~ N .
(a) sets first type contain least one MC-contradicting projection.
case O~ N MC-contradicting too. Assume contrary: exists
minimal ordering S~ S0, binder-consistent O~ N . Let O~ MCcontradicting projection. Since O~ consistent O~ N , consistent
91

fiLedeniov & Markovitch

S~ . Since B(Ni ) = B(N ), subgoals B(Ni) appear S~
subgoals (Ni ). Therefore, O~ binder-consistent S~ , since S~
minimal, O~ min-consistent MC-contradicting { contradiction.
(b) sets second type contain MC-contradicting projections,
O~ N block projection violated, max-blocks different
projections ordered cn. case, O~ N MC-contradicting,
Corollary 3 Lemma 6.
(c) sets third type contain MC-contradicting projections,
max-blocks projections violated O~ N sorted cn.
Every projection O~ either belongs CandSet(Ni), not. O~ 62 CandSet(Ni),
exists O~ i0 2 CandSet(Ni) O~ blockwise-equivalent
O~ i0 (because CandSet(Ni) strongly valid inductive hypothesis,
O~ MC-contradicting). O~ 2 CandSet(Ni), set O~ i0 = O~ i.
~0
~0 ~0
Let O~ N0 = O~ N jOO~ jOO~ : : : jOO~ kk . substitution well defined, since O~
number max-blocks O~ i0 , max-blocks projections
violated O~ N . Let S~ minimal ordering S0, binder-consistent
O~ N . Since S~ minimal, blocks O~ 1 violated S~ . Since O~ 1
~0
blockwise-equivalent O~ 10 , ordering S~1 = S~ jOO~ well-defined
minimal. S~1 positions subgoals B(N ) change;
thus, O~ 2 min-consistent S~1, blockwise equivalence O~ 2 O~ 20
~0
~0 ~0
entails minimality ordering S~2 = S~1 jOO~ = S~ jOO~ jOO~ . continue
~0
~0 ~0
O~ -s, finally obtain S~ 0 = S~ jOO~ jOO~ : : : jOO~ kk minimal.
~0
definition O~ N0 , S~ 0 = S~ jOO~ NN (note introduced blockwise equivalence
strong validity able perform transition). S~ 0 minimal,
therefore O~ N blockwise-equivalent O~ N0 . O~ N0 2 ConsSet(N ), since
projections candidates child nodes. Thereupon, O~ N blockwiseequivalent member ConsSet(N ).
So, ConsSet(N ) strongly valid. prove CandSet(N ) strongly valid,
suces show members ConsSet(N ) included
CandSet(N ) Algorithm 6, either MC-contradicting blockwise-equivalent
members CandSet(N ). orderings three types:
(a) Orderings violate blocks children projections. MCcontradicting Corollary 3.
(b) Orderings violate blocks, max-blocks children projections ordered cn. MC-contradicting Lemma 6.
(c) Orderings violate blocks sorted cn.
combination projections, one consistent ordering N retained
candidate set, rejected. Corollary 5, rejected
orderings blockwise-equivalent retained candidate.
Consequently, CandSet(N ) strongly valid.
1

2

1

2

1
1

92

2

1

2

2

1

2

1

2

1

2

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

2. N OR-node. Again, start showing ConsSet(N ) strongly
valid.
Let O~ N 2 (S (N )) n ConsSet(N ). O~ N constructed binder H
\tail" sequence T~ : O~ N = H kT~ . Let NH child N corresponds
binder H . inductive hypothesis, CandSet(NH ) strongly valid.
T~ 62 CandSet(NH ), since otherwise O~ N 2 ConsSet(N ). Therefore, T~ either MC-contradicting, blockwise-equivalent T~ 0 2 CandSet(NH ).
T~ MC-contradicting, O~ N MC-contradicting (proof contradiction, AND-nodes). T~ blockwise-equivalent T~ 0 , O~ N = H kT~
blockwise-equivalent H kT~ 0 2 ConsSet(N ) (the proof easy). Hence,
ConsSet(N ) strongly valid. orderings ConsSet(N ) included CandSet(N ) dac algorithm cheaper permutations
leading max-blocks, therefore MC-contradicting, Lemma 7. Hence,
CandSet(N ) strongly valid.
2

Corollary 7 candidate set found Algorithm 6 root node valid.
Corollary 8 Algorithm 6 finds minimal ordering given set subgoals.

References

Aho, A. V., Hopcroft, J. E., & Ullman, J. D. (1987). Data Structures Algorithms.
Addison-Wesley.
Boddy, M., & Dean, T. (1989). Solving time-dependent planning problems. Sridharan, N. S. (Ed.), Proceedings 11th International Joint Conference Artificial
Intelligence, pp. 979{984, Detroit, MI, USA. Morgan Kaufmann.
Bol, R. N., Apt, K. R., & Klop, J. W. (1991). analysis loop checking mechanisms
logic programs. Theoretical Computer Science, 86 (1), 35{79.
Braem, C., Le Charlier, B., Modar, S., & Van Hentenryck, P. (1994). Cardinality Analysis
Prolog. Bruynooghe, M. (Ed.), Logic Programming - Proceedings 1994
International Symposium, pp. 457{471, Massachusetts Institute Technology.
MIT Press.
Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. (1984). Classification
Regression Trees. Wadsworth International Group, Belmont, CA.
Bruynooghe, M., De Schreye, D., & Krekels, B. (1989). Compiling control. Journal
Logic Programming, 6, 135{162.
Clark, K. L., & McCabe, F. (1979). control facilities IC-Prolog. Michie, D. (Ed.),
Expert Systems Microelectronic Age., pp. 122{149. University Edinburgh,
Scotland.
Clocksin, W. F., & Mellish, C. S. (1987). Programming Prolog (Third edition). SpringerVerlag, New York.
93

fiLedeniov & Markovitch

Cohen, W. W. (1990). Learning approximate control rules high utility. Proceedings
Seventh International Machine Learning Workshop, pp. 268{276, Austin, Texas.
Morgan Kaufmann.
Cormen, T. H., Leiserson, C. E., & Rivest, R. L. (1991). Introduction Algorithms. MIT
Press, Cambridge, Mass.
Cortesi, A., Le Charlier, B., & Rossi, S. (1997). Specification-based automatic verification
Prolog programs. Gallagher, J. (Ed.), Proceedings 6th International Workshop Logic Program Synthesis Transformation, Vol. 1207 LNCS, pp. 38{57,
Stockholm, Sweden. Springer-Verlag.
De Boeck, P., & Le Charlier, B. (1990). Static type analysis Prolog procedures ensuring
correctness. Deransart, P., & Maluszynski, J. (Eds.), Programming Languages
Implementation Logic Programming, Vol. 456 LNCS, pp. 222{237, Linkoping,
Sweden. Springer-Verlag.
De Schreye, D., & Decorte, S. (1994). Termination logic programs: never-ending
story. Journal Logic Programming, 19 & 20, 199{260.
Debray, S., Lopez-Garca, P., Hermenegildo, M., & Lin, N.-W. (1997). Lower bound cost
estimation logic programs. Maluszynski, J. (Ed.), Proceedings International Symposium Logic Programming (ILPS-97), pp. 291{306, Cambridge. MIT
Press.
Debray, S. K., & Lin, N.-W. (1993). Cost analysis logic programs. ACM Transactions
Programming Languages Systems, 15 (5), 826{875.
Debray, S. K., & Warren, D. S. (1988). Automatic mode inference logic programs.
Journal Logic Programming, 5, 207{229.
Dejong, G., & Mooney, R. (1986). Explanation-based learning: alternative view. Machine Learning, 1, 145{176.
Deville, Y. (1990). Logic Programming: Systematic Program Development. International
Series Logic Programming, Addison-Wesley.
Etzioni, O. (1991). STATIC: problem-space compiler PRODIGY. Dean, Thomas
L.; McKeown, K. (Ed.), Proceedings 9th National Conference Artificial
Intelligence, pp. 533{540, Anaheim, California. MIT Press.
Etzioni, O. (1993). Acquiring search-control knowledge via static analysis. Artificial Intelligence, 62, 255{301.
Greiner, R., & Orponen, P. (1996). Probably approximately optimal satisficing strategies.
Artificial Intelligence, 82 (1-2), 21{44.
Henrard, J., & Le Charlier, B. (1992). FOLON: environment declarative construction
logic programs. Bruynooghe, M., & Wirsing, M. (Eds.), Proceedings Fourth
International Symposium Programming Language Implementation Logic Programming, Vol. 631 LNCS, pp. 217{231, Leuven, Belgium. Springer-Verlag.
94

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Itai, A., & Makowsky, J. A. (1987). Unification complexity measure logic programming. Journal Logic Programming, 4, 105{117.
Knuth, D. E. (1973). Art Computer Programming, Vol. 3. Addison-Wesley, Reading,
Mass.
Kowalski, R. A. (1979). Algorithm = Logic + Control. Communications ACM, 22(7),
424{436.
Laird, P. D. (1992). Ecient dynamic optimization logic programs. Proceedings
ML92 Workshop Knowledge Compilation Speedup Learning Aberdeen,
Scotland.
Langley, P. (1985). Learning search: weak methods domain-specific heuristics.
Cognitive Science, 9, 217{260.
Lavrac, N., & Dzeroski, S. (1994). Inductive Logic Programming: Techniques Applications. Artificial Intelligence. Ellis Harwood, New York.
Ledeniov, O., & Markovitch, S. (1998a). Controlled utilization control knowledge
speeding logic inference. Tech. rep. CIS9812, Technion, Haifa, Israel.
Ledeniov, O., & Markovitch, S. (1998b). Learning investment functions controlling
utility control knowledge. Proceedings Fifteenth National Conference
Artificial Intelligence, pp. 463{468, Madison, Wisconsin. Morgan Kaufmann.
Lenat, D. B. (1995). CYC: large-scale investment knowledge infrastructure. Communications ACM, 38 (11), 33{38.
Lloyd, J. W. (1987). Foundations Logic Programming (Second edition). Springer-Verlag,
Berlin.
Markovitch, S., & Scott, P. D. (1989). Automatic ordering subgoals | machine learning
approach. Lusk, E. L., & Overbeek, R. A. (Eds.), Proceedings North American
Conference Logic Programming, pp. 224{242, Cleveland, Ohio. MIT Press.
Markovitch, S. (1989). Information Filtering: Selection Mechanisms Learning Systems.
Ph.D. thesis, EECS Department, University Michigan.
Markovitch, S., & Scott, P. D. (1993). Information filtering: Selection mechanisms
learning systems. Machine Learning, 10, 113{151.
Minker, J. (1978). Search strategy selection function inferential relational system.
ACM Transactions Database Systems, Vol. 3, pp. 1{31.
Minton, S. (1988). Learning Search Control Knowledge: Explanation-Based Approach.
Kluwer, Boston, MA.
Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). Explanation-based generalization: unifying view. Machine Learning, 1, 47{80.
95

fiLedeniov & Markovitch

Mooney, R. J., & Zelle, J. M. (1993). Combining FOIL EBG speed-up logic programs.
Bajcsy, R. (Ed.), Proceedings Thirteenth International Joint Conference
Artificial Intelligence, pp. 1106{1111, Chambery, France. Morgan Kaufmann.
Morris, K. A. (1988). algorithm ordering subgoals NAIL!. Proceedings
Seventh ACM SIGACT-SIGMOD Symposium Principles Database Systems, pp.
82{88, Austin, TX. ACM Press, New York.
Muggleton, S., & De Raedt, L. (1994). Inductive logic programming: Theory methods.
Journal Logic Programming, 19 & 20, 629{680.
Naish, L. (1984). MU-Prolog 3.1db Reference Manual. Dept. Computer Science, Univ.
Melbourne.
Naish, L. (1985a). Automatic control logic programs. Journal Logic Programming,
3, 167{183.
Naish, L. (1985b). Prolog control rules. Joshi, A. (Ed.), Proceedings 9th International Joint Conference Artificial Intelligence, pp. 720{723, Los Angeles, CA.
Morgan Kaufmann.
Natarajan, K. S. (1987). Optimizing backtrack search solutions conjunctive problems. McDermott, J. (Ed.), Proceedings 10th International Joint Conference
Artificial Intelligence, pp. 955{958, Milan, Italy. Morgan Kaufmann.
Nie, X., & Plaisted, D. A. (1990). Experimental results subgoal ordering. IEEE
Transactions Computers, Vol. 39, pp. 845{848.
Pettorossi, A., & Proietti, M. (1994). Transformation logic programs: Foundations
techniques. Journal Logic Programming, 19 & 20, 261{320.
Pettorossi, A., & Proietti, M. (1996). Rules strategies transforming functional
logic programs. ACM Computing Surveys, 28 (2), 360{414.
Porto, A. (1984). Epilog: language extended programming. Campbell, J. (Ed.),
Implementations Prolog. Ellis Harwood.
Prieditis, A. E., & Mostow, J. (1987). PROLEARN: Towards prolog interpreter
learns. Forbus, Kenneth; Shrobe, H. (Ed.), Proceedings 6th National Conference Artificial Intelligence, pp. 494{498, Seattle, WA. Morgan Kaufmann.
Quinlan, J. R. (1986). Induction decision trees. Machine Learning, 1, 81{106.
Quinlan, J. R., & Cameron-Jones, R. M. (1995). Induction logic programs: FOIL
related systems. New Generation Computing, Special Issue Inductive Logic Programming, 13 (3-4), 287{312.
Simon, H. A., & Kadane, J. B. (1975). Optimal problem-solving search: All-or-none solutions. Artificial Intelligence, 6, 235{247.
Smith, D. E. (1989). Controlling backward inference. Artificial Intelligence, 39 (1), 145{208.
96

fiThe Divide-and-Conquer Subgoal-Ordering Algorithm

Smith, D. E., & Genesereth, M. R. (1985). Ordering conjunctive queries. Artificial Intelligence, 26, 171{215.
Smith, D. E., Genesereth, M. R., & Ginsberg, M. L. (1986). Controlling recursive inference.
Artificial Intelligence, 30 (3), 343{389.
Somogyi, Z., Henderson, F., Conway, T., Bromage, A., Dowd, T., Jeffery, D., & al. (1996a).
Status Mercury system. Proc. JICSLP '96 Workshop Parallelism
Implementation Technology (Constraint) Logic Programming Languages, pp.
207{218, Bonn, Germany.
Somogyi, Z., Henderson, F., & Conway, T. (1996b). execution algorithm Mercury,
ecient purely declarative logic programming language. Journal Logic Programming, 29 (1{3), 17{64.
Sterling, L., & Shapiro, E. (1994). Art Prolog (Second edition). MIT Press, Cambridge, MA.
Tamaki, H., & Sato, T. (1984). Unfold/fold transformation logic programs. Tarnlund,
S.-
A. (Ed.), Proceedings Second International Conference Logic Programming, pp. 127{138, Uppsala, Sweden.
Ullman, J. D., & Vardi, M. Y. (1988). complexity ordering subgoals. Proceedings
Seventh ACM SIGACT-SIGMOD Symposium Principles Database Systems,
pp. 74{81, Austin, TX. ACM Press, New York.
Ullman, J. D. (1982). Principles Database Systems. Computer Science Press, Rockville,
MD.
Vasak, T., & Potter, J. (1985). Metalogical control logic programs. Journal Logic
Programming, 2 (3), 203{220.
Warren, D. H. D. (1981). Ecient processing interactive relational database queries
expressed logic. Zaniola, & Delobel (Eds.), Proceedings 7th International
Conference Large Data Bases, pp. 272{281, Cannes, France. IEEE Computer
Society Press.

97


