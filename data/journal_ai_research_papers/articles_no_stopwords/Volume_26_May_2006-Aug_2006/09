Journal Artificial Intelligence Research 26 (2006) 371-416

Submitted 11/05; published 8/06

Clause/Term Resolution Learning Evaluation
Quantified Boolean Formulas
Enrico Giunchiglia
Massimo Narizzano
Armando Tacchella

giunchiglia@unige.it
mox@dist.unige.it
tac@dist.unige.it

DIST - Universita di Genova
Viale Causa 13, 16145 Genova, Italy

Abstract
Resolution rule inference basis procedures automated reasoning. procedures, input formula first translated equisatisfiable
formula conjunctive normal form (CNF) represented set clauses. Deduction starts inferring new clauses resolution, goes empty clause
generated satisfiability set clauses proven, e.g., new clauses
generated.
paper, restrict attention problem evaluating Quantified Boolean
Formulas (QBFs). setting, outlined deduction process known
sound complete given formula CNF form resolution, called Qresolution, used. introduce Q-resolution terms, used formulas disjunctive normal form. show computation performed available
procedures QBFs based Davis-Logemann-Loveland procedure (DLL) propositional satisfiability corresponds tree Q-resolution terms clauses
alternate. poses theoretical bases introduction learning, corresponding
recording Q-resolution formulas associated nodes tree. discuss
problems related introduction learning DLL based procedures, present
solutions extending state-of-the-art proposals coming literature propositional
satisfiability. Finally, show DLL based solver extended learning, performs
significantly better benchmarks used 2003 QBF solvers comparative evaluation.

1. Introduction
Resolution (Robinson, 1965) rule inference basis procedures
automated reasoning (see, e.g., Fermuller, Leitsch, Hustadt, & Tammet, 2001; Bachmair &
Ganzinger, 2001). procedures, input formula first translated equisatisfiable formula conjunctive normal form (CNF) represented set clauses.
Deduction starts inferring new clauses resolution, goes empty clause
generated satisfiability set clauses proven, e.g., new clauses
generated. restrict attention problem evaluating Quantified Boolean
Formulas (QBFs). setting, outlined deduction process known sound
complete given formula CNF form resolution, called Q-resolution,
used (Kleine-Buning, Karpinski, & Flogel, 1995). However, available decision
procedures QBFs based extend Davis-Logemann-Loveland procedure
(DLL) (Davis, Logemann, & Loveland, 1962) propositional satisfiability (SAT).
c
2006
AI Access Foundation. rights reserved.

fiGiunchiglia, Narizzano & Tacchella

propositional case, well known computation performed DLL corresponds
specific form resolution called regular tree resolution (see, e.g., Urquhart, 1995).
paper introduce Q-resolution terms, used formulas disjunctive
normal form. show computation performed DLL based decision procedures
QBFs corresponds tree Q-resolution terms clauses alternate.
correspondence poses theoretical bases introduction learning, corresponding
recording Q-resolution formulas associated nodes tree. particular,
recording Q-resolutions clauses generalizes popular nogood learning constraint satisfaction SAT literatures (see, e.g., Dechter, 1990; Bayardo, Jr. & Schrag,
1997): nogood corresponds set assignments falsifying input formula,
useful pruning assignments existential variables. Recording Q-resolutions
terms corresponds good learning: good corresponds set assignments satisfying input formula, useful pruning assignments universal variables.
discuss problems related introduction learning DLL based procedures
QBFs, present solutions extending state-of-the-art proposals coming literature
SAT. show effectiveness learning QBFs evaluation problem,
implemented QuBE, state-of-the-art QBF solver. Using QuBE, done
experimental tests several real-world QBFs, corresponding planning (Rintanen, 1999;
Castellini, Giunchiglia, & Tacchella, 2003) circuit verification (Scholl & Becker, 2001;
Abdelwaheb & Basin, 2000) problems, two primary application domains
interest. results witness effectiveness learning.
paper structured follows. first review basics Quantified Boolean
Logic, time introducing terminology notation used
throughout paper. Section 3, introduce clause term resolution,
relation DLL based decision procedures QBFs. Then, Section 4, introduce
nogood good learning, show effectively integrated DLL
based decision procedures QBFs. implementation experimental results
presented Section 5. paper ends conclusions related work.
paper builds extends many ways AAAI paper (Giunchiglia, Narizzano, & Tacchella, 2002). respect paper, (i) introduce clause
term resolution; (ii) show correspondence clause/term Q-resolution
computation tree searched DLL based decision procedures; (iii) basis
correspondence, extend basic backtracking search procedure, first backjumping
learning, prove soundness completeness; (iv) discuss
implementation QuBE providing many details, (v) present results
much broader detailed experimental analysis.
on, simply write resolution Q-resolution.

2. Quantified Boolean Logic
Consider set P symbols. variable element P. literal variable
negation variable. following, literal l,
|l| variable occurring l;
l negation l l variable, |l| otherwise.
372

fiClause/Term Resolution Learning Quantified Boolean Formulas

sake simplicity, consider formulas negation normal form (NNF).
Thus, us, propositional formula combination literals using k-ary (k 0)
connectives (for conjunctions) (for disjunctions). following, use True
False abbreviations empty conjunction empty disjunction respectively.
QBF expression form
= Q1 z1 Q2 z2 . . . Qn zn

(n 0)

(1)


every Qi (1 n) quantifier, either existential universal ,
z1 , . . . , zn distinct variables,
propositional formula z1 , . . . , zn .
example,
x1 yx2 ((x1 x2 ) (y x2 ) (x2 ((x1 y) (y x2 ))))

(2)

QBF.
(1), Q1 z1 . . . Qn zn prefix matrix. say literal l
existential |l| belongs prefix, universal otherwise. Finally, (1),
define
level variable zi , 1 + number expressions Qj zj Qj+1 zj+1
prefix j Qj 6= Qj+1 ;
level literal l, level |l|.
example, (2) x2 existential level 1, universal level 2, x1
existential level 3.
value semantics QBF defined recursively follows:
1. prefix empty, evaluated according truth tables propositional
logic.
2. x, true x true x true.
3. y, true true.
(1) l literal |l| = zi , l QBF
whose matrix obtained substituting
zi True z False l = zi ,
zi False z True l = z .
whose prefix Q1 z1 Q2 z2 . . . Qi1 zi1 Qi+1 zi+1 . . . Qn zn .
easy see QBF without universal quantifiers, problem determining
value reduces SAT problem.
Two QBFs equivalent either true false.
373

fiGiunchiglia, Narizzano & Tacchella

3. Resolution DLL Based Decision Procedures QBFs
section first introduce clause/term resolution DLL based decision procedures
QBFs, show correspondence two.
3.1 Clause Term Resolution
According definition QBF, matrix combination conjunctions
disjunctions literals. However, using common clause form transformations based
renaming first used Tseitin (1970), possible perform linear time conversion
arbitrary QBF equivalent one matrix conjunctive normal form
(CNF). conversions based fact QBF (1) equivalent
Q1 z1 Q2 z2 . . . Qn zn x((x ) [x/])

(n 0)


propositional formula literal;
x variable distinct z1 , z2 , . . . , zn ;
[x/] propositional formula obtained substituting one occurrences x.
Thus,
((x1 y) (y x2 ))
follows (2) equivalent
x1 yx2 x3 ((x1 x2 ) (y x2 ) (x2 x3 ) (x1 x3 ) (y x2 x3 ))

(3)

Thanks conversions, restrict attention QBFs matrix
CNF, represent matrix formula set clauses interpreted
conjunctively, clause finite set literals interpreted disjunctively. Further,
assume clause non-tautological minimal. clause tautological
contains variable negation. clause C minimal literals C
minimum level existential. minimal form clause C clause obtained
C deleting universal literals cause C non-minimal. instance,
(4), clauses non-tautological minimal. assumption clauses
non-tautological minimal restriction, following theorem states.
Theorem 1 Let QBF matrix CNF. Let 0 QBF obtained

1. eliminating tautological clauses;
2. replacing non-tautological non-minimal clause minimal form.
0 equivalent.
374

fiClause/Term Resolution Learning Quantified Boolean Formulas

Proof. Clearly, tautological clauses eliminated result equivalent
QBF. Let C = {l1 , . . . , ln , ln+1 , . . . , lm } non-tautological non-minimal clause
ln+1 , . . . , lm universal literals C \ min(C) (0 n < m). Further, without
loss generality, assume level li less equal level li+1 ,
1 < m. Then, form (p m)
. . . Q1 |l1 | . . . |ln | . . . |ln+1 | . . . |lm |Qm+1 zm+1 . . . Qp zp {{l1 , . . . , ln , ln+1 , . . . , lm }, . . .},
standing
. . . Q1 |l1 | . . . |ln | . . . |ln+1 | . . . |lm |Qm+1 zm+1 . . . Qp zp ((l1 . . . ln ln+1 . . . lm ) ).
Then, applying standard rules quantifiers, rewritten
. . . Q1 |l1 | . . . |ln | . . . |ln+1 | . . . |lm |((l1 . . . ln ln+1 . . . lm ) Qm+1 zm+1 . . . Qp zp ),
equivalent
. . . Q1 |l1 | . . . |ln | . . . |ln+1 | . . . (|lm |(l1 . . .ln ln+1 . . .lm )|lm |Qm+1 zm+1 . . . Qp zp ),
equivalent
. . . Q1 |l1 | . . . |ln | . . . |ln+1 | . . . ((l1 . . . ln ln+1 . . . lm1 ) |lm |Qm+1 zm+1 . . . Qp zp ),
equivalent
. . . Q1 |l1 | . . . |ln | . . . |ln+1 | . . . |lm |Qm+1 zm+1 . . . Qp zp ((l1 . . . ln ln+1 . . . lm1 ) ),
i.e., QBF obtained deleting lm clause C. iterating
reasoning process, literals C \ min(C) eliminated C, hence
thesis.

on, QBF CNF matrix conjunction clauses,
clause minimal non-tautological. represent matrix QBF
set clauses,
empty clause {} stands False;
empty set clauses {} stands True;
formula {{}} equivalent False;
QBF (3) written
x1 yx2 x3 {{x1 , y, x2 }, {y, x2 }, {x2 , x3 }, {x1 , y, x3 }, {y, x2 , x3 }}.

(4)

Clause resolution (Kleine-Buning et al., 1995) similar ordinary resolution
existential literals matched. precisely, clause resolution (on literal l)
rule
C1
C2
(5)
min(C)

375

fiGiunchiglia, Narizzano & Tacchella

(c1)
(c2)
(c3)
(c4)

{x1 , y, x2 }
{y, x2 }
{x2 , x3 }
{x1 , y, x3 }

Input
Input
Input
Input

formula
formula
formula
formula

(c5)
(c6)
(c7)
(c8)

{x1 }
{x3 , y}
{x1 }
{}






(c1),
(c2),
(c4),
(c5),

(c2)
(c3)
(c6)
(c7)

Table 1: clause resolution deduction showing (4) false. prefix x1 yx2 x3 .

l existential literal;
C1 , C2 two clauses {l, l} (C1 C2 ), literal l0 6= l, {l0 , l0 }
(C1 C2 );
C (C1 C2 ) \ {l, l}.
C1 C2 antecedents, min(C) resolvent rule.
Theorem 2 ((Kleine-Buning et al., 1995)) Clause resolution sound complete
proof system deciding QBFs CNF: QBF CNF true empty
clause derivable clause resolution.
instance, fact (4) false follows deduction Table 1.
Alternatively CNF conversion, could converted (2) QBF
matrix disjunctive normal form (DNF), linear time, basis QBF
(1), equivalent
Q1 z1 Q2 z2 . . . Qn zn y((y ) [y/])

(n 0),

assuming propositional formula literal, variable distinct
z1 , z2 , . . . , zn .
simple recursive application equivalence (2) leads following
equivalent QBF:
x1 yx2 y1 y2 y3 y4 y5 y6 ((y1 y2 y3 )
(y 1 x1 ) (y 1 y) (y 1 x2 )
(y 2 y) (y 2 x2 )
(y 3 x2 ) (y 3 y4 )
(y 4 y5 y6 )
(y 5 x1 ) (y 5 y)
(y 6 y) (y 6 x2 )).

(6)

Given QBF matrix DNF, represent matrix set terms
interpreted disjunctively, term finite set literals interpreted
conjunctively. Further, assume term non-contradictory minimal.
term contradictory contains variable negation. term minimal
literals minimum level universal. minimal form term
term obtained deleting existential literals cause non-minimal.
terms (6) non-contradictory minimal. Analogously said
QBFs CNF, QBF DNF assume terms
non-contradictory minimal without loss generality.
376

fiClause/Term Resolution Learning Quantified Boolean Formulas

Theorem 3 Let QBF matrix DNF. Let 0 QBF obtained

1. eliminating contradictory terms;
2. replacing non-contradictory non-minimal term minimal form.
0 equivalent.
Proof. Analogous proof Theorem 1.



before, on, QBF DNF matrix disjunction
terms, term minimal non-contradictory.
introduce term resolution (on literal l) consists rule
T1
T2
min(T )

l universal literal;
T1 , T2 two terms {l, l} (T1 T2 ), literal l0 6= l, {l0 , l0 }
(T1 T2 );
(T1 T2 ) \ {l, l}.
T1 T2 antecedents, min(T ) resolvent rule.
Theorem 4 Term resolution sound complete proof system deciding QBFs
DNF: QBF DNF true empty term derivable term resolution.
Proof. fact term resolution sound complete proof system follows
soundness completeness clause resolution.
Let set sets literals, = Q1 z1 Q2 z2 . . . Qn zn QBF
interpreted set clauses. Without loss generality assume clause
non-tautological minimal. following chain equivalences holds:
exists deduction empty clause using clause resolution

false

QBF = Q1 z1 Q2 z2 . . . Qn zn interpreted set terms true

deduction empty term using term resolution.
chain equivalences, Q Q = , Q = .



example term resolution deduction empty term, consider QBF :
x1 yx2 x3 ((x1 x2 ) (y x2 ) (x2 x3 ) (x1 x3 ) (y x2 x3 ))
377

fiGiunchiglia, Narizzano & Tacchella

i.e., QBF obtained (3) simultaneously replacing , , ,
. Then, deduction Table 1 deduction empty term
using term resolution.
QBF DNF CNF term resolution cannot applied,
thus term resolution sufficient proving truth falsity . However,
following model generation rule

min(T )

matrix ;
non-contradictory term clause C , C 6= ,
get sound complete proof system QBFs CNF. Intuitively, model generation rule allows us start minimal form terms propositionally entail
matrix input formula.
Theorem 5 Term resolution model generation sound complete proof system
deciding QBFs CNF: QBF CNF true empty term derivable
term resolution model generation.
Proof. Given QBF CNF matrix , model generation rule derive
set terms form min(T )
term non-contradictory clause C , C 6= ;

disjunction terms propositionally logically equivalent .
Let 0 QBF DNF obtained substituting . 0
value. Hence thesis thanks Theorem 4.


3.2 DLL Based Decision Procedures QBFs
Given said far, arbitrary QBF converted (in linear time)
equivalent QBF CNF. this, end paper, restrict
attention QBFs format. assumption, (1) l literal
|l| = zi , redefine l QBF
whose matrix obtained removing clauses C l C,
removing l clauses;
whose prefix Q1 z1 Q2 z2 . . . Qi1 zi1 Qi+1 zi+1 . . . Qn zn .
378

fiClause/Term Resolution Learning Quantified Boolean Formulas

Further, extend notation sequence literals: = l1 ; l2 ; . . . ; lm (m 0),
defined (. . . ((l1 )l2 ) . . .)lm .
Consider QBF .
simple procedure determining value starts empty assignment
recursively extends current assignment z and/or z, z heuristically
chosen variable highest level , either empty clause empty set
clauses produced . basis values ;z ;z , value
determined according semantics QBFs. value value .
Cadoli, Giovanardi, Giovanardi Schaerf (2002) introduced various improvements
basic procedure.
first improvement directly conclude value
matrix contains contradictory clause (Lemma 2.1 Cadoli et al., 2002). clause
C contradictory contains existential literal. example contradictory clause
empty clause.
second improvement allows us directly extend l l unit monotone
(Lemmas 2.4, 2.5, 2.6 Cadoli et al., 2002). (1), literal l is:
Unit l existential 0,
clause {l, l1 , . . . , lm } belongs ;
literal li (1 m) universal level lower level l.
Monotone pure
either l existential, l belong clause , l occurs ;
l universal, l belong clause , l occurs .
example, QBF form
. . . x1 yx2 . . . {{x1 , y}, {x2 }, . . .},
x1 x2 unit. QBF
y1 x1 y2 x2 {{y 1 , y2 , x2 }, {x1 , 2 , x2 }},
monotone literals y1 x1 .
improvements, resulting procedure, called Q-DLL, essentially one
presented work Cadoli, Giovanardi, Schaerf (1998), extends DLL
order deal QBFs. Figure 1 simple, recursive presentation it. figure,
given QBF ,
1. False returned contradictory clause matrix (line 1); otherwise
2. True returned matrix empty (line 2); otherwise
3. line 3, recursively extended ; l l unit (and say l
assigned unit); otherwise
379

fiGiunchiglia, Narizzano & Tacchella

0 function Q-DLL(, )
1
(ha contradictory clause matrix i) return False;
2
(hthe matrix emptyi) return True;
3
(hl unit i) return Q-DLL(, ; l);
4
(hl monotone i) return Q-DLL(, ; l);
5
l := ha literal highest level i;
6
(hl existentiali) return Q-DLL(, ; l) Q-DLL(, ; l);
7
else return Q-DLL(, ; l) Q-DLL(, ; l).
Figure 1: algorithm Q-DLL.
4. line 4, recursively extended ; l l monotone (and say l
assigned monotone); otherwise
5. literal l highest level chosen
l existential (line 6), extended ; l first (and say l
assigned left split). result False, ; l tried returned (and
case say l assigned right split).
Otherwise (line 7), l universal, extended ; l first (and say l
assigned left split). result True, ; l tried returned
(and case say l assigned right split).
Theorem 6 Q-DLL(, ) returns True true, False otherwise.
Proof. Trivial consequence Lemmas 2.1, 2.4, 2.5, 2.6 work Cadoli, Giovanardi,
Giovanardi, Schaerf (2002) semantics QBFs.

Given said far, clear Q-DLL evaluates generating
semantic tree (Robinson, 1968) node corresponds invocation Q-DLL
thus assignment . us,
assignment (for QBF ) possibly empty sequence = l1 ; l2 ; . . . ; lm (m 0)
literals li , li unit, monotone, highest level
l1 ;l2 ;...;li1 ;
(semantic) tree representing run Q-DLL tree
node call Q-DLL(, );
edge connecting two nodes ; l, l literal.
tree representing run Q-DLL least node .
example run Q-DLL, consider QBF (4). simplicity, assume
literal returned line 5 Figure 1 negation first variable prefix
occurs matrix QBF consideration. Then, tree searched
Q-DLL (4) represented Figure 2. figure:
380

fiClause/Term Resolution Learning Quantified Boolean Formulas

{}{{x1 , y, x2 }, {x1 , y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}{}
{x1 } hx1 , li {x1 }
{{y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

{x1 } hx1 , ri {x1 }
{{y, x2 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

hy, ri {x1 }
hy, li {y}
hy, li {y}
hy, ri {x1 }
hx2 , pi{y} {x1 , y, x2 }hx2 , ui{x1 }
hx2 , pi{y} {x1 , y, x3 }hx3 , ui{x1 }
{{}} {y, x2 }
{y} {} {y}
{y, x2 }hx2 , ui{y, x3 } {y} {} {y}
{{}} {x2 , x3 }

Figure 2: tree generated Q-DLL (4). matrix (4) shown root
node, prefix x1 yx2 x3 . u, p, l, r stand unit, pure, left
split, right split respectively, obvious meaning.

node labeled literal assigned Q-DLL order extend assignment built far. Thus, assignment corresponding node sequence
labels path root node. instance, assignment corresponding node label x3 x1 ; y; x3 .
literals assigned unit monotone, corresponding nodes aligned
one other. assigned literal l, show whether l
assigned unit, monotone, left right split marking u, p, l, r
respectively.
l assigned left right split, show matrix ;l ,
sequence literals assigned l.
node leaf, matrix either empty (in case
write {} node), contains contradictory clause (in case
write {{}} node).
Considering Figure 2, easy see Q-DLL would correctly return False, meaning (4) (and thus (2)) false.
3.3 Resolution DLL Based Decision Procedures QBFs
well known correspondence SAT semantic trees resolution (see, e.g.,
Urquhart, 1995) gives us starting point analysis, aimed establish correspondence Q-DLL clause/term resolution.
Consider QBF . Let tree explored Q-DLL evaluating .
time being, assume dealing SAT problem, i.e.,
contain universal quantifiers. Then, Q-DLL reduces DLL, false
use generate clause resolution deduction empty clause . basic idea
associate node clause C -falsified, i.e.,
381

fiGiunchiglia, Narizzano & Tacchella

literal l C, l . (We say literal l assigned l1 ; . . . ; lm
l {l1 , . . . , lm }). precisely:
every leaf , associate arbitrarily selected clause matrix
-falsified. least one clause exists contains empty
clause.
C clause associated node ; l,
1. l 6 C C clause associated . Notice l monotone
l 6 C.
2. l C l unit clause associated resolvent
C arbitrarily selected clause causes l unit .
3. l C l unit consider clause C 0 associated
node ; l. l 6 C 0 C 0 clause associated (as
first case). l C 0 , clause associated resolvent C C 0 .
Lemma 1 Let QBF without universal quantifiers. Let tree searched
Q-DLL(, ). Let assignment . false, clause associated
node
-falsified;
contain existential literals whose negation assigned monotone
.
Proof. Let set assignments extend . Clearly, assignment
0 S, 0 false ( contain universal quantifiers). S, define partial
order relation according two assignments 0 00 0 00
0 extends 00 . Clearly well founded minimal elements
assignments extending corresponding leaves .
0 extends leaf , 0 contains contradictory clause C. Since
contain universal quantifiers, C 0 -falsified associated node
0 . Clearly, C contain existential literals whose negation assigned
monotone.
induction hypothesis, assignment 0 = 00 ; l 00 0 -falsified
clause containing existential literals whose negation assigned monotone.
show thesis 00 . three cases:
1. l assigned unit. Let C1 clause associated 00 ; l. induction
hypothesis, thesis holds C1 . C1 contain l, thesis trivially follows.
Otherwise, clause associated 00 resolvent C C1 clause C2
causes l unit 00 . C2 00 ; l-falsified contain existential
literals whose negation assigned monotone. C = C1 C2 \ {l, l} thus
thesis trivially holds.
2. l assigned monotone. case clause C associated 00
clause associated 00 ; l. induction hypothesis C contain l
thus C 00 -falsified.
382

fiClause/Term Resolution Learning Quantified Boolean Formulas

3. l split. case clause C1 associated 00 ; l clause C2
associated 00 ; l. thesis holds C1 C2 induction hypothesis.
C1 contain l, clause associated 00 C1 thesis
trivially holds. Otherwise, C2 contain l, clause associated
00 C2 thesis trivially holds. Otherwise, clause associated 00
C1 C2 \ {l, l} thesis trivially holds.

Theorem 7 Let false QBF without universal quantifiers. tree searched QDLL(, ) corresponds clause resolution deduction empty clause.
Proof. Let sequence clauses obtained listing clauses matrix
according arbitrary order, followed clauses associated internal nodes
tree searched Q-DLL(, ), assuming visited post order. Clearly,
deduction. deduction empty clause node associated
-falsified clause (Lemma 1), i.e., empty clause.

theorem points close correspondence computation Q-DLL
clause resolution, assuming input formula false contain
universal quantifiers. input formula contain universal quantifiers true,
still tree explored Q-DLL generating path ending empty matrix
corresponds sequence clause resolutions, one maximal subtree whose leaves
contains empty clause.
longer assume input formula contain universal quantifiers,
consider case arbitrary QBF, situation gets complicated,
possibility assigning unit literals highest level.
So, assume literal l assigned unit node , l highest
level .
Then, input formula false, use tree searched Q-DLL
generate clause resolution deduction empty clause. construction analogous
one described before. difference restrict attention
minimal false subtree , i.e., tree obtained deleting subtrees
starting left split universal literal: subtrees originated wrong
choices deciding branch explore first. minimal false subtree 0 ,
leaves terminate empty clause, associate node 0
clause exactly way described SAT case. instance, (4),
Q-DLL assigns unit literals highest level. Figure 3 shows
minimal false subtree Q-DLLs computation, associated clause resolution
deduction empty clause. figure,
clause associated node written red right node
itself;
node corresponds assignment unit literal l, clause
causes l unit node (used corresponding clause resolution) written
red left node.
383

fiGiunchiglia, Narizzano & Tacchella

{}{{x1 , y, x2 }, {x1 , y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}{}
{x1 } hx1 , li {x1 }
{{y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

{x1 } hx1 , ri {x1 }
{{y, x2 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

hy, ri {x1 }
{x1 , y, x3 }hx3 , ui{x1 }
{y, x2 }hx2 , ui{y, x3 }
{{}} {x2 , x3 }

hy, ri {x1 }
{x1 , y, x2 }hx2 , ui{x1 }
{{}} {y, x2 }

Figure 3: clause resolution corresponding tree generated Q-DLL (4).
prefix x1 yx2 x3 .

Lemma 2 Let false QBF. Let minimal false subtree tree searched
Q-DLL(, ) assume node ; l , l unit l
highest level . Let assignment . false, clause associated
node
-falsified;
contain existential literals whose negation assigned monotone
.
Proof. Trivial extension proof Lemma 1. assumption node ; l
, l unit l highest level , ensures clause associated
node -falsified.


Theorem 8 Let false QBF. Let minimal false subtree tree searched
Q-DLL(, ) assume node ; l , l unit l
highest level . corresponds clause resolution deduction empty
clause.
Proof. Given Lemma 2, proof analogous one Theorem 7.



Regardless whether input formula true false, tree explored Q-DLL
may contain (exponentially many) subtrees whose nodes false.
procedure described above, allows us associate clause resolution deduction
subtrees.
input formula true, situation simpler far unit
universal literals, use tree searched Q-DLL generate deduction
empty term . Intuitively, process analogous one described
false, except leaves term resolution deduction terms corresponding
assignments computed Q-DLL entailing matrix . details:
384

fiClause/Term Resolution Learning Quantified Boolean Formulas

First, restrict attention minimal true subtree , i.e., tree
obtained deleting subtrees starting left split existential
literal: Analogously case false, leaf minimal true
subtree terminates empty matrix.
Second, associate node term, represented set, follows:
term associated leaf minimal term min(T ) 1
1. contain universal literals assigned monotone,
2. propositionally entail matrix, i.e., clause C matrix
, C 6= ,
3. subset literals , i.e., {l : l }.
term associated node ; l,
1. l 6 term associated node . Notice l
either existential universal monotone , l 6 .
2. l consider term 0 associated node
; l. l 6 0 0 term associated (as first case).
l 0 , term associated resolvent 0 .
easy see term associated node -entailed: literal
.
Lemma 3 Let true QBF. Let minimal true subtree tree searched
Q-DLL(, ). Let assignment . true, term associated
node
-entailed;
contain universal literals assigned monotone.
Proof. Analogous proof Lemma 2.



Theorem 9 Let true QBF. Let minimal true subtree tree searched
Q-DLL(, ). corresponds model generation term resolution deduction
empty term.
Proof. Let sequence terms obtained listing terms associated
nodes visited post order. Clearly, model generation term resolution deduction. deduction empty term node associated -entailed
term (Lemma 3), i.e., empty term.

before, regardless whether input formula true false, tree explored
Q-DLL may contain (exponentially many) subtrees whose nodes associated
1. sake efficiency, important term satisfies properties. However,
necessary time being, discussed next section.

385

fiGiunchiglia, Narizzano & Tacchella

{}{{x1 , y, x2 }, {x1 , y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}{}
{x1 } hx1 , ri {x1 }
{x1 } hx1 , li {x1 }
{{y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }} {{y, x2 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}
hy, li {y}
hx2 , pi{y}
{y, x2 } {} {y}

hy, li {y}
hx2 , pi{y}
{y, x2 } {} {y}

Figure 4: term resolutions corresponding tree generated Q-DLL (4).
prefix x1 yx2 x3 .

{}{{x1 , y, x2 }, {x1 , y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}{}
{x1 } hx1 , li {x1 }
{{y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

{x1 } hx1 , ri {x1 }
{{y, x2 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

hy, li {y}
hy, li {y}
hy, ri {x1 }
hy, ri {x1 }
hx2 , pi{y} {x1 , y, x3 }hx3 , ui{x1 }
hx2 , pi{y} {x1 , y, x2 }hx2 , ui{x1 }
{y, x2 } {} {y}
{{}} {y, x2 }
{y, x2 }hx2 , ui{y, x3 } {y, x2 } {} {y}
{{}} {x2 , x3 }

Figure 5: resolution corresponding tree generated Q-DLL (4). prefix
x1 yx2 x3 .

assignments true. described procedure allows us associate
term resolution deduction subtrees. instance, (4)
two maximal subtrees, roots x1 ; x1 ; y. associated deductions
represented Figure 4. figure,
represent nodes along path root subtrees,
term associated node written green right node
itself,
leaf, non-contradictory term entailing matrix whose minimal
form min(T ) associated , written green left .
Merging trees Figures 3 4 obtain whole tree deductions corresponding search tree explored Q-DLL (represented Figure 5) clause
term resolutions intermixed.
386

fiClause/Term Resolution Learning Quantified Boolean Formulas

consider case input QBF false longer assume
literals assigned unit highest level. restrict
attention minimal false subtree tree searched Q-DLL(, ). Then,
procedure described associating clause node may longer work.
one thing, given leaf , may -falsified clauses matrix input
formula. However, guaranteed existence -contradicted clause
matrix input formula. clause C -contradicted if2
literal l C, l ;
existential literal l C, l .
long associate node -contradicted clause (either belonging
matrix obtained clause resolution) corresponds clause resolution
deduction empty clause: Indeed clause associated root
empty (remember resolvent clause resolution minimal form). Thus,
obvious solution try associate
1. leaf -contradicted clause input formula,
2. internal node -contradicted clause obtained resolving input clauses
and/or previously deduced clauses along lines outlined before.
cases process runs smoothly. Consider instance, QBF form:
x1 x2 yx3 {{x1 , x3 }, {x2 , x3 }, {x2 , y, x3 }, . . .}.

(7)

Then, assume split x1 occurs first, following path explored (we
using conventions Figure 3):
hx1 , li
hx3 , ui
hx2 , ui
{{}}

(8)

clause associated node are:
hx1 , li
{x1 , x3 } hx3 , ui
{x2 , x3 } hx2 , ui
{{}}

{x1 }
{x1 }
{y, x3 }
{x2 , y, x3 }

see that:
1. clause associated leaf = x1 ; x3 ; x2 -falsified -contradicted;

2. respect definition contradictory clause given Section 3.2, clear clause C
contradictory -contradicted. Further, QBF assignment , exists
-contradicted clause matrix , contains -contradicted clause,
contains contradictory clause.

387

fiGiunchiglia, Narizzano & Tacchella

0 function Rec-C-Resolve(, C1 , C2 , l, )
1
:= {l : l C1 , l C2 };
2
(S = ) return C-Resolve(C1 , C2 );
3
l1 := han existential literal C1 level level literals C1 }i;
4
C := ha clause causes l1 unit 0 , 0 ; l1 prefix i;
5
C3 := C-Resolve(C1 , C);
6
return Rec-C-Resolve(, C3 , C2 , l, ).
Figure 6: algorithm Rec-C-Resolve.
2. able associate node -contradicted clause.
Unfortunately, cases things run smoothly, i.e., may possible
associate clause internal node simple single resolution input and/or
previously deduced clauses. Indeed, clause resolutions may blocked
universal variables occurring clauses used resolution.
Consider instance QBF form (obtained (7) replacing clause {x2 , x3 }
{x2 , y, x3 }):
x1 x2 yx3 {{x1 , x3 }, {x2 , y, x3 }, {x2 , y, x3 }, . . .}.

(9)

Then, (8) would still valid path, corresponding clause resolutions would be:
hx1 , li
{x1 , x3 } hx3 , ui
{x2 , y, x3 } hx2 , ui . . .
{{}} {x2 , y, x3 }

(10)

possible perform clause resolution associated node
label hx2 , ui. example, clause resolution (5) may blocked
blocking universal literal l
l l ,
l C1 l C2 .
Since C1 C2 minimal form, possible C1 C2 contain
existential literal l0
level less equal level literals clause;
assigned unit.
Then, obvious solution get rid, e.g., blocking literals l C1 resolving
away C1 existential literals level lower level l.
idea behind procedure Rec-C-Resolve Figure 6. figure,
assume
1. input QBF;
388

fiClause/Term Resolution Learning Quantified Boolean Formulas

2. ; l assignment;
3. l existential literal either unit highest level ;
4. C1 clause containing l, minimal form ; l-contradicted;
5. C2 clause containing l, minimal form ; l-contradicted. Further, l unit
, C2 clause causes l unit ;
6. C-Resolve(C1 , C2 ) returns resolvent clause resolution two
clauses C1 C2 .
on, h, C1 , C2 , l, satisfies first 5 conditions, say
pair hC1 , C2 ; l-Rec-C-Resolved (in ). Given two clauses hC1 , C2
; l-Rec-C-Resolved:
1. set universal literals blocking clause resolution C1 C2
computed (line 1).
2. empty, simply return resolvent C1 C2 (line 2);
otherwise
3. pick existential literal l1 C1 minimum level C1 (line 3): l1
assigned unit earlier search, consider clause C caused
l1 assigned unit (line 4). C3 resolvent C1 C (line 5),
Rec-C-Resolve(, C3 , C2 , l, ) returned (line 6).
hC1 , C2 ; l-Rec-C-Resolved , Rec-C-Resolve(, C1 , C2 , l, ) returns minimal clause -contradicted without existential literals whose negation
assigned monotone . formally stated following lemma.
Lemma 4 Let C1 C2 two clauses hC1 , C2 ; l-Rec-C-Resolved
QBF . Rec-C-Resolve(, C1 , C2 , l, ) terminates returns clause
minimal form -contradicted;
contain existential literals whose negation assigned monotone .
proof lemma quite long reported appendix.
Assuming input QBF false, construction deduction empty
clause (associated minimal false subtree tree searched Q-DLL)
following:
every leaf , associate clause C input formula contradicted.
C clause associated node ; l,
1. l 6 C l universal C clause associated parent
; l, i.e., node . Notice l existential monotone
l 6 C.
389

fiGiunchiglia, Narizzano & Tacchella

2. l C l unit clause associated node
result Rec-C-Resolve(, C, C 0 , l, ), C 0 clause causes l
unit .
3. l C, l existential unit , consider
clause C 0 associated node ; l. l 6 C 0 C 0 clause associated
(as first case). l C 0 , clause associated node
result Rec-C-Resolve(, C, C 0 , l, ).
example, (9) reference deduction (10), blocked resolution one associated node x1 ; x3 ; x2 . Rec-C-Resolve(, {x2 , y, x3 }, {x2 , y, x3 }, x2 , x1 ; x3 )
1. line 5, resolves {x2 , y, x3 } {x1 ; x3 }, resolvent C3 min({x1 , x2 , y}) =
{x1 , x2 };
2. following recursive call Rec-C-Resolve(, {x1 , x2 }, {x2 , y, x3 }, x2 , x1 ; x3 ) line 6
returns {x1 , y, x3 }.
Thus, clause associated node are:
hx1 , li
{x1 , x3 } hx3 , ui
{x2 , y, x3 } hx2 , ui
{{}}

{x1 }
{x1 }
{x1 , y, x3 }
{x2 , y, x3 }

Notice that, reference Figure 6, choice eliminating blocking literals
C1 maintaining C2 invariant, arbitrary. Indeed, could eliminate blocking
literals C2 maintain C1 invariant. case deduction (10), amounts
eliminate universal literal {x2 , y, x3 }: resolving clause {x1 , x3 }
x3 , get resolvent {x1 , x2 }, leads following legal deduction:
hx1 , li
{x1 , x3 } hx3 , ui
(From {x2 , y, x3 }, {x1 , x3 }) {x1 , x2 } hx2 , ui
{{}}

{x1 }
{x1 }
{x1 , y, x3 }
{x2 , y, x3 }

Lemma 5 Let false QBF. Let minimal false subtree tree searched
Q-DLL(, ). Let assignment . false, clause associated
node
minimal form -contradicted;
contain existential literals whose negation assigned monotone
.
Proof. construction, clause associated leaf -contradicted.
show clause C associated internal node -contradicted,
assuming clause C 0 associated child ; l ; l-contradicted.
child ; l, assume clause C 00 associated child ; l ; l-contradicted.
390

fiClause/Term Resolution Learning Quantified Boolean Formulas

1. l 6 C 0 l universal C = C 0 . Hence, C minimal form. Since l 6 C 0
l universal, C 0 ; l-contradicted C 0 -contradicted. thesis
follows C = C 0 .
2. l C 0 l unit C =Rec-C-Resolve(, C 0 , C 00 , l, ), C 00
clause causes l unit . thesis follows Lemma 4.
3. l C, l existential unit , consider clause
C 0 associated node ; l. Assuming l C 0 (otherwise would first
case), clause associated result Rec-C-Resolve(, C, C 0 , l, ).
previous case, thesis follows Lemma 4.

Theorem 10 Let false QBF. Let minimal false subtree tree searched
Q-DLL(, ). corresponds clause resolution deduction empty clause.
Proof. Given Lemma 5, proof analogous one Theorem 7.



4. Backjumping Learning DLL Based Procedures QBFs
section first show computing resolvent associated node allows
backjump branches backtracking (Subsection 4.1). Then, show
learning resolvents allows prune search tree branches different ones
resolvents computed learned (Subsection 4.2).
4.1 Conflict Solution Directed Backjumping
procedure described Section 3.2 uses standard backtracking schema whenever
empty clause (resp. matrix) generated: Q-DLL backtrack first existential
(resp. universal) literal assigned left split. instance, given QBF
y1 x1 y2 x2 x3 {{y1 , y2 , x2 }, {y1 , 2 , x2 , x3 }, {y1 , x2 , x3 },
{y 1 , x1 , x3 }, {y 1 , y2 , x2 }, {y 1 , y2 , x2 }, {y 1 , x1 , 2 , x3 }},

(11)

tree searched Q-DLL represented Figure 7, use conventions
Section 3.
2001 work Giunchiglia, Narizzano, Tacchella (2001), shown
exploration branches necessary. particular, input QBF
assignment, show possible compute reason (un)satisfiability
backtracking. Intuitively speaking, reason result subset
literals assignment 0
assigns true false literals assigned (i.e., {|l| :
l 0 } = {|l| : l });
extends (i.e., {l : l 0 }),
391

fiGiunchiglia, Narizzano & Tacchella

{}
{{y1 , y2 , x2 }, {y1 , 2 , x2 , x3 }, {y1 , x2 , x3 },
{y 1 , x1 , x3 }, {y 1 , y2 , x2 }, {y 1 , y2 , x2 }, {y 1 , x1 , 2 , x3 }}
{y 1 }hy 1 , li{y 1 }
{{y2 , x2 }, {y 2 , x2 , x3 }, {x2 , x3 }}
hy 2 , li{y 1 }
{y 1 , 2 , x2 }hx2 , ui{y 1 }
{y 1 , x2 , x3 }hx3 , ui{y 1 }
{y 1 , x2 , x3 } {} {y 1 }

hy1 , ri{}
{{x1 , x3 }, {y2 , x2 }, {y2 , x2 }, {x1 , 2 , x3 }}

hy2 , ri
{{x2 , x3 }, {x2 , x3 }}
hx2 , li
hx3 , ui
{}

hx1 , li{}
{y 1 , x1 , x3 }hx3 , ui{}
hy 2 , pi{}
{y 1 , y2 , x2 }hx2 , ui{}
{{}} {y 1 , y2 , x2 }

hx1 , ri
hx3 , pi
hy 2 , pi
hx2 , ui
{{}}

Figure 7: resolution corresponding tree generated Q-DLL (11). prefix
y1 x1 y2 x2 x3 .

0 equivalent . Then, computing reasons, avoid right split
literal l l reason: assigning l false would change result.
resulting procedure generalization QBF popular Conflict-directed Backjumping
(CBJ) (Prosser, 1993b), introduces concept Solution-directed Backjumping
(SBJ), avoiding useless splits universal variables.
later paper, Giunchiglia, Narizzano, Tacchella (2003) show possible
optimize computation reasons. particular, paper, shown
assuming unsatisfiable, consider reasons subset existential
literals ,
assuming satisfiable, consider reasons subset universal
literals .
Apart optimizations, tree searched procedures described former
latter papers same, and, case (11), exploration branches
starting hy2 , ri, hx1 , ri skipped (see Figure 7).
show computation resolutions corresponding Q-DLL allows
avoid exploration branches pretty much CBJ SBJ do: case
QBF (11), branches skipped skipped CBJ SBJ.
key point think Q-DLL procedure producing clause (resp. term)
deduction empty clause (resp. term), proving unsatisfiable (resp. satisfiable).
Then, according rules use associating deduction tree searched QDLL, that:
C clause associated node ; l l 6 C, clause associated
node C, even l existential assigned left split.
392

fiClause/Term Resolution Learning Quantified Boolean Formulas

0 function Q-DLL-BJ(, )
1
(ha clause C -contradictedi)
2
return C;
3
(hthe matrix emptyi) return ModelGenerate();
4
(hl unit i)
5
C := ha clause matrix causes l unit i;
6
W R := Q-DLL-BJ(, ; l);
7
(hW R termi l 6 W R) return W R;
8
return Rec-C-Resolve(, W R, C, l, );
9
(hl monotone i) return Q-DLL-BJ(, ; l);
10
l := ha literal highest level i;
11
W R := Q-DLL-BJ(, ; l);
12
(hl existentiali (hW R termi l 6 W R)) return W R;
13
(hl universali (hW R clausei l 6 W R)) return W R;
14
W R0 := Q-DLL-BJ(, ; l);
15
(hl existentiali (hW R0 termi l 6 W R0 )) return W R0 ;
16
(hl universali (hW R0 clausei l 6 W R0 )) return W R0 ;
17
(hl existentiali) return Rec-C-Resolve(, W R0 , W R, l, );
18
return T-Resolve(W R0 , W R, l, ).
Figure 8: algorithm Q-DLL-BJ.
Analogously, term associated node ; l l 6 , term
associated node , even l universal assigned left
split.
rules take account clause/term associated node ; l,
thus need explore branch starting ; l.
Consider example Figure 7, use standard conventions and, e.g., write
clause (resp. term) associated node red (resp. green) right
node. reference figure, clear considering term {y 1 } associated
node 1 ; 2 , need explore branch starting hy2 , ri order
associate 1 -entailed term node 1 . Similarly, considering empty clause {}
associated node y1 ; x1 , need explore branch starting
hx1 , ri order associate y1 -contradicted clause node y1 .
procedure Q-DLL-BJ(, ) Figure 8 incorporates ideas. figure,
ModelGenerate() returns minimal form non-contradictory -entailed
term
clause C , C 6= ;
universal literal l assigned monotone, l 6 .
Rec-C-Resolve(, C1 , C2 , l, ) Figure 6.
393

fiGiunchiglia, Narizzano & Tacchella

T-Resolve(T1 , T2 ) returns resolvent term resolution two terms
T1 T2 .
behavior Q-DLL-BJ illustrated words saying Q-DLL-BJ(, )
computes returns clause/term would associated node tree
explored Q-DLL. particular, assuming
W R clause (resp. term) returned Q-DLL-BJ(, ; l);
l existential (resp. universal);
l assigned left split,
Q-DLL-BJ(, ) explore branch starting ; l l 6 W R (resp. l 6 W R),
see line 12 (resp. line 13) Q-DLL-BJ.
far, reference Figure 7, interpret clause (resp. term) red
(resp. green) right node value returned Q-DLL-BJ(, ). Then,
considering term {y 1 } associated node 1 ; 2 , Q-DLL-BJ explore
branch starting hy2 , ri. Similarly, considering empty clause {} associated
node y1 ; x1 , Q-DLL-BJ explore branch starting hx1 , ri.
Theorem 11 Q-DLL-BJ(, ) returns empty clause false, empty term
true.
Proof.(Sketch) enough notice that:
node associated clause C, C -contradicted, C result
sequence clause resolutions.
node associated term , -entailed, result
sequence model generations term resolutions.
Then, previous section:
empty clause associated initial node , false.
empty term associated initial node , true.



4.2 Learning
Learning well known technique SAT avoiding useless traversal branches.
SAT, learning amounts storing (clause) resolvents associated nodes tree
explored DLL: resolvents called nogoods simply added set
input clauses.
case QBFs, situation different complicated. Indeed,
two types resolutions (term clause), resolvents clause resolutions
added conjunctively matrix, resolvents term resolutions (that
call goods) considered disjunction matrix.
practice, handle three sets formulas:
394

fiClause/Term Resolution Learning Quantified Boolean Formulas

set terms corresponding goods learned search;
set clauses corresponding matrix input QBF;
set clauses corresponding nogoods learned search.
Formally, QBF form (1), QBF Extended Learning (EQBF)
expression form
Q1 z1 . . . Qn zn h, ,
(n 0)
(12)

set terms, called goods, interpreted disjunctively. good
obtained model generation and/or term resolution ;
set clauses, called nogoods, interpreted conjunctively. nogood
obtained clause resolution .
Clearly,
Q1 z1 . . . Qn zn ( )

Q1 z1 . . . Qn zn ( )
equivalent (1).
Initially empty set, input set clauses. search
proceeds,
Nogoods determined backtracking contradiction (i.e., assignment unsatisfiable) possibly added ;
Goods determined backtracking solution (i.e., assignment
satisfiable) possibly added .
following, use term constraints want refer goods
nogoods indifferently.
Consider EQBF (12). constraints and/or , search
pruned considerably. Indeed, descending search tree, literal assigned
long guaranteed reconstruct valid clause/term deduction
backtracking empty clause/term. availability already derived clauses/terms
allows prune search constraints : Given assignment ,
exists -contradicted clause C (resp. -satisfied term ) stop
search return C (resp. ). term -satisfied
literal l , l ;
universal literal l , l .
Clearly, -entailed term -satisfied. Further, extend notion unit
take account constraints and/or . literal l
unit EQBF (12)
395

fiGiunchiglia, Narizzano & Tacchella

0 function Rec-Resolve(, W1 , W2 , l, )
1
:= {l : l W1 , l W2 };
2
(S = ) return Resolve(W1 , W2 );
3
l0 := ha literal W1 level level literals W1 }i;
4
W := ha constraint causes l0 unit 0 , 0 ; l0 prefix i;
5
W3 := Resolve(W1 , W );
6
return Rec-Resolve(, W3 , W2 , l, ).
Figure 9: algorithm Rec-Resolve.
either l existential 0,
clause {l, l1 , . . . , lm } belongs ,
expression |li | (1 m) occurs right |l| prefix
(12).
l universal 0,
term {l, l1 , . . . , lm } belongs ,
expression |li | (1 m) occurs right |l| prefix
(12).
definition monotone literals, crucial property ensured
dealing EQBFs, existential (resp. universal) literal l assigned monotone
; l never enter nogood (resp. good) associated node extending ; l.
guaranteed defining literal l monotone pure if3
either l existential l belong constraint ;
l universal l belong constraint .
possibility assigning universal literals unit, may case
term resolutions may blocked existential literals l l,
occurring one terms used antecedents term resolution. However,
procedure Rec-C-Resolve presented Subsection 3.3 easily generalized
work case constraints resolved terms. result
procedure Rec-Resolve(, W1 , W2 , l, ) Figure 9, assumed
1. EQBF;
3. various ways guarantee existential literal l assigned monotone ; l
enter nogood associated node extending ; l. Another one
keep definition existential monotone literal unchanged: existential literal assigned
monotone (12) l belong clause ;
update (or proceed search updated to) \ {C : C , l C}.
Analogously universal monotone literals. See work Giunchiglia, Narizzano Tacchella (2004a) details possibilities, including discussion interaction
monotone rule learning.

396

fiClause/Term Resolution Learning Quantified Boolean Formulas

2. ; l assignment;
3. l existential (resp. universal) literal either unit highest level
;
4. W1 clause (resp. term) containing l (resp. l), minimal form ; l-contradicted
(resp. ; l-satisfied);
5. W2 clause (resp. term) containing l (resp. l), minimal form ; l-contradicted
(resp. ; l-satisfied). Further, l unit , W2 clause (resp. term)
causes l unit ;
6. existential (resp. universal) literal l0 assigned unit 0 ; l0 , 0 ; l0
prefix ; l, clause (resp. term) causes l0 unit
0 .
7. Resolve(W1 , W2 ) returns C-Resolve(W1 , W2 ) (resp. T-Resolve(W1 , W2 )).
h, W1 , W2 , l, satisfy first 6 7 conditions, say pair hW1 , W2
; l-Rec-Resolved (in ).
above, (12), l defined EQBF obtained
removing (resp. ) clauses C (resp. terms ) l C (resp.
l ), removing l (resp. l) clauses (resp. terms
);
removing Q|l| prefix.
= l1 ; l2 ; . . . ; lm (m 0), defined (. . . ((l1 )l2 ) . . .)lm .
hW1 , W2 ; l-Rec-Resolved , Rec-Resolve(, W1 , W2 , l, ) returns
constraint minimal form -contradicted -satisfied, stated following
lemma.
Lemma 6 Let W1 W2 two clauses (resp. terms) hW1 , W2 ; lRec-Resolved EQBF . Rec-Resolve(, W1 , W2 , l, ) terminates returns minimal
clause (resp. term)
-contradicted (resp. -satisfied);
contain existential literals whose negation (resp. universal literals
been) assigned monotone .
Proof.(Sketch) proof equal (resp. analogous to) proof Lemma 4 l
existential (resp. universal).

procedure Q-DLL-LN (, ) incorporates new definitions ideas,
represented Figure 10. Considering figure,
definition ModelGenerate() relaxed respect definition provided Subsection 4.1 order return minimal form non-contradictory
-satisfied term
397

fiGiunchiglia, Narizzano & Tacchella

0 := {};
1 := {};
2 function Q-DLL-LN (, )
3
Q := hthe prefix i;
4
:= hthe matrix i;
5
(ha -contradicted clause C i)
6
return C;
7
(ha -satisfied term i)
8
return ;
9
(hthe matrix emptyi) return ModelGenerate();
10
(hl unit (Qh, , i) i)
11
W := ha constraint causes l unit (Qh, , i) i;
12
W R := Q-DLL-LN (, ; l);
13
(hl existentiali (hW R termi l 6 W R)) return W R;
14
(hl universali (hW R clausei l 6 W R)) return W R;
15
W R := Rec-Resolve(Qh, , i, W R, W, l, );
16
Learn(, W R);
17
return W R;
18
(hl monotone (Qh, , i) i) return Q-DLL-LN (, ; l);
19
l := ha literal highest level i;
20
W R := Q-DLL-LN (, ; l);
21
(hl existentiali (hW R termi l 6 W R)) return W R;
22
(hl universali (hW R clausei l 6 W R)) return W R;
23
W R0 := Q-DLL-LN (, ; l);
24
(hl existentiali (hW R0 termi l 6 W R0 )) return W R0 ;
25
(hl universali (hW R0 clausei l 6 W R0 )) return W R0 ;
26
W R := Rec-Resolve(Qh, , i, W R0 , W R, l, );
27
Learn(, W R);
28
return W R.
Figure 10: algorithm Q-DLL-LN.
clause C , C 6= ;
universal literal l assigned monotone, l 6 .
Learn(, W R) updates set goods nogoods according given policy.
simply assume Learn(, W R) updates 0 0 respectively,
0 0 satisfy following conditions:
0 subset {W R} W R term, otherwise;
0 subset {W R} W R clause, otherwise;
existential (resp. universal) literal l assigned unit initial prefix
0 ; l , 0 (resp. 0 ) still contains clause (resp. term) causes l
assigned unit (Qh0 , , 0 i)0 .
398

fiClause/Term Resolution Learning Quantified Boolean Formulas

reference Figure 9, last condition necessary order guarantee
existence constraint W satisfying condition line 4.
conditions Learn(, W R) general ensure soundness
completeness Q-DLL-LN.
Theorem 12 Q-DLL-LN(, ) returns empty clause false, empty term
true.
Proof. Analogous proof Theorem 11.



understand benefits learning, assume input QBF (4). corresponding
EQBF
x1 yx2 x3 h{}, {{x1 , y, x2 }, {y, x2 }, {x2 , x3 }, {x1 , y, x3 }, {y, x2 , x3 }}, {}i,
search proceeds Figure 2, first path leading empty matrix,
starts term resolution process. Assuming term min({y, x2 }) = {y} added
set goods checking value x1 ;y , soon x1 assigned true,
detected unit correspondingly assigned;
path corresponding assignment x1 ; explored.
example shows, (good) learning avoid useless exploration branches
would explored backtracking backjumping schema. Indeed,
assuming deduced term learned backtracking. policy according
Learn(, W R) simply adds W R
W R clause;
otherwise,
easily implemented. However, simple policy may easily lead store exponential number goods and/or nogoods (notice call Learn(, W R)
literal assigned unit right split). Thus, practical implementations incorporate
policies guaranteed space bounded, i.e., ones store polynomial number goods
nogoods most. SAT, three popular space bounded learning schemes are:
Size learning order n (Dechter, 1990): nogood added
cardinality less equal n. added, never deleted.
Relevance learning order n (Ginsberg, 1993): given current assignment ,
nogood C always added , deleted soon number
literals l C l 6 bigger n.
Unique Implication Point (UIP) based learning (Marques-Silva & Sakallah, 1996):
nogood C stored C contains one literal maximum decision
level. Given assignment , decision level literal l number
splits done l . UIP based learning, set added clauses
periodically inspected clauses deleted according various criteria.
399

fiGiunchiglia, Narizzano & Tacchella

Thus, size learning, nogood stored, never deleted. relevance UIP
based learning, nogoods dynamically added deleted depending current assignment. See work Bayardo (1996) details related size relevance
learning (including complexity analysis), work Zhang, Madigan, Moskewicz
Malik (2001) discussion various UIP based learning mechanisms SAT. Size,
relevance, UIP based learning various possibilities limiting
number stored clauses, one generalized various ways considering
QBFs instead SAT formulas. next section, present particular learning
schema implemented QuBE.

5. Implementation Experimental Analysis
section first describe details implementation nogood good
learning QuBE, report experimental analysis conducted order
evaluate (separate) benefits nogood good learning, relative efficiency
solver compared state-of-the-art QBF solvers.
5.1 Implementation QuBE
evaluate benefits deriving learning, implemented good nogood learning QuBE. QuBE QBF solver based search which, non-random
instances, compares well respect state-of-the-art solvers based search,
semprop (Letz, 2002), yquaffle (Zhang & Malik, 2002a), i.e., best solvers based
search non-random instances according (Le Berre, Simon, & Tacchella, 2003),
see (Giunchiglia, Narizzano, & Tacchella, 2004c) details.
Besides learning, version QuBE used features
efficient detection unit monotone literals using lazy data structures (Gent,
Giunchiglia, Narizzano, Rowley, & Tacchella, 2004);
branching strategy exploits information gleaned input formula initially,
leverages information extracted learning phase.
See (Giunchiglia, Narizzano, & Tacchella, 2004b) description characteristics.
learning, computation nogoods goods corresponding internal
nodes search tree carried clause term resolution
working reason initialized backtracking starts, reasons stored
descending search tree
unit literal, stored reason constraint literal unit;
literal assigned right split, stored reason constraint computed
backtracking left branch;
monotone literals, way working reasons initialized ensures existential
(resp. universal) monotone literals never belong working reason computed
backtracking contradiction (resp. solution).
400

fiClause/Term Resolution Learning Quantified Boolean Formulas

Assume = l1 ; l2 ; . . . ; lm assignment corresponding leaf consideration. Considering problem initializing working reason, way
QuBE
return -contradicted clause matrix input QBF set learned
nogoods, contradiction;
compute minimal form -satisfied prime implicant matrix contains universal literals possible, solution.
second case, computation prime implicant important order short
reasons, possible universal literals important order backjump
nodes. requirements met recursively removing irrelevant literals
set literals , starting universals ones. Given set literals, say
literal irrelevant clause C matrix l C exists another
literal l0 l0 V
C. prime() set literals result recursive
procedure, term prime()
satisfied ;
prime implicant matrix input QBF;
exist another term satisfying first two properties
smaller (under set inclusion) set universal literals.
order reduce number universal literals initial goods, take
advantage fact assignment may partial: literal l may
case neither l l . Then, use existential literals ,
level lower level universal literals assigned left split,
order reduce number universals prime(). fact, sequence 0
literals extending existential literals, set universals prime(0 ) subset
prime(). instance, considering QBF (11) = 1 ; y2 ; x2 ; x3 ,
prime() {y 1 , y2 , x2 , x3 };
extend 0 = ; x1 prime(0 ) {x1 , y2 , x2 , x3 }.
Finally, evaluating universal literals irrelevant, follow reverse
order assigned, order try backjump high possible
search tree.
said previous section, besides problem setting initial working
reason, another problem learning unconstrained storage clauses (resp. terms)
obtained reasons conflicts (resp. solutions) may lead exponential memory
blow up. practice, necessary introduce criteria
1. limiting constraints learned; and/or
2. unlearning them.
401

fiGiunchiglia, Narizzano & Tacchella

implementation learning QuBE works follows. Assume backtracking
literal l assigned decision level n. constraint corresponding reason
current conflict (resp. solution) learned following conditions satisfied:
1. l existential (resp. universal);
2. assigned literals reason except l, decision level strictly lower
n;
3. open universal (resp. existential) literals reason l
prefix.
Notice three conditions ensure l unit constraint corresponding
reason. QuBE learned constraint, backjumps node
maximum decision level among literals reason, excluding l. say l
Unique Implication Point (UIP) therefore lookback QuBE UIP based.
Notice definition UIP generalizes QBF concepts first described Silva
Sakallah (1996) used SAT solver grasp. SAT instance, QuBE lookback
scheme behaves similarly 1-UIP-learning scheme used zCHAFF (and described
Zhang et al., 2001). Even QuBE guaranteed learn one clause (resp. term)
per conflict (resp. solution), still number learned constraints may blow up,
number backtracks exponential. stop course, QuBE scans periodically
set learned constraints search became irrelevant, i.e., clauses (resp.
terms) number open literals exceeds parameter n, corresponding
relevance order. Thus, implementation uses UIP based learning decide store
constraint, relevance based criteria decide forget constraint.
experimental analysis presented next subsection, parameter n set 20
set learned constraints scanned every 5000 nodes.
Besides learning mechanism, current version QuBE features lazy data
structures unit literal detection propagation (as described Gent et al., 2004),
monotone literal fixing (as described Giunchiglia et al., 2004a), Variable State Independent Decaying Sum heuristic (VSIDS) (as introduced SAT Moskewicz, Madigan,
Zhao, Zhang, & Malik, 2001). SAT, basic ideas heuristic (i) initially
rank literals basis occurrences matrix, (ii) increment weight
literals learned constraints, (iii) periodically divide constant weight
literal.
5.2 Experimental Results
evaluate effectiveness implementation, considered 450 formal verification planning benchmarks constituted part 2003 QBF solvers comparative
evaluation4 : 25% instances comes verification problems (described Scholl
& Becker, 2001; Abdelwaheb & Basin, 2000), remaining planning domains (described Rintanen, 1999; Castellini, Giunchiglia, & Tacchella, 2001). start
analysis considering QuBE without learning enabled. versions QuBE
4. respect non-random instances used 2003 QBF comparative evaluation, test set
include QBF encodings modal K formulas submitted Pan Vardi (2003).

402

fiClause/Term Resolution Learning Quantified Boolean Formulas

Figure 11: Effectiveness learning: QuBE versus QuBE(cbj,sbj). CPU time (left)
number backtracks instances solved solvers (right).

compute goods nogoods order backjump irrelevant existential universal
branching nodes. differ treatment computed goods nogoods:
learning enabled, QuBE records goods nogoods;
learning disabled, QuBE records neither nogoods goods.
call two versions QuBE(cln,sln) QuBE(cbj,sbj) respectively, order
specify type look-back used two systems. Notice consider
QuBE backtracking (i.e., version computes neither nogoods goods
performs simple chronological backtracking) competitive
solvers.
experiments run farm identical PCs, one equipped
Pentium 4, 3.2GHz processor, 1GB RAM, running Linux Debian (sarge). Finally,
system timeout value 900s per instance.
Figure 11 left shows performances QuBE(cln,sln) versus QuBE(cbj,sbj).
plot, x-axis CPU-time QuBE(cln,sln) y-axis CPU-time
QuBE(cbj,sbj). plotted point hx, yi represents benchmark QuBE(cln,sln)
QuBE(cbj,sbj) take x seconds respectively.5 convenience, plot
points hx, xi, representing benchmarks solved QuBE(cln,sln) x seconds.
first observation learning pays off:
5. principle, one point hx, yi could correspond many benchmarks solved QuBE(cln,sln)
QuBE(cbj,sbj) x seconds respectively. However, scatter diagrams
present, point (except point h900, 900i, representing instances solvers
time-out) corresponds single instance cases.

403

fiGiunchiglia, Narizzano & Tacchella

Figure 12: Effectiveness learning random heuristic: QuBE(rnd,cln,sln)[3] versus QuBE(rnd,cbj,sbj)[3]. CPU time (left) number backtracks
instances solved solvers (right).

QuBE(cln,sln) (resp. QuBE(cbj,sbj)) able solve 16 (resp. 1) instances
solved QuBE(cbj,sbj) (resp. QuBE(cln,sln));
among instances solved solvers, QuBE(cln,sln) (resp. QuBE(cbj,sbj))
least one order magnitude faster QuBE(cbj,sbj) (resp. QuBE(cln,sln))
39 (resp. 0) instances.
order implementation-quality independent measure pruning introduced
learning, right plot figure shows number backtracks (i.e., number
solutions conflicts found) QuBE(cbj,sbj) versus QuBE(cln,sln) 358
problems solved systems. plotted point hx, yi represents benchmark
solved QuBE(cln,sln) QuBE(cbj,sbj) performing x backtracks
respectively. seen, learning substantially prunes search space:
point diagonal, meaning never case QuBE(cbj,sbj) performs
less backtracks QuBE(cln,sln).6 Still, learning overhead, thus
pruning caused learning always pays terms speed, proved
points diagonal left plot.
experimental data entirely satisfactory two reasons.
First, learning heuristic tightly coupled QuBE: Whenever QuBE learns
constraint, increments score literals it. QuBE(cbj,sbj) constraint
6. imply tree searched QuBE(cln,sln) subtree tree searched
QuBE(cbj,sbj): Indeed, literal selected branching node two systems guaranteed
same.

404

fiClause/Term Resolution Learning Quantified Boolean Formulas

Figure 13: Effectiveness conflict learning:
QuBE(rnd,cln,sln)[3] versus
QuBE(rnd,cbj,sln)[3]. CPU time (left) number conflict backtracks
instances solved solvers (right).

ever learned. consequence, QuBE(cbj,sbj), (i) literals initially sorted
basis occurrences input QBF, (ii) score literal periodically
halved becomes 0. literals score 0, literals prefix
level chosen according lexicographic order.
Second, independently heuristic used, plot showing performances
QuBE without learning, say two learning schemes (conflict,
solution) effective (Gent & Rowley, 2004).
address first problem, consider QuBE random heuristic, i.e., heuristic
randomly selects literal among maximum level yet assigned.
call resulting systems QuBE(rnd,cln,sln) QuBE(rnd,cbj,sbj) respectively:
names suggest, first learning enabled, second learning
disabled. randomness, run solver 5 times instance. Then,
define QuBE(rnd,cln,sln)[i] system whose performances are,
instance, i-th best among 5 results obtained running QuBE(rnd,cln,sln)
instance. QuBE(rnd,cbj,sbj)[i] defined analogously.
Figure 12 shows CPU time (left) number backtracks solved instances
(right) QuBE(rnd,cln,sln)[3] QuBE(rnd,cbj,sbj)[3]. plots, easy
see QuBE(rnd,cln,sln)[3] faster QuBE(rnd,cbj,sbj)[3] cases.
witness fact
QuBE(rnd,cln,sln) (resp. QuBE(rnd,cbj,sbj)) able solve 21 (resp. 2) instances solved QuBE(cbj,sbj) (resp. QuBE);
405

fiGiunchiglia, Narizzano & Tacchella

Figure 14: Effectiveness solution learning:
QuBE(rnd,cln,sln)[3] versus
QuBE(rnd,cln,sbj)[3]. CPU time (left) number solution backtracks instances solved solvers (right).

among instances solved solvers, QuBE (resp. QuBE(cbj,sbj)) least
one order magnitude faster QuBE(cbj,sbj) (resp. QuBE) 68 (resp. 2)
instances.
Still, longer case enabling learning always causes reduction number
backtracks. different literals selected branching node,
pruning node may prevent long backjump (Prosser, 1993a)
would cause vast reduction search space. Interestingly, comparing results
Figure 11, seems random heuristic learning becomes important.
fact witnesses setting well known tension look-ahead look-back
techniques: smart look-ahead makes look-back less important, viceversa.
address second problem, considered systems QuBE(rnd,cbj,sln)
QuBE(rnd,cln,sbj), i.e., systems obtained QuBE(rnd,cln,sln) disabling
conflict learning solution learning respectively. usual, system run 5 times
instance, QuBE(rnd,cbj,sln)[i] QuBE(rnd,cln,sbj)[i] (1 5)
defined before. left plots Figures 13 14 show performances
QuBE(rnd,cln,sln)[3] versus QuBE(rnd,cbj,sln)[3] QuBE(rnd,cln,sbj)[3] respectively. measured number backtracks. However, order better
highlight pruning due conflict (resp. solution) learning, right plot Figure 13
(resp. 14) shows number conflict (resp. solution) backtracks QuBE(rnd,cbj,sln)[3]
(resp. QuBE(rnd,cln,sbj)[3]). plots, see conflict solution
learning prune search space pay off: plot, points
well diagonal. Comparing two left plots, see that, test set
406

fiClause/Term Resolution Learning Quantified Boolean Formulas

QuBE(rnd,cln,sln)[3]
QuBE(rnd,cln,sln)[1]
QuBE(rnd,cln,sln)[2]
QuBE(rnd,cln,sln)[4]
QuBE(rnd,cln,sln)[5]
QuBE(rnd,cbj,sbj)[1]
QuBE(rnd,cbj,sbj)[2]
QuBE(rnd,cbj,sbj)[3]
QuBE(rnd,cbj,sbj)[4]
QuBE(rnd,cbj,sbj)[5]
QuBE(rnd,cbj,sln)[1]
QuBE(rnd,cbj,sln)[2]
QuBE(rnd,cbj,sln)[3]
QuBE(rnd,cbj,sln)[4]
QuBE(rnd,cbj,sln)[5]
QuBE(rnd,cln,sbj)[1]
QuBE(rnd,cln,sbj)[2]
QuBE(rnd,cln,sbj)[3]
QuBE(rnd,cln,sbj)[4]
QuBE(rnd,cln,sbj)[5]

=
136
169
156
109
131
137
123
110
84
130
133
129
115
86
135
151
169
141
103

<
0
0
203
244
145
164
192
205
222
96
134
169
209
245
78
110
134
183
218

>
225
192
0
0
72
43
25
17
10
128
82
48
20
6
142
90
39
11
2


0
0
2
8
13
17
21
29
45
7
12
15
17
24
6
10
19
26
38


3
1
0
0
7
2
2
2
2
5
5
3
1
1
4
4
1
0
0

./
86
88
89
89
82
87
87
87
87
84
84
86
88
88
85
85
88
89
89

10<
0
0
27
61
27
43
68
83
99
20
27
40
54
87
7
15
29
51
69

0.1>
43
19
0
0
20
7
2
1
1
26
14
5
1
0
36
15
5
0
0


86
88
91
97
95
104
108
116
132
91
96
101
105
112
91
95
107
115
127

Table 2: Comparison among various versions QuBE. row compares system written first column respect QuBE(rnd,cln,sln)[3] taken reference.
QuBE(rnd,cln,sln)[3] B solver first column,
columns report number problems that: =, B solve
time; <, B solve takes less time B; >, B solve
takes time B; , solves B not; , solve
B does; ./, B solve; 10<, B solve
least one order magnitude faster; 0.1<, B solve
least one order magnitude slower; TO, B solve.
number timeouts QuBE(rnd,cln,sln)[3] 89.
considered, solution learning helps solving problems conflict learning:
QuBE(rnd,cbj,sln)[3] times 101 QuBE(rnd,cln,sbj)[3] times 107.
hand, two right plots suggest conflict learning prunes solution learning, conclusion correct. Indeed, plot shows either number
conflicts number solutions: Pruning node (no matter whether existential
universal) may avoid finding (exponentially many) solutions and/or conflicts. particular,
given instances CNF thus form
. . . yx1 x2 . . . xn
(n 1) pruning variable {x1 , x2 , . . . , xn } potential prune 2n conflicts.
407

fiGiunchiglia, Narizzano & Tacchella

detailed quantitative information CPU times reported Table 2. last column table see that, indicate TO(S)
number timeouts system S, then, {1, 2, 3, 4, 5},
TO(QuBE(rnd,cln,sln)[i]) <

TO(QuBE(rnd,cbj,sln)[i])
< TO(QuBE(rnd,cbj,sbj)[i]).
TO(QuBE(rnd,cln,sbj)[i])

gives indication capacity solvers, i.e., ability solve
problems. order get indication productivity, i.e., considering problems
solve, ability solve quickly, consider number FS(S)
difference 0.1 > 10 < columns: lower FS(S) is, better
is.
FS(QuBE(rnd,cln,sln)[i]) <

FS(QuBE(rnd,cbj,sln)[i])
< FS(QuBE(rnd,cbj,sbj)[i])
FS(QuBE(rnd,cln,sbj)[i])

{1, 2, 3, 4, 5}. above, clear conflict solution learning
allow improve capacity productivity. experimental results thus seem
contradict negative results reported Gents Rowleys work (2004) solution
based look-back mechanisms. However, results comparable ours, given
different mechanisms implemented respective solvers (e.g., computing
initial solution monotone literal fixing), different experimental setting (e.g.,
testset).

6. Conclusions Related Work
paper based extends (Giunchiglia et al., 2002) introduces nogood
good learning QBFs satisfiability. show correspondence computation trees searched DLL based QBF solvers clause/term resolution deductions.
Nogoods goods clauses terms respectively resolution deductions.
perspective, learning simply amounts storing nogoods goods. show
incorporate nogoods goods learning DLL based QBF solvers considering
EQBFs (QBFs extended learning), illustrate means examples
computation nogoods goods:
allows solution conflict directed backjumping spirit (Giunchiglia et al.,
2001, 2003);
stored, allows pruning branches parts search tree.
present high level description algorithms incorporating ideas, formally
prove soundness completeness. discuss problems related effective
implementations DLL based QBF solvers, present (in details) implementation QuBE, state-of-the-art QBF solver. experimental analysis shows QuBE
enhanced nogood good learning effective, considering selection
nonrandom problems consisting planning formal verification benchmarks.
show QuBE competitive respect state art.
408

fiClause/Term Resolution Learning Quantified Boolean Formulas

already said, work builds (Giunchiglia et al., 2002). papers dealing
learning QBFs satisfiability (Letz, 2002), (Zhang & Malik, 2002a) (Gent &
Rowley, 2004). particular, (Letz, 2002) conflict solution learning called lemma
model caching. paper proposes technique based model caching dealing QBFs variable-independent subformulas. Zhang Malik (2002a) propose
conflict learning (which extended solution learning Zhang & Malik, 2002b).
second paper, terms called cubes. Gent Rowley (2004) introduce new form
solution learning: new technique revisits less solutions standard techniques,
experimental results reported paper positive. works share
intuitions thus propose similar techniques. Though difficult establish
precise relation among works due differences terminology and/or
different level detail presentations,7 believe main differences
implementation level, i.e., way solution conflict learning implemented.
therefore quite difficult impossible compare different alternatives, without
re-implementing recasting different learning mechanisms even different solvers
common framework. Indeed, specific learning mechanism implemented within
solver may motivated characteristics solver, e.g., data structures used heuristic. instance, watched data structures (used, e.g.,
QuBE, yquaffle semprop) allow efficient detection propagation unit pure literals (Gent et al., 2004). consequence, solvers watched
data structures may profitably maintain huge databases goods nogoods. solvers
standard data structures, costs involved managing huge databases may
overwhelm advantages. Considering solvers whole, experimental
analysis conducted (Giunchiglia et al., 2004c) shows solver QuBE compares
well respect semprop yquaffle 450 formal verification planning
benchmarks considered paper.

Acknowledgments
would thank Ian Gent Andrew Rowley discussions related subject
paper, anonymous reviewers suggestions corrections. work
partially supported MIUR.

Appendix A. Proof Lemma 4
proof well founded induction. Thus, steps follow are:
1. definition well founded order tuples hC1 , C2 , l, i;
2. proof thesis holds minimal elements partial order;
3. assuming thesis holds tuples hC3 , C2 , l, hC3 , C2 , l,
hC1 , C2 , l, i, proof thesis holds hC1 , C2 , l, i.
7. instance, (Letz, 2002; Zhang & Malik, 2002b) initial work (Giunchiglia et al.,
2002), method used computing initial working reason corresponding solution (procedure
ModelGenerate Figure 10) detailed.

409

fiGiunchiglia, Narizzano & Tacchella

deliberately omitted properties elements tuples
hC1 , C2 , l, partial order satisfy. Indeed, standard assumption would
C1 C2 two clauses hC1 , C2 ; l-Rec-C-Resolved. However,
sufficient. Indeed, may happen starting two clauses hC1 , C2
; l-Rec-C-Resolved (line numbers refer Figure 6)
1. set {l : l C1 , l C2 , l universal} empty (see line 1);
2. clause C3 computed line 5 Figure 6 ; l-contradicted; thus
3. tuple hC3 , C2 , l, element partial order.
better understand problem, consider following simple example:
x1 y1 x2 y2 x3 x4 {{x4 }, {x2 , y2 , x4 }, {y 2 , x3 }, {x1 , 1 , x3 }, {x1 , y1 , x2 , x3 }}.

(13)

QBF :
1. x4 ; x2 ; y2 ; x3 ; x1 assignment producing contradictory clause;
2. h{x1 , y1 , x2 , x3 },{x1 , 1 , x3 }i x4 ; x2 ; y2 ; x3 ; x1 -Rec-C-Resolved;
3. Rec-C-Resolve(, {x1 , y1 , x2 , x3 }, {x1 , 1 , x3 }, x1 , x4 ; x2 ; y2 ; x3 ; x1 ),
(a) causes call Rec-C-Resolve(, {x1 , y1 , y2 , x4 }, {x1 , 1 , x3 }, x1 , x4 ; x2 ; y2 ; x3 ; x1 ),
clause C3 = {x1 , y1 , y2 , x4 } x4 ; x2 ; y2 ; x3 ; x1 -contradicted;
(b) returns clause {y 1 , x3 } x4 ; x2 ; y2 ; x3 ; x1 -contradicted, expected.
fact universal literal y2 causes C3 x4 ; x2 ; y2 ; x3 ; x1 -contradicted
appear clause returned Rec-C-Resolve due following two facts:
1. y2 lower level blocking literal y1 ;
2. negation existential literals C3 level lower y2 assigned
y2 x4 ; x2 ; y2 ; x3 ; x1 .
formally define notions, need additional notation. First, consider
given clause C2 . ResC2 (C1 ) set literals C1 level lower literal
blocking resolution C1 C2 . Formally:
ResC2 (C1 ) = {l : l C1 , l0 BlockingC2 (C1 )level(l) < level(l0 )},

literal l, level(l) prefix level l;
BlockingC2 () function defined
BlockingC2 (C1 ) = {l : l C1 , l C2 , l universal}
Let assignment. say clause C1 -contradictable (with respect
C2 )
410

fiClause/Term Resolution Learning Quantified Boolean Formulas

1. existential literal l C1 , l ;
2. universal literal l C1 , l
(a) l ResC2 (C1 );
(b) existential literal l0 C1 , level(l0 ) < level(l) l0 left l
.
Clearly, clause -contradicted -contradictable. Considering QBF
(13), clause {x1 , y1 , y2 , x4 } x4 ; x2 ; y2 ; x3 ; x1 -contradicted; x4 ; x2 ; y2 ; x3 ; x1 contradictable (with respect {x1 , 1 , x3 }).
well founded order induction set tuples hC1 , C2 , l,
C1 ; l-contradictable. preliminary step, first define well founded order
literals according l0 l00 either l0 = l00 l0 l00
l0 assigned l00 (i.e., l0 left l00 ).
extend partial order relation literals clauses (i) minimal form, (ii)
containing l, (iii) ; l-contradictable, saying two clauses C1 C3 ,
C3 C1
either C3 = C1 ;
E
E
E
E
00
0
00
l0 (ResE
C2 (C1 )\ResC2 (C3 ))l (ResC2 (C3 )\ResC2 (C1 ))l l , ResC2 (C1 )
subset existential literals ResC2 (C1 ), similarly ResE
C2 (C3 ).

order well founded, minimal elements ResC2 (C) (or,
equivalently, BlockingC2 (C)) empty.
Finally, consider set W tuples hC1 , C2 , l,
1. ; l assignment;
2. l existential literal either unit highest level ;
3. C1 clause containing l, minimal form ; l-contradictable respect
C2 ;
4. C2 contains l, minimal form ; l-contradicted. Further, l unit ,
C2 clause causes l unit .
set, define well founded order according hC3 , C2 , l, hC1 , C2 , l,
C3 C1 .
consider procedure Rec-C-Resolve Figure 6. prove well founded
induction that, tuple hC1 , C2 , l, W , Rec-C-Resolve(, C1 , C2 , l, ) terminates
returns clause C minimal form -contradicted. end, show
assume C1 ; l-contradicted (and simply ; l-contradictable),
C contain existential literals whose negation assigned monotone
.
base case, C1 ResC2 (C1 ) empty. Hence, universal literal
l C1 , l thus C1 ; l-contradicted. Since ResC2 (C1 ) empty, set
computed line 1 empty thus Rec-C-Resolve(, C1 , C2 , l, ) terminates returning
411

fiGiunchiglia, Narizzano & Tacchella

resolvent C C1 C2 . Clearly C minimal form, easy show C
-contradicted.
step case, induction hypothesis, thesis holds Rec-CResolve(, C3 , C2 , l, ) show holds Rec-C-Resolve(, C1 , C2 , l, ),
assuming hC3 , C2 , l, hC1 , C2 , l, i. set ResC2 (C1 ) empty, see base case.
Assume ResC2 (C1 ) empty, thus BlockingC2 (C1 ) empty.
on, let l0 literal BlockingC2 (C1 ) highest level. l0
l0 6 ResC2 (C1 ) C1 ; l-contradictable. l0 l0 C2 C2
; l-contradicted. Further, level(l0 ) < level(l). see why, consider two possible
cases:
1. l unit : Since l0 C2 , C2 clause causes l unit ,
must level(l0 ) = level(l0 ) < level(l).
2. l highest level : Since l0 l0 l highest
level , level(l0 ) level(l). hand, level(l0 ) 6= level(l) l0
universal l existential.
Since C1 minimal form, exists existential literal l00 l00 C1 , l00
, level(l00 ) < level(l0 ) < level(l). on, let l1 existential literal
C1 (not necessarily distinct l00 ) level less equal level
literals C1 (see line 3). Since
level(l1 ) < level(l0 ) < level(l)

(14)

l1 (because C1 ; l-contradictable), follows l1 assigned unit,
thus exists clause C causes l1 unit 0 , 0 ; l1
initial prefix (see line 4).
Consider set
BlockingC (C1 ) = {l : l C1 , l C, l universal}.
BlockingC (C1 ) empty. fact, universal literal l00 C
level(l00 ) < level(l1 ) l00 6 C1 since C1 minimal form;
level(l00 ) > level(l1 ) l00 l1 . Assume l00 C1 . Since C1 ; l-contradictable,
l1 l00 . However, l00 l1 l1 l00 possible l1 6= l00 (l1 existential
l00 universal).
Since BlockingC (C1 ) empty, resolve C C1 l1 , obtaining
C3 = min((C1 C) \ {l1 , l1 })
resolvent. C3 minimal form contains l.
show C3 C1 remains showed C3 ; l-contradictable. Indeed,
existential literal l C3 , l , universal literals C3 , consider
two cases:
412

fiClause/Term Resolution Learning Quantified Boolean Formulas

1. BlockingC2 (C3 ) empty. case, l0 BlockingC2 (C3 ). easy
consequence following facts:
(a) literal l00 BlockingC2 (C), level(l00 ) < level(l0 ): l00 C2 definition
BlockingC2 (C), hence l00 C2 ; l-contradicted, therefore
level(l00 ) < level(l1 ), thus thesis (see (14));
(b) BlockingC2 (C3 ) = (BlockingC2 (C1 )BlockingC2 (C))C3 thus (BlockingC2 (C1 )
BlockingC2 (C)) \ BlockingC2 (C3 ) = (C C1 ) \ ({l1 , l1 } C3 ), i.e., literals
BlockingC2 (C1 ) BlockingC2 (C) BlockingC2 (C3 )
omitted minimal form C3 ;
(c) BlockingC2 (C3 ) empty.
Since l0 BlockingC2 (C3 ), literals ResC2 (C1 ) C3 , belong
ResC2 (C3 ), i.e.,
ResC2 (C3 ) ResC2 (C1 ) C3 .
(15)
consider universal literal l00 C1 C3 . l00
(a) l00 ResC2 (C1 ) C1 ; l-contradictable, hence l00 ResC2 (C3 )
(see (15));
(b) existential literal l000 C1 , level(l000 ) < level(l00 ) l000 l00
C1 ; l-contradictable;
(c) existential literal l000 6= l1 C, l000 l00 . fact, level(l1 ) < level(l00 ),
l1 l00 C1 ; l-contradictable, existential literal l000 6= l1
C, l000 l1 .
Finally, consider universal literal l00 C C3 . l00 level(l00 ) < level(l1 )
hence
(a) l00 ResC2 (C3 ) level(l1 ) < level(l0 ) (see (14));
(b) existential literal l000 C3 , level(l000 ) < level(l00 ) l000 C hence
l000 l00 .
2. BlockingC2 (C3 ) empty. Let lowest among level literals C3 .
level(l0 ) < since l0 6 C3 . Then, universal literal l00 C3 , l00 , i.e.,
C3 ; l-contradicted. fact, assume exists universal literal l00 C3
. Then, level(l00 ) > either l00 C1 l00 C. Consider first case l00 C1 .
Then, l00 ResC2 (C1 ) C1 ; l-contradictable, level(l00 ) < level(l0 ).
possible level(l00 ) > level(l0 ) < m. Consider case
l00 C. Then, level(l00 ) < level(l1 ) hence level(l00 ) < level(l0 ) (see (14))
possible.
Since C3 C1 , hC3 , C2 , l, hC1 , C2 , l, i, conclude induction hypothesis
Rec-C-Resolve(, C3 , C2 , l, ) returns clause minimal form -contradicted.
413

fiGiunchiglia, Narizzano & Tacchella

make assumption input clause C1 ; l-contradicted.
Then, C1 contain existential literals whose negation assigned monotone, holds C2 clause C used line 5. Hence, Rec-CResolve(, C3 , C2 , l, ) returns clause without existential literals whose negation
assigned monotone .

References
Abdelwaheb, A., & Basin, D. (2000). Bounded model construction monadic second-order
logics. 12th International Conference Computer-Aided Verification (CAV00),
No. 1855 Lecture Notes Computer Science, pp. 99113, Chicago, USA. SpringerVerlag.
Bachmair, L., & Ganzinger, H. (2001). Resolution theorem proving. Robinson, A., &
Voronkov, A. (Eds.), Handbook Automated Reasoning, Vol. I, chap. 2, pp. 1999.
Elsevier Science.
Bayardo, Jr., R. J., & Schrag, R. C. (1997). Using CSP look-back techniques solve
real-world SAT instances. Proceedings 14th National Conference Artificial Intelligence 9th Innovative Applications Artificial Intelligence Conference
(AAAI-97/IAAI-97), pp. 203208, Menlo Park. AAAI Press.
Bayardo, Jr., Roberto J., & Miranker, D. P. (1996). complexity analysis space-bounded
learning algorithms constraint satisfaction problem. Proceedings
Thirteenth National Conference Artificial Intelligence Eighth Innovative
Applications Artificial Intelligence Conference, pp. 298304, Menlo Park. AAAI
Press / MIT Press.
Cadoli, M., Schaerf, M., Giovanardi, A., & Giovanardi, M. (2002). algorithm evaluate
quantified Boolean formulae experimental evaluation. Journal Automated
Reasoning, 28, 101142.
Cadoli, M., Giovanardi, A., & Schaerf, M. (1998). algorithm evaluate Quantified
Boolean Formulae. Proceedings 15th National Conference Artificial Intelligence (AAAI-98) 10th Conference Innovative Applications Artificial
Intelligence (IAAI-98), pp. 262267, Menlo Park. AAAI Press.
Castellini, C., Giunchiglia, E., & Tacchella, A. (2001). Improvements SAT-based conformant planning. Proc. ECP.
Castellini, C., Giunchiglia, E., & Tacchella, A. (2003). SAT-based planning complex
domains: Concurrency, constraints nondeterminism. Artificial Intelligence, 147 (12), 85117.
Davis, M., Logemann, G., & Loveland, D. W. (1962). machine program theorem
proving. Communication ACM, 5 (7), 394397.
de la Tour, T. B. (1990). Minimizing Number Clauses Renaming. Proc.
10th Conference Automated Deduction, pp. 558572. Springer-Verlag.
Dechter, R. (1990). Enhancement schemes constraint processing: Backjumping, learning,
cutset decomposition. Artificial Intelligence, 41 (3), 273312.
414

fiClause/Term Resolution Learning Quantified Boolean Formulas

Fermuller, C. G., Leitsch, A., Hustadt, U., & Tammet, T. (2001). Resolution decision procedures. Robinson, A., & Voronkov, A. (Eds.), Handbook Automated Reasoning,
Vol. II, chap. 25, pp. 17911849. Elsevier Science B.V.
Gent, I., Giunchiglia, E., Narizzano, M., Rowley, A., & Tacchella, A. (2004). Watched data
structures QBF solvers. Giunchiglia, E., & Tacchella, A. (Eds.), Theory
Applications Satisfiability Testing, 6th International Conference, SAT 2003. Santa
Margherita Ligure, Italy, May 5-8, 2003 Selected Revised Papers, Vol. 2919 Lecture
Notes Computer Science, pp. 2536. Springer.
Gent, I. P., & Rowley, A. G. (2004). Solution learning solution directed backjumping revisited. Tech. rep. APES-80-2004, APES Research Group. Available
http://www.dcs.st-and.ac.uk/apes/apesreports.html.
Ginsberg, M. L. (1993). Dynamic backtracking. Journal Artificial Intelligence Research,
1, 2546.
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2001). Backjumping quantified Boolean
logic satisfiability. Proc. International Joint Conference Artificial Intelligence (IJCAI2001).
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2002). Learning Quantified Boolean
Logic Satisfiability. Proceedings Eighteenth National Conference Artificial
Intelligence Fourteenth Conference Innovative Applications Artificial Intelligence, July 28 - August 1, 2002, Edmonton, Alberta, Canada. AAAI Press, 2002,
pp. 649654.
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2003). Backjumping Quantified Boolean
Logic Satisfiability. Artificial Intelligence, 145, 99120.
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2004a). Monotone literals learning
QBF reasoning. Tenth International Conference Principles Practice
Constraint Programming, CP 2004, pp. 260273.
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2004b). Qbf reasoning real-world instances. Theory Applications Satisfiability Testing, 7th International Conference, SAT 2004, Vancouver, BC, Canada, May 10-13, 2004, Revised Selected Papers,
pp. 105121.
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2004c). Qube++: efficient qbf solver.
5th International Conference Formal Methods Computer-Aided Design, FMCAD
2004, pp. 201213.
Kleine-Buning, H., Karpinski, M., & Flogel, A. (1995). Resolution quantified Boolean
formulas. Information Computation, 117 (1), 1218.
Le Berre, D., Simon, L., & Tacchella, A. (2003). Challenges QBF arena: SAT03
evaluation QBF solvers. Sixth International Conference Theory Applications Satisfiability Testing (SAT 2003), Vol. 2919 LNCS. Springer Verlag.
Letz, R. (2002). Lemma model caching decision procedures quantified Boolean
formulas. Proceedings Tableaux 2002, LNAI 2381, pp. 160175. Springer.
415

fiGiunchiglia, Narizzano & Tacchella

Marques-Silva, J. P., & Sakallah, K. A. (1996). GRASP - New Search Algorithm
Satisfiability. Proceedings IEEE/ACM International Conference ComputerAided Design, pp. 220227.
Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering Efficient SAT Solver. Proceedings 38th Design Automation
Conference (DAC01), pp. 530535.
Pan, G., & Vardi, M. Y. (2003). Optimizing BDD-based modal solver. Automated
Deduction - CADE-19, 19th International Conference Automated Deduction Miami
Beach, FL, USA, July 28 - August 2, 2003, Proceedings, pp. 7589.
Plaisted, D., & Greenbaum, S. (1986). Structure-preserving Clause Form Translation.
Journal Symbolic Computation, 2, 293304.
Prosser, P. (1993a). Domain filtering degrade intelligent backjumping search. Proceedings 13th International Joint Conference Artificial Intelligence (IJCAI99-Vol2), pp. 262267.
Prosser, P. (1993b). Hybrid algorithms constraint satisfaction problem. Computational Intelligence, 9 (3), 268299.
Rintanen, J. (1999). Constructing conditional plans theorem prover. Journal Artificial Intelligence Research, 10, 323352.
Robinson, A. (1965). machine-oriented logic based resolution principle. Journal
ACM, 12 (1), 2341.
Robinson, A. (1968). generalized resolution principle. Machine Intelligence, Vol. 3,
pp. 7793. Oliver Boyd, Edinburgh.
Scholl, C., & Becker, B. (2001). Checking equivalence partial implementations.
Proceedings 38th Design Automation Conference (DAC01), pp. 238243.
Tseitin, G. (1970). complexity proofs propositional logics. Seminars Mathematics, 8.
Urquhart, A. (1995). complexity propositional proofs. Bulletin Symbolic
Logic, 1 (4), 425467.
Zhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Efficient conflict driven
learning Boolean satisfiability solver. International Conference ComputerAided Design (ICCAD01), pp. 279285.
Zhang, L., & Malik, S. (2002a). Conflict driven learning quantified Boolean satisfiability solver. Proceedings International Conference Computer Aided Design
(ICCAD02).
Zhang, L., & Malik, S. (2002b). Towards symmetric treatment satisfaction conflicts
quantified Boolean formula evaluation. Proceedings Eighth International
Conference Principles Practice Constraint Programming, pp. 200215.

416


