Journal Artificial Intelligence Research 26 (2006) 35-99

Submitted 8/05; published 5/06

Planning Graph Heuristics Belief Space Search
Daniel Bryce
Subbarao Kambhampati,

DAN . BRYCE @ ASU . EDU
RAO @ ASU . EDU

Department Computer Science Engineering
Ira A. Fulton School Engineering
Arizona State University, Brickyard Suite 501
699 South Mill Avenue, Tempe, AZ 85281

David E. Smith

DE 2 SMITH @ EMAIL . ARC . NASA . GOV

NASA Ames Research Center
Intelligent Systems Division, MS 269-2
Moffett Field, CA 94035-1000

Abstract
recent works conditional planning proposed reachability heuristics improve
planner scalability, many lack formal description properties distance estimates.
place previous work context extend work heuristics conditional planning,
provide formal basis distance estimates belief states. give definition
distance belief states relies aggregating underlying state distance measures.
give several techniques aggregate state distances associated properties. Many existing
heuristics exhibit subset properties, order provide standardized comparison
present several generalizations planning graph heuristics used single planner.
compliment belief state distance estimate framework investigating efficient planning
graph data structures incorporate BDDs compute effective heuristics.
developed two planners serve test-beds investigation. first, CAltAlt,
conformant regression planner uses A* search. second, P D, conditional
progression planner uses AO* search. show relative effectiveness heuristic
techniques within planners. compare performance planners several
state art approaches conditional planning.

1. Introduction
Ever since CGP (Smith & Weld, 1998) SGP (Weld, Anderson, & Smith, 1998) series planners developed tackling conformant conditional planning problems including
GPT (Bonet & Geffner, 2000), C-Plan (Castellini, Giunchiglia, & Tacchella, 2001), PKSPlan (Petrick & Bacchus, 2002), Frag-Plan (Kurien, Nayak, & Smith, 2002), MBP (Bertoli, Cimatti, Roveri,
& Traverso, 2001b), KACMBP (Bertoli & Cimatti, 2002), CFF (Hoffmann & Brafman, 2004),
YKA (Rintanen, 2003b). Several planners extensions heuristic state space planners
search space belief states (where belief state set possible states). Without
full-observability, agents need belief states capture state uncertainty arising starting
uncertain state executing actions uncertain effects known state. focus
first type uncertainty, agent starts uncertain state deterministic actions.
seek strong plans, agent reach goal certainty despite partially known
state. Many aforementioned planners find strong plans, heuristic search planners
c
2006
AI Access Foundation. rights reserved.

fiB RYCE , K AMBHAMPATI , & MITH

currently among best. Yet foundation constitutes good distance-based heuristic
belief space adequately investigated.
Belief Space Heuristics: Intuitively, argued heuristic merit belief state depends
least two factorsthe size belief state (i.e., uncertainty current state),
distance individual states belief state destination belief state. question
course compute measures effective. Many approaches estimate
belief state distances terms individual state state distances states two belief
states, either lack effective state state distances ways aggregate state distances.
instance MBP planner (Bertoli et al., 2001b) counts number states current belief
state. amounts assuming state distance unit cost, planning state
done independently. GPT planner (Bonet & Geffner, 2000) measures state state distances
exactly takes maximum distance, assuming states belief state positively interact.
Heuristic Computation Substrates: characterize several approaches estimating belief state
distance describing terms underlying state state distances. basis investigation adapting classical planning reachability heuristics measure state distances
developing state distance aggregation techniques measure interaction plans states
belief state. take three fundamental approaches measure distance two belief
states. first approach involve aggregating state distance measures, rather use
classical planning graph compute representative state distance. second retains distinctions
individual states belief state using multiple planning graphs, akin CGP (Smith
& Weld, 1998), compute many state distance measures aggregated. third
employs new planning graph generalization, called Labelled Uncertainty Graph (LU G),
blends first two measure single distance two belief states. techniques discuss types heuristics compute special emphasis relaxed
plans. present several relaxed plan heuristics differ terms employ state distance aggregation make stronger assumptions states belief state co-achieve
goal action sequences independent, positively interact, negatively interact.
motivation first three planning graph techniques measuring belief state
distances try minimal extension classical planning heuristics see work us.
Noticing use classical planning heuristics ignores distinctions states belief
state may provide uninformed heuristics, move second approach possibly
build exponentially many planning graphs get better heuristic. multiple planning
graphs extract heuristic graph aggregate get belief state distance
measure. assume states belief state independent, aggregate measures
summation. Or, assume positively interact use maximization. However,
show, relaxed plans give us unique opportunity measure positive interaction
independence among states essentially taking union several relaxed plans. Moreover,
mutexes play role measuring negative interactions states. Despite utility
robust ways aggregate state distances, still faced exponential blow
number planning graphs needed. Thus, third approach seeks retain ability measure
interaction state distances avoid computing multiple graphs extracting heuristics
each. idea condense symbolically represent multiple planning graphs single
planning graph, called Labelled Uncertainty Graph (LU G). Loosely speaking, single graph
unions causal support information present multiple graphs pushes disjunction,
36

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

describing sets possible worlds (i.e., initial literal layers), labels. planning graph
vertices present multiple graphs, redundant representation avoided.
instance action present multiple planning graphs would present
LU G labelled indicate applicable planning graph projection
possible world. describe extract heuristics LU G make implicit
assumptions state interaction without explicitly aggregating several state distances.
Ideally, planning graph techniques considers every state belief state compute
heuristics, belief states grow size could become uninformed costly. example,
single classical planning graph ignores distinctions possible states heuristic
based multiple graphs leads construction planning graph state. One way
keep costs base heuristics subset states belief state. evaluate
effect sampling cost heuristics. single graph sample single
state multiple graphs LU G sample percent states. evaluate
state sampling show appropriate, find dependent compute
heuristics states.
Standardized Evaluation Heuristics: issue evaluating effectiveness heuristic techniques many architectural differences planners use heuristics. quite hard
pinpoint global effect assumptions underlying heuristics performance.
example, GPT outperformed MBPbut questionable whether credit efficiency attributable differences heuristics, differences search engines (MBP uses
BDD-based search). interest paper systematically evaluate spectrum approaches
computing heuristics belief space planning. Thus implemented heuristics similar
GPT MBP use compare new heuristics developed around notion
overlap (multiple world positive interaction independence). implemented heuristics
within two planners, Conformant-AltAlt planner (CAltAlt) Partially-Observable NonDeterministic planner (P D). P handle search non-deterministic actions,
bulk paper discuss deterministic actions. general action formulation,
pointed Smith Weld (1998), translated initial state uncertainty. Alternatively,
Section 8.2 discuss direct approach reason non-deterministic actions
heuristics.
External Evaluation: Although main interest paper evaluate relative advantages spectrum belief space planning heuristics normalized setting, compare
performance best heuristics work current state art conformant
conditional planners. empirical studies show planning graph based heuristics provide effective guidance compared cardinality heuristics well reachability heuristic used GPT
CFF, planners competitive BDD-based planners MBP YKA,
GraphPlan-based ones CGP SGP. notice planners gain scalability
heuristics retain reasonable quality solutions, unlike several planners compare
against.
rest paper organized follows. first present CAltAlt P planners
describing state action representations well search algorithms. understand
search guidance planners, discuss appropriate properties heuristic measures
belief space planning. follow description three planning graph substrates used
compute heuristics. carry empirical evaluation next three sections, describing
37

fiB RYCE , K AMBHAMPATI , & MITH

test setup, presenting standardized internal comparison, finally comparing several
state art planners. end related research, discussion, prospects future work,
various concluding remarks.

2. Belief Space Planners
planning formulation uses regression search find strong conformant plans progression
search find strong conformant conditional plans. strong plan guarantees finite
number actions executed many possible initial states, resulting states goal
states. Conformant plans special case plan conditional plan branches,
classical planning. Conditional plans general case plans structured graph
include conditional actions (i.e. actions causative observational effects).
presentation, restrict conditional plans DAGs, conceptual reason
cannot general graphs. plan quality metric maximum plan path length.
formulate search space belief states, technique described Bonet Geffner
(2000). planning problem P defined tuple D, BSI , BSG , domain
description, BSI initial belief state, BSG goal belief state (consisting states
satisfying goal). domain tuple F, A, F set fluents set
actions.
Logical Formula Representation: make extensive use logical formulas F represent
belief states, actions, LU G labels, first explain conventions. refer every
fluent F either positive literal negative literal, either denoted l.
discussing literal l, opposite polarity literal denoted l. Thus l = at(location1),
l = at(location1). reserve symbols denote logical false true, respectively.
Throughout paper define conjunction empty set equivalent , disjunction
empty set .
Logical formulas propositional sentences comprised literals, disjunction, conjunction,
negation. refer set models formula f M(f ). consider disjunctive normal
), conjunctive normal form f , (f ). DNF seen
form logical formula f , (f
disjunction constituents conjunction literals. Alternatively CNF
seen conjunction clauses C disjunction literals.1 find useful
think DNF CNF represented sets disjunctive set constituents conjunctive set
clauses. refer complete representation (f ) formula f DNF every
constituent case state model f .
Belief State Representation: world state, S, represented complete interpretation
fluents. refer states possible worlds. belief state BS set states symbolically represented propositional formula F . state set states represented
belief state BS M(BS), equivalently |= BS.
pedagogical purposes, use bomb toilet clogging sensing problem,
BTCS, running example paper.2 BTCS problem includes two packages, one
) readily related. Specifically constituent contains k |F | literals,
1. easy see M(f ) (f
corresponding 2|F |k models.
2. aware negative publicity associated B&T problems fact handle interesting
problems difficult reachability uncertainty (e.g. Logistics Rovers), simplify discussion
choose small problem.

38

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

contains bomb, toilet dunk packages defuse potential
bombs. goal disarm bomb allowable actions dunking package
toilet (DunkP1, DunkP2), flushing toilet becomes clogged dunking (Flush),
using metal-detector sense package contains bomb (DetectMetal). fluents encoding
problem denote bomb armed (arm) not, bomb package (inP1, inP2)
not, toilet clogged (clog) not. consider conformant variation BTCS,
called BTC, DetectMetal action.
belief state representation BTCS initial condition, clausal representation is:
(BSI ) = arm clog (inP1 inP2) (inP1 inP2),
constituent representation is:

(BS
) = (arm clog inP1 inP2) (arm clog inP1 inP2).
goal BTCS clausal constituent representation:

(BSG ) = (BS
G ) = arm.
However, goal complete representation:
(BSG ) = (arm clog inP1 inP2) (arm clog inP1 inP2)
(arm clog inP1 inP2) (arm clog inP1 inP2)
(arm clog inP1 inP2) (arm clog inP1 inP2)
(arm clog inP1 inP2) (arm clog inP1 inP2).
last four states (disjuncts) complete representation unreachable, consistent
goal description.
Action Representation: represent actions causative observational effects.
actions described tuple e (a), (a), (a) e (a) execution precondition,
(a) set causative effects, (a) set observations. execution precondition,
e (a), conjunction literals must hold action executable. action executable, apply set causative effects find successor states apply observations
partition successor states observational classes.
causative effect j (a) (a) conditional effect form j (a) = j (a),
antecedent j (a) consequent j (a) conjunction literals. handle disjunction
e (a) j (a) replicating respective action effect different conditions,
loss generality assume conjunctive preconditions. However, cannot split disjunction
effects. Disjunction effect amounts representing set non-deterministic outcomes. Hence
allow disjunction effects thereby restricting deterministic effects. convention
0 (a) unconditional effect, equivalent conditional effect 0 (a) = .
way obtain observations execute action observations. observation
formula oj (a) (a) possible sensor reading. example, action observes
truth values two fluents p q defines (a) = {p q, p q, p q, p q}. differs
slightly conventional description observations conditional planning literature.
works (e.g., Rintanen, 2003b) describe observation list observable formulas,
define possible sensor readings boolean combinations formulas. directly define
possible sensor readings, illustrated example. note convention helpful
problems boolean combinations observable formulas never sensor readings.
causative sensory actions example BTCS problem are:
39

fiB RYCE , K AMBHAMPATI , & MITH

DunkP1: e = clog, = {0 = clog, 1 = inP1 = arm}, = {},
DunkP2: e = clog, = {0 = clog, 1 = inP2 = arm}, = {},
Flush: e = , = {0 = clog}, = {},
DetectMetal: e = , = , = {o0 = inP1, o1 = inP1}.
2.1 Regression
perform regression CAltAlt planner find conformant plans starting goal
belief state regressing non-deterministically relevant actions. action (without
observations) relevant regressing belief state (i) unconditional effect consistent
every state belief state (ii) least one effect consequent contains literal present
constituent belief state. first part relevance requires every state successor
belief state actually reachable predecessor belief state second ensures
action helps support successor.
Following Pednault (1988), regressing belief state BS action a, conditional
effects, involves finding execution, causation, preservation formulas. define regression
terms clausal representation, generalized arbitrary formulas. regression
belief state conjunction regression clauses (BS). Formally, result BS
regressing belief state BS action defined as:3




BS = Regress(BS, a) = (a)




((a, l) IP (a, l))

C(BS) lC

Execution formula ((a)) execution precondition e (a). must hold BS
applicable.
Causation formula ((a, l)) literal l w.r.t effects (a) action defined
weakest formula must hold state l holds BS. intuitive meaning
l already held BS , antecedent (a) must held BS make l hold BS.
Formally (a, l) defined as:

(a)
(a, l) = l
i:li (a)

Preservation formula (IP (a, l)) literal l w.r.t. effects (a) action defined
formula must true l violated effect (a). intuitive
meaning antecedent every effect inconsistent l could held BS .
Formally IP (a, l) defined as:
IP (a, l) =



(a)

i:li (a)

Regression formalized MBP planner (Cimatti & Roveri, 2000) symbolic
pre-image computation BDDs (Bryant, 1986). formulation syntactically different,
approaches compute result.
3. Note BS may clausal form regression (especially action multiple conditional effects).

40

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

BSG
Flush

BS1
Flush

BS4
Flush

BS7

DunkP1

BS8

DunkP1

BS2
DunkP1

BS5

DunkP2

BS3
DunkP2

BS6

DunkP2

BS9

Figure 1: Illustration regression search path conformant plan BT C problem.
2.2 CAltAlt
CAltAlt planner uses regression operator generate children A* search. Regression
terminates search node expansion generates belief state BS logically entailed
initial belief state BSI . plan sequence actions regressed BSG obtain
belief state entailed BSI .
example, BTC problem, Figure 1, have:
BS2 =Regress(BSG , DunkP1) = clog (arm inP1).
first clause execution formula second clause causation formula
conditional effect DunkP1 arm.
Regressing BS2 Flush gives:
BS4 = Regress(BS2 , Flush) = (arm inP1).
BS4 , execution precondition Flush , causation formula clog = ,
(arm inP1) comes persistence causation formula.
Finally, regressing BS4 DunkP2 gives:
BS9 = Regress(BS4 , DunkP2) = clog (arm inP1 inP2).
terminate BS9 BSI |= BS9 . plan DunkP2, Flush, DunkP1.
2.3 Progression
progression handle causative effects observations, general, progressing
action belief state BS generates set successor belief states B. set belief
states B empty action applicable BS (BS
|= e (a)).
Progression belief state BS action best understood union result
applying model BS fact implement BDD images, MBP planner
41

fiB RYCE , K AMBHAMPATI , & MITH

(Bertoli et al., 2001b). Since compute progression two steps, first finding causative successor, second partitioning successor observational classes, explain steps separately.
causative successor BS found progressing belief state BS causative effects
action a. action applicable, causative successor disjunction causative
progression (Progressc ) state BS a:



: BS
|= e (a)



BS = Progressc (BS, a) =
SM(BS) Progressc (S, a) : otherwise
progression action state conjunction every literal persists (no
applicable effect consequent contains negation literal) every literal given
effect (an applicable effect consequent contains literal).


= Progressc (S, a) =

l:lS
j S|=j (a)
lj (a)



l
l:j

S|=j (a)
lj (a)

l


Applying observations action results set successors B. set found (in
Progresss ) individually taking conjunction sensor reading oj (a) causative
successor BS . Applying observations (a) belief state BS results set B belief
states, defined as:

: BS =



{BS }
: (a) =
B = Progresss (BS , a) =



j

{BS |BS = (a) BS } : otherwise
full progression computed as:
B = Progress(BS, a) = Progresss (Progressc (BS, a), a).
2.4 P
use top AO* search (Nilsson, 1980), P planner generate conformant
conditional plans. search graph, nodes belief states hyper-edges actions.
need AO* applying action observations belief state divides belief state
observational classes. use hyper-edges actions actions observations
several possible successor belief states, must included solution.
AO* search consists two repeated steps: expand current partial solution,
revise current partial solution. Search ends every leaf node current solution
belief state satisfies goal better solution exists (given heuristic function). Expansion involves following current solution unexpanded leaf node generating children.
Revision dynamic programming update node current solution selects best
hyper-edge (action). update assigns action minimum cost start best solution
rooted given node. cost node cost best action plus average cost
children (the nodes connected best action). expanding leaf node, children
applied actions given heuristic value indicate estimated cost.
42

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

main differences formulation AO* Nilsson (1980)
allow cycles search graph, update costs nodes average rather
summation, use weighted estimate future cost. first difference ensure plans
strong (there finite number steps goal), second guide search toward plans
lower average path cost, third bias search trust heuristic function.
define plan quality metric (maximum plan path length) differently metric search
minimizes two reasons. First, easier compare competing planners
measure plan quality metric. Second, search tends efficient using average
instead maximum cost actions children. using average instead maximum,
measured cost plan lower means likely search shallower search graph
prove solution best solution.
Conformant planning, using actions without observations, special case AO* search,
similar A* search. hyper-edges represent actions singletons, leading
single successor belief state. Consider BTC problem (BTCS without DetectMetal action)
future cost (heuristic value) set zero every search node. show search graph
Figure 2 conformant example well conditional example, described shortly.
expand initial belief state progressing applicable actions. get:
B1 = {BS10 } = Progress(BSI , DunkP1)
= {(inP1 inP2 clog arm) (inP1 inP2 clog arm)}

B3 = {BS20 } = Progress(BSI , DunkP2)
= {(inP1 inP2 clog arm) (inP1 inP2 clog arm)}.
Since clog already holds every state initial belief state, applying Flush BSI leads
BSI creating cycle. Hence, hyper-edge Flush added search graph BSI .
assign cost zero BS10 BS20 , update internal nodes best solution, add
DunkP1 best solution rooted BSI (whose cost one).
expand leaf nodes best solution, single node BS10 , applicable actions.
applicable action Flush, get:
B3 = {BS30 } = Progress(BS10 , Flush)
= {(inP1 inP2 clog arm) (inP1 inP2 clog arm)}.
assign cost zero BS30 update best solution. choose Flush best action
BS10 (whose cost one), choose DunkP2 best action BSI (whose cost
one). DunkP2 chosen BSI successor BS20 cost zero, opposed
BS10 cost one.
Expanding leaf node BS20 applicable action, Flush, get:
B4 = {BS40 } = Progress(BS20 , Flush)
= {(inP1 inP2 clog arm) (inP1 inP2 clog arm)}.
update BS40 (to cost zero) BS20 (to cost one), choose Flush best
action BS20 . root node BSI two children, cost one, arbitrarily choose
DunkP1 best action.
expand BS30 relevant actions get BSG DunkP2 action. DunkP1 creates
cycle back BS10 added search graph. solution leaf
nodes terminal. required terminal belief state contains subset
43

fiB RYCE , K AMBHAMPATI , & MITH

BSI
DunkP1

Detect
Metal

DunkP2

:inP1

inP1

B1

B2

BS10

B5

BS50

BS20

Flush

Flush

B3

B4

BS30

DunkP2

DunkP1
DunkP2

DunkP1

B6

BS40
DunkP2

BS51

B7

BS60

BS70

DunkP1

BSG

Figure 2: Illustration progression search conformant plan (bold dashed edges) conditional plan (bold solid edges) BTCS problem.

states BSG , case terminal belief state contains exactly states BSG . cost
solution three because, revision, BS30 cost one, sets BS10 cost
two. However, means BSI cost three best action DunkP1. Instead,
revision sets best action BSI DunkP2 cost currently two.
expand BS40 DunkP1 find successor BSG . DunkP2 creates cycle
back BS20 added search graph. second valid solution
contains unexpanded leaf nodes. Revision sets cost BS40 one, BS20 two,
BSI three. Since solutions starting BSI equal cost (meaning cheaper
solutions), terminate plan DunkP2, Flush, DunkP1, shown bold dashed lines
Figure 2.
example search conditional plan P D, consider BTCS example whose
search graph shown Figure 2. Expanding initial belief state, get:
B1 = {BS10 } = Progress(BSI , DunkP1),
B2 = {BS20 } = Progress(BSI , DunkP2),

B5 = {BS50 , BS51 } = Progress(BSI ,DetectMetal)
= {inP1 inP2 clog arm, inP1 inP2 clog arm}.
leaf nodes assigned cost zero, DunkP1 chosen arbitrarily best
solution rooted BSI cost solution identical. cost including
hyper-edge average cost children plus cost, cost using DetectMetal (0+0)/2
+ 1 = 1. Thus, root BSI cost one.
44

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

conformant problem expand BS10 , giving child cost zero BS10 cost
one. changes best solution BSI use DunkP2, expand BS20 , giving child
cost zero cost one. choose DetectMetal start best solution BSI
gives BSI cost one, using either Dunk action would give BSI cost two.
expand first child DetectMetal, BS50 , DunkP1 get:
{inP1 inP2 clog arm},
goal state, DunkP2 get:
B6 = {BS60 } = Progress(BS50 ,DunkP2) = {inP1 inP2 clog arm}.
expand second child, BS51 , DunkP2 get:
{inP1 inP2 clog arm},
goal state DunkP1 get:
B7 = {BS70 } = Progress(BS51 ,DunkP1) = {inP1 inP2 clog arm}.
none new belief states equivalent BSG , two entail BSG ,
treat terminal connecting hyper-edges actions BSG . choose
DunkP1 DunkP2 best actions BS50 BS51 respectively set cost node
one. turn sets cost using DetectMetal BSI (1+1)/2 + 1 = 2. terminate
plan cost equal possible plans starting BSI leaf nodes
satisfy goal. plan shown bold solid lines Figure 2.

3. Belief State Distance
CAltAlt P planners need guide search node expansion heuristics
estimate plan distance dist(BS, BS ) two belief states BS BS . convention, assume BS precedes BS (i.e., progression BS search node BS goal
belief state, regression BS initial belief state BS search node). simplicity,
limit discussion progression planning. Since strong plan (executed BS) ensures
every state M(BS) transition state M(BS ), define plan distance
BS BS number actions needed transition every state M(BS)
state M(BS ). Naturally, strong plan, actions used transition state S1 M(BS)
may affect transition another state S2 M(BS). usually degree positive
negative interaction S1 S2 ignored captured estimating plan distance.4 following explore perform estimates using several intuitions
classical planning state distance heuristics.
start example search scenario Figure 3. three belief states BS1 (containing states S11 S12 ), BS2 (containing state S21 ), BS3 (containing states S31 S32 ).
goal belief state BS3 , two progression search nodes BS1 BS2 . want
expand search node smallest distance BS3 estimating dist(BS1 , BS3 ) denoted
bold, dashed line dist(BS2 , BS3 ) denoted bold, solid line. assume
estimates state distance measures dist(S, ) denoted light dashed
solid lines numbers. state distances represented numbers action sequences.
example, use following action sequences illustration:
4. Interaction states captures notion actions performed transition one state goal may interfere
(negatively interact) aid (positively interact) transitioning states goals states.

45

fiB RYCE , K AMBHAMPATI , & MITH

BS1
S11

BS3

14
5

S12

S31

3
7

BS2

S32

8

S21

10

Figure 3: Conformant Plan Distance Estimation Belief Space
dist(S11 , S32 ) : ({a1 , a2 }, {a5 }, {a6 , a7 }),
dist(S12 , S31 ) : ({a1 , a7 }, {a3 }),
dist(S21 , S31 ) : ({a3 , a6 }, {a9 , a2 , a1 }, {a0 , a8 }, {a5 }).
sequence may several actions step. instance, dist(S21 , S31 ) a3
a6 first step, total eight actions sequence meaning distance
eight. Notice example includes several state distance estimates, found
classical planning techniques. many ways use similar ideas estimate belief
state distance addressed issue belief states containing several states.
Selecting States Distance Estimation: exists considerable body literature estimating plan distance states classical planning (Bonet & Geffner, 1999; Nguyen,
Kambhampati, & Nigenda, 2002; Hoffmann & Nebel, 2001), would apply estimate plan distance two belief states, say BS1 BS3 . identify four possible
options using state distance estimates compute distance belief states BS1
BS3 :
Sample State Pair: sample single state BS1 single state BS3 ,
whose plan distance used belief state distance. example, might sample S12
BS1 S31 BS3 , define dist(BS1 , BS3 ) = dist(S12 , S31 ).
Aggregate States: form aggregate states BS1 BS3 measure plan
distance. aggregate state union literals needed express belief state formula,
46

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

define as:
S(BS) =



l

l:lS,S(BS)

Since possible express belief state formula every literal (e.g., using (q q) p
express belief state p true), assume reasonably succinct representation,
ROBDD (Bryant, 1986). quite possible aggregate states inconsistent, many classical planning techniques (such planning graphs) require consistent states. example, aggregate states would compute belief state distance
dist(BS1 , BS3 ) = dist(S(BS1 ), S(BS3 )).
Choose Subset States: choose set states (e.g., random sampling)
BS1 set states BS3 , compute state distances pairs states
sets. Upon computing state distances, aggregate state distances (as
describe shortly). example, might sample S11 S12 BS1 S31
BS3 , compute dist(S11 , S31 ) dist(S12 , S31 ), aggregate state distances
define dist(BS1 , BS3 ).
Use States: use states BS1 BS3 , and, similar sampling subset
states (above), compute distances state pairs aggregate distances.
former two options computing belief state distance reasonably straightforward, given
existing work classical planning. latter two options compute multiple state distances.
multiple state distances two details require consideration order obtain
belief state distance measure. following treat belief states contain states
appropriately replaced subset chosen states.
first issue state distances may needed. Since state BS1
needs reach state BS3 , consider distance state BS1 state
BS3 . However, dont necessarily need distance every state BS1 every state
BS3 . explore assumptions state distances need computed Section 3.1.
second issue, arises computing state distances, need aggregate
state distances belief state distance. notice popular state distance estimates
used classical planning typically measure aggregate costs state features (literals). Since
planning belief space, wish estimate belief state distance aggregate cost
belief state features (states). Section 3.2, examine several choices aggregating state
distances discuss captures different types state interaction. Section 3.3,
conclude summary choices make order compute belief state distances.
3.1 State Distance Assumptions
choose compute multiple state distances two belief states BS BS ,
whether considering states sampling subsets, state distances important.
given state BS need know distance every state BS
state BS need transition one state BS . two assumptions make
states reached BS help us define two different belief state distance measures
terms aggregate state distances:
47

fiB RYCE , K AMBHAMPATI , & MITH

optimistically assume earlier states M(BS) reach closest
later states M(BS ). assumption compute distance as:
dist(BS, BS ) = ffSM(BS)

min

M(BS )

dist(S, ).

assume earlier states M(BS) reach later state
M(BS ), aggregate distance minimum. assumption compute distance as:
dist(BS, BS ) =

min

M(BS )

ffSM(BS) dist(S, ),

represents aggregation technique (several discuss shortly).
Throughout rest paper use first definition belief state distance
relatively robust easy compute. drawback treats earlier states
independent fashion, flexible allowing earlier states transition different later states.
second definition measures dependencies earlier states, restricts reach
later state. second may sometimes accurate, misinformed cases
earlier states cannot reach later state (i.e., measure would infinite).
pursue second method may return distance measures infinite
fact finite.
see Section 4, discuss computing measures planning graphs,
implicitly find state BS closest state BS , enumerate
states minimization term first belief state distance (above). Part reason
) rather actual states.

compute distance terms constituents (BS
Also, consider constituents BS , discuss sampling belief states include distance computation sample BS. avoid explicit aggregation
using LU G, describe several choices understand implicit assumptions made
heuristics computed LU G.
3.2 State Distance Aggregation
aggregation function plays important role measure distance belief
states. compute one state distance measure, either exhaustively sampling
subset (as previously mentioned), must combine measures means, denoted ff.
range options taking state distances aggregating belief state
distance. discuss several assumptions associated potential measures:
Positive Interaction States: Positive interaction assumes difficult state BS
requires actions help transition states BS state BS .
example, means assume actions used transition S11 S32 help us
transition S12 S31 (assuming state BS1 transitions closest state BS3 ).
Inspecting action sequences, see positively interact need actions a1
a7 . need know action sequences assume positive interaction
define aggregation maximization numerical state distances:
dist(BS, BS ) =

max

min

SM(BS) M(BS )

dist(S, ).
48

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

belief state distances dist(BS1 , BS3 ) = max(min(14, 5), min(3, 7)) = 5
dist(BS2 , BS3 ) = max(min(8, 10)) = 8. case prefer BS1 BS2 .
state distance admissible sample belief states, assuming positive
interaction admissible.
Independence States: Independence assumes state BS requires actions
different states BS order reach state BS . Previously, found
positive interaction action sequences transition S11 S32 S12 S31
shared actions a1 a7 . independence sequences
first contains a2 , a5 , a6 , second contains a3 . Again, need
know action sequences assume independence define aggregation
summation numerical state distances:

min dist(S, ).
dist(BS, BS ) =


SM(BS) M(BS )

example, dist(BS1 , BS3 ) = min(14, 5) + min(3, 7) = 8, dist(BS2 , BS3 ) =
min(8, 10) = 8. case preference BS1 BS2 .
notice using cardinality belief state |M(BS)| measure dist(BS, BS )
special case assuming state independence, S, dist(S, ) = 1. use cardinality measure distance example, dist(BS1 , BS3 ) = |M(BS1 )| = 2,
dist(BS2 , BS3 ) = |M(BS2 )| = 1. cardinality prefer BS2 BS1
better knowledge BS2 .
Overlap States: Overlap assumes positive interaction independence
actions used states BS reach state BS . intuition
actions often used multiple states BS simultaneously count
actions once. example, computed dist(BS1 , BS3 ) assuming positive
interaction, noticed action sequences dist(S11 , S32 ) dist(S12 , S31 )
used a1 a7 . aggregate sequences would count a1 a7
potentially overlap. However, truly combining action sequences
maximal overlap plan merging problem (Kambhampati, Ihrig, & Srivastava, 1996),
difficult planning. Since ultimate intent compute heuristics,
take simple approach merging action sequences. introduce plan merging
operator picks step align sequences unions aligned
steps. use size resulting action sequence measure belief state distance:
dist(BS, BS ) = SM(BS)

min

M(BS )

dist(S, ).

Depending type search, define differently. assume sequences used
progression search start time used regression end time.
Thus, progression sequences aligned first step union steps,
regression sequences aligned last step union.
example, progression dist(S11 , S32 ) dist(S12 , S31 ) = ({a1 , a2 }, {a5 }, {a6 , a7 })
({a1 , a7 }, {a3 }) = ({a1 , a2 , a7 }, {a5 , a3 }, {a6 , a7 }) align sequences
first steps, union step. Notice resulting sequence seven actions, giving
49

fiB RYCE , K AMBHAMPATI , & MITH

dist(BS1 , BS3 ) = 7, whereas defining maximum gave distance five summation gave distance eight. Compared overlap, positive interaction tends
estimate distance, independence tends estimate distance. see empirical evaluation (in Section 6.5), accounting overlap provides accurate
distance measures many conformant planning domains.
Negative Interaction States: Negative interaction states appear example
transitioning state S11 state S32 makes difficult (or even impossible) transition
state S12 state S31 . could happen performing action a5 S11 conflicts action
a3 S12 . say BS1 cannot reach BS3 possible action sequences start
S11 S12 , respectively, end M(BS3 ) negatively interact.
two ways negative interactions play role belief state distances. Negative interactions allow us prove impossible belief state BS reach belief state
BS , meaning dist(BS, BS ) = , potentially increase distance finite
amount. use first, extreme, notion negative interaction computing
cross-world mutexes (Smith & Weld, 1998) prune belief states search.
cannot prune belief state, use one aforementioned techniques aggregate
state distances. such, provide concrete definition measure negative
interaction.
explore ways adjust distance measure negative interactions,
mention possibilities. work classical planning (Nguyen et al., 2002),
penalize distance measure dist(BS1 , BS3 ) reflect additional cost associated serializing conflicting actions. Additionally conditional planning, conflicting actions
conditioned observations execute plan branch. distance
measure uses observations would reflect added cost obtaining observations,
well change cost associated introducing plan branches (e.g., measuring average
branch cost).
techniques belief state distance estimation terms state distances provide
basis use multiple planning graphs. show empirical evaluation
measures affect planner performance differently across standard conformant conditional
planning domains. quite costly compute several state distance measures, understanding aggregate state distances sets foundation techniques develop
LU G. already mentioned, LU G conveniently allows us implicitly aggregate state
distances directly measure belief state distance.
3.3 Summary Methods Distance Estimation
Since explore several methods computing belief state distances planning graphs, provide summary choices must consider, listed Table 1. column headed
choice, containing possible options below. order columns reflects order
consider options.
section covered first two columns relate selecting states belief
states distance computation, well aggregating multiple state distances belief state
distance. test options choices empirical evaluation.
50

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

State
Selection
Single
Aggregate
Subset


State Distance
Aggregation
+ Interaction
Independence
Overlap
- Interaction

Planning
Graph
SG
MG
LU G

Mutex
Type
None
Static
Dynamic
Induced

Mutex
Worlds

Intersect
Cross

Heuristic
Max
Sum
Level
Relaxed Plan

Table 1: Features belief state distance estimation.
next section expand upon aggregate distance measures well
discuss remaining columns Table 1. present type planning graph: single
planning graph (SG), multiple planning graphs (M G), labelled uncertainty graph (LU G).
Within planning graph describe several types mutex, including static, dynamic,
induced mutexes. Additionally, type mutex computed respect different
possible worlds means mutex involves planning graph elements (e.g., actions)
exist world (i.e., mutexes computed within planning graph single
state), across worlds (i.e., mutexes computed planning graphs different states)
two methods (denoted Intersect Cross). Finally, compute many different heuristics
planning graphs measure state distances max, sum, level, relaxed plan. focus
discussion planning graphs, same-world mutexes, relaxed plan heuristics next
section. Cross-world mutexes heuristics described appendices.

4. Heuristics
section discusses use planning graph heuristics measure belief state distances.
cover several types planning graphs extent used compute
various heuristics. begin brief background planning graphs.
Planning Graphs: Planning graphs serve basis belief state distance estimation. Planning graphs initially introduced GraphPlan (Blum & Furst, 1995) representing optimistic, compressed version state space progression tree. compression lies unioning
literals every state subsequent steps initial state. optimism relates underestimating number steps takes support sets literals (by tracking subset
infeasible tuples literals). GraphPlan searches compressed progression (or planning graph)
achieves goal literals level two goal literals marked infeasible. search
tries find actions support top level goal literals, find actions support chosen
actions reaching first graph level. basic idea behind using planning graphs
search heuristics find first level planning graph literal state
appears; index level lower bound number actions needed achieve
state literal. techniques estimating number actions required
achieve sets literals. planning graphs serve way estimate reachability state literals discriminate goodness different search states. work generalizes
literal estimations belief space search considering GraphPlan CGP style planning
graphs plus new generalization planning graphs, called LU G.
Planners CGP (Smith & Weld, 1998) SGP (Weld et al., 1998) adapt GraphPlan
idea compressing search space planning graph using multiple planning graphs, one
51

fiB RYCE , K AMBHAMPATI , & MITH

Overlap

n-distances

hMG
RPU

hLUG
RP

State Distance Aggregation

CFF

Independence

Positive
Interaction

None

h card
MBP
KACMBP
YKA

hMG
s-RP

GPT

hMG
m-RP

h0
NG

1

hSG
RP
U
hSG
RP
SG

MG

LUG

Planning Graph Type

Figure 4: Taxonomy heuristics respect planning graph type state distance aggregation. Blank entries indicate combination meaningless possible.

possible world initial belief state. CGP SGP search planning graphs,
similar GraphPlan, find conformant conditional plans. work paper seeks
apply idea extracting search heuristics planning graphs, previously used state space
search (Nguyen et al., 2002; Hoffmann & Nebel, 2001; Bonet & Geffner, 1999) belief space
search.
Planning Graphs Belief Space: section proceeds describing four classes heuristics
estimate belief state distance N G, SG, G, LU G. N G heuristics techniques existing
literature based planning graphs, SG heuristics techniques based single
classical planning graph, G heuristics techniques based multiple planning graphs (similar
used CGP) LU G heuristics use new labelled planning graph. LU G combines
advantages SG G reduce representation size maintain informedness. Note
include observations planning graph structures SGP (Weld et al.,
1998) would, however include feature future work. conditional planning formulation directly uses planning graph heuristics ignoring observations, results show
still gives good performance.
Figure 4 present taxonomy distance measures belief space. taxonomy
includes related planners, whose distance measures characterized section.
related planners listed N G group, despite fact actually use planning graphs,
clearly fall one planning graph categories. figure shows
52

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

different substrates (horizontal axis) used compute belief state distance aggregating
state state distances various assumptions (vertical axis). combinations
considered make sense impossible. reasons omissions
discussed subsequent sections. wealth different heuristics one
compute using planning graphs, concentrate relaxed plans proven
effective classical planning previous studies (Bryce & Kambhampati, 2004).
provide additional descriptions heuristics max, sum, level Appendix A.
Example: illustrate computation heuristic, use example derived BTC
called Courteous BTC (CBTC) courteous package dunker disarm bomb
leave toilet unclogged, discourteous person left toilet clogged. initial
belief state CBTC clausal representation is:
(BSI ) = arm clog (inP1 inP2) (inP1 inP2),
goal is:
(BSG ) = clog arm.
optimal action sequences reach BSG BSI are:
Flush, DunkP1, Flush, DunkP2, Flush,

Flush, DunkP2, Flush, DunkP1, Flush.
Thus optimal heuristic estimate distance BSI BSG , regression,
h (BSG ) = 5 either plan five actions.
use planning graphs progression regression search. regression search
heuristic estimates cost current belief state w.r.t. initial belief state progression
search heuristic estimates cost goal belief state w.r.t. current belief state. Thus,
regression search planning graph(s) built (projected) possible worlds
initial belief state, progression search need built search node.
introduce notation BSi denote belief state find heuristic measure, BSP
denote belief state used construct initial layer planning graph(s).
following subsections describe computing heuristics regression, generalized
progression changing BSi BSP appropriately.
previous section discussed two important issues involved heuristic computation:
sampling states include computation using mutexes capture negative interactions
heuristics. directly address issues section, deferring discussion
respective empirical evaluation sections, 6.4 6.2. heuristics computed
decided set states use, whether sampling not. Also, previously
mentioned, consider sampling states belief state BSP implicitly
find closest states BSi without sampling. explore computing mutexes planning
graphs regression search. use mutexes determine first level planning graph
goal belief state reachable (via level heuristic described Appendix A) extract
relaxed plan starting level. level heuristic level belief
state reachable, prune regressed belief state.
proceed describing various substrates used computing belief space distance estimates. Within describe prospects various types world aggregation. addition
heuristics, mention related work relevant areas.
53

fiB RYCE , K AMBHAMPATI , & MITH

4.1 Non Planning Graph-based Heuristics (N G)
group many heuristics planners N G group using SG, G,
LU G planning graphs. mention group mean
using planning graphs form.
Aggregation: Breadth first search uses simple heuristic, h0 heuristic value set
zero. mention heuristic gauge effectiveness search substrates
relative improvements gained using heuristics.
Positive Interaction Aggregation: GPT planner (Bonet & Geffner, 2000) measures belief
state distance maximum minimum state state distance states source
destination belief states, assuming optimistic reachability mentioned Section 3. GPT measures
state distances exactly, terms minimum number transitions state space. Taking
maximum state state distance akin assuming positive interaction states current
belief state.
Independence Aggregation: MBP planner (Bertoli et al., 2001b), KACMBP planner (Bertoli
& Cimatti, 2002), YKA planner (Rintanen, 2003b), comparable hcard heuristic measure
belief state distance assuming every state state distance one, taking summation
state distances (i.e. counting number states belief state). measure useful
regression goal belief states partially specified contain many states consistent
goal formula many states consistent goal formula reachable
initial belief state. Throughout regression, many unreachable states removed
predecessor belief states inconsistent preconditions regressed action.
Thus, belief states reduce size regression cardinality may indicate
closer initial belief state. Cardinality useful progression belief states
become smaller, agent knowledge easier reach goal state.
CBTC, hcard (BSG ) = 4 BSG four states consistent complete representation:
(BSG ) = (inP1 inP2clog arm) (inP1 inP2 clog arm)
(inP1 inP2 clog arm) (inP1 inP2 clog arm).
Notice, may uninformed BSG two states (BSG ) reachable,
like: (inP1 inP2 clog arm). n packages, would 2n1 unreachable
states represented (BSG ). Counting unreachable states may overestimate distance estimate
need plan them. general, addition problem counting unreachable states, cardinality accurately reflect distance measures. instance, MBP reverts
breadth first search classical planning problems state distance may large small
still assigns value one.
Overlap Aggregation: Rintanen (2004) describes n-Distances generalize belief state
distance measure GPT consider maximum n-tuple state distance. measure involves,
n-sized tuple states belief state, finding length actual plan transition
n-tuple destination belief state. maximum n-tuple distance taken distance
measure.
example, consider belief state four states. n equal two, would define
six belief states, one size two subset four states. belief states
find real plan, take maximum cost plans measure distance original
54

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

L0

A0

E0

L1

A1

E1

L2

inP1

inP1

inP1

inP1

inP1

inP1

inP2

inP2

inP2

inP2

inP2

inP2
DunkP1

1(DunkP1)
0(DunkP1)

arm
DunkP2
arm

arm

1(DunkP2)
0(DunkP2)

clog

clog

clog
Flush

0(Flush)

clog

arm

Flush

0(Flush)

clog

Figure 5: Single planning graph CBTC, relaxed plan components bold. Mutexes omitted.

four state belief state. n one, computing measure GPT, n
equal size belief state directly solving planning problem. costly
compute measure large values n, informed accounts overlap
negative interactions.
CFF planner (Hoffmann & Brafman, 2004) uses version relaxed planning graph
extract relaxed plans. relaxed plans measure cost supporting set goal literals
states belief state. addition traditional notion relaxed planning graph ignores
mutexes, CFF ignores one antecedent literal conditional effects keep relaxed
plan reasoning tractable. CFF relaxed plan capture overlap ignores subgoals
mutexes. way CFF ensures goal supported relaxed problem encode
relaxed planning graph satisfiability problem. encoding satisfiable, chosen number
action assignments distance measure.
4.2 Single Graph Heuristics (SG)
simplest approach using planning graphs belief space planning heuristics use
classical planning graph. form initial literal layer projected belief state, could
either sample single state (denoted SG1 ) use aggregate state (denoted SGU ). example,
CBTC (see Figure 5) assuming regression search BSP = BSI , initial level L0
planning graph SG1 might be:
55

fiB RYCE , K AMBHAMPATI , & MITH

L0 = {arm, clog, inP1, inP2}
SGU defined aggregate state S(BSP ):
L0 = {arm, clog, inP1, inP2, inP1, inP2}.
Since two versions single planning graph identical semantics, aside initial
literal layer, proceed describing SGU graph point differences SG1
arise.
Graph construction identical classical planning graphs (including mutex propagation)
stops two subsequent literal layers identical (level off). use planning graph formalism used IPP (Koehler, Nebel, Hoffmann, & Dimopoulos, 1997) allow explicit representation conditional effects, meaning literal layer Lk , action layer Ak , effect
layer Ek level k. Persistence literal l, denoted lp , represented action
e (lp ) = 0 (lp ) = l. literal Lk effect previous effect layer Ek1 contains
literal consequent. action action layer Ak every one execution precondition
literals Lk . effect effect layer Ek associated action action layer Ak
every one antecedent literals Lk . Using conditional effects planning graph avoids
factoring action conditional effects possibly exponential number non-conditional
actions, adds extra planning graph layer per level. graph built, extract
heuristics.
Aggregation: Relaxed plans within single planning graph able measure,
optimistic assumptions, distance two belief states. relaxed plan represents
distance subset initial layer literals literals constituent belief
state. SGU , literals initial layer used support may hold
single state projected belief state, unlike SG1 . classical relaxed plan heuristic hSG
RP
finds set (possibly interfering) actions support goal constituent. relaxed plan RP
RP
RP
RP
RP
RP
subgraph planning graph, form {ARP
0 , E0 , L1 , ..., Ab1 , Eb1 , Lb }.
layers contains subset vertices corresponding layer planning graph.

formally, find relaxed plan support constituent (BS
) reached
SG
earliest graph (as found hlevel (BSi ) heuristic Appendix A). Briefly, hSG
level (BSi )
returns first level b constituent BSi literals Lb none marked
pair-wise mutex. Notice incorporate negative interactions heuristics.
start extraction level b, defining LRP
literals constituent used level
b
RP
heuristic. literal l Lb , select supporting effect (ignoring mutexes) Eb1
RP . prefer persistence literals effects supporting literals.
form subset Eb1
RP
supporting set effects found, create ARP
b1 actions effect Eb1 .
RP
RP added
needed preconditions actions antecedents chosen effects Ab1 Eb1
list literals support LRP
b2 . algorithm repeats find needed actions
A0 . relaxed plans value summation number actions action layer.
literal persistence, denoted subscript p, treated action planning graph,
|. single graph relaxed plan
relaxed plan include final computation | ARP
j
heuristic computed
hSG
RP (BSi )

=

b1

j=0

56

| ARP
|
j

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

CBTC problem find relaxed plan SGU , shown Figure 5 bold
edges nodes. Since arm clog non mutex level two, use persistence
RP use persistence inP1,
support clog DunkP1 support arm LRP
2 . L1
SG
Flush clog. Thus, hRP (BSG ) = 2 relaxed plan is:
= {inP1p , Flush},
ARP
0
E0RP = {0 (inP1p ), 0 (Flush)},

= {inP1, clog},
LRP
1
= {clogp , DunkP1},
ARP
1

E1RP = {0 (clogp ), 1 (DunkP1)},
= {arm, clog}.
LRP
2

relaxed plan use DunkP2 DunkP1 support arm. result arm
supported worlds (i.e. supported state inP2 holds initial
state). initial literal layer threw away knowledge inP1 inP2 holding different worlds,
relaxed plan extraction ignored fact arm needs supported worlds. Even
SG1 graph, see similar behavior reasoning single world.
single, unmodified classical planning graph cannot capture support possible worlds hence
explicit aggregation distance measures states. result, mention
aggregating states measure positive interaction, independence, overlap.
4.3 Multiple Graph Heuristics (M G)
Single graph heuristics usually uninformed projected belief state BSP often corresponds multiple possible states. lack accuracy single graphs able
capture propagation multiple world support information. Consider CBTC problem
projected belief state BSI using single graph SGU . DunkP1 action
would say arm clog reached cost two, fact cost infinite
(since DunkP2 support arm possible worlds), strong plan.
account lack support possible worlds sharpen heuristic estimate, set
multiple planning graphs considered. single graph, previously discussed.
multiple graphs similar graphs used CGP (Smith & Weld, 1998), lack
general cross-world mutexes. Mutexes computed within graph, i.e. sameworld mutexes computed. construct initial layer L0 graph different state
M(BSP ). multiple graphs, heuristic value belief state computed terms
graphs. Unlike single graphs, compute different world aggregation measures
multiple planning graphs.
get informed heuristic considering states M(BSP ),
certain cases costly compute full set planning graphs extract relaxed plans.
describe computing full set planning graphs, later evaluate (in Section 6.4)
effect computing smaller proportion these. single graph SG1 extreme case
computing fewer graphs.
illustrate use multiple planning graphs, consider example CBTC. build two
graphs (Figure 6) projected BSP . respective initial literal layers:
L10 = {arm, clog, inP1, inP2}
L20 = {arm, clog, inP2, inP2}.

57

fiB RYCE , K AMBHAMPATI , & MITH

L0

inP1

A0

E0

inP2

A1

L1

inP1

E1

inP2

inP2
DunkP1

1

1(DunkP1)
0(DunkP1)

arm
clog

1(DunkP2)

arm
Flush

0(Flush)

DunkP2

clog

Flush

clog
inP1

inP1

inP2

inP2

L2

inP1

arm
arm

0(DunkP2)
0(Flush)

clog
clog
inP1

DunkP1

1(DunkP1)
0(DunkP1)

2

inP2

arm
arm
clog

1(DunkP2)

arm
Flush

0(Flush)

DunkP2

clog

Flush

clog

0(DunkP2)
0(Flush)

arm
clog
clog

Figure 6: Multiple planning graphs CBTC, relaxed plan components bolded. Mutexes
omitted.

graph first possible world, arm comes DunkP1 level 2.
graph second world, arm comes DunkP2 level 2. Thus, multiple
graphs show actions different worlds contribute support literal.
single planning graph sufficient aggregate state measures, following consider compute achievement cost belief state multiple graphs
aggregating state distances.
Positive Interaction Aggregation: Similar GPT (Bonet & Geffner, 2000), use worstG
case world represent cost belief state BSi using hM
mRP heuristic. difference
GPT compute heuristic planning graphs, compute plans state
space. heuristic account number actions used given world, assume
positive interaction across possible worlds.
G
hM
mRP heuristic computed finding relaxed plan RP planning graph ,
exactly done single graph hSG
RP . difference unlike single graph relaxed
plan SGU , SG1 , initial levels planning graphs states, relaxed plan
reflect support needed world corresponding . Formally:


b 1

RP
G

| Aj |
hM
mRP (BSi ) = max


j=0

b level constituent BSG first reachable.
58

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

Notice computing state distances states BSP BSi .
planning graph corresponds state BSP , extract single relaxed plan.
need enumerate states BSi find relaxed plan each. instead support
set literals one constituent BSi . constituent estimated minimum distance
state BSi first constituent reached .
G
CBTC, computing hM
mRP (BSG ) (Figure 6) finds:
RP 1 =
1
= {inP1p , Flush},
ARP
0

E0RP1 = {0 (inP1p ), 0 (Flush)},
1
= {inP1, clog},
LRP
1
1
= {clogp , DunkP1},
ARP
1

E1RP1 = {0 (clogp ), 1 (DunkP1)},

1
= {arm, clog}
LRP
2

RP 2 =
2
= {inP2p , Flush},
ARP
0

E0RP2 = {0 (inP2p ), 0 (Flush)},

2
= {inP2, clog},
LRP
1
2
= {clogp , DunkP2},
ARP
1

E1RP2 = {0 (clogp ), 1 (DunkP2)},

2
= {arm, clog}.
LRP
2

relaxed plan contains two actions taking maximum two relaxed plan values
G
gives hM
mRP (BSG ) = 2. aggregation ignores fact must use different Dunk actions
possible world.
G
Independence Aggregation: use hM
sRP heuristic assume independence among
worlds belief state. extract relaxed plans exactly described previous heuristic
simply use summation rather maximization relaxed plan costs. Formally:


1
b
RP
G

| Aj |
hM
sRP (BSi ) =


j=0

b level constituent BSG first reachable.
G
MG
CBTC, computing hM
sRP (BSG ), find relaxed plans hmRP (BSG )
heuristic, sum values get 2 + 2 = 4 heuristic. aggregation ignores fact
use Flush action possible worlds.
State Overlap Aggregation: notice two previous heuristics either taking
maximization accounting actions, taking summation possibly accounting
G
extra actions. present hM
RP U heuristic balance measure positive interaction
independence worlds. Examining relaxed plans computed two previous heuristics
CBTC example, see relaxed plans extracted graph overlap.
1
2
Notice, ARP
ARP
contain Flush action irrespective package bomb
0
0
1
2
contains DunkP1, ARP
contains DunkP2
showing positive interaction. Also, ARP
1
1
59

fiB RYCE , K AMBHAMPATI , & MITH

showing independence. take layer-wise union two relaxed plans, would
get unioned relaxed plan:
RPU =
U
= {inP1p , Flush},
ARP
0

E0RPU = {0 (inP1p ), 0 (inP2p ), 0 (Flush)},
U
LRP
= {inP1, inP2, clog},
1
U
= {clogp , DunkP1, DunkP2},
ARP
1

E1RPU = {0 (clogp ), 1 (DunkP1), 1 (DunkP2)},
U
LRP
= {arm, clog}.
2

relaxed plans accounts actions possible worlds
actions differ. Notice Flush appears layer zero Dunk actions
appear layer one.
order get union relaxed plans, extract relaxed plans ,
two previous heuristics. computing heuristics regression search, start
last level (and repeat level) taking union sets actions relaxed plan
level another relaxed plan. relaxed plans end-aligned, hence unioning levels
proceeds last layer relaxed plan create last layer RPU relaxed plan,
second last layer relaxed plan unioned on. progression search,
relaxed plans start-aligned reflect start time, whereas regression
assume end time. summation number actions action
level unioned relaxed plan used heuristic value. Formally:
G
hM
RP U (BSi ) =

b1


U
| ARP
|
j

j=0

b greatest level b constituent BSG first reachable.
CBTC, found RPU , counting number actions gives us heuristic value
G (BS ) = 3.
hM
G
RP U
4.4 Labelled Uncertainty Graph Heuristics (LU G)
multiple graph technique advantage heuristics aggregate costs multiple
worlds, disadvantage computing redundant information different graphs (c.f.
G
Figure 6) using every graph compute heuristics (c.f hM
RP U ). next approach addresses
limitations condensing multiple planning graphs single planning graph, called
labelled uncertainty graph (LU G). idea implicitly represent multiple planning graphs
collapsing graph connectivity one planning graph, use annotations, called labels (),
retain information multiple worlds. could construct LU G generating
multiple graphs taking union, instead define direct construction procedure.
start manner similar unioned single planning graph (SGU ) constructing initial
layer literals source belief state. difference LU G prevent
loss information multiple worlds keeping label literal records
worlds relevant. discuss, use simple techniques propagate
60

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

labels actions effects label subsequent literal layers. Label propagation relies
expressing labels propositional formulas using standard propositional logic operations.
end product single planning graph labels graph elements; labels indicate
explicit multiple graphs (if build them) contain graph element.
trading planning graph structure space label storage space. choice BDDs
represent labels helps lower storage requirements labels. worst-case complexity
LU G equivalent G representation. LU Gs complexity savings realized
projected possible worlds relevant actions completely disjoint; however,
often appear practice. space savings comes two ways: (1) redundant representation actions literals avoided, (2) labels facilitate non-redundant representation
stored BDDs. nice feature BDD package (Brace, Rudell, & Bryant, 1990) use
efficiently represents many individual BDDs shared BDD leverages common substructure. Hence, practice LU G contains information G much lower
construction usage costs.
section present construction LU G without mutexes, describe
introduce mutexes, finally discuss extract relaxed plans.
4.4.1 L ABEL P ROPAGATION
single graph multiple graphs, LU G based IP P (Koehler et al., 1997)
planning graph. extend single graph capture multiple world causal support, present
multiple graphs, adding labels elements action A, effect E, literal L layers.
denote label literal l level k k (l). build LU G belief state BSP ,
illustrate BSP = BSI CBTC example. label formula describing set states (in
BSP ) graph element (optimistically) reachable. say literal l reachable
set states, described BS, k levels, BS |= k (l). instance, say arm
reachable two levels L2 contains arm BSI |= 2 (arm), meaning models
worlds arm holds two levels superset worlds current belief state.
intuitive definition LU G planning graph skeleton, represents causal relations,
propagate labels indicate specific possible world support. show skeleton
CBTC Figure 7. Constructing graph skeleton largely follows traditional planning graph
semantics, label propagation relies simple rules. initial layer literal labelled,
indicate worlds BSP holds, conjunction literal BSP .
action labelled, indicate worlds execution preconditions co-achieved,
conjunction labels execution preconditions. effect labelled, indicate
worlds antecedent literals actions execution preconditions co-achieved,
conjunction labels antecedent literals label associated action. Finally,
literals labelled, indicate worlds given effect, disjunction
labels effects previous level affect literal. following describe label
propagation detail work CBTC example.
Initial Literal Layer: LU G initial layer consisting every literal non false ()
label. initial layer label 0 (l) literal l identical lBSP , representing states
BSP l holds. labels initial layer literals propagated actions
effects label next literal layer, describe shortly. continue propagation
label literal changes layers, condition referred level off.
61

fiB RYCE , K AMBHAMPATI , & MITH

L0

A0

E0

L1

A1

E1

L2

inP1

inP1

inP1

: inP1

: inP1

: inP1

inP2

inP2

inP2

: inP2

: inP2

DunkP1

1(DunkP1)
0(DunkP1)

DunkP2

: inP2
: arm

1(DunkP2)
0(DunkP2)

arm

arm

arm

clog

clog

clog

Flush

0(Flush)

: clog

Flush

0(Flush)

: clog

G
Figure 7: LU G skeleton CBTC, mutexes. relaxed plan hLU
RP shown
bold.

LU G CBTC, shown Figure 7 (without labels), using BSP =BSI initial literal
layer:
L0 = {inP1, inP2, inP2, inP1, clog, arm}
0 (inP1) = 0 (inP2) = (arm clog inP1 inP2),
0 (inP2) = 0 (inP1) = (arm clog inP1 inP2),
0 (clog) = 0 (arm) = BSP
Notice inP1 inP2 labels indicating respective initial states hold,
clog arm BSP label hold states BSP .
Action Layer: previous literal layer Lk computed, construct label action
layer Ak . Ak contains causative actions action set A, plus literal persistence. action
included Ak label false (i.e. k (a)
=). label action level k, equivalent
extended label execution precondition:
k (a) = k (e (a))
Above, introduce notation extended labels k (f ) formula f denote worlds
BSP reach f level k. say propositional formula f reachable BS
62

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

k levels BSi |= k (f ). Since labels literals, substitute labels
literals literals formula get extended label formula. extended label
propositional formula f level k, defined:
k (f f ) = k (f ) k (f ),
k (f f ) = k (f ) k (f ),

k ((f f )) = k (f f ),
k ((f f )) = k (f f ),
k () = BSP ,
k () =,
k (l) = k (l)
zeroth action layer CBTC is:
A0 = {Flush, inP1p , inP2p , inP2p , inP1p , clogp , armp }
0 (Flush) = BSP ,
0 (inP1p ) = 0 (inP2p ) = (arm clog inP1 inP2),
0 (inP2p ) = 0 (inP1p ) = (arm clog inP1 inP2),
0 (clogp ) = 0 (armp ) = BSP
literal persistence label identical label corresponding literal
previous literal layer. Flush action BSP label always applicable.
Effect Layer: effect layer Ek depends literal layer Lk action layer Ak . Ek
contains effect j (a) effect non false label (i.e. k (j (a))
=).
action effect must applicable world, label effect level k
conjunction label associated action extended label antecedent
k (j (a)) = k (a) k (j (a))
zeroth effect layer CBTC is:
E0 = {0 (Flush), 0 (inP1p ), 0 (inP2p ), 0 (inP2p ),
0 (inP1p ), 0 (clogp ), 0 (armp )}
0 (0 (Flush)) = BSP
0 (0 (inP1p )) = 0 (0 (inP2p )) = (arm clog inP1 inP2),
0 (0 (inP2p )) = 0 (0 (inP1p )) = (arm clog inP1 inP2),
0 (0 (clogp )) = 0 (0 (armp )) = BSP
Again, action layer, unconditional effect literal persistence label identical corresponding literal previous literal layer. unconditional effect Flush
label identical label Flush.
Literal Layer: literal layer Lk depends previous effect layer Ek1 , contains
literals non false labels (i.e. k (l)
=). effect j (a) Ek1 contributes label
literal l effect consequent contains literal l. label literal disjunction
labels effect previous effect layer gives literal:

k1 (j (a))
k (l) =
j (a):lj (a),
j (a)Ek1

63

fiB RYCE , K AMBHAMPATI , & MITH

first literal layer CBTC is:
L1 = {inP1, inP2, inP2, inP1, clog, clog, arm}
1 (inP1) = 1 (inP2) = (arm clog inP1 inP2),
1 (inP2) = 1 (inP1) = (arm clog inP1 inP2),
1 (clog) = 1 (clog) = 1 (arm) = BSP
literal layer identical initial literal layer, except clog goes false
label (i.e. existing layer) label BSP .
continue level one action layer L1 indicate BSG reachable
BSP (arm
L1 ). Action layer one defined:
A1 = {DunkP1, DunkP2, Flush, inP1p , inP2p , inP2p , inP1p , clogp , armp , clogp }
1 (DunkP1) = 1 (DunkP2) = 1 (Flush) = BSP ,
1 (inP1p ) = 1 (inP2p ) = (arm clog inP1 inP2),
1 (inP2p ) = 1 (inP1p ) = (arm clog inP1 inP2),
1 (clogp ) = 1 (armp ) = 1 (clogp ) = BSP
action layer similar level zero action layer. adds Dunk actions
executable. add persistence clog. Dunk action gets label identical
execution precondition label.
level one effect layer is:
E1 = {0 (DunkP1), 0 (DunkP2), 1 (DunkP1), 1 (DunkP2), 0 (Flush), 0 (inP1p ),
0 (inP2p ), 0 (inP2p ), 0 (inP1p ), 0 (clogp ), 0 (armp ), 0 (clogp )}
1 (0 (DunkP1)) = 1 (0 (DunkP2)) = 1 (0 (Flush)) = BSP
1 (1 (DunkP1)) = (arm clog inP1 inP2),
1 (1 (DunkP2)) = (arm clog inP1 inP2),
1 (0 (inP2p )) = 1 (0 (inP1p )) = (arm clog inP1 inP2),
1 (0 (inP1p )) = 1 (0 (inP2p )) = (arm clog inP1 inP2),
1 (0 (clogp )) = 1 (0 (armp )) = 1 (0 (clogp )) = BSP
conditional effects Dunk actions CBTC (Figure 7) labels indicate
possible worlds give arm antecedents hold possible
worlds. example, conditional effect 1 (DunkP1) label found taking conjunction actions label BSP antecedent label 1 (inP1) obtain (arm clog inP1
inP2).
Finally, level two literal layer:
L2 = {inP1, inP2, inP2, inP1, clog, clog, arm, arm}
2 (inP1) = 2 (inP2) = (arm clog inP1 inP2),
2 (inP2) = 2 (inP1) = (arm clog inP1 inP2),
2 (clog) = 2 (clog) = 2 (arm) = 2 (arm) = BSP
labels literals level 2 CBTC indicate arm reachable BSP label entailed BSP . label arm found taking disjunction
labels effects give it, namely, (arm clog inP1 inP2) conditional
64

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

effect DunkP1 (arm clog inP1 inP2) conditional effect DunkP2,
reduces BSP . Construction could stop BSP entails label goal
k (armclog)= k (arm) k (clog) = BSP BSP = BSP . However, level occurs
next level change labels literals.
level occurs level three example, say BS, BS |=
BSP , formula f reachable k steps BS |= k (f ). level k exists, f
reachable BS. level k, f reachable BS, first k
lower bound number parallel plan steps needed reach f BS. lower bound
similar classical planning max heuristic (Nguyen et al., 2002). provide
informed heuristic extracting relaxed plan support f respect BS, described shortly.
4.4.2 AME -W ORLD L ABELLED UTEXES
several types mutexes added LU G. start with, concentrate
evolve single possible world same-world mutexes effective
well relatively easy understand. extend mutex propagation used
multiple graphs mutexes one planning graph. savings computing mutexes
LU G instead multiple graphs reduce computation mutex exits
several worlds. Appendix B describe handle cross-world mutexes, despite lack
effectiveness experiments conducted. Cross-world mutexes extend LU G compute
set mutexes found CGP (Smith & Weld, 1998).
Same-world mutexes represented single label, k (x1 , x2 ), two elements
(actions, effect, literals). mutex holds elements x1 x2 worlds
|= k (x1 , x2 ). elements mutex world, assume label mutex
false . discuss labelled mutexes discovered propagated
actions, effect relations, literals.
using mutexes, refine means formula f reachable set
worlds BSP . must ensure every state BSP , exists state f reachable.
state f reachable state BSP two literals
mutex world BSP |= k (S).
action, effect, literal layers multiple ways pair
elements become mutex (e.g. interference competing needs). Thus, mutex label pair
disjunction labelled mutexes found pair means.
Action Mutexes: same-world action mutexes level k set labelled pairs actions.
pair labelled formula indicates set possible worlds actions
mutex. possible reasons mutex actions interference competing needs.

Interference Two actions a, interfere (1) unconditional effect consequent 0 (a)
one inconsistent execution precondition e (a ) other, (2) vice versa.
additionally interfere (3) unconditional effect consequents 0 (a) 0 (a )
inconsistent, (4) execution preconditions e (a) e (a ) inconsistent. mutex
exist possible world projections k (a, ) = BSP . Formally, interfere
65

fiB RYCE , K AMBHAMPATI , & MITH

one following holds:
(1) 0 (a) e (a ) =
(2) e (a) 0 (a ) =
(3) 0 (a) 0 (a ) =
(4) e (a) e (a ) =
Competing Needs Two actions a, competing needs world pair literals
execution preconditions mutex world. worlds
mutex competing needs described by:


k (a) k (a )

k (l, l )

lj (a),l j (a )

formula find worlds pair execution preconditions l e (a), l
e (a ) mutex actions reachable.
Effect Mutexes: effect mutexes set labelled pairs effects. pair labelled
formula indicates set possible worlds effects mutex. possible reasons
mutex effects associated action mutexes, interference, competing needs, induced effects.
Mutex Actions Two effects (a) (a), j (a ) (a ) mutex worlds
associated actions mutex, k (a, ).
Interference actions, two effects (a), j (a ) interfere (1) consequent (a)
one inconsistent antecedent j (a ) other, (2) vice versa. additionally interfere (3) effect consequents (a) j (a ) inconsistent, (4)
antecedents (a) j (a ) inconsistent. mutex exist possible world projections, label mutex k (i (a), j (a )) = BSP . Formally, (a) j (a )
interfere one following holds:
(1) (a) j (a ) =
(2) (a) j (a ) =
(3) (a) j (a ) =
(4) (a) j (a ) =
Competing Needs actions, two effects competing needs world pair
literals antecedents mutex world. worlds (a) j (a )
competing needs mutex are:
k (i (a)) k (j (a ))



k (l, l )

li (a),l j (a )

formula find worlds pair execution preconditions l (a), l
j (a ) mutex actions reachable.
66

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

Lk

lk(p)
p

Ek

Ak

lk(a)


h(a)

lk(h(a))



lk(p, q)
Induced mutex worlds:

lk(j(a),h(a))lk(i(a))



lk(j(a), h(a))

lk(q)
q
lk(a)


j(a)

lk(r)
r

lk(j(a))
i(a) induces j(a) in:
lk(i(a))lk(j(a))

i(a) lk(i(a))

Figure 8: Effect (a) induces effect j (a). j (a) mutex h (a ), (a) induced mutex
h (a ).

Induced induced effect j (a) effect (a) effect action
may execute time. effect induced another possible worlds
reachable. example, conditional effect action always induces
unconditional effect action.
Induced mutexes, involving inducing effect (a), come induced effect
j (a) mutex another effect h (a ) (see Figure 8). induced mutex
(a) effect h (a ) mutex induced effect j (a) (b) inducing effect
(a). label mutex conjunction label mutex k (j (a), h (a ))
label induced effect j (a). additional discussion methodology behind
induced mutexes refer Smith Weld (1998).

Literal Mutexes: literal mutexes set labelled pairs literals. pair labelled
formula indicates set possible worlds literals mutex. reason
mutex literals inconsistent support.
Inconsistent Support Two literals inconsistent support possible world level k
two non-mutex effects support literals world. label
literal mutex level k disjunction worlds inconsistent support.
worlds inconsistent support mutex l l are:
67

fiB RYCE , K AMBHAMPATI , & MITH





S:i (a),j (a )E

k1 ,
li (a),l j (a ),
S|=k1 (i (a),j (a ))

meaning formula two literals mutex worlds
pairs effects support literals mutex S.
4.4.3 LU G H EURISTICS
heuristics computed LU G capture measures similar G heuristics,
exists new opportunity make use labels improve heuristic computation efficiency. single
planning graph sufficient state aggregation measured, mention
measures LU G.
Positive Interaction Aggregation: Unlike G heuristics, compute positive interaction
based relaxed plans LU G. G approach measure positive interaction across
state belief state compute multiple relaxed plans take maximum value. get
measure LU G would still need extract multiple relaxed plans, situation
trying avoid using LU G. graph construction overhead may lowered using
LU G, heuristic computation could take long. Hence, compute relaxed plans
LU G measure positive interaction alone, compute relaxed plans measure
overlap (which measures positive interaction).
Independence Aggregation: positive interaction aggregation, need relaxed plan every
state projected belief state find summation costs. Hence, compute
relaxed plans assume independence.
G
State Overlap Aggregation: relaxed plan extracted LU G get hLU
RP heuristic

G

G
resembles unioned relaxed plan hRP U heuristic. Recall hRP U heuristic extracts
relaxed plan multiple planning graphs (one possible world) unions
set actions chosen level relaxed plans. LU G relaxed plan heuristic
similar counts actions positive interaction multiple worlds
accounts independent actions used subsets possible worlds. advantage
G
hLU
RP find actions single pass one planning graph.
trading cost computing multiple relaxed plans cost manipulating LU G
labels determine lines causal support used worlds. relaxed plan
want support goal every state BSP , need track states
BSP use paths planning graph. subgoal may several different (and possibly
overlapping) paths worlds BSP .
RP
RP
RP
RP
RP
RP
LU G relaxed plan set layers: {ARP
0 , E0 , L1 , ..., Ab1 , Eb1 , Lb }, Ar
RP
RP
set actions, Er set effects, Lr+1 set clauses. elements layers
labelled indicate worlds BSP chosen support. relaxed plan
G
extracted level b = hLU
level (BSi ) (i.e., first level BSi reachable, described
Appendix A).
Please note extracting relaxed plan BSi terms clauses, literals, different SG G versions relaxed plans. Previously found

68

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

constituent BSi first reached planning graph commit
one constituent. rationale possibly using different constituents
multiple graphs, condensed version multiple graphs still want able
support different constituents BSi different worlds. could use constituent representation BSi defining layers relaxed plan, choose clausal representation
BSi instead know support clause. However constituents
know need support one (but dont need know one).
relaxed plan, shown bold Figure 7, BSI reach BSG CBTC listed follows:
= {inP1p , inP2p , Flush},
ARP
0
RP
0 (inP1p ) = (arm clog inP1 inP2),
RP
0 (inP2p ) = (arm clog inP1 inP2),
RP
0 (Flush) = BSP ,
E0RP = {0 (inP1p ), 0 (inP2p ), 0 (Flush)},
0
RP
0 ( (inP1p )) = (arm clog inP1 inP2),
0
RP
0 ( (inP2p )) = (arm clog inP1 inP2),
RP
0 (0 (Flush)) = BSP ,
= {inP1, inP2, clog},
LRP
1
RP
1 (inP1) = (arm clog inP1 inP2),
RP
1 (inP2) = (arm clog inP1 inP2),
RP
1 (clog) = BSP ,
= {DunkP1, DunkP2, clogp },
ARP
1
RP
1 (DunkP1) = (arm clog inP1 inP2),
RP
1 (DunkP2) = (arm clog inP1 inP2),
RP
1 (clogp ) = BSP ,
E1RP = {1 (DunkP1), 1 (DunkP2), 0 (clogp )},
1
RP
1 ( (DunkP1)) = (arm clog inP1 inP2),
1
RP
1 ( (DunkP2)) = (arm clog inP1 inP2),
RP
1 (0 (clogp )) = BSP ,
= {arm, clog},
LRP
2
RP
2 (arm) = BSP ,
RP
2 (clog) = BSP
start forming LRP
clauses (BSG ), namely arm clog; label
2
clauses BSP need supported states belief state. Next,
support clause LRP
relevant effects E1 form E1RP . clog use
2
persistence supports clog worlds described BSP (this example positive
interaction worlds). arm relevant effects respective 1 Dunk action.
choose effects support arm need support arm worlds BSP ,
effect gives support one world (this example independence worlds).
appropriate label indicating
insert actions associated chosen effect ARP
1
69

fiB RYCE , K AMBHAMPATI , & MITH

worlds needed, general fewer worlds reachable (i.e.
RP execution preconditions
always case RP
r () |= r ()). Next form L1
actions ARP
antecedents effects E1RP , clog, inP1, inP2, labelled
1
worlds action effect needed them. fashion level two, support
literals level one, using persistence inP1 inP2, Flush clog. stop here,
supported clauses level one.
general case, extraction starts level b BSi first reachable BSP .
RP
RP
RP contains clauses
first relaxed plan layers construct ARP
b1 , Eb1 , Lb , Lb
RP
C (BSi ), labelled k (C) = BSP .
choosing relevant effects
level r, 1 r b, support clause LRP
r
RP . effect j (a) relevant reachable worlds
Er1 form Er1
need support C (i.e. r1 (j (a)) RP
r (C)
=) consequent gives literal l C.
clause, choose enough supporting effects chosen effect worlds
superset worlds need support clause, formally:









RP
RP
j

(C)
|=

(
(a))
CLRP


r
r1
r
j

(a):lj (a),

lC,
j (a)Er1

think supporting clause set worlds set cover problem effects cover
subsets worlds. algorithm cover worlds clause worlds effects variant
well known greedy algorithm set cover (Cormen, Leiserson, & Rivest, 1990). first
choose relevant persistence effects cover worlds, choose action effects cover
RP labelled new
new worlds. effect choose support added Er1
RP
worlds covered C. clauses Lr covered, form action layer ARP
r1
RP . actions ARP labelled indicate worlds
actions effect Er1
r1
RP .
effects labelled Er1
obtain next subgoal layer, LRP
r1 , adding literals execution preconditions
RP
RP . literal l LRP labelled indicate
actions Ar1 antecedents effects Er1
r1
worlds action effect requires l. support literals LRP
r1 fashion
.

continue

support
literals

effects,
insert
actions,

insert action effect
LRP
r
RP
preconditions supported literals L1 .
G
get relaxed plan, relaxed plan heuristic, hLU
RP (BSi ), summation
number actions action layer, formally:
G
hLU
RP (BSi )

=

b1


| ARP
|


i=0
G
Thus CBTC example hLU
RP (BSG ) = 3. Notice construct LU G
without mutexes CBTC reach goal two layers. included mutexes
LU G, would reach goal three layers. way use mutexes change
relaxed plan use mutexes influence relaxed plan extraction. Mutexes help
identify belief state BSi reachable BSP .

70

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

Problem

PDDL Parser
(IPC)
Actions

Belief
States

Search Engine
(HSP-r: CAltAlt/
LAO*: POND)

Heuristics

BDDs
(CUDD)

Labels

(POND only)

Planning
Graph(s)
(IPP)

Figure 9: implementations CAltAlt P rely many existing technologies.
search engine guided heuristics extracted planning graphs.

5. Empirical Evaluation: Setup
section presents implementation CAltAlt P planners domains
use experiments. tests run Linux x86 machine 2.66GHz P4 processor
1GB RAM timeout 20 minutes. CAltAlt P used heuristic weight
five the, respective, A* AO* searches. compare competing approaches (CGP,
SGP, GPT v1.40, MBP v0.91, KACMBP, YKA, CFF) several domains problems.
planners domain problem files compared planners found
online appendix.
5.1 Implementation
implementation CAltAlt uses several off-the-shelf planning software packages. Figure 9
shows diagram system architecture CAltAlt P D. CAltAlt extends
name AltAlt, relies limited subset implementation. components CAltAlt
IPC parser PDDL 2.1 (slightly extended allow uncertain initial conditions), HSPr search engine (Bonet & Geffner, 1999), IPP planning graph (Koehler et al., 1997),
CUDD BDD package (Brace et al., 1990) implement LU G labels. custom parts
implementation include action representation, belief state representation, regression operator,
heuristic calculation.
implementation P similar CAltAlt aside search engine,
state action representation. P uses IPP source code planning graphs. P
uses modified LAO* (Hansen & Zilberstein, 2001) source code Eric Hansen perform AO*
71

fiB RYCE , K AMBHAMPATI , & MITH

Problem
Rovers1
Rovers2
Rovers3
Rovers4
Rovers5
Rovers6
Logistics1
Logistics2
Logistics3
Logistics4
Logistics5
BT(n)
BTC(n)
CubeCenter(n)
Ring(n)

Initial
States
1
2
3
4
16
12
2
4
2
4
8
n
n
n3
n3n

Goal
Literals
1
1
1
1
3
3
1
2
1
2
3
1
1
3
n

Fluents
66
66
66
66
71
119
29
36
58
68
78
n+1
n+2
3n
4n

Causative
Actions
88
88
88
88
97
217
70
106
282
396
510
n
n+1
6
4

Observational
Actions
0 {12}
0 {12}
0 {12}
0 {12}
0 {12}
0 {18}
0 {10}
0 {20}
0 {21}
0 {42}
0 {63}
0 {n}
0 {n}
0
0

Optimal
Parallel
5 {5}
8 {7}
10 {?}
13 {?}
? {?}
? {?}
6 {6}
6 {?}
8 {?}
8 {?}
? {?}
1 {1}
2n-1 {2}
(3n-3)/2
3n-1

Optimal
Serial
5 {5}
8 {7}
10 {8}
13 {10}
20 {?}
? {?}
9 {7}
15 {12}
11 {8}
18 {?}
28 {?}
n {n-1}
2n-1 {n-1}
(9n-3)/2
3n-1

Table 2: Features test domains problems - Number initial states, Number goal literals, Number fluents, Number causative actions, Number Observational Actions,
Optimal number parallel plan steps, Optimal number serial plan steps. Data conditional versions domains braces; plan lengths conditional plans maximum
conditional branch length.

search, CUDD (Brace et al., 1990) represent belief states actions. Even deterministic
actions possible obtain cycles actions observations planning
belief space. P constructs search graph directed acyclic graph employing cyclechecking algorithm. adding hyper-edge search graph creates cycle, hyper-edge
cannot represent action strong plan hence added graph.
5.2 Domains
Table 2 shows relative features different problems used evaluate approach. table shows number initial states, goal literals, fluents, actions, optimal
plan lengths. used guide gauge difficulty problems, well
performance.
Conformant Problems addition standard domains used conformant planningsuch
Bomb-in-the-Toilet, Ring, Cube Center, developed two new domains Logistics
Rovers. chose new domains difficult subgoals, many
plans varying length.
Ring domain involves ring n rooms room connected two adjacent
rooms. room window open, closed, locked. goal every
window locked. Initially, state possible could room window could
configuration. four actions: move right, move left, close window current
72

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

room, lock window current room. Closing window works window
open, locking window works window closed. good conformant plan involves
moving one direction closing locking window room.
Cube Center domain involves three-dimensional grid (cube) six actions
possible move two directions along dimension. dimension consists n possible
locations. Moving direction along grid points leaves one
position. Using phenomena, possible localize dimension repeatedly moving
direction. Initially possible location cube goal reach
center. good conformant plan involves localizing corner moving center.
Rovers domain conformant adaptation analogous domain classical planning
track International Planning Competition (Long & Fox, 2003). added uncertainty
initial state uses conditions determine whether image objective visible various
vantage points due weather, availability rock soil samples. goal upload
image objective rock soil sample data. Thus conformant plan requires visiting
possible vantage points taking picture, plus visiting possible locations soil
rock samples draw samples.
first five Rovers problems 4 waypoints. Problems one four one
four locations, respectively, desired imaging objective possibly visible (at least one
work, dont know one). Problem 5 adds rock soil samples part goal
several waypoints one obtained (again, dont know waypoint
right sample). Problem 6 adds two waypoints, keeps goals Problem
5 changes possible locations rock soil samples. cases waypoints
connected tree structure, opposed completely connected.
Logistics domain conformant adaptation classical Logistics domain trucks
airplanes move packages. uncertainty initial locations packages. Thus, actions
relating movement packages conditional effect predicated package
actually location. conformant version, drivers pilots cannot sense communicate packages actual whereabouts. problems scale adding packages cities.
Logistics problems consist one airplane, cities airport, post office,
truck. airplane travel airports trucks travel within cities. first
problem two cities one package could start either post office, goal get
package second citys airport. second problem adds another package
possible starting points destination. third problem three cities
one package could post office reach third airport. fourth problem
adds second package third problem starting ending locations. fifth
problem three cities three packages, one two three post offices
reach different airports.
Conditional Problems conditional planning consider domains literature: Bombin-the-Toilet sensing BTS, Bomb-in-the-Toilet clogging sensing BTCS.
extend conformant Logistics Rovers include sensory actions.
Rovers problem allows rover, particular waypoint, sense availability image, soil, rock data location. locations collectable data expressed
one-of constraints, rover deduce locations collectable data failing sense
possibilities.
73

fiB RYCE , K AMBHAMPATI , & MITH

Logistics observations determine package location exists, observation
assumed made driver pilot particular location. Since several drivers
pilot, different agents make observations. information gained agents assumed
automatically communicated others, planner agent knowledge.5

6. Empirical Evaluation: Inter-Heuristic Comparison
start comparing heuristic approaches within planners. next section, continue
describing planners, using best heuristics, compare state art
approaches. section intend validate claims belief space heuristics measure
overlap perform well across several domains. justify using LU G multiple
planning graphs applying mutexes improve heuristics regression pruning belief
states.
compare many techniques within CAltAlt P conformant planning domains, addition test heuristics P conditional domains. performance metrics include total planning time number search nodes expanded. Additionally, discussing mutexes analyze planning graph construction time. proceed
showing heuristics perform CAltAlt various mutex computation schemes
LU G affect performance. present P performs different
heuristics conformant conditional domains, explore effect sampling proportion
worlds build SG1 , G, LU G graphs, compare heuristic estimates P
optimal plan length gauge heuristic accuracy. finish summary important
conclusions.
compute mutexes planning graphs CAltAlt planning graph(s)
built search episode mutexes help prune inconsistent belief states encountered
regression search. abstain computing mutexes P progression
build new planning graphs search node want keep graph computation time low.
exception discussion sampling worlds construct planning graphs,
planning graphs constructed deterministically. means single graph unioned
single graph SGU , G LU G graphs built possible worlds.
6.1 CAltAlt
results CAltAlt conformant Rovers, Logistics, BT, BTC domains, terms
total time number expanded search nodes, presented Table 3. show number
expanded nodes gives indication well heuristic guides planner. total
time captures amount time computing heuristic searching. high total time
high number search nodes indicates poor heuristic, high total time low number
search nodes indicates expensive informed heuristic.
discuss Ring Cube Center domains CAltAlt cannot solve
even smallest instances. Due implementation details planner performs poorly
domains actions several conditional effects hence scale. trouble stems
5. problem may interesting investigate multi-agent planning scenario, assuming global communication
(e.g. radio dispatcher).

74

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

Problem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70

h0
2255/5
49426/8

1108/9

19/2
4837/10

30/3
15021/19

-

hcard
18687/14

4268/9

14/2
56/10
418/20
1698/30
5271/40
12859/50
26131/60
48081/70
82250/80
16/3
161/19
1052/39
3823/59
11285/79
26514/99
55687/119
125594/140

hSG
RP
543/5
78419/8
91672/10

198/9
7722/15
3324/14
141094/19

18/2
5158/10

16/3
15679/19

-

G
hM
mRP
542/5
8327/8
20162/10
61521/16

183/9
15491/15
70882/14

20/2
8988/10

33/3
41805/19

-

G
hM
RP U
185/5
29285/9
2244/11
3285/15

1109/9
69818/19

21/2
342/10
2299/20
9116/30
44741/40

23/3
614/19
2652/39
9352/59
51859/79

-

LU G(F X)

hRP
15164/5
32969/8
16668/10
31584/13

1340/9
18535/15
16458/15
178068/19

12/2
71/10
569/20
2517/30
7734/40
18389/50
37820/60
70538/70
188603/80
18/3
1470/19
51969/39
484878/59

-

Table 3: Results CAltAlt conformant Rovers, Logistics, BT, BTC. data Total
Time / # Expanded Nodes, indicates time (20 minutes) - indicates
attempt.

weak implementation bringing general propositional formulas (obtained regression
several conditional effects) CNF.
describe results left right Table 3, comparing different planning graph
structures relaxed plans computed planning graph. start non-planning
graph heuristics h0 hcard . expected, h0 , breadth-first search, perform well
large portion problems, shown large number search nodes inability scale
solve larger problems. notice hcard heuristic performance good BT
BTC problems (this confirms results originally seen Bertoli, Cimatti, & Roveri, 2001a).
However, hcard perform well Rovers Logistics problems size
belief state, planning, necessarily indicate belief state good plan.
Part reason hcard works well domains measures knowledge, plans
domains largely based increasing knowledge. reason hcard performs poorly
domains finding causal support (which measure) important
knowledge domains.
75

fiB RYCE , K AMBHAMPATI , & MITH

Next, single planning graph (SGU ), CAltAlt reasonably well hSG
RP heuristic
Rovers Logistics domains, fails scale well BT BTC domains. Rovers
Logistics comparatively fewer initial worlds BT BTC problems. Moreover
deterministic plans, assuming initial state real state, somewhat similar Rovers
Logistics, mostly independent BT BTC. Therefore, approximating fully observable plan single graph relaxed plan reasonable plans achieving goal
world high positive interaction. However, without high positive interaction heuristic
degrades quickly number initial worlds increases.
multiple planning graphs, CAltAlt able perform better Rovers domain, takes
quite bit time Logistics, BT, BTC domains. Rovers, capturing distance estimates
individual worlds aggregating means tends better aggregating
worlds computing single distance estimate (as single graph). Logistics, part
reason computing multiple graphs costly computing mutexes
planning graphs. BT BTC, total time increases quickly number planning
graphs, number relaxed plans every search node increase much problems get larger.
G
MG
Comparing two multiple graph heuristics6 CAltAlt namely hM
mRP hRP U ,

G
see effect choices state distance aggregation. hmRP relaxed plan heuristic
aggregates state distances, found planning graph, taking maximum distance.
G
hM
RP U unions relaxed plans graph, counts number actions unioned
G
relaxed plan. single graph relaxed plan, hM
mRP relaxed plan essentially measures
one state state distance; thus, performance suffers BT BTC domains. However, using
unioned relaxed plan heuristic, capture independence among multiple worlds
scale better BT BTC. Despite usefulness unioned relaxed plan, costly
compute scalability limited, turn LU G version measure.
LU G(F X)

LU G, use hRP
heuristic CAltAlt. heuristic uses LU G
G
full cross-world mutexes (denoted F X). similar hM
RP U heuristic, measuring overlap
important, improving speed computing heuristic tends improve scalability
CAltAlt. CAltAlt slower Rovers BTC domains using LU G, note
added cost computing cross-world mutexes able improve
speed relaxing mutexes, describe shortly.
6.2 Mutexes
Mutexes used help determine belief state unreachable. Mutexes improve pruning
power heuristics accounting negative interactions. mutexes used improve
heuristics, reasonable compute subset mutexes. would know
mutexes cost effective number possible mutexes find
quite large.
use several schemes compute subset mutexes. schemes combine different
types mutexes types cross-world checking. mutex types are: computing mutexes
(NX), computing static interference mutexes (StX), computing (StX) plus inconsistent support competing needs mutexes dynamic mutexes (DyX), computing (DyX) plus induced
mutexes full mutexes (FX). cross-world checking (see appendix B) reduction schemes are:
G
6. show hM
sRP P D.

76

fiProblem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70

LU G(N X)

hRP
13/1112/51
20/904/41
13/8704/384

5/868/81
10/63699/1433

1/34/2
4/72/10
19/452/20
62/1999/30
130/6130/40
248/14641/50
430/30140/60
680/55202/70
1143/135760/80
0/62/3
4/93/19
21/546/39
58/2311/59
133/6889/79
260/15942/99
435/32201/119
742/62192/139

LU G(StX)

hRP
19/1119/51
16/903/41
17/8972/384

10/868/81
88/78448/1433

0/13/2
4/56/10
22/448/20
59/1981/30
132/6170/40
255/14760/50
440/29891/60
693/55372/70
1253/140716/80
1/16/3
4/77/19
32/545/39
61/2293/59
149/6879/79
261/16452/99
443/32923/119
745/61827/139

LU G(DyX)

hRP
15453/89/6
13431/138/8
17545/185/10
32645/441/14
698575/3569/45

1250/117/9
16394/622/15
17196/1075/15
136702/1035/19

0/13/2
13/57/10
120/453/20
514/1999/30
1534/6432/40
3730/14711/50
7645/30127/60
15019/55417/70
26478/132603/80
0/15/3
14/78/19
139/553/39
543/2288/59
1564/6829/79

-

LU G(F X)

hRP
15077/87/6
32822/147/8
16481/187/10
31293/291/14

1242/98/9
18114/421/15
16085/373/15
176995/1073/19

0/12/2
13/58/10
120/449/20
509/2008/30
1517/6217/40
3626/14763/50
7656/30164/60
14636/55902/70
26368/162235/80
4/14/3
1388/82/19
51412/557/39
482578/2300/59

-

LU G(DyXSX)

hRP
15983/87/6
10318/139/8
10643/185/10
14988/291/14
61373/3497/45
217507/3544/37
791/116/9
2506/356/15
10407/403/15
24214/648/19
52036/2690/41
0/16/2
12/59/10
102/450/20
421/1994/30
1217/6326/40
2866/14707/50
5966/30017/60
11967/55723/70
21506/136149/80
0/16/3
13/76/19
105/546/39
427/2294/59
1211/6798/79
2890/16184/99
6045/32348/119


LU G(DyXIX)

hRP
15457/87/6
10625/134/8
11098/209/10
16772/291/14
379230/3457/45
565013/3504/37
797/117/9
7087/428/15
10399/408/15
71964/871/19
328114/4668/52
0/15/2
14/59/10
139/454/20
600/2007/30
1822/6163/40
4480/14676/50
9552/30337/60
18475/55572/70
32221/105654/80
1/14/3
16/75/19
140/549/39
606/2300/59
1824/6816/79
4412/16414/99
9492/32350/119


LU G(F XSX)

hRP
15098/86/6
10523/138/8
10700/191/10
14726/290/14
60985/3388/45
225213/3408/37
796/115/9
2499/352/15
10214/387/15
23792/642/19
52109/2672/41
0/25/2
13/59/10
105/444/20
413/1986/30
1196/6113/40
2905/14867/50
5933/30116/60
11558/55280/70
21053/139079/80
1/13/3
14/75/19
110/555/39
444/2287/59
1253/6830/79
2926/16028/99
6150/32876/119


LU G(F XIX)

hRP
15094/85/6
14550/138/8
11023/184/10
16907/290/14
378869/3427/45
588336/3512/37
808/115/9
6968/401/15
10441/418/15
71099/858/19
324508/4194/52
0/13/2
14/56/10
137/454/20
596/2002/30
1797/6127/40
4392/14683/50
9234/29986/60
18081/55403/70
32693/109508/80
2/14/3
440/81/19
19447/568/39
199601/2401/59
1068019/6940/79

-

P LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

G
Table 4: Results CAltAlt using hLU
RP mutex schemes. data Graph Construction
Time (ms)/All Time (ms)/# Expanded Nodes, indicates time (20 minutes)
- indicates attempt.

77

fiB RYCE , K AMBHAMPATI , & MITH

computing mutexes across same-worlds (SX) computing mutexes across pairs worlds
intersection (conjunction) element labels (IX).
Table 4 shows within CAltAlt, using relaxed plan heuristic changing way
compute mutexes LU G drastically alter performance. Often, cross-world mutexes
numerous building LU G takes much time. see could reduce graph
G
construction overhead without hindering performance, evaluated hLU
RP LUG built
(a) considering cross-world relations, schemes (NX), (StX), (DyX), (FX); (b)
same-world relations schemes (DyX-SX) (FX-SX), (c) cross-world relations
possible worlds pairs intersection elements labels (DyX-IX) (FX-IX).
results show simpler problems BT BTC benefit much advanced
computation mutexes beyond static interference. However, Rovers Logistics problems, advanced mutexes play larger role. Mainly, interference, competing needs, inconsistent
support mutexes important. competing needs inconsistent support mutexes seem
large impact informedness guidance given LU G, scalability improves
here. Induced mutexes dont improve search time much, add graph computation
time. possible reason induced mutexes dont help much domains actions
two effects, unconditional conditional effect. Reducing cross-world mutex
checking helps quite bit. seems checking same-world mutexes sufficient
solve large problems. Interestingly, G graphs compute same-world interference, competing
needs, inconsistent support mutexes within graph, equating scenario (DyXSX), however, LUG provides much faster construction time, evidenced LU Gs ability
out-scale G.
6.3 P
show total time number expanded nodes P solving conformant
problems (including Ring Cube Center) Table 5, P solving conditional
problems Table 6. CAltAlt show total time number expanded nodes
G
test. add hM
sRP heuristic, implemented CAltAlt, takes summation
values relaxed plans extracted multiple planning graphs. compute mutexes
planning graphs used heuristics P mainly build planning
graphs search node. proceed first commenting performance P D,
different heuristics, conformant domains, discuss conditional domains.
conformant domains, P generally better CAltAlt. may attributed
part implementation-level details. P makes use existing (highly optimized) BDD
package belief state generation progression, previously mentioned, CAltAlt relies
less optimized implementation belief state generation regression. see next
section, regression planners employ sophisticated implementation perform much better,
could still benefit heuristics. Aside differences mention, see
similar trends performance various heuristics CAltAlt P D. Namely,
N G SG heuristics limited ability help planner scale, G heuristics help
planner scale better costly, LU G provides best scalability. difference
G LU G especially pronounced Cube Center Ring, size
initial belief state quite large instances scale. Interestingly Ring, breadth first
search single graph relaxed plan able scale due reduced heuristic computation time
78

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

Problem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70
CubeCenter 3
5
7
9
11
13
Ring 2
3
4
5
6
7
8
9
10

h0
540/36
940/249
3340/1150

560/169

450/3
760/1023

460/5
1090/2045

10/184
180/3198
1940/21703

20/15
20/59
30/232
160/973
880/4057
5940/16299
39120/64657
251370/261394


hcard
520/21
790/157
2340/755
14830/4067

530/102

460/2
590/428

460/4
970/1806

30/14
20/58
40/203
70/363
230/1010
700/2594
20/7
20/11
20/15
20/19
30/23
40/27
40/31
50/35
70/39

hSG
RP
590/6
700/15
3150/230
13480/1004

680/46

460/3
1560/1023

450/5
3160/2045

90/34
3510/1342
46620/10316
333330/46881

30/15
70/59
350/232
2270/973
14250/4057
83360/16299
510850/64657

-

G
hM
mRP
580/6
1250/32
3430/77
10630/181
85370/452
180890/416
970/58
2520/32
27820/927
5740/27
42980/59
450/2
6200/428

460/4
18250/1806

1050/61
60460/382

80/8
1500/41
51310/77

-

G
hM
sRP
580/6
750/10
1450/24
7000/163
12470/99
15780/38
730/21
6420/105
4050/83
29180/211
51380/152
450/2
820/10
6740/20
41320/30
179930/40
726930/50

460/3
980/19

370/9
11060/55
852630/359

80/7
500/8
6370/11
283780/16

-

G
hM
RP U
580/6
830/13
1370/23
2170/34
31480/73
31950/73
650/9
2310/20
2000/15
53470/382
471850/988
500/2
880/10
6870/20
44260/30
183930/40
758140/50

470/3
990/19
9180/39
54140/59
251140/79
1075250/99

0430/11
14780/82
1183220/444

80/8
920/19
19300/40

-

G
hLU
RP
590/6
680/11
850/16
1130/28
2050/36
9850/147
560/9
910/15
1130/14
3180/46
6010/42
460/2
520/10
1230/20
4080/30
11680/40
28420/50
59420/60
113110/70
202550/80
460/3
540/19
1460/39
4830/59
14250/79
34220/99
71650/119
134880/139
70/11
1780/205
27900/1774
177790/7226
609540/17027

30/8
70/10
250/24
970/44
4080/98
75020/574
388300/902

-

Table 5: Results P conformant Rovers, Logistics, BT, BTC, Cube Center, Ring.
data Total Time (ms)/# Expanded Nodes, indicates time - indicates
attempt.

low branching factor search. LU G able provide good search guidance, tends
take long time computing heuristics Ring.
able compare choices aggregating distance measures reG
laxed plans multiple graphs. see taking maximum relaxed plans, hM
mRP ,
assuming positive interaction among worlds useful Logistics Rovers, loses independence worlds BT BTC domains. However, taking summation relaxed plan
79

fiB RYCE , K AMBHAMPATI , & MITH

Problem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70

h0
550/36
1030/262
1700/467
5230/1321

530/118

460/5

450/6

-

hcard
480/21
550/36
590/48
620/58


460/3
470/19
510/39
620/59
850/79
1310/99
2240/119
24230/139
45270/159
460/3
480/19
510/39
660/59
970/79
1860/99
4010/119
7580/139

hSG
RP
580/6
780/15
3930/248
6760/387

740/46

450/3
111260/7197

470/5
271410/10842

-

G
hM
mRP
570/6
760/14
830/15
1020/20
16360/175
31870/173
580/10
1630/30
1360/20
4230/59
27370/183
460/3
970/19
9070/39
52410/59
207890/79
726490/99

470/3
1150/19
11520/39
62060/59
251850/79
941220/99

-

G
hM
sRP
570/6
710/12
830/15
1040/21
11100/232
24840/159
570/10
1300/36
1250/19
3820/57
19620/178
450/3
970/19
9060/39
52210/59
206830/79
719000/99

460/3
1140/19

-

G
hM
RP U
580/6
730/12
910/17
1070/21
12810/209
30250/198
600/10
1360/36
1290/19
3940/57
20040/178
470/3
1020/19
9380/39
55750/59
233720/79

470/3
1200/19
11610/39
64290/59
274610/79

-

G
hLU
RP
580/6
730/13
810/16
910/21
7100/174
13560/174
570/10
1250/36
1210/19
4160/57
20170/178
460/3
550/19
1610/39
5970/59
17620/79
43020/99
91990/119
170510/139
309940/159
470/3
590/19
1960/39
6910/59
19830/79
49080/99
103480/119
202040/139

Table 6: Results P conditional Rovers, Logistics, BTS, BTCS. data Total Time
(ms)/# Expanded Nodes, indicates time (20 minutes) - indicates
attempt.

G
values different worlds, hM
sRP able capture independence BT domain. notice
summation help P BTC domain; overestimate
heuristic value nodes counting Flush action world fact
G
needs done (i.e. miss positive interaction). Finally, using hM
RP U heuristic
well every domain, aside cost computing multiple graph heuristics,
account positive interaction independence taking overlap relaxed plans.
Again, LU G relaxed plan, analogous multiple graph unioned relaxed plan, P
scales well measure overlap lower cost computing heuristic significantly.

main change see using P versus CAltAlt direction search
different, hcard heuristic performs unlike before. BT BTC domains cardinality
work well progression size belief states change get closer
goal (it impossible ever know package contains bomb). However, regression
start belief state containing states consistent goal regressing actions limits
80

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

belief state states reach goal actions. Thus regression
size belief states decreases, progression remains constant.
performance P conditional domains exhibits similar trends conformant domains, exceptions. conformant domains, G relaxed plans tend
outperform SG relaxed plan, LU G relaxed plan best overall. Unlike conformant
G
domains, hM
mRP performs much better BTS BTCS BT BTC partly
conditional plans lower average cost. hcard heuristic better BTS BTCS
BT BTC belief states actually decrease size partitioned
sensory actions.
6.4 Sampling Worlds
evaluations point considered effectiveness different heuristics, computed respect possible worlds belief state. would use many
possible worlds can, reduce computation cost hopefully still get reasonable
heuristics considering subset worlds. scheme considering subsets worlds
heuristics sample single world (SG1 ), sample given percentage worlds
build multiple graphs, LU G.
MG
LU G
sampling approaches, use hSG
RP , hRP U , hRP relaxed plans. build
G LU G 10%, 30%, 50%, 70%, 90% worlds belief state, sampled
randomly. Figure 10, show total time taken (ms) solve every problem test set
(79 problems 10 domains). unsolved problem contributed 20 minutes total time.
comparison show previously mentioned heuristics: hSG
RP computed unioned single
U
graph SG , denoted Unioned compared sampled single graph SG1 denoted Single,
G
LU G
hM
RP U hRP computed worlds denoted 100%. total time heuristic
samples worlds averaged ten runs.
two major points see Figure 10. First, hSG
RP heuristic much effective
1
U
computed SG versus SG . SG1 less optimistic. builds
planning graph real world state, opposed union literals possible world states,
SGU . Respecting state boundaries considering single state better ignoring
state boundaries naively consider possible states. However, seen G
LU G heuristics, respecting state boundaries considering several states much better,
bringing us second point.
see different performance using possible worlds build multiple graphs
compared LU G. better using fewer worlds build multiple graphs
become costly number worlds increases. contrast, performance
improves possible worlds use LU G. Using possible worlds compute
heuristics good idea, takes efficient substrate exploit them.
6.5 Accuracy
heuristics account overlap possible worlds accurate
heuristics make assumption full positive interaction full independence. check
intuitions, compare heuristic estimates distance initial belief state
goal belief state heuristics used conformant problems solved P D. Figure
11 shows ratio heuristic estimate h(BSI ) optimal serial plan length h (BSI )
81

fiB RYCE , K AMBHAMPATI , & MITH

SG
MG
LUG

16

14

12

10

8

6

4

2

0
Unioned

Single

10%

30%

50%

70%

90%

100%

Figure 10: Total Time (hours) P solve conformant conditional problems
sampling worlds use heuristic computation.

several problems. points line (where ratio one) under-estimates,
over-estimates. problem instances shown optimal plan
length known.
G
MG

note domains hLU
RP hRP U heuristics close h , confirming

G

G

intuitions. Interestingly, hsRP hmRP close h Rovers Logistics;
whereas former close BT BTC problems, latter close CubeCenter
Ring. expected, assuming independence (using summation) tends over-estimate,
assuming positive interaction (using maximization) tends under-estimate. hSG
RP heuristic
tends under-estimate, cases (CubeCenter Ring) gives value zero (because
initial state satisfies goal). hcard heuristic accurate BT BTC,
under-estimates Rovers Logistics, over-estimates Cube Center Ring.

accuracy heuristics cases disconnected run time performance.
instance hcard highly overestimates Ring Cube Center, well domains
G
MG
exhibit special structure heuristic fast compute. hand, hLU
RP hRP U
82

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

10000
1000
100
10
1
0.1
0.01
0.001

3
3
3
3

3
33
3
3
3
3


3
3


3











+





33333333
2
2

2

22
2
2++

2

2
2






+


33
22
222 ++
33333
+
33
+
3
33
2
33 + 3 3
+
2
+
+
2
2+
2+
+
2+
2+
2+
2+
2+
2+
2
2+
2+
2+
2
hcard 3
hSG
RP +

G
hmRP
2

G
hsRP
G
hM
RP U
G
hLU
RP

Rv1 Rv4 L1

L5 B10

B80 BC10
BC70 C3
Problem

C13 R2

R10

Figure 11: Ratio heuristic estimates distance BSI BSG optimal plan length.
Rv = Rovers, L = Logistics, B = BT, BC = BTC, C = Cube Center, R = Ring.

accurate many domains, suffer Ring Cube Center costly
compute.
6.6 Inter-Heuristic Conclusions
findings fall two main categories: one, effective estimates belief state distances
terms state state distances, two, exploit planning graphs support
computation distance measures.
comparing ways aggregate state distance measures compute belief state distances,
found measuring interaction single graph heuristics tends poorly guide planners,
measuring independence positive interaction worlds works well specific domains,
measuring overlap (i.e. combination positive interaction independence) tends work well
large variety instances. studying accuracy heuristics found
cases accurate effective. however find accurate
best cases.
Comparing graph structures provide basis belief state distance measures, found
heuristics extracted single graph fail systematically account independence positive interaction among different possible worlds. Despite lack distance
measure, single graphs still identify structure domains Rovers Logistics.
accurately reflect belief state distances, multiple graphs reason reachability
world independently. accuracy comes cost computing lot redundant G structure limiting instances large belief states. reduce cost G structure
83

fiB RYCE , K AMBHAMPATI , & MITH

Planner
CAltAlt
P
MBP
KACMBP
CGP
SGP
GPT
YKA
CFF

Search Space
Belief Space
Belief Space
Belief Space
Belief Space
Planning Graph
Planning Graph
Belief Space
Belief Space
Belief Space

Search Direction
Backward
Forward
Forward/Backward
Forward
Backward
Backward
Forward
Backward
Forward

Conditional






Heuristic
Planning Graph
Planning Graph
Cardinality
Cardinality
Planning Graph
Planning Graph
State Space Plans
Cardinality
Planning Graph

Implementation
C
C
C
C
Lisp
Lisp
C
C
C

Table 7: Comparison planner features.
sampling worlds used construction. However planners able exhibit better scalability
considering worlds optimizing representation redundant structure
LU G. improvement scalability attributed lowering cost heuristic computation, retaining measures multiple state distances. LU G makes trade-off using
exponential time algorithm evaluation labels instead building exponential number
planning graphs. trade-off justified experiments.

7. Empirical Evaluation: Inter-Planner Comparison
first compare CAltAlt P several planners conformant domains,
compare P conditional planners conditional domains. purpose
section identify advantages techniques state art planners. end
section discussion general conclusions drawn evaluation.
7.1 Conformant Planning
Although work aimed giving general comparison heuristics belief space planning,
present comparison best heuristics within CAltAlt P
leading approaches conformant planning. Table 7 lists several features evaluated
planners, search space, search direction, whether conditional, type
heuristics, implementation language. Note, since approach uses different planning
representation (BDDs, GraphPlan, etc.), even use heuristics, hard get
standardized comparison heuristic effectiveness. Furthermore, planners use PDDLlike input syntax; MBP, KACMBP use AR encodings may give advantage
reducing number literals actions. gave MBP planners grounded
filtered action descriptions used CAltAlt P D. tried, report
results, giving MBP planners full set ground actions without filtering irrelevant actions.
appears MBP planners use sort action pre-processing performance
much worse full grounded set actions. Nevertheless, Table 8 compares MBP, KACMBP,
LU G(DyXSX)
G
GPT, CGP, YKA, CFF hRP
CAltAlt hLU
RP P respect
run time plan length.
MBP: MBP planner uses cardinality heuristic many cases overestimates plan distances
(as per implementation hcard ). MBP uses regression search conformant plans,
progression search conditional plans. interesting note difficult problem
84

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

Problem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70
CubeCenter 3
5
7
9
11
Ring 2
3
4
5
6
7
8

CAltAlt
LU G(DyXSX)
hRP U
16070/5
10457/8
10828/10
15279/13
64870/29
221051/25
907/9
2862/15
10810/15
24862/19
54726/34
16/2
71/10
552/20
2415/30
7543/40
17573/50
35983/60
67690/70
157655/80
16/3
89/19
651/39
2721/59
8009/79
19074/99
38393/119
65448/139


-

POND
G
hLU
RP
590/5
680/9
850/11
1130/16
2050/25
8370/25
560/9
910/15
1130/14
3180/22
6010/29
460/2
520/10
1230/20
4080/30
11680/40
28420/50
59420/60
113110/70
202550/80
460/3
540/19
1460/39
4820/59
14250/79
34220/99
71650/119
134880/139
70/9
1780/18
27900/29
177790/36
609540/47
30/6
70/8
250/13
970/17
4080/22
75020/30
388300/29

MBP

KACMBP

GPT

CGP

YKA

CFF

66/5
141/8
484/10
3252/13
OoM
727/32
37/9
486/24
408/14
2881/27
OoM
6/2
119/10
80/20
170/30
160/40
300/50
480/60
730/70
1080/80
8/3
504/19
98/39
268/59
615/79
1287/99
2223/119
3625/139
10/9
16/18
35/27
64/36
130/45
0/5
0/8
10/11
20/14
30/17
80/20
160/23

9293/5
9289/15
9293/16
9371/18
39773/40

127/12
451/19
1578/18
8865/22
226986/42
10/2
16/10
84/20
244/30
533/40
1090/50
2123/60
3529/70
1090/80
18/3
45/19
211/39
635/59
1498/79
10821/99
5506/119
2640/139
20/9
20/18
70/27
120/36
230/45
0/5
40/8
30/11
50/14
120/18
230/21
600/24

3139/5
4365/8
5842/10
7393/13
399525/20

916/9
1297/15
1711/11
9828/18
543865/28
487/2
627/10
472174/20

465/3
715/19
40/9
363/18
4782/27
42258/36
26549/45
31/5
35/8
60/11
635/14
51678/17

-

70/5
180/8
460/10
1860/13
OoM
60/6
290/6
400/8
1170/8

20/1
520/1
3200/1
10330/1
24630/1
49329/1
87970/1
145270/1

0/3
39370/19
28990/3


-

1220/7
2050/10
1740/12
2010/16
7490/27
24370/26
250/13
670/19
20280/21
17530/27
141910/40
0/2
0/10
20/20
80/30
160/40
250/50
420/60
620/70
3310/80
10/3
30/19
240/39
1210/59
3410/79
8060/50
15370/119
27400/139
0/9
0/19
20/34
80/69
190/68
0/5
0/8
20/11
80/14
110/17
300/20
480/23

70/5
30/8
10/10
10/13
18/22
21/23
10/9
12/15
14/12
12/18
25/28
0/2
30/10
4400/20
4500/30
26120/40
84730/50
233410/60
522120/70
979400/80
10/3
57/19
2039/39
23629/59
116156/79
334879/99

20/15
28540/45

360/12

-

LU G(DyXSX)

G
Table 8: Results CAltAlt using hRP
, P using hLU
RP , MBP, KACMBP, GPT,
CGP, YKA, CFF conformant Rovers, Logistics, BT, BTC, Cube Center, Ring.
data Total Time / # Plan Steps, indicates time (20 minutes), OoM
indicates memory (1GB), - indicates attempt.

instances Rovers Logistics domains MBP KACMBP tend generate much longer
plans planners. MBP outperform P cases find
solutions certain instances (like Rovers 5), likely heuristic. note
KACMBP MBP quite fast Cube Center Ring domains, trouble
domains Rovers Logistics. illustrates heuristic modeling knowledge opposed
reachability well domains challenge uncertainty reachability.
85

fiB RYCE , K AMBHAMPATI , & MITH

Optimal Planners: optimal approaches (CGP GPT) tend scale well, despite
good solutions. CGP trouble constructing planning graphs parallel conformant plan
depth increases. CGP spends quite bit time computing mutexes, increases planning
cost plan lengths increase. CGP much better shallow parallel domains BT,
find one step plans dunk every package parallel.
GPT performs progression search guided heuristic measures cost fully
observable plans state space. GPT finds optimal serial plans effective size
search space increases. GPT fails scale search space becomes difficult
even compute heuristic (due larger state space well).
YKA: YKA, CAltAlt regression planner, search engine different YKA
uses cardinality heuristic. YKA performs well domains search engine
based BDDs. notice difference progression regression comparing P
YKA, similar trends found comparison P CAltAlt. Additionally,
seems YKA stronger regression search engine CAltAlt. P able better
YKA Rovers Logistics domains, unclear whether search
direction heuristics.
CFF: Conformant FF, progression planner using relaxed plan similar LU G relaxed plan,
well Rovers Logistics domains uses highly optimized search
engine well cheap compute relaxed plan heuristic. However, CFF well
BT, BTC, Cube Center, Ring problems many literals
entailed belief state. CFF relies implicitly representing belief states terms literals
entailed belief state, initial belief state, action history.
literals entailed belief state, reasoning belief state requires
inference action history. Another possible reason CFF suffers encodings.
Cube Center Ring domains naturally expressed multi-valued state features,
transformation binary state features describe values must hold values
must hold. difficult CFF conditional effect antecedents contain several
literals heuristic restricted considering one literal. may CFF
choosing wrong literal simply enough literals get effective heuristics. However BT
BTC used one literal effect antecedents CFF still performs poorly.
7.2 Conditional Planning
Table 9 shows results testing conditional versions domains P D, MBP, GPT,
SGP, YKA.
MBP: P planner similar MBP uses progression search. P
uses AO* search, whereas MBP binary used uses depth first And-Or search. depth
first search used MBP contributes highly sub-optimal maximum length branches (as much
order magnitude longer P D). instance, plans generated MBP
Rovers domain rover navigating back forth locations several times
anything useful; situation beneficial actual mission use. MBP tends scale
well P domains tested. possible reason performance MBP
Logistics Rovers domains sensory actions execution preconditions,
prevent branching early finding deterministic plan segments branch. experimented
86

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

Problem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70

POND
G
hLU
RP
580/5
730/8
810/8
910/10
7100/19
13560/22
570/7
1250/12
1210/9
4160/15
20170/22
460/2
550/10
1610/20
5970/30
17620/40
43020/50
91990/60
170510/70
309940/80
470/2
590/10
1960/20
6910/30
19830/40
49080/50
103480/60
202040/70

MBP

GPT

SGP

YKA

3312/11
4713/75
5500/119
5674/146
16301/76
OoM
41/16
22660/177
2120/45
OoM
0/2
240/10
OoM
20/2
280/10
OoM
-

3148/5
5334/7
7434/8
11430/10

1023/7
5348/12
2010/8

510/2
155314/10
OoM
529/2
213277/10

-

70/5
760/7

5490/6

0/1
70/1
950/1
4470/1
13420/1
32160/1
90407/1
120010/1

10/2

-

3210/5
6400/7
7490/8
11210/10

1390/8


0/2
20/10
60/20
200/30
400/40
810/50
1350/60
2210/70
3290/80
0/4
210/12
2540/22
13880/32
46160/42
109620/52
221460/62
41374/72

G
Table 9: Results P using hLU
RP , MBP, GPT, SGP, YKA conditional Rovers, Logistics, BT, BTC. data Total Time / # Maximum possible steps execution,
indicates time (20 minutes), OoM indicates memory (1GB), -
indicates attempt.

MBP using sensory actions without execution preconditions able scale somewhat
better, plan quality much longer.
Optimal Planners: GPT SGP generate better solutions slowly. GPT better
Rovers Logistics problems exhibit positive interaction plans,
SGP well BT planning graph search well suited shallow, yet broad (highly
parallel) problems.
YKA: see YKA fares similar GPT Rovers Logistics, trouble scaling
reasons. think YKA may trouble regression sensory actions
since able scale reasonably well conformant version domains. Despite this,
YKA proves well BT BTC problems.
87

fiB RYCE , K AMBHAMPATI , & MITH

7.3 Empirical Evaluation Conclusions
internal comparisons heuristics within CAltAlt P D, well external comparisons several state art conformant conditional planners learned many
interesting lessons heuristics planning belief space.
Distance based heuristics belief space search help control conformant conditional plan
length because, opposed cardinality, heuristics model desirable plan quality metrics.
Planning graph heuristics belief space search scale better planning graph search
admissible heuristic search techniques.
planning graph heuristics presented, relaxed plans take account overlap
individual plans states source destination belief states
accurate tend perform well across many domains.
LUG effective planning graph regression progression search heuristics.
regression search, planning graphs maintain same-world mutexes provide best
trade-off graph construction cost heuristic informedness.
Sampling possible worlds construct planning graphs reduce computational cost,
considering worlds exploiting planning graph structure common possible worlds
(as LU G), efficient informed.
LUG heuristics help conditional planner, P D, scale conditional domains,
despite fact heuristic computation model observation actions.

8. Related Work & Discussion
discuss connections several related works involve heuristics and/or conditional planning first half section. second part section discuss extend
work directly handle non-deterministic outcomes actions heuristic computation.
8.1 Related Work
Much interest conformant conditional planning traced CGP (Smith & Weld, 1998),
conformant version GraphPlan (Blum & Furst, 1995), SGP (Weld et al., 1998), analogous
conditional version GraphPlan. graph search conducted several planning graphs,
constructed one possible initial states. recent work C-plan (Castellini
et al., 2001) Frag-Plan (Kurien et al., 2002) generalize CGP approach ordering
searches different worlds plan hardest satisfy world found first,
extended worlds. Although CAltAlt P utilize planning graphs
similar CGP Frag-plan uses compute reachability estimates. search
conducted space belief states.
Another strand work models conformant conditional planning search space
belief states. started Genesereth Nourbakhsh (1993), concentrated formulating set admissible pruning conditions controlling search. heuristics
choosing among unpruned nodes. GPT (Bonet & Geffner, 2000) extended idea consider
88

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

simple form reachability heuristic. Specifically, computing estimated cost belief state,
GPT assumes initial state fully observable. cost estimate done terms
reachability (with dynamic programming rather planning graphs). GPTs reachability heuristic
G
similar hM
mRP heuristic estimate cost farthest (maximum distance) state looking deterministic relaxation problem. comparison GPT, CAltAlt
P seen using heuristics better job considering cost belief
state across various possible worlds.
Another family planners search belief states MBP-family plannersMBP
(Bertoli et al., 2001b), KACMBP (Bertoli & Cimatti, 2002). contrast CAltAlt similar P D, MBP-family planners represent belief states terms binary decision
diagrams. Action application modeled modifications BDDs. MBP supports progression regression space belief states, KACMBP pure progression planner.
computing heuristic estimates, KACMBP pro-actively reduces uncertainty belief
state preferring uncertainty reducing actions. motivation approach applying
cardinality heuristics belief states containing multiple states may give accurate enough direction search. reducing uncertainty seems effective idea, note (a)
domains may contain actions reduce belief state uncertainty (b) need uncertainty reduction may reduced heuristics effectively reason multiple
worlds (viz., multiple planning graph heuristics). Nevertheless, could fruitful integrate knowledge goal ideas KACMBP reachability heuristics CAltAlt P
handle domains contain high uncertainty costly goals.
contrast domain-independent approaches require models domain
physics, PKSPlan (Petrick & Bacchus, 2002) forward-chaining knowledge-based planner
requires richer domain knowledge. planner makes use several knowledge bases, opposed
single knowledge base taking form belief state. knowledge bases separate binary
multi-valued variables, planning execution time knowledge.
YKA (Rintanen, 2003b) regression conditional planner using BDDs uses cardinality heuristic. Recently Rintanen developed related reachability heuristics consider
distances groups states, rely planning graphs (Rintanen, 2004).
recently, closely related work heuristics constructing conformant
plans within CFF planner (Hoffmann & Brafman, 2004). planner represents belief states
implicitly set known facts, action history (leading belief state), initial
belief state. CFF builds planning graph forward set known literals goal literals
backwards initial belief state. planning graph, conditional effects restricted
single literals antecedent enable tractable 2-cnf reasoning. planning graph,
CFF extracts relaxed plan represents supporting goal belief state states
initial belief state. biggest differences LU G CFF technique
LU G reasons forward source belief state (assuming explicit, albeit symbolic, belief
state), LU G restrict number literals antecedents. result, LU G
lose causal information perform backward reasoning initial belief state.
handling uncertainty labels label propagation reminiscent related
de Kleers assumption based truth maintenance system (ATMS) (de Kleer, 1986). ATMS
uses labels identify assumptions (contexts) particular statement holds, traditional
truth maintenance system requires extensive backtracking consistency enforcement identify
contexts. Similarly, reason multiple possible worlds (contexts)
89

fiB RYCE , K AMBHAMPATI , & MITH

LUG simultaneously, MG approach requires, backtracking, reproduction planning
graphs possible worlds.
Finally, CAltAlt P related to, adaptation work reachability
heuristics classical planning, including AltAlt (Nguyen et al., 2002), (Hoffmann & Nebel,
2001) HSP-r (Bonet & Geffner, 1999). CAltAlt conformant extension AltAlt uses
regression search (similar HSP-r) guided planning graph heuristics. P similar
uses progression search planning graph heuristics.
8.2 Extension Non-Deterministic Actions
scope presentation evaluation restricted planning initial state uncertainty deterministic actions, planning graph techniques extended include
non-deterministic actions type described Rintanen (2003a). Non-deterministic actions
effects described terms set outcomes. simplicity, consider Rintanens
conditionality normal form, actions set conditional effects (as before)
consequent mutually-exclusive set conjunctions (outcomes) one outcome effect
result randomly. outline generalization single, multiple, labelled planning graphs
reason non-deterministic actions.
Single Planning Graphs: Single planning graphs, built approximate belief states
sampled state, lend straight-forward extension. single graph ignores
uncertainty belief state unioning literals sampling state form initial planning
graph layer. Continuing single graph assumptions uncertainty, makes sense treat
non-deterministic actions deterministic. Similar approximate belief state set
literals form initial literal layer sample state, assume non-deterministic effect
adds literals appearing effect samples outcome action deterministic
(i.e. gives set literals). Single graph relaxed plan heuristics thus remain unchanged.
Multiple Planning Graphs: Multiple planning graphs much Conformant GraphPlan
(Smith & Weld, 1998). generalize splitting non-determinism current belief state
multiple initial literal layers splitting outcomes non-deterministic effects multiple
literal layers. idea root set new planning graphs level,
initial literal layer containing literals supported interpretation previous effect layer.
interpretations effect layer mean every possible set joint effect outcomes. set effect
outcomes possible two outcomes outcomes effect. Relaxed plan extraction
still involves finding relaxed plan planning graph. However, since planning graph
split many times (in tree-like structure) relaxed plan extracted path tree.
note technique likely scale exponential growth redundant
planning graph structure time. Further, experiments CGP enough trouble initial
state uncertainty. expect able much better LU G.
Labelled Uncertainty Graph: multiple planning graphs forced capture non
determinism splitting planning graphs initial literal layer,
literal layer follows least one non-deterministic effect. saw LU G labels
capture non-determinism drove us split initial literal layer multiple graphs.
such, labels took syntactic form describes subsets states source belief
state. order generalize labels capture non-determinism resulting uncertain effects,
90

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

need extend syntactic form. objective label represent sources
uncertainty (arising source belief state effects) causally support labelled item.
introduce graph layer Ok represent outcomes connect effects literals.
might seem natural describe labels outcomes terms affected literals,
lead trouble. problem literals effect outcomes describing states
different time literals projected belief state. Further, outcome appears two
levels graph describing random event different times. Using state literals describe
labels lead confusion random events (state uncertainty effect outcomes
distinct steps) causally support labelled item. pathological example effect
whose set outcomes matches one-to-one states source belief state. case,
using labels defined terms state literals cannot distinguish random event (the state
uncertainty effect uncertainty) described label.
two choices describing effect outcomes labels. choices introduce
new set label variables describe literal layer split. new variables used
describe effect outcomes labels confused variables describing initial state
uncertainty. first case, variables one-to-one matching original set
literals, thought time-stamped literals. number variables add
label function order 2F per level (the number fluent literals assuming boolean
fluents). second option describe outcomes labels new set fluents,
interpretation fluents matched particular outcome. case, add order
log |Ok | variables, Ok k th outcome layer. would actually lower many
outcomes deterministic effects need describe labels.
former approach likely introduce fewer variables lot non-deterministic
effects affect quite literals. latter introduce fewer variables
relatively non-deterministic effects whose outcomes fairly independent.
generalized labelling, still say item reachable source belief
state label entailed source belief state. even though adding
variables labels, implicitly adding fluents source belief state. example, say
add fluent v describe two outcomes effect. One outcome labelled v, v.
express source belief state BSP projected LU G new fluent
BSP (v v) = BSP . item labelled BSP v entailed projected belief
state (i.e. unreachable) one outcome causally supports it. outcomes support
item, reachable.
Given notion reachability, determine level extract relaxed
plan. relaxed plan procedure change much terms semantics
extra graph layer outcomes. still ensure literals causally supported
worlds labelled relaxed plan, whether worlds initial state
uncertainty supporting non-deterministic effects.

9. Conclusion
intent establishing basis belief state distance estimates, have:
Discussed heuristic measures aggregate state distance measures capture positive
interaction, negative interaction, independence, overlap.
91

fiB RYCE , K AMBHAMPATI , & MITH

Shown compute heuristic measures planning graphs provided empirical
comparisons measures.
Found exploiting planning graph structure reduce cost considering possible
states belief state preferable sampling subset states heuristics.
Shown labelled uncertainty graph capture support information multiple
graphs, reduces cost heuristic computation.
Shown labelled uncertainty graph useful conformant planning and, without
considering observational actions knowledge, perform well conditional planning.
intent work provide formal basis measuring distance belief
states terms underlying state distances. investigated several ways aggregate state
distances reflect various assumptions interaction state state trajectories. best
measures turned measure positive interaction independence, call
overlap. saw planners using notion overlap tend well across large variety
domains tend accurate heuristics.
Weve shown planning Labelled Uncertainty planning Graph LU G, condensed
version multiple graphs useful encoding conformant reachability information. main
innovation idea labels labels attached literals, actions, effect relations,
mutexes indicate set worlds respective elements hold. experimental
results show LU G outperform multiple graph approach. comparison
approaches, weve able demonstrate utility structured reachability heuristics
controlling plan length boosting scalability conformant conditional planning.
intend investigate three additions work. first, incorporate sensing
knowledge heuristics. already promising results without using features
planning graphs, hope help approaches scale even better conditional
problems. second addition consider heuristics stochastic planning problems.
major challenges associate probabilities labels indicate likelihood
possible world integrate reasoning probabilistic action effects.
Lastly, recently extended LU G within framework state agnostic planning
graphs (Cushing & Bryce, 2005), hope improve technique. state agnostic planning
graph essentially multiple source planning graph, analogy conventional planning
graph single source. Planning graphs already multiple destination, generalization
state agnostic planning graph allows us compute distance measure pair
states belief states. LU G seeks avoid redundancy across multiple planning graphs
built states belief state. extended notion avoid redundancy planning
graphs built every belief state. shown state agnostic LU G (SLU G)
built per search episode (as opposed LU G node) reduce heuristic computation
cost without sacrificing informedness.
Acknowledgments would thank Minh B. Do, Romeo Sanchez, Terry Zimmermam,
Satish Kumar Thittamaranahalli, Cushing helpful discussions feedback, Jussi Rintanen help YKA planner, Piergiorgio Bertoli help MBP planner.
work supported part NASA grants NCC2-1225 NAG2-1461, NSF grant IIS0308139, 2003 NASA RIACS SSRP, ARCS Foundation, IBM faculty award.
92

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

Appendix A. Additional Heuristics
completeness, present additional heuristics adapted classical planning reason
belief state distances type planning graph. Many heuristics appeared
previous work (Bryce & Kambhampati, 2004). show compute max, sum, level
heuristics single graph SG, multiple graphs G, labelled uncertainty graph LU G.
heuristics tend less effective relaxed plan heuristics, provide
reference. Section 4, describe heuristics terms regression search.
A.1 Single Planning Graph Heuristics (SG)
Like, relaxed plan single unmodified planning graph, cannot aggregate state distances
notion separate states lost forming initial literal layer, thus compute
heuristics aggregate state distances.
State Aggregation:
Max classical planning, maximum cost literal used get max heuristic, use
formulas describe belief states, take maximum cost clause cost
belief state find max heuristic hSG
max . maximum cost clause belief state,
respect single planning graph, is:
hSG
max (BSi ) =

max

C(BSi )

cost(C)

cost clause is:
cost(C) = min min k
lC k:lLk

find cheapest literal cost clause find maximum cost clause.
underestimate closest state current belief state.
Sum classical planning sum heuristic, take sum hSG
sum costs
clauses belief state estimate belief state distance

cost(C)
hSG
sum (BSi ) =
C(BSi )

heuristic takes summation costs literals closest estimated state
belief state, inadmissible may single action support every
clause, could count clause.
Level mutexes planning graph, compute level heuristic hSG
level
(without mutexes level heuristic equivalent max heuristic). level heuristic
maintains admissibility max heuristic improves lower bound considering
level planning graph literals constituent non-pairwise mutex.

level heuristic computed taking minimum among (BS
), first level
(lev(S)) planning graph literals present none marked
pairwise mutex. Formally:
hSG
level (BSi ) =

93

min

S(BSi )

lev(S)

fiB RYCE , K AMBHAMPATI , & MITH

A.2 Multiple Planning Graph Heuristics (M G)
Similar various relaxed plan heuristics multiple graphs, compute max, sum,
level heuristic multiple planning graphs aggregate maximum
summation respectively measure positive interaction independence. reason cannot
aggregate individual graph heuristics measure overlap numbers, sets
actions. Measuring overlap involves taking union heuristics graph union
numbers meaningful union action sets relaxed plans. before,
reason use multiple graphs state distance aggregation.
Positive Interaction Aggregation:
G
Max max heuristic hM
mmax computed multiple planning graphs measure posM
G
itive interaction hmmax heuristic. heuristic computes maximum cost clause
(BSi ) graph , similar hSG
mmax (BSi ) computed, takes
maximum. Formally:
G

hM
mmax (BSi ) = max (hmax (BSi ))


G
hM
mmax heuristic considers minimum cost, relevant literals belief state (those
reachable given possible world graph ) get state measures. maximum
taken estimate accounts worst (i.e., plan needed difficult
world achieve subgoals).

Sum sum heuristic measures positive interaction multiple planning graphs
G
hM
msum . computes summation cost clauses (BSi ) graph
takes maximum. Formally:
G

hM
msum (BSi ) = max (hsum (BSi ))


heuristic considers minimum cost, relevant literals belief state (those
reachable given possible worlds represented graph ) get state measures.
G
hM
mmax , maximum taken estimate costly world.

G
MG
MG
Level Similar hM
mmax hmsum , hmlevel heuristic found first finding hlevel
graph get state distance measure, taking maximum across

graphs. hlevel (BSi ) computed taking minimum among (BS
),

first level lev (S) planning graph literals present none
marked mutex. Formally:

hlevel (BSi ) =

min

S(BSi )

lev (S)



G
hM
mlevel (BSi ) = max(hlevel (BSi ))


Note heuristic admissible. reasoning classical planning, first
level subgoals present non-mutex underestimate true cost
state. holds graphs. Taking maximum accounts difficult
94

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

world achieve constituent BSi thus provable underestimate h .
G
GPTs max heuristic (Bonet & Geffner, 2000) similar hM
mlevel , computed
dynamic programming state space rather planning graphs.
Independence Aggregation: heuristics mentioned Positive Interaction Aggregation
augmented take summation costs found individual planning graphs rather
G
MG
MG
maximum. denote as: hM
smax , hssum , hslevel . None heuristics
admissible action may used worlds, count cost every world
using summation.
A.3 Labelled Uncertainty Graph (LU G)
max, sum, level heuristics LU G similar analogous multiple graph heuristics. main difference heuristics LU G much easier compute
positive interaction measures independence measures. reason positive interaction easier
compute find cost clause states belief state once, rather
multiple planning graphs. before, consider heuristics aggregate
state distances.
Positive Interaction Aggregation:
G
Max max heuristic hLU
mmax LU G finds maximum clause cost across clauses
current belief state BSi . cost clause first level becomes reachable.
Formally:


G
hLU
mmax (BSi )

=

max

C(BSi )


min

k:BSP |=k (C)

k

G
Sum sum heuristic hLU
msum LU G sums individual levels clause
(BSi ) first reachable. Formally:


G
min
hLU
(BS
)
=
k

msum

C(BSi )

k:BSP |=k (C)

G
Level level heuristic hLU
mlevel index first level BSi reachable.
Formally:
G
hLU
mlevel (BSi ) =

min

k:BSP |=k (BSi )



Independence Aggregation: heuristics mentioned positive interaction aggregation
augmented take summation costs state belief state. may inefficient
due fact lose benefit LU G evaluating heuristic state
BSP , rather states positive interaction aggregation. case
work similar multiple graph heuristic extraction, aside improved graph
construction time. positive interaction aggregation able implicitly calculate maximum
worlds heuristics, whereas sum heuristic need explicitly find
G
LU G
LU G
cost world. denote sum heuristics as: hLU
smax , hssum , hslevel .
95

fiB RYCE , K AMBHAMPATI , & MITH

Appendix B. Cross-World Mutexes
Mutexes develop possible world two possible worlds,
described Smith Weld (1998). Cross-world mutexes useful capture negative interactions belief state distance measures (mentioned Section 3). representation crossworld mutexes requires another generalization labelling mutexes. world mutexes
require keeping one label mutex signify possible worlds mutex holds. extended representation keeps pair labels, one element mutex;
x possible world mutex x possible world , denote mutex pair
(k (x) = S, k (x ) = ).
compute cross-world mutexes several worlds elements x x . example, k (x) = S1 S2 S3 k (x ) = S2 S3 , check cross-world mutexes need
consider mutexes world pairs (S1 , S2 ), (S1 , S3 ), (S2 , S2 ), (S2 , S3 ), (S3 , S2 ), (S3 , S3 ).
check mutexes intersection element labels k (x) k (x ) = S2 S3 ,
meaning cross world pairs check mutexes (S2 , S2 ), (S2 , S3 ), (S3 , S2 ),
(S3 , S3 ).
say formula f reachable projected belief state BSP , considering
cross-world mutexes, every pair states BSP , f reachable. pair states
, f reachable |= k (f ) every pair constituents , f
|= k (S ) |= k (S ), two literals either same-world
mutex = , mutex literals , across respective
worlds
= . mutex pair literals l l , respectively
mutex (k (l), k (l )) |= k (l) |= k (l ).
computation cross-world mutexes requires changes mutex formulas,
outlined next. major change check, instead single possible worlds S, pairs
possible worlds mutexes.
Action Mutexes: action mutexes hold actions executable different
possible worlds.
Interference Interference mutexes change cross-world mutexes, except
pair labels (k (a) = BSP , k (a ) = BSP ), instead single label.
Competing Needs Competing needs change mutexes cross-world mutexes two
actions , worlds respectively, could competing. Formally, crossworld competing needs mutex ((k (a) = S, k (a ) = ) exists worlds
if:
le (a),l e (a ) (k (l) = S, k (l ) = )
Effect Mutexes: effect mutexes hold effects occur different possible worlds.
Interference Effect interference mutexes change cross-world mutexes, except
pair labels (k (i (a)) = BSP , k (j (a )) = BSP ), instead single
label.
96

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

Lk

lk(p)
p


Ek

Ak

lk(a)


h(a)

lk(h(a))



(lk(p), lk(q))
Induced mutex across worlds:


(lk(j(a))lk(i(a)), lk(h(a)))





(lk(j(a)), lk(h(a)))

lk(q)
q
lk(a)


j(a)

lk(r)
r

lk(j(a))
i(a) induces j(a) in:
lk(i(a))lk(j(a))

i(a) lk(i(a))

Figure 12: Example cross-world induced effect mutex.
Competing Needs Effect competing needs mutexes change cross-world mutexes
two effects (a) j (a ), worlds respectively, could competing. Formally,
cross-world competing needs mutex (k (i (a)) = S, k (j (a )) = ) exists (a)
j (a ) worlds if:
li (a),l j (a ) (k (l) = S, k (l ) = )
Induced Induced mutexes change slightly cross-world mutexes. worlds one
effect induces another, remains same, mutex changes slightly.
j (a) k (j (a)) mutex h (a ) k (h (a )), (a) induces effect j (a)
possible worlds described k (i (a)) k (j (a)), induced mutex
(a) k (j (a)) k (i (a)) h (a ) k (h (a )) (see Figure 12).

Literal Mutexes: literal mutexes hold literals supported different possible worlds.
Inconsistent Support changes cross-world mutexes. mutex (k (l) = S, k (l ) = )
holds l l (a), j (a ) Ek1 l (a), l j (a ),
mutex k1 (i (a)) = S, k1 (j (a )) = ).

97

fiB RYCE , K AMBHAMPATI , & MITH

References
Bertoli, P., & Cimatti, A. (2002). Improving heuristics planning search belief space.
Proceedings AIPS02.
Bertoli, P., Cimatti, A., & Roveri, M. (2001a). Heuristic search + symbolic model checking =
efficient conformant planning. Proceedings IJCAI01.
Bertoli, P., Cimatti, A., Roveri, M., & Traverso, P. (2001b). Planning nondeterministic domains
partial observability via symbolic model checking. Proceedings IJCAI01.
Blum, A., & Furst, M. (1995). Fast planning planning graph analysis. Proceedings
IJCAI95.
Bonet, B., & Geffner, H. (1999). Planning heuristic search: New results. Proceedings
ECP99.
Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic search belief
space. Proceedings AIPS00.
Brace, K., Rudell, R., & Bryant, R. (1990). Efficient implementation bdd package. Proceedings 27th ACM/IEEE design automation conference.
Bryant, R. (1986). Graph-based algorithms Boolean function manipulation. IEEE Transactions
Computers, C-35(8), 677691.
Bryce, D., & Kambhampati, S. (2004). Heuristic guidance measures conformant planning.
Proceedings ICAPS04.
Castellini, C., Giunchiglia, E., & Tacchella, A. (2001). Improvements sat-based conformant
planning. Proceedings ECP01.
Cimatti, A., & Roveri, M. (2000). Conformant planning via symbolic model checking. Journal
Artificial Intelligence Research, 13, 305338.
Cormen, T. H., Leiserson, C. E., & Rivest, R. L. (1990). Introduction Algorithms. McGraw-Hill.
Cushing, W., & Bryce, D. (2005). State agnostic planning graphs. Proceedings AAAI05.
de Kleer, J. (1986). Assumption-Based TMS. Artificial Intelligence, 28(2), 127162.
Genesereth, M. R., & Nourbakhsh, I. R. (1993). Time-saving tips problem solving incomplete information. Proceedings AAAI93.
Hansen, E., & Zilberstein, S. (2001). LAO: heuristic-search algorithm finds solutions
loops. Artificial Intelligence, 129(12), 3562.
Hoffmann, J., & Brafman, R. (2004). Conformant planning via heuristic forward search: new
approach. Proceedings ICAPS04.
Hoffmann, J., & Nebel, B. (2001). planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research, 14, 253302.
Kambhampati, S., Ihrig, L., & Srivastava, B. (1996). candidate set based analysis subgoal
interactions conjunctive goal planning. Proceedings AIPS96.
Koehler, J., Nebel, B., Hoffmann, J., & Dimopoulos, Y. (1997). Extending planning graphs
adl subset. Proceedings ECP97.
98

fiP LANNING G RAPH H EURISTICS B ELIEF PACE EARCH

Kurien, J., Nayak, P., & Smith, D. (2002). Fragment-based conformant planning. Proceedings
AIPS02.
Long, D., & Fox, M. (2003). 3rd international planning competition: Results analysis.
Journal Artificial Intelligence Research, 20, 159.
Nguyen, X., Kambhampati, S., & Nigenda, R. (2002). Planning graph basis deriving
heuristics plan synthesis state space CSP search. Artificial Intelligence, 135(1-2),
73123.
Nilsson, N. (1980). Principles Artificial Intelligence. Morgan Kaufmann.
Pednault, E. P. D. (1988). Synthesizing plans contain actions context-dependent effects.
Computational Intelligence, 4, 356372.
Petrick, R., & Bacchus, F. (2002). knowledge-based approach planning incomplete information sensing. Proceedings AIPS02.
Rintanen, J. (2003a). Expressive equivalence formalisms planning sensing. Proceedings ICAPS03.
Rintanen, J. (2003b). Product representation belief spaces planning partial observability.
Proceedings IJCAI03.
Rintanen, J. (2004). Distance estimates planning discrete belief space. Proceedings
AAAI04.
Smith, D., & Weld, D. (1998). Conformant graphplan. Proceedings AAAI98.
Weld, D., Anderson, C., & Smith, D. (1998). Extending graphplan handle uncertainty sensing
actions. Proceedings AAAI98.

99


