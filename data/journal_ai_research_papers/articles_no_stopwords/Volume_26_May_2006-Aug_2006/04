Journal Artificial Intelligence Research 26 (2006) 153-190

Submitted 10/05; published 06/06

Convexity Arguments Efficient Minimization
Bethe Kikuchi Free Energies
Tom Heskes

t.heskes@science.ru.nl

IRIS, Faculty Science, Radboud University Nijmegen
Toernooiveld 1, 6525 ED, Nijmegen, Netherlands

Abstract
Loopy generalized belief propagation popular algorithms approximate inference Markov random fields Bayesian networks. Fixed points algorithms
shown correspond extrema Bethe Kikuchi free energy,
approximations exact Helmholtz free energy. However, belief propagation always converge, motivates approaches explicitly minimize
Kikuchi/Bethe free energy, CCCP UPS.
describe class algorithms solves typically non-convex constrained
minimization problem sequence convex constrained minimizations upper
bounds Kikuchi free energy. Intuitively one would expect tighter bounds lead
faster algorithms, indeed convincingly demonstrated simulations. Several
ideas applied obtain tight convex bounds yield dramatic speed-ups CCCP.

1. Introduction
Pearls belief propagation (Pearl, 1988) popular algorithm inference Bayesian
networks. known exact special cases, e.g., tree-structured (singly connected)
networks Gaussian discrete nodes. networks containing cycles,
so-called loopy belief propagation empirically often leads good performance (approximate
marginals close exact marginals) (Murphy, Weiss, & Jordan, 1999; McEliece, MacKay,
& Cheng, 1998). notion fixed points loopy belief propagation correspond
extrema so-called Bethe free energy (Yedidia, Freeman, & Weiss, 2001) important
step theoretical understanding success.
Kikuchi free energy (Kikuchi, 1951) generalization Bethe free energy
lead better approximations exact Helmholtz free energy. fixed points
loopy belief propagation correspond extrema Bethe free energy, fixed points
algorithm called generalized belief propagation (Yedidia et al., 2001) correspond
extrema Kikuchi free energy.
problem loopy generalized belief propagation always
converge stable fixed point. New algorithms (Yuille, 2002; Teh & Welling, 2002)
derived therefore explicitly minimize Bethe Kikuchi free energy.
describe Section 2, minimization Kikuchi free energy corresponds usually nonconvex constrained minimization problem. Non-convex constrained minimization problems
known rather difficult solve, Section 3 first derive sufficient
conditions Kikuchi free energy convex (over set constraints). Section 4
derive class converging double-loop algorithms, inner loop
corresponds constrained minimization convex bound Kikuchi free energy,
c
2006
AI Access Foundation. rights reserved.

fiHeskes

outer-loop step recalculation bound. Based intuition
tightest bound yields fastest algorithm, come several ideas construct
tight bounds. see Yuilles (2002) CCCP algorithm corresponds special
case rather loose bound discuss relationship UPS algorithm Teh
Welling (2002) Section 4.5. simulations Section 5 illustrate use tight
convex bounds several inference problems. Implications issues discussed
Section 6. Technical details treated appendices.

2. Kikuchi Approximation
Exact inference graphical models often intractable. section introduce
Kikuchi approximation particular example variational approach towards approximate inference.
2.1 Graphical Models
undirected graph G = (V, E) consists set nodes vertices V = {1, . . . , N }
joined set edges E. place node variable xi takes values
finite discrete alphabet. vector containing variables denoted x (x1 , . . . , xn ).
Let subset V ; call region. clique fully connected subset V ; C
set cliques. potential, referred compatibility kernel function, (x )
strictly positive function depends variables part clique
. define probability distribution probability mass function
pexact (x)

1
(x ) ,
Z

(1)

C

Z normalizing constant, often called partition function. HammersleyClifford theorem (Besag, 1974) guarantees us underlying probability process
Markov respect graph and, vice versa, distribution Markov random field G strictly positive expressed form. process
moralization, directed graphical model (Bayesian network) transformed
corresponding undirected model. Consequently, probability distribution corresponding
Bayesian network written form (1) (Lauritzen, 1996).
Computing partition function Z, well computing marginals subsets variables, principle requires summation exponential number states. circumvent
exponential summation two kinds approaches: sampling techniques
variational methods. sampling, one draws samples exact probability distribution. variational methods try find approximation exact probability
distribution.
2.2 Variational Methods
Variational methods often derived approximation so-called free energy
X
XX
p(x ) log (x ) +
p(x) log p(x) E(p) S(p) .
(2)
F (p) =
C x

x

154

fiEfficient minimization Kikuchi free energy

first term, E(p), referred energy, second term S(p) entropy.
Functional minimization F (p) respect functions p(x) constraint
p(x) properly normalized yields pexact (x). Furthermore, partition function Z
follows
log Z = F (pexact ) .
stick exact free energy (2), really gain anything: entropy
part S(p) still consists sum exponentially many terms. Variational methods
based tractable approximation free energy. roughly divided two
classes, mean-field Kikuchi approximations. mean-field approach one
confines minimization free energy restricted class (tractable) probability
distributions instead considering class P probability distributions:
log Z = F (pexact ) = min F (p) min F (p) .
pP

pT

crux choose class entropy S(p) becomes tractable p .
Note however restriction typically affects energy term E(p) (Jordan,
Ghahramani, Jaakkola, & Saul, 1998; Jaakkola & Jordan, 1999).
Kikuchi approximation free energy (2) leaves energy term
approximates entropy S(p) combination marginal entropies:
X
X
S(p) =
p(x) log p(x)
c (p)
R

x

=

X

c

R

X

p(x ) log p(x ) .

(3)

x

R denotes collection so-called regions; parameters c called Moebius
overcounting numbers.
2.2.1 Partially Ordered Sets
Following Pakzad Anantharam (2002, 2005), use language partially ordered
sets posets. Specifically, collection R regions viewed poset
ordering defined respect inclusion operator . region includes
region , written , variables part . use denote
strict inclusion, i.e., 6 . say covers R, written ,
exists R . visualize poset
so-called Hasse diagram region graph (see examples below). Given particular poset
R, Hasse diagram GR directed acyclic graph, whose vertices elements R,
whose edges corresponds cover relationships. is, edge
iff .
2.3 Cluster Variation Method
Kikuchis (1951) original cluster variation method (CVM), collections regions
overcounting numbers constructed follows. start defining collection
outer regions. minimal choice original set cliques C, choose
155

fiHeskes

combine cliques construct larger ones, similar process triangulation (Lauritzen,
1996). convenience, redefine potentials correspondingly, i.e.,
precisely one potential (x ) per outer region (see example below).
Given outer regions, construct new regions taking intersections
outer regions, intersections intersections, on, intersections
made. refer regions constructed way inner regions, combined
collection I. collection regions R (3) union outer
inner regions: R = I.
overcounting Moebius numbers original CVM follow Moebius
formula
X
(4)
c = 1
c .


definition c = 1 outer regions O.
Bethe free energy considered special case Kikuchi free energy.
Bethe free energy intersectionsPof intersections, i.e., one level
inner regions c = 1 n n O; 1 equals number outer regions
covering inner region .
2.3.1 Alternatives
Several alternatives original CVM, weaker constraints and/or constraints
choice regions overcounting numbers, proposed recently. Yedidia,
Freeman, Weiss (2005) present overview. particular choice inner regions
subsets overcounting numbers junction graphs (Aji & McEliece, 2001) join
graphs (Dechter, Kask, & Mateescu, 2002) leads entropy approximation
overcounting numbers inner regions negative. resulting algorithms
similar junction tree algorithm, applied graph loops.
entropy approximation follows original cluster variation method takes
account entropy contributions level outer regions consistent manner
and, theoretical grounds, seems reason deviate (Pakzad
& Anantharam, 2005). paper, therefore focus original cluster variation
method, analysis holds much generally poset region graph.
2.4 Constrained Minimization
Kikuchi approximation free energy depends marginals p(x )
R. replace minimization exact free energy complete
distribution p(x) minimization Kikuchi free energy
XX
X X
FKikuchi (q) =
q (x ) log (x ) +
c
q (x ) log q (x )
(5)
x

R

156

x

fiEfficient minimization Kikuchi free energy

pseudo-marginals q {q ; R} consistency normalization constraints
q (x ) 0 R x
X

q (x ) = 1 R

(positive)

(6a)

(normalized)

(6b)

(consistent)

(6c)

x

X

q (x ) = q (x ) , R;

x \

Referring class pseudo-marginals satisfying constraints Q,
approximation
log Z min FKikuchi (q) .
qQ

Furthermore, hope pseudo-marginals q (x ) corresponding minimum accurate approximations exact marginals pexact (x ). Kikuchi free
energy corresponding marginals exact Hasse diagram turns singlyconnected (Pakzad & Anantharam, 2005).
2.5 Illustration
illustration main concepts, consider probability model 4 variables
(nodes) pairwise interactions nodes visualized Figure 1(a).
obvious shorthand notation, exact distribution form
1
1
pexact (x) =
ij (xi , xj ) = 12 13 14 23 24 34 .
Z
Z
{i,j}

Note potentials originally defined single nodes always incorporated
definition two-node potentials. region graph corresponding minimal
choice outer regions, i.e., equivalent potential subsets, given Figure 1(b).
outer regions pairs nodes, inner regions subsets single nodes.
fact, case region graph equivalent so-called factor graph (Kschischang,
Frey, & Loeliger, 2001) Kikuchi approximation free energy boils
Bethe approximation:
XX
qij (xi , xj ) log ij (xi , xj )
FKikuchi (q) =
{i,j} xi ,xj

+

XX

qij (xi , xj ) log qij (xi , xj ) +

{i,j} xi ,xj

X
X
(1 ni )
qi (xi ) log qi (xi ) ,


xi

ni = 3 number outer regions containing inner region i.
cluster variation method allows us choose larger outer regions, example,
consisting triples {i, j, k}. redefine factorization potentials
pexact (x) =

1
ijk (xi , xj , xk ) = 123 124 134 234 ,
Z
{i,j,k}

157

fiHeskes

1
x1

x3

EE
EE yyy
EyEy
yy EEE

E
yy

1

1

1

1

1

1, 2 1, 3 1, 4 2, 3
2, 4
3, 4
66 II
II
II
u
u
u
u
II
II
u
66 III
uu
uu
66 III IIII IuIuIuIu
uu
u
66

II uu II uu

IuIu
Iu
6 IIII

uuuII
uu
1
2
3
4

x2

x4

-2

(a) Markov random field.

-2

-2

-2

(b) Hasse diagram Bethe approximation.

1

1

1

1

1, 2, 3I 1, 2, 4I 1, 3, 4I 2, 3, 4

II 66
Iu
Iu

II
uuII
uuII
uuu III uuu III
II 666


II 6


u
u





u
u
II 66

u
u


II
II
uuu
II 6
uu





u

uu


uu

1, 2 1, 3 1, 4 2, 3
2, 4
3, 4
66 II
II
II
u
u
u
u



u
u
II
II uu -1 uu -1
II
-1 666 -1
-1
-1
u
66 IIII IIII uuIuIuII
uu
II
II uuu
II uu
66



uI

II
uuuII
uu
1
2
3
4
1

1

1

1

(c) Region graph Kikuchi approximation.
Figure 1: Region graphs Bethe Kikuchi approximations. Lines nodes
Markov random field (a) indicate edges. region graphs (b) (c),
outer regions drawn highest level. Lines indicate covering
relationship, lower regions covered higher regions. oblique
numbers overcounting numbers follow Moebius formula.
Bethe approximation (b) corresponds minimal approximation
outer regions equivalent cliques graph; pairs nodes.
particular Kikuchi approximation (c) follows taking outer regions
node triples.

158

fiEfficient minimization Kikuchi free energy

example (distribute symmetrically)
1

123 [12 13 23 ] 2

1

124 [12 14 24 ] 2

1

134 [13 14 34 ] 2

1

234 [23 24 34 ] 2 ,
(assign first outer region)
123 12 13 23
124 14 24
134 34
234 1 .
corresponding region graph given Figure 1(c). first-level inner regions
pairs nodes second-level inner regions single nodes, overcounting numbers -1 1, respectively. Kikuchi approximation entropy boils

X
X
X
SKikuchi (q) =
Sijk
Sij +
Si .
{i,j,k}

{i,j}



intuitive reasoning behind approximation follows. sum threenode entropies overcounts two-node interactions (each combination {i, j} appears twice
rather once), therefore discounted once. single-node
interactions much discounted (overcounting number -1 times 3 appearances, compared 3 appearances overcounting number 1 three-node entropies),
yielding overcounting number 1 3 (1) 3 (1) = 1.
2.6 Generalized Loopy Belief Propagation
summarize, finding Kikuchi approximation partition function Z boils
minimization Kikuchi free energy respect set pseudo-marginals
linear constraints them. Introducing Lagrange multipliers constraints,
shown fixed points popular algorithm called loopy belief propagation correspond extrema Bethe free energy and, generally, fixed points generalized
belief propagation extrema Kikuchi free energy (Yedidia et al., 2001). However,
algorithms guaranteed converge minimum practice get stuck
example limit cycles. explains search convergent alternatives directly
minimize Kikuchi free energy, topic rest paper.

3. Convexity Kikuchi Free Energy
section derive sufficient conditions Kikuchi free energy convex
set consistency constraints (6). relevant Kikuchi free
energy indeed convex constraint set, must unique minimum
minimization problem relatively straightforward. Furthermore, argument
159

fiHeskes

use deriving conditions play important role construction efficient
minimization algorithms later on.
3.1 Sufficient Conditions
consider Kikuchi free energy (5) function pseudo-marginals q.
reasoning convexity, disregard energy term linear q.
entropy terms give either convex concave contribution, depending whether
corresponding overcounting numbers positive negative, respectively. Ignoring
constraints (6), free energy (5) convex concave contributions vanish,
i.e., c = 0 R .
However, really care subspace induced constraints (6). Therefore introduce notion convexity set constraints. call free energy
convex set constraints (6)
F (q1 + (1 )q2 ) F (q1 ) + (1 )F (q2 ) 0<<1 q1 ,q2 Q .
Note that, since constraints linear, q1 q2 satisfy constraints (6),
q1 + (1 )q2 . following, talk convexity Kikuchi free
energy, conditioning constraint set implicitly assumed.
One way proceed make use (consistency) constraints express Kikuchi
free energy terms outer region pseudo-marginals study convexity.
approach along lines. particular, replace inner region pseudomarginals correspond concave contributions outer region pseudo-marginals.
pseudo-marginals corresponding convex contributions concern. fact, may
able use convex contributions well compensate concave
contributions.
make reasoning precise, define positive regions (or perhaps better,
nonnegative) R+ , R+ { R; c 0} I+ negative regions R ,
R { R; c < 0} . idea, formulated following theorem,
Kikuchi free energy convex compensate concave contributions
negative regions R convex contributions positive regions R+ .
Theorem 3.1. Kikuchi free energy convex set constraints (6)
exists allocation matrix positive regions R+ negative regions
R satisfying
6= 0

( used compensate )

(7a)

0
X
c

(positivity)

(7b)

(sufficient amount resources)

(7c)

(sufficient compensation)

(7d)

R+



X

|c |

R



160

fiEfficient minimization Kikuchi free energy

Proof First all, note worry energy terms
linear q. words, prove theorem restrict showing
minus entropy


X
X
S(q) =
c (q )
|c |S (q )
R+

R

convex set constraints.
intermediate step, let us consider combination convex entropy contribution
positive region R+ concave entropy contribution negative inner region
R , subset :
X
X
(q) [S (q) (q)] =
q (x ) log q (x )
q (x ) log q (x )
x

=

X

q (x ) log q (x )

=

x

q (x ) log q (x )

x

x

X

x

X



q (x )

X

x\



q (x\ |x ) log q (x\ |x ) ,

used standard definitions
X
q (x )
q (x ) q (x\ |x )
q (x )
.
q (x )
x
\

first step, applied constraint q (x ) = q (x ) extended summation
x second term summation x . second step basically turned
difference two entropies (a weighted sum of) conditional entropies.
difference , depends q , is, Lemma A.1 Appendix A, convex
q . words, concave contribution fully compensated convex
contribution , yielding overall convex term relevant set constraints.
resulting operation matter resource allocation. concave contribution |c |S find convex contributions compensate it. Let denote
amount resources take positive region R+ compensate
negative region R . Obviously, positive region compensate negative regions
contains, = 0 subset , explains condition (7a).
Now, shorthand notation little bit rewriting


X
X
|c |S
c
S(q) =
R+

=

X

R+

=

X

R+



c



c

R

X

+



X



X











X X

R+

161

X

R





X

+



[S ]

X



X

R






|c |

X





|c | .

fiHeskes

P
Convexity first term guaranteed
P c 0 (7c), second term
0 (7b), third term |c | 0 (7d).

3.2 Checking Conditions

Checking conditions Theorem 3.1 cast form linear programming
problem, example follows. define auxiliary variable replacing condition (7c)

X
(8)
= |c | R (variable compensation)


solve linear programming problem attempts maximize single variable constraints implied four conditions. interpretation
try use available resources compensate much concave contributions
can. find solution 1 conditions satisfied: Kikuchi free energy
convex set constraints unique minimum. optimal turns
smaller 1, matrix satisfying constraints convexity
Kikuchi free energy guaranteed Theorem 3.1.
Instead solving linear program, often get away simpler checks.
example, guess particular check whether conditions (7) hold. obvious
choice
X
c
= n
1,

n
R ,


satisfies condition (7c) substituted (7d) yields condition
X

c +

R+ ,

c
0
n


R .

(9)

Similarly, choice
=

X
|c |
+

n

1

n+

R ,
+

satisfies condition (7d) yields condition
X

R ,

c
+ c 0 R+
n+


(10)

substituted (7c). (9) (10) holds, Theorem 3.1 guarantees convexity
Kikuchi free energy.
two conditions sufficient, necessary Theorem 3.1 apply.
necessary condition
X
X
c 0
(11)
c +
R

R+

easily derived summing condition (7d) R substituting condition (7c). condition (11) fails, cannot use Theorem 3.1 prove convexity
Kikuchi free energy.

162

fiEfficient minimization Kikuchi free energy

would conjecture conditions Theorem 3.1 sufficient,
necessary convexity Kikuchi free energy. pursue
here, irrelevant current purposes. Furthermore, may
relevant practice either, since convexity sufficient necessary condition unique minimum. Tatikonda Jordan (2002), Heskes (2004), Ihler,
Fisher, Willsky (2005) give conditions convergence loopy belief propagation
uniqueness minimum corresponding Bethe free energy. conditions
depend graphical structure, (strength the) kernels (x ).
3.3 Related Work
Chiang Forney (2001) present similar ideas, convex entropy terms compensating
concave terms set constraints, derive conditions convexity Bethe
free energy pairwise potentials. resulting conditions formulated terms
single-node marginals, may difficult validate practice generalize
Kikuchi case.
Closely related Theorem 3.1 following theorem Pakzad Anantharam
(2002, 2005).
Theorem 3.2. (Pakzad & Anantharam, 2002, 2005) Kikuchi free energy (5) convex
set consistency constraints imposed collection regions R (and hence
constrained minimization problem unique solution) overcounting numbers c
c satisfy:
X
X
R,
c +
c 0 .
(12)
R\S:
S,



words, subset R, sum overcounting numbers elements
ancestors R must nonnegative.
fact, using Halls (1935) matching theorem, shown conditions (7)
Theorem 3.1 equivalent conditions (12) Theorem 3.2. latter
direct require solution linear program.
Theorem 3.1 Theorem 3.2 used show Bethe free energy
graphs single loop convex set constraints (Heskes, 2004; McEliece &
Yildirim, 2003; Pakzad & Anantharam, 2002, 2005).
3.4 Minimization Convex Kikuchi Free Energy
Kikuchi free energy convex, guaranteed unique minimum,
minimum relatively easy find message-passing algorithm similar
standard (loopy) belief propagation.
basic idea follows. focus case overcounting numbers
positive. case negative overcounting numbers involved worked
Appendix B. Furthermore, rest paper ignore positivity
constraints (6a). easy check satisfied solutions obtain.
introduce Lagrange multipliers (x ) consistency constraints well

163

fiHeskes

normalization constraints construct Lagrangian


XX
X
L(q, ) = FKikuchi (q) +
q (x )
(x ) q (x )
,


+

X




x \

x

1

X
x



q (x ) .

(13)

Minimization Kikuchi free energy appropriate consistency normalization constraints is, terms Lagrangian, equivalent
min FKikuchi (q) = min max L(q, ) ,
q

qQ



minimization q unconstrained. Standard results constrained
optimization (e.g., Luenberger, 1984) tell us
min max L(q, ) max min L(q, ) ,
q





q

equality convex problems linear equality constraints. is, convex
problems allowed interchange maximum minimum q.
Furthermore, optimal q () corresponding minimum Lagrangian (13)
function unique, since L(q, ) convex q . Substitution solution
yields so-called dual
L () min L(q, ) = L(q (), ) .

(14)

q

dual concave unique maximum.
Many algorithms used find maximum dual (14). particular
one, derived Appendix B, given Algorithm 1. slightly differs presented
Yedidia et al. (2005) Yuille (2002) sending messages (messages directly related
Lagrange multipliers) inner regions outer regions, i.e., never
inner regions subsets inner regions. price one pay update
line 7 depends overcounting number c . Bethe free energy, c = 1 n ,
obtain standard (loopy) belief propagation update rules. particular ordering
Algorithm 1, running inner regions updating messages inner
region neighboring outer regions, guarantees dual (14) increases
iteration1 . local partition functions Z Z lines 10 7 chosen
normalize pseudo-marginals q (x ) q (x ). normalization strictly
necessary, helps prevent numerical instability. Algorithm 1 initialized
setting messages (x ) = 1 skipping lines 3 6 first iteration.
1. positive overcounting numbers c . argumentation negative overcounting numbers
complicated may require damping updates achieve convergence. See Appendix B details.

164

fiEfficient minimization Kikuchi free energy

Algorithm 1 Message-passing algorithm constrained minimization Kikuchi free
energy.
1:

converged

2:



3:
4:

O,
X
q (x ) =
q (x )
x\

5:

(x ) =

q (x )
(x )

6:

end

7:

q (x ) =

8:

O,
q (x )
(x ) =
(x )

1
q (x ) =
(x )
(x )
Z
I,

1
n +c
1
(x )
Z O,


9:
10:



11:

end

12:

end

13:

end

4. Double-Loop Algorithms Guaranteed Convergence
Even Kikuchi free energy convex, still run Algorithm 1
hope converges fixed point. fixed point must correspond
extremum Kikuchi free energy appropriate constraints (Yedidia et al.,
2001). Even better, empirically general Kikuchi free energy provably
Bethe free energy (Heskes, 2003), extremum fact minimum. However, practice
single-loop2 algorithm always converge resort double-loop
algorithms guarantee convergence minimum Kikuchi free energy.
4.1 General Procedure
introduce class double-loop algorithms based following theorem.
2. Note single loop refers message-passing algorithm nothing
notion single loop graphical model.

165

fiHeskes

Theorem 4.1. Given function Fconvex (q; q ) properties
Fconvex (q; q ) FKikuchi (q)

q,q Q

Fconvex (q; q) = FKikuchi (q)

Fconvex (q; q ) fifi
FKikuchi (q)
=
q
q
q =q

Fconvex (q; q ) convex q Q

(bound)

(15a)

qQ

(touching)

(15b)

q Q

(convex)

(15c)

algorithm
qn+1 = argmin Fconvex (q; qn ) ,

(16)

qQ

qn pseudo-marginals iteration n, guaranteed converge local minimum
Kikuchi free energy FKikuchi (q) appropriate constraints.
Proof immediate Kikuchi free energy decreases iteration:
FKikuchi (qn+1 ) Fconvex (qn+1 ; qn ) Fconvex (qn ; qn ) = FKikuchi (qn ) ,
first inequality follows condition (15a) (upper bound) second
definition algorithm. gradient property (15b) ensures algorithm
stationary points gradient FKikuchi zero. construction qn Q
n.
See Figure 2 illustration algorithm proof. fact, convexity
Fconvex used establish proof. But, argued Section 3.4,
algorithmic point view constrained minimization convex functional much simpler
constrained minimization non-convex functional. general idea, replacing
minimization complex functional consecutive minimization easier
handle upper bound functional, forms basis popular algorithms
EM algorithm (Dempster, Laird, & Rubin, 1977; Neal & Hinton, 1998) iterative
scaling/iterative proportional fitting (Darroch & Ratcliff, 1972; Jirousek & Preucil, 1995).
Intuitively, tighter bound, faster algorithm.
4.2 Bounding Concave Terms
first step, lay main ideas, build convex bound removing concave
entropy contributions . so, make use linear bound
X
X

q (x ) log q (x )
(17)
q (x ) log q (x ) ,
x

x

directly follows
0

KL(q , q )

=

X
x

"

q (x )
q (x ) log
q (x )

166

#

fiEfficient minimization Kikuchi free energy

(1)
(2)

(3)

Figure 2: Illustration proposed algorithm corresponding convergence proof.
iteration n, Fconvex (q; qn ) (dashed line) convex bound non-convex
FKikuchi (q) (solid line). touch qn , point (1), Fconvex (qn ; qn ) =
FKikuchi (qn ).
minimum, point (2), Fconvex (qn+1 ; qn )
Fconvex (qn ; qn ). corresponding Kikuchi free energy, point (3), obeys
FKikuchi (qn+1 ) Fconvex (qn+1 ; qn ) bounding property.

KL Kullback-Leibler divergence. choice Fconvex reads

X
XX
X
q (x )
(1)

Fconvex (q; q ) =
q (x ) log
q (x ) log q (x )
c
+
(x )
x
x
I+


X
X
X
X
|c | 1
q (x ) . (18)
|c |

q (x ) log q (x ) +




x

x

easy check functional properties (15a) (15c). last term
added fulfill property (15b). Next make crucial observation that, using
(1)
constraints (6) fixed q , rewrite Fconvex normal form (5):

X X
XX
q (x )
(1)
Fconvex
(q; q ) =
q (x ) log
+
c
q (x ) log q (x ) + C(q) , (19)

(x
)


x
x


C(q) evaluates zero q Q , implicitly depends q ,
c defined

X |c |
0

log q (x ) c
.
(20)
log (x ) log (x ) +
c I+
n
,



is, always incorporate terms linear q energy term
redefinition potentials. chosen distribute terms equally
n neighboring outer regions, choices possible well.
167

fiHeskes

term C(q) (19) evaluates zero q Q thus irrelevant
optimization inner loop. consists terms last one (18)
(1)
serve make bound Fconvex satisfy (15b). construction bounds below,
ignore terms: affect algorithm way3 .
(1)
Fconvex convex normal form, use Algorithm 1
solve constrained problem (16). resulting double-loop algorithm described
two lines.
Outer loop: recompute (20) q = qn .
Inner loop: run Algorithm 1 c c, yielding qn+1 .
inner loop, initialize messages converged values previous
inner loop.
4.3 Bounding Convex Terms
section show many cases make algorithm better
simpler. idea bound concave, convex entropy
contributions inner regions. is, enforce c 0 set


XX
q (x )
(2)

Fconvex (q; q ) =
q (x ) log
,
(21)
(x )
x

log (x ) log (x )

X c
log q (x ) .
n

(22)



(2)

Let us first explain algorithm based Fconvex simpler one based
(21), reference inner regions disappeared. fact, constraints
care outer regions pseudo-marginals agree
intersections. Consequently, inner loop (Algorithm 1), run
inner regions direct intersections outer regions, is,
exist outer regions x = x x . Similar arguments
used algorithm based (19) well, neglecting negative inner regions
correspond direct intersections outer regions. practice, however,
negative inner regions direct intersections outer regions, whereas many positive
inner regions arise next level, intersections intersections. See instance
example Figure 1, six negative inner regions direct intersections outer
regions, contrast four positive inner regions.
(2)
(17), applied positive inner regions, clear Fconvex (q; q )
(1)
(2)
(1)
Fconvex (q; q ): bound, Fconvex tighter bound Fconvex expect
(2)
algorithm based Fconvex perform better. remains shown
(2)
conditions FKikuchi (q) Fconvex (q; q ). following theorem comes in.
(1)
Fconvex .

3. Alternatively, could relax condition (15b) statement gradients Fconvex FKikuchi
equal subspace orthogonal constraints. milder condition, C(q)
well last term (18) longer needed.

168

fiEfficient minimization Kikuchi free energy

Theorem 4.2. functional Fconvex (21) convex bound Kikuchi free energy (5) exists allocation matrix negative inner regions
positive inner regions I+ satisfying
6= 0

( used compensate )

(23a)

0
X
|c |

(positivity)

(23b)

(sufficient amount resources)

(23c)

(sufficient compensation)

(23d)





X

c

I+



Proof surprisingly, proof follows line reasoning proof Theorem 3.1. First consider combination concave entropy contribution
(17) convex entropy contribution I+ , :
X
X

q (x ) log q (x ) +
q (x ) log q (x )
x

x



X

q (x ) log q (x ) +

x

X

q (x ) log q (x ) ,

(24)

x

follows

q (x\ |x )
0
q (x ) q (x\ |x )
q (x\ |x )
x



X
q (x )
q (x ) q (x )
=
q (x )
log
,
(x )
q
(x
)
q
(x
)
q






x
X







recognize term braces Kullback-Leibler divergence two
probability distributions.
(2)
show difference Fconvex FKikuchi nonnegative,
able compensate concave contributions c I+ convex contributions , without exceeding available amount resources
|c |. shorthand notation,
#
"
X
q (x )
K
,
q (x ) log
q (x )
x


decomposition
X
X
X
(2)
Fconvex
FKikuchi =
c K =
c K
|c |K


=

X





|c |

X





K +



X X

I+

(K K ) +



X

I+

169




X





c K 0 ,

fiHeskes

123456
1

2

3

4

5

1237

12457

13467

23567

4567

6

1

2

123
3

1245

1346

2356

456

127

137

237

147

257

457

367

467

567

1 1 1 1 1 1 1 1 1 1 1 1 1 1

4

5

6

12

13

23

14

25

45

36

46

56

17

27

37

47

57

67

1

1

1

1

1

1

1

1

1

1

1

1

1

1

1

7

(a) Outer regions.

7

1

2

3

4

5

6

1

1

1

1

1

1

1

(b) Region graph.
Figure 3: Smallest example showing conditions Theorem 4.2 need always
hold region graph overcounting numbers constructed cluster
variation method. (a) Visualization outer regions: black means
variable (1 7) part outer region (1 6).
(b) Region graph overcounting numbers boldface. positive overcounting numbers third level outweigh negative overcounting numbers second level.

inequality follows since terms guaranteed nonnegative
conditions (23) satisfied.
above, conditions Theorem 4.2 checked linear program.
generated many different sets overcounting numbers resulting Moebius formula (4), started wondering whether conditions (23) perhaps automatically satisfied. However, exhaustively checking possible outer region combinations given fixed
number variables, come counterexample. smallest counterexample
violates conditions Theorem 4.2, illustrated Figure 3.
Even if, counterexample, positive inner regions compensated
negative inner regions, pay get rid many possible. Finding optimal
assignment may complex problem, heuristics easy find (see Appendix C).
4.4 Pulling Tree
(1)

previous section tightened convex bound Fconvex Kikuchi free energy
FKikuchi bounding convex contributions positive regions well. Another way
get tighter bound bound part concave contributions negative

170

fiEfficient minimization Kikuchi free energy

inner regions. first illustrate considering Bethe free energy, i.e.,
non-overlapping negative inner regions (nodes) c = 1 n .
Bethe free energy convex singly-connected structures. Inspired Teh
Welling (2002), choose set nodes Ibound remaining nodes Ifree
become singly-connected take


XX
X
X
q (x )
(3)

Fconvex (q; q ) =
q (x ) log
+
(1 n )
q (x ) log q (x )
(x )
x
x
Ifree
X
X
+
(1 n )
(25)
q (x ) log q (x ) .
Ibound

x

is, bound entropy terms corresponding bounded nodes Ibound
simply keep entropy terms correspond free nodes Ifree . construction
Fconvex satisfies conditions (15). Furthermore, rewritten normal form (5)
definitions

X 1 n
0
Ibound

log (x ) log (x )
.
log q (x ) c
1

n
n
Ifree

,
bound



Note resulting inner-loop algorithm completely equivalent running standard belief propagation tree free nodes: send messages
bounded nodes Ibound well enforce constraints q (x ) = q (x )
, .
Rather pulling single tree, pull convex combination
trees. is, suppose several bounds, result pulling
particular tree corresponding set overcounting numbers ci .
convex combination
X
X
c =
wi ci wi 0
wi = 1




corresponds convex bound. generally, combine ideas
previous section choosing c resulting bound convex.
procedure given Appendix C. Basically, first try shield much
concave entropy contributions convex entropy contributions can. Next,
tighten bound incorporating convex contributions linear bounds
concave contributions manage shield first step. steps
cast form easy solve linear programming problem.
4.5 Related Work
(1)

double-loop algorithm described Section 4.2 based Fconvex closely related
Yuilles (2002) CCCP (concave-convex procedure) algorithm. Although originally formulated completely different way, CCCP applied minimization Kikuchi free
energy understood particular case general procedure outlined
Theorem 4.1. specifically, based bounding concave contributions
X
X
X
|c |
q (x ) log q (x )
q (x ) log q (x ) (|c | 1)
q (x ) log q (x ) , (26)
x

x

x

171

fiHeskes

compared (17). is, bounding concave entropy contributions, part concave terms taken convex side. reason
CCCP algorithm requires functional convex, independent
constraints involved4 . procedure, hand, makes use fact
functional convex set constraints. allows us use
tighter bounds, yielding efficient sometimes simpler algorithms. less important note, inner-loop algorithm particular message-passing scheme applied
Yuille (2002) somewhat different.
(3)
double-loop algorithm based Fconvex (25) inspired Teh Wellings
(2002) UPS (unified propagation scaling) algorithm. difference
bound entropy contributions nodes tree, UPS nodes (and thus
entropy contributions) clamped values resulting previous inner loop.
is, inner loop UPS algorithm corresponds minimizing


XX
X
X
q (x )
UPS

Fconvex (q; q ) =
q (x ) log
+
(1 n )
q (x ) log q (x )
(x )
x
x
Ifree
X
X

(1 n )
q (x ) log q (x ) .
Iclamped

x

constraints
q (x ) = q (x ) Ifree , , yet q (x ) = q (x ) Iclamped , .
boils iterative scaling algorithm, relatively easy solve.
outer-loop iteration, different choice made Ifree Iclamped . UPS
algorithm understood coordinate descent guaranteed converge
local minimum Bethe free energy (under appropriate conditions choices made
(3)
Ifree Iclamped ). inner loop results Fconvex allows changes
marginals q (x ) Ibound , i.e., flexible make larger steps. Loosely
(3)
UPS . Furthermore, approach
speaking, Fconvex tighter bound Fconvex
choose different subdivisions bounded free nodes
within inner loop.
Wainwright, Jaakkola, Willsky (2002b, 2002a) present similar ideas, exploiting
convexity Bethe free energy tree structures. Wainwright et al. (2002b) use
tree structure obtain efficient implementation loopy belief propagation, without
however guaranteeing convergence. Wainwright et al. (2002a) show particular convex
combinations convex Bethe free energies lead convex bounds exact Helmholtz
free energy (2). bounds, overcounting numbers inner regions still follow
Moebius relation (4), overcounting numbers outer regions smaller
equal 1. Constrained minimization bound similar constrained
(3)
minimization Fconvex algorithm used Wainwright, Jaakkola, Willsky (2003)
indeed closely related Algorithm 1.
4. procedure described Yuille (2002) often even moves part convex terms concave side.
makes (implicit) bound even worse corresponding algorithm slower. following
stick favorable interpretation CCCP algorithm based implicit
bound (26).

172

fiEfficient minimization Kikuchi free energy

5. Simulations
Intuitively, would expect algorithms based tightest bound converge
fastest terms outer-loop iterations. However, larger steps outer loop,
might need inner-loop iterations achieve convergence inner loop.
following simulations designed check this.
5.1 General Set-up
simulations compare four different algorithms, based different
bound.
convex tightest bound Kikuchi free energy convex. Based
ideas described Section 4.4 Appendix C.
negative zero bound obtained setting negative overcounting numbers
zero, explained Section 4.2.
zero bound described Section 4.3 follows setting overcounting
numbers, negative positive, zero. models considered below,
overcounting numbers satisfy conditions Theorem 4.2, i.e., setting zero
indeed yields bound Kikuchi free energy. Note zero
equivalent negative zero Bethe free energy.
cccp (rather favorable interpretation the) bound implicit Yuilles (2002) CCCP
algorithm, explained Section 4.5.
Algorithm 1 applied inner loop algorithms: difference
setting overcounting numbers c implied bound.
inner loop runs preset convergence criterion met. Specifically, end inner loop
inner region marginals change less 104 . criterion algorithms
happened converge, probably would case looser criteria.
example, Yuille (2002) reports two inner-loop iterations sufficient obtain
convergence.
simulations report Kullback-Leibler (KL) divergence exact
approximate marginals, either summed nodes subset nodes. Plots
different error functions look much same. Kikuchi/Bethe free energy
somewhat less illustrative: close minimum, marginals
thus KL divergence still change considerably. visualize KL divergence
function outer-loop iterations function floating point operations,
count necessary operations involved inner-loop outer-loop updates (i.e.,
involved convergence checks, computing KL divergence, on).
comparing number inner-loop iterations used different algorithms meet
convergence criterion, scale outer-loop iterations relative outer-loop iterations
convex algorithm. is, number outer-loop iterations used
algorithm reach particular level accuracy, consider corresponding number
outer-loop iterations used convex algorithm reach level.

173

fiHeskes

(a)

(b)
just_convex
negative_to_zero
cccp
kldivergence

kldivergence

just_convex
negative_to_zero
cccp
0

10

2

0

10

2

10

10
0

20

40
60
80
outerloop iterations

100

0

1

2
flops

3

4
6

x 10

Figure 4: Bethe approximation 9 9 Boltzmann grid. Kullback-Leibler divergence
exact approximate single-node marginals function outerloop iterations (a) floating point operations (b) three different algorithms.

done simulations quite number different problems problem instances, involving Markov random fields Bayesian networks. results shown
exemplary meant illustrate general findings summarize
below.
5.2 Bethe Free Energy Boltzmann Grid
first set simulations concerns minimization Bethe free energy Boltzmann grid 9 9 nodes pairwise interactions form


tj
ti
(27)
ij (xi , xj ) = exp wij (2xi 1)(2xj 1) + (2xi 1) + (2xj 1)
ni
nj
ni number neighbors node i, i.e., 2 corner node, 3 nodes
boundary, 4 nodes middle. Weights wij biases ti drawn
random normal distribution mean zero standard deviation 0.5.
Bethe approximation outer regions pairs neighboring nodes.
Figure 4 shows summed KL divergence exact approximate single-node
marginals function number outer loop iterations (a) function
number floating point operations (b) convex, negative zero,
cccp algorithms. seen that, expected, convex algorithms converges
faster negative zero algorithm, converges faster cccp algorithm. speed-up terms outer-loop iterations translates almost equivalent
speed-up terms flops. Indeed, seen Figure 5(a), number inner-loop
iterations required convex algorithm slightly higher
two algorithms.
curves Figure 4(a) mapped onto rough linear scaling
number outer-loop iterations. suggested straight lines
174

fiEfficient minimization Kikuchi free energy

2

outerloop iterations

10

(b)
number innerloop iterations

(a)
just_convex
negative_to_zero
cccp

1

10

0

10
0
10

8
6
4
2
0

1

just_convex
negative_to_zero
cccp

10
outerloop iterations

10
20
30
40
outerloop iterations (scaled)

Figure 5: Bethe approximation 9 9 Boltzmann grid. (a) Outer loop iterations
convex algorithm versus corresponding outer-loop iterations
two algorithms. (b) Number inner loop iterations needed meet
convergence criterion function outer-loop iterations, scaled according
(a).

Figure 5(a). slope lines relate 0.34, 1 (by definition), 1.35
convex, negative zero cccp, respectively (see convergence rates
Table 1). following argumentation shows striking correspondence
numbers respective bounds.
negative overcounting numbers
P
Bethe free energy FKikuchi
P add c = 207. respective convex
bounds Fconvex , sums c = 144, 0, 81. translate
fraction negative overcounting mass bounded, i.e.,
P
P
c
c
P
,
c

obtain, respectively 0.30, 1 (by definition), 1.39. is, appears
almost linear relationship tightness bound (here expressed fraction
concave entropy contributions bounded linearly) speed convergence.
noticed almost linear relationship simulations involving
Bethe free energy (no positive overcounting numbers).
5.3 Kikuchi Free Energy Boltzmann Grid

second set simulations 99 Boltzmann grid, outer regions
chosen squares four neighboring nodes. Potentials form (27)
weights biases drawn normal distribution standard deviation 4 0.5,
respectively. Note size weights much larger previous set
simulations, make problem still bit challenge Kikuchi approximation.
weights, Bethe approximation badly (summed Kullback-Leibler
175

fiHeskes

(a)

(b)

2

2

10
just_convex
negative_to_zero
all_to_zero
cccp

1

10

kldivergence

kldivergence

10

0

10

just_convex
negative_to_zero
all_to_zero
cccp

1

10

0

10

0

200
400
600
outerloop iterations

800

0

5

10
flops

15
7

x 10

Figure 6: Kikuchi approximation 9 9 Boltzmann grid. Kullback-Leibler divergence
exact approximate single-node marginals function outerloop iterations (a) floating point operations (b) four different algorithms.

divergence larger 10). Bethe Kikuchi algorithm, singleloop algorithm convergence problems: Bethe approximation typically gets
stuck limit cycle Kikuchi approximation tends diverge. total
8 8 = 64 outer regions (8 7) 2 = 122 negative inner regions (all node pairs
correspond intersections outer regions) 7 7 = 49 positive inner regions
(all single nodes correspond intersections node pairs).
Figure 6 shows KL divergence approximate exact single-node marginals
four different algorithms terms outer-loop iterations (a) floating point
operations (b). seen ordering (a) expected: tighter
bound, faster algorithm. terms floating point operations, convex
zero algorithm get much closer together.
Part explanation given Figure 7: convex algorithm requires considerably inner-loop iterations meet convergence criterion.
effect zero algorithm inner loop runs 112 negative
inner regions instead 161 positive negative inner regions. makes
inner-loop iteration zero requires factor 1.8 less floating point operations
inner-loop iteration three algorithms.
difficult find quantitative relationship tightness
bounds (asymptotic) convergence rates. One complications
negative, positive overcounting numbers play role. case,
algorithms still seem converge linearly, faster convergence rates tighter bounds.
convergence rates, expressed time scale corresponding exponential decay
(KL(t) KL() exp[t/ ], outer-loop iterations), summarized
Table 1.

176

fiEfficient minimization Kikuchi free energy

3

outerloop iterations

10

(b)
number innerloop iterations

(a)
just_convex
negative_to_zero
all_to_zero
cccp

2

10

1

10

0

10
0
10

25
20
15
10
5
0

1

10
outerloop iterations

just_convex
negative_to_zero
all_to_zero
cccp

5

10
15
20
25
outerloop iterations (scaled)

Figure 7: Kikuchi approximation 9 9 Boltzmann grid. (a) Outer loop iterations
convex algorithm versus corresponding outer-loop iterations
three algorithms. (b) Number inner loop iterations needed meet
convergence criterion function outer-loop iterations, scaled according
(a).

Figure 8: Graphical structure QMR-like network.
5.4 QMR Network
third set simulations concerns QMR-like (Quick Medical Reference) Bayesian
network (Heckerman, 1989; Jaakkola & Jordan, 1999): bipartite graph layer
disease nodes layer findings. particular network used simulations
generated Bayes Net Toolbox (Murphy, 2001). contains 20 finding nodes,
18 observed (positive), 10 hidden disease nodes; see Figure 8. diseases
Bernoulli probability distributions prior drawn random 0 0.01.
findings noisy-or conditional probability distributions without leakage. Diseases
findings linked randomly probability 0.5. absence leakage, large amount
findings, strong connectivity make relatively difficult inference problem.
outer regions take subsets implied conditional probability distribution, i.e.,
outer region consists disease findings linked it. Figure 9 gives
corresponding region graph.

177

fiHeskes

11111111111111111111111111111111
1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
0

0

1

1

0

1

1

1

1

0
2

1

2

2

0

1

1

1

1

1

0

1

1

1

1

1

0

1
1

Figure 9: Region graph resulting QMR-like network.

(a)
just_convex
negative_to_zero
all_to_zero
cccp

10

10

2

10

0

200
400
600
outerloop iterations

just_convex
negative_to_zero
all_to_zero
cccp

0

kldivergence

0

kldivergence

(b)

800

2

10

0

2

4

6
flops

8

10
8

x 10

Figure 10: Kikuchi approximation QMR-like network. Kullback-Leibler divergence
exact approximate single-node marginals function outerloop iterations (a) floating point operations (b) four different algorithms.

178

fiEfficient minimization Kikuchi free energy

(b)
number innerloop iterations

outerloop iterations

(a)
just_convex
negative_to_zero
all_to_zero
cccp

2

10

1

10

0

10
0
10

35

25
20
15
10
5
0

1

10
outerloop iterations

just_convex
negative_to_zero
all_to_zero
cccp

30

5
10
15
outerloop iterations (scaled)

20

Figure 11: Kikuchi approximation QMR-like network. (a) Outer loop iterations
convex algorithm versus corresponding outer-loop iterations
three algorithms. (b) Number inner loop iterations needed meet
convergence criterion function outer-loop iterations, scaled according
(a).

original
convex
negative zero
zero
cccp

-207
-144
0
0
81

Bethe
+

0
0
3.8
0 11.3
0 11.3
0 15.3

Kikuchi
+

-112 49
-64
1
11
0 49
41
0
0
29
112 49 153

-54
-34
0
0
52

QMR
+

35
15
6
35
67
0
17
35 166

Table 1: Summary asymptotic convergence ( time constant, time outerloop iterations, exponential decay) sums negative positive overcounting numbers original Kikuchi/Bethe free energy convex bounds
used different algorithms.

results found Figure 10 11. comparable
Kikuchi approximation Boltzmann grid. single-loop algorithm fails
converge. convex algorithm converges much faster three algorithms, requires inner-loop iterations less efficient zero algorithm, makes latter preferable terms floating point operations. However,
relatively straightforward speed-up convex algorithm. First, probably
need many inner-loop iterations outer loop converge properly.
secondly, bound part entropy contribution, efficient choice
would many zero overcounting numbers possible.

179

fiHeskes

5.5 General Findings
summarize points illustrated
encountered many simulations well.
tighter (convex) bound used inner loop, faster convergence
terms outer-loop iterations.
number outer-loop iterations needed meet prespecified convergence criterion tends decrease looser bound, never nearly enough compensate
slower convergence outer loop.
fact, observed strong dependency number inner-loop
iterations tightness bound bound convex problem
hard sense single-loop algorithm would fail converge.
terms floating point operations, looser bound sets overcounting numbers
inner loop zero, beat tighter bound negative overcounting numbers:
slower convergence terms outer-loop iterations compensated
efficient inner loop.
Pelizzola (2005) tests several convergent algorithms Kikuchi approximations problems statistical physics reports similar findings. study, convex algorithm, described first time Heskes, Albers, Kappen (2003), clearly outperforms competitors.

6. Discussion
article based perspective interested minima Kikuchi
free energy appropriate constraints. Finding minimum becomes possibly non-convex constrained minimization problem. Here, well studies,
approach solve non-convex problem sequential constrained minimization convex bounds Kikuchi free energy. presumption tighter
bounds yield faster algorithms, worked several ideas construct tight convex
bounds. simulation results article well obtained Pelizzola (2005)
clearly validate presumption show speed-ups significant.
Heskes, Zoeter, Wiegerinck (2004) apply bounds (approximate) parameter
learning directed graphical models.
double-loop algorithms considered article based convex bounds
Kikuchi free energy. principle, necessary: concern
inner-loop algorithm converges might well case tighter bounds. One
practical solution simply choose (tight) bound Kikuchi free, check whether
inner-loop algorithm converge, restart looser bound not. Alternatively,
construct tighter bounds making use conditions guaranteed convergence
belief propagation derived Tatikonda Jordan (2002), Heskes (2004),
Ihler et al. (2005) Bethe approximation.
suggested non-convergence single-loop generalized/loopy belief propagation indication Kikuchi/Bethe approximation inaccurate.
180

fiEfficient minimization Kikuchi free energy

results Section 5.3 5.4 show need always case. Apparently,
exist middle range problems Kikuchi free energy easy minimize, yield decent approximations. problems algorithms
described article useful.

Acknowledgments
author would thank Wim Wiegerinck, Onno Zoeter, Kees Albers, Bert Kappen fruitful discussions anonymous reviewers constructive comments.
work supported part Dutch Technology Foundation STW.

Appendix A: Convexity Difference Two Entropies
appendix treats two lemmas convexity difference two entropies.
first one used proof Theorem 3.1. similar lemma used McEliece
Yildirim (2003).
Lemma A.1. difference two entropies
X
X
q (x ) log q (x )
q (x ) log q (x )
(q )
x

x

=

X
x

convex q .



q (x )

X

x\



q (x\ |x ) log q (x\ |x )

Proof take step backwards write

(q ) =

X
x





q (x )
.
q (x ) log
X

q (x )

x\

taking derivatives, best interpret table q , specifying value q (x )
possible realization x , vector x playing role index. Taking second
derivatives, obtain
Hx ,x (q )

2 (q )
1
1
.
=
Ix ,x

q (x )q (x )
q (x ) q (x ) x ,x

Ix,x 1 elements x x equal zero otherwise.

181

fiHeskes

Next would show matrix positive semi-definite, i.e.,
tables q, interpreted vectors indices x ,
0

X

q(x )Hx ,x (q )q(x ) =

x ,x

x


X q 2 (x , x )
X

\

=

q (x\ , x )
x x


\

X q(x )q(x )


q (x )
q (x ) x ,x

x ,x



q(x\ , x )q(x\ , x )

X q 2 (x )

X

x\ ,x\



q (x )


i2
hP



X X q 2 (x\ , x )
x\ q(x\ , x )
=
P
.

q (x\ , x )

x\ q (x\ , x )
x x





\

Cauchys inequality,

X

a2k

k

X

b2k

k

"

X
k

ak bk

#2

,

follows term braces indeed semi-positive q
realization x .
see this, make substitutions x\ k, q(x\ , x )/ q (x\ , x ) ak ,
q
q (x\ , x ) bk find
{. . .}

X
k

a2k

P
2
k ak bk ]
P
0.
2
k bk
[

following related lemma used Appendix B.

Lemma A.2. difference two entropies
X
X
(q , q )
q (x ) log q (x )
q (x ) log q (x )
x

x

convex {q , q }.
Proof Hessian matrix components
Hx ,x



2 (q )
1
=
Ix ,x

q (x )q (x )
q (x )

Hx ,x



2 (q )
1

=


q (x )q (x )
q (x ) x ,x

Hx ,x



q (x )
2 (q )
.

= 2

q (x )q (x )
q (x ) x ,x

182

fiEfficient minimization Kikuchi free energy

Convexity requires q = (q (x ), q (x )),
q (x ) q (x )

0
=

X q2 (x )

2

Hx ,x
Hx ,x

Hx ,x
Hx ,x

X q (x )q (x )

q (x )


X
q (x ) q (x ) 2

.
q (x )
=
q (x ) q (x )
x
x

q (x )



x

+

!

q (x )
q (x )



X q (x )q2 (x )
q2 (x )

x



Appendix B: Minimizing Convex Kikuchi Free Energy
appendix, derive Algorithm 1 minimizing convex Kikuchi free energy
appropriate linear constraints. simplify notation, use convention runs
outer regions, inner regions.
First, note principle necessary explicitly take account
constraints (6), since constraints implied others. Obviously, constraint
two inner region marginals,
q (x ) = q (x ) ,
implied corresponding constraints inner region marginals outer
region subsuming inner regions,
q (x ) = q (x ) q (x ) = q (x ) .
is, take account constraints inner regions
inner regions. Similarly, normalization constraints outer region pseudo-marginals follow
normalization constraints inner region pseudo-marginals. So, sufficient set
constraints
X
q (x )

q (x ) = q (x ) q (x ) =
x\

X

q (x ) = 1

.

x

Introducing Lagrange multipliers (x ) corresponding constraints,
obtain Lagrangian
X X

XX
q (x )
q (x ) log q (x )
+
c
L(q, ) =
q (x ) log
(x )
x
x





XXX
X
X
X
+
(x ) q (x )
q (x ) +
1
q (x ) . (B-1)
x

x\

183



x

fiHeskes

Convex Independent Constraints
Let us first consider case overcounting numbers c strictly positive (c >
0). Then, Lagrangian convex set constraints, convex
q independent constraints. Minimization Lagrangian respect
pseudo-marginals follows setting derivatives zero, yielding

e (x )
(B-2)
q (x ) = (x )e1


q (x )

/c 1

= e



e (x )/c ,

(B-3)



following noted q q functions
Lagrange multipliers . Substituting solution back Lagrangian, obtain
dual
X
XX
X X
L () L(q (), ) =

q (x )
c
q (x ) .
(B-4)




x



x

Now, consider optimizing L () respect subset components corresponding
inner region , collected ( , (x ) ,x ), keeping
6= fixed. concavity dual L (), find maximum
direction setting corresponding derivatives zero. yields

L () fifi
= qnew (x ) qnew (x ) = 0 x ;
(x ) fi=new

X
L () fifi
=
1

qnew (x ) = 0 ,
(B-5)
fi=new
x
q new refers solution (B-2) (B-3) (x ) replaced new
(x )
new
.
Since

(B-2)

new

qnew (x )

e (x )
= (x ) q (x ) ,
e

solution new
(x ) must obey
new
new
(x ) = log q (x ) + (x ) + log q (x ) ,

still solve qnew (x ). Summing expression , substituting (B-3), solving qnew (x ) get
log qnew (x ) =

X
1
1
[log q (x ) (x )] +
(new c ) .
n + c
n + c


Now, obtain exactly updates Algorithm 1 define
(x ) = e (x ) (x ) = q (x )e (x ) ,
184

fiEfficient minimization Kikuchi free energy

properly normalize q (x ), line 7. normalization q (x ) line 10
fact unnecessary, since construction updates ensure q (x ) = q (x )
Z = 1.
bottom line particular ordering Algorithm 1 joint update
messages particular subset interpreted coordinate-wise gradient
ascent dual L (), updating Lagrange multipliers (x ) particular
time. Therefore Algorithm 1 guaranteed converge
unique maximum case positive overcounting numbers c .
Convex Set Constraints
Next, let us consider general case (some of) overcounting numbers
negative, Kikuchi free energy still convex set constraints.
consider case inner region overcounting numbers negative5 .
show that, sufficient damping updates, Algorithm 1 still guaranteed
converge unique minimum Kikuchi free energy set constraints.
Note direct application argumentation fails, solution (B-3)
q (x ) negative c corresponds maximum rather minimum. Consequently, dual L () (B-4) need concave. updates Algorithm 1
follow setting derivatives zero interpreted fixed-point iterations, coordinate ascent L (). Still, practice seem work fine indeed without
always increasing L (). following explain why: argue updates Algorithm 1 correspond coordinate ascent, rather something
coordinate descent-ascent convex-concave saddle function. sufficient damping,
algorithm converge unique saddle point, corresponds
minimum Kikuchi free energy set constraints.
Convexity set
P according Theorem 3.1, exists
P constraints implies,
matrix = |c | 1. Using q (x ) = q (x ), replace
Lagrangian (B-1)

XX
XX
X
q (x )
L(q, ) =
q (x ) log
q (x ) log q (x )


(x )
x
x





XXX
X
X
X
X
1
+
(x )
q (x )
q (x ) +
1
q (x ) . (B-6)
n
x
x
x








\



since, Lemma A.2 Appendix A,
X
X
q (x ) log q (x )
q (x ) log q (x )
x

x

convex {q (x ), q (x )}, Lagrangian (B-6) indeed convex q independent
constraints. Thus could apply argumentation above: find minimum
5. argumentation hold negative inner region entropy contributions
compensated positive inner region subset entropy contributions prove convexity Kikuchi free
energy. case, might need slightly different algorithm guarantee convergence.

185

fiHeskes

convex Lagrangian respect q, substitute corresponding solution q () back
Lagrangian obtain concave dual L (), maximize dual respect
. problem closed-form expression optimal q ()
thus closed-form expression dual L (), makes procedure
rather awkward.
Instead, distinguish outer region marginals, collected qO ,
inner region marginals, collected qI . rewritten consistency constraint terms
outer region marginals alone, replace constrained minimization respect
qO unconstrained maximization respect corresponding Lagrange multipliers
, leaving minimization respect qI normalization constraint
is. gives us saddle-point problem type minqI maxO . Even without explicitly
writing equations, tell maximization respect particular
corresponds finding
qnew (x ) = qnew
(x )

, .

Then, minimization respect q given fixed qnew (x ) immediately yields
X
qnew (x ) ,
qnew (x )


properly normalized sum 1. exactly updates particular inner
region Algorithm 1 amount to: yield unique maximum respect
minimum respect q , keeping q 6= fixed.
coordinate descent-ascent procedure works fine saddle function convex minimizing parameter concave maximizing parameter (e.g., Seung,
Richardson, Lagarias, & Hopfield, 1998). concavity immediate, convexity
qI follows convexity Lagrangian (B-6) q = (qO , qI ): minimizing
overall convex function parameters, qO , yields convex function
remaining parameters, qI . Technically, convergence unique solution
saddle-point problem proven construction Lyapunov function
decreases infinitesimal updates parameters descent ascent direction
zero unique saddle point (Seung et al., 1998). Convergence guaranteed
sufficiently damped updates, full ones Algorithm 1. Empirically full updates, correspond full maximization minimization one inner region
moving next one, work fine cases, occasionally indeed require little
damping. Wainwright et al. (2003) successfully apply damping similar algorithm
attempt minimize convexified Bethe free energy.

Appendix C: Constructing Tight Convex Bound
appendix, describe procedure constructing tight convex bound Fconvex
Kikuchi free energy FKikuchi . combines ideas Section 4.3 4.4. is,
first convexify Kikuchi free energy, bounding little concave contributions
negative inner regions possible. Next, terms bound anyways,
try incorporate many convex contributions can. leads following
procedure.
186

fiEfficient minimization Kikuchi free energy

Consider minus entropy
=


X

+





X

c +

X

c

,



I+






choose c c first term



X
X

X
X
c
c +
(c c )S ,
=
+



I+





(just) convex.

corresponding allocation matrix Theorem 3.1, define used resources
X
|c | c ,
c


rewrite
=


X


+





c +




X


X

X

c

I+

(c c )S +

X

I+



construction, first term still convex.





(c c )S




.



guarantee convexity, bound entropy contributions second
term . make bound tighter, include many convex
contributions can, still satisfying conditions Theorem 4.2. Call
corresponding overcounting numbers c c c c put remaining
c c back first term:


X

X
X
c
=
c +
+


I+



X

X

(c c )S .
(c c )S +


I+



Choose Fconvex first term plus linear bound second term.

find c first step similarly c third, use linear program
similar one described Section 3.2 checking conditions Theorem 3.1.
introduce slack variables replace condition (7d)
X
= (variable compensation) ,


187

fiHeskes

similar spirit (8). Furthermore, add inequality constraints |cP
|
(no need compensate |c |) search maximum
(compensate much possible). terms corresponding solution , set c =
c .

References
Aji, S., & McEliece, R. (2001). generalized distributive law free energy minimization. Proceedings Allerton Conference Communication, Control,
Computing.
Besag, J. (1974). Spatial interaction statistical analysis lattice systems. Journal
Royal Statistical Society Series B, 36, 192236.
Chiang, M., & Forney, G. (2001). Statistical physics, convex optimization sum
product algorithm. Tech. rep., Stanford University.
Darroch, J., & Ratcliff, D. (1972). Generalized iterative scaling. Annals Mathematical
Statistics, 43, 14701480.
Dechter, R., Kask, K., & Mateescu, R. (2002). Iterative join-graph propagation. Darwiche, A., & Friedman, N. (Eds.), Proceedings UAI-2002, pp. 128136.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood incomplete data
via EM algorithm. Journal Royal Statistical Society B, 39, 138.
Hall, P. (1935). representatives subsets. Journal London Mathematical Society,
10, 2630.
Heckerman, D. (1989). tractable inference algorithm diagnosing multiple diseases.
Kanal, L., Henrion, M., Shachter, R., & Lemmer, J. (Eds.), Proceedings Fifth
Workshop Uncertainty Artificial Intelligence, pp. 163171, Amsterdam. Elsevier.
Heskes, T. (2003). Stable fixed points loopy belief propagation minima Bethe
free energy. Becker, S., Thrun, S., & Obermayer, K. (Eds.), Advances Neural
Information Processing Systems 15, pp. 359366, Cambridge. MIT Press.
Heskes, T. (2004). uniqueness loopy belief propagation fixed points. Neural
Computation, 16, 23792413.
Heskes, T., Albers, K., & Kappen, B. (2003). Approximate inference constrained optimization. Uncertainty Artificial Intelligence: Proceedings Nineteenth
Conference (UAI-2003), pp. 313320, San Francisco, CA. Morgan Kaufmann Publishers.
Heskes, T., Zoeter, O., & Wiegerinck, W. (2004). Approximate Expectation Maximization. Thrun, S., Saul, L., & Scholkopf, B. (Eds.), Advances Neural Information
Processing Systems 16, pp. 353360, Cambridge. MIT Press.
Ihler, A., Fisher, J., & Willsky, A. (2005). Loopy belief propagation: Convergence
effects message errors. Journal Machine Learning Research, 6, 905936.
Jaakkola, T., & Jordan, M. (1999). Variational probabilistic inference QMR-DT
network. Journal Artificial Intelligence Research, 10, 291299.
188

fiEfficient minimization Kikuchi free energy

Jirousek, R., & Preucil, S. (1995). effective implementation iterative proportional fitting procedure. Computational Statistics Data Analysis, 19, 177189.
Jordan, M., Ghahramani, Z., Jaakkola, T., & Saul, L. (1998). introduction variational
methods graphical models. Jordan, M. (Ed.), Learning Graphical Models,
pp. 183233. Kluwer Academic Publishers, Dordrecht.
Kikuchi, R. (1951). theory cooperative phenomena. Physical Review, 81, 9881003.
Kschischang, F., Frey, B., & Loeliger, H. (2001). Factor graphs sum-product algorithm. IEEE Transactions Information Theory, 47 (2), 498519.
Lauritzen, S. (1996). Graphical models. Oxford University Press, Oxford.
Luenberger, D. (1984). Linear Nonlinear Programming. Addison-Wesley, Reading,
Massachusetts.
McEliece, R., MacKay, D., & Cheng, J. (1998). Turbo decoding instance Pearls
belief propagation algorithm. IEEE Journal Selected Areas Communication,
16 (2), 140152.
McEliece, R., & Yildirim, M. (2003). Belief propagation partially ordered sets.
Gilliam, D., & Rosenthal, J. (Eds.), Mathematical Systems Theory Biology, Communications, Computation, Finance, pp. 275300. Springer, New York.
Murphy, K. (2001). Bayes Net toolbox Matlab. Computing Science Statistics,
33, 331350.
Murphy, K., Weiss, Y., & Jordan, M. (1999). Loopy belief propagation approximate
inference: empirical study. Laskey, K., & Prade, H. (Eds.), Proceedings
Fifteenth Conference Uncertainty Articial Intelligence, pp. 467475, San
Francisco, CA. Morgan Kaufmann Publishers.
Neal, R., & Hinton, G. (1998). view EM algorithm justifies incremental,
sparse, variants. Jordan, M. (Ed.), Learning Graphical Models, pp.
355368. Kluwer Academic Publishers, Dordrecht.
Pakzad, P., & Anantharam, V. (2002). Belief propagation statistical physics. 2002
Conference Information Sciences Systems, Princeton University.
Pakzad, P., & Anantharam, V. (2005). Estimation marginalization using Kikuchi approximation methods. Neural Computation, 17, 18361873.
Pearl, J. (1988). Probabilistic Reasoning Intelligent systems: Networks Plausible Inference. Morgan Kaufmann, San Francisco, CA.
Pelizzola, A. (2005). Cluster variation method statistical physics graphical models.
Journal Physics A, 38, R309R339.
Seung, S., Richardson, T., Lagarias, J., & Hopfield, J. (1998). Minimax Hamiltonian
dynamics excitatory-inhibitory networks. Jordan, M., Kearns, M., & Solla, S.
(Eds.), Advances Neural Information Processing Systems 10, pp. 329335. MIT
Press.
Tatikonda, S., & Jordan, M. (2002). Loopy belief propagation Gibbs measures. Darwiche, A., & Friedman, N. (Eds.), Uncertainty Artificial Intelligence: Proceedings
189

fiHeskes

Eighteenth Conference (UAI-2002), pp. 493500, San Francisco, CA. Morgan
Kaufmann Publishers.
Teh, Y., & Welling, M. (2002). unified propagation scaling algorithm. Dietterich,
T., Becker, S., & Ghahramani, Z. (Eds.), Advances Neural Information Processing
Systems 14, pp. 953960, Cambridge. MIT Press.
Wainwright, M., Jaakkola, T., & Willsky, A. (2002a). new class upper bounds log
partition function. Darwiche, A., & Friedman, N. (Eds.), Uncertainty Artificial
Intelligence: Proceedings Eighteenth Conference (UAI-2002), pp. 536543, San
Francisco, CA. Morgan Kaufmann Publishers.
Wainwright, M., Jaakkola, T., & Willsky, A. (2002b). Tree-based reparameterization
approximate estimation loopy graphs. Dietterich, T., Becker, S., & Ghahramani,
Z. (Eds.), Advances Neural Information Processing Systems 14, pp. 10011008,
Cambridge. MIT Press.
Wainwright, M., Jaakkola, T., & Willsky, A. (2003). Tree-reweighted belief propagation
algorithms approximate ML estimation via pseudo-moment matching. Bishop,
C., & Frey, B. (Eds.), Proceedings Ninth International Workshop Artificial
Intelligence Statistics. Society Artificial Intelligence Statistics.
Yedidia, J., Freeman, W., & Weiss, Y. (2001). Generalized belief propagation. Leen,
T., Dietterich, T., & Tresp, V. (Eds.), Advances Neural Information Processing
Systems 13, pp. 689695, Cambridge. MIT Press.
Yedidia, J., Freeman, W., & Weiss, Y. (2005). Constructing free energy approximations
generalized belief propagation algorithms. IEEE Transactions Information
Theory, 51, 22822312.
Yuille, A. (2002). CCCP algorithms minimize Bethe Kikuchi free energies:
Convergent alternatives belief propagation. Neural Computation, 14, 16911722.

190


