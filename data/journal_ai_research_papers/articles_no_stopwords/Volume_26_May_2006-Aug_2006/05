journal artificial intelligence

submitted published

fast downward system
malte helmert

helmert informatik uni freiburg de

institut fur informatik
albert ludwigs universitat freiburg
georges kohler allee gebaude
freiburg germany

abstract
fast downward classical system heuristic search deal general deterministic encoded propositional fragment pddl including
advanced features adl conditions effects derived predicates axioms
well known planners hsp fast downward progression planner searching
space world states task forward direction however unlike pddl systems fast downward use propositional pddl representation
task directly instead input first translated alternative representation called multivalued tasks makes many implicit constraints propositional
task explicit exploiting alternative representation fast downward uses hierarchical decompositions tasks computing heuristic function called causal graph heuristic
different traditional hsp heuristics ignoring negative interactions
operators
article give full account fast downwards solving multi valued
tasks extend earlier discussion causal graph heuristic tasks involving
axioms conditional effects present novel techniques search control used
within fast downwards best first search preferred operators transfer idea helpful actions local search global best first search deferred evaluation heuristic functions
mitigates negative effect large branching factors search performance multi heuristic
best first search combines several heuristic evaluation functions within single search
orthogonal way describe efficient data structures fast state expansion successor
generators axiom evaluators present non heuristic search called focused
iterative broadening search utilizes information encoded causal graphs novel
way
fast downward proven remarkably successful classical e propositional
non optimising track th international competition icaps following
footsteps planners lpg experiments performs
well benchmarks earlier competitions provide insights
usefulness search enhancements

introduction
consider typical transportation task postal service must deliver number parcels
respective destinations vehicle fleet cars trucks let us assume car
serves locations one city different cities connected via highways
served trucks sake simplicity let us assume travelling segment
road highway incurs cost highly realistic assumption purposes
exposition number parcels posted arbitrary locations
c

ai access foundation rights reserved

fih elmert

p

b

f

c





e

c

g

c

c

p

figure transportation task deliver parcel p c g parcel p f e
cars c c c truck cars may use inner city roads thin edges
truck may use highway thick edge

arbitrary destinations moreover cities varying size one several cars
within city one several trucks connecting cities cars never leave
city fig shows example task kind two cities three cars single truck
two parcels delivered one p must moved two cities
p stay within initial city
astute reader familiar literature noticed
essentially describing l ogistics domain standard benchmark classical systems
extended roadmaps complete graphs part propositional strips encoding
task shown fig
would human planners go solving tasks kind likely would use
hierarchical p clear parcel needs moved cities
possible truck since example city access highway one
location see must first load parcel car initial location drop
first citys highway access location load truck drop citys highway
access location load car city finally drop destination
commit high level plan delivering p without worrying lower level aspects
path cars obvious us good solution structure
since parcel change location clearly defined ways fig figure
shows reasonable plans getting p destination require loading car
initial city dropping target location point ever loading
truck cars left city
say committed partially ordered movements two parcels
interleaved high level plan shown fig need complete plan choose
linearization high level steps fill movements vehicle fleet
thus decomposed task number subproblems parcel scheduling
vehicles parcel loaded unloaded separated
path vehicle fleet move point x


fit fast ownward p lanning ystem

variables
p p b p c p p e
p p b p c p p e
c c b c c c
c c b c c c
c e c f c g
e
p c p c p c p
p c p c p c p
init
p c p f c c b c g
goal
p g p e
operator drive c
pre c add c del c
operator drive c b
pre c b add c del c b
operator drive c c
pre c c add c del c c

operator load c p
pre c p add p c del
operator load c p b
pre c b p b add p c del
operator load c p c
pre c c p c add p c del

operator unload c p
pre c p c add p del
operator unload c p b
pre c b p c add p b del
operator unload c p c
pre c c p c add p c del


p f p g
p f p g

e

p
p b
p c

p c
p c
p c

figure part typical propositional encoding transportation task actual
pddl syntax



fih elmert

c




b

c



e

f

c

g

c

figure domain transition graph parcels p p indicates parcel change
state example arcs correspond actions
loading unloading parcel location truck

b
f







e

e

g
c

figure domain transition graphs cars c c left truck centre car c right
note graph corresponds part roadmap traversed
respective vehicle

load
c p c

unload
c p

load
p

unload
p e

load
c p f

unload
c p e

load
c p e

figure high level plan transportation task


unload
c p g

fit fast ownward p lanning ystem

c

c

c

p

p



figure causal dependencies transportation task
graph search corresponding graphs shown fig fig
graphs kind formally introduced domain transition graphs section
course graph search interact limited ways state
transitions parcels associated conditions regarding vehicle fleet need
considered addition actual path fig example parcel change
state location inside car c car c location however state transitions
vehicles associated conditions parts task hence
moving vehicle one location another indeed easy finding path associated
domain transition graph say parcels causal dependencies vehicles
operators change state parcels preconditions state
vehicles indeed causal dependencies task since parcels depend
parcels vehicles depend anything except fig set causal
dependencies task visualized causal graph
argue humans often solve tasks hierarchical fashion outlined preceding paragraphs algorithmic approaches action usefully apply similar
ideas indeed following section first introduce domain transition graphs causal graphs however earlier work almost exclusively focused acyclic
causal graphs good reason causal graph task exhibits cycle hierarchical decomposition possible subproblems must solved achieve
operator precondition necessarily smaller original task far aware
first helmert present general focuses exploiting hierarchical information causal graphs however causal graph heuristic requires
acyclicity general case considers relaxed operator
preconditions ignored break causal cycles
knowing cycles causal graphs undesirable take closer look transportation
task let us recall informal definition causal graphs causal graph
task contains vertex state variable arcs variables occur preconditions
variables occur effects operator far may given impression
causal graph example task well behaved shape shown fig unfortunately
closer look strips encoding fig see case correct
causal graph shown fig looks messy discrepancy intuitive actual
graph due fact informal account human style solving made
use non binary state variables location car c state parcel p
strips level state variables correspond binary object location propositions parcel p


fih elmert

figure causal graph strips encoding transportation task
location would much nicer given multi valued encoding
task explicitly contains variable location car c similar properties indeed
nice looking acyclic graph fig causal graph multi valued encoding shown
fig
provided intuition underlying concepts let us state design goal
fast downward system develop efficiently solves general
propositional tasks exploiting hierarchical structure inherent causal graphs
need overcome three major obstacles undertaking
first propositionally encoded tasks usually unstructured causal graphs
however intuitive dependencies often become visible encodings multi valued
state variables exploit fact automated pddl system devised
automatic translating reformulating propositional tasks multi valued
ones translation considered independently rest planner fact used part systems van den briel vossen
kambhampati keep article focused discuss translation
referring earlier work central ideas edelkamp helmert
instead consider output multi valued task base formalism
second matter clever encoding tasks completely hierarchical nature deal causal cycles consider relaxations causal
dependencies ignored use solutions relaxed within heuristic search

third even tasks solved hierarchically finding solution difficult indeed still pspace complete reason heuristic function considers
fragment task time namely subproblems induced single state variable
predecessors causal graph even still np complete


fit fast ownward p lanning ystem

variables
p p b c e f g
c c c
c c b c
c
e f g

e
init
p c p f
c c b c g e
goal
p g p e
operator drive c
pre c eff c
operator drive c b
pre c b eff c
operator drive c c
pre c c eff c

operator load c p
pre c p eff p c
operator load c p b
pre c b p b eff p c
operator load c p c
pre c c p c eff p c

operator unload c p
pre c p c eff p
operator unload c p b
pre c b p c eff p b
operator unload c p c
pre c c p c eff p c

figure part encoding transportation task multi valued state variables



fih elmert

content incomplete solution within heuristic solver solution
theoretical shortcomings never failed us practice
introduced rationale discuss related work next section
followed overview general architecture fast downward system
section system consists three components translation knowledge compilation
search translation component converts pddl tasks multi valued tasks
formally introduce section knowledge compilation component discussed
section search component section conclude presentation experimental
section discussion section

related work
system heuristic forward search fast downward clearly related
heuristic planners hsp bonet geffner hoffmann nebel
architectural level however section focus work related conceptual level
e work uses similar forms hierarchical decomposition causal graphs work uses
similar forms search domain transition graphs
causal graphs abstraction
term causal graph first appears literature work williams nayak
general idea considerably older hierarchically decomposing tasks
arguably old field ai first surfaced newell simons
work general solver
still took long time notions evolve modern form sacerdotis
abstrips introduced concept abstraction spaces strips tasks
abstraction space strips task state space abstracted task obtained
removing preconditions operators original task belong given set
propositions abstracted away solve task abstrips first generates
plan abstracted task refines plan inserting concrete plans abstract
plan steps bridge gap abstract states satisfying operator preconditions
ignored abstract level idea easily generalized several levels abstraction forming abstraction hierarchy abstract level top almost
preconditions ignored successively introducing preconditions every layer final
layer hierarchy equals original task
one general guarantee
abstract plans bear resemblance reasonable concrete plans example abstraction spaces
chosen badly quite possible finding concrete plan satisfies precondition
first operator abstract plan difficult solving original goal concrete level
shortcomings spawned large amount properties abstraction hierarchies
generated automatically
later work authors propositions abstracted away removed operator effects
makes difference subtle cases require presence axioms distinguish
two kinds abstraction



fit fast ownward p lanning ystem

tenenberg gives one first formal accounts properties different kinds
abstraction among contributions defines called upward solution property
informally stated exists concrete solution exists abstract
solution rather surprisingly abstractions considered time satisfied basic
property without one would loathe call given state space abstraction another
state space
limitation upward solution property states relationship concrete
abstract plan abstrips style hierarchical successful abstract
plan must bear resemblance concrete one otherwise little point trying
refine indeed tenenberg introduces stronger versions upward solution property
relevant fast downward knoblocks work ordered monotonicity property
abstraction space satisfies ordered monotonicity property roughly speaking concrete
solution derived abstract solution leaving actions abstract plan
intact relevant concrete plan clearly important property abstripslike hierarchical
knoblocks article causal graphs first surface although introduce name
translated terminology knoblock proves following relationship
useful abstractions causal graphs causal graph contains path variable
abstracted away variable abstracted away abstraction ordered
monotonicity property particular means acyclic causal graphs possible devise
abstraction hierarchy one variable introduced level
besides theoretical contributions knoblock presents system called alpine
computes abstraction hierarchy task causal graph exploits
within hierarchical refinement planner although method different
derivation abstraction hierarchy similar fast downwards method generating
hierarchical decompositions tasks section
ordered monotonicity property sufficient guarantee good performance
hierarchical guarantees every concrete solution obtained
natural way abstract solution guarantee abstract solutions
refined concrete ones guarantee provided downward refinement property
introduced bacchus yang
downward refinement property rarely guaranteed actual domains
bacchus yang develop analytical model performance hierarchical situations given abstract plan refined certain probability p
analysis present extension alpine called highpoint selects abstraction hierarchy high refinement probability among satisfy ordered monotonicity
property practice feasible compute refinement probability highpoint approximates value notion k ary necessary connectivity
causal graphs unary strips operators
causal graphs first given name jonsson backstrom b call
dependency graphs study fragment propositional strips negative conditions
interesting property plan existence decided polynomial time minimal
solutions task exponentially long polynomial exists


fih elmert

present incremental polynomial delay e
decides within polynomial time whether given task solution generates
solution step step requiring polynomial time two subsequent steps
fragment strips covered jonsson backstroms called
defined requirement causal graph task acyclic state variables
static symmetrically reversible splitting static variables easy
guarantee never change value solution plan variables detected
compiled away easily symmetrically reversible variables operator
makes true corresponding operator identical preconditions makes
false vice versa words variable symmetrically reversible iff domain
transition graph undirected finally variable v splitting iff removal causal graph
weakly disconnects positive successors variables appear effects operators
v precondition negative successors variables appear effects
operators v precondition
williams nayak independently prove incremental setting reactive
polynomial strips setting causal graphs acyclic
operators reversible operators reversible according definition williams
nayak variables symmetrically reversible according definition jonsson
backstrom actually special case previous however williams nayaks
work applies general formalism propositional strips approaches
directly comparable
recently domshlak brafman provide detailed account complexity finding plans propositional strips negation formalism unary operators acyclic
graphs domshlak brafman brafman domshlak among
prove restriction unary operators acyclic graphs reduce complexity
plan existence pspace complete unrestricted propositional strips
bylander singly connected causal graphs shortest plans
cannot exponentially long still np complete even restricted class
causal graphs namely polytrees bounded indegree present polynomial generally analysis relates complexity strips unary domains
number paths causal graph
multi valued tasks
exception williams nayaks work discussed far exclusively deals
propositional state variables assume values binary domain observed introduction question propositional vs multi valued encodings
usually strong impact connectivity causal graph task fact apart
trivial ovie domain none common benchmarks exhibits acyclic causal graph
however guarantee length generated solution polynomially related length
optimal solution might exponentially longer therefore might spend exponential time tasks
solved polynomial time
according formal definition causal graphs section operators several effects induce
cycles causal graph acyclic causal graph implies unary operators researchers define causal graphs
differently name properties explicitly



fit fast ownward p lanning ystem

considering propositional representation contrast multi valued encoding
introductory example acyclic causal graph
due dominance pddl previously strips formalism non binary state variables studied often classical literature one important exceptions rule work sas formalism papers backstrom
nebel jonsson backstrom relevant fast downward
sas formalism basically equivalent multi valued tasks introduce
section apart fact include derived variables axioms conditional
effects backstrom nebel analyse complexity subclasses sas formalism discover three properties unariness post uniqueness single valuedness together
allow optimal polynomial time one three properties unariness related
acyclicity causal graphs one post uniqueness implies particularly simple shape domain
transition graphs namely post unique tasks domain transition graphs must simple cycles
trees
backstrom nebel analyse domain transition graphs formally indeed term
introduced later article jonsson backstrom refines earlier
introducing five additional restrictions sas tasks related properties
domain transition graphs
neither two articles discusses notion causal graphs indeed earlier work
aware includes causal graphs domain transition graphs central concepts
article domshlak dinitz state transition support sts
essentially equivalent sas unary operators context sts domain
transition graphs called strategy graphs causal graphs called dependence graphs
apart minor details semantics two formalisms identical domshlak dinitz
provide map complexity sts terms shape causal graph
showing np complete worse almost non trivial cases one interesting
causal graph simple chain n nodes variables three valued
length minimal plans already grow n contrast propositional tasks
causal graph shape admit polynomial according brafman
domshlak causal graphs polytrees constant indegree bound
namely bound
summarize conclude discussion related work observe central concepts fast downward causal graph heuristic causal graphs domain transition
graphs firmly rooted previous work however fast downward first attempt marry
hierarchical decomposition use multi valued state variables within general framework first attempt apply techniques similar knoblock
bacchus yang within heuristic search planner
significance latter point underestimated classical approaches
hierarchical decomposition imperative abstraction satisfies ordered monotonicity property important probability able refine abstract plan
concrete plan high analysis bacchus yang shows unfortunately non trivial
abstraction hierarchies rarely ordered monotonic even rarely guarantee high refinement probabilities within heuristic must haves turn nice haves
abstraction hierarchy ordered monotonic abstract plan considered heuristic
evaluator refinable merely reduces quality heuristic estimate rather caus

fih elmert

translation





normalization
invariant synthesis
grounding
translation mpt

knowledge
compilation
domain transition
graphs
causal graph
successor generator
axiom evaluator

search






causal graph heuristic
heuristic
greedy best first search
multi heuristic best first search
focused iterative broadening search

figure three phases fast downwards execution
ing search fail worst case spend long time trying salvage non refinable abstract
plans much better case

fast downward
describe overall architecture planner fast downward classical
system ideas heuristic forward search hierarchical decomposition
deal full range propositional pddl fox long edelkamp hoffmann
e addition strips supports arbitrary formulae operator preconditions
goal conditions deal conditional universally quantified effects derived
predicates axioms
name planner derives two sources course one sources hoffmanns successful fast forward planner hoffmann nebel fast
downward heuristic progression planner e computes plans heuristic search space
world states reachable initial situation however compared fast downward uses
different heuristic evaluation function called causal graph heuristic heuristic evaluator proceeds downward far tries solve tasks hierarchical fashion
outlined introduction starting top level goals recurses
causal graph remaining subproblems basic graph search tasks
similar planner shown excellent performance original implementation
causal graph heuristic plugged standard best first search outperformed previous champions area lpg gerevini saetti serina set strips
benchmarks first three international competitions helmert fast downward followed footsteps lpg winning propositional non optimizing
track th international competition icaps referred ipc

mentioned introduction fast downward solves task three phases fig
translation component responsible transforming pddl input nonbinary form amenable hierarchical approaches applies number normalizations compile away syntactic constructs disjunctions
directly supported causal graph heuristic performs grounding axioms operators importantly uses invariant synthesis methods groups related propo

fit fast ownward p lanning ystem

sitions encoded single multi valued variable output translation
component multi valued task defined following section
knowledge compilation component generates four kinds data structures play
central role search domain transition graphs encode conditions
state variables change values causal graph represents hierarchical dependencies different state variables successor generator efficient data
structure determining set applicable operators given state finally axiom
evaluator efficient data structure computing values derived variables
knowledge compilation component described section
search component implements three different search actual
two make use heuristic evaluation functions one well known
greedy best first search causal graph heuristic called multiheuristic best first search variant greedy best first search tries combine several
heuristic evaluators orthogonal way case fast downward uses causal
graph heuristics third search called focused iterative broadening
search closely related ginsberg harveys iterative broadening
heuristic search sense use explicit heuristic evaluation
function instead uses information encoded causal graph estimate usefulness operators towards satisfying goals task search component described
section

multi valued tasks
let us formally introduce multi valued state variables
formalism sas model backstrom nebel jonsson backstrom
extends axioms conditional effects
definition multi valued tasks mpts
multi valued task mpt given tuple hv oi following
components
v finite set state variables associated finite domain v state variables partitioned fluents affected operators derived variables computed
evaluating axioms domains derived variables must contain undefined value
partial variable assignment partial state v function subset v
v dv wherever v defined partial state called extended state
defined variables v reduced state state defined fluents v
context partial variable assignments write v variable value pairing
v v
state v called initial state
partial variable assignment v called goal
finite set mpt axioms v axioms triples form hcond v di
cond partial variable assignment called condition body axiom v derived


fih elmert

variable called affected variable v called derived value v pair
v called head axiom written v
axiom set partitioned totally ordered set axiom layers ak
within layer affected variable may associated single
value axiom heads bodies words within layer axioms
affected variable different derived values forbidden variable appears
axiom head may appear different value body called
layering property
finite set mpt operators v operator hpre effi consists partial
variable assignment pre v called precondition finite set effects eff effects
triples hcond v di cond possibly empty partial variable assignment called
effect condition v fluent called affected variable v called
value v
axioms effects use notation cond v place hcond v di
provide formal semantics mpt first need formalize axioms
definition extended states defined state
let state mpt axioms layered ak extended state defined
written following
evaluate axioms ak
variable
v
v v fluent variable
v

v derived variable
k
exists axiom cond v cond v
choose axiom cond v
v
words axioms evaluated layer layer fashion fixed point computations
similar semantics stratified logic programs easy see layering
property definition guarantees terminates produces deterministic
defined semantics axioms define state space mpt
definition mpt state spaces
state space mpt hv oi denoted directed graph vertex
set set states v contains arc iff exists operator hpre effi

pre
v effects cond v eff cond
v v fluents


fit fast ownward p lanning ystem

finally define mpt
definition mpt
mpt p lan e x following decision given mpt initial state goal
contain path state
mpt p lanning following search given mpt initial state goal
compute path state prove none exists
mpt p lan e x easily shown pspace hard generalizes plan
existence propositional strips known pspace complete bylander
easy see addition multi valued domains axioms conditional effects
increase theoretical complexity mpt beyond propositional strips thus
conclude formal introduction mpt stating mpt p lan e x pspacecomplete turn practical side things following section

knowledge compilation
purpose knowledge compilation component set stage search
compiling critical information task number data structures efficient access contexts computations kind often called preprocessing however
preprocessing nondescript word mean basically anything reason
prefer term puts stronger emphasis role module rephrase critical information task way directly useful search
three building blocks fast downward translation knowledge compilation search
least time critical part requiring less time translation dominated search
trivial tasks
knowledge compilation comprises three items first foremost compute domain
transition graph state variable domain transition graph state variable encodes
circumstances variable change value e values domain
transitions values operators axioms responsible transition conditions state variables associated transition domain
transition graphs described section central concept computation
causal graph heuristic described section
second compute causal graph task domain transition graphs encode dependencies values given state variable causal graph encodes dependencies
different state variables example given location task unlocked
means key carried agent variable representing lock state
location dependent variable represents whether key carried
dependency encoded arc causal graph domain transition graphs causal
graphs central concept computation causal graph heuristic giving name
causal graph heuristic requires causal graphs acyclic reason knowledge compilation component generates acyclic subgraph real causal graph cycles occur
amounts relaxation task operator preconditions ignored
addition usefulness causal graph heuristic causal graphs key concept
focused iterative broadening search introduced section discuss causal
graphs section


fih elmert

third compute two data structures useful forward searching
mpts called successor generators axiom evaluators successor generators compute set
applicable operators given world state axiom evaluators compute values derived
variables given reduced state designed job quickly possible
especially important focused iterative broadening search compute heuristic estimates thus requires basic operations expanding search node
implemented efficiently data structures discussed section
domain transition graphs
domain transition graph state variable representation ways variable
change value conditions must satisfied value changes allowed domain transition graphs introduced jonsson backstrom context
sas formalization domain transition graphs generalizes original definition
tasks involving axioms conditional effects
definition domain transition graphs
let hv oi multi valued task let v v state variable
domain transition graph v symbols dtg v labelled directed graph vertex
set dv v fluent dtg v contains following arcs
effect cond v operator precondition pre pre cond
contains condition v arc labelled pre cond v
effect cond v operator precondition pre pre cond
contain condition v v arc dv
labelled pre cond
v derived variable dtg v contains following arcs
axiom cond v cond contains condition v arc
labelled cond v
axiom cond v cond contain condition v
dv arc dv labelled cond
arcs domain transition graphs called transitions labels referred
conditions transition
domain transition graphs weighted case transition associated
non negative integer weight unless stated otherwise assume transitions derived
operators weight transitions derived axioms weight
definition somewhat lengthy informal content easy grasp domain transition graph v contains transition exists operator axiom
change value v transition labelled conditions state
variables must true transition shall applied multiple transitions
values different conditions allowed occur frequently
already seen domain transition graphs introductory section figs although introduced informally arc labels usually associated


fit fast ownward p lanning ystem

open












r

r k carried

closed

r k carried

r

open











r




r



r

r

r

r






r
r

carried

r





r

open

open














r k carried


figure domain transition graphs g rid task top left dtg r robot right dtg k
key bottom left dtg door

transitions fig shows examples simple task g rid domain featuring grid single initially locked location centre upper row unlockable
single key mpt encoding task three state variables variable r
dr x x encodes location robot variable k
dk dr carried encodes state key variable closed open
encodes state initially locked grid location
operators mpt unary e single effect leave aside axioms
moment strong correspondence state space mpt
domain transition graphs since vertices domain transition graphs correspond values state
variables given state represented selecting one vertex domain transition graph called
active vertex state variable applying operator means changing active vertex
state variable performing transition corresponding domain transition graph
whether transition allowed depends condition checked
active vertices domain transition graphs
let us use g rid example illustrate correspondence consider initial state
robot location key location door locked represent
placing pebbles appropriate vertices three domain transition graphs want
move pebble domain transition graph key location done
moving robot pebble vertex moving key pebble vertex
carried moving robot pebble back vertex moving door pebble open moving
robot pebble vertex finally moving key pebble vertex


fih elmert

open r
open r

open r

closed






r



r

open r

r
r

figure domain transition graphs freezing variable g rid task normal left
extended right note extended graph shows change state
freezing freezing

example shows plan execution viewed simultaneous traversal domain
transition graphs cf domshlak dinitz important notion fast downward
causal graph heuristic computes heuristic estimates solving subproblems
task looking paths domain transition graphs basically way described
mentioned view mpt completely accurate unary tasks
without axioms domain transition graphs indeed complete representation
state space non unary operators would need link certain transitions different domain
transition graphs belong operator could executed together
axioms would need mark certain transitions mandatory requiring taken
whenever possible intended rough analogy leaves details layered
axioms
previous work helmert successfully applied view
strips tasks extending notion plans conditional effects provides challenges domain transition graphs consider operators one effect time
case effect condition simply seen part operator precondition however axioms
provide challenge easily overlooked want change value fluent
domain transition graph contains important information path
try associated conditions achieved consider
derived state variable let us assume unlocking location g rid example leads
drought causing robot freeze enters horizontally adjacent location could encode
derived variable f freezing domain f defined axioms
open r f open r f domain transition graph
dtg f depicted fig left
domain transition graph tell us change
state variable f general mpts derived strips tasks derived
predicates occur negatively condition domain transition graph contain sufficient
information changing value derived variable true false derived variables


fit fast ownward p lanning ystem

never assume value due derivation value negation failure semantics
assume value default value derived want reason
ways setting value derived variable need make information explicit
logical notation whether derived variable assumes given value triggering
axiom given layer determined formula disjunctive normal form one disjunct
axiom setting value example axioms open r f
open r f correspond dnf formula open r
open r want know rules trigger must negate formula
leading cnf formula open r open r able encode
information domain transition graph need replace inequalities equalities
translate formula back dnf since transformations increase formula size
dramatically apply simplifications along way removing duplicated dominated disjuncts
case dnf formula closed r r r r

domain transition graph derived variable enriched contain possible
ways causing variable assume value called extended domain transition graph
shown g rid example fig right since computing extended domain transition
graph costly necessary knowledge compilation component scans
conditions task axioms operator preconditions effect conditions goal
occurrences pairings type v derived variables v extended domain transition
graphs computed derived variables required
note negative occurrences derived variables cascade u v w derived
variables domain condition v present operator precondition
moreover v defined axiom u w v v assumes value
whenever u w would require extended domain transition graphs u w well
hand multiple layers negation failure cancel derived
variable v occurs conditions form v never positive form defined
axiom u w v necessarily require extended domain transition
graphs u w
general whether need extended domain transition graphs derived variable
determined following rules
v derived variable condition v appears operator
precondition effect condition goal v used positively
v derived variable condition v appears operator precondition
effect condition goal v used negatively
v derived variable condition v appears body
axiom whose head used positively negatively v used positively negatively
v derived variable condition v appears body axiom
whose head used positively negatively v used negatively positively
knowledge compilation component computes extended domain transition graphs derived variables used negatively standard domain transition graphs state
variables normal domain transition graphs computed going set axioms


fih elmert

set operator effects following definition reasonably straight forward computation extended domain transition graphs outlined therefore algorithmic
aspects topic require discussion
causal graphs
causal graphs introduced informally introduction formal definition
definition causal graphs
let multi valued task variable set v causal graph symbols
cg directed graph vertex set v containing arc v v iff v v one
following conditions true
domain transition graph v transition condition v
set affected variables effect list operator includes v v
first case say arc induced transition condition second case say
induced co occurring effects
course arcs induced transition conditions arcs induced co occurring effects
mutually exclusive causal graph arc generated reasons
informally causal graph contains arc source variable target variable changes
value target variable depend value source variable arcs
included dependency form effect source variable agrees
definition dependency graphs jonsson backstrom b although authors
distinguish two different ways arc graph introduced
labelled arcs
whether co occurring effects induce arcs causal graph depends intended semantics arcs included set causal graph ancestors anc v variable
v precisely variables relevant goal change value v plans
goal computed without considering variables outside anc v eliminating variables outside anc v task simplifying axioms operators accordingly
call achievability definition causal graphs causal graphs encode variables
important achieving given assignment state variable
however achievability definition planner considers anc v generating
action sequence achieves given valuation v may modify variables outside anc v e
generated plans side effects could destroy previously achieved goals otherwise
negative impact overall therefore prefer definition call
separability definition causal graphs
acyclic c ausal g raphs
following separability definition causal graphs solving subproblem variables anc v
possible without changing values outside anc v leads us following
observation


fit fast ownward p lanning ystem

observation acyclic causal graphs strongly connected domain transition graphs
let mpt cg acyclic domain transition graphs strongly connected
derived variables trivially false conditions occur operators goals
solution
trivially false conditions mean conditions kind v v
note similarity observation williams nayak domains unary operators acyclic causal graphs reversible transitions separability
definition causal graphs acyclic causal graphs imply unariness operators operators
several effects introduce causal cycles moreover strong connectedness domain transition
graphs closely related williams nayaks reversibility property although weaker
requirement
truth observation easily seen inductively task one state
variable domain transition graph strongly connected state one variable
transformed state applying graph search techniques task
several state variables causal graph acyclic pick sink causal graph e
variable v without outgoing arcs check goal defined variable
remove variable task thus reducing one fewer state variables
solved recursively yes search path v v domain transition graph
v guaranteed exist graph strongly connected yields high level
plan setting v v fleshed recursively inserting plans setting
variables predecessors v causal graph values required transitions
form high level plan desired value v set v eliminated
task remaining solved recursively
shown fig although backtrack free require exponential
time execute generated plans exponentially long unavoidable even
mpts satisfy conditions observation shortest plans exponentially long
family tasks property given proof theorem article
backstrom nebel
method solving multi valued tasks essentially refinement
begin constructing abstract skeleton plan merely path domain transition
graph lower level abstraction adding operators satisfy preconditions required
transitions taken path strong connectedness domain transition graphs guarantees
every abstract plan actually refined concrete plan precisely bacchus
yangs downward refinement property cf section
g enerating



p runing c ausal g raphs

usefulness causal graphs refinement limited acyclic case consider subset v task variables contains causal graph descendants general
restrict task v removing occurrences variables initial state goal
operators axioms obtain abstraction original satisfies knoblocks
ordered monotonicity property section
unfortunately one major requirement include causal
graph descendants quite limiting uncommon causal graph task
strongly connected case technique allow us abstract away variables


fih elmert

solve easy mpt v

goal empty empty plan solution
return hi
else
let v v variable occurring preconditions effect conditions
variable exists causal graph task acyclic
v v v
affect v
plan hi
v defined
let tk path transitions dtg v v v
tk high level plan reaches goal v
ignores preconditions variables
tk
recursively plan achieves conditions
let cond condition operator associated
let state reached executing plan restricted v
extend plan solve easy mpt v cond
extend plan
dealing v recursively plan goals remaining variables
let state reached executing plan restricted v
restricted v
extend plan solve easy mpt v
return plan
figure mpts acyclic causal graph strongly connected domain
transition graphs



fit fast ownward p lanning ystem

however heuristic free simplify task particular
ignoring operator preconditions purposes heuristic evaluation make
arbitrary causal graph acyclic clearly aspects real task ignore worse
expect heuristic approximate actual goal distance considering aim ignore
little information possible explain done
knowledge compilation component begins causal graph processing generating
full causal graph definition one consequence separability definition causal graphs
state variables ancestors variables mentioned goal completely
irrelevant therefore computed graph compute causal graph ancestors
variables goal state variables found goal ancestors eliminated task causal graph associated operators axioms removed
afterwards compute pruned causal graph acyclic subgraph causal graph
vertex set try fashion important causal dependencies retained
whenever possible specifically apply following
first compute strongly connected components causal graph cycles occur
within strongly connected components component dealt separately second
connected component compute total order vertices retaining
arcs v v v v v v say v higher level v total order
computed following way
assign weight arc causal graph weight arc n induced
n axioms operators lower cumulated weight incoming arcs vertex
fewer conditions ignored assigning low level vertex
pick vertex v minimal cumulated weight incoming arcs select
lowest level e set v v vertices v strongly connected component
since v dealt remove vertex incident arcs consideration
rest ordering
remaining solved iteratively applying technique order
vertices single vertex remains
reader notice pruning choices within strongly connected component
performed greedy could try sets arcs minimal total weight
eliminating arcs acyclic graph however np equivalent
even case unweighted graphs garey johnson gt
generating pruned causal graph prune domain transition graphs removing transition labels dtg v conditions variables v v v
conditions ignored heuristic computation finally simplify domain transition
graphs removing dominated transitions transitions two values
variable condition proper subset condition transition
easier apply remove similarly several transitions identical
conditions keep one
simplification closely related knoblocks criterion specific ordered monotonicity property
knoblock



fih elmert







p

p



figure causal graph l ogistics task state variables ai encode locations
trucks airplanes state variables p locations packages

f

p

f

f

f

f

f

l

l

l

l

c

c

c

c

p

p

p

figure causal graph ystery task left relaxed version task right state
variables encode fuel location state variables l ci encode locations
remaining capacities trucks state variables p encode locations packages

c ausal g raph e xamples
give impression types causal graphs typically found standard benchmarks
effects pruning examples increasing graph complexity
first simplest example fig shows causal graph task l ogistics
domain featuring two trucks two airplanes two packages seen graph acyclic
requires pruning causal graph heuristic since l ogistics tasks feature strongly
connected domain transition graphs even solved polynomial solve easy mpt

slightly complicated example next figure fig shows task ys tery domain three locations two trucks two packages causal graph contains
number cycles mostly local pruning arcs vertices l fj ignore


fit fast ownward p lanning ystem

r

r



l



k

k

l

k

k

figure causal graph g rid task left relaxed version task right state
variable r encodes location robot encodes status robot arm empty
carrying key l encodes status locked location locked open k
k encode locations two keys

fact must move trucks certain locations want use fuel location
fuel useful thing big loss information pruning arcs
vertices pi cj ignore fact vehicles increase decrease current
capacity unloading loading packages compared heuristics ignoring delete effects great loss information since ignoring delete effects ystery domain
almost amounts ignoring capacity fuel constraints altogether pruning arcs
eliminate cycles causal graph ystery domain considered fairly
well behaved
worse case shown fig shows example g rid domain
arbitrary number locations single one locked two keys one
unlock locked location eliminating cycles requires minor relaxations regarding
status robot arm empty non empty one major simplification namely
elimination arc l r representing fact robot enter locked
location unlocked
nearly worst case example consider task b locksworld domain figure
typical mpt encoding uses one state variable h encoding whether hand empty
two state variables per block task th block encodes whether block
lying table bi encodes block lying top clear held
arm causal graph task variable h ingoing arcs outgoing arcs
state variables state variables b connected directions
state variables ti slightly simpler connection structure connected h
bi value relaxation eliminates cycles causal
graph loses large amount information surprising epot domain
includes b locksworld subproblem one precursor fast downward fared
worst helmert still pointed planners ignore delete effects
similar b locksworld domains comparison causal
graph heuristics article shows


fih elmert

successor generators axiom evaluators
addition good heuristic guidance forward searching system needs efficient methods
generating successor states applied benchmark suite international
competitions domains causal graph heuristic popular methods
heuristic provide excellent goal estimates yet still time consuming
long plans vast branching factors
variant best first search implemented fast downward compute heuristic
estimate state generated essentially heuristic evaluations computed
closed nodes computation deferred nodes search frontier domains
strong heuristic guidance large branching factors number nodes frontier
far dominate number nodes closed set case point consider instance
atellite solving task default configuration fast downward computes
heuristic estimates world states adding states frontier clearly
determining set applicable operators quickly critical importance scenario
atellite tasks almost ground operators try
avoid individually checking operator applicability similarly biggest psr tasks
axioms must evaluated state compute values derived
variables computation must made efficient purposes fast downward uses two
data structures called successor generators axiom evaluators
uccessor g enerators
successor generators recursive data structures similar decision trees internal nodes
associated conditions likened decisions decision tree leaves
associated operator lists likened set classified samples decision tree
leaf formally defined follows
definition successor generators
successor generator mpt hv oi tree consisting selector nodes
generator nodes
selector node internal node tree associated variable v v called
selection variable moreover v children accessed via labelled edges one edge labelled
v value dv one edge labelled latter edge called dont care
edge selector
generator node leaf node tree associated set operators called
set generated operators
operator must occur exactly one generator node set edge labels
leading root node excluding dont care edges must equal precondition
given successor generator mpt state compute set
applicable operators traversing successor generator follows starting root
selector node selection variable v follow edge v v dont care edge
generator node report generated operators applicable


fit fast ownward p lanning ystem

evaluate axiom layer
axiom ai
counter cond
variable v
axiom ai condition v v body
counter counter
exists axiom ai counter yet considered
let hv di head axiom
v
v
axiom ai condition v body
counter counter
figure computing values derived variables given state
build successor generator apply top considers task
variables arbitrary order v v vn root node choose v selection variable classify set operators according preconditions respect v operators
precondition v represented child root accessed edge
corresponding label operators without preconditions v represented child
root accessed dont care edge children root choose v selection
variable grandchildren v
one exception rule avoid creating unnecessary selection nodes operator
certain branch tree condition v vi considered selection variable
branch construction branch ends variables considered
stage generator node created operators associated branch
xiom e valuators
axiom evaluators simple data structure used efficiently implementing well known
marking propositional horn logic dowling gallier extended modified
layered logic programs correspond axioms mpt consist two parts
firstly indexing data structure maps given variable value pairing given axiom layer
set axioms given layer whose body pairing appears secondly set counters
one axiom counts number conditions axiom yet derived
within fast downward axioms evaluated two steps first derived variables set
default value second evaluate axiom layer fig executed axiom
layer sequence determine final values derived variables
assume reader familiar enough marking require much
explanation point test whether axiom ready trigger implemented means queue axioms put soon counter reaches actual
implementation evaluate axiom layer within fast downward initializes axiom counters slightly
efficiently indicated pseudo code however minor technical detail
turn remaining piece fast downwards architecture search component


fih elmert

search
unlike translation knowledge compilation components single
mode execution search component fast downward perform work alternative ways three basic search choose
greedy best first search standard textbook russell norvig
modified technique called deferred heuristic evaluation mitigate negative influence wide branching extended deal preferred operators similar ffs helpful actions hoffmann nebel discuss greedy best first
search section fast downward uses together causal graph
heuristic discussed section
multi heuristic best first search variation greedy best first search evaluates
search states multiple heuristic estimators maintaining separate open lists
variant greedy best first search supports use preferred operators multiheuristic best first search discussed section fast downward uses
together causal graph heuristics discussed sections
focused iterative broadening search simple search use
heuristic estimators instead reduces vast set search possibilities focusing
limited operator set derived causal graph experimental
future hope develop basic idea robust method
focused iterative broadening search discussed section
two heuristic search second choice must made regarding use
preferred operators five options supported planner
use preferred operators
use helpful transitions causal graph heuristic preferred operators
use helpful actions heuristic preferred operators
use helpful transitions preferred operators falling back helpful actions
helpful transitions current search state
use helpful transitions helpful actions preferred operators
five options combined two heuristic search
total eleven possible settings search component ten one
heuristic one focused iterative broadening search
addition basic settings search component configured execute several
alternative configurations parallel making use internal scheduler configurations
fast downward participated ipc made use feature running one configuration
heuristic search parallel focused iterative broadening search heuristic
search configuration fast downward employed greedy best first search helpful
transitions falling back helpful actions necessary option configuration fast diagonally downward employed multi heuristic best first search helpful transitions helpful
actions preferred operators option


fit fast ownward p lanning ystem

avoid confusion complete fast downward system particular
configuration called fast downward refer ipc planner configurations fd
fdd rest name system whole never abbreviated
causal graph heuristic
causal graph heuristic centrepiece fast downwards heuristic search engine estimates cost reaching goal given search state solving number subproblems
task derived looking small windows pruned causal graph
additional intuitions design heuristic discussion theoretical aspects
refer article heuristic first introduced helmert
c onceptual v iew



c ausal g raph h euristic

state variable v pair values dv causal graph heuristic computes
heuristic estimate cost v cost changing value v assuming
state variables carry values current state simplification cost
estimates computed state variables v values never required
ignore fact discussing heuristic conceptual level heuristic estimate
given state sum costs cost v v v variables v goal
condition v defined
conceptually cost estimates computed one variable traversing pruned
causal graph bottom fashion bottom mean start variables
predecessors causal graphs call order computation bottom
consider variables change state accord low level variables
whose state transitions require help variables complex transition semantics
thus considered high level note figures depicting causal graphs high level
variables typically displayed near bottom
variables without predecessors causal graph cost v simply equals cost
shortest path pruned domain transition graph dtg v variables
cost estimates computed graph search domain transition graph however
conditions transitions must taken account path addition
counting number transitions required reach destination value consider costs
achieving value changes variables necessary set transition conditions
important point computing values cost v completely consider
interactions state variable v predecessors causal graph changing
value requires several steps steps associated condition
variable v realize v must assume values required conditions sequence
example v represents package transportation task must moved b
means vehicle located c recognize vehicle must first move c
b order drop package b different way hspor heuristics work examples however consider interactions
immediate predecessors v causal graph interactions occur via several graph layers
captured heuristic estimator
essence compute cost v solving particular subproblem mpt induced
variable v predecessors pruned causal graph subproblem assume


fih elmert

compute costs bottom
variable v traversing pruned causal graph bottom order
let v set immediate predecessors v pruned causal graph
pair values dv dv
generate task v following components
variables v v
initial state v v v v v
goal v
axioms operators
corresponding transitions pruned dtg v
variables v v values e e dv operator
precondition v e effect v e cost cost v e e
note variables v v considered previously
cost values known
set costv cost plan solves v
figure compute costs bottom high level description causal graph
heuristic

v initially set want v assume value state variables carry
value current state call local subproblem v
local subproblem v leave target value open
formalization intuitive notions cost estimates generated consider
pseudo code fig reflect way heuristic values actually computed
within fast downward figure would far expensive evaluate
search state however computes cost values fast downward provided
generating plans last line one one used
real cost estimator
c omputation



c ausal g raph h euristic

actual computation causal graph heuristic traverses causal graph top direction starting goal variables rather bottom starting variables without causal
predecessors fact top traversal causal graph reason fast downwards
name
computing cost estimates top traversal implies computing
plans local subproblems given variable typically yet know costs changing
state causal predecessors compute costs addresses evaluating
cost values dependent variables recursive invocations
given variable value pairing v compute costs cost v values
dv time similar way dijkstras computes shortest path
single source single destination vertex single source possible destination
vertices computing costs values much expensive computing


fit fast ownward p lanning ystem

one values cost values determined cache use
needed later parts computation heuristic value
current state
fact similarity shortest path superficial runs quite deeply
ignore recursive calls computing cost values dependent variables compute costs basically implementation dijkstras single source shortest path
domain transition graphs difference regular lies fact
know cost arc advance transitions derived variables base cost
transitions fluents base cost addition base cost must pay
cost achieving conditions associated transition however cost achieving
given condition v e depends current value e state variable time transition
taken thus compute real cost transition know values
dependent state variables relevant situation
course many different ways taking transitions domain transition graphs
potentially leading different values dependent state variables first introduced
causal graph heuristic showed deciding plan existence local subproblems npcomplete helmert content lead complete
long works well subproblems face practice
chosen achieve value state variable v local subproblem
v quickly possible following greedy policy context dijkstra
means start finding cheapest possible plan make transition
value found cheapest possible plan commit annotating
vertex domain transition graph local state obtained applying plan
current state next step look cheapest possible plan achieve another value
considering transitions start initial value considering transitions
continue plan moving neighbour process iterated vertices
domain transition graph reached progress possible
implementation follows dijkstras fig implemented priority queue vector buckets maximal speed use cache avoid generating
costv value twice state addition use global cache shared
throughout whole process need compute values cost v variables v ancestors pruned causal graph note cost v depends
current values ancestors v
apart technical considerations fig gives accurate account
fast downwards implementation causal graph heuristic details including
complexity considerations worked example refer original description
helmert
tates

nfinite

h euristic value

noted fast downward uses incomplete determining solutions
local therefore states cost v v v even though
goal condition v v still reached means cannot trust infinite values
returned causal graph heuristic experience states infinite heuristic evaluation
still possible reach goal rare indeed treat states dead ends


fih elmert

compute costs v
let v set immediate predecessors v pruned causal graph
let dtg pruned domain transition graph v
costv
costv dv
local state restricted v
unreached dv
unreached contains value dv cost v
choose value unreached minimizing cost v
unreached unreached
transition dtg leading unreached
transition cost v derived variable v fluent
pair v e condition
e local state v
call compute costs v e
transition cost transition cost cost v e e
costv transition cost cost v
costv costv transition cost
local state local state
pair v e condition
local state v e
figure fast downwards implementation causal graph heuristic compute costs computing estimates cost v values dv state
mpt



fit fast ownward p lanning ystem

turns states search frontier dead ends cannot make progress
causal graph heuristic case use sound dead end detection routine verify
heuristic assessment turns frontier states indeed dead ends report
unsolvable otherwise search restarted heuristic cf section
sound purposes dead end detection
dead end detection routine originally developed strips tasks however
extending full mpts easy fact changes core required works
level domain transition graphs still sound applied tasks conditional
effects axioms since central aspect fast downward discuss
referring earlier work instead helmert
h elpful ransitions
inspired hoffmanns successful use helpful actions within planner hoffmann
nebel extended computing causal graph heuristic
addition heuristic estimate generates set applicable operators considered useful
steering search towards goal
compute helpful actions hoffmanns generates plan relaxed task defined current search state considers operators helpful belong
relaxed plan applicable current state
follows similar idea computing heuristic estimate cost v v v
variable v goal condition defined look domain transition graph
v trace path transitions leading v v gave rise cost estimate
particular consider first transition path starting v transition corresponds
applicable operator consider operator helpful transition continue check
next goal transition correspond applicable operator associated
conditions form v e currently satisfied recursively look helpful transitions domain transition graph variable v checking path
generated computation cost v v e
recursive process continues found helpful transitions unlike case
helpful actions found non goal states might helpful
transition may case transition correspond applicable operator
even though associated conditions happen operator preconditions
represented pruned domain transition graph due cycles causal graph even
found helpful transitions useful tool guiding best first search
heuristic
heuristic named hoffmanns name context
originally introduced hoffmann nebel notion
relaxed tasks ignore negative interactions context mpts ignoring negative
interactions means assume state variable hold several values simultaneously
operator effect axiom sets variable v value original task corresponds
practice never observed causal graph heuristic fail solvable task therefore fallback
mechanism used unsolvable tasks iconic f ull adl domain recognized
dead end detection technique



fih elmert

effect axiom adds value range values assumed v relaxed task
condition v original task corresponds condition requiring element
set values currently assumed v relaxed task
easy see applying operator solvable relaxed task never render
unsolvable lead operators applicable goals true
significant effect reason relaxed tasks solved efficiently even
though optimal solutions still np hard compute bylander plan relaxation
task called relaxed plan task
heuristic estimates goal distance world state generating relaxed plan
task reaching goal world state number operators generated plan
used heuristic estimate implementation heuristic necessarily
generate even equally long relaxed plan experiments turn
problematic implementations appear equally informative
heuristic originally introduced adl domains extending tasks involving derived predicates straight forward one possible extension simply assume
derived predicate initially set default value treat axioms relaxed operators cost
slightly complicated accurate derived variables initialized
actual value given world state allowing relaxed planner achieve value
values applying transitions extended domain transition graph derived
variable followed second
addition heuristic estimates heuristic exploited restricting biasing
choice operators apply given world state set helpful actions consists
operators relaxed plan computed applicable state mentioned
introduction section fast downward configured treat helpful actions
preferred operators
wealth work heuristic literature discuss
thorough treatment point references hoffmann nebel hoffmann

greedy best first search fast downward
fast downward uses greedy best first search closed list default search
assume reader familiar refer literature details russell
norvig
implementation greedy best first search differs textbook two ways
first treat helpful transitions computed causal graph heuristic helpful actions computed heuristic preferred operators second performs deferred heuristic evaluation
reduce influence large branching factors turn describing two search
enhancements
p referred perators
make use helpful transitions computed causal graph heuristic helpful actions computed heuristic variant greedy best first search supports use called preferred operators set preferred operators given state subset set applicable
operators state operators considered preferred depends settings


fit fast ownward p lanning ystem

search component discussed earlier intuition behind preferred operators randomly
picked successor state likely closer goal generated preferred operator case call preferred successor preferred successors considered
non preferred ones average
search implements preference maintaining two separate open lists one
containing successors expanded states one containing preferred successors exclusively
search alternates expanding regular successor preferred successor
even iterations consider one open list odd iterations matter
open list state taken successors placed first open list preferred
successors additionally placed second open list course could limit first open
list contain non preferred successors however typically total number successors
vast number preferred successors tiny therefore cheaper add successors
first open list detect duplicates upon expansion scan list successors
determining element whether preferred
since number preferred successors smaller total number successors
means preferred successors typically expanded much earlier others especially
important domains heuristic guidance weak lot time spent exploring plateaus
faced plateaus fast downwards open lists operate first first fashion
words constant heuristic function search behaves breadth first
search preferred operators typically offer much better chances escaping plateaus since
lead significantly lower effective branching factors
eferred h euristic e valuation
upon expanding state textbook version greedy best first search computes heuristic
evaluation successor states sorts open list accordingly
wasteful many successors heuristic evaluations costly two conditions often
true heuristic search approaches
second modification comes play successor better heuristic
estimate generated early leads promising path towards goal would
avoid generating successors let us assume successors
th successor generated better heuristic estimate furthermore let us
assume goal reached path non increasing heuristic estimates
would avoid computing heuristic values later successors altogether
deferred heuristic evaluation achieves computing heuristic estimates successors expanded state immediately instead successors placed open list
together heuristic estimate state heuristic estimates computed
expanded time used sorting successors open
list general state sorted open list according heuristic evaluation
parent initial state exception fact need put successor
state open list since require representation want evaluate
heuristic estimate instead save memory storing reference parent state
operator transforming parent state successor state open list
might clear lead significant savings time since deferred
evaluation means information available later potential savings become


fih elmert

apparent considering deferred heuristic evaluation together use preferred operators
improving successor state reached preferred operator likely
expanded via second open list long successors even siblings
situation described exists non increasing path goal
heuristic evaluations never computed successors fact deferred heuristic
evaluation significantly improve search performance even preferred operators
used especially tasks branching factors large heuristic estimate informative
first glance deferred heuristic evaluation might appear related another technique reducing effort expanding node within best first search namely partial
expansion yoshizumi miura ishida however designed reducing
space requirements best first search expense additional heuristic evaluations
expanding node partial expansion computes heuristic value successors
stores open queue whose heuristic values fall certain relevance threshold
later iterations might turn threshold chosen low case node
needs expanded heuristic values successors evaluated general
partial expansion never compute fewer heuristic estimates standard usually
require less memory
however heuristic search approaches certainly fast downward heuristic evaluations usually costly time memory storing open closed lists
limiting factor thus willing trade memory time opposite way deferred
heuristic evaluation normally leads node expansions higher space requirements
standard best first search heuristic values used guiding search less informative evaluate predecessor search node rather node however heuristic
computations required nodes actually removed open queue rather
nodes fringe latter usually significantly numerous
multi heuristic best first search
alternative greedy best first search fast downward supports extended called
multi heuristic best first search differs greedy best first search use
multiple heuristic estimators observation different heuristic estimators different weaknesses may case given heuristic sufficient directing search
towards goal except one part plan gets stuck plateau another heuristic
might similar characteristics get stuck another part search space
ways combining heuristics proposed literature typically adding
together taking maximum individual heuristic estimates believe often
beneficial combine different heuristic estimates single numerical value instead
propose maintaining separate open list heuristic estimator sorted according
respective heuristic search alternates expanding state
open list whenever state expanded estimates calculated according heuristic
successors put open list
fast downward configured use multi heuristic best first search computes estimates causal graph heuristic heuristic maintaining two open lists course
combined use preferred operators case search
maintains four open lists heuristic distinguishes normal preferred successors


fit fast ownward p lanning ystem

reach one goal v cond
max threshold
let set operators whose modification distance respect v

assign cost c operator modification distance c
respect v
call uniform cost search closed list operator set
state satisfying v cond
return plan uniform cost search succeeded
figure reach one goal procedure reaching state v value max threshold
equal maximal modification distance operator respect v

focused iterative broadening search
focused iterative broadening search experimental piece fast downwards search arsenal present form unsuitable many domains
especially containing comparatively different goals yet think might contain
nucleus successful domain independent different
current methods include completeness source inspiration
intended first step towards developing search techniques emphasize
idea heuristic criteria locally limiting set operators apply rather globally
choosing states expand global set open states made first experiments
direction observing large boost performance obtained preferred
operators heuristic search performed surprisingly well standard
benchmark domains performing badly others
name suggests focuses search concentrating one goal time
restricting attention operators supposedly important reaching goal
definition modification distances
let mpt let operator let v variable
modification distance respect v defined minimum variables
v occur affected variables effect list distance v v cg
example operators modify v directly modification distance respect
v operators modify variables occur preconditions operators modifying v
modification distance assume order change value variable
operators low modification distance respect variable useful
fig shows reach one goal procedure achieving single goal mpt time
assume cond parameter procedure makes use assumption
high modification distance implies low usefulness two ways first operators high
modification distance respect goal variable considered higher associated
cost hence applied less frequently second operators whose modification distance beyond
certain threshold forbidden completely instead choosing threshold priori


fih elmert

first tries solution lowest possible threshold increasing threshold
whenever previous search failed uniform cost search mentioned fig
standard textbook method russell norvig
although ignorant fact time conceived core idea
reach one goal ginsberg harvey present search technique called iterative
broadening idea repeatedly sequence uninformed searches
ever growing set operators work demonstrates superiority iterative broadening standard depth bounded search empirically analytically reasonable
assumption choices made branching point equally important original iterative broadening applies scenarios without knowledge domain
chooses set operators may applied every search node randomly rather
heuristic information causal graph case however ginsberg harvey
already discuss potential incorporation heuristics operator selection introduction operator costs form modification distances fairly straightforward
extension heuristic information available
focused iterative broadening search reach one goal method
idea achieve goals task one reach one goal
core subroutine satisfying individual goals since obvious good
order achieving goals would one invocation reach one goal started goal
parallel one goal solver focuses supposedly relevant operators reaching
particular goal hope number states considered goal reached small
one one goal solvers reaches goal resulting plan reported sub searches
stopped overall search commits part plan situation
first goal reached considered initial state
situation try satisfy second goal starting parallel invocations
reach one goal possible second goal course lead situation
search oscillates goals first achieving goal abandoning favour goal
b without sign making real progress therefore demand reach one goal achieves
second goal addition one reached first setting cond argument accordingly
two goals reached sub searches stopped sub searches third
goal started goals reached
sense focusing technique similar beam search lowerre
performs fixed number concurrent searches avoid committing particular path
search space early beam search uses heuristic function evaluate branches
search abandoned branches spawned focused iterativebroadening search appear use heuristic evaluations first glance number satisfied
goals state used evaluation criterion essentially way one important difference beam search use modification distances relative particular goal means
different beams explore state space qualitatively different ways
one final twist motivate reach one goal needlessly wander away satisfied goals forbid applying operators undo previously achieved goals cond
old idea called goal protection joslin roach well known protecting
see original analysis precise definition equally important ginsberg harvey ginsberg
harveys assumption certainly valid practice much convincing competing model
goal states uniformly distributed across search fringe



fit fast ownward p lanning ystem

reach one goal v cond
max threshold
let set operators whose modification distance respect v
affect state variable occurring cond
assign cost c operator modification distance c
respect v
call uniform cost search closed list operator set
state satisfying v cond
return plan uniform cost search succeeded
max threshold
let set operators whose modification distance respect v

assign cost c operator modification distance c
respect v
call uniform cost search closed list operator set
state satisfying v cond
return plan uniform cost search succeeded
figure reach one goal procedure reaching state v corrected
goals renders search incomplete even state spaces operators reversible
local search approaches focused iterative broadening search would otherwise complete
particular search must fail tasks serializable korf therefore
first solution attempt fails restarted without goal protection complete
procedure shown fig concludes discussion fast downwards search component

experiments
evaluate performance fast downward specifically differences
configurations search component performed number experiments set
benchmarks previous international competitions purpose experiments compare fast downward state art pddl contrast
performance different search fast downward greedy best first search
without preferred operators multi heuristic best first search without preferred operators
focused iterative broadening search
clearly state purpose experiments let us point two areas worthy study
choose investigate
compare causal graph heuristic heuristics hsp
heuristics comparison would require evaluating different heuristics within otherwise identical systems performed experiment helmert
thus prefer dedicate section evaluation complete fast downward
system rather heuristic function


fih elmert

give final answer question fast downward performs well badly
domains analyse observe bad performance try give plausible
explanation conduct full blown study heuristic quality spirit
hoffmanns work h heuristics hoffmann believe
much could learned investigation major undertaking would go
beyond scope article
aim section evaluate fast downward planner whole
number algorithmic questions address example one might wonder
speed obtained successor generators simpler methods test
operator applicability whenever node expanded another question concerns extent
deferred heuristic evaluation affects search performance keep section reasonable
length discuss questions however conducted experiments
addressing include electronic appendix
benchmark set
benchmark set use consists propositional tasks fully automated
tracks first four international competitions hosted aips aips aips
icaps set benchmark domains shown fig altogether benchmark suite comprises tasks numbers fig add atellite
instances introduced ipc part benchmark set ipc
count
distinguish three classes domains
strips domains domains feature derived predicates conditional effects
conditions appearing goal operators conjunctions positive literals
adl domains domains make use conditional effects operator contain
general conditions simple conjunctions goals operators however
require axioms
pddl domains domains use full range propositional pddl including
features present adl domains axioms
ipc domains presented different formulations meaning realworld task encoded several different ways participants asked work one
formulation per domain able choose preferred formulation given domain freely
example irport domain available strips formulation adl formulation
however organizers strictly follow rule considering different encodings
real world task different formulations rather different domains proper namely
psr iddle p romela domains encodings without axioms available
considered different domains grounds encodings without axioms
see http www jair org short summary successor generators speed search two
orders magnitude extreme cases largest atellite tasks little impact performance
time deferred heuristic evaluation beneficial domains speed ups one order
magnitude common somewhat beneficial majority domains speed ups
rarely detrimental performance



fit fast ownward p lanning ystem

competition

domain

class

number tasks

ipc aips

ssembly
g rid
g ripper
l ogistics
ovie
ystery
mp rime

adl
strips
strips
strips
strips
strips
strips









ipc aips

b locksworld
f reecell
l ogistics
iconic strips
iconic imple adl
iconic f ull adl
chedule

strips
strips
strips
strips
adl
adl
adl









ipc aips

epot
riverlog
f reecell
rovers
atellite
z enotravel

strips
strips
strips
strips
strips
strips








ipc icaps

irport
p romela pticalt elegraph
p romela p hilosophers
p ipesworld n otankage
p ipesworld tankage
psr mall
psr iddle
psr l arge
atellite

strips
pddl
pddl
strips
strips
strips
pddl
pddl
strips











figure domains first four international competitions



fih elmert

much larger hence likely difficult solve apply formulation vs encoding view
strictly thus consider one psr iddle domain one domain two
p romela variants p romela p hilosophers p romela pticalt elegraph
ipc benchmark set tasks solvable except ystery instances
ipc benchmark set tasks solvable except iconic f ull adl instances
ipc benchmarks solvable ipc checked instances p ipesworld tankage domain assume tasks solvable
run heuristic search modes fast downward proves unsolvability
unsolvable ystery iconic f ull adl tasks dead end detection routine described earlier article causal graph heuristic helmert cases
iconic f ull adl domain exhaustively searching states finite heuristic
course unsolvable task proved unsolvable planner report successfully
solved instance experimental
experimental setup
discussed section eleven possible configurations fast downwards search
component however equally reasonable example use ffs helpful
actions would seem wasteful use heuristic estimate since two calculated
together therefore greedy best first search setup exclude configurations
helpful actions computed multi heuristic best first search setup exclude
configurations one type preferred operators considered since
would seem arbitrary choice leaves us six different configurations
planner
g use greedy best first search without preferred operators
g p use greedy best first search helpful transitions preferred operators
g p use greedy best first search helpful transitions preferred operators use
helpful actions preferred operators states helpful transitions
use multi heuristic best first search without preferred operators
p use multi heuristic best first search helpful transitions helpful actions
preferred operators
f use focused iterative broadening search
apply planner configurations benchmark tasks
computer ghz intel xeon cpu machine used ipc set
memory limit gb timeout seconds
compare fast downward state art try solve benchmark
best performing planners literature unfortunately involves intricacies
planners publicly available others cover restricted subset pddl
main experiment thus partition benchmark domains three sets depending
planners available comparison


fit fast ownward p lanning ystem

domain

task

configuration

f reecell ipc
g rid
mp rime
psr l arge
atellite ipc

probfreecell
prob
prob
p n l f
p hc pfile

p


g p
p

preprocessing






search






figure tasks could solved configuration fast downward search
timeout seconds total processing timeout seconds
column preprocessing shows total time translation knowledge compilation

translation knowledge compilation vs search
course report fast downward include time spent three components
planner translation knowledge compilation search therefore following presentation consider task solved total processing time seconds
however investigated tasks solved timeout seconds
search component alone allowing components use arbitrary amount resources
turns makes difference five cases could solved
total time seconds fig one five cases atellite instance
exorbitant size search take less time two phases combined
search component time critical part fast downward practice therefore
report separate performance individual components
strips domains ipc
let us present main experiment abstain listing runtimes individual tasks due prohibitively large amount data available electronic
appendix article instead report following information
tables showing number tasks solved planner within second timeout
present individual domain
graphs showing number tasks solved given time planner
present separate domain would require many graphs
discuss plan lengths observations regard similar made
original implementation causal graph heuristic helmert
fig shows number unsolved tasks strips domains ipc
figs number tasks solved planner within given time bound
seconds addition six configurations fast downward consideration
table includes four columns
heading include hypothetical meta planner guesses
best six configuration fast downward input task executes fast downward
http www jair org



fih elmert

domain

tasks

g

b locksworld
epot
riverlog
f reecell ipc
f reecell ipc
g rid
g ripper
l ogistics ipc
l ogistics ipc
iconic strips
ovie
ystery
mp rime
rovers
atellite ipc
z enotravel





































































total









g p g p

p

f



cg



lpg






































































































































figure number unsolved tasks strips domains ipc ipc ipc
psfrag replacements
fdd fast downward



fd fast downward
yahsp
macro



lpg td
cg

lpg

solved tasks

sgplan



fast downward
g p fast downward
p fast downward
g fast downward
g p fast downward
fast downward
f fast downward










search time







figure number tasks solved vs runtime strips domains ipc ipc ipc
graph shows configurations fast downward



fit fast ownward p lanning ystem

psfrag replacements
fdd fast downward



fd fast downward
yahsp
macro



lpg td

solved tasks

sgplan



g p fast downward
fast downward
g p fast downward
cg

lpg


g fast downward
p fast downward
fast downward
f fast downward








search time







figure number tasks solved vs runtime strips domains ipc ipc ipc
graph shows cg lpg hypothetical planner
chooses best configuration fast downward greedy
best first search helpful transitions repeated ease comparison fig



fih elmert

setting heading cg report first implementation
causal graph heuristic helmert finally lpg refer well known planners
hoffmann nebel gerevini et al fully automated tracks ipc
ipc chosen comparison benchmark set showed best
performance far publicly available planners experimented lpg uses
randomized search strategy attempted solve task five times report median
excellent performance fast downward set benchmarks compared cg already shown solve tasks lpg benchmark set
helmert get another slight improvement half planner configurations one
configurations multi heuristic best first search preferred operators solves benchmarks
domains except epot f reecell even importantly number tasks
solved fast downward configurations small note competitions typically allowed planner spend minutes task time constraints
could allocate five minutes six configurations fast downward getting
least good reported planner might even better
cleverer allocation scheme
even configuration focused iterative broadening search performs comparatively well
benchmarks although cannot compete planners surprisingly
version planner difficulties domains many dead ends f reecell ystery
mp rime goal ordering important b locksworld epot fares comparatively badly domains large instances namely l ogistics ipc atellite
reader keep mind lpg excellent systems
planners experimented including awarded prizes first three competitions none solved benchmarks group focused iterative broadening
search
one domain proves quite resistant fast downwards solution attempts configuration epot already observed initial experiments causal graph heuristic
helmert believe one key fast downward unlike
use goal ordering techniques important domain fact domain
includes b locksworld subproblem problematic gives rise dense causal
graphs demonstrated section
adl domains ipc
second present adl domains first three competitions
much smaller group previous including four domains time cannot consider
cg lpg since neither cg publicly available version lpg supports adl domains
therefore compare exclusively report number unsolved tasks
domain fig present graphs showing quickly tasks solved figs
look good first group domains iconic
domains good even improving however greedy best first search performs
badly ssembly domain configurations perform badly chedule domain
apart missing support adl axioms cg similar fast downward greedy best first search
preferred operators configuration g translation knowledge compilation components essentially
identical older search component mainly differs fast downward use deferred heuristic
evaluation



fit fast ownward p lanning ystem

domain

tasks

ssembly
iconic imple adl
iconic f ull adl
chedule
total







g






g p g p


















p

f





























figure number unsolved tasks adl domains ipc ipc ipc

psfrag replacements
fdd fast downward



fd fast downward



yahsp
macro



lpg td
cg

lpg

solved tasks

sgplan




fast downward


p fast downward
g p fast downward
g p fast downward
fast downward
g fast downward
f fast downward










search time







figure number tasks solved vs runtime adl domains ipc ipc ipc
graph shows configurations fast downward



fih elmert

psfrag replacements
fdd fast downward



fd fast downward



yahsp
macro



lpg td
cg

lpg

g p fast downward

solved tasks

sgplan





g p fast downward
g fast downward

fast downward
f fast downward




fast downward
p fast downward









search time







figure number tasks solved vs runtime adl domains ipc ipc ipc
graph shows hypothetical planner
chooses best configuration fast downward multi heuristic bestfirst search preferred operators repeated ease comparison fig



fit fast ownward p lanning ystem

currently good explanation ssembly behaviour chedule domain weak performance seems related missing goal ordering techniques
many chedule tasks several goals defined object satisfied
certain order instance objects cylindrical polished painted
three goals must satisfied precisely order making object cylindrical reverts effects
polishing painting polishing reverts effect painting recognising constraints heuristic search assumes close goal object already
polished painted cylindrical loathe transform object cylindrical shape
would undo already achieved goals rudimentary manual goal ordering
ignoring painting goals goals satisfied number tasks solved
multi heuristic best first search preferred operators drops three failures
appear due remaining ordering regard cylindrical polished objects
domains ipc
third finally present ipc domains compare
benchmarks perform well best planners competition besides several
ipc competitors extensions hybrids part bigger system ffbased well represented even limit attention ipc planners
comparison chose four successful competition participants besides fast downward
namely lpg td sgplan macro yahsp cf hoffmann edelkamp
similar previous two experiments report number unsolved tasks domain
fig present graphs showing quickly tasks solved figs
fast downward competitive planners across domains better others
p ipesworld domains ones planners noticeably better two competition versions fast downward case yahsp
p ipesworld domain variants sgplan p ipesworld n otankage p ipesworld
domain hierarchical nature might domain decomposition causal graph heuristic appropriate heuristic search
configurations p romela pticalt elegraph domain extremely bad require investigation
interestingly focused iterative broadening search performs well benchmarks suite one reasons many tasks ipc suite
many individual goals easy serialize solved mostly independently
comparing configuration g g p especially p observe preferred operators useful benchmarks even two previous
experiments
final remark observe implemented meta planner calling six
fast downward configurations round robin fashion would obtain system
could solve ipc benchmarks within minute timeout almost
par top performer ipc fast diagonally downward solved ipc
benchmarks timeout thus benchmark set exploring different
planner configurations definitely pays
devised experiment shows property artificially violated simple goal reformulation
performance degrades quickly see electronic appendix details



fih elmert

domain

tasks

irport
p ipesworld n otankage
p ipesworld tankage
p romela pticalt elegraph
p romela p hilosophers
psr mall
psr iddle
psr l arge
atellite ipc
total












g











g p g p

p

f





































































domain

fd

fdd

lpg td

macro

sgplan

yahsp

irport
p ipesworld n otankage
p ipesworld tankage
p romela pticalt elegraph
p romela p hilosophers
psr mall
psr iddle
psr l arge
atellite ipc
total



































































figure number unsolved tasks ipc domains configurations
fast downward listed upper part competition participants
lower part fd fdd denote versions fast downward participated ipc names fast downward fast diagonally downward
cf section



fit fast ownward p lanning ystem

psfrag replacements
fdd fast downward



fd fast downward



yahsp



macro
sgplan

cg

lpg


solved tasks

lpg td

fast downward





p fast downward
g p fast downward
g p fast downward
fast downward
f fast downward
g fast downward










search time







figure number tasks solved vs runtime ipc domains graph shows
configurations fast downward
psfrag replacements




cg

lpg

g p fast downward
g p fast downward
g fast downward

solved tasks







fast downward
fdd fast downward
fd fast downward
sgplan
lpg td
yahsp
macro




p fast downward
fast downward
f fast downward








search time







figure number tasks solved vs runtime ipc domains graph shows
hypothetical planner chooses best configuration fast
downward competition configurations fast downward best four
participants



fih elmert

conclusions experiment
interpret experimental first conclusion fast downward
clearly competitive state art especially true configuration
multi heuristic best first search preferred operators p outperforms competing
systems set strips domains ipc domains ipc
chedule domain would true remaining
group benchmarks adl domains ipc
regard second objective investigation evaluating relative strengths
different planner configurations p configuration emerges clear cut winner
domains configuration solves tasks unlike configurations
one domain p romela pticalt elegraph performs badly conclude
multi heuristic best first search use preferred operators promising extensions
heuristic planners
particularly true preferred operators indeed p configuration two
variants greedy best first search preferred operators next best overall performance
terms number domains among top performers terms
total number tasks solved comparing g g p ten domains variant
preferred operators solves tasks one opposite true five
domains comparing p difference even striking preferred operator
variant outperforming fifteen domains worse two
solves one task less convincing arguments use preferred operators

summary discussion
turn discussion let us briefly summarize contributions article motivating starting point explained tasks often exhibit simpler structure expressed
multi valued state variables rather traditional propositional representations
introduced fast downward system idea converting tasks multivalued formalism exploiting causal information underlying encodings
fast downward processes pddl tasks three stages skipped first
stages translation automatically transforms pddl task equivalent multi valued
task nicer causal structure explained inner workings second stage
knowledge compilation demonstrating depth kind knowledge planner extracts
representation discussing causal graphs domain transition graphs successor generators axiom evaluators discussion fast downwards search component
introduced heuristic search use technique deferred heuristic evaluation
reduce number states heuristic goal distance estimate must computed
addition greedy best first search fast downward employs multi heuristic best first search
usefully integrate information two heuristic estimators namely causal graph
heuristic heuristic heuristic search utilize preference information
operators introduced fast downwards experimental focused iterative broadening
search idea pruning set operators consider
successor states likely lead towards specific goal
thus tried give complete account fast downward systems
solving multi valued tasks including motivation architecture algorithmic founda

fit fast ownward p lanning ystem

tions previous section demonstrated empirical behaviour showing good performance
across whole range propositional benchmarks previous competitions
among novel search enhancements discussed article two
aspects fast downward consider central importance would
emphasize one use multi valued state variables pddl style
believe multi valued representations much structured hence much amenable
automated reasoning purposes heuristic evaluation decomposition
aspects goal ordering extraction landmarks central
idea use hierarchical decompositions within heuristic framework hierarchical
approaches domain independent considerable potential since work
knoblock bacchus yang little work published fast downward hope renew interest area believe promising ground
advances automated
future several aspects fast downward would investigate
first intend experiment search techniques along lines focused
iterative broadening search emphasize heuristically evaluating operator usefulness rather
heuristically evaluating states
second would come efficient heuristic multi valued tasks
require pruning cycles causal graph initial experiments direction
shown difficult achieve goal without losing performance fast downwards
heuristic estimator perhaps better heuristic accuracy outweigh worse per state performance
many cases
third want investigate far performance planner could improved
encoding domains differently cases merging set state variables
closely interrelated single state variable whose domain product domains
original state variables might beneficial want test hand tailored encodings lead
better performance automatically derived ones large performance gap
fourth finally would evaluate behaviour causal graph heuristic
specific domains empirically theoretically following hoffmanns work
heuristic hoffmann hopefully give indication
expect good performance causal graph heuristic advisable look
approaches

acknowledgements
author wishes thank silvia richter member fast downward team
th international competition part implementing planner valuable
advice throughout competition deserves thanks helping
experiments proof reading article suggesting number improvements
anonymous reviewers article handling editor maria fox made number
useful suggestions led significant improvements
work partly supported german council dfg within graduate
programme mathematical logic applications part transregional collaborative
centre automatic verification analysis complex systems sfb tr avacs
see www avacs org information


fih elmert

references
bacchus f yang q downward refinement efficiency hierarchical
solving artificial intelligence
backstrom c nebel b complexity sas computational intelligence
bonet b geffner h heuristic search artificial intelligence
brafman r domshlak c structure complexity unary operators
journal artificial intelligence
bylander computational complexity propositional strips artificial
intelligence
domshlak c brafman r structure complexity unary operators
ghallab hertzberg j traverso p eds proceedings sixth international
conference artificial intelligence scheduling aips pp aaai
press
domshlak c dinitz multi agent line coordination structure complexity
cesta borrajo eds pre proceedings sixth european conference
ecp pp toledo spain
dowling w f gallier j h linear time testing satisfiability
propositional horn formulae journal logic programming
edelkamp helmert exhibiting knowledge minimize
state encoding length fox biundo eds recent advances ai
th european conference ecp vol lecture notes artificial
intelligence pp york springer verlag
edelkamp hoffmann j pddl language classical part th
international competition tech rep albert ludwigs universitat freiburg
institut fur informatik
fox long pddl extension pddl expressing temporal
domains journal artificial intelligence
garey r johnson computers intractability guide theory
np completeness freeman
gerevini saetti serina stochastic local search temporal
action graphs lpg journal artificial intelligence
ginsberg l harvey w iterative broadening artificial intelligence
helmert heuristic causal graph analysis zilberstein koehler
j koenig eds proceedings fourteenth international conference automated
scheduling icaps pp aaai press
hoffmann j local search topology benchmarks empirical analysis
nebel b ed proceedings th international joint conference artificial intelligence ijcai pp morgan kaufmann


fit fast ownward p lanning ystem

hoffmann j local search topology benchmarks theoretical analysis
ghallab hertzberg j traverso p eds proceedings sixth international conference artificial intelligence scheduling aips pp aaai
press
hoffmann j ignoring delete lists works local search topology benchmarks journal artificial intelligence
hoffmann j edelkamp deterministic part ipc overview journal
artificial intelligence
hoffmann j nebel b system fast plan generation heuristic
search journal artificial intelligence
jonsson p backstrom c incremental ghallab milani eds
directions ai ewsp rd european workshop vol
frontiers artificial intelligence applications pp amsterdam ios press
jonsson p backstrom c state variable structural restrictions complexity artificial intelligence
jonsson p backstrom c b tractable plan existence imply tractable plan generation annals mathematics artificial intelligence
joslin roach j theoretical analysis conjunctive goal artificial
intelligence note
knoblock c automatically generating abstractions artificial intelligence

korf r e search quantitative artificial intelligence

lowerre b harpy speech recognition system ph thesis computer science
department carnegie mellon university pittsburgh pennsylvania
newell simon h gps program simulates human thought feigenbaum
e feldman j eds computers thought pp oldenbourg
russell norvig p artificial intelligence modern prentice hall
sacerdoti e hierarchy abstraction spaces artificial intelligence

tenenberg j abstraction allen j f kautz h pelavin r n
tenenberg j reasoning plans chap pp morgan kaufmann san
mateo
van den briel vossen kambhampati reviving integer programming approaches ai branch cut framework biundo myers k rajan
k eds proceedings fifteenth international conference automated
scheduling icaps pp aaai press
williams b c nayak p p reactive planner model executive pollack
e ed proceedings th international joint conference artificial intelligence
ijcai pp morgan kaufmann


fih elmert

yoshizumi miura ishida partial expansion large branching factor kautz h porter b eds proceedings seventeenth national
conference artificial intelligence aaai pp aaai press




