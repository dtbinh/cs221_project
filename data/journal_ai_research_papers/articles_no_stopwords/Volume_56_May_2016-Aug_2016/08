journal artificial intelligence

submitted published

engineering note
ibacop system instance configured portfolios
isabel cenamor
tomas de la rosa
fernando fernandez

icenamor inf uc es
trosa inf uc es
ffernand inf uc es

departamento de informatica universidad carlos iii de madrid
avda de la universidad leganes madrid spain

abstract
sequential portfolios powerful exploiting complementary strength
different automated planners main challenge portfolio planner define
base planners run assign running time planner decide order
carried optimize metric portfolio configurations usually derived
empirically training benchmarks remain fixed evaluation phase work
create per instance configurable portfolio able adapt every task
proposed system pre selects group candidate planners pareto dominance filtering
decides planners include time assigned according predictive
estimate whether base planner able solve given
long take define different portfolio strategies combine knowledge
generated experimental evaluation shows resulting portfolios provide
improvement compared non informed strategies one proposed portfolios
winner sequential satisficing track international competition held


introduction
process chooses organizes actions anticipating outcomes
aim achieving pre stated objectives artificial intelligence automated ap
computational study deliberation process ghallab nau traverso automated
planners systems regardless application domain able receive declarative
representation environment initial state set goals input output synthesized plan achieve goals initial situation context international
competition ipc excellent initiative foster studying development automated systems ipc created set common framework comparing
automated planners
different systems awards previous ipcs however one main invariants
competition single planner best planner least equal
every domain every means although planner following
quality metrics competition considered best
different domains planners outperform overall winner therefore assume
ap community generated set single planners better others specific
situations reason discarding priori solvers seems meaningless
c

ai access foundation rights reserved

fic enamor de la rosa f ern andez

fact idea reusing set individual base systems generate accurate solutions obtained separately artificial intelligence instance machine
learning meta classifiers use different base classifier increase coverage representation
bias resulting classifier dietterich solving portfolios search
demonstrated outperform single search strategy xu hutter
hoos leyton brown xu hoos leyton brown malitsky sabharwal samulowitz sellmann example sat competition included special track
portfolios automated community planner portfolios subject great
deal interest ipcs portfolio approaches close winning
tracks took part
however although use portfolios become usual community still
agreement portfolio vallati chrpa kitchin work
assume portfolio planners set base planners selection strategy selection
strategy generates specific portfolio configuration whose goal maximize performance metrics therefore configuration define three main elements sub set
planners run long run planner order many
techniques configure portfolio vallati depending accurate
chances selecting best planner given situation increase note
definition planner different configuration parameters modify behavior parameterization considered different base planner base planners considered black
boxes
number planners state art huge first filtering select minimum
number ensures best performance achieved evaluated domain even
domain obviously good current domains ensure good
domains shown good estimator sense pareto efficiencybased censor reduce number planners consider eligible
portfolio presented however mechanism first
aforementioned questions answered partially since number candidate planners
might still large
best solution portfolio configuration oracle predicts
given domain planner obtain best performance long
take given oracle work propose use predictive automatically generated machine learning data mining techniques summarize candidate planners past whether able solve
well time required generate good solution cenamor de la rosa
fernandez given knowledge past inductive hypothesis gives us
estimation behave future domains different
order planners implemented given accuracy predictions
therefore predictive able configure portfolio previous works use portfolios search gomes selman
renewed idea automated since recent works focused static helmert
domain specific portfolios gerevini saetti vallati configuration
portfolio fixed domains chosen one respectively
ibac p instance configured portfolio family portfolios built
competing ipc article first present ibac p general framework


fit ibac p p lanning ystem

ultimate goal building per instance configurable portfolios technique reproduced
whenever automated planners benchmarks arise describe
build different version ibac p following defined processes one versions
winner sequential satisficing track ipc include empirical
study confirms good performance ibac p planners compared different base
planners different portfolio configuration strategies summarize related work
finally last section sets conclusions future lines

system architecture
section present general idea building portfolio configured
particular task predictive process seen general
technique given inputs planners benchmarks might change future due progress
community portfolio configurations generated use
inputs
portfolio construction
consider construction instance portfolio comprises three main
parts planner filtering making pre selection good candidate planners set
known available planners proposed pre selection technique multi criteria approximation previously unexplored technique selecting set planners provides
enough diversity planner portfolio performance modeling providing predictors
planners behavior function task features include set
well known features cenamor et al built preprocessing step
fast ownward helmert take advantage output information
translation process fawcett vallati hutter hoffmann hoos leyton brown
heuristic values computed first step search process fast ownward addition
use several totally features characteristics relaxed plan initial state
proposed finally strategy selection establish procedure combines performance
predictions output portfolio configuration propose novel strategy selection
exploit effectiveness predictive next explain details
construction steps
p lanner f iltering
planner filtering process consists pre selection good candidate base planners
larger amount available planners even though sufficient evidence
overall best planner across variety benchmarks verified empirically
dominance planners others therefore make sense include base
planners worse terms performance metrics want filtering process
select diverse small subset planners elements among divide
available execution time
work propose multi criteria pre selection mechanism focuses two ipc metrics quality time alternative extended ones planner filtering example
fdss helmert roger seipp karpas hoffmann keyder nissim richter westphal


fic enamor de la rosa f ern andez

uses selection planners maximizes coverage mip lan nunez borrajo linares
lopez uses portfolio configuration obtains best achievable performance terms
score
filtering propose run candidate planners representative set benchmarks
evaluate terms time quality consider metrics propose
pareto efficiency censor allows us determine dominance
planners multi criteria fashion particular select planner candidate
portfolio best planner least one domain terms ipc multi criteria qt
score linares lopez celorrio olaya briefly single metric computes
tuple hq planner q quality planners best solution
time used solution given planner p dominance relations p
rest planners computed
tuple hq pareto dominates tuple hq q q planner
p gets nn points n number tuples p pareto dominates another planner
n number different tuples planner p appears finally qt pareto score
domain sum points achieved domain idea selection
mechanism follows planner shows good dominance property given domain
included portfolio good candidate solving
domain even tasks similar characteristics therefore simple strategy
filter first pool planners given procedure selects planners
maximum qt pareto score least one domain refer procedure qt pareto score
filtering
p erformance odeling
given task want predict selected base planners perform order
decide whether include make good assignment time ordering
configuring portfolio thus modeling planner behavior function
task features becomes key process building instance portfolios learn predictive
follow data mining shown figure case start set
candidate planners set benchmarks output process set
predict performance candidate planners defined data mining goal
creation two predictive first whether planner able solve
e classification task time required compute best plan e
regression task
first step mining process comprises generation training test datasets
one hand planners run set benchmarks obtain performance data
data includes outcome execution success failure positive cases time
elapsed finding best solution hand tasks processed extract set
features characterize features extended set previously proposed
set cenamor et al according mechanism generating features classify
following categories
pddl features basic features extracted pddl representation domain
files instance number actions objects goals


fit ibac p p lanning ystem

figure general diagram learning performance predictive
fd instantiation features fast downward pre processor instantiates translates
tasks finite domain representation helmert output take
general information number instantiated actions number relevant
facts data specific fd translator number auxiliary atoms
sas features finite domain representation sas associated causal graph
cg set domain transition graphs dtgs cg extract basic properties
e g number variables edges ratios properties regards
dtgs number graphs corresponds number edges cg
makes difficult encode general attributes dtg therefore summarize dtgs characteristics aggregating relevant properties graphs thus
features dtgs statistics maximum average standard
deviation graph properties
heuristic features initial state compute heuristic values set widely used
unit cost heuristic functions e g hmax hff compute heuristics
initial state obtained reasonable cost use unit cost heuristics
obtain domain independent estimation helps characterization size
difficulty
fact balance features relaxed plan rp initial state extracted computing hff heuristic compute set features represent fact balance
rp define fact balance fact p number times p appears added
effect action belonging rp minus number times p deleted effect
action rp considering original actions deletes ignored intuition
behind fact balances high positive values would characterize easier relaxed
given domain since achieved facts need deleted many times given
number relevant facts task variable compute statistics e min max
average variance fact balance relevant facts additionally compute
statistics considering facts goals following procedure


fic enamor de la rosa f ern andez

complete set features listed organized category appendix
data integration process figure receives features performance datasets inputs
produce final dataset according modeling goal dataset classification task
training test instance includes task features plus planner name boolean
feature indicating whether planner solved task dataset regression task
includes cases tasks solved make exclusion
make sense model estimate time beyond given time limit
cases time unknown training test instance regression dataset includes
task features planner name time planner used best solution
feature selection optional process reducing number features used
modeling procedure applied might irrelevant redundant features
could degrade modeling capabilities learning techniques blum langley
outcome process dependent original data thus decision whether apply
taken model evaluation
modeling process use shelf data mining tool provides set learning
classification regression generated evaluated
evaluation process determine best model classification regression tasks
many different ways carrying model evaluation comparison han kamber pei
witten frank reflect generalization ability different
making predictions unseen data
trategy election
strategy selection final step construction ibac p planner selecting strategy implies decide transform predictions best actual
portfolio configuration several alternatives range ignoring model predictions trusting completely classification model candidate planner get
yes prediction given task direct use boolean variable makes difficult
decide planners include portfolio consider instance two extreme cases
planners get positive prediction include planners get
negative prediction planner include portfolio instead boolean
prediction propose rank predictions confidence positive class
make selection planners according ranking planner assigned
slide total time assignment carried uniformly dependently
predictive learned therefore depending use make predictive
propose three basic strategies
equal time et strategy use predictive assign
equal time planner uniform strategy idea behind strategy
planners less time one strategy obtained good
portfolios seipp braun garimort helmert
best n confidence bn strategy include subset n planners best
prediction confidence positive class portfolio get equal time
solving task case idea select subset promising planners
spend time solving task


fit ibac p p lanning ystem

best n estimated time bne subset planners selected mentioned
time assigned proportionally estimated time provided regression model
portfolio configuration
instance configuration portfolio implies subset base planners time
assigned one varies function task features set candidate planners
predictive configuration strategy previously fixed construction phase
shows use components configure portfolio given
task
configuring portfolio particular task
data domain set base planners pini classification model c
regression model r available time strategy sn
portfolio configuration sequence planners assigned runtime
portfolio hp hpc tc
portfolio
sn et
classification regression available
n size pini
p pini
append hp tn portfolio
else
hf tf extractfeatures
pk pini
predictionhpk confk predict c hf pk

sorted candidates sort prediction key conf
p sorted candidates n
sn bn
classification model available applying best n confidence strategy
n
f
append hpi
n portfolio
else
regression model available applying best n estimated time
n
ti predict time r hf pi
scaletime tf
n
append hpi ti portfolio

method receives domain set base planners pini classification model c regression model r time available portfolio configuration
strategy sn et bn bn e procedure calls several functions described


fic enamor de la rosa f ern andez

extractfeatures feature extraction procedure used portfolio construction phase pair domain function outputs set features f
function computes time tf time spent extracting features
predict function query classification model c receives instance
represented tuple hf pi f previously computed features p
planner name function ignore class keep prediction
confidence positive class forming tuple hp conf output represents
confidence planner p solve
predict time function uses model r estimate execution time subset
planners pn pini established best n candidates terms classification confidence classification model function receives input tuple
hf pi
scaletime function transforms vector estimated times another proportional
vector sum fits available time original time bound minus
time used compute features tf thus time assigned planner computed
f
formula tpt
n
ti

output sequence planners assigned time execution
particular configuration portfolio comprises sequential execution base planners
ensuring cpu process exceed assigned time

ibacop system
section describe follow presented section build different
portfolios
candidate planners
initial set planners includes planners sequential satisficing track ipc
plus lpg td gerevini saetti serina although lgp td compete ipc
considered worthwhile include still considered state art planner due
great performance previous competitions
first step apply qt pareto score filtering described subsection reduce
initial set candidate planners benchmarks computing qt pareto score set
domains sequential satisficing track ipc
table shows best planner terms qt pareto score domain additionally
include number solved best planner highlight correlation among
values qt pareto score values closer reflect planner able beat
planners p robe best planner domains however
planners stood one domain reinforces motivation diverse subset
planners finally initial planners qt pareto score filtering pre selected candidate
planners subset planners made lama probe arvand fdss fd autotune fd autotune lamar lama madagascar yahsp mt
lpg td brief description planners found appendix


fit ibac p p lanning ystem

planner
probe
probe
probe
probe
arvand
madagascar
lama
lama
fd autotune
fd autotune
fdss
lamar
yahsp mt
lpg td

domain
scanalyzer
woodworking
tidybot
barman
pegsol
parcprinter
transport
openstacks
sokoban
nomystery
elevators
parking
visitall
floortile

total

qt
















coverage
















table list best planners ordered qt pareto score domain ipc
table shows ranking planners ipc e planner ordering established
quality score linares lopez et al selected qt pareto score
filtering worth noting attention best planners ipc built top
fd reduces diversity planners however qt pareto score filtering
includes addition pointed last three selections qt pareto
score filtering planners lower positions table demonstrated
later increases diversity portfolio performance
ranking















planner
lama
fdss
fdss
fd autotune
roamer
forkuniform
fd autotune
probe
arvand
lama
lamar
yahsp mt
madagascar
lpg td

eligible












fd











table list best planners ordered score ipc third column shows whether
selected qt pareto score filtering forth column shows planners
built top fd



fic enamor de la rosa f ern andez

performance
inputs performance modeling phase candidate planners e candidates
selected previous section benchmark tasks selected purpose next
describe generated training data inputs produce specific instances
ibac p planners
raining data
training data learning process requires set domains used gather
input features need wide range domains generalize future unknown
tasks properly included available ipc onwards mention test set explicitly refer satisficing tracks
competitions included domain
ipc openstacks pathways rovers storage tpp trucks
ipc cybersec elevators openstacks pegsol pipesworld scanalyzer sokoban transport woodworking
ipc barman elevators floortile nomystery visitall tidybot openstacks parcprinter
parking pegsol sokoban scanalyzer transport woodworking
learning track ipc gold miner matching bw n puzzle parking thoughful sokoban
learning track ipc barman blockworld depots gripper parking rovers satellite
spanner tpp
list obtained different domain descriptions although represent
alternative encodings domain included candidate planners run
benchmarks obtain features related performance planners thus used
total tasks performance data comprises instances e planners successful failed proportion instances
solved candidate planner different table appendix c shows per planner summary
performance data
features representing task automatically generated domain
definitions pddl features fd instantiation sas features computed
fast ownward pre processor computation time needed extract features
negligible compared sas translation given compute sums statistics
data provided sas representation heuristic features computed fastd ownward search engine fact balance features generated relaxed
graph structures initial state provided planner hoffmann fastd ownward pre processor could fail instantiating task case regarding
features computed missing values assumed
table shows success rate extracting features type training average maximum time seconds extract pddl fd sas
features extracted fd pre processor success rate
time required compute heuristic features time calculating heuristic value
initial state calculated fd pre process finished successfully


fit ibac p p lanning ystem

class
pddl
fd
sas
heuristic
fact balance
total

success







average







max







features







table summary extracted features average maximum time seconds
extract processes top two first step planners
fd

f eature election
carried feature selection process two main reasons one hand features
might irrelevant whilst others might redundant modeling purpose therefore want
analyze whether possible obtain better subset available features
hand study allow us recognize relevant features characterizing
task
feature selection carried j top induction
build decision trees quinlan selecting features appear top nodes
tree grabczewski jankowski decision trees make implicit feature selection
model includes queries features considered relevant applying feature selection
process feature dataset total number features decreased leads
dataset size reduction around table contains list features resulting
feature selection process selection chooses features categories modeling
evaluation process kept datasets separate one available features f
one selected features f
c lassification odels
trained classifiers classification provided weka witten frank
includes different model types decision trees rules support vector machines
instance learning recall training instances include task features
described section plus planner name boolean feature indicating whether
planner solved task performance predictive evaluated
fold cross validation uniform random permutation training data best
model datasets f f generated rotation forest rodriguez kuncheva
alonso achieving accuracy respectively quite
better default model zeror obtained accuracy see
classification table appendix b
even though good accuracy classification model guarantee good performance
portfolio great starting point selecting promising planners accuracy
feature selection showed small differences compared obtained


fic enamor de la rosa f ern andez

type

pddl


cg dtg


features
types
goal
objects
functions

numbervariablescg
inputedgecgstd
outputedgecgavg
outputweightcgmax
outputweightcgavg
outputedgehvstd
outputweighthvmax
numbervariablesdtg
totaledgesdtg
inputweightdtgmax
hvratio

type

fd


heuristics


balance


features
auxiliary atoms
implied effects removed
translator facts
translator total mutex groups size
num relevant facts
num instance actions
additive
context enhanced additive

goal count
landmark count
landmark cut
max
rp fact balance avg
rp fact balance var
rp goal balance min
rp goal balance avg
rp goal balance var
h ratio

table list features feature selection complete set features listed appendix

features statistically better accuracy f dataset nine
similar accuracy cases best achieved accuracy

r egression odels
trained regression positive instances classification training
phase classification phase planners proportion instances
case planners number instances given solved different
number nevertheless consider relevant bias
include planner name somehow encodes single planner grouped
model trained regression provided weka
best f decision table kohavi relative absolute error
rae best one f bagging breiman rae
nevertheless simplicity selected decision table model regression task
datasets f f decision justified significant
difference test following sections regression model refer
trained decision table see regression
table appendix b


fit ibac p p lanning ystem

ibacop strategies
considered strategies configuration ibac p portfolios list
strategies ordered depending use make knowledge provided predictive
experiments configuration run seconds named
portfolios according names given ipc
ibac p portfolio uses equal time strategy et set candidate planners previously filtered qt pareto score filtering procedure therefore single planners
run seconds strategy use predictive planner
strategy awarded runner sequential satisficing track ipc
ibac p portfolio uses best n confidence strategy bn n means
planners best prediction confidence solving included
configuration run time assigned uniformly planner seconds
strategy f model winner sequential satisficing track ipc
ibac p b e portfolio uses best estimated time strategy bne n follows procedure ibac p select planners time assigned
scaling time prediction provided regression model decision table strategy
participated learning track ipc name libac p case
training data generated domain separately since learning track
provides training set domain priori
addition built portfolio configurations serve baseline comparison
overall equal time oet strategy non informed strategy carry
planner filtering use predictive assigns equal time available planner
given planners participants ipc plus lpg td planner
run seconds planner see need planner filtering since
although already obtains close current state art base planners
improved selecting reduced set planners
best planners b strategy selects top planners ipc ordered score
competition shown table although selecting best planners good
choice intuitively table selection reduces planner diversity
portfolio since top planners competition fd exception probe strategy comparable implemented bus portfolio howe
dahlman hansen scheetz von mayrhauser control strategy ordering planners allocating time derived performance study data
random planners rand strategy one baselines compare best confidence strategy ibac p given task strategy takes random sample
planners population candidate planners selected qt pareto filtering
predictive submitted ibac p ipc trained different benchmark set case
best accuracy achieved random forest breiman



fic enamor de la rosa f ern andez

assigns equal time expect wise selection planners ibac p
average better random selection
default planners def case strategy includes best planners terms
quality score training data planners subset candidate
planners selected qt pareto filtering e lama probe fd autotune
lama fd autotune time assigned equitably want see
whether best planners better making per instance selection planners
implementation details
section describe engineering details incorporated ibac p
planners instance competition rules proposed include domains conditional effects
included parser translates tasks conditional effects
equivalent task without property translator previous translator adl strips hoffmann edelkamp thiebaux englert dos santos liporace trug
specifically implemented compilation creates artificial actions effect evaluations nebel
furthermore many candidate planners built fast ownward framework among things separate process sub process translation
pre processing search indeed translation pre process steps already executed
feature generation given task performed take advantage fact avoid
first two steps repeatedly planners included configuration
portfolio regarding task version compatibility reasons procedure divided
two groups output fd pre process used feature extraction used
search input lama fdss fd autotune previous fd pre processor
used common lama arvand lamar optimization used
strategies evaluated remaining planners totally independent fd pre processing
moreover bugs arose execution ipc issues domain
required updates vallati chrpa mcmcluskey planners updated
mercury vallati chrpa mcmcluskey b issues fixed prior
running experimental evaluation presented article

experimental evaluation
section describe settings experimental evaluation present
planners benchmarks used ipc specifically sequential satisficing
track addition provide analysis diversity planner selection achieved
configurations
experimental settings
evaluated different portfolio strategies described section permits different
portfolio configurations created ibac p ibac p b e run two predictive
model versions one trained features f one trained selected fea version corresponds version used submit planners ipc



fit ibac p p lanning ystem

tures f random strategy run times average reported addition
included jasper ercury planners comparison planners competed ipc ercury domshlak hoffmann katz second best planner
terms ipc score jasper xie muller holte second best planner terms
solved coverage test set used benchmarks ipc
updates described section test set comprises domains
domain
experiments run cluster intel xeon ghz nodes gb ram
linux ubuntu lts planners cutoff seconds gb ram
ibac p configurations requiring feature extraction process limited gb ram
following ipc competition rules seconds maximum time used training
set obtain features described table time extract features included
execution portfolio worse case feature extraction process took seconds
therefore candidate planners run system extract
features time input features treated missing values

table shows evaluated planners ipc quality score recall

score gives ratio q
qi planner qi quality best solution
found planner q best solution found planner planner solve
score

hiking
openstacks
thoughtful
ged
barman
parking
visitall
maintenance
tetris
childsnack
transport
floortile
citycar
cavediving
total

ibacop
f
f

ibacop b
f
f

mercury

jasper

oet

b

def

rand

ibacop




























































































































































































table ibac p configurations table includes jasper mercury
four baseline configurations oet best default random

overall best planner ibac p b e f closely followed ibac p f
difference two configurations negligible configurations predictive
much better oet default best random ibac p good performance comparable best performance moreover big difference


fic enamor de la rosa f ern andez

configurations planners jasper mercury ibac p configurations
points higher cases
figure details evolution number solved function run time
elapsed far right hand point figure represents final coverage best planner
terms coverage ibac p second ibac p f
figure planners two different behaviors one hand asymptotic growing
number solved demonstrates giving time planners permit
number solved increased jasper extreme case seconds
almost unable improve ercury well portfolio configurations
take care diversity however ibac p ibac p ibac p b e
selected diverse set planners growing behavior throughout time










ibacop
ibacop
ibacop b e
random
jasper
default
mercury
best
et
























time

figure comparison ibac p configurations baseline configurations mercury
jasper planners
derive insights regarding different configurations score
difference oet ibac p reveals importance making pre selection candidate
planner accurate filtering procedure pareto dominance allows us
smaller set planners means time per planner trade
time per planner loosing diversity solvers suggest
important maintain diversity increasing running time per planner instance
best ipc planners b obtain worse original oet even
though b base planners longer running time however qt pareto filtering
able reduce number planners sacrificing diversity produces good

reducing number planners portfolio configuration puts risk
diversity solvers shown def best planners terms


fit ibac p p lanning ystem

performance rand random selection planners nevertheless ibac p f
f perform quite better def rand demonstrates classification
select average good subset planners solving particular task quite
promising exploiting empirical performance portfolios however
current setting ibac p quite similar ibac p thus classification
manage reduce set planners without deteriorating performance fixed portfolio
hardly contribute better overall performance
table presents number solved candidate planners final
column maximum number solved complete set candidate
planners e solved least one candidate planners solved
optimal selection planners task would lead
solved ibac p close optimum confirming ability selecting good candidates
portfolio default configuration solved average number
solved random configuration far best possible
value
hiking
thoughtful
openstacks
tetris
ged
transport
parking
barman
maintenance
citycar
visitall
childsnack
floortile
cavediving
total

lama















probe















fda















lama















fda















lamar















arvand















fdss















ya mt















lpg































max







































table candidate planners defined table maximum number
solved complete set planners

set planners selected per instance configuration regression
contribute better performance task estimating run time needed
solve difficult classification task schwefel wegener weinert
additionally given aggregated time predictions could exceed time limit proposal rescales estimations alters real predictions one alternative proposal keep
real prediction run planners order established confidence classification
prediction one reaches time limit however preliminary experiments
development planner showed us compensate risk losing
diversity due fewer planner executions
another aspect analyzed performance planners domains ipc incorporated seven domains means qt pareto filtering predictive
trained domains cave diving child snack citycar


fic enamor de la rosa f ern andez

ged hiking maintenance tetris conclude behavior
ibac p configurations domains average similar performance previously seen
domains
per instance selection planners
previous section showed benefit configuring portfolio per
set selected planners better adjusted fewer planners providing
execution time planner section want analyze diversity planner
selections made ibac p see predictive classifying planners good
solving specific domains identifying properties specific
different domains note test given domain usually range easy hard
increase difficulty mainly due larger size nevertheless increase
affects learning features different scale intensity

lama
probe
fd autotune
lama
fd autotune
lamar
arvand
fdss
yahsp mt
lpg td
madagascar

ita
vis
rt
po
ns
l
tra
tfu
gh
ou
th
tris
te
ng
rki
pa tacks

en
e
op nanc
e
int

ing

hik


ge e
il
ort
flo r

yc
k
cit
ac
sn
ild
ch
ing
div

ca n

rm
ba

figure proportion number times planner selected domain red
dots proportion ibac p f blue dots proportion ibac p
f

figure shows diversity planners according selection made ibac p blue
dots f red dots f x axis shows ipc domains axis lists
candidate planners portfolio use size dots proportional
number times planner selected particular domain e number
planner selected domain five dots one column one domain means
selected portfolio configuration domain however every


fit ibac p p lanning ystem

column five dots reveals use different planner sets different
domain highlight analysis planners selected
least one domain domains selections involve planners
note instance lama best priori confidence solving
sometimes used e selected times floortile times openstacks
furthermore planners low priori probability selected frequently
used domains lpg td floortile
table shows sum number times planner selected maximum number times planner could selected last column reports
average standard deviation number times planner selected
per domain approximations reduced set features

lama
probe
fd autotune
lama
fd autotune
lamar
arvand
fdss
yahsp mt
lpg td
madagascar

f












f












average

























std












table number times candidate planner selected two different classification
f f

addition previous analysis wanted delve underlying mechanism
achieve per instance selection planners recall planners selected
confidence success prediction therefore order achieve different planner sets
domain ranking prediction confidence vary throughout
visualize confirm fact selected tetris domain one
domains ipc shows good diversity selection shown figure domain
simplified version well known tetris game
heatmap success prediction confidences appears figure glance realized general planner higher success rate training time obtains higher confidence
confidence ranking varies throughout different domain another way
read picture darkest squares per column form set selected planners instance lama selected probe selected times hand
madagascar selected lpg td selected times


fic enamor de la rosa f ern andez

lama
probe
fd autotune
lama

score

fd autotune
lamar
arvand
fdss
yahsp mt
lpg td
madagascar






















figure success prediction confidence provided classification model f planner
tetris domain scale goes white confidence
dark blue complete confidence

related work
section summarize relevant portfolio configuration relates
work addition summarize different approaches characterization
tasks cornerstone work predict behavior planners
idea exploiting synergy different solvers improve performance individual ones applied propositional satisfiability sat constraint satisfaction
csp answer set programming asp scope automated
sat area carried extensive importance selecting components
portfolio xu hutter hoos leyton brown select component lindauer hoos hutter schaub b automatically study strategy selection area
includes per instance selections lindauer hoos hutter addition intensive
study solver runtime prediction hutter xu hoos leyton brown including good
characterization satisfiability task fields artificial intelligence csp portfolio configurations machine learning techniques sunny amadini gabbrielli
mauro b empirical amadini gabbrielli mauro example
asp asp solver scheduling hoos kaminski schaub schneider multicriteria optimization provides corresponding asp encodings
report main systems related automated detail
portfolios automated
howe et al describes one first planner portfolios implement system called
bus runs planners whose goal solution shortest period time
achieve run planners portions time circular order one finds
solution portfolio planners sorted following estimation provided linear


fit ibac p p lanning ystem

regression model success run time case use predictive
behavior planners decide order execution however use features
extracted pddl description domain count number actions
number predicates count number objects number predicates
initial conditions number goals bus minimizes expected cost implementing
sequence one works contrast ibac p ibac p stop
assigned time
fast downward stone soup fdss helmert et al fast downward fd
system helmert several versions different tracks fdss
select combine heuristics search configuration combination search
group heuristics training evaluate possible configurations time
limit select set configurations maximizes coverage portfolio presented
ipc sequential satisficing track sort configurations decreasing order
coverage hence beginning likely succeed quickly time limit
component lowest value would still lead portfolio score training phase
however order important since setting communicates quality best solution
found far following one value used improve performance next
setting therefore fdss include configurations within fd framework conversely
ibac p ibac p build portfolio mixture generic planners different styles
techniques indeed fdss one ibac p candidate planners
pbp gerevini et al configures domain specific portfolio portfolio incorporates
macro actions specific knowledge domains incorporation knowledge establishes order subset planners contain macro actions running time assigned
round robin strategy portfolio incorporates seven planners latest version pbp
adds lama see gerevini et al automatic portfolio configuration pbp iba c p aims build different types systems domain optimized portfolio planner
given domain pbp ibac p efficient domain independent planner portfolio
ibac p pbp configuration processes significantly different pbp uses several planners
focus macro actions whilst ibac p uses generic planners execution scheduling
strategy pbp runs selected planners round robin rather sequentially case
ibac p
fast downward cedalion seipp sievers helmert hutter automatically configuring sequential portfolios parametric planner given parametric
planner set training instances selects pair planner time iteratively end
iteration instances current portfolio finds best solution removed
training set stops total run time added configurations
reaches portfolio time limit training set becomes empty configurations generated
smac hutter hoos leyton brown model configurator
remaining training instances cedalion configuration
different configuration per version ibac p different configuration per diversity candidate planner limited ibac p may completely include independent base
planners configuration processes resulting configured portfolios cedalion
fdss
fast downward uniform seipp et al portfolio runs automatically configured fast
downward instantiations sequentially amount time uniform portfolio approaches


fic enamor de la rosa f ern andez

configured automatic parameter tuning framework paramils hutter hoos leytonbrown stutzle fast configurations fast downward system
domains separately runtime configurations found run sequentially
amount time seconds
miplan nunez et al sequential portfolio mixed integer programming
computes portfolio obtains best achievable performance respect selection
training tasks case created sequential portfolio subset
sequential planners fixed times whilst ibac p different configurations per
approximation planner consider portfolios components
contrast ibac p ibac p includes planners appear competitions e
black boxes
features
construction predict performance planners novel idea roberts et
al showed learned planners performance known benchmarks
obtain high accuracy predicting whether planner succeed
use features extracted domain definition main difference
include features sas heuristics initial state
fact balance relaxed plan features come ground instantiation
key differentiate tasks share feature values pddl
level
torchlight hoffmann toolkit allows search space topology analyzed
without actually running search analysis relation topology
delete relaxation heuristics causal graph well dtgs feature extraction
process built top planner hoffmann nebel
recently fawcett et al generated accurately predicting planner run
time exploit large set instance features including many features depicted
section features derived pddl sas representations sat encoding short runs planners features
extracted torchlight hoffmann experimental work indicate
performance generated able produce accurate run time predictions study
empirical performance applied portfolio configurations

conclusion future work
work introduced framework creation configurable portfolios
ibac p first step portfolio creation small number planners maintains
diversity initial planner set qt pareto score filtering train predictive
select promising sub set planners solving particular task
experimental evaluation confirmed great performance ibac p ibac p
ipc summarize lessons learned development current ibac p
portfolios following
really matters generation good portfolio selection diverse set
planners shown qt pareto score filtering reduces set candidate plan

fit ibac p p lanning ystem

ners preserving diversity filtering produces better rankings
coverage quality score
selection smaller sets planners portfolio configuration e g sub set
planners experiments dangerous given portfolio might lose planner diversity
observed situation def random configurations select
planners
portfolio configurations classification able select good subset
planners uniformly distributed time outperformed selection provided
random default selection number planners
estimating runtime solving still difficult reason regression providing additional useful information portfolio construction
current form predictive hardly contribute overall performance
portfolio per instance configurations classification achieve similar performance fixed portfolio running fewer planners
even though current architecture benefits predictive limited
promising good performance ibac p compared baseline
configurations think room direction argument
static portfolio configurations including ibac p limited components fixed
time bound base planner performance upper limit computed miplan
smaller achievable performance dynamic configuration
per instance configuration portfolio strategy could assign different times base planners
future work want study additional features better characterization
tasks computation could carried pre process step even information
first evaluated search nodes could help making predictive accurate
could incorporate information instance landmark graph time elapsed
computing initial state heuristics future work study importance created
features including comparison different groups accordance semantics
features

acknowledgments
thank authors base planners work largely previous effort
work partially supported spanish projects tin c tin c tin c r



fic enamor de la rosa f ern andez

appendix complete feature description
appendix present list features used characterize task
feature include brief description computed features grouped
category separate tables
pddl features
n









name
objects
goals
init
types
actions
predicates
axioms
functions

description
number objects
number goals
number facts initial state
number types domain
number actions domain
number predicates domain
number axioms domain
number functions domain

table pddl features

fd instantiation features
n






name
relevant facts
cost metric
generated rules
relevant atoms
auxiliary atoms



final queue length





total queue pushes
implied
effects
removed
effect preconditions
added
translator variables



derived variables







translator facts
mutex groups
total mutex size
translator operators
total task size




description
number facts marked relevant instantiation
whether action costs used
number created rules translation process create sas task
number relevant atoms found translator process
number auxiliary atoms found translator process
length queue end translation queue auxiliary
list used translation process compute model
number times element pushed queue
number implied effects removed implied effects
translator knows already included
number implied effects added
number created variables sas formulation
number state variables correspond derived predicates
artificial variables directly affected operator applications
number facts pre process takes account
number mutex groups
sum mutex group sizes
number instantiated operators sas formulation
allowed memory translation process

table features extracted console output fd system



fit ibac p p lanning ystem

sas feature description
recall cg high level variables variables defined value
goal although common definition cg consider edges weighted
fd system computes edge weights cg number instantiated actions induced
edge consider weights computing features
n

name






number variables
high level variables
totaledges
totalweight



veratio



weratio



wvratio



hvratio



inputedge



inputweight



outputedge



outputweight



inputedgehv



inputweighthv



outputedgehv



outputweighthv

description
general features
number variables cg
number high level variables
number edges
sum edge weights
cg ratios
ratio total number variables total number
edges ratio shows level connection cg
ratio sum weights number edges
ratio shows average weight edges
ratio sum weights number variables
ratio number high level variables total number variables ratio shows percentage variables involved
goals
statistics cg
maximum average standard deviation number incoming
edges variable
maximum average standard deviation sum weights
incoming edges variable
maximum average standard deviation number outgoing
edges variable
maximum average standard deviation sum weights
incoming edges variable
statistics high level variables
number incoming edges high level variables
value produces three features following computation
inputedgecg features
edge weight sum incoming edges high level
variables value produces three features following
computation inputweightcg
number outgoing edges high level variables
sum weights incoming edges high level variables

table features causal graph



fic enamor de la rosa f ern andez

n

name




number vertices
total edges



total weight



edva ratio



weedratio



wevaratio



input edge



input weight



output edge



output weight

description
general aggregated features dtg
sum number nodes dtgs
sum number edges dtgs
sum edge weights dtgs edge weight dtg
corresponds cost applying action induced edge
dtg ratios
ratio total number edges total numbers
variables ratio shows level connection dtg
ratio sum weights number edges
ratio shows number restrictions need make transition
ratio sum weights number variables
statistics dtgs
maximum average standard deviation number incoming
edges vertex dtg
maximum average standard deviation sum weights
incoming edges nodes
maximum average standard deviation number outgoing
edges vertex dtg
maximum average standard deviation sum weights
outgoing edges nodes

table features aggregate information dtgs



fit ibac p p lanning ystem

heuristic features
n

name



max



landmark cut



landmark
count
goal count







additive



causal graph



contextenhanced
additive

description
bonet loerincs geffner bonet geffner maximum
accumulated costs paths goal propositions relaxed

helmert domshlak sum costs disjunctive action
landmark represents cut justification graph towards goal propositions
richter helmert westphal sum costs minimum
cost achiever unsatisfied required landmark
number unsatisfied goals
hoffmann nebel cost plan reaches goals
relaxed ignores negative interactions
bonet et al bonet geffner sum accumulated costs
paths goal propositions relaxed
helmert cost reaching goal given search state
solving number sub task derived
causal graph
helmert geffner causal graph heuristic modified use pivots
define contexts relevant heuristic computation

table unit cost heuristics included features

fact balance
n

name



rp init



rp goal



ratio

description
minimum average variance number times fact
initial state deleted computation relaxed plan
minimum average variance number times goal
deleted computation relaxed plan
ratio value max heuristic proportion
shows idea parallelization plan

table fact balance features



fic enamor de la rosa f ern andez

b appendix learning
appendix shows detailed machine learning used train predictive
b classification

rules zeror
rules ridor
rules part
rules jrip
rules decisiontable
rules conjunctiverule
trees reptree
trees randomtree
trees randomforest
trees lmt
trees j
trees adtree
trees nbtree
trees decisionstump
lazy lwl
lazy ibk k
lazy ibk k
lazy ibk k
meta rotationforest
meta attributeselectedclassifier
meta classificationviaclustering
meta classificationviaregression
meta bagging
meta multiclassclassifier
functions simplelogistic
functions multilayerperceptron
functions rbfnetwork
functions smo
bayes naivebayes
bayes naivebayesupdateable
bayes bayesnet

f dataset
































f dataset
























































table accuracy standard deviation training fold crossvalidation test omahony two training sets shown
symbols means statistically significant improvement degradation respectively
significance level test baseline left column



fit ibac p p lanning ystem

b regression

trees decisionstump
trees reptree
trees randomtree
trees randomforest
functions p
rules conjunctiverule
rules decisiontable
rules rules
meta bagging
meta additiveregression
lazy ibk
lazy ibk
lazy ibk
lazy kstar
lazy lwl
functions linearregression
functions multilayerperceptron
functions leastmedsq
functions rbfnetwork
functions smoreg

f dataset
rae






















f dataset
rae































table fold cross validation regression rae relative
absolute error correlation coefficient small rae values better
symbols means statistically significant improvement degradation respectively
significance level test baseline left column



fic enamor de la rosa f ern andez

c appendix training

openstacks
pathways
rovers
storage
tpp
trucks
pipesworld
cybersec
openstacks adl
openstacks
pegsol
scanalyzer
sokoban
transport
woodworking
elevators
barman
elevators
floortile
nomystery
openstacks
parcprinter
parking
pegsol
scanalyzer
sokoban
tidybot
transport
visitall
woodworking
gold miner
matching bw
n puzzle
parking
sokoban
thoughtful
barman
blocksworld
depots
gripper
parking
rovers
satellite
spanner
tpp
total

l

probe

fda

l

fda

lamar

arvand

fdss

ya mt

lpg



































































































































































































































































































































































































































































































































































































table solved training phase first part table ipc second part ipc ipc satisficing tracks two last rows
gold miner tpp ipc learning track last column
number included training



fit ibac p p lanning ystem

appendix planners
following list set planners pre selected candidates pareto dominance filtering
described section
arvand nakhost muller valenzano xie stochastic planner uses monte
carlo random walks balance exploration exploitation heuristic search version
uses online learning best configuration parameters given

fast downward autotune fast downward autotune fawcett helmert hoos karpas
roger seipp two instantiations fd system automatically configured performance wide range domains well known paramils
configurator planners use three main types search combination several heuristics
fast downward stone soup helmert et al fdss sequential portfolio
several search heuristics given training benchmarks
best combination heuristics found hill climbing search
information communicated component solvers quality best
solution found far
lama lama richter westphal richter westphal helmert
propositional planner combination landmark count heuristic
heuristic search performs set weighted iteratively decreasing weights
planner developed within fd system helmert
lamar olsen bryce modification lama planner includes randomized construction landmark count heuristic
madagascar rintanen implements several innovations sat including
compact parallelized interleaved search strategies sat heuristics
probe lipovetzky geffner exploits idea wisely constructed lookaheads
probes action sequences computed without searching given state
quickly go deep state space terminating goal failure technique
integrated within standard greedy best first search
yahsp mt vidal extracts information relaxed plan order generate
lookahead states strategy implemented complete best first search
modified take helpful actions account
lpg td gerevini et al stochastic local search space particular
action graphs derived specification

references
amadini r gabbrielli mauro j portfolio approaches constraint optimization
tplp


fic enamor de la rosa f ern andez

amadini r gabbrielli mauro j b sunny lazy portfolio constraint
solving tplp
blum l langley p selection relevant features examples machine learning
artificial intelligence
bonet b geffner h heuristic search recent advances
ai pp springer
bonet b loerincs g geffner h robust fast action selection mechanism
aaai iaai pp
breiman l bagging predictors machine learning
breiman l random forests machine learning
cenamor de la rosa fernandez f mining ipc proceedings
third workshop international competition icaps
cenamor de la rosa fernandez f learning predictive configure portfolios proceedings workshop learning icaps
censor pareto optimality multiobjective applied mathematics optimization
dietterich g ensemble methods machine learning kittler j roli f
eds multiple classifier systems first international workshop mcs cagliari italy
june proceedings vol lecture notes computer science pp
springer
domshlak c hoffmann j katz red black systematic
partial delete relaxation artificial intelligence
fawcett c helmert hoos h karpas e roger g seipp j fd autotune
domain specific configuration fast downward proceedings workshop
learning icaps
fawcett c vallati hutter f hoffmann j hoos h h leyton brown k improved features runtime prediction domain independent planners proceedings
th international conference automated scheduling icaps
gerevini saetti vallati automatically configurable portfolio planner
macro actions pbp proceedings th international conference automated
scheduling icaps
gerevini saetti serina temporal scheduling
domains predictable exogenous events journal artificial intelligence

gerevini saetti vallati automatic portfolio configuration
pbp journal artificial intelligence
ghallab nau traverso p automated theory practice access online
via elsevier
gomes c p selman b portfolios artificial intelligence


fit ibac p p lanning ystem

grabczewski k jankowski n feature selection decision tree criterion proceedings fifth international conference hybrid intelligent systems pp
ieee
han j kamber pei j data mining concepts techniques elsevier
helmert heuristic causal graph analysis proceedings
th international conference automated scheduling icaps vol
pp
helmert fast downward system journal artificial intelligence
helmert concise finite domain representations pddl tasks artificial
intelligence
helmert domshlak c landmarks critical paths abstractions whats difference anyway proceedings th international conference automated
scheduling icaps
helmert geffner h unifying causal graph additive heuristics proceedings th international conference automated scheduling icaps pp
helmert roger g seipp j karpas e hoffmann j keyder e nissim r richter
westphal fast downward stone soup seventh international
competition ipc planner abstracts
hoffmann j metric system translating ignoring delete lists numeric
state variables journal artificial intelligence
hoffmann j analyzing search topology without running search connection
causal graphs h journal artificial intelligence
hoffmann j edelkamp thiebaux englert r dos santos liporace f trug
engineering benchmarks domains used deterministic part ipc
journal artificial intelligence
hoffmann j nebel b system fast plan generation heuristic
search journal artificial intelligence
hoos h kaminski r schaub schneider aspeed asp solver scheduling iclp technical communications
howe e dahlman e hansen c scheetz von mayrhauser exploiting
competitive planner performance biundo fox eds recent advances ai
th european conference ecp durham uk september
proceedings vol lecture notes computer science pp springer
hutter f hoos h h leyton brown k sequential model optimization
general configuration learning intelligent optimization pp
springer
hutter f hoos h h leyton brown k stutzle paramils automatic
configuration framework journal artificial intelligence


fic enamor de la rosa f ern andez

hutter f xu l hoos h leyton brown k runtime prediction methods
evaluation extended abstract yang q wooldridge eds proceedings
twenty fourth international joint conference artificial intelligence ijcai buenos
aires argentina july pp aaai press
kohavi r power decision tables machine learning ecml pp
springer
linares lopez c celorrio j olaya g deterministic part seventh
international competition artificial intelligence
lindauer hoos h h hutter f sequential selection parallel
portfolio selection dhaenens c jourdan l marmion eds learning intelligent optimization th international conference lion lille france january
revised selected papers vol lecture notes computer science pp
springer
lindauer hoos h h hutter f schaub b autofolio automatically configured selector journal artificial intelligence
lipovetzky n geffner h searching plans carefully designed probes
proceedings st international conference automated scheduling
icaps pp
malitsky sabharwal samulowitz h sellmann portfolios
cost sensitive hierarchical clustering proceedings twenty third international
joint conference artificial intelligence pp aaai press
nakhost h muller valenzano r xie f arvand art random walks
seventh international competition ipc planner abstracts
nebel b compilability expressive power propositional formalisms
journal artificial intelligence
nunez borrajo linares lopez c automatic construction optimal static
sequential portfolios ai beyond artificial intelligence
olsen bryce randward lamar randomizing heuristic seventh
international competition ipc planner abstracts
omahony sensory evaluation food statistical methods procedures vol
crc press
quinlan j r c programs machine learning vol morgan kaufmann
richter helmert westphal landmarks revisited aaai vol pp

richter westphal lama planner guiding cost anytime
landmarks journal artificial intelligence
richter westphal helmert lama seventh international
competition ipc planner abstracts
rintanen j madagascar efficient sat seventh international
competition ipc planner abstracts


fit ibac p p lanning ystem

roberts howe learning planner performance artificial intelligence

roberts howe e wilson b desjardins makes planners predictable
proceedings th international conference automated scheduling icaps pp
rodriguez j j kuncheva l alonso c j rotation forest classifier ensemble
method ieee transactions pattern analysis machine intelligence

schwefel h p wegener weinert k advances computational intelligence theory
practice springer science business media
seipp j braun garimort j helmert learning portfolios automatically tuned
planners mccluskey l williams b silva j r bonet b eds proceedings
twenty second international conference automated scheduling icaps
atibaia sao paulo brazil june aaai
seipp j sievers helmert hutter f automatic configuration sequential
portfolios bonet b koenig eds proceedings twenty ninth
aaai conference artificial intelligence january austin texas usa pp
aaai press
vallati guide portfolio multi disciplinary trends artificial
intelligence pp springer
vallati chrpa l kitchin e portfolio state art common
practice open challenges ai communications
vallati chrpa l mcmcluskey l
https helios hud ac uk scommv ipc benchmark html

competition

domains

vallati chrpa l mcmcluskey l b source code erratum deterministic part
https helios hud ac uk scommv ipc errplan html
vidal v yahsp keep simple stupid seventh international competition
ipc planner abstracts
witten h frank e data mining practical machine learning tools techniques
nd edition morgan kaufmann
xie f muller holte r jasper art exploration greedy best first search
planner abstracts ipc
xu l hoos h leyton brown k hydra automatically configuring
portfolio selection proceedings twenty fourth aaai conference artificial
intelligence aaai pp
xu l hutter f hoos h leyton brown k evaluating component solver contributions portfolio selectors theory applications satisfiability
testingsat pp springer
xu l hutter f hoos h h leyton brown k satzilla portfolio
selection sat journal artificial intelligence




