Journal Artificial Intelligence Research 56 (2016) 61-87

Submitted 09/15; published 05/16

Automatic Wordnet Development Low-Resource
Languages using Cross-Lingual WSD
Nasrin Taghizadeh

nsr.taghizadeh@ut.ac.ir

School Electrical Computer Engineering
College Engineering, University Tehran, Tehran, Iran

Hesham Faili

hfaili@ut.ac.ir

School Electrical Computer Engineering
College Engineering, University Tehran, Tehran, Iran

Abstract
Wordnets eective resource natural language processing information
retrieval, especially semantic processing meaning related tasks. far, wordnets
constructed many languages. However, automatic development wordnets low-resource languages well studied. paper, ExpectationMaximization algorithm used create high quality large scale wordnets poorresource languages. proposed method benefits possessing cross-lingual word sense
disambiguation develops wordnet using bi-lingual dictionary monolingual corpus. proposed method executed Persian language
resulting wordnet evaluated several experiments. results show
induced wordnet precision score 90% recall score 35%.

1. Introduction
One important projects natural language processing years
construction English wordnet (WordNet) Princeton University direction George A. Miller (1995). WordNet consists lexical database, English
words grouped sets cognitive synonyms called synsets. eectiveness WordNet wide range language technology applications inspired many researchers create
wordnets languages. first attempts led construction EuroWordNet (Vossen, 1998) BalkaNet (Tufis, Cristea, & Stamou, 2004). EuroWordNet
deals European languages English, Dutch, German, French, Spanish, Italian,
Czech Estonian; BalkaNet covers languages Balkan zone. interconnect wordnets dierent languages, EuroWordNet links synsets language
interlingual index (ILI). ILI allows find equivalent synsets across languages
connected ILI.
Although first wordnet created manually, several automatic semi-automatic
techniques used developing wordnets. methods usually
divided merge expansion approaches (Fellbaum & Vossen, 2012; Oliver & Climent, 2012; Erjavec & Fiser, 2006). However, methods combine merge
expansion models benefit advantages approaches (Prabhu, Desai,
Redkar, Prabhugaonkar, Nagvenkar, & Karmali, 2012; Apidianaki & Sagot, 2014).
merge approach, small wordnet created manually, contains high-level
c
2016
AI Access Foundation. rights reserved.

fiTaghizadeh & Faili

basic concepts. Next, small wordnet developed using automatic semi-automatic
techniques. process, mono-lingual resources language-specific properties
employed. Wordnets created manner later mapped onto either WordNet
ILI. using expansion approach, multilingual wordnet constructed translating words inside synsets WordNet (or existing wordnets) target
language using multi-lingual resources. Therefore structure original wordnet
preserved words translated.
Among dierent methods proposed wordnet construction, applicable low-resource languages. Methods follow merge approach labourintensive time-consuming. Moreover, need vast knowledge language require many resources, main obstacle low-resource languages
- makes approach inapplicable practice. hand, methods
follow expansion approach usually adopt WordNet structure find correct
translation associated words WordNet synsets target language.
process, multilingual resources comparable corpora (Kaji & Watanabe, 2006),
parallel corpora (Oliver & Climent, 2012; Kazakov & Shahid, 2009; Fiser, 2009; Diab, 2004),
thesaurus (Gunawan & Saputra, 2010), machine translators (Saveski & Trajkovski, 2010)
multiple bi-lingual machine readable dictionaries (Atserias, Climent, Farreres, Rigau,
& Rodrguez, 2000; Patanakul & Charnyote, 2005; Bond, Isahara, Kanzaki, & Uchimoto,
2008; Lam, Al Tarouti, & Kalita, 2014) used, causes bottleneck low-resource
languages.
Taking deeper look expansion-based methods, synset WordNet
kept words associated translated target language. bi-lingual
dictionary usually employed English words inside WordNet synsets translated.
Since dictionaries translate word sense word sense, rather word word,
translations ambiguous disambiguated. Looking carefully,
translating English words inside WordNet synset, set candidate words target
language obtained; equivalent senses English words
thus omitted. Methods following expansion approach rank
candidate words omit low-rated ones candidate sets. task scoring
candidate words WordNet synsets considered optimization problem, (sub)optimal values found using algorithms Expectation-Maximization (Montazery
& Faili, 2011). proposed method extension work low-resource languages.
paper, problem automatically constructing large scale high quality
wordnets low-resource languages studied. two major approaches, merge
expansion, first one suitable; requires vast knowledge
target language many language resources. preferred approach utilize wordnets languages adopting structure translating content.
Finding correct senses target language words AI-complete problem (Mallery,
1988), is, analogy NP-completeness complexity theory, problem
whose diculty equivalent solving central problems AI (Navigli, 2009).
paper, iterative optimization method based cross-lingual WSD proposed find
local optimum problem reasonable time. main idea iteratively
improve estimation probability selecting WordNet synsets words
target language. Additionally, proposed method needs resources suitable
62

fiAutomatic Wordnet Development Low-Resource Languages

poor-resource languages. investigate performance proposed method, Persian selected poor-resource language resulting wordnet examined
conducting several experiments.
roadmap paper follows: Section 2 presents related works; Section 3
explains wordnet construction problem proposed formulation; Section 4 presents
case study Persian language error analysis; conclusions given future
works suggested last section, Section 5.

2. Related Work
section, automatic methods constructing wordnets reviewed
based expansion approach. main stage expansion-based methods finding
set words lexicalizes concept captured given synset existing wordnet
another language. candidate words usually extracted dictionary scoring
system utilized find correct words.
work Kaji Watanabe (2006), gloss information WordNet
used automatic construction Japanese wordnet. Given English synset,
calculates score Japanese translation candidates according gloss
appended synset. score defined sum correlations translation candidates associated words appear gloss. pair words
deemed associated amount mutual information predefined threshold. Since availability bi-lingual corpora limited, iterative approach
proposed calculating pair-wise correlations.
Another study creating wordnet automatically expanding WordNet describes
Romanian wordnet. work Barbu Barbu Mititelu (2005), order identify
Romanian words corresponding WordNet synset, several heuristics proposed. According first heuristic, words related synset share common meaning.
Therefore, intersection translations words associated WordNet synsets
considered. second heuristic states synset hypernym share
meaning. Therefore, intersection word translations given WordNet synset
hypernym selected Romanian synset. According third heuristic,
translations domain label selected given WordNet synset.
fourth heuristic, Romanian word selected English translations words based
definition maximum similarity words gloss given synset.
research conducted Patanakul Charnyote (2005), semi-automatic expanding approach presented construct Thai wordnet. Candidates links
Thai words WordNet synsets derived WordNet translations. rank links, 13 criteria used categorized three groups:
monosemic, polysemic, structural criteria. Monosemic criteria focus English words
one meaning assume English words one synset
WordNet. Polysemic criteria focus English words multiple meanings,
believe English words multiple synsets WordNet. Structural criteria
focus structural relations among synsets respect wordnet 1.7.
Another idea creating wordnet use word-aligned parallel corpus n languages, annotate word lexical sense tag consists n-tuple aligned
63

fiTaghizadeh & Faili

words. result, occurrences given word text language L considered
sense, provided tagged multi-lingual synset. However, kind corpus easily available languages. research,
conducted Oliver Climent (2012), two strategies automatic construction
corpora proposed: (i) machine translation sense-tagged corpora, (ii)
automatic sense tagging bi-lingual word-aligned corpora. results Spanish
language showed first strategy works better second. suggests
lexical selection errors made machine translation systems less important
sense tagging errors.
BabelNet project, undertaken Navigli Ponzetto (2010, 2012a),
large multi-lingual semantic network constructed. project, original wordnet
used lexicographic resource well Wikipedia pages dierent languages
encyclopedic knowledge. First mapping English Wikipedia pages
synsets original wordnet established. Given Wikipedia page w
mapping, Babel synset created using wordnet synset s, page w, inter-language
links, translation w languages. project, coverage
resulting network analyzed comparing gold-standard wordnets
terms synset coverage, word coverage, synset extra coverage. results show
synset coverage varies dierent languages 52% Italian 86% French.
work Bond Foster (2013), open multi-lingual wordnet
eighty languages developed. project, common interface accessing multiple
wordnets created gathering existing freely available wordnets dierent languages automatically linking WordNet. Next, wordnets extended
using Unicode Common Locale Data Repository (UCLDR) Wiktionary. rank
candidate links WordNet synsets Wiktionary, several similarity measures
employed. results show precision score 85%-99% measured sense.
Arabic wordnet created follows EuroWordNet methodology manually
encoding set base concepts maximizing compatibility across Arabic English
wordnets (Black, Elkateb, & Vossen, 2006; Elkateb, Black, Rodrguez, Alkhalifa, Vossen,
Pease, & Fellbaum, 2006). Next, project, performed Rodrquez et al.
(2008), machine learning algorithm employed extending Arabic wordnet
augmenting formal specification senses synsets. order associate Arabic
words WordNet synsets, Bayesian network four layers proposed. Four
layers respectively represent: Arabic words; corresponding English translation
Arabic words first layer; synsets English words second layer;
WordNet synsets linked synsets layer three. set candidates word-synset
built pairs <x, y>, x Arabic word WordNet synset third
layer Bayesian network non-null probability path
x y. score link calculated posterior probability y, given
evidence provided network. tuples score threshold selected
inclusion final set candidates word-synset. best results method
proposed study noted score 71% precision.
work Boudabous et al. (2013), Arabic wordnet enriched via adding
semantic relations synsets. method consisted two main phases; first
phase consisted defining morpho-lexical patterns using study corpora extracted
64

fiAutomatic Wordnet Development Low-Resource Languages

Arabic Wikipedia. second phase consisted using morpho-lexical patterns, defined
previous phase, order extract new semantic relations Arabic Wikipedia.
Extracted relations validated, added Arabic wordnet data base.
Piasecki et al. (2011) proposed algorithm automatically expanding Polish
wordnet. method uses heterogeneous knowledge sources, extracted
large corpus, combines based weighted voting scheme. method extracts
potential instances lexicon-semantic relations corpus measures semantic
similarity lexical units. analyzes eect using dierent knowledge resources
performance algorithm. Due high accuracy results, approach
said good basis semi-automatic methods constructing wordnets using
human knowledge correct output automatic approaches.
Lam et al. (2014) proposed automatic method constructing wordnet synsets
uses publicly available wordnets, machine translator bi-lingual dictionaries.
purpose, synset existing wordnet translated target language,
ranking method applied resulting translation candidates find best
translations. generate candidate synsets, three approaches proposed; first one
directly translates synsets WordNet target language. second one uses intermediate wordnets handle ambiguities synset translations. case dictionaries
available, addition wordnets intermediate languages, third approach
used. experimental results showed resulting wordnets coverage
19%, 65%, 37%, 21% 83% Karbi, Arabic, Assamese, Dimasa Vietnamese
languages, respectively.
project, conducted Hasanuzzaman et al. (2014), method
constructing Tempo-wordnet suggested. According method, WordNet
augmented temporal information following two-step process: first
step, synsets WordNet classified atemporal temporal. Next, synsets
associated past, present future probabilities. obtained Tempo-wordnet
used time-related applications.
work Shamsfard (2008), semi-automated method proposed developing Persian lexical ontology called FarsNet. 1,500 verbs 1,500 nouns
gathered manually make wordnets core. that, two heuristics Word Sense
Disambiguation (WSD) method used find likely related Persian synsets.
practical evaluation proposed automatic method used studt shows score
70% correctness covers 6,500 entries WordNet. extension work
(Shamsfard, Hesabi, Fadaei, Mansoory, Famian, Bagherbeigi, Fekri, Monshizadeh, & Assi,
2010a), known first published Persian wordnet, FarsNet, contains
18,000 Persian words covers 6,500 WordNet synsets.
research, performed Montazery Faili (2010), automatic
approach Persian wordnet construction based WordNet introduced.
proposed approach uses two mono-lingual corpora English Persian, bilingual dictionary order construct mapping WordNet synsets Persian
words using two dierent methods; links selected directly using heuristics
recognize links unambiguous. types links ambiguous,
scoring method used select appropriate synset. practical evaluation links
500 randomly selected Persian words shows 76.4% quality terms accuracy.
65

fiTaghizadeh & Faili

augmenting Persian wordnet unambiguous words, total accuracy
automatically extracted Persian wordnet becomes 82.6%.

3. Iterative Method Wordnet Construction
construct multi-lingual wordnet, several methods presented; however,
paid attention low-resource languages. Creating wordnet scratch
languages time-consuming expensive process. Instead, new wordnets could
developed adopting structure existing wordnets languages (usually WordNet) translating words associated synsets target language. One
important advantage approach resulting wordnet aligned WordNet ILI, thus interesting contrastive semantic analysis particularly
useful multi-lingual tasks multi-lingual information retrieval (Dini, Peters, Liebwald, Schweighofer, Mommers, & Voermans, 2005; Otegi, Arregi, Ansa, & Agirre, 2015)
multi-lingual semantic web (Buitelaar & Cimiano, 2014). main assumption
one develop wordnet using expansion approach concepts
semantic relations common among dierent languages. Therefore, language-specific
concepts relations may covered resulting wordnet.
general, regardless approach taken, main step toward constructing
complete wordnet generate synonym sets. section, automatic method
extracting synsets languages limited resources proposed. proposed method
follows expansion approach; start, wordnet initialized WordNet synsets.
every WordNet synset s, translations English words inside extracted bilingual dictionary links translation words WordNet synsets established.
Since dictionaries translate word word, word sense word sense, translations
ambiguous. Therefore, task score links find incorrect ones. consider
scores probability selecting candidate synset word target
language.
paper, task finding correct translation words associated
WordNet synsets regarded optimization problem. sensed-tagged corpus similar
English SemCor (Landes, Leacock, & Tengi, 1998) exists target language,
problem creating wordnet converted maximum likelihood estimation (MLE).
English SemCor corpus sense-tagged corpus created Princeton University
wordnet project research team. corpus consists subset Brown Corpus
contains 700,000 words. SemCor words POS tagged
200,000 content words sense-tagged reference WordNet lexical database.
Since resources may exist, use word sense disambiguation method find
correct sense word raw corpus. shown research, conducted
Mallery (1988), WSD AI-complete problem whose diculty equivalent solving
central problems AI. class problems analogous NP-complete problems
complexity theory, classified dicult problems. proposed
idea use iterative algorithm finds local optima problem
iterations reasonable time. work regarded extension work
performed Montazery Faili (2011). proposed method adopts
66

fiAutomatic Wordnet Development Low-Resource Languages

Mono-lingual
corpus

extract
unique words

Bi-lingual
Dictionary

w

extract English
translations

WordNet

(w, e)

extract
WordNet
synsets

(w, s)

EM algorithm
(w, s, p)

Synsets
target
language

deleting
low-rated links

Figure 1: overview proposed approach constructing wordnet

work low-resource languages; method additionally attempts solve major
drawbacks.
idea proposed work Montazery Faili (2011) wordnet construction,
use bi-lingual dictionary well raw-corpus. First, Farsi word
corpus, translations extracted bi-lingual dictionary. Next, synsets
English translations considered candidate synsets Farsi word.
score calculated pair Farsi words WordNet synsets using expectationmaximization (EM) algorithm. expectation step, use relative-based WSD
method (PMI), co-occurrence frequency pairs words Farsi language
used disambiguate words corpus. Experimental results showed
precision method varies dierent POS tags. highest precision shown
adjectives 89.7%; next adverbs, 65.6%; lowest precision
nouns 61.6%.
major drawbacks method calculating co-occurrence pair words target language usually requires large corpus, may
easily found low-resource languages; important quality
resulting wordnet highly depends co-occurrence values. result, propose
change expectation step PMI-based algorithm WSD procedure
performed without needing additional corpus language resources. Figure 1
represents overview proposed method. Next, experimental analysis,
re-implement work baseline compare proposed method it.
EM iterative algorithm finding maximum likelihood parameters statistical model cases equations cannot directly solved. models typically
consist latent variables addition unknown parameters known data observations.
is, either missing values among data, model formulated
simply assuming existence additional unobserved data points. basic
idea EM follows:
1. actual sucient statistics data, compute parameter
values maximize likelihood data. problem learning
probabilistic model complete data.
67

fiTaghizadeh & Faili

Maximization Step

initial values

Parameters w,s

sense-tagged corpus

Expectation Step

Figure 2: Expectation-Maximization algorithm wordnet construction
2. actually succeed learning model parameters, could compute
probability distribution values missing attributes.
case problem, EM algorithm find probability mapping
word target language candidate synsets. candidate synset represents
correct sense word target language, expected sense occurs
corpus containing word. observed data words corpus target
language; unseen part data WordNet sense tag words.
Th EM algorithm switches two stages: 1) finding approximate distribution
missing data given parameters; 2) finding better parameters given approximation. first step known expectation E-step, second step
called maximization M-step. Figure 2 represents overview EM algorithm
used learning words connected WordNet synsets. Next, details step
proposed algorithm presented.
3.1 E-Step
Similar work Montazery Faili (2011), word target language,
w, WordNet synset, s, w,s defined probability choosing WordNet
synset word w, P (s|w). words, number times word w appears
large corpus sense divided total number appearance w. is:
w, :
w :

w,s [0, 1].


w,s = 1.

(1)

(2)



step, current values parameters w,s used label corpus sense
tags. word w appearing corpus, appropriate sense among candidate
WordNet synsets chosen. task, unsupervised cross-lingual word
sense disambiguation (WSD) could employed. WSD algorithms aim resolve word
ambiguity without use annotated corpora. Unsupervised WSD well-studied task
literature. Among these, two categories knowledge-based algorithms gained
popularity: overlap- graph-based methods. former owns success simple
intuition underlies family algorithms, diusion latter started
growing development semantic networks (Basile, Caputo, & Semeraro, 2014).
68

fiAutomatic Wordnet Development Low-Resource Languages

Within graph-based framework WSD, graph built lexical knowledge
base (usually WordNet) representing possible senses word sequence
disambiguated. Graph nodes correspond word senses, whereas edges represent dependencies senses. dependencies include hypernymy, synonymy, antonymy, etc.
Next, graph structure analyzed determine importance node. Finding
right sense word sequence amounts identifying important
node among set graph nodes representing candidate senses. main challenge
graph-based WSD methods create graph, especially dependencies
chosen graphs edges, connectivity measure used
score nodes graph.
research, conducted Navigli Lapata (2010), comprehensive
study unsupervised graph-based WSD conducted. evaluated wide range
local global measures graph connectivity aim isolating
particularly suited task. Local measures include degree, page-rank, HITS, KPP
betweenness, whereas global measures consist compactness, graph entropy, edge
density. results indicate local measures yield better performance global
ones. best local measures Degree PageRank.
task wordnet development, adapt graph-based WSD method presented
work Navigli Lapata (2010), problem sense labelling corpus
using current parameters w,s . assumed true sense word
corpus determined senses words sentence. every sentence
corpus, following procedure executed:
word w sentence, candidate WordNet synsets picked, one
terminal node synset graph created. set terminal nodes
called Vw .
terminal node v, depth-first search (DFS) WordNet graph performed. Every time node v Vw (w = w ) along path length L encountered,
intermediate nodes edges path v v added graph. L
parameter algorithm usually takes small values 3, 4 5.
Terminal nodes graph scored according degree follows: node
v Vw ,
deg(v)
C(v) =
,
(3)
maxuVw (deg(u))
deg(v) number edges terminating v graph G = (V, E):
deg(v) = |{(u, v) E : u, v V }|,

(4)

Relations chosen graphs edges consist lexical semantic relations
defined WordNet addition gloss relation. pair synsets connected
via gloss relation unambiguous word w occurs gloss s. word
w must unambiguous; otherwise, connected appropriate
sense w (Navigli & Lapata, 2010). use gloss relation WSD procedure, sense
disambiguated glosses WordNet utilized (Semantically Tagged glosses, 2016),
69

fiTaghizadeh & Faili

word forms glosses WordNets synsets manually linked contextappropriate sense WordNet. Therefore, gloss relation established ,
appears correct sense word gloss .
time complexity calculating degree measure less PageRank,
performance shown better; last step WSD procedure,
degree measure preferred scoring nodes graph. illustrate steps
WSD procedure, provide example next section.
3.1.1 WSD Persian Sentence
order better understand WSD procedure, example presented. Consider following Persian sentence means Workers thirty years service become retired.

.

|{z}
punc

JPA


J PAK
AK. @Y
g K . @X
. IY
YK
| {z } | {z } | {z } | {z } |{z} |{z} | {z } |{z} | {z }
verb

adj

noun

noun noun num

noun

prep

noun

Preposition, number punctuation tags involved wordnet
/retired sentence. According Aryanignored. Consider word J PAK
.
pour dictionary, word three translations: emeritus; pensionary; retired. According
wordnet 3.0: first translation one noun synset one adjective synset;
second one two noun synsets; third one eleven verb synsets one
adjective synset. Since word noun adjective Persian corpus, verb
synsets ignored. definitions synsets follows:
{10051861} (noun.person) emeritus#1 (a professor minister retired
assigned duties)
{01645490} (adj.all) emeritus#1 (honorably retired assigned duties retaining title along additional title emeritus professor emeritus)
{10414612} (noun.person) pensioner#1, pensionary#1 (the beneficiary pension
fund)
{10176913} (noun.person) hireling#1, pensionary#2 (a person works
money)
{00035368} (adj.all) retired#1 (no longer active work profession)



. /retired consists five
Therefore, candidate set Persian word J PAK
synsets. general, synsets could correct sense sentence.
However, POS tag word given sentence come aid
WSD procedure order filter synsets. Indeed WSD procedure,
70

fiAutomatic Wordnet Development Low-Resource Languages

Table 1: Persian words candidate synsets.
Persian word


YJPA

@X

K .

g
IY

J PAK
.

POS
noun
noun
noun
noun

noun
adjective
verb

Translations
employee,
worker,
member
relieve, own,
year
background,
antecedent,
history,
record, service
work, job, activity,
profession
retired, emeritus,
wind, grow, lapse,
branch, become,

candidate synsets

selected synset

correct

10

workern1

3

1
4
40

have1n
yearn1
record1n

3
3
7

30

job1n

3

2
42

retired1a
growv3

3
7

synsets POS given POS sentence involved.
/retired adjective POS sentence, adjective
Since word J PAK
.
synsets involved graphs construction. Following steps
words sentence leads finding candidate synsets word
accounted WSD graph. Table 1 represents Persian words, translations,
number candidate synsets regarding POS tag Persian words.
candidate synsets represent terminal nodes WSD graph. Figure 3 shows,
candidate synsets Persian word given sentence grouped dotted
box.
next step, DFS algorithm run terminal node WordNet graph
length three. Upon finding path one terminal node another,
intermediate nodes edges added WSD graph. Part WSD graph
shown Figure 3. word graph associated POS, denoted
subscript: n stands noun, v verb, adjective, r adverb. superscript
denotes sense number associated word WordNet 3.0. graph three


/become A/year
separate components; one component word K
component remaining words. means word given sentence indicates
sense words.
construction WSD graph, correct sense Persian word
determined. this, synset degree among candidate set
/retired;
word chosen correct synset word. Consider word J PAK
.
1
WSD graph Figure 3, node retireda degree one; whereas node
emeritus1a degree zero. selected sense word retired1a . Using
degree measure, selected sense word given sentence determined,
represented bold box. Table 1 summarizes steps taken WSD procedure
given sentence. last column shows, selected sense words

/become.
correct except K. A/background
71

fiTaghizadeh & Faili

.
J PAK
retired1a

workn3

workn1

record1n

move2n

wind3n

historyn2
photographyn1

unf ortunate1n

grown3

ancendent1n
relative1n

job10
n
job6n

wind1n

be1n

...

processorn1

have1n

wind2n

person1n

job7n

employee1n
...

...

decade1n

yearn1

period1n

yearn3

season1n

yearn2



workern1


YJPA

job1n

...


@X

g
IY

activityn1

traveln1



YK

occupation1n employment2n

service5n

K .

prof ession1n

emeritus1a

...


JPA
.

J PAK
g K . @X
AK. @Y
. IY
Figure 3: Part WSD graph sentence YK
3.2 M-Step
maximization step, new estimation models parameters calculated
based sense-tagged corpus resulted expectation step. Similar
work Montazery Faili (2011), iteration j, new value parameter w,s ,
denotes probability assigning sense tag word w, equal averaging
conditional probability P (s|j1 ) dierent occurrences w corpus, j1
set parameters w,s iteration j 1. formal notation,
n
P (si |w1n , j1 )
i=1
w
=w,s
=s


j
w,s
=
,
(5)
N (w)
j
w,s
denotes value w,s iteration j, w1n presents sequence corpus words
N (w) number occurrence w w1n .
iteration EM algorithm, likelihood data given new parameter
values least great likelihood given old ones. EM behaves similar
gradient descent; step, adjusts parameter values improve
likelihood data. follows EM converges set parameter values
locally maximizes likelihood.
proposed EM method repeated changes probability selecting
candidate synset word target language becomes negligible. So, end
iteration, maximum change probabilities computed. value less
t, algorithm stops. execution EM algorithm, links score
threshold tremove (w,s tremove ) deleted wordnet.

72

fiAutomatic Wordnet Development Low-Resource Languages



. /retired per iteration.
Table 2: Assigned probabilities word J PAK
Synset ID
Noun:10051861
Adjective:01645490
Noun:10414612
Noun:10176913
Adjective:00035368
Entropy

Correct
7
7
7
7
3

Itr #0
0.2
0.2
0.2
0.2
0.2
2.1502

Itr #1
0.11111
0.29885
0.11111
0.11111
0.36781
1.8340

Itr # 2
0.11111
0.08315
0.11111
0.11111
0.58350
1.7880

Itr #3
0.11111
0
0.11111
0.11111
0.66666
1.7797

Itr #4
0.11111
0
0.11111
0.11111
0.66666
1.7781

Itr #5
0.11111
0
0.11111
0.11111
0.66666
1.7768

iteration, links current score ignored corresponding senses
presented graphs construction WSD procedure. end,
words target language mapped onto synset WordNet make
synsets resulting wordnet.
better follow process updating probabilities word per iteration,
example presented here. demonstrating probability adjustment iteration,
/retired. expectation step, words corpus
consider word J PAK
.
disambiguated. Next maximization step, new value probabilities

computed. Table 2 represents probabilities synsets assigned word J PAK
.
/retired iteration. first second columns show synset ID
correction synsets specified word, respectively. following columns represent
probability values first five iterations. Values less 0.005 considered
0. table shows probabilities start uniformly; iteration,
probability correct synsets increases probability incorrect synsets
frequent enough corpus decreases change. Indeed,
/retired corpus, tagged
number occurrences word J PAK
.
specific WordNet sense iteration iteration 1, probability
/retired change iteration i.
sense given word J PAK
.
value becomes greater, probability increases value becomes smaller,
probability decreases. particular example, five iterations, synset achieving
highest probability correct synset. iteration three, probability word
. /retired assigned second synset goes 3.9E-7,
J PAK
threshold. next iterations, synset considered WSD procedure
probability zero. last row table presents entropy value
respect iteration. steady decrease entropy indicates iteration,
distinction candidates synsets word becomes clear, leads
identification correct synsets. subject analysis entropy word
per iteration discussed later Section 4.2.1.

4. Case Study: Persian Language
section, proposed method automatic wordnet construction applied
Persian low-resource language. following subsections, experimental setup
evaluation methods described; that, results presented.
73

fiTaghizadeh & Faili

4.1 Experimental Setup Data
section, required resources setup experiments explained1 .
construct wordnet Persian language, Bijankhan Persian corpus2
used. collection gathered daily news common texts,
documents categorized dierent subjects political, cultural on.
Bijankhan contains ten million manually-tagged words tag set containing 550
fine-grained Persian POS tags (Oroumchian, Tasharofi, Amiri, Hojjat, & Raja, 2006).
Although POS tags explicitly used proposed method, get better WSD
results, one use POS tags prune synsets along tags candidate
set word explained Section 3.1.1. result, WSD procedure,
synsets POS tag word corpus taken part. WordNet,
four categories tags included: noun, verb, adverb adjective. Thus words
corpus tags pronoun preposition ignored.
Bijankhan large corpus. low-resource languages may large
corpus. order evaluate behaviour proposed method corpus size
limited, part Bijankhan picked training Persian wordnet.
PMI-based graph-based method conducted using part. part
includes nearly 13% total size corpus. remaining 87% used
testing phase coverage wordnet corpus evaluated.
details coverage analysis presented Section 4.2.4. Also, complete analysis
eect corpus size quality final wordnet presented Section
4.4.
words corpus appear inflected forms may found
dictionary. Therefore beginning proposed algorithm, lemmatizer
used dierent inflected forms words converted base form.
example, plural nouns converted singular form. this, STeP-1 tool
(Shamsfard, Jafari, & Ilbeygi, 2010b) utilized. STeP-1 package set
fundamental tools Persian text processing provides support tokenization, spell
checking, morphological analysis, POS tagging.
Another required resource proposed method bi-lingual machine readable
dictionary. electronic version Aryanpour dictionary3 used extract
English equivalent Bijankhan words. Also, WordNet version 3.0 used
extract synsets English equivalents.
WSD procedure, context word sentence containing word.
depth-first search WSD performed maximum depth 3 similar
work Navigli Ponzetto (2012b). mentioned Section 3.2, probability
WordNet sense given word w less equal t, sense ignored
WSD process EM algorithm. experiments, set = 0.005.

1. source code freely available download http://ece.ut.ac.ir/en/node/940
2. See http://ece.ut.ac.ir/dbrg/bijankhan/
3. See http://www.aryanpour.com

74

fiAutomatic Wordnet Development Low-Resource Languages

Iteration
Entropy

Table 3: Entropy values respect iteration
0
1
2
3
4
5
2.15025 1.83406 1.78804 1.77978 1.77813 1.77680

6
1.77677

4.2 Evaluation Results
section, results evaluation proposed method various experiments
presented.
4.2.1 Convergence Proposed Method
EM algorithm iterates expectation maximization steps,
criteria satisfied. experiment, iteration, entropy synset probabilities per word calculated average entropy words considered.
changing value two consecutive iterations becomes near zero, EM algorithm stops. Formally, entropy probability distribution defined equation
6:
H(w) =



w,s log(w,s ).

(6)



Entropy best understood measure uncertainty, entropy larger
random values. Indeed first, links Persian word equal probability,
maximum entropy granted. iteration, links sink threshold
probability thus probability links increases. expected final
step incorrect links obtain low probability correct links obtain
high probability. Therefore, entropy analysis demonstrate behaviour EM
method changing probabilities. Table 3, entropy values per iteration shown.
iteration 6, changing entropy values reaches predetermined threshold 0.001
EM algorithm stops.
4.2.2 Precision Recall Wordnet
primary goal work construct high quality wordnet low-resource
languages. execution EM algorithm, probability assigning candidate
synset word target language finalized. probabilities sorted
links probability threshold tremove removed final
wordnet. value tremove determines size wordnet aects quality
wordnet. So, experiments conducted used dierent values tremove
including 0.1, 0.05, 0.02, 0.01, 0.005 0.0.
evaluate resulting wordnet, re-implemented PMI-based method (Montazery & Faili, 2011) compared wordnet baseline. experiments,
wordnet referred graph-based wordnet, contrast PMI-based
wordnet. evaluation process, two data sets used: 1) FarsNet 2) Manual judges.
FarsNet semi-manually created wordnet Persian, available two versions;
second release FarsNet contains 36,000 Persian words phrases
organized 20,000 synsets nouns, adjectives, adverbs verbs. FarsNet 2
75

fiTaghizadeh & Faili

inter-lingual relations connect Persian synsets English ones
Princeton wordnet 3.0.
second data set consists subset 1,750 links resulting wordnet,
selected randomly judged manually. link (w, s) given two annotators
decide Persian word w semantically equal WordNet s. ensure
accuracy judges, annotators selected among people native speakers
Persian time learn English professionally. case disagreement two judges, third annotator asked decide link. inter-annotator
agreement 80%, means 80% judgements, two annotators agreed.
Additionally, computed Cohens Kappa coecient (Cohen, 1960), two annotators,
takes account amount agreement could expected occur
chance. Kappa computed follows:
=

po pe
,
1 pe

(7)

po relative observed agreement among annotators, pe hypothetical
probability chance agreement. two annotators, Kappa value 0.55.
general, annotators complete agreement, = 1. agreement
annotators would expected chance (as given pe ), 0.
carrying manual judgements, precision recall resulting wordnet
measured set.
precision resulting wordnet defined number correct links
wordnet exist test data correct links, divided total number links
wordnet exist test data. Also, recall wordnet defined
number correct links wordnet exist test set correct links, divided
total number correct links test set. accuracy wordnet another
measure, defined number correct links wordnet exist
test set plus number incorrect links test set exist wordnet,
divided total number links test set. definitions precision, recall,
accuracy wordnet used BabelNet project (Navigli & Ponzetto,
2010).
Figure 4a Figure 4b represent precision recall PMI-based method
proposed method according FarsNet. shown, precision recall
wordnet better PMI-based method. figures, precision 18%,
seems low wordnet considered reliable resource language.
Additionally, recall 49%. due lack correct links FarsNet.
evaluation resulting wordnet according FarsNet link (w, s) placed
one categories:
Persian word w exist FarsNet. link ignored counted.
Persian word w exists FarsNet; however WordNet synset given it.
link ignored counted.
Persian word w exists FarsNet least one WordNet synset given it.
one WordNet synsets, link counted correct else counted
incorrect.
76

fiAutomatic Wordnet Development Low-Resource Languages

WordNet sense distinctions fine-grained, meaning several WordNet
synsets may mapped onto one synset FarsNet; given
FarsNet. Therefore, correct links wordnet counted incorrect. Figure 4c
shows accuracy wordnets according FarsNet, shows graph-based
wordnet surpasses PMI-based wordnet.
reasons low precision according FarsNet follows:
Translations Persian words inaccurate incomplete, meaning
correct WordNet synset according FarsNet exist candidate set.
J/motaalleqAt/possession, three equivalent
example, Persian word HA
English words written Aryanpour dictionary: Appurtenance, Paraphernalia,
J/possession determined
Belongings. wordnet, correct synsets HA
follows: {13244109} (noun.possession), property#1, belongings#1, holding#2
(something owned; tangible intangible possession owned someone;
hat property; man property). However according FarsNet,
correct synset {00032613} (noun.Tops) possession#2 (anything owned
J/possession synset Noun-02671421
possessed). evaluation, link HA
considered incorrect penalized.
Persian word lemmatized correctly; English translations consequently candidate set contain correct synset. example, Persian
word @P K. /bArAk/Barak proper noun, stemmer recognizes PA K.
/bAr/load stem, means load.
resolve problems, set manually judged links used second
experiment. Figure 5 represents precision recall resulting wordnet dierent
values tremove according manual judges. Parameter tremove demonstrates threshold,
links score lower deleted final wordnet. High
values tremove result wordnet high precision low recall. hand,
low values tremove cause low precision high recall wordnet. Thus trade-o
precision recall. tremove = 0.1, precision PMI-based wordnet
86%, precision wordnet created proposed method 90% according
manual judges. tremove = 0, means links contained final
wordnet, precision 74%. Therefore, initial wordnet seen without executing
EM algorithm 74% precision. Figures 4d 5c show another quality measure
wordnets, F -measure. Definition F -measure complete analysis
presented Section 4.3.
4.2.3 Size Polysemy Rate Wordnet
One important aspects wordnets size. Large wordnets may tens
thousands sysnsets (Miller, 1995; Patanakul & Charnyote, 2005; Black et al., 2006;
Piasecki et al., 2011). hand, wordnets polysemic words
useful NLP IR tasks. Polysemic words words one
sense wordnet. Finding correct sense polysemic words great significance
automatic wordnet construction.
77

fiTaghizadeh & Faili

Graph-based
PMI-based

0.15

Recall

Precision

0.8

0.6

Graph-based
PMI-based

0.1
0

2 102 4 102 6 102 8 102

0.4

0.1

0

2 102 4 102 6 102 8 102

tremove

0.1

tremove

(a) Precision

(b) Recall

0.8

F1

Accuracy

0.25
0.7
0.6
Graph-based
PMI-based

0.5
0

2 102 4 102 6 102 8 102

0.2
Graph-based
PMI-based

0.15

0.1

0

2 102 4 102 6 102 8 102

tremove

0.1

tremove

(c) Accuracy

(d) F-measure

Figure 4: Comparison wordnets according FarsNet.
0.8

Recall

0.85
Graph-based
PMI-based

0.8
0

2 102 4 102 6 102 8 102

Graph-based
PMI-based

0.6

0.4

0.1

0

2 102 4 102 6 102 8 102

tremove

tremove

(a) Precision

(b) Recall
0.8

Graph-based
PMI-based

0.7
F1

Precision

0.9

0.6
0.5
0

2 102 4 102 6 102 8 102

0.1

tremove

(c) F-measure

Figure 5: Comparison wordnets according manual judges.
78

0.1

fiAutomatic Wordnet Development Low-Resource Languages

Table 4: Comparison size wordnets

Threshold
0.1
0.05
0.02
0.01
0.005
0

PMI-based wordnet
unique words word-synset polysemy
11,880
27,358
0.63
11,969
36,922
0.71
11,974
49,070
0.76
11,974
58,874
0.78
11,974
71,761
0.80
11,974
141,103
0.85

Graph-based wordnet
unique words word-synset polysemy
11,899
29,944
0.73
11,972
43,690
0.79
11,972
61,823
0.80
11,972
74,619
0.80
11,972
86,879
0.83
11,972
141,103
0.85

section, size resulting wordnet polysemy rate two wordnets,
PMI-based graph-based wordnets, reported. Table 4 presents number unique
words, number Persian word-WordNet synset links proportion polysemic words based dierent values tremove . tremove decreases 0.1 0.01,
unique words contained wordnets, number word-synset links increases,
proportion polysemic words unique words wordnet increases.
seen, wordnet created result graph-based method surpasses PMI-based
wordnet.
links included wordnet, polysemic words 85% unique
words. However, wordnet, removing links probability less
0.1, 73% words polysemic, 10% better PMI-base wordnet.
tremove = 0.1, wordnets 12,000 unique words. Since methods
executed corpus, significant dierence sizes.
4.2.4 Coverage Wordnet
evaluate coverage resulting wordnet, interested observing coverage
WordNet synsets coverage language words. section, three
experiments performed: 1) core concepts coverage, 2) WordNet synset coverage,
3) corpus coverage.
first experiment, coverage wordnet core synsets evaluated. BoydGraber et al. (2006) published list 5,000 word-senses WordNet 3.0,
contains 5,000 frequently used word-senses (Core WordNet, 2015). Coverage
wordnet list regarded covering common concepts
language. core wordnet used measure percentage synsets list
covered PMI-based graph-based wordnets. Figure 6a represents core coverage
dierent values tremove . Selecting links, (tremove = 0), causes coverage 88%
core wordnet, choosing links probable 0.1, leads coverage
53% 34% core wordnet graph-based PMI-based wordnets, respectively.
second experiment, coverage wordnets WordNet synsets studied.
Since resulting wordnet multi-lingual wordnet, coverage WordNet
synsets measure quality. Figure 6b represents coverage PMI-based
graph-based wordnets WordNet 3.0 synsets dierent values tremove . figure
shows graph-based wordnet covers WordNet synsets PMI-based wordnet
values tremove . example, selecting links probability higher 0.1,
79

fiGraph-based
PMI-based

0.8
Core Coverage

WordNet synsets Coverage

Taghizadeh & Faili

0.6

0.4
0

2 102 4 102 6 102 8 102

0.1

0.25

Graph-based
PMI-based

0.2
0.15
0.1
2 102 4 102 6 102 8 102

0

tremove

0.1

tremove

(a) Core Coverage

(b) WordNet Coverage

Figure 6: Coverage wordnets core synsets synsets WordNet.
Table 5: Comparison coverage wordnets.

FarsNet
PMI-based wordnet
graph-based wordnet

Coverage Bijankhan (unique words)
3,050
11,523
11,543

graph-based wordnet covers 14% WordNet synsets; PMI-based wordnet
covers 10% WordNet synsets.
third experiment, coverage wordnets Bijankhan corpus evaluated.
Bijankhan large corpus proposed method trained 13% it. rest
corpus used measuring word coverage wordnets. Table 5 demonstrates
number unique words corpus, covered PMI-based graph-based wordnets,
tremove = 0.1. evaluation performed FarsNet baseline
presented Table 5. Although training testing corpus separate,
significance dierence FarsNet EM-based wordnets coverage.
4.3 Parameter Selection
proposed method wordnet construction convergence EM algorithm,
set links words target language synsets source language
obtained. links scored lower threshold tremove removed final
wordnet. previous experiments showed, value tremove aects quality
resulting wordnet. experiments section 4.2.2 illustrated changing tremove
0.005 0.1 positive eect precision negative eect recall
resulting wordnet. Indeed, trade-o precision recall.
question may arise; best value tremove .
section, F -measure used investigate quality wordnet, considering
precision recall. formula F1 follows:
F1 = 2.

precision.recall
,
precision + recall
80

(8)

fiAutomatic Wordnet Development Low-Resource Languages

F1 harmonic mean precision recall. order gain insight
optimum value tremove , F1 resulting wordnet calculated
dierent values tremove . precision recall, F1 calculated
manual judgement FarsNet. Figure 5c shows F1 decreases 77%
50% tremove increases 0.005 0.1 graph-based wordnet according
manual judgement. means precision value important
recall rate precision decreasing higher rate recall
increasing. Therefore, gain precise wordnet, increase tremove ; however,
must accept loosing recall.
hand, Figure 4d shows highest value F1 graph-based
wordnet obtained tremove = 0.1 according FarsNet. fact means
recall value eect F1 precision value. reason dierence
due low precision values obtained evaluation according
FarsNet, reported Section 4.2.2. FarsNet lacks correct mappings
Persian words WordNet synsets. Indeed wordnet construction, precision
final wordnet important recall.
Finally, choosing threshold tremove important eect quality resulting
wordnet. However, matter depends application. applications,
precise wordnet preferential large accurate enough one.
cases, greater values tremove preferential. Although, applications high
recall needed, one choose low values tremove .
4.4 Eect Corpus Size Dictionary
section, eect required resources final wordnet looked at.
proposed method needs bi-lingual dictionary mono-lingual corpus. previous
experiments, Aryanpour dictionary Bijankhan corpus used. Since
Bijankhan large corpus 13% used previous experiments.
investigate eect corpus size quality resulting wordnet, proposed
method executed using four sizes Bijankhan: 5%, 10%, 20% 50%.
Additionally, examine eect dictionary quality final wordnet,
Google translator4 used another experiment instead Aryanpour; resulting
wordnet compared wordnet created using Aryanpour size
Bijankhan. link removal threshold tremove experiments section
0.1. resulting wordnets evaluated precision, recall, accuracy, coverage
WordNet core synsets, coverage synsets WordNet, number
Persian words.
shown Figure 7, size corpus increases 5% 50%
Bijankhan corpus using dictionary, measures increase except precision,
either change changes slightly. result beyond expectation. Indeed, precision resulting wordnet depends precision WSD
procedure depend size corpus. However, new possible senses
words discovered increasing size corpus therefore recall,
accuracy, coverage size wordnet increase growth corpus size.
4. http://translate.google.com/

81

fiTaghizadeh & Faili

Aryanpour dictionary
Google translator
0.5

0.38

0.9

0.89

accuracy

recall

precision

0.36
0.34
0.32

0.48

0.46

0.3
0.28

0.88
5 10

20

5 10

50

20

5 10

50

20

(a) precision

50
size

size

size

(b) recall

(c) accuracy
104

0.56

0.16

1.4

0.52
0.5
0.48
0.46

number words

synset coverage

core coverage

0.54
0.14

0.12

1.2

1

0.1

0.8

0.44
5 10

20

50

5 10

20

size

(d) core coverage

50
size

(e) WordNet synset coverage

5 10

20

50
size

(f) number words

Figure 7: Evaluation resulting wordnet trained dierent sizes Bijankhan.

Figure 7f demonstrates, wordnet least 10,000 words, corpus size
least 10% Bijankhan corpus. Figure 7 illustrates wordnet trained
Aryanpour dictionary excels wordnet derived Google translator.
experiment demonstrates dictionary heavily aects final wordnet even
corpus size. result, small corpus large dictionary results
precise wordnet large corpus small dictionary.
last experiment, proposed method executed using full Bijankhan
corpus Aryanpour dictionary. precision, recall accuracy resulting
wordnet 90%, 41% 52%, respectively. Comparing wordnet, created
using 13% Bijankhan dictionary, recall accuracy increased 6%
3%, accordingly; precision change. wordnet 15,406 Persian
word covers 61% core synsets WordNet. Considering synsets
WordNet, covers 20% them.

5. Conclusion
paper, EM algorithm employed order develop wordnet lowresourced languages. successfully applied unsupervised cross lingual WSD expectation step algorithm. proposed method use features specific
82

fiAutomatic Wordnet Development Low-Resource Languages

target language, used languages generate wordnets.
Resources needed proposed algorithm include bi-lingual dictionary monolingual corpus. proposed method belongs expansion approach creates
multi-lingual wordnet word target language, equivalent synset
WordNet known.
proposed method applied Persian language quality resulting wordnet examined several experiments. precision 18% according
FarsNet 90% according manual judgement. reason dierence
WordNet synsets fine-grained comparison FarsNet synsets,
synsets FarsNet mapped onto one synset WordNet;
however FarsNet provides one two WordNet synsets FrasNet synsets.
problem means correct links resulting wordnet considered
incorrect thus reported precision becomes low. Also, resulting wordnet
contains 12,000 words Persian language using 13% Bijankhan
corpus, several wordnets languages. Additionally, 53% core
synsets 14% synsets WordNet covered. Analysis eects corpus
size dictionary size resulting wordnet showed dictionary size aect
precision wordnet corpus size therefore important use
large-enough dictionaries.

Acknowledgements
research part supported Institute Research Fundamental Sciences
(No. CS1395-4-19).

References
Apidianaki, M., & Sagot, B. (2014). Data-driven synset induction disambiguation
wordnet development. Language Resources Evaluation, 48 (4), 655677.
Atserias, J., Climent, S., Farreres, X., Rigau, G., & Rodrguez, H. (2000). Combining
multiple methods automatic construction multilingual wordnets. Amsterdam
studies theory history linguistic science series 4, 327340.
Barbu, E., & Barbu Mititelu, V. (2005). case study automatic building wordnets.
Proceedings OntoLex 2005- Ontologies Rexical Resources, pp. 8590, Jeju
Island, Korea. Asian Federation Natural Language Processing.
Basile, P., Caputo, A., & Semeraro, G. (2014). enhanced lesk word sense disambiguation
algorithm distributional semantic model. Proceedings COLING 2014,
25th International Conference Computational Linguistics: Technical Papers,
pp. 15911600, Dublin, Ireland. International Committee Computational Linguistics.
Black, W., Elkateb, S., & Vossen, P. (2006). Introducing Arabic wordnet project.
Proceedings Third International WordNet Conference (GWC-06), pp. 295299,
South Jeju Island, Korea. Global WordNet Association.
83

fiTaghizadeh & Faili

Bond, F., & Foster, R. (2013). Linking extending open multilingual wordnet. Proceedings 51st Annual Meeting Association Computational Linguistics,
pp. 13521362, Sofia, Bulgaria. Association Computational Linguistics.
Bond, F., Isahara, H., Kanzaki, K., & Uchimoto, K. (2008). Boot-strapping wordnet using
multiple existing wordnets. Proceedings Sixth International Conference
Language Resources Evaluation (LREC08), pp. 16191624, Marrakech, Morocco.
European Language Resources Association (ELRA).
Boudabous, M. M., Chaaben Kammoun, N., Khedher, N., Belguith, L. H., & Sadat, F.
(2013). Arabic wordnet semantic relations enrichment morpho-lexical patterns. Proceeding 1st International Conference Communications, Signal Processing, Applications (ICCSPA), pp. 16, American University Sharjah,
United Arab Emirates. IEEE.
Boyd-Graber, J., Fellbaum, C., Osherson, D., & Schapire, R. (2006). Adding dense, weighted
connections WordNet. Proceedings third International WordNet Conference (GWC-06), pp. 2935, South Jeju Island, Korea. Global WordNet Association.
Buitelaar, P., & Cimiano, P. (2014). Towards Multilingual Semantic Web. Springer
Berlin Heidelberg.
Cohen, J. (1960). coecient agreement nominal scales. Educational Psychological Measurement, 20 (1), 3746.
Core

WordNet (2015)
core-wordnet.txt.

http://wordnetcode.princeton.edu/standoff-files/

Diab, M. (2004). feasibility bootstrapping Arabic wordnet leveraging parallel
corpora English WordNet. Proceedings Arabic Language Technologies
Resources, Cairo, NEMLAR.
Dini, L., Peters, W., Liebwald, D., Schweighofer, E., Mommers, L., & Voermans, W. (2005).
Cross-lingual legal information retrieval using WordNet architecture. Proceedings
10th international conference Artificial intelligence law (ACAIL), pp.
163167, Bologna, Italy. ACM.
Elkateb, S., Black, W., Rodrguez, H., Alkhalifa, M., Vossen, P., Pease, A., & Fellbaum, C.
(2006). Building wordnet Arabic. Proceedings 5th international conference Language Resources Evaluation (LREC 2006), Genoa, Italy. European
Language Resources Association (ELRA).
Erjavec, T., & Fiser, D. (2006). Building Slovene wordnet. Proceedings 5th International Conference Language Resources Evaluation (LREC 2006), Genoa,
Italy. European Language Resources Association (ELRA).
Fellbaum, C., & Vossen, P. (2012). Challenges multilingual wordnet. Language Resources Evaluation, 46 (2), 313326.
Fiser, D. (2009). Human language technology. Leveraging Parallel Corpora Existing
Wordnets Automatic Construction Slovene Wordnet, pp. 359368. Springer
Berlin Heidelberg.
84

fiAutomatic Wordnet Development Low-Resource Languages

Gunawan, G., & Saputra, A. (2010). Building synsets Indonesian wordnet monolingual lexical resources. Proceedings International Conference Asian Language
Processing (IALP), pp. 297300, Harbin, China. IEEE.
Hasanuzzaman, M., Caen, F., Dias, G., Ferrari, S., & Mathet, Y. (2014). Propagation strategies building temporal ontologies. Proceedings 14rd conference European
Chapter Association Computational Linguistics, pp. 611, Guthenburg, Sweden. Association Computational Linguistics.
Kaji, H., & Watanabe, M. (2006). Automatic construction Japanese wordnet. Proceedings 5th International Conference Language Resources Evaluation
(LREC 2006), Genoa, Italy. European Language Resources Association (ELRA).
Kazakov, D., & Shahid, A. R. (2009). Unsupervised construction multilingual wordnet
parallel corpora. Proceedings Workshop Natural Language Processing
Methods Corpora Translation, Lexicography, Language Learning, pp. 912,
Borovets, Bulgaria. Association Computational Linguistics.
Lam, K. N., Al Tarouti, F., & Kalita, J. (2014). Automatically constructing wordnet synsets.
52nd Annual Meeting Association Computational Linguistics (ACL 2014),
pp. 106111, Baltimore, USA. Association Computational Linguistics.
Landes, S., Leacock, C., & Tengi, R. I. (1998). Building semantic concordances. WordNet:
electronic lexical database, 199 (216), 199216.
Mallery, J. C. (1988). Thinking foreign policy: Finding appropriate role artificially intelligent computers. Ph.D. thesis, MIT Political Science Department.
Miller, G. A. (1995). WordNet: lexical database english. Communications ACM,
38 (11), 3941.
Montazery, M., & Faili, H. (2010). Automatic Persian wordnet construction. Proceedings
23rd International Conference Computational Linguistics: Posters, pp. 846
850, Beijing, China. Association Computational Linguistics.
Montazery, M., & Faili, H. (2011). Unsupervised learning Persian wordnet construction.
Proceedings Recent Advances Natural Language Processing (RANLP), pp.
302308, Hissar, Bulgaria. Association Computational Linguistics.
Navigli, R. (2009). Word sense disambiguation: survey.
(CSUR), 41 (2), 10.

ACM Computing Surveys

Navigli, R., & Lapata, M. (2010). experimental study graph connectivity unsupervised word sense disambiguation. Pattern Analysis Machine Intelligence, IEEE
Transactions on, 32 (4), 678692.
Navigli, R., & Ponzetto, S. P. (2010). BabelNet: Building large multilingual semantic network. Proceedings 48th annual meeting association computational linguistics, pp. 216225, Uppsala, Sweden. Association Computational
Linguistics.
Navigli, R., & Ponzetto, S. P. (2012a). BabelNet: automatic construction, evaluation
application wide-coverage multilingual semantic network. Artificial Intelligence, 193, 217250.
85

fiTaghizadeh & Faili

Navigli, R., & Ponzetto, S. P. (2012b). Multilingual WSD lines code:
BabelNet API. Proceedings 50th Annual Meeting Association Computational Linguistics (ACL 2012), pp. 6772, Jeju, Republic Korea. Association
Computational Linguistics.
Oliver, A., & Climent, S. (2012). Parallel corpora wordnet construction: machine translation vs. automatic sense tagging. Proceedings 13th International Conference
Intelligent Text Processing Computational Linguistics, pp. 110121, New Delhi,
India. Springer.
Oroumchian, F., Tasharofi, S., Amiri, H., Hojjat, H., & Raja, F. (2006). Creating feasible
corpus Persian POS tagging. Tech. rep. TR3/06, University Wollongong, Dubai.
Otegi, A., Arregi, X., Ansa, O., & Agirre, E. (2015). Using knowledge-based relatedness
information retrieval. Knowledge Information Systems, 44 (3), 689718.
Patanakul, S., & Charnyote, P. (2005). Construction Thai wordnet lexical database
machine readable dictionary. Conference Proceedings: tenth Machine
Translation Summit, pp. 8792, Phuket, Thailand. Language Technology World.
Piasecki, M., Kurc, R., & Broda, B. (2011). Heterogeneous knowledge sources graph-based
expansion Polish wordnet. Intelligent Information Database Systems,
Vol. 6591, pp. 307316. Springer.
Prabhu, V., Desai, S., Redkar, H., Prabhugaonkar, N., Nagvenkar, A., & Karmali, R. (2012).
ecient database design IndoWordNet development using hybrid approach.
Proceedings 3rd Workshop South Southeast Asian Natural Language
Processing (SANLP), pp. 229236, Mumbai, India. International Committee Computational Linguistics.
Rodrquez, H., Farwell, D., Ferreres, J., Bertran, M., Alkhalifa, M., & Mart, M. A.
(2008). Arabic wordnet: Semi-automatic extensions using Bayesian inference.
Proceedings Sixth International Conference Language Resources Evaluation (LREC08), Marrakech, Morocco. European Language Resources Association
(ELRA).
Saveski, M., & Trajkovski, I. (2010). Automatic construction wordnets using machine translation language modeling. Proceedings 13th International
Multiconference, pp. 7883, Ljubljana, Slovenia. Information Society.
Semantically Tagged glosses (2016) http://wordnet.princeton.edu/glosstag.shtml.
Shamsfard, M. (2008). Towards semi automatic construction lexical ontology Persian. Proceedings 6th International Conference Language Resources
Evaluation (LREC 2008), Marrakech, Morocco. European Language Resources Association (ELRA).
Shamsfard, M., Hesabi, A., Fadaei, H., Mansoory, N., Famian, A., Bagherbeigi, S., Fekri, E.,
Monshizadeh, M., & Assi, S. M. (2010a). Semi automatic development FarsNet;
Persian wordnet. Proceedings 5th Global WordNet Conference, Mumbai, India.
Global WordNet Association.
86

fiAutomatic Wordnet Development Low-Resource Languages

Shamsfard, M., Jafari, H. S., & Ilbeygi, M. (2010b). STeP-1: set fundamental tools
Persian text processing. Proceedings 7th International Conference Language Resources Evaluation (LREC 2010), Valletta, Malta. European Language
Resources Association (ELRA).
Tufis, D., Cristea, D., & Stamou, S. (2004). BalkaNet: Aims, methods, results perspectives. general overview. Romanian Journal Information Science Technology,
7 (1-2), 943.
Vossen, P. (1998). Introduction EuroWordNet. EuroWordNet: multilingual database
lexical semantic networks, pp. 117. Springer.

87


