Journal Artificial Intelligence Research 5 (1996) 27-52

Submitted 9/95; published 8/96

Hierarchy Tractable Subsets
Computing Stable Models
Rachel Ben-Eliyahu

rachel@cs.bgu.ac.il

Mathematics Computer Science Department
Ben-Gurion University Negev
P.O.B. 653, Beer-Sheva 84105, Israel

Abstract

Finding stable models knowledge base significant computational problem
artificial intelligence. task computational heart truth maintenance
systems, autoepistemic logic, default logic. Unfortunately, NP-hard.
paper present hierarchy classes knowledge bases,
1
2 , following
properties: first,
1 class stratified knowledge bases; second, knowledge
base
, stable models, may found time
( ), length knowledge base number atoms ; third,
arbitrary knowledge base , find minimum belongs

time polynomialSin1 size ; and, last, K class knowledge bases,
case =1
= K, is, every knowledge base belongs class
hierarchy.
;

k

k

lnk

; :::

l

n

k



k



1. Introduction
task computing stable models knowledge base lies heart three
fundamental systems Artificial Intelligence (AI): truth maintenance systems (TMSs),
default logic, autoepistemic logic. Yet, task intractable (Elkan, 1990; Kautz &
Selman, 1991; Marek & Truszczynski, 1991). paper, introduce hierarchy
classes knowledge bases achieves task polynomial time. Membership
certain class hierarchy testable polynomial time. Hence, given knowledge base,
cost computing stable models bounded prior actual computation (if
algorithms hierarchy based used).
First, let us elaborate relevance computing stable models AI tasks. define
knowledge base set rules form

C ,A1 ; :::; Am; B1; :::; Bn

(1)

C , As, B atoms propositional language. Substantial efforts
give meaning, semantics, knowledge base made logic programming
community (Przymusinska & Przymusinski, 1990). One successful semantics
knowledge bases stable model semantics (Bidoit & Froidevaux, 1987; Gelfond & Lifschitz,
1988; Fine, 1989), associates knowledge base (possibly empty) set
models called stable models. Intuitively, stable model represents set coherent
c 1996


AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBen-Eliyahu
conclusions one might deduce knowledge base. turns stable models
play central role major deductive systems AI. 1

1.1 Stable Models TMSs

TMSs (Doyle, 1979) inference systems nonmonotonic reasoning default assumptions. TMS manages set nodes set justifications, node
represents piece information justifications rules state dependencies
nodes. TMS computes grounded set nodes assigns set
information believed true given point time. Intuitively, set believed
nodes grounded satisfies rules, node believed true solely basis
circular chain justifications. Elkan (1990) pointed nodes TMS
viewed propositional atoms, set justifications knowledge base.
showed task computing grounded interpretations set TMS justifications corresponds exactly task computing stable models knowledge base
represented set TMS justifications.

1.2 Stable Models Autoepistemic Logic

Autoepistemic logic invented Moore (1985) order formalize process
agent reasoning beliefs. language autoepistemic logic propositional
language augmented modal operator L. Given theory (a set formulas)
autoepistemic logic, theory E called stable expansion iff
E = (T SfLF jF 2 E gSf:LF jF 2= E g)
denotes logical closure . restrict subset
autoepistemic logic formula form
A1 ^ ::: ^ ^ :LB1 ^ ::: ^ :LBn ,!C
(2)
C , As, B propositional atoms. call subset
class autoepistemic programs. Every autoepistemic program translated
knowledge base representing formula (2) knowledge base rule (1). Elkan
(1990) shown stable model iff expansion E
set positive atoms E . Thus, algorithms computing stable models
may used computing expansions autoepistemic programs. relationship
stable model semantics autoepistemic logic explored Gelfond (1987)
Gelfond Lifschitz (1988, 1991).

1.3 Stable Models Default Logic

Default logic formalism developed Reiter (1980) reasoning default assumptions. default theory viewed set defaults, default defined
expression form
: fi1; :::; fin
(3)



1. logic programming terminology, knowledge bases discussed paper called normal logic
programs.

28

fiA Hierarchy Tractable Subsets
ff; , fi1 ; :::; fin formulas first-order language. According Reiter, E
extension default theory iff E coincides one minimal deductively
closed sets sentences E 0 satisfying condition2 grounded instance
default (3) , 2 E 0 :fi1 ; :::; :fin 2= E , 2 E 0.
consider subset default theories call default programs. default
program set defaults form

A1 ^ ::: ^ : :B1; :::; :Bn
(4)
C
C , As, B atoms propositional language.

default program associated knowledge base replacing
default form (4) rule (1).
Gelfond Lifschitz (1991) shown logical closure set atoms E
extension iff E stable model . Algorithms computing stable models
thus used computing extensions Reiter's default theories.


paper organized follows. next section, define terminology.
Section 3 presents two algorithms computing stable models knowledge base.
complexity first algorithms depends number atoms appearing
negatively knowledge base, complexity algorithm depends
number rules negative atoms bodies. Section 4, present
main algorithm paper, called algorithm AAS. Algorithm AAS works
bottom superstructure dependency graph knowledge base uses
two algorithms presented Section 3 subroutines. Section 5 explains AAS
algorithm generalized handle knowledge bases first-order language. Finally,
Sections 6 7, discuss related work make concluding remarks.

2. Preliminary Definitions
Recall knowledge base defined set rules form

C ,A1 ; :::; Am; B1; :::; Bn

(5)

C , As, B propositional atoms. expression
left , called head rule, expression right , called
body rule. said appear positive rule, and, accordingly,
B said appear negative rule. Rule (5) said C . rule
empty body called unit rule. Sometimes treat truth assignment (in
words, interpretation) propositional logic set atoms | set atoms
assigned true interpretation. Given interpretation set atoms A, IA
denotes projection A. Given two interpretations, J , sets atoms
2. Note appearance E condition.

29

fiBen-Eliyahu
B , respectively, interpretation + J defined follows:
8>
P 2 n B
>< IJ((PP))
P 2 BTn
+ J (P ) = > (P )
P 2 B (P ) = J (P )

>:
undefined otherwise

(P ) = J (P ) every P 2 B , say J consistent.

partial interpretation truth assignment subset atoms. Hence, partial
interpretation represented consistent set literals: positive literals represent
atoms true, negative literals atoms false, rest unknown.
knowledge base called Horn rules Horn. model theory (set
clauses) propositional logic truth assignment satisfies clauses. one
looks knowledge base theory propositional logic, Horn knowledge base
unique minimal model (recall model minimal among set models iff
model m0 2 m0 m).
Given knowledge base set atoms m, Gelfond Lifschitz defined
called Gelfond-Lifschitz (GL) transform w.r.t. m, knowledge base
obtained deleting rule negative literal P body
P 2 deleting negative literals bodies remaining rules. Note
Horn knowledge base. model stable model knowledge base iff
unique minimal model (Gelfond & Lifschitz, 1988).
Example 2.1 Consider following knowledge base 0, used one
canonical examples throughout paper:
(6)
warm blooded , mammal
live land , mammal; ab1
(7)
female , mammal; male
(8)
male , mammal; female
(9)
mammal , dolphin
(10)
ab1 , dolphin
(11)
mammal , lion
(12)
lion ,
(13)
= flion; mammal; warm blooded; live land; femaleg stable model 0 . Indeed,
0m (the GL transform 0 w.r.t. m)

,
,
,
,
,
,
,

warm blooded
live land
female
mammal
ab1
mammal
lion

30

mammal
mammal
mammal
dolphin
dolphin
lion

fiA Hierarchy Tractable Subsets
minimal model 0m .
set atoms satisfies body rule iff atom appears positive
body atom appears negative body . set
atoms satisfies rule iff either satisfy body, satisfies body
atom appears head belongs .
proof atom sequence rules atom derived. Formally,
recursively define atom P proof w.r.t. set atoms
knowledge base :
unit rule P , , P proof w.r.t. .
rule P ,A1; :::; Am; B1; :::; Bn , every = 1; :::; n Bi
, every = 1; :::; Ai already proof w.r.t. , P
proof w.r.t. .
Theorem 2.2 (Elkan, 1990; Ben-Eliyahu & Dechter, 1994) set atoms stable
model knowledge base iff
1. satisfies rule ,
2. atom P , proof P w.r.t .
simple matter show following lemma true.
Lemma 2.3 Let knowledge base, let set atoms. Define:
1. S0 = ;,

2. Si+1 = Si fP jP ,A1 ; :::; Am; B1 ; :::; Bn ;
A's belong Si none B 's belong g.
S.
stable model iff = 1
0
Observe although every stable model minimal model knowledge base
viewed propositional theory, every minimal model stable model.
Example 2.4 Consider knowledge base
b ,
fag fbg minimal models knowledge base above, fbg stable
model knowledge base.
Note knowledge base may one stable models, stable model all.
knowledge base least one stable model, say consistent.
dependency graph knowledge base directed graph atom
node positive edge directed P Q iff rule Q
P appears positive body. Accordingly, negative edge
P Q iff rule Q P appears negative body. Recall
source directed graph node incoming edges, sink node
outgoing edges. Given directed graph G node G, subgraph rooted
subgraph G nodes path directed G.
children G nodes arc directed G.
31

fiBen-Eliyahu

Example 2.5 dependency graph 0 shown Figure 1. Negative edges
marked \not." children mammal lion dolphin. subgraph rooted
land subgraph include nodes lion, mammal, dolphin, ab1, land.

male

warm_blood
female



on_land
mammal

lion



ab1
dolphin

Figure 1: dependency graph 0
knowledge base stratified iff assign atom C positive integer iC
every rule form (5) above, As, iA iC ,
B s, iB < iC . readily demonstrated knowledge base stratified iff
dependency graph directed cycles going negative edges. well
known logic programming community stratified knowledge base unique
stable model found linear time (Gelfond & Lifschitz, 1988; Apt, Blair, &
Walker, 1988).

Example 2.6 0 stratified knowledge base. following knowledge base, 1,

stratified (we assign ab2 penguin number 1, atoms
number 2):

live land
fly
bird
ab2

,
,
,
,
32

bird
bird; ab2
penguin
penguin

fiA Hierarchy Tractable Subsets
strongly connected components directed graph G make partition
set nodes that, subset partition x; 2 ,
directed paths x x G. strongly connected components
identifiable linear time (Tarjan, 1972).

male




female
warm_blood

on_land
mammal

lion



ab1
dolphin

Figure 2: super dependency graph 0
super dependency graph knowledge base , denoted G , superstructure
dependency graph . is, G directed graph built making strongly
connected component dependency graph node G . arc exists
node node v iff arc one atoms one atoms v
dependency graph . Note G acyclic graph.

Example 2.7 super dependency graph 0 shown Figure 2. nodes

square grouped single node.

3. Two Algorithms Computing Stable Models
main contribution paper presentation algorithm whose eciency
depends \distance" knowledge base stratified knowledge base.
distance measured precisely Section 4. first describe two algorithms
computing stable models. two algorithms take account level
\stratifiability" knowledge base, is, still work exponential time
stratified knowledge bases. main algorithm use two algorithms procedures.
33

fiBen-Eliyahu
Given truth assignment knowledge base, verify polynomial time whether
stable model using Lemma 2.3. Therefore, straightforward algorithm computing stable models simply check possible truth assignments determine whether
stable model. time complexity straightforward procedure
exponential number atoms used knowledge base. Below, present two
algorithms often function eciently straightforward procedure.

3.1 Algorithm Depends Number Negative Atoms
Knowledge Base
Algorithm All-Stable1 (Figure 3) enables us find stable models time expo-

nential number atoms appear negative knowledge base.
algorithm follows work abductive extensions logic programming
stable models characterized terms sets hypotheses drawn additional information (Eshghi & Kowalski, 1989; Dung, 1991; Kakas & Mancarella, 1991).
done making negative atoms abductible imposing appropriate denials
disjunctions integrity constraints. work Eshghi Kowalski (1989), Dung
(1991), Kakas Mancarella (1991) implies following.
Theorem 3.1 Let knowledge base, let H set atoms appear negated
. stable model iff interpretation H
1. every atom P 2 H , P 2 , P 2 0 ,
2. 0 consistent,
3. = +M 0 ,
0 unique stable model .
Proof: proof follows directly definition stable models. Suppose
stable model knowledge base , let H set atoms appear negative
. Then, definition, stable model . note = MH . Hence,
conditions Theorem 3.1 hold , taking 0 = = MH . Now, suppose
knowledge base = 0 + , 0 Theorem 3.1. Observe
= and, hence, since 0 stable model , 0 stable model .
show stable model . First, note condition 1, 0 . Thus,
satisfies rules and, atom P proof w. r. t. 0 ,
proof w. r. t. . So, Theorem 2.2, stable model and,
definition, stable model .
Theorem 3.1 implies algorithm All-Stable1 (Figure 3), computes stable
models knowledge base . Hence, following complexity analysis.
Proposition 3.2 knowledge base k atoms appear negated
2k stable models found time O(nl2k ), l size
knowledge base n number atoms used knowledge base.
Proof: Follows fact computing computing unique stable model
positive knowledge base O(nl).
34

fiA Hierarchy Tractable Subsets

All-Stable1()

Input: knowledge base .
Output: set stable models .
1. := ;;
2. possible interpretation set atoms appear negative ,
do:
(a) Compute 0 , unique stable model ;

(b) 0 consistent, let := fM 0 + g;
3. Return M;
Figure 3: Algorithm All-Stable1

3.2 Algorithm Depends Number Non-Horn Rules
Algorithm All-Stable2 (Figure 4) depends number rules

negated atoms. gets input knowledge base , and, outputs set stable
models . algorithm based upon observation stable model
built attempting possible means satisfying negated atoms bodies nonHorn rules. Two procedures called All-Stable2: UnitInst, shown Figure 5;
NegUnitInst, shown Figure 6. Procedure UnitInst gets input knowledge base
partial interpretation m. UnitInst looks recursively unit rules . unit rule
P , , P assigned false m, follows cannot part model ,
procedure returns false. P false m, procedure instantiates P true
interpretation deletes positive appearances P body rule.
deletes rules P rules P appears negative.
Procedure NegUnitInst receives input knowledge base , partial interpretation
m, set atoms Neg. first instantiates atom Neg false updates
knowledge base ect instantiation. instantiations recorded m.
case con ict, namely, procedure tries instantiate true atom
already set false, procedure returns false; otherwise, returns true.

Proposition 3.3 Algorithm All-Stable2 correct, is, stable model
knowledge base iff generated All-Stable2().
Proof: Suppose stable model knowledge base . Then, Theorem 2.2, every
atom set true proof w. r. t. . Let set non-Horn
rules whose bodies satisfied m. Clearly, point checked step 3
algorithm All-Stable2. happens, atoms proof w. r. t.
set true procedure NegUnitInst (as proved induction
length proof). Hence, generated.
Suppose generated All-Stable2(). Obviously, every rule satisfied
(step 3.c.ii), every atom set true NegUnitInst proof w. r. t.
35

fiBen-Eliyahu

All-Stable2()
Input: knowledge base .
Output: set stable models .
1. := ;;
2. Let set non-Horn rules .
3. subset , do:
(a) Neg = fP jnot P body rule g;
(b) 0 := ; := ;;
(c) NegUnitInst(0 ; Neg; m),
i. P m[P ] = null, let m[P ] := false;

ii. satisfies rules , := fmg;
4. EndFor;
5. Return ;
Figure 4: Algorithm All-Stable2
UnitInst(; m)
Input: knowledge base partial interpretation m.
Output: Updates using unit rules . Returns false con ict
unit rule value assigned atom m; otherwise, returns true .
1. unit rules, do:
(a) Let P , unit rule ;
(b) m[P ] = false, return false;
(c) m[P ] := true;
(d) Erase P body rule ;
(e) Erase rules P ;
(f) Erase rules P appears negative;
2. EndWhile;
3. Return true;
Figure 5: Procedure UnitInst
36

fiA Hierarchy Tractable Subsets
NegUnitInst(; Neg; m)
Input: knowledge base , set atoms Neg , partial interpretation m.
Output: Updates assuming atoms Neg false. Returns false inconsistency
detected; otherwise, returns true.
1. atom P Neg
(a) m[P ] := false;
(b) Delete body rule occurrence P ;
(c) Delete rule P appears positive body;
2. EndFor;
3. Return UnitInst(; m);
Figure 6: Procedure NegUnitInst



1
2

lion dolphin ab1 mammal warm b land male female


F

F







F





F

F









F

Table 1: Models generated Algorithm All-Stable2
(as readily observable way NegUnitInst works). Hence, Theorem 2.2,
stable model .

Proposition 3.4 knowledge base c non-Horn rules 2c stable models

found time O(nl2c), l size knowledge base
n number atoms used knowledge base.

Proof: Straightforward, induction c.
Example 3.5 Suppose call All-Stable2 0 input knowledge base.
step 2, set rules (7), (8), (9). subsets include rules
(8) (9) considered step 3, NegUnitInst return false UnitInst

detect inconsistency. subset containing rules (7) (8) considered,
stable model 1 Table 1 generated. subset containing rules (7)
(9) considered, stable model 2 Table 1 generated.
subsets contain rules (8) (9) tested step 3, generated
satisfy rules and, hence, appear output.
Algorithms All-Stable1 All-Stable2 take account structure
knowledge base. example, polynomial class stratified
knowledge bases. present next algorithm exploits structure knowledge
base.
37

fiBen-Eliyahu

4. Hierarchy Tractable Subsets Based Level Stratifiability
Knowledge Base

Algorithm Acyclic-All-Stable (AAS) Figure 7 exploits structure knowledge
base ected super dependency graph knowledge base. computes
stable models traversing super dependency graph bottom up, using
algorithms computing stable models presented previous section subroutines.
Let knowledge base. node G (the super dependency graph
), associate , , Ms . subset containing rules
atoms s, set atoms subgraph G rooted s, Ms set
stable models associated subset knowledge base contains rules
atoms . Initially, Ms empty every s. algorithm traverses G
bottom up. node s, first combines submodels children
single set models Mc(s) . source, Mc(s) set f;g3. Next,
model Mc(s) , AAS converts knowledge base sm using GL transform
transformations depend atoms m; then, finds stable models
sm combines m. set Ms obtained repeating operation
Mc(s) . AAS uses procedure CartesProd (Figure 8), receives input
several sets models returns consistent portion Cartesian product. one
sets models CartesProd gets input empty set, CartesProd
output empty set models. procedure Convert gets input knowledge base ,
model m, set atoms s, performs following: atom P m,
positive occurrence P deleted body rule ; rule ,
P body rule P 2 m, rule deleted ; P
body rule P 2= m, then, P 2= s, P deleted body.
procedure All-Stable called AAS may one procedures previously presented
(All-Stable1 All-Stable2) may procedure generates stable
models.

Example 4.1 Suppose AAS called compute stable models 0. Suppose

algorithm traverses super dependency graph Figure 2 order flion,
dolphin, mammal, ab1, land, warm blooded, female-maleg (recall nodes inside square make one node calling female-male or, short, FM).
visiting nodes except last, Mlion = ffliongg, Mdolphin = f;g,
Mmammal = fflion; mammalgg, Mon land = fflion; mammal; onlandgg, Mwarm blooded =
fflion; mammal; warm bloodedgg. visiting node FM, step 1.c
Mc(FM ) = Mmammal . step 1.d loops once, = flion; mammalg. Recall
FM knowledge base

female
male

, mammal; male
, mammal; female

3. Note difference f;g, set one model - model assigns
atoms, ;, set contains models.

38

false



fiA Hierarchy Tractable Subsets

Acyclic-All-Stable()

Input: knowledge base .
Output: set stable models .
1. Traverse G bottom up. node s, do:
(a) Ms := ;;
(b) Let s1 ; :::; sj children s.
(c) j = 0, Mc(s) := f;g;
else Mc(s) := CartesProd(fMs1 ; :::; Msj g);
(d) 2 Mc(s) , do:
i. sm := Convert(s ; m; s);
ii. := All-Stable(sm );

iii. 6= ;, Ms := Ms CartesProd(ffmg; g);
2. Output CartesProd(fMs1 ; :::; Msk g), s1 ; :::; sk sinks G .
Figure 7: Algorithm Acyclic-All-Stable (AAS)
CartesProd(M)
Input: set sets models M.
Output: set models consistent portion Cartesian product
sets M.
1. single element fE g, return E ;
2. := ;;
3. Let 0 2 M;
4. := CartesProd(M n fM 0g);
5. D, do:
(a) 0 , do:

consistent, := fm + dg;
(b) EndFor;
6. EndFor;
7. Return ;
Figure 8: Procedure CartesProd
39

fiBen-Eliyahu
executing step 1.d.i, FM set

female
male

, male
, female

knowledge base two stable models: ffemaleg fmaleg. Cartesian
product set flion; mammalg yields MFM = fflion; mammal; femaleg;
flion; mammal; malegg. step 2, Cartesian product Mwarm blooded , Mon land,
MFM taken. Thus, algorithm outputs fflion; mammal; land; warm blooded; femaleg,
flion; mammal; land; warm blooded; malegg, indeed two stable models
0 . Note algorithm AAS ecient either All-Stable1 All-Stable2
knowledge base 0 .

Theorem 4.2 Algorithm AAS correct, is, stable model knowledge base
iff generated AAS applied .
Proof: Let s0; s1; :::; sn ordering nodes super dependency graph

algorithm executed. show induction AAS, node
si, generates stable models portion knowledge base composed
rules use atoms Asi .
case = 0: case, step 1.d.ii AAS, sm = s; thus, claim follows
correctness algorithm All-Stable called step 1.d.ii.
case > 0: Showing every model generated stable straightforward, induction hypothesis Theorem 2.2. direction is: suppose stable model
; show generated. Clearly, child si , projection
onto stable model part knowledge base uses atoms
As. induction, mc , projection onto union every
child si , must belong Mc(si ) computed step 1.c. Therefore, show
generated, need show m0 = , mc stable model simc .
easily done using Theorem 2.2.
analyze complexity AAS. First, given knowledge base
set atoms s, define ^ knowledge base obtained deleting
negative occurrence atom belong body every rule.
example, = fa ,not b; c ,not d; ag = fbg, ^ = fa ,not b; c ,ag.
visiting node execution AAS, compute step 1.d.ii
stable models knowledge base sm . Using either All-Stable1 All-Stable2,
estimated time required find stable models sm shorter equal
time required find stable models ^ . occurs number negative
atoms number rules negative atoms bodies ^ higher
equal number negative atoms number rules negative atoms
bodies sm , regardless is. Thus, ^ Horn knowledge base,
find stable model ^ , hence sm , polynomial time, matter is.
40

fiA Hierarchy Tractable Subsets
^ positive, find stable models ^ , hence sm , time
min(ln 2k ; ln 2c ), l length ^ , n number atoms used ^ , c
number rules ^ contain negative atoms, k number atoms appear
negatively ^ .
Then, knowledge base , associate number follows. Associate
number vs every node G . ^ Horn knowledge base, vs 1; else, vs
min(2k ; 2c), c number rules ^ contain negative atoms s,
k number atoms appear negatively ^ . associate number ts
every node s. leaf node, ts = vs . children s1 ; :::; sj G ,
ts = vs ts1 ::: tsj . Define ts1 ::: tsk , s1 ; :::; sk sink nodes
G .
Definition 4.3 knowledge base belongs
j = j .
Theorem 4.4 knowledge base belongs
j j , j stable
models computed time O(lnj ).
Proof: induction j . dependency graph super dependency graph
built time linear size knowledge base. may consider
time takes compute stable models super dependency graph given.
case j = 1: 2
1 means every node G, ^ Horn knowledge base.
words, stratified, therefore exactly one stable model.
n nodes graph. node, loop step 1.d executed
once, one model generated every node. Procedure Convert runs
time O(ls), ls length (we assume stored array
access atom constant time). Since, every node s, ^
Horn knowledge base, sm computed time O(lsn). Thus, overall complexity
O(ln).
case j > 1: induction n, number nodes super dependency graph .
case n = 1: Let single node G . Thus, j = vs. Using algorithms
Section 3, stable models = found time O(lnvs ),
vs models.
case n > 1: Assume without loss generality G single sink (to get
single sink, add program rule P , s1 ; ::; sk, s1 ; :::; sk
sinks P new atom). Let c1 ; :::; ck children s.
child ci , (ci ), part knowledge base corresponds subgraph
rooted ci, must belong
ti ti j . induction n,
child node ci, stable models (ci ) computed time O(lnti ),
(ci) ti stable models. let us observe happens AAS
visiting node s. First, Cartesian product models computed
child nodes taken. executed time O(n t1 ::: tk), yields
t1 ::: tk models Mc(s) . every 2 Mc(s) , call Convert (O(ln))
compute stable models sm (O(lnvs)). combine
using CartesProd (O(nvs )). Thus, overall complexity computing Ms ,
is, computing stable models , O(lnt1 ::: tk vs ) = O(lnj ).
41

fiBen-Eliyahu

Note stratified knowledge bases belong
1 , knowledge
base looks stratified, ecient algorithm AAS be.
Given knowledge base , easy find minimum j belongs
j .
follows building G finding c k every node G polynomialtime tasks. Hence,
Theorem 4.5 Given knowledge base , find minimum j belongs

j polynomial time.
Example 4.6 nodes G0 except FM, vs =1. vFM = 2. Thus, 0 2
2. 1
stratified knowledge base therefore belongs
1.



male


female
warm_blood

on_land
mammal

lion

fly




ab1
dolphin

bird

ab2

penguin



Figure 9: super dependency graph 0 1
next example shows step 5 procedure CartesProd necessary.
Example 4.7 Consider knowledge base 4:
, b
b ,

c

e
f

,
,
,
,

42


b
c;
c

fiA Hierarchy Tractable Subsets

f

e

c







b


Figure 10: Super dependency graph 4





c

c








b

b





(1)

(2)

Figure 11: Dependency graph (1) super dependency graph (2) 2
43

fiBen-Eliyahu
super dependency graph 4 shown Figure 10. run algorithm AAS,
Mab (the set models computed node fa; bg) set ffa; :bg; f:a; bgg. AAS
visits nodes c d, get Mc = ffa; :b; cg; f:a; bgg, Md = ff:a; b; dg; fa; :bgg.
AAS visits node e, CartesProd called input fMc ; Mdg, yielding output =
ffa; :b; cg; f:a; b; dgg. Note CartesProd output model c
true, models fa; :b; cg f:a; b; dg inconsistent CartesProd
checks consistency step 5. visiting node f , get Mf = ffa; :b; c; f g; f:a; bgg.
AAS returns CartesProd(fMe; Mf g), ffa; :b; c; f g; f:a; b; dgg.
next example demonstrates models generated nodes super dependency graph run AAS may later deleted, since cannot
completed stable model whole knowledge base.

Example 4.8 Consider knowledge base 2:

b
c

, b
,
, a; c

dependency graph super dependency graph 2 shown Figure 11.
run algorithm AAS, Mab (the set models computed node fa; bg)
set ffag; fbgg. However, fbg stable model 2 .
Despite deficiency illustrated Example 4.8, algorithm AAS desirable
features. First, AAS enables us compute stable models modular fashion. use
G structure store stable models. knowledge base changed,
need resume computation nodes affected change. example,
suppose computing stable models knowledge base 0 , add toS 0
knowledge base 1 Example 2.6, gives us new knowledge base, 3 = 0 1.
super dependency graph new knowledge base 3 shown Figure 9.
need compute stable models nodes penguin, bird, ab2, y, land
combine models generated sinks. re-compute
stable models nodes well.
Second, using AAS algorithm, always compute stable models
root node. queried atom somewhere middle
graph, often enough compute models subgraph rooted
node represents atom. example, suppose given knowledge base
2 asked mammal true every stable model 2 . run AAS
nodes dolphin, lion, mammal | stop. mammal true stable
models computed node mammal (i.e., models Mmammal ), answer
\yes", otherwise, must continue computation.
Third, AAS algorithm useful computing labeling TMS subject
nogoods. set nodes TMS declared nogood, means acceptable
labeling assign false least one node nogood set.4 stable models
terminology, means handling nogoods, look stable models
4. logic programming terminology nogoods simply integrity constraints.

44

fiA Hierarchy Tractable Subsets
least one atom nogood false. straightforward approach would first
compute stable models choose ones comply nogood
constraints. since AAS algorithm modular works bottom up,
many cases prevent generation unwanted stable models early stage.
computation, exclude submodels comply nogood
constraints erase submodels Ms node super
dependency graph includes members certain nogood.

5. Computing Stable Models First-Order Knowledge Bases
section, show generalize algorithm AAS find stable
models knowledge base first-order language function symbols. new
algorithm called First-Acyclic-All-Stable (FAAS).
refer knowledge base set rules form

C ,A1; A2; :::; Am; B1; :::; Bn

(14)

As, B s, C atoms first-order language function symbols.
definitions head, body, positive negative appearances atom
propositional case. expression p(X1; :::; Xn), p called predicate name.
propositional case, every knowledge base associated directed graph
called dependency graph , (a) predicate name node, (b)
positive arc directed node p node q iff rule
p predicate name one Ai q predicate name head, (c)
negative arc directed node p node q iff rule
p predicate name one Bi q predicate name head. super
dependency graph, G , defined analogous manner. define stratified knowledge
base knowledge base cycles negative edges
dependency graph knowledge base.
knowledge base called safe iff rules safe. rule safe iff
variables appearing head rule predicates appearing negative rule
appear positive predicates body rule. section, assume
knowledge bases safe. Herbrand base knowledge base set atoms
constructed using predicate names constants knowledge base. set
ground instances rule set rules obtained consistently substituting variables
rule constants appear knowledge base possible ways.
ground instance knowledge base union ground instances rules. Note
ground instance first-order knowledge base viewed propositional
knowledge base.
model knowledge base subset knowledge base's Herbrand base.
subset property every rule grounded knowledge base,
atoms appear positive body rule belong atoms
appear negative body rule belong , atom head
rule belongs . stable model first-order knowledge base Herbrand
model , stable model grounded version .
45

fiBen-Eliyahu

First-Acyclic-All-Stable()

Input: first-order knowledge base .
Output: stable models .
1. Traverse G bottom up. node s, do:
(a) Ms := ;;
(b) Let s1 ; :::; sj children s;
(c) Mc(s) := CartesProd(fMs1 ; :::; Msj g);
(d) 2 Mc(s)
Ms := MsSall-stable(s SfP ,jP 2 mg)
2. Output CartesProd(fMs1 ; :::; Msk g), s1 ; :::; sk sinks G .
Figure 12: Algorithm First-Acyclic-All-Stable (FAAS)
present FAAS, algorithm computes stable models first-order
knowledge base. Let first-order knowledge base. propositional case,
node G (the super dependency graph ), associate , , Ms .
subset containing rules predicates whose names s.
set predicate names P appear subgraph G rooted s. Ms
stable models associated sub{knowledge base contains rules
predicates whose names . Initially, Ms empty every s. Algorithm FAAS
traverses G bottom up. node s, algorithm first combines
submodels children single set models, Mc(s) . Then, model
Mc(s), calls procedure finds stable models union set
unit clauses P , P 2 m. procedure All-Stable called FAAS
procedure computes stable models first-order knowledge base.
procedure All-Stable computes stable models parts knowledge base,
may take advantage fractions knowledge base stratified
property simplifies computation stable models fraction.

Theorem 5.1 Algorithm FAAS correct, is, stable model knowledge base
iff one models output applying FAAS .

Proof: proof Theorem 4.2.

Note knowledge base appears stratified, ecient algorithm
FAAS becomes.

Example 5.2 Consider knowledge base 5:
warm blooded(X )
live land(X )
female(X )

, mammal(X )
, mammal(X ); ab1(X )
, mammal(X ); male(X )
46

fiA Hierarchy Tractable Subsets
male(X )
mammal(X )
ab1(X )
mammal(X )
dolphin(flipper)

,
,
,
,
,

mammal(X ); female(X )
dolphin(X )
dolphin(X )
lion(X )

, bird(X )
, bird(X ); ab2(X )
, penguin(X )
, penguin(X )
,
super dependency graph 5 , G5 , super dependency graph
live land(X )
fly (X )
bird(X )
ab2(X )
bird(bigbird)

knowledge base 2 (see Figure 9). Observe node mammal, example,

step 1.d algorithm looks stable models knowledge base 0 = mammal
f ,dolphin(flipper)g, mammal =fmammal(X ) ,dolphin(X ); mammal(X ) ,lion(X )g.
0 stratified knowledge base unique stable model found eciently.
Hence, algorithm FAAS saves us ground rules knowledge base
starting calculate models, take advantage parts knowledge
base stratified.

6. Related Work

recent years, quite algorithms developed reasoning stable models.
Nonetheless, far know, work presented original sense
provides partition set knowledge bases hierarchy tractable
classes. partition based structure dependency graph. Intuitively,
task computing stable models knowledge base using algorithm AAS becomes
increasingly complex \distance" knowledge base stratified becomes
larger. Next, summarize work seems us relevant.
Algorithm AAS based idea appears work Lifschitz Turner
(1994), show many cases logic program divided two parts,
one part, \bottom" part, refer predicates defined \top"
part. explain task computing stable models program
simplified program split parts. Algorithm AAS, using superstructure
dependency graph, exploits specific method splitting program.
Bell et al. (1994) Subrahmanian et al. (1995) implement linear integer programming techniques order compute stable models (among nonmonotonic logics). However, dicult assess merits approaches terms complexity.
Ben-Eliyahu Dechter (1991) illustrate knowledge base translated
propositional theory model latter corresponds stable model
former. follows problem finding stable models
knowledge base corresponds problem finding models propositional
theory. Satoh Iwayama (1991) provide nondeterministic procedure computing
47

fiBen-Eliyahu
stable models logic programs integrity constraints. Junker Konolige (1990)
present algorithm computing TMS' labels. Antoniou Langetepe (1994) introduce
method representing classes default theories normal logic programs
way SLDNF-resolution used compute extensions. Pimentel Cuadrado
(1989) develop label-propagation algorithm uses data structures called compressible
semantic trees order implement TMS; algorithm based stable model semantics. algorithms developed Marek Truszczynski (1993) autoepistemic
logic adopted computing stable models. procedures Marek
Truszczynski (1993), Antoniou Langetepe (1994), Pimentel Cuadrado (1989), BenEliyahu Dechter (1991), Satoh Iwayama (1991), Bell et al. (1994), Subrahmanian
et al. (1995), Junker Konolige (1990) take advantage structure
knowledge base ected dependency graph, therefore ecient
stratified knowledge bases.
Sacca Zaniolo (1990) present backtracking fixpoint algorithm constructing one
stable model first-order knowledge base. algorithm similar algorithm AllStable2 presented Section 3 complexity worse complexity
All-Stable2. show backtracking fixpoint algorithm modified
handle stratified knowledge bases ecient manner, algorithm needs
adjustments deal eciently knowledge bases close
stratified. Leone et al. (1993) present improved backtracking fixpoint algorithm
computing one stable model Datalog: program discuss improved algorithm
implemented. One procedures called improved algorithm based
backtracking fixpoint algorithm Sacca Zaniolo (1990). backtracking
fixpoint algorithm, improved algorithm take advantage structure
program, i.e., ecient programs close stratified.
Several tractable subclasses computing extensions default theories (and, hence,
computing stable models) known (Kautz & Selman, 1991; Papadimitriou & Sideri,
1994; Palopoli & Zaniolo, 1996; Dimopoulos & Magirou, 1994; Ben-Eliyahu & Dechter,
1996). tractable subclasses characterized using graph ects
dependencies program atoms rules. algorithms presented
papers complete subclass knowledge bases, however. Algorithms
computing extensions stratified default theories extensions default theories
odd cycles (in precise sense) given Papadimitriou Sideri (1994)
Cholewinski (1995a, 1995b).
Algorithms handling TMS nogoods developed AI community Doyle (1979) Charniak et al. (1980). But, Elkan (1990) points out,
algorithms always faithful semantics TMS complexities
analyzed. Dechter Dechter (1994) provide algorithms manipulating TMS
represented constraint network. eciency algorithms depends
structure constraint network representing TMS, structure
employ differs dependency graph knowledge base.
48

fiA Hierarchy Tractable Subsets

7. Conclusion
task computing stable models heart several systems central AI,
including TMSs, autoepistemic logic, default logic. task shown
NP-hard. paper, present partition set knowledge bases classes

1 ;
2; :::, knowledge base
k , k stable models,
may found time O(lnk), l length knowledge base
n number atoms . Moreover, arbitrary knowledge base , find
minimum k belongs
k time linear size . Intuitively,
knowledge base stratified, ecient algorithm becomes. believe
beyond stratified knowledge bases, expressive knowledge base (i.e.
rules nonstratified negation knowledge base), less likely needed.
Hence, analysis quite useful. addition, show algorithm AAS
several advantages dynamically changing knowledge base, provide applications
answering queries implementing TMS's nogood strategies. illustrate
generalization algorithm AAS class first-order knowledge bases.
Algorithm AAS easily adjusted find one stable model knowledge
base. traversing super dependency graph, generate one model
node. arrive node cannot generate model based
computed far, backtrack recent node several models available
choose take next model yet chosen. worst-case time
complexity algorithm equal worst-case time complexity algorithm
finding stable models may exhaust possible ways generating
stable model finding certain knowledge base stable model
all. Nevertheless, believe average case, finding one model
easier finding all. similar modification AAS algorithm required
interested finding one model one particular atom gets value true.
work another attempt bridge gap declarative systems (e.g.,
default logic, autoepistemic logic) procedural systems (e.g., ATMs, Prolog)
nonmonotonic reasoning community. argued declarative methods
sound, impractical since computationally expensive, procedural methods ecient, dicult completely understand performance
evaluate correctness. work presented illustrates declarative
procedural approaches combined yield ecient yet formally supported
nonmonotonic system.

Acknowledgments
Thanks Luigi Palopoli useful comments earlier draft paper Michelle
Bonnice Gadi Dechter editing parts manuscript. Many thanks
anonymous referees useful comments.
work done author visiting Cognitive Systems Laboratory, Computer Science Department, University California, Los Angeles, California,
USA. work partially supported NSF grant IRI-9420306 Air Force Oce
Scientific Research grant #F49620-94-1-0173.
49

fiBen-Eliyahu

References

Antoniou, G., & Langetepe, E. (1994). Soundness completeness logic programming
approach default logic. AAAI-94: Proceedings 12th national conference
artificial intelligence, pp. 934{939. AAAI Press, Menlo Park, Calif.
Apt, K., Blair, H., & Walker, A. (1988). Towards theory declarative knowledge.
Minker, J. (Ed.), Foundations deductive databases logic programs, pp. 89{148.
Morgan Kaufmann.
Bell, C., Nerode, A., Ng, R., & Subrahmanian, V. (1994). Mixed integer programming
methods computing non-monotonic deductive databases. Journal ACM,
41 (6), 1178{1215.
Ben-Eliyahu, R., & Dechter, R. (1994). Propositional semantics disjunctive logic programs. Annals Mathematics Artificial Intelligence, 12, 53{87. short version
appears JICSLP-92: Proceedings 1992 joint international conference
symposium logic programming.
Ben-Eliyahu, R., & Dechter, R. (1996). Default reasoning using classical logic. Artificial
Intelligence, 84 (1-2), 113{150.
Bidoit, N., & Froidevaux, C. (1987). Minimalism subsumes default logic circumscription
stratified logic programming. LICS-87: Proceedings IEEE symposium
logic computer science, pp. 89{97. IEEE Computer Science Press, Los Alamitos,
Calif.
Charniak, E., Riesbeck, C. K., & McDermott, D. V. (1980). Artificial Intelligence Programming, chap. 16. Lawrence Erlbaum, Hillsdale, NJ.
Cholewinski, P. (1995a). Reasoning stratified default theories. Marek, W. V.,
Nerode, A., & Truszczynski, M. (Eds.), Logic programming nonmonotonic reasoning: proceedings 3rd international conference, pp. 273{286. Lecture notes
computer science, 928. Springer-Verlag, Berlin.
Cholewinski, P. (1995b). Stratified default theories. Pacholski, L., & Tiuryn, A. (Eds.),
Computer science logic: 8th workshop, CSL'94: Selected papers, pp. 456{470. Lecture
notes computer science, 933. Springer-Verlag, Berlin.
Dechter, R., & Dechter, A. (1996). Structure-driven algorithms truth maintenance.
Artificial Intelligence, 82 (1-2), 1{20.
Dimopoulos, Y., & Magirou, V. (1994). graph-theoretic approach default logic. Journal
Information Computation, 112, 239{256.
Doyle, J. (1979). truth-maintenance system. Artificial Intelligence, 12, 231{272.
Dung, P. M. (1991). Negation hypothesis: abductive foundation logic programming. Furukawa, K. (Ed.), ICLP-91: Proceedings 8th international conference
logic programming, pp. 3{17. MIT Press.
50

fiA Hierarchy Tractable Subsets
Elkan, C. (1990). rational reconstruction nonmonotonic truth maintenance systems.
Artificial Intelligence, 43, 219{234.
Eshghi, K., & Kowalski, R. A. (1989). Abduction compared negation failure. Levi,
G., & Martelli, M. (Eds.), ICLP-89: Proceedings 6th international conference
logic programming, pp. 234{254. MIT Press.
Fine, K. (1989). justification negation failure. Logic, Methodology Philosophy
Science, 8, 263{301.
Gelfond, M. (1987). stratified autoepistemic theories. AAAI-87: Proceedings
5th national conference artificial intelligence, pp. 207{211. Morgan Kaufmann.
Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.
Kowalski, R. A., & Bowen, K. A. (Eds.), Logic Programming: Proceedings 5th
international conference, pp. 1070{1080. MIT Press.
Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctive
databases. New Generation Computing, 9, 365{385.
Junker, U., & Konolige, K. (1990). Computing extensions autoepistemic default logics TMS. AAAI-90: Proceedings 8th national conference
artificial intelligence, pp. 278{283. AAAI Press.
Kakas, A. C., & Mancarella, P. (1991). Stable theories logic programs. Saraswat,
V., & Udea, K. (Eds.), ISLP-91: Proceedings 1991 international symposium
logic programming, pp. 85{100. MIT Press.
Kautz, H. A., & Selman, B. (1991). Hard problems simple default logics. Artificial
Intelligence, 49, 243{279.
Leone, N., Romeo, N., Rullo, M., & Sacca, D. (1993). Effective implementation negation
database logic query languages. Atzeni, P. (Ed.), LOGIDATA+: Deductive
database complex objects, pp. 159{175. Lecture notes computer science, 701.
Springer-Verlag, Berlin.
Lifschitz, V., & Turner, H. (1994). Splitting logic program. Van Hentenryck, P. (Ed.),
ICLP-94: Proceedings 11th international conference logic programming, pp.
23{37. MIT Press.
Marek, V. W., & Truszczynski, M. (1993). Nonmonotonic logic: Context-dependent reasoning. Springer Verlag, Berlin.
Marek, W., & Truszczynski, M. (1991). Autoepistemic logic. Journal ACM, 38,
588{619.
Moore, R. C. (1985). Semantical consideration nonmonotonic logic. Artificial Intelligence, 25, 75{94.
Palopoli, L., & Zaniolo, C. (1996). Polynomial-time computable stable models.. Annals
Mathematics Artificial Intelligence, press.
51

fiBen-Eliyahu
Papadimitriou, C. H., & Sideri, M. (1994). Default theories always extensions.
Artificial Intelligence, 69, 347{357.
Pimentel, S. G., & Cuadrado, J. L. (1989). truth maintenance system based stable
models. Lusk, E. L., & Overbeek, R. A. (Eds.), ICLP-89: Proceedings 1989
North American conference logic programming, pp. 274{290. MIT Press.
Przymusinska, H., & Przymusinski, T. (1990). Semantic issues deductive databases
logic programs. Banerji, R. B. (Ed.), Formal techniques artificial intelligence:
sourcebook, pp. 321{367. North-Holland, New York.
Reiter, R. (1980). logic default reasoning. Artificial Intelligence, 13, 81{132.
Sacca, D., & Zaniolo, C. (1990). Stable models non-determinism logic programs
negation. PODS-90: Proceedings 9th ACM SIGACT-SIGMOD-SIGART
symposium principles database systems, pp. 205{217. ACM Press.
Satoh, K., & Iwayama, N. (1991). Computing abduction using TMS. Furukawa, K.
(Ed.), ICLP-91: Proceedings 8th international conference logic programming,
pp. 505{518. MIT Press.
Subrahmanian, V., Nau, D., & Vago, C. (1995). WFS + branch bound = stable models.
IEEE Transactions Knowledge Data Engineering, 7 (3), 362{377.
Tarjan, R. (1972). Depth-first search linear graph algorithms. SIAM Journal
Computing, 1, 146{160.

52


