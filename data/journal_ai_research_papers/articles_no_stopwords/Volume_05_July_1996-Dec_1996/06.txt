Journal Artificial Intelligence Research 5 (1996) 239-288

Submitted 3/96; published 11/96

MUSE CSP: Extension
Constraint Satisfaction Problem
Randall A. Helzerman
Mary P. Harper

School Electrical Computer Engineering
1285 Electrical Engineering Building
Purdue University
West Lafayette, 47907-1285 USA

helz@ecn.purdue.edu
harper@ecn.purdue.edu

Abstract

paper describes extension constraint satisfaction problem (CSP) called
MUSE CSP (MU ltiply SE gmented C onstraint atisfaction P roblem). extension
especially useful problems segment multiple sets partially shared
variables. problems arise naturally signal processing applications including computer vision, speech processing, handwriting recognition. applications,
often dicult segment data one way given low-level information utilized
segmentation algorithms. MUSE CSP used compactly represent several
similar instances constraint satisfaction problem. multiple instances CSP
common variables domains constraints,
combined single instance MUSE CSP, reducing work required apply
constraints. introduce concepts MUSE node consistency, MUSE arc consistency,
MUSE path consistency. demonstrate MUSE CSP used compactly represent lexically ambiguous sentences multiple sentence hypotheses
often generated speech recognition algorithms grammar constraints
used provide parses syntactically correct sentences. Algorithms MUSE arc
path consistency provided. Finally, discuss create MUSE CSP
set CSPs labeled indicate variable shared
single CSP.

1. Introduction
paper describes extension constraint satisfaction problem (CSP) called MUSE
CSP (MU ltiply SE gmented C onstraint atisfaction P roblem). extension especially
useful problems segment multiple sets partially shared variables.
First, describe constraint satisfaction problem define extension.

1.1 Constraint Satisfaction Problem
Constraint satisfaction problems (CSP) rich history Artificial Intelligence (Davis
& Rosenfeld, 1981; Dechter, Meiri, & Pearl, 1991; Dechter & Pearl, 1988; Freuder, 1989,
1990; Mackworth, 1977; Mackworth & Freuder, 1985; Villain & Kautz, 1986; Waltz, 1975)
(for general reference, see Tsang, 1993). Constraint satisfaction provides convenient way
represent solve certain types problems. general, problems
solved assigning mutually compatible values predetermined number variables
c 1996


AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiHelzerman & Harper

set constraints. approach used variety disciplines including
machine vision, belief maintenance, temporal reasoning, graph theory, circuit design,
diagnostic reasoning. using CSP approach (e.g., Figure 1), variables typically depicted vertices nodes, node associated finite set possible
values, constraints imposed variables depicted using arcs. arc looping
node represents unary constraint (a constraint single variable),
arc two nodes represents binary constraint (a constraint two variables).
classic example CSP map coloring problem (e.g., Figure 1), color must
assigned country two neighboring countries color.
variable represents country's color, constraint arc two variables indicates
two joined countries adjacent assigned color.
Formally, CSP (Mackworth, 1977) defined Definition 1.

Definition 1 (Constraint Satisfaction Problem)
N = fi; j; : : :g set nodes (or variables), jN j = n,
L = fa; b; : : :g set labels, jLj = l,
Li = faja 2 L (i; a) admissibleg,
R1 unary constraint, (i; a) admissible R1 (i; a),
R2 binary constraint, (i; a) , (j; b) admissible R2 (i; a; j; b).
CSP network contains n-tuples Ln satisfy R1 R2 . Since

labels associated node may incompatible labels assigned nodes,
desirable, constraints suciently tight (van Beek, 1994), eliminate
many labels possible enforcing local consistency conditions globally
consistent solution extracted (Dechter, 1992). Node arc consistency defined
Definitions 2 3, respectively. addition, may desirable eliminate many label
pairs possible using path consistency, defined Definition 4.

Definition 2 (Node Consistency) instance CSP said node consistent
node's domain contains labels unary constraint R1 holds, i.e.:
8i 2 N : 8a 2 Li : R1 (i; a)
Definition 3 (Arc Consistency) instance CSP said arc consistent

every pair nodes j , element Li (the domain i) least one element Lj
binary constraint R2 holds, i.e.:
8i; j 2 N : 8a 2 Li : 9b 2 Lj : R2 (i; a; j; b)
{red, green, blue}
Different
Color

1
2

3

{red, green, blue}

Different
Color

1
2

3

{red, green, blue}

Different
Color

Figure 1: map coloring problem example CSP.
240

fiMUSE CSP: Extension Constraint Satisfaction Problem

Definition 4 (Path Consistency) instance CSP said path consistent if:
8i; j 2 N : 6= j ) (8a 2 Li : 8b 2 Lj : 8k 2 N : k 6= ^ k 6= j ^ P ath(i; k; j ) )
(R2(i,a,j,b)) 9c 2 Lk : R2 (i; a; k; c) ^ R2 (k; c; j; b)))
Path(i; k; j ) indicates path arcs length two connecting j
goes k.

Node consistency easily enforced operation Li = Li \ fxjR1 (i; x)g, requiring
O(nl) time (where n number variables l maximum domain size). Arc
consistency enforced ensuring every label node supported least one
label node shares binary constraint (Mackworth, 1977; Mackworth
& Freuder, 1985; Mohr & Henderson, 1986). arc consistency algorithm AC-4 (Mohr
& Henderson, 1986) worst-case running time (el2) (where e number
constraint arcs). AC-3 (Mackworth & Freuder, 1985) often performs better AC-4
practice, though slower running time worst case. AC-6 (Bessiere, 1994)
worst-case running time AC-4 faster AC-3 AC-4 practice.
Path consistency ensures pair labelings (i; a) , (j; b) allowed (i; j ) arc
directly allowed arc paths j . Montanari proven ensure
path consistency complete graph, suces check every arc path length two
(Montanari, 1974). path consistency algorithm PC-4 (Han & Lee, 1988) worstcase running time O(n3 l3) time (where n number variables CSP).

1.2 Multiply Segmented Constraint Satisfaction Problem

many types problems solved using CSP less direct
fashion. problems might benefit CSP approach,
dicult represent single CSP. class problems paper addresses.
example, suppose map represented Figure 1 scanned noisy computer
vision system, resulting uncertainty whether line regions 1 2
really border artifact noise. situation would yield two CSP problems
depicted Figure 2. brute-force approach would solve problems,
would reasonable scenes containing ambiguous borders. However,
number ambiguous borders increases, number CSP networks would grow
combinatorially explosive fashion. case ambiguous segmentation,
ecient merge constraint networks single network would compactly
represent instances simultaneously, shown Figure 3. Notice CSP
instances combined directed acyclic graph paths DAG
start end correspond CSPs combined. paper, develop
extension CSP called MUSE CSP (MU ltiply SE gmented C onstraint atisfaction
P roblem), represents multiple instances CSP problem DAG.
multiple, similar instances CSP, separately applying constraints
instance result much duplicated work. avoid duplication,
provided way combine multiple instances CSP MUSE CSP,
241

fiHelzerman & Harper

{red, green, blue}

{red, green, blue}

1

1

3
Different
Color

3

1

{red, green, blue}

2

3
1

Different
Color

1

Different
Color

2

3
{red, green, blue}

{red, green, blue}

3

2

Different
Color

Figure 2: ambiguous map yields two CSP problems.

start

{red, green, blue}

Different
Color

Different
Color

1
{red, green, blue}

3
{red, green, blue}

Different
Color

1

{red, green,
blue}

Different
Color

Different
Color

1

3

2

2

3

end

{red, green, blue}

{red, green, blue}

{red, green, blue}

Different
Color

{red, green, blue}

Different
Color

Figure 3: two CSP problems Figure 2 captured single instance
MUSE CSP. directed edges form DAG directed paths
DAG correspond instances CSPs combined.

242

fiMUSE CSP: Extension Constraint Satisfaction Problem

developed concepts MUSE node consistency, MUSE arc consistency, MUSE path
consistency. Formally, define MUSE CSP follows:

Definition 5 (MUSE CSP)
N = fi; j; : : :g set nodes (or variables), jN j = n,
2N set segments jj = s,
L = fa; b; : : :g set labels, jLj = l,
Li = faja 2 L (i; a) admissible least one segmentg,
R1 unary constraint, (i; a) admissible R1 (i; a),
R2 binary constraint, (i; a) , (j; b) admissible R2 (i; a; j; b).
segments different sets nodes representing CSP instances
combined form MUSE CSP. solution MUSE CSP defined solution
one segments:

Definition 6 (Solution MUSE CSP) solution MUSE CSP assignment
segment = fi1; : : :; ip g 2 2 Li1 Lip R1(ix ; ff(ix )) holds
every node ix 2 , R2(ix ; ff(ix); iy ; ff(iy )) holds every pair nodes ix ; iy 2 ,
ix 6= iy .
Depending application, solution MUSE CSP could set
consistent labels single path MUSE CSP, single set labels
paths (or CSPs), compatible sets labels paths.
MUSE CSP solved modified backtracking algorithm finds
consistent label assignment segment. However, constraints suciently
tight, search space pruned enforcing local consistency conditions, node,
arc, path consistency. gain eciency resulting enforcing local consistency
conditions backtracking, node, arc, path consistency must modified MUSE
CSP. definitions MUSE CSP node consistency, arc consistency, path consistency
appear Definitions 7, 8, 9, respectively.

Definition 7 (MUSE Node Consistency) instance MUSE CSP said node consistent
node's domain Li contains labels unary constraint R1 holds,
i.e.:
8i 2 N : 8a 2 Li : R1 (i; a)
Definition 8 (MUSE Arc Consistency) instance MUSE CSP said MUSE arc consis-

tent every label domain Li least one segment whose nodes'
domains contain least one label b binary constraint R2 holds, i.e.:

8i 2 N : 8a 2 Li : 9 2 : 2 ^ 8j 2 : j 6= ) 9b 2 Lj : R2 (i; a; j; b)

Definition 9 (MUSE Path Consistency) instance MUSE CSP said path consistent
if:

8i; j 2 N : 6= j ) (8a 2 Li : 8b 2 Lj : 9 2 : i; j 2 ^ 8k 2 : k 6= ^ k 6= j ^ P ath(i; k; j ) )
(R2 (i; a; j; b) ) 9c 2 Lk : R2 (i; a; k; c) ^ R2 (k; c; j; b)))
243

fiHelzerman & Harper

a.

b.

3

{c,d}

start

1

{e}

3

{e}

{d}

end

2

{a,b}


e 1

b
e 1

c
e 0 1

b
e 0 1

start

end

2

1
{b}

4

4
{f}

{f}
c
1 0
b 0 1


b
f 1 1

c
f 0 1

b

1

b
f 1

f


1

Figure 4: a. MUSE CSP MUSE arc consistency achieved; b. MUSE CSP
MUSE arc consistency achieved.
MUSE CSP node consistent segments node consistent. Unfortunately,
MUSE CSP arc consistency requires attention. enforcing arc consistency
CSP, label 2 Li eliminated node whenever domain Lj
labels together satisfy binary constraints. However, MUSE CSP,
label eliminated node, must unsupported arcs every
segment appears, required definition MUSE arc consistency shown
Definition 8. Notice Definition 8 reduces Definition 3 number segments
one.
demonstrate MUSE arc consistency applies MUSE CSP, consider MUSE
CSP Figure 4a. Notice label c 2 L2 supported labels L3
L4 , receive support labels L1. label considered
MUSE arc consistent? answer node 2 member paths
DAG contain node 3 node 4, neither support label
c. segment nodes label supports
c, c eliminated L2. c eliminated L2, eliminated
L1 . elimination c L2 causes loose support node
2. Since node 2 member every path, segment provides support a.
MUSE arc consistent DAG depicted Figure 4b. Note MUSE arc consistency
ensure individual segments arc consistent CSPs. example, Figure
5 MUSE arc consistent even though segments CSP arc consistent.
c receives arc support (which local computation) arcs least
one paths. cannot ensure values support label
mutually consistent considering MUSE arc consistency alone. case, MUSE path
consistency together MUSE arc consistency would needed eliminate illegal
labels c a.
enforcing path consistency CSP, R2 (i; a; j; b) becomes false if, third
node k, label c 2 Lk R2 (i; a; k; c) R2 (k; c; j; b) true.
244

fiMUSE CSP: Extension Constraint Satisfaction Problem

c
e 1 1

b
e 0 1

3

{c,d}

start

1

{e}

end

2

{a,b}

4
{f}

c
1 0
b 0 1

b
f 1 1

c
f 0 1

Figure 5: MUSE CSP MUSE arc consistent, arc consistent
segment.
MUSE CSP, binary constraint becomes path inconsistent one segment, could still
allowed another. Therefore, definition MUSE path consistency modified
shown Definition 9.
Enforcement MUSE arc path consistency requires modification traditional
CSP algorithms. algorithms described introduce several applications
MUSE CSP proven useful.

2. MUSE CSP Constraint-based Parsing
desirable represent MUSE CSP directed acyclic graph (DAG)
directed paths DAG correspond instances CSP problems. often
easy determine variables shared construct DAG.
application presented section one MUSE CSP useful. parsing
problem naturally represented DAG presence ambiguity. many
cases, word multiple parts speech; convenient represent
words nodes MUSE CSP. speech recognition systems, identification
correct words sentence improved using syntactic constraints. However, word
recognition algorithm often produces lattice word candidates. Clearly, individually
parsing sentences lattice inecient.

2.1 Parsing Constraint Dependency Grammar
Maruyama developed new grammar called Constraint Dependency Grammar (CDG)
(Maruyama, 1990a, 1990b, 1990c). showed CDG parsing cast
CSP finite domain, constraints used rule ungrammatical sentences.
CDG four-tuple, h; R; L; C i, where:
245

fiHelzerman & Harper

= finite set preterminal symbols, lexical categories.
R = finite set uniquely named roles (or role-ids) = fr1; : : :; rp g.
L = finite set labels = fl1 ; : : :; lq g.
C = finite set constraints assignment must satisfy.

sentence = w1 w2w3 : : :wn 2 string length n. word wi 2
sentence s, must keep track p different roles (or variables). role variable
takes role values form <l; m>, l 2 L 2 fnil; 1; 2; : : :ng. Role values
denoted examples label-modifiee. parsing, label L indicates different
syntactic function. value role value <l; m>, assigned particular
role wi, specifies position word wi modifying takes
function specified label, l (e.g., subj-3 indicates word label
subject modifies third word sentence). sentence said
generated grammar G exists assignment maps role value
n p roles constraint set C (described next paragraph)
satisfied.
constraint set logical formula form: 8x1 ; x2; : : :; xa (and P1 P2 : : : Pm ),
xi ranges role values roles word s.
subformula Pi C must form: (if Antecedent Consequent), Antecedent
Consequent predicates predicates joined logical connectives.
basic components used express constraints.

Variables: x1 , x2, : : : xa (a = 2 (Maruyama, 1990a)).
Constants: elements subsets [ L [ R [ fnil, 1, 2, : : :, ng, n corresponds
number words sentence.

Functions:
(pos x) returns position word role value x.
(rid x) returns role-id role value x.
(lab x) returns label role value x.
(mod x) returns position modifiee role value x.
(cat y) returns category (i.e., element ) word position y.
Predicates: =, >, <1 .
Logical Connectives: and, or, not.
subformula Pi called unary constraint contains one variable binary constraint contains two. CDG grammar two associated parameters, degree
arity. degree grammar G number roles. arity grammar, a,
corresponds maximum number variables subformulas C .
Consider example grammar, G1 , defined using following four-tuple:
h1 = fdet; noun; verbg; R1 = fgovernorg, L1 = fdet; root; subjg, C1 (see constraints
Figure 6)i. G1 degree one arity two. illustrate process parsing
1. Note 1 > nil 1 < nil false, nil integer. MUSE networks, relate position
intervals using <, >, =.

246

fiMUSE CSP: Extension Constraint Satisfaction Problem

constraint satisfaction, Figure 6 shows steps parsing sentence dog
eats. simplify presentation example, grammar uses single role,
governor role, denoted G constraint network Figure 6. governor
role indicates function word fills sentence governed head word.
word called head phrase forms basis phrase (e.g., verb
head sentence). useful grammars, would include several needs roles
(e.g, need1, need2) make certain head word constituents needs
complete (e.g., singular count noun needs determiner complete noun phrase).
determine whether sentence, dog eats, generated grammar, CDG
parser must able assign least one role value n p roles satisfies
grammar constraints (n = 3 sentence length, p = 1 number roles).
values role selected finite set L1 fnil, 1, 2, 3g, CDG parsing
viewed constraint satisfaction problem finite domain. Therefore, constraint
satisfaction used determine possible parses sentence.
Initially, word, possible role values assigned governor role.
assume word must either modify another word (other itself) modify
word (m=nil). Nothing gained CDG word modify itself. Next unary
constraints applied role values constraint network. role value
incompatible unary constraint satisfies antecedent,
consequent. Notice Figure 6 role values associated governor role
first word (the) satisfy antecedent first unary constraint, det-nil, subjnil, subj-2, subj-3, root-nil, root-2, root-3 satisfy consequent,
incompatible constraint. role value violates unary constraint, node
consistency eliminates role values role never participate
parse sentence. unary constraints applied top constraint
network Figure 6, second network produced.
Next, binary constraints applied. Binary constraints determine pairs role
values legally coexist. keep track pairs role values, arcs constructed connecting role roles network, arc associated arc matrix,
whose row column indices role values associated two roles connects.
entries arc matrix either 1 (indicating two role values indexing
entry compatible) 0 (indicating role values cannot simultaneously exist). Initially, entries matrix set 1, indicating pair role values
indexing entry initially compatible (because constraints applied).
example, single binary constraint (shown Figure 6) applied pairs
role values indexing entries matrices. example, x=det-3
y=root-nil eats, consequent binary constraint fails; hence, role values
incompatible. indicated replacing entry 1 0.
Following binary constraints, roles constraint network still contain
role values incompatible parse sentence. Role values
supported binary constraints eliminated achieving arc consistency.
example, det-3 supported remaining role value eats thus
deleted role.
arc consistency, example sentence single parse one
value per role sentence. parse sentence consists assignment role values
247

fiHelzerman & Harper


det
1

dog

eats

noun
2

verb
3

G

G
{detnil, det2, det3,
subjnil, subj2, subj3,
rootnil, root2, root3}

G

{detnil, det1, det3,
subjnil, subj1, subj3,
rootnil, root1, root3}

{detnil, det1, det2,
subjnil, subj1, subj2,
rootnil, root1, root2}

1. (if (= (cat (pos x)) det)
2. (if (= (cat (pos x)) noun)
(and (= (lab x) det)
(and (= (lab x) subj)
(< (pos x) (mod x))))
(< (pos x) (mod x))))

Apply Unary Constraints
Enforce Node Consistency:

3. (if (= (cat (pos x)) verb)
(and (= (lab x) root)
(= (mod x) nil)))

det
1

dog

eats

noun
2

verb
3

G

G

G
{subj3}

{det2, det3}

{rootnil}
rootnil

subj3
det2

1

det3

1

subj3

1

rootnil
det2

1

det3

1

(if (and (= (lab x) det)
(= (mod x) (pos y)))
(= (cat (pos y)) noun))

Apply Binary Constraints:


det
1

dog

eats

noun
2

G

verb
3

G

G
{subj3}

{det2, det3}

{rootnil}
rootnil

subj3
det2

1

det3

1

subj3

1

rootnil
det2

1

det3

0

Enforce Arc Consistency:


det
1

dog

eats

noun
2

verb
3

G

G

{det2}

{subj3}

G
{rootnil}

Figure 6: Using constraints parse sentence: dog eats.
248

fiMUSE CSP: Extension Constraint Satisfaction Problem

roles unary binary constraints satisfied assignment.
general, one parse sentence; hence, one
assignment values roles sentence. Note assignment example
sentence is:

pos word cat governor role's value
1 det
det-2
2 dog noun
subj-3
3 eats verb
root-nil
one possible sentence part speech words
known advance, parsing problem cast CSP. However,
ambiguity present written spoken sentences handled uniformly requires use
MUSE CSP.

2.2 Processing Lexically Ambiguous Sentences CDG
One shortcoming Maruyama's constraint-based parser requires word
single part speech; however, many words English language one
lexical category. assumption captured way Maruyama writes constraints
involving category information; category determined based position
word sentence. However, even simple example, word dog could
either noun verb prior propagation syntactic constraints. Since parsing
used lexically disambiguate sentence, ideally, parsing algorithm
require part speech words known prior parsing.
Lexically ambiguous words easily accommodated creating CSP
possible combination lexical categories; however, would combinatorially explosive.
contrast, using MUSE CSP, create separate word node legal part
speech word, sharing words ambiguous across segments. Since
position uniquely define category word, must allow category information
accessed role value rather position word sentence
(i.e., use (cat x) rather (cat (pos x))). associate category information
role value, could instead create role values lexical category word
store values single word node. However, representation
convenient MUSE CSP representation problem. lexically augmented
CSP, one role per word (this usually case), role values
associated one lexical category one role cannot support role values associated
another lexical category another role word. Additional constraints
must propagated enforce requirement. MUSE CSP representation
suffer problem. using separate node part speech, MUSE CSP
directly represents independence alternative lexical categories given word.
space requirements arc matrices MUSE representation lower
lexicalized CSP arc roles different lexical categories
word MUSE representation. Note MUSE arc consistency equivalent
performing arc consistency lexically augmented CSP (after additional constraints
249

fiHelzerman & Harper

propagated)2. importantly, MUSE CSP represent lattices cannot
combined single CSP.
technique creating separate nodes different instances word
used handle feature analysis (like number person) parsing (Harper & Helzerman,
1995b). Since words multiple feature values, often ecient create
single node set feature values, apply syntactic constraints, split node
set nodes single feature value prior applying constraints pertaining
feature type. Node splitting used support use context-specific
constraints (Harper & Helzerman, 1995b).

2.3 Lattice Example

Much motivation extending CSP comes work spoken language parsing
(Harper & Helzerman, 1995a; Harper, Jamieson, Zoltowski, & Helzerman, 1992; Zoltowski,
Harper, Jamieson, & Helzerman, 1992). output hidden-Markov-model-based
speech recognizer thought lattice word candidates. Unfortunately,
lattice contains many word candidates never appear sentence covering
duration speech utterance. converting lattice word graph, many word
candidates lattice eliminated. Figure 7 depicts word graph constructed
simple lattice. Notice word tour eliminated word graph
constructed. order accommodate words occur time intervals may
overlap, word's position lattice represented tuple (b; e)
b < e. positional relations defined constraints easily modified operate
tuples (Harper & Helzerman, 1995a).
construction, word graph often contains spurious sentence hypotheses
pruned using variety constraints (e.g., syntactic, semantic, etc.).
apply constraints individual sentences rule ungrammatical; however,
individually processing sentence hypothesis inecient since many high degree
similarity. spoken language parsing problem structured MUSE CSP problem,
constraints used parse individual sentences would applied word graph
sentence hypotheses, eliminating consideration many hypotheses
ungrammatical.
developed MUSE CSP constraint-based parser, PARSEC (Harper & Helzerman, 1995a, 1995b; Harper et al., 1992; Zoltowski et al., 1992), capable parsing
word graphs containing multiple sentences produced speech recognition module.
developed syntactic semantic constraints parsing single sentences,
applied word graph, eliminate hypotheses syntactically semantically
incorrect. MUSE CSP used parser thought parse forest
pruned using constraints. applying constraints wide variety knowledge
sources, parser prunes composite structure many role values associated
role, well word nodes remaining role values. Several experiments
(Harper et al., 1992; Zoltowski et al., 1992) considered effective syntactic
2. simple demonstration, consider merging nodes 3 4 Figure 5 single node
value e f keep track fact type 3 4, respectively. circumstances,
CSP arc consistency give results MUSE CSP arc consistency; even though c appear
solutions, eliminated. Note example uses one role per node.

250

fiMUSE CSP: Extension Constraint Satisfaction Problem

tour


wreck
hard


1



nice

beach


recognizes

2

3

4

5

wreck



(4,6)

(1,2)

hard

start


(1,2)

6

(2,3)

speech

7

8



nice

(6,7)

(7,8)

9

beach
(8,9)


(3,4)

end

recognizes
(4,8)

speech
(8,9)

Figure 7: Multiple sentence hypotheses parsed simultaneously applying constraints word graph rather individual sentences extracted
lattice.
semantic constraints pruning word nodes appear sentence hypothesis.
work speech processing, MUSE arc consistency algorithm effective
pruning role values composite structure never appear parse
sentence (i.e., individual CSP). Constraints usually tight enough MUSE
arc consistency eliminates role values participate least one parse
represented sentences.
MUSE CSP useful way process multiple sentences arc consistency
algorithm effective eliminating role values cannot appear sentence parses.
Several factors contribute effectiveness arc consistency algorithm
problem. First, syntactic constraints fairly tight constraints. Second, role
values contain segmental information constrain problem. Consider word
graph Figure 8. value s-(3,4) associated role marked N word
cannot support values role marked G word dogs position (3,5),
legal segment involving position (3,5). figure, mark
entries value associated one role segmentally incompatible values
another N. entries equivalent 0. Third, many times constraints
create symmetric dependencies words sentence. example, one constraint
might indicate verb needs subject left, another subject must
governed verb right.

2.4 Demonstration Utility MUSE CSP Parsing

demonstrate utility MUSE CSP simultaneously parsing multiple CSP instances,
consider problem determining strings length 3n consisting a's, b's, c's
251

fiHelzerman & Harper

obj(1,2) obj(2,3)
s(3,4)

N

N

s(3,5)

0

1

{obj(1,2),
obj(2,3)}

{rootnil}

G

start

N

G

N

N {npnil}

G
dogs
(3,5)

{s(3,4),
s(3,5)}

end

{blanknil}
{subj(2,3),
subj(3,4),
subj(3,5)}


(1,2)


(2,3)
{obj(1,2),
obj(2,3)}

G

N {np(1,2),
np(2,3)}
dog
(3,4)

obj(1,2) obj(2,3)
s(3,4)

0

1

s(3,5)

N

N

Figure 8: parsing word graphs, values assigned roles contain segmental
information make incompatible values associated
roles. example, s-(3,4) cannot support values associated
G N roles word dogs.
language bn cn . value n = 3, problem represented
single MUSE CSP problem shown Figure 9 (the roles role values depicted
simplify figure). devised constraints language (see Figure 10)
eliminate role values sentences language well ungrammatical
role values sentence language. constraints applied followed
MUSE arc consistency lattice Figure 9 length divisible three,
grammatical sentence remain single parse. lattices containing
sentences lengths divisible three, role values eliminated
MUSE arc consistency (there grammatical sentence). Hence, search
required extract parse one. n = 3 case Figure 9, parse appears
Figure 11. single parse result regardless n chosen. Note modifiees
role values parse used ensure a, corresponding
c; b, corresponding a; c, corresponding b. Figure
12 examines time needed extract parse sentences language bn cn
MUSE CSPs representing strings length 3n, 1 n 7, containing a, b, c.
time perform MUSE AC-1 extract solution compared time extract
solution without preprocessing. time perform MUSE AC-1 extract
parse stable sentence length grows, time extract parse grows quickly
sentence lengths greater 15 MUSE arc consistency used.
previous example involves grammar one parse single
sentence lattice; however, simple matter provide similar demonstrations
252

fiMUSE CSP: Extension Constraint Satisfaction Problem

start



















(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

(7,8)

(8.9)

(9,10)

b

b

b

b

b

b

b

b

b

(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

(7,8)

(8.9)

(9,10)

c

c

c

c

c

c

(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

c

c

c

(7,8)

(8.9)

(9,10)

end

Figure 9: single MUSE CSP simultaneously test possible orderings a's, b's,
c's membership language anbncn , n = 3.

2

= fa, b, cg
= fgovernorg
L2 = fa, b, cg
C2 = see below:
R2

; 3 Unary Constraints
(if (and (=
(=
(and (=
(>

(cat
(rid
(lab
(mod

x)
x)
x)
x)

a)
governor))
a)
(pos x))))

(if (and (=
(=
(and (=
(<

(cat
(rid
(lab
(mod

x)
x)
x)
x)

c)
governor))
c)
(pos x))))

(if (and (=
(=
(and (=
(<

(cat
(rid
(lab
(mod

x)
x)
x)
x)

b)
governor))
b)
(pos x))))

; 8 Binary Constraints
(if (and (= (lab x) a)
(or (= (lab y) b)
(= (lab y) c)))
(< (pos x) (pos y)))

(if (and (= (lab x) b)
(= (lab y) c))
(< (pos x) (pos y)))

(if (and (=
(=
(>
(< (mod

(lab x)
(lab y)
(pos x)
x) (mod

a)
a)
(pos y)))
y)))

(if (and (=
(=
(=
(= (lab

(if (and (=
(=
(>
(< (mod

(lab x)
(lab y)
(pos x)
x) (mod

b)
b)
(pos y)))
y)))

(if (and (= (lab x) b)
(= (mod x) (pos y))
(= (rid y) governor))
(= (lab y) a))

(if (and (=
(=
(>
(< (mod

(lab x)
(lab y)
(pos x)
x) (mod

c)
c)
(pos y)))
y)))

(if (and (=
(=
(=
(= (lab

(lab x) a)
(mod x) (pos y))
(rid y) governor))
y) c))

(lab x) c)
(mod x) (pos y))
(rid y) governor))
y) b))

Figure 10: G2 = h2; R2; L2; C2i accepts language bn cn , n 0.
253

fiHelzerman & Harper

pos
(1,2)
(2,3)
(3,4)
(4,5)
(5,6)
(6,7)
(7,8)
(8,9)
(9,10)

cat governor role's value



b
b
b
c
c
c

a-(9,10)
a-(8,9)
a-(7,8)
b-(3,4)
b-(2,3)
b-(1,2)
c-(6,7)
c-(5,6)
c-(4,5)

Figure 11: single parse remaining network depicted Figure 9 applying
constraints G2 enforcing MUSE arc consistency.

2500

CPU Time seconds

2000

Extract without MUSE AC1
1500

1000

500

Extract plus MUSE AC1
0
2

4

6

8

10

12
14
Lattice Length

16

18

20

22

Figure 12: graph depicts time extract parse language bn cn
MUSE CSP representing sentences length 3n, n varies 1
7. time extract parse without MUSE arc consistency compared
time perform MUSE AC-1 extract parse.

254

fiMUSE CSP: Extension Constraint Satisfaction Problem

3

= fa, b, cg
= fgovernorg
L3 = fw1, w2g
C3 = see below:
R3

; 2 Unary Constraints
(if (= (lab x) w1)
(< (pos x) (mod y)))

(if (= (lab x) w2)
(> (pos x) (mod y)))
; 6 Binary Constraints

(if (and (= (lab x) w1)
(= (lab y) w2))
(< (pos x) (pos y)))
(if (and (=
(=
(>
(> (mod

(lab x)
(lab y)
(pos x)
x) (mod

w1)
w1)
(pos y)))
y)))

(if (and (=
(=
(and (=
(=

(lab
(mod
(lab
(cat

w1)
(pos y)))
w2)
(cat y))))

x)
x)
y)
x)

(if (and (= (lab x) w1)
(= (lab y) w2))
(> (mod x) (mod y)))
(if (and (= (lab x) w2)
(= (lab y) w2)
(> (pos x) (pos y)))
(< (mod x) (mod y)))
(if (and (= (lab x) w2)
(= (mod x) (pos y)))
(= (lab y) w1))

Figure 13: G3 = h3 ; R3; L3; C3i accepts language ww.
complex cases. example, constraint grammar shown Figure 13
parse possible sentences given length language ww, w
fa; b; cg+. Consider MUSE CSP Figure 14 (the roles role values
depicted simplify figure). applying constraints performing MUSE arc
consistency MUSE CSP, precisely 81 strings ww,
parses compactly represented constraint network. constraints plus MUSE
arc consistency eliminate every value cannot appear parse. lattices containing
odd length sentences, role values remain MUSE arc consistency. Figure 15 shows
time needed extract parses sentences language ww
MUSE CSPs vary length w 1 8. time perform MUSE AC-1
extract parses grows slowly sentence length increases number parses
increases sentence length; however, grows slowly time extract
parses MUSE arc consistency used.
Similar results obtained grammars used parse word graphs constructed spoken sentences resource management ATIS domains (Harper
et al., 1992; Zoltowski et al., 1992; Harper & Helzerman, 1995a).

3. MUSE CSP Arc Consistency Algorithm
section, introduce algorithm, MUSE AC-1, achieve MUSE CSP arc consistency. algorithm builds upon AC-4 algorithm (Mohr & Henderson, 1986),
present algorithm first comparison purposes.
255

fiHelzerman & Harper

start

















(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

(7,8)

(8.9)

b

b

b

b

b

b

b

b

(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

(7,8)

(8.9)

c

c

c

c

c

c

(1,2)

(2,3)

(3,4)

(4,5)

(5,6)

(6,7)

c

c

(7,8)

(8.9)

end

Figure 14: single MUSE CSP simultaneously test possible orderings a's, b's,
c's membership language ww jwj = 4 .

3000

CPU Time seconds

2500

2000
Extract without MUSE AC1
1500

1000

500
Extract plus MUSE AC1
0
2

4

6

8
10
Lattice Length

12

14

16

Figure 15: graph depicts time extract parses language ww
MUSE CSP representing sentences length 2 16 w 2 fa; b; cg+.
time extract parses without MUSE arc consistency compared
time perform MUSE AC-1 extract parses.

256

fiMUSE CSP: Extension Constraint Satisfaction Problem

Notation

Meaning

ordered pair nodes.
node pairs (i; j ). (i; j ) 2 E , (j; i) 2 E .
E
ordered pair node label 2 Li .
(i; a)
faja 2 L (i; a) permitted constraints (i.e., admissible)g
Li
R2 (i; a; j; b) = 1 indicates admissibility 2 Li b 2 Lj given
R2 (i; a; j; b)
binary constraints.
Counter[(i; j ); a] number labels Lj compatible 2 Li .
(j; b) 2 [i; a] means 2 Li b 2 Lj simultaneously
[i; a]
admissible. implies supports b.
[i; a] = 1 indicates label admissible (and
[i; a]
already eliminated from) node i.
queue arc support deleted.
List
(i; j )

Figure 16: Data structures notation arc consistency algorithm, AC-4.

3.1 CSP Arc Consistency: AC-4
AC-4 builds maintains several data structures, described Figure 16, allow
eciently achieve arc consistency CSP. Note modified notation
slightly eliminate subscripts (which become quite cumbersome path consistency
algorithm). Figure 17 shows code initializing data structures, Figure 18
contains algorithm eliminating inconsistent labels domains. algorithm
requires (el2) time, e number constraint arcs, l domain size (Mohr
& Henderson, 1986).
AC-4, label 2 Li compatible b 2 Lj , supports b (and vice
versa). keep track much support label has, number labels Lj
compatible Li counted total stored Counter[(i; j ); a]
algorithm Figure 17. Counter[(i; j ); a] zero, removed Li
(because cannot appear solution), ordered pair (i; a) placed List,
M[i; a] set 1 (to avoid removing element Li once). algorithm
must keep track labels label supports using S[i; a], set arc
label pairs. example, S[i; a] = f(j; b); (j; c)g means Li supports b c Lj .
ever removed Li , b c loose support.
preprocessing step Figure 17, algorithm Figure 18 loops List
becomes empty, point CSP arc consistent. (i; a) popped List
procedure, element (j; b) S[i; a], Counter[(j; i); b] decremented.
Counter[(j; i); b] becomes zero, b would removed Lj , (j; b) placed List,
M[j; b] set 1.
257

fiHelzerman & Harper

1. List := ;
2. 2 N
3.
2 Li f
4.
[i; a] := ;
5.
[i; a] := 0; g
6. (i; j ) 2 E
7.
2 Li f
8.
Total := 0;
9.
b 2 Lj
10.
R2 (i; a; j; b) f
11.
Total := Total+1;
12.
[j; b] := [j; b] [ f(i; a)g; g
13.
Total = 0 f
14.
Li := Li , fag;
15.
List := List [ f(i; a)g;
16.
[i; a] := 1; g
17.
Counter[(i; j ); a] := Total; g

Figure 17: Initialization data structures AC-4.

1. List 6= f
2.
pop (i; a) List;
3.
(j; b) 2 S[i; a] f
4.
Counter[(j; i); b] := Counter[(j; i); b] , 1;
5.
Counter[(j; i); b] = 0 ^ [j; b] = 0 f
6.
Lj := Lj , fbg;
7.
List := List [ f(j; b)g;
8.
[j; b] := 1; g g g

Figure 18: Eliminating inconsistent labels domains AC-4.

258

fiMUSE CSP: Extension Constraint Satisfaction Problem

Next, describe MUSE arc consistency algorithm MUSE CSP, called MUSE
AC-1. purposely keep notation presentation MUSE AC-1 close possible
AC-4 reader benefit similarity two algorithms.

3.2 MUSE AC-1

MUSE arc consistency enforced removing labels Li violate conditions Definition 8. MUSE AC-1 builds maintains several data structures, described
Figure 19, allow eciently perform operation. Many data structures
borrowed AC-4, others exploit DAG representation MUSE CSP
determine values incompatible segments. Figure 22 shows
code initializing data structures, Figures 23 24 contain algorithm
eliminating inconsistent labels domains.
MUSE AC-1 AC-4, label node compatible label b node j ,
supports b. keep track much support label has, number labels Lj
compatible Li counted, total stored Counter[(i; j ); a].
CSP arc consistency, Counter[(i; j ); a] zero, would immediately removed
Li, would mean could never appear solution. However, MUSE
arc consistency, may case, even though participate
solution segments contain j , could another segment
would perfectly legal. label cannot become globally inadmissible
incompatible every segment. Hence, MUSE CSP, Counter[(i; j ); a] zero,
algorithm simply places [(i; j ); a] List records fact setting M[(i; j ); a] 1.
placing [(i; j ); a] List, algorithm indicating segments containing
j support label a.
MUSE AC-1 must keep track labels j label Li supports
using S[(i; j ); a], set node-label pairs. example, S[(i; j ); a] = f(j; b); (j; c)g means
Li supports b c Lj . ever invalid Li , b c loose
support.
DAG, MUSE AC-1 able use properties DAG identify
local (and hence eciently computable) conditions labels become globally
inadmissible. Segments defined paths MUSE CSP start end.
value associated variable supported variables precede
follow it, way value used segment,
deleted arc consistency algorithm. addition, value variable's domain
supported constraints values associated second variable, second
variable preceded followed variables values supporting value,
solution involves path variables MUSE DAG, value cannot
supported segment involving two variables. two ideas provide basis
remaining data structures used MUSE AC-1.
Consider Figure 20, shows nodes adjacent node DAG.
every segment DAG contains node represented directed path
DAG going node i, either node j node k must every segment containing
i. Hence, label remain Li, must compatible least one label
either Lj Lk . Also, either n must contained every segment containing
259

fiHelzerman & Harper

Notation

Meaning

(i; j )

ordered pair nodes.
node pairs (i; j ) exists path directed edges G
j . (i; j ) 2 E , (j; i) 2 E .
ordered pair node label 2 Li .

E

(i; a)
[(i; j ); a]

ordered pair node pair (i; j ) label 2 Li .
faja 2 L (i; a) permitted constraints (i.e., admissible)g

Li

2 (i; a; j; b)

R

Counter[(i; j ); a]
S[(i; j ); a]
M[(i; j ); a]
List

G

Next-Edgei
Prev-Edgei
Local-Prev-Support(i; a)
Local-Next-Support(i; a)
Prev-Support[(i; j ); a]
Next-Support[(i; j ); a]

2 (i; a; j; b) = 1 indicates admissibility 2 Li b 2 Lj given
binary constraints.
number labels Lj compatible 2 Li .
(j; b) 2 [(i; j ); a] means 2 Li b 2 Lj simultaneously
admissible. implies supports b.
M[(i; j ); a] = 1 indicates label admissible (and
already eliminated from) segments containing j .
queue arc support deleted.
G set node pairs (i; j ) exists directed
edge j .
Next-Edgei contains node pairs (i; j ) exists
directed edge (i; j ) 2 G. contains (i; end) last node
segment.
Prev-Edgei contains node pairs (j; i) exists
directed edge (j; i) 2 G. contains (start; i) first node
segment.
set elements (i; j ) (j; i) 2 Prev-Edgei , j 6= start,
must compatible least one j 's labels.
Local-Prev-Support(i; a) becomes empty, longer admissible.
set elements (i; j ) (i; j ) 2 Next-Edgei , j 6= end,
must compatible least one j 's labels.
Local-Next-Support(i; a) becomes empty, longer admissible.
(i; k) 2 Prev-Support[(i; j ); a] implies (k; j ) 2 Prev-Edgej ,
k 6= start, 2 Li compatible least one j 's
one k's labels. Prev-Support[(i; j ); a] becomes empty,
longer admissible segments containing j .
(i; k) 2 Next-Support[(i; j ); a] implies (j; k) 2 Next-Edgej ,
k 6= end, 2 Li compatible least one j 's
one k's labels. Next-Support[(i; j ); a] becomes empty,
longer admissible segments containing j .
R

Figure 19: Data structures notation MUSE AC-1.

260

fiMUSE CSP: Extension Constraint Satisfaction Problem

n

j




k
{...,a,...}

LocalPrevSupport(i,a) = {(i,n),(i,m)}
LocalNextSupport(i,a) = {(i,j)}

Figure 20: Local-Prev-Support Local-Next-Support example DAG. sets indicate label allowed every segment contains n, m, j ,
disallowed every segment contains k. solid directed lines
members G, solid undirected lines represent members E .

i, label remain Li, must compatible least one label either
Ln Lm .
order track dependency, two sets maintained label node i,
Local-Next-Support(i; a) Local-Prev-Support(i; a). Local-Next-Support(i; a) set
ordered node pairs (i; j ) (i; j ) 2 Next-Edgei , (i; j ) 2 E , least one
label b 2 Lj compatible a. Local-Prev-Support(i; a) set ordered pairs
(i; j ) (j; i) 2 Prev-Edgei , (i; j ) 2 E , least one label b 2 Lj
compatible a. Dummy ordered pairs created handle cases node
beginning end network: (start; i) 2 Prev-Edgei , (i; start) added
Local-Prev-Support(i; a), (i; end) 2 Next-Edgei , (i; end) added Local-NextSupport(i; a). prevent label ruled nodes precede
follow DAG. Whenever one i's adjacent nodes, j , longer labels b
domain compatible a, (i; j ) removed Local-PrevSupport(i; a) Local-Next-Support(i; a), depending whether edge j
j , respectively. either Local-Prev-Support(i; a) Local-Next-Support(i; a)
becomes empty, longer part MUSE arc consistent instance,
eliminated Li . Figure 20, label admissible segments containing
j , segments containing k. constraints,
labels j become inconsistent i, (i; j ) would eliminated Local-NextSupport(a; i), leaving empty set. case, would longer supported

segment.
algorithm utilize similar conditions nodes directly connected
Next-Edgei Prev-Edgei . Consider Figure 21. Suppose label node
compatible label Lj , incompatible labels Lx Ly ,
reasonable eliminate segments containing j , segments
would include either node x . determine whether label admissible
set segments containing j , calculate Prev-Support[(i; j ); a] NextSupport[(i; j ); a] sets. Next-Support[(i; j ); a] includes (i; k) arcs support
261

fiHelzerman & Harper

z
{...,a,...}

x
j

w



Figure 21: Next-Edgej = f(j; x); (j; )g; Counter[(i; x); a] = 0, Counter[(i; ); a] = 0,
inadmissible every segment containing j . solid directed lines members G, solid undirected lines represent members
E .
given directed edge j k, (i; j ) supports a. Prev-Support[(i; j ); a]
includes (i; k) arcs support given directed edge k
j , (i; j ) supports a. Note Prev-Support[(i; j ); a] contain ordered pair
(i; j ) (i; j ) 2 Prev-Edgej , Next-Support[(i; j ); a] contain ordered pair (i; j )
(j; i) 2 Next-Edgej . elements included edge nodes
j sucient allow j 's labels support segment containing j . Dummy
ordered pairs created handle cases node beginning end
network: (start; j ) 2 Prev-Edgej , (i; start) added Prev-Support[(i; j ); a],
(j; end) 2 Next-Edgej , (i; end) added Next-Support[(i; j ); a]. prevent
label ruled nodes precede follow DAG.
Figure 22 shows Prev-Support, Next-Support, Local-Next-Support, Local-PrevSupport sets initialization algorithm creates simple example DAG.
initialization step, sets contain node pairs allowed based connectivity G. Later, consistency step node pairs support
associated label eliminated set.
illustrate data structures used second step MUSE AC-1 shown
Figure 23, consider happens initially [(1; 3); a] 2 List MUSE CSP depicted
Figure 22. [(1; 3); a] placed List indicate label L1 supported
labels associated node 3. value popped List, necessary
(3; x) 2 S[(1; 3); a] decrement Counter[(3; 1); x] one. Counter[(3; 1); x]
becomes 0, [(3; 1); x] already placed List, added future
processing. done, necessary remove [(1; 3); a]'s uence MUSE
DAG. handle this, examine two sets Prev-Support[(1; 3); a] = f(1; 2); (1; 3)g
262

fiMUSE CSP: Extension Constraint Satisfaction Problem

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.

List := ;
E := f(i; j )j9 2 : i; j 2 ^ 6= j ^ i; j 2 N g;
(i; j) 2 E
2 Li f
S[(i; j ); a] := ;
M[(i; j ); a] := 0;
Local-Prev-Support(i; a) := ; Local-Next-Support(i; a) := ;
Prev-Support[(i; j ); a] := ; Next-Support[(i; j ); a] := ; g
(i; j) 2 E
2 Li f

Total := 0;

b 2 Lj
R2 (i; a; j; b) f

Total := Total+1;
S[(j; i); b] := S[(j; i); b] [ f(i; a)g; g
Total=0 f
List := List [ f[(i; j ); a]g;
M[(i; j ); a] := 1; g
Counter[(i; j ); a] := Total;
Prev-Support[(i; j ); a] := f(i; x)j(i; x) 2 E ^ (x; j ) 2 Prev-Edgej g
[ f(i; j )j(i; j ) 2 Prev-Edgej g
[ f(i; start)j(start; j ) 2 Prev-Edgej g;
Next-Support[(i; j ); a] := f(i; x)j(i; x) 2 E ^ (j; x) 2 Next-Edgej g
[ f(i; j )j(j; i) 2 Next-Edgej g
[ f(i; end)j(j; end) 2 Next-Edgej g;
Local-Prev-Support(i; a) := f(i; x)j(i; x) 2 E ^ (x; i) 2 Prev-Edgei g
[ f(i; start)j(start; i) 2 Prev-Edgei g;
Local-Next-Support(i; a) := f(i; x)j(i; x) 2 E ^ (i; x) 2 Next-Edgei g
[ f(i; end)j(i; end) 2 Next-Edgei g; g
{c}

2

start

1

3

{a,b}

end
{d}

Prev-Support[(1; 2);a] = f(1; 2)g
Prev-Support[(1; 3);a] = f(1; 2); (1; 3)g
Prev-Support[(1; 2);b] = f(1; 2)g
Prev-Support[(1; 3);b] = f(1; 2); (1; 3)g
Prev-Support[(2; 1);c] = f(2; start)g
Prev-Support[(2; 3);c] = f(2; 3); (2; 1)g
Prev-Support[(3; 1);d] = f(3; start)g
Prev-Support[(3; 2);d] = f(3; 1)g
Local-Prev-Support(1;a) = f(1; start)g
Local-Prev-Support(1;b) = f(1; start)g
Local-Prev-Support(2;c) = f(2; 1)g
Local-Prev-Support(3;d) = f(3; 1); (3; 2)g

Next-Support[(1; 2);a] = f(1; 3)g
Next-Support[(1; 3);a] = f(1; end)g
Next-Support[(1; 2);b] = f(1; 3)g
Next-Support[(1; 3);b] = f(1; end)g
Next-Support[(2; 1);c] = f(2; 1); (2; 3)g
Next-Support[(2; 3);c] = f(2; end)g
Next-Support[(3; 1);d] = f(3; 1); (3; 2)g
Next-Support[(3; 2);d] = f(3; 2)g
Local-Next-Support(1;a) = f(1; 2); (1; 3)g
Local-Next-Support(1;b) = f(1; 2); (1; 3)g
Local-Next-Support(2;c) = f(2; 3)g
Local-Next-Support(3;d) = f(3; end)g

Figure 22: Initialization data structures MUSE AC-1 along simple example.
263

fiHelzerman & Harper

1. List 6= f
2.
Pop [(i; j ); a] List;
3.
(j; b) 2 S[(i; j ); a] f
4.
Counter[(j; i); b] := Counter[(j; i); b] , 1;
5.
Counter[(j; i); b] = 0 ^ M[(j; i); b] = 0 f
6.
List := List [ f[(j; i); b]g;
7.
M[(j; i); b] := 1; g g
8.
Update-Support-Sets([(i; j ); a]); (see Figure 24) g

Figure 23: Eliminating inconsistent labels domains MUSE AC-1.
Update-Support-Sets ([(i; j ); a]) f
1. (i; x) 2 Prev-Support[(i; j ); a] ^ x 6= j ^ x 6= start f
2.
Prev-Support[(i; j ); a] := Prev-Support[(i; j ); a] , f(i; x)g ;
3.
Next-Support[(i; x); a] := Next-Support[(i; x); a] , f(i; j )g;
4.
Next-Support[(i; x); a] = ^ M[(i; x); a] = 0 f
5.
List := List [ f[(i; x); a]g;
6.
M[(i; x); a] := 1; g g
7. (i; x) 2 Next-Support[(i; j ); a] ^ x 6= j ^ x 6= end f
8.
Next-Support[(i; j ); a] := Next-Support[(i; j ); a] , f(i; x)g;
9.
Prev-Support[(i; x); a] := Prev-Support[(i; x); a] , f(i; j )g;
10.
Prev-Support[(i; x); a] = ^ M[(i; x); a] = 0 f
11.
List := List [ f[(i; x); a]g;
12.
M[(i; x); a] := 1; g g
13. (j; i) 2 Prev-Edgei
14. Local-Prev-Support(i; a) := Local-Prev-Support(i; a) , f(i; j )g;
15. Local-Prev-Support(i; a) = f
16. Li := Li , fag;
17. (i; x) 2 Local-Next-Support(i; a) ^ x 6= j ^ x 6= end f
18.
Local-Next-Support(i; a) := Local-Next-Support(i; a) , f(i; x)g;
19.
M[(i; x); a] = 0 f
20.
List := List [ f[(i; x); a]g;
21.
M[(i; x); a] := 1; g g g
22. (i; j ) 2 Next-Edgei
23. Local-Next-Support(i; a) := Local-Next-Support(i; a) , f(i; j )g;
24. Local-Next-Support(i; a) = f
25. Li := Li , fag;
26. (i; x) 2 Local-Prev-Support(i; a) ^ x 6= j ^ x 6= start f
27.
Local-Prev-Support(i; a) := Local-Prev-Support(i; a) , f(i; x)g;
28.
M[(i; x); a] = 0 f
29.
List := List [ f[(i; x); a]g;
30.
M[(i; x); a] := 1; g g g g

Figure 24: function Update-Support-Sets([(i; j ); a]) MUSE AC-1.
264

fiMUSE CSP: Extension Constraint Satisfaction Problem

Next-Support[(1; 3); a] = f(1; end)g. Note value (1; end) Next-Support[(1; 3); a]
value (1; 3) Prev-Support[(1; 3); a], require action
dummy values. However, value (1; 2) Prev-Support[(1; 3); a] indicates (1; 3)
member Next-Support[(1; 2); a], since admissible (1; 3), (1; 3)
removed Next-Support[(1; 2); a], leaving empty set. Note NextSupport[(1; 2); a] empty, assuming M[(1; 2); a] = 0, [(1; 2); a] added List
processing. Next, (1; 3) removed Local-Next-Support(1; a), leaving set
f(1; 2)g. next iteration loop [(1; 2); a] popped List.
Prev-Support[(1; 2); a] Next-Support[(1; 2); a] processed, Next-Support[(1; 2); a] =
Prev-Support[(1; 2); a] contains dummy, requiring action. Finally, (1; 2)
removed Local-Next-Support(1; a), set becomes empty, longer compatible segment containing node 1 eliminated consideration
possible label node 1. eliminated node 1, necessary remove
support 2 L1 labels nodes precede node 1, nodes x
(1; x) 2 Local-Prev-Support(1; a). Since Local-Prev-Support(1; a) = f(1; start)g,
start dummy node, work done.
contrast, consider happens initially [(1; 2); a] 2 List MUSE CSP
Figure 22. case, Prev-Support[(1; 2); a] contains (1; 2) requires additional
work; whereas, Next-Support[(1; 2); a] contains (1; 3), indicating (1; 2) must removed
Prev-Support[(1; 3); a]'s set. removal, Prev-Support[(1; 3); a] non-empty,
segment containing nodes 1 3 still supports label L1. reason
two cases provide different results constraint arc nodes 1 3
contained every segment; whereas, constraint arc nodes 1 2 found
one them.

3.3 Running Time Space Complexity MUSE AC-1
worst-case running time routine initialize MUSE AC-1 data structures
(in Figure 22) O(n2 l2 + n3 l), n number nodes MUSE CSP l
number labels. Given number (i; j ) elements E O(n2 )
domain size O(l), size Counter arrays O(n2 l). determine
number supporters given arc-label pair requires O(l) work; hence, initializing
Counter arrays requires O(n2 l2) time. However, O(n2 l) Prev-Support
Next-Support sets, Prev-Support[(i; j ); a] Next-Support[(i; j ); a] requires
O(n) time compute, time calculate Prev-Support Next-Support sets
O(n3 l). Finally, time needed calculate Local-Next-Support Local-PrevSupport sets O(n2 l) O(nl) sets O(n) elements per set.
worst-case running time algorithm prunes labels MUSE
arc consistent (in Figures 23 24) operates O(n2 l2 + n3 l) time. Clearly
Counter array contains O(n2 l) entries (a similar argument made array)
keep track algorithm. Counter[(i; j ); a] l magnitude,
never become negative, maximum running time line 4 Figure 23
(given elements appear List M) O(n2 l2).
O(n2 l) Next-Support Prev-Support lists, O(n) size, maximum
running time required lines 3 9 Figure 24 O(n3 l). Finally, since O(nl)
265

fiHelzerman & Harper

Approach
CSPs
MUSE CSP

Nodes
Degree
Number
Number
per Path Node splitting Constraint Networks Nodes

n
n

kn

k
k

1

n
kn

Asymptotic
Time

kn n2 l2
2
(kn) l2 + (kn)3 l

Table 1: Comparison space time complexity MUSE arc consistency
MUSE CSP arc consistency multiple CSPs representing node splitting
problem (e.g., lexical ambiguity parsing).
Local-Prev-Support Local-Next-Support sets eliminate O(n) elements,
maximum running time lines 14 23 Figure 24 O(n2 l). Hence, maximum
running time MUSE CSP arc consistency algorithm O(n2 l2 + n3 l).
space complexity MUSE CSP AC-1 O(n2 l2 + n3 l) arrays
Counter contain O(n2 l) elements, O(n2 l) sets, containing O(l)
items; O(n2 l) Prev-Support Next-Support sets, containing O(n) items; O(nl)
Local-Next-Support Local-Prev-Support sets, containing O(n) items.
comparison, worst-case running time space complexity CSP arc consistency O(n2 l2), assuming n2 constraint arcs. Note applications
l = n, worst-case running times algorithms order (this
true parsing spoken language MUSE CSP). Also, representable planar
DAG (in terms Prev-Edge Next-Edge, E), running times two
algorithms order average number values Prev-Support
Next-Support would constant. hand, compare MUSE CSP
use multiple CSPs problems k alternative variables particular
variable CSP, MUSE CSP AC-1 asymptotically attractive, shown
Table 1.

3.4 Correctness MUSE AC-1

Next prove correctness MUSE AC-1.
Theorem 1 label eliminated Li MUSE AC-1 label
unsupported arcs (i; x) every segment.

Proof:
1. must show label eliminated, inadmissible every segment.
label eliminated domain MUSE AC-1 (see lines 16 25 Figure 24)
Local-Prev-Support set Local-Next-Support set becomes empty
(see lines 15 24 Figure 24). either case, label eliminated
make MUSE CSP instance MUSE arc consistent. prove label's
local support sets become empty, label cannot participate MUSE arc
consistent instance MUSE CSP. proven Local-Next-Support (LocalPrev-Support follows symmetry.) Observe 2 Li , unsupported
266

fiMUSE CSP: Extension Constraint Satisfaction Problem

nodes immediately follow DAG, cannot participate
MUSE arc consistent instance MUSE CSP. line 23 Figure 24, (i; j )
removed Local-Next-Support(i; a) set [(i; j ); a] must popped
List. removal (i; j ) Local-Next-Support(i; a) indicates that,
segment containing j , 2 Li inadmissible. remains shown
[(i; j ); a] put List 2 Li unsupported every segment contains
j . proven induction number iterations loop
Figure 23.
Base case: initialization routine puts [(i; j ); a] List 2 Li incompatible every label Lj (line 17 Figure 22). Therefore, 2 Li unsupported
segments containing j .
Induction step: Assume start kth iteration loop
[(x; ); c] ever put List indicate c 2 Lx inadmissible
every segment contains x . remains show kth
iteration, [(i; j ); a] put List, 2 Li unsupported every segment
contains j . several ways new [(i; j ); a] put
List:
(a) labels Lj compatible 2 Li eliminated.
item could placed List either initialization (see line 17
Figure 22) previous iteration loop (see line 6 Figure
23)), CSP AC-4 algorithm. obvious that, case, 2 Li
inadmissible every segment containing j .
(b) Prev-Support[(i; j ); a] = (see line 10 Figure 24) indicating 2 Li
incompatible nodes k (k; j ) 2 Prev-Edgej . way
[(i; j ); a] placed List reason (at line 11) tuples
form [(i; k); a] (where (k; j ) 2 Prev-Edgej ) already put List.
induction hypothesis, [(i; k); a] items placed List
2 Li inadmissible segments containing k DAG.
supported node immediately precedes j DAG,
unsupported every segment contains j . Therefore, correct
put [(i; j ); a] List.
(c) Next-Support[(i; j ); a] = (see line 4 Figure 24) indicating 2 Li
incompatible nodes k (j; k) 2 Next-Edgej . way [(i; j ); a]
placed List (at line 5) reason tuples form
[(i; k); a] (where (j; k) 2 Next-Edgej ) already put List. induction
hypothesis, [(i; k); a] items placed List 2 Li inadmissible segments containing k DAG. supported
node immediately follows j DAG, inadmissible
every segment contains j . Therefore, correct put [(i; j ); a] List.
(d) Local-Next-Support(i; a) = (see line 24 Figure 24) indicating 2 Li
incompatible nodes k (i; k) 2 Next-Edgei . way
[(i; j ); a] placed List (at line 29) reason node
follows DAG supports a, pairs (i; k) legally removed
267

fiHelzerman & Harper





1

...

1

...

c

...

b

...

Local_Prev_Support(i,a) = {(i,j),...}
Local_Next_Support(i,a) = {(i,k},...}

j



k

{b,...}

Prev_Support[(i,j),a] nonempty
{c,...}

{a,...}
c

Prev_Support[(i,k),a] = {(i,k),...}

...

Next_Support[(i,k),a] nonempty

1

b

...

Next_Support[(i,j),a] = {(i,j),...}

1

Figure 25: 2 Li MUSE AC-1, must preceded node j followed
node k support a.
Local-Next-Support(i; a) previous iterations.
segment containing supports a, follows segment containing
j supports label.
(e) Local-Prev-Support(i; a) = (see line 15 Figure 24) indicating 2 Li
incompatible nodes k (k; i) 2 Prev-Edgei . way
[(i; j ); a] placed List (at line 20) reason node
precedes DAG supports a, pairs (i; k) legally
removed Local-Prev-Support(i; a) previous iterations.
segment containing supports a, follows segment containing
j supports label.
beginning (k + 1)th iteration loop, every [(x; ); c] List
implies c supported segment contains x . Therefore,
induction, true iterations loop Figure 23. Hence,
label's local support sets become empty, label cannot participate MUSE arc
consistent instance MUSE CSP.
2. must show eliminated Li MUSE arc consistency
algorithm, must MUSE arc consistent. MUSE arc consistent,
must exist least one path start end goes node
nodes n path contain least one label compatible
2 Li . deleted MUSE AC-1, Local-Next-Support(i; a) 6=
Local-Prev-Support(i; a) 6= . Hence, must preceded followed least
one node supports 2 Li ; otherwise, would deleted. depicted
Figure 25, know must node j precedes that,
start, must contain least one label b supports a, NextSupport[(i; j ); a] Prev-Support[(i; j ); a] must non-empty. Similarly, must
node k follows that, end, must contain least one
label c supports a, Next-Support[(i; k); a] Prev-Support[(i; k); a] must
non-empty.
268

fiMUSE CSP: Extension Constraint Satisfaction Problem

show path DAG, must show path beginning
start reaches nodes along path support 2 Li ,
path beginning reaches end nodes along
path support 2 Li . show necessity path end
nodes along path support 2 Li given remains MUSE AC-1;
necessity path start shown similar way.
Base case: 2 Li MUSE AC-1, must exist least one node
follows i, say k, [(i; k); a] never placed List. Hence,
R2 (i; a; k; c) = 1 least one c 2 Lk Next-Support[(i; k); a] PrevSupport[(i; k); a] must non-empty.
Induction Step: Assume path n nodes follows supports
2 Li, none nodes end node. implies n
nodes contains least one label compatible Next-Support[(i; n); a]
Prev-Support[(i; n); a] must non-empty n nodes.
Next, show path length (n + 1) must support 2 Li ; otherwise,
label would deleted MUSE AC-1. already noted
nth node path induction step, Next-Support[(i; n); a] must
non-empty; hence, must exist least one node, say n0 , follows nth
node path length n supports 2 Li . n0 end node,
case. n0 end, way (i; n0) member
Next-Support[(i; n); a] [(i; n0); a] placed List. hasn't,
R2 (i; a; n0; l) = 1 least one l 2 Ln Next-Support[(i; n0); a] PrevSupport[(i; n0); a] must non-empty. case, (i; n0) would
removed Next-Support[(i; n); a], n would longer support 2 Li .
Hence, 2 Li MUSE AC-1, must path nodes end
node n end node, R2 (i; a; n; l) = 1 least one l 2 Ln
Next-Support[(i; n); a] Prev-Support[(i; n); a] must non-empty. Hence
MUSE arc consistent.
0

2

theorem, may conclude MUSE AC-1 builds largest MUSE arc
consistent structure. MUSE arc consistency takes account segments,
single CSP selected MUSE CSP MUSE arc consistency enforced,
CSP arc consistency could eliminate additional labels.

3.5 Profile MUSE AC-1

Given fact MUSE AC-1 operates composite data structure, benefits
using algorithm high payoff individually processing CSPs. section 2.4,
provided several examples payoff obvious. gain insight factors
uencing effectiveness MUSE CSP, conducted experiment
randomly generate MUSE CSP instances two different graph topologies. tree
topology characterized two parameters: branching factor (how many nodes follow
non-leaf node tree) path length (how many nodes path
root node leaf node). lattice topology characteristic MUSE CSP
269

fiHelzerman & Harper

produced hidden-Markov-model-based spoken language recognition system
constraint-based parser. Lattices characterized length
branching factor.
experiment, examined trees path length four branching
factor two three, lattices path length four branching factor
two three. initialized variable either 3 6 labels. randomly
generated constraints network, varying probability R2 (i; a; j; b) = 1
0.05 .95 steps 0.05. probability, 6 instances generated. lower
probability R2 (i; a; j; b) = 1, tighter constraints. Note probability
constraint two nodes understood probability constraint
two nodes given constraint allowed them. example, nodes
level tree topology different segments, constraints
cannot occur them.
results experiment displayed Figures 26 27. four
panels figure, four curves displayed. MUSE AC-1 appears curves
displaying average number labels remaining MUSE AC-1 applied instances
MUSE CSP probability constraint varies. curves labeled Solution
indicate average number labels remaining MUSE AC-1 used
solution. CSP AC associated curves display number labels remain
least one segment segment extracted MUSE CSP CSP
arc consistency applied. Unused indicates difference number labels
remain MUSE AC-1 number CSP arc consistent least one
segment.
topologies, probability R2 (i; a; j; b) = 1 low (e.g., .1) high
(e.g., .8), MUSE AC-1 tracks performance arc consistency performed
individual instances either topology. However, topology impact range
low high probabilities true. constraints randomly generated,
MUSE AC-1 performed, tree topology fewer remaining values lattice
topology CSP arc consistent. results suggest MUSE CSP AC-1 may
effective topologies others. However, tree topology
randomly generated constraints values two variables independent
probabilities generated. case lattice; pair variables
set randomly generated constraints, shared paths lattice.
Notice increasing number values domain seems impact
tree increasing branching factor, probably branching factor
increases, number independent nodes.
experiment show problem tightly constrained, MUSE AC-1
effectively used eliminate values unsupported constraints. Clearly,
case parsing problems presented section 2.4. small set syntactic
constraints effectively eliminates values never used parse sentence,
even lattice branching factor three arbitrarily long paths.
270

fiMUSE CSP: Extension Constraint Satisfaction Problem

a. Tree branching factor 2, path length 4, 3 labels per variable, 15 variables.

b. Tree branching factor 3, path length 4, 3 labels per variable, 90 variables.
3

Average number role values per role 3

Average number role values per role 3

3

2.5
MUSE AC1
2

CSP AC

1.5

Solution

1

0.5

2.5
MUSE AC1
2

CSP AC

1.5
Solution
1

0.5
Unused

Unused
0
0

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

0
0

1

c. Tree branching factor 2, path length 4, 6 labels per variable, 15 variables.

0.2

0.3

0.8

0.9

1

Average number role values per role 6

6

5
MUSE AC1
4

CSP AC
3

2
Solution
1

5

4

MUSE AC1
CSP AC

3

Solution

2

1

Unused
0
0

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

d. Tree branching factor 3, path length 4, 6 labels per variable, 90 variables.

6

Average number role values per role 6

0.1

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

Unused
0.8

0.9

0
0

1

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

1

Figure 26: Simulation results trees path length 4, branching factor 2
3, 3 6 labels per variable.

271

fiHelzerman & Harper

a. Lattice branching factor 2, path length 4, 3 labels per variable, 8 variables.

b. Lattice branching factor 3, path length 4, 3 labels per variable, 12 variables.

3

3
MUSE AC1

Average number role values per role 3

Average number role values per role 3

CSP AC
MUSE AC1

2.5

2
Solution
1.5

1

0.5
Unused

0
0

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

2

Solution

1.5

1

Unused
0.5

0
0

1

c. Lattice branching factor 2, path length 4, 6 labels per variable, 8 variables.

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

1

d. Lattice branching factor 3, path length 4, 6 labels per variable, 12 variables.

6

6
MUSE AC1

MUSE AC1

Average number role values per role 6

Average number role values per role 6

CSP AC

2.5

CSP AC

5

4
Solution
3

2

1

5
CSP AC

4
Solution
3

2

Unused

1

Unused
0
0

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

0
0

1

0.1

0.2

0.3

0.4
0.5
0.6
0.7
Probability R2(i,a,j,b)=1

0.8

0.9

1

Figure 27: Simulation results lattices path length 4, branching factor 2
3, 3 6 labels per variable.

272

fiMUSE CSP: Extension Constraint Satisfaction Problem

Local-Next-Support(B, b1) = {(B, E)}
Local-Next-Support(B, b2) = {(B, C), (B, E)}
Local-Next-Support(B, b3) = {(B, C)}

Next-Support[(B, C), b3] = {(B, D)}
Next-Support[(B, C), b2] = {(B, F)}

C
{c1}

start


{a1}


{d1}

B

end

{b1, b2, b3}
{e1}

{f1}

E

F

Figure 28: Using MUSE arc consistency data structures guide backtracking search.

3.6 Extracting Solutions MUSE CSP MUSE AC-1
Solutions regular CSP problems typically generated using backtracking (or fancier
search algorithms) assemble set labels, one node, consistently
admissible. Extracting solutions MUSE CSPs done similar way,
desirable make modifications search algorithms take advantage
extra information contained MUSE AC-1 data structures.
Consider example shown Figure 28. figure presents simple MUSE CSP.
Suppose interested solutions segment highlighted: fA, B, C,
Dg. Suppose one solution segment: a1 A, b3 B, c1
C, d1 D. wish find solution depth-first search.
begin assigning a1 A. However, domain B, addition desired
label b3, contains labels b1 b2, valid segments.
initially (and naively) choose b1 B continue depth-first search, would
waste lot time backtracking. Fortunately, enforcing MUSE arc consistency,
MUSE data structures contain useful information concerning segments
labels valid. case, backtracking algorithm check Local-Next-Support(B,
b1) determine outgoing nodes b1 compatible with. Since (B, C)
element Local-Next-Support(B, b1), smart search algorithm would choose b1
label B.
However, looking local support sets might enough. search
algorithm rejected b1 label B, would go consider b2. Local-NextSupport(B, b2) indicates b2 valid label segments contain
C, fails tell us b2 valid segment examining. Despite
this, search algorithm still eliminate b2 looking Next-Support[(B, C), b2],
indicates b2 compatible segments containing node F. Clearly,
type information effectively guide search solution along certain
path. Improved search strategies MUSE CSPs focus future research efforts.
273

fiHelzerman & Harper

4. MUSE CSP Path Consistency Algorithm
section, introduce algorithm achieve MUSE CSP path consistency, MUSE
PC-1, builds upon PC-4 algorithm (Han & Lee, 1988).

4.1 MUSE PC-1

MUSE path consistency enforced setting R2 (i; a; j; b) false violates
conditions Definition 9. MUSE PC-1 builds maintains several data structures comparable data structures defined MUSE AC-1, described Figure 29, allow
eciently perform operation. Figure 32 shows code initializing data structures, Figures 33 34 contain algorithm eliminating MUSE path inconsistent
binary constraints.
MUSE PC-1 must keep track labels Lk support R2 (i; a; j; b). keep track
much path support R2 (i; a; j; b) has, number labels Lk satisfy
R2 (i; a; k; c) R2 (k; c; j; b) counted using Counter[(i; j ); k; a; b]. Additionally,
algorithm must keep track set S[(i; j ); k; a; b], contains members form
(k; c) R2 (i; a; k; c) R2 (k; c; j; b) supported R2 (i; a; j; b). R2 (i; a; j; b)
ever becomes false segment containing i, j , k, R2 (i; a; k; c) R2 (k; c; j; b)
loose support. MUSE PC-1 uses Local-Next-Support, Local-PrevSupport, Prev-Support, Next-Support sets similar MUSE AC-1.
MUSE PC-1 able use properties DAG identify local (and hence
eciently computable) conditions binary constraints fail lack path
support. Consider Figure 30, shows nodes adjacent node j
DAG. every segment DAG contains node j represented
directed path DAG going node node j , node must precede
follow nodes j R2 (i; a; j; b) hold. order track dependency, two sets
maintained [(i; j ); a; b] tuple: Local-Prev-Support[(i; j ); a; b] Local-NextSupport[(i; j ); a; b]. Note distinguish Local-Prev-Support[(i; j ); a; b] LocalPrev-Support[(j; i); b; a] separately keep track elements directly preceding
directly preceding j . distinguish Local-Next-Support[(i; j ); a; b] LocalNext-Support[(j; i); b; a]. sets become empty, (i; j ) arc
longer support R2 (i; a; j; b). Local-Prev-Support[(i; j ); a; b] set ordered node pairs
(i; x) (x; i) 2 Prev-Edgei , (i; x) 2 E , least one label 2 Lx
compatible R2 (i; a; j; b). Local-Next-Support[(i; j ); a; b] set ordered
node pairs (i; x) (i; x) 2 Next-Edgei , (i; x) 2 E , least one label
2 Lx compatible R2 (i; a; j; b). Dummy ordered pairs created
handle cases node beginning end network: (start; i) 2 PrevEdgei , (i; start) added Local-Prev-Support[(i; j ); a; b], (i; end) 2 Next-Edgei ,
(i; end) added Local-Next-support[(i; j ); a; b].
algorithm utilize similar conditions nodes may directly connected j . Consider Figure 31. Suppose R2 (i; a; j; b) compatible
label Lk , incompatible labels Lx Ly , R2 (i; a; j; b)
R2 (j; b; i; a) false segments containing i, j , k segments would
include either node x . determine whether constraint admissible
set segments containing i, j , k, calculate Prev-Support[(i; j ); k; a; b], Prev274

fiMUSE CSP: Extension Constraint Satisfaction Problem

Notation

Meaning
ordered pair nodes.

(i; j )

node pairs (i; j ) exists path directed edges G
j . (i; j ) 2 E , (j; i) 2 E .
ordered quadruple node pair (i; j ), node k, labels
2 Li b 2 Lj .

E

[(i; j ); k; a; b]

faja 2 L (i; a) permitted constraints (i.e., admissible)g

Li

2 (i; a; j; b) = 1 indicates admissibility 2 Li b 2 Lj given
binary constraints.

2 (i; a; j; b)

R

R

Counter[(i; j ); k; a; b]
S[(i; j ); k; a; b]
M[(i; j ); k; a; b]
List

G

Next-Edgei
Prev-Edgei
Local-Prev-Support[(i; j ); a; b]
Local-Next-Support[(i; j ); a; b]
Prev-Support[(i; j ); k; a; b]
Next-Support[(i; j ); k; a; b]

number labels Lk compatible R2 (i; a; j; b).
(k; c) 2 [(i; j ); k; a; b] means c 2 Lk compatible
R2 (i; a; j; b).
M[(i; j ); k; a; b] = 1 indicates R2 (i; a; j; b) false paths
including i, j , k.
queue path support deleted.
G set node pairs (i; j ) exists directed
edge j .
Next-Edgei contains node pairs (i; j ) exists
directed edge (i; j ) 2 G. contains (i; end) last
node segment.
Prev-Edgei contains node pairs (j; i) exists
directed edge (j; i) 2 G. contains (start; i) first
node segment.
set elements (i; k) (k; i) 2 Prev-Edgei , k 6= start,
R2 (i; a; j; b) must compatible one k 's labels.
Local-Prev-Support[(i; j ); a; b] becomes empty, R2 (i; a; j; b) becomes false.
set elements (i; k) (i; k) 2 Next-Edgei , k 6= end,
R2 (i; a; j; b) must compatible one k 's labels.
Local-Next-Support[(i; j ); a; b] becomes empty, R2 (i; a; j; b) becomes false.
(i; x) 2 Prev-Support[(i; j ); k; a; b] implies (x; k) 2 Prev-Edgek ,
x 6= start, R2 (i; a; j; b) compatible least one k's
one x's labels. Prev-Support[(i; j ); k; a; b] becomes empty,
R2 (i; a; j; b) longer true segments containing i, j , k .
(i; x) 2 Next-Support[(i; j ); k; a; b] means (k; x) 2 Next-Edgek ,
x 6= end, R2 (i; a; j; b) compatible least one k's
one x's labels. Next-Support[(i; j ); k; a; b] becomes empty,
R2 (i; a; j; b) longer true segments containing i, j , k .

Figure 29: Data structures notation MUSE PC-1.

275

fiHelzerman & Harper

l

{...,a,...} n






p

r
j

q

{...,b,...}



LocalPrevSupport[(i,j), a, b] = {(i,l), (i,m)}
LocalPrevSupport[(j,i), b, a] = {(j,p), (j,q)}
LocalNextSupport[(i,j), a, b] = {(i,n), (i,o)}
LocalNextSupport[(j,i), b, a] = {(j,r), (j,s)}

Figure 30: Local-Prev-Support Local-Next-Support path consistency example DAG. solid directed lines members G, solid undirected
line represents (i; j ) (j; i) members E .
Support[(j; i); k; b; a], Next-Support[(i; j ); k; a; b], Next-Support[(j; i); k; b; a] sets. NextSupport[(i; j ); k; a; b] includes (i; x) arcs support R2 (i; a; j; b) given
directed edge k x, R2 (i; a; j; b) = 1, R2 (i; a; k; c) = 1, R2 (k; c; j; b) = 1 (NextSupport[(j; i); k; b; a] defined similarly). Prev-Support[(i; j ); k; a; b] includes (i; x) arcs
support R2 (i; a; j; b) given directed edge x k, R2 (i; a; j; b) = 1,
R2 (i; a; k; c) = 1, R2 (k; c; j; b) = 1 (Prev-Support[(j; i); k; b; a] defined similarly).
Note Prev-Support[(i; j ); k; a; b] contain ordered pair (i; k) (i; k) 2 PrevEdgek , (i; j ) (j; k) 2 Prev-Edgek . Next-Support[(i; j ); k; a; b] contain ordered
pair (i; k) (k; i) 2 Next-Edgek (i; j ) (k; j ) 2 Next-Edgek . elements included edge nodes sucient allow support. Dummy
ordered pairs created handle cases node beginning end
network: (start; k) 2 Prev-Edgek , (i; start) added Prev-Support[(i; j ); k; a; b],
(k; end) 2 Next-Edgek , (i; end) added Next-Support[(i; j ); k; a; b].

4.2 Running Time, Space Complexity, Correctness MUSE PC-1
worst-case running time routine initialize MUSE PC-1 data structures (in
Figure 32) O(n3 l3 + n4 l2), n number nodes MUSE CSP l
number labels. Given number (i; j ) elements E O(n2 ) domain size
O(l), O(n3 l2) entries Counter array determine number
supporters, requiring O(l) work; hence, initializing Counter array requires O(n3 l3)
time. Additionally, O(n3 l2) sets determine, O(l) values,
time required initialize O(n3 l3). Determining Prev-Support[(i; j ); k; a; b]
276

fiMUSE CSP: Extension Constraint Satisfaction Problem

z

x
{...,c,...}

{...,a,...}



k
w

j {...,b,...}


Figure 31: found Next-Edgek = f(k; x); (k; )g; Counter[(i; j ); x; a; b] =
0; Counter[(i; j ); y; a; b] = 0, R2 (i; a; j; b) ruled every segment containing i, j , k. solid directed lines members G,
solid undirected lines represent members E .

277

fiHelzerman & Harper

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.
27.

List := ;
E := f(i; j )j9 2 : i; j 2 ^ 6= j ^ i; j 2 N g;
(i; j) 2 E
2 Li
b 2 Lj f
Local-Prev-Support[(i; j ); a; b] := ; Local-Next-Support[(i; j ); a; b] := ;
k 2 N (i; k) 2 E ^ (j; k) 2 E f
S[(i; j ); k; a; b] := ;
M[(i; j ); k; a; b] := 0;
Prev-Support[(i; j ); k; a; b] := ; Next-Support[(i; j ); k; a; b] := ; g g
(i; j) 2 E
2 Li
b 2 Lj R2 (i; a; j; b) f
k 2 N (i; k) 2 E ^ (j; k) 2 E f

Total := 0;

c 2 Lk
R2 (i; a; k; c) R2 (k; c; j; b) f

Total := Total+1;
S[(i; k); j; a; c] := S[(i; k); j; a; c] [ f(j; b)g; g
Total = 0 f
List := List [ f[(i; j ); k; a; b]g;
M[(i; j ); k; a; b] := 1; g
Counter[(i; j ); k; a; b] := Total;
Prev-Support[(i; j ); k; a; b] :=
f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (x; k) 2 Prev-Edgek g
[ f(i; k)j(i; k) 2 Prev-Edgek g
[ f(i; start)j(start; k) 2 Prev-Edgek g;
Next-Support[(i; j ); k; a; b] :=
f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (k; x) 2 Next-Edgek g
[ f(i; k)j(k; i) 2 Next-Edgek g
[ f(i; end)j(k; end) 2 Next-Edgek g; g
Local-Prev-Support[(i; j ); a; b] :=
f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (x; i) 2 Prev-Edge ig
[ f(i; start)j(start; i) 2 Prev-Edgei g;
Local-Next-Support[(i; j ); a; b] :=
f(i; x)j(i; x) 2 E ^ (x = j _ (j; x) 2 E ) ^ (i; x) 2 Next-Edgei g
[ f(i; end)j(i; end) 2 Next-Edgeig; g

Figure 32: Initialization data structures MUSE PC-1.

278

fiMUSE CSP: Extension Constraint Satisfaction Problem

1. List 6=
2.
Pop [(i; j ); k; a; b] List;
3.
(k; c) 2 S[(i; j ); k; a; b] f
4.
Counter[(i; k); j; a; c] := Counter[(i; k); j; a; c] , 1;
5.
Counter[(k; i); j; c; a] := Counter[(k; i); j; c; a] , 1;
6.
Counter[(i; k); j; a; c] = 0 ^ M[(i; k); j; a; c] = 0 f
7.
List := List [ f[(i; k); j; a; c]; [(k; i); j; c; a]g;
8.
M[(i; k); j; a; c] := 1; M[(k; i); j; c; a] := 1; g g
9.
Update-Support-Sets([(i; j ); k; a; b]); (see Figure 34) g

Figure 33: Eliminating inconsistent binary constraints MUSE PC-1.
Update-Support-Sets ([(i; j ); k; a; b])f
1. (i; x) 2 Prev-Support[(i; j ); k; a; b] ^ x 6= j ^ x 6= k ^ x 6= start f
2.
Prev-Support[(i; j ); k; a; b] := Prev-Support[(i; j ); k; a; b] , f(i; x)g;
3.
Next-Support[(i; j ); x; a; b] := Next-Support[(i; j ); x; a; b] , f(i; k)g;
4.
Next-Support[(i; j); x; a; b] = ^ M[(i; j ); x; a; b] = 0 f
5.
List := List [ f[(i; j ); x; a; b]; [(j; i); x; b; a]g;
6.
M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g
7. (i; x) 2 Next-Support[(i; j ); k; a; b] ^ x 6= j ^ x 6= k ^ x 6= end f
8.
Next-Support[(i; j ); k; a; b] := Next-Support[(i; j ); k; a; b] , f(i; x)g;
9.
Prev-Support[(i; j ); x; a; b] := Prev-Support[(i; j ); x; a; b] , f(i; k)g;
10.
Prev-Support[(i; j); x; a; b] = ^ M[(i; j ); x; a; b] = 0 f
11.
List := List [ f[(i; j ); x; a; b]; [(j; i); x; a; b]g;
12.
M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g
13. (k; i) 2 Prev-Edgei
14. Local-Prev-Support[(i; j ); a; b] := Local-Prev-Support[(i; j ); a; b] , f(i; k)g;
15. Local-Prev-Support[(i; j ); a; b] = f
16. R2 (i; a; j; b) := 0; R2 (j; b; i; a) := 0;
17. (i; x) 2 Local-Next-Support[(i; j ); a; b] ^ x 6= j ^ x 6= k ^ x 6= end f
18.
Local-Next-Support[(i; j ); a; b] := Local-Next-Support[(i; j ); a; b] , f(i; x)g;
19.
M[(i; j ); x; a; b] = 0 f
20.
List := List [ f[(i; j ); x; a; b]; [(j; i); x; b; a]g;
21.
M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g g
22. (i; k) 2 Next-Edgei
23. Local-Next-Support[(i; j ); a; b] := Local-Next-Support[(i; j ); a; b] , f(i; k)g;
24. Local-Next-Support[(i; j ); a; b] = f
25. R2 (i; a; j; b) := 0; R2 (j; b; i; a) := 0;
26. (i; x) 2 Local-Prev-Support[(i; j ); a; b] ^ x 6= j ^ x 6= k ^ x 6= start dof
27.
Local-Prev-Support[(i; j ); a; b] := Local-Prev-Support[(i; j ); a; b] , f(i; x)g;
28.
M[(i; j ); x; a; b] = 0 f
29.
List := List [ f[(i; j ); x; a; b]; [(j; i); x; b; a]g;
30.
M[(i; j ); x; a; b] := 1; M[(j; i); x; b; a] := 1; g g g g

Figure 34: function Update-Support-Sets([(i; j ); k; a; b]) MUSE PC-1.
279

fiHelzerman & Harper

Approach
CSPs
MUSE CSP

Nodes
Degree
Number
Number
per Path Node splitting Constraint Networks Nodes

n
n

kn

k
k

1

n
kn

Asymptotic
Time

knn3 l3
3
(kn) l3 + (kn)4 l2

Table 2: Comparison space time complexity MUSE path consistency
MUSE CSP path consistency multiple CSPs representing node splitting
problem (e.g., lexical ambiguity parsing).
Next-Support[(i; j ); k; a; b] requires O(n) time, time required calculate
Prev-Support Next-Support sets O(n4 l2). Finally, time needed calculate
Local-Next-Support Local-Prev-Support sets O(n3 l2) O(n2 l2) sets
O(n) elements per set.
worst-case running time algorithm enforces MUSE path consistency
(in Figures 33 34) operates O(n3 l3 + n4 l2) time. Clearly O(n3 l2)
entries Counter array keep track algorithm. Counter[(i; j ); k; a; b]
l magnitude, never become negative, maximum running
time lines 4 5 Figure 33 (given elements, M, appear list
once) O(n3 l3). O(n3 l2) Prev-Support Next-Support lists,
O(n) size, maximum running time required eliminate O(n) elements
support sets O(n4 l2). Finally, since O(n2 l2) Local-Next-Support
Local-Prev-Support sets eliminate O(n) elements, worst-case time
eliminate items local sets O(n3 l2). Hence, worst-case running time
MUSE CSP path consistency algorithm O(n3 l3 + n4 l2).
space complexity MUSE CSP PC-1 O(n3 l3 + n4 l2 ) arrays
Counter contain O(n3 l2) elements O(n3 l2) sets, containing
O(l) items; O(n3 l2) Prev-Support Next-Support sets, containing O(n) items;
O(n2 l2) Local-Next-Support Local-Prev-Support sets, containing O(n) items.
comparison, worst-case running time space complexity CSP path consistency, PC-4, O(n3 l3). Note applications representable planar DAG
l = n, worst-case running times algorithms order. compare
MUSE CSP use multiple CSPs problems k alternative variables
particular variable CSP, MUSE CSP path consistency asymptotically
attractive, shown Table 2.
proof correctness MUSE PC-1 similar proof MUSE AC-1,
brie outline proof here. binary constraint looses support MUSE
PC-1 (see lines 16 25 Figure 34) Local-Prev-Support set Local-NextSupport set becomes empty (see lines 15 24 Figure 34, respectively). either case,
inadmissible MUSE path consistent instance. prove constraint's local
support sets become empty cannot participate MUSE path consistent
instance MUSE CSP. proven Local-Next-Support (Local-Prev-Support follows
symmetry). Observe R2 (i; a; j; b) = 1, nodes immediately
280

fiMUSE CSP: Extension Constraint Satisfaction Problem

2 = f 1j, 2j, 3jg
1 = f 4j, 5jg

1

2

3

start

end
4

5

Figure 35: example set CSP problems would good candidate MUSE
CSP lack node sharing.
follow (and similarly j ) DAG incompatible truth constraint,
cannot participate MUSE path consistent instance. line 23 Figure 34,
(i; k) removed Local-Next-Support[(i; j ); a; b] [(i; j ); k; a; b]
popped List. removal (i; k) Local-Next-Support[(i; j ); a; b] indicates
segment containing i, j , k support R2 (i; a; j; b). remains shown
[(i; j ); k; a; b] put List R2 (i; a; j; b) must false every segment
contains i, j , k. proven induction number iterations
loop Figure 33 (much proof MUSE AC-1). must show
R2 (i; a; j; b) = 1 MUSE PC-1, MUSE path consistent. R2 (i; a; j; b)
MUSE path consistent, must exist least one path start end
goes nodes j nodes n path contain least one label
consistent constraint. proof would similar second half proof
MUSE AC-1 correctness. this, may conclude MUSE PC-1 builds
largest MUSE path consistent structure.

5. Combining CSPs MUSE CSP
Problems inherent lattice structure problems solved
node splitting approach natural areas application MUSE CSP,
exponential number CSPs replaced single instance MUSE CSP, DAG
representation inherent problem. section discuss DAG construction
application areas would benefit MUSE CSP approach,
obvious construct DAG. set CSP problems
used segments MUSE CSP. example, Figure 35 illustrates two instances
CSP combined single MUSE CSP. However, using MUSE CSP
example would right choice; node sharing cannot offset cost using
extra MUSE AC-1 data structures.
Multiple nodes name various CSPs potentially represented
single node MUSE CSP. assume two nodes, k1 k2 given
name (say k) two instances CSP, domain obey
constraints, i.e.:
1. Lk1 = Lk2 (i.e., domains equal.)
2. R1(k1; a) = R1(k2; a) every 2 Lk1 ; Lk2 (i.e., unary constraints
same.)
281

fiHelzerman & Harper

1 = f 1j, 2jg
2 = f 1j, 3jg
3 = f 2j, 3jg

1

2
start

end

1

3

2

start

end

2

3

Figure 36: example maximal node sharing leads spurious segments.
first DAG contains two paths, f1,2,3g f2g, correspond none
segments. second DAG presents preferred sharing created
Create-DAG routine.
3. R2(k1; a; i; b) = R2(k2; a; i; b) labels 2 Lk1 ; Lk2 b 2 Li ,
segments (i.e., binary constraints same.)
However, illustrated Figure 36, much sharing common nodes introduce
additional segments appear original list CSPs. extra
segments cause extra work done, often desirable create DAG
shares nodes without introducing extra segments. algorithm Create-DAG, shown
Figure 38 takes arbitrary set CSP problems input (a list segments), outputs
DAG representation CSPs shares nodes without introducing spurious
segments. Create-DAG calls auxiliary procedure Order-Sigma defined Figure 39.
data structures used two routines defined Figure 37.
hold individual segments , routine Create-DAG uses special data
structure ordered sets supports useful operations. segment n
integer, [n] node position n . [0] always start node,
[j j , 1] always end node. [k::m] ordered subset consisting
nodes positions k m. addition, ordered set allows us insert node
immediately node j already set. node [pos] structure
name field next-set field, set names nodes follow
node [pos] set segments.
Create-DAG begins adding special purpose start end nodes segment.
calls routine Order-Sigma shown Figure 39 order nodes
segment. Order-Sigma orders nodes segment ones
common tend occur earlier set. order elements, uses operator
> (i.e., larger than) defined nodes. Note start node defined
\largest" node, end node \smallest" node. addition, > j means either
appears segments j does, appear number
segments, lower ordinal number j . Thus operator > induces total
ordering nodes N .
Order-Sigma first called Create-DAG selects largest node
smaller start node. constructs set , set segments
containing i. point, segments ordered start node first
second. calls Order-Sigma order nodes smaller i.
recursive call done, segments considered (i.e., Z ). Note
282

fiMUSE CSP: Extension Constraint Satisfaction Problem

Notation

Meaning



set node sets. node set represents CSP.
node set segment . set modified include
begin end nodes Create-DAG algorithm work
properly. Note [0] always start node, [jj , 1]
always end node. node [pos] structure name
next-set (names nodes follow node DAG).
G set node pairs (i; j ) exists
directed edge j DAG created Create-DAG.
N set nodes placed DAG
Create-DAG.
Z set segments order respect node j
Order-Sigma.
node j used Order-Sigma order remaining
elements smaller node.
U set nodes already considered current call
Order-Sigma.
R set nodes Z Order-Sigma.
node largest node smaller j R , U
(if non-empty) R Order-Sigma.
Order-Sigma, set segments Z contain node i.


G
N
Z
j
U
R



Figure 37: Data structures used Create-DAG Order-Sigma.

283

fiHelzerman & Harper

Create-DAG () f

1.
2.
3.
4.
5.
6.
7.
8.
9.

10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.
27.
28.
29.
30.
31.
32.
33.
34.

Add start first node end last node every segment ;
Order-Sigma(, start);
pos := 1 maximum segment length f
:= copy();
2 ^ jj , 1 > pos f
[pos].name = end f
G := G [ f([pos , 1], [pos])g; g
0

0

else f

EDGE SET := f1j 1[pos , 1].name = [pos , 1].name ^
1[pos].name = [pos].nameg;
next-set := f[pos + 1].name j 2 EDGE SETg;
:= , EDGE SET;
node [pos].name N f
N := N [ [pos];
[pos].next := next-set;
G := G [ f([pos , 1], [pos])g; g
0

0

else f
node := get node N name [pos].name;
node.next = next-set f
G := G [ f([pos , 1]; [pos])g; g
else f

new-node : = Create new node;
new-node.name := concatenate([pos].name, ');
node := get node N named new-node.name (if one);
node && node.next !=next-set f
new-node.name := concatenate(new-node.name, ');
node := get node N named new-node.name (if one); g
(node = NULL)
N := N [ new-node;
else new-node := node;
new-node.next := next-set;
Replace [pos].name new-node.name [pos , 1].next;
G := G [ f([pos , 1]; new-node)g;
Replace every occurance [pos] pos new-node
segments EDGE SET; g g g g g
Eliminate start end G 2 ; g

Figure 38: Routine create DAG represent .

284

fiMUSE CSP: Extension Constraint Satisfaction Problem

Order-Sigma (Z; j ) f
1. U := ;
2. Z 6= f
3.
R :=
;

[

4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.

2Z

R , U 6=
:= \largest" node R , U less j ;
else
:= \largest" node R less j ;
:= fj 2 Z ^ 2 g ;
Z := Z , ;
=6 end f
2 f
Put j ;
U := U [ ; g
Order-Sigma(S; i) g g g

Figure 39: routine arrange nodes within segments convenient merging.
first iteration loop, preference select largest node
contained segments ordered recursive call Order-Sigma.
items independent ordered segments, create spurious paths
placed early DAG; however, items occur already ordered segments,
placed earlier items occur ordered segments would tend introduce
spurious paths. loop continues segments ordered. worstcase running time Order-Sigma O(n2 ), n sum cardinalities
segments .
Order-Sigma orders nodes segments, Create-DAG begins construct DAG, represented set nodes N set directed edges G.
DAG constructed going segment beginning position
second element (the position start). loop line 3 looks nodes left
right order, one position time, elements segment added
G. node certain name already placed N (i.e., set nodes
already DAG created) adding node graph (as well directed
edge [pos , 1] [pos] G) cannot create spurious paths DAG.
hand, node name [pos] already placed N ,
possible current segment could add paths DAG correspond
segments . avoid adding spurious segments, deal segments
one time share previous node node name
current position. basic idea add edge keep track nodes
follow node DAG. this, easily determine whether
node used occurs another segment later position. node
used followed precisely set next nodes follow
node already placed graph; otherwise, second node would renamed
avoid adding spurious segments. event, create new name node.
285

fiHelzerman & Harper

Note DAG complete, eliminate start end nodes G
(and corresponding outgoing incoming edges) make G consistent use
MUSE arc consistency MUSE path consistency algorithms. running time
Create-DAG O(n2 ), n sum cardinalities segments .
Even though DAGs produced routine Create-DAG nice properties,
routine probably used starting point custom combining routines
specific intended application area. believe domain-specific information play important role MUSE combination. example domain specific
combining algorithm presented (Harper et al., 1992), describes spoken-language
parsing system uses MUSE CSP. distinguishing feature application's combining algorithm instead avoiding creation extra segments, allows controlled
introduction extra segments extra segments often represent sentences
N-Best sentence spoken language recognition system would miss.

6. Conclusion

conclusion, MUSE CSP used eciently represent several similar instances
constraint satisfaction problem simultaneously. multiple instances CSP
common variables domains compatible constraints,
combined single instance MUSE CSP, much work required enforce
node, arc, path consistency need duplicated across instances, especially
constraints suciently tight.
developed MUSE CSP constraint-based parser, PARSEC (Harper & Helzerman, 1995a; Harper et al., 1992; Zoltowski et al., 1992), capable parsing word
graphs containing multiple sentence hypotheses. developed syntactic semantic
constraints parsing sentences, applied word graph, eliminate hypotheses syntactically semantically incorrect. work speech processing,
MUSE arc consistency algorithm effective pruning incompatible labels
individual CSPs represented composite structure. extracting
parses sentences remaining MUSE CSP MUSE AC-1, usually unnecessary enforce arc consistency CSP represented directed path
network tightness syntactic semantic constraints.
Speech processing area segmenting signal higher-level
chunks problematic. Vision systems handwriting analysis systems comparable
problems. addition, problems allow parallel alternative choices type
variable, parsing lexically ambiguous sentences, excellent candidates
MUSE CSP.
C++ implementations algorithms described paper available following location: ftp://transform.ecn.purdue.edu/pub/speech/harper code/. directory
contains README file file called muse csp.tar.Z.

286

fiMUSE CSP: Extension Constraint Satisfaction Problem

Acknowledgements
work supported part Purdue Research Foundation grant
Intel Research Council. would thank anonymous reviewers insightful
recommendations improving paper.

References

Bessiere, C. (1994). Arc-consistency arc-consistency again. Artificial Intelligence, 65,
170{190.
Davis, A. L., & Rosenfeld, A. (1981). Cooperating processes low-level vision: survey.
Artificial Intelligence, 17, 245{263.
Dechter, R. (1992). local global consistency. Artificial Intelligence, 55, 87{107.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49, 61{95.
Dechter, R., & Pearl, J. (1988). Network-based heuristics constraint-satisfaction problems. Artificial Intelligence, 34, 1{38.
Freuder, E. (1989). Partial constraint satisfaction. Proceedings International Joint
Conference Artificial Intelligence, pp. 278{283.
Freuder, E. (1990). Complexity K-tree-structured constraint-satisfaction problems.
Proceedings Eighth National Conference Artificial Intelligence, pp. 4{9.
Han, C., & Lee, C. (1988). Comments Mohr Henderson's path consistency algorithm.
Artificial Intelligence, 36, 125{130.
Harper, M. P., & Helzerman, R. A. (1995a). Extensions constraint dependency parsing
spoken language processing. Computer Speech Language, 9 (3), 187{234.
Harper, M. P., & Helzerman, R. A. (1995b). Managing multiple knowledge sources
constraint-based parsing spoken language. Fundamenta Informaticae, 23 (2,3,4),
303{353.
Harper, M. P., Jamieson, L. H., Zoltowski, C. B., & Helzerman, R. (1992). Semantics
constraint parsing word graphs. Proceedings International Conference
Acoustics, Speech, Signal Processing, pp. II{63{II{66.
Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8 (1),
99{118.
Mackworth, A. K., & Freuder, E. (1985). complexity polynomial networkconsistency algorithms constraint-satisfaction problems. Artificial Intelligence, 25,
65{74.
287

fiHelzerman & Harper

Maruyama, H. (1990a). Constraint dependency grammar. Tech. rep. #RT0044, IBM,
Tokyo, Japan.
Maruyama, H. (1990b). Constraint dependency grammar weak generative capacity.
Computer Software.
Maruyama, H. (1990c). Structural disambiguation constraint propagation.
Proceedings Annual Meeting ACL, pp. 31{38.
Mohr, R., & Henderson, T. C. (1986). Arc path consistency revisited. Artificial Intelligence, 28, 225{233.
Montanari, U. (1974). Networks constraints: Fundamental properties applications
picture processing. Information Science, 7, 95{132.
van Beek, P. (1994). inherent level local consistency constraint networks.
Proceedings Twelfth National Conference Artificial Intelligence, pp. 368{373.
Villain, M., & Kautz, H. (1986). Constraint-propagation algorithms temporal reasoning.
Proceedings Fifth National Conference Artificial Intelligence, pp. 377{382.
Waltz, D. L. (1975). Understanding line drawings scenes shadows. Winston, P.
(Ed.), Psychology Computer Vision. McGraw Hill, New York.
Zoltowski, C. B., Harper, M. P., Jamieson, L. H., & Helzerman, R. (1992). PARSEC:
constraint-based framework spoken language understanding. Proceedings
International Conference Spoken Language Understanding, pp. 249{252.

288


