Journal Artificial Intelligence Research 5 (1996) 163{238

Submitted 5/94; published 10/96

Mechanisms Automated Negotiation
State Oriented Domains
Gilad Zlotkin

giladz@agentsoft.com

AgentSoft Ltd.
P.O. Box 53047
Jerusalem, Israel

Jeffrey S. Rosenschein

jeff@cs.huji.ac.il

Institute Computer Science
Hebrew University
Givat Ram, Jerusalem, Israel

Abstract

paper lays part groundwork domain theory negotiation, is,
way classifying interactions clear, given domain, negotiation
mechanisms strategies appropriate. define State Oriented Domains, general
category interaction. Necessary sucient conditions cooperation outlined.
use notion worth altered definition utility, thus enabling agreements
wider class joint-goal reachable situations. approach offered con ict resolution,
shown even con ict situation, partial cooperative steps taken
interacting agents (that is, agents fundamental con ict might still agree cooperate
certain point).
Unified Negotiation Protocol (UNP) developed used types
encounters. shown certain borderline cooperative situations, partial cooperative agreement (i.e., one achieve agents' goals) might preferred
agents, even though exists rational agreement would achieve goals.
Finally, analyze cases agents incomplete information goals
worth agents. First consider case agents' goals private information, analyze goal declaration strategies agents might adopt increase
utility. Then, consider situation agents' goals (and therefore standalone costs) common knowledge, worth attach goals private
information. introduce two mechanisms, one \strict," \tolerant," analyze affects stability eciency negotiation outcomes.

1. Introduction
Negotiation major research topic distributed artificial intelligence (DAI)
community (Smith, 1978; Malone, Fikes, Grant, & Howard, 1988; Kuwabara & Lesser,
1989; Conry, Meyer, & Lesser, 1988; Kreifelts & von Martial, 1991). term negotiation,
however, used variety different ways. researchers, negotiation
serves important mechanism assigning tasks agents, resource allocation,
deciding problem-solving tasks undertake. systems, generally
notion global utility system trying maximize.
c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiZlotkin & Rosenschein

researchers focused negotiation might take place among agents
serve interests truly distinct parties (Rosenschein & Genesereth, 1985; Sycara, 1988;
Kraus & Wilkenfeld, 1990; Zlotkin & Rosenschein, 1989). agents autonomous
sense utility functions, global notion utility (not
even implicit one) plays role design. Negotiation used share work
associated carrying joint plan, resolve outright con ict arising limited
resources.
Despite varied use terminology, clear DAI community whole
operation interacting agents would enhanced able exchange
information reach mutually beneficial agreements.
work described paper follows general direction previous research
authors (Rosenschein & Genesereth, 1985; Zlotkin & Rosenschein, 1989) treating
negotiation spirit game theory. focus research analyze existence
properties certain kinds deals protocols among agents.
examining computational issues arise discovering deals, though design
ecient, possibly domain-specific, algorithms constitute important future phase
research. Initial work building domain theory negotiation previously
undertaken (Zlotkin & Rosenschein, 1993a), expanded generalized current
paper. analysis serves critical step applying theory negotiation realworld applications.

1.1 Applying Game Theory Tools Protocol Design Automated Agents

ongoing research motivated one, focused premise: problem
get computers interact effectively heterogeneous systems tackled
use game theory tools.
concern computer systems made machines programmed
different entities pursue differing goals. One approach achieving coordination
circumstances establish mutually accepted protocols machines use
coming agreements.
perspective research one use game theory tools design
evaluate high-level protocols. intend, paper, make contributions
game theory itself. defining new notions equilibria, providing
new mathematical tools used general game theory. taking
game theory approach, tools, solve specific problems high-level
protocol design.
game theory makes contributions understanding many different fields,
particularly serendipitous match game theory heterogeneous computer systems. Computers, pre-programmed behavior, make concrete
notion \strategy" plays central role game theory|the idea player
adopts rules behavior starting play given game, rules entirely
control responses game. idealized player imperfect model human
behavior, one quite appropriate computers.
first apply game theoretic ideas computer science,
using tools new way. others used game theory answer question,
164

fiMechanisms Automated Negotiation

\How one program computer act given specific interaction?" addressing question design rules interaction automated
agents. approach taken paper is, therefore, strongly based previous work
game theory, primarily known \Nash's Bargaining Problem" (Nash, 1950;
Luce & Raiffa, 1957) \Nash's Model Bargaining" (Roth, 1979), \mechanism design"
\implementation theory" (Binmore, 1992; Fudenberg & Tirole, 1992), \correlated
equilibrium theory" (Aumann, 1974, 1987; Myerson, 1991; Forges, 1993). short overview
game theory results used referred paper found Section 9.1.

1.2 Overview Paper
previous work, began laying groundwork domain theory negotiation,
is, way classifying interactions clear, given domain, negotiation
mechanisms strategies appropriate. Previously, considered Task Oriented Domains (Zlotkin & Rosenschein, 1989, 1993a), restricted category interactions.
paper, define State Oriented Domains, general category interaction.
Section 4.4 examine scenarios interacting agents State Oriented Domains
find cooperative, compromise, con ict encounters. con ict situations, agents' goals cannot simultaneously achieved. joint-goal reachable situation
(i.e., agents' goals simultaneously achieved) cooperative compromise, depending cost reaching state satisfies agents compared
cost agent (alone) achieving stand-alone goal.
Section 4.1, necessary sucient conditions cooperation outlined. Cooperative situations lend mixed-joint-plan-based negotiation mechanisms. However,
compromise situations require special treatment. propose using notion worth
altered definition utility, thereby enabling agreements wider class joint-goal
reachable situations. approach offered con ict resolution, shown
even con ict situation, partial cooperative steps taken interacting agents
(that is, agents fundamental con ict might still agree cooperate certain point).
Unified Negotiation Protocol (UNP) developed Section 5.4 used
types encounters. shown certain borderline cooperative situations, partial
cooperative agreement (i.e., one achieve agents' goals) might preferred
agents, even though exists rational agreement would achieve
goals.
UNP enhanced Section 6 deal case agents
assigned unlimited worth goals fact common knowledge. solution
depends concept \cleaning yourself," tidiness, new method
evaluating agent utility. show two tidy agents able reach agreements
joint-goal reachable situations State Oriented Domains.
Section 7 analyze cases agents incomplete information goals
worth agents. First, consider case agents' goals private
information, consider goal declaration strategies agents might adopt
increase utility.
consider, Section 8, situation agents' goals (and therefore
stand-alone costs) common knowledge, worth attach goals
165

fiZlotkin & Rosenschein

private information. many situations agent's goals might known,
worth private. example, two cars approaching intersection may know
other's goals (because lanes located). worth
associates passing intersection target lane, however, private. Goal
recognition techniques suitable discovering agent's intentions; worth,
however, harder discern short-term external evidence.
agents declare, ,1-phase, worths, used baseline
utility calculation (and thus affect negotiation outcome). concerned
analyzing worth declaration strategies agents might adopt increase utility.
introduce two mechanisms, one \strict," \tolerant," analyze affects
stability eciency negotiation outcomes. strict mechanism turns
stable, tolerant mechanism ecient.

2. Negotiation State Oriented Domains
machines decide share resources, machine give way
proceeds? Negotiation compromise necessary, build
machines things? designers separate machines decide
techniques agreement enable mutually beneficial behavior? techniques
appropriate? make definite statements techniques' properties?
way address questions synthesize ideas artificial intelligence
tools game theory. Assuming automated agents, built separate, self-interested
designers, interact, interested designing protocols specific domains
get agents interact useful ways.
word \protocol" means different things different people. use word
protocol, mean rules agents come agreements. specifies kinds
deals make, well sequence offers counter-offers allowed.
Protocols intimately connected domains, mean environment
agents operate. Automated agents control telecommunications networks
operating different domain (in formal sense) robots moving boxes. Much
research focused relationship different kinds domains, protocols
suitable each.
Given protocol, need consider agent strategy appropriate. strategy
way agent behaves interaction. protocol specifies rules
interaction, exact deals agent proposes result strategy
designer put him. analogy, protocol rules governing movement
pieces game chess. strategy way chess player decides
next move.

2.1 Attributes Standards
attributes might interest protocol designers? set attributes,
relative importance, ultimately affect choice interaction rules.
considered several attributes might important system designers.
166

fiMechanisms Automated Negotiation

1.

2.

3.

4.
5.

Eciency: agents squander resources come agree-

ment; wasted utility agreement reached. example,
makes sense agreements satisfy requirement Pareto Optimality
(no agent could derive different agreement, without agent
deriving less alternate agreement). Another consideration might Global
Optimality, achieved sum agents' benefits maximized.
Global Optimality implies Pareto Optimality, vice versa. Since speaking self-motivated agents (who care utilities, sum
system-wide utilities|no agent general would willing accept lower utility
increase system's sum), Pareto Optimality plays primary role eciency
evaluation. Among Pareto Optimal solutions, however, might consider
secondary criterion solutions increase sum system-wide utilities.
Stability: agent incentive deviate agreed-upon strategies.
strategy agents adopt proposed part interaction environment
design. strategies proposed, however, want individual
designers (e.g., companies) incentive go back build agents
different, manipulative, strategies.
Simplicity: desirable overall interaction environment make low
computational demands agents, require little communication overhead.
related eciency stability: interaction mechanism
simple, increases eciency system, fewer resources used carrying
negotiation itself. Similarly, stable mechanisms, resources need
spent outguessing opponent, trying discover optimal choices.
optimal behavior publicly revealed, nothing better
carry out.
Distribution: Preferably, interaction rules require central decision
maker, obvious reasons. want distributed system
performance bottleneck, collapse due single failure special node.
Symmetry: may want agents play different roles interaction scenario. simplifies overall mechanism, removes question agent
play role interaction gets way.

attributes need universally accepted. fact, sometimes tradeoffs one attribute another (for example, eciency stability sometimes
con ict one another; see Section 8). protocols designed, specific
classes domains, satisfy attributes. Ultimately,
kinds criteria rate acceptability one interaction mechanism another.
one example, attribute stability assumes particular importance consider open systems, new agents constantly entering leaving community
interacting machines. Here, might want maintain stability face new agents
bring new goals potentially new strategies well. mechanism
\self-perpetuating," benefit society whole follow
rules, benefit individual member, social behavior remains
167

fiZlotkin & Rosenschein

stable even society's members change dynamically. interaction rules
create environment particular strategy optimal, beneficial social behavior
resistant outside invasion.

2.2 Side Effects Encounters
Various kinds encounters among agents, various types domains, possible. previous work (Zlotkin & Rosenschein, 1989, 1993a, 1994, 1996b) examined Task Oriented
Domains (TODs), encompass certain kinds encounters among agents. State
Oriented Domains (SODs) describe larger class scenarios multiagent encounters
TODs. fact, see below, set Task Oriented Domains actually
proper subset State Oriented Domains. classical domains Artificial Intelligence
instances State Oriented Domains.
main attribute general SODs agents' actions side effects. Task
Oriented Domains, side effects exist general common resources unrestricted.
Thus, agent achieves set tasks TOD positive negative
effects agent whatsoever. hinder agent achieving
goal, never satisfies agent's goals \by accident." enable another agent
carry task, example Postmen Domain (Zlotkin & Rosenschein,
1989), necessary explicitly declare existence letter, hand over,
delivered. absence side effects rules positive negative
interactions among agent goals. positive interactions remain
explicitly coordinated agents.
general State Oriented Domains, side effects exist, agents unintentionally
achieve one another's goals, thus benefit one another's actions. ip side
side effects, however, negative interactions goals exist. Thus,
SOD domain (unlike TODs) necessarily cooperative, action
side effects. SODs, agents deal goal con ict interference, well
possibility unintended cooperation.1
example, consider Blocks World situation Figure 1. simplest plan
achieve On(White; Gray) side effect achieving Clear(Black).

Figure 1: Side Effects State Oriented Domains
1. interesting discussions issue con ict role human encounters, see (Schelling, 1963,
1984).

168

fiMechanisms Automated Negotiation

2.3 Domain Definition
Consider group agents co-exist environment. agent goal
interested achieving. mean achieve goal? State Oriented Domains,
classic AI notion goal achievement: means carry sequence actions
(a plan) results transformation environment state goal
satisfied.
Imagine, example, person interested getting work. goal
work; current state, work. plan sequence actions
get work (driving car, calling taxi, walking, riding bicycle,. . . ).
final, goal, state, may differ depending plan executed (e.g.,
car is, bicycle is). states work, however, satisfy goal.
Let's assume optimal plan (from time point view) involves driving car
work.
specification goal states may implicit. fact needs true
(the goal) may given. situation fact true, i.e., goal satisfied,
acceptable. State Oriented Domain, goal described set states
satisfy it.
imagine person's wife interested place work.
states satisfy husband's wife's goals, plans
achieve state (e.g., one takes car, calls taxi). However,
certain plans suitable either spouse isolation, cannot
coexist. example, husband taking car perfectly good plan (and optimal)
alone world. Similarly, wife's taking car good plan (and optimal)
alone. Together, another plan may suitable (husband drives wife
work, continues car work). case, extra work required
husband's point view, wife present world; certain burden
coordination.
example above, agents carry sequence activities, suitably synchronized, reach goal state satisfying both. husband wife enter car,
husband drives particular location, wife exits, on. environment, primitive operations agent alone do. operations
combined coherent sequence actions specifying agents (and
order done), say agents executing joint plan.
joint plan general transforms world initial state goal state satisfying
agents (when possible). plan transforms world initial state
husband wife home goal state (satisfying agents)
wife work, car husband place work. final state,
one many goal states.
Task Oriented Domains cost coordinated plan need never worse
stand-alone plan|at worst, agent achieves set tasks.
husband/wife sharing one car example, however, coordinated plan may worse
one agents stand-alone plans. example one attribute
State Oriented Domains, namely negative interactions, sometimes called
169

fiZlotkin & Rosenschein

\deleted-condition interactions" (Gupta & Nau, 1992). taking car
side effect depriving agent car.
Imagine new situation, arises weekend. husband interested
carpentry garage (currently occupied car). wife interested
taking car baseball game. themselves, agent optimal plan reach
goal state (e.g., husband moves car garage, parks outside,
carpentry). However, wife takes car game, executing stand-alone
optimal plan, husband benefits side effect car moved, namely,
garage emptied. example another typical attribute State Oriented
Domains|accidental achievement goals, \enabling-condition interactions" (Gupta &
Nau, 1992) \favor relations" (von Martial, 1990) among goals.
agents carry joint plan, one plays \role." theory assumes
way assessing cost role. measure cost essential
agent evaluates given joint plan. Among joint plans achieve goal,
prefer role lower cost.
express intuitive ideas precise definition below.

Definition 1 State Oriented Domain (SOD) tuple < ; A; J ; c > where:
1. set possible world states;

2. = fA1; A2; : : :A g ordered list agents;
n

3. J set possible joint (i.e., n-agent) plans. joint plan J 2 J moves
world one state another. actions taken agent k called k's role
J , written J . write J (J1; J2; : : :; J );
k

n

4. c function c: J ! (IR+ ) : joint plan J J , c(J ) vector n positive
real numbers, cost agent's role joint plan. c(J ) i-th element
cost vector, i.e., cost i-th role J . agent plays role
J , cost 0.
n



use term joint plan differs uses AI literature (Levesque &
Cohen, 1990; Cohen & Levesque, 1991). There, term joint plan implies joint goal,
mutual commitment agents full implementation plan (e.g., one agent
dropped suddenly, would still continue). use term, agents
committed goal part combined plan. may
part plan different reasons, different goal achieve.
one agent drop out, agent may may continue, depending whether
suited goal.
details description joint plans J critical overall theory.
minimal requirement must possible evaluate cost joint plan
agent (i.e., cost role). many domains, joint plan sequence
actions agent associated schedule (partial order) constraining actions'
parallel execution.
Note cost function relates joint plan not,
example, initial state world. fact, cost function could altered
170

fiMechanisms Automated Negotiation

include parameters (like initial state world), without affecting discussion
below. model sensitive details cost function definition,
requirement cost role agents. called symmetric
abilities assumption (see below, Section 2.4).

Definition 2 encounter within SOD < ; A; J ; c > tuple < s; (G1; G2; : : :; G ) >

2 initial state world, k 2 f1 : : :ng; G set
acceptable final world states agent . G called 's goal.
n

k

k

k

k

agent's goal fixed, pre-determined, set states. agent will, conclusion
joint plan, either achieve goal achieve goal. Goals cannot partially
achieved. Domains goals partially achieved called Worth Oriented
Domains (WODs) discussed detail elsewhere (Zlotkin & Rosenschein, 1991c,
1996a).
One thing specifically ruling SODs one agent goal
makes reference another agent's (as yet) unknown goal. example, specification
\Agent 1's goal make sure Agent 2's goal achieved, whatever
latter's goal is" cannot constitute part description encounter State
Oriented Domain, cannot described static set goal states. However,
meta-goal might exist within agent, give rise well-defined set states
specific encounter (e.g., given G2, G1 complement). Similarly, one agent might
goal another agent specific goal G2|the first agent wants world
state agent specific goal G2.
consider sets goal states specified finite way, either
set finite, infinite set specified closed formula
first-order logic (i.e., free variables; states satisfy formula,
states, goal set). example, agent might goal \There exists
block x block B x."
consider restrictions kind goals agents may have.
example, consider domains agents' goals restricted sets
grounded predicates (i.e., variables) rather closed formula.
2.3.1 Reachability

may case exist goal states satisfy agents' goals,
constraints reachability states. example, may case
state satisfying goal reached agent alone, state satisfying
combined goal cannot reached agent alone. generally, reaching
state might require n agents working together, unreachable fewer n agents
involved (we call n \parallelism factor" goal). goal
intersection cannot reached number agents working parallel, say
parallelism factor infinite. parallelism factor particularly appropriate concept
multiagent actions possible required domain (e.g., carrying
heavy table).
171

fiZlotkin & Rosenschein

2.4 Assumptions

Throughout paper, making number simplifying assumptions enable
us lay foundation theory mechanism design automated agents.
Here, present assumptions.
1.
2.

3.
4.
5.

6.

Expected Utility Maximizer: Designers design agents maximize expected utility. example, assume designer build agent prefer
51% chance getting $100, rather sure $50.
Isolated Negotiation: agent cannot commit part current negotiation behavior future negotiation, expect current
behavior way affect future negotiation. Similarly, agent cannot expect
others behave particular way based previous interaction history,
act differently past behavior. negotiation stands
alone.
Interagent Comparison Utility: designers means transforming
utilities held different agents common utility units.
Symmetric Abilities: agents able perform set operations
world, cost operation independent agent carrying out.
Binding Commitments: Designers design agents keep explicit public
commitments. assume nothing relationship private preferences
public behavior, public commitment followed public performance
commitment. monitored, necessary, enforced.
Explicit Utility Transfer: Although agents compare respective utilities, way explicitly transferring utility units one other.
is, example, \money" used compensate one agent
disadvantageous agreement. Utility transfer occur, however, implicitly.
implicit transfer utility forms basis agreement among agents.

3. Examples State Oriented Domains

section, present several examples State Oriented Domains. specific
examples illustrate nuances describing class domains.

3.1 Blocks Domain

Blocks Domain, table unlimited size, set blocks. block
table block, limit height stack
blocks. One state domain seen Figure 2.
World States Goals: basic predicates make world states goals are:

On(x; y): x blocks; meaning block x (directly)
block .

172

fiMechanisms Automated Negotiation

Figure 2: State Blocks Domain

1

2

3

Figure 3: State Slotted Blocks Domain

On(x; Table): x block; meaning block x (directly)

table.
Clear(x): x block; meaning block x, i.e.,
Clear(x) :9y On(y; x).
SOD, goals sets world states. world states expressed
first order closed formula predicates. Sample goals are:

:Clear(R) | Block R clear.
9xOn(R; x) | Block R table.
8xOn(x; Table) | blocks table (and therefore, implicitly, blocks
Clear).

Atomic Operation: one operation world: Move(x; ). operation moves
clear block x onto top another clear block .
Cost: move operation cost 2.

3.2 Slotted Blocks Domain

domain Blocks Domain above. However, table
bounded number slots blocks placed. One state domain
seen Figure 3.
World States Goals: basic predicates make world states goals are:

On(x; y): x blocks; meaning block x (directly)
block .

173

fiZlotkin & Rosenschein

At(x; n): x block n slot name; meaning block

x (directly) table slot n.
Clear(x): x block; meaning block
x, i.e., Clear(x) :9y On(y; x).
Atomic Operations: two operations Slotted Blocks Domain:

PickUp(i) | Pick top block slot (can executed whenever slot

empty);
PutDown(i) | Put block currently held slot i.
agent hold one block time.
Cost: operation cost one.

Slotted Blocks Domain different Blocks Domain two ways:
1. table unlimited size replaced bounded table distinguishable locations call \slots."
2. atomic \Move" operation broken two sub-operations PickUp PutDown.
allows cooperation among agents. example, want swap
blocks slot 1 Figure 3 would take one agents minimally total
4 Move operations, i.e., block (Black White) touched twice. However,
allow agents use PickUp PutDown operations two agents
swap two PickUp two PutDown operations (which equivalent two
move operations), i.e., block touched once. finer granularity
operations allows exibility scheduling within joint plan.

3.3 Delivery Domain Bounded Storage Space

Delivery Domain, weighted graph G = G(V; E ). v 2 V represents
warehouse, e 2 E represents road. weight function w: E ! IR+ length
given road. edge e 2 E , w(e) length e \cost" e.
agent deliver containers one warehouse another. deliveries, agents
rent trucks, unlimited supply available rental every node.
truck carry 5 containers. warehouse limited capacity holding
containers.
Atomic Operations: operations domain are:

Load(c; t) | loads container c onto truck t. preconditions are:

{ Container c truck warehouse h;
{ Truck less 5 containers board, 5 capacity limit

truck.
results operation are:
{ Warehouse h one container less;
174

fiMechanisms Automated Negotiation

{ Truck one container more.

Load operation costs 1.
Unload(c; t) | unloads container c truck t. preconditions are:
{ Container c truck t;
{ Truck warehouse h;
{ Warehouse h full.
results operation are:
{ Warehouse h one container more;
{ Truck one container less.
Unload operation costs 1.
Drive(t; h) | Truck drives warehouse h. preconditions
operation. result truck warehouse h. cost operation
equal distance (i.e., minimal weighted path) current
position truck warehouse h.
World States Goals: full description world state includes location
container (either warehouse truck) location truck
(either warehouse road). However, restrict goals
specify containers need warehouses.

3.4 Restricted Usage Shared Resource Domain

domain, set agents able use shared resource (such
communication line, shared memory device, road, bridge. . . ). restriction
1 agents use resource time (m denotes
maximal capacity resource).
Atomic Operations: atomic operations Shared Resource Domain are:

Use | agent using shared resource one time unit. Use operation

costs 0.
Wait | agent waiting use shared resource one time unit.
operation costs 1, i.e., waiting one time unit access shared resource
costs 1.
NOP | agent need resource therefore neither uses
waits it. operation costs 0.
objective find schedule time unit
agents performing Use operation.
World States Goals: world state describes current activity agents
accumulated resource usage since time 0 (i.e., accumulated cost). goal
agent state accumulated target number time units
using resource, currently NOP operation. Formally, state
175

fiZlotkin & Rosenschein




e

A1

Joint Plan
A2

A3

A1

0 Use Use Wait
1 Use Use Wait
2 NOP Use Use
3 NOP NOP Use
4 NOP NOP NOP

World States

(Use,0)
(Use,1)
(NOP,2)
(NOP,2)
(NOP,2)

A2

(Use,0)
(Use,1)
(Use,2)
(NOP,3)
(NOP,3)

A3

(Wait,0)
(Wait,0)
(Use,0)
(Use,1)
(NOP,2)

Figure 4: Joint Plan States Restricted Usage Shared Resource Domain

n-element vector, one element agent, element pair consisting

agent's current operation accumulated number time units using
resource (i.e., set states (fWait,Use,NOPg IN) ).
Assume, example, three agents, one resource maximal
capacity two. Agents 1 3 need two units resource, agent 2 needs three
units resource. joint plan seen left side Figure 4, described
matrix. time agent , entry column row agent 's action
time t. resulting world state time unit joint plan seen
right side Figure 4. final state satisfies agents' goals.
n





4. Deals, Utility, Negotiation Mechanisms

defined characteristics State Oriented Domain, looked
simple examples, turn attention agents SOD reach agreement
joint plan brings agreed-upon final state. Hopefully, final state
satisfy agents' goals. However, isn't always possible. three
cases:
1. might case doesn't exist state satisfies agents' goals
(i.e., goals contradict one another);
2. might case exists state satisfies both, cannot
reached primitive operations domain (see Section 2.3.1 above);
3. might case exists reachable state satisfies both,
expensive get agents unwilling expend required
effort.

4.1 Negotiation Mechanism

start presenting simple mechanism suitable cases exists
reachable final state (that is, reachable suciently inexpensive plan) satisfies
agents' goals. call cooperative situation. Later, enhance mechanism
handle possible encounters State Oriented Domains, i.e.,
handle con ict resolution.
176

fiMechanisms Automated Negotiation

Definition 3 Given SOD < ; A; J ; c >, define:
P J set one-agent plans, i.e., joint plans one agent
active role.

cost c(P ) one-agent plan agent k active role, P 2 P ,
vector one non-zero element, position k.
likelihood confusion, use c(P ) stand k-th element (i.e., c(P ) ),
rather entire vector.
k

Definition 4 Best Plans

! f minimal cost one-agent plan P agent k plays active role
moves world state state f .
plan exist ! f stand constant plan ./
k

k

k

costs infinity agent k 0 agents.

= f ! f stand empty plan costs 0 agents.
! F (where world state F set world states) minimal cost
one-agent plan P agent k plays active role moves world
k

k

state one states F :

c(s ! F ) = min
c(s ! f ):
2
k

k

f

F

mentioned above, moment restricting attention encounters
exist one states satisfy agents' goals.
one state exists? state agents choose reach?
one joint plan reach states? joint plan agents
choose?
example, let's say two states satisfy agents' goals. State 1
two possible roles, one roles costing 6 costing 3. State 2
two roles also, costing 5. State 1 cheaper overall reach, State
2 seems allow fairer division labor among agents.
Assuming agents want agreement ecient, decide reach
State 1. agent role costs 6, role
costs 3? approach allow agree \lottery" equalize
benefit derive joint plan. Although eventually one agent
other, expected benefit two agents identical (prior holding
lottery). plans include probabilistic component called mixed joint plans.
Throughout paper, limit bulk discussion mechanisms twoagent encounters. Initial work generalization techniques encounters among
two agents found elsewhere (Zlotkin & Rosenschein, 1994). research
considers issues coalition formation n-agent Task Oriented Domains.

Definition 5 Deals Given encounter two-agent SOD < s; (G1; G2) >:
177

fiZlotkin & Rosenschein

define Pure Deal joint plan J 2 J moves world state
state G1 \ G2.
define Deal mixed joint plan J : p; 0 p 1 2 IR J Pure
Deal.

semantics Deal agents perform joint plan (J1; J2)
probability p, symmetric joint plan (J2 ; J1) probability 1 , p (where agents
switched roles J ). symmetric abilities assumption Section 2.4,
agents able execute parts joint plan, cost role
independent agent executes it.

Definition 6

= (J : p) Deal, Cost () defined pc(J ) + (1 , p)c(J ) (where k


i's opponent).



k

Deal, Utility () defined c(s ! G ) , Cost ():






utility (or benefit) agent deal simply difference
cost achieving goal alone expected part deal. Note write (for
example) c(s ! G ) rather c(s ! G ); since cost plan independent
agent executing it.
k





Definition 7

Deal individual rational if, i, Utility () 0:
Deal pareto optimal exist another Deal dominates it|


exist another Deal better one agents worse
other.

negotiation set NS set deals individual rational
pareto optimal.

necessary condition negotiation set empty contradiction two agents' goals, i.e., G1 \ G2 6= ;. states exist
intersection agents' goal sets might, course, reachable given domain
actions agents disposal. condition reachability sucient
NS empty, however, even contradiction
agents' goals, may still cooperative solution them. situation,
joint plan satisfies union goals cost one agent (or both)
would spent achieving goal isolation (that is, deal individual rational).
example Slotted Blocks Domain, consider following encounter.
initial state seen left Figure 5. A1's goal \The White block slot 2
table" A2 's goal \The Black block slot 1 table."
achieve goal alone, agent execute one PickUp one PutDown;
c(s ! G ) = 2. two goals contradict one another, exists state


178

fiMechanisms Automated Negotiation

world satisfies (where White Black blocks placed
Gray block). exist joint plan moves world initial
state state satisfies two goals total cost less eight2 |that is, deal
individual rational.
Initial State

1

A1s
goal

2

3

1

.
.
.

2

3

Joint plan

1

A2s
goal

2

.
.
.

1

2

3

1

2

3

Figure 5: Con ict Exists Even Though Union Goals Achievable
existence joint plan moves world initial state mutuallydesired state G1 \ G2 necessary (but sucient) condition negotiation set
non-empty. agents agree joint plan, individual rational.
means sum roles agents play exceed sum
individual stand-alone costs (otherwise, least one agents would get positive
utility, i.e., work stand-alone plan). even condition
sucient guarantee individual rational deal, since case minimal
role joint plan still expensive agent minimum stand-alone cost.
Even probabilistic mixture two roles reduce expected cost
agent cost minimal role (and thus role individual rational
him).
show, however, combination conditions necessary sucient negotiation set empty.

Theorem 1 necessary sucient condition negotiation set empty
existence joint plan moves world initial state state G1 \ G2
satisfies following two conditions (the sum condition min condition):

joint plan J satisfies sum condition

X2 c(s ! G ) X2 c(J ) :


=1



=1





2. One agent lifts white block, agent rearranges blocks suitably (by picking
putting block once), whereupon white block put down. best plan
block picked put once.

179

fiZlotkin & Rosenschein

joint plan J satisfies min condition
2

2

min
c(s ! G ) min
c(J ) :
=1
=1








Proof:

NS 6= ;; let J : p mixed joint plan NS; thus, individual rational.
8i 2 f1; 2g
Utility (J : p) 0
c(s ! G ) , Cost (J : p) 0
c(s ! G ) Cost (J : p)
c(s ! G ) pc(J ) + (1 , p)c(J )
min 2f1 2gc(J )
c(s ! G )
c (J )










X

X



k

;

l



2f1 2g

;



;

min c(s ! G ) min c(J )

2f1 2g





l

2f1 2g





2f1 2g



;





;

Let J minimal total cost joint plan moves world state state
G1 \ G2 ; satisfies sum min conditions. show NS =
6 ;;
sucient show exists deal individual rational pareto
optimal. Without loss generality, assume c(s ! G2) c(s ! G1 )
c(J )2 c(J )1: min condition, see c(s ! G1) c(J )1:
two cases:

{ c(s ! G2) c(J )2; deal J : 1 individual rational.
{ c(s ! G2) < c(J )2; deal J : p (where p = 1 ,
individual rational.

( ! 1 ), ( )1 )
( )2 , ( )1

c

c J

G

c J

c J



J : p pareto optimal, another deal J 0 : q dominates J : p
J 0 : q individual rational therefore satisfies min sum conditions

(see proof, above, initial half theorem).
Since J 0 : q dominates J : p implies

X



2f1 2g

Utility (J 0 : q ) >


;

X Utility (J : p):

X

true

2f1 2g



;

X c(J ) :

c(J 0) <


;



2f1 2g



2f1 2g





;

contradicts fact J minimal total cost joint plan satisfies
sum min conditions.
180

fiMechanisms Automated Negotiation

sum condition states sum roles exceed sum individual
agents' stand-alone costs. min condition states minimal role joint plan
less minimum stand-alone cost.
conditions Theorem 1 true, say encounters cooperative. encounters, agents use negotiation mechanism mixed joint
plans. question next examine kind negotiation mechanism
use.

4.2 Mechanisms Maximize Product Utilities

general would negotiation mechanism symmetrically distributed,
would negotiation strategy (for mechanism)
equilibrium itself. symmetrically distributed mechanism one agents
play according rules, e.g., special agents different responsibility negotiation process. asymmetric negotiation mechanisms used,
problem responsibility assignment needs resolved first (e.g.,
coordinator agent). would need special mechanism responsibility assignment negotiation. mechanism asymmetric need another mechanism,
on. Therefore, better symmetric negotiation mechanism start with.
Among symmetric mechanisms, prefer symmetric negotiation strategy equilibrium. Given negotiation mechanism , say
negotiation strategy equilibrium if, assumption
agents using strategy using , (or agent) cannot better using
negotiation strategy different .
Among symmetrically distributed negotiation mechanisms symmetric
negotiation strategy equilibrium, prefer maximize product
agents' utilities. means agents play equilibrium strategy,
agree deal maximizes product utilities. one
product-maximizing deal, agree deal (among product maximizers)
maximizes sum utilities. one sum-maximizing product
maximizer, protocol choose among deals arbitrary probability.
definition implies individual rationality pareto optimality agreed-upon
deals.
Note maximization product utilities decision agents
assumed making run-time; property negotiation mechanism agreed
upon agent designers (i.e., exploring happens protocol designers
would agree property). classic game theory terms (see Section 9.1),
protocol acts kind \mediator," recommending \maximization product
utilities" cases.
call class mechanisms Product Maximizing Mechanisms, PMMs.
previous work TODs (Zlotkin & Rosenschein, 1989, 1993a) presented Monotonic
Concession Protocol One-Step Protocol, PMMs. mentioned
above, paper examine computational issues arise discovering deals.
number existing approaches bargaining problem game theory.
One earliest popular Nash's axiomatic approach (Nash, 1950; Luce
181

fiZlotkin & Rosenschein

& Raiffa, 1957). Nash trying axiomatically define \fair" solution bargaining
situation. listed following criteria ones fair solution would satisfy:
1. Individual rationality (it would fair participant get less would
anyway without agreement);
2. Pareto Optimality (a fair solution specify agreement could improved
one participant without harming other);
3. Symmetry (if situation symmetric, i.e., agents would get utility
without agreement, every possible deal, symmetric deal possible,
fair solution symmetric, i.e., give participants
utility);
4. Invariance respect linear utility transformations. example, imagine two
agents negotiating divide $100. one agent measures utility
dollars measures cents, uence fair solution.
Similarly, one agent already $10 bank, evaluates deal gives
x dollars utility 10 + x evaluates deal
utility x, uence fair solution (i.e., change origin doesn't affect
solution);
5. Independence irrelevant alternatives. Imagine two agents negotiating
divide 10,000 cents. Nash solution 5,000 cents each, due
symmetry assumption above. imagine agents negotiating
$100. Even though deals can't reach (for example,
one one agent gets $49.99, gets $50.01), solution
same, original solution 5,000 cents still found new
deal space.
Nash showed product maximizing solution satisfies criteria,
solution satisfies them. first four criteria explicitly
implicitly assumed approach (in fact, example, version fourth
assumption restrictive Nash's). fifth criteria assumed
work, turns true cases anyway. use Nash solution,
general, reasonable bargaining outcome, applicable. Nash, however,
assumptions space deals have. example,
Nash bargaining problem assumes bounded, convex, continuous, closed region
negotiation. agent negotiations, assume space deals convex,
continuous.

4.3 Worth Goal

encounter cooperative, agents use PMM mixed joint plans.
mechanism guarantees fair ecient cooperative agreement. question now,
however, done non-cooperative encounters?
Consider encounter Restricted Usage Shared Resource Domain
three agents, one resource maximal capacity two. Agents 1
182

fiMechanisms Automated Negotiation




e

A1

Agents
A2

A3

0 Use Use Wait
1 Use Use Wait
2 NOP Use Use
3 NOP NOP Use
4 NOP NOP NOP

0
1
2
3
4
5

A1

Agents
A2

A3

Use Wait Use
Use Wait Use
NOP Use NOP
NOP Use NOP
NOP Use NOP
NOP NOP NOP

Figure 6: Two Joint Plans Restricted Usage Shared Resource Domain
3 need two units resource agent 2 needs 3 units resource.
agent, alone world, could achieve goal cost (i.e., without waiting
resource). However, since maximal capacity resource two, three
agents together cannot achieve combined goal without agent wait.
Two possible joint plans achieve agents' goals seen Figure 6. left
joint plan gives agents 1 2 utility 0, giving agent 3 utility ,2. right joint
plan gives agents 1 3 utility 0, giving agent 2 utility ,2. Globally, plan
left finishes sooner. perspective individual agents, two plans
really comparable|in one, agent 3 suffers waiting two time units, other,
agent 2 suffers exactly amount. assumed, however, agents
concerned global aspects resource utilization, concerned
local cost. addition, plans Pareto Optimal, neither
individual rational (because one agent gets negative utility).
exists joint plan J brings world state satisfies agents'
goals, either min condition sum condition true, agents
cooperatively bring world state satisfies agents' goals, least one
alone world achieved
goals. either one agree extra work? depends important
goal agent i, i.e., much willing pay bring world state G .
example, Shared Resource encounter above, agent 2 3 might willing
wait two time units get turn resource. Although could
done better alone world, must cope presence
agents. original definition utility, deal achieves agents' goals
individual rational|someone wait, thus get negative utility.
utility definition, agent willing wait. agents fail reach
agreement, one achieve goal. utility calculated
difference cost agent's plan alone world cost
role joint plan agents.
However, agents use stand-alone cost baseline determining
utility? may case agents willing, presence agents,
admit need pay extra cost, sort \coordination overhead." fact
agents around necessarily make irrational more.


183

fiZlotkin & Rosenschein

Task Oriented Domains (Zlotkin & Rosenschein, 1989, 1993a, 1994), reasonable
use stand-alone cost utility baseline since never coordination overhead.
worst case, agent could always achieve goal stand-alone price,
coordination could improve situation. State Oriented Domains, however,
makes sense consider altering utility baseline, agents rationally coordinate
even exists coordination overhead. One way assume
agent upper bound cost willing bear achieve goal.
Then, agent's utility measured relative upper bound. call upper
bound worth agent's goal.
Even TODs, one conceive stand-alone cost worth agent assigns
achieving goal. stand-alone cost maximum agent willing
expend. TOD, maximum need never violated, it's reasonable worth value
use.
upper bound exist, i.e., agent willing achieve goal
cost, techniques used (see Section 6 below).

Definition 8 Given encounter two-agent SOD < s; (G1; G2) >, let w maxi

imum expected cost agent willing pay order achieve goal G . w
called worth goal G agent i. denote enhanced encounter
< s; (G1; G2); (w1; w2) > :






definition Utility usefully altered follows:

Definition 9 Given encounter < s; (G1; G2); (w1; w2) >; deal, i.e., mixed
joint plan satisfying agents' goals, Utility ( ) defined w , Cost ( ):






utility agent deal difference worth goal
achieved, cost role agreed-upon joint plan. agent achieves
goal alone, utility difference worth goal cost
pays achieve goal. point is, agent might better alone still
derive positive utility joint plan, use worth utility baseline.
new definition utility, may rational compromise.

Theorem 2 Theorem 1 change every occurrence c(s ! G ) w ,


theorem still true.



Proof: Substitute w every occurrence c(s ! G ) proof Theorem 1.




introducing worth concept definition encounter, enlarged
number encounters non-empty negotiation set. Cooperative behavior
enhanced. negotiation mechanism, makes use product maximizing protocol,
becomes applicable SOD encounters.

4.4 Interaction Types

discussion above, begun see emerging different kinds encounters
agents. TOD meetings, agents really benefit coordination. SODs,
184

fiMechanisms Automated Negotiation

isn't necessarily case. Sometimes agents benefit, sometimes called upon
bear coordination overhead everyone achieve goals. even extreme
situations, agents' goals may simply con ict, might impossible satisfy
time, coordination overhead may exceed willingness
agents bear required burden.
four possible interactions, point view individual agent:

symmetric cooperative situation one exists deal negotiation

set preferred agents achieving goals alone. Here, agents
welcome existence agent.
symmetric compromise situation one individual rational deals
agents. However, agents would prefer alone world,
accomplish goals alone. Since agent forced cope presence
other, would prefer agree reasonable deal. deals NS
better agents leaving world initial state s.
non-symmetric cooperative/compromise situation one one agent views
interaction cooperative (he welcomes existence agent),
second views interaction compromise (he would prefer alone
world).
con ict situation one negotiation set empty|no individual rational
deals exist.
general SOD, four types interaction arise. TOD, symmetric
cooperative situation ever exists.



u





@@
@@
@@@@
@R

G1

G2

Figure 7: Symmetric Cooperative Situation
situations visualized informally using diagrams. symmetric
cooperative situation seen Figure 7, symmetric compromise situation Figure 8, non-symmetric cooperative/compromise situation Figure 9, con ict
situation Figure 10. point plane represents state world. oval
represents collection world states satisfies agent's goal. initial state
world. triple lines emanating represent joint plan moves world
final state. agents share carrying joint plan.
185

fiZlotkin & Rosenschein



u


@
@@
@@

@@@R G1

G2

Figure 8: Symmetric Compromise Situation



u


@
@@ G
@@@@ 2
@R

G1

Figure 9: Non-Symmetric Cooperative/Compromise Situation
overlap ovals represents final states satisfy goals agents A1
A2 . Informally, distance either oval represents cost associated
single-agent plan transforms world state satisfying agent's goal.
Note Figure 8, distance either agent's oval less distance
overlap ovals. represents situation would easier
agent simply satisfy goal, alone world. Figure 7, agent
actually benefits existence other, since share work joint

u





-

q

G1

?

G2

Figure 10: Con ict Situation
186

fiMechanisms Automated Negotiation

plan. Note Figure 9, one agent benefits existence other,
would prefer alone world.
Let's consider simple examples slotted blocks world domain cooperative,
compromise, con ict situations. initial situation depicted Figure 11, white
block slot 1 black block slot 2. Agent A1 wants white block alone
slot 2, agent A2 wants black block alone slot 1. either agents alone
world, would cost 4 pickup/putdown operations achieve goal.
example, A1 would pick black block slot 2 move slot 3,
pick white block slot 1 move slot 2. two agents together, however,
able achieve goals total cost 4. execute joint plan
simultaneously pick blocks, put appropriate places.
role joint plan costs 2, agent derives utility 2 reaching
agreement other. cooperative situation. Coordination results actual
benefit agents.

Initial State

1

2

A1s goal

3

1

A2s goal

2

Joint plan
1

2

1

2

3

3

1

2

3

Figure 11: Cooperative Situation
let's consider complicated, compromise, situation. initial state shown
Figure 12, white block slot 1, black block slot 2, two gray blocks
slot 3. Agent A1 's goal white block somewhere slot 2,
table. Similarly, agent A2 's goal black block somewhere slot 1,
table. Alone world, agent A1 would one pickup one putdown
operation, moving white block onto black block slot 2. way,
agent A2 alone world achieve goal two operations. since
(in stand-alone plan) using other's block base, achievement state
satisfies agents' goals requires additional blocks operations.
best plan achieving agents' goals requires moving one gray block slot
3 slot 1 gray block slot 2 act bases white
black blocks. block needs picked put least once; best plan
187

fiZlotkin & Rosenschein

block moving total cost 8. Obviously, one agents need
extra work (greater stand-alone situation) bring mutually
satisfying state.
Initial State

1

2

A1s
goal
3

1
1

.
.
.

2

3

Joint plan

A2s
goal

2

.
.
.

1

2

3

1

2

3

Figure 12: Compromise Situation
best plan two roles, one requiring 6 operations one requiring 2 operations.
One agent lift black (or white) block, agent rearranges
blocks appropriately. first agent put black (or white) block,
completing plan. agents' worths satisfy min sum conditions (meaning,
here, sum worths greater equal 8, worth greater
equal 2), reach agreement gives positive utility
(using worth new baseline evaluating utility).
example, let's say agent A1 assigned worth 3 achieving goal,
agent A2 assigned worth 6 achieving goal. Since one role best joint plan
costs 2 costs 6, one unit utility shared agents.
mechanism maximizes product utilities split one unit equally
agents. done case? one deal negotiation set
gives agents expected utility 21 , namely mixed joint plan
agent A1 cost-2 role probability 78 , cost-6 role probability
1
A2 course assumes complementary role. Agent A1 's expected utility
8 . Agent
7
3 , 2( 8 ) , 6( 18 ) = 12 ; equal agent A2 's expected utility 6 , 2( 18 ) , 6( 78 ) = 12 :
division utility maximizes product expected utility among agents.
interesting phenomenon note deal. agents apparently
symmetric situation, apart internal attitude towards achieving goals
(i.e., much willing pay). seen above,
willing pay, pay. agent worth 3 ends
less expected work agent worth 6. gives agents incentive
misrepresent true worth values, pretending worth values smaller
really are, agents' positions within negotiation strengthened.
agent feign indifference, claim really doesn't care much achieving
188

fiMechanisms Automated Negotiation

goal, come better negotiation (with lower expected cost). examine
question greater detail Section 8.
final example con ict situation, shown Figure 13. Again, white
block slot 1 black block slot 2|the initial state
cooperative compromise examples. cooperative example, agents wanted
blocks moved another, empty slot. compromise example, agents wanted
blocks moved specific non-empty slot. Here, con ict example, agents want
blocks moved onto specific block specific slot. Agent A1 wants white
block top black block slot 2; agent A2 wants black block top white
block slot 1. Here, real contradiction two agents' goals.
exists world state satisfies both. next section, discuss
kinds coordination mechanisms used con ict situation.
Initial State

1

2

A1s
goal
3

1

A2s
goal
1

2

1

3

1

?

2

3

2

3

2

Figure 13: Con ict Situation
negotiation set empty, distinguish compromise
cooperative situations particular agent using following algorithm:
1. w c(s ! G ); agent cooperative situation.
2. w > c(s ! G ); agent might cooperative compromise situation.
way distinguish follows:
(a) Set w = c(s ! G ); leave agent's worths unchanged.
(b) resulting NS empty, agent compromise situation.
(c) Otherwise, agent cooperative situation.












5. Con ict Resolution Cooperation

seen cooperative compromise encounters exist deals
individual rational agents. Agents negotiate deals
reached, one. What, however, done agents
189

fiZlotkin & Rosenschein

con ict situation, i.e., individual rational deals? Here, agents true
con ict needs resolved, merely choosing among mutually acceptable
outcomes.

5.1 Con ict Resolution

simple approach con ict resolution would agents ip coin decide
going achieve goal going disappointed. See Figure 14.
case negotiate probabilities (weightings) coin toss. run
con ict negotiation (fail agree coin toss weighting), world
stay initial state s.3
Initial State

1

2

A1s Goal

3

1

2

3

Flip coin
A2s Goal
1

2

1

2

3

1

2

3

Figure 14: Con ict Resolution
deal visualized graphically Figure 15. Single lines represent one agent
plans.
con ict situations agents use utility product maximizing protocol
decide weighting coin. However, turns case probability
12 always results maximum product two agents' utilities. agents
maximize utility product, always agree symmetric coin.
exception initial state already satisfies one agent's goal. Then, agent
simply cause negotiation fail, rather risk moving away goal-satisfying
state. Nevertheless, even here, product maximizing deal would agents ip
symmetric coin.
symmetric coin going maximize product agent utilities? simple
mathematics shows reason. Assume agent A1 worth w1, cost
achieving goal alone c1 . A1 wins coin toss, utility w1 , c1.
utility deal coin weighting p p(w1 , c1). opponent's utility
3. special case initial state already satisfies one agent's goals, let's say agent
1 (s cannot satisfy goals since would con ict situation). case,
agreement reached leave world state s. Agent 1 agree deal
cause negotiation fail.

190

fiMechanisms Automated Negotiation

u





-

q

G

?



G

b

Figure 15: Con ict Situation
deal (1 , p)(w2 , c2). product two agents' utilities
(p , p2 )(w1 , c1)(w2 , c2). function p maximized p equals 21 values
w1; w2; c1; c2 (simply take derivative function set equal zero).
may seem \fair" solution, certainly ecient one.
maximizing product agents' utilities, maximize sum. sum
utilities maximized simply agent larger w , c achieve
goal. This, hand, certainly fair solution.
might able fair ecient agents able transfer utility one
another. case, one agent could achieve goal share part utility
agent. negotiation would center much utility
transferred! product maximizing mechanism used resolve question transfer
half gained utility agent, constant sum game, dividing
utility equally maximizes utility product.
entire subject explicit utility transfer side payments complicated one
treated length game theory community. intention
examine questions paper. Even utility explicitly transferable, agents
make commitments perform future actions, effect transfer utility
promises. Again, many complicated issues involved assessing value
promises, believed, discount factors, limits amount
promising debts agent accrue. agents accumulate debt indefinitely,
possible always pay previous commitments making additional
commitments others. Here, too, leaving issues aside, returning
assumptions interaction stands own, explicit side payments
possible.




5.2 Cooperation Con ict Resolution
cooperative compromise situations, agents implicitly able transfer utility
single encounter actions joint plan. agent
work joint plan relieves agent, increasing latter's utility.
thought kind utility transfer. Here, see similar kind implicit utility
transfer possible even con ict situations.
191

fiZlotkin & Rosenschein

agents may find that, instead simply ipping coin con ict situation,
better cooperatively reach new world state (not satisfying either
goals) ip coin decide whose goal ultimately satisfied.
Consider following example. One agent wants block currently slot 2
slot 3; agent wants slot 1. addition, agents share goal
swapping two blocks currently slot 4 (i.e., reverse stack's order). See Figure 16.
Assume W1 = W2 = 12. cost agent achieving goal alone 10.
agents decide ip coin initial state, agree weighting 21 ,
brings utility 1 (i.e., 12 (12 , 10)). If, hand, decide swap
cooperatively (at cost 2 each), ip coin, still agree weighting
12 , brings overall utility 4 (i.e., 12 (12 , 2 , 2)).
Initial State

1

2

3

A1s goal
4

1

2

3

4

Semi-cooperative
deal

A2s goal

2

1

1

2

3

4

1

2

3

4

Figure 16: Cooperation Certain Point
fact agents, even con ict situation, get utility first cooperatively working together, ipping coin, exploited defining new
kind deal, called Semi-Cooperative Deal. want agents able negotiate
agree deal allows mixed cooperative/con ict resolution interaction.
Changing deal type enough make possible. ends increasing expected
utility agents derive encounter.

Definition 10 Semi-Cooperative Deal tuple (t; J; q) world state, J

mixed joint plan moves world initial state intermediate state t,
0 q 1 2 IR weighting coin toss|the probability agent A1 achieve
goal.

semantics kind deal two agents perform mixed joint
plan J , bring world intermediate state t. Then, state t, ip
coin weighting q decide continues plan towards goal. allows
agents handle con ict goals, still cooperating certain
point.
192

fiMechanisms Automated Negotiation

utility semi-cooperative deal agent defined follows. loses
coin toss intermediate state t, simply negative expected utility equal
expected cost role joint plan reached state t. wins coin toss
intermediate state t, expected utility difference worth goal
costs role joint plan reached well stand-alone cost
moving goal state. written formally follows:

Definition 11
Utility (t; J; q ) = q (w , c(J ) , c(t ! G ) ) , (1 , q )c(J )
= q (w , c(t ! G ) ) , c(J )


























assumes, course, agents' goals con ict|the state satisfies
one agent worth other.
Semi-Cooperative Deal visualized graphically Figure 17. figure
similar spirit figures presented Section 4.4, represented cooperative,
compromise, con ict encounters. Again, triple line represents joint plan
single line represents one-agent plan.

u
u





@@
@@@R

q

- G1

?

G2

Figure 17: Semi-Cooperative Deal

5.3 Semi-Cooperative Deals Non-Con ict Situations

cooperative compromise situations, agents negotiate deals mixed
joint plans, J : p (cooperative deals). con ict situation, agents negotiate deals
form (t; J; q ) (semi-cooperative deals).
Even though semi-cooperative deals intended used con ict situations,
used cooperative compromise situations (with minor generalization
definition utility, discussed below). question is, kinds agreements
agents non-con ict situation reach, negotiating semi-cooperative deals?
better using standard cooperative (mixed joint plan) deals?
worse?
cooperative deal mixed joint plan J : p represented (J (s); J : p; 0)
J (s) final world state resulting joint plan J initial state s.
words, mixed deals proper subset semi-cooperative deals, mixed
193

fiZlotkin & Rosenschein

deal represented semi-cooperative deal special form. intermediate state
taken final state agents' cooperative joint plan. Since final state
satisfies agents' goals, result coin ip irrelevant|neither agents
wants change world state anyway.
Therefore, agents non-con ict situation negotiate semi-cooperative
deals, enlarging space agreements. deal reached
negotiating subset (i.e., mixed joint plans) reached negotiating
larger set (i.e., semi-cooperative plans). agents non-con ict situation
certainly worse, using semi-cooperative deals. better?
two potential ways agents could better. first would
agents find cheaper way achieve goals. turns impossible|
semi-cooperative deals uncover ecient way achieving agents' goals.
However, surprising way agents benefit semi-cooperative
deals. Agents benefit always achieving goals. using semi-cooperative
deals, give guaranteed goal satisfaction, gain expected utility.
see mean, consider following example Slotted Blocks World.
initial situation Figure 18 consists 5 duplications example Figure 5, slots
1 15. addition, two slots (16 17) contain stack 2 blocks. Agent A1 's goal
\White blocks slots 2; 5; 8; 11 14 table; blocks slots 16
swapped, blocks slot 17 swapped (i.e., tower reversed)." Agent
A2's goal \Black blocks slots 1; 4; 7; 10 13 table; blocks
slot 16 swapped, blocks slot 17 swapped."
Initial State

1

2

...

3

13

14

15

16

17

15

16

17

A1s goal
.
1

2

.
3

...

13

14

A2s goal
.
1

.
2

3

...

13

14

15

16

17

Figure 18: Semi-Cooperative Agreement Cooperative Situation
stand-alone cost agents is: c(s ! G ) = 26 = (5 2)+(2 8). Let's assume
w = 26 worth goal. minimal cost joint plan achieves
agents' goals 7 parts:




Cooperative swap slot 17 agent one pickup one putdown;
swap slot 16;
194

fiMechanisms Automated Negotiation

Five duplications joint plan Example 5. joint plans
role costs 6 role costs 2.

Thus average cost agent's role joint plan 24, namely (2 2) +
(5 12 (6 + 2)): Since stand-alone cost 26, situation cooperative|each agent
welcomes existence other. agents, expected utility joint plan
2 (i.e., 26 , 24). cooperative deal achieves agents' goals.
find semi-cooperative deal better? agents cooperated
swapping blocks slots 16 17, tossed coin see gets fulfill
goal (leaving other's goal unsatisfied)? semi-cooperative deal actually turns
better agents.
Let intermediate state state blocks slots 16 17 swapped,
slots unchanged. agent invests 4 operations part two
swaps. chance 12 continuing achieve goal, chance
12 losing coin toss wasted initial investment. wins coin toss,
additional 10 operations (5 2), achieve goal worth 26. Overall
utility 26 , 10 , 4; i.e., 12. loses coin toss, wasted initial
investment 4, utility ,4. expected utility average two cases,
i.e., 4. better utility 2 agents got using cooperative deal!
words, case, agents would prefer guarantee
goal, take gamble semi-cooperative deal. expected utility doubles,
willing take risk. even cooperative situation, agents benefit
negotiating semi-cooperative deals.
Now, turns borderline situation, brought w low.
long w high enough, semi-cooperative deal agents agree cooperative
situation equivalent cooperative deal. achieving goal isn't worth much
(your profit margin small), might willing forgo guaranteed achievement
exchange higher expected utility.
semi-cooperative deals, used non-con ict situation, sometimes result better
agreements (when forgoing guaranteed goal achievement beneficial), never result
worse agreements. Clearly, worthwhile agents negotiate semi-cooperative
deals, regardless whether cooperative, compromise, con ict situations.




5.4 Unified Negotiation Protocols (UNP)

section, make necessary generalizations agents use semicooperative deals types encounters. call product maximizing mechanisms
based semi-cooperative deals \Unified Negotiation Protocols (UNP)," since
used con ict resolution, well cooperative agreements.4
mentioned above, need generalize previous definition utility
semi-cooperative deal, enable UNPs. Before, assumed (since con ict
situation) final state would benefit agent lost coin toss.
4. earlier version subsection next two appeared (Zlotkin & Rosenschein, 1991a).
current treatment incorporates new material multi-plan deals, recasts protocols context
domain theory, alters notation correspond general domain framework.

195

fiZlotkin & Rosenschein

Now, even though semi-cooperative deal used, final state might still satisfy
agents' goals, goal agent wins coin toss.
(t; J; q ) semi-cooperative deal, we'll define f final state world
agent wins coin toss state t. f = (t ! G )(t) 2 G . worth agent
state r, write W (r), goal worth w r goal state,
0 otherwise. Now, revise definition utility semi-cooperative deals:












Definition 12 Utility (t; J; q) = q (w , c(t ! G ) ) + (1 , q )w (f ) , c(J )












j



utility semi-cooperative deal (t; J; q ) agent defined
expected worth final state minus expected cost. worth expected final
state, course, depends weighting coin, whether possible final
states (or one) goal states agent. Similarly, expected cost depends
weighting coin (whether agent participates first, joint, plan,
continues second, lone, plan).
definition utility given completely consistent earlier definition
utility cooperative deals, viewed generalization earlier
definition. words, cooperative deal (a mixed joint plan) mapped
semi-cooperative deal (t; J; q ) using transformation discussed above, definition
utility mixed joint plan (Definition 9) definition utility (Definition 12)
semi-cooperative deal yield number.
sucient condition negotiation set non-empty semi-cooperative
deals agents' worths high enough, agent would able achieve
goal alone:

Theorem 3 agent worth goal greater equal standalone cost (i.e., 8i w c(s ! G )), negotiation set semi-cooperative deals
empty.




Proof: show NS 6= ;; sucient show individual rational

semi-cooperative deal. existence pareto-optimal deals among individual rational
deals due compactness deal space (since finite number
agent operations, worth agent goals bounded). (s; ; q ); empty
joint deal, individual rational q:
condition sucient, necessary, negotiation set nonempty. example, consider situation given Figure 16, agents'
worths equal 8 (instead 12). Neither agent achieve goal alone, thus
conditions theorem satisfied. However, perfectly good
semi-cooperative deal gives agents positive utility|they perform joint plan
swaps blocks slot 4, ip coin see whether block slot 2 goes slot 1
3. mixed deal gives agent expected utility 1. negotiation set
empty.
turns semi-cooperative deal negotiation set, one
agents, winning coin toss, bring world state satisfies agents'
goals, exists another deal negotiation set utility
agents intermediate state already satisfies agents' goals.
196

fiMechanisms Automated Negotiation

Theorem 4 semi-cooperative deal (t; J; q) 2 NS, exists f 2
G1 \ G2, semi-cooperative deal equivalent cooperative deal.
Proof: two cases: final states, one final state, G1 \ G2:
f1; f2 2 G1 \ G2; view last step performing mixed joint plan
moves world state state G1 \ G2 .
c(t ! G1) = c(t ! G1 \ G2) = c(t ! G2 );
X (t ! )(t) 2 X; c(t ! X ) = c(t ! ): f1 ; f2
necessarily state, deal equivalent deal f1 = f2 :
look concatenation two mixed joint plans (the first J
t, second ! G1 \ G2 ), mixed joint plan P G1 \ G2 : P
cooperative deal equivalent (t; J; q );
Utility (t; J; q ) = q (w , c(t ! G )) + (1 , q )(w ) , c(J )
= w , (q c(t ! G ) + c(J ) )
= w , c(P )
= Utility (P ):






























f1 2 G1 \ G2 f2 62 G1 \ G2; agent 2 would prefer lose coin toss
state let agent 1 achieve goal without spending more.
deal (t; J; 1) better 1 better 2 well, dominates
(t; J; q ); (t; J; q ) 2 NS; equivalent. (t; J; 1) equivalent mixed
joint plan P agents perform joint plan J t; agent 1
performs one-agent plan ! G1 \ G2: P cooperative deal.

words, exists semi-cooperative deal negotiation set sometimes satisfies agents' goals (depending wins coin toss),
exists another semi-cooperative deal negotiation set always satisfies agents'
goals (equivalent cooperative deal). Even though semi-cooperative deals constitute
superset cooperative deals, extra utility derived using semi-cooperative deals
agreement preserves mutual satisfaction agents (i.e., it's equivalent
cooperative deal).
cooperative situation, agents cannot extract utility semi-cooperative
deal, unless willing agree deal never satisfy agents' goals.
example (Section 5.3) prototype situation. Agents increase
utility using semi-cooperative deal cooperative situation. forgoing
guaranteed mutual satisfaction. theorem implies way
increase utility semi-cooperative deals.

5.5 Multi-Plan Deals

semi-cooperative deals, assume agents cooperate, ip coin, winner
proceeds alone achieve goal. arrangement requires agents engage
197

fiZlotkin & Rosenschein

\pre- ip cooperation." agents willing (or required) engage
\post- ip cooperation"? Then, entirely new dimension agreements would opened
up. section, consider kind deal exploits cooperation coin toss.
illustrate potential new kind deal, consider following encounter,
shown Figure 19.
A1s
Goal

Initial
State
1

2

3

1

2
1

3

?

2

A2s
Goal
1

2

3

1

2

3

Figure 19: Post-Flip Cooperation Helpful
initial state world seen Figure 19. A1 's goal swap position
blocks slot 3, leave blocks slot 2 initial position. A2 's goal
swap position blocks slot 2, leave blocks slot 3 initial
position.
achieve goal alone, agent needs least 8 pickup putdown operations.
Apparently, little room cooperation. final state
satisfies agents' goals, intermediate state (other initial state)
agents cooperatively bring world, tossing coin (as semicooperative deal).
Negotiating semi-cooperative deals, agents agree ip coin initial
state, whoever wins coin toss bring world goal state
(at cost 8). Assume worth agent's goal 10. negotiating
semi-cooperative deals brings agent expected utility 1. compromise
situation (alone world, agent would utility 2).
agents could reach following agreement (as shown Figure 20):
ip coin initial state. Whoever wins toss gets goal satisfied. However,
matter wins, agents commit work together joint plan achieve
chosen goal.
either swap jointly costs total 4 two agents (2 each). agent
wins coin toss gets utility 10 , 2 (his goal satisfied expends 2
joint plan). agent loses gets utility ,2 (he expends 2 joint plan
achieves opponent's goal). agent equal chance winning coin
toss, expected utility 3. better semi-cooperative deal gave
198

fiMechanisms Automated Negotiation

2

1
1

1

2

2
3
1

2

3

Multi-plan deal
1

2

1

2

3

Figure 20: Multi-Plan Deal
agents utility 1. It's even better stand-alone utility 2
agents could get alone! Suddenly, situation become cooperative.
agents welcome other's existence, even though goals nothing common.
goal state satisfies agents; subgoals agents
common; positive interactions agents' stand-alone plans.
goals completely decoupled, yet situation cooperative.
agreement above, course, requires \post- ip cooperation." semi-cooperative
deals, \pre- ip cooperation" contributed potentially either agents' benefit|either
agent might win coin toss exploit early work. new deal type, even
agent loses coin toss required expend effort, knowing
benefit agent.
agents commit post- ip cooperation, new deal type
possible. Agents could negotiate deals pairs mixed joint plans.
call new deals multi-plan deals. committing post- ip cooperation, agents
enlarge space agreements, potentially improves expected utility.

Definition 13

Multi-Plan Deal (1; 2; q); mixed joint plan moves
world state satisfies i's goal. 0 q 1 2 IR probability agents
perform 1 (they perform 2 probability 1 , q ).
Assuming j i's opponent, Utility (1; 2; q) = q(w , Cost ( )) , (1 ,




q )Cost ( ).








j

multi-plan deal agents agreeing two joint plans, deciding execute tossing coin. deal visualized informally Figure 21, Section 4.4
above. triple line represents joint plan, carried multiple agents.
Note symmetric abilities assumption Section 2.4 may essential
(i.e., multi-plan deal type agents may need able perform
199

fiZlotkin & Rosenschein

u





-

q

G1

?

G2

Figure 21: Multi-Plan Deal

plans equivalent cost). two mixed joint plans comprise multi-plan deal might
pure (i.e., p 0 1) without overly restricting agents' ability divide
utility accurately, since agents additional q probability adjust.
semi-cooperative deals used cooperative situations, multi-plan deals
used cooperative situations (since, see below, generalization
semi-cooperative deals). needed enhance definition multi-plan deal
utility appropriately, done semi-cooperative deals (Definition 12).
Consider following example, shows increased utility available agents
share negotiate multi-plan deals instead mixed joint plans.

2

1
1

1

2

2
3
1

2

3

Multi-plan deal
1

2

1

2

3

Figure 22: Relationship Multi-Plan Deal Type Mixed Joint Plans
initial state world seen Figure 22. A1 's goal swap position
blocks slot 3, leave blocks slot 2 initial position (there
one state satisfies goal; call f1 ). A2 's goal swap position blocks
slot 2, leave blocks slot 3 initial position (f2 ).
achieve goal alone, agent needs least 8 pickup putdown operations
(each cost 1). Assume A1 's worth function assigns 10 f1 0
states, A2 's worth function assigns 10 f2 0 states. case,
200

fiMechanisms Automated Negotiation

negotiation set includes deals (s ! f1 ; ): 1 (; ! f2 ): 0. Using protocol
mentioned above, agents break symmetry situation ipping coin.
utility agent deal 1 = 12 (10 , 8).
Negotiation multi-plan deal type cause agents agree (1 ; 2): 12 ,
mixed joint plan agents cooperatively achieve i's goal.
best joint plan swap one slots costs 2 pickup/putdown operations
agent. utility agent deal 3 = ( 12 (10 , 2) + 21 (,2)).
negotiating using multi-plan deal type instead mixed joint plans, utility
agents share, 6 instead 2.


5.6 Hierarchy Deal Types | Summary

exists ordering relationship among various kinds deals agents
considered; call relationship \deal hierarchy." bottom
hierarchy pure deals mixed deals. first two types deals hierarchy
used cooperative situations. negotiation general non-cooperative domains,
additional types deals needed.
Next hierarchy come semi-cooperative deals. shown, semi-cooperative
deals superset mixed deals. Even cooperative situations, may
semi-cooperative deals achieve goals, dominate mixed
joint plans achieve agents' goals.
Finally, top hierarchy, come multi-plan deals, superset semicooperative deals. general deal type deal hierarchy. deal type
serve foundation class Unified Negotiation Protocols.
summary, hierarchy looks follows:

fJ g fJ : pg ft; ; qg f(1; 2): qg
Pure Deals Mixed Deals Semi-Cooperative Deals Multi-Plan Deals

6. Unbounded Worth Goal|Tidy Agents

Section 4.3, assumed agent assigns finite worth achieving goal,
upper bound cost willing spend achieve goal.
upper bound exist? may situations domains
limit cost agent willing pay order achieve goal|he would
willing pay cost. Similarly, may situations agent simply unable,
design, evaluate worth goal. However, even though worth unbounded
unevaluable, agent still interested expending minimum necessary achieve
goal. agent gets utility spends less, determine ordinal
ranking possible deals, even though diculty assigning cardinal values
utility derived deals.
Nevertheless, really interested cardinal values used
negotiation mechanisms. whole approach negotiation founded existence
inter-agent comparable cardinal utility functions. worth unbounded
agents, seem deprived tool depended.
201

fiZlotkin & Rosenschein

would identify different baseline define concept utility.
Originally, above, used baseline \stand-alone cost," c(s ! G ), taking utility
deal agent difference cost achieving goal alone
agent's part deal. Then, used baseline \worth" similar manner,
linearly transforming utility calculation. Utility deal agent
difference maximum cost willing pay agent's part
deal. worth unbounded, however, linear transformation obviously cannot
used.
work (Zlotkin & Rosenschein, 1993b), present alternative baseline
satisfy desire symmetry, fairness, simplicity, stability, eciency. turns
constitute minimum sucient baseline agents reach agreements.
minimum cost agent must offer bear compromise encounter,
neither agent upper bound worth, leaves agent
less cost latter's stand-alone cost. words, first agent offer
\clean himself," carry sucient portion joint plan achieves
goals agent's remaining part joint plan cost less
stand-alone cost. call agent willing clean tidy
agent; formal definition appears elsewhere (Zlotkin & Rosenschein, 1993b). shown
joint-goal reachable encounter (i.e., exists joint plan achieves
agents' goals), agents tidy, negotiation set empty.


7. Negotiation Incomplete Information
mechanisms considered sections straightforwardly implemented
agents full information other's goals worths. many
situations, won't case, section examine happens
negotiating mechanisms State Oriented Domains agents don't necessarily full
information other.
consider incomplete information goals, incomplete information
worths, two separate issues. agent, example, might particular information
worth, goals, vice versa. thus four possible cases,
worths known known, combined goals known known.
previous sections, considered case goals worth known.
section consider two three situations, neither goals worth
known, goals known worth not. analyze situations
worth known goals not.
general conclusion strategic player gain benefit pretending
worth lower actually is. done directly, declaring low worth (in
certain mechanisms), declaring cheaper goal (in case stand-alone cost
taken implicit worth baseline).
first section, consider space lies available different types
interactions, different types mechanisms.
several frameworks dealing incomplete information, incremental goal recognition techniques (Allen, Kautz, Pelavin, & Tenenberg, 1991),
framework explore \,1 negotiation phase" agents simultane202

fiMechanisms Automated Negotiation

ously declare private information beginning negotiation (this introduced
elsewhere (Zlotkin & Rosenschein, 1989, 1993a) case TODs). negotiation
proceeds revealed information true. TOD case, analyzed
strategy agent adopt playing extended negotiation game,
particular, whether agent benefit declaring something true goal.
Here, take similar approach, consider ,1-phase game State Oriented
Domains. agents benefit lying private information? kinds
mechanisms devised give agents compelling incentive tell
truth?5
negotiation mechanism gives agents compelling incentive tell truth
called (in game theory) incentive compatible. Although able construct
incentive compatible mechanism used worths unknown, unable
construct mechanism State Oriented Domains used other's goals
unknown.

7.1 Worth Goal Role Lies
assume agents associate worth achievement particular goal.
Sometimes, worth exactly equal would cost agent achieve goal
himself. times, worth goal agent exceeds cost goal
agent. worth goal baseline calculating utility deal
agent; section, always assume worth bounded.
worth goal intimately connected specific deals agents agree on.
First, agent agree deal costs worth (he would
negative utility deal). Second, since agents agree deal maximizes
product utilities, agent lower worth, ultimately reduce
amount work part deal. Thus, one might expect agent A1 wants
less work, try fool agent A2 thinking that, particular goal, A1's
worth lower really is. strategy, fact, often turns beneficial,
seen below.
Let's consider following example Slotted Blocks World.
initial state seen left Figure 23. G1 \The Black block
Gray block table slot 2" G2 \The White block Gray block
table slot 1".
achieve goal alone, agent execute four PickUp four PutDown
operations cost (in total) 8. two goals contradict other,
exists state world satisfies both. exists joint plan moves
world initial state state satisfies goals total cost 8|one
agent lifts black block, agent rearranges blocks suitably (by
picking putting block once), whereupon black block put down.
agents agree split joint plan probability 12 , leaving expected
utility 4.
5. issues, everyday human contexts, explored (Bok, 1978). immediate motivation
discouraging lies among agents negotiation mechanisms ecient.

203

fiZlotkin & Rosenschein

Initial State

1

2

A1s
goal
3

1

2

3

Joint plan

1

A2s
goal
1

2

2

3

1

2

3

Figure 23: Agents Work Together Equally

7.2 Beneficial Lies Mixed Deals

agent A1 lies true goal above, claiming wants black block
block slot 2? See Figure 24. agent A1 alone world, could
apparently satisfy relaxed goal cost 2. Assuming agent A2 reveals true goal,
agents agree one plan: agent A1 lift block (either white black
one), agent A2 rest work. apparent utility agent A1
0 (still individual rational), agent A2 utility 2. reality, agent A1
actual utility 6. Agent A1 's lie benefited him.

...
1

2

3

1

1

2

2

3

3

1

2

1

2

3

Figure 24: Agent A1 Relaxes Goal
works agent A1 able reduce apparent cost carrying
goal alone (which ultimately causes carry less burden final plan),
compromising ultimate achievement real goal. reason real goal
204

fiMechanisms Automated Negotiation

\accidentally" satisfied one state satisfies agent A2 's real goal
agent A1's apparent goal, coincidentally state satisfies real
goals.
lie agent A1 's beneficial lie example. agent A1
claimed goal \Slot 3 empty Black block clear"? See Figure 25.
Interestingly, goal quite different real goal. agent A1 alone
world, could apparently satisfy variant goal cost 4. agents forced
agree deal above: A1 two operations, apparent utility 2,
agent A2 six operations, utility 2. Again, agent A1's actual utility 6.


1

2

3

1



2

1

2

3

3

1

2

1

2

3

Figure 25: Agent A1 Makes Entirely New Goal
Task Oriented Domains (Zlotkin & Rosenschein, 1989, 1993a), saw something
similar lying goal. There, example, agent could hide task, lower
apparent cost stand-alone plan. Similarly, first lie agent
Blocks World relaxed true goal, lowered apparent cost stand-alone plan
(and thus worth). set states satisfy relaxed goal superset
set states satisfying true goal.
However, major difference lying SODs lying TODs:
latter, never \accidental" achievement hidden goals. lying agent
always find necessary carry hidden goal himself, main
reason subadditive TODs hiding goals beneficial. SODs, hidden goal
might achieved one's opponent, carries actions side effects. Thus,
even hide goal, may fortuitously find goal satisfied front
eyes.
situation visualized informally Figure 26, SOD interactions
Section 4.4 above. figure, agent A1 's expanded apparent goal states represented
thicker oval labeled G01. Note expansion goal states toward
initial state s. meaning lowering one's apparent cost, necessary
beneficial lie.
205

fiZlotkin & Rosenschein



u



@
@@
@@@
@@R

G01
G1

G2

Figure 26: Expanding Apparent Goal States Lie
Alternatively, agent manufacture totally different goal purposes
reducing apparent cost, saw Figure 25. Agent A1 said
wanted slot 3 empty Black block clear. Consider Figure 27, agent A1's
altered apparent goal states represented thick outline labeled G01.
Note again, expansion goal states toward initial state s.



u



@
@@
@@@@
R

G01

G1

G2

Figure 27: Altering Apparent Goal States Lie
agent needs make sure intersection apparent goal states
true goal states empty. Although necessary precondition successful
lie, course sucient precondition successful lie. lies
example useful agent A1 regardless negotiation protocol
used: pure deal, mixed deal, semi-cooperative deal, multi-plan deal.

7.3 Beneficial Lies Semi-Cooperative Deals

might seem agents con ict situation, potential beneficial lies
reduced. fact, beneficial lying exist con ict situations.
\Con ict" agents' goals means exist mixed joint plan
achieves goals individual rational. either state
exist, joint plan costly individual rational. Even
con ict exists goals, might common subgoals, therefore beneficial
lie may exist.
206

fiMechanisms Automated Negotiation

Taking Advantage Common Subgoal Con ict Situation: Let initial

state world Figure 28. One agent wants block currently slot 2
slot 1; agent wants slot 3. addition, agents share goal
swapping two blocks currently slot 4 (i.e., reverse stack's order).
cost agent achieving goal alone 10. Negotiating true goals
using semi-cooperative deals would lead agents agree swap cooperatively
(at cost 2 each), ip coin, weighting 12 , decide whose goal
individually satisfied. deal brings overall expected utility 2 (i.e.,
1
2 (10 , 2) , 2).

1

2

3

..

4

1

2

3

2

. ..

.

1

2

3

4

4

1

1

2

3

4

Figure 28: Taking Advantage Common Subgoal
agent A1 lies tells agent A2 goal is: \The Black block clear
slot 1 White block Gray block"? Agent A1 thus hides fact
real goal stack blocks slot 4, claims really care
stack slot 2, 3 4. cost agent A1 achieving apparent goal 6,
supposedly build reversed stack slot 3 cost 4. Assuming
agent A2 reveals true goal, agents still agree swap cooperatively,
weighting coin 47 . deal would give agent A1 apparent utility
1 37 (i.e., 47 (8 , 2) , 2) A2 's real utility (i.e., 73 (10 , 2) , 2). A1's real utility,
however, 2 74 = 47 (10 , 2) , 2. lie beneficial A1 .
situation illustrated Figure 29, agent A1 's lie modifies apparent goal
states closer initial state, plan still ends bringing
world one real goal states.
example above, existence common subgoal agents allowed
one agent exploit common subgoals (assuming, course, lying agent knew
opponent's goals). lying agent relaxes true goal claiming common
subgoal mainly opponent's demand|as far concerned (he claims), would
satisfied much cheaper subgoal. really necessary achieve expensive
subgoal (he claims), burden must fall opponent.
207

fiZlotkin & Rosenschein




u
u








G0

@@
@@@R



- G1

q

?

G2

Figure 29: Lying Con ict Situation

One might think absence common subgoal, would
opportunity one agent beneficially lie other. This, however, true,
see below.

7.4 Beneficial Lies Multi-Plan Deals
Another Example Beneficial Lying Con ict Situation: initial state

seen Figure 30, similar example used Section 5.5 above. A1 's goal
reverse blocks slot 2, leave blocks slot 1 initial position.
A2 's goal reverse blocks slot 1, leave blocks slot 2 initial
position. achieve goal alone, agent needs least 8 PickUp/PutDown
operations. con ict situation.



1

2

3

1

2

3

1
1

2

2

3

3

2

1

1

2

3

Figure 30: Example Interference Decoy Lie
Negotiation multi-plan deals cause agents agree (1 ; 2): 21 ,
mixed joint plan agents cooperatively achieve i's goal. best joint
plan reverse either one slots costs 2 PickUp/PutDown operations
agent. agent's utility deal 2 = ( 12 (8 , 2) , 21 (2)).


208

fiMechanisms Automated Negotiation

Agent A1 might lie claim goal reverse blocks slot 1 leave
blocks slot 2 initial position (his real goal) white block alone
slot 2. costs A1 6 achieve apparent goal alone. reverse alone would
cost 8, thus achieve imaginary part goal cheaper. agreement
(1; 2 ): 47 , mixed joint plan agents cooperatively
achieve i's goal. turns cheaper agents cooperatively carry
A1's real goal cope A1 's imaginary alternative. A1's apparent utility
1 37 = 47 (6 , 2) , 37 (2). A2 's utility. A1 's actual utility, however,
2 47 = 47 (8 , 2) , 73 (2), greater unvarnished utility 2 A1 would get
without lying. even without common subgoal, A1 beneficial lie.
introduced new type lie, kind \interference decoy," used even
agents' common subgoals.


8. Incomplete Information Worth Goals
Consider situation two agents encounter one another shared environment.
individual goals commonly known (because prior knowledge type
agent, goal recognition process, etc.), well cost achieving goals,
agent alone world. addition, con ict goals.
exists non-empty set states satisfies agents' goals.
agents upper bounds worth, (in contrast public goals)
upper bound private information, known agent. common
situation; agents queue access common resource, goals often selfevident. example, two agents approaching narrow bridge opposite ends may
know wants cross, know crossing worth
(e.g., long willing wait). agents need agree deal (for example,
go first, wait).
One simple way design negotiation mechanism handles lack information
agents exchange private information prior actual negotiation process.
pre-negotiation exchange information another variant ,1-phase game mentioned
above. current case, agents exchange private information worth. section,
consider situation agents negotiating mixed joint plans.
One question, then, agents play ,1-phase game best advantage?
mentioned Sections 4.4 7.2, agent generally incentive
misrepresent worth goal lowering it|the less agent willing pay,
less pay utility product maximizing mechanism (PMM). However,
everyone lowers worth may able reach agreement all, whereas
declared true worth agreement would reached. Agents might lower
worth much driven inecient outcome. instance
free rider problem. Every agent individually motivated lower worth,
someone else carry burden. group whole stands suffer, particularly
agreements reached otherwise would been.
exert control tendency lower one's apparent worth careful design
post-exchange part negotiation mechanism. interested designing
mechanism satisfies desire ecient, symmetric, simple, stable outcomes.
209

fiZlotkin & Rosenschein

research TODs, managed (in certain cases) provide post-exchange mechanism
satisfied attributes, found incentive compatible|the agents'
best strategy declare true goals. section, introduce two mechanisms
private-worth SODs, one \strict," \tolerant," analyze affects
stability eciency negotiation outcomes. strict mechanism turns
stable, tolerant mechanism ecient.

8.1 Strict Tolerant Mechanisms

several cases need addressed mechanism, treated
differently different mechanisms. example, happen one agent declares
worth lower stand-alone cost (i.e., apparently would achieve
goal alone, worth him)? agent still
allowed offer deal, negotiation considered failed point?
mechanisms present start way. agents simultaneously
declare worth value, claimed worth assign achievement goal.

goals apparently achievable alone: agents declare worth

greater stand-alone cost (which commonly known), negotiation proceeds worth declarations true. agents use product
maximizing mechanism negotiation set mixed joint plans, declared worths baseline utility calculations. result equal
division apparent available utility them.
one agent's goal apparently achievable alone: one agent declares
worth greater stand-alone cost, doesn't, former agent
free decide do. either propose take-it-or-leave-it deal
agent (if it's refused, he'll carry goal alone), simply bypass
offer carry goal. Since declared worth greater
stand-alone cost, rational accomplish goal himself.
agents' goals apparently unachievable alone: agents declare
worths lower stand-alone costs, two mechanisms differ
situation handled:

{ Strict Mechanism: con ict, actions carried out.
{

agents derive utility con ict deal.
Tolerant Mechanism: agents continue negotiation first
case (i.e., use mixed joint plans, divide apparent available
utility them). Even though agents claim unwilling achieve
goals alone, may certainly case together, carry
rational joint plan achieving goals.

tolerant mechanism gives agents \second chance" complete negotiation
successfully reach rational agreement, whereas strict mechanism forgive
low worth declarations, \punishes" causing con ict. course,
agents' true worths really lower stand-alone costs, strict mechanism
210

fiMechanisms Automated Negotiation

causes unnecessary failure (and thus inecient), tolerant mechanism still
allows reach deal possible. see below, however, tolerance
sometimes lead instability.
approach rest section consider various relationships
among two agents' worth values, cost values, interaction types, joint
plans achieve agents' goals. relationship, we'll analyze strategies
available agents. mentioned above, considering situations
agents' goals achievable two-agent mixed joint plans (e.g., reachable
states satisfy agents' goals).
idea tidy agents agent cleaning himself, introduced
Section 6, used situations agents willing pay price achieve
goals|their worths unbounded. There, worth could used baseline
utility calculation. Instead, found \minimal sucient" value
utility baseline gave rise ecient fair mechanism. similar idea
useful analysis below. tidy agent baseline, explored above, serves
minimal sucient declaration point worths private information.

8.2 Variables Interest
general, agent would declare low worth possible, without risking
con ict. lower declaration worth, smaller share joint plan be.
Unfortunately agent, declared worth low, may eliminate possibility
reaching agreement. necessary sucient condition negotiation set
empty sum min conditions, Section 4.1, hold (given
declarations worth). Since assume joint plan achieves
agents' goals, agreement still possible among plans least one
satisfies sum min conditions.
several variables play role analysis below. First, agent
stand-alone cost (known all, dependent goal), denoted c .
Second, agent true worth (privately known) assigns achievement
goal, denoted w . total cost minimal (total cost) joint plan
achieves agents' goals. cost minimal role among joint plans
cost . Below, analyze possible configurations variables.
analysis presented according interaction type con ict, i.e., symmetric cooperative, non-symmetric cooperative/compromise, symmetric compromise.
type, consider three subcases depend relationships c ,
w , , .




r





r

8.3 Symmetric Cooperative Situation
symmetric cooperative situations, one strategy agent use declare
worth minimum true worth, maximum stand-alone cost
minimal role joint plan:
Min-Sucient Strategy min(w ; max(c ; )):


211



r

fiZlotkin & Rosenschein

motivation agent wants declare minimal worth sucient
agreement. Declaring c satisfies sum condition, make sure
satisfies min condition, agent must declare max(c ; ). make sure
declaration individual rational, must make declaration greater true
worth, w ; thus, takes minimum w (c ; ) maximum.
Min-Sucient Strategy one possible strategy might adopted. However, agents adopt it, strategy equilibrium (in cases),
agreement guaranteed. analyze characteristics strategy six
cases.










r

r

8.3.1 Goals Achievable Alone

situation (as shown Figure 31), agents would able achieve positive
utility agent around, achieved stand-alone goal
themselves.

Equilibrium Point
W1

conflict
C1

A1 decides

Mr

Negotiation
A2 decides
Mr

C2

W2

Figure 31: Goals Achievable Alone
diagram Figure 31 describes, sense, game normal form. agent
declare worth number 0 infinity. outcome depends two
numbers declared; every point plain possible result. colors regions
denote types outcomes.
Note, example, agent A1 declares less c1 , agent A2 declares
c2 , outcome A2 decide (offering A1 take-it-or-leave-it deal,
going alone). A1 A2 offer little (so sum less ),
reach con ict. assume agents rational, consider areas
plain framed w1 w2 (rational agents would declare worth greater
true worths).
difference Strict Tolerant mechanisms mentioned color
triangle lower left c1=c2 point. Strict mechanism, would
white (con ict), Tolerant mechanism still region allows subsequent
negotiation occur. point equilibrium mechanisms c1 =c2
point, reached Min-Sucient Strategy given above. Thus, strategy
stable ecient Strict Tolerant mechanisms situation.
212

fiMechanisms Automated Negotiation

8.3.2 One Goal Achievable Alone

Assume situation shown Figure 32, one agent would able
achieve positive utility agent around (though ultimately
benefit other's existence, one other).


Equilibrium Point

W1
conflict
C1

A1 decides

Mr

Negotiation
A2 decides
Mr

W2 C2



Figure 32: One Goal Achievable Alone
phenomenon similar Section 8.3.1. negotiation triangle
lower left c1 =w2 white (con ict) Strict mechanism negotiable
Tolerant mechanism. mechanisms, c1=w2 point equilibrium,
point results agents play Min-Sucient Strategy. Again, strategy
stable ecient Strict Tolerant mechanisms situation.
8.3.3 Goals Achievable Alone

consider situation shown Figure 33, neither agent could achieve positive
utility alone world|the way achieve goals cooperating.

Resulting
Non-equilibrium Point

conflict
C1
W1

A1 decides

Mr

Negotiation
A2 decides
Mr

W2 C2



Figure 33: Goals Achievable Alone
Again, negotiation triangle lower left w1=w2 white (con ict)
Strict mechanism, agreement reached situation (the whole plain is,
fact, white). Though Min-Sucient Strategy ecient Strict mechanism,
213

fiZlotkin & Rosenschein

stable. Tolerant mechanism, Min-Sucient Strategy ecient (it results
w1=w2 point), unfortunately stable|assuming one agent declares
w1, agent benefit declaring , w1 instead w2 .
fact, agents actually know situation (the one Figure 32
Figure 33), guaranteed beneficial divergence equilibrium point would really
require total knowledge situation opponent playing. Thus, although
Min-Sucient Strategy stable, agents may unlikely diverge
real-world constraints knowledge.

8.4 Non-Symmetric Cooperative/Compromise Situation
section continue analysis situations one agent, situation
cooperative, other, compromise situation. continue analyze
case agents use Min-Sucient Strategy. Agreement reached
compromising agent contributes stand-alone cost joint plan;
minimal role greater stand-alone cost. way
agents reach agreement compromising agent willing
stand-alone cost|otherwise, con ict.
8.4.1 Compromise Sufficient

situation described Figure 34, true worth compromising agent (w2)
greater minimal role c2.
Equilibrium Point

W1
C1

conflict
A1 decides
Mr

Negotiation
A2 decides
C2 Mr

W2



Figure 34: Compromise Sucient
sucient compromising agent declare true worth. declared
less that, agent declared c1, reach con ict;
declaring , guarantees goal achieved. diagram
Strict Tolerant Mechanisms. Min-Sucient Strategy brings agents
c1=M point, stable ecient result (for mechanisms).
r

r

r

214

fiMechanisms Automated Negotiation

8.4.2 Compromise, Enough

Consider situation, portrayed Figure 35, w2 less ,
rational agent A2 compromise declare worth greater w2. MinSucient Strategy brings agents c1=w2 point, con ict.
r


W1
C1

conflict
A1 decides
Negotiation

Mr

A2 decides
C2 W2 Mr



Figure 35: Compromise, Enough
picture identical Strict Tolerant mechanisms. agents
use Min-Sucient Strategy, resulting point (c1=w2) ecient, even though
stable.6 However, enhanced mechanism con ict-resolution techniques,
allowed agents negotiate multi-plan deals Section 5.5 (or even semicooperative deals Section 5.3), conjecture result c1 =w2 would
stable ecient. enhancement, however, beyond scope work described
paper.
8.4.3 Reason Compromise

situation shown Figure 36, non-compromising agent A1 cannot achieve
goal alone. Min-Sucient Strategy declare something less c1 (either
w1 ), result agent A2 option decide
do|and reasonable decision A2 achieve goal alone (there
reason compromise).
result ecient stable, Strict Tolerant mechanisms.
r

8.5 Symmetric Compromise Situation
section continue analysis situations agents,
compromise situation. agents stand-alone costs
order achieve goals.
6. Con ict ecient result one agent achieves goal, rather agents
nothing, would ecient.

215

fiZlotkin & Rosenschein



Equilibrium Point

C1
W1

conflict
A1 decides
Mr
Negotiation
A2 decides
C2

Mr

W2



Figure 36: Reason Compromise
section, propose another strategy agents could use, namely
Min-Concession Strategy:
Min-Concession Strategy min(w ; (c + , (c21 + c2 ) )):




situation, agent choosing propose (as true worth)
stand-alone cost, ensure agreement reached. However, would
propose minimal sucient concession, enough enable agreement. MinConcession Strategy agents make concession. overall strategy
analyzing (and covers cases section) use Min-Concession Strategy
symmetric compromise situations, otherwise use Min-Sucient Strategy (as
presented above). Agents know kind situation (and thus strategy
use) stand-alone costs common knowledge.
8.5.1 Agents Compromise Equally

agents situation compromise equally (as shown Figure 37),
use Min-Concession Strategy, end point (c1 +)=(c2 +)
(where = (T , c1 , c2)=2). point ecient stable, Strict
Tolerant mechanisms.
8.5.2 Non-Symmetric Compromise, Goals Achieved

agents symmetric compromise situation, one one agent needs
compromise (as Figure 38), use Min-Concession Strategy
results point (c1 +)=w2. point con ict, unfortunately neither stable
ecient.
result stable A1 could make greater compromise benefit
it. result ecient even one agent could achieve goal,
would superior con ict outcome. dicult imagine strategies
would lead agents ecient solutions (e.g., declare , c agent i, Tidy
Agent would Section 6), would stable, either. hand,
j

216

fiMechanisms Automated Negotiation



Equilibrium Point

W1

conflict
C1+

A1 decides

C1
Negotiation

Mr

A2 decides
Mr

C2 C2+

W2

Figure 37: Agents Compromise Equally



W1

conflict
C1+
C1

A1 decides

Mr

Negotiation
A2 decides
Mr

C2 W2 C2+



Figure 38: Non-Symmetric Compromise, Goals Achieved

217

fiZlotkin & Rosenschein

negotiation mechanism enhanced con ict-resolution techniques (such multiplan deals semi-cooperative deals), conjecture Min-Concession Strategy
stable ecient. enhancement, however, beyond scope
work described paper.
8.5.3 One Agent Cannot Compromise

Consider situation one agent cannot compromise (because could even
achieve goal alone), shown Figure 39. case, agents use MinConcession Strategy, result (c1 + )=w2. Agent 1 choose achieve
goal alone (and compromise). outcome stable ecient.

Equilibrium Point
W1

conflict
C1+
C1

A1 decides

Mr

Negotiation
A2 decides
Mr

W2 C2 C2+



Figure 39: One Agent Cannot Compromise

8.6 Summary Strict Tolerant Mechanisms

results analysis summarized Figure 40. tradeoff
eciency stability apparent symmetric cooperative case, neither
agent able achieve goal alone. strict mechanism, con ict caused simply
agent declare worth higher stand-alone cost, thus
bring immediate con ict. tolerant mechanism gives agents second chance
reach agreement, unstable (as described above).
mechanism incentive compatible. agents incentive
declare true worths; rather, use Min-Sucient Strategy decide
optimal declaration is.

9. Related Work Game Theory DAI

section review research game theory distributed artificial intelligence
related work.

9.1 Related Work Game Theory

mentioned beginning paper, research relies heavily existing game
theory tools use design evaluate protocols automated agents. Here,
218

fiMechanisms Automated Negotiation

Strict
Efficient

Stable

Tolerant
Efficient

Stable

Symmetric Cooperation
boals achievable alone
One goal achievable alone
goals arent achievable alone

Non-Symmetric Cooperation/Compromise
Compromise sufficient
Compromise insufficient
reason compromise

Symmetric Compromise
Agents compromise equally
Agents cant compromise equally
One agent cant compromise

Figure 40: Summary Strict Tolerant Mechanisms
review game theory work Bargaining Theory, Mechanism Design Implementation
Theory, Correlated Equilibria.
9.1.1 Bargaining Theory

Classic game theory (Nash, 1950; Zeuthen, 1930; Harsanyi, 1956; Roth, 1979; Luce & Raiffa,
1957) talks players reaching \deals," defined vectors utilities (one
player). bargaining game end possible outcome (i.e., \deal").
player full preference order set possible outcomes; preference order
expressed utility function. deal, utility vector
list utilities deal every participant. special utility vector called
\con ict" (or sometimes \status quo point") utility player assigns
con ict (that is, lack final agreement). Classic game theory deals following
question: given set utility vectors, utility vector players
agree (under particular assumptions)? words, classic bargaining theory
focused prediction outcomes, certain assumptions players
outcomes themselves.
Nash (Nash, 1950, 1953) showed rational behavior assumptions (i.e.,
individual rational pareto optimal behavior), symmetry assumptions, players
219

fiZlotkin & Rosenschein

reach agreement deal maximizes product players' utility (see Section 4.2 complete discussion).
alternative approach negotiation, looks upon dynamic, iterative process, discussed work Rubinstein Osborne (Rubinstein, 1982, 1985; Osborne
& Rubinstein, 1990).
Game theory work negotiation assumes negotiation game welldefined. assumes set possible deals players evaluating using
certain utility functions. Therefore, deals players' utility functions induce set
utility vectors forms basis negotiation game.
contrast analysis given, well-defined negotiation encounter, exploring design space negotiation games. Given multiagent encounter (involving,
example, task redistribution), design assortment negotiation games, formulating
various sets possible deals various kinds utility functions agents may have.
given negotiation game, use game theory approaches analyze
evaluate negotiation mechanisms propose.
Game theorists usually concerned games played,
descriptive normative point view. essentially constructive point view;
since game theory tells us, given game, played, endeavor design
games good properties played game theory predicts.
9.1.2 Equilibrium

Game solutions game theory consist strategies equilibrium; somehow social
behavior reaches equilibrium, agent incentive diverge equilibrium
behavior. equilibrium considered solution game. may one
(or no) strategies equilibrium, different notions equilibrium
game theory literature.
Three levels equilibrium commonly used game theory Nash equilibrium,
perfect equilibrium, dominant equilibrium (Binmore, 1990; Rasmusen, 1989). level
equilibrium enumerated stronger previous one. Two strategies S;
Nash equilibrium if, assuming one agent using , agent cannot better
using strategy , vice versa. Perfect equilibrium means
game multiple steps, one player using , exists state game
player better sticking strategy . exist
situations strategies might Nash equilibrium, perfect equilibrium;
case, although strategy best start game, game unfolds
would better diverge . Dominant strategy equilibrium means matter
strategy opponent chooses, cannot better play strategy ; strategies
dominant strategy equilibrium dominant strategy one
player, dominant strategy other.
work, generally use Nash equilibrium (the weakest equilibrium concept)
requirement solution; provides us widest range interaction solutions.
times, solution inherently perfect equilibrium, introduced
additional rules interaction, compel agents follow particular Nash equilibrium
220

fiMechanisms Automated Negotiation

strategies game progresses (such introducing penalty mechanism breaking
public commitment).
provides interesting example power wield designers game.
First, would normally require perfect equilibria multiagent encounters,
adopt Nash equilibria sucient needs, impose rules keep agents
deviating Nash equilibrium strategies. Second, strong requirement
dominant equilibrium, might desirable two arbitrary agents play given
game, needed recommended strategies commonly known|Nash equilibrium sucient.
9.1.3 Mechanism Design Implementation Theory

groups game theorists consider problem design games
certain attributes. area mechanism design closest
concerns, design protocols automated agents.
Mechanism design known game theory literature implementation
problem. implementation question (Binmore, 1992; Fudenberg & Tirole, 1992) asks
whether mechanism (also called game form ) distinguishable equilibrium
point (dominant strategy, perfect, merely Nash) social profile (i.e.,
group behavior) associated, players follow equilibrium strategies,
desired outcome.
words, assumed group agents, utility
function preferences possible social outcomes. social welfare function
rates possible social outcomes (e.g., socially ecient agreement may
rated higher non-ecient one) (Arrow, 1963). question then, one design
game unique solution (equilibrium strategies),
individual agent behaves according equilibrium strategy, social behavior
maximize social welfare function. game designed, said
game implements social welfare function.
example social welfare function, consider minimization pollution.
everyone may interested lowering pollution levels, everyone interested others
bearing associated costs. mechanism implement social welfare function might
include, example, taxes polluting industries tax credits given purchase
electric cars. precisely kind mechanism would cause agents, following
equilibrium strategy, minimize pollution.
Given negotiation game designed (i.e., set deals utility functions),
design actual negotiation mechanism. One important attributes
negotiation mechanism eciency, i.e., maximization total group's utility.
social welfare function trying implement. assume
agents incomplete information one another's utility function, basically
(negotiation) mechanism design problem.
However, unlike classic mechanism design game theory, satisfied (negotiation) mechanism Nash equilibrium point implements eciency.
need uniqueness, need stronger notion equilibrium (i.e., dominant equilibrium). negotiation mechanism design intended suggestion community
221

fiZlotkin & Rosenschein

agents' designers, along negotiation strategy. negotiation mechanism
strategy part suggested standard. make standard self-enforcing
sucient strategy part standard Nash equilibrium.
9.1.4 Correlated Equilibrium

Players sometime communicate prior actually playing game. communicating,
players coordinate strategies even sign binding contracts strategies
use. Contracts various types. agent commit
playing pure strategy agent commits playing another pure strategy. Agents
commit contract ip coin play strategy
according coin.
contract thus seen agreement players correlate
strategies. correlated strategy general case probability distribution
possible joint activities (i.e., strategy combinations) players. order players
play according correlated strategy, mediator conduct
lottery, choose joint activity according agreed probabilities, suggest
strategy players. cases mediator assumed release player
information player's action (strategy) chosen joint action,
player's action.
Contracts players binding; however, cannot assume contracts
binding cases. Even contracts binding, selfenforcing. contract self-enforcing player signs contract cannot
better following contract, assumption agents following
contract. mediator's communications observable players,
self-enforcing non-binding contracts randomize among Nash
equilibria original game ((Myerson, 1991), pp. 251).
Self-enforcing contracts correlated strategy called correlated equilibria. Aumann
introduced term correlated equilibrium (Aumann, 1974); defined correlated equilibrium given game Nash equilibrium extension game,
players receive private signals original game actually played. Aumann
showed (Aumann, 1987) correlated equilibrium defined terms Bayesian
rationality. Forges extended approach games incomplete information (Forges,
1993).
Myerson showed correlated equilibrium specific case general concept equilibrium, called communication equilibrium, games incomplete
information (Myerson, 1982, 1991).
deal types defined involve coin ipping. is,
course, directly related notion correlated strategies. correlated equilibrium theory, assume agents able agree deals (i.e., contracts)
involve jointly observed random process (e.g., coin toss). However, unlike correlated
equilibrium theory, assume contracts binding. Therefore, assume
agents follow contract (whatever result coin ip) even
longer rational agent so. Relaxation binding agreement assumption,
222

fiMechanisms Automated Negotiation

designing negotiation mechanisms based self-enforcing correlated strategies,
part future research plans.

9.2 Related Work Distributed Artificial Intelligence

several streams research Distributed Artificial Intelligence (DAI)
approached problem multiagent coordination different ways.
brie review work, categorizing general areas multiagent planning,
negotiation, social laws, economic approaches.
9.2.1 Multiagent Planning

One focus DAI research \planning multiple agents," considers
issues inherent centrally directed multiagent execution. Smith's Contract Net (Smith,
1978, 1980) falls category, DAI work (Fox, Allen, & Strohm, 1982;
Rosenschein, 1982; Pednault, 1987; Katz & Rosenschein, 1993). second focus research
\distributed planning," multiple agents participate coordinating
deciding upon actions (Konolige & Nilsson, 1980; Corkill, 1982; Rosenschein & Genesereth, 1985; Rosenschein, 1986; Durfee, Lesser, & Corkill, 1987; Zlotkin & Rosenschein,
1991b; Ephrati & Rosenschein, 1991; Pollack, 1992; Pope, Conry, & Mayer, 1992).
question whether group activity fashioned centrally distributed
manner one axis comparison. Another important issue distinguishes
various DAI research efforts whether goals need adjusted, is,
whether may fundamental con icts among different agents' goals. Thus,
example, Georgeff's early work multiagent planning assumed basic
con ict among agent goals, coordination necessary guarantee
success (Georgeff, 1983, 1984; Stuart, 1985). Similarly, planning context Lesser,
Corkill, Durfee, Decker's research (Decker & Lesser, 1992, 1993b, 1993a) often involves
coordination activities (e.g., sensor network computations) among agents
inherent con ict one another (though surface con ict may exist). \Planning"
means avoidance redundant distracting activity, ecient exploration search
space, etc.
Another important issue relationship agents one another, e.g.,
degree willing compromise goals one another (assuming
compromise necessary). Benevolent Agents that, design, willing
accommodate one another (Rosenschein & Genesereth, 1985); built
cooperative, share information, coordinate pursuit (at least implicit)
notion global utility. contrast, Multiagent System agents cooperate
best interests (Genesereth, Ginsberg, & Rosenschein, 1986). Still
another potential relationship among agents modified master-slave relationship, called
\supervisor-supervised" relationship, non-absolute control exerted one agent
another (Ephrati & Rosenschein, 1992a, 1992b).
synthesis, synchronization, adjustment process multiple agent plans thus constitute (varied) foci DAI planning research. Synchronization con ict
avoidance (Georgeff, 1983, 1984; Stuart, 1985), distribution single-agent planner among
multiple agents (Corkill, 1979), use centralized multiagent planner (Rosenschein,
223

fiZlotkin & Rosenschein

1982), use consensus mechanisms aggregating subplans produced multiple agents (Ephrati & Rosenschein, 1993b), explored, well related
issues (Cohen & Perrault, 1979; Morgenstern, 1987; von Martial, 1992a, 1992b; Kreifelts
& von Martial, 1991; Kamel & Syed, 1989; Grosz & Sidner, 1990; Kinny, Ljungberg, Rao,
Sonenberg, Tidhar, & Werner, 1992; Ferber & Drogoul, 1992; Kosoresow, 1993).
paper, dealing classical problems planning research
(e.g., construction sequences actions accomplish goals). Instead, taken
given agents capable deriving joint plans domain, considered might choose among alternative joint plans satisfy potentially
con icting notions utility. help agents bridge con icts, introduced frameworks plan execution (such ipping coin decide two joint plans
carried out), actual base planning mechanism subject work.
9.2.2 Axiomatic Approaches Group Activity

exists large growing body work within artificial intelligence attempts
capture notions rational behavior logical axiomatization (Cohen & Levesque,
1990, 1991; Rao, Georgeff, & Sonenberg, 1991; Rao & Georgeff, 1991, 1993; Georgeff &
Lansky, 1987; Georgeff, 1987; Belegrinos & Georgeff, 1991; Grosz & Kraus, 1993; Konolige,
1982; Morgenstern, 1990, 1986; Kinny & Georgeff, 1991). approach usually centers
formalized model agent's beliefs, desires, intentions (the so-called \BDI
model") (Hughes & Cresswell, 1968; Konolige, 1986). purpose formal model
characterize precisely constitutes rational behavior, intent impose
rational behavior automated agent. formal axioms might used run-time
directly constrain agent's decision process, (more likely) could used
compile-time produce ecient executable module.
focus research, coming single-agent artificial intelligence
perspective, architecture single automated agent. example, Cohen
Levesque explored relationship choice, commitment, intention (Cohen
& Levesque, 1987, 1990)|an agent commit certain plans action,
remain loyal plans long appropriate (for example, agent discovers
plan infeasible, plan dropped).
Even looking multiagent systems, researchers examined member group designed|again, looking design individual agent
productive group member. example, certain work (Kinny et al., 1992)
axioms proposed cause agent, discovers fail fulfill
role joint plan, notify members group. Axiomatizations, however,
might need deal groups agents could joint commitment accomplishing goal (Cohen & Levesque, 1991), agent make interpersonal
commitments without use notions (Grosz & Kraus, 1993). Another use
BDI abstractions allow one agent reason agents, relativize one's
intentions terms beliefs agents' intentions beliefs.
Axiomatic approaches tend closely link definitions behavior internal agent
architecture. Thus, definition commitment explored Cohen Levesque intended constrain design agent, behave certain way.
224

fiMechanisms Automated Negotiation

work, hand, takes arms-length approach question constraining
agents' public behavior. rules encounter really specification domain
(not agent), agent designer free build agent internally however
sees fit. rules themselves, however, induce rational designers build agents
behave certain ways, independent agents' internal architectures.
9.2.3 Social Laws Multiple Agents

Various researchers Distributed Artificial Intelligence suggested would
worthwhile isolate \aspects cooperative behavior," general rules would cause
agents act ways conducive cooperation. hypothesis agents act
certain ways (e.g., share information, act predictable ways, defer globally constraining
choices), easier carry effective joint action (Steeb, Cammarata,
Hayes-Roth, & Wesson, 1980; Cammarata, McArthur, & Steeb, 1983; McArthur, Steeb, &
Cammarata, 1982).
Moses, Shoham, Tennenholtz (Tennenholtz & Moses, 1989; Moses & Tennenholtz,
1990; Shoham & Tennenholtz, 1992b, 1992a; Moses & Tennenholtz, 1993; Shoham & Tennenholtz, 1995), example, suggested applying society metaphor artificial
systems improve performance agents operating system. issues
dealt analyzing multiagent environment concern synchronization, coordination agents' activities, cooperative ways achieve tasks, safety
fairness constraints system guaranteed. propose coordinating agent
activity avoid con icts; system structured agents arrive
potential con ict situations.
Thus social laws seen method avoid necessity costly coordination
techniques, planning negotiation. agents following appropriate social laws,
need run-time coordination reduced. important, although
agent designers may willing invest large amount effort design time building
effective multiagent systems, often critical run-time overhead low
possible.
similarity use pre-compiled, highly structured social laws,
development pre-defined interaction protocols. However, social law approach
assumes designers laws full control agents; agents assumed follow social laws simply designed to,
individually benefit social laws. Obeying social laws may \stable";
assuming everyone else obeys laws, agent might better breaking them.
approach concerned social conventions stable, suitable
individually motivated agents.
9.2.4 Decision Theoretic Approaches

related work Artificial Intelligence addresses reasoning process single
agent decision-theoretic terms. certain work (Horvitz, 1988; Horvitz, Cooper, & Heckerma, 1989; Russell & Wefald, 1989), decision-theoretic approaches used optimize
value computation uncertain varying resource limitations. Etzioni considered
using decision-theoretic architecture, learning capabilities, control problem solving
225

fiZlotkin & Rosenschein

search (Etzioni, 1991). introductory treatment decision theory itself, see Raiffa's
classic text subject (Raiffa, 1968).
Classical decision theory research considers agent \playing nature,"
trying maximize utility uncertain circumstances. key assumption \nature's"
behavior independent decision made agent. course, assumption
hold multiagent encounter.
concept \rationality," usually expressed decision-theoretic terms,
used model agent activity multiagent encounters (Rosenschein & Genesereth, 1985;
Genesereth et al., 1986). Here, axioms defining different types rationality, along
assumptions rationality others, led agents particular choices action.
contrast work, research employs standard game theory notions equilibrium
rationality. discussions use rationality general reasoning found
Doyle's research (Doyle, 1985, 1992).
Another decision theoretic approach, taken Gmytrasiewicz Durfee,
used model multiagent interactions (Gmytrasiewicz, Durfee, & Wehe, 1991a, 1991b;
Gmytrasiewicz & Durfee, 1992, 1993). assumes predefined protocol structure
interaction (in marked contrast research protocol design). research uses
decision-theoretic method coordinating activities autonomous agents called
Recursive Modeling Method. agent models agents recursive manner,
allowing evaluation expected utility attached potential actions communication.
9.2.5 Economic Approaches

several attempts consider market mechanisms way eciently
allocating resources distributed system. Among AI work Smith's Contract
Net (Smith, 1978, 1980; Sandholm, 1993), Malone's Enterprise system (Malone et al., 1988),
Wellman's WALRAS system (Wellman, 1992).
Contract Net high-level communication protocol Distributed Problem
Solving system. enables distribution tasks among nodes operate
system. contract two nodes established tasks executed;
node net act either manager contractor. task
assigned node decomposed contractor. contract established
bidding scheme includes announcement task manager, bids
sent potential contractors.
Enterprise (Malone et al., 1988) system built using variation Contract Net protocol. Distributed Scheduling Protocol locates best available machine
perform task. protocol similar Contract Net, makes use
well-defined assignment criteria.
Another system (Wellman, 1992) takes economic approach solving distributed problem use price mechanism explored Wellman.
Wellman uses consumer/producer metaphor establish market pricing-based mechanism task redistribution ensures stability eciency. agents act
consumers producers. distinct good auction associated it, agents
get good submitting bids auction good. system developed
Wellman, WALRAS, computes market equilibrium price.
226

fiMechanisms Automated Negotiation

two main differences economic approaches work
mechanism design. First, underlying assumption economic approach
utility explicitly transferable (e.g., money used). work involve
need explicit utility transfer. Instead, exploit various methods implicit utility
transfer, example, sharing work joint plan, tossing coin, etc. course,
constrains available coordination mechanism, removes assumption (that is,
existence money) may suitable certain multiagent environments. Second,
economic models deal n agents market, work deals
two-agent encounters; however, work deals n-agent negotiation
coalition formation problem (Zlotkin & Rosenschein, 1994).
9.2.6 Negotiation

Negotiation subject central interest DAI, economics
political science (Raiffa, 1982). word used variety ways, though
general refers communication processes coordination (Smith, 1978; Lesser
& Corkill, 1981; Kuwabara & Lesser, 1989; Conry et al., 1988; Kreifelts & von Martial,
1991; Kraus, Ephrati, & Lehmann, 1991). negotiating procedures included
exchange Partial Global Plans (Durfee, 1988; Durfee & Lesser, 1989), communication
information intended alter agents' goals (Sycara, 1988, 1989), use
incremental suggestions leading joint plans action (Kraus & Wilkenfeld, 1991).
Interagent collaboration Distributed Problem Solving systems explored
ongoing research Lesser, Durfee, colleagues. Much work focused
implementation analysis data fusion experiments, systems distributed
sensors absorb interpret data, ultimately arriving group conclusion (Durfee &
Lesser, 1987; Decker & Lesser, 1993a; L^aasri, L^aasri, & Lesser, 1990). Agents exchange
partial solutions various levels detail construct global solutions; much work
examined effective strategies communication data hypotheses among agents,
particular kinds relationships among nodes aid effective group analysis.
example, different organizations, different methods focusing node activity,
help system whole far ecient.
two main distinctions work work Lesser
colleagues. First, underlying assumption bulk Lesser's work agents
designed implemented part unified system, work towards global goal.
agents, hand, motivated achieve individual goals. Second, unlike
formal approach mechanism design, Lesser's work historically heuristic
experimental, although recent work explored theoretical basis
system-level phenomena (Decker & Lesser, 1992, 1993a, 1993b).
Sycara examined model negotiation combines case-based reasoning
optimization multi-attribute utilities (Sycara, 1988, 1989). particular, assume
agents' goals fixed negotiation, Sycara specifically interested
agents uence one another change goals process negotiation
(information transfer, etc.).
Kraus colleagues explored negotiation negotiation time
issue (Kraus & Wilkenfeld, 1991; Kraus, 1993; Kraus, Wilkenfeld, & Zlotkin, 1995). Agents
227

fiZlotkin & Rosenschein

may lose value negotiation drags long, different agents asymmetric
regard cost negotiation time. Agents' attitudes towards negotiation time
directly uences kinds agreements reach. Interestingly, however,
agreements reached without delay. avoidable ineciency delaying
agreement. work, contrast, assumes agent utility remains constant throughout
negotiation process, negotiation time uence agreement.
Kraus' work assumes explicit utility transfer (while work, mentioned above,
not).
Gasser explored social aspects agent knowledge action multiagent
systems (\communities programs") (Gasser, 1991, 1993). Social mechanisms dynamically emerge; communities programs generate, modify, codify
local languages interaction. Gasser's approach may effective agents
interacting unstructured domains, domains structure continuously
changing. research present, hand, exploits pre-designed social layer
multiagent systems.
work focuses organizational aspects societies agents exists (Fox,
1981; Malone, 1986).
Ephrati Rosenschein used Clarke Tax voting procedure consensus mechanism, essence avoid need classical negotiation (Ephrati & Rosenschein, 1991,
1992c, 1993a). mechanism assumes ability transfer utility explicitly. Clarke
Tax technique assumes (and requires) agents able transfer utility
system (taxes paid agents). utility transferred system
actually wasted, reduces eciency overall mechanism. This, however,
price needs paid ensure stability. Again, work present paper
assume explicit transfer utility. Also, negotiation mechanism ensures
stability without ineciency transferring utility system. However, voting
mechanisms Clarke Tax deal n-agent agreement (not two-agent agreement research), demonstrates kind dominant equilibrium (in contrast
weaker notion Nash equilibrium).

10. Conclusions
paper explored State Oriented Domains (SODs). State Oriented Domains
current description world modeled state, operators cause world
move one state another. goal agent transform world
one collection target states. SODs, real con ict possible agents,
general, agents may find four possible types interactions, symmetric
cooperative, symmetric compromise, non-symmetric cooperative/compromise, con ict.
Agents negotiate different deal types kinds interactions;
particular, introduced semi-cooperative deal, multi-plan deals, use con ict situations. Unified Negotiation Protocols, product maximizing mechanisms based
either semi-cooperative deals multi-plan deals, provide suitable basis con ict
resolution, well reaching cooperative agreements.
Strategic manipulation possible SODs. State Oriented Domain, agent might
misrepresent goals, worth function, gain advantage negotiation.
228

fiMechanisms Automated Negotiation

general approach deceitful agent would pretend worth lower
actually is. done directly, declaring low worth (in certain mechanisms),
declaring cheaper goal (in case stand-alone cost taken implicit
worth baseline). able construct incentive compatible mechanisms used
worths unknown, unable SODs goals unknown.

Acknowledgements
paper submitted Gilad Zlotkin aliated Center Coordination Science, Sloan School Management, MIT. research began Zlotkin
aliated Institute Computer Science Hebrew University Jerusalem,
supported Leibniz Center Research Computer Science. material
paper appeared preliminary form AAAI, IJCAI, ICICIS conference
papers (Zlotkin & Rosenschein, 1990, 1991b; Rosenschein, 1993; Zlotkin & Rosenschein,
1993c) journal article (Zlotkin & Rosenschein, 1991a) (earlier version material
UNP protocol). research partially supported Israeli Ministry
Science Technology (Grant 032-8284) Israel Science Foundation (Grant
032-7517). would thank anonymous reviewers contributed improvement paper.

References

Allen, J. F., Kautz, H. A., Pelavin, R. N., & Tenenberg, J. D. (1991). Reasoning
Plans. Morgan Kaufmann Publishers, Inc., San Mateo, California.
Arrow, K. J. (1963). Social Choice Individual Values. John Wiley, New York.
Aumann, R. (1987). Correlated equilibrium expression bayesian rationality. Econometrica, 55, 1{18.
Aumann, R. J. (1974). Subjectivity correlation randomized strategies. Journal
Mathematical Economics, 1, 67{96.
Belegrinos, P., & Georgeff, M. P. (1991). model events processes. Proceedings
Twelfth International Joint Conference Artificial Intelligence, pp. 506{511
Sydney, Australia.
Binmore, K. (1990). Essays Foundations Game Theory. Basil Blackwell, Cambridge, Massachusetts.
Binmore, K. (1992). Fun Games, Text Game Theory. D. C. Heath Company,
Lexington, Massachusetts.
Bok, S. (1978). Lying: Moral Choice Public Private Life. Vintage Books, New York.
Cammarata, S., McArthur, D., & Steeb, R. (1983). Strategies cooperation distributed
problem solving. Proceedings Eighth International Joint Conference Artificial Intelligence, pp. 767{770 Karlsruhe, West Germany.
229

fiZlotkin & Rosenschein

Cohen, P. R., & Levesque, H. J. (1987). Intention = choice + commitment. Proceedings Sixth National Conference Artificial Intelligence, pp. 410{415 Seattle,
Washington.
Cohen, P. R., & Levesque, H. J. (1990). Intention choice commitment. Artificial
Intelligence, 42 (2{3), 213{261.
Cohen, P. R., & Levesque, H. J. (1991). Teamwork. Technote 503, SRI International, Menlo
Park, California.
Cohen, P. R., & Perrault, C. R. (1979). Elements plan-based theory speech acts.
Cognitive Science, 3, 177{212.
Conry, S. E., Meyer, R. A., & Lesser, V. R. (1988). Multistage negotiation distributed
planning. Bond, A., & Gasser, L. (Eds.), Readings Distributed Artificial Intelligence, pp. 367{384. Morgan Kaufmann Publishers, Inc., San Mateo.
Corkill, D. D. (1979). Hierarchical planning distributed environment. Proceedings
Sixth International Joint Conference Artificial Intelligence, pp. 168{175 Tokyo.
Corkill, D. D. (1982). Framework Organizational Self-Design Distributed Problem
Solving Networks. Ph.D. thesis, University Massachusetts, Amherst, MA.
Decker, K. S., & Lesser, V. R. (1992). Generalizing partial global planning algorithm.
International Journal Intelligent Cooperative Information Systems, 1(2), 319{346.
Decker, K. S., & Lesser, V. R. (1993a). approach analyzing need meta-level
communication. Proceedings Thirteenth International Joint Conference
Artificial Intelligence, pp. 360{366 Chambery, France.
Decker, K. S., & Lesser, V. R. (1993b). one-shot dynamic coordination algorithm
distributed sensor networks. Proceedings Eleventh National Conference
Artificial Intelligence, pp. 210{216 Washington, DC.
Doyle, J. (1985). Reasoned assumptions pareto optimality. Proceedings
Ninth International Joint Conference Artificial Intelligence, pp. 87{90 Los Angeles,
California.
Doyle, J. (1992). Rationality roles reasoning. Computational Intelligence, 8 (2),
376{409.
Durfee, E. H. (1988). Coordination Distributed Problem Solvers. Kluwer Academic
Publishers, Boston.
Durfee, E. H., & Lesser, V. R. (1987). Using partial global plans coordinate distributed
problem solvers. Proceedings Tenth International Joint Conference Artificial Intelligence, pp. 875{883 Milan.
Durfee, E. H., & Lesser, V. R. (1989). Negotiating task decomposition allocation using
partial global planning. Gasser, L., & Huhns, M. N. (Eds.), Distributed Artificial
Intelligence, Vol. II, pp. 229{243. Morgan Kaufmann, San Mateo, California.
230

fiMechanisms Automated Negotiation

Durfee, E. H., Lesser, V. R., & Corkill, D. D. (1987). Cooperation communication
distributed problem solving network. Huhns, M. N. (Ed.), Distributed Artificial Intelligence, chap. 2, pp. 29{58. Morgan Kaufmann Publishers, Inc., Los Altos,
California.
Ephrati, E., & Rosenschein, J. S. (1991). Clarke Tax consensus mechanism among
automated agents. Proceedings Ninth National Conference Artificial
Intelligence, pp. 173{178 Anaheim, California.
Ephrati, E., & Rosenschein, J. S. (1992a). Constrained intelligent action: Planning
uence master agent. Proceedings Tenth National Conference
Artificial Intelligence, pp. 263{268 San Jose, California.
Ephrati, E., & Rosenschein, J. S. (1992b). Planning please: Planning constrained
master agent. Proceedings Eleventh International Workshop Distributed
Artificial Intelligence, pp. 77{94 Glen Arbor, Michigan.
Ephrati, E., & Rosenschein, J. S. (1992c). Reaching agreement partial revelation preferences. Proceedings Tenth European Conference Artificial
Intelligence, pp. 229{233 Vienna, Austria.
Ephrati, E., & Rosenschein, J. S. (1993a). Distributed consensus mechanisms selfinterested heterogeneous agents. First International Conference Intelligent
Cooperative Information Systems, pp. 71{79 Rotterdam.
Ephrati, E., & Rosenschein, J. S. (1993b). Multi-agent planning dynamic search
social consensus. Proceedings Thirteenth International Joint Conference
Artificial Intelligence, pp. 423{429 Chambery, France.
Etzioni, O. (1991). Embedding decision-analytic control learning architecture. Artificial
Intelligence, 49, 129{159.
Ferber, J., & Drogoul, A. (1992). Using reactive multi-agent systems simulation problem solving. Avouris, N. M., & Gasser, L. (Eds.), Distributed Artificial Intelligence:
Theory Praxis, pp. 53{80. Kluwer Academic Press.
Forges, F. (1993). Five legitimate definitions correlated equilibrium games incomplete information. Theory Decision, 35, 277{310.
Fox, M. S. (1981). organizational view distributed systems. IEEE Transactions
Systems, Man, Cybernetics, SMC-11 (1), 70{80.
Fox, M. S., Allen, B., & Strohm, G. (1982). Job-shop scheduling: investigation
constraint-directed reasoning. Proceedings National Conference Artificial
Intelligence, pp. 155{158 Pittsburgh, Pennsylvania.
Fudenberg, D., & Tirole, J. (1992). Game Theory. MIT Press, Cambridge, Massachusetts.
231

fiZlotkin & Rosenschein

Gasser, L. (1991). Social conceptions knowledge action: DAI foundations open
systems semantics. Artificial Intelligence, 47 (1{3), 107{138.
Gasser, L. (1993). Social knowledge social action. Proceedings Thirteenth International Joint Conference Artificial Intelligence, pp. 751{757 Chambery, France.
Genesereth, M. R., Ginsberg, M. L., & Rosenschein, J. S. (1986). Cooperation without
communication. Proceedings National Conference Artificial Intelligence,
pp. 51{57 Philadelphia, Pennsylvania.
Georgeff, M. P. (1983). Communication interaction multi-agent planning. Proceedings National Conference Artificial Intelligence, pp. 125{129 Washington,
D.C.
Georgeff, M. P. (1984). theory action multi-agent planning. Proceedings
National Conference Artificial Intelligence, pp. 121{125 Austin, Texas.
Georgeff, M. P. (1987). Actions, processes, causality. Georgeff, M. P., & Lansky, A. L.
(Eds.), Reasoning Actions & Plans, pp. 99{122. Morgan Kaufmann Publishers,
Inc., Los Altos, California.
Georgeff, M. P., & Lansky, A. L. (1987). Reactive reasoning planning. Proceedings Sixth National Conference Artificial Intelligence, pp. 677{682 Seatle,
Washington.
Gmytrasiewicz, P. J., & Durfee, E. H. (1992). logic knowledge belief recursive
modeling: Preliminary report. Proceedings Tenth National Conference
Artificial Intelligence, pp. 628{634 San Jose, California.
Gmytrasiewicz, P. J., & Durfee, E. H. (1993). Elements utilitarian theory knowledge action. Proceedings Thirteenth International Joint Conference
Artificial Intelligence, pp. 396{402 Chambery, France.
Gmytrasiewicz, P. J., Durfee, E. H., & Wehe, D. K. (1991a). decision theoretic approach
coordinating multiagent interaction. Proceedings Twelfth International
Joint Conference Artificial Intelligence, pp. 62{68 Sydney, Australia.
Gmytrasiewicz, P. J., Durfee, E. H., & Wehe, D. K. (1991b). utility communication
coordinating intelligent agents. Proceedings Ninth National Conference
Artificial Intelligence, pp. 166{172.
Grosz, B. J., & Kraus, S. (1993). Collaborative plans group activities. Proceedings
Thirteenth International Joint Conference Artificial Intelligence, pp. 367{373
Chambery, France.
Grosz, B. J., & Sidner, C. (1990). Plans discourse. Cohen, P. R., Morgan, J., &
Pollack, M. E. (Eds.), Intentions Communication. MIT Press.
Gupta, N., & Nau, D. S. (1992). complexity blocks-world planning. Artificial
Intelligence, 56 (2{3), 223{254.
232

fiMechanisms Automated Negotiation

Harsanyi, J. C. (1956). Approaches bargaining problem theory
games: critical discussion Zeuthen's, Hick's Nash theories. Econometrica,
pp. 144{157.
Horvitz, E., Cooper, G., & Heckerma, D. (1989). ection action scare resources:
Theoretical principles empirical study. Proceedings Eleventh International Joint Conference Artificial Intelligence, pp. 1121{1127 Detroit, Michigan.
Horvitz, E. J. (1988). Reasoning varying uncertain resource constraints.
Proceedings Seventh National Conference Artificial Intelligence, pp. 111{
116.
Hughes, G. E., & Cresswell, J. M. (1968). Introduction Modal Logic. Methuen
Co. Ltd.
Kamel, M., & Syed, A. (1989). object-oriented multiple agent planning system.
Gasser, L., & Huhns, M. N. (Eds.), Distributed Artificial Intelligence, Volume II, pp.
259{290. Pitman Publishing/Morgan Kaufmann Publishers, San Mateo, CA.
Katz, M. J., & Rosenschein, J. S. (1993). Verifying plans multiple agents. Journal
Experimental Theoretical Artificial Intelligence, 5, 39{56.
Kinny, D., Ljungberg, M., Rao, A., Sonenberg, E., Tidhar, G., & Werner, E. (1992). Planned
team activity. Pre-Proceedings Fourth European Workshop Modeling
Autonomous Agents Multi-Agent World Rome, Italy.
Kinny, D. N., & Georgeff, M. P. (1991). Commitment effectiveness situated agents.
Proceedings Twelfth International Joint Conference Artificial Intelligence,
pp. 82{88 Sydney, Australia.
Konolige, K. (1982). first-order formalization knowledge action multi-agent
planning system. Machine Intelligence, 10.
Konolige, K. (1986). Deduction Model Belief. Pitman Publishers/Morgan Kaufmann,
San Matheo, CA.
Konolige, K., & Nilsson, N. J. (1980). Multiple-agent planning systems. Proceedings
First Annual National Conference Artificial Intelligence, pp. 138{142 Stanford,
California.
Kosoresow, A. P. (1993). fast first-cut protocol agent coordination. Proceedings
Eleventh National Conference Artificial Intelligence, pp. 237{242 Washington,
DC.
Kraus, S. (1993). Agents contracting tasks non-collaborative environments. Proceedings
Eleventh National Conference Artificial Intelligence, pp. 243{248.
Kraus, S., Ephrati, E., & Lehmann, D. (1991). Negotiation non-cooperative environment. Journal Experimental Theoretical Artificial Intelligence, 3 (4), 255{282.
233

fiZlotkin & Rosenschein

Kraus, S., & Wilkenfeld, J. (1990). function time cooperative negotiations: Extended abstract. Proceedings Tenth Workshop Distributed Artificial Intelligence Bandera, Texas.
Kraus, S., & Wilkenfeld, J. (1991). Negotiations time multi-agent environment:
Preliminary report. Proceedings Twelfth International Joint Conference
Artificial Intelligence, pp. 56{61 Sydney.
Kraus, S., Wilkenfeld, J., & Zlotkin, G. (1995). Multiagent negotiation time constraints. Artificial Intelligence, 75 (2), 297{345.
Kreifelts, T., & von Martial, F. (1991). negotiation framework autonomous agents.
Demazeau, Y., & Muller, J.-P. (Eds.), Decentralized A. I. 2, Proceedings Second
European Workshop Modelling Autonomous Agents Multi-Agent World, pp.
71{88. North-Holland, Amsterdam.
Kuwabara, K., & Lesser, V. R. (1989). Extended protocol multistage negotiation.
Proceedings Ninth Workshop Distributed Artificial Intelligence, pp. 129{161
Rosario, Washington.
L^aasri, B., L^aasri, H., & Lesser, V. R. (1990). Negotiation role cooperative distributed problem problem solving. Proceedings Tenth International Workshop
Distributed Artificial Intelligence Bandera, Texas. Chapter 8.
Lesser, V. R., & Corkill, D. D. (1981). Functionally-accurate, cooperative distributed systems. IEEE Transactions Systems, Man, Cybernetics, SMC-11 (1), 81{96.
Levesque, H. J., & Cohen, P. R. (1990). acting together. Proceedings Eighth
National Conference Artificial Intelligence, pp. 94{99 Boston, Massachusetts.
Luce, R. D., & Raiffa, H. (1957). Games Decisions. John Wiley & Sons, Inc., New
York.
Malone, T. W. (1986). Organizing information processing systems: Parallels human
organizations computer systems. Zacharai, W., Robertson, S., & Black, J.
(Eds.), Cognition, Computation, Cooperation. Ablex Publishing Corp., Norwood,
NJ.
Malone, T. W., Fikes, R. E., Grant, K. R., & Howard, M. T. (1988). Enterprise:
market-like task scheduler distributed computing environments. Huberman,
B. A. (Ed.), Ecology Computation, pp. 177{205. North-Holland Publishing
Company, Amsterdam.
McArthur, D., Steeb, R., & Cammarata, S. (1982). framework distributed problem
solving. Proceedings National Conference Artificial Intelligence, pp.
181{184 Pittsburgh, Pennsylvania.
Morgenstern, L. (1986). first order theory planning, knowledge, action. Halpern,
J. Y. (Ed.), Theoretical Aspects Reasoning Knowledge, pp. 99{114. Morgan
Kaufmann, Los Altos.
234

fiMechanisms Automated Negotiation

Morgenstern, L. (1987). Knowledge preconditions actions plans. Proceedings
Tenth International Joint Conference Artificial Intelligence, pp. 867{874
Milan, Italy.
Morgenstern, L. (1990). formal theory multiple agent nonmonotonic reasoning.
Proceedings Eighth National Conference Artificial Intelligence, pp. 538{544
Boston, Massachusetts.
Moses, Y., & Tennenholtz, M. (1990). Artificial social systems part 1: Basic principles.
Tech. rep. CS90-12, Weizmann Institute.
Moses, Y., & Tennenholtz, M. (1993). Off-line reasoning on-line eciency. Proceedings
Thirteenth International Joint Conference Artificial Intelligence, pp. 490{
495 Chambery, France.
Myerson, R. (1982). Optimal coordination mechanisms generalized principal-agent problems. Journal Mathematical Economics, 10, 67{81.
Myerson, R. (1991). Game Theory: Analysis Con ict. Harvard University Press, Cambridge, Massachusetts.
Nash, J. F. (1950). bargaining problem. Econometrica, 28, 155{162.
Nash, J. F. (1953). Two-person cooperative games. Econometrica, 21, 128{140.
Osborne, M. J., & Rubinstein, A. (1990). Bargaining Markets. Academic Press Inc.,
San Diego, California.
Pednault, E. P. D. (1987). Formulating multiagent dynamic-world problems classical
planning framework. Georgeff, M. P., & Lansky, A. L. (Eds.), Reasoning Actions Plans: Proceedings 1986 Workshop, pp. 47{82 San Mateo, California.
Morgan Kaufmann.
Pollack, M. E. (1992). uses plans. Artificial Intelligence, 57 (1).
Pope, R. P., Conry, S. E., & Mayer, R. A. (1992). Distributing planning process
dynamic environment. Proceedings Eleventh International Workshop
Distributed Artificial Intelligence, pp. 317{331 Glen Arbor, Michigan.
Raiffa, H. (1968). Decision Analysis, Introductory Lectures Choices Uncertainty.
Addison-Wesley Publishing Company, Reading, Massachusetts.
Raiffa, H. (1982). Art Science Negotiation. Belknap Press Harvard
University Press, Cambridge, Massachusetts.
Rao, A. S., & Georgeff, M. P. (1991). Asymmetry thesis side-effect problems lineartime branching-time intention logics. Proceedings Twelfth International
Joint Conference Artificial Intelligence, pp. 498{504 Sydney, Australia.
235

fiZlotkin & Rosenschein

Rao, A. S., & Georgeff, M. P. (1993). model-theoretic approach verification
situated reasoning systems. Proceedings Thirteenth International Joint
Conference Artificial Intelligence, pp. 318{324 Chambery, France.
Rao, A. S., Georgeff, M. P., & Sonenberg, E. (1991). Social plans: preliminary report.
Pre-Proceedings Third European Workshop Modeling Autonomous Agents
Multi-Agent Worlds Germany.
Rasmusen, E. (1989). Games Information, Introduction Game Theory. Basil
Blackwell, Cambridge, Massachusetts.
Rosenschein, J. S. (1982). Synchronization multi-agent plans. Proceedings
National Conference Artificial Intelligence, pp. 115{119 Pittsburgh, Pennsylvania.
Rosenschein, J. S. (1986). Rational Interaction: Cooperation Among Intelligent Agents.
Ph.D. thesis, Stanford University.
Rosenschein, J. S. (1993). Consenting agents: Negotiation mechanisms multi-agent
systems. Proceedings Thirteenth International Joint Conference Artificial
Intelligence, pp. 792{799 Chambery, France.
Rosenschein, J. S., & Genesereth, M. R. (1985). Deals among rational agents. Proceedings
Ninth International Joint Conference Artificial Intelligence, pp. 91{99 Los
Angeles, California.
Roth, A. E. (1979). Axiomatic Models Bargaining. Springer-Verlag, Berlin.
Rubinstein, A. (1982). Perfect equilibrium bargaining model. Econometrica, 50 (1),
97{109.
Rubinstein, A. (1985). Choice conjectures bargaining game incomplete information. Roth, A. E. (Ed.), Game-theoretic models bargaining, pp. 99{114.
Cambridge University Press, Cambridge, New York.
Russell, S., & Wefald, E. (1989). Principles metareasoning. Proceedings First
International Conference Principles Knowledge Representation Reasoning,
pp. 400{411. Morgan Kaufmann.
Sandholm, T. (1993). implementation contract net protocol based marginal
calculations. Proceedings Eleventh National Conference Artificial Intelligence, pp. 256{262.
Schelling, T. C. (1963). Strategy Con ict. Oxford University Press, New York.
Schelling, T. C. (1984). Choice Consequence. Harvard University Press, Cambridge,
Massachusetts.
Shoham, Y., & Tennenholtz, M. (1992a). Emergent conventions multi-agent systems:
initial experimental results observations (preliminary report). Principles
knowledge representation reasoning: Proceedings Third International Conference Cambridge, Massachusetts.
236

fiMechanisms Automated Negotiation

Shoham, Y., & Tennenholtz, M. (1992b). synthesis useful social laws artificial
agent societies (preliminary report). Proceedings National Conference
Artificial Intelligence San Jose, California.
Shoham, Y., & Tennenholtz, M. (1995). social laws artificial agent societies: Off-line
design. Artificial Intelligence. appear.
Smith, R. G. (1978). Framework Problem Solving Distributed Processing Environment. Ph.D. thesis, Stanford University.
Smith, R. G. (1980). contract net protocol: High-level communication control
distributed problem solver. IEEE Transactions Computers, C-29 (12), 1104{1113.
Steeb, R., Cammarata, S., Hayes-Roth, F., & Wesson, R. (1980). Distributed intelligence
air eet control. Tech. rep. WD-839-ARPA, Rand Corporation.
Stuart, C. J. (1985). implementation multi-agent plan synchronizer. Proceedings
Ninth International Joint Conference Artificial Intelligence, pp. 1031{1035
Los Angeles, California.
Sycara, K. P. (1988). Resolving goal con icts via negotiation. Proceedings Seventh
National Conference Artificial Intelligence, pp. 245{250 St. Paul, Minnesota.
Sycara, K. P. (1989). Argumentation: Planning agents' plans. Proceedings
Eleventh International Joint Conference Artificial Intelligence, pp. 517{523
Detroit.
Tennenholtz, M., & Moses, Y. (1989). cooperation multi-entity model (preliminary
report). Proceedings Eleventh International Joint Conference Artificial
Intelligence, pp. 918{923 Detroit, Michigan.
von Martial, F. (1990). Coordination plans multiagent worlds taking advantage
favor relation. Proceedings Tenth International Workshop Distributed
Artificial Intelligence Bandera, Texas.
von Martial, F. (1992a). Coordinating Plans Autonomous Agents. No. 610 Lecture
Notes Artificial Intelligence. Springer Verlag, Heidelberg, Germany.
von Martial, F. (1992b). Coordination negotiation based connection dialogue
states actions. Proceedings Eleventh International Workshop Distributed Artificial Intelligence, pp. 227{246 Glen Arbor, Michigan.
Wellman, M. P. (1992). general equilibrium approach distributed transportation planning. Proceedings Tenth National Conference Artificial Intelligence San
Jose, California.
Zeuthen, F. (1930). Problems Monopoly Economic Walfare. G. Routledge & Sons,
London.
237

fiZlotkin & Rosenschein

Zlotkin, G., & Rosenschein, J. S. (1989). Negotiation task sharing among autonomous
agents cooperative domains. Proceedings Eleventh International Joint
Conference Artificial Intelligence, pp. 912{917 Detroit, Michigan.
Zlotkin, G., & Rosenschein, J. S. (1990). Negotiation con ict resolution noncooperative domains. Proceedings Eighth National Conference Artificial
Intelligence, pp. 100{105 Boston, Massachusetts.
Zlotkin, G., & Rosenschein, J. S. (1991a). Cooperation con ict resolution via negotiation among autonomous agents noncooperative domains. IEEE Transactions
Systems, Man, Cybernetics, 21 (6), 1317{1324.
Zlotkin, G., & Rosenschein, J. S. (1991b). Incomplete information deception multiagent negotiation. Proceedings Twelfth International Joint Conference
Artificial Intelligence, pp. 225{231 Sydney, Australia.
Zlotkin, G., & Rosenschein, J. S. (1991c). Negotiation goal relaxation. Demazeau,
Y., & Muller, J.-P. (Eds.), Decentralized A. I. 2, Proceedings Second European
Workshop Modelling Autonomous Agents Multi-Agent World, pp. 273{286.
North-Holland, Amsterdam.
Zlotkin, G., & Rosenschein, J. S. (1993a). domain theory task oriented negotiation.
Proceedings Thirteenth International Joint Conference Artificial Intelligence,
pp. 416{422 Chambery, France.
Zlotkin, G., & Rosenschein, J. S. (1993b). extent cooperation state-oriented domains: Negotiation among tidy agents. Computers Artificial Intelligence, 12 (2),
105{122.
Zlotkin, G., & Rosenschein, J. S. (1993c). Negotiation incomplete information
worth: Strict versus tolerant mechanisms. Proceedings First International
Conference Intelligent Cooperative Information Systems, pp. 175{184 Rotterdam, Netherlands.
Zlotkin, G., & Rosenschein, J. S. (1994). Coalition, cryptography, stability: Mechanisms coalition formation task oriented domains. Proceedings National
Conference Artificial Intelligence, pp. 432{437 Seattle, Washington.
Zlotkin, G., & Rosenschein, J. S. (1996a). Compromise negotiation: Exploiting worth
functions states. Artificial Intelligence, 84 (1{2), 151{176.
Zlotkin, G., & Rosenschein, J. S. (1996b). Mechanism design automated negotiation,
application task oriented domains. Artificial Intelligence. appear.

238


