Journal Artificial Intelligence Research 5 (1996) 329349

Submitted 5/96; published 12/96

Quantitative Results Comparing Three Intelligent Interfaces
Information Capture: Case Study Adding Name Information
Electronic Personal Organizer
Jeffrey C. Schlimmer
School Electrical Engineering & Computer Science
Washington State University, Pullman, WA 99164-2752, U.S.A.
Patricia Crane Wells
AllPen Software, Inc.
16795 Lark Avenue, Suite 200, Los Gatos, CA 95030, U.S.A.

SCHLIMME@EECS.WSU.EDU

PATRICIA@ALLPEN.COM

Abstract
Efficiently entering information computer key enjoying benefits
computing. paper describes three intelligent user interfaces: handwriting recognition,
adaptive menus, predictive fillin. context adding persons name address
electronic organizer, tests show handwriting recognition slower typing
on-screen, soft keyboard, adaptive menus predictive fillin twice fast.
paper presents strategies applying three interfaces information
collection domains.

1. Introduction
meet someone new, often wish get name phone number. may
write small notebook personal organizer. takes minutes do,
put business card small slip paper organizer, promising copy
later time.1 later time comes, face tedious task finding nowseveral names go organizer recopying information.
comfortable computers, may use electronic organizer (a small computer
includes software managing names appointments). Looking someones phone
number faster devices, adding tedious, owning costly.
concession reality, devices often include pockets holding queued slips
paper.
solutions could propose eliminate procrastination? adding persons
name2 organizer fun (say choice inspirational message, gratuitous
violence, lottery ticket), might add names readily. Avoiding whimsy,
could get desired effect making faster add persons name. reason
paper organizers use index tabs; electronic organizers use automatic filing. faster still,
organizer could read card handwritten note (via optical character handwriting

1. friend places rubber band around organizer ensure paper slips dont escape
time.
2. brevity, well refer persons name, address, phone numbers, e-mail, etc. name. Whether
aggregate information persons first last name intended clear context.

1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiS CHLIMMER & W ELLS

recognition). Applying artificial intelligence ideas, could even imagine organizer
predicts need write you.
paper describes electronic organizer almost fast slip paper,
certainly much faster previous organizers. uses commercial hardware (Newton,
described Section 2). software three interface components designed speed
adding persons name (described Section 3): handwriting recognition, adaptive menus
recent values, predictive fillin. primary contributions paper detailed
evaluations benefits three components (described Section 4).
Adding persons name organizer special case capturing organizing
information. ubiquitous task. Big businesses institute careful procedures
custom forms databases, billions smaller, one-or-two-person tasks
could done efficiently accurately getting information computer
easier. Even small gains would repeated many times whenever someone needed
collect information make decision, monitor process, investigate something new.
secondary contributions paper consideration three components may
applied broadly (described Section 5).
three interface components robust familiar. Whether intelligent
arguable. advocate behavior-based definition may apply here, i.e.,
question whether device intelligence answered examining
behavior rather internal processes representations (e.g., Agre & Chapman, 1987;
Horswill & Brooks, 1988). Even not, goal address question
much intelligence, agency, support one wants interface (Lee, 1990; Rissland, 1984).
assert: much speed users performance task. Furthermore, much
research directed automatically learning hard-code study (e.g.,
Dent, Boticario, McDermott, Mitchell, & Zabowski, 1992; Hermens & Schlimmer, 1994;
Schlimmer & Hermens, 1993; Yoshida, 1994). Even learning works perfectly, result
worthwhile? claim answer found empirical study usefulness
various user interface components.

2. Newton
Newton operating system introduced Apple Computer, Inc. 1993. designed
single-user, highly-portable computer. Frames central data structure Newton.
stored persistent object databases maintained RAM (Smith, 1994).
Newton computer includes pressure-sensitive, bitmapped display
user writes, draws, taps enter information (Culbert, 1994). small enough hold
one hand weigh around one US pound. Battery life one days worth
continuous use. thorough overview hardware software context current pen
computers, reader may wish consult (Meyer, 1995).
lowest levels, Newton supports recognition. handwriting recognition
highly publicized first introduced. recognizer allows free-form input
printed cursive writing.3 uses on-line recognition convert writing Unicode4 text.
recognizer uses contextual information limit types characters within specific
fields combinations characters within words. latter relies heavily
3. Throughout paper references handwriting refer handprinting. distinction required,
latter term used explicitly.
4. character encoding similar ASCII two-bytes per character languages larger character
sets.

330

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

dictionaryonly words appearing dictionary recognized. user types
new word using on-screen soft keyboard,5 Newton volunteers add dictionary
future recognition. Optionally, user invoke secondary recognizer
use dictionary attempts recognize written letter letter; Section 4
describes accuracy option. Application developers customize handwriting
recognition providing special purpose dictionaries regular expression describing
syntax words recognized.
Newton computers include several applications ROM serve
electronic organizer. Relevant point paper, Newton computers date
include application called Names storing retrieving peoples names, addresses,
etc.; Figure 1 depicts application. Section 4 describes experiments using standard
enhanced version Names application add peoples names.

Figure 1: Names application included Newton computers depicted one
quarter life size Apple Newton MessagePad 100 used experiments.
user taps field, expands ease writing. picture, First Name field
expanded. folder tab button top screen displaying names
one eleven user-defined folders. left right, buttons bottom
application screen showing time battery state (labeled clock
face), changing display name (labeled Show), adding new name
(labeled New), refiling name (labeled file folder picture), printing/
faxing/infrared beaming/mailing/duplicating/deleting name (labeled
envelope picture), closing application (labeled large X).
universal buttons visible applications. left right, provide access
Names application, calendar application, storage place
applications, scrolling buttons, undo, find, natural language recognition.

3. Names++
Newton computers built-in Names application includes one three components
suggested Section 1 speed adding new persons name. recognizes handwriting,
5. Throughout paper references typing refer tapping on-screen soft keyboard.

331

fiS CHLIMMER & W ELLS

recognition dictionary expanded needed. Names++ extended version
Names wrote include two components.
3.1

Adaptive Menus

Names++ extends Names adding adaptive menu 9 Names 17 fields: 7 menus
consisting 4 recently entered values 2 menus 4 recently entered values prepended
fixed choices. word user needs menu, choose rather write
out. Figure 2 depicts Names++ menu open City field. choices

Figure 2: Names++ application. picture, user tapped word
City opened menu recently used city names. user chooses one
cities, copied City field name. Compare
Figure 1. Note Names++ includes features Names relevant adding new
name.
menu four recently entered values specific field. (Each field
separate menu.) may convenient user series related names
add, perhaps people company city. course, user adds
four unusual values row, common choices inadvertently dropped menu.
sophisticated approach would list number recent values
number common; Names++ doesnt explore sake simplicity
speed. menus adaptive, users use linear search examine
choices cannot rely muscle-level memory choice locations. menus include
choices, cost search likely dominate Fitts law effect.6
Two Names fields already menu. Honorific field offered user Ms.,
Mrs., Mr., Dr.; Country field offered menu thirteen countries.
completeness, Names++ prepends four recent values fields menus.
Technically split menus.7 Mitchell Shneiderman (1989) compared large
statically ordered menus (unsplit) prepended most-recently-used choices
6. Fitts law states time move given distance target width W proportional log D/
W.
7. confused splitting menu choices across multiple menus (Witten, Cleary, & Greenberg, 1984).

332

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

(split, exactly condition). Static faster split menus one task;
difference another. Sears Shneiderman (1994) later found evidence favor split
menus including 1758% improvement selection time compared unsplit menus.
compared alternative organizations split part recommend limiting
number split choices four less (which Names++ does) sorting split choices
frequency (which Names++ approximates most-recently-used). context menu
hierarchies, Snowberry, Parkinson, Sisson (1985) found adding items containing
upcoming selections resulted greater accuracy faster search times. result
confirmed (Kreigh, Pesot, Halcomb, 1990) may much effect
preventing users getting lost menu hierarchies assisting making
selections per se. test adaptive (split) menus Names++ understand relative
contribution compared interfaces data entry task.
four Phone Number fields menus, give user way categorize
phone number rather enter number itself. category menus (Norman,
1991). phone menus include choices Phone, Home, Work, Fax, Car,
Beeper, Mobile, Other. phone fields identical menus. Names++
modify them. menus provided First Name, Last Name, Birthday fields.
Section 5 describes input fields menus.
understand computational space time demands adaptive menus, note
Names++ stores menus single object object database. size object
linear number fields menus (f) number choices menu
(c), fc. menu implemented circular queue, time update object
would constant menu, f. Names++ uses slightly slower array
implementation menus takes fc time. practice works slightly
one half second nine fields four choices.
3.2

Predictive Fillin

Names++ extends Names automatically filling 11 empty fields new name
predicted values. treats previous names case base (Kolodner, 1993) copies
information relevant case. Specifically, user adds company new name
matches previous names company, Names++ copies address
previous name new one. Values copied verbatim two address lines
City, State, Zip Code, Country fields. user ID electronic mail address
dropped e-mail address copied new name. (The remaining components
e-mail address likely people company.) last
word Phone Number values dropped; area code prefix copied
new name typical area code-prefix-extension phone number. user writes
chooses another value Company, replacing value field, predictive fillin
recopies dependent values previous name. Figure 3 illustrates sequence events
users perspective.
Names++ behaves similarly user adds city state matches previous
name, copies less information matching company found. value
copied predictive fillin incorrect, user write choose correct value
manually. Table 1 summarizes fields menus predictive fillin. structure
predictive fillin fixed design Names++. work attempts learn comparable
structure examples (e.g., Dent et al., 1992; Hermens & Schlimmer, 1994; Schlimmer &

333

fiS CHLIMMER & W ELLS

Figure 3: Names++ application user adds company new name.
left panel, application finds previous name matching company, displays
dialog, fills remaining fields predicted information copied
previous name. center panel shows much information filled. right
panel shows completed name. example user written four
additional words complete name.
Hermens, 1993; Yoshida, 1994). goal determine whether end result
learning worthwhile.
one previous name matches company, city, state new name,
Names++ fills fields values recent name. Values second-most
recent occurrence name added menus. gives user chance select
alternate addresses company alternate zip codes city.
terms computational requirements, Names++ needs additional storage
predictive fillin; object database previously added names reused case base.
Matching new names company, city, state previous name implemented
Newton primitive; informal study depicted Figure 4 indicates Newtons proprietary
algorithm appears run time linear number names match found
logarithmic matches found.
Names++ source code on-line Appendix A.

4. Experiments
hypothesize recognition, adaptive menus, predictive fillin speed adding new
name. find extent, conducted experiment
subjects added names using different combinations three interface components.
4.1

Method

Five computer science students ages 18 35 years age participated
subjects experiments. Prior experiments used Newton computer
least six months familiar Newtons handwriting recognition QWERTY
layout Newtons on-screen keyboard.
experiment used within-subject design subject participated
six conditions summarized Table 2. Conditions designed assess contribution
334

fiTime Seconds

HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

J

5.2

J
1.6

BJ
BJ
0.1 B
JBJ
0.7

10

E

J
BG

B

B
640
Number Names

200

Figure 4: Time find matching name using Newton function number
names database match exists (circles upper line) several matches
exist (squares lower line). axes linear scale. upper line linear fit;
lower line logarithmic. comparison experiment, interpolated values
200 names shown open symbols.
interface component separately collectively. control, Typed condition,
subject types values without using components. Null condition,
subject writes words using remedial recognition steps (to described) types words
recognizable. subject add words Newtons dictionary
asked assistance either adaptive menus predictive fillin.
condition extends Null requiring subject add words Newtons dictionary
asked. condition extends Null adding adaptive menus. PF condition extends
Null adding predictive fillin. condition combines extensions D, AM,
PF.
used pair Apple Newton MessagePad 100 computers (running Newton OS
version 1.3) experiment three versions Names++ application. One version
interface components disabled used Typed, Null, conditions.
second version adaptive menus used AM. third version adaptive menus
predictive fillin used PF All.
set 448 name records experiments donated development officer
Washington State University. job involves contacting alumni others solicit
support university programs. Almost records include first last name, full
mailing address, one three phone numbers. include honorific, country, email address. Informal tests indicated MessagePads could hold 250 names
Names++ installed, selected random set 200 records.

335

fiS CHLIMMER & W ELLS

Menu Choices
Field
Honorific

Predictive Fillin

Built-in Adaptive
4

Company

City

State

Notes
Ms., Mrs., Mr., Dr.

4

First Name
Last Name
Title

4

Company

4

Address (1)

4

Address (2)

Yes
label tap menu.

Yes

City

4

Yes

State

4

Yes

Yes

Zip Code

4

Yes

Yes

4

Yes

Yes

4

Yes

Country

13

E-Mail
Phone 1

8

Phone 2

8

Phone 3

8

Phone 4

8

Area Code
Prefix

Yes
User ID removed.
Category menu used select
type phone number rather
phone number itself. Choices
include Phone, Home,
Work, Fax, Car, Beeper,
Mobile, Other.

Area Code

Birthdate

Table 1: Name++ fields adaptive menus predictive fillin.
Condition

Writing

Add Dictionary

Adaptive Menus

Predictive Fillin

Typed
Null

Yes



Yes



Yes

PF

Yes



Yes

Yes
Yes
Yes
Yes

Yes

Yes

Table 2: Experimental conditions, one row per condition. Columns indicate
user interface components used. Blank cells represent No.
simulate worst case recognition, adaptive menus, predictive fillin, chose
5 names (listed below) residual 248 names company
preload set 200 names. (To preserve anonymity here, first last names swapped
phone numbers replaced artificial values. Actual first last name pairs phone
numbers used experiment.)
336

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

Robert Anderson
Account Marketing Rep
IBM
W 201 N River Drive
Spokane, WA 99201
509 555 0000
509 555 1111

Eric Brice
Director Engineering
RAIMA Corp
3245 146th Place SE
Bellevue, WA 98007
206 555 2222
206 555 3333
205 555 4444

Peter Friedman
President
NOVA Information Systems
12277 134th Court NE
Suite 203
Redmond, WA 98052
206 555 7777

Thomas Leland
Staffing Manager
Aldus Corporation
411 First Ave South
Seattle WA 98104 2871
206 555 8888
206 555 9999

Mike Carlson
VP Engineering & Estimating
General Construction
2111 N Northgate Way
Suite 305
Seattle, WA 98133
206 555 5555
206 555 6666

score words names entered total time, used sheet
Figure 5. Fictitious data corresponding subjects entering second name
condition depicted.

Figure 5: Scoring sheet used time name added. 1 center right
columns indicates first word field value entered using recognition
(cf. Figure 6), adaptive menu (cf. Figure 2), predictive fillin (cf. Figure 3). 2
indicates second word, on. highest digit row corresponds
number words fields value.
facilitate setting condition, constructed backup images MessagePads
correctly configured six conditions. images, 200 names
appropriate version Names++ installed. images All, added
First, Last, Company names dictionary using built-in feature Newton.
initialize adaptive menus images All, used special purpose
application. Prior use MessagePads completely erased restored
backup image appropriate condition tested.

337

fiS CHLIMMER & W ELLS

task subject enter five names twice six
conditions. first time name entered condition simulates worst-case scenario;
second time, best.
4.2

Procedure

Subjects given listing one five names MessagePad initialized one
six experimental conditions. subject entered name condition; name/
condition pairs randomly ordered subject counteract subject learning
effects. instructed enter names quickly. Subjects made mistakes.
instructed correct finishing. Times reported include time correct
mistakes.
Subjects given precise script follow entering name. done
partially bias results hypotheses partially minimize individual variation.
Specifically, subject instructed enter values field order, top
bottom, completing one going next (cf. Figure 1). conditions involving
handwriting, word correctly recognized, subject check menu
alternate recognitions (depicted left panel Figure 6). intended word

Figure 6: Remedial steps handwritten word correctly recognized.
example, subject wrote Brice misrecognized Brian.
subject double-taps word, menu alternative recognitions appears (left
panel). none correct, subject requests recognition without
dictionary (or letter letter). Another double-tap word generates second
menu alternatives (middle panel). none correct, subject entered
word tapping buttons on-screen keyboard (right panel).
list, select Try letters attempts recognition without dictionary.
result correct, check second menu alternative
recognitions (depicted center panel Figure 6). intended word
second menu, tap button keyboard picture, type word using
on-screen keyboard, close keyboard. word already part
dictionary, Newton asked would add (depicted right panel Figure 6).
Note recognition menus, original handwriting shown near
338

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

bottom. first choice Newtons best guess, second choice best guess
different capitalization. subject instructed ensure words correctly
capitalized.
Typed, subject instructed enter data using Newtons on-screen soft
keyboard. Null, subject enter data handwriting. All,
subject instructed add words Newtons dictionary asked. All,
subject instructed check fields menu (if one) writing data.
special instructions required PF beyond default adding words
dictionary.
stopwatch started subject tapped New button stopped
last field value correctly entered. Choosing manual timing method simplified
development experimental software. method word field
entered recorded scoring sheet indicated Figure 5.
experiment took three five hours subject spread
two sessions approximately two hours within week. Subjects took short
breaks adding name minimize fatigue.
subject completed experiment, asked rank favorite
methods entering names least.
4.3

Results

Table 3 summarizes median standard deviation subjects time enter name
six conditions. Times include user input, predictive fillin computation, time
correct errors (if any). first row reports time add novel name, simulation
worst case. second row reports time repeat name, simulation best case.
ANOVA reveals significant main effect condition F(5, 21.07) < 0.001. interaction
number times name entered condition significant F(5, 19.61) < 0.001.
Comparing worst cases across conditions, post-hoc multiple comparisons test using
Tukeys HSD indicates Typed significantly different (faster)
conditions. (All p < 0.05.) Comparing worst best cases within condition, D, AM,
PF, significantly faster. Comparing best cases across conditions, Typed, AM,
PF significantly faster Null; significantly faster Typed, PF, D,
Null. pairwise comparisons significant.
Typed

Null





PF



Worst

2.72 (0.86)

4.25 (1.31)

4.50 (1.45)

4.32 (1.70)

4.07 (1.26)

4.15 (1.13)

Best

2.52 (0.60)

3.65 (1.24)

3.30 (1.09)

1.37 (0.51)

2.02 (0.45)

1.08 (0.24)

Table 3: Median time minutes add new name five names five subjects
(25 samples per cell, standard deviation parentheses). Columns list six
experimental conditions.
difference within D, AM, PF across worst best cases confirms
hypothesis interfaces speed entering names, 29%, 210%, 110% compared
Null, respectively. surprised find predictive fillin fast
adaptive menus (though difference statistically significant). designing data
entry system one might tempted implement adaptive menus given algorithmic
simplicity, especially compared sophisticated methods machine learning
proposed predictive fillin. However, latter suffer recency effects imposed
339

fiS CHLIMMER & W ELLS

limited size adaptive menus; entering new data related distant
past, predictive fillin would little difficulty providing assistance adaptive menus
could not. Adaptive menus could refined use frequency frequency-recency
combination, performance suggests implementing adaptive menus
predictive fillin. Combined adding words dictionary, speed entering names
294%. practical terms, interfaces could make entering name electronic
organizer faster writing paper certainly fast enough capture
information phone conversation.
Prior work confirms difference Typed conditions. Ward
Blesser (1986) state normal writing speed rarely greater 69 characters per minute
(cpm) single line text. Using fact mean number characters per name
experiment 98.2, subjects achieved 30 cpm. MacKenzie, Nonnecke, Riddersma,
McQueen, Meltz (1994) compare four interfaces entering numeric text data
pen-based computers, including hand printing using on-screen keyboard. (The
two interfaces experimental gesture-based techniques entering single characters.)
numeric entry conditions, found on-screen keyboard 30 words per
minute (wpm) 1.2% error whereas hand printing 18.5 wpm 10.4% error.
text entry conditions, keyboard 23 wpm 1.1% error whereas hand printing
16 wpm 8.1% error. Using fact mean number words per name
experiment 20.8, subjects achieved 8.3 wpm typing 6.3 wpm handwriting
mixed numeric/text input. key point comparison studies
found using stylus tap on-screen keyboard faster handwriting printing.
Differences speed studies likely result differences
experimental procedures (theirs versus ours): single versus multiple field fillin, copying
information memory screen versus paper, block comb-type (letter) versus
open (word) interface.
Figure 7 presents Box plot summaries time data. interest reduction
variance time adaptive menus predictive fillin best case (right plot).
Differences individual performance reduced interface components.
left half Table 4 lists recognition accuracy field conditions,
subjects, names. first row indicates 94% first names written
correctly recognized immediately. checking first menu alternate recognitions,
accuracy rises 95%. Similarly, second row indicates 59% second names
written correctly recognized immediately. rate rose 74% letter-by-letter
recognition invoked 79% checking second menu alternate
recognitions. Phone numbers enjoyed second highest recognition rate first names.
reference, Cesar Shinghal (1990) report 90% recognition rate hand
printed, Canadian postal codes {letter, digit, letter, space, digit, letter, digit}.
comparable observed rates first names, second address lines, phone
numbers.
right half Table 4 lists percentage words entered using typing, adaptive
menus, predictive fillin field conditions, subjects, names. first row
indicates 5% first names typed. row State indicates 32% state
names typed, 20% chosen adaptive menu, 39% predictively
filled in. (Note numbers row total 100% left half
table lists percentages words written right half lists percentages
words.)
340

fiTime Minutes

HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

*
10

10
*
*
*
*
*

5

*

*

*

5
*

Worst Case



Fillin

Menu

Dictionary

Null

0

Typed

*



Fillin

Menu

Dictionary

Typed

0

Null

*

Best Case
Experimental Condition

Figure 7: Box plots time enter name condition worst best cases.
box summarizes 25 values. Values outside inner fences plotted
asterisks. Values outside outer fences plotted circles (Wilkinson, Hill,
Vang, 1992).
Combining left right halves Table 4 reveal many difficult-torecognize fields considerable assistance adaptive menus predictive fillin.
accentuates speed improvements providing help needed. Figure 8
depicts relationship fields, recognition accuracy,
adaptive menus predictive fillin. Several fields near perfect recognition accuracy;
recognized without resorting typing. instance, numeric fields easier
recognize; Phone Number fields recognized nearly 90% even though area
code, prefix, suffix varied name name. First Last name fields
high recognition accuracy. first names built-in dictionary. two
last names were, others often recognized letter letter. Recognition
poorer Company Address fields. Words full capitals (e.g., RAIMA) words
combination numbers letters (e.g., 146th) difficult recognize.
low recognition accuracy State field apparently due oversight Newtons
dictionary. WA included many two-letter abbreviations US states are.
compensate low accuracy, Names++ includes adaptive menu and/or predictive fillin
difficult-to-recognize fields.
Table 5 summarizes subjects preference condition enter name. lists frequency
ranking five subjects. Subjects partitioned conditions non-overlapping
groups (Typed, Null), (D, AM, PF), (ALL). (The authors know suitable statistic
asserting differences.) results contradict MacKenzie et al. (1994)
found subjects preferred typing handwriting, mildly text entry
341

fiS CHLIMMER & W ELLS

100

XFirst Name

GPhone

GAddress (2)
XLast Name
75

Title

Recognition (%)

City

Company

Address (1)

Zip Code
50

X

G

25
State

Recognition
Adaptive Menus
Predictive Fillin


0
0

200

400

600
800
Number Words

1000

1200

Figure 8: Recognition rate function number total words entered
conditions subjects names. Fields adaptive menus predictive fillin
(or both) marked. Note every field less 75% accuracy either
adaptive menu predictive fillin (or both).
strongly numeric entry. restricted hand printing input block comb-type
interface; unnaturalness may account dispreference toward handwriting.
Writing stylus advantages. Meyer (1995) points out, keyboards
faster linear text entry, pen input device natural, handle text
graphic input, jump quickly point point. Writing pen supports
heads writing, allowing user visually attend aspects task hand.
Typing on-screen keyboard requires heads entry.
One subject experimented Names++ outside experimental setting offered
number observations. First, adaptive menus short, sometimes menus
would useless matter long were. wished City Company
fields menus longer (especially City). frustrating one common
city names large metropolitan region bumped short list. contrast, Title
fields menu rarely useful, see point maintaining it. principles
outlined Section 5 suggest similar revisions.
342

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

Field

Cumulative Recognition Accuracy
Letter
Correct
1st Menu
2nd Menu
Letter

Percent Words Entered
Adaptive Predictive
Typed
Menu
Fillin

First Name

94

95

95

95

5

Second
Name

59

59

74

80

21

Title

52

62

66

68

26

20

Company

42

49

59

61

31

20

Address

48

60

62

67

23

10

Address 2

81

85

87

87

10

City

62

62

67

71

19

12

20

State

22

22

22

22

32

20

39

Zip

51

52

58

59

29

10

20

Phone

86

89

89

89

10

20
20

15

Table 4: left columns list cumulative recognition accuracy field words
written conditions, names subjects. right columns list
percentage words field entered typing, adaptive menus, predictive
fillin. 5190 values total. Blank cells represent 0.
5th

6th

Typed

1

4

Null

4

1

Condition

1st

2nd



3rd

1

4
1



2

2

PF

3

2



4th

5

Table 5: Subjects frequency ranking preference different conditions
means enter name. 30 values total. Blanks cells represent 0.
Second, found predictive fillin helpful. Sometimes filled didnt
expect to. noted predictive fillin copies many fields,
encourages user add complete name. may advantage harried
setting.

5. Design Recommendations
Given experimental results, configure handwriting recognition,
adaptive menus, predictive fillin another application (or redesigned Names++)?
handwritten input, recognition use dictionaries specific type field: numbers
numeric fields, lists domain terms text fields.
5.1

Adaptive Menus

adaptive menus, add menu field might repeated values.
accidentally added adaptive menu field never value twice,
343

fiS CHLIMMER & W ELLS

Last Name

John
Jim
Bob
Jerry
Paul
David
Steve
Ron
Bill
Tom
Robert
Jack
Dennis
Robin
Rich
Julie
James
Edmund

Dave

Title

President
Executive Director
Vice President - Human Resources
Vice President
Travel Consultant
Staffing Specialist
Sales Representative
Program Officer
Principal
Manager
Industrial Research Marketing Manager
Human Resources Manager
Human Resources
General Manager
Chair
Account Manager
consultant Seattle Govt. Relations
Western Regional Sales Manager
Vice President/Managing Principal
Vice President, Finance & Administra
0%
25%
50%
75%
100%
Percent Values

Brown
Wood
Smith
Lee
Baker
Thomas
Schroeder
Ray
Nelson
Jones
Johnson
Hoffman
Hand
Frost
Evans
Erickson
Dalpiaz
Anderson
Adams
Zipp

Boeing
Hewlett-Packard Company
Tektronix, Inc.
Battelle
Fluke Corporation
Microsoft Corporation
Mentor Graphics Corporation
ELDEC Corporation
Puget Sound Power & Light
Motorola Inc.
ARCO Products Company
University Washington
Sundstrand
Sandia National Laboratories
Honeywell
Washington Technology Center
Intel Corporation
Asymetrix Corporation
Oregon State University
Digital Equipment Corporation
0%
25%
50%
75%

Company

First Name

mistake would harmless. user would surely notice choices useless
avoid checking menu. menu appropriate, user would save time
choosing common values it.
long menu be? Long enough include common values
short enough checked quickly. make sure menu long enough, study often
fields values repeat. Names++, Figures 9a 9b depict frequency histogram

100%

Figure 9a: Frequency values First Name, Last Name, Title, Company
fields 448 names used Section 4. plot histogram 20
common values. Dark lines indicate percent values could chosen
different sized menus. menu includes choices top vertical
position, would allow user choose percentage field values indicated
horizontal position.

344

fiP.O. Box 3707
P.O. Box 3999
Pacific Northwest Laboratories
P.O. Box 999
P.O. Box 500
One Microsoft Way
P.O. Box C9090
P.O. Box 100
8005 S.W. Boeckman Road
160520 Microsoft BVUE
P.O. Box 97034
Cherry Point Refinery
Boeing Commercial Airplane Company
Post Office Box 8100
P.O. Box 97001
Battelle Boulevard
TAF C-34
P.O. Box 9090
P.O. Box 1970
FJ-15

City

Address

HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

WA

State

ID
TX
IL
NY

AZ
UT
OH
NM
MN
MI
KS
FL
British Columbia
Virginia
VA
Texas
0%
25%
50%
75%
Percent Values

99352
98124-2207
98124-2499
99220
98206
98195
98124
98052-6399
98009
98046-0100
98006
99336
98206-9090
98073-9701
98004
97077
97070-7777
99163
97070
98477
0%
25%

Zip Code


CA

Seattle
Bellevue
Richland
Redmond
Spokane
Everett
Beaverton
Hillsboro
Wilsonville
Lynnwood
Vancouver
Pullman
Kennewick
Tacoma
San Francisco
Portland
Blaine
San Ramon
Kirkland
Corvallis

100%

50%

75%

100%

Figure 9b: Frequency values Address, City, State, Zip Code fields
448 names used Section 4.
20 common values 8 fields drawn 448 name records used
experiments. Overlaid plot line indicating percent field values could
chosen particular size menu. instance, First Name field Figure 9a,
histogram almost flat. menu including John would allow user choose
value field less 5% time. menu included 20 first names
shown, user could choose value 25% time. field menu
long enough include common values would take long
check. (Also, Newton computer used Section 4 limits menus 23 choices
screen size.) contrast, Company field Figure 9a, menu including

345

fiS CHLIMMER & W ELLS

Boeing would allow user choose value 10% time. included
20 values shown, user could choose value 50% time.
Studying histograms aiming menus include 50% fields values,
might re-engineer Names++ menus size 20 Company Field, size 10
City field, size 5 State field. fields flat histograms would
need large menus include high percentage field values. Recall Section 4 reports
one subjects frustration Title field. President seems repeated
field 448 names used.
5.2

Predictive fillin

Set predictive fillin field functionally dependent (Ullman, 1988) another.
functional dependency related artificial intelligence idea determination
(Russell, 1989). Intuitively, one field R, range, functionally depends another field D,
domain, if, given value D, compute unique value R. predictive fillin
find previous entry value new entry, copies
previous entrys value R new entry. Names++, Company field
domain Address field range functional dependency.
Predictive fillin functionally dependent fields probably strict
strategy. functional dependencies useful predictive fillin
domain values unique database. so, predictive fillin cannot find
previously matching entry cannot copy relevant information. instance, US
citizens address functionally dependent Social Security number. application
Names++ dont expect see Social Security number twice, predictive
fillin would never opportunity help user filling address. Functional
dependencies repeated domain values database, dense functional
dependencies, used set predictive fillin.
Conversely, non-functional dependencies may close enough functional
useful predictive fillin. Technically, dependency functional unless one value
range computed every value domain. values range
computed values domain, dependency might still useful (Raju &
Majumdar, 1988, Russell, 1989, Ziarko, 1992). instance, companies single
office address, may one. still quite useful fill address
fields Names++ finds previous name matching Company field. user
interface strategies compensate possible range values arise;
instance, Names++ puts alternate addresses Address fields adaptive menu.
Therefore, dense dependencies functional nearly so, dense approximatelyfunctional dependencies, used set predictive fillin.
determine dense approximately-functional dependencies hold new
application area, may necessary repeat type empirical domain analysis
described adaptive menus. Names++, used common sense knowledge
people, companies, addresses set predictive fillin. Recall goal
discover end result automatic learning worthwhile (e.g., Dent et al., 1992;
Hermens & Schlimmer, 1994; Schlimmer & Hermens, 1993; Yoshida, 1994). recommend
considering field number logical components dependencies may exist
parts rather whole fields. instance, person company may share
common telephone number area code prefix, likely different

346

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

extensions. predictively filling last component phone number, Names++
fills much without adding poor quality information.

6. Related Work
Though interested different tasks, researchers studied using intelligent user
interfaces speed information capture. instance, Hermens Schlimmer (1994) built
electronic form filler tried provide default values every field form.
field form decision tree calculate default value. Names++,
calculations used previously entered information generate defaults predictively fill
fields. Unlike Names++, calculations constructed run-time using
machine learning method. (Names++ alter predictive fillin run-time. cf. Table 1.)
field tested system single electronic form filled several hundred times
eight month period. report 87% reduction keystrokes; loosely translating
speedup yields 669% speedup approximately 3 times 210% speedup
observed entering name.
Studying text prediction without field boundaries, Pomerleau (1995) built typing
completion aid. Without relying note-taking properties, system predicts completion
current word typed (presumably editor). connectionist network
estimates probability number possible completions current word;
likely, threshold, offered user. Pomerleau tested system pair
subjects two-week period reports increase typing speed 2% English
text 1318% computer program code. modest gain may due inefficiencies
learning method, lack redundancy task, limitations user
interface itself.
complement earlier research, paper reports individual collective
accuracy three user interface components. reports user task time showing
components significantly improve efficiency. paper clarifies issue confounded
earlier work. learning interface less effective expected, due inherent
limitation interface itself, learning method perform inadequately?
answer second question, work compares two learning methods.
paper, hand-built predictive fillin structures (cf. Table 1) able assess
quality predictive fillin interface directly.

7. Conclusion
paper makes two main contributions. First, presents study impact three
user interface components time enter information computer: handwriting
recognition, adaptive menus, predictive fillin. Handwriting recognition slower
typing preferred users. Advances handwriting recognition may make faster,
recognition would still much slower choosing value menu predictive
fillin. three components work well together preferred users.
Second, paper discusses principles applying adaptive menus predictive fillin
new application areas. Fields few, frequently repeated values candidates
adaptive menus; functional dependencies indicate candidates predictive fillin. Whether
characteristics learned run-time topic future research.

347

fiS CHLIMMER & W ELLS

Acknowledgments
Kerry Hersh Raghavendra provided names used Section 4. Apple Computer developed
supports Newton Newton ToolKit programming environment. Newton AI
group WSU provided many useful comments earlier draft paper. Geoff Allen,
Karl Hakimian, Mike Kibler, EECS staff provided consistent reliable
computing environment. Anonymous reviewers earlier draft paper provided
many (many) valuable suggestions. work supported part NASA grant
number NCC 2-794.

References
Agre, P. E., & Chapman, D. (1987). Pengi: implementation theory activity.
Proceedings Sixth National Conference Artificial Intelligence (pp. 268272).
Seattle, WA: AAAI Press.
Cesar, M., & Shinghal, R. (1990). algorithm segmenting handwriting postal codes.
Int. J. Man-Machine Studies, 33, 6380.
Culbert, M. (1994). Low power hardware high performance PDA. Proceedings
1994 IEEE Computer Conference. San Francisco, CA: IEEE.
Dent, L., Boticario, J., McDermott, J., Mitchell, T., & Zabowski, D. (1992). personal
learning apprentice. Proceedings Tenth National Conference Artificial
Intelligence (pp. 96103). San Jose, CA: AAAI Press.
Hermens, L. A., & Schlimmer, J. C. (1994). machine learning apprentice
completion repetitive forms. IEEE Expert, 9, 1, 2833.
Horswill, I. D., & Brooks, R. A. (1988). Situated vision dynamic world: Chasing objects.
Proceedings Seventh National Conference Artificial Intelligence (pp. 796800).
St. Paul, MN: AAAI Press.
Kolodner, J. (1993). Case-based reasoning. San Francisco, CA: Morgan Kaufmann.
Kreigh, R. J., Pesot, J. F., & Halcomb, C. G. (1990). evaluation look-ahead help fields
various types menu hierarchies. Int. J. Man-Machine Studies, 32, 649661.
Lee, J. (1990). Intelligent interfaces UIMS. D. A. Duce, M. R. Gomes, F. R. A.
Hopgood, & J. R. Lee (Eds.), User interface management design. NY: SpringerVerlag.
MacKenzie, S. I., Nonnecke, B., Riddersma, S., McQueen, C., & Meltz, M. (1994).
Alphanumeric entry pen-based computers. Int. J. Human-Computer Studies, 41,
755792.
Meyer, A. (1995). Pen computing: technology overview vision. SIGCHI Bulletin, 27,
3, 4690.
Mitchell, J., & Shneiderman, B. (1989). Dynamic versus static menus: exploratory
comparison. SIGCHI Bulletin, 20, 4, 33-37.
348

fiT HREE NTERFACES NORMATION C APTURE: C ASE TUDY DDING N AME NFORMATION

Norman, K. L. (1991). psychology menu selection: Designing cognitive control
human/computer interface. Norwood, NJ: Ablex.
Pomerleau, D. A. (1995). connectionist technique accelerated textual input: Letting
network typing. Advances Neural Information Processing Systems 7.
Cambridge, MA: MIT Press.
Rissland, E. L. (1984). Ingredients intelligent user interfaces. Int. J. Man-Machine
Studies, 21, 377388.
Raju, K. V. S. V. N., & Majumdar, A. K. (1988). Fuzzy functional dependencies lossless
join decomposition fuzzy relational database systems. ACM Trans. Database Syst. 13,
2, 129166.
Russell, S. J. (1989). use knowledge analogy induction. San Francisco, CA:
Morgan Kaufmann.
Schlimmer, J. C., & Hermens, L. A. (1993). Software agents: Completing patterns
constructing interfaces. Journal Artificial Intelligence Research, 1, 6189.
Sears, A. & Shneiderman, B. (1994). Split menus: Effectively using selection frequency
organize menus. ACM Trans. Computer-Human Interaction, 1, 1, 2751.
Smith, W. R. (1994). Newton application architecture. Proceedings 1994 IEEE
Computer Conference. San Francisco, CA: IEEE.
Snowberry, K., Parkinson, S., & Sisson, N. (1985). Effects help fields navigating
hierarchical menu structures. Int. J. Man-Machine Studies, 22, 479491.
Ullman, J. D. (1988). Principles database knowledge-base systems: Volume 1.
Rockville, MD: Computer Science Press.
Ward, J. R., & Blesser, B. (1986). Interactive recognition handprinted characters
computer input. SIGCHI Bulletin, 18, 1, 4457.
Wilkinson, L., Hill, M., & Vang, E. (1992). SYSTAT: Graphics, Version 5.2 Edition.
Evanston, IL: SYSTAT, Inc.
Witten, I. H., Cleary, J. G., & Greenberg, S. (1984). frequency-based menu-splitting
algorithms. Int. J. Man-Machine Studies, 21, 135-148.
Yoshida, K. (1994). User command prediction graph-based induction. Sixth IEEE
International Conference Tools Artificial Intelligence (pp. 732735). New
Orleans, LA: IEEE.
Ziarko, W. (1992). discovery, analysis, representation data dependencies.
Piatetsky-Shapiro, G., & Frawley, W. (Eds.), Knowledge discovery databases. Palo
Alto, CA: AAAI Press.

349


