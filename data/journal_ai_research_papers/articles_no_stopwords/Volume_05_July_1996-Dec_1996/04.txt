Journal Artificial Intelligence Research 5 (1996) 139-161

Submitted 4/96; published 10/96

Learning First-Order Definitions Functions
J. R. Quinlan

quinlan@cs.su.oz.au

Basser Department Computer Science
University Sydney
Sydney 2006 Australia

Abstract

First-order learning involves finding clause-form definition relation examples
relation relevant background information. paper, particular first-order
learning system modified customize finding definitions functional relations.
restriction leads faster learning times and, cases, definitions
higher predictive accuracy. first-order learning systems might benefit similar
specialization.

1. Introduction
Empirical learning subfield AI develops algorithms constructing theories
data. classification research area used attribute-value formalism,
data represented vectors values fixed set attributes labelled
one small number discrete classes. learning system develops mapping
attribute values classes used classify unseen data.
Despite well-documented successes algorithms developed paradigm (e.g.,
Michie, Spiegelhalter, Taylor, 1994; Langley Simon, 1995), potential
applications learning fit within it. Data may concern objects observations
arbitrarily complex structure cannot captured values predetermined
set attributes. Similarly, propositional theory language employed attribute-value
learners may inadequate express patterns structured data. Instead, may
necessary describe learning input relations, relation set tuples
constants, represent learned first-order language. Four examples
practical learning tasks kind are:

Speeding logic programs (Zelle Mooney, 1993). idea learn

guard nondeterministic clause inhibits execution unless lead
solution. Input learner consists Prolog program one
execution traces. one example Dolphin, system cited above, transformed
program complexity O(n!) O(n2 ).

Learning search control heuristics (Leckie Zukerman, 1993). Formulation pref-

erence criteria improve eciency planning applications similar avor.
One task investigated familiar `blocks world' varying numbers
blocks must rearranged robot manipulator. input learning concerns
particular situation search includes complete description current planning state goals. amount information increases

c 1996 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiQuinlan

number blocks inter-relationships, cannot encoded fixed set
values.
Recovering software specifications. Cohen (1994) describes application based
software system consisting million lines C code. Part system implements virtual relations compute projections joins underlying base
relations, goal reconstruct definitions. Input learning consists
queries, responses, traces showing base relations accessed answering queries. output logical description virtual relation; since
involves quantified variables, lies beyond scope propositional attribute-value
languages.
Learning properties organic molecules (Muggleton, King, Sternberg, 1992;
Srinivasan, Muggleton, Sternberg, King, 1996). approach learning
papers based representing structure molecules
addition properties molecules molecule segments. latter paper notes
discovery useful indicator mutagenicity expressed terms structure.
development learning methods based powerful relational formalism
sometimes called inductive logic programming (Muggleton, 1992; Lavrac Dzeroski,
1994; De Raedt, 1996). Input typically consists tuples belong, belong,
target relation, together relevant information expressed set background
relations. learning task formulate definition target relation terms
background relations.
relational learning task described detail following section. Several
algorithms relational learning developed recently, Section 3 introduces
one system called foil (Quinlan, 1990). foil used relations
kind, one particularly common use relations represent functions. Changes
foil effect customize learning functional relations outlined Section 4.
Several comparative studies, presented Section 5, show specialization leads
much shorter learning times and, cases, accurate definitions. Related work
learning functional relations discussed Section 6, paper ends
conclusions study directions development.

2. Relational Learning

n-ary relation consists set n-tuples ground terms (here constants).
constants ith position tuples belong type, types may differentiated constants may taken belong single universal type.
alternative extensional definition (possibly infinite) set, relation
specified intensionally via n-argument predicate RI defined Prolog program.

hc1 ; c2 ; :::cn 2 RI (c1 ; c2 ; :::; cn ) true
constants fci g, intensional extensional definitions equivalent.
convenience, subscripts RI omitted R used denote
either set tuples predicate.
140

fiLearning First-Order Definitions Functions

Input relational learning task consists extensional information target
relation R extensional intensional definitions collection background relations.
Examples tuples known belong target relation provided and, cases,
examples tuples known belong R. goal learn Prolog program
R covers tuples known belong R tuples known belong R
or, words, program agrees extensional information provided
R.
Many relations interest infinite. alternative selecting examples belong
belong R define finite vocabulary V specify relations respect
vocabulary. is, R represented finite set tuples, constants
belong V . Since specification R complete vocabulary, tuples
belong R inferred closed world assumption complement
tuples R.
function f (X1 ; X2 ; :::; Xk ) k arguments represented k+1-ary relation
F (X1 ; X2 ; :::; Xk ; Xk+1 ) where, tuple F , value last argument
result applying f first k arguments. (Rouveirol (1994) proves attening
used remove non-constant function symbols first-order language.)
functional relations additional property constants fc1 ; c2 ; ::; ck g
exactly one value ck+1 hc1 ; c2 ; :::; ck+1 belongs F .
example, consider three-argument predicate append(A,B,C) whose meaning
result appending list list B list C.1 corresponding relation append
infinite, restricted vocabulary defined lists containing elements
f1,2,3g whose length less equal 3. 40 lists
[ ], [1], [2], [3], [1,2], ...., [3,3,2], [3,3,3]

64,000 3-tuples lists. respect vocabulary, append consists 142
3-tuples, viz.:

h[ ],[ ],[ ]i, h[ ],[1],[1]i, ..., h[2],[1,3],[2,1,3]i, ..., h[3,3,3],[ ],[3,3,3]i.
background relation components, components(A,B,C) means list
head B tail C. goal learn intensional definition append given
background relation components. suitable result might expressed
append([ ],A,A).
append(A,B,C) :- components(A,D,E), append(E,B,F), components(C,D,F).

recognizable Prolog definition append.
1. Prolog, append invoked combination arguments bound find possible
values unbound arguments. Section 5.1, however, append treated function
first two arguments third.

141

fiQuinlan

Initialization:
definition := null program
remaining := tuples belonging target relation R
remaining empty
/* Grow new clause */
clause := R(A; B; :::) :While clause covers tuples known belong R
/* Specialize clause */
Find appropriate literal(s) L
Add L body clause
Remove remaining tuples R covered clause
Add clause definition
Figure 1: Outline foil

3. Description foil

common many first-order learning systems, foil requires background relations defined extensionally sets tuples constants.2 Although intensional
definition learned particular set examples, intended executable
Prolog program background relations may specified intensionally
definitions rather sets ground tuples. instance, although append definition
might learned particular examples lists, correctly append
arbitrary lists, provided components specified suitable clausal definition. (The
applicability learned definitions unseen examples cannot guaranteed, however; Bell
Weber (1993) call open domain assumption.)
language foil expresses theories restricted form Prolog omits
cuts, fail, disjunctive goals, functions constants, allows negated literals
not(L(...)). essentially Datalog language specified Ullman (1988), except
requirement variables negated literal appear head
another unnegated literal; foil interprets using negation failure (Bratko, 1990).

3.1 Broad-brush overview
outlined Figure 1, foil uses separate-and-conquer method, iteratively learning
clause removing tuples target relation R covered clause none
remain. clause grown repeated specialization, starting general clause
2. Prominent exceptions include focl (Pazzani Kibler, 1992), filp (Bergadano Gunetti, 1993),
Foidl (Mooney Califf, 1995), allow background relations defined extensionally,
Progol (Muggleton, 1995), information relations non-ground form.

142

fiLearning First-Order Definitions Functions

head adding literals body clause cover tuples known
belong R.
Literals appear body clause restricted requirement
programs function-free, constants appearing equalities. possible
literal forms foil considers are:

Q(X1 ; X2 ; :::; Xk ) (Q(X1 ; X2 ; :::; Xk )), Q relation Xi's de-

note known variables bound earlier clause new variables.
least one variable must bound earlier partial clause, either
head literal body.

Xi =Xj Xi 6=Xj , known variables Xi Xj type.
Xi =c Xi6=c, Xi known variable c constant appropriate

type. constants designated suitable appear definition
considered { reasonable definition append might reference null list [ ]
arbitrary list [1,2].

Xi Xj , Xi > Xj , Xi t, Xi > t, Xi Xj known variables
numeric values threshold chosen foil.

learned definition must pure Prolog, negated literal forms (Q(:::)) Xi 6=...
excluded option.
Clause construction guided different possible bindings variables partial
clause satisfy clause body. clause contains k variables, binding k-tuple
constants specifies value variables sequence. possible binding
labelled according whether tuple values variables clause head
belong target relation.
illustration, consider tiny task constructing definition plus(A,B,C),
meaning A+B = C, using background relation dec(A,B), denoting B = A,1.
vocabulary restricted integers 0, 1, 2, plus consists tuples

h0,0,0i, h1,0,1i, h2,0,2i, h0,1,1i, h1,1,2i, h0,2,2i
dec contains h1,0i h2,1i.
initial clause consists head
plus(A,B,C) :-

variable unique. labelled bindings corresponding initial partial
clause tuples belong, belong, target relation, i.e.:

h0,0,0i
h0,0,1i
h1,0,0i
h1,2,2i
h2,2,0i

h1,0,1i
h0,0,2i
h1,0,2i
h2,0,0i
h2,2,1i

h2,0,2i
h0,1,0i
h1,1,0i
h2,0,1i
h2,2,2i

h0,1,1i
h0,1,2i
h1,1,1i
h2,1,0i

143

h1,1,2i
h0,2,0i
h1,2,0i
h2,1,1i

h0,2,2i
h0,2,1i
h1,2,1i
h2,1,2i

.

fiQuinlan

foil repeatedly tries construct clause covers tuples target relation

R tuples definitely R. restated finding clause

bindings bindings, one reason adding literal clause
move direction increasing relative proportion bindings. gainful
literals evaluated using information-based heuristic. Let number
bindings partial clause n n respectively. average information provided
discovery one bindings label
!
n


(n ; n ) = , log2 n + n bits.
literal L added, bindings may excluded rest give
rise one bindings new partial clause. Suppose k n bindings
excluded L, numbers bindings new partial clause
respectively. L chosen increase proportion bindings, total
information gained adding L

k (I (n; n ) , (m ; )) bits.
Consider result specializing clause addition literal A=0.
nine bindings eliminated corresponding values variables
satisfy new partial clause. bindings reduced

h0,0,0i h0,1,1i h0,2,2i
h0,0,1i h0,0,2i h0,1,0i h0,1,2i h0,2,0i h0,2,1i
proportion bindings increased 6/27 3/9. information
gained adding literal therefore 3 (I (6; 21) , (3; 6)) 2 bits. Adding
literal B=C excludes bindings, giving complete first clause
plus(A,B,C) :- A=0, B=C.

or, would commonly written,
plus(0,B,B).

clause covers three tuples plus removed set tuples
covered subsequent clauses. commencement search second clause,
head plus(A,B,C) bindings

h1,0,1i
h0,0,1i
h1,0,0i
h1,2,2i
h2,2,0i

h2,0,2i
h0,0,2i
h1,0,2i
h2,0,0i
h2,2,1i

h1,1,2i
h0,1,0i h0,1,2i h0,2,0i h0,2,1i
h1,1,0i h1,1,1i h1,2,0i h1,2,1i
h2,0,1i h2,1,0i h2,1,1i h2,1,2i
h2,2,2i
.

literals added body first clause gain information. quite different justification adding literal introduce new variables
may needed final clause. Determinate literals based idea introduced
144

fiLearning First-Order Definitions Functions

Golem (Muggleton Feng, 1992). determinate literal one introduces new
variables new partial clause exactly one binding binding
current clause, one binding binding. Determinate literals useful introduce new variables, neither reduce potential coverage
clause increase number bindings.
bindings include A=0, literal dec(A,D) determinate
because, value A, one value satisfies literal. Similarly, since
bindings contain none C=0, literal dec(C,E) determinate.
Figure 1, literals L added foil step

literal greatest gain, gain near maximum possible
(namely n (n ; n )) ; otherwise
determinate literals found; otherwise
literal highest positive gain; otherwise
first literal investigated introduces new variable.
start second clause, literal near-maximum gain determinate
literals added clause body. partial clause
plus(A,B,C) :- dec(A,D), dec(C,E),

five variables bindings satisfy

h1,0,1,0,0i h2,0,2,1,1i h1,1,2,0,1i
h1,0,2,0,1i h1,1,1,0,0i h2,0,1,1,0i h2,1,1,1,0i h2,1,2,1,1i
literal plus(B,D,E), uses newly-introduced variables, satisfied
three bindings none bindings, giving complete second clause
plus(A,B,C) :- dec(A,D), dec(C,E), plus(B,D,E).

tuples plus covered one clauses, constitute complete
intensional definition target relation.

3.2 Details omitted
foil good deal complex overview would suggest. Since

important paper, matters following discussed here,
covered (Quinlan Cameron-Jones, 1993; 1995):

Recursive soundness. goal able execute learned definitions

ordinary Prolog programs, important terminate. foil elaborate
mechanism ensure recursive literal (such plus(B,D,E) above)
added clause body cause problems respect, least ground
queries.
145

fiQuinlan

Pruning. practical applications numerous background relations, number

possible literals L could added step grows exponentially
number variables partial clause. foil employs heuristics limit
space, Golem's bound depth variable (Muggleton Feng,
1992). importantly, regions literal space pruned without
examination shown contain neither determinate literals,
literals higher gain best gainful literal found far.
complete search. presented above, foil straightforward greedy hillclimbing algorithm. fact, foil sometimes reach impasse
search clause, contains limited non-chronological backtracking facility
allow recover situations.
Simplifying definitions. addition partial clause determinate literals
found may seem excessive. However, clause completed, foil examines
literal clause body see whether could discarded without causing
simpler clause match tuples target relation R. Similarly,
definition complete, clause checked see whether could omitted
without leaving tuples R uncovered. heuristics aim
make clauses understandable substituting simpler literals (such variable
equalities) literals based complex relations.
Recognizing boundaries closed worlds. literals appear discriminate
bindings consequence boundary effects attributable
limited vocabulary.3 definition including literals executed larger
vocabularies, open domain assumption mentioned may violated. foil
contains optional mechanism describing literals might satisfied
bindings outside closed world, allowing literals unpredictable behavior
excluded.
Quinlan (1990) Quinlan Cameron-Jones (1995) summarize several applications
successfully addressed foil, discussed Section 5.

4. Learning Functional Relations
learning approach used foil makes assumptions form target

relation R. However, append plus above, relation often used represent
function { tuple constants satisfies R, last constant uniquely determined
others. Bergadano Gunetti (1993) show property exploited
make learning task tractable.

4.1 Functional relations foil
Although foil learn definitions functional relations, handicapped two ways:
Ground queries: foil's approach recursive soundness assumes ground
queries made learned definition. is, definition R(X1 ; X2 ; :::; Xn )

3. example arises Section 5.1.

146

fiLearning First-Order Definitions Functions

used provide true-false answers queries form R(c1 ; c2 ; :::; cn )?
ci 's constants. R functional relation, however, sensible query
would seem R(c1 ; c2 ; :::; cn,1 ; X )? determine value function
specified ground arguments. case plus, instance, would expect ask plus(1,1,2)? (\is 1+1=2?"), rather plus(1,1,X)? (\what 1+1?").
R(c1 ; c2 ; :::; cn,1 ; X )? called standard query functional relations.
Negative examples: foil needs tuples belong target relation
least not. common ILP systems Golem (Muggleton
Feng, 1992), latter used detect partial clause still general.
specified foil directly or, commonly, derived
closed world assumption that, respect vocabulary, tuples R
given. second mechanism often lead large collections tuples
R; nearly 64,000 append illustration earlier. Every
tuple belonging R results binding start clause,
uncomfortably many bindings must maintained tested stage
clause development.4 However, functional relations need explicit counterexamples, even set tuples belonging R complete respect
vocabulary { knowing hc1 ; c2 ; :::; cn belongs R implies
constant c0n hc1 ; c2 ; :::; c0n R.
problematic aspects foil vis vis functional relations suggest modifications
address them. alterations lead new system, ffoil, still close spirit
progenitor.

4.2 Description ffoil

Since last argument functional relation special role, referred
output argument relation. Similarly, variable corresponding argument
head clause called output variable.
fundamental change ffoil concerns bindings partial clauses
way labelled. new constant 2 introduced indicate undetermined
value output variable binding. Bindings labelled according value
output variable, namely value correct (given value earlier
constants), value incorrect, value undetermined.
outline ffoil (Figure 2) similar Figure 1, differences
highlighted. start clause one binding every remaining tuple
target relation. output variable value 2 bindings value
changed subsequent literal assigns value variable. small
plus example Section 3.1, initial bindings first clause
h0,0,2i h1,0,2i h2,0,2i h0,1,2i h1,1,2i h0,2,2i
ancestor, ffoil assesses potential literals adding clause body
gainful determinate, although concepts must adjusted accommodate new
label fi. Suppose r distinct constants range target function.
4. reason, foil includes option sample bindings instead using them.

147

fiQuinlan

Initialization:
definition := null program
remaining := tuples belonging target relation R
remaining empty
/* Grow new clause */
clause := R(A; B; :::) :While clause bindings
/* Specialize clause */
Find appropriate literal(s) L
Add L body clause
Remove remaining tuples R covered clause
Add clause definition
Simplify final definition
Add default clause
Figure 2: Outline ffoil

binding converted binding changing 2 correct value
function, binding changing 2 r , 1 incorrect values.
computing information gain, ffoil thus counts binding 1 binding r , 1
bindings. determinate literal one introduces one variables that,
new partial clause, exactly one binding current binding
one binding current binding. ffoil uses preference criterion
adding literals L: literal near-maximum gain, determinate literals,
gainful literal, finally non-determinate literal introduces new variable.
first literal chosen foil Section 3.1 A=0 since increases concentration bindings 9 64 3 9 (with corresponding information gain).
ffoil's perspective, however, literal simply reduces six bindings three gives
gain; range plus set f0,1,2g, r = 3, putative concentration
bindings would alter 6 18 3 9. literal A=C, hand, causes
value output variable determined results bindings

h0,0,0i h1,0,1i h2,0,2i
h0,1,0i h1,1,1i h0,2,0i .
corresponds increase concentration bindings notional 6 18

3 6, information gain 2 bits. literal added
clause body, ffoil finds literal B=0 eliminates bindings, giving
148

fiLearning First-Order Definitions Functions

complete clause
plus(A,B,C) :- A=C, B=0.

remaining tuples plus give bindings

h0,1,2i h1,1,2i h0,2,2i
start second clause. literals dec(B,D) dec(E,A) determinate
and, added clause, bindings become

h0,1,2,0,1i h1,1,2,0,2i h0,2,2,1,1i
output variable still undetermined. partial clause specialized
adding literal plus(E,D,C), new bindings

h0,1,1,0,1i h1,1,2,0,2i h0,2,2,1,1i
give correct value C case. Since bindings, clause

complete.
One important consequence new way bindings initialized start
clause easily overlooked. foil, one binding tuple
belong R; since clause excludes bindings, discriminates tuples
R tuples R. reason learned clauses regarded
set executed order without changing set answers query.
ffoil, however, initial bindings concern remaining tuples R, learned
clause depends context established earlier clauses. example, suppose target
relation background relation defined
= fhv,1i, hw,1i, hx,1i, hy,0i, hz,0ig
= fhvi, hwi, hxig .

first clause learned ffoil might
S(A,1) :- T(A).

remaining bindings fhy,0i, hz,0ig could covered clause
S(A,0).

latter clause clearly correct standard queries covered
first clause. example illustrates, learned clauses must interpreted order
learned, clause must ended cut `!' protect later
clauses giving possibly incorrect answers query. Since target relation R
functional, one correct response standard query defined above,
use cuts safe cannot rule correct answer.
foil ffoil tend give easily learning definitions explain noisy
data. result over-specialized clauses cover target relation partially.
tasks definition learned ffoil incomplete, final global simplification
149

fiQuinlan

phase invoked. Clauses definition generalized removing literals long
total number errors target relation increase. way, accuracy
individual clauses balanced accuracy definition whole; simplifying
clause removing literal may increase number errors made clause,
offset reduction number uncovered bindings consequently
lower global error rate. clauses simplified much possible, entire
clauses contribute nothing accuracy definition removed.
final step Figure 2, target relation assumed represent total function,
consequence response must always returned standard query.
safeguard, ffoil adds default clause

R(X1 ; X2 ; :::; Xn,1 ; c):
c common value function.5 common value output
argument plus 2, complete definition example, normal Prolog notation,
becomes
plus(A,0,A) :- !.
plus(A,B,C) :- dec(B,D), dec(E,A), plus(E,D,C), !.
plus(A,B,2).

4.3 Advantages disadvantages ffoil

Although definitions plus Sections 3.1 4.2 superficially similar,
considerable differences learning processes constructed
operational characteristics used.

ffoil generally needs maintain fewer bindings learns quickly. Whereas

foil keeps 27 bindings learning definition plus, ffoil never uses
6.

output variable guaranteed bound every clause learned ffoil.
necessarily case foil, since requirement every variable
appearing head must appear clause body.

Definitions found ffoil often execute eciently foil counterparts.

Firstly, ffoil definitions, use cuts, exploit fact cannot
one correct answer standard query. Secondly, clause bodies constructed
ffoil tend use output variable bound, less
backtracking evaluation. illustration, foil definition Section
3.1 evaluates 81 goals answering query plus(1,1,X)?, many six
evaluations needed ffoil definition query.

entries side ledger:
5. default clause added value function occurs once.

150

fiLearning First-Order Definitions Functions

Task

Bkgd
Relns

append
last element
reverse
left shift
translate

2
3
10
12
14

Length 3
Bindings
Time





foil ffoil

142 63,858
3.0
39
81
0.0
40 1560
2.6
39 1561
0.5
40 3120 817.9

Length 4
Bindings
Time





foil ffoil

0.5 1593 396,502 22.4
0.0 340
1024
0.5
0.3 341 115,940 195.9
0.3 340 115,940 26.6
1.1 341 115,940 495.9

10.9
0.3
9.0
6.8
28.0

Table 1: Results tasks (Bratko, 1990).

foil applicable learning tasks ffoil, limited learning
definitions functional relations.

implementation ffoil complex foil. example, many

heuristics pruning literal search space checking recursive soundness
require special cases constant 2 bindings.

5. Empirical Trials

section performance ffoil variety learning tasks summarized
compared foil (release 6.4). Since systems similar respects,
comparison highlights consequences restricting target relation function.
Times DEC AXP 3000/900 workstation. learned definitions first
three subsections may found Appendix.

5.1 Small list manipulation programs

Quinlan Cameron-Jones (1993) report results applying foil 16 tasks taken
Bratko's (1990) well-known Prolog text. list-processing examples exercises
Chapter 3 attempted sequence, background information task
includes previously-encountered relations (even though irrelevant
task hand). Two different vocabularies used: 40 lists length 3
three elements 341 lists length 4 four elements.
Table 1 describes five functional relations set presents performance
foil ffoil them. learned definitions correct arbitrary lists,
one exception { foil's definition reverse learned larger vocabulary includes
clause
reverse(A,A) :- append(A,A,C), del(D,E,C).

exploits bounded length lists.6 times reveal considerable advantage
6. C twice length E one element longer C still length 4,
length must 0 1. case reverse.

151

fiQuinlan

Task
foil ffoil
quicksort
4.7
2.2
bubblesort 7.3
0.4
Table 2: Times (sec) learning sort.

[3,3]
0.7
0.8
Golem 4.8
Progol 43.0

ffoil
foil

Time (secs)
Ratio [3,3]
[3,4] [4,4]
[4,5] [3,4] [4,4]
[4,5]
1.5
4.5
15.0 2.1
6.4
21.4
4.3
11.9
146.3 5.4 14.9
182.9
14.6
59.6
>395 3.0 12.4 >82.3
447.9 5271.9 >76575 10.4 122.6 >1780.8

Table 3: Comparative times quicksort task.

ffoil tasks except second. fact, first last task larger
vocabulary, times understate ffoil's advantage. total number bindings
append 3413 , 40 million, foil option used sample 1%
bindings prevent foil exceeding available memory. possible run foil

bindings, time required learn definition would considerably
longer. Similarly, foil exhausted available memory translation task 232,221
possible bindings used, results obtained using sample 50%
bindings.

5.2 Learning quicksort bubblesort
tasks concern learning sort lists examples sorted lists. first,
target relation qsort(A,B) means B sorted form A. Three background
relations provided: components append before, partition(A,B,C,D), meaning
partitioning list B value gives list C elements less list
elements greater A. second task, background relations learning
bsort(A,B) components lt(A,B), meaning A<B. vocabulary used tasks
lists length 4 non-repeated elements drawn f1,2,3,4g.
thus 65 4160 bindings task.
foil ffoil learn \standard" definition quicksort. Times shown Table
2 comparable, mainly ffoil learns super uous over-specialized clause
later discarded favor general recursive clause. outcome bubblesort
quite different { ffoil learns twenty times faster foil definition
verbose.
quicksort task provides opportunity compare ffoil two wellknown relational learning systems. ffoil foil, Golem (Muggleton
152

fiLearning First-Order Definitions Functions

Task
foil ffoil
Ackermann's function
12.3
0.2
greatest common divisor 237.5
1.2
Table 4: Times (sec) arithmetic functions.

Feng, 1992) Progol (release 4.1) (Muggleton, 1995) implemented C,
timing comparisons meaningful. Furthermore, systems include quicksort among
demonstration learning tasks, reasonable assume parameters
control systems set appropriate values.
four learning systems evaluated using four sets training examples, obtained
varying maximum length lists size alphabet nonrepeating elements appear lists, (Quinlan, 1991). Denoting set
pair [S ,A], four datasets [3,3], [3,4], [4,4], [4,5]. total numbers
possible bindings tasks, 256, 1681, 4225, 42,436 respectively, span two orders
magnitude. Table 3 summarizes execution times7 required systems
datasets. Neither Golem Progol completed last task; Golem exhausted available
swap space 60Mb, Progol terminated using nearly day cpu time.
table shows ratio execution time latter three simplest dataset
[3,3]. growth ffoil's execution time far slower systems,
primarily ffoil needs tuples others use tuples.
Golem's execution time seems grow slightly slower foil's, Progol's growth
rate much higher.

5.3 Arithmetic functions

systems used learn definitions complex functions arithmetic.
Ackermann's function
8
>
= 0
< n+1
f (m; n) = > f (m , 1; 1)
n = 0
: f (m , 1; f (m; n , 1)) otherwise
provides testing example recursion control; background relation succ(A,B) represents B=A+1. Finding greatest common divisor two numbers another interesting
task; background relation plus. tasks vocabulary consists integers
0 20 1 20 respectively, giving 51 tuples Ackermann(A,B,C) A, B
C less equal 20, 400 tuples gcd(A,B,C).
shown Table 4, ffoil 60 times faster foil learning definition
Ackermann 200 times faster gcd. due solely ffoil's smaller
numbers bindings. gcd, example, foil starts 203 8,000 bindings whereas
ffoil never uses 400 bindings.
7. Diculties experienced running Golem AXP 3000/900, times table
DECstation 5000/260.

153

fiQuinlan

foil ffoil learn exactly program Ackermann's function
mirrors definition above. case gcd, however, definitions highlight
potential simplification achievable ordered clauses. definition found foil
gcd(A,A,A).
gcd(A,B,C) :- plus(B,D,A), gcd(B,A,C).
gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C).

learned ffoil (omitting default clause)
gcd(A,A,A) :- !.
gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C), !.
gcd(A,B,C) :- gcd(B,A,C), !.

last clause exploits fact cases less equal B
filtered first two clauses.

5.4 Finding past tense English verbs
previous examples concerned tasks compact, correct definition
known exist. application, learning change English verb phonetic
notation present past tense, real-world avor totally correct
definition would extremely complex. considerable literature built around
task, starting connectionist community, moving symbolic learning
work Ling (1994), relational learning (Quinlan, 1994; Mooney Califf, 1995).
Quinlan (1994) proposes representing task relation past(A,B,C), interpreted
past tense verb formed stripping ending B adding string C.
single background relation split(A,B,C) shows ways word split two
non-empty substrings B C. Following experiment reported (Ling, 1994), corpus
1391 verbs used generate ten randomly-selected learning tasks, containing 500
verbs definition learned 500 different verbs used test definition.
Prolog interpreter used evaluate definitions learned foil, unseen word
w mapped test query past(w,X,Y)?. result query judged correct
X bound proper strings. multiple responses
query, first used { disadvantages foil somewhat, since system
attempt reorder learned clauses maximum accuracy single-response queries.
average accuracy definitions found foil 83.7%.
apply ffoil task, relation past(A,B,C) must factored two functional
relations delete(A,B) add(A,C) since ffoil currently learn functions
single output variable. training test sets verbs used, giving rise
two separate learning tasks, test judged correct delete add
give correct results unseen verb. definitions learned ffoil higher
average accuracy 88.9%; ten trials, ffoil outperforms foil nine inferior
one, difference significant 1% level using one-tailed sign test.
average time required ffoil learn pair definitions, approximately 7.5 minutes,
somewhat less time taken foil learn single definition.
154

fiLearning First-Order Definitions Functions

Object Edges

B
C

E
Total

54
42
28
57
96
277

Correct

Time (sec)

foil ffoil mfoil Golem fors foil ffoil

16
21
22
17
22
2.5
9
15
12
9
12
1.7
8
11
9
5
8
3.3
10
22
6
11
16
2.4
16
54
10
10
29
4.7
59
123
59
52
87 14.6
(21%) (44%) (21%) (19%) (31%)

9.1
11.0
9.7
11.1
5.9
46.8

Table 5: Cross-validation results finite element mesh data.

5.5 Finite element mesh design
application, first discussed Dolsak Muggleton (1992), concerns division
object appropriate number regions finite element simulation. edge
object cut number intervals task learn determine suitable
number { fine division requires excessive computation simulation,
coarse partitioning results poor approximation object's true behavior.
data concern five objects total 277 edges. target relation mesh(A,B)
specifies edge number intervals B recommended expert, ranging
1 12. Thirty background relations describe properties edge, shape
topological relationship edges object. Five trials conducted,
information one object withheld, definition learned edges
remaining objects, definition tested edges omitted object.
Table 5 shows, trial, number edges definitions learned
foil ffoil predict number intervals specified expert. Table 5 shows
published results mesh task three relational learning systems. numbers
edges mfoil Golem predict correct number intervals taken
(Lavrac Dzeroski, 1994). general relational learning systems foil,
fors (Karalic, 1995), ffoil, specialized learning functional relations
kind. Since general relational learning systems could return multiple answers
query mesh(e,X)? edge e, first answer used; puts disadvantage
respect foil fors accounts least part lower accuracy. Using
one-tailed sign test 5% level, ffoil's accuracy significantly higher
achieved foil Golem, differences significant.
time required ffoil domain approximately three times used
foil. turnabout caused ffoil's global pruning phase, requires many literal
eliminations order maximize overall accuracy training data. one ply
cross-validation, instance, initial definition, consisting 30 clauses containing 64
body literals, fails cover 146 249 given tuples target relation mesh.
global pruning, however, final definition 9 clauses 15 body literals,
makes 101 errors training data.
155

fiQuinlan

6. Related Research

Mooney Califf's (1995) recent system Foidl strong uence development ffoil. Three features together distinguish Foidl earlier systems
foil are:

Following example focl (Pazzani Kibler, 1992), background relations

defined intensionally programs rather extensionally tuple sets.
eliminates problem applications complete extensional definition
background relations would impossibly large.

Examples tuples belong target relation needed. Instead,
argument target relation mode Foidl assumes output
completeness, i.e., tuples relation show valid outputs inputs
appear.

learned definition ordered every clause ends cut.
Output completeness weaker restriction functionality since may several
correct answers standard query R(c1 ; c2 ; :::; cn,1 ; X )?. However, fact
clause ends cut reduces exibility somewhat, since answers query must
generated single clause.
Although Foidl ffoil learn ordered clauses cuts,
different ways. ffoil learns clause, sequence clauses cover remaining
tuples, first clause definition first clause learned. Foidl instead
follows Webb Brkic (1993) learning last clause first, prepending sequence
clauses filter exceptions learned clause. strategy advantage
general rules learned first still act defaults clauses cover
specialized situations.
principal differences Foidl ffoil thus use intensional versus
extensional background knowledge order clauses learned.
subsidiary differences { example, Foidl never manipulates bindings explicitly
estimates number syntactically. However, many ways ffoil may viewed
intermediate system lying mid-way foil Foidl.
Foidl motivated past tense task described Section 5.4, performs
extremely well it. formulation task Foidl uses relation past(A,B)
indicate B past tense verb A, together intensional background
relation split(S,H,T) denote possible ways dividing string substrings H
T. Definitions learned Foidl compact intelligible, slightly higher
accuracy (89.3%) ffoil's using ten sets training test examples.
interesting see systems compare applications.
Bergadano Gunetti (1993) first pointed advantages learning systems
restricting relations functions. filp system assumes relations, target
background, functional, although allow functions multiple outputs.
assumption greatly reduces number literals considered specializing clause,
leading shorter learning times. (On hand, many tasks discussed
previous section involve non-functional background relations would satisfy filp's
156

fiLearning First-Order Definitions Functions

functionality assumption.) theory, filp requires oracle answer non-ground
queries regarding unspecified tuples target background relations, although
would required relevant tuples provided initially. filp guarantees
learned definition completely consistent given examples, inappropriate
noisy domains discussed Sections 5.4 5.5.
contrast ffoil Foidl, definitions learned filp consist unordered
sets clauses, despite fact target relation known functional.
prevents clause exploiting context established earlier clauses. gcd task
(Section 5.3), definition learned filp would require bodies second
third clauses include literal plus(...,...,...). domains past tense task,
complexity definitions learned ffoil Foidl would greatly increased
constrained unordered clauses.

7. Conclusion
study, mature relational learning system modified customize
functional relations. fact specialized ffoil performs much better
general foil relations kind lends support Bergadano Gunetti's
(1993) thesis functional relations easier learn. interesting speculate
similar improvement might well obtainable customizing general first-order
systems Progol (Muggleton, 1995) learning functional relations.
Results quicksort experiments suggest ffoil scales better general
first-order systems learning functional relations, past tense
mesh design experiments demonstrate effectiveness noisy domains.
Nevertheless, hoped improve ffoil several ways. system
extended multifunctions one output variable, permitted
filp Foidl. Secondly, many real-world tasks Sections 5.4 5.5
result definitions output variable usually bound equated
constant rather appearing body literal. applications, ffoil heavily
biased towards constructing next clause cover frequent function value
remaining tuples, binding tends highest gain. time
clause specialized exclude exceptions, however, end covering
tuples relation. special cases could filtered first, clauses
would simpler would cover tuples target relation. better learning
strategy situations would seem grow new clause every function value
uncovered tuples, retain one greatest coverage discard rest.
would involve increase computation lead better, concise
definitions.
Although conceptual changes moving foil ffoil relatively slight,
effects code level substantial (with three 19 files make
foil escaping modification). result decided preserve separate
systems, rather incorporating ffoil option foil. available (for
academic research purposes) anonymous ftp ftp.cs.su.oz.au, directory pub, file names
foil6.sh ffoil2.sh.
157

fiQuinlan

Acknowledgements
research made possible grant Australian Research Council. Thanks
William Cohen, Ray Mooney, Michael Pazzani, anonymous reviewers comments helped improve paper.

Appendix: Learned Definitions
definition learned foil appears left ffoil right.
latter's default clauses irrelevant tasks, omitted.

List processing functions (Section 5.1)
(a) Using lists length 3:
append([ ],B,B).
append(A,B,C) :- components(A,D,E),
components(C,D,F), append(E,B,F).
last(A,B) :- components(A,B,[ ]).
last(A,B) :- components(A,C,D), last(D,B).
reverse(A,A) :- append(A,C,D),
components(D,E,A).
reverse(A,B) :- last(A,C), last(B,D),
components(A,D,E),
components(B,C,F), reverse(E,G),
del(D,B,G).
shift(A,B) :- components(A,C,D), del(C,B,D),
append(D,E,B).
translate([ ],[ ]).
translate(A,B) :- components(A,C,D),
components(B,E,F), translate(D,F),
means(C,E).

append([ ],B,B) :- !.
append(A,B,C) :- components(A,D,E),
append(E,B,F), components(C,D,F), !.
last(A,B) :- components(A,C,D), last(D,B), !.
last(A,B) :- member(B,A), !.
reverse(A,A) :- append(A,C,D),
components(D,E,A), !.
reverse(A,B) :- components(A,C,D),
reverse(D,E), append(F,D,A),
append(E,F,B).

append([ ],B,B).
append(A,B,C) :- components(A,D,E),
components(C,D,F), append(E,B,F).
last(A,B) :- components(A,B,[ ]).
last(A,B) :- components(A,C,D), last(D,B).
reverse(A,A) :- append(A,A,C), del(D,E,C).
reverse(A,B) :- components(A,C,D),
reverse(D,E), append(F,D,A),
append(E,F,B).

append([ ],B,B) :- !.
append(A,B,C) :- components(A,D,E),
append(E,B,F), components(C,D,F), !.
last(A,B) :- components(A,C,D), last(D,B), !.
last(A,B) :- member(B,A), !.
reverse(A,A) :- append(A,C,D),
components(D,E,A), !.
reverse(A,B) :- components(A,C,D),
reverse(D,E), append(F,D,A),
append(E,F,B).
shift(A,B) :- components(A,C,D),
append(E,D,A), append(D,E,B).

shift(A,B) :- components(A,C,D),
append(E,D,A), append(D,E,B).
translate([ ],[ ]) :- !.
translate(A,B) :- components(A,C,D),
translate(D,E), means(C,F),
components(B,F,E).

(b) Using lists length 4:

shift(A,B) :- components(A,C,D), del(C,B,D),
append(D,E,B).

158

fiLearning First-Order Definitions Functions

translate([ ],[ ]).
translate(A,B) :- components(A,C,D),
components(B,E,F), translate(D,F),
means(C,E).

translate([ ],[ ]) :- !.
translate(A,B) :- components(A,C,D),
translate(D,E), means(C,F),
components(B,F,E).

Quicksort bubblesort (Section 5.2)
qsort([ ],[ ]).
qsort(A,B) :- components(A,C,D),
partition(C,D,E,F), qsort(E,G),
qsort(F,H), components(I,C,H),
append(G,I,B).
bsort([ ],[ ]).
bsort(A,A) :- components(A,C,[ ]).
bsort(A,B) :- components(A,C,D),
components(B,C,E), bsort(D,E),
components(E,F,G), lt(C,F).
bsort(A,B) :- components(A,C,D),
components(B,E,F), bsort(D,G),
components(G,E,H), lt(E,C),
components(I,C,H), bsort(I,F).

qsort([ ],[ ]) :- !.
qsort(A,B) :- components(A,C,D),
partition(C,D,E,F), qsort(E,G),
qsort(F,H), components(I,C,H),
append(G,I,B), !.
bsort([ ],[ ]) :- !.
bsort(A,A) :- components(A,C,[ ]), !.
bsort(A,B) :- components(A,C,D), bsort(D,E),
components(E,F,G),
components(B,C,E), lt(C,F), !.
bsort(A,B) :- components(A,C,D), bsort(D,E),
components(E,F,G),
components(D,H,I),
components(J,C,I), bsort(J,K),
components(B,F,K), !.
bsort(A,B) :- components(A,C,D), bsort(D,E),
components(F,C,E), bsort(F,B), !.

Arithmetic functions (Section 5.3)
Ackermann(0,B,C) :- succ(B,C).
Ackermann(A,0,C) :- succ(D,A),
Ackermann(D,1,C).
Ackermann(A,B,C) :- succ(D,A), succ(E,B),
Ackermann(A,E,F),
Ackermann(D,F,C).
gcd(A,A,A).
gcd(A,B,C) :- plus(B,D,A), gcd(B,A,C).
gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C).

Ackermann(0,B,C) :- succ(B,C), !.
Ackermann(A,0,C) :- succ(0,D), succ(E,A),
Ackermann(E,D,C), !.
Ackermann(A,B,C) :- succ(D,A), succ(E,B),
Ackermann(A,E,F),
Ackermann(D,F,C), !.
gcd(A,A,A) :- !.
gcd(A,B,C) :- plus(A,D,B), gcd(A,D,C), !.
gcd(A,B,C) :- gcd(B,A,C), !.

References

Bell, S., & Weber, S. (1993). close logical relationship foil frameworks Helft Plotkin. Proceedings Third International Workshop Inductive
Logic Programming, Bled, Slovenia, pp. 127{147.
Bergadano, F., & Gunetti, D. (1993). interactive system learn functional logic programs. Proceedings Thirteenth International Joint Conference Artificial Intelligence, Chambery, France, pp. 1044{1049. San Francisco: Morgan Kaufmann.
Bratko, I. (1990). Prolog Programming Artificial Intelligence (2nd edition). Wokingham,
UK: Addison-Wesley.
159

fiQuinlan

Cameron-Jones, R. M., & Quinlan, J. R. (1994). Ecient top-down induction logic
programs. SIGART, 5, 33{42.
De Raedt, L. (Ed.). (1996). Advances Inductive Logic Programming. Amsterdam: IOS
Press.
Dolsak, B., & Muggleton, S. (1992). application inductive logic programming
finite element mesh design. Muggleton, S. (Ed.), Inductive Logic Programming, pp.
453{472. London: Academic Press.
Karalic, A. (1995). First Order Regression. Ph.D. thesis, Faculty Electrical Engineering
Computer Science, University Ljubljana, Slovenia.
Langley, P., & Simon, H. A. (1995). Applications machine learning rule induction.
Communications ACM, 38 (11), 55{64.
Lavrac, N., & Dzeroski, S. (1994). Inductive Logic Programming. London: Ellis Horwood.
Ling, C. X. (1994). Learning past tense english verbs: symbolic pattern associator
versus connectionist models. Journal Artificial Intelligence Research, 1, 209{229.
Michie, D., Spiegelhalter, D. J., & Taylor, C. C. (Eds.). (1994). Machine Learning, Neural
Statistical Classification. Hertfordshire, UK: Ellis Horwood.
Mooney, R. J., & Califf, M. E. (1995). Induction first-order decision lists: results
learning past tense english verbs. Journal Artificial Intelligence Research, 3,
1{24.
Muggleton, S. (Ed.). (1992). Inductive Logic Programming. London: Academic Press.
Muggleton, S. (1995). Inverse entailment progol. New Generation Computing, 13,
245{286.
Muggleton, S., & Feng, C. (1992). Ecient induction logic programs. Muggleton, S.
(Ed.), Inductive Logic Programming, pp. 281{298. London: Academic Press.
Muggleton, S., King, R. D., & Sternberg, M. J. (1992). Protein secondary structure prediction using logic-based machine learning. Protein Engineering, 5, 646{657.
Pazzani, M. J., & Kibler, D. (1992). utility knowledge inductive learning. Machine
Learning, 9, 57{94.
Quinlan, J. R. (1990). Learning logical definitions relations. Machine Learning, 5,
239{266.
Quinlan, J. R. (1991). Determinate literals inductive logic programming. Proceedings
Twelfth International Joint Conference Artificial Intelligence, Sydney, pp. 746{750.
San Francisco: Morgan Kaufmann.
Quinlan, J. R. (1994). Past tenses verbs first-order learning. Proceedings AI'94
Seventh Australian Joint Conference Artificial Intelligence, Armidale, Australia,
pp. 13{20. Singapore: World Scientific.
160

fiLearning First-Order Definitions Functions

Quinlan, J. R., & Cameron-Jones, R. M. (1993). Foil: midterm report. Proceedings European Conference Machine Learning, Vienna, pp. 3{20. Berlin: Springer-Verlag.
Quinlan, J. R., & Cameron-Jones, R. M. (1995). Induction logic programs: foil
related systems. New Generation Computing, 13, 287{312.
Rouveirol, C. (1994). Flattening saturation: two representation changes generalization. Machine Learning, 14, 219{232.
Srinivasan, A., Muggleton, S. H., Sternberg, M. J. E., & King, R. D. (1996). Theories
mutagenicity: study first-order feature-based induction. Artificial Intelligence, 84, 277{299.
Ullman, J. D. (1988). Principles Database Knowledge-Base Systems. Rockville, MD:
Computer Science Press.
Webb, G. I., & Brkic, N. (1993). Learning decision lists prepending inferred rules. Proceedings Australian Workshop Machine Learning Hybrid Systems, Melbourne,
Australia, pp. 6{10.
Zelle, J. M., & Mooney, R. J. (1993). Combining foil ebg speed-up logic programs.
Proceedings Thirteenth International Joint Conference Artificial Intelligence,
Chambery, France, pp. 1106{1111. San Francisco: Morgan Kaufmann.

161


