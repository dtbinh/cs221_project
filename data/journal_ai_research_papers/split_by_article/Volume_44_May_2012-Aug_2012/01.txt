Journal of Artificial Intelligence Research 44 (2012) 97-140

Submitted 2/2012; published 5/2012

Solving Limited Memory Influence Diagrams
Denis Deratani Maua
Cassio Polpo de Campos
Marco Zaffalon

denis@idsia.ch
cassio@idsia.ch
zaffalon@idsia.ch

Istituto Dalle Molle di Studi sullIntelligenza Artificiale (IDSIA)
Galleria 2, Manno, 6928 Switzerland

Abstract
We present a new algorithm for exactly solving decision making problems represented as
influence diagrams. We do not require the usual assumptions of no forgetting and regularity;
this allows us to solve problems with simultaneous decisions and limited information. The
algorithm is empirically shown to outperform a state-of-the-art algorithm on randomly
generated problems of up to 150 variables and 1064 solutions. We show that these problems
are NP-hard even if the underlying graph structure of the problem has low treewidth and
the variables take on a bounded number of states, and that they admit no provably good
approximation if variables can take on an arbitrary number of states.

1. Introduction
Influence diagrams (Howard & Matheson, 1984) are graphical models aimed at the representation of problems of decision making under uncertainty. Traditionally, they are designed
to handle situations involving a single, non-forgetful decision maker. Limited memory influence diagrams (hereafter LIMIDs) are generalizations of influence diagrams that allow for
decision making with limited information, as in the case of simultaneous decisions, bounded
memory controllers and non-communicating cooperative agents (Zhang, Qi, & Poole, 1994;
Lauritzen & Nilsson, 2001; Poupart & Boutilier, 2003; Detwarasiti & Shachter, 2005). More
precisely, LIMIDs relax the regularity and no forgetting assumptions of influence diagrams,
namely, that there is a complete temporal ordering over the decision variables, and that any
disclosed information (i.e., decisions and observations made) is remembered and considered
for future decisions. These assumptions might not only be hard to meet in some applications, but they might lead to an exponential growth in the size of policies, and consequently
to intractability.
Solving a (limited memory) influence diagram refers to finding an optimal plan of action,
that is, a combination of decision rules, or policies, that associate any possible observation
to an action. Optimality is understood as maximizing expected utility. This task has been
empirically and theoretically shown to be very hard (de Campos & Ji, 2008). In fact, we
show here that solving a LIMID is NP-hard even if we admit only singly connected diagrams
with bounded number of states per variable,1 and that devising an algorithm that produces
provably good approximate solutions within any fixed factor is unlike to exist even for
diagrams of low treewidth.
1. A diagram is singly connected if the underlying (undirected) graph contains no cycles.
2012 AI Access Foundation. All rights reserved.

fiMaua, de Campos, & Zaffalon

Lauritzen and Nilsson (2001) have shown that LIMIDS that satisfy certain graphstructural conditions (which no forgetting and regularity imply) can be solved exactly by
a dynamic programming procedure with complexity exponential in the treewidth. Hence,
solving such LIMIDs is computationally similar to performing probabilistic inference in
Bayesian networks (Koller & Friedman, 2009). In fact, the single policy updating (SPU)
algorithm of Lauritzen and Nilsson (2001) performs a local search in the space of policies
and at each step performs a probabilistic inference to evaluate each candidate solution.
However, many problems fail to meet the conditions necessary for SPU achieving optimality, and in these cases SPU might converge to a local optimum that is much inferior to the
actual (global) optimum. To circumvent this problem, de Campos and Ji (2008) formulated
the credal reformulation (CR) algorithm that maps a LIMID into a mixed integer linear
programming problem. They showed that the CR algorithm is able to solve small problems exactly and to obtain good approximations for medium-sized problems by relaxing the
integrality constraints.
We show in this paper that LIMIDs can be solved exactly by a variable elimination
scheme that simultaneously propagates sets of (partial) solutions. Although the algorithm
runs in exponential time in the worst case (which is just to be expected, as the problem
is NP-hard), we show that for many problem instances it is possible to obtain an optimal
solution efficiently by pruning solutions that are Pareto-dominated by others. At the heart
of the algorithms efficiency is the property that at any moment during variable elimination
local Pareto dominance implies global Pareto dominance, that is, that a partial solution
that is Pareto-dominated by another partial solution cannot be part of an optimal solution,
and hence can be safely discarded. We show experimentally that the pruning of Paretodominated local solutions can enormously save computational resources, and enable us to
compute exact solutions for much bigger problems than previous algorithms. In fact, the
algorithm is orders of magnitude faster than the CR algorithm on randomly generated
diagrams containing up to 150 variables and 1064 strategies.
The paper is organized as follows. Section 2 describes the LIMID formalism and presents
new results about the complexity of solving a LIMID. The variable elimination algorithm
for computing exact solutions is presented in Section 3, and evaluated in Section 4. At last,
Sections 5 and 6 contain related work and a final discussion. To improve readability, some
of the proofs and supporting results are given in the appendix.

2. Limited Memory Influence Diagrams
In this section, we describe the LIMID formalism, state the complexity of solving a LIMID
instance, and show that any LIMID can be transformed into an equivalent (in terms of
maximum expected utility) diagram whose utilities are nonnegative and decision variables
have no parents. Such LIMIDs are the input of our algorithm in the next section. We start
with an example of a decision problem with limited information, which we use throughout
the rest of the paper to illustrate and motivate concepts. Although this example (which
is essentially a team coordination problem) is rather simple, it can easily be extended to
account for more realistic scenarios.
98

fiSolving LIMIDs

2.1 The Fire Dispatching Problem
A particular fire station contains a group of firefighters divided in three units. The fire
dispatcher decides which units to dispatch for each reported accident. Each dispatched
unit costs -1 utile, and units not dispatched cost no utiles. In case of fire, the higher
the number of dispatched teams the higher the chances of minimum damage (which implies
saving lives and preventing third-party financial losses). To make things simple, we consider
that an accident can be handled either appropriately, in which case we say it is a success,
or inappropriately, in which case we say it is a failure. Ideally, the dispatcher wants to
maximize the chance of success while minimizing the number of dispatched teams (and
hence the cost of the operation). A successful operation is rewarded with 7/2 utiles, while
a failure gets zero utiles.
2.2 Variables and Domains
In the formalism of (limited memory) influence diagrams, the quantities and events of
interest are represented by three distinct types of variables or nodes.2 Chance variables
represent events on which the decision maker has no control, such as outcomes of tests or
consequences of actions. Decision variables represent the options available to a decision
maker. Finally, value variables represent additive parcels of the utility associated to a state
of the world. The set of all variables considered relevant for a problem is denoted by U.
Each variable X in U has an associated domain X , which is the finite non-empty set of
values that X can assume. The elements of X are called states. We assume the existence
of the empty domain  , {}, which contains a single element  which is not in any
other domain. Decision and chance variables are assumed to have domains different from
the empty domain, whereas value variables are always associated to the empty domain.
In the fire dispatching problem, we can represent the act of dispatching or not the
unit i by a decision variable Ti ; hence we have three decision variables T1 , T2 , and T3
with domains T1 = T2 = T3 = {a, w}, where a stands for act and means the unit is
dispatched, while w stands for wait and means the unit is not dispatched. The outcome
of the incident after the assignment of units is represented by a binary chance variable O
with domain O = {s, f } (representing success and failure, respectively), and evaluated
by a value variable V (which is associated to  ). There are also individual costs per unit
dispatched, which are modeled by three value variables V1 , V2 and V3 . The set of relevant
variables for the problem is then U = {T1 , V1 , T2 , V2 , T3 , V3 , O, V }.
The domain x of a set of variables x = {X1 , . . . , Xn }  U is given by the Cartesian
product X1      Xn of the variable domains. Thus, an element u  U defines a
state of the world, that is, a realization of all actions and events of interest. If x and y are
sets of variables such that y  x  U, and x is an element of the domain x , we write
xy to denote the projection of x onto the smaller domain y , that is, xy  y contains
only the components of x that are compatible with the variables in y. By convention,
x , . The cylindrical extension of y  y to x is the set y x , {x  x : xy = y}.
Often, we write X1    Xn to denote the set {X1 , . . . , Xn } and, if clear from the context,
X to denote the singleton {X}. For instance, if x = {T1 , O} and y = {T1 }, then x =
2. We make no distinction between a node in the graphical representation of a decision problem and its
corresponding variable.

99

fiMaua, de Campos, & Zaffalon

{(a, s), (w, s), (a, f ), (w, f )}. Also, if x = (w, s)  x then xy = w and xO = s. The
cylindrical extension of s  O to x is given by sx = {(a, s), (w, s)}.
2.3 Operations Over Real-Valued Functions
Some operations over real-valued functions need to be defined. Let f and g be functions
over domains x and y , respectively. The product f g is defined as the function over the
domain xy such that (f g)(w) = f (wx )g(wy ) for any w of its domain. Sum of functions
is defined analogously: (f + g)(w) = f (wx ) + g(wy ). Notice that product and sum of
functions are associative and commutative, and that product distributes over sum, that is,
f g = gf , f + g = gP+ f , and f (g + h) = f g + f h. If f is a function over x , and y  U,
the sum-marginalP y f returns
w of its
P a function over x\y such that for any element
P
domain we have ( y f )(w) = xwx f (x). Notice that if y  x = , then y f = f . Also,
the sum-marginal operation
inherits
commutativity
P
P P
P Pand associativity from addition of real
numbers, and hence xy f = x\y y f = y\x x f .
If {fxy }yy is a set containing functions fxy of domain x , one for each element of y ,
y
we write fxy to denote the function that for all w  xy satisfies fxy (w) = fxw (wx ).
For instance, if X and Y are two binary-valued variables with domains X = {x1 , x2 }
y
y
y
and Y = {y 1 , y 2 }, and fX1 and fX2 are two functions over X such that fX1 (x1 ) = 1/2,
y2
y2
y1
Y is such that
fX (x2 ) = 1/2, fX (x1 ) = 0 and fX (x2 ) = 1, then the function fX
y

y

Y
fX
(x2 , y 1 ) = fX1 (x2 ) = 1/2 ,

y

Y
fX
(x2 , y 2 ) = fX2 (x2 ) = 1 .

Y
fX
(x1 , y 1 ) = fX1 (x1 ) , = 1/2

y

Y
fX
(x1 , y 2 ) = fX2 (x1 ) , = 0

When clear from the context, we write 1 to denote a function that returns one to all
values in its domain and 0 to denote a function that returns always zero. For x  x , the
indicator function Ix returns one if x = x and zero otherwise.
If f and g are functions over a domain x and k is a real number, the expressions f  g
and f = k denote that f (x)  g(x) and f (x) = k, respectively, for all x  x (e.g., in the
y
previous example we have fX1 = 1/2). Finally, any function over a domain containing a
single element (e.g., the empty domain) is identified with the real number it returns.
2.4 Definition
A LIMID L consists of a direct acyclic graph (DAG) over the set of variables U annotated
with variable types (decision, chance and value), together with a collection of (conditional)
probability mass functions (one per chance variable) and utility functions (one per value
variable). The value nodes in the graph are assumed to have no children. The precise
meaning of the arcs varies according to the type of node to which they point. Arcs entering
chance and value nodes denote stochastic and functional dependency, respectively; arcs
entering decision nodes describe information awareness at the time the decision is made.
For each variable X in U, we denote by paX the set of parents of X, that is, the set of
nodes of from which there is an arc pointing to X. Similarly, we let chX denote the set of
children of X (i.e., nodes to which there is an arc from X), and faX , paX  {X} denote
its family. We let C, D and V be a partition of U in sets of chance, decision and value
variables, respectively. Each chance variable C in C has an associated set {p
C :   paC }
100

fiSolving LIMIDs

V1

V2

V3

T1

T2

T3

uV1 (a) = uV2 (a) = uV3 (a) = 1
uV1 (w) = uV2 (w) = uV3 (w) = 0

O

pTO1 ,T2 ,T3 (s, t1 , t2 , t3 ) = I(a,a,a)
uV (s) = 7/2
uV (f ) = 0

V
Figure 1: A LIMID representing the fire dispatching problem.
of (conditional) probability mass functions p
C quantifying the decision makers beliefs about
states x  C conditional on a state  of its parents (if C has no parents, it has a single
probability mass function assigned). Using the notation introduced in the previous section,
we equivalently represent the set of probability mass functions associated to a variable C by
pa
a function pC C . We assume any chance variable X  C to be stochastically independent of
its non-descendant non-parents given its parents. Each value variable V  V is associated
with a real-valued utility function uV over paV , which quantifies the (additive) contribution
of the states of its parents to the overall utility. Thus, thePoverall utility of a state x  CD
is given by the sum of utility functions, that is, u(x) = V V uV (xpaV ).
2.5 A LIMID for the Fire Dispatching Problem
Figure 1 depicts a LIMID for the fire dispatching problem. In the graph, chance, decision
and value variables are represented by ovals, rectangles and diamonds, respectively. The
value variables V1 , V2 and V3 have associated utility functions uV1 , uV2 and uV3 , respectively,
representing the cost per unit dispatched. The utility of the outcome is quantified by the
function uV associated to the value variable V . The chance variable O has associated
a function pTO1 ,T2 ,T3 that quantifies the conditional probabilities P (O = o|T1 = tT1 , T2 =
tT2 , T3 = tT3 ) of success (o = s) or failure (o = f ) given a joint decision t  T1 ,T2 ,T3 .
According to the model in the figure, dispatching the three units results in certain success,
whereas dispatching less than three units leads to a failure.
2.6 Policies and Strategies
For any decision variable D  D with at least one parent, a policy D specifies an action
for each possible state configuration of its parents, that is, D : paD  D . If D has no
parents, then D is a state in D . The set of all policies D for a variable D is denoted by
D . For instance, a policy T1 for the first unit in the running example is a state from T1 .
The space of policies for T1 is given by T1 = {a, w}.
Let  , DD D denote the space of possible combination of policies. An element
s = (D )DD   is said to be a strategy for L. Given a policy D and a state   paD , let

p
D denote a probability mass function for D conditional on paD =  such that pD = ID () .
If D has no parents, then pD = ID is an unconditional probability mass function over D .
101

fiMaua, de Campos, & Zaffalon

pa

To simplify notation, we sometimes write pD D irrespective of whether D has any parent.
pa
There is a one-to-one correspondence between functions pD D and policies D  D such
paD
that specifying a policy D is equivalent to specifying pD and vice-versa. We denote the
pa
set of all functions pD D obtained in this way by PD . So, for instance, PT1 = {Ia , Iw }.
A strategy s induces a joint probability mass function over the variables in C  D by
Y pa Y pa
ps ,
pC C
pD D ,
(1)
CC

DD

and has an associated expected utility
Es [L] ,

X

ps

CD

X

uV .

(2)

V V

Notice that the two sums in Eq. (2) have different semantics. The outer (leftmost) sum
denotes the sum-marginal of the S
set of variables C D, whereas the inner (rightmost) denotes
the overall utility function over V V paV that results from the sum of functions uV .
In the fire dispatching problem, there are eight possible strategies consisting of a decision
to act or wait for each of the units, for example, s = (T1 , T2 , T3 ) = (a, w, a) is a possible
strategy. The policy T1 = a that dispatches unit T1 induces a probability mass function
pT1 = Ia on T1 . Likewise, the policy T2 = w induces a function pT2 = Iw , and the policy
T3 = a induces pT3 = Ia . The strategy s = (a, w, a) then induces the joint probability
mass function such that for x  O,T1 ,T2 ,T3
T1 ,T2 ,T3
ps (x) = pO
(x)pT1 (xT1 )pT2 (xT2 )pT3 (xT3 ) ,

and has an expected utility of
X
Es [L] =
ps [uV1 + uV2 + uV3 + uV ]
O,T1 ,T2 ,T3

=

X

h
i
ps (x) uV1 (xT1 ) + uV2 (xT2 ) + uV3 (xT3 ) + uV (xO ) = 2 .

xO,T1 ,T2 ,T3

The optimal strategy s = (a, a, a) that dispatches all units, on the other hand, has an
expected utility of Es [L] = 1/2.
2.7 Theoretical Complexity
The treewidth of a graph measures its resemblance to a tree and is given by the number
of vertices in the largest clique of the corresponding triangulated moral graph minus one
(Bodlaender, 1996). As in Bayesian networks, the complexity of solving a LIMID is strongly
affected by its treewidth. Given a LIMID L of treewidth , we can evaluate the expected
utility of any given strategy s in time and space at most exponential in  (Koller & Friedman,
2009). Hence, if  is bounded by a constant, computing Es [L] takes (at most) polynomial
time in the input size.
The primary task of a LIMID is to find a strategy s with maximal expected utility,
that is, to find s   such that
Es [L]  Es [L]
102

for all s.

(3)

fiSolving LIMIDs

The value Es [L] is called the maximum expected utility of L and it is denoted by MEU[L].
For most real problems, enumerating all the strategies is prohibitively costly. In fact,
computing the MEU in bounded treewidth diagrams is NP-hard (de Campos & Ji, 2008),
and, as the following result implies, it remains NP-hard in even simpler LIMIDs.
Theorem 1. Given a singly connected LIMID with treewidth equal to two, and with variables having at most three states, deciding whether there is a strategy with expected utility
greater than a given k is NP-complete.
The proof, based on a reduction from the partition problem (Garey & Johnson, 1979),
is given in the appendix.
Under the usual assumptions of complexity theory, when a problem is NP-hard to solve
the best available options are (i) trying to devise an algorithm that runs efficiently on
many instances but has exponential worst-case complexity, or (ii) trying to develop an
approximation algorithm that for all instances provides in polynomial time a solution that
is provably within a certain range of the optimal solution. In Section 3, we take option (i),
and present an algorithm that efficiently computes optimal solutions for many LIMIDs, but
runs in exponential time for many others. In the following we state a result that suggests
that alternative (ii) is most likely unfeasible, even if we consider only diagrams of bounded
treewidth.
Given  > 1, a -approximation algorithm (for solving a LIMID) obtains a strategy s
such that
MEU[L]
 Es [L] .
(4)

If we set  = 1/(1  ), for 0 <  < 1, then a -approximation algorithm finds a solution
whose induced relative error is at most , that is,
MEU[L]  Es [L]
 .
MEU[L]

(5)

The following result indicates that provably good approximation algorithms do not exist
unless P=NP.
Theorem 2. Given a singly connected LIMID L with bounded treewidth, (unless P=NP)
there is no polynomial time -approximation algorithm, for any 1 <  < 2 , where  is the
number of numerical parameters (i.e., probabilities and utilities) required to specify L.
We defer the proof to the appendix. The result asserts that any algorithm that finds
solutions to LIMIDs in polynomial time cannot guarantee a relative error smaller than
1  2 , even if the set of inputs is restricted to LIMIDs of bounded treewidth. Hence, any
polynomial-time algorithm for LIMIDs must eventually produce very poor solutions, with
relative error close to one for large models. An exception is when both treewidth and the
number of states per variable are bounded. In such cases, we have shown constructively
in an early work (Maua, de Campos, & Zaffalon, 2011) that there is a -approximation
algorithm that runs in polynomial time.
103

fiMaua, de Campos, & Zaffalon

2.8 Constraining LIMIDs to Nonnegative Utilities
In principle, the utilities associated to value variables in a LIMID can take on any real
value. This complicates the ordering between functions that we use in the algorithm we
devise here. Fortunately, we can easily and efficiently transform any LIMID L into an
equivalent LIMID L0 where all utilities are nonnegative and whose optimal strategies s are
also optimal strategies in L. Moreover, obtaining Es [L] from Es [L0 ] for any strategy s is
straightforward.
Let L be a LIMID and let k denote the smallest utility value associated to any of the
value variables, that is, for all V  V it follows that k  uV , and there is V such that
uV (x) = k for some x  paV . The following transformation generates a new LIMID L0
whose value variables are associated only to nonnegative values.
Transformation 3. For each value variable V  V, substitute its associated utility function
uV with a new utility function u0V = uV  k.
The transformation shifts the utility functions so that uV  0, and makes uV (x) = 0 for
at least one V and x  paV . Since it affects only value variables, any strategy for L (the
LIMID before the transformation) is also a valid strategy for L0 (the transformed LIMID).
The expected utilities of a strategy s in L and L0 are related according to the following
result.
Proposition 4. For any strategy s, Es [L] = Es [L0 ] + k|V|.
Proof. The expected utility of s with respect to L0 is given by
Es [L0 ] =

X

=

X
x

V

=

X

X

ps (x)

x

X

u0V (xpaV )

V

X
ps (x)
[uV (xpaV )  k]
ps (x)

x

uV (xpaV )  k|V|

X

ps (x)

x

V

= Es [L]  k|V| ,
where the last step follows from

P

x ps (x)

= 1.

An optimal strategy s for L satisfies Es [L]  Es [L] for all s, and hence Proposition 4
ensures that Es [L] = Es [L0 ]+k|V|  Es [L0 ]+k|V| = Es [L], which implies that s is also an
optimal strategy for L0 . Similarly, if s is an optimal strategy for L0 , we have by the same
proposition that Es [L0 ] = Es [L]  k|V|  Es [L]  k|V| = Es [L0 ] for all s, and therefore s
is also optimal for L. The following corollary summarizes these results.
Corollary 5. A strategy s for L0 is an optimal strategy if and only if it is also an optimal
strategy for L.
104

fiSolving LIMIDs

Consider the running example once more. The smallest utility value is k = 1. The
utilities associated to the value variables of the transformed LIMID L0 are given by
u0V (s) = 9/2

u0V (f ) = 1

u0V1 (a) = 0

u0V1 (w) = 1

u0V2 (a) = 0

u0V2 (w) = 1

u0V3 (a) = 0

u0V3 (w) = 1 .

The strategy s = (a, w, a) has expected utility Es [L0 ] = Es [L]  k|V| = 2  (1)4 = 2.
The optimal strategy s = (a, a, a) obtains Es [L0 ] = 9/2.
In the rest of the paper, we consider only LIMIDs with nonnegative utilities, which due
to Proposition 4 does not incur any loss of generality.
2.9 Decision Nodes with Many Parents Versus Parentless Decision Nodes
A policy for a decision variable with no parents corresponds to a choice of one of its states.
Hence, the space of policies of such nodes contains a number of policies that is polynomial in
the input. On the other hand, the cardinality of the space of policies for decision nodes with
many parents is exponential in the number of states of the parents. To see this, consider a
ten-state decision variable D. If D has no parents then the space of policies D contains 10
4
policies. However, if D has four ternary parent nodes, the space D contains 103 = 1081
policies.
One might then wonder whether LIMIDs whose decision nodes have many parents are
more difficult to solve than LIMIDs with parentless decision nodes. We will show that,
at least from a theoretical perspective, this is not the case, and that any LIMID can be
efficiently mapped into a MEU-equivalent LIMID where decision nodes have no parents.
We then show how an optimal strategy for the original diagram can be produced from an
optimal strategy for the transformed diagram. This is particularly relevant for algorithms
that search the space of policies, as is the case of the algorithm we devise here, and it allow
us, without loss of generality, to focus on LIMIDs whose decision nodes have no parents.
Before formally describing the transformation and showing that it produces a diagram
with equal MEU, let us first give an idea of how and why it works. To this end, consider a
LIMID L and a decision node D with at least one parent (e.g., the diagram in Figure 2(a)),
and let  1 , . . . , m denote the configurations in paD . A policy D maps a configuration
pa
 i to a decision d  D . A function pD D associated to a policy D can be seen as a
i
set of probability mass functions pT1 , . . . , pTm where pTi = p
D = ID ( i ) , that is, each
function pTi represents a choice of a state of D for a fixed configuration  i of the parents.
Recall that a policy associated to a parentless variable is simply a choice of a state. The
transformation replaces the decision variable D with m decision variables T1 , . . . , Tm and m
chance variables X1 , . . . , Xm such that each policy Ti corresponds to a decision D (i ) of the
original variables policy (see diagram in Figure 2(b)). The chain X1      Xm of chance
variables is responsible for making only the policy Ti active when the parents assume
configuration  i , as it occurs with D , by either blocking or allowing information to
flow according to the value of the parents of D. Thus, the parents of D act as a selector that
105

fiMaua, de Campos, & Zaffalon

paD

paD
D

X1

X2

chD

T1

T2



(a)

Xm

chD

Tm
(b)

Figure 2: A piece of a diagram before (a) and after (b) Transformation 6.

decides which of the probability mass functions pTi associated to decision nodes T1 , . . . , Tm is
going to be used, so that the transformed diagram acts as the original one. The probability
X
,Ti ,paD
mass functions of pXi1
are set to ensure that Xi = Ti if paD =  i and Xi = Xi1
i
otherwise.
Transformation 6. Consider a LIMID L and a decision node D with at least one parent,
and let  1 , . . . , m denote the configurations in paD . Remove D and add m = |paD |
chance nodes X1 , . . . , Xm and m decision nodes T1 , . . . , Tm with domains Xi = Ti = D
(for i = 1, . . . , m). Add an arc from every parent of D to each of X1 , . . . , Xm , an arc from
every Xi to Xi+1 , with i < m, and an arc from every Ti to Xi , i = 1, . . . , m. Add an arc
from Xm to each child of D. Associate to X1 the function


if xpaD =  1 and xX1 = xT1
1,
T ,pa
pX11 D (x) = 0,
if xpaD =  1 and xX1 6= xT1


1/m if xpaD 6=  1 .
For each node Xi , i = 2, . . . , m, associate a function


1, if (xpaD 6=  i



0, if (xpaD 6= 
X
,Ti ,paD
i
pXi1
(x)
=
i
pa
D

1, if (x
= i



0, if (xpaD = 
i

and
and
and
and

xXi
xXi
xXi
xXi

= xXi1 )
6= xXi1 )
= xTi )
6= xTi ) .

pa

Finally, the functions pX X for each child X of D have D substituted by Xm in their domain,
without altering the numerical values.
Figure 2 depicts a decision node with many parents (on the left) and the new sub-diagram
generated by Transformation 6 (on the right). It is not difficult to see that the treewidth
of the transformed diagram is increased by at most three, because the subgraph containing
the new nodes, the parents of D and the children of D is triangulated and contains cliques
with at most |paD  {Xi , Xi1 , Di }| variables.3 Also, the transformation for two different
decision variables affect different parts, and hence transforming a diagram in a diagram
with parentless decisions does not increase the treewidth by more than three. The following
result states that also optimality of strategies is preserved by the transformation.
3. Since the treewidth is given by the size of largest clique in the triangulated moral graph minus one, |paD |
is a lower bound on the treewidth of the original graph.

106

fiSolving LIMIDs

Proposition 7. Let L0 be the result of applying Transformation 6 on a decision variable
D in a LIMID L, s0 denote a strategy for L0 , and T1 , . . . , Tm denote the corresponding
policies for T1 , . . . , Tm in s0 . Let also D be a policy for D such that D ( i ) = Ti for all
 i  paD . Finally, let s be a strategy for L obtained by substituting T1 , . . . , Tm in s0 with
D (and keeping the remaining policies). Then s is an optimal strategy for L if and only if
s0 is an optimal strategy for L0 .
The proof is in the appendix. For each decision variable D in the original LIMID, the
transformed model contains m chance variables specifying m|D |3 values, and m decision
nodes with |D | states. If the treewidth of the original diagram is bounded, then m is
bounded and the transformation takes polynomial time.4 In the example of a ten-state
decision variable with four ternary parents, the transformation replaces the decision variable
D with 34 = 81 decision variables whose space of policies contain 10 elements each, besides
the 81 chance variables. The combined space of policies, that is, T1      T81 contains
also 1081 elements, so that the total search space is still (doubly) exponential in the input.
However, algorithms can take advantage of the smaller local policy spaces to reach better
solutions, and this is particularly true for the algorithm we devise later on.
In the rest of the paper we assume without loss of generality that decision nodes have
no parents and utilities are nonnegative.

3. Solving LIMIDs
In this section, we describe a new algorithm for solving LIMIDs exactly by propagating
multiple non-dominated solutions. We start by defining the basic algebraic structure of
our algorithm, which is given by the framework of valuation algebra. We show that this
framework alone, similar to the one used by SPU, might lead to poor accuracy. We thus
extend the framework with sets of valuations that attempt to improve accuracy by increasing
complexity. Efficiency is obtained by pruning sets so that their cardinality is kept as small
as possible without affecting accuracy.
3.1 Valuation Algebra
The basic ingredients of our algorithmic framework for representing and handling information in LIMIDs are the so called valuations, which encode information (probabilities, utilities
and policies) about the elements of a domain. Each valuation is associated to a subset of the
variables in U, called its scope. More concretely, a valuation  with scope x is a pair (p, u)
of nonnegative real-valued functions p and u over the domain x ; we refer to p and u as
the probability and utility part, respectively, of . Often, we write x to make explicit the
scope x of a valuation . For any x  U, we denoted the set of all possible
S valuations with
scope x by x . The set of all possible valuations is thus given by  , xU x . The set
 is closed under two basic operations of combination and marginalization. Combination
represents the aggregation of information and is defined as follows.
Definition 8. If  = (p, u) and  = (q, v) are valuations with scopes x and y, respectively,
its combination    is the valuation (pq, pv + qu) with scope x  y.
4. If the treewidth is not bounded then the output of any algorithm, that is, an optimal strategy, might
take space exponential in the input.

107

fiMaua, de Campos, & Zaffalon

Marginalization, on the other hand, acts by coarsening information:
Definition 9. If  = (p, u) is a valuationP
with scope
P x, and y is a set of variables such that
y  x, the marginal y is the valuation ( x\y p, x\y u) with scope y. In this case, we say
that z , x \ y has been eliminated from , which we denote by z .
Notice that our definitions of combination and marginalization slightly differ from previous works on influence diagrams (e.g., Lauritzen & Nilsson, 2001), which usually require
a division of the utility part by the probability part. The removal of the division operation
turns out to be an important feature when we discuss maximality of valuations later on,
but otherwise our definition is equivalent to valuations with division, in the sense that one
could easily reformulate message-passing algorithms like SPU using our definition.
In terms of computational complexity, combining two valuations  and  with scopes
x and y, respectively, requires 3|xy | multiplications and |xy | additions of numbers;
computing y , where y  x, costs |xy | operations of addition. In other words, the cost
of combining or marginalizing a valuation is exponential in the cardinality of its scope (and
linear in the cardinality of its domain). Hence, we wish to work with valuations whose
scope is as small as possible. The following result shows that our framework respects the
necessary conditions for computing efficiently with valuations (in the sense of keeping the
scope of valuations obtained from combinations and marginalizations of other valuations
minimal).
Proposition 10. The system (, U, , ) satisfies the following three axioms of a (weak)
labeled valuation algebra (Shenoy & Shafer, 1990; Kohlas, 2003).
(A1) Combination is commutative and associative, that is, for any 1 , 2 , 3   we have
that
1  2 = 2  1 ,
1  (2  3 ) = (1  2 )  3 .
(A2) Marginalization is transitive, that is, for z  z and y  x  z we have that
y
(x
= y
z )
z .

(A3) Marginalization distributes over combination, that is, for x  x , y  y and
x  z  x  y we have that
(x  y )z = x  yyz .
Proof. (A1) follows directly from commutativity, associativity and distributivity of product
and sum of real-valued functions, and (A2) follows directly from commutativity of the summarginal operation. To show (A3), consider any two valuations (p, u) and (q, v) with scopes
x and y, respectively, and a set z such that x  z  x  y. By definition of  and , we
have that


X
X
[(p, u)  (q, v)]z = 
pq,
(pv + qu) .
xy\z

108

xy\z

fiSolving LIMIDs

Since x  y \ z = y \ z, and p and u are functions over x , it follows that

 

X
X
X
X
X

q
v+u
q, p
(pv + qu) = p
pq,
xy\z

y\z

xy\z

y\z

y\z



X X
v ,
= (p, u)  
q,
y\z

y\z

which equals (p, y)  (q, v)yz .
The following result by Kohlas (2003, Section 2.2) is a direct consequence of (A3) that
we shall use to prove the correctness of our algorithm.
Lemma 11. If x  x , y  y , z  y and z  x = , then (x  y )z = x  z
y .
The primary goal of a valuation algebra is the computation of marginal valuations of
the form  = (1      m ) . Let {X1 , . . . , Xn } be the set of variables appearing in the
scopes of 1 , . . . , m . The marginal  can be computed efficiently by a variable elimination
procedure5 that receives a set  = {1 , . . . , m } and a permutation  of the variables
(1)
(k )
X1 , . . . , Xn , and for i = 1, . . . , n replaces all valuations i , . . . , i i whose scope contains


(1)
(k ) (Xi )
variable (Xi ) with the marginal i = i      i i
. Algorithm 1 describes the
procedure. The algorithm returns a valuation j      k , where j , . . . , k  n , which
equals  by Axioms (A1)(A3) (Kohlas, 2003, Section 4.1).
Algorithm 1 VariableElimination(x,,)
Input: A permutation  of the variables x = {X1 , . . . , Xn } and a set of valuations  =
{1 , . . . , m } over subsets of x
Output: The marginal valuation (1      m )
1: Let 0  
2: for i  1 to n do
(1)
(k)
3:
Let i , . . . , i denote the valuations in i1 whose scope contains (Xi )


(1)
(k) (Xi )
4:
Compute i = i      i
(1)

(k)

Let i  i1  {i } \ {i , . . . , i }
6: end for
7: return the combination of all valuations in n

5:

The complexity of the variable elimination procedure is given by the size of the largest
valuation i generated in the loop. This valuation might have a size exponential in the
size of valuations 1 , . . . , m given as input, but, as we discuss later on, there are certain
conditions under which the size of i is bounded and the procedure takes time polynomial
in the input.
5. Variable elimination algorithms are also known in the literature as fusion algorithms (Shenoy & Shafer,
1990) and bucket elimination (Dechter, 1999).

109

fiMaua, de Campos, & Zaffalon

3.2 Computing Expected Utilities
We can use the valuation algebra framework introduced to compute the expected utility of a
given strategy using variable elimination. Let s = (D )DD   be a strategy for a LIMID
L whose expected utility we want to compute, and  be a permutation of the variables in
C  D. We assume that the decision nodes in L have no parents (otherwise we need first
to apply Transformation 6), so that the strategy s is simply a configuration in D . The
procedure in Algorithm 2 computes the expected utility induced by the strategy s. The
pa
procedure calls variable elimination with a set  that contains a valuation C = (pC C , 0)
for each chance variable, a valuation V = (1, uV ) for each value variable, and a valuation
D = (ID , 0) for each decision variable. We have the following result.
Algorithm 2 ExpectedUtility(L, , s)
Input: A LIMID L whose decision nodes have no parents, a permutation  of the variables
in C  D, and a strategy s = (D )DD  
Output: The expected utility of s
1: Let   
2: for C  C do
pa
3:
Add C = (pC C , 0) to 
4: end for
5: for V  V do
6:
Add V = (1, uV ) to 
7: end for
8: for D  D do
9:
Add D = (ID , 0) to 
10: end for
11: Let s  VariableElimination(C  D, , )
12: return the utility part of s

Proposition 12. The procedure described in Algorithm (2) returns the expected utility of
the strategy s.
Proof. Let s be the output of the Variable Elimination Algorithm. According to Axioms
(A1)(A3), we have that s =   , where
"
# "
# "
#
O pa
O
O

=
pC C , 0 
(ID , 0) 
(1, uV ) .
CC

DD

V V

Let p and u denote the probability and
of s . By definition of
P utility part, respectively,
Q
pa
combination, we have that  = (ps , ps V V uV ), where ps = PXCD pX X as in (1). Since
ps isP
a probability
P distribution over C  D, it follows that p = xCD ps (x) = 1. Finally,
u = CD ps V V uV , which equals Es [L] by (2).
Consider the LIMID of the fire dispatching problem (Figure 1) and the strategy s =
(a, w, a) whose expected utility we want to compute using the procedure above. We assume
110

fiSolving LIMIDs

that the utilities are nonnegative (i.e., we have already applied Transformation 3). According to the procedure in Algorithm 2, we first generate the set  = {O = (pTO1 ,T2 ,T3 , 0), V1 =
(1, u0V1 ), V2 = (1, u0V2 ), V3 = (1, u0V3 ), V = (1, u0v ), T1 = (Ia , 0), T2 = (Iw , 0), T2 =
(Ia , 0)}. For X1 = O, X2 = T1 , X3 = T2 , X4 = T3 , let  be a permutation of the variables
such that (Xi ) = Xi for i = 1, . . . , 4. The variable elimination algorithm with  and  as
input produces the valuations
1 = (V  O )O

2 = (V1  T1  1 )T1

3 = (V2  T2  2 )T2

4 = (V3  T3  3 )T3

during its loop, and outputs the valuation s = 4 = (1, 2). Similarly, to compute the
expected utility of the optimal strategy s = (a, a, a) we run variable elimination with
 = {O = (pTO1 ,T2 ,T3 , 0), V1 = (1, u0V1 ), V2 = (1, u0V2 ), V3 = (1, u0V3 ), V = (1, u0v ), T1 =
(Ia , 0), T2 = (Ia , 0), T2 = (Ia , 0)}, which then outputs s = (1, 9/2).
In general, the described procedure can take time exponential in the input. However,
when L has bounded treewidth it can be shown that there exists a permutation  for
which the procedure takes time polynomial in the input. (e.g., Koller & Friedman, 2009,
Section 23.4.3). Hence, if the space of strategies is sufficiently small, we can find an optimal
strategy by simply ranking strategies according to their expected utilities. However, we do
not expect this to be feasible for any realistic diagram as the space of strategies increases
exponentially with the number of decision nodes (assuming they have no parents), even in
diagrams of bounded treewidth and bounded number of states per variable.
3.3 Local Search Algorithms
As a first attempt to design a fast algorithm to solve LIMIDs, one might suggest a local
search scheme that starts with a random solution and repeatedly explores its neighborhood
in order to find a solution with higher expected utility. If the treewidth of the diagram is
bounded, the expected utility of each neighbor solution can be efficiently computed, so the
complexity of the algorithm is given by the size of the neighborhood. A possible approach
is then to define the neighborhood of a solution to be the strategies obtained by changing
a single policy, which gives a local search space polynomial in the input. Algorithm 3
describes a greedy procedure that at each step looks for a new policy that improves on
the current best solution. The algorithm is guaranteed to find a strategy which is locally
optimal in its neighborhood, that is, it cannot be improved by changing only one of its
policies. Lauritzen and Nilsson (2001) stated sufficient conditions that a diagram has to
satisfy in order to guarantee that the solution produced by a local search procedure is
(globally) optimal. Unfortunately, as the following example shows, these conditions are
violated by even structurally very simple chain diagrams, and in such cases a local search
procedure might output local optima of very poor accuracy.
Consider the LIMID of our running example, and suppose we start with strategy s0 =
(a, w, a), which has expected utility 2. At the first step we might try to improve the policy
for T1 , producing strategy s = (w, w, a) whose expected utility is 3. Since this is higher
than the expected utility of the initial solution, we set sbest  s and update the highest
expected utility found. Next, we try to search for a better policy for T2 , and we generate
strategy s = (w, a, a). This strategy has an expected utility of 2, which is less than the
111

fiMaua, de Campos, & Zaffalon

Algorithm 3 GreedyPolicySearch(L, , s0 )
Input: A LIMID L, a permutation  of the variables in C  D, and an initial strategy
s0 = (D )DD
Output: A locally optimum strategy sbest
1: Let sbest  s0 and Esbest [L]  ExpectedUtility(L, , s0 )
2: repeat
3:
Generate a new candidate strategy s by replacing a single policy D in sbest
4:
Compute Es [L]  ExpectedUtility(L, , s)
5:
if Es [L] > Esbest [L] then
6:
Set sbest  s and Esbest [L]  Es [L]
7:
end if
8: until current solution cannot be further improved in this way
9: return sbest

X0

D1

D2

X1

X2

Dn



Xn

R

Figure 3: A chain structure diagram with n decision variables.
expected utility of the best solution found so far. Finally, we look for a better policy for T3 ,
which leads us to strategy s = (w, w, w), whose expected utility is 4. Since this is better
than our current best solution we set sbest  s and update the associated expected utility.
Since no change of a single policy can improve this strategy, the algorithm halts with a
solution whose expected utility is 4 against a maximum expected utility of 9/2 achieved by
strategy s = (a, a, a) (more than 10% relative error), or, in terms of the original diagram
(by means of Proposition 4), an expected utility of zero against a maximum expected utility
of 1/2.
The procedure we have just described is very similar to the SPU algorithm, and it
illustrates the pitfalls of a local search. In fact, SPU will output just the same local optimum
(but it would start with a uniform policy for every decision variable). Note that the solution
obtained by the greedy local search on the example degrades as the ratio of the utility of
success (achieved only by strategy (a, a, a)) and the utility of failure increases. For instance,
if the utility of success were increased to u0V (s) = 10 and the utility of failure remained the
same, that is, if u0V (f ) = 0, the algorithm would reach a solution whose expected utility is
4, an error of 60% relative to the maximum expected utility of 10. Moreover, cases where
SPU performs poorly are not rare. For instance, the plots in Figure 4 show SPUs relative
performance in chain diagrams like the one in Figure 3. Each diagram was generated by
independently sampling each conditional distribution associated to a chance node from a
symmetric Dirichlet distribution with parameter 1/m, where m is the number of variable
states. The maximum expected utility of each diagram was computed using the algorithm
we devise here, which took less than 3 seconds on any diagram in the experiment.
Each (blue) point in the plots in Figure 4 depict the relative error of SPU on a given
diagram. The (red) line indicates the third quartile of each fixed configuration. The di112

fiSolving LIMIDs

0.6

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Relative error

0.5
0.4
0.3
0.2
0.1
0
10
20
30
40
50
Number of decision nodes

10
20
30
40
50
Number of states per variable

Figure 4: Relative performance of SPU on randomly generated chain diagrams. Each (blue)
circle depicts an experiment and the (red) line depicts the third quartile.
agrams in the left hand-side plot were obtained with the number of states fixed at 15,
while the diagrams on the right had the number of decision variables fixed in ten. For
example, we see from the third quartile line on the right-hand side plot that in 25% of the
chain diagrams of 20 states and ten decision variables, SPU returned a strategy s such that
(MEU[L]  Es [L])/ MEU[L]  0.1. Also, there were cases where SPU obtains up to 70%
relative error. On the other hand, we see that in the majority of the cases the solution
returned by SPU achieved a relative error of less than 10%. All in all, these experiments
show that local search is effective in many cases, but may produce very poor results.
3.4 Ordered Valuations
Can we also exploit the redundancy in the computation of expected utility of neighboring
strategies to decide whether a candidate solution improves the current solution without
having to run variable elimination completely? For instance, when evaluating the quality
of a new candidate strategy that differs from the current best strategy only by the policy
associated to T1 , can we have any insight by inspecting two valuations 2 produced by
variable elimination in the example in Section 3.2 using two different strategies? Fortunately,
the answer is yes, and to show this we need the concept of ordered valuations.
Let us define a partial order (i.e., a reflexive, antisymmetric and transitive relation) over
, the set of all possible valuations, as follows.
Definition 13. For any two valuations  = (p, u) and  = (q, v) in , we say that 
dominates  (conversely, we say that  is dominated by ), and we write   , if  and
 have equal scope, p  q, and u  v.
If  and  have scope x, deciding whether  dominates  costs at most 2|x | operations
of comparison of numbers. The following result shows that the algebra of valuations is
monotonic with respect to dominance.
Proposition 14. The system (, U, , , ) satisfies the following two additional axioms
of an ordered valuation algebra (Haenni, 2004).
113

fiMaua, de Campos, & Zaffalon

(A4) Combination is monotonic with respect to dominance, that is,
if x  x and y  y then (x  y )  (x  y ) .
(A5) Marginalization is monotonic with respect to dominance, that is,
y
if x  x then y
x  x .

Proof. (A4). Consider two valuations (px , ux ) and (qx , vx ) with scope x such that (px , ux ) 
(qx , vx ), and two valuations (py , uy ) and (qy , vy ) with scope y satisfying (py , uy )  (qy , vy ).
By definition of , we have that px  qx , ux  vx , py  qy and uy  vy . Since all
functions are nonnegative, it follows that px py  qx qy , px uy  qx vy and py ux  qy vx .
Hence, (px , ux )  (py , uy ) = (px py , px uy + py ux )  (qx qy , qx vy + qy vx ) = (qx , vx )  (qy , vy ).
(A5). Let y be a subset of x. It follows from monotonicity of  with respect to addition of
real numbers that

 

X
X
X
X
(px , ux )y = 
px ,
ux   
qx ,
vx  = (qx , vx )y .
x\y

x\y

x\y

x\y

Hence, the result follows.
Axioms (A4) and (A5) assert that combination and marginalization preserve the partial
ordering between valuations. This allow us to detect suboptimal strategies early in the
variable elimination procedure. Consider comparing the strategies s = (w, w, w) and s0 =
(w, a, w) for the LIMID of our running example. At the third iteration of the loop (i.e.,
when i = 3), the variable elimination procedure produces valuations s3 = (ps3 , us3 ) and
0
0
0
s3 = (ps3 , us3 ) for the strategies s and s0 , respectively, such that
ps3 (a) = 1 ,

ps3 (w) = 1 ,

us3 (a) = 3 ,

us3 (w) = 3 ,

0

ps3 (w) = 1 ,

0

0

us3 (w) = 2 .

ps3 (a) = 1 ,

0

us3 (a) = 2 ,
0

0

0

Thus, s3  s3 . Since s4 = (sT3  V3  s3 )T3 and s4 = (sT3  V3  s3 )T3 , we know
0
by Axioms (A4) and (A5) that s4  s4 , and hence that Es0 [L]  Es [L]. Therefore, there is
no need to continue the execution of variable elimination for s0 , as its expected value cannot
be higher than that of s.
Unfortunately, suboptimal solutions do not always produce valuations that are dominated by an optimal one during variable elimination. As an example, consider strategies
s = (a, w, a) and s = (a, a, a). At the third step, variable elimination generates valuations



s3 = (ps3 , us3 ) and s3 = (ps3 , us3 ) such that
ps3 (a) = 1 ,

ps3 (w) = 1 ,

us3 (a) = 2 ,

us3 (w) = 2 ,




ps3 (w) = 1 ,



us3 (w) = 1 .

ps3 (a) = 1 ,



us3 (a) = 9/2 ,
114

fiSolving LIMIDs



Thus, even though s is an optimal strategy, s3 6 s3 .
The algorithm we devise later on exploits that fact that some suboptimal solutions can
be early detected and eliminated from the search space. Because some suboptimal solutions
might not be eliminated during variable elimination, the algorithm runs in exponential time
in the worst case, but this is just to be expected, as the problem is NP-hard. Fortunately,
our experiments with random problems suggest that situations like this are not frequent.
3.5 Sets of Valuations
The multiple runs of variable elimination for different inputs but same elimination ordering (i.e., a permutation of the variables) are represented by sets in the framework of the
algorithm we devise later on. For instance, we might consider the set 3 of all valuations
3 produced by variable elimination at the third iteration of the loop for every possible
strategy. Due to the monotonicity of combination and marginalization with respect to ,
we can immediately halt the computation of valuations from 3 that are dominated by
some other, that is, we can remove dominated valuations from 3 . This is formalized by
the concept of maximal valuations and the operator max:
Definition 15. Given a finite set of valuations   , we say that    is maximal if for
all    such that    it holds that   . The operator max returns the set max()
of maximal valuations of .
If x is a set with m valuations of scope x, the set of maximal valuations max(x ) can
be obtained by m2 comparisons   , where (, )  x  x .
When all valuations in the set x have the same scope x, we say that x also have scope
x. We can extend combination and marginalization to sets of valuations as follows.
Definition 16. If x and y are any two sets of valuations in ,
x  y , {x  y : x  x , y  y }
denotes the set obtained from all combinations of a valuation in x and a valuation in y .
Definition 17. If x  x is a set of valuations with scope x and y  x,
y
y
x , {x : x  x }

denote the set of valuations obtained by element-wise marginalization of valuations to y.
It can be checked that sets of valuations with combination and marginalization defined
element-wise satisfy axioms (A1)(A3), and therefore form a valuation algebra. Hence,
Lemma 11 applies also for sets of valuations with marginalization and combination defined
as above.
Lemma 18. If x  x and y  y are two sets of valuations with scope x and y,
respectively, and z is a set of variables such that z  y and z  x = , then (x  y )z =
x  yz .
Proof. The result follows from element-wise application of Lemma 11 to (x  y )z 
(x  y )z .
115

fiMaua, de Campos, & Zaffalon

3.6 Solving LIMIDs Exactly
We are now ready to describe the MultiplePolicyUpdating (MPU) algorithm, which
solves arbitrary LIMIDs exactly. The algorithm assumes that the decision nodes have no
variables, and that utilities are nonnegative, hence Transformations 6 and 3 have to be
applied before running the algorithm in case some of these assumptions fail.
Consider a LIMID L and a permutation  of the variables in C  D, and let n = |C  D|.
pa
The algorithm is initialized by generating a set S0 that contains a singleton {(pC C , 0)}
for each chance variable C, a singleton {(1, uV )} for each value variable V and a set of
valuations {(pD , 0)}, which contains one element (pD , 0) per policy D , for each decision
variable D. Then a set-valued variable elimination is performed for the sets of valuations
in S0 , with dominated valuations being discarded after each set marginalization. Finally,
an optimal solution is obtained from the utility part of the single maximal valuation in the
set combination of all sets of valuations in Sn obtained after the variable elimination. The
procedure is detailed in Algorithm 4.
Algorithm 4 MultiplePolicyUpdating(L, )
Input: A LIMID L and a permutation  of the variables in C  D
Output: The maximum expected utility
1: Let S0  
2: for C  C do
pa
3:
Add a singleton {(pC C , 0)} to S0
4: end for
5: for V  V do
6:
Add a singleton {(1, uV )} to S0
7: end for
8: for D  D do
9:
Add a set {(Id , 0) : d  D } to S0
10: end for
11: for i  1 to n do
(1)
(k)
12:
Let i , . . . , i denote
whose
h the sets in Si1
 scope contains (Xi )
i
(1)
(k) (Xi )
13:
Compute i = max i      i
(1)

(k)

Let Si  Si1  {i } \ {i , . . . , i }
15: end for
16: Let S denote the set combination of all sets in Sn
17: return the utility part u of (p, u)  max(S)

14:

Since all variables have been eliminated at the end of the loop, the valuations in sets
in S have empty scope and have both their probability and utility parts identified with
numbers. Hence, the algorithm outputs an expected utility (i.e., a real number) at line 17.
Let us illustrate the algorithm with an example. Once more, consider the LIMID L of the
fire dispatching problem after applying Transformation 3 and assume the same elimination
ordering of the variables used in the example in Section 3.2. We start with an empty set
116

fiSolving LIMIDs

S0 . O is the only chance variable, and we add a set
O = {(pTO1 ,T2 ,T3 , 0)}
to S0 . Then we add the sets
V1 = {(1, u0V1 )} ,

V2 = {(1, u0V2 )} ,

V3 = {(1, u0V3 )} ,

V = {(1, u0V )}

to S0 due to the value variables V1 , V2 , V3 and V , respectively. The decision variable T1
causes a set
T1 = {(Ia , 0), (Iw , 0)}
with scope T1 to be included in S0 , and similarly, for variables T2 and T3 , that is, we add
the sets
T2 = {(Ia , 0), (Iw , 0)} ,

T3 = {(Ia , 0), (Iw , 0)} ,

with scopes T2 and T3 , respectively, to S0 , obtaining S0 = {O , V1 , V2 , V3 , V , T1 , T2 , T3 }.
In the first iteration (i = 1) of the variable elimination loop (lines 1115), we have that


1 = max [V  O ]O = {(p1 , u1 )} ,
where p1 and u1 are functions over T1 ,T2 ,T3 such that p1 = 1 and u1 (a, a, a) = 9/2, and
u1 (x) = 1 for all x 6= (a, a, a). Note that 1 is a singleton since only singletons were
involved is its computation. In the second iteration we have that


w
2 = max [V1  T1  1 ]T1 = {(pa2 , ua2 ), (pw
2 , u2 )} ,
w
a
w
a
where pa2 , ua2 , pw
2 , u2 are functions over T2 ,T3 such that p2 = p2 = 1, u2 (a, a) = 9/2,
a
w
u2 (x) = 1 for all x 6= (a, a), and u2 = 2. Note that we have labeled the functions
according to the policies T1 that generated them. This allows us to easily extract the
optimal strategy at the end of the algorithm.
In the third iteration we need to compute


3 = max [V2  T2  2 ]T2
(a,a)

= max({(p3
(a,a)

= {(p3
(a,a)

(a,a)

(a,w)

(a,a)

, u3

(a,a)

(a,w)

), (p3

(w,w)

(a,w)

, u3

(w,w)

, u3

), (p3

, u3

(a,w)

(w,w)

(w,w)

(w,w)

), (p3

(w,w)

, u3

)})

)} ,
(a,a)

where p3 , u3 , p3
, u3
, p3
, u3
are functions over T3 such that p3
=
(a,w)
(w,w)
(a,a)
(a,a)
(a,w)
(w,w)
p3
= p3
= 1, u3 (a) = 9/2, u3 (w) = 1, u3
= 2, and u3
= 3. Note that
the valuation associated to the policies T2 = w and T2 = a do not appear in 3 because
(a,w) (a,w)
they generate a valuation equal to (p3
, u3
). This implies that strategies (a, w, w)
and (w, a, w) have the same expected utility, and also strategies (a, w, a) and (w, a, a).
117

fiMaua, de Campos, & Zaffalon

In the last iteration, we generate the set


4 = max [V3  T3  3 ]T3
(a,a,a)

(a,a,a)

= max({(p4

, u4

(a,a,a)

(a,a,a)

= {(p4

, u4

(a,a,a)

(a,a,a)

(w,w,a)

), (p4

(w,w,a)

, u4

(a,a,w)

), (p4

(a,a,w)

, u4

(w,w,w)

), (p4

(w,w,w)

, u4

)})

)} ,
(w,w,a)

(w,w,a)

(a,a,w)

(a,a,w)

(w,w,w)

(w,w,w)

where p4
, u4
, p4
, u4
, p4
, u4
, p4
, u4
are functions over
(a,a,a)
(w,w,a)
(a,a,w)
(w,w,w)
(a,a,a)
the empty set such that p4
= p4
= p4
= p4
= 1, u4
= 9/2,
(w,w,a)
(a,a,w)
(w,w,w)
u4
= 3, u4
= 2, and u4
= 4.
(a,a,a)
Finally, we have that S4 = {4 }, so the algorithm returns u4
= 9/2, which is the
expected utility of the optimal strategy (a, a, a). As one can see, the optimal strategy is
easily recovered by labeling valuations with their corresponding policies.
Differently from other message-passing algorithms that obtain approximate solutions
to LIMIDs by (repeatedly) propagating a single valuation (e.g., the SPU algorithm), the
MPU algorithm computes exact solutions by propagating several maximal valuations that
correspond to partial combinations of local decision rules. The efficiency of the algorithm in
handling the propagation of many valuations derives from the early removal of valuations
performed by the max operation in the propagation step.
Consider the set L , {s : s  }, where each s is given by
"

#
O

s =

pa

pC C , 0



"


CC

#
O

DD

(Id , 0) 

#!

"
O

(1, uV )

V V

such that the functions Id are consistent with the policies in s. It is not difficult to see that
#

"
O

L =

	
pa
pC C , 0

CC



#
O

{(Id , 0) : d  D } 

#!

"
O

{(1, uV )}

V V

DD




=

"

O

X 

.

X S0

Hence, by Proposition 12 we have that each s in L is a valuation with probability part
one and utility part equal to the expected utility of some strategy s in . Since the relation
 induces a strict (linear) order over L , the MEU of the diagram equals the utility part of
the (single) valuation in max(L ). The
N variable elimination procedure in the propagation
step is responsible
Nfor obtaining max( Sn ) = max(L ) more efficiently by distributing
max and  over X S0 X , which allows for a significant reduction in the cardinalities of
sets and scopes of valuations produced.
We now formally prove the correctness of the algorithm. We start by showing that max
distributes over marginalization and combination:
Lemma 19. (Distributivity of maximality). If x  x and y  y are two finite sets of
ordered valuations and z  x, the following holds.
118

fiSolving LIMIDs

(i) max(x  max(y )) = max(x  y );
(ii) max(max(x )z ) = max(z
x ).
Proof. Part (i) has been shown by Fargier, Rollon, and Wilson (2010, Lemma 1(iv)). We
use a similar proof to show that part (ii) also holds. First, we show that max(z
x ) 
z
z
max(max(x ) ). Assume, to show a contradiction, that there is an element x  max(z
x ),
where x  x , which is not an element of max(max(x )z ). By definition of max(x ), there
z
z
z
is x  max(x ) such that x  x . Hence, (A5) implies z
x  x , and because x  x
z
z
z
z
it follows that z
/ max(max(x )z )
x = x , and therefore x  max(x ) . Since x 
there is z  max(max(x )z ) such that z
x  z . But this contradicts our initial assumpz
tion since z  x .
Let us now show that max(xz )  max(max(x )z ). Assume by contradiction that
z
z
there is z  max(max(x )z ) \ max(z
x ). Since z  x , there is z  max(x ) such
z
that z  z . But we have shown that max(x )  max(max(x )z ), hence z = z and
z  max(z
x ), a contradiction.
At any iteration i of the propagation step, the combination of all sets in the current pool
of sets Si produces the set of maximal valuations of the initial factorization marginalized
to Xi+1 , . . . , Xn :
Lemma 20. For i  {0, 1, . . . , n}, it follows that

{X1 ,...,Xi } 


O
O


max 

 ,
 = max 
S0

Si

where for each i, Si is the collection of sets of valuations generated at the i-th iteration of
the propagation step of MPU.
Proof. By induction on i. The basis (i = 0) follows trivially.
Assume the result holds at i, that is,



{X1 ,...,Xi } 
O
O


max 

 .
 = max 
Si

S0

By eliminating Xi+1 from both sides and then applying the max operation we get to

{X1 ,...,Xi } Xi+1 

Xi+1 
O

 O 




max max 



 = max max 
.




S0

Si

119

fiMaua, de Campos, & Zaffalon

Applying Lemma 19(ii) to both sides and (A2) to the left-hand side yields


{X1 ,...,Xi+1 } 
Xi+1 
 O 

 O 

max 


 = max 

S0

Si



= max 

Xi+1 
O

  




O



Bi+1

Si \Bi+1



= max 



Xi+1 
 O

  max 




O

Bi+1

Si \Bi+1


= max 


O



  i 

Si \Bi+1


= max 


O

 ,

Si+1

where the passage from the first to the second identity follows from element-wise application
of (A1) and Lemma 11, the third follows from the second by Lemma 19(i), and the last two
follow from the definitions of i and Si+1 , respectively.
We are now able to show the correctness of the algorithm in solving LIMIDs exactly.
Theorem 21. Given a LIMID L, MPU outputs MEU[L].

N
Proof. The algorithm returns the utility part of a valuation (p, u) in max
 , which,
S
n
N
 
by Lemma 20 for i = n, equals max

. By definition of S0 , any valuation 
S0

N
in
S0  satisfies
"
=

#
O
CC


pa
pC C , 0

"


#
O

DD

(Id , 0) 

"

#
O

(1, uV ) ,

V V

for some combination of decisions (d)
N  D , which corresponds to a strategy in , and
there is exactly one valuation  
S0  for each strategy in . Hence, by Propo
N
sition 12, the set
contains a pair (1, Es [L]) for every strategy s inducing
S0 
a distinct expected utility. Moreover, since functions with empty scope correspond to

N
numbers, the relation  specifies a total ordering over the valuations in
,
S0 
 be a strategy associated to (p, u). Since
which implies a single maximal
element.
Let
s
N
 
(p, u)  max

, it follows from maximality that Es [L]  Es [L] for all s, and
S0
hence u = MEU[L].
120

fiSolving LIMIDs

3.7 Complexity Analysis
As with any variable elimination, the complexity of the algorithm depends on the permutation  given as input. The time complexity of the algorithm is given by the cost of creating
the sets of valuations in the initialization step plus the overall cost of the combination and
marginalization operations performed during the propagation step. Regarding the initialization step, the loops for chance and value variables generate singletons, and thus take time
linear in the input. Since decision nodes have no parents, each set D added due to a decision variable D contains D , |D | valuations. Let  , maxDD D be the cardinality of
the largest domain of a decision variable. Then the initialization loop for decision variables
takes O(|D|) time, which is polynomial in the input. Let us now analyze the propagation
step. The running time of propagating (sets of) valuations is exponential in the maximum
number of variables in the scope of the valuations generated during the loop step. This
number depends on the permutation  chosen and is in the best case equal to the treewidth
of the diagram plus one. Although finding an optimal permutation (i.e., one that leads to
a minimum maximum number of variables per scope) is an NP-hard task, we can generate
permutations  using the standard heuristics for variable elimination in Bayesian networks,
such as minimizing the number of fill-ins or the cardinality of the domain of the neighbor
set, which have been empirically shown to produce good elimination orderings (Jensen &
Nielsen, 2007; Koller & Friedman, 2009).
Consider a permutation  that induces a maximum number of variables per scope of
, and a diagram with bounded number of states per variable . Then the cost of each
combination or marginalization is bounded by a constant, and the complexity depends
only on the number of operations performed. Moreover, we have in this case that   .
Let  denote the cardinality of the largest set i , for i = 1, . . . , n. Thus, computing i
requires at most  |U |1 operations of combination (because
that is the maximum number
N
of sets that we might need to combine to compute Bi  in the propagation step) and
 operations of marginalization. In the worst case,  is equal to |D|  O(|D| ), that is, all
sets associated to decision variables have been combined without discarding any valuation.
Hence, the worst-case complexity of the propagation step is exponential in the number of
decision variables, even if the width of the elimination ordering and the number of states per
variable are bounded. Note however that this is a very pessimistic scenario and, on average,
the removal of non-maximal elements greatly reduces the complexity, as the experiments in
Section 4 show.
3.8 Reverse Topological Ordering
The valuations used by MPU specify twice as many numbers as the cardinality of the domain
of their associated scope. It is possible to decrease the number of numerical parameters per
valuation the algorithm needs to handle by a factor of two by constraining the elimination
of variables to follow a reverse topological ordering according to the diagram, that is, by
requiring each variable to be processed only after all its descendants have been processed.
As the following result shows, any reverse topological ordering produces valuations whose
probability part equals one in all coordinates.

121

fiMaua, de Campos, & Zaffalon

A

B

V1

D

C

E

V2

F

Figure 5: A LIMID in which a reverse topological ordering increases treewidth.

Proposition 22. If  defines a reverse topological ordering over the variables in C  D,
then for i = 1, . . . , n the valuations in i have probability part p = 1, where 1 is the function
that always returns the unity.
Proof. We show the result by induction on i. Regarding the basis, we have from the reverse
topological ordering that X1 is a variable containing only value nodes as children. Hence,
paX
B1 = {X1 }  {{(1, uV )} : V  chX1 }, where by definition X1 equals {(pX1 1 , 0)} if
paX

paX

X1 is a chance node, and {(pX1 1 , 0) : pX1 1  PX1 } if it is a decision node. It follows
P
paX P
paX P
that 1 = max({( X1 pX1 1 , X1 pX1 1 V chX uV )}). Since for any   paX , p
X1
1
1
P
paX
1
is a probability mass function over X1 , we have that p =
= 1. Assume by
X1 pX1
N
inductive hypothesis
that
the
result
holds
for
1,
.
.
.
,
i

1,
and
let

,
x
Bi \S0 . Then
N
i = max([ Bi S0 ]  x ). By inductive hypothesis all valuations in a set  in Bi \ S0
have probability part p = 1. Hence, by definition of combination, the valuations in x
contain also probability part equal to one. The reverse topological ordering implies that
by the time variable Xi is processed in the propagation step, all its children have been
paX
processed. Hence, the only element of Bi  S0 is the set Xi , which equals {(pXi i , 0)} if Xi
paX

paX

is a chance node, {(pXi i , 0) : pXi i  PXi } if Xi is a decision node, and {(1, uXi )} if it is a
value node. Thus, we have that i = max(Xi  x ). The case when Xi is a value node is
immediate, since any valuation in i is the result of a combination of two valuations with
probability part equal to one. If Xi is not a value node then


 X


paX X paX
paX
i = max 
pXi i ,
pXi i ux : (pXi i , 0)  faXi , (1, ux )  x 
Xi

Xi



 X


paX
paX
= max  1,
pXi i ux : (pXi i , 0)  Xi , (1, ux )  x  ,
Xi

since p
Xi is a probability mass function for any   paX .
i

The result states that if we assume a reverse topological elimination ordering, then MPU
needs to care only about the utility part of the valuations. Unfortunately, constraining the
elimination order might increase the complexity of the algorithm, as the following example
shows.
Consider the LIMID in Figure 5, where all variables are assumed binary (we omit the
specification of probabilities and utilities as they are not relevant for the matter). After
122

fiSolving LIMIDs

the initialization, we have that S0 = {A , B , C , D , E , F , V1 , V2 }. Using a reverse
topological elimination ordering implies we first have to eliminate E, which generates the
set


1 = max [E , V1  V2 ]E = {(1, u1 )} ,

whose single element (1, u1 ) has scope {A, C, D, F } and size 24 = 16. Eliminating variables
in the ordering F, C, B, A, D, E, on the other hand, generates the following sets.


1 = max [F  V2  C ]F = {(p1 , u1 )} ,


2 = max [C  E  1 ]C = {(p2 , u2 )} ,

 n
o
(d) (d)
3 = max [B  D ]B = (p3 , u3 ) : d  D ,

 n
o
(d) (d)
4 = max [A  V1  3 ]A = (p4 , u4 ) : d  D ,
 n
o

(d) (d)
5 = max [2  4 ]D = (p5 , u5 ) : d  D ,
 n
o

(d)
=
(1,
u
)
:
d


.
6 = max E
D
5
6
The scopes of the valuations in 1 , 2 , 3 , 4 , 5 and 6 are, respectively, {E, C}, {D, E},
{D, A}, {E, D}, {E} and {}. As one can see, the largest valuation generated using ordering
F, C, B, A, D, E contains two variables in its scope and therefore has size 22 = 4. This is
a four-fold decrease in size compared to the size of the set 1 generated using the reverse
topological ordering.
Notice however that even though using reverse topological ordering might increase the
size of the valuations generated during variable elimination, it does not necessarily results
in higher complexity for the MPU. This is because the overall complexity of the algorithm
depends not only on the size of the largest valuation generated but also on the cardinality of
the generated sets, and it is possible that a reverse topological ordering induces significantly
smaller sets, as it produces valuations whose probability parts are always equal to one, which
might increase the number of dominated elements.

4. Experiments
We evaluate the performance of the algorithm on random LIMIDs generated in the following
way. Each LIMID is parameterized by the number of decision nodes d , |D|, the number
of chance nodes c , |C|, the maximum cardinality of the domain of the family of a chance
variable C , maxC |faC |, and the maximum cardinality of the domain of the family of
a decision variable D , maxD |faD |. We set the number of value nodes v to be d + 2.
For each variable Xi , i = 1, . . . , c + d + v, we sample Xi to contain from 2 to 4 states.
Then we repeatedly add an arc from a decision node with no children to a value node
with no parents (so that each decision node has at least one value node as children). This
step guarantees that all decisions are relevant for the computation of the MEU. Finally, we
repeatedly add an arc that neither makes the domain of a variable greater than the given
bounds nor makes the treewidth more than 10, until no arcs can be added without exceeding
123

fiMaua, de Campos, & Zaffalon

the bounds.6 Note that this generates diagrams where decision and chance variables have
at most log2 D  1 and log2 C  1 parents, respectively. Once the DAG is obtained, we
randomly sample the probability mass functions and utility functions associated to chance
and value variables, respectively.
We compare MPU against the CR algorithm of de Campos and Ji (2008) in 1620 LIMIDs
randomly generated by the described procedure with parameters 5  d  50, 8  c  50,
8  D  64 and 16  C  64. MPU was implemented in C++ and tested in the
same computer as CR.7 Table 1 contrasts the running times of each algorithm (averages 
standard deviation) for different configurations of randomly generated LIMIDs. Each row
contains the percentage of solved diagrams (SCR and SMPU ) and time performance (TCR
and TMPU ) of each of the algorithms for N diagrams randomly generated using parameters
d, c, v, D , and C . For each fixed parameter configuration, MPU outperforms CR by
orders of magnitude (line 12 contains the only case in which the average running time of
CR is lower than MPUs, but note that in this case CR solve it only one instance, whereas
MPU solved 86% of the instances). Also, CR was unable to solve most of the diagrams with
more than 50 variables, whereas MPU could solve diagrams containing up to 150 variables
and with D  32. Both algorithms failed to solve diagrams with D = 64. A diagram is
consider unsolved by an algorithm if the algorithm was not able to reach the exact solution
within the limit of 12 hours. All in all, MPU appears to scale well on the number of nodes
(i.e., on d, c and v) but poorly on the domain cardinality of the family of decision variables
(i.e., on D ).
A good succinct measure of the hardness of solving a LIMID is the total number of
strategies ||, which represents the size of the search space in a brute-force approach. ||
can also be loosely interpreted as the total number of alternatives (over all decision variables)
in the problem instance. Figure 6 depicts running time against number of strategies in a
log-log scale for the two algorithms on the same test set of random diagrams. For each
algorithm, only solved instances are shown, which covers approximately 96% of the cases
for MPU, and 68% for CR. We note that MPU solved all cases that CR solved (but not the
opposite). Again, we see that MPU is orders of magnitude faster than CR. Within the limit
of 12 hours, MPU was able to compute diagrams containing up to 1064 strategies, whereas
CR solved diagrams with at most 1025 strategies.
The reduction in complexity obtained by the removal of non-maximal valuations during
the propagation step can be checked in Figure 7, which shows the maximum cardinality of
a set i generated in the propagation step in contrast to the number of strategies. For each
diagram (a point in the figure) solved by MPU, the cardinality of the sets remains bounded
above by 106 while we vary the number of strategies (which equals the largest cardinality
of a propagated set in the worst case where no valuation is discarded). This shows that the
worst-case analysis in Section 3.7 is very pessimistic.
6. Since current algorithms for checking whether the treewidth of a graph exceeds a fixed k are too slow
for k  5 (Bodlaender, 1996), we resort to a greedy heuristic that resulted in diagrams whose actual
treewidth ranged from 5 to 10.
7. We used the CR implementation available at http://www.idsia.ch/~cassio/id2mip/ and CPLEX
(http://www.ilog.com) as mixed integer programming solver. Our implementation of MPU can be
downloaded at http://www.idsia.ch/~cassio/mpu/.

124

fiSolving LIMIDs

N

d

c

v

D

C

SCR (%)

TCR (s)

SMPU (%)

TMPU (s)

60
60
60
60
60
60
60
60
30
30
60
30
30
60
60
90
30
60
30
30
60
60
30
60
60
60
60
30
60
30
30
30
30

5
5
5
10
10
10
10
10
10
10
10
10
10
10
20
20
20
20
20
20
20
10
10
20
20
20
30
30
30
30
30
50
50

8
8
8
8
8
8
28
28
28
28
28
28
28
28
8
8
8
8
8
8
8
78
78
58
58
58
38
38
38
88
88
48
48

7
7
7
12
12
12
12
12
12
12
12
12
12
12
22
22
22
22
22
22
22
12
12
22
22
22
32
32
32
32
32
52
52

12
16
8
12
16
8
12
16
16
32
32
32
64
8
12
16
16
32
32
64
8
16
32
12
16
8
12
16
8
12
8
12
8

16
16
16
16
16
16
16
16
64
16
32
64
64
16
16
16
64
32
64
64
16
16
16
16
16
16
16
16
16
16
16
16
16

100
100
100
98
93
100
96
83
10
93
0
3
0
100
93
38
30
0
0
0
100
60
70
50
11
96
28
0
96
0
60
0
10

6  45
9  43
6  51
15  53
107  273
0.4  0.2
1175  6126
3340  8966
2838  1493
1070  2461

73  0

13
2687  7564
5443  10070
9660  10303



7  20
5944  9920
3820  8127
6455  9344
11895  12662
849  4098
3416  4827

2261  6572

3448  5837

5014  2974

100
100
100
100
100
100
100
100
96
100
93
86
0
100
100
98
100
78
76
0
100
100
100
100
100
100
98
100
100
100
100
96
100

0.006  0.01
0.02  0.05
0.002  0.01
0.02  0.02
103  786
0.007  0.01
0.05  0.08
0.2  0.2
47  142
0.2  0.4
905  2847
2440  7606

0.01  0.007
155  1196
270  1822
29  84
938  1417
1592  3402

0.02  0.008
0.5  0.5
0.6  1
522  4011
2  11
0.07  0.04
35  214
2  10
0.1  0.03
230  1027
0.2  0.1
1753  7405
0.5  0.09

Table 1: Performance of MPU and CR on randomly generated LIMIDs (numbers are
rounded down).

125

fiMaua, de Campos, & Zaffalon

105

MPU
CR

Running time (s)

104
103
102
101
100
101
102
101

1020
1040
1060
Number of strategies (||)

Maximum set cardinality (maxi |i |)

Figure 6: Running time of MPU and CR on randomly generated LIMIDs.
106
105
104
103
102
101
100
101

1020
1040
1060
Number of strategies (||)

Figure 7: Maximum number of valuations in a set during the propagation step of MPU.

5. Related Work
Influence diagrams were introduced by Howard and Matheson (1984) as a concise language
for the specification of utility-based decision problems. There is a substantial literature that
formalizes influence diagrams and develop algorithms under the premises of no forgetting
and regularity (Cooper, 1988; Qi & Poole, 1995; Shachter & Peot, 1992). We point the
interested reader to the works of Jensen and Nielsen (2007) and Koller and Friedman (2009).
Zhang et al. (1994) studied families of LIMIDs that could be solved by dynamic programming, such as LIMIDs respecting no forgetting and regularity. The SPU algorithm
of Lauritzen and Nilsson (2001) solves these cases in polynomial time if the diagram has
126

fiSolving LIMIDs

bounded treewidth. To the best of our knowledge, the only attempt to (globally) solve arbitrary LIMIDs exactly without recurring to an exhaustive search on the space of strategies
is the CR algorithm of de Campos and Ji (2008) against which we compare our algorithm.
Shenoy and Shafer (1990) introduced the framework of valuation algebras, which states
the basic algebraic requirements for efficient computation with valuations. More recently,
Haenni (2004) incorporated partially ordered preferences in the algebra to enable approximate computation. Fargier et al. (2010) then extended the framework with a preference
degree structure in order to capture the common algebraic structure of optimization problems based on a partial order. The algebra we develop in Section 3 can be partly casted in
this framework.
The PFU framework of Pralet, Verfaillie, and Schiex (2007) subsumes many formalisms
of probabilistic reasoning, constraint satisfaction and decision making. When it comes
to decision problems the framework is geared towards sequential decision making under
equivalent assumptions of non-forgetting, although the authors mention the possibility of
extending it to limited information decision scenarios.
The variable elimination algorithm we develop here is conceptually close to the message
passing algorithm of Dubus, Gonzales, and Perny (2009). Their algorithm, however, does
not handle uncertainty and target primarily the obtention of Pareto-efficient solutions for
a specific class of multi-objective optimization problems.
There is a close relation between maximum a posteriori (MAP) inference in Bayesian
networks and LIMIDs whose decision variables have no parents. In this sense, the algorithm of de Campos (2011), which solves MAP by propagating Pareto efficient probability
potentials in a join tree, relates to ours.

6. Conclusion
Solving limited memory influence diagrams is a very hard task. The complexity results
presented here show that the problem is NP-hard even for diagrams with bounded treewidth
and number of states per variable, and that obtaining provably good approximations in
polynomial time is unlikely if the number of states is not small.
Despite the theoretical hardness of the problem, we developed an algorithm that in
spite of its exponential worst-case complexity performed empirically well on a large set of
randomly generated problems. The algorithms efficiency is based on the early removal of
suboptimal solutions, which helps the algorithm to drastically reduce the search space.
Designing good heuristics for elimination orderings with our algorithm seems to be
a more complex task than with standard variable elimination algorithms (e.g., for belief
updating in Bayesian networks), because there is a second component, the cardinality of a
set, that together with domain cardinalities we wish to minimize. In fact, some preliminary
experimentation has shown that favoring set cardinality at expense of domain cardinality
might be a good approach. Unlike standard variable elimination, given an elimination
ordering and a LIMID, it does not seem to be possible to determine the true complexity
of MPU in advance (i.e., prior to running the algorithm). It is an open question whether
MPUs complexity can be estimated beforehand, and which heuristics for finding elimination
orderings perform better.
127

fiMaua, de Campos, & Zaffalon

Acknowledgments
This work was partially supported by the Swiss National Science Foundation (SNSF)
grants no. 200020 134759/1, 200020 137680/1 and 200020 132252, Hasler Foundation grant
no. 10030, and the Canton Ticino Computational Life Sciences Project. We thank the
reviewers for pointing us to related work and making a number of comments that helped
us improve the readability of the paper. A short version of this paper appeared in NIPS
11 (Maua & de Campos, 2011).

Appendix A. Missing Proofs
This section contains long proofs and supporting results that were left out of the main part
of the text to improve readability.
The following two lemmas are used in the proof of Theorem 1 later on.
Lemma 23. If   2 is a real number and i is a nonnegative integer then 2 + 2(i+3) <
i
2+2 .
Proof. Since 2  22 , we have that 2 + 2(i+3) = 2 + 22  2i1  2 (1 + 2i1 ), and
i
it is sufficient to show that 1 + 2i1 < 22 . From the Binomial Theorem we have that
i

(1 + 2

i1 2i

)

=

2  i
X
2
k=0

k

(2i1 )k .

For k = 0, . . . , 2i , we have that
 i
2
2i (2i  1)    (2i  k + 1)
=
 (2i )k .
k
k!
Hence,
i

(1 + 2

i1 2i

)

i

2
2

X
X
X
i k i1 k
k

(2 ) (2
) =
2 
2k = 2 ,
k=0

2i

and therefore 1 + 2i1 < 2

k=0

k=0

.
4

Lemma 24. If 0  x  1/2 then 2x1 + 2x1  2x .
Proof. We obtain the result by approximating the functions on the left- and right-hand side
of the inequalities by their truncated Taylor expansions f (x) and g(x), respectively, and
4
then showing that 2x1 + 2x1  f (x)  g(x)  2x . The n-th order Taylor expansion of
the left-hand side around zero is given by
Tn (x) = 1 +

n/2
X
[ln(2)]2k
k=1

(2k)!

x2k .

Clearly, the series converges and hence 2x1 + 2x1 = limn Tn (x). Moreover, for any
n, the residual Rn (x) = 2x1 + 2x1  Tn (x) is positive because the terms of the sum are
128

fiSolving LIMIDs

all non negative. Thus,
f (x) = T2 (x) = 1 +

[ln(2)]2 2
x  2x1 + 2x1 .
2

In a similar fashion, we apply the variable change y = x4 on the right-hand side and
obtain its Taylor expansion around zero, given by
Tn0 (y) = 1 +
=1+

n
X
[ln(2)]k
k=1
n
X
k=1

k!

yk

[ln(2)]k 4k
x ,
k!

which also converges and has positive residual. Hence,
4

2x = lim Tn0 (x)
n

= 1 + x4 ln(2) + x2 ln(2)


X
[ln(2)]k1
k=2

 1 + x4 ln(2) + x2 ln(2)


X
k=2

= 1 + x4 ln(2) +

[ln(2)]2
32

1

k!
!

!
x4k2

24k1

x2 = g(x) .

The inequality is obtained by noticing that [ln(2)]k1 /k! < 1/2, x  1/2  ln(2) and that
the geometric series

X
k=2

1
24k1


 
  
1 X 1 k
1
ln(2)
1 X 1 k
< 7
= 6 <
.
= 7
4
2
2
2
2
2
32
k=0

k=0

Finally, since x2  1/4 < 15 ln(2)/32 we have that


ln(2)
2
g(x) = 1 + x ln(2) x +
32


15
ln(2)
2
< 1 + x ln(2)
ln(2) +
32
32
2
[ln(2)] 2
=1+
x = f (x) .
2
2

4

Hence, 2x  g(x)  f (x)  2x1 + 2x1 and the result holds.
The following result shows that solving LIMIDs is NP-hard even if we assume bounded
treewidth and number of states per variable.
129

fiMaua, de Campos, & Zaffalon

X0

D1

D2

X1

X2

Dn



Xn

R

Figure 8: LIMID used to solve the partition problem in the Proof of Theorem 1.

Proof of Theorem 1. Given a strategy s, deciding whether Es [L] > k can be done in polynomial time (Koller & Friedman, 2009), so the problem is in NP. Hardness is shown using
a reduction from the partition problem, which is NP-complete (Garey & Johnson, 1979)
and can be stated as follows. PGiven a set
P of n positive integers a1 , . . . , an , is there a set
I  A = {1, . . . , n} such that iI ai = iA\I ai ? We assume that n > 3.
P
P
Let a = 21 iA ai . An even partition is a subset I  A that achieves iI ai = a.
To solve partition, we consider the rescaled problem (dividing every element
by a), so that
P
vP
i = ai /a  2 are the elements and we look for a partition such that
iI vi = 1 (because
v
=
2).
iA i
Consider the following LIMID with topology as in Figure 8. There are n binary decision
nodes labeled D1 , . . . , Dn . Each decision Di can take on states d1 and d2 . The chain of
chance nodes has n + 1 ternary variables X0 , X1 , . . . , Xn with states x, y, and z. There is
an arc from Xn to the single value node R. For notational purposes, we specify a function
f over the domain {x, y, z} as a triple (f (x), f (y), f (z)). The value node has an associated
utility function uR = (0, 0, 1). For i = 1, . . . , n, each chance node Xi has an associated set
of conditional probability mass functions given by
d1 ,x
= (ti , 0, 1  ti ),
pX
i

d2 ,x
= (1, 0, 0),
pX
i

pdX1i,y = (0, 1, 0),

pdX2i,y = (0, ti , 1  ti ),

pdX1i,z = (0, 0, 1),

pdX2i,z = (0, 0, 1),
DX

for ti  [0, 1] (we specify these variables later on). Note that pXii i1 (w) = 0 for every
w  faXi such that wXi 6= wXi1 and wXi 6= z. Finally, we define pX0 = (1/3, 1/3, 1/3).
Given a strategy s = (D1 , . . . , Dn ), let I , {i : Di = d1 } be the index set of policies
in s such that Di () = d1 . We have that
Es [L] =

X

pX0

CD

n
Y

!
DX
pXii i1 pDi

i=1


=

X

X

pX0


Xn

uR

n
Y


D Xi1

pXii

i=1

CD\{Xn }

Let
ps , pX0

n
Y

D Xi1

pXii

i=1

130

pDi

pDi  uR .

fiSolving LIMIDs

and
X

pXn ,

n
Y

pX0

D Xi1

pXii

i=1

CD\{Xn }

X

pDi =

ps .

CD\{Xn }
D Xn1

For w  CD such that wXn = x (i.e., for w  xCD ) it follows that pXnn
0 if and only if wXn1 = x. But for wXn1

(wfaXn ) 6=

D
Xn2
= x we have that pXn1
(wfaXn1 ) 6= 0
n1
DX
Also, for any i  {1, . . . , n}, pXii i1 (wfaXi )

if and only if wXn2 = x and so recursively.
equals ti if i  I and 1 otherwise. Hence,
( Q
1
ti , if wXi = x for i = 1, . . . , n  1
ps (w) = 3 iI
0,
otherwise,
and

n

1Y
ti .
ps (w) =
3
CD

X

pXn (x) =

iI

wx

Likewise, it holds for w  y CD that
( Q
ps (w) =

1
3

iA\I ti ,

0,

if wXi = y for i = 1, . . . , n  1
otherwise,

and therefore
pXn (x) =

n
1 Y
ti .
3
iA\I

Since pXn is a probability mass function on Xn , pXn (z) = 1  pXn (x)  pXn (y), and
X
pXn uR
Es [L] =
Xn

= 1  pXn (x)  pXn (y)
1Y
1 Y
=1
ti 
ti .
3
3
iI

iA\I

Let us assume initially that ti = 2vi . The reduction from the original problem in
this way is not polynomial, and we will use it only as an upper bound for the outcome of
the reduction we obtain later. It is not difficult
to see
P
P that Es [L] is a concave function of
v1 , . . . , vn that achieves its maximum at iI vi = iA\I vi = 1. Since each strategy s
defines a partition of A and vice-versa, there is an even partition if and only if MEU[L] =
1  1/3(1/2 + 1/2) = 2/3.
We will now show a reduction that encodes the numbers ti in time and space polynomial
in b, the number of bits used to encode the original problem. This part is in close analogy
with the last part of the proof of hardness of MAP in Bayesian networks by de Campos
(2011, Theorem 10).
By setting ti to represent 2vi with 6b + 3 bits of precision (rounding up if necessary),
that is, by choosing ti so that 2vi  ti < 2vi + i , where 0  i < 2(6b+3) , we have that
131

fiMaua, de Campos, & Zaffalon

2vi  ti < 2vi + 2(6b+3) , which implies (by using Lemma 23 with  = vi  2 and
6b
i = 6b) that 2vi  ti < 2vi +2 .
Assume that an even partition I exists. Then8
P
Y
6b
6b
5b
ti < 22 n iI vi = 21+2 n  21+2 ,
iI

Y

6b n

t i < 22

P

iA\I

vi

6b n

= 21+2

5b

 21+2

,

iA\I

and

5b


22
1  1+25b
5b
2
+ 21+2
=1
.
MEU[L] > 1 
3
3

(6)

5b

Let r be equal to 22
encoded with 5b + 3 bits of precision (and rounded up), that is,
5b
5b
2
2
(5b+3)
2
r<2
+2
, which implies (by Lemma 24 with  = 25b  2 and i = 5b)
that
5b
5b
5b
15b
4b
22
 r < 22 +2
= 22
< 22 .
(7)
The reduction is done by verifying whether MEU[L] > 1  r/3. We already know that an
even partition has an associated strategy which obtains an expected utility greater than
1  r/3, because of Equality (6) and the fact that r is rounded up. Let us consider the
case where an even partition does not exist. We want to show that in this case MEU[L] 
4b
1  22 /3, which by Inequality (7) implies MEU[L] < 1  r/3. Since there is not an even
partition, any strategy induces
a partition such
P
P that, for some integer a  c  a different
from zero, we have that iI ai = ac and iA\I ai = a+c, because the original numbers
ai are positive integers that add up to 2a. It follows that
Y
Y
ti +
ti = 2c/a1 + 2c/a1 .
iI

iA\I

The right-hand side of the equality is a function on c  {a, . . . , a}\{0}, which is symmetric
with respect to the y-axis (i.e., f (c) = f (c)) and monotonically increasing for c > 0.
Therefore, it obtains its minimum at c = 1. Hence,
Y
Y
ti +
ti  21/a1 + 21/a1 .
iI

iA\I

Since n > 3 implies a  2 (because the numbers ai are positive integers), we have by
Lemma 24 that
4
21/a1 + 21/a1  21/a .
Each number ai is encoded with at least log2 ai bits, and therefore b  log2 (a1 ) +    +
log2 (an ) = log2 (a1    an ). The latter is greater than or equal to log2 (a1 +    + an ), and
hence is also greater than log2 a. Thus, we have that a  2b , which implies a4  24b and
4
4b
therefore 1/a4  24b and 21/a  22 . Hence,
4b

21/a1 + 21/a1  22

.

8. Since the number of bits used to encode the partition problem must be greater than or equal to n, we
have that n/2b  n/b  1, and hence 2(j+1)b n < 2jb , for any j > 0.

132

fiSolving LIMIDs

Thus, if an even partition does not exist we have that


4b
Y
22
1 Y
ti   1 
MEU[L] = 1 
ti +
< 1  r/3 .
3
3
iI

iA\I

To summarize, we have built a LIMID L in polynomial time since each ti was specified
DX
using O(b) bits and there are n functions pXii i1 , each encoding 18 numbers (which are
either 1, 0 or ti ), and 2n + 2 variables with bounded number of states. We have shown that
there is a one-to-one correspondence between partitions of A in the original problem and
strategies of L, and that for a given rational r = f (b) encoded with O(b) bits the existence
of an even partition is equivalent to MEU[L] > 1  r/3.
The following lemma is used in the proof of Theorem 2. A similar result has been shown
by Park and Darwiche (2004, Lemma 9).
Lemma 25. For any x  1 it follows that x + 1/2 > 1/ ln(1 + 1/x).
Proof. Let f (x) = ln(1 + 1/x)  1/(x + 1/2). Then
f 0 (x) = 

x2

1
1
+ 2
,
+ x x + x + 1/4

which is strictly negative for x  1 since x2 +x < x2 +x+1/4. Hence, f (x) is a monotonically
decreasing function for x  1. Because limx f (x) = 0, f (x) is strictly positive in [1, ).
Thus, the result follows from ln(1 + 1/x) > 1/(x + 1/2), since x  1.
We now show that approximately solving LIMIDs of bounded treewidth for any given
minimum performance is NP-hard.
Proof of Theorem 2. We will show that for any fixed 0 <  < 1 the existence of a polynomial

time 2 -approximation algorithm for solving a LIMID would imply the existence of a
polynomial time algorithm for the CNF-SAT problem, which is known to be impossible
unless P=NP (Garey & Johnson, 1979). A very similar reduction was used by Park and
Darwiche (2004, Theorem 8) to show an analogous inapproximability result for maximum a
posteriori inference in Bayesian networks. Notice that for any 1 <  < 2 there is 0 <  < 1

such that  = 2 , hence the existence of an -approximation algorithm implies the existence

of a 2 -approximation, and it suffices for the desired result to show that the latter cannot
be true (unless P=NP).
A clause is a disjunction of literals, each literal being either a boolean variable or its
negation. We say that a clause is satisfied if, given an assignment of truth values to its
variables, at least one of the literals evaluates to 1. Thus, we can decide if a truth-value
assignment satisfies a clause in time linear in the number of variables. The CNF-SAT
problem is defined as follows. Given a set of clauses C1 , . . . , Cm over (subsets of ) boolean
variables X1 , . . . , Xn , is there an assignment of truth values to the variables that satisfies
all the clauses?
For a positive integer q that we specify later on, consider the LIMID obtained as follows
(the topology is depicted in Figure 9). For each boolean variable Xi we add q binary
133

fiMaua, de Campos, & Zaffalon

B1
Dn1

Sn1

Dn2

Bq
Dnq

Sn2

.
.
.
D11



B2

.
.
.

S11

D12

Snq

.
.
.
D1q

S12

S01

U

S1q
S0q

S02

Figure 9: Graph structure of the LIMID used in the proof of Theorem 2.

decision variables Di1 , . . . , Diq and q chance variables Si1 , . . . , Siq with domain {0, 1, . . . , m}.
Additionally, there are q clause selector variables S01 , . . . , S0q taking values on {1, 2, . . . , m},
q binary variables B 1 , . . . , B q , and a value node U with B q as parent. As illustrated in
Figure 9, the LIMID consists of q replicas of a polytree-shaped diagram over variables
D1j , . . . , Dnj , S0j , . . . , Snj , B j , and the probability mass functions for the variables B 1 , . . . , B q
are chosen so as to make the expected utility equal the product of the expected utilities of
each replica. In any of the replicas (i.e., for j  {1, . . . , q}), a variable Dij (i = 1, . . . , n)
represents an assignment of truth value for Xi and has no parents. The selector variables
S0j represent the choice of a clause to process, that is, S0j = k denotes clause Ck is being
processed, and by summing out S0j we process all clauses. Each variable Sij , for i =
j
1, . . . , n and j = 1, . . . , q, has Dij and Si1
as parents. The variables B j have Snj and, if
j > 1, B j1 as parents. For all j, we assign uniform probabilities to S0j , that is, pS j , 1/m.
0

For j = 1, . . . , q, we set the probabilities associated to variables S1j , . . . , Snj so that if Ck is
the clause selected by S0j then Sij is set to zero if Ck is satisfied by Di but not by any of
j
D1 , . . . , Di1 , and Sij = Si1
otherwise. Formally, for x  {S j ,Dj ,S j } we have that
i



1,




j j
D S
1,
p ji i1 (x) ,
Si
1,




0,

i

i1

j

j

if xSi = xSi1 = 0 ;
j

j

if xSi = 0 and xSi1 = k  1 and Xi = xDi satisfies Ck ;
j

j

if xSi = xSi1 = k  1 and Xi = xDi does not satisfy Ck ;
otherwise.

Notice that for S1j the first case never occurs since S0j takes values on {1, . . . , m}. For any
j
joint state configuration x of S0j , . . . , Snj , D1j , . . . , Dnj such that xS0 = k  {1, . . . , m} (i.e.,
j
clause Ck is being processed) and xSn = 0, it follows that
!
n
j
Y
Dij Si1
pS j
p j
pDj (x)
0

i=1

Si

i

equals 1/m only if for some 0 < i  n clause Ck is satisfied by Xi = xDi but not
j
by any of X1 = xD1 , . . . , Xi1 = xDi1 , variables S1j , . . . , Si1
all assume value k (i.e.,
134

fiSolving LIMIDs

j

j

j

j

xS1 =    = xSi1 = k), and xSi =    = xSn = 0. Otherwise, it equals 0. Hence, for
any (partial) strategy sj = (Dj , . . . , Dnj ) we have for x = 0 that
1




j
psS j (x)
n

 X

,

S j ,...,S j

pS j

0

n1

0

n
Y
i=1

j
Dij Si1

p

Sij



SAT (sj )
pD j 
(x)
=
,
i
m


j
D1j ,...,Dn

where SAT (sj ) denotes the number of clauses satisfied by the truth-value assignment of
j

Sn B
X1 , . . . , Xn according to sj . Each variable B j is associated to a function pB
j
for x  faBj ,

j
B j = xB j1 and xSn

= 0;
1, if x
j j1
j
j
pSBnj B (x) = 1, if xB = 0 and xSn 6= 0 ;


0, otherwise;

j1

such that

0

where for B 1 we assume xB = 1. Hence, we have for any joint state configuration x of
B 1 , . . . , B q , Sn1 , . . . , Snq that

q
1
B 1 =    = xB q = 1 and xSn

=    = xSn = 0;
1, if x
j j1
1
q
1

pSBnj B  (x) = 1, if xB =    = xB = 0 and xSn 6= 0;


j=1
0, otherwise.




q
Y

Finally, we set the utility functionu associated to U to return 1 if B q = 1 and 0
j j1
Q
1
q
1
otherwise. In this way, u qj=1 pSBnj B
(x) equals 1 if xB =    = xB = 1 and xSn =
q

   = xSn = 0 and zero otherwise. Thus, for any strategy s = (s1 , . . . , sq ), where sj =
Dj , . . . , Dnj , it follows that
1

Es [L] =

X

u

CD

=

q
Y

u

B 1 ,...,B q
1 ,...,S q
Sn
n

=

=

j1

pS j

0

j=1

X

X

j

pSBnj B
q
Y

j

pSBnj B

u

B 1 ,...,B q j=1
1 ,...,S q
Sn
n
q
Y
j
psS j (0) =
n
j=1

i=1

j1

j=1

q
Y

n
Y

p

j
Dij Si1

Sij

X

i

pS j

j
S0j ,...,Sn1
j
j
D1 ,...,Dn
j

Sn B
pB
j

j1

pD j

0

n
Y
i=1

p

j
Dij Si1

Sij

pD j
i

j

psS j

n

q
1 Y
SAT (sj ) .
mq
j=1

If the instance of CNF-SAT problem is satisfiable then there is an optimum strategy s
such that SAT (sj ) = m for all j, and MEU[L] = 1. On the other hand, if the instance
135

fiMaua, de Campos, & Zaffalon

is not satisfiable, we have for all j and strategy s that SAT (sj )  m  1, and hence
MEU[L]  (m  1)q /mq . For some given 0 <  < 1, let q be a positive integer chosen so

that 1/2 > mq /(m + 1)q . We show later on that q can be obtained from a polynomial

on the input. If the CNF-SAT instance is satisfiable, a 2 -approximation algorithm for
MEU[L] returns a value Es [L] such that
q 


m1 q
MEU[L]
m
>
,
Es [L] 
>
m+1
m
2 
where the rightmost strict inequality follows from m/(m + 1) > (m  1)/m. On the other
hand, if the CNF-SAT instance is not satisfiable, the approximation returns


m1 q
Es [L]  MEU[L] 
.
m


Hence, we can use a 2 -approximation algorithm to solve CNF-SAT by checking whether its
output E[L] > (m1)q /mq . Since q and m are positive integers, the test bound (m1)q /mq
can be obtained in polynomnial time.
It remains to show that the reduction is polynomial in the input. The LIMID contains
q(2n + 2) + 1 variables, each requiring the specification of at most 2(m + 1)2 numbers in
{0, 1/m, 1}. So , the number of numerical parameters in L, is polynomially bounded by
q(m + 1)2 (4n + 4) + 2. Therefore, it suffices to show that q is a polynomial on m and n. By
definition, q obeys


1 q
2

1+
> 2[q(m+1) (4n+4)+2] ,
m
which is equivalent to


1
q ln 1 +
m



> q  [(m + 1)2 (4n + 4) + 2] ln 2

[(m + 1)2 (4n + 4) + 2]

ln 2
1
ln 1 + m
! 1
1
[(m + 1)2 (4n + 4) + 2]

ln 2
1
ln 1 + m

 q 1 >

q>

Since (by Lemma 25) m + 1/2 > 1/ ln(1 + 1/m) and 2 > ln(2), it suffices to choose q such
that
 1
q > (2m + 1)[(m + 1)2 (4n + 4) + 2] 1 .
2+1



In other words, q is polynomially bounded by m 1 4n 1 . Therefore, if MEU[L] can

be approximated in polynomial time with an ratio no greater than 2 then we can solve
CNF-SAT in polynomial time.
The next result show that Transformation 6 preserves expected utility of strategies, and
that strategies can be easily mapped back and forward between original and transformed
diagrams.
136

fiSolving LIMIDs

paD =  j

X1

X2

T1

T2



Xj1

Xj

Xj+1

Tj1

Tj

Tj+1



Xm

chD

Tm

Figure 10: Reasoning of the proof of Transformation 6.

T ,pa

X

,T ,pa

Proof of Proposition 7. By looking at the definition of the functions pX11 D and pXii1 i D ,
for i = 2, . . . , m, we can see that when paD selects  j , that is, conditional on paD =  j ,
the variable Xj is independent of Xj1 and for i = 1, . . . , m, i 6= j, the variable Xi is
independent of Ti . In other words, we have that
T

Pr(Xj |Xj1 , Tj , paD =  j ) = Pr(Xj |Tj , paD =  j ) , pXjj .
and, for any i 6= j,
X

Pr(Xi |Xi1 , Ti , paD =  j ) = Pr(Xi |Xi1 , paD =  j ) , pXii1 .
We can visualize this situation by removing the arc from Xj1 to Xj and all the arcs from
Ti to Xi for i 6= j in the diagram of Figure 2(b) (the arcs leaving paD can also be removed
as we are conditioning on a value of paD ), which results in the diagram in Figure 10. Note
that in principle the case for j = 1 deserves special attention, as the X1 does not depend
on any other Xi variable, and the function associated to X1 slightly differ from others.
Nevertheless, a similar reasoning can be applied. We will omit the case for j = 1 for the
sake of simplicity.
It follows from the previous reasoning that


pXjm , Pr(Xm |paD =  j )
m
X
X
Y
T
X
=
(pX1 pT1 )(pXjj pTj )
pXii1 pTi
T1 ,...,Tm X1 ,...,Xm1

=

X

pTj

Tj

X

i=2,i6=j
T

pXjj

m
Y

X

i=j+1

Xj ,...,Xm1

X

pXi1
i

X1 ,...,Xj1

|
=

X
Tj

pTj

X
Xj ,...,Xm1

T

pXjj

m
Y

X

pXii1 .

i=j+1

137

pX1

j1
Y

X

pXi1
i

i=2

X

m
Y

pTi

T1 ,...,Tm \Tj i=1,i6=j

{z

=1

}

fiMaua, de Campos, & Zaffalon

X

When paD =  j , each function pXi1
for i 6= j equals the indicator function IXi =Xi1 , by
i
T

design, and pXjj = IXj =Tj . We thus have that

pXjm

=

X

X

pTj

Tj

m
Y

IXj =Tj

IXi =Xi1 .

i=j+1

Xj ,...,Xm1

For each term of the outer sum over Tj , the inner sum over Xj , . . . , Xm1 differs from zero
only when Tj = Xj = Xj+1 =    = Xm , in which case it equals one. Hence, we have that
X

pXjm =
pTj IXm =Tj
Tj

= pTj .
pa

Now consider a strategy s0 = (T1 , . . . , Tm , . . . ) for L0 , and let pXmD be a function that

equals pXjm for every value  j  paD . Let also D be a policy for the original decision
variable D in L such that D ( j ) = Tj for all j, and s be a strategy for L obtained by
substituting policies T1 , . . . , Tm with D in s0 . Finally, let pT1 , . . . , pTm be the distributions
pa
induced by the policies for T1 , . . . , Tm in s0 , and pD D be the distribution induced by D .
paD
Since for each value  j of paD we have that pXm ( j ) = pTj , and since by design Xm = D ,
pa
pa
it follows that pXmD = pD D . Hence, for each combination of policies T1 , . . . , Tm in L0 we
can derive a corresponding policy in L. The converse is also true: for each policy D we can
pa
pa
generate T1 , . . . , Tm such that pXmD = pD D (simply choose Ti = D ( j ) for all i). Thus,
there is a one-to-one correspondence between policies T1 , . . . , Tm and policies D , and a
pa
pa
one-to-one correspondence between the induced functions pXmD and pD D .
It remains to show that a combination of policies T1 , . . . , Tm and a corresponding policy
D induce the same expected utility. Let C 0 and D0 denote, respectively, the set of chance
and decision variables in L0 , and C and D the set of chance and decision variables in L.
Also, for a given strategy s for L, let
Y
pa
p0s ,
pX X .
CD\{D}
pa

Note that the above function is independent of the choice of policy D , and that ps = p0s pD D .
Given any strategy s0 for L0 we have that
X
X
Es0 [L0 ] =
ps0
uV
C 0 D0

=

X

V V

p0s

T ,pa
pX11 D

C 0 D0

m
Y

X
,T ,pa
pXii1 i D

i=2

m
Y

!
pTi

=

p0s

X

uV

V V

CD\{D}

X X
C 0 \C D0 \D

X

X

CD\{D} Xm

pa

pXmD p0s

X

m
Y

X

pXii1

i=2

{z

|
=

T ,paD

pX11

uV

V V

i=1

!
X

X

P
paD
= Xm pXm

uV

V V

138

,Ti ,paD

m
Y

pTi

i=1

}

fiSolving LIMIDs

=

X

X

pa

pD D p0s

X

ps

CD

X

uV

V V

CD\{D} D

=

X

uV

V V

= Es [L] ,
where s is the strategy for L obtained from s0 by substituting T1 , . . . , Tm with the corresponding policy D .

References
Bodlaender, H. L. (1996). A linear-time algorithm for finding tree-decompositions of small
treewidth. SIAM Journal on Computing, 25 (6), 13051317.
Cooper, G. F. (1988). A method for using belief networks as influence diagrams. Fourth
Workshop on Uncertainty in Artificial Intelligence.
de Campos, C. P. (2011). New results for the MAP problem in Bayesian networks. In
Proceedings of the 22nd International Joint Conference on Artificial Intelligence, pp.
21002106.
de Campos, C. P., & Ji, Q. (2008). Strategy selection in influence diagrams using imprecise probabilities. In Proceedings of the 24th Conference in Uncertainty in Artificial
Intelligence, pp. 121128.
Dechter, R. (1999). Bucket elimination: A unifying framework for reasoning. Artificial
Intelligence, 113 (1-2), 4185.
Detwarasiti, A., & Shachter, R. D. (2005). Influence diagrams for team decision analysis.
Decision Analysis, 2, 207228.
Dubus, J.-P., Gonzales, C., & Perny, P. (2009). Multiobjective optimization using GAI
models. In Proceedings of the 21st International Joint Conference on Artificial Intelligence, pp. 19021907.
Fargier, H., Rollon, E., & Wilson, N. (2010). Enabling local computation for partially
ordered preferences. Constraints, 15, 516539.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the Theory
of NP-Completeness. W. H. Freeman.
Haenni, R. (2004). Ordered valuation algebras: a generic framework for approximating
inference. International Journal of Approximate Reasoning, 37 (1), 141.
Howard, R. A., & Matheson, J. E. (1984). Influence diagrams. In Readings on the Principles
and Applications of Decision Analysis, pp. 721762. Strategic Decisions Group.
Jensen, F. V., & Nielsen, T. D. (2007). Bayesian Networks and Decision Graphs (2nd
edition). Information Science and Statistics. Springer.
Kohlas, J. (2003). Information Algebras: Generic Structures for Inference. Springer-Verlag,
New York, USA.
139

fiMaua, de Campos, & Zaffalon

Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles and Techniques. MIT Press.
Lauritzen, S. L., & Nilsson, D. (2001). Representing and solving decision problems with
limited information. Management Science, 47, 12351251.
Maua, D. D., & de Campos, C. P. (2011). Solving decision problems with limited information. In Advances in Neural Information Processing Systems 24, pp. 603611.
Maua, D. D., de Campos, C. P., & Zaffalon, M. (2011). Solving limited memory influence
diagrams. ArXiv:1109.1754v2 [cs.AI].
Park, J. D., & Darwiche, A. (2004). Complexity results and approximation strategies for
MAP explanations. Journal of Artificial Intelligence Research, 21, 101133.
Poupart, P., & Boutilier, C. (2003). Bounded finite state controllers. In Advances in Neural
Information Processing Systems 16 (NIPS).
Pralet, C., Verfaillie, G., & Schiex, T. (2007). An algebraic graphical model for decision with
uncertainties, feasibilities, and utilities. Journal of Artificial Intelligence Research, 29,
421489.
Qi, R., & Poole, D. (1995). A new method for influence diagram evaluation. Computational
Intelligence, 11, 498528.
Shachter, R. D., & Peot, M. A. (1992). Decision making using probabilistic inference methods. In Proceedings of the 8th Conference on Uncertainty in Artificial Intelligence,
pp. 276283.
Shenoy, P., & Shafer, G. (1990). Axioms for probability and belief-function propagation.
In Proceedings of the 4th Conference on Uncertainty in Artificial Intelligence, pp.
169198.
Zhang, N. L., Qi, R., & Poole, D. (1994). A computational theory of decision networks.
International Journal of Approximate Reasoning, 11 (2), 83158.

140

fi