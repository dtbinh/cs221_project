Journal of Artificial Intelligence Research 57 (2016) 39-112

Submitted 4/16; published 9/16

PDT Logic: A Probabilistic Doxastic Temporal Logic for
Reasoning about Beliefs in Multi-agent Systems
Karsten Martiny
Ralf Moller

karsten.martiny@uni-luebeck.de
moeller@uni-luebeck.de

Institute of Information Systems,
Universitat zu Lubeck
Lubeck, Germany

Abstract
We present Probabilistic Doxastic Temporal (PDT) Logic, a formalism to represent
and reason about probabilistic beliefs and their temporal evolution in multi-agent systems.
This formalism enables the quantification of agents beliefs through probability intervals
and incorporates an explicit notion of time. We discuss how over time agents dynamically
change their beliefs in facts, temporal rules, and other agents beliefs with respect to any
new information they receive. We introduce an appropriate formal semantics for PDT Logic
and show that it is decidable. Alternative options of specifying problems in PDT Logic
are possible. For these problem specifications, we develop different satisfiability checking
algorithms and provide complexity results for the respective decision problems. The use
of probability intervals enables a formal representation of probabilistic knowledge without
enforcing (possibly incorrect) exact probability values. By incorporating an explicit notion
of time, PDT Logic provides enriched possibilities to represent and reason about temporal
relations.

1. Introduction
Logical analysis of knowledge and belief has been an active topic of research in diverse fields
such as philosophy (Hintikka, 1962), economics (Aumann, 1976), game theory (Harsanyi,
1967, 1968a, 1968b), and computer science (Fagin, Halpern, Moses, & Vardi, 1995). Numerous extensions to modal epistemic logic have been made to reason about knowledge in
multi-agent settings (Fagin et al., 1995; Baltag & Moss, 2004), to add probabilistic knowledge (Fagin & Halpern, 1994; Cripps, Ely, Mailath, & Samuelson, 2008), and to analyze
the dynamic evolution of knowledge (van Ditmarsch, van der Hoek, & Kooi, 2007).
In most realistic scenarios, an agent has only incomplete and inaccurate information
about the actual state of the world, and thus considers several different worlds as actually
being possible. As it receives new information (e.g., it observes some facts that currently
hold), it has to update its beliefs about possible worlds such that they are consistent with
this new information. These updates can for example result in regarding some (previously
considered possible) worlds as impossible or judging some worlds to be more likely than
before. Thus, in addition to analyzing the set of worlds an agent believes to be possible,
it is also useful to quantify these beliefs in terms of probabilities. This provides means to
specify fine-grained distinctions between the range of worlds that an agent considers possible
but highly unlikely, and worlds that seem to be almost certainly the actual world.
c
2016
AI Access Foundation. All rights reserved.

fiMartiny & Moller

When multiple agents are involved in such a setting, an agent may not only have varying
beliefs regarding the facts of the actual world, but also regarding the beliefs of other agents.
In many scenarios, the actions of one agent will not only depend on its belief in ontic facts
(i.e., facts of the actual world), but also on its beliefs in some other agents beliefs.
To illustrate how reasoning about other agents beliefs can yield significant advantages
in practical scenarios, we start with the following informal description of an application
from the cyber security domain (a formal analysis of this example using PDT Logic has
been presented by Martiny, Motzek, & Moller, 2015): Suppose that an adversary is trying
to break into a computer system. This is usually done with an attack graph to detect
and exploit potential vulnerabilities of the system. An attack graph specifies a set of
paths (i.e., sequences of actions) to carry out an attack. Several paths of the attack graph
might be used in parallel, potentially by different agents (for instance, a number of infected
computers controlled by a botnet). Usually, attack patterns specified by one attack graph
are used multiple times, which has two important ramifications: the adversary will learn
from experience which of the paths yield a high probability of successfully breaking into a
system. Defenders in turn will be able to gain knowledge of the attack graph through the
repeated observation of certain patterns. Thus, when a system is under attack, the defender
will have beliefs about both the chosen attack paths and the adversarys belief regarding the
success of the respective path. Thus, the defender can choose countermeasures effectively
by reacting only on paths where these nested beliefs are high and which indeed pose a threat
according the systems mission impact model.
To formalize reasoning about such beliefs in multi-agent settings, we present Probabilistic Doxastic Temporal (PDT) Logic. PDT Logic builds upon recent work on Annotated
Probabilistic Temporal (APT) Logic (Shakarian, Parker, Simari, & Subrahmanian, 2011;
Shakarian, Simari, & Subrahmanian, 2012) and provides a formalism which enables representing and reasoning about dynamically changing quantified temporal multi-agent beliefs
through probability intervals and incorporates a subset of epistemic actions (Baltag & Moss,
2004). Using concepts from APT Logic as a semantic foundation, PDT Logic merges work
on epistemic logic with recent work on temporal logic by Shakarian et al. Apart from
reasoning about imprecise probabilities, this introduces the temporal concept of frequency
functions into epistemic temporal logic.
Quantifying probabilistic knowledge through probability intervals instead of single probability values yields two main advantages. On the one hand, using probability intervals
significantly eases the task of formally representing existing knowledge of a human domain
expert. In most cases, a domain expert can give reasonable probability estimates of her
knowledge, but will inevitably fail at giving correct precise numerical values on these probabilities. Consider for instance a weather forecast: most people find it easy to give coarse
probabilistic quantifications such as the chance of rain is high, while virtually nobody
could quantify this through an exact numerical value. Employing exact numerical values
in a formal representation would then inevitably introduce errors in the probability model.
Thus, the use of probability intervals provides means to express probabilistic knowledge as
precisely as possible without enforcing unrealistic precision. On the other hand, there are
many scenarios where probabilities (and even rough estimates of them) are simply unavailable, while bounds on these values may be known. To illustrate this, consider the scenario
described by Ellsberg (1961):
40

fiPDT Logic

Example 1.1 (The Ellsberg paradox, Ellsberg, 1961). Imagine an urn known to contain
30 red balls and 60 black and yellow balls, the latter in unknown proportion. One ball is
to be drawn at random from the urn; the following actions are considered: Action I is a
bet on red, II is a bet on black.
Now, it is easy to see that any rational agent would believe that action I will be successful
with a probability of 1/3. For action II, no such quantification is possible because the
respective probability is unknown. Yet omitting any probabilistic information about action
II altogether would ignore some available information about the unknown probability value,
namely that it is somewhere between 0 and 2/3. This example exhibits two different types
of uncertainty: the former action is subject to risk, i.e., the outcome is unknown, but
occurs with known probability, while the later action is subject to ambiguity (also known
as Knightian uncertainty), where the probability is unknown (Bradley, 2015). Through
probability intervals, PDT Logic is able to work with such imprecise probabilities. The
width of a probability interval can then give additional information about the certainty of a
probability quantification. Naturally, a narrow interval is associated with a high certainty
of the respective probability and vice versa, a wide interval is associated with low certainty.
PDT Logic employs an explicit notion of time and thereby facilitates the expression
of richer temporal relations. This allows for the analysis of temporal doxastic problems
beyond the scope of previous work. The resulting framework provides means to reason
about the temporal evolution of beliefs in multi-agent systems. Two different applications
of this framework are possible: First, any agent of the respective multi-agent system can
employ this framework online during a run of the system to reason about its own beliefs.
By analyzing nested beliefs as introduced above, this gives an agent also means to reason
about probable evolutions of other agents belief states. Second, this framework can be used
offline by an external observer to analyze whether desired evolutions of a given system are
possible.
The remainder of this work is structured as follows: The next section presents related
work about knowledge in multi-agent systems and APT Logic. Then, in Section 3, the
syntax of PDT Logic is introduced, followed by the definition of a formal semantics. Decision
algorithms and complexity results for PDT Logic are discussed in Section 4. While the
formally defined semantics is based on precise probability values, this section shows that
satisfiability in PDT Logic can be decided even if only imprecise probabilities are given.
Finally, the paper concludes with Section 5.

2. Related Work
Approaches to formalize reasoning about knowledge and belief date back to Hintikkas work
on epistemic logic (Hintikka, 1962). Hintikka proposed to represent knowledge through sets
of states or worlds, together with a binary relation for every agent, to determine which worlds
are indistinguishable for an agent. This approach has sparked multiple branches of research
on epistemic logic, which are still active topics of research today. These branches of research
can be broadly classified into four (not mutually exclusive) areas that are relevant for our
work: multi-agent epistemic logic, probabilistic epistemic logic, epistemic temporal logic,
41

fiMartiny & Moller

and dynamic epistemic logic.1 In the following, we give an overview of the key contributions
in each area and discuss existing approaches that merge these fields of research.
Early research on epistemic logic culminated in the influential work Reasoning about
Knowledge (Fagin et al., 1995), which provides a unified presentation of various preceding
contributions on epistemic logic. This work uses a so-called interpreted systems approach
to represent knowledge in multi-agent systems, where time is represented through runs. A
run is a sequence of a systems global states and it thus identifies the state of a system
for every time point. Among other contributions, this work provides notions for multiagent epistemic modalities such as nested knowledge, distributed knowledge, and common
knowledge.
Several works have extended epistemic logic to represent dynamic evolutions of knowledge. This direction of research is known as Dynamic Epistemic Logic (DEL). A first formal
analysis of the dynamics of knowledge has been presented by Plaza (1989; reprinted as Plaza,
2007). In this contribution, Plaza introduces public communication events (now commonly
known as public announcements) to analyze the dynamic evolution of knowledge in groups
upon truthful public announcements of facts to a group of agents. Independently from
Plaza, a related approach for a public announcement logic was proposed by Gerbrandy and
Groeneveld (1997). Baltag, Moss, and Solecki (1998) and Baltag and Moss (2004) generalize the dynamic approach to epistemic logic to incorporate a variety of complex epistemic
actions. Here, epistemic updates themselves are represented through Kripke models. This
extends dynamic epistemic logic to represent a variety of additional epistemic actions such
as private group announcements (i.e., announcements where agents outside of the receiving
group are unaware of this announcement), lies (i.e., untruthful announcements), and combinations thereof. In PDT Logic, we use public and private group announcements, but we
assume that all announcements are truthful. A thorough treatment of dynamic epistemic
logic is given by van Ditmarsch et al. (2007). Van Eijck (2014) provides a recent overview
of this field.
An alternative approach of modeling the evolution of knowledge is to combine epistemic
logic with some temporal system. One example for this are the aforementioned interpreted
systems from Fagin et al. (1995). Another approach of modeling temporal aspects in epistemic logic was proposed by Parikh and Ramanujam (2003). This approach is known as
Epistemic Temporal Logic (ETL). Here, possible situations are represented through sets of
histories, with local histories for every agent, which represent the respective agents previous
observations. Based on these histories, knowledge based semantics of messages are defined,
and it is shown that messages can vary in meaning, depending on the respective context
of the messages receiver. The temporal model we employ in PDT Logic is closely related
to epistemic temporal logic. Instead of specifying local histories for every agent, we define
the semantics of PDT Logic with respect to a global history. However, the local contexts
1. To simplify the following discussion, we do not explicitly distinguish between epistemic and doxastic
logics in this section, but use epistemic as a general term. Strictly speaking, epistemic formalisms
deal with knowledge, while doxastic formalisms deal with beliefs. The usual axiomatic definition of
knowledge in the literature uses the Truth Axiom, which stipulates that an agent can only know true
facts. Omitting this axiom then leads to the notion of belief. Even though not unanimously accepted
(cf. e.g., Halpern, Samet, & Segev, 2009), this axiom is usually considered as the key distinction between
knowledge and belief.

42

fiPDT Logic

in the sense of ETL can easily be extracted from the global history by filtering this history
for the respective agents observations.
The traditional work on epistemic logic discussed so far does not allow to quantify an
agents degree of belief in certain facts; it can only be specified whether an agent does or
does not know (resp. believe) some fact. To remove this limitation, several approaches have
been proposed to combine logics of knowledge and belief with probabilistic quantifications.
Fagin and Halpern (1994) laid the foundation for this combination in their seminal paper.
They define a belief operator to quantify lower bounds on the probabilities that an agent
assigns to a formula. This is modeled by associating a probability space with each state
and each agent. In their framework, it is generally not guaranteed that formulae define
measurable sets, but they present some properties that can guarantee the measurability of
such sets. In contrast, the semantics defined for PDT Logic always produces events with
measurable probabilities. A special case of the framework introduced by Fagin and Halpern
is presented by Milch and Koller (2000). Just as in PDT Logic, in this formalism it is
assumed (i) that there exists a common prior probability distribution over the set of worlds
and (ii) that each agents local probability distribution at some world is derived from the
global distribution conditioned on the respective set of worlds the agent considers possible.
The additional feature from Milch and Koller is that models are represented as Bayesian
networks to find the probabilities of defined formulae. Van der Hoek (1997) introduces the
logic PF D, which was later extended by de Carvalho Ferreira, Fisher, and van der Hoek
(2008). Like Fagin and Halpern, this framework introduces an operator to quantify the
lower bounds of probabilistic beliefs. Probabilistic values in this work are semantically
restricted to a finite base set of probability values, yielding a logically compact framework
that enables efficient implementations.
A variety of approaches have been proposed to extend probabilistic epistemic logics
to dynamic frameworks: Kooi (2003) restricts the probabilistic epistemic logic from Fagin
and Halpern (1994) to finite settings and combines it with the dynamic epistemic logic
from Gerbrandy and Groeneveld (1997) to create Probabilistic Dynamic Epistemic Logic
(PDEL). This work analyzes the effects on probabilistic beliefs upon public announcements.
As this framework is based on dynamic epistemic logic, it does not have capabilities to
represent temporal relationships; features regarding the past cannot be expressed at all,
and features regarding the future can only be expressed to a limited extent as the result
of certain actions. Van Benthem (2003) extends this framework to analyze the results of
various epistemic actions as described by Baltag et al. (1998). Another extension to this
framework is proposed by van Benthem, Gerbrandy, and Kooi (2009b), where different
sources of probabilities are distinguished. A simplification of this approach is presented by
van Eijck and Schwarzentruber (2014). This paper distinguishes itself from the above work
on probabilistic epistemic logic in that certainty is equated with knowledge. Other works
make an explicit distinction between belief with probability 1 and knowledge. The difference
between these two concepts is often illustrated with repeatedly throwing a fair coin: the
event that the coin shows head at least once is 1 for an infinite number of repetitions.
Yet no agent can know in this example that the coin will eventually show head. As PDT
Logic works only with countable models in finite time frames, we can adopt the view from
van Eijck and Schwarzentruber and consider certainty and knowledge as equivalent in our
models. Deviating from these approaches to extend epistemic logic with probabilities, PDT
43

fiMartiny & Moller

Logic provides a belief operator with probability interval quantifications, so that both lower
and upper bounds on the probability values can be specified explicitly. This provides a
natural means to represent imprecise probabilities as discussed in the introduction.
Another direction of probabilistic extensions is discussed by Halpern and Pucella (2006)
and Doder, Markovic, Ognjanovic, Perovic, and Raskovic (2010), for example. These approaches consider the problem of estimating unknown prior probabilities based on given
evidence. Essentially, the unknown priors are then represented as a set of hypotheses, and
the likelihood of a hypothesis given specific observations is estimated. In these approaches,
all hypotheses represent possible configurations of the world and are thus satisfiable. In
contrast, the aim of PDT Logic is to verify whether any possible assignment of priors exists
such that a given set of formulae is satisfiable.
In dynamic epistemic logic, it is only possible to reason about step-wise changes in
the future. In order to reason about temporal relations, Sack (2008) extends the update
mechanism of dynamic epistemic logic with temporal operators, namely previous-time and
next-time operators. Sack (2009) further extends this approach to probabilistic frameworks by augmenting the work on probabilistic dynamic epistemic logic (Kooi, 2003) with
a previous-time operator and the ability to reason about continuous probabilities. These
approaches enrich dynamic epistemic logic with the ability to reason about events in the
past. Van Benthem, Gerbrandy, Hoshi, and Pacuit (2009a) give a systematic and precise
comparison between ETL (called TEL by van Benthem, Gerbrandy, Hoshi, and Pacuit) and
DEL and it is shown how these approaches can be merged into a single framework.
Shakarian et al. (2011) and Shakarian et al. (2012) introduce APT Logic, a framework
to represent probabilistic temporal evolutions of worlds in threads. APT Logic assigns
prior probabilities to every thread and uses these probabilities to determine probabilities
of events occurring in specific threads. To represent temporal relationships between events,
APT Logic introduces the concept of frequency functions. We utilize the approach of APT
Logic to create a doxastic multi-agent framework that supports explicit reasoning about
temporal relationships through the adoption of frequency functions. While the explicit
notion of time in our formalism increases the complexity of decision problems, it significantly
enhances the expressibility of temporal relations. For instance, in contrast to all approaches
with implicit representations of time, in PDT Logic we are able to specify that events occur
within a certain time interval (cf. the introduction of frequency functions below).

3. PDT Logic: Syntax and Semantics
In this section, we discuss how beliefs in multi-agent systems can be formalized. We start
with defining the syntax of PDT Logic, discuss the employed model of time, and provide
a formal semantics. The proposed formalism enables the expression of different types of
beliefs and can quantify these beliefs using imprecise probabilities. By introducing a suitable
update rule we show how agents beliefs evolve over time and how agents can update their
beliefs such that new information is correctly integrated into their belief state.
44

fiPDT Logic

3.1 Syntax
We assume the existence of a function-free and quantifier-free fragment of first order logic2
language L with finite sets of constant symbols Lcons and predicate symbols Lpred , and an
infinite set of variable symbols Lvar . Every predicate symbol p  Lpred has an arity. A term
is any member of the set Lcons  Lvar . A term is called a ground term if it is a member
of Lcons . If t1 , .., tn are (ground) terms, and p is a predicate symbol in Lpred with arity n,
then p(t1 , ..., tn ) is a (ground) atom. If a is a (ground) atom, then a and a are (ground)
literals. The former is called a positive literal, the latter is called a negative literal. The set
of all ground literals is denoted by Llit . As usual, B denotes the Herbrand Base of L, i.e.,
the set of all ground atoms that can be formed through from Lpred and Lcons .
Time is modeled in discrete steps and we assume that all agents reason about an arbitrarily large, but fixed-size window of time. The set of time points is given by  = {1, ..., tmax }.
The set of agents is denoted by A. Again, we assume that this set may be arbitrarily large,
but of finite size. To describe what agents observe, we define observation atoms as follows.
Definition 3.1 (Observation atoms). For any non-empty group of agents G  A and
ground literal l  Llit , ObsG (l) is an observation atom. The set of all observation atoms is
denoted by Lobs .
Intuitively, the meaning of a statement of the form ObsG (l) is that all agents in the group
G observe that the fact l holds. Note that l may be a negative literal and therefore we can
explicitly specify observations of certain facts being false (such as it is not raining). We
assume that the agents in G not only observe that l holds, but that each agent in G is also
aware that all other agents in G make the same observation. In the line of Baltag and Moss
(2004), observations can be viewed as the effects of private group announcements of a fact
l to a group G (i.e., l becomes common knowledge within G, while all agents outside of G
remain entirely oblivious of the observation): it represents an epistemic action, i.e., it alters
the belief states of all agents in G (as formally defined below), but does not influence the
ontic facts of the respective world.
Definition 3.2 (Formulae). Both atoms and observation atoms are formulae. If F and G
are formulae, then F  G, F  G, and F are formulae. A formula is ground if all atoms of
the formula are ground.
Example 3.1 (Coin toss). Consider two agents 1, 2 and a coin that is tossed. The event
that the coin lands heads is denoted by the primitive proposition Head, and accordingly,
the coin lands tails is denoted by Head. Let us assume that the coin actually lands heads.
Then, all sets of possible observations in this scenario are {Obs{1} (Head)}, {Obs{2} (Head)},
{Obs{1} (Head), Obs{2} (Head)}, {Obs{1,2} (Head)}.
Note that there is a difference between the third and the fourth set: in the former
scenario, both agents observe the outcome of the coin throw but both are unaware that the
other agent actually made the same observation. In the latter scenario, both agents observe
the outcome and are aware that the other agent observes the same. Since we do not allow
2. We use a first order structure for our language definition to have a syntactically convenient way of
representing observations. Apart from this, propositional logic could be used as a base language.

45

fiMartiny & Moller

for nesting of observations (i.e., expressions such as ObsG1 (ObsG2 (l))) in PDT Logic, only
a subset of the epistemic actions discussed by Baltag and Moss (2004) can be represented
in our formalism. While this limits the expressivity of epistemic actions to some extent, we
can ensure that the resulting set of possible observations Lobs is always finite and therefore
we can show that PDT Logic is decidable (as shown in Section 4). Further, note that the
formal concept of observations is not limited to express passive acts of observing facts, but
can instead be used to model a wide range of actions: for instance, in the above example
one could also use Obs{1,2} (Head) to model the act of one agent telling the other about
the outcome of the coin throwthe ramifications of the communication act are exactly the
same as they would be in a shared observation (assuming that agents do not lie).
To express temporal relationships, we define temporal rules following the approach of
APT rules from Shakarian et al. (2011). The definition of temporal rules already relies on
the concept of frequency functions, even though these are defined in the next section. We
still introduce temporal rules now to enable a clearly separated presentation of syntax and
semantics of PDT Logic.
Definition 3.3 (Temporal rules). Let F, G be two ground formulae, t a time interval,
fr (F, G)
and fr a name for a frequency function (as defined below in Section 3.2.5). Then rt
is called a temporal rule.
Frequency functions provide information about temporal connections between events.
fr (F, G) is to be understood as F is followed by G in t
The meaning of an expression rt
time units w.r.t. frequency function fr. Frequency functions enable the specification of
various types of temporal relations. For example, they can be used to determine how often
F is followed by G within t time units or how often F is followed by G exactly after t
time units. The usage of fr in the syntax of temporal rules is used to specify a set of possible
names for the employed types of frequency function.
`,u
`,u
Now, we can define the belief operator Bi,t
0 to express agents beliefs. Intuitively, Bi,t0 ()
means that at time t0 , agent i believes that some fact  is true with a probability p  [`, u].
Particularly, the intuitive meaning of belief in a temporal rule is that agent i believes
fr (F, G), given that F holds at some time point. We call
that G will hold according to rt
the probability interval [`, u] the quantification of agent is belief. We use Ft to denote
that formula F holds at time t and, accordingly, ObsG (l)t to denote that an observation
ObsG (l) occurs at time t. We call these expressions time-stamped formulae and timestamped observation atoms, respectively.
Definition 3.4 (Belief formulae). Let i be an agent, t0 a time point, and [`, u]  [0, 1].
Then, belief formulae are inductively defined as follows:
`,u
1. If F is a ground formula and t is a time point, then Bi,t
0 (Ft ) is a belief formula.
fr (F, G) is a temporal rule, then B `,u (r fr (F, G)) is a belief formula.
2. If rt
i,t0 t
`,u
3. If F and G are belief formulae, then so are Bi,t
0 (F ), F  G , F  G , and F .
`,u
For a belief Bi,t
0 () about something, we call  the belief object. Belief operators are the
`,u
atomic elements in PDT Logic, i.e., any expression Bi,t
0 () (including possibly nested belief

46

fiPDT Logic

formulae) is called an atom. We use script fonts (e.g., F ) to distinguish belief formulae
from standard formulae. Note that we can have both ontic facts and observation atoms
as standard formulae (cf. Definition 3.2) and therefore agents can also have beliefs about
possible observations.
The use of probability intervals [`, u] provides an option to represent imprecise probabilities (Bradley, 2015): When using imprecise probabilities, it is usually assumed that
the degree of belief in some proposition is not represented using a single probability function p(), but instead through a set P of such functions. Then, the belief state P () in a
proposition  is represented through the set
P () = {p() : p  P }.
For this set of probabilities P (), so-called lower and upper envelopes are defined as P () =
inf P () and P () = sup P (), respectively. The belief quantifications in our belief operator
represent such imprecise probabilities and the ` and u values of the probabilistic belief can be
considered as the lower and upper envelopes P and P of the respective imprecise probability.
`,u
Remark 3.1. We decided to index both the belief operators Bi,t
0 () and facts Ft appearing
as belief objects  with time stamps to allow for a concise representation of temporal
relations. Alternatively, one could use the more traditional approach (cf. Sack, 2009 for
example) and introduce previous-time and next-time operators into the language to express
`,u
temporal relationships between t and t0 in Bi,t
0 (Ft ). Then, we could also omit the temporal
0
index t of the belief operator and instead evaluate whether the belief holds at time t0 of
the model. However, these are merely syntactic considerations that do not impact the
underlying formalism. Thus we decided to encode time explicitly into the belief operators
to avoid the introduction of additional temporal operators. Moreover, belief operators can
also be used to express general temporal relationships of the modeled domain. We will
illustrate this point in detail in Section 4.

3.2 Semantics
In this section, we will provide a formal semantics for PDT Logic that captures the intuitions
explained above. To ease understanding of the presentation, we start with the introduction
of an example, to which we will return repeatedly when introducing the various concepts of
the semantics. For an illustration of our formalisms features, we use a simplified exemplary
domain. While the practical use of this example is somewhat limited, it serves to illustrate
how PDT Logic can be applied, and especially how the analysis of multi-agent beliefs can
yield valuable information when deciding on meaningful actions. The resulting insights can
then be easily applied to more sophisticated domains.
Example 3.2 (Trains). Let Alice and Bob be two agents living in two different cities CA
and CB , respectively. Suppose that Alice wants to take a train to visit Bob. Unfortunately,
there is no direct connection between cities CA and CB , so Alice has to change trains at a
third city CC . We assume that train T1 connects CA and CC , and train T2 connects CC and
CB . Both trains usually require 2 time units for their trip, but they might be running late
and arrive one time unit later than scheduled. Alice requires one time unit to change trains
at city CC . If T1 runs on time, she has a direct connection to T2 , otherwise she has to wait
47

fiMartiny & Moller

for two time units until the next train T2 leaves at city CC . If a train is running late, she
can call Bob to let him know. These calls can be modeled as shared observations between
Alice and Bob. For instance, if Alice wants to tell Bob that train T1 is running late (i.e., T1
does not arrive at CC at the expected time), this can be modeled as Obs{AB} (at(T1 , CC ))
at the expected arrival time.
3.2.1 Possible Worlds
Ontic facts and corresponding observations (e.g., as described in the above example) form
worlds (or states in the terminology of Fagin et al., 1995). A world  consists of a set
of ground atoms and a set of observation atoms, i.e.,   2BLobs .3 We use a   and
ObsG (l)   to denote that an atom a, resp. observation atom ObsG (l), holds in world .
Since agents can only observe facts that actually hold in the respective world, we can define
admissibility conditions of worlds w.r.t. the set of observations:
Definition 3.5 (Admissible worlds). A world  is admissible, iff for every observation atom
ObsG (l)  
1. the observed fact holds, i.e., x   if l is a positive literal x, and x 6  if l is a negative
literal x, and
2. for every subgroup G 0  G, ObsG 0 (l)  .
We use adm() to denote that a world  is admissible.
The set of all possible worlds is denoted by  and the set of admissible worlds by .
For the following discussion in this section we assume that some specification of  is given.
While it is possible to employ the usual definition of  as the set of all combinations of
ground atoms and observation atoms ( = 2BLobs ), and  as the maximum subset of 
complying with Definition 3.5, this usually contains a vast number of worlds which are
blatantly impossible according to the respective problem modeled. Therefore, we assume
that a succinct specification of a set of admissible worlds depending on the respective domain
is given. The main reason for this assumption is to simplify the following presentationwe
will describe a method to obtain such a set algorithmically in Section 4.
Remark 3.2. As already discussed in Section 3.1, for group observations ObsG (l) every
agent i  G is aware that all other agents in G have observed this fact. Together with
Definition 3.5, the semantics of observations is then equivalent to the usual semantics of
common knowledge. Fagin et al. (1995) give a definition of common knowledge through the
fixed-point axiom: A fact l is common knowledge among a group G if and only if all members
of G know that l is true and is common knowledge. Thus, we could also equivalently use the
established common knowledge operator CG (l) instead of the previously defined observation
3. Most formalisms in epistemic logic do not encode facts directly into the worlds, but instead use a set of
named states s1 , s2 , ... and some valuation function (si ) to determine which facts hold in world si (cf.
Fagin et al., 1995). This is mainly done to obtain the option of having multiple worlds si , sj where the
same facts hold (i.e., (si ) = (sj )), but the knowledge states of the agents differ. As described below,
in PDT Logic worlds appear within threads, and thus it is possible that worlds with the same valuation
appear at some time point in multiple threads. Thus, in our formalism we can encode facts directly into
the possible worlds and save the valuation function without limiting the epistemic expressivity.

48

fiPDT Logic

atoms ObsG (l). However, the concept of common knowledge is usually used to describe
emergent states of agents knowledge. On the other hand, in the context of our approach,
observations are an extrinsic feature that will result in the emergence of other belief states.
To keep a clear distinction of the intended use of the operator, we will therefore continue
to use ObsG (l) instead of CG (l).
Example 3.3 (Trains continued). For Example 3.2, we have ground terms A, B, CA , CB ,
CC , T1 , and T2 , representing Alice, Bob, three cities, and two trains. Furthermore, we have
atoms on(y, x) indicating that person y is on train x, and at(x, z) indicating that train x
is at city z. Finally, we have observation atoms of the kind ObsG (at(x, z)), indicating that
the agents in G observe that train x is at station z. A possible world can for example be
1 = {at(T1 , CA ), on(A, T1 ), Obs{A} (at(T1 , CA ))}, indicating that train T1 is at city CA and
A has boarded that train.
We define satisfaction of a ground formula F by a world  in the usual way (Lloyd,
1987):
Definition 3.6 (Satisfaction of ground formulae). Let F, F 0 , F 00 be ground formulae and 
a world. Then, F is satisfied by  (denoted  |= F ) if and only if:
case F = a for some ground atom a:
a  .
case F = F 0 for some ground formula F 0 :

case F = F 0  F 00 for formulae F 0 and F 00 :

case F = F 0  F 00 for formulae F 0 and F 00 :

 6|= F 0 .

 |= F 0 and  |= F 00 .

 |= F 0 or  |= F 00 .

We say that a formula F is a tautology if  |= F for all admissible worlds   . We
say that a formula F is a contradiction if there is no world    such that  |= F . We use
the usual symbols > and  to denote tautologies and contradictions, respectively.
3.2.2 Threads
To model temporal evolutions of the problem domain we use the definition of threads from
Shakarian et al. (2011):
Definition 3.7 (Thread). A thread T h is a mapping from the set of time points  to the
set of admissible worlds: T h :   
Thus, a thread is a sequence of worlds and T h(t) identifies the actual world at time t
according to thread T h. The set of all possible threads (i.e., all possible sequences constructible from  and ) is denoted by T . Again, we refrain from directly working with
T , and instead assume that any meaningful problem specification gives information about
possible temporal evolutions of the system. We use T to represent this set of relevant possible threads. For notational convenience, we assume that there is an additional prior world
T h(0) for every thread.
Following Definition 3.6, we use T h |= Ft to denote that thread T h satisfies formulae F
at time t (i.e., T h |= Ft  T h(t) |= F ). Accordingly, we use T |= Ft to denote that every
thread T h  T satisfies formula F at time t.
49

fiObs{A}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

Obs{A,B}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

Obs{A}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

1 2 T h7

1 2 T h6

T h5

T h4

1

1

T hi

T h1

2 T h2
on(A, T1 )
at(T1 , CC )
on(A, T1 )

on(A, T1 ) on(A, T1 )
at(T1 , CA )
on(A, T1 ) on(A, T1 )

3

at(T1 , CC )

at(T1 , CA )

2

on(A, T1 )

on(A, T1 ) on(A, T1 )

1

at(T1 , CC )

at(T1 , CA )

at(T1 , CA )

at(T1 , CA )

at(T1 , CA )

at(T1 , CA )

on(A, T2 )

on(A, T2 )

on(A, T2 )

on(A, T2 )

4
1

5

on(A, T2 ) on(A, T2 )

at(T2 , CC )

at(T2 , CC )

6

on(A, T2 )

at(T2 , CB )

7

Obs{A}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 ) on(A, T2 ) on(A, T2 )

at(T2 , CC )

8

at(T2 , CB )

at(T2 , CC )
on(A, T2 )

at(T2 , CB )
on(A, T2 )

9

t

Obs{A}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 )
on(A, T2 )

Obs{A}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 )
on(A, T2 )

Obs{A,B}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 )
on(A, T2 )

Obs{A,B}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 )
on(A, T2 )

at(T2 , CC )

on(A, T2 )

at(T2 , CC )

on(A, T2 )

at(T2 , CC )

on(A, T2 )

at(T2 , CC )

on(A, T2 )

at(T2 , CC )

Obs{A,B}
at(T2 , CB )
(at(T2 , CB ))
on(A, T2 ) on(A, T2 ) on(A, T2 ) on(A, T2 )

Obs{A,B}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

2 T h3

Obs{A}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

1 2 T h8

at(T1 , CA )

Obs{A,B}
at(T1 , CC )
(at(T1 , Cc ))
on(A, T1 ) on(A, T1 ) on(A, T1 ) on(A, T1 )

at(T1 , CA )

1 2 T h9

Martiny & Moller

Figure 1: Visualization of the possible threads T hi from Example 3.2. For an easier distinction, shared observations between A and B are marked in blue, single observations
of A are marked in red, and all situations where Alice is on train 1 or train 2
are marked in green and orange, respectively. Note that if a train is running late
(the respective threads are marked with according circles), there are always two
possible threads: one where only A observes this and one where both share the
observation.
50

fiPDT Logic

We assume that the system is synchronous, i.e., the agents have a global clock. Thus,
even if an agent does not observe anything in world T h(t), it is still aware of time passing
and can therefore distinguish between worlds T h(t) and T h(t  1).
Example 3.4 (Trains continued). The description from Example 3.2 (p. 47) yields the
set of possible threads T depicted in Figure 1. Note that this is a manually specified set
of threads containing only threads that comply with the description in Example 3.2. The
set of all possible threads T would contain a vast number of additional threads that are
irrelevant to the described scenario.
3.2.3 Kripke Structures
With the definition of threads, we can use a slightly modified version of Kripke structures
(Kripke, 1963). As usual, we define a Kripke structure as a tuple h, K1 , ..., Kn i, with the
set of admissible worlds  and binary relations Ki on  for every agent i  A. Thus, the
Kripke relation (also called possibility relation) for agent i at world  is defined as
Ki () = { 0 : (,  0 )  Ki }

(1)

Intuitively, (,  0 )  Ki specifies that in world , agent i considers  0 also as a possible
world. In other words, with its current information agent i is unable to distinguish worlds
 and  0 .
We initialize the Kripke structure such that all threads are considered possible at time
t = 0:
[
T h  T : Ki (T h(0)) =
{T h0 (0)}, i  A
(2)
T h0 T

With the evolution of time, each agent can eliminate the worlds that do not comply with its
respective observations. Through the elimination of worlds, an agent will also reduce the
set of threads it considers possible (ifdue to some observationa world  is considered
impossible at a time point t, then all threads T h with T h(t) =  are considered impossible).
We assume that agents have perfect recall and therefore will not consider some thread
possible again if it was considered impossible at one point. Thus, Ki is updated w.r.t. the
agents respective observations, such that it considers all threads possible that both comply
with its current observations and were considered possible at the previous time point:

Ki (T h(t)) = T h0 (t) : T h0 (t  1)  Ki (T h(t  1))
	
{ObsG (l)  T h(t) : i  G} = {ObsG (l)  T h0 (t) : i  G}
(3)
The following two corollaries describe key properties of Ki that follow immediately from
the definitions in (2) and (3):
Corollary 3.1 (Equivalence relation). Ki defines an equivalence relation over the possible
worlds Ki (T h(t)) for time points t   .
Corollary 3.2 (Reduction of considered threads). The set of threads T h0 considered possible
w.r.t. Ki is narrowing to a smaller and smaller subset over time, i.e., {T h0 : T h0 (t) 
Ki (T h(t))}  {T h0 : T h0 (t  1)  Ki (T h(t  1))} for all T h  T and t   .
51

fiMartiny & Moller

Note that updates of Ki are defined such that new information is incorporated instantaneously, i.e., if at time t an agent observes some fact, it updates its possibility relations
already at time t such that it considers every world impossible that does not comply with
the observation of time t.
Example 3.5 (Trains continued). From Figure 1, we obtain that at time 1, the only
possible world is {at(T1 , CA ), on(A, T1 )}, which is contained in all possible threads. Thus,
Ki (T hj (1)) contains exactly this world for all agents i and threads j. Consequently, both
agents consider all threads as possible at time 1.
Now, assume that time evolves for two steps and the actual thread is T h4 (i.e., train
T1 is running late, but A does not inform B about this). Both agents will update their
possibility relations accordingly, yielding
KA (T h4 (3)) = {{Obs{A} (at(T1 , CC )), on(A, T1 )}}
and
KB (T h4 (3)) = {{at(T1 , CC ), on(A, T1 )}, {Obs{A} (at(T1 , CC )), on(A, T1 )}},
i.e., A knows that T1 is not on time, while B is unaware of T1 being late, since he still
considers a situation possible where train T1 is at city CC at time t = 3.
3.2.4 Subjective Posterior Temporal Probabilistic Interpretations
Each agent has probabilistic beliefs about the expected evolution over time. This is expressed through subjective temporal probabilistic interpretations:
Definition 3.8 (Subjective posterior probabilistic temporal interpretation). Given a set of
possible threads T , some thread Th  T , a time point t0 > 0 and an agent i, the function
Th : T  [0, 1] specifies the subjective posterior probabilistic temporal interpretation from
Ii,t
0
agent is point of view at time t0 in thread Th, i.e., a probability distribution over all possible
P
Th (T h) = 1. Since the probabilistic interpretations over possible threads
threads: T hT Ii,t
0
depend on the respective perspective of agent i, Th marks the point of view for a subjective

interpretation. Thus, we call Th the point of view (pov) thread of interpretation I T h0 .
i,t

The concept of point of view threads can be seen as conditional probabilities: A subjecTh specifies agent is probabilistic interpretation
tive posterior probabilistic interpretation Ii,t
0
at time t0 given that Th is the actual thread. Different threads yield different evolutions
of the world andsince every possible thread can be taken as a pov thread may induce
different probabilistic interpretations of an agent. Thus, the notion of pov threads allows
to reason about hypothetical beliefs of an agent, for instance if possible future beliefs are
analyzed or nested beliefs are evaluated.
Th as a vector and occasionally represent a probabilistic
To simplify notation, we see Ii,t
0


T h over a vector of possible threads T as a vector as well, so that the jth
interpretation Ii,t
0


T h refers to the probability assigned to thread T h .
element of Ii,t
0
j



T h (T h). Since
The prior probabilities of each agent for all threads are then given by Ii,0
all threads are indistinguishable a priori, there is only a single prior distribution needed

52

fiPDT Logic

0



0

T h (T h) = I T h (T h)). Furthermore, in order
for each agent (i.e., T h, Th, Th  T : Ii,0
i,0
to be able to reason about nested beliefs (as discussed below), we assume that the prior
probability assessments of all agents are commonly known (i.e., all agents know how all
other agents assess the prior probabilities of each thread). This in turn requires that all
agents have exactly the same prior probability assessment over all possible threads: if two
agents have different, but commonly known prior probability assessments, we essentially
have an instance of Aumanns well-known problem of agreeing to disagree (Aumann,
1976). Intuitively, if differing priors are commonly known, it is common knowledge that
(at least) one of the agents is at fault and should revise its probability assessments. As a
result, we have only one prior probability distribution which is the same from all viewpoints,
denoted by I. Note that I directly corresponds to the concept of temporal probabilistic
interpretations by Shakarian et al. (2011).

Remark 3.3. We could use the prior probability distribution I as an alternative method
to distinguish between the set of all possible threads T and the set of threads T relevant
to a specific problem domain. To do so, we simply assign all unwanted threads T h 6 T a
probability of zero.
Example 3.6 (Trains continued). A meaningful prior interpretation is

I(T ) = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03 ,
which assigns the highest probability to T h1 (no train running late), lower probabilities to
the threads where one train is running late and A informs B (T h3 and T h5 ), even lower
probabilities to the events that either both trains are running late and A informs B (T h7 ,
T h8 , and T h9 ) or that one train is running late and A does not inform B (T h2 and T h4 ),
and lowest probability to the thread where both trains are running late and A does not
inform B (T h6 ). Note that I represents the prior interpretation for the train example and
thus is the same for every agent i  A and every possible pov thread Th.
Even though we only have a single prior probability distribution over the set of possible
threads, it is still necessary to distinguish the viewpoints of different agents in different
threads, as the following definition of interpretation updates shows.
Whenever an agent updates its Kripke relations according to Equation (3) (p. 51), it
is necessary to update the probabilistic interpretations of that agent to match the new
knowledge. An intuitive way to update the probabilities is conditioning on the remaining
worlds in the agents Kripke structure. We want to point out that conditioning is a suitable
choice in PDT Logic, although it is known to produce undesired or incorrect results in
many cases, most notably in the Monty Hall problem (vos Savant, 1990). Grunwald and
Halpern (2003) discuss that naive conditioning tends to produce errors because updates are
carried out in a simplified space where several events are collapsed since they are seemingly
one event. If one uses so-called sophisticated conditioning instead (i.e., conditioning in the
sophisticated space, which means that all possible events are represented), probabilities are
updated correctly. As the semantics of PDT Logic is based on an exhaustive specification of
all relevant threads, conditioning in a proper specification of all relevant threads is inherently
sophisticated in the sense of Grunwald and Halpern and will therefore produce correct
results. One can easily verify that with the following update rule, well-known probability
53

fiMartiny & Moller

puzzles such as the Monty Hall Problem can be correctly represented in PDT Logic. Thus,
we use the following conditioning-based update rule:
Definition 3.9 (Interpretation update). Let i be an agent, t0 a time point, and Th a pov
thread. Then, if the system is actually in thread Th at time t0 , agent is probabilistic
interpretation over the set of possible threads is given by the update rule:

Th (T h) if T h(t0 )  K (Th(t0 ))
 1  Ii,t
0 1
i
h
Th
T
0
i,t
Ii,t0 (T h) =
(4)
0
if T h(t0 ) 6 Ki (Th(t0 ))
with

1
h
T
i,t0

being a normalization factor to ensure that


X

Th
i,t
0 =

T hT ,

P



T hT

T h (T h) = 1:
Ii,t
0



Th
Ii,t
0 1 (T h)

(5)

T h(t0 )Ki (Th(t0 ))

The invocation of Ki in the update rule yields obvious ramifications about the evolution
of interpretations, as stated in the following corollary:
Corollary 3.3 (Nonzero probabilities). The subjective temporal probabilistic interpretation
Th of an agent i assigns nonzero probabilities exactly to the set of threads that i still
Ii,t
0

considers possible at time t0 , i.e., I T h0 (T h) > 0 iff (T h(t), Th(t))  Ki
i,t

Essentially, the update rule assigns all impossible threads a probability of zero and
scales the probabilities of the remaining threads such that they are proportional to the
probabilities of the previous time point. With a given prior probability distribution I over
Th in a specific pov thread
the set of possible threads, the subjective posterior probabilities Ii,t
0
0

T h for all agents i and all time points t are induced by the respective observations contained


in Th. We use I T h to denote the set of all subjective posterior interpretations I T h0 induced
i,t

in pov thread Th.

Example 3.7 (Trains continued). Applying the update rule from (4) to the situation
described in Example 3.5 (p. 52), with I as given in Example 3.6, yields the updated
interpretation for A:


T h4
IA,3
= 0 0 0 0.4 0 0.2 0 0.4 0



(6)

i.e., A considers exactly those threads possible, where the train is running late and she does
not inform B (threads T h4 , T h6 , and T h8 ). Due to the lack of any new information, B
can only eliminate the situations where A does indeed inform him about being late at time
point 3, and thus Bs interpretation is updated to:

Th4
IB,3
 0.82 0.02 0.10 0.02 0 0.02 0 0.02 0 .
54

(7)

fiPDT Logic

T h(1)

T h(2)

T h(3)

T h(4)

T h(5)

T h(6)

T h(7)

T h(8)

F

G

F

G

G

F

G

F

Figure 2: Example thread T h with  = {1, ..., 8}, adopted from Shakarian et al. (2011).
This figure shows each world that satisfies formula F or formula G.

3.2.5 Frequency Functions
To represent temporal relationships within threads, we adapt the concept of frequency functions as introduced by Shakarian et al. (2011). Frequency functions provide a flexible way of
representing temporal relations between the occurrences of specific events. To illustrate the
motivation behind using frequency functions, consider the exemplary thread T h depicted in
Figure 2. In this thread, one of the events F or G occurs at every time point from t = 1 to
t = 8. As discussed by Shakarian et al., there are multiple ways of characterizing temporal
relationships between the events F and G: For instance, one might specify how often event
F is followed by event G in, say, exactly 2 time points. According to Figure 2, this happens
in one out of four occurrences of F in T h. It might prove meaningful to exclude the final
occurrence of F in T h when determining this frequency, because naturally an occurrence
of F at tmax cannot be followed by a subsequent occurrence of G. Excluding the final
occurrence of F would yield one out of three for the desired frequency. Alternatively, one
could also specify how often F is followed by G within the next two time points. For the
exemplary thread from Figure 2, this would produce frequencies of 1 and 0.75 respectively,
again depending on whether the final occurrence of F is included.
This example illustrates already four different possible definitions of temporal relations
between events. To maintain flexibility in expressing temporal relations, we do not commit to specific definitions in PDT Logic, but instead we adapt an axiomatic definition of
frequency functions:
Definition 3.10 (Frequency functions, adapted from Shakarian et al., 2011). Let T h be
a thread, F , F 0 , G, and G0 be ground formulae, and t  0 be an integer. A frequency
function fr maps quadruples of the form (T h, F, G, t) to [0, 1] such that the following
axioms hold:
(FF1) If (F  G) is a tautology, then fr(T h, F, G, t) = 1.
(FF2) If (F  G) is a contradiction, then fr(T h, F, G, t) = 0.
(FF3) If (F  G) is neither a tautology nor a contradiction, then there exist threads T h1 ,
T h2  T such that fr(T h1 , F, G, t) 6= fr(T h2 , F, G, t).
(FF4) If F  F 0 and G  G0 , then fr(T h, F, G, t) = fr(T h, F 0 , G0 , t).
Axioms (FF1) and (FF2) ensure that in special casesi.e., (G  >), (F  ), or
(F  >, G  )frequency functions behave as temporal implications with premise
F and conclusion G. Axiom (FF3) enforces non-trivial frequency functions by requiring
that in all cases not covered by the first two axioms, there must be at least two threads
55

fiMartiny & Moller

with differing frequency values. Axiom (FF4) ensures that that fr is congruent to logical
equivalence. Examples of frequency functions satisfying these axioms are introduced below.
Remark 3.4. This definition mostly corresponds to the definition of frequency functions
from Shakarian et al. (2011), except that we do not require t > 0. In the work from
Shakarian et al., frequency functions are only intended to express temporal relationships
and therefore t is limited to nonzero values. By additionally allowing t = 0, we obtain
a concise framework that can express both temporal relationships and static constraints
within one time point. This will be exploited in the next section, where decision procedures
for PDT Logic are discussed.
To illustrate the concept of frequency functions, we now present formal definitions for
point and existential frequency functions adapted from Shakarian et al. that represent the
informal descriptions of frequencies from above:
The point frequency function pfr expresses how frequently some event F is followed by
another event G in exactly t time units:
pfr(T h, F, G, t) =

|{t : T h(t) |= F  T h(t + t) |= G}|
|{t : (t  tmax  t)  T h(t) |= F }|

(8)

If the denominator is zero, we define pfr to be 1. The denominator counts the total number of
occurrences of F in a given thread T h and the numerator counts the number of occurrences
of F followed by G after exactly t time units. Thus, the ratio pfr expresses how frequently
F is followed by G in exactly t time units. Note that the denominator only considers
occurrences of F up to time tmax  t. This is done to reflect the previously discussed
intuition that occurrences of F in the last t time points should be excluded from the
frequency, because there is no possibility that they can be followed by a subsequent G after
t time units.
The existential frequency function efr expresses how frequently some event F is followed
by another event G within the next t time units:
efr(T h, F, G, t) =
efn(T h, F, G, t, 0, tmax )
,
|{t : (t  tmax  t)  T h(t) |= F }| + efn(T h, F, G, t, tmax  t, tmax )

(9)

with
efn(T h, F, G, t, t1 , t2 ) =|{t : (t1 < t  t2 )  T h(t) |= F

 t0  [t, min(t2 , t + t)] (T h(t0 ) |= G)}|

The function ef n counts the number of occurrences of F followed by a subsequent occurrence
of G within the next t time units. The first summand of the denominator again counts the
total number of occurrences of F up to the time point tmax  t. In the second summand
of the denominator, additional occurrences of F followed by G within t time units. The
intuition of this definition is again to exclude occurrences of F in the final t time units if
they are not followed by G. Since G may occur within the range t, but this range cannot
be fully considered for the final t time points, only occurrences of F with an according
subsequent occurrence of G are considered for these final time points. Consequently, the
56

fiPDT Logic

ratio efr expresses how frequently some event F is followed by G within the next t time
units without letting single occurrences of F in the final t time points decrease the ratio.
Returning to the exemplary thread T h from Figure 2, we can evaluate the frequency
functions for the given thread: Suppose that we want to determine how often F is followed
by G exactly after two time steps. This can be expressed through a point frequency function:
1
pfr(T h, F, G, 2) = .
3
If instead we want to know how often F is followed by G within the next two time steps,
we can use an existential frequency function:
efr(T h, F, G, 2) =

3
=1
3

It should be noted that frequency functions can be used to model temporal relationships
usually expressed through temporal operators. For instance, pfr with t = 1 reflects
the next operator and efr with t = tmax reflects the future operator. The meaning
of additional temporal operators such as until can be captured through the definition of
additional frequency functions, if required.
3.2.6 Semantics of the Belief Operator
Now, with the definitions of subjective posterior probabilistic temporal interpretations and
the introduction of frequency functions, we can provide a formal semantics for the belief operators defined in Section 3.1. This semantics extends definitions from Shakarian
et al. (2011) for the satisfiability of static interpretations to obtain a formal definition of
probabilistic multi-agent beliefs. We start with providing a definition for the semantics of
atomic belief operators for the three different types of beliefs. Semantics of compound belief
formulae (i.e., involving connectives , , ) are defined below in Definition 3.16.
Definition 3.11 (Belief Semantics of the atomic belief operator). Let i be an agent and
Th be agent is interpretation at time t0 in pov thread Th. Then, it follows from this
Ii,t
0
interpretation that agent i believes at time t0 with a probability in the range [`, u] that
1. (Belief in ground formulae)
Th |= B `,u (F )) iff
a formula F holds at time t (denoted by Ii,t
0
t
i,t0
`

X
T hT ,T h(t)|=F



Th
Ii,t
0 (T h)  u.

(10)

2. (Belief in rules)
fr (F, G) holds (denoted by I Th |= B `,u (r fr (F, G))) iff
a temporal rule rt
i,t0
i,t0 t
`

X
T hT



Th
Ii,t
0 (T h)  fr(T h, F, G, t)  u.

57

(11)

fiMartiny & Moller

3. (Nested beliefs)
` ,u
a belief Bj,tj j () of some other agent j holds at time t0 (denoted by


` ,u

T h |= B `,u (B j j ())) iff
Ii,t
0
j,t
i,t0

`



X
T hT
` ,u
T h |=B j j ()
Ij,t
j,t

Th
Ii,t
0 (T h)  u.

(12)

The intuition behind this semantics is as follows. For beliefs in ground formulae Ft , the
Th (T h) of an agent i at time t0 in pov thread Th are
subjective posterior probabilities Ii,t
0
added for all threads T h that satisfy F at time t. Thus, the sum in (10) represents the
Th assigns to F . If this sum is within the specified boundaries [`, u],
exact probability that Ii,t
0
t
`,u
the respective belief B 0 (Ft ) holds for agent i at time t0 in pov thread Th.
i,t



T h (T h) for every thread are
For beliefs in rules, the subjective posterior probabilities Ii,t
0
fr (F, G). Thus,
weighted with the corresponding frequency fr(T h, F, G, t) from rule rt

T h (T h) in (11) represents the exact probability that I Th assigns to
the weighted sum of Ii,t
0
i,t0
the temporal relation between F and G according to frequency function fr. For beliefs
fr (F, G) only contains information about the type of frequency
in rules, the belief object rt
function fr, while constraints on the respective frequency values are given through the belief
quantification [`, u], i.e., an agent does not have probabilistic beliefs in specific frequency
values.

Remark 3.5. It should be noted that the semantics of beliefs in rules in (11) together
with the axiomatic definition of frequency functions in Definition 3.10 (p. 55) yields certain
fr (F, G). If G is a tautology or F is a contradiction
constraints on satisfiable beliefs in rules rt
(i.e., in Definition 3.10 FF1 is satisfied), it holds for the respective frequency function that
`,u fr
fr(T h, F, G, t) = 1 for every possible thread T h, and thus, any belief Bi,t
0 (rt (F, G)) is
satisfiable if and only if the belief is quantified with u = 1, regardless of the set of threads
Th . Analogously, if F is a tautology and G is a
T or the corresponding interpretation Ii,t
0
`,u fr
contradiction (i.e., FF2 is satisfied), any belief Bi,t
0 (rt (F, G)) is only satisfiable for ` = 0.
` ,u

`,u
j j
For nested beliefs Bi,t
()), the expression is unnested by first determining all
0 (Bj,t
` ,u

` ,u

possible pov threads T h for agent j such that Bj,tj j () is satisfied. If Bj,tj j () corresponds
to a belief in a fact or in a rule, (10) respectively (11) can be used to identify threads T h
T h |= B `j ,uj (). Otherwise, if  represents another belief formula, the belief has
such that Ij,t
j,t
to be unnested recursively until the innermost belief of the expression is obtained. Then, for
T h |= B `j ,uj (), agent is subjective posterior probabilities I Th (T h)
all threads T h with Ij,t
j,t
i,t0
are added again to determine whether the outer belief holds. Note that agent i does not
know the actual beliefs of agent j. However, due to the assumption of common and equal
priors discussed in Section 3.2.4, agent i is able to reason about agent js hypothetical
interpretation updates given that the system is in a specific thread. Thus, agent i is able
to compute (12) without knowing js exact beliefs.
Example 3.8 (Trains continued). We can use a point frequency function to express beliefs
about the punctuality of trains. Assume that both A and B judge the probability of a
58

fiPDT Logic

train running late (i.e., arriving after 3 instead of 2 time units, expressed through the
temporal rule r3pfr (at(T1 , CA ), at(T1 , CC ))) as being at most 0.4. This yields the following
belief formulae
0,0.4 pfr
Bi,0
(r3 (at(T1 , CA ), at(T1 , CC )))

,
0,0.4 pfr
Bi,0
(r3 (at(T2 , CC ), at(T2 , CB )))

i  {A, B}.

(13)

For the temporal rules expressed in these belief formulae, we obtain the following frequencies
from Figure 1 (p. 50):
pfr(T h, at(T1 , CA ), at(T1 , CC ), 3) = 0
pfr(T h, at(T1 , CA ), at(T1 , CC ), 3) = 1
pfr(T h, at(T2 , CC ), at(T1 , CB ) , 3) = 0
pfr(T h, at(T2 , CC ), at(T1 , CB ), 3) = 1

for T h  {T h1 , ..., T h3 }

for T h  {T h4 , ..., T h9 }

for T h  {T h1 , T h4 , T h5 }

for T h  {T h2 , T h3 , T h6 , ..., T h9 }

Combining these frequency values with the prior interpretation

I(T ) = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03 ,
given in Example 3.6 (p. 53) yields the sum
X
I(T h)  pfr(T h, F, G, 3) = 0.19
T hT

for both F = at(T1 , CA ), G = at(T1 , CC ) and F = at(T2 , CC ), G = at(T2 , CB ). As this sum
is within the belief quantification [`, u] = [0, 0.4], the belief formulae in (13) are valid. Note
that the prior probabilities from Example 3.6 have been specified such that both trains are
late with the same probability, and thus the respective sums for the above frequencies are
the same.
From the above definitions, we can use the belief about some fact F to quantify the
belief about the negation of this fact F :

`,u
Corollary 3.4 (Belief in negated facts). Let Bi,t
0 (Ft ) be an agents quantified temporal belief
about some fact F according to Definition 3.11. Then, the agents belief in the negation of
`0 ,u0
0
0
this fact F is given as Bi,t
0 (F ) with ` = 1  u and u = 1  `.

3.3 Evolution over Time
In order to completely specify a problem in PDT Logic, we introduce the concept of doxastic
systems. In the following, we assume that all syntactical objects are finite.
|A||T |

Definition 3.12 (Doxastic system). Let A be a set of agents, T be a set of threads, A0
be a matrix of prior probability distributions across T for every agent in A, and F be a
|A||T |

set of frequency functions. Then, we call the quadruple D = hA, T , F, A0
system.
59

i a doxastic

fiMartiny & Moller

Note that several of the parameters discussed before are not explicitly specified in a
doxastic system: neither the set of possible worlds , the set of ground atoms B, the set of
observation atoms Lobs , nor the set of time points  are explicitly specified. However, all
relevant information regarding these parameters is already contained in the specification of
T .

Remark 3.6. Since all agents share a common prior, all rows of A0 are the same. Thus,
one could obtain a more parsimonious problem specification by only providing the single
unique row vector of prior probabilities. The choice of using the matrix A0 nonetheless
is for notational purposes only: it will simplify the presentation of interpretation update
operations later on.
|A||T |

Definition 3.13 (Admissibility of doxastic systems). Let D = hA, T , F, A0
i be a
doxastic system. D is called admissible iff every world (implicitly) defined in T is admissible
|A||T |

(according to Definition 3.5, p. 48) and all rows of A0

sum to one.

To identify specific situations in a doxastic system after some time has passed and some
observations occurred, we furthermore define pointed doxastic systems:
|A||T |

Definition 3.14 (Pointed doxastic system, pds). Let D = hA, T , F, A0
i be a doxastic
system and H be a set of time-stamped observation atoms such that all observation atoms
from H occur in at least one of the worlds (implicitly) defined in T . Then we call the pair
hD, Hi a pointed doxastic system.
Definition 3.15 (Admissibility of pointed doxastic systems). Let hD, Hi be a pointed
doxastic system, and T the set of threads from D. hD, Hi is called admissible iff D is
admissible and there exists a thread T h  T such that ObsG (l)t  H : ObsG (l)  T h(t)
(i.e., T must contain at least one thread that complies with all timed observations from H).
Intuitively, the set of timed observations specified in a pds points to a certain situation
in a doxastic system. One could view t(H) = max{t : ObsG (l)t  H} as the present time in
a pds: the most recent observation occurred at t(H), all observations that actually occurred
in the past (t < t(H)) are specified in H (and are thus deterministic in retrospective), and
no further information about future observations t > t(H) is given. In this sense, H specifies
a certain history up to t(H) in a doxastic system and points to the last event of this history.
Example 3.9 (Trains continued). A doxastic system for the train example can be specified
as
D = h{A, B}, {T h1 , ..., T h9 }, {pfr, efr}, A0 i,
with



0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03
A0 =
.
0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03

To identify the situation described in Example 3.5 (p. 52, T1 is running late), we can specify
the following pointed doxastic system:
hD, {Obs{A} (at(T1 , CC )3 )}i
60

fiPDT Logic

3.3.1 Evolution of Probabilistic Interpretations
In accordance with the prior probability matrix A0 from Definition 3.12, we define an

interpretation matrix ATt h to store the interpretations of all agents A (with n denoting the
number of agents |A|) across all threads T h1 , ..., T hm given that the doxastic system is in
pov thread Th at time t:


Th (T h ) . . . I Th (T h )
I1,t
m
1
1,t



..
..
..

(14)
ATt h = 
.
.
.






T h (T h ) . . . I T h (T h )
In,t
m
1
n,t

With the definition of Ki from Equation (3) (p. 51), the update rule from Equation (4)
(p. 54), and using the prior probability matrix A0 from Definition 3.12, we can provide an

update matrix UtT h to calculate the interpretation matrix for any pov thread Th at any
time point t ( denotes the element-wise multiplication of matrices):






h
ATt h = ATt1
 UtT h

with

(uTt h )ij

=


0
1

 Th

i,t0

if T hj (t) 6 Ki (Th(t))
if T hj (t)  Ki (Th(t))

(15)

(16)



T h a normalization factor as defined in Equation (5) (p. 54).
and i,t
0
The time-stamped observations specified in the history H of a pds hD, Hi induce an
updated set of reachability relations Ki (T h(t)) for every thread T h that complies with
the given observations (for threads T h that do not comply with the given observations
Ki (T h (t)) = ). These updated reachability relations in turn yield the updated interpre
tations in ATt h . The complete state of interpretations at any time point for every possible
pov thread Th1 , ..., Thm can then be specified as a block matrix, which we call the belief
state (bs) of a pds at time t:
 


bs(hD, Hi, t) = ATt h1 , ..., ATt hm
(17)

We use bs(hD, Hi) to denote the sequence of all belief states bs(hD, Hi, t) from t = 1 to
t = tmax .
This definition of belief states can be seen as a specification of conditional probabilities:
the kth entry of bs(hD, Hi, t) specifies the interpretations of all agents across all threads at
time t given that the system is in pov thread Thk . Thusas every thread is considered as
a potential pov threada full specification of an agents belief state for m threads requires
m  m conditional probabilities for every time point t. This is a very general representation
of belief states to allow for an easy evaluation of subjective posterior interpretations at
arbitrary time points and pov threads and for an intuitive definition of belief state updates.
However, this general definition contains some redundant information. By leveraging certain properties of the semantics of PDT Logic, we identify means to obtain compressed
representations of the belief state in the following.
61

fiMartiny & Moller





Corollary 3.5 (Null vectors in ATt hk ). Due to the definition of (16), the ith row of ATt hk is
~0 iff agent is actual observations (as specified in H) do not match the observations specified
in thread T hk .
Proposition 3.6 (Belief state compression). Let hD, Hi be a pointed doxastic system and
let t be a time point such that t  t(H). Then, without any loss of information, the belief
state bs(hD, Hi, t) at time t can be represented through
T
(18)
bs(hD, Hi, t)0 = ~v1,t , ..., ~vn,t
with one probability distribution vector ~vi,t per agent i.


Proof. It follows directly from Corollaries 3.3 (p. 54) and 3.5 that the matrices ATt hk from
bs(hD, Hi, t) with nonzero rows i are exactly those that correspond to threads considered
possible by agent i at time t.
From the properties of Ki given in Corollary 3.1 (p. 51) follows that all worlds T h0 (t) 
Ki for t  t(H) are indistinguishable to agent i and therefore are associated with the same
interpretation. Thus, all nonzero ith rows of the matrices in bs are identical. Defining ~vi,t
as these unique nonzero rows i of bs, we obtain the representation of (18). Information
about impossible pov threads (as described in Corollary 3.5) is still maintained as they are
assigned a probability of 0 in ~vi,t .
It is important to note that this compressed representation is only applicable to time
points t  t(H), because in retrospective an agent is able to classify threads into two
categories: those that comply with the observations so far (i.e., those that are considered
possible), and those that do not. For time points t > t(H) this classification is not possible
because Ki (T h(t)) then depends on future observations and can therefore lead to a branching
of several distinct interpretations depending on the respective observations.
3.3.2 Evolution of Beliefs
In order to analyze the temporal evolution of beliefs, we use the update rule from (15) to
update belief states. Since different possible observations yield different branches in the
evolution of beliefs, we have to update every thread in the belief state individually, using

the respective update matrices UtT h as defined in (16):




bs(hD, Hi, t) = bs(hD, Hi, t  1)  (UtT h1 , ..., UtT hm )

(19)

Furthermore, to analyze satisfiability and validity of arbitrary finite belief expressions
`,u
~
Bi,t
0 () w.r.t. a given pds hD, Hi, we define an auxiliary belief vector b() for different beliefs
`,u
B 0 (). This vector ~b() contains one entry (~b())j for every possible thread T hj  T and
i,t

is defined as follows:
a)

`,u
Bi,t
0 (Ft )

b)

`,u fr
Bi,t
0 (rt (F, G)) :

c)

`,u
`k ,uk
Bi,t
()) :
0 (Bk,t

:

(
1 if T hj (t) |= F
(~b(Ft ))j =
0 if T hj (t) 6|= F

fr
(~b(rt
(F, G)))j = fr(T hj , F, G, t)
(
Th
`k ,uk
1 if Ik,t j |= Bk,t
()
`
,u
k k
~
(b(Bk,t ()))j =
T hj
`k ,uk
0 if Ik,t 6|= Bk,t ()

62

(20)

fiPDT Logic

Note that in the case of nested beliefs, the respective entries (~b())j are set to one if the
inner belief holds in thread T hj , i.e., it is assumed that T hj is the point of view thread for
`k ,uk
() is satisfied in this thread.
agent k and then it is checked whether ks belief Bk,t


Using (19) and (20), we can determine a matrix Pt0 () with the probabilities pTi,th0 k ()
that each agent i assigns at time t0 to some event , for all possible pov threads
Th1 , ..., Thm :4




T h1

T p1,t0
.
Pt0 () = bs(hD, Hi, t0 )  ~b(), ..., ~b() = 
 ..


pTn,th01



. . . pT1,th0m
.. 
..

.
.  ()

. . . pTn,th0m

(21)

For n agents and m threads, this results in a n  m matrix. The rows of this matrix can
be seen as conditional probabilities: agent i believes at time t0 that a fact  is true with

probability pTi,th0 k () given that the system is in pov thread Thk .
Remark 3.7. Computation of Pt0 () is straightforward for cases 20.a) and 20.b). To compute
the probabilities for nested beliefs in 20.c), we start with computing the innermost belief
(which is an instance of case 20.a) or case 20.b) since we assume finite expressions), and
then compute the nested beliefs iteratively.
Using Definition 3.11 (p. 57) and Equation (21), we can provide a definition for the
satisfiability and validity of beliefs:
Definition 3.16 (Validity and satisfiability of beliefs). Let B be a belief formula as defined
in Definition 3.4 (p. 46), hD, Hi a pointed doxastic system, and Pt0 () the corresponding
matrix of probabilities at time t0 as defined in (21). B is satisfiable (valid) w.r.t. hD, Hi iff
`,u
1. For B = Bi,t
0 ():

For at least one (all) thread(s) Thk  T , the entries in row i of Pt0 () satisfy ` 




T hk
T hk
pi,t
0 () and u  pi,t0 ().

`,u
2. For B = Bi,t
0 ():

For at least one (all) thread(s) Thk  T , the entries in row i of Pt0 () satisfy ` >




T hk
T hk
pi,t
0 () or u < pi,t0 ().

3. For B = B1  B2 :
For at least one (all) thread(s) Thk  T , the entries in the corresponding rows of
Pt0 () satisfy both B1 and B2 .
4. For B = B1  B2 :
B1 is satisfiable (valid) or B2 is satisfiable (valid).


4. Since we have to consider every possible pov thread Thk , we have to multiply every matrix ATt h 

T
bs(hD, Hi, t) with ~b(), thus we need to use the vector ~b(), ..., ~b()
with m rows.

63

fiMartiny & Moller

Remark 3.8. The distinction between valid and satisfiable belief formulae is only of interest
for beliefs at time t > t(H). For time points t  t(H) an agents belief is uniquely determined through the given observations (cf. Proposition 3.6), resulting in a single probability
associated to any belief. Therefore, all invalid belief formulae for t  t(H) are unsatisfiable.
From Definition 3.4 (p. 3.4) it follows that the belief object of an atomic belief formula B
as in Definition 3.16-1 can again be any arbitrary belief formula. If the inner belief formula
B 0 is one of the cases defined in Definition 3.16, validity and satisfiability of the entire
`,u
0
expression B = Bi,t
0 (B ) follows inductively from the above definition: If for at least one
(all) thread(s) Thk  T , both the inner belief formula B 0 is satisfied and the limits for the
`,u
0
outer belief of the respective thread are satisfied, the entire belief formula is B = Bi,t
0 (B )
satisfiable (valid).
Definition 3.16 gives rise to an important property of the belief operator, as the following
lemma shows:
`,u
Lemma 3.7 (Distributivity of the belief operator). Let B = Bi,t
0 (1  2 ) be a belief
formula with a belief object (1  2 ) and a connective   {, }. Then, we can express
`,u
`,u
B equivalently as B 0 = Bi,t
0 (1 )  Bi,t0 (2 ).

Proof. This result follows immediately from the validity and satisfiability of beliefs in Definition 3.16:
`,u
The formula B = Bi,t
0 (1  2 ) is satisfiable (valid) iff for at least one (all) thread(s)


T hk  T it holds that T hk |= 1 or Thk |= 2 and the respective entries in Pt0 () satisfy

`,u
Definition 3.16-1. For the former case, Bi,t
0 (1 ) is satisfiable (valid) as well, while for the
`,u
latter case Bi,t
0 (2 ) is satisfiable (valid), which reflects exactly the definition of disjunctive
`,u
`,u
belief formulae from Definition 3.16-4. Thus, B 0 = Bi,t
0 (1 )  Bi,t0 (2 ) is satisfiable (valid)

`,u
iff B = Bi,t
0 (1  2 ) is satisfiable (valid).

`,u
Similarly, the formula B = Bi,t
0 (1  2 ) is satisfiable (valid) iff for at least one (all)

thread(s) T hk  T it holds that both Thk |= 1 and Thk |= 2 hold and the respective
`,u
`,u
entries in Pt0 () satisfy Definition 3.16-1. Then, both Bi,t
0 (1 ) and Bi,t0 (2 ) are satisfiable
`,u
`,u
(valid) and thus, the formula B 0 = Bi,t
0 (1 )  Bi,t0 (2 ) is satisfiable (valid) according
`,u
`,u
to definition Definition 3.16-3. Thus, B 0 = Bi,t
0 (1 )  Bi,t0 (2 ) is satisfiable (valid) iff
`,u
B = Bi,t
0 (1  2 ) is satisfiable (valid).

To illustrate the evolution of beliefs, we finish the train example with an analysis of
expected arrival times.
Example 3.10 (Trains continued). From D, as specified in Example 3.9 (p. 60), we can
infer that Bob (and of course Alice, too) can safely assume at time 1 that Alice will arrive
at time 8 at the latest with a probability in the range [0.9, 1], as expressed in the belief
formula
0.9,1 ef r
BB,t = BB,t
(r7 (on(A, T1 ), (at(T2 , CB )  on(A, T2 ))))

64

(22)

fiPDT Logic

with t = 1. For this rule, we obtain the frequencies
efr(T h, at(T1 , CA ), (at(T2 , CB )  on(A, T2 )), 7) = 1

efr(T h, at(T1 , CA ), (at(T2 , CB )  on(A, T2 )), 7) = 0

for T h  {T h1 , ..., T h5 },

for T h  {T h6 , ..., T h9 },

i.e., in threads T h1 , ..., T h5 from Figure 1 (p. 50), the event (at(T2 , CB )  on(A, T2 )) occurs
within 7 time points following the event on(A, T1 ) from time t = 1 (and thus at time t = 8
at latest), while in threads T h6 , ..., T h9 , the event (at(T2 , CB )  on(A, T2 )) occurs only at
time t = 9, which is outside of the scope of r7efr and thus yields a frequency of zero.
At time point 1, Bob still considers all threads as possible, and thus Bobs subjective
posterior probabilistic interpretation

Th
IB,1
(T ) = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03
is equal to the prior interpretation given in Example 3.6 (p. 53) for all possible pov threads
Th. Combining this interpretation with the frequencies given above yields the sum
X 
Th
IB,1
(T h)  efr(T h, at(T1 , CA ), (at(T2 , CB )  on(A, T2 )), 7) = 0.92
T hT

and thus formula BB,1 is valid.
Now, consider the previously described situation, where T1 is running late and A does
not inform B about it. This leads to the updated interpretations given in (6) and (7) on
page 54, i.e.,


T h4
IA,3
=(

Th4
IB,3

0

0

0

0.4 0

0.2 0

0.4 0 ),

and

 ( 0.82 0.02 0.10 0.02 0 0.02 0 0.02 0 ).

These updates lead to a significant divergence in the belief of the expected arrival time:
The corresponding sum with respect to Alices updated interpretation is
X
T h4
IA,3
(T h)  efr(T h, at(T1 , CA ), (at(T2 , CB )  on(A, T2 )), 7) = 0.4,
(23)
T hT

(24)
obtained by Alices subjective posterior probability assignment of thread T h4 , which is the
only nonzero summand in the above sum; all other threads T h are either impossible from
T h4
Alices point of view (i.e., IA,3
(T h) = 0 for threads T h  {T h1 , T h2 , T h3 , T h5 , T h7 , T h9 }),
or the corresponding frequency is zero (for threads T h6 and T h8 ). Thus, Alices belief in
arriving at time point 8 at the latest is drastically reduced, as the lower bound ` of Alices
belief may not exceed 0.4. For instance,

0.4,1 ef r
BA,3
r8 (on(A, T1 ), (at(T2 , CB )  on(A, T2 ))) ,
(25)
is now a valid belief formula. The corresponding sum for Bobs belief at time point 3 is
X
T h4
IB,3
(T h)  efr(T h, at(T1 , CA ), (at(T2 , CB )  on(A, T2 )), 7) = 0.96,
(26)
T hT

65

fiMartiny & Moller

obtained by summing over Bobs subjective posterior interpretations for threads T h1 , ..., T h4 ;
the remaining threads again only contribute zero summands because either Bobs probability assignment or the corresponding frequency is zero for those threads. Thus, Bobs
previous belief (expressed in (22)) remains valid at time point t = 3, denoted by BB,3 .
Even though Alices beliefs have changed significantly, she is aware that Bob maintains
beliefs conflicting with her own, as is shown by the following valid expression of nested
beliefs:
1,1
BA,3
(BB,3 )
To verify that this nested belief holds, we need to consider all threads that Alice considers
possible (T h4 , T h6 , T h8 ) and determine what Bobs hypothetical beliefs would be in these
threads. For T h4 , this has already been analyzed in (26). Since threads T h4 , T h6 , and
T h8 are indistinguishable to Bob at time point 3, the same analysis results hold for all
three threads. Consequently, BB3 holds in every thread that Alice considers possible and
therefore the sum for this nested belief is
X
Th
Ii,t
0 (T h) = 1,
T hT

T h |=B
IB,3
B,3

i.e., Alice knows that Bobs belief is outdated.
Finally, consider the pointed doxastic system hD, Obs{AB} (at(T1 , CC ))3 i, i.e., the same
situation as before with the only difference that Alice now shares her observation of the
delayed train with Bob. It immediately follows that Bob updates his beliefs in the same
way as Alice, which in turn yields an update in Alices beliefs about Bobs beliefs so that
now the following expression is valid (because 1 is not a valid lower bound any longer):
1,1
(BB,3 )
BA,3

This example shows how Alice can reason about the influence of her own actions on
Bobs belief state and therefore she can decide on actions that improve Bobs utility (as he
does not have to wait in vain).

4. Satisfiability Checking for PDT Logic
In this section we will describe procedures to check whether there exists a model for some
given set of belief formulae B. For the discussions in this chapter, we assume that all models
and sets of formulae are finite. We start with formally defining the satisfiability checking
problem in PDT Logic. Using the semantics from the previous section, we derive a model
checking algorithm based on fully specified doxastic systems. Afterwards, we show how a set
of belief formulae can be used to specify a problem in PDT Logic andtogether with a given
set of threadshow this can be transformed into a mixed integer linear program in order
to employ existing solvers to decide satisfiability of PDT Logic formulae. Finally, we show
how suitable threads can be derived from a given set of belief formulae automatically. Using
transformations to linear programs is an established approach when deciding satisfiability
of probabilistic logics, as discussed for example by Fagin, Halpern, and Megiddo (1990).
However, if no priors are given, established decision procedures for probabilistic logics are
66

fiPDT Logic

not applicable to PDT Logic due to the formalisms update mechanism (cf. the update rule
from Definition 3.9, p. 54). This update mechanism
If a fully specified doxastic system hD, Hi is given, we can define the problem of checking
whether a set of belief formulae B is satisfiable with respect to this doxastic system as

follows. Recall from Section 3.2.4 that we use I T h to denote the set of all subjective
Th induced by a prior interpretation I in a pov thread Th.
posterior interpretations Ii,t
0
Definition 4.1 (Satisfiability Checking for PDT Logic). Let hD, Hi be a pointed doxastic
system with the set of threads T and according prior interpretation I specified in hD, Hi,
and B be a set of belief formulae. We say that B is satisfiable w.r.t. hD, Hi if there exists
a thread Th in T such that the corresponding interpretations satisfy all belief formulae B
from B:



sat(B, hD, Hi)  Th  T : B  B : I T h |= B
(27)
If such a specification is given, checking satisfiability of B with respect to hD, Hi corresponds to checking whether hD, Hi is a model for B. We continue with introducing a model
checking procedure for this fully specified input. Afterwards, we discuss how satisfiability
of a set of belief formulae B can be decided if no prior probabilities, or neither threads nor
prior probabilities are given.
4.1 A Model Checking Algorithm
A first approach of developing an algorithm to check whether a given set of belief formulae
B is satisfied by a given pointed doxastic system hD, Hi (i.e., checking whether hD, Hi is
a model for B) can be obtained through a direct application of the semantics of the belief
operator given in Definition 3.11 (p. 57). Algorithm 1 shows the resulting model checking
procedure. It starts with computing the belief states for all possible evolutions of the world
from t = 1 to tmax . Afterwards, it iterates through all belief formulae B  B and potential
pov threads Thk to determine whether the interpretation in the respective pov thread is
able to satisfy the current belief formula. If a thread is unable to satisfy some belief formula,
it is excluded from the set of potential pov threads for subsequent checks. If at least one
potential pov thread remains after all belief formulae have been checked (i.e., there is at
least one thread Thk so that all belief formulae B  B are satisfied), hD, Hi is a model for
B.
Theorem 4.1 (Soundness and completeness of Algorithm 1). The decision procedure Algorithm 1 is sound and complete and therefore a model checking procedure for PDT Logic.
Proof. Since the presented algorithm is essentially an inductive application of Definition 3.16
(p. 63), it is easy to see that it yields a sound and complete decision procedure for PDT
`,u
`,u fr
Logic. Basic belief formulae (Bi,t
0 (Ft ) and Bi,t0 (rt (F, G))) return satisfiability results by
directly using the respective semantic definitions from (10) and (11) as calculation rules.
`,u
`,u
0
00
For every possible compound belief formula of PDT Logic (Bi,t
0 (), Bi,t0 (B), B B , and
0
00
B  B ), the procedure provides an appropriate rule according to Definition 3.16 to break
down these formulae iteratively until base formulae are obtained, which can be decided as
above.
67

fiMartiny & Moller

Algorithm 1 Model Checking
procedure ModelChecking(hD, Hi, B)
h1
hm
bs(hD, Hi, 0)  (AT
, ..., AT
)
0
0
for t  1, tmax do
bs(hD, Hi, t)  bs(hD, Hi, t  1)  (UtT h1 , ..., UtT hm )
for B  B do
for Thk  T do
if not Check(bs(hD, Hi), Thk , B)) then
T  T \ {Thk }
if T =  then
return false
return true

. compute all belief states

. check if B is satisfied in Thk
. otherwise remove Thk from threads to check
. exit if no Th can satisfy B
. success if T is nonempty after checking all B  B

function Check(bs(hD, Hi), Thk , B)
switch (B)
. check formulae according to Def. 3.16
`,u
case Bi,t
0 ():
if  = B 0 then
. check nested belief formulae recursively (B 0 is a belief formula)
0

if not Check(bs(hD, Hi), T hk , B )) then
return false
Th
Pt0  bs(hD, Hi, t0 )  ~b()
. use ~b() from (20) to compute Pt0 with elements pi,t0k
Th

Th

Th

. true if pi,t0k  [`, u]

return (`  pi,t0k and u  pi,t0k )
`,u
case Bi,t
0 ():

Pt0  bs(hD, Hi, t0 )  ~b()
Th

Th

Th

. true if pi,t0k 6 [`, u]

return (`  pi,t0k or u  pi,t0k )
case B 0  B 00 :
return (Check(bs(hD, Hi), Thk , B 0 ) and
Check(bs(hD, Hi), Thk , B 00 ))
case B 0  B 00 :
return (Check(bs(hD, Hi), Thk , B 0 ) or
Check(bs(hD, Hi), Thk , B 00 ))

68

fiPDT Logic

The asymptotic complexity of Algorithm 1 depends on the number of belief operators
`,u
Bi,t
0 () contained in B:
Theorem 4.2 (Time complexity of Algorithm 1). Let B be a set of belief formulae and let
k be the number of belief operators contained within B. Then, using Algorithm 1 to check
whether a given pointed doxastic system hD, Hi with m threads is a model for B has time
complexity O(k  m).
Proof. For a given pds with m threads and k belief formulae in B, the main procedure calls
the check function at most m  k times. If B is a base formula with only a single belief
`,u
operator Bi,t
0 (), a single call of the check function will return a result. Otherwise, if a
`,u
belief formula B contains more than one belief operator Bi,t
0 (), the check function will
be called recursively, until base formulae are obtained. Thus, for k belief operators in B,
the satisfaction checks are performed at most k  m times, yielding a time complexity of
O(k  m).

From Theorem 4.2 we immediately obtain a complexity result for the model checking
problem in PDT Logic:
Corollary 4.3 (Complexity of model checking for PDT Logic). The model checking problem
for PDT Logic is in PTIME.
This result shows that model checking of a set of belief formulae w.r.t. a given pointed
doxastic system can be done in polynomial time. If a fully specified pds (and thereby an
exhaustive specification of the set of possible threads T ) is given, this result shows that
Algorithm 1 presents a tractable procedure to perform the model checking task. However,
this approach has a significant drawback as it assumes an exhaustive specification of T
together with precise prior probability assignments I(T ). Although there are some problem
domains that actually come with such a specification (e.g., cf. the cyber security scenario
described in the introduction), this assumption renders Algorithm 1 infeasible for most
problem domains. To overcome this problem, we will proceed with discussing a different
approach, which enables satisfiability checking without requiring a specification of exact
probabilities. Moreover, we show how representative threads with respect to a set of belief
formulae B can be constructed automatically, so that positive satisfiability results can
potentially be obtained without requiring a full materialization of all possible threads T .
4.2 A Compact Problem Specification
Up until now we used a (pointed) doxastic system to specify a problem domain for model
checking a set of belief formulae B in PDT Logic. In the following sections, we show how
we can reformulate the problem such that an extended set of belief formulae together with a
value for tmax is used. The main idea of this approach is that background knowledge regarding the target domain is not given through an explicit specification of possible threads and
according probabilities, but instead through sets of rules in B that describe how the target
domain may evolve over time. This approach has several advantages: In most scenarios,
compared to requiring an exhaustive set of possible threads, specifying a set of rules (which
can be expressed as prior beliefs) gives a more natural means of specifying background
69

fiMartiny & Moller

knowledge of the problem domain (e.g., cf. Example 3.2 on page 47, which actually starts
with a verbal description of rules and only later introduces the corresponding set of possible
threads). Furthermore, using a set of rules to describe a problem domain is a fairly established approach and therefore this approach will provide options to simplify transformation
of existing problem specifications into PDT Logic. Finally, since the set of possible threads
grows exponentially with every additional time point in the set of time points  and every
additional ground atom of the language L, an exhaustive problem specification through
the set of possible threads quickly becomes infeasible, while the same situation could be
described succinctly through a small set of rules. Even though such a succinct specification shifts the exponential nature of this problem from the required input specification to
computational efforts, we show that the exponential effect can be curtailed with heuristics
when constructing possible threads automatically.
4.2.1 Identification of Key Parameters from a Set of Belief Formulae
To simplify the following discussion, we will restrict temporal rules to only use the point
frequency function pfr. Recall that point frequency functions are used to specify that
some event F is followed by another event G after exactly t time points, while existential
frequency functions efr are used to specify that some event F is followed by another event G
within a time interval t. If existential frequency functions are required to specify a problem
domain, we can rewrite them as disjunctions of point frequency functions, as the following
proposition shows. If further frequency functions are defined, the presented techniques can
be easily adapted.
Proposition 4.4 (efr rewriting). An existential frequency function efr can be equivalently
represented as a disjunction of point frequency functions pfr:
efr
(F, G) 
rt

_

pfr
rt
 (F, G)

 0tt

t:

Recall that, according to Definitions 3.12 and 3.14 on page 59, the specification of a pds
consists of a set of agents A, a set of threads T , a set of frequency functions F, a matrix of
|A||T |

prior probability distributions A0
, and a set of time-stamped observations H.
Since we will only use point frequency functions in the following, the set of frequency
functions F is always fixed to {pfr}, and thus there is no need to specify this set separately.
Instead of explicitly specifying the set of agents A, we can just determine it from the
`,u
belief expressions Bi,t
0 () contained in the set of belief formulae B. With a slight abuse of
`,u
`,u
notation, we use Bi,t
0 ()  B to denote that belief operator Bi,t0 () appears somewhere in
a set of belief formulae B. Then, we can define the set of agents AB specified through a set
of belief formulae B as
`,u
AB = {i : Bi,t
(28)
0 ()  B}

Generally, it is possible that the explicit specification of the set of agents A is larger than
the set AB . However, it is obvious that if no beliefs are expressed for some agent i (i.e.,
i  A and i 6 AB ), this agent will not influence satisfiability checking results whatsoever.
Thus, this agent can simply be disregarded and, consequently, it suffices to use the set AB .
70

fiPDT Logic

Similarly, instead of specifying the set of ground atoms of the language L through the
sets of predicates Lpred and constants Lcons , we can define a set of event formulae FB
representing all belief objects occurring in a set of belief formulae B as
n
o
`,u
`,u fr
`,u fr
FB = F : Bi,t
.
(29)
0 (Ft )  B  Bi,t0 (rt (F, G))  B  Bi,t0 (rt (G, F ))  B
This definition gives rise to a potential definition of the set of possible worlds  as
the Herbrand base B FB of FB (resp. the set of admissible worlds    complying with
Definition 3.5 (p. 48). However, as we will show later, there are more options to constrain
the sets of possible worlds to allow for a more concise problem representation.
Note that according to Definition 3.2 (p. 45), formulae may include both atoms and
observation atoms. Consequently, FB does not only specify ontic facts of possible worlds,
but also possible observations of these ontic facts. With this approach, occurrences of
observations are limited to the ones specified in FB . This can be seen as the specification
of a sensor model for groups of agents G  AB .
Remark 4.1. A strict application of (29) would prohibit simple specifications of group observations ObsG (l) with |G| > 1 in B. To ensure that the set of admissible worlds
actually
V
contains worlds with ObsG (l), a full specification of such an observation as G 0 G ObsG 0 (l)
in B would be required (otherwise there might be no world   B FB with  |= ObsG (l)
that satisfies the second property in the definition of possible worlds (cf. Definition 3.5)).
However, the required full specification of an observation for admissible worlds can be determined solely through the simple observation specification ObsG (l). In order to keep the
specification of B as compact as possible,
we allow for simple specifications ObsG (l) and
V
assume that they are expanded with G 0 G ObsG 0 (l) while creating FB .
An alternative approach would be to construct FB only through ontic facts appearing
in B and create a set of admissible worlds by combining all ontic facts with all possible
admissible observations w.r.t. Definition 3.5. These approaches differ in the requirements
of observation specifications: the former requires to specify every possible observation explicitly, while the latter requires to exclude every impossible observation explicitly. Since in
most scenarios the set of observations actually being possible (w.r.t. the problem domain)
is significantly smaller than the set of all admissible observations, the presented approach
will usually yield a more compact problem specification. If desired, one could employ the
latter approach instead without impacting the functionality of the following methods.
Background knowledge regarding the target domainthat was given through an explicit
representation of possible threads beforecan now also be specified as prior beliefs (i.e.,
`,u
beliefs Bi,0
()) in B. Recall from Section 3.2.4 that we assume a commonly known prior


T h which is equal for all agents i  A . As the belief semantics is defined
distribution Ii,t
B


T h (cf. Definition 3.11, p. 57), it follows
with respect to the probabilistic interpretations Ii,t
0

`,u
that every prior belief Bi,0
() is common knowledge as well. Consequently, we can express
background knowledge as prior beliefs of any arbitrary agent i  AB .
`,u fr
As pointed out in Section 3, satisfiability of beliefs in temporal rules Bi,t
0 (rt (F, G))

with certain properties are independent of the respective set of threads T or the associated
interpretation I(T ) (cf. Remark 3.5, p. 58): if the respective frequency function corresponds
71

fiMartiny & Moller

to FF1 or FF2 of Definition 3.10 (i.e., F is a contradiction, G is a tautology, or F is a tautology and G is a contradiction), beliefs are either trivially satisfied for quantifications with
u = 1 (resp. ` = 0) or generally unsatisfiable. In the former case, trivially satisfiable beliefs
can be disregarded without influencing satisfiability results, while for the latter case satisfiability checking can terminate immediately with a negative result. Thus, in the following we
assume that B contains only beliefs in rules that do not correspond to frequency function
axioms FF1 and FF2.
Example 4.1 (Trains revisited). An informal verbal description of the train problem was
given in Example 3.2 (p. 47) with a corresponding formal specification through a set of
possible threads T in Example 3.4 (p. 51)and probability assignments in Example 3.6 (p. 53).
Using the above considerations on the expression of background knowledge as beliefs in rules,
we can reformulate the verbal rules given in Example 3.2 together with the probabilistic
information from Example 3.6 as a set of formal beliefs B with according explanations
below:



1,1
1,1


B1 = BA,0
at(T
,
C
)

B
on(A,
T
)
,
1
1
1
1
A

A,0







.81,.81 pfr


(B20 )
r0 (at(T1 , CA ), punct(T1 ))
BA,0


B
=

2


.81,.81 pfr

 BA,0
r0 (at(T2 , CC ), punct(T2 )) ,
(B200 )









1,1


r3pfr ( punct(T1 )  at(T1 , CA ), at(T2 , CC )  on(A, T2 )) (B30 )
BA,0


B3 =



1,1 pfr

 BA,0
(r5 (punct(T1 )  at(T1 , CA ), at(T2 , CC )  on(A, T2 )) , (B300 )







1,1
B=
r2pfr ( punct(T2 )  at(T2 , CC ), at(T2 , CB )  on(A, T2 )) (B40 )
BA,0

B4 =



1,1


 BA,0
r3pfr (punct(T2 )  at(T2 , CC ), at(T2 , CB )  on(A, T2 )) , (B400 )








1,1


B5 = BA,0
r0pfr (punct(train)  at(train, city), Obs{A} (punct(train))) ,









.93,.93 pfr

B6 = BA,0
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) ,









train  {T1 , T2 },




city  {C , C }
A

B













































































Note that all beliefs are expressed for time t = 0, i.e., these are prior beliefs that are by
definition commonly known among all agents. All beliefs expressed in this example are
assigned to A, but they could equivalently be assigned to B or to both.
B1 states that train T1 is at city CA at time t = 1 and that Alice is on that train. B2
states that both agents believe that trains are punctual (denoted by punct(train)) with a
probability of 0.81. The probability values in this example are obtained by summing over the
probabilities given in Example 3.6 for all threads given in Example 3.4 where the respective
belief object is satisfied. To have an equivalent representation of the previous example, we
72

fiPDT Logic

use exact probability values (i.e., ` = u) instead of intervals. Note that punct(train) is an
additional predicate with a variable train that helps to formulate the background knowledge
in a concise way. Formula B2 does not yet specify what the consequences of a non-punctual
train are, only that a train is expected to be punctual with a certain probability. B3 states
that Alice is able to board train T2 after three time steps if train T1 is punctual and that
Alice has to wait for two additional time points otherwise. B4 states that train T2 will
arrive at city CB two time points after being in city CC . Otherwise she will arrive one
time point later. B5 states that Alice will always notice when her train leaves a city not
punctually. This is an example for a sensor model specification as discussed above. Finally,
B6 states that Alice will call Bob with a probability of 0.93 if her train is not punctual.
Example 4.2 (Trains continued). With the definition of the set of belief formulae B from
the above example, we can now also specify the set of event formulae FB required to model
the possible scenarios described through B:






at(T
,
C
),
at(T
,
C
),
at(T
,
C
),
at(T
,
C
),
1
1
2
2
A
B
B
C






 on(A, T ), on(A, T ), punct(T ), punct(T ),

1
2
1
2
FB =


Obs{A} (punct(T1 )), Obs{AB} (punct(T1 )),








 Obs (punct(T2 )), Obs

(punct(T
))
2
{A}
{AB}
To simplify the following discussion, we assume that conjunctive formulae B = B 0 
 B are replaced with individual formulae of the respective conjuncts: B = B \
{B}  {B 0 , B 00 }. This does not impact the satisfiability checking properties of B because
all formulae in B have to be satisfied simultaneously in order to return a positive result
and thus, both B 0 and B 00 have to be satisfied, regardless of their representation as two
individual formulae or as one conjunction.
Now, what remains to be determined is the set of threads T , a corresponding prior
B 00

|A||T |

probability distribution I(T ) (resp. a matrix of prior probability distributions A0
,
where every row is formed by I(T )), and possibly a set of time-stamped observation atoms
H. The tasks of determining T and H can be treated jointly: since the set of relevant
threads needs to be determined anyway, we simply create T such that T |= H.
In the next section we will show how we can transform a set of PDT Logic belief formulae
B together with a given set of threads T into a linear program in order to determine
satisfiability of B with respect to T . Afterwards, we will discuss how a suitable set of
threads T to represent the information contained in B can be constructed automatically.
Using these results, it is possible to model a problem domain in PDT Logic solely through
a set of belief formulae B together with the specification of a maximum time point tmax .
All other key parameters of the domainsuch as the set of agents and the set of ground
atomscan be extracted from B automatically.
4.3 Representing the Satisfiability Problem as a Linear Program

The considerations from the previous section show that most parameters for a problem
specification can be extracted from a given set of belief formulae B. In this section, we
assume that only a set of belief formulae B together with a set of possible threads T is given.
73

fiMartiny & Moller

B is then satisfiable with respect to T (denoted by sat(B, T )) if a prior interpretation I(T )
can be found such that all belief formulae in B are satisfied. By extracting linear constraints
on I(T ) from B, we show how the satisfiability problem can be transformed into a linear
program. Checking satisfiability of B with respect to T is then equivalent to checking
whether the corresponding linear program has a feasible solution.
For a given set of threads with an unknown prior interpretation I(T ), the satisfiability
checking task significantly increases in complexity compared to the model checking task.
Formulation of the satisfiability checking problem in Definition 4.1 (p. 67) might be somewhat delusive: As the existence of a single thread in the context of some interpretation
suffices to verify satisfiability of a set of belief formulae B, it appears intuitive to develop
a method to construct such a threadif possibleand neglect the other threads, or, vice
versa, start with the entire set of threads T and iteratively prune all threads that fail to satisfy any formula from B. In fact, such a pruning approach was used in Algorithm 1 (p.68)
to check whether a given set of threads is a model for a set of belief formulae. Unfortunately,
these approaches are inapplicable if the prior interpretation is unknown. As the semantics of
belief operators (cf. Definition 3.11 (p. 57) relies on subjective posterior probabilistic interpretations (i.e., on probability assignments for multiple threads), it is generally not possible
to find a single thread Th satisfying the satisfiability checking problem from Definition 4.1
without determining probabilities for all threads. Vice versa, it is generally not possible
to discard any thread, because determining whether it satisfies any belief formula can only
be done if its respective probability assignment is known. Instead, we will show that belief
formulae can equivalently be expressed as sets of linear constraints on the unknown prior
interpretation I(T ). Then, checking satisfiability of B is equivalent to checking whether
there is a possible assignment to I(T ) so that all constraints are satisfied.
We will use xk to denote the unknown prior probability of thread T hk , i.e., if T contains
m threads, then its unknown prior probability assignment is represented as
I(T ) = x1 ,    , xm

T

.

(30)

The goal of the following methods is to provide constraints on the xk so that all belief
formulae B  B are satisfied. Since these variables represent a probability distribution
over the set of threads, there are two obvious constraints to begin with:
0  xk  1, k  {1, ..., m}
and

m
X

xk = 1

(31)

(32)

k=1

4.3.1 Representation of Subjective Posterior Probabilities
Since the semantics of beliefs is defined in terms of the respective agents subjective probability assignments in the respective pov thread, we need means to express the subjective
Th of an agent i in terms of the prior probability
posterior probabilistic interpretations Ii,t
0
values xk . These interpretations change at a time point t whenever an observation Obs{i} (l)t
is possible for agent i. If an observation is possible for an agent, we can partition the set of
threads into two sets: one partition containing the set of threads where agent i does observe
74

fiPDT Logic

the respective fact l and one partition where agent i does not observe the respective fact.
The subjective probability assignments need to be updated within each partition to reflect
this information about observation occurrences: Taking every thread within a partition as
a possible pov thread, the probability assignments for all other threads within this partition
need to be scaled according to the update rule in Definition 3.9 and the pov thread specific
probability assignments for all threads outside of the respective partition need to be set to
zero.
Generally, this leads to one vector of subjective probabilities over all threads for every
possible pov thread (cf. the Definition of belief states in Equation (17), p. 61). However, we
can leverage the semantic properties of PDT Logic to obtain a parsimonious representation
of the updated subjective probabilities without representing every pov thread explicitly.
Note that all threads within one partition as described above are indistinguishable to agent
i at the respective time point (i.e., all threads within one partition exhibit exactly the same
set of observations for agent i up to time point t) and therefore receive the same probability
assignment for every possible pov thread within this partition (cf. Proposition 3.6, p. 62).
Consequently, the updated probability assignments for every thread in T can receive only
one of two different types of value assignments: a scaled version of the threads previous
probability assignment according to Definition 3.9 (p. 54), or zero, depending on whether
the agent actually observes the fact l or not. The following proposition shows that we do not
need to consider the cases with zero probabilities in order to perform satisfiability checking
tasks.


T h be the subjective posterior
Proposition 4.5 (Irrelevance of zero-interpretations). Let Ii,t
0
0
probability interpretation at time t for some agent i in pov thread Th (i.e., this interpreta-

tion is determined through the prior interpretation and interpretation updates corresponding
to pov thread Th). If this interpretation assigns a probability of zero to some thread T h (i.e.,
Th (T h) = 0), then satisfiability of any subsequent nontrivial belief B 00 () with t00 > t0 is
Ii,t
0
i,t


T h (T h).
independent of Ii,t
0

`,u
Proof. Every belief Bi,t
0 () with ` > 0 in a fact or in another belief (i.e.,  = Ft or
` ,u

 = Bj,tj j ()) requires that there needs to be at least one thread T h with a nonzero


T h (T h) = 0 can clearly not
probability such that T h |= . Therefore, a thread T h with Ii,t
0
`,u
00
0
prove satisfiability of a belief Bi,t
00 () with t  t . A negative satisfiability result (i.e., B

is unsatisfiable w.r.t. T ) cannot be obtained from such a zero assignment either, because
any consistent interpretation (i.e., the probability assignments of all threads sum to one)
needs to assign a nonzero probability to at least one thread, which could then possibly
`,u
satisfy the belief. The same considerations hold for beliefs Bi,t
0 () with ` = 0 and u < 1:


T h (T h) = 0 satisfies the lower bound ` = 0, the upper bound u < 1
Although a thread with Ii,t
0


T h (T h0 ) > 0 such
requires the existence of another thread T h0 with a nonzero probability Ii,t
0


T h (T h) = 0 can only prove satisfiability of beliefs B `,u ()
that T h0 |= . Consequently, Ii,t
0
i,t0
with ` = 0 and u = 1. These are trivial beliefs that are satisfied by every thread and
every possible probability assignment and thus, their satisfiability can be proven without
Th (T h) = 0, too.
Ii,t
0

75

fiMartiny & Moller

`,u fr
Analogous considerations hold for beliefs in rules: A belief Bi,t
0 (rt (F, G)) with ` > 0
requires the existence of a thread with a nonzero probability such that fr(T h, F, G, t) > 0,
Th (T h) = 0 cannot prove satisfiability of this belief. Satisfiaand thus a thread T h with Ii,t
0
`,u fr
bility of a belief Bi,t
0 (rt (F, G)) with ` = 0 and u < 1 depends on the respective frequencies
0
fr(T h , F, G, t) in additional threads T h0 with nonzero probabilities.

As a result of this proposition, we can merge the nonzero entries from both cases (agent
i observes the fact l and agent i does not observe the fact l) into a single probability
distribution vector for each agent i and time point t. This yields a modified version of the
update rule from Definition 3.9. We will use this modified update rule to determine linear
constraints on the unknown prior probabilities xk .
Definition 4.2 (Modified update rule). Let i be an agent, t0 be a time point where some observation Obs{i} (l) can occur and T h be a thread. Then, a compressed subjective posterior
probability assignment Ii,t0 (T h) for agent i at time t0 for thread T h is given through
Ii,t0 (T h) =

1
 Ii,t0 1 (T h)
Th
i,t
0

(33)

T h again being a normalization factor to ensure that the probabilities of all threads
with i,t
0
that agent i considers possible sum to one:
X
Th
Ii,t0 (T h0 )
i,t
0 =
T h0 (t0 )Ki (T h(t0 ))

Example 4.3 (Modified update rule). To illustrate the modified update rule, we return to
the situation described in Example 3.7 (p. 54). In this example we assumed that train T1
is running late and A does not inform B about it. This resulted in the following updated
interpretation for A:

Th8
Th6
Th4
= 0 0 0 0.4 0 0.2 0 0.4 0
= IA,3
= IA,3
IA,3
In the given example, two additional hypothetical partitions of the set of threads T are
possible for Alice at time point t = 3 . If train T1 is running late and A does inform
B about it, threads T h5 , T h7 , and T h9 are indistinguishable to A, yielding the updated
subjective interpretation

Th5
Th7
Th9
IA,3
= IA,3
= IA,3
= 0 0 0 0 0.14 0 0.65 0 0.21
If T1 is on time, Alice considers threads T h1 , T h2 , and T h3 as possible. The corresponding
subjective interpretation is then

Th1
Th2
Th3
IA,3
= IA,3
= IA,3
= 0.86 0.03 0.11 0 0 0 0 0 0
These three different subjective interpretations have nonzero entries exactly for the threads
that are in the partitions of the respective pov thread. Since the partitions are not overlapping, we can merge the nonzero entries into a single probability vector

IA,3 = 0.86 0.03 0.11 0.4 0.14 0.2 0.65 0.4 0.21 .
76

fiPDT Logic

Note that in this modified update rule, the update for each pov thread does not specify interpretations over all threads anymore, but instead only the reflexive interpretations
for each thread T h, given that T h is the pov thread, are used. As discussed above, for
the satisfiability problem this is still a sufficient representation of posterior probabilities,
because all other potential pov threads Th in the respective partition are indistinguishable
to agent i and therefore yield exactly the same interpretations. It should be noted however that Ii,t0 (T h) is not a probabilistic vector anymore, i.e., its elements do not sum to
one. Compared to the representation of belief states from Section 3.3.1 (p. 61), information
about distinguishable worlds is lost. Thus, reconstruction of an agents belief state from this
representation is only possible with an additional specification of the respective relations
Ki .
Returning to the problem representation from (30) (p. 74), we can use the modified update rule to obtain an inductive definition of subjective posterior probabilities based on the
T
respective (unknown) prior probabilities xk . If I(T ) = x1 ,    , xm is the prior interpretation over the set of threads, agent is compressed subjective posterior interpretations
Ii,t0 at the time point t0 of the first possible interpretation can be represented as
Ii,t0 (T ) =



1
1i,t0

 x1 ,    ,

1
m
i,t0

 xm



0

T

,

(34)

k determined through
with the update factors i,t
0

1
i,t
0



i,t
1,1



.
m T

i,t
x
,



,
x
=

0
1
m
 ..


..
.

0

i,t
m,1   

i,t0

j,k


0
i,t
1,m
.. 

. ,
0

i,t
m,m

(
1 if T hk (t0 )  Ki (T hj (t0 ))
=
0 if T hk (t0 ) 6 Ki (T hj (t0 ))
0

with a (symmetric) matrix of indicators i,t
j,k denoting whether agent i considers thread
0
T hk possible in thread T hj at time t . Using (34) as the base case, we can then define
interpretation updates for the next possible observation at time t00 inductively as
Ii,t00 (T ) =



1
1i,t00



1
1i,t0

 x1 ,    ,

1

m
i,t00



1

m
i,t0

 xm

T

(35)

To simplify notation, in the following we use a single factor aki,t0 to represent the agk  k  ...) for all observations that can occur at
gregated sequence of scaling factors (i,t
i,t2
1
time points t1 , t2 , ... between t = 1 and t = t0 for agent i, i.e., agent is subjective posterior
interpretations Ii,t0 (T ) at time t0 are given as
Ii,t0 (T ) = a1i,t0  x1 ,    , am
i,t0  xm

T

.

(36)

Note that potential interpretation updates for an agent i can occur at some time point t
if and only if some observation Obs{i} (l) is possible at that time point. Hence, for any time
interval between two possible observations, the subjective interpretations are constant:
77

fiMartiny & Moller

Proposition 4.6 (Piecewise constant interpretations). Let t1 and t2 with t1 < t2 be two
time points such that observations for an agent i are possible at t1 and t2 , but at no time
point t in between t1 and t2 . Then, the compressed subjective interpretation Ii,t0 (T ) is
constant for all time points t1  t < t2 :
t  [t1 , t2  1] : Ii,t (T ) = Ii,t1 (T )
This proposition states that all constraints identified in the following section do not
only restrict the subjective interpretations at single time points, but instead restrict the
interpretations for the respective time interval between any two possible observations.
4.3.2 Extracting Linear Constraints from Belief Formulae
Now that we have established representation (36) of subjective posterior interpretations in
terms of the unknown prior probabilities xk , we can use this representation to extract linear
constraints on the xk from the set of belief formulae B.
We assume that the distributive property of the belief operator from Lemma 3.7 (p. 64)
`,u
is applied whenever possible, i.e., belief formulae Bi,t
0 (B1  B2 ) with   {, } are
`,u
`,u
separated into Bi,t
0 (B1 )Bi,t0 (B2 ). Furthermore, without loss of generality, we can assume
that conjunctive formulae B = B1  B2 are replaced through B \ {B}  {B1 , B2 } and that
trivial beliefs (with ` = 0 and u = 1) are removed from B.
Moreover, we assume that all belief formulae B  B are represented in negation normal
form (NNF), i.e., the negation operator is only applied to atoms. Since any arbitrary logic
formula can equivalently be expressed as a formula in NNF (cf. e.g., Baaz, Egly, Leitsch,
Goubault-Larrecq, & Plaisted, 2001), this assumption does not restrict B either.
With these assumptions, the following types of belief formulae B can occur in B:
`,u
 atomic belief formulae B = Bi,t
0 ()
`,u
 negated atomic belief formulae B = Bi,t
0 ()

 disjunctive belief formulae B = B1  B2
For each of these types, we will now show how the respective formula can be expressed as
a set of linear constraints on the prior probabilities xk .
Atomic Belief Formulae Using the parsimonious representation of subjective posterior
interpretations Ii,t0 (T h) given through the modified update rule in Definition 4.2 requires
an adaption when deciding satisfiability of belief formulae. Before, satisfaction of a belief
formula in a given pov thread could be determined by summing over the respective subjective interpretations of all threads in which the belief object is satisfied. Threads that
an agent does not consider possible anymore w.r.t. the given pov thread are automatically
excluded as they have a probability assignment of zero. In the compressed representation,
the respective probability assignments for threads considered impossible are overloaded with
different probability assignments given that the agent is in another pov thread, as illustrated
in Example 4.3. We obtain an adapted version of satisfiability testing by explicitly ensuring
that only those interpretations of threads are summed that are still considered possible
w.r.t. the respective pov thread. As this additional constraint only excludes summands
78

fiPDT Logic

with zero-values, the original semantics is still maintained. Thus, we use equivalence classes
1 , C 2 , ...} to represent the set of distinguishable situations for agent i at time t0 .
Ci,t0 = {Ci,t
0
i,t0
Naturally, two threads T h1 , T h2 are indistinguishable and therefore in the same equivalence
class for agent i at time t0 , if they exhibit exactly the same observations for agent i for all
time points t  {1, .., t0 }. All threads outside of a particular equivalence class receive a
probability of zero for every pov thread Th within the respective equivalence class andas
discussed in the previous sectiontherefore do not contribute to the satisfiability properties. Then, in the belief semantics from Definition 3.11 (p. 57), instead of summing over all
k : (Th  C k )
threads T h  T with certain properties, we can restrict the range to T h  Ci,t
i,t
while maintaining the original semantics. Naturally, a belief formula is then satisfiable if
there exists at least one equivalence class that satisfies the respective beliefs. For instance,
`,u
a belief in a fact Bi,t
0 (Ft ) is satisfiable with respect to an agent is compressed subjective
posterior interpretation Ii,t0 at time t0 iff
k
Ci,t
0  Ci,t0 : ` 

X
n:

k T h (t)|=F )
(T hn Ci,t
n
0

ani,t0  xn  u

(37)

Such a constraint can equivalently be expressed as a set of linear inequalities with
conjunctive and disjunctive connectives, leading to an alternative representation of the
satisfiability problem.
Corollary 4.7 (Alternative satisfiability representation for atomic beliefs). Let Ii,t0 (T ) =
T
T
a1i,t0  x1 ,    , am
and Ij,t (T ) = a1j,t  x1 ,    , am
be the compressed
j,t  xm
i,t0  xm
representation of agent i and js respective subjective posterior probabilities at time t0 and
t, respectively, as given in (36), and let Ci,t0 and Cj,t be the sets of worlds that agent i and
agent j can distinguish at the respective time point. Then, an atomic belief expression B is
satisfiable w.r.t. Ii,t0 (T ) for
`,u
1. belief in a fact B = Bi,t
0 (Ft ) iff



_
k C
Ci,t
0
i,t0

X
k
(T hn Ci,t
0

n:
T hn (t)|=F )

ani,t0



 xn  ` 



X
k
(T hn Ci,t
0

n:
T hn (t)|=F )

ani,t0


 xn  u

!
(38)

`,u pfr
2. belief in a rule B = Bi,t
0 (rt (F, G)) iff

_



k C
Ci,t
0
i,t0

X
k )
n: (T hn Ci,t
0




X
n:

k )
(T hn Ci,t
0


ani,t0  xn  pfr(T hn , F, G, t)  `
ani,t0  xn  pfr(T hn , F, G, t) 

79


u

!
(39)

fiMartiny & Moller

` ,u

`,u
j j
3. nested belief B = Bi,t
()) iff
0 (Bj,t

_



k C
Ci,t
0
i,t0

X
k )
n: (T hn Cj,t
k
k }6=)
T hn |=  ({Cj,t Ci,t
0




X
k )
n: (T hn Cj,t
k C k }6=)
T hn |=  ({Cj,t
i,t0




X

X
n:

anj,t  xn 

ani,t0  xn 

k C k }
T hn {Cj,t
0
i,t0



uj

ani,t0  xn  `

k C k }
n: T hn {Cj,t
i,t0
 T hn |=




anj,t  xn  `j

u







!
(40)

 T hn |=

As discussed above, the representations for satisfiability of beliefs in facts (38) and beliefs
in rules (39) are obtained directly by replacing the range of threads T in the sum with the
k considered possible by agent i at time t0 . The inequalities for
respective set of threads Cj,t
0
nested beliefs (40) are obtained by ensuring in the first two lines that in every situation
that agent i conceives as a possible situation for agent j (expressed through the constraint
k )  C k  C k 6= ), agent js belief in the respective fact  (expressed
n : (T hn  Cj,t
j,t
i,t0
through the constraint T hn |= ) is within [`j , uj ]. The latter two lines ensure that for
these respective situations, the outer belief of agent i is satisfied, as well. Note that the
belief object  in (40) might contain additional belief operators, i.e., beliefs with multiple
levels of nesting are expressed. In this case, evaluation of T h |=  in the first two lines
of (40) yields additional constraints of type (38)(40), such that the formula is evaluated
recursively.
Negated Atomic Belief Formulae To satisfy a negated atomic belief formula B =
`,u
Bi,t
0 (), the accumulated probabilities of all threads that satisfy the belief object  in
k must be either lower than ` or higher than u, i.e., the individual
an equivalence class Ci,t
0
disjuncts
in (38)(40) have to be negated. By pushing the negations inward and using
X
(   ) as a representative for the respective sums defined in (38) and (39) to express


satisfiability of atomic beliefs, we can represent negations of the according beliefs expressed
in (38) and (39) as
!
 X
  X

_

(   ) < `  
(   ) < u .
(41)
k C
Ci,t
0
i,t0





If nested beliefs as defined in (40) contain negated belief operators, this can be expressed
accordingly by replacing the conjunctive constraints on ` and u (resp. `j and uj ) with the
corresponding disjunctive constraints (41) for negated atomic belief formulae.
80

fiPDT Logic

Disjunctive Belief Formulae With the above inequalities, the required constraints for
a disjunctive formula B = B1  B2 can easily be expressed as an additional disjunction of
inequalities. Let C1 and C2 be the sets of inequalities to express satisfiability of B1 and B2
according to (38)(41), respectively. Then, the constraints for B can be expressed as
C1  C2

(42)

Example 4.4 (Trains continued). In Example 4.1 (p. 72), a set of belief formulae B has
been given for the train example. To illustrate the extraction of linear constraints from
this set, we continue to use the set of threads depicted in Figure 1 (p. 50) with a minor
modification: to reflect the model specified in B of Example 4.1, we assume that the
predicate punct(train) is explicitly encoded in the respective threads. Moreover, for the
sake of the example we assume that the prior probabilistic interpretations are yet unknown.
We use x1 , ..., x9 to denote these unknown probabilities. Note that for our example, we
are only dealing with prior beliefs, i.e., we only have one equivalence class C = T and
all scaling factors ani,t0 are equal to one. This significantly eases the presentation of this
example. Of course, in general we have to deal with both multiple equivalence classes and
multiple varying scaling factors. As this highly increases complexity of the presentation, we
refrain from giving explicit examples for these cases. The constraints from B are extracted
as follows:

.81,.81 pfr
r0 (at(T1 , CA ), punct(T1 )) :
 For belief B20 = BA,0
pfr(T h, at(T1 , CA ), punct(T1 ), 0) = 1 for T h  {T h1 , ..., T h3 }

pfr(T h, at(T1 , CA ), punct(T1 ), 0) = 0 for T h  {T h4 , ..., T h9 }

and thus application of rule (39) yields the constraints
x1  x2  x3  0.81
x1 + x2 + x3 

0.81

In this special case where ` = u, we can simplify this constraint to
x1 + x2 + x3 =

0.81

Since all of the rules exhibit this property, we slightly deviate from (39) and only
give the equivalent equality constraints for subsequent rules in order to simplify the
presentation.

.81,.81 pfr
Accordingly, for belief B200 = BA,0
r0 (at(T2 , CC ), punct(T2 )) we obtain:
pfr(T h, at(T2 , CC ), punct(T2 ), 0) = 1 for T h  {T h1 , T h4 , T h5 }

pfr(T h, at(T2 , CC ), punct(T2 ), 0) = 0 for T h  {T h2 , T h3 , T h6 ..., T h9 }

with the corresponding constraints
x1 + x4 + x5 =
81

0.81

fiMartiny & Moller


.93,.93 pfr
 For belief B6 = BA,0
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) :
for T h  {T h1 , T h3 , T h5 , T h9 } :

pfr(T h, punct(train), Obs{AB} (punct(train)), 2) = 1,

for T h  {T h2 , T h4 , T h6 } :

pfr(T h, punct(train), Obs{AB} (punct(train)), 2) = 0,

for T h  {T h7 , T h8 } :

pfr(T h, punct(train), Obs{AB} (punct(train)), 2) = 0.5

and thus application of rule (39) yields the constraint
x1 + x3 + x5 + 0.5  x7 + 0.5  x8 + x9 = 0.93
 For the remaining beliefs, the respective belief objects are satisfied in every thread
and thus we only obtain the redundant constraints
9
X

xk = 1.

k=1

One can easily verify that prior probabilistic interpretation given in Example 3.6, i.e.,

x = 0.7 0.02 0.09 0.02 0.09 0.01 0.02 0.02 0.03
indeed is a solution with respect to the above constraints. Of course, for the given
example, this solution was expected, as B was defined such that it exactly reflects the
situation described in the examples from the previous section.
4.3.3 Transformation into a Disjunctive Program
For every belief formula B  B, the above extractions of linear constraints yield a set of
inequalities of the form
ai,1 x1 + ai,2 x2 + ... + ai,m xm  bi ,

(43)

with xj representing the unknown prior probabilities of threads T h1 , ..., T hm , the coefficients
ai,j set to the respective values of ani,t0 if they contribute to this constraint and set to zero
otherwise, and the value b1 set to the respective limit obtained through ` or u.
As Corollary 4.7 shows, every belief formula B  B yields a disjunctive set of inequality
constraints, i.e., every belief formula B introduces branches in the set of linear constraints.
By collecting all inequalities of the form (43) that constrain a single branch, we can express
the constraints in matrix form:
Ax  b,
(44)
with



a1,1
 ..
A= .
an,1


..
.



 
 
a1,m
x1
b1
..  , x =      , and b =   
. 
xm
bm
an,m
82

fiPDT Logic

This form of representation has a close connection to linear programming (LP). Linear
programming (e.g., Murty, 1983) is a solution method to optimization problems where some
linear function of a set of continuous variables xk is to be optimized with respect to a given
set of linear constraints. While the task of satisfiability checking does not require any
optimization and thus actually solving a linear program is not required for this work, we
will exploit similarities between our sets of linear constraints and LP in order to show how
the satisfiability problem can be solved.
The standard form of an LP problem (Murty, 1983) gives a set of constraints exactly in
the form of (44). Every solution x that satisfies these constraints is called feasible and the
entire solution space for (44) is called feasible region. Thus, checking whether a set of belief
formulae B is satisfiable is equivalent to checking whether a corresponding LP problem
has a non-empty feasible region. For standard LP problems with constraints of the form
(44), the feasible region is a convex polytope, which allows performing this check with little
computational effort (Garey & Johnson, 1979).
Unfortunately, extracting linear constraints from a set of belief formulae B as described
in Section 4.3.2 does not yield a single set of constraints in the form of (44), but instead
a disjunction of different sets of constraints. This gives rise to the representation of the
satisfiability checking problem as a disjunctive program (DP) (Balas, 1998):
Corollary 4.8 (Satisfiability Checking as a Disjunctive Program). Let B be a set of belief
formulae, let T be a set of threads and let D be the set of all disjunctive branches d of linear
constraints extracted from B and T according to the extraction rules (38)-(42). Then, the
satisfiability checking problem can be formulated as a disjunctive program (Balas, 1998):
_
Ad x  bd
(45)
dD

B is satisfiable with respect to T , denoted by sat(B, T ), if (45) has a solution.
A disjunctive program is called bounded, if the range of every variable xk is restricted
through lower and upper bounds. Since we will rely on the bounded property subsequently,
we state the following result:
Lemma 4.9 (Satisfiability Checking as a Bounded DP). Let B be a set of belief formulae
and T be a set of threads. Checking satisfiability of B with respect to T can be represented
as a bounded disjunctive program.
Proof. This is a straightforward result: Corollary 4.8 shows that satisfiability checking
for PDT Logic can be represented as a disjunctive program in the form of (45). Since
every variable xk in (45) represents a probability value, all xk are naturally bounded by
0  xk  1.
In a disjunctive program, the feasible region cannot be guaranteed to be convex anymore,
nor can it be guaranteed that the solution space even represents a connected region. This
significantly increases the complexity of determining whether a nonempty solution space
exists. To analyze this problem in more detail and to show connections to established
solution approaches, we will discuss in the next section how a disjunctive program in the
form (45) can be further transformed.
83

fiMartiny & Moller

4.3.4 Transformation into a 0-1 Mixed Integer Linear Program
The concept of linear programs with continuous variables xk subject to linear constraints of
the form (43) can be extended to so-called mixed integer linear programs (MILPs) (Schrijver,
1986). Opposed to standard linear programming, for MILPs it is not required that all
variables xk have a continuous domain. Instead, MILPs can use a mix of both continuous
and integer variables. There are several equivalent ways of representing a MILP, we adopt
the representation from Fischetti, Glover, and Lodi (2005), which specifies the constraints
of a MILP as
Ax  b

xj integer

j  I

with an index set I indicating which of the variables xj are integer variables. A special
case of MILPs are 0-1 mixed integer linear programs (Williams, 2009), where the integer
variables xj are restricted to binary values:
Ax  b

xj  {0, 1}

(46)
j  I

By augmenting the set of variables x with binary switching variables xj for every possible
disjunction, it is possible to represent disjunctive programs in the form of (45) as 0-1 MILPs
in the form of (46) (Balas, 1985). This leads to a central result for satisfiability checking in
PDT Logic:
Theorem 4.10 (Satisfiability Checking as 0-1 MILP). Let B be a set of belief formulae
and T be a set of threads. The problem of checking satisfiability of B with respect to T
can be transformed into a corresponding 0-1 mixed integer linear program M so that B is
satisfiable with respect to T iff M has a feasible solution.
Proof. Lemma 4.9 shows that satisfiability checking for PDT Logic can be represented as
a bounded disjunctive program, such that a set of belief formulae B is satisfiable iff the
corresponding bounded disjunctive program has a feasible solution. The proof of Theorem
4.4 from Balas (1985) shows that every bounded disjunctive program can be equivalently
represented as a 0-1 mixed integer program M . Consequently, satisfiability checking for
PDT Logic is equivalent to checking whether M has a feasible solution.
We can leverage Theorem 4.10 to obtain complexity results for the satisfiability problem
in PDT Logic:
Theorem 4.11 (Complexity of PDT SAT w.r.t. a given set of threads). Checking satisfiability of a set of PDT Logic belief formulae B with respect to a given set of threads T is
NP-complete.
Proof. It is generally known that checking whether a bounded 0-1 mixed integer linear
program has a feasible solution is NP-complete (cf. Bienstock, 1996). As Theorem 4.10
shows that satisfiability checking in PDT Logic with respect to a given set of threads T can
be reformulated as a 0-1 MILP with bounded variables xk (cf. Lemma 4.9), it follows that
84

fiPDT Logic

satisfiability checking for a set of belief formulae B with respect to a given set of threads
T is in NP.
Arbitrary propositional formulae F (cf. Definition 3.2, p. 45) can be expressed in PDT
1,1
Logic by using them as a belief object for a strict prior belief Bi,0
(F ). Since it is well known
that the boolean satisfiability problem (SAT) is NP-complete (Cook, 1971), it follows that
any problem in NP can be transformed to a satisfiability checking problem in PDT Logic.
Hence, the satisfiability checking problem in PDT Logic is NP-hard and consequently NPcomplete.
The NP-completeness result shows that the problem is in NP and therefore we immediately obtain another important property of the satisfiability problem in PDT Logic:
Corollary 4.12 (Decidability of PDT SAT). Checking satisfiability of a set of PDT Logic
belief formulae B is decidable.
MILPs have been subject to extensive research for decades, and thus an ample variety
of solving methods has been proposed (e.g., Balas, Ceria, & Cornuejols, 1993, Balas, Ceria,
& Cornuejols, 1996, Balas & Perregaard, 2002, to name some of the most notable work on
MILP solving, and especially Fischetti et al., 2005 and Bertacco, Fischetti, & Lodi, 2007 to
find feasible solutions of MILPs). This research gave rise to various efficient implementations
of MILP solvers, both commercial (e.g., ILOG, 2016, Gurobi Optimization, Inc., 2016) and
non-profit products (e.g., Gnu Project, 2016, Computational Infrastructure For Operations
Research (COIN-OR) Project, 2016). For a given set of threads, PDT Logic satisfiability
checking can be reformulated as a 0-1 MILP problem, and thus any of these state-of-the-art
MILP solvers can be exploited for relatively fast satisfiability checks for most instances of
PDT Logic belief formulae B with respect to a given set of threads T .
The results from this section show how satisfiability of a set of PDT Logic belief formulae B can be decided with respect to a given set of threads, even if no specific prior
probability assignment is specified. As the overall goal of this section is the design of a
decision procedure that requires only a set of belief formulae B as an input, we continue
the discussion of satisfiability testing with the development of a method to automatically
construct a set of threads representing the background knowledge specified in B.
4.4 Prior Constraints on Possible Threads
To determine whether the set of belief formulae B is satisfiable, we need to obtain a set
of possible threads that reflects the background knowledge specified in B. In this section,
we describe how we can identify certain constraints on the set of possible threads T prior
to actually starting to generate threads that represent the information specified in B. To
identify such prior constraints, we discuss different properties of the belief formulae contained in B. Using these properties, we can create a taxonomy of belief formulae depending
on the respective impact on the set of possible threads T . Beliefs with certain properties
can then be used to constrain the search space for sets of possible threads prior to actually search for these sets. After discussing prior constraints in this section, we use these
results in Section 4.5 to develop a decision procedure for PDT Logic that requires neither
a specification of probabilities nor a specification of possible threads.
85

fiMartiny & Moller

4.4.1 A Taxonomy of Belief Formulae
The set of belief formulae B may contain beliefs with various features that will have different
impacts on the sets of admissible worlds at specific time points t. We will discuss these
features below and show how they yield a taxonomy of belief formulae. This taxonomy
allows for the classification of beliefs into three different types with respect to their impact
on the sets of admissible worlds. In particular, we can identify beliefs that are independent
of any specific probability assignment and of any Kripke relations Ki . This classification is
for technical purposes: beliefs that depend neither on specific probability assignments nor
on specific Kripke relations can be used to derive initial constraints on the sets of possible
worlds at some or all time points t  tmax . We use B to denote the set of all worlds
admissible with respect to a set of belief formulae B, and we use B (t) to denote the set
of admissible worlds with respect to a set of belief formulae B at time t.
Recall that there are three different kinds of beliefs: beliefs in facts, beliefs in rules, and
beliefs in beliefs. As before, we differentiate between prior beliefs that hold at time point
t = 0 (and are therefore commonly known among all agents) and posterior beliefs that hold
at time points t > 0.
`,u pfr
We can further distinguish beliefs in rules Bi,t
0 (rt (F, G)) with respect to t: we call
pfr
pfr
(F, G) a dynamic rule if t > 0. Accordingly,
(F, G) a static rule if t = 0 and we call rt
rt
we can separate beliefs in rules into beliefs in static rules and beliefs in dynamic rules,
respectively. These beliefs differ with respect to their temporal impact: a static rule will
constrain the possible worlds instantaneously, i.e., r0pfr (F, G) states that there can be no
world  such that both  |= F and  6|= G hold. A dynamic rule on the other hand requires
that whenever a world  with  |= F occurs, there must be another world  0 with  0 |= G
after t time steps.
Finally, we can classify beliefs with respect to their probabilistic quantifications: we call
`,u
a belief Bi,t
0 () strict, if both ` = u = 0 or ` = u = 1. For the sake of simplicity, in the
following we assume without loss of generality that strict beliefs are always represented with
0,0
1,1
` = u = 1. Any strict belief Bi,t
() can easily be rewritten as Bi,t
().5 We call a belief
trivial if ` = 0 and u = 1. Obviously, these beliefs are trivially satisfied by any arbitrary
interpretation, thus they do not impact satisfiability checking results at all and therefore
can be removed from B.
Remark 4.2. From the definition of the belief semantics (Definition 3.11, p. 57) it follows for
1,1
the special case of strict beliefs Bi,t
() that (i) agent i considers the occurrence of the belief
objects complement  as impossible and (ii) that this occurrence is indeed impossible.
Thus, strict beliefs comply with the common definitions of knowledge as justified true belief
and belief that is stable with respect to the truth (cf. e.g., Shoham & Leyton-Brown, 2009,
page 433). Consequently, we could also refer to a strict belief as knowledge and equivalently
use the established knowledge operator Ki () instead of Bi1,1 ().
1,1
Remark 4.3. Note that the concept of strict beliefs only applies to positive beliefs Bi,t
().
1,1
For the negation of such a belief, Bi,t (), it follows from Definition 3.16 (p. 63) that there
fr
fr
5. If the belief object  is a temporal rule rt
(F, G), we represent  as rt
(F, G). This is possible
because we do not need to consider frequency functions that correspond to axioms FF1 and FF2 from
Definition 3.10 (p. 55) and only use point frequency functions pfr. If other frequency functions are used,
their negations need to be defined accordingly.

86

fiPDT Logic

is at least one thread that does not satisfy the belief object , which in turn implies ` < 1.
1,1
Consequently, these beliefs Bi,t
() are considered as non-strict in the following discussion.

Using these features, we can create a taxonomy of beliefs as depicted in Figure 3 to
identify prior constraints on the set of possible threads. This taxonomy is obtained by
successively distinguishing between strict and non-strict, prior and posterior beliefs, between
beliefs in facts, rules and nested beliefs, and finally between beliefs in static and dynamic
rules. Nested beliefs are only considered as strict (prior) beliefs, if all involved beliefs are
strict (prior), otherwise they are considered as non-strict (posterior). If a nested belief is
actually strict and prior, we can unnest this belief and consider only the innermost belief
expression: since prior beliefs are commonly known and therefore identical for all agents
i  AB , it is evident that for any strict belief of any agent i, all other agents know that agent
i has this strict belief. Consequently, strict prior beliefs can be nested to an arbitrary depth
without introducing any further constraints: they are satisfied exactly if the innermost
belief is satisfied. Thus, we do not need to consider nested strict prior beliefs explicitly.
This taxonomy gives rise to three different types of belief formulae with respect to their
impact on the sets of admissible worlds:
Definition 4.3 (Belief formula typification). A set of belief formulae B can be categorized
into three different types of beliefs:
 Type 0: These are beliefs that restrict the set of admissible worlds B (t) at every
time point t   . Thus, type 0 beliefs have the highest impact because they can be
exploited to prune the set of admissible worlds B globally. An evaluation of these
beliefs relies neither on a specific probability assignment nor on any given Kripke
structures Ki .
 Type 1: These are beliefs that restrict sequences of possible worlds. Moreover, they
can potentially restrict the sets of admissible worlds B (t) at specific time points.
Thus, type 1 beliefs have less impact than type 0 beliefs because they can only be
exploited to prune the sets of admissible worlds B (t) locally. Again, an evaluation
of these beliefs relies neither on a specific probability assignment nor on any given
Kripke structures Ki .
 Type 2: This type encompasses all remaining beliefs in B that are neither type 0 nor
type 1 beliefs. These beliefs are situation-specific and cannot be used to prune the
sets of admissible worlds a priori. Satisfiability of these beliefs depends on a suitable
probability assignment or on the evaluation of Kripke structures in the respective
threads.
We use Tk (B) to denote the set of type k beliefs from B.
The main goal of this belief formula taxonomy is to identify constraints on possible
worlds  and possible threads T h that can be evaluated prior to searching for a suitable
probability assignment, namely by using the belief formulae in T0 (B) and T1 (B) to prune
the search space of possible sets of threads T that may show satisfiability of B. It should
be noted that the existence of a thread T h  T violating a belief from T0 (B) or T1 (B)
technically does not preclude satisfiability of B with respect to T , as there is a special
87

fiMartiny & Moller

all beliefs

non-strict beliefs
`<1

strict beliefs
`=1

If all ` = 1, only
the innermost beprior beliefs
lief is of interest

posterior beliefs
t0 > 0

0

t =0
belief in 0 beliefs
1,1
` ,u0
Bi,0
(Bj,t
())

belief in beliefs
`,u
1,1
B1,1
0 (Bj,t ())
TF
1 (B)

belief in rules
1,1 fr
Bi,0
(rt (F, G))

belief in facts
1,1
Bi,0
(Ft )

disjunctive belief
formulae
1,1
1,1
Bi,0
(1 )  Bi,0
(2 )    

belief in dynamic rules
t > 0

belief in facts
1,1
Bi,t
0 (Ft )
belief in rules
1,1 fr
Bi,t
0 (rt (F, G))

disjunctive belief
formulae
1,1
1,1
Bi,0
(1 )  Bi,0
(2 )    

belief in dynamic rules
t > 0

T1 (B)

belief in static rules
t = 0
T0 (B)

Type 0: These beliefs
have the highest impact,
because they restrict every
world at every time point.

belief in static rules
t = 0

Type 1: These beliefs restrict threads independently of any probabiliy assignment.
Moreover, they can potentially restrict possible worlds at individual time points.

Figure 3: Taxonomy of belief formulae

88

T2 (B)

Type 2: All remaining beliefs; they can be
treated the same way.

fiPDT Logic

case of a suitable probability assignment: If there is a thread T h  T such that some
belief B  T0 (B) or B  T1 (B) is not satisfied, there could still be suitable probability
assignments I(T ) such that sat(B, T ) holds iff I(T h) = 0. The effect of excluding such a
thread T h from T or assigning a prior probability I(T h) of zero is the same (cf. Remark 3.3,
p. 53), i.e., the respective thread is marked as impossible. Since we aim at reducing both
the search space of possible threads and the input to the satisfiability check sat(B, T ), we
exploit belief formulae in T0 (B) and T1 (B) to exclude impossible threads prior to searching
for suitable probability assignments.
Type 0 belief formulae As depicted in Figure 3, the set of type 0 belief formulae is
1,1 pfr
formed by formulae with strict prior beliefs in static rules Bi,0
(r0 (F, G)) from B. Since
prior beliefs represent the background knowledge and since it follows from the definition of
strict beliefs that they cannot be violated in any world, it is clear that the rule r0pfr (F, G)
has to be always satisfied. As this is a static rule, it has to be satisfied in every world
  B . We define the set of type 0 beliefs as
1,1 pfr
T0 (B) = {B  B : B = Bi,0
(r0 (F, G))}

(47)

with arbitrary formulae F and G.
Type 1 belief formulae The set of type 1 beliefs contains all strict prior beliefs that
are not in the set T0 (B). The contributions of this set T1 (B) are twofold: As T1 (B) only
comprises strict prior beliefs, every thread in a potential set of threads T has to satisfy all
beliefs B  T1 (B). Moreover, constraints from T1 (B) may constrain the sets of worlds
B (t) at individual time points t   regardless of any specific thread. According to
Figure 3, we define the set of type 1 beliefs as

1,1
T1 (B) = B  B :
B = Bi,0
(Ft )
1,1 pfr
 B = (Bi,0
(rt (F, G))  t > 0)

1,1
1,1
 B = (Bi,0
(1 )  Bi,0
(2 )     )

	

(48)

For a potential set of possible threads T , the beliefs specified in this set T1 (B) have to
be satisfied by every thread T h  T . Note that satisfiability of beliefs in dynamic rules and
disjunctive belief formulae generally depends on worlds  at multiple time points and thus
satisfiability of T1 (B) cannot be ensured by only constraining sets of worlds at single time
points. However, by analyzing strict prior beliefs in facts and their potential interplay with
dynamic rules we can derive constraints for the sets of worlds B (t) at specific time points
t   as follows.
1,1
Strict prior beliefs in facts B = Bi,0
(Ft ) restrict the set of admissible worlds B (t) at
time t by enforcing that F holds at every world   B (t). In the following, we use TF1 (B)
to denote such strict prior beliefs in facts F at certain time points t. Moreover, we use
1,1
B |= Ft as a shorthand for Bi,0
(Ft )  B to denote that B enforces F at time t.
Through interplay with existing constraints on sets possible worlds B (t) at individual
time points t, strict beliefs in dynamic rules can yield additional constraints: For a belief
1,1 pfr
formula B = Bi,0
(rt (F, G)), t > 0, additional constraints might be derived, depending
on the type of belief in the respective rules premise F : if (T0 (B)  TF1 (B)) |= Ft is given,
89

fiMartiny & Moller

1,1
we can extract a strict prior belief in a fact B 0 = Bi,0
(Gt+t ), which then again restricts
the set of possible worlds at time point t + t and is therefore added to TF1 (B).
Since dynamic rules can be considered as temporal implications (cf. Definition 3.10 from
Section 3), these rules can also be applied backwards to obtain additional constraints: If a
1,1 pfr
belief formula B = Bi,0
(rt (F, G)), t > 0 is given and the rules negated conclusion G
is already enforced at some time point t (i.e., (T0 (B)  TF1 (B)) |= Gt ), the rules premise
1,1
F cannot be satisfied at time t  t. Thus, we can add the belief B 0 = Bi,0
(Ftt ) as an
F
additional constraint to T1 (B).
Extending the set of type 1 beliefs through dynamic rules may lead to a chained ex1,1 pfr
tension: if we have a belief in a dynamic rule Bi,0
(rt (F, G)) and a corresponding belief
1,1
1,1
F
Bi,0 (Ft )  T1 (B), this will lead to the additional belief Bi,0
(Gt+t )  TF1 (B), which
1,1 pfr
in turn might trigger another dynamic rule Bi,0
(rt (G, G0 )). Analogously, any additional
belief in TF1 (B) could also trigger further backward rule applications.
To capture all constraints that emerge from forward and backward chaining of strict
dynamic rules, we define the set TF1 (B) as the following fix-point set:6

TF1 (B) =

1,1
{Bi,0
(Ft )  B}
1,1
 {Bi,0
(Gt+t ) :

1,1 pfr
t > 0  Bi,0
(rt (F, G))  B

 (T0 (B)  T1 (B)) |= Ft }

1,1
 {Bi,0
(Ftt ) :

1,1 pfr
t > 0  Bi,0
(rt (F, G))  B

 (T0 (B)  T1 (B)) |= Gt }

(49)

After having determined all constraints on individual time points, we can reduce this
1,1
set TF1 (B) such that it contains at most one belief Bi,0
(Ft ) for every time point t. If
1,1
1,1
F
T1 (B) contains multiple beliefs Bi,0 (Ft ), Bi,0 (Gt ) regarding the same time point t, we
1,1
can replace them by a joint belief Bi,0
(Ft0 ) with F 0 = F  G. Note that this substitution
uses Lemma 3.7 (p. 64) to merge different belief expressions into one expression with a
conjunctive belief object. We still assume that belief formulae with conjunctions of belief
operators are separated into atomic belief formulae.
Type 2 belief formulae The set of type 2 belief formulae consists of all beliefs in B that
are neither type 0 nor type 1 beliefs. Thus we define this set as
T2 (B) = (B \ T0 (B)) \ T1 (B)

(50)

6. For this representation, we have only considered the influence of temporal rules for the set TF
1 (B). In
1,1
1,1
principle, information from disjunctive formulae B = Bi,0
(1 )      Bi,0
(n ) in T1 (B) could yield
additional constraints on the sets B (t): If TF
1 (B) enforces n1 disjuncts in B to be false, the remaining
disjunct must be satisfied. As the belief objects of the respective disjuncts might be dynamic rules again,
a formal representation of this consideration would result in a rather intricate specification. Since we have
to ensure that any potential thread satisfies all beliefs in T1 (B) anyways, omitting disjunctive formulae
in the construction of TF
1 (B) does not impact satisfiability results. Yet an actual implementation of the
described procedures could exploit this consideration to obtain additional pruning conditions in special
cases.

90

fiPDT Logic

Example 4.5 (Trains continued). Continuing with the set of belief formulae B from Example 4.1 (p. 72) and assuming that conjunctive formulae B = B 0  B 00 are treated as
individual formulae B 0 and B 00 , we obtain the following sets of typed belief formulae:
 1,1 pfr
	
T0 (B) = BA,0
r0 (punct(train)  at(train, city), Obs{A} (punct(train)))
(B5 )
 1,1

T1 (B) = BA,0
at(T1 , CA )1 ,

1,1
BA,0
on(A, T1 )1 ,

(B10 )
(B100 )


1,1
BA,0
r3pfr ( punct(T1 )  at(T1 , CA ), at(T2 , CC )  on(A, T2 )) ,

1,1 pfr
BA,0
(r5 (punct(T1 )  at(T1 , CA ), at(T2 , CC )  on(A, T2 )) ,

1,1
BA,0
r2pfr ( punct(T2 )  at(T2 , CC ), at(T2 , CB )  on(A, T2 ))
	
1,1
BA,0
r3pfr (punct(T2 )  at(T2 , CC ), at(T2 , CB )  on(A, T2 )) ,
 1,1

TF1 (B) = BA,0
at(T1 , CA )1 ,
	
1,1
BA,0
on(A, T1 )1 ,

(B30 )
(B300 )
(B40 )
(B400 )
(B10 )
(B100 )

T2 (B) = B \ T0 (B) \ T1 (B)

.81,.81 pfr
= {BA,0
r0 (at(T1 , CA ), punct(T1 )) ,

.81,.81 pfr
BA,0
r0 (at(T2 , CC ), punct(T2 )) ,

.93,.93 pfr
BA,0
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) }

(B20 )
(B200 )
(B6 )

The taxonomy of belief formulae provides means to construct sets of admissible worlds
B (t) for every time point t   . Type 0 beliefs (i.e., beliefs with the highest impact)
constrain the global set of possible worlds B . Certain beliefs of type 1materialized in
the set TF1 (B)can then give additional constraints for specific time points t, such that
only subsets B (t)  B need to be considered as possible worlds for time t. The sets
T0 (B) and T1 (B) together provide satisfiability conditions that are independent of any
specific probability assignments. Then, only beliefs of type 2 need to be considered as
probabilistic constraints to check whether B can be satisfied with respect to T , i.e., the
satisfiability problem sat(B, T ) from the previous section can be reduced to sat(T2 (B), T ),
if unsatisfiability of B has not yet been shown through constraints in T0 (B) and T1 (B).
Since the prior constraints define necessary conditions for any potential thread, they give
rise to a definition of thread soundness with respect to a given set of belief formulae B:
Definition 4.4 (Thread soundness). Let B be a set of belief formulae, and let T0 (B) and
T1 (B) be the set of type 0 and type 1 belief formulae in this set, respectively. Then, a
thread T h is sound with respect to B (denoted snd(T h, B)) if it satisfies all belief formulae
from T0 (B) and T1 (B):
snd(T h, B)  B  (T0 (B)  T1 (B)) : T h |= B
91

(51)

fiMartiny & Moller

Accordingly, we use snd(T , B) to denote that all threads T h  T are sound.
Note that this definition only relies on strict prior beliefs and the soundness property can
therefore be verified for every thread individually, without having to consider other threads
or probability assignments. Thus, a simplified version of the model checking procedure from
Section 4.1 can be used to verify soundness. The intuition behind this property is that we
can verify it easily prior to checking sat(B, T ) and can therefore obtain a reduced version
of the satisfiability problem:
Theorem 4.13 (Reduced satisfiability checking). Let B be a set of belief formulae, let
T2 (B) be the set of type 2 beliefs in B according to (50), and let T be a set of sound
threads. Then, B is satisfiable with respect to T iff T2 (B) is satisfiable with respect to T :
sat(B, T )  snd(T , B)  sat(T2 (B), T )

(52)

Proof. This follows directly from Definition 4.4: snd(T , B) is defined so that it satisfies all
belief formulae in the sets T0 (B) and T1 (B). Consequently, these sets resemble tautologies
with respect to T and therefore do not have any impact on the satisfiability checking
properties. Thus, instead of checking B for satisfiability, it suffices to check the set (B \
T0 (B)) \ T1 (B), which is exactly the definition of T2 (B).
4.4.2 Constraining Possible Worlds at Individual Time Points
Using the classification of beliefs in B into the three different types, we can now continue
with constructing sets of possible worlds B (t) for every time point t   . The main goal of
this section is an identification of obvious pruning conditions for possible worlds at specific
time points. Since we are in the process of searching for a set of possible threads that
satisfies a set of belief formulae B, any constraints on the sets B (t) have the potential to
significantly reduce the later used search space. Thus, the results of this section highlight
possible optimizations for an implementation of a PDT Logic sat solver. Even if the following constraints are notor only partiallyapplied, the search for possible threads as
described in subsequent Section 4.5 can be carried out, yet with a potentially larger search
space.
Since the set of type 0 beliefs has to be satisfied in every admissible world, we can define
the global set of admissible worlds B as follows:
Definition 4.5 (Global set of admissible worlds). Let B be a set of belief formulae, with
the corresponding sets of belief objects FB and type 0 beliefs T0 (B). Then, the set of
admissible worlds B w.r.t. B is given as
n

o
1,1 pfr
B =   B FB : adm()  Bi,0
(r0 (F, G))  T0 (B) :  |= (F  G) .
(53)
Remark 4.4. This definition uses adm() to ensure that all worlds   B are admissible
as defined in the external Definition 3.5 (p. 48). Alternatively, we could use the existing
formalism to encode these admissibility conditions directly as strict prior beliefs in B:
1,1 pfr
1,1 pfr
Bi,0
(r0 (ObsG (l), l)) and G 0  G : Bi,0
(r0 (ObsG (l), ObsG 0 (l))) represent conditions 1
and 2 of Definition 3.5, respectively. However, since these conditions are independent of the
respective problem being modeled, we do not include them in the problem-specific belief
set B, but use them as external constraints.
92

fiPDT Logic

Example 4.6 (Trains continued). The global set of worlds B admissible with respect to
B from Example 4.1 (p. 72) can be automatically constructed from all combinations of
events from FB shown in Example 4.2 (p. 73), given that these combinations are admissible
with respect to Definition 3.5 and satisfy the type 0 beliefs in T0 (B) from Example 4.4
(p. 81). We refrain from enumerating all of these worlds explicitly and instead describe
which worlds are excluded from the Herbrand base B FB of FB : From FB it follows that the
only possible shared observation between A and B is the fact that a train is not punctual
(Obs{AB} (punct(train))). In every possible world where this observation occurs, admissibility conditions require that both agents A and B observe that the respective train is
not punctual and that the train is indeed not punctual. Furthermore, the beliefs in T0 (B)
require that there is a corresponding observation for A at every possible world where a
train is not punctual (which incidentally also enforces admissibility conditions for these
observations).
Next, we can build upon the set of globally admissible worlds B and use the set of
type 1 beliefs to further prune the set of admissible worlds B (t) at individual time points
t:
Definition 4.6 (Local sets of admissible worlds). Let B be a set of belief formulae with
the corresponding sets of admissible worlds B , TF1 (B) be the set of materialized strict
prior beliefs induced by T0 (B) and T1 (B), and  be a set of time points. Then, the set of
admissible worlds B (t) w.r.t. B at time t   is given as
n

o
1,1
F
B (t) =   B : Bi,0 (Ft )  T1 (B) :  |= F
.
(54)
Example 4.7 (Trains continued). To obtain the scenario from the original Example 3.2,
we assume tmax = 9. From the set TF1 (B) identified in Example 4.5, we can restrict the set
of worlds at time 1 to
n
o
B (1) =   B :  |= (at(T1 , CA )  on(A, T1 ))
For all other time points, there are no options for further restrictions, thus the respective
local sets B (t) of possible worlds for all time points t 6= 1 remain at B .
Using Definition 4.6, we can now formulate constraints for the set of sound threads T :
T h  T , t   : T h(t)  B (t).

(55)

Note that this constraint provides a necessary but not sufficient condition for thread
soundness. To illustrate this, consider Example 4.5 again: the set TF1 (B) requires that
{at(T1 , CA ), on(A, T1 )} holds at every possible world at time t = 1 and thus we can constrain B (1) as shown in Example 4.7, because any thread violating this constraint is
inherently unsound. On the other hand, a thread according to (55) may contain the
fact, say punct(T1 )  T h(1), whichaccording to B30 only yields a sound thread if
{at(T2 , CC ), on(A, T2 )}  T h(4) holds as well. Thus, (55) provides general constraints on
the set of threads with respect to beliefs from T0 (B) and TF1 (B), while additional beliefs
from T1 (B) can discard individual threads by catching any potential unsatisfiable interplay
of possible worlds at different time points.
93

fiMartiny & Moller

Of course, in general it is possible that the methods discussed so far result in special
cases: for one thing, it is possible that B induces a set T0 (B)  TF1 (B) of inconsistent
beliefs, i.e., it will contain beliefs that contradict each other. Then, B or B (t) for some
t will be empty. This precludes the creation of any set of threads T such that I(T ) |= B.
In this case, satisfiability checking can terminate immediately with a negative result. For
another, it is possible that the above simplification process will result in an empty set
T2 (B). In this case, there are no probabilistic constraints that could impact satisfiability of
B and thus it is unnecessary to search for a suitable probability assignment. In this case, it
needs to be checked whether any of the threads in compliance with (55) is sound according
to Definition 4.4. If such a thread can be found, satisfiability checking can terminate
immediately with a positive result, otherwise B is unsatisfiable. Verifying soundness of a
single thread can be done with a simplified version of the model checking procedure from
Section 4.1 and is therefore in PTIME (cf. Corollary 4.3). However, as the number threads
satisfying condition (55) can grow exponentially with the number of ground atoms and the
number of time points, the problem of finding a sound thread is more complex:
Theorem 4.14 (Complexity of finding a sound thread). Let B be a set of belief formulae
such that all included formulae are grounded. Deciding whether there exists a sound thread
with respect to B, as defined in Definition 4.4, is NP-complete.
Proof. According to Definition 4.4, a set is sound if it satisfies all formulae from the set
T0 (B)  T1 (B). By treating the belief objects atoms F at all time points t as individual
variables Ft , we can transform beliefs in facts and belief in rules from T0 (B)  T1 (B) into
a boolean sat problem as follows:7
1,1
Bi,0
(Ft )

 Ft

1,1 pfr
Bi,0
(rt (F, G)) 

tmax
^t
t=0

(Ft  Gt+t )

Accordingly, disjunctive belief formulae can then be expressed through transforming every
disjunct individually. This transformation requires at most tmax conjuncts for every belief
operator and can therefore be performed in linear time. Since the boolean sat problem is
known to be NP-complete (Cook, 1971), it follows that searching for a sound thread with
respect to B is in NP.
NP-hardness of this problem has already been shown in the proof of Theorem 4.11
(p. 84) and consequently it follows that searching for a sound thread with respect to B is
NP-complete.
It should be noted that this result analyzes the worst-case complexity of the problem,
but in practice finding a sound thread is usually not dominated by this worst case. In most
cases, a sound thread can be found easily by employing the principle of least effort: For
1,1 pfr
belief in temporal rules Bi,0
(rt (F, G)), choosing worlds  such that  |= F ensures that
consequences of this rule do not have to be evaluated at other time points. Accordingly, for
7. This transformation is only defined for temporal rules with point frequency functions pfr. If other
frequency functions are used, the transformation has to be adapted accordingly.

94

fiPDT Logic

disjunctive rules a disjunct should be selected such that no temporal rule is triggered by this
fact. Of course, this is only a heuristic that may not give a sound thread immediately for
every input B, but it represents a feasible approach for most problems. We will illustrate
this approach with an example subsequently.
In this work, we only consider ground formulae for PDT Logic. In general, the formalism
as introduced in Section 3 allows the treatment of non-ground formulae as well. However,
for non-ground formulae the complexity result from Theorem 4.14 does not hold, because
transformation into a boolean sat problem is then exponential in the number of possible
groundings. Finding a sound thread then requires the use of sophisticated grounding procedures, (e.g., Dal Palu, Dovier, Pontelli, & Rossi, 2009 and Faber, Leone, & Perri, 2012),
which is beyond the scope of this work.
Now that sets of possible worlds are identified for every time point t   , we can proceed
with creating sets of representative threads with respect to these constraints. The aim of
the following discussion is the successive generation of a set of representative threads T
such that sat(B, T ) can be decided.
4.5 Representative Threads
Using Definition 4.4 and constraint (55) gives rise to a potential definition of the set of
possible threads T by constructing all possible combinations of sound world sequences from
B (t) for all t   . However, this would still result in an unnecessarily large set of possible
threads. Instead of constructing all of these threads explicitly, we will heuristically create
representative threads that represent excerpts from the situations modeled by T2 (B). This
approach uses heuristics to successively expand the set of representative threads. As soon as
a suitable set of threads (i.e., a model for B) is found, the decision procedure can terminate
with a positive result. If a set of representative threads does not show satisfiability of
B, additional threads are created until either a positive satisfiability result is obtained
or all possible threads have been created. Consequently, the heuristic search for models
constitutes a complete decision procedure for PDT Logic.
For the following discussion, we assume that the set T2 (B) is nonempty, i.e., there are
additional constraints that need to be satisfied by the generated set of threads. Otherwise,
if the set T2 (B) was empty, satisfiability could already be determined by checking whether
a sound thread with respect to B exists, as discussed in the previous section and there
would be no need to generate any specific set of threads.
`,u
`0 ,u0
For all beliefs in facts Bi,t
0 (Ft ) from B, the dual belief in the negated fact Bi,t0 (Ft )
with `0 = 1  u and u0 = 1  ` (cf. Corollary 3.4, p. 59) has to be satisfied as well. For
`,u fr
beliefs in rules Bi,t
0 (rt (F, G)), satisfiability depends on the accumulated subjective posterior interpretations of all threads weighted with their respective frequencies. The goal of
`,u
the following procedure is to successively create threads for every belief in a fact Bi,t
0 (Ft )
in T2 (B), such that we obtain representatives for the set of threads that (i) satisfy the
respective fact Ft and for the set of threads that satisfy Ft , and (ii) exhibit varying fre`,u fr
quencies for all beliefs in temporal rules Bi,t
0 (rt (F, G))  T2 (B). Consequently, belief
formulae can be considered as splitting rules and their application to generate representative threads results in a procedure similar to tableau-based methods. However, beliefs in
temporal rules can induce splits both forward and backward in time and thusunlike con95

fiMartiny & Moller

ventional tableau-based methodsthe following procedure does not create a tree structure,
but instead a set of sequences that represent possible threads. A key difference between
the generation of representative threads and other logical sat solvers is that in PDT Logic
it is virtually impossible to discard any generated potential thread: the probabilistic nature of the semantics requires that not only threads are considered where a given formula
holds, but also threads where it does not. Thus, even threads violating the objects of given
belief formulae are usually required to show satisfiability of a corresponding set of belief
formulae B. The following discussion provides a general outline for a decision procedure
in PDT Logic if only a set of belief formulae B is given. An actual implementation of
these methods is possible, but to obtain feasible run times for practical problems, various
optimization techniques from research on logic reasoning implementations would need to be
implemented, which is beyond the scope of this work.
4.5.1 Generating Representative Threads
`,u
Since the existence of any non-strict belief in a fact Bi,t
0 (Ft ) requires the existence of at
least two threadsone, where the respective belief object is satisfied and one, where it is
not8 we start with creating two threads from hB (1), ..., B (tmax )i such that we obtain a
set T = hT h1 , T h2 i with T h1 |=  and T h2 |=  for all belief objects  = Ft contained
in the set T2 (B) to obtain a minimal set of set threads T such that all belief formulae
B  T2 (B) can potentially be satisfied. This set will then subsequently be expanded with
additional threads until either a suitable set of threads to show satisfiability of T2 (B) is
found, or until no more additional threads can be created.
To allow for a concise notation, in the following we adapt the frequency notation for all
belief objects and use (1  ) to denote that  is true, (0  ) to denote that  is false, and
generally (x  ) to denote that  holds with frequency x. Of course, values 0 < x < 1 can
only occur for belief objects that represent temporal rules. With this notation, we try to
create initial sound threads such that
^
T h1 |= (1  j ), and
(56)
j

T h2 |=

^
j

(0  j )

(57)

holds for the respective belief objects j of all belief formulae Bj  T2 (B).9
This initial set T = {T h1 , T h2 } is meant to represent the two extreme choices for possible
threads with respect to T2 (B) to provide a suitable starting point for the subsequently
employed search heuristic. In general, it is not necessarily possible to create such extreme
threads in compliance with (56) and (57) for every possible set of belief formulae T2 (B). For
`,u
`,u
instance, T2 (B) might contain conflicting beliefs in facts Bi,t
0 (Ft ) and Bi,t0 (Ft ). Obviously,
no single thread can satisfy both belief objects simultaneously, but it might still be possible
`,u
8. Technically, a non-strict belief Bi,t
0 () could be satisfied with a single thread T h such that T h |=  if
the beliefs quantification has an upper bound u = 1. This might give rise to further optimizations for
an actual implementation, but for the sake of simplicity, we do not consider this case explicitly.
`,u
`,u
0
00
9. This notation is slightly simplified: for disjunctive belief formulae Bj = Bi,t
0 (j )  Bi,t0 (j ), we use j
0
00
as an abbreviation for j  j .

96

fiPDT Logic

to create a set of threads such thattogether with a suitable probability assignmentboth
beliefs can be satisfied. Thus, (56) and (57) characterize the intended goal when creating
the initial threads T h1 , T h2 , but do not represent hard constraints on these threads.
To find suitable threads that match these constraints, we employ the principle of least
`,u
effort by adding as few facts as possible to each thread: For every belief in a fact Bi,t
0 (Ft ),
we add the explicit constraints F  T h1 (t) and F 6 T h2 (t), such that T h1 represents the
thread where all belief objects are true and T h2 represents the set where all belief objects are
`,u fr
false. For beliefs in rules Bi,t
0 (rt (F, G)) we add G  T h1 (t + t) (resp. F  T h1 (t  t))
whenever another constraint enforces F  T h1 (t) (resp. G  T h2 (t)). If no occurrence of
fr (F, G) is trivially satisfied with frequency
F respectively G is enforced in T h1 , a rule rt
1 (i.e., there are no occurrences where F is not followed by G in t steps) and no further
constraints need to be added. Analogously, for T h2 we need to ensure that F holds at
least once and that whenever F  T h2 (t) holds, G  T h2 (t + t) holds, as well. For
`,u
`,u
disjunctive belief formulae Bi,t
0 (1 )  Bi,t0 (2 ), we need to ensure that belief object 1 or
2 holds in thread T h1 , as described above, and that 1  2 holds in thread T h2 . If
possible, the respective belief object 1 or 2 for thread T h1 should be chosen such that no
additional beliefs are triggered (we say that a belief is triggered by a fact F , if the existence
of F enforces another constraint through a belief in a temporal rule or a disjunctive belief
formula). Nested belief formulae are treated as above with respect to their innermost belief
object. If some constraint cannot be applied because it is in conflict with previously added
constraints from T2 (B), it is simply skipped in this stage. As the creation of T h1 and T h2 is
only the initialization step for a heuristic search of possible set threads, skipped constraints
will still be considered later in subsequent expansions.
Whenever a constraint regarding a fact F is added to T h1 or T h2 , it is necessary to
check whether this triggers additional rules from set of type 1 beliefs T1 (B). If necessary,
resulting facts are added to the respective threads. This application works analogously
to the construction of the set TF1 (B) as described in Section 4.4.1. Finally, if all belief
formulae have been processed, we search for a sound thread with respect to the created
constraints. Usually, a sound thread can be found easily by choosing all facts that are
yet unconstrained in T h1 and T h2 such that they do not trigger any additional beliefs.
Especially, for possible worlds T h(t) that are unconstrained, we can choose T h(t) =  if B
does not contain any belief in rules with purely negative preconditions or disjunctive belief
formulae that are not satisfiable by . More generally, the principle of least effort should
be employed such that worlds  are selected so that no further belief formulae need to be
considered. Such a selection is impossible if and only if the addition of both F and F to
some world triggers additional beliefs. Then, the consequences of adding the respective fact
need to be evaluated, as well. The resulting set T = {T h1 , T h2 } then provides a minimal
set of representative threads that that can be used to check sat(T2 (B), T ).
In the following, we show how the principle of least effort can be used to obtain representative threads as efficiently as possible. The constraints used in the following example
provide the minimal number of constraints that need to be enforced to obtain representative threads for the desired threads T h1 and T h2 . For all worlds  without any specific
constraints, we simply use  = . One can easily verify that this indeed yields threads in
compliance with (56) and (57).

97

fiMartiny & Moller

Example 4.8 (Trains continued). We continue the train example with the sets of typed
belief formulae specified in Example 4.5 (p.91). In Example 4.7 (p. 93), it was shown that
the set of worlds at time 1 B (1) is restricted such that {at(T1 , CA ), on(A, T1 )}   for
every world   B (1). The set T2 (B) contains three non-strict belief formulae, namely

.81,.81 pfr
T2 (B) = {BA,0
r0 (at(T1 , CA ), punct(T1 )) ,
(B20 )

.81,.81 pfr
BA,0
r0 (at(T2 , CC ), punct(T2 )) ,
(B200 )

.93,.93 pfr
BA,0
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train))) }
(B6 )
By evaluating these belief formulae, we obtain constraints on the possible worlds in
threads T h1 and T h2 . A visualization of the following steps is given in Figure 4.
Analysis of belief formula B20 results in the constraints punct(T1 )  T h1 (1) and
punct(T1 ) 6 T h2 (1). These facts in turn trigger rules B30 and B300 , respectively:

1,1
BA,0
r3pfr ( punct(T1 )  at(T1 , CA ), at(T2 , CC )  on(A, T2 )) and

1,1 pfr
BA,0
(r5 (punct(T1 )  at(T1 , CA ), at(T2 , CC )  on(A, T2 )) ,

(B30 )
(B300 )

resulting in the additional constraints {at(T2 , CC ), on(A, T2 )}  T h1 (4) and {at(T2 , CC ),
on(A, T2 )}  T h2 (6).
Application of belief formula B200 then yields the additional facts punct(T2 )  T h1 (4)
and punct(T2 ) 6 T h2 (6). Again, this triggers rules from T1 (B):

1,1
(B40 )
r2pfr ( punct(T2 )  at(T2 , CC ), at(T2 , CB )  on(A, T2 )) and
BA,0

1,1 pfr
(B400 )
(r3 (punct(T2 )  at(T2 , CC ), at(T2 , CB )  on(A, T2 )) ,
BA,0
resulting in the additional constraints T h1 (6) = at(T2 , CB ), on(A, T2 ) and T h2 (9) =
at(T2 , CB ), on(A, T2 ).
Note that belief formula

1,1
BA,0
r0pfr (punct(train)  at(train, city), Obs{A} (punct(train)))
(B5 )
from T0 (B) provides a global constraint on the set of possible worlds B such that
Obs{A} (punct(train)) holds in every world where punct(train) holds, and thus we obtain
for thread T h2 the additional facts Obs{A} (punct(T1 ))  T h2 (1) and Obs{A} (punct(T1 )) 
T h2 (6).
Finally, rule

.93,.93 pfr
BA,0
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train)))
(B6 )

98

fiPDT Logic

00
T h2 B2
B5
0
T h1 B2

at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )

B300

B200
B5

B30

B200

at(T2 , CC ), on(A, T2 )
punct(T2 )



1

B40


4

at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CB ), on(A, T2 )

6

B400



at(T2 , CB ), on(A, T2 )

9

t

1

Figure 4: Visualization of the representative thread set generation for the train example.
Both threads start with the given facts at(T1 , CA ), on(A, T1 ). Applications of
formulae from T2 (B)such that T h1 contains positive belief objects and T h2
contains negative belief objectsare marked in blue, additional constraints from
T0 (B) and T1 (B) are marked in red.

does not change the created threads T h1 , T h2 : in T h1 the rules precondition is never
enforced to be satisfied and thus the resulting frequency is one, while the lack of any
observation in T h2 even though there are nonpunctual trainsensures that the resulting
frequency is zero.
When trying to solve the resulting problem sat(T2 (B), {T h1 , T h2 }), the non-strict belief
formulae yield the following constraints on T h1 :
B20 :
B200

:

B6 :

0.81  I(T h1 )  0.81

0.81  I(T h1 )  0.81

0.93  I(T h1 )  0.93

Clearly, these constraints cannot be satisfied simultaneously and therefore the set T =
{T h1 , T h2 } is insufficient to show satisfiability of T2 (B) (and therefore B).
If the created set of threads fails to show satisfiability of T2 (B), additional threads can
be created to continue searching for an expanded set T such that T2 (B) can be satisfied
with respect to T . Based on an existing thread T h, an additional thread T h0 can be created
by ensuring that one conjunct for T h1 or T h2 in (56) and (57) is not satisfied anymore,
i.e., from a given thread T h with existing constraints (xk  k ), a new thread T h0 can be
obtained through the substitution
^
^
T h |= (xj  j )  T h0 |=
(xj  j )  x0k  k , x0k 6= xk .
(58)
j

j6=k

Every such substitution of one conjunct with a new constraint provides a choice point to
direct the continuation of the search for a suitable set of threads. The constraint notation
in 58 is used to provide a formal characterization of choice points. In practice, a new thread
T h0 satisfying the above constraint can usually be created easily through the addition of new
or the modification of existing facts in T h as follows. To simplify the following discussion,
we assume that the expansion keeps a history of expansion steps and resulting consequences,
such that all effects of adding an additional F can be undone if the respective fact F is
changed for a newly created thread.
99

fiMartiny & Moller

Definition 4.7 (Principle of least effort (ple) expansion). Let T be a set of threads and let
T2 (B) be a set of type 2 belief formulae. A principle of least effort expansion creates an
expanded set T 0 = T  {T h0 } according to a single application of one of the following rules.
`,u
 For a (possibly negated) belief in an a fact Bi,t
0 (Ft )  T2 (B): If there exists a thread

T h  T such that F  T h(t) (resp. F 6 T h(t)) is not yet enforced, T h0 is created as
a duplication of T h with the additional constraint F  T h(t) (resp. F 
6 T h(t)).

`,u fr
 For a belief in a temporal rule Bi,t
0 (rt (F, G))  T2 (B): If there exists a thread

T h  T such that F  T h(t) but G  T h(t + t) (resp. G 
6 T h(t + t)) is not
0
yet enforced, T h is created as a duplication of T h with the additional constraint
G  T h(t + t) (resp. G 6 T h(t + t)).

`,u
`,u
 For a disjunctive belief formula B = (Bi,t
0 (1 )  Bi,t0 (2 )     )  T2 (B): If possible,
`,u
expansion is carried out with respect to one belief Bi,t
0 () as described in the two
previous steps.

 Nested beliefs are again treated with respect to their innermost belief object.
 If the new thread T h0 is created from T h through the addition of F  T h0 for some
fact F and time point t and F 6 T h was enforced in the original thread T h, the
consequences of adding F 6 T h are undone in the new thread T h0 .

Then, for the created thread T h0 , additional belief formulae from T1 (B) that are
triggered by this modification need to be evaluated to obtain a sound thread, as
described above for the creation of initial threads T h1 , T h2 .

The intuition behind this ple-expansion is to create additional threads that satisfy an
alternative set of belief objects  contained in the set T2 (B) with as little effort as possible.
In general, it is possible to add constraints on arbitrary facts at arbitrary time points and
then continue with a successive expansion based on this thread. However, this would result
in a rather aimless exploration of the exponential search space. Following the ple-expansion
instead helps to direct the search for a suitable model guided by the rules specified in
T2 (B). To illustrate this, consider Figure 4 from the previous example: Possible pleexpansions could for example result in an additional thread by altering the punctuality of
train T2 . Clearly, the resulting situations are intended in this model, as they were already
considered in the original thread specification (cf. Figure 1, p. 50). On the other hand, by
deviating from the ple-expansion, one could add additional factssay at(T1 , CA ), on(A, T1 )
at arbitrary time points t > 1. This could then give rise to multiple subsequent expansions
of the resulting thread and may actually serve to generate a model for B, while such a
situation was not intended by the specification of B. The example about train punctuality
also illustrates the requirement of an undo operation: The fact punct(T2 )  T h1 (4) produced
the additional constraint {at(T2 , CB ), on(A, T2 )} at time t = 6. Clearly, this constraint
should not be enforced any longer ifbased on T h1 a new thread T h0 is created such that
punct(T2 ) 6 T h0 (4).
With information about violated constrains from the linear program corresponding to
sat(T2 (B), {T h1 , T h2 }), we can perform a dependency-directed selection of choice points:
100

fiPDT Logic

`,u
If the lower bound of a belief Bi,t
0 (k ) cannot be satisfied with the current set of threads,
0
an additional thread T h can be created with the existing constraints on T h1 or T h2 and
substituting the respective constraint on k , as shown in (58).
The dependency of choice points on violated lower bounds can best be illustrated through
the results from the previous example: Clearly, the upper bounds induced by B20 and B200
and the lower bound induced by B6 hinder satisfiability of T2 (B) with respect to the created
threads. Using the belief object of formula B20 (or B200 ) to create an additional thread T h3
yields the updated constraint

B20 :

0.81  I(T h1 ) + x  I(T h3 )  0.81

with a factor x depending on the frequency of the respective belief object in T h3 , while the
constraint induced by B6 remains unchanged. As a result, the new constraint only allows
for lower values of I(T h1 ), and thus the lower bound induced by B6 remains unsatisfiable.
Using the belief object of formula B6 to create an additional thread instead yields the
constraint
B6 :

0.93  I(T h1 ) + x  I(T h3 )  0.93,

whichthrough nonzero values for x and I(T h3 )potentially allows for lower values on
I(T h1 ). Note that this example only uses atomic belief formulae. For disjunctive belief
`,u
`,u
formulae B = (Bi,t
0 (1 )Bi,t0 (2 )   ), any of the respective belief objects with a violated
lower bound can be used to direct the selection of subsequent choice points (given that no
other disjunct of B is satisfiable, of course).
Combining information about violated lower bounds with the principle of least effort
provides a multi-stage heuristic to proceed with a dependency-directed selection of choice
points:
Definition 4.8 (Dependency-directed search heuristic). Let T2 (B) be a set of type 2 belief
formulae and let T be a set of threads such that sat(T2 (B), T ) holds. Then, to enable a
dependency-directed search for an expanded set T 0  T such that sat(T2 (B), T 0 ) holds, T
is expanded with an additional thread T h0 6 T according to the following rules.
1. If the existing set of threads T fails to satisfy lower bounds of constraints induced by
a belief formula B with belief object  and an additional thread T h0 can be obtained
through one ple-expansion with respect to , T is expanded to T 0 = T  {T h0 }.
2. Otherwise, if no dependency-directed ple-expansion is possible, another ple-expansion
is applied to T , if possible.
3. Finally, if no ple-expansion is possible in T , an additional thread T h0 can be created
by adding the constraint F  T h(t) (resp. F 6 T h(t)) for arbitrary facts F that are
not yet constrained in T h(t).
The intuition behind this heuristic is that information about violated probabilistic constraints should be used to select a suitable next expansion step, if possible. Otherwise,
other possible ple-expansion steps should be performed to use rules from T2 (B) to guide the
101

fiMartiny & Moller

search. Only if no further ple-expansions are possible, additional constraints should be employed to continue the search. Restricting possible expansions with respect to criterion 1 to
one step follows the principle of least effort, again: To illustrate this, consider Example 4.8:
It was shown that the created set of threads {T h1 , T h2 } fails to satisfy the lower bound of
belief formula B6 . In thread T h1 , there is no world T h1 (t) |= Obs{A} (punct(train)) such
that the precondition of the rule in B6 is satisfied. Consequently, there is no single step
ple-expansion of T h1 that could change the constraints induced by B6 . On the other hand,
T h2 provides two such choice points and should therefore be preferred for expansion. Note
that the soundness requirement will determine choices for all unconstrained facts. Thus,
in general the proposed expansion may produce threads that are already contained in T
by constraining facts that have been determined before. We will not consider this scenario
explicitly but instead assume that in such cases, further expansion steps are performed until
an additional thread is created.
4.5.2 A Thread Generation Example
To illustrate the expansion of a set of threads T with respect to the dependency-directed
search heuristic from Definition 4.8, in the following we resume the train example.
Example 4.9 (Trains continued). In the previous example, a set of threads T = {T h1 , T h2 }
has been created that fails to show satisfiability of T2 (B). Consequently, the heuristic from
Definition 4.8 should be used to iteratively expand this set until an expanded set of threads
T 0 is created such that a model for B is obtained or no further expansions of T 0 are possible.
Belief formula

.93,.93 pfr
r2 (Obs{A} (punct(train)), Obs{AB} (punct(train)))
B6 = BA,0
has already been identified as a belief formula which yields constrains with an unsatisfiable
lower bound and this should therefore be used to guide the subsequent expansion. As
already discussed before, no single-step ple-expansion of T h1 is possible to influence the
constraints induced by B6 . Therefore we continue with an expansion based on thread T h2 .
A visualization of the following steps is given in Figure 5.
There are two worlds in T h2 where Obs{A} (punct(train)) is satisfied, namely
Obs{A} (punct(T1 ))  T h2 (1) and Obs{A} (punct(T2 ))  T h2 (6). Both of these occurrences allow for an ple-expansion. We choose T h2 (1) to perform the expansion. This yields
a new thread T h3 with the additional constraint Obs{A,B} (punct(T1 ))  T h3 (3), while all
constraints from T h2 remain intact, since there are no constraints that need to be undone
by adding Obs{A,B}  T h3 (3).
The expanded set T 0 = T  {T h3 } can then be used to check sat(T2 (B), T 0 ). In thread
T h3 , the rule contained in B6 is satisfied in one of two occurrences of Obs{A} (punct(train))
and therefore yields a frequency of 0.5. Consequently, through transformation into a linear
program we obtain the constraints
B20 :
B200

:

B6 :

0.81 

I(T h1 )

 0.81

0.93 

I(T h1 ) + 0.5  I(T h3 )

 0.93

0.81 

I(T h1 )

102

 0.81

fiPDT Logic

T h4

T h3

00
T h2 B2
B5
0
T h1 B2

at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
1

Obs{A,B} (punct(T1 ))

Obs{A,B} (punct(T1 ))
B6
B300

B200
B5

B30



at(T2 , CC ), on(A, T2 )
punct(T2 )

B200
3

B40

4
1

Obs{A,B} (punct(T2 ))

at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CB ), on(A, T2 )



6

B6

at(T2 , CB ), on(A, T2 )

B400



8

9

t

Figure 5: Visualization of ple-expansions for the train example. Applications of formulae
from T2 (B) are marked in blue, additional constraints from T0 (B) and T1 (B)
are marked in red. Expansion steps are marked in green.

Apparently, B6 allows for lower values of I(T h1 ) for the this set T 0 . From the constraints
induced by B20 (resp. B200 ) we still obtain I(T h1 ) = 0.81. Then, the constraint induced
by B6 requires I(T h3 ) = 0.24 (since 0.81 + 0.5  0.24 = 0.93). This is still no suitable
probability assignment since the sum over all priors exceeds one. Consequently, the thread
set expansion continues. The above constraints show thataccording to condition 1 of the
search heuristicthread T h3 is now a suitable candidate for further expansion with respect
to the belief object of B6 .
Thus, based on T h3 , we create an additional thread T h4 through ple-expansion. In this
case, the only possible expansion step is Obs{A,B}  T h4 (8), which results in a frequency of
one for the rule contained in B6 . Thus, testing sat(Tk (B), T 0 ) with the further expanded
set T 0 yields the following constraints:
B20 :
B200

:

B6 :

0.81 

I(T h1 )

 0.81

0.93 

I(T h1 ) + 0.5  I(T h3 ) + 1  I(T h4 )

 0.93

0.81 

I(T h1 )

 0.81

These constraints are now satisfiable, for instance with

I(T 0 ) = 0.81, 0.07, 0, 0.12 .
Thus, sat(T2 (B), T 0 ) returns a positive result and satisfiability checking of B can terminate
with this result.
This result concludes satisfiability testing of the set of belief formulae B originally
specified in Example 4.1 (p. 72). Nevertheless, for illustration purposes we show the result
of further applications of ple-expansion steps in Figure 6. Changes in the additionally
created threads are obtained through a further respectively different application of a belief
formula from T2 (B), marked in blue in the respective threads. Worlds T h(t) that remain
unconstrained after a saturated application of ple-expansions are marked with /. All of
these worlds then give rise to further expansions according to step 3 of the search heuristic.
103

fi104

0
T h1 B2

00
T h2 B2
B5

T h3

T h4

T h5

T h6

T h7

T h8

T h9

1

at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )

at(T1 , CA ), on(A, T1 )
punct(T1 )

at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )
Obs{A} (punct(T1 ))
at(T1 , CA ), on(A, T1 )
punct(T1 )

B30

2

/

/

/

/

/

/

B200
B5

B6

3

/

/

B300

B200

Obs{A,B} (punct(T1 ))

Obs{A,B} (punct(T2 ))

/

/

/

/

Obs{A,B} (punct(T2 ))
B6

/

4

B200

00
/ B2
B5

/

1

5

at(T2 , CC ), on(A, T2 )
B40
punct(T2 )
/

/

/

/

/

at(T2 , CC ), on(A, T2 )
punct(T2 )
/
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
/
Obs{A} (punct(T2 ))

/

/

/

6

at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CC ), on(A, T2 )
punct(T2 )
Obs{A} (punct(T2 ))
at(T2 , CB ), on(A, T2 )

B400

B6

Obs{A,B} (punct(T2 ))

at(T2 , CC ), on(A, T2 )
punct(T2 )

at(T2 , CC ), on(A, T2 )
punct(T2 )

/

7

/

/

/

/

/

B400

8

/

/

/

Obs{A,B} (punct(T2 ))
B6

9

/
t

at(T2 , CB ), on(A, T2 )

at(T2 , CB ), on(A, T2 )

at(T2 , CB ), on(A, T2 )

at(T2 , CB ), on(A, T2 )

Obs{A,B} (punct(T2 ))
B6

/

/

/

/

/

at(T2 , CB ), on(A, T2 )

/

at(T2 , CB ), on(A, T2 )

at(T2 , CB ), on(A, T2 )

at(T2 , CB ), on(A, T2 )

B40

/

Martiny & Moller

Figure 6: Visualization of continued ple-expansions for the train example. Applications of
formulae from T2 (B) are marked in blue, additional constraints from T0 (B) and
T1 (B) are marked in red. Expansion steps originating from T h1 and T h2 are
marked in green and orange, respectively. Unconstrained worlds are marked with
/.

fiPDT Logic

Some comments on the resulting set of threads from this example are necessary. Comparing the final threads depicted in Figure 6 with the original set of threads introduced in
Figure 1 shows that the expansion result largely corresponds to the original specification
(except differing thread labels). There are some notable differences however.
 First of all, there is the additional predicate punct(train), which was introduced in
Example 4.1 (p. 72) to allow for a concise specification of the background knowledge.
As the concept of nonpunctual trains (and especially the respective ramifications)
are implicitly encoded in Figure 1 as well, this does not change the properties of the
modeled example.
 With the explicit representation of train punctuality, observations of nonpunctual
trains can be expressed explicitly in this example, while the previous example uses
the ramifications of nonpunctual trains to model observations. Since rules B3 and
B4 assert that ramifications of punctual respectively nonpunctual trains are common
knowledge among Alice and Bob, both modeling alternatives preserve the intended
meaning of the example.
 Another difference is the timing of Alices observations. In the original example we
assumed that such an observation occurs at the time point when a train was supposed
to arrive at the destination city. In the current example we assume that Alice already
observes that a train is not punctual when leaving the departure city. The reason
for this change is solely for illustration purposes: specifying in rule B5 that Alice
immediately observes a nonpunctual train yields a type 0 belief and thus serves to
illustrate how additional facts can be obtained through global constraints. Since rule
B6 ensures that potential calls to Bob (i.e., shared observations) occur two time points
after Alices original observation, the intended model of the original example is still
maintained.
 The above points are only concerned with specific details of the modeled domain.
Comparing the set threads from Figure 1 with the threads from Figure 6 also shows a
more general modeling problem: for instance, analyzing the worlds at time point 2 in
Figure 6 shows that Alice is not (necessarily) on train T1 , while she is on this train both
at the previous time point and later time points. Naturally, one should expect that
Alice is on the train at all intermediate time points between boarding and exiting the
train. This is an instance of the frame problem (e.g., Reiter, 2001) that occurs when
specifying dynamic systems through logic formulae. Generally, the frame problem is
concerned with finding a suitable set of axioms to describe adequate evolutions of the
world. From a modeling perspective, evolutions where Alice vanishes and reappears
while on a train ride are obviously no adequate evolutions of the world. An application
of the final step of the search heuristic could then yield a tremendous blow-up of the
considered set of threads. For the modeled problem, this would clearly result in
unintended models, but the resulting models could still serve to show satisfiability of
the respective set of belief formulae B, even though this result might not be desired.
This problem could be fixed by adding successor state axioms in the style of Reiter,
e.g., specifying that if Alice is on a train, she remains there for the next time point
unless she explicitly exits the train.
105

fiMartiny & Moller

4.5.3 Properties of the Representative Thread Generation
In this section, we provide results to connect the set of representative threads to the satisfiability problem of PDT Logic and discuss the complexity of generating representative
threads.
Theorem 4.15 (PDT Logic Decision Procedure). Let B be a set of PDT Logic belief
formulae, and let T = {T h1 , T h2 } be the initial set of threads with length tmax obtained
from B according to Equations (56) and (57). Iteratively expanding this set according to
the search heuristic from Definition 4.8 and testing sat(T2 (B), T 0 ) for the expanded sets T 0
until (i) sat(T2 (B), T 0 ) returns a positive result, or (ii) T 0 is fully expanded with respect to
the search heuristic yields a sound and complete decision procedure for sat(B, tmax ).
Proof. Both the initial set of threads T = {T h1 , T h2 } and the expanded sets T 0 obtained through ple-expansion steps are defined such that only sound threads according
to Definition 4.4 are considered. Theorem 4.13 (p. 92) states that the decision problem
sat(T2 (B), T ) is equivalent to sat(B, T ) if the set T contains only threads that are sound
with respect to B. A positive result for sat(B, T ) for threads with length tmax shows
that T is a model for B and thus sat(B, tmax ) follows. Consequently, a positive result for
sat(T2 (B), T 0 ) always proofs that B is satisfiable for tmax time points.
On the other hand, if no model for B has been found and it is not possible to create
additional threads according to the search heuristic from Definition 4.8 (p. 101), the search
space is fully explored. From this it follows that no model for B with tmax time points
exists and therefore B is unsatisfiable for tmax time points. Consequently, it follows that
the PDT Logic decision procedure is sound.
With these properties, the completeness result is straightforward: For any arbitrary
input B and tmax , either a model can be found or non-existence of such a model can be
proven through a full exploration of the search space, and thus completeness of the procedure
follows.
In the following, we analyze the complexity of generating representative threads for a
set of belief formulae B.
Theorem 4.16 (Complexity of representative thread generation). Let B be a set of belief
formulae. Creating a set of expanded representative threads T 0 for B is in EXPSPACE.
Proof. The maximum number of possible threads for a given set of belief formulae B is
determined through the size |FB | and the maximum time point tmax . Recall from Equation (29) (p. 71) that we use FB to identify all event formulae from B and use this as the set
of ground atoms to construct possible worlds. Since every PDT Logic formula contains at
most two event formulae, we obtain the constraint |FB |  2  |B|. The largest set of possible
threads is then obtained as the sequences of combinations of all possible worlds over all
time points, yielding 22tmax |B| possible threads. In the worst case, all |FB |  2  |B| representative threads are created before obtaining a satisfiability result. Consequently, creating
all possible representative threads is in the complexity class DSPACE(2p(n) ), which is the
class EXPSPACE.
From this theorem, we immediately obtain complexity results for the satisfiability problem sat(B, tmax ).
106

fiPDT Logic

Corollary 4.17 (Complexity of PDT SAT without a given set of threads). Checking satisfiability of a set of PDT Logic belief formulae B without a specification of possible threads
is in EXPSPACE.
Proof. The generation of representative threads is in EXPSPACE, as shown in Theorem 4.16. For a given set of threads Theorem 4.11 shows that satisfiability checking in
PDT Logic is in NP. Thus, this does not further increase complexity of the PDT sat problem without a given set of threads and it follows that this problem is in EXPSPACE.
Some comments on these results are necessary. Since the decision procedure outlined
in Theorem 4.15 yields an exponential expansion of possible threads T 0 which all need
to be fed into the decision problem sat(T2 (B), T 0 )the exponential space requirement is
evident. However, as we have illustrated with the example, positive satisfiability results can
possibly be already obtained through small sets of possible threads T 0 with a diminutive
size compared to the entire search space. Moreover, the discussion of the train example has
shown that a major part of the search space stems from insufficient rule specifications. This
is not a specific problem of our formalism nor the presented decision procedure, but a general
problem of rule-based modeling approaches, namely the aforementioned frame problem. An
incomplete model specification then leads to the generation of unintended models, which
serve to show satisfiability of the modeled problem, but have not been intended by the
respective modeler. This could lead to the worst caseboth from a complexity and from
a model perspectivethat after an exponential execution of the decision procedure, the
result only shows that the input specification does not specify the intended model. The
problem can be addressed on the modeling side by providing additional axioms to ensure
that no unintended model is generated. However, this leads to a significant increase in the
specification size and it is difficult to ensure through rule specifications that indeed every
unintended model is prevented.
The ple-expansion steps could be used as a heuristic to discriminate between intended
and unintended models: As shown in the train example, only applying ple-expansion steps
results in a relatively small set of threads, which indeed corresponds to the intention of
the model, while any further expansions inherently leads to an exponential growth of the
set of threads and introduces only additional unintended models. Thus, omitting the final
step of the search heuristic would give a significantly faster termination of the decision
procedure, even though the resulting procedure cannot prove unsatisfiable sets of formulae
any longer. However, one could use the expansion procedure to create the set of intended
threads first andpossibly after an inspection by the modelercontinue to use this set to
perform satisfiability checks with respect to the intended model.
The runtime of the expansion procedure and resulting satisfiability checks is clearly
tilted towards the positive side: If a set of belief formulae is satisfiable, there is a good
chance that satisfiability can be shown in a small number of steps. Negative results on
the other hand can only be obtained after an exhaustive exploration of the search space.
However, for many applications negative satisfiability results are required. For instance,
checking entailment B |= B can be checked through the reformulation sat(B  B).
For applications relying on such a reformulation, the presented procedure is unfavorable
because positive entailment results can never be obtained efficiently. One could overcome
this problem as sketched above by generating a set of intended threads first and then use
107

fiMartiny & Moller

this set to perform subsequent satisfiability testsonce a set of threads is given, the decision
problems complexity significantly decreases, as shown in Section 4.3.

5. Conclusion
In this work, by extending APT Logic to dynamic scenarios with multiple agents, we have
developed a general framework to represent and reason about the belief change in multiagent systems. Next to lifting the single-agent case of APT Logic to multiple agents, we
have also provided a suitable semantics to the temporal evolution of beliefs. The resulting
framework extends previous work on dynamic multi-agent epistemic logics by enabling the
quantification of agents beliefs through probability intervals. An explicit notion of temporal relationships is provided through temporal rules building on the concept of frequency
functions.
The quantification of beliefs with probability intervals instead of precise values has
the advantage that when domain experts model a problem, they can not only provide
background knowledge about the problem domain, but can also specify their certainty in
the respective specifications. Narrow interval quantifications reflect a high certainty and
vice versa. This can be a significant advantage compared to other probabilistic approaches,
because in most approaches, sharp probability values are required which a human can
usually not express with precise values and thus has to rely on guesses. Specifying precise
values, when these are actually not precisely known can yield misleading results. PDT Logic
is not exposed to this problem, because it is not required to guess sharp values to specify a
problem.
We have shown that there are two alternative ways of specifying problems in PDT Logic,
either through explicit enumerations of possible threads or through a set of appropriate
rules. Both approaches exhibit their specific advantages and drawbacks: For many problem
domains, requiring an exhaustive enumeration of all possible threads poses a severe obstacle
for modeling the respective scenarios, as the combinatorial blow-up renders the specification
practically unmanageable. On the other hand, there are problem domains (e.g., attack
graphs in cyber security scenarios) that come with such an explicit specification anyways.
For these types of problems, we have shown that it is possible to check satisfiability of these
models very efficiently.
To overcome modeling disadvantages of the thread-based approach, we have also shown
how a problem domain can be solely specified through a set of PDT Logic belief formulae.
For most problem domains, this is a more natural way of specifying the problem. Also, this
provides means to easily adapt many existing problemsthat are specified in other formal
languages as sets of rulesto PDT Logic. On the other hand, waiving the requirement
of an exhaustive thread specification and according probabilities extremely increases the
problem complexity of checking satisfiability of a set of PDT Logic formulae. Nevertheless,
even when only imprecise probabilities are given, the resulting problem remains decidable
and the increased complexity might be curtailed through search heuristics.
Combinations of both approaches are possible as well: If an exhaustive specification
of possible threads is given, but probability intervals are only specified through beliefs
with imprecise probabilities, the satisfiability problem can be transformed into a 0-1 mixed
integer linear program. As there are a variety of efficient solvers available for this class of
108

fiPDT Logic

problems, this transformation provides a means to exploit existing optimizations to check
satisfiability of PDT Logic formulae.

References
Aumann, R. J. (1976). Agreeing to Disagree. The Annals of Statistics, 4 (6), 12361239.
Baaz, M., Egly, U., Leitsch, A., Goubault-Larrecq, J., & Plaisted, D. (2001). Normal Form
Transformations. In Robinson, A., & Voronkov, A. (Eds.), Handbook of Automated
Reasoning, chap. 5, pp. 273  333. MIT Press.
Balas, E. (1985). Disjunctive Programming and a Hierarchy of Relaxations for Discrete
Optimization Problems. SIAM Journal on Algebraic Discrete Methods, 6 (3), 466
486.
Balas, E. (1998). Disjunctive Programming: Properties of the Convex Hull of Feasible
Points. Discrete Applied Mathematics, 89 (1), 344.
Balas, E., Ceria, S., & Cornuejols, G. (1993). A Lift-and-project Cutting Plane Algorithm
for Mixed 0-1 Programs. Mathematical Programming, 58 (3), 295324.
Balas, E., Ceria, S., & Cornuejols, G. (1996). Mixed 0-1 Programming by Lift-and-project
in a Branch-and-cut Framework. Management Science, 42 (9), 12291246.
Balas, E., & Perregaard, M. (2002). Lift-and-project for Mixed 0-1 Programming: Recent
Progress. Discrete Applied Mathematics, 123 (1), 129154.
Baltag, A., & Moss, L. S. (2004). Logics for Epistemic Programs. Synthese, 139 (2), 165224.
Baltag, A., Moss, L. S., & Solecki, S. (1998). The Logic of Public Announcements, Common
Knowledge, and Private Suspicions. In Proceedings of the Seventh Conference on
Theoretical Aspects of Rationality and Knowledge, TARK 98, pp. 4356.
Bertacco, L., Fischetti, M., & Lodi, A. (2007). A Feasibility Pump Heuristic for general
Mixed-Integer Problems. Discrete Optimization, 4 (1), 6376.
Bienstock, D. (1996). Computational Study of a Family of Mixed-Integer Quadratic Programming Problems. Mathematical Programming, 74 (2), 121140.
Bradley, S. (2015). Imprecise probabilities. In Zalta, E. N. (Ed.), The Stanford Encyclopedia
of Philosophy (Summer 2015 edition).
Computational Infrastructure For Operations Research (COIN-OR) Project, T. (2016).
CBC (Coin-or branch and cut) user guide. http://www.coin-or.org/Cbc/index.html.
accessed: 2016-04-15.
Cook, S. A. (1971). The Complexity of Theorem-proving Procedures. In Proceedings of the
Third Annual ACM Symposium on Theory of Computing, STOC 71.
Cripps, M. W., Ely, J. C., Mailath, G. J., & Samuelson, L. (2008). Common Learning.
Econometrica, 76 (4), 909933.
Dal Palu, A., Dovier, A., Pontelli, E., & Rossi, G. (2009). Gasp: Answer set programming
with lazy grounding. Fundamenta Informaticae - Advances in Computational Logic,
96 (3), 297322.
109

fiMartiny & Moller

de Carvalho Ferreira, N., Fisher, M., & van der Hoek, W. (2008). Specifying and Reasoning
about Uncertain Agents. International Journal of Approximate Reasoning, 49 (1),
3551.
Doder, D., Markovic, Z., Ognjanovic, Z., Perovic, A., & Raskovic, M. (2010). A Probabilistic Temporal Logic That Can Model Reasoning about Evidence. In Foundations of
Information and Knowledge Systems: 6th International Symposium, FoIKS 2010.
Ellsberg, D. (1961). Risk, Ambiguity, and the Savage Axioms. The Quarterly Journal of
Economics, 75 (4), 643669.
Faber, W., Leone, N., & Perri, S. (2012). The intelligent grounder of DLV. In Correct
Reasoning: Essays on Logic-Based AI in Honour of Vladimir Lifschitz. Springer.
Fagin, R., & Halpern, J. Y. (1994). Reasoning about Knowledge and Probability. Journal
of the ACM, 41 (2), 340367.
Fagin, R., Halpern, J. Y., & Megiddo, N. (1990). A Logic for Reasoning about Probabilities.
Information and Computation, 87 (1), 78128.
Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning About Knowledge.
MIT Press.
Fischetti, M., Glover, F., & Lodi, A. (2005). The Feasibility Pump. Mathematical Programming, 104 (1), 91104.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability; A Guide to the Theory
of NP-Completeness. W. H. Freeman & Co.
Gerbrandy, J., & Groeneveld, W. (1997). Reasoning About Information Change. Journal
of Logic, Language and Information, 6 (2), 147169.
Gnu

Project, T. (2016).
GLPK: GNU Linear Programming
http://www.gnu.org/software/glpk/glpk.html. accessed: 2016-04-15.

Kit.

Grunwald, P. D., & Halpern, J. Y. (2003). Updating Probabilities. Journal of Artificial
Intelligence Research, 19 (1), 243278.
Gurobi Optimization, Inc. (2016).
Gurobi optimizer reference
http://www.gurobi.com/documentation/. accessed: 2016-04-15.

manual.

Halpern, J. Y., & Pucella, R. (2006). A Logic for Reasoning about Evidence. Journal of
Artificial Intelligence Research, 26 (1), 134.
Halpern, J. Y., Samet, D., & Segev, E. (2009). Defining Knowledge in Terms of Belief: The
Modal Logic Perspective. The Review of Symbolic Logic, 2 (3), 469487.
Harsanyi, J. C. (1967). Games with Incomplete Information Played by Bayesian Players.
Part I. The Basic Model. Management Science, 14 (3), 159182.
Harsanyi, J. C. (1968a). Games with Incomplete Information Played by Bayesian Players.
Part II. Bayesian Equilibrium Points. Management Science, 14 (5), 320324.
Harsanyi, J. C. (1968b). Games with Incomplete Information Played by Bayesian Players.
Part III. The Basic Probability Distribution of the Game. Management Science, 14 (7),
486502.
110

fiPDT Logic

Hintikka, J. (1962). Knowledge and Belief: An Introduction to the Logic of the Two Notions.
Cornell University Press.
ILOG,
I.
(2016).
CPLEX
Optimizer.
01.ibm.com/software/commerce/optimization/cplex-optimizer/.
04-15.

http://wwwaccessed: 2016-

Kooi, B. P. (2003). Probabilistic Dynamic Epistemic Logic. Journal of Logic, Language and
Information, 12 (4), 381408.
Kripke, S. A. (1963). Semantical Considerations on Modal Logic. Acta Philosophica Fennica,
16, 8394.
Lloyd, J. W. (1987). Foundations of Logic Programming, 2nd Edition. Springer.
Martiny, K., Motzek, A., & Moller, R. (2015). Formalizing Agents Beliefs for Cyber-Security
Defense Strategy Planning. In CISIS 2015 - Proceedings of the 8th International Conference on Computational Intelligence in Security for Information Systems, Burgos,
Spain, 15-17 June, 2015.
Milch, B., & Koller, D. (2000). Probabilistic Models for Agents Beliefs and Decisions. In
Proceedings of the Sixteenth Annual Conference on Uncertainty in Artificial Intelligence, UAI 00. Morgan Kaufmann Publishers Inc.
Murty, K. G. (1983). Linear Programming. John Wiley & Sons.
Parikh, R., & Ramanujam, R. (2003). A Knowledge Based Semantics of Messages. Journal
of Logic, Language and Information, 12 (4), 453467.
Plaza, J. (1989). Logics of public communications. In Proceedings of the Fourth International
Symposium on Methodologies for Intelligent Systems: Poster session program, ISMIS
89. Oak Ridge National Laboratory.
Plaza, J. (2007). Logics of Public Communications. Synthese, 158 (2), 165179.
Reiter, R. (2001). Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems. MIT Press.
Sack, J. (2008). Temporal Languages for Epistemic Programs. Journal of Logic, Language
and Information, 17 (2), 183216.
Sack, J. (2009). Extending Probabilistic Dynamic Epistemic Logic. Synthese, 169 (2), 241
257.
Schrijver, A. (1986). Theory of Linear and Integer Programming. John Wiley & Sons.
Shakarian, P., Parker, A., Simari, G., & Subrahmanian, V. S. (2011). Annotated Probabilistic Temporal Logic. ACM Transactions on Computational Logic, 12 (2), 14:114:44.
Shakarian, P., Simari, G. I., & Subrahmanian, V. S. (2012). Annotated Probabilistic Temporal Logic: Approximate Fixpoint Implementation. ACM Transactions on Computational Logic, 13 (2), 13:113:33.
Shoham, Y., & Leyton-Brown, K. (2009). Multiagent Systems: Algorithmic, GameTheoretic, and Logical Foundations. Cambridge University Press.
van Benthem, J. (2003). Conditional Probability Meets Update Logic. Journal of Logic,
Language and Information, 12 (4), 409421.
111

fiMartiny & Moller

van Benthem, J., Gerbrandy, J., Hoshi, T., & Pacuit, E. (2009a). Merging Frameworks for
Interaction. Journal of Philosophical Logic, 38 (5), 491526.
van Benthem, J., Gerbrandy, J., & Kooi, B. (2009b). Dynamic Update with Probabilities.
Studia Logica, 93 (1), 6796.
van der Hoek, W. (1997). Some Considerations on the Logic PFD: A Logic combining
Modality and Probability. Journal of Applied Non-Classical Logics, 7 (3), 287307.
van Ditmarsch, H., van der Hoek, W., & Kooi, B. (2007). Dynamic Epistemic Logic.
Springer.
van Eijck, J. (2014). Dynamic epistemic logics. In Johan van Benthem on Logical and
Informational Dynamics, chap. 7, pp. 175202. Springer.
van Eijck, J., & Schwarzentruber, F. (2014). Epistemic Probability Logic Simplified. In
Gore, R., Kooi, B. P., & Kurucz, A. (Eds.), Advances in Modal Logic 10, invited and
contributed papers from the tenth conference on Advances in Modal Logic,, AiML
14. College Publications.
vos Savant, M. (1990). Ask Marilyn. Parade Magazine, 16.
Williams, H. P. (2009). Logic and Integer Programming. Springer.

112

fi