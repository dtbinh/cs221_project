Journal of Artificial Intelligence Research 39 (2010) 51-126

Submitted 4/10; published 9/10

Implicit Abstraction Heuristics
Michael Katz
Carmel Domshlak

dugi@tx.technion.ac.il
dcarmel@ie.technion.ac.il

Faculty of Industrial Engineering & Management,
Technion, Israel

Abstract
State-space search with explicit abstraction heuristics is at the state of the art of costoptimal planning. These heuristics are inherently limited, nonetheless, because the size of
the abstract space must be bounded by some, even if a very large, constant. Targeting
this shortcoming, we introduce the notion of (additive) implicit abstractions, in which
the planning task is abstracted by instances of tractable fragments of optimal planning.
We then introduce a concrete setting of this framework, called fork-decomposition, that is
based on two novel fragments of tractable cost-optimal planning. The induced admissible
heuristics are then studied formally and empirically. This study testifies for the accuracy
of the fork decomposition heuristics, yet our empirical evaluation also stresses the tradeoff
between their accuracy and the runtime complexity of computing them. Indeed, some
of the power of the explicit abstraction heuristics comes from precomputing the heuristic
function offline and then determining h(s) for each evaluated state s by a very fast lookup
in a database. By contrast, while fork-decomposition heuristics can be calculated in
polynomial time, computing them is far from being fast. To address this problem, we
show that the time-per-node complexity bottleneck of the fork-decomposition heuristics can
be successfully overcome. We demonstrate that an equivalent of the explicit abstraction
notion of a database exists for the fork-decomposition abstractions as well, despite their
exponential-size abstract spaces. We then verify empirically that heuristic search with the
databased fork-decomposition heuristics favorably competes with the state of the art of
cost-optimal planning.

1. Introduction
Heuristic search, either through progression in the space of world states or through regression in the space of subgoals, is a common and successful approach to classical planning.
It is probably the most popular approach to cost-optimal planning, that is, finding a plan
with a minimal total cost of its actions. The difference between various heuristic-search
algorithms for optimal planning is mainly in the admissible heuristic functions they employ.
In state-space search, such a heuristic estimates the cost of achieving the goal from a given
state and guarantees not to overestimate that cost.
A useful heuristic function must be accurate as well as efficiently computable. Improving
the accuracy of a heuristic function without substantially worsening the time complexity
of computing it usually translates into faster search for optimal solutions. During the last
decade, numerous computational ideas evolved into new admissible heuristics for classical
planning; these include the delete-relaxing max heuristic hmax (Bonet & Geffner, 2001), critical path heuristics hm (Haslum & Geffner, 2000), landmark heuristics hL , hLA (Karpas &
Domshlak, 2009) and hLM-cut (Helmert & Domshlak, 2009), and abstraction heuristics such
c
2010
AI Access Foundation. All rights reserved.

fiKatz & Domshlak

as pattern database heuristics (Edelkamp, 2001) and merge-and-shrink heuristics (Helmert,
Haslum, & Hoffmann, 2007). Our focus in this work is on the abstraction heuristics.
Generally speaking, an abstraction of a planning task is given by a mapping  : S  S 
from the states of the planning tasks transition system to the states of some abstract
transition system such that, for all states s, s0  S, the cost from (s) to (s0 ) is upperbounded by the cost from s to s0 . The abstraction heuristic value h (s) is then the cost from
(s) to the closest goal state of the abstract transition system. Perhaps the most well-known
abstraction heuristics are pattern database (PDB) heuristics, which are based on projecting
the planning task onto a subset of its state variables and then explicitly searching for optimal
plans in the abstract space. Over the years, PDB heuristics have been shown to be very
effective in several hard search problems, including cost-optimal planning (Culberson &
Schaeffer, 1998; Edelkamp, 2001; Felner, Korf, & Hanan, 2004; Haslum, Botea, Helmert,
Bonet, & Koenig, 2007). The conceptual limitation of these heuristics, however, is that the
size of the abstract space and its dimensionality must be fixed.1 The more recent merge-andshrink abstractions generalize PDB heuristics to overcome the latter limitation (Helmert
et al., 2007). Instead of perfectly reflecting just a few state variables, merge-and-shrink
abstractions allow for imperfectly reflecting all variables. As demonstrated by the formal
and empirical analysis of Helmert et al., this flexibility often makes the merge-and-shrink
abstractions much more effective than PDBs. However, the merge-and-shrink abstract
spaces are still searched explicitly, and thus they still have to be of fixed size. While quality
heuristics estimates can still be obtained for many problems, this limitation is a critical
obstacle for many others.
Our goal in this paper is to push the envelope of abstraction heuristics beyond explicit
abstractions. We introduce a principled way to obtain abstraction heuristics that limit neither the dimensionality nor the size of the abstract spaces. The basic idea behind what we
call implicit abstractions is simple and intuitive: instead of relying on abstract problems
that are easy to solve because they are small, we can rely on abstract problems belonging to
provably tractable fragments of optimal planning. The key point is that, at least theoretically, moving to implicit abstractions removes the requirement on the abstractions size to
be small. Our contribution, however, is in showing that implicit abstractions are far from
being of theoretical interest only. Specifically,
1. We specify acyclic causal-graph decompositions, a general framework for additive implicit abstractions that is based on decomposing the problem at hand along its causal
graph. We then introduce a concrete family of such abstractions, called fork decompositions, that are based on two novel fragments of tractable cost-optimal planning.
Following the type of analysis suggested by Helmert and Mattmuller (2008), we formally analyze the asymptotic performance ratio of the fork-decomposition heuristics
and prove that their worst-case accuracy on selected domains is comparable with that
of (even parametric) state-of-the-art admissible heuristics. We then empirically evaluate the accuracy of the fork-decomposition heuristics on a large set of domains from
recent planning competitions and show that their accuracy is competitive with the
state of the art.
1. This does not necessarily apply to symbolic PDBs which, on some tasks, may exponentially reduce the
PDBs representation (Edelkamp, 2002).

52

fiImplicit Abstraction Heuristics

2. The key attraction of explicit abstractions is that state-to-goal costs in the abstract
space can be precomputed and stored in memory in a preprocessing phase so that
heuristic evaluation during search can be done by a simple lookup. A necessary condition for this would seem to be the small size of the abstract space. However, we
show that an equivalent of the PDB and merge-and-shrinks notion of database
exists for the fork-decomposition abstractions as well, despite the exponential-size abstract spaces of the latter. These databased implicit abstractions are based on a proper
partitioning of the heuristic computation into parts that can be shared between search
states and parts that must be computed online per state. Our empirical evaluation
shows that A equipped with the databased fork-decomposition heuristics favorably
competes with the state of the art of cost-optimal planning.
This work is a revision and extension of the formulation and results presented by Katz
and Domshlak (2008, 2009), which in turn is based on ideas first sketched also by Katz and
Domshlak (2007a).

2. Preliminaries
We consider classical planning tasks corresponding to state models with a single initial state
and only deterministic actions. Specifically, we consider state models captured by the sas+
formalism (Backstrom & Nebel, 1995) with nonnegative action costs. Such a planning task
is given by a quintuple  = hV, A, I, G, costi, where:
 V is a set of state variables, with each v  V being associated with a finite domain
D(v). For a subset of variables V 0  V , we denote the set of assignments to V 0 by
D(V 0 ) = vV 0 D(v). Each complete assignment to V is called a state, and S = D(V )
is the state space of . I is an initial state. The goal G is a partial assignment to V ;
a state s is a goal state iff G  s.
 A is a finite set of actions. Each action a is a pair hpre(a), eff(a)i of partial assignments
to V called preconditions and effects, respectively. By Av  A we denote the actions
affecting the value of v. cost : A  R0+ is a real-valued, nonnegative action cost
function.
For a variable v and a value   D(v), instantiation of v by  is denoted by v : . For a
partial assignment p, V(p)  V denotes the subset of state variables instantiated by p. In
turn, for any V 0  V(p), by p[V 0 ] we denote the value of V 0 in p; if V 0 = {v} is a singleton,
we use p[v] for p[V 0 ]. For any sequence of actions  and variable v  V , by v we denote the
restriction of  to actions changing the value of v; that is, v is the maximal subsequence
of  consisting only of actions in Av .
An action a is applicable in a state s iff s[v] = pre(a)[v] for all v  V(pre(a)). Applying
a changes the value of v  V(eff(a)) to eff(a)[v]. The resulting state is denoted by sJaK; by
sJha1 , . . . , ak iK we denote the state obtained from sequential application of the (respectively
applicable) actions a1 , . . . , ak starting at state s. Such an action sequence is an s-plan if
G  sJha1 , . . . , ak iK, and it is a cost-optimal (or, in what follows, optimal) s-plan if the
sum of its action costs is minimal among all s-plans. The purpose of (optimal) planning is
finding an (optimal) I-plan. For a pair of states s1 , s2  S, by cost(s1 , s2 ) we refer to the
53

fiKatz & Domshlak

p2

B

c2

F
c

A
c1

t

D

c

c

t

E
p

c3

C

p

G
p1

(a)

(b)
in t

in c

B
A

D

F
D

E

C

E

at A

at B

at C

at D

at E

at F

at G

G
in c

(c)

in c

(d)

Figure 1: Logistics-style example adapted from Helmert (2006) and illustrated in (a). The
goal is to deliver p1 from C to G and p2 from F to E using the cars c1 , c2 , c3 and
truck t, making sure that c3 ends up at F . The cars may only use city roads (thin
edges); the truck may only use the highway (thick edge). Figures (b), (c), and
(d) depict, respectively, the causal graph of the problem, the domain transition
graphs (labels omitted) of c1 and c2 (left), t (center), and c3 (right), and the
identical domain transition graphs of of p1 and p2 .

cost of a cost-optimal plan from s1 to s2 ; h (s) = mins0 G cost(s, s0 ) is the custom notation
for the cost of the optimal s-plan in . Finally, important roles in what follows are played
by a pair of standard graphical structures induced by planning tasks.
 The causal graph CG() of  is a digraph over nodes V . An arc (v, v 0 ) is in CG()
iff v 6= v 0 and there exists an action a  A such that (v, v 0 )  V(eff(a))  V(pre(a)) 
V(eff(a)). In this case, we say that (v, v 0 ) is induced by a. By succ(v) and pred(v) we
respectively denote the sets of immediate successors and predecessors of v in CG().
 The domain transition graph DTG(v, ) of a variable v  V is an arc-labeled digraph
over the nodes D(v) such that an arc (, 0 ) labeled with pre(a)[V \ {v}] and cost(a)
exists in the graph iff both eff(a)[v] = 0 , and either pre(a)[v] =  or v 6 V(pre(a)).
To illustrate various constructs, we use a slight variation of a Logistics-style example
from Helmert (2006). This example is depicted in Figure 1a, and in sas+ it has
54

fiImplicit Abstraction Heuristics

V

= {p1 , p2 , c1 , c2 , c3 , t}

D(p1 ) = D(p2 ) = {A, B, C, D, E, F, G, c1 , c2 , c3 , t}
D(c1 ) = D(c2 ) = {A, B, C, D}

D(c3 ) = {E, F, G}
D(t) = {D, E}

I = {p1 : C, p2 : F, t : E, c1 : A, c2 : B, c3 : G}

G = {p1 : G, p2 : E, c3 : F },

and actions corresponding to all possible loads and unloads, as well as single-segment movements of the vehicles. For instance, if action a captures loading p1 into c1 at C, then
pre(a) = {p1 : C, c1 : C}, and eff(a) = {p1 : c1 }. All actions in the example have unit cost.
The causal graph of this example, as well as the domain transition graphs of the state
variables, are depicted in Figures 1b-1d.
Heuristic functions are used by informed-search procedures to estimate the cost (of the
cheapest path) from a search node to the nearest goal node. Our focus here is on statedependent, admissible abstraction heuristics. A heuristic function h is state-dependent if its
estimate for a search node depends only on the problem state associated with that node,
that is, h : S  R0+  {}. Most heuristics in use these days are state-dependent (though
see, e.g., Richter, Helmert, & Westphal, 2008 and Karpas & Domshlak, 2009 for a different
case). A heuristic h is admissible if h(s)  h (s) for all states s. If h1 and h2 are two
admissible heuristics, and h2 (s)  h1 (s) for all states s, we say that h1 dominates h2 .
For any set of admissible heuristics h1 , . . . , hm , their pointwise maximum is always an
admissible heuristic, dominating each individual heuristic in the set. For some sets of admissible heuristics, their pointwise sum is also admissible and dominates their pointwise
maximum. Many recent works on cost-optimal planning are based on additive ensembles of admissible heuristics, and this includes critical-path heuristics (Haslum, Bonet, &
Geffner, 2005; Coles, Fox, Long, & Smith, 2008), pattern database heuristics (Edelkamp,
2001; Haslum et al., 2007), and landmark heuristics (Karpas & Domshlak, 2009; Helmert &
Domshlak, 2009). In particular, Katz and Domshlak (2007a, 2008) and Yang et al. (2007,
2008) independently introduced a general criterion for admissible additive ensembles of
heuristics, called in the former work action cost partitioning. This criterion can be formalized as follows. Let  = hV, A, I, G,
be a planning task and {costi : A  R0+ }m
i=1 a
Pcosti
m
family of cost functions such that i=1 costi (a)  cost(a) for all actions a  A. If {hi }m
i=1
is a set
of
arbitrary
admissible
heuristic
functions
for

=
hV,
A,
I,
G,
cost
i,
respectively,
i
i
P
m
then m
i=1 hi is also an admissible heuristic for . The set of cost functions {costi }i=1 can
be seen as a partition of the action costs cost.

3. Abstractions and Abstraction Heuristics
The semantics of any planning task  is given by its induced state-transition model, often
called the transition graph of .

55

fiKatz & Domshlak

Definition 1 A transition graph is a tuple T = (S, L, Tr, s0 , S ? , $) where S is a finite
set of states, L is a finite set of transition labels, Tr  S  L  S is a set of (labeled)
transitions, s0  S is an initial state, S ?  S is a set of goal states, and $ : L  R0+ is a
transition cost function.
 For a state s  S and a subset of states S 0  S in T, cost(s, S 0 ) is the cost (of a
cheapest with respect to $ path) from s to a state in S 0 along the transitions of T; if
no state in S 0 is reachable from s, then we have cost(s, S 0 ) = .
 Any path from s0 to S ? is a plan for T, and cheapest such plans are called optimal.
The states of the transition graph T() induced by a planning task  = hV, A, I, G, costi
are the states of . The transition labels of T() are the actions A; there is a transition
(s, a, sJaK)  Tr iff a is applicable in s; the initial state s0 = I; the set of goal states
S ? = {s  S | s  G}; and the transition cost function $ = cost.
We now proceed
with formally specifying the notion of abstraction. Our definition of abstraction resembles
that of Prieditis (1993), and right from the beginning we specify a more general notion of
additive abstraction. Informally, by additive abstraction we refer to a set of abstractions
interconstrained by a requirement to jointly not overestimate the transition-path costs in
the abstracted transition graph.
Definition 2 An additive abstraction of a transition graph T = (S, L, Tr, s0 , S ? , $) is
a set of pairs {hTi , i i}m
i=1 where, for 1  i  m,
 Ti = (Si , Li , Tri , s0i , Si? , $i ) is a transition graph,
 i : S  Si is a function, called abstraction mapping, such that
 i (s0 ) = s0i , i (s)  Si? for all s  S ? , and,
 for all pairs of states s, s0  S holds
m
X
i=1

cost(i (s), i (s0 ))  cost(s, s0 ).

(1)

A few words on why we use this particular notion of abstraction. The term abstraction
is usually associated with simplifying the original system, reducing and factoring out details
less crucial in the given context. Which details can be reduced and which should better
be preserved depends, of course, on the context. For instance, in the context of formal
verification, the abstract transition graphs are required not to decrease the reachability
between the states; that is, if there is a path from s to s0 in the original transition graph,
then there should be a path from (s) to (s0 ) in the abstract transition graph (Clarke,
Grumberg, & Peled, 1999). In addition, the reachability should also be increased as little as
possible. Beyond that, the precise relationship between the path costs in the original and
abstract transition graphs is only of secondary importance. In contrast, when abstractions
are designed to induce admissible heuristic functions for heuristic search, the relationship
between the path costs as captured by Eq. 1 is what must be obeyed. However, requirements
above and beyond the general requirement of Eq. 1 not to overestimate the distances between
56

fiImplicit Abstraction Heuristics

the states are unnecessary. Hence, in particular, Definition 2 generalizes the notion of
abstraction by Helmert et al. (2007) by replacing the condition of preserving individual
transitions and their labels, that is, ((s), l, (s0 )) if (s, l, s0 ), with a weaker condition stated
in Eq. 1. The reader, of course, may well ask whether the generality of the condition in
Eq. 1 beyond the condition of Helmert et al. (2007) really delivers any practical gain, and
later we show that the answer to this question is affirmative. For now, we proceed with
adding further requirements essential to making abstraction usable as a basis for heuristic
functions.
Definition 3 Let  be a planning task over states S, and let {hTi , i i}m
i=1 be an additive
abstraction of the transition graph T(). If m = O(poly(||||)) and, for all states s  S
and all 1P
 i  m, the cost cost(i (s), Si? ) in Ti is computable in time O(poly(||||)), then
?
hA (s) = m
i=1 cost(i (s), Si ) is an abstraction heuristic function for .
Note that admissibility of hA is implied by the cost conservation condition of Eq. 1. To further illustrate the connection between abstractions and admissible heuristics, consider three
well-known mechanisms for devising admissible planning heuristics: delete relaxation (Bonet
& Geffner, 2001), critical-path relaxation (Haslum & Geffner, 2000),2 and pattern database
heuristics (Edelkamp, 2001).
First, while typically not considered this way, the delete relaxation of a planning task
? , $ ),  i
 = hV, A, I, G, costi does correspond to an abstraction hT+ = (S+ , L+ , Tr+ , s0+ , S+
+
+
of the transition
graph
T().
Assuming
unique
naming
of
the
variable
values
in

and
deS
noting D+ = vV D(v), we have the abstract states S+ being the power-set of D+ , and the
labels L+ = {a, a+ | a  A}. The transitions come from two sources: for each abstract state
s+  S+ and each original action a  A applicable in s+ , we have both (s+ , a, s+ JaK)  Tr+
and (s+ , a+ , s+  eff(a))  Tr+ . With a minor abuse of notation, the initial state and the
? = {s  S | s  G}, and the abstraction
goal states of the abstraction are s0+ = I and S+
+
+
+
mapping + is simply the identity function. It is easy to show that, for any state s of our
? ) = h+ (s), where h+ (s) is the delete-relaxation
planning task , we have cost(+ (s), S+
estimate of the cost from s to the goal. As an aside, we note that this delete-relaxation
abstraction hT+ , + i in particular exemplifies that nothing in Definition 2 requires the
size of the abstract state space to be limited by the size of the original state space. In any
event, however, the abstraction hT+ , + i does not induce a heuristic in terms of Definition 3
because computing h+ (s) is known to be NP-hard (Bylander, 1994).
The situation for critical-path relaxation is exactly the opposite. While computing
the corresponding family of admissible estimates hm is polynomial-time for any fixed m,
this computation is not based on computing the shortest paths in an abstraction of the
planning task. The state graph over which hm is computed is an AND/OR-graph (and not
an OR-graph such as transition graphs), and the actual computation of hm corresponds
to computing a critical tree (and not a shortest path) to the goal. To the best of our
knowledge, the precise relation between critical path and abstraction heuristics is currently
an open question (Helmert & Domshlak, 2009).
Overall, the only abstraction heuristics in the toolbox of planning these days appear to
be the explicit homomorphism abstractions, whose best-known representative is probably
2. We assume the reader is familiar with these two relaxations. If not, their discussion here can be safely
skipped.

57

fiKatz & Domshlak

the pattern database (PDB) heuristics. Given a planning task  over state variables V ,
a PDB heuristic is based on projecting  onto a subset of its variables V   V . Such a
homomorphism abstraction  maps two states s1 , s2  S into the same abstract state iff
s1 [V  ] = s2 [V  ]. Inspired by the (similarly named) domain-specific heuristics for search
problems such as (n2  1)-puzzles or Rubiks Cube (Culberson & Schaeffer, 1998; Hernadvolgyi & Holte, 1999; Felner et al., 2004), PDB heuristics have been successfully exploited in domain-independent planning as well (Edelkamp, 2001, 2002; Haslum et al.,
2007). The key decision in constructing PDBs is what sets of variables the problem is
projected to (Edelkamp, 2006; Haslum et al., 2007). However, apart from that need to
automatically select good projections, the two limitations of PDB heuristics are the size of
the abstract space S  and its dimensionality. First, the number of abstract states should
be small enough to allow reachability analysis in S  by exhaustive search. Moreover, an
O(1) bound on |S  | is typically set explicitly to fit the time and memory limitations of
the system. Second, since PDB abstractions are projections, the explicit constraint on |S  |
implies a fixed-dimensionality constraint |V  | = O(1). In planning tasks with, informally,
many alternative resources, this limitation is a pitfall. For instance, suppose {i }
i=1 is a
sequence of Logistics problems of growing size with |Vi | = i. If each package in i can be
transported by some (i) vehicles, then starting from some i, h will not account at all for
movements of vehicles essential for solving i (Helmert & Mattmuller, 2008).
Aiming at preserving the attractiveness of the PDB heuristic while eliminating the bottleneck of fixed dimensionality, Helmert et al. (2007) have generalized the methodology
of Drager, Finkbeiner, and Podelski (2006) and introduced the so called merge-and-shrink
(MS) abstractions for planning. MS abstractions are homomorphisms that generalize PDB
abstractions by allowing for more flexibility in selection of pairs of states to be contracted.
The problems state space is viewed as the synchronized product of its projections onto the
single state variables. Starting with all such atomic abstractions, this product can be
computed by iteratively composing two abstract spaces, replacing them with their product.
While in a PDB the size of the abstract space S  is controlled by limiting the number of
product compositions, in MS abstractions it is controlled by interleaving the iterative composition of projections with abstraction of the partial composites. Helmert et al. (2007) have
proposed a concrete strategy for this interleaved abstraction/refinement scheme and empirically demonstrated the power of the merge-and-shrink abstraction heuristics. Like PDBs,
however, MS abstractions are explicit abstractions, and thus computing their heuristic values is also based on explicitly searching for optimal plans in the abstract spaces. Hence,
while merge-and-shrink abstractions escape the fixed-dimensionality constraint of PDBs,
the constraint on the abstract space to be of a fixed size still holds.

4. Implicit Abstractions
Focusing on the O(1) bound posted by explicit abstractions on the size of the abstract
space, our first observation is that explicit abstractions are not necessarily the only way to
proceed with abstraction heuristics. Given a planning task  over states S, suppose we can
transform it into a different planning task  such that
1. the transformation induces an abstraction mapping  : S  S  where S  is the state
space of  , and
58

fiImplicit Abstraction Heuristics

2. both the transformation of  to  , as well as computing  for any state in S, can
be done in time polynomial in ||||.
Having such planning-task-to-planning-task transformations in mind, we define what we
call (additive) implicit abstractions.
Definition 4 An additive implicit abstraction of a planning task  is a set of pairs
m
m
A = {hi , i i}m
i=1 such that {i }i=1 are some planning tasks and {hT(i ), i i}i=1 is an
additive abstraction of T().
Let us now examine the notion of implicit abstractions more closely. First, implicit
abstractions allow for a natural additive combination of admissible heuristics for the abstract
tasks. This composition is formulated below by Theorem 1, extending the original criterion
for admissibility of additive heuristics described in Section 2. Second, as formulated by
Theorem 2, implicit abstractions can be composed via the functional composition of their
abstraction mappings. These two easy-to-prove properties of implicit abstractions allow us
then to take the desired step from implicit abstractions to implicit abstraction heuristics.
Theorem 1 (Admissibility) Let  be a planning task and A = {hi , i i}m
i=1 be an additive implicit abstraction of
.
If,
for
each
1

i

m,
h
is
an
admissible
heuristic
for i ,
i
Pm
then the function h(s) = i=1 hi (i (s)) is an admissible heuristic for .
Proof: The proof is straightforward. Let T = (S, L, Tr, s0 , S ? , $) be the transition graph
of , and let s be some state in S. For each 1  i  m, let Ti = (Si , Li , Tri , s0i , Si? , $i ) be
the transition graph of i .
First, if hi is an admissible heuristic for i , then for all si  Si? ,
hi (i (s))  cost(i (s), si ).
Now, for each state s0  S ? , from Definition 2 we have i (s0 )  Si? , and from Eq. 1 we have
m
X
i=1

and thus
h(s) =

m
X
i=1

cost(i (s), i (s0 ))  cost(s, s0 ),

hi (i (s)) 

giving us an admissible estimate for

m
X

i=1

h (s).

cost(i (s), i (s0 ))  cost(s, s0 ),


Theorem 2 (Composition) Let  be a planning task and A = {hi , i i}m
i=1 be an addimi
tive implicit abstraction of . If, for each
i,j , i,j i}j=1 is an additive
S 1  i  m, Ai = m{h
i
implicit abstraction of i , then A0 = m
{h
,



i}
is
an additive implicit abi,j
i,j
i j=1
i=1
straction of .
Proof: Let T = (S, L, Tr, s0 , S ? , $) be the transition graph of . For each 1  i  m,
let Ti = (Si , Li , Tri , s0i , Si? , $i ) be the transition graph of i , and for each 1  j  mi , let
? , $ ) be the transition graph of  . We need to show that
Ti,j = (Si,j , Li,j , Tri,j , s0i,j , Si,j
i,j
i,j
i,j  i is an abstraction mapping as in Definition 2. From i and i,j being abstraction
mappings, we have
59

fiKatz & Domshlak

 s0i,j = i,j (s0i ) = i,j (i (s0 )) = i,j  i (s0 ),
? , and
 for all s  S ? we have i (s)  Si? and thus i,j (i (s)) = i,j  i (s)  Si,j
P i
0
0
 for all si , s0i  Si , cost(si , s0i )  m
j=1 cost(i,j (si ), i,j (si )), and thus for all s, s  S,

cost(s, s0 ) 

m
X
i=1

cost(i (s), i (s0 )) 
=

mi
m X
X
i=1 j=1
mi
m X
X
i=1 j=1

cost(i,j (i (s)), i,j (i (s0 )))
cost(i,j  i (s), i,j  i (s0 )).


Together, Theorems 1 and 2 suggest the following scheme for deriving abstraction heuristics. Given an additive implicit abstraction A = {hi , i i}m
i=1 , if all its individual abstract
tasks belong to some tractable fragments of optimal planning, then we can use in practice
the (sum of the) true costs in all i as the admissible estimates for the costs in . Otherwise, if optimal planning for some abstract tasks i in A cannot be proven polynomial-time
solvable, then we can further abstract these tasks, obtaining admissible estimates for the
true costs in i .
Definition 5 Let  be a planning task over states S, and let A = {hi , i i}m
i=1 be an
additive implicit abstraction of . If m = O(poly(||||)), and, for allP
states s  S and all

1  i  m, h (i (s)) is polynomial-time computable, then hA (s) = m
i=1 h (i (s)) is an
implicit abstraction heuristic function for .
Compared to explicit abstraction heuristics such as PDB heuristics and merge-andshrink heuristics, the direction of implicit abstraction heuristics is, at least in principle,
appealing because neither the dimensionality nor even the size of the state spaces induced
by implicit abstractions are required to be bounded by something restrictive, if at all. The
pitfall, however, is that implicit abstraction heuristics correspond to tractable fragments of
optimal planning, and the palette of such known fragments is extremely limited (Backstrom
& Nebel, 1995; Bylander, 1994; Jonsson & Backstrom, 1998; Jonsson, 2007; Katz & Domshlak, 2007b). In fact, none so far has appeared to us very convenient for automatically devising useful problem transformations as above. Fortunately, we show next that the boundaries
of tractability can be expanded in the right way, allowing us to successfully materialize the
idea of implicit abstraction heuristics.
In the following, a key role is played by the causal graphs induced by the planning
tasks. Informally, the basic idea behind what we call causal-graph decompositions is to
abstract the given planning task  along a subgraph of s causal graph, with the goal of
obtaining abstract problems of specific structure. Naturally, there are numerous possibilities
for obtaining such structure-oriented abstractions. We now present one such decomposition
that is tailored to abstractions around acyclic subgraphs. Informally, this decomposition
can be seen as a sequential application of two kinds of task transformations: dropping
preconditions (Pearl, 1984) and (certain form of) breaking actions with conjunctive effects
into single-effect actions.
60

fiImplicit Abstraction Heuristics

Definition 6 Let  = hV, A, I, G, costi be a planning task, and let G = (VG , EG ) be an
acyclic subgraph of the causal graph CG(). A planning task G = hVG , AG , IG , GG , costG i
is an acyclic causal-graph decomposition of  with respect to G if
1. IG = I[VG ], GG = G[VG ],
S
2. AG = aA AG (a) where each AG (a) = {a1 , . . . , al(a) } is a set of actions over VG
such that, for a topological with respect to G ordering of the variables {v1 , . . . , vl(a) } =
V(eff(a))  VG , and 1  i  l(a),
(
eff(a)[v],
v = vi
i
eff(a )[v] =
unspecified, otherwise

(2)

(v, vi )  EG  v 6 V(eff(a)) or v = vi
pre(a)[v],
pre(ai )[v] = eff(a)[v],
(v, vi )  EG  v  V(eff(a))


unspecified, otherwise
3. For each action a  A,

X
a0 AG (a)

costG (a0 )  cost(a).

(3)

It is not hard to verify from Definition 6 that for any planning task  and any acyclic
causal-graph decomposition G of , the causal graph CG(G ) is exactly the subgraph G underlying the decomposition. To illustrate the notion of acyclic causal-graph decomposition,
we consider a planning task  = hV, A, I, G, costi over five state variables V = {u, v, x, y, z},
two unit-cost actions A = {a1 , a2 } as in Figure 2a, initial state I = {u : 0, v : 0, x : 0, y : 0, z : 0},
and goal G = {u : 1, v : 1, x : 0, y : 1, z : 1}. The causal graph CG() is depicted in Figure 2a.
Figures 2b-c show two subgraphs G1 and G2 of CG(), respectively, as well as the action sets AG1 (a1 ) = {a11 , a21 , a31 } and AG1 (a2 ) = {a12 , a22 , a32 } in Figure 2(b), and the action
sets AG2 (a1 ) = {a11 , a21 , a31 } and AG2 (a2 ) = {a12 , a22 , a32 } in Figure 2(c). For i  {1, 2}, let
i = hV, Ai , I, G, costi i be the planning task with Ai = AGi (a1 )AGi (a2 ) and costi (a) = 1/3
for all a  Ai . These two planning tasks i (individually) satisfy the conditions of Definition 6 with respect to  and Gi , and thus they are acyclic causal-graph decompositions of
 with respect to Gi .
We now proceed with specifying implicit abstractions defined via acyclic causal-graph
decompositions.
Definition 7 Let  = hV, A, I, G, costi be a planning task over states S, and let G = {Gi =
m
(VGi , EGi )}m
i=1 be a set of acyclic subgraphs of the causal graph CG(). A = {hGi , i i}i=1
is an acyclic causal-graph abstraction of  over G if, for some set of cost functions
{costi : A  R0+ }m
i=1 satisfying
a  A :

m
X
i=1

costi (a)  cost(a),

we have, for 1  i  m,
61

(4)

fiKatz & Domshlak

a1 = h{x : 0, y : 0, z : 0}, {x : 1, y : 1, z : 1}i

a11 = h{x : 0}, {x : 1}i
a21 = h{x : 1, y : 0}, {y : 1}i
a31 = h{x : 1, z : 0}, {z : 1}i

a11 = h{y : 0}, {y : 1}i
a21 = h{z : 0}, {z : 1}i
a31 = h{y : 1, z : 1, x : 0}, {x : 1}i

a2 = h{u : 0, v : 0, x : 1}, {u : 1, v : 1, x : 0}i

a12 = h{x : 1}, {x : 0}i
a22 = h{x : 0, u : 0}, {u : 1}i
a32 = h{x : 0, v : 0}, {v : 1}i

a12 = h{u : 0}, {u : 1}i
a22 = h{v : 0}, {v : 1}i
a32 = h{u : 1, v : 1, x : 1}, {x : 0}i

u

a1

a2

x

a2
a2

y

x
a1

a22

a1

v

z

u

a31

a32 a21

y

v

(a)

u

(b)

a32

z

y

v
a32

a31

z
a31

x
(c)

Figure 2: (a) The actions and causal graph CG() of the planning graph in the example
illustrating Definition 2. (b) Subgraph G1 of CG() and the induced action sets
AG1 (a1 ) and AG1 (a2 ). (c) Subgraph G2 of CG() and the induced action sets
AG2 (a1 ) and AG2 (a2 ). The arcs of both CG() and its subgraphs G1 and G2 are
labeled with the actions inducing the arcs.

 Gi = hVGi , AGi , IGi , GGi , costGi i is an acyclic causal-graph decomposition of i =
hV, A, I, G, costi i with respect to Gi , and
 the abstraction mapping i : S  Si is the projection mapping i (s) = s[VGi ].
Theorem 3 Acyclic causal-graph abstractions of the planning tasks are additive implicit
abstractions of these tasks.
Proof: Let  = hV, A, I, G, costi be a planning task, and let A = {hGi , i i}m
i=1 be an
acyclic causal-graph abstraction of  over a set of subgraphs G = {Gi = (VGi , EGi )}m
i=1 .
Let T = (S, L, Tr, s0 , S ? , $) be the transition graph of , and, for 1  i  m, Ti =
(Si , Li , Tri , s0i , Si? , $i ) be the transition graph of Gi . We need to show that i is an abstraction mapping as in Definition 2.
First, from Definitions 6 and 7, we have
 s0i = IGi = I[VGi ] = s0 [VGi ] = i (s0 ), and
 for all s  S ? we have s  G and thus i (s) = s[VGi ]  G[VGi ] = GGi , providing us
with i (s)  Si? .
Now, if s is a state of  and a  A is an action with pre(a)  s, then i (s) is a state of Gi
and pre(a)[VGi ]  i (s). Let the action sequence  = ha1 , a2 , . . . , al(a) i be constructed from
a as in Eq. 2. We inductively prove that  is applicable in i (s). First, for each v  VGi ,
either pre(a1 )[v] = pre(a)[v], or pre(a1 )[v] is unspecified, and thus 1 = ha1 i is applicable in
i (s). The inductive hypothesis is now that j = ha1 , a2 , . . . , aj i is applicable in i (s), and
0
let s0 = i (s)Jj K. From Eq. 2, for each 1  j 0  j, aj changes the value of vj 0 to eff(a)[vj 0 ],
62

fiImplicit Abstraction Heuristics

and that is the only change of vj 0 along j . Likewise, since all the actions constructed as in
Eq. 2 are unary-effect, {v1 , . . . , vj } are the only variables in VGi affected along j . Hence,
for all v  VGi , if v = vj 0 , 1  j 0  j, then s0 [v] = eff(a)[v] = pre(aj+1 )[v], and otherwise,
s0 [v] = i (s)[v], and if pre(aj+1 )[v] is specified, then pre(aj+1 )[v] = pre(a)[v] = i (s)[v]. This
implies that aj+1 is applicable in s0 and, as a result, j+1 = ha1 , a2 , . . . , aj+1 i is applicable in
i (s), finalizing the inductive proof. Likewise, exactly the same arguments on the affect of
l(a)
{aj }j=1 on i (s) immediately imply that, if  = ha1 , a2 , . . . , al(a) i, then i (sJaK) = i (s)JK.
Next, for each a  A, from Eqs. 3 and 4 we have
m
X

X

i=1 a0 AGi (a)

costGi (a0 ) 

m
X
i=1

costi (a)  cost(a).

(5)

Now, let s, s0  S be a pair of original states such that cost(s, s0 ) < , and let % =
0
ha1 , . . . , ak i be the sequence
Pk of labels along a cheapest path from s to s in T. From that,
0
cost(s, s ) = cost(%) = j=1 cost(aj ). The decomposition of such a path to the sequences
of actions as in Eq. 2 is aP(not P
neccesarily cheapest) path from i (s) to i (s0 ) in Ti , and
k
0
thus cost(i (s), i (s ))  j=1 a0 AG (aj ) costGi (a0 ), providing us with
i

m
X
i=1

0

cost(i (s), i (s )) 
(5)



m X
k
X

X

0

costGi (a ) =

i=1 j=1 a0 AGi (aj )
k
X

k X
m
X

X

costGi (a0 )

j=1 i=1 a0 AGi (aj )

cost(aj ) = cost(s, s0 ).

j=1


Thus, if we can decompose the given task  into a set of tractable acyclic causalgraph decompositions  = {G1 , . . . , Gm }, then we can solve all these tasks in polynomial
time, and derive an additive admissible heuristic for . Before we proceed with considering
concrete acyclic causal-graph decomposition, note that Definition 2 leaves the decision about
the actual partition of the action costs rather open. In what follows we adopt the most
straightforward, uniform action cost partition in which theScost of each action a is equally
split among all the non-redundant representatives of a in m
i=1 AGi (a). However, a better
choice of action cost partition can sometimes be made. In fact, sometimes it can even be
optimized (Katz & Domshlak, 2010)

5. Fork Decompositions
We now proceed with introducing two concrete acyclic causal-graph decompositions that,
when combined with certain variable domain abstractions, provide us with implicit abstraction heuristics. These so called fork-decomposition heuristics are based on two novel
fragments of tractable cost-optimal planning for tasks with fork and inverted-fork structured
causal graphs.
Definition 8 For a planning task  over variables V , and a variable v  V ,
63

fiKatz & Domshlak

(1) v-fork of  is the subgraph Gvf of CG() over nodes VGvf = {v}  succ(v) and edges
EGvf = {(v, u) | u  succ(v)}, and
(2) v-ifork (short for inverted fork) of  is a subgraph Gvi of CG() over nodes VGvi =
{v}  pred(v) and edges EGvi = {(u, v) | u  pred(v)}.
The sets of all v-forks and all v-iforks of  are denoted by GF = {Gvf }vV and GI =
{Gvi }vV , respectively.
For any planning task and each of its state variables v, both v-fork and v-ifork are
acyclic digraphs, allowing us to define our three implicit abstractions as follows.
Definition 9 For any planning task  = hV, A, I, G, costi,

(1) any acyclic causal-graph abstraction AF = {hfv , vf i}vV of  over GF is called
F-abstraction, and the set of abstract planning tasks F = {fv }vV is called
F-decomposition of ;
(2) any acyclic causal-graph abstraction AI = {hiv , vi i}vV of  over GI is called
I-abstraction, and the set of abstract planning tasks I = {iv }vV is called
I-decomposition of ;
(3) any acyclic causal-graph abstraction AFI = {hfv , vf i, hiv , vi i}vV of  over
GFI = GF  GI is called FI-abstraction, and the set of abstract planning tasks
FI = {fv , iv }vV is called FI-decomposition of .

Definition 9 can be better understood by considering the FI-abstraction of the problem
 from our Logistics example; Figure 3 schematically illustrates the process. To simplify
the example, here we as if eliminate from GFI all the single-node subgraphs, obtaining
AFI = {hfc1 , cf 1 i, {hfc2 , cf 2 i, {hfc3 , cf 3 i, {hft , tf i, {hip1 , pi 1 i, {hip2 , pi 2 i}.
Considering the action sets of the problems in FI = {fc1 , fc2 , fc3 , ft , ip1 , ip2 }, we see
that each original driving action has one nonredundant (that is, changing some variable)
representative in three of the abstract planning tasks, while each load/unload action has
one nonredundant representative in five of these tasks. For instance, the action drive-c1 from-A-to-D has one nonredundant representative in each of the tasks {fc1 , ip1 , ip2 }, and
the action load-p1 -into-c1 -at-A has one nonredundant representative in each of the tasks
{fc1 , fc2 , fc3 , ft , ip1 }. Since we assume a uniform partition of the action costs, the cost
of each driving and load/unload action in each relevant abstract planning task is thus set
to 1/3 and 1/5, respectively. From Theorem 3 we have AFI being an additive implicit
abstraction of , and from Theorem 1 we then have

X
hFI =
hf + hi ,
(6)
v

v

vV

being an admissible estimate of h in . The question now is how good this estimate is.
The optimal cost of solving our running example is 19. Taking as a reference the well-known
admissible heuristics hmax (Bonet & Geffner, 2001) and h2 (Haslum & Geffner, 2000), we
have hmax (I) = 8 and h2 (I) = 13. Considering our FI-abstraction, the optimal plans for
the tasks in FI are as follows.
64

fiImplicit Abstraction Heuristics

fc1 : load-p1 -into-c2 -at-C, unload-p1 -from-c2 -at-D, load-p1 -into-t-at-D,
unload-p1 -from-t-at-E, load-p1 -into-c3 -at-E, unload-p1 -from-c3 -at-G,
load-p2 -into-c3 -at-F, unload-p2 -from-c3 -at-E.
fc2 : load-p1 -into-c1 -at-C, unload-p1 -from-c1 -at-D, load-p1 -into-t-at-D,
unload-p1 -from-t-at-E, load-p1 -into-c3 -at-E, unload-p1 -from-c3 -at-G,
load-p2 -into-c3 -at-F, unload-p2 -from-c3 -at-E.
fc3 : load-p1 -into-c1 -at-C, unload-p1 -from-c1 -at-D, load-p1 -into-t-at-D,
unload-p1 -from-t-at-E, drive-c3 -from-G-to-E, load-p1 -into-c3 -at-E,
drive-c3 -from-E-to-G, unload-p1 -from-c3 -at-G, drive-c3 -from-G-to-E,
drive-c3 -from-E-to-F, load-p2 -into-c3 -at-F, drive-c3 -from-F-to-E,
unload-p2 -from-c3 -at-E, drive-c3 -from-E-to-F.
ft : load-p1 -into-c1 -at-C, unload-p1 -from-c1 -at-D, drive-t-from-E-to-D,
load-p1 -into-t-at-D, drive-t-from-D-to-E, unload-p1 -from-t-at-E,
load-p1 -into-c3 -at-E, unload-p1 -from-c3 -at-G, load-p2 -into-c3 -at-F,
unload-p2 -from-c3 -at-E.
ip1 : drive-c1 -from-A-to-D, drive-c1 -from-D-to-C, load-p1 -into-c1 -at-C,
drive-c1 -from-C-to-D, unload-p1 -from-c1 -at-D, drive-t-from-E-to-D,
load-p1 -into-t-at-D, drive-t-from-D-to-E, unload-p1 -from-t-at-E,
drive-c3 -from-G-to-E, load-p1 -into-c3 -at-E, drive-c3 -from-E-to-G,
unload-p1 -from-c3 -at-G, drive-c3 -from-G-to-E, drive-c3 -from-E-to-F.
ip2 : drive-c3 -from-G-to-E, drive-c3 -from-E-to-F, load-p2 -into-c3 -at-F,
drive-c3 -from-F-to-E, unload-p2 -from-c3 -at-E, drive-c3 -from-E-to-F.
Hence, we have
hFI = hf

c1

=

8
5

+ hf

+

8
5

+

c2

+

hf
8
5

c3

+

6
3

hf

+
+

8
5

t

+

2
3

+

hi

+

6
5

p1

+

9
3

+

hf

+

2
5

p2

+

4
3

= 15,

(7)

and so hFI appears at least promising.
Unfortunately, despite the seeming simplicity of the planning tasks in FI , it turns out
that implicit fork-decomposition abstractions as in Definitions 9 do not fit the requirements
of implicit abstraction heuristics as in Definition 5. The causal graphs of the planning
tasks in F and I form directed forks and directed inverted forks, respectively, and, in
general, the number of variables in each such planning task can be as large as (|V |).
The problem is that even satisficing planning for sas+ fragments with fork and inverted
fork causal graphs is NP-complete (Domshlak & Dinitz, 2001). In fact, recent results by
Chen and Gimenez (2008) show that planning for any sas+ fragment characterized by any
nontrivial form of causal graph is NP-hard. Moreover, even if the domain transition graphs
of all the state variables are strongly connected (as in our example), optimal planning for
fork and inverted fork structured problems remain NP-hard (see Helmert 2003, and 2004
for the respective results). Next, however, we show that this is not the end of the story for
fork decompositions.
65

fiKatz & Domshlak



B
A
c1

p2

c2

CG()

F
c!

t

D

p!

G

p1

c#

t

E
c3

C

c"

p"

{fv , iv }vV
fc1

c!

p!

c!

p"

c"

c#

t

ip1

p!
if
CG(
CG(p1ip1))

CG(fcfc11))
CG(

Figure 3: Schematic illustration of FI-decomposition for our running Logistics example
While the hardness of optimal planning for problems with fork and inverted fork causal
graphs casts a shadow on the relevance of fork decompositions, a closer look at the proofs of
the corresponding hardness results of Domshlak and Dinitz (2001) and Helmert (2003, 2004)
reveals that they in particular rely on root variables having large domains. Exploiting this
observation, we now show that this reliance is not incidental and characterize two substantial
islands of tractability within the structural fragments of sas+ .
Theorem 4 (Tractable Forks) Given a planning task  = hV, A, I, G, costi with a fork
causal graph rooted at r  V , if |D(r)| = 2, the time complexity of the cost-optimal planning
for  is polynomial in ||||.
Proof: Observe that, for any planning task  as in the theorem, the fork structure of the
causal graph CG() implies that all the actions in  are unary-effect, and each leaf variable
v  succ(r) preconditions only the actions affecting v itself. The algorithm below is based
on the following three properties satisfied by the optimal plans  for .
(i) For any leaf variable v  succ(r), the path v from I[v] to G[v] induced by  in
DTG(v, ) is either cycle-free or contains only zero-cost cycles. This is the case because
otherwise all the nonzero-cost cycles can be eliminated from v while preserving its
validity, violating the assumed optimality of . Without loss of generality, in what
follows we assume that this path v in DTG(v, ) is cycle-free; in the case of fork
causal graphs, we can always select an optimal  that satisfies this requirement for all
v  succ(r). Thus, we have |v |  |D(v)|  1.
(ii) Having fixed a sequence of value changes of r, the forks leaves become mutually
independent; that is, our ability to change the value of one of them does not affect
our ability to change the value of all the others.
66

fiImplicit Abstraction Heuristics

(iii) Because r is binary-valued, if v  V \ {r} is the most demanding leaf variable in
terms of the number of value changes required from r by the action preconditions
along v , then these are the only value changes of r along , except for, possibly, a
final value change to G[r]. Thus, in particular, we have |r |  maxvsucc(r) |D(v)|.
We begin with introducing some auxiliary notations. With |D(r)| = 2, let D(r) = {0, 1}
with I[r] = 0. Let (r) be an alternating 0/1 sequence starting with 0, and having 0 in
all odd and 1 in all even positions. This sequence (r) is such that |(r)| = 1 if no action
in A can change rs value to 1, |(r)| = 2 if some action can change rs value to 1 but no
action can then restore it to value 0, and otherwise, |(r)| = 1 + maxvsucc(r) |D(v)|. Let
[(r)] be the set of all nonempty prefixes of (r) if G[r] is unspecified; otherwise, let it
be the set of all nonempty prefixes of (r) ending with G[r]. Note that, if [(r)] = ,
then the problem is trivially unsolvable; in what follows we assume this is not the case. For
each v  succ(r), let DT G0v and DT G1v be the subgraphs of the domain transition graphs
DTG(v, ), obtained by removing from DTG(v, ) all the arcs labeled with r : 1 and r : 0,
respectively.
The algorithm below incrementally constructs a set R of valid plans for , starting with
R = .
(1) For each v  succ(r), and each pair of vs values x, y  D(v), compute the cheapest
(that is, cost-minimal) paths v0 (x, y) and v1 (x, y) from x to y in DT G0v and DT G1v ,
respectively. For some pairs of values x, y, one or even both these paths may, of course,
not exist.
(2) For each sequence   [(r)], and each v  succ(r), construct a layered digraph Lv ()
with || + 1 node layers L0 , . . . , L|| , where L0 consists of only I[v], and for 1  i  ||,
[i]

Li consists of all nodes y  D(v) for which a path v (x, y) from some node x  Li1
has been constructed in step (1). For each x  Li1 , y  Li , Lv () contains an arc
[i]
(x, y) weighted with cost(v (x, y)).

(3) For each   [(r)], let k = ||. A candidate plan  for  is constructed as follows.

(a) For each v  succ(r), find a cost-minimal path from I[v] to G[v] in Lv (). If no such
path exists, then proceed with the next prefix in [(r)]. Otherwise, note that the
i-th edge on this path (taking us from some x  Li1 to some y  Li ) corresponds
[i]
to the cost-minimal path v (x, y) from x to y. Let us denote this path from x to
y by Svi .

(b) Set R = R{ }, where  = S 1 a[2] S 2 . . .a[k] S k , each sequence S i is obtained
by an arbitrary merge of the sequences {Svi }vsucc(r) , and a is the cheapest action
changing the value of r to value .
(4) If R = , then fail, otherwise return  = argmin R cost( ).
It is straightforward to verify that the complexity of the above procedure is polynomial
in the description size of . To prove correctness, we show that the procedure returns a
plan for any solvable task , and that the returned plan 0 satisfies cost(0 )  cost() for
any optimal plan  for .
67

fiKatz & Domshlak

Given a solvable task , let  be an optimal plan for  with all v for the leaf variables
v being cycle-free. Let r = ha2 . . . , ak i; the numbering of actions along r starts with
a2 to simplify indexing later on. For each v  succ(r), the actions of r divide v into
subsequences of v-changing actions v = 1v  . . .  kv , separated by the value changes
required from r. That is, for each 1  i  k, all actions in iv are preconditioned by the
same value of r, if any, and if two actions a  iv and a0  i+1
are preconditioned by r, then
v
pre(a)[r] 6= pre(a0 )[r]. Let   [(r)] be a value sequence such that || = k = |r | + 1. For
each v  succ(r), v is a path from I[v] to G[v] in Lv (), and therefore some  is added
into R by the algorithm, meaning that the algorithm finds a solution. Now, if   R,
then, for each v  succ(r), let Sv1  Sv2  . . .  Svk be a cost-minimal path from I[v] to G[v] in
Lv () such that Svi is the sequence of actions changing the value of v and preconditioned
either by r : 0 or nothing for odd i, and by r : 1 or nothing for even i. Thus,
cost(Sv1  Sv2  . . .  Svk ) =

k
X
i=1

cost(Svi )  cost(v ).

Because sequence S i is obtained by an arbitrary merge of the sequences {Svi }vsucc(r) , and
a is the cheapest action changing the value of r to , then  = S 1  a[2]  S 2  . . .  a[k]  S k
is an applicable sequence of actions that achieves the goal values for each v  succ(r) as
well as for r, and
cost( ) = cost(S 1  a[2]  S 2  . . .  a[k]  S k ) =

k
X

cost(a[i] ) +

i=2

cost(r ) +

k
X
i=1

X

cost(S i ) 

cost(v ) = cost().

vsucc(r)

Hence, if  is solvable, then the algorithm returns a plan for , and this plan must be
optimal. Finally, if  is not solvable, then R necessarily remains empty, and thus the
algorithm fails.

While Theorem 4 concerns the tractability tasks with fork-structured causal graphs and
roots with binary domains, in our earlier work we also reported an additional tractability
result for fork-structured causal graphs with the domains of all variables being of a fixed
size, though not necessarily binary-valued (Katz & Domshlak, 2008). We do not discuss
this result here in detail because, at least so far, we have not found it very helpful in the
context of devising effective abstraction heuristics.
Theorem 5 (Tractable Inverted Forks) Given a planning task  = hV, A, I, G, costi
with an inverted fork causal graph with sink r  V , if |D(r)| = O(1), the time complexity of
the cost-optimal planning for  is polynomial in ||||.
Proof: Let |D(r)| = d. Observe that the inverted-fork structure of the causal graph CG()
implies all the actions in  are unary-effect, and that the sink r preconditions only the
actions affecting r itself. Hence, in what follows we assume that G[r] is specified; otherwise
68

fiImplicit Abstraction Heuristics

Given a path ha1 , . . . , am i from I[r] to G[r] in DTG(r, ):
 := hi
am+1 := hG[pred(r)], i
foreach v  pred(r) do xv := I[v]
for i := 1 to m + 1 do
foreach v  pred(r) do
if pre(ai )[v] is specified and pre(ai )[v] 6= xv then
if pre(ai )[v] is not reachable from xv in DTG(v, ) then fail
append to  the actions induced by some cost-minimal path
from pre(ai )[v] to xv in DTG(v, )
xv := pre(ai )[v]
if i < m + 1 then append to  the action ai
return 
Figure 4: Detailed outline of step (3) of the planning algorithm for inverted-fork structured
task.

 breaks down to a set of trivial planning problems over a single variable each. Likewise,
from the above properties of  it follows that, if  is an optimal plan for , then the path
r from I[r] to G[r] induced by  in DTG(r, ) is either cycle-free or contains only zerocost cycles. The latter can be safely eliminated from , and thus we can assume that r
is cycle-free. Given that, a simple algorithm that finds a cost-optimal plan for  in time
(||||d + ||||3 ) is as follows.
(1) Create all (|Ar |d1 ) cycle-free paths from I[r] to G[r] in DTG(r, ).
(2) For each variable v  pred(r), and each pair of vs values x, y  D(v), compute the
cost-minimal path from x to y in DTG(v, ). The whole set of such cost-minimal paths
can be computed using (d|V |) applications of the Floyd-Warshall algorithm on the
domain transition graphs of the sinks parents pred(r).
(3) For each I[r]-to-G[r] path in DTG(r, ) generated in step (1), construct a plan for
 based on that path for r, and the cheapest paths computed in (2). This simple
construction, depicted in Figure 4, is possible because the values of each parent variable
can be changed independently of the values of all other variables in the inverted fork.
(4) Take the cheapest plan among those constructed in (3). If no plan was constructed in
step (3), then  is unsolvable.
We have already observed that, for each cost-optimal plan , r is one of the I[r]-to-G[r]
paths generated in step (1). For each v  pred(r), let Sv denote the sequence of values from
D(v) that is required by the preconditions of the actions along r . For each v  pred(r), we
have v corresponding to a (possibly cyclic) path from I[v] to G[v] in DTG(v, ), traversing
the values (= nodes) from Sv in the order required by Sv . In turn, the plan for  generated
in (3) consists of cost-minimal such paths for all v  pred(r). Therefore, at least one of the
69

fiKatz & Domshlak

plans generated in (3) must be cost-optimal for , and the minimization step (4) will select
one of them.

Theorems 4 and 5 clarify the gap between fork decompositions and implicit abstraction
heuristics, and now we can bridge this gap by further abstracting each task in the given fork
decomposition of . We do that by abstracting domains of the fork roots and inverted-fork
sinks to meet the requirements of the tractable fragments. We note that, in itself, the idea
of domain decomposition is not very new in general (Hernadvolgyi & Holte, 1999) and in
domain-independent planning in particular (Domshlak, Hoffmann, & Sabharwal, 2009). In
fact, the shrinking step of the algorithm for building the merge-and-shrink abstractions
is precisely a variable domain abstraction for meta-variables constructed in the merging
steps (Helmert et al., 2007).
Definition 10 Let  = hV, A, I, G, costi be a planning task over states S, v  V be a state
variable, and  = {1 , . . . , m } be a set of mappings from D(v) to some sets 1 , . . . , m ,
respectively. A = {hi , i i}m
i=1 is a domain abstraction of  over  if, for some set of
cost functions {costi : A  R0+ }m
i=1 satisfying
a  A :

m
X
i=1

costi (a)  cost(a),

(8)

we have, for 1  i  m,
 the abstraction mapping i of states S is
u  V :

(
i (s[u]),
i (s)[u] =
s[u],

u=v
,
u 6= v

and, extending i to partial assignments on V 0  V as i (s[V 0 ]) = i (s)[V 0 ],
 i = hV, Ai , Ii , Gi , costi i is a planning task with
1. Ii = i (I), Gi = i (G),
2. Ai = {ai = hi (pre(a)), i (eff(a))i | a  A}, and

3. for each action a  A,

costi (ai ) = costi (a).

(9)

We say that i is a domain decomposition of i = hV, A, I, G, costi i with respect to i .
Theorem 6 Domain abstractions of the planning tasks are additive implicit abstractions
of these tasks.
Proof: Let  = hV, A, I, G, costi be a planning task and A = {hi , i i}m
i=1 be a domain
abstraction of  over  = {1 , . . . , m }. Let T = (S, L, Tr, s0 , S ? , $) be the transition
graph of . For each 1  i  m, let Ti = (Si , Li , Tri , s0i , Si? , $i ) be the transition graph of
i . We need to show that i is an abstraction mapping as in Definition 2.
First, from Definition 10 we have
70

fiImplicit Abstraction Heuristics

 s0i = Ii = i (I) = i (s0 ), and
 for all s  S ? we have s  G and thus i (s)  i (G) = Gi , providing us with
i (s)  Si? .
Now, if s is a state of  and a  A is an action with pre(a)  s, then i (s) is a state of i
and pre(ai ) = i (pre(a))  i (s). Thus, ai is applicable in i (s), and now we show that
applying ai in i (s) results in i (s)Jai K = i (sJaK).
1. For the effect variables v  V(eff(a)) = V(eff(ai )), we have eff(ai )  i (s)Jai K and
eff(ai ) = i (eff(a))  i (sJaK).
2. For all other variables v 6 V(eff(a)), we have sJaK[v] = s[v] and i (s)Jai K[v] =
i (s)[v], and thus
i (s)Jai K[v] = i (s)[v] = i (s[v]) = i (sJaK[v]) = i (sJaK)[v].
Next, for each a  A, from Eqs. 8 and 9 we have
m
X

costi (ai ) =

i=1

m
X
i=1

costi (a)  cost(a).

(10)

Now, let s, s0  S be a pair of states such that cost(s, s0 )  , and let % = ha1 , . . . , al i be the
sequence
of labels along a cheapest path from s to s0 in T. From that, cost(s, s0 ) = cost(%) =
Pl
j
j=1 cost(a ). The decomposition of such a path to the actions as in Definition 10 is a
(not
cheapest) path from i (s) to i (s0 ) in Ti , and thus cost(i (s), i (s0 )) 
Pl neccesarily
j
j=1 costi (a ), providing us with
m
X
i=1

cost(i (s), i (s0 )) 

m X
l
X
i=1 j=1

costi (aji ) =

l X
m
X
j=1 i=1

(10)

costi (aji ) 

l
X

cost(aj ) = cost(s, s0 ).

j=1


Having put the notion of domain abstraction in the framework of implicit abstractions,
we are now ready to connect fork decompositions and implicit abstraction heuristics. Given
a FI-abstraction AFI = {hfv , vf i, hiv , vi i}vV of a planning task  = hV, A, I, G, costi,
 for each fv  FI , we associate the root v of CG(fv ) with mappings fv = {fv,1 , . . . , fv,kv }
such that kv = O(poly(||||)) and all fv,i : D(v)  {0, 1}, and then abstract fv with
f i}kv , and
Afv = {hfv,i , v,i
i=1
 for each iv  FI , we associate the sink v of CG(iv ) with mappings iv = {iv,1 , . . . , iv,kv0 }
such that kv0 = O(poly(||||)) and all iv,i : D(v)  {0, 1, . . . , bv,i }, bv,i = O(1), and
k0

i i} v .
then abstract iv with Aiv = {hiv,i , v,i
i=1

71

fiKatz & Domshlak

From Theorem 3, Theorem 6, and the composition Theorem 2, we then immediately have


kv0
kv
[ [
[
f
i
 {hfv,i , v,i
AFI =
 vf i}  {hiv,i , v,i
 vi i}
(11)
vV

i=1

i=1

being an additive implicit abstraction of . Hence, from Theorem 1,


kv0
kv
X X
X

hFI =
hi 
hf +
vV

v,i

i=1

i=1

v,i

(12)

is an admissible estimate of h for , and, from Theorems 4 and 5, hFI is also computable
in time O(poly(||||)).
This finalizes our construction of a concrete family of implicit abstraction heuristics. To
illustrate the mixture of acyclic causal-graph and domain abstractions as above, we again
use our running Logistics example. One bothersome question is to what extent further
abstracting fork decompositions using domain abstractions affects the informativeness of
the heuristic estimate. Though generally a degradation here is unavoidable, below we show
that the answer to this question can sometimes be somewhat surprising.
To begin with an extreme setting, let all the domain abstractions for roots of forks and
sinks of inverted forks be to binary-valued domains. Among multiple options for choosing the mapping sets {fv } and {iv }, here we use a simple choice of distinguishing between different values of each variable v on the basis of their cost from I[v] in DTG(v, ).
Specifically, for each v  V , we set fv = iv , and, for each value   D(v) and each
1  i  max0 D(v) d(I[v], 0 ),
(
0, d(I[v], ) < i
fv,i () = iv,i () =
(13)
1, otherwise
For example, the problem fc1 is decomposed (see the domain transition graph of c1
on the left in Figure 1c) into two problems, fc1 ,1 and fc1 ,2 , with the binary abstract
domains of c1 corresponding to the partitions {{A}, {B, C, D}} and {{A, D}, {B, C}} of
D(c1 ), respectively. As yet another example, the problem ip1 is decomposed (see the
domain transition graph of p1 in Figure 1d) into six problems ip1 ,1 , . . . , ip1 ,6 along the
abstractions of D(p1 ) depicted in Figure 5a. Now, given the FI-decomposition of  and
mappings {fv , iv }vV as above, consider the problem ip1 ,1 , obtained from abstracting 
along the inverted fork of p1 and then abstracting D(p1 ) using
(
0,   {C}
ip1 ,1 () =
.
1,   {A, B, D, E, F, G, c1 , c2 , c3 , t}
It is not hard to verify that, from the original actions affecting p1 , we are left in ip1 ,1 with
only actions conditioned by c1 and c2 . If so, then no information is lost3 if we remove
from ip1 ,1 both variables c3 and t, as well as the actions changing (only) these variables,
3. No information is lost here because we still keep either fork or inverted fork for each variable of .

72

fiImplicit Abstraction Heuristics

in t

in c

at A

at B

at C

at D

at E

in c

at F

at G

in c

(a)
in t

in c

at A

at B

at C

at D

in t

in c

at E

in c

at F

at G

at A

in c

at B

at C

at D

at E

in c

D(p1 ) in fp1 ,1

in t

in c

at F

at A

at G

at B

at C

at D

at E

in c

in c

D(p1 ) in fp1 ,2

at F

at G

in c

D(p1 ) in fp1 ,3

(b)
Figure 5: Domain abstractions for D(p1 ). (a) Binary-valued domain abstractions: the values inside and outside each dashed contour are mapped to 0 and 1, respectively.
(b) Ternary-valued domain abstractions: values that are mapped to the same
abstract value are shown as nodes with the same color and borderline.

and redistribute the cost of the removed actions between all other representatives of their
originals in . The latter revision of the action cost partition can be obtained directly by
replacing the cost-partitioning steps corresponding to Eqs. 3-4 and 8-9 by a single, joint
action cost partitioning applied over the final additive implicit abstraction AFI as in Eq. 11
and satisfying

kv
X X
cost(a) 

vV



0

X

costfv,i (fv,i (a0 )) +

i=1 a0 A f (a)
G

kv
X

X


costiv,i (iv,i (a0 )) .

(14)

i=1 a0 A i (a)
G
v

v

In what follows, by uniform action cost partition we refer to a partition in which the cost of
each action is equally split among all its nonredundant representatives in the final additive
implicit abstraction.
Overall, computing hFI as in Eq. 12 under our all binary-valued domain abstractions
7
and such a uniform action cost partition provides us with hFI (I) = 12 15
, and knowing that
FI
the original costs are all integers we can safely adjust it to h (I) = 13. Hence, even under
the most severe domain abstractions as above, the estimate of hFI in our example task is
not lower than that of h2 .
Let us now slightly refine our domain abstractions for the sinks of the inverted forks to
be to a ternary range {0, 1, 2}. While mappings {fv } remain unchanged, {iv } are set to
73

fiKatz & Domshlak



0, d(I[v], ) < 2i  1
i
  D(v) : v,i () = 1, d(I[v], ) = 2i  1


2, d(I[v], ) > 2i  1

.

(15)

For example, the problem ip1 is now decomposed into ip1 ,1 , . . . , ip1 ,3 along the abstractions
of D(p1 ) depicted in Figure 5b. Applying now the same computation of hFI as in Eq. 12
over the new set of domain abstractions gives hFI (I) = 15 12 , which, again, can be safely
adjusted to hFI (I) = 16. Note that this value is higher than hFI = 15 obtained using the
(generally intractable) pure fork-decomposition abstractions as in Eq. 6. At first view,
this outcome may seem counterintuitive as the domain abstractions are applied over the fork
decomposition, and one would expect a coarser abstraction to provide less precise estimates.
This, however, is not necessarily the case when the employed action cost partition is ad hoc.
For instance, domain abstraction for the sink of an inverted fork may create independence
between the sink and its parent variables, and exploiting such domain-abstraction specific
independence relations leads to more targeted action cost partition via Eq. 14.
To see why this surprising estimate improvement has been obtained, note that before
the domain abstraction in Eq. 15 is applied on our example, the truck-moving actions
drive-t-from-D-to-E and drive-t-from-E-to-D appear in three abstractions ft , ip1 and ip2 ,
while after domain abstraction they appear in five abstractions ft,1 , ip1 ,1 , ip1 ,2 , ip1 ,3 and
ip2 ,1 . However, a closer look at the action sets of these five abstractions reveals that the
dependencies of p1 in CG(ip1 ,1 ) and CG(ip1 ,3 ), and of p2 in CG(ip2 ,1 ) on t are redundant,
and thus keeping representatives of move-D-E and move-E-D in the corresponding abstract
tasks is entirely unnecessary. Hence, after all, the two truck-moving actions appear only in
two post-domain-abstraction tasks. Moreover, in both these abstractions the truck-moving
actions are fully counted, in contrast to the predomain-abstraction tasks where the portion
of the cost of these actions allocated to ip2 simply gets lost.

6. Experimental Evaluation: Take I
To evaluate the practical attractiveness of the fork-decomposition heuristics, we have conducted an empirical study on a wide sample of planning domains from the International
Planning Competitions (IPC) 1998-2006, plus a non-IPC Schedule-STRIPS domain.4
The domains were selected to allow a comparative evaluation with other, both baseline and
state-of-the-art, approaches/planners, not all of which supported all the PDDL features at
the time of our evaluation.
Later we formally prove that, under ad hoc action cost partitions such as our uniform
partition, none of the three fork decompositions as in Definition 9 is dominated by the
other two. Hence, we have implemented three additive fork-decomposition heuristics, hF ,
hI , and hFI , within the standard heuristic forward search framework of the Fast Downward
planner (Helmert, 2006) using the A algorithm with full duplicate elimination. The hF
heuristic corresponds to the ensemble of all (not clearly redundant) fork subgraphs of the
4. Schedule-STRIPS appears in the domains distribution of IPC-2000. Later we became aware of the
fact that this domain was excluded from the competition because its encoding generated problems for
various planners.

74

fiImplicit Abstraction Heuristics

domain

S

airport-ipc4
blocks-ipc2
depots-ipc3
driverlog-ipc3
freecell-ipc3
grid-ipc1
gripper-ipc1
logistics-ipc1
logistics-ipc2
miconic-strips-ipc2
mprime-ipc1
mystery-ipc1
openstacks-ipc5
pathways-ipc5
pipes-notank-ipc4
pipes-tank-ipc4
psr-small-ipc4
rovers-ipc5
satellite-ipc4
schedule-strips
tpp-ipc5
trucks-ipc5
zenotravel-ipc3

21
30
7
12
5
2
20
6
22
85
24
21
7
4
21
14
50
7
6
43
6
9
11

total

433

hF
s
11
17
2
9
3
1
5
3
21
45
17
16
7
4
9
6
47
5
6
42
5
5
8

%S
52
57
29
75
60
50
25
50
95
53
71
76
100
100
43
43
94
71
100
98
83
56
73
294

hI
s
14
15
2
10
2
1
5
2
15
42
17
15
7
4
11
6
48
6
6
35
5
5
9

%S
67
50
29
83
40
50
25
33
68
49
71
71
100
100
52
43
96
86
100
81
83
56
82
282

hFI
s
11
15
2
9
2
1
5
2
14
40
17
16
7
4
8
6
47
6
5
39
5
5
8

%S
52
50
29
75
40
50
25
33
64
47
71
76
100
100
38
43
94
86
83
91
83
56
73

MS -104

MS -105

s
19
18
7
12
5
2
7
4
16
54
21
17
7
3
20
13
50
6
6
22
6
6
11

s
17
20
4
12
1
2
7
5
21
55
12
13
7
4
12
7
50
7
6
1
6
5
11

274

%S
90
60
100
100
100
100
35
67
73
64
88
81
100
75
95
93
100
86
100
51
100
67
100
332

%S
81
67
57
100
20
100
35
83
95
65
50
62
100
100
57
50
100
100
100
2
100
56
100
285

HSPF

s
15
30
4
9
5
0
6
3
16
45
8
11
7
4
13
7
50
6
5
11
5
9
8

%S
71
100
57
75
100
0
30
50
73
53
33
52
100
100
62
50
100
86
83
26
83
100
73

277

Gamer
s
11
30
4
11
2
2
20
6
20
85
9
8
7
4
11
6
47
5
6
3
5
3
10

%S
52
100
57
92
40
100
100
100
91
100
38
38
100
100
52
43
94
71
100
7
83
33
91
315

blind
s
18
18
4
7
4
1
7
2
10
50
19
18
7
4
14
10
48
5
4
29
5
5
7

%S
86
60
57
58
80
50
35
33
45
59
79
86
100
100
67
71
96
71
67
67
83
56
64
296

hmax
s
20
18
4
8
5
2
7
2
10
50
24
18
7
4
17
10
49
6
5
31
6
7
8

%S
95
60
57
67
100
100
35
33
45
59
100
86
100
100
81
71
98
86
83
72
100
78
73
318

Table 1: A summary of the experimental results. Per domain, S denotes the number of
tasks solved by any planner. Per planner/domain, the number of tasks solved by
that planner is given both by the absolute number (s) and by the percentage from
solved by some planners (%S). The last row summarize the number of solved
instances.

causal graph, with the domains of the roots being abstracted using the leave-one-value-out
binary-valued domain decompositions as follows:
(
0,  = i
i  D(v) : fv,i () =
.
(16)
1, otherwise
The hI heuristic is the same but for the inverted fork subgraphs, with the domains of the
sinks being abstracted using the distance-to-goal-value ternary-valued domain decompositions5 as in Eq. 17.


0, d(, G[v]) < 2i  1
i
  D(v) : v,i () = 1, d(, G[v]) = 2i  1 .
(17)


2, d(, G[v]) > 2i  1
The ensemble of the hFI heuristic is the union of these for hF and hI . The action cost
partition in all three heuristics was what we call uniform.
We make a comparison with two baseline approaches, namely blind A  with heuristic
value 0 for goal states and 1 otherwise, and A with the hmax heuristic (Bonet & Geffner,
2001), as well as with state-of-the-art abstraction heuristics, represented by the mergeand-shrink abstractions of Helmert et al. (2007). The latter were constructed under the
5. While distance-from-initial-value is reasonable for the evaluation of just the initial state, leave-onevalue-out for fork roots and distance-to-goal-value for inverted-fork sinks should typically be much
more attractive for the evaluation of all the states examined by A .

75

fiKatz & Domshlak

linear, f -preserving abstraction strategy proposed by these authors, and this under two
fixed bounds on the size of the abstract state spaces, notably |S  | < 104 and |S  | < 105 .
These four (baseline and merge-and-shrink) heuristics were implemented by Helmert et al.
(2007) within the same planning system as our fork-decomposition heuristics, allowing for
a fairly unbiased comparison. We also compare to the Gamer (Edelkamp & Kissmann,
2009) and HSPF (Haslum, 2008) planners, the winner and the runner-up at the sequential
optimization track of IPC-2008. On the algorithmic side, Gamer is based on a bidirectional
blind search using sophisticated symbolic-search techniques, and HSPF uses A with an
additive critical-path heuristic. The experiments were conducted on a 3GHz Intel E8400
CPU with 2 GB memory, using 1.5 GB memory limit and 30 minute timeout. The only
exception was Gamer, for which we used similar machines but with 4 GB memory and 2
GB memory limit; this was done to provide Gamer with the environment for which it was
configured.
Table 1 summarizes our experimental results in terms of the number of tasks solved by
each planner. Our impression of fork-decomposition heuristics from Table 1 is somewhat
mixed. On the one hand, the performance of all three fork-decomposition based planners
was comparable to one of the settings of the merge-and-shrink heuristic, and this clearly
testifies for that the framework of implicit abstractions is not of theoretical interest only.
On the other hand, all the planners, except for A with the merge-and-shrink heuristic with
|S  | < 104 , failed to outperform A with the baseline hmax heuristic. More important for
us is that, unfortunately, all three fork-decomposition based planners failed to outperform
even the basic blind search.
This, however, is not the end of the story for the fork-decomposition heuristics. Some
hope can be found in the detailed results in Tables 9-14 in the appendix. As it appears from
Table 10, on, e.g., the Logistics-ipc2 domain, hF almost consistently leads to expanding
fewer search nodes than the (better between the two merge-and-shrink heuristics on this
domain) MS -105 , with the difference hitting four orders of magnitude. However, the time
complexity of hF per search node is substantially higher than that of MS -105 , with the
two expanding at a rate of approximately 40 and 100000 nodes per second, respectively.
The outcome is simple: while with no time limits (and only memory limit of 1.5 GB) hF
solves more tasks in Logistics-ipc2 than MS -105 (task 12-1 is solved with hF in 2519.01
seconds), this is not so with a standard time limit of half an hour used for Table 10. In what
follows we examine the possibility of exploiting the informativeness of fork-decomposition
heuristics while not falling into the trap of costly per-node heuristic evaluation.

7. Back to Theory: h-Partitions and Databased Implicit Abstraction
Accuracy and low time complexity are both desired yet competing properties of heuristic
functions. For many powerful heuristics, and abstraction heuristics in particular, computing
h(s) for each state s in isolation is impractical: while computing h(s) is polynomial in the
description size of , it is often not efficient enough to be performed at each search node.
However, for some costly heuristics this obstacle can be largely overcome by sharing most
of the computation between the evaluations of h on different states. If that is possible,
the shared parts of computing h for all problem states are precomputed and memorized
before the search, and then reused during the search by the evaluations of h on different
76

fiImplicit Abstraction Heuristics

states. Such a mixed offline/online heuristic computation is henceforth called h-partition,
and we define the time complexity of an h-partition as the complexity of computing h
for a set of states. Given a subset of k problem states S 0  S, the h-partitions time
complexity of computing {h(s) | s  S 0 } is expressed as O(X + kY ), where O(X) and O(Y )
are, respectively, the complexity of the (offline) pre-search and (online) per-node parts of
computing h(s).
These days h-partitions are being adopted by various optimal planners using criticalpath heuristics hm for m > 1 (Haslum et al., 2005), landmark heuristics hL and hLA (Karpas
& Domshlak, 2009), and PDB and merge-and-shrink abstraction heuristics (Edelkamp,
2001; Helmert et al., 2007). Without effective h-partitions, optimal search with these
heuristics would not scale up well, while with such h-partitions it constitutes the state of the
art of cost-optimal planning. For instance, a very attractive property of PDB abstractions
is the complexity of their natural h -partition. Instead of computing h (s) = h ((s)) from
scratch for each evaluated state s (impractical for all but tiny projections), the practice is
to precompute and store h (s0 ) for all abstract states s0  S , after which the per-node
computation of h (s) boils down to a hash-table lookup for h ((s)) with a perfect hash
function. In our terms, the time and space complexity of that PDB h -partition for a set
of k states is O(|S  |(log(|S  |) + |A|) + k) and O(|S  |), respectively. This is precisely what
makes PDB heuristics so attractive in practice. In that respect, the picture with mergeand-shrink abstractions is very much similar. While the order in which composites are
formed and the choice of abstract states to contract are crucial to the complexity of their
natural h -partitions, the time and space complexity for the concrete linear abstraction
strategy of Helmert et al. are respectively O(|V ||S  |(log(|S  |) + |A|) + k  |V |) and O(|S  |).
Similarly to PDB abstractions, the per-node computation of h (s) with a merge-and-shrink
abstraction  is just a lookup in a data structure storing h ((s)) for all abstract states
(s)  S . Hence, while the pre-search computation with MS abstractions can be more
costly than with PDBs, the online part of computing heuristic values is still extremely
efficient. This per-node efficiency provides the merge-and-shrink heuristics with impressive
practical effectiveness on numerous IPC domains (Helmert et al., 2007).
To sum up, we can say that the fixed size of abstract spaces induced by explicit abstractions such as PDBs and merge-and-shrink is not only a limitation but also a key to obtaining
effective h-partitions. In contrast, escaping that limitation with implicit abstractions might
trap us into having to pay a high price for each search-node evaluation. We now show, however, that the time-per-node complexity bottleneck of fork-decomposition heuristics can
be successfully overcome. Specifically, we show that an equivalent of PDBs and mergeand-shrink notion of database exists for fork-decomposition abstractions as well, despite
their exponential-size abstract spaces. Of course, unlike with PDB and merge-and-shrink
abstractions, the databased fork-decomposition heuristics do not (and cannot) provide us
with a purely lookup online computation of h (s). The online part of the h -partition has
to be nontrivial in the sense that its complexity cannot be O(1). In what comes next we
prove the existence of such effective h-partitions for fork and inverted fork abstractions.
In Section 8 we then empirically show that these h-partitions lead to fast pre-search and
per-node computations, allowing the informativeness of the fork-decomposition heuristics
to be successfully exploited in practice.

77

fiKatz & Domshlak

Theorem 7 Let  = hV, A, I, G, costi be a planning task with a fork causal graph rooted at a
binary-valued variable r. There exists an h -partition for  such that, for any set of k states,
the time and space complexity of that h -partition is, respectively, O(d3 |V | + |Ar | + kd|V |)
and O(d2 |V |), where d = maxv D(v).
Proof: The proof is by a modification of the polynomial-time algorithm for computing
h (s) for a state s of such a task  used in the proof of Theorem 4 (Tractable Forks). Given
a state s, let D(r) = {0, 1}, where s[r] = 0. In what follows, for each of the two roots
values   D(r),  denotes the opposite value 1  ; (r), [(r)], DTG 0v and DTG 1v are
defined exactly as in the proof of Theorem 4.
(1) For each of the two values r  D(r) of the root variable, each leaf variable v  V \ {r},
and each pair of values , 0  D(v), let p,0 ;r be the cost of the cheapest sequence of
actions changing v from  to 0 provided r : r . The whole set {p,0 ;r } for all the leaves
v  V \{r} can be computed by a straightforward variant of the all-pairs-shortest-paths,
Floyd-Warshall algorithm on DTG v r in time O(d3 |V |).
(2) For each leaf variable v  V \ {r}, 1  i  d + 1, and   D(v), let g;i be the cost of
the cheapest sequence of actions changing s[v] to  provided a sequence   [(r)],
|| = i, of value changes of r. Having the values {p,0 ;r } from step (1), the set {g;i }
is given by the solution of the recursive equation


ps[v],;s[r] ,
i=1






min g0 ;i1 + p0 ,;s[r] ,
1 < i   , i is odd
0 

g;i =
,

0 ;i1 + p0 ,;s[r] ,
min
g
1
<
i


,
i
is
even



 0


g
 < i  d + 1
;i1 ,
where  = |D(v)| + 1. Given that, we have

h (s) =

min

 cost() +

[(r)]


X

gG[v];||  ,

vV \{r}

P||
with cost() = i=2 cost(a[i] ), where a[i]  A is the cheapest action changing the
value of r from [i  1] to [i].
Note that step (1) is already state-independent, but the heavy step (2) is not. However,
the state dependence of step (2) can mostly be overcome as follows. For each v  V \ {r},
  D(v), 1  i  d + 1, and r  D(r), let g;i (r ) be the cost of the cheapest sequence of
actions changing  to G[v] provided the value changes of r induce a 0/1 sequence of length
i starting with r . The set {g;i (r )} is given by the solution of the recursive equation


,
i=1

p,G[v];
 r

g0 ;i1 (r ) + p,0 ;r , 1 < i  
,
g;i (r ) = min
0


g
 < i  d + 1
;i1 (r ),
78

(18)

fiImplicit Abstraction Heuristics

24

0

1

r ||

24

0
1

1
1

1

0
100

1
0

1 1
1
50

1

2

3
0
100

3
0

0

1

0
100

0

0

2

1

1 1
1
50

1

5
0

1

1

4

1
2
3
4
5
6
7
1
2
3
4
5
6
7

cost()

v :0

v :1 v :2 v :3

u:0

u:1 u:2 u:3 u:4 u:5

0
24
48
72
96
120
144
0
24
48
72
96
120
144

100
100
100
100
3
3
3

100
3
3
3
3
3


2
2
2
2
2
2


2
2
2
2
2

201
201
53
53
5
5
5

101
101
53
53
5
5

200 101 100
200 101 100
102 3
2
102 3
2
4
3
2
4
3
2
4
3
2
  
52 51
2
52 51
2
4
3
2
4
3
2
4
3
2
4
3
2


1
1
1
1
1
1
1
1
1
1
1
1
1

0
0
0
0
0
0
0
0
0
0
0
0
0
0

(a)

1
1
1
1
1
1
1

1
1
1
1
1
1

0
0
0
0
0
0
0
0
0
0
0
0
0
0

(b)

Figure 6: The database for a fork-structured problem with a binary-valued root variable r
and two children v and u, and G[r] = 0, G[v] = 3, and G[u] = 5. (a) depicts the
domain transition graphs of r (top), v (middle), and u (bottom); the numbers
above and below each edge are the precondition on r and the cost of the respective
action. (b) depicts the database created by the algorithm. For instance, the entry
in row r : 0  || = 5 and column v : 0 captures the value of gv:0;5 (r : 0) computed as
in Eq. 18. The shaded entries are those examined during the online computation
of h (r : 0, v : 0, u : 0).
which can be solved in time O(d3 |V |). Note that this equation is now independent of the
evaluated state s, and yet {g;i (r )} allow for computing h (s) for a given state s via

h (s) =

min



 cost() +

[(r|s[r])]

X

gs[v];|| (s[r]) 

(19)

vV \{r}

where (r|r ) is defined similarly to (r) but with respect to the initial value r of r.
With the new formulation, the only computation that has to be performed online, per
search node, is the final minimization over [(r|s[r])] in Eq. 19, and this is the lightest
part of the whole algorithm anyway. The major computations, notably those of {p,0 ;r }
and {g;i (r )}, can now be performed offline and shared between the evaluated states. The
space required to store this information is O(d2 |V |) as it contains only a fixed amount of
information per pair of values of each variable. The time complexity of the offline computation is O(d3 |V | + |Ar |); the |Ar | component stems from precomputing the costs cost().
The time complexity of the online computation per state is O(d|V |); |V | comes from the
internal summation and d comes from the size of [(r|s[r])].

Figure 6b shows the database created for a fork-structured problem with a binary-valued
root r, two children v and u, and G[r] = 0, G[v] = 3, and G[u] = 5; the domain transition
79

fiKatz & Domshlak

graphs of v and u are depicted in Figure 6(a). Online computation of h (s) as in Eq. 19
for s = (r : 0, v : 0, u : 0) sums over the shaded entries of each of the four rows having such
entries, and minimizes over the resulting four sums, with the minimum being obtained in
the row r : 0  || = 5.
Theorem 8 Let  = hV, A, I, G, costi be a planning task with an inverted fork causal graph
with sink r and |D(r)| = b = O(1). There exists an h -partition for  such that, for any set
of k states, the time and space complexity of that h -partition is O(b|V ||Ar |b1 + d3 |V | +
k|V ||Ar |b1 ) and O(|V ||Ar |b1 + d2 |V |), respectively, where d = maxv D(v).
Proof: Like the proof of Theorem 7, the proof of Theorem 8 is based on a modification
of the polynomial-time algorithm for computing h (s) used for the proof of Theorem 5
(Tractable Inverted Forks).
(1) For each parent variable v  V \ {r}, and each pair of its values , 0  D(v), let p,0
be the cost of the cheapest sequence of actions changing  to 0 . The whole set {p,0 }
can be computed using the Floyd-Warshall algorithm on the domain transition graph
of v in time O(d3 |V |).
(2) Given a state s, for each cycle-free path  = ha1 , . . . , am i from s[r] to G[r] in DTG(v, ),
let g be the cost of the cheapest plan from s in  based on , and the cheapest paths
{p,0 } computed in step (1). Each g can be computed as
g =

m
X
i=1

cost(ai ) +

m
X
X

pprei [v],prei+1 [v] ,

i=0 vV \{r}

where pre0 , . . . , prem+1 are the values required from the parents of r along the path .
That is, for each v  V \ {r}, and 0  i  m + 1,


s[v],
i=0



G[v],
i = m + 1, and G[v] is specified
prei [v] =
.

pre(a
)[v],
1

i

m,
and
pre(a
)[v]
is
specified
i
i



pre [v]
otherwise
i1
From that, we have h (s) = min g .
Note that step (1) is state-independent, but step (2) is not. However, the dependence
of step (2) on the evaluated state can be substantially relaxed. As there are only O(1)
different values of r, it is possible to consider cycle-free paths to G[r] from all values of r.
For each such path , and each parent variable v  V \ {r}, we know what the first value of
v required by  would be. Given that, we can precompute the cost-optimal plans induced
by each  assuming the parents start at their first required values. The remainder of the
computation of h (s) is delegated to online, and the modified step (2) is as follows.
For each r  D(r) and each cycle-free path  = ha1 , . . . , am i from r to G[r] in
DTG(r, ), let a proxy state s be


v=r
r ,
s [v] = G[v],
1  i  m : pre(ai )[v] is unspecified ,


pre(ai )[v], i = argminj {pre(aj )[v] is specified}
80

fiImplicit Abstraction Heuristics

that is, the nontrivial part of s captures the first values of V \ {r} required along .6 Given
that, let g be the cost of the cheapest plan from s in  based on , and the cheapest
paths {p,0 } computed in (1). Each g can be computed as
g =

m
X





cost(ai ) +

i=1

X

pprei [v],prei+1 [v]  ,

vV \{r}

where, for each v  V \ {r}, and 1  i  m + 1,


s [v],
i=1



G[v],
i = m + 1, and G[v] is specified
prei [v] =
.

pre(ai )[v], 2  i  m, and pre(ai )[v] is specified



pre [v], otherwise
i1
Storing the pairs (g , s ) accomplishes the offline part of the computation. Now, given a
search state s, we can compute

h (s) =

min

 s.t.
s [r]=s[r]



g +

X

ps[v],s [v] .

(20)

vV \{r}

The number of cycle-free paths to G[r] in DTG(r, ) is (|Ar |b1 ), and g for each
such path  can be computed in time O(b|V |). Hence, the overall offline time complexity is
O(b|V ||Ar |b1 + d3 |V |), and the space complexity (including the storage of the proxy states
s ) is O(|V ||Ar |b1 + d2 |V |). The time complexity of the online computation per state via
Eq. 20 is O(|V ||Ar |b1 ); |V | comes from the internal summation and |Ar |b1 from the upper
bound on the number of cycle-free paths from s[r] to G[r].

Figure 7(b) shows the database created for an inverted fork structured problem with a
ternary-valued sink variable r, two parents u and v, and G[r] = 2, G[u] = 0, and G[v] = 2.
The domain transition graphs of u and v are depicted at the top of Figure 7(a); the actual
identities of actions affecting these two parents are not important here. The actions affecting
the sink r are
a1 = h{u : 1, r : 0}, {r : 1}i
a2 = h{v : 1, r : 0}, {r : 1}i

a3 = h{u : 2, r : 1}, {r : 2}i

a4 = h{v : 1, r : 1}, {r : 2}i.
The domain transition graph of r is depicted at the bottom of Figure 7(a). Online computation of h (s) as in Eq. 20 for s = (r : 0, v : 0, u : 0) sums over the shaded entries of each
of the four rows having such entries, and minimizes over the resulting four sums, with the
minimum being obtained in the lowest such row.
81

fiKatz & Domshlak

0

2

50

0

50

50

2

1
1

1

100

1

u:2

u:1

1

1

0

1

2

v:1

v:1

50

100

r



ha1 , a3 i
0 ha1 , a4 i
ha2 , a3 i
ha2  a4 i
ha3 i
1
ha4 i

(a)

s

g

u:0

u:1 u:2

v :0

u : 1, v : 2
u : 1, v : 1
u : 2, v : 1
u : 0, v : 1
u : 2, v : 2
u : 0, v : 1

202
153
153
152
101
102

100
100
50
0
50
0

0
50
0
50
100 0
50 100
100 0
50 100

1
101
101
101
1
101

v :1 v :2
2
0
0
0
2
0

0
100
100
100
0
100

(b)

Figure 7: The database for an inverted fork-structured problem with a O(1) bounded sink
variable r and two parents u and v, and G[r] = 2, G[u] = 0, and G[v] = 2.
(a) depicts the domain transition graphs of u (top left), v (top right), and r
(bottom); the numbers above and below each edge are the preconditions and the
cost of the respective action, respectively. (b) depicts the database created by the
algorithm. The shaded entries are those examined during the online computation
of h (r : 0, u : 0, v : 0).

8. Experimental Evaluation: Take II
To evaluate the practical attractiveness of the databased fork-decomposition heuristics, we
have repeated our empirical evaluation as in Section 6, but now for the databased versions
of the heuristics. The detailed results of this evaluation are relegated to Tables 15-20 in
the appendix, but they are summarized here in Table 2. For each domain, the S column
captures the number of tasks in that domain that were solved by at least one planner
in the suite. Per planner/domain, the number of tasks solved by that planner is given
both by the absolute number (s) and by the percentage from solved by some planners
(%S). Boldfaced results indicate the best performance within the corresponding domain.
The last three rows summarize the performance of the planners via three measures. The
first is the number of tasks solved in all the 23 domains; this is basically the performance
evaluation measure used in the optimization track at IPC-2008. As domains are not equally
challenging and do not equally discriminate between the planners performance, the second
is a domain-normalized performance measure
s(p) =

X
domain D

#tasks in D solved by planner p
.
#tasks in D solved by some planners

Finally, the third measure corresponds to the number of domains w in which the planner
in question solved at least as many tasks as any other planner.
Overall, Table 2 clearly suggests that heuristic search with databased fork-decomposition
heuristics favorably competes with the state of the art of optimal planning. In particular,
6. For ease of presentation, we omit here the case where v is required neither along , nor by the goal; such
variables should be simply ignored when accounting for the cost of .

82

fiImplicit Abstraction Heuristics

domain

S

airport-ipc4
blocks-ipc2
depots-ipc3
driverlog-ipc3
freecell-ipc3
grid-ipc1
gripper-ipc1
logistics-ipc2
logistics-ipc1
miconic-strips-ipc2
mprime-ipc1
mystery-ipc1
openstacks-ipc5
pathways-ipc5
pipes-notank-ipc4
pipes-tank-ipc4
psr-small-ipc4
rovers-ipc5
satellite-ipc4
schedule-strips
tpp-ipc5
trucks-ipc5
zenotravel-ipc3

22
30
7
12
5
2
20
22
7
85
24
21
7
4
21
14
50
7
6
46
6
9
11

total
s
w

438

hF
s
22
21
7
12
5
2
7
22
6
51
23
21
7
4
17
11
49
6
6
46
6
6
11

%S
100
70
100
100
100
100
35
100
86
60
96
100
100
100
81
79
98
86
100
100
100
67
100

368
20.56
14

hI
s
20
18
4
12
4
1
7
16
4
50
22
18
7
4
15
9
49
7
6
40
6
7
11

%S
91
60
57
100
80
50
35
73
57
59
92
86
100
100
71
64
98
100
100
87
100
78
100

337
18.38
7

hFI
s
21
18
7
12
4
1
7
16
5
50
21
21
7
4
16
9
49
6
6
46
6
7
11

%S
95
60
100
100
80
50
35
73
71
59
88
100
100
100
76
64
98
86
100
100
100
78
100

350
19.13
9

MS -104

MS -105

s
19
18
7
12
5
2
7
16
4
54
21
17
7
3
20
13
50
6
6
22
6
6
11

s
17
20
4
12
1
2
7
21
5
55
12
13
7
4
12
7
50
7
6
1
6
5
11

%S
86
60
100
100
100
100
35
73
57
64
88
81
100
75
95
93
100
86
100
48
100
67
100

332
19.07
11

%S
77
67
57
100
20
100
35
95
71
65
50
62
100
100
57
50
100
100
100
2
100
56
100

285
16.64
9

HSPF

s
15
30
4
9
5
0
6
16
3
45
8
11
7
4
13
7
50
6
5
11
5
9
8

%S
68
100
57
75
100
0
30
73
43
53
33
52
100
100
62
50
100
86
83
24
83
100
73

277
15.45
6

Gamer
s
11
30
4
11
2
2
20
20
6
85
9
8
7
4
11
6
47
5
6
3
5
3
10

%S
50
100
57
92
40
100
100
91
86
100
38
38
100
100
52
43
94
71
100
7
83
33
91

315
16.66
8

blind
s
18
18
4
7
4
1
7
10
2
50
19
18
7
4
14
10
48
5
4
29
5
5
7

%S
82
60
57
58
80
50
35
45
29
59
79
86
100
100
67
71
96
71
67
63
83
56
64

296
15.58
2

hmax
s
20
18
4
8
5
2
7
10
2
50
24
18
7
4
17
10
49
6
5
31
6
7
8

%S
91
60
57
67
100
100
35
45
29
59
100
86
100
100
81
71
98
86
83
67
100
78
73

318
17.66
6

Table 2: A summary of the experimental results with databased versions of the forkdecomposition heuristics. Per domain, S denotes the number of tasks solved by
any planner. Per planner/domain, the number of tasks solved by that planner
is given both by the absolute number (s) and by the percentage from solved by
some planners (%S). Boldfaced results indicate the best performance within the
corresponding domain. The last three rows summarize the number of solved instances, the domain-normalized measure of solved instances (s), and the number
of domains in which the planners achieved superior performance (w).

A with the only forks heuristic hF exhibited the best overall performance according to
all three measures. In terms of the absolute number of solved instances, A with all three
fork-decomposition heuristics outperformed all other planners in the suite. The contribution
of databasing to the success of the fork-decomposition heuristics was dramatic. Looking
back at the results with fully online heuristic computation depicted in Table 1, note that
the total number of solved instances for the fork-decomposition heuristics hF , hI , and hFI
increased by 74, 55, and 76, respectively, and this made the whole difference.
We have also performed a comparative evaluation on the planning domains from the
recent IPC-2008. The IPC-2008 domains differ from the previous domains in that actions
had various costs, and, more importantly, many actions had zero cost. The latter is an
issue for heuristic-search planners because heuristic functions cannot differentiate between
subplans that have the same cost of zero, but differ in length. In any case, the comparative
side of our evaluation on the IPC-2008 domains differ on several points from the previous
one. First, neither for merge-and-shrink nor for hmax heuristics, we had implementation
supporting arbitrary action costs. Hence, our comparison here is only with Gamer, HSPF ,
and blind search. Second, to ensure admissibility of the blind search, the latter has been
modified to return on non-goal states the cost of the cheapest applicable action. Finally, all
the planners were run on a 3GHz Intel E8400 CPU with 4 GB memory, using 2 GB memory
83

fiKatz & Domshlak

domain

S

elevators-strips-ipc6
openstacks-strips-ipc6
parcprinter-strips-ipc6
pegsol-strips-ipc6
scanalyzer-strips-ipc6
sokoban-strips-ipc6
transport-strips-ipc6
woodworking-strips-ipc6

22
21
16
27
12
28
11
14

total
s
w

152

hF
s
18
19
14
27
12
25
11
8

%S
82
90
88
100
100
89
100
57

134
7.06
3

hI
s
14
19
13
27
6
26
11
8

%S
64
90
81
100
50
93
100
57

124
6.35
2

hFI
s
15
19
13
27
6
27
11
8

%S
68
90
81
100
50
96
100
57

126
6.43
3

HSPF

s
7
21
16
27
6
13
9
9

%S
32
100
100
100
50
46
82
64

108
5.74
3

Gamer
s
22
19
9
24
11
20
11
14

%S
100
90
56
89
92
71
100
100

130
6.99
3

blind
s
11
19
10
27
12
20
11
7

%S
50
90
63
100
100
71
100
50

117
6.24
3

Table 3: A summary of the experimental results. Per domain, S denotes the number of
tasks solved by any planner. Per planner/domain, the number of tasks solved by
that planner is given both by the absolute number (s) and by the percentage from
solved by some planners (%S). Boldfaced results indicate the best performance
within the corresponding domain. The last three rows summarize the number of
solved instances, the domain-normalized measure of solved instances (s), and the
number of domains in which the planners achieved superior performance (w).

limit and 30 minute timeout. The results of this evaluation are summarized in Table 3; for
the detailed results we refer the reader to Tables 21-22 in the appendix. Overall, these
results show that A with the fork-decomposition heuristics are very much competitive on
the IPC-2008 domains as well.

9. Formal Analysis: Asymptotic Performance Ratios
Empirical evaluation on a concrete set of benchmark tasks is a standard and important
methodology for assessing the effectiveness of heuristic estimates: it allows us to study the
tradeoff between the accuracy of the heuristics and the complexity of computing them.
However, as rightfully noted by Helmert and Mattmuller (2008), such evaluations almost
never lead to absolute statements of the type Heuristic h is well-suited for solving problems from benchmark suite X, but only to relative statements of the type Heuristic h
expands fewer nodes than heuristic h0 on benchmark suite X. Moreover, one would probably like to obtain formal evidence of the effectiveness of a heuristic before proceeding with
its implementation, especially for very complicated heuristic procedures such as those underlying the proofs of Theorems 7 and 8. Our formal analysis of the effectiveness of the
fork-decomposition heuristics using the methodology suggested and exploited by Helmert
and Mattmuller was motivated primarily by this desire for formal evidence.
Given a planning domain D and heuristic h, Helmert and Mattmuller (2008) consider
the asymptotic performance ratio of h in D. The goal is to find a value (h, D)  [0, 1] such
that
(1) for all states s in all problems   D, h(s)  (h, D)  h (s) + o(h (s)), and
(2) there is a family of problems {n }nN  D and solvable, non-goal states {sn }nN such
that sn  n , limn h (sn ) = , and h(sn )  (h, D)  h (sn ) + o(h (sn )).
84

fiImplicit Abstraction Heuristics

Domain

h+

hk

hPDB

hPDB
add

hF

hI

hFI

Gripper
Logistics
Blocksworld
Miconic-Strips
Satellite

2/3
3/4
1/4
6/7
1/2

0
0
0
0
0

0
0
0
0
0

2/3
1/2
0
1/2
1/6

2/3
1/2
0
5/6
1/6

0
1/2
0
1/2
1/6

4/9
1/2
0
1/2
1/6

Table 4: Performance ratios of multiple heuristics in selected planning domains; ratios for
h+ , hk , hPDB , hPDB
add are by Helmert and Mattmuller (2008).

In other words, h is never worse than (, domain, )h (plus a sublinear term), and it can
become as bad as (h, D)  h (plus a sublinear term) for arbitrarily large inputs; note that
both the existence and uniqueness of (h, D) are guaranteed for any h and D.
Helmert and Mattmuller (2008) study the asymptotic performance ratio of some standard admissible heuristics on a set of well-known benchmark domains from the first four
IPCs. Their results for Gripper, Logistics, Blocksworld, Miconic, and Satellite
are shown in the first four columns of Table 4.
 The h+ estimate corresponds to the optimal cost of solving the well-known delete
relaxation of the original planning task, which is generally NP-hard to compute (Bylander, 1994).
 The hk , k  N+ , family of heuristics is based on a relaxation where the cost of
achieving a partial assignment is approximated by the highest cost of achieving its
sub-assignment of size k (Haslum & Geffner, 2000); computing hk is exponential only
in k.
 The hPDB and hPDB
add heuristics are regular (maximized over) and additive pattern
database heuristics where the size of each pattern is assumed to be O(log(n)) where
n = |V |, and, importantly, the choice of the patterns is assumed to be optimal.
These results provide us with a baseline for evaluating our fork-decomposition heuristics
hI , and hFI . First, however, Theorem 9 shows that these three heuristics are worth
analyzing because each alone can be strictly more informative than the other two, depending
on the planning task and/or the state being evaluated.7
hF ,

Theorem 9 (Undominance) Under uniform action cost partition, none of the heuristic
functions hF , hI , and hFI dominates another.
Proof: The proof is by example of two tasks, 1 and 2 , which illustrate the following
two cases: hF (I) > hFI (I) > hI (I) and hF (I) < hFI (I) < hI (I). These two tasks
are defined over the same set of binary-valued variables V = {v1 , v2 , v3 , u1 , u2 , u3 }, have
the same initial state I = {v1 : 0, v2 : 0, v3 : 0, u1 : 0, u2 : 0, u3 : 0}, and have the same goal
7. Theorem 9 is formulated and proven under the uniform action cost partition that we use throughout the
paper, including the experiments. For per-step optimal action cost partitions (Katz & Domshlak, 2010),
it is trivial to show that hFI dominates both hF and hI for all planning tasks.

85

fiKatz & Domshlak

A1

u1

u2

u3

v1

v2

v3

a1
a2
a3
a4
a5
a6
a7
a8
a9

h{v1 : 0, u1 : 0, u2 : 0, u3 : 0}, {v1 : 1}i
h{v2 : 0, u1 : 1, u2 : 0, u3 : 1}, {v2 : 1}i
h{v3 : 0, u1 : 1, u2 : 1, u3 : 0}, {v3 1}i
h{u1 : 0}, {u1 : 1}i
h{u1 : 1}, {u1 : 0}i
h{u2 : 0}, {u2 : 1}i
h{u2 : 1}, {u2 : 0}i
h{u3 : 0}, {u3 : 1}i
h{u3 : 1}, {u3 : 0}i

(a)

1
F

1
I

1
FI

1/3
1/3
1/3
1
1
1
1
1
1

1
1
1
1/3
1/3
1/3
1/3
1/3
1/3

1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4

(c)

u1

u2

u3

v1 v2 v3

v1 v2 v3

v1 v2 v3

Guf 1

Guf 2

Guf 3

u1 u2 u3

u1 u2 u3

u1 u2 u3

v1

v2

v3

Gvi 1

Gvi 2

Gvi 3

A2
a1
a2
a3
a4
a5
a6
a7
a8
a9
a10
a11
a12

(b)

h{v1 : 0, u1 : 1}, {v1 : 1}i
h{v1 : 0, u2 : 1}, {v1 : 1}i
h{v1 : 0, u3 : 1}, {v1 : 1}i
h{v2 : 0, u1 : 1}, {v2 : 1}i
h{v2 : 0, u2 : 1}, {v2 : 1}i
h{v2 : 0, u3 : 1}, {v2 : 1}i
h{v3 : 0, u1 : 1}, {v3 : 1}i
h{v3 : 0, u2 : 1}, {v3 : 1}i
h{v3 : 0, u3 : 1}, {v3 : 1}i
h{u1 : 0}, {u1 : 1}i
h{u2 : 0}, {u2 : 1}i
h{u3 : 0}, {u3 : 1}i

2
F

2
I

2
FI

1/3
1/3
1/3
1/3
1/3
1/3
1/3
1/3
1/3
1
1
1

1
1
1
1
1
1
1
1
1
1/3
1/3
1/3

1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4

(d)

Figure 8: Illustrations for the proof of Theorem 9: (a) causal graphs of 1 and 2 , (b) fork
and inverted fork subgraphs of the (same) causal graph of 1 and 2 , and the
action sets of (c) 1 and (d) 2 , as well as the costs of the action representatives
in each abstract problem along these subgraphs. Considering for example the
first row of table (c), the action a1 in 1 has a single representative in each of the
three fork abstractions, as well as a representative in the inverted-fork abstraction
1G i . Hence, the cost of each of its representatives in F-decomposition is 1/3,
v1

while the cost of its sole representative in I-decomposition is 1.

G = {v1 : 1, v2 : 1, v3 : 1}. The difference between 1 and 2 is in the action sets, listed in
Figure 8c-d, with all the actions being unit-cost actions. The two tasks induce identical
causal graphs, depicted in Figure 8a. Hence, the collections of v-forks and v-iforks of both
tasks are also identical; these are depicted in Figure 8b. The fractional costs of the tasks
action representatives in the corresponding abstract problems are given in Figure 8c-d.
Figure 9 shows the optimal plans for all the abstract problems in F-decompositions 1F =
{1G f , 1G f , 1G f } and 2F = {2G f , 2G f , 2G f }, I-decompositions 1I = {1G i , 1G i , 1G i }
u1

u2

u3

u1

u2

u3

v1

v2

v3

and 2I = {2G i , 2G i , 2G i }, and FI-decompositions 1FI = 1F  1I and 2FI = 2F  2I .
v1

v2

v3

The last column in both tables captures the estimates of the three heuristics for the initial
states of 1 and 2 , respectively. Together, these two cases show that none of the forkdecomposition heuristic functions hF , hI , and hFI dominates any other, and, since all the
86

fiImplicit Abstraction Heuristics

h
hF

hI

h

FI

task
1G f
u1
1G f
u2
1G f
u3
1G i
v1
1G i
v2
1G i
v3
1G f
u1
1G f
u2
1G f
u3
1G i
v1
1G i
v2
1G i
v

optimal plan

cost

ha1 , a4 , a2 , a3 i

2

ha1 , a2 , a6 , a3 i

2

ha1 , a3 , a8 , a2 i

2

ha1 i

1

ha4 , a8 , a2 i

5/3

ha4 , a6 , a3 i

5/3

ha1 , a4 , a2 , a3 i

1

ha1 , a2 , a6 , a3 i

1

ha1 , a3 , a8 , a2 i

1

ha1 i

1/4

ha4 , a8 , a2 i

3/4

ha4 , a6 , a3 i

3/4

h(I)

h
hF

6

hI

4 31

4 43

h

3

FI

task

optimal plan

2G f
u1
2G f
u2
2G f
u3
2G i
v1
2G i
v2
2G i
v3
2G f
u1
2G f
u2
2G f
u3
2G i
v1
2G i
v2
2G i
v

ha2 , a5 , a8 i

1

ha1 , a4 , a7 i

1

ha1 , a4 , a7 i

cost

h(I)
3

1

ha10 , a1 i

4/3

ha10 , a4 i

4/3

ha10 , a7 i

4/3

ha2 , a5 , a8 i

3/4

ha1 , a4 , a7 i

3/4

ha1 , a4 , a7 i

3/4

ha10 , a1 i

1/2

ha10 , a4 i

1/2

ha10 , a7 i

1/2

4

15/4

3

(a)

(b)

Figure 9: Illustrations for the proof of Theorem 9: Optimal plans for all the abstract problems of (a) 1 , where we have hF (I) > hFI (I) > hI (I), and (b) 2 , where we have
hF (I) < hFI (I) < hI (I).

variables above are binary-valued, the claim holds in conjunction with arbitrary variable
domain abstractions.

One conclusion from Theorem 9 is that it is worth studying the asymptotic performance
ratios for all three heuristics. The last three columns of Table 4 present our results for
hF , hI , and hFI for the Gripper, Logistics, Blocksworld, Miconic, and Satellite
domains. We also studied the performance ratios of max{hF , hI , hFI }, and in these five
domains they appear to be identical to those of hF . (Note that ratio of max should not
necessarily be identical to max of ratios, and thus this analysis is worthwhile.) Taking
a conservative position, the performance ratios for the fork-decomposition heuristics in
Table 4 are worst-case in the sense that
(i) here we neither optimize the action cost partition (setting it to uniform as in the rest
of the paper) nor eliminate clearly redundant abstractions, and
(ii) we use domain abstractions to (up to) ternary-valued abstract domains only.
The domains of the fork roots are all abstracted using the leave-one-out binary-valued
domain decompositions as in Eq. 16 while the domains of the inverted-fork sinks are all
abstracted using the distance-from-initial-value ternary-valued domain decompositions
as in Eq. 15.
Overall, the results for fork-decomposition heuristics in Table 4 are gratifying. First,
note that the performance ratios for hk and hPDB are all 0. This is because every subgoal
set of size k (for hk ) and size log(n) (for hPDB ) can be reached in the number of steps that
only depends on k (respectively, log(n)), and not n, while h (sn ) grows linearly in n in
all the five domains. This leaves us with hPDB
add being the only state-of-the-art (tractable
87

fiKatz & Domshlak

and) admissible heuristic to compare with. Table 4 shows that the asymptotic performance
F
ratio of hF heuristic is at least as good as that of hPDB
add in all five domains, while h is
+
PDB
superior to hPDB
add in Miconic, getting here quite close to h . When comparing hadd and
fork-decomposition heuristics, it is crucial to recall that the ratios devised by Helmert and
Mattmuller for hPDB
add are with respect to optimal, manually-selected set of patterns. By
contrast, the selection of variable subsets for fork-decomposition heuristics is completely
nonparametric, and thus requires no tuning of the abstraction-selection process.
In the rest of the section we prove these asymptotic performance ratios of hF , hI , and
FI
h in Table 4 for the five domains. We begin with a very brief outline of how the results are
obtained. Some familiarity with the domains is assumed. Next, each domain is addressed
in detail: we provide an informal domain description as well as its sas+ representation, and
then prove lower and upper bounds on the ratios for all three heuristics.
Gripper Assuming n > 0 balls should be moved from one room to another, all three
heuristics hF , hI , hFI account for all the required pickup and drop actions, and only for
O(1)-portion of move actions. However, the former actions are responsible for 2/3 of
the optimal-plan length (= cost). Now, with the basic uniform action-cost partition,
hF , hI , and hFI account for the whole, O(1/n), and 2/3 of the total pickup/drop
actions cost, respectively, providing the ratios in Table 4.8
Logistics An optimal plan contains at least as many load/unload actions as move actions,
and all three heuristics hF , hI , hFI fully account for the former, providing a lower bound
of 1/2. An instance on which all three heuristics achieve exactly 1/2 consists of two
trucks t1 , t2 , no airplanes, one city, and n packages such that the initial and goal
locations of all the packages and trucks are all pair-wise different.
Blocksworld Arguments similar to those of Helmert and Mattmuller (2008) for hPDB
add .
Miconic All three heuristics fully account for all the loads/unload actions. In addition, hF
accounts for the full cost of all the move actions to the passengers initial locations,
and for half of the cost of all the other move actions. This provides us with lower
bounds of 1/2 and 5/6, respectively. Tightness of 1/2 for hI and hFI is shown on a
task consisting of n passengers, 2n + 1 floors, and all the initial and goal locations
being pair-wise different. Tightness of 5/6 for hF is shown on a task consisting of n
passengers, n + 1 floors, the elevator and all the passengers are initially at floor n + 1,
and each passenger i wishes to get to floor i.
Satellite The length of an optimal plan for a problem with n images to be taken and k
satellites to be moved to some end-positions is  6n + k. All three heuristics fully
account for all the image-taking actions and one satellite-moving action per satellite
as above, providing a lower bound of 61 . Tightness of 1/6 for all three heuristics
is shown on a task as follows: Two satellites with instruments {i}li=1 and {i}2l
i=l+1 ,

respectively, where l = n  n. Each pair of instruments {i, l + i} can take images
in modes {m0 , mi }. There is a set of directions {dj }nj=0 and a set of image objectives
8. We note that a very slight modification of the uniform action-cost partition results in a ratio of 2/3 for
all three heuristics. Such optimizations, however, are outside of our scope here.

88

fiImplicit Abstraction Heuristics

right

lef t

robot

right
b1

b1



bn

...
f
Gright

lef t
bn

...

b1

right

robot
bn

b1

f
Glef
t

(a)

...

robot

bn

f
Grobot

lef t

b
Gbi , b  Balls

(b)

Figure 10: Grippers (a) causal graph and (b) the corresponding collection of v-forks and
v-iforks

{oi }ni=1 such that, for 1  i  l, oi = (d0 , mi ) and, for l < i  n, oi = (di , m0 ).
Finally, the calibration direction for each pair of instruments {i, l + i} is di .
9.1 Gripper
The domain consists of one robot robot with two arms Arms = {right, lef t}, two rooms
Rooms = {r1, r2}, and a set Balls of n balls. The robot can pick up a ball with an arm
arm  Arms if arm is empty, release a ball b  Balls from the arm arm if arm currently
holds b, and move from one room to another. All balls and the robot are initially in room
r1, both arms are empty, and the goal is to move all the balls to room r2. A natural
description of this planning task in sas+ is as follows.
S
S
 Variables V = {robot} Arms Balls with domains
D(robot) = Rooms

D(lef t) = D(right) = Balls  {empty}

b  Balls : D(b) = Rooms  {robot}.

 Initial state I = {b : r1 | b  Balls}  {robot : r1, right : empty, lef t : empty}.
 Goal G = {b : r2 | b  Balls}.
 Actions
A ={M ove(r, r0 ) | {r, r0 }  Rooms}

[

{P ickup(b, arm, r), Drop(b, arm, r) | b  Balls, arm  Arms, r  Rooms},
where
 move robot: M ove(r, r0 ) = h{robot : r}, {robot : r0 }i,

 pickup ball:
P ickup(b, arm, r) = h{b : r, arm : empty, robot : r}, {b : robot, arm : b}i, and

 drop ball: Drop(b, arm, r) = h{b : robot, arm : b, robot : r}, {b : r, arm : empty}i.

The (parametric in n) causal graph of this task is depicted in Figure 10a.
89

fiKatz & Domshlak

frobot

Action
0

M ove(r, r )
P ickup(b, arm, r)
Drop(b, arm, r)

farm,empty

1
1
1

0
2
2

farm,b

farm,b0

0
2
2

0
1
1

farm0 ,
0
1
1

ib
1
2
2

ib0
1
1
1

F

I

FI

1

1
n
1
n+1
1
n+1

1
n+1
1
3n+6
1
3n+6

1
2n+5
1
2n+5

Table 5: Number of representatives for each original Gripper action in each abstract task,
as well as the partition of the action costs between these representatives
frobot

fright,empty
fright,b
fright,b0
flef t,
ib
ib0

P ickup(b, right, r1) = h{robot : r1, b : r1}, {b : robot}i
P ickup(b, right, r1)1 = h{right : empty}, {right : b}i,
P ickup(b, right, r1)2 = h{right : b, b : r1}, {b : robot}i
P ickup(b, right, r1)1 = h{right : empty}, {right : b}i,
P ickup(b, right, r1)2 = h{right : b, b : r1}, {b : robot}i
P ickup(b, right, r1) = h{right : b, b : r1}, {b : robot}i
P ickup(b, right, r1) = h{right : b, b : r1}, {b : robot}i
P ickup(b, right, r1)1 = h{right : empty}, {right : b}i,
P ickup(b, right, r1)2 = h{right : b, robot : r1, b : r1}, {b : robot}i
P ickup(b, right, r1) = h{right : empty}, {right : b}i

Table 6: The sets of representatives of the original action P ickup(b, right, r1) in the abstract
tasks

9.1.1 Fork Decomposition
Since the variables robot, right, and lef t have no goal value, the collection of v-forks and
v-iforks is as in Figure 10b. The domains of inverted fork sinks are ternary valued. The
domains of fork roots are abstracted as in Eq. 16 (leave one out), and thus
F = {frobot }  {fright, , flef t, |   {empty}  Balls},
I = {ib | b  Balls},

FI = {frobot }  {fright, , flef t, |   {empty}  Balls}  {ib | b  Balls}.
For each original action, the number of its representatives in each abstract task, as well as
the cost assigned to each such representative, are listed in Table 5. Table 6 illustrates derivation of these numbers via decomposition of an example action P ickup(b, right, r1) in each
of the fork decomposition abstractions. That action has one nonredundant representative
in frobot , two such representatives in each of fright,empty and fright,b , one representative in
each fright,b0 for b0  Balls \ {b}, one representative in each flef t, for   Balls  {empty},
two representatives in ib , and one representative in each ib0 for b0  Balls \ {b}. This
1
1
results in cost 2n+5
for each representative in F , n+1
for each representative in I , and
1
3n+6 for each representative in FI .
Given that, the optimal plans for the abstract tasks are as follows.
90

fiImplicit Abstraction Heuristics

h

task
frobot

hF

fright,
flef t,

hI

ib
frobot

hFI

fright,
flef t,
ib

optimal plan
hP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1),
, M ove(r1, r2), Drop(b1 , right, r2), . . . , Drop(bn , right, r2)i
hP ickup(b1 , lef t, r1), . . . , P ickup(bn , lef t, r1),
, Drop(b1 , lef t, r2), . . . , Drop(bn , lef t, r2)i
hP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1),
, Drop(b1 , right, r2), . . . , Drop(bn , right, r2)i
hP ickup(b, right, r1)1 , P ickup(b, right, r1)2 , M ove(r1, r2), Drop(b, lef t, r2)2 i
hP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1), M ove(r1, r2),
, Drop(b1 , right, r2), . . . , Drop(bn , right, r2)i
hP ickup(b1 , lef t, r1), . . . , P ickup(bn , lef t, r1),
, Drop(b1 , lef t, r2), . . . , Drop(bn , lef t, r2)i
hP ickup(b1 , right, r1), . . . , P ickup(bn , right, r1),
, Drop(b1 , right, r2), . . . , Drop(bn , right, r2)i
hP ickup(b, right, r1)1 , P ickup(b, right, r1)2 , M ove(r1, r2), Drop(b, lef t, r2)2 i

cost

#

4n+5
2n+5

1

2n
2n+5

n+1

2n
2n+5

n+1

3
1
+ n
n+1
1
2n +
3n+6
n+1

n

2n
3n+6

n+1

2n
3n+6

n+1

3
3n+6

1
+ n+1

h(I)

2n  2n5
2n+5

4n+1
n+1

1
4n
3

+ 4n+6
3n+6

n

Assuming n > 0 balls should be moved from one room to another, the cost of the optimal
plan for the original task is 3n  1 when n is even, and 3n when n is odd. Therefore, the
asymptotic performance ratios for the heuristics hF , hI , hFI on Gripper are 2/3, 0, and 4/9,
respectively.
9.2 Logistics
Each Logistics task consists of some k cities, x airplanes, y trucks and n packages. Each
city i is associated with a set Li = {li1 . . . , lii } of locations within that city; the union of
S
the locations of all the cities is denoted by L = ki=1 Li . In addition, precisely one location
in each city is an airport, and the set of airports is LA = {l11 . . . , lk1 }  L. Each truck can
move only within the city in which it is located, and airplanes can fly between airports.
The airplanes are denoted by U = {u1 , . . . , ux }, the trucks by T = {t1 , . . . , ty }, and the
packages by P = {p1 , . . . , pn }. Let Ti = {t  T | I[t]  Li } denote the trucks of city i, and
P = P1  P2  P3  P4  P5 denote a partition of the packages as follows:
 each package in P1 = {p  P | I[p], G[p]  LA } is both initially at an airport and
needs to be moved to another airport,
 each package in P2 = {p  P | I[p]  LA  Li , G[p]  Lj \ LA , i 6= j} is initially at an
airport and needs to be moved to a non-airport location in another city,
 each package in P3 = {p  P | I[p]  Li , G[p]  Li } needs to be moved within one
city,
 each package in P4 = {p  P | I[p]  Li \ LA , G[p]  LA \ Li } needs to be moved from
a non-airport location in one city to the airport of some other city, and
 each package in P5 = {p  P | I[p]  Li \ LA , G[p]  Lj \ LA , i 6= j} needs to be moved
from a non-airport location in one city to a non-airport location in another city.
A natural Logistics task description in sas+ is as follows.
 Variables V = U  T  P with domains
u  U : D(u) = LA ,

1  i  k, t  Ti : D(t) = Li ,

p  P : D(p) = L  U  T.
91

fiKatz & Domshlak

u1    ux

t1   

ty

u
p1 . . .

p1   

pi    pn
(a)

u1 . . . ux

t
pn

Guf , u  U

p1 . . .

pn

Gtf , t  T
(b)

t1 . . . ty
p

Gpi , p  P

Figure 11: Logisticss (a) causal graph and (b) the corresponding collection of v-forks and
v-iforks

 Initial state I  (LA )x  L1      Lk  (L)n .
 Goal G = {p1 : l1 , . . . , pn : ln }  (L)n .
 Actions
A=

k [ [
[

i=1 lLi tTi



[ [
lLA uU


{Lt(p, t, l), U t(p, t, l) | p  P }  {M t(t, l, l0 ) |, l0  Li \ {l}}


{La(p, u, l), U a(p, u, l) | p  P }  {M a(u, l, l0 ) | l0  LA \ {l}} ,

where
 load package p onto truck t in location l: Lt(p, t, l) = h{p : l, t : l}, {p : t}i,
 unload package p from truck t in location l: U t(p, t, l) = h{p : t, t : l}, {p : l}i,
 move truck t from location l to location l0 : M t(t, l, l0 ) = h{t : l}, {t : l0 }i,
 load package p onto airplane u in l: La(p, u, l) = h{p : l, u : l}, {p : u}i,
 unload package p from airplane u into l: U a(p, u, l) = h{p : u, u : l}, {p : l}i, and
 move airplane u from location l to l0 : M a(u, l, l0 ) = h{u : l}, {u : l0 }i.
The (parametrized in n, x, and y) causal graph of Logistics tasks is depicted in Figure 11a.
9.2.1 Fork Decomposition
Since the variables u  U and t  T have no goal value, the collection of v-forks and viforks is as in Figure 11b. The domains of the inverted-fork sinks are all abstracted as in
Eq. 15 (distance-from-initial-value), while the domains of the fork roots are abstracted
92

fiImplicit Abstraction Heuristics

fu,l fu,l0 fu,l00 fu0 ,l ft,l ft,l0 ft,l00 ft0 ,l ip,m F I FI

Action
0

M t(t, l, l )
M a(u, l, l0 )

0
1

0
1

0
0

0
0

1
0

1
0

0
0

0
0

1
2
1
2

1
1

1
1
ni 2+ni
1
1
ni 2+ni

(a)
I[p]  LA  Li
I[p]  Li \ LA
p  P1 p  P2 p  P3 p  P3 p  P4
p  P5
fu,l ft,l ip0 ,m ip,1 ip,1 ip,2 ip,1 ip,1 ip,1 ip,2 ip,1 ip,2 ip,3 F I FI

Action
l  Li
l  Lj
La(p, u, l), U a(p, u, l)

Lt(p, t, l), U t(p, t, l)

1
1
1

1
1
1

0
0
0

1
0
1

1
0
1

0
1
0

1
0
1

1
0
0

1
0
0

0
0
1

1
0
0

0
0
1

0
1
0

1
nf
1
nf
1
nf

1
1
1

1
nf +1
1
nf +1
1
nf +1

(b)
Figure 12: Number of representatives of each original Logistics action in each abstract
task, as well as the partition of the action costs between these representatives;
tables (a) and (b) capture the move and load/unload actions, respectively

as in Eq. 16 (leave-one-out). Thus, we have
F =

[ [
uU lLA

I =

FI =

{fu,l } 

[

[

k [ [
[
i=1 tTi lLi

{ip,1 } 
{ip,2 }
pP
pP2 P4 P5
[ [
uU lLA

{fu,l } 



{ft,l },

[
pP5

k [ [
[
i=1 tTi lLi

{ip,3 },

{ft,l } 

[
pP

{ip,1 } 

[

{ip,2 } 

pP2 P4 P5

[
pP5

{ip,3 }.

P
The total number of forks is nf = |F | = |U |  |LA | + ki=1 |Ti |  |Li |, and the total number
of inverted forks is ni = |I | = |P1 | + 2  |P2 | + |P3 | + 2  |P4 | + 3  |P5 |. For each action
a  A, the number of its representatives in each abstract task, as well as the cost assigned
to each such representative, are given in Figure 12. Each row in the tables of Figure 12
corresponds to a certain Logistics action, each column (except for the last three) represents
an abstract task, and each entry captures the number of representatives an action has in
the corresponding task. The last three columns show the portion of the total cost that is
given to an action representative in each task, in each of the three heuristics in question.
9.2.2 Lower Bound
Note that any optimal plan for a Logistics task contains at least as many load/unload
actions as move actions. Thus, the following lemma provides us with the lower bound of
1/2 for all three heuristics in question.

93

fiKatz & Domshlak

Lemma 1 For any Logistics task, hF , hI , and hFI account for the full cost of the load/unload
actions required by any optimal plan for that task.
Proof: For any Logistics task, all the optimal plans for that task contain the same amount
of load/unload actions for each package p  P as follows.

p  P1 :

2 actions  one load onto an airplane, and one unload from that airplane,

p  P2 : 4 actions  one load onto an airplane, one unload from that airplane, one load
onto a truck, and one unload from that truck,
p  P3 :

2 actions  one load onto a truck, and one unload from that truck,

p  P4 : 4 actions  one load onto a truck, one unload from that truck, one load onto an
airplane, and one unload from that airplane, and
p  P5 : 6 actions  two loads onto some trucks, two unloads from these trucks, one load
onto an airplane, and one unload from that airplane.
Consider the fork-decomposition F . Any optimal plan for each of the abstract tasks
will contain the number of load/unload actions exactly as above (the effects of these actions
remain unchanged in these tasks). The cost of each representative of each load/unload
action is n1f , and there are nf abstract tasks. Therefore, the heuristic hF fully accounts for
the cost of the required load/unload actions.
Now consider the fork-decomposition I . With m being the domain-decomposition
index of the abstraction, any optimal plan for the abstract task ip,m will include one load
and one unload actions as follows.
p  P1 :

one load onto an airplane and one unload from that airplane,

p  P2 , m = 1:

one load onto an airplane and one unload from that airplane,

p  P2 , m = 2:

one load onto a truck and one unload from that truck,

p  P3 :

one load onto a truck and one unload from that truck,

p  P4 , m = 1:

one load onto a truck and one unload from that truck,

p  P4 , m = 2:

one load onto an airplane, and one unload from that airplane,

p  P5 , m = 1:

one load onto a truck and one unload from that truck,

p  P5 , m = 2:

one load onto an airplane and one unload from that airplane, and

p  P5 , m = 3:

one load onto a truck and one unload from that truck.

The cost of each representative of load/unload actions is 1, and thus the heuristic hI fully
accounts for the cost of the required load/unload actions.
Finally, consider the fork-decomposition FI . Any optimal plan for each of the forkstructured abstract tasks will contain the same number of load/unload actions as for F .
The cost of each representative of load/unload actions is nf1+1 and there are nf such abstract
tasks. In addition, each of these load/unload actions will also appear in exactly one inverted
fork-structured abstract task. Therefore the heuristic hFI also fully accounts for the cost of
the required load/unload actions.

94

fiImplicit Abstraction Heuristics

t1
p1

t2

...

pn

p1

Gtf1

t1

...

t2

pn

p
Gpi , p  P

Gtf2

Figure 13: Collection of v-forks and v-iforks for the Logistics task used for the proof of
the upper bound of 1/2

9.2.3 Upper Bound
An instance on which all three heuristics achieve exactly 1/2 consists of two trucks t1 , t2 , no
airplanes, one city, and n packages such that the initial and goal locations of all the packages
are all pairwise different, and both trucks are initially located at yet another location. More
+
formally, if L = {li }2n
i=0 , and T = {t1 , t2 }, then the sas encoding for this Logistics task
is as follows.
 Variables V = {t1 , t2 , p1 , . . . , pn } with domains
t  T : D(t) = L,

p  P : D(p) = L  T.
 Initial state I = {t1 : l0 , t2 : l0 , p1 : l1 , . . . , pn : ln }.
 Goal G = {p1 : ln+1 , . . . , pn : l2n }.
 Actions A = {Lt(p, t, l), U t(p, t, l) | l  L, t  T, p  P }  {M t(t, l, l0 ) | t  T, {l, l0 } 
L}.
The collection of v-forks and v-iforks for this task is depicted in Figure 13. The domains of
the inverted-fork sinks are all abstracted as in Eq. 15 (distance-from-initial-value), while
the domains of the fork roots are abstracted as in Eq. 16 (leave-one-out), and therefore
we have
F = {ft1 ,l ft2 ,l | l  L},
I = {ip,1 | p  P },

FI = {ft1 ,l ft2 ,l | l  L}  {ip,1 | p  P }.
The total number of forks is thus nf = 4n + 2 and the total number of inverted forks is
ni = n. The partition of the action costs for Logistics tasks is described in Figure 12.
Here we have P = P3 and thus the action cost partition is as follows.
ft,l

Action
0

M t(t, l, l )
Lt(p, t, l)
U t(p, t, l)

1
1
1

ft,l0
1
1
1

ft,l00
0
1
1

ft0 ,l
0
1
1

95

ip,1
1
1
1

ip0 ,1

F

I

FI

0
0
0

1
2
1
4n+2
1
4n+2

1
n

1
n+2
1
4n+3
1
4n+3

1
1

fiKatz & Domshlak

Given that, the optimal plans for the abstract task are
h

task

hF

ft1 ,l
ft2 ,l
ipi ,1
ft1 ,l
ft2 ,l
ipi ,1

hI
hFI

optimal plan
hLt(p1 , t2 , l1 ), . . . , Lt(pn , t2 , ln ), U t(p1 , t2 , ln+1 ), . . . , U t(pn , t2 , l2n )i
hLt(p1 , t1 , l1 ), . . . , Lt(pn , t1 , ln ), U t(p1 , t1 , ln+1 ), . . . , U t(pn , t1 , l2n )i
hM t(t1 , l0 , li ), Lt(pi , t1 , li ), M t(t1 , li , ln+i ), U t(pi , t1 , ln+i )i
hLt(p1 , t2 , l1 ), . . . , Lt(pn , t2 , ln ), U t(p1 , t2 , ln+1 ), . . . , U t(pn , t2 , l2n )i
hLt(p1 , t1 , l1 ), . . . , Lt(pn , t1 , ln ), U t(p1 , t1 , ln+1 ), . . . , U t(pn , t1 , l2n )i
hM t(t1 , l0 , li ), Lt(pi , t1 , li ), M t(t1 , li , ln+i ), U t(pi , t1 , ln+i )i

cost

#

2n
4n+2
2n
4n+2
2
+2
n
2n
4n+3
2n
4n+3

2n + 1
2n + 1
n
2n + 1
2n + 1
n

2
n+2

+

2
4n+3

h(I)
2n
2n + 2
2n +

2n
n+2

while an optimal plan for the original task, e.g., hM t(t1 , l0 , l1 ), Lt(p1 , t1 , l1 ), M t(t1 , l1 , l2 ), Lt(p2 , t1 , l2 ),
M t(t1 , l2 , l3 ), . . . , Lt(pn , t1 , ln ), M t(t1 , ln , ln+1 ), U t(p1 , t1 , ln+1 ), M t(t1 , ln+1 , ln+2 ), U t(p2 , t1 , ln+2 ),
M t(t1 , ln+2 , ln+3 ), . . . , U t(pn , t1 , l2n )i,

has the cost of 4n, providing us with the upper bound of
1/2 for all three heuristics. Putting our lower and upper bounds together, the asymptotic
ratio of all three heuristics in question is 1/2.
9.3 Blocksworld
Each Blocksworld task consists of a table table, a crane c, and n + 1 blocks B =
{b1 , . . . , bn+1 }. Each block can be either on the table, or on top of some other block,
or held by the crane. The crane can pick up a block if it currently holds nothing, and that
block has no other block on top of it. The crane can drop the held block on the table or on
top of some other block.
Consider now a Blocksworld task as follows. The blocks initially form a tower
b1 , . . . , bn , bn+1 with bn+1 being on the table, and the goal is to move them to form a
tower b1 , . . . , bn1 , bn+1 , bn with bn being on the table. That is, the goal is to swap the
lowest two blocks of the tower. A natural description of this task in sas+ is as follows.
 Variables V = {b, clearb | b  B}  {c} with domains
D(c) = {empty}  B,

b  B : D(b) = {table, c}  B \ {b},
D(clearb ) = {yes, no}.

 Initial state
I = {c : empty, bn+1 : table, clearb1 : yes}
[
{bi : bi+1 | 1  i  n}

[

{clearb : no | b  B \ {b1 }} .
 Goal G = {bn : table, bn+1 : bn , bn1 : bn+1 }  {bi : bi+1 | 1  i  n  2}.
 Actions A = {PT (b), DT (b) | b  B}  {P (b, b0 ), D(b, b0 ) | {b, b0 }  B} where
 pick block b from the table: PT (b) = h{c : empty, b : table, clearb : yes}, {cb, b : c}i,
 pick block b from block b0 :
P (b, b0 ) = h{c : empty, b : b0 , clearb : yes, clearb0 : no}, {c : b, b : c, clearb0 : yes}i,
96

fiImplicit Abstraction Heuristics

c

clearb1 . . . clearbn+1

c
b
Gbi , b  {bn1 , bn , bn+1 }

clearb0

clearb

c
b0

b

bn1

bn

clearb
bn+1

bn1

Gcf
(a)

bn

bn+1

f
Gclear
,b  B
b

(b)

Figure 14: (a) Causal graph and (b) the corresponding collection of v-forks and v-iforks for
the Blocksworld task used in the proof

 drop block b on the table: DT (b) = h{c : b, b : c}, {c : empty, b : table}i, and
 drop block b on block b0 :
D(b, b0 ) = h{c : b, b : c, clearb0 : yes}, {c : empty, b : b0 , clearb0 : no}i.

A schematic version of the causal graph of this task is depicted in Figure 14a. Since only
the variables bn1 , bn , bn+1 have goal values that are different from their values in the initial
state, the collection of v-forks and v-iforks is as in Figure 14b. After the (leave-one-out,
Eq. 16) domain abstraction of the variable c, c-fork Gcf breaks down into n + 2 abstract
tasks. The sinks of v-iforks Gbi n1 , Gbi n , and Gbi n+1 also go through the process of domain
decomposition (distance-from-initial-value, Eq. 15). However, due to the structure of the
domain transition graphs of the block variables, domain decomposition here results in only
a single abstract task for each of the v-iforks. Thus we have
F ={fc,empty }  {fc,b | b  B}  {fclearb | b  B},
I ={ibn1 ,1 , ibn ,1 , ibn+1 ,1 },

FI ={fc,empty }  {fc,b | b  B}  {fclearb | b  B}  ibn1 ,1 , ibn ,1 , ibn+1 ,1 }.
It is technically straightforward to verify that, for each abstract task in F , I , and FI ,
there exists a plan that (i) involves only the representatives of the actions
{P (bn1 , bn ), DT (bn1 ), P (bn , bn+1 ), DT (bn ), PT (bn+1 ), D(bn+1 , bn ), PT (bn1 ), D(bn1 , bn+1 )} ,
(21)
and (ii) involves each representative of each original action at most once. Even if together
these plans account for the total cost of all eight actions in Eq. 21, the total cost of all these
plans (and thus the estimates of all the three heuristics) is upper-bounded by 8, while an
optimal plan for the original task, e.g., hP (b1 , b2 ), DT (b1 ), P (b2 , b3 ), DT (b2 ), . . . , P (bn , bn+1 ), DT (bn ),
PT (bn+1 ), D(bn+1 , bn ), PT (bn1 ), D(bn1 , bn+1 ), PT (bn2 ), D(bn2 , bn1 ), . . . , PT (b1 ), D(b1 , b2 )i, has a cost
97

fiKatz & Domshlak

e

p1



e
p1   

pn

Gef

(a)

e
pn

(b)

p
Gpi , p  P

Figure 15: Miconics (a) causal graph and (b) the corresponding collection of v-forks and
v-iforks

of 4n. Hence, the asymptotic performance ratio of all three heuristics on the Blocksworld
domain is 0.
9.4 Miconic
Each Miconic task consists of one elevator e, a set of floors F , and the passengers P . The
elevator can move between |F | floors and on each floor it can load and/or unload passengers.
A natural sas+ description of a Miconic task is as follows.
 Variables V = {e}  P with domains
D(e) = F,

p  P : D(p) = F  {e}.
 Initial state I = {e : fe }  {p : fp | p  P }  (F )|P |+1 .
 Goal G = {p : fp0 | p  P }  (F )|P | .
 Actions A = {In(p, f ), Out(p, f ) | f  F, p  P }  {M ove(f, f 0 ) | {f, f 0 }  F }, where
 load passenger p into e on floor f : In(p, f ) = h{e : f, p : f }, {p : e}i,
 unload passenger p from e to floor f : Out(p, f ) = h{e : f, p : e}, {p : f }i, and
 move elevator from floor f to floor f 0 : M ove(f, f 0 ) = h{e : f }, {e : f 0 }i.
The (parametrized in n) causal graph of Miconic tasks is depicted in Figure 15a, and
Figure 15b depicts the corresponding collection of v-forks and v-iforks. The domains of the
inverted-fork sinks are all abstracted as in Eq. 15 (distance-from-initial-value), and the
domains of the fork roots are abstracted as in Eq. 16 (leave-one-out). Thus, we have
F = {fe,f | f  F },
I = {ip,1 | p  P },

FI = {fe,f | f  F }  {ip,1 | p  P }.
The total number of the fork-structured abstract tasks is thus nf = |F | = |F | and the
total number of the inverted fork structured abstract tasks is ni = |I | = |P |. For each
action a  A, the number of its representatives in each abstract task, as well as the cost
assigned to each such representative, are given in Table 7.
98

fiImplicit Abstraction Heuristics

Action
M ove(f, f 0 )
In(p, f )
In(p0 , f )
Out(p, f )
Out(p0 , f )

fe,f fe,f 0 fe,f 00 ip,1 ip0 ,1 F I FI
1
1
1
1
1

1
1
1
1
1

0
1
1
1
1

1
1
0
1
0

1
0
1
0
1

1
2
1
nf
1
nf
1
nf
1
nf

1
1
ni 2+ni
1 nf1+1
1 nf1+1
1 nf1+1
1 nf1+1

Table 7: Number of representatives for each original Miconic action in each abstract task,
as well as the partition of the action costs among these representatives

9.4.1 Lower Bounds
First, as Miconic is a special case of the Logistics domain, Lemma 1 applies here analogously, with each package in P3 corresponding to a passenger. Thus, for each p  P , all
three heuristics account for the full cost of the load/unload actions required by any optimal
plan for that task.
Let us now focus on the abstract tasks F = {fe,f | f  F }. Recall that the task fe,f
is induced by an e-fork and, in terms of domain decomposition, distinguishes between being
at floor f and being somewhere else. Without loss of generality, the set of floors F can be
restricted to the initial and the goal values of the variables, and this because no optimal
plan will move the elevator to or from a floor f that is neither an initial nor a goal location
of a passenger or the elevator. Let FI = {I[p] | p  P } and FG = {G[p] | p  P }. The costs
of the optimal plans for each abstract task fe,f are as follows.
f  FI  FG : Let p, p0  P be a pair of passengers with initial and goal locations in f ,
respectively; that is, I[p] = G[p0 ] = f . If f = I[e], then any plan for fe,f has to move
the elevator from f in order to load passenger p0 , and then move the elevator back
to f in order to unload passenger p0 . Therefore the cost of any plan for fe,f is at
|
least 2|P
|F | + 1, where (see the last three columns of Table 7) the first component of the
summation comes from summing the costs of the representatives of the load/unload
actions for all the passengers, and the second component is the sum of the costs of
representatives of the two respective move actions. Similarly, if f 6= I[e], then any
plan for fe,f has to move the elevator to f in order to load passenger p, and then
move the elevator from f in order to unload p. Therefore, here as well, the cost of
|
any plan for fe,f is at least 2|P
|F | + 1.

f  FI \ FG : Let p  P be a passenger initially at f , that is, I[p] = f . If f = I[e], then
any plan for fe,f has to move the elevator from f in order to unload p, and thus the
cost of any plan for fe,f is at least

2|P |
|F |

+ 12 . Otherwise, if f 6= I[e], then any plan

for fe,f has to move the elevator to f in order to load p, and then move the elevator
from f in order to unload p. Hence, in this case, the cost of any plan for fe,f is at
least

2|P |
|F |

+ 1.
99

fiKatz & Domshlak

f  FG \ FI : Let p  P be a passenger who must arrive at floor f , that is, G[p] = f . If
f = I[e], then any plan for fe,f has to move the elevator from f in order to load p,
and then move the elevator back to f in order to unload p. Hence, here as well, the
|
cost of any plan for fe,f is at least 2|P
|F | + 1. Otherwise, if f 6= I[e], then any plan for

fe,f has to move the elevator to f in order to unload p, and thus the cost of any plan

for fe,f is at least

2|P |
|F |

+ 12 .

f 6 FG  FI : If f = I[e], then any plan for fe,f has to include a move from f in order to

|
1
load/unload the passengers, and thus the cost of any plan for fe,f is at least 2|P
|F | + 2 .
Otherwise, if f 6= I[e], the elevator is initially in the set of all other locations, and
|
thus the cost of any plan for fe,f is at least 2|P
|F | .

Putting this case-by-case analysis together, we have

|FG \FI |

,
I[e]  FI  FG
2|P | + |FI  FG | + |FI \ FG | +
2


2|P | + |F  F | + |F \ F |  1 + 1 + |FG \FI | , I[e]  F \ F
I
G
I
G
I
G
2
2
.
hF (I) 
|FG \FI |1

2|P
|
+
|F

F
|
+
|F
\
F
|
+
1
+
,
I[e]

F
\
F
I
G
I
G
G
I

2


2|P | + |F  F | + |F \ F | + |FG \FI |1 + 1 ,
I[e] 6 FG  FI
I
G
I
G
2
2

Note that the value in the second case is the lowest. This gives us a lower bound on the hF
estimate as in Eq. 22.
|FG \ FI |
1
+ |FI  FG |  .
(22)
2
2
Now, let us provide an upper bound on the length (= cost) of the optimal plan for a
Miconic task. First, let P 0  P denote the set of passengers with both initial and goal
locations in FI  FG . Let m(P 0 , FI  FG ) denote the length of the optimal traversal of the
floors FI  FG such that, for each passenger p  P 0 , a visit of I[p] comes before some visit of
G[p]. Given that, on a case-by-case basis, a (not necessarily optimal) plan for the Miconic
task at hand is as follows.
hF (I)  2|P | + |FI \ FG | +

I[e]  FI  FG : Collect all the passengers at I[e] if any, then traverse all the floors in
FI \ FG and collect passengers from these floors, then move the elevator to the first
floor f on the optimal path  traversing the floors FI  FG , drop off the passengers
whose destination is f , collect the new passengers if any, keep moving along  while
collecting and dropping off passengers at their initial and target floors, and then
traverse FG \ FI , dropping off the remaining passengers at their destinations. The
cost of such a plan (and thus of the optimal plan) is upper-bounded as in Eq. 23
below.
h (I)  2|P | + |FI \ FG | + m(P 0 , FI  FG ) + |FG \ FI |.
(23)
I[e]  FI \ FG : Collect all the passengers at I[e] if any, then traverse all the floors in
FI \ FG and collect passengers from these floors while making sure that this traversal
ends up at the first floor f of the optimal path  traversing the floors FI  FG , then
follow  while collecting and dropping passengers off at their initial and target floors,
and then traverse FG \ FI , dropping the remaining passengers off at their destinations.
As in the first case, the cost of such a plan is upper-bounded as in Eq. 23.
100

fiImplicit Abstraction Heuristics

I[e] 6 FI : Traverse the floors FI \ FG and collect all the passengers from these floors, then
move along the optimal path  traversing the floors FI  FG while collecting and
dropping off passengers at their initial and target floors, and then traverse the floors
FG \ FI , dropping the remaining passengers off at their destinations. Here as well, the
cost of such a plan is upper-bounded by the expression in Eq. 23.
Lemma 2 For any Miconic task with passengers P , we have

hF (I)
h (I)



5|P |1
6|P | .

Proof: Recall that P 0  P is the set of all passengers with both initial and goal locations
in FI  FG . First we give two upper bounds on the length of the optimal traversal of the
floors FI  FG such that, for each passenger p  P 0 , a visit of I[p] comes before some visit
of G[p]. From Theorem 5.3.3 of Helmert (2008) we have
m(P 0 , FI  FG ) = |FI  FG | + m (G 0 ),

(24)

where m (G 0 ) is the size of the minimum feedback vertex set of the directed graph G 0 =
(V 0 , E 0 ), with V 0 = FI  FG and E 0 containing an arc from f to f 0 if and only if a passenger
p  P 0 is initially at floor f and should arrive at floor f 0 .
Note that m (G 0 ) is trivially bounded by the number of graph nodes V 0 . In addition,
observe that, for any order of the nodes V 0 , the arcs E 0 can be partitioned into forward and
0
backward arcs, and one of these subsets must contain no more than |E2 | arcs. Removing
from G 0 all the nodes that are origins of the arcs in that smaller subset of E 0 results in a
directed acyclic graph. Hence, the set of removed nodes is a (not necessarily minimum)
0
feedback vertex set of G 0 , and the size of this set is no larger than |E2 | . Putting these two
bounds on m (G 0 ) together with Eq. 24 we obtain


|P 0 |
0
m(P , FI  FG )  min 2|FI  FG |, |FI  FG | +
.
(25)
2
From the disjointness of FG \ FI and FI  FG , and the fact that the goal of all the
passengers in P 0 is in FI , we have |FG \ FI |  |P |  |P 0 |. From Eqs. 22 and 23 we have
2|P | + |FI \ FG | + |FG2\FI | + |FI  FG |  12
hF

.
h
2|P | + |FI \ FG | + |FG \ FI | + m(P 0 , FI  FG )

(26)

F

As we are interested in a lower bound on the ratio hh , the right-hand side of the
inequality should be minimized, and thus we can safely set |FI \ FG | = 0 and |FG \ FI | =
|P |  |P 0 |, obtaining
0

|
2|P | + |P ||P
+ |FI  FG |  12
hF
5|P |  |P 0 | + 2|FI  FG |  1
2

=
.
h
2|P | + |P |  |P 0 | + m(P 0 , FI  FG )
6|P |  2|P 0 | + 2m(P 0 , FI  FG )

(27)

Let us examine the right-most expression in Eq. 27 with respect to the two upper bounds
on m(P 0 , FI  FG ) as in Eq. 25.

 If the minimum is obtained on 2|FI  FG |, then m(P 0 , FI  FG )  2|FI  FG | 
0
|FI  FG | + |P2 | , where the last inequality can be reformulated as
2|FI  FG |  |P 0 |  0.
101

fiKatz & Domshlak

This allows us to provide a lower bound on the right-most expression in Eq. 27, and
F
thus on hh as
hF
5|P |  |P 0 | + 2|FI  FG |  1
5|P | + (2|FI  FG |  |P 0 |)  1
5|P |  1



.
h
6|P |  2|P 0 | + 2m(P 0 , FI  FG )
6|P | + 2(2|FI  FG |  |P 0 |)
6|P |
(28)
0

0

 If the minimum is obtained on |FI FG |+ |P2 | , then m(P 0 , FI FG )  |FI FG |+ |P2 | <
2|FI  FG |, where the last inequality can be reformulated as
2|FI  FG |  |P 0 | > 0.
This again allows us to provide a lower bound on

hF
h

via Eq. 27 as

5|P |  |P 0 | + 2|FI  FG |  1
5|P | + (2|FI  FG |  |P 0 |)  1
5|P |  1
hF



.

0
0
0
h
6|P |  2|P | + 2m(P , FI  FG )
6|P | + (2|FI  FG |  |P |)
6|P |
(29)
Note that both lower bounds on
the lemma.

hF
h

in Eq. 28 and Eq. 29 are as required by the claim of


9.4.2 Upper Bounds
A Miconic task on which the heuristic hF achieves the performance ratio of exactly 5/6
consists of an elevator e, floors F = {fi }ni=0 , passengers P = {pi }ni=1 , all the passengers and
the elevator being initially at f0 , and the target floors of the passengers all being pairwise
disjoint. The sas+ encoding for the Miconic task is as follows.
 Variables V = {e}  P with the domains D(e) = F and p  P : D(p) = F  {e}.
 Initial state I = {e : f0 , p1 : f0 , . . . , pn : f0 }.
 Goal G = {p1 : f1 , . . . , pn : fn }.
 Actions A = {In(p, f ), Out(p, f ) | f  F, p  P }  {M ove(f, f 0 ) | {f, f 0 }  F }.
The causal graph of this task and the corresponding collection of v-forks (consisting of
only one e-fork) are depicted in Figure 15. The domain of e is abstracted as in Eq. 16
(leave-one-out), providing us with
F = {fe,f0 , fe,f1 , . . . , fe,fn }.
The costs of the action representatives in these abstract tasks are given in Table 7 with
nf = n + 1. The optimal plans for the abstract tasks in F are
task optimal plan
fe,f0
fe,f1
fe,fn

cost

hIn(p1 , f0 ), . . . , In(pn , f0 ), M ove(f0 , f1 ), Out(p1 , f1 ), . . . , Out(pn , fn )i
hIn(p1 , f0 ), . . . , In(pn , f0 ), Out(p2 , f2 ), . . . , Out(pn , fn ), M ove(f0 , f1 ), Out(p1 , f1 )i
hIn(p1 , f0 ), . . . , In(pn , f0 ), Out(p1 , f1 ), . . . , Out(pn1 , fn1 ), M ove(f0 , fn ), Out(pn , fn )i

102

1
2
1
2
1
2

+
+
+

2n
n+1
2n
n+1
2n
n+1

#

hF (I)

n+1

5n+1
2

fiImplicit Abstraction Heuristics

while an optimal plan for the original task, hIn(p1 , f0 ), . . . , In(pn , f0 ), M ove(f0 , f1 ), Out(p1 , f1 ),
has a cost of 3n, providing us with the
F
upper bound of 5/6 for the h heuristic in Miconic. Putting this upper bound together with
the previously obtained lower bound of 5/6, we conclude that the asymptotic performance
ratio of hF in Miconic is 5/6.
A Miconic task on which the heuristics hI and hFI achieve exactly 1/2 consists of an
n
elevator e, floors F = {fi }2n
i=0 , passengers P = {pi }i=1 , and the initial and target floors for
all the passengers and the elevator being pairwise disjoint. The task description in sas+ is
as follows.
M ove(f1 , f2 ), Out(p2 , f2 ), M ove(f2 , f3 ), . . . , Out(pn , fn )i,

 Variables V = {e}  P with the domains D(e) = F and p  P : D(p) = F  {e}.
 Initial state I = {e : f0 , p1 : f1 , . . . , pn : fn }.
 Goal G = {p1 : fn+1 , . . . , pn : f2n }.
 Actions A = {In(p, f ), Out(p, f ) | f  F, p  P }  {M ove(f, f 0 ) | {f, f 0 }  F }.
The causal graph of this task and the corresponding collection of v-forks and v-iforks are
depicted in Figure 15. The domains of the inverted-fork sinks are all abstracted as in Eq. 15
(distance-from-initial-value), and the domains of the fork roots are all abstracted as in
Eq. 16 (leave-one-out). This provides us with
I = {ip1 ,1 , . . . , ipn ,1 },

FI = {fe,f0 , fe,f1 , . . . , fe,fn , fe,fn+1 , . . . , fe,f2n , ip1 ,1 , . . . , ipn ,1 }.
The costs of the action representatives in these abstract tasks are given in Table 7 with
nf = 2n + 1 and ni = n. The optimal plans for the abstract tasks in I and FI are
h

task

optimal plan

hI

ipi ,1
fe,f0

hM ove(f0 , fi ), In(pi , fi ), M ove(fi , fn+i ), Out(pi , fn+i )i
hM ove(f0 , f1 ), In(p1 , f1 ), . . . , In(pn , fn ),
Out(p1 , fn+1 ), . . . , Out(pn , f2n )i
hM ove(f0 , f1 ), In(p1 , f1 ), M ove(f1 , f2 ), In(p2 , f2 ), . . . , In(pn , fn ),
Out(p1 , fn+1 ), . . . , Out(pn , f2n )i
hM ove(f0 , fn ), In(pn , fn ), M ove(fn , f1 ),
In(p1 , f1 ), . . . , In(pn1 , fn1 ), Out(p1 , fn+1 ), . . . , Out(pn , f2n )i
hIn(p1 , f1 ), . . . , In(pn , fn ), Out(p2 , fn+2 ), . . . , Out(pn , f2n ),
M ove(f0 , fn+1 ), Out(p1 , fn+1 )i
hIn(p1 , f1 ), . . . , In(pn , fn ), Out(p1 , fn+1 ), . . . , Out(pn1 , f2n1 ),
M ove(f0 , f2n ), Out(pn , f2n )i
hM ove(f0 , fi ), In(pi , fi ), M ove(fi , fn+i ), Out(pi , fn+i )i

hFI

fe,f1
fe,fn
fe,f

n+1

fe,f2n
ipi ,1

cost

#

h(I)

n
1

2n + 2

1
n+2

+2
2n
+ 2n+2

2
n+2

+

2n
2n+2

n

2
n+2

+

2n
2n+2

1
n+2

+

2n
2n+2

1
n+2

+

2n
2n+2

2
n+2

+

2
2n+2

2
n

2n +

5n+1
n+2

n

n

while an optimal plan for the original task, hM ove(f0 , f1 ), In(p1 , f1 ), M ove(f1 , f2 ), In(p2 , f2 ),
M ove(f2 , f3 ), . . . , In(pn , fn ), M ove(fn , fn+1 ), Out(p1 , fn+1 ), M ove(fn+1 , fn+2 ), Out(p2 , fn+2 ),
M ove(fn+2 , fn+3 ), . . . , Out(pn , f2n )i, has the cost of 4n, providing us with the upper bound of
1/2 for the hI and hFI heuristics in Miconic. Putting this upper bound together with the
previously obtained lower bound of 1/2, we conclude that the asymptotic performance ratio
of hI and hFI in Miconic is 1/2.

103

fiKatz & Domshlak

9.5 Satellite
The Satellite domain is quite complex. A Satellite tasks
S consists of some satellites S,
each s  S with a finite set of instruments Is onboard, I = sS Is . There is a set of image
modes M, and for each mode m  M, there is a set Im  I of instruments supporting
mode m. Likewise, there is a set of directions L, image objectives O  LM, and functions
cal : I 7 L, p0 : S 7 L, and p : S0 7 L with S0  S, where cal is the calibration target
direction function, p0 is the initial direction function, and p is the goal pointing direction
function.
Let us denote by Oi = {o = (d,Sm)  O | i  Im } the subset of all images that can
be taken by instrument i, by Os = iIs Oi the subset of all images that can be taken by
instruments on satellite s, and by Sm = {s | Is  Im 6= } the subset of all satellites that
can take images in mode m. The problem description in sas+ is as follows.
 Variables V = S  {Oni , Ci | i  I}  O with domains
s  S : D(s) = L,

i  I : D(Oni ) = D(Ci ) = {0, 1},
o  O : D(o) = {0, 1}.

 Initial state I = {s : p0 (s) | s  S}  {Oni : 0, Ci : 0 | i  I}  {o : 0 | o  O}.
 Goal G = {s : p (s) | s  S0 }  {o : 1 | o  O}.
 Actions
[

A=
{T urn(s, d, d0 ) | {d, d0 }  L}  {SwOn(i, s), Cal(i, s), SwOf f (i) | i  Is } 
sS

{T akeIm(o, d, s, i) | o = (d, m)  O, s  Sm , i  Im  Is },
where
 turn satellite: T urn(s, d, d0 ) = h{s : d}, {s : d0 }i,

 power on instrument: SwOn(i, s) = h{Oni0 : 0 | i0  Is }, {Oni : 1}i,
 power off instrument: SwOf f (i) = h{Oni : 1}, {Oni : 0, Ci : 0}i,

 calibrate instrument: Cal(i, s) = h{Ci : 0, Oni : 1, s : cal(i)}, {Ci : 1}i, and
 take an image: T akeIm(o, d, s, i) = h{o : 0, Ci : 1, s : d}, {o : 1}i.

9.5.1 Fork Decomposition
The causal graph of an example Satellite task and a representative subset of the collection
of v-forks and v-iforks are depicted in Figure 16. Since the variables {Oni , Ci | i  I}S \S0
have no goal value, the collection of v-forks and v-iforks will be as follows in the general
case.
 For each satellite s  S, an s-fork with the leaves Os .
104

fiImplicit Abstraction Heuristics

o1

o2

o3

o4

s1

C3

s2

s2

C1

C2

C4

On1

On2

On3

On4

C5

C7

o1

C6

o3

C5
o4

Gsf 2
s1

o3

C6
o1

f
GC
5
s2

C2

C7
o3

f
GC
6
C4

o4
f
GC
7

C7

On7
o4
On5

On6

(a)

Goi 4
(b)

Figure 16: Satellite example task (a) causal graph and (b) a representative subset of the
collection of v-forks and v-iforks

 For each instrument i  I, a Ci -fork with the leaves Oi .
 For each image objective o = (d, m)  O, a o-ifork with the parents {Ci | i  Im }Sm .
The root domains of all forks rooted at instruments i  I and of all the inverted-fork sinks
are binary in the first place, and the root domains of the forks rooted at satellites s  S are
abstracted as in Eq. 16 (leave-one-out). This provides us with
F = {fs,d | s  S, d  L}  {fCi | i  I},
I = {io | o  O},

FI = {fs,d | s  S, d  L}  {fCi | i  I}  {io | o  O}.
The total number of forks is thus nf = |S|  |L| + |I| and the total number of inverted
forks is ni = |O|. For each action a  A, the number of its representatives in each abstract
task, as well as the cost assigned to each such representative, are given in Figure 17.
9.5.2 Lower Bounds
First, note that any optimal plan for a Satellite task contains at most 6 actions per image
objective o  O and one action per satellite s  S0 such that I[s] 6= G[s]. Now we show
that each of the three heuristics fully account for the cost of at least one action per image
objective o  O and one action per such a satellite. This will provide us with the lower
bound of 1/6 on the asymptotic performance ratios of our three heuristics.
Lemma 3 For any Satellite task, hF , hI , and hFI fully account for the cost of at least
one Take Image action T akeIm(o, d, s, i) for each image objective o  O.
Proof: For an image objective o = (d, m)  O, some actions T akeIm(o, d, s, i) = h{o :
0, Ci : 1, s : d}, {o : 1}i will appear in optimal plans for |Sm |  |L| fork abstract tasks rooted
105

fiKatz & Domshlak

fs,d

Action
0

T urn(s, d, d )
SwOn(i, s)
Cal(i, s)
SwOf f (i)

1
0
0
0

fs,d0
1
0
0
0

fs,d00

fs0 ,d

0
0
0
0

0
0
0
0

fCi
0
0
1
1

fCi0
0
0
0
0

o  Oi o  Os \ Oi o 6 Os
io
io
io
F I
1
0
1
1

1
0
0
0

1
2

0
0
0
0

0
1
1

1
|O s |

FI
1
|O s |+2

0

0

1
|Oi |
1
|Oi |

1
|Oi |+1
1
|Oi |+1

(a)

Action
T akeIm(o, d, s, i),
o = (d, m)

s0  Sm s0 6 Sm i0  Im i0 6 Im
fs0 ,d0
fs0 ,d0
fCi0
fCi0
io io0
1

0

1

0

1

0

F

I

FI

1
|Sm ||L|+|Im |

1

1
|Sm ||L|+|Im |+1

(b)
Figure 17: Number of representatives for each original Satellite action in each abstract
task, as well as the partition of the action costs between these representatives;
table (a) shows Turn, Switch On, Switch Off, and Calibrate actions, and
table (b) shows Take Image actions

in satellites, |Im | fork abstract tasks rooted in instrument calibration status variables Ci ,
and one inverted-fork abstract task with sink o. Together with the costs of the action
representatives in the abstract problems (see Figure 17), we have
hF : cost of each representative is
tasks,

1
|Sm ||L|+|Im |

and there are |Sm |  |L| + |Im | fork abstract

hI : cost of each representative is 1 and there is one inverted fork abstract task, and
hFI : cost of each representative is
tasks.

1
|Sm ||L|+|Im |+1

and there are |Sm |  |L| + |Im | + 1 abstract

Therefore, for each o  O, the cost of one T akeIm(o, d, s, i) action will be fully accounted
for by each of the three heuristics.

Lemma 4 For any Satellite task, hF , hI , and hFI fully account for the cost of at least
one Turn action T urn(s, d, d0 ) for each s  S0 such that I[s] 6= G[s].
Proof: If s  S0 is a satellite with I[s] 6= G[s], then an action T urn(s, I[s], d0 ) will appear
in any optimal plan for fs,I[s] , an action T urn(s, d, G[s]) will appear in any optimal plan
for fs,G[s] , and for each o  Os , an action T urn(s, d, G[s]) will appear in any optimal plan
for io . Together with the costs of the action representatives in the abstract problems (see
Figure 17) we have
hF : cost of each representative is

1
2

and there are 2 fork abstract tasks,
106

fiImplicit Abstraction Heuristics

hI : cost of each representative is
hFI : cost of each representative is

1
|Os |

and there are |Os | inverted fork abstract tasks, and

1
|Os |+2

and there are |Os | + 2 abstract tasks.

Therefore, for each s  S0 such that I[s] 6= G[s], the cost of one T urn(s, d, d0 ) action will
be fully accounted for by each of the three heuristics.

h
h

Together, Lemmas 3 and 4 imply that, for h  {hF , hI , hFI }, on Satellite we have
 1/6.

9.5.3 Upper Bound
A Satellite task on which all three heuristics achieve the ratio of exactly 1/6 consists of
two identical satellites S = {s, s0 } with l instruments each, I = Is  Is0 = {1, . . . , l}  {l +
1, . . . , 2l}, such that instruments {i, l+i} have two modes each: m0 and mi . There is a set of
n + 1 directions L = {dI , d1 , . . . , dn } and a set of n image objectives O = {o1 , . . . , on }, oi =
(dI , mi ) for 1  i  l and oi = (di , m0 ) for l < i  n. The calibration direction of
instruments {i, l + i} is di . The sas+ encoding for this planning task is as follows.
 Variables V = S  O  {Oni , Ci | i  I}.
 Initial state I = {s : dI | s  S}  {Oni : 0, Ci : 0 | i  I}  {o : 0 | o  O}.
 Goal G = {o : 1 | o  O}.
 Actions
[

A=
{T urn(s, d, d0 ) | {d, d0 }  L}  {SwOn(i, s), Cal(i, s), SwOf f (i) | i  Is } 
sS


[
sS

{T akeIm((dI , mi ), dI , s, i) | i  Is } 

n
[


{T akeIm((dj , m0 ), dj , s, i) | i  Is } .

j=l+1

The causal graph of this task is depicted in Figure 18a. The state variables {Oni , Ci |
i  I}  S have no goal value, and thus the collection of v-forks and v-iforks for this task
is as in Figure 18b. The domains of the inverted-fork sinks are binary, and the domains of
the fork roots are abstracted as in Eq. 16 (leave-one-out). This provides us with
F = {fs,d , fs0 ,d | d  L}  {fCi | i  I},
I = {io | o  O},

FI = {fs,d , fs0 ,d | d  L}  {fCi | i  I}  {io | o  O}.
The total number of forks in this task is nf = 2n + 2l + 2 and the total number of inverted
forks is ni = n. The costs of the action representatives in each abstract task are given in
0
Figure 17, where |Os | = |Os | = |O| = n, |Oi | = n  l + 1, |Sm | = 2, |Im0 | = 2l, |Imi | = 2,
and |L| = n + 1.
The optimal plans per abstract task are depicted in Table 8, while an optimal plan for
the original problem, hSwOn(1, s), T urn(s, dI , d1 ), Cal(1, s), T urn(s, d1 , dI ), T akeIm(o1 , dI , s, 1),
107

fiKatz & Domshlak

s0

s
o1

C1

ok

oi

Cl+1

Cl

Ci

ol+1

s

s0

o1 . . . on

o1 . . . on

Gsf

Gsf 0

Cl+i

C2l
s

Oni

On1

Ci

on

s0

Ci

oi

ol+1 . . . on
f
GC
,i  I
i

s

Cl+i

s0

C1 . . . C2l

Onl+i

Onl

Onl+1

On2l

oi

oi

Goi i , 1  i  l

Goi i , l < i  n

(a)

(b)

Figure 18: (a) Causal graph and (b) the corresponding collection of v-forks and v-iforks for
the Satellite task used in the proof of the upper bound of 1/6

h

hF

hI

hFI

task

optimal plan

cost

hT akeIm(o1 , dI , s0 , l+1), . . . , T akeIm(ol , dI , s0 , 2l),
fs,d
T akeIm(ol+1 , dl+1 , s0 , 2l), . . . , T akeIm(on , dn , s0 , 2l)i
hT akeIm(o1 , dI , s, 1), . . . , T akeIm(ol , dI , s, l),
f
s0 ,d
T akeIm(ol+1 , dl+1 , s, l), . . . , T akeIm(on , dn , s, l)i
hT akeIm(oi , dI , s0 , l + i),
f
 Ci , i  I s
T akeIm(ol+1 , dl+1 , s0 , 2l), . . . , T akeIm(on , dn , s0 , 2l)i
hT akeIm(oi , dI , s, i),
fCi , i  Is0
T akeIm(ol+1 , dl+1 , s, l), . . . , T akeIm(on , dn , s, l)i
ioj , 1  j  l hT urn(s, dI , dj ), Cal(j, s), T urn(s, dj , dI ), T akeIm(oj , dI , s, j)i
ioj , l < j  n hT urn(s, dI , d1 ), Cal(1, s), T urn(s, d1 , dj ), T akeIm(oj , dI , s, 1)i
hT akeIm(o1 , dI , s0 , l + 1), . . . , T akeIm(ol , dI , s0 , 2l),
fs,d
T akeIm(ol+1 , dl+1 , s0 , 2l), . . . , T akeIm(on , dn , s0 , 2l)i
hT akeIm(o1 , dI , s, 1), . . . , T akeIm(ol , dI , s, l),
f
s0 ,d
T akeIm(ol+1 , dl+1 , s, l), . . . , T akeIm(on , dn , s, l)i
hT akeIm(oi , dI , s0 , l + i),
f
 Ci , i  I s
T akeIm(ol+1 , dl+1 , s0 , 2l), . . . , T akeIm(on , dn , s0 , 2l)i
hT akeIm(oi , dI , s, i),
fCi , i  Is0
T akeIm(ol+1 , dl+1 , s, l), . . . , T akeIm(on , dn , s, l)i
ioj , 1  j  l hT urn(s, dI , dj ), Cal(j, s), T urn(s, dj , dI ), T akeIm(oj , dI , s, j)i
ioj , l < j  n hT urn(s, dI , d1 ), Cal(1, s), T urn(s, d1 , dj ), T akeIm(oj , dI , s, 1)i

#

l
2n+4

+

nl
2n+2l+2

n+1

l
2n+4

+

nl
2n+2l+2

n+1

1
2n+4

+

nl
2n+2l+2

l

nl
1
+ 2n+2l+2
2n+4
2
1
+ nl+1
+1
n
2
1
+
+1
n
nl+1

l
l
nl

h(I)

n

l
2n+5

+

nl
2n+2l+3

n+1

l
2n+5

+

nl
2n+2l+3

n+1

1
2n+5

+

nl
2n+2l+3

l

nl
1
+ 2n+2l+3
2n+5
2
1
+ nl+2 +
n+2
1
2n+5
2
1
+ nl+2
+
n+2
1
2n+2l+3

l

n + 2+
n
nl+1

n+

l

2n
n+2

+

n
nl+2

nl

Table 8: Optimal plans for the abstract tasks and the overall heuristic estimates for the
Satellite task used in the proof of the upper bound of 1/6

SwOf f (1), . . . SwOn(l  1, s), T urn(s, dI , dl1 ), Cal(l  1, s), T urn(s, dl1 , dI ), T akeIm(ol1 , dI , s, l  1),
SwOf f (l  1), SwOn(l, s), T urn(s, dI , dl ), Cal(l, s), T urn(s, dl , dI ), T akeIm(ol , dI , s, l), T urn(s, dI , dl+1 ),
T akeIm(ol+1 , dl+1 , s, l), . . . , T urn(s, dn1 , dn ), T akeIm(on , dn , s, l)i,

108

has the cost of 4l + 2n  1. For

fiImplicit Abstraction Heuristics


l = n  n, this provides us with the asymptotic performance ratio of 1/6 for all three
heuristics.

10. Summary
We considered heuristic search for cost-optimal planning and introduced a domain-independent
framework for devising admissible heuristics using additive implicit abstractions. Each such
implicit abstraction corresponds to abstracting the planning task at hand by an instance of a
tractable fragment of optimal planning. The key motivation for our investigation was to escape the restriction of explicit abstractions, such as pattern-database and merge-and-shrink
abstractions, to abstract spaces of a fixed size. We presented a concrete scheme for additive
implicit abstractions by decomposing the planning task along its causal graph and suggested
a concrete realization of this idea, called fork-decomposition, that is based on two novel fragments of tractable cost-optimal planning. We then studied the induced admissible heuristics
both formally and empirically, and showed that they favorably compete in informativeness
with the state-of-the-art admissible heuristics both in theory and in practice. Our empirical
evaluation stressed the tradeoff between the accuracy of the heuristics and runtime complexity of computing them. To alleviate the problem of expensive per-search-node runtime
complexity of fork-decomposition heuristics, we showed that an equivalent of the explicit
abstractions notion of database exists also for the fork-decomposition abstractions, and
this despite their exponential-size abstract spaces. Our subsequent empirical evaluation of
heuristic search with such databases for the fork-decomposition heuristics showed that it
favorably competes with the state of the art of cost-optimal planning.
The basic principles of the implicit abstraction framework motivate further research
in numerous directions, most importantly in (i) discovering new islands of tractability of
optimal planning, and (ii) abstracting the general planning tasks into such islands. Likewise, there is promise in combining implicit abstractions with other techniques for deriving admissible heuristic estimates. A first step towards combining implicit abstractions
with polynomial-time discoverable landmarks of the planning tasks has recently been taken
by Domshlak, Katz, and Lefler (2010). We believe that various combinations of such techniques might well improve the informativeness of the heuristics, and this without substantially increasing their runtime complexity.

Acknowledgments
The work of both authors was partly supported by Israel Science Foundation grants 670/07
and 1101/07.

109

fiKatz & Domshlak

Appendix A. Detailed Results of Empirical Evaluation
hF
task

hI

h nodes time nodes

hFI
time nodes

time

MS-104

MS-105

nodes

nodes

time

HSPF

time

nodes

9
0.00
10
0.00
18
0.03
21
0.01
22
0.01
42
0.17
42
0.17
96231549.13
89525 466.14
19
0.01
22
0.01
40
0.21
38
0.21
8968 238.16
8931 267.81
3053401077.90

9
10
29
21
22
42
42
203
12956
19
22
40
38
62
59

time

blind
nodes time

hmax
nodes time

airport-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
19
21
22
36

8
9
17
20
21
41
41
62
71
18
21
39
37
60
58
79
88
90
101
148
109

10 0.01
12 0.03
86 0.25
22 0.02
23 1.29
51336.72
51437.00

9 0.00
15 0.01
133 0.07
21 0.02
30 0.06
639 1.54
632 1.53
21544166.51

9 0.00
15 0.03
93 0.31
21 0.02
27 1.43
567 45.25
550 44.15

19 0.02
23 1.90
47554.18
43447.48

19 0.02
30 0.08
728 2.76
663 2.60
25110334.72
23317307.60

19 0.03
27 2.13
568 71.23
479 59.82

9 0.00
10 0.00
18 0.04
21 0.02
22 0.01
42 0.16
42 0.17
24372 25.42
152408 64.92
19 0.02
22 0.02
40 0.21
38 0.20
30637 51.23
28798 46.20
1031524200.95

7326372.92
1119943762.02
34365853.70

102

10.28

0.72
11 0.00
9 0.00
1.23
13 0.00
10 0.00
5.10
164 0.00
57 0.00
1.32
23 0.00
21 0.00
46.54
27 0.00
22 0.00
123.13
738 0.01
418 0.02
117.56
742 0.01
405 0.02
602.09 27032 0.28
9687 0.90
993.07 175717 2.47 56484 7.62
2.45
21 0.00
19 0.00
65.36
27 0.00
22 0.01
169.02
873 0.01
392 0.03
134.87
822 0.01
342 0.03
714.76 35384 0.39
9196 1.11
647.05 33798 0.38
8200 1.01
124746719.72 221993 49.03
1043661310.89
831632253.21
18809 0.42
3184 1.12
159967105.29
63061 1.44

blocks-ipc2
04-0
04-1
04-2
05-0
05-1
05-2
06-0
06-1
06-2
07-0
07-1
07-2
08-0
08-1
08-2
09-0
09-1
09-2
10-0
10-1
10-2
11-0
11-1
11-2
12-0
12-1
13-0
13-1
14-0
14-1

6
15 0.01
46 0.01
17 0.01
7 0.03
7
0.03
7
0.36
93 0.00
25 0.00
10
14 0.01
31 0.00
15 0.00
11 0.04
11
0.03
11
0.39
66 0.00
23 0.00
6
7 0.01
26 0.00
10 0.00
7 0.04
7
0.03
7
0.38
63 0.00
18 0.00
12
32 0.03
302 0.06
113 0.08
13 0.30
13
0.96
13
1.32
467 0.00
145 0.00
10
37 0.03
280 0.06
98 0.07
11 0.29
11
0.96
11
1.36
567 0.00
135 0.00
16
152 0.09
596 0.10
348 0.18
17 0.29
17
0.95
17
1.49
792 0.00
297 0.00
12
33 0.04
766 0.27
207 0.25
13 0.95
13
8.56
13
4.10
1826 0.00
276 0.00
10
41 0.07 2395 0.74
578 0.78
11 0.90
11
8.34
11
4.17
4887 0.01
755 0.01
20
855 0.80 5444 1.23 3352 2.88
733 0.87
85
8.84
31
4.29
6385 0.02
2556 0.03
20
278 0.56 20183 8.26 4022 8.18
577 1.93
144 23.32
22 11.47 37157 0.14
5943 0.11
22 691011.22 59207 17.37 38539 49.71
10071 1.70
1835 21.05
174 11.25 63376 0.21 33194 0.46
20 1458 2.85 46009 15.05 18854 29.61
1855 1.59
782 20.37
90 10.99 55218 0.19 18293 0.29
18 1533 4.79344157179.42 69830208.07
5557 3.67
678 36.80
25 26.00 519107 2.28 94671 2.07
20 1004027.97517514236.64191352475.33
45711 3.88
11827 33.49
151 26.57 636498 2.60 199901 3.85
16
479 1.79237140136.18 32567110.76
277 3.63
54 32.53
17 25.85 433144 1.93 52717 1.30
30
1233374 16.00 971409 77.74
464 56.76798464936.763840589 85.00
28 343518.17
95068 7.35
58873 63.15
82 56.98591457229.731200345 32.06
26 637935.22
161719 13.54
20050 82.45
81 57.02596316030.021211463 32.15
34
1800 114.26
32
12063665 228.76
1835 115.19
34
3685 116.75
32
7046739 141.44
2678 213.32
30
1510 203.79
34
3984 213.97
34
1184 370.06
34
614 382.34
42
83996 860.45
44
1634381104.27
38
27791063.02
36
71541087.40

depots-ipc3
01
02
03
04
07
10
13

10
15
27
30
21
24
25

114 0.24
113410.82

279 0.11
9344 12.40

161 0.32
2638 22.68

11 0.00
11
0.00
45
0.77
329 0.00
136 0.00
738 3.24
16
1.14
898 11.56 15404 0.11
3771 0.17
348288 20.69 239313 222.35 103089 247.13293039827.201204646 97.62
1284048 52.05 1273762 529.34
211820 37.54
41328 324.19650110071.581331701166.76
3241083157.52
1427824116.06

grid-ipc1
01
02

14
26

57160.28

1117

9.49

472 55.87

660 8.63
467 121.10
3392724 50.35 3244132 241.94

6446 0.08

190 0.10
664016231.26

Table 9: Runtimes of cost-optimal heuristic-search planners on the Airport,
Blocksworld, Depots, and Grid domains. The description of the planners is given in Section 6; here the fork-decomposition heuristics are computed
fully online. Column task denotes problem instance, column h denotes optimal
solution length. Other columns capture the run time and number of expanded
nodes.

110

fiImplicit Abstraction Heuristics

hF
task

h

nodes

hI

hFI

time

nodes

time nodes

time

0.05
18.27
0.25
19.15
45.02
5.21
9.56

37
18452
190
10778
11400
795
1730

0.01
37
10.29 15794
0.13
163
17.14 7665
18.91 10984
3.60
492
7.71 1006

0.04
23.80
0.31
29.88
46.16
6.05
13.80

HSPF

MS-104

MS-105

nodes

time

nodes

time

nodes

8 0.04
20 0.13
13 0.16
17 0.49
2614 0.60
291 1.35
14 1.42
287823 7.34
15504 1.70
18 1.64
34137 1.99
1298884 19.52

8
20
13
17
19
12
14
2952
23
18
10790
870875

0.03
0.26
0.25
2.41
4.58
9.72
15.35
20.31
10.43
18.54
17.01
35.33

44
15998
863
22933
24877
3804
25801

blind
time

nodes

time

hmax
nodes
time

driverlog-ipc3
01
02
03
04
05
06
07
08
09
10
11
13

7
19
12
16
18
11
13
22
22
17
19
26

49
15713
164
6161
13640
608
864

4304 199.81
433951421.90

198651 849.04
16099 85.74 4037 200.52
41445 186.53 390691395.51

0.47
182 0.00
20
4.55
68927 0.36
54283
1.25
16031 0.09
2498
12.20 999991 8.12 393673
18.77 6290803 61.57 1724611
10.08 681757 7.64
54451
41.34 6349767 81.53 493480

18234 68.22
5596231193.00

0.00
0.52
0.03
6.56
34.73
1.71
17.31

6141130 330.22

freecell-ipc3
01
02
03
04
05

8
234
1.54
14 30960 107.07
18 197647 877.16
26
30

974
4.88
274
3.25
75150 230.54 37131 224.62

87 3.12
31487 40.40
95805140.96
943074 86.78
5950977243.74

9 38.74

9 13.01
3437 0.03
1043
0.15
466 70.29 130883 1.46
41864 10.77
1589 169.39 944843 11.45 210503 75.62
15848 341.02 3021326 38.80 600525 247.70
40642 916.44
14080351062.25

gripper-ipc1
01
02
03
04
05
06
07

11
214
0.04
240
0.02
214
0.05
12 0.00
12 0.00
33
0.11
236 0.00
208
0.00
17
1768
0.54
1832
0.36 1803
0.75
18 0.11
18 0.08
680
0.37
1826 0.01
1760
0.01
23 11626
5.38 11736
4.05 11689
8.11
11514 0.47
2094 1.75
7370
1.52
11736 0.04
11616
0.08
29 68380 43.58 68558 35.24 68479 70.72
68380 1.24
68190 8.05
55568 10.29
68558 0.27
68368
0.56
35 376510 328.10 376784 296.59376653 560.93
376510 3.52 376510 19.46 344386 79.96 376772 1.59 376496
3.51
41
1982032 13.42 1982032 42.16 1911592 577.49 1982394 9.59 1982016 21.57
47
10091986 61.6610091986106.84
10092464 51.1010091968 119.64

logistics-ipc1
01
05
31
32
33

26
22
13
20
27

3293 945.35
436
9.67
392
2.57

1981
2704

2.53
2.24

1284
962

21.84
5.53

21
0.02
193
0.06
65
20
0.03
570
0.13
293
16
0.02
117
0.03
79
28
0.05
2550
0.98 1171
18
0.03
675
0.19
427
9
0.02
24
0.01
13
26
0.06
4249
1.85 2461
15
0.03
181
0.09
99
26
0.05
2752
1.22 1394
25
0.04
2395
0.94 1428
37
0.42 251287 203.64 98053
1689 10.08
32
0.42 82476 78.73 35805
45
0.6611836081306.92
37
0.54 351538 407.06167038
31
0.50 59336 80.88 25359
46
2.26
43
2.10
697 26.78
21959 696.23
43
2.78

0.06
0.16
0.05
1.09
0.31
0.02
2.54
0.13
1.51
1.34
386.80

1918881 41.03
768161 18.69
494 0.42
21 0.16

949586 34.82
609393 35.27
14 2.11
21 0.72
529338 32.55

2119551700.26
6.58
7.08

155645
245325

1.66
2.07

32282
81156

0.57
1.00

21 0.05
20 0.04
16 0.05
28 0.38
18 0.38
9 0.38
26 1.23
15 1.26
26 1.26
25 1.22
37 4.87
49 4.94
32 6.90
45 7.21
37 9.46
31 9.43
668834 29.73
1457130 43.00
701106 37.42

21
0.34
20
0.37
16
0.36
28
0.58
18
0.72
9
0.78
26
1.03
15
1.16
26
1.03
25
1.02
24317 35.46
362179 453.06
14890 33.50
114155 198.84
32017 83.16
6720 26.48

11246
9249
4955
109525
22307
1031
490207
24881
476661
422557

0.05
0.04
0.02
0.64
0.13
0.00
3.40
0.16
3.32
2.95

4884
4185
1205
74694
6199
280
202229
3604
200012
133521

0.03
0.03
0.01
0.59
0.05
0.00
1.92
0.03
1.98
1.29

3636

0.07

481
9598

logistics-ipc2
04-0
04-1
04-2
05-0
05-1
05-2
06-0
06-1
06-2
06-9
07-0
07-1
08-0
08-1
09-0
09-1
10-0
10-1
11-0
11-1
12-0
12-1

20
19
15
27
17
8
25
14
25
24
36
44
31
44
36
30
45
42
48
60
42
68

161.33
883.68
168.73

21
20
16
28
18
9
26
15
26
25
525
666324
1042
16708
20950
31

0.03
0.03
0.04
0.10
0.10
0.09
0.18
0.18
0.19
0.18
0.65
8.83
0.96
1.15
1.56
1.27

775996 43.56
2222340 87.47

mprime-ipc1
01
02
03
04
05
07
08
09
11
12
15
16
17
19
21
25
26
27
28
29
31
32
34
35

5
7
4
8
11
5
6
8
7
6
6
6
4
6
6
4
6
5
7
4
4
7
4
5

196
0.19
11604 422.83
427 35.09
3836
6.62
3314

14.91

10
0.03
440451620.68
7
0.50
1775
1.17
47

0.15

19838 454.91 1001881798.69
9
0.16
219
0.54
16320 192.10
8118 46.69
252 171.97

24
0.07
2565 242.83
11
3.15
1093
3.44
346

3.07

5227 284.13
8
0.16
5243 95.01
448 447.49

6 2.00
3317 88.58
36 33.64
9 6.09
1705009127.53
1667 46.72
1469752403.45
21993 36.25
8 4.69
34763 11.45

6 20.45
5463.85
9 82.71

108

49.59

19076 781.74

9868 0.67
599590 23.58
18744

8 62.68
42055143.27

22 394.26
25665 724.12

473 81.42

0.56

2197646 71.69
73260 2.21
108652 3.50
425144 32.17
172736 42.48

453 671.03
123039313.25
75

0.10

30

54
2.28
8
0.03
182
4.53
248 52.86
31759 133.33
234 11.65
392
3.09

1772
403
56
46
12436
46
290

0.04

29

0.08

33.82
9
0.23
37
1.11
32
7.83
19
34.94 11839
2.13
23
2.54
84

1.31
0.08
1.79
11.79
95.52
3.08
1.89

5 0.48
172432 46.33
6 11.59
8 1.88
5 14.92
419 99.87
19429 21.61
450151.69
359 3.63

5 2.75
189154454.69
6154.43
8 22.55
5201.40
7269292.37
6 43.43

1503293103.23
383 0.00
819590 61.01
84079 3.50
128 146.80
17333 0.25
3187 0.17
3584 0.19
110731701.00 115479 2.75
3618 0.19
706 96.55
2476 0.05
85

8.71

68
0.04
12606 36.65
5
0.07
200
0.24
14881571638.78
11
0.04
7650 84.33
19023 30.26
915
0.54
1520
1.78
1039 178.55
7962 35.65
5
1.06
36013 533.75
15250 101.75
6
0.00
440
2.69
831
2.08
211
0.06
7
0.10
11
0.17
3096
1.74
11
0.18
44
0.03

Table 10: Similar to Table 9 for the Driverlog, Freecell, Gripper, Logistics-ipc1,
Logistics-ipc2, and Mprime domains.
111

fiKatz & Domshlak

hF
task

h

nodes

hI
time

nodes

hFI
time nodes

time

MS-104

MS-105

nodes

nodes

time

time

HSPF

nodes

blind
time

nodes

time

hmax
nodes time

miconic-strips-ipc2
01-0
01-1
01-2
01-3
01-4
02-0
02-1
02-2
02-3
02-4
03-0
03-1
03-2
03-3
03-4
04-0
04-1
04-2
04-3
04-4
05-0
05-1
05-2
05-3
05-4
06-0
06-1
06-2
06-3
06-4
07-0
07-1
07-2
07-3
07-4
08-0
08-1
08-2
08-3
08-4
09-0
09-1
09-2
09-3
09-4
10-0
10-1
10-2
10-3
10-4
11-0
11-1
11-2
11-3
11-4

4
3
4
4
4
7
7
7
7
7
10
11
10
10
10
14
13
15
15
15
17
17
15
17
18
19
19
20
20
21
23
24
22
22
25
27
27
26
28
27
31
30
30
32
28
33
32
32
34
33
37
34
38
38
35

5 0.00
5
0.00
5 0.00
5 0.00
5
0.00
5 0.00
5 0.00
5
0.00
5 0.00
5 0.00
5
0.00
5 0.00
5 0.00
5
0.00
5 0.00
19 0.00
22
0.00
19 0.00
21 0.00
23
0.00
21 0.00
21 0.00
23
0.00
21 0.00
24 0.01
24
0.00
24 0.00
19 0.00
22
0.00
19 0.00
86 0.01
129
0.01
98 0.01
120 0.01
168
0.01
147 0.01
137 0.01
143
0.01
137 0.01
96 0.01
153
0.01
117 0.01
103 0.01
149
0.01
115 0.01
524 0.06
843
0.08
686 0.12
505 0.06
817
0.08
663 0.12
685 0.08
942
0.09
802 0.13
681 0.07
942
0.09
798 0.13
685 0.07
942
0.09
802 0.13
2468 0.37
4009
0.66 3307 0.93
2807 0.42
4345
0.71 3677 1.01
1596 0.29
2981
0.55 2275 0.73
2256 0.36
3799
0.62 3104 0.87
3210 0.46
4732
0.78 4267 1.11
9379 1.98 17665
4.74 13531 5.90
9106 1.93 18134
4.75 14052 5.94
10900 2.19 19084
4.90 15111 6.28
12127 2.43 21708
5.69 17807 7.19
13784 2.62 23255
5.93 19536 7.66
53662 13.29 96092 37.56 79449 46.76
56328 13.86 99109 38.56 83677 47.49
48141 12.52 96139 38.02 78471 46.17
46867 12.11 93117 36.63 75424 44.43
84250 18.24 126595 46.11111984 61.34
272580 81.51 485051 267.27408114317.78
284415 86.93 527216 288.07446837347.43
207931 66.37 414294 235.89330993271.03
369479104.29 598031 320.33527216392.87
297516 87.65 507910 278.64431432333.91
1461729497.72
1207894438.6923351661787.13
1294691460.1123404111791.16
1840936589.09
1252484467.94

5 0.00
5 0.00
4 0.00
4 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
8 0.00
11 0.00
11 0.00
12 0.00
12 0.00
11 0.00
11 0.00
11 0.00
11 0.00
11 0.00
11 0.00
15 0.01
15 0.01
14 0.01
14 0.01
16 0.01
16 0.01
16 0.01
16 0.01
16 0.01
16 0.01
18 0.06
18 0.05
18 0.06
18 0.05
16 0.06
16 0.05
18 0.06
18 0.05
19 0.06
19 0.05
20 0.18
20 0.32
20 0.18
20 0.32
21 0.18
21 0.32
21 0.17
21 0.32
22 0.17
22 0.32
24 0.32
24 1.75
7001 0.38
25 1.75
1646 0.33
23 1.71
1861 0.33
23 1.74
23159 0.52
26 1.71
41629 0.91
28 4.18
42679 0.90
28 4.25
37744 0.86
27 4.25
140453 1.94
29 4.21
62933 1.16
28 4.12
684737 9.07 126918 8.89
406041 5.61 100937 8.73
442547 6.06 82946 8.63
765455 10.00 277302 11.14
317692 4.65
29 7.03
2436164 35.24 863244 23.76
2340169 34.09 335745 15.68
1735477 25.29 486286 17.72
3952148 55.86 940556 24.24
2715866 39.44 625559 19.91
11473359183.604724980 93.56
7535468124.801934943 47.91
14645785233.686330198120.71
5809711110.10
5853546 95.561082086 32.22

5
0.01
4
0.00
5
0.01
5
0.00
5
0.01
26
0.01
26
0.01
27
0.00
20
0.01
23
0.01
100
0.03
140
0.02
122
0.02
131
0.02
114
0.02
669
0.10
634
0.11
822
0.12
820
0.12
821
0.12
2829
0.44
3260
0.49
1594
0.32
2568
0.42
3953
0.55
9312
1.76
10252
1.96
11247
2.11
14216
2.56
16880
3.04
56686 14.31
63035 16.33
55751 13.98
53121 13.27
96327 24.76
290649 104.18
339177 123.10
204614 73.39
435617 160.49
315339 111.84
1555286 794.93
1344815 683.05
1357681 692.11
20831681051.95
1231554 605.01

5 0.00
5 0.00
5 0.00
4 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
30 0.00
20 0.00
30 0.00
22 0.00
30 0.00
22 0.00
26 0.00
17 0.00
31 0.00
20 0.00
193 0.00
105 0.00
218 0.00
150 0.00
164 0.00
92 0.00
197 0.00
130 0.00
190 0.00
114 0.00
1182 0.00
866 0.00
1176 0.00
860 0.00
1277 0.00
969 0.00
1319 0.00
970 0.00
1334 0.00
969 0.00
6350 0.03
4387 0.03
6602 0.03
4664 0.03
5565 0.03
3524 0.03
5944 0.03
4140 0.03
6949 0.04
5268 0.04
30786 0.20
21194 0.20
30093 0.20
21255 0.20
32390 0.21
21694 0.21
32574 0.21
24552 0.23
33793 0.22
26167 0.24
155466 1.22 116685 1.32
164470 1.29 118494 1.33
161342 1.27 119688 1.36
155176 1.23 114649 1.30
168219 1.33 140128 1.58
755255 7.16 594032 7.95
794365 7.56 636587 8.66
731622 6.92 534711 7.37
833421 7.97 690267 9.29
771608 7.33 613253 8.43
3685552 41.04 3006991 49.12
3649801 40.32 2893803 47.54
3576134 39.61 2895182 47.26
3796035 42.13 3304570 53.29
3589382 39.29 2956995 48.84
15804498200.9013267920250.58
16472633208.3913720664256.89
15867374201.0112497087236.89
16309701208.4213801989262.53
16472551209.1313925654262.57

mystery-ipc1
01
02
03
04
07
09
11
12
15
16
17
18
19
20
24
25
26
27
28
29
30

5
7
4


8
7

6

4

6
7

4
6
5
7
4
9

7 0.01
2404 64.94
73 1.92
0 0.01
0 0.00
3049 47.68
9 0.02

0 0.14
354200.98
0 0.00

0 0.13
9 0.02
1807 50.40
14 0.27
8 0.01
31 0.26

6
0.00
8012 234.10
7
0.12
0
0.00
10764 137.61
33
0.03
2093419 938.05

85 26.31
0
0.00
4968 183.24

10
1835
159
47
14

0.01
25.34
1.61
0.02
0.10

6 0.01
722 47.50
11 0.59
0 0.00
0 0.00
1215 40.75
8 0.02

0 0.19
83 90.17
0 0.00

0 0.30
9 0.02
1344 60.20
6 0.22
15 0.02
10 0.17

6 0.20
1672 82.70
5 16.46

6

1.79

10

5.38

5193.75

65 811.87

0 0.00
0 0.00
3165 29.34
8 1.51
8 16.59
2102777 14.612102729 27.84

0
0.00
3868 670.08
34 41.20

198445.85
0 0.00
0 0.00
12478 96.38
285069 59.22 547246578.39
5 0.10
2526 5.94
6 4.80
8 0.63
5 8.94
42112 28.07

5 0.10
346 70.78
6 80.48
8 6.77
5107.10
44893357.07

0

0.00

14
1.22
3107 291.36
7 243.78
31 16.67
27 536.30

30 0.00
770852 21.85
507 0.02

0.00
4.47
0.03

0 0.00
0 0.00
138289 2.18
1458 1.44
426 0.00
19 0.00
2102777 15.09 1177842 21.87
279973 13.21
135 2.62
5400 0.41
0 0.00
133871 3.65
686125 23.28
31 0.00
8455 0.10
2174 0.03
843 0.00
153 0.01
1977063 38.26

Table 11: Similar to Table 9 for the Miconic and Mystery domains.
112

8
2368
5

5
0
1516
718

0.35
0.00
5.44
3.76

6 0.00
37 0.05
73 0.04
32 0.00
7 0.02
26686 28.27

fiImplicit Abstraction Heuristics

hF
task

h

hI

hFI

MS-104

MS-105

time

nodes

nodes

2264
0.49
3895
1.19
3070
1.36
2617
0.56
4485
1.32
3561
1.57
2264
0.49
3895
1.15
3070
1.36
2264
0.49
3895
1.15
3070
1.36
2264
0.48
3895
1.15
3070
1.35
366768 255.00 7797101599.86 5874821498.20
410728 277.99 7606681546.44 6067821515.46

24
24
24
24
24
621008
594758

nodes

time

nodes

time

nodes

time

time

HSPF

nodes

blind

hmax
nodes
time

time

nodes

time

0.06
2000
1.02
0.06
2378
1.07
0.06
2000
1.02
0.06
2000
1.02
0.05
2000
1.02
7.86 379735 217.37
7.34 405564 226.32

4822
5501
4822
4822
4822
882874
836647

0.01
0.02
0.01
0.02
0.01
4.91
4.62

4016
4594
4016
4016
4016
822514
787163

0.03
0.04
0.03
0.03
0.03
18.71
17.81

1624
2984
87189
456143

0.00
0.02
1.06
8.22

36
348
4346
104068

0.00
0.01
0.16
2.61

openstacks-ipc5
01
02
03
04
05
06
07

23
23
23
23
23
45
46

0.05
24
0.06
24
0.06
24
0.06
24
0.06
24
4.85 279614
4.69 264535

pathways-ipc5
01
02
03
04

6
12
18
17

1624
2755
44928
126950

0.03
0.08
2.59
11.45

1299
2307
20416
33788

0.02
0.06
1.06
2.97

1299
2437
29106
58738

0.03
0.09
2.14
7.07

7
1946
21671

1.14
2.56
6.43

7 0.79
13 42.11
14901129.23
98484288.39

1405
990
14772
34206

0.28
0.29
6.99
27.00

pipesworld-notankage-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
17
19
21
23
24
41

5
12
8
11
8
10
8
10
13
18
20
24
16
30
26
22
24
14
18
24
12

121
0.15
1413
2.05
1742
5.26
7007 24.71
4093 27.45
12401 105.37
4370 71.75
18851 406.67

109
0.05
1542
0.86
3001
3.31
8911 12.43
6805 19.74
27377 103.75
9168 68.10
56189 483.28

121
0.18
1413
2.42
1742
6.43
7007 30.79
4093 35.40
12401 140.53
4370 105.53
20584 600.94

4729501577.22
117475 899.72

238331663.46

49035 495.53

6 0.04
6 0.04
6
2.79
121 0.00
13
0.00
169 0.30
13 0.17
435
3.07
1808 0.01
792
0.02
9 1.15
9 0.69
128
3.84
3293 0.02
262
0.02
651 1.95
12 7.05
812
8.84
16088 0.11
2925
0.13
77 5.63
9 21.15
155 16.53
11128 0.12
1121
0.15
1299 5.26
61 39.31
1151 23.41
49905 0.48
7102
0.72
233 19.78
9 59.70
185 29.88
46502 0.57
2631
0.48
561 12.42
497 94.69
1673 48.84 273585 3.39
22874
3.58
104875 25.48
10478 74.26 5513309 80.62 321861 68.99
2982520 66.89
6898321439.64
111212451579.77
90598 9.20 52159 43.24 108503 625.52 710123 3.86 107061 14.51
594661 12.41 416184109.43 4332961117.57 2467804 13.83 464982 56.82
12835 34.28
242241019.65 481045 3.14
33417
6.38
13255718119.54
648132 65.43
4921698 34.90 555619 105.49
3200672 90.07
8767431150.88
3992 18.13
948159.63
157782 1.31
8966
2.42
296506 49.11 104750256.13
481859 229.00
7315150142.82
114257 250.18

pipesworld-tankage-ipc4
01
02
03
04
05
06
07
08
11
13
15
17
21
31

5
12
8
11
8
10
8
11
22
16
30
44
14
39

77
0.13
126
0.07
105
0.20
960
1.20
1005
0.60
960
1.55
20803 155.53 52139 158.91 20803 207.57
1102841004.10 157722 668.67 1102841408.50
6531 73.63 13148 79.04
6531 112.61
20171 329.40 43583 310.24 20171 460.45

6 3.54
110 3.04
244 22.64
3892 16.68
376 15.46
1794328.18

6 0.13
13 0.20
9 36.89
12155.03
9120.06
11201.44

6
3.88
128 0.00
179
6.04
1012 0.01
818 24.47
52983 0.77
8116 64.68 221429 3.06
313 59.99
12764 0.21
3102 97.31
58487 0.87
2695 339.76 5404036198.08

13
0.01
659
0.02
1802
1.33
41540 14.49
2834
1.61
15746
6.61
104531 420.47

4116344 30.67

752867 334.42

4423951 65.44
1726598 13.56

126845 222.23
919764 381.66

96043191.77
660104 28.60 660102162.93
188517122.11
2546587141.12
12850247352.46
13241 69.80
1357801124.64

tpp-ipc5
01
02
03
04
05
06

5
8
11
14
19
25

6
9
12
15
623

0.00
0.00
0.00
0.01
0.52

6
11
27
78
5110

0.00
0.00
0.00
0.01
1.36

6
9
16
47
1455

0.00
0.00
0.00
0.01
1.21

6 0.00
9 0.00
12 0.00
15 0.01
20 0.36
947059 14.22

6 0.00
9 0.00
12 0.00
15 0.00
20 0.77
74798 23.97

6
9
12
15
624

0.01
0.01
0.03
0.07
0.48

7
26
116
494
24698

0.00
0.00
0.00
0.00
0.12

6
0.00
16
0.00
83
0.00
430
0.00
17398
0.15
9267024 216.69

trucks-ipc5
01
02
03
04
05
06
07
08
09

13
1691
0.41
1027
0.22
1039
0.40
14 0.03
14 0.02
285
0.56
5774 0.02
402
0.01
17
9624
2.68
2898
0.57
2957
1.35
4192 0.22
18 0.17
1413
1.04
28348 0.14
939
0.03
20
80693 71.37 20752 19.93 22236 31.25
199405 2.89 173790 6.88
4049
4.43 379582 2.97
9465
0.40
23 17538661237.601205793 850.3413156721394.88 2591561 29.172568634 56.96
8817
7.75 2990366 26.65 209140
9.43
25
23444940392.99
14744 23.12
1248571 90.78
30
308920 343.47
23 21347281313.60 719751 408.75 755608 820.55 7575415 88.918080496117.13 43270 27.6212410588117.92 223011 19.34
25
49663 47.61
3106944 403.36
28
233577 248.21

Table 12: Similar to Table 9 for the Openstacks, Pathways, Pipesworld-NoTankage,
Pipesworld-Tankage, TPP, and Trucks domains.

113

fiKatz & Domshlak

hF
task

h

nodes

hI
time

nodes

hFI
time

nodes

time

MS-104

MS-105

nodes time

nodes

time

HSPF

nodes

blind
time

hmax
nodes time

nodes

time

0.00
9
0.01
11
0.00
20
0.08
71
0.00
20
0.04
33
0.00
12
0.34
332
0.00
23
0.11
154
0.00
9
0.01
11
0.00
26
0.09
122
0.00
9
0.12
128
0.00
9
0.06
49
0.04
18
1.04
1358
0.00
96
0.19
153
0.00
40
0.17
153
0.00
59
0.16
95
0.00
13
0.06
27
2.58
356 18.99
3562
0.12
2287
1.34
2742
0.00
13
0.03
16
0.00
29
0.21
158
0.77
6338
4.46
9009
0.00
52
0.18
84
0.00
21
0.12
42
0.87
22315
8.16 189516
0.01
30
0.43
200
0.00
21
0.12
42
37.93
28 780.38
8913
0.00
52
0.28
182
0.01
179
0.85
773
0.00
49
0.29
95
1.43
3337
7.12 244499
0.02
393
1.35
2295
6.55
7530 32.97 53911
0.00
352
0.74
435
0.63
947
2.29
2291
0.00
158
0.50
227
6.36
7448
8.27 165170
14.07 188564 111.991669788
0.01
277
2.10
1532
0.01
33
0.74
562
0.07
146
1.78
4103
12.86
23371 87.911036992
0.00
21
0.16
54
0.18
1773
1.29
1908
0.00
256
0.50
333
0.05
407
2.18
4142
0.00
121
0.74
434
4.05
19865
6.91 80785
0.04
515
2.32
5075
11.08 200559 101.21
23.32 27728751408.64
0.02
390
1.40
690

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.02
0.01
0.00
0.00
0.04
0.00
0.00
0.67
0.00
0.00
0.12
0.00
0.00
0.00
1.27
0.01
0.25
0.00
0.01
0.00
0.63
9.44
0.00
0.00
0.01
6.74
0.00
0.01
0.00
0.01
0.00
0.25
0.01

9 0.00
47 0.00
28 0.00
102 0.00
69 0.00
9 0.00
62 0.00
52 0.00
20 0.00
376 0.01
142 0.00
113 0.00
86 0.00
18 0.00
324 0.02
1876 0.01
14 0.00
91 0.00
6925 0.08
75 0.00
31 0.00
177138 1.43
116 0.00
31 0.00
854 0.18
142 0.00
616 0.00
79 0.00
192459 2.32
1834 0.01
16766 0.36
424 0.00
1073 0.01
216 0.00
61548 1.06
717884 18.27
1342 0.01
357 0.00
2597 0.02
229210 9.51
35 0.00
1636 0.01
315 0.00
3235 0.02
358 0.00
65984 0.63
4406 0.02
19020089286.02

0.00

642

psr-small-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50

8
11
11
10
11
8
11
8
8
7
19
16
15
9
10
25
9
12
25
17
10
33
12
10
9
17
21
14
21
22
19
24
21
21
22
22
23
13
23
20
10
30
20
19
20
34
27
37
47
23

10
52
31
66
75
10
61
24
18
131
149
120
90
19
1200
2328
15
85
8025
80
28
163299
77
28
485
144
616
79
142772
1791
11278
431
1480
223
65965
571766
1307
301
2486
31
1855
328
2990
347
60888
4104

637

0.00
10
0.00
10
0.00
0.01
55
0.00
52
0.01
0.01
31
0.00
31
0.00
0.04
91
0.03
73
0.06
0.01
79
0.01
75
0.02
0.00
10
0.00
10
0.00
0.01
61
0.00
61
0.01
0.01
29
0.00
25
0.01
0.01
19
0.00
18
0.00
0.20
183
0.18
155
0.32
0.03
149
0.02
149
0.04
0.03
123
0.02
120
0.04
0.02
90
0.01
90
0.02
0.00
19
0.00
19
0.00
6.55
708
6.25
769
9.91
0.65
2158
0.34
2176
0.85
0.00
15
0.00
15
0.00
0.03
90
0.01
85
0.03
4.31
7856
2.19
7876
5.80
0.02
80
0.01
80
0.02
0.01
28
0.00
28
0.01
405.65 176058 245.42 168685 617.45
0.04
93
0.03
77
0.06
0.01
28
0.00
28
0.01
84.24
463 145.38
482 213.42
0.05
150
0.03
146
0.06
0.33
675
0.21
650
0.49
0.02
79
0.01
79
0.02
436.34 187319 307.77 159325 709.89
1.25
1982
0.80
1883
1.90
25.93
6810 38.66
8297 53.43
0.17
431
0.10
431
0.25
0.84
1436
0.30
1391
1.00
0.07
223
0.04
223
0.09
160.36 63186 39.55 68281 199.30
392.49 371834 786.06 4584021094.61
1.29
1417
0.95
1363
2.10
0.20
372
0.15
326
0.32
2.49
2942
1.64
2682
3.91
1826081384.90
0.01
34
0.00
31
0.01
0.50
1747
0.17
1739
0.59
0.09
328
0.05
328
0.12
3.25
3430
2.30
3121
5.24
0.16
376
0.11
359
0.25
51.77 61842 21.14 61563 68.33
5.27
4522
3.93
4284
8.70

0.39

659

0.26

645

9 0.00
9
12 0.00
12
12 0.00
12
11 0.00
11
12 0.00
12
9 0.00
9
12 0.00
12
9 0.00
9
9 0.00
9
8 0.04
8
20 0.00
20
17 0.00
17
16 0.00
16
10 0.00
10
11 0.46
11
975 0.11
26
10 0.00
10
13 0.00
13
2910 0.27
26
18 0.00
18
11 0.00
11
34 0.28
34
13 0.00
13
11 0.00
11
10 5.42
10
18 0.00
18
22 0.01
22
15 0.00
15
22 0.39
22
23 0.01
23
2647 0.89
723
25 0.00
25
446 0.26
22
22 0.00
22
24021 0.83 11113
48350 2.98
2783
24 0.02
24
14 0.01
14
24 0.08
24
38837 1.88
7767
11 0.00
11
1117 0.18
31
21 0.00
21
20 0.05
20
21 0.01
21
36941 0.67 32582
28 0.04
28
129627 2.37
2500
204836815.84 594399
0.60
24 0.02
24

0.00

rovers-ipc5
01
02
03
04
05
07
12

10
8
11
8
22
18
19

147
0.01
147
0.01
147
0.02
11 0.03
11 0.03
48
0.07
1104 0.00
283 0.00
44
0.01
44
0.01
44
0.01
9 0.00
9 0.00
16
0.03
254 0.00
129 0.00
672
0.11
419
0.05
448
0.10
12 0.11
12 0.12
804
0.16
3543 0.02
757 0.00
47
0.02
20
0.00
24
0.01
9 0.04
9 0.04
58
0.08
897 0.00
223 0.00
808084 237.13 410712 123.64 522937 231.28 61726711.48 375808 18.46 298400 101.658559690126.19 4318309 81.53
741649 517.1816822451780.27 328088451.022212903 59.20 1459792 866.93
9618062199.91
5187273166.77

satellite-ipc4
01
02
03
04
05
06

9
24
0.00
32
0.00
13
86
0.02
337
0.10
11
2249
1.24
656
0.53
17
9817 10.65 14860 24.90
15 2795691251.83 46453 515.80
20 1496577 968.2415723271721.87

29
0.00
241
0.13
728
0.82
11250 26.18
61692 877.26

10 0.00
10 0.00
14 0.01
14 0.01
12 0.56
12 0.64
4152 0.99
18 4.43
81972 7.26 148667 69.28
276922974.73 307962 32.52

46
0.06
89
646
0.21
1728
1945
0.93 15185
15890
9.50 345663
267513 565.18

2 0.00
2 0.00
7 0.00
7 0.00
7 0.21
7 0.90
9 0.20
9 0.89
12 0.25
12 1.90
12 0.38
12 3.54
16 0.38
16 3.48
14354 2.00
12 14.48
251703551.18 611457 30.47
132287134.84 137872 25.44
31003011.28 110726 26.65

2
0.45
2
9
0.46
58
40
3.42
5160
215
3.44
5256
422
7.70 82289
1957 11.81 596531
34890 30.36 405626
83533 292.05

0.00
0.01
0.17
4.70

59
940
6822
180815

0.00
0.00
0.11
3.37

10751017371.43

zenotravel-ipc3
01
02
03
04
05
06
07
08
09
10
11

1
6
6
8
11
11
15
11
21
22
14

2
17
28
99
177
2287
5088
3268

0.01
0.02
0.08
0.15
0.32
5.51
9.63
43.96

2
18
18
88
220
1144
4234
1026

0.00
0.02
0.12
0.26
0.22
2.00
5.56
8.92

769041090.67

2
17
12
81
136
504
4199
1655

0.01
0.02
0.11
0.30
0.36
2.40
10.58
30.06

0.00
0.00
0.04
0.03
0.63
5.90
3.56

2 0.00
22 0.00
492 0.02
665 0.01
12466 0.33
85931 2.47
115348 2.60
687846 50.76

Table 13: Similar to Table 9 for the PSR, Rovers, Satellite, and Zenotravel domains.

114

fiImplicit Abstraction Heuristics

hF
task

h nodes

hI
timenodes

hFI
timenodes

MS-104
time nodes

MS-105

timenodes

HSPF

time nodes

blind
hmax
time nodes time nodes
time

schedule-strips
02-0
02-1
02-2
02-3
02-4
02-5
02-6
02-7
02-8
02-9
03-0
03-1
03-2
03-3
03-4
03-5
03-6
03-7
03-8
03-9
04-0
04-1
04-2
04-3
04-4
04-5
04-6
04-7
04-8
04-9
05-0
05-1
05-3
05-4
05-5
05-6
05-7
05-8
05-9
06-2
06-4
07-0
07-9

3
5
0.15
5
0.14
5
0.22
2
3
0.16
4
0.11
3
0.18
2
3
0.32
3
0.17
3
0.40
3
26
0.50
37
0.76
26
0.61
3
68
1.34 188
2.24 220
7.20
2
3
0.33
3
0.14
3
0.38
2
3
0.14
5
0.12
3
0.17
2
3
0.30
3
0.13
3
0.34
2
3
0.32
3
0.14
3
0.38
3
5
0.15
5
0.14
5
0.22
4
40
2.72 407 12.16 140 14.55
2
3
0.51
3
0.35
3
0.72
4
27
1.16
50
1.83
33
2.33
4
15
0.79
91
2.39
15
0.96
3
4
1.11
16
2.08
4
1.52
4
73
6.13 471 16.71
74
8.32
4
72
1.27
75
1.80
69
1.33
4
28
1.05
50
1.83
28
1.43
4
273 11.53 266 11.46 273 17.48
4
8
0.96
31
1.77
14
2.13
5
373 13.91 1498 74.46 167 24.60
6 175591373.8010707 626.54
5
209
9.88 406 20.85
66
5.30
5
142 10.47 674 33.29 251 29.28
5
921 64.48 450 46.95 574 116.65
6
483 47.25 4544 268.77 850 187.46
6
779 27.0911610 361.74 1834 102.68
5
99 18.48 424 38.04 163 40.04
5
102 16.01 573 31.87 111 23.35
4 1043 80.06 996 76.64 1050 143.48
5
163 41.61 483 63.23 167 62.53
6 2701 213.92
1257 286.28
7
136221693.68
6
989 100.02 3433 229.05 582 100.05
6
198 21.67 9550 767.94 347 68.64
7 6033 743.61
103251508.56
6
944 131.19175621446.20 2107 379.70
7 1190 172.59
2709 730.54
6 1537 140.49158291248.19 2717 547.56
6
888 243.14
1709 730.36
8 115351776.87
7 2489 786.76
8 68291559.86

4 511.10
3 104.98
3 231.99
4 56.51
3
3
3
3
4

363.11
121.84
323.77
316.53
251.46

5 191.03
5 259.13
5 682.30
5 121.58
5 195.72
5 235.48
71115.76
6 267.29
7
7
6
6
5

837.68
459.19
936.68
711.65
316.22

41743.32

5
3
3
4
4
3
3
3
3
5

577.39
754.26
495.56
658.90
484.62
667.32
697.42
604.06
668.79
577.16

76 0.02
5
0.09
6 0.02
3
0.07
5 0.02
3
0.07
529 0.03
95
0.45
543 0.03
108
0.44
3 0.03
3
0.07
6 0.02
3
0.06
13 0.02
3
0.07
8 0.02
3
0.07
76 0.03
5
0.09
11915 0.60 1127
8.98
31 0.04
25
0.37
3617 0.23 1228
9.56
3379 0.23
170
1.85
41223.90
301 0.06
22
0.27
12217 0.64 1175 12.43
2663 0.19 1542 11.73
12859 0.68 1323 13.47
12616 0.65 1590 11.13
4339 0.27
913
7.69
31219326.88 22993 273.38
55206949.79
47696 4.97 9703 131.69
89272 8.74 12941 163.84
62013 6.03 13614 168.07
1079781399.99
1071151001.40
61327 5.97 8683 103.50
34046729.56 15122 181.98
41673 4.27 5480 83.69
14335022.71 43336 751.35

120602 989.42

Table 14: Similar to Table 9 for the (non-IPC) Schedule-STRIPS domain.

115

fiKatz & Domshlak
hF
task

h

nodes

hI
time

nodes

hFI
time

nodes

time

MS-104

MS-105

nodes

nodes

time

HSPF

time

nodes

9
0.00
10
0.00
18
0.03
21
0.01
22
0.01
42
0.17
42
0.17
96231549.13
89525 466.14
19
0.01
22
0.01
40
0.21
38
0.21
8968 238.16
8931 267.81
3053401077.90

9
10
29
21
22
42
42
203
12956
19
22
40
38
62
59

time

blind
nodes time

hmax
nodes time

airport-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
19
21
22
36
37

8
10
0.01
9 0.00
9
0.00
9 0.00
9
12
0.01
15 0.00
15
0.01
10 0.00
17
86
0.02
133 0.01
93
0.02
18 0.04
20
22
0.01
21 0.00
21
0.01
21 0.02
21
23
0.08
30 0.02
27
0.09
22 0.01
41
513
0.16
639 0.06
567
0.19
42 0.16
41
514
0.15
632 0.05
550
0.19
42 0.17
62
12733
1.89 21544 1.36 14398
4.02
24372 25.42
71
88670 16.58 136717 9.60 90412 38.78 152408 64.92
18
19
0.01
19 0.01
19
0.01
19 0.02
21
23
0.10
30 0.03
27
0.12
22 0.02
39
475
0.20
728 0.07
568
0.25
40 0.21
37
434
0.20
663 0.07
479
0.24
38 0.20
60
12040
2.90 25110 1.86 15948
4.64
30637 51.23
58
11477
2.74 23317 1.71 14557
4.25
28798 46.20
79 267277 77.39 824491 97.12 353592 114.58 1031524200.95
88 2460667 708.82
26786891235.79
90 1354353 592.533400142492.061462739 660.17
101
5156 48.29 11259 3.72
4773 51.13
7326372.92
148 6066481110.091063668318.90 4778361082.91 1119943762.02
109
9504 129.73 34986 14.41
9436 140.75
34365853.70
142
37873 820.33

102

10.28

0.72
11 0.00
9 0.00
1.23
13 0.00
10 0.00
5.10
164 0.00
57 0.00
1.32
23 0.00
21 0.00
46.54
27 0.00
22 0.00
123.13
738 0.01
418 0.02
117.56
742 0.01
405 0.02
602.09 27032 0.28
9687 0.90
993.07 175717 2.47 56484 7.62
2.45
21 0.00
19 0.00
65.36
27 0.00
22 0.01
169.02
873 0.01
392 0.03
134.87
822 0.01
342 0.03
714.76 35384 0.39
9196 1.11
647.05 33798 0.38
8200 1.01
124746719.72 221993 49.03
1043661310.89
831632253.21
18809 0.42
3184 1.12
159967105.29
63061 1.44

blocks-ipc2
04-0
04-1
04-2
05-0
05-1
05-2
06-0
06-1
06-2
07-0
07-1
07-2
08-0
08-1
08-2
09-0
09-1
09-2
10-0
10-1
10-2
11-0
11-1
11-2
12-0
12-1
13-0
13-1
14-0
14-1

6
15
10
14
6
7
12
32
10
37
16
152
12
33
10
41
20
855
20
278
22
6910
20
1458
18
1533
20
10040
16
479
30 134185
28
3435
26
6379
34 1524599
32 610206
34 1516087
32
30
34
34
34
42
44
38
36

0.00
46 0.00
17
0.00
7 0.03
7
0.03
0.00
31 0.00
15
0.00
11 0.04
11
0.03
0.00
26 0.00
10
0.00
7 0.04
7
0.03
0.00
302 0.01
113
0.00
13 0.30
13
0.96
0.00
280 0.00
98
0.00
11 0.29
11
0.96
0.00
596 0.00
348
0.01
17 0.29
17
0.95
0.00
766 0.01
207
0.01
13 0.95
13
8.56
0.00
2395 0.03
578
0.02
11 0.90
11
8.34
0.01
5444 0.05
3352
0.06
733 0.87
85
8.84
0.01 20183 0.28
4022
0.12
577 1.93
144 23.32
0.10 59207 0.60 38539
0.67
10071 1.70
1835 21.05
0.02 46009 0.52 18854
0.39
1855 1.59
782 20.37
0.03 344157 5.46 69830
2.09
5557 3.67
678 36.80
0.17 517514 7.22 191352
4.91
45711 3.88
11827 33.49
0.02 237140 4.08 32567
1.09
277 3.63
54 32.53
3.107405904117.144346535 118.23 1233374 16.00 971409 77.74
0.094145371 77.54 917197 33.32
95068 7.35
58873 63.15
0.174145278 78.21 923365 33.79 161719 13.54
20050 82.45
36.52
15.79
12063665 228.76
37.71
7046739 141.44

7
0.36
93 0.00
25 0.00
11
0.39
66 0.00
23 0.00
7
0.38
63 0.00
18 0.00
13
1.32
467 0.00
145 0.00
11
1.36
567 0.00
135 0.00
17
1.49
792 0.00
297 0.00
13
4.10
1826 0.00
276 0.00
11
4.17
4887 0.01
755 0.01
31
4.29
6385 0.02
2556 0.03
22 11.47 37157 0.14
5943 0.11
174 11.25 63376 0.21 33194 0.46
90 10.99 55218 0.19 18293 0.29
25 26.00 519107 2.28 94671 2.07
151 26.57 636498 2.60 199901 3.85
17 25.85 433144 1.93 52717 1.30
464 56.76798464936.763840589 85.00
82 56.98591457229.731200345 32.06
81 57.02596316030.021211463 32.15
1800 114.26
1835 115.19
3685 116.75
2678 213.32
1510 203.79
3984 213.97
1184 370.06
614 382.34
83996 860.45
1634381104.27
27791063.02
71541087.40

depots-ipc3
01
02
03
04
07
10
13

10
114
0.01
279 0.01
161
0.02
11 0.00
11
0.00
45
0.77
329 0.00
136 0.00
15
1134
0.08
9344 0.31
2638
0.22
738 3.24
16
1.14
898 11.56 15404 0.11
3771 0.17
27 134428
8.592520703159.84 581726 66.43 348288 20.69 239313 222.35 103089 247.13293039827.201204646 97.62
30 1254545 101.18
5835295 923.87 1284048 52.05 1273762 529.34
21 109765
9.174271196336.59 487961 76.02 211820 37.54
41328 324.19650110071.581331701166.76
24 2964635 283.55
60814781187.66 3241083157.52
25 1003709 152.30
81618721559.21 1427824116.06

driverlog-ipc3
01
02
03
04
05
06
07
08
09
10
11
13

7
49
0.00
37 0.00
37
0.00
8 0.04
19
15713
0.42 18452 0.27 15794
0.55
20 0.13
12
164
0.00
190 0.00
163
0.01
13 0.16
16
6161
0.42 10778 0.30
7665
0.62
17 0.49
18
13640
1.01 11400 0.36 10984
1.07
2614 0.60
11
608
0.09
795 0.06
492
0.11
291 1.35
13
864
0.14
1730 0.11
1006
0.21
14 1.42
22 669994 75.741181268 61.32 694996 104.59 287823 7.34
22 150255 14.72 198651 11.44 164109 23.06
15504 1.70
17
4304
0.44 16099 1.21
4037
0.69
18 1.64
19
43395
4.99 41445 2.22 39069
5.90
34137 1.99
26 1303099 325.711014865144.641098694 422.20 1298884 19.52

8
20
13
17
19
12
14
2952
23
18
10790
870875

0.03
44
0.47
182 0.00
20 0.00
0.26 15998
4.55 68927 0.36 54283 0.52
0.25
863
1.25 16031 0.09
2498 0.03
2.41 22933 12.20 999991 8.12 393673 6.56
4.58 24877 18.77629080361.571724611 34.73
9.72
3804 10.08 681757 7.64 54451 1.71
15.35 25801 41.34634976781.53 493480 17.31
20.31
10.43
18.54 18234 68.22
17.01 5596231193.00
6141130330.22
35.33

Table 15: Runtimes of cost-optimal heuristic-search planners on the Airport,
Blocksworld, Depots, and Driverlog domains.
The description of
the planners is given in Section 6; here the fork-decomposition heuristics are via
structural-pattern databases. Column task denotes problem instance, column
h denotes optimal solution length. Other columns capture the run time and
number of expanded nodes.
116

fiImplicit Abstraction Heuristics

hF
taskh

nodes

hI
time

nodes

hFI
time

nodes

time

MS-104

MS-105

nodes

nodes

time

time

HSPF

nodes

blind
time

nodes

time

hmax
nodes
time

freecell-ipc3
01
02
03
04
05

8
14
18
26
30

234
0.10
974
0.15
274 0.17
30960
1.95
75150
5.53
37131 4.79
197647 14.41 533995 78.27 240161 51.24
997836 60.67 1921470 232.95 1218329213.02
6510089 448.22

87 3.12
31487 40.40
95805140.96
943074 86.78
5950977243.74

9 38.74

9 13.01
3437 0.03
1043
0.15
466 70.29 130883 1.46
41864 10.77
1589 169.39 944843 11.45 210503 75.62
15848 341.02 3021326 38.80 600525 247.70
40642 916.44
14080351062.25

grid-ipc1
01
02

14
26

571
0.60
33302741078.55

1117

0.34

472

0.78

660 8.63
467121.10
3392724 50.35 3244132241.94

6446

0.08

190
0.10
664016 231.26

gripper-ipc1
01
02
03
04
05
06
07

11
214
0.00
240
0.00
214 0.00
12 0.00
12 0.00
33
0.11
236 0.00
208
0.00
17
1768
0.02
1832
0.01
1803 0.03
18 0.11
18 0.08
680
0.37
1826 0.01
1760
0.01
23
11626
0.19
11736
0.08
11689 0.22
11514 0.47
2094 1.75
7370
1.52
11736 0.04
11616
0.08
29
68380
1.46
68558
0.51
68479 1.63
68380 1.24
68190 8.05
55568 10.29
68558 0.27
68368
0.56
35
376510 10.07 376784
3.20 376653 11.11
376510 3.52 376510 19.46 344386 79.96 376772 1.59 376496
3.51
41 1982032 70.91 1982408 19.08 1982227 77.81 1982032 13.42 1982032 42.16 1911592 577.49 1982394 9.59 1982016 21.57
47 10091986 438.4110092464 105.6710092241478.67 10091986 61.6610091986106.84
10092464 51.1010091968 119.64

logistics-ipc1
01
05
31
32
33
35

26
22
13
20
27
30

77763
7.14 1469610
3293
0.46 850312
436
0.03
1981
392
0.01
2704
312180 27.19
477883 183.08

95.49
42.43
0.07
0.07

830292 98.59
173477 18.19
1284 0.09
962 0.05
3617185427.52

1918881 41.03
768161 18.69
494 0.42
21 0.16

949586 34.82
609393 35.27
14 2.11
21 0.72
529338 32.55

2119551700.26
6.58
7.08

155645
245325

1.66
2.07

32282
81156

0.57
1.00

21 0.05
20 0.04
16 0.05
28 0.38
18 0.38
9 0.38
26 1.23
15 1.26
26 1.26
25 1.22
37 4.87
49 4.94
32 6.90
45 7.21
37 9.46
31 9.43
668834 29.73
1457130 43.00
701106 37.42

21
0.34
20
0.37
16
0.36
28
0.58
18
0.72
9
0.78
26
1.03
15
1.16
26
1.03
25
1.02
24317 35.46
362179 453.06
14890 33.50
114155 198.84
32017 83.16
6720 26.48

11246
9249
4955
109525
22307
1031
490207
24881
476661
422557

0.05
0.04
0.02
0.64
0.13
0.00
3.40
0.16
3.32
2.95

4884
4185
1205
74694
6199
280
202229
3604
200012
133521

0.03
0.03
0.01
0.59
0.05
0.00
1.92
0.03
1.98
1.29

3636

0.07

481
9598

logistics-ipc2
04-0 20
04-1 19
04-2 15
05-0 27
05-1 17
05-2 8
06-0 25
06-1 14
06-2 25
06-9 24
07-0 36
07-1 44
08-0 31
08-1 44
09-0 36
09-1 30
10-0 45
10-1 42
11-0 48
11-1 60
12-0 42
12-1 68

21
20
16
28
18
9
26
15
26
25
37
1689
32
45
37
31
46
43
697
21959
43
106534

0.00
193
0.00
570
0.00
117
0.00
2550
0.00
675
0.00
24
0.00
4249
0.00
181
0.00
2752
0.00
2395
0.00 251287
0.07 3532213
0.00
82476
0.01 1183608
0.00 351538
0.00
59336
0.01
0.01
0.09
2.22
0.02
11.64

0.00
65 0.00
0.01
293 0.00
0.00
79 0.00
0.05
1171 0.03
0.01
427 0.01
0.00
13 0.00
0.09
2461 0.07
0.00
99 0.00
0.06
1394 0.04
0.04
1428 0.04
7.52
98053 4.59
99.33 1705009 72.35
2.69
35805 1.78
45.72 462244 25.36
13.75 167038 9.76
2.48
25359 1.73

21
20
16
28
18
9
26
15
26
25
525
666324
1042
16708
20950
31

0.03
0.03
0.04
0.10
0.10
0.09
0.18
0.18
0.19
0.18
0.65
8.83
0.96
1.15
1.56
1.27

775996 43.56
2222340 87.47

mprime-ipc1
01
02
03
04
05
07
08
09
11
12
15
16
17
19
21
25
26
27
28
29
31
32
34
35

5
7
4
8
11
5
6
8
7
6
6
6
4
6
6
4
6
5
7
4
4
7
4
5

196
0.02
10
0.01
11604
2.72
44045 80.68
427
0.27
7
0.08
3836
0.22
1775
0.10
1745027 195.08
3314
0.25
47
0.03
485381 491.53 13767801426.21
19838
2.92 100188 74.85
9
0.02
219
0.03
16320
1.89
8118
0.73
252
0.76
2746 10.47
727401 521.78
174221 55.09
75
0.01
77622 24.69
54
0.16
8
0.01
182
0.12
248
0.51
31759
1.73
234
0.26
392
0.07

51590 135.00
453 18.78
95361 485.79
34022 47.43
30
0.01
147854 48.25
1772
1.50
403
0.02
56
0.08
46
0.68
12436
1.46
46
0.16
290
0.06

24 0.01
2565 4.20
11 0.16
1093 0.09
604756592.60
346 0.08
5227
8
5243

6.31
0.03
1.13

448 2.76
451 21.40

6 2.00
3317 88.58
36 33.64
9 6.09
1705009127.53
1667 46.72
1469752403.45
21993 36.25
8 4.69
34763 11.45

6 20.45
5463.85
9 82.71

108

49.59

19076 781.74

9868 0.67
599590 23.58
18744

8 62.68
42055143.27

0.56

2197646 71.69
22 394.26
73260 2.21
25665 724.12 108652 3.50

473 81.42

425144 32.17
172736 42.48

123039313.25
169400392.30
29 0.01
68239106.35
9 0.18
37 0.02
32 0.11
19 1.00
11839 1.93
23 0.28
84 0.08

5 0.48
172432 46.33
6 11.59
8 1.88
5 14.92
419 99.87
19429 21.61
450151.69
359 3.63

5 2.75
189154454.69
6154.43
8 22.55
5201.40
7269292.37
6 43.43

1503293103.23
383 0.00
819590 61.01
84079 3.50
128 146.80
17333 0.25
3187 0.17
3584 0.19
110731701.00 115479 2.75
3618 0.19
706 96.55
2476 0.05
85

8.71

68
0.04
12606 36.65
5
0.07
200
0.24
14881571638.78
11
0.04
7650 84.33
19023 30.26
915
0.54
1520
1.78
1039 178.55
7962 35.65
5
1.06
36013 533.75
15250 101.75
6
0.00
440
2.69
831
2.08
211
0.06
7
0.10
11
0.17
3096
1.74
11
0.18
44
0.03

Table 16: Similar to Table 15 for the Freecell, Grid, Gripper, Logistics-ipc1,
Logistics-ipc2, and Mprime domains.

117

fiKatz & Domshlak

hF
task

h

nodes

hI
time

nodes

hFI
time

nodes

time

MS-104

MS-105

nodes

nodes

time

time

HSPF

nodes

blind
time

nodes

time

hmax
nodes time

miconic-strips-ipc2
01-0
01-1
01-2
01-3
01-4
02-0
02-1
02-2
02-3
02-4
03-0
03-1
03-2
03-3
03-4
04-0
04-1
04-2
04-3
04-4
05-0
05-1
05-2
05-3
05-4
06-0
06-1
06-2
06-3
06-4
07-0
07-1
07-2
07-3
07-4
08-0
08-1
08-2
08-3
08-4
09-0
09-1
09-2
09-3
09-4
10-0
10-1
10-2
10-3
10-4
11-0
11-1
11-2
11-3
11-4

4
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
3
5 0.00
5 0.00
5 0.00
4 0.00
4 0.00
4
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
4
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
4
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
7
19 0.00
22 0.00
19 0.00
8 0.00
8 0.00
7
21 0.00
23 0.00
21 0.00
8 0.00
8 0.00
7
21 0.00
23 0.00
21 0.00
8 0.00
8 0.00
7
24 0.00
24 0.00
24 0.00
8 0.00
8 0.00
7
19 0.00
22 0.00
19 0.00
8 0.00
8 0.00
10
86 0.00
129 0.00
98 0.00
11 0.00
11 0.00
11
120 0.00
168 0.00
147 0.00
12 0.00
12 0.00
10
137 0.00
143 0.00
137 0.00
11 0.00
11 0.00
10
96 0.00
153 0.00
117 0.00
11 0.00
11 0.00
10
103 0.00
149 0.00
115 0.00
11 0.00
11 0.00
14
524 0.00
843 0.00
686 0.01
15 0.01
15 0.01
13
505 0.00
817 0.00
663 0.01
14 0.01
14 0.01
15
685 0.00
942 0.00
802 0.01
16 0.01
16 0.01
15
681 0.00
942 0.00
798 0.01
16 0.01
16 0.01
15
685 0.00
942 0.00
802 0.01
16 0.01
16 0.01
17
2468 0.03
4009 0.03
3307 0.05
18 0.06
18 0.05
17
2807 0.04
4345 0.03
3677 0.06
18 0.06
18 0.05
15
1596 0.02
2981 0.02
2275 0.04
16 0.06
16 0.05
17
2256 0.03
3799 0.03
3104 0.05
18 0.06
18 0.05
18
3210 0.04
4732 0.03
4267 0.06
19 0.06
19 0.05
19
9379 0.18
17665 0.15 13531 0.26
20 0.18
20 0.32
19
9106 0.17
18134 0.15 14052 0.27
20 0.18
20 0.32
20
10900 0.20
19084 0.16 15111 0.28
21 0.18
21 0.32
20
12127 0.23
21708 0.18 17807 0.33
21 0.17
21 0.32
21
13784 0.24
23255 0.19 19536 0.35
22 0.17
22 0.32
23
53662 1.19
96092 0.97 79449 1.76
24 0.32
24 1.75
24
56328 1.24
99109 0.96 83677 1.83
7001 0.38
25 1.75
22
48141 1.10
96139 0.94 78471 1.77
1646 0.33
23 1.71
22
46867 1.08
93117 0.92 75424 1.69
1861 0.33
23 1.74
25
84250 1.70 126595 1.22 111984 2.36
23159 0.52
26 1.71
27
272580 7.05 485051 5.51 408114 10.53
41629 0.91
28 4.18
27
284415 7.56 527216 6.01 446837 11.58
42679 0.90
28 4.25
26
207931 5.60 414294 4.79 330993 8.90
37744 0.86
27 4.25
28
369479 9.25 598031 6.74 527216 13.30
140453 1.94
29 4.21
27
297516 7.74 507910 5.79 431432 11.04
62933 1.16
28 4.12
31 1461729 43.82 2491975 32.672138656 63.58
684737 9.07 126918 8.89
30 1207894 37.47 2335166 30.761952916 59.39
406041 5.61 100937 8.73
30 1294691 40.03 2340411 30.971972234 59.25
442547 6.06 82946 8.63
32 1840936 52.68 2889342 38.122571844 74.47
765455 10.00 277302 11.14
28 1252484 40.34 2352633 31.351944297 59.37
317692 4.65
29 7.03
33 5716041202.3710316603153.808774563300.08 2436164 35.24 863244 23.76
32 5601282201.4310789013162.699144153315.23 2340169 34.09 335745 15.68
32 4153191155.86 9148616138.697466572265.86 1735477 25.29 486286 17.72
34 6108094214.6810960203167.109400386320.13 3952148 55.86 940556 24.24
33 5920127211.4011075136170.829448049322.74 2715866 39.44 625559 19.91
37
11473359183.604724980 93.56
34 15349953668.77
7535468124.801934943 47.91
38
14645785233.686330198120.71
38
5809711110.10
35
5853546 95.561082086 32.22

5
0.01
4
0.00
5
0.01
5
0.00
5
0.01
26
0.01
26
0.01
27
0.00
20
0.01
23
0.01
100
0.03
140
0.02
122
0.02
131
0.02
114
0.02
669
0.10
634
0.11
822
0.12
820
0.12
821
0.12
2829
0.44
3260
0.49
1594
0.32
2568
0.42
3953
0.55
9312
1.76
10252
1.96
11247
2.11
14216
2.56
16880
3.04
56686 14.31
63035 16.33
55751 13.98
53121 13.27
96327 24.76
290649 104.18
339177 123.10
204614 73.39
435617 160.49
315339 111.84
1555286 794.93
1344815 683.05
1357681 692.11
20831681051.95
1231554 605.01

5 0.00
5 0.00
5 0.00
4 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
5 0.00
30 0.00
20 0.00
30 0.00
22 0.00
30 0.00
22 0.00
26 0.00
17 0.00
31 0.00
20 0.00
193 0.00
105 0.00
218 0.00
150 0.00
164 0.00
92 0.00
197 0.00
130 0.00
190 0.00
114 0.00
1182 0.00
866 0.00
1176 0.00
860 0.00
1277 0.00
969 0.00
1319 0.00
970 0.00
1334 0.00
969 0.00
6350 0.03
4387 0.03
6602 0.03
4664 0.03
5565 0.03
3524 0.03
5944 0.03
4140 0.03
6949 0.04
5268 0.04
30786 0.20
21194 0.20
30093 0.20
21255 0.20
32390 0.21
21694 0.21
32574 0.21
24552 0.23
33793 0.22
26167 0.24
155466 1.22 116685 1.32
164470 1.29 118494 1.33
161342 1.27 119688 1.36
155176 1.23 114649 1.30
168219 1.33 140128 1.58
755255 7.16 594032 7.95
794365 7.56 636587 8.66
731622 6.92 534711 7.37
833421 7.97 690267 9.29
771608 7.33 613253 8.43
3685552 41.04 3006991 49.12
3649801 40.32 2893803 47.54
3576134 39.61 2895182 47.26
3796035 42.13 3304570 53.29
3589382 39.29 2956995 48.84
15804498200.9013267920250.58
16472633208.3913720664256.89
15867374201.0112497087236.89
16309701208.4213801989262.53
16472551209.1313925654262.57

mystery-ipc1
01
02
03
04
07
09
11
12
15
16
17
18
19
20
24
25
26
27
28
29
30

5
7
4


8
7

6

4

6
7

4
6
5
7
4
9

7 0.00
6 0.00
6 0.00
2404 0.50
8012 11.19
722 1.01
73 0.08
7 0.04
11 0.10
0 0.00
0 0.00
0 0.00
0 0.00
0 0.00
3049 0.37
10764 5.66
1215 1.01
9 0.01
33 0.01
8 0.01
2102777 33.84 2093419 55.582093419 76.80
28271 20.21
21572 41.22
5079 44.42
0 0.15
0 0.27
354 1.32
85 2.74
83 3.59
0 0.00
0 0.00
0 0.00
21717 4.87
4968 5.26 16276 29.28
89887 46.32
84572153.53 53114173.34
0 0.13
0 0.30
9 0.00
10 0.00
9 0.01
1807 0.27
1835 0.30
1344 0.69
14 0.05
159 0.09
6 0.07
8 0.00
47 0.00
15 0.00
31 0.04
14 0.03
10 0.06
23175 5.16
76480169.86
7232 13.30

6 0.20
1672 82.70
5 16.46

6

1.79

10

5.38

5193.75

65 811.87

0 0.00
0 0.00
3165 29.34
8 1.51
8 16.59
2102777 14.612102729 27.84

0
0.00
3868 670.08
34 41.20

198445.85
0 0.00
0 0.00
12478 96.38
285069 59.22 547246578.39
5 0.10
2526 5.94
6 4.80
8 0.63
5 8.94
42112 28.07

5 0.10
346 70.78
6 80.48
8 6.77
5107.10
44893357.07

0

0.00

14
1.22
3107 291.36
7 243.78
31 16.67
27 536.30

30 0.00
770852 21.85
507 0.02

0.00
4.47
0.03

0 0.00
0 0.00
138289 2.18
1458 1.44
426 0.00
19 0.00
2102777 15.09 1177842 21.87
279973 13.21
135 2.62
5400 0.41
0 0.00
133871 3.65
686125 23.28
31 0.00
8455 0.10
2174 0.03
843 0.00
153 0.01
1977063 38.26

Table 17: Similar to Table 15 for the Miconic and Mystery domains.
118

8
2368
5

5
0
1516
718

0.35
0.00
5.44
3.76

6 0.00
37 0.05
73 0.04
32 0.00
7 0.02
26686 28.27

fiImplicit Abstraction Heuristics

hF
task h

nodes

hI
time

nodes

hFI

MS-104

MS-105

nodes

time

nodes

nodes

time

0.03
3070
0.04
3561
0.03
3070
0.03
3070
0.03
3070
18.93 587482
18.33 606782

0.05
0.05
0.05
0.05
0.05
22.20
22.53

24
24
24
24
24
621008
594758

0.05
24
0.06
24
0.06
24
0.06
24
0.06
24
4.85 279614
4.69 264535

0.06
0.06
0.06
0.06
0.05
7.86
7.34

0.00
0.02
0.43
1.31

7
1946
21671

time

time

HSPF

nodes

blind
time

hmax
nodes
time

nodes

time

2000
1.02
4822
2378
1.07
5501
2000
1.02
4822
2000
1.02
4822
2000
1.02
4822
379735 217.37 882874
405564 226.32 836647

0.01
0.02
0.01
0.02
0.01
4.91
4.62

4016
4594
4016
4016
4016
822514
787163

0.03
0.04
0.03
0.03
0.03
18.71
17.81

0.00
0.02
1.06
8.22

36
348
4346
104068

0.00
0.01
0.16
2.61

openstacks-ipc5
01
02
03
04
05
06
07

23
23
23
23
23
45
46

2264
2617
2264
2264
2264
366768
410728

0.02
3895
0.03
4485
0.02
3895
0.02
3895
0.02
3895
7.52 779710
8.23 760668

pathways-ipc5
01
02
03
04

6
12
18
17

1624
2755
44928
126950

0.00
0.02
0.62
2.66

1299
2307
20416
33788

0.00
0.01
0.25
0.59

1299
2437
29106
58738

1.14
2.56
6.43

7 0.79
13 42.11
14901129.23
98484288.39

1405
990
14772
34206

0.28
1624
0.29
2984
6.99 87189
27.00 456143

pipesworld-notankage-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
17
19
21
23
24
41

5
12
8
11
8
10
8
10
13
18
20
24
16
30
26
22
24
14
18
24
12

121
0.02
109
0.01
121
0.02
1413
0.06
1542
0.02
1413
0.08
1742
0.14
3001
0.07
1742
0.18
7007
0.45
8911
0.22
7007
0.59
4093
0.49
6805
0.26
4093
0.65
12401
1.44 27377
1.34 12401
2.03
4370
0.97
9168
0.77
4370
1.34
18851
3.84 56189
6.21 20584
6.42
1092472 160.712419903 151.991092472 219.75
313952
684234
39998

27.68 472950 29.55 313952 43.90
75.721319980 133.58 686186 145.41
6.02 117475 18.08 40226 12.69

1594863 254.432588849 192.901594863 353.40
54373931588.68
23833
4.02 49035
7.76 23833
7.87
2285790 568.937047138 871.032282678 843.28
502308 370.68

6 0.04
6 0.04
169 0.30
13 0.17
9 1.15
9 0.69
651 1.95
12 7.05
77 5.63
9 21.15
1299 5.26
61 39.31
233 19.78
9 59.70
561 12.42
497 94.69
104875 25.48
2982520 66.89
90598 9.20 52159 43.24
594661 12.41 416184109.43
12835 34.28
13255718119.54
648132 65.43
3200672 90.07
8767431150.88
3992 18.13
948159.63
296506 49.11 104750256.13
7315150142.82

6
2.79
121 0.00
13
0.00
435
3.07
1808 0.01
792
0.02
128
3.84
3293 0.02
262
0.02
812
8.84 16088 0.11
2925
0.13
155 16.53 11128 0.12
1121
0.15
1151 23.41 49905 0.48
7102
0.72
185 29.88 46502 0.57
2631
0.48
1673 48.84 273585 3.39
22874
3.58
10478 74.265513309 80.62 321861 68.99
6898321439.64
111212451579.77
108503 625.52 710123 3.86 107061 14.51
4332961117.572467804 13.83 464982 56.82
242241019.65 481045 3.14
33417
6.38
4921698 34.90

157782

1.31

5023081092.50

555619 105.49

8966
2.42
481859 229.00
114257 250.18

pipesworld-tankage-ipc4
01
02
03
04
05
06
07
08
11
13
15
17
21
31

5
77
0.02
126
0.01
105
0.02
6 3.54
6 0.13
12
960
0.05
1005
0.02
960
0.06
110 3.04
13 0.20
8
20803
1.89 52139
2.46 20803
2.82
244 22.64
9 36.89
11 110284
8.06 157722
9.60 110284 14.05
3892 16.68
12155.03
8
6531
0.86 13148
1.03
6531
1.32
376 15.46
9120.06
10
20171
2.41 43583
4.32 20171
4.41
1794328.18
11201.44
8 202706 73.8326437521379.11 202706 208.81
11
96043191.77
22 2345399 296.872629204 662.942365735 838.85
660104 28.60 660102162.93
16
188517122.11
30 96520911721.67
2546587141.12
44
12850247352.46
14 839847 250.39
13241 69.80
39 1501847 240.381568963 661.881504072 850.16 1357801124.64

6
3.88
128 0.00
179
6.04
1012 0.01
818 24.47 52983 0.77
8116 64.68 221429 3.06
313 59.99 12764 0.21
3102 97.31 58487 0.87
2695 339.765404036198.08

13
0.01
659
0.02
1802
1.33
41540 14.49
2834
1.61
15746
6.61
104531 420.47

4116344 30.67

752867 334.42

4423951 65.44
1726598 13.56

126845 222.23
919764 381.66

rovers-ipc5
01
02
03
04
05
07
12

10
147
0.00
147
8
44
0.00
44
11
672
0.01
419
8
47
0.00
20
22 808084 22.61 410712
18 4546797 191.34 741649
19
1529551

0.00
147
0.00
0.00
44
0.00
0.00
448
0.01
0.00
24
0.00
9.23 522937 18.29
21.011682245 102.77
76.46

11 0.03
11 0.03
48
0.07
1104 0.00
283
0.00
9 0.00
9 0.00
16
0.03
254 0.00
129
0.00
12 0.11
12 0.12
804
0.16
3543 0.02
757
0.00
9 0.04
9 0.04
58
0.08
897 0.00
223
0.00
617267 11.48 375808 18.46 298400 101.658559690126.19 4318309 81.53
3280884 51.022212903 59.20 1459792 866.93
9618062 199.91
5187273166.77

0.00
29
0.00
0.00
241
0.01
0.01
728
0.04
0.38 11250
0.76
4.92 61692 18.85
51.681518261 105.65

10 0.00
10 0.00
14 0.01
14 0.01
12 0.56
12 0.64
4152 0.99
18 4.43
81972 7.26 148667 69.28
2769229 74.73 307962 32.52

satellite-ipc4
01
02
03
04
05
06

9
24
13
86
11
2249
17
9817
15 279569
20 1496577

0.00
32
0.00
337
0.08
656
0.57 14860
49.47 46453
92.221572327

46
0.06
89
646
0.21
1728
1945
0.93 15185
15890
9.50 345663
267513 565.18

0.00
0.01
0.17
4.70

59
940
6822
180815

0.00
0.00
0.11
3.37

10751017 371.43

Table 18: Similar to Table 15 for the Openstacks, Pathways, PipesworldNoTankage, Pipesworld-Tankage, Rovers, and Satellite domains.

119

fiKatz & Domshlak

hF
task h

nodes

hI
time

nodes

hFI
time

nodes

time

MS-104

MS-105

nodes

nodes

time

time

HSPF

nodes

blind
time

hmax
nodes time

nodes

time

0.00
9
0.01
11
0.00
20
0.08
71
0.00
20
0.04
33
0.00
12
0.34
332
0.00
23
0.11
154
0.00
9
0.01
11
0.00
26
0.09
122
0.00
9
0.12
128
0.00
9
0.06
49
0.04
18
1.04
1358
0.00
96
0.19
153
0.00
40
0.17
153
0.00
59
0.16
95
0.00
13
0.06
27
2.58
356 18.99
3562
0.12
2287
1.34
2742
0.00
13
0.03
16
0.00
29
0.21
158
0.77
6338
4.46
9009
0.00
52
0.18
84
0.00
21
0.12
42
0.87
22315
8.16 189516
0.01
30
0.43
200
0.00
21
0.12
42
37.93
28 780.38
8913
0.00
52
0.28
182
0.01
179
0.85
773
0.00
49
0.29
95
1.43
3337
7.12 244499
0.02
393
1.35
2295
6.55
7530 32.97
53911
0.00
352
0.74
435
0.63
947
2.29
2291
0.00
158
0.50
227
6.36
7448
8.27 165170
14.07 188564 111.99 1669788
0.01
277
2.10
1532
0.01
33
0.74
562
0.07
146
1.78
4103
12.86
23371 87.91 1036992
0.00
21
0.16
54
0.18
1773
1.29
1908
0.00
256
0.50
333
0.05
407
2.18
4142
0.00
121
0.74
434
4.05
19865
6.91
80785
0.04
515
2.32
5075
11.08 200559 101.21
23.32 27728751408.64
0.02
390
1.40
690

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.02
0.01
0.00
0.00
0.04
0.00
0.00
0.67
0.00
0.00
0.12
0.00
0.00
0.00
1.27
0.01
0.25
0.00
0.01
0.00
0.63
9.44
0.00
0.00
0.01
6.74
0.00
0.01
0.00
0.01
0.00
0.25
0.01

9 0.00
47 0.00
28 0.00
102 0.00
69 0.00
9 0.00
62 0.00
52 0.00
20 0.00
376 0.01
142 0.00
113 0.00
86 0.00
18 0.00
324 0.02
1876 0.01
14 0.00
91 0.00
6925 0.08
75 0.00
31 0.00
177138 1.43
116 0.00
31 0.00
854 0.18
142 0.00
616 0.00
79 0.00
192459 2.32
1834 0.01
16766 0.36
424 0.00
1073 0.01
216 0.00
61548 1.06
717884 18.27
1342 0.01
357 0.00
2597 0.02
229210 9.51
35 0.00
1636 0.01
315 0.00
3235 0.02
358 0.00
65984 0.63
4406 0.02
19020089286.02

0.00

642

psr-small-ipc4
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50

8
10 0.00
10 0.00
10 0.00
11
52 0.00
55 0.00
52 0.00
11
31 0.00
31 0.00
31 0.00
10
66 0.00
91 0.00
73 0.00
11
75 0.00
79 0.00
75 0.00
8
10 0.00
10 0.00
10 0.00
11
61 0.00
61 0.00
61 0.00
8
24 0.00
29 0.00
25 0.00
8
18 0.00
19 0.00
18 0.00
7
131 0.01
183 0.00
155 0.01
19
149 0.00
149 0.00
149 0.00
16
120 0.00
123 0.00
120 0.00
15
90 0.00
90 0.00
90 0.00
9
19 0.00
19 0.00
19 0.00
10
1200 0.08
708 0.03
769 0.09
25
2328 0.02
2158 0.01
2176 0.03
9
15 0.00
15 0.00
15 0.00
12
85 0.00
90 0.00
85 0.00
25
8025 0.11
7856 0.05
7876 0.12
17
80 0.00
80 0.00
80 0.00
10
28 0.00
28 0.00
28 0.00
33
163299 4.17 176058 1.56 168685 5.01
12
77 0.00
93 0.00
77 0.00
10
28 0.00
28 0.00
28 0.00
9
485 3.06
463 0.58
482 3.28
17
144 0.00
150 0.00
146 0.00
21
616 0.01
675 0.00
650 0.01
14
79 0.00
79 0.00
79 0.00
21
142772 4.55 187319 2.12 159325 5.80
22
1791 0.03
1982 0.01
1883 0.04
19
11278 0.25
6810 0.08
8297 0.24
24
431 0.01
431 0.00
431 0.01
21
1480 0.02
1436 0.01
1391 0.03
21
223 0.00
223 0.00
223 0.00
22
65965 1.43
63186 0.46
68281 1.70
22
571766 12.62 371834 3.41 458402 11.77
23
1307 0.03
1417 0.01
1363 0.03
13
301 0.01
372 0.00
326 0.01
23
2486 0.05
2942 0.02
2682 0.07
20
259683 8.59 182608 2.70 270195 11.73
10
31 0.00
34 0.00
31 0.00
30
1855 0.02
1747 0.01
1739 0.02
20
328 0.00
328 0.00
328 0.00
19
2990 0.07
3430 0.03
3121 0.08
20
347 0.00
376 0.00
359 0.01
34
60888 0.86
61842 0.31
61563 0.99
27
4104 0.09
4522 0.03
4284 0.11
37 12080249604.4317435137247.2013514084784.80
47
23
637 0.01
659 0.01
645 0.02

9 0.00
9
12 0.00
12
12 0.00
12
11 0.00
11
12 0.00
12
9 0.00
9
12 0.00
12
9 0.00
9
9 0.00
9
8 0.04
8
20 0.00
20
17 0.00
17
16 0.00
16
10 0.00
10
11 0.46
11
975 0.11
26
10 0.00
10
13 0.00
13
2910 0.27
26
18 0.00
18
11 0.00
11
34 0.28
34
13 0.00
13
11 0.00
11
10 5.42
10
18 0.00
18
22 0.01
22
15 0.00
15
22 0.39
22
23 0.01
23
2647 0.89
723
25 0.00
25
446 0.26
22
22 0.00
22
24021 0.83 11113
48350 2.98
2783
24 0.02
24
14 0.01
14
24 0.08
24
38837 1.88
7767
11 0.00
11
1117 0.18
31
21 0.00
21
20 0.05
20
21 0.01
21
36941 0.67 32582
28 0.04
28
129627 2.37
2500
2048368 15.84 594399
24 0.02
24

0.00

tpp-ipc5
01
02
03
04
05
06

5
8
11
14
19
25

6 0.00
6 0.00
6 0.00
9 0.00
11 0.00
9 0.00
12 0.00
27 0.00
16 0.00
15 0.00
78 0.00
47 0.00
623 0.02
5110 0.08
1455 0.05
5843306179.03 6916518 95.86 6153923222.35

6 0.00
9 0.00
12 0.00
15 0.01
20 0.36
947059 14.22

6 0.00
9 0.00
12 0.00
15 0.00
20 0.77
74798 23.97

6
9
12
15
624

0.01
0.01
0.03
0.07
0.48

7
26
116
494
24698

0.00
0.00
0.00
0.00
0.12

6 0.00
16 0.00
83 0.00
430 0.00
17398 0.15
9267024216.69

trucks-ipc5
01
02
03
04
05
06
07
08
09

13
1691 0.03
1027 0.01
1039 0.03
14 0.03
14 0.02
17
9624 0.23
2898 0.04
2957 0.11
4192 0.22
18 0.17
20
80693 2.99
20752 0.44
22236 1.14
199405 2.89 173790 6.88
23 1753866 48.55 1205793 23.48 1315672 50.35 2591561 29.172568634 56.96
25 12472562515.50 8007189242.98 9483222512.55 23444940392.99
30
23 2134728 96.15 719751 16.91 755608 50.72 7575415 88.918080496117.13
25
5199440221.76 6630689687.95
28

285
0.56
5774 0.02
402 0.01
1413
1.04
28348 0.14
939 0.03
4049
4.43 379582 2.97
9465 0.40
8817
7.75 2990366 26.65 209140 9.43
14744 23.12
1248571 90.78
308920 343.47
43270 27.6212410588117.92 223011 19.34
49663 47.61
3106944403.36
233577 248.21

zenotravel-ipc3
01
02
03
04
05
06
07
08
09
10
11

1
6
6
8
11
11
15
11
21
22
14

2 0.00
2 0.00
2 0.00
17 0.00
18 0.00
17 0.00
28 0.01
18 0.01
12 0.01
99 0.01
88 0.01
81 0.01
177 0.01
220 0.01
136 0.02
2287 0.10
1144 0.05
504 0.05
5088 0.16
4234 0.09
4199 0.19
3268 0.35
1026 0.12
1655 0.32
2844771177.70 2842546176.05 2433822262.84
2283679295.65 1921903196.38 1832871383.99
139687 18.63
76904 8.20
93782 19.51

2 0.00
2 0.00
7 0.00
7 0.00
7 0.21
7 0.90
9 0.20
9 0.89
12 0.25
12 1.90
12 0.38
12 3.54
16 0.38
16 3.48
14354 2.00
12 14.48
2517035 51.18 611457 30.47
1322871 34.84 137872 25.44
310030 11.28 110726 26.65

2
0.45
9
0.46
40
3.42
215
3.44
422
7.70
1957 11.81
34890 30.36
83533 292.05

2
58
5160
5256
82289
596531
405626

0.00
0.00
0.04
0.03
0.63
5.90
3.56

2 0.00
22 0.00
492 0.02
665 0.01
12466 0.33
85931 2.47
115348 2.60
687846 50.76

Table 19: Similar to Table 15 for the PSR, TPP, Trucks, and Zenotravel domains.
120

fiImplicit Abstraction Heuristics

hF
task

h

hI

hFI

nodes timenodes time nodes

MS-104
time nodes

MS-105

timenodes

HSPF

time nodes

blind
hmax
time nodes time nodes
time

schedule-strips
02-0
02-1
02-2
02-3
02-4
02-5
02-6
02-7
02-8
02-9
03-0
03-1
03-2
03-3
03-4
03-5
03-6
03-7
03-8
03-9
04-0
04-1
04-2
04-3
04-4
04-5
04-6
04-7
04-8
04-9
05-0
05-1
05-2
05-3
05-4
05-5
05-6
05-7
05-8
05-9
06-2
06-4
06-6
07-0
07-7
07-9

3
5 0.07
5 0.04
5 0.08
2
3 0.08
4 0.05
3 0.10
2
3 0.17
3 0.06
3 0.19
3
26 0.17
37 0.06
26 0.18
3
68 0.17 188 0.07
220 0.26
2
3 0.17
3 0.05
3 0.19
2
3 0.07
5 0.04
3 0.09
2
3 0.15
3 0.05
3 0.17
2
3 0.17
3 0.05
3 0.19
3
5 0.07
5 0.04
5 0.08
4
40 0.31 407 0.16
140 0.45
2
3 0.22
3 0.08
3 0.25
4
27 0.21
50 0.09
33 0.25
4
15 0.13
91 0.09
15 0.15
3
4 0.39
16 0.10
4 0.44
4
73 0.38 471 0.14
74 0.43
4
72 0.12
75 0.08
69 0.13
4
28 0.23
50 0.09
28 0.25
4
273 0.43 266 0.14
273 0.48
4
8 0.23
31 0.09
14 0.27
5
373 0.45 1498 0.50
167 0.54
6 1755915.4510707 3.48 17686 17.58
5
209 0.40 406 0.19
66 0.34
5
142 0.40 674 0.25
251 0.58
5
921 1.14 450 0.31
574 1.39
6
483 0.95 4544 1.11
850 2.11
6
779 0.5611610 2.44 1834 1.43
5
99 0.58 424 0.31
163 0.78
5
102 0.52 573 0.24
111 0.60
4
1043 1.27 996 0.67 1050 1.66
5
163 0.86 483 0.51
167 1.05
6
2701 2.951887811.36 1257 3.10
7 11885586.65
158640178.66
7 2715924.884144713.08 13622 16.72
6
989 1.63 3433 1.29
582 1.36
6
198 0.61 9550 4.61
347 1.05
7
603311.164987316.17 10325 16.63
6
944 1.9217562 9.03 2107 4.10
7
1190 2.436153920.22 2709 7.24
6
1537 2.2415829 6.85 2717 5.45
6
888 3.292698622.47 1709 6.91
8 1153520.81
56273131.69
8 1558946.68
41764133.76
7
2489 9.10
6995 25.49
8 1072641.01
38251154.49
8
682919.20
30148109.49

4 511.10
3 104.98
3 231.99
4 56.51
3
3
3
3
4

363.11
121.84
323.77
316.53
251.46

5 191.03
5 259.13
5 682.30
5 121.58
5 195.72
5 235.48
71115.76
6 267.29
7
7
6
6
5

837.68
459.19
936.68
711.65
316.22

41743.32

5
3
3
4
4
3
3
3
3
5

577.39
754.26
495.56
658.90
484.62
667.32
697.42
604.06
668.79
577.16

76 0.02
5
0.09
6 0.02
3
0.07
5 0.02
3
0.07
529 0.03
95
0.45
543 0.03
108
0.44
3 0.03
3
0.07
6 0.02
3
0.06
13 0.02
3
0.07
8 0.02
3
0.07
76 0.03
5
0.09
11915 0.60 1127
8.98
31 0.04
25
0.37
3617 0.23 1228
9.56
3379 0.23
170
1.85
41223.90
301 0.06
22
0.27
12217 0.64 1175 12.43
2663 0.19 1542 11.73
12859 0.68 1323 13.47
12616 0.65 1590 11.13
4339 0.27
913
7.69
31219326.88 22993 273.38
55206949.79
47696 4.97 9703 131.69
89272 8.74 12941 163.84
62013 6.03 13614 168.07
1079781399.99
1071151001.40
61327 5.97 8683 103.50
34046729.56 15122 181.98
41673 4.27 5480 83.69
14335022.71 43336 751.35

120602 989.42

Table 20: Similar to Table 15 for the (non-IPC) Schedule-STRIPS domain.

121

fiKatz & Domshlak

hF
task

h

nodes

hI

hFI

HSPF

blind

time

nodes

time

nodes

time

nodes

time

nodes

time

0.39
0.45
4.00
10.59
68.19
125.83
1.34
3.39
18.43
43.80
31.37
327.82
5.99
112.11
335.39
291.88
203.57
249.28

10507
5184
219439
294029
3269854
3869775
50734
78362
432280
1325517
2823019

0.84
1.12
13.43
74.29
290.07
1167.78
4.64
23.84
66.00
337.57
570.43

8333
4044
139760
146396
2113017
1965371
31545
46386
297147
687420
1255479

1.03
1.46
15.62
62.26
317.53
965.39
5.00
21.36
68.80
290.86
425.27

12935
4810
276441
278087

30.55
42.63
469.96
885.94

26670
16162
650316
1025329
9567169

0.40
0.49
11.32
29.51
174.38

72109
74663

190.25
325.43

145170
152021
1426461
6238743

2.53
4.47
32.06
199.63

79574
859710
10935187

9.93
349.90
1208.05

66582
757718
7542146

13.62
395.63
1319.93

123510

443.99

194669
1633295

4.28
57.19

4430537

1578.04

49
144
317
2208
4220
998
61253
70808
4920
5261
98783
10580
398023
157304
711526
411732
421646
34754
812451
473553
173929

0.37
0.73
1.32
2.63
4.87
5.66
40.74
57.12
18.26
23.40
105.44
43.05
443.57
222.14
1034.92
671.53
745.34
186.40
1731.49
1018.62
651.93

193
769
1665
8113
17151
3288
201137
234328
114281
72673
563261
341169
2547985
1233115
11926297
4928793
8065113
953049

0.00
0.00
0.01
0.06
0.16
0.02
2.31
2.92
1.32
0.76
7.17
4.11
35.07
17.19
184.57
75.73
128.80
14.32

1536764

27.62

12
19
334
993
6922
19613
10
153
8348
422571
9
22
260
2281
68293
121897

0.20
1.44
0.72
11.21
35.00
115.36
0.55
3.39
18.14
792.78
0.09
0.51
2.03
6.38
145.47
404.98

20
1375
4903
12302518

0.00
0.01
0.03
126.46

23
5138
1130810

0.00
0.05
12.72

16
2485
285823

0.00
0.02
3.32

44047
45529
45882
10175657
10310817
10321465
54
54
54
10170980
10254740
10294023

0.68
0.54
0.49
314.87
242.27
222.66
0.01
0.01
0.01
113.29
95.91
88.03

elevators-strips-ipc6
01
02
03
04
05
06
11
12
13
14
15
18
21
22
23
24
25
26

42
26
55
40
55
53
56
54
59
63
66
61
48
54
69
56
63
48

7483
2898
61649
60039
909822
716238
18313
21812
186526
248709
201777
1057327
71003
890048
4089071
1430559
1384406
699757

openstacks-strips-ipc6
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
18
19
21
22

2
2
2
3
4
2
5
5
3
3
4
3
4
4
4
4
4
3
4
3
4

209
769
1729
8209
16705
3658
195109
228847
116425
77681
575677
354913
2596593
1260363
11995225
5064737
8193065
1020905

0.00
0.02
0.04
0.17
0.41
0.11
5.85
7.77
5.03
3.57
28.75
19.85
150.86
81.43
867.27
379.45
673.91
88.15

209
769
1729
8209
16705
3658
195109
228847
116425
77681
575677
354913
2596593
1260363
11995225
5064737
8193065
1020905

0.00
0.00
0.01
0.07
0.18
0.04
2.45
3.23
1.61
1.10
9.11
5.63
46.30
23.36
245.32
104.37
179.00
22.24

209
769
1729
8209
16705
3658
195109
228847
116425
77681
575677
354913
2596593
1260363
11995225
5064737
8193065
1020905

0.00
0.02
0.04
0.20
0.48
0.13
6.85
9.06
5.77
4.14
32.97
22.85
172.13
93.01
987.24
432.44
765.15
99.67

1805050

204.83

1805050

48.73

1805050

233.98

0.01
0.02
0.04
13.85
219.49
613.02
0.01
0.07
5.83
463.93
0.00
0.01
0.28
8.49

15
183
821
77520
892002
3529327
24
1243
144084

0.00
0.01
0.01
2.28
31.78
148.95
0.00
0.04
4.27

15
179
668
68116
822442
3443221
24
1135
97683

0.00
0.02
0.03
7.56
115.96
557.75
0.01
0.08
9.25

13
303
15825
694503

0.00
0.01
0.47
24.62

13
282
8778
316839

0.00
0.02
0.63
31.37

1.68
1.88
1.90
687.38
870.50
869.52
0.14
0.15
0.14
834.36
720.23
643.41

22012
37569
43298

5.20
4.36
4.02

19809
37524
43298

6.39
6.07
5.71

21259
29253
37754

13.69
13.92
14.05

51
51
51

0.08
0.08
0.08

46
46
46

0.20
0.19
0.19

6
6
6

0.05
0.05
0.05

parcprinter-strips-ipc6
01
02
03
04
05
06
11
12
13
14
21
22
23
24
25
26

169009
438047
807114
876094
1145132
1514200
182808
510256
693064
1020512
143411
375821
519232
751642
1215840
1216460

19
240
880
142314
1780073
4113487
25
1183
74201
4491265
13
225
4376
96748

scanalyzer-strips-ipc6
01
02
03
04
05
06
22
23
24
25
26
27

18
22
26
24
30
36
13
13
13
26
30
34

19788
37182
43115
3947796
9193480
10140909
46
46
46
8974317
9936832
10202674

Table 21: Runtimes of cost-optimal heuristic-search planners on the Elevators,
Openstacks-strips-08, Parcprinter, and Scanalyzer domains. The description of the planners is given in Section 6; here the fork-decomposition heuristics are via structural-pattern databases. Column task denotes problem instance,
column h denotes optimal solution length. Other columns capture the run time
and number of expanded nodes.

122

fiImplicit Abstraction Heuristics

hF
task

h

hI

nodes

hFI

HSPF

blind

time

nodes

time

nodes

time

nodes

time

nodes

time

0.02
0.07
0.07
0.07
0.03
0.16
0.08
2.56
0.36
2.45
1.08
2.98
2.51
4.82
5.84
0.83
22.38
4.93
20.71
27.36
41.78
5.66
97.46
106.00
68.95
553.11
523.12

10
83
209
181
251
901
110
25253
3951
28241
12881
37358
33374
55127
73733
10598
300972
50222
257988
293860
494477
48190
954593
1219589
899323
6943124
2121936

0.02
0.12
0.12
0.12
0.02
0.14
0.12
0.71
0.20
0.77
0.38
0.86
0.76
1.29
1.67
0.33
6.38
1.37
5.62
8.56
11.49
1.43
25.16
31.83
25.33
177.06
82.61

10
83
209
181
251
901
110
25253
3951
28241
12881
37358
33374
55127
73733
10598
300972
50222
257988
293860
494477
48190
954593
1219589
899323
6943124
2121936

0.03
0.18
0.19
0.19
0.04
0.27
0.18
2.89
0.53
3.21
1.36
3.63
3.09
5.63
7.09
1.10
27.00
5.55
24.49
36.43
50.51
5.95
108.53
136.27
107.61
719.81
339.83

6
20
50
15
43
247
26
7898
757
7522
5979
21133
25897
17144
37810
7939
282810
10358
90950
83693
141906
13123
181830
271157
201932
2031156
132701

0.16
5.17
6.91
1.82
5.62
25.68
11.67
28.50
23.02
28.25
20.60
32.73
33.29
32.20
38.72
27.70
124.39
29.81
61.77
63.99
87.89
30.94
114.89
157.50
122.27
1024.04
118.20

11
66
174
192
242
1265
215
30776
3538
29658
13430
38561
32370
62047
76150
10090
294396
62726
275969
328583
545896
69465
1258767
1324907
830182
7178802
6091864

0.00
0.01
0.00
0.01
0.01
0.01
0.01
0.15
0.03
0.14
0.06
0.18
0.15
0.29
0.35
0.05
1.44
0.29
1.29
1.63
2.64
0.33
6.17
6.69
4.33
37.78
34.53

372
551
394
130524
50
526
47522
2114443
23083
69797
271598
155166
169436
20737
7943562
335238
80459
2109516
5238957
648
337852
5866700
3565151
14504610

0.03
0.02
0.01
5.57
0.32
0.04
2.81
135.12
1.47
3.17
15.63
10.98
8.93
1.05
602.99
20.20
4.17
156.88
354.84
0.14
74.21
473.77
222.48
1151.55

287
497
177
45048
203202
534
42195
1204212
26189
21291
282061
60655
294710
6984
7742698
242778
40425
119938
3558809
648
450027
4053413
3613835
2244156
23044275
12138101

0.01
0.01
0.00
0.28
7.28
0.01
0.38
11.27
0.26
0.18
2.09
0.70
3.63
0.07
84.75
1.66
0.29
0.97
33.60
0.69
14.64
45.18
50.31
30.10
275.91
152.95

269
509
173
44198
3073
526
28163
1080337
16013
20741
271598
46865
169436
6952
7456505
240912
36889
119784
3459314
648
76647
3868663
2563159
1759660
17832156
10473204
8738457

0.02
0.02
0.01
2.07
0.96
0.04
1.84
74.55
1.12
1.07
16.87
3.69
10.26
0.41
622.89
15.14
2.05
9.18
251.38
0.79
16.85
335.31
181.66
154.33
1612.04
996.25
1131.26

1079
700
621
282895

6.17
4.57
2.63
177.07

6815
75669

6.83
174.92

459188
620685
440869

400.45
315.43
586.91

1631677
178574

994.61
121.96

852948
239522

859.44
220.86

1762
1348
1165
320446
9607487
10526
315405
13329538
818693
852150
531305
4705742
2363177
255203
21598353
935561
317984
7219504
23255133
649

0.01
0.00
0.00
1.43
81.84
0.04
1.49
77.70
4.09
4.07
2.71
25.21
12.60
1.17
120.25
4.74
1.43
39.20
130.46
0.01

2074534

679.61
12
874
225310
1462063
111
9976
224986
67
4455
56897
292004

0.00
0.10
48.69
714.49
0.01
1.41
74.09
0.00
0.37
13.82
120.98

16
998
257608
1660874
103
11130
246069
62
5408
70579
382588

0.01
0.15
59.28
856.87
0.02
1.70
89.04
0.01
0.54
19.32
196.82

60
1567
380982

0.48
6.36
274.86

135
14874
373133
62
7544
100347

0.94
19.85
454.55
0.50
7.71
92.93

64
2093
408643
4204372
164
14796
408449
112
7610
106548
1663856

0.00
0.01
3.69
50.69
0.00
0.12
4.36
0.00
0.06
1.07
19.29

119
409
80794
50
11665
113386
16
1931
4673

0.85
3.03
136.95
0.93
18.49
273.76
0.91
5.96
9.05

9086
21076

0.09
0.30

3487
1862476

0.05
37.91

227
177942
962698

0.00
3.97
23.76

pegsol-strips-ipc6
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27

2
5
4
4
4
4
3
6
5
6
7
8
9
7
8
8
10
7
8
7
8
6
8
8
8
9
7

12
84
208
193
266
1343
217
31681
3743
29756
13832
39340
33379
63096
77932
10491
299676
63247
279822
329570
548254
69922
1262645
1326517
830637
7196836
6092258

sokoban-strips-ipc6
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
30

11
9
10
29
8
9
15
31
19
30
35
32
20
29
76
50
37
49
47
2
10
44
31
50
39
33
23
14

transport-strips-ipc6
01
02
03
04
11
12
13
21
22
23
24

54
131
250
318
456
594
550
478
632
630
614

60
1558
380375
3526204
135
14873
372845
62
7544
100269
1587821

0.01
0.06
10.47
164.35
0.02
0.37
15.07
0.01
0.18
3.65
77.96

woodworking-strips-ipc6
01
02
03
11
12
13
21
22
23

170
185
275
130
225
215
95
185
195

4313
5550

0.23
0.34

3716
5054

0.10
0.14

4157
5408

0.28
0.41

860
328229
4413726
54
31189
44641

0.10
41.44
954.34
0.02
4.66
8.39

987
328728
4125788
54
67528
155426

0.05
16.57
455.35
0.02
3.26
9.71

897
328930
4404104
53
38912
64840

0.13
52.03
1297.06
0.03
6.83
14.42

Table 22: Similar to Table 21 for the Pegsol, Sokoban, Transport, and Woodworking domains.
123

fiKatz & Domshlak

References
Backstrom, C., & Nebel, B. (1995). Complexity results for SAS+ planning. Computational
Intelligence, 11 (4), 625655.
Bonet, B., & Geffner, H. (2001). Planning as heuristic search. Artificial Intelligence, 129 (1
2), 533.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning.
Artificial Intelligence, 69 (1-2), 165204.
Chen, H., & Gimenez, O. (2008). Causal graphs and structurally restricted planning. In Proceedings of the 18th International Conference on Automated Planning and Scheduling
(ICAPS), pp. 3643, Sydney, Australia.
Clarke, E., Grumberg, O., & Peled, D. (1999). Model Checking. MIT Press.
Coles, A. I., Fox, M., Long, D., & Smith, A. J. (2008). Additive-disjunctive heuristics for
optimal planning. In Proceedings of the 18th International Conference on Automated
Planning and Scheduling (ICAPS), pp. 4451.
Culberson, J., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence, 14 (4),
318334.
Domshlak, C., & Dinitz, Y. (2001). Multi-agent off-line coordination: Structure and complexity. In Proceedings of Sixth European Conference on Planning (ECP), pp. 277288.
Domshlak, C., Hoffmann, J., & Sabharwal, A. (2009). Friends or foes? On planning as
satisfiability and abstract CNF encodings. Journal of Artificial Intelligence Research,
36, 415469.
Domshlak, C., Katz, M., & Lefler, S. (2010). When abstractions met landmarks. In Proceedings of the 20th International Conference on Automated Planning and Scheduling
(ICAPS), pp. 5056, Toronto, Canada.
Drager, K., Finkbeiner, B., & Podelski, A. (2006). Directed model checking with distancepreserving abstractions. In Valmari, A. (Ed.), Proceedings of the 13th International
SPIN Workshop on Model Checking Software, Vol. 3925 of Lecture Notes in Computer
Science, pp. 1936, Berlin Heidelberg. Springer-Verlag.
Edelkamp, S. (2001). Planning with pattern databases. In Proceedings of the European
Conference on Planning (ECP), pp. 1334.
Edelkamp, S. (2002). Symbolic pattern databases in heuristic search planning. In Proceedings of the International Conference on AI Planning and Scheduling (AIPS), pp.
274293.
Edelkamp, S. (2006). Automated creation of pattern database search heuristics. In Proceedings of the 4th Workshop on Model Checking and Artificial Intelligence (MoChArt).
Edelkamp, S., & Kissmann, P. (2009). Optimal symbolic planning with action costs and
preferences. In Proceedings of the 21st International Joint Conference on Artificial
Intelligence (IJCAI), pp. 16901695, Pasadena, CA, US.
Felner, A., Korf, R. E., & Hanan, S. (2004). Additive pattern database heuristics. Journal
of Artificial Intelligence Research, 22, 279318.
124

fiImplicit Abstraction Heuristics

Haslum, P. (2008). Additive and reversed relaxed reachability heuristics revisited. In Proceedings of the 6th International Planning Competition.
Haslum, P., Bonet, B., & Geffner, H. (2005). New admissible heuristics for domainindependent planning. In Proceedings of the Twentieth National Conference on Artificial Intelligence (AAAI), pp. 11631168.
Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independent
construction of pattern database heuristics for cost-optimal planning. In Proceedings
of the 19th National Conference on Artificial Intelligence (AAAI), pp. 10071012.
Haslum, P., & Geffner, H. (2000). Admissible heuristics for optimal planning. In Proceedings of the Fifth International Conference on Artificial Intelligence Planning Systems
(ICAPS), pp. 140149.
Helmert, M. (2003). Complexity results for standard benchmark domains in planning.
Artificial Intelligence, 146 (2), 219262.
Helmert, M. (2004). A planning heuristic based on causal graph analysis. In Proceedings of
the 14th International Conference on Automated Planning and Scheduling (ICAPS),
pp. 161170, Whistler, Canada.
Helmert, M. (2006). The Fast Downward planning system. Journal of Artificial Intelligence
Research, 26, 191246.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths and abstractions: Whats
the difference anyway?. In Proceedings of the 19th International Conference on Automated Planning and Scheduling (ICAPS), pp. 162169, Thessaloniki, Greece.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics for optimal
sequential planning. In Proceedings of the 17th International Conference on Automated
Planning and Scheduling (ICAPS), pp. 176183, Providence, RI, USA.
Helmert, M., & Mattmuller, R. (2008). Accuracy of admissible heuristic functions in selected planning domains. In Proceedings of the 23rd AAAI Conference on Artificial
Intelligence, pp. 938943, Chicago, USA.
Helmert, M. (2008). Understanding Planning Tasks: Domain Complexity and Heuristic
Decomposition, Vol. 4929 of Lecture Notes in Computer Science. Springer.
Hernadvolgyi, I., & Holte, R. (1999). PSVN: A vector representation for production systems.
Tech. rep. 1999-07, University of Ottawa.
Jonsson, A. (2007). The role of macros in tractable planning over causal graphs. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI-07),
pp. 19361941.
Jonsson, P., & Backstrom, C. (1998). State-variable planning under structural restrictions:
Algorithms and complexity. Artificial Intelligence, 100 (12), 125176.
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning with landmarks. In Proceedings
of the International Joint Conference on Artificial Intelligence (IJCAI-09), pp. 1728
1733, Pasadena, CA, USA.
125

fiKatz & Domshlak

Katz, M., & Domshlak, C. (2007a). Structural patterns heuristics. In ICAPS-07 Workshop on Heuristics for Domain-independent Planning: Progress, Ideas, Limitations,
Challenges, Providence, RI, USA.
Katz, M., & Domshlak, C. (2007b). Structural patterns of tractable sequentially-optimal
planning. In Proceedings of the 17th International Conference on Automated Planning
and Scheduling (ICAPS), pp. 200207, Providence, RI, USA.
Katz, M., & Domshlak, C. (2008). Structural patterns heuristics via fork decomposition. In
Proceedings of the 18th International Conference on Automated Planning and Scheduling (ICAPS), pp. 182189, Sydney, Australia.
Katz, M., & Domshlak, C. (2009). Structural-pattern databases. In Proceedings of the
19th International Conference on Automated Planning and Scheduling (ICAPS), pp.
186193, Thessaloniki, Greece.
Katz, M., & Domshlak, C. (2010). Optimal admissible composition of abstraction heuristics.
Artificial Intelligence, 174, 767798.
Pearl, J. (1984). Heuristics - Intelligent Search Strategies for Computer Problem Solving.
Addison-Wesley.
Prieditis, A. (1993). Machine discovery of effective admissible heuristics. Machine Learning,
12, 117141.
Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks revisited. In Proceedings of
the Twenty-Third National Conference on Artificial Intelligence (AAAI), pp. 975982,
Chicago, IL, USA.
Yang, F., Culberson, J., & Holte, R. (2007). A general additive search abstraction. Tech.
rep. TR07-06, University of Alberta.
Yang, F., Culberson, J., Holte, R., Zahavi, U., & Felner, A. (2008). A general theory
of additive state space abstractions. Journal of Artificial Intelligence Research, 32,
631662.

126

fi