Journal of Artificial Intelligence Research 50 (2014) 923970

Submitted 06/14; published 08/14

Belief Tracking for Planning with Sensing: Width,
Complexity and Approximations
Blai Bonet

bonet@ldc.usb.ve

Departamento de Computacion
Universidad Simon Bolvar
Caracas, Venezuela

Hector Geffner

hector.geffner@upf.edu

ICREA & Universitat Pompeu Fabra
Roc Boronat 138
08018 Barcelona, Spain

Abstract
We consider the problem of belief tracking in a planning setting where states are valuations over a set of variables that are partially observable, and beliefs stand for the sets
of states that are possible. While the problem is intractable in the worst case, it has been
recently shown that in deterministic conformant and contingent problems, belief tracking is exponential in a width parameter that is often bounded and small. In this work,
we extend these results in two ways. First, we introduce a width notion that applies to
non-deterministic problems as well, develop a factored belief tracking algorithm that is exponential in the problem width, and show how it applies to existing benchmarks. Second,
we introduce a meaningful, powerful, and sound approximation scheme, beam tracking, that
is exponential in a smaller parameter, the problem causal width, and has much broader applicability. We illustrate the value of this algorithm over large instances of problems such
as Battleship, Minesweeper, and Wumpus, where it yields state-of-the-art performance in
real-time.

1. Introduction
Planning with incomplete information can be formulated as a search problem in belief space
where two issues need to be addressed: keeping track of beliefs, and searching for a goal
belief (Bonet & Geffner, 2000). While the two tasks are intractable in the worst case
over compact representations, this is the approach adopted in most recent conformant and
contingent planners where beliefs are handled using SAT, regression techniques, or logical
normal forms such as CNF, DNF, and OBDDs, and the search for goal beliefs is guided
by domain-independent heuristics (Bertoli, Cimatti, Roveri, & Traverso, 2001; Hoffmann &
Brafman, 2006; Bryce, Kambhampati, & Smith, 2006; To, Pontelli, & Son, 2011; Shani &
Brafman, 2011; Brafman & Shani, 2012).
Recently, the complexity of belief tracking in deterministic conformant and contingent
planning has been shown to be exponential in a problem width parameter that is often
bounded and small (Palacios & Geffner, 2009; Albore, Palacios, & Geffner, 2009). The
bound follows from a family of translations developed for compiling planning problems over
beliefs into planning problems over states. The translations are exponential in the problem
c
2014
AI Access Foundation. All rights reserved.

fiBonet & Geffner

width, and for deterministic conformant problems result in problems that can be solved by
classical planners.
The difficulty in extending the results of Palacios, Albore, and Geffner to the nondeterministic setting is a consequence of the special role played by the initial situation in
deterministic problems. In such a case, all uncertainty, and in particular, the uncertainty
about observations, action preconditions, and goals, which is the one that matters in a
complete planner, is the result of the uncertainty about the initial situation. In the nondeterministic setting, on the other hand, uncertainty is produced dynamically as a result of
the application of non-deterministic actions. Moreover, while an uncertain initial situation
can always be modeled by a fully known initial situation and a dummy non-deterministic
action, the opposite transformation is not as simple. Indeed, non-deterministic effects can
be compiled into deterministic effects that are conditional on the value of hidden variables,
but the number of hidden variables required must grow then with the planning horizon
(Weld, Anderson, & Smith, 1998; Albore, Ramirez, & Geffner, 2010).
The aim of this work is the study of the computational complexity of belief tracking
in terms of novel width parameters that apply to both deterministic and non-deterministic
planning problems, and the formulation of practical approximate belief tracking algorithms
that can be efficient and effective even for problems with large width. We will achieve this
by considering two decomposition schemes for belief tracking, and three algorithms based
on these decompositions. More precisely, we introduce:
1. A width notion for planning that is in close correspondence with the notion introduced
by Palacios, Albore, and Geffner but which applies to non-deterministic problems as
well.
2. A first belief tracking algorithm, factored belief tracking, that is sound and complete
for both deterministic and non-deterministic problems P , and runs in time and space
exponential in the problem width w(P ). The algorithm is based on a decomposition
of the problem P into projected subproblems PX , one for every goal and precondition
variable X, each one including the variables that are relevant to X.
3. A second belief tracking algorithm, causal belief tracking, that is based on an alternative
decomposition scheme, where subproblems PX are defined for every goal, precondition,
and observable variable X, each one including the variables that are causally relevant to
X. The algorithm is sound and complete for a large and meaningful class of problems,
and while it is still time exponential in the problem width, it is space exponential in the
causal width of the problem that is often much smaller.
4. A final belief tracking algorithm, beam tracking that is a sound but incomplete approximation of causal belief tracking, and is often practical enough, even in problems with
large widths, as it runs in time and space that are exponential in the problem causal
width.
The power of the last algorithm, beam tracking, will be shown empirically over large
instances of problems such as Minesweeper, Battleship, and Wumpus, where state-of-the924

fiBelief Tracking for Planning with Sensing

art performance is obtained in real-time by combining the belief tracking algorithm with
simple heuristics for action selection.1
The organization of the paper follows this structure, preceded by an overview of the
relevant notation and background, and followed by a description of the experiments, a
discussion of related work, and a summary. The paper integrates results from two conference
papers (Bonet & Geffner, 2012b, 2013), providing proofs and additional details. The work
is related to other proposals for tractable forms of belief tracking in logical and probabilistic
frameworks (Doucet, Freitas, Murphy, & Russell, 2000; Amir & Russell, 2003), yet there are
two key differences. One is that we start with an exact account that is used to determine with
certainty whether the goal has been achieved or an action is applicable. The second is that
belief tracking accounts in planning do not have to be complete over all formulas. In order to
have a sound and complete planner, only the beliefs over observations, action preconditions,
and goals are required. This is important because observations, action preconditions, and
goals are given, and the structure of the actions, sensors, and goals can be exploited to
track those beliefs more efficiently. This observation is implicit in lazy belief tracking
schemes for planning with incomplete information that appeal to SAT-solvers (Hoffmann &
Brafman, 2006) or regression (Shani & Brafman, 2011). Well say more about related work
in Section 12.

2. Model
The model for planning with sensing is a simple extension of the model for conformant
planning where a goal is to be achieved with certainty in spite of uncertainty in the initial
situation or action effects (Goldman & Boddy, 1996; Smith & Weld, 1998). The model for
conformant planning is characterized by a tuple S = hS, S0 , SG , A, F i where
 S is a finite state space,
 S0 is a non-empty set of possible initial states, S0  S,
 SG is a non-empty set of goal states, SG  S,
 A is a set of actions with A(s) denoting the sets of actions applicable in s  S, and
 F is a non-deterministic state-transition function such that F (a, s) denotes the nonempty set of possible successor states that follow action a in s, for a  A(s).
A solution to a conformant model is an action sequence that maps each possible initial state
into a goal state. More precisely,  = ha0 , . . . , an1 i is a conformant plan if for each possible
sequence of states s0 , s1 , . . . , sn such that s0  S0 and si+1  F (ai , si ), i = 0, . . . , n  1,
action ai is applicable in si and sn is a goal state.
Conformant planning can be cast as a path finding problem over beliefs, defined as the
sets of states that are deemed possible at any time point (Bonet & Geffner, 2000). The
initial belief b0 is S0 , and the belief ba that results from an action a in a belief state b is:
ba = {s0 | there is a s  b such that s0  F (a, s)} ,

(1)

1. A real-time animation of the algorithm for several instances of Minesweeper can be seen in https:
//www.youtube.com/watch?v=U98ow4n87RA, while all the source code and graphical interfaces can be
obtained at http://code.google.com/p/belief-tracking.

925

fiBonet & Geffner

where the action a is applicable in b if it is applicable in each state s in b. In this formulation,
a conformant plan is an action sequence that maps the initial belief b0 into a goal belief bG ;
i.e., a set of goal states.
Contingent planning or planning with sensing is planning with both uncertainty and
feedback. The model for contingent planning is the model for conformant planning extended
with a sensor model. A sensor model is a function O(s, a) mapping state-action pairs
into observations tokens o. The expression o  O(s, a) means that token o is a possible
observation when s is the true state of the system and a is the last action done. The
observed token o provides partial information about the true but possibly hidden system
state as the same token may be possible in different states. If two different tokens o1
and o2 belong to O(s, a), it means that either one can be observed in s when a is the
last action. Sensing is deterministic or noiseless when O(s, a) contains one token, else it
is non-deterministic or noisy. The contingent model is similar to POMDPs (Kaelbling,
Littman, & Cassandra, 1999) but with uncertainty encoded through sets of states rather
than probability distributions.
Executions in the contingent setting are sequences ha0 , o0 , a1 , o1 , . . .i of pairs of actions
ai and observations oi . If b = bi is the belief state when the action ai is applied and oi is
the token that is observed, then the belief ba after the action a = ai is given by (1), and
the belief bi+1 = boa that follows from observing the token o is:
boa = {s | s  ba and o  O(s, a)} .

(2)

An execution ha0 , o0 , a1 , o1 , . . .i is possible if starting from the initial belief b0 , each action
ai is applicable in the belief bi (i.e., ai  A(s) for all s  bi ), for i  0, and each belief bi is
not empty.
In off-line contingent planning, an action selection strategy is sought that ensures that
all possible executions end up in a goal belief. In on-line contingent planning, an action
selection strategy is sought that ensures that the single execution that results from the
interaction with the real system or simulator, ends up in a goal belief. In both cases, the
action selection strategy can be expressed as a partial function  over beliefs, called a policy,
such that (b) is the action to do in belief b. The function is partial because it has to be
defined only over the initial belief b0 and some non-goal beliefs b; namely, those that can be
reached with  from b0 in off-line planning, and those that have been reached with  from
b0 in on-line planning.

3. Language
Syntactically, conformant problems can be expressed in compact form through a set of
state variables, which for convenience we assume to be multi-valued.2 More precisely, a
conformant planning problem is a tuple P = hV, I, A, Gi where V stands for the problem
variables X, each one with a finite and discrete domain DX , I is a set of clauses over the
V -literals defining the initial situation, A is a set of actions, and G is a set of V -literals
defining the goal. Every action a has a precondition P re(a) given by a set of V -literals, and
2. Multi-valued variables can be compiled into boolean variables but the compilation affects the syntactic
structure of the problem. In principle, such a structure could be recovered from boolean encodings but
this would result in a more complex formulation.

926

fiBelief Tracking for Planning with Sensing

a set of conditional effects C  E1 | . . . |En where C and each Ei are sets (conjunctions) of
V -literals. The conditional effect is non-deterministic if n > 1; else n = 1 and the effect is
deterministic.
A problem P = hV, I, A, Gi defines a conformant model S(P ) = hS, S0 , SG , A, F i, where
S is the set of possible valuations over the variables in V , S0 and SG are the sets of valuations
that satisfy I and G respectively, A(s) is the set of operators whose preconditions are true
in s, and F (a, s) is the non-deterministic transition function that results from collecting
the successor states that may follow from a by selecting one head Ei from each conditional
effect C  E1 | . . . |En whose body C is true in s.3
Contingent problems can be described by extending the syntactic description of conformant problems with a compact encoding of the sensor model. For this, we assume a set
V 0 of observable multi-valued variables Y , not necessarily disjoint with the state variables
V (i.e., some state variables may be observable), and formulas Wa (Y = y) over the state
variables, for each action a and each possible value y of each observable variable Y . The
formula Wa (Y = y) implicitly encodes the states over which the observation literal Y = y
is possible when a is the last action executed. The formulas Wa (Y = y) for the different y
values in DY must be logically exhaustive, as every state-action pair must give rise to some
observation Y = y. If in addition, the formulas Wa (Y = y) for the different y values are
logically exclusive, then every state-action pair gives rise to a single observation Y = y and
the sensing over Y is deterministic. If a state variable X is observable, then Wa (X = x) is
just the formula X = x.
A contingent problem P is a tuple P = hV, I, A, G, V 0 , W i that defines a contingent
model which is made of the conformant model hS, S0 , SG , A, F i determined by the first four
components in P , and the sensor model O(a, s) determined by the last two components,
where o  O(a, s) iff o is a valuation over the observable variables Y  V 0 such that Y = y
is true in o only if the formula Wa (Y = y) in W is true in s for y  DY .
This is a standard language for representing contingent problems in compact form featuring both incomplete information, and non-deterministic actions and sensors. Its two
distinctive features in relation to similar languages are the use of multi-valued variables,
and the distinction between state and observable variables.
As an illustration, if X encodes the position of an agent, and Y encodes the position of
an object that can be seen by the agent when X = Y , we can have an observable variable
Z  {Y es, N o} encoding whether
the object can be seen by the agent or
W
W not, defined by the
formulas Wa (Z = Y es) = lD (X = lY = l), and Wa (Z = N o) =  lD (X = lY = l),
where D is the set of possible locations and a is any action. This will be a deterministic
sensor. A non-deterministic sensor could be used if, for example, the agent cannot detect
0
the presence
W of the object at certain locations l  D . For this, it suffices to push the
disjunct lD0 (X = l) into the formulas characterizing Wa (Z = Y es) and Wa (Z = N o), so
that the two observations Z = Y es and Z = N o would be possible when the agent is in a
position l  D0 .
Since a conformant problem hV, I, A, Gi can be expressed as a contingent problem
hV, I, A, G, V 0 , W i with just one (dummy) observable variable Z, with Z 
/ V and domain
3. These conditional effects must be consistent in the sense that is explained below.

927

fiBonet & Geffner

DZ = {>}, and observation model Wa (Z = >) = true for every action a, we will focus
from now on on the more general contingent problem.
Likewise, for convenience, if a variable Y is boolean, we often represent the literals
Y = true and Y = f alse as Y and Y . Similarly, if variable Y is observable, unless stated
otherwise, we assume that the observation model for Y is deterministic so that the formula
Wa (Y = f alse) becomes the complement of the formula Wa (Y = true).

4. Belief Tracking Problem and Flat Belief Tracking Algorithm
An execution over the problem P = hV, I, A, G, V 0 , W i is a sequence ha0 , o0 , a1 , o1 , . . .i of
actions ai and observations oi such that each ai is in A and each observation oi is a full
valuation over observation variables in V 0 . An execution ha0 , o0 , . . . , an , on i is possible over
a problem P with a non-empty belief state b0 , if it generates a sequence of beliefs b0 , . . . , bn
such that the preconditions of the action ai are true in the belief bi , and the belief states
bi are not empty. The problem of belief tracking in contingent planning is the problem of
determining if an execution is possible and if the final belief state achieves the goal:
Definition 1. Belief tracking in planning (BTP) is the problem of determining whether an
execution ha0 , o0 , a1 , o1 , . . .i over a planning problem P = hV, I, A, G, V 0 , W i is possible, and
if so, whether the resulting belief state makes the goal G true.
A complete planner needs to solve this problem for determining which actions are applicable after a given execution, what observations may result, and whether the goal has
been achieved. The machinery that we will develop is aimed at the slightly more general
belief tracking problem over generalized executions: these are executions ha0 , o0 , a1 , o1 , . . .i
where the observations oi are partial rather than full valuations over the observable variables. Moreover, it suffices to consider generalized executions where the observations are
valuations over a single observable variable. Such observations oi can be represented by
observation literals `i :
Definition 2. Generalized belief tracking in planning (GBTP) is the problem of determining whether a generalized execution ha0 , `0 , a1 , `1 , . . .i over a planning problem P =
hV, I, A, G, V 0 , W i is possible, and if so, whether it achieves a given goal, precondition, or
observation literal.
Given a procedure for deciding GBTP, it is simple to decide BTP over an execution 
by calling the procedure for deciding GBTP over the generalized execution  0 that replaces
each observation oi by a sequence of the observation literals that are true in oi separated
by NO-OP actions (actions with no effects).
Proposition 3. BTP is polynomial-time reducible to GBTP.
While our interest is in belief tracking for planning, we will find it convenient to focus on
the generalized problem, as none of the belief update equations or algorithms is sensitive to
this distinction. For simplicity, however, we will just talk about belief tracking, and make
explicit the distinctions between BTP and GBTP, and between normal and generalized
executions, when needed.
928

fiBelief Tracking for Planning with Sensing

The plain solution to the belief tracking problem is given by the updates expressed in
Eqs. 1 and 2, where belief states are explicitly represented as sets of states, states are full
valuations over the state variables, and the actions, transition function, and observations
are obtained from the syntactic representation of the problem:
Definition 4. The flat belief tracking algorithm over an execution ha0 , o0 , a1 , o1 , . . .i and
problem P , starts with the belief b0 that contains the states that satisfy the initial situation,
setting the next belief state bi+1 to boa using (1) and (2) with b = bi , a = ai , and o = oi .
The complexity of flat belief tracking is exponential in the number of state variables. Yet,
often some state variables do not add up to the complexity of tracking beliefs. Syntactically,
this happens when a state variable X is initially known, all variables Y that are causally
relevant to X (see below) are initially known as well, and neither X nor any variable Y
causally relevant to X appears in the head of a non-deterministic effect. We say that these
variables are determined as their value in every reachable belief is known, and can be fully
predicted from the preceding actions and their preceding values. For example, the variable
that encodes the position of the agent in the Wumpus game is determined, as its initial
value is known and the effect of the actions on the variable is deterministic and depends
only on its previous value.
Formally, we define the set of variables that are determined in a problem to be the
largest set of state variables X in the problem that are initially known such that every
state variable X 0 that is causally relevant to X belongs to the set. This set of variables
is easily identifiable in low polynomial time. The complexity of flat belief tracking can be
then expressed as follows:
Theorem 5. Flat belief tracking is exponential in |VU |, where VU = V \ VK and VK is the
set of state variables that are determined in the problem.
Given this result, the first question that arises is how bad is the naive approach of flat belief
tracking. Interestingly, the following result for the decision problem shows that flat belief
tracking is not bad in the worst case:
Theorem 6. BTP and GBTP are Turing complete for the class PNP .
That is, BTP and GBTP can be decided in polynomial time using an oracle for NP (SAT,
for example), and every decision problem that can be decided in polynomial time with
such an oracle, can be decided in polynomial time with an oracle for BTP or GBTP. The
complexity class PNP includes the classes NP and coNP, and it is contained in PSPACE
(Sipser, 2006).

5. Structure and Width
It is possible to improve on the complexity of flat belief tracking over a specific problem
by exploiting the structure of the problem. Before introducing the graph that captures
this structure, it will be convenient to make explicit some assumptions that do not restrict
the generality of the approach but make the definitions simpler. First, we assume that the
formula I encoding the initial situation contains just positive or negative literals; i.e., unit
clauses only. This is not a restrictive assumption since any set of clauses can be encoded
929

fiBonet & Geffner

with the help of dummy observations. Second, we assume that non-deterministic effects
involve just one variable in their heads. Again, this can always be achieved by adding extra
variables and effects. For example, the non-deterministic effect X  Y  Z | Y  Z of an
action can be replaced by the deterministic effects X W  Y Z and X W  Y Z,
along with the non-deterministic effect true  W | W , where W is a new random boolean
variable that is initially unknown and changes randomly. Third, we assume that the problem
is consistent, meaning that the initial situation I is logically consistent so that the initial
belief state b0 is not empty, and that the effects of any action a are consistent so that the
heads of the deterministic conditional effects that are applicable in a reachable state s, along
with any choice of heads of the non-deterministic conditional effects that are applicable in
s, are jointly consistent.4 Last, we assume that every observable variable is relevant to a
variable appearing in some precondition or goal, with the notion of relevance to be spelled
below. Observable variables that dont comply with this condition can be eliminated from
the problem with no relevant information loss.
5.1 Relevance and Width
For a variable X, whether a state variable, an observable variable, or both, the immediate
causes of X are defined as follows:
Definition 7. A variable X is an immediate cause of a variable Y in a problem P , written
X  Ca(Y ), iff X 6= Y , and either X occurs in the body C of a conditional effect C 
E1 |    |En and Y occurs in a head Ei , 1  i  n, or Y is an observable variable and X
occurs in a formula Wa (Y = y) for some y  DY and some action a.
Basically, X is an immediate cause of Y when uncertainty about X may affect the
uncertainty about Y directly, not through other variables. X is not necessarily an immediate
cause of Y when X appears as the precondition of an action that affects Y , as preconditions
must be known with certainty, and hence, do not propagate uncertainty. The notion of
causal relevance is given by the transitive closure of the immediate cause relation:
Definition 8. X is causally relevant to Y in P if X = Y , X  Ca(Y ), or X is causally
relevant to a variable Z that is causally relevant to Y .
In order to test whether a given literal Z = z is known after a certain execution
ha0 , a1 , . . . , ai i of actions in the conformant setting, it is possible to show that one can
just progress the state over the variables X that are causally relevant to Z:
Proposition 9. Belief tracking in the deterministic or non-deterministic conformant setting is exponential in the maximum number of non-determined variables that are all causally
relevant to a variable appearing in an action precondition or goal.
This bound is closely related to the bound obtained by Palacios and Geffner in the
deterministic setting. Indeed, if we refer to the number of non-determined state variables
4. From a semantic point of view, this means that a state s0 is a possible successor of state s after an
action a applicable in s, i.e. s0  F (a, s), iff for every literal X = x true in s0 , X = x is in the head of a
deterministic or non-deterministic conditional effect of the action a whose body is true in s, or if X = x
is true in s, and there is no effect of the action a with X = x0 in the head, with x0 6= x, whose body is
true in s.

930

fiBelief Tracking for Planning with Sensing

that are causally relevant to X, as the conformant width of X, and set the width of P as
the maximum conformant width over the variables X that appear in action preconditions
or goals, Proposition 9 simply says that belief tracking for a non-deterministic conformant
problem is exponential in the problem width. This width notion, however, is not exactly
equivalent to the notion of Palacios and Geffner when used in the deterministic setting as
it is defined over variables rather than literals. We will say more about this distinction
below. In general, however, the two accounts yield similar widths over most deterministic
benchmarks.
In the contingent setting, there are variables whose uncertainty may affect a variable
Z but which are not causally relevant to Z. The situation is similar to the one arising in
Bayesian networks (Pearl, 1988), where relevance flows both causally, in the direction of
the arrows, and evidentially, from the observations against the direction of the arrows.
Definition 10. X is evidentially relevant to Y in P if X is an observable variable and Y
is causally relevant to X.
The notion of relevance captures the transitive closure of the (directional) causal and evidential relations:
Definition 11. X is relevant to Y if X is causally or evidentially relevant to Y , or X is
relevant to a variable Z that is relevant to Y .
Thus, a variable X = W1 is relevant to a variable Y = Wn iff there is a chain of variables
Wi , 1  i  n  1, such each variable Wi is causally or evidentially relevant to the next
variable Wi+1 in the chain. For example, if X is causally relevant to Y and Z, and Y is an
observable variable, then Y will be relevant to Z as Y is evidentially relevant to X and X
is causally relevant to Z.
Like in Bayesian networks, the relevance relations can be understood graph-theoretically.
Thus, if the directed edge Z  Y stands for Z being an immediate cause of Y , then X is
causally relevant to X 0 when there is a directed path from X to X 0 , and X is evidentially
relevant to X 0 when X is an observable variable, and there is a directed path from X 0
to X. In terms of Bayesian networks, the relevance relation takes the transitive closure
of the causal and evidential relationships, and encodes potential dependency given what
may be observed, using the information that certain variables will not be observed (are
not observable). Unlike Bayesian networks, this means however that the relevance relation
is not symmetric. Namely, a cause X of Y is relevant to Y , but Y is not automatically
relevant to X if it is not causally relevant to an observable variable Z, which may be Y
itself. The context of a variable is the set of variables in the problem that are relevant to
X:
Definition 12. The context of variable X, Ctx(X), denotes the set of state variables in
the problem that are relevant to X.
The width of a variable is defined as the number of state variables in its context that are
not determined:
Definition 13. The width of a variable X, w(X), is |Ctx(X)  VU |, where VU = V \ VK
and VK is the set of state variables that are determined.
931

fiBonet & Geffner

The width of a problem is then:
Definition 14. The width w(P ) of a conformant or contingent problem P , whether deterministic or not, is maxX w(X) where X ranges over the variables that appear in a goal or
action precondition in P .
The relation between width and complexity can be expressed as:
Theorem 15. Belief tracking in P is exponential in w(P ).
The proof for this theorem follows from the results below where an algorithm that
achieves this complexity bound is presented. The significance of the theorem is that belief
tracking over planning domains with width bounded by a constant becomes polynomial in the
number of problem variables. We will see examples of this below. This complexity bound is
similar to the ones obtained for deterministic conformant and contingent problems (Palacios
& Geffner, 2009; Albore et al., 2009). The main difference is that the new account applies
to non-deterministic problems as well. The new account is simpler and more general, but
as we will see, it is also slightly less tight on some deterministic domains.

6. Examples
We illustrate the definitions above with some benchmark domains, starting with DET-Ring
(Cimatti, Roveri, & Bertoli, 2004). In this domain, there is a ring of n rooms and an
agent that can move forward or backward along the ring. Each room has a window which
can be opened, closed, or locked when closed. Initially, the status of the windows is not
known and the agent does not know his initial location. In this domain the agent has no
means for obtaining information about the status of the windows or its position, and its
goal is to have all windows locked. A plan for this deterministic conformant problem is to
repeat n times the actions (close, lock, f wd), skipping the last f wd action. Alternatively,
the action f wd can be replaced by the action bwd throughout the plan. The state variables
for the problem encode the agent location Loc  {1, . . . , n}, and the status of each window,
W (i)  {open, closed, locked}, i = 1, . . . , n. The location variable Loc is (causally) relevant
to each window variable W (i), but no window variable W (i) is relevant to Loc or W (k)
for k 6= i, as W (i) is not causally relevant to an observable variable. None of the variables
is determined and the largest contexts are for the window variables W (i) that include two
variables, W (i) itself and Loc. As a result the width of the domain is 2, which is independent
of the number of state variables W (i) that grows with the number of rooms n. The causal
graph of the problem, where a directed edge X  Y means that X is an immediate cause
of Y is shown in Figure 1a.
NON-DET-Ring is a variation of the domain where the actions f wd and bwd of the
agent have a non-deterministic effect on the status of all windows that are not locked,
capturing the possibility of external events that can open or close unlocked windows. This
non-determinism has no effect on the causal graph over the variables. As a result, the
change has no effect on the contexts or domain width that remains bounded and equal to
2 for any number of rooms n.
The last version of the domain considered by Cimatti et al. is NON-DET-Ring-Key,
where a key is required to lock the windows. The initial position of the key is not known,
932

fiBelief Tracking for Planning with Sensing

Loc

Loc

W (1)

W (2)



W (n)

W (1)

(a) DET-Ring

W (2)

KLoc



W (n)

H

(b) CONT-NON-DET-Ring-Key

Figure 1: Causal graphs for the problems DET-Ring (left) and CONT-NON-DET-Ring-Key
(right). In the latter, the variable H is observable and tells us whether the key is being held
or not. An arc X  Y denotes that X is an immediate cause of Y . In these graphs, variables
in preconditions or goals are underlined and yellow colored, while observable variables are
enclosed in a blue circle.
yet if the agent tries to collect the key from a room and the key is there, the agent will
have the key. A conformant plan for this problem is to repeat the actions pick and f wd, n
times, skipping the last f wd action, following then the plan for DET-Ring. In NON-DETRing-Key, there is an additional state variable, KLoc  {1, . . . , n, hand}, that represents the
key location. The agent location Loc is relevant to KLoc which is relevant to each window
variable W (i). As a result, both the size of the contexts Ctx(W (i)) and the problem width
increase by 1. The width however remains bounded with a value of 3 independently of the
number of rooms n.5
In the presence of partial observability, the analysis is similar but it is necessary to
consider the relevance relationships that arise due to the presence of observable variables.
For example, one can express that the agent can always observe whether it is holding the
key or not, by having a boolean observable variable H with (deterministic) observation
model Wa (H = true) given by KLoc = hand, for all actions a. The only new relevance
relation among state variables that arises from adding this observable variable is between
Loc and KLoc, as both are causally relevant to H. Before, Loc was relevant to KLoc but
not the other way around. Yet this does not affect the domain width that remains 3 for
any n. The causal graph of the resulting domain is shown in Figure 1b.

7. Factored Belief Tracking
Belief tracking over a problem P is exponential in the width w(P ) of P . The algorithm
that achieves this bound exploits the relevance relations encoded in the variable contexts
for decomposing beliefs. In particular, if no variable is relevant to any other variable,
the problem width is 1, and beliefs over each variable can be maintained separately. The
belief decomposition is obtained from projecting the problem P into smaller problems PS
where S is a set of state variables in P . Semantically, the projected problems PS capture the
dynamics of the problem P when expressed over a subset S of state variables. Syntactically,
the projected problems PS are defined by means of the logical notion of projection. The
5. The problem can also be encoded by making holding key a precondition rather than a condition for
locking the windows. In such an encoding, the variable KLoc is no longer relevant to the window
variables W (i) according to the definitions, as then KLoc = hand must be known with certainty, and
hence uncertainty about the windows variables W (i) is not affected by uncertainty about KLoc. The
result is that in such an encoding, the domain width reduces to 2.

933

fiBonet & Geffner

logical projection of a formula F over a subset S of its variables refers to the formula F 0
defined over the variables in S, such that the valuations that satisfy F 0 are exactly those that
can be extended into valuations that satisfy F (Darwiche & Marquis, 2002). Likewise, the
projection of a conditional effect C  E 1 |    |E n is the conditional effect CS  ES1 |    |ESn
where the body C and the effects E i are replaced by their logical projections CS and ESi
respectively.
Definition 16. The projection of problem P = hV, I, A, G, V 0 , W i over a set of variables
S  V is the problem PS = hVS , IS , AS , GS , VS0 , WS i where VS is S, IS and GS are the
initial and goal formulas I and G logically projected on the variables in S, AS is A but with
the preconditions and conditional effects projected over S, VS0 is V 0 , and WS is the set of
formulas Wa (Y = y) in W logically projected on the variables in S.
The notion of a projected planning problem has been used before in the setting of
classical planning for introducing a class of admissible heuristics known as pattern databases
(Edelkamp, 2001). Here we use it in the richer contingent setting for decomposing the belief
tracking problem over P into the belief tracking problem over smaller problems PS obtained
from P by projecting away some of the state variables in P .
Before defining the target subproblems PS of the decomposition, notice that variables
Y that are both state and observable variables in P but are not in S, will belong to VS0 but
not to VS , meaning that they will be just observable variables in the projected problem PS .
Moreover, the formulas for such variables Y in WS will become Wa (Y = y) = true for all
y  DY , meaning that in the problem PS , the observations Y = y will be possible for any
y, regardless of the state and last action done. Such observations will thus be completely
irrelevant in PS and will have no effect. In any case, P and PS share the same set of actions
and the same set of observations even if some of the actions and observations in PS may be
defined over a smaller set of state variables.
The target subproblems PS are defined in terms of the set of state variables that are
relevant to precondition and goal variables. Recall that we assume that each observable
variable in the problem is relevant to some action precondition or goal, as else the variable
could be safely removed.
Definition 17. The projection of a problem P over a variable X, denoted as PX , is the
projection PS of P over the set of variables S = Ctx(X), where Ctx(X) is the context for
X in P ; i.e., the set of state variables in P that are relevant to X.
Two basic properties of the projected problems PX are:
Proposition 18. If variable X appears in a goal or precondition, then the number of state
variables in PX that are not determined is bounded by w(P ).
Proposition 19. If an execution ha0 , o0 , a1 , o1 , . . .i is possible in P , then it is also possible
in PX for any state variable X in P .
If b is the belief that results after an execution in P , we will call bX the belief that
results after the same execution in the projected problem PX . The completeness of the
decomposition of the global belief b over P is expressed in terms of the local beliefs bX
over the subproblems PX . We treat the beliefs b and bX as relations in a database where
934

fiBelief Tracking for Planning with Sensing

the state variables in these beliefs are the columns and the possible combination of values
(states and local states) are the rows. The projection Y b, for a set of variables Y thus
represents the combination of values of the variables in Y that are possible in b, while the
join bX o
nbY represents the combination of values x and y over the sets of variables in the
two beliefs bX and bY such that x and y coincide over the variables that are in both X and
Y . For example, if b contains the valuations (states) X = 1, Y = 1 and X = 2, Y = 2, the
projection {X} b will contain the valuations X = 1 and X = 2. Likewise, if b0 contains
Y = 1, Z = 1 and Y = 1, Z = 2, the join b o
n b0 will contain X = 1, Y = 1, Z = 1 and
X = 1, Y = 1, Z = 2.
Theorem 20. For a state variable X, let b and bX be the beliefs that result from an execution
that is possible over both P and PX . Then,
X bX = X b .

(3)

Equation 3 states that a literal X = x is possible in the true global belief b iff it is
possible in the belief bX that results from the same execution in the projected problem
PX . This is exactly the type of completeness that is needed in planning for any variable
X involved in an action precondition or goal. The stronger form of completeness over all
formulas, that can be expressed as

o
nX bX = b ,

(4)

where o
n stands for the join operation and X ranges over all precondition and goal variables
in the problem, is not needed, and it is actually not necessarily true, even when all state
variables appear in some context Ctx(X). For example, if the value of the boolean variable
Z is initially unknown, and variables X and Y are initially false, an action a with conditional
effects Z  X  Y and Z  Z results in a belief b with two states, corresponding to the
terms Z  X  Y and Z  X  Y . If X and Y are precondition or goal variables such that
they are not relevant to each other, the projected problem PX will contain the variables
X and Z, and the projected problem PY will contain the variables Y and Z. The belief
bX resulting from the execution of the action a in PX will include then the local states
corresponding to the terms Z  X and Z  X, while the belief bY over PY will include the
local states corresponding to the terms Z  Y and Z  Y . Clearly, the projection of b and
bX (bY ) over the variable X (Y ) coincide as dictated by (3), but the join of the two local
beliefs bX and bY does not yield the global belief b as would correspond to (4); indeed, a
formula like X  Y is false in the latter but not in the former. From (3), we can prove
inductively on the size of any execution that:
Theorem 21. 1) An execution is possible in P iff it is possible over each of the subproblems
PX for X being a precondition or goal variable in P . 2) For an execution  and precondition
or goal variable X, X = x (resp. X 6= x) is true in b iff X = x (resp. X 6= x) is true in
bX , where b and bX are the beliefs that result of executing  in P and PX respectively.
Since plain belief tracking over each projected problem PX is exponential in the size of
PX , which is bounded by w(P ) once the determined variables are excluded, it follows that:
935

fiBonet & Geffner

Theorem 22. Flat belief tracking over each of the projected problems PX for X being a
precondition or goal variable in P , provides a sound and complete factored algorithm for
belief tracking over P that is time and space exponential in the width of P .
We call this algorithm, factored belief tracking. In order to check whether a precondition
or goal literal X = x is true after an execution, factored belief tracking checks whether
X = x is true in the belief bX that results from the execution over the subproblem PX . An
execution is not possible if an action precondition X = x is not true in bX or if it results in
an empty belief over some subproblem. Theorem 22 thus says that factored belief tracking is
a sound and complete algorithm for BTP with time and space complexity exponential in the
problem width. Indeed, since every observable variable Y is relevant to some precondition
or goal variable X by assumption, then every direct cause Z of Y is relevant to X because
Y is evidentially relevant to X. Thus, any formula Wa (Y = y) can be evaluated in bX to
determine whether the observation Y = y is necessary, possible or impossible after applying
the action a. Thus, factored belief tracking also solves the generalized BTP problem.
As an illustration of Theorem 22, let us go back to the DET-Ring problems P whose
structure was analyzed before. The theorem implies that in order to check whether a given
possible execution achieves the goal in P , it is sufficient to check whether each goal literal
W (i) = locked, for 1  i  n, is achieved by the execution over the subproblem PW (i) . Thus,
factored belief tracking over P can be done in O(n2 ) time since there are n subproblems
PW (i) , each one involving 2 variables: W (i) with a constant-size domain and Loc with a
domain of size n.
The exact same situation arises in the non-deterministic conformant problem NON-DET
Ring whose causal graph is the same as the one for DET-Ring. On the other hand, for NONDET-Ring-Key, all the subproblems must keep track of the KLoc variable encoding the key
location, and thus a belief update operation requires O(n3 ) time, which is still much better
than flat belief tracking over P which requires time exponential in n. The same complexity
results applies when the problem is no longer conformant and the agent can observe whether
it is holding the key or not.
Some experimental figures for these domains are shown in Table 1, where factored belief
tracking was used in combination with simple heuristics. The experiments were run on a
Xeon Woodcrest 5140 CPU running at 2.33 GHz and with 8 GB of RAM. The planner
KACMBP by Cimatti et al. uses an OBDD-based belief representation and cardinality
heuristics, and can solve problems with up to n = 20 rooms, producing plans with 206
steps in slightly more than 1,000 seconds in NON-DET-Ring-Key. Conformant planners
such as T0 (Palacios & Geffner, 2009) cannot be used as the problem is non-deterministic.
Tables 1a and 1b show the scalability of the factored belief tracking algorithm in the context
of a greedy best-first search with a P
heuristic h(b), similar to the one used by Albore, Ramirez,
and Geffner (2011), where h(b) = ni=1 h(bi ), with bi being the belief factor in the projected
problem for the goal variable W (i) representing the status of the ith window, and h(bi )
representing the fraction of states in bi where the goal W (i) = locked is false. As displayed
in the tables, the resulting planner scales up polynomially, and for NON-DET-Ring-Key
with 100 rooms, produces a plan with 1, 111 actions in 783.1 seconds. For the contingent
version of the problem in which the agent detects when the key is in the room, CONT-DETRing-Key, a policy greedy in the cardinality heuristic h(b) = maxni=1 |bi | is used instead, with
936

fiBelief Tracking for Planning with Sensing

n

steps

exp.

time

n

steps

exp.

time

n

avg. steps

avg. time

10
20
30
40
50
60
70
80
90
100

68
138
208
277
345
415
476
545
610
679

355
705
1,055
1,400
1,740
2,090
2,395
2,740
3,065
3,410

< 0.1
0.1
0.9
3.1
8.3
18.6
34.5
62.8
106.4
171.0

10
20
30
40
50
60
70
80
90
100

118
198
278
488
438
468
543
616
682
1,111

770
1,220
1,670
3,210
2,570
2,660
3,080
3,480
3,880
7,220

< 0.1
0.8
4.2
15.2
34.4
52.2
100.6
172.9
285.6
783.1

10
20
30
40
50
60
70
80
90
100

326.8  4.3
1, 036.0  13.5
2, 068.0  26.5
3, 462.9  47.2
5, 130.7  71.0
7, 070.9  100.9
9, 334.1  127.6
11, 724.0  162.2
14, 617.4  204.6
17, 891.2  252.3

0.0
0.1
0.5
1.8
4.4
9.3
17.5
30.6
50.0
79.0

(a) DET-Ring-Key

(b) NON-DET-Ring-Key

(c) CONT-DET-Ring-Key

Table 1: Results for conformant and contingent Ring problems obtained by combining factored belief tracking with simple heuristics. Each data point in panel (c) for the contingent
problem is the average (and sample standard deviation) over 1,000 random instances. Times
are in seconds. The column exp. contains number of expansions.

ties broken randomly, where bi is the belief factor for the goal variable W (i). As it can be
seen in Table 1c, the resulting planner runs in polynomial time and can solve problems with
up to 100 rooms. Thus, while the heuristic and policy are weak, and long executions result,
belief tracking in this problem is efficient and scales up well.

8. Causal Belief Tracking
Factored belief tracking is exponential in the problem width. In many problems, however,
the width may be too high for the method to be usable in practice. As an illustration,
consider a problem P with state variables X1 , . . . , Xn+1 , and observable variables O1 , . . . , On
such that Oi is true iff Xi = Xi+1 . The sensors are thus Wa (Oi = true) = (Xi = Xi+1 )
and Wa (Oi = f alse) = (Xi 6= Xi+1 ) for all actions a and 1  i  n. Let us also assume
that the actions in the problem may affect each of the Xi variables but do not introduce
causal relations among them, and that all the state variables appear in preconditions or
goals. The causal graph of the problem is shown in Figure 2. Its width is n + 1 as all the
state variables interact. Indeed, each variable Xi is relevant to each variable Xk , with the
relevance flowing from Xi to Xi+1 , and vice versa, as both variables are causally relevant
to the observable variable Oi which is evidentially relevant to both. The result is that the
problem P and the projected problems PXi all coincide and denote the same problem, as
the contexts for each of the state variables include all state variables.
We now focus on a different decomposition for belief tracking that maps a problem P
into smaller subproblems PXc whose size is bounded by the number of state variables that are
all causally relevant to a given precondition, goal, or observation variable. This new width
measure will be called the causal width of the problem. The problem shown in Figure 2 has
width n + 1 but causal width 2. We will then explore belief tracking algorithms that are
exponential in the problem causal width and analyze the conditions under which they are
937

fiBonet & Geffner

X1

X2

X3



Xn

O1

O2

O3



On

Xn+1

Figure 2: Causal graph for the 2-layer network example with state variables X1 , . . . , Xn+1
and observable variables O1 , . . . , On+1 . The immediate causes of each observable Oi are
the variables Xi and Xi+1 . Precondition or goal variables appear as underlined and in a
yellow box, while observable variables appear within a blue circle. Since all Xi variables
are relevant to each other, the width of the problem is n + 1. On the other hand, since at
most two variables are causally relevant to a precondition, goal, or observable variable, the
causal width of the problem is 2.
complete. For this, we first generalize and make explicit the decomposition underlying the
factored belief tracking algorithm:
Definition 23. A decomposition of a problem P is a pair D = hT, Bi, where T is a set of
variables X appearing in P , called the target variables of the decomposition, and B is the
collection of beams B(X) associated with each such target variable which are made up of
state variables from P .
A decomposition D = hT, Bi maps P into a set of subproblems PXD , one for each variable
X in T , that corresponds to the projections of P over the state variables in the beam B(X).
The decomposition that underlies factored belief tracking is:
Definition 24. The factored decomposition F = hTF , BF i of P is the decomposition with
target variables TF given by the state variables X appearing in action preconditions or goals,
and beams BF (X) given by the state variables Y that are relevant to X.
Factored belief tracking is flat belief tracking applied to the subproblems determined by
the factored decomposition. The algorithms that we introduce next are based on a different
decomposition:
Definition 25. The causal decomposition C = hTC , BC i of P is the decomposition with
target variables TC given by the observable variables and the state variables appearing in
action precondition or goals, with beams BC (X) given by the state variables Y that are
causally relevant to X.
The causal decomposition determines a larger number of subproblems, as subproblems
are also generated for the observable variables, but these subproblems have smaller beams
BC (X), as they only contain the state variables that are causally relevant to X as opposed
to the variables that are relevant to X. The causal width of a problem is given by the size of
the largest beam in the causal decomposition, discounting the variables that are determined
in the problem:
Definition 26. The causal width of a variable X in a problem P , wc (X), is the number of
state variables that are causally relevant to X and are not determined. The causal width
938

fiBelief Tracking for Planning with Sensing

of P is maxX wc (X), where X ranges over the target variables in the causal decomposition
of P .
The first and simplest belief tracking algorithm defined over the causal decomposition
is what we call Decoupled Causal Belief Tracking, which runs in time and space that are
exponential in the problem causal width:
Definition 27. Decoupled causal belief tracking (Decoupled CBT) is flat belief tracking
applied independently to each of the problems PXC determined by the causal decomposition
C = hTC , BC i of P . The subproblem PXC is the problem P projected on the variables in
BC (X) for X  TC ; i.e., PXC = PBC (X) .
Since causal width is never greater than width and is often much smaller, Decoupled
CBT runs much faster than factored belief tracking in general. This, however, comes at a
price that we express using the expression S b for denoting the projection of (the states in
the) belief b over the variables in S.
Theorem 28. Decoupled CBT runs in time and space that are exponential in wc (P ), and
it is sound but not complete. That is, for any target variable X in the causal decomposition,
if b and bX are the beliefs resulting from an execution on P and PXC respectively, then
bX  BC (X) b is necessarily true, but bX  BC (X) b is not.
One reason for the incompleteness is that the beliefs bX associated with different target
variables X are assumed to be independent in Decoupled CBT while this may not be
true. Indeed, the causal decomposition of a problem may give rise to a beam BC (Y )
involving variable X, and a second beam BC (Z) involving the same variable X and another
variable X 0 . If variable Y is then observed, X = x may become false, which from a further
observation on Z may lead to X 0 = x0 becoming false as well. Yet, in Decoupled CBT, this
inference cannot be captured as there is no information flow across beams. In the factored
decomposition a situation like this cannot happen as variable X 0 will be relevant to variable
X and hence beams that contain X will necessarily contain X 0 (X 0 is relevant to X because
its causally relevant to Z which is evidentially relevant to X).
In the causal decomposition, beams are kept small by not closing them with the relevance
relation, but as a result, the beliefs over such beams are no longer independent. However,
regarding the beliefs as tables or relations, a consistency relation among the local beliefs
in the causal decomposition can be enforced by means of the join operation. The resulting
algorithm is Coupled Causal Belief Tracking, abbreviated simply as Causal Belief Tracking:
Definition 29. Causal Belief Tracking (CBT) is the belief tracking algorithm that operates
on the causal decomposition C = hTC , BC i by setting the beliefs b0X at time 0 for each beam
BC (X) to the projection on BC (X) of the initial belief, X  TC , and the successive beliefs
bi+1
X as:
bi+1
n{(biY )oa : Y  TC and Y is relevant to X}
(5)
X = BC (X) o
where a = ai and o = oi are the action and observation at time i in the execution, and
(biY )oa is boa from Eqs. 1-2 with b = biY .
In CBT, the beliefs are not tracked independently over each of the subproblems PXC of
the causal decomposition; rather, the beliefs are first progressed and filtered independently,
939

fiBonet & Geffner

but are then merged and projected back onto the beams, making them consistent with each
other. The progression and filtering of the local beliefs in the causal decomposition is performed in time and space exponential in the problem causal width, but the full consistency
operation captured by the join-project operation in (5) requires time that in the worst case
is exponential in the problem width:
Theorem 30. CBT is space exponential in the causal width of the problem, and time
exponential in its width.
CBT is sound but incomplete. However, the range of problem for which CBT is complete,
unlike Decoupled CBT, is large and meaningful enough, and it includes for example three
of the domains to be considered in the experiments below: Battleship, Minesweeper and
Wumpus. We express the completeness conditions for CBT by introducing the notion of
memory variables:
Definition 31. A state variable X is a memory variable in problem P when the value X k of
the variable X at time point k in an execution is determined uniquely from an observation
of the value X i of X at any time point i, i  k, the actions in the execution, and the initial
belief state of the problem.
For example, static variables are memory variables as they do not change and thus
knowing their value at any time point determines their value at any other point. Determined
variables (Section 4) are also memory variables since the value X k of such variables is
determined by the initial belief and the actions done up to time k. Likewise, variables in
permutation domains where actions permute the values of the variables (Amir & Russell,
2003), are also memory variables. These are three sufficient conditions for a state variable
to be a memory variable that are all easy to check. A problem is said then to be causally
decomposable when the following condition holds:
Definition 32. A problem P is causally decomposable when for every pair of beams BC (X)
and BC (X 0 ) in the causal decomposition of P with a non-empty intersection, where X 0 is
an observation variable, either 1) the variables in the intersection are all memory variables,
or 2) there is a variable W in the causal decomposition that is relevant to X or X 0 and
whose causal beam BC (W ) contains both BC (X) and BC (X 0 ).
If the problem is causally decomposable, the filtering implemented by the updates in
CBT using Equation 5 suffices for completeness:
Theorem 33. Causal belief tracking is always sound and it is complete for causally decomposable problems.
The importance of this result is that there are many meaningful domains whose problem
instances are causally decomposable; in particular, domains where all variables that appear
in two different beams are static (this include Minesweeper), domains where all variables
that appear in two different beams are either static or determined (this includes Wumpus,
where the non-static variable for the agent location is determined), domains where the
hidden non-static state variables only appear in one beam (this includes Battleship where
the hidden non-static variables do not appear in intersection of beams), and other cases
as well. In Sect. 11.4, we present a variation of Wumpus in which the monster moves
non-deterministically in the grid and that it is also an instance of a causally-decomposable
problem.
940

fiBelief Tracking for Planning with Sensing

9. Approximation: Beam Tracking
The causal belief tracking algorithm shows that it is possible to track beliefs for planning in a
sound and complete manner for a large and meaningful class of problems, while considering
the beliefs over subproblems that are smaller than those in the factored decomposition.
The algorithm, however, while space exponential in the causal width of the problem, it is
time exponential in the problem width. This is because of the global consistency operation
enforced by (5). Beam tracking is the final belief tracking algorithm that we consider:
it replaces this global consistency operation by a local consistency operation that can be
performed in polynomial time. Beam tracking is thus an approximation of causal belief
tracking which is aimed at being efficient and effective rather than complete.
Definition 34. Beam tracking is the belief tracking algorithm that operates on the causal
decomposition C = hTC , BC i, setting the beliefs b0X at time 0 to the projection of the initial
belief over the beam for X  TC , and setting the successive beliefs bi+1
X in two steps. First,
i
o
they are set to the progressed and filtered belief ba for b = bX , a = ai and o = oi , where
ai and oi are the action and observation at time i in the execution. Then, a local form
of consistency is enforced upon these beliefs by means of the following updates until a fixed
point is reached:
i+1
(6)
bi+1
nbi+1
Y )
X = BC (X) (bX o
where Y refers to any other target variable in the causal decomposition such that BC (Y ) 
BC (X) is non-empty.
The filtering represented by the iterative update in Eq. 6 defines a form of relational
arc consistency (Dechter & Beek, 1997) where equality constraints among beams sharing
common variables is enforced in polynomial time and space in the size of the beams. Beam
tracking remains sound but is not complete. In causally decomposable problems, however,
the incompleteness is the sole result of replacing global by local consistency.

10. Extensions, Modeling, and Width
Before testing the beam tracking algorithm empirically, we present two simple extensions
to the language of contingent planning that are useful for modeling, and briefly discuss
modeling choices that affect the causal width of a problem. The first extension allows the
use of defined variables in preconditions and goals; the second extension allows the use of
state constraints for restricting the possible value combination of subsets of variables.
10.1 Defined Variables
A variable Z with domain DZ can be defined as a function of a subset of state variables in the
problem, or as a function of the belief over such variables. For example, a boolean variable
Z can be defined as true when two variables X and Y are equal, or when a third variable W
is known to be true. Defined variables Z that are a function of a set SZ of state variables
or a function of the belief over such variables, can then be handled in action preconditions
and goals by introducing a beam in the decomposition that includes the variables in SZ
along with the variables that are relevant or causally relevant to them, according to whether
the decomposition is factored or causal. The width and causal width of the problem follow
941

fiBonet & Geffner

then, as before, as the size of the largest beam in the factored and causal decompositions
with the determined variables excluded.
10.2 State Constraints
State constraints are used to restrict the value combinations of given subsets of state variables. The game of Battleship, for example, can be modeled with state variables associated
with each of the cells in a grid for representing whether the cell is part of a ship, the size of
the ship to which the cell belongs (if any), the relative position of the cell within the ship
to which the cell belongs (if any), and whether such a ship is placed vertically or horizontally. These state variables, however, are not independent, and indeed, if a ship of size 10
is horizontally placed at cell (0, 0), the cells (0, i), for i  {0, 1, . . . , 9} must belong to (the
same) ship.
Formally, a state constraint represented by a formula C over the state variables can
be encoded by means of a dummy observable variable Y that is always observed to be
true, and that can be observed to be true only in states where C holds; i.e., with model
Wa (Y = true) = C for every action a. For the implementation, however, it pays off to treat
such constraints C as relations (the set of valuations that satisfy C), and to include them
in all the joins over the beliefs that include the variables in C. In causal belief tracking
this has no effect on the completeness or complexity of the algorithm, but in beam tracking,
changing the update in (6) to
i+1
n C1 o
n  o
n Cn )
n bi+1
bi+1
Y o
X = BC (X) (bX o

(7)

where C1 , . . . , Cn are the state constraints whose variables are included in BC (X)  BC (Y ),
makes local consistency stronger with no effect on the complexity of the algorithm. Moreover, when there is one such pair of beams for each state constraint, the state constraints
can increase the causal width of the problem by a constant factor of 2 at most, yet the
effective causal width of the problem does not change, as the beams associated with the
dummy observables introduced for such constraints are redundant and can then be ignored.
In this later case, when using beam tracking, the constraints Ci do not need to be stored
in extensional form as relations but can be handled intentionally as boolean functions that
test whether an assignment in the join of two beams satisfies the constraint.
10.3 Modeling and Width
The complexity of the belief tracking algorithms is a function of the width or causal width
of the problem, which in turns depends on the way the problem is encoded. Often small
changes in the encoding can have a drastic effect on the resulting widths. For example, in
the Wumpus problem (Russell & Norvig, 2009), it is natural to define the conditions under
which the stench signal can be received by setting its observation model to:

W
W
Wa (stench = true) = c (pos = c)  c0 wumpc0
where pos encodes the agent position, c ranges over the possible cells, c0 ranges over the cells
that are adjacent to c, and wumpc0 denotes the presence of a wumpus at c0 . This encoding,
however, results in a beam for the observable variable stench that includes all the wumpc
942

fiBelief Tracking for Planning with Sensing

szx,y

hitx,y

waterx,y

nhitsx,y

ancx,y

hzx,y

Figure 3: Causal graph fragment for Battleship. Circled variables are observable while the
others are state variables. The problem has one type of variable for each cell (x, y) on the
grid. Causal width for the problem is 5.
variables, and hence whose size grows with the grid size. A better alternative that results
in beams of bounded causal width is to exploit the fact that the position of the agent pos
is determined. Taking advantage of this, the observable variable stench can be replaced by
observable variables stenchc , one for each cell in the grid, with sensors characterized by the
model:
Wa (stenchc = true) = (pos = c) 

W

c0

wumpc0 .

The beams for the stenchc variables contain at most four wumpc0 variables, one for each cell
c0 adjacent to c. In this way, the causal width of the Wumpus problem becomes bounded
and independent of the grid size, and of the number of wumpus and pits (see below).
The idea
W can be generalized and automated. Any observation model of the form Wa (Z =
z) = x (x)  (x), where (x) is a formula constructed from determined variables,
can be replaced by observation models Wa (Zx = z) = (x)  (x) by expanding the
number of observable variables. Likewise, multiple observation models Wai (Z = z) = i
for one observable variable Z and different actions {ai }iR can be conveniently replaced by
observation models Wai (Zi = z) = i , i  R for different observable variables Zi , when the
different i formulas involve different variables. These alternatives in the domain encoding
can be the difference between bounded and unbounded causal width, and hence, on whether
the complexity of beam tracking will grow polynomially or exponentially.

11. Experiments
We have tested beam tracking over large instances of Battleship, Minesweeper, and Wumpus, in combination with simple heuristics for action selection that make use of the computed beliefs. The width of these problems is not bounded, and hence, neither factored
or causal belief tracking can be used except over small instances. On the other hand, all
these domains have small and bounded causal widths in the encodings provided, and hence
beam tracking runs efficiently in both time and space. Exact belief tracking in some of
these domains is difficult (Kaye, 2000; Scott, Stege, & Rooij, 2011), and the sizes of the
instances considered are much larger than those used in contingent planning. Moreover,
some of these domains do not have full contingent solutions. We thus compare our on-line
planner that relies on handcrafted heuristics with two reported solvers that rely on belief
tracking algorithms tailored to the domains. We also consider a non-deterministic version
of the Wumpus domain. The results have been obtained on a Xeon Woodcrest 5140 CPU
running at 2.33 GHz with 8GB of RAM.
943

fiBonet & Geffner

11.1 Battleship
Battleship is a popular two-player guessing game. The standard version consists of four
ships of length 2, 3, 4 and 5 units that are secretly placed on a 10-by-10 grid, with no ship
adjacent or diagonally adjacent to another. The task is to sink the ships by firing torpedos
at specific cells. For each fired torpedo, we are told whether the torpedo hits water or ship.
A ship is sunk when all its cells are hit. The problem is encoded with 6 state variables
per cell (x, y):6 hitx,y tells if a torpedo has been fired at the cell, szx,y tells the size of the
ship occupying the cell (0 if no such a ship), hzx,y tells if the ship is placed horizontally or
vertically (true if no such ship), nhitsx,y tells the number of hits on the ship (0 if no such
ship), and ancx,y tells the relative position of the ship on the cell (0 if no such ship). There
is a single observable boolean variable water with a deterministic sensor model given by
Wf ire(x,y) (waterx,y = true) = (szx,y = 0). The action model is more complex because firing
a torpedo at (x, y) may cause a change in the variables associated to other cells (x0 , y 0 ).
Indeed, if d denotes the maximum size of a ship (5 in the standard game), then f ire(x, y)
includes conditional effects for variables referring to cells (x0 , y 0 ) that are at a vertical or
horizontal distance of at most d units. The goal of the problem is to achieve the equality
nhitsx,y = szx,y over the cells that may contain a ship. State constraints are used for
constraining sets of state variables as described above. In this encoding, the causal beams
never contain more than 5 variables, even though the problem width is not bounded and
grows with the grid size. Figure 3 shows a fragment of the causal graph for Battleship.
Table 2 shows results for two policies: a random policy that fires at a non-fired cell at
random, and a greedy policy that fires at the non-fired cell most likely to contain a ship.
Approximations of these probabilities are obtained from the beliefs maintained by beam
tracking.7 The difference in performance between the two policies shows that the beliefs
are very informative. Moreover, for the 10  10 game, the agent fires 40.0  6.9 torpedos
in average, matching quite closely the average results of Silver and Veness (2010) that are
obtained with a combination of UCT (Kocsis & Szepesvari, 2006) for action selection, and
a particle filter (Doucet et al., 2000) hand-tuned to the domain for belief tracking. Their
approach, however, involves 65,000 simulation per action that result in the order of 2 seconds
per game over 10  10 instances, while our greedy approach takes 0.0096 seconds per game.
11.2 Minesweeper
The objective in Minesweeper is to clear a rectangular minefield without detonating a mine.
Each play either opens or flags a cell. In the first case, if the cell contains a mine, the game
is terminated; otherwise an integer counting the number of mines surrounding the cell is
revealed. An initial configuration for minesweeper consists of a m  n minefield with k
randomly-placed mines. There are three standard difficulty levels for the game that are
made up of 8  8, 16  16 and 16  30 boards with 10, 40 and 99 mines respectively.
6. This is a rich encoding that allows to accommodate the observation that a ship has been fully sunk. In
the experiments, however, this observation is not used in order to compare with the results reported by
Silver and Veness (2010).
7. Probabilities for events defined by the variables in a beam are obtained by the ratio of number of states
in the beam that satisfy the event to the total number of states in the beam.

944

fiBelief Tracking for Planning with Sensing

avg. time per
dim

policy

#ships

#torpedos

decision

game

10  10
20  20
30  30
40  40

greedy
greedy
greedy
greedy

4
8
12
16

40.0  6.9
163.1  32.1
389.4  73.4
723.8  129.2

2.4e-4
6.6e-4
1.2e-3
2.1e-3

9.6e-3
1.0e-1
4.9e-1
1.5

10  10
20  20
30  30
40  40

random
random
random
random

4
8
12
16

94.2  5.9
387.1  13.6
879.5  22.3
1,572.8  31.3

5.7e-5
7.4e-5
8.5e-5
9.5e-5

5.3e-3
2.8e-2
7.4e-2
1.4e-1

Table 2: Results for Battleship. The table contains results for the greedy and random
policies described in the text. For the 10  10 board, there are 4 ships of sizes 2, 3, 4 and 5.
As the size of the board is increased with n, the number of ships of each size gets multiplied
by n. Average and sample standard deviation for the number of torpedos required to sunk
all ships, calculated over 10,000 random instances for each board, are shown. Average times
are in seconds.

The problem is encoded with 3mn boolean state variables minex,y , openedx,y and
f laggedx,y that denote the presence/absence of a mine at cell (x, y) and whether the cell has
been opened or flagged, and mn observable variables obsx,y with domain D = {0, . . . , 9}.
There are two type of actions open(x, y) and f lag(x, y) where the first has no precondition and effect f laggedx,y  openedx,y , while the second has precondition minex,y and
effect f laggedx,y . The sensor model is given by formulas that specify the integer that the
agent receives when opening a cell in terms of the status of the minex0 ,y0 variables over the
surrounding cells. These formulas are:
Wopen(x,y) (obsx,y = 9) = minex,y ,
Wopen(x,y) (obsx,y = k) = minex,y 

W

tN (x,y,k) t ,

for 0  k < 9 ,

Wopen(x,y) (obsx0 ,y0 = k) = true ,

for (x0 , y 0 ) 6= (x, y) and 0  k  9 ,

Wf lag(x,y) (obsx0 ,y0 = k) = true ,

for each (x0 , y 0 ) and 0  k  9 ,

where N (x, y, k) are the terms over the 8 cell variables minex0 ,y0 surrounding the cell (x, y)
that make exactly k literals true. In the initial situation, the variables openedx,y and
f laggedx,y are false and minex,y is unknown. The goal of the problem is to get the disjunction f laggedx,y  openedx,y for each cell (x, y) without triggering an explosion.
The beams that result from the factored decomposition contain all the 3mn state variables, making all beams identical and resulting in an unbounded width of 3mn. The causal
width, on the other hand, is 9 as the causal beams for openedx,y and f laggedx,y are identical
and contain just 3 variables, while the beams for obsx,y contain the 9 minex0 ,y0 variables
for the cells (x0 , y 0 ) that surround the cell (x, y) along with the variable minex,y . Figure 4
contains a fragment of the causal graph for Minesweeper.
945

fiBonet & Geffner

minex0 ,y0

minex,y

f laggedx,y

openedx,y

obsx,y
Figure 4: Sketch of the causal graph for Minesweeper. There are observable variables obsx,y
and state variables minex,y , f laggedx,y and openedx,y for each cell (x, y). The cell (x0 , y 0 )
represents one of the adjacent cells to (x, y). Since there are 8 such cells, the causal width
of the problem is 9.
avg. time per
dim

#mines

density

%win

#guess

decision

game

88
16  16
16  30
32  64

10
40
99
320

15.6%
15.6%
20.6%
15.6%

83.4
79.8
35.9
80.3

606
670
2,476
672

8.3e-3
1.2e-2
1.1e-2
1.3e-2

0.21
1.42
2.86
2.89

Table 3: Results for Minesweeper. The table contains results for the three standard levels
of the game plus a larger instance. Average results over 1,000 runs are shown. Average
times are in seconds.

Table 3 shows results for the three standard levels of the game and for a much larger
instance. As in Battleship, the greedy policy used for action selection makes use of the beliefs
computed by beam tracking, flagging or opening a cell when certain about its content, else
selecting the cell with the lowest probability of containing a mine and opening it, with the
probabilities approximated from the beliefs over the beams as indicated before. Despite
the complexity of the game, NP-complete for checking consistency (Kaye, 2000) and coNPcomplete for inference (Scott et al., 2011), beam tracking scales well and solves difficult
games quickly. Moreover, the results shown in the table are competitive with those recently
reported by Lin, Buffet, Lee, and Teytaud (2012), which are obtained with a combination of
UCT for action selection, and a domain-specific CSP solver for tracking beliefs. The success
ratios that they report are: 80.2  0.48% for the 8  8 instances with 10 mines, 74.4  0.5%
for the 16  16 instances with 40 mines, and 38.7  1.8% for the 16  30 instances with 99
mines. The authors do not report times.
11.3 Wumpus
The Wumpus game (Russell & Norvig, 2009) consists of a maze in which there is an agent
that moves around looking for the gold while avoiding hidden pits and wumpus monsters.
Initially, the agent does not know the positions of the gold, pits or wumpuses, but it senses
glitter when at the same cell as the gold, and senses a stench or a breeze when at an adjacent
cell to a wumpus or a pit respectively. An m  n instance is described with known state
variables for the position and orientation of the agent, and hidden boolean variables for
each cell that tell whether there is a pit, a wumpus, or nothing at the cell. One more
946

fiBelief Tracking for Planning with Sensing

heading
gold-pos

pos

pitx0 ,y0

wumpx0 ,y0

glitter

deadx0 ,y0

breezex,y

stenchx,y

Figure 5: Fragment of the causal graph for Wumpus. There are observable variables
breezex,y , stenchx,y and deadx,y , and state variables heading, pos, pitx,y and wumpx,y ,
for (x, y) ranging over the grid cells. Cells (x0 , y 0 ) stand for cells adjacent to (x, y). The
causal width of the problem is 4 as there are 4 such cells, while the state variables heading
and pos are determined.
hidden state variable stores the position of the gold. The observable variables are boolean:
glitter, breezex,y , stenchx,y and deadx,y , with (x, y) ranging over the different cells. The
actions are move forward, rotate right or left, and grab the gold. The causal width for the
encoding is 4 while the problem width grows with m and n. Figure 5 shows a fragment
of the causal graph for Wumpus. The size of the causal beams for the breeze and stench
variables is bounded by 4 because each cell has at most 4 neighbors and the heading and
position variables for the agent are determined.
Table 4 shows results for different grid sizes and number of pits and wumpus, for an
agent that selects actions with a greedy policy based on a heuristic that returns the length
of a minimum-length safe path to the nearest cell that may contain the gold. The beliefs
computed by beam tracking are used to determine which cells are safe (known to contain
no wumpus or pit) and may contain the gold. We are not aware of any other tested and
scalable solver for Wumpus for making a comparison, with the exception of our own recent
LW1 planner that has built on this work (Bonet & Geffner, 2014). The figures in the table
show clearly that beam tracking computes beliefs effectively and efficiently in this domain.
For instance, the 30  30 instances with 32 pits and 32 wumpus are solved successfully 89%
of the time, in less than 4.4 seconds on average. Moreover, all the unsolved instances were
actually shown to be unsolvable in the sense that the agent could not reach an unvisited
cell in a safe manner. This was proved for each unsolved instance by calling a SAT solver
on a propositional theory that encodes the game and the literals learned by the agent after
the execution.
11.4 Non-Deterministic Moving Wumpus
In order to evaluate beam tracking in a more complex non-deterministic domain (the NONDET-Ring-Key domain in Section 7 has small width), we designed a non-deterministic
variant of the Wumpus domain. In Moving Wumpus there is just one wumpus in the grid
but this wumpus moves around non-deterministically everytime that the agent moves. The
grid still contains the hidden pits and the hidden gold, but in order to make the game safer
for the agent, the wumpus sensor is enhanced to detect the position of the wumpus when at
a (euclidean) distance less than 3 from the agent (else there is no safe strategy for escaping
death in general).
947

fiBonet & Geffner

avg. time per
dim

#pits/#wumpus

%density

#decisions

%win

decision

game

55
10  10
15  15
20  20
25  25
30  30
35  35
40  40
45  45
50  50

1/1
2/2
4/4
8/8
16 / 16
32 / 32
64 / 64
128 / 128
256 / 256
512 / 512

8.0
4.0
3.5
4.0
5.1
7.1
10.4
16.0
25.2
40.9

22,863
75,507
165,263
295,305
559,595
937,674
2,206,905
4,471,168
6,026,625
7,492,503

93.6
98.3
97.9
97.8
94.0
89.0
54.3
7.3
0.8
0.1

3.8e-4
9.6e-4
1.6e-3
2.4e-3
3.8e-3
4.7e-3
3.7e-3
2.8e-3
8.6e-3
1.3e-2

8.7e-3
7.2e-2
2.6e-1
7.2e-1
2.1
4.4
8.2
12.7
51.8
100.4

Table 4: Results for Wumpus. For each size, we performed 1,000 runs. The table shows
the total number and density of pits and wumpus in the grid, the total number of decisions
across all the runs, the percentage of runs in which the agent found the gold, and the average
time in seconds per decision and game.

Moving Wumpus is causally decomposable and thus the incompleteness of beam tracking
in this domain is only due to the replacement of the full consistency among beams done
by CBT by the weaker but efficient (relational) arc consistency done by beam tracking. To
see this, observe that the only variable that is not a memory variable is the position of
the wumpus WLoc. However, there are only two beams in the causal decomposition that
contain this variable: the beam for WLoc and the beam for the observable variable that
tells the position of the wumpus, and the former beam is contained in the latter beam.8
Experimental results for beam tracking over this domain are presented in Table 5 for a
policy obtained using the AOT lookahead algorithm based on AO* (Bonet & Geffner, 2012a)
that builds a lookahead tree of depth 10 using 50 expansions, and a heuristic function that
measures the distance between the agent position and the closest unvisited cell.
The algorithm was evaluated on different instances with grids nn for n = 4, 6, 8, . . . , 20,
each with a number of pits equal to (n  4)/2. For each grid size, we performed 1,000
evaluations for different initial configurations where the wumpus, pits and gold are randomly
placed. An instance of this game may turn unsolvable because the gold is isolated from the
agent by pits, because the agent finds itself in a position where there is no safe movement,
or because the agent exceeded the maximum number of actions (set to 3 times the number
of cells in the grid).

8. Indeed, a more general version of this problem involves m wumpuses that move non-deterministically
in the grid. This version is also causally decomposable as the beams for the positions of the wumpuses
(one for each wumpus) are all contained in the beam for the observable variable. In such general case,
the problem would have causal width equal to m.

948

fiBelief Tracking for Planning with Sensing

avg. time per
dim

#pits

%density

#decisions

%win

decision

game

44
66
88
10  10
12  12
14  14
16  16
18  18
20  20

0
1
2
3
4
5
6
7
8

0.0
2.7
3.1
3.0
2.7
2.5
2.3
2.1
2.0

13,770
30,666
54,528
85,635
123,921
159,977
231,307
309,919
362,816

97.6
95.0
94.8
93.0
93.6
93.4
91.7
90.0
90.8

3.5e-2
1.6e-1
4.1e-1
8.5e-1
1.3
2.2
3.1
4.1
5.3

4.9e-1
5.1
22.7
73.5
173.4
352.4
722.0
1,282.3
1,942.8

Table 5: Results for the Non-Deterministic Moving Wumpus domain. For each grid size,
averages over 1,000 runs shown. The table shows the total number and density of pits in
the grid, the total number of decisions across all the runs, the percentage of runs in which
the agent found the gold, and the average time in seconds per decision and game.

12. Related Work
The formulation in the paper is closely related to recent translation-based approaches to
conformant and contingent planning that compile beliefs away (Palacios & Geffner, 2009;
Albore et al., 2009). These translations, however, assume that the problems are deterministic.
Our account yields similar widths on most deterministic benchmarks, but is
simpler, because it is defined over multi-valued variables, and is more general, because it
handles non-deterministic actions. Yet our account is also less tight on some deterministic problems. As an illustration, if I = {x1      xn } and the actions are ai , each with
conditional effect xi  G, i = 1, . . . , n, the conformant problem with goal G has width
1 in Palacios and Geffners account, but width n in ours. The relevance account based
on literals is indeed finer than the one based on variables but it is also more difficult to
generalize to non-deterministic settings. This difference does not seem to have practical
effects over most benchmarks where disjunctions in the initial situation are exclusive and
implicitly encode the possible values of a set of multi-valued variables. Another important
difference with these approaches is that complete translations are always exponential in the
problem width, while our complexity bound is worst case; i.e., if the variables in contexts
are highly correlated, the actual complexity of factored belief tracking can be much lower.
The notion of width appears also in Bayesian networks where inference is exponential
in the width of the network (Pearl, 1988). Three differences that can be pointed out in
relation to our notion of width are that 1) we exploit the knowledge that certain variables
are not observable, 2) we can determine and use the knowledge that certain variables are
determined, and 3) we make use of the distinction between action conditions and preconditions in planning. As an example, a problem where an agent has to go through n doors
whose status, open or closed, can only be observed when the agent is near the door, will
have width no smaller than n when modeled as a dynamic Bayesian network, as all the door
variables affect the agent location variable. In our setting, however, the problem has width
949

fiBonet & Geffner

1 because the status of a door need to be known to the agent before it can open, close or
walk through the door.
The causal decomposition and the resulting causal belief tracking algorithms are similarly related to the ideas of variable splitting or renaming in graphical models, where a
variable X appearing in different factors fi is replaced by different variables Xi , one per
factor fi (Choi & Darwiche, 2006; Ramirez & Geffner, 2007), so that the problem width
can be reduced. Then, equality constraints relating the Xi variables must be enforced.
Approximate belief tracking algorithms for dynamic bayesian networks and POMDPs have
also appealed to the idea of decomposing global beliefs over all the variables into local beliefs over subsets of variables (Boyen & Koller, 1998; Shani, Poupart, Brafman, & Shimony,
2008). A key difference with the causal belief tracking algorithm is that we provide the
conditions under which this type of decomposition remains sound and complete. On the
other hand, we only deal with uncertainty represented by sets of states, not probability
distributions.
A number of logical schemes for representing and tracking beliefs have been used and
developed in contingent planning, appealing to OBDDs, CNF, and DNF representations
(Bertoli et al., 2001; Bryce et al., 2006; To et al., 2011), relevance considerations (Tran,
Nguyen, Son, & Pontelli, 2013), and lazy SAT and regression techniques (Hoffmann & Brafman, 2005; Rintanen, 2008; Shani & Brafman, 2011). None of these approaches, however,
has been tried on the domains considered in this paper or over instances of similar size.
Indeed, while the causal width of these domains bounds the complexity of beam tracking, no similar bound is known for these schemes that unlike beam tracking are complete.
Moreover, while in principle some of these schemes handle non-determinism naturally, other
methods like those based on SAT do not. The K-replanner (Bonet & Geffner, 2011) is also
based on a very efficient and effective belief tracking method that is polynomial but not
fully general and cannot deal with non-deterministic actions. The follow up LW1 planner
(Bonet & Geffner, 2014) shares the features of the K-replanner and is complete for width-1
problems.
From an experimental perspective, several comments and questions are in order on the
relation between beam tracking and the algorithms used for belief tracking in contingent
planners over the existing benchmarks. First of all, practically all of the benchmarks used
so far in contingent planning are easy from a belief tracking point of view. Indeed, the
quadratic and linear time representation of beliefs in CLG and LW1 respectively, have been
shown to be adequate for all such problems, including the Wumpus problems above. The
exception to this is Minesweeper, where belief tracking is provably NP-hard and where
the linear approximation in LW1 turns out to be much weaker than beam tracking, failing
to solve without guessing most of the instances that beam tracking can solve in this
way (Bonet & Geffner, 2014). This means that, whether the width of these problems
is low or high, their effective width is 1, and in such cases, beam tracking cannot help
computationally, and actually, may degrade performance (except in Minesweeper), as beam
tracking is exponential in the problem causal width, which while lower than width in general
is usually higher than 1. The effective width of a problem P is the minimum non-negative
integer value i such that the contingent translation Xi (P ) (Palacios & Geffner, 2009; Albore
et al., 2009) has a solution. The effective width of a problem is never greater than its width
but can be much smaller than both its width and than its causal width. For example, a
950

fiBelief Tracking for Planning with Sensing

avg. time per
dim

#mines

%density

%succ

%failure

%aborted

decision

game

88
16  16
30  16

10
40
99

15.6
15.6
20.6

93.0
94.0
65.0

7.0
6.0
6.0

0.0
0.0
29.0

0.8
4.9
12.4

56.3
1,268.4
5,998.6

Table 6: Comparison with the SDR on-line planner over Minesweeper instances. SDR is fed
with random hidden states and solutions (action sequences) computed by beam tracking
with no guessing. The planner task is then to check the applicability of actions in the given
solution and whether the goal holds. For each instance size, SDR is tested over 100 different
random problems. The column failure indicates the number of times that SDR was not able
to verify a correct solution, while the column aborted indicates the number of times that
SDR terminated early due to a bug. Times are in seconds. Beam tracking takes a few
seconds for solving these instances (see Table 3).

problem with actions ai with conditional effects that map valuations vi of a set of variables
X1 , . . . , Xn into the goal literal Y = y, will have a width and a causal width not smaller
than n as all the variables Xi are causally relevant to Y . Yet the effective width of such
a problem may be 1 if the values of each the Xi variables can be observed directly or
inferred from the observations, or also, if the goal can be achieved without using any of
these actions at all. In this sense, while the notion of effective width provides a lower bound
on the number of state variables whose uncertainty must be tracked jointly in order to make
the problem solvable, the notions of width, characterized syntactically, provides an upper
bound on the number of state variables whose uncertainty must be tracked jointly so that
no solution would be missed. The gap between these two bounds can be large indeed, and
obtaining syntactic characterizations of the former is an open problem.
A related question is how the various belief tracking algorithms used in contingent planning such as regression, OBDDs, CNF, and DNF, scale up over these domains. While a
general comparison of these complete but exponential algorithms with incomplete and polynomial algorithms like beam tracking (over domains with bounded causal width) would not
be fair, it would still be interesting to find out in which of the easy cases these algorithms scale up polynomially and in which exponentially. Performing these tests, however,
is not simple, as it requires getting into the code of the planners so that they would all
follow a fixed common policy in each instance, thus leaving the planning component aside.
Moreover, even fixing a policy for each instance, is not enough, as some of the planners are
off-line and hence track beliefs over many possible executions and not just one, as in the
case of on-line planners.
Just for the purpose of an illustration we performed this test in one of the difficult
domains, Minesweeper, by supplying the on-line planner SDR (Shani & Brafman, 2011)
the execution computed from beam tracking along with the hidden initial state for such an
execution. In this setting, the on-line planner SDR is not doing planning, but rather it is
tracking the beliefs over the problem to verify goal achievement and the preconditions of
the given applicable action at each time point. These are all Minesweeper instances solved
951

fiBonet & Geffner

by beam tracking without guessing; i.e., by pure inference after a first fixed choice. Table 6
shows the results for SDR that tracks beliefs using a form of regression (Rintanen, 2008;
Shani & Brafman, 2011). Two observations can be made by comparing the results in this
table with those in Table 3 for beam tracking. First, while SDR takes 56.3, 1,268.4 and
5,998.6 seconds on average for verifying solutions for 8  8, 16  16 and 30  16 instances
respectively, beam tracking takes 0.21, 1.42 and 2.86 seconds for finding these solutions by
following a greedy policy. Since finding solutions is more expensive than verifying them
 one must at least identify all applicable actions at each time point  the difference in
performance turns out to be of several orders of magnitude, growing with the grid size. In
addition, the regression mechanism in SDR fails to verify correct solutions in several cases
and aborts with failure in a large number of cases for the large instances. In any case,
the performance gap is not surprising: belief tracking in Minesweeper is NP-hard, thus
complete algorithms like regression will run in exponential time in the worst case, while
beam tracking remains polynomial as the causal width of the domain is bounded. In other
challenging problems, the gap in performance between beam tracking and complete belief
tracking algorithms will be similar. Beam tracking will be useful then if the causal width
of the problem is bounded and not too large, trading off in a principled way completeness
by tractability.

13. Summary
Effective belief tracking is crucial for planning with incomplete information and sensing.
While the problem is intractable in general, it has been shown elsewhere that belief tracking over deterministic problems is exponential in a width parameter that is often bounded
and small. In this work, we have introduced a related formulation that applies to nondeterministic problems as well. The factored belief tracking algorithm results from a set of
projected problems whose size is bounded by the problem width. The beliefs over goals
and preconditions are then obtained directly from the beliefs over these projected problems
that can be maintained independently. We have then developed a different decomposition
scheme and belief tracking algorithm that maintains beliefs over smaller projections, and
have provided the conditions under which the algorithm is complete. Causal belief tracking
is space exponential in the problem causal width but remains time exponential in the problem width, as the global consistency of the beliefs over the smaller projections need to be
enforced. Finally, beam tracking is a sound but incomplete approximation of causal belief
tracking where global consistency is replaced by a local but powerful form of consistency.
Beam tracking runs in time and space that are exponential in the problem causal width that
is often much smaller than the problem width. We have tested beam tracking over large
instances of Battleship, Minesweeper, and Wumpus, in combination with simple heuristics
for action selection, where performance compares well with state-of-the-art solvers while
using orders-of-magnitude less time. In the future, we would like to explore extensions of
the proposed framework for belief tracking in POMDPs, where belief states are not sets
of states but probability distributions, and particle-based algorithms provide a common
approximation (Doucet et al., 2000).
952

fiBelief Tracking for Planning with Sensing

Acknowledgments
We thank Gabriel Detoni for his Java Tewnta framework (http://code.google.com/p/
tewnta) for implementing client/server games with a graphical interface on which we developed graphical interfaces for Battleship, Minesweeper and Wumpus. Thanks also to
James Biagioni for his wumpuslite JAVA simulator (http://www.cs.uic.edu/~jbiagion/
wumpuslite.html) that we adapted to run the experiments for Wumpus, and to Guy Shani
for help running SDR. Hector Geffner is partially supported by EU FP7 Grant# 270019
(Spacebook) and MICINN CSD2010-00034 (Simulpast).

Appendix A. Proofs
Formal results that are needed but which are not stated as propositions or theorems in the
main text of the article appear here in the form of lemmas.
A.1 Complexity of Flat Belief Tracking
Let us first formally define the decision problems BTP and GBTP. BTP is the language
BTP = {hP,  i : P is a contingent problem,  is a possible execution, and b |= G}
where P = hV, I, A, G, V 0 , W i,  = ha0 , o0 , . . . , an , on i is an execution, and b is the belief
that results of the execution of  on the initial belief state. GBTP is like BTP except that it
consists of triplets hP, , `i such that P is a contingent problem,  is a possible generalized
execution, ` is a goal, precondition or observation literal, and b |= `.
Observe that BTP and GBTP respectively include the tuples hP,  i and hP, , `i such
that the problem has an empty initial belief state, due to two complementary literals appearing as unit clauses in I, since in such case every execution is trivially possible and b
trivially entails any literal `.
Proposition 3. BTP is polynomial-time reducible to GBTP.
Proof. The idea is to map a normal execution  into a generalized execution m that results
of replacing each pair ha, oi in  by the sequence ha, `1 , noopa , `2 , . . . , noopa , `|V 0 | i where
`1 , . . . , `|V 0 | are the observation literals made true by o, one for each observable variable
in V 0 , and noopa is the action that requires nothing and does nothing and whose sensor
model is Wnoopa (`) = Wa (`) for each observation literal `.
Formally, given an instance hP,  i for BTP, the reduction must generate in polynomial
time an instance hP 0 ,  0 , `i for GBTP such that hP,  i  BTP iff hP 0 ,  0 , `i  GBTP.
The problem P 0 is the problem P extended with the actions noopa , a new boolean
variable Xgoal that denotes the achievement of the goal G in P , a new action agoal with
precondition G and effect Xgoal , and a new dummy observable variable Y with domain
{>} and models Wa (Y = >) = true for all actions a. On the other hand, the generalized
execution  0 is hm , agoal , Y = >i and ` = Xgoal . Clearly, the reduction works in polynomial
time and hP,  i  BTP iff hP 0 ,  0 , `i  GBTP.
Theorem 5. Flat belief tracking is exponential in |VU |, where VU = V \ VK and VK is the
set of state variables in V that are determined.
953

fiBonet & Geffner

Proof. As described in Definition 4, flat belief tracking consists of an explicit representation
of beliefs as set of states, but some savings in space and time can be obtained by noting
that the variables in VK are determined.
With an explicit representation of beliefs, the belief tracking problem gets trivially solved
because checking whether an execution  = ha0 , o0 , . . . , an , on i is possible and a literal ` is
true after  reduces to computing the belief bn+1 that results from  and checking whether
bn+1 is empty and whether every state in it satisfies `. The time complexity of this algorithm
is the time needed to compute the initial belief b0 plus (n + 1) multiplied by the time needed
to compute bi+1 from bi plus the time needed to check the validity of `. Among these times,
the last is the easiest to calculate as it is linear in the size of bn+1 . We thus need to bound
the first two times. We begin the proof by showing that flat belief tracking can be done in
time exponential in |V | and then reduce the exponential dependency from |V | to |VU |.
For computing b0 it is enough to generate all possible states (valuations of variables)
and filter out those that do not satisfy the clauses in I. The total time thus spent is
|V |  |I|  2O(|V |) since there are 2O(|V |) valuations, |I| clauses, and each clause has at most
|V | literals.9
The time to compute bi+1 from bi consists of the time to check that the preconditions
of a hold at b, and the times to compute ba from b and boa from ba when b = bi , a = ai and
o = oi . The preconditions are easily verified by iterating over all states in b. The time for
this is bounded by |V |  2O(|V |) since a contains at most |V | preconditions and b contains
at most 2O(|V |) states. If some precondition is not satisfied at some state in b, the execution
is not possible.
The belief ba can be computed from b by iterating over each state s in b, and each
possible state s0 for ba , and then and checking whether s0  F (a, s). The two nested
iterations require time 2O(|V |)  2O(|V |) = 2O(|V |) . The test s0  F (a, s) can be performed
in time that is exponential in |V | as follows. Let Ci  E1i |    |Eni i , for 1  i  m, be the
collection of conditional effects for the action a that trigger at the state s. If s0  F (a, s),
then s0 is the result of applying one head from each such conditional effect on s. Since the
problem has |V | variables, then among the m heads there are at most |V | heads that map
s into s0 while the rest (if any) are subsumed by the first. All subsets of heads of size at
most |V | can be enumerated in 2O(|V |) time, for each such subset checking whether s gets
mapped into s0 requires O(|V |) time. Therefore, checking s0  F (a, s) requires 2O(|V |) time
as well as computing ba from b.
Once ba is obtained, boa is calculated by removing (filtering) from ba all states that do
not comply with the observation o. For each state s in ba and each observation literal
` compatible with o, the state s belongs to boa iff s |= Wa (`). This latter test can be
performed in time linear in |Wa (`)|, the size of the formula Wa (`). Hence, since there are
|V 0 | observation literals compatible with o, boa can be computed from ba in time O(|ba | 
|V 0 |  |Wa |) where |Wa | = max` |Wa (`)| and the max ranges over all observation literals `.
If boa is empty and ba is non-empty, the execution is not possible.
9. In this calculation, we implicitly assume that the variable domains are of constant size. Otherwise, if the
domains have size n that is linear in the input size, the number of valuations is bounded by 2O(|V | log n)
instead of 2O(|V |) . In either case, the number of valuations is still exponential in the number of variables
as well as the resulting complexity of flat belief tracking.

954

fiBelief Tracking for Planning with Sensing

Once all times are weighed in, we see that flat belief tracking can be done in time that
is exponential in |V |.
We now reduce the exponent from |V | to |VU |. This is direct since any determined
variable has the same valuation across all states in a reachable belief. Hence, such variables
do not contribute to increase the number of states in reachable beliefs. Likewise, only
subsets of heads of size |VU | need to be considered when computing the belief ba from b.
Hence, all computations can be done in time and space that is exponential only in |VU |.
Theorem 6. BTP and GBTP are Turing complete for the class PNP .
Proof. By Proposition 3, BTP is polynomial-time reducible to GBTP, and thus it is enough
to show the hardness for BTP and the inclusion for GBTP.
The class PNP is the set of all decisions problems that can be decided in (deterministic)
polynomial time using an oracle for SAT. To show that BTP is hard for this class, it is
enough to show that UNSAT can be reduced in polynomial time to BTP since then every
call to the NP oracle can be replaced by a call to the BTP oracle. On the other hand, to
show that GBTP belongs to PNP , it is enough to show that there is an algorithm for the
complement of GBTP (since PNP is closed under complementation) that runs in polynomial
time and that makes calls to an oracle for SAT.
Hardness. Let  = {C1 , . . . , Cm } be a CNF theory over boolean variables X1 , . . . , Xn .
We need to construct in polynomial time a contingent problem P = hV, I, A, G, V 0 , W i
and an execution  such that hP,  i  BTP iff  is unsatisfiable. The variables in the
problem P are all boolean given by V = {X1 , . . . , Xn , Q} and V 0 = {Z1 , . . . , Zm }. I is
the empty set of clauses and G = {Q = true}. The actions are a1 , . . . , am , all with empty
preconditions and no conditional effects, but with sensor model Wai (Zi = true) = Ci  Q
and Wai (Zj = true) = f alse for j 6= i. Finally, the execution is  = ha1 , o1 , . . . , am , om i
where oi is the V 0 -valuation that makes Zi true and Zj false for j 6= i.
Note that the initial belief contains all the 2n+1 V -valuations, half of them satisfying
Q and the other half Q. After the first observation o1 is received, only the valuations
that satisfy the clause C1 or Q are preserved. Thus, inductively, after observation oi is
received, only the valuations that satisfy the clauses in {C1 , C2 , . . . , Ci } or Q are preserved.
Therefore, b is the set of valuations that satisfy  or Q and hence it is non-empty (i.e.,  is
a possible execution). Thus, b |= G iff all valuations for Q are gone iff  is unsatisfiable.
Inclusion. The complement of GBTP consists of all tuples hP, , `i such that b0 is non-empty
and either  is non-executable or b 6|= `. Since I consists only of unit clauses, b0 6=  iff
I contains no pair of complementary literals. Assume that  = ha0 , `0 , a1 , `1 , . . . , an , `n i,
where the literals `i are observation literals, and let bi be the belief before the action ai
is applied; i.e., bi = boa for b = bi1 , a = ai1 and o = `i1 . Then,  is possible iff each
bi is non-empty and each action ai is applicable at bi . Assume that we have established
that the prefix i = ha0 , `0 , . . . , ai1 , `i1 i is possible, then checking whether i+1 is possible
involves two operations: 1) checking that each precondition literal of ai holds at bi1 and
2) checking whether there is at least one state in bai that complies with `i , for b = bi1 .
The first check can be done by calling the SAT oracle over the CNF theory i1 , over
time-indexed propositions for state-variable literals and actions, that encodes all possible
state trajectories for a fixed valuation of the actions. The time horizon for the theory is
955

fiBonet & Geffner

T = 0, . . . , i  1, and the theory is built in such way that it is satisfiable iff there is a state s
at time i  i (i.e., s in bi1 ) that does not satisfy at least one precondition of ai . This theory
is of polynomial size and can be built in polynomial time. Likewise, the second check can
be performed by calling the SAT oracle over the CNF theory i1 with the property that
it is satisfiable iff there is a state in bi1 that complies with the observation `i .
Hence, the algorithm A that decides the complement of GBTP works by building theories
t and t for t = 0, . . . , n. At each stage t, A ACCEPTs the input if t is satisfiable or t is
unsatisfiable. If, at the end, the algorithm has not accepted yet, then it builds another theory
n+1 , that is like i but instead of checking whether a precondition of action ai doesnt
hold, checks whether the input literal ` doesnt hold. If n+1 is satisfiable, A ACCEPTs
since the belief b does not satisfy `, else A REJECTs because hP, , `i  GBTP.
A.2 Factored Belief Tracking
In the following, for a state s (valuation of variables) and a subset S of variables, we write
s|S to denote the valuation s restricted to the variables in S, also called the projection of
s on S. In general, we use the symbols s, t and their primed versions to denote states,
and the symbols u, v and their primed versions to denote projected states (restrictions or
partial valuations).
Proposition 9. Belief tracking in the deterministic or non-deterministic conformant setting is exponential in the maximum number of non-determined variables that are all causally
relevant to a variable appearing in an action precondition or goal.
Proof. This proposition is a special case of Theorem 15 (and also of Theorem 33).
Theorem 15. Belief tracking in P is exponential in w(P ).
Proof. In the conformant setting, there are no observable variables and hence the evidential
relevance relation is empty and the relevant relation equals the causally relevant relation.
Therefore, the context of a variable X equals the set of variables that are causally relevant
to X, and this theorem establish Proposition 9 in the conformant setting.
In the general setting, the theorem is shown by constructing an algorithm for belief
tracking whose time complexity is only exponential in w(P ). The definition and analysis of
the algorithm is done through a series of claims that terminate at Theorem 22 below.
Proposition 18. If variable X appears in a goal or precondition, then the number of state
variables in PX that are not determined is bounded by w(P ).
Proof. The number of state variables in PX is |Ctx(X)| and the number of state variables
that are not determined in PX is |Ctx(X)  VU |. By definition of width, this quantity is
less than or equal to w(P ) when X is a goal or precondition variable.
We now establish two fundamental lemmas about the progression of actions and projection of observable models. In the following, we say that a subset S of variable is causally
closed if for any variable X  S and any variable Y that is causally relevant to X, Y  S.
Likewise, the causal closure of a variable Z is the minimum (with respect to set inclusion)
subset S of variables that is causally closed and includes Z.
956

fiBelief Tracking for Planning with Sensing

Lemma 1 (Factored Progression). Consider a consistent problem P . Let s be a state, and
a be an action that is applicable at s. Then, for any causally-closed subset S of variables:
1) for every u0 , if u0  FS (a, s|S ) then there is s0  F (a, s) such that u0 = s0 |S , and
2) for every s0 , if s0  F (a, s) then s0 |S  FS (a, s|S )
where FS is the transition function on the projected problem PS . Therefore, S F (a, s) =
FS (a, s|S ) for every state s on which a is applicable, and S F (a, U ) = FS (a, S U ) for every
set U of valuations on which a is applicable.
Proof. Part 1. Let u0 be an element in FS (a, s|S ) and let HS = {ESi }m
i=1 be the collection
of heads of the conditional effects CSi  ESi for a that trigger at s|S and result in u0 . For
fixed i  {1, . . . , m}, we know that s|S |= CSi . If ESi 6=  then, by definition of the causally
relevant relation, V ars(C i )  S and thus CSi = C i . Therefore, s |= C i and this effect also
triggers when a is applied at s. We now show that no other effect that affects a variable
in S triggers when a is applied at s. Indeed, if a conditional effect C  F that affects a
variable in S triggers, then s |= C and thus s|S |= CS and FS  HS . Finally, the effects
that trigger and affect the variables in S are the same in both problems P and PS . Since P
is consistent, the set of effects {E i }m
i=1 is contained in a set H of heads for the effects that
trigger when a is applied at s. Therefore, u0 is the projection over S of the state s0 that
results of applying the effects in H at s; i.e., u0 = s0 |S .
Part 2. Let s0 be an element in F (a, s) and let H = {E i }m
i=1 be the collection of heads of the
conditional effects C i  E i for a that trigger at s and result in s0 . For fixed i  {1, . . . , m},
we know that s |= C i and thus s|S |= C i |S . Therefore, the effects CSi  ESi also trigger
when a is applied at s|S in PS . We now show that no other effect that affects a variable in S
triggers when a is applied at s|S in PS . Indeed, let us suppose that a projected conditional
effect CS  FS that affects a variable in S triggers at s|S . Then, V ars(F )  S and thus
V ars(C)  S, since S is causally closed, and CS = C. Therefore, s |= C and this effect
also triggers when a is applied at s. Finally, since the effects that trigger and affect the
variables in S are the same in both problems P and PS , then s0 |S is the result of applying
0
the projected effects {ESi }m
i=1 at s|S ; i.e., s |S  FS (a, s|S ).
Lemma 2 (Observational Closure). For every variable X, action a, and observation literal
` = Z = z, Wa (`)S is either Wa (`) or true, where S = Ctx(X).
Proof. Let {X1 , . . . , Xn } be the variables in Wa (`). By the definition of the relevant relation,
Z is relevant to each Xi and vice versa. Hence, if Z or some Xi belongs to S, then Z and
all Xi belongs to S as well. Therefore, Wa (`)S is either Wa (`) or true.
The following results are obtained by induction on the length of the executions. As
noted before, there is no loss of generality if we consider generalized executions instead of
executions. However, it is easier to consider even more general executions that correspond
to finite sequences over the alphabet A  {ha, `i : a  A, `  Lits(V 0 )} where A is the
set of actions and Lits(V 0 ) is the set of observation literals. This type of executions are
more general because they do not require the interleaving of actions and observations; i.e.,
such an execution may contain multiple actions or observations in sequence. For example,
957

fiBonet & Geffner

an execution like ha0 , a1 , ha2 , `2 i, ha3 , `3 i, . . .i indicates that the initial belief needs to be
progressed with the actions a0 and a1 , then filtered with the formula Wa2 (`2 ), filtered again
with the formula Wa3 (`3 ), and so on. As in the case of normal and generalized executions,
there is a direct mapping between generalized executions and this new type of executions.
If  is one such execution, then b denotes the belief that results of applying  at the initial
belief, while if b = b , then ba and ba,` denote the beliefs that result from the executions
 0 = h, ai and  0 = h, ha, `ii respectively. Therefore, when making induction on the
length of executions to prove a claim, we need to show the claim for the initial belief that
corresponds to the empty execution, and then for beliefs of the form ba and ba,` for b = b .
The next definition and lemma make precise the notion of decomposable belief that
plays a fundamental role in our results. Intuitively, a belief b is decomposable when for
every pair of states s, t  b, there is a state w  b that agrees with s on the variables in
a subset S and agrees with t on the variables in a subset T (where S and T are certain
subsets of variables); in symbols, there is w  b such that w|S = s|S and w|T = t|T .
Definition and Lemma 3 (Decomposability). A belief state b is decomposable iff for
every variable X, observation literal ` = Z = z, action a, and subset T  V ars(Wa (`))
such that T is causally closed and T  Ctx(X) = , it holds:


s, t s, t  b = w w  b  w|Ctx(X) = s|Ctx(X)  w|T = t|T .
It turns out that every reachable belief is decomposable.
Proof. Let b be a reachable belief. Then, there is an execution  such that b = b . The
proof is by induction on the length of  . If  is empty, the claim holds since I contains only
unit clauses and T  Ctx(X) = .
Assume now that all beliefs reachable through executions of length less than or equal
to n are decomposable, and consider an execution  0 of length n + 1 that augments an
execution  of length n. In the following, b denotes the belief b , and res(a, s) denotes the
state that results of applying a deterministic action a on state s.
Case:  0 = h, a0 i. Let X, `, a and T be as in the statement of the lemma, S = Ctx(X),
and let s0 , t0 be two states in ba0 . Therefore, there are two determinizations a1 and a2 of
a0 such that s0 = res(a1 , s) and t0 = res(a2 , t) for some s, t  b. Apply inductive hypothesis
to obtain w  b such that w|S = s|S and w|T = t|T . Since S and T are disjoint and
causally closed, there is a determinization10 a3 of a0 such that res(a1 , s)|S = res(a3 , w)|S
and res(a2 , t)|T = res(a3 , w)|T . The sought w0  ba0 is thus w0 = res(a3 , w).
Case:  0 = h, ha0 , `0 ii. As before, let X, `, a and T be as in the statement of the lemma,
0 0
let `0 = Z 0 = z 0 , and let s0 , t0 be two states in ba ,` . We consider the two subcases whether
V ars(Wa0 (`0 ))  S or not, for S = Ctx(X):
Subcase: V ars(Wa0 (`0 ))  S. Since, s0 , t0  b, apply the inductive hypothesis to get w0  b
0 0
such that w0 |S = s0 |S and w0 |T = t0 |T . Then, w0  ba ,` because w0 |S = s0 |S |= Wa0 (`0 )S =
Wa0 (`0 ).
10. The existence of this determinization is granted by the second assumption on the planning problem and
the fact that the sets S and T of variables are disjoint.

958

fiBelief Tracking for Planning with Sensing

Subcase: V ars(Wa0 (`0 )) * S. By Lemma 2, V ars(Wa0 (`0 ))  S = . Let T 0 be the minimal
causally-closed subset of variables that includes T and V ars(Wa0 (`0 )). Observe that T 0 S =
 since if Y belongs to the intersection, then Z 0 is relevant to Y , Y is relevant to X, and thus
Z 0 is relevant to X contradicting V ars(Wa0 (`0 ))  S = . Apply the inductive hypothesis
using T 0 to get w0  b such that w0 |S = s0 |S and w0 |T 0 = t0 |T 0 . This is the w0 that
0 0
we are looking for because T  T 0 and thus w0 |T = t0 |T , and because w0  ba ,` since
w0 |T 0 = t0 |T 0 |= Wa0 (`0 )T 0 = Wa0 (`0 ).
A last technical lemma, before giving the proofs of Theorems 20 to 22, that establish
the existence of partial valuations in the projection of filtered beliefs is the following:
Lemma 4 (Factored Filtering). Let X be a variable, S = Ctx(X), b be a reachable belief,
a be an action, and ` = Z=z be an observation literal. If ba,` is non-empty and u is such
that u  S b and u |= Wa (`)S , then u  S ba,` .
Proof. Assume that ba,` is non-empty and let u be an S-valuation that satisfies the antecedent in the lemma. If Wa (`)S = Wa (`), then u |= Wa (`) and u  S ba,` .
If Wa (`)S 6= Wa (`) then by Lemma 2, V ars(Wa (`))  S = . Let T be the minimal
causally-closed subset of variables that includes V ars(Wa (`)). Note that if Y  S  T then
Z is evidentially relevant to Y which is relevant to X, and thus Z is relevant to X and
V ars(Wa (`))  S. Therefore, S  T = . Let t  ba,`  b and apply Lemma 3 to get
w  b such that w|S = u and w|T = t|T . Hence, w|T |= Wa (`)T = Wa (`), w  ba,` and
u  S ba,` .
Theorem 20. For a state variable X, let b and bX be the beliefs that result from an execution
that is possible over both P and PX . Then, X bX = X b.
Proof. Let  be an execution that is possible over both P and PX . We prove the more
general result that bX = S b for S = Ctx(X); it is more general because X  S and
X bX = X S b = X b. The proof is by induction on the length of  . If  is the empty
execution, then result follows readily since I contains only unit clauses. Assume that the
claim holds for executions of length n, and let  0 be an execution of length n + 1 that
augments an execution  of length n and that is possible over P and PX . Further, let b
and bX be the beliefs that result from  in P and PX respectively. Then, by inductive
hypothesis bX = S b.
Case:  0 = h, ai. We need to show that bX,a = S ba . In the following, FS denotes the
transition function in PX . The forward inclusion is given by


1
u0  bX,a = u u  bX  u0  FS (a, u)


2
= us u  bX  u0  FS (a, u)  s  b  s|S = u


3
= uss0 u  bX  u0  FS (a, u)  s  b  s|S = u  s0  F (a, s)  s0 |S = u0


4
= ss0 s  b  s0  F (a, s)  s0 |S = u0

 6
5
= s0 s0  ba  s0 |S = u0 = u0  S ba
959

fiBonet & Geffner

where 1 is by the definition of bX,a , 2 by inductive hypothesis, 3 by Lemma 1, and 5
and 6 by the definitions of ba and S ba respectively. The backward inclusion is

 2


1
s0 |S  S ba = s s  b  s0  F (a, s) = s s  b  s0  F (a, s)  s0 |S  FS (a, s|S )

 4
3
= s s|S  bX  s0 |S  FS (a, s|S ) = s0 |S  bX,a
where 1 is by the definition of ba , 2 by Lemma 1, 3 by inductive hypothesis, and 4 by
the definition of bX,a . Therefore, bX,a = S ba .
a,`
Case:  0 = h, ha, `ii. We need to show that ba,`
X = S b . The forward inclusion is
1

2

3

a,`
u  ba,`
X = u  bX  u |= Wa (`)S = u  S b  u |= Wa (`)S = u  S b

where 1 is by the definition of ba,`
X , 2 by inductive hypothesis, and 3 by Lemma 4. The
backward inclusion is
1

2

3

s|S  S ba,` = s  b  s |= Wa (`) = s|S  bX  s|S |= Wa (`)S = s|S  ba,`
X .
where 1 is by the definition of ba,` , 2 by inductive hypothesis, and 3 by the definition of
a,`
a,`
ba,`
X . Therefore, bX = S b .
Theorem 21. 1) An execution is possible in P iff it is possible over each of the subproblems
PX for X being a precondition or goal variable in P . 2) For an execution  and precondition
or goal variable X, X = x (resp. X 6= x) is true in b iff X = x (resp. X 6= x) is true in
bX , where b and bX are the beliefs that result of executing  in P and PX respectively.
Proof. Part 1. The proof is by induction on the length of the executions. The base case for
the induction is for the empty execution which is possible in P and in each PX . Assume
that the claim holds for executions  of length n, and let b and bX be the beliefs that result
from  in P and in each subproblem PX respectively. Let  0 be an execution of length
n + 1 that augments  . In the following, F denotes the collection of precondition and goal
variables in P , and S = Ctx(X) for X  F.
Case:  0 = h, ai. First, assume that  0 is possible in P . We need to show that  0 is possible
on each PX for X  F. By assumption, for each literal `  P re(a) and each s  b, s |= `.
Let ` be a literal in P re(a)S and u  bX for X  F. Then, V ars(`)  S and, by inductive
hypothesis and Theorem 20 (since  is applicable at P and PX ) applied to  , u = s|S for
some s  b. Therefore, u |= ` and a is applicable at bX .
Now, assume that  0 is possible in PX for each X  F. We need to show that  0 is
possible in P . If ` = X = x is a precondition of a, then `  P re(a)S and ` holds at each
state u  bX . If s  b then, by inductive hypothesis and Theorem 20 applied to  , there is
u  bX such that s|S = u. Thus, s |= ` and a is applicable at b.
Case:  0 = h, ha, `ii. First, assume that  0 is possible in P ; i.e., ba,` is non-empty. We need
to show that ba,`
X is non-empty as well for each X  F. We have
1

2

3

s  ba,` = s  b  s |= Wa (`) = s|S  bX  s|S |= Wa (`)S = s|S  ba,`
X
960

fiBelief Tracking for Planning with Sensing

where 1 is by the definition of ba,` , 2 by inductive hypothesis and Theorem 20, and 3 by
a,`
the definition of ba,`
X . Hence, bX is non-empty.
Finally, assume that  0 is possible in each PX ; i.e., ba,`
X is non-empty for each X  F.
a,`
We need to show that b is non-empty. Let X  F be such that Wa (`)S = Wa (`) for
S = Ctx(X); it exists because of the fourth assumption on the problem P and Lemma 2.
We have


1
2
u  ba,`
X = u  bX  u |= Wa (`)S = s u  bX  u |= Wa (`)S  s  b  u = s|S


3
= s u  bX  s |= Wa (`)  s  b  u = s|S

 5


4
= s s |= Wa (`)  s  b = s s  ba,`
where 1 is by the definition of ba,`
X , 2 by inductive hypothesis and Theorem 20, 3 by
Wa (`)S = Wa (`), and 5 by the definition of ba,` . Hence, ba,` is non-empty.
Part 2. Let  be a possible execution in P , and hence, by part 1, also possible in PX .
Let b and bX be the beliefs that result from  in P and PX respectively. By Theorem 20,
X bX = X b. Therefore, X = x (or X 6= x) holds at bX iff it holds at b.
Theorem 22. Flat belief tracking over each of the projected problems PX for X being a
precondition or goal variable in P , provides a sound and complete factored algorithm for
belief tracking over P that is time and space exponential in the width of P .
Proof. This is direct from Theorem 21. Let  be an execution and b and bX, be the
beliefs that result of executing  in P and PX respectively. Then,  is possible in P iff it is
possible at each PX . Therefore, flat belief tracking for the subproblems PX tells whether 
is possible or not in P . Furthermore, for each precondition or goal variable X, X = x holds
at b iff it holds at bX, . Thus, flat belief tracking for the subproblems PX is sufficient to
determine when an action is applicable or a goal belief has been reached.
By Theorem 5, flat belief tracking for subproblem PX is exponential in |Ctx(X)  VU |.
Therefore, flat belief tracking for all subproblems PX (simultaneously) is exponential only
in maxX |Ctx(X)  VU | where the max ranges over the precondition or goal variables X.
This latter expression is the one that defines w(P ).
Proposition 19. If an execution ha0 , o0 , a1 , o1 , . . .i is possible in P , then it is also possible
in PX for any state variable X in P .
Proof. If X is a precondition or goal variable, then the claim follows from Theorem 21. So,
assume that X is a state variable that does not appear as a precondition or goal. We show
using induction on the length of the (generalized) execution  that if  is possible in P
then it is also possible in PX . The base case for empty executions is direct. Consider an
execution  0 of length n + 1 that extends an execution  of length n. Let b and bX be the
result of applying the execution  in P and PX respectively, and let S = Ctx(X).
Case:  0 = h, ai. Let ` = Y = y be a precondition in P re(a)S and T = Ctx(Y ). Then,
Y  S and Ctx(Y )  Ctx(X) because Y is relevant to X. By Lemma 5 (below), bY  T bX .
961

fiBonet & Geffner

On the other hand, by Theorem 21, s |= ` for every s  bY . Therefore, ` holds at each state
s in bX , a is applicable at bX , and  0 is possible at PX .
Case:  0 = h, ha, `ii. If Wa (`)S = true, then ba,`
X = bX which is non-empty by inductive
hypothesis and thus  0 is possible at PX . If Wa (`)S 6= true and ` = Z = z, then Z is
relevant to X. Since by assumption there is a precondition or goal variable Y such that Z
is relevant to Y , it is not difficult to show that X is relevant to Y . Thus, Ctx(X)  Ctx(Y )
and bX  S bY by Lemma 5. Since  0 is possible in P and ba,`
Y is non-empty by Theorem 21,
0 is possible in P .
then ba,`
is
non-empty
and

X
X
A.3 Causal Belief Tracking
Lemma 5 (Soundness of Causally-Closed Decompositions). Let D = hT, Bi be a decomposition whose beams are causally closed, and let PXD be the subproblem corresponding to the
projection of P on the variables in B(X) for X  T . For any target variable X  T , if b and
bX are the beliefs resulting from an execution on P and PXD respectively, then bX  B(X) b.
Proof. The proof is by induction on the length of the executions. For the empty execution,
the claims holds since I contains only unit clauses. Let  0 be an execution of length  0
that augments  . In the following, b and bX denote the beliefs in P and PXD resulting after
execution  , and S denotes B(X).
Case:  0 = h, ai. Let u0  S ba . Then, there is s  b such that u0  S F (a, s). By
Lemma 1, u0  FS (a, s|S ). Thus, since s|S  bX by inductive hypothesis, u0  bX,a .
Case:  0 = h, ha, `ii. Let s|S  S ba,` . We have s  b and s |= Wa (`). By inductive
hypothesis, s|S |= Wa (`)S and s|S  bX . Thus, s|S  ba,`
X .
Theorem 28. Decoupled CBT runs in time and space that are exponential in wc (P ), and
it is sound but not complete. That is, for any target variable X in the causal decomposition,
if b and bX are the beliefs resulting from an execution on P and PXC respectively, then
bX  BC (X) b is necessarily true, but bX  BC (X) b is not.
Proof. Soundness follows directly from Lemma 5. The bounds on time and space are also
direct because the size of each beam BC (X) is bounded by the causal width wc (P ).
Theorem 30. CBT is space exponential in the causal width of the problem, and time
exponential in its width.
Proof. CBT maintains beliefs over the beams of the causal decomposition whose size are
bounded by the causal width of the problem. The join-project operation in CBT can be
performed across time, by considering one valuation at a time, without the need to first
compute and store the full joint. This is done by recursively iterating over all the beliefs
(bY )oa that participate in the join in (5), combining partial valuations from each belief, and
then storing its projection on the resulting belief bi+1
X . The number of valuations in the join
O(w(P
))
in (5) is bounded by 2
as any variable Z  BC (Y ), for Y relevant to X, is relevant
to X and thus Z  Ctx(X).
962

fiBelief Tracking for Planning with Sensing

It only remains to show Theorem 33 (stated below). The proof is not straightforward
so we split it in two parts. The first part reformulates CBT into an algorithm called Wide
(Causal) Belief Tracking (WBT), that is like CBT but performs the join operation over the
beliefs for all the variables in the problem and not only for the variables that are relevant to
X, and shows the soundness and completeness of WBT. In the second part, we show that
CBT is simply WBT applied to the subproblem PCtx(X) associated to the variable X in the
factored decomposition F , and then use the soundness and completeness of the factored
decomposition to finish the proof. The first part of the proof consists of Lemmas 68, while
the second part consists of Lemma 9 and Theorem 33.
WBT works on the causal decomposition C = hTC , BC i like CBT. The beliefs at time
0 for WBT are the same as for CBT: they are the initial belief projected into the causal
beams BC (X) for X  TC . Beliefs at later times are associated with executions  0 that
augment executions  . If we denote the belief for variable X  TC and execution  with
bX, , then the update equations for WBT are:
bX,h,ai = BC (X) o
n{FT (a, bY, ) : Y  TC } ,
bX,h,ha,`ii = BC (X) o
n{F ilter(Wa(`)T , bY, ) : Y  TC }

(8)
(9)

where T = BC (Y ) is the beam for Y , FT (a, U ) is the set uU FT (a, u), and F ilter(, U )
is the set {u  U : u |= }. These equations are essentially the equation (5) for CBT,
where progression and filtering had been separated, except that the join is performed over
all target variables instead of joining only the target variables that are relevant to X.
The following basic facts about joins, projections and filtering are easily shown and will
be used in the proofs. (We do not include their proofs here.) In their statements, the sets
U and Ui refer to sets of valuations, S refers to a collection of subset of variables, S refers
to a subset of variables and Si = V ars(Ui ), and  refers to a logical formula. The facts are:
BF1. U  o
n{S U : S  S},
BF2. For collection {Ui }iI ,

o
n{Si o
n{Ui : i  I} : i  I} = o
n{Ui : i  I},

BF3. S F ilter(, U )  F ilter(S , S U ).
Definition and Lemma 6. A decomposition D = hT, Bi factors a set U of V -valuations
iff U = o
n{B(X) U : X  T }.
A decomposition D = hT, Bi preserves transitions in a set U of V -valuations iff for
each pair of variables X, Y  T , and Z  B(X)  B(Y ), either i) Z is known in U (i.e.,
u[Z] = u0 [Z] for each u, u0  U ), ii) B(X)  B(Y )  B(W ) for some variable W  T , or
iii) for every action a, the transition function FS (a, ) is 1-1 for variable Z in U , where S
is the causal closure of Z.
Let D = hT, Bi be a decomposition such that V = XT B(X) and B(X) is causally
closed for each X  T , U be a set of V -valuations, and  be a V -formula. The following
claims hold:
1. If D factors U , then
F (a, U )  o
n{B(X)F (a, U ) : X  T } = o
n{FB(X)(a, B(X)U ) : X  T } .
963

fiBonet & Geffner

2. If D factors and preserves transitions in U , then
F (a, U ) = o
n{B(X)F (a, U ) : X  T } = o
n{FB(X)(a, B(X)U ) : X  T } .
3. If D factors U and there is X  T such that B(X) = , then
F ilter(, U ) = o
n{B(X)F ilter(, U ) : X  T } = o
n{F ilter(B(X), B(X)U ) : X  T } .
Proof. Part 1. The containment is direct by BF1, while the equality follows directly from
B(X) F (a, U ) = FB(X) (a, B(X) U ) by Lemma 1.
Part 2. The second equality and the forward inclusion for the first equality are the same
as in Part 1. We thus only need to show F (a, U )  o
n{B(X) F (a, U ) : X  T }. Let
u0 be an element in the right-hand side of this expression and X  T . Then, u0 |B(X) 
B(X) F (a, U ) and so (by Lemma 1) there is uX  B(X) U such that u0 |B(X)  FB(X) (a, uX ).
We claim that {uX }XT is a consistent collection of valuations. Indeed, if it is not, there
are valuations uX , uY and variable Z such that uX [Z] 6= uY [Z]. Clearly, Z is not known
in U . If B(X)  B(Y )  B(W ) for some W  T , then we can exchange uX and uY by
uW |B(X) and uW |B(Y ) respectively. Otherwise, we see that the function FS (a, ), where S is
the causal closure for Z, is not 1-1 for Z, contradicting the assumptions. Therefore, there is
a valuation u such that u|B(X) = uX for all X  T (i.e., u  o
n{B(X) U : X  T }) and thus,
by the assumption, u  U . Finally, since B(X) F (a, u) = FB(X) (a, u|B(X) ) = FB(X) (a, uX )
by Lemma 1, we have u0 |B(X)  B(X) F (a, u) and u0  F (a, U ).
Part 3. First, observe that BF1 and BF3 imply the chain of containments
F ilter(, U )  o
n{B(X)F ilter(, U ) : X  T }  o
n{F ilter(B(X), B(X)U ) : X  T } .
We finish by showing that equality holds through by proving that the last subset is contained
in the first. Let u0 be an element in the last subset. This u0 belongs to o
n{B(X) U : X  T }
and also to U since D factors U . We thus only need to show that u0 |= . This is direct
since by assumption there is X  T with B(X) = , and thus u0 |B(X) |= B(X) = .
Lemma 7 (Soundness of WBT). WBT is sound. That is, if C = hTC , BC i is the causal
decomposition of problem P , {bX }XTC are the local beliefs at time i, and b is the global
belief at time i, then b  o
n{bX : X  TC } and BC (X) b  bX for X  TC .
Proof. We really only need to proof the first claim b  o
n{bX : X  TC } because the second
follows directly from it by observing that bX is a belief over the variables in BC (X).
The proof of the first claim is by induction on the length of the executions. The base
case for the empty execution is easily verified. Assume that the claims hold for executions
of length n and let  0 be an execution of length n + 1 that augments an execution  of
length n. Observe that C factors U = o
n{bY, : Y  TC } by BF2, and b  U by inductive
hypothesis.
Case:  0 = h, ai.

o
n{bX,

1

0

: X  TC } = o
n{BC (X) o
n{FBC (Y )(a, bY, ) : Y  TC } : X  TC }
964

fiBelief Tracking for Planning with Sensing

2

o
n{BC (X) o
n{FBC (Y )(a, BC (Y )U ) : Y  TC } : X  TC }
3

4

 F (a, U )  F (a, b ) = b 0
where 1 is by Eq. 8, 2 because bY,  BC (Y ) U , 3 by part 1 of Lemma 6, and 4 by
inductive hypothesis.
Case:  0 = h, ha, `ii.

o
n{bX,

9

0

: X  TC } = o
n{BC (X) o
n{F ilter(Wa(`)BC (Y ), bY, ) : Y  TC } : X  TC }
10



o
n{B

C (X)

o
n{F ilter(Wa(`)B

C (Y

) , BC (Y ) U )

: Y  TC } : X  TC }

12

11

= F ilter(Wa (`), U )  F ilter(Wa (`), b ) = b 0
where 9 is by Eq. 9,
inductive hypothesis.

10

because bY,  BC (Y ) U ,

11

by part 3 of Lemma 6, and

12

by

Lemma 8 (Completeness of WBT). Let C = hTC , BC i be the causal decomposition of
problem P . If C preserves transitions in every reachable belief state, then WBT is complete.
That is, if {bX }XTC are the local beliefs at time i, and b is the global belief at time i, then
b=o
n{bX : X  TC } and BC (X) b = bX for X  TC .
Proof. The proof is by induction on the length of the executions. The base case for the
empty execution is easily verified since I contains only unit clauses. Assume that the claims
hold for executions of length n and let  0 be an execution of length n + 1 that augments
an execution  of length n. Observe that C factors U = o
n{bY, : Y  TC } by BF2, and
the inductive hypothesis implies b = U and bY, = BC (Y ) U . The proof of the first claim
b=o
n{bX : X  TC } is exactly like the proof of Lemma 7 except that all the containments
are replaced by equalities, by either using the part 2 of Lemma 6 or the inductive hypothesis.
For the second claim, we make a similar induction (in tandem with the first induction).
Again, the base case of the induction is easily verified. For the inductive step,
Case:  0 = h, ai.
1

2

bX, 0 = BC (X) o
n{FBC (Y )(a, bY, ) : Y  TC } = BC (X) o
n{FBC (Y )(a, BC (Y )U ) : Y  TC }
3

4

= BC (X) F (a, U ) = BC (X) F (a, b ) = BC (X) b 0
where 1 is by Eq. 8, 2 and 4 by inductive hypothesis, and 3 by part 2 of Lemma 6.
Case:  0 = h, ha, `ii.
5

bX, 0 = BC (X) o
n{F ilter(Wa(`)BC (Y ), bY, ) : Y  TC }
6

= BC (X) o
n{F ilter(Wa(`)BC (Y ), BC (Y )U ) : Y  TC }
7

8

= BC (X) F ilter(Wa (`), U ) = BC (X) F ilter(Wa (`), b ) = BC (X) b 0
where 5 is by Eq. 9, 6 and 8 by inductive hypothesis, and 7 by part 3 of Lemma 6.
965

fiBonet & Geffner

The following lemma shows that the tracking that CBT does on a variable X is equivalent
to the tracking that WBT does on the subproblem PX of the factored decomposition (i.e.,
PX = PBF (X) for the factored decomposition F = hTF , BF i).
Lemma 9. Let F = hTF , BF i and C = hTC , BC i be the factored and causal decompositions
W
for problem P . If  is an execution and X  TC is a state variable, then bC
X = bX where
C
bX denotes the local belief after  for variable X that is computed by CBT on the problem
P , and bW
X denotes the local belief after  for variable X that is computed by WBT on the
subproblem PBF (X) .
Proof sketch. This is a simple but tedious proof, so we just provide the sketch. Let CX =
hTX , BX i be the causal decomposition of the subproblem PBF (X) for X  TF (i.e., the
causal decomposition of the subproblem associated with variable X  TF in the factored
decomposition). The beams that participate in the join in CBT are the beams for the
variables Y  TC that are relevant to X; all such variables appear in TX as well. TX has
other variables however: observable variables Y that are not relevant to X. Yet, since all
the state variables in PBF (X) are relevant to X, the projected formulas Wa (Y = y)BF (X)
for such variables Y are all equal to true. Hence, the beams for such variables are over an
empty set of variables and just contain the empty valuation. Therefore, such beams can be
removed from the join that defines WBT on the problem PBF (X) without altering its value.
The resulting join for WBT on PBF (X) just contain the beams for variables Y  TC that
are relevant to X.
Once this fact is observed, the proof consists of a simple induction on the length of the
executions. An induction that is left as an exercise.
Theorem 33. Causal belief tracking is always sound. It is complete for causally decomposable problems.
Proof. Let F = hTF , BF i and C = hTC , BC i be the factored and causal decompositions for
problem P , and CX = hTX , BX i be the causal decomposition of the subproblem PBF (X) for
X  TF (notice that X is a state variable as TF is only comprised of such). Further, let 
W
be an execution, let bC
X and bX be the local beliefs after  for variable X that are computed
by CBT on problem P and WBT on problem PBF (X) respectively, let bFX be the local belief
after  for variable X that is computed by factored belief tracking on problem P , and let b
be the (global) belief after  on problem P .
If no observable variable is relevant to X, then BC (X) = BF (X) and CBT on X is equal
to factored belief tracking on X which is sound and complete by Theorem 20. If there are
observable variables that are relevant to X, then first notice that
W
F
bC
X = bX  BC (X) bX = BC (X) b

(10)

because Lemma 9, the soundness of WBT (cf. Lemma 7), and the soundness and completeness of FBT (cf. Theorem 20). Therefore, CBT is sound.
If the causal decomposition CX preserves transitions for every reachable belief state in
problem PBF (X) , then the containment in (10) is an equality and CBT is complete as well.
We thus finish the proof by showing that the decomposition CX for causally-decomposable
problems is a decomposition that preserves transitions for each reachable belief in PBF (X) .
966

fiBelief Tracking for Planning with Sensing

Let X  TC be a variable, let bX be a reachable belief in problem PBF (X) , let X 0 and
be two variables in TX (the target variables for the causal decomposition of problem
PBF (X) ), and let Z be a variable in BC (X 0 )  BC (X 00 ). We will show that either 1) Z is
known in bX , 2) BC (X 0 )  BC (X 00 )  BC (W ) for some variable W  TX , or 3) for every
action a, the transition function FS (a, ) is 1-1 for variable Z in bX where S is the causal
closure of Z. In such a case, the causal decomposition CX preserves transitions for every
reachable belief in problem PBF (X) .
X 00

We consider two cases:
Case: X 0 or X 00 is observable. First, apply the causal-decomposability of P to conclude that
either there is a variable W  TC that is relevant to X 0 or X 00 with BC (W )  BC (X 0 ) 
BC (X 00 ), or that Z is a memory variable. In the former case, W is relevant to X and thus
belongs to TX . In the latter case, we will show that either Z is known in bX or the transition
function FS (a, ) is 1-1 for Z in bX , where S is the causal closure of Z and a is any action
applicable at bX .
Indeed, for a proof by contradiction let us suppose that Z is not known in bX and that
the transition function is not 1-1. Then, there are two valuations s1 , s2  bX and two
progressions s01  FX (a, s1 ) and s02  FX (a, s2 ) such that s1 [Z] 6= s2 [Z] and s01 [Z] = s02 [Z].
Therefore, from observing the value of Z at state s01 and knowing the initial belief and the
actions in the execution h, ai (where  is the execution that leads to bX ), one cannot infer
the value of Z at bX because there are two different such values that are compatible with
the observation, namely s1 [Z] and s2 [Z]. Hence, Z is not a memory variable contradicting
the assumed causal-decomposability of P .
Case: X 0 and X 00 are not observables. We further divide this case in two subcases on
whether both variables X 0 and X 00 are causal ancestors of X or not. In the affirmative
subcase, BC (X 0 )  BC (X 00 )  BC (X). In the negative subcase, assume without loss of
generality that X 0 is not a causal ancestor of X. Then, there is an observable variable Y
such that X 0 is a causal ancestor of Y and Y is relevant to X. Hence, BC (Y )  BC (X 0 )
which implies Z  BC (Y )  BC (X 00 ) and this case is reduced to the previous case.

References
Albore, A., Palacios, H., & Geffner, H. (2009). A translation-based approach to contingent
planning. In Proc. 21st Int. Joint Conf. on Artificial Intelligence, pp. 16231628,
Pasadena, California.
Albore, A., Ramirez, M., & Geffner, H. (2010). Compiling uncertainty away in nondeterministic conformant planning. In Proc. 19th European Conf. on Artificial Intelligence, pp. 465470, Lisbon, Portugal.
Albore, A., Ramirez, M., & Geffner, H. (2011). Effective heuristics and belief tracking
for planning with incomplete information. In Proc. 21st Int. Conf. on Automated
Planning and Scheduling, pp. 29, Freiburg, Germany.
Amir, E., & Russell, S. (2003). Logical filtering. In Proc. 18th Int. Joint Conf. on Artificial
Intelligence, pp. 7582, Acapulco, Mexico.
967

fiBonet & Geffner

Bertoli, P., Cimatti, A., Roveri, M., & Traverso, P. (2001). Planning in nondeterministic domains under partial observability via symbolic model checking. In Nebel, B.
(Ed.), Proc. 17th Int. Joint Conf. on Artificial Intelligence, pp. 473478, Seattle, WA.
Morgan Kaufmann.
Bonet, B., & Geffner, H. (2000). Planning with incomplete information as heuristic search
in belief space. In Chien, S., Kambhampati, S., & Knoblock, C. (Eds.), Proc. 5th
Int. Conf. on Artificial Intelligence Planning Systems, pp. 5261, Breckenridge, CO.
AAAI Press.
Bonet, B., & Geffner, H. (2011). Planning under partial observability by classical replanning:
Theory and experiments. In Proc. 22nd Int. Joint Conf. on Artificial Intelligence, pp.
19361941, Barcelona, Spain.
Bonet, B., & Geffner, H. (2012a). Action selection for MDPs: Anytime AO* vs. UCT. In
Proc. 26th AAAI Conf. on Artificial Intelligence, pp. 17491755, Toronto, Canada.
Bonet, B., & Geffner, H. (2012b). Width and complexity of belief tracking in nondeterministic conformant and contingent planning. In Proc. 26th AAAI Conf. on
Artificial Intelligence, pp. 17561762, Toronto, Canada.
Bonet, B., & Geffner, H. (2013). Causal belief decomposition for planning with sensing:
Completeness results and practical approximation. In Proc. 23rd Int. Joint Conf. on
Artificial Intelligence, pp. 22752281, Beijing, China.
Bonet, B., & Geffner, H. (2014). Flexible and scalable partially observable planning with
linear translations. In Proc. 28th AAAI Conf. on Artificial Intelligence, pp. 22352241,
Quebec City, Canada.
Boyen, X., & Koller, D. (1998). Tractable inference for complex stochastic processes. In
Cooper, G., & Moral, S. (Eds.), Proc. 14th Conf. on Uncertainty in Artificial Intelligence, pp. 3342, Madison, WI. Morgan Kaufmann.
Brafman, R. I., & Shani, G. (2012). Replanning in domains with partial information and
sensing actions. Journal of Artificial Intelligence Research, 1 (45), 565600.
Bryce, D., Kambhampati, S., & Smith, D. E. (2006). Planning graph heuristics for belief
space search. Journal of Artificial Intelligence Research, 26, 3599.
Choi, A., & Darwiche, A. (2006). An edge deletion semantics for belief propagation and
its practical impact on approximation quality. In Proc. 21st Nat. Conf. on Artificial
Intelligence, pp. 11071114.
Cimatti, A., Roveri, M., & Bertoli, P. (2004). Conformant planning via symbolic model
checking and heuristic search. Artificial Intelligence, 159, 127206.
Darwiche, A., & Marquis, P. (2002). A knowledge compilation map. Journal of Artificial
Intelligence Research, 17, 229264.
Dechter, R., & Beek, P. V. (1997). Local and global relational consistency. Theoretical
Computer Science, 173 (1), 283308.
Doucet, A., Freitas, N. D., Murphy, K., & Russell, S. (2000). Rao-blackwellised particle filtering for dynamic bayesian networks. In Proc. 16th Conf. on Uncertainty in Artificial
Intelligence, pp. 176183.
968

fiBelief Tracking for Planning with Sensing

Edelkamp, S. (2001). Planning with pattern databases. In Cesta, A. (Ed.), Proc. 6th
European Conf. on Planning, pp. 1324, Toledo, Spain. Springer: LNCS.
Goldman, R. P., & Boddy, M. S. (1996). Expressive planning and explicit knowledge. In
Drabble, B. (Ed.), Proc. 3rd Int. Conf. on Artificial Intelligence Planning Systems,
pp. 110117, Edinburgh, Scotland. AAAI Press.
Hoffmann, J., & Brafman, R. I. (2005). Contingent planning via heuristic forward search
with implicit belief states. In Biundo, S., Myers, K., & Rajan, K. (Eds.), Proc. 15th
Int. Conf. on Automated Planning and Scheduling, pp. 7180, Monterey, CA. Morgan
Kaufmann.
Hoffmann, J., & Brafman, R. I. (2006). Conformant planning via heuristic forward search:
A new approach. Artificial Intelligence, 170, 507541.
Kaelbling, L. P., Littman, M., & Cassandra, A. R. (1999). Planning and acting in partially
observable stochastic domains. Artificial Intelligence, 101, 99134.
Kaye, R. (2000). Minesweeper is NP-Complete. Mathematical Intelligencer, 22 (2), 915.
Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. In Proc. 17th
European Conf. on Machine Learning, pp. 282293. Springer.
Lin, W., Buffet, O., Lee, C., & Teytaud, O. (2012). Optimistic heuristics for Minesweeper.
In Proc. of the Int. Computer Symposium (ICS-12). At http://hal.inria.fr/docs/
00/75/05/77/PDF/mines3.pdf.
Palacios, H., & Geffner, H. (2009). Compiling uncertainty away in conformant planning
problems with bounded width. Journal of Artificial Intelligence Research, 35, 623
675.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann.
Ramirez, M., & Geffner, H. (2007). Structural relaxations by variable renaming and their
compilation for solving MinCostSAT. In Proc. 13th Int. Conf. on Principles and
Practice of Constraint Programming, pp. 605619. Springer.
Rintanen, J. (2008). Regression for classical and nondeterministic planning. In Ghallab,
M., Spyropoulos, C. D., Fakotakis, N., & Avouris, N. M. (Eds.), Proc. 18th European
Conf. on Artificial Intelligence, pp. 568572, Patras, Greece.
Russell, S., & Norvig, P. (2009). Artificial Intelligence: A Modern Approach (3rd edition).
Prentice Hall.
Scott, A., Stege, U., & Rooij, I. V. (2011). Minesweeper may not be NP-Complete but is
Hard nonetheless. Science+Business Media, LLC, 33 (4), 517.
Shani, G., & Brafman, R. I. (2011). Replanning in domains with partial information and
sensing actions. In Proc. 22nd Int. Joint Conf. on Artificial Intelligence, pp. 2021
2026, Barcelona, Spain.
Shani, G., Poupart, P., Brafman, R. I., & Shimony, S. (2008). Efficient ADD operations
for point-based algorithms. In Rintanen, J., Nebel, B., & J. C. Beck, E. A. H. (Eds.),
Proc. 18th Int. Conf. on Automated Planning and Scheduling, pp. 330337, Sydney,
Australia.
969

fiBonet & Geffner

Silver, D., & Veness, J. (2010). Monte-Carlo planning in large POMDPs. In Proc. 24th
Annual Conf. on Advances in Neural Information Processing Systems, pp. 21642172.
Sipser, M. (2006). Introduction to Theory of Computation (2nd edition). Thomson Course
Technology, Boston, MA.
Smith, D., & Weld, D. (1998). Conformant graphplan. In Mostow, J., & Rich, C. (Eds.),
Proc. 15th Nat. Conf. on Artificial Intelligence, pp. 889896, Madison, WI. AAAI
Press / MIT Press.
To, S. T., Pontelli, E., & Son, T. C. (2011). On the effectiveness of CNF and DNF representations in contingent planning. In Proc. 22nd Int. Joint Conf. on Artificial Intelligence,
pp. 20332038, Barcelona, Spain.
Tran, V., Nguyen, K., Son, T. C., & Pontelli, E. (2013). A conformant planner based on
approximation: CpA(H). ACM Trans. on Intelligent Systems and Technology, 4 (2),
36.
Weld, D., Anderson, C., & Smith, D. (1998). Extending Graphplan to handle uncertainty
and sensing actions. In Proc. 15th Nat. Conf. on Artificial Intelligence, pp. 897904.
AAAI Press.

970

fi