Journal of Artificial Intelligence Research 49 (2014) 323-361

Submitted 08/13; published 02/14

Symmetric Subgame-Perfect Equilibria
in Resource Allocation
Ludek Cigler
Boi Faltings

ludek.cigler@epfl.ch
boi.faltings@epfl.ch

Artificial Intelligence Laboratory
Ecole Polytechnique Federale de Lausanne
CH-1015 Lausanne, Switzerland

Abstract
We analyze symmetric protocols to rationally coordinate on an asymmetric, efficient
allocation in an infinitely repeated N -agent, C-resource allocation problems, where the
resources are all homogeneous. Bhaskar proposed one way to achieve this in 2-agent, 1resource games: Agents start by symmetrically randomizing their actions, and as soon as
they each choose different actions, they start to follow a potentially asymmetric convention that prescribes their actions from then on. We extend the concept of convention
to the general case of infinitely repeated resource allocation games with N agents and C
resources. We show that for any convention, there exists a symmetric subgame-perfect
equilibrium which implements it. We present two conventions: bourgeois, where agents
stick to the first allocation; and market, where agents pay for the use of resources, and
observe a global coordination signal which allows them to alternate between different allocations. We define price of anonymity of a convention as a ratio between the maximum
social payoff of any (asymmetric) strategy profile and the expected social payoff of the
subgame-perfect equilibrium which implements the convention. We show that while the
price of anonymity of the bourgeois convention is infinite, the market convention decreases
this price by reducing the conflict between the agents.

1. Introduction
In many situations, agents have to coordinate their use of some resource. One wireless channel can only be used by one device, one parking slot may only be occupied by one vehicle,
etc. The problem is that often, the agents have identical preferences: Everyone prefers to
access rather than yield. Similarly, everyone prefers to have a parking slot rather than leave
their car at home. However, if multiple agents try to use one resource simultaneously, they
collide and everyone loses.
Consider a simple example: two agents want to access a single resource. We can describe
the problem as a game. Both agents have two actions: yield (Y ) and access (A). If agent
 yields, it gets a payoff of 0. When agent  accesses the resource while the other agent
yields, it gets a payoff of 1. But if both agents access the resource at the same time, they
both incur a cost  > 0.
The normal form of such a game looks as follows:

Y
A
c
2014
AI Access Foundation. All rights reserved.

Y
0, 0
1, 0

A
0, 1
, 

fiCigler & Faltings

This is a symmetric game, but the two efficient Nash equilibria (NE) are asymmetric:
either one agent yields and the other one accesses the resource, or vice versa. The only
symmetric equilibrium outcome is the mixed NE where both agents access the resource
1
with probability Pr(A) := ||+1
. However, this mixed equilibrium is not efficient, because
the expected payoff of both agents is 0.
Asymmetric equilibria of symmetric games are undesirable for two reasons: First, they
are not fair. In our example, only one agent can access the resource. Second, coordinating
on an asymmetric equilibrium is difficult. Imagine that the agents are all identical and
anonymous, i.e. they cannot observe their own identity, nor the identity of any other agent.
We cannot prescribe a different strategy for each of the agents. Agents in some peer-to-peer
file-sharing networks are assumed to be anonymous (Chothia & Chatzikokolakis, 2005), as
well as agents in some wireless sensor networks (Durresi, Paruchuri, Durresi, & Barolli,
2005).
Consider the following example: Millions of wireless sensors are produced all by the
same pipeline. We take two of them randomly, and put them in a room. There is only one
frequency on which the sensors can transmit their measurements. How can each sensor know
when to transmit and when to stay quiet? The factory could program half of the sensors
to transmit in odd slots, and the other half to transmit in the even slots. Nevertheless, it
would be just as likely to have an odd-even pair of sensors, as it would be to have a pair
where the sensors transmit at the same time.
Aumann (1974) proposed the notion of correlated equilibria which fixes some of our issues
with the Nash equilibria in the resource allocation game above. A correlated equilibrium
(CE) is a probability distribution over the joint strategy profiles in the game. A correlation
device samples this distribution and recommends an action for each agent to play. The
probability distribution is a CE if agents do not have an incentive to deviate from the
recommended action. The correlation device takes away the burden of coordination from
the anonymous agents. They can all follow the same strategy: do what the correlation
device has told me.
What if such smart correlation device, which can send each agent a different private
signal, is not available? Can we still reach a correlated equilibrium outcome, one in which
anonymous agents can play identical strategies, and yet achieve an efficient and fair allocation? In our previous work (Cigler & Faltings, 2011), we have proposed an algorithm
that allows agents to learn a correlated equilibrium outcome through repeated play. We
considered a special case of a resource allocation problem. We proposed to use a global
coordination signal and multi-agent learning to reach a symmetric, fair and efficient outcome (Wang et al. (2011) later implemented this approach in an actual wireless network
and achieved throughput 3 higher than standard ALOHA protocols).
How does the coordination signal from our previous work (Cigler & Faltings, 2011) differ
from the smart correlation device assumed by Aumann (1974)? Firstly, it is public and
cannot send private signals to the agents. Such private signals are necessary for anonymous
agents to implement the desirable correlated equilibrium in a single stage resource allocation
game. The anonymous agents all have to follow the same strategy for each given public signal
value. Secondly, the coordination signal is not specific to the game. The only requirement
is that it is ergodic, i.e. it regularly sends each of its possible values. An example of such
324

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

signal is the day of the week, the decimal value of a price of a certain stock, or even a noise
on some frequency.
However, our previous solution had a major limitation: The learning algorithm itself was
not an equilibrium of the repeated game. A selfish agent could force everyone else to yield
by accessing all the time, securing the resource for herself. Therefore, in this paper, we focus
on learning algorithms which are themselves equilibria of the repeated game. We propose a
distributed algorithm to find an allocation of a set of resources which is not only symmetric
and fair, but also an equilibrium. We draw inspiration from the works of Bhaskar (2000)
and Kuzmics, Palfrey, and Rogers (2010) on symmetric equilibria for symmetric repeated
games.
Assume that agents play an infinitely repeated game, and they discount future payoffs
with a common discount factor 0 <  < 1. A strategy for an agent is a mapping from
any history of the play to a probability distribution over the actions. Our goal is to find a
symmetric subgame perfect equilibrium. A subgame perfect equilibrium is a strategy profile
(vector of strategies for every agent) which is a NE in any history, including those that
cannot occur on the equilibrium path.
The symmetric subgame perfect equilibria that we study have the following form: The
agents start by choosing their actions randomly, all according to a given probability distribution. As soon as they play an (asymmetric) pure-strategy Nash equilibrium of the
game, they adopt a convention, that prescribes their actions deterministically from then
on. Bhaskar (2000) gives two examples of conventions for symmetric 2-agent, 2-action
games:
Bourgeois Agents keep using the action they played in the last round;
Egalitarian Agents play the action of their opponent from the last round.
In this paper, we extend the notion of convention to arbitrary resource allocation problems with N agents and C homogeneous resources, and we show that for any convention,
there exists a symmetric subgame-perfect equilibrium that reaches this convention. We give
a closed form expression to calculate the subgame-perfect equilibrium for the bourgeois convention, and show that for a small number of resources C, this convention leads to zero
expected payoff. This means that the price of anonymity of the bourgeois convention is .
We present the market convention as a generalization of the egalitarian convention of
Bhaskar (2000). The main idea is that 1) agents pay a price for each successful access
of a resource, and 2) before each round of the game, they observe a global coordination
signal k  {1, . . . , K}, based on which they decide whether and which resource they access.
The agents have a decreasing marginal utility from accessing more often. The price helps
to decrease the demand for the resources, while the global coordination signal effectively
increases the capacity K-times. We show that compared to the bourgeois convention, the
market convention improves the expected payoff. Its price of anonymity is therefore finite.
This paper is structured as follows: In Section 2, we review some basic notions from game
theory, and we present the general definitions of conventions and their implementations. In
Section 3, we formally define the resource allocation game of N players and C resources, and
show that for any convention, there exists a symmetric subgame-perfect equilibrium which
implements it. In Section 4 we present two concrete examples of a convention: bourgeois and
325

fiCigler & Faltings

market conventions and discuss their properties. In Section 5 we discuss the relationship of
this work to the work on folk theorems in game theory. Finally, Section 6 concludes.

2. Preliminaries
In this section, we will first introduce some basic concepts of game theory that we are going
to use throughout the paper. Then, we will define the notion of price of anonymity. Finally,
we will give the general definition of a convention and its implementation.
2.1 Game Theory
Game theory is the study of interactions among independent, self-interested agents. An
agent who participates in a game is called a player. Each player has a utility function
associated with each state of the world. Self-interested players take actions so as to achieve
a state of the world that maximizes their utility. Game theory studies and attempts to
predict the behaviour, as well as the final outcome of such interactions. Leyton-Brown and
Shoham (2008) give a more complete introduction to game theory.
The basic way to represent a strategic interaction (game) is using the so-called normal
form.
Definition 1. (Normal form game) A finite, N -person normal-form game is a tuple
G = (N, A, u), where
 N is a set of N players;
 A = A1  A2  . . .  AN , where Ai is a set of actions available to player i. Each vector
a = (a1 , a2 , . . . , aN )  A is called an action profile;
 u = (u1 , u2 , . . . , uN ), where ui : A  R is a utility function for player i that assigns
each action vector a certain utility (payoff).
In this paper, we will be studying symmetric games. In such games, the players are
anonymous, and the only thing that influences the outcome is the number of agents who
took a certain action.
Definition 2. (Symmetric game) We say that a normal-form game G = (N, A, u) is a
symmetric game, if for any permutation of the vector of players  : N  N, it holds that
for any strategy vector  = (1 , 2 , . . . , N ) and any i  N,
ui (1 , 2 , . . . , N ) = u(i) ((1) , (2) , . . . , (N ) ).
Besides playing a single deterministic action, the player can also choose her action
randomly from a certain probability distribution.
Definition 3. (Mixed strategy) A mixed strategy selects a probability distribution over
the entire action space, i.e. i  (Ai ). A mixed strategy profile is a vector of mixed
strategies for each player. For a mixed strategy i , we define its support supp(i ) as
supp(i ) = {ai  Ai : i (ai ) > 0} .
326

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

Given a game specified using its normal form, how should the players choose their
strategy? When players know the strategies of the others, they can choose their action
quite easily: just pick the strategy that maximizes the payoff given what everyone else is
playing:
Definition 4. (Best response) We say that a mixed strategy i of player i is a best
response to the strategy profile of the opponents i if for any strategy i0 ,
ui (i , i )  ui (i0 , i ).
As we mentioned earlier, one of the basic goals of game theory is to predict an outcome
of a strategic interaction. Such outcome should be stable  therefore, it is usually called
an equilibrium. One requirement for an outcome to be an equilibrium is that none of the
players has an incentive to change their strategy, i.e. all players play their best-response to
the strategies of the others. This defines perhaps the most important equilibrium concept,
the Nash equilibrium:
Definition 5. (Nash equilibrium) A strategy profile  = (1 , 2 , . . . , N ) is a Nash
equilibrium (NE) if for every player i, her strategy i is a best response to the strategies
of the others i .
Correlated equilibrium extends the notion of Nash equilibrium. In the canonical interpretation, it assumes that there is a central correlation device which samples the space of
possible outcomes of the game according to some probability distribution, and then recommends an action to play to each player. No player has an incentive to deviate from the
recommended action. The formal definition is as follows:
Definition 6. (Correlated equilibrium) Given an N -player game G = (N, A, u), a
correlated equilibrium is a tuple (v, , ), where v is a tuple of random variables v =
(v1 , v2 , . . . , vN ) with domains D = (D1 , D2 , . . . , DN ),  is a joint probability distribution
over v,  = (1 , 2 , . . . , N ) is a vector of mappings i : Di 7 Ai , and for each player i and
every mapping 0i : Di 7 Ai it is the case that
X

(d)ui (1 (d1 ), 2 (d2 ), . . . , N (dN )) 

dD

X


(d)ui 01 (d1 ), 02 (d2 ), . . . , 0N (dN ) .

dD

In an equilibrium, each agent chooses the best strategy for himself. Oftentimes, the end
result is not the best for the agents as a whole. To analyze the overall utility of a game
outcome to all of the agents, we define its social payoff:
Definition 7. (Social payoff ) For a (mixed) strategy P
vector (1 , 2 , . . . , N ), we define
its social payoff as the sum of utilities of all the players, N
i=1 ui (1 , 2 , . . . , N ).
2.2 Repeated Game
In a repeated game, the same players play a given game (for example specified by its normal
form) repeatedly. We call the normal form game that is being played in each round the
stage game.
327

fiCigler & Faltings

(1)

(2)

Definition 8. (Future discounted payoff ) Given an infinite sequence of payoffs ri , ri , . . .
for player i and a discount factor , 0 <  < 1, the future discounted payoff of player i is
Ei :=


X

(j)

 j ri .

j=1

Definition 9. (Infinitely repeated game) Let G = (N, A, u) be a normal form game.
An infinitely repeated version G of the game G with discounting is a game where the players
play the normal form game G for an infinite number of rounds. The payoff of player i in
game G is defined as its future discounted reward ri ().
In this paper, we will study symmetric equilibria of an extended version of the repeated
game, so-called augmented game. We assume that in every round of the game, the players
can observe a common coordination signal, on which they can condition what strategy
they will use. In general, this coordination signal is just a random integer taken from set
{0, 1, . . . , K  1}. In practice, it can be any piece of information observable by everyone:
price of a certain stock at a given time, temperature in the room, day of the week, etc.
Such a signal will allow agents to coordinate more efficiently, while at the same time it is
more realistic than a general correlation device which recommends actions to the agents, as
is assumed in the definition of correlated equilibria.
Definition 10. (Augmented repeated game) Let G = (N, A, u) be a normal form
game, let K := {0, 1, . . . , K  1} be a set of coordination signals. An augmented infinitely
repeated version G of the game G with discounting is a game where players play the normal
form game G for an infinite number of rounds. In each round t, the players observe a
coordination signal kt  K. The coordination signal is chosen from a uniform distribution
over K. The players discount future payoff with a discount factor .
W.l.o.g., we always assume that repeated games are augmented, since in an ordinary
repeated game, we can just assume that there is only one coordination signal. Therefore, in
the rest of the paper, whenever we refer to a repeated game or its strategy etc., we always
assume that the game is augmented with a coordination signal.
Definition 11. (History of a repeated game) Let G be an infinitely repeated game
with discounting. We define the history ht of the play in round t  0 as

t1
t1
ht := ((a01 , a02 , . . . , a0N ), k0 ), . . . , ((at1
1 , a2 , . . . , aN ), kt1 )
where ati is the action taken by player i in round t, and kt is the signal that the players
observe in round t.
Definition 12. (Strategy of a repeated game) A strategy in the repeated game of a
player i is a function i from the history ht and a currently observed coordination signal kt
to a probability distribution over the action space,
i : (ht , kt ) 7 (Ai ).
We can define the Nash equilibrium of the repeated game in the same way as for the
stage game (we can treat the repeated game as if it was just a normal form game where
players commit to their strategy for the entire game up front).
328

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

Definition 13. (Nash equilibrium of a repeated game) A strategy profile  =
(1 , 2 , . . . , N ) is a Nash equilibrium of the infinitely repeated game if for each player
i,
Ei (i , i )  Ei (0i , i )
(1)
for any alternative strategy of the repeated game 0i . Here Ei ((i , i ), ht , kt ) is the future
discounted payoff of player i when she adopts strategy i and the other players adopt a
strategy vector i .
In the following text, we will use the notion of future discounted social payoff:
Definition 14. (Future discounted social payoff ) Given a strategy profile  of the
infinitely repeated game G, the future discounted social payoff is defined as
E() :=

N
X

Ei ().

(2)

i=1

For the repeated games, there exists a stronger notion of equilibria, which is a refinement
of the standard Nash equilibrium definition.
Definition 15. (Subgame-perfect equilibrium) Let G be an infinitely repeated game
with a discount factor 0 <  < 1. A strategy vector  = (1 , 2 , . . . , N ) is a subgame-perfect
equilibrium of the game G if for each player i,
Ei ((i , i ), ht , kt )  Ei ((0i , i ), ht , kt )
for any strategy 0i , history ht and coordination signal kt .
In the subgame-perfect equilibrium, players play a best-response strategy given any
history of the play, including the histories which cannot occur if they follow the equilibrium
strategy from the beginning. The notion of subgame-perfect equilibria eliminates this way
non-credible threats, or equilibria in which a player threatens someone else with a strategy
which the player might be prefer to avoid if it was supposed to be executed.
2.3 Price of Anonymity
In Section 1, we have seen that in the simple resource-allocation game, the symmetric
equilibrium leads to a significantly lower payoff than the asymmetric equilibria. Symmetry
of the equilibria is a natural requirement when players are all the same, i.e. anonymous.
How much social payoff do we have to sacrifice for the requirement of symmetry? Inspired
by the price of anarchy of Koutsoupias and Papadimitriou (1999), we propose the price
of anonymity as a measure of how efficient a given symmetric strategy vector is (the term
price of anonymity was used previously in a different context by Bonnet & Raynal, 2011).
For a given symmetric strategy vector of the stage game , we calculate the ratio between
the social payoff of the most efficient (potentially asymmetric) Nash equilibrium of the
game, and the social payoff of strategy vector . The formal definition is as follows:
329

fiCigler & Faltings

Definition 16. (Price of anonymity of a Nash equilibrium) Let G be a symmetric
game, let  = (1 , 2 , . . . , N ) be a symmetric Nash equilibrium (that is i, j : i = j ),
and let  be a (mixed) Nash equilibrium of the game G with the maximum social payoff.
We define the price of anonymity of strategy vector  as follows:
RG () :=

E( )
.
E()

Definition 17. (Price of anonymity of a stage game) Let G be a symmetric game,
 ) be a symmetric Nash equilibrium with minimal social payoff, and
let   = (1 , 2 , . . . , N
let  be a (mixed) Nash equilibrium of the game G with the maximum social payoff. We
define the price of anonymity of the game G as follows:
RG :=

E( )
.
E(  )

For infinitely repeated games, we define the price of anonymity for their subgame-perfect
equilibria:
Definition 18. (Price of anonymity of a repeated game) Let G be a symmetric game,
let  = (1 , 2 , . . . , N ) be a symmetric subgame-perfect equilibrium with minimal social
payoff, and let  be a subgame-perfect equilibrium of the game G with the maximum social
payoff. We define the price of anonymity of the game G as follows:
RG :=

E()
.
E( )

2.4 Conventions and Implementations
As we have shown for the example of the 2-agent, 1-resource allocation game in Section 1,
there exist symmetric games that have nevertheless only asymmetric efficient equilibria. If
we allow for a central coordination device, the agents can play a symmetric and efficient
correlated equilibrium that selects randomly from the set of efficient Nash equilibria. Without such a device, in the stage game, there is no way to reach a symmetric efficient outcome
in an equilibrium.
However, if the agents play the game repeatedly, they can use the history of the play
to condition their strategy. If two agents have different histories, they can take different
actions in the future. In the first round of the game though, the history is empty for
everyone. Therefore, a symmetric strategy for the players has to randomize in order to ever
reach a point when the histories of the agents are distinct.
Bhaskar (2000) considered the problem of playing asymmetric outcomes of the stage
game using a symmetric strategy of the repeated game. His work considers games with 2
players and 2 actions, such as the 1-resource allocation game. The idea is that the two players start by playing randomly, using the same probability distribution over actions. They
randomize until they reach a round t where they happen to play some pure-strategy Nash
equilibrium (that is, they take a different action each). We call this round the asynchrony
round. Then, the agents start following a so-called convention. A convention maps the
asymmetric pure-strategy Nash equilibrium to a (potentially asymmetric) strategy vector
that the agents then adopt.
330

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

We have already mentioned the two basic conventions proposed by Bhaskar (2000): the
bourgeois and egalitarian convention. In the 1-resource allocation game, in the asynchrony
round, one agent chooses action A and the other one chooses Y . We will call the agent who
chose A in the asynchrony round the winner. The other agent is the loser. The bourgeois
convention guarantees that the agents will keep playing this NE forever after. This way,
the winner will be forever guaranteed a higher payoff than the loser. In the egalitarian
convention, the players alternate between the two pure-strategy Nash equilibria. That way
the payoffs of the winner and a loser will be closer.
In the infinitely repeated game with discounting, the social payoff will depend on two
things: the discount factor , and the probability of a collision, that is the probability that
the players both play action A. When there is a big difference between the winner and loser
payoff, the losers will fight back harder, so they will play their most preferred action A
with higher probability. This will increase the probability of a collision. In the egalitarian
convention, the payoffs to the loser are closer to the winner. Therefore, the agents will
collide less often, and they will also reach the asynchrony faster.
As another example of a convention, Kuzmics et al. (2010) analyze the Nash demand
game. The Nash demand game is a game of N players who choose between N actions
labeled 1, . . . , N . If all the players choose a distinct action, each player receives a payoff
equal to the label of her chosen action. If there are any two players who chose the same
action, every player (including those who chose an action alone) receives zero payoff. In a
pure-strategy Nash equilibrium, all the players choose a different action. Naturally, each
player prefers the equilibrium where she is the one who chose action N .
In the Nash demand game, we can also define bourgeois and egalitarian conventions.
Kuzmics et al. (2010) define three notions of payoff symmetry:
Ex-ante All agents have the same expected payoffs before the game starts.
Ex-post All agents have the same expected payoffs when asynchrony occurs (regardless of
who was the winner).
Strong ex-post All agents have the same payoff along any realization of the play.
The bourgeois convention is only ex-ante payoff symmetric, since once asynchrony occurs, the winner gets a higher payoff than the loser. The egalitarian convention is strong
ex-post payoff symmetric. In fact, Kuzmics et al. (2010) show that in the Nash demand
game, if a convention is socially efficient, it must be strong ex-post payoff symmetric. The
intuition is that in order to maximize social efficiency, we want to reach asynchrony as fast
as possible. This is only possible if agents choose their actions uniformly at random. They
will only do that if they are indifferent between which action they choose at the moment
asynchrony occurs.
We will now formally define the convention for an augmented repeated game of N agents.
Definition 19. (Convention) Let G = (N , A, u)
and let G be the repeated version of game G. We
that maps a vector of pure-strategy Nash equilibria
a = (a1 , a2 , . . . , aK ) to a vector of strategies of the
331

be a symmetric normal form game
define a convention as a function 
of the game G for each signal value
repeated game G, such that for any

fiCigler & Faltings

permutation  : N  N of the set of players,
(((a1 ), . . . , (aK ))) = ((a1 , a2 , . . . , aK ))

(3)

that is, the convention of a permutation is a permutation of a convention (here i denotes
the strategy for player i). The strategies can be different for each coordination signal value.

We use the notation (a) := a(1) , . . . , a(N ) , and ((a)) := (1) (a), . . . , (N ) (a) to
denote the permutation of the history vector using , and the permutation of the strategy
vectors respectively.
Our definition of convention generalizes the definition Bhaskar (2000) gave for symmetric
games of 2 players and two actions , . Bhaskar defined a convention as a mapping from
a set of Nash equilibrium action profiles {(, ), (, )} to a set of strategies in which the
players alternate the strategy profiles (, ) and (, ) in some order. In our definition, a
convention maps any Nash equilibrium of the stage game to any strategy profile, provided
that it satisfies the permutation condition.
Intuitively, a convention prescribes each agent a potentially different role. The problem
for anonymous agents is to learn their role. We will call the learning algorithm they will
use an implementation of a convention.
Definition 20. (Implementation) Let G be an infinitely repeated game, and let  be a
convention defined for this game. An implementation  of a convention  is a strategy
vector of the infinitely repeated game, that is a function that assigns
 : (ht , kt ) 7 (A1 )  . . .  (AN ),
and that satisfies the following conditions:
Let ht be the history of the game at time t.
1. If the players have already played some pure-strategy Nash equilibrium for all coordination signals k  K in some round t0 < t (t0 is the round in which they played
the NE for the last signal), follow the strategy prescribed by the convention  for the
history ht \ ht0 (that is, the history from round t0 + 1 onwards).
2. Otherwise, let kt be the signal observed in the current round, and let vector a =
(a1 , a2 , . . . , aK ) such that ak is the action vector from the last round when the signal
k was observed (if signal k was not observed yet, we define ak = ). Then, the actions
of the players in the current round t only depend on vector a (abusing the notation,
we can write  (ht , kt ) =  (a, kt )), and for any permutation  : {1, 2, . . . , N } 
{1, 2, . . . , N },

(,1 ((a), kt ), . . . , ,N ((a), kt )) = ,(1) (a, kt ), . . . , ,(N ) (a, kt ) ,
that is the strategy for the current round only depends on the actions a played in the
last round each signal was observed, and on the current coordination signal.
In Section 3, we will be concerned with equilibrium strategies for the resource allocation
game. That is, we will look at its symmetric subgame-perfect equilibria. To construct
such equilibria, we define the concepts of an equilibrium convention, and its equilibrium
implementation.
332

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

Definition 21. (Equilibrium convention) Let G be an infinitely repeated game, and let
 be some convention. We say that the convention  is an equilibrium convention when for
every vector of pure-strategy Nash equilibria a = (a1 , . . . , aK ), (a) is a vector of subgameperfect equilibria of the game G.
Definition 22. (Equilibrium implementation) Let G be an infinitely repeated game, 
some equilibrium convention, and  an implementation of convention . We say that  is
an equilibrium implementation if it is a subgame-perfect equilibrium.

3. Resource Allocation Game
In this section, we will first formally define the resource allocation game, and discuss its
Nash equilibria. We will then show that for any equilibrium convention of the resource
allocation game, there exists an equilibrium implementation.
3.1 Definitions
We will first define the resource allocation game, and restricted notions of uniform convention and uniform implementation.
Definition 23. (Resource allocation game) A resource allocation game GN,C is a game
of N agents. Each agent i can access one of C identical resources. The agent chooses its
action ai from Ai = {Y, A1 , A2 , . . . , AC }, where action ai = Y means to yield, and action
ai = Ac means to access resource c. Because all resources are identical, we can define a
special meta-action ai = A. To take action A means to choose to access, and then to choose
the resource uniformly at random from the set of available resources.
The payoff function for agent i is defined as follows:

0
if ai = Y



1
if ai 6= Y,
ui (a1 , . . . , ai , . . . , aN ) :=
(4)
j
6= i, aj 6= ai



 < 0 otherwise
This game has a set of pure strategy NEs where C agents each access a resource ci and
N  C agents do not. There is also a symmetric mixed strategy NE in which each agent
decides to play action A with probability
s
(
! )
||
Pr(ai > 0) := min C  1  N 1
,1 .
(5)
1 + ||
Note that for high enough values of C, all agents will always choose to access. 1
Since we assume that the resources are identical, when the agents start following a
convention, their expected future payoff shouldnt depend on which resource they have
1. The resource allocation game as defined here is an instance of a class of games known as potential games
(Monderer & Shapley, 1996). In an (exact) potential game, there exists a potential function  : A  R
00
such that ai  Ai , a0i , ai  Ai ,
(a0i , ai )  (a00i , ai ) = ui (a0i , ai )  ui (a00i , ai ).

333

fiCigler & Faltings

accessed in the Nash equilibrium. We will therefore restrict ourselves to so-called uniform
conventions:
Definition 24. (Uniform convention) Let GN,C be a resource allocation game, and GN,C
its infinitely repeated version. Let  be a convention. We say that the convention  is a
uniform convention, if the following holds: Let a = (a1 , a2 , . . . , aK ) be a vector of purestrategy Nash equilibria for each coordination signal. Let for each player i, ci the number
of signals for which player i accesses some resource in action vector a. Then
i, j : ci = cj = Ei ((a)) = Ej ((a)).
That is, if the number of signals for which the two players access some resource is the
same, their expected payoff in the remainder of the game has to be the same too.
Definition 25. (Losers, winners, claimed and unclaimed resources) Let GN,C be
an infinitely repeated resource allocation game, let ht be the history of play in round t, and
let ak = (ak1 , ak2 , . . . , akN ) be the action vector played in the last round when signal k was
observed.
 Player i is a winner for signal k if aki = Ai and for all other players j 6= i, akj 6= Ai ;
 Player i is a loser for signal k otherwise;
 Resource c is claimed for signal k, if there exists exactly one player i such that aki = Ac ;
 Resource c is unclaimed for signal k otherwise.
If signal k was never observed before, all the players are losers and all the resources are
unclaimed for signal k.
Definition 26. (Uniform implementation) Let GN,C be an infinitely repeated resource
allocation game, let  be some uniform convention. A uniform implementation  is defined
as follows: Let ht be the history of the game at time t, let kt be the signal observed in the
current round.
1. If the players have already played some pure-strategy Nash equilibrium for all coordination signals follow the strategy prescribed by the convention .
2. Otherwise, let n be the number of losers for signal kt , and let c be the number of
unclaimed resources for signal k. The strategy prescribed by implementation  in
round t is then the following:
For an action vector a such that there are co occupied resources, and nA agents who access some resource,
the exact potential function of the resource allocation game is
(a) := co +   (nA  co ).
Exact potential games are also referred to as congestion games (Rosenthal, 1973). Finite versions
of such games are always guaranteed to have a pure-strategy Nash equilibrium. Moreover, agents can
reach a pure-strategy Nash equilibrium by starting from an arbitrary action vector a0 and iteratively
playing best-response action, one by one. When the players are anonymous and update their strategies
simultaneously, as we study in this paper, this doesnt hold. Hence, the theory of potential games cannot
be applied to the scenario we study in this paper.

334

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

Agents follow implementation 

Asynchrony

Initial state

Agents follow
convention 

n=4
c=3

n=3
c=2

n=2
c=1

n=1
c=0

Figure 1: Learning to play a convention in a resource allocation game with N = 4 agents
and C = 3 resources. Under each state, we denote the number of losers in the
current state n, and the number of unclaimed resources c. Winners are denoted
as black circles, losers as light grey circles. In the asynchrony state, there are
3 winners and one loser. Arrows indicate the possible transitions between the
states. Once the players reach the asynchrony state, they start following the
convention from the next round on.

 If player i is a winner for signal kt , she will access the same resource as she did
the last time signal kt was observed.
 If player i is a loser, she will access choose to access an unclaimed resource r
p
with probability 0  (n,c)
 1. The probability of accessing a claimed resource
c
is zero.
In the remainder of this section, instead of studying general strategies for the repeated
game, we will limit ourselves to strategies which are a uniform implementation.
Figure 1 shows how the agents learn to follow a convention when N = 4 and C = 3.
Assume that the players adopt a convention , and they use its implementation . Initially,
they are all losers, and the implementation prescribes the same strategy to all of them.
Once an agent accesses some resource alone, she becomes a winner and will access the same
resource until the agents reach an asynchrony round (a state where each resource is accessed
by exactly one agent).
Definition 27. (Expected payoff functions EA and EY ) Let GN,C be an infinitely
repeated resource allocation game, let  be some uniform convention and  its equilibrium
implementation. Let ht be the history of the game in round t, such that some k  K, the
Nash equilibrium has not been reached (and so the convention has not been activated yet).
Let nk the number of losers for signal k  K and ck the number of unclaimed resources
for signal k  K. Let p = (pn1 ,c1 , . . . , pnK ,cK ) be the access probability of the losers for
335

fiCigler & Faltings

each signal k  K. Let kt be the currently observed coordination signal. Let w (nw ) be the
expected payoff of a new winner (player who was a loser in previous rounds and becomes
winner in round t) given that there are nw new winners in round t. Let l (nw ) be the
expected payoff of a player who stays a loser, when there are nw new winners in round t.
Assume that player  is a loser for signal kt . We define her expected payoff functions EA
and EY when she takes action A (or Y ) for signal kt , and adopts the strategy prescribed
by the implementation  for other signals:
EA (p, kt ) :=
min(n,c)

X

[Pr( wins & nw winners|A)w (nw ) + Pr( loses & nw winners|A)( + l (nw ))]

nw =1







K
X


 



+ Pr(0 winners|A)   +
E
(p,
k)
+
(p
E
(p,
l)
+
(1

p
)E
(p,
l))
n
,c
n
,c
A
A
Y
l
l
l
l

K
l=1
l6=k

(6)
min(n,c)

EY (p, k) :=

X

Pr(nw winners|Y )  l (nw )

nw =1





K
X

 
EY (p, k) +
(pnl ,cl EA (p, l) + (1  pnl ,cl )EY (p, l))
+ Pr(0 winners|Y ) 


K

(7)

l=1
l6=k

3.2 Existence of an Equilibrium Implementation
We are now ready to prove that for any uniform equilibrium convention, there exists its
equilibrium implementation.
Lemma 1. For any signal k  K, the functions EA and EY are continuous in p  h0, 1iK .
Proof. The probabilities Pr(nw winners|A) and Pr(nw winners|Y ) are continuous. The
functions EA and EY are sums of products of continuous functions, so they must be themselves continuous.
Lemma 2. Functions EA and EY are well-defined for any k  K and p  h0, 1iK .
Proof. For fixed p,  and , the functions EA and EY define a system of 2K linear equations.
We can write this system as (I  A)E = b, where E = (EA,1 , . . . , EA,K , EY,1 , . . . , EY,K ) is
a vector of variables corresponding to the payoff functions, b  R2K and I is 2K  2K unit
matrix. The matrix A is defined as follows: The first K rows correspond to variables EA,k
and the second K rows correspond to variables EY,k .
The elements in row k corresponding to EA,k are defined as:

for l = k
Pr(0 winners|A, pnk ,ck )  K



0
for l = K + k
Ak,l :=

Pr(0
winners|A,
p
)


p
for l  K, l 6= k

nk ,ck
nl ,cl

K


Pr(0 winners|A, pnk ,ck )  K  (1  pnl ,cl ) for K < l  2K, l 6= K + k
336

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

The elements in row K + k corresponding to EY,k are defined as:

AK+k,l


Pr(0 winners|Y, pnk ,ck ) 



0
:=
Pr(0
winners|Y, pnk ,ck ) 



Pr(0 winners|Y, pnk ,ck ) 


K

K

K

for
for
for
 pnl ,cl
 (1  pnl ,cl ) for

l =K +k
l=k
l  K, l 6= k
K < l  2K, l 6= K + k

This system of equations has a unique solution if the matrix A is non-singular. This is
equivalent to saying that det(A) 6= 0.
PK
The matrix A is diagonally dominant, that is aii >
j=1,j6=i |aij |. This is because
P2K
0 <  < 1, and the rows of the matrix A sum to l=1 Ak,l =   Pr(0 winners|A, pnk ,ck ) for
P
1 < k  K, and 2K
l=1 AK+k,l =   Pr(0 winners|Y, pnk ,ck ) for K < K + k  2K.
It is known that diagonally dominant matrices are non-singular (Taussky, 1949). Therefore, a unique solution E of the system exists and the functions EA , EY are well-defined for
a fixed p,  and .
Lemma 3. There exists p such that for any k  K, one of the following is true:
1. pk = 0 and EY (p , k) > EA (p , k);
2. pk = 1 and EA (p , k) > EY (p , k);
3. 0 < pk < 1 and EA (p , k) = EY (p , k).
Such p defines a symmetric best-response strategy for the losers.
Proof. Fix  and . We will show that for an arbitrary p and every signal k  K, there
exists p0k which satisfies one of the three conditions of the Lemma 3 above.
For contradiction, assume that for p0k = 0, EY (p0 , k)  EA (p0 , k) and for p0k = 1,
EA (p0 , k)  EY (p0 , k). Then from the fact that both functions EA and EY are well-defined
and continuous for 0  pk  1, they must intersect for some 0 < p0k < 1.
From this, there must exist a vector p where for all k  K, the conditions of the
Lemma 3 are satisfied.
Corollary 1. Let GN,C be an infinitely repeated resource allocation game. For any uniform
equilibrium convention  of the game GN,C , there exists an equilibrium implementation  .
To illustrate the different equilibrium payoffs agents can get when they adopt different
conventions, consider the resource allocation game with N = 4 agents and C = 1 (to
simplify the presentation, assume that K = 1). Assume that before round t, the resource
has been claimed yet, so there are n = 4 losers and c = 1 unclaimed resource. If some
agent becomes a winner in round t, the agents adopt an extended uniform convention that
prescribes their strategies from then on.
For comparison, assume that the agents can adopt either a convention 1 , or a convention

2 . If they adopt convention 1 , the winners have an expected payoff w1 = 4, and the losers
an expected payoff l = 0. On the other hand, if they adopt convention 2 , the winners
1

have an expected payoff w2 = 2, and the losers an expected payoff l2 = 1.
337

fiCigler & Faltings

(a) Convention 1

(b) Convention 2

Figure 2: Example of expected payoff functions for resource allocation game with N = 4
agents, C = 1 resources, cost of collision  = 2 and discount factor  = 0.8,
1 and E 1 are expected payoff
given the access probability p. The function EA
Y
functions of accessing and yielding, when the agents use an extended convention
2 and E 2 are expected payoff functions when the agents use an
1 . Similarly, EA
Y
extended convention 2 . Convention 1 has an expected winner payoff w1 = 4,
and expected loser payoff l = 0. Convention 2 has an expected winner payoff
1

w2 = 2 and expected loser payoff l2 = 1.
In the equilibrium implementation 1 of the convention 1 , the agents access
the resource with probability p1 , and their expected payoff is E1 = 0. In the
equilibrium implementation 2 of the convention 2 , the agents access the resource
with probability p2 < p1 , and their expected payoff is E2 > E1 = 0.

1 and E 1 for the convention  , and E 2
Figure 2 shows the expected payoff functions (EA
1
Y
A
2

and EY for the convention 2 ), depending on the access probability p. We can see that the
equilibrium implementation payoff E2 of the convention 2 is higher than the equilibrium
payoff E1 of the convention 1 , even though the sum of the winner and loser payoffs is higher
for convention 1 . This is because the loser receives a positive payoff when the agents adopt
a convention 2 ; the agents are less likely to fight to become a winner, and they access
the resource with a lower probability p2 < p1 . This way, there will be less collisions, and
the agents will receive a higher expected social payoff when they adopt the convention 2 .

3.3 Calculating the Equilibrium
While the symmetric subgame-perfect equilibrium is guaranteed to exist, in order to actually
play it, the agents need to be able to calculate it. It is not always possible to obtain the
338

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

closed form of the probability of accessing a resource. Therefore, we will show how to
calculate the equilibrium strategy numerically.
Let p be a probability vector and k a signal. Let p0 := (p1 , p2 , . . . , pk = 0, . . . , pK ), i.e.
vector p with pk set to 0. Let p1 := (p1 , p2 , . . . , pk = 1, . . . , pK ). From Lemma 3 we know
that either EY (p0 , k) > EA (p0 , k), or EA (p1 , k) > EY (p1 , k) or the two functions intersect
for some 0  pk  1. Furthermore, we know that EA (p0 , k) = w (c) since the probability
of successfully claiming a resource is 1 when everyone else yields, and also EY (p0 , k) = 0.
Therefore, EY (p0 , k) > EA (p0 , k) iff w (c) > 0.
W.l.o.g, we will assume that w (c) > 0. Algorithm 1 shows then how to calculate the
probability vector.
Algorithm 1 Calculating the equilibrium probabilities
for Each subset S  {1, 2, . . . , K} do
Let  be a system of equations
i 
/ S,  contains two equations for E(p, i). One corresponding to EA (p, i), one to
EY (p, i) (see Equations 6 and 7).
j  S, we set pj := 1.  contains only one equation for E(p, j), corresponding to
EA (p, j).
So  is a system of 2K  |S| equations with 2K  |S| variables.
Solve numerically the system of equations .
if there exists a solution to  for which i 
/ S, 0  pi  1 then
We have found a solution
break;
end if
end for
The numerical algorithm has a complexity exponential in K, and is therefore only suitable for small K. In Section 4.2.3, we will show conditions under which the access probabilities are easy to compute and define a -equilibrium of the repeated game. That is, no
agent can gain more than  factor more by deviating from the prescribed strategy.

4. Actual Conventions
In the previous section, we have shown that we can find a symmetric way to reach any
convention, provided the agents access the resources with a certain probability. We have
also shown how to calculate the resource access probability in every stage of the game. In
this section, we would like to show specific examples of the conventions that agents can
adopt, and discuss their properties.
4.1 Bourgeois Convention
The bourgeois convention is the simplest one. Once an agent has accessed a resource
successfully for the first time, he will keep accessing it forever. We say that the agent has
claimed the resource. We dont need any coordination signal to implement it, so we can set
K := 1.
339

fiCigler & Faltings

We will describe the decision problem from the point of view of agent . Assume that
there are N agents and C resources. At round t, let ct be the number of resources which
have not been claimed yet, and nt := N C +ct the number of players who have not claimed
a resource yet. Assume that other players besides  use the following strategy:
 If a player has claimed a resource previously, she will keep accessing it;
 If a player hasnt claimed any resource yet (she is a loser), she will choose to access
with probability pct and then choose the actual resource to access uniformly at random.
Definition 28. (Expected payoff function of the Bourgeois convention) Let p :=
(p1 , p2 , . . . , pC ) be a probability vector, such that pc is the probability with which any of
the losers will access when there are c unclaimed resources. We define the expected payoff
function to player  should she choose to access (play A, that is choose to access and then
choose the resource uniformly at random) or yield (play Y ), respectively:



p n1
1
p n1
EA (p, c) := 1 

+ 1 1
 ()
c
1
c
c
X
Pr( loses and nw = l|A)  E(p, c  l);
+


l=0

EY (p, c) :=  

c
X

Pr(nw = l|Y )  E(p, c  l);

l=0

In both equations, E(p, c) = max {EA (p, c), EY (p, c)}.
Lemma 4. For any p and 1  c  C, E(p, c)  0.
Proof. No matter what is the strategy of the opponents, if agent  chooses to always yield,
its payoff will be 0.
Lemma 5. Let p be a probability vector which defines the strategies of the other losers, and
let ct be the number of unclaimed resources in round t. If c  ct , EA (p, c) = EY (p, c),
then c  ct , E(p, c) = 0.
Proof. When there are ct unclaimed resources in round t, in every following round t0  t
there will be c  ct unclaimed resources (in bourgeois convention, agents never release
claimed resources). If the agent  is indifferent between actions Y and A in every round
following round t, that means that it is indifferent between a strategy of the subgame that
prescribes Y in every round and any other strategy. The (expected) payoff of the strategy
that prescribes always Y is 0. Therefore, the expected payoff of any other subgame strategy
must be 0 as well.
For the purpose of our problem, all the unclaimed resources are identical. Therefore the
only parameter of the losers strategy is the probability with which the agents decide to
access  the resource itself is then chosen uniformly at random. Lemma 5 shows a necessary
condition on p for agent  to be indifferent. The following lemma shows that such p exists
and is unique.
340

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

Lemma 6. Assumeat timer
t there are
 ct unclaimed resources. Let for all c  ct unclaimed
||
resources be pc = c 1  n1 ||+ 1
the probability with which the losers play A. Then
1

for all c  ct unclaimed resources, agent  is indifferent between yielding and accessing.
For a given c, such probability is unique on the interval [0, c].
Proof. From Lemma 5 we know that when agent  is indifferent (i.e. EA (p, c) = EY (p, c)),
it must be that E(p, c) = 0 for all 1  c  ct .
From Definition 28, the expected profit to agent  from playing A and then following
best-response strategy (with zero payoff) is




pc n1
1
pc n1
EA (p, c) = 1 

+ 1 1
 ()
c
1
c
(8)
+   Pr( loses and nw = 0|A)  E(p, c).
Here pc is the probability with which the other losers access. We want EA (p, c) =
EY (p, c) = 0. This holds if pc is defined as in the lemma above.
Function EA is decreasing in pc on the interval [0, c], while function EY is constantly 0.
Therefore, their intersection is unique on an interval [0, c].
Lemma 7. Assume that all the opponents who havent claimed any resource access a resource with probability p < pc . Then it is best-response for agent  to access.
Proof. The probability that agent  claims successfully a resource after playing A is

p n1
Pr(claim some resource|A) := 1 
(9)
c
This probability increases as p decreases. Therefore the expected profit of playing A is
increasing as p decreases, whereas the profit of playing Y stays 0.
Theorem 8. Define an agents strategy  as follows: If there are c unclaimed resources,
play A with probability pc := min (1, pc ) (where pc is defined in Lemma 6). Then a joint
strategy profile  = (1 , 2 , . . . , N ) where c, c =  is a subgame-perfect equilibrium of the
infinitely repeated resource allocation game.
Proof. From Lemma 6, if pc < 1, any agent is indifferent between playing Y and playing A,
therefore will happily follow strategy  . From Lemma 7, if pc = 1 < pc , it is best response
for any agent to play A, just as the strategy  prescribes.
Theorem 9. For all c  N, if pc = pc , E(p, c) = 0.
Proof. We will proceed by induction.
For c = 0, the expected payoff is trivially E(p, 0) = 0, because there are no free resources.
Let j < c, E(p, j) = 0 and pc = pc . If agent  plays Y , the expected payoff is clearly 0
(it will be 0 now and 0 in the future by the induction hypothesis). If agent  plays A, the
expected payoff is (by Definition 28):

pc n1
1

EA (p, c) := 1 
c
1


c
(10)


X
pc n1
Pr( loses and nw = l|A)  E(p, c  l)
+ 1 1
 () +  
c
l=0

341

fiCigler & Faltings

Because of the way the pc is defined, and from the induction hypothesis E(p, j) = 0 for
j < c, we get
EA (p, c) := Pr( loses and nw = 0|A)  E(c,  )
=  Pr( loses and nw = 0|A)  max{EA (p, c), EY (p, c)}

(11)

Since   Pr( loses and nw = 0|A) < 1, it must be that EA (p, c) = 0.
Theorem 10. If pc < pc , E(p, c) > 0.
Proof. From Lemma 7 we know that when pc < pc , it is a best response to access, so
E(p, c) = EA (p, c). From Lemma 4 we know that for all j, E(p, j)  0. If pc < pc , by
Definition 28 we see that E(p, c) > 0.
Theorem 10 shows that if we have enough resources so that pc  1, the expected payoff
for the agents, even when they access all the time, will be positive.
Given the number of agents N , discount factor  and collision cost , the necessary
number of resources c for the expected payoff to be positive is:
c :=
1

1
r
n1

||
1
||+ 1

(12)

Figure 3 illustrates the value of c depending on N , , and  respectively. Figure 3a shows
how the number of resources c increases as N increases  naturally, more agents need more
resources.
Figure 3b shows on the other hand that with an increasing discount factor , the necessary number of resources drops. This is because for high , the agents are almost indifferent
between winning now and winning later. In Section 4.2.3, we will explore this idea in more
detail  we will show that for high enough delta, a strategy which prescribes the agents to
access with a constant probability until they reach the asynchrony is an -equilibrium of
the resource allocation game.
Finally, Figure 3c shows an increasing number of resources which are necessary for the
bourgeois convention to have positive payoff, as the collision cost  increases. The increase
is almost linear in . This is because the higher the cost of collision, the lower the expected
payoff of accessing EA . For the bourgeois convention to have positive expected payoff, we
need EA > 0 for all 0  p  1.
Let us now look at the price of anonymity for the bourgeois convention (as defined in
Definition 16).
Theorem 11. The price of anonymity of the bourgeois convention is infinite.
Proof. The highest social payoff any strategy profile  can achieve in an N -agent, C-resource
allocation game (N  C) is
C
max E( ) :=
.
(13)
1
This is achieved when in every round, every resource is accessed by exactly one agent. Such
strategy profile is obviously asymmetric.
342

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

25

20

200

20
15

150

15
C*

C*
10

C*
100

10
5
0
0

50

5
5

10
N

15

20

0
0

0.5


(a) N

1

0
0

50


(b) 

100

(c) 

Figure 3: Minimum number of resources c needed for the expected payoff of bourgeois
convention to be positive, depending on N , , and . One parameter is varying,
the other parameters are set to N = 10,  = 0.8,  = 2. For varying N , the
dashed line shows when c = N .

3.5
N=3
N=4
3

2.5
R
2

1.5

1
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Figure 4: Market convention: Price of anonymity for C = 1, K = N ,  = 0.5 and varying .

If each agent knew which part of the bourgeois convention to play at the beginning of the
game, this convention would be socially efficient. However, when the agents are anonymous,
they have to learn which part of the convention they should play through randomization.
For the bourgeois convention for small C relative to N , this randomization is such that
the agents are indifferent between accessing some resource and yielding, and their expected
payoff of both is zero. Therefore, its price of anonymity is infinite.
4.2 Market Convention
We saw that the bourgeois convention leads to zero expected social payoff for a small
number of resources. We would like to improve the expected payoff here. In the bourgeois
convention, the agents receive zero expected payoff because the demand for resources is
too high compared to the supply. We need to decrease the demand, while increasing the
343

fiCigler & Faltings

2.5
N=3
N=4

2
R

1.5

1
0

1

2

3

4

5

Figure 5: Market convention: Price of anonymity for C = 1, K = N ,  = 0.9 and varying .

supply. This is often achieved through markets. Shneidman et al. (2005) present some of
the reasons why markets might be appropriate for resource allocation.
We assume the following:
 Agents can observe K  1 coordination signals.
 Agents have a decreasing marginal utility when they access a resource more often.
 They pay a fixed price per each successful access, to the point that each agent prefers
to access a resource only for one signal out of K. In practice, this could be implemented by a central authority that observes the convergence rate of the agents, and
dynamically increases or decreases the price to achieve convergence.
Such assumptions define what we call market convention, where the winners only access their claimed resource for the signals they observed when they first claimed it. The
price the agents have to pay serves to decrease the demand. The coordination signal effectively increases the supply of resources K-times, because the resource allocation may be
different for each of the signal values.
We know that we can implement this convention for C  1 resources using symmetric
play (see Section 3). For small K, we can also use Algorithm 1 to calculate the access
probabilities. For the ease of exposition, we will first describe the market convention for
C = 1 resource. Then we will generalize the description to C > 1 resources.
4.2.1 One Resource
When each agent only accesses the resource for one signal, we need K = N signals to make
sure everyone gets to access once.
In the N -agent, 1-resource case, imagine there are still n agents playing and (N  n)
agents who have already claimed the resource for some signal. Imagine that the n agents
observe one of the n signals for which no resource has been claimed.
344

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

Assume that all agents access the resource with probability pn . The expected payoff of
accessing a resource for agent  is



1
EA (pn , n) := (1  pn )
 1+

N 1




n
+ 1  (1  pn )n1   +
EA (pn , n)
N  (N  n)
n1



(14)

The expected payoff of yielding for agent  is

EY (pn , n) := (n  1)pn (1  pn )n2 E(n  1)


n
EY (pn , n)
+ 1  (n  1)pn (1  pn )n2
N  (N  n)

(15)

When pn = 1, accessing a resource will always lead to a collision, so the payoff of
accessing will be negative. When pn = 0, accessing a resource will always claim it, so the
payoff of accessing will be positive. In the equilibrium, the agents should be indifferent
between accessing and yielding. Therefore, we want to find pn such that EA (pn , n) =
EY (pn , n) = E(n).
Finding a closed form expression for pn is difficult, but we can use Algorithm 1 to
calculate this probability, as well as the expected payoff E(n), numerically (albeit in practice
only for small K).
Figures 4 and 5 show the price of anonymity of the market convention (as defined in
Definition 16) for varying discount factor , and varying cost of collision , respectively.
From Section 4.1, the price of anonymity for C = 1 is . In contrast, for the market
convention this price is in both cases finite and relatively small.
4.2.2 Multiple Resources
Assume now that C  1. In any given round, we will denote c := (c1 , c2 , . . . , cK ) the
vector of resources which have not been claimed yet for each value of the coordination
signal k  {1, 2, . . . , K}. We will denote n the number of players who have not claimed any
resource yet for any signal value. Finally, let p := (pn,c1 , pn,c2 , . . . , pn,cK ) be the vector of
probabilities, where pn,ck denotes the probability that a loser will access some resource for
signal k  K, given that ck resources are available.
From Corollary 1, we know that for the market convention, there exists an equilibrium
implementation. But what does it look like exactly? In order to be able to express it (albeit
only numerically), we need to define the expected payoff functions the players receive for
each action.
345

fiCigler & Faltings

For number of losers n, observed coordination signal k and vectors p and c, we can
define expected payoff functions when a player  takes action A and Y , respectively:
EA (p, c, n, k) := Pr( wins|A)  w + (1  Pr( wins|A))  ()
min(ck ,n)

+

X

Pr( loses, nw winners|A)  E(p, (ck  nw , ck ), n  nw )

nw =1

+ Pr(nw = 0|A) 


 EA (p, c, n, k)
K



+ Pr(nw = 0|A)  
K 

K
X
l=1
l6=k

(16)



(pn,cl EA (p, c, n, l) + (1  pn,cl )EY (p, c, n, l))


min(n,c)

EY (p, c, n, k) :=

X

Pr(nw winners|Y )  E(p, (ck  nw , ck ), n  nw )

nw =1


+ Pr(nw = 0|Y ) 



K
X

 
EY (p, c, n, k) +
(pn,cl EA (p, c, n, l) + (1  pn,cl )EY (p, c, n, l))


K
l=1
l6=k

(17)
In the equations above, E(p, c, n) is the expected payoff before the players observe the
coordination signal. It is defined as
E(p, c, n) :=

K
1 X
E(p, c, n, k).
K
k=1


The winner payoff w is defined as w := 1 + K(1)
. This is because the winner will
access for only one signal: once in the current round, and than in any future round with
probability K1 .
What are the probabilities that there will be nw winners in each of the cases? We will
start with the simplest case, Pr(nw winners|Y ), given that there are n agents (including
agent ), ck resources and all agents except  play action A with probability pk .
The problem of calculating this probability is very similar to the well-known balls-andbins problem (Raab & Steger, 1998). In the balls-and-bins problem we assume that we
have n balls who are each randomly assigned into one of the c bins. The goal is to find a
probability that i bins will have exactly one ball in them. We will express this probability
as (n, c, i).
There are Ni ways to pick some i balls, place them into some i bins so that each bin
has one ball, and place the remaining n  i balls into the remaining c  i bins randomly,

  
c n
Ni :=
 i!  (c  i)ni
i
i
346

(18)

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

There are a total of cn ways to arrange n balls into c bins. Therefore, the probability
(n, c, i) is The total number of ways to place n balls in c bins so that exactly i have one
ball can be then obtained from the generalized inclusion-exclusion principle:
1
(n, c, i) := n
c
1
= n
c
=

min(c,n)

X

ji

(1)

j=i
min(c,n)

X

ji

(1)

j=i

 
j
Nj
i

   
j
c n
 j!  (c  j)nj
i
j
j

(19)



  min(c,n)
nj
X
n! c
ji c  i (c  j)
(1)
.
j  i (n  j)!
cn i
j=i

 
 ci
In the simplification above, we use the absorption identity ji jc = ci ji
.
How can we use the function  to calculate Pr(nw winners|Y )? The n  1 agents (other
than ) decide to play action A with probability pk , and then choose the resource to access
randomly. The agents who choose to access a resource correspond to the balls-and-bins
problem. Therefore,
Pr(nw winners|Y ) :=

n1
X


n1 i
pk  (1  pk )n1i  (i, c, nw ).
i

i=0

(20)

To calculate the probability Pr( wins|A), we can proceed as follows. We assume w.l.o.g
that  accesses resource 1. There will be some i agents (out of n  1) who will choose action
A. We then need all of them to choose other resource than 1. Therefore,
Pr( wins|A) :=

n1
X
i=0




n1
1 i
i
n1i
 pk  (1  pk )
1
c
i

(21)

Finally, to calculate the probability Pr( loses, nw winners|A), we can use again the
balls-and-bins problem. Given that there are 0  i  n  1 agents who choose action A,
there will be 0  j  i agents who choose the same resource as agent . The remaining
(i  j) agents face the same balls-and-bins problem for c  1 bins (1 bin is already occupied
by agent ). Therefore,
Pr( loses, nw winners|A) :=

n1
i    j 
X n  1
X
i
1
1 ij
1
 (i  j, c  1, nw )
pik (1  pk )n1i
i
j
c
c
i=1

j=1

(22)
Now that we have expressed the expected payoff functions EA and EY explicitly, we can
use Algorithm 1 to calculate the equilibrium access probabilities and expected payoffs.
Figures 6 and 7 show the price of anonymity of the market convention for C = 3, K = 2
and N = C  K = 6. When the discount factor  grows, the price of anonymity decreases
347

fiCigler & Faltings

600

Price of anonymity

500

400

300

200

100

0
0.1

0.2

0.3

0.4

0.5


0.6

0.7

0.8

0.9

Figure 6: Market convention: Price of anonymity for N = 6, C = 3, K = 2,  = 0.5 and
varying .

2.6
2.5

Price of anonymity

2.4
2.3
2.2
2.1
2
1.9
1.8
1.7
0

1

2

3

4

5



Figure 7: Market convention: Price of anonymity for N = 6, C = 3, K = 2,  = 0.9 and
varying .

(note that in Figure 6 the y-axis is logarithmic). This is because for small , the benefit
of winning the resource right away is much higher than the payoff of winning later. On
the other hand, as  gets closer to 1, the agents dont care whether they win now or later.
Since the market convention guarantees that everyone will be able to access some resource
for some signal value, when   1, the expected payoff of winner and losers will be the
same. Also, as   1, the cost the agents have to pay for learning the convention decreases
compared to the payoff they obtain after they have learnt it.
When  increases, the price of anonymity increases. The cost of collision has a direct
effect on the expected payoff functions EA and EY . Therefore, the expected equilibrium
348

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

payoff will be higher if the cost is lower. Changing the  has no effect on the optimal
asymmetric outcome though, since the agents dont have to pay any cost because there are
no collisions.
4.2.3 -equilibrium
Calculating the equilibrium access probabilities for the market convention is difficult  we
need to use a numerical algorithm, and as the number of signals K grows, the number of
equations grows exponentially. Therefore, we would like to find access probabilities which
are easy to compute and for which the agents incentive to deviate is too small. Indeed,
game theory is often interested in -equilibria, in which no agent can improve her payoff by
more than  > 0.
The market pricing ensures that each agent only wants to access a resource for one signal
value. It also doesnt depend on the access probabilities of the agents, only on their utility
functions. Once the agents converge to the asynchrony round (i.e. a pure-strategy NE of
the resource allocation for every signal value), their future expected payoff will be
K 1
,
1

(23)

and no agent can improve her payoff by deviating since the players are playing a PSNE of
the stage game in each round.
If the agents who havent claimed their resource yet play action A with a constant
probability 0 < pconst < 1, the expected time before the reach the asynchrony is finite.
(from the properties of the balls-and-bins problem, see Section 4.3, or Raab & Steger,
1998). We can prove the following theorem:
Theorem 12. Suppose that in the N -agent, C-resource allocation game, the agents adopt
the market convention with the following implementation: The agents who havent claimed
any resource yet play action A with a constant probability pconst (we call this the constantprobability implementation). Let E() be the expected payoff for each agent in this case for
a given discount factor . Let E 0 () be the expected payoff of the best-response strategy to
this convention and implementation.
Then for any  > 0, there exists 0 < 0 < 1 such that for all , 0   < 1,
E()
> 1  .
E 0 ()

(24)

Proof. Because of the market pricing, each agent only wants to access one resource for one
value of the coordination signal. So the best-response payoff E 0 is
E 0 () 

K 1
,
1

(25)

no matter what strategy do the other agents play.
When the agents adopt the market convention with the constant-probability implementation, then in every round until they converge to a PSNE, they receive a payoff between
 < 0 (the collision cost) and 1. After they reach the PSNE, their expected payoff is
K 1
1
349

(26)

fiCigler & Faltings

as stated above. We can therefore say that
E() 


X
i=0

i
1  i
+ K 1 
Pr(agents reach PSNE in i steps)   
1
1



(27)

We can define a random variable X such that X = i if the agents reach a PSNE after
exactly i steps. From the properties of the expected value, we can ee that
 
 
  (1  E  X ) + K 1  E  X
E() 
.
(28)
1
The function (x) :=  x is a convex function. From Jensens inequality (1906), we know
that
 
E  X   E[X] .
(29)
Therefore,

  1   E[X] + K 1   E[X]
E()

.
E 0 ()
K 1

(30)

The expected time E[X] to reach the PSNE is finite and doesnt depend on , so we can
treat is as a constant. Because  E[X] is continuous in , monotonous and lim1  E[X] = 1,
we can see that for a given  > 0, there exists 0 < 0 < 1 such that for all , 0   < 1,
E()
> 1  .
E 0 ()

(31)

By ensuring that each agent only wants to access some resource for one signal value,
the market convention makes the cooperative strategy from our previous work (Cigler &
Faltings, 2011) almost rational.
4.3 Expected Convergence Time
In this section, we will analyze what is the expected number of rounds the agents need to
converge to a perfect allocation of resources (one where all resources are used by exactly one,
and there are no collisions). We will first prove an upper bound on the expected number
of steps to the convergence for the bourgeois convention, and then present experiments for
the market convention.
4.3.1 Bourgeois Convention
In order to prove the convergence of the bourgeois convention, we will describe its execution
as a Markov chain. A Markov chain describing the execution of the bourgeois convention in
N -agent, C-resource allocation game is a chain whose state at round t is Xt  {0, 1, . . . , C},
where Xt = c means that there are c unclaimed resources at round t.
We are interested in the expected number of rounds it will take to this Markov chain to
reach state 0 if it started in state C. This is called the expected hitting time:
350

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

Definition 29. (Norris, 1998) (Hitting time) Let (Xt )t0 be a Markov chain with state
space I. Given a probability space (, , Pr), the hitting time of a subset A  I is a random
variable H A :   {0, 1, . . .}  {} given by
H A () = inf{t  0 : Xt ()  A}
In general, the expected hitting time of a set of states A can be found by solving a
system of linear equations:
Theorem 13. The vector of mean hitting times k A = E(H A ) = (kiA : i  I) is the minimal
non-negative solution to the system of linear equations
 A
ki = 0 P
for i  A
(32)
A for i 
kiA = 1 + j A
p
k
/A
ij j
/
Solving them analytically for our Markov chain is however difficult. Fortunately, when
the Markov chain has only one absorbing state i = 0, and it can only move from state i to
j if i  j, we can use the following theorem to derive an upper bound on the hitting time
(proved by Rego, 1992):
Theorem 14. Let A = {0}. If
i  1 : E(Xt+1 |Xt = i) <
for some  > 1, then


kiA < log i +

i



1

In order to use the Theorem 14, we need to calculate the expected state E(Xt+1 |Xt = c).
Lemma 15. Let Xt = c, and let there be n := N  C + c agents who have not claimed a
n1
that a resource i will be claimed in
resource yet. Let us denote q(n, c) = pc  n  1  pc
round t if the agents play the subgame-perfect equilibrium strategy vector described above.
Then the next expected state is
E(Xt+1 |Xt = c) := (1  q(n, c))  c
Proof. For a resource i, we can denote Wi the random variable, where Wi = 1 if the resource
i has been claimed in round t, and Wi = 0 otherwise. The random variable Wi is Bernoullidistributed with probability q(n, c).
The next expected state is then
" c
#
c
X
X
E(Xt+1 |Xt = c) = c  E
Wi = c 
E[Wi ] = (1  q(n, c))  c,
(33)
i=1

i=1

because E[Wi ] = q(n, c).
In the following lemmas, we will denote
 :=

||
1
|| + 1
351

(34)

fiCigler & Faltings

Lemma 16. For a given collision cost  and discount factor , there exists a constant
0 <  < 1 such that for c    n, p < 1.
Proof. According
to the definition of the subgame-perfect equilibrium strategy, p := c 

 
n1
1
 .
We want p < 1, which is equivalent to

 
n1
c 1
 <1
(35)


1 n1
1
<
(36)
c
(37)
We know that c    n, so



n1
1 n1
1
1
 1
 e .
c
n

(38)

If we therefore set  such that e < , the access probability p < 1.
Lemma 17. For given  and , there exists 0 <  < 1 such that for any c,
E(Xt+1 |Xt = c)  (1  )  c

Proof. We will prove the lemma for two cases: when p <
 1 andwhen
 p = 1.
First, let us prove the case p < 1, that is p = c  1  n1  . Therefore, q(n, c) =

 
1  n1   n  . It can be shown that for any n,


q(n, c) = 1 

 
  n     log .

n1

Now let p = 1. From Lemma 16 it must be that c >   n. Then



n1
c
1 n1
1
q(n, c) :=  1 
 1
,
n
c
n
because q(n, c) is increasing with c.
Now

 1

1
n

n1

   e .

(39)

(40)

(41)

For fixed , , the  and  are constants, so we can set  as
 := min(  e ,  log ).

(42)

From above, this proves the lemma.
Theorem 18. The expected time for the agents to converge to a resource allocation where
all the resources are claimed is O(log C).
352

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

Proof. We have shown how we can express the expected convergence time as expected
hitting time of a certain Markov chain.
From Lemma 17 we saw that there exists  such that for any c,
E(Xt+1 |Xt = c)  (1  )  c.
We can now combine this result with Theorem 14 to show that the expected hitting
time from the state C to state 0 is


1
1
0
kN < dlog 1 Ce +  O
 log C = O(log C),
(43)
1


because  is a constant.

4.3.2 Market Convention
For the market convention, it is unfortunately very difficult to express the expected number
of convergence steps in a closed-form expression. However, we can use linear programming
to calculate the expected number of convergence steps for a given parameters N , C, K, 
and .
The Markov chain for the market convention for K signals and C resources looks as
follows: Its state at time t is Vt  {0, 1, . . . , C}K , where Vtk denotes how many resources
have not been claimed for signal k. The initial state V0 is such that V0k = C for all
k  {1, . . . , K}. If N  C  K,Pthe final state is when Vtk = 0 for all k. When N < C  K,
the final states are such that k{1,...,K} Vtk = C  K  N .
The transition probabilities between two states Vi and Vj , Vi 6= Vj , are the following:
Suppose k : Vjk < Vik and l 6= k : Vjl 6= Vil . Let us denote c := Vik , i.e. the number of
unclaimed resources in state Vi for signal k, and n := N  (C  Vik ) the number of agents
who have not claimed any resource for signal k in state Vi .
Pr(Vt+1

n  
1 X n m
= Vj |Vt = Vi ) :=
p (1  pk )nm  (m, c, Vik  Vjk )
K
m k

(44)

m=0

Otherwise if Vj 6= Vi , Pr(Vt+1 = Vj |Vt = Vi ) := 0.
Figure 8 shows the expected number of rounds to converge for varying discount factor
. Generally, we would expect the access probability to increase with increasing , since
the profit from winning the resource increases. This should then increase the convergence
time. However, in our experiments the influence of  on the convergence time is negligible,
although we can observe a slight increase as  increases. Figure 9 shows the convergence for
varying collision cost . For  close to 0, the convergence time remains stable. However, for
very high cost , the convergence time increases linearly with . In this case, the high cost
of collision drives the resource access probability low, because agents try to avoid collisions
at all costs.
Figure 10 shows the expected convergence when we increase number of resources C and
number of agents N proportionally. The increase in convergence time is still sub-linear to
the increase in C.
353

fiCigler & Faltings

7.8

Convergence steps

7.78
7.76
7.74
7.72
7.7
7.68
7.66
0

0.2

0.4

0.6

0.8

1



Figure 8: Market convention: Expected number of convergence steps given N = 6, C = 3,
K = 2,  = 1.0 and varying .

50
45

Convergence steps

40
35
30
25
20
15
10
5 4
10

2

10

0

10


2

10

4

10

Figure 9: Market convention: Expected number of convergence steps given N = 6, C = 3,
K = 2,  = 0.9 and varying .

354

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

13
12

Convergence steps

11
10
9
8
7
6
5
4
1

1.5

2

2.5

3
C

3.5

4

4.5

5

Figure 10: Market convention: Expected number of convergence steps given K = 2,  = 0.9,
 = 1.0 and varying number of resources C and agents N = 2  C.

C&F11
Bourgeois
Egalitarian2
Market

ex-post fair
(X)1
no
X
X

efficient
X
no
X
?

equilibrium
no
X
X
X

Table 1: Properties of conventions
4.4 Convention Properties
We compare the properties of the following conventions: C&F11, a channel allocation
algorithm presented in our previous work (Cigler & Faltings, 2011); bourgeois and egalitarian
conventions, presented by Bhaskar (2000); and market convention, presented in above.
We compare the conventions according to the following properties:
Ex-post fairness Is the expected payoff to all agents the same even after asynchrony?
Efficiency Does the convention maximize social welfare among all possible conventions?
Equilibrium Does the convention have an equilibrium implementation?
Table 1 summarizes the properties of the conventions. The C&F11 convention is only
approximately ex-post fair. The fairness is improving as the number of coordination signals
increases, but some agents might have a worse payoff than others. On the other hand,
it is efficient, at least with no discounting ( = 1). However, it is not an equilibrium
1. Fair asymptotically, as N  .
2. Only for 2-agents, 1-resource games.

355

fiCigler & Faltings

of the repeated game. The bourgeois convention is neither fair nor efficient, in fact the
expected payoff to the agents is 0 (for a small number of resources). It is has an equilibrium
implementation though, since the agents are indifferent between being a winner and a loser.
The egalitarian convention is fair, efficient and has an equilibrium implementation. However,
it is only defined for games of 2 agents and 1 resource. Finally, the market convention is fair
and also has an equilibrium implementation. It is clearly more efficient than the bourgeois
convention. Nevertheless, finding the most efficient convention remains an open problem.

5. Folk Theorems and Symmetric Equilibria
In the previous sections, we have analyzed a special kind of symmetric equilibria of the
resource allocation game. The agents first followed a Markovian implementation, and as
soon as they play a pure-strategy NE, they adopted a convention. For an infinitely repeated
game with discounting, the set of Nash equilibria can be characterized using the so-called folk
theorem. While their name indicates that they have been known and used well before they
were first published, we will follow the version described by Fudenberg and Maskin (1986).
Informally, the folk theorem states that in the infinitely repeated game, for every feasible
and individually rational payoff vector of the stage game, there exists a Nash equilibrium
of the repeated game where the average payoffs per round correspond to the stage game
payoff vector.
A payoff vector is individually rational if it Pareto-dominates the minimax payoff of the
stage game. For player i, the minimax payoff is
vi := min max ui (i , i ).
i

i

(45)

To simplify the notation, Fudenberg and Maskin (1986) normalize the payoffs so that
 ) = (0, 0, . . . , 0). Let
for the minimax payoffs, (v1 , v2 , . . . , vN
U := {(v1 , . . . , vN )|(a1 , . . . , aN )  A  . . .  AN s.t. u(a1 , . . . , aN ) = (v1 , . . . , vN )},
V := convex hull of U,
V  := {(v1 , . . . , vN )  V |vi > 0 for all i}.
The set V is the set of feasible payoffs in the stage games (that is, payoffs which can be
achieved by playing some mixed or correlated strategy). The set V  is the subset of feasible
payoffs which are also individually rational.
Theorem 19. (Fudenberg & Maskin, 1986) For any (v1 , . . . , vN )  V  , if the discount
factor  is close enough to 1, there exists a Nash equilibrium of the infinitely repeated game
with discounting where, for all i, the average payoff to player i is vi .
The idea of the proof is as follows: The agents cycle through a prescribed sequence of
game outcomes so that they achieve the desired payoffs. If one player deviates, the others
punish him by playing the minimax strategy forever after.
Our focus so far has been on finding symmetric equilibrium strategies. The folk theorem doesnt say anything about whether the equilibrium strategy will be symmetric, even
if the payoff vector is symmetric. Nevertheless, we can define another class of symmetric
356

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

strategies of the infinitely repeated game, than the one based on conventions and their
implementations. The strategies have the following form: The players follow a symmetric
(mixed) strategy of the stage game. If one player deviates from this strategy, other players
punish her by following the minimax strategy. For the resource allocation game, the minimax payoff is (0, 0, . . . , 0) and is achieved in the mixed strategy Nash equilibrium. From
the Folk theorem, such strategy can be sustained as the Nash equilibrium of the repeated
game (though not necessarily a subgame-perfect equilibrium).
A symmetric strategy of the stage resource allocation game is a vector of access probabilities q = (q1 , q2 , . . . , qC ) where qc is the probability that each agent will access resource c.
We are interested in finding access probability vector q which achieves the highest expected
payoff.
For a given access probability vector q, the expected payoff that an agent receives is as
follows:
C
X



E(q) :=
qj  (1  qj )N 1  1  1  (1  qj )N 1  ||
(46)
j=1

Theorem 20. For a resource allocation game with N = 2 agents and C = 1 resource, the
resource access probability which maximizes the expected payoff of the stage game is
q =

1
1

.
2 1 + ||

(47)

Proof. We calculate the derivative of expected payoff function from Equation 46 for N = 2
and C = 1:
E(q)
= 1  2q  (1 + ||)
q
Setting the first derivative equal to 0, we get
q =

1
1

.
2 1 + ||

Since the second derivative is
 2 E(q)
= 1  || < 0,
2q
the probability q  is a local maximum of the expected payoff function E(q).
Corollary 2. For a resource allocation game with N = 2 agents and C = 1 resource, the
highest expected payoff of a symmetric strategy in the stage game is
E =

1
1

.
4 1 + ||

(48)

Corollary 3. For a resource allocation game with N = 2 agents and C = 1 resource, the
price of anonymity of the strategy which accesses with the optimal access probability q  is
4  (1 + ||).
357

fiCigler & Faltings

2

10

Folk theorem
Market convention

R 1
10

0

10

0

1

2

3

4

5



Figure 11: Price of anonymity of the symmetric strategy following from the folk theorem,
compared to the price of anonymity of the market convention for N = 3, C = 1
and varying cost of collision .

For the general case of resource allocation game with N agents and C resources, we
can
46 (given the constraint
PC find the probability vector which maximizes the Equation
2
j=1 qj  1) using the method of Lagrangian multipliers .
P
2. Our goal is to maximize E(q1 , q2 , . . . , qC ) such that q0 + C
i=1 qi = 1 and qi  0, where q0 is the
probability that an agent yields. The Lagrangian function is then
(q0 , q1 , . . . , qC , ) := E(q1 , q2 , . . . , qC ) +  

q0 +

C
X

!
qi  1 .

i=1

The first partial derivatives are

:= 
q0

E
:=
+
qi
qi

(49)
(50)

= (1  ||)  (1  qi )N 1  qi  (1 + ||)  (N  1)  (1  qi )N 2  || +  for 1  i  C

:= q0 +


C
X

1.

(51)
(52)

i=1

A necessary condition for a solution to be a maximum
is that the partial derivatives of the Lagrangian
P
function are 0. Therefore,  := 0 and q0 := 1  C
i=1 qi . For qi , 1  i  C we can find the solution to

= 0 using a numerical root-finding algorithm. If there is no point where the partial derivatives are
qi
zero, we have to compare E(q) for a (finite) number of extreme points.

358

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

Figure 11 compares the price of anonymity of the folk-theorem-based symmetric strategy
with the price of anonymity of the market convention, for N = 3 agents and C = 1 resource.
Since the price of anonymity of the folk theorem strategy doesnt depend on the discount
factor  (it only needs to be high enough for the strategy to be an equilibrium), we only show
the graph for varying collision cost . The price of anonymity of the folk-theorem strategy
is an order of magnitude higher than the price of anonymity of the market convention.

6. Conclusions
In this paper, we considered symmetric protocols to rationally coordinate on an asymmetric,
efficient allocation infinitely repeated resource allocation game with discounting of N agents
and C resources. We assumed that the agents are identical, and that the resources are
homogeneous. We based our work on the idea of Bhaskar (2000): we let the agents choose
their actions randomly, after which they adopt a certain convention. We generalize the work
of Bhaskar to an arbitrary resource allocation problem with N agents and C resources. We
show that for any convention, there exists a symmetric subgame-perfect equilibrium that
implements it. We presented two such conventions for the repeated resource allocation
game: bourgeois and market convention. We defined the price of anonymity as the ratio
between the expected social payoff of the best asymmetric strategy profile and the expected
social payoff of a given symmetric Nash equilibrium. We showed that while the price of
anonymity for the bourgeois convention is infinite (at least for small number of resources),
the price of anonymity of the market convention is finite and relatively small. This is because
the market convention reduces the demand by imposing a price on successful access, while
at the same time increasing the supply by having the agents condition their strategy on
a global coordination signal k  {1, . . . , K}. This way, the conflict between the agents is
reduced. We also showed analytically that when the agents adopt the bourgeois convention,
they will converge to a perfect resource allocation in polynomial time.
For the market convention, calculating the equilibrium access probabilities is difficult.
We need to use a numerical algorithm, whose complexity is exponential in the number of
coordination signals K. However, the market mechanism already makes sure that no agent
wants to access some resource for more than one coordination signal. Therefore, we showed
that the cooperative solution where agents access the resources with constant probability
is an -equilibrium, given that the discount factor  is high enough.
In the future work, we would like to investigate whether there exist more efficient conventions than the market convention (i.e. conventions with smaller price of anonymity). In
general, finding an optimal convention is an NP-hard problem (Balan, Richards, & Luke,
2011), but for a more restricted set of infinitely repeated resource allocation games, we might
be able to find the optimal convention, similar to the Thue-Morse sequence (Richman, 2001)
used by Kuzmics et al. (2010) in the Nash demand game.

Acknowledgements
We are particularly thankful to David Parkes for giving the first author the unique opportunity to spend a few weeks in his lab at Harvard. Davids openness and unparalleled
knowledge is what really helped originate this work. We would also like to thank Kate
359

fiCigler & Faltings

Larson for reading the draft of this paper and helping make the theoretical analysis much
more readable.

References
Aumann, R. (1974). Subjectivity and correlation in randomized strategies. Journal of
Mathematical Economics, 1 (1), 6796.
Balan, G., Richards, D., & Luke, S. (2011). Long-term fairness with bounded worst-case
losses. Autonomous Agents and Multi-Agent Systems, 22 (1), 4363.
Bhaskar, V. (2000). Egalitarianism and efficiency in repeated symmetric games. Games
and Economic Behavior, 32 (2), 247262.
Bonnet, F., & Raynal, M. (2011). The price of anonymity: Optimal consensus despite
asynchrony, crash, and anonymity. ACM Trans. Auton. Adapt. Syst., 6 (4), 23:1
23:28.
Chothia, T., & Chatzikokolakis, K. (2005). A survey of anonymous peer-to-peer filesharing. In Embedded and Ubiquitous ComputingEUC 2005 Workshops, pp. 744755.
Springer.
Cigler, L., & Faltings, B. (2011). Reaching correlated equilibria through multi-agent learning. In The 10th International Conference on Autonomous Agents and Multiagent
Systems-Volume 2, pp. 509516. International Foundation for Autonomous Agents
and Multiagent Systems.
Durresi, A., Paruchuri, V., Durresi, M., & Barolli, L. (2005). A hierarchical anonymous
communication protocol for sensor networks. In Embedded and Ubiquitous Computing
EUC 2005, pp. 11231132. Springer.
Fudenberg, D., & Maskin, E. (1986). The folk theorem in repeated games with discounting
or with incomplete information. Econometrica, 54 (3), 533554.
Jensen, J. L. (1906). Sur les fonctions convexes et les inegalites entre les valeurs moyennes.
Acta Mathematica, 30 (1), 175193.
Koutsoupias, E., & Papadimitriou, C. (1999). Worst-case equilibria. In Proceedings of the
16th annual conference on Theoretical aspects of computer science, STACS99, pp.
404413, Berlin, Heidelberg. Springer-Verlag.
Kuzmics, C., Palfrey, T., & Rogers, B. (2010). Symmetric players in repeated games: Theory
and evidence..
Leyton-Brown, K., & Shoham, Y. (2008). Essentials of Game Theory: A Concise, Multidisciplinary Introduction. Morgan & Claypool, San Rafael, CA.
Monderer, D., & Shapley, L. S. (1996). Potential games. Games and economic behavior,
14 (1), 124143.
Norris, J. R. (1998). Markov Chains (Cambridge Series in Statistical and Probabilistic
Mathematics). Cambridge University Press.
360

fiSymmetric Subgame-Perfect Equilibria in Resource Allocation

Raab, M., & Steger, A. (1998). Balls into Bins A Simple and Tight Analysis, Vol. 1518 of
Lecture Notes in Computer Science, chap. 13, pp. 159170. Springer Berlin Heidelberg,
Berlin, Heidelberg.
Rego, V. (1992). Naive asymptotics for hitting time bounds in markov chains. Acta Informatica, 29 (6), 579594.
Richman, R. M. (2001). Recursive binary sequences of differences. Complex Systems, 13 (4),
381392.
Rosenthal, R. W. (1973). A class of games possessing pure-strategy nash equilibria. International Journal of Game Theory, 2 (1), 6567.
Shneidman, J., Ng, C., Parkes, D. C., Auyoung, A., Snoeren, A. C., Vahdat, A., & Chun, B.
(2005). Why markets could (but dont currently) solve resource allocation problems
in systems. In In USENIX 05: Proceedings of the 10th USENIX Workshop on Hot
Topics in Operating Systems, p. 7.
Taussky, O. (1949). A recurring theorem on determinants. The American Mathematical
Monthly, 56 (10), 672676.
Wang, L., Wu, K., Hamdi, M., & Ni, L. M. (2011). Attachment learning for multi-channel
allocation in distributed OFDMA networks. Parallel and Distributed Systems, International Conference on, 0, 520527.

361

fi