Journal of Artificial Intelligence Research 49 (2014) 403-449

Submitted 10/13; published 03/14

Mechanisms for Fair Allocation Problems:
No-Punishment Payment Rules in Verifiable Settings
Gianluigi Greco

ggreco@mat.unical.it

Dipartimento di Matematica e Informatica
Universita della Calabria
I-87036 Rende, Italy

Francesco Scarcello

scarcello@dimes.unical.it

DIMES
Universita della Calabria
I-87036 Rende, Italy

Abstract
Mechanism design is considered in the context of fair allocations of indivisible goods
with monetary compensation, by focusing on problems where agents declarations on allocated goods can be verified before payments are performed. A setting is considered where
verification might be subject to errors, so that payments have to be awarded under the presumption of innocence, as incorrect declared values do not necessarily mean manipulation
attempts by the agents. Within this setting, a mechanism is designed that is shown to be
truthful, efficient, and budget-balanced. Moreover, agents utilities are fairly determined by
the Shapley value of suitable coalitional games, and enjoy highly desirable properties such as
equal treatment of equals, envy-freeness, and a stronger one called individual-optimality.
In particular, the latter property guarantees that, for every agent, her/his utility is the
maximum possible one over any alternative optimal allocation.
The computational complexity of the proposed mechanism is also studied. It turns
out that it is #P-complete so that, to deal with applications with many agents involved,
two polynomial-time randomized variants are also proposed: one that is still truthful and
efficient, and which is approximately budget-balanced with high probability, and another
one that is truthful in expectation, while still budget-balanced and efficient.

1. Introduction
Whenever the outcome of some social choice process depends on the information collected
from a number of self-interested agents, strategic issues may come into play. Indeed, agents
may find it convenient to misreport their types, i.e., the relevant information they own
as private knowledge, so that the (global) best possible solution can be missed. In these
cases, mechanism design techniques can be used as solution approaches, which augment
combinatorial algorithms with appropriate monetary payments, aimed at motivating all
agents to truthfully report their private types (see, e.g., Nisan, Roughgarden, Tardos, &
Vazirani, 2007; Shoham & Leyton-Brown, 2009).
On the class of social choice utilitarian problems, agent types encode (monetary) valuations over the set of all solutions and the goal is to compute a solution maximizing the social
welfare, i.e., the sum of agents true evaluations. A prominent role in mechanism design
for problems of this class is played by the Vickrey-Clarke-Grove (VCG) paradigm (Vick-

c
2014
AI Access Foundation. All rights reserved.

fiGreco & Scarcello

ery, 1961; Clarke, 1971; Groves, 1973), which is a general method for designing truthful
mechanisms, i.e., mechanisms where truth-telling is a dominant strategy for each agent. In
particular, VCG mechanisms are efficient. That is, they guarantee that a solution maximizing the social welfare is actually computed. However, they are not budget-balanced, i.e., the
algebraic sum of the monetary transfers is not always zero and mechanisms from this class
can run into deficit. In fact, this is a well-known drawback of VCG mechanisms (see, e.g.,
Archer & Tardos, 2007), but it is essentially the best one can hope to do, given classical
impossibility theorems (Green & Laffont, 1977; Hurwicz, 1975) stating that no truthful
mechanism can be designed to be always efficient and budget-balanced.
In many practical applications, however, payments to agents can be performed after
the final outcome is known, so that some kind of verification on reported types might be
possible. This additional power is not considered in the classical mechanism-design setting
and, in fact, whenever verification is allowed, some impossibility results might no longer
hold. Mechanisms with verification have been introduced by Nisan and Ronen (2001), who
considered verification for a task scheduling problem: We have some agents declaring the
amount of time they need to solve each task, and the goal is to have all tasks being solved,
by minimizing the completion time of the last-solved one (hence, the make-span). In this
context, payments are computed after the actual task release times have been observed, so
that we have, for instance, the ability to punish some agent whose declared ability has
been verified to be different than its actual performance in the process.
Compared to standard mechanisms (see, e.g., Nisan et al., 2007), those with verification
have received considerably less attention in the literature (see, e.g., Nisan & Ronen, 2001;
Auletta, De Prisco, Penna, & Persiano, 2009; Penna & Ventre, 2012a; Krysta & Ventre,
2010; Ferrante, Parlato, Sorrentino, & Ventre, 2009; Penna & Ventre, 2012b; Auletta,
De Prisco, Penna, Persiano, & Ventre, 2006; Auletta, Penna, Persiano, & Ventre, 2011). In
particular, such works consider a verification ability that is partial, in the sense that agents
reporting is restricted to true types plus certain specific kinds of deviations (e.g., values
that are lower than the true ones) and verification is focused on detecting such lies only.
An extension of the above model has been recently proposed by Caragiannis, Elkind,
Szegedy, and Yu (2012), who assume no a-priori restrictions on the agents reported types,
within a setting where an agent cheating on her/his type will be caught with some probability that may depend on her/his true type, the reported type, or both. In fact, despite the
different facets of the verification power, most of the mechanisms with verification proposed
in the literature share the idea of providing incentives to truthfully report private types by
exploiting the intimidation of punishing those agents that will be caught lying. Moreover,
while budget limits have been considered in some approaches (see, e.g., Nisan & Ronen,
2001), no mechanism with verification has been designed to be budget-balanced, with the
focus being on truthfulness and efficiency.
In this paper, we consider instead a budget-balanced mechanism based on a model
of verification where there is no restriction on the possible declarations (hence, arbitrary
deviations are possible), and nevertheless no punishment can be used after the verification
process. This design constraint has been guided by real-world applications where it clearly
emerges that a punishing approach would hardly be acceptable by agents, unless a clear
proof of a deliberate malevolent behavior can be exhibited. Moreover, even in this case
the punishment should be proportional to the amount of discrepancy between declared and
404

fiMechanisms for Fair Allocation Problems

verified values that can be attributed to a malevolent behavior. The resulting setting shares
the spirit of the work by Feige and Tennenholtz (2011), where it is observed that possible
discrepancies between agents declarations and third-party verified values are more often
due to different reasons, in particular to the fact that agents, while not being malevolent,
might still be unable to accurately collect and/or report information about their valuations.
In more detail, Feige and Tennenholtz (2011) considered a scheduling problem on a single
machine where each agent reports the length of her/his job and the scheduler needs to finish
as many jobs as possible by a given deadline. Differently from earlier literature, it is assumed
that agents are uncertain of their own job lengths, for instance, because of their limited
computational resources. Moving from the observation that mechanisms with verification
are often designed in way that performs well when agents have accurate information about
their private features, but might perform arbitrarily bad when agents are uncertain of this
information, Feige and Tennenholtz then proposed the use of the forgiving mechanisms,
where punishments are not used to enforce truthfulness. These mechanisms are applied
over two models of uncertainty: One that is probabilistic in nature, and another (called
qualitative private input) where there is no quantitative model explaining to which extent
the agents can trust their estimate, and the preference of an agent over various lotteries
might be even inconsistent with any probability distribution.
In this paper we follow the work by Feige and Tennenholtz (2011) and in particular their
qualitative model of uncertainty. Moreover, in addition to their subjective perspective of
the problem, where uncertainty is inherent to private inputs, we also take into account the
dual (objective) perspective, where discrepancies between declared and verified values
might due to errors that can occur in the verification process. Indeed, verification can
be practically implemented by sensing some parameters that become observable after the
mechanism is performed, and sensing is clearly affected by errors (it is unrealistic to assume
that it can be carried out with arbitrary precision).
In fact, no matter the perspective (objective vs subjective) from which the problem
discussed above is analyzed, an intrinsic limit of mechanisms with verification has clearly
emerged: Whenever an agent misreports her/his type and this is detected by the verifier,
punishing this agent might be effective in mathematical studies, but very inappropriate
in real life situations in which uncertainty is inherent. Accordingly, we will therefore assume
that only a limited use of the verification power given at hand can be made. In particular,
the goal of the paper is to design mechanisms that are not based on punishments (while
nonetheless resulting to be truthful, efficient, and budget-balanced) and that are tolerant of
measurement errors and uncertain inputs, in the sense that small errors should determine
small deviations from the outcome we would have obtained with no errors at all.
1.1 Mechanisms for Fair Division with Monetary Compensation
We consider mechanisms with verification in the context of fair allocation problems (see,
e.g., Moulin, 2003; Young, 1994; Thomson, 2011). We assume that we are given a set
of indivisible goods to be allocated to a set of agents. Each agent is equipped with a private preference relation, which is encoded as a real-valued function (basically, a monetary
valuation) over all possible goodsformal definitions are in Section 2. An agent can have
allocated more then one good, in which case her/his evaluation is additive over them. More-

405

fiGreco & Scarcello

over, goods are indivisible, i.e., each good can be allocated to one agent at most. However,
monetary transfers are allowed, in terms of both payments charged to agents and monetary
compensations provided to them. The goal is to find an efficient allocation, that is, an allocation maximizing the total value of the allocated goods, by designing rules guaranteeing
that certain desirable properties are achieved, such as truthfulness and individual rationality, i.e., no agent is ever worse off than she/he would have been without participating in the
mechanism. Moreover, we want to obtain outcomes that are politically acceptable. That
is, agents should perceive the designed mechanism as a fair one (see, e.g., Brandt, Conitzer,
& Endriss, 2012), independently of the rules leading them to be honest. For instance, it
is desirable that no agent envies the allocation of any other agent, or that the selected
outcome is Pareto efficient, i.e., there must be no different allocation that is preferred by
all agents and strictly preferred by at least one of them.
The model and, in particular, properties of fair allocations with indivisible objects
and monetary transfers have been studied, e.g., by Svensson (1983), Bevia (1998), Maskin
(1987), Tadenuma and Thomson (1993), Meertens, Potters, and Reijnierse (2002), Tadenuma and Thomson (1991), Alkan, Demange, and Gale (1991), Willson (2003), Su (1999),
Yang (2001), Quinzii (1984), and Sakai (2007). Moreover, procedures to compute fair allocations have been proposed by Aragones (1995), Klijn (2000), Haake, Raith, and Su (2002),
Brams and Kilgour (2001), Potthoff (2002), and Abdulkadiroglu, Sonmez, and Unver (2004).
None of the approaches listed above, however, can guarantee the elicitation of honest
preferences from the agents. In fact, the question of designing truthful and fair mechanisms
has been recently considered as well (Andersson & Svensson, 2008; Andersson, 2009; Svensson, 2009; Yengin, 2012; Ohseto, 2004; Porter, Shoham, & Tennenholtz, 2004; Shioura,
Sun, & Yang, 2006). In these approaches, while budget limits are sometimes enforced and
mechanisms are defined that cannot run into deficit, budget-balance is never guaranteed.
Indeed, this comes again with no surprise, given that no truthful mechanism can be simultaneously fair (e.g., envy-free or Pareto-efficient) and budget-balanced (see, e.g., Tadenuma
& Thomson, 1995; Alcalde & Barbera, 1994; Andersson, Svensson, & Ehlers, 2010).
To circumvent this impossibility, approaches have been studied that focus on weaker
notions of truthfulness. For instance, Andersson et al. (2010) and Pathak (2013) consider
a notion of degree of manipulability which can be used to compare the ease of manipulation in allocation mechanisms, whereas the notion of weak strategy-proofness is considered
by Lindner (2010), i.e., cheating agents are always risking an actual loss, and are never
guaranteed to cheat successfully.
In this paper, we depart from the settings studied in all such earlier approaches, because
we are interested in applications where a form of verification is available to the mechanism
at the time of deciding monetary compensations among agents. In particular, we assume
that valuations as well as allocation scenarios are determined by objective properties of
goods and agents that can be observed and measured by a verifier, after an allocation is
performed and payments are to be computed. Note that only information on allocated
goods can be verified and hence used by the mechanism. In this framework, classical
impossibility results no longer hold. Indeed, we propose mechanisms for allocation problems
that enjoy a number of highly desirable properties, being in particular truthful, efficient,
budget-balanced, individually rational, and fair, even though agents with verified incorrect
declarations are not punished. Observe that having this kind of a-posteriori knowledge
406

fiMechanisms for Fair Allocation Problems

at payment time is quite common to many applications. We also point out that in some
cases a thorough verification could also be performed in advance, in order to get the best
performances independently of agents declarations. However, in practice this is not done
because of either money or time restrictions, so that it is more convenient to allocate goods
on the basis of agents declarations (especially if a mechanism makes them honest enough).
Anyway, our results can be used even when the full information is known to the mechanism,
to provide a fair division enjoying a number of desirable properties listed below.
Appendix A reports a number of examples of possible applications of the proposed
framework, including the real-world case of the Italian research-assessment program, which
first motivated this work.
For completeness, we leave the section by recalling that our work, as well as the above
mentioned related literature, deals with a setting where monetary transfers are allowed. In
fact, fair division of indivisible goods without money transfers has also attracted attention
in the literature. For instance, this topic has been studied by Bouveret and Lang (2008)
from the points of view of compact representation (for expressing preference relations)
and computational complexity (of reasoning about efficiency and fairness concepts in the
resulting framework), and by Lipton, Markakis, Mossel, and Saberi (2004) from the point of
view of defining approximation schemes for envy-freeness. Finally, it is relevant to point out
that, in our paper and in the papers discussed above, allocations are assumed to be computed
in a centralized way. However, it might be relevant in some cases to adopt decentralized
approaches, based on successive negotiations of goods (and of money) between groups of
agents. The reader interested in distributed negotiation frameworks is referred to the work
by Sandholm (1998), Dunne, Wooldridge, and Laurence (2005), Dunne (2005), and Endriss,
Maudet, Sadri, and Toni (2006), and to the references therein.
1.2 Contributions
In this paper, we study allocation problems in a strategic setting where agents can misreport
their private types, and we study mechanisms with verification from both the algorithmic
and the computational complexity viewpoint.
1.2.1 Algorithmic Issues
We show that in the given setting none of the classical impossibility theorems discussed
above holds. In particular, we exhibit a payment rule p that turns any optimal allocation
algorithm, i.e., any algorithm computing an optimal allocation given the reported types,
into a mechanism with verification such that:
I The mechanism is truthful. This is shown by pointing out a number of properties of
allocation problems which are of interest on their own.
I The mechanism is efficient, budget-balanced, individually rational, envy-free, and Pareto
efficient.
I The payment rule is indifferent w.r.t. the values (possibly misreports) declared for goods
that do not occur in the allocation being selected (and hence that are not verified).

407

fiGreco & Scarcello

I For each agent, her/his utility (when truthtelling) is the maximum one over all possible
allocations. In particular, the utility is indifferent w.r.t. the specific choice of allocated
goods in optimal allocations. Note that this is a strong fairness property, which immediately entails envy-freeness and Pareto-efficiency.
I Verification is not used to force truthfulness by just punishing those agents whose reported values are found different from the verified ones, so that the mechanism is forgiving in the sense recently discussed by Feige and Tennenholtz (2011). Moreover, the
mechanism is shown to be tolerant of discrepancies emerging between declared types and
verified/true ones. That is, all its properties hold at the equilibrium where all agents
report their true types, and are also preserved approximatively in case of discrepancies,
with a guarantee that is within a constant factor from the distance between declared
types and verified/true ones. Note that this is generally not possible in mechanisms
based on punishment approaches where, to enforce truthfulness, the punishment might
be disproportional to the harm done by misreporting (cf. Feige & Tennenholtz, 2011).
I Agents utilities are distributed according to the Shapley value of two suitably-associated
coalitional gamessee, e.g., (Nisan et al., 2007), for a comprehensive introduction to
sharing problems and coalitional games. In fact, the Shapley value is a prototypical
solution concept for fair division with monetary compensations,1 and its desirable properties in (games associated with) allocation problems have been extensively studied in
the literature (e.g., Moulin, 1992; Maniquet, 2003; Mishra & Rangarajan, 2007).
Note that the Shapely value has been studied in mechanism-design contexts too, where
emphasis has been given to the pricing problem for a service provider (Moulin & Shenker,
2001; Moulin, 1999; Jain & Vazirani, 2001): The cost of providing a service is a function
of the sets of customers, and the goal is that of determining which customers (and at
what price) have to receive it. The model gives rise to a cross-monotonic cost-sharing
game, where Shapley-value based sharing mechanisms can be defined that are truthful and
budget-balanced, and which achieve the lowest worst-case loss of efficiency over all utility
profiles (Moulin & Shenker, 2001). With this respect, our pricing rule p can abstractly be
viewed as a witness that, whenever (partial) verification is possible, Shapley-valued based
mechanisms may also be implemented with no loss of efficiency at all.
1.2.2 Complexity Issues
Computing an optimal allocation on the basis of the reported types is an easy task, which
can be carried out via adaptations of classical matching algorithms. However, one might
suspect that computing payments is not computationally-efficient, as it is based on the
computation of a Shapley value. This is indeed a challenging task that involves iterating
over all possible subsets of agents. We analyze these issues, and we provide the following
contributions:
I We show that computing the Shapley value for allocation problems is inherently intractable, in fact, #P-complete. Note that #P-hardness results for problems involving
1. Depending on the application, solutions concepts different from the Shapley value might be more appropriate. For instance, in bankruptcy problems, the nucleolus is considered as the most appropriate
solution concept for fair distribution (Aumann & Maschler, 1985).

408

fiMechanisms for Fair Allocation Problems

Shapley value computation have been proven in the literature, for instance, for weighted
voting games (Deng & Papadimitriou, 1994), minimum spanning-tree games (Nagamochi, Zeng, Kabutoya, & Ibaraki, 1997), and games associated with normative systems (Agotnes, van der Hoek, Tennenholtz, & Wooldridge, 2009). Moreover, #Phardness results have been established for the Banzhaf power index, which is a solution
concept closely related to the Shapley value (see, e.g., Bachrach & Rosenschein, 2009,
2008; Bachrach, Zuckerman, Wooldridge, & Rosenschein, 2013).
I Therefore, in order to deal also with scenarios involving a large number of agents, two
modified rules, p and p , are presented, which allow us to employ a fully polynomialtime randomized approximation scheme for the Shapley value computation. The resulting polynomial-time mechanisms retain most of the properties of p . In particular,
the mechanism based on p is universally truthful, efficient, and with high-probability
approximately budget-balanced. Instead, the mechanism based on p is truthful in expectation, but it is always efficient and budget-balanced.
1.2.3 Organization
The rest of the paper is organized as follows. Section 2 illustrates the formal framework and
the basic concepts to design mechanisms with verification, whose desirable properties are
illustrated in Section 3. The payment rule p is defined in Section 4, and its connections
with coalitional games are pointed out in Section 5. Rules p and p are defined in Section 6,
where computational issues are dealt with. A comparison with related works is reported in
Section 7, and a few concluding remarks are discussed in Section 8. Finally, Appendix A
illustrates a real-world case study and further application examples of the notions presented
in the paper.

2. Formal Framework
In this section, we define a formal framework for studying allocation problems based on
mechanism design tools. In particular, we focus on mechanisms equipped with a verification
ability that meets the no-punishment perspective.
2.1 Allocation Scenarios
We focus on allocation problems where goods from a set G have to be allocated to a set of
agents A = {1, ..., n} in such a way that the overall value of the allocated goods is maximum
over all feasible allocations, that is, the social welfare is maximized. More precisely, an
allocation is a function  : A  2G mapping each agent i  A into a non-empty set of
goods (i)  G such that (i)  (j) = , for each j 6= i. Moreover, we are given a vector
of upper-bound constraints  = (1 , ..., n ) that specifies the maximum number of goods i
that can be assigned to any agent i  A. The tuple S = hA, G, i is called an allocation
scenario. A mapping  : A  2G is a feasible allocation for the scenario S if it is an
allocation of goods in G to agents in A such that, for each agent i  A, |(i)|  i holds.
Observe that it is not required that all goods from G are allocated to the agents.
Note that in most applications the maximum number of goods i that can be assigned
to agent i represents some ability of i (e.g., the maximum number of tasks that she/he
409

fiGreco & Scarcello

can execute), hence we next represent it as a function i = fu (i ), where i is an objective
property of the agent (e.g., her/his speed) and fu is a public-knowledge computable function.
Note that the setting is more general than earlier approaches in the literature for which
upper bounds are fixed and independent of agents features.
Moreover, in this paper we assume that the value of each good g for agent i is determined
by some objective property g of the good, as well as by the property i of the agent.
Formally, we assume that good valuations are encoded by a valuation vector w = (w1 , ..., wn )
where, for each i  A, is valuation function assigns to any good g  G a real value
wi (g) = fv (g , i ), for some public-knowledge computable function fv .2
The idea is that a verifier, best described in the next section, should be able to measure,
after an allocation  of goods to agents has been performed, the objective property g
of every allocated good g and the objective property i of every agent. Therefore, by
using the (public) function fv , it is then possible to compute the values of all those goods
that have been assigned to some agent. We believe that this assumption about valuations
as functions of objective properties of goods and agents holds for many applications of
allocation problems, in particular for those where the social welfare is to be maximized
(since this is typically a measurable value). We provide some examples in Appendix A,
including the real-world application about the evaluation of the research activities in Italy,
which originally motivated the present work.
Let us fix an allocation scenario S = hA,
PG, i and a valuation vector w = (w1 , ..., wn ).
Let  be an allocation. Define
wi () =
g(i) wi (g), for each i  A, and denote by
P
val(, w) the overall value iA wi (). We say that  is optimal (for S) w.r.t. w if it is a
feasible allocation for S and there is no feasible allocation  0 for S such that val( 0 , w) >
val(, w). The value of an optimal allocation for S w.r.t. w is denoted by opt(S, w).
An allocation algorithm is a function A mapping each allocation scenario S and each
vector w to a feasible allocation A(S, w) for S. The algorithm is optimal if A(S, w) is an
optimal allocation w.r.t. w, for any given pair (S, w).
2.2 Strategic Issues and Verification
We consider a classical setting for mechanism design where optimal allocations have to be
computed in a context where neither the agent-depending upper bounds  nor the valuation
vector w is known to the allocation algorithm. Therefore, even having an optimal algorithm
A at hand, we do not have enough information to find an optimal allocation, in general.
In fact, we assume as usual that each agent i  A privately knows certain features,
called is type, determining both the maximum number of goods i that can be allocated to
her/him, as well as the function wi encoding her/his preferences over the allocations. Note
that, in our setting, the type of agent i naturally consists of her/his characterizing property
i plus the property g , for any good g (s)he is interested in. In Section 3.2, we also consider
what happens when agent i may have a subjective, possibly incorrect, perception of such
properties (including her/his characterizing property i ).
2. Note that, for the sake of simplicity, we use two functions fu and fv for all agents. However, nothing
changes in the paper if we consider a slightly more general version where different agents may have
different public functions.

410

fiMechanisms for Fair Allocation Problems

Figure 1: Running example in Section 2.
We assume that the type of agent i is taken from a set i of available types, and we
denote by  the cartesian product 1      n of all possible agents types. Then, we
consider direct revelation mechanisms where agents are asked to report such types to let the
mechanism compute an allocation. While doing so, agents are self-interested, and strategic
issues come into play.
For each agent i  A, we hereinafter assume that ti  i always denotes the true type
of agent i, i.e., the type owned as private knowledge, and that di  i is her/his declared
type. Then, t = (t1 , ..., tn ) and d = (d1 , ..., dn ) are the vectors of true and declared types,
respectively. In general, it can happen that d does not coincide with t, if agents find
convenient to misreport their types.
For any (true or declared) type vector  = (1 , ..., n )  , we denote hereinafter
by S = hA, G,   i the allocation scenario for , that is, the scenario where the vector
  = (1 , ..., n ) is such that, for each i  A, i is the upper bound determined by is
type i . Similarly, we denote by w = (w1 , ..., wn ) the valuation vector such that wi is the
valuation function determined by is type i , for each i  A.
Example 2.1. Let us consider two agents, a1 and a2 , the type vector t = (t1 , t2 ), and
the allocation scenario St = hA, G,  t i illustrated in Figure 1(I) by means of an intuitive
graphical notation, with A = {a1 , a2 }, G = {g1 , ..., g8 }, and  t = (3, 3). Moreover, consider
the valuation vector w with wt = (wa1 , wa2 ) such that, if there is an edge connecting
a1 (resp., a2 ) with gj in Figure 1(I), then wa1 (gj ) (resp., wa2 (gj )) is the value associated
with it. Otherwise, i.e., if there is no edge connecting a1 (resp., a2 ) with gj , then wa1 (gj )
(resp., wa2 (gj )) is some negative number, say 1. Given this setting, it is easily seen that
an optimal allocation for St w.r.t. wt is the allocation   where   (a1 ) = {g1 , g2 , g4 } and
  (a2 ) = {g5 , g7 , g8 }see Figure 1(II). Note that wa1 (  ) = 25 and wa2 (  ) = 26.
Consider now the allocation   of Figure 1(III). Note that   is another optimal allocation. However, we have wa1 (  ) = 26 > wa1 (  ) and wa2 (  ) = 25 < wa2 (  ).


411

fiGreco & Scarcello

Figure 2: Strategic manipulation.
Example 2.2. Consider again the setting of Example 2.1, where the type vector t is private
knowledge of the agents. Moreover, assume that the vector d of declared types is such that
Sd = St (the allocation scenario is the correct one) and that the vector wd is the one
illustrated in Figure 2(I), where negative edges are omitted. Basically, agent a2 truthfully
reports her/his type, while agent a1 reports a type for which the values of the goods g2
and g3 are underestimated. Therefore, wd 6= wt holds. The only optimal allocation   for
Sd w.r.t. wd is shown in Figure 2(II). It emerges that, because of the declarations of agent
a1 , it is not convenient to include g2 and g3 in   . In fact,   coincides with the optimal
allocation   depicted in Figure 1(III). Hence, by misreporting the type, agent a1 has now
the guarantee that the overall value of the goods assigned to her/him is 26. Instead, by
truthfully reporting the type, a1 might risk that the allocation   is selected, where the
overall value of the goods assigned to her/him is only 25.
Finally, consider a slight variant of the problem instance where the actual value of good
g7 is 6 (instead of 8) for a2 . Then, the above egoistic behavior of agent a1 also leads to an
allocation that is no longer optimal. Indeed, due to the low declared values for g2 and g3 ,
the good g7 is selected and allocated to a2 in the unique (wrong) optimal allocation, whose
total value is now 49 (instead of 51).

In this paper, we focus on allocation problems where some kind of verification on reported types is possible, because objective properties of agents and goods can be observed
and measured (we say verified, hereinafter) by a third-party verifier after an allocation  is
performed. Recall that
Sin general only a subset of goods is actually assigned to some agent
by . Denote the set iA (i)  G of allocated goods by img(). Thus, in our model, for
each good g  img(), its objective property g can be verified, while nothing can be said
for non-allocated and hence non-observed goods. Moreover, for each agent i  A participating in the mechanism, is property i that determines the upper-bound constraint and
is preferences over good allocations is verifiable, too. Thus, by using such a verifier, the
correct allocation scenario and a restriction over img() of the valuation functions can be
determined, as formalized next.
Definition 2.3. Let t be the vector of true types. Then, the verifier v (for t) is the function
mapping any allocation  to the pair Sv() , wv() such that:
(1) Sv() is the actual allocation scenario St (in particular, the true upper bound fu (i )
is computed by the verifier for each agent i); and
(2) wv() = (wv1 , ..., wvn ) is the vector such that, for each agent i  A, wvi : img()  R
is the function assigning to each good g  img() its actual value fv (g , i ) for agent
412

fiMechanisms for Fair Allocation Problems

i. Observe that, by definition of the framework, wvi coincides with the restriction over
img() of the valuation function wti : G  R determined by is (true) type ti .
2
It is worthwhile noting that the verifier is in general unable to discover whether some
agent misreported her/his type, because goods that are not allocated do not undergo any
measurement process. We pinpoint that this is actually the case in practical applications,
where measurements over non-allocated goods may be technically unfeasible or simply too
expensive (in money or time). We refer the reader to Appendix A.1 (in particular, subsections A.1.1A.1.3) for an exemplification of these notions in the real-world case study of the
Italian research evaluation (VQR).
Example 2.4. Consider again the setting of Example 2.2, and recall that agent a1 finds it
convenient to underestimate the true values of g2 and g3 . However, since g2 and g3 are not
selected in   , as we can see in Figure 2(II), then there is no way to discover that a1 has
actually misreported her/his type.

In some cases, the constraints in the allocation scenario depend only on the specific
application and not on agents types, so that item (1) above is immaterial. More generally,
however, the proposed setting allows us to model classes of problems where types play a
role even in the definitions of upper-bound constraints.
For completeness, we remark that all results in the paper can easily be shown to hold
even for allocation problems where every agent must get a minimum number of goods
greater than one (defined by the specific application). However, for the sake of presentation
we prefer to keep the standard setting where any non-empty set of goods can be assigned
to each agent, as long as her/his upper bound constraint is met.
2.3 Payment Rules and Mechanisms with Verification
In order to encourage agents to truthfully report their private types, we design mechanisms
where monetary transfers can be performed, after the verification process.
For the sake of presentation, let us assume that St = hA, G,  t i is an allocation scenario
(recall that t denotes the vector of true types), that d is a vector of declared types with an
associated allocation scenario Sd = hA, G,  d i, and that v is the verifier (for t).
A payment rule p is defined as a vector of functions (p1 , ..., pn ), with pi (, wd , v) being
some amount of money that is given to agent i, on the basis of a given allocation , the
vector of declared valuations wd , and the verifier v. Observe that, with this notation, any
negative value pi (, wd , v) means that some amount of money is charged to i. Let wt be
the vector (w1 , ..., wn ). Then, is (quasi-linear) utility under p, sometimes called individual
welfare, is defined as the value ui,p (, wd , v) = wi () + pi (, wd , v). As the verifier v for t
is always understood, ui,p (, wd , v) and pi (, wd , v) are simply denoted by ui,p (, wd ) and
pi (, wd ), respectively. Moreover, whenever the payment rule is also understood from the
context, is utility is simply denoted as ui (, wd ).
As payments can be computed after the verification process, to define the amount of
money pi (, wd ) to be paid to agent i, we exploit the verifier v. Accordingly, it is desirable
that goods that are not allocated, and hence not verified, play no role in the definition of
the payments. This latter property is formalized below.

413

fiGreco & Scarcello

 verifiability: Let d0 and d00 be two type vectors, and let wd0 = (w10 , ..., wn0 ) and wd00 =
(w100 , ..., wn00 ) be their associated valuations. Moreover, let  be any mapping that is a
feasible allocation for both scenarios Sd0 and Sd00 . Then, for each i  A, pi (, wd0 ) =
pi (, wd00 ) whenever wi0 (g) = wi00 (g) holds for every allocated good g  img(). Therefore,
d0 and d00 are undistinguishable as far as the computation of the payments is concerned,
even if they differ on some unallocated goods. That is, the payment rule depends only
on goods subject to the verifier evaluation.
A mechanism with verification is a pair (A, p), where A is an allocation algorithm and
p is a payment rule that can exploit the verifier v. The mechanism (A, p) can be viewed
as consisting of the following two-phases: First, agents report a declaration vector d, and
a feasible allocation  = A(wd ) for Sd is computed. Second, v() is made available, and
payments under a given rule p are calculated with respect to the allocation  and the
valuations wd , by exploiting the knowledge of v(). Our goal is to design a payment rule p
guaranteeing that declared types in d lead to an allocation  maximizing the social welfare,
i.e., such that  is an optimal allocation for St w.r.t. wt . This might be problematic as, in
our setting, even the fact that  is a feasible allocation for St is not guaranteed, because
the allocation scenario depends on the types of the agents and we might have St 6= Sd .
In order to accomplish the above goal, we use an optimal allocation algorithm A, and
we need that p encourages agents to truthfully report their private types. Formally, for any
type vector  = (1 , ..., n )   and for any type i  i , with i  A, let (i , i ) be the
type vector (1 , ..., i1 , i , i+1 , ..., n )  . Then, we shall consider the following concept
of truthful mechanism.
Definition 2.5. Let (A, p) be a mechanism with verification, and let i be any agent in A.
We say that i is a dominant strategy of agent i w.r.t. (A, p) if, for each type vector   ,
ui (A(w(i ,i ) ), w(i ,i ) )  ui (A(w ), w ) holds. The mechanism (A, p) is truthful if, for
each i  A, ti is a dominant strategy.
2
Example 2.6. Consider again the setting discussed in Example 2.2, and the trivial payment
rule p where no payment is actually performed. Consider again the optimal allocation  
(for St w.r.t. wt ) depicted in Figure 1(II), and note that ua1 (  , wt ) = 25. Instead, for the
allocation   depicted in Figure 2(II), we have ua1 (  , wt ) = 26, with   being the unique
optimal allocation for Sd = St w.r.t. wd , where d = (da1 , ta1 ).
Therefore, any mechanism (A, p ), with A being an optimal allocation algorithm such
that A(wt ) =   , is not truthful. More generally, for each optimal allocation algorithm A,
an example witnessing that (A, p ) is not truthful can be easily defined by suitably adapting
the above. Hence, non-trivial payment rules are necessary to encourage agents to truthfully
report their types.

A comparison of our approach to verification with existing ones is reported in Section 7.

3. Properties of (Truthful) Mechanisms
In this section, we discuss desiderata for mechanisms that lead to fair allocations and that
are tolerant of uncertain inputs. Note that the design of mechanisms that are able to
deal with these two issues is of interest even in settings that are not strategic, i.e., even
414

fiMechanisms for Fair Allocation Problems

when we are granted that all agents truthfully report their types. Exemplifications of the
proposed notions are reported Appendix A.1.4, which completes the description of the case
study regarding the Italian research evaluation (VQR). Further examples are described in
Appendix A.2 and Appendix A.3.
3.1 Fairness Issues and Further Desirable Properties
Let (A, p) be any truthful mechanism with verification. In the paper, we focus on a number
of (ex-post) properties of such a mechanism, to be checked at the equilibrium t where agents
truthfully report their private types.
 (allocative) efficiency: A(wt ) is an optimal allocation for St w.r.t. wt . That is, the social
welfare is maximized.
 individual rationality: ui (A(w(ti ,i ) ), w(ti ,i ) )  0, for each agent i  A and for each
type vector i for the agents in A \ {i}. Hence, voluntary participation of each agent to
take part in the allocation problem is encouraged (independently of whether the other
agents actually report their true types or not).
P
 (strong) budget-balance: iA pi (A(wt ), wt ) = 0. In other words, there is no transfer of
money out or into the scenario.
 envy-freeness: for each pair of agents i, j  A, and for each feasible allocation  for St
such that (i)  A(wt )(j) 6= , ui (A(wt ), wt )  ui (, wt ).
 Pareto-efficiency: there is no feasible allocation  for St such that: (1) ui (, wt ) 
ui (A(wt ), wt ), for each agent i  A, and (2) there is an agent j  A with uj (, wt ) >
uj (A(wt ), wt ). That is, A(wt ) is not Pareto-dominated by any other allocation.
 equal treatment of equals: for each pair of agents i, j  A such that i = j and wi = wj ,
with wt = (w1 , ..., wn ), it must be the case that ui (A(wt ), wt ) = uj (A(wt ), wt ).
 individual optimality: ui (A(wt ), wt )  ui (, wt ), for each i  A and each feasible allocation  for St .
Note that all the above properties make sense even in settings that are not strategic,
but where the goal is to compute a fair allocation. Indeed, in a setting that is not strategic,
agents report their true types, even without any monetary incentive. However, without such
payments, fairness cannot be achieved in general: just think, for instance, about a scenario
with two agents, a1 and a2 , and one good g having the same value for both agents. In this
case, no matter which optimal allocation is considered (where g is assigned to either a1 or
a2 ), one of the two agents would envy the other. This makes it clear that payment rules
play not only the role to encourage agents to reports their true types, but they are also
crucial to induce agents to perceive a given allocation as a fair one. In fact, all the above
properties, but the last, have been classically considered in the context of fair allocation
problems, also in absence of strategic issues.
Here, we have additionally considered individual optimality, which is readily seen to
imply both envy-freeness and Pareto-efficiency. It also entails that there is a unique possible
415

fiGreco & Scarcello

vector of utilities for agents. In particular, this means that agents utilities are not sensible
to possible alternative allocations, and hence are independent of the specific set of allocated
goods selected by the optimal algorithm A.
Example 3.1. Consider the trivial payment rule p discussed in Example 2.6. Consider
the optimal allocation   depicted in Figure 1(II), and compare it with the allocation  
of Figure 1(III). Recall that   is another optimal allocation (for St w.r.t. wt ). Moreover,
under p , ua1 (  , wt ) = 25 and ua1 (  , wt ) = 26 hold. Therefore, while from the optimization perspective the choice between   and   is immaterial, a1 might have good arguments
to complain if   is selected in place of   . In fact, p is not individually optimal.

Individual optimality is definitely a very desirable requirement, but we still miss something. Indeed, notice that this property is trivially satisfied by the fully uniform payment
rule, which guarantees that each agent gets the same utility, no matter of her/his valuation
of goods. Of course, this is not desirable in general. Rather, meritocracy should be somehow
addressed, so that a true fair rule should reflect the actual contribution of each agent to
the overall value of the allocation.
Let  be an allocation for St , not necessarily an optimal one w.r.t. wt , and define the
marginal contribution of a non-empty set C  A of agents to  w.r.t. wt as the value:
marg,wt (C) = opt(hA, img(),  t i, wt )  opt(hA \ C, img(),  t i, wt ).

(1)

In words, the marginal contribution marg,wt (C) of the agents in C assesses the loss of
the overall value of  we would register if the agents in C were not part of the problem.
Example 3.2. Consider the setting of Example 2.1 and the optimal allocation   of Figure 1(II). Note that marg ,wt ({a1 }) = marg ,wt ({a2 }) = 51  26 = 25. Therefore, the two
agents (viewed as singletons) have the same marginal contribution, and defining a payment
rule that leads to utilities equally sharing the overall value of 51 is a natural option.
Consider now a different setting, where true types induce the same allocation scenario
St and the same vector wt , but for the valuation of good g8 for agent a2 , which is now
110 instead of 10. In this case,   would still remain an optimal allocation, with overall
value 151. Moreover, the marginal contribution of a1 is not affected by the modification,
while the marginal contribution of a2 would become 151  26 = 125. This witnesses that a2
contributes more than a1 , and a payment rule leading to equally sharing the overall value
can be no longer perceived as a fair one.

The intuition conveyed by the above example can be then formalized via the following
requirement.
P
 marginality: For each non-empty set C  A of agents,
iC ui (A(wt ), wt ) 
margA(wt ),wt (C). Hence, each group of agents gets at least its own marginal contribution
to the given allocation.
3.2 Sensing and Errors
We conclude the presentation of our (strategic) setting for fair allocation problems by illustrating some subtle issues arising with the process of verification. The starting point of our
416

fiMechanisms for Fair Allocation Problems

discussion is the observation that verifiers can be practically implemented by sensing some
parameters (in our setting the parameters i , for each agent i, and g , for each allocated
good g) that become observable after the allocation is performed and that, in real-world
applications, sensing is subject to errors; for instance, because of the limited precision of
the measurement instruments. Therefore, it is unrealistic to assume that the verifier is
always able to exactly discover (i.e., with arbitrary precision) the actual upper bounds in
the scenario St and the valuation vector wt , and it might be problematic to decide whether
an observed discrepancy between verified values and declared ones is due to a strategic
behavior or to such sensing errors. In fact, sensing troubles arise even in settings where all
relevant information is available as public knowledge that can be acquired via sensing the
environment, i.e., even by getting rid of any strategic consideration.
As discussed in the Introduction, this issue has been pointed out in the recent work by
Feige and Tennenholtz (2011), though from a slightly different perspective. There, it is observed that mechanisms with verification are often designed in way that performs well when
agents have accurate information about their private inputs, but might perform arbitrarily
bad when agents are uncertain of their private features. Uncertainty might be again the
result of hardware measurement errors, or due to the limited computational resources
employed by agents for identifying the declared valuations. For instance, in our setting, the
type of an agent i consists of her/his characterizing property i plus the property g , for
each good g (s)he is interested in. According to the perspective of Feige and Tennenholtz
(2011), agent i might only have an estimate of this type. For instance, the agent might
not have enough computational resources to precisely determine such properties g for all
goods g, so that is type actually represent just a subjective perception of them.
In the light of the above observations, it clearly emerges that punishing agents might
be effective in mathematical studies, but very inappropriate in real life situations in which
uncertainty is inherent due to measurements errors or uncertain inputs. Therefore, in addition to the requirements discussed so far, another desirable property is for the mechanism
to use no punishment (or to be forgiving, in the sense of Feige & Tennenholtz, 2011).
 no punishment: For each type vector   , for each feasible allocation  for S , and for
each agent i  A, it is the case that pi (, w ) = pi (, w(ti ,i ) ). That is, discrepancies
between the given type (possibly declared) and the true/verified one do not have any
impact on the payment to agent i. In other words, we may think of payments being
always computed under the presumption of innocence, where incorrect declared values
do not mean manipulation attempts by the agents.
Moreover, if we admit that sensing errors (or uncertain inputs) might occur, then it
is relevant to quantitatively assess their impact, too. Ideally, we would like to deal with
mechanisms that can tolerate such errors, in the sense that small errors should determine
small deviations from the outcome we would have obtained with no errors at all. Note
that this is generally not possible in mechanisms based on punishment approaches where,
to enforce truthfulness, the punishment might be disproportional to the harm done by
misreporting (cf. Feige & Tennenholtz, 2011). We next formalize our final desideratum.
For any type vector , for any set C  A of agents, and for any set G0  G of goods,
let us define hC, G0 ,   i as the restriction of the scenario hA, G,   i where only agents in C
417

fiGreco & Scarcello

and goods in G0 are considered.3 Moreover, given two type vectors  and , we denote by
[, ] the set of all type vectors of the form (X1 , ..., Xn ), where Xi  {i , i }, for each
i  A. Then, the distance dist w (, ) between  and  under the valuation vector w
(or just dist(, ), if w is understood from the context) is defined by looking at the worst
possible impact that type vectors in [, ] may have on the optimal solutions computed
over all possible restrictions of the given setting:
dist w (, ) =

max

CA, G0 G,  0 , 00 [,]

|opt(hC, G0 ,  0 i, w0 )  opt(hC, G0 ,  00 i, w00 )|.

Now, recall that in a truthful mechanism it is always convenient for the agents to report
the true types. Assume however that agents declare a type vector t different from their
true type vector t.4 As a consequence, we get a revealed setting St and a valuation vector
wt = (w1 , ..., wn ), while the available verifier v discloses information about the scenario St
and the vector wt = (w1 , ..., wn ) (restricted to allocated goods). In standard mechanisms
design settings (and in particular under punishment approaches), no guarantee on any
property could be given in this case, as mechanisms are designed to be analyzed when
reports are truthful. Instead, we would like here that mechanisms are tolerant of sensing
errors, as formalized below.
 error tolerance: There is a constant c  0 such that, for each type vector t and for each
agent i  A, |ui (A(wt ), wt )  ui (A(wt ), wt )|  c  dist(t, t).
Intuitively, under an error tolerant mechanism, the consequences of errors over good
allocation outcomes produce a linear distorting effect over agents utilities (and, in turn
on the various properties of the mechanism). In particular, the above property is stated
without any assumption about how sensing errors come into play. Indeed, the notion of
dist(t, t) formalizes these errors from a global perspective. For instance, we do not require
that errors affect uniformly the valuations of agents, and it might be well the case that
errors are biased towards some specific agent.

4. Mechanisms with Verification for Allocation Problems
In this section, we introduce a mechanism with verification for allocation problems and start
its analysis, by preliminary proving some properties that hold over optimal allocations.
4.1 General Properties of Allocation Problems
Let    be any given type vector, and consider the allocation scenario S = hA, G,   i,
where   = (1 , ..., n ), together with the valuations given by w = (w1 , ..., wn ). We start
3. Note the little abuse of notation: the vector  in hC, G0 , i should be in fact its restriction over C. However,
to keep the notation simple, we just write , as no confusion may arise. Similarly, any valuation vector
w for A will be transparently considered as a valuation vector for any subset of agents C  Awe just
get rid of the unused components associated with agents in A \ C.
4. The property is discussed from the perspective of uncertain inputs. The adaptation to the case of
verification errors (or to the case when both types of errors occur) is an easy task, as it is mainly a
matter of different interpretation of concepts.

418

fiMechanisms for Fair Allocation Problems

Figure 3: One-good version of the allocation problem in Example 4.1, with two allocations
and their associated update graph, as defined in the proof of Theorem 4.4. In the
graphical representation, crossing lines represent the edges of the bipartite cliques
connecting the two groups of virtual agents with the goods they are interested in.

by observing that the optimization problem used to allocate goods to agents can be equivalently reformulated in such a way that precisely one good can be allocated to each agent.
Intuitively, we may replace each agent i by i fresh agents with the same valuations as i.
We remark that such an equivalence is just used for combinatorial optimization purposes,
i.e., without affecting any game theoretic issue.
Let us now formalize the above intuition. First, we denote by S1 the one-good version
hA1 , G, 1i of the scenario S , where:
S
 A1 is the set of agents iA clones(i) such that for each agent i  A, clones(i) is a
set of i fresh agents;
 1 is the vector where all components are 1.
Moreover, we denote by w1 the vector for agents in A1 where, for each agent c  A1 ,
the component wc1 associated with c is such that wc1 = wi , with i being the agent in A
for which c  clones(i) holds. Thus, in the allocation problem S1 and by considering the
vector w1 , each clone c  clones(i) gets exactly one good, and has the same valuations
as agent i in w .
Example 4.1. Consider the scenario St = hA, {g1 , ..., g8 },  t i, with A = {a1 , a2 }, and the
vector wt = (wa1 , wa2 ) discussed in Example 2.1. The one-good version is the scenario
St1 = hA1 , {g1 , ..., g8 }, 1i shown Figure 3(I). Note that the set of agents in this scenario
is A1 = {(a1 )1 , (a1 )2 , (a1 )3 , (a2 )1 , (a2 )2 , (a2 )3 }, where clones(ai ) = {(ai )1 , (ai )2 , (ai )3 }, for
1
each i  {1, 2}. Indeed, recall that  t = (3, 3). Finally, the vector wt1 is such that w(a
=
1 )h
1

wa1 (resp., w(a2 )h = wa2 ), for each h  {1, 2, 3}.
419

fiGreco & Scarcello

Now, consider the scenario hC, G0 ,   i, i.e., the restriction of hA, G,   i where only agents
in C and goods in G0 are considered, and let C1 be an allocation for S
its one-good version
0
0
1
G
hC, G ,   i . Consider the function C : C  2 such that C (i) = cclones(i) C1 (c), for
each i  A. Note that |C (i)|  i , for each i  A. Therefore, C is a feasible allocation for
hC, G0 ,   i, denoted by -good(C1 ). Moreover, by construction, val(C , w ) = val(C1 , w1 ).
Conversely, any feasible allocation C for hC, G0 ,   i is associated with the non-empty set
one-good(C ) of all those allocations C1 for hC, G0 ,   i1 such that C = -good(C1 ), also
called the one-good forms of C . The following is immediate by definition of one-good
version and forms.
Fact 4.2. Let    be any given type vector, let S1 be the one-good version of S , and let
C1 be an allocation for S1 . Then, C1 is an optimal allocation for S1 w.r.t. w1 if, and only
if, -good(C1 ) is an optimal allocation for S w.r.t. w .
Example 4.3. Consider again the setting of Example 4.1, and the allocation  such that
(a1 ) = {g1 , g2 , g3 } and (a2 ) = {g5 , g7 , g8 }. Note that  is not an optimal allocation
w.r.t. the valuation vector wt (reported in Figure 1(I)), because val(, wt ) = 50 while
opt(St , wt ) = 51 (see, e.g., the optimal allocation   in Figure 1(II)). Now, notice that the
allocation depicted in Figure 3(II) is indeed an associated one-good form allocation, which
is actually not an optimal allocation for St1 w.r.t. wt1 , by Fact 4.2.

We are now in the position of stating a property that holds on any optimal allocation .
The property is in fact of interest of its own, i.e., independently of its application to the
study of fair allocation problems. In words, it tells us that, whenever we are interested
in allocating goods to any subset of agents, we may safely consider only goods in img(),
rather than the whole set G. In our case, it is a basic technical ingredient for showing a
number of key properties because, intuitively, it allows us to get rid of alternative (optimal)
allocations, possibly based on non-allocated goods in G \ img().
Theorem 4.4. Let    be any given type vector, let  be an optimal allocation for
hA, G,   i w.r.t. w , and let C  A be a set of agents. Then, every optimal allocation for
hC, img(),   i w.r.t. w is an optimal allocation for hC, G,   i w.r.t. w .
Proof. Let C  A be any set of agents, and assume that C is an optimal allocation for
hC, img(),   i w.r.t. w . We shall show that C is an optimal allocation for the unrestricted
problem hC, G,   i w.r.t. w , too.
To this end, consider any optimal allocation C for the problem hC, G,   i where all
goods in G are available to the agents in C. We next prove that val(C , w ) = val(C , w ).
This clearly follows from the optimality of C if img(C )  img() holds. Therefore, to
be strictly better than C , C must allocate some good in G \ img(). Assume thus by
contradiction that val(C , w ) < val(C , w ), and hence img(C ) 6 img(), which entails
that img()  G. Consider two allocations C1  one-good(C ) and 1C  one-good(C ), and
observe first that: val(C1 , w1 ) = val(C , w ) < val(C , w ) = val(1C , w1 ).
Let L be the set of agents whose good-assignment are the same according to these
allocations, i.e., L = {c  C 1 | 1C (c) = C1 (c)}. Then, define (C1 , 1C ) = (C 1 \ L  {s, t}, E)
to be the directed graph, called update graph for C1 w.r.t. 1C , whose nodes are the agents
in C 1 that change their goods in the two allocations plus two distinguished nodes s and t,
and whose edges in E are defined as follows:
420

fiMechanisms for Fair Allocation Problems

 There is an edge from agent c to agent c0 if 1C (c0 ) = C1 (c) 6= ;
 There is an edge from s to agent c0 if there is no agent c such that 1C (c0 ) = C1 (c) 6= ;
 There is an edge from agent c to t if there is no agent c0 such that 1C (c0 ) = C1 (c) 6= ;
 No further edges are in E.
For an example construction, consider Figure 3(IV) showing the update graph for the allocation shown in Figure 3(II) w.r.t. the allocation shown in Figure 3(III).
As each agent gets one good in C1 and 1C , each node in (C1 , 1C ) but s and t has exactly
one incoming edge and one outgoing edge. Moreover, by construction, s has no incoming
edge, and t has no outgoing edge. Thus, the update graph consists of a number of paths
from s to t and a number of cycles, all of them being disjoint from each other.
Let {1 , ..., h } be the set of all possible paths from s to t or cycles in (C1 , 1C ), and
for a path or a cycle i = 1 , ..., m , let agents(i ) be the set {1 , ..., m } \ {s, t}. In
addition, let us fix the following notation: For any function  : X  2G over some given
domain X, let [X 0 ] denote the restriction of  over the (sub-)domain X 0  X. Moreover,
: X2  2G2 over the two domains X1 and X2 ,
given two functions 1 : X1  2G1 and 2 U
respectively,
= , let 1 2 : X1  X2  2G1 G2 be the function such
U such that X1  X2 U
that (1 2 )[X1 ] = 1 and (1 2 )[X2 ] = 2 .
By the construction of the update graph, note that 1C can be expressed in terms of the
disjoint paths/cycles 1 , ..., h by the following expression:
C1 [C 1 \

h
[

agents(i )]

h
]

1C [agents(i )].

i=1

i=1

Observe now that, because val(C1 , w1 ) < val(1C , w1 ), there must exists a set of agents
agents(k ), associated with some disjoint path/cycle k , with 1  k  h, such that the value
of the goods allocated to these agents according to 1C is greater than the corresponding
value for theUsame agents obtained with C1 . Then, consider the function k = C1 [C 1 \
agents(k )] 1C [agents(k )], and note first that k is an allocation for hC, G,   i1 . In
particular, note that, for each agent c  C 1 , |k (c)| = 1 holds, because this
U constraint
actually holds on C1 and 1C , and because of the definition of the operator  . Moreover,
by the choice of k , we also have val(k , w1 ) > val(C1 , w1 ).
Note that if k were either a cycle or a path of the form s, 2 , . . . , m1 , t such that
1C (2 )  img(), then img(k )  img() would hold. Indeed, by definition of the edges
of the update graph, only the first node of a path (that is, 2 in case k is a path) may
be such that 1C (2 ) \ img() 6= . However, as observed above, this is impossible because
val(k , w1 ) > val(C1 , w1 ) would contradict the optimality of C1 , and hence the optimality
of C , by Fact 4.2. Therefore, we can conclude that k is a path of the form s, 2 , . . . , m1 , t
with k (2 ) = 1C (2 ) = {g 0 }  G \ img(). That is, the allocation k (over the agents
in C 1 ) is such that img(k ) = {g 0 }  img(C1 ) \ C1 (m1 ). In particular, observe that
C1 (m1 )  img() \ img(k ) holds, by definition of the edges of the update graph and
since there is an edge from m1 to t.
Let us now come back to the optimal allocation  for hA, G,   i w.r.t. w , and let  1
be an (optimal) allocation in one-good(). Let A  C 1 be a set of agents with 2  A
421

fiGreco & Scarcello

Input:
Assumption:
Notation:
1.
2.
3.
4.
5.
6.
7.
8.

A type vector   , and a feasible allocation  for S ;
The verifier v (for t) is available, with v() = (v1 , ..., vn );
S = hA, G,   i, w = (w1 , ..., wn ), wv() = (wv1 , ..., wvn );

Let C denote the set of all possible subsets of A;
For each i  A and C  C,
b Compute an optimal allocation C,i for hC, img(),  (vi ,i ) i w.r.t. w(vi ,i ) ;
For each agent i  A,
| For each set C  C such that i  P
C,
1
(=val(C,i , w(vi ,i ) ));
| | Let C,i (, ) := wvi (C,i ) + jC\{i} wj (C,i );
P
(=val(C\{i},i , w(vi ,i ) ));
| b Let 2C,i (, ) := jC\{i} wj (C\{i},i );
P
(1C,i (, )  2C,i (, ));
| Let i (, w ) := CC (|A||C|)!(|C|1)!
|A|!

9. b

Define pi (, w ) := i (, w )  wvi ();

Figure 4: Payment rule p .
S
such
of goods cA  1 (c) allocated to these agents according to  1 is equal to
S that the set
0
00
00
00
cA k (c)\{g }G , where G  img()\img(k ) and |G |  1. Note that a set A having
this property in fact exists: just start with {2 } and then add agents from agents(k ) until
some c is found with  1 (c)  img()
U 1 \1img(k ).
Consider then  = k [A]  [A \ A] and note that  is well-defined, because the
construction of the set A guarantees that no good allocated according to k [A] can be
allocated by  1 to agents in A1 \ A, and vice-versa. Moreover,  is a feasible allocation for
hA, G,   i1 . Indeed, for each agent c  A1 , |(c)| = 1 holds, because this constraint actually
holds on k and  1 . Eventually, since  1 is an optimal allocation for hA, G,   i1 w.r.t. w1 ,
val( 1 , w1 )  val(, w1 ) holds. Thus, by construction of , we get val( 1 [A], w1 ) 
val([A], w1 ) = val(k [A], w1 ). U
Finally, let C0 = k [C 1 \ A]  1 [A] and note that C0 is a feasible allocation for
hC, G,   i1 , because of the arguments used above to show that  is a feasible allocation.
Moreover, observe that val(C0 , w1 )  val(k , w1 ) > val(C1 , w1 ) and img(C0 )  img().
For this latter, just recall that 2  A is the only agent in C 1 such that k (2 )\img() 6= .
Again, this entails that C1 is not optimal w.r.t. w1 and hence, by Fact 4.2, C is also not
optimal for hC, img(),   i w.r.t. w . Contradiction.
The result immediately entails the following two corollaries.
Corollary 4.5. For each optimal allocation  for hA, G,   i w.r.t. w and for each set
C  A of agents, opt(hC, img(),   i, w ) = opt(hC, G,   i, w ).
Corollary 4.6. Let  be an optimal allocation for hA, G,   i w.r.t. w , and let  0 be any
feasible allocation for hA, G,   i, hence with val(, w )  val( 0 , w ). Then, for each set
C  A of agents, opt(hC, img(),   i, w )  opt(hC, img( 0 ),   i, w ).

422

fiMechanisms for Fair Allocation Problems

4.2 The Design of a Truthful Mechanism
Consider the payment rule p defined in Figure 4: We are given a type vector   ,
and a feasible allocation  for S that selects some goods img()  G for the agents in
A. Moreover, we use the verifier v (for the vector of true types t) that, given , is able
to compute the actual scenario Sv() and the valuation vector wv() = (wv1 , ..., wvn ) over
the allocated goods in img(). Note that, for the sake of presentation, in this section it is
convenient to look at the output of the verifier as a list of equivalent types v() = (v1 , ..., vn )
where vi , for each agent i, is such that is upper bound constraint and is goods valuation
over img() are those computed by the verifier v. Then, as usual, (vi , i ) denotes the
type vector obtained from  by replacing is type i with the verified type vi . In particular,
w(vi ,i ) denotes the valuation vector (defined over img()) where the function wvi is used
in place of the valuation function declared in i .
In the first three steps, the payment rule associates an optimal allocation C,i for
hC, img(),  (vi ,i ) i w.r.t. w(vi ,i ) with each set C  C of agents and each agent i  A,
where C is the powerset of A, i.e., the set of all possible subsets of agents. Then, for each
agent i  A, the rule computes the value i (, w ) in step 8, by means of a formula that
depends on the valuations associated with the allocations C,i and C\{i},i , for each C  C.
In particular, it defines two terms (1C,i (, ) and 2C,i (, )), which evaluate the allocations
C,i and C\{i},i , respectively, w.r.t. the valuation vector w(vi ,i ) . Actually, for the term
2C,i (, ), is valuation is immaterial as C\{i},i is an allocation over C \ {i}. Finally, the
payment pi (, w) is defined in step 9 as the difference between i (, w ) and wvi ().
Note that the payment rule depends only on the values of the goods in img(), so that
it is verifiable, according to the definition provided in Section 2.3. Moreover note that, as
far as paying agent i is concerned, the rule depends only on the values given by wvi over
allocated goods, i.e., by those values returned by the verifier, rather than by wi . Thus, is
declaration is immaterial as far as the computation of the payment is concerned, and the
next fact easily follows.
Fact 4.7 (no punishment). For each type vector   , for each feasible allocation  for
S , and for each agent i  A, it is the case that pi (, w ) = pi (, w(ti ,i ) ).
Moreover, note that the idea underlying the definition of p is that, after verification
is performed, the utility function will precisely coincide with the bonus i (, w ), hence
sharing the spirit5 of the approach by Nisan and Ronen (2001).
Lemma 4.8. For each type vector    and for each feasible allocation  for S , it is the
case that ui (, w ) = i (, w ).
By exploiting this characterization, we can now show the first crucial result on the payment rule p , i.e., that the mechanism (A, p ) is truthful, provided that A is any arbitrary
optimal allocation algorithm.
To get a high-level intuition of the proof below observe that i (, w ) depends on two
groups of terms, with 2C,i (, ) being basically independent on the given agent i. Thus,
5. We say the spirit, because the peculiar form of i (, w ) does not formally fit the framework considered
by Nisan and Ronen (2001).

423

fiGreco & Scarcello

the goal of agent i is to maximize the terms of the form 1C,i (, ) defined in step 6 as
the valuations of optimal allocations computed (in step 3) by considering is verified type,
by focusing on goods in img() (so that verified values coincide with true ones), and by
considering subsets of the whole set A of agents. The salient machinery is then provided
by Corollary 4.5, according to which it will be always convenient for agent i to report its
true type. Indeed, if  is an optimal allocation computed via A based on the true type
of agent i, then Corollary 4.5 guarantees that 1C,i (, ) will get the maximum possible
value over all possible allocations for scenarios obtained by considering subsets of agents,
i.e., independently on the allocation  being actually selected. This can be done without
strategically interacting with the other agents. Therefore, by designing the payment rule in
a way that depends only on the values returned by the verifier, not only we end up with a
verifiable rule using no punishment, but we also obtain a truthful mechanism based on it.
Theorem 4.9 (truthfulness). Let A be any optimal allocation algorithm. Then, the mechanism with verification (A, p ) is truthful.
Proof. We have to show that, for each agent i  A and each reported type vector d, the
following holds: ui (A(w(ti ,di ) ), w(ti ,di ) )  ui (A(wd ), wd ); hence, by Lemma 4.8, that
i (A(w(ti ,di ) ), w(ti ,di ) )  i (A(wd ), wd ).
Consider the construction reported in Figure 4 for the two cases of  = d and  =
(ti , di ), and let  = A(wd ) and  0 = A(w(ti ,di ) ) be the corresponding optimal allocations
(for the scenarios Sd and S(ti ,di ) , respectively) received as input by the payment rule in
0 ) be
Figure 4. For any set C  C of agents, and for any agent i  A, let C,i (resp., C,i
the allocation computed at step 3. Note that this step is well defined, because such an
optimal allocation always exists. Indeed, just note that there exist feasible allocations for
any scenario S , e.g., any allocation  : C  2img() such that (j) = {g} for some good
g  (j). That is, any allocation that trivially satisfies every upper-bound constraint, since
it assigns one good to each agent.
We now show that the following two properties hold, for each C  C and i  A:
(A) 1C,i ( 0 , (ti , di ))  1C,i (, d), and
(B) 2C,i ( 0 , (ti , di )) = 2C,i (, d).
In order to prove (A), observe that by step 6, 1C,i ( 0 , (ti , di )) = val(C,i , w(vi ,di ) ) =
0
val(C,i , w(ti ,di ) ), where the last equality holds because C,i
 img( 0 ), so that the true
0
is an optimal allocation for
valuation is disclosed by the verifier. Then, observe that C,i
0
0
hC, img( ),  (vi ,di ) i = hC, img( ),  (ti ,di ) i w.r.t. w(vi ,di ) and, hence, w.r.t. w(ti ,di ) , and
 0 = A(w(ti ,di ) ) is an optimal allocation for S(ti ,di ) = hA, G,  (ti ,di ) i w.r.t. w(ti ,di ) .
Thus, by Corollary 4.5, we get the following expression:
0
1C,i ( 0 , (ti , di )) = val(C,i
, w(ti ,di ) ) = opt(hC, G,  (ti ,di ) i, w(ti ,di ) ).

(2)

Similarly, 1C,i (, d) = val(C,i , w(vi ,di ) ) = val(C,i , w(ti ,di ) ) holds. Thus, we
can use Equation 2, in order to get 1C,i ( 0 , (ti , di )) = opt(hC, G,  (ti ,di ) i, w(ti ,di ) ) 
val(C,i , w(ti ,di ) ). This shows that (A) holds.

424

fiMechanisms for Fair Allocation Problems

0
Let us now focus on (B). By step 7, we have 2C,i ( 0 , (ti , di )) = val(C\{i},i
, w(vi ,di ) )
2
0
whereas C,i (, d) = val(C\{i},i , w(vi ,di ) ). Recall that C\{i},i (resp., C\{i},i ) is an optimal allocation for hC \{i}, img(),  (vi ,di ) i (resp., hC \{i}, img( 0 ),  (vi ,di ) i) w.r.t. w(vi ,di ) .
Then, because of the fact that is evaluation is immaterial here, we have that C\{i},i (resp.,
0
C\{i},i
) is an optimal allocation for hC \ {i}, img(),  d i (resp., hC \ {i}, img( 0 ),  (ti ,di ) i)
w.r.t. wd (resp., w(ti ,di ) ). Then, we recall that  (resp.,  0 ) is an optimal allocation for
Sd (resp., S(ti ,di ) ) w.r.t. wd (resp., w(ti ,di ) ). Thus, by Corollary 4.5, 2C,i ( 0 , (ti , di )) =
opt(hC \ {i}, G,  (ti ,di ) i, w(ti ,di ) ). Moreover, we get:

2C,i (, d) = opt(hC \ {i}, G,  d i, wd ).

(3)

Eventually, 2C,i ( 0 , (ti , di )) = opt(hC \ {i}, G,  (ti ,di ) i, w(ti ,di ) ) = opt(hC \
{i}, G,  d i, wd ) holds, as is valuation is immaterial, and we get (B) by Equation 3.
4.3 Further Properties of Truthful Strategies
Let us now analyze some relevant properties that hold whenever agents choose the dominant strategy of truthfully reporting their private types. The first property is a useful
characterization of agents utilities.
Theorem 4.10. For each optimal allocation  for St = hA, G,  t i w.r.t. wt , and for each
agent i  A, it holds that:
ui (, wt ) =


X (|A|  |C|)!(|C|  1)! 
opt(hC, G,  t i, wt )  opt(hC \ {i}, G,  t i, wt ) .
|A|!

CC

Proof. By Lemma 4.8, we know that ui (, wt ) = i (, wt ). Then, for each set C  C of
agents, and for each agent i  A, consider the expressions 1C,i (, t) and 2C,i (, t) defined
in step 6 and step 7, respectively, of the mechanism in Figure 4. Note that, because of the
properties of the verifier v stated in Definition 2.3 and the fact that the payment rule consider only goods that are allocated via , 1C,i (, t) = val(C,i , w(vi ,ti ) ) = val(C,i , wt ) and
2C,i (, t) = val(C,i , w(vi ,ti ) ) = val(C\{i},i , wt ) hold, where C,i and C\{i},i are optimal
allocations for hC, img(),  t i w.r.t. wt and for hC \ {i}, img(),  t i w.r.t. wt , respectively.
Thus, 1C,i (, t) = opt(hC, img(),  t i, wt ) and 2C,i (, t) = opt(hC \ {i}, img(),  t i, wt ).
It follows that:
ui (, wt ) =

X (|A|  |C|)!(|C|  1)!
(opt(hC, img(),  t i, wt )  opt(hC \ {i}, img(),  t i, wt )) .
|A|!

CC

(4)

Recall now by Corollary 4.5 that, for each optimal allocation  for hA, G,  t i w.r.t. wt
and for each set C  C of agents, opt(hC, img(),  t i, wt ) = opt(hC, G,  t i, wt ). Therefore,
1C,i (, t) = opt(hC, G,  t i, wt ) and 2C,i (, t) = opt(hC \ {i}, G,  t i, wt ). By using these
equalities, the result follows from Equation 4.
As agents utilities are completely independent of the particular optimal allocation ,
every agent gets precisely the same utility in every optimal allocation.
425

fiGreco & Scarcello

Corollary 4.11. Let  and  0 be two optimal allocations for St w.r.t. wt . Then, ui (, wt ) =
ui ( 0 , wt ) holds, for each i  A.
Example 4.12. Consider the scenario S = hA, G,  t i, with A = {a1 , a2 } and G =
{g1 , ..., g8 }, the valuation vector wt = (wa1 , wa2 ) discussed in Example 2.1, and the allocation   illustrated in Figure 1(I)). Then, we have:
ua1 (  , wt ) =

1
2 (opt(h{a1 , a2 }, G,  t i, wt )  opt(h{a2 }, G,  t i, wt ))+
1
2 (opt(h{a1 }, G,  t i, wt )  opt(h{}, G,  t i, wt ))+
1
2 (opt(h{a2 }, G,  t i, wt )  opt(h{a2 }, G,  t i, wt ) =
1
1
1
51
2 (51  26) + 2 (26  0) + 2 (26  26) = 2 .

For instance, note that opt(h{a1 }, G,  t i, wt )) = 26, as we can allocate g1 , g4 , and g5 to
a1 , if (s)he is the only agent in the scenario.
Similarly, we get ua2 (  , wt ) = 51
2 . That is, the two agents will share precisely half of
the total value, based on our payment scheme. In fact, by looking at the allocation   in
Figure 1(II), one might navely suppose that a2 contributed more than a1 to the overall
value associated with   . However, this is only due to the specific allocation considered, and
not to the actual values of the goods of the two agents. Indeed, the fairness of the utility
values resulting from our payment rule suddenly appears when considering the existence
of the alternative allocation   in Figure 1(II), which is symmetric w.r.t.   and where it
seems that a1 contributed more than a2 to the overall value: As a matter of fact, the two
agents are completely interchangeable over optimal allocations, and this is correctly reflected
by our payment scheme (without the need of actually looking at   ). In particular, from
Corollary 4.11, the agents are indifferent w.r.t. the specific optimal allocation being selected,
and hence in this case they equally divide all the available value between themselves.

Further basic properties of the mechanism are pointed out next.
Theorem 4.13 (basic properties). Let A be any optimal allocation algorithm. Then, the
mechanism (A, p ) is efficient and guarantees an equal treatment of the equals. Moreover,
if all valuations are non-negative, then (A, p ) is individually rational.
Proof. It is clear that (A, p ) satisfies efficiency and equal treatment of equals.
Let now i  A be an agent and recall from Lemma 4.8 that, for each type vector
   and allocation  for S , ui (, w ) = i (, w ) holds. Consider the payment rule
p defined in Figure 4, and observe that i (, w ) is defined as a weighted summation,
over all coalitions C  C, of terms having the form 1C,i (, )  2C,i (, ). In particular,
all weights are positive and we claim that 1C,i (, )  2C,i (, )  0 holds. Indeed, just
check that, by definition, 1C,i (, ) = opt(hC, img(),   i, w ) and 2C,i (, ) = opt(hC \
{i}, img(),   i, w ). So, under the hypothesis that all valuations are non-negative, we have
that opt(hC, img(),   i, w )  opt(hC \ {i}, img(),   i, w )  0 holds, for each C  A and
agent i  A. Thus, ui (, w )  0, hence the fact that (A, p ) is individually rational trivially
follows (even independently of the allocation , and of whether agent i is truthtelling).
Moreover, the mechanism is also tolerant of sensing errors (or uncertain inputs), in the
sense of Section 3.2.
426

fiMechanisms for Fair Allocation Problems

Theorem 4.14 (error tolerance). Let A be any optimal allocation algorithm. Then, the
mechanism (A, p ) is such that for each type vector t and each agent i  A, |ui (A(wt ), wt )
ui (A(wt ), wt )|  3  dist(t, t).
Proof. Consider the construction reported in Figure 4 for the two cases of  = t and  = t,
and let  = A(wt ) and  = A(wt ) be the corresponding allocations received as its input by
the payment rule (optimal w.r.t. wt and wt , respectively). Moreover, for any set C  C of
agents and for any agent i  A, let C,i and C,i be the corresponding allocations computed
at step 3. Then, we get:
 1C,i (, t) = opt(hC, G,  t i, wt ), by Equation 2 in the proof of Theorem 4.9;
 1C,i (, t) = opt(hC, img(),  (ti ,ti )i, w(ti ,ti ) ), by step 3 in Figure 4 and the fact the
true valuation of agent i is disclosed by the verifier because C,i  img().
 2C,i (, t) = opt(hC \ {i}, G,  t i, wt ), by Equation 3 in the proof of Theorem 4.9;
 2C,i (, t) = opt(hC \ {i}, G,  t i, wt ), again by Equation 3;
Note now that |1C,i (, t)  opt(hC, img(),  t i, wt )|  dist(t, t). Moreover, since  is an
optimal allocation w.r.t. wt , by Corollary 4.5, opt(hC, img(),  t i, wt ) = opt(hC, G,  t i, wt )
and, hence, |1C,i (, t)  opt(hC, G,  t i, wt )|  dist(t, t) holds. Then, observe that
|opt(hC, G,  t i, wt )  1C,i (, t)|  dist(t, t). Therefore, we conclude that |1C,i (, t) 
1C,i (, t)|  2  dist(t, t).
Similarly, |2C,i (, t)  2C,i (, t)|  dist(t, t) holds. Hence, by putting it all together,
we derive |(1C,i (, t)  2C,i (, t))  (1C,i (, t)  1C,i (, t))|  3  dist(t, t).
In the light of the above expression and by step 7 in Figure 4, we have that
|i (, wt )  i (, wt )| 

X (|A|  |C|)!(|C|  1)!
3  dist(t, t).
|A|!

CC

P
To conclude the proof, observe that CC (|A||C|)!(|C|1)!
= 1 holds, so that |i (, wt ) 
|A|!
i (, wt )|  3  dist(t, t).
Therefore, by Lemma 4.8, we get |ui (A(wt ), wt ) 
ui (A(wt ), wt )| = |i (, wt )  i (, wt )|  3  dist(t, t).
In fact, we next show that (A, p ), with A being an optimal allocation algorithm, satisfies
all the remaining properties discussed in Section 3.1. To this end, we first discuss an
interpretation of p in the context of coalitional games.

5. A Coalitional Game Theory Viewpoint
A coalitional game can be modeled as a pair G = hN, i, where N = {1, ..., n} is a finite
set of agents, and  is a function associating with each coalition R  N a real-value
(R)  R, with ({}) = 0, which is meant to encode the worth that agents in C obtain
by collaborating with each other. The function  is supermodular (resp., submodular ) if
(R  T ) + (R  T )  (R) + (T ) (resp., (R  T ) + (R  T )  (R) + (T )) holds,
for each pair of coalitions R, T  N .
427

fiGreco & Scarcello

A fundamental problem for coalitional games is to single out the most desirable outcomes, usually called solution concepts, in terms of appropriate notions
of worth distribuP
n
tions, i.e., of vectors of payoffs x = (x1 , ..., xn )  R such that iN xi = (N ). This
question was studied in economics and game theory with the aim of providing arguments
and counterarguments about why such proposals are reasonable mathematical renderings
of the intuitive concepts of fairness and stability. For further background on coalitional
games, the reader is referred to, e.g., the work of Osborne and Rubinstein (1994).
Here, we consider the Shapley value of G = hN, i, which is a well-known solution
concept such that:
X (|N |  |R|)!(|R|  1)!
i (G) =
((R)  (R \ {i})), for each i  N.
|N |!
RN

Indeed, we shall show that the mechanism defined in Section 4 has a nice interpretation in
terms of the Shapley value of some suitable-defined coalitional games. The correspondence
will be exploited to prove further properties of our mechanism, at the equilibrium t where
agents truthfully report their types.
5.1 The Shapley Value of Allocation Games
We consider two coalitional games defined on top of an allocation problem.
marg
best
Definition 5.1. Given the valuation vector w, we define Gw
= hA, margw i and Gw
=
hA, bestw i as the coalitional games such, that for each set C  A of agents,

 margw (C) = opt(hA, G,  t i, wt )  opt(hA \ C, G,  t i, wt ); and,
 bestw (C) = opt(hC, G,  t i, wt ).

2

Recall that in Section 3.1 we have defined the concept of marginal contribution
marg,w (C) of a coalition C with respect to a given allocation  (because it is sensible
to the set of goods allocated by ). In the above definition, with a slight abuse of notation,
we have defined a similar concept margw (C), which does not depend on any goods allocation.
It turns out that these two concepts actually coincide over optimal allocations.
Theorem 5.2. Let  be any optimal allocation for St w.r.t. wt , and let C  A be an
arbitrary set of agents. Then, marg,w (C) = margw (C).
Proof. Let  be an optimal allocation for St = hA, G,  t i w.r.t. wt , hence optimal
for hA, img(),  t i w.r.t. wt . That is, opt(St , wt ) = opt(hA, img(),  t i, wt ). Moreover, for each set C  A of agents, by Corollary 4.5, opt(hA \ C, img(),  t i, wt ) =
opt(hA\C, G,  t i, wt ) holds. Therefore, margw (C) = opt(St , wt )opt(hA\C, G,  t i, wt ) =
opt(hA, img(),  t i, wt )  opt(hA \ C, img(),  t i, wt ), and the result follows as this value
is equivalent to the definition of marg,w (C) in Equation 1 (on page 416).
Note also that bestw (C) is the best contribution of C, computed assuming that agents in
best
has already
C were the only agents in the allocation problem. In particular, the game Gw
been considered by Moulin (1992), precisely in the setting of fair division for allocation
best
is submodular.
problems. There, it is shown that the cost function associated with Gw
428

fiMechanisms for Fair Allocation Problems

Proposition 5.3. The function bestw is submodular.
marg
Since opt(hC, G,  t i, wt ) = bestw (C), it turns out that Gw
is what is called in the
best
literature the dual game of Gw , and the following result is known to hold. Nevertheless,
we give a direct proof, for completeness.

Corollary 5.4. The function margw is supermodular.
Proof. Let St = hA, G,  t i be the given scenario. The result just follows by noticing that
margw (C) = opt(hA, G,  t i, wt )  opt(hA \ C, G,  t i, wt ) = opt(hA, G,  t i, wt )  bestw (A \
C), for each set of agents C  A. Therefore, bestw (C) = opt(hA, G,  t i, wt )margw (A\C).
Thus, if bestw (R  T ) + bestw (R  T )  bestw (R) + bestw (T ) holds R, T  A, then
we have that margw (A \ (R  T )) + margw (A \ (R  T ))  margw (A \ R) + margw (A \ T )
holds as well, R, T  A. Eventually, by letting R0 = A \ R and T 0 = A \ T , we get
margw (R0  T 0 ) + margw (R0  T 0 ))  margw (R0 ) + margw (T 0 ), for each R0 , T 0  A. That
is, margw is supermodular.
The second relevant property is that the payment rule in Section 4 coincides with the
best
Shapley value of the game Gw
associated with w. The result follows by comparing the utility function as in Theorem 4.10 with the expression for the Shapley value of the coalitional
best
game Gw
. Moreover, we show that the same result can be established for the dual game
marg
Gt , so that the Shapley values of the two games are identicalfor similar correspondences
between Shapley values of different games, see also the works by Maniquet (2003) and Kalai
and Samet (1983).
Theorem 5.5. For each optimal allocation  for St w.r.t. wt , and for each agent i  A,
marg
best
).
) = i (Gw
it holds that ui (, wt ) = i (, wt ) = i (Gw
Proof. By comparing the utility function as in Theorem 4.10 with the expression for the
best
associating with each coalition C of agents the
Shapley value of the coalitional game Gw
worth opt(hC, G,  t i, wt ), we immediately get that, for each optimal allocation  for St
best
).
w.r.t. wt , and for each agent i  A, it holds that ui (, wt ) = i (, wt ) = i (Gw
marg
best
In order to conclude the proof, we show that for each agent i  A, i (Gw ) = i (Gw
)
holds. To this end, first note that these Shapley values can be written as follows:
P
marg
 i (Gw
) = CA,iC (|A||C|)!(|C|1)!
TC0 , and
|A|!
best
 i (Gw
)=

P

CA,iC

(|A||C|)!(|C|1)!
TC ,
|A|!

where TC0 = margw (C)margw (C\{i}) and TC = opt(hC, G,  t i, wt )opt(hC\{i}, G,  t i, wt ).
Then, we claim that:
(1) for each set C  A of agents with i  C, the set C = (A \ C)  {i} is such that TC0 = TC,
and
 the set C = (A \ C)
  {i} is such that T 0 = T .
(2) for each set C  A of agents with i  C,
C
C

429

fiGreco & Scarcello

(1) Let C  A such that i  C, and observe that TC0 = margw (C)  margw (C \ {i}) =
(opt(St , wt )  opt(hA \ C, G,  t i, wt ))  (opt(St , wt )  opt(hA \ (C \ {i}), G,  t i, wt )) =
opt(hA \ (C \ {i}), G,  t i, wt )  opt(hA \ C, G,  t i, wt ) = opt(h(A \ C)  {i}), G,  t i, wt ) 
opt(hA \ C, G,  t i, wt ). Thus, let C = (A \ C)  {i}, and note that TC0 = TC.
 G,  t i, wt ) 
 and observe that T  = opt(hC,
(2) Let C  A such that i  C,
C


opt(hC \ {i}, G,  t i, wt ) = (opt(St , wt )  opt(hC \ {i}, G,  t i, wt ))  (opt(St , wt ) 
 G,  t i, wt )) = marg ((A \ C)
  {i})  marg (A \ C).
 Thus, let C = (A \ C)
  {i} and
opt(hC,
w
w
0
note that TC = TC.
marg
best
As (1) and (2) hold, and given the two expressions for i (Gw
) and i (Gw
), we conclude
that the two values coincide.

5.2 Marginality, Budget-Balancedness, and Individual Optimality
Now that we have established a precise correspondence between our mechanism and the
Shapley value of its associated allocation games, we can show further desirable properties of p . In fact, we exploit the following well-known properties (see, e.g., Osborne &
Rubinstein, 1994; Young, 1985) of the Shapley value of any game G = hN, i:
(I)

P

iN

i (G) = (N );

(II) P
If  is supermodular (resp., submodular ), then
iR i (G)  (R)), for each coalition R  N .

P

iR i (G)

 (R) (resp.,

(III) If G 0 = hN, 0 i is a game such that 0 (R)  (R), for each R  N , then i (G 0 )  i (G),
for each agent i  N .
In particular, Property
(II) entails that the Shapley value of the supermodular game
P
marg
)  margw (R). This means that the Shapley value of this
Gw is such that iR i (Gw
game belongs to another important solution concept for coalitional games called core (Osborne & Rubinstein, 1994), which is highly desirable for its stability, as every coalition
marg
gets at least the worth it deserves according to the function margw .
of agents in Gw
In our context, this will easily entail that the utility of every group (coalition) of agents
C (i.e., the sum of the utilities of agents in C), is not less than its actual marginal contribution to the best possible allocations. Note that considering such a collective utility is
particularly useful whenever we reason in terms of fairness for groups of agents, rather than
just singletons. We first pinpoint that bestw (C) and margw (C) provide an upper bound
and a lower bound, respectively, to the utility of C.
marg

Theorem 5.6. Let  be
Pan optimal allocation for St w.r.t. wt . Then, for each set C  A
of agents, bestw (C)  iC ui (, wt )  margw (C).

marg
best
), for each agent
) = i (Gw
Proof. By Theorem 5.5, we know that ui (, wt ) = i (Gw
i  A and optimal allocation . Then, we can simply recall that the function margw (resp.,
marg
best
bestw ) associated with the game Gw
(resp., Gw
) is supermodular (resp.,
P submodular)
by
Corollary
5.4
(resp.,
Proposition
5.3).
Hence,
the
result
follows
as
iC ui (, wt ) =
P
P
marg
best

(G
)
and
by
property
(II).

(G
)
=
iC i w
iC i w

430

fiMechanisms for Fair Allocation Problems

By combining the above result and Theorem 5.2, we immediately get the following.
Corollary 5.7 (marginality).
P Let A be any optimal allocation algorithm. Then, the mechanism (A, p ) is such that iC ui (A(wt ), wt )  margA(wt ),w (C), for each set C  A.
Hence, under the payment rule p and optimal allocation algorithms, we get mechanisms
that accurately take care of the marginality property defined in Section 3.1. Our next result
pertains the budget-balance property of the mechanisms. Again, the correspondence with
the Shapley value is crucial to establish the result.
Theorem
5.8. Let  be an optimal allocation for St w.r.t. wt .
P

p
(,
w
t ) = 0.
iA i

Then, it holds that

best
), for each agent i  A and optiProof. By Theorem 5.5, we know that ui (, wt ) = i (Gw
best
best
mal allocation , where

(G
)
is
the
Shapley
value
of
G
w . By property (I)
Pof the Shapley
P
P i w best
best
)=
value, we know that iA i (Gw ) = bestw (A). Thus, iA ui (, wt ) = iA i (Gw
opt(hA, G,  t i, wt ). By definition of the utility and letting wt = (w1 , ..., wn ), it then folP
P
P


lows that opt(hA, G,  t i, wt ) =
iA pi (, w). Hence,
iA wi () 
iA pi (, wt ) =
opt(hA, G,  t i, wt )  val(, wt ) = 0, as  is indeed an optimal allocation w.r.t. wt .

Corollary 5.9 (budget-balancedness). Let A be any optimal allocation algorithm. Then,
the mechanism (A, p ) is budget-balanced.
Finally, we complete the picture of our analysis by proving a strong fairness property
of the proposed payment rule p : In words, the best outcome for every agent is always
determined by a (global) optimal allocation. Moreover, from Corollary 4.11, any agent
is indifferent about the specific optimal allocation being considered. That is, any chosen
optimal allocation leads to the best results for all agents.
Lemma 5.10. Let  and  0 be two feasible allocations for St such that  is optimal w.r.t. wt ,
and hence val(, wt )  val( 0 , wt ). Then, ui (, wt )  ui ( 0 , wt ), for each i  A. Moreover, if  0 is not optimal, there exists some agent i  A such that ui (, wt ) > ui ( 0 , wt ).
Proof. For any allocation , consider the coalitional game G  = hA, v  i such that v  (C) =
opt(hC, img(),  t i, wt ), for each C  A. By looking at the expression of the Shapley value
for G  , it is easy to check that ui (, wt ) = i (G  ) (just use the same reasoning in the proof
of Theorem 4.10). Assume now that  0 is an allocation with val(, wt )  val( 0 , wt ), and
0
consider the value v  (C) = opt(hC, img( 0 ),  t i, wt ), for each C  A. By Corollary 4.6,
0
we have that v  (C)  v  (C), for each C  A. Then, we derive that ui (, wt ) = i (G  ) 
0
i (G  ) = ui ( 0 , w) for every i  A, because of property (III).
Now assume that  0 is not optimal, and thus val(, wt ) > val( 0 , wt ). Therefore, for
0
the grand-coalition A, we have v  (A) > v  (A). Because of property (I) of the Shapley
0
value, only (and all) the total value v  (A) is distributed to agents. It follows that there
0
exists some agent i  A such that ui (, wt ) = i (G  ) > i (G  ) = ui ( 0 , wt ).
By focusing on optimal allocation algorithms, the above lemma immediately entails the
following two fairness properties.

431

fiGreco & Scarcello

Theorem 5.11 (individual optimality). Let A be any optimal allocation algorithm.
Then, for any agent i  A and any feasible allocation  for St , ui (A(wt ), wt )  ui (, wt ).
Corollary 5.12 (Pareto-efficiency and envy-freeness). Let A be any optimal allocation
algorithm. Then, the mechanism (A, p ) is Pareto efficient and envy-free.
Note that individual optimality guarantees much more than classical Pareto efficiency
and envy-freeness, because it entails that the mechanism leads to a unique evaluation,
independently of the chosen optimal allocation. In particular, the Pareto set is a singleton.

6. Complexity Issues
In this section, we shall reconsider our mechanism with verification from a computational
perspective. Note first that computing an optimal allocation on the basis of the reported
types is an easy task, which can be carried out via adaptations of classical matching algorithms. Indeed, in the light of Fact 4.2, computing an optimal allocation for an arbitrary
scenario (with agents in A and goods in G) reduces to computing an optimal allocation for
a scenario where each agent (in A1 ) gets one good. This is equivalent to finding a matching
of maximum weight over a complete bipartite graph over the set of disjoint nodes A1 and
G, and where edge weights are encoded via the function w1 . Such a combinatorial problem
is known to be feasible in polynomial time (e.g., Schrijver, 2003).
6.1 Hardness Result
Despite the fact that optimal allocations can be computed in polynomial time, our mechanism is not computationally-efficient, since payments are unlikely to be computable in
polynomial time. Indeed, we next show that this computation problem is complete for the
complexity class #P (see Papadimitriou, 1993).
Let us recall that a counting Turing machine is a standard nondeterministic Turing
machine with an auxiliary output device that prints in binary notation the number of
accepting computations induced by the input. It has (worst-case) time complexity f (n) if
the longest accepting computation induced by the set of all inputs of size n takes f (n) steps.
Then, #P is the class of all functions that can be computed by counting Turing machines of
polynomial time complexity. A prototypical #P-complete problem is to count the number
of truth variable assignments that satisfy a Boolean formula. Of course, NP#P, and a
polynomial-time algorithm for solving a #P-complete problem would imply P = NP.
Theorem 6.1. Computing the Shapley value of coalitional games associated with allocation
problems (as in Definition 5.1) is #P-complete.
Proof. The problem belongs to #P, because computing the Shapley value is known to be feasible in #P for any class of coalitional games with polynomial-time value/cost functions (c.f.
Deng & Papadimitriou, 1994). To show that it is #P-hard, we exhibit a reduction from the
following problem: Let G = (A  B, E) be a bipartite graph with |A| = |B| = n, E  A  B,
and |E| = m  n. Recall that a matching is a set E 0  E of edges such that for each pair
of distinct edges (a, b) and (a0 , b0 ) in E 0 , a 6= a0 and b 6= b0 hold. The matching E 0 is perfect
if |E 0 | = n. The problem of counting the number of perfect matchings in such bipartite
graphs is #P-complete (Valiant, 1979a).
432

fiMechanisms for Fair Allocation Problems

Given a graph G = (A  B, E) as above and a constant k  1 (which we shall fix below),
we build in polynomial-time a tuple S(G) = hA, G,  t i and a vector wt such that:
S
(1) A = {}  (a,b)E {(a, b)1 , ..., (a, b)k }, i.e., agents are one-to-one associated with k
distinct clones of each edge (a, b)  E, plus a distinguished agent . Note that |A| > n,
because in the considered bipartite graphs m  n holds.
(2) G = {g }  A  B, i.e., goods correspond to nodes, plus a distinguished good g .
(3)  = 1 and (a,b)i = 2, for each (a, b)  A and i  {1, ..., k}, are the components of  t
associated with agents  and (a, b)i , respectively.
(4) For each agent c  A, the associated component wc in the vector wt is defined as
follows. For each (a, b)i  A, w(a,b)i (a) = 2, w(a,b)i (b) = 2, w(a,b)i (g ) = 1, w(a,b)i (x) = 0,
x  (A  B) \ {a, b}. Moreover, w (g ) = 1, w (x0 ) = 0, x0  (A  B).
Let us now fix some notations. For any set E 0  E of edges, let match(E 0 ) denote the
size of the largest set E 00  E 0 of edges that is a matching. For any set C  A \ {} of
agents, let A(C) = {a | (a, b)i  C} and B(C) = {b | (a, b)i  C}. Finally, we say that
C  A \ {} is tight if it does not contain two agents of the form (a, b)i and (a, b)j , with
i 6= j, i.e., associated with the same edge of G.
Observe that, for each set C  A \ {} of agents,
opt(hC  {}, G,  t i, wt )  opt(hC, G,  t i, wt ) =



1
0

if C is tight, and |C| = A(C) = B(C)
otherwise

(5)

Indeed, if C0 is an optimal allocation for hC  {}, G,  t i w.r.t. wt , then we always have that
val(C0 , t) = 2  |A(C)| + 2  |B(C)| + 1. Instead, if C is an optimal allocation for hC, G,  t i
w.r.t. wt , then we have

2  |A(C)| + 2  |B(C)|
if C is tight, and |C| = A(C) = B(C)
val(C ) =
2  |A(C)| + 2  |B(C)| + 1 otherwise
best
for
By exploiting Equation 5, we can now express the Shapley value of the game GS(G),t
agent  in a convenient way. Let Xh denote the number of sets C  A \ {} of agents which
are tight and such that |C| = |A(C)| = |B(C)| = h, and let X0 = 1. Then,

|A|1
best
 (Gw
)=

X (|A|  h  1)!(h)!
Xh .
|A|!

(6)

h=0

In particular, let us now focus on the coefficient Xh . Denote by Yh the number of matchings
in G whose cardinality is h. By construction of S(G) it is immediate to check that for each
matching of cardinality h in G, there are precisely k h sets of agents C  A \ {} that are
tight and such that |C| = |A(C)| = |B(C)| = h. Thus, we can rewrite the above expression:
|A|1
best
 (Gw
)=

X

(Zh  Yh )  k h , with Zh =

h=0

433

(|A|h1)!(h)!
.
|A|!

(7)

fiGreco & Scarcello

best
For an expression as the one above, given the value of  (Gw
), it is known that under
certain circumstances we can reconstruct in polynomial time the value of each single term of
the form Zh  Yh (see Fact 6 in the work by Valiant (1979b)): We need an integer constant
A > 2 such that, for each h  {0, ..., |A|  1}, Zh  Yh  A, and k  A2 . In our case, it can
be noticed that, for each h  {0, ..., |A|1}, Zh Yh  1 holds, as Yh  |A|!/((h)!(|A|  h)!).
best
), we can compute in polynomial
Thus, for k = 9, we have that, given the value of  (Gw
time all such terms. In particular, we can compute in polynomial time the term associated
to h = |A| = |B| = n, where recall that |A| > n. This term has the form Zn  Yn , with Yn
being the number of perfect matchings in G. Thus, by putting it all together and since Zn
can be computed in polynomial time (as the size of the numbers n and |A| are logarithmic
w.r.t. the size of G), the number of perfect matchings in bipartite graphs can be counted in
polynomial time too, which concludes the proof.

By Lemma 4.8 and Theorem 5.5, the following is immediate.
Corollary 6.2. Computing the payments as given by the rule p is #P-complete.
6.2 A Fully Polynomial-Time Randomized Approximation Scheme
An approach to circumvent the intractability of the Shapley value is based on approximation:
For a game G = hN, i, a vector  is an -approximation of the Shapley value if |i i (G)| 
  i (G) holds, for each i  N .
Recently, a sampling method conceived by Bachrach, Markakis, Resnick, Procaccia,
Rosenschein, and Saberi (2010) for the special class of simple coalitional games has been
extended to deal with arbitrary games that are supermodular and monotone 6 (Liben-Nowell,
Sharp, Wexler, & Woods, 2012), under the assumption that the value (R) can be computed
by an oracle having unitary cost, for each R  N . The result is that, for any  > 0 and
 > 0, it is possible to compute in time poly(N, 1/, log(1/)) a vector  that is an approximation of the Shapley value with probability of failure at most . A method with
these properties is called a fully polynomial-time randomized approximation scheme.
Next, we propose a payment rule p that is founded on the sampling strategy described
in the work by Liben-Nowell et al. (2012). The payment rule, reported in Figure 5, samples
m subsets of A storing them in C (together with other subsets functionally determined by
the samples), and then computes the value (, w ) as in Figure 4, but with C playing the
role of the power-set C. The process is repeated (log(1/)) times, and the componentwise median vector of all such payments is computed. The resulting payment is eventually
defined at step 9.
The new rule p gives rise to a randomized mechanism that is of course still verifiable
and uses no punishment. Moreover, the mechanism is truthful even when the realization
of the set C, sampled in step 1, is known beforehand.7 Formally, the mechanism turns out
to be universally truthful, i.e., it is a probability distribution over deterministic truthful
mechanisms (see, e.g., Dobzinski & Dughmi, 2009).
6. Monotonicity of G = hN, i means that (R)  (T ), T  R  N .
7. This evidences that if truthfulness is our only desideratum, then there is no need to implement a payment
rule computing the Shapley value of the coalitional game associated with the allocation problem (as in
Definition 5.1), which in fact is a concept defined over all possible subsets of A and which we have shown
to be computationally hard in Theorem 6.1.

434

fiMechanisms for Fair Allocation Problems

Input:
A type vector   , a feasible allocation  for S , and an integer m > 0;
Assumption: The verifier v (for t) is available, with v() = (v1 , ..., vn );
Notation:
S = hA, G,   i, w = (w1 , ..., wn ), wv() = (wv1 , ..., wvn );
1.
2.
3.
4.
5.
6.
7.
8.
9.

Generate a set C of m subsets of A, and
let C := C  {(A \ C)  {i} | C  C, i  C}  {A};
For each i  A and C  C,
| Compute an optimal allocation C,i for hC, img(),  (vi ,i ) i w.r.t. w(vi ,i ) ;
b Compute an optimal allocation for C\{i},i for hC \ {i}, img(),  (vi ,i ) i w.r.t. w(vi ,i ) ;
For each agent i  A,
b Compute i (, w ) as in Figure 4 (steps 48), with C := C;
Repeat (log(1/)) times steps 1, 2, and 5, and
 w ) be the component-wise median vector of these vectors (, w );
Let (,
Define pi (, w ) := i (, w )  wvi ();
Figure 5: Payment rule p .

Theorem 6.3. Let A be any optimal allocation algorithm. Then, the mechanism (A, p ) is
universally truthful.
Proof. The result follows by inspecting the proof of Theorem 4.9 for rule p in Section 4.
Indeed, it can be immediately checked that the proof does not depend on the specific
subset of coalitions C, and thus it smoothly applies if any set of coalitions C is used as
in Figure 5, instead of all possible subsets of A. Note in particular that, in the proof of
Theorem 4.9, properties (A) and (B) are precisely those guaranteeing truthfulness, and that
these properties hold for each given coalition C. Therefore, they still hold for any subset of
coalitions randomly chosen by the mechanism.
Similarly, by inspecting the proofs in Section 4, in this universally truthful mechanism,
the following properties are seen to hold for every realization of the random coin tosses.
Theorem 6.4 (basic properties). Let A be any optimal allocation algorithm. Then, the
mechanism (A, p ) is efficient and guarantees an equal treatment of the equals. Moreover,
if all valuations are non-negative, then (A, p ) is individually rational.
For a deeper analysis of the payment rule p , we next point out a relationship between
utility values and approximations of the Shapley value, at the equilibrium when all agents
report their true types.
Lemma 6.5. Let A = {1, ..., |A|}, and let m = (|A|2 /2 ). For each optimal allocation
 for St w.r.t. wt , the vector (u1,p (, wt ), ..., u|A|,p (, wt )) is an -approximation of the
marg
best
Shapley value of Gw
(and Gw
) with probability 1  , and coincides with it in expectation.
Proof. By exploiting the same line of reasoning as in the proofs in Section 4 for p , we can
see that i (, wt ) (at step 6 of the algorithm in Figure 5) can be rewritten as follows:
i (, wt ) =

X (|A|  |C|)!(|C|  1)!
(bestw (C)  bestw (C \ {i})) .
|A|!

CC

435

fiGreco & Scarcello

Then, we observe that by construction of C in step 1, for each set C  C and each agent
i  A, the set (A \ C)  {i} is in C, too. Thus, we can apply the same line of reasoning as
in the proof of Theorem 5.5, in order to conclude that:
i (, wt ) =

X (|A|  |C|)!(|C|  1)!
(margw (C)  margw (C \ {i})) .
|A|!

CC

marg
= hA, margw i is supermodular by Corollary 5.4. MoreNow, recall that the game Gw
marg
over, Gw is clearly monotone. Thus, by Liben-Nowell et al. (2012), the above expression
marg
, and it approximates this value
coincides in expectation with the Shapley value of Gw
with constant probability. Steps 7 and 8 serve to amplify the probability (c.f. Liben-Nowell
et al., 2012), and to get a fully polynomial-time randomized approximation scheme. The
result follows as step 9 implements the usual bonus and compensation approach, so that
ui,p (, wt ) coincides with the above expression, for each i  A (cf. Lemma 4.8).

Note that in the approach by Liben-Nowell
P et al. (2012), a final normalization step
is carried out that would guarantee that
iA u1,p (, wt ) = margw (A) = bestw (A).
Unfortunately, this way truthfulness might be lost, hence we did not include such a normalization procedure in the above payment rule. As a consequence, the mechanism p does
not guarantee (for instance) budget-balancedness and Pareto-efficiency. However, because
of Lemma 6.5, since the expected utility profile coincides with the Shapley value, p enjoys
in expectation all the properties of p including the above two ones. In particular, we can
still have approximate counterparts for Theorem 5.6 and Theorem 5.8.
Theorem 6.6. Let  be an optimal allocation for St w.r.t. wt . Let m = (|A|2 /2 ). Then,
with probability 1  ,
P
 (1 + )  bestw (C)  iC ui,p (, wt )  (1  )  margw (C), for each C  A;
   val(, wt ) 

P


iA pi (, wt )

   val(, wt ).

Proof. Here, just observe
of Lemma 6.5 and TheoremP5.5, for each set
Pthat, in the light P
C  A, we have (1) iC ui,p (, wt )  iC ui,p (, wt )  (1+) iC ui,p (, wt ).
The result then follows by substituting such bounds in Theorem 5.6 and Theorem 5.8,
respectively, with simple algebraic manipulations.
Finally, we propose a further randomized mechanism that is able to guarantee both economic efficiency and budget-balancedness. The price to be paid is however that truthfulness
holds in expectation only. The mechanism is based on a payment rule that we call p .
Theorem 6.7. Let A be any optimal allocation algorithm. Then, there is a (randomized)
mechanism with verification (A, p ) that is truthful in expectation, and that (at the truthful
equilibrium) is efficient and budget-balanced. Moreover, if all valuations are non-negative,
then (A, p ) is individually rational.
Proof. The payment rule p follows the steps in Figure 5, with minor modifications in
step 8 and step 9: First, in step 8, whenever we compute the median value i (, w ) for
agent i, we also compute the corresponding value i (, wv() ) (evaluated on the revealed
436

fiMechanisms for Fair Allocation Problems

types rather than on the reported ones). Then, we define a normalization factor R =
P
opt(hA, img(),  v() i, wv() )/( iA i (, wv() )), so that, in step 9, pi (, w ) is eventually
returned as wvi ()  i (, w )  R.
Concerning truthfulness, we can just note that the expected value of R is 1. Indeed, by
Lemma 6.5, the expected value of i (, wv() ) is i (, wv() ); hence, the sum of all these
values coincides with opt(hA, img(),  v() i, wv() ) by the efficiency of the Shapley value
(as in the proof of Theorem 5.8). Thus, the expected utility of an agent i under the payment
rule p coincides with the (actual, i.e., not in expectation) utility of i under the rule p .
Hence, truthfulness in expectation follows by Theorem 6.3. Now, we can just check that,
at the truthful equilibrium, the maximum social welfare is achieved (equilibrium efficiency)
P
P
and iA pi (, wt ) = opt(hA, img(),  t i, wv() )  iA i (, wt )  R = 0. That is, the
mechanism is budget-balanced, too. Finally, the mechanism p is seen to be individuallyrational, by exploiting the same line of reasoning as the one used for the mechanism based on
p , since the corresponding proof in Section 4 is not affected by the sampling strategy.
Again, by Lemma 6.5, all the remaining properties hold in expectation.

7. Related approaches to Mechanisms with Verification
We next review the main approaches in the literature for mechanisms with verification, and
point out the differences w.r.t. our proposal.
First we observe that, differently from our general setting where the types of the agents
can determine the vector of the upper bounds for the allocation problem, in earlier approaches it is assumed that agent types do not have any impact on the underlying combinatorial problem, so that the type vector precisely coincides with the valuation vector. Instead,
we deal explicitly with both allocation constraints and goods valuations. For instance, in
a scheduling problem formalized in our setting, the private type of an agent/machine can
be its speed, while its valuation function is fully determined by this speed and the size
of the job to be processed. Then, the verifier is just asked to measure the speed of such
agents/machinessee also Appendix A. In fact, it is immediate to encode the valuations
as types as well, at the price however of hiding the true complexity (or simplicity) of the
setting. For instance, in the above example, if the type of an agent is the vector of its
valuations, then we would miss the information that the agent is ultimately characterized
by one (observable) parameter only.
More substantial differences between earlier approaches and our proposal come in the
very definition of the utility of an agent. In the works by Auletta et al. (2009), Penna
and Ventre (2012a, 2012b), Krysta and Ventre (2010), Auletta et al. (2006) and Ferrante
et al. (2009), the individual welfare of an agent i, given the outcome  and the vector d of
reported types, is assumed to be of the following form:

0
if i is caught lying
ui,p (, d) = ti () 
pi (, d) otherwise
where pi (, ) is a payment that does not depend on the vector t of the true types.
In these papers, the only information that is assumed to be available at payment time is
whether the reported type di of agent i differs or not from its actual true type ti . This is the

437

fiGreco & Scarcello

role played by the verifier, and in fact pi (, d) does not exploit the possibility of partially
revealing ti . Moreover, the payment scheme adopted punishes those agents that are caught
lying. Hence, while the verification process provides a smaller amount of information than
the verification process in our approach, the rules used to discourage strategic behaviors
are stronger than ours and based on punishing agents. Also, the above works assume
that agents misreporting is restricted to certain kinds of lies (e.g., values lower than the
corresponding true ones), so that a form of one-sided verification suffices.
Recently, the above model of (partial) verification has been extended by Caragiannis
et al. (2012) to a setting where an agent cheating on her/his type will be identified with
some probability that may depend on her/his true type, the reported type, or both. In fact,
Caragiannis et al. also showed that there are cases in which verification does not help if
it is not one-sided. The payment scheme is exactly the same as the one discussed above
and, hence, verification does not exploit any (possibly partial) knowledge of the actual
true type and a punishment approach is still used. The main novelty, in addition to the
probabilistic verification, is that there is no constraint on the type that an agent can report
while cheating.
Finally, a different kind of verification model goes back to the seminal paper by Nisan
and Ronen (2001), and it is actually closer to our no-punishment perspective, because an
agent i can in principle be paid by the mechanism even if i has been caught lying. Given
n agents, Nisan and Ronen consider a vector e = (e1 , ..., en ) of observed agent types,
which are completely known after the verification process. Moreover, the individual utility
of any agent i has the form ui,p (, d) = ei ()  pi (, d), so that the vector e in such a
framework plays the same role as the verifiers output in our approach. A first difference
between the work by Nisan and Ronen and our approach is that, in the above model, agents
misreporting is again restricted only to certain kinds of lies. On the other hand, we consider
a restriction on the form of valuation functions, since our verification model assumes that
valuations are determined by some objective and observable properties of goods and agents
(encoded by functions of the form g and i , as defined in Section 2). As a consequence,
at payment time, the valuation of any agent i is known for every good in img(). Instead,
in the setting by Nisan and Ronen, the valuation of each agent i for goods in img() \ (i)
remains unknown even after the verification is performed. From the results presented in this
paper, it turns out that this difference between the two framework is crucial to overcome
classical impossibility results, and to meet all desirable properties at once (without using
any punishing power).

8. Conclusion
In this paper, we have proposed and analyzed mechanisms for fair allocation problems in a
setting where agents declarations regard objective properties of goods or agents, and thus
can be (partially) verified before payments are made. In particular, we have considered a
model of verification that is able to disclose the true values of allocated goods, in contrast
to previous approaches in the literature where partial and probabilistic verification have
been considered. However, the use of this verification power is in fact quite limited, because
payment rules have been designed so that no punishment is meted out to agents whose
declarations do not match the output of the verification process. This requirement is crucial
438

fiMechanisms for Fair Allocation Problems

for practical applications of the framework, such as the Italian research evaluation described
in (Greco & Scarcello, 2013) (and summarized in the Appendix), because any discrepancy
between declared and verified values may be due to sensing errors or subjective issues that
cannot be interpreted as agents lies to be punished.
The challenge was to show that, in this framework, truthfulness, efficiency, budgetbalancedness, and fairness (as well as further desirable properties discussed in Section 2)
can be achieved simultaneously, unlike the classical setting. It is worthwhile noting that, if
one is guaranteed that all agents truthfully report their true types (no strategic behaviors)
or, equivalently, if these types are given as public knowledge, then the problem is quite easy.
For instance, one can just use payments in a way that each agent gets as her/his utility
the Shapley value according to either coalitional game defined in Section 5. Moreover, if
fairness is not an issue, then the other properties can be obtained by even using the simple
uniform payment rule. However, whenever agents may behave strategically, reporting the
true type is no longer a dominant strategy, if such approaches are used. In fact, truthfulness
might be enforced by equipping the mechanism with suitable punishment rules. However,
we already argued that this would be not appropriate in our context, and typically the
resulting mechanism would not be error tolerant.
By looking at the proposed framework from an abstract perspective, one may notice that
it is based on two fundamental ingredients: a base combinatorial problem that determines
feasible and optimal allocations, and a game-theoretic notion that describes what is considered fair, with respect to agents contributions and expectations. Namely, in the application
domain of allocation problems addressed in the paper, the weighted matching is the basic
combinatorial problem and the Shapley value is the most natural game-theoretic solution
concept. Under this perspective, a natural research direction is to study different instances
of such an abstract framework for mechanisms with verification, where other combinatorial
problems (colorings, coverings, etc.) and different solution concepts (Nucleolus, Banzhaf
index, etc.) may be more appropriate and best describe the problem at hands.
Another interesting avenue for further research would be to study a modification of
the framework where agents preferences are not directly expressed in terms of real-valued
functions, but they are rather formalized in terms of orderings/ranks over available goods.
This is particularly interesting given that, in the strategic setting we have defined, agents
declarations only contribute to the definition of which goods will be selected, but they do
not determine their values.

Acknowledgments
We thank the anonymous referees and the Associate Editor for their very useful comments.

Appendix A. Application Scenarios
Fair allocation with monetary compensation has been intensively studied in the literature,
very often in settings where all parameters of interest are public knowledge (or, simply,
by getting rid of strategic issues). One example application discussed in the literature is
parking space and benefit allocation at a workplace, where each employee gets a parking
space and a share from a fixed benefits package. House allocation problems are another

439

fiGreco & Scarcello

classical example, where agents collectively own a set of houses, and we look for a systematic
way of exclusively assigning a house to each agent, possibly with monetary compensations.
A third example is room assignment-rent division, where a group of agents rent a house,
with each of them getting a room and paying a share of the rent.
In the following, we illustrate further applications of fair allocation problems that fit
our general framework discussed in Section 2. In the applications we shall discuss, part of
the relevant information is private knowledge of the agents, and verification can be adopted
to measure observable properties before the payment phase. Nonetheless, we stress here
that, even if all the relevant information were available as public knowledge or could be
measured in advance, such applications would still remain of interest, as they show the
need of defining allocation policies that guarantee fair and/or error tolerant solutions.
A.1 The Italian Research Assessment Program (VQR) 20042010
We start our overview of possible application scenarios by focusing on a real-world case
study that first motivated our investigation on allocation problems. This application is
best described in a companion paper (Greco & Scarcello, 2013), which applies the results
presented here to the specific case of the Italian research assessment program.
A.1.1 The Setting
In 2012, the National Agency for the Evaluation of Universities and Research Institutes
(ANVUR) has promoted the VQR assessment program devoted to evaluate the quality of
the whole Italian research production. In its first application, the program focuses on the
period 2004-2010, while the evaluation will be repeated on a regular basis (the next one
should cover years 20112014).
In the first phase of the program, every structure R (a university or a research institute)
selects and submits to ANVUR a set P of its products, under the constraints that (i) each
product has to be univocally associated with an author (even if the product is co-authored)
and that (ii) at most three products can be associated with each author affiliated with R.8
In abstract terms, R computes in this phase an allocation , with img() = P , for the
scenario where R is the set of the agents/researchers affiliated with R, where P is the set
of all the goods/products they have co-authored, and where for each r  R, r = 3 is the
associated constraint on the number of goods/products that can be allocated to r. The way
this allocation is performed is described below.
In the second phase, ANVUR evaluates the products in P by equipping each of them
with a quality score, expressed as a number.9 Hence, this phase defines an official valuation
such that, for each product p  (r), w(p) is the quality score assigned by ANVUR to p.
The overall score of R will be the sum of the values of all products in P , and it will be
used to proportionally transfer to R the funds allocated by the Ministry to support research
activities in the next years, until data from a new evaluation for the subsequent period will
be available.
8. We simplify here. Actually, the number of publications may be less than three, for some authors.
9. The set of the possible scores is defined in the VQR guidelines. To our ends, this detail is immaterial
and scores are just viewed as (arbitrary) real numbers.

440

fiMechanisms for Fair Allocation Problems

A.1.2 The Need of a Fair Division
The VQR program actually assigns a score not only to the structure R, but also to all its
substructures (e.g., to departments, if R is a university). Of course, this is expected to
have an impact on the funds redistribution inside every research structure, and therefore a
crucial problem is to define a fair rule for funds redistribution, that is, a rule that is capable
to assign funds by clearly reflecting the true contribution of each researcher/substructure
to the performances of the structure as a whole. Moreover, the recruitment policies of
universities are going to be evaluated as well, by looking at the (VQR) performances of
researchers that were hired recently. However, no redistribution rule has been specified in
the program, and most researchers believe that the evaluation
P of (the contribution of) each
r  R will just coincide with the overall value wr () =
p(r) w(p) of those products
allocated to r in the submission phase. Of course this is not fair in general, because if a
product p  P is co-authored by two researchers of R, then they both (and, in turn, their
structures) might claim this contribution even if the product has been formally allocated
just to one of them.10 Therefore, more sophisticated approaches have to be defined for a
proper evaluation of individuals and substructures.
A.1.3 Strategic Issues and Verification in the VQR Program
Recall that the goal of structure R is to submit to ANVUR (in the first phase of the program) the products that will likely get the highest possible scores (in the second phase).
To this end, there are publicly available evaluation criteria that should allow one to perform a ranking of products, ideally by equipping each of them with the quality score that
will be assigned to it by ANVUR in the subsequent phase. Both for time and economic
reasons, this first evaluation phase was based only on self-evaluations performed by the
authors of the products, which are clearly assumed to be the best experts on their research
subjects. Moreover, in most structures, to decide the precise allocation of products, hence
to deal with the conflicts related to co-authored products, researchers performed choices in
a decentralized way; only a few structures set up an optimization framework to compute
an optimal allocation, based on agents declarations. In any case, by abstracting from the
specific method adopted to end up with a feasible allocation to be submitted for the VQR,
strategic issues emerged in this phase. In particular, there are some researchers r  R that
guided the allocation of the products (e.g., cheating on their quality) for the supposed
personal interest of maximizing the value wr (). Clearly enough, this way optimal product
selections can hardly be achieved by the structure.
Note that the VQR case perfectly fits our framework of allocation problems: here the research products are the indivisible goods to be allocated to researchers/agents, who initially
declare their goods valuations. Moreover, the social welfare is the total ANVUR score of
the research structure, that should be distributed in a budget-balanced way to researchers,
and hence to their substructures, in a fair way. Note that the upper bound constraint for
each researcher (3 products, with some exceptions) does not depend on the type in this case,
10. This problem does not occur for products co-authored by researchers belonging to different structures.
Indeed, the same product can be submitted by several structures (assigned to a different co-author in
each of them). Thus, for a given research structure R, the co-authors of interest are only those affiliated
with R.

441

fiGreco & Scarcello

because it is a parameter fixed by ANVUR. Therefore, the private information of agents
is limited to good valuations. Moreover, observe that the specific valuation functions occurring in the VQR fit the verification model proposed in the paper. In particular, every
research product has an objective value, which can be measured by a verifier for each
allocated and hence submitted product (while nothing can be said for products that are not
allocated to any researcher). Thus, ANVUR precisely acts as the verifier of the model.
A.1.4 Mechanisms for the VQR Program
The basic approach of assigning to each researcher r  R the value wr () is precisely the
(trivial no-payment) rule p in Example 2.6. There, we have observed that mechanisms
based on this rule are not truthful in general. Moreover, from Example 3.1 is also emerged
that the rule is not fair (in particular) when combined with an optimal allocation algorithm
(in order to to guarantee efficiency). Therefore, this rule is highly undesirable, and different
kinds of mechanisms have to be defined for the VQR setting.
In fact, we would like to end up with a mechanism that is able as able to collect the
correct self-evaluations (truthfulness) and to obtain the maximum possible performance
(efficiency) for the research structures. These two goals, however, have to be accomplished
together with fairness. Indeed, we would like to guarantee to every researcher or group of
researchers to get at least their marginal contributions, and that the resulting mechanism is
also individually optimal. The latter property is very important for this application, since
it guarantees that, for any researcher, her/his score is the maximum one over all possible
alternative allocations, including allocations using products that were not submitted by the
structure and hence not verified. Moreover, it is also relevant that these properties are
guaranteed via mechanisms enjoying the verifiability property, in that the payment rule
only uses certified valuations (it would be unacceptable to use product values that are
not verified by ANVUR).
Finally, it is worthwhile noting that ANVUR guidelines defines a range of possible product values determined, e.g., by the publishing venues and by citation indices, by pointing
out that peer-reviews can also be used to override such a basic classification (e.g., for papers published on a good journal but without many citations, or after an explicit authors
request). Clearly enough, this entails that discrepancies between authors declarations and
ANVUR evaluations might well emerge even in absence of any malicious behavior. Hence,
the no-punishment (and error-tolerant) approach seems to be unavoidable for a concrete
and politically acceptable application of any mechanism.
A.2 (Cooperative) Scheduling and Task Allocation
Assume that h jobs in the set J = {1 , ..., h } have to be executed within a deadline d, and
that n agents/machines, m1 , ..., mn , with n  h, are available to execute in parallel these
jobs. For each machine mi , with i  {1..., n}, let i  J denote the set of jobs that mi can
in principle execute. These sets are determined, for instance, by physical, technological, or
accessibility constraints and are known to the scheduler, while the precise speed that the
machines guarantee for this process is not known to the scheduler, and should be declared by
agents. It is assumed that each machine mi can always work at such a speed independently
of the workload actually assigned to it (for the considered jobs i at hand). For the sake of
442

fiMechanisms for Fair Allocation Problems

simplicity, assume also that each job consists of the same workload wl , and that for each
executed job, a fixed profit pr is earned. Moreover, a further profit pr add will be earned
by the scheduler if all jobs are correctly executed, and (part of it) can be distributed to
agents. Every machine participating in the process will execute at least one job (i.e., we
are assuming we have many jobs that can be executed by any machine and machines have
comparable speeds so that it is convenient to use all of them). Furthermore, every machine
is dedicated to this process and it aims at executing as many jobs from J as possible,
because it cannot earn any profit from external jobs (not in J ).
Therefore, we have an allocation problem where the goods/jobs in the set {1 , ..., h }
have to be allocated/scheduled to the agents/machines in the set {m1 , ..., mn }. Here, the
private type of agent mi is its speed si (devoted to this process), for each i  {1, ..., n}.
Moreover, the vector  of the upper bounds to the number of goods that can be allocated
i
to the agents is defined as i (si ) = b ds
wl c, for each i  {1, ..., n}. Note, in particular, that
the jobs have to be completed within the deadline, so that the upper bound constraints of
the allocation scenario are functions of the types/speeds of agents/machines. Finally, we
can define the valuation vector w = (w1 , ..., wh ) so that, for each i  {1, ..., n}, wi (x ) = pr ,
if x  i ; and wi (x ) = 1, if x 6 i . Note that in this case valuations are independent on
the types of the agents (of course, we are assuming that any single job in i can be executed
within the deadline d).
Given that the same task can be carried out by different agents, it is sensible that
allocations are perceived to be as fair ones (see, e.g., Porter et al., 2004). To this end, the
mechanism with monetary compensations described in this paper can be adopted. In fact,
note that strategic issues come into play, and the egoistic behavior of some agents may lead
to allocations that are not optimal and possibly can miss the extra-reward pr add . Observe
that the scheduler may act as the verifier in our model, at the end of the process. Indeed,
after the allocation is computed and jobs are executed based on it, it can immediately
verify the truthfulness of agents declarations by looking at the amount of time used by
each machine to execute the jobs assigned to it.
Furthermore, in practice, speed values are given with a finite precision, as well as their
physical verification is subject to measurement errors. For this reason, even this mechanism
should be tolerant of errors, and not based on punishments.
As a further example, consider the following task allocation problem, which can be
viewed as a variation of the previous one: Assume that a company select some agents
e1 , ..., en to perform a given set of tasks {t1 , ..., tm } within a certain deadline, and assume
that the company does not know precisely whether or not such agents have the necessary
skills (experience, strength, speed, competence, etc.). For instance, this may happen if the
company is starting some new line of production with new tasks, or if such tasks should be
executed by means of crowdsourcing, where agents are selected through an internet call.
Therefore, in this case agents types declarations comprise both their skills and the
number of tasks they are able to execute within the required deadline. Valuation functions
encode the profit to be earned by any agent executing a given task (where the value 0
means that the agent is not able to execute that task). Note that here both the upper
bound constraints of the allocation scenario and the valuations functions depend on agents
types. Again, a mechanism with monetary compensations can be used, in order to provide a
fair distribution of the company reward for those tasks, and to encourage agents to truthfully
443

fiGreco & Scarcello

declare their skills. Note that the framework with verification proposed in this paper can
be used under the assumption that the agents skills necessary for the proposed set of tasks
can be observed and evaluated by the verifier, (at least) at the end of the process, where
all agents performed their work (possibly with failures).
A.3 Protocols for Wireless Communication Networks
We conclude this overview of possible applications by considering a cost problem where,
moreover, there is no private information, and hence no strategic behavior. This is to remark
that the proposal described in the paper can be used even when mechanism design is not
necessary, but one still needs a policy for fair division that enjoys the properties described
in Section 3.1 (e.g., envy freeness, individual optimality, and so on). In fact, fairness
issues are currently attracting much attention in the design of scheduling protocols over
wireless communication networks, where the underlying problem is bandwidth allocation;
for instance, in the design of protocols for high-speed wide area wireless networks, where
the role of monetary compensation is played by adjustments in the priorities of users (see,
e.g., Jalali, Padovani, & Pankaj, 2000). Moreover, a number of network applications are
emerging where direct forms of monetary compensation are considered.
As an example, let us consider ad-hoc networks, which are self-organizing wireless infrastructures where mobile nodes cooperatively act via multi-hop routing to transmit data even
when source and destination nodes are out of their transmission ranges. Cooperation can be
achieved by associating a credit balance with each node, so that nodes use credits to pay for
sending their own traffic, and earn credits by forwarding traffic from other nodes to compensate bandwidth and power consumptionsee, for instance, the work by Gobel, Krzesinski,
and Mandjes (2009) and the references therein. Consider a setting where the nodes s1 , ..., sn
are willing to transmit some data in an ad-hoc network. In a given configuration of the
network, the nodes r1 , ..., rm can be used to forward these data. In particular, whenever
si and rj , with i  {1, ..., n} and j  {1, ..., m}, are within their transmission ranges, we
denote by ci,j the credit paid by si to transfer the data via rj a large enough value for ci,j
can be used to state that the transmission is not possible. The resulting cost problem can
be modeled via an allocation scenario where i = 1, and where the valuation vector is such
that wi (rj ) = ci,j , for each i  {1, ..., n} and j  {1, ..., m}. Thus, maximizing the social
welfare amounts to minimizing the overall credits paid by source nodes.
It is easily seen that, even if there is no private information and everything is public,
fairness issues emerge in this context, too. Indeed, different sources may want to use the
same routing node to transfer data. For instance, in a simple setting where m = 2 and
n = 2 and where r1 is the most preferred routing node for both s1 and s2 (i.e., c1,1 < c1,2
and c2,1 < c2,2 ), the node that is forced to transfer data via r2 might perceive the
given allocation as unfair. This suggests that the credits paid by source nodes should be
adjusted via payment rules that, in our proposal, are based on the Shapley value of the
coalitional games described in Section 5.
A setting similar to the one discussed above emerges in wireless cooperative file sharing
systems, where mobile subscribers cluster together by downloading (portions of) files of
interest over long-range cellular links, and by exchanging them over short-range radio communications in a wireless local area network. These systems are cooperative environments,

444

fiMechanisms for Fair Allocation Problems

whose benefits can be appreciated not only in terms of increased throughput and reduced
energy consumption, but also in terms of economic advantages both for users and content
providers. In order to be effective, however, fair allocation protocols have to be designed,
whose goal is to encourage cooperation (see, e.g., Militano, Iera, & Scarcello, 2013).

References
Abdulkadiroglu, A., Sonmez, T., & Unver, M. U. (2004). Room assignment-rent division:
A market approach. Social Choice and Welfare, 22, 515538.
Agotnes, T., van der Hoek, W., Tennenholtz, M., & Wooldridge, M. (2009). Power in
normative systems. In Proc. of AAMAS09, pp. 145152.
Alcalde, J., & Barbera, S. (1994). Top dominance and the possibility of strategyproof stable
allocations to matching problems. Economic Theory, 4, 417435.
Alkan, A., Demange, G., & Gale, D. (1991). Fair allocation of indivisible goods and criteria
of justice. Econometrica, 59 (4), 102339.
Andersson, T. (2009). A general strategy-proof fair allocation mechanism revisited. Economics Bulletin, 29 (3), 17171722.
Andersson, T., & Svensson, L.-G. (2008). Non-manipulable assignment of individuals to
positions revisited. Mathematical Social Sciences, 56 (3), 350354.
Andersson, T., Svensson, L.-G., & Ehlers, L. (2010). Budget-balance, fairness and minimal
manipulability. Working papers 2010:16, Lund University, Department of Economics.
Aragones, E. (1995). A derivation of the money rawlsian solution. Social Choice and
Welfare, 12, 267276.
Archer, A., & Tardos, E. (2007). Frugal path mechanisms. ACM Transactions on Algorithms, 3, 122.
Auletta, V., De Prisco, R., Penna, P., & Persiano, G. (2009). The power of verification for
one-parameter agents. Journal of Computer and System Sciences, 75, 190211.
Auletta, V., De Prisco, R., Penna, P., Persiano, G., & Ventre, C. (2006). New constructions
of mechanisms with verification. In Proc. of ICALP06, pp. 596607.
Auletta, V., Penna, P., Persiano, G., & Ventre, C. (2011). Alternatives to truthfulness are
hard to recognize. Autonomous Agents and Multi-Agent Systems, 22 (1), 200216.
Aumann, R. J., & Maschler, M. (1985). Game-theoretic analysis of a bankruptcy problem
from the talmud. Journal of Economic Theory, 36 (2), 195213.
Bachrach, Y., Markakis, E., Resnick, E., Procaccia, A. D., Rosenschein, J. S., & Saberi, A.
(2010). Approximating power indices: theoretical and empirical analysis. Autonomous
Agents and Multi-Agent Systems, 20, 105122.
Bachrach, Y., & Rosenschein, J. S. (2008). Coalitional skill games. In Proc. of AAMAS08,
pp. 10231030.
Bachrach, Y., & Rosenschein, J. (2009). Power in threshold network flow games. Autonomous Agents and Multi-Agent Systems, 18 (1), 106132.

445

fiGreco & Scarcello

Bachrach, Y., Zuckerman, M., Wooldridge, M., & Rosenschein, J. (2013). Proof systems
and transformation games. Annals of Mathematics and Artificial Intelligence, 67 (1),
130.
Bevia, C. (1998). Fair allocation in a general model with indivisible goods. Review of
Economic Design, 3, 195213.
Bouveret, S., & Lang, J. (2008). Efficiency and envy-freeness in fair division of indivisible goods: Logical representation and complexity. Journal of Artificial Intelligence
Research, 32, 525564.
Brams, S. J., & Kilgour, D. M. (2001). Competitive fair division. Journal of Political
Economy, 109 (2), 418443.
Brandt, F., Conitzer, V., & Endriss, U. (2012). Multiagent Systems, chap. Computational
Social Choices. MIT Press.
Caragiannis, I., Elkind, E., Szegedy, M., & Yu, L. (2012). Mechanism design: from partial
to probabilistic verification. In Proc. of EC12, pp. 266283.
Clarke, E. (1971). Multipart pricing of public goods. Public Choice, 8, 1933.
Deng, X., & Papadimitriou, C. H. (1994). On the complexity of cooperative solution concepts. Mathematics of Operations Research, 19, 257266.
Dobzinski, S., & Dughmi, S. (2009). On the power of randomization in algorithmic mechanism design. In Proc. of FOCS09, pp. 505514.
Dunne, P. E. (2005). Extremal behaviour in multiagent contract negotiation. Journal of
Artificial Intelligence Research, 23, 4178.
Dunne, P. E., Wooldridge, M., & Laurence, M. (2005). The complexity of contract negotiation. Artificial Intelligence, 164 (1-2), 2346.
Endriss, U., Maudet, N., Sadri, F., & Toni, F. (2006). Negotiating socially optimal allocations of resources. Journal of Artificial Intelligence Research, 25, 315348.
Feige, U., & Tennenholtz, M. (2011). Mechanism design with uncertain inputs: (to err is
human, to forgive divine). In Proc. of STOC11, pp. 549558.
Ferrante, A., Parlato, G., Sorrentino, F., & Ventre, C. (2009). Fast payment schemes for
truthful mechanisms with verification. Theoretical Computer Science, 410, 886899.
Gobel, J., Krzesinski, A., & Mandjes, M. (2009). Incentive-based control of ad hoc networks:
A performance study. Computer Networks, 53 (14), 24272443.
Greco, G., & Scarcello, F. (2013). Fair division rules for funds distribution: The case of the
italian research assessment program (vqr 2004-2010). Intelligenza Artificiale, 7 (1),
4556.
Green, J., & Laffont, J. (1977). Characterization of satisfactory mechanisms for the revelation of preferences for public goods. Econometrica, 45 (2), 427438.
Groves, T. (1973). Incentives in teams. Econometrica, 41, 617631.
Haake, C.-J., Raith, M. G., & Su, F. E. (2002). Bidding for envy-freeness: A procedural
approach to n-player fair-division problems. Social Choice and Welfare, 19 (4), 723
749.
446

fiMechanisms for Fair Allocation Problems

Hurwicz, L. (1975). On the existence of allocation systems whose manipulative nash equilibria are pareto optimal. Unpublished paper, presented at the third World Congress
of the Economic Sosciety, Toronto.
Jain, K., & Vazirani, V. (2001). Applications of approximation algorithms to cooperative
games. In Proc. of STOC01, pp. 364372.
Jalali, A., Padovani, R., & Pankaj, R. (2000). Data throughput of cdma-hdr a high efficiencyhigh data rate personal communication wireless system. In Proc. of IEEE VTC00,
Vol. 3, pp. 18541858.
Kalai, E., & Samet, D. (1983). On weighted Shapley values. Discussion papers 602, Northwestern University, Center for Mathematical Studies in Economics and Management
Science.
Klijn, F. (2000). An algorithm for envy-free allocations in an economy with indivisible
objects and money. Social Choice and Welfare, 17 (2), 201215.
Krysta, P., & Ventre, C. (2010). Combinatorial auctions with verification are tractable. In
Proc. of ESA10, pp. 3950.
Liben-Nowell, D., Sharp, A., Wexler, T., & Woods, K. (2012). Computing Shapley value in
supermodular coalitional games. In Proc. of COCOON12, pp. 568579.
Lindner, C. (2010). A market-affected sealed-bid auction protocol. In Proc. of SETN10,
pp. 193202.
Lipton, R. J., Markakis, E., Mossel, E., & Saberi, A. (2004). On approximately fair allocations of indivisible goods. In Proc. of EC04, pp. 125131.
Maniquet, F. (2003). A characterization of the Shapley value in queueing problems. Journal
of Economic Theory, 109 (1), 90103.
Maskin, E. (1987). On the Fair Allocation of Indivisible Goods, pp. 341349. MacMillan.
Meertens, M., Potters, J., & Reijnierse, H. (2002). Envy-free and pareto efficient allocations
in economies with indivisible goods and money. Mathematical Social Sciences, 44 (3),
223233.
Militano, L., Iera, A., & Scarcello, F. (2013). A fair cooperative content-sharing service.
Computer Networks, 57 (9), 19551973.
Mishra, D., & Rangarajan, B. (2007). Cost sharing in a job scheduling problem. Social
Choice and Welfare, 29 (3), 369382.
Moulin, H. (1992). An application of the Shapley value to fair division with money. Econometrica, 60 (6), 133149.
Moulin, H. (1999). Incremental cost sharing: Characterization by coalition strategyproofness. Social Choice and Welfare, 16 (2), 279320.
Moulin, H. (2003). Fair Division and Collective Welfare. MIT Press.
Moulin, H., & Shenker, S. (2001). Strategyproof sharing of submodular costs: budget balance
versus effciency. Economic Theory, 18 (3), 511533.
Nagamochi, H., Zeng, D.-Z., Kabutoya, N., & Ibaraki, T. (1997). Complexity of the minimum base game on matroids. Mathematics of Operations Research, 22, 146164.
447

fiGreco & Scarcello

Nisan, N., & Ronen, A. (2001). Algorithmic mechanism design. Games and Economic
Behavior, 35, 166196.
Nisan, N., Roughgarden, T., Tardos, E., & Vazirani, V. V. (2007). Algorithmic Game
Theory. Cambridge University Press, Cambridge, UK.
Ohseto, S. (2004). Implementing egalitarian-equivalent allocation of indivisible goods on
restricted domains. Economic Theory, 23, 659670 (2004).
Osborne, M. J., & Rubinstein, A. (1994). A Course in Game Theory. The MIT Press,
Cambridge, MA, USA.
Papadimitriou, C. H. (1993). Computational Complexity. Addison-Wesley.
Pathak, A.P., S. T. (2013). Comparing mechanisms by their vulnerability to manipulation.
The American Economic Review, 103 (27), 80106.
Penna, P., & Ventre, C. (2012a). Collusion-resistant mechanisms with verification yielding
optimal solutions. ACM Transaction on Computation Theory, 4 (2), 117.
Penna, P., & Ventre, C. (2012b). Optimal collusion-resistant mechanisms with verification. Games and Economic Behavior, in press, electronically available with doi
10.1016/j.geb.2012.09.002.
Porter, R., Shoham, Y., & Tennenholtz, M. (2004). Fair imposition. Journal of Economic
Theory, 118 (2), 209228.
Potthoff, R. F. (2002). Use of linear programming to find an envy-free solution closest
to the bramskilgour gap solution for the housemates problem. Group Decision and
Negotiation, 11, 405414.
Quinzii, M. (1984). Core and competitive equilibria with indivisibilities. International
Journal of Game Theory, 13, 4160.
Sakai, T. (2007). Fairness and implementability in allocation of indivisible objects with
monetary compensations. Journal of Mathematical Economics, 43 (5), 549563.
Sandholm, T. (1998). Contract types for satisficing task allocation: I theoretical results. In
AAAI Spring Symposium: Satisficing Models.
Schrijver, A. (2003). Combinatorial Optimization: Polyhedra and Efficiency. SpringerVerlag.
Shioura, A., Sun, N., & Yang, Z. (2006). Efficient strategy proof fair allocation algorithms.
Journal of the Operations Research Society of Japan, 49 (2), 144150.
Shoham, Y., & Leyton-Brown, K. (2009). Multiagent Systems. Cambridge University Press.
Su, F. (1999). Rental harmony: Sperners lemma in fair division. American Mathematical
Monthly, 106, 930942.
Svensson, L.-G. (1983). Large indivisibles: An analysis with respect to price equilibrium
and fairness. Econometrica, 51 (4), pp. 939954.
Svensson, L.-G. (2009). Coalitional strategy-proofness and fairness. Economic Theory, 40,
227245.

448

fiMechanisms for Fair Allocation Problems

Tadenuma, K., & Thomson, W. (1991). No-envy and consistency in economies with indivisible goods. Econometrica, 59 (6), 175567.
Tadenuma, K., & Thomson, W. (1993). The fair allocation of an indivisible good when
monetary compensations are possible. Mathematical Social Sciences, 25 (2), 117132.
Tadenuma, K., & Thomson, W. (1995). Games of fair division. Games and Economic
Behavior, 9 (2), 191204.
Thomson, W. (2011). Fair allocation rules. In Kenneth J. Arrow, A. S., & Suzumura, K.
(Eds.), Handbook of Social Choice and Welfare, Vol. 2, pp. 393506. Elsevier.
Valiant, L. G. (1979a). The complexity of computing the permanent. Theoretical Computer
Science, 8 (2), 189201.
Valiant, L. G. (1979b). The complexity of enumeration and reliability problems. SIAM
Journal on Computing, 8 (3), 410421.
Vickery, W. (1961). Counterspeculation, auctions and competitive sealed tenders. Journal
of Finance, 837.
Willson, S. J. (2003). Money-egalitarian-equivalent and gain-maximin allocations of indivisible items with monetary compensation. Social Choice and Welfare, 20, 247259.
Yang, Z. (2001). An intersection theorem on an unbounded set and its application to the fair
allocation problem. Journal of Optimization Theory and Applications, 110, 429443.
Yengin, D. (2012). Egalitarian-equivalent groves mechanisms in the allocation of heterogenous objects. Social Choice and Welfare, 38 (1), 137160.
Young, H. P. (1985). Monotonic solutions of cooperative games. International Journal of
Game Theory, 14, 6572.
Young, H. P. (1994). Equity in Theory and Practice. Princeton University Press.

449

fi