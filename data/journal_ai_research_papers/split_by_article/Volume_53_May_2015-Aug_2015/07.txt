Journal of Artificial Intelligence Research 53 (2015) 541-632

Submitted 01/15; published 07/15

ITSAT: An Efficient SAT-Based Temporal Planner
Masood Feyzbakhsh Rankooh
Gholamreza Ghassem-Sani

feyzbakhsh@ce.sharif.edu
sani@sharif.edu

Computer Engineering Department,
Sharif University of Technology,
Azadi ave., Tehran, Iran

Abstract
Planning as satisfiability is known as an efficient approach to deal with many types of
planning problems. However, this approach has not been competitive with the state-space
based methods in temporal planning. This paper describes ITSAT as an efficient SAT-based
(satisfiability based) temporal planner capable of temporally expressive planning. The
novelty of ITSAT lies in the way it handles temporal constraints of given problems without
getting involved in the difficulties of introducing continuous variables into the corresponding
satisfiability problems. We also show how, as in SAT-based classical planning, carefully
devised preprocessing and encoding schemata can considerably improve the efficiency of
SAT-based temporal planning. We present two preprocessing methods for mutex relation
extraction and action compression. We also show that the separation of causal and temporal
reasoning enables us to employ compact encodings that are based on the concept of parallel
execution semantics. Although such encodings have been shown to be quite effective in
classical planning, ITSAT is the first temporal planner utilizing this type of encoding. Our
empirical results show that not only does ITSAT outperform the state-of-the-art temporally
expressive planners, it is also competitive with the fast temporal planners that cannot
handle required concurrency.

1. Introduction
Temporal planning is an extension of classical planning where actions are durative rather
than being instantaneous. The introduction of durative actions adds a new dimension to
solving planning problems, namely reasoning about time. Temporal reasoning is per se very
different from causal reasoning, because time is a real-valued quantity, whereas the causal
aspects of planning are normally represented by propositions.
The current standard language for defining temporal planning problems is PDDL2.1
(Fox & Long, 2003). Although PDDL+ (Fox & Long, 2002) has been introduced to the
planning community as a more expressive language for defining temporal and numerical
planning problems, throughout this paper, we will focus on PDDL2.1, because the planning
problems that we have tackled do not need the expressive power of PDDL+. In PDDL2.1,
actions can have separate preconditions and effects upon starting and ending. Each temporal
action can also have some invariants, which must be preserved during the execution of that
action. An important subset of problems defined by PDDL2.1 are problems for which every
valid plan includes the concurrent execution of two or more actions. This subset is called the
problems with required concurrency. It has been shown that the concurrent execution of two
actions may be necessary for solving some temporal problems (Halsey, Long, & Fox, 2004;
Cushing, Kambhampati, Mausam, & Weld, 2007). For instance, in some temporal planning
c
2015
AI Access Foundation. All rights reserved.

fiRankooh & Ghassem-Sani

problems, actions may require a proposition that is only available during the execution of
another action. In such cases, these two actions must be executed concurrently. A more
specific example is given in Section 2, where we describe the Driverlogshift domain. A
common approach in many planners that are not temporally expressive is to eliminate such
cases by compressing all temporal actions to create non-durative classical actions.
In this paper, we describe ITSAT, a temporally expressive SAT-based (i.e., satisfiability
based) planner. ITSAT uses an approach that takes advantage of parallel execution semantics without rendering it incomplete for the problems with required concurrency. In this
approach, the durations of all actions of a given problem are first abstracted out. This is
done by breaking each temporal action into two starting and ending instantaneous events.
Then the obtained temporally abstract problem is encoded into a SAT formula using novel
-step and -step semantics for causally valid plans. We show how these semantics can be
used to encode a given temporal planning problem into a SAT formula. Classical -step
and -step encoding methods have been introduced before (Rintanen, Heljanko, & Niemela,
2006). In addition to extending these methods to the temporal planning context, we also
introduce a new encoding method based on -step semantics for causally valid plans. We
show that our new encoding often results in a significant reduction of the number of required
steps.
After generating a causally valid plan, ITSAT performs a scheduling phase. During this
phase, ITSAT tries to satisfy those temporal constraints that are imposed by considering the
durations of actions. This is done by solving a Simple Temporal Problem (STP) (Dechter,
Meiri, & Pearl, 1991). However, for problems with required concurrency, the posed STP
may be inconsistent. In such cases, the cause of inconsistency, which manifests itself as a
negative cycle in the corresponding Simple Temporal Network (STN), is detected. ITSAT
then generates a number of clauses that if added to the SAT formula, collectively prevent
the reoccurrence of the particular negative cycle that has occurred and other similar cycles.
This process is repeated until a temporally valid plan is found.
Similar to other SAT-based planners, ITSAT takes advantage of a preprocessing phase
to extract some information about the structure of problems. Such information is used
throughout the encoding phase to produce a formula whose satisfiability can be checked
more efficiently by the SAT solver. In Section 3, we describe the preprocessing phase of
ITSAT, which includes the reasoning about mutual exclusion and the so-called safe action
compression (Coles, Coles, Fox, & Long, 2009). Two propositions are regarded as mutually
exclusive if they can never be jointly true in the same state of a valid temporal plan. Here, we
show that one can detect the mutually exclusive propositions of temporal problems by using
planning graph analysis (Blum & Furst, 1997). It is known that employing mutual exclusion
reasoning can significantly improve the performance of SAT-based planners (Gerevini &
Schubert, 1998).
As we mentioned earlier, ITSAT breaks down each temporal action into two starting
and ending instantaneous events. Although in some cases such breaking down might be
necessary for producing concurrent plans, there are situations where this is not necessary
for finding valid plans. In Section 3, we show that by using the mutual exclusion information,
one can identify those temporal actions that can safely be compressed into a classical action
without falsifying the validity of temporal plans. This analysis results in a smaller number
of distinct events and therefore a simpler planning problem.
542

fiITSAT: An Efficient SAT-Based Temporal Planner

We empirically show that by taking advantage of its preprocessing, encoding, and
scheduling phases, not only does ITSAT significantly outperform state-of-the-art temporally expressive planners, it is also competitive with the best temporally simple planners
which are incapable of solving problems with required concurrency property. The components of ITSAT are shown in Figure 1. In this figure, the processing components of
ITSAT system are shown by rectangular blocks, while links represents the data produced
and received by these components.

Figure 1. The block diagram of ITSAT

543

fiRankooh & Ghassem-Sani

1.1 Motivation
As we mentioned earlier, temporal planners need to reason about time, which is a continuous
quantity. Nevertheless, causal structures of problems in temporal planning are still very
similar to those in classical planning. The existence of abundant temporal planning domains
that also have classical versions can be regarded as an evidence to this claim. This suggests
that temporal planners can benefit from using approaches that have been previously shown
to be effective in dealing with classical problems.
The usage of Boolean satisfiability checking is a well-known paradigm in tackling classical
planning problems (Kautz & Selman, 1992). In this approach, a given planning problem is
translated into a formula in propositional logic. Each variable of the SAT formula typically
represents the occurrence of the corresponding action or proposition in a certain place of
potential plan. The causal constraints of the planning problem are represented by a number
of ground clauses. The output plan is assumed to have a finite number of steps. Each step
may include one or more actions. The original SAT-based planner allowed only one action
per step (Kautz & Selman, 1992). However, the previously introduced SAT-based planners
allow multiple occurrence of actions in each step. The produced formula is given as the
input to an off-the-shelf SAT solver, which tries to find a model for it. If such a model is
found, a plan is extracted from it. Otherwise, the number of steps in the output plan is
increased by one and the corresponding SAT formula is given again to the SAT solver. This
process is repeated until a valid plan is extracted or some predefined termination condition
is reached. In order to obtain an efficient SAT-based planner, one important issue that
should be considered is how to encode the given planning problem into a SAT formula.
SAT-based planning was originally used to find optimal plans, i.e., plans with minimum
number of actions (Kautz & Selman, 1992). To guarantee the optimality of the output plan,
the formula must include certain clauses to ban each step from containing more than one
action. However, in the so-called satisficing planning, in which optimality is not the main
objective, forcing single-action steps is not necessary. An alternative approach is to consider
actions that can be executed in parallel in each step of the output plan (Ernst, Millstein,
& Weld, 1997). Exploiting such parallelism can result in a smaller number of steps in the
SAT formula. Another important benefit of producing compact formulae is lower memory
requirements. Several encoding methods have been introduced to take advantage of action
parallelism. These encoding methods are based on the so-called -step and -step semantics
of valid plans (Rintanen et al., 2006).
The -step and -step semantics are different in the extent of action parallelism that they
allow to occur in each step. The -step semantics allows a set of actions to be executed in
parallel, only if those actions can be executed in every possible ordering without affecting the
validity of the plan. The -step semantics, on the other hand, imposes a weaker restriction:
for each step of a plan, there must exist at least one possible ordering in which the actions
can be executed without falsifying the validity of the plan. It should be clear that the -step
semantics potentially allows more parallelism than is permitted by the -step semantics. In
fact, by taking advantage of -step semantics, the most efficient SAT-based classical planner,
i.e., Mp (Rintanen, 2012), is competitive with the state-of-the-art state-space planners. In
this paper, we show that the separation of causal and temporal reasoning phases of temporal
planning enables us to employ these compact encodings for efficient temporal planning.
544

fiITSAT: An Efficient SAT-Based Temporal Planner

1.2 Related Work
Previous research in the field of temporal planning has benefited enormously from employing
well-developed classical planning strategies. For instance, many successful temporal planners have utilized the ideas of partial order planning, e.g. VHPOP (Younes & Simmons,
2003) and CPT (Vidal & Geffner, 2006). Planning graph analysis has also been adopted by
temporal planners such as TGP (Smith & Weld, 1999) and TPSYS (Garrido, Fox, & Long,
2002). Some other temporal planners have embedded temporal reasoning into heuristic
state space search. TFD (Eyerich, Mattmuller, & Roger, 2009), LPG-td (Gerevini, Saetti,
& Serina, 2006), and POPF (Coles, Coles, Fox, & Long, 2010) are the successful instances
of this latter approach.
The usage of Boolean satisfiability checking is one of the well-known paradigms in tackling classical planning problems (Kautz & Selman, 1992). In order to obtain an efficient
SAT-based planner, one important issue that should be considered is how to encode the
given planning problem into a SAT formula. In fact, devising efficient encoding methods
has been an important research trend in the field of SAT-based planning. Examples of
efficient encodings are: the split action representation (Kautz & Selman, 1996; Ernst et al.,
1997; Robinson, Gretton, Pham, & Sattar, 2009), the SAS+ based encoding (Huang, Chen,
& Zhang, 2012), and the compact mutual exclusion representation (Rintanen, 2006). Based
on parallel semantics of plans, another effective encoding method has been introduced (Rintanen et al., 2006). This latter encoding method is of particular interest in this paper.
Satisfiability checking has also been employed in the field of temporal planning. However,
SAT-based temporal planners do encounter a major challenge: representing temporal aspects of problems. Since time is a continuous quantity, it cannot be treated in the exact same
way in which discrete causality is handled. To tackle this problem, STEP (Huang, Chen, &
Zhang, 2009), SCP2 (Lu, Huang, Chen, Xu, Zhang, & Chen, 2013), and T-SATPLAN (Mali
& Liu, 2006) use a discrete representation of time. These planners assign explicit discrete
time labels to each step of the encoding. Generally speaking, in this approach, each step i
is exactly one time unit ahead of step i + 1. As a result, if an action with duration d starts
in step i, it is forced to end in step i + d. One immediate outcome of such an approach
is the introduction of an enormous number of steps into the encoding, many of which will
not contribute to the output plan. This drawback of the explicit time representation causes
STEP, SCP2, and T-SATPLAN to be inefficient in terms of both speed and memory usage. To obtain a better performance, SCP2 uses -step semantic to allow causal relations
between actions in each time point (Lu et al., 2013).
TM-LPSAT (Shin & Davis, 2005), which has been designed to solve planning problems
defined in PDDL+ (Fox & Long, 2002), is another SAT-based planner capable of handling
temporal planning problems. Similar to STEP and T-SATPLAN, TM-LPSAT attaches
time labels to each step. However, in TM-LPSAT, these labels are not predefined discrete
numbers. Instead, each label is a numeric variable whose value will be determined after
the problem is solved by an SMT solver (Armando & Giunchiglia, 1993). This approach
can result in encodings which are more compact than those produced by STEP and TSATPLAN.
A major disadvantage of assigning a time label to each step of the formula is that the parallelism mentioned above cannot be exploited effectively. That is because when two events
545

fiRankooh & Ghassem-Sani

are to happen in a certain step of the plan, their time labels must be the same, and thus,
they must be simultaneous when the final plan is executed. This compulsory simultaneity
is a restriction that reduces the number of events that can happen in each step of the final
plan, which in turn, increases the number of steps needed for solving input problems. This
implies that all the efficiency gain one could obtain from using parallel execution semantics
will be sacrificed to achieve an easy way to deal with temporal constraints. However, in the
majority of current temporal planning problems, satisfying temporal constrains is not the
hardest task in finding a valid plan. It was shown that for the problems without required
concurrency, one can omit the temporal constraints altogether, find a causally valid plan,
and then, by considering temporal constraints only in a postproccessing step, schedule the
actions of that plan to find a temporally valid plan (Cushing et al., 2007). This approach
has actually been used by many previous temporal planners including YAHSP3-mt (Vidal,
2014), the winner of the temporal satisficing track of IPC 2014. Despite being efficient in
solving many temporal problems, such planners are incomplete, as they are incapable of
solving problems with required concurrency.
In addition to classical planning problems, SAT-based methods have also been used to
deal with other categories of planning problems. Examples are planning under uncertainty
(Castellini, Giunchiglia, & Tacchella, 2003), cost-optimal planning (Robinson, Gretton,
Pham, & Sattar, 2010) and numerical planning (Hoffmann, Gomes, Selman, & Kautz,
2007).

2. Preliminaries
The standard language used for defining temporal planning problems is PDDL2.1 (Fox &
Long, 2003). Figure 2 presents an example of the PDDL2.1 representation of a temporal
planning domain. This domain, which is a simplified version of Driverlogshift (Halsey, 2004),
will be referred to several times throughout this paper. As Figure 2 shows, in PDDL2.1,
each action can have separate conditions and effects upon starting and ending. The starting
and ending conditions (or effects) of an action are specified by the at start and at end
tokens, respectively. Each action may also have some conditions that need to be preserved
during execution. These conditions are specified using the over all token. Moreover, the
duration of each action is defined by an (= ?duration x) statement, where x is a rational
number or a function specifying the actual duration of that action.
Driverlogshift is the temporal version of the Driverlog domain from IPC3. As in its
classical counterpart, in Driverlogshift, the objective is to transfer several objects from their
original places to their destinations. Each object can be loaded into and unloaded from a
certain truck by using the LOAD and UNLOAD operators, respectively. A truck can move
between locations using the MOVE operator. The main difference between Driverlogshift and
Driverlog is that the trucks here must be rested during the intervals between their working
shifts. Each working shift is defined by the WORK operator, which produces the (working
truck) proposition upon starting, and deletes that proposition upon ending. LOAD, UNLOAD,
and MOVE have (working truck) as their invariant. Once (working truck) is deleted by
the ending of WORK, it may be reproduced by the REST operator, which defines the resting
shift of a certain truck.
546

fiITSAT: An Efficient SAT-Based Temporal Planner

(define (domain driverlogshift)
(:requirements :typing :durative-actions)
(:types
location locatable - object
truck obj - locatable)
(:predicates
(at ?obj - locatable ?loc - location)
(in ?obj1 - obj ?obj - truck)
(link ?x ?y - location)
(working ?t - truck)
(need-rest t - truck)
(rested t - truck))
(:durative-action WORK
:parameters
(?truck - truck)
:duration (= ?duration 100)
:condition (and
(at start (rested ?truck)))
:effect (and (at start (working ?truck))
(at end (not (working ?truck)))
(at start (not (rested ?truck)))
(at end (need-rest ?truck))))
(:durative-action REST
:parameters
(?truck - truck)
:duration (= ?duration 20)
:condition (and
(at start (need_rest ?truck)))
:effect (and
(at start (not (need_rest ?truck)))
(at end (rested ?truck))))
(:durative-action LOAD
:parameters
(?obj - obj
?truck - truck
?loc - location)
:duration (= ?duration 10)
:condition (and
(over all (at ?truck ?loc))
(over all (working ?truck))
(at start (at ?obj ?loc)))
:effect (and
(at start (not (at ?obj ?loc)))
(at end (in ?obj ?truck))))

(:durative-action UNLOAD
:parameters
(?obj - obj
?truck - truck
?loc - location)
:duration (= ?duration 10)
:condition (and
(over all (at ?truck ?loc))
(over all (working ?truck))
(at start (in ?obj ?truck)))
:effect (and
(at start (not (in ?obj ?truck)))
(at end (at ?obj ?loc))))
(:durative-action MOVE
:parameters
(?truck - truck
?loc-from - location
?loc-to - location)
:duration (= ?duration 50)
:condition (and
(at start (at ?truck ?loc-from))
(at start (link ?loc-from ?loc-to))
(over all (working ?truck)))
:effect (and
(at start (not (at ?truck ?loc-from)))
(at end (at ?truck ?loc-to)))))

Figure 2. PDDL2.1 description of Driverlogshift domain

Note that the version of Driverlogshift described in Figure 2 is slightly different from
its original version (Halsey, 2004), in which there are drivers that can walk to, board, and
disembark trucks. Furthermore, the REST and WORK actions are performed by the drivers
rather than trucks. However, in order to make the examples simpler, we have merged drivers
and trucks into a single entity of just trucks.
A simple example of problems in Driverlogshift is shown in Figure 3. In this problem,
there are three locations (s0, s1, and s2), one truck (truck1), and one object (package1).
In the initial state, truck1 and package1 are at s0. The objective of the problem is to
transfer package1 to s2.
2.1 Formalism of PDDL2.1
Now we present our formalism of the specifications of PDDL2.1. Our formalism is devised in
a way that simplifies the description of the preprocessing, encoding, and scheduling phases
of ITSAT. We should mention that our formalism has some limitations compared to the
full specifications of PDDL2.1. These limitations will be discussed in details in Section 2.2.
547

fiRankooh & Ghassem-Sani

(define (problem DLOG)
(:domain driverlogshift)
(:objects
truck1
- truck
package1 - obj
s0 s1 s2 - location)
(:init
(rested truck1)
(at truck1 s0)
(at package1 s0)
(link s0 s1)
(link s1 s0)
(link s2 s1)
(link s1 s2)
)
(:goal (and
(at package1 s2))))

Figure 3. PDDL2.1 description of a problem in Driverlogshift domain

Definition 1 (events). An event, e, is a triple (pre(e), add(e), del(e)), where pre(e),
add(e), and del(e) are three sets of atomic propositions (facts) representing preconditions,
positive effects, and negative effects of e, respectively.
Definition 2 (temporal actions) A temporal action, a, is a quadruple (start(a), end(a),
inv(a), dur(a)), where start(a) and end(a) are two events denoting the starting and ending
events of a, inv(a) is a set of atomic propositions representing the invariants of a, and
dur(a) is a positive rational number specifying the duration of a.
Example 1. Figure 4 shows a temporal action a = LOAD(package1, truck1, s0), which
is an instance of the LOAD operator defined in Figure 2. In Figure 4, a is depicted by a rectangular box. Conditions and effects of a are written above and below the box, respectively.
The at start conditions and effects of a are placed at the left hand side of the box, and
the at end conditions and effects are placed at the right hand side of the box. The over
all conditions of a are placed at the middle of the box. Here, start(a) and end(a) are
two events, where pre(start(a)) = {(at package1 s0)}, add(start(a)) = , del(start(a)) =
{(at package1 s0)}, pre(end(a)) = , add(end(a)) = {(at package1 truck1)}, and also
del(end(a)) = . Moreover, we have inv(a) = {(at truck1 s0), (working truck1)}, and
dur(a) = 10.
548

fiITSAT: An Efficient SAT-Based Temporal Planner

Figure 4. A temporal action

Definition 3 (temporal states). A temporal state, s, is a pair (state(s), agenda(s)),
where state(s) is a classical planning state represented by a set of atomic propositions, and
agenda(s) contains a finite set of open actions (i.e., actions started prior to s and not yet
ended).
Definition 4 (applicability). The starting event e of an action a is applicable in state s,
if the following conditions hold:
(1) state(s) contains all the preconditions of e and
S all the invariants of a (except for those
invariants of a that are added by e): pre(e) (inv(a)  add(e))  state(s)
(2) a is not already open in s: a 
/ agenda(s)
(3) eSdoes not delete theTinvariants of any open action of s:

del(e) = 
a agenda(s) inv(a )
The ending event e of an action a is applicable in state s, if the following conditions hold:
(1) state(s) contains all the preconditions of e: pre(e)  state(s)
(2) a is open in s: a  agenda(s)
(3) S
e does not delete the invariants
of any open action of s (other than a):
T
)
inv(a
del(e)
=
a agenda(s){a}
Definition 5 (successors). If the starting event e of action a is applicable in state s, it
will change s to the unique state s satisfying the following conditions:


 The set of open
S actions of s is equal to the set of open actions of s with a: agenda(s ) =
agenda(s) {a}

 All positive and negative effects
S of e are respectively added to and deleted from s :

state(s ) = (state(s)  del(e)) add(e)

If the ending event e of action a is applicable in state s, it will change s to the unique state
s satisfying the following conditions:
549

fiRankooh & Ghassem-Sani

 The set of open actions of s is equal to the set of open actions of s without a:
agenda(s ) = agenda(s)  {a}
 All positive and negative
effects of e are respectively added and deleted in s : state(s ) =
S
(state(s)  del(e)) add(e)
From now on, we may use succ(s, e) to represent the successor state s obtained by applying
e to s.
Definition 4 and Definition 5 can be easily extended to also cover any sequence of events:
succ(s, he1 , ..., en i) = succ(succ(s, he1 , ..., en1 i), en ), and succ(s, hi) = s. A sequence of
events he1 , ..., en i is applicable in a temporal state s, if succ(s, he1 , ..., en i) is defined.
Example 2. Let s be a temporal state such that
state(s) = {(at package1 s0), (at truck1 s0), (working truck1), (link s0 s1)}
and
agenda(s) = .
Let a = LOAD(package1, truck1, s0) and a = MOVE(truck1, s0, s1) be two temporal actions, which are respectively instances of the LOAD and MOVE operators presented in Figure
2. the event start(a) is applicable in s and it changes s to s such that
state(s ) = {(at truck1 s0), (working truck1), (link s0 s1)}
and
agenda(s ) = {LOAD(package1, truck1, s0)}.
Now, start(a) is not applicable in s because a is already open in s . Nor isstart(a ) applicable in s , as it deletes (at truck1 s0) that is an invariant of a, which is still open in s .
However, end(a) is applicable in s and changes it to s such that
state(s ) = {(at package1 truck1), (at truck1 s0), (working truck1), (link s0 s1)}
and
agenda(s ) = .

Definition 6 (temporal problems). A temporal problem, P, is a triple (I, G, A), where
I, representing the initial state, is a temporal state such that agenda(I) = . G is a set
of atomic propositions denoting the goal conditions, and A is the finite set of all possible
temporal actions of P.
Definition 7 (causally valid plans). Let P = (I, G, A) be a temporal problem and
 = he1 , ..., en i be a sequence of events where for each i, ei is a starting or an ending event of
an action in A.  is a causally valid plan for P, if it is applicable in I, G  state(succ(s, )),
and agenda(succ(s, )) = .
550

fiITSAT: An Efficient SAT-Based Temporal Planner

Definition 8 (pairing events). Let  = he1 , ..., en i be a causally valid plan for problem P = (I, G, A). Assume that ei and ej are respectively the starting and ending events of
a certain action a  A and i < j. If for all k such that i < k < j, ek is neither the starting
nor the ending event of a, we say that ei (ej ) is the pairing event of ej (ei ) in . In other
words, ei and ej are pairing events in  if they are related to the same occurrence of a in .
Definition 9 (valid temporal plans and makespan). Let  = he1 , ..., en i be a causally
valid plan for P = (I, G, A), and  : {1, ..., n}  Q be a scheduling function for , where Q
is the set of rational numbers. (,  ) is a valid temporal plan for P if  has the following
properties:
 For all i,  (i) <  (i + 1).
 For each a  A, if start(a) = ei , and ej is the pairing event of ei , then  (j) =
 (i) + dur(a).
The maximum value assigned by  to the events of  is called the makespan of .
Example 3. Consider the problem P = (I, G, A) depicted in Figure 3, where state(I)
and G contain the propositions listed after the labels :init and :goal, respectively, and A
is the set of all possible instantiations of operators presented in Figure 2 with the objects
listed after label :objects of Figure 3. Let
 = hstart(WORK(truck1)),
start(LOAD(truck1, package1, s0)),
end (LOAD(truck1, package1, s0)),
start(MOVE(truck1, s0, s1)),
end (MOVE(truck1, s0, s1)),
start(MOVE(truck1, s1, s2)),
end (MOVE(truck1, s1, s2)),
start(UNLOAD(truck1, package1, s2)),
end (UNLOAD(truck1, package1, s2)),
end (WORK(truck1))i
A schematic representation of  is depicted in Figure 5. A straightforward checking shows
that  is a causally valid plan for P. However,  is not a valid temporal plan because the
duration of WORK(truck1) is 100,  requires the serial execution of two MOVE actions, one
LOAD action, and one UNLOAD action, with the total duration of 120, while WORK(truck1)
is still open. In other words, one single working shift of truck1 is not sufficient to transfer
package1 from s0 to s2. Therefore, no scheduling function  with the properties of
Definition 9 exists for . A valid temporal plan for P is depicted in Figure 6. In this
plan, two working shifts of truck1 are used.
551

fiRankooh & Ghassem-Sani

Figure 5. A causally valid plan

Figure 6. A valid plan

2.2 Limitations
We end this section by describing the differences between our formalism of valid temporal
plans and that of PDDL2.1. The main limitations of our formalism are listed below:
 According to Definition 4, the starting event of an action a is applicable in the state
s only if a is not already open in s. This means that, similar to many previous
temporal planners, we do not permit two versions of the same action to overlap.
Consequently, the current implementation of ITSAT does not allow self-overlapping
actions. However, the specification of PDDL2.1 allows plans to have such actions,
which have been shown to be necessary for solving certain temporal problems (Fox &
Long, 2007). Our experimental results indicate that this restriction does not render
ITSAT incapable of solving current benchmark problems. Nevertheless, it has been
shown that, in theory, having self-overlapping actions may cause the complexity of
temporal planning to become EXPSPACE-hard rather than PSPACE-hard (Rintanen,
2007).
 Our formalism does not allow two or more events to be simultaneously applied to any
state. As an example of cases where such a simultaneity is required, consider two
temporal actions a and b, such that the starting event of a adds an invariant of b,
552

fiITSAT: An Efficient SAT-Based Temporal Planner

and the starting event of b adds an invariant of a. In this case, it might be necessary
to simultaneously apply the starting event of both actions to a given state. It is not
clear from the specification of PDDL2.1 whether such a simultaneity is permitted or
not. On the other hand, it has been shown that almost none of current benchmark
problems require such a simultaneity for being solvable (Rankooh & Ghassem-Sani,
2013).
 PDDL2.1 allows the usage of numerical variables. This is not supported by ITSAT.
PDDL2.1 also allows duration dependent effects and state dependent durations for
actions in numerical planning problems. These features are not supported by ITSAT
either; because ITSAT does not currently handle numerical fluents.
 According to our formalism, the duration of a temporal action is defined by an (=
?duration x) assignment, where x is a rational number or a function specifying
the actual duration of that action. PDDL2.1, on the other hand, also allows using
inequalities such as ( ?duration x) and ( ?duration x) to define a range for
the duration of any temporal action. Nevertheless, the current benchmark problems
do not include such inequalities. Although the current implementation of ITSAT does
not support these inequalities, it is quite easy to include this feature, as these kinds
of constraints on the duration of actions are handled by Simple Temporal Problems
(Dechter et al., 1991).

3. Preprocessing Phase
Preprocessing is an important phase in many planners. The main objective of this phase
is to extract certain information from the problem. This information can later be used to
enhance search performance. One important issue that should be addressed when devising
any preprocessing method is the correctness of extracted information. In other words, the
constraints inferred during the preprocessing phase must be correct in the sense that, it
does not cause the planner to become incapable of finding valid plans. Moreover, for a
preprocessing method to be effective, it is required to be performed in at most polynomial
time. In this section, we explain two different preprocessing methods used by ITSAT: mutual
exclusion analysis and action compression. We also formally prove that these methods are
both correct and can be performed in polynomial time.
3.1 Mutual Exclusion Analysis
Mutual exclusion analysis is a preprocessing method to find pairs of propositions that cannot be mutually true in any state of a valid plan. SAT-based planners typically add an
explicit clause to their SAT formula for each pair of mutually exclusive propositions. Such
clauses prevent mutually exclusive pairs of propositions from being true true at the same
time. Although such information can be obtained through the search phase itself, by acquiring it beforehand, one can prune the search tree of the SAT solver and thereby improve
performance.
Polynomial time mutual exclusion analysis for classical planning problems was originally performed by constructing planning graphs, a data structure which was introduced
553

fiRankooh & Ghassem-Sani

in GRAPHPLAN (Blum & Furst, 1997). It has been shown that the mutual exclusion
information obtained from planning graphs can be quite effective in improving the performance of SAT-based planners (Gerevini & Schubert, 1998). Other methods have also been
introduced to compute n-way mutexes (instead of the pairwise mutexes computed by the
planning graphs). The hn heuristic (Haslum & Geffner, 2000), which analyzes the reachability of any set of n propositions from the initial state, is an example of such methods.
It has been shown that a generalization of the hn heuristic can be efficiently computed by
using a syntactic regression operation (Rintanen & Gretton, 2013).
The method used by ITSAT for finding mutual exclusion relations is based on the
planning graph analysis. A classical planning graph is a layered structure. The first layer
includes all the propositions that are present in the initial state of the problem. In each
layer of planning graph, mutual exclusion (mutex ) relations between pairs of proposition
are computed. Two propositions are non-mutex in the first layer if and only if they are
both present in the initial state. An action is applicable in a layer if all its preconditions
are non-mutex in that layer. Two different actions are mutex in layer i, if at least one of
the following conditions holds: 1) they have interference with each other (i.e., one action
deletes any effect of the other action), 2) they have conflict with each other (i.e., one action
deletes any precondition of the other action), or 3) their preconditions are mutex in layer i.
Layer i + 1 includes all the effects of the actions applicable in layer i. Two propositions that
are mutex in layer i become non-mutex in layer i + 1 if they are produced by non-mutex
actions of layer i. To transfer propositions from one layer to the next layer, there exists a
special noopp action for each proposition p that both requires and adds p. The construction
of planning graph may continue until no change take places between two consecutive layers.
In that case, we say the graph has leveled off.
Planning graphs have previously been employed to tackle temporal planning problems
(Smith & Weld, 1999). In fact, the first completely domain-independent temporal planner
called TGP, was an extension of GRAPHPLAN (Blum & Furst, 1997). TGP requires all
preconditions of each temporal action to be preserved throughout the time that the action
is open, and also does not allow actions to have effects upon starting. As a result, TGP
is not compatible with the requirements of PDDL2.1. TPSYS (Garrido et al., 2002), an
extension of TGP, is another planning graph based temporal planner that can produce
plans in domains with required concurrency. Similar to GRAPHPLAN, in addition to the
construction of a planning graph, both TPSYS and TGP perform a backward search for a
valid temporal plan.
LPGP (Long & Fox, 2003) is another planning graph based temporal planner. In LPGP,
the mutex relations between proposition and actions are computed by considering only
the causal constraints of the problem; whereas the temporal constraints are taken into
account later while a plan is being extracted by solving a Linear Programming (LP) problem.
Omitting the temporal constraints of the problem is done by converting the given temporal
problem into a classical problem. As a result, the graph construction of LPGP is very
similar to that of GRAPHPLAN.
As mentioned earlier, in ITSAT, the temporal constraints of the problem are considered
only after a causally valid plan is produced. Therefore, those constraints are not needed to
be dealt with in the planning graph construction phase. This makes the graph structure of
LPGP suitable for ITSAT. Here, we explain the graph construction phase of LPGP. The
554

fiITSAT: An Efficient SAT-Based Temporal Planner

correctness of mutual exclusion information obtained by this method is essential for the
correctness of our action compression and SAT encoding methods. However, the description
of LPGP was not accompanied by any formal proof of correctness. Therefore, here, we
formally prove the correctness and tractability of this preprocessing method.
Definition 10 (causal abstraction of temporal problems). Let P = (I, G, A) be a
temporal planning problem and Ac be a set of classical actions such that for each a  A
there are exactly three classical actions as , ai , and ae in Ac , with the following properties:
 pre(as ) = pre(start(a))  (inv(a)  add(a))
 add(as ) = add(start(a))  {opena }, where opena is a new proposition specifying that
a is started but not yet finished
 del(as ) = del(start(a))  add(start(a))
 pre(ai ) = inv(a)  {opena }
 add(ai ) = inv(a)  {opena }
 del(ai ) = 
 pre(ae ) = pre(end(a))  {opena }
 add(ae ) = add(end(a))
 del(ae ) = (del(end(a))  add(end(a)))  {opena }
The causal abstraction of P is the classical problem P c = (state(I), G, Ac ).
In fact, by Definition 10, to produce a causal abstraction of a given temporal planning problem, we split any temporal action a into three classical actions as , ai , and ae .
Actions as and ae correspond respectively to the starting and ending events of a. In addition to their normal effects and preconditions, as adds a special proposition named opena ,
which is required and deleted by ae . The action ai is called the invariant checking action
of a, and requires all invariants of a plus opena as its preconditions, and produces opena as
its effect.
For a given temporal planning problem P = (I, G, A), ITSAT produces
c
P = (state(I), G, Ac ) i.e., the causal abstraction of P. ITSAT then constructs a classical planning graph for P c .
The planning graph in ITSAT is very similar to that of GRAPHPLAN. There is only one
difference between the planning graphs of these two planners. In GRAPHPLAN, as mentioned earlier, all propositions are propagated through layers by the so-called noop actions.
However, in ITSAT, there is an exception to this usage of noop actions: the new proposition
of form opena introduced by our causal abstraction of action a. This particular proposition
is propagated by ai , the invariant checking action of a. Therefore, ai can be seen as a new
kind of noop action used to cover the invariants during the reasoning about mutex relations.

555

fiRankooh & Ghassem-Sani

Theorem 1. Let P = (I, G, A) be a temporal planning problem and P c = (state(I), G, Ac )
be the causal abstraction of P. Let  = he1 , ..., en i be any finite sequence of events that is
applicable in I, and sn = succ(I, ). Then the following conditions must hold:
 If two propositions p and q are both members of state(sn ), then p and q are non-mutex
in the layer n of the planning graph of P c .
 If proposition p is a member of state(sn ), and action a is a member of agenda(sn ),
then p and opena are non-mutex in layer n of the planning graph of P c .
Proof. See Appendix A.
After a planning graph has been leveled off, all the subsequent extensions of the graph
has no effect on the new layers. Therefore, if two propositions are mutex in the last layer of
a leveled-off graph, they will remain mutex in all subsequently produced layers. In this case,
Theorem 1 implies that such pairs of propositions can never appear at the same temporal
state during the execution of a valid temporal plan. The only matter that remains is to
show that the mutual exclusion analysis of ITSAT can be performed in polynomial time.
Let P be a temporal planning problem, and P c be the causal abstraction of P. It can be
deduced from Definition 10, that the size of P c is greater than that of P only by a constant
factor. The process of constructing the planning graph of P c can be obtained by modifying
the construction process of planning graphs in GRAPHPLAN planner, in such a way that
for any temporal action a, noopopena is never used. GRAPHPLAN constructs its planning
graphs in polynomial time (Blum & Furst, 1997). Therefore, the overall time needed for
the mutual exclusion analysis of ITSAT is also polynomial in the size of any given temporal
planning problem.
3.2 Action Compression
Temporal actions can have a variety of temporal relations with one another. A popular
model for representing temporal relations between actions was initially introduced by James
Allen (1984). The model included 13 possible temporal relations between any two actions.
Some of Allens temporal relations require the starting and/or ending events of actions to
be executed simultaneously. As it was mentioned in Section 2.2, none of the temporal plans
produced by ITSAT can necessitate such a simultaneity. As a result, the set of temporal
relations between any two temporal actions will be confined to a proper subset of all Allens
temporal relations. These possible temporal relations are depicted in Figure 7. As it is
shown in Figure 7, in 4 out of 6 types of these relations, the actions are concurrent, i.e.,
there exists a time in which the two actions are both being executed. Such a concurrency is
unnecessary for solving some temporal planning problems. If we know that two actions are
not required to be concurrently executed, in order to find a valid plan, checking only the
two temporal relations depicted in Figure 7-(c) is sufficient in the searching phase of any
planner. However, if all valid plans include concurrent executions of two or more actions,
restricting the temporal relations of actions to just the two relations depicted in Figure
7-(c) will render the planner incomplete.

556

fiITSAT: An Efficient SAT-Based Temporal Planner

Figure 7. Temporal relations between two PDDL2.1 actions

Definition 11 (compression-safe sets of actions and compressed plans). Let
P = (I, G, A) be a temporal planning problem for which there exists at least one valid
temporal plan, and A be a subset of A. We say A is compression-safe for P, if there exists
a causally valid plan for P that is compressed with respect to A . A causally valid plan
 = he1 , ..., en i is compressed with respect to A if it has the following property:
 For each k, if ek is the starting event of action a  A , then ek+1 is the ending event
of a.
According to Definition 11, the starting and ending events of all members of A are
assumed to be executed consecutively in at least one causally valid plan. Therefore, while
that plan is being executed, no other event is causally needed to happen between the starting
and ending of any member of A . This suggests that members of A can be regarded as a
single event in the environment, rather than having two separate starting and ending events.
557

fiRankooh & Ghassem-Sani

In other words, for each member of A , we can compress the starting and ending events
into a single event without rendering the problem unsolvable. As an example, consider the
DRIVERLOGSHIFT temporal planning problem presented in Example 3. The plan  presented
in Example 3 shows that the set of all LOAD, MOVE, and UNLOAD actions is a compressionsafe set of actions for that problem. A straightforward analysis of this example shows that
neither of WORK actions presented in Example 3 can be a member of any compression-safe
subset of actions.
Note that, according to Definition 11, only a causally valid plan can be regarded as a
compressed sequence of events. Although the concept of compression can be extended to
cover even those sequences of events that do not lead to any goal state, for the sake of
simplicity, we have focused our attention to only those sequences that are causally valid
plans, and defined compression-safe actions only for solvable temporal planning problems.
As we explain later in Section 4, the information obtained by our compression-safety analysis
is incorporated into the encoding of the problem by adding some extra SAT formulae, which
makes the problem at hand tighter. In other words, this information is only used to prune
the search space of the SAT solver. As a result, our handling of compression-safety can
never cause the planner to produce any (invalid) plan for an unsolvable planning problem.
Safe action compression has been employed before in the field of temporal planning
(Coles et al., 2009). It has been shown that in the temporal problems that do not possess the
property of required concurrency, all temporal actions can be safely compressed into classical
actions (Cushing et al., 2007). A temporal problem is said to have required concurrency, if
its every valid temporal plan includes at least one action whose execution overlaps with the
execution of some other action. In the problems without required concurrency, all temporal
actions can be compressed into classical actions. In this case, the problem is transformed
into a classical planning problem. This phenomenon is completely consistent with the
semantics of Definition 11, as it can be easily shown that in the problems without required
concurrency, the set of all actions is indeed a compression-safe set of actions. However,
as it is the case in Example 3, even when the problem does have the required concurrency
property, there may still exist a non-empty compression-safe set of actions.
CRIKEY3 and its successor, POPF, are two state-space based temporal planners that
detect the compression-safe actions as a preprocessing task (Coles et al., 2009). However,
the concept of compression-safety in those planners is different from what we presented
in Definition 11. CRIKEY3 does not assume that the ending event of a compression-safe
action must be executed immediately after its corresponding starting event. Instead, once
the starting event of a compression-safe action is applied to a state, using a simple inference
method, CRIKEY3 can determine when to apply the corresponding ending event. This
method can reduce the branching factor of the search space in state-space based temporal
planning. Here, we show that by using the idea of detecting compression-safe actions,
one can significantly reduce the search space of the satisfiability checking based temporal
planning. As it is later explained in Section 4.4, for each compression-safe action a, we add
a clause to the SAT formula to guarantee that the starting event of a is present in a step
if and only if the ending event of a is present in the same step. These clauses can be used
to prune the search tree when the SAT solver is checking the satisfiability of the produced
formula.
CRIKEY3 considers action a to be compression-safe if the following two conditions hold:
558

fiITSAT: An Efficient SAT-Based Temporal Planner

 pre(end(a))  inv(a)
 del(end(a)) = 
Figure 8-(a) shows a temporal plan that is executed to reach proposition q. In this example the ending event of action b does not have any precondition or delete effect. Therefore,
CRIKEY3 considers b to be compression safe. However, if our goal is to produce q, the
singleton A = {b} is not a compression-safe set by Definition 11. In fact, the method used
by CRIKEY3 has been specifically devised for the state-space based temporal planners, and
cannot be easily employed by the SAT-based planners such as ITSAT. In contrast, as it is
later shown, our method can be easily used by both state-space based temporal planners
and SAT-based planners.
There are also cases where the method used by CRIKEY3 cannot detect actions that
are compression-safe according to Definition 11. Consider the plan depicted in Figure 8(b). Suppose that proposition p is the only member of the initial state, and the goal is
to produce proposition g. In this plan, actions a and b must be executed consecutively to
produce g. That is because p and q, which are respectively the overall conditions of a and
b are mutually exclusive, and can never be true together. However, neither a nor b has
the second property required by CRIKEY3 to be regarded as a compression-safe action. In
this section we show how the mutex information can be used for detecting compression-safe
actions.
Definition 12 (swappable events). Let a and a be two different temporal actions, e be
the starting or ending event of a, and e be the starting or ending event of a . We say e and
e are swappable if all the following conditions hold:
 e and e do not have interference with each other: add(e)  del(e ) =  and add(e ) 
del(e) = .
 e and e do not have conflict with each other: del(e)  (pre(e )  inv(a )) =  and
del(e )  (pre(e)  inv(a)) = .
 e and e are not supporting each other: add(e)  (pre(e )  (inv(a )  add(e ))) = 
and add(e )  (pre(e)  (inv(a)  add(e))) = .
According to Definition 12, two events are swappable if there is no causal relation
between them. This means in any causally valid plan  = he1 , ..., e, e , ..., en i, we can swap
e and e to reach another causally valid plan  = he1 , ..., e , e, ..., en i. We can use such
swapping to reorder the events of a given causally valid plan without falsifying it.
Consider a causally valid plan  = he1 , ..., en i. Let ei and ej be the starting and
ending event of the same action. If all other events of this plan are swappable with ej ,
then, by repeatedly swapping, one can reorder  to produce another causally valid plan
  = he1 , ..., ei , ej , ei+1 , ..., ej1 , ej+1 , ..., en i, in which ei and ej are two consecutive events.
Therefore, here {a} is a compression-safe set. In this case, we say that a is compressed
towards its start. Similarly, if every event of the plan other than ei and ej is swappable
with ei , then, by repeatedly swapping, one can reorder  to produce the causally valid
plan   = he1 , ..., ei1 , ei+1 , ..., ej1 , ei , ej , ..., en i. Once again, we can conclude that {a} is
a compression-safe set. In this latter case, we say that a is compressed towards its end.
559

fiRankooh & Ghassem-Sani

Figure 8. Temporal actions that are not regarded as compressible by ITSAT (a) and CRIKEY3 (b)

To find out whether it is safe to compress a given action a, there is no need to check if
all events are swappable with the starting and/or ending events of a. In fact, by considering
the mutex relations obtained from the planning graph of the problem, we already know that
some events can never be executed while a is open. This information can be effectively used
to find out if a given set of actions is compression-safe.
Definition 13 (compressible actions). Let P = (I, G, A) be a temporal planning problem, and a  A be a particular temporal action. We say that a is compressible towards its
start, if for every event e such that e is the starting or ending event of a  A  {a}, at least
one of the following conditions holds:
 A precondition or add effect of e is mutex with opena in the last layer of the leveled-off
planning graph of the causal abstraction of P.
 e is swappable with end(a).
560

fiITSAT: An Efficient SAT-Based Temporal Planner

Similarly, we say that a is compressible towards its end, if for every event e such that e is
the starting or ending event of a  A  {a}, at least one of the following conditions holds:
 A precondition or add effect of e is mutex with opena in the last layer of the leveled-off
planning graph of the causal abstraction of P.
 e is swappable with start(a).
Theorem 2. Let P = (I, G, A) be a solvable temporal planning problem. Let A be the set
of every member of A that is either compressible towards its start or compressible towards
its end. A is compression-safe for P.
Proof. See Appendix A.
We now give an example for further clarification of this matter.
Example 4. Let P = (I, G, A) be a temporal planning problem, where A is the set of
three temporal actions a, b, and c. Consider the hypothetical causally valid plan depicted
in Figure (9-a), where the execution of action a includes the execution of action b that in
turn includes the execution of action c. Assume that a is compressible towards its start,
and b is compressible towards its end. We show how this plan can be converted to another
causally valid plan in which a, b, and c are being executed sequentially. Figures (9-b) and
(9-c) show the results of doing two consecutive swaps by which b is compressed towards its
end. The starting event of b has been swapped with the starting event of c to transform
the plan of Figure (9-a) into the plan of Figure (9-b). Since b is compressible towards its
end, this swapping cannot result in an invalid plan. Similarly, the starting event of b has
been swapped with the ending event of c to transform the plan of Figure (9-b) into the
plan of Figure (9-c). Figures (9-d) to (9-g) show the results of doing four consecutive swaps
by which a is compressed towards its start. As a result of doing these swaps, the fully
sequential plan shown in figure (9-g) is produced. This implies that even if a planner does
not allow the execution of any event while a or b is open, it will still be capable of producing
the temporally valid plan of Figure (9-g).
For any given problem P = (I, G, A), ITSAT computes the compression-safe set A
of Theorem 2. To check the first condition of Definition 13, ITSAT needs to construct
a planning graph for the causal abstraction of P which, as we showed in the previous
subsection, can be done in polynomial time. For the second condition of Definition 13, it
suffices to check every possible pair of events to see if they are swappable. Since this can
be done for each pair in constant time, the total time will be O(|A|2 ). We conclude that
finding A can be performed in polynomial time.
The method described here for finding compression-safe actions can be used by statespace temporal planners, too. State-space temporal planners can be divided into two categories. The first category includes the planners that are based on the so-called decision
epoch planning method (Cushing et al., 2007). Examples of decision epoch planners are
TP4 (Haslum, 2006), SAPA (Do & Kambhampati, 2003), and TFD (Eyerich et al., 2009).
561

fiRankooh & Ghassem-Sani

Figure 9. Action compression

In this method, the start of each action is restricted to be immediately after the start or
end of another action. Each state has an explicit time-stamp. When an action is applied to
a state, the starting time of the action will be set to time-stamp of that state. As a result,
once the starting event of an action is added to the plan, the time of its corresponding
ending event will be exactly known. When searching for a valid plan, in each state, the
562

fiITSAT: An Efficient SAT-Based Temporal Planner

planner has to make a decision between either advancing to the time of the ending event of
an open action, or to open a new action. However, if we know that an action is compressionsafe, the planner can advance the time to the ending of that action and thereby prune the
search space. Plans produced in this way might have larger makespans in comparison to
those produced without pruning the search space. Nevertheless, the produced plans can
be rescheduled to find plans with improved makespans by the method we explain later in
Section 6.
An alternative approach for the state space search is the so-called temporally lifted
progression planning, which has been proved to be complete for PDDL2.1 (Fox & Long,
2003). CRIKEY3 and POPF are examples of the planners that are using this approach.
Each state in the temporally lifted progression planning represents a permutation of a
number of events. At each state, the consistency of temporal constraints imposed by the
sequence of events in that state is checked by solving a Simple Temporal Problem (STP).
Similar to the decision epoch planning, in each state, there may exist two possible choices: to
add the ending event of an open action, or to open a new action. However, for compressionsafe actions, the ending event of actions can be applied immediately after the starting event,
which in turn reduces the future choices of the planner. We will show in Section 6 that by
taking advantage of compression-safe actions in this manner, the planner can still visit all
the STPs of all causally valid permutations of events.
Table 1 shows the comparison between the average percentage of actions regarded as
compression-safe by our new method and the method used in CRIKEY3 and POPF, in various temporal planning domains. We will explain more information regarding our benchmark
domains and problems later in Section 6. At it can be seen in Table 1, our compression
method can detect significantly more compressible actions in a number of benchmark domain.

4. Encoding Phase
In this section, we explain how the abstract causal problem associated with a given temporal
problem is encoded into a SAT formula. As in classical planning, there exist more than one
way to translate a particular planning problem into its corresponding SAT formula. Previous
investigations in the field of classical planning show that the choice of the encoding method
can have a major impact on the efficiency of a SAT-based planner. As mentioned earlier,
the most successful SAT-based classical planners have used special encoding methods that
are based on the so-called -step and -step semantics of valid plans (Rintanen et al., 2006).
In this section, we define the temporal versions of the classical -step and -step plans.
We also show how exactly these semantics can be used to translate a given temporal planning
problem into a SAT formula. We introduce a -step encoding and two different types of
-step encodings in temporal planning. The -step and the first -step encoding methods
are temporal versions of the classical -step and -step encodings. Similar to their classical
versions, in these new encodings, a few restrictive simplifying assumptions are assumed to
hold. Our second type of the -step encoding, however, is obtained by relaxing one of these
assumptions. As we later show, this new -step encoding often requires fewer steps than the
other one. Besides, as our experimental results show, among these new encoding methods,
the second -step encoding results in the best performance of ITSAT in terms of both speed
563

fiRankooh & Ghassem-Sani

domain
zenotravel
rovers
depots
airport
pegsol
crewplanning
openstacks
elevators
sokoban
parcprinter
driverlog
floortile
mapanalyser
matchcellar
parking
rtam
satellite
storage
turnandopen
tms
driverlogshift
matchlift

CRIKEY3
12
85
100
0
100
100
100
100
100
100
100
100
13
96
100
88
100
100
95
73
98
95

ITSAT
100
100
100
95
100
100
100
100
100
100
98
100
96
96
100
95
98
99
99
75
98
95

Table 1: Average Percentage of Compressed Actions
and memory usage of the planner. The necessary proofs of soundness and completeness of
our encoding methods are also given in this section.
4.1 Parallel Semantics for Causally Valid Plans
As mentioned earlier, the classical -step semantics permits the parallel execution of more
than one action in each step, only if the validity of the plan does not depend on the execution
order of those actions. This can simply be guaranteed by adding a particular clause for
each pair of mutually exclusive actions to ensure that such actions will not be included in
the same step. However, this strategy does not work in temporal planning. In temporal
planning, because of the temporal constraints imposed on the starting and ending events
of the actions, the validity of a particular ordering of events in a certain step, also depends
on the ordering of events in the other steps. Nevertheless, in ITSAT this problem has been
tackled by separating the causal and temporal reasoning phases. In general, if we focus only
on finding causally valid plans, and postpone the scheduling phase, the mentioned problem,
about checking the feasibility of imposing different orderings of events in each step, will no
longer exist. We next introduce our semantics for causally valid -step and -step temporal
plans.

564

fiITSAT: An Efficient SAT-Based Temporal Planner

Definition 14 (temporal -steps and -steps). Let E = {e1 , ..., en } be a set of events,
and s1 and s2 be two temporal states. S is a temporal -step from s1 to s2 only if for all
one-to-one ordering functions O : {1, ..., n}  {1, ..., n} (i.e., all permutations of events),
we have: s2 = succ(s1 , heO(1) , ..., eO(n) i). S is a temporal -step from s1 to s2 only if there
exist at least a one-to-one ordering function O : {1, ..., n}  {1, ..., n} (i.e., at least one
permutation of events), such that: s2 = succ(s1 , heO(1) , ..., eO(n) i).
Definition 15 (causally valid -step and -step plans). Let P = (I, G, A) be a temporal planning problem. Suppose s0 , ..., sn is a sequence of temporal states such that s0 = I,
G  state(sn ), and agenda(sn ) = . If for each 1  i  n, Stepi is a -step (-step) from
si1 to si , then we call the sequence  = hStep1 , ..., Stepn i, a causally valid -step (-step)
plan for P. We say that hs0 , ..., sn i is the state transition sequence of .
Classical -step and -step encodings (Rintanen et al., 2006) are based on the -step
and -step semantics for classical valid plans, respectively. However, in the -step encoding,
for the sake of improving the efficiency of the planner, the following restrictive rules have
been also enforced on the semantics.
 Rule 1: Instead of accepting all possible orderings among the actions of each step,
only a fixed arbitrary ordering is allowed. As a result, by this rule, the execution of a
step necessitates the execution of its actions according to this fixed ordering.
 Rule 2: Preconditions of all actions of each step must be members of the state immediately before that step. Similarly, the effects of all actions of each step must be
consistent with the state reached immediately after that step.
In this section, we present one -step and two -step encodings for planning in causal
abstractions of temporal planning. Our encodings are based on the -step and -step
semantics for causally valid plans (Definition 15). By considering events, instead of actions,
both of the above rules can be applied to temporal planning, too. While in our first -step
encoding, we respect both rules, in our second -step encoding, the second restrictive rule
is relaxed.
In fact, the second rule imposes some serious restrictions on the applicability of actions
in each step. For instance, it prevents a proposition from being both produced and used
in the same step of a plan. Neither does it allow the deletion and production of any
particular proposition in the same step. By relaxing these restrictions, the encoding can be
more compact, i.e., the relaxation permits more events to occur in each step. In classical
planning, a less relaxed form of Rule 2 has been introduced so that the effects of actions
in each step can be used by other actions in that step (Wehrle & Rintanen, 2007). Here,
however, we totally relax Rule 2 and allow each proposition to be required, added, and
deleted many times in the same step.
Before explaining our SAT encodings, we first define SAT variables and auxilary clauses
commonly used in our three encoding methods. Let  = hStep1 , ..., Stepn i be a causally
valid -step (or -step) plan for a given temporal planning problem P = (I, G, A), and
hs0 , ..., sn i be the state transition sequence of . In order to encode P into a SAT formula
whose model can be translated back into , we use the following SAT variables:
565

fiRankooh & Ghassem-Sani

 For each proposition p, and each t such that 0  t  n, we define a SAT variable pt .
Assigning true (f alse) to pt implies that p is (is not) a member of state(st ).
 For each action a  A, and each t such that 0  t  n, we define a SAT variable at .
Assigning true (f alse) to at implies that a is (is not) a member of agenda(st ).
 For each event e such that e is the starting or ending event of an action in A, and
each t such that 1  t  n, we define a SAT variable et . Assigning true (f alse) to et
implies that e is (is not) a member of Stept .
If a SAT formula is satisfiable there exists a model for it. This model is a binary function
that assigns a value of true or f alse to each variable of the formula in such a way that the
formula is satisfied. For each of our encoding methods, if the produced formula has a
model M , one can easily translate M to a corresponding causally valid -step (or -step)
plan, using the description given above about the variables of the formula. We denote the
resulting plan by plan(M ). For showing the correctness of a particular encoding method,
two issues must be addressed. First, we must show that if there exists a causally valid
plan for the temporal problem P, then the encoding of P has a model. We call this the
completeness of our encoding method. Second, we must show that if the encoding of P has
a model M , then plan(M ) is a causally valid plan for P. This is called the soundness of
our encoding method.
Note that here, we prove the finite-horizon completeness and not the -completeness for
our encodings. In other words, we prove that if there exists a -step (or -step) plan  with
l steps for a given problem, then the problem can be translated by our -step (or -step)
encoding into a satisfiable SAT formula with at most l steps, so that the model of the formula
can be translated back into . On the other hand, proof of -completeness would need the
value of l to be determined. Our proofs of the finite-horizon completeness could have implied
the -completeness if at least an upper bound on the value of l had been determined. Recent
research in the field of classical planning has shown that in some classical planning domains,
tight upper bounds on the length of optimal plans can be determined (Rintanen & Gretton,
2013). However, determining such upper bounds in temporal planning is beyond the scope
of the current work. To find a causally valid plan, ITSAT starts from an encoding with only
one step, and sequentially produces and tries to satisfy formulae with increasing number
of steps, until a satisfiable formula will be encountered or a predefined time limit will be
reached.
In classical SAT-based planning, in order to produce linear-size encodings for -step
and -step semantics of valid plans, special sets of clauses, named chains, have been used
(Rintanen et al., 2006). Since we have also used these chains in ITSAT, the formal definition
of their temporal version is given here. Let e1 , ..., en be an arbitrary fixed ordering of all
events, E and R be two sets of events, k be a natural number, and m be special symbol
that assigns a unique name to the chain at hand. We define chain(e1 , ..., en ; E; R; k; m) by
the conjunction of formulae (C-1) to (C-3) stated below.
(C-1)

V

{eki  bkj,m |i < j, ei  E, ej  R, {ei+1 , ..., ej1 }  R = }

(C-2)

V

{bki,m  bkj,m |i < j, {ei , ej }  R, {ei+1 , ..., ej1 }  R = }
566

fiITSAT: An Efficient SAT-Based Temporal Planner

(C-3)

V

{bki,m  eki |ei  R}

The above formulae in fact encodes a message passing strategy. The symbol m specifies
the name of the message and is used to distinguish the SAT variables of a certain chain
from those of other chains. The number k specifies the step whose variables are affected
by the message to be produced. The message may be produced by any member of E. The
receivers of the message are the members of R. If bki,m is true, it means that message is
received by the i-th event of the k-th step of the formula. If ei is a member of E, and eki
is true, then a message will be produced and sent to ej , which is the first member of R
located after ei in the fixed ordering. This is represented in chain(e1 , ..., en ; E; R; k; m) by
the clauses of the form eki  bkj,m in formula (C-1). Once the message is produced, it will be
transmitted forward according to the fixed ordering by the clauses of the form bki,m  bkj,m
in formula (C-2). If an event ei receives the message, its corresponding SAT variable will
bef alse by the clauses of the form bki,m  eki in formula (C-3). In fact, the members of R
that receive the message will certainly be excluded from the final plan.
We now present some examples to show how these chains are practically used to guarantee particular characteristics that the output plan will have.
Example 5. Assume that e1 , e2 , e3 , e4 are four events. Suppose that proposition x is
required by e1 and e4 , deleted by e2 , and added by e3 . Also assume that four propositions
p1 , ..., p4 are respectively added by e1 , ..., e4 . Consider the following two cases:
 Case 1: we want to prevent proposition x from being both required and deleted in the
same step, say k, of the final plan. For this purpose, we can add the conjunction of
chain(e1 , ..., e4 ; E; R; k; mx1 ) and chain(e4 , ..., e1 ; E; R; k; mx2 ) to the formula, where E
is the set of all events that delete x (i.e., E = {e2 }), and R is the set of all events that
require x (i.e., R = {e1 , e4 }). Note that mx1 and mx2 are two symbols that enable us to
distinguish between the SAT variables used in these two different chains. In this case,
adding chain(e1 , ..., e4 ; E; R; k; mx1 ) will add the following formulae to the encoding of
the problem:
 ek2  bk4,mx
1



bk1,mx
1



bk4,mx
1

 bk1,mx  ek1
1

 bk4,mx  ek4
1

Assume that there exists a model M for the produced SAT encoding such that
M (ek2 ) = true. In this case, since M satisfies ek2  bk4,mx , we have M (bk4,mx ) = true.
1
1
Consequently, since M satisfies bk4,mx  ek4 , we have M (ek4 ) = f alse. In other words,
1
if e2 is a member of step k, then e4 cannot be a member of the same step. Similarly,
adding chain(e4 , ..., e1 ; E; R; k; mx2 ) will add the following formulae to the encoding of
the problem:
 ek2  bk1,mx
2

567

fiRankooh & Ghassem-Sani

 bk4,mx  bk1,mx
2



bk4,mx
2

2



ek4

 bk1,mx  ek1
2

An argument similar to the one given for chain(e1 , ..., e4 ; E; R; k; mx1 ) shows that after
adding chain(e4 , ..., e1 ; E; R; k; x2 ), if e2 is a member of step k, then e1 cannot be a
member of the same step. As a result, by adding both mentioned chains to the SAT
formula, if the execution of step k produces p2 , it then cannot produce p1 or p4 . This
is actually how the occurrence of conflicting actions in each step of the final plan is
avoided by the linear-size classical -step encoding (Rintanen et al., 2006).
 Case 2: we allow proposition x to be both required and deleted in a particular step
k only if the deleting event does not precede the requiring event in the fixed ordering
he1 , e2 , e3 , s4 i. For this purpose, we only need to add chain(e1 , ..., en ; E; R; k; mx ) to
the formula, where E and R are the same as E and R in case 1. In this case, if the
execution of step k produces p2 , it can also produce p1 , but not p4 . This strategy, too,
was initially introduced for the linear-size classical -step encoding (Rintanen et al.,
2006).
Note that if one admits the second restrictive rule mentioned above, which is the case in
classical -step and -step encodings, no proposition can be added by an event in any step
while being deleted by another event in the same step. As a result, if the execution of step
k produces p2 , it cannot produce p3 in any of the above cases.

4.2 Temporal Versions of Classical -step and -step Encodings
We first present the temporal versions of the classical -step and -step encodings. Similar
to their classical forms, in the temporal versions of these encodings, we assume an arbitrary
but fixed ordering e1 , ..., en for all events of the given temporal problem P = (I, G, A).
We also assume that the output plan will have a fixed number of steps, denoted by l.
Let  = hStep1 , ..., Stepl i be an output plan for P, and hs0 , ..., sl i be the state transition
sequence of . For each event e, let action(e) be the member of A whose starting or
ending event is equal to e. Let P be the set of all propositions of P. For each proposition
p  P , let Ep = {e|p  del(e)}, Ep+ = {e|p  add(e)} and Rp = {e|p  pre(e)}  {e|p 
inv(action(e))  add(e)}. Moreover, assume that there are two dummy events e0 and en+1 ,
which do not have any precondition, add effect, or delete effect.
4.2.1 The -step Encoding
Given the temporal problem P = (I, G, A), we produce the SAT-formula l , which is based
on the -step semantics of causally valid plans, for P by the conjunction of all formulae
described below.
V
(-1) {p0 |p  state(I)}  {p0 |p 
/ state(I)}
V l
(-2) {p |p  G}
568

fiITSAT: An Efficient SAT-Based Temporal Planner

(-3)

V

{a0 |a  A}

(-4)

V

{al |a  A}

(-5)

V

{ek  pk1 |0 < k  l, p  P, e  Rp }

(-6)

V

{ek  pk |0 < k  l, p  P, e  Ep+ }

(-7)

V

(-9)

V

(-10)

V

(-11)

V

(-12)

V

{ek  ak1  ak |0 < k  l, a  A, e = start(a)}

(-13)

V

{ek  ak1  ak |0 < k  l, a  A, e = end(a)}

{ek  pk |0 < k  l, p  P, e  Ep }
V
W
(-8) {pk1  pk  eEp+ ek |0 < k  l, p  P }
{pk1  pk 

W

eEp

ek |0 < k  l, p  P }

{chain(e1 , ..., en+1 ; Ep ; Rp  {en+1 }; k; mp1 )|0 < k  l, p  P } 
{(bkn+1,mp  ak )|0 < k  l, p  inv(a)}
1

{chain(en , ..., e0 ; Ep ; Rp  {e0 }; k; mp2 )|0 < k  l, p  P } 
{(bk0,mp  ak1 )|0 < k  l, p  inv(a)}
2

Formula (-1) indicates that any member of state(s0 ) is true iff it is present in the initial state. Similarly, formula (-2) states that all members of the goal state must be true in
state(sl ). Formulae (-3) and (-4) imply that agenda(s0 ) and agenda(sl ) are both empty.
Formulae (-5) to (-7) show that when an event is applied to step k, its preconditions must
be present in state(sk1 ), and its effects must be consistent with state(sk ). Formulae (8) and (-9) are responsible for encoding the so-called explanatory frame axioms: formula
(-8) implies that if p is present after but not before step k, then there must exist at least
one event in step k that has p in its add effects. Similarly, formula (-9) implies that if p is
present before but not after step k, then there must exist at least one event in step k that
deletes p. Formulae (-10) and (-11) are added to guarantee that the events of each step
can be executed in any possible ordering. Formula (-10) implies that if p is deleted by an
event ei in step k, then p cannot be required by any other event ej of step k such that j > i.
It also implies that if p is deleted by any event in step k, and action a has p as an invariant,
then a cannot be a member of agenda(sk ). Note that in chain(e1 , ..., en+1 ; Ep ; Rp ; k; mp1 )
used in formula (-10), the value of bn+1,mp1 indicates whether or not p is deleted by any
event in step k. The reason why we are using the dummy event en+1 is to have such an
indicator. Analogously, formula (-11) implies that if p is deleted by an event ei in step k,
then p cannot be needed by any other event ej of step k such that j < i. Formula (-11)
also implies that if p is deleted by any event in step k, and action a has p as an invariant,
then a cannot be a member of agenda(sk1 ). Formulae (-12) and (-13) are responsible for
applying appropriate changes in the agendas of the states that are located before and after
each step of the final plan. Formula (-12) implies that if the starting event of an action a
is a member of the step k of the output plan, then a must be a member of agenda(sk ) but
not agenda(sk1 ). Similarly, formula (-13) implies that if the ending event of action a is a
569

fiRankooh & Ghassem-Sani

member of step k of the plan, then a must be a member of agenda(sk1 ) but not agenda(sk ).
Theorem 3 (completeness of temporal -step encoding). Let P = (I, G, A) be a
solvable temporal planning problem, {e1 , ..., en } be the set of all events of P, and  =
hStep1 , ..., Stepl i be a causally valid -step plan for P. There exists a model M for l such
that  = plan(M ).
Proof. See Appendix A.
Theorem 4 (soundness of -step encoding). Let P = (I, G, A) be a temporal planning
problem, {e1 , ..., en } be the set of all events of P, and l be the -step encoding for P. If
l has a model M , then plan(M ) is a causally valid -step plan for P.
Proof. See Appendix A.
4.2.2 The -step Encoding
In this part, we present the SAT-formula l , which is based on the -step semantics of
causally valid plans. By considering the two restrictive rules stated above, our -step
encoding is very similar to the -step encoding described previously in this section. However,
there are two major differences between these two kinds of encoding. First, our -step
encoding allows each proposition to be both required and deleted in each step, provided
that the deleting event does not precede the requiring event in the fixed ordering he1 , ..., sn i.
This is in contrast with our -step encoding, where a proposition could not be both deleted
and required in the same step of the final plan. Second, in our -step encoding, each
step may also contain both the starting and ending event of the same action. Given the
temporal problem P = (I, G, A), we produce the SAT-formula l , which is based on the
-step semantics of causally valid plans, for P by the conjunction of all formulae described
below.
V
(-1) {p0 |p  state(I)}  {p0 |p 
/ state(I)}
V l
(-2) {p |p  G}
V
(-3) {a0 |a  A}
V
(-4) {al |a  A}
V
(-5) {ek  pk1 |0 < k  l, p  P, e  Rp }
V
(-6) {ek  pk |0 < k  l, p  P, e  Ep+ }
V
(-7) {ek  pk |0 < k  l, p  P, e  Ep }
V
W
(-8) {pk1  pk  eEp+ ek |0 < k  l, p  P }
(-9)

V

{pk1  pk 

W

(-10)

V

{chain(e1 , ..., en+1 ; Ep ; Rp  {en+1 }; k; mp1 )|0 < k  l, p  P }  {(bkn+1,mp 

eEp

ek |0 < k  l, p  P }
1

ak )|0 < k  l, p  inv(a)}
570

fiITSAT: An Efficient SAT-Based Temporal Planner

(-11)

V

(-12)

V

(-13)

V

(-14)

V

(-15)

V

(-16)

V

(-17)

V

(-18)

V

(-19)

V

(-20)

V

{eki  ak1 |0 < k  l, a  A, ei = start(a), ej = end(a), i < j}
{eki  ak  ekj |0 < k  l, a  A, ei = start(a), ej = end(a), i < j}
{ekj  ak |0 < k  l, a  A, ei = start(a), ej = end(a), i < j}
{ekj  ak1  eki |0 < k  l, a  A, ei = start(a), ej = end(a), i < j}
{eki  ak1  ekj |0 < k  l, a  A, ei = start(a), ej = end(a), j < i}
{eki  ak |0 < k  l, a  A, ei = start(a), ej = end(a), j < i}
{ekj  ak  eki |0 < k  l, a  A, ei = start(a), ej = end(a), j < i}
{ekj  ak1 |0 < k  l, a  A, ei = start(a), ej = end(a), j < i}
{ak1  ak  eki |0 < k  l, a  A, ei = start(a)}
{ak1  ak  ekj |0 < k  l, a  A, ej = end(a)}

Note that formulae (-1) to (-9) are exactly the same as formulae (-1) to (-9). Similar
to our -step encoding, these formulae are responsible for the validity of the initial state, goal
state, conditions and effects of events, and also for the explanatory frame axioms explained
before. Moreover, notice that while formula (-10) is also present in our -step encoding as
formula (-10), formula (-11) is not present in l . This results in the first major difference
stated above between our -step encoding and -step encoding. Formulae (-11)to (-20)
enforce appropriate changes to agenda(sk1 ) and agenda(sk ), which are the agendas of the
states immediately before and after step k of the final plan. According to their definitions,
formulae (-11) to (-14) are added for each action a with the property that start(a) is
located before end(a) in the fixed ordering he1 , ..., en i. Formula (-11) ensures that a can
be started in step k, only if it is not open in sk1 . Formula (-12) guarantees that if a is
started but not ended in step k, it must be open in sk . Formula (-13) ensures that if a
is ended in step k, it will not be open in sk . Formula (-14) implies that if a is ended but
not started in step k, then it must be open in sk1 . Analogously, formulae (-15) to (-18)
guarantee similar properties for each action a with the property that start(a) is located
after end(a) in the fixed ordering he1 , ..., en i. Formula (-19) ensures that if a is a member
of agenda(sk ) but not agenda(sk1 ), it must be started in step k. Similarly, formula (-20)
ensures that if a is a member of agenda(sk1 ) but not agenda(sk ), it must be ended in step
k.
Since our -step encoding conforms to the two restrictive rules stated earlier in this
section, there may exist a -step causally valid plan with l steps for a given problem while
l would be unsatisfiable for the same problem. This is also the case in the linear size step encoding of the classical planning problems (Rintanen et al., 2006). However, since we
showed by Theorem 3 that our -step encoding is complete, the completeness of our -step
encoding can be proved by showing that the satisfiability of l entails the satisfiability of l .
Theorem 5 (completeness of -step encoding). Let P = (I, G, A) be a solvable temporal planning problem, {e1 , ..., en } be the set of all events of P, and  = hStep1 , ..., Stepl i
be a causally valid -step plan for P. There exists a model M for l such that  = plan(M ).
571

fiRankooh & Ghassem-Sani

Proof. See Appendix A.
Theorem 5 also shows that in our -step encoding, the number of required steps to
solve a temporal planning problem is less than (or equal to) what is required by our -step
encoding. In other words, our -step encoding is more compact than its -step counterpart.
Theorem 6 (soundness of -step encoding). Let P = (I, G, A) be a temporal planning
problem, {e1 , ..., en } be the set of all events of P, and l be the -step encoding for P. If
l has a model M , then plan(M ) is a causally valid -step plan P.
Proof. See Appendix A.
4.3 The Relaxed -step Encoding
As we mentioned in Section 4.2.2, our -step encoding allows each proposition to be both
required and deleted by any two events of the same step, only if the deleting event does not
precede the requiring event in the fixed ordering he1 , ..., en i. Besides, since formulae (-5)
and (-6) are present in both of our -step and -step encodings, no proposition can be
both added and deleted in the same step of these encodings. These restrictions, which are
also present in the classical -step and -step encodings (Rintanen et al., 2006), are lifted in
our new relaxed version of -step encoding. As a result, each proposition can be required,
added, and deleted in any step as many times as it is needed. This property has not been
previously examined in classical -step encoding, and consequently, the chaining mechanism
explained in Section 4.1 is not compatible with it. Here, we introduce a generalized version
of the chains and explain the conceptual difference with those used in classical encodings.
We also present new kinds of chains to be used specially in temporal planning for preserving
the invariants of temporal actions while the plan is being produced. Note that, similar to
our non-relaxed -step encoding, here we assume that the events of each step are executed
according to a fixed ordering he1 , ..., en i.
Let k be a natural number and e1 , ..., en be a fixed ordering of all events. For some reasons to be discussed later, we assume that if ei is the starting event of an action, then ei+1
is the ending event of that action. In other words, we assume that the ending event of each
action is located immediately after its starting event in the fixed ordering. Note that here,
we do not demand the end of an action to immediately follow its start in the final plan. We
only put this constraint on the fixed ordering. This cannot compromise the completeness of
ITSAT: the SAT solver can still choose the start of an action a from step k, choose whatever
actions are needed from steps k to k + m for an arbitrary m, and then choose the end of a
from step k +m. Moreover, suppose that there are two dummy events e0 and en+1 , which do
not have any precondition, add-effect, or delete-effect. Let P be the set of all propositions of
P. For each proposition p  P , let Ep = {e|p  del(e)}, Ep+ = {e|p  add(e)}, Op = {e|p 
inv(action(e))}  {e0 , en+1 }, and Rp = {e|p  pre(e)}  {e|p  inv(action(e))  add(e)}.
We define chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ) by the conjunction of formulae (C -1) to
(C -8) stated below. Note that mp is a symbol used for distinguishing the SAT varibales
used in the formula chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ) from other variables used in other
formulae.

572

fiITSAT: An Efficient SAT-Based Temporal Planner

(C -1)

V

{eki  bkj,mp |i < j, ei  Ep+ , ej  Rp  Ep , {ei+1 , ..., ej1 }  (Rp  Ep ) = }

(C -2)

V

{eki  bkj,mp |i < j, ei  Ep , ej  Rp  Ep+ , {ei+1 , ..., ej1 }  (Rp  Ep+ ) = }

V

{bki,mp  bkj,mp |i < j, ei  Rp  (Ep+  Ep ), ej  R  Ep+  Ep , {ei+1 , ..., ej1 } 
(Rp  Ep+  Ep ) = }
V
(C -4) {(bki,mp  eki )  bkj,mp |i < j, {ei , ej }  Rp  Ep+  Ep , {ei+1 , ..., ej1 }  (Rp  Ep+ 
Ep ) = }
V
(C -5) {(bki,mp  eki )  bkj,mp |i < j, {ei , ej }  Rp  Ep+  Ep , {ei+1 , ..., ej1 }  (Rp 
Ep+  Ep ) = }
V
(C -6) {bki,mp  eki |ei  Rp }

(C -3)

(C -7) bk0,mp  pk1
(C -8) bkn+1,mp  pk
In fact, chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ) encodes a message passing method that is
different from that of chain(e1 , ..., en ; E; R; k; m). In chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ),
the conveyed message is in fact the value of proposition p, and is therefore either true or
f alse. Similar to the message passing strategy of chain(e1 , ..., en ; E; R; k; m), the received
message is transferred only in the forward direction of the fixed ordering e1 , ..., en . Each
event in Ep+ , Ep , or Rp receives a message from its previous event in the fixed ordering.
Every event may or may not change the value of the received message. In either cases, the
message is then passed to the next event. The events in Ep+ can only change the value
of the received message to true, as these events have p in their add-effects. Similarly, the
events in Ep can only change the value of the received message to f alse. The formulae
(C -1) and (C -2) impose such changes on the value of a received message. If an event is
not a member of Ep+ or Ep , it neither adds nor deletes p, and thus, it will pass the received
message without altering its value. This is enforced by (C -3). (C -4) and (C -5) ensure
that received messages are passed without being changed by those events that are not to
be chosen for Stepk of the output plan. According to (C -6), if an event in Rp receives a
message with the value of f alse, the event cannot be chosen as a member of Stepk . That
is because members of Rp require p, which necessitates their received messages to have a
value of true. (C -7) implies that the initial value of the message produced in Stepk is equal
to the value of p in the state immediately before the execution of Stepk . Similarly, (C -8)
implies that the value of p in the state immediately after the execution of Stepk will be
equal to the final value of the message in Stepk .
Example 6. Consider the same events given in Example 5. Let E + be the set of events
that add x (i.e., E + = {a3 }), E  be the set of events that delete x (i.e., E  = {a2 }),
and R be the set of events that require x (i.e., R = {a1 , a4 }). Moreover, suppose that
there are two dummy events e0 and e5 , which do not have any precondition, add-effect, or
delete-effect. Assume that we have added chain (e0 , ..., e5 ; E + ; E  ; R  {e0 , e5 }; k; mx ) to
573

fiRankooh & Ghassem-Sani

the SAT formula. According to formulae (C -1) to (C -8), this chain is the conjunction of
the following formulae:
 ek3  bk4,mp
 ek2  bk3,mp
 bk0,mp  bk1,mp
 bk1,mp  bk2,mp
 bk4,mp  bk5,mp
 bk0,mp  ek0  bk1,mp
 bk1,mp  ek1  bk2,mp
 bk2,mp  ek2  bk3,mp
 bk3,mp  ek3  bk4,mp
 bk4,mp  ek4  bk5,mp
 bk0,mp  ek0  bk1,mp
 bk1,mp  ek1  bk2,mp
 bk2,mp  ek2  bk3,mp
 bk3,mp  ek3  bk4,mp
 bk4,mp  ek4  bk5,mp
 bk0,mp  ek0
 bk1,mp  ek1
 bk4,mp  ek4
 bk5,mp  ek5
 bk0,mp  xk1
 bk5,mp  xk
574

fiITSAT: An Efficient SAT-Based Temporal Planner

A straightforward examination shows that we can have a model M for the chain mentioned above such that M (ek0 ) = M (ek1 ) = M (ek2 ) = M (ek3 ) = M (ek4 ) = M (ek5 ) = true,
M (bk0,mp ) = M (bk1,mp ) = M (bk2,mp ) = M (bk4,mp ) = M (bk5,mp ) = true, and M (bk3,mp ) = f alse.
In other words, if x is deleted by e2 in Stepk of the final plan, it can later be produced again
by e3 , and as a result, e4 can appear in Stepk , too. Here, M (bk3,mp ) = f alse represents the
fact that x has been deleted after the execution of e2 . In this example, all four propositions
p1 , p2 , p3 , and p4 can be produced by a single step of the final plan. Note that in neither
of the cases of Example 5, producing all these propositions by only one step was possible.
This is an example of how our new -step encoding, which employs the generalized message
passing strategy, can permit more parallelism than is allowed by the temporal versions of
classical -step and -step encodings.
In addition to chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ), which is responsible for tracking
the value of p inside Stepk , we also need some extra formulae to prevent p from being deleted
whenever p is an invariant of an open temporal action. Therefore, we introduce two new
ob

ob
chain formulae: chainof (e1 , ..., en+1 ; Ep ; Op ; k; mof
p ) and chain (e0 , ..., en ; Ep ; Op ; k; mp ).
Formula chainof (e1 , ..., en+1 ; Ep ; Op ; k; mof
p ) is produced by the conjunction of formulae
of
of
(C -1) to (C -4). Similar to the chains explained before, mof
p is a symbol used to distinguish the SAT varibales of this chain from those of other formulae.
V
(Cof -1) {eki  bk of |i < j, ei  Ep , ej  Op , {ei+1 , ..., ej1 }  Op = }
j,mp

(Cof -2)

V

{bk

(Cof -3)

V

{(bk

 ekj )  eki |ei  Op , ei = start(a), ej = end(a)}

(Cof -4)

V

{(bk

 ak )  eki |a  A, ei = start(a), ei  Op }

i,mof
p

 bk

j,mof
p

j,mof
p

n+1,mof
p

|i < j, {ei , ej }  Op , {ei+1 , ..., ej1 }  Op = }

Similar to chain(e1 , ..., en ; Ep ; Rp ; k; mp ), chainof (e1 , ..., en ; Ep ; Op ; k; mof
p ) represents a
message that is produced and sent in the forward direction of the fixed ordering, whenever a
proposition p is deleted by an event. (Cof -1) and (Cof -2) are responsible for the production
and propagation of the mentioned message, respectively. By (Cof -3), if the ending event of
an action a with p as its invariant receives this message in step k, then step k must also
include the starting event of a. In these cases, (Cof -3) prevents a from being open when p
is deleted. That is because we assume that in the fixed ordering, the ending event of each
action is located immediately after its starting event. (Cof -4) guarantees that if p is deleted
somewhere in step k, and an action a with p as its invariant is open after step k, then step
k must also include the starting event of a (otherwise, a is open everywhere in step k, and
thus, p, which is an invariant of a, is deleted while a is open).
In chainof (e1 , ..., en+1 ; Ep ; Op ; k; mof
p ), the message that indicates p is deleted is only sent
forward. Thus, it cannot help preserving the invariants of those members of Op that
are started prior to the deletion of p. To tackle this problem, we add another chain,
namely chainob (e0 , ..., en ; Ep ; Op ; k; mob
p ), to the formula. This chain is quite analogous to
of
of

chain (e1 , ..., en+1 ; Ep ; Op ; k; mp ), that whenever p is deleted by an event, the chain sends
575

fiRankooh & Ghassem-Sani

the message backward according to the fixed ordering. chainob (e0 , ..., en ; Ep ; Op ; k; mob
p ) is
ob
ob
produced by the conjunction of formulae (C -1) to (C -4).
(Cob -1)

V

{eki  bkj,mob |j < i, ei  Ep , ej  Op , {ej+1 , ..., ei1 }  Op = }

(Cob -2)

V

{bki,mob  bkj,mob |j < i, {ei , ej }  Op , {ej+1 , ..., ei1 }  Op = }

(Cob -3)

V

{(bki,mob  eki )  ekj |ei  Op , ei = start(a), ej = end(a)}

(Cob -4)

V

{(bk0,mob  ak1 )  ekj |a  A, ej = end(a), ej  Op }

p

p

p

p

p



We now present the SAT-formula l , which represents our relaxed -step encoding and

is based on the -step semantics of causally valid plans. l is produced by the conjunction
of all formulae described below.
V
( -1) {p0 |p  state(I)}  {p0 |p 
/ state(I)}
V
( -2) {pl |p  G}
V
( -3) {a0 |a  A}
V
( -4) {al |a  A}
V
( -5) {chain (e0 , e1 , ..., en+1 ; Ep+ ; Ep ; Rp  {e0 , en+1 }; k; mp )|0 < k  l, p  P }
( -6)

V

{chainof (e1 , ..., en+1 ; Ep ; Op ; k; mof
p )|0 < k  l, p  P }

( -7)

V

{chainob (e0 , ..., en ; Ep ; Op ; k; mob
p )|0 < k  l, p  P }

( -8)

V

( -9)

V

{eki  ak1 |0 < k  l, a  A, ei = start(a)}

( -10)

V

{ekj  ak |0 < k  l, a  A, ej = end(a)}

( -11)

V

{ekj  ak1  eki |0 < k  l, a  A, ei = start(a), ej = end(a)}

( -12)

V

( -13)

V

{ak1  ak  eki |0 < k  l, a  A, ei = start(a)}

{eki  ak  ekj |0 < k  l, a  A, ei = start(a), ej = end(a)}

{ak1  ak  ekj |0 < k  l, a  A, ej = end(a)}

( -1) ensures that any member of state(s0 ) is true if and only if that member is present in
the initial state. Similarly, ( -2) guarantees that all members of the goal state are true in
state(sl ). ( -3) and ( -4) imply that agenda(s0 ) and agenda(sl ) are both empty. ( -5),
as explained before, is responsible for imposing appropriate changes in the value of the SAT
variables, whenever proposition p is added or deleted by an event in a certain step of the
output plan. ( -6) and ( -7) prevent the invariants of an action a from being deleted
while a is open. ( -8) to ( -13) are responsible for enforcing the appropriate changes to
agenda(sk1 ) and agenda(sk ), which are agendas of the states immediately before and after
576

fiITSAT: An Efficient SAT-Based Temporal Planner

step k of the output plan. ( -8) ensures that a can be started in step k only if it is not
open in sk1 . ( -9) indicates that if a is started but not ended in step k, then it has to be
open in sk . ( -10) ensures that if a is ended in step k, it will not be open in sk . ( -11)
implies that if a is ended but not started in step k, then it has to be open in sk1 . ( -12)
ensures that if a is a member of agenda(sk ) but not a member of agenda(sk1 ), then a is
started in step k. Similarly, ( -13) ensures that if a is a member of agenda(sk1 ) but not
agenda(sk ), then a is ended in step k.
By Theorem 5, we know that if a temporal planning problem P is satisfiable, then there
exists a positive number l, such that the non-relaxed -step encoding of P with l steps
(i.e., l ) is satisfiable. Accordingly, the completeness of our relaxed -step encoding can be

proved by showing that if l is satisfiable then l will also be satisfiable.
Theorem 7 (completeness of the relaxed -step encoding). Let P = (I, G, A) be a

temporal planning problem and formulae l and l be two -step encodings of P explained

above. If M is a model for l , then l has a model M  such that plan(M  ) = plan(M ).
Proof. See Appendix A.
Theorem 7 also shows that, in our  -step encoding, the number of required steps to
solve a temporal planning problem is less than (or equal to) what is required by our -step
encoding, provided that the same fixed ordering has been used in these two encodings. In
other words, our  -step encoding is more compact than our -step encoding.
Theorem 8 (soundness of the relaxed -step encoding). Let P = (I, G, A) be a

temporal planning problem, {e1 , ..., en } be the set of all events of P, and l be the relaxed

-step encoding for P. If l has a model M , then plan(M ) is a causally valid -step plan
P.
Proof. See Appendix A.
4.4 Mutual Exclusion Relations and Action Compression
As we mentioned earlier in Section 3, the performance of any SAT-based temporal planner
can be improved by mutual exclusion analysis and action compression. In this section,
we show how the information obtained by these tasks has been utilized in ITSAT. Let
P = (I, G, A) be a temporal planning problem, MU T be the set of all mutually exclusive
pairs of propositions of P, and COM be the set of all compression-safe actions of P (see

Section 3). Let l be the encoding of P, which can be any of l , l , or l . For taking
advantage of mutual exclusion relations, we add an extra formula mut
to l , where mut
=
l
l
V
k
k
{p  q |(p, q)  MU T , 1  k  l}. As Theorem 1 shows, two mutually exclusive
propositions p and q can never be both true in any state that is achieved by the execution
of a valid temporal plan starting from I. As a result, adding mut
to the encoding cannot
l
render the planner incapable of finding valid plans.
Let a  A be a compression-safe action. As it was showed in Section 3.2, it is safe
to assume that in any causally valid plan, the ending event of a occurs immediately after
its starting event. One way to impose such constraint is to add some extra clauses to the
577

fiRankooh & Ghassem-Sani

encoding to guarantee that both starting and ending events of a are always included in the
same step. However, these two events may have conflicting effects, in which case l and
l will not allow such events to be both present at any step. Therefore, the information

regarding compression-safe actions is only added
to our relexed -step encoding, l . This
V

is done by adding com
to l , where com
= {eki  eki+1 |a  COM, ei = start(a), 1 
l
l


k  l}. Note that in l , if ei is the starting event of an action, ei+1 denotes its ending
event.

5. Scheduling Phase
In this section, we describe how a causally valid plan is augmented by temporal information
to produce a valid temporal plan. Let  = he1 , ..., en i be a causally valid plan produced by
our planner. The scheduling of  is done by defining the scheduling function  of Definition
9, which assigns a rational number to each event of  as its execution time. Suppose that
we have given different names to different occurrences of the same action in this plan, so
all the events e1 , ..., en are unique. We can assume that for each i,  (i) <  (i + 1), and
thereby satisfy the first condition of Definition 9. However, this can lead to the plans with
unnecessarily large makespans. Alternatively, for obtaining plans with improved quality,
we impose a more relaxed set of constraints on the function  .
Definition 16 (relaxed scheduling functions). Let  be a causally valid plan. The
scheduling function  is a relaxed scheduling function if it has the following properties:
(S-1) For all i and j such that ei is located before ej in , and ei is not swappable with ej
(cf. Definition 12), we require that  (i) <  (j).
(S-2) For all i and j, if ei is the starting event of a particular action a, and ej is the pairing
event of ei in  (cf. Definition 8), we require that  (j) =  (i) + dur(a).
Theorem 9. Let P = (I, G, A) be a temporal planning problem,  = he1 , ..., en i be a
causally valid plan for P, and  : {1, ..., n}  Q be a relaxed scheduling function for .
There exists a valid temporal plan for P.
Proof. See Appendix A.
Theorem 9 shows that whenever a relaxed scheduling function exists for a causally valid
plan of P, a valid temporal plan can be produced for P. To prove that our scheduling
method does not render ITSAT incomplete, we also need to show that if P is solvable,
our planner will be able to produce a causally valid plan  and a scheduling function 
such that  is a relaxed scheduling function for . Let (,  ) be a valid temporal plan
for P. Every causally valid plan can also be regarded as a causally valid -step plan with
singleton steps. Therefore, by Theorem 3, l has a model M such that  = plan(M ).

By Theorem 5, M also satisfies l . Moreover, by Theorem 7, l has a model M  such
that  = plan(M  ) = plan(M ). Therefore, if any of our encoding methods are used for
translating P to a SAT formula, the resulting formula has a model that will be translated
to . On the other hand, according to Definition 9,  satisfies all constraints of the form
(S-1) and (S-2), and therefore, is a relaxed scheduling function of . However, as mentioned
578

fiITSAT: An Efficient SAT-Based Temporal Planner

in Section 4.2.4, we may add certain clauses to the encoding to ensure that the produced
causally valid plan is always compressed (Definition 11). We now show that for each solvable temporal plan, there exists a compressed causally valid plan that can be scheduled to
a valid temporal plan by a relaxed scheduling function.
Theorem 10. Let P = (I, G, A) be a solvable temporal planning problem, and COM
be the set of every member of A that is either compressible towards its start or compressible towards its end (Definition 13). There exists a valid temporal plan (,  ) for P such
that  is a causally valid plan for P,  is compressed with respect to COM, and  is a
relaxed scheduling function for .
Proof. See Appendix A.
To check the existence of the function  with the properties stated above, we solve an
instance of a Simple Temporal Problem (STP) (Dechter et al., 1991). Each STP is associated
with a weighted graph named a Simple Temporal Network (STN). We construct an STN in
which node xi corresponds to the event ei in the causally valid plan . Let  be an arbitrary
small rational number. For each constraint of the form  (i) <  (j), we add an edge with
the weight  from xi to xj . For each constraint of the form  (j) =  (i) + dur(a), we
add an edge with the weight -dur(a) from xi to xj , and another edge with weight dur(a)
from xj to xi . We also add a reference node x0 to the constructed STN. x0 has an edge
with the weight 0 to every other node. A solution of any STP can be found by computing
the length of the shortest path form x0 to all other nodes (Dechter et al., 1991). Suppose
that such shortest paths exist and the length of the shortest from x0 to xi is shown by
distance(x0 , xi ). For each event ei , we define  (i) to be equal to distance(x0 , xi ). In
this case, Theorem 9 guarantees that the resulting plan has all the specifications of a valid
temporal plan.
To see the intuition behind the explained method of defining the function  , suppose that in the constructed STN, there is an edge with the weight  from xi to xj .
This means that distance(x0 , xj )  distance(x0 , xi )  , which implies distance(x0 , xi ) 
distance(x0 , xj )  . This, in turn, implies that distance(x0 , xi ) < distance(x0 , xj ),
and  (i) <  (j). Similarly, it can be easily shown that if there exists an edge with the
weight -dur(a) from xi to xj , and another edge with weight dur(a) from xj to xi , then
we will have:  (j) =  (i) + dur(a). Bellman-Ford algorithm (Cormen, Leiserson, Rivest,
& Stein, 2009) can be used to find all single source shortest paths of any weighted graph
in polynomial time. Besides, the number of the nodes of the produced STN is equal to
the number of events of the causally valid plan. Therefore, we can conclude that, if the
mentioned shortest paths exist,  (i) can be computed in polynomial time.
However, there are situations in which such shortest paths do not exist. It happens when
the corresponding STN has a negative cycle. In these situations, the STP is inconsistent
and consequently, all the temporal constraints cannot be satisfied at the same time. An
example of such a case is depicted in Figure 10.
In Figure 10, action a adds propositions p and g by its starting and ending events,
respectively. a needs proposition q as a precondition for its ending event. Action b requires
p upon starting and adds q upon ending. Durations of actions a and b, are 5 and 10,
respectively. The goal of planning is reaching fact g. For this problem,  = has , bs , be , ae i
579

fiRankooh & Ghassem-Sani

Figure 10. Negative Cycles

is a causally valid plan, where as = start(a), ae = end(a), bs = start(b), be = end(b). This
plan is depicted in Figure 10-(a). In this plan, the execution of action b must be entirely
inside that of action a (i.e., b is started after starting a and is ended before ending a).
However, this is impossible considering the fact that the duration of a is less than that of
b. The invalidity of this plan is caused by the fact that while producing this causally valid
plan, all the durations are abstracted out. The STN constructed for the plan of Figure
10-(a) is depicted in Figure 10-(b). as bs be ae as is a negative cycle with the total weight of
5  2.
5.1 Negative Cycle Prevention
If the STN of a causally valid plan includes a negative cycle, the plan cannot be transformed
into a valid temporal plan. In such cases, the SAT solver will be forced to find a different
solution. This can be done by adding an extra clause such that at least one of the events
of the current negative cycle will be prevented from occurring in its current step. However,
after adding such a blocking clause, the planner can still produce new plans that are basically
equivalent to the previous plan. For instance, consider the example given in Figure 10.
Suppose as , bs , be , and ae are members of steps 1 to 4, respectively. Assume that the
output plan is to have 5 steps. If we forbid the exact occurrence of the negative cycle, a
580

fiITSAT: An Efficient SAT-Based Temporal Planner

new causally valid plan can still be produced by shifting ae to layer 5 and maintaining all
other events in their current steps. The new solution will have the same negative cycle and
therefore cannot be transformed to a valid temporal plan. In fact, here the cause of the
invalidity of the plan has not changed. We now show how by exploiting the simple structure
of negative cycles, one can prevent the reoccurrence of such cycles more effectively.
From the discussion given above, it should be clear that the main reason that such
negative cycles are encountered in the STN of a particular causally valid plan, is some
specific order of events in that plan. In fact, if the events of any negative cycle reoccur with
the same order in a new causally valid plan, the new plan will include the same negative
cycle, too.
For any temporal planning problem P, P
we can regard the set of all possible sequences
of events as a language over the alphabet
= {e1 , ..., en }, where n is the number of all
events of P. The set of all sequences of events in which certain P
events have appeared in
a particular order can also be regarded as another language over . It is straightforward
to show that this latter language is in fact a regular language and can be accepted by a
Finite State Machine (FSM). Figure 10-(c) shows a Finite State Machine that detects the
sequences of events in which as , ae , bs , and be appear according to the order has , bs , be , ae i.
Note that, for the sake of clarity, the self-loop transitions of the Finite State Machine are
not shown in Figure 10-(c).
P
Definition 17 (FSMs). AP
Finite State Machine  is a 5-tuple (S , , T , xP
0 , A ), where
S is a finite set of states,
is a finite set of alphabet symbols, T : S 
 S is a
mapping defining all transitions of , x0  S is the starting state, and A  S is a set of
accepting states.
We now show how by adding certain formulae to our SAT encodings, one can avoid
the members of a given regular language
from being produced as causally valid plans. Let
P
P be a temporal problem,P
and
= {e1 , ..., en } be the set of all events of P. Let L be
any regular
. Assume that L is accepted P
by the Finite State Machine
P langaue over
out
|T (xi , e) = xj , i 6= j} and
 = (S , ,P
T , A ). For each xi  S , let Ei = {e 
Eiin = {e 
|T (xj , e) = xi , i 6= j}. Assume that there are two dummy events e0 and
en+1 , which do not have any precondition, add effect, or delete effect. We define the SAT
variable xk,i for 1  k  l, 0  i  n + 1, and x  S . Assigning a value of true to xk,i
means that  will be in state x, after operating on the sequence of all events of the steps 1
to k  1 and the events of step k with the indices less than i of the final plan. We construct
the formula 
l by the conjunction of formulae (-1) to (-6) stated below:
(-1)

V

k,j
out  E in  {e
{eki  xk,i
s  xt |1  k  l, i < j, T (xs , ei ) = xt , ej  Et
n+1 },
t
in
out
{ei+1 , ..., ej1 }  (Et  Et ) = }

(-2)

V

(-3)

V

k,j
in
out
out
{eki  xk,i
s  xs |1  k  l, i < j, ei  Es , ej  Es  Es  {en+1 },
in
out
{ei+1 , ..., ej1 }  (Es  Es ) = }

k,i
in
out
{xk,0
s  xs |1  k  l, 1  i  n, xs  S , ei  Es  Es ,
in
out
{e1 , ..., ei1 }  (Es  Es ) = }

581

fiRankooh & Ghassem-Sani

(-4)

V

{xk,n+1
 xk+1,0
|1  k < l, xs  S }
s
s

(-5)

V

{xk,i
0 |1  k  l, 1  i  n}

(-6)

V

{xk,i |x  A , 1  k  l, 1  i  n + 1}

Adding 
l to the encoding of a problem makes the SAT solver to somehow simulate
the behavior of , while finding a model that represents a causally valid plan. Assume that
observing ei causes  to make a transition from xs to xt . Moreover, let ej be the first event
after ei (according to the fixed ordering e1 , ..., en ) that may cause a transition to or from
xt . Formula (-1) guarantees that if ei is a member of Stepk , and  is at state xs at the
time of observing ei , then the state of  will be changed to xt , and the next relevant event
of xt (i.e., ej ) will become aware of this transition. (-2) implies that if ei is not a member
of Stepk , and  is at state xs at the time of observing ei , then  will remain at xs , and
the next relevant event of xs will become aware of the current state of . (-3) causes the
information regarding the state of  at the start of each step to be propagated to the first
relevant event of that step. (-4) propagates the information regarding the state of  at
the end of each step to the next step. (-5) ensures that  can be at its starting state
at any place of the final plan. This means that the simulation of  can be started from
anywhere in the plan that is being produced. This enables the SAT solver to detect not
only the strings accepted by , but also strings that have some subsequences accepted by
. Finally, (-6) guarantees that  will never be at one of its accepting states.

Example 7. Let  be the Finite State Machine depicted in Figure 10-(c). This Finite
State Machine detects the sequences of events in which as , ae , bs , and be appear according
to the order has , bs , be , ae i. Assume that we have four events: e1 = as , e2 = ae , e3 = bs , and
e4 = be . Also assume that there are two dummy events e0 and e5 . For the sake of simplicity,
suppose that the problem does not have any events other than e0 to e5 , and the encoding has
only two steps. Consider a boolean assignment M , such that M (e11 ) = M (e13 ) = M (e14 ) =
M (e22 ) = true, and M (e12 ) = f alse. In other words, M is choosing as , bs , and be from the
first step, and ae from the second step. In fact, we have plan(M ) = has , bs , be , ae i. In this
example, we have E0in = {e2 }, because e2 = ae is the only event that causes a transition to
state s0 of . Similarly, we have: E0out = {e1 }, E1in = {e1 }, E1out = {e2 , e3 }, E2in = {e3 },
E2out = {e2 , e4 }, E3in = {e4 }, E3out = {e2 }, E4in = {e2 }, and E4out = . We show that if we
use the formulae (-1) to (-6) stated above to encode , then M cannot be a model for
the produced SAT formula. We show this by contradiction. Assume that M is a model for
the produced SAT formula.
 s0 is the starting state of . Hence, according to (-5), we have M (s01,1 ) = true,
which means that  is in state s0 , prior to checking whether e1 is present in the first
step of the final plan.
1
 s1,2
 According to (-1), we have e11  s1,1
1 . Since we have M (e1 ) = true and
0
1,2
M (s1,1
0 ) = true, we must also have M (s1 ) = true. In other words,  verifies that e1
is present in the first step of the final plan, which causes the current state of  to be

582

fiITSAT: An Efficient SAT-Based Temporal Planner

changed from s0 to s1 . M (s1,2
1 ) = true implies that  is in state s1 , prior to checking
whether e2 is present in the first step of the final plan.
1,3
1
 According to (-2), we have e12  s1,2
1  s1 . Since we have M (e2 ) = f alse and
1,3
1,2
M (s1 ) = true, we must also have M (s1 ) = true. In other words,  verifies that
e2 is not present in the first step of the final plan, which causes the state of  to
remain s1 . M (s1,3
1 ) = true implies that  is in state s1 , prior to checking whether e3
is present in the first step of the final plan.
1
 According to (-1), we have e13  s1,3
 s1,4
1
2 . Since we have M (e3 ) = true and
1,4
1,3
M (s1 ) = true, we must have M (s2 ) = true. In other words,  verifies that e3 is
present in the first step of the final plan, which causes the state of  to be changed
from s1 to s2 . M (s1,4
2 ) = true implies that  is in state s2 , prior to checking whether
e4 is present in the first step of the final plan.
1
 s1,5
 According to (-1), we have e14  s1,4
3 . Since we have M (e4 ) = true and
2
1,5
M (s1,4
2 ) = true, we must have M (s3 ) = true. In other words,  finds out that e4 is
present in the first step of the final plan, which causes the state of  to be changed
from s2 to s3 . M (s1,5
3 ) = true implies that  is in state s3 , after visiting all events of
the first step of the final plan.
1,5
2,0
 According to (-4), we have s1,5
3  s3 . Since we have M (s3 ) = true, we must also
have M (s2,0
3 ) = true, which implies that  is in state s3 , prior to visiting any event
of the second step of the final plan.
2,0
2,2
 According to (-3), we have s2,0
3  s3 . Since we have M (s3 ) = true, we must also
have M (s2,2
3 ) = true, which implies that  is in state s3 , prior to checking whether e2
is present in the second step of the final plan.
2
 s2,5
 According to (-1), we have e22  s2,2
4 . Since we have M (e2 ) = true and
3
2,5
M (s2,2
3 ) = true, we must also have M (s4 ) = true. In other words,  verifies that
e2 is present in the second step of the final plan, which causes the state of  to be
changed from s3 to s4 . M (s2,5
4 ) = true implies that  is in state s4 , after visiting all
events of the first two steps of the final plan. On the other hand, s4 is an accepting
state of . Hence, according to (-6), we have M (s2,5
4 ) = f alse. This is clearly a
contradiction. Therefore, we can conclude that M cannot be a model for the produced
SAT formula.

We now prove that adding 
l to the encoding of the given problem, prevents the planner
from producing those causally valid plans with a subsequence of events that is equivalent to
any string accepted by . This means that once a negative cycle has been translated into
an FSM, the reoccurrence of the negative cycle can be avoided by translating that FSM
into a SAT formula, and adding the formula to the encoding of the problem.
P
Theorem 11. Let P = (I, G, A) be a temporal planning problem,
= {e1 , ..., en } be the




set of all events of P, l be any of the three formulae l , l , l (defined in Section
P 4), and 
be a non-empty causally valid plan for P obtained by solving l . Let  = (S , , T , x0 , A )
583

fiRankooh & Ghassem-Sani

be an FSM that accepts a subsequence   = he1 , ..., em i of , and 
l be the encoding of
 presented by (-1) to (-6). There does not exist any model M for l  
l such that
 = plan(M ).
Proof. See Appendix A.
We also need to show that adding 
l to the encoding will not render our planner incapable of producing those plans that do not contain any subsequence accepted by .
P
Theorem 12. Let P = (I, G, A) be a temporal planning problem,
= {e1 , ..., en } be

the set of all events of P, and l be any of the three formulae l , l , l (defined in
Section 4). Let M be a model that satisfies l , and  = he1 , ..., em i = plan(M ). Let
P
 = (S , , T , x0 , A ) be an FSM that does not accept any subsequence of , and 
l be


the encoding of  composed of (-1) to (-6). There exists a model M for l  l such
that  = plan(M  ).
Proof. See Appendix A.
We now explain how a sequence of events that introduce a negative cycle in the STN of a
causally valid plan can be used to prevent similar negative cycles from reoccurringP
in future
plans produced for the problem at hand. Let P be a temporal planning problem,
be the
set of all events of P, and  = e1 , ..., en be a causally valid plan for P. Assume that the STN
representing the scheduling function of  has a negative cycle N with nodes xi1 , ..., xim . Note
that xik is the node corresponding to event eik of . Without loss of generality, we assume
that i1 < ... < im , i.e., the events of the negative cycle are ordered by the same order that
that are started but not finished
they have in . Let Oik be the set of all temporal actions P
{e|action(e)  Oik }  {eik }.
before reaching eik in the sequence ei1 , ..., eim , and P
ik =
Consider the regular language LN over the alphabet
defined by LN = ei1 i2 ei2 ...im eim ,
where ik denotes any string of the symbols in ik . In fact, in the strings of LN , events other
than those already present in the current negative cycle can be inserted in the sequence in
such a way that the temporal constraints among ei1 , ..., eim remain unchanged. To see why
we exclude the events of open actions from ik , consider two hypothetical events eij and eij 
that are respectively the starting event and the ending event of an action a. Therefore, there
is a temporal constraint on the scheduling function  in the form of  (ij  ) (ij ) = dur(a).
Here, if we insert another copy of the ending event of a between these two events, then a is
ended before the execution of eij  and, as a result, eij  will no longer be the pairing event
of eij , and the mentioned constraint will no longer exist.
Theorem 13. Let N = xi1 , ..., xim be a negative cycle in the STN corresponding to a
causally valid plan  = e1 , ..., en of a temporal problem P, where xik is the node corresponding to event eik of . Let   be another causally valid plan for P. If a subsequence of
  is a member of LN (defined above), the corresponding STN of   will also have N as a
negative cycle.
Proof. See Appendix A.
584

fiITSAT: An Efficient SAT-Based Temporal Planner

Consrtucting an FSM that accepts LN is straightforward. Let  be that FSM. Theorem
13 shows that if  is added to the encoding of the input problem, ITSAT will still be
capable of finding a valid temporal plan, provided that such a plan exists.

6. Empirical Results
In this section, we show how our preprocessing, encoding, and scheduling methods contribute to the overall performance of ITSAT. Since the contribution of the preprocessing
part can be investigated only when the encoding is fixed, we first analyze the performance of
the three encodings explained in Section 4. We also compare the performance of ITSAT with
several state-of-the-art temporal planners on all non-numerical temporal planning problems
of the previous International Planning Competitions.
In Section 4, we theoretically showed that our novel relaxed -step encoding is at least as
compact as the temporal versions of the -step and -step encodings for fixed ordering (i.e.,
the number of steps needed by our relaxed -step encoding to solve a given problem is less
than or equal to that of the temporal versions of the -step and -step encodings). Here, we
empirically show that our relaxed -step often needs a significantly smaller number of steps,
compared to the -step and -step encodings. We also show that the mentioned compactness
causes our relaxed -step to significantly outperform -step and -step encodings in the
benchmark problems in terms of both memory and speed.
In Section 3, we explained two preprocessing methods, namely mutual exclusion analysis
and action compression. In this section we show how each of these methods contribute to the
overall performance of ITSAT on the benchmark problems. For this purpose, we compare
four versions of ITSAT: 1) ITSAT without preprocessing, 2) ITSAT with mutual exclusion
analysis, 3) ITSAT with action compression, and 4) ITSAT with both mutual exclusion
analysis and action compression. Our experimental results show that each of these methods
separately enhance the performance of ITSAT.
In Section 5, we discussed that by adding certain blocking clauses to the encoding of
the problem, one can prevent negative cycles from reoccurring in the STNs of the produced
causally valid plans. We also introduced a more elaborate method for preventing such negative cycles, by adding some extra clauses that are based on certain Finite State Machines.
Here, we empirically show that our FSM-based method is crucial for the efficiency of ITSAT
in the problems with required concurrency.
Finally, we compare the performance of ITSAT with that of the state-of-the-art temporal planners, namely OPTIC (Coles et al., 2010), LPG-td (Gerevini et al., 2006), and
TFD (Eyerich et al., 2009). OPTIC and TFD have different degrees of temporal expressivity, whereas LPG-td is not temporally expressive at all (i.e., it is not capable of solving
the problems with required concurrency). We show that ITSAT significantly outperforms
OPTIC and TFD, while it is competitive with LPG-td in many domains.
6.1 Implementation Details
In order to parse the planning problems and domain, and also validating output plans
produced by ITSAT, we have used VAL, which is a plan validation tool developed by the
organizers of in IPC 2011. The schematic operators of a given domain are instantiated by the
objects of the input problem to produce all possible valid ground temporal actions. ITSAT
585

fiRankooh & Ghassem-Sani

then performs a polynomial reachability analysis to recognize those actions and prepositions
that are relevant to the given problem. For this purpose, all the goal conditions are initially
assumed to be relevant propositions. Any action that produces a relevant proposition upon
starting or ending is considered to be a relevant action. ITSAT then adds all preconditions of
starting and ending events of all relevant actions to the current set of relevant propositions.
The invariants of relevant actions will be added to this set, too. Updating the sets of relevant
propositions and actions are repeated until no further changes will occur in these sets. We
then update the set of relevant propositions by omitting some of relevant propositions that
are present in the initial state of the given problem. The omitted propositions are those that
are not deleted by any relevant action. These propositions will also be omitted from the
at-start, at-end, and invariants of all relevant actions. Mutual exclusion analysis and action
compression methods described in Section 3, are then performed on the sets of relevant
actions and propositions.
As we mentioned in Section 4, in all our encoding methods we assume that there exists a
predefined fixed ordering on all events of the given problem. In the current implementation
of ITSAT, the ordering in which the events are produced while constructing ground actions,
is taken as the presumed fixed ordering of events. The starting event of each action is
placed immediately before its corresponding ending event in the mentioned ordering. More
elaborate heuristic methods for producing such an ordering may result in a more compact
encoding (Rintanen et al., 2006). Investigating such methods is beyond the scope of this
paper and is left for future research.
In the current version of ITSAT, we use P recosat (Biere, 2009), which is a free off-theshelf system, as our SAT solver. We have also examined two other SAT solvers, namely
M inisat (Een & Biere, 2005) and Lingeling (Biere, 2013) for satisfying the formulae.
However, precosat had the best overall performance among these three SAT solvers; though
Lingeling had a better performance in terms of memory usage.
Since P recosat accepts formulae only in the Conjunctive Normal Form (CNF), all formulae described throughout this paper had to be translated to their equivalent CNF formulae. This has been performed simply by using logical equivalence relations such as
(1  2  1  2 ) and ((1  2 )  1  2 ).
For each problem, we start with a formula with just one step. We set a time limit
of three minutes for precosat to find a model for the formula. In the case of the failure,
we add three more steps to the formula and repeat this process until either a model is
found or a predetermined maximum time of 30 minutes is reached. In the case of success
in finding a model, a causally valid plan is extracted from the model. The plan is then
given to a scheduling process to find a valid temporal plan. If the scheduling function
fails, an appropriate FSM is generated and encoded in the problem formula (see Section
5) without increasing the number of steps. The new formula is again given to P recosat
to find a new model. Although parallel solving of formulae with different number of steps
was shown to be more effective than a nave sequential approach (Rintanen et al., 2006;
Streeter & Smith, 2007), our empirical results show that even our simple sequential method
is sufficient to outperform current temporal planners in many planning domains. We leave
the investigation regarding the effect of using such parallelism for our future research.
All the experiments explained in this section have been conducted on a 3.1GHz corei5
CPU with 4GB main memory. As our benchmark problems, we have used the problem
586

fiITSAT: An Efficient SAT-Based Temporal Planner

sets of all previous IPCs. These problems are from different planning domains including
zenotravel, rovers, and depots of IPC 2004, airport of IPC 2006, pegsol, crewplanning,
openstacks, elevators, sokoban, and parcprinter of IPC 2011, and driverlog, f loortile,
matchcellar, mapanalyser, parking, rtam, satellite, storage, turnandopen, and tms of
IPC 2014. Note that some of these domains have been used in different IPCs. For such
domains, we have chosen the problem set of the most recent competition with those domains.
That is why no problem set of IPC 2008 is present in our experiments.
Among the domains used in previous IPCs, only matchcellar, turnandopen, and tms
include problems with the required concurrency. These are the problem sets in which only
temporally expressive planners are capable of producing valid plans. In order to achieve
a better assessment of ITSAT in problems with required concurrency, we have used two
extra domains driverlogshift and matchlift (Halsey, 2004). We have also performed our
experiments on time-window variants of satellite and airport domains. These domains,
which have been used in IPC 2004 and do have required concurrency, are referred throughout
this section by satellite-tw and airport-tw, respectively. The mentioned domains with the
required concurrency are explained in more details in Section 6.4.
6.2 The Impact of Different Encoding Methods
To evaluate our -step, -step, and relaxed -step encodings we have produced three different versions of ITSAT, namely, ITSAT-, ITSAT-, and ITSAT- , respectively. In all
these versions, the formula mut , which encodes the mutex relations, is also added to the
encoding. None of these versions take advantage of action compression. The negative cycle
prevention method described in Section 5 has been used in all the three versions of ITSAT.
Table 2 shows a comparison in each domain among these versions with regard to the number
of solved problems.
As it can be seen in Table 2, ITSAT- has the best performance among the three
versions. In fact, ITSAT- has been able to solve 65 problems more than ITSAT-, and
103 problems more than ITSAT-. Furthermore, almost all problems solved by ITSAT-
or ITSAT- were also solved by ITSAT- . This means that our relaxed -step encoding
is significantly more efficient than the temporal versions of the classical -step and -step
encodings.
Table 3, shows a more detailed comparison among the mentioned encodings. The different columns of Table 3 represent the following items: the name of the domain, the problem
number, the used encoding method, the number of steps in the encoding, the result of
P recosat in terms of satisfiability or unsatisfiability of the formula, the number of clauses
and variables divided by 1000, the amount of time taken by P recosat to determine the
result, and the amount of memory needed for solving the formula. For each problem and
each encoding method, the results are presented for two cases: unsatisfiable formula with
the highest number of steps, and satisfiable formula with the lowest number of steps. Note
that to produce these results, we have increased the number of steps by one when a formula
was unsatisfiable. Symbol  is used in the time column for those cases in which P recosat
has failed to find a model for the formula in 1800 seconds. The results are presented only for
those domains in which at least one of the problems has been solved by at least two of the
planners. Accordingly, openstacks, elevators, matchcellar, and rtam have been omitted
587

fiRankooh & Ghassem-Sani

domain
zenotravel
rovers
depots
satellite-tw
airport-tw
airport
pegsol
crewplanning
openstacks
elevators
sokoban
parcprinter
driverlog
floortile
mapanalyser
matchcellar
parking
rtam
satellite
storage
turnandopen
tms
driverlogshift
matchlift
total

problems
20
20
22
36
50
50
20
20
20
20
20
20
20
20
20
20
20
20
20
20
20
20
10
14
542

ITSAT-
13
18
13
3
19
20
20
8
0
0
2
15
0
10
14
0
10
0
0
0
1
18
10
14
208

solved
ITSAT-
16
18
17
3
21
21
20
8
0
0
3
16
2
16
19
0
10
0
3
9
2
18
10
14
246

ITSAT-
16
20
19
3
21
38
20
20
9
0
2
17
3
20
19
18
10
0
3
9
2
18
10
14
311

Table 2: Overall Comparison of Different Encoding Methods
from Table 3. Moreover, in satellite and storage, the results are only presented for the
 -step and -step encodings.
In each domain, Table 3 presents only the results for the hardest problem (i.e., the
problem with the greatest number of propositions). In our experiments, we have observed a
pattern similar to that of the chosen problems for other problems of each domain. Note that
the results presented in Table 3 are only for finding the first causally valid plan. Therefore,
these results do not include the information regarding FSM encoding method described in
Section 5. We will explain the impact of our FSM-based negative cycle prevention later in
this section.

588

fiITSAT: An Efficient SAT-Based Temporal Planner

domain

zenotravel

rovers

depots

satellite-tw

airport-tw

airport

prob encoding steps

10

4

13

3

11

5

4

26

25

18

2

27

26

3

10

6

17

3

11

7


4

12

12

3

5

13

13


6

72

33

19

7

73

34


8

70

31
20

5

71

32


6
Continued on next page

result
F
F
F
T
T
T
F
F
F
T
T
T
F
F
F
T
T
T
F
F
F
T
T
T
F
F
F
T
T
T
F
F
F
T
T
T

589

C
1000

V
1000

474
133
69
521
167
92
5467
4444
375
5673
4618
511
7950
3256
1008
8747
3802
1336
33
26
7
36
28
8
5415
1811
243
5573
1817
270
9261
3189
430
9392
3290
506

136
33
23
150
42
32
560
412
15
581
428
24
1259
455
236
1387
534
326
9
7
3
10
8
3
1516
412
44
1541
439
49
1381
361
37
1401
373
44

time
(s)
25
0.4
0.38
33
0.54
0.56


0.14
89
47
0.36
6.6
2.2
1.39
8.9
3
2.1
1.2
1.4
0.1
0.7
0.7
0.1
24
3.7
0.43
19
4.1
0.5
27
3.5
0.16
21
4.3
0.62

mem
(MB)
131
18
10
146
20
17
413
244
12
353
220
12
598
284
129
1001
301
141
3
2
1
4
4
1
912
271
22
900
283
28
837
257
31
844
263
36

fiRankooh & Ghassem-Sani

domain

prob encoding steps

12

12

pegsol
20

5

13

13


6

69

69

crewplanning 8

4

70

70

5

19

13

sokoban
4

6

20

14

7

42

31

parcprinter
20

8

43

32


9

7

driverlog
2

5

8

6

22

11

floortile
10

6

23

12

7

17

9

mapanalyser 15

2
Continued on next page

result
F
F
F
T
T
T
F
F
F
T
T
T
F
F
F
T
T
T
F
F
F
T
T
T
F
F
T
T
F
F
F
T
T
T
F
F
F

590

C
1000

V
1000

34
25
10
37
27
12
112
102
3
114
104
3
542
274
122
571
295
142
2325
1436
345
2380
1482
385
2634
2803
5248
3291
201
74
31
211
80
36
187009
101893
29988

9
6
3
10
7
4
34
29
1
35
30
1
143
64
37
150
69
43
382
198
51
391
205
58
258
184
294
221
21
11
6
22
12
7
1005
534
122

time
(s)


0.05
22.4
7.3
0.3


0
30
15
0

12
3.9
74
40
1.5

30
1.1
93
25
0.7
6.2
14
23
13.9
55
7
0.14
20
0.62
0.16
18
10
5.4

mem
(MB)
28
26
1
14
11
3
40
49
1
44
46
1
163
78
23
190
125
20
319
119
24
289
128
26
165
70
280
131
48
16
5
49
13
5
1196
519
75

fiITSAT: An Efficient SAT-Based Temporal Planner

time
domain
prob encoding steps result
(s)

18
T
197433 1064
26

10
T
112123 593
11


3
T
40062
181
6.7

4
F
1769
150
2.5

2
F
605
75
0.5

parking
11

1
F
238
38
0.4

5
T
1868
187
4.2

3
T
911
112
2.5


2
T
470
75
2

11
F
870
221


satellite
3

5
F
294
91


12
T
950
244
157

6
T
352
110
4.9

11
F
1523
125


storage
9

8
F
633
84
48

12
T
1662
136
5.9


9
T
710
94
9.4

42
F
2416
203


22
F
944
106
33

turnandopen 1

10
F
371
53
1.1

43
T
2474
207
176

23
T
987
111
37

11
T
406
58
1.3

9
F
491
51
2.3

7
F
257
39
0.5

tms
18

3
F
91
18
0.1

10
T
546
56
1.4

8
T
284
43
0.5


4
T
115
23
0.3

18
F
373
65
1.5

15
F
235
37
0

driverlogshift 11

9
F
54
17
0

19
T
411
69
0.6

16
T
260
39
0.3


10
T
57
20
0.3
Table 3: Detailed Comparison of the Encoding Methods
C
1000

591

V
1000

mem
(MB)
1177
538
128
177
70
34
297
87
72
431
91
440
95
198
69
149
72
454
112
41
465
106
42
65
42
14
67
42
17
35
19
7
39
21
9

fiRankooh & Ghassem-Sani

Figure 11. Speed Comparison Between ITSAT- and ITSAT-

In Section 4, we theoretically showed that in order to solve a given planning problem,
our relaxed -step encoding requires fewer steps than the temporal versions of classical
-step and -step encodings when the ordering is fixed. Table 3 shows that ITSAT-
often needs a considerably smaller number of steps. This phenomenon is most prominent
in airport, crewplanning, and mapanalyser. Moreover, in openstacks and matchcellar,
neither ITSAT- nor ITSAT- was able to solve any problem due to the very large number
of steps that had been required. This suggests a correlation between the performance of
the planner, and the compactness of the encoding. Generally speaking, when a relatively
high number of steps is needed for -step encoding to solve a problem, we can deduce that
there is a strong causal connection between the actions of the produced plan. On the other
hand, our  -step encoding has been devised to take advantage of such causal connections.
Therefore, the  -step encoding is expected to have more advantage over the -step encoding
in such domains. This phenomenon is most visible in airport, crewplanning, openstacks,
and matchcellar domains, as the numbers of steps required by the -step encoding in these
domains are exceptionally high. Table 3 also shows that our relaxed -step encoding results
in a significant improvement of the planner in terms of the memory usage.
592

fiITSAT: An Efficient SAT-Based Temporal Planner

Figure 12. Speed Comparison Between ITSAT- and ITSAT-

We have also compared the speed of ITSAT- with that of ITSAT- and ITSAT- in
solving all the benchmark problems. The results are depicted in Figure 11 and Figure 12.
As it can be seen, ITSAT- has outperformed ITSAT- and ITSAT- in almost all the
problems.
6.3 The Impact of the Mutual Exclusion Analysis and Action Compression
In Section 3, we explained how mutual exclusion analysis and action compression are performed as preprocessing components of ITSAT. Here, we empirically show that these components are both quite effective in enhancing the performance of our planner. As we showed

before,  is the encoding that results the best performance of ITSAT. We have fixed this
formula as the base of comparison, and produced three other formulae to investigate the

impact of each preprocessing method. These three formulae are   mut (the base encod
ing plus the mutual exclusion information),   com (the base encoding plus the action

compression information), and   mut  com (the base encoding plus both mutual exclusion and action compression information). Table 4 shows the number of problems solved
by each of the mentioned versions of ITSAT.
593

fiRankooh & Ghassem-Sani

domain
zenotravel
rovers
depots
satellite-tw
airport-tw
airport
pegsol
crewplanning
openstacks
elevators
sokoban
parcprinter
driverlog
floortile
mapanalyser
matchcellar
parking
rtam
satellite
storage
turnandpen
tms
driverlogshift
matchlift
total

problems
20
20
22
36
50
50
20
20
20
20
20
20
20
20
20
20
20
20
20
20
20
20
10
14
542




13
20
11
3
21
38
20
20
1
0
1
17
0
3
14
0
3
0
0
0
2
0
10
14
211



  mut
16
20
19
3
21
38
20
20
9
0
2
17
3
20
19
18
10
0
3
9
2
18
10
14
311



  com
14
20
14
3
21
38
20
20
5
0
3
19
1
20
19
20
7
0
0
0
3
18
10
14
289



  mut  com
18
20
20
3
21
39
20
20
13
0
8
20
4
20
20
20
17
0
16
20
9
18
10
14
370

Table 4: The Impact of the Mutual Exclusion Analysis and Action Compression
As it can be seen in Table 4, these preprocessing methods result in a significant improvement in terms of overall coverage. In fact, the version of ITSAT that uses both methods
solves 159 problems more than the base planner. Besides, the version that uses both methods even considerably outperforms any of the two versions that only use one preprocessing
method. This suggest that both preprocessing components are necessary for producing the
best performance of ITSAT.
To investigate the effectiveness of our action compression method in the domains that
ITSAT compresses considerably more actions than CRIKEY, we have performed another
experiment. We compressed only the actions that ITSAT considers compression safe but
CRIKEY3 does not. In this new version of ITSAT, we also used the mutual exclusion
information. This version of ITSAT solves six problems more than the version where only
594

fiITSAT: An Efficient SAT-Based Temporal Planner

mutual exclusion information was used: of these six problems, four problems are from
zenotravel, one is from airport, and one is from mapanalyser. The results does not change
much in other domains. Note that the three mentioned domains are those in which ITSAT
compresses considerably more actions than CRIKEY.
6.4 The Impact of the FSM-Based Negative Cycle Detection
As mentioned earlier, among the domains used to evaluate ITSAT, matchcellar, turnandopen, tms, driverlogshift, matchlift, and time-window versions of airport and satellite can
have problems with required concurrency. In fact, in these domains, it may be impossible
to schedule a causally valid plan produced by solving a SAT formula, into a valid temporal
plan. Here, we briefly explain why the problems in each of these domains may require concurrency, and how this may introduce some negative cycles into the STN associated with a
causally valid plan.
In matchcellar and matchlift, there exists an action for lighting a match. This action
produces light for a certain amount of time. The objective is to mend some fuses. The
actions for mending a fuse can only be executed if there is light. As a result, the actions of
lighting a match and mending a fuse must be executed concurrent. However, in a causally
valid plan, since the planner does not consider the durations of actions, it may assume that
any match can remain lit until all the fuses are mended. As it was discussed in Section 5,
this can introduce a negative cycle into the STN of a produced causally valid plan.
In tms, the objective is to produce a certain number of ceramic structures. These
structures need several preparations that can be done only while a furnace is producing
heat. It should be clear that this domain is very similar to matchcellar and matchlift, and
requires concurrency in a similar way.
A simplified version of driverlogshift was introduced in Section 2. The only difference
between that simplified version and the one used in this section to evaluate the planners, is
that here, there are drivers that can walk to, board, and disembark trucks. Furthermore,
the REST and WORK actions are performed by the drivers rather than trucks. In this domain,
the working shifts of the drivers are analogous to the action of lighting a match in the
matchcellar domain.
In turnandopen, there exists a robot that needs to move between a number of rooms.
There are doors between each pair of adjacent rooms. All these doors, which are closed in
the initial state, should be opened by the robot. The robot can open a door only while it
is turning the doorknob. In this domain, the actions of turning the doorknob and opening
the door must be executed concurrently. However, the duration of the action for turning
the knob is 3, whereas that of opening the door is 2. This enables ITSAT to schedule every
causally valid plan into a valid temporal plan. Therefore, preventing negative cycles is not
necessary in this domain.
In time-window versions of airport and satellite, there is a specific time by which all
goals must be obtained. Such a deadline is introduced into a problem by using a specific
frame action with the duration equal to the time of that deadline. All other actions can
be executed only when this frame action is being executed. In other words, all the actions
must be concurrent with the is frame action. However, in a causally valid plan, since the
planner does not consider the durations of actions, it may assume that the frame action can
595

fiRankooh & Ghassem-Sani

domain
problem
satellite-tw
3
airport-tw
21
matchcellar
20
tms
18
driverlogshift
10
matchlift
14

restarts
121
1
34
3
43
9

C
1000


12
552
44
121
68
72

FSM
1450
5
408
12
930
180

V
1000


3
65
22
23
26
15

FSM
318
2
203
10
280
112

memory (MB)

FSM
1
382
41
1
9
77
16
2
13
107
31
98

Table 5: The Collective Size of the SAT Encodings of FSMs
be arbitrarily long, and thereby neglect to meet the deadline for achieving the goals. This
can introduce negative cycles into the STNs of produced causally valid plans.
As we explained in Section 5, if the STN of a causally valid plan includes a negative
cycle, we must force the SAT solver to find a different solution. This can be done simply
by adding an extra blocking clause to the current SAT formula to prevent at least one of
the events of that negative cycle from reoccurring in its current step. Alternatively, we
introduced a more elaborate method for doing the same thing, by adding the encoding of
certain FSMs into the encoding. In this method, when the STN of a causally valid plan with
k steps includes a negative cycle, an FSM that detects that negative cycle will be encoded
into a SAT formula, and the solver will be restarted. In order to decrease the number of
restarts, whenever a sequence of events corresponding to a negative cycle is found, ITSAT
tries to find other potential negative cycles by replacing the actions of current sequence by
other actions of the problem and checking the STN of the resulting sequence for negative
cycles.
Table 5 shows the collective size of the SAT encodings of the FSMs required for solving
the problems of the above domains. As our base encoding, we have used the relaxed
-step encoding with both mutual exclusion analysis and action compression. For each
domain, the results are shown in Table 5 only for the hardest problem solved by ITSAT. The
turnandopen domain has been excluded from Table 5, as no negative cycle is encountered
when solving problems of this domain. The different columns of Table 5 represent the
following items: the name of the domain, the problem number, the number of clauses and
variables divided by 1000, and the amount of memory needed to produce the formula. The
results for the number of causes, number of variables, and the used memory are presented
with separated columns for the base encoding and the encoding of the FSMs.
As it can be seen in Table 5, our negative cycle prevention method helps ITSAT solve
a considerable number of problems with required concurrency. Nevertheless, the SAT encoding of the required FSMs is significantly larger than the base encoding in the domains
where the number of restarts are relatively high. On the other hand, as the number of the
restarts increase, the speed of ITSAT declines. That is because after each restart, the SAT
solver must verify the satisfiability of the formula, from scratch. In fact, these numerous
restarts are the main reason for the poor performance of ITSAT in the time-window version
of satellite.
596

fiITSAT: An Efficient SAT-Based Temporal Planner

6.5 ITSAT Versus the State-of-the-art Temporal Planners
We now compare ITSAT with three efficient temporal planners, namely, OPTIC (Benton,
Coles, & Coles, 2012), TFD (Eyerich et al., 2009), and LPG-td (Gerevini et al., 2006).
Because of the similarities between the approach used in ITSAT and that of SCP2 (Lu
et al., 2013), we have also included the results of this planner in our experimental results.
OPTIC is the newest version of POPF (Coles et al., 2010). It is a heuristic state-space
temporal planner based on the so-called temporally-lifted progression planning (Cushing
et al., 2007). Using this approach of planning enables OPTIC to solve problems with
required concurrency. Besides, OPTIC handles self-overlapping actions, which makes it
more expressive than ITSAT. Although handling self-overlapping actions is hardly necessary
for solving non-numerical temporal planning problems (Fox & Long, 2007), among the
current benchmark domains, zenotravel, rovers, and airport do permit such actions due to
some modeling errors. For a fair comparison between ITSAT and OPTIC, we have used the
corrected versions of these three domains1 in our evaluations. For guiding its search, OPTIC
benefits from a heuristic function that is based on the relaxed planning graph (Hoffmann
& Nebel, 2001).
TFD is another heuristic state-space temporal planner. TFD is based on the so-called
decision epoch planning (Cushing et al., 2007). The planners that use this approach are
not as temporally expressive as the planners that are based on temporally lifted progression planning. In other words, in theory, there are temporal planning problems defined in
PDDL2.1 that can be solved by ITSAT and OPTIC but not by TFD. However, all the current benchmark problems can potentially be solved by using decision epoch planning. For
guiding its search, TFD benefits from a temporal version of the so-called Context-enhanced
Additive Heuristic (Helmert & Geffner, 2008).
LPG-td is a very fast temporal planner, which is not temporally expressive. In fact,
LPG-td at first generates a sequential plan for a given problem, and then tries to reschedule
the plan to produce one with an improved quality. This renders LPG-td incapable of
solving any problem in matchcellar, turnandopen, tms, driverlogshift, or matchlift. Similar
to OPTIC, LPG-td benefits from a heuristic based on the relaxed planning graph. However,
instead of searching in the state space of the problem, LPG-td performs its search by making
some local improvements to a structure that is similar to partial plans, which is called Linear
Action Graph. Two different configurations of LPG-td can be used based on whether we
prefer speed of the planner or the quality of produced plans. Here, we only present the
results of the quality configuration of LPG-td, as it produced better results than the speed
configuration in our experiments.
SCP2 (Lu et al., 2013), is a SAT-based temporal planner that uses a discrete representation of time. This planner assigns explicit discrete time labels to each step of the encoding.
In this approach, each step i is exactly one time unit ahead of step i + 1. As a result, if an
action with duration d starts in step i, it is forced to end in step i + d. This means that the
number of layers required for producing a plan  is greater than or equal to the makespan
of . SPC2 starts with a formula with only one step, an increases the number of steps by
one, every time the formula is unsatisfiable. This enables SPC2 to find the optimal plan for
1. The corrected version of mentioned domains can be downloaded from the official website of POPF
planner.

597

fiRankooh & Ghassem-Sani

a number of given problems. To obtain a better performance, SCP2 uses -step semantic
to allow causal relations between actions in each time point.
We have compared ITSAT with the above planners based on the number of problems
they can solve in each domain and also by the total score given to each planner using the
scoring strategy of recent IPCs; that is, if a planner cannot solve a problem, it will get a
score of 0 for that problem; Otherwise, its score will be equal to the makespan of the best
produced plan divided by the makespan of the plan found by this planner. The results are
presented in Table 6.
As it can be seen in Table 6, ITSAT significantly outperforms OPTIC, TFD, and SCP2.
In fact, ITSAT solves 162 problems more than OPTIC, 145 problems more than TFD, and
282 problems more than SCP2. ITSAT also solves 64 problems more than LPG-td. However,
this is mainly because LPG-td is incapable of solving problems with required concurrency.
If we exclude satellite-tw, airport-tw, matchcellar, turnandopen, tms, driverlogshift, and
matchlift that are the domains in which LPG-td cannot solve any problem, ITSAT solves
only 31 problems less than LPG-td. This shows that ITSAT is quite competitive with
LPG-td even in solving the problems without required concurrency.
As it is shown in Table 6, OPTIC solves zero problems in parcprinter, driverlog, floortile,
mapanalyser, matchcellar, rtam, storage, and tms. In all of these domains, the main reason
of poor performance of OPTIC is that it runs out of memory, early during its search. TFD
solves zero problems in satellite-tw, airport-tw, parcprinter, driverlog, floortile, rtam, storage,
and tms. Except for parcprinter, in which TFD runs out of memory, in other domains
TFD performs poorly because it is unable to find a plan within 1800 seconds. As we
mentioned before, LPG-td solves zero problems in the domains with required concurrency.
The performance of SCP2 is rather poor in many of the benchmark domains. The reason of
the poor performance of SCP2 is that, for many of the benchmark problems, the makespan
of the optimal plan is relatively large. As a result, in most of the problems, SCP2 is unable
to check the satisfiability of all the formulae with numbers of steps less than the makespan
of the optimal plan, within the 1800 seconds time limit.
To compare the quality of the plans produced by ITSAT with those of other competing
planners, consider Table 7. The numbers presented in Table 7 are the average makespan
ratio of plans mutually solved by the corresponding planner and ITSAT in the corresponding
domain. Ratios less than one indicate better average quality of the solutions produced by
ITSAT in comparison with the competing planners. For those cases that neither ITSAT nor
the competing planner has been able to solve any problem of a domain, the corresponding
cell of Table 7 has remained blank.
We have also performed some experiments based on a number of two planners portfolios
of different pairs of the above planners. The portfolios enabled us to combine the advantages
of two planners. To do this, the 30 minutes time limit is divided equally between each pair
of planners. The results of running these portfolios are presented in Table 8. The results
show that the best configuration has been obtained by combining ITSAT and LPG-td. The
resulting planner was capable of solving 423 out of 542 benchmark problems. Moreover,
each of these planners has produced its best results when it was combined with ITSAT.

598

fiITSAT: An Efficient SAT-Based Temporal Planner

solved

domain

N

zenotravel

20

18

rovers

20

depots

ITSAT

OPTIC

SCP2

IPC

score

ITSAT

OPTIC

TFD

LPG-td

SCP2

TFD

LPG-td

12

12

20

1

11.41

10.56

11.32

17.68

1

20

20

20

20

4

18.25

18.35

18.56

16.88

4

22

20

7

5

21

6

9.52

4.21

3.04

19.43

6

satellite-tw

36

3

4

0

0

0

3

4

0

0

0

airport-tw

50

21

7

0

0

0

21

7

0

0

0

airport

50

39

24

20

43

0

35.2

23.35

18.11

39.68

0

pegsol

20

20

19

18

20

20

19.36

18.02

17.24

18.98

20

crewplanning

20

20

20

14

9

0

18.37

20

11.94

7.82

0

openstacks

20

13

20

20

20

0

7.26

17.01

19.83

15.23

0

elevators

20

0

1

3

9

0

0

1

3

7.44

0

sokoban

20

8

2

3

5

1

7.64

1.72

3

3.26

1

parcprinter

20

20

0

0

7

0

20

0

0

5.72

0

driverlog

20

4

0

0

14

0

3.89

0

0

13.38

0

floortile

20

20

0

0

20

10

17.05

0

0

16.51

10

mapanalyser

20

20

0

19

20

0

18.48

0

15.62

14.81

0

matchcellar

20

20

20

20

0

0

20

20

16

0

0

parking

20

17

16

20

20

6

5.05

13.98

18.72

19.02

6

rtam

20

0

0

0

20

0

0

0

0

20

0

satellite

20

16

4

13

20

0

2.61

3.55

7.05

20

0

storage

20

20

0

0

18

20

18.77

0

0

1.45

20

turnandopen

20

9

9

18

0

1

9

6.52

13.34

0

1

tms

20

18

0

0

0

0

18

0

0

0

0

driverlogshift

10

10

10

6

0

9

8.01

9.48

5.03

0

9

matchlift

14

14

13

14

0

13

14

13

14

0

13

total

542 370

208

225

306

88

305.87 191.75 195.8

Table 6: ITSAT Versus State-of-the-art Temporal Planners

599

256.29 88

fiRankooh & Ghassem-Sani

domain
zenotravel
rovers
depots
satellite-tw
airport-tw
airport
pegsol
crewplanning
openstacks
elevators
sokoban
parcprinter
driverlog
floortile
mapanalyser
matchcellar
parking
rtam
satellite
storage
turnandopen
tms
driverlogshift
matchlift

OPTIC

TFD

LPG-td

SCP2

1.47
0.99
1.24
1
1
1.06
0.98
1.11
1.34

0.86




1
2.94

6.72

0.72

1.14
1

1.50
1.03
1.41


0.95
0.98
0.89
1.90

1.18



0.86
0.80
2.98

4.45

0.48

0.98
1

1.41
0.89
2.02


0.91
0.96
0.88
1.31

0.69
0.81
1.03
0.97
0.79

3.01

7.35
0.11





1
1.27
2.11



1.02



1


1.05


3.15


1.05
1

1.19
1

Table 7: Average Makespan Ratio

ITSAT
OPTIC
TFD
LPG-td
SCP2

ITSAT

375
385
423
348

OPTIC
375

262
350
237

TFD
385
262

360
256

Table 8: 2-planners Portfolio

600

LPG-td
423
350
360
302

SCP2
348
237
256
302


fiITSAT: An Efficient SAT-Based Temporal Planner

Figure 13. Speed Comparison Between ITSAT and OPTIC

Although ITSAT is quite competitive with the state-of-the-art temporal planners, our
empirical results reveal a few drawbacks of the planner. We have compared the speed of
ITSAT with that of OPTIC, TFD, LPG-td, and SCP2 on all of our benchmark problems.
The results are presented in Figure 13, Figure 14, Figure 15, and Figure 16, respectively.
In these figures, the results for the required concurrency domains have been separated
from that of other domains by using different symbols in the scatterplots: the star symbol
represents the problems with required concurrency, and the diamond symbol represents
other problems. As it can be seen, ITSAT is slower than OPTIC, TFD, and LPG-td in a
number of the benchmark problems. A major cause of this drawback is that in ITSAT, the
SAT solver spends too much time refuting several formulae before it will finally find the
first satisfiable formula. As it has been shown in the case of classical planning, the speed of
SAT-based planners can be significantly improved by checking the satisfiability of several
formulae with different number of steps in parallel. We discuss this in more detail in Section
7 as our future research.
Another observation is that, ITSAT performs rather slowly in solving a number of
problems with required concurrency that are quickly solved by OPTIC and TFD. This is
mainly due to restarting the SAT solver whenever negative cycles are encountered. As we
601

fiRankooh & Ghassem-Sani

Figure 14. Speed Comparison Between ITSAT and TFD

explained earlier, when the STN of a causally valid plan with k steps includes a negative
cycle, an FSM detecting that negative cycle will be encoded into a SAT formula, and the
solver will try to satisfy the new formula with k steps, from scratch. In the domains where
these negative cycles are abundant, the performance of ITSAT can be significantly affected
by the numerous restarts of the SAT solver.
The performance of ITSAT is particularly poor in three domains, namely elevators,
driverlog, and rtam. In these domains, the number of ground actions is higher than
that of other domains. A linear increase in the number of ground actions may cause an
exponential growth in the size of the search space of the problem. To tackle this problem,
state-space based planners take advantage of heuristic functions that are devised specially
for pruning the search space of planning problems. It has also been shown that using SAT
solvers tailored for solving planning problems can result in a significant improvement of the
performance of SAT-based classical planning (Rintanen, 2012). We think that employing
this idea can also improve the speed of ITSAT in the mentioned domains.
Another drawback of ITSAT is the poor quality of its produced plans in some benchmark
domains. Most notably, although ITSAT solves most of the problems in depots, openstacks,
parking, and satellite, the quality of its plans is rather low in these domains, according to
602

fiITSAT: An Efficient SAT-Based Temporal Planner

Figure 15. Speed Comparison Between ITSAT and LPG-td

Table 7. This is mainly due to the fact that ITSAT abstracts out the duration of actions,
and thus, its SAT solver lacks the competency for evaluating the quality of the plans that
are being produced. Nevertheless, the quality of the plans produced by ITSAT is generally
comparable to that of other planners in most benchmark domains. In Section 7, we explain
an idea for improving the quality of the plans produced by ITSAT.

7. Conclusions and Future Research
In this paper, we described ITSAT, a temporally expressive SAT-based planner. ITSAT is
based on an approach that takes advantage of parallel encodings. In this approach, at first,
the durations of all actions of a given problem are abstracted out. Then the abstract problem
is encoded into a SAT formula using -step and -step semantics for causally valid plans.
After generating a causally valid plan, ITSAT performs a scheduling process. During this
process, ITSAT tries to satisfy those temporal constraints that are imposed by considering
the durations of actions. This is done by solving a Simple Temporal Problem (STP). In the
cases with an inconsistent STP, the cause, which is a negative cycle in the corresponding
Simple Temporal Network (STN), is detected. ITSAT then adds certain clauses to the SAT
formula at hand to prevent the reoccurrence of such negative cycles. This process is then
603

fiRankooh & Ghassem-Sani

Figure 16. Speed Comparison Between ITSAT and SCP2

repeated until a temporally valid plan will be produced, or a predefined time limit will be
reached.
The main contributions of this paper can be summarized as follows:
 We introduced a novel method to detect temporal actions that can be compressed into
classical ones. The new compression technique is performed as a preprocessing task
and thus is independent from the planning algorithm and can be used by any other
temporal planner. This makes our compression technique more general than that of
POPF, which is specifically tailored for that planner. Our empirical results showed
that such action compression results in an improved performance for ITSAT. We also
empirically showed that our method is capable of detecting more compression-safe
temporal actions than the only previous action compression method, used by POPF.
 We introduced three new encoding methods based on the concept of parallel plans for
SAT-based temporal planning. While two of these methods have been adopted from
classical planning, our third method, which produces more compact formulae, has
been employed by ITSAT for the first time. Our empirical results show that this new
encoding can significantly enhance the performance of SAT-based temporal planning.
604

fiITSAT: An Efficient SAT-Based Temporal Planner

 We introduced a method to avoid producing the plans that are members of a given
regular language over the set of all events. This was done by embedding the SAT
encoding of a particular FSM that accepts the language into the SAT encoding of
the input problem. We used this method for preventing the temporal inconsistencies
of the produced causally valid plans from reoccurring in subsequent causally valid
plans. Our experiments showed that this method contributed considerably to the
performance of ITSAT in current benchmark problems with required concurrency.
According to our empirical results, by taking advantage of these new approaches, not
only does ITSAT outperform the state-of-the-art temporally expressive planners, it is also
competitive with the most efficient temporal planners that do not handle required concurrency. Nevertheless, we believe that the performance of ITSAT can be improved in several
ways, which are discussed below.
In the current version of ITSAT, the satisfiability of formulae with different number of
steps are checked in a sequential manner, starting with a formula encoding one step. This
means that the SAT solver has to refute several formulae until it finds the first satisfiable
formula. If the time required for checking the satisfiability of formulae increased with the
number of steps, this policy would result in the best performance of ITSAT. However, this
is almost never the case. As it has been shown in the case of classical planning, for a fixed
planning problem, the time needed for finding a model for a satisfiable formula is usually
considerably less than the time needed for refuting an unsatisfiable formula (Rintanen et al.,
2006). Based on our experiments, the same phenomenon happens in the case of temporal
planning, too. Similar to the SAT-based classical planning, one can take advantage of this
phenomenon by checking for the satisfiability of formulae with different numbers of steps
in parallel. The applicability of such parallelisms can be very sensistive to the amount
of memory required for saving the formulae. As it was shown in Section 6, our newly
introduced  -step encoding is considerably more efficient than the temporal version of the
classical -step encoding in terms of the memory usage. This suggests that our  -step
encoding is more suitable for employing such parallelism.
As in linear sized classical -step and -step encodings, in all our encoding methods,
we assume that there exists a predefined fixed ordering on all events of a given problem.
This ordering can have a great impact on the number of steps needed for solving the input
problem. For example, consider a sequential plan in which no ground action is applied more
than once. If this potential plan is a subsequence of the mentioned fixed ordering, then only
one step will be sufficient for finding the plan. On the other hand, if in this case we reversed
this fixed ordering, the number of steps that would be required to find the model might be as
large as the size of the plan itself. In the current implementation of ITSAT, the ordering in
which the events are produced while constructing ground actions, is taken as the predefined
fixed ordering of events. However, considering the causal relationships among the actions
of a given problem, one might be able to find more effective orderings that would result
in a fewer steps for solving the problem. We believe that this enhancement would result
in an improved version of ITSAT, which will be more efficient in terms of both speed and
memory usage.
The current version of ITSAT uses off-the-shelf general-purpose SAT solvers. This
means that any advancement in designing such solvers can also improve the performance of
ITSAT. Recent investigations in the field of SAT-based classical planning have shown that
605

fiRankooh & Ghassem-Sani

designing a SAT solver tailored for solving planning problems can result in a much improved
performance of SAT-based planners. In particular, the most efficient SAT-based classical
planner, Mp (Rintanen, 2012), has been able to be competitive with the sate-of-the-art
state-space based planners by employing this idea. Since the causal structures of temporal
planning problems are generally very similar to that of classical planning problems, we
believe that ITSAT can benefit enormously from employing a planning-oriented SAT solver.
As mentioned in Section 6, one of the main drawbacks of ITSAT is the poor quality of
its produced plans in some of the benchmark domains. This is mainly due to the fact that
ITSAT abstracts out the duration of actions, and thus, the SAT solver does not have the
needed resources for evaluating the quality of the plans that are being produced. Alternatively, one can add an explicit representation of the time into the encoding (Shin & Davis,
2005). This can be done by using SMT solvers (Armando & Giunchiglia, 1993), which handle continuous variables. However, as it was discussed in Section 1, this solution may result
in a considerably slower search. We think that ITSAT can benefit from a combination of
these two approaches: after that the first plan is produced by ITSAT, it can proceed by
introducing appropriate numerical constraint to the SAT formula at hand, and then use an
SMT solver to produce improved plans. This is the subject of our ongoing research.
Finally, we should mention that some of the components of ITSAT, can also be used in
other fields of AI planning. Most notably, our  -step encoding can also be employed in
SAT-based classical planning. Our empirical results show that this encoding method can
be quite effective in reducing the number of steps needed to produce valid plans in several
temporal planning domains that also have a classical version. We think that the improved
performance of the  -step encoding in comparison to the -step encoding can be achieved
in classical planning, too. Moreover, in Section 5, we showed how to prevent members of
any given regular language on the events of the input problem from being produced as the
output plan. We used this method to prevent ITSAT from producing temporally invalid
plans. The same method can be employed to enforce a variety of constraints on the plan
that is being produced. For example, consider the case where we require certain actions
to be executed only in a specific order. It must be clear that the set of all plans violating
this constraint can be regarded as a regular language over the set of all actions. Therefore,
such a constraint can be introduced to the encoding of the problem by the same method
discussed in Section 5.

Acknowledgments
The authors would like to thank the handling editor, Jorg Hoffmann, and the anonymous
reviewers for their invaluable contributions to the quality of this paper.

Appendix A. Proofs
Theorem 1. Let P = (I, G, A) be a temporal planning problem and P c = (state(I), G, Ac )
be the causal abstraction of P. Assume that  = he1 , ..., en i is a sequence of events that is
applicable in I, and sn = succ(I, ). Then the following conditions must hold:
 If two propositions p and q are both members of state(sn ), then p and q are non-mutex
in the layer n of the planning graph of P c .
606

fiITSAT: An Efficient SAT-Based Temporal Planner

 If proposition p is a member of state(sn ), and action a is a member of agenda(sn ),
then p and opena are non-mutex in layer n of the planning graph of P c .
Proof. We give the proof by induction on n (the length of ). For n = 0, i.e., when no
event is applied to I, the conclusions obviously hold because every member of state(I) is
present in the first layer of the graph, we have no mutex in the first layer, and we have
agenda(I) =  by Definition 6. Now suppose the conclusions hold for n = k  1. We show
that they will also hold for n = k. Assume that  = he1 , ..., ek i is a sequence of events that
is applicable in I, sk = succ(I, ), and sk1 = succ(I, he1 , ..., ek1 i).
 Let p and q be two members of state(sk ). There are three possible cases:
Case 1: if both p and q are members of sk1 , then by the induction hypothesis, p and
q are non-mutex in layer k  1 of the planning graph of P c and thus noopp and noopq
are non-mutex in layer k  1. Hence, p and q will not be mutex in layer k.
Case 2: if neither p nor q are members of state(sk ), then by Definition 5, p and q
must be both members of add(ek ). Assume that ek is the ending event of action a
(the case where ek is the starting event of a is analogous and thus is omitted here).
Since ek is applicable in state sk1 , by Definition 4, all members of pre(ek ) must be
also members of state(sk1 ), and a must be a member of agenda(sk1 ). Therefore, by
the induction hypothesis, all members of pre(ae ) are non-mutex in layer k  1. As a
result, p and q, which based on Definition 10 are both added by ae , will be non-mutex
in layer k.
Case 3: if only p is a member of state(sk1 ), then by Definition 5, q must be a member
of add(ek ), and p cannot be a member del(ek ). Assume that ek is the ending event of
action a (again, the case where ek is the starting event of a is analogous and thus is
omitted here). By the induction hypothesis, all members of pre(ae ) are non-mutex in
layer k  1, and by Definition 10, ae does not delete p. Therefore, ae will be present
in layer k  1 and it cannot be mutex with noopp . As a result, p and q are non-mutex
in layer k.
 Let p be a member of state(sk ), and action a be a member of agenda(sk ). There are
two possible cases:
Case 1: if a is also a member of agenda(sk1 ), then a is started but not yet ended
before reaching sk1 , and all invariants of a have to be members of state(sk1 ). By
the induction hypothesis, these invariants must be non-mutex in layer k 1. Hence, ai
is present in layer k  1. By Definition 10, ai adds opena . Now, we must show that p
can be added by an action that is not mutex with ai in layer k  1. If p is a member of
state(sk1 ), then by the induction hypothesis, p is present in layer k  1. Therefore,
noopp , which is not mutex with ai , is applicable in layer k  1 and, as a result, p
and opena are not mutex in layer k. On the other hand, if p is not a member of
state(sk1 ), it must be added by ek . Since ek is applicable in sk1 and a is a member
of agenda(sk1 ), by Definition 4, ek cannot delete any invariant of a. Assume that ek
is the ending event of action b (the case where ek the starting event of b is analogous
and thus is omitted here). By the induction hypothesis, be , which is not mutex with
607

fiRankooh & Ghassem-Sani

ai must be applicable in layer k  1. This means that p and opena will not be mutex
in layer k.
Case 2: if a is not a member of agenda(sk1 ), then by Definition 5, ek must be the
starting event of a, and a does not delete p. Moreover, by Definition 4, all starting and
invariants of a must be present in state(sk1 ). Therefore, by the induction hypothesis,
as is applicable in layer k  1. If p is not present in state(sk1 ), then it must be added
by ek . By Definition 10, all propositions added by the starting event of a are also
added by as . Since as also adds opena , then p and opena cannot be mutex in layer k.
On the other hand, if p is a member of state(sk1 ), then by the induction hypothesis,
p is present in layer k  1. Therefore, noopp , which is not mutex with as , is applicable
in layer k  1. This means that p and opena will not be mutex in layer k.

Theorem 2. Let P = (I, G, A) be a solvable temporal planning problem. Let A be the set
of every member of A that is either compressible towards its start or compressible towards
its end. A is compression-safe for P.
Proof. Let 0 be a causally valid plan for P (Such a plan must exist because P is solvable).
Starting from 0 , we produce a sequence of causally valid plans by swapping the events
that are next to each other in the plan at hand. Assume an arbitrary order ha1 , ..., an i
on all members of A . Without loss of generality, we assume that no action is repeated in
0 (otherwise, different names can be given to the different occurrences of the same action
to eliminate such a repetition). For producing the causally valid plan i , we consider the
causally valid plan i1 . If ai is compressible towards its start, we keep swapping the ending
event of ai with its previous event in i1 until that previous event becomes the starting
event of ai . In fact, doing these swaps collectively cause ai to become compressed towards
its start. Doing such swaps can never falsify the causally valid plan at hand: assume that
e is the event immediately prior to the ending event of ai in a causally valid plan, and e
is not the starting event of ai . Then each precondition and effect of e must be present
in at least one state whose agenda includes ai . Thus, by Theorem 1, no precondition or
effect of e can be mutex with openai in the last layer of the levelled-off planning graph of
the causal abstraction of P. Then by Definition 13, e must be swappable with the ending
event ai . Therefore, i is a causally valid plan in which the starting and ending events of
ai are located next to each other. Similarly, if ai is compressible towards its end, we keep
swapping the starting event of ai with its next event in i1 until that next event becomes
the ending event of ai . As a result, in n , the ending event of all members of A are located
next to their corresponding starting events, and therefore, according to Definition 11, A is
compression-safe for P.
Lemma 1. Let S = {e1 , ..., en } be a set of events, E and R, be two subsets of S. Assume
that S  is a subset of S such that if ei  S   E, we have ej 
/ S   R for all j > i. Let M
be the function that is defined by the following rules and assigns a value of true or f alse
to each SAT variable of chain(e1 , ..., en ; E; R; k; m):
608

fiITSAT: An Efficient SAT-Based Temporal Planner

 For each i, M (eki ) = true if and only if ei is a member of S  .
 For each i, M (bki,m ) = true if and only if there is ej  S   E such that j < i.
Then M satisfies chain(e1 , ..., en ; E; R; k; m).
Proof. We show that M satisfies formulae (C-1) to (C-3), and therefore it satisfies
chain(e1 , ..., en ; E; R; k; m).
/ S  then
(C-1) Consider an arbitrary formula eki  bkj,m from the formula (C-1). If ei 
M (eki ) = f alse, and thus the formula is trivially satisfied. Now consider the case
where ei  S  . By the definition of formula (C-1), we know that i < j and ei  E.
Therefore, according to the definition of M , we must have M (bkj,m ) = true, and thus
again the formula is satisfied.
(C-2) Consider an arbitrary formula bki,m  bkj,m from the formula (C-2). If M (bki,m ) =
f alse, the formula is trivially satisfied. On the other hand, if M (bki,m ) = true, then
there must exist an l, such that l < i and el  S   E. Since i < j, we must have
l < j, and therefore, we have M (bkj,m ) = true, and hence the formula is satisfied.
(C-3) Consider an arbitrary formula bki,m  eki from the formula (C-3). If M (bki,m ) =
f alse, the formula is trivially satisfied. On the other hand, if M (bki,m ) = true,
then there must exist an l, such that l < i and el  S   E. Then according to
the properties of S  , we must have ei 
/ S   R. However, by the definition of
chain(e1 , ..., en ; E; R; t; m), we have ei  R and, as a result, ei 
/ S  . Therefore,
k
M (ei ) = f alse and the formula is satisfied.

Lemma 2. Let S = {e1 , ..., en } be a set of events, and E and R be two subsets of S. Assume
that M is a model for chain(e1 , ..., en ; E; R; k; m). If ei  E and M (eki ) = true, then for all
j > i such that ej  R, we have M (bkj,m ) = true, and consequently M (ekj ) = f alse.
Proof. Suppose that in sequence e1 , ..., en , event ej is the first event after ei such that
ej  R. Since in the formula (C-1) of chain(e1 , ..., en ; E; R; k; m), we have eki  bkj,m , then
M (bkj,m ) = true. Similarly, if in sequence e1 , ..., en , event ej  is the first event after ej
such that ej   R, then we must have the formula bkj,m  bkj ,m in (C-2), which implies
that M (bkj ,m ) = true. By repeating the argument of the latter case, we infer that for
all j > i such that ej  R, we have M (bkj,m ) = true, and according to (C-3), we have
M (ekj ) = f alse.
Theorem 3 (completeness of temporal -step encoding). Let P = (I, G, A) be a
solvable temporal planning problem, {e1 , ..., en } be the set of all events of P, and  =
hStep1 , ..., Stepl i be a causally valid -step plan for P. There exists a model M for l such
that  = plan(M ).
609

fiRankooh & Ghassem-Sani

Proof. We construct a function M that assigns true or f alse to all SAT variables of the
formula l . Let hs0 , ..., sl i be the state transition sequence of . M is defined by the
following rules:
 For each proposition p, and each k such that 0  k  l, M (pk ) = true iff p is a
member of state(sk ).
 For each action a  A, and each k such that 0  k  l, M (ak ) = true iff a is a member
of agenda(sk ).
 For each each i such that 1  i  n, and each k such that 1  k  l, M (eki ) = true
iff ei is a member of Stepk . Moreover, for each k such that 1  k  l, M (ek0 ) =
M (ekn+1 ) = f alse.
 For each proposition p, each i such that 0  i  n + 1, and each k such that 0  k  l,
M (bki,mp ) = true iff there exists and event ej , such that j < i, ej  Ep , and ej  Stepk .
1

 For each proposition p, each i such that 0  i  n + 1, and each k such that 0  k  l,
M (bki,mp ) = true iff there exists and event ej , such that j > i, ej  Ep , and ej  Stepk .
2

We show that M satisfies all formulae (-1) to (-13), and therefore is a model for l . Note
that by the way M is constructed, we directly have  = plan(M ).
(-1) According to Definition 15, we have s0 = I, and thus formula (-1) is clearly satisfied.
(-2) According to Definition 15, we have G  state(sl ), and thus formula (-2) is clearly
satisfied.
(-3) According to Definition 6, we have agenda(I) = , and thus formula (-3) is clearly
satisfied.
(-4) According to Definition 15, we have agenda(sl ) = , and thus formula (-4) is clearly
satisfied.
(-5) Let p be an arbitrary proposition, and e be an event such that e  Rp . If e 
/ Stepk ,
then M (ek ) = f alse and, therefore, formula (-5) is trivially satisfied. Consider the
case where e  Stepk . According to Definition 15, Stepk must be a -step from sk1
to sk . Thus, by Definition 14, for any possible ordering on the events of Stepk , we
must be able to execute these events according to the ordering, starting from state
sk1 . One possible ordering can be an specific ordering that puts e in the front of
all other events. Therefore, e must be applicable to sk1 . Then, by Definition 4, we
have p  state(sk1 ). This implies that M (pk1 ) = true, from which the satisfaction
of formula (-5) easily follows.
/ Stepk ,
(-6) Let p be an arbitrary proposition, and e be an event such that e  Ep+ . If e 
then M (ek ) = f alse and, therefore, formula (-6) is trivially satisfied. Consider the
case where e  Stepk . Similar to the previous case, starting from state sk1 , we
must be able to execute the events of Stepk by any possible ordering and reach sk .
610

fiITSAT: An Efficient SAT-Based Temporal Planner

One such possible ordering is one that puts e after all other events. Therefore, addeffects of e must be members of state(sj ), and by Definition 5, we have p  state(sk ).
This implies that M (pk ) = true, from which the satisfaction of formula (-6) easily
follows.
/ Stepk
(-7) Let p be an arbitrary proposition, and e be an event such that e  Ep . If e 
k
then M (e ) = f alse and, therefore, formula (-7) is trivially satisfied. Otherwise,
by the same argument given case (-6), we have p 
/ state(sk ), and the satisfaction
of formula (-7) easily follows.
(-8) Let p be an arbitrary proposition. Consider the nontrivial case where p is a member
of state(sk ) but not state(sk1 ). It can be easily derived from Definition 5, that if p
is added by the application of a sequence of events, then at least one of those events
must add p. This implies the satisfaction of formula (-8).
(-9) This case is analogous to case (-8)
(-10) Lemma 1 is used to prove that M satisfies chain(e1 , ..., en+1 ; Ep ; Rp  {en+1 }; k; mp1 ).
It is straightforward to see that M has all the properties of the model M in Lemma
1. We only need to show that for any proposition p, provided that ei  Stepk  Ep
and j > i, then ej 
/ Stepk  Rp . Suppose that ej  Stepk . By Definition 14, for any
possible ordering on the events of Stepk , we must be able to execute those events
according to the ordering, starting from the state sk1 . One such possible ordering
can be one that puts ei immediately before ej . Notice that ei deletes p, because
ei  Ep . Thus, ej cannot have p as its precondition, and ej 
/ Rp . We can infer
that ej 
/ Stepk  Rp . Therefore, by Lemma 1, M satisfies chain(e1 , ..., en+1 ; Ep ; Rp 
{en+1 }; k; mp1 ). Now, we show that M also satisfies bkn+1,mp  ak . Consider the
1

nontrivial case, where M (bkn+1,mp ) = true. Based on the way we construct M , at
1
least one of e1 , ..., en , say ej , must delete p. Again, since Stepk is a -step from sk1
to sk , we must be able to execute the events of Stepk by any possible ordering and
reach sk . Consider an specific ordering that puts ej after all other events. Now,
if a  agenda(sk ), according to Definition 5, ej cannot be the ending event of a.
Therefore, by Definition 4, a is also a member of the agenda of the state to which
ej is applied. This clearly contradicts the applicability of ej , because ej deletes p,
which is an invariant of a. Therefore, M (ak ) = f alse, which implies that M satisfies
bkn+1,mp  ak .
1

(-11) In this case, too, Lemma 1 is used to prove that M satisfies chain(en , ..., e0 ; Ep ; Rp 
{e0 }; k; mp1 ). Similar to the previous case, it is straightforward to confirm that M
has all the properties of Lemma 1. Since the ordering in chain(e1 , ..., en+1 ; Ep ; Rp 
{en+1 }; k; mp1 ) is reversed in chain(en , ..., e0 ; Ep ; Rp  {e0 }; k; mp1 ), we need to show
that for any proposition p, provided that ei  Stepk  Ep and j < i, then ej 
/
Stepk  Rp . Suppose that ej  Stepk . By Definition 14, for any possible ordering
on the events of Stepk , we must be able to execute these events according to the
ordering, starting from state sk1 . One such possible ordering can be one that
puts ei immediately before ej . By the same argument as the one given in case
611

fiRankooh & Ghassem-Sani

(-10), we infer that ej 
/ Stepk  Rp and, therefore, by Lemma 1, M satisfies
chain(en , ..., e0 ; Ep ; Rp  {e0 }; k; mp1 ). Now, we show that M also satisfies bk0,mp 
2

ak1 . Consider the nontrivial case, where M (bk0,mp ) = true. Based on the way we
2
construct M , at least one of e1 , ..., en , say ej , must delete p. Again, because Stepk is
a -step from sk1 to sk , starting from the state sk1 , we must be able to execute the
events of Stepk by any possible ordering. Consider the specific ordering that puts ej
before all other events. By Definition 4, since ej deletes p, which is an invariant of
a, a cannot be a member of agenda(sk1 ). Therefore, M (ak ) = f alse, which implies
that M satisfies bk0,mp  ak1 .
2

(-12) Assume that e is the starting event of action a. Because Stepk is a -step from sk1
to sk , starting from the state sk1 , we must be able to execute the events of Stepk
by any possible ordering. Consider the specific ordering that puts e before all other
events. Therefore, e must be applicable to sk1 . Then, by Definition 4, a cannot be
a member of agenda(sk1 ), and thus M (ak1 ) = f alse. To see that M (ak ) = true,
consider the specific ordering of events that puts e after all other events. If the events
are executed by this ordering, the results of applying e will appear in state sk , and
thus a must be a member of agenda(sk ). Hence, M satisfies ek  ak1  ak .
(-13) Analogous to case (-12), assume that e is the ending event of action a. Since Stepk
is a -step from sk1 to sk , starting from state sk1 , we must be able to execute the
events of Stepk by any possible ordering. Consider a specific ordering that puts e
before all other events. Therefore, e must be applicable to sk1 . Then, by Definition
4, a must be a member of agenda(sk1 ), and thus M (ak1 ) = true. To see that
M (ak ) = f alse, consider the specific ordering of events that puts e after all other
events. If the events are executed by this ordering, the results of applying e will
appear in state sk , and thus a cannot be a member of agenda(sk ). We conclude that
M satisfies ek  ak1  ak .

Theorem 4 (soundness of -step encoding). Let P = (I, G, A) be a temporal planning
problem, {e1 , ..., en } be the set of all events of P, and l be the -step encoding for P. If
l has a model M , then plan(M ) is a causally valid -step plan for P.
Proof. We can obtain plan(M ) as follows. For each k such that 1  k  l, let Stepk
be the set of all events e for which M (ek ) = true. For each k such that 0  k  l, let
sk be a temporal state. Assume that state(sk ) is the set of all propositions p for which
M (pk ) = true, and agenda(sk ) is the set of all actions a for which M (ak ) = true. We now
show that  = plan(M ) = hStep1 , ..., Stepl i is a causally valid -step plan for P with the
state transition sequence hs0 , ..., sl i.
From formula (-1), it immediately follows that I = state(s0 ). Formula (-2) implies
that G  state(sl ). Formulae (-3) and (-4) respectively imply that agenda(s0 ) and
agenda(sn ) are empty sets. Now, we only need to show that for each k such that 1  k  l,
Stepk = {e1 , ..., em }  {e1 , ..., en } is a -step from sk1 to sk . We first show that for any
612

fiITSAT: An Efficient SAT-Based Temporal Planner

proposition p, Stepk cannot include two different events ei and ej such that ei  Rp , and
ej  Ep . If j < i, since M satisfies formula (-10), by Lemma 2, we can infer M (eki ) and
M (ekj ) cannot be both equal to true. On the other hand, if i < j, since M satisfies formula
(-11), again by Lemma 2, we can infer M (eki ) and M (ekj ) cannot be both equal to true.
Thus, ei and ej cannot be both members of Stepk . Let O : {1, ..., m}  {1, ..., m} be an
arbitrary ordering function. We now show by induction on k  , where k   m, the sequence
heO(1) , ..., eO(k ) i is applicable to sk1 . For k  = 0 (i.e., the case where no event is to be
applied to sk1 ), the conclusion trivially holds. As the induction hypothesis, let sk be the
temporal state resulting from applying the sequence heO(1) , ..., eO(k ) i to sk1 . Let eO(k +1)
be the starting event of action a (we omit the very similar case where eO(k +1) is the ending
event of a). We show that conditions (1) to (3) of Definition 4 hold and thereby eO(k +1) is
applicable to sk . As a result, heO(1) , ..., eO(k +1) i will be applicable to sk1 .
(1) From formula (-5), it easily follows that all preconditions of eO(k +1) and all invariants of a (except for those invariants of a that are added by eO(k +1) ) are members
if state(sk1 ). As mentioned above, neither of these propositions can be deleted by
another member of Stepk . Thus, these propositions are also members of state(sk ).
(2) From formula (-7), it easily follows that a is not a member agenda(sk1 ). Notice that
according to Definition 5, the starting event of a, i.e., eO(k +1) , is the only event that
can add a to the agenda of any state. Therefore, a cannot be a member of agenda(sk ),
either.
(3) Let a be any action with an invariant p such that p  del(eO(k +1) ). Clearly we have
start(a )  Rp , and thus, as it was argued above, start(a ) and eO(k+1) cannot be both
members of Stepk . Hence, start(a ) 
/ Stepk . On the other hand, since p is deleted in
step k, and M satisfies chain(en , ..., e0 ; Ep ; Rp {e0 }; k; mp2 ), then according to Lemma 2,
we have: M (b0,mp2 ) = true. Therefore, by formula (-11), we can infer that M (ak1 ) =
f alse, and thus, a 
/ agenda(sk1 ). start(a ) 
/ Stepk and a 
/ agenda(sk1 ) jointly


imply that a 
/ agenda(sk ).
We now show that sm , which is the result of applying heO(1) , ..., eO(m) i to sk1 , is equal to
sk .
 Let p be an arbitrary member of state(sm ). From formulae (-6) and (-7) it follows
that if p is deleted by any member of Stepk , it cannot be added by any other member
 ). Therefore, p is not deleted by
of Stepk and thus, p cannot be a member
m
Wof state(s
k
any member of Stepk , and the formula eEp e is not satisfied by M . Besides, if p
is not added by any member of Stepk , it must be a member of state(sk1 ), and thus
M (pk1 ) = true. Now, by formula (-9), we can infer that M (pk ) = true, and hence
p  state(sk ). On the other hand, if p is added by a member of Stepk , from formula
(-6), we can deduce that M (pk ) = true, and again we have p  state(sk ). Therefore,
state(sm )  state(sk ).
 Let p be an arbitrary member of state(sk ). According to formula (-7), p cannot be
deleted by any member of Stepk . Besides, by formula (-8), p is either a member of
613

fiRankooh & Ghassem-Sani

state(sk1 ) or is added by a member of Stepk . In both cases, Definition 5 implies that
p  state(sm ). Therefore, state(sk )  state(sm ).
 Let a be an arbitrary member of agenda(sm ). From formulae (-12) and (-13), it
follows that the starting and ending events of no single action can be both members of
Stepk . If a  agenda(sk1 ), then because a is still open in state sm , we can infer that
end(a) 
/ Stepk . Therefore, according to formula (-13), M (ak ) = true, and a must
be a member of agenda(sk ). On the other hand, if a 
/ agenda(sk1 ), then start(a)
must be a member of Stepk . Then, by formula (-12), we have: M (ak ) = true, and
again, a must be a member of agenda(sk ). Therefore, agenda(sm )  agenda(sk ).
 Let a be an arbitrary member of agenda(sk ). According to formula (-13), start(a)
cannot be a member of Stepk . Besides, by formula (-12), a is either a member of
agenda(sk1 ) or start(a) is a member of Stepk . In both cases, Definition 5 implies
that a  agenda(sm ). Therefore, agenda(sk )  agenda(sm ).
Above argument shows that state(sk ) = state(sm ) and agenda(sk ) = agenda(sm ). Hence,
sk = sm = succ(sk1 , heO(1) , ..., eO(m) i). Therefore, Stepk is a -step from sk1 to sk .
Theorem 5 (completeness of -step encoding). Let P = (I, G, A) be a solvable temporal planning problem, {e1 , ..., en } be the set of all events of P, and  = hStep1 , ..., Stepl i
be a causally valid -step plan for P. There exists a model M for l such that  = plan(M ).
Proof. By Theorem 3, there exists a model M for l such that  = plan(M ). We show that
M can be translated into a model for l . Since formulae (1) to (10) are shared between
l and l , then M also satisfies all these formulae. We now show that M also satisfies
all formulae (-11) to (-20), and therefore can be translated into a model for l . In the
following cases, a is an arbitrary temporal action, ei is the starting event of a, and ej is the
ending event of a.
(-11) If M (eki ) = f alse, then formula (-11) is trivially satisfied. If M (eki ) = true, then by
formula (-12) we have: M (ak1 ) = f alse, and therefore formula (-11) is satisfied.
(-12) If M (eki ) = f alse, then formula (-12) is trivially satisfied. If M (eki ) = true, then
by formula (-12) we have: M (ak ) = true, and therefore formula (-12) is satisfied.
(-13) If M (ekj ) = f alse, then formula (-13) is trivially satisfied. If M (ekj ) = true, then by
formula (-13) we have: M (ak ) = f alse, and therefore formula (-13) is satisfied.
(-14) If M (ekj ) = f alse, then formula (-14) is trivially satisfied. If M (ekj ) = true, then by
formula (-13) we have: M (ak1 ) = true, and therefore formula (-14) is satisfied.
(-15) Exactly the same as case (-11).
(-16) Exactly the same as case (-12).
(-17) Exactly the same as case (-13).
(-18) Exactly the same as case (-14).
614

fiITSAT: An Efficient SAT-Based Temporal Planner

(-19) Follows immediately from the fact that M satisfies formula (-12).
(-20) Follows immediately from the fact that M satisfies formula (-13).

Theorem 6 (soundness of -step encoding). Let P = (I, G, A) be a temporal planning
problem, {e1 , ..., en } be the set of all events of P, and l be the -step encoding for P. If
l has a model M , then plan(M ) is a causally valid -step plan P.
Proof. We can obtain plan(M ) as follows. For each k such that 1  k  l, let Stepk be
the set of all events e for which we have M (ek ) = true. Moreover, for each k such that
0  k  l, let sk be a temporal state. Assume that state(sk ) is the set of all propositions p
such that M (pk ) = true and agenda(sk ) is the set of all actions a such that M (ak ) = true.
We construct  = plan(M ) = hStep1 , ..., Stepl i and show that  is a causally valid -step
plan for P with state transition sequence hs0 , ..., sl i.
From formula (-1), it immediately follows that I = state(s0 ). Formula (-2) implies
that G  state(sl ). Formulae (-3) and (-4) imply that agenda(s0 ) and agenda(sn )
are both empty sets. Now, we only need to show that for each k such that 1  k  l,
Stepk = {e1 , ..., em }  {e1 , ..., en } is a -step from sk1 to sk . Without loss of generality,
assume that the sequence he1 , ..., em i is ordered by the fixed ordering he1 , ..., en i. Note that
since M satisfies formula (-10), by Lemma 2, for any proposition p, Stepk cannot include
any two events ei and ej such that ei  Rp , ej  Ep , and j < i. By induction on k  , we show
that for every k   m, the sequence he1 , ..., ek i is applicable to sk1 . For k  = 0 (i.e., the
case where no event is applied to sk1 ), the conclusion obviously holds. As the induction
hypothesis, let sk be the temporal state resulting from applying the sequence he1 , ..., ek i
to sk1 . Assume that ek +1 is the starting event of action a (we omit the very similar case
where ek +1 is the ending event of a). We show that conditions (1) to (3) of Definition 4
hold and thereby ek +1 is too applicable to sk .
(1) From formula (-5), it clearly results that all preconditions of ek +1 and all invariants of a
(except for those invariants of a that are added by eO(k +1) ) are members of state(sk1 ).
As we stated before, neither of these propositions can be deleted by ei for i < k  . Thus,
these propositions are also members of state(sk ).
(2) There are two possible cases. Consider the first case, where according to the fixed
ordering he1 , ..., en i, the ending event of a is located after ek +1 . Formula (-11) implies
that a cannot be a member agenda(sk1 ). Notice that according to Definition 5, the
starting event of a, i.e., ek +1 , is the only event that can add a to the agenda of any
state. Therefore, a cannot be a member of agenda(sk ). In the other case, where the
ending event of a is located before ek +1 , formula (-15) implies that either a is not
a member of agenda(sk1 ), or end(a) is a member of Stepk . However, if end(a) is a
member of Stepk , it will certainly remove a from the agenda of its resulting state. Since
ek +1 is the only event that can add a to the agenda of any state, we can conclude that
a cannot be a member of agenda(sk ). Therefore, in neither of these two cases, a is a
member of agenda(sk ).
615

fiRankooh & Ghassem-Sani

(3) Let a be an action that has p  del(ek +1 ) as an invariant. Since p is deleted in step k,
and M satisfies chain(e1 , ..., en ; Ep ; Rp {en+1 }; k; mp1 ), then according to Lemma 2, we
have M (bn+1,np1 ) = true. Therefore, by formula (-10), we have a 
/ agenda(sk ). On
the other hand, we clearly have end(a )  Rp , and thus, as we argued before, if end(a )
is a member of Stepk , it cannot be located after ek +1 in the fixed ordering he1 , ..., en i.
Hence, if a is not a member of agenda(sk ), it cannot be a member of agenda(sk ),
either. Therefore, we can infer that a 
/ agenda(sk ).
We now show that sm , which is the result of applying he1 , ..., em i to sk1 , is equal to sk .
 By the same argument given in the proof of Theorem 4, we have state(sm )  state(sk )
and state(sk )  state(sm ), hence, state(sm ) = state(sk ).
 Let a be an arbitrary member of agenda(sm ). Let ei and ej be the starting and ending
events of a, respectively. There are three possible cases. Consider the first case where
a  agenda(sk1 ), ei 
/ Stepk , and ej 
/ Stepk (i.e., a is open immediately before step
k and is neither started nor ended in step k). In this case, since M satisfies (-20), we
have M (ak ) = true, and therefore, a  agenda(sk ). Consider the second case where
a  agenda(sk1 ), ei  Stepk , ej  Stepk , and j < i (i.e., a is open immediately
before step k, and is first ended and then started again in step k). In this case, since
M satisfies formula (-16), we have M (ak ) = true, and therefore, a  agenda(sk ).
Finally, consider the third case where a 
/ agenda(sk1 ), ei  Stepk , and ej 
/ Stepk
(i.e., a is not open immediately before step k, and it is started but not ended in
step k). In this case, if j < i, then M must satisfy formula (-16) and we have
M (ak ) = true. On the other hand, if i < j, then M must satisfy formula (-12) and,
since M (ekj ) = f alse, we must have M (ak ) = true, and therefore, a  agenda(sk ).
Consequently, in all these three cases, a must be a member of agenda(sk ); hence
agenda(sm )  agenda(sk ).
 Let a be an arbitrary member of agenda(sk ), i.e., M (ak ) = true. There are two
possible cases. Case 1) a is not a member of agenda(sk1 ), and hence M (ak1 ) =
f alse. By formula (-19), we have: M (eki ) = true. This means that a is started in
step k. Now, if j < i, the ending event of a cannot happen after its starting event,
and therefore, a must remain open after the execution of step k, i.e., a  agenda(sm ).
On the other hand, if i < j, by formula (-14) we have: M (ekj ) = f alse. This
means that a is started but not ended in step k, and therefore a must remain open
after the execution of step k, i.e., a  agenda(sm ). Now consider case 2) a is a
member of agenda(sk1 ), and hence M (ak1 ) = true. If i < j, by formula (-11)
we have M (eki ) = f alse, and by formula (-13) we have M (ekj ) = f alse. This means
that a is open immediately before the execution of step k, and is neither started nor
ended in step k. Therefore, a must also be open after the execution of step k, i.e.,
a  agenda(sm ). On the other hand, if j < i, since both M (ak ) and M (ak1 ) are
false, formulae (-15) and (-17) can be combined to form the formula (eki  ekj ).
This means that a is ended in step k if and only if it is later started again in the same
step. Therefore, again a must be open after the execution of step k, and we have
a  agenda(sm ). Therefore, agenda(sk )  agenda(sm ).
616

fiITSAT: An Efficient SAT-Based Temporal Planner

Above arguments show that state(sk ) = state(sm ) and agenda(sk ) = agenda(sm ). Hence,
sk = sm = succ(sk1 , he1 , ..., em i). Therefore, for the ordering functions O : {1, ..., m} 
{1, ..., m}, such that O(i) = i, we have sk = succ(sk1 , heO(1) , ..., eO(m) i), and thus Stepk is
a -step from sk1 to sk .
Lemma 3. Let M be a model for chain (e1 , ..., en ; Ep+ ; Ep ; Rp ; k; mp ), ej be a member of
Rp , and EpM = {e|e  Ep+  Ep , M (ek ) = true}. M have the following properties:
 If there exists no event ei such that ei  EpM and i < j, then M (bkj,mp ) = M (pk1 ).
 If there exists an event ei such that ei  Ep+ , i < j, {ei+1 , ..., ej1 }  EpM = , and
M (eki ) = true, then M (bkj,mp ) = true.
 If there exists an event ei such that ei  Ep , i < j, {ei+1 , ..., ej1 }  EpM = , and
M (eki ) = true, then M (bkj,mp ) = f alse.
Proof.
 Assume that there exists no event ei such that ei  EpM and i < j. Consider the
case where we have M (pk1 ) = true. Let {ei0 , ..., eim } be the set of all events ei
such that ei  Rp  Ep+  Ep , and 0  i  j. Without loss of generality, we can
assume that 0 = i0 < i1 < ... < im = j. Since M must satisfy (C -7), we know that
M (bki ,m ) = true. Assume that for an arbitrary s, M (bkis ,mp ) = true. If eis  Ep+ Ep ,
0

p

then we know that M (ekis ) = f alse, and by (C -4) we have M (bki


s+1 ,mp

other hand, if eis 

Rp Ep+ Ep ,

by

(C -3),

we have

M (bki ,m )
p
s+1

) = true. On the

= true. We can infer

that for each 1  s  j, we have M (bkis ,mp ) = true, and thereby M (bkj,mp ) = M (pk1 ).
The proof for the case where we have M (pk1 ) = f alse is analogous, except that
instead of (C -4), we need to use (C -5) .
 Assume that there exists an event ei such that ei  Ep+ , i < j, {ei+1 , ..., ej1 } 
EpM = , and M (eki ) = true. Let {ei0 , ..., eim } be the set of all events ei such that
ei  Rp  Ep+  Ep , and i  i  j. Without loss of generality, we can assume that i =
i0 < i1 < ... < im = j. Since M must satisfy (C -1), we know that M (bki ,m ) = true.
1

p

Assume that for an arbitrary s  1, M (bkis ,mp ) = true. If eis  Ep+  Ep , then we
know that M (ekis ) = f alse, and by (C -4), we have M (bki
hand, if eis  Rp 

Ep+



 ) = true. On the other
s+1 ,mp
k
by
we have M (bi ,m ) = true. We can infer
p
s+1
k
have M (bis ,mp ) = true, and thereby M (bkj,mp ) = true.

Ep ,

that for each 1  s  j, we

(C -3),

 Assume that there exists an event ei such that ei  Ep , i < j, {ei+1 , ..., ej1 } 
EpM = , and M (eki ) = true. Let {ei0 , ..., eim } be the set of all events ei such that
ei  Rp  Ep+  Ep , and i  i  j. Without loss of generality, we can assume that i =
617

fiRankooh & Ghassem-Sani

i0 < i1 < ... < im = j. Since M must satisfy (C -1), we know that M (bki ,m ) = f alse.
1

p

Assume that for an arbitrary s  1, M (bkis ,mp ) = f alse. If eis  Ep+  Ep , then we
know that M (ekis ) = f alse, and by (C -5), we have M (bki
hand, if eis  Rp 

Ep+



 ) = f alse. On the other
s+1 ,mp
k
by
we have M (bi ,m ) = f alse. We can infer
p
s+1
k
have M (bis ,mp ) = f alse, and thereby M (bkj,mp ) = f alse.

Ep ,

that for each 1  s  j, we

(C -3),


Lemma 4. Let M be a model for chain(e1 , ..., en+1 ; Ep ; Rp ; k; mof
p ). Assume that ei  Ep ,
M (eki ) = true, and p  inv(a). Let ej and ej+1 be the starting event and ending event of
a, respectively. M has the following properties:

 If M (ekj+1 ) = true, and i < j, then M (ekj ) = true.
 If M (ak ) = true, then M (ekj ) = true.
Proof. Let {ei1 , ..., eim } be equal to the set {es |es  Op , i < s  n + 1}. Without loss
of generality, we can assume that i1 < i2 < ... < im = n + 1. Since M (eki ) = true, by
(Cof -1), we can infer that M (bi1 ,mof ) = true. For each s, such that M (bis ,mof ) = true, by
p

p

(Cof -2), we can deduce that M (bis+1 ,mof ) = true. Therefore, we have M (bn+1,mof ) = true.
p
p
Furthermore, if i < j, we have ej+1  {ei1 , ..., eim }, and thus M (bj+1,mof ) = true. Besides,
p

if M (ekj+1 ) = true, then by (Cof -3), we have M (ekj ) = true. On the other hand, if M (ak ) =
true, we can infer from formula (Cof -4) that M (ekj ) = true.

Lemma 5. Let M be a model for chain(e0 , ..., en ; Ep ; Rp ; k; mob
p ). Assume that ei  Ep ,
M (eki ) = true, and p  inv(a). Let ej and ej+1 be the starting event and ending event of
a, respectively. M has the following properties:

 If M (ekj ) = true, and j + 1 < i, then M (ekj+1 ) = true.
 If M (ak1 ) = true, then M (ekj+1 ) = true.
Proof. The proof is very analogous to that of Lemma 4, and thus is omitted.
Theorem 7 (completeness of the relaxed -step encoding). Let P = (I, G, A)

be a temporal planning problem and formulae l and l be two -step encodings of

P explained in Section 4. If M is a model for l , then l has a model M  such that
plan(M  ) = plan(M ).
Proof. Let M be a model for l . We construct the function M  to assign a value of true

or f alse to each binary variable of l , by using the following rules:
(R-1) For 1  i  n and 1  k  l, M  (eki ) = M (eki ).
618

fiITSAT: An Efficient SAT-Based Temporal Planner

(R-2) For 1  k  l, M  (ek0 ) = M  (ekn+1 ) = f alse.
(R-3) For 0  k  l and each proposition p, M  (pk ) = M (pk ).
(R-4) For 0  k  l and each action a, M  (ak ) = M (ak ).
(R-5) For 0  i  n + 1, 1  k  l, and each proposition p, if there exist j < i such that
M (ekj ) = true and ej  Ep+  Ep then M  (bki,mp ) = M (pk ); otherwise, M  (bki,mp ) =
M (pk1 ).
(R-6) For 1  i  n + 1, 1  k  l, and each proposition p, if there exist j < i such that
M (ekj ) = true and ej  Ep then M  (bk of ) = true; otherwise, M  (bk of ) = f alse.
i,mp

i,mp

(R-7) For 0  i  n, 1  k  l, and each proposition p, if there exist j > i such that
M (ekj ) = true and ej  Ep then M  (bki,mob ) = true; otherwise, M  (bki,mob ) = f alse.
p

p

We now show that M  satisfies all formulae ( -1) to ( -13), and therefore is a model for

l . From above rules, it should be clear that we have plan(M  ) = plan(M ).
( -1) Formula ( -1) is exactly the same as (-1). Besides, M and M  assign the same
value to each variable of this formula.
( -2) Formula ( -2) is exactly the same as (-2). Besides, M and M  assign the same
value to each variable of this formula.
( -3) Formula ( -3) is exactly the same as (-3). Besides, M and M  assign the same
value to each variable of this formula.
( -4) Formula ( -4) is exactly the same as (-4). Besides, M and M  assign the same
value to each variable of this formula.
( -5) Formula ( -4) is the conjunction of formulae (C -1) to (C -8). We show that M 
satisfies all formulae (C -1) to (C -8), and thereby, it satisfies ( -5).
 Consider an arbitrary formula eki  bkj,mp from (C -1). If M (eki ) = f alse, then
the formula is trivially satisfied. If M (eki ) = true, then by (R-5), we have
M  (bki,mp ) = M (pk ). On the other hand, because M satisfies (-6), we have
M (pk ) = true. Therefore, M  (bki,mp ) = true, and the formula is satisfied again.
 Consider an arbitrary formula eki  bkj,mp from (C -2). If M (eki ) = f alse,
then the formula is trivially satisfied. If M (eki ) = true, then by (R-5), we have
M  (bki,mp ) = M (pk ). On the other hand, because M satisfies (-7), we have
M (pk ) = f alse. Therefore, M  (bki,mp ) = f alse, and the formula is satisfied
again.
 Consider an arbitrary formula bki,mp  bkj,mp from (C -3). Since ei is not a
member of Ep+  Ep , and none of the events located between ei and ej in the
fixed ordering are members of Ep+  Ep , then by (R-5), we can easily show
that M  (bki,mp ) = M  (bkj,mp ). Thus, the formula is satisfied.
619

fiRankooh & Ghassem-Sani

 Consider an arbitrary formula bki,mp  eki  bkj,mp from (C -4). If M (eki ) =
true, then the formula is trivially satisfied. If M (eki ) = f alse, then since none
of the events located between ei and ej in the fixed ordering are members of
Ep+ Ep , then by (R-5), we can easily show that M  (bki,mp ) = M  (bkj,mp ). Thus,
the formula is satisfied.
 Consider an arbitrary formula bki,mp eki  bkj,mp from (C -5). By the same
argument as the one given for (C -4), we can infer that M  (bki,mp ) = M  (bkj,mp ).
Thus, the formula is satisfied.
 Consider an arbitrary formula bki,mp  eki from (C -6). If M  (bki,mp ) = true,
then the formula is trivially satisfied. If M  (bki,mp ) = f alse, then there exist two
possible cases. Case 1: there exists an event ej such that j < i, M (ekj ) = true,
and ej  Ep+ Ep . In this case, by (R-5), we have M (pk ) = M  (bki,mp ) = f alse.
Since M must also satisfy (-6), we have ej 
/ Ep+ , and thus ej  Ep . Besides,
M must satisfy (-10), which implies M (eki ) = f alse. By (R-1), we have
M  (eki ) = M (eki ) = f alse, and therefore, the formula is satisfied. Case 2: there
does not exist any event ej such that j < i, M (ekj ) = true, and ej  Ep+  Ep .
In this case, by (R-5), we have M (pk1 ) = M  (bki,mp ) = f alse. Now, since
M must satisfy (-5), we can infer that M (eki ) = f alse. By (R-1), we have
M  (eki ) = M (eki ) = f alse, and therefore, the formula is satisfied again.
 Consider the formula bk0,mp  pk1 from (C -6). From (R-5), it can be easily deducted that M  (bk0,mp ) is always equal to M (pk1 ). By (R-3), we have
M  (pk1 ) = M (pk1 ). As a result, M  (bk0,mp ) = M  (pk1 ), and the formula is
satisfied.
 Consider the formula bkn+1,mp  pk from (C -6). There are two possible cases.
Case 1: there exists an event e such that M (ek ) = true, and e  Ep+  Ep .
In this case, by (R-5), we have M  (bn+1,mp ) = M (pk ). Now, by (R-5), we
have M (pk ) = M  (pk ). Therefore, M  (bn+1,mp ) = M  (pk ), and the formula is
satisfied. Case 2: there does not exist any event e such that M (ek ) = true and
e  Ep+ Ep . In this case, by (R-5), we have M  (bn+1,mp ) = M (pk1 ). Besides,
since M satisfies formulae (-8) and the right hand side of (-8) becomes f alse,
the left hand side of (-8), i.e., pk1  pk , has to be f alse, too. Thus, if
M (pk1 ) = f alse, then we have M (pk ) = f alse. A similar argument about
(-9) can show that if M (pk1 ) = true, then we have M (pk ) = true. Thus,
M (pk1 ) = M (pk ), and by (R-3), we have M  (pk ) = M (pk1 ). Therefore,
M  (bn+1,mp ) = M (pk1 ) = M  (pk ), and the formula is satisfied again.
( -6) We show that M  satisfies all formulae (Cof -1) to (Cof -4), and thereby, it satisfies
( -6).
 Consider an arbitrary formula eki  bk

j,mof
p

from (Cof -1). We know from (Cof -

1) that i < j. If M  (eki ) = f alse, the formula is trivially satisfied. If M  (eki ) =
true, by (R-6), we have M  (bj,mof ) = true, and the formula is satisfied.
p

620

fiITSAT: An Efficient SAT-Based Temporal Planner

 Consider an arbitrary formula bk

i,mof
p

from (Cof -2). If M  (bk

 bk

j,mof
p

i,mof
p

= f alse, the formula is trivially satisfied. If M  (bk

i,mof
p

)

) = true, by the rule

i

(R-6), there must exist an event ei , such that
< i, M (eki ) = true, and
ei  Ep . Since we have i < j, we must also have i < j. Now, by (R-6), we
have M  (bj,mof ) = true, and the formula is satisfied.
p

 Consider an arbitrary formula bk

j,mof
p

 ekj  eki from (Cof -3). If M  (bk

j,mof
p

f alse, the formula is trivially satisfied. If M  (bk

j,mof
p

)=

) = true, by (R-6), there

must exist an event ej  such that j  < j, M (ekj ) = true, and ej   Ep . Now,
since M satisfies (-10), we can infer that M (ekj ) = f alse. By (R-1), we have
M  (ekj ) = M (ekj ) = f alse, and therefore, the formula is satisfied.
 Consider an arbitrary formula bk

n+1,mof
p

ak  eki from (Cof -4). If M  (bk

n+1,mof
p

= f alse, the formula is trivially satisfied. If M  (bk

)

) = true, by (R-6),

n+1,mof
p
k
an event ej such that M (ej ) = true and ej  Ep . Now,
(-10), we can infer that M (ak ) = f alse. By (R-4), we have

there must exist
since M satisfies
M  (ak ) = M (ak ) = f alse, and therefore, the formula is satisfied.

( -7) We show that M  satisfies all formulae (Cob -1) to (Cof -4), and thereby, it satisfies
( -7).
 Consider an arbitrary formula eki  bkj,mob from (Cob -1). We know from (Cob -1)
p

that j < i. If M  (eki ) = f alse, the formula is trivially satisfied. If M  (eki ) =
true, by (R-7), we have M  (bj,mob
) = true, and the formula is satisfied.
p
 Consider an arbitrary formula bki,mob  bkj,mob from (Cob -2). If M  (bki,mob ) =
p

p

p

f alse, the formula is trivially satisfied. If M  (bki,mob ) = true, by the rule (R-7),
p

there must exist an event ei such that i < i , M (eki ) = true, and ei  Ep .
Since we have j < i, we must also have j < i . Now, by (R-7), we have
) = true, and the formula is satisfied.
M  (bj,mob
p
 Consider an arbitrary formula bki,mob  eki  ekj from (Cob -3). If M  (bki,mob ) =
p

p

f alse or M  (eki ) = f alse, the formula is trivially satisfied. If M  (bki,mob ) = true
p

and M  (eki ) = true, by (R-7), there must exist an event ei , such that i < i ,
M (eki ) = true, and ei  Ep . Since M satisfies (-10), we can infer that
M (ak ) = f alse. However, we know that i = j  1 < j; thus M must satisfy (12). Therefore, we have M (ekj ) = true. By (R-1), we have M  (ekj ) = M (ekj ) =
true, and therefore, the formula is satisfied.
 Consider an arbitrary formula bk0,mob  ak1  ekj from (Cob -4). If M  (bk0,mob ) =
p

p

f alse or M  (ak1 ) = f alse, the formula is trivially satisfied. If M  (bk0,mob ) =
p

true and M  (ak1 ) = true, by (R-7), there must exist an event ei such that
M (eki ) = true, and ei  Ep . Since M satisfies (-10), we can infer that
M (ak ) = f alse. However, M must satisfy (-20). Therefore, we have M (ekj ) =
621

fiRankooh & Ghassem-Sani

true. By (R-1), we have M  (ekj ) = M (ekj ) = true, and therefore, the formula
is satisfied.
( -8) Consider an arbitrary formula eki  ak1 from ( -8). Let ej be the ending event
of a. We know that i = j  1 < j. Therefore, M must satisfy (-11). ( -8)
is exactly the same as (-11). Besides, M and M  assign the same value to each
variable of these formulae. Thus, ( -8) is satisfied by M  .
( -9) Consider an arbitrary formula eki  ak ekj from ( -9). We know that i = j 1 < j.
Therefore, M must satisfy formula (-12). ( -9) is exactly the same as (-12).
Besides, M and M  assign the same value to each variable of these formulae. Thus,
( -9) is satisfied by M  .
( -10) Consider an arbitrary formula ekj  ak from ( -10). Let ei be the starting event
of a. We know that i = j  1 < j. Therefore, M must satisfy (-13). ( -10)
is exactly the same as (-13). Besides, M and M  assign the same value to each
variable of these formulae. Thus,( -10) is satisfied by M  .
( -11) Consider an arbitrary formula ekj  ak1  eki from ( -11). We know that i =
j  1 < j. Therefore, M must satisfy (-14). ( -11) is exactly the same as (-14).
Besides, M and M  assign the same value to each variable of these formulae. Thus,
( -11) is satisfied by M  .
( -12) ( -12) is exactly the same as (-19). Besides, M and M  assign the same value to
each variable of these formulae. Thus, ( -12) is satisfied by M  .
( -13) ( -13) is exactly the same as (-20). Besides, M and M  assign the same value to
each variable of these formulae. Thus, ( -13) is satisfied by M  .

Theorem 8 (soundness of the relaxed -step encoding). Let P = (I, G, A) be a

temporal planning problem, {e1 , ..., en } be the set of all events of P, and l be the relaxed

-step encoding for P. If l has a model M , then plan(M ) is a causally valid -step plan
P.
Proof. We can obtain plan(M ) as follows. For each k such that 1  k  l, let Stepk be
the set of all events e for which we have M (ek ) = true. For each k such that 0  k  l,
let sk be a temporal state. Assume that state(sk ) is the set of all propositions p such that
M (pk ) = true, and agenda(sk ) is the set of all actions a such that M (ak ) = true. We
construct  = plan(M ) = hStep1 , ..., Stepl i and show that  is a causally valid -step plan
for P with state transition sequence hs0 , ..., sl i.
From ( -1), it immediately follows that I = state(s0 ). Also, ( -2) implies that G 
state(sl ). Besides, ( -3) and ( -4) imply that agenda(s0 ) and agenda(sn ) are empty sets,
respectively. Now we only need to show that for each k such that 1  k  l, Stepk =
{ei1 , ..., eim }  {e1 , ..., en } is a -step from sk1 to sk . Without loss of generality, we
622

fiITSAT: An Efficient SAT-Based Temporal Planner

assume that the sequence hei1 , ..., eim i is ordered according to the fixed ordering he1 , ..., en i,
i.e., i1 < i2 < ... < im .
By induction on k  , we can conclude that for each k   m, the sequence hei1 , ..., eik i is
applicable to sk1 . For k  = 0 (i.e., the case, where no event is applied to sk1 ), the conclusion obviously holds. Let sk be the temporal state resulting from applying hei1 , ..., eik i
to sk1 . Assume that eik +1 is the starting event of action a. We omit the very similar case
where eik +1 is an ending event of a. We show that conditions (1) to (3) of Definition 4
holds and thereby eik +1 is applicable to sk .
(1) Assume that p 
/ state(sk ), where p is either a precondition of eik +1 or an invariant
of a that is not added by eik +1 . There are two possible cases. Case 1: p is not a
member of state(sk1 ), and is not added or deleted by any member of {ei1 , ..., eik }.
In this case, we have M (pk1 ) = f alse. Moreover, there exists no event ei such that
ei  Ep+  Ep , i < k  + 1, and M (eki ) = true. Case 2: p is deleted by an event
ei  Stepk and is not added or deleted by any event ej  Stepk , such that i < j  k  .
In this case, we have ei  Ep , i < ik +1 , {ei+1 , ..., eik +1 }  EpM = , and M (eki ) = true,
where EpM = {e|e  Ep+  Ep , M (ek ) = true}. In both cases, by Lemma 3, we have
M (bkik +1 ,mp ) = f alse, which contradicts the fact that M satisfies (C -6).
(2) Since M satisfies ( -8), a is not a member of agenda(sk1 ). However, eik +1 is the only
event in Stepk that can add a to the agenda of any state. Thus, a is not a member of
agenda(sk ).
(3) Let b be any action other than a, with an invariant p  del(eik +1 ). Let ej and ej+1
be the starting and ending events of b, respectively. As mentioned earlier, we assume
that the ending event of each action is located immediately after its starting event in
the fixed ordering. We show that b cannot be a member of agenda(sk ). There are
two possible cases in which b may be a member of agenda(sk ). Case 1: b is an open
action immediately before the execution of Stepk ; and b it is not ended in Stepk until
eik +1 is executed. In this case, we have M (bk1 ) = true, and M (ekik +1 ) = true. Since
M satisfies ( -7), by Lemma 5, we have M (ekj+1 ) = true. As we just assumed that b
is not ended until the execution of eik +1 , we have ik +1 < j + 1. On the other hand,
since ej is the starting event of b, we have ik +1 6= j, and thus, ik +1 < j. Therefore,
by Lemma 4, we have M (ekj ) = true. This contradicts the fact that M satisfies ( -8),
because here we have M (bk1 ) = true, M (ekj ) = true, and ej = start(b). Case 2: b is
started in step k, and it is not ended during step k until the execution of eik +1 . In this
case, we have M (ekj ) = true, M (ekj+1 ) = f alse, j + 1 < ik +1 , and M (ekik +1 ) = true.
Since M satisfies ( -7), by Lemma 5, we must have M (ekj+1 ) = true, which again is a
contradiction.
We now show that sm , which is the result of applying hei1 , ..., eim i to sk1 , is equal to sk .
 Let p be an arbitrary proposition. If p  state(sm ), there are two possible cases.
Case 1: p is a member of state(sk1 ), and is not added or deleted by any member of
{ei1 , ..., eim }. In this case, we have M (pk1 ) = true. Moreover, there exists no event ei
such that ei  Ep+  Ep , i < n + 1, and M (eki ) = true. Case 2: p is added by an event
623

fiRankooh & Ghassem-Sani

ei  Stepk and is not added or deleted by any event ej  Stepk , such that i < n + 1.
In this case, we have ei  Ep+ , i < n + 1, {ei+1 , ..., en }  EpM = , and M (eki ) = true,
where EpM = {e|e  Ep+  Ep , M (ek ) = true}. In both cases, by Lemma 3, we
have M (bkn+1,mp ) = true. Since M satisfies (C -8), we have M (pk ) = true, and thus
p  state(sk ). Therefore, state(sm )  state(sk ).
 Let p be an arbitrary proposition. If p 
/ state(sm ), there are two possible cases. Case
1: p is not a member of state(sk1 ), and is not added or deleted by any member of
{ei1 , ..., eim }. In this case, we have M (pk1 ) = f alse. Moreover, there exists no event
ei such that ei  Ep+  Ep , i < n + 1, and M (eki ) = true. Case 2: p is deleted by
an event ei  Stepk and is not added or deleted by any event ej  Stepk , such that
i < j < n + 1. In this case, we have ei  Ep , i < n + 1, {ei+1 , ..., en }  EpM = , and
M (eki ) = true, where EpM = {e|e  Ep+ Ep , M (ek ) = true}. In both cases, by Lemma
3, we have M (bkn+1,mp ) = f alse. Since M satisfies (C -8), we have M (pk ) = f alse,
and thus p 
/ state(sk ). Therefore, state(sk )  state(sm ).
 Let a be an arbitrary action, and ei and ej be its starting event and ending event,
respectively. If a  agenda(sm ), since we assume that the ending event of each action
is located immediately after its starting event in the fixed ordering, there are only two
possible cases. Case 1: a is open immediately before step k, and is not ended during
step k. In this case, we have M (ak1 ) = true and M (ekj ) = f alse. Since M satisfies
( -13), we must have M (ak ) = true. Therefore, a  agenda(sk ). Case 2: a is started
but not ended in step k. In this case, we have M (eki ) = true and M (ekj ) = f alse. As
M satisfies ( -9), we must have M (ak ) = true. Therefore, a  agenda(sk ). Since in
both cases, we have a  agenda(sk ), we can infer that agenda(sm )  agenda(sk ).
 Let a be an arbitrary action, and ei and ej be its starting event and ending event of a,
respectively. If a 
/ agenda(sm ), since we assume that ending event of each action is
located immediately after its starting event in the fixed ordering, there are only two
possible cases. Case 1: a is not open immediately before execution of step k, and is
not started during step k. In this case, we have M (ak1 ) = f alse and M (eki ) = f alse.
Since M satisfies ( -12), we must have M (ak ) = f alse. Therefore, a 
/ agenda(sk ).
k
Case 2: a is ended in step k. In this case, we have M (ej ) = true. Since M satisfies
( -10), we must have M (ak ) = f alse. Therefore, a 
/ agenda(sk ). Because in both
cases, we have a 
/ agenda(sk ), we can infer that agenda(sk )  agenda(sm ).
The above arguments show that state(sk ) = state(sm ) and agenda(sk ) = agenda(sm ).
Hence, we have sk = sm and sk = succ(sk1 , hei1 , ..., eim i). Therefore, for the ordering functions O : {1, ..., m}  {1, ..., m}, where O(i) = i, we have sk = succ(sk1 , heO(i1 ) , ..., eO(im ) i),
and thus Stepk is a -step from sk1 to sk .

Theorem 9. Let P = (I, G, A) be a temporal planning problem,  = he1 , ..., en i be a
causally valid plan for P, and  : {1, ..., n}  Q be a relaxed scheduling function for .
There exists a valid temporal plan for P.
624

fiITSAT: An Efficient SAT-Based Temporal Planner

Proof. By using the bubble sort algorithm, we can sort the events of  in an increasing order
according the values given to them by  . This algorithm takes two consecutive members
of a sequence, and swaps them only if the value of the first one is greater than that of the
second one. It continues doing the swaps until the whole sequence is properly sorted. Let ei
and ej be two events swapped by the bubble sort in any stage of the algorithm (assume that
ei is located before ej in the sequence prior to swapping). Then, we must have  (i) >  (j).
Thus, according to (S-1), we know that ei and ej are swappable (c.f., Definition 12). As a
result, if the whole sequence was a causally valid plan prior to swapping, it would also be a
causally valid plan after that swapping. This means that sorting  according to the values
given by  will result in another causally valid plan, say   . The plan   obviously satisfies
the two conditions of Definition 9, and therefore, (  ,  ) is a valid temporal plan for P.

Theorem 10. Let P = (I, G, A) be a solvable temporal planning problem, and COM be
the set of every member of A that is either compressible towards its start or compressible
towards its end (Definition 13). There exists a valid temporal plan (,  ) for P such that
 is a causally valid plan for P,  is compressed with respect to COM, and  is a relaxed
scheduling function for .
Proof. Let 1 = e1 , ..., ei , ei+1 , ..., en be a causally valid plan for P such that ei and ei+1 are
two swappable events. Let 2 = e1 , ..., ei+1 , ei , ..., en be the result of swapping ei and ei+1
in 1 . We show that if  is a relaxed scheduling function for 1 , then it is also a relaxed
scheduling function for 2 .
 Consider any two events ej and ek such that in 2 , ej is located before ek . If j 6= i + 1
or k 6= i, then in 1 , ej is definitely located before ek , too, and therefore the property
(S-1) holds for ej and ek . On the other hand, if j = i + 1 and k = i, ej and ek are
swappable and therefore the property (S-1) trivially holds for ej and ek .
 Assume that ej is the starting event of a particular action a, and ek is the pairing
event of ej in 2 . From Definition 8, we can easily infer that if in 2 , ei is located
between ej and ek , then ei cannot be the starting or ending event of a. Similarly, if
ei+1 is located between ej and ek , then ei+1 cannot be the starting or ending event of
a. On the other hand, since ei and ei+1 are swappable, we know that they cannot be
both some events of the same action, and therefore, either j 6= i + 1 or k 6= i. Thus,
swapping ei and ei+1 cannot falsify the fact that ej and ek are pairing events. In other
words, in 1 , too, ek is the pairing event of ej . This implies that the property (S-2)
holds for ej and ek .
Let (  ,  ) be an arbitrary valid temporal plan for P. Since  is a scheduling function for
  , it can obviously be also regarded as a relaxed scheduling function for   . As we showed
in Section 3.2,   can be transformed to a causally valid plan  that is compressed with
respect to COM, by doing a series of swaps, where each swapping occurs between a pair
of consecutive swappable events. Therefore,  must also be a relaxed scheduling function
for , and (,  ) is a valid temporal plan for P, where  is the same scheduling function
as  .
625

fiRankooh & Ghassem-Sani

P
Theorem 11. Let P = (I, G, A) be a temporal planning problem,
= {e1 , ..., en } be the




set of all events of P, l be any of the three formulae l , l , l (defined in Section
P 4), and 
be a non-empty causally valid plan for P obtained by solving l . Let  = (S , , T , x0 , A )
be an FSM that accepts a subsequence   = he1 , ..., em i of , and 
l be the encoding of
 presented by (-1) to (-6). There does not exist any model M for l  
l such that
 = plan(M ).
Proof. We give the proof by contradiction. Assume that there exists a model M for l  
l
such that  = plan(M ). Let f : {1, ..., m}  {1,P
..., n} be a function such that for each i,
f (i) is equal to the index of the i-th event of   in . Moreover, let g : {1, ..., m}  {1, ..., l}
be a function such that for each i, g(i) is equal to the step number of the SAT variable in
l that corresponds to the i-th event of   . Assume x0 , ..., xm to be a sequence of states
of  such that for 0 < i  m, we have xi = T (xi1 , ef (i) ). Since  accepts   , we must
f (1),g(1)

have xm  A . As M satisfies (-5), we have M (x0
) = true. Here, two cases can be
considered. case 1: g(2) = g(1). In this case, since  = plan(M ), for f (1) < j < f (2), we
g(1)
must have M (ej ) = f alse. Now, by considering (  1) and (  2), we can infer that
g(2),f (2)

M (x1
) = true. Case 2: g(2) > g(1). In this case, by considering (  1) and (  2),
g(1),n+1
we can infer that M (x1
) = true. Then by, considering (  4), we can deduce that
g(1)+1,0
M (x1
) = true. By the same argument plus considering (  3) we can show that
g(2),f (2)
g(i),f (i)
M (x1
) = true. The whole deduction can be repeated to show that M (xi1
) = true
g(m),f (m)

for 1  i  m. Therefore, we have M (xm1
) = true. Since xm = T (xm1 , ef (m) ),
out  E in  {e
by considering (  1), we can infer that for j, such that ej  Em
n+1 } and
m
g(m),j
in
out
) = true. However, since xm  A ,
{ef (m)+1 , ..., ej1 }  (Em  Em ) = , we have M (xm
this contradicts the assumption that M satisfies (  6).
P
Theorem 12. Let P = (I, G, A) be a temporal planning problem,
= {e1 , ..., en } be



the set of all events of P, and l be any of the three formulae l , l , l (defined in
Section 4). Let M be a model that satisfies l , and  = he1 , ..., em i = plan(M ). Let
P
 = (S , , T , x0 , A ) be an FSM that does not accept any subsequence of , and 
l be


the encoding of  composed of (-1) to (-6). There exists a model M for l  l such
that  = plan(M  ).
Proof. Let us introduce a total order relation  on those SAT variables of l that correspond


to events of the input problem. For any two sat variables eki and eki , we have eki  eki if
and only if one of the following two conditions holds: 1) k < k  . 2) k = k  and i < i .
Assume that f : {1, ..., m}  {1, ...,Pn} is a function such that for each i, f (i) is equal to
the index of the i-th event of  in . Moreover, assume that g : {1, ..., m}  {1, ..., l} is
a function such that for each k, g(k) is equal to the step number of the SAT variable in l
that corresponds to the k-th event of . Let uk,i = heu , ..., et i denote a subsequence of 
with the following properties:
g(t)

 M (ef (t) ) = true.
626

fiITSAT: An Efficient SAT-Based Temporal Planner

g(t)





 For all i and k  such that ef (t)  eki  eki , we have M (eki ) = f alse.
In fact, uk,i is a substring of  that spans from the u-th event of  to the last event of 
whose corresponding SAT variable is located before eki in l . We define the model M  for
l  
l by the following rules:
(R-1) For each SAT variable v of l , M  (v) = M (v).
(R-2) For 1  k  l and 1  i  n, M  (xk,i
0 ) = true.
(R-3) For 1  k  l, 1 < i  n, and xs  S , M  (xk,i
s ) = true iff for some j, the sequence
jk,i transforms  from x0 to xs .
From (R-1), we can infer that M  satisfies l . We now show that M  also satisfies all
formulae (-1) to (-6), and thereby, it satisfies 
l .
 xk,j
be an arbitrary formula from (-1). If M  (eki ) = f alse or
(-1) Let eki  xk,i
s
t
 k,i
 k
M  (xk,i
s ) = f alse, the formula is trivially satisfied. Assume that M (ei ) = M (xs ) =
k,i
true. By (R-3), for some u, the sequence u transforms  from x0 to xs . Since
eki  ekj , by the way we defined uk,j , we can deduce that uk,j = uk,i  hei i    , where ()
denotes the concatenation operator and   is a sequence of events from {ei+1 , ..., ej1 }.
By (-1), we have T (xs , ei ) = xt , and therefore ei causes  to transit from xs to
xt . Besides, {ei+1 , ..., ej1 }  Etout = , and thus, no member of   can cause  to
transit to a state other than xt . Therefore, uk,j transforms  from x0 to xt , and
M  (xk,j
t ) = true. Hence, the formula is satisfied.
k,j
be an arbitrary formula from (-2). If M  (eki ) = true or
(-2) Let eki  xk,i
s  xs
 k
M  (xk,i
s ) = f alse, the formula is trivially satisfied. Assume that M (ei ) = f alse and
k,i
M  (xk,i
s ) = true. By (R-3), for some u, the sequence u transforms  from x0 to xs .
k,j
Since eki  ekj , by the way we defined u , we can deduce that uk,j = uk,i    , where
  is a sequence of events from {ei+1 , ..., ej1 }. Besides, {ei+1 , ..., ej1 }  Esout = ,
and thus, no member of   can cause  to transit to a state other than xs . Therefore,
uk,j transforms  from x0 to xs , and M  (xk,j
s ) = true. Hence, the formula is satisfied.
k,i
 k,0
(-3) Let xk,0
s  xs be an arbitrary formula from (-3). If M (xs ) = f alse, the formula
is trivially satisfied. Assume that M  (xk,0
s ) = true. By (R-3), for some u, the
k,0
sequence u transforms  from x0 to xs . Since ek0  eki , by the way we defined uk,i ,
we can deduce that uk,i = uk,0   , where   is a sequence of events from {e1 , ..., ei1 }.
Besides, {e1 , ..., ei1 }Esout = , and thus, no member of   can cause  to transit to a
state other than xs . Therefore, uk,i transforms  from x0 to xs , and M  (xk,i
s ) = true.
Hence, the formula is satisfied.

(-4) Let xk,n+1
 xk+1,0
be an arbitrary formula from (-4). By the way we defined
s
s
k+1,0
) =
, we can deduce that uk,n+1 = uk+1,0 for every u. Therefore, M  (xk,n+1
u
s
k+1,0

M (xs
). Hence, the formula is satisfied.
(-5) According to (R-2), any formula from (-5) is directly satisfied by M  , .
627

fiRankooh & Ghassem-Sani

(-6) Let xk,i be an arbitrary formula from (-6). Accorrding to our assumptions, uk,i
cannot cause  to transit to any of its accepting states. Since we have x  A , (R-3)
implies that M  (xk,i ) = f alse. Hence, the formula is satisfied.

Theorem 13. Let N = xi1 , ..., xim be a negative cycle in the STN corresponding to a
causally valid plan  = e1 , ..., en of a temporal problem P, where xik is the node corresponding to event eik of . Let   be another causally valid plan for P. If a subsequence of
  is a member of LN (defined in Section 5), the corresponding STN of   will also have N
as a negative cycle.
Proof. Let ei1 , e2,1 ..., e2,k2 , ei2 , ..., eim1 , em,1 , ..., em,km , eim be a subsequence of   , where
ej,1 , ..., ej,kj is a string of symbols in j , for 1 < j  m. Consider two arbitraty events
eij and eij  from this sequence, such that ij < ij  . We show that any temporal constraints
between  (eij ) and  (eij  ) is also present between  (ij ) and  (ij  ).
 If we have the constraint  (ij ) <  (ij  ), then by the scheduling constraint (S-1)
explained in Section 5, eij and eij  are not swappable. Besides, in   , eij is clearly
located before eij  . Consequently, we must have  (ij ) <  (ij  ) according to the
scheduling constraint (S-1).
 If we have the constraint  (ij  ) (ij ) = dur(a), then by the scheduling rule (S-2), eij
and eij  have to be the starting event and the ending event of a, respectively. Moreover,
for j < j  < j  , we have action(eij  ) 6= a. This indicates that for j < j   j  , a is
in Oj  , and therefore eij  
/ j  . Since ej  ,1 ..., ej  ,k  is a string of symbols in j  ,
j
we conclude that in   , a is not yet ended before reaching eij  . This means that eij
and eij  are pairing events in   . Thus, by the scheduling constraint (S-2), we have
 (ij  )   (ij ) = dur(a).
This shows that any edge between xij and xij  in the corresponding STN of  is also present
in the corresponding STN of   , and thus the latter STN has N as its negative cycle.

References
Allen, J. F. (1984). Towards a general theory of action and time. Artif. Intell., 23 (2),
123154.
Armando, A., & Giunchiglia, E. (1993). Embedding complex decision procedures inside an
interactive theorem prover. Ann. Math. Artif. Intell., 8 (3-4), 475502.
Benton, J., Coles, A. J., & Coles, A. (2012). Temporal planning with preferences and
time-dependent continuous costs. In Proceedings of the Twenty-Second International
Conference on Automated Planning and Scheduling, ICAPS 2012, Atibaia, Sao Paulo,
Brazil, June 25-19, 2012.
Biere, A. (2009). P{re,i}cosat@sc09. solver description for SAT competition 2009. In SAT
2009 Competitive Event Booklet.
628

fiITSAT: An Efficient SAT-Based Temporal Planner

Biere, A. (2013). Lingeling, Plingeling and Treengeling entering the sat competition 2013.
In Proceedings of SAT Competition 2013.
Blum, A., & Furst, M. L. (1997). Fast planning through planning graph analysis. Artif.
Intell., 90 (1-2), 281300.
Castellini, C., Giunchiglia, E., & Tacchella, A. (2003). SAT-based planning in complex
domains: Concurrency, constraints and nondeterminism. Artif. Intell., 147 (1-2), 85
117.
Coles, A. J., Coles, A., Fox, M., & Long, D. (2009). Extending the use of inference in
temporal planning as forwards search. In Proceedings of the 19th International Conference on Automated Planning and Scheduling, ICAPS 2009, Thessaloniki, Greece,
September 19-23, 2009.
Coles, A. J., Coles, A., Fox, M., & Long, D. (2010). Forward-chaining partial-order planning. In Proceedings of the 20th International Conference on Automated Planning and
Scheduling, ICAPS 2010, Toronto, Ontario, Canada, May 12-16, 2010, pp. 4249.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). Introduction to Algorithms
(3. ed.). MIT Press.
Cushing, W., Kambhampati, S., Mausam, & Weld, D. S. (2007). When is temporal planning
really temporal?. In IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence, Hyderabad, India, January 6-12, 2007, pp. 18521859.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artif. Intell.,
49 (1-3), 6195.
Do, M. B., & Kambhampati, S. (2003). Sapa: A multi-objective metric temporal planner.
J. Artif. Intell. Res. (JAIR), 20, 155194.
Een, N., & Biere, A. (2005). Effective preprocessing in SAT through variable and clause
elimination. In Theory and Applications of Satisfiability Testing, 8th International
Conference, SAT 2005, St. Andrews, UK, June 19-23, 2005, Proceedings, pp. 6175.
Ernst, M. D., Millstein, T. D., & Weld, D. S. (1997). Automatic sat-compilation of planning
problems. In Proceedings of the Fifteenth International Joint Conference on Artificial
Intelligence, IJCAI 97, Nagoya, Japan, August 23-29, 1997, 2 Volumes, pp. 1169
1177.
Eyerich, P., Mattmuller, R., & Roger, G. (2009). Using the context-enhanced additive
heuristic for temporal and numeric planning. In Proceedings of the 19th International Conference on Automated Planning and Scheduling, ICAPS 2009, Thessaloniki,
Greece, September 19-23, 2009.
Fox, M., & Long, D. (2002). PDDL+: Modelling continuous time-dependent effects. In the
Third International NASA Workshop on Planning and Scheduling for Space.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal
planning domains. J. Artif. Intell. Res. (JAIR), 20, 61124.
Fox, M., & Long, D. (2007). A note on concurrency and complexity in temporal planning.
In the 26th Workshop of the UK Planning and Scheduling Special Interest Group.
629

fiRankooh & Ghassem-Sani

Garrido, A., Fox, M., & Long, D. (2002). A temporal planning system for durative actions of
PDDL2.1. In Proceedings of the 15th Eureopean Conference on Artificial Intelligence,
ECAI2002, Lyon, France, July 2002, pp. 586590.
Gerevini, A., Saetti, A., & Serina, I. (2006). An approach to temporal planning and scheduling in domains with predictable exogenous events. J. Artif. Intell. Res. (JAIR), 25,
187231.
Gerevini, A., & Schubert, L. K. (1998). Inferring state constraints for domain-independent
planning. In Proceedings of the Fifteenth National Conference on Artificial Intelligence
and Tenth Innovative Applications of Artificial Intelligence Conference, AAAI 98,
IAAI 98, July 26-30, 1998, Madison, Wisconsin, USA., pp. 905912.
Halsey, K. (2004). CRIKEY! Its Co-ordination in Temporal Planning. Ph.D. thesis, University of Durham.
Halsey, K., Long, D., & Fox, M. (2004). Multiple relaxations in temporal planning. In
Proceedings of the 16th Eureopean Conference on Artificial Intelligence, ECAI2004,
including Prestigious Applicants of Intelligent Systems, PAIS 2004, Valencia, Spain,
August 22-27, 2004, pp. 10291030.
Haslum, P. (2006). Improving heuristics through relaxed search - an analysis of TP4 and
HSP*a in the 2004 planning competition. J. Artif. Intell. Res. (JAIR), 25, 233267.
Haslum, P., & Geffner, H. (2000). Admissible heuristics for optimal planning. In Proceedings of the Fifth International Conference on Artificial Intelligence Planning Systems,
Breckenridge, CO, USA, April 14-17, 2000, pp. 140149.
Helmert, M., & Geffner, H. (2008). Unifying the causal graph and additive heuristics. In
Proceedings of the Eighteenth International Conference on Automated Planning and
Scheduling, ICAPS 2008, Sydney, Australia, September 14-18, 2008, pp. 140147.
Hoffmann, J., Gomes, C. P., Selman, B., & Kautz, H. A. (2007). SAT encodings of statespace reachability problems in numeric domains. In IJCAI 2007, Proceedings of the
20th International Joint Conference on Artificial Intelligence, Hyderabad, India, January 6-12, 2007, pp. 19181923.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through
heuristic search. J. Artif. Intell. Res. (JAIR), 14, 253302.
Huang, R., Chen, Y., & Zhang, W. (2009). An optimal temporally expressive planner:
Initial results and application to P2P network optimization. In Proceedings of the
19th International Conference on Automated Planning and Scheduling, ICAPS 2009,
Thessaloniki, Greece, September 19-23, 2009.
Huang, R., Chen, Y., & Zhang, W. (2012). SAS+ planning as satisfiability. J. Artif. Intell.
Res. (JAIR), 43, 293328.
Kautz, H. A., & Selman, B. (1992). Planning as satisfiability. In ECAI, pp. 359363.
Kautz, H. A., & Selman, B. (1996). Pushing the envelope: Planning, propositional logic and
stochastic search. In Proceedings of the Thirteenth National Conference on Artificial
Intelligence and Eighth Innovative Applications of Artificial Intelligence Conference,
AAAI 96, IAAI 96, Portland, Oregon, August 4-8, 1996, Volume 2., pp. 11941201.
630

fiITSAT: An Efficient SAT-Based Temporal Planner

Long, D., & Fox, M. (2003). Exploiting a graphplan framework in temporal planning. In
Proceedings of the Thirteenth International Conference on Automated Planning and
Scheduling (ICAPS 2003), June 9-13, 2003, Trento, Italy, pp. 5261.
Lu, Q., Huang, R., Chen, Y., Xu, Y., Zhang, W., & Chen, G. (2013). A SAT-based approach
to cost-sensitive temporally expressive planning. ACM TIST, 5 (1), 18.
Mali, A. D., & Liu, Y. (2006). T-satplan: a SAT-based temporal planner. International
Journal on Artificial Intelligence Tools, 15 (5), 779802.
Rankooh, M. F., & Ghassem-Sani, G. (2013). New encoding methods for sat-based temporal
planning. In Proceedings of the Twenty-Third International Conference on Automated
Planning and Scheduling, ICAPS 2013, Rome, Italy, June 10-14, 2013.
Rintanen, J. (2006). Compact representation of sets of binary constraints. In ECAI 2006,
17th European Conference on Artificial Intelligence, August 29 - September 1, 2006,
Riva del Garda, Italy, Including Prestigious Applications of Intelligent Systems (PAIS
2006), Proceedings, pp. 143147.
Rintanen, J. (2007). Complexity of concurrent temporal planning. In Proceedings of the
Seventeenth International Conference on Automated Planning and Scheduling, ICAPS
2007, Providence, Rhode Island, USA, September 22-26, 2007, pp. 280287.
Rintanen, J. (2012). Planning as satisfiability: Heuristics. Artif. Intell., 193, 4586.
Rintanen, J., & Gretton, C. O. (2013). Computing upper bounds on lengths of transition
sequences. In IJCAI 2013, Proceedings of the 23rd International Joint Conference on
Artificial Intelligence, Beijing, China, August 3-9, 2013.
Rintanen, J., Heljanko, K., & Niemela, I. (2006). Planning as satisfiability: parallel plans
and algorithms for plan search. Artif. Intell., 170 (12-13), 10311080.
Robinson, N., Gretton, C., Pham, D. N., & Sattar, A. (2009). Sat-based parallel planning
using a split representation of actions. In Proceedings of the 19th International Conference on Automated Planning and Scheduling, ICAPS 2009, Thessaloniki, Greece,
September 19-23, 2009.
Robinson, N., Gretton, C., Pham, D. N., & Sattar, A. (2010). Partial weighted MaxSAT
for optimal planning. In PRICAI 2010: Trends in Artificial Intelligence, 11th Pacific
Rim International Conference on Artificial Intelligence, Daegu, Korea, August 30September 2, 2010. Proceedings, pp. 231243.
Shin, J.-A., & Davis, E. (2005). Processes and continuous change in a SAT-based planner.
Artif. Intell., 166 (1-2), 194253.
Smith, D. E., & Weld, D. S. (1999). Temporal planning with mutual exclusion reasoning. In
Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence,
IJCAI 99, Stockholm, Sweden, July 31 - August 6, 1999. 2 Volumes, 1450 pages, pp.
326337.
Streeter, M. J., & Smith, S. F. (2007). Using decision procedures efficiently for optimization.
In Proceedings of the Seventeenth International Conference on Automated Planning
and Scheduling, ICAPS 2007, Providence, Rhode Island, USA, September 22-26, 2007,
pp. 312319.
631

fiRankooh & Ghassem-Sani

Vidal, V. (2014). Yahsp3 and Yahsp3-mt in the 8th international planning competition. In
International Planning Competition.
Vidal, V., & Geffner, H. (2006). Branching and pruning: An optimal temporal POCL
planner based on constraint programming. Artif. Intell., 170 (3), 298335.
Wehrle, M., & Rintanen, J. (2007). Planning as satisfiability with relaxed -Step plans.
In AI 2007: Advances in Artificial Intelligence, 20th Australian Joint Conference on
Artificial Intelligence, Gold Coast, Australia, December 2-6, 2007, Proceedings, pp.
244253.
Younes, H. L. S., & Simmons, R. G. (2003). VHPOP: Versatile heuristic partial order
planner. J. Artif. Intell. Res. (JAIR), 20, 405430.

632

fi