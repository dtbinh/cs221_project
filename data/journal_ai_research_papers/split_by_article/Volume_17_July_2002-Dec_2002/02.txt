Journal of Artificial Intelligence Research 17 (2002) 57-81

Submitted 12/01; published 8/02

A Logic for Reasoning about Upper Probabilities
Joseph Y. Halpern
Riccardo Pucella

halpern@cs.cornell.edu
riccardo@cs.cornell.edu

Department of Computer Science
Cornell University
Ithaca, NY 14853
http://www.cs.cornell.edu/home/halpern

Abstract
We present a propositional logic to reason about the uncertainty of events, where the
uncertainty is modeled by a set of probability measures assigning an interval of probability
to each event. We give a sound and complete axiomatization for the logic, and show that
the satisfiability problem is NP-complete, no harder than satisfiability for propositional
logic.

1. Introduction
Various measures exist that attempt to quantify uncertainty. For many trained in the use
of probability theory, probability measures are an obvious choice. However, probability
cannot easiliy capture certain situations of interest. Consider a simple example: suppose
we have a bag of 100 marbles; we know 30 are red and we know the remaining 70 are
either blue or yellow, although we do not know the exact proportion of blue and yellow. If
we are modeling the situation where we pick a ball from the bag at random, we need to
assign a probability to three different events: picking up a red ball (red-event), picking up
a blue ball (blue-event), and picking up a yellow ball (yellow-event). We can clearly assign
a probability of .3 to red-event, but there is no clear probability to assign to blue-event or
yellow-event.
One way to approach this problem is to represent the uncertainty using a set of probability measures, with a probability measure for each possible proportion of blue and yellow
balls. For instance, we could use the set of probabilities P = { :   [0, .7]}, where
 gives red-event probability .3, blue-event probability , and yellow-event probability
.7  . To any set of probabilities P we can assign a pair of functions, the upper and lower
probability measure, that for an event X give the supremum (respectively, the infimum) of
the probability of X according to the probability measures in P. These measures can be
used to deal with uncertainty in the manner described above, where the lower and upper
probability of an event defines a range of probability for that event.1 (This example can
be viewed as giving a frequentist interpretation of upper probabilities. Upper probabilities
can also be given a subjective interpretation, for example, by considering the odds at which
someone would be willing to accept or reject a bet (Smith, 1961; Walley, 1991).)
1. Note that using sets of probability measures is not the only way to model this situation. An alternative
approach, using inner measures, is studied by Fagin and Halpern (1991).

c
2002
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiHalpern & Pucella

Given a measure of uncertainty, one can define a logic for reasoning about it. Fagin,
Halpern and Megiddo (1990) (FHM from now on) introduce a logic for reasoning about
probabilities, with a possible-worlds semantics that assigns a probability to each possible
world. They provide an axiomatization for the logic, which they prove sound and complete
with respect to the semantics. They also show that the satisfiability problem for the logic,
somewhat surprisingly, is NP-complete, and hence no harder than the satisfiability problem
for propositional logic. They moreover show how their logic can be extended to other notions
of uncertainty, such as inner measures (Fagin & Halpern, 1991) and Dempster-Shafer belief
functions (Shafer, 1976).
In this paper, we describe a logic for reasoning about upper probability measures, along
the lines of the FHM logic. The logic allows reasoning about linear inequalities involving
upper probabilities measures. Like the logics considered in FHM, our logic is agnostic
as to the interpretation of upper probabilities, whether frequentist or subjectivist. The
main challenge is to derive a provably complete axiomatization of the logic; to do this, we
need a characterization of upper probability measures in terms of properties that can be
expressed in the logic. Many semantic characterizations of upper probability measures have
been proposed in the literature. The characterization of Anger and Lembcke (1985) turns
out to be best suited for our purposes. Even though we are reasoning about potentially
infinite sets of probability measures, the satisfiability problem for our logic remains NPcomplete. Intuitively, we need guess only a small number of probability measures to satisfy
any given formula, polynomially many in the size of the formula. Moreover, these probability
measures can be taken to be defined on a finite state space, again polynomial in the size of
the formula. Thus, we need to basically determine polynomially many valuesa value for
each probability measure at each stateto decide the satisfiability of a formula.
The rest of this paper is structured as follows. In Section 2, we review the required
material from probability theory and the theory of upper probabilities. In Section 3, we
present the logic and an axiomatization. In Section 4, we prove that the axiomatization is
sound and complete with respect to the natural semantic models expressed in terms of upper
probability spaces. Finally, in Section 5, we prove that the decision problem for the logic is
NP-complete. The proofs of the new, more technical results are given in Appendix A. To
make the paper self-contained, we also review Anger and Lembckes results in Appendix B.

2. Characterizing Upper Probability Measures
We start with a brief review of the relevant definitions. Recall that a probability measure
is a function  :   [0, 1] for  an algebra of subsets of  (that is  is closed under
complements and unions), satisfying () = 0, () = 1, and (A  B) = (A) + (B) for
all disjoint sets A, B in .2 A probability space is a tuple (, , ), where  is a set,  is
an algebra of subsets of  (the measurable sets), and  is a probability measure defined on
. Given a set P of probability measures, let P  be the upper probability measure defined
2. If  is infinite, we could also require that  be a -algebra (i.e., closed under countable unions) and that
 be countably additive. Requiring countable additivity would not affect our results, since we show that
we can take  to be finite. For ease of exposition, we have not required it.

58

fiA Logic for Reasoning about Upper Probabilities

by P  (X) = sup{(X) :   P} for X  .3 Similarly, P (X) = inf{(X) :   P} is
the lower probability of X  . A straightforward derivation shows that the relationship
P (X) = 1P  (X) holds between upper and lower probabilities, where X is the complement
of X in . Because of this duality, we restrict the discussion to upper probability measures
in this paper, with the understanding that results for lower probabilities can be similarly
derived. Finally, an upper probability space is a tuple (, , P) where P is a set of probability
measures on .
We would like a set of properties that completely characterizes upper probability measures. In other words, we would like a set of properties that allow us to determine if a
function f :   R (for an algebra  of subsets of ) is an upper probability measure,
that is, whether there exists a set P of probability measures such that for all X  ,
P  (X) = f (X).4
One approach to the characterization of upper probability measures is to adapt the
characterization of Dempster-Shafer belief functions; these functions are known to be the
lower envelope of the probability measures that dominate them, and thus form a subclass
of the class of lower probability measures. By the duality noted earlier, a characterization
of lower probability measures would yield a characterization of upper probability measures.
The characterization of belief functions is derived from a generalization of the following
inclusion-exclusion principle for probabilities (obtained by replacing the equality with an
inequality):
(

n
[

n
X
(1)i1 (

Ai ) =

i=1

i=1

X

(

J{1,... ,n}
|J|=i

\

Aj )).

jJ

It seems reasonable that a characterization of lower (or upper) probability measures
could be derived along similar lines. However, as is well known, most properties derivable
from the inclusion-exclusion principle (which include most of the properties reported in the
literature) are insufficient to characterize upper probability measures. Huber (1981, p. 257)
and Walley (1991, p. 85) give examples showing the insufficiencies of such properties.
To give a sense of the insufficiency of simple properties, consider the following inclusionexclusionstyle properties, some of which are taken from (Walley, 1991). To simplify the
statement of these properties, let P 1 = P  and P +1 = P .
P P
i T
(1) P  (A1      An )  ni=1 |I|=i (1)i+1 P (1) ( jI Aj ),
(2) P (A1      An ) 

Pn P
i=1

|I|=i (1)

i+1 P (1)i+1 (

T

jI

Aj ),

(3) P (A  B) + P (A  B)  P (A) + P  (B)  P  (A  B) + P  (A  B),
3. In the literature, the term upper probability is sometimes used in a more restricted sense than here. For
example, Dempster (1967) uses the term to denote a class of measures which were later characterized as
Dempster-Shafer belief functions (Shafer, 1976); belief functions are in fact upper probability measures
in our sense, but the converse is not true (Kyburg, 1987). In the measure theory literature, what we call
upper probability measures are a special case of upper envelopes of measures, which are defined as the
sup of sets of general measures, not just probability measures.
4. It is possible to define a notion of upper probability over an arbitrary set of subsets of , not necessearily
an algebra, by simply requiring that f coincides with P  on its domain, for some set P of probability
measures. See Walley (1991) for details.

59

fiHalpern & Pucella

(4) P (A) + P (B)  P (A  B) + P  (A  B)  P  (A) + P  (B),
(5) P (A) + P (B)  P (A  B) + P  (A  B)  P  (A) + P  (B).
Note that without the alternation between upper probabilities and lower probabilities,
(1) and (2) would just be the standard notions of subadditivity and superadditivity, respectively. While subadditivity and superadditivity hold for upper and lower probabilities,
respectively, (1) and (2) are stronger properties. It is easily verified that all five properties
hold for upper probability measures. The question is whether they completely characterize
the class of upper probability measures. We show the inherent incompleteness of these
properties by proving that they are all derivable from the following simple property, which
is by itself insufficient to characterize upper probability measures:
(6) If A  B = , then P  (A) + P (B)  P  (A  B)  P  (A) + P  (B).
Proposition 2.1: Property (6) implies properties (1)-(5).
Observe that our property (6) is already given by Walley (1991, p. 84), as properties (d)
and (e). The following example shows the insufficiency of Property (6). Let P be the set
of probability measures {1 , 2 , 3 , 4 } over  = {a, b, c, d} (with  containing all subsets
of ) defined on singletons by
1 (b) =

1
4

1 (c) =

1
4

1 (d) =

1
4

2 (a) = 0 2 (b) =

1
8

2 (c) =

3
8

2 (d) =

1
2

3
8

3 (c) = 0

3 (d) =

1
2

1 (a) =

1
4

3 (a) =

1
8

3 (b) =

4 (a) =

3
8

4 (b) = 0 4 (c) =

1
8

4 (d) = 12 ,

and extended by additivity to all of . This defines an upper probability measure P  over
. Consider the function  :   [0, 1] defined by
 
P (X) +  if X = {a, b, c}
 (X) =
P  (X)
otherwise.
We claim that the function  , for small enough  > 0, satisfies property (6), but cannot be
an upper probability measure.
Proposition 2.2: For 0 <  < 18 , the function  satisfies property (6), but is not an
upper probability measure. That is, we cannot find a set P 0 of probability measures such
that  = (P 0 ) .
This example clearly illustrates the need to go beyond the inclusion-exclusion principle
to find properties that characterize upper probability measures. As it turns out, various
complete characterizations have been described in the literature (Lorentz, 1952; Huber,
1976, 1981; Williams, 1976; Wolf, 1977; Giles, 1982; Anger & Lembcke, 1985; Walley, 1991).
Most of these characterizations are obtained by considering upper and lower expectations,
rather than working directly with upper and lower probabilities. Anger and Lembcke (1985)
60

fiA Logic for Reasoning about Upper Probabilities

give a characterization in terms of upper and lower probabilities. Since their characterization
is particularly well-suited to the logic presented in the next section, we review it here.
The characterization is based on the notion of set cover. A set A is said to be covered
n times by a multiset {{A1 , . . . , Am }} of sets if every element of A appears in at least
n sets from A1 , . . . , Am : for all x  A, there exists distinct i1 , . . . , in in {1, . . . , m} such
that for all j  n, x  Aij . It is important to note here that {{A1 , . . . , Am }} is a multiset, not a set; the Ai s are not necessarily distinct. (We use the {{ }} notation to denote
multisets.) An (n, k)-cover of (A, ) is a multiset {{A1 , . . . , Am }} that covers  k times
and covers A n + k times. For example, {{1, 2}, {2, 3}, {1, 3}} covers {1, 2, 3} 2 times, and
{{{1, 2}, {2, 3}, {1, 3}, {2}, {2}}} is a (2,2) cover of ({2}, {1, 2, 3}).
The notion of (n, k)-cover is the key concept in Anger and Lembckes characterization
of upper probability measures.
Theorem 2.3: (Anger & Lembcke, 1985) Suppose that  is a set,  is an algebra of subsets
of , and  :   R. Then there exists a set P of probability measures with  = P  if and
only if  satisfies the following three properties:
UP1. () = 0,
UP2. () = 1,
UP3. for all natural numbers m, n, k and all subsets A1P
, . . . , Am in , if {{A1 , . . . , Am }}
is an (n, k)-cover of (A, ), then k + n(A)  m
i=1 (Ai ).
Proof: We reproduce a proof of this result in Appendix B.
Note that UP1 is redundant in the presence of UP2 and UP3. Indeed, {{, }} is a
(0, 1)-cover of (, ), and applying UP3 yields () + () = 1. Since UP2 states that
() = 1, this means that () = 0. A further consequence of UP3 is that if A  B, then
(A)  (B), since {{B}} is a (1, 0)-cover of (A, ). Therefore, for all A  , (A)  [0, 1].
We need to strengthen Theorem 2.3 in order to prove the main result of this paper,
namely, the completeness of the axiomatization of the logic we introduce in the next section.
We show that if the cardinality of the state space  is finite, then we need only finitely
many instances of property UP3. Notice that we cannot derive this from Theorem 2.3
alone: even if || is finite, UP3 does not provide any bound on m, the number of sets to
consider in an (n, k) cover of a set A. Indeed, there does not seem to be any a priori reason
why the value of m, n, and k can be bounded. Bounding this value of m (and hence of n
and k, since they are no larger than m) is one of the key technical results of this paper, and
a necessary foundation for our work.
Theorem 2.4: There exist constants B0 , B1 , . . . such that if  is a finite set,  is an
algebra of subsets of , and  :   R, then there exists a set P of probability measures
such that  = P  if and only if  satisfies the following properties:
UPF1. () = 0,
UPF2. () = 1,
UPF3. for all integers m, n, k  B|| and all sets A1 , P
. . . , Am , if {{A1 , . . . , Am }}
is an (n, k)-cover of (A, ), then k + n(A)  m
i=1 (Ai ).
61

fiHalpern & Pucella

Property UPF3 is significantly weaker than UP3. In principle, checking that UP3
holds for a given function requires checking that it holds for arbitrarily large collections of
sets, even if the underlying set  is finite. On the other hand, UPF3 guarantees that if  is
finite, then it is in fact sufficient to look at collections of size at most B|| . This observation
is key to the completeness result.
Theorem 2.4 does not prescribe any values for the constants B0 , B1 , . . . . Indeed, the
proof found in Appendix A relies on a Ramsey-theoretic argument that does not even
provide a bound on the Bi s. We could certainly attempt to obtain such bounds, but
obtaining them is completely unnecessary for our purposes. To get completeness of the
axiomatization of the logic introduced in the next section, it is sufficient for there to exist
finite constants B0 , B1 , . . . .

3. The Logic
The syntax for the logic is straightforward, and is taken from FHM. We fix a set 0 =
{p1 , p2 , . . . } of primitive propositions. The set  of propositional formulas is the closure
of 0 under  and . We assume a special propositional formula true, and abbreviate
true as false. We use p to represent primitive propositions, and  and  to represent
propositional formulas. A term is an expression of the form 1 l(1 ) +    + k l(k ), where
1 , . . . , k are reals and k  1. A basic likelihood formula is a statement of the form t  ,
where t is a term and  is a real. A likelihood formula is a Boolean combination of basic
likelihood formulas. We use f and g to represent likelihood formulas. We use obvious
abbreviations where needed, such as l()  l()  a for l() + (1)l()  a, l()  l()
for l()  l()  0, l()  a for l()  a, l() < a for (l()  a) and l() = a for
(l()  a)  (l()  a). Define the length |f | of the likelihood formula f to be the number
of symbols required to write f , where each coefficient is counted as one symbol. Let LQU be
the language consisting of likelihood formulas. (The QU stands for quantitative uncertainty.
The name for the logic is taken from (Halpern, 2002).)
In FHM, the operator l was interpreted as either probability or belief (in the sense
of Dempster-Shafer). Under the first interpretation, a formula such as l() + l()  2/3
would be intereted as the probability of  plus the probability of  is at least 2/3. Here
we interpret l as upper probaiblity. Thus, the logic allows us to make statements about
inequalities involving upper probabilities.
To capture this interpretation, we assign a semantics to formulas in LQU using an upper
probability space, as defined in Section 2. Formally, an upper probability structure is a
tuple M = (, , P, ) where (, , P) is an upper probability space and  associates with
each state (or world) in  a truth assignment on the primitive propositions in 0 . Thus,
(s)(p)  {true, false} for s   and p  0 . Let [[p]]M = {s   : (s)(p) = true}.
We call M measurable if for each p  0 , [[p]]M is measurable. If M is measurable then
[[]]M is measurable for all propositional formulas . In this paper, we restrict our attention
to measurable upper probability structures. Extend (s) to a truth assignment on all
propositional formulas in a standard way, and associate with each propositional formula
the set [[]]M = {s   : (s)() = true}. An easy structural induction shows that [[]]M

62

fiA Logic for Reasoning about Upper Probabilities

is a measurable set. If M = (, , P, ), let
M |= 1 l(1 ) +    + k l(k )   iff 1 P  ([[1 ]]M ) +    + k P  ([[k ]]M )  
M |= f iff M 6|= f
M |= f  g iff M |= f and M |= g.
Note that LQU can express lower probabilities: it follows from the duality between upper
and lower probabilities that M |= l()    1 iff P ([[]]M )  .5
Consider the following axiomatization AXup of upper probability, which we prove sound
and complete in the next section. The key axioms are simply a translation into LQU of the
characterization of upper probability given in Theorem 2.3. As in FHM, AXup is divided
into three parts, dealing respectively with propositional reasoning, reasoning about linear
inequalities, and reasoning about upper probabilities.
Propositional reasoning
Taut. All instances of propositional tautologies in LQU (see below).
MP. From f and f = g infer g.
Reasoning about linear inequalities
Ineq. All instances of valid formulas about linear inequalities (see below).
Reasoning about upper probabilities
L1. l(false) = 0.
L2. l(true) = 1.
L3. l()  0.
W
V
L4. l(1 ) +    + l(m )  nl()  k if   J{1,... ,m}, |J|=k+n jJ j and
W
V
6
J{1,... ,m}, |J|=k jJ j are propositional tautologies.
L5. l() = l() if    is a propositional tautology.
The only difference between AXup and the axiomatization for reasoning about probability
given in FHM is that the axiom l(  ) + l(  ) = l() in FHM, which expresses
the additivity of probability, is replaced by L4. Although it may not be immediately
obvious, L4 is the logical analogue of SUP3. To see this,
T first note that {{A1 , . . . , Am }}
covers
A
m
times
if
and
only
if
A

J{1,... ,m}, |J|=n jJ Aj . Thus, the formula  
W
V

says
that

(more
J{1,... ,m}, |J|=k+n jJ j
Wprecisely, the setVof worlds where  is true)
is covered k +n times by {{1 , . . . , n }}, while J{1,... ,m}, |J|=k jJ j says that the whole
space is covered k times by {{1 , . . . , n }}; roughly speaking, the multiset {{1 , . . . , n }}
is an (n, k)-cover of (, true). The conclusion of L4 thus corresponds to the conclusion of
5. Another approach, more in keeping with FHM, would be to interpret l as a lower probability measure.
On the other hand, interpreting l as an upper probability measure is more in keeping with the literature
on upper probabilities.
6. Note that, according to the syntax of LQU , 1 , . . . , m must be propositional formulas.

63

fiHalpern & Pucella

UP3. Note that in the same way that UP1 follows from UP2 and UP3, axiom L1 (as
well as L3) follows from L2 and L4.
Instances of Taut include all formulas of the form f  f , where f is an arbitrary
formula in LQU . We could replace Taut by a simple collection of axioms that characterize
propositional reasoning (see, for example, (Mendelson, 1964)), but we have chosen to focus
on aspects of reasoning about upper probability.
As in FHM, the axiom Ineq includes all valid formulas about linear inequalities. An
inequality formula is a formula of the form a1 x1 +    + an xn  c, over variables x1 , . . . , xn .
An inequality formula is said to valid if it is true under every possible assignment of real
numbers to variables. To get an instance of Ineq, we replace each variable xi that occurs
in a valid inequality formula by a primitive likelihood term of the form l(i ) (naturally each
occurence of the variable xi must be replaced by the same primitive likelihood term l(i )).
As with Taut, we can replace Ineq by a sound and complete axiomatization for Boolean
combinations of linear inequalities. One such axiomatization is given in FHM.

4. Soundness and Completeness
A formula f is provable in an axiom system AX if f can be proven using the axioms and
rules of inferences of AX. AX is sound with respect to a class M of structures if every
formula provable in AX is valid in M (i.e., valid in every structure in M); AX is complete
with respect to M if every formula valid in M is provable in AX.
Our goal is to prove that AXup is a sound and complete axiomatization for reasoning
about upper probability (i.e., with respect to upper probability structures). The soundness
of AXup is immediate from our earlier disscussion. Completeness is, as usual, harder. Unfortunately, the standard technique for proving completeness in modal logic, which involves
considering maximal consistent sets and canonical structures (see, for example, (Popkorn,
1994)) does not work. We briefly review the approach, just to point out the difficulties.
The standard approach uses the following definitions. A formula  is consistent with
an axiom system AX if  is not provable from AX. A finite set of formulas {1 , . . . , n }
is consistent with AX if the formula 1      n is consistent with AX; an infinite set
of formulas is consistent with AX if all its finite subsets are consistent with AX. F is
a maximal AX-consistent set if F is consistent with AX and no strict superset of F is
consistent with AX. If AX includes Taut and MP, then it is not hard to show, using
only propositional reasoning, that every AX-consistent set of formulas can be extended to
a maximal AX-consistent set.
To show that AX is complete with respect to some class M of structures, we must show
that every formula that is valid in M is provable in AX. To do this, it is sufficient to show
that every AX-consistent formula is satisfiable in some structure in M. Typically, this is
done by constructing what is called a canonical structure M c in M whose states are the
maximal AX-consistent sets, and then showing that a formula  is satisfied in a world w
in M c iff  is one of the formulas in the canonical set associated with world w.
Unfortunately, this approach cannot be used to prove completeness here. To see this,
consider the set of formulas
F 0 = {l() 

1
, n = 1, 2, . . . }  {l() > 0}.
n
64

fiA Logic for Reasoning about Upper Probabilities

This set is clearly AXup consistent according to our definition, since every finite subset
is satisfiable in an upper probability structure and AXup is sound with respect to upper
probability structures. It thus can be extended to a maximal AXup consistent set F .
However, the set F 0 of formulas is not satisfiable: it is not possible to assign l() a value
that will satisfy all the formulas at the same time. Hence, F is not satisfiable. Thus, the
canonical model approach, at least applied naively, simply will not work.
We take a different approach here, similar to the one taken in FHM. We do not try to
construct a single canonical model. Of course, we still must show that if a formula f is
AXup -consistent then it is satisfiable in an upper probability structure. We do this by an
explicit construction, depending on f . We proceed as follows.
By a simple argument, we can easily reduce the problem to the case where f is a
conjunction of basic likelihood formulas and negations of basic likelihood formulas. Let
N
p1 , . . . , pN be the primitive propositions that appear in f . Observe that there are 22
inequivalent propositional formulas over p1 , . . . , pN . The argument goes as follows. Let an
atom over p1 , . . . , pN be a formula of the form q1  . . .  qN , where qi is either pi or pi .
There are clearly 2N atoms over p1 , . . . , pN . Moreover, it is easy to see that any formula
N
over p1 , . . . , pN can be written in a unique way as a disjunction of atoms. There are 22
such disjunctions, so the claim follows.
Continuing with the construction of a structure satisfying f , let 1 , . . . , 22N be some
canonical listing of the inequivalent formulas over p1 , . . . , pN . Without loss of generality, we assume that 1 is equivalent to true, and 22N is equivalent to false. Since every propositional formula over p1 , . . . , pN is provably equivalent to some , it follows
that f is provably equivalent to a formula f 0 where each conjunct of f 0 is of the form
1 l(1 ) +    + 22N l(22N )  . Note that the negation of such a formula has the form
1 l(1 ) +    + 22N l(22N ) <  or, equivalently, (1 )l(1 ) +    + (22N )l(22N ) > .
Thus, the formula f gives rise in a natural way to a system of inequalities of the form:
1,1 l(1 ) +    + 1,22N l(22N )
...
r,1 l(1 ) +    + r,22N l(22N )
0 l( ) +    +  0
1,1
1
N l(22N )
1,22
..
.
0
s,1 l(1 ) +    + 0 2N l(22N )
s,2

 1
..
..
.
.
 r
> 1
..
..
.
.
> s .

(1)

We can express (1) as a conjunction of inequality formulas, by replacing each occurrence
of l(i ) in (1) by xi . Call this inequality formula f .
If f is satisfiable in some upper probability structure M , then we can take xi to be the
upper probability of i in M ; this gives a solution of f . However, f may have a solution
without f being satisfiable. For example, if f is the formula l(p) = 1/2  l(p) = 0, then
f has an obvious solution; f , however, is not satisfiable in an upper probability structure,
because the upper probability of the set corresponding to p and the upper probability of the
set corresponding to p must sum to at least 1 in all upper probability structures. Thus,
we must add further constraints to the solution to force it to act like an upper probability.
UP1UP3 or, equivalently, the axioms L1L4, describe exactly what additional constraints are needed. The constraint corresponding to L1 (or UP1) is just x1 = 0, since
65

fiHalpern & Pucella

we have assumed 1 is the formula false. Similarly, the constraint corresponding to L2 is
N
x22N = 1. The constraint corresponding to L3 is xi  0, for i = 1, . . . , 22 . What about
L4? This seems to require an infinite collection of constraints, just as UP3 does.7
This is where UPF3 comes into play. It turns out that, if f is satisfiable at all, it
is satisfiable in a structure with at most 2N worlds, one for each atom over p1 , . . . , pN .
Thus, we need to add only instances of L4 where k, m, n < B2N and 1 , . . . , m ,  are all
among 1 , . . . , 22N . Although this is a large number of formulas (in fact, we do not know
exactly how large, since it depends on B2N , which we have not computed), it suffices for our
purposes that it is a finite number. For each of these instances of L4, there is an inequality
of the form a1 x1 +    + a22N x22N  k. Let f, the inequality formula corresponding to f ,
be the conjunction consisting of f , together with all the inequalities corresponding to the
relevant instances of L4, and the equations and inequalities x1 = 0, x22N = 1, and xi  0
N
for i = 1, . . . , 22 , corresponding to axioms L1L3.
Proposition 4.1: The formula f is satisfiable in an upper probability structure iff the
inequality formula f has a solution. Moreover, if f has a solution, then f is satisfiable in
an upper probability structure with at most 2|f | worlds.
Theorem 4.2: The axiom system AXup is sound and complete for upper probability structures.
Proof: For soundness, it is easy to see that every axiom is valid for upper probability
structures, including L4, which represents UP3.
For completeness, we proceed as in the discussion above. Assume that formula f is not
satisfiable in an upper probability structure; we must show that f is AXup inconsistent.
We first reduce f to a canonical form. Let g1      gr be a disjunctive normal form
expression for f (where each gi is a conjunction of basic likelihood formulas and their
negations). Using propositional reasoning, we can show that f is provably equivalent to this
disjunction. Since f is unsatisfiable, each gi must also be unsatisfiable. Thus, it is sufficient
to show that any unsatisfiable conjunction of basic likelihood formulas and their negations is
inconsistent. Assume that f is such a conjunction. Using propositional reasoning and axiom
N
L5, f is equivalent to a likelihood formula f 0 that refers to 22 propositional formulas, say
1 , . . . , 22N . Since f is unsatisfiable, so is f 0 . By Proposition 4.1, the inequality formula
f0 corresponding to f 0 has no solution. Thus, by Ineq, the formula f 00 that results by
replacing each instance of xi in f0 by l(i ) is AXup provable. All the conjuncts of f 00 that
are instances of axioms L1L4 are AXup provable. It follows that f 0 is AXup provable,
and hence so is f .

5. Decision Procedure
Having settled the issue of the soundness and completeness of the axiom system AXup ,
we turn to the problem of the complexity of deciding satisfiability. Recall the problem of
7. Although we are dealing with only finitely many formulas here, 1 , . . . , 22N , recall that the formulas
1 , . . . , m in L4 need not be distinct, so there are potentially infinitely many instances of L4 to deal
with.

66

fiA Logic for Reasoning about Upper Probabilities

satisfiability: given a likelihood formula f , we want to determine if there exists an upper
probability structure M such that M |= f . As we now show, the satisfiability problem is
NP-complete, and thus no harder than satisfiability for propositional logic.
For the decision problem to make sense, we need to restrict our language slightly. If
we allow real numbers as coefficients in likelihood formulas, we have to carefully discuss
the issue of representation of such numbers. To avoid these complications, we restrict our
language (in this section) to allow only integer coefficients. Note that we can still express
rational coefficients by the standard trick of clearing the denominator. For example, we
can express 32 l()  1 by 2l()  3 and l()  23 by 3l()  2. Recall that we defined
|f | to be the length of f , that is, the number of symbols required to write f , where each
coefficient is counted as one symbol. Define ||f || to be the length of the longest coefficient
appearing in f , when written in binary. The size of a rational number ab , denoted || ab ||,
where a and b are relatively prime, is defined to be ||a|| + ||b||.
A preliminary result required for the analysis of the decision procedure shows that if a
formula is satisfied in some upper probability structure, then it is satisfied in a structure
(, , P, ), which is small in terms of the number of states in , the cardinality of the
set P of probability measures, and the size of the coefficients in f .
Theorem 5.1: Suppose f is a likelihood formula that is satisfied in some upper probability
structure. Then f is satisfied in a structure (, , P, ), where ||  |f |2 ,  = 2 (every
subset of  is measurable), |P|  |f |, (w) is a rational number such that ||(w)|| is
O(|f |2 ||f || + |f |2 log(|f |)) for every world w   and   P, and (w)(p) = false for every
world w   and every primitive proposition p not appearing in f .
Theorem 5.2: The problem of deciding whether a likelihood formula is satisfiable in an
upper probability structure is NP-complete.
Proof: For the lower bound, it is clear that a given propositional formula  is satisfiable iff
the likelihood formula l() > 0 is satisfiable, therefore the satisfiability problem is NP-hard.
For the upper bound, given a likelihood formula f , we guess a small satisfying structure
M = (, , P, ) for f of the form guaranteed to exist by Theorem 5.1. We can describe
such a model M in size polynomial in |f | and ||f ||. (The fact that (w)(p) = false for
every world w   and every primitive proposition p not appearing in f means that we
must describe  only for propositions that appear in f .) We verify that M |= f as follows.
Let l() be an arbitrary likelihood term in f . We compute [[]]M by checking the truth
assignment of each s   and seeing whether this
P truth assignment makes  true. We then
replace each occurence of l() in f by maxP { s[[]]M (s)} and verify that the resulting
expression is true.

6. Conclusion
We have considered a logic with the same syntax as the logic for reasoning about probability, inner measures, and belief presented in FHM, with uncertainty interpreted as the upper
probability of a set of probability measures. Under this interpretation, we have provided
a sound and complete axiomatization for the logic. We further showed that the satisfiability problem is NP-complete (as it is for reasoning about probability, inner measures, and
67

fiHalpern & Pucella

beliefs), despite having to deal with probability structures with possibility infinitely many
states and infinite sets of probability measures. The key step in the axiomatization involves
finding a characterization of upper probability measures that can be captured in the logic.
The key step in the complexity result involves showing that if a formula is satisfiable at all,
it is satisfiable in a small structure, where the size of the state space, as well as the size
of the set of probability measures and the size of all probabilities involved, are polynomial
in the length of the formula.
Given the similarity in spirit of the results for the various interpretations of the uncertainty operator (as a probability, inner measure, belief function, and upper probability),
including the fact that the complexity of the decision problem is NP-complete in all cases,
we conjecture that there is some underlying result from which all these results should follow.
It would be interesting to make that precise.
In FHM, conditional probabilities as well as probabilities are investigated. We have not,
in this paper, discussed conditional upper probabilities. The main reason for this is that,
unlike probability, we cannot characterize conditional upper probabilities in terms of (unconditional) upper probabilities. Thus, our results really tell us nothing about conditional
upper probabilities. It might be of interest to consider a logic that allows conditional upper probabilities as primitive likelihood terms (that is, allows likelihood terms of the form
l( | )). While there is no intrinsic difficult giving semantics to such a language, it is far
from clear what an appropriate axiomatization would be, or the effect of this extension on
complexity.
Finally, it is worth noting that the semantic framework developed here and in FHM
is in fact rich enough to talk about gambles (that is, real-valued functions over the set
of states) and the expectation of such gambles. Expectation functions can be defined for
the different measures of uncertainty, including upper probabilities, and it is not difficult to
extend the FHM logic in order to reason about expectation. One advantage of working with
expectation functions is that they are typically easier to characterize than the corresponding
measures; for instance, the characterization of expected upper probabilities is much simpler
than that of upper probabilities (Huber, 1981; Walley, 1981, 1991). However, getting a
complete axiomatization is quite nontrivial. We refer the reader to (Halpern & Pucella,
2002) for more details on this subject. We remark that Wilson and Moral (1994) take as
their starting point Walleys notion of lower and upper previsions. They consider when
acceptance of one set of gambles implies acceptance of another gamble. Since acceptance
involves expectation, it cannot be expressed in the logic considered in this paper; however,
it can be expressed easiliy in the logic of (Halpern & Pucella, 2002).

Acknowledgments
A preliminary version of this paper appears in Uncertainty in Artificial Intelligence, Proceedings of the Seventeenth Conference, 2001. Thanks to Dexter Kozen, Jon Kleinberg, and
Hubie Chen for discussions concerning set covers. Vicky Weissman read a draft of this paper
and provided numerous helpful comments. We also thank the anonymous UAI and JAIR
reviewers for their useful comments and suggestions. This work was supported in part by
NSF under grants IRI-96-25901 and IIS-0090145, and ONR under grants N00014-00-1-03-

68

fiA Logic for Reasoning about Upper Probabilities

41, N00014-01-10-511, and N00014-01-1-0795. The first author was also supported in part
by a Guggenheim and a Fulbright Fellowship while on sabbatical leave; sabbatical support
from CWI and the Hebrew University of Jerusalem is also gratefully acknowledged.

Appendix A. Proofs
Proposition 2.1: Property (6) implies properties (1)-(5).
Proof: We introduce the following auxiliary properties to help derive the implications:
(7) P (A) + P (B)  P (A  B) + P  (A  B).
(8) P (A) + P (B)  P (A  B) + P  (A  B).
(9) P (A  B) + P (A  B)  P (A) + P  (B).
(10) If A  B = , then
P (A) + P (B)  P (A  B)  P (A) + P  (B)  P  (A  B)  P  (A) + P  (B).
Using these properties, we show the following chain of implications:

(6) = (10)

(10) = (9) = (3)
(10) = (7) = (4)
(10) = (8) = (5)

(4), (5) = (1), (2).

The implication (4), (5) = (1), (2) follows easily by mutual induction on n. The
base case is the following instances of properties (4) and (5): P (A  B)  P (A) + P (B) 
P  (A  B) and P  (A  B)  P  (A) + P  (B)  P (A  B). The details are left to the reader.
We now prove the remaining implications.
(9) = (3): Since (9) is already one of the inequalities in (3), it remains to show that
it implies the other inequality in (3), that is, P (A)+P  (B)  P  (AB)+P  (AB).
P  (A  B) + P  (A  B) = 1  P (A  B) + 1  P (A  B)
= 1  P (A  B) + 1  P (A  B)
= 2  (P (A  B) + P (A  B))
= 2  (P (B  A) + P (B  A))
 2  (P (B) + P  (A))
= 1  P (B) + 1  P  (A)
= P  (B) + P (A).

69

fiHalpern & Pucella

(7) = (4): Since (7) is already one of the inequalities in (4), it remains to show that
it implies the other inequality in (4), that is, P (AB)+P  (AB)  P  (A)+P  (B).
P  (A) + P  (B) = 1  P (A) + 1  P (B)
= 2  (P (A) + P (B))
 2  (P (A  B) + P  (A  B))
= 1  P (A  B) + 1  P  (A  B)
= 1  P (A  B) + 1  P  (A  B)
= P  (A  B) + P (A  B).
(8) = (5): Since (8) is already one of the inequalities in (5), it remains to show that
it implies the other inequality in (5), that is, P (AB)+P  (AB)  P  (A)+P  (B).
P  (A) + P  (B) = 1  P (A) + 1  P (B)
= 2  (P (A) + P (B))
 2  (P (A  B) + P  (A  B))
= 1  P (A  B) + 1  P  (A  B)
= 1  P (A  B) + 1  P  (A  B)
= P  (A  B) + P (A  B).
For the next implications, given A, B, let Z = A  B.
(10) = (9):
P (A  B) = P ((A  Z)  B)
 P (A  Z) + P  (B)

[since (A  Z)  B = ]

 P ((A  Z)  Z)  P (Z) + P  (B)
= P (A) + P  (B)  P (A  B).
(10) = (7):
P (A  B) = P ((A  Z)  B)
 P (A  Z) + P (B)
 P ((A  Z)  Z)  P  (Z) + P (B)
= P (A) + P (B)  P  (A  B).
(10) = (8):
P  (A  B) = P  ((A  Z)  B)
 P  (A  Z) + P (B)
 P ((A  Z)  Z)  P (Z) + P (B)
= P (A) + P (B)  P (A  B).
70

fiA Logic for Reasoning about Upper Probabilities

(6) = (10): Again, since (6) already comprises two of the inequalities in (10), it
remains to show that it implies the other two, that is, if A  B = , then
P (A) + P (B)  P (A  B)  P  (A) + P (B).
First, we show that P (A) + P (B)  P (A  B). Using (6), we know that
P  (A  B) + P (A)  P  ((A  B)  A) = P  (B).
In other words, P  (A  B)  P  (B) + P (A). From this, we derive that
P (A  B) = 1  P  (A  B)
= 1  P  (A  B)
 1  (P  (B)  P (A))
= 1  P  (B) + P (A)
= P (B) + P (A).
Second, we show that P (A  B)  P  (A) + P (B). Using (6), we know that
P  (A  B) + P  (A)  P  ((A  B)  A) = P  (B).
(The last equality follows from the fact that (A  B)  A = B when A  B = .) In
other words, P  (A  B)  P  (B)  P  (A). From this, we derive that
P (A  B) = 1  P  (A  B)
= 1  P  (A  B)
 1  (P  (B)  P  (A))
= 1  P  (B) + P  (A)
= P (B) + P  (A).
Proposition 2.2: For 0 <  < 18 , the function  satisfies property (6), but is not an
upper probability measure. That is, we cannot find a set P 0 of probability measures such
that  = (P 0 ) .
Proof: We are given 0 <  < 81 . It is easy to check mechanically that  satisfies (6).
We now show that there is no set P 0 such that  = (P 0 ) . By way of contradiction,
assume there is such a P 0 . By the properties of sup, this means that there is a   P 0 such
that ({a, b, c}) > 43 , since  ({a, b, c}) = 34 +  > 34 . Consider this  in detail. Since   P,
we must have for all X  , X 6= {a, b, c}, that (X)  (P 0 ) (X) = P  (X). In particular,
({a, b}), ({b, c}), ({a, c})  21 . Therefore,
3
({a, b}) + ({b, c}) + ({a, c})  .
2

(2)

However, from standard properties of probability, it follows that
({a, b}) + ({b, c}) + ({a, c}) = 2({a, b, c}) > 2 
71

3
3
= ,
4
2

fiHalpern & Pucella

which contradicts (2). Therefore, , and therefore P 0 cannot exist, and  is not an upper
probability measure.
Theorem 2.4: There exists constants B0 , B1 , . . . such that if  is an algebra of subsets
of  and  is a function  :   R, then there exists a set P of probability measures such
that  = P  if and only if  satisfies the following properties:
UPF1. () = 0,
UPF2. () = 1,
UPF3. for all integers m, n, k  B|| and all sets A1 , P
. . . , Am , if {{A1 , . . . , Am }}
is an (n, k)-cover of (A, ), then k + n(A)  m
i=1 (Ai ).
Proof: In view of Theorem 2.3, we need only show that there exist constant B0 , B1 , . . .
such that a function  satisfies UP3 iff it satisfies UPF3. Clearly, UP3 always implies
UPF3, so it is sufficient to show that there exists B0 , B1 , . . . such that UPF3 implies
UP3.
We need some terminology before proceeding. An exact (n, k)-cover of (A, ) is a cover
C of A with the property that every element of A appears in exactly n + k sets in C, and
every element of   A appears in exactly k sets in C. Thus, while an (n, k)-cover of (A, )
can have many extra sets, as long as the sets cover A at least n + k times and  k times,
an exact cover has only the necessary sets, with the right total number of elements. An
exact (n, k)-cover C of (A, ) is decomposable if there exists an exact (n1 , k1 )-cover C1 and
an exact (n2 , k2 )-cover C2 of (A, ) such that C1 and C2 form a nontrivial partition of C,
with n = n1 + n2 and k = k1 + k2 . Intuitively, an exact cover C is decomposable if it
can be split into two exact covers. It follows easily by induction that for any exact (n, k)cover, there exists a (not necessarily unique) finite set of nondecomposable exact covers
C1 , . . . , Cm
Pm(ni , ki )-cover, such that the Ci s a nontrivial partition of C
P, mwith Ci an exact
with n = i=1 ni and k = i=1 . (If C is itself nondecomposable, we can take m = 1 and
C1 = C.) One can easily verify that if C is an exact (n, k)-cover of (A, ) and C 0  C is
an exact (n0 , k 0 )-cover of (A, ) with n0 + k 0 < n + k, then C is decomposable.
The following lemma highlights the most important property of exact covers from our
perspective. It says that for any set A  , there cannot be a large nondecomposable
exact cover of (A, ).
Lemma A.1: There exists a sequence B10 , B20 , B30 , . . . such that for all A  , every exact
0
0
(n, k)-cover of (A, ) with n > B||
or k > B||
is decomposable.
Proof: It is clearly sufficient to show that for any finite  we can find a B|| with the
required properties. Fix a . Given A  , we first show that there exists NA such that
if n > NA or k > NA , every exact (n, k)-cover of (A, ) is decomposable. Suppose for the
sake of contradiction that this is not the case. This means that we can find an infinite
sequence C1 , C2 , . . . such that Ci is a nondecomposable exact (ni , ki )-cover of (A, ), with
either n1 < n2 < . . . or k1 < k2 < . . . .
To derive a contradiction, we use the following lemma, known as Dicksons Lemma
(Dickson, 1913).
72

fiA Logic for Reasoning about Upper Probabilities

Lemma A.2: Every infinite sequence of d-dimensional vectors over the natural
numbers contains a monotonically nondecreasing subsequence in the pointwise
ordering (where x  y in the pointwise ordering iff xi  yi for all i).
Proof: It is straightforward to prove by induction on k that if k  d, then
every infinite sequence of vectors x1 , x2 , . . . contains a subsequence xi1 , xi2 , . . .
such that xij1 , xij2 , . . . is a nondecreasing sequence of natural numbers for all
j  k. The base case is immediate from the observation that every infinite
sequence of natural numbers contains a nondecreasing subsequence. For the
inductive step, observe that if xi1 , xi2 , . . . is a subsequence such that xij1 , xij2 , . . .
is a nondecreasing sequence of natural numbers for all j  k, then the sequence
1
2
xik+1
, xik+1
, . . . of natural numbers must have a nondecreasing subsequence. This
determines a subsequence of the original sequence with the appropriate property
for all j  k + 1.
Let S1 , . . . , S2|| be an arbitrary ordering of the 2|| subsets of . We can associate
C
C
with any cover C a 2|| -dimensional vector xC = (xC
1 , . . . , x2|| ), where xi is the number
of times the subset Si of  appears in the multiset C. The key property of this association
0
is that if C 0 and C are multisets, then C 0  C iff xC  xC in the pointwise ordering.
Consider the sequence of vectors xC1 , xC2 , . . . associated with the sequence C1 , C2 , . . .
of nondecomposable exact covers of (A, ). By Lemma A.2, there is a nondecreasing subsequence of vectors, xCi1  xCi2     . But this means that Ci1  Ci2     . Since
n1 < n2 < . . . or k1 < k2 < . . . , every cover in the chain must be distinct. But any pair
of exact covers in the chain is such that Ci  Ci+1 , meaning Ci+1 is decomposable, contradicting our assumption. Therefore, there must exist an NA such that any exact (n, k)-cover
of A with n > NA or k > NA is decomposable.
0
= max{NA : A  {1, . . . , ||}}. It is easy to see that this choice
Now define B||
works.
0 , for N = 1, 2, . . . , where B 0 is as
To get the constants B1 , B2 , . . . , let BN = 2N BN
N
in Lemma A.1. We now show that UPF3 implies UP3 with this choice of B1 , B2 , . . . .
Assume that UPF3 holds. Fix . Suppose that C = {{A1 , .P
. . , Am }} is an (n, k)-cover
of (A, ) with |C| = m. We want to show that k + n(A)  m
i=1 (Ai ). We proceed as
follows.
The first step is to show that, without loss of generality, C is an exact (n, k)-cover of
(A, ). Let Bi consist of those states s  Ai such that either s  A and s appears in
more than n + k sets in A1 , . . . , Ai1 or s    A and s appears in more than k sets in
A1 , . . . , Ai1 . Let A0i = Ai  Bi . Let C 0 = {{A01 , . . . , A0m }}. It is easy to check that C 0 is
an exact (n, k)-cover of (A, ). For if s  A, then s appears in exactly n + k sets in C 0 (it
appears in A0j iff Aj is among the first n + k sets in C in which s appeared) and, similarly,
if s    A, then s appears in exactly k sets in C 0 . Clearly if UP3 holds for C 0 , then it
holds for C, since (A0i )  (Ai ) for i = 1, . . . , m. Thus, we can assume without loss of
generality that C is an exact (n, k)-cover of A.
We can also assume without loss of generality that no set in C is empty (otherwise,
we can simply remove the empty sets in C; the resulting set is still an (n, k)-cover of
(A, )). There are now two cases to consider. If max(m, n, k)  B|| , the desired result

73

fiHalpern & Pucella

follows from UPF3. If not, consider a decomposition of C into multisets C1 , . . . , Cp ,
where Ch is an exact (nh , kh )-cover of (A, ) and is not further decomposable. We claim
that max(|Ch |, nh , kh )  B|| for h = 1, . . . , p. If nh > B|| or kh > B|| , then it is
immediate from Lemma A.1 that Ch can be further decomposed, contradicting
the fact
P
that Ch is not decomposable. And if |Ch | > B|| , then observe that XCh |X|  |Ch |.
0 , there must be some s   which appears in at least 2B 0
Since |Ch | > B|| = 2||B||
||
0 or k > B 0 .
sets in Ch . Since Ch is an exact (nh , kh )-cover, it follows that either nh > B||
h
||
But then, by Lemma A.1, Ch is decomposable, again a contradiction.
Now we can apply UPF3 to each of C1 , . . . , Ck to get
X
(X)  nh (A)  kh .
XCh

Since the Ch s form a decomposition of C, we have


p
p
X
X
X


kh
(X)  nh (X) 
XCh

h=1





p
X
h=1



m
X

p
p
X
X
(Ai )  (
nh )(A) 
kh

i=1

Pp

h=1





X

XCh

(X) 

p
X

h=1

By decomposition, n = h=1 nh and k =
showing that UP3 holds, as desired.

nh (A) 

h=1

p
X

kh

h=1

h=1

Pp

h=1 kh ,

and therefore

Pm

i=1 (Ai )  n(A)

 k,

Proposition 4.1: The formula f is satisfiable in an upper probability structure iff the
inequality formula f has a solution. Moreover, if f has a solution, then f is satisfiable in
an upper probability structure with at most 2|f | worlds.
Proof: Assume first that f is satisfiable. Thus there is some upper probability structure
M = (, , P, ) such that M |= f . As in Section 4, let p1 , . . . , pN be the primitive propositions that appear in f , and let 1 , . . . , 22N be some canonical listing of the inequivalent
formulas over p1 , . . . , pN . Without loss of generality, we assume that 1 is equivalent to
true, and 22N is equivalent to false. Define the vector x by letting xi = P  ([[i ]]M ),
N
for 1  i  22 . Since M |= f , it is immediate that x is a solution to the inequality
2N

formula f . Moreover, since 1 = false and 2
= true, it follows that x1 = 0 (since
P  ([[false]]M ) = P  () = 0) and x2N = 1 (since P  ([[true]]M ) = P  () = 1). Final2
ly, consider a conjunct of f corresponding to an instance of L4; suppose it has the form
xi1 +    xW
Since this conjunct appears
in f, it must be the case that
im  nxim+1  k. V
W
V
(im+1  J{1,... ,m}, |J|=k+n J{1,... ,m}, jJ ij )  ( |J|=k jJ ij ) is a propositional tautology. Thus, it follows that [[i1 ]]M , . . . , [[im ]]M is an (n, k)-cover for ([[im+1 ]]M , [[true]]M ).
It follows from UP3 that
P  ([[i1 ]]M ) +    + P  ([[im ]]M )  nP  ([[]]M )  k.
74

fiA Logic for Reasoning about Upper Probabilities

Thus, x is a solution to the inequality formulas corresponding to L4. Hence, x is a solution
to f.
For the converse, assume that x is a solution to f. We construct an upper probability
structure M = (S, E, P, ) such that M |= f as follows. Let p1 , . . . , pN be the primitive
propositions appearing in f . Let S = {1 , . . . , 2N } be the atoms over p1 , . . . , pN . Let E be
the set of all subsets of S. As observed earlier, every propositional formula over p1 , . . . , pn
is equivalent to a unique disjunction of atoms. Thus, we can get a canonical collection
1 , . . . , 22N of inequivalent formulas over p1 , . . . , pn by identifying each formula i with a
different element of E, where 1 corresponds to the empty set and 22N corresponds to all
of S. Define a set function  by taking ({i1 , . . . , ij }) = xi if i is the disjunction of the
atoms i1 , . . . , ij . Let ()() = true iff   .
It is now sufficient to show that  is an upper probability (of a set P of probability
measures), since then it is clear that (S, E, P, ) |= f (since x is a solution to f, the system
of inequalities derived from formula f ). To do this, by Theorem 2.4, it suffices to verify
UPF1, UPF2, and UPF3, using B2N in UPF3, since |S| = 2N .
UPF1: () = x1 = 0.
UPF2: (S) = x2N = 1.
2

UPF3: Suppose that A and A1 , . . . , Am are in E and satisfy the premises of property UPF3, with k, m, n  B2N . Let i1 , . . . , im , im+1 be the canonical
to A1 , . . . , AmW, A, respectively. Clearly,
A 
V
S formulas corresponding
T
iff



A
i
i
i
m+1
j
J{1,...
J{1,... ,m}, |J|=k+n jJ
S ,m}, |J|=k+n TjJ j is a
propositional tautology and similarly   J{1,... ,m}, |J|=k jJ Aij iff
W
V
Pm
J{1,... ,m}, |J|=k jJ ij is a propositional tautology. Thus,
j=1 xij 

x
 k is one of the inequality formulas in f . Thus, it follows that
Pim+1
m


 k, as desired. By our definition of , we therefore have
j=1 xij  xiP
m+1
k + n(A)  m
i=1 (Ai ), and so UPF3 holds.
Theorem 5.1: Suppose f is a likelihood formula that is satisfied in some upper probability
structure. Then f is satisfied in a structure (, , P, ), where ||  |f |2 ,  = 2 (every
subset of  is measurable), |P|  |f |, (w) is a rational number such that ||(w)|| is
O(|f |2 ||f || + |f |2 log(|f |)) for every world w   and   P, and (w)(p) = false for every
world w   and every primitive proposition p not appearing in f .
Proof: The first step in the proof involves showing that if P is a set of probability measures
defined on an algebra  of a finite space , we can assume without loss of generality that
for each set X  , there is a probability measure X  P such that X (X) = P  (X)
(rather than P  (X) just being the sup of (X) for   P).
Lemma A.3: Let P be a set of probability measures defined on an algebra  over a finite set
. Then there exists a set P 0 of probability measures such that, for each X  , P  (X) =
(P 0 ) (X); moreover, there is a probability measure X  P 0 such that X (X) = P  (X). In
addition, for any interpretation , if M = (, , P, ) and M = (, , P 0 , ), then for all
likelihood formulas f , M |= f iff M 0 |= f .

75

fiHalpern & Pucella

Proof: Since  is finite, to show that P 0 exists, it clearly suffices to show that, for each
X  , there is a probability measure X such that X (X) = P  (X) and, if P 0 = P {X },
then P  (Y ) = (P 0 ) (Y ) for all Y  .
Given X, if there exists   P such that (X) = P  (X), then we are done. Otherwise,
we construct a sequence 1 , 2 , . . . of probability measures in P such that limi i (X) =
P  (X) and, for all Y  , the sequence i (Y ) converges to some limit. Let X1 , . . . , Xn
be an enumeration of the sets in , with X1 = X. We inductively construct a sequence of
measures m1 , m2 , . . . in P for m  n such that mi (Xj ) converges to a limit for i  k
and limi mi (X) = P  (X). For m = 1, we know there must be a sequence 11 , 12 , . . .
of measures in P such that 1i (X) converges to P  (X). For the inductive step, if m < n,
suppose we have constructed an appropriate sequence m1 , m2 , . . . . Consider the sequence
of real numbers mi (Xm+1 ). Using the Bolzano-Weierstrass theorem (Rudin, 1976) (which
says that every sequence of real numbers has a convergent subsequence), this sequence has
a convergent subsequence. Let (m+1)1 , (m+1)2 , . . . be the subsequence of m1 , m2 , . . .
which generates this convergent subsequence. This sequence of probability measures clearly
has all the required properties. This completes the inductive step.
Define X (Y ) = limi ni (Y ). It is easy to check that that X is indeed a probability
measure, that X (X) = P  (X), and if P 0 = P  {X }, that P  (Y ) = (P 0 ) (Y ) for all
Y  . This shows that an appropriate set P 0 exists.
Now, given , let M = (, , P, ) and M 0 = (, , P 0 , ). A straightforward induction
on the structure of f shows that M |= f iff M 0 |= f . For the base case:
(, , P, ) |= a1 l(1 ) +    + an l(n )  a
 a1 P  ([[1 ]]M ) +    + an P  ([[n ]]M )  a
 a1 (P 0 ) ([[1 ]]M 0 ) +    + an (P 0 ) ([[n ]]M 0 )  a
 (, , P 0 , ) |= a1 l(1 ) +    + an l(n )  a.
The others cases are trivial.
Just as in FHM, to prove Theorem 5.1, we make use of the following lemma which
can be derived from Cramers rule (Shores, 1999) and simple estimates on the size of the
determinant (see also (Chvatal, 1983) for a simpler variant):
Lemma A.4: If a system of r linear equalities and/or inequalities with integer coefficients
each of length at most l has a nonnegative solution, then it has a nonnegative solution with at
most r entries positive, and where the size of each member of the solution is O(rl +r log(r)).
Continuing with the proof of Theorem 5.1, suppose that f is satisfiable in an upper
probability structure. By Proposition 4.1, the system f of equality formulas has a solution,
so f is satisfied in a upper probability structure with a finite state space. Thus, by Lemma A.3, f is satisfied in a structure M = (, , P, ) such that for all X  , there exists
X  P such that X (X) = P  (X).
As in the completeness proof, we can write f in disjunctive normal form. Each disjunct
g is a conjunction of at most |f |  1 basic likelihood formulas and their negations. Since
M |= f , there must be some disjunct g such that M |= g. Suppose that g is the conjunction
of r basic likelihood formulas and s negations of basic likelihood formulas. Let p1 , . . . , pN
76

fiA Logic for Reasoning about Upper Probabilities

be the primitive formulas appearing in f . Let 1 , . . . , 2N be the atoms over p1 , . . . , pN .
As in the proof of completeness, we derive a system of equalities and inequalities from g.
It is a slightly more complicated system, however. Recall that each propositional formula
over p1 , . . . , pN is a disjunction of atoms. Let 1 , . . . , k be the propositional formulas that
appear in g. Notice that k < |f | (since there are some symbols in f , such as the coefficients,
that are not in the propositional formulas). The system of equations and inequalities we
construct involve variables xij , where i = 1, . . . , k and j = 1, . . . , 2N . Intuitively, xij
represents [[i ]]M ([[ j ]]M ), where [[i ]]M  P is such that [[i ]]M ([[i ]]M ) = P  ([[i ]]M ). Thus,
the system includes k < |f | equations of the following form,
xi1 +    + xi2N = 1,
for i = 1, . . . , k. Since [[i ]]M ([[i ]]M )  ([[i ]]M ) for all   P, if Ei is the subset of
W
{1, . . . , 2N } such that i = jEi j , the system includes k 2  k inequalities of the form
X
X
xij 
xi 0 j ,
jEi

i0

jEi

i0 .

for each pair i,
such that i 6=
For each conjunct in g of the form 1 l(1 ) +    +
n l(k )  , there is a corresponding inequalityP
where, roughly speaking, we replace l(i )
by [[i ]]M ([[]]M ).8 Since [[i ]]M corresponds to jEi xij , the appropriate inequality is
k
X

i

i=1

X

xij  .

jEi

Negations of such formulas correspond to a negated inequality formula; as before, this is
equivalent to a formula of the form
(

k
X
i=1

i

X

xij ) > .

jEi

Notice that there are at most |f | inequalities corresponding to the conjuncts of g. Thus,
altogether, there are at most k(k  1) + 2|f | < |f |2 equations and inequalities in the
system (since k < |f |). We know that the system has a nonnegative solution (taking
xij to be [[i ]]M ([[ j ]]M )). It follows from Lemma A.4 that the system has a solution
x = (x11 , . . . , x12N , . . . , xk1 , . . . , xk2N ) with t  |f |2 entries positive, and with each entry
of size O(|f |2 ||f || + |f |2 log(|f |)).
We use this solution to construct a small structure satisfying the formula f . Let I =
{i : xij is positive, for some j}; suppose that I = {i1 , . . . , it0 }, for some t0  t. Let
M = (S, E, P, ) where S has t0 states, say s1 , . . . , st0 , and E consists of all subsets of S. Let
(sh ) be the truth assignment corresponding to the formula ih , that is, (sh )(p) = true
if and only if ih  p (and where (sh )(p) = false if p does not appear in f ). Define
P = {j : 1  i  k}, where j (sh ) = xih j . It is clear from the construction that M |= f .
Since |P| = k < |f |, |S| = t0  t  |f |2 and j (sh ) = xih j , where, by construction, the size
of xih j is O(|f |2 ||f || + |f |2 log(|f |)), the theorem follows.
8. For simplicity here, we are implicitly assuming that each of the formulas i appears in each conjunct of
g. This is without loss of generality, since if i does not appear, we can put it in, taking i = 0.

77

fiHalpern & Pucella

Appendix B. Proof of the Characterization of Upper Probabilities
To make this paper self-contained, in this appendix we give a proof of Theorem 2.3. The
proof we give is essentially that of Anger and Lembcke (1985). Walley (1991) gives an
alternate proof along somewhat similar lines. Note that the functional g we define in our
proof corresponds to the construction in Walleys Natural Extension Theorem, which is
needed in his version of this result.
Theorem 2.3: Suppose that  is a set,  is an algebra of subsets of , and  :   R.
Then there exists a set P of probability measures with  = P  if and only if  satisfies the
following three properties:
UP1. () = 0,
UP2. () = 1,
UP3. for all integers m, n, k and all subsets A1 , . . . , A
Pm in , if {{A1 , . . . , Am }}
is an (n, k)-cover of (A, ), then k + n(A)  m
i=1 (Ai ).
Proof: The if direction of the characterization is straightforward. Given P = {i }iI a
set of probability measures, we show P  satisfies UP1-UP3.
UP1: P  () = sup{i ()} = sup{0} = 0
UP2: P  () = sup{i ()} = sup{1} = 1
S
T
UP3: GivenSA1 , . . . , Am and
T A such that A  J{1,... ,m},|J|=k+n jJ Aij and
  J{1,... ,m},|J|=k jJ Aij , then for any i we have ki () + ni (A) 
Pm
P
Pm
i (Aj ), that is kP+ ni (A)  m
j=1 i (Aj )  supi { j=1 i (Aj )} 
Pj=1
m
m
 (A ). But sup {k+n (A)} = k+n sup { (A)} =
j
i
i
i
i
j=1 supi {i (Aj )} =
j=1 P P
 (A ), as required.
k + nP  (A), so k + nP  (A)  m
P
j
j=1
As for the only if direction, we first prove a general lemma relating the problem to the
Hahn-Banach Theorem. Some general definitions are needed. Suppose that we are given a
space W and an algebra F of subsets of W . Let K be the vector space generated by the
indicator functions 1X defined by

0 if x 6 X
1X (x) =
1 if x  X,
for X  F. A sublinear functional on K is a mapping c : K  R such that c(h) = c(h)
for   0 and c(h1 + h2 )  c(h1 ) + c(h2 ) for all h1 , h2 . A sublinear functional is increasing
if h  0 implies c(h + h0 )  c(h0 ) for all h0  K. The following result is a formulation of the
well-known Hahn-Banach Theorem (see, for example, (Conway, 1990)).
Theorem (Hahn-Banach): Let K be a vector space over R, and let g be a sublinear
functional on K. If M is a linear subspace in K and  : M  R is a linear functional such
that (x)  g(x) for all x in M, then there is a linear functional 0 : K  R such that
0 |M =  and 0 (x)  g(x) for all x in K.
Lemma B.1: Let g : F  [0, 1] be such that g(W ) = 1 and suppose that there is an
increasing sublinear functional g on K such that
78

fiA Logic for Reasoning about Upper Probabilities

1. g(1K ) = g(K) for K  F;
2. g(h)  0 if h  0;
3. g(1)  1 (where g() is identified with g(1W )).
Then g is an upper probability measure.
Proof: We show that g is an upper probability by exhibiting a set {X : X  } of
probability measures, with the property that X (X) = g(X) and X (Y )  g(X) for Y 6= X.
Each probability measure X is constructed through an application of the Hahn-Banach
Theorem.
Given X  F, define the linear functional  on the subspace generated by 1X by
(1X ) = g(1X ). We claim that (h)  g(h) for all h in the subspace. Since the elements
of the subspace have the form 1X , there are two cases to consider:   0 and  < 0.
If   0, then (1X ) = g(1X ) = g(1X ), since g is sublinear. Moreover, 0 = g(0) =
g(1X + 1X )  g(1X ) + g(1X ), so g(1X )  g(1X ). Thus, if  > 0, then
(1X ) = g(1X )  g(1X ) = g(1X ).
Now, by the Hahn-Banach Theorem, we can extend  to a linear functional 0 on all of
K such that 0 (h)  g(h) for all h. We claim that (a) 0 (1Y )  0 for all Y  K and (b)
0 (1) = 1. For (a), note that 0 (1Y )  g(1Y )  0 by assumption, so 0 (1Y )  0. For
(b), note that 0 (1)  g(1) = g(W ) = 1 and that 0 (1) = 0 (1)  g(1)  1 (since
g(1)  1, by assumption).
Define X (Y ) = 0 (1Y ). Since 0 (1W ) = 1, X (W ) = 1. If Y and Y 0 are disjoint, it is
immediate from the linearity of  that X (Y  Y 0 ) = X (Y ) + X (Y 0 ). By construction,
X (Y )  g(1Y ) = g(Y ) for any Y 6= X, and X (X) = (1X ) = g(1X ) = g(X). Bottom
line: there is a probability measure X dominated by g such that X (X) = g(X).
Take P = {X : X  }. Since for any X we have that X (X) = g(X) and
X (Y )  g(X) (if Y 6= X), we have P  (X) = X (X) = g(X). Therefore, g = P  .
The main result follows by showing how to construct, from a function  satisfying the
properties of Theorem 2.3, a sublinear functional c on K with the required properties.
Suppose that g :   R is a function satisfying UP1-UP3. As we show in the discussion
after Theorem 2.3 in the text, UP1-UP3 show that the range of g is in fact [0, 1].PSince g
m
satisfies UP3, if {{K1 , . . . , Km }} is an (n, k)-cover
Pm of (K, ), we have k +ng(K)  i=1 Ki .
This is equivalent
to saying that k + n1K  Pi=1 1Ki . Hence, for all K1 , . . . , Km such that
P
m
k + n1K  m
1
i=1 Ki , we have k + ng(K) 
i=1 g(Ki ), or equivalently
m

k
1X
 +
g(Ki )  g(K).
n n

(3)

i=1

This observation motivates the following definition of the functional g : K  R 
{, }:
(
)
m
m
k
1X
k
1X
g(h) = inf  +
g(Ki ) : m, n, k  N, m, n > 0, K1 , . . . , Km  F,  +
1Ki  h .
n n
n n
i=1

i=1

Our goal now is to show that g satisfies the conditions of Lemma B.1.
79

fiHalpern & Pucella

 It is almost immediate from the definitions that g is increasing: if h  0 and  nk +
1 Pm
k
1 Pm
0
0
i=1 1Ki  h + h , then  n + n
i=1 1Ki  h .
n
 To see that g is sublinear, note that it is easy to see using the properties of inf that
g(h1 + h2 )  g(h1 ) + g(h2 ). To show that g(h) = g(h) for   0, first observe that
the definition of g is equivalent to
(
)
m
m
X
X
inf  +
i g(Ki ) : m  N, , i  R+ , K1 , . . . , Km  F   +
i 1Ki  h .
i=1

i=1

Consider first the case  > 0. Then
(
)
m
m
X
X
g(h) = inf  +
i g(Ki ) :   +
i 1Ki  h
i=1

= inf

(

 +

m
X
i=1

=  inf

(

i=1

)
m
1X

i 1Ki  h
i g(Ki ) :  +
 


1
 +
 

i=1

m
X
i=1

)
m

1X
i g(Ki ) :  +
i 1Ki  h
 
i=1

= g(h).
For  = 0, it is clear from the definition of g that g(1 )  g(). From (3) it follows
that g(1 )  g(), and hence g(0) = g(1 ) = g() = 0.
 It is immediate from the definition of g that g(1K )  g(K) for K  F; the fact that
g(1K ) = g(K) now follows from (3).
 It is immediate from the definition that g(1)  1.
 If h  0, then h  0; since g is increasing, g(h)  g(h + h) = g(0), and since g is
sublinear, g(0) = 0.
Since the conditions of Lemma B.1 are satisfied, g is an upper probability measure.

References
Anger, B., & Lembcke, J. (1985). Infinitely subadditive capacities as upper envelopes of
measures. Zeitschrift fur Wahrscheinlichkeitstheorie und Verwandte Gebiete, 68, 403
414.
Chvatal, V. (1983). Linear Programming. W. Freeman and Co., San Francisco, Calif.
Conway, J. B. (1990). A Course in Functional Analysis (Second edition). No. 96 in Graduate
Texts in Mathematics. Springer-Verlag.
Dempster, A. P. (1967). Upper and lower probabilities induced by a multivalued mapping.
Annals of Mathematical Statistics, 38 (2), 325339.

80

fiA Logic for Reasoning about Upper Probabilities

Dickson, L. E. (1913). Finiteness of the odd perfect and primitive abundant numbers with
n distinct prime factors. American Journal of Mathematics, 35 (4), 413422.
Fagin, R., & Halpern, J. Y. (1991). Uncertainty, belief and probability. Computational
Intelligence, 7 (3), 160173.
Fagin, R., Halpern, J. Y., & Megiddo, N. (1990). A logic for reasoning about probabilities.
Information and Computation, 87 (1,2), 78128.
Giles, R. (1982). Foundations for a theory of possibility. In Gupta, M. M., & Sanchez, E.
(Eds.), Fuzzy Information and Decision Processes, pp. 183195. North-Holland.
Halpern, J. Y. (2002). Reasoning about uncertainty. Book manuscript.
Halpern, J. Y., & Pucella, R. (2002). Reasoning about expectation. In Proc. Eighteenth
Conference on Uncertainty in Artificial Intelligence (UAI 2002).
Huber, P. J. (1976). Kapazitaten statt Wahrscheinlichkeiten? Gedanken zur Grundlegung
der Statistik. Jber. Deutsch. Math.-Verein, 78, 8192.
Huber, P. J. (1981). Robust Statistics. Wiley Interscience.
Kyburg, Jr., H. E. (1987). Bayesian and non-Bayesian evidential updating. Artificial Intelligence, 31, 271293.
Lorentz, G. G. (1952). Multiply subadditive functions. Canadian Journal of Mathematics,
4 (4), 455462.
Mendelson, E. (1964). Introduction to Mathematical Logic. Van Nostrand, New York.
Popkorn, S. (1994). First Steps in Modal Logic. Cambridge University Press, Cambridge;
New York.
Rudin, W. (1976). Principles of Mathematical Analysis (Third edition). McGraw-Hill.
Shafer, G. (1976). A Mathematical Theory of Evidence. Princeton University Press, Princeton, NJ.
Shores, T. (1999). Applied Linear Algebra and Matrix Analysis (Second edition). McGrawHill.
Smith, C. A. B. (1961). Consistency in statistical inference and decision. Journal of the
Royal Statistical Society, Series B, 23, 125.
Walley, P. (1981). Coherent lower (and upper) probabilities. Manuscript, Dept. of Statistics,
University of Warwick.
Walley, P. (1991). Statistical Reasoning with Imprecise Probabilities. Chapman and Hall.
Williams, P. M. (1976). Indeterminate probabilities. In Przelecki, M., Szaniawski, K., &
Wojciki, E. (Eds.), Formal Methods in the Methodology of Empirical Sciences, pp.
229246.
Wilson, N., & Moral, S. (1994). A logical view of probability. In Proc. 11th European
Conference on Artificial Intelligence (ECAI-94), pp. 7195.
Wolf, G. (1977). Obere und Untere Wahrscheinlichkeiten. Doctoral dissertation, Eidgenossischen Technischen Hochschule, Zurich. (Diss. ETH 5884).

81

fi