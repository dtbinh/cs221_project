Journal of Artificial Intelligence Research 17 (2002) 379-449

Submitted 4/02; published 12/02

Specific-to-General Learning for Temporal Events
with Application to Learning Event Definitions from Video
Alan Fern
Robert Givan
Jeffrey Mark Siskind

AFERN @ PURDUE . EDU
GIVAN @ PURDUE . EDU
QOBI @ PURDUE . EDU

School of Electrical and Computer Engineering
Purdue University, West Lafayette, IN 47907 USA

Abstract
We develop, analyze, and evaluate a novel, supervised, specific-to-general learner for a simple temporal logic and use the resulting algorithm to learn visual event definitions from video
sequences. First, we introduce a simple, propositional, temporal, event-description language called
AMA that is sufficiently expressive to represent many events yet sufficiently restrictive to support
learning. We then give algorithms, along with lower and upper complexity bounds, for the subsumption and generalization problems for AMA formulas. We present a positive-examplesonly
specific-to-general learning method based on these algorithms. We also present a polynomialtimecomputable syntactic subsumption test that implies semantic subsumption without being
equivalent to it. A generalization algorithm based on syntactic subsumption can be used in place of
semantic generalization to improve the asymptotic complexity of the resulting learning algorithm.
Finally, we apply this algorithm to the task of learning relational event definitions from video and
show that it yields definitions that are competitive with hand-coded ones.

1. Introduction
Humans conceptualize the world in terms of objects and events. This is reflected in the fact that
we talk about the world using nouns and verbs. We perceive events taking place between objects,
we interact with the world by performing events on objects, and we reason about the effects that
actual and hypothetical events performed by us and others have on objects. We also learn new
object and event types from novel experience. In this paper, we present and evaluate novel implemented techniques that allow a computer to learn new event types from examples. We show results
from an application of these techniques to learning new event types from automatically constructed
relational, force-dynamic descriptions of video sequences.
We wish the acquired knowledge of event types to support multiple modalities. Humans can
observe someone faxing a letter for the first time and quickly be able to recognize future occurrences
of faxing, perform faxing, and reason about faxing. It thus appears likely that humans use and
learn event representations that are sufficiently general to support fast and efficient use in multiple
modalities. A long-term goal of our research is to allow similar cross-modal learning and use of
event representations. We intend the same learned representations to be used for vision (as described
in this paper), planning (something that we are beginning to investigate), and robotics (something
left to the future).
A crucial requirement for event representations is that they capture the invariants of an event
type. Humans classify both picking up a cup off a table and picking up a dumbbell off the floor
as picking up. This suggests that human event representations are relational. We have an abstract

c 2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiF ERN , G IVAN , & S ISKIND

relational notion of picking up that is parameterized by the participant objects rather than distinct
propositional notions instantiated for specific objects. Humans also classify an event as picking
up no matter whether the hand is moving slowly or quickly, horizontally or vertically, leftward or
rightward, or along a straight path or circuitous one. It appears that it is not the characteristics of
participant-object motion that distinguish picking up from other event types. Rather, it is the fact
that the object being picked up changes from being supported by resting on its initial location to
being supported by being grasped by the agent. This suggests that the primitive relations used to
build event representations are force dynamic (Talmy, 1988).
Another desirable property of event representations is that they be perspicuous. Humans can
introspect and describe the defining characteristics of event types. Such introspection is what allows us to create dictionaries. To support such introspection, we prefer a representation language
that allows such characteristics to be explicitly manifest in event definitions and not emergent consequences of distributed parameters as in neural networks or hidden Markov models.
We develop a supervised learner for an event representation possessing these desired characteristics as follows. First, we present a simple, propositional, temporal logic called AMA that is a
sublanguage of a variety of familiar temporal languages (e.g. linear temporal logic, or LTL Bacchus & Kabanza, 2000, event logic Siskind, 2001). This logic is expressive enough to describe a
variety of interesting temporal events, but restrictive enough to support an effective learner, as we
demonstrate below. We proceed to develop a specific-to-general learner for the AMA logic by giving algorithms and complexity bounds for the subsumption and generalization problems involving
AMA formulas. While we show that semantic subsumption is intractable, we provide a weaker syntactic notion of subsumption that implies semantic subsumption but can be checked in polynomial
time. Our implemented learner is based upon this syntactic subsumption.
We next show means to adapt this (propositional) AMA learner to learn relational concepts.
We evaluate the resulting relational learner in a complete system for learning force-dynamic event
definitions from positive-only training examples given as real video sequences. This is not the first
system to perform visual-event recognition from video. We review prior work and compare it to
the current work later in the paper. In fact, two such prior systems have been built by one of the
authors. H OWARD (Siskind & Morris, 1996) learns to classify events from video using temporal,
relational representations. But these representations are not force dynamic. L EONARD (Siskind,
2001) classifies events from video using temporal, relational, force-dynamic representations but
does not learn these representations. It uses a library of hand-code representations. This work adds
a learning component to L EONARD , essentially duplicating the performance of the hand-coded
definitions automatically.
While we have demonstrated the utility of our learner in the visual-eventlearning domain, we
note that there are many domains where interesting concepts take the form of structured temporal sequences of events. In machine planning, macro-actions represent useful temporal patterns of
action. In computer security, typical application behavior, represented perhaps as temporal patterns of system calls, must be differentiated from compromised application behavior (and likewise
authorized-user behavior from intrusive behavior).
In what follows, Section 2 introduces our application domain of recognizing visual events and
provides an informal description of our system for learning event definitions from video. Section 3
introduces the AMA language, syntax and semantics, and several concepts needed in our analysis
of the language. Section 4 develops and analyzes algorithms for the subsumption and generalization
problems in the language, and introduces the more practical notion of syntactic subsumption. Sec380

fiL EARNING T EMPORAL E VENTS

tion 5 extends the basic propositional learner to handle relational data and negation, and to control
exponential run-time growth. Section 6 presents our results on visual-event learning. Sections 7
and 8 compare to related work and conclude.

2. System Overview
This section provides an overview of our system for learning to recognize visual events from video.
The aim is to provide an intuitive picture of our system before providing technical details. A formal
presentation of our event-description language, algorithms, and both theoretical and empirical results appears in Sections 36. We first introduce the application domain of visual-event recognition
and the L EONARD system, the event recognizer upon which our learner is built. Second, we describe
how our positive-only learner fits into the overall system. Third, we informally introduce the AMA
event-description language that is used by our learner. Finally, we give an informal presentation of
the learning algorithm.
2.1 Recognizing Visual Events
L EONARD (Siskind, 2001) is a system for recognizing visual events from video camera input
an example of a simple visual event is a hand picking up a block. This research was originally
motivated by the problem of adding a learning component to L EONARDallowing L EONARD to
learn to recognize an event by viewing example events of the same type. Below, we give a high-level
description of the L EONARD system.
L EONARD is a three-stage pipeline depicted in Figure 1. The raw input consists of a video-frame
image sequence depicting events. First, a segmentation-and-tracking component transforms this
input into a polygon movie: a sequence of frames, each frame being a set of convex polygons placed
around the tracked objects in the video. Figure 2a shows a partial video sequence of a pick up event
that is overlaid with the corresponding polygon movie. Next, a model-reconstruction component
transforms the polygon movie into a force-dynamic model. This model describes the changing
support, contact, and attachment relations between the tracked objects over time. Constructing
this model is a somewhat involved process as described in Siskind (2000). Figure 2b shows a
visual depiction of the force-dynamic model corresponding to the pick up event. Finally, an eventrecognition component armed with a library of event definitions determines which events occurred
in the model and, accordingly, in the video. Figure 2c shows the text output and input of the
event-recognizer for the pick up event. The first line corresponds to the output which indicates
the interval(s) during which a pick up occurred. The remaining lines are the text encoding of the
event-recognizer input (model-reconstruction output), indicating the time intervals in which various
force-dynamic relations are true in the video.
The event-recognition component of L EONARD represents event types with event-logic formulas like the following simplified example, representing x picking up y off of z .

4

P ICK U P (x; y; z ) = (S UPPORTS (z; y ) ^ C ONTACTS (z; y )); (S UPPORTS (x; y ) ^ ATTACHED (x; y ))

This formula asserts that an event of x picking up y off of z is defined as a sequence of two states
where z supports y by way of contact in the first state and x supports y by way of attachment in
the second state. S UPPORTS , C ONTACTS , and ATTACHED are primitive force-dynamic relations.
This formula is a specific example of the more general class of AMA formulas that we use in our
learning.
381

fiF ERN , G IVAN , & S ISKIND

image
sequence

Segmentation
and Tracking

polygonscene
sequence

Model
Reconstruction

training
models
event
labels

model
sequence

Event
Learner

Event
Classification

event
labels

learned event
definitions

Figure 1: The upper boxes represent the three primary components of L EONARDs pipeline. The
lower box depicts the event-learning component described in this paper. The input to the
learning component consists of training models of target events (e.g., movies of pick up
events) along with event labels (e.g., P ICK U P (hand; red; green)) and the output is an
event definition (e.g., a temporal logic formula defining P ICK U P (x; y; z )).
2.2 Adding a Learning Component
Prior to the work reported in this paper, the definitions in L EONARD s event-recognition library
were hand coded. Here, we add a learning component to L EONARD so that it can learn to recognize
events. Figure 1 shows how the event learner fits into the overall system. The input to the event
learner consists of force-dynamic models from the model-reconstruction stage, along with event
labels, and its output consists of event definitions which are used by the event recognizer. We take
a supervised-learning approach where the force-dynamic model-reconstruction process is applied
to training videos of a target event type. The resulting force-dynamic models along with labels
indicating the target event type are then given to the learner which induces a candidate definition of
the event type.
For example, the input to our learner might consist of two models corresponding to two videos,
one of a hand picking up a red block off of a green block with label P ICK U P (hand; red; green) and
one of a hand picking up a green block off of a red block with label P ICK U P (hand; green; red)the
output would be a candidate definition of P ICK U P (x; y; z ) that is applicable to previously unseen
pick up events. Note that our learning component is positive-only in the sense that when learning
a target event type it uses only positive training examples (where the target event occurs) and does
not use negative examples (where the target event does not occur). The positive-only setting is of
interest as it appears that humans are able to learn many event definitions given primarily or only
positive examples. From a practical standpoint, a positive-only learner removes the often difficult
task of collecting negative examples that are representative of what is not the event to be learned
(e.g., what is a typical non-pickup event?).
The construction of our learner involves two primary design choices. First, we must choose an
event representation language to serve as the learners hypothesis space (i.e., the space of event definitions it may output). Second, we must design an algorithm for selecting a good event definition
from the hypothesis space given a set of training examples of an event type.
2.3 The AMA Hypothesis Space
The full event logic supported by L EONARD is quite expressive, allowing the specification of a
wide variety of temporal patterns (formulas). To help support successful learning, we use a more
382

fiL EARNING T EMPORAL E VENTS

(a)

Frame 0

Frame 1

Frame 2

Frame 13

Frame 14

Frame 20

Frame 0

Frame 1

Frame 2

Frame 13

Frame 14

Frame 20

(b)

(PICK-UP HAND RED GREEN)@{[[0,1],[14,22])}

(c)

(SUPPORTED? RED)@{[[0:22])}
(SUPPORTED? HAND)@{[[1:13]), [[24:26])}
(SUPPORTS? RED HAND)@{[[1:13]), [[24:26])}
(SUPPORTS? HAND RED)@{[[13:22])}
(SUPPORTS? GREEN RED)@{[[0:14])}
(SUPPORTS? GREEN HAND)@{[[1:13])}
(CONTACTS? RED GREEN)@{[[0:2]), [[6:14])}
(ATTACHED? RED HAND)@{[[1:26])}
(ATTACHED? RED GREEN)@{[[1:6])}

Figure 2: L EONARD recognizes a pick up event. (a) Frames from the raw video input with the automatically generated polygon movie overlaid. (b) The same frames with a visual depiction
of the automatically generated force-dynamic properties. (c) The text input/output of the
event classifier corresponding to the depicted movie. The top line is the output and the
remaining lines make up the input that encodes the changing force-dynamic properties.
GREEN represents the block on the table and RED represents the block being picked up.

383

fiF ERN , G IVAN , & S ISKIND

restrictive subset of event logic, called AMA, as our learners hypothesis space. This subset excludes
many practically useless formulas that may confuse the learner, while still retaining substantial
expressiveness, thus allowing us to represent and learn many useful event types. Our restriction to
AMA formulas is a form of syntactic learning bias.
The most basic AMA formulas are called states which express constant properties of time intervals of arbitrary duration. For example, S UPPORTS (z; y ) ^ C ONTACTS (z; y ) is a state which tells us
that z must support and be in contact with y . In general, a state can be the conjunction of any number
of primitive propositions (in this case force-dynamic relations). Using AMA we can also describe
sequences of states. For example, (S UPPORTS (z; y ) ^ C ONTACTS (z; y )) ; (S UPPORTS (x; y ) ^
ATTACHED (x; y )) is a sequence of two states, with the first state as given above and the second
state indicating that x must support and be attached to y . This formula is true whenever the first
state is true for some time interval, followed immediately by the second state being true for some
time interval meeting the first time interval. Such sequences are called MA timelines since they
are the Meets of Ands. In general, MA timelines can contain any number of states. Finally, we can
conjoin MA timelines to get AMA formulas (Ands of MAs). For example, the AMA formula

[(S UPPORTS (z; y) ^ C ONTACTS (z; y)) ; (S UPPORTS (x; y) ^ ATTACHED (x; y))] ^
[(S UPPORTS (u; v) ^ ATTACHED (u; v)) ; (S UPPORTS (w; v) ^ C ONTACTS (w; v))]
defines an event where two MA timelines must be true simultaneously over the same time interval.
Using AMA formulas we can represent events by listing various property sequences (MA timelines),
all of which must occur in parallel as an event unfolds. It is important to note, however, that the
transitions between states of different timelines in an AMA formula can occur in any relation to one
another. For example, in the above AMA formula, the transition between the two states of the first
timeline can occur before, after, or exactly at the transition between states of the second timeline.
An important assumption leveraged by our learner is that the primitive propositions used to construct states describe liquid properties (Shoham, 1987). For our purposes, we say that a property is
liquid if when it holds over a time-interval it holds over all of its subintervals. The force-dynamic
properties produced by L EONARD are liquide.g., if a hand S UPPORTS a block over an interval
then clearly the hand supports the block over all subintervals. Because primitive propositions are
liquid, properties described by states (conjunctions of primitives) are also liquid. However, properties described by MA and AMA formulas are not, in general, liquid.
2.4 Specific-to-General Learning from Positive Data
Recall that the examples that we wish to classify and learn from are force-dynamic models, which
can be thought of (and are derived from) movies depicting temporal events. Also recall that our
learner outputs definitions from the AMA hypothesis space. Given an AMA formula, we say that
it covers an example model if it is true in that model. For a particular target event type (such as
P ICK U P ), the ultimate goal is for the learner to output an AMA formula that covers an example
model if and only if the model depicts an instance of the target event type. To understand our
learner, it is useful to define a generality relationship between AMA formulas. We say that AMA
formula 	1 is more general (less specific) than AMA formula 	2 if and only if 	2 covers every
example that 	1 covers (and possibly more).1
1. In our formal analysis, we will use two different notions of generality (semantic and syntactic). In this section, we
ignore such distinctions. We note, however, that the algorithm we informally describe later in this section is based on
the syntactic notion of generality.

384

fiL EARNING T EMPORAL E VENTS

If the only learning goal is to find an AMA formula that is consistent with a set of positiveonly training data, then one result can be the trivial solution of returning the formula that covers
all examples. Rather than fix this problem by adding negative training examples (which will rule
out the trivial solution), we instead change the learning goal to be that of finding the least-general
formula that covers all of the positive examples.2 This learning approach has been pursued for a
variety of different languages within the machine-learning literature, including clausal first-order
logic (Plotkin, 1971), definite clauses (Muggleton & Feng, 1992), and description logic (Cohen &
Hirsh, 1994). It is important to choose an appropriate hypothesis space as a bias for this learning
approach or the hypothesis returned may simply be (or resemble) one of two extremes, either the
disjunction of the training examples or the universal hypothesis that covers all examples. In our
experiments, we have found that, with enough training data, the least-general AMA formula often
converges usefully.
We take a standard specific-to-general machine-learning approach to finding the least-general
AMA formula that covers a set of positive examples. The approach relies on the computation of two
functions: the least-general covering formula (LGCF) of an example model and the least-general
generalization (LGG) of a set of AMA formulas. The LGCF of an example model is the least general
AMA formula that covers the example. Intuitively, the LGCF is the AMA formula that captures the
most information about the model. The LGG of any set of AMA formulas is the least-general AMA
formula that is more general than each formula in the set. Intuitively, the LGG of a formula set is
the AMA formula that captures the largest amount of common information among the formulas.
Viewed differently, the LGG of a formula set covers all of the examples covered by those formulas,
but covers as few other examples as possible (while remaining in AMA).3
The resulting specific-to-general learning approach proceeds as follows. First, use the LGCF
function to transform each positive training model into an AMA formula. Second, return the LGG
of the resulting formulas. The result represents the least-general AMA formula that covers all of
the positive training examples. Thus, to specify our learner, all that remains is to provide algorithms for computing the LGCF and LGG for the AMA language. Below we informally describe
our algorithms for computing these functions, which are formally derived and analyzed in Sections 3.4 and 4.
2.5 Computing the AMA LGCF
To increase the readability of our presentation, in what follows, we dispense with presenting examples where the primitive properties are meaningfully named force-dynamic relations. Rather, our
examples will utilize abstract propositions such as a and b. In our current application, these propositions correspond exclusively to force-dynamic properties, but may not for other applications. We
now demonstrate how our system computes the LGCF of an example model.
Consider the following example model: fa@[1; 4]; b@[3; 6]; c@[6; 6]; d@[1; 3]; d@[5; 6]g . Here,
we take each number (1, . . . , 6) to represent a time interval of arbitrary (possibly varying with the
number) duration during which nothing changes, and then each fact p@[i; j ] indicates that proposition p is continuously true throughout the time intervals numbered i through j . This model can
be depicted graphically, as shown in Figure 3. The top four lines in the figure indicate the time
2. This avoids the need for negative examples and corresponds to finding the specific boundary of the version space
(Mitchell, 1982).
3. The existence and uniqueness of the LGCF and LGG defined here is a formal property of the hypothesis space and is
proven for AMA in Sections 3.4 and 4, respectively.

385

fiF ERN , G IVAN , & S ISKIND

1

2

a

3

4

a

a

b

b

5

6

b

b
c

d
a^d

d

d

d

; a^b^d ; a^b ; b^d ; b^c^d

Figure 3: LGCF Computation. The top four horizontal lines of the figure indicate the intervals over which the propositions a; b; c and d are true in the model given by
fa@[1; 4]; b@[3; 6]; c@[6; 6]; d@[1; 3]; d@[5; 6]g . The bottom line shows how the model
can be divided into intervals where no transitions occur. The LGCF is an MA timeline,
shown at the bottom of the figure, with a state for each of the no-transition intervals. Each
state simply contains the true propositions within the corresponding interval.
intervals over which each of the propositions a; b; c, and d are true in the model. The bottom line
in the figure shows how the model can be divided into five time intervals where no propositions
change truth value. This division is possible because of the assumption that our propositions are
liquid. This allows us, for example, to break up the time-interval where a is true into three consecutive subintervals where a is true. After dividing the model into intervals with no transitions, we
compute the LGCF by simply treating each of those intervals as a state of an MA timeline, where
the states contain only those propositions that are true during the corresponding time interval. The
resulting five-state MA timeline is shown at the bottom of the figure. We show later that this simple
computation returns the LGCF for any model. Thus, we see that the LGCF of a model is always an
MA timeline.
2.6 Computing the AMA LGG
We now describe our algorithm for computing the LGG of two AMA formulasthe LGG of m
formulas can be computed via a sequence of m 1 pairwise LGG applications, as discussed later.
Consider the two MA timelines: 1 = (a ^ b ^ c); (b ^ c ^ d); e and 2 = (a ^ b ^ e); a; (e ^ d).
It is useful to consider the various ways in which both timelines can be true simultaneously along
an arbitrary time interval. To do this, we look at the various ways in which the two timelines
can be aligned along a time interval. Figure 4a shows one of the many possible alignments of
these timelines. We call such alignments interdigitationsin general, there are exponentially many
interdigitations, each one ordering the state transitions differently. Note that an interdigitation is
allowed to constrain two transitions from different timelines to occur simultaneously (though this is
not depicted in the figure).4
4. Thus, an interdigitation provides an ordering relation on transitions that need not be anti-symmetric, but is reflexive,
transitive, and total.

386

fiL EARNING T EMPORAL E VENTS

(a)

a^b^e
(b)

a^b^c

b^c^d

a

e^d

e

a^b^c a^b^c a^b^c b^c^d
a^b^e
a^b ;

a

e^d

e^d

a

; true ;

d

e
e^d
;

e

Figure 4: Generalizing the MA timelines (a ^ b ^ c); (b ^ c ^ d); e and (a ^ b ^ e); a; (e ^ d). (a)
One of the exponentially many interdigitations of the two timelines. (b) Computing the
interdigitation generalization corresponding to the interdigitation from part (a). States are
formed by intersecting aligned states from the two timelines. The state true represents a
state with no propositions.

Given an interdigitation of two timelines, it is easy to construct a new MA timeline that must be
true whenever either of the timelines is true (i.e., to construct a generalization of the two timelines).
In Figure 4b, we give this construction for the interdigitation given in Figure 4a. The top two
horizontal lines in the figure correspond to the interdigitation, only here we have divided every state
on either timeline into two identical states, whenever a transition occurs during that state in the other
timeline. The resulting pair of timelines have only simultaneous transitions and can be viewed as
a sequence of state pairs, one from each timeline. The bottom horizontal line is then labeled by
an MA timeline with one state for each such state pair, with that state being the intersection of the
proposition sets in the state pair. Here, true represents the empty set of propositions, and is a state
that is true anywhere.
We call the resulting timeline an interdigitation generalization (IG) of 1 and 2 . It should be
clear that this IG will be true whenever either 1 or 2 are true. In particular, if 1 holds along a
time-interval in a model, then there is a sequence of consecutive (meeting) subintervals where the
sequence of states in 1 are true. By construction, the IG can be aligned relative to 1 along the
interval so that when we view states as sets, the states in the IG are subsets of the corresponding
aligned state(s) in 1 . Thus, the IG states are all true in the model under the alignment, showing
that the IG is true in the model.
In general, there are exponentially many IGs of two input MA timelines, one for each possible
interdigitation between the two. Clearly, since each IG is a generalization of the input timelines,
then so is the conjunction of all the IGs. This conjunction is an AMA formula that generalizes the
input MA timelines. In fact, we show later in the paper that this AMA formula is the LGG of the
two timelines. Below we show the conjunction of all the IGs of 1 and 2 which serves as their
LGG.
387

fiF ERN , G IVAN , & S ISKIND

[(a ^ b); b; e; true; e] ^
[(a ^ b); b; true; e] ^
[(a ^ b); b; true; true; e] ^
[(a ^ b); b; true; e] ^
[(a ^ b); b; true; d; e] ^
[(a ^ b); true; true; e] ^
[(a ^ b); true; e] ^
[(a ^ b); true; d; e] ^
[(a ^ b); a; true; true; e] ^
[(a ^ b); a; true; e] ^
[(a ^ b); a; true; d; e] ^
[(a ^ b); a; d; e] ^
[(a ^ b); a; true; d; e]
While this formula is an LGG, it contains redundant timelines that can be pruned. First, it is
clear that different IGs can result in the same MA timelines, and we can remove all but one copy
of each timeline from the LGG. Second, note that if a timeline 0 is more general than a timeline
, then  ^ 0 is equivalent to thus, we can prune away timelines that are generalizations of
others. Later in the paper, we show how to efficiently test whether one timeline is more general
than another. After performing these pruning steps, we are left with only the first and next to last
timelines in the above formulathus, [(a ^ b); a; d; e] ^ [(a ^ b); b; e; true; e] is an LGG of 1 and
2 .
We have demonstrated how to compute the LGG of pairs of MA timelines. We can use this
procedure to compute the LGG of pairs of AMA formulas. Given two AMA formulas we compute
their LGG by simply conjoining the LGGs of all pairs of timelines (one from each AMA formula)
i.e., the formula
m^
n
^
LGG(i ; 0j )
i j

is an LGG of the two AMA formulas 1 ^    ^ m and 01 ^    ^ 0n , where the i and 0j are
MA timelines.
We have now informally described the LGCF and LGG operations needed to carry out the
specific-to-general learning approach described above. In what follows, we more formally develop
these operations and analyze the theoretical properties of the corresponding problems, then discuss
the needed extensions to bring these (exponential, propositional, and negation-free) operations to
practice.

3. Representing Events with AMA
Here we present a formal account of the AMA hypothesis space and an analytical development of the
algorithms needed for specific-to-general learning for AMA. Readers that are primarily interested in
a high-level view of the algorithms and their empirical evaluation may wish to skip Sections 3 and 4
and instead proceed directly to Sections 5 and 6, where we discuss several practical extensions to
the basic learner and then present our empirical evaluation.
We study a subset of an interval-based logic called event logic (Siskind, 2001) utilized by
L EONARD for event recognition in video sequences. This logic is interval-based in explicitly rep388

fiL EARNING T EMPORAL E VENTS

resenting each of the possible interval relationships given originally by Allen (1983) in his calculus
of interval relations (e.g., overlaps, meets, during). Event-logic formulas allow the definition
of event types which can specify static properties of intervals directly and dynamic properties by
hierarchically relating sub-intervals using the Allen relations. In this paper, the formal syntax and
semantics of full event logic are needed only for Proposition 4 and are given in Appendix A.
Here we restrict our attention to a much simpler subset of event logic we call AMA, defined
below. We believe that our choice of event logic rather than first-order logic, as well as our restriction
to the AMA fragment of event logic, provide a useful learning bias by ruling out a large number of
practically useless concepts while maintaining substantial expressive power. The practical utility
of this bias is demonstrated via our empirical results in the visual-eventrecognition application.
AMA can also be seen as a restriction of LTL (Bacchus & Kabanza, 2000) to conjunction and
Until, with similar motivations. Below we present the syntax and semantics of AMA along with
some of the key technical properties of AMA that will be used throughout this paper.
3.1 AMA Syntax and Semantics
It is natural to describe temporal events by specifying a sequence of properties that must hold over
consecutive time intervals. For example, a hand picking up a block might become the block
is not supported by the hand and then the block is supported by the hand. We represent such
sequences with MA timelines5 , which are sequences of conjunctive state restrictions. Intuitively, an
MA timeline is given by a sequence of propositional conjunctions, separated by semicolons, and is
taken to represent the set of events that temporally match the sequence of consecutive conjunctions.
An AMA formula is then the conjunction of a number of MA timelines, representing events that
can be simultaneously viewed as satisfying each of the conjoined timelines. Formally, the syntax of
AMA formulas is given by,
state
MA
AMA

::= true j prop j prop ^ state
::= (state) j (state); MA
// may omit parens
::= MA j MA ^ AMA

where prop is any primitive proposition (sometimes called a primitive event type). We take this
grammar to formally define the terms MA timeline, MA formula, AMA formula, and state. A k MA formula is an MA formula with at most k states, and a k -AMA formula is an AMA formula
all of whose MA timelines are k -MA timelines. We often treat states as proposition sets with
true the empty set and AMA formulas as MA-timeline sets. We may also treat MA formulas as
sets of statesit is important to note, however, that MA formulas may contain duplicate states,
and the duplication can be significant. For this reason, when treating MA timelines as sets, we
formally intend sets of state-index pairs (where the index gives a states position in the formula).
We do not indicate this explicitly to avoid encumbering our notation, but the implicit index must be
remembered whenever handling duplicate states.
The semantics of AMA formulas is defined in terms of temporal models. A temporal model
M = hM; I i over the set PROP of propositions is a pair of a mapping M from the natural numbers
(representing time) to the truth assignments over PROP, and a closed natural-number interval I .
We note that Siskind (2001) gives a continuous-time semantics for event logic where the models
5. MA stands for Meets/And, an MA timeline being the Meet of a sequence of conjunctively restricted intervals.

389

fiF ERN , G IVAN , & S ISKIND

are defined in terms of real-valued time intervals. The temporal models defined here use discrete
natural-number time-indices. However, our results here still apply under the continuous-time semantics. (That semantics bounds the number of state changes in the continuous timeline to a countable number.) It is important to note that the natural numbers in the domain of M are representing
time discretely, but that there is no prescribed unit of continuous time represented by each natural
number. Instead, each number represents an arbitrarily long period of continuous time during which
nothing changed. Similarly, the states in our MA timelines represent arbitrarily long periods of time
during which the conjunctive restriction given by the state holds. The satisfiability relation for AMA
formulas is given as follows:




A state s is satisfied by a model hM; I i iff M [x] assigns P true for every x 2 I and P



An AMA formula 1 ^ 2 ^    ^ n is satisfied by M iff each i is satisfied by M.

2 s.

An MA timeline s1 ; s2 ; : : : ; sn is satisfied by a model hM; [t; t0 ]i iff there exists some t00
in [t; t0 ] such that hM; [t; t00 ]i satisfies s1 and either hM; [t00 ; t0 ]i or hM; [t00 + 1; t0 ]i satisfies
s2 ; : : : ; sn .

The condition defining satisfaction for MA timelines may appear unintuitive at first due to the
fact that there are two ways that s2 ; : : : ; sn can be satisfied. The reason for this becomes clear by recalling that we are using the natural numbers to represent continuous time intervals. Intuitively, from
a continuous-time perspective, an MA timeline is satisfied if there are consecutive continuous-time
intervals satisfying the sequence of consecutive states of the MA timeline. The transition between
consecutive states si and si+1 can occur either within an interval of constant truth assignment (that
happens to satisfy both states) or exactly at the boundary of two time intervals of constant truth
value. In the above definition, these cases correspond to s2 ; : : : ; sn being satisfied during the time
intervals [t00 ; t0 ] and [t00 + 1; t0 ] respectively.
When M satisfies  we say that M is a model of  or that  covers M. We say that AMA 	1
subsumes AMA 	2 iff every model of 	2 is a model of 	1 , written 	2  	1 , and we say that 	1
properly subsumes 	2 , written 	2 < 	1 , when we also have 	1 6 	2 . Alternatively, we may state
	2  	1 by saying that 	1 is more general (or less specific) than 	2 or that 	1 covers 	2 . Siskind
(2001) provides a method to determine whether a given model satisfies a given AMA formula.
Finally, it will be useful to associate a distinguished MA timeline to a model. The MA projection
of a model M = hM; [i; j ]i written as MAP(M) is an MA timeline s0 ; s1 ; : : : ; sj i where state sk
gives the true propositions in M (i + k ) for 0  k  j i. Intuitively, the MA projection gives
the sequence of propositional truth assignments from the beginning to the end of the model. Later
we show that the MA projection of a model can be viewed as representing that model in a precise
sense.
The following two examples illustrate some basic behaviors of AMA formulas:
Example 1 (Stretchability). S1 ; S2 ; S3 , S1 ; S2 ; S2 ; : : : ; S2 ; S3 , and S1 ; S1 ; S1 ; S2 ; S3 ; S3 ; S3 are
all equivalent MA timelines. In general, MA timelines have the property that duplicating any state
results in a formula equivalent to the original formula. Recall that, given a model hM; I i, we
view each truth assignment M [x] as representing a continuous time-interval. This interval can
conceptually be divided into an arbitrary number of subintervals. Thus if state S is satisfied by
hM; [x; x]i, then so is the state sequence S ; S ; : : : ; S .
390

fiL EARNING T EMPORAL E VENTS

Example 2 (Infinite Descending Chains). Given propositions A and B , the MA timeline  =
is subsumed by each of the formulas A; B , A; B ; A; B , A; B ; A; B ; A; B , . . . . This is
intuitively clear when our semantics are viewed from a continuous-time perspective. Any interval
in which both A and B are true can be broken up into an arbitrary number of subintervals where
both A and B hold. This example illustrates that there can be infinite descending chains of AMA
formulas where the entire chain subsumes a given formula (but no member is equivalent to the given
formula). In general, any AMA formula involving only the propositions A and B will subsume .

(A ^ B )

3.2 Motivation for AMA
MA timelines are a very natural way to capture stretchable sequences of state constraints. But
why consider the conjunction of such sequences, i.e., AMA? We have several reasons for this language enrichment. First of all, we show below that the AMA least-general generalization (LGG)
is uniquethis is not true for MA. Second, and more informally, we argue that parallel conjunctive constraints can be important to learning efficiency. In particular, the space of MA formulas
of length k grows in size exponentially with k , making it difficult to induce long MA formulas.
However, finding several shorter MA timelines that each characterize part of a long sequence of
changes is exponentially easier. (At least, the space to search is exponentially smaller.) The AMA
conjunction of these timelines places these shorter constraints simultaneously and often captures a
great deal of the concept structure. For this reason, we analyze AMA as well as MA and, in our
empirical work, we consider k -AMA.
The AMA language is propositional. But our intended applications are relational, or first-order,
including visual-event recognition. Later in this paper, we show that the propositional AMA learning algorithms that we develop can be effectively applied in relational domains. Our approach to
first-order learning is distinctive in automatically constructing an object correspondence across examples (cf. Lavrac, Dzeroski, & Grobelnik, 1991; Roth & Yih, 2001). Similarly, though AMA
does not allow for negative state constraints, in Section 5.4 we discuss how to extend our results to
incorporate negation into our learning algorithms, which is crucial in visual-event recognition.
3.3 Conversion to First-Order Clauses
We note that AMA formulas can be translated in various ways into first-order clauses. It is not
straightforward, however, to then use existing clausal generalization techniques for learning. In
particular, to capture the AMA semantics in clauses, it appears necessary to define subsumption and
generalization relative to a background theory that restricts us to a continuous-time first-order
model space.
For example, consider the AMA formulas 1 = A ^ B and 2 = A; B where A and B are
propositionsfrom Example 2 we know that 1  2 . Now, consider a straightforward clausal
translation of these formulas giving C1 = A(I ) ^ B (I ) and C2 = A(I1 ) ^ B (I2 ) ^ M EETS (I1 ; I2 ) ^
I = S PAN (I1 ; I2 ), where the I and Ij are variables that represent time intervals, M EETS indicates
that two time intervals meet each other, and S PAN is a function that returns a time interval equal
to the union of its two time-interval arguments. The meaning we intend to capture is for satisfying
assignments of I in C1 and C2 to indicate intervals over which 1 and 2 are satisfied, respectively.
It should be clear that, contrary to what we want, C1 6 C2 (i.e., 6j= C1 ! C2 ), since it is easy to
find unintended first-order models that satisfy C1 , but not C2 . Thus such a translation, and other
similar translations, do not capture the continuous-time nature of the AMA semantics.
391

fiF ERN , G IVAN , & S ISKIND

In order to capture the AMA semantics in a clausal setting, one might define a first-order theory
that restricts us to continuous-time modelsfor example, allowing for the derivation if property B
holds over an interval, then that property also holds over all sub-intervals. Given such a theory ,
we have that  j= C1 ! C2 , as desired. However, it is well known that least-general generalizations relative to such background theories need not exist (Plotkin, 1971), so prior work on clausal
generalization does not simply subsume our results for the AMA language.
We note that for a particular training set, it may be possible to compile a continuous-time background theory  into a finite but adequate set of ground facts. Relative to such ground theories,
clausal LGGs are known to always exist and thus could be used for our application. However,
the only such compiling approaches that look promising to us require exploiting an analysis similar to the one given in this paperi.e., understanding the AMA generalization and subsumption
problem separately from clausal generalization and exploiting that understanding in compiling the
background theory. We have not pursued such compilations further.
Even if we are given such a compilation procedure, there are other problems with using existing clausal generalization techniques for learning AMA formulas. For the clausal translations of
AMA we have found, the resulting generalizations typically fall outside of the (clausal translations
of formulas in the) AMA language, so that the language bias of AMA is lost. In preliminary empirical work in our video-event recognition domain using clausal inductive-logic-programming (ILP)
systems, we found that the learner appeared to lack the necessary language bias to find effective
event definitions. While we believe that it would be possible to find ways to build this language bias
into ILP systems, we chose instead to define and learn within the desired language bias directly, by
defining the class of AMA formulas, and studying the generalization operation on that class.
3.4 Basic Concepts and Properties of AMA
We use the following convention in naming our results: propositions and theorems are the key
results of our work, with theorems being those results of the most technical difficulty, and lemmas
are technical results needed for the later proofs of propositions or theorems. We number all the
results in one sequence, regardless of type. Proofs of theorems and propositions are provided in the
main textomitted proofs of lemmas are provided in the appendix.
We give pseudo-code for our methods in a non-deterministic style. In a non-deterministic language functions can return more than one value non-deterministically, either because they contain
non-deterministic choice points, or because they call other non-deterministic functions. Since a nondeterministic function can return more than one possible value, depending on the choices made at
the choice points encountered, specifying such a function is a natural way to specify a richly structured set (if the function has no arguments) or relation (if the function has arguments). To actually
enumerate the values of the set (or the relation, once arguments are provided) one can simply use
a standard backtracking search over the different possible computations corresponding to different
choices at the choice points.
3.4.1 S UBSUMPTION

AND

G ENERALIZATION

FOR

S TATES

The most basic formulas we deal with are states (conjunctions of propositions). In our propositional
setting computing subsumption and generalization at the state level is straightforward. A state S1
subsumes S2 (S2  S1 ) iff S1 is a subset of S2 , viewing states as sets of propositions. From this, we
derive that the intersection of states is the least-general subsumer of those states and that the union
of states is likewise the most general subsumee.
392

fiL EARNING T EMPORAL E VENTS

3.4.2 I NTERDIGITATIONS
Given a set of MA timelines, we need to consider the different ways in which a model could simultaneously satisfy the timelines in the set. At the start of such a model (i.e., the first time point),
the initial state from each timeline must be satisfied. At some time point in the model, one or more
of the timelines can transition so that the second state in those timelines must be satisfied in place
of the initial state, while the initial state of the other timelines remains satisfied. After a sequence
of such transitions in subsets of the timelines, the final state of each timeline holds. Each way of
choosing the transition sequence constitutes a different interdigitation of the timelines.
Viewed differently, each model simultaneously satisfying the timelines induces a co-occurrence
relation on tuples of timeline states, one from each timeline, identifying which tuples co-occur at
some point in the model. We represent this concept formally as a set of tuples of co-occurring states,
i.e., a co-occurrence relation. We sometimes think of this set of tuples as ordered by the sequence
of transitions. Intuitively, the tuples in an interdigitation represent the maximal time intervals over
which no MA timeline has a transition, with those tuples giving the co-occurring states for each
such time interval.
A relation R on X1      Xn is simultaneously consistent with orderings 1 ,. . . ,n, if,
whenever R(x1 ; : : : ; xn ) and R(x01 ; : : : ; x0n ), either xi i x0i , for all i, or x0i i xi , for all i. We say
R is piecewise total if the projection of R onto each component is totali.e., every state in any Xi
appears in R.
Definition 1 (Interdigitation). An interdigitation I of a set f1 ; : : : ; n g of MA timelines is a cooccurrence relation over 1      n (viewing timelines as sets of states6 ) that is piecewise total
and simultaneously consistent with the state orderings of each i . We say that two states s 2 i
and s0 2 j for i 6= j co-occur in I iff some tuple of I contains both s and s0 . We sometimes refer to
I as a sequence of tuples, meaning the sequence lexicographically ordered by the i state orderings.
We note that there are exponentially many interdigitations of even two MA timelines (relative to the
total number of states in the timelines). Example 3 on page 396 shows an interdigitation of two MA
timelines. Pseudo-code for non-deterministically generating an arbitrary interdigitation for a set of
MA timelines can be found in Figure 5. Given an interdigitation I of the timelines s1 ; s2 ; : : : ; sm
and t1 ; t2 ; : : : ; tn (and possibly others), the following basic properties of interdigitations are easily
verifiable:
1. For i < j , if si and tk co-occur in I then for all k 0
2.

< k, sj does not co-occur with tk

0

in I .

I (s1 ; t1 ) and I (sm ; tn ).

We first use interdigitations to syntactically characterize subsumption between MA timelines.
Definition 2 (Witnessing Interdigitation). An interdigitation I of two MA timelines 1 and 2
is a witness to 1  2 iff for every pair of co-occurring states s1 2 1 and s2 2 2 , we have that
s2 is a subset of s1 (i.e., s1  s2 ).
The following lemma and proposition establish the equivalence between witnessing interdigitations
and MA subsumption.
6. Recall, that, formally, MA timelines are viewed as sets of state-index pairs, rather than just sets of states. We ignore
this distinction in our notation, for readability purposes, treating MA timelines as though no state is duplicated.

393

fiF ERN , G IVAN , & S ISKIND

1:

an-interdigitation (f1 ; 2 ; : : : ; n g)

// Input: MA timelines 1 ; : : : ; n
// Output: an interdigitation of f1 ; : : : ; n g

2:
3:

S0 := hhead(1 ); : : : ; head(n )i;
if for all 1  i  n; ji j = 1
then return hS0 i;
0
T := fi such that ji j > 1g;
T 00 := a-non-empty-subset-of (T 0 );

4:
5:
6:
7:
8:

for i := 1 to n
if i 2 T 00
then 0i := rest(i )
else 0i := i ;

9:
10:
12:
12:

return extend-tuple (S0 ; an-interdigitation (f01 ; : : : ; 0n g));

13:

Figure 5: Pseudo-code for an-interdigitation(), which non-deterministically computes an interdigitation for a set f1 ; : : : ; n g of MA timelines. The function head() returns the first
state in the timeline . rest() returns  with the first state removed. extend-tuple(x,I )
extends a tuple I by adding a new first element x to form a longer tuple. a-non-emptysubset-of(S ) non-deterministically returns an arbitrary non-empty subset of S .
Lemma 1. For any MA timeline  and any model M, if M satisfies , then there is a witnessing
interdigitation for MAP(M)  .
Proposition 2. For MA timelines 1 and 2 , 1

1  2 .

 2 iff there is an interdigitation that witnesses

Proof: We show the backward direction by induction on the number of states n in timeline 1 . If
n = 1, then the existence of a witnessing interdigitation for 1  2 implies that every state in 2
is a subset of the single state in 1 , and thus that any model of 1 is a model of 2 so that 1  2 .
Now, suppose for induction that the backward direction of the theorem holds whenever 1 has n
or fewer states. Given an arbitrary model M of an n + 1 state 1 and an interdigitation W that
witnesses 1  2 , we must show that M is also a model of 2 to conclude 1  2 as desired.
Write 1 as s1 ; : : : ; sn+1 and 2 as t1 ; : : : ; tm . As a witnessing interdigitation, W must identify
some maximal prefix t1 ; : : : ; tm of 2 made up of states that co-occur with s1 and thus that are
subsets of s1 . Since M = hM; [t; t0 ]i satisfies 1 , by definition there must exist a t00 2 [t; t0 ] such
that hM; [t; t00 ]i satisfies s1 (and thus t1 ; : : : ; tm ) and hM; I 0 i satisfies s2 ; : : : ; sn+1 for I 0 equal to
either [t00 ; t0 ] or [t00 + 1; t0 ]. In either case, it is straightforward to construct, from W , a witnessing
interdigitation for s2 ; : : : ; sn+1  tm +1 ; : : : ; tm and use the induction hypothesis to then show that
hM; I 0 i must satisfy tm +1; : : : ; tm . It follows that M satisfies 2 as desired.
For the forward direction, assume that 1  2 , and let M be any model such that 1 =
MAP(M). It is clear that such an M exists and satisfies 1 . It follows that M satisfies 2 .
Lemma 1 then implies that there is a witnessing interdigitation for MAP(M)  2 and thus for
1  2 . 2
0

0

0

0

394

fiL EARNING T EMPORAL E VENTS

3.4.3 L EAST-G ENERAL C OVERING F ORMULA
A logic can discriminate two models if it contains a formula that satisfies one but not the other. It
turns out that AMA formulas can discriminate two models exactly when much richer internal positive event logic (IPEL) formulas can do so. Internal formulas are those that define event occurrence
only in terms of properties within the defining interval. That is, satisfaction by hM; I i depends only
on the proposition truth values given by M inside the interval I . Positive formulas are those that
do not contain negation. Appendix A gives the full syntax and semantics of IPEL (which are used
only to state and prove Lemma 3 ). The fact that AMA can discriminate models as well as IPEL
indicates that our restriction to AMA formulas retains substantial expressive power and leads to
the following result which serves as the least-general covering formula (LGCF) component of our
specific-to-general learning procedure. Formally, an LGCF of model M within a formula language
L (e.g. AMA or IPEL) is a formula in L that covers M such that no other covering formula in
L is strictly less general. Intuitively, the LGCF of a model, if unique, is the most representative
formula of that model. Our analysis uses the concept of model embedding. We say that model M
embeds model M0 iff MAP(M)  MAP(M0 ).
Lemma 3.

For any E

2 IP EL, if model M embeds a model that satisfies E , then M satisfies E .

Proposition 4. The MA projection of a model is its LGCF for internal positive event logic (and
hence for AMA), up to semantic equivalence.
Proof: Consider model M. We know that MAP(M) covers M, so it remains to show that
MAP(M) is the least general formula to do so, up to semantic equivalence.
Let E be any IPEL formula that covers M. Let M0 be any model that is covered by MAP(M)
we want to show that E also covers M0 . We know, from Lemma 1, that there is a witnessing
interdigitation for MAP(M0 )  MAP(M). Thus, by Proposition 2, MAP(M0 )  MAP(M)
showing that M0 embeds M. Combining these facts with Lemma 3 it follows that E also covers
M0 and hence MAP(M)  E . 2
Proposition 4 tells us that, for IPEL, the LGCF of a model exists, is unique, and is an MA
timeline. Given this property, when an AMA formula 	 covers all the MA timelines covered by
another AMA formula 	0 , we have 	0  	. Thus, for the remainder of this paper, when considering
subsumption between formulas, we can abstract away from temporal models and deal instead with
MA timelines. Proposition 4 also tells us that we can compute the LGCF of a model by constructing
the MA projection of that model. Based on the definition of MA projection, it is straightforward to
derive an LGCF algorithm which runs in time polynomial in the size of the model7 . We note that
the MA projection may contain repeated states. In practice, we remove repeated states, since this
does not change the meaning of the resulting formula (as described in Example 1).
3.4.4 C OMBINING I NTERDIGITATION

WITH

G ENERALIZATION

OR

S PECIALIZATION

Interdigitations are useful in analyzing both conjunctions and disjunctions of MA timelines. When
conjoining a set of timelines, any model of the conjunction induces an interdigitation of the timelines
such that co-occurring states simultaneously hold in the model at some point (viewing states as
sets, the the states resulting from unioning co-occurring states must hold). By constructing an
7. We take the size of a model M = hM; I i to be the sum over x 2 I of the number of true propositions in M (x).

395

fiF ERN , G IVAN , & S ISKIND

interdigitation and taking the union of each tuple of co-occurring states to get a sequence of states,
we get an MA timeline that forces the conjunction of the timelines to hold. We call such a sequence
an interdigitation specialization of the timelines. Dually, an interdigitation generalization involving
intersections of states gives an MA timeline that holds whenever the disjunction of a set of timelines
holds.
Definition 3. An interdigitation generalization (specialization) of a set  of MA timelines is an MA
timeline s1 ; : : : ; sm , such that, for some interdigitation I of  with m tuples, sj is the intersection
(respectively, union) of the components of the jth tuple of the sequence I . The set of interdigitation
generalizations (respectively, specializations) of  is called IG() (respectively, IS()).
Example 3. Suppose that s1 ; s2 ; s3 ; t1 ; t2 ; and t3 are each sets of propositions (i.e., states). Consider the timelines S = s1 ; s2 ; s3 and T = t1 ; t2 ; t3 . The relation

f hs1; t1 i ; hs2; t1 i ; hs3; t2 i ; hs3; t3 i g
is an interdigitation of S and T in which states s1 and s2 co-occur with t1 , and s3 co-occurs with
t2 and t3 . The corresponding IG and IS members are

s1 \ t1 ; s2 \ t1 ; s3 \ t2 ; s3 \ t3
s1 [ t1 ; s2 [ t1 ; s3 [ t2 ; s3 [ t3

2 IG(fS; T g)
2 IS(fS; T g):

If t1  s1 ; t1  s2 ; t2  s3 ; and t3  s3 , then the interdigitation witnesses S

 T.

Each timeline in IG() (dually, IS()) subsumes (is subsumed by) each timeline in this is
easily verified using Proposition 2. For our complexity analyses, we note that the number of states
in any member of IG() or IS() is bounded from below by the number of states in any of the
MA timelines in  and is bounded from above by the total number of states in all the MA timelines
in . The number of interdigitations of , and thus of members of IG() or IS(), is exponential in that same total number of states. The algorithms that we present later for computing LGGs
require the computation of both IG () and IS(). Here we give pseudo-code to compute these
quantities. Figure 6 gives pseudo-code for the function an-IG-member that non-deterministically
computes an arbitrary member of IG() (an-IS-member is the same, except that we replace intersection by union). Given a set  of MA timelines we can compute IG() by executing all possible
deterministic computation paths of the function call an-IG-member(), i.e., computing the set of
results obtainable from the non-deterministic function for all possible decisions at non-deterministic
choice points.
We now give a useful lemma and a proposition concerning the relationships between conjunctions and disjunctions of MA concepts (the former being AMA concepts). For convenience here,
we use disjunction on MA concepts, producing formulas outside of AMA with the obvious interpretation.
Lemma 5. Given an MA formula  that subsumes each member of a set  of MA formulas,  also
subsumes some member 0 of IG(). Dually, when  is subsumed by each member of , we have
that  is also subsumed by some member 0 of IS(). In each case, the length of 0 is bounded by
the size of .

396

fiL EARNING T EMPORAL E VENTS

an-IG-member (f1 ; 2 ; : : : ; n g)

// Input: MA timelines 1 ; : : : ; n
// Output: a member of IG(f1 ; 2 ; : : : ; n g)

return map (intersect-tuple ; an-interdigitation (f1 ; : : : ; n g));
Figure 6: Pseudo-code for an-IG-member, which non-deterministically computes a member of
IG(T ) where T is a set of MA timelines. The function intersect-tuple(I ) takes a tuple I
of sets as its argument and returns their intersection. The higher-order function map(f; I )
takes a function f and a tuple I as arguments and returns a tuple of the same length as I
obtained by applying f to each element of I and making a tuple of the results.
Proposition 6.

The following hold:

1. (and-to-or) The conjunction of a set  of MA timelines equals the disjunction of the timelines
in IS().
2. (or-to-and) The disjunction of a set  of MA timelines is subsumed by the conjunction of the
timelines in IG().
Proof: To prove or-to-and, recall that, for any  2  and any 0 2 IG(), we have that   0 .
W
V
From this it is immediate that ( )  ( IG()). Using a dual argument, we can show that
W
V
V
W
( IS())  ( ). It remains Vto show that ( )  ( ISW()), which is equivalent to showing
that any timeline subsumed by ( ) is also subsumed by ( IS()) (by Proposition 4). Consider
V
any MA timeline  such that   ( )this implies that each member of  subsumes . Lemma
W
5 then implies that there is some 0 2 IS() such that   0 . From this we get that   ( IS())
as desired. 2
Using and-to-or, we can now reduce AMA subsumption to MA subsumption, with an exponential increase in the problem size.
Proposition 7.
	2 ; 1  2 .

For AMA

	1

and

	2 , 	1

 	2 if and only if for all 1 2 IS(	1) and 2 2

Proof: For the forward direction we show the contrapositive. Assume there is a 1 2 IS(	1 ) and a
2 2 	2 such that W1 6 2 . Thus, there is an MA timeline
 such that   1 but  6 2 . This
W
tells us that   ( IS(	1 )) and that  6 	2 , thus ( IS(	1 )) 6 	2 and by and-to-or we get
that 	1 6 	2 .
For the backward direction assume that for all 1 2 IS(	1 ) and 2 2 	2 that 1  2 . This
W
tells us that for each 1 2 IS(	1 ), that 1  	2 thus, 	1 = ( IS(	1 ))  	2 . 2

4. Subsumption and Generalization
In this section we study subsumption and generalization of AMA formulas. First, we give a
polynomial-time algorithm for deciding subsumption between MA formulas and then show that
deciding subsumption for AMA formulas is coNP-complete. Second we give algorithms and complexity bounds for the construction of least-general generalization (LGG) formulas based on our
397

fiF ERN , G IVAN , & S ISKIND

MA-subsumes (1 ; 2 )
// Input: 1 = s1 ; : : : ; sm and 2
// Output: 1  2

= t1 ; : : : ; tn

1. if there is a path from v1;1 to vm;n in SG(1 ; 2 ) then return TRUE. For example,
(a)
(b)

(c)

Create an array Reachable(i,j ) of boolean values, all FALSE, for 0
0  j  n.
for i := 1 to m, Reachable(i; 0) := TRUE;
for j := 1 to n, Reachable(0; j ) := TRUE;
for i := 1 to m
for j := 1 to n
Reachable(i; j ) := (ti  sj ^ ( Reachable(i
Reachable(i; j
Reachable(i

if Reachable(m; n) then return TRUE;

 i  m and

1; j ) _
1) _
1; j 1));

2. Otherwise, return FALSE;
Figure 7: Pseudo-code for the MA subsumption algorithm.
defined in the main text.

SG(1 ; 2 ) is the subsumption graph

analysis of subsumption, including existence, uniqueness, lower/upper bounds, and an algorithm for
the LGG on AMA formulas. Third, we introduce a polynomial-timecomputable syntactic notion
of subsumption and an algorithm that computes the corresponding syntactic LGG that is exponentially faster than our semantic LGG algorithm. Fourth, in Section 4.4, we give a detailed example
showing the steps performed by our LGG algorithms to compute the semantic and syntactic LGGs
of two AMA formulas.
4.1 Subsumption
All our methods rely critically on a novel algorithm for deciding the subsumption question 1  2
between MA formulas 1 and 2 in polynomial-time. We note that merely searching the possible
interdigitations of 1 and 2 for a witnessing interdigitation provides an obvious decision procedure
for the subsumption questionhowever, there are, in general, exponentially many such interdigitations. We reduce the MA subsumption problem to finding a path in a graph on pairs of states
in 1  2 , a polynomial-time operation. Pseudo-code for the resulting MA subsumption algorithm is shown in Figure 7. The main data structure used by the MA subsumption algorithm is the
subsumption graph.
Definition 4. The subsumption graph of two MA timelines 1 = s1 ;    ; sm and 2 = t1 ;    ; tn
(written SG(1 ; 2 )) is a directed
graph G = hV; E i with V = fvi;j j 1  i  m; 1  j  ng	.

The (directed) edge set E equals hvi;j ; vi ;j i j si  tj ; si  tj ; i  i0  i + 1; j  j 0  j + 1 .
0

0

0

0

To achieve a polynomial-time bound one can simply use any polynomial-time pathfinding algorithm. In our case the special structure of the subsumption graph can be exploited to determine if
398

fiL EARNING T EMPORAL E VENTS

the desired path exists in O (mn) time, as the example method shown in the pseudo-code illustrates.
The following theorem asserts the correctness of the algorithm assuming a correct polynomial-time
path-finding method is used.
Lemma 8. Given MA timelines 1 = s1 ; : : : ; sm and 2 = t1 ; : : : ; tn , there is a witnessing
interdigitation for 1  2 iff there is a path in the subsumption graph SG(1 ; 2 ) from v1;1 to
vm;n .
Theorem 9.
mial time.

Given MA timelines 1 and 2 , MA-subsumes(1 ; 2 ) decides 1

 2 in polyno-

Proof: The algorithm clearly runs in polynomial time. Lemma 8 tells us that line 2 of the algorithm
will return TRUE iff there is a witnessing interdigitation. Combining this with Proposition 2 shows
that the algorithm returns TRUE iff 1  2 . 2
Given this polynomial-time algorithm for MA subsumption, Proposition 7 immediately suggests
an exponential-time algorithm for deciding AMA subsumptionby computing MA subsumption
between the exponentially many IS timelines of one formula and the timelines of the other formula.
Our next theorem suggests that we cannot do any better than this in the worst casewe argue that
AMA subsumption is coNP-complete by reduction from boolean satisfiability. Readers uninterested
in the technical details of this argument may skip directly to Section 4.2.
To develop a correspondence between boolean satisfiability problems, which include negation,
and AMA formulas, which lack negation, we imagine that each boolean variable has two AMA
propositions, one for true and one for false. In particular, given a boolean satisfiability problem
over n variables p1 ; : : : ; pn , we take the set PROPn to be the set containing 2n AMA propositions
Truek and Falsek for each k between 1 and n. We can now represent a truth assignment A to the pi
variables with an AMA state sA given as follows:

sA = fTruei j 1  i  n; A(pi ) = trueg [ fFalsei j 1  i  n; A(pi ) = falseg
As Proposition 7 suggests, checking AMA subsumption critically involves the exponentially
many interdigitation specializations of the timelines of one of the AMA formulas. In our proof, we
design an AMA formula whose interdigitation specializations can be seen to correspond to truth
assignments8 to boolean variables, as shown in the following lemma.
Lemma 10.

Given some n, let 	 be the conjunction of the timelines
n
[
i=1

f(PROPn; Truei; Falsei; PROPn); (PROPn; Falsei; Truei; PROPn)g:

We have the following facts about truth assignments to the Boolean variables p1 ; : : : ; pn :
1. For any truth assignment A, PROPn ; sA ; PROPn is semantically equivalent to a member
of IS(	).
2. For each  2 IS(	) there is a truth assignment A such that   PROPn ; sA ; PROPn .
8. A truth assignment is a function mapping boolean variables to true or false.

399

fiF ERN , G IVAN , & S ISKIND

With this lemma in hand, we can now tackle the complexity of AMA subsumption.
Theorem 11.

Deciding AMA subsumption is coNP-complete.

Proof: We first show that deciding the AMA-subsumption of 	1 by 	2 is in coNP by providing
a polynomial-length certificate for any no answer. This certificate for non-subsumption is an
interdigitation of the timelines of 	1 that yields a member of IS(	1 ) not subsumed by 	2 . Such
a certificate can be checked in polynomial time: given such an interdigitation, the corresponding
member of IS(	1 ) can be computed in time polynomial in the size of 	1 , and we can then test
whether the resulting timeline is subsumed by each timeline in 	2 using the polynomial-time MAsubsumption algorithm. Proposition 7 guarantees that 	1 6 	2 iff there is a timeline in IS(	1 )
that is not subsumed by every timeline in 	2 , so that such a certificate will exist exactly when the
answer to a subsumption query is no.
To show coNP-hardness we reduce the problem of deciding the satisfiability of a 3-SAT formula
S = C1 ^  ^ Cm to the problem of recognizing non-subsumption between AMA formulas. Here,
each Ci is (li;1 _ li;2 _ li;3 ) and each li;j either a proposition p chosen from P = fp1 ; : : : ; pn g or
its negation :p. The idea of the reduction is to construct an AMA formula 	 for which we view
the exponentially many members of IS(	) as representing truth assignments. We then construct an
MA timeline  that we view as representing :S and show that S is satisfiable iff 	 6 .
Let 	 be as defined in Lemma 10. Let  be the formula s1 ; : : : ; sm , where

si =

fFalsej j li;k = pj for some kg [
fTruej j li;k = :pj for some kg:

Each si can be thought of as asserting not Ci . We start by showing that if S is satisfiable
then 	 6 . Assume that S is satisfied via a truth assignment Awe know from Lemma 10
that there is a 0 2 IS(	) that is semantically equivalent to PROPn ; sA ; PROPn . We show that
PROPn ; sA ; PROPn is not subsumed by , to conclude 	 6  using Proposition 7, as desired.
Suppose for contradiction that PROPn ; sA ; PROPn is subsumed by then the state sA must be
subsumed by some state si in . Consider the corresponding clause Ci of S . Since A satisfies S
we have that Ci is satisfied and at least one of its literals li;k must be true. Assume that li;k = pj (a
dual argument holds for li;k = :pj ), then we have that si contains Falsej while sA contains Truej
but not Falsej thus, we have that sA 6 si (since si 6 sA ), contradicting our choice of i.
To complete the proof, we now assume that S is unsatisfiable and show that 	  . Using
Proposition 7, we consider arbitrary 0 in IS(	)we will show that 0  . From Lemma 10 we
know there is some truth assignment A such that 0  PROPn ; sA ; PROPn . Since S is unsatisfiable
we know that some Ci is not satisfied by A and hence :Ci is satisfied by A. This implies that
each primitive proposition in si is in sA . Let W be the following interdigitation between T =
PROPn ; sA ; PROPn and  = s1 ; : : : ; sm :

fhPROPn; s1 i hPROPn; s2 i    hPROPn; sii hsA; sii hPROPn; sii hPROPn; si+1i    hPROPn; smig

We see that in each tuple of co-occurring states given above that the state from T is subsumed by
the state from . Thus W is a witnessing interdigitation to PROPn ; sA ; PROPn  , which then
holds by Proposition 2combining this with 0  PROPn ; sA ; PROPn we get that 0  . 2
Given this hardness result we later define a weaker polynomial-timecomputable subsumption
notion for use in our learning algorithms.
400

fiL EARNING T EMPORAL E VENTS

4.2 Least-General Generalization.
An AMA LGG of a set of AMA formulas is an AMA formula that is more general than each
formula in the set and not strictly more general than any other such formula. The existence of
an AMA LGG is nontrivial as there can be infinite chains of increasingly specific formulas all of
which generalize given formulas. Example 2 demonstrated such chains for an MA subsumee and
can be extended for AMA subsumees. For example, each member of the chain P ; Q, P ; Q; P ; Q,
P ; Q; P ; Q; P ; Q; : : : covers 	1 = (P ^ Q); Q and 	2 = P ; (P ^ Q). Despite such complications,
the AMA LGG does exist.
Theorem 12. There is an LGG for any finite set  of AMA formulas that is subsumed by all other
generalizations of .
Proof: Let be the set 	 2 IS(	0 ). Let 	 be the conjunction of all the MA timelines that
generalize while having size no larger than . Since there are only a finite number of primitive
propositions, there are only a finite number of such timelines, so 	 is well defined9 . We show that
	 is a least-general generalization of . First, note that each timeline in 	 generalizes and thus
 (by Proposition 6), so 	 must generalize . Now, consider arbitrary generalization 	0 of .
Proposition 7 implies that 	0 must generalize each formula in . Lemma 5 then implies that each
timeline of 	0 must subsume a timeline  that is no longer than the size of and that also subsumes
the timelines of . But then  must be a timeline of 	, by our choice of 	, so that every timeline of
	0 subsumes a timeline of 	. It follows that 	0 subsumes 	, and that 	 is an LGG of  subsumed
by all other LGGs of , as desired. 2
S

0

Given that the AMA LGG exists and is unique we now show how to compute it. Our first step is to
strengthen or-to-and from Proposition 6 to get an LGG for the MA sublanguage.
Theorem 13. For a set  of MA formulas, the conjunction of all MA timelines in IG() is an AMA
LGG of .
Proof: Let 	 be the specified conjunction. Since each timeline of IG() subsumes all timelines
in , 	 subsumes each member of . To show 	 is a least-general such formula, consider an
AMA formula 	0 that also subsumes all members of . Since each timeline of 	0 must subsume all
members of , Lemma 5 implies that each timeline of 	0 subsumes a member of IG() and thus
each timeline of 	0 subsumes 	. This implies 	  	0 . 2
We can now characterize the AMA LGG using IS and IG.
Theorem 14.

S

IG( 	2 IS(	)) is an AMA LGG of the set  of AMA formulas.

Proof: Let  = f	1 ; : : : ; 	n g and E = 	1 _    _ 	n . We know that the AMA LGG of 
must subsume E , or it would fail to subsume one of the 	i . Using and-to-or we can represent
W
W
E as a disjunction of MA timelines given by E = ( IS(	1 )) _    _ ( IS(	n )). Any AMA
LGG must be a least-general formula that subsumes E i.e., an AMA LGG of the set of MA
S
timelines fIS(	)j	 2 g. Theorem 13 tells us that an LGG of these timelines is given by
S
IG( fIS(	)j	 2 g). 2
9. There must be at least one such timeline, the timeline where the only state is true

401

fiF ERN , G IVAN , & S ISKIND

1:
2:
3:
4:
5:
6:
7:
8:
9:

10:
11:
12:
13:
14:

15:

semantic-LGG(f	1 ; 	2 ; : : : ; 	m g)

// Input: AMA formulas 	1 ; : : : ; 	m
// Output: LGG of f	1 ; : : : ; 	m g

S := fg;
for i := 1 to m
for each  in all-values(an-IS-member (	i ))
if (80 2 S :  6 0 )
then S 0 := f00 2 S j 00  g;
S := (S S 0 ) [ fg;
G := fg;
for each  in all-values(an-IG-member(S ))
if (80 2 G : 0 6 )
then G0 := f00 2 G j   00 g;
G := (G G0 ) [ fg;
V

return (

G)

Figure 8: Pseudo-code for computing the semantic AMA LGG of a set of AMA formulas.
Theorem 14 leads directly to an algorithm for computing the AMA LGGFigure 8 gives
pseudo-code for the computation. Lines 4-9 of the pseudo-code correspond to the computation
S
of fIS(	)j	 2 g, where timelines are not included in the set if they are subsumed by timelines
already in the set (which can be checked with the polynomial time MA subsumption algorithm).
This pruning, accomplished by the if test in line 7, often drastically reduces the size of the timeline set for which we perform the subsequent IG computationthe final result is not affected by
the pruning since the subsequent IG computation is a generalization step. The remainder of the
S
pseudo-code corresponds to the computation of IG( fIS(	)j	 2 g) where we do not include
timelines in the final result that subsume some other timeline in the set. This pruning step (the if test
in line 12) is sound since when one timeline subsumes another, the conjunction of those timelines
is equivalent to the most specific one. Section 4.4.1 traces the computations of this algorithm for an
example LGG calculation.
Since the sizes of both IS() and IG() are exponential in the sizes of their inputs, the code in
Figure 8 is doubly exponential in the input size. We conjecture that we cannot do better than this,
but we have not yet proven a doubly exponential lower bound for the AMA case. When the input
formulas are MA timelines the algorithm takes singly exponential time, since IS(fg) =  when
 is in MA. We now prove an exponential lower bound when the input formulas are in MA. Again,
readers uninterested in the technical details of this proof can safely skip forward to Section 4.3.
For this argument, we take the available primitive propositions to be those in the set fpi;j j 1 
i  n; 1  j  ng, and consider the MA timelines
and

1 = s1; ; s2; ; : : : ; sn;
2 = s;1 ; s;2 ; : : : ; s;n ;
402

where

fiL EARNING T EMPORAL E VENTS

and

si; = pi;1 ^    ^ pi;n
s;j = p1;j ^    ^ pn;j :

We will show that any AMA LGG of 1 and 2 must contain an exponential number of timelines.
In particular, we will show that any AMA LGG is equivalent to the conjunction of a subset of
IG(f1 ; 2 g), and that certain timelines may not be omitted from such a subset.
Lemma 15. Any AMA LGG 	 of a set
timelines from IG() with j	0 j  j	j

 of MA timelines is equivalent to a conjunction 	0 of

Proof: Lemma 5 implies that any timeline  in 	 must subsume some timeline 0 2 IG(). But
then the conjunction 	0 of such 0 must be equivalent to 	, since it clearly covers  and is covered
by the LGG 	. Since 	0 was formed by taking one timeline from IG() for each timeline in 	,
we have j	0 j  j	j. 2 We can complete our argument then by showing that exponentially many
timelines in IG(f1 ; 2 g) cannot be omitted from such a conjunction while it remains an LGG.
Notice that for any i; j we have that si; \s;j = pi;j . This implies that any state in IG(f1 ; 2 g)
contains exactly one proposition, since each such state is formed by intersecting a state from 1 and
2 . Furthermore, the definition of interdigitation, applied here, implies the following two facts for
any timeline q1 ; q2 ; : : : ; qm in IG(f1 ; 2 g):
1. q1

= p1;1 and qm = pn;n.

2. For consecutive states qk
and not both i = i0 and j

= pi;j and qk+1 = pi ;j , i0 is either i or i + 1, j 0 is either j or j + 1,
= j0.
0

0

Together these facts imply that any timeline in IG(f1 ; 2 g) is a sequence of propositions starting
with p1;1 and ending with pn;n such that any consecutive propositions pi;j ; pi ;j are different with
i0 equal to i or i + 1 and j 0 equal to j or j + 1. We call a timeline in IG(f1 ; 2 g) square if
and only if each pair of consecutive propositions pi;j and pi ;j have either i0 = i or j 0 = j . The
following lemma implies that no square timeline can be omitted from the conjunction of timelines
in IG(1 ; 2 ) if it is to remain an LGG of 1 and 2 .
0

0

0

0

Lemma 16. Let 1 and 2 be as given above and let 	 = IG(f1 ; 2 g). For any
timelines are a subset of those in 	 that omits some square timeline, we have 	 < 	0 .
V

	0 whose

n 2)! and hence is exponenThe number of square timelines in IG(f1 ; 2 g) is equal to (n (21)!(
n 1)!
tial in the size of 1 and 2 . We have now completed the proof of the following result.

Theorem 17.

The smallest LGG of two MA formulas can be exponentially large.

Proof: By Lemma 15, any AMA LGG 	0 of 1 and 2 is equivalent to a conjunction of the same
number of timelines chosen from IG(f1 ; 2 g). However, by Lemma 16, any such conjunction
n 2)! timelines, and then so must 	0 , which must then be exponentially
must have at least (n (21)!(
n 1)!
large. 2
Conjecture 18.

The smallest LGG of two AMA formulas can be doubly-exponentially large.
403

fiF ERN , G IVAN , & S ISKIND

We now show that our lower-bound on AMA LGG complexity is not merely a consequence of
the existence of large AMA LGGs. Even when there is a small LGG, it can be expensive to compute
due to the difficulty of testing AMA subsumption:
Theorem 19. Determining whether a formula 	 is an AMA LGG for two given AMA formulas 	1
and 	2 is co-NP-hard, and is in co-NEXP, in the size of all three formulas together.
Proof: To show co-NP-hardness we use a straightforward reduction from AMA subsumption. Given
two AMA formulas 	1 and 	2 we decide 	1  	2 by asking whether 	2 is an AMA LGG of 	1
and 	2 . Clearly 	1  	2 iff 	2 is an LGG of the two formulas.
To show the co-NEXP upper bound, note that we can check in exponential time whether 	1  	
and 	2  	 using Proposition 7 and the polynomial-time MA subsumption algorithm. It remains
to show that we can check whether 	 is not the least subsumer. Since Theorem 14 shows that the
LGG of 	1 and 	2 is IG(IS(	1 ) [ IS(	2 )), if 	 is not the LGG then 	 6 IG(IS(	1 ) [ IS(	2 )).
Thus, by Proposition 7, if 	 is not a least subsumer, there must be timelines 1 2 IS(	) and
2 2 IG(IS(	1 ) [ IS(	2 )) such that 1 6 2 . We can then use exponentially long certificates
for No answers: each certificate is a pair of an interdigitation I1 of 	 and an interdigitation I2 of
IS(	1 ) [ IS(	2 ), such that the corresponding members 1 2 IS(	) and 2 2 IG(IS(	1 ) [ IS(	2 ))
have 1 6 2 . Given the pair of certificates I1 and I2 , 1 can be computed in polynomial time,
2 can be computed in exponential time, and the subsumption between them can be checked in
polynomial time (relative to their size, which can be exponential). If 	 is the LGG then 	 
IG(IS(	1 ) [ IS(	2 )), so that no such certificates will exist. 2
4.3 Syntactic Subsumption and Syntactic Least-General Generalization.
Given the intractability results for semantic AMA subsumption, we now introduce a tractable generality notion, syntactic subsumption, and discuss the corresponding LGG problem. The use of
syntactic forms of generality for efficiency is familiar in ILP (Muggleton & De Raedt, 1994)
where, for example,  -subsumption is often used in place of the entailment generality relation.
Unlike AMA semantic subsumption, syntactic subsumption requires checking only polynomially
many MA subsumptions, each in polynomial time (via Theorem 9).
Definition 5. AMA 	1 is syntactically subsumed by AMA 	2 (written 	1
timeline 2 2 	2 , there is an MA timeline 1 2 	1 such that 1  2 .

syn 	2) iff for each MA

Proposition 20. AMA syntactic subsumption can be decided in polynomial time.
Syntactic subsumption trivially implies semantic subsumptionhowever, the converse does not
hold in general. Consider the AMA formulas (A; B ) ^ (B ; A), and A; B ; A where A and B are
primitive propositions. We have (A; B ) ^ (B ; A)  A; B ; A; however, we have neither A; B 
A; B ; A nor B ; A  A; B ; A, so that A; B ; A does not syntactically subsume (A; B ) ^ (B ; A).
Syntactic subsumption fails to recognize constraints that are only derived from the interaction of
timelines within a formula.
Syntactic Least-General Generalization. A syntactic AMA LGG is a syntactically least-general
AMA formula that syntactically subsumes the input AMA formulas. Here, least means that no
404

fiL EARNING T EMPORAL E VENTS

formula properly syntactically subsumed by a syntactic LGG can syntactically subsume the input
formulas. Based on the hardness gap between syntactic and semantic AMA subsumption, one might
conjecture that a similar gap exists between the syntactic and semantic LGG problems. Proving such
a gap exists requires closing the gap between the lower and upper bounds on AMA LGG shown in
Theorem 14 in favor of the upper bound, as suggested by Conjecture 18. While we cannot yet
show a hardness gap between semantic and syntactic LGG, we do give a syntactic LGG algorithm
that is exponentially more efficient than the best semantic LGG algorithm we have found (that of
Theorem 14). First, we show that syntactic LGGs exist and are unique up to mutual syntactic
subsumption (and hence up to semantic equivalence).
Theorem 21. There exists a syntactic LGG for any AMA formula set  that is syntactically subsumed by all syntactic generalizations of .
Proof: Let 	 be the conjunction of all the MA timelines that syntactically generalize  while
having size no larger than . As in the proof of Theorem 12, 	 is well defined. We show that
	 is a syntactic LGG for . First, note that 	 syntactically generalizes  because each timeline
of 	 generalizes a timeline in every member of , by the choice of 	. Now consider an arbitrary
syntactic generalization 	0 of . By the definition of syntactic subsumption, each timeline  in
	0 must subsume some timeline ff in each member ff of . Lemma 5 then implies that there is a
timeline 0 of size no larger than  that subsumes all the ff while being subsumed by . By our
choice of 	, the timeline 0 must be a timeline of 	. It follows then that 	0 syntactically subsumes
	, and that 	 is a syntactic LGG of  subsumed by all other syntactic generalizations of . 2
In general, we know that semantic and syntactic LGGs are different, though clearly the syntactic
LGG is a semantic generalization and so must subsume the semantic LGG. For example, (A; B ) ^
(B ; A), and A; B ; A have a semantic LGG of A; B ; A, as discussed above; but their syntactic LGG
is (A; B ; true) ^ (true; B ; A), which subsumes A; B ; A but is not subsumed by A; B ; A. Even
so, for MA formulas:
Proposition 22.

For MA  and AMA 	,  syn

	 is equivalent to   	.

Proof: The forward direction is immediate since we already know syntactic subsumption implies
semantic subsumption. For the reverse direction, note that   	 implies that each timeline of 	
subsumes thus since  is a single timeline each timeline in 	 subsumes some timeline in 
which is the definition of syntactic subsumption. 2
Proposition 23.

Any syntactic AMA LGG for an MA formula set  is also a semantic LGG for .

Proof: Now, consider a syntactic LGG 	 for . Proposition 22 implies that 	 is a semantic
generalization of . Consider any semantic LGG 	0 of . We show that 	  	0 to conclude that 	
is a semantic LGG for . Proposition 22 implies that 	0 syntactically subsumes . It follows that
	0 ^ 	 syntactically subsumes . But, 	0 ^ 	 is syntactically subsumed by 	, which is a syntactic
LGG of it follows that 	0 ^ 	 syntactically subsumes 	, or 	 would not be a least syntactic
generalization of . But then 	  (	0 ^ 	), which implies 	  	0 , as desired. 2
We note that the stronger result stating that a formula 	 is a syntactic LGG of a set  of MA formulas if and only if it is a semantic LGG of  is not an immediate consequence of our results above. At
405

fiF ERN , G IVAN , & S ISKIND

first examination, the strengthening appears trivial, given the equivalence of   	 and  syn 	
for MA . However, being semantically least is not necessarily a stronger condition than being syntactically leastwe have not ruled out the possibility that a semantically least generalization 	 may
syntactically subsume another generalization that is semantically (but not syntactically) equivalent.
(This question is open, as we have not found an example of this phenomenon either.)
Proposition 23 together with Theorem 21 have the nice consequence for our learning approach
that the syntactic LGG of two AMA formulas is a semantic LGG of those formulas, as long as the
original formulas are themselves syntactic LGGs of sets of MA timelines. Because our learning approach starts with training examples that are converted to MA timelines using the LGCF operation,
the syntactic LGGs computed (whether combining all the training examples at once, or incrementally computing syntactic LGGs of parts of the training data) are always syntactic LGGs of sets of
MA timelines and hence are also semantic LGGs, in spite of the fact that syntactic subsumption is
weaker than semantic subsumption. We note, however, that the resulting semantic LGGs may be
considerably larger than the smallest semantic LGG (which may not be a syntactic LGG at all).
Using Proposition 23, we now show that we cannot hope for a polynomial-time syntactic LGG
algorithm.
Theorem 24.

The smallest syntactic LGG of two MA formulas can be exponentially large.

Proof: Suppose there is always a syntactic LGG of two MA formulas that is not exponentially large.
Since by Proposition 23 each such formula is also a semantic LGG, there is always a semantic LGG
of two MA formulas that is not exponentially large. This contradicts Theorem 17. 2
While this is discouraging, we have an algorithm for the syntactic LGG whose time complexity
matches this lower-bound, unlike the semantic LGG case, where the best algorithm we have is
doubly exponential in the worst case. Theorem 14 yields an exponential time method for computing
the semantic LGG of a set of MA timelines since for a timeline , IS() = , we can simply
conjoin all the timelines of IG(). Given a set of AMA formulas, the syntactic LGG algorithm uses
this method to compute the polynomially-many semantic LGGs of sets of timelines, one chosen
from each input formula, and conjoins all the results.
Theorem 25.
	1 ; : : : ; 	n .

The formula

 2	 IG(f1 ; : : : ; n g) is a syntactic LGG of the AMA formulas

V

i

i

Proof: Let 	 be i 2	i IG(f1 ; : : : ; n g). Each timeline  of 	 must subsume each 	i because
 is an output of IG on a set containing a timeline of 	i thus 	 syntactically subsumes each 	i .
To show that 	 is a syntactically least such formula, consider a 	0 that syntactically subsumes every
	i . We show that 	 syn 	0 to conclude. Each timeline 0 in 	0 subsumes a timeline Ti 2 	i ,
for each i, by our assumption that 	i syn 	0 . But then by Lemma 5, 0 must subsume a member
of IG(fT1 ; : : : ; Tn g)and that member is a timeline of 	so each timeline 0 of 	0 subsumes a
timeline of 	. We conclude 	 syn 	0 , as desired. 2
V

This theorem yields an algorithm that computes a syntactic AMA LGG in exponential time
pseudo-code for this method is given in Figure 9. The exponential time bound follows from the fact
that there are exponentially many ways to choose 1 ; : : : ; m in line 5, and for each of these there
are exponentially many semantic-LGG members in line 6 (since the i are all MA timelines)the
product of these two exponentials is still an exponential.
406

fiL EARNING T EMPORAL E VENTS

1:
2:
3:
4:
5:
6:

syntactic-LGG(f	1 ; 	2 ; : : : ; 	m g)

// Input: AMA formulas f	1 ; : : : ; 	m g
// Output: syntactic LGG of f	1 ; : : : ; 	m g

G := fg;

for each h1 ; : : : ; m i 2 	1      	m

for each  in semantic-LGG(f1 ; : : : ; m g)

7:
8:
9:
10:

V

return (

if (80 2 G : 0 6 )
then G0 := f00 2 G j   00 g;
G := (G G0 ) [ fg;

G)

Figure 9: Pseudo-code that computes the syntactic AMA LGG of a set of AMA formulas.
The formula returned by the algorithm shown is actually a subset of the syntactic LGG given
by Theorem 25. This subset is syntactically (and hence semantically) equivalent to the formula
specified by the theorem, but is possibly smaller due to the pruning achieved by the if statement in
lines 79. A timeline is pruned from the set if it is (semantically) subsumed by any other timeline in
the set (one timeline is kept from any semantically equivalent group of timelines, at random). This
pruning of timelines is sound, since a timeline is pruned from the output only if it subsumes some
other formula in the outputthis fact allows an easy argument that the pruned formula is syntactically equivalent to (i.e. mutually syntactically subsumed by) the unpruned formula. Section 4.4.2
traces the computations of this algorithm for an example LGG calculation. We note that in our empirical evaluation discussed in Section 6, there was no cost in terms of accuracy for using the more
efficient syntactic vs. semantic LGG. We know this because our learned definitions made errors in
the direction of being overly specificthus, since the semantic-LGG is at least as specific as the
syntactic-LGG there would be no advantage to using the semantic algorithm.
The method does an exponential amount of work even if the result is small (typically because
many timelines can be pruned from the output because they subsume what remains). It is still an
open question as to whether there is an output-efficient algorithm for computing the syntactic AMA
LGGthis problem is in coNP and we conjecture that it is coNP-complete. One route to settling
this question is to determine the output complexity of semantic LGG for MA input formulas. We
believe that problem also to be coNP-complete, but have not proven this; if that problem is in P,
there is an output-efficient method for computing syntactic AMA LGG based on Theorem 25.
A summary of the algorithmic complexity results from this section can be found in Table 3 in
the conclusions section of this paper.
4.4 Examples: Least-General Generalization Calculations
Below we work through the details of a semantic and a syntactic LGG calculation. We consider the
AMA formulas 	 = (A; B ) ^ (B ; A) and  = A; B ; A, for which the semantic LGG is A; B ; A
and the syntactic LGG is (A; B ; true) ^ (true; B ; A).

407

fiF ERN , G IVAN , & S ISKIND

4.4.1 S EMANTIC LGG E XAMPLE
The first step in calculating the semantic LGG, according to the algorithm given in Figure 8, is to
compute the interdigitation-specializations of the input formulas (i.e., IS() and IS(	)). Trivially,
we have that IS() =  = A; B ; A. To calculate IS(	), we must consider the possible interdigitations of 	, for which there are three,

f hA; B i ; hB; B i ; hB; Ai g
f hA; B i ; hB; Ai g
f hA; B i ; hA; Ai ; hB; Ai g
Each interdigitation leads to the corresponding member of IS(	) by unioning (conjoining) the states
in each tuple, so IS(	) is

f (A ^ B ); B ; (A ^ B );
(A ^ B );
(A ^ B ); A; (A ^ B ) g:
Lines 59 of the semantic LGG algorithm compute the set S , which is equal to the union of the
timelines in IS(	) and IS(), with all subsumed timelines removed. For our formulas, we see that
each timeline in IS(	) is subsumed by thus, we have that S =  = A; B ; A.
After computing S , the algorithm returns the conjunction of timelines in IG(S ), with redundant
timelines removed (i.e., all subsuming timelines are removed). In our case, IG(S ) = A; B ; A,
trivially, as there is only one timeline in S , thus the algorithm correctly computes the semantic LGG
of 	 and  to be A; B ; A.
4.4.2 S YNTACTIC LGG E XAMPLE
The syntactic LGG algorithm, shown in Figure 9, computes a series of semantic LGGs for MA
timeline sets, returning the conjunction of the results (after pruning). Line 5 of the algorithm, cycles
through timeline tuples from the cross-product of the input AMA formulas. In our case the tuples
in   	 are T1 = hA; B ; A; A; B i and T2 = hA; B ; A; B ; Aifor each tuple, the algorithm
computes the semantic LGG of the tuples timelines.
The semantic LGG computation for each tuple uses the algorithm given in Figure 8, but the
argument is always a set of MA timelines rather than AMA formulas. For this reason, lines 4
9 are superfluous, as for an MA timeline 0 , IS(0 ) = 0 . In the case of tuple T1 , lines 49
of the algorithm just compute S = fA; B ; A; A; B g. It remains to compute the interdigitationgeneralizations of S (i.e., IG(S )), returning the conjunction of those timelines after pruning (lines
1015 in Figure 8). The set of all interdigitations of S are,

f hA; Ai ; hB; Ai ; hB; B i ; hB; Ai g
f hA; Ai ; hB; B i ; hB; Ai g
f hA; Ai ; hA; B i ; hB; B i ; hB; Ai g
f hA; Ai ; hA; B i ; hB; Ai g
f hA; Ai ; hA; B i ; hA; Ai ; hB; Ai g
By intersecting states in interdigitation tuples we get IG(S ),

f A; true; B ; true; A; B ; true; A; true; B ; true; A; true; true; A; true; A; true g
408

fiL EARNING T EMPORAL E VENTS

Since the timeline A; B ; true is subsumed by all timelines in IG(S ), all other timelines will be
pruned. Thus the semantic LGG algorithm returns A; B ; true as the semantic LGG of the timelines
in T1 .
Next the syntactic LGG algorithm computes the semantic LGG of the timelines in T2 . Following
the same steps as for T1 , we find that the semantic LGG of the timelines in T2 is true; B ; A. Since
A; B ; true and true; B ; A do not subsume one another, the set G computed by lines 59 of the
syntactic LGG algorithm is equal to f A; B ; true; true; B ; A g. Thus, the algorithm computes the
syntactic LGG of  and 	 to be (A; B ; true) ^ (true; B ; A). Note that, in this case, the syntactic
LGG is more general than the semantic LGG.

5. Practical Extensions
We have implemented a specific-to-general AMA learning algorithm based on the LGCF and syntactic LGG algorithms presented earlier. This implementation includes four practical extensions.
The first extension aims at controlling the exponential complexity by limiting the length of the
timelines we consider. Second we describe an often more efficient LGG algorithm based on a
modified algorithm for computing pairwise LGGs. The third extension deals with applying our
propositional algorithm to relational data, as is necessary for the application domain of visual event
recognition. Fourth, we add negation into the AMA language and show how to compute the corresponding LGCFs and LGGs using our algorithms for AMA (without negation). Adding negation
into AMA turns out to be crucial to achieving good performance in our experiments. We end this
section with a review of the overall complexity of our implemented system.
5.1 k-AMA Least-General Generalization
We have already indicated that our syntactic AMA LGG algorithm takes exponential time relative
to the lengths of the timelines in the AMA input formulas. This motivates restricting the AMA
language to k -AMA in practice, where formulas contain timelines with no more than k states.
As k is increased the algorithm is able to output increasingly specific formulas at the cost of an
exponential increase in computational time. In the visual-eventrecognition experiments shown
later, as we increased k , the resulting formulas became overly specific before a computational bottleneck is reachedi.e., for that application the best values of k were practically computable and the
ability to limit k provided a useful language bias.
We use a k -cover operator in order to limit our syntactic LGG algorithm to k -AMA. A k -cover
of an AMA formula is a syntactically least general k -AMA formula that syntactically subsumes
the inputit is easy to show that a k -cover for a formula can be formed by conjoining all k -MA
timelines that syntactically subsume the formula (i.e., that subsume any timeline in the formula) .
Figure 10 gives pseudo-code for computing the k -cover of an AMA formula. It can be shown that
this algorithm correctly computes a k -cover for any input AMA formula. The algorithm calculates
the set of least general k -MA timelines that subsume each timeline in the inputthe resulting k -MA
formulas are conjoined and redundant timelines are pruned using a subsumption test. We note that
the k -cover of an AMA formula may itself be exponentially larger than that formula; however, in
practice, we have found k -covers not to exhibit undue size growth.
Given the k -cover algorithm we restrict our learner to k -AMA as follows: 1) Compute the
k-cover for each AMA input formula. 2) Compute the syntactic AMA LGG of the resulting kAMA formulas. 3) Return the k -cover of the resulting AMA formula. The primary bottleneck of
409

fiF ERN , G IVAN , & S ISKIND

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

12:
13:
14:
15:
17:
18:
19:
20:

V

k-cover(k; 1im i )
V
// Input: positive natural number k , AMA formula 1im i
V
// Output: k -cover of 1im i
G := fg;
for i := 1 to m

:= hP1 ; : : : ; Pn i in all-values(a-k-partition (k; i ))
T
T
 := ( P1 ); : : : ; ( Pn );
if (80 2 G : 0 6 )
then G0 := f00 2 G j   00 g;
G := (G G0 ) [ fg;
V
return ( G)
for each P

a-k-partition (k; s1 ; : : : ; sj )

// Input: positive natural number k , MA timeline s1 ; : : : ; sj
// Output: a tuple of  k sets of consecutive states that partitions s1 ; : : : ; sj

 k then return hfs1g; : : : ; fsj gi;
if k = 1 then return hfs1 ; : : : ; sj gi;
l := a-member-of(f1; 2; : : : ; j k + 1g);
P0 = fs1 ; : : : ; sl g;
if j

return extend-tuple (P0 ; a-k-partition (k

// pick next block size
// construct next block

1; sl+1 ; : : : ; sj ));

Figure 10: Pseudo-code for non-deterministically computing a k-cover of an AMA formula, along
with a non-deterministic helper function for selecting a  k block partition of the states
of a timeline.

the original syntactic LGG algorithm is computing the exponentially large set of interdigitationgeneralizationsthe k -limited algorithm limits this complexity as it only computes interdigitationgeneralizations involving k -MA timelines.
5.2 Incremental Pairwise LGG Computation
Our implemented learner computes the syntactic k-AMA LGG of AMA formula setshowever,
it does not directly use the algorithm describe above. Rather than compute the LGG of formula
sets via a single call to the above algorithm, it is typically more efficient to break the computation
into a sequence of pairwise LGG calculations. Below we describe this approach and the potential
efficiency gains.
It is straightforward to show that for both syntactic and semantic subsumption we have that
LGG(	1 ; : : : ; 	m ) = LGG(	1 ; LGG(	2 ; : : : ; 	m )) where the 	i are AMA formulas. Thus, by
recursively applying this transformation we can incrementally compute the LGG of m AMA formulas via a sequence of m 1 pairwise LGG calculations. Note that since the LGG operator is
410

fiL EARNING T EMPORAL E VENTS

commutative and associative the final result does not depend on the order in which we process the
formulas. We will refer to this incremental pairwise LGG strategy as the incremental approach and
to the strategy that makes a single call to the k-AMA LGG algorithm (passing in the entire formula
set) as the direct approach.
To simplify the discussion we will consider computing the LGG of an MA formula set the
argument can be extended easily to AMA formulas (and hence to k-AMA). Recall that the syntactic
LGG algorithm of Figure 9 computes LGG() by conjoining timelines in IG() that do not subsume any of the others, eliminating subsuming timelines in a form of pruning. The incremental
approach applies this pruning step after each pair of input formulas is processedin contrast, the
direct approach must compute the interdigitation-generalization of all the input formulas before any
pruning can happen. The resulting savings can be substantial, and typically more than compensates
for the extra effort spent checking for pruning (i.e. testing subsumption between timelines as the
incremental LGG is computed). A formal approach to describing these savings can be constructed
S
S
based on the observation that both 2IG(f1 ;2 g) IG(fg[ ) and 2LGG(1 ;2 ) IG(fg[ )
can be seen to compute the LGG of  [ f1 ; 2 g, but with the latter being possibly much cheaper
to compute due to pruning. That is, LGG(1 ; 2 ) typically contains a much smaller number of
timelines than IG(f1 ; 2 g).
Based on the above observations our implemented system uses the incremental approach to
compute the LGG of a formula set. We now describe an optimization used in our system to speedup
the computation of pairwise LGGs, compared to directly running the algorithm in Figure 9. Given a
pair of AMA formulas 	1 = 1;1 ^    ^ 1;m and 	2 = 2;1 ^    ^ 2;n , let 	 be their syntactic
LGG obtained by running the algorithm in Figure 9. The algorithm constructs 	 by computing
LGGs of all MA timeline pairs (i.e., LGG(1;i ; 2;j ) for all i and j ) and conjoining the results
while removing subsuming timelines. It turns out that we can often avoid computing many of these
MA LGGs. To see this consider the case when there exists i and j such that 1;i  2;j , we know
LGG(1;i ; 2;j ) = 2;j which tells us that that 2;j will be considered for inclusion into 	 (it may
be pruned). Furthermore we know that any other LGG involving 2;j will subsume 2;j and thus
will be pruned from 	. This shows that we need not compute any MA LGGs involving 2;j , rather
we need only to consider adding 2;j when constructing 	.
The above observation leads to a modified algorithm (used in our system) for computing the
syntactic LGG of a pair of AMA formulas. The new algorithm only computes LGGs between
non-subsuming timelines. Given AMA formulas 	1 and 	2 , the modified algorithm proceeds as
follows: 1) Compute the subsumer set S = f 2 	1 j 90 2 	2 s:t: 0  g [ f 2 	2 j 90 2
	1 s:t: 0  g. 2) Let AMA 	01 (	02 ) be the result of removing timelines from 	1 (	2 ) that are
in S . 3) Let 	0 be the syntactic LGG of 	01 and 	02 computed by running the algorithm in Figure 9
(if either 	0i is empty then 	0 will be empty). 4) Let S 0 be the conjunction of timelines in S that do
not subsume any timeline in 	0 . 5) Return 	 = 	0 ^ S 0 . This method avoids computing MA LGGs
involving subsuming timelines (an exponential operation) at the cost of performing polynomially
many MA subsumption tests (a polynomial operation). We have noticed a significant advantage to
using this procedure in our experiments. In particular, the advantage tends to grow as we process
more training examples. This is due to the fact that as we incrementally process training examples
the resulting formulas become more generalthus, these more general formulas are likely to have
more subsuming timelines. In the best case when 	1 syn 	2 (i.e., all timelines in 	2 are subsuming), we see that step 2 produces an empty formula and thus step 3 (the expensive step) performs no
workin this case we return the set S = 	2 as desired.
411

fiF ERN , G IVAN , & S ISKIND

5.3 Relational Data
L EONARD produces relational models that involve objects and (force dynamic) relations between
those objects. Thus event definitions include variables to allow generalization over objects. For
example, a definition for P ICK U P (x; y; z ) recognizes both P ICK U P (hand; block; table) as well as
P ICK U P (man; box; floor). Despite the fact that our k -AMA learning algorithm is propositional, we
are still able to use it to learn relational definitions.
We take a straightforward object-correspondence approach to relational learning. We view the
models output by L EONARD as containing relations applied to constants. Since we (currently)
support only supervised learning, we have a set of distinct training examples for each event type.
There is an implicit correspondence between the objects filling the same role across the different training models for a given type. For example, models showing P ICK U P (hand; block; table)
and P ICK U P (man; box; floor) have implicit correspondences given by hhand; mani, hblock; boxi,
and htable; floori. We outline two relational learning methods that differ in how much objectcorrespondence information they require as part of the training data.
5.3.1 C OMPLETE O BJECT C ORRESPONDENCE
This first approach assumes that a complete object correspondence is given, as input, along with
the training examples. Given such information, we can propositionalize the training models by
replacing corresponding objects with unique constants. The propositionalized models are then given
to our propositional k -AMA learning algorithm which returns a propositional k -AMA formula. We
then lift this propositional formula by replacing each constant with a distinct variable. Lavrac et al.
(1991) has taken a similar approach.
5.3.2 PARTIAL O BJECT C ORRESPONDENCE
The above approach assumes complete object-correspondence information. While it is sometimes
possible to provide all correspondences (for example, by color-coding objects that fill identical
roles when recording training movies), such information is not always available. When only a
partial object correspondence (or even none at all) is available, we can automatically complete the
correspondence and apply the above technique.
For the moment, assume that we have an evaluation function that takes two relational models
and a candidate object correspondence, as input, and yields an evaluation of correspondence quality. Given a set of training examples with missing object correspondences, we perform a greedy
search for the best set of object-correspondence completions over the models. Our method works
by storing a set P of propositionalized training examples (initially empty) and a set U of unpropositionalized training examples (initially the entire training set). For the first step, when P is empty, we
evaluate all pairs of examples from U , under all possible correspondences, select the pair that yields
the highest score, remove the examples involved in that pair from U , propositionalize them according to the best correspondence, and add them to P . For each subsequent step, we use the previously
computed values of all pairs of examples, one from U and one from P , under all possible correspondences. We then select the example from U and correspondence that yields the highest average
score relative to all models in P this example is removed from U , propositionalized according to
the winning correspondence, and added to P . For a fixed number of objects, the effort expended
here is polynomial in the size of the training set; however, if the number of objects b that appear in a
training example is allowed to grow, the number of correspondences that must be considered grows
412

fiL EARNING T EMPORAL E VENTS

as bb . For this reason, it is important that the events involved manipulate only a modest number of
objects.
Our evaluation function is based on the intuition that object roles for visual events (as well as
events from other domains) can often be inferred by considering the changes between the initial
and final moments of an event. Specifically, given two models and an object correspondence, we
first propositionalize the models according to the correspondence. Next, we compute ADD and
DELETE lists for each model. The ADD list is the set of propositions that are true at the final
moment but not the initial moment. The DELETE list is the set of propositions that are true at the
initial moment but not the final moment. These add and delete lists are motivated by STRIPS action
representations (Fikes & Nilsson, 1971). Given such ADDi and DELETEi lists for models 1 and 2,
the evaluation function returns the sum of the cardinalities of ADD1 \ ADD2 and DELETE1 \
DELETE2 . This heuristic measures the similarity between the ADD and DELETE lists of the two
models. The intuition behind this heuristic is similar to the intuition behind the STRIPS actiondescription languagei.e., that most of the differences between the initial and final moments of an
event occurrence are related to the target event, and that event effects can be described by ADD and
DELETE lists. We have found that this evaluation function works well in the visual-event domain.
Note, that when full object correspondences are given to the learner (rather than automatically
extracted by the learner), the training examples are interpreted as specifying that the target event
took place as well as which objects filled the various event roles (e.g., P ICK U P (a,b,c)). Rather,
when no object correspondences are provided the training examples are interpreted as specifying the
existence of a target event occurrence but do not specify which objects fill the roles (i.e., the training
example is labeled by P ICK U P rather than P ICK U P (a,b,c)). Accordingly, the rules learned when no
correspondences are provided only allow us to infer that a target event occurred and not which
objects filled the event roles. For example when object correspondences are manually provided the
learner might produce the rule,
"

4 (S UPPORTS (z; y) ^ C ONTACTS (z; y));
P ICK U P (x; y; z ) =
(S UPPORTS (x; y) ^ ATTACHED (x; y))

#

whereas a learner that automatically extracts the correspondences would instead produce the rule,
"

4 (S UPPORTS (z; y) ^ C ONTACTS (z; y));
P ICK U P =
(S UPPORTS (x; y) ^ ATTACHED (x; y))

#

Its worth noting, however, that upon producing the second rule the availability of a single training
example with correspondence information allows the learner to determine the roles of the variables,
upon which it can output the first rule. Thus, under the assumption that the learner can reliably
extract object correspondences, we need not label all training examples with correspondence information in order to obtain definitions that explicitly recognize object roles.
5.4 Negative Information
The AMA language does not allow negated propositions. Negation, however, is sometimes necessary to adequately define an event type. In this section, we consider the language AMA , which is a
superset of AMA, with the addition of negated propositions. We first give the syntax and semantics
of AMA , and extend AMA syntactic subsumption to AMA . Next, we describe our approach to
413

fiF ERN , G IVAN , & S ISKIND

learning AMA formulas using the above-presented algorithms for AMA. We show that our approach correctly computes the AMA LGCF and the syntactic AMA LGG. Finally, we discuss
an alternative, related approach to adding negation designed to reduce the overfitting that appears to
result from the full consideration of negated propositions.
AMA has the same syntax as AMA, only with a new grammar for building states with negated
propositions:
literal
state

::= true j prop j :3prop
::= literal j literal ^ state

where prop is any primitive proposition. The semantics of AMA
for state satisfaction.

are the same as for AMA except



A positive literal P (negative literal
true (false), for every x 2 I .10

:3P ) is satisfied by model hM; I i iff M [x] assigns P



A state l1 ^    ^ lm is satisfied by model hM; I i iff each literal li is satisfied by hM; I i.

Subsumption. An important difference between AMA and AMA is that Proposition 2, establishing the existence of witnessing interdigitations to MA subsumption, is no longer true for MA .
In other words, if we have two timelines 1 ; 2 2 AMA , such that 1  2 , there need not be an
interdigitation that witnesses 1  2 . To see this, consider the AMA timelines:

1 = (a ^ b ^ c); b; a; b; (a ^ b ^ :  c)
2 = b; a; c; a; b; a; :  c; a; b
We can then argue:
1. There is no interdigitation that witnesses 1  2 . To see this, first show that, in any such
witness, the second and fourth states of 1 (each just b) must interdigitate to align with
either the first and fifth, or the fifth and ninth states of 2 (also, each just b). But in either
of these cases, the third state of 1 will interdigitate with states of 2 that do not subsume it.
2. Even so, we still have that 1  2 . To see this, consider any model hM; I i that satisfies 1 .
There must be an interval [i1 ; i2 ] within I such that hM; [i1 ; i2 ]i satisfies the third state of 1 ,
that is the state a. We have two cases:
(a) The proposition c is true at some point in hM; [i1 ; i2 ]i. Then, one can verify that hM; I i
satisfies both 1 and 2 in the following alignment:

1
2

=
=

(a ^ b ^ c); b;
b;

a;
a; c; a;

b;
b;

(a ^ b ^ :  c)
a; :  c; a; b

10. We note that it is important that we use the notation :3P rather than just :P . In event-logic, the formula :P
is satisfied by a model whenever P is false as some instant in the model. Rather, event-logic interprets :3P as
indicating that P is never true in the model (as defined above). Notice that the first form of negation does not yield a
liquid propertyi.e., :P can be true along an interval but not necessarily during all subintervals. The second form of
negation, however, does yield a liquid property provided that P is liquid. This is important to our learning algorithms,
since they all assume states are built from liquid properties.

414

fiL EARNING T EMPORAL E VENTS

(b) The proposition c is false everywhere in hM; [i1 ; i2 ]i. Then, one can verify that hM; I i
satisfies both 1 and 2 in the following alignment:

1 =
(a ^ b ^ c);
2 =
b; a; c; a;
It follows that 1  2 .

b;
b;

a;
a; :  c; a;

b; (a ^ b ^ :  c)
b

In light of such examples, we conjecture that it is computationally hard to compute AMA
subsumption even between timelines. For this reason, we extend our definition of syntactic subsumption to AMA in a way that provides a clearly tractable subsumption test analogous to that
discussed above for AMA.
Definition 6. AMA 	1 is syntactically subsumed by AMA 	2 (written 	1 syn 	2 ) iff for
each timeline 2 2 	2 , there is a timeline 1 2 	1 such that there is a witnessing interdigitation
for 1  2 .
The difference between the definition here and the previous one for AMA is that here we only need
to test for witnessing interdigitations between timelines rather than subsumption between timelines.
For AMA formulas, we note that the new and old definition are equivalent (due to Proposition 2);
however, for AMA the new definition is weaker, and will result in more general LGG formulas. As
one might expect, AMA syntactic subsumption implies semantic subsumption and can be tested
in polynomial-time using the subsumption graph described in Lemma 8 to test for witnesses.
Learning. Rather than design new LGCF and LGG algorithms to directly handle AMA , we
instead compute these functions indirectly by applying our algorithms for AMA to a transformed
problem. Intuitively, we do this by adding new propositions to our models (i.e., the training examples) that represent the proposition negations. Assume that the training-example models are over the
set of propositions P = fp1 ; : : : ; pn g. We introduce a new set P = fp1 ; : : : ; pn g of propositions
and use these to construct new training models over P [ P by assigning true to pi at a time in a
model iff pi is false in the model at that time. After forming the new set of training models (each
with twice as many propositions as the original models) we compute the least general AMA formula
that covers the new models (by computing the AMA LGCFs and applying the syntactic AMA LGG
algorithm), resulting in an AMA formula 	 over the propositions P [ P . Finally we replace each pi
in 	 with :3pi resulting in an AMA formula 	0 over propositions in P it turns out that under
syntactic subsumption 	0 is the the least general AMA formula that covers the original training
models.
We now show the correctness of the above transformational approach to computing the AMA
LGCF and syntactic LGG. First, we introduce some notation. Let M be the set of all models over
P . Let M be the set of models over P [ P , such that at any time, for each i, exactly one of pi
and pi is true. Let T be the following mapping from M to M: for hM; I i 2 M, T [hM; I i] is the
unique hM 0 ; I i 2 M such that for all j 2 I and all i, M 0 (j ) assigns pi true iff M (j ) assigns pi
true. Notice that the inverse of T is a functional mapping from M to M. Our approach to handling
negation using purely AMA algorithms begins by applying T to the original training models. In
what follows, we consider AMA formulas over the propositions in P , and AMA formulas over
the propositions in P [ P .
Let F be a mapping from AMA to AMA where for 	 2 AMA , F [	] is an AMA formula
identical to 	 except that each :3pi in 	 is replaced with pi . Notice that the inverse of F is a func415

fiF ERN , G IVAN , & S ISKIND

tion from AMA to AMA and corresponds to the final step in our approach described above. The
following lemma shows that there is a one-to-one correspondence between satisfaction of AMA
formulas by models in M and satisfaction of AMA formulas by models in M.
Lemma 26. For any model hM; I i 2 M and any 	 2 AMA ,
T [hM; I i].

	 covers hM; I i

iff

F [	] covers

Using this lemma, it is straightforward to show that our transformational approach computes the
AMA LGCF under semantic subsumption (and hence under syntactic subsumption).
Proposition 27.

For any

hM; I i 2 M, let  be the AMA LGCF of the model T [hM; I i].
LGCF of hM; I i, up to equivalence.

F 1 [] is the unique AMA

Then,

Proof: We know that  covers T [hM; I i], therefore by Lemma 26 we know that F 1 [] covers
hM; I i. We now show that F 1[] is the least-general formula in AMA that covers hM; I i. For
the sake of contradiction assume that some 0 2 AMA covers hM; I i but that 0 < F 1 []. It
follows that there is some model hM 0 ; I 0 i that is covered by F 1 [] but not by 0 . By Lemma 26
we have that F [0 ] covers T [hM; I i] and since  is the unique AMA LGCF of T [hM; I i], up to
equivalence, we have that   F [0 ]. However, we also have that T [hM 0 ; I 0 i] is covered by 
but not by F [0 ] which gives a contradiction. Thus, no such 0 can exist. It follows that  is an
AMA LGCF. The uniqueness of the AMA LGCF up to equivalence follows because AMA is
closed under conjunction; so that if there were any two non-equivalent LGCF formulas, they could
be conjoined to get an LGCF formula strictly less than one of them. 2
Below we use the fact that the F operator preserves syntactic subsumption. In particular, given
two MA timelines 1 ; 2 , it is clear that any witnessing interdigitation of 1  2 can be trivially
converted into a witness for F [1 ]  F [2 ] (and vice versa). Since syntactic subsumption is defined
in terms of witnessing interdigitations, it follows that for any 	1 ; 	2 2 AMA , (	1 syn 	2 ) iff
(F [	1 ] syn F [	2 ]). Using this property, it is straightforward to show how to compute the syntactic
AMA LGG using the syntactic AMA LGG algorithm.
Proposition 28.

For any AMA

formulas

	1 ; : : : ; 	m ,

let

	

fF [	1 ]; : : : ; F [	m ]g. Then, F 1[	] is the unique syntactic AMA

be the syntactic AMA LGG of
LGG of f	1 ; : : : ; 	m g.

Proof: We know that for each i, F [	i ] syn 	thus, since F 1 preserves syntactic subsumption,
we have that for each i, 	i syn F 1 [	]. This shows that F 1 [	] is a generalization of the inputs.
We now show that F 1 [	] is the least such formula. For the sake of contradiction assume that
F 1 [	] is not least. It follows that there must be a 	0 2 AMA such that 	0 <syn F 1 [	] and for
each i, 	i syn 	0 . Combining this with the fact that F preserves syntactic subsumption, we get
that F [	0 ] <syn 	 and for each i, F [	i ]  F [	0 ]. But this contradicts the fact that 	 is an LGG;
so we must have that F 1 [	] is a syntactic AMA LGG. As argued elsewhere, the uniqueness of
this LGG follows from the fact that AMA is closed under conjunction. 2
These propositions ensure the correctness of our transformational approach to computing the
syntactic LGG within AMA . For the case of semantic subsumption, the transformational approach
does not correctly compute the AMA LGG. To see this, recall that above we have given two timelines 1 ; 2 2 AMA , such that 1  2 , but there is no witnessing interdigitation. Clearly under
416

fiL EARNING T EMPORAL E VENTS

semantic subsumption, the AMA LGG of 1 and 2 is 2 . However, the semantic AMA LGG of
F [1 ] and F [2 ] is not F [2 ]. The reason for this is that since there is no witness to F [1 ]  F [2 ]
(and the F [i ] are MA timelines), we know by Proposition 2 that F [1 ] 6 F [2 ]. Thus, F [2 ]
cannot be returned as the AMA LGG, since it does not subsume both input formulasthis shows
that the transformational approach will not return 2 = F 1 [F [2 ]]. Here, the transformational
approach will produce an AMA formula that is more general than 2 .
On the computational side, we note that, since the transformational approach doubles the number of propositions in the training data, algorithms specifically designed for AMA may be more
efficient. Such algorithms might leverage the special structure of the transformed examples that our
AMA algorithms ignorein particular, that exactly one of pi or pi is true at any time.
Boundary Negation. In our experiments, we actually compare two methods for assigning truth
values to the pi propositions in the training data models. The first method, called full negation,
assigns truth values as described above, yielding the syntactically least-general AMA formula that
covers the examples. We found, however, that using full negation often results in learning overly
specific formulas. To help alleviate this problem, our second method places a bias on the use of
negation. Our choice of bias is inspired by the idea that, often, much of the useful information for
characterizing an event type is in its pre- and post-conditions. The second method, called boundary
negation, differs from full negation in that it only allows pi to be true in the initial and final moments
of a model (and then only if pi is false). pi must be false at all other times. That is, we only allow
informative negative information at the beginnings and ends of the training examples. We have
found that boundary negation provides a good trade-off between no negation (i.e., AMA), which
often produces overly general results, and full negation (i.e., AMA ), which often produces overly
specific and much more complicated results.
5.5 Overall Complexity and Scalability
We now review the overall complexity of our visual event learning component and discuss some
scalability issues. Given a training set of temporal models (i.e., a set of movies), our system does the
following: 1) Propositionalize the training models, translating negation as descried in Section 5.4.
2) Compute the LGCF of each propositional model. 3) Compute the k -AMA LGG of the LGCFs.
4) Return a lifted (variablized) version of the LGG. Steps two and four require little computational
overhead, being linear in the sizes of the input and output respectively. Steps one and three are
the computational bottlenecks of the systemthey encompass the inherent exponential complexity
arising from the relational and temporal problem structure.
Step One. Recall from Section 5.3.2 that our system allows the user to annotate training examples with object correspondence information. Our technique for propositionalizing the models was
shown to be exponential in the number of unannotated objects in a training example. Thus, our
system requires that the number of objects be relatively small or that correspondence information
be given for all but a small number of objects. Often the event class definitions we are interested
in do not involve a large number of objects. When this is true, in a controlled learning setting we
can manage the relational complexity by generating training examples with only a small number (or
zero) irrelevant objects. This is the case for all of the domains studied empirically in this paper.
In a less controlled setting, the number of unannotated objects may prohibit the use of our
correspondence techniquethere are at least three ways one might proceed. First, we can try to
417

fiF ERN , G IVAN , & S ISKIND

develop efficient domain-specific techniques for filtering objects and finding correspondences. That
is, for a particular problem it may be possible to construct a simple filter that removes irrelevant
objects from consideration and then to find correspondences for any remaining objects. Second, we
can provide the learning algorithm with a set of hand-coded first-order formulas, defining a set of
domain-specific features (e.g., in the spirit of Roth & Yih, 2001). These features can then be used
to propositionalize the training instances. Third, we can draw upon ideas from relational learning to
design a truly first-order version of the k -AMA learning algorithm. For example, one could use
existing first-order generalization algorithms to generalize relational state descriptions. Effectively
this approach pushes the object correspondence problem into the k -AMA learning algorithm rather
than treating it as a preprocessing step. Since it is well known that computing first-order LGGs can
be intractable (Plotkin, 1971), practical generalization algorithms retain tractability by constraining
the LGGs in various ways (e.g., Muggleton & Feng, 1992; Morales, 1997).
Step Three. Our system uses the ideas of Section 5.2 to speedup the k -AMA LGG computation
for a set of training data. Nevertheless, the computational complexity is still exponential in k thus,
in practice we are restricted to using relatively small values of k . While this restriction did not limit
performance in our visual event experiments, we expect that it will limit the direct applicability
of our system to more complex problems. In particular, many event types of interest may not
be adequately represented via k -AMA when k is small. Such event types, however, often contain
significant hierarchical structurei.e., they can be decomposed into a set of short sub-event types.
An interesting research direction is to consider using our k -AMA learner as a component of a
hierarchical learning systemthere it could be used to learn k -AMA sub-event types. We note
that our learner alone cannot be applied hierarchically because it requires liquid primitive events,
but learns non-liquid composite event types. Further work is required (and intended) to construct a
hierarchical learner based perhaps on non-liquid AMA learning.
Finally, recall that to compute the LGG of m examples, our system uses a sequence of m 1
pairwise LGG calculations. For a fixed k , each pairwise calculation takes polynomial time. However, since the size of a pairwise LGG can grow by at least a constant factor with respect to the
inputs, the worst-case time complexity of computing the sequence of m 1 pairwise LGGs is exponential in m. We expect that this worst case will primarily occur when the target event type does not
have a compact k -AMA representationin which case a hierarchical approach as described above
is more appropriate. When there is a compact representation, our empirical experience indicates
that such growth does not occurin particular, each pairwise LGG tends to yield significant pruning. For such problems, reasonable assumptions about the amount of pruning11 imply that the time
complexity of computing the sequence of m 1 pairwise LGGs is polynomial in m.

6. Experiments
6.1 Data Set
Our data set contains examples of 7 different event types: pick up, put down, stack, unstack, move,
assemble, and disassemble. Each of these involve a hand and two to three blocks. For a detailed
description and sample video sequences of these event types, see Siskind (2001). Key frames from
sample video sequences of these event types are shown in Figure 11. The results of segmentation,
11. In particular, assume that the size of a pairwise k-AMA LGG is usually bounded by the sizes of the k-covers of the
inputs.

418

fiL EARNING T EMPORAL E VENTS

tracking, and model reconstruction are overlaid on the video frames. We recorded 30 movies for
each of the 7 event classes resulting in a total of 210 movies comprising 11946 frames.12 We
replaced one assemble movie (assemble-left-qobi-04), with a duplicate copy of another (assembleleft-qobi-11) because of segmentation and tracking errors.
Some of the event classes are hierarchical in that occurrences of events in one class contain occurrences of events in one or more simpler classes. For example, a movie depicting a
M OVE (a; b; c; d) event (i.e. a moves b from c to d) contains subintervals where P ICK U P (a; b; c)
and P UT D OWN (a; b; d) events occur. In our experiments, when learning the definition of an event
class only the movies for that event class are used in training. We do not train on movies for other
event classes that may also depict an occurrence of the event class being learned as a subevent.
However, in evaluating the learned definitions, we wish to detect both the events that correspond to
an entire movie as well as subevents that correspond to portions of that movie. For example, given a
movie depicting a M OVE (a; b; c; d) event, we wish to detect not only the M OVE(a; b; c; d) event but
also the P ICK U P (a; b; c) and P UT D OWN (a; b; d) subevents as well. For each movie type in our data
set, we have a set of intended events and subevents that should be detected. If a definition does not
detect an intended event, we deem the error a false negative. If a definition detects an unintended
event, we deem the error a false positive. For example, if a movie depicts a M OVE(a; b; c; d) event,
the intended events are M OVE(a; b; c; d), P ICK U P (a; b; c), and P UT D OWN (a; b; c). If the definition
for pick up detects the occurrence of P ICK U P (c; b; a) and P ICK U P (b; a; c), but not P ICK U P (a; b; c),
it will be charged two false positives as well as one false negative. We evaluate our definitions in
terms of false positive and negative rates as describe below.
6.2 Experimental Procedure
For each event type, we evaluate the k -AMA learning algorithm using a leave-one-movie-out crossvalidation technique with training-set sampling. The parameters to our learning algorithm are k
and the degree D of negative information used. The value of D is either P, for positive propositions
only, BN, for boundary negation, or N, for full negation. The parameters to our evaluation procedure
include the target event type E and the training-set size N . Given this information, the evaluation
proceeds as follows: For each movie M (the held-out movie) from the 210 movies, apply the k AMA learning algorithm to a randomly drawn training sample of N movies from the 30 movies of
event type E (or 29 movies if M is one of the 30). Use L EONARD to detect all occurrences of the
learned event definition in M . Based on E and the event type of M , record the number of false
positives and false negatives in M , as detected by L EONARD . Let FP and FN be the total number
of false positives and false negatives observed over all 210 held-out movies respectively. Repeat the
entire process of calculating FP and FN 10 times and record the averages as FP and FN.13
Since some event types occur more frequently in our data than others because simpler events
occur as subevents of more complex events but not vice versa, we do not report FP and FN directly.
Instead, we normalize FP by dividing by the total number of times L EONARD detected the target
event correctly or incorrectly within all 210 movies and we normalize FN by dividing by the total
12. The source code and all of the data used for these experiments are available as Online Appendix 1, and also from
ftp://ftp.ecn.purdue.edu/qobi/ama.tar.Z.
13. While we did not record the times for our experiments, the system is fast enough to give live demos when N = 29
and k = 3 with boundary negation, giving the best results we show here (though we dont typically record 29 training
videos in a live demo for other reasons). Some of the less favorable parameter settings (particularly k = 4 and full
negation) can take a (real-time) hour or so.

419

fiF ERN , G IVAN , & S ISKIND

pick up

put down

stack

unstack

move

assemble

disassemble

Figure 11: Key frames from sample videos of the 7 event types.

420

fiL EARNING T EMPORAL E VENTS

number of correct occurrences of the target event within all 210 movies (i.e., the human assessment
of the number of occurrences of the target event). The normalized value of FP estimates the probability that the target event did not occur given that it was predicted to occur, while the normalized
value of FN estimates the probability that the event was not predicted to occur given that it did
occur.
6.3 Results
To evaluate our k -AMA learning approach, we ran leave-one-movie-out experiments, as described
above, for varying k , D , and N . The 210 example movies were recorded with color-coded objects to
provide complete object-correspondence information. We compared our learned event definitions to
the performance of two sets of hand-coded definitions. The first set HD1 of hand-coded definitions
appeared in Siskind (2001). In response to subsequent deeper understanding of the behavior of
L EONARD s model-reconstruction methods, we manually revised these definitions to yield another
set HD2 of hand-coded definitions that gives a significantly better FN performance at some cost
in FP performance. Appendix C gives the event definitions in HD1 and HD2 along with a set of
machine-generated definitions, produced by the k -AMA learning algorithm, given all training data
for k = 30 and D = BN.
6.3.1 O BJECT C ORRESPONDENCE
To evaluate our algorithm for finding object correspondences, we ignored the correspondence information provided by color coding and applied the algorithm to all training models for each event
type. The algorithm selected the correct correspondence for all 210 training models. Thus, for this
data set, the learning results when no correspondence information is given will be identical to those
where the correspondences are manually provided, except that, in the first case, the rules will not
specify particular object roles, as discussed in section 5.3.2. Since our evaluation procedure uses
role information, the rest of our experiments use the manual correspondence information, provided
by color-coding, rather than computing it.
While our correspondence technique was perfect in these experiments, it may not be suited to
some event types. Furthermore, it is likely to produce more errors as noise levels increase. Since
correspondence errors represent a form of noise and our learner makes no special provisions for
handling noise, the results are likely to be poor when such errors are common. For example, in the
worst case, it is possible for a single extremely noisy example to cause the the LGG to be trivial (i.e.,
the formula true). In such cases, we will be forced to improve the noise tolerance of our learner.
6.3.2 VARYING k

The first three rows of Table 1 show the FP and FN values for all 7 event types for k 2 f2; 3; 4g ,
N = 29 (the maximum), and D = BN. Similar trends were found for D = P and D = N. The
general trend is that, as k increases, FP decreases or remains the same and FN increases or remains
the same. Such a trend is a consequence of our k -cover approach. This is because, as k increases,
the k -AMA language contains strictly more formulas. Thus for k1 > k2 , the k1 -cover of a formula
will never be more general than the k2 -cover. This strongly suggests, but does not prove, that FP
will be non-increasing with k and FN will be non-decreasing with k .
Our results show that 2-AMA is overly general for put down and assemble, i.e. it gives high
FP. In contrast, 3-AMA achieves FP = 0 for each event type, but pays a penalty in FN compared
421

fiF ERN , G IVAN , & S ISKIND

k D
2 BN

pick up

put down

stack

unstack

move

assemble

disassemble

FP
FN

0
0

0.14
0.19

0
0.12

0
0.03

0
0

0.75
0

0
0

3

BN

FP
FN

0
0

0
0.2

0
0.45

0
0.10

0
0.03

0
0.07

0
0.10

4

BN

FP
FN

0
0

0
0.2

0
0.47

0
0.12

0
0.03

0
0.07

0
0.17

3

P

FP
FN

0.42
0

0.5
0.19

0
0.42

0.02
0.11

0
0.03

0
0.03

0
0.10

3

BN

FP
FN

0
0

0
0.2

0
0.45

0
0.10

0
0.03

0
0.07

0
0.10

3

N

FP
FN

0
0.04

0
0.39

0
0.58

0
0.16

0
0.13

0
0.2

0
0.2

HD1

FP
FN

0.01
0.02

0.01
0.22

0
0.82

0
0.62

0
0.03

0
1.0

0
0.5

HD2

FP
FN

0.13
0.0

0.11
0.19

0
0.42

0
0.02

0
0.0

0
0.77

0
0.0

Table 1: FP and FN for learned definitions, varying both k and D , and for hand-coded definitions.
to 2-AMA. Since 3-AMA achieves FP = 0, there is likely no advantage in moving to k -AMA for
k > 3. That is, the expected result is for FN to become larger. This effect is demonstrated for
4-AMA in the table.
6.3.3 VARYING D

Rows four through six of Table 1 show FP and FN for all 7 event types for D 2 fP; BN; Ng, N = 29,
and k = 3. Similar trends were observed for other values of k . The general trend is that, as the
degree of negative information increases, the learned event definitions become more specific. In
other words, FP decreases and FN increases. This makes sense since, as more negative information
is added to the training models, more specific structure can be found in the data and exploited by
the k -AMA formulas. We can see that, with D = P, the definitions for pick up and put down are
overly general, as they produce high FP. Alternatively, with D = N, the learned definitions are
overly specific, giving FP = 0, at the cost of high FN. In these experiments, as well as others, we
have found that D = BN yields the best of both worlds: FP = 0 for all event types and lower FN
than achieved with D = N.
Experiments not shown here have demonstrated that, without negation for pick up and put down,
we can increase k arbitrarily, in an attempt to specialize the learned definitions, and never significantly reduce FP. This indicates that negative information plays a particularly important role in
constructing definitions for these event types.

422

fiL EARNING T EMPORAL E VENTS

6.3.4 C OMPARISON

TO

H AND -C ODED D EFINITIONS

The bottom two rows of table 1 show the results for HD1 and HD2 . We have not yet attempted to
automatically select the parameters for learning (i.e. k and D ). Rather, here we focus on comparing
the hand-coded definitions to the parameter set that we judged to be best performing across all event
types. We believe, however, that these parameters could be selected reliably using cross-validation
techniques applied to a larger data set. In that case, the parameters would be selected on a perevent-type basis and would likely result in an even more favorable comparison to the hand-coded
definitions.
The results show that the learned definitions significantly outperform HD1 on the current data
set. The HD1 definitions were found to produce a large number of false negatives on the current
data set. Notice that, although HD2 produces significantly fewer false negatives for all event types,
it produces more false positives for pick up and put down. This is because the hand definitions
utilize pick up and put down as macros for defining the other events.
The performance of the learned definitions is competitive with the performance of HD2 . The
main differences in performance are: (a) for pick up and put down, the learned and HD2 definitions
achieve nearly the same FN but the learned definitions achieve FP = 0 whereas HD2 has significant
FP, (b) for unstack and disassemble, the learned definitions perform moderately worse than HD2
with respect to FN, and (c) the learned definitions perform significantly better than HD2 on assemble
events.
We conjecture that further manual revision could improve HD2 to perform as well as (and perhaps better than) the learned definitions for every event class. Nonetheless, we view this experiment
as promising, as it demonstrates that our learning technique is able to compete with, and sometimes
outperform, significant hand-coding efforts by one of the authors.
6.3.5 VARYING N
It is of practical interest to know how training-set size affects our algorithms performance. For this
application, it is important that our method work well with fairly small data sets, as it can be tedious
to collect event data. Table 2 shows the FN of our learning algorithm for each event type, as N is
reduced from 29 to 5. For these experiments, we used k = 3 and D = BN. Note that FP = 0
for all event types and all N and hence is not shown. We expect FN to increase as N is decreased,
since, with specific-to-general learning, more data yields more-general definitions. Generally, FN
is flat for N > 20, increases slowly for 10 < N < 20, and increases abruptly for 5 < N < 10. We
also see that, for several event types, FN decreases slowly, as N is increased from 20 to 29. This
indicates that a larger data set might yield improved results for those event types.
6.3.6 P ERSPICUITY

OF

L EARNED D EFINITIONS

One motivation for using a logic-based event representation is to support perspicuityin this respect
our results are mixed. We note that perspicuity is a fuzzy and subjective concept. Realizing this,
we will say that an event definition is perspicuous if most humans with knowledge of the language
would find the definition to be natural. Here, we do not assume the human has a detailed knowledge of the model-reconstruction process that our learner is trying to fit. Adding that assumption
would presumably make the definitions qualify as more perspicuous, as many of the complex features of the learned definitions appear in fact to be due to idiosyncrasies of the model-reconstruction
process. In this sense, we are evaluating the perspicuity of the output of the entire system, not just
423

fiF ERN , G IVAN , & S ISKIND

of the learner itself, so that a key route to improving perspicuity in this sense would be to improve
the intuitive properties of the model-reconstruction output without any change to the learner.
While the learned and hand-coded definitions are similar with respect to accuracy, typically the
learned definitions are much less perspicuous. For our simplest event types, however, the learned
definitions are arguably perspicuous. Below we look at this issue in more detail. Appendix C gives
the hand-coded definitions in HD1 and HD2 along with a set of machine-generated definitions. The
learned definitions correspond to the output of our k -AMA learner when run on all 30 training
movies from each event type with k = 3 and D = BN (i.e., our best performing configuration with
respect to accuracy).
Perspicuous Definitions. The P ICK U P (x; y; z ) and P UT D OWN (x; y; z ) definitions are of particular interest here since short state sequences appear adequate for representing these event types
thus, we can hope for perspicuous 3-AMA definitions. In fact, the hand-coded definitions involve short sequences. Consider the hand-coded definitions of P ICK U P(x; y; z )the definitions
can roughly be viewed as 3-MA timelines of the form begin;trans;end.14 State begin asserts facts
that indicate y is on z and is not being held by x and end asserts facts that indicate y is being held by
x and is not on z . State trans is intended to model the fact that L EONARDs model-reconstruction
process does not always handle the transition between begin and end smoothly (so the definition
begin;end does not work well). We can make similar observations for P UT D OWN(x; y; z ).
Figure 15 gives the learned 3-AMA definitions of P ICK U P (x; y; z ) and P UT D OWN (x; y; z )
the definitions contain six and two 3-MA timelines respectively. Since the definitions consists of
multiple parallel timelines, they may at first not seem perspicuous. However, a closer examination
reveals that, in each definition, there is a single timeline that is arguably perspicuouswe have
placed these perspicuous timelines at the beginning of each definition. The perspicuous timelines
have a natural begin;trans;end interpretation. In fact, they are practically equivalent to the definitions
of P ICK U P (x; y; z ) and P UT D OWN (x; y; z ) in HD2 .15
With this in mind, notice that the HD2 definitions are overly general as indicated by significant
false positive rates. The learned definitions, however, yield no false positives without a significant
increase in false negatives. The learned definitions improve upon HD2 by essentially specializing
the HD2 definitions (i.e., the perspicuous timelines) by conjoining them with the non-perspicuous
timelines. While these non-perspicuous timelines are often not intuitive, they capture patterns in the
events that help rule out non-events. For example, in the learned definition of P ICK U P (x; y; z ) some
of the non-perspicuous timelines indicate that ATTACHED (y; z ) is true during the transition period
of the event. Such an attachment relationship does not make intuitive sense. Rather, it represents a
systematic error made by the model reconstruction process for pick up events.
In summary, we see that the learned definitions of P ICK U P (x; y; z ) and P UT D OWN (x; y; z ) each
contain a perspicuous timeline and one or more non-perspicuous timelines. The perspicuous timelines give an intuitive definition of the events, whereas the non-perspicuous timelines capture nonintuitive aspects of the events and model reconstruction process that are important in practice. We
note that, for experienced users, the primary difficulty of hand-coding definitions for L EONARD is
14. Note that the event-logic definition for P ICK U P(x; y; z ) in HD2 is written in a more compact form than 3-MA, but
this definition can be converted to 3-MA (and hence 3-AMA). Rather, HD1 cannot be translated exactly to 3-MA
since it uses disjunctionit is the disjunction of two 3-MA timelines.
15. The primary difference is that the HD2 definitions contain more negated propositions. The learner only considers a
proposition and its negation if the proposition is true at some point during the training movies. Many of the negated
propositions in HD2 never appear positively, thus they are not included in the learned definitions.

424

fiL EARNING T EMPORAL E VENTS

to determining which non-perspicuous properties must be included. Typically this requires many
iterations of trial and error. Our automated technique can relieve the user of this task. Alternatively,
we could view the system as providing guidance for this task.
Large Definitions. The S TACK (w; x; y; z ) and U NSTACK (w; x; y; z ) events are nearly identical
to put down and pick up respectively. The only difference is that now we are picking up from and
putting down onto a two block (rather than single block) tower (i.e., composed of blocks y and z ).
Thus, here again we might expect there to be perspicuous 3-AMA definitions. However, we see that
the learned definitions for S TACK (w; x; y; z ) and U NSTACK (w; x; y; z ) in Figures 16 and 17 involve
many more timelines than those for P ICK U P (w; x; y ) and P UT D OWN (w; x; y ). Accordingly, the
definitions are quite overwhelming and much less perspicuous.
Despite the large number of timelines, these definitions have the same general structure as those
for pick up and put down. In particular, they each contain a distinguished perspicuous timeline,
placed at the beginning of each definition, that is conjoined with many non-perspicuous timelines.
It is clear that, as above, the perspicuous timelines have a natural begin;trans;end interpretation
and, again, they are very similar to the definitions in HD 2 . In this case, however, the definitions
in HD2 are not overly general (committing no false positives). Thus, here the inclusion of the
non-perspicuous timelines has a detrimental effect since they unnecessarily specialize the definition
resulting in more false negatives.
We suspect that a primary reason for the large number of non-perspicuous timelines relative
to the definitions of pick up and put down stems from the increased difficulty of constructing
force-dynamic models. The inclusion of the two block tower in these examples causes the modelreconstruction process to produce more unintended results, particularly during the transition periods
of S TACK and U NSTACK . The result is that often many unintuitive and physically incorrect patterns
involving the three blocks and the hand are produced during the transition period. The learner
captures these patterns roughly via the non-perspicuous timelines. It is likely that generalizing the
definitions by including more training examples would filter out some of these timelines, making the
overall definition more perspicuous. Alternatively, it is of interest to consider pruning the learned
definitions. A straightforward way to do this is to generate negative examples. Then with these,
we could remove timelines (generalizing the definition) that do not contribute toward rejecting the
negative examples. It is unclear how to prune definitions without negative examples.
Hierarchical Events. M OVE(w; x; y; z ), A SSEMBLE (w; x; y; z ), and D ISASSEMBLE (w; x; y; z )
are inherently hierarchical, being composed of the four simpler event types. The hand-coded definitions leverage this structure by utilizing the simpler definitions as macros. In this light, it should
be clear that, when viewed non-hierarchically, (as our learner does) these events involve relatively
long state sequences. Thus, 3-AMA is not adequate for writing down perspicuous definitions. In
spite of this representational shortcoming, our learned 3-AMA definitions perform quite well. This
performance supports one of our arguments for using AMA from section 3.2. Namely, given that it
is easier to find short rather than long sequences, a practical approach to finding definitions for long
events is to conjoin the short sequences within those events. Examining the timelines of the learned
3-AMA definitions reveals what we might expect. Each timeline captures an often understandable
property of the long event sequence, but the conjunction of those timelines cannot be considered
to be a perspicuous definition. A future direction is to utilize hierarchical learning techniques to
improve the perspicuity of our definitions while maintaining accuracy.
425

fiF ERN , G IVAN , & S ISKIND

N

pick up

put down

stack

unstack

move

assemble

disassemble

29
25
20
15
10
5

0.0
0.0
0.01
0.01
0.07
0.22

0.20
0.20
0.21
0.22
0.27
0.43

0.45
0.47
0.50
0.53
0.60
0.77

0.10
0.16
0.17
0.26
0.36
0.54

0.03
0.05
0.08
0.14
0.23
0.35

0.07
0.09
0.12
0.20
0.32
0.57

0.10
0.10
0.12
0.16
0.26
0.43

Table 2: FN for k

= 3, D = BN, and various values of N .

We note, however, that, at some level, the learned definition of M OVE (w; x; y; z ) given in Figure 18 is perspicuous. In particular, the first 3-MA timeline is naturally interpreted as giving the
pre- and post-conditions for a move action. That is, initially x is supported by y and the hand w is
empty and finally x is supported by z and the hand w is empty. Thus, if all we care about is preand post-conditions, we might consider this timeline to be perspicuous. The remaining timelines in
the definition capture pieces of the internal event structure such as facts indicating that x is moved
by the hand. A weaker case can be made for assemble and disassemble. The first timeline in each
of the learned definitions in Figures 19 and 20 can be interpreted as giving pre- and post-conditions.
However, in these cases, the pre(post)-conditions for assemble(disassemble) are quite incomplete.
The incompleteness is due to the inclusion of examples where the model-reconstruction process did
not properly handle the initial(final) moments.

7. Related Work
Here we discuss two bodies of related work. First, we present previous work in visual event recognition and how it relates to our experiments here. Second, we discuss previous approaches to learning
temporal patterns from positive data.
7.1 Visual Event Recognition
Our system is unique in that it combines positive-only learning with a temporal, relational, and
force-dynamic representation to recognize events from real video. Prior work has investigated various subsets of the features of our systembut, to date, no system has combined all of these pieces
together. Incorporating any one of these pieces into a system is a significant endeavor. In this respect, there are no competing approaches to directly compare our system against. Given this, the
following is a representative list of systems that have common features with ours. It is not meant to
be comprehensive and focuses on pointing out the primary differences between each of these systems and ours, as these primary differences actually render these systems only very loosely related
to ours.
Borchardt (1985) presents a representation for temporal, relational, force-dynamic event definitions but these definitions are neither learned nor applied to video. Regier (1992) presents techniques for learning temporal event definitions but the learned definitions are neither relational, force
dynamic, nor applied to video. In addition the learning technique is not truly positive-onlyrather,
it extracts implicit negative examples of an event type from positive examples of other event types.
426

fiL EARNING T EMPORAL E VENTS

Yamoto, Ohya, and Ishii (1992), Brand and Essa (1995), Siskind and Morris (1996), Brand, Oliver,
and Pentland (1997), and Bobick and Ivanov (1998) present techniques for learning temporal event
definitions from video but the learned definitions are neither relational nor force dynamic. Pinhanez
and Bobick (1995) and Brand (1997a) present temporal, relational event definitions that recognize
events in video but these definitions are neither learned nor force dynamic. Brand (1997b) and Mann
and Jepson (1998) present techniques for analyzing force dynamics in video but neither formulate
event definitions nor apply these techniques to recognizing events or learning event definitions.
7.2 Learning Temporal Patterns
We divide this body of work into three main categories: temporal data mining, inductive logic
programming, and finite-statemachine induction.
Temporal Data Mining. The sequence-mining literature contains many general-to-specific (levelwise) algorithms for finding frequent sequences (Agrawal & Srikant, 1995; Mannila, Toivonen,
& Verkamo, 1995; Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001). Here we explore a specific-togeneral approach. In this previous work, researchers have studied the problem of mining temporal
patterns using languages that are interpreted as placing constraints on partially or totally ordered
sets of time points, e.g., sequential patterns (Agrawal & Srikant, 1995) and episodes (Mannila et al.,
1995). These languages place constraints on time points rather than time intervals as in our work
here. More recently there has been work on mining temporal patterns using interval-based pattern
languages (Kam & Fu, 2000; Cohen, 2001; Hoppner, 2001).
Though the languages and learning frameworks vary among these approaches, they share two
central features which distinguish them from our approach. First, they all typically have the goal
of finding all frequent patterns (formulas) within a temporal data setour approach is focused
on finding patterns with a frequency of one (covering all positive examples). Our first learning
application of visual-event recognition has not yet required us to find patterns with frequency less
than one. However, there are a number of ways in which we can extend our method in that direction
when it becomes necessary (e.g., to deal with noisy training data). Second, these approaches all
use standard general-to-specific level-wise search techniques, whereas we chose to take a specificto-general approach. One direction for future work is to develop a general-to-specific level-wise
algorithm for finding frequent MA formulas and to compare it with our specific-to-general approach.
Another direction is to design a level-wise version of our specific-to-general algorithmwhere for
example, the results obtained for the k -AMA LGG can be used to more efficiently calculate the
(k + 1)-AMA LGG. Whereas a level-wise approach is conceptually straightforward in a general-tospecific framework it is not so clear in the specific-to-general case. We are not familiar with other
temporal data-mining systems that take a specific-to-general approach.
First-Order Learning In Section 3.3, we pointed out difficulties in using existing first-order
clausal generalization techniques for learning AMA formulas. In spite of these difficulties, it is still
possible to represent temporal events in first-order logic (either with or without capturing the AMA
semantics precisely) and to apply general-purpose relational learning techniques, e.g., inductive
logic programming (ILP) (Muggleton & De Raedt, 1994). Most ILP systems require both positive
and negative training examples and hence are not suitable for our current positive-only framework.
Exceptions include G OLEM (Muggleton & Feng, 1992), P ROGOL (Muggleton, 1995), and C LAU DIEN (De Raedt & Dehaspe, 1997), among others. While we have not performed a full evaluation
427

fiF ERN , G IVAN , & S ISKIND

Inputs
MA
AMA

Subsumption
Semantic
Syntactic
P
P
coNP-complete P

Semantic AMA LGG
Lower Upper Size
P
coNP EXP
coNP NEXP 2-EXP?

Syntactic AMA LGG
Lower Upper Size
P
coNP EXP
P
coNP EXP

Table 3: Complexity Results Summary. The LGG complexities are relative to input plus output size.
The size column reports the worst-case smallest correct output size. The ? indicates a
conjecture.
of these systems, our early experiments in the visual-event recognition domain confirmed our belief
that horn clauses, lacking special handling of time, give a poor inductive bias. In particular, many of
the learned clauses find patterns that simply do not make sense from a temporal perspective and, in
turn, generalize poorly. We believe a reasonable alternative to our approach may be to incorporate
syntactic biases into ILP systems as done, for example, in Cohen (1994), Dehaspe and De Raedt
(1996), Klingspor, Morik, and Rieger (1996). In this work, however, we chose to work directly in a
temporal logic representation.
Finite-State Machines Finally, we note there has been much theoretical and empirical research
into learning finite-state machines (FSMs) (Angluin, 1987; Lang, Pearlmutter, & Price, 1998). We
can view FSMs as describing properties of strings (symbol sequences). In our case, however, we are
interested in describing sequences of propositional models rather than just sequences of symbols.
This suggests learning a type of factored FSM where the arcs are labeled by sets of propositions
rather than by single symbols. Factored FSMs may be a natural direction in which to extend the
expressiveness of our current language, for example by allowing repetition. We are not aware of
work concerned with learning factored FSMs; however, it is likely that inspiration can be drawn
from symbol-based FSM-learning algorithms.

8. Conclusion
We have presented a simple logic for representing temporal events called AMA and have shown
theoretical and empirical results for learning AMA formulas. Empirically, weve given the first
system for learning temporal, relational, force-dynamic event definitions from positive-only input
and we have applied that system to learn such definitions from real video input. The resulting
performance matches that of event definitions that are hand-coded with substantial effort by human
domain experts. On the theoretical side, Table 3 summarizes the upper and lower bounds that
we have shown for the subsumption and generalization problems associated with this logic. In
each case, we have provided a provably correct algorithm matching the upper bound shown. The
table also shows the worst-case size that the smallest LGG could possibly take relative to the input
size, for both AMA and MA inputs. The key results in this table are the polynomial-time MA
subsumption and AMA syntactic subsumption, the coNP lower bound for AMA subsumption, the
exponential size of LGGs in the worst case, and the apparently lower complexity of syntactic AMA
LGG versus semantic LGG. We described how to build a learner based on these results and applied
it to the visual-event learning domain. To date, however, the definitions we learn are neither crossmodal nor perspicuous. And while the performance of the learned definitions matches that of hand428

fiL EARNING T EMPORAL E VENTS

coded ones, we wish to surpass hand coding. In the future, we intend to address cross-modality by
applying our learning technique to the planning domain. We also believe that addressing perspicuity
will lead to improved performance.

Acknowledgments
The authors wish to thank our anonymous reviewers for helping to improve this paper. This work
was supported in part by NSF grants 9977981-IIS and 0093100-IIS, an NSF Graduate Fellowship
for Fern, and the Center for Education and Research in Information Assurance and Security at
Purdue University. Part of this work was performed while Siskind was at NEC Research Institute,
Inc.

Appendix A. Internal Positive Event Logic
Here we give the syntax and semantics for an event logic called Internal Positive Event Logic
(IPEL). This logic is used in the main text only to motivate our choice of a small subset of this
logic, AMA, by showing, in Proposition 4, that AMA can define any set of models that IPEL can
define.
An event type (i.e., set of models) is said to be internal if whenever it contains any model
M = hM; I i, it also contains any model that agrees with M on truth assignments M [i] where i 2 I .
Full event logic allows the definition of non-internal events, for example, the formula 	 = 3< P
is satisfied by hM; I i when there is some interval I 0 entirely preceding I such that P is satisfied
by hM; I 0 i, thus 	 is not internal. The applications we are considering do not appear to require
non-internal events, thus we currently only consider events that are internal.
Call an event type positive if it contains the model M = hM; [1; 1]i where M (1) is the truth
assignment assigning all propositions the value true. A positive event type cannot require any proposition to be false at any point in time.
IPEL is a fragment of full propositional event logic that can only describe positive internal
events. We conjecture, but have not yet proven, that all positive internal events representable in the
full event logic of Siskind (2001) can be represented by some IPEL formula. Formally, the syntax
of IPEL formulas is given by

E ::= true j prop j E1 _ E2 j 3R E1 j E1 ^R E2 ;
0

where the Ei are IPEL formulas, prop is a primitive proposition (sometimes called a primitive event
type), R is a subset of the thirteen Allen interval relations fs,f,d,b,m,o,=,si,fi,di,bi,ai,oi g (Allen,
1983), and R0 is a subset of the restricted set of Allen relations fs,f,d,=g, the semantics for each
Allen relation is given in Table 4. The difference between IPEL syntax and that of full propositional
event logic is that event logic allows for a negation operator, and that, in full event logic, R0 can
be any subset of all thirteen Allen relations. The operators ^ and ; used to define AMA formulas
are merely abbreviations for the IPEL operators ^f=g and ^fmg respectively, so AMA is a subset of
IPEL (though a distinguished subset as indicated by Proposition 4).
Each of the thirteen Allen interval relations are binary relations on the set of closed naturalnumber intervals. Table 4 gives the definitions of these relations, defining [m1 ; m2 ] r [n1 ; n2 ] for
each Allen relation r . Satisfiability for IPEL formulas can now be defined as follows,
429

fiF ERN , G IVAN , & S ISKIND

I1
[m1 ; m2 ]
[m1 ; m2 ]
[m1 ; m2 ]
[m1 ; m2 ]
[m1 ; m2 ]
[m1 ; m2 ]
[m1 ; m2 ]

Relation
s
f
d
b
m
o
=

I2
[n1 ; n2 ]
[n1 ; n2 ]
[n1 ; n2 ]
[n1 ; n2 ]
[n1 ; n2 ]
[n1 ; n2 ]
[n1 ; n2 ]

English
starts
finishes
during
before
meets
overlaps
equals

Definition
m1 = n1 and m2
m1  n1 and m2
m1  n1 and m2

 n2
= n2
 n2

m2  n1
m2 = n1 or m2 + 1 = n1
m1  n1  m2  n2
m1 = n1 and m2 = n2

Inverse
si
fi
di
bi
mi
oi
=

Table 4: The Thirteen Allen Relations (adapted to our semantics).

 true is satisfied by every model.
 prop is satisfied by model hM; I i iff M [x] assigns prop true for every x 2 I .
 E1 _ E2 is satisfied by a model M iff M satisfies E1 or M satisfies E2.
 3RE is satisfied by model hM; I i iff for some r 2 R there is an interval I 0 such that I 0 r I
and hM; I 0 i satisfies E .
 E1 ^R E2 is satisfied by model hM; I i iff for some r 2 R there exist intervals I1 and I2 such
that I1 r I2 , S PAN (I1 ; I2 ) = I and both hM; I1 i satisfies E1 and hM; I2 i satisfies E2 .
where prop is a primitive proposition, E and Ei are IPEL formulas, R is a set of Allen relations, and
S PAN (I1 ; I2 ) is the minimal interval that contains both I1 and I2 . From this definition, it is easy to
show, by induction on the number of operators and connectives in a formula, that all IPEL formulas
define internal events. One can also verify that the definition of satisfiability given earlier for AMA
formulas corresponds to the one we give here.

Appendix B. Omitted Proofs
Lemma 1. For any MA timeline  and any model M, if M satisfies  then there is a witnessing
interdigitation for MAP(M)  .
Proof: Assume that M = hM; I i satisfies the MA timeline  = s1 ; : : : ; sn , and let 0 =
MAP(M). It is straightforward to argue, by induction on the length of , that there exists a mapping
V 0 from states of  to sub-intervals of I , such that

 for any i 2 V 0 (s), M [i] satisfies s,
 V 0(s1) includes the initial time point of I ,
 V 0(sn) includes the final time point of I , and
 for any i 2 [1; n 1], we have V 0(si ) meets V 0(si+1) (see Table 4).
430

fiL EARNING T EMPORAL E VENTS

Let V be the relation between states s 2  and members i 2 I that is true when i 2 V 0 (s). Note
that the conditions on V 0 ensure that every s 2  and every i 2 I appear in some tuple in V (not
necessarily together). Below we use V to construct a witnessing interdigitation W .
Let R be the total, one-to-one, onto function from time-points in I to corresponding states in 0 ,
noting that 0 has one state for each time-point in I , as 0 = MAP(hM; I i). Note that R preserves
ordering in that, when i  j , R(i) is no later than R(j ) in 0 . Let W be the composition V  R of
the relations V and R.
We show that W is an interdigitation. We first show that each state from  or 0 appears in a
tuple in W , so W is piecewise total. States from  must appear, trivially, because each appears in a
tuple of V , and R is total. States from 0 appear because each i 2 I appears in a tuple of V , and R
is onto the states of 0 .
It now suffices to show that for any states s before t from , W (s; s0 ) and W (t; t0 ) implies that
s0 is no later than t0 in 0 , so that W is simultaneously consistent. The conditions defining V 0 above
imply that every number in i 2 V (s) is less than or equal to every j 2 V (t). The order-preservation
property of R, noted above, then implies that every state s0 2 V  R(s) is no later than any state
t0 2 V  R(t) in 0 , as desired. So W is an interdigitation.
We now argue that W witnesses 0  . Consider s 2  and t 2 0 such that W (s; t). By the
construction of W , there must be i 2 V 0 (s) for which t is the ith state of 0 . Since 0 = MAP(M),
it follows that t is the set of true propositions in M [i]. Since i 2 V 0 (s), we know that M [i] satisfies
s. It follows that s  t, and so t  s. 2

2 IPEL, if model M embeds a model that satisfies E then M satisfies E .
Proof: Consider the models M = hM; I i and M0 = hM 0 ; I 0 i such that M embeds M0 , let
 = MAP(M) and 0 = MAP(M0 ). Assume that E 2 IPEL is satisfied by M0 , we will show that
E is also satisfied by M.
We know from the definition of embedding that   0 and thus there is a witnessing interdigitation W for   0 by Proposition 2. We know there is a one-to-one correspondence between
numbers in I (I 0 ) and states of  (0 ) and denote the state in  (0 ) corresponding to i 2 I (i0 2 I 0 )
Lemma 3. For any E

as si (ti ). This correspondence allows us to naturally interpret W as a mapping V from subsets of
I 0 to subsets of I as follows: for I10  I 0 , V (I10 ) equals the set of all i 2 I such that for some i0 2 I10 ,
si co-occurs with ti in W . We will use the following properties of V ,
0

0

1. If I10 is a sub-interval of I 0 , then V (I10 ) is a sub-interval of I .

2. If I10 is a sub-interval of I 0 , then hM; V (I10 )i embeds hM 0 ; I10 i.

3. If I10 and I20 are sub-intervals of I 0 , and r is an Allen relation, then I10 rI20 iff V (I10 )rV (I20 ).
4. If I10 and I20 are sub-intervals of I 0 , then V (S PAN (I10 ; I20 )) = S PAN (V (I10 ); V (I20 )).

5.

V (I 0 ) = I .

We sketch the proofs of these properties. 1) Use induction on the length of I10 , with the
definition of interdigitation. 2) Since V (I10 ) is an interval, MAP(hM; V (I10 )i) is well defined.
MAP(hM; V (I10 )i)  MAP(hM 0 ; I10 i) follows from the assumption that M embeds M0 . 3) From
Appendix A, we see that all Allen relations are defined in terms of the  relation on the natural
431

fiF ERN , G IVAN , & S ISKIND

number endpoints of the intervals. We can show that V preserves  (but not <) on singleton sets
(i.e., every member of V (fi0 g) is  every member of V (fj 0 g) when i0  j 0 ) and that V commutes with set union. It follows that V preserves the Allen interval relations. 4) Use the fact that
V preserves  in the sense just argued, along with the fact that S PAN (I10 ; I20 ) depends only on the
minimum and maximum numbers in I10 and I20 . 5) Follows from the definition of interdigitation and
the construction of V .
We now use induction on the number of operators and connectives in E to prove that, if M0
satisfies E , then so must M. The base case is when E = prop, where prop is a primitive proposition,
or true. Since M0 satisfies E , we know that prop is true in all M 0 [x0 ] for x0 2 I 0 . Since W witnesses
  0 , we know that, if prop is true in M 0 [x], then prop is true in all M [x], where x 2 V (x0 ).
Therefore, since V (I 0 ) = I , prop is true for all M 0 [x], where x 2 I , hence M0 satisfies E .
For the inductive case, assume that the claim holds for IPEL formulas with fewer than N operators and connectiveslet E1 ; E2 be two such formulas. When E = E1 _ E2 , the claim trivially
holds. When E = 3R E1 , R must be a subset of the set of relations fs,f,d,=g. Notice that E can
be written as a disjunction of 3r E1 formulas, where r is a single Allen relation from R. Thus, it
suffices to handle the case where R is a single Allen relation. Suppose E = 3fsg E1 . Since M0
satisfies E , there must be a sub-interval I10 of I 0 such that I10 s I 0 and hM 0 ; I10 i satisfies E1 . Let
I1 = V (I10 ), we know from the properties of V that V (I 0 ) = I , and, hence, that I1 s I . Furthermore, we know that hM; I1 i embeds hM 0 ; I10 i, and, thus, by the inductive hypothesis, hM; I1 i
satisfies E1 . Combining these facts, we get that E is satisfied by M. Similar arguments hold for
the remaining three Allen relations. Finally, consider the case when E = E1 ^R E2 , where R can
be any set of Allen relations. Again, it suffices to handle the case when R is a single Allen relation
r. Since M0 satisfies E = E1 ^r E2 , we know that there are sub-intervals I10 and I20 of I 0 such that
S PAN (I10 ; I20 ) = I 0 , I10 r I20 , hM 0 ; I10 i satisfies E1 , and hM 0 ; I20 i satisfies E2 . From these facts, and
the properties of V , it is easy to verify that M satisfies E . 2
Lemma 5. Given an MA formula  that subsumes each member of a set  of MA formulas, 
also subsumes some member 0 of IG(). Dually, when  is subsumed by each member of , we
have that  is also subsumed by some member 0 of IS(). In each case, the length of 0 can be
bounded by the size of .
Proof: We prove the result for IG(). The proof for IS() follows similar lines. Let

 =

f1 ; : : : ; ng,  = s1; : : : ; sm, and assume that for each 1  i  n, i  . From Proposition 2, for each i, there is a witnessing interdigitation Wi for i  . We will combine the Wi

into an interdigitation of , and show that the corresponding member of IG() is subsumed by
. To construct an interdigitation of , first notice that, for each sj , each Wi specifies a set of
states (possibly a single state but at least one) from i that all co-occur with sj . Furthermore, since
Wi is an interdigitation, it is easy to show that this set of states corresponds to a consecutive subsequence of states from i let j;i be the MA timeline corresponding to this subsequence. Now
let j = fj;i j 1  i  ng, and ffj be any interdigitation of j . We now take I to be the union of
all ffj , for 1  j  m. We show that I is an interdigitation of . Since each state s appearing in 
must co-occur with at least one state sj in  in at least one Wi , s will be in at least one tuple of ffj ,
and, hence, be in some tuple of I so I is piecewise total.
Now, define the restriction I i;j of I to components i and j , with i < j , to be the relation given
by taking the set of all pairs formed by shortening tuples of I by omitting all components except
432

fiL EARNING T EMPORAL E VENTS

the ith and the j th. Likewise define ffi;j
k for each k . To show I is an interdigitation, it now suffices
to show that each I i;j is simultaneously consistent. Consider states si and sj from timelines i and
j , respectively, such that I i;j (si ; sj ). Suppose that ti occurs after si in i, and for some tj 2 j ,
I i;j (ti ; tj ) holds. It suffices to show that sj is no later than tj in j . Since I i;j (si ; sj ) and I i;j (ti ; tj ),
i;j
0
0
we must have ffi;j
k (si ; sj ) and ffk (ti ; tj ), respectively, for some k and k . We know k  k because
0
si is before ti in i and Wi is simultaneously consistent. If k = k , then sj is no later than tj in j ,
because ffk must be simultaneously consistent, being an interdigitation. Otherwise, k < k 0 . Then sj
is no later than tj in j , as desired, because Wj is simultaneously consistent. So I is simultaneously
consistent, and an interdigitation of .
Let 0 be the member of IG() corresponding to I . We now show that 0  . We know that
each state s0 2 0 is the intersection of the states in a tuple of some ffj we say that s0 derives from
ffj . Consider the interdigitation I 0 between  and 0 , where I 0 (sj ; s0 ), for sj 2  and s0 2 0 , if and
only if s0 derives from ffj . I 0 is piecewise total, as every tuple of I 0 derives from some ffj , and no ffj
is empty. I 0 is simultaneously consistent because tuples of I 0 deriving from later ffk must be later in
the lexicographic ordering of I , given the simultaneous consistency of the Wk interdigitations used
to construct each ffj . Finally, we know that sj subsumes (i.e., is a subset of) each state in each tuple
of ffj , because each Wk is a witnessing interdigitation to k  , and, hence, subsumes (is a subset
of) the intersection of those states. Therefore, if sj 2  co-occurs with s0 2 0 in I 0 we have that
s0  sj . Thus, I 0 is a witnessing interdigitation for 0  , and by Proposition 2 we have 0  .
The size bound on 0 follows, since, as pointed out in the main text, the size of any member of
IG() is upper-bounded by the number of states in . 2
0

Lemma 8. Given MA timelines 1 = s1 ; : : : ; sm and 2 = t1 ; : : : ; tn , there is a witnessing
interdigitation for 1  2 iff there is a path in the subsumption graph SG(1 ; 2 ) from v1;1 to
vm;n .
Proof: Subsumption
graph SG(1 ; 2 ) is equal to hV; E i with V = fvi;j j 1	  i  m; 1  j  ng

and E = hvi;j ; vi ;j i j si  tj ; si  tj ; i  i0  i + 1; j  j 0  j + 1 . Note that there is a
correspondence between vertices and state tupleswith vertex vi;j corresponding to hsi ; tj i.
For the forward direction, assume that W is a witnessing interdigitation for 1  2 . We
know that, if the states si and tj co-occur in W , then si  tj since W witnesses 1  2 . The
vertices corresponding to the tuples of W will be called co-occurrence vertices, and satisfy the
first condition for belonging to some edge in E (that si  tj ). It follows from the definition of
interdigitation that both v1;1 and vm;n are both co-occurrence vertices. Consider a co-occurrence
vertex vi;j not equal to vm;n , and the lexicographically least co-occurrence vertex vi ;j after vi;j
(ordering vertices
 by ordering
the pair of subscripts). We show that i, j , i0 , and j 0 satisfy the
ff
requirements for vi;j ; vi ;j 2 E . If not, then either i0 > i + 1 or j 0 > j + 1. If i0 > i + 1, then
there can be no co-occurrence vertex vi+1;j , contradicting that W is piecewise total. If j 0 > j + 1,
then since W is piecewise total, there must be a co-occurrence vertex vi ;j +1 : but if i00 < i or
i00 > i0 , this contradicts the simultaneous consistency of W , and if i00 = i, this contradicts the
lexicographically least choice of vi ;j . It follows that every co-occurrence vertex but vm;n has an
edge to another co-occurrence vertex closer in Manhattan distance to vm;n , and thus that there is a
path from v1;1 to vm;n .
For the reverse direction assume there is a path of vertices in SG(1 ; 2 ) from v1;1 to vm;n
given by, vi1 ;j1 ; vi2 ;j2 ; : : : ; vir ;js with i1 = j1 = 1, ir = m; js = n. Let W be the set of state
0

0

0

0

0

0

0

00

00

0

0

433

0

fiF ERN , G IVAN , & S ISKIND

tuples corresponding to the vertices along this path. W must be simultaneously consistent with the
i orderings because our directed edges are all non-decreasing in the i orderings. W must be
piecewise total because no edge can cross more than one state transition in either 1 or 2 , by the
edge set definition. So W is an interdigitation. Finally, the definition of the edge set E ensures
that each tuple hsi ; tj i in W has the property si  tj , so that W is a witnessing interdigitation for
1  2 , showing that 1  2 , as desired. 2
Lemma 10. Given some n, let 	 be the conjunction of the timelines
n
[
i=1

f(PROPn; Truei; Falsei; PROPn); (PROPn; Falsei; Truei; PROPn)g:

We have the following facts about truth assignments to the Boolean variables p1 ; : : : ; pn :
1. For any truth assignment A, PROPn ; sA ; PROPn is semantically equivalent to a member
of IS(	).
2. For each  2 IS(	) there is a truth assignment A such that   PROPn ; sA ; PROPn .
Proof: To prove the first part of the lemma, we construct an interdigitation I of 	 such that the
corresponding member of IS(	) is equivalent to PROPn ; sA ; PROPn . Intuitively, we construct I
by ensuring that some tuple of I consists only of states of the form Truek or Falsek that agree with
the truth assignmentthe union of all the states in this tuple, taken by IS(	) will equal sA . Let
I = fT0 ; T1 ; T2 ; T3 ; T4 g be an interdigitation of 	 with exactly five state tuples Ti . We assign the
states of each timeline of 	 to the tuples as follows:
1. For any k , such that 1  k




 n and A(pk ) is true,

for the timeline s1 ; s2 ; s3 ; s4 = Q; T ruek ; F alsek ; Q, assign each state si to tuple Ti ,
and assign state s1 to T0 as well, and
for the timeline s01 ; s02 ; s03 ; s04 = Q; F alsek ; T ruek ; Q, assign each state s0i to tuple Ti 1 ,
and state s04 to tuple T4 as well.

2. For any k , such that 1  k  n and A(pk ) is false, assign states to tuples as in item 1 while
interchanging the roles of T ruek and F alsek .

It should be clear that I is piecewise total and simultaneously consistent with the state orderings
in 	, and so is an interdigitation. The union of the states in each of T0 , T1 , T3 , and T4 is equal to
PROPn , since PROPn is included as a state in each of those tuples. Furthermore, we see that the
union of the states in T2 is equal to sA . Thus, the member of IS(	) corresponding to I is equal to
PROPn ; PROPn ; sA ; PROPn ; PROPn , which is semantically equivalent to PROPn ; sA ; PROPn , as
desired.
To prove the second part of the lemma, let  be any member of IS(	). We first argue that
every state in  must contain either Truek or Falsek for each 1  k  n. For any k , since 	 contains PROPn ; Truek ; Falsek ; PROPn , every member of IS(	) must be subsumed by PROPn ; Truek ;
Falsek ; PROPn . So,  is subsumed by PROPn ; Truek ; Falsek ; PROPn . But every state in PROPn ;
Truek ; Falsek ; PROPn contains either Truek or Falsek , implying that so does , as desired.
434

fiL EARNING T EMPORAL E VENTS

Next, we claim that for each 1  k  n, either   Truek or   Falsek i.e., either all states
in  include Truek , or all states in  include Falsek (and possibly both). To prove this claim, assume,
for the sake of contradiction, that, for some k ,  6 Truek and  6 Falsek . Combining this assumption with our first claim, we see there must be states s and s0 in  such that s contains T ruek but
not F alsek , and s0 contains F alsek but not T ruek , respectively. Consider the interdigitation I of 	
that corresponds to  as a member of IS(	). We know that s and s0 are each equal to the union of
states in tuples T and T 0 , respectively, of I . T and T 0 must each include one state from each timeline
s1 ; s2 ; s3 ; s4 = PROPn ; Truek ; Falsek ; PROPn and s01 ; s02 ; s03 ; s04 = PROPn ; Falsek ; Truek ; PROPn .
Clearly, since s does not include Falsek , T includes the states s1 and s02 , and likewise T 0 includes
the states s2 and s01 . It follows that I is not simultaneously consistent with the state orderings in
s1 ; s2 ; s3 ; s4 and s01 ; s02 ; s03 ; s04 , contradicting our choice of I as an interdigitation. This shows that
either   Truek or   Falsek .
Define the truth assignment A such that for all 1  k  n, A(pk ) if and only if   Truek .
Since,for each k ,   Truek or   Falsek , it follows that each state of  is subsumed by
sA . Furthermore, since  begins and ends with PROPn , it is easy to give an interdigitation of
 and PROPn ; sA ; PROPn that witnesses   PROPn ; sA ; PROPn . Thus, we have that  
PROPn ; sA ; PROPn . 2
Lemma 16. Let 1 and 2 be as given on page 402, in the proof of Theorem 17, and let 	 =
V
IG(f1 ; 2 g). For any 	0 whose timelines are a subset of those in 	 that omits some square
timeline, we have 	 < 	0 .
Proof: Since the timelines in 	0 are a subset of the timelines in 	, we know that 	  	0 . It remains
to show that 	0 6 	. We show this by constructing a timeline that is covered by 	0 , but not by 	.
Let  = s1 ; s2 ; : : : ; s2n 1 be a square timeline in 	 that is not included in 	0 . Recall that each
si is a single proposition from the proposition set P = fpi;j j 1  i  n; 1  j  ng, and that,
for consecutive states si and si+1 , if si = pi;j , then si+1 is either pi+1;j or pi;j +1 . Define a new
timeline  = s2 ; s3 ; : : : ; s2n 2 with si = (P si ). We now show that  6  (so that  6 	), and
that, for any 0 in 	 fg,   0 (so that   	0 ).
For the sake of contradiction, assume that   then there must be a interdigitation W
witnessing   . We show by induction on i that, for i  2, W (si ; sj ) implies j > i. For the
base case, when i = 2, we know that s2 6 s2 , since s2 6 s2 , and so W (s2 ; s2 ) is false, since
W witnesses subsumption. For the inductive case, assume the claim holds for all i0 < i, and that
W (si ; sj ). We know that si 6 si , and thus i 6= j . Because W is piecewise total, we must have
W (si 1 ; sj ) for some j 0 , and, by the induction hypothesis, we must have j 0 > i 1. Since W is
simultaneously consistent with the sk and sk state orderings, and i 1 < i, we have j 0  j . It
follows that j > i as desired. Given this claim, we see that s2n 2 cannot co-occur in W with any
state in , contradicting the fact that W is piecewise total. Thus we have that  6 .
Let 0 = s01 ; : : : ; s0m be any timeline in 	 fg, we now construct an interdigitation that
witnesses   0 . Note that while  is assumed to be square, 0 need not be. Let j be the smallest
index where sj 6= s0j  since s1 = s01 = p1;1 , and  6= 0 , we know that such a j must exist, and is
in the range 2  j  m. We use the index j to guide our construction of an interdigitation. Let W
be an interdigitation of  and 0 , with exactly the following co-occurring states (i.e., state tuples):
0

0

1. For 1  i  j

1, si+1 co-occurs with s0i .
435

fiF ERN , G IVAN , & S ISKIND

 i  m, sj co-occurs with s0i.
For j + 1  i  2n 2, si co-occurs with s0m .

2. For j
3.

It is easy to check that W is both piecewise total and simultaneously consistent with the state
orderings in  and , and so is an interdigitation. We now show that W witnesses   0 by
showing that all states in  are subsumed by the states they co-occur with in W . For co-occurring
states si+1 and s0i corresponding to the first item above we have that s0i = si this implies that s0i
is contained in si+1 , giving that si+1  s0i . Now consider co-occurring states sj and s0i from the
second item above. Since  is square, choose k and l so that sj 1 = pk;l , we have that sj is either
pk+1;l or pk;l+1. In addition, since sj 1 = s0j 1 we have that s0j is either pk+1;l ; pk;l+1 or pk+1;l+1
but that sj 6= s0j . In any of these cases, we find that no state in 0 after s0j can equal sj this follows
by noting that the proposition indices never decrease across the timeline 0 16 . We therefore have
that, for i  j , sj  s0i . Finally, for co-occurring states si and s0m from item three above, we have
si  s0m , since s0m = pn;n, which is in all states of . Thus, we have shown that for all co-occurring
states in W , the state from  is subsumed by the co-occurring state in 0 . Therefore, W witnesses
  0 , which implies that   0 . 2
Lemma 26. For any model hM; I i 2 M and any 	 2 AMA ,
T [hM; I i].

	 covers hM; I i

iff

F [	] covers

Proof: Recall that M is the set of models over propositions in the set P = fp1 ; : : : ; pn g and that
we assume AMA uses only primitive propositions from P (possibly negated). We also have the
set of propositions P = fp1 ; : : : ; pn g, and assume that formulas in AMA use only propositions in
P [ P and that M is the set of models over P [ P , where for each i, exactly one of pi and pi is
true at any time. Note that F [	] is in AMA and that T [hM; I i] is in M. We prove the lemma via
straightforward induction on the structure of 	proving the result for literals, then for states, then
for timelines, and finally for AMA formulas.
To prove the result for literals, we consider two cases (the third case of true is trivial). First, 	
can be a single proposition pi , so that 	0 = F [pi ] = pi . Consider any model hM; I i 2 M and let
hM 0 ; I i = T [hM; I i]. The following relationships yield the desired result.

	 covers hM; I i

iff
iff
iff

for each i 2 I , M [i] assigns pi true
for each i 2 I , M 0 [i] assigns pi true
	0 = pi covers T [hM; I i]

(by definition of satisfiability)
(by definition of T )
(by definition of satisfiability)

The second case is when 	 is a negated proposition :3pi here, we get that 	0 = pi . Let
hM; I i 2 M and hM 0 ; I i = T [hM; I i]. The following relationships yield the desired result.

	 covers hM; I i

iff
iff
iff

for each i 2 I , M [i] assigns pi false
for each i 2 I , M 0 [i] assigns pi true
	0 = pi covers T [hM; I i]

(by definition of satisfiability)
(by definition of T )
(by definition of satisfiability)

This proves the lemma for literals.
16. Note that if
pk+1;l+1 .

 were not required to be square then it is possible for +1 to equal
0

sj

436

sj

i.e., they could both equal

fiL EARNING T EMPORAL E VENTS

To prove the result for states, we use induction on the number k of literals in a state. The base
case is when k = 1 (the state is a single literal) and was proven above. Now assume that the lemma
holds for states with k or fewer literals and let 	 = l1 ^    ^ lk+1 and hM; I i 2 M. From the
inductive assumption we know that  = l1 ^  ^ lk covers hM; I i iff F [] covers T [hM; I i]. From
our base case we also know that lk+1 covers hM; I i iff F [lk+1 ] covers T [hM; I i]. From these facts
and the definition of satisfiability for states, we get that 	 covers hM; I i iff F [] ^ F [lk+1 ] covers
T [hM; I i]. Clearly F has the property that F [] ^ F [lk+1 ] = F [	], showing that the lemma holds
for states.
To prove the result for timelines, we use induction on the number k of states in the timeline. The
base case is when k = 1 (the timeline is a single state) and was proven above. Now assume that the
lemma holds for timelines with k or fewer states. Let 	 = s1 ; : : : ; sk+1 and hM; [t; t0 ]i 2 M with
hM 0 ; [t; t0 ]i = T [hM; [t; t0 ]i]. We have the following relationships.

	 covers hM; [t; t0 ]i

iff
iff
iff
iff

there exists some t00 2 [t; t0 ], such that s1 covers hM; [t; t00 ]i and
 = s2 ; : : : ; sk+1 covers either hM; [t00 ; t0 ]i or hM; [t00 + 1; t0 ]i
there exists some t00 2 [t; t0 ], such that F [s1 ] covers hM 0 ; [t; t00 ]i and
F [] covers either hM 0 ; [t00 ; t0 ]i or hM 0 ; [t00 + 1; t0 ]i
F [s1 ]; F [] covers hM 0 ; [t; t0 ]i
F [	] covers hM 0 ; [t; t0 ]i

Where the first iff follows from the definition of satisfiability; the second follows from our inductive
hypothesis, our base case, and the fact that for I  [t; t0 ] we have T [hM; I i] = hM 0 ; I i; the third
follows from the definition of satisfiability; and the fourth follows from the fact that F [s1 ]; F [] =
F [	].
Finally, we prove the result for AMA formulas, by induction on the number k of timelines
in the formula. The base case is when k = 1 (the formula is a single timeline) and was proven
above. Now assume that the lemma holds for AMA formulas with with k or fewer timelines
and let 	 = 1 ^    ^ k+1 and hM; I i 2 M. From the inductive assumption, we know that
	0 = 1 ^    ^ k covers hM; I i iff F [	0 ] covers T [hM; I i]. From our base case, we also
know that k+1 covers hM; I i iff F [k+1 ] covers T [hM; I i]. From these facts and the definition of
satisfiability, we get that 	 covers hM; I i iff F [	0 ] ^ F [k+1 ] covers T [hM; I i]. Clearly F has the
property that F [	0 ] ^ F [k+1 ] = F [	], showing that the lemma holds for AMA formulas. This
completes the proof. 2

Appendix C. Hand-coded and Learned Definitions Used in Our Experiments
Below we give the two sets of hand-coded definitions, HD1 and HD2 , used in our experimental
evaluation. We also give a set of learned AMA event definitions for the same seven event types. The
learned definitions correspond to the output of our k -AMA learning algorithm, given all available
training examples (30 examples per event type), with k = 3 and D = BN. All the event definitions
are written in event logic, where :3p denotes the negation of proposition p.

437

fiF ERN , G IVAN , & S ISKIND

1

0

4

P ICK U P (x; y; z )

=

P UT D OWN(x; y; z )

=

S TACK (w; x; y; z )

=

U NSTACK (w; x; y; z )

=

M OVE(w; x; y; z )
A SSEMBLE(w; x; y; z )
D ISASSEMBLE(w; x; y; z )

4

4

4

4
4
=
4
=
=

:3x = y ^ :3z = x ^ :3z = y^
C
B S UPPORTED(y ) ^ :3ATTACHED(x; z )^
B 8 2
3 9 C
C
B >
:3ATTACHED(x; y) ^ :3S UPPORTS(x; y)^
>
>
C
B >
>
7
>
C
B >
>
6
S UPPORTS (z; y )^
>
7
>
C
B >
>
6
>
7
>
C
B >
>
6
:
3
S UPPORTED(x) ^ :3ATTACHED(y; z )^ 7 ; >
>
C
B >
>
6
>
>
C
B >
>
5
4
:3S UPPORTS(y; x) ^ :3S UPPORTS(y; z )^
>
>
C
B >
>
>
>
B >
>
:3S UPPORTS(x; z ) ^ :3S UPPORTS(z; x)
= C
C
B <
C
B
B > [2ATTACHED(x; y ) _ ATTACHED(y; z )] ;
3 > C
>
C
B >
ATTACHED(x; y ) ^ S UPPORTS(x; y )^
>
>
C
B >
>
>
6
7
>
C
B >
>
:3S UPPORTS(z; y)^
>
6
7
>
C
B >
>
>
6
7
>
C
B >
>
:
3
S
UPPORTED
(
x
)
^
:
3
A
TTACHED
(
y;
z
)
^
>
6
7
>
C
B >
>
>
>
>
4
5
A
@ >
:
3
S
UPPORTS
(
y;
x
)
^
:
3
S
UPPORTS
(
y;
z
)
^
>
>
>
>
;
:
:3S UPPORTS(x; z ) ^ :3S UPPORTS(z; x)
1
0
:3x = y ^ :3z = x ^ :3z = y^
C
B S UPPORTED(y ) ^ :3ATTACHED(x; z )^
B 8 2
3 9 C
C
B >
A
TTACHED
(
x; y ) ^ S UPPORTS (x; y )^
>
>
C
B >
>
>
C
7
B >
>
6
:
3
S
UPPORTS
(
z;
y
)
^
>
>
C
7
B >
>
6
>
>
C
B >
>
6
7
:
3
S
UPPORTED
(
x
)
^
:
3
A
TTACHED
(
y;
z
)
^
;
>
>
C
B >
>
6
7
>
>
C
B >
>
4
5
:
3
S
UPPORTS
(
y;
x
)
^
:
3
S
UPPORTS
(
y;
z
)
^
>
>
C
B >
>
>
>
B >
>
:
3
S
UPPORTS
(
x;
z
)
^
:
3
S
UPPORTS
(
z;
x
)
= C
C
B <
C
B
B > [2ATTACHED(x; y ) _ ATTACHED(y; z )] ;
3 > C
>
C
B >
A
TTACHED
(
x; y ) ^ :3 S UPPORTS(x; y )^
:
3
>
>
> C
B >
7 >
>
C
B >
>
6 S UPPORTS (z; y )^
>
>
7 > C
B >
6
>
C
B >
>
6 :3S UPPORTED(x) ^ :3ATTACHED(y; z )^ 7 >
>
>
7 > C
B >
6
>
>
A
@ >
4 :3S UPPORTS(y; x) ^ :3S UPPORTS(y; z )^ 5 >
>
>
>
>
;
:
:3S UPPORTS(x; z ) ^ :3S UPPORTS(z; x)
3
2
:3z = w ^ :3z = x ^ :3z = y^
4 P UT D OWN(w; x; y ) ^ S UPPORTS(z; y )^ 5
:ATTACHED(z; y)


:3z = w ^ :3z = x ^ :3z = y^
P ICK U P (w; x; y ) ^ S UPPORTS(z; y ) ^ :ATTACHED(z; y )
:3y = z ^ [P ICK U P(w; x; y); P UT D OWN(w; x; z )]
P UT D OWN(w; y; z ) ^f g S TACK (w; x; y; z )
U NSTACK(w; x; y; z ) ^f g P ICK U P (x; y; z )
<

<

Figure 12: The HD1 event-logic definitions for all seven event types.

438

fiL EARNING T EMPORAL E VENTS

0

1
:3x = y ^ :3z = x ^ :3z = y^
B
C
(y) ^ :3ATTACHED (x; z )^
B S UPPORTED
C
3
9 C
B 8 2
B >
C
A
TTACHED (x; y ) ^ :3S UPPORTS (x; y )^
:
3
>
>
B >
C
> 6
>
7
>
B >
C
> 6 S UPPORTS (z; y ) ^ C ONTACTS (z; y )^
>
7
>
B >
C
>
>
7
6
>
B >
C
> 6 :3S UPPORTED (x) ^ :3ATTACHED (y; z )^ 7 ^f<;mg >
>
B >
C
>
>
7
6
>
B >
C
>
> 4 :3S UPPORTS (y; x) ^ :3S UPPORTS (y; z )^ 5
>
4
B >
C
>
>
>
P ICK U P (x; y; z ) = B >
= C
<
B
C
S
UPPORTS (x; z ) ^ :3S UPPORTS (z; x)
:
3
3
B
2
C
B >
C
>
A
TTACHED
(
x;
y
)
^
S
UPPORTS
(
x;
y
)
^
>
B >
C
>
> 6
>
7
B >
C
>
>
:
3
S
UPPORTS
(
z;
y
)
^
>
6
7
B >
C
>
> 6
>
7
B >
C
>
>
>
:
3
S
UPPORTED
(
x
)
^
:
3
A
TTACHED
(
y;
z
)
^
6
7
B >
C
> 6
>
>
7
B >
C
>
>
>
4
5
@ >
A
:
3
S
UPPORTS
(
y;
x
)
^
:
3
S
UPPORTS
(
y;
z
)
^
>
>
>
>
;
:
:3S UPPORTS(x; z) ^ :3S UPPORTS(z; x)
0
1
:3x = y ^ :3z = x ^ :3z = y^
C
B
(y) ^ :3ATTACHED (x; z )^
C
B S UPPORTED
3
9 C
B 8 2
C
B >
A
TTACHED (x; y ) ^ S UPPORTS (x; y )^
>
>
C
B >
>
> 6
7
>
C
B >
>
>
S
UPPORTS
(
z;
y
)
^
:
3
7
6
>
C
B >
>
> 6
7
>
C
B >
>
>
:
3
S
UPPORTED
(
x
)
^
:
3
A
TTACHED
(
y;
z
)
^
^
7
6
>
f
<;
m
g
C
B >
>
>
7
> C
> 6
B >
>
5
4
>
:
3
S
UPPORTS
(
y;
x
)
^
:
3
S
UPPORTS
(
y;
z
)
^
4 B>
C
>
>
>
P UT D OWN (x; y; z ) = B >
= C
<
C
B
:
3
S
UPPORTS (x; z ) ^ :3S UPPORTS (z; x)
3
C
B
2
C
B >
>
:
3ATTACHED (x; y) ^ :3S UPPORTS(x; y)^
>
C
B >
>
>
>
6
7
C
B >
>
> 6 S UPPORTS (z; y ) ^ C ONTACTS (z; y )^
>
7
C
B >
>
>
>
6
7
B >
C
>
> 6 :3S UPPORTED (x) ^ :3ATTACHED (y; z )^ 7
>
B >
C
>
>
>
6
7
B >
> C
>
>
4 :3S UPPORTS (y; x) ^ :3S UPPORTS (y; z )^ 5
A
@ >
>
>
>
>
;
:
:3S UPPORTS(x; z) ^ :3S UPPORTS(z; x)

Figure 13: Part I of the HD2 event-logic definitions.

439

fiF ERN , G IVAN , & S ISKIND

0

1

:3w = x ^ :3y = w ^ :3y = x^
B :3z = w ^ :3z = x ^ :3z = y ^
C
B
C
B S UPPORTED (x) ^ :3ATTACHED(w; y )^
C
B 8 2
9 C
3
B >
C
ATTACHED(w; x) ^ S UPPORTS (w; x)^
>
B >
>
C
> 6
>
B >
7
>
C
:
3
S UPPORTS(y; x)^
>
B >
>
7
>
6
C
> 6
>
B >
7
>
C
S UPPORTS(z; y ) ^ C ONTACTS(z; y )^
>
B >
7
>
6
>
C
> 6
>
B >
7
C
>
:
3
ATTACHED(z; y )^
^
f
mg >
B >
7
6
C
>
>
> 6
>
7
B >
C
>
:
3
S UPPORTED(w) ^ :3ATTACHED(x; y )^ 7
>
B >
6
C
>
>
> 4
>
B >
C
>
5
:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^
>
B >
>
>
= C
B <
C
B
C
2 :3S UPPORTS(w; y ) ^ :3S UPPORTS(y; w)
3
B >
C
:3ATTACHED(w; x) ^ :3S UPPORTS(w; x)^
>
B >
C
>
>
B >
C
6
7
>
>
S UPPORTS(y; x) ^ C ONTACTS (y; x)^
>
B >
C
6
7
>
>
>
B >
C
6
7
>
>
>
B >
C
6 S UPPORTS(z; y ) ^ C ONTACTS(z; y )^
7
>
>
>
>
B >
C
6
7
>
>
B >
C
7
> 6 :3ATTACHED(z; y )^
>
>
>
B >
C
6
7
>
>
B >
C
> 6 :3S UPPORTED(w) ^ :3ATTACHED(x; y )^ 7
>
>
>
>
@ >
A
4
5
:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^
>
>
>
>
:
;
:3S UPPORTS(w; y) ^ :3S UPPORTS(y; w)
1
0
:3w = x ^ :3y = w ^ :3y = x^
C
B :3z = w ^ :3z = x ^ :3z = y ^
C
B
C
B S UPPORTED(x) ^ :3ATTACHED(w; y )^
9 C
B 8 2
3
C
B >
:3ATTACHED(w; x) ^ :3S UPPORTS(w; x)^
>
C
>
B >
>
C
>
6
B >
7
>
>
C
>
6 S UPPORTS (y; x) ^ C ONTACTS (y; x)^
B >
7
>
>
>
C
>
6
B >
7
>
C
>
B >
7
> 6 S UPPORTS (z; y ) ^ C ONTACTS (z; y )^
>
>
C
>
6
B >
7
C
>
6 :3ATTACHED(z; y )^
B >
7 ^f mg >
>
>
>
C
>
6
B >
7
>
C
>
B >
> 6 :3S UPPORTED(w) ^ :3ATTACHED(x; y )^ 7
>
>
C
>
B >
4
5
:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^
>
C
>
B >
>
=
<
C
B
C
B
2 :3S UPPORTS(w; y ) ^ :3S UPPORTS(y; w) 3
C
B >
ATTACHED(w; x) ^ S UPPORTS(w; x)^
>
C
>
B >
>
>
6
C
7
>
B >
>
C
7
>
B >
> 6 :3S UPPORTS(y; x)^
>
>
6
C
7
>
B >
>
6 S UPPORTS (z; y ) ^ C ONTACTS (z; y )^
C
7
>
B >
>
>
>
6
C
7
>
B >
>
C
7
>
B >
> 6 :3ATTACHED(z; y )^
>
>
6
C
7
>
B >
>
C
>
B >
> 6 :3S UPPORTED(w) ^ :3ATTACHED(x; y )^ 7
>
>
>
4
A
5
@ >
:3S UPPORTS(x; w) ^ :3S UPPORTS(x; y)^
>
>
>
>
;
:
:3S UPPORTS(w; y) ^ :3S UPPORTS(y; w)
:3y = z ^ [P ICK U P(w; x; y); P UT D OWN(w; x; z )]
P UT D OWN(w; y; z ) ^f g S TACK (w; x; y; z )
U NSTACK (w; x; y; z ) ^f g P ICK U P (x; y; z )
<;

S TACK(w; x; y; z )

4

=

<;

U NSTACK(w; x; y; z )

M OVE(w; x; y; z )
A SSEMBLE(w; x; y; z )
D ISASSEMBLE(w; x; y; z )

4

=

4
4
=
4
=
=

<

<

Figure 14: Part II of the HD2 event-logic definitions.

440

fiL EARNING T EMPORAL E VENTS

3 9
0 8 2
S UPPORTED (y ) ^ S UPPORTS (z; y )^
>
>
>
>
>
B >
> 4 C ONTACTS (y; z ) ^ : S UPPORTS(x; y )^
5; >
>
>
B >
>
>
>
B >
>
: ATTACHED(x; y) ^ : ATTACHED(y; z )
=
B <
B
S UPPORTED(y );
B > 2
3 >^
>
B >
S UPPORTED (y ) ^ S UPPORTS (x; y )^
>
>
>
B >
>
>
B >
>
5
4
ATTACHED(x; y ) ^ : S UPPORTS(z; y )^
>
>
>
B >
;
:
B
: C ONTACTS(y; z ) ^ : ATTACHED(y; z9)
B 8
B > S UPPORTED(y );
>
B >

 >
=
B <
S UPPORTED(y ) ^ ATTACHED(x; y )^
B
;
^
B >
ATTACHED(y; z )
>
B >
>
:
;
B
B 8 [S UPPORTED(y ) ^ ATTACHED(x; y )] 9
B < [S UPPORTED(y ) ^ C ONTACTS (y; z )] ; =
B
B
B : [S UPPORTED(y ) ^ ATTACHED(y; z )] ; ; ^
B
B 8 [2S UPPORTED(y ) ^ ATTACHED(x; y )]
3 9
B >
S UPPORTED (y ) ^ S UPPORTS (z; y )^
>
>
B >
>
> 4 C ONTACTS (y; z ) ^ : S UPPORTS(x; y )^
B >
5; >
=
B <
B
:
A
TTACHED
(
x; y ) ^ : ATTACHED(y; z )
^
B >
>
>
B >
[
S
UPPORTED
(
y
)
^
S
UPPORTS
(
z;
y
)]
;
>
>
>
B >
;
B : [S UPPORTED(y ) ^ ATTACHED(x; y )]
9
B 8
B > [S UPPORTED(y ) ^ S UPPORTS (z; y )] ;
>
>
B >
>
>
> [S UPPORTED(y ) ^ ATTACHED(x; y )] ;
B >
B < 2
3 =
B
S
UPPORTED
(
y ) ^ S UPPORTS (x; y )^
B >
>
5 >
@ >
>
> 4 ATTACHED(x; y ) ^ : S UPPORTS(z; y )^
>
>
:
;

3

3

3

3

P ICK U P (x; y; z )

4

=

3

3

3

3

3

3

:3C ONTACTS(y; z ) ^ :3ATTACHED(y; z )

P UT D OWN(x; y; z )

4

=

1
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
A

3 9
0 8 2
S UPPORTED(y ) ^ S UPPORTS(x; y ) ^ ATTACHED(x; y )^
>
>
>
>
> 4 : S UPPORTS(z; y ) ^ : C ONTACTS(y; z )^
>
B >
5; >
>
B >
>
>
=
B <
: ATTACHED(y; z )
B
^
B > S UPPORTED (y );
>
>
B >


>
>
>
B >
S UPPORTED(y ) ^ S UPPORTS (z; y ) ^ C ONTACTS(z; y )^
>
B >
>
>
;
B :
:
S
UPPORTS
(
x; y ) ^ :
A
TTACHED
(
x; y )
B 8 
9

B <
B
 S UPPORTED (y ) ^ ATTACHED(x; y ) ;
 =
@
S UPPORTED (y ) ^ ATTACHED(x; y ) ^ ATTACHED(y; z ) ;
:
;

3
3

3

3

3

S UPPORTED (y )

Figure 15: The learned 3-AMA definitions for P ICK U P (x; y; z ) and P UT D OWN (x; y; z ).

441

1
C
C
C
C
C
C
C
C
C
C
C
C
A

fiF ERN , G IVAN , & S ISKIND

0 8
>
>
B <
B
B >
B >
B :
B (
B
B
B
B
B (
B
B
B
B
B (
B
B
B
B
B (
B
B
B
B
B (
B
B
B
B
B 8
B <
B
B
B :
B
B (
B
B
B
B
B (
B
B
B
B
B 8
B
B <
B
B
B :
B 8
B
B <
B
B
B :
B
B (
B
B
B
B
B 8
B <
B
B
B :
B
B 8
B >
B >
B <
B
@ >
>
:

h

^

^

^

^

S UPPORTED(y ) ATTACHED(w; x) S UPPORTS(z; y ) C ONTACTS(y; z )
S UPPORTS(x; y )
S UPPORTS(y; x)
C ONTACTS(x; y )
ATTACHED(x; y )

:3

^ :3

^ :3

^ :3

i

;

9
>
>
=

1

C
C
i >^ C
S UPPORTED(y ) ^ S UPPORTED(x) ^ S UPPORTS(y; x) ^ C ONTACTS(x; y ) ^ C ONTACTS(y; z )^
>
; C
C
:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y) ^ :3)ATTACHED(y; z)
C
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
C
[S UPPORTED(y) ^ ATTACHED(x; y)] ;
^
C
C
[S UPPORTED(y) ^ S UPPORTED(x) ^ S UPPORTS(y; x) ^ C ONTACTS(x; y)]
)
C
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
[S UPPORTED(y) ^ S UPPORTS(x; y) ^ ATTACHED(w; x) ^ ATTACHED(x; y) ^ ATTACHED(y; z)] ; ^ C
C
C
[S UPPORTED(y) ^ S UPPORTED(x)S UPPORTS(y; x)]
)
C
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
C
[S UPPORTED(y) ^ S UPPORTED(x) ^ S UPPORTS(x; y) ^ S UPPORTS(y; x) ^ ATTACHED(w; x)] ; ^
C
C
[S UPPORTED(y) ^ S UPPORTED(x) ^ S UPPORTS(y; x)]
)
C
C
[S UPPORTED(y) ^ ATTACHED(w; x) ^ S UPPORTS(z; y) ^ C ONTACTS(y; z)] ;
C
[S UPPORTED(y) ^ ATTACHED(y; z)] ;
^
C
C
[S UPPORTED(y) ^ S UPPORTED(x) ^ S UPPORTS(y; x) ^ C ONTACTS(y; z)] )
C
C
[S UPPORTED(y) ^ ATTACHED(w; x) ^ S UPPORTS(z; y) ^ C ONTACTS(y; z)] ;
C
[S UPPORTED(y) ^ ATTACHED(w; x) ^ ATTACHED(y; z)] ;
^
C
C
[hS UPPORTED(y) ^ S UPPORTED(x) ^ S UPPORTS(y; x)]
i 9
C
S UPPORTED(y ) ^ ATTACHED(w; x) ^ S UPPORTS(z; y ) ^ C ONTACTS(y; z )^
C
=
;
C
:3S UPPORTS(x; y) ^ :3S UPPORTS(y; x) ^ :3C ONTACTS(x; y) ^ :3ATTACHED(x; y)
C
^
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
;
C
[S UPPORTED(y) ^ S UPPORTED(x) ^ S UPPORTS(y; x)]
C
)
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
C
[S UPPORTED(y) ^ ATTACHED(w; x) ^ S UPPORTS(z; y) ^ C ONTACTS(y; z)] ; ^
C
C
[S UPPORTED(y) ^ S UPPORTED(x)]
C
)
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
C
[S UPPORTED(y) ^ ATTACHED(w; x) ^ S UPPORTS(z; y) ^ S UPPORTED(x)] ; ^
C
C
[S UPPORTED(y) ^ S UPPORTED(x)]
C
9
C
[hS UPPORTED(y) ^ ATTACHED(w; x)] ;
i =
C
S UPPORTED(y ) ^ C ONTACTS(y; z ) ^ S UPPORTS(z; y ) ^ S UPPORTED(x)^
C
;
^
C
:3S UPPORTS(x; y) ^ :3ATTACHED(x; y)
;
C
C
[S UPPORTED(y) ^ S UPPORTED(x)]
9
C
S UPPORTED(y );
C
h
i =
C
S UPPORTED(y ) ^ C ONTACTS(y; z ) ^ S UPPORTS(z; y ) ^ S UPPORTED(x)^
^
;
C
:3S UPPORTS(x; y) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)
C
;
C
[S UPPORTED(y) ^ S UPPORTED(x) ^ S UPPORTS(y; x)] )
C
C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
C
[S UPPORTED(y) ^ C ONTACTS(y; z) ^ S UPPORTED(x)] ; ^
C
C
[S UPPORTED(y) ^ S UPPORTED(x) ^ S UPPORTED(y)x]
9 C
[S UPPORTED(y) ^ ATTACHED(w; x)] ;
= C
C
[hS UPPORTED(y) ^ S UPPORTED(x) ^ S UPPORTS(y; x)] ;
i
^C
S UPPORTED(y ) ^ S UPPORTED(x) ^ S UPPORTS(y; x) ^ C ONTACTS(x; y ) ^ C ONTACTS(y; z )^
; C
C
:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)
9 C
S
UPPORTED(y );
> C
h
i
>
= C
S UPPORTED(y ) ^ S UPPORTED(x) ^ S UPPORTS(y; x) ^ S UPPORTS(z; y )^
C
;
C
C
ONTACTS(x; y ) ^ C ONTACTS(y; z )
h
i > A
S UPPORTED(y ) ^ S UPPORTED(x) ^ S UPPORTS(y; x) ^ C ONTACTS(x; y ) ^ C ONTACTS(y; z )^
>
;

[S UPPORTED(y)] ;
h

:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)

Figure 16: The learned 3-AMA definition for S TACK (w; x; y; z ).

442

fiL EARNING T EMPORAL E VENTS

0 8
>
>
B >
>
B >
>
B >
>
B <
B
B >
B >
>
B >
B >
>
>
B >
B :
B
B (
B
B
B
B
B (
B
B
B
B
B
B (
B
B
B
B
B (
B
B
B
B
B 8
B
B >
>
B >
>
B >
B <
B
B >
B >
>
B >
:
B >
B 8
B
B >
>
B >
>
B >
B <
B
B >
B >
>
B >
>
B :
B
B (
B
B
B
B
B 8
B
B >
<
B
B
B >
B :
B
B (
B
B
B
B
B (
B
B
B
B
B
B 8
B >
B <
B
@
>
:

"

#

9

S UPPORTED(x) ^ S UPPORTED(y ) ^ S UPPORTS(y; x)^
>
>
>
;
C ONTACTS(x; y ) ^ C ONTACTS(y; z ) ^ :3S UPPORTS(w; x)^
>
>
>
>
:3S UPPORTS(x; y) ^ :3ATTACHED(w; x) ^ :3ATTACHED(x; y)
>
=
[2S UPPORTED(x) ^ S UPPORTED(y)] ;
3
^
S UPPORTED(x) ^ S UPPORTED(y ) ^ ATTACHED(w; x) ^ S UPPORTS(z; y )^
>
>
>
6 C ONTACTS(y; z ) ^ ATTACHED(w; x) ^ :3S UPPORTS(x; y )^
7 >
>
4
5 >
>
:3S UPPORTS(y; x) ^ :3C ONTACTS(x; y)^
>
;
:3ATTACHED(x; y) ^ :3ATTACHED(y; z)
)
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x)] ;
[S UPPORTED(x) ^ S UPPORTED(y) ^ ATTACHED(w; x) ^ ATTACHED(y; z)] ; ^
[S UPPORTED(x) ^ S UPPORTED(y) ^ ATTACHED(w; x) ^ C ONTACTS(y; z)] )
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x) ^ C ONTACTS(y; z)] ;
[S UPPORTED(x) ^ S UPPORTED(y) ^ ATTACHED(y; z)] ;
^
[S UPPORTED(x) ^ S UPPORTED(y) ^ ATTACHED(w; x) ^ C ONTACTS(y; z)] )
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x) ^ C ONTACTS(x; y)] ;
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x) ^ ATTACHED(x; y)] ; ^
[S UPPORTED(x) ^ S UPPORTED(y) ^ ATTACHED(w; x)] )
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x)] ;
[S UPPORTED(x) ^ S UPPORTED(y) ^ C ONTACTS(y; z)] ; ^
[S UPPORTED(x) ^ S UPPORTED(y) ^ ATTACHED(w; x)]
9
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x)] ;
>
>
>
>
[2S UPPORTED(x) ^ S UPPORTED(y) ^ ATTACHED(w; x)] ;
3 >
=
S UPPORTED(x) ^ S UPPORTED(y ) ^ ATTACHED(w; x) ^ S UPPORTS(z; y )^
^
7 >
6 C ONTACTS(y; z ) ^ ATTACHED(w; x) ^ :3S UPPORTS(x; y )^
5 >
4
>
>
:3S UPPORTS(y; x) ^ :3C ONTACTS(x; y)^
>
;
ATTACHED(x; y ) ^ :3ATTACHED(y; z )
:
3
2
3 9
S UPPORTED(x) ^ S UPPORTED(y ) ^ S UPPORTS(y; x)^
>
>
>
6 C ONTACTS(x; y ) ^ C ONTACTS(y; z )^
7 >
>
4
5; =
:3S UPPORTS(w; x) ^ :3S UPPORTS(x; y)^
^
:3ATTACHED(w; x) ^ :3ATTACHED(x; y)
>
>
>
>
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x)] ;
>
;
[S UPPORTED(x) ^ S UPPORTED(y) ^ ATTACHED(w; x)]
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x) ^ C ONTACTS(y; z)] ; )
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x) ^ ATTACHED(y; z)] ; ^
[S UPPORTED(x) ^ S UPPORTED(y) ^ ATTACHED(w; x)]
9
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x)] ;

 >
=
S UPPORTED(x) ^ S UPPORTED(y ) ^ S UPPORTS(y; x) ^ ATTACHED(y; z )^
^
;
S UPPORTS(x; y ) ^ ATTACHED(w; x) ^ ATTACHED(x; y )
>
;
[S UPPORTED(x) ^ S UPPORTED(y) ^ ATTACHED(w; x)]
)
[S UPPORTED(x) ^ S UPPORTED(y)] ;
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x) ^ ATTACHED(w; x)] ; ^
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(w; x) ^ ATTACHED(w; x)] )
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x)] ;
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(w; x) ^ ATTACHED(w; x)] ; ^
[S UPPORTED(x) ^ S UPPORTED(y) ^ ATTACHED(w; x)]
9
[S UPPORTED(x) ^ S UPPORTED(y) ^ S UPPORTS(y; x)] ;

 >
=
S UPPORTED(x) ^ S UPPORTED(y ) ^ C ONTACTS(y; z )^
;
:3S UPPORTS(x; y) ^ :3ATTACHED(x; y) ^ :3ATTACHED(y; z)
>
;
[S UPPORTED(x) ^ S UPPORTED(y)]

Figure 17: The learned 3-AMA definition for U NSTACK (w; x; y; z ).

443

1
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
A

fiF ERN , G IVAN , & S ISKIND

0 8
>
>
>
B >
>
B >
>
B >
>
B >
B <
B
B >
B >
>
B >
>
B >
>
B >
>
B >
B :
B 8
B >
B <
B
B
B >
B :
B 8
B >
B <
B
B
B >
B :
B 8
B >
B <
B
B
B >
B :
B 8
B >
B <
B
B
B >
B :
B 8
B >
B <
B
B
B >
B :
B 8
B >
B <
B
@
>
:

2
6
4

S UPPORTED (x) ^ S UPPORTS (y; x) ^ C ONTACTS (y; x)^
:3S UPPORTS(w; x) ^ :3S UPPORTS(z; x) ^ :3C ONTACTS(x; z)^
:3ATTACHED(w; x) ^ :3ATTACHED (y; x) ^ :3ATTACHED (x; z)

3
7
5

S UPPORTED (x);
S UPPORTED (x) ^ S UPPORTS (z; x) ^ C ONTACTS (x; z )^
6
:
4 3S UPPORTS (w; x) ^ :3S UPPORTS (y; x) ^ :3C ONTACTS (y; x)^
:3ATTACHED(w; x) ^ :3ATTACHED9(y; x) ^ :3ATTACHED (x; z)
[S UPPORTED (x) ^ S UPPORTS (y; x)] ; >
=
[S UPPORTED (x) ^ ATTACHED (w; x)] ; > ^
;
S UPPORTED (x)
9
>
S UPPORTED (x);
=
[S UPPORTED (x) ^ ATTACHED (w; x) ^ ATTACHED (x; z )] ; > ^
;
S UPPORTED (x)
9
>
[S UPPORTED (x)] ;
=
[S UPPORTED (x) ^ ATTACHED (x; z )] ; > ^
[S UPPORTED (x) ^ C ONTACTS (x; z )] ;
9
>
S UPPORTED (x);
=
[S UPPORTED (x) ^ ATTACHED (w; x) ^ S UPPORTS (w; x)] ; > ^
;
S UPPORTED (x)
9
>
S UPPORTED (x);
=
[S UPPORTED (x) ^ ATTACHED (w; x) ^ ATTACHED (y; x)] ; > ^
;
S UPPORTED (x)
9
[S UPPORTED (x) ^ C ONTACTS (y; x)] ; >
=
[S UPPORTED (x) ^ ATTACHED (y; x)] ; >
;
S UPPORTED (x)
2

Figure 18: The learned 3-AMA definition for M OVE (w; x; y; z ).

444

3
7
5

;

9
>
>
>
>
>
>
>
>
>
>
=
>
>
>
>
>
>
>
>
>
>
;

1

^

C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
A

fiL EARNING T EMPORAL E VENTS

0 8
>
>
>
B >
>
>
B >
B >
>
>
B <
B
B
B >
B >
>
B >
>
B >
>
B >
>
B >
:
B
B 8
B >
B >
B >
>
B >
<
B
B
B >
B >
>
B >
>
B :
B 8
B
B >
B <
B
B >
B :
B 8
B
B >
B <
B
B >
B :
B 8
B
B >
B <
B
B >
B :
B 8
B
B >
B <
@
>
:

2

3

9

:3S UPPORTED (x) ^ :3S UPPORTS(z; y) ^ :3S UPPORTS(y; x)^ 7 >
>
>
6
>
:
4 3C ONTACTS (x; y ) ^ :3C ONTACTS (z; y )^
5; >
>
>
>
>
>
:3ATTACHED(w; x) ^ :3ATTACHED (z; y)
=

true
;
2
6
4
2
6
4

3

S UPPORTED (x) ^ S UPPORTED (y ) ^ S UPPORTS (z; y )^
7
S UPPORTS (y; x) ^ C ONTACTS (x; y )^
5
C ONTACTS (z; y ) ^ :3ATTACHED (w; y )
:3S UPPORTED (x) ^ :3S UPPORTS(z; y) ^ :3S UPPORTS(y; x)^
:3C ONTACTS(x; y) ^ :3C ONTACTS(z; y)^
:3ATTACHED(w; x) ^ :3ATTACHED (z; y)

ATTACHED (w; y );
S UPPORTED (y )

9
>
=

true;

3
7
5

;

>
>
>
>
>
>
>
>
>
>
;
9
>
>
>
>
>
=
>
>
>
>
>
;

[S UPPORTED (y) ^ :3ATTACHED (w; x) ^ :3ATTACHED (z; y)] ; > ^
;
S UPPORTED (y )
9
>
true;
=
[S UPPORTED (y) ^ ATTACHED (z; y)] ; > ^
[S UPPORTED (y) ^ C ONTACTS (z; y)] ;
true;
[S UPPORTED (y) ^ S UPPORTS (z; y)C ONTACTS (z; y) ^ ATTACHED (w; x)] ;
S UPPORTED (y )
9
>
true;
=
[S UPPORTED (y) ^ ATTACHED (w; y)ATTACHED (z; y)] ; >
;
S UPPORTED (y )
Figure 19: The learned 3-AMA definition for A SSEMBLE (w; x; y; z ).

445

1

^

^

9
>
=
>
;

^

C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
A

fiF ERN , G IVAN , & S ISKIND

0 8
>
>
B >
>
B >
>
B >
>
B >
>
B <
B
B >
B >
B >
>
B >
>
B >
>
B >
>
B :
B 8
B >
B >
B <
B
B >
B >
B :
B 8
B >
B >
B <
B
B >
B >
B :
B 8
B >
B >
B <
B
B >
B >
B :
B 8
B >
B >
B <
B
B >
B >
B :
B 8
B <
B
B
B :
B
B 8
B <
B
@
:

3

2

9

S UPPORTED (x) ^ S UPPORTED(y ) ^ S UPPORTS(y; x) ^ S UPPORTS (z; y )^
>
>
7 >
>
6 C ONTACTS (x; y ) ^ C ONTACTS(z; y ) ^ : S UPPORTS(w; x)^
7; >
>
6
>
5 >
4 : S UPPORTS(w; y ) ^ : S UPPORTS(x; y ) ^ : ATTACHED(x; w)^
>
>
=
: ATTACHED(w; y) ^ : ATTACHED(x; y) ^ : ATTACHED(z; y)
^
S UPPORTED(y );
>
>
2
3
>
>
S UPPORTED (y ) ^ : S UPPORTED(x) ^ : S UPPORTS(w; x)^
>
>
>
>
4 : S UPPORTS(z; y ) ^ : S UPPORTS(y; x) ^ : C ONTACTS(x; y )^ 5 ;
>
>
;
: C ONTACTS(z; y) ^ : ATTACHED(x; w) ^ : ATTACHED9(z; y)
[ S UPPORTED (x) ^ S UPPORTED (y )] ;
>

 >
=
S UPPORTED(x) ^ S UPPORTED (y ) ^ S UPPORTS (w; x)^
^
;
S UPPORTS(z; y ) ^ C ONTACTS (z; y ) ^ ATTACHED(x; w)
>
>
;
S UPPORTED(y )
9


S UPPORTED(x) ^ S UPPORTED (y ) ^ S UPPORTS (z; y )^
>
>
;
=
S UPPORTS(y; x) ^ C ONTACTS (x; y ) ^ C ONTACTS(z; y )
^
[ S UPPORTED (x) ^ S UPPORTED (y ) ^ S UPPORTS (y; x) ^ ATTACHED (x; y )] ; >
>
;
S UPPORTED(y )
9
[ S UPPORTED (x) ^ S UPPORTED (y ) ^ S UPPORTS (y; x) ^ C ONTACTS (z; y )] ; >
>


=
S UPPORTED(x) ^ S UPPORTED (y ) ^ S UPPORTS (x; y )^
;
^
S UPPORTS(y; z ) ^ ATTACHED(x; y ) ^ ATTACHED(z; y )
>
>
;
S UPPORTED(y )
9
[ S UPPORTED (x) ^ S UPPORTED (y ) ^ S UPPORTS (y; x)] ;
>
 >

=
S UPPORTED(x) ^ S UPPORTED (y ) ^ S UPPORTS (x; y )^
;
^
S UPPORTS(y; z ) ^ ATTACHED(x; y ) ^ ATTACHED(z; y ) ^ ATTACHED(x; w)
>
>
;
S UPPORTED(y )
9
S UPPORTED(y );
=
[ S UPPORTED (y ) ^ ATTACHED (w; y ) ^ ATTACHED (z; y )] ;
^
;
S UPPORTED(y )
9
S UPPORTED(y );
=
[ S UPPORTED (y ) ^ S UPPORTS (w; y ) ^ ATTACHED (w; y )] ;
;
S UPPORTED(y )

3
3

3
3

3
3

3

3
3

3

3

3
3

3
3

Figure 20: The learned 3-AMA definition for D ISASSEMBLE (w; x; y; z ).

446

1
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
A

fiL EARNING T EMPORAL E VENTS

References
Agrawal, R., & Srikant, R. (1995). Mining sequential patterns. In Proceedings of the Eleventh
International Conference on Data Engineering, pp. 314.
Allen, J. F. (1983). Maintaining knowledge about temporal intervals. Communications of the ACM,
26(11), 832843.
Angluin, D. (1987). Learning regular sets from queries and counterexamples. Information and
Computation, 75, 87106.
Bacchus, F., & Kabanza, F. (2000). Using temporal logics to express search control knowledge for
planning. Artificial Intelligence, 16, 123191.
Bobick, A. F., & Ivanov, Y. A. (1998). Action recognition using probabilistic parsing. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,
pp. 196202, Santa Barbara, CA.
Borchardt, G. C. (1985). Event calculus. In Proceedings of the Ninth International Joint Conference
on Artificial Intelligence, pp. 524527, Los Angeles, CA.
Brand, M. (1997a). The inverse Hollywood problem: From video to scripts and storyboards via
causal analysis. In Proceedings of the Fourteenth National Conference on Artificial Intelligence, pp. 132137, Providence, RI.
Brand, M. (1997b). Physics-based visual understanding. Computer Vision and Image Understanding, 65(2), 192205.
Brand, M., & Essa, I. (1995). Causal analysis for visual gesture understanding. In Proceedings of
the AAAI Fall Symposium on Computational Models for Integrating Language and Vision.
Brand, M., Oliver, N., & Pentland, A. (1997). Coupled hidden Markov models for complex action
recognition. In Proceedings of the IEEE Computer Society Conference on Computer Vision
and Pattern Recognition.
Cohen, P. (2001). Fluent learning: Elucidating the structure of episodes. In Proceedings of the
Fourth Symposium on Intelligent Data Analysis.
Cohen, W. (1994). Grammatically biased learning: Learning logic programs using an explicit antecedent description lanugage. Artificial Intelligence, 68, 303366.
Cohen, W., & Hirsh, H. (1994). Learning the CLASSIC description logic: Theoretical and experimental results. In Proceedings of the Fourth International Conference on Principles of Knowledge
Representation and Reasoning, pp. 121133.
De Raedt, L., & Dehaspe, L. (1997). Clausal discovery. Machine Learning, 26, 99146.
Dehaspe, L., & De Raedt, L. (1996). DLAB: A declarative language bias formalism. In Proceedings
of the Ninth International Syposium on Methodologies for Intelligent Systems, pp. 613622.
Fikes, R., & Nilsson, N. (1971). STRIPS: A new approach to the application of theorem proving to
problem solving. Artificial Intelligence, 2(3/4).
Hoppner, F. (2001). Discovery of temporal patternsLearning rules about the qualitative behaviour
of time series. In Proceedings of the Fifth European Conference on Principles and Practice
of Knowledge Discovery in Databases.
447

fiF ERN , G IVAN , & S ISKIND

Kam, P., & Fu, A. (2000). Discovering temporal patterns for interval-based events. In Proceedings
of the Second International Conference on Data Warehousing and Knowledge Discovery.
Klingspor, V., Morik, K., & Rieger, A. D. (1996). Learning concepts from sensor data of a mobile
robot. Artificial Intelligence, 23(2/3), 305332.
Lang, K., Pearlmutter, B., & Price, R. (1998). Results of the Abbadingo one DFA learning competition and a new evidence-driven state merging algorithm. In Proceedings of the Fourth
International Colloquium on Grammatical Inference.
Lavrac, N., Dzeroski, S., & Grobelnik, M. (1991). Learning nonrecursive definitions of relations
with LINUS. In Proceedings of the Fifth European Working Session on Learning, pp. 265
288.
Mann, R., & Jepson, A. D. (1998). Toward the computational perception of action. In Proceedings
of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp.
794799, Santa Barbara, CA.
Mannila, H., Toivonen, H., & Verkamo, A. I. (1995). Discovery of frequent episodes in sequences.
In Proceedings of the First International Conference on Knowledge Discovery and Data Mining.
Mitchell, T. (1982). Generalization as search. Artificial Intelligence, 18(2), 51742.
Morales, E. (1997). Pal: A pattern-based first-order inductive system. Machine Learning, 26, 227
252.
Muggleton, S. (1995). Inverting entailment and Progol. Machine Intelligence, 14, 133188.
Muggleton, S., & Feng, C. (1992). Efficient induction of logic programs. In Muggleton, S. (Ed.),
Inductive Logic Programming, pp. 281298. Academic Press.
Muggleton, S., & De Raedt, L. (1994). Inductive logic programming: Theory and methods. Journal
of Logic Programming, 19/20, 629679.
Pinhanez, C., & Bobick, A. (1995). Scripts in machine understanding of image sequences. In
Proceedings of the AAAI Fall Symposium Series on Computational Models for Integrating
Language and Vision.
Plotkin, G. D. (1971). Automatic Methods of Inductive Inference. Ph.D. thesis, Edinburgh University.
Regier, T. P. (1992). The Acquisition of Lexical Semantics for Spatial Terms: A Connectionist Model
of Perceptual Categorization. Ph.D. thesis, University of California at Berkeley.
Roth, D., & Yih, W. (2001). Relational learning via propositional algorithms: An information extraction case study. In Proeedings of the Seventeenth International Joint Conference on Artificial
Intelligence.
Shoham, Y. (1987). Temporal logics in AI: Semantical and ontological considerations. Artificial
Intelligence, 33(1), 89104.
Siskind, J. M. (2000). Visual event classification via force dynamics. In Proceedings of the Seventeenth National Conference on Artificial Intelligence, pp. 149155, Austin, TX.
Siskind, J. M. (2001). Grounding the lexical semantics of verbs in visual perception using force
dynamics and event logic. Journal of Artificial Intelligence Research, 15, 3190.
448

fiL EARNING T EMPORAL E VENTS

Siskind, J. M., & Morris, Q. (1996). A maximum-likelihood approach to visual event classification. In Proceedings of the Fourth European Conference on Computer Vision, pp. 347360,
Cambridge, UK. Springer-Verlag.
Talmy, L. (1988). Force dynamics in language and cognition. Cognitive Science, 12, 49100.
Yamoto, J., Ohya, J., & Ishii, K. (1992). Recognizing human action in time-sequential images using
hidden Markov model. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 379385.

449

fi