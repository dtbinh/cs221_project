Journal of Articial Intelligence Research 38 (2010) 85-133

Submitted 05/09; published 05/10

BnB-ADOPT:
An Asynchronous Branch-and-Bound DCOP Algorithm
William Yeoh

wyeoh@usc.edu

Computer Science Department,
University of Southern California,
Los Angeles, CA 90089, USA

Ariel Felner

felner@bgu.ac.il

Information Systems Engineering,
Deutsche Telekom Labs,
Ben-Gurion University of the Negev,
Beer-Sheva, 85104, Israel

Sven Koenig

skoenig@usc.edu

Computer Science Department,
University of Southern California,
Los Angeles, CA 90089, USA

Abstract
Distributed constraint optimization (DCOP) problems are a popular way of formulating and
solving agent-coordination problems. A DCOP problem is a problem where several agents coordinate their values such that the sum of the resulting constraint costs is minimal. It is often
desirable to solve DCOP problems with memory-bounded and asynchronous algorithms. We introduce Branch-and-Bound ADOPT (BnB-ADOPT), a memory-bounded asynchronous DCOP search
algorithm that uses the message-passing and communication framework of ADOPT (Modi, Shen,
Tambe, & Yokoo, 2005), a well known memory-bounded asynchronous DCOP search algorithm,
but changes the search strategy of ADOPT from best-first search to depth-first branch-and-bound
search. Our experimental results show that BnB-ADOPT finds cost-minimal solutions up to one
order of magnitude faster than ADOPT for a variety of large DCOP problems and is as fast
as NCBB, a memory-bounded synchronous DCOP search algorithm, for most of these DCOP
problems. Additionally, it is often desirable to find bounded-error solutions for DCOP problems
within a reasonable amount of time since finding cost-minimal solutions is NP-hard. The existing bounded-error approximation mechanism allows users only to specify an absolute error bound
on the solution cost but a relative error bound is often more intuitive. Thus, we present two
new bounded-error approximation mechanisms that allow for relative error bounds and implement
them on top of BnB-ADOPT.

1. Introduction
A distributed constraint optimization (DCOP) problem consists of agents, each responsible for taking
on (= assigning itself) a value from its nite domain of values. The agents coordinate their values,
which are subject to constraints. Two agents are constrained if they share a constraint. Each
constraint has an associated constraint cost, which depends on the values of the constrained agents.
A (complete) solution is an assignment of values to all agents, and a partial solution is an assignment
of values to a subset of agents. The solution cost of a (partial or complete) solution is the sum of the
constraint costs of all constraints resulting from the given assignment of values to agents. Solving a
DCOP problem optimally means nding a solution with minimal solution cost and is NP-hard (Modi
et al., 2005).
Formulating agent-coordination problems as constraint optimization (COP) problems, a specic
type of weighted constraint satisfaction problems (Schiex, Fargier, & Verfaillie, 1995; Bistarelli,

c
2010
AI Access Foundation. All rights reserved.

fiYeoh, Felner & Koenig

a1

a2
a3

a1
a4

a2
a3

(a)

a4

a1
0
0
1
1
a2
0
0
1
1

a2
0
1
0
1
a3
0
1
0
1

Constraint Cost
5
8
20
3
Constraint Cost
5
4
3
3

(b)

a1
0
0
1
1
a2
0
0
1
1

a3
0
1
0
1
a4
0
1
0
1

Constraint Cost
5
10
20
3
Constraint Cost
3
8
10
3

(c)

Figure 1: Example DCOP Problem
Montanari, Rossi, Schiex, Verfaillie, & Fargier, 1999), is more general than formulating them as the
more common constraint satisfaction problems (Dechter, 2003). Constraint satisfaction problems
have constraints that are either satised or unsatised. Solving a constraint satisfaction problem
means nding a solution such that all constraints are satised. An example application is the
scheduling of jobs in a job-shop, where constraints express that some jobs can only be performed
by certain machines and some jobs can only be performed after some other jobs. There could
potentially be multiple solutions that satisfy all constraints. However, some solutions might be more
desirable than others. For example, one might prefer the solution with the shortest completion time.
Unfortunately, constraint satisfaction problems cannot capture these preferences. However, COP
problems are able to do so by using the constraint costs to represent the preferences.
DCOP algorithms are better suited compared to COP algorithms for problems that are naturally distributed. As a result, DCOP algorithms have been applied to coordinating unmanned
aerial vehicles (Schurr, Okamoto, Maheswaran, Scerri, & Tambe, 2005), scheduling meetings (Maheswaran, Tambe, Bowring, Pearce, & Varakantham, 2004b; Petcu & Faltings, 2005b; Greenstadt,
Grosz, & Smith, 2007; Zivan, 2008; Yeoh, Varakantham, & Koenig, 2009), coordinating sensor networks (Lesser, Ortiz, & Tambe, 2003; Zhang, Xing, Wang, & Wittenburg, 2003; Modi et al., 2005;
Jain, Taylor, Tambe, & Yokoo, 2009; Stranders, Farinelli, Rogers, & Jennings, 2009; Zivan, Glinton,
& Sycara, 2009), synchronizing trac lights (Junges & Bazzan, 2008), planning truck routes (Ottens
& Faltings, 2008) and managing power distribution networks (Kumar, Faltings, & Petcu, 2009).
It is common to visualize a DCOP problem as a constraint graph where the vertices are the
agents and the edges are the constraints. Most DCOP algorithms operate on a pseudo-tree, which
is a spanning tree of the (completely connected) constraint graph with the property that edges
in the constraint graph connect a vertex with one of its ancestor or descendant vertices in the
constraint tree (Freuder & Quinn, 1985; Bayardo & Miranker, 1995). An edge of the constraint
graph that is not part of the pseudo-tree is a backedge. An agent c is a pseudo-child agent of
agent p if agent c is a descendant agent of agent p in the pseudo-tree and they are constrained
via a backedge. Similarly, agent p is the pseudo-parent agent of agent c. Sibling subtrees represent
independent DCOP subproblems (since no two agents in dierent sibling subtrees share a constraint).
Figure 1(a) shows the constraint graph of an example DCOP problem with four agents that can
each take on value 0 or value 1, Figure 1(b) shows one possible pseudo-tree where the assignments of
values to agents a3 and a4 are independent DCOP subproblems (the dotted line is a backedge), and
Figure 1(c) shows the constraint costs. For our example DCOP problem, a cost-minimal solution
results if all agents take on value 1. The minimal solution cost is 12.
1.1 DCOP Algorithms
We now provide a taxonomy of DCOP algorithms. Figure 2 shows the taxonomy. DCOP algorithms
are divided into two groups: complete and incomplete DCOP algorithms. Complete DCOP algorithms nd cost-minimal solutions while incomplete DCOP algorithms are often faster but typically
nd suboptimal solutions.
86

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

DCOP Algorithms

Incomplete Algorithms
e.g., DBA, DSA, MGM,
k-optimal algorithms

Complete Algorithms

Partially Centralized Algorithms
e.g., OptAPO

Fully Decentralized
Algorithms

Search Algorithms
e.g., SBB, ADOPT,
NCBB, AFB

Inference Algorithms
e.g., DPOP

Figure 2: Taxonomy of DCOP Algorithms
1.1.1 Incomplete DCOP Algorithms
Incomplete DCOP algorithms typically use local search to nd locally optimal solutions and can
thus potentially get trapped in local minima. Nevertheless, since solving DCOP problems optimally
is NP-hard, such DCOP algorithms are desirable for large DCOP problems where nding costminimal solutions might be slow. DBA (Yokoo & Hirayama, 1996), DSA (Fitzpatrick & Meertens,
2003), MGM (Maheswaran, Pearce, & Tambe, 2004a) and the more recent class of k-optimal DCOP
algorithms (Pearce & Tambe, 2007; Bowring, Pearce, Portway, Jain, & Tambe, 2008; Greenstadt,
2009) are examples of incomplete DCOP algorithms.
1.1.2 Complete DCOP Algorithms
Complete DCOP algorithms are generally divided into two groups, namely partially centralized and
fully decentralized DCOP algorithms.
Partially Centralized DCOP Algorithms
Partially centralized DCOP algorithms allow some agents to transfer their constraint information
(= information regarding the constraints that they are involved in) to a central agent for processing. OptAPO (Mailler & Lesser, 2004) is an example of a partially centralized DCOP algorithm
that uses cooperative mediation, where certain agents act as mediators to solve overlapping DCOP
subproblems centrally.
Fully Decentralized DCOP Algorithms
Fully decentralized DCOP algorithms do not have central agents that collect constraint information of other agents that are not constrained with them. Rather, every agent has access to only
its own constraint information. Fully decentralized DCOP algorithms are generally divided into two
groups, namely DCOP inference and search algorithms.
 DCOP inference algorithms: DCOP inference algorithms typically use dynamic programming to propagate aggregated constraint costs from one agent to another agent and thus reduce
87

fiYeoh, Felner & Koenig

DCOP
Algorithm
SBB
ADOPT
NCBB
AFB
BnB-ADOPT

Search
Strategy
DFBnB
best-first
DFBnB
DFBnB
DFBnB

Agent
Operation
sequential & synchronous
concurrent & asynchronous
sequential & synchronous
concurrent & asynchronous
concurrent & asynchronous

Communication
point-to-point with neighbors
point-to-point with neighbors
point-to-point with neighbors
broadcast to all agents
point-to-point with neighbors

Agent
Ordering
chain
tree
tree
chain
tree

Table 1: Properties of DCOP Search Algorithms

the DCOP problem size by one agent at each step. They repeat this procedure until the DCOP
problem size is reduced to only one agent and the solution space (= space of all possible partial solutions) thus cannot be reduced anymore. The sole remaining agent has then sucient
knowledge to nd a cost-minimal solution. DPOP (Petcu & Faltings, 2005b) is an example
of a DCOP inference algorithm. The number of messages sent between agents is only linear
in the number of agents. However, its memory requirements are exponential in the induced
width of the DCOP problem. The induced width depends on the number of backedges in the
pseudo-tree. It can be as large as the number of agents minus one if the constraint graph is
fully connected and every agent is thus constrained with every other agent.
 DCOP search algorithms: DCOP search algorithms use search strategies to search through
the solution space to nd a cost-minimal solution. ADOPT (Modi et al., 2005) uses best-rst
search, and SBB (Hirayama & Yokoo, 1997), NCBB (Chechetka & Sycara, 2006), AFB (Gershman, Meisels, & Zivan, 2009) and our new DCOP search algorithm, BnB-ADOPT, use
depth-rst branch-and-bound search. Their memory requirements are only polynomial in the
number of agents. However, the number of messages sent between agents can be exponential
in the number of agents.
Therefore, both groups of fully decentralized DCOP algorithms are desirable under dierent
conditions as there is a tradeo between space (memory requirements) and time (number of messages
sent).
1.2 Motivation
We now describe the motivation behind our work.
1.2.1 BnB-ADOPT
We study DCOP search algorithms because they can be memory-bounded. This property is important for applications, such as sensor networks, where every agent/sensor has only a xed amount of
memory available. As a result, several DCOP search algorithms, such as SBB, ADOPT, NCBB and
AFB, were developed with this limitation in mind. As described earlier, their memory requirements
are polynomial in the number of agents. Table 1 shows the properties of these DCOP search algorithms as well as the properties of our new DCOP search algorithm, BnB-ADOPT. We now describe
each property in more detail and justify the properties of BnB-ADOPT.
 Search strategy: ADOPT uses best-rst search to search the solution space, while SBB,
NCBB and AFB use depth-rst branch-and-bound (DFBnB) search. Best-rst search repeatedly searches for the next best partial solution until it nds a cost-minimal solution. The next
best partial solution is the cost-minimal partial solution among all partial solutions that have
not yet been found. Depth-rst branch-and-bound search starts by nding a complete (but

88

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

often suboptimal) solution and stores its solution cost as the upper bound. It then continues
to search for a solution whose solution cost is less than the upper bound. It stores the solution
cost of this solution as the upper bound, and the search proceeds until it can no longer nd a
solution whose solution cost is less than the upper bound.
For centralized search, it is known that search problems with depth-bounded search trees can
often be solved faster with depth-rst branch-and-bound search than with memory-bounded
best-rst search because memory-bounded best-rst search algorithms, such as RBFS (Korf,
1993), need to repeatedly reconstruct partial solutions that they purged from memory. Depthrst branch-and-bound search algorithms are memory-bounded but do not suer from this
problem (Zhang & Korf, 1995). Since DCOP problems are search problems with depthbounded search trees, we hypothesize that depth-rst branch-and-bound search might be faster
than best-rst search. Therefore, we decided that BnB-ADOPT should use depth-rst branchand-bound search.
 Agent operation: Agents of SBB and NCBB operate sequentially. Only agents with tokens
are active while the other agents remain idle. Once the token-holding agents are done, they pass
their tokens on and then remain idle. On the other hand, agents of ADOPT and AFB operate
concurrently (= at all times). Agents that operate concurrently might be able to solve DCOP
problems faster than agents that operate sequentially since the former agents can perform
potentially useful computation instead of having to wait for other agents. Therefore, we
decided that all agents of BnB-ADOPT should operate concurrently. Agents of SBB and NCBB
also operate synchronously. Communication between agents is often in form of messages.
Synchronous agents operate in cycles (Modi et al., 2005). A cycle is the time required for an
agent to process all incoming messages in its queue and send all outgoing messages, which
are then processed by the receiving agents in the next cycle (see Section 6.1 for more details).
Therefore, all agents wait until the last agent is done sending its messages before they start
a new cycle. On the other hand, asynchronous agents, such as agents of ADOPT and AFB,
are able to operate independently of each other, which often increases robustness (Silaghi,
Landwehr, & Larrosa, 2004). For example, all synchronous agents are aected if a single
communication link suers from congestion while only a small number of asynchronous agents
are aected. We therefore decided that agents of BnB-ADOPT should operate asynchronously.
 Communication:
DCOP search algorithms such as SBB, ADOPT and NCBB restrict
communication to agents that share constraints. This restriction is motivated by applications
such as sensor networks where communication is restricted to neighboring agents/sensors due
to their limited communication radius. Neighboring sensors share constraints since they need
to coordinate to sense the areas near them. DCOP search algorithms such as AFB do not have
this restriction and allow agents to broadcast messages to all other agents. We decided that
agents of BnB-ADOPT should obey the restrictions of applications such as sensor networks
and thus communicate only with neighboring agents.
 Agent ordering: All DCOP search algorithms mentioned above start with a pre-processing
step that arranges the agents into a pseudo-tree. DCOP search algorithms such as SBB and
AFB arrange the agents into a chain, while ADOPT and NCBB arrange the agents into a tree.
A tree ordering can capture independent DCOP subproblems (represented as sibling subtrees)
while a chain ordering can not. DCOP search algorithms that operate on trees can thus
operate on independent DCOP subproblems independently, while DCOP search algorithms
that operate on chains can not. Therefore, we decided that BnB-ADOPT should arrange
agents into a tree.
ADOPT has all preferred properties mentioned above except that it uses best-rst search. We
therefore introduce BnB-ADOPT, a memory-bounded asynchronous DCOP search algorithm that
89

fiYeoh, Felner & Koenig

uses the message passing and communication framework of ADOPT but changes the search strategy
of ADOPT from best-rst search to depth-rst branch-and-bound search.
1.2.2 Bounded-Error Approximations
Solving DCOP problems optimally is NP-hard, which makes it advantageous to allow users to trade
o solution cost for a smaller runtime. It is also desirable to have the error of the resulting solution
cost be bounded to provide guarantees on the solution cost. ADOPT is, to the best of our knowledge,
the only DCOP search algorithm with this property. Its Absolute Error Mechanism allows its users
to specify an absolute error bound on the solution cost, for example, that the solution cost should
be at most 10 larger than the minimal solution cost. However, it is often much more desirable to
specify a relative error bound on the solution cost, for example, that the solution cost should be
at most 10 percent larger than the minimal solution cost or, equivalently, 1.1 times larger than the
minimal solution cost. This cannot be done with the Absolute Error Mechanism without knowing
the minimal solution cost a priori. Thus, we propose two approximation mechanisms that allow users
to specify a relative error bound on the solution cost, namely the Relative Error Mechanism and the
Weighted Heuristics Mechanism, and implement them on top of BnB-ADOPT. These approximation
mechanisms allow BnB-ADOPT to nd solutions with bounded errors faster than cost-minimal
solutions.
1.3 Experimental Results
We experimentally compare ADOPT, BnB-ADOPT and NCBB on three dierent DCOP problem
types, namely graph coloring problems, sensor network problems and meeting scheduling problems.
Our results show that BnB-ADOPT is up to one order of magnitude faster (measured in the number
of non-concurrent constraint checks and the number of cycles) than ADOPT on a variety of large
DCOP problems. BnB-ADOPT can also be inferred to be faster than SBB since ADOPT is faster
than SBB (Modi et al., 2005). BnB-ADOPT is also as fast as NCBB on most of these DCOP
problems. Our results for the suboptimal variants of BnB-ADOPT show that the Weighted Heuristics
Mechanism dominates both the Absolute Error Mechanism and Relative Error Mechanism.
1.4 Article Structure
This article is organized as follows: We formalize DCOP problems in Section 2 and describe our
DCOP search algorithm, BnB-ADOPT, in Section 3. We describe approximation mechanisms that
allow BnB-ADOPT to nd solutions with bounded error in Section 4. We outline correctness and
completeness proofs of BnB-ADOPT in Section 5. Lastly, we present our experimental evaluations
in Section 6 and our conclusions in Section 7.

2. DCOP Problems
In this section, we formally dene distributed constraint optimization (DCOP) problems and describe
their solution space.
2.1 Definition of DCOP Problems
A DCOP problem is dened by the following elements:
 a nite set of agents A = {a1 , a2 , ..., an };
 a set of nite domains D = {Dom(a1 ), Dom(a2 ), ..., Dom(an )}, where Dom(ai ) is the domain
of possible oating point values of agent ai  A; and

90

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

a1

OR

A

OR

AND

0

0

AND

a

b

OR

a2

a2

OR

B

C

5

AND

OR

AND

8

a3
10 14

a4
3

20

a3
8

8

13

a3

a4
10

3

3

25

a4
7

3

a3
8

23

a4
6

c

AND

10

D

OR

3

AND

d

g

E
h

i

e

F
j

k

(a)

G
l

m

f

H
n

o

I
p

q

J
r

s

K
t

u

v

(b)

Figure 3: AND/OR Search Tree
 a set of binary constraints F = {f1 , f2 , ..., fm }, where each constraint fi : Dom(ai1 ) 
Dom(ai2 )  R+  , species its non-negative constraint cost as a function of the values
of the distinct agents ai1 and ai2 that share the constraint.
The above denition assumes that each agent takes on one value rather than multiple values,
for example, a dierent value for each constraint that it is involved in. These DCOP problems
are more commonly formulated as each agent being responsible for the assignments of values to
multiple variables. However, there exist techniques that reduce such DCOP problems to our DCOP
problems (Burke & Brown, 2006). Thus, we use the terms agent and variable interchangeably. The
above denition also assumes that constraints are binary (= between two agents) rather than n-ary
(= between n agents). One should be able to extend BnB-ADOPT to solve DCOP problems with nary constraints by using the same techniques that were proposed to extend ADOPT to solve DCOP
problems with n-ary constraints (Modi et al., 2005). Additionally, we assume that the messages sent
between agents can be delayed by a nite amount of time but are never lost.
2.2 Search Trees
The solution space of DCOP problems can be visualized with search trees. Traditional search trees
or, synonymously, OR search trees (Marinescu & Dechter, 2009) assign values to agents sequentially.
They do not utilize the fact that the values of agents that belong to independent DCOP subproblems
do not have to be assigned sequentially. AND/OR search trees are based on pseudo-trees and remedy
this issue (Marinescu & Dechter, 2009). Thus, we use AND/OR search trees and refer to them as
search trees in this article. Their depth is bounded by (twice) the number of agents.
Figure 3(a) shows the search tree that is based on the pseudo-tree in Figure 1(b). Figure 3(b)
labels each node of the search tree with an identier to allow us to refer to the nodes easily. Circular
nodes are OR nodes (labeled with upper-case letters) and correspond to agents. For example, the
agent of node C is agent a2 . Left branches of OR nodes correspond to the agents taking on value
0 and right branches correspond to the agents taking on value 1. Square nodes are AND nodes
(labeled with lower-case letters) and correspond to the partial solutions from the root node to those
nodes. For example, the partial solution of node f is {(a1 , 1), (a2 , 1)}. The subtree rooted at an
AND node represents the DCOP subproblem that assumes the partial solution of the AND node.
For example, the subtree rooted at node f represents the DCOP subproblem of assigning values
to agents a3 and a4 given that {(a1 , 1), (a2 , 1)}. The number of independent DCOP subproblems
within this DCOP subproblem is indicated by the number of branches exiting the AND node. For
example, there are two branches exiting node f , indicating that there are two independent DCOP
subproblems, namely of assigning values to agents a3 and a4 . The numbers in the AND nodes
are the delta costs of the nodes. The delta cost of an AND node is dened to be the sum of the
constraint costs of all constraints in its partial solution that involve the agent of its parent OR node.

91

fiYeoh, Felner & Koenig

For example, the partial solution of node v is {(a1 , 1), (a2 , 1), (a4 , 1)}. There are two constraints in
this partial solution, namely the constraint between agents a1 and a2 , which has constraint cost 3,
and the constraint between agents a2 and a4 , which also has constraint cost 3. Since the parent
node of node v is node K with agent a4 , the delta cost of node v is 3, namely the constraint cost of
the latter constraint. The former constraint is not included since it does not involve agent a4 . The
solution cost of a partial solution of an AND node is the sum of the delta costs of all AND nodes
along the branch from the root node to that node. For example, the solution cost of the partial
solution of node v (= 6) is the sum of the delta costs of nodes b, f and v. In our example DCOP
problem, a cost-minimal solution is the union of the partial solutions of nodes t and v (all agents
take on value 1). Thus, the minimal solution cost (= 12) is the sum of the delta costs of nodes b, f ,
t and v.

3. BnB-ADOPT
In this section, we present Branch-and-Bound ADOPT (BnB-ADOPT). We do not describe BnBADOPT as a modication of ADOPT since this approach requires the readers to have an in-depth
understanding of ADOPT. Instead, we give a stand-alone description of BnB-ADOPT that requires
no knowledge of ADOPT, with the intention of creating a self-contained and hopefully easy-to-read
description.
3.1 Search Strategies of ADOPT and BnB-ADOPT
We rst describe centralized versions of the search strategies of ADOPT and BnB-ADOPT and omit
technical details since these are described in more detail in later sections.
3.1.1 Search Strategy of ADOPT
ADOPT (Modi et al., 2005) is a popular DCOP search algorithm (Modi & Ali, 2004; Ali, Koenig,
& Tambe, 2005; Bowring, Tambe, & Yokoo, 2006; Davin & Modi, 2006; Pecora, Modi, & Scerri,
2006; Choxi & Modi, 2007; Silaghi & Yokoo, 2009; Matsui, Silaghi, Hirayama, Yokoo, & Matsuo,
2009) that traverses the search tree in a best-rst search order. We now describe a simplied version
of best-rst search. The complete version can be found in (Marinescu & Dechter, 2007). Bestrst search maintains a list that initially contains only the child AND nodes of the root node. It
repeatedly performs the following operations: It expands the AND node with the smallest solution
cost in the list by removing that node from the list and adding the grandchild AND nodes of that
node into the list. For our example DCOP problem, best-rst search expands the AND nodes in the
search tree in Figure 3 for the rst time in the following order, where the numbers in parentheses
indicate the solution costs of the partial solutions of the expanded nodes: a (0), b (0), f (3), c (5),
v (6), i (8), d (8) and t (9).
Figure 4 shows a simplied trace of ADOPT on our example DCOP problem. ADOPT terminates
after fteen steps with minimal solution cost 12. The numbers in the AND nodes are the delta costs
r
of the nodes. The lower bound LBX
r is an optimistic estimate of the minimal solution cost. It is
the smallest underestimated solution cost, over all solutions. The underestimated solution cost of
a solution is the sum of the delta costs of all AND nodes of that solution whose parent OR node
is the root node or whose grandparent AND node is expanded. For example, the underestimated
solution cost of the solution {(a1 , 1), (a2 , 1), (a3 , 1), (a4 , 1)} is 3 if node b is expanded and nodes f , t
r
and v are not expanded. The upper bound U BX
r is a pessimistic estimate of the minimal solution
cost. It is the solution cost of the solution with the smallest solution cost found so far. ADOPT
r
r
terminates when the upper bound U BX
r is no larger than the lower bound LBX r . In order to be
memory-bounded, ADOPT maintains only one branch of the search tree (shaded grey in the gure)
from the root node to the currently expanded node and thus needs to repeatedly reconstruct nodes

92

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

LBrXr = 0

A

OR

AND

a

b

AND

OR

B

C

OR

c

AND

AND

d

D

OR

g

E
h

i

e

F
j

k

G
l

m

f

H
n

o

I
p

q

r

s

K
t

u

OR

v

AND

0

0

a2

a2

5

AND

J

a3

8
a4

10 14 3

a3
8

a1

OR

AND

OR

8 13 10 3 25 7

AND

a3

0
a2
8

10 14 3

=5
= infinity

0

a4

a3
8

OR

3
a4

8 13 10 3 25 7

3

a1

OR

AND

20
a3

a4

a3

8 23 6 10 3

AND

a3

0

0
a2
8

a4

10 14 3

a3

OR

AND

a3

0

8
a4

10 14 3

a3
8

8

3

a3

a1

AND

OR

8 23 6 10 3

OR

AND

a3

AND

a3

0
a2
8

10 14 3

=8
= infinity

0

a4

a3

0

8

10 14 3

8

8

AND

OR

3

a3

AND

a3
10 14 3

8

= 12
= infinity

0

0
a2

a3

OR

AND

a3

8

8 13 10 3 25 7

10 14 3

8

OR

AND

a3

0
a2
8

10 14 3

a3
8

OR

a3

8 13 10 3 25 7

3
a4

3

a3

8 23 6 10 3

OR

AND

a3

3

8 13 10 3 25 7

OR

AND

a3

0

0
a2
8

a4

10 14 3

a3
8

10 14 3

8

a1

AND

OR

3

a3

8 13 10 3 25 7

AND

a3

0
a2

10 14 3

8

20
a4

a3

8 13 10 3 25 7

OR

AND

0

0
a2

a3
10 14 3

8
a4

a3
8

20
a4

a3

8 13 10 3 25 7

3
a4

3

a3

3
a4

3

a3

a4

8 23 6 10 3

Step 15

Figure 4: Trace of Simplied Memory-Bounded Best-First Search (Centralized ADOPT)

93

a4

8 23 6 10 3

= 12
= 12

0

a3

a4

8 23 6 10 3

Step 14

LBrXr
UBrXr

8
a4

3

a3

a2
5

AND

a4

8 23 6 10 3

a2
5

AND

OR

3
a4

a1 UBrXr = infinity

OR

Step 13
OR

a3

LBrXr = 12

3
a4

8 13 10 3 25 7

Step 12

20
a4

OR

AND

20
a3

a4

a4

8 23 6 10 3

a2
5

AND

a4

= 12
= infinity
0

8

3

a3

Step 11

LBrXr
UBrXr

a2

a3

3
a4

a1 UBrXr = infinity

OR

8 23 6 10 3

0

a4

a3

LBrXr = 8

a3

a2
5

AND

a4

20
a4

OR

3
a4

8 13 10 3 25 7

a1

a4

8 23 6 10 3

0

a4

AND

20

OR

3

a3

a2
5

AND

a4

=8
= infinity

a3

a4

3
a4

Step 8

LBrXr
UBrXr

0

a3

a3

a1 UBrXr = infinity

OR

8 23 6 10 3

a2

a4

AND

20
a4

8

20
a4

Step 10

LBrXr
UBrXr

8
a4

3

0

5

AND

a4

8 23 6 10 3

a2
5

AND

OR

10 14 3

a3

LBrXr = 8

a3

a2

Step 9
a1

8
a4

OR

3
a4

8 13 10 3 25 7

a1

OR

3
a4

8 13 10 3 25 7

OR

AND

a3

AND

20
a3

a4

OR

AND

20
a3

a4

OR

0
a2

Step 5

a2

a3

a4

8 23 6 10 3

0

5

AND

a4

8 23 6 10 3

0

a4

3

a3

a2

Step 7

a2
5

AND

OR

3

a3

a2
5

AND

a4

3
a4

a1 UBrXr = infinity

OR

a1 UBrXr = infinity

OR

a3

8 13 10 3 25 7

OR

3
a4

8 13 10 3 25 7

Step 6
LBrXr
UBrXr

20
a4

LBrXr = 8

3
a4

8 13 10 3 25 7

OR

8

AND

20
a3

a4

OR

AND

20
a3

a4

10 14 3

a3

Step 4

a2
5

AND

OR

8
a4

LBrXr = 8

=5
= infinity

a2

LBrXr = 8

OR

AND

a3

Step 2

LBrXr
UBrXr

0

5

AND

a4

a1 UBrXr = infinity

AND

OR

0
a2

5

AND

a4

8 23 6 10 3

a2

Step 3
OR

3

a3

0
a2

Step 1

a2
5

AND

OR

OR

3
a4

a1 UBrXr = infinity

OR

AND

20
a3

a4

Identifiers
LBrXr
UBrXr

LBrXr = 3

a1 UBrXr = infinity

OR

fiYeoh, Felner & Koenig

LBrXr = 0

A

OR

AND

a

b

AND

OR

B

C

OR

c

AND

AND

d

D

OR

g

E
h

i

e

F
j

k

G
l

m

f

H
n

o

I
p

q

r

s

K
t

u

OR

v

AND

0

0

a2

a2

5

AND

J

a3

8
a4

10 14 3

a3
8

a1

OR

AND

OR

AND

a3

0
a2
8

10 14 3

=0
= infinity

0

a4

a3

8 13 10 3 25 7

8

AND

OR

3
a4

8 13 10 3 25 7

3

a1

OR

20
a3

a4

a1

AND

OR

a3

AND

a3

OR

AND

a3

8

8 13 10 3 25 7

8

10 14 3

a3

a1

AND

OR

8

AND

a3

3

a3

8 23 6 10 3

OR

AND

a3
10 14 3

8

0
a2

10 14 3

8

AND

a3

0
a2
8

a4

10 14 3

a3
8

OR

a3

8 13 10 3 25 7

3
a4

3

a3

a4

8 13 10 3 25 7

OR

3

a3

8 23 6 10 3

OR

AND

a3

8

10 14 3

8

OR

AND

0

0
a2

a3

8
a4

10 14 3

a3
8

20
a4

3

a3

a4

8 13 10 3 25 7

3

a3

a4

8 23 6 10 3

OR

3
a4

3

a1 UBrXr = 18

AND

20
a3

8 13 10 3 25 7

Step 9

a4

8 23 6 10 3

LBrXr = 12

0

a4

3

a3

a2

OR

a2

a3

a4

Step 8

LBrXr = 12
UBrXr = 18

0

a4

3

a3

8 13 10 3 25 7

5

AND

a4

8 23 6 10 3

a2
5

AND

a4

20
a4

a1 UBrXr = 18

AND

3

a3

a1

AND

20
a4

OR

0

OR

20

OR

a4

8 23 6 10 3

LBrXr = 0

=0
= 18
0

a4

3

a3

Step 5

LBrXr
UBrXr

8

a4

a2
5

AND

a4

8 23 6 10 3

a2

a3

3

a3

8 13 10 3 25 7

Step 7

0

a3

3

0

a4

20
a4

a1 UBrXr = 18

OR

a3

a2
5

AND

a4

LBrXr = 3
UBrXr = 18

8
a4

8

AND

3
a4

8 13 10 3 25 7

a1

OR

3
a4

a2
5

AND

OR

10 14 3

a3

OR

20
a3

a4

Step 6
OR

8
a4

LBrXr = 0

=0
= infinity
0

a4

AND

20
a3

a4

a3

Step 2

LBrXr
UBrXr

a2

OR

0

8

10 14 3

=0
= 18

a2

a3

AND

0
a2

Step 4

LBrXr
UBrXr

0

a4

OR

0
a2
5

AND

a4

8 23 6 10 3

0

5

AND

a4

8 23 6 10 3

a2
5

AND

OR

3

a3

a2

Step 3
OR

OR

Step 1

a2
5

AND

OR

AND

3
a4

a1 UBrXr = infinity

OR

20
a3

a4

Identifiers
LBrXr
UBrXr

LBrXr = 0

a1 UBrXr = infinity

OR

a3

8 23 6 10 3

Step 10

OR

AND

0
a2

5

AND

a4

0
a2

a3
10 14 3

8
a4

a3
8

20
a4

a3

8 13 10 3 25 7

3
a4

3

a3

a4

8 23 6 10 3

Step 11

LBrXr = 12

a1 UBrXr = 12

OR

AND

OR

AND

0
a2

5

AND

OR

0
a2

a3
10 14 3

8
a4

a3
8

20
a4

a3

8 13 10 3 25 7

3
a4

3

a3

a4

8 23 6 10 3

Step 12

Figure 5: Trace of Simplied Depth-First Branch-and-Bound Search (Centralized BnB-ADOPT)
that it purged from memory. For example, in Step 3, ADOPT has the branch to node f in memory.
The next node that best-rst search expands is node c, and ADOPT discards the branch to node f
in Step 4. In Steps 6 and 7, it then needs to reconstruct the discarded branch to node f in order to
expand node v in Step 8.
3.1.2 Search Strategy of BnB-ADOPT
We now describe a simplied version of depth-rst branch-and-bound search. The complete version
r
r
can be found in (Marinescu & Dechter, 2009). We use the same denitions of LBX
r and U BX r as
described earlier for Figure 4. Depth-rst branch-and-bound search maintains a stack that initially
contains only the child AND nodes of the root node. It expands the AND node on top of the

94

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

stack by removing that node from the stack and performing the following check. If the solution
r
cost of that node is no smaller than the upper bound U BX
r , it prunes that node and repeats the
operation. Otherwise, it adds the grandchild AND nodes of that node to the top of the stack and
r
repeats the operation. It terminates when the upper bound U BX
r is no larger than lower bound
r
LBX r . Depth-rst branch-and-bound search can add the grandchild AND nodes of an expanded
AND node (and the child AND nodes of the root node) in decreasing order of their solution costs
instead of a random order to the top of the stack. This ordering ensures that depth-rst branchand-bound search expands the grandchild AND node with the smallest solution cost rst. We use
this improvement throughout the article. For our example DCOP problem, depth-rst branch-andbound search expands the AND nodes in the search tree in the following order, where it prunes the
nodes in brackets: a (0), c (5), i (8), j (13), g (15), [h (19)], d (8), n (11), k (16), [m (18)], [l (21)],
b (0), f (3), v (6) and t (9). Figure 5 shows a trace of depth-rst branch-and-bound search for our
example DCOP problem. It is memory-bounded without having to repeatedly reconstruct nodes
that it purged from memory but expands some nodes that a best-rst search does not expand, such
as node j in Step 4. The depth-rst branch-and-bound search terminates after twelve steps with
minimal solution cost 12, which is three steps fewer than ADOPT.
3.2 Description of BnB-ADOPT
We now provide an incremental description of BnB-ADOPT. First, we provide the notations and key
terms of BnB-ADOPT. Then, we describe how BnB-ADOPT updates its bounds, adheres to memory
limitations, performs depth-rst search and performs branch-and-bound. Finally, we introduce our
enhanced nal version of BnB-ADOPT and show both its pseudocode and its trace for our example
DCOP problem.
3.2.1 Notation and Key Terms
We adopt the following notation from ADOPT to describe BnB-ADOPT:
 V alInit(a)  Dom(a) is the initial value of agent a  A;
 CD(a)  A is the set of child and pseudo-child agents of agent a  A;
 C(a)  CD(a) is the set of child agents of agent a  A;
 pa(a)  A is the parent agent of agent a  A except for the root agent;
 P (a)  A is the set of ancestor agents (including the parent agent) of agent a  A;
 SCP (a)  P (a) is the set of ancestor agents (including the parent agent) of agent a  A that
are parent or pseudo-parent agents of agent a or one (or more) of its descendant agents; and
 CP (a)  SCP (a) is the set of ancestor agents (including the parent agent) of agent a  A
that are parent or pseudo-parent agents of agent a.
We adopt the following key terms from ADOPT to describe BnB-ADOPT:
 Context (X): The context X a of agent a is the set of values of all ancestor agents of agent
a. The context X r of the root agent r is always equal to {}.
a
 Delta cost (): The delta cost X
a (d) is the sum of the constraint costs of all constraints
that involve both agent a and one of its ancestor agents, under the assumption that agent a
takes on value d and its ancestor agents take on the values in context X a . In the search tree,
a
a
X
 (a, d). For example,
a (d) is the delta cost of the AND node that has partial solution X
a2
{(a1 ,1)} (1) is the delta cost of node f in Figure 3.

95

fiYeoh, Felner & Koenig

a
a
 Gamma cost (): The gamma costs X
a (d) and X a are dened as follows:

a
a
X
a (d) := X a (d) +



c
X
a (a,d)

(1)

cC(a)
a
X
a :=

min

a
{X
a (d)}

dDom(a)

(2)

a
for all agents a, all values d and all contexts X a . Thus, the gamma cost X
a (d) is the sum of
the constraint costs of all constraints that involve agent a or one of its descendant agents (that
is, either both agent a and one of its ancestor agents, both agent a and one of its descendant
agents, both a descendant agent and an ancestor agent of agent a or two descendant agents of
agent a) minimized over all possible values of its descendant agents, under the assumption that
agent a takes on value d and its ancestor agents take on the values in context X a . In the search
a
a
 (a, d). For
tree, X
a (d) is the gamma cost of the AND node that has partial solution X
a2
a
example, {(a1 ,1)} (1) is the gamma cost of node f in Figure 3. The gamma cost X
a is the sum
of the constraint costs of all constraints that involve agent a or one of its descendant agents
minimized over all possible values of agent a and its descendant agents, under the assumption
that the ancestor agents of agent a take on the values in context X a . In the search tree, the
a
gamma cost X
a is the gamma cost of the OR node whose agent is agent a and whose parent
a2
is the gamma cost of node C in
AND node has partial solution X a . For example, {(a
1 ,1)}
Figure 3. Therefore, the gamma cost of an AND node is the sum of its delta cost and the
gamma costs of its child OR nodes, and the gamma cost of an OR node is the minimum of
the gamma costs of its child AND nodes. For example, the gamma cost of node f in Figure 3
is the sum of its delta cost and the gamma costs of nodes J and K, and the gamma cost of
node C in Figure 3 is the minimum of the gamma costs of nodes e and f .
r
Solving a DCOP problem optimally means to determine X
r for the root agent r or, equivalently,
r
the gamma cost of the root node since X r is the minimal solution cost. It is not dicult for the
agents to cache information that allows them to determine a cost-minimal solution.

3.2.2 Updating the Bounds
Every agent a of BnB-ADOPT stores and updates several bounds on the gamma costs, namely
a,c
a
a
a
a
lba,c
X a (d), LBX a (d), LBX a , ubX a (d), U BX a (d) and U BX a for all values d, all child agents c and all
a
contexts X , maintaining the following bound property:
a
LBX
a 
a
LBX
a (d)
a,c
lbX a (d)




a
X
a
a
X
a (d)
c
X
a (a,d)

a
 U BX
a

(3)




(4)
(5)

a
U BX
a (d)
a,c
ubX a (d)

In the search tree,
a
a
 LBX
a and U BX a are lower and upper bounds, respectively, (on the gamma cost) of the OR
node whose agent is agent a and whose parent AND node has partial solution X a ;
a
a
 LBX
a (d) and U BX a (d) are lower and upper bounds, respectively, (on the gamma cost) of the
AND node that has partial solution X a  (a, d); and
a,c
 lba,c
X a (d) and ubX a (d) are lower and upper bounds, respectively, (on the gamma cost) of the
OR node whose agent is agent c and whose parent AND node has partial solution X a  (a, d).

96

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

a2
a2
a2
For example, LB{(a
and U B{(a
are bounds of node C in Figure 3, LB{(a
(1) and
1 ,1)}
1 ,1)}
1 ,1)}
a2 ,a3
a2 ,a3
a2
U B{(a1 ,1)} (1) are bounds of node f , and lb{(a1 ,1)} (1) and ub{(a1 ,1)} (1) are bounds of node J.
a3
a3
2 ,a3
2 ,a3
lba{(a
(1), uba{(a
(1), LB{(a
and U B{(a
are bounds of node J, but agent
1 ,1)}
1 ,1)}
1 ,1),(a2 ,1)}
1 ,1),(a2 ,1)}
a2 maintains the rst two bounds while agent a3 maintains the last two bounds.
Each agent a uses the following update equations for all values d, all child agents c and all
a,c
a,c
contexts X a to initialize its bounds lba,c
X a (d) and ubX a (d), where the heuristic values hX a (d) are
a,c
c
oating point numbers that are admissible and thus satisfy 0  hX a (d)  X a (a,d) :

a,c
lba,c
X a (d) := hX a (d)

uba,c
X a (d)

:= 

(6)
(7)

Agent a then uses repeatedly the following update equations for all values d, all child agents c,
all contexts X a and all contexts X c (= X a  (a, d)) to tighten the bounds:
a,c
c
lba,c
X a (d) := max{lbX a (d), LBX c }
 a,c
a
a
LBX
lbX a (d)
a (d) := X a (d) +

(8)
(9)

cC(a)
a
LBX
a :=

uba,c
X a (d) :=
a
U BX
a (d)

:=

a
U BX
a :=

a
min {LBX
a (d)}
dDom(a)
c
min{uba,c
X a (d), U BX c }

a
X
uba,c
a (d) +
X a (d)
cC(a)

min

a
{U BX
a (d)}

dDom(a)

(10)
(11)
(12)
(13)

The updates maintain the bound property and improve the bounds monotonically, that is,
the lower bounds are monotonically non-decreasing and the upper bounds are monotonically nona
a
a
increasing.1 After a nite amount of time, U BX
a  LBX a for all agents a and all contexts X .
r
r
BnB-ADOPT terminates when its termination condition U BX r  LBX r for the root agent r is
r
r
r
r
satised. Then, U BX
r  LBX r and the bound property U BX r  LBX r together imply that
r
r
r
U BX r = X r = LBX r , and the DCOP problem is solved optimally.
Figure 6 shows a simplied trace of the updates of the (lower and upper) bounds for our example
DCOP problem. We assume that the updates proceed sequentially from the leaf agents to the root
agent. Due to this simplication, the lower and upper bounds of each node are identical to its
gamma cost and independent of the heuristic values. The numbers in the nodes are their bounds.
Two agents maintain the bounds of OR nodes except for the root node. The gure shows the bounds
that the parent agent maintains rather than the bounds that the child agent maintains. For example,
the number in node B is the bounds that agent a1 rather than agent a2 maintains. The bounds
that the child agent maintains can be computed by taking the minimum of the bounds of the child
AND nodes of the OR node. Agents update the bound of an AND node to the sum of its delta cost
and the bounds of its child OR nodes according to update equations 9 and 12. They update the
bound of an OR node to the minimum of the bounds of its child AND nodes according to update
equations 10 and 13. A more detailed description of the trace is as follows:
 Step 1: Leaf agent a3 updates the bounds of AND nodes g, h, k, l, o, p, s and t to their
delta costs according to update equations 9 and 12 and the bounds of OR nodes D, F , H and
1. Leaf agents use the same update equations. Since they do not have child agents, the sums over their child agents
a (d) = U B a (d) =  a (d) for all leaf agents a, all values d and all contexts X a .
evaluate to 0. For example, LBX
a
Xa
Xa

97

fiYeoh, Felner & Koenig

A

OR

0

OR

0

OR

AND

a

b

AND

0

0

AND

0

OR

B

C

OR

0

0

OR

0

c

AND

D

OR

AND

d

g

E
h

i

e

F
j

k

G
l

m

f

H
n

o

I
p

q

J
r

s

K
t

0

AND

u

OR

v

AND

0

0
0

10 14 3

0
8

0
0

0

8 13 10 3 25 7

Identifiers

0
0
3

0

8 23 6 10 3

Step 1

18

OR

18

10 14 3

3

8
8

30
3

7

8 13 10 3 25 7

12
3

3

6

3

8 23 6 10 3

Step 2

12
12

18

AND

AND

AND

10

19

12

OR

AND

OR

OR

0

18

AND

0

0

10
10 14 3

19
3

8
8

30
3

7

8 13 10 3 25 7

12
3

3

6

3

8 23 6 10 3

Step 3

Figure 6: Simplied Trace of the Updates of the (Lower and Upper) Bounds
J to the minimum of the bounds of their child AND nodes according to update equations 10
and 13. Similarly, leaf agent a4 updates the bounds of AND nodes i, j, m, n, q, r, u and
v to their delta costs according to update equations 9 and 12 and the bounds of OR nodes
E, G, I and K to the minimum of the bounds of their child AND nodes according to update
equations 10 and 13. The bounds of OR nodes D to K are not shown in the gure since they
are not (yet) maintained by agent a2 .
 Step 2: Agent a2 updates the bounds of OR nodes D to K that it maintains to the bounds
of the same OR nodes that leaf agents a3 and a4 maintain according to update equations 8
and 11, the bounds of AND nodes c to f to the sum of their delta costs and the bounds of their
child OR nodes according to update equations 9 and 12 and the bounds of OR nodes B and
C to the minimum of the bounds of their child AND nodes according to update equations 10
and 13. The bounds of OR nodes B and C are not shown in the gure since they are not (yet)
maintained by agent a1 .
 Step 3: Agent a1 updates the bounds of OR nodes B and C that it maintains to the bounds
of the same OR nodes that agent a2 maintains according to update equations 8 and 11, the
bounds of AND nodes a and b to the sum of their delta costs and the bounds of their child OR
nodes according to update equations 9 and 12 and the bounds of OR node A to the minimum
of the bounds of its child AND nodes according to update equations 10 and 13. Since the
lower and upper bounds of a node are equal to its gamma cost, the lower and upper bounds
of the root node are equal to its gamma cost, which in turn is equal to the minimal solution
cost. The propagation terminates after three steps with minimal solution cost 12.
3.2.3 Adhering to Memory Limitations
Our description of BnB-ADOPT so far assumes no memory limitations. However, BnB-ADOPT is
a memory-bounded DCOP search algorithm with memory requirements per agent that are linear
in the number of agents. We now describe how BnB-ADOPT adheres to these memory limitations
using techniques that were introduced for ADOPT but apply to BnB-ADOPT as well.
The simplied trace in Figure 6 assumes that every agent a maintains its bounds for all values d,
all child agents c and all contexts X a . The number of contexts can be exponential in the depth of the
agent in the pseudo-tree. For our example DCOP problem, agent a3 has four dierent contexts for
the four dierent combinations of values of its ancestor agents a1 and a2 . An agent cannot maintain
98

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

an exponential number of bounds due to the memory limitations. Therefore, every agent maintains
its bounds for only one context at any given time. This context is stored in the variable X a for
agent a. The size of the context is at most linear in the number of agents. The number of bounds of
an agent is now linear in the product of its domain cardinality and the number of its child agents.
Thus, the memory requirements per agent are only linear in the number of agents if the domain
cardinality and the magnitude of the bounds (and the other variables) are constant for each agent.
3.2.4 Performing Depth-First Search
Our description of BnB-ADOPT so far applies to ADOPT as well. However, BnB-ADOPT uses
depth-rst branch-and-bound search and ADOPT uses best-rst search. We now describe how
BnB-ADOPT implements depth-rst search.
Agents of BnB-ADOPT send messages that are similar to that of ADOPT but processes them
dierently. They send messages of three dierent types, namely VALUE, COST and TERMINATE
messages. At the start, every agent a initializes its context X a , uses update equations 6, 9, 10, 7, 12
a
and 13 to initialize its bounds and takes on its best value da := arg mindDom(a) {LBX
a (d)}. It sends
VALUE messages to all child agents and a COST message to its parent agent. It then repeatedly
waits for incoming messages, processes them, possibly takes on a dierent value and again sends
VALUE messages to all child agents and a COST message to its parent agent. A description of the
three message types and how agents process them is as follows:
 VALUE messages: An agent a with context X a and value da sends VALUE messages to
all child agents with the desired context X a  (a, da ), which is its context augmented with its
value. Leaf agents do not have child agents and thus do not send VALUE messages. VALUE
messages thus propagate contexts down the pseudo-tree.
When an agent receives a VALUE message, it checks whether its context is identical to the
desired context in the VALUE message. If it is not, then the agent changes its context to the
desired context in the VALUE message. In either case, it then executes the common program
(see below).
 COST messages: An agent a sends COST messages to its parent agent with its identity
a
a
a, its context X a and its bounds LBX
a and U BX a . The root agent does not have a parent
agent and thus does not send COST messages. COST messages thus propagate bounds up the
pseudo-tree.
When an agent receives a COST message, it checks whether its context and the context in the
COST message are compatible. Two contexts are compatible if no agent takes on dierent
values in the two contexts. If they are, then the agent uses update equations 8 to 13 with the
bounds in the COST message to improve its bounds for the value in the message. In either
case, it then executes the common program (see below).
r
r
 TERMINATE messages: When the termination condition U BX
r  LBX r is satised,
the root agent r sends TERMINATE messages (without parameters) to all child agents to
inform them that the search is complete and then terminates. When an agent receives such
a TERMINATE message, it sends TERMINATE messages to all child agents and terminates
as well. Leaf agents do not have child agents and thus do not send TERMINATE messages.
TERMINATE messages thus propagate down the pseudo-tree until all agents terminate.

The common program is as follows:
 Context change: If an agent a changed its context X a , it executes the following statements:
It uses update equations 6, 9, 10, 7, 12 and 13 to initialize its bounds and takes on its best
a
value da := arg mindDom(a) {LBX
a (d)}. It then sends VALUE messages to all child agents
and a COST message to its parent agent.
99

fiYeoh, Felner & Koenig

A

OR

0

OR

0

OR

AND

a

b

AND

0

0

AND

5

OR

B

C

OR

0

0

OR

5

c

AND

D

OR

AND

d

g

E
h

i

e

F
j

k

G
l

m

f

H
n

o

I
p

q

J
r

s

K
t

5

AND

u

OR

v

AND

8

0

0

10 14 3

8

X

0

X

X

X

X

X X

X X

X X

X X

X X

X X

OR

AND

0

18

AND

0

Identifiers

10

8
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

0

OR

AND

8

0

AND

8

0

AND

18

OR

8

0

OR

8

0

OR

18

18

AND

OR

AND

8

10

3

X X

X X

0

X
0

8 13 10 3

X

18

AND

X

X

X

X

X X

X X

X X

X X

OR

AND

19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X

OR

AND

10

19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

3

OR

18

0

AND

18

3

AND

18

OR

18

0

OR

18

3

OR

18

X

OR

AND

10
10 14 3

X
3
8

20

3

X

AND

X

X

0

0

0

0

X X

X X

X X

X X

X X

X X

OR

AND

X

20

X

X

X

X

0

X X

X X

X X

X X

X X

Cycle 6

3
0

0

0

X X 23 6 10 3

OR

AND

3
X

20

X

X

X

X

0

X X

X X

X X

X X

X X

12
0

6

3

X X 23 6 10 3

Cycle 8

12

OR

AND

18

OR

18

12
12

X

AND

AND

3

X

AND

Cycle 7

OR

X

3

Cycle 5

3

OR

X

8

AND

AND

0

18

AND

X

0

Cycle 4

0

OR

X
3

X

0

Cycle 2

0

OR

X

0

Cycle 1

0

OR

X

0

X

20

X

X

X

X

0

X X

X X

X X

X X

X X

12
0

6

3

X X 23 6 10 3

Cycle 9

Figure 7: Trace of the Updates of the Lower Bounds
 No context change: If an agent a did not change its context X a , it executes the following
a
a
a
a
statements: If U BX
a  LBX a (d ) for its value d , then the context of the agent augmented
with its value cannot be completed to a solution whose solution cost is smaller than the solution
a
cost of the best solution found so far for its context X a (= U BX
a ) and the agent thus takes on
a
a
its best value d := arg mindDom(a) {LBX a (d)}. It then sends VALUE messages to all child
agents and a COST message to its parent agent.
Assume that the context X a of an agent a does not change. After a nite amount of time,
a
a
a
a
U BX
The agent then takes on its best value and repeats the
a  LBX a (d ) for its value d .
a
a
procedure. After a nite amount of time, U BX
a  LBX a (d) for all values d, which implies that
a
a
a
a
a
U BX a  LBX a . The agent takes on every value d at most once until U BX
a  LBX a since LBX a (d)
a
remains unchanged and U BX a is monotonically non-increasing once the agent changes its value
from d to a dierent value, which prevents the agent from changing its value back to d before
a
a
U BX
a  LBX a . BnB-ADOPT thus performs depth-rst search. Then, after a nite amount of time,
r
r
r
r
r
r
r
U BX r  LBX r and the bound property U BX
r  LBX r together imply that U BX r = X r = LBX r
for the root agent r, and the DCOP problem is solved optimally.
Figures 7 and 8 show traces of the updates of the lower and upper bounds, respectively, for our
example DCOP problem. BnB-ADOPT uses the zero heuristic values. The initial context of every
100

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

A

OR

inf

OR

inf

OR

AND

a

b

AND

inf

inf

AND

inf

OR

B

C

OR

inf

inf

OR

inf

c

AND

D

OR

AND

d

g

E
h

i

e

F
j

k

G
l

m

f

H
n

o

I
p

q

J
r

s

inf

AND

K
t

u

OR

v

AND

inf

inf
inf

10 14 3

8

X

inf

X

X

X

X

X X

X X

X X

X X

X X

X X

OR

AND

10

inf
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 2

18

OR

18

OR

18

inf

AND

18

inf

AND

18

OR

18

inf

OR

18

inf

OR

18

18

OR

AND

inf

10

3

X X

X X

inf

X
inf

8 13 10 3

X

18

AND

X

X

X

X

X X

X X

X X

X X

OR

AND

19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X

OR

AND

10

19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

18

OR

18

inf

AND

18

inf

AND

18

OR

18

inf

OR

18

inf

OR

18

X

OR

AND

10
10 14 3

X
3
8

inf

inf

X

AND

X

X

inf

inf

inf

inf

X X

X X

X X

X X

X X

X X

OR

AND

X

inf

X

X

X

X

inf

X X

X X

X X

X X

X X

Cycle 6

inf
inf

inf

inf

X X 23 6 10 3

OR

AND

inf
X

inf

X

X

X

X

inf

X X

X X

X X

X X

X X

12
inf

6

3

X X 23 6 10 3

Cycle 8

12

OR

AND

18

OR

18

12
12

X

AND

AND

inf

X

AND

Cycle 7

OR

X

3

Cycle 5

18

OR

X

8

AND

AND

inf

18

AND

X

inf

Cycle 4

18

OR

X
3

X

inf

Cycle 1

18

X

inf

AND

AND

0

18

AND

inf

Identifiers
OR

X

inf

X

inf

X

X

X

X

inf

X X

X X

X X

X X

X X

12
inf

6

3

X X 23 6 10 3

Cycle 9

Figure 8: Trace of the Updates of the Upper Bounds
agent assigns value 0 to all ancestor agents of the agent. We partition time into cycles. Agents
maintain their bounds for only one context at any given time. Nodes in the gures are crossed out if
their agent does not maintain their bounds. AND nodes are shaded if their partial solution is equal
to the context of the agent of their parent OR node augmented with its value. For example, agents
a1 , a3 and a4 take on value 0 in Cycle 2, and agent a2 takes on value 1. The context of agent a1 is
{}, the context of agent a2 is {(a1 , 0)} and the contexts of agents a3 and a4 are {(a1 , 0), (a2 , 0)}. A
description of the trace is as follows:
 Cycle 1: Root agent a1 initializes its context X a1 to {}. It initializes the lower bounds of
nodes B (= lbaX1a,a1 2 (0)) and C (= lbaX1a,a1 2 (1)) to 0 since it uses the zero heuristic values. It
a1
updates the lower bound of node a (= LBX
a1 (0)) to the sum of its delta cost (= 0) and the
lower bound of node B (= 0) according to the update equations. It updates the lower bound
a1
of node b (= LBX
a1 (1)) to the sum of its delta cost (= 0) and the lower bound of node C (= 0)
a1
according to the update equations. It updates the lower bound of node A (= LBX
a1 ) to the
minimum of the lower bound of node a (= 0) and the lower bound of node b (= 0) according to
the update equations. It initializes the upper bounds of nodes B and C to innity. It updates
the upper bounds of nodes a, b and A to innity according to the update equations. It takes

101

fiYeoh, Felner & Koenig

on its best value. It can take on either value 0 or value 1 since the lower bounds of nodes a
and b are both 0. It takes on value 0 and sends a VALUE message to its child agent a2 .
Agent a2 initializes its context X a2 to {(a1 , 0)}. It initializes the lower bounds of nodes D, E,
F and G to 0. It updates the lower bounds of nodes c, d and B to 5, 8 and 5, respectively. It
initializes the upper bounds of nodes D, E, F and G to innity. It updates the upper bounds
of nodes c, d and B to innity. The bounds of node B that agent a2 maintains are not shown
in the gures. It takes on its best value 0, sends VALUE messages to its child agents a3 and
a4 and sends a COST message to its parent agent a1 .
Leaf agent a3 initializes its context X a3 to {(a1 , 0), (a2 , 0)}. It updates the lower bounds of
nodes g and h to their delta costs 10 and 14, respectively, since leaf agents do not have child
agents. It updates the lower bound of node D to 10. It updates the upper bounds of nodes g
and h to their delta costs 10 and 14, respectively, since leaf agents do not have child agents. It
updates the upper bound of node D to 10. The bounds of node D that leaf agent a3 maintains
are not shown in the gures. It takes on its best value 0 and sends a COST message to its
parent agent a2 .
Leaf agent a4 initializes its context X a4 to {(a1 , 0), (a2 , 0)}. It updates the lower bounds of
nodes i and j to their delta costs 3 and 8, respectively. It updates the lower bound of node E
to 3. It updates the upper bounds of nodes i and j to their delta costs 3 and 8, respectively. It
updates the upper bound of node E to 3. The bounds of node E that leaf agent a4 maintains
are not shown in the gures. It takes on its best value 0 and sends a COST message to its
parent agent a2 .
In summary, the following messages are sent during Cycle 1:
 message (VALUE, {(a1 , 0)}) from agent a1 to agent a2 ;
 message (VALUE, {(a1 , 0), (a2 , 0)}) from agent a2 to agent a3 ;
 message (VALUE, {(a1 , 0), (a2 , 0)}) from agent a2 to agent a4 ;
 message (COST, a2 , {(a1 , 0)}, 5, ) from agent a2 to agent a1 ;
 message (COST, a3 , {(a1 , 0), (a2 , 0)}, 10, 10) from agent a3 to agent a2 ; and
 message (COST, a4 , {(a1 , 0), (a2 , 0)}, 3, 3) from agent a4 to agent a2 .
 Cycle 2: Root agent a1 receives the COST message sent by its child agent a2 in Cycle 1. Since
the context of agent a1 (= {}) is compatible with the context in the message (= {(a1 , 0)}), it
improves its bounds. It updates the bounds of node B to the bounds in the message (= 5 and
innity, respectively). It updates the bounds of nodes a, b and A. It does not change its value
a1
a1
) = 5 for its value da1 = 0) is still smaller than
since the lower bound of node a (= LBX
a1 (d
a1
the upper bound of node A (= U BX a1 = ). It sends a VALUE message to its child agent
a2 .
Agent a2 receives the VALUE message sent by its parent agent a1 in Cycle 1. Its context
(= {(a1 , 0)}) remains unchanged since it is the same as the desired context in the message
(= {(a1 , 0)}). Agent a2 also receives the COST messages sent by its child agents a3 and a4
in Cycle 1. Since the context of agent a2 (= {(a1 , 0)}) is compatible with the contexts in the
messages (= {(a1 , 0), (a2 , 0)}), it improves its bounds. It updates the bounds of node D to
the bounds in the rst message (= 10 and 10, respectively) and the bounds of node E to the
bounds in the second message (= 3 and 3, respectively). It updates the bounds of nodes c, d
a2
a2
) = 18 for its value
and B. It changes its value since the lower bound of node c (= LBX
a2 (d
a2
a2
d = 0) is no longer smaller than the upper bound of node B (= U BX a2 = 18). It takes on its
best value 1, sends VALUE messages to its child agents a3 and a4 and sends a COST message
to its parent agent a1 .

102

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

Leaf agents a3 and a4 receive the VALUE messages sent by their parent agent a2 in Cycle 1.
Their contexts (= {(a1 , 0), (a2 , 0)}) remain unchanged since they are the same as the desired
context in the message (= {(a1 , 0), (a2 , 0)}). They send the same COST messages as before to
their parent agent a2 .
In summary, the messages sent during Cycle 2 are identical to the ones sent during Cycle 1,
except for the messages sent by agent a2 , which are as follows:
 message (VALUE, {(a1 , 0), (a2 , 1)}) from agent a2 to agent a3 ;
 message (VALUE, {(a1 , 0), (a2 , 1)}) from agent a2 to agent a4 ; and
 message (COST, a2 , {(a1 , 0)}, 8, 18) from agent a2 to agent a1 .
The VALUE messages are dierent because agent a2 changed its value from 0 to 1. The COST
message is dierent because agent a2 changed its bounds.
 Cycles 3-9: The messages sent during Cycle 3 are identical to the ones sent during Cycle 2,
except for the messages sent by agents a3 and a4 , which are as follows:
 message (COST, a3 , {(a1 , 0), (a2 , 1)}, 8, 8) from agent a3 to agent a2 ; and
 message (COST, a4 , {(a1 , 0), (a2 , 1)}, 3, 3) from agent a4 to agent a2 .
The COST messages are dierent because agents a3 and a4 changed their contexts. The
termination condition holds after a nite amount of time when the upper bound of node A
a1
a1
(= U BX
a1 = 12) is no larger than the lower bound of node A (= LBX a1 = 12). Root agent a1
sends TERMINATE messages to all child agents, and the TERMINATE messages propagate
down the pseudo-tree until all agents terminate. BnB-ADOPT terminates after nine cycles
with minimal solution cost 12.
3.2.5 Performing Branch-and-Bound
We now rene our description of BnB-ADOPT by explaining how the agents implement branchand-bound search to make BnB-ADOPT faster. Every agent a of BnB-ADOPT now also maintains
a
the variable threshold T HX
a , which it initializes to innity. The threshold of the root agent always
remains innity. Every other agent uses its threshold for pruning, meaning that it can change its
value earlier than previously.
 First change: If an agent a did not change its context X a , it previously executed the following
a
a
a
a
statements: If U BX
a  LBX a (d ) for its value d , then the agent took on its best value. It
then sent VALUE messages to all child agents and a COST message to its parent agent. Now, if
a
a
a
a
a
T HX
a  LBX a (d ), then the agent also takes on its best value. Thus, if min{T HX a , U BX a } 
a
a
LBX
(d
),
then
the
agent
takes
on
its
best
value
and
thus
potentially
changes
its
value,
which
a
a
a
is earlier than previously. min{T HX
,
U
B
}
is
the
pruning
quantity.
a
Xa
 Second change: An agent a with context X a and value da sends VALUE messages
to all its child agents, which previously contained only the desired context X a  (a, da ).
a
a
a
a
VALUE messages now also contain the desired threshold min{T HX
a , U BX a }  X a (d ) 

a,c a
c C(a)\c lbX a (d ) for the child agent c. When agent c receives a VALUE message, it sets
its threshold to the desired threshold and then proceeds as described earlier. The desired
a
a
a
reaches its
threshold is set such that the lower bound LBX
a (d ) of agent a for its value d
c
pruning quantity (and agent a thus potentially changes its value) when the lower bound LBX
c
of agent c reaches the desired threshold. This property can be veried as follows:

103

fiYeoh, Felner & Koenig



c
a
a
a
a
LBX
c  min{T HX a , U BX a }  X a (d ) 



a
lba,c
X a (d )

(14)

c C(a)\c



a
a
a
a
a
lba,c
X a (d )  min{T HX a , U BX a }  X a (d ) 
a,c
a
a
a
a
a
 min{T HX
a , U BX a }  X a (d )  lb a (d ) 
X



a
lba,c
X a (d )

(15)

c C(a)\c





a
lba,c
X a (d )

(16)

c C(a)\c



a,c
a
a
a
a
a
min{T HX
a , U BX a }  X a (d ) + lb a (d ) +
X



a
a
a
a
min{T HX
a , U BX a }  X a (d ) +



a
lba,c
X a (d )

(17)

c C(a)\c


a
lba,c
X a (d )

(18)

c C(a)
a
a
a
a
min{T HX
a , U BX a }  LBX a (d )

(19)

3.2.6 Further Enhancements
We continue to rene our description of BnB-ADOPT by explaining a number of additional enhancements, which were introduced for ADOPT.
 Reduced contexts: The agents now use reduced contexts, which are subsets of the contexts
described previously. The reduced context X1a of agent a contains the values of all ancestor
agents p  SCP (a), while the context X2a described previously contains the values of all
a
a
a
ancestor agents p  P (a). The agents can use reduced contexts since X
a = X a and X a (d) =
1
2
1
a
X2a (d) for all values d. Agents now use reduced contexts because they need to change their
contexts and thus initialize their bounds less often when they receive VALUE messages since
their contexts are then more often identical to the desired contexts in the VALUE messages.
For our example DCOP problem, the reduced context of agent a4 contains the values of only
agent a2 rather than the values of agents a1 and a2 . Therefore, the following pairs of nodes in
the search tree are actually the same node: nodes i and q, nodes j and r, nodes m and u, and
nodes n and v.
 VALUE and COST messages: An agent sends VALUE messages to all child agents, which
previously contained the desired context and the desired threshold. The desired context is the
context of the agent augmented with its value. When an agent receives a VALUE message,
it previously checked whether its context is identical to the desired context in the VALUE
message. If it was not, then the agent changed its context to the desired context in the
VALUE message. Agents now update their contexts dierently to reduce the size of the
VALUE messages. An agent sends VALUE messages to all child and pseudo-child agents with
its identity, value and desired threshold, which is innity for its pseudo-child agents. When an
agent receives a VALUE message, it sets its threshold to the desired threshold if the message
is from its parent agent. It also checks whether the value of the ancestor agent in the VALUE
message is more recent than the value of the ancestor agent in its context. If it is, then the
agent changes the value of the ancestor agent in its context to the value of the ancestor agent in
the VALUE message. However, the context of an agent does not only contain the values of its
parent and pseudo-parent agents but also the values of its ancestor agents that are the parent
or pseudo-parent agents of one (or more) of its descendant agents, and ancestor agents that
are not constrained with the agent cannot send VALUE messages to the agent. However, they
send VALUE messages to their pseudo-child agents, at least one of which is a descendant agent
of the agent, and the information then propagates up the pseudo-tree with COST messages
until it reaches the agent. When an agent receives a COST message, it now checks whether
104

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

the value of an ancestor agent in the context of the COST message is more recent than the
value of the ancestor agent in its context. If it is, then the agent changes the value of the
ancestor agent in its context to the value of the ancestor agent in the context of the COST
message. Our example DCOP problem is too simple to allow us to illustrate the propagation
of the information up the pseudo-tree. However, imagine that a new agent a5 is a child agent
of agent a4 and is constrained with agents a1 and a4 . The context of agent a4 then contains
the value of agent a1 but agent a1 cannot send VALUE messages to agent a4 . However, agent
a1 sends VALUE messages to agent a5 . Agent a5 changes the value of agent a1 in its context
and sends COST messages with its context to agent a4 , which then changes the value of agent
a1 in its context as well.
The agents now need to determine whether the value of an agent in VALUE messages or in the
contexts of COST messages is more recent than the value of the agent in their contexts. Every
agent a therefore now also maintains a counter IDa and increments it whenever it changes its
value. Therefore, a larger ID indicates a more recent value. The values of agents in contexts
are now labeled with their IDs, and VALUE messages contain the identity of the sending agent,
its value, its ID and the desired threshold.
 Bounds: Whenever an agent changes its context X a , it previously initialized its bounds and
took on its best value. The (reduced) context of a child agent of an agent can now be a strict
subset of the (reduced) context of the agent since the parent or some pseudo-parent agents of
the agent might not be (parent or) pseudo-parent agents of the child agent or its descendant
agents. If the context of child agent c does not contain the values of any agents whose values
changed in the context of agent a, then agent a does not initialize its lower bounds lba,c
X a (d)
and upper bounds uba,c
(d)
for
agent
c
and
all
values
d
before
it
takes
on
its
best
value.
Agents
Xa
use this optimization because they need to initialize their bounds less often this way. For our
example DCOP problem, if agent a2 changes its context from {(a1 , 0)} to {(a1 , 1)} (where the
IDs are omitted for simplicity), then it does not initialize its lower bounds lbaX2a,a2 4 (d) and upper
bounds ubaX2a,a2 4 (d) for child agent a4 and all values d since the context of agent a4 does not
contain the value of agent a1 .
Additionally, if an agent a changes its context due to a COST message from its child agent c
and its new context X a is compatible with the context in the COST message, then agent a
a,c
can set its lower bound lba,c
X a (d) and upper bound ubX a (d) for agent c and the value d of agent
a in the COST message to the bounds in the COST message before it takes on its best value.
Agents use this optimization because the bounds in the COST message are more informed than
the initialized bounds. Our example DCOP problem is too simple to allow us to illustrate this
optimization. However, imagine again that a new agent a5 is a child agent of agent a4 and is
constrained with agents a1 and a4 . Assume that the context of agent a4 is {(a1 , 0), (a2 , 0)}
(where the IDs are again omitted for simplicity) and it receives a COST message from agent
a5 with context {(a1 , 1), (a4 , 0)}. Agent a4 then changes its context to {(a1 , 1), (a2 , 0)}, sets
4 ,a5
4 ,a5
its lower bound lba{(a
(0) and its upper bound uba{(a
(0) to the bounds in the
1 ,1),(a2 ,0)}
1 ,1),(a2 ,0)}
COST message and initializes all other bounds before it takes on its best value.

3.2.7 Pseudocode
Figure 9 shows the BnB-ADOPT pseudocode of every agent. The pseudocode does not index
variables with the context since this context is implicitly given by the variable X a . It uses the
predicate Compatible(X, X  ) = (a,d,ID)X,(a ,d ,ID )X  (a = a  d 
= d ) that determines if two
contexts X and X  are compatible, that is, if no agent takes on two dierent values in the two contexts
[Lines 35, 44, 46, 48 and 51]. The pseudocode also uses the procedure PriorityMerge(X, X  ) that
executes X  := {(a , d , ID )  X  | (a,d,ID)X (a = a )}  {(a , d , ID )  X  | (a,d,ID)X (a =

105

fiYeoh, Felner & Koenig

procedure Start()
[01]
X a := {(p, ValInit(p), 0) | p  SCP (a)};
[02]
IDa := 0;
[03]
forall c  C(a), d  Dom(a)
[04]
InitChild(c, d);
[05]
InitSelf ();
[06]
Backtrack();
[07]
loop forever
[08]
if (message queue is not empty)
[09]
while(message queue is not empty)
[10]
pop msg o message queue;
[11]
When Received(msg);
[12]
Backtrack();
procedure InitChild(c, d)
[13]
lba,c (d) := ha,c (d);
[14]
uba,c (d) := ;
procedure InitSelf ()

[15]
da := arg mindDom(a) { a (d) + cC(a) lba,c (d)};
a
a
[16]
ID := ID + 1;
[17]
T H a := ;
procedure Backtrack()
[18]
forall d  Dom(a) 
[19]
LB a (d) :=  a (d) + cC(a) lba,c (d);

[20]
UB a (d) :=  a (d) + cC(a) uba,c (d);
a
[21]
LB := mindDom(a) {LB a (d)};
[22]
UB a := mindDom(a) {UB a (d)};
[23]
if (LB a (da )  min{T H a , UB a })
[24]
da := arg mindDom(a) {LB a (d)} (choose the previous da if possible);
[25]
if a new da has been chosen
[26]
IDa := IDa + 1;
[27]
if ((a is root and UB a  LB a ) or termination message received)
[28]
Send(TERMINATE) to each c  C(a);
[29]
terminate execution;


[30]
Send(VALUE, a, da , IDa , min{T H a , UB a }   a (da )  c C(a)\c lba,c (da )) to each c  C(a);
a
a
[31]
Send(VALUE, a, d , ID , ) to each c  CD(a) \ C(a);
[32]
Send(COST, a, X a , LB a , UB a ) to pa(a) if a is not root;
procedure When Received(VALUE, p, dp , IDp , T H p )
[33]
X  := X a ;
[34]
PriorityMerge((p, dp , ID p ), X a );
[35]
if (!Compatible(X  , X a ))
[36]
forall c  C(a), d  Dom(a)
[37]
if (p  SCP (c))
[38]
InitChild(c, d);
[39]
InitSelf ();
[40]
if (p = pa(a))
[41]
T H a := T H p ;
procedure When Received(COST, c, X c , LB c , UB c )
[42]
X  := X a ;
[43]
PriorityMerge(X c , X a );
[44]
if (!Compatible(X  , X a ))
[45]
forall c  C(a), d  Dom(a)
[46]
if (!Compatible({(p, dp , ID p )  X  | p  SCP (c)},X a ))
[47]
InitChild(c,d);
[48]
if (Compatible(X c , X a ))
[49]
lba,c (d) := max{lba,c (d), LB c } for the unique (a , d, ID)  X c with a = a;
[50]
uba,c (d) := min{uba,c (d), UB c } for the unique (a , d, ID)  X c with a = a;
[51]
if (!Compatible(X  , X a ))
[52]
InitSelf ();
procedure When Received(TERMINATE)
[53]
record termination message received;

Figure 9: Pseudocode of BnB-ADOPT
a  ID  ID )}  {(a, d, ID)  X | (a ,d ,ID )X  (a = a  ID > ID )} and thus replaces the values

106

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

of agents in context X  with more recent values, if available, of the same agents in context X [Lines
34 and 43].
The code is identical for every agent except that the variable a is a self variable that points to
the agent itself. At the start, BnB-ADOPT calls Start() for every agent. When an agent a receives
a VALUE message from an ancestor agent, then the When Received handler for VALUE messages
is called with p being the ancestor agent, dp being the value of the ancestor agent, IDp being the
ID of the ancestor agent and T H p being the desired threshold for agent a if the ancestor agent is
its parent agent (and innity otherwise) [Line 11]. When agent a receives a COST message from a
child agent, then the When Received handler for COST messages is called with c being the child
c
agent, X c being the context of the child agent, LB c being the lower bound LBX
c of the child agent
c
c
and U B being the upper bound U BX c of the child agent [Line 11]. Finally, when agent a receives a
TERMINATE message from its parent agent, then the When Received handler for TERMINATE
messages is called without any arguments [Line 11].
BnB-ADOPT uses the same message passing and communication framework as ADOPT and
has the same memory requirements. It uses similar VALUE, COST and TERMINATE messages,
a similar strategy to update the context of an agent based on VALUE messages from its ancestor
agents and COST messages from its child agents, the same semantics for the bounds and the same
update equations to update these bounds. BnB-ADOPT and ADOPT both use thresholds but BnBADOPT uses the thresholds for pruning while ADOPT uses them to reconstruct partial solutions
that were purged from memory. Thus, BnB-ADOPT uses a dierent threshold initialization [Line
17], dierent desired threshold calculation [Line 30] and dierent termination condition [Line 27].
BnB-ADOPT also diers from ADOPT in that it maintains IDs that agents use to indicate the
recency of their values and labels the values of agents in contexts with their IDs.
3.2.8 Trace
Figures 10 and 11 show traces of the updates of the lower and upper bounds, respectively, for our
example DCOP problem, and Table 2 shows a trace of the update of all variables. BnB-ADOPT
uses the heuristic values haX1a,a1 2 (0) := 3, haX1a,a1 2 (1) := 6, haX2a,a2 3 (0) := 2, haX2a,a2 3 (1) := 2, haX2a,a2 4 (0) := 2
and haX2a,a2 4 (1) := 2 for all contexts X a1 and X a2 . These heuristic values were chosen by hand. Every
agent assigns the value of all its ancestor agents in its initial context to 0. We partition time into
cycles as in Figures 7 and 8 and continue to use the conventions made in the context of those gures.
 Cycle 1: Root agent a1 initializes its context X a1 to {} [Line 1]. It initializes the lower bounds
of nodes B (= lbaX1a,a1 2 (0)) and C (= lbaX1a,a1 2 (1)) to their heuristic values 3 and 6, respectively
a1
[Line 13]. It updates the lower bound of node a (= LBX
a1 (0)) to the sum of its delta cost
(= 0) and the lower bound of node B (= 3) according to the update equations [Line 19]. It
a1
updates the lower bound of node b (= LBX
a1 (1)) to the sum of its delta cost (= 0) and the
lower bound of node C (= 6) according to the update equations [Line 19]. It updates the
a1
lower bound of node A (= LBX
a1 ) to the minimum of the lower bound of node a (= 3) and
the lower bound of node b (= 6) according to the update equations [Line 21]. It initializes the
upper bounds of nodes B and C to innity [Line 14]. It updates the upper bounds of nodes a,
b and A to innity according to the update equations [Lines 20 and 22]. It takes on its best
value 0 since the lower bound of node a (= 3) is smaller than the lower bound of node b (= 6)
[Line 15], initializes its ID IDa1 to 1 [Lines 2 and 16], initializes its threshold T H a1 to innity
[Line 17] and sends VALUE messages to its child agent a2 and pseudo-child agent a3 [Lines 30
and 31].
Agent a2 initializes its context X a2 to {(a1 , 0, 0)} [Line 1]. It initializes the lower bounds of
nodes D, E, F and G to their heuristic value 2 [Line 13]. It updates the lower bounds of nodes
c, d and B to 9, 12 and 9, respectively [Lines 19 and 21]. It initializes the upper bounds of
nodes D, E, F and G to innity [Line 14]. It updates the upper bounds of nodes c, d and B
to innity [Lines 20 and 22]. The bounds of node B that agent a2 maintains are not shown
107

fiYeoh, Felner & Koenig

Cycle
X a1
da1
ID a1
T H a1
LB a1 (0)
LB a1 (1)
LB a1
U B a1 (0)
U B a1 (1)
U B a1
lba1 ,a2 (0)
lba1 ,a2 (1)
uba1 ,a2 (0)
uba1 ,a2 (1)
X a2
da2
ID a2
T H a2
LB a2 (0)
LB a2 (1)
LB a2
U B a2 (0)
U B a2 (1)
U B a2
lba2 ,a3 (0)
lba2 ,a3 (1)
uba2 ,a3 (0)
uba2 ,a3 (1)
lba2 ,a4 (0)
lba2 ,a4 (1)
uba2 ,a4 (0)
uba2 ,a4 (1)
X a3
da3
ID a3
T H a3
LB a3 (0)
LB a3 (1)
LB a3
U B a3 (0)
U B a3 (1)
U B a3
X a4
da4
ID a4
T H a4
LB a4 (0)
LB a4 (1)
LB a4
U B a4 (0)
U B a4 (1)
U B a4

1

2

3

4

5

6

7

8

9

0
1

3
6
3



3
6


(a1 , 0, 0)
0
1

9
12
9



2
2


2
2


(a1 , 0, 0)
(a2 , 0, 0)
0
1

10
14
10
10
14
10
(a2 , 0, 0)
0
1

3
8
3
3
8
3

0
1

9
6
6



9
6


(a1 , 0, 1)
1
2

18
12
12
18

18
10
2
10

3
2
3

(a1 , 0, 1)
(a2 , 0, 1)
0
1

10
14
10
10
14
10
(a2 , 0, 1)
0
1

3
8
3
3
8
3

0
1

12
6
6
18

18
12
6
18

(a1 , 0, 1)
1
2

18
12
12
18

18
10
2
10

3
2
3

(a1 , 0, 1)
(a2 , 1, 2)
0
2
8
8
13
8
8
13
8
(a2 , 1, 2)
1
2
8
10
3
3
10
3
3

0
1

12
6
6
18

18
12
6
18

(a1 , 0, 1)
0
3
18
18
19
18
18
19
18
10
8
10
8
3
3
3
3
(a1 , 0, 1)
(a2 , 1, 2)
0
2
8
8
13
8
8
13
8
(a2 , 1, 2)
1
2
8
10
3
3
10
3
3

1
2

18
6
6
18

18
18
6
18

(a1 , 0, 1)
0
3
18
18
19
18
18
19
18
10
8
10
8
3
3
3
3
(a1 , 0, 1)
(a2 , 0, 3)
0
3
10
10
14
10
10
14
10
(a2 , 0, 3)
0
3
3
3
8
3
3
8
3

1
2

18
6
6
18

18
18
6
18

(a1 , 1, 2)
1
4
18
25
8
8



2
2


3
3
3
3
(a1 , 1, 2)
(a2 , 0, 3)
1
4
10
25
7
7
25
7
7
(a2 , 0, 3)
0
3
3
3
8
3
3
8
3

1
2

18
8
8
18

18
18
8
18

(a1 , 1, 2)
1
4
18
30
8
8
30

30
7
2
7

3
3
3
3
(a1 , 1, 2)
(a2 , 1, 4)
1
5
12
23
6
6
23
6
6
(a2 , 1, 4)
1
4
13
10
3
3
10
3
3

1
2

18
8
8
18
30
18
18
8
18
30
(a1 , 1, 2)
1
4
18
30
12
12
30
12
12
7
6
7
6
3
3
3
3
(a1 , 1, 2)
(a2 , 1, 4)
1
5
12
23
6
6
23
6
6
(a2 , 1, 4)
1
4
13
10
3
3
10
3
3

1
2

18
12
12
18
12
12
18
12
18
12
(a1 , 1, 2)
1
4
18
30
12
12
30
12
12
7
6
7
6
3
3
3
3
(a1 , 1, 2)
(a2 , 1, 4)
1
5
6
23
6
6
23
6
6
(a2 , 1, 4)
1
4
3
10
3
3
10
3
3

Table 2: Trace of the Update of all Variables of BnB-ADOPT

108

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

A

OR

3

OR

6

OR

AND

a

b

AND

3

6

AND

9

OR

B

C

OR

3

6

OR

9

c

AND

D

OR

AND

d

g

E
h

i

e

F
j

k

G
l

m

f

H
n

o

I
p

q

J
r

s

K
t

9

AND

u

OR

v

AND

12

2

2

10 14 3

8

X

2

X

X

X

X

X X

X X

X X

X X

X X

X X

OR

AND

6

18

AND

2

Identifiers

10

12
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

6

OR

AND

12

6

AND

12

6

AND

18

OR

12

6

OR

12

6

OR

18

18

AND

OR

AND

12

10

3

X X

X X

2

X
2

8 13 10 3

X

18

AND

X

X

X

X

X X

X X

X X

X X

OR

AND

19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X

OR

AND

10

19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

8

OR

18

6

AND

18

8

AND

18

OR

18

6

OR

18

8

OR

18

X

OR

AND

X

X

X

X

X X

X X

X X

25
X

2

X X 25 7

8
3

3

8

X

AND

2

3

X X

X X

OR

AND

X

30

X

X

X

X

7

X X

X X

X X

X X

X X

Cycle 6

8
3

2

3

X X 23 6 10 3

AND

8
X

30

X

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 8

12

OR

AND

18

OR

18

12
12

X

AND

AND

OR

8

X

AND

Cycle 7

OR

X

3

Cycle 5

8

OR

X

8

AND

AND

6

18

AND

X

6

Cycle 4

6

OR

X
3

X

2

Cycle 2

6

OR

X

2

Cycle 1

6

OR

X

6

X

30

X

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 9

Figure 10: Trace of the Update of the Lower Bounds of BnB-ADOPT
in the gure. It takes on its best value 0 [Line 15], initializes its ID to 1 [Lines 2 and 16],
initializes its threshold to innity [Line 17] and sends VALUE messages to its child agents a3
and a4 and a COST message to its parent agent a1 [Lines 30-32].
Leaf agent a3 initializes its context X a3 to {(a1 , 0, 0), (a2 , 0, 0)} [Line 1]. It updates the lower
bounds of nodes g and h to their delta costs 10 and 14, respectively, since leaf agents do not
have child agents [Line 19]. It updates the lower bound of node D to 10 [Line 21]. It updates
the upper bounds of nodes g and h to their delta costs 10 and 14, respectively, since leaf agents
do not have child agents [Line 20]. It updates the upper bound of node D to 10 [Line 22]. The
bounds of node D that leaf agent a3 maintains are not shown in the gure. It takes on its
best value 0 [Line 15], initializes its ID to 1 [Lines 2 and 16], initializes its threshold to innity
[Line 17] and sends a COST message to its parent agent a2 [Line 32].
Leaf agent a4 initializes its (reduced) context X a4 to {(a2 , 0, 0)} [Line 1]. It updates the lower
bounds of nodes i and j to their delta costs 3 and 8, respectively [Line 19]. It updates the
lower bound of node E to 3 [Line 21]. It updates the upper bounds of nodes i and j to their
delta costs 3 and 8, respectively [Line 20]. It updates the upper bound of node E to 3 [Line
22]. The bounds of node E that leaf agent a4 maintains are not shown in the gure. It takes

109

fiYeoh, Felner & Koenig

A

OR

inf

OR

inf

OR

AND

a

b

AND

inf

inf

AND

inf

OR

B

C

OR

inf

inf

OR

inf

c

AND

D

OR

AND

d

g

E
h

i

e

F
j

k

G
l

m

f

H
n

o

I
p

q

J
r

s

inf

AND

K
t

u

OR

v

AND

inf

inf
inf

10 14 3

8

X

inf

X

X

X

X

X X

X X

X X

X X

X X

X X

10

OR

AND

inf
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 2

18

OR

18

OR

18

inf

AND

18

inf

AND

18

OR

18

inf

OR

18

inf

OR

18

18

OR

AND

inf

10

3

X X

X X

inf

X
inf

8 13 10 3

X

18

AND

X

X

X

X

X X

X X

X X

X X

OR

AND

19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X

10

OR

AND

19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

18

OR

18

inf

AND

18

inf

AND

18

OR

18

inf

OR

18

inf

OR

18

X

OR

AND

X

X

X

X

X X

X X

X X

inf
X

inf

X X 25 7

inf
3

3

8

X

AND

inf

3

X X

X X

OR

AND

X

30

X

X

X

X

7

X X

X X

X X

X X

X X

Cycle 6

inf
3

inf

3

X X 23 6 10 3

30

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 8

12

OR

AND

18

OR

18

12
12

X

AND

AND

30
X

X

OR

AND

30

X

AND

Cycle 7

OR

X

3

Cycle 5

18

OR

X

8

AND

AND

inf

18

AND

X

inf

Cycle 4

18

OR

X
3

X

inf

Cycle 1

18

X

inf

AND

AND

inf

18

AND

inf

Identifiers
OR

X

inf

X

30

X

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 9

Figure 11: Trace of the Update of the Upper Bounds of BnB-ADOPT
on its best value 0 [Line 15], initializes its ID to 1 [Lines 2 and 16], initializes its threshold to
innity [Line 17] and sends a COST message to its parent agent a2 [Line 32].
In summary, the following messages are sent during Cycle 1:
 message (VALUE, a1 , 0, 1, ) from agent a1 to agent a2 ;
 message (VALUE, a1 , 0, 1, ) from agent a1 to agent a3 ;
 message (VALUE, a2 , 0, 1, ) from agent a2 to agent a3 ;
 message (VALUE, a2 , 0, 1, ) from agent a2 to agent a4 ;
 message (COST, a2 , {(a1 , 0, 0)}, 9, ) from agent a2 to agent a1 ;
 message (COST, a3 , {(a1 , 0, 0), (a2 , 0, 0)}, 10, 10) from agent a3 to agent a2 ; and
 message (COST, a4 , {(a2 , 0, 0)}, 3, 3) from agent a4 to agent a2 .
 Cycle 2: Root agent a1 receives the COST message sent by its child agent a2 in Cycle 1. Since
the context of agent a1 (= {}) is compatible with the context in the message (= {(a1 , 0, 0)}), it
improves its bounds. It updates the bounds of node B to the bounds in the message (= 9 and
innity, respectively) [Lines 48-50]. It updates the bounds of nodes a, b and A [Lines 18-22].
110

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

a1
a1
It does not change its value since the lower bound of node a (= LBX
) = 9 for its value
a1 (d
a1
a1
a1
d = 0) is still smaller than its pruning quantity (= min{T HX a1 , U BX a1 } = min(, ) =
). It sends VALUE messages to its child agent a2 and pseudo-child agent a3 [Lines 30-31].

Agent a2 receives the VALUE message sent by its parent agent a1 in Cycle 1. It updates its
context from {(a1 , 0, 0)} to {(a1 , 0, 1)} since the ID of agent a1 in its context (= 0) is smaller
than the ID in the message (= 1) [Line 34]. Its threshold (= ) remains unchanged since it
is the same as the desired threshold (= ) in the message. Agent a2 also receives the COST
messages sent by its child agents a3 and a4 in Cycle 1. Since its context (= {(a1 , 0, 1)}) is compatible with the contexts in the messages (= {(a1 , 0, 0), (a2 , 0, 0)} and {(a2 , 0, 0)}, respectively),
it improves its bounds. It updates the bounds of node D to the bounds in the rst message
(= 10 and 10, respectively) and the bounds of node E to the bounds in the second message (= 3
and 3, respectively) [Lines 48-50]. It updates the bounds of nodes c, d and B [Lines 18-22]. It
a2
a2
) = 18 for its value da2 = 0) is
changes its value since the lower bound of node c (= LBX
a2 (d
a2
a2
no longer smaller than its pruning quantity (= min{T HX a2 , U BX
a2 } = min(, 18) = 18). It
takes on its best value 1 [Line 24], increments its ID to 2 [Lines 25-26], sends VALUE messages
to its child agents a3 and a4 [Lines 30-31] and sends a COST message to its parent agent a1
[Line 32].
Leaf agent a3 receives the VALUE messages sent by its parent agent a2 and pseudo-parent
agent a1 in Cycle 1. It updates its context from {(a1 , 0, 0), (a2 , 0, 0)} to {(a1 , 0, 1), (a2 , 0, 1)}
since the IDs of agents a1 and a2 in its context (= 0 and 0, respectively) are smaller than
the IDs in the messages (= 1 and 1, respectively) [Line 34]. Its threshold (= ) remains
unchanged since it is the same as the desired threshold (= ) in the message. Its bounds are
not reinitialized since its context is compatible with its previous context [Line 35]. It sends
the same COST message as before to its parent agent a2 [Line 32].
Leaf agent a4 receives the VALUE message sent by its parent agent a2 in Cycle 1. It updates its
contexts from {(a2 , 0, 0)} to {(a2 , 0, 1)} since the ID of agent a2 in its context (= 0) is smaller
than the ID in the message (= 1) [Line 34]. Its threshold (= ) remains unchanged since it is
the same as the desired threshold (= ) in the message. Its bounds are not reinitialized since
its context is compatible with its previous context [Line 35]. It sends the same COST message
as before to its parent agent a2 [Line 32].
In summary, the messages sent during Cycle 2 are identical to the ones sent during Cycle 1,
except for the messages sent by agents a2 , a3 and a4 , which are as follows:
 message (VALUE, a2 , 1, 2, 8) from agent a2 to agent a3 ;
 message (VALUE, a2 , 1, 2, 8) from agent a2 to agent a4 ; and
 message (COST, a2 , {(a1 , 0, 1)}, 12, 18) from agent a2 to agent a1 .
 message (COST, a3 , {(a1 , 0, 1), (a2 , 0, 1)}, 10, 10) from agent a3 to agent a2 ; and
 message (COST, a4 , {(a2 , 0, 1)}, 3, 3) from agent a4 to agent a2 .
The VALUE messages are dierent because agent a2 changed its value from 0 to 1. The COST
messages are dierent because agent a2 changed its bounds and its context and agents a3 and
a4 changed their contexts.
 Cycles 3-9: The messages sent during Cycle 3 are identical to the ones sent during Cycle 2,
except for the messages sent by agents a3 and a4 , which are as follows:
 message (COST, a3 , {(a1 , 0, 1), (a2 , 1, 2)}, 8, 8) from agent a3 to agent a2 ; and
 message (COST, a4 , {(a2 , 1, 2)}, 3, 3) from agent a4 to agent a2 .

111

fiYeoh, Felner & Koenig

The COST messages are dierent because agents a3 and a4 changed their contexts. The
termination conditions holds after a nite amount of time when the upper bound of node A
a1
a1
(= U BX
a1 = 12) is no larger than the lower bound of node A (= LBX a1 = 12) [Line 27]. Root
agent a1 sends TERMINATE messages to all child agents [Line 28], and the TERMINATE
messages propagate down the pseudo-tree [Line 28] until all agents terminate. BnB-ADOPT
terminates after nine cycles with minimal solution cost 12.

4. Bounded-Error Approximations
In this section, we present three approximation mechanisms that allow BnB-ADOPT to trade o
solution cost for a smaller runtime. They bound the error on the solution cost by a user-dened
error bound. First, we modify the Absolute Error Mechanism of ADOPT (Modi et al., 2005) to
work with BnB-ADOPT. This approximation mechanism allows users to specify an absolute error
bound on the solution cost (for example, that the solution cost should be at most 10 larger than the
minimal solution cost). However, it is often much more desirable to specify a relative error bound on
the solution cost (for example, that the solution cost should be at most 10 percent larger than the
minimal solution cost or, equivalently, 1.1 times larger than the minimal solution cost). This cannot
be done with the Absolute Error Mechanism without knowing the minimal solution cost a priori.
Thus, we introduce two approximation mechanisms that allow users to specify a relative error bound
on the solution cost, namely the Relative Error Mechanism and the Weighted Heuristics Mechanism.
All approximation mechanisms let the root agent r (and only the root agent) maintain the
limit limr . The root agent uses this limit in the same way in the termination condition for all
r
r
approximation mechanisms but updates it dierently. The termination condition U BX
r  LBX r on
r
r
Line 27 of the pseudocode of BnB-ADOPT is replaced with U BX r  lim . The root agent updates
the limit between Lines 26 and 27 in the pseudocode, outside of the preceding if statement.
4.1 Absolute Error Mechanism
The Absolute Error Mechanism of ADOPT requires a user-dened absolute error bound 0  b < 
that species that the solution cost should be at most b larger than the minimal solution cost. This
approximation mechanism can easily be modied for BnB-ADOPT by setting the limit as follows:
limr

:=

r
b + LBX
r

(20)

BnB-ADOPTAEM is the resulting variant of BnB-ADOPT with the Absolute Error Mechanism.
BnB-ADOPTAEM terminates once the upper bound of the root node (which is equal to the solution
cost of the solution with the smallest solution cost found so far) is no larger than the limit (which
is equal to the absolute error bound b plus the lower bound of the root node, which is a lower
bound on the minimal solution cost). BnB-ADOPTAEM terminates with a solution cost that is
equal to the upper bound of the root node although the minimal solution cost could be as small as
the lower bound of the root node. It thus terminates with a solution cost that is at most b larger
than the minimal solution cost. Figure 12 shows a trace of BnB-ADOPTAEM with absolute error
bound b = 24 for our example DCOP problem. BnB-ADOPTAEM terminates after three cycles
with suboptimal solution cost 18, which is six cycles faster than BnB-ADOPT.
4.2 Relative Error Mechanism
It is often much more desirable to specify a relative error bound on the solution cost rather than
an absolute error bound. Fortunately, the Absolute Error Mechanism of BnB-ADOPT can easily
be changed to the Relative Error Mechanism by setting the limit as follows. The Relative Error
112

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

a

3

OR

a

lim 1 = 27
a
UB 1 = infinity

a

lim 1 = 30
a
UB 1 = infinity

6

OR

6

OR

AND

3

6

AND

9

6

AND

12

OR

3

6

OR

9

6

OR

12

9

AND

OR

AND

2

12
2

10 14 3

8

X

X

18

AND

2

2

X

X

X

X

X X

X X

X X

X X

X X

X X

OR

AND

10

12
3

10 14 3

8

X

X

2

2

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 1

OR

AND

6
6

18

AND

lim 1 = 30
a
UB 1 = 18

12

10

3

X X

X X

2

X
2

8 13 10 3

Cycle 2

X

X

X

X

X

X X

X X

X X

X X

Cycle 3

Figure 12: Trace of the Update of the Lower Bounds of BnB-ADOPTAEM with b = 24
a

3

OR

a

lim 1 = 9
a
UB 1 = infinity

a

lim 1 = 18
a
UB 1 = infinity

6

OR

6

OR

AND

3

6

AND

9

6

AND

12

OR

3

6

OR

9

6

OR

12

9

AND

OR

AND

2

12
2

10 14 3

8

X

X

18

AND

2

2

X

X

X

X

X X

X X

X X

X X

X X

X X

OR

AND

10

12
3

10 14 3

8

X

X

2

2

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 1

Cycle 2

OR

AND

6
6

18

AND

lim 1 = 18
a
UB 1 = 18

12

10

3

X X

X X

2

X
2

8 13 10 3

X

X

X

X

X

X X

X X

X X

X X

Cycle 3

Figure 13: Trace of the Update of the Lower Bounds of BnB-ADOPTREM with p = 3
Mechanism requires a user-dened relative error bound 1  p <  that species that the solution
cost should be at most p times larger than the minimal solution cost:
limr

r
:= p  LBX
r

(21)

BnB-ADOPTREM is the resulting variant of BnB-ADOPT with the Relative Error Mechanism.
BnB-ADOPTREM terminates once the upper bound of the root node (which is equal to the solution
cost of the solution with the smallest solution cost found so far) is no larger than the limit (which
is equal to the relative error bound p times the lower bound of the root node, which is a lower
bound on the minimal solution cost). BnB-ADOPTREM terminates with a solution cost that is
equal to the upper bound of the root node although the minimal solution cost could be as small as
the lower bound of the root node. It thus terminates with a solution cost that is at most p times
larger than the minimal solution cost. Figure 13 shows a trace of BnB-ADOPTREM with relative
error bound p = 3 for our example DCOP problem. BnB-ADOPTREM terminates after three cycles
with suboptimal solution cost 18, which is six cycles faster than BnB-ADOPT.
4.3 Weighted Heuristics Mechanism
There is a second way of implementing a relative error bound for BnB-ADOPT since BnB-ADOPT
uses admissible heuristic values. It is common practice in the context of A* to trade o solution
cost for a smaller runtime by using weighted heuristic values (Pohl, 1973), which are derived from
admissible heuristic values by multiplying them with a user-dened weight 1  w < . The
resulting heuristic values can be inadmissible. A* is then no longer guaranteed to nd cost-minimal
solutions but it is guaranteed to terminate with a solution cost that is at most w times larger than
the minimal solution cost (Pohl, 1970). This approximation mechanism can easily be modied for
BnB-ADOPT by setting the limit as follows:
limr

:=

113

r
LBX
r

(22)

fiYeoh, Felner & Koenig

a

9

OR

a

lim 1 = 9
a
UB 1 = infinity

a

lim 1 = 17

lim 1 = 18

17 UBa1 = infinity

OR

18 UBa1 = 18

OR

AND

9

18

AND

17

18

AND

20

OR

9

18

OR

17

18

OR

20

17

AND

OR

AND

6

20
6

10 14 3

8

X

X

21

AND

6

6

X

X

X

X

X X

X X

X X

X X

X X

X X

OR

AND

10

20
6

10 14 3

8

X

X

6

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 1

Cycle 2

OR

AND

18

21

AND

6

18

20

10

6

X X

X X

6

X
6

8 13 10 3

X

X

X

X

X

X X

X X

X X

X X

Cycle 3

Figure 14: Trace of the Update of the Lower Bounds of BnB-ADOPTW HM with w = 3
and by initializing the lower bounds lba,c
X a (d) as follows:
lba,c
X a (d)

:= w  ha,c
X a (d)

(23)

for all agents a, all values d, all child agents c and all contexts X a . BnB-ADOPTW HM is the
resulting variant of BnB-ADOPT with the Weighted Heuristics Mechanism. BnB-ADOPTW HM
terminates once the upper bound of the root node (which is equal to the solution cost of the solution
with the smallest solution cost found so far) is no larger than the limit (which is equal to the lower
bound of the root node, which is a lower bound on w times the minimal solution cost). BnBADOPTW HM terminates with a solution cost that is equal to the upper bound of the root node
although the minimal solution cost could be as small as the lower bound of the root node divided
by w. It thus terminates with a solution cost that is at most w times larger than the minimal
solution cost. Figure 14 shows a trace of BnB-ADOPTW HM with w = 3 for our example DCOP
problem. BnB-ADOPTW HM terminates after three cycles with suboptimal solution cost 18, which
is six cycles faster than BnB-ADOPT.

5. Correctness and Completeness
In this section, we prove the correctness and completeness of BnB-ADOPT and its suboptimal
variants. All denitions, lemmata, theorems and corollaries hold for BnB-ADOPT and its suboptimal variants except when mentioned otherwise. Therefore, each agent a uses the following update
equation for all values d, all child agents c and all contexts X a to initialize its bounds lba,c
X a (d):
a,c
lba,c
X a (d) := w  hX a (d)

(24)

where the weight w is a oating point number that satises 1  w <  and the heuristic values
ha,c
X a (d) are oating point numbers that satisfy
c
0  ha,c
X a (d)  X a (a,d)

(25)

Messages are sent at the end of a cycle and received in the beginning of a cycle.  is the largest
duration between the time a message is sent and the time it is processed, and  is the largest duration
of a cycle.
Lemma 1. If two contexts X and X  of an arbitrary agent a  A agree on the values of all ancestor
a
a
= X
agents p  SCP (a) of agent a, then X
.
Proof. By denition, X a  X is the (reduced) context that contains the values of all ancestor agents
a
is the sum of the constraint costs of all constraints that
p  SCP (a) of agent a. The gamma cost X
114

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

involve agent a or one of its descendant agents minimized over all possible values of agent a and its
descendant agents, under the assumption that the ancestor agents of agent a take on the values in
a
thus depends only on the values of the ancestor agents (including
context X. The gamma cost X
the parent agent) of agent a that are the parent or pseudo-parent agents of agent a or one (or more)
of its descendant agents, that is, the values of all ancestor agents p  SCP (a) of agent a. Therefore,
a
a
a
a
= X
X
a . Similarly, X  = X a .
Definition 1. Contexts are correct i the IDs of the values of all agents in the contexts are equal
to the IDs of the agents, which implies that the values of all agents in the contexts are equal to the
values of the agents.
Lemma 2. If the context X a of an arbitrary agent a  A does not change for a period of time,
a
a
then the lower bounds lba,c
X a (d), LBX a (d) and LBX a are monotonically non-decreasing and the upper
a,c
a
a
bounds ubX a (d), U BX a (d) and U BX a are monotonically non-increasing during that period of time
for all values d  Dom(a) and all child agents c  C(a).
a
Proof. Since the context X a does not change, the delta values X
a (d) are constant and the bounds
(once initialized) are updated according to update equations 8 to 13. Thus, the lower bounds are
monotonically non-decreasing and the upper bounds are monotonically non-increasing.

Lemma 3. If the value of an arbitrary ancestor agent p  SCP (a) of an arbitrary agent a  A does
not change between the current time T and a future time t with t  T + |A|  ( + ) + , then the
value of agent p and its ID in the context of agent a are equal to the value of agent p and its ID,
respectively, between some time t and time t with t  t.
Proof. Assume that the value of an arbitrary ancestor agent p  SCP (a) of an arbitrary agent a  A
does not change between the current time T and a future time t with t  T + |A|  ( + ) + . There
are the following two cases.
 Case 1: If agent p is a parent or pseudo-parent agent of agent a, then it sent a VALUE message
to agent a with its value and ID at time t  T + , that is, in the same cycle in which it took
on the value that it has at time T since the duration of that cycle is no larger than . (The
agents send VALUE messages at the end of every cycle.) Agent a receives the VALUE message
by time t +  since messages are delivered with nite delay . It then updates the value of
agent p and its ID in its context by time t +  +  since the update is done in the same cycle
and the duration of that cycle is no larger than . Thus, the value of agent p and its ID in
the context of agent a are equal to the value of agent p and its ID, respectively, between some
time t and time t with t  t  t +  +   T +  + 2    t since agent p does not change
its value between time t and time t.
 Case 2: If agent p is not a parent or pseudo-parent agent of agent a, then one of its pseudo-child
agents c is a descendant agent of agent a. Agent p sent a VALUE message to agent c with its
value and ID at time t  T + . Agent c receives the VALUE message by time t + . It then
updates the value of agent p and its ID in its context and sends a COST message to its parent
agent pa(c) with its updated context by time t +  + . (The agents send COST messages at
the end of every cycle.) Agent pa(c) receives the COST message by time t + 2   + . It then
updates the value of agent p and its ID in its context and sends a COST message to its parent
agent pa(pa(c)) with its updated context by time t + 2  ( + ). This process continues until
agent a updates the value of agent p and its ID in its context by time t + n  ( + ), where
n  |A| is the number of messages in the chain of messages. Thus, the value of agent p and its
ID in the context of agent a are equal to the value of agent p and its ID, respectively, between
some time t and time t with t  t  t + n  ( + )  T + |A|  ( + ) +   t since agent
p does not change its value between time t and time t.

115

fiYeoh, Felner & Koenig

Corollary 1. If the values of all ancestor agents p  SCP (a) of an arbitrary agent a  A do not
change between the current time T and a future time t with t  T + |A|  ( + ) + , then the context
of agent a is correct between some time t and time t with t  t.
c
c
c
Lemma 4. If LBX
c  w  X c  w  U BX c at all times for all child agents c  C(a) of an arbitrary
a,c
a,c
c
c
agent a and their contexts X , then lbX a (d)  w  X
a (a,d)  w  ubX a (d) at all times for the context
X a of agent a, all values d  Dom(a) and all child agents c  C(a).

Proof. We prove the lemma by induction on the number of times that agent a changes its context
a,c
or updates its bounds lba,c
X a (d) and ubX a (d) for an arbitrary value d and an arbitrary child agent c
after agent a initializes its bounds. The conclusion of the lemma holds after agent a with context
X a initializes its bounds since
a,c
lba,c
X a (d) = w  hX a (d)

(Eq. 24)

w

(Eq. 25)

c
X
a (a,d)


= w  uba,c
X a (d)

(Eq. 7)

for the (unchanged or new) context X a of agent a (induction basis). Now assume that the lemma
holds after agent a changed its context or updated its bounds a number of times (induction assumption). We show that it then also holds after agent a changes its context or updates its bounds one
more time (induction step). There are the following two cases (where we split the operations after
receiving a COST message into two parts).
 Case 1: The conclusion of the lemma holds when agent a changes its context from X a to X a
after receiving a VALUE or COST message and the two contexts agree on the values of all
ancestor agents p  SCP (c) since agent a then does not change its bounds and thus
(d) = lba,c
lba,c
X a (d)
X a
c
 w  X
a (a,d)

(induction assumption)

c
w  X
a (a,d)
a,c
ubX a (d)
c
X
a (a,d)
c
X a (a,d)

(Lemma 1)

=
uba,c
(d)
X a

(premise of case)

=

=

(premise of case)
(induction assumption)
(Lemma 1)

after receiving the VALUE or COST message (since contexts X a and X a agree on the values
of all ancestor agents p  SCP (c)).
 Case 2: The conclusion of the lemma holds when agent a updates its bounds from lba,c
X a (d) and
a,c
a,c
a,c


ubX a (d) to lbX a (d) and ubX a (d), respectively, after receiving a COST message from some child
c
c
c
agent c with bounds LBX
that is compatible with its context X a
c and U BX c and context X
and in which agent a has value d since

116

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

 a,ca (d) = max{lba,ca (d), LB c c }
lb
X
X
X
c
c
 max{w  X
a (a,d) , w  X c }

(Eq. 8)
(induction assumption and premise of lemma)

c
c
= max{w  X
a (a,d) , w  X a (a,d) }

=w
 a,ca (d)
ub
X

(Lemma 1)

c
X
a (a,d)

c
= min{uba,c
X a (d), U BX c }
c
c
 min{X
a (a,d) , X c }

(Eq. 11)
(induction assumption and premise of lemma)

c
c
= min{X
a (a,d) , X a (a,d) }

=

(Lemma 1)

c
X
a (a,d)

after receiving the COST message (since contexts X a  (a, d) and X c agree on the values of
all ancestor agents p  SCP (c)).
a,c
c
Thus, lba,c
X a (d)  w  X a (a,d)  w  ubX a (d) at all times for all values d  Dom(a) and all child
agents c  C(a).
a
a
a
a
a
a
Lemma 5. LBX
a (d)  w  X a (d)  w  U BX a (d) and LBX a  w  X a  w  U BX a at all times for
a
all values d  Dom(a) and the context X of an arbitrary agent a  A.

Proof. We prove the lemma by induction on the depth of an agent in the pseudo-tree. The lemma
holds for a leaf agent a in the pseudo-tree with context X a since
a
a
LBX
a (d) = X a (d)

(Eq. 9)

a
X
a (d)
a
X a (d)
a
X
a (d)

(Eq. 1)
(Eq. 12)

=
a
U BX
a (d) =
=

(Eq. 1)

a
a
a
a
for all values d at all times. Thus, LBX
a (d) = X a (d)  w  X a (d) = w  U BX a (d) for all values d
at all times. Furthermore,

a
LBX
a =

=

a
U BX
a

min

a
{LBX
a (d)}

(Eq. 10)

dDom(a)

min

a
{X
a (d)}

(see above)

dDom(a)

a
= X
a
= min

(Eq. 2)
(Eq. 13)

a
{U BX
a (d)}
dDom(a)

=

min

a
{X
a (d)}

(see above)

dDom(a)
a
= X
a

(Eq. 2)

a
a
a
a
at all times. Thus, LBX
a = X a  w  X a = w  U BX a at all times (induction basis). Now assume
that the lemma holds for all agents of depth d in the pseudo-tree (induction assumption). We show
that it then also holds for all agents of depth d  1 in the pseudo-tree each time after they update
their bounds (induction step). The lemma holds for agent a with context X a since

117

fiYeoh, Felner & Koenig



a
a
LBX
a (d) = X a (d) +

lba,c
X a (d)

(Eq. 9)

cC(a)



a
 X
a (d) +

c
w  X
a (a,d)

(induction assumption and Lemma 4)

cC(a)
a
 w  X
a (d)
a
a
U BX
a (d) = X a (d) +

(Eq. 1)



uba,c
X a (d)

(Eq. 12)

cC(a)



a
 X
a (d) +

c
X
a (a,d)

(induction assumption and Lemma 4)

cC(a)
a
= X
a (d)

(Eq. 1)

a
a
a
Thus, LBX
a (d)  w  X a (d)  w  U BX a (d) at all times for all values d  Dom(a). Furthermore,

a
LBX
a =



min

a
{LBX
a (d)}

(Eq. 10)

dDom(a)

min

a
{w  X
a (d)}

(see above)

dDom(a)

=w

min

a
{X
a (d)}

dDom(a)

a
= w  X
a
a
U BX
a

=


(Eq. 2)

a
min {U BX
a (d)}
dDom(a)

min

(Eq. 13)

a
{X
a (d)}

(see above)

dDom(a)

a
= X
a

(Eq. 2)

a
a
a
Thus, LBX
a  w  X a  w  U BX a at all times.

Definition 2. The potential of an agent a  A with context X a is
a
LBX
a (d)}.



dDom(a) {w

a
 U BX
a (d) 

Lemma 6. If the context X a of an arbitrary agent a  A no longer changes, then the potential of
the agent is monotonically non-increasing and decreases by more than a positive constant every time
the agent changes its value.
a
a
Proof. The lower bounds LBX
a (d) are monotonically non-decreasing and the upper bounds U BX a (d)
are monotonically non-increasing for all values d according to Lemma 2 since the context X a of
agent a no longer changes. Therefore, the potential of agent a is monotonically non-increasing.
a
a
Furthermore, agent a changes its value d to a new value only if mindDom(a) {LBX
a (d)} < LBX a (d)
a
[Line 24]. Thus, the lower bound LBX a (d) must have strictly increased between the time when the
agent changed its value to d and the time when it changes its value d to a new value. Thus, its
potential has decreased by more than a positive constant, namely the smallest possible increase of the
a
lower bound LBX
a (d). Assume that all constraint costs, weights and heuristic values are integers.
Then, the smallest possible increase is bounded from below by one because the only possible values of
a
LBX
a (d) are combinations of all constraint costs and weighted heuristic values. A similar statement
holds if all constraint costs, weights and heuristic values are oating point numbers since they can
then all be transformed into integers by multiplying them with the same suciently large integer.

Lemma 7. All agents change their values only a nite number of times.
118

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

Proof. Assume that the lemma does not hold and choose an agent a that changes its value an
innite number of times but whose ancestor agents p  SCP (a) change their values only a nite
number of times. Then, there exists a time when the ancestor agents do not change their values
any longer. There exists a (later) time when agent a no longer changes its context X a according to
Corollary 1. Every time agent a changes its value afterwards, its potential decreases by more than
a positive constant according to Lemma 6, towards minus innity. However, its potential cannot
a
a
become negative since LBX
a (d)  w  U BX a (d) for all values d according to Lemma 5, which is a
contradiction. Thus, all agents change their values only a nite number of times.
a
Lemma 8. If BnB-ADOPT and its suboptimal variants do not terminate earlier, then U BX
a 
a
a
LBX a after a nite amount of time for all agents a  A and their contexts X .

Proof. We prove the lemma by induction on the depth of an agent in the pseudo-tree. There exists
a time when no agent changes its value any longer according to Lemma 7. There exists a (later)
time when the contexts of all agents are correct and no longer change according to Corollary 1. Let
X a be the context of agent a at this point in time for all agents a. There exists an (even later)
a,c
a
a
a
a
time when the bounds lba,c
X a (d), LBX a (d), LBX a , ubX a (d), U BX a (d) and U BX a no longer change
a
for all agents a, all values d and all child agents c since (1) the lower bounds lba,c
X a (d), LBX a (d) and
a,c
a
a
a
LBX a are monotonically non-decreasing and the upper bounds lbX a (d), U BX a (d) and U BX
a are
monotonically non-increasing for all agents a, all values d and all child agents c according to Lemma
a
a
a
a
a
a
2, (2) LBX
a (d)  w  X a (d)  w  U BX a (d) and LBX a  w  X a  w  U BX a for all agents a and
a,c
a,c
all values d according to Lemma 5, (3) lbX a (d)  w  ubX a (d) for all agents a, all values d and all
child agents c according to Lemma 4 and (4) the smallest possible increases of the lower bounds and
the smallest possible decreases of the upper bounds are larger than a positive constant since the
only possible values of the bounds are combinations of all constraint costs and heuristic values, as
explained in more detail in the proof of Lemma 6. Consider the rst COST message that each agent
sends after this time and the earliest time when all of these COST messages have been processed by
their receiving agents. The lemma holds for a leaf agent a in the pseudo-tree with context X a since
a
a
LBX
a (d) = X a (d)
a
= X
a (d)

(Eq. 9)
(Eq. 1)

a
a
U BX
a (d) = X a (d)
a
= X
a (d)

(Eq. 12)
(Eq. 1)

for all values d after the considered time. Furthermore,
a
LBX
a =

=

a
U BX
a

min

a
{LBX
a (d)}

min

a
{X
a (d)}

(Eq. 10)

dDom(a)

(see above)

dDom(a)

a
= X
a
= min

(Eq. 2)
(Eq. 13)

a
{U BX
a (d)}
dDom(a)

=

min

a
{X
a (d)}

(see above)

dDom(a)

a
= X
a

(Eq. 2)

a
a
after the considered time. Thus, U BX
a = LBX a after the considered time (induction basis). Now
assume that the lemma holds for all agents of depth d in the pseudo-tree after the considered time
(induction assumption). We show that it then also holds for all agents of depth d  1 in the pseudotree after the considered time (induction step). For agent a with context X a

119

fiYeoh, Felner & Koenig

a
a
LBX
a (d) = X a (d) +



lba,c
X a (d)

(Eq. 9)

c
max{lba,c
X a (d), LBX c }

(Eq. 8)

cC(a)
a
= X
a (d) +



cC(a)
a
 X
a (d) +



c
LBX
c

cC(a)



a
X
a (d)

+



c
U BX
c

(induction assumption)

cC(a)
a
 X
a (d) +



c
min{uba,c
X a (d), U BX c }

cC(a)

=

a
X
a (d)

+



uba,c
X a (d)

(Eq. 11)

cC(a)
a
= U BX
a (d)

(Eq. 12)

a
for its value d after the considered time since all bounds no longer change. Thus, U BX
a (d) 
a
(d)
for
its
value
d
after
the
considered
time.
Since
agent
a
does
not
change
its
value
d after
LBX
a
a
a
a
a
the considered time, it must hold that LBX
(d)
<
min{T
H
,
U
B
}
[Line
23]
or
LB
a
Xa
Xa
X a (d) =
a
mindDom(a) {LBX
(d)}
[Line
24].
The
rst
disjunct
implies
that
a

a
a
a
min{T HX
a , U BX a }  U BX a
a
 U BX
a (d)
a
 LBX a (d)

(Eq. 13)
(see above)

a
a
< min{T HX
a , U BX a }

(rst disjunct)

for its value d, which is a contradiction. The second disjunct implies that
a
a
U BX
a  U BX a (d)
a
 LBX
a (d)

=

min

(Eq. 13)
(see above)

a
{LBX
a (d)}

(second disjunct)

dDom(a)

a
= LBX
a

(Eq. 10)

a
a
for its value d and thus that U BX
a  LBX a .

Theorem 1. BnB-ADOPT and its suboptimal variants terminate after a nite amount of time.
a
a
Proof. If BnB-ADOPT and its suboptimal variants do not terminate earlier, then U BX
a  LBX a
after a nite amount of time for all agents a  A and their contexts X a according to Lemma 8.
r
r
r
r
In particular, U BX
for the root agent r, where limr = LBX
r  LBX r  lim
r for BnB-ADOPT
r
r
with
b

0
for
BnB-ADOPT
and
limr = p  LBX
and BnB-ADOPTW HM , limr = b + LBX
r
r
AEM
with p  1 for BnB-ADOPTREM according to Section 4. Thus, both the termination condition
r
r
r
r
U BX
of its suboptimal
r  LBX r of BnB-ADOPT and the termination condition U BX r  lim
variants are satised.
r
Theorem 2. BnB-ADOPT terminates with the minimal solution cost X
r.

120

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

Proof. BnB-ADOPT terminates after a nite amount of time according to Theorem 1. The solution
r
r
r
cost of BnB-ADOPT is the upper bound U BX
r of the root agent r. U BX r  LBX r upon termination
r
r
r
according to its termination condition. w  U BX r  w  X r  LBX r according to Lemma 5.
r
r
r
Therefore, U BX
r = X r = LBX r since w = 1.
Theorem 3. BnB-ADOPTAEM terminates with a solution cost that is bounded from above by the
r
user-dened absolute error bound b plus the minimal solution cost X
r.
Proof. BnB-ADOPTAEM terminates after a nite amount of time according to Theorem 1. The
r
r
r
solution cost of BnB-ADOPTAEM is the upper bound U BX
r of the root agent r. U BX r  lim =
r
r
r
b + LBX r upon termination according to its termination condition. LBX r  w  X r according to
r
r
Lemma 5. Therefore, U BX
r  b + X r since w = 1.
Theorem 4. BnB-ADOPTREM terminates with a solution cost that is bounded from above by the
r
user-dened relative error bound p times the minimal solution cost X
r.
Proof. BnB-ADOPTREM terminates after a nite amount of time according to Theorem 1. The
r
r
r
solution cost of BnB-ADOPTREM is the upper bound U BX
r of the root agent r. U BX r  lim =
r
r
r
p  LBX r upon termination according to its termination condition. LBX r  w  X r according to
r
r
Lemma 5. Therefore, U BX
r  p  X r since w = 1.
Theorem 5. BnB-ADOPTW HM terminates with a solution cost that is bounded from above by the
r
user-dened weight w times the minimal solution cost X
r.
Proof. BnB-ADOPTW HM terminates after a nite amount of time according to Theorem 1. The
r
r
r
solution cost of BnB-ADOPTW HM is the upper bound U BX
r of the root agent r. U BX r  lim =
r
r
r
upon
termination
according
to
its
termination
condition.
LB

w


according
to
LBX
r
Xr
Xr
r
r
Lemma 5. Therefore, U BX

w


.
r
Xr

6. Experimental Evaluations
In this section, we compare BnB-ADOPT to two other memory-bounded DCOP search algorithms
that also restrict communication to agents that share constraints, namely ADOPT and NCBB. We
also compare the three suboptimal variants of BnB-ADOPT to each other. We use the distributed
DFS algorithm with the max-degree heuristic (Hamadi, Bessiere, & Quinqueton, 1998) that is used
by ADOPT to construct the pseudo-trees. We use DP2 (Ali et al., 2005) that is used by ADOPT to
pre-calculate the heuristic values for ADOPT and BnB-ADOPT. DP2 solves a relaxed version of the
given DCOP problem (where backedges are ignored) with a dynamic programming based approach.
NCBB calculates its own heuristic values during the search rather than in a pre-processing step.
6.1 Runtime Metrics
We use two common runtime metrics, namely non-concurrent constraint checks (Meisels, Kaplansky,
Razgon, & Zivan, 2002) and cycles (Modi et al., 2005).
 Non-concurrent constraint checks (NCCCs): NCCCs are a weighted sum of processing
and communication time. Every agent a maintains a counter N CCC a , which is initialized
to 0. The agent assigns N CCC a := N CCC a + 1 every time it performs a constraint check
to account for the time it takes to perform the constraint check. It assigns N CCC a :=

max{N CCC a , N CCC a + t} every time it receives a message from agent a to account for the

time it takes to wait for agent a to send the message (N CCC a ) and the transmission time
of the message (t). We use t = 0 to simulate fast communication and t = 1000 to simulate
slow communication. The number of NCCCs then is the largest counter value of any agent.

121

fiYeoh, Felner & Koenig

Sensors
1
3

2

Targets
5

6

7

8

9

4
10

11

12

13

Constraints

A unit

Figure 15: Example: Allocating Targets

Figure 16: Example: Scheduling Meetings

NCCCs are a good runtime metric if the ratio of processing and communication time can be
estimated reliably.
 Cycles: Cycles are time slices. A cycle is the time required for an agent to process all incoming
messages in its queue and send all outgoing messages, which are then processed by the receiving
agents in the next cycle. Thus, the number of cycles indicates the length of the longest chain
of messages between agents. Cycles are a good runtime metric if the communication time is
much larger than the processing time. Cycles will become a better and better runtime metric
in the future since the communication time is expected to remain relatively stable while the
processing time is expected to decrease (Silaghi, Lass, Sultanik, Regli, Matsui, & Yokoo, 2008).
6.2 DCOP Problem Types
We use three DCOP problem types in our experiments, namely graph coloring problems, sensor
network problems and meeting scheduling problems.
 Graph coloring: Graph coloring problems involve coloring the vertices of a graph, taking
restrictions between the colors of adjacent vertices into account. The agents are the vertices,
their domains are the colors, and the constraints are between adjacent vertices. We vary the
number of vertices from 5 to 15, the constraint density (= the ratio between the number of
constraints and the number of agents) from 2 (sparse graphs) to 3 (dense graphs) and the
range of constraint costs from a range of 0 to 1 (small range) to a range of 0 to 10,000 (large
range). Each agent always has three possible values. We average the experimental results over
50 DCOP problem instances with randomly generated constraints and randomly generated
integer constraint costs.
 Sensor network: Sensor network problems involve assigning targets to sensors in a sensor
network, taking restrictions in the availability of the sensors, restrictions in the number of
sensors that need to track each target and the priorities of the targets into account. The
agents are the targets, their domains are the time slots when they can be tracked, and the
constraints are between adjacent targets (Maheswaran et al., 2004b). Figure 15 shows a sensor
network where the targets are located on a grid and each target is surrounded by four sensors,
all of which are needed to track the target. We vary the number of targets from 4 to 15. We
always use 8 time slots. The cost of assigning a time slot to a target that is also assigned to an
adjacent target is innity (to be precise: 1,000,000) since the same sensor cannot track both
targets during the same time slot. The cost of targets that are not tracked during any time
slot is 100. All other costs are in the range of 0 to 100. We average the experimental results
over 50 DCOP problem instances with randomly generated integer constraint costs.
 Meeting scheduling: Meeting scheduling problems involve scheduling meetings between the
employees of a company, taking restrictions in their availability as well as their priorities into
account. The agents are the meetings, their domains are the time slots when they can be
held, and the constraints are between meetings that share participants (Maheswaran et al.,
122

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

Graph Coloring, Density = 2
Communication Cost = 0

Graph Coloring, Density = 2
Communication Cost = 1000

1.E+08
ADOPT
BnB-ADOPT
NCBB

1.E+04

NCCC

NCCC

1.E+05

1.E+03
1.E+02

ADOPT
BnB-ADOPT
NCBB

1.E+07
1.E+06
1.E+05

5

6

7

8

9

10

11

12

13

14

5

6

7

Number of Vertices

8

9

(a)
Graph Coloring, Density = 2

12

13

14

Graph Coloring, Density = 3
Communication Cost = 0

1.E+06

ADOPT
BnB-ADOPT
NCBB

NCCC

1.E+05
Cycles

11

(b)

1.E+04

1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+04
1.E+03
1.E+02

1.E+02
5

6

7

8
9
10 11
Number of Vertices

12

13

7

14

8

9

11

12

13

14

(d)

Graph Coloring, Density = 3
Communication Cost = 1000

1.E+09

10

Number of Vertices

(c)

Graph Coloring, Density = 3
1.E+05

Cycles

ADOPT
BnB-ADOPT
NCBB

1.E+08
NCCC

10

Number of Vertices

1.E+07
1.E+06
1.E+05

1.E+04
ADOPT
BnB-ADOPT
NCBB

1.E+03
1.E+02

7

8

9

10

11

12

13

14

7

8

9

10

11

12

13

14

Number of Vertices

Number of Vertices

(e)

(f)

Figure 17: Experimental Results Comparing ADOPT, BnB-ADOPT and NCBB for Graph Coloring
Problems with Constraint Costs Ranging from 0 to 10,000

2004b). Figure 16 shows a hierarchical organization with 4 units of a supervisor and its three
subordinates. For example, supervisor 2 has three subordinates 5, 6 and 7. In each unit, we
assume ve possible meetings: one of the entire unit (e.g., 2, 5, 6, 7), two parent-child meetings
(e.g., 2, 5 and 2, 7) and two sibling-sibling meetings (e.g., 5, 6 and 6, 7). We vary the number
of meetings from 5 (1 unit) to 20 (4 units). We always use 8 time slots. The cost of assigning
a time slot to a meeting that has at least one participant who has another meeting during the
same time slot is innity (to be precise: 1,000,000) since the same person cannot attend more
than one meeting at a time. The cost of a non-scheduled meeting is 100. All other costs are in
the range of 0 to 100. We average the experimental results over 50 DCOP problem instances
with randomly generated integer constraint costs.

123

fiYeoh, Felner & Koenig

1.E+05

Graph Coloring, Density = 2
Communication Cost = 0

1.E+08
1.E+07
NCCC

NCCC

1.E+04

Graph Coloring, Density = 2
Communication Cost = 1000

1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+06
ADOPT
BnB-ADOPT
NCBB

1.E+05

1.E+01

1.E+04
0-1

0-10

0-100

0-1,000 0-10,000

0-1

Range of Constraint Costs

0-10

0-100

0-1,000 0-10,000

Range of Constraint Costs

(a)

(b)

Graph Coloring, Density = 2
1.E+06

1.E+04

Graph Coloring, Density = 3
Communication Cost = 0

NCCC

Cycles

1.E+05
1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+04
1.E+03

ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+01

1.E+01
0-1

0-10

0-100

0-1,000 0-10,000

0-1

Range of Constraint Costs

(c)

1.E+09

0-100

0-1,000 0-10,000

(d)

Graph Coloring, Density = 3
Communication Cost = 1000

Graph Coloring, Density = 3
1.E+05

1.E+08

1.E+04
Cycles

NCCC

0-10

Range of Constraint Costs

1.E+07
1.E+06

ADOPT
BnB-ADOPT
NCBB

1.E+05

1.E+03

ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+04

1.E+01
0-1

0-10

0-100

0-1,000 0-10,000

Range of Constraint Costs

0-1

0-10

0-100

0-1,000 0-10,000

Range of Constraint Costs

(e)

(f)

Figure 18: Experimental Results Comparing ADOPT, BnB-ADOPT and NCBB for Graph Coloring
Problems with 10 Vertices

6.3 Experimental Results: Optimal DCOP Search Algorithms
We rst compare BnB-ADOPT to ADOPT and NCBB. Figure 17 shows our experimental results
for graph coloring problems with constraint costs ranging from 0 to 10,000, where we varied the
number of vertices, while Figure 18 shows our experimental results for graph coloring problems
with 10 vertices, where we varied the range of constraint costs. Figures 17(a-c) and 18(a-c) show
the results for coloring sparse graphs, and Figures 17(d-f) and 18(d-f) show the results for coloring
dense graphs. The y-axes are in log scale and show the runtimes in NCCCs or cycles. DCOP search
algorithms on sparse graphs are faster than on dense graphs because, for example, there is a larger
likelihood of independent DCOP subproblems in sparse graphs. BnB-ADOPT is generally faster
than NCBB on sparse graphs but not on dense graphs because BnB-ADOPT allows agents to send
messages only to their parent agents in the pseudo-tree (along edges of the pseudo-tree) but NCBB

124

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

Sensor Network
Communication Cost = 1000

1.E+06

1.E+09

1.E+05

1.E+08
NCCC

NCCC

Sensor Network
Communication Cost = 0

1.E+04
1.E+03

ADOPT
BnB-ADOPT
NCBB

1.E+02

ADOPT
BnB-ADOPT
NCBB

1.E+07
1.E+06
1.E+05

1.E+01

1.E+04
4

5

6

4

7 8 9 10 11 12 13 14 15
Number of Targets

5

6

(a)

(b)

Sensor Network

Meeting Scheduling
Communication Cost = 0

1.E+05

1.E+06
ADOPT
BnB-ADOPT
NCBB

1.E+05
NCCC

Cycles

1.E+04
1.E+03
1.E+02

1.E+04
ADOPT
BnB-ADOPT
NCBB

1.E+03

1.E+01

1.E+02
4

5

6

5

7 8 9 10 11 12 13 14 15
Number of Targets

6

7

(c)

13

14

15

Meeting Scheduling
1.E+05

1.E+07

1.E+04
Cycles

1.E+08

1.E+06
ADOPT
BnB-ADOPT
NCBB

1.E+05

8
9 10 11 12
Number of Meetings

(d)

Meeting Scheduling
Communication Cost = 1000

NCCC

7 8 9 10 11 12 13 14 15
Number of Targets

1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+04

1.E+01
5

6

7

8
9 10 11 12
Number of Meetings

13

14

15

(e)

5

6

7

8
9 10 11 12
Number of Meetings

13

14

15

(f)

Figure 19: Experimental Results Comparing ADOPT, BnB-ADOPT and NCBB for Sensor Network
and Meeting Scheduling Problems

allows agents also to send messages to their pseudo-parent agents (along backedges of the pseudotree). Thus, agents of NCBB receive updates faster than agents of BnB-ADOPT. This eect is more
prevalent in dense graphs since there are more backedges in dense graphs. However, the dierence
between BnB-ADOPT and NCBB becomes negligible when communication is slow.
Figure 17 shows that BnB-ADOPT is at least half an order of magnitude faster than ADOPT
when the number of vertices is small. The speedup over ADOPT increases as the number of vertices
gets larger and the DCOP problems thus become more complex. Similarly, Figure 18 shows that the
speedup over ADOPT increases as the range of constant costs increases and the DCOP problems
thus become more complex. However, ADOPT can be faster than BnB-ADOPT for simple DCOP
problems. For example, ADOPT requires fewer cycles than BnB-ADOPT for DCOP problems with
constraint costs ranging from 0 to 1. Figure 19 shows the same trend for sensor network and meeting
scheduling problems. The reason for this behavior is as follows. ADOPT uses memory-bounded best125

fiYeoh, Felner & Koenig

Sensor Network
Communication Cost = 0

1.E+05

Sensor Network
Communication Cost = 1000

1.E+06

NCCC

NCCC

1.E+04
1.E+03
ADOPT

1.E+02

1.E+05
ADOPT

BnB-ADOPT

BnB-ADOPT

1.E+01

1.E+04
0.5

0.6

0.7
0.8
Weight

0.9

1

0.5

0.6

(a)

0.9

1

0.9

1

(b)

Sensor Network
1.E+03

Sensor Network
Unique Contexts Explored

1.E+02
No. of
Contexts

Cycles

0.7
0.8
Weight

1.E+02
ADOPT

ADOPT
BnB-ADOPT

BnB-ADOPT

1.E+01

1.E+01
0.5

0.6

0.7
0.8
Weight

0.9

1

0.5

0.6

(c)

0.7
0.8
Weight

(d)
Sensor Network
Repeated Contexts Explored

No. of
Contexts

1.E+03
1.E+02

ADOPT
BnB-ADOPT

1.E+01
1.E+00
0.5

0.6

0.7
0.8
Weight

0.9

1

(e)

Figure 20: Experimental Results on the Cause of Speedup for ADOPT and BnB-ADOPT
rst search and thus exploits the heuristic values well but needs to repeatedly reconstruct partial
solutions that it purged from memory, especially if the heuristic values are poorly informed. BnBADOPT uses depth-rst branch-and-bound search and thus does not exploit the heuristic values
quite as well but does not have to repeatedly reconstruct partial solutions. ADOPT can thus be
faster than BnB-ADOPT for DCOP problems with well informed heuristic values, such as simple
DCOP problems.
We conrm this intuition with an additional experiment on sensor network problems with four
targets and dierent informedness of heuristic values. We use the heuristic values cha,c
X a (d) for 0.5 
c  1, where ha,c
X a (d) are the heuristic values calculated by DP2, as used until now. Figures 20(a-c)
show the number of NCCCs for dierent weights c. When the heuristic values are well informed (large
weights), ADOPT can indeed be faster than BnB-ADOPT. Since ADOPT relies on the heuristic
values more than BnB-ADOPT, the speedup of ADOPT is much larger than that of BnB-ADOPT
as the heuristic values get more informed. Figures 20(d) and 20(e) show the number of unique

126

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

(= dierent) and repeated contexts per agent for dierent weights c. When the heuristic values are
well informed (large weights), agents of ADOPT explore fewer unique contexts than agents of BnBADOPT since they are more focused in their search. However, when the heuristic values are poorly
informed (small weights), they explore more unique contexts. Agents of ADOPT explore many more
repeated contexts than agents of BnB-ADOPT since they need to reconstruct partial solutions that
they purged from memory. Agents of BnB-ADOPT explore a few repeated contexts even though it
does not have to reconstruct partial solutions. The reason for this behavior is the distributed nature
of BnB-ADOPT. For example, assume that the context of an agent is {(a1 , 0), (a2 , 0)} and the next
context of a centralized variant of BnB-ADOPT would be {(a1 , 1), (a2 , 1)} (where the IDs are omitted
for simplicity). The agent updates its context to {(a1 , 1), (a2 , 0)} when it receives the message from
agent a1 that it takes on value 1. The agent then updates its context to {(a1 , 1), (a2 , 1)} when it
receives the message from agent a2 that it takes on value 1. Thus, the agent explores the intermediate
context {(a1 , 1), (a2 , 0)} that a centralized variant of BnB-ADOPT would not explore. It counts as a
repeated context if the agent explores this context intentionally in the future. Overall, BnB-ADOPT
tends to be faster than ADOPT if the heuristic values are poorly informed (small weights). Thus,
BnB-ADOPT has great potential as a DCOP search algorithm since heuristic values are often poorly
informed for complex DCOP problems, such as DCOP problems with large numbers of agents, large
domains, large numbers of constraints or large ranges of constraint costs.
6.4 Experimental Results: Suboptimal Variants of BnB-ADOPT
We now compare the three suboptimal variants of BnB-ADOPT to each other. The experimental
setup is identical to the one for the optimal DCOP search algorithms, except as follows: For graph
coloring problems, the number of vertices is 10, the range of constraint costs is 0 to 10,000 and the
constraint density is 2; for sensor network problems, the number of targets is 9; and for meeting
scheduling problems, the number of meetings is 10. We measure the runtimes in cycles. (The results
for NCCCs are similar.) However, we report normalized runtimes, that is, the runtimes divided by
the runtime for nding a cost-minimal solution with BnB-ADOPT. Thus, the normalized runtime
0.25 refers to one quarter of the number of cycles that it takes to nd a cost-minimal solution with
BnB-ADOPT. Similarly, we report normalized solution costs, that is, the solution costs divided by
the minimal solution costs. Thus, the normalized solution cost 2.5 refers to a solution cost that is
two and a half times larger than the minimal solution cost. We vary the relative error bound (which
is the worst acceptable normalized solution cost) from 1.0 to 4.0. The relative error bound is p for
BnB-ADOPTREM and w for BnB-ADOPTW HM . We pre-calculate the minimal solution costs to
set the correct value of b for BnB-ADOPTAEM . For example, if the minimal solution cost is 100 and
the relative error bound is 2.5, then p = 2.5 for BnB-ADOPTREM , w = 2.5 for BnB-ADOPTW HM
and b = (2.5  1)  100 = 150 for BnB-ADOPTAEM .
Figure 21(a-c) shows our experimental results for graph coloring problems. Figure 21(a) shows
that the normalized solution costs of all three suboptimal variants increase as the relative error
bound increases. However, the solution costs remain much smaller than the error bound. For
example, the normalized solution costs of all three suboptimal variants are less than 1.3 (rather
than 3) when the relative error bound is 3. The normalized solution costs of BnB-ADOPTAEM are
usually larger than the normalized solution costs of BnB-ADOPTREM for the same relative error
r
r
bound. The reason for this behavior is that BnB-ADOPTAEM terminates when U BX
=
r  lim
r
r
r
r
b + LBX r = (p  1)  X r + LBX r , where X r is the minimal solution cost. Thus, the solution cost of
r
r
r
BnB-ADOPTAEM can be at most U BX
r  LBX r  (p  1)  X r larger than the minimal solution
r
r
r
cost. On the other hand, BnB-ADOPTREM terminates when U BX
r  lim = p  LBX r . Thus, the
r
r
r
solution cost of BnB-ADOPTREM can be at most U BX r  LBX r  (p  1)  LBX r larger than the
minimal solution cost. The absolute error bound of BnB-ADOPTAEM is thus no smaller than the
r
r
absolute error bound of BnB-ADOPTREM since X
r  LBX r but is initially strictly greater than
r
r
the absolute error bound of BnB-ADOPTREM since X r > LBX
r during most of the search.

127

fiYeoh, Felner & Koenig

Graph Coloring
Solution Cost of BnB-ADOPT Variants

Graph Coloring
Computation Time of BnB-ADOPT Variants
1.00
Normalized Runtimes
(Cycles)

Normalized Costs

1.35
1.30
1.25
1.20
1.15

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

1.10
1.05
1.00
1.00

1.50

2.00
2.50
3.00
Relative Error Bound

3.50

0.80

0.40
0.20
0.00
1.00

4.00

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60

1.50

2.00
2.50
3.00
Relative Error Bound

(a)
Graph Coloring
Performance of BnB-ADOPT Variants

Sensor Network
Performance of BnB-ADOPT Variants
1.00

0.80

Normalized Runtimes
(Cycles)

Normalized Runtimes
(Cycles)

4.00

(b)

1.00
Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60
0.40
0.20
0.00
1.00

3.50

1.05

1.10
1.15
1.20
Normalized Costs

1.25

1.30

0.80

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60
0.40
0.20
0.00
1.00

1.02

1.04

(c)

1.06
1.08
1.10
Normalized Costs

1.12

1.14

(d)
Meeting Scheduling
Performance of BnB-ADOPT Variants
Normalized Runtimes
(Cycles)

1.00
0.80

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60
0.40
0.20
0.00
1.00

1.05

1.10
1.15
Normalized Costs

1.20

1.25

(e)

Figure 21: Experimental Results Comparing the Suboptimal Variants of BnB-ADOPT
Figure 21(b) shows that the normalized runtimes of all three suboptimal variants decrease as the
relative error bound increases. They decrease to almost 0 when the relative error bound is about 2.0.
Therefore, all three suboptimal variants terminate almost immediately after nding the rst solution.
The normalized runtimes of BnB-ADOPTAEM are usually smaller than the normalized runtimes of
BnB-ADOPTREM for the same relative error bound since BnB-ADOPTAEM can terminate with a
suboptimal solution cost that is within its absolute error bound but not yet within the absolute error
bound of BnB-ADOPTREM if the absolute error bound of BnB-ADOPTAEM is strictly greater than
the absolute error bound of BnB-ADOPTREM . In other words, BnB-ADOPTAEM can terminate
r
r
r
with a suboptimal solution cost (p  1)  LBX
r < U BX r  (p  1)  X r while BnB-ADOPTREM can
not.
Figure 21(c) shows the normalized runtimes needed to achieve a given normalized solution cost.
BnB-ADOPTW HM terminates faster than BnB-ADOPTAEM , which in turn terminates faster than
BnB-ADOPTREM . For example, the normalized runtime needed to achieve the normalized solu-

128

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

tion cost 1.05 is about 0.18 for BnB-ADOPTW HM , 0.30 for BnB-ADOPTAEM and 0.35 for BnBADOPTREM . Thus, BnB-ADOPTW HM is the suboptimal variant of BnB-ADOPT with the best
performance. Figures 21(d-e) show the same trend for sensor network and meeting scheduling problems.

7. Conclusions
In this article, we introduced Branch-and-Bound ADOPT (BnB-ADOPT), a memory-bounded
DCOP search algorithm. BnB-ADOPT uses the message passing and communication framework
of ADOPT but changes the search strategy of ADOPT from best-rst search to depth-rst branchand-bound search to make ADOPT faster by taking advantage of the fact that DCOP problems have
depth-bounded search trees. The other properties of BnB-ADOPT are similar to those of ADOPT.
BnB-ADOPT allows agents to operate concurrently (in order to decrease the runtime) and asynchronously (in order to increase robustness). BnB-ADOPT restricts communication to agents that
share constraints (in order to t the restrictions of applications such as sensor networks). Finally,
BnB-ADOPT orders agents into a pseudo-tree (in order to take advantage of independent DCOP
subproblems). Our experimental results showed that BnB-ADOPT nds cost-minimal solutions up
to one order of magnitude faster than ADOPT for a variety of large DCOP problems and is as fast
as NCBB for most of these DCOP problems. The reason for this behavior is the following: Agents
of NCBB operate sequentially and are thus often idle. ADOPT can construct fewer partial solutions
than BnB-ADOPT but has to reconstruct some partial solutions that it purged from memory. The
advantage of ADOPT with respect to the number of constructed partial solutions decreases and
its disadvantage with respect to the number of reconstructed partial solutions increases as heuristic
values become more poorly informed. Thus, BnB-ADOPT has great potential as a DCOP search
algorithm since heuristic values are often poorly informed for complex DCOP problems such as
DCOP problems with large numbers of agents, large domains, large numbers of constraints or large
ranges of constraint costs.
We also investigated three approximation mechanisms that trade o the solution cost of BnBADOPT for a smaller runtime, namely the Absolute Error Mechanism from ADOPT (resulting in
BnB-ADOPTAEM ), the new Relative Error Mechanism (resulting in BnB-ADOPTREM ) and the
new Weighted Heuristics Mechanism (resulting in BnB-ADOPTW HM ). The two new approximation mechanisms allow users to specify a relative error bound, which is often more meaningful than
an absolute error bound. The Weighted Heuristics Mechanism dominated both the Absolute Error Mechanism and the Relative Error Mechanism in our experiments and should apply to other
DCOP search algorithms as well since they all benet from using heuristic values to focus their
searches (Yeoh, Koenig, & Sun, 2008b).
In the future, we plan to improve BnB-ADOPT in the following ways: First, we would like to
reduce the number of sent messages and handle lost messages. Second, we would like to study
how dierent pseudo-tree arrangements (Atlas & Decker, 2007; Sultanik, Lass, & Regli, 2009) and
pre-processing techniques (Matsui et al., 2009) aect the eciency of BnB-ADOPT. Finally, we
would like to compare BnB-ADOPT and its approximation mechanisms to other DCOP algorithms,
including OptAPO, DPOP and their variants (Petcu & Faltings, 2005a, 2006).

Acknowledgments
This article is an extension of two earlier publications (Yeoh, Felner, & Koenig, 2008a; Yeoh et al.,
2008b) and contains additional expositions, examples and proofs. We thank Anton Chechetka for
providing us with his implementation of NCBB and the anonymous reviewers for their helpful
comments. This research was done while Ariel Felner spent his sabbatical at the University of
Southern California, visiting Sven Koenig. This research has been partly supported by a U.S. Army

129

fiYeoh, Felner & Koenig

Research Laboratory (ARL) and U.S. Army Research Oce (ARO) award to Sven Koenig under
grant W911NF-08-1-0468, by a Oce of Naval Research (ONR) award to Sven Koenig under grant
N00014-09-1-1031, by a National Science Foundation (NSF) award to Sven Koenig under grant
0413196 and by an Israeli Science Foundation (ISF) award to Ariel Felner under grants 728/06 and
305/09. The views and conclusions contained in this document are those of the authors and should
not be interpreted as representing the ocial policies, either expressed or implied, of the sponsoring
organizations, agencies, companies or the U.S. government.

References
Ali, S., Koenig, S., & Tambe, M. (2005). Preprocessing techniques for accelerating the DCOP
algorithm ADOPT. In Proceedings of the International Joint Conference on Autonomous
Agents and Multiagent Systems (AAMAS), pp. 10411048.
Atlas, J., & Decker, K. (2007). A complete distributed constraint optimization method for nontraditional pseudotree arrangements. In Proceedings of the International Joint Conference on
Autonomous Agents and Multiagent Systems (AAMAS), pp. 736743.
Bayardo, R., & Miranker, D. (1995). On the space-time trade-o in solving constraint satisfaction problems. In Proceedings of the International Joint Conference on Articial Intelligence
(IJCAI), pp. 558562.
Bistarelli, S., Montanari, U., Rossi, F., Schiex, T., Verfaillie, G., & Fargier, H. (1999). Semiring-based
CSPs and valued CSPs: Basic properties and comparison. Constraints, 4 (3), 199240.
Bowring, E., Pearce, J., Portway, C., Jain, M., & Tambe, M. (2008). On k-optimal distributed
constraint optimization algorithms: New bounds and algorithms. In Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS), pp.
607614.
Bowring, E., Tambe, M., & Yokoo, M. (2006). Multiply-constrained distributed constraint optimization. In Proceedings of the International Joint Conference on Autonomous Agents and
Multiagent Systems (AAMAS), pp. 14131420.
Burke, D., & Brown, K. (2006). Eciently handling complex local problems in distributed constraint
optimisation. In Proceedings of the European Conference on Articial Intelligence (ECAI), pp.
701702.
Chechetka, A., & Sycara, K. (2006). No-commitment branch and bound search for distributed
constraint optimization. In Proceedings of the International Conference on Autonomous Agents
and Multiagent Systems (AAMAS), pp. 14271429.
Choxi, H., & Modi, P. (2007). A distributed constraint optimization approach to wireless network
optimization. In Proceedings of the AAAI-07 Workshop on Conguration, pp. 18.
Davin, J., & Modi, P. (2006). Hierarchical variable ordering for multiagent agreement problems.
In Proceedings of the International Joint Conference on Autonomous Agents and Multiagent
Systems (AAMAS), pp. 14331435.
Dechter, R. (Ed.). (2003). Constraint Processing. Morgan Kaufmann.
Fitzpatrick, S., & Meertens, L. (2003). Distributed coordination through anarchic optimization.
In Lesser, V., Ortiz, C., & Tambe, M. (Eds.), Distributed Sensor Networks: A Multiagent
Perspective, pp. 257295. Kluwer.
Freuder, E., & Quinn, M. (1985). Taking advantage of stable sets of variables in constraint satisfaction problems. In Proceedings of the International Joint Conference on Articial Intelligence
(IJCAI), pp. 10761078.

130

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

Gershman, A., Meisels, A., & Zivan, R. (2009). Asynchronous Forward-Bounding for distributed
COPs. Journal of Articial Intelligence Research, 34, 6188.
Greenstadt, R. (2009). An overview of privacy improvements to k-optimal DCOP algorithms (extended abstract). In Proceedings of the International Joint Conference on Autonomous Agents
and Multiagent Systems (AAMAS), pp. 12791280.
Greenstadt, R., Grosz, B., & Smith, M. (2007). SSDPOP: Improving the privacy of DCOP with
secret sharing. In Proceedings of the International Joint Conference on Autonomous Agents
and Multiagent Systems (AAMAS), pp. 10981100.
Hamadi, Y., Bessiere, C., & Quinqueton, J. (1998). Distributed intelligent backtracking. In Proceedings of the European Conference on Articial Intelligence (ECAI), pp. 219223.
Hirayama, K., & Yokoo, M. (1997). Distributed partial constraint satisfaction problem. In Proceedings of the International Conference on Principles and Practice of Constraint Programming
(CP), pp. 222236.
Jain, M., Taylor, M., Tambe, M., & Yokoo, M. (2009). DCOPs meet the real world: Exploring
unknown reward matrices with applications to mobile sensor networks. In Proceedings of the
International Joint Conference on Articial Intelligence (IJCAI), pp. 181186.
Junges, R., & Bazzan, A. (2008). Evaluating the performance of DCOP algorithms in a real world,
dynamic problem. In Proceedings of the International Joint Conference on Autonomous Agents
and Multiagent Systems (AAMAS), pp. 599606.
Korf, R. (1993). Linear-space best-rst search. Articial Intelligence, 62 (1), 4178.
Kumar, A., Faltings, B., & Petcu, A. (2009). Distributed constraint optimization with structured
resource constraints. In Proceedings of the International Joint Conference on Autonomous
Agents and Multiagent Systems (AAMAS), pp. 923930.
Lesser, V., Ortiz, C., & Tambe, M. (Eds.). (2003). Distributed Sensor Networks: A Multiagent
Perspective. Kluwer.
Maheswaran, R., Pearce, J., & Tambe, M. (2004a). Distributed algorithms for DCOP: A graphical game-based approach. In Proceedings of the International Conference on Parallel and
Distributed Computing Systems (PDCS), pp. 432439.
Maheswaran, R., Tambe, M., Bowring, E., Pearce, J., & Varakantham, P. (2004b). Taking DCOP to
the real world: Ecient complete solutions for distributed event scheduling. In Proceedings of
the International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS),
pp. 310317.
Mailler, R., & Lesser, V. (2004). Solving distributed constraint optimization problems using cooperative mediation. In Proceedings of the International Joint Conference on Autonomous Agents
and Multiagent Systems (AAMAS), pp. 438445.
Marinescu, R., & Dechter, R. (2007). Best-rst AND/OR search for graphical models. In Proceedings
of the AAAI Conference on Articial Intelligence (AAAI), pp. 11711176.
Marinescu, R., & Dechter, R. (2009). AND/OR branch-and-bound search for combinatorial optimization in graphical models. Articial Intelligence, 173 (16-17), 14571491.
Matsui, T., Silaghi, M., Hirayama, K., Yokoo, M., & Matsuo, H. (2009). Directed soft arc consistency
in pseudo trees. In Proceedings of the International Joint Conference on Autonomous Agents
and Multiagent Systems (AAMAS), pp. 10651072.
Meisels, A., Kaplansky, E., Razgon, I., & Zivan, R. (2002). Comparing performance of distributed
constraints processing algorithms. In Proceedings of the Distributed Constraint Reasoning
Workshop, pp. 8693.

131

fiYeoh, Felner & Koenig

Modi, P., & Ali, S. (2004). Distributed constraint reasoning under unreliable communication. In
Zhang, W., & Sorge, V. (Eds.), Frontiers in Articial Intelligence and Applications, Vol. 112,
pp. 141150. IOS Press.
Modi, P., Shen, W.-M., Tambe, M., & Yokoo, M. (2005). ADOPT: Asynchronous distributed constraint optimization with quality guarantees. Articial Intelligence, 161 (1-2), 149180.
Ottens, B., & Faltings, B. (2008). Coordinating agent plans through distributed constraint optimization. In Proceedings of the ICAPS-08 Workshop on Multiagent Planning.
Pearce, J., & Tambe, M. (2007). Quality guarantees on k-optimal solutions for distributed constraint
optimization problems. In Proceedings of the International Joint Conference on Articial
Intelligence (IJCAI), pp. 14461451.
Pecora, F., Modi, P., & Scerri, P. (2006). Reasoning about and dynamically posting n-ary constraints
in ADOPT. In Proceedings of the Distributed Constraint Reasoning Workshop, pp. 5771.
Petcu, A., & Faltings, B. (2005a). Approximations in distributed optimization. In Proceedings of
the International Conference on Principles and Practice of Constraint Programming (CP), pp.
802806.
Petcu, A., & Faltings, B. (2005b). A scalable method for multiagent constraint optimization. In
Proceedings of the International Joint Conference on Articial Intelligence (IJCAI), pp. 1413
1420.
Petcu, A., & Faltings, B. (2006). ODPOP: An algorithm for open/distributed constraint optimization. In Proceedings of the National Conference on Articial Intelligence (AAAI), pp. 703708.
Pohl, I. (1970). First results on the eect of error in heuristic search. Machine Intelligence, 5,
219236.
Pohl, I. (1973). The avoidance of (relative) catastrophe, heuristic competence, genuine dynamic
weighting and computational issues in heuristic problem solving. In Proceedings of the International Joint Conference on Articial Intelligence (IJCAI), pp. 1217.
Schiex, T., Fargier, H., & Verfaillie, G. (1995). Valued constraint satisfaction problems: Hard and
easy problems. In Proceedings of the International Joint Conference on Articial Intelligence
(IJCAI), pp. 631637.
Schurr, N., Okamoto, S., Maheswaran, R., Scerri, P., & Tambe, M. (2005). Evolution of a teamwork
model. In Sun, R. (Ed.), Cognition and Multi-Agent Interaction: From Cognitive Modeling to
Social Simulation, pp. 307327. Cambridge University Press.
Silaghi, M., Landwehr, J., & Larrosa, J. (2004). Asynchronous branch & bound and A* for disWCSPs
with heuristic function based on consistency-maintenance. In Zhang, W., & Sorge, V. (Eds.),
Frontiers in Articial Intelligence and Applications, Vol. 112, pp. 4962. IOS Press.
Silaghi, M., Lass, R., Sultanik, E., Regli, W., Matsui, T., & Yokoo, M. (2008). The operation point
units of distributed constraint solvers. In Proceedings of the Distributed Constraint Reasoning
Workshop, pp. 116.
Silaghi, M., & Yokoo, M. (2009). ADOPT-ing: Unifying asynchronous distributed optimization with
asynchronous backtracking. Autonomous Agents and Multi-Agent Systems, 19 (2), 89123.
Stranders, R., Farinelli, A., Rogers, A., & Jennings, N. (2009). Decentralised coordination of mobile
sensors using the Max-Sum algorithm. In Proceedings of the International Joint Conference
on Articial Intelligence (IJCAI), pp. 299304.
Sultanik, E., Lass, R., & Regli, W. (2009). Dynamic conguration of agent organizations. In
Proceedings of the International Joint Conference on Articial Intelligence (IJCAI), pp. 305
311.

132

fiBnB-ADOPT: An Asynchronous Branch-and-Bound DCOP Algorithm

Yeoh, W., Felner, A., & Koenig, S. (2008a). BnB-ADOPT: An asynchronous branch-and-bound
DCOP algorithm. In Proceedings of the International Joint Conference on Autonomous Agents
and Multiagent Systems (AAMAS), pp. 591598.
Yeoh, W., Koenig, S., & Sun, X. (2008b). Trading o solution cost for smaller runtime in DCOP
search algorithms (short paper). In Proceedings of the International Joint Conference on
Autonomous Agents and Multiagent Systems (AAMAS), pp. 14451448.
Yeoh, W., Varakantham, P., & Koenig, S. (2009). Caching schemes for DCOP search algorithms.
In Proceedings of the International Joint Conference on Autonomous Agents and Multiagent
Systems (AAMAS), pp. 609616.
Yokoo, M., & Hirayama, K. (1996). Distributed breakout algorithm for solving distributed constraint
satisfaction problems. In Proceedings of the International Conference on Multiagent Systems
(ICMAS), pp. 401408.
Zhang, W., & Korf, R. (1995). Performance of linear-space search algorithms. Articial Intelligence,
79 (2), 241292.
Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2003). An analysis and application of distributed
constraint satisfaction and optimization algorithms in sensor networks. In Proceedings of the
International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS),
pp. 185192.
Zivan, R. (2008). Anytime local search for distributed constraint optimization. In Proceedings of
the AAAI Conference on Articial Intelligence (AAAI), pp. 393398.
Zivan, R., Glinton, R., & Sycara, K. (2009). Distributed constraint optimization for large teams
of mobile sensing agents. In Proceedings of the International Conference on Intelligent Agent
Technology (IAT), pp. 347354.

133

fi