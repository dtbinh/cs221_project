Journal of Articial Intelligence Research 38 (2010) 339-369

Submitted 11/09; published 07/10

Mixed Strategies in Combinatorial Agency
Moshe Babaio

moshe@microsoft.com

Microsoft Research - Silicon Valley
Mountain View, CA 94043 USA

Michal Feldman

mfeldman@huji.ac.il

School of Business Administration
and Center for the Study of Rationality,
Hebrew University of Jerusalem,
Jerusalem, Israel

Noam Nisan

noam@cs.huji.ac.il

School of Computer Science,
The Hebrew University of Jerusalem,
Jerusalem, Israel

Abstract
In many multiagent domains a set of agents exert eort towards a joint outcome, yet the
individual eort levels cannot be easily observed. A typical example for such a scenario is
routing in communication networks, where the sender can only observe whether the packet
reached its destination, but often has no information about the actions of the intermediate
routers, which inuences the nal outcome. We study a setting where a principal needs to
motivate a team of agents whose combination of hidden eorts stochastically determines an
outcome. In a companion paper we devise and study a basic combinatorial agency model
for this setting, where the principal is restricted to inducing a pure Nash equilibrium. Here
we study various implications of this restriction. First, we show that, in contrast to the
case of observable eorts, inducing a mixed-strategies equilibrium may be benecial for the
principal. Second, we present a sucient condition for technologies for which no gain can be
generated. Third, we bound the principals gain for various families of technologies. Finally,
we study the robustness of mixed equilibria to coalitional deviations and the computational
hardness of the optimal mixed equilibria.

1. Introduction
In this paper we study Combinatorial Agency with Mixed Strategies, this section reviews
some background on Combinatorial Agency with pure strategies and then present our results
for mixed strategies.
1.1 Background: Combinatorial Agency
The well studied principal-agent problem deals with how a principal can motivate a
rational agent to exert costly eort towards the welfare of the principal. The diculty
in this model is that the agents action (i.e. whether he exerts eort or not) is invisible
to the principal and only the nal outcome, which is probabilistic and also inuenced
c
2010
AI Access Foundation. All rights reserved.

fiBabaioff, Feldman & Nisan

by other factors, is visible1 . This problem is well studied in many contexts in classical
economic theory and we refer the readers to introductory texts on economic theory such
as the work of Mass-Colell, Whinston, and Green (1995), Chapter 14. In these settings, a
properly designed contract, in which the payments are contingent upon the nal outcome,
can inuence a rational agent to exert the required eort.
In many multiagent settings, however, a set of agents work together towards a joint
outcome. Handling combinations of agents rather than a single agent is the focus of the
work by Babaio, Feldman, and Nisan (2006a). While much work was previously done
on motivating teams of agents (e.g., Holmstrom, 1982; Strausz, 1996), our emphasis is on
dealing with the complex combinatorial structure of dependencies between agents actions.
In the general case, each combination of eorts exerted by the n dierent agents may result
in a dierent expected gain for the principal. The general question asks, given an exact
specication of the expected utility of the principal for each combination of agents actions,
which conditional payments should the principal oer to which agents as to maximize his
net utility?
We view this problem of hidden actions in computational settings as a complementary
problem to the problem of hidden information that is the heart of the eld of Algorithmic
Mechanism Design (Nisan, Roughgarden, Tardos, & Vazirani, 2007; Nisan & Ronen, 2001).
In recent years, computer science and articial intelligence have showed a lot of interest
in algorithmic mechanism design. In particular, they imported concepts from game theory
and mechanism design for solving problems that arise in articial intelligence application
domains, such as computer networks with routers as autonomous software agents.
Communication networks serve as a typical application to our setting. Since many computer networks (such as the Internet and mobile ad-hoc networks) are used and administered
by multiple entities with dierent economic interests, their performance is determined by
the actions among the various interacting self-interested parties. Thus, taking into account
the economic and strategic considerations together with the technical ones may be crucial
in such settings. Indeed, recent years have seen a urry of research employing game theoretic models and analysis for better understanding the eect of strategic considerations on
network design and performance.
An example that was discussed in the work of Feldman, Chuang, Stoica, and Shenker
(2007) is Quality of Service routing in a network: every intermediate link or router may
exert a dierent amount of eort (priority, bandwidth, etc.) when attempting to forward
a packet of information. While the nal outcome of whether a packet reached its destination
is clearly visible, it is rarely feasible to monitor the exact amount of eort exerted by each
intermediate link  how can we ensure that they really do exert the appropriate amount
of eort? For example, in Internet routing, IP routers may delay or drop packets, and in
mobile ad hoc networks, devices may strategically drop packets to conserve their constrained
energy resources. Aside from forwarding decisions, which are done in a sequential manner,
some eort decisions take place prior to the actual packet transmission, and are done in
a simultaneous manner. There are many examples for such decisions, among them are the
quality of the hardware, appropriate tuning of the routers, and more. Our focus is on these
1. Invisible here is meant in a wide sense that includes not precisely measurable, costly to determine,
or non-contractible (meaning that it can not be upheld in a court of law).

340

fiMixed Strategies in Combinatorial Agency

a-priori eort decisions, since they are crucial to the quality of the transmission, and it is
harder to detect agents who shirk with respect to these matters.
In the general model presented in the work of Babaio et al. (2006a), each of n agents
has a set of possible actions, the combination of actions by the players results in some
outcome, where this happens probabilistically. The main part of the specication of a
problem in this model is a function (the technology) that species this distribution for
each n-tuple of agents actions. Additionally, the problem species the principals utility
for each possible outcome, and for each agent, the agents cost for each possible action.
The principal motivates the agents by oering to each of them a contract that species a
payment for each possible outcome of the whole project. Key here is that the actions of
the players are non-observable (hidden-actions) and thus the contract cannot make the
payments directly contingent on the actions of the players, but rather only on the outcome
of the whole project.
Given a set of contracts, each agent optimizes his own utility; i.e., chooses the action that
maximizes his expected payment minus the cost of the action. Since the outcome depends
on the actions of all players together, the agents are put in a game here and are assumed
to reach a Nash Equilibrium (NE). The principals problem is that of designing the optimal
contract: i.e. the vector of contracts to the dierent agents that induce an equilibrium that
will optimize his expected utility from the outcome minus his expected total payment. The
main diculty is that of determining the required Nash equilibrium point.
Our interest in this paper, as in the work of Babaio et al. (2006a), is focused on the
binary case: each agent has only two possible actions exert eort and shirk and there
are only two possible outcomes success and failure. Our motivating examples come
from the following more restricted and concrete structured subclass of problem instances:
Every agent i performs a subtask which succeeds with a low probability i if the agent does
not exert eort and with a higher probability i > i , if the agent does exert eort. The
whole project succeeds as a deterministic Boolean function of the success of the subtasks.
For example, the Boolean AND and OR functions represent the respective cases where
the agents are complementary (i.e., where the project succeeds if and only if all the agents
succeed) or substitutive (i.e., where the project succeeds if and only if at least one of the
agents succeeds). Yet, a more restricted subclass of problem instances are those technologies
that can be represented by read-once networks with two specied source and sink nodes,
in which every edge is labeled by a single agent, and the project succeeds (e.g., a packet
of information reaches the destination) if there is a successful path between the source and
the sink nodes.
1.2 This Paper: Mixed Equilibria
The focus in the work by Babaio et al. (2006a) was on the notion of Nash-equilibrium in
pure strategies: we did not allow the principal to attempt inducing an equilibrium where
agents have mixed strategies over their actions. In the observable-actions case (where the
principal can condition the payments on the agents individual actions) the restriction to
pure strategies is without loss of generality: mixed actions can never help since they simply
provide a convex combination of what would be obtained by pure actions.
341

fiBabaioff, Feldman & Nisan

Yet, surprisingly, we show this is not the case for the hidden-actions case which we are
studying: in some cases, a Mixed-Nash equilibrium can provide better expected utility to
the principal than what he can obtain by equilibrium in pure strategies. In particular, this
already happens in the case of two substitutive agents with a certain (quite restricted) range
of parameters (see Section 3).
While inducing mixed strategy equilibria might be benecial for the principal, mixed
Nash equilibrium is a much weaker solution concept than pure Nash equilibrium, as was
already observed by Harsanyi (1973). As opposed to Nash equilibria in pure strategies, the
guarantees that one obtains are only in expectation. In addition, any player can deviate from
his equilibrium strategy without lowering his expected payo even if he expects all other
players to stick to their equilibrium strategies. Moreover, best-response dynamics converge
to pure proles, and there is no natural dynamics leading to a mixed Nash equilibrium.
As a result, if the principal cannot gain much by inducing a Nash equilibrium in mixed
strategies, he might not be willing to tolerate the instability of this notion. Our main goal
is to quantify the principals gain from inducing mixed equilibrium, rather than pure. To do
that, we analyze the worst ratio (over all principals values) between the principals optimal
utility with mixed equilibrium, and his optimal utility with pure equilibrium. We term this
ratio the price of purity (POP) of the instance under study.
The price of purity is at least 1 by denition, and the larger it is, the more the principal
can gain by inducing a mixed equilibrium compared to a pure one. We prove that for
super-modular technologies (e.g. technologies with increasing returns to scale) which
contains in particular the AN D Boolean function, the price of purity is trivial (i.e., P OP =
1). Moreover, we show that for any other Boolean function, there is an assignment of
the parameters (agents individual success probabilities) for which the obtained structured
technology has non trivial POP (i.e., P OP > 1). (Section 4).
While the price of purity may be strictly greater than 1, we obtain quite a large number
of results bounding this ratio (Section 5). These bounds range from a linear bound for
very general families of technologies (e.g., P OP  n for any anonymous or sub-modular
technology) to constant bounds for some restricted cases (e.g., P OP  1.154... for a family
of anonymous OR technologies, and P OP  2 for any technology with 2 agents).
Additionally, we study some other properties of mixed equilibrium. We show that mixed
Nash equilibria are more delicate than pure ones. In particular, we show that unlike the
pure case, in which the optimal contract is also a strong equilibrium (Aumann, 1959)
(i.e., resilient to deviations by coalitions), an optimal mixed contract (in which at least two
agents truly mix) never satises the requirements of a strong equilibrium (Section 6).
Finally, we study the computational hardness of the optimal mixed Nash equilibrium,
and show that the hardness results from the pure case hold for the mixed case as well
(Section 7).

2. Model and Preliminaries
We focus on the simple binary action, binary outcome scenario where each agent has two
possible actions (exert eort or shirk) and there are two possible outcomes (failure,
success). We begin by presenting the model with pure actions (which is a generalization
of the model of Winter, 2004), and then move to the mixed case. A principal employs a set
342

fiMixed Strategies in Combinatorial Agency

of agents N of size n. Each agent i  N has a set of two possible actions Ai = {0, 1} (binary
action), the low eort action (0) has a cost of 0 (ci (0) = 0), while the high eort action (1) as
a cost of ci > 0 (ci (1) = ci ). The played prole of actions determine, in a probabilistic way,
a contractible outcome, o  {0, 1}, where the outcomes 0 and 1 denote project failure and
success, respectively (binary-outcome). The outcome is determined according to a success
function t : A1  . . .  An  [0, 1], where t(a1 , . . . , an ) denotes the probability of project
success where players play with the action prole a = (a1 , . . . , an )  A1  . . .  An = A.
We use the notation (t, c) to denote a technology (a success function and a vector of costs,
one for each agent). We assume that everything but the eort of the agents is common
knowledge.
The principals value of a successful project is given by a scalar v > 0, where he gains
no value from a project failure. In this hidden-actions model the actions of the players are
invisible, but the nal outcome is visible to him and to others, and he may design enforceable
contracts based on this outcome. We assume that the principal can pay the agents but not
ne them (known as the limited liability constraint). The contract to agent i is thus given
by a scalar value pi  0 that denotes the payment that i gets in case of project success. If
the project fails, the agent gets no money (this is in contrast to the observable-actions
model in which payment to an agent can be contingent on his action). The contracts to all
the agents public, all agents know them before making their eort decisions.
Given this setting, the agents have been put in a game, where the utility of agent i
under the prole of actions a = (a1 , . . . , an )  A is given by ui (a) = pi  t(a)  ci (ai ). As
usual, we denote by ai  Ai the (n  1)-dimensional vector of the actions of all agents
excluding agent i. i.e., ai = (a1 , . . . , ai1 , ai+1 , . . . , an ). The agents will be assumed to
reach Nash equilibrium, if such an equilibrium exists. The principals problem (which is our
problem in this paper) is how
 to design the contracts pi as to maximize his own expected
utility u(a, v) = t(a)  (v  iN pi ), where the actions a1 , . . . , an are at Nash-equilibrium.
In the case of multiple Nash equilibria, in our model we let the principal choose the desired
one, and suggest it to the agents, thus focusing on the best Nash equilibrium.2
As we wish to concentrate on motivating agents, rather than on the coordination between
agents, we assume that more eort by an agent always leads to a better probability of
success. Formally, i  N, ai  Ai we have that t(1, ai ) > t(0, ai ). We also assume
that t(a) > 0 for any a  A.
We next consider the extended game in which an agent can mix between exerting eort
and shirking (randomize over the two possible pure actions). Let qi denote the probability
that agent i exerts eort, and let qi denote the (n  1)-dimensional vector of investment
probabilities of all agents except for agent i. We can extend the denition of the success
function t to the range of mixed strategies, by taking the expectation.
t(q1 , . . . , qn ) =



n

( qiai  (1  qi )(1ai ) )t(a1 , . . . , an )

a{0,1}n i=1

2. While in the pure case (Babaio, Feldman, & Nisan, 2006b), the best Nash equilibrium is also a strong
equilibrium, this is not the case in the more delicate mixed case (see Section 6). Other variants of NE
exist. One variant, which is similar in spirit to strong implementation in mechanism design, would be
to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists
(as in the work of Winter, 2004).

343

fiBabaioff, Feldman & Nisan

Note that for any agent i and any (qi , qi ) it holds that t(qi , qi ) = qi  t(1, qi ) + (1  qi ) 
t(0, qi ). A mixed equilibrium prole in which at least one agent mixes with probability
pi  [0, 1] is called a non-degenerate mixed equilibrium.
In pure strategies, the marginal contribution of agent i, given ai  Ai , is dened to
be: i (ai ) = t(1, ai )  t(0, ai ). For the mixed case we dene the marginal contribution
of agent i, given qi to be: i (qi ) = t(1, qi )  t(0, qi ). Since t is monotone, i is a
positive function.
We next characterize what payment can result in an agent mixing between exerting
eort and shirking.
Claim 2.1 Agent is best response is to mix between exerting eort and shirking with probability qi  (0, 1) only if he is indierent between ai = 1 and ai = 0. Thus, given a prole
of strategies qi , agent i mixes only if:
pi =

ci
ci
=
i (qi )
t(1, qi )  t(0, qi )

which is the payment that makes him indierent between exerting eort and(shirking. The
)

q
.
expected utility of agent i, who exerts eort with probability qi is: ui (q) = ci  it(q)
i
(qi )
Proof: Recall that ui (q) = t(q)  pi  qi  ci , thus ui (q) = qi  ui (1, qi ) + (1  qi )  ui (0, qi ).
Since i maximizes his utility, if qi  (0, 1), it must be the case that ui (1, qi ) = ui (0, qi ).
ci
.
2
Solving for pi we get that pi = i (q
i )
A prole of mixed strategies q = (q1 , . . . , qn ) is a Mixed Nash equilibrium if for any agent
i, qi is agent is best response, given qi .
The principals expected utility under the mixed Nash prole q is given
=
 by u(q, v)
ci
(v  P )  t(q), where P is the total payment in case of success, given by P = i|qi >0 i (q
.
i )

An optimal mixed contract for the principal is an equilibrium mixed strategy prole q (v)
that maximizes the principals utility at the value v. In Babaio et al. (2006a) we show a
similar characterization of optimal pure contract a  A. An agent that exerts eort is paid
ci
i (ai ) , and the utilities are the same as the above, when given the pure prole. In the
pure Nash case, given a value v, an optimal pure contract for the principal is a set of agents
S  (v) that exert eort in equilibrium, and this set maximizes the principals utility at the
value v.
A simple but crucial observation, generalizing a similar one in the work of Babaio
et al. (2006a) for the pure Nash case, shows that the optimal mixed contract exhibits some
monotonicity properties in the value.
Lemma 2.2 (Monotonicity lemma): For any technology (t, c) the expected utility of
the principal at the optimal mixed contract, the success probability of the optimal mixed
contract, and the expected payment of the optimal mixed contract, are all monotonically
non-decreasing with the value.
The proof is postponed to Appendix A, and it also shows that the same monotonicity
also holds in the observable-actions case. Additionally, the lemma holds in more general
settings, where each agent has an arbitrary action set (not restricted to the binary-actions
model considered here).
344

fiMixed Strategies in Combinatorial Agency

We wish to quantify the gain by inducing mixed Nash equilibrium, over inducing pure
Nash. We dene the price of purity as the worse ratio (over v) between the maximum
utilities that are obtained in mixed and pure strategies.
Denition 2.3 The price of purity P OP (t, c) of a technology (t, c) is dened as the worse
ratio, over v, between the principals optimal utility in the mixed case and his optimal utility
in the pure case. Formally,
)
(

t(q  (v)) v  i|q (v)>0 i (qci (v))
i
i
(
)
P OP (t, c) = Supv>0

ci

t(S (v)) v  iS  (v) i (ai )
where S  (v) denotes an optimal pure contract and q  (v) denotes an optimal mixed contract,
for the value v.
The price of purity is at least 1, and may be greater than 1, as we later show. Additionally, it is obtained at some value that is a transition point of the pure case (a point in
which the principal is indierent between two optimal pure contracts).
Lemma 2.4 For any technology (t, c), the price of purity is obtained at a nite v that is a
transition point between two optimal pure contracts.
2.1 Structured Technology Functions
In order to be more concrete, we next present technology functions whose structure can be
described easily as being derived from independent agent tasks  we call these structured
technology functions. This subclass gives us some natural examples of technology functions,
and also provides a succinct and natural way to represent technology success functions.
In a structured technology function, each individual succeeds or fails in his own task
independently. The projects success or failure deterministically depends, maybe in a complex way, on the set of successful sub-tasks. Thus we will assume a monotone Boolean
function f : {0, 1}n  {0, 1} which indicates whether the project succeeds as a function of
the success of the n agents tasks.
A structured technology function t is dened by t(a1 , . . . , an ) being the probability
that f (x1 , . . . , xn ) = 1 where the bits x1 , . . . , xn are chosen according to the following
distribution: if ai = 0 then xi = 1 with probability i  [0, 1) (and xi = 0 with probability
1  i ); otherwise, i.e. if ai = 1, then xi = 1 with probability i > i (and xi = 0 with
probability 1  i ). Thus, a structured technology is dened by n, f and the parameters
{i , i }iN .
Let us consider two simple structured technology functions, AND and OR. First
consider
the AND technology: f (x1 , . . . , xn ) is the logical conjunction of xi (f (x) =

x
).
Thus the project succeeds only if all agents succeed in their tasks. This is shown
iN i
graphically as a read-once network in Figure 1(a). For this technology, the probability
of success is the product of the individual
success probabilities. Agent i succeeds with

probability iai  i1ai , thus t(a) = iN iai  i1ai .
Next,consider the OR technology: f (x1 , . . . , xn ) is the logical disjunction of xi
(f (x) = iN xi ). Thus the project succeeds if at least one of the agents succeed in their
345

fiBabaioff, Feldman & Nisan

S

x1 x2

xn

x1
x2
t

S

t

xn
(b) OR technology

(a) AND technology

Figure 1: AND and OR technologies. In AND (a), the project is successful if a packet is routed
along a linear path (where each agent controls an edge), and in OR (b), the project is
successful if a packet is routed at least along one edge.

tasks. This is shown graphically as a read-once network in Figure 1(b). For this technology,
the probability of success is 1 minus the probability
that all of them fail. Agent i fails with
probability (1  i )ai  (1  i )1ai , thus t(a) = 1  iN (1  i )ai  (1  i )1ai .
These are just two simple examples. One can consider other more interesting examples
as the Majority function (the project succeed if the majority of the agents are successful),
or the OR-Of-ANDs technology, which is a disjunction over conjunctions (several teams,
the project succeed if all the agents in any one of the teams are successful). For additional
examples see the work of Babaio et al. (2006a).
A success function t is called anonymous
if it is symmetric with respect to the players.

I.e. t(a1 , . . . , an ) depends only on i ai . For example, in an anonymous OR technology
there are parameters 1 >  >  > 0 such that each agent i succeed with probability 
with no eort, and with probability  >  with eort. If m agents exert eort, the success
probability is 1  (1  )m  (1  )nm .
A technology has identical costs if there exists a c such that for any agent i, ci = c.
As in the case of identical costs the POP is independent of c, we use P OP (t) to denote
the POP for technology t with identical costs. We abuse notation and denote a technology
with identical costs by its success function t. Throughout the paper, unless explicitly stated
otherwise, we assume identical costs. A technology t with identical costs is anonymous if t
is anonymous.

3. Example: Mixed Nash Outperforms Pure Nash!
If the actions are observable (henceforth, the observable-actions case), then an agent that
exerts eort is paid exactly his cost, and the principals utility equals the social welfare.
In this case, the social welfare in mixed strategies is a convex combination of the social
welfare in pure strategies; thus, it is clear that the optimal utility is always obtained in pure
strategies. However, surprisingly enough, in the hidden-actions case, the principal might
gain higher utility when mixed strategies are allowed. This is demonstrated in the following
example:

346

fiMixed Strategies in Combinatorial Agency

Figure 2: Optimal mixed contracts in OR technologies with 2 agents. The areas indicated by 0,
1, and 2 correspond to areas where it is optimal that 0, 1, or 2 agents, respectively,
exert eort with probability 1. The white area corresponds to both agents exert eort
with the same non-trivial probability, q. For any xed , q increases in v.

Example 3.1 Consider an anonymous OR technology with two agents, where c = 1,  =
1 = 2 = 1  1 = 1  2 = 0.09 and v = 348. It holds that t(0, 0) = 1  (1  )2 =
0.172, t(0, 1) = t(1, 0) = 1  (1  )(1  ) = 0.9181, and t(1, 1) = 1  (1  )2 = 0.992.
Consider the mixed strategy q1 = q2 = 0.92. It holds that: t(0, 0.92) = 0.08  t(0, 0) +
0.92  t(0, 1) = 0.858, t(1, 0.92) = 0.92  t(1, 1) + 0.08  t(1, 0) = 0.986, and t(0.92, 0.92) =
0.082  t(0, 0) + 0.08  0.92  t(0, 1)  2 + 0.922  t(1, 1) = 0.976. The payment to each player
1
= 7.837, thus the principals
under a successful project is pi (0.92, 0.92) = t(1,0.92)t(0,0.92)
utility under the mixed strategies q1 = q2 = 0.92 and v = 348 is u((0.92, 0.92), 348) =
t(0.92, 0.92)  (348  2  7.837) = 324.279.
While the principals utility under the mixed prole q1 = q2 = 0.92 is 324.279, the
optimal contract with pure strategies is obtained when both agents exert eort and achieves
a utility of 318.3. This implies that by moving from pure strategies to mix strategies, one
gains at least 324.27/318.3 > 1.0187 factor improvement (which is approximately 1.8%).
A worse ratio exists for the more general case (in which it does not necessarily hold that
 = 1  ) of  = 0.0001,  = 0.9 and v = 233. For this case we get that the optimal pure
contract is with one agent, gives utility of 208.7, while the mixed contract q1 = q2 = 0.92
gives utility of 213.569, and the ratio is at least 1.0233 (approximately 2.3%).
To complete the example, Diagram 2 presents the optimal contract for OR of 2 agents,
as a function of  (when  = 1  ) and v. It shows that for some parameters of  and v,
the optimal contract is obtained when both agents exert eort with equal probabilities.
The following lemma (proved in Appendix A.1) shows that optimal mixed contracts in
any anonymous OR technology (with n agents) have this specic structure. That is, all
agents that do not shirk, mix with exactly the same probability.

347

fiBabaioff, Feldman & Nisan

Lemma 3.2 For any anonymous OR technology (any  > , c, n) and value v, either the
optimal mixed contract is a pure contract, or, in the optimal mixed contract k  {2, . . . n}
agents exert eort with equal probabilities q1 = . . . = qk  (0, 1), and the rest of the agents
exert no eort.

4. When is Pure Nash Good Enough?
Next, we identify a class of technologies for which the price of purity is 1; that is, the
principal cannot improve his utility by moving from pure Nash equilibrium to mixed Nash
equilibrium. These are technologies for which the marginal contribution of any agent is nondecreasing in the eort of the other agents. Formally, for two pure action proles a, b  A
we denote b  a if for all j, bj j aj (eort bj is at least as high as the eort aj ).
Denition 4.1 A technology success function t exhibits (weakly) increasing returns to
scale (IRS)3 if for every i, and every pure proles b  a
t(bi , bi )  t(ai , bi )  t(bi , ai )  t(ai , ai )
Any AND technology exhibits IRS (Winter, 2004; Babaio et al., 2006a). For IRS
technologies we show that P OP = 1.
Theorem 4.2 Assume that t is super-modular. For any cost vector c, P OP (t, c) = 1.
Moreover, a non-degenerate mixed contract is never optimal.
Proof: For a mixed prole q = (q1 , q2 , . . . , qn ), let S(q) be the support of q, that is, i  S(q)
if and only if qi > 0, and for any agent i  S(q) let Si = S(q) \ {i} be the support of q
excluding i. Similarly, for a pure prole a = (a1 , a2 , . . . , an ) let S(a) be the support a. Under
ci
. Similarly, under
the mixed prole q, agent i  S(q) is being paid pi (qi ) = t(1,qi )t(0,q
i )
ci
the pure prole a, agent i  S(a) is being paid pi (S(a) \ {i}) = pi (ai ) = t(S(a))t(S(a)\{i})
,
where t(T ) is the success probability when aj = 1 for j  T , and aj = 0 for j 
/ T . We also
denote i (T ) = t(T )  t(T \ {i}).
We show that if q is a non-degenerate mixed prole (i.e., at least one agent in q exerts
eort with probability qi  (0, 1)), the prole in which each agent in S(q) exerts eort with
probability 1 yields a higher utility to the principal.
By Lemma 5.3 (see Section 5), it holds that pi (qi )  minT Si pi (T ), where pi (T ) =
ci
i (T ) . But if t exhibits IRS, then i (T ) is an increasing function by denition (see Section 4), therefore minT Si pi (T ) = pi (Si ). Therefore it holds that for any i  S(q),
pi (qi )  pi (Si ), thus:


pi (qi ) 
pi (Si )
iS(q)

iS(q)

3. Note that t exhibits IRS if and only if it is super-modular.

348

fiMixed Strategies in Combinatorial Agency

In addition, due to the monotonicity of t, it holds that t(q) < t(S(q)). Therefore,



u(q, v) = t(q) v 
pi (qi )


iS(q)

< t(S(q)) v 

 t(S(q)) v 


iS(q)




pi (qi )

pi (Si )

iS(q)

= u(S(q), v)
where u(S(q), v) is the principals utility under the pure prole in which all the agents in
S(q) exert eort with probability 1, and the rest exert no eort.
2
We show that AN D (on some subset of bits) is the only function such that any structured
technology based on this function exhibits IRS, that is, this is the only function such that for
any choices of parameters (any n and any {i , i }iN ), the structured technology exhibits
IRS. For any other Boolean function, there is an assignment for the parameters such that the
created structured technology is essentially OR over 2 inputs (Lemma B.1 in Appendix B),
thus it has non-trivial POP (recall Example 3.1). For the proof of the following theorem
see Appendix B.
Theorem 4.3 Let f be any monotone Boolean function with n  2 inputs, that is not
constant and not a conjunction of some subset of the input bits. Then there exist parameters
{i , i }ni=1 such that the POP of the structured technology with the above parameters (and
identical cost c = 1) is greater than 1.0233.
Thus, our goal now is to give upper bounds on the POP for various technologies.

5. Quantifying the Gain by Mixing
In this section we present bounds on the price of purity for general technologies, following
by bounds for the special case of OR technology.
5.1 POP for General Technologies
We rst show that the POP can be bounded by the principals price of unaccountability (Babaio et al., 2006b), whose denition follows.
Denition 5.1 The principals price of unaccountability P OUP (t, c) of a technology (t, c)
is dened as the worst ratio (over v) between the principals utility in the observable-actions
case and the hidden-actions case:

 (v))  v 
t(Soa
 (v) ci
iSoa

P OUP (t, c) = Supv>0
ci
t(S  (v))  v  iS  (v) i (a
i )
 (v) is the optimal pure contract in the observable-actions case, and S  (v) is the
where Soa
optimal pure contract in the hidden-actions case.

349

fiBabaioff, Feldman & Nisan

Theorem 5.2 For any technology t it holds that P OUP (t)  P OP (t).
Proof: Both P OUP (t) and P OP (t) are dened as supremum over utilities ratio for a given
value v. We present a bound for any v, thus it holds for the supremum. The denominator in
both case is the same: it is the optimal utility of the principal in the hidden-actions case with
pure strategies. The numerator in the POP is the optimal principal utility in the hiddenactions case with mixed strategies. Obviously, this is at most the optimal principal utility
in the observable-actions case with mixed strategies. It has already been observed that in
the observable-actions case mixed strategies cannot help the principal (see Section 3), i.e.,
the principal utility with mixed strategies equals the principal utility with pure strategies.
The assertion of the theorem follows by observing that the optimal principal utility with
pure strategies in the observable-action case is the numerator of P OUP .
2
However, this bound is rather weak. To best see this, note that the principals price of
unaccountability for AND might be unbounded (e.g., Babaio et al., 2006b). Yet, as shown
in Section 4.2, P OP (AN D) = 1.
In this section we provide better bounds on technologies with identical costs. We begin
by characterizing the payments for a mixed contract. We show that under a mixed prole,
each agent in the support of the contract is paid at least the minimal payment to a single
agent under a pure prole with the same support, and at most the maximal payment.
For a mixed prole q = (q1 , q2 , . . . , qn ), let S(q) be the support of q, that is, i  S(q)
if and only if qi > 0. Similarly, for a pure prole a = (a1 , a2 , . . . , an ) let S(a) be the
ci
support a. Under the mixed prole q, agent i  S(q) is being paid pi (qi ) = t(1,qi )t(0,q
.
i )
Similarly, under the pure prole a, agent i  S(a) is being paid pi (S(a) \ {i}) = pi (ai ) =
ci
t(S(a))t(S(a)\{i}) , where t(T ) is the success probability when aj = 1 for j  T , and aj = 0
for j 
/ T.
Lemma 5.3 For a mixed prole q = (q1 , q2 , . . . , qn ), and for any agent i  S(q) let Si =
S(q) \ {i} be the support of q excluding i. It holds that
maxT Si pi (T )  pi (qi )  minT Si pi (T )
Proof: We show that for any agent i  S(q), the increase in the success probability from him
exerting eort when some other players play mixed strategies, is a convex combination of
the increases in the success probability
when
in the support play pure strategies.

nthe aagents
i
Recall that: t(q1 , . . . , qn ) = a{0,1}n ( i=1 qi  (1  qi )(1ai ) )t(a1 , . . . , an ).
Let t be the technology t restricted to the support S = S(q), that is, if i1 , . . . , iS are
the agents in S then t (ai1 , ai2 , . . . , aiS ) is dened to be the value of t on a, when aj = 0
for any agent j 
/ S, and aj = aik for j = ik  S. t is dened on mixed strategies in the
expected way. Thus,
i (qi ) = t(1, qi )  t(0, qi )
= t (1, qSi )  t (0, qSi )

 aj
=
(
qj  (1  qj )(1aj ) ) t (1, a) 
a{0,1}|S|1 jSi

=



(





(



a{0,1}|S|1 jSi
a
qj j

 (1  qj )(1aj ) )(t (1, a)  t (0, a))

a{0,1}|S|1 jSi

350

qj j  (1  qj )(1aj ) )t (0, a)
a

fiMixed Strategies in Combinatorial Agency

We conclude that i (qi ) is a convex combination of i (bi ) for b with support S(b) 
Si . Therefore, minT Si (t({i}  T )  t(T ))  i (qi )  maxT Si (t({i}  T )  t(T )).
Thus,
maxT Si 1/(t({i}  T )  t(T )) = 1/minT Si (t({i}  T )  t(T ))
 1/i (qi ) = pi (qi )
 1/maxT Si (t({i}  T )  t(T ))
= minT Si 1/(t({i}  T )  t(T ))
2
In what follows, we consider two general families of technologies with n agents: anonymous technologies and technologies that exhibit decreasing returns to scale (DRS). DRS
technologies are technologies with decreasing marginal contribution (more eort by others
decrease the contribution of an agent). For both families we present a bound of n on the
POP.
We begin with a formal denition of DRS technologies.
Denition 5.4 A technology success function t exhibits (weakly) decreasing returns to
scale (DRS)4 if for every i, and every b  a
t(bi , bi )  t(ai , bi )  t(bi , ai )  t(ai , ai )
Theorem 5.5 For any anonymous technology or a (non-anonymous) technology that exhibits DRS, it holds that P OP (t)  n.
For the proof of this theorem as well as the proofs of all claims that appear later in this
section, see Appendix C. We also prove a bound on the POP for any technology with 2
agents (even not anonymous), and an improved bound for the anonymous case.
Theorem 5.6 For any technology t (even non-anonymous) with 2 agents, it holds that
P OP (t)  2. If t is anonymous then P OP (t)  3/2.
We do not provide bounds for non-anonymous technologies, this is left as an open
problem for future research. We believe that the linear bound for anonymous and DRS
technologies are not tight and we conjecture that there exists a universal constant C that
bounds the POP for any technology. Moreover, our simulations seem to indicate that a nonanonymous OR technology with 2 agents yields the highest possible POP. This motivates
us to explore the POP for the OR technology in more detail.
5.2 POP for the OR Technology
As any OR technology (even non-anonymous) exhibits DRS (see Appendix A.1), this implies
a bound of n on the POP of the OR technology. Yet, for anonymous OR technology we
present improved bounds on the POP. In particular, if  = 1   < 1/2 we can bound the
POP by 1.154....
4. Note that t exhibits DRS if and only if it is submodular.

351

fiBabaioff, Feldman & Nisan

Theorem 5.7 For any anonymous OR technology with n agents:
n

 n  (n  1). (b) POP goes to 1 as n goes
1. If 1 >  >  > 0: (a) P OP  1(1)

to  (for any xed ) or when  goes to 1 (for any xed n  2).
2. If

1
2

>  = 1   > 0: (a) P OP 

to 0 or as  goes to

1
2


2(32 3)

(=
3( 32)

1.154..). (b) POP goes to 1 as  goes

(for any xed n  2).

While the bounds for anonymous OR technologies for the case in which  = 1   are
much better than the general bounds, they are still not tight. The highest POP we were able
to obtain by simulations was of 1.0233 for  > , and 1.0187 for  = 1   (see Section 3),
but deriving the exact bound analytically is left as an open problem.

6. The Robustness of Mixed Nash Equilibria
In order to induce an agent i to truly mix between exerting eort and shirking, pi must
be equal exactly to ci /i (qi ) (see claim 2.1). Even under an increase of  in pi , agent
i is no longer indierent between ai = 0 and ai = 1, and the equilibrium falls apart.
ci
This is in contrast to the pure case, in which any pi  i (a
will maintain the required
i )
equilibrium. This delicacy exhibits itself through the robustness of the obtained equilibrium
to deviations in coalitions (as opposed to the unilateral deviations as in Nash). A strong
equilibrium (Aumann, 1959) requires that no subgroup of players (henceforth coalition)
can coordinate a joint deviation such that every member of the coalition strictly improves
his utility.
Denition 6.1 A mixed strategy prole q  [0, 1]n is a strong equilibrium (SE) if there
does not exist any coalition   N and a strategy prole q  i [0, 1] such that for any
 , q ) > u (q).
i  , ui (q
i

In the work of Babaio et al. (2006b) we show that under the payments that induce the
pure strategy prole S  as the best pure Nash equilibrium (i.e., the pure Nash equilibrium
that maximizes the principals utility), S  is also a strong equilibrium. In contrast to the
pure case, we next show that any non-degenerate mixed Nash equilibrium q in which there
exist at least two agents that truly mix (i.e., i = j s.t. qi , qj  (0, 1)), can never be a strong
equilibrium. This is because if the coalition  = {i|qi  (0, 1)} deviate to q in which each
i   exerts eort with probability 1, each agent i   strictly improves his utility (see
proof in Appendix D).
Theorem 6.2 If the mixed optimal contract q includes at least two agents that truly mix
(i = j s.t. qi , qj  (0, 1)), then q is not a strong equilibrium.
In any OR technology, for example, it holds that in any non-degenerate mixed equilibrium at least two agents truly mix (see lemma 3.2). Therefore, no non-degenerate contract
in the OR technology can be a strong equilibrium.
As generically a mixed Nash contract is not a strong equilibrium while a pure Nash
contract always is, if the pricipal wishes to induce a strong Nash equilibrium (e.g., when
the agents can coordinate their moves), he can restrict himself to inducing a pure Nash
equilibrium, and his loss from doing so is bounded by the POP (see Section 5).
352

fiMixed Strategies in Combinatorial Agency

7. Algorithmic Aspects
The computational hardness of nding the optimal mixed contract depends on the representation of the technology and how it is being accessed. For a black-box access and for
the special case of read-once networks, we generalize our hardness results of the pure case
(Babaio et al., 2006b) to the mixed case. The main open question is whether it is possible
to nd the optimal mixed contract in polynomial time, given a table representation of the
technology (the optimal pure contract can be found in polynomial time in this case). Our
generalization theorems follow (see proofs in Appendix E).

Theorem 7.1 Given as input a black box for a success function t (when the costs are
identical), and a value v, the number of queries that is needed, in the worst case, to nd the
optimal mixed contract is exponential in n.

Even if the technology is a structured technology and further restricted to be the sourcepair reliability of a read-once network (see (Babaio et al., 2006b)), computing the optimal
mixed contract is hard.
Theorem 7.2 The optimal mixed contract problem for read once networks is #P -hard
(under Turing reductions).

8. Conclusions and Open Problems
This paper studies a model in which a principal induces a set of agents to exert eort through
individual contracts that are based on the nal outcome of the project. The focus of this
paper is the question how much the principal can benet when inducing a Nash equilibrium
in mixed strategies instead of being restricted to a pure Nash equilibrium (as was assumed
in the original model). We nd that while in the case of observable actions mixed equilibria
cannot yield the principal a higher utility level than pure ones, this can indeed happen
under hidden actions. Yet, whether or not mixed equilibria improve the principals utility
depends on the technology of the project. We give sucient conditions for technologies
in which mixed strategies yield no gain to the principal. Moreover, we provide bounds on
the principals gain for various families of technologies. Finally, we show that an optimal
contract in non-degenerated mixed Nash equilibrium is not a strong equilibrium (in contrast
to a pure one) and that nding such an optimal contract is computationally challenging.
Our model and results raise several open problems and directions for future work. It
would be interesting to study the principals gain (from mixed strategies) for dierent
families of technologies, such as series-parallel technologies. Additionally, the model can be
extended beyond the binary eort level used here. Moreover, our focus was on inducing some
mixed Nash equilibrium, but that equilibrium might not be unique. One can consider other
solution concepts such as a unique Nash equilibrium or iterative elimination of dominated
strategies. Finally, it might be of interest to study the performance gap between pure and
mixed Nash equilibria in domains beyond combinatorial agency.
353

fiBabaioff, Feldman & Nisan

9. Acknowledgments
Michal Feldman is partially supported by the Israel Science Foundation (grant number
1219/09) and by the Leon Recanati Fund of the Jerusalem school of business administration.

Appendix A. General
Lemma 2.2 ( Monotonicity lemma) For any technology (t, c) the expected utility of
the principal at the optimal mixed contract, the success probability of the optimal mixed
contract, and the expected payment of the optimal mixed contract, are all monotonically
non-decreasing with the value.
Proof: Suppose the proles of mixed actions q 1 and q 2 are optimal for v1 and v2 < v1 ,
respectively. Let P 1 and P 2 be the total payment in case a successful project, corresponding
to the minimal payments that induce q 1 and q 2 as Nash equilibria, respectively. The utility
is a linear function of the value, u(a, v) = t(a)  (v  P ) (P is the total payments in case
of successful project). As q 1 is optimal at v1 , u(q 1 , v1 )  u(q 2 , v1 ), and as t(a)  0 and
v1 > v2 , u(q 2 , v1 )  u(q 2 , v2 ). We conclude that u(q 1 , v1 )  u(q 2 , v2 ), thus the utility is
monotonic non-decreasing in the value.
Next we show that the success probability is monotonic non-decreasing in the value. q 1
is optimal at v1 , thus:
t(q 1 )  (v1  P 1 )  t(q 2 )  (v1  P 2 )
q 2 is optimal at v2 , thus:
t(q 2 )  (v2  P 2 )  t(q 1 )  (v2  P 1 )
Summing these two equations, we get that (t(q 1 )  t(q 2 ))  (v1  v2 )  0, which implies that
if v1 > v2 then t(q 1 )  t(q 2 ).
Finally we show that the expected payment is monotonic non-decreasing in the value.
As q 2 is optimal at v2 and t(q 1 )  t(q 2 ), we observe that:
t(q 2 )  (v2  P 2 )  t(q 1 )  (v2  P 1 )  t(q 2 )  (v2  P 1 )
or equivalently, P 2  P 1 , which is what we wanted to show.
2
We note that the above lemma also holds for the case of proles of pure actions, and
for the observable-actions case (by exactly the same arguments).
Lemma 2.4 For any technology (t, c), the price of purity is obtained at a nite v that is a
transition point between two optimal pure contracts.
Proof: Clearly for a large enough value v  , the ratio is 1, as in both cases all agents exert
maximal eort. For small enough values the principal will choose not to contract with any
agent in both cases (and the ratio is 1). This is true as at a value that is smaller than any
agents cost, an optimal contract is to contract with no agent in both cases. Let v be the
supremum on all values for which the principal will choose not to contract with any agent
in both cases. Now, the ratio is a continuous function on the compact range [v, v  ], thus its
supremum is obtained, for some value that is at most v  .
354

fiMixed Strategies in Combinatorial Agency

We have seen that the POP is obtained at some value v, we next prove that it is obtained
at a transition point of the pure case. If P OP = 1 the claim clearly holds, thus we should
only consider the case that P OP > 1. Let v be the maximal value for which the POP is
obtained. Assume in contradiction that v is not a transition point between two optimal
pure contracts, and that a and q are optimal for the pure and mixed cases, respectively. As
P OP > 1, q is non-degenerate and u(q, v) > u(a, v). Let P (a) and P (q) denote the total
payment in case of success for a and q, respectively. We next consider two options.
We rst consider the case that t(a)  t(q). We show that in this case, the utilities ratio
for v  , for some  > 0 is worse than the utilities ratio for v, and we get a contradiction.
For  > 0 small enough, the optimal pure contract is still a, and u(q, v  ) > 0. Let q be
the optimal mixed contract at v  . It holds that
P OP 

u(q , v  )
u(q, v  )
u(q, v)  t(q)  
u(q, v)

=
>
u(a, v  )
u(a, v  )
u(a, v)  t(a)  
u(a, v)

where the last strict inequality is by the following argument.
u(q, v)  t(q)  
u(q, v)
>
u(a, v)  t(a)  
u(a, v)



t(q)  u(a, v) < t(a)  u(q, v)



P (q) < P (a)

and P (q) < P (a) as u(q, v) = t(q)(v  P (q)) > t(a)(v  P (a)) = u(a, v) and t(a)  t(q).
Next we consider the case that t(q) > t(a). If P (q) < P (a), the argument that was
presented above shows that the utilities ratio for v  , for some  > 0, is worse than the
utilities ratio for v, and we get a contradiction. On the other hand, if P (q)  P (a) we show
that the utilities ratio for v + , for some  > 0, is at least as large as the utilities ratio for
v, in contradiction to v being the maximal value for which the POP is obtained. For  > 0
small enough, the optimal pure contract is still a (as v is not a transition point between
pure contracts). Let q be the optimal mixed contract at v + . It holds that
P OP 

u(q, v + )
u(q, v) + t(q)  
u(q, v)
u(q , v + )

=

u(a, v + )
u(a, v + )
u(a, v) + t(a)  
u(a, v)

where the last inequality is by the following argument.
u(q, v) + t(q)  
u(q, v)

u(a, v) + t(a)  
u(a, v)

 t(q)  u(a, v)  t(a)  u(q, v)



P (q)  P (a)

which holds by our assumption.
2
The following corollary of Lemma 2.4 will be helpful in nding the POP for technologies
with 2 agents.
Corollary A.1 Assume that technology t with 2 agents and with identical costs exhibits
DRS, then the POP is obtained at the transition point of the pure case, to the contract with
both agents.
Proof: By Lemma 2.4 the POP is obtained at a transition point of the pure case. If there
is a single transition point, between 0 agents and 2 agents, the claim holds. If contracting
with a single agent is sometimes optimal, it must be the case that the single agent that is
contracted is the agent with the (possibly weakly) highest success probability (agent i such
355

fiBabaioff, Feldman & Nisan

that t({i})  t({j}) where j = i, which implies that i = t({i})t()  t({j})t() = j ).
Thus we only need to show that the POP is not obtained at the transition point v between
0 agents and the contract with agent i. Assume that q is the optimal mixed contract at
v, and that P (q) is the total payment in case of success. If q gives the same utility as the
contract {i}, we are done.
Otherwise, u(q, v) > u({i}, v) , and by Corollary C.9 it holds that P (q)  c1 , thus
t(q) > t({i}). This implies that the utilities ratio at the value v +  for  > 0 small enough
is worse than the ratio for v (by the argument presented in Lemma 2.4 for the case that
t(q) > t(a)).
2
A.1 Analysis of the OR Technology

Lemma 3.2 For any anonymous OR technology (any  > , c, n) and value v, either the
optimal mixed contract is a pure contract, or, in the optimal mixed contract k  {2, . . . n}
agents exert eort with equal probabilities q1 = . . . = qk  (0, 1), and the rest of the agents
exert no eort.
Proof: First, observe that it cannot by the case that all agents but one exert no eort, and
this single agent mix with probability 0 < qi < 1. This is so as the principal would rather
change the prole to qi = 1 (pays the same, but gets higher success probability). Suppose
by contradiction that a contract that induces a prole (qi , qj , qij ) such that qi , qj  (0, 1]
and qi = qj (qi > qj without loss of generality) is optimal. For agent k, we denote the
probability of failure of agent k in his task by (qk ). That is, (qk ) = 1  (qk  + (1  qk )) =
1   + (  )qk =  + qk where  =   .
We show that for a suciently small  > 0, the mixed prole q  = (qi , qj + (qji ) , qij )
(q )

(qi )
}, ) obtains a better contract, in
(for  such that q   [0, 1]. i.e.,  < min{qi , (1  qi ) (q
j)
contradiction to the optimality of the original contract.


For the OR technology,t(q) = 1  kN (qk ) = 1  (q), where (q) = kN (qk ).
We also denote ij (q) = k=i,j (qk ). The change in success probability is related to the
(
)

new product (qi  )   qj + ji  :

(qi )



(qj )

(

)
(qj )
= (qi  )   qj + 
(qi )
)
(
(qj )
= ((qi )  )  (qj ) + 
(qi )
(qj )
(qj )
= (qi )(qj )  (qj ) + 
(qi )   2 2
(qi )
(qi )
(qj )
= (qi )(qj )   2 2
(qi )
356

fiMixed Strategies in Combinatorial Agency

Therefore the new success probability t(q  ) has increased by the change:
j
, qij )
i
(
)
(qj )
= 1  (qi  )   qj + 
 ij (q)
(qi )
)
(
(qj )
= 1  (qi )(qj )   2 2
 ij (q)
(qi )
(
)
 2 2 (q)
 2 2 (q)
= t(q) +
= t(q) 1 +
((qi ))2
t(q)  ((qi ))2

t(q  ) = t(qi  , qj +

2 2

  (q)

We denote z() = t(q)((q
2 , thus t(q ) = t(q)  (1 + z()), where z() > 0 for any .
i ))
After showing that the success probability increases, we are left to show that for suciently small , the total payment decreases. The payment to agent l is given by:

pl =

c
c  (ql )
c

=
=
t(1, ql )  t(0, ql )
(  ) m=l (qm )
(  )  t(q)

The change in the payment of agent k is
c  (qk )
c  (qk )

(  )  t(q) (  )  t(q  )
(
)
(qk )
c
=
 (qk ) 
t(q)  (  )
(1 + z())
(
)
c
=
 (qk )  (qk ) + (qk )  z()
t(q)  (  )  (1 + z())
(
)
= W ()  (qk )  (qk ) + (qk )  z()

pk  pk =

c
for W () = t(q)()(1+z())
For agent k = i, j, as (qk ) = (qk ) we get pk  pk = W ()  (qk )  z(). For agent i, as
(qi )  (qi ) =  we get pi  pi = W ()  ( + (qi )  z()). For agent j, as (qj )  (qj ) =

 (qji ) we get pj  pj = W ()  ( (qji ) + (qj )  z()).
By summing over all agents we get
(q )

(q )


kN

pk 


kN

pk =



(pk  pk )

kN

= (pi  pi ) + (pj  pj ) +



(pk  pk )

k=i,j

)

(qj )
+ z() 
(qk )
= W ()    
(qi )
kN
( (
)
)

(qj )
= W ()   1 
+ z() 
(qk )
(qi )
(

kN

357

fiBabaioff, Feldman & Nisan

which is positive by the following observations. W () > 0 and z() > 0 for any , and clearly

(qj )
kN (qk ) > 0. Additionally, (1  (qi ) ) > 0 as  =    < 0, and (qi ) < (qj ) as
pi > p j .
To conclude, we have show that the success probability of q  is greater than the success
probability of q, and the payments are lower, thus the utility of the principal increases when
he moves from q to q  , which is a contradiction to the optimality of q.
2
Observation A.2 The OR technology exhibits DRS.
Proof: Let ra , rb  [0, 1]n be two proles of actions, such that rb  ra (for any i, rib  ria ).
b )  t (r a , r b )  t (r b , r a )  t (r a , r a ). Indeed,
We need to show that for every i, ti (rib , ri
i i
i i i
i i
i
i


b
b
ti (rib , ri
)  ti (ria , ri
) = 1  (1  rib ) (1  rjb )  (1  (1  ria ) (1  rjb ))
j=i


= (rib  ria ) (1  rjb )

j=i

j=i



(rib



ria )


(1  rja )
j=i

= 1  (1  rib )



(1  rja )  (1  (1  ria ) (1  rja ))
j=i

=

a
ti (rib , ri
)



j=i

a
ti (ria , ri
)

2

Appendix B. When is Pure Nash Good Enough?
Lemma B.1 Let f : {0, 1}n  {0, 1} for n  2 be a monotone Boolean function that is
not constant and not a conjunction of some subset of the input bits. Then there exist an
assignment to all but two of the bits such that the restricted function is a disjunction of the
two bits.
Proof: By induction on the number of bits the function depends on. The base case is n = 2,
where the only monotone function that is not constant and not a conjunction of some subset
of the input bits is the disjunction of two input bits.
Let xi be a variable on which f depends (which must exist since f is not constant). Let
|x
=a
i
f
= f (a, xi ) denote the function f restricted to xi = a. We denote h = f |xi =0 and
|x
g = f i =1 . As f is monotone, f = x  f |xi =1 + f |xi =0 = g  x + h, where f |xi =1  f |xi =0 (that
is, for any xi , if f (0, xi ) = 1 then f (1, xi ) = 1, and if f (1, xi ) = 0 then f (0, xi ) = 0).
If h is not constant and not a conjunction of some subset of the input bits, then we continue
by induction using h by setting x = 0. Similarly If g is not constant and not a conjunction
of some subset of the input bits, then we continue by induction using g by setting x = 1.
So we are left with the case where both h and g are conjunctions of some subset of
the variables (where the constant 1 is considered to be the conjunction of the empty set of
variables, and it is easy to verify that h and g cannot be the constant 0). Since f depends
on xi , we have that h = g, and since h  g, there exists some variable xj (j = i) that is in
358

fiMixed Strategies in Combinatorial Agency

the set of variables whose conjunction is h but not in that of g. Now set all variables but
xi and xj to 1, and we are left with xi + xj .
2
Theorem B.2 Let f be any monotone Boolean function with n  2 inputs, that is not
constant and not a conjunction of some subset of the input bits. Then there exist parameters
{i , i }ni=1 such that the POP of the structured technology with the above parameters (and
identical cost c = 1) is greater than 1.0233.
Proof: By Lemma B.1 there is an assignment to all but two variables such that the restricted
function over the two variables is an OR function. For these two variables we choose the
parameters according to the worst POP we know of for an OR technology (see Section 3).
For the rest of the variables we choose parameters such that for the value for which the
worst utilities ratio is achieved, all the rest of the agents exert no eort and provide success
probabilities that are (almost) the success probabilities dictated by the assignment. Next
we make this argument formal.
Recall that by Lemma B.1 there is an assignment to all but two variables such that the
restricted function over the two variables is an OR function. Let i1 and i2 be the indices of
these two variables. In Section 3 we have observed that for OR technology with two agents
with values v = 233, 1 = 2 = 0.0001 and 1 = 2 = 0.9, the POP is at least 1.0233.
We embed this into an instance of an OR technology with n agents by considering a value
v = 233 and success probabilities as follows: For agents i1 and i1 , let i1 = i2 = 0.0001 and
i1 = i2 = 0.9. For the rest of the agents, x a suciently small  > 0. Then set i = 1  
and i = 1  2 if i was set to 1 in the assignment, and set i = 2 and i =  if i was set
to 0 in the assignment.
When  > 0 is small enough the payment needed to induce every agent i = i1 , i2 to
exert eort (for any prole of eorts of the others) will be greater than v as it is inversely
proportional to the increase in the success probability due to is eort, and this goes to
zero with . Thus, for a small enough  all agents i = i1 , i2 will not exert eort in the
optimal contract, but each such agent i will provide an almost sure success in the case
the assignment of variable i is 1, and an almost sure failure in the case the assignment of
variable i was zero. The created technology is essentially the same as the OR technology
with agents i1 and i2 with i1 = i2 = 0.0001, i1 = i2 = 0.9, and for the value v = 233 the
POP will be at least 1.0233.
2

Appendix C. Quantifying the Gain by Mixing
C.1 POP for n Agents
We observe that for any technology, the POP is bounded by the ratio between the success
probability when all agents exert eort, and the success probability when none of the agents
exert eort. This simple bound shows that if the success probability when none of the agents
exert eort is at least some positive constant, the POP is bounded by a constant.
Observation C.1 For any technology (t, c) with set of agents N , P OP (t) 
359

t(N )
t() .

fiBabaioff, Feldman & Nisan

Proof: For any given value v, the utility of the principal with the optimal mixed Nash is
at most v  t(N ), while the utility of the principal with the optimal pure Nash is at least
)
t(N )
v  t(), thus the POP is bounded by vt(N
2
vt() = t() .
From this point we only consider technologies with identical costs. The following lemma
shows that anonymous technologies as well as any technology that exhibits DRS have POP
at most n.
Lemma C.2 Assume that for a technology t with n agents the following holds: For any
optimal mixed contract q with support S, there is a pure prole a with support T  S such
that
 t(a) 

t(S)
|S|

 For each agent i  T , and any pure prole b with support R  S it holds that t(1, ai )
t(0, ai )  t(1, bi )  t(0, bi ).
Then the P OP (t)  n.
Proof: We rst observe that P (a), the total payment under the prole a in the case of
success, is at most P (q), the total payment under the prole q. As T  S, the set of agents
that are paid under a is a subset of the set of agents that are paid under q. Each agent in
T is paid at least as much under q, as he is paid under a (by the second condition, as the
increase in success probability under q is a convex combination of the increase in success
probability for pure proles with support R  S). Thus, P (a)  P (q), and U (a) > 0. We
conclude that
t(q)(v  P (q))
t(q)
t(S)
u(q, v)



 |S|
u(a, v)
t(a)(v  P (a))
t(a)
t(a)
where the last inequality is derived from the rst condition. This implies that the POP is
bounded by n.
2
Corollary C.3 For any anonymous technology t with n agents, P OP (t)  n.
Proof: Assume that for the value v the mixed prole q is optimal, and its support is of size
k. Let tm be the success probability if m agents exert eort, and let m = tm  tm1 . Let
m = argmaxmk m .
By the denition of m the second condition holds. The rst condition holds as:
ktm  k(t0 +tm t0 )  t0 +k(tm t0 )  t0 +k(tm tm1 ) = t0 +km  t0 +(tk t0 ) = tk
2
Corollary C.4 For any technology t with n agents that exhibits DRS and has identical
costs, P OP (t)  n.
Proof: Let agent i  S be the agent with maximal individual contribution in S, the support
of q (t({i})  t({j}) for all j  S). DRS ensures that the two conditions of Lemma C.2
hold.
2
The following holds for OR technology with n agents (even non-anonymous), as it exhibits DRS. In particular, even if a single agent has i > 1/2 we get a bound of 2 on the
POP.
360

fiMixed Strategies in Combinatorial Agency

Observation C.5 Assume that the technology t with n agents (with identical costs) exhibits
t(N )
DRS, then P OP (t)  t({i})
, for agent i with maximal individual contribution (t({i}) 
t({j}) for all j  N ).
Proof: Let agent j  S be the agent with maximal individual contribution in S, the support
of q. Following the proof of Lemma C.2, as t({i})  t({j}) and P (q)  P ({j})  P ({i}),
and u(q, v) > 0 ,this implies that u({i}, v)  u({j}, v) > 0. Thus the optimal pure contract
a gives utility of at least u({i}, v) > 0, therefore for any v we have the bound
u(q, v)
u(q, v)
t(q)(v  P (q))
t(S)
t(N )

=


u(a , v)
u({i}, v)
t({i})(v  P ({i}))
t({i})
t({i})
which implies that the POP is bounded by

t(N )
t({i}) .

2

Corollary C.6 For any anonymous technology with n agents that exhibits DRS, it holds
that P OP (t)  ttn1 .
C.2 POP for Anonymous OR
As OR exhibits DRS, the following in a direct corollary of Observation C.5.
Corollary C.7 For any anonymous OR technology with n agents, it holds that P OP (OR) 
tn
t1 .
Theorem 5.7 For any anonymous OR technology with n agents:
n

1. If 1 >  >  > 0: (a) P OP  1(1)
 n  (n  1). (b) POP goes to 1 as n goes

to  (for any xed ) or when  goes to 1 (for any xed n  2).
2. If

1
2

>  = 1   > 0: (a) P OP 

to 0 or as  goes to

1
2


2(32 3)

(=
3( 32)

1.154..). (b) POP goes to 1 as  goes

(for any xed n  2).

Proof: Based on Corollary C.7, P OP 

t(1n )
,
t(1,0n1 )

all the results are based on this bound.

1. Proof of part 1(a):
t(1n )
1  (1  )n
1  (1  )n
1  (1  )n
=

=
t(1, 0n1 )
1  (1  )(1  )n1
1  (1  )

Additionally,


1  (1  )n 
=
(1  )j = 1 +
(1  )j  1 +
(1  ) = n  (n  1)
1  (1  )
n1

n1

n1

j=0

j=1

j=1

and this concludes the proof.
361

fiBabaioff, Feldman & Nisan

2. Proof of part 1(b):
t(1n )
1  (1  )n
=
t(1, 0n1 )
1  (1  )(1  )n1
this expression goes to 1 for any xed  >  > 0, when n goes to , as (1  )n and
(1  )n1 goes to zero.
1(1)n
,


Additionally, we saw that P OP 
goes to 1, the POP goes to 1.

thus it is clear that if n is xed and 

3. Proof of part 2(a): We rst bound the POP for the case of anonymous OR with 2
agents and with  = 1   < 1/2. For this case the POP is bounded by
t(1, 1)
(2  )
= 2
t(0, 1)
 +1

2
The derivative of this ratio is (22
3  1. This is
2 +1)2 , which equals to zero at  =
a maximum point since the second derivative is negative, and the ratio at this point
equals to 1.154... Therefore, t(1,1)
t(1,0)  1.154... Observation C.8 below shows that for
any n  2 it holds that

t(1n )
t(1,0n1 )



t(1,1)
t(0,1)

4. Proof of part 2(b): The expression
or

thus the same bound holds for any n.

t(1n )
t(1,0n1 )

=

1 n
1(1)n1

goes to 1 when  goes to 0

1
2.

2
For anonymous OR technology with n agents and  = 1   < 1/2 we can bound the
POP by 1.154...
Observation C.8 Let ORn, denote the anonymous OR technology of n agents with  =
1   < 1/2. For any k  3 it holds that
P OP (ORk, ) 

ORk, (1k )
ORk1, (1k1 )

ORk, (1, 0k1 )
ORk1, (1, 0k2 )

thus for any k  3 it holds that
P OP (ORk, ) 

ORk, (1k )
OR2, (1, 1)

 1.154...
k1
ORk, (1, 0 )
OR2, (1, 0)

Proof: For the technology ORk, it holds that
ORk, (1k )
1  k
=
ORk, (1, 0k1 )
1    (1  )k1
Thus we need to show that for any k  3
1  k
1   k1

1    (1  )k1
1    (1  )k2
362

fiMixed Strategies in Combinatorial Agency

which holds if and only if
1   k    (1  )k2 +  k+1  (1  )k2  1   k1    (1  )k1 +  k  (1  )k1
which holds if and only if
 k1 (1  ) +   (1  )k2  (1  (1  )) +  k  (1  )k2  ((1  )  )  0
by dividing by  2  (1  ), this holds if and only if
 k3 + (1  )k3 +  k2  (1  )k3 (1  2  )  0
which holds as 1     thus (1  )k3   k3 and  k2  (1  )k3 (1  2  )  0.

2

C.3 POP for 2 Agents
Let us now consider the case that n = 2, and prove a better bound on the POP. We have
shown that the POP for IRS technology is 1. Since an anonymous technology with 2 agents
exhibits either IRS or DRS, we only need to handle the DRS case. Let 1 = t1  t0 and
2 = t2  t1 . Assume that 1 =   2 for some   1 (DRS).
The following is a corollary of Lemma 5.3.
Corollary C.9 For a DRS technology over 2 agents, assume w.l.o.g. that t({1})  t({2})
and denote 1 = t({1})  t(). For any mixed prole q = (q1 , q2 ) it holds that each agent
is paid at least c1 .
Proof: As t({1})  t({2}) it implies that 1 = t({1})  t()  t({2})  t(), and DRS
implies that 1 = t({1})  t()  t({1, 2})  t({1}) and t({2})  t()  t({1, 2})  t({2}),
2
thus Lemma 5.3 implies that each agent is paid at least c1 .
Theorem C.10 For any anonymous technology t with 2 agents, it holds that the P OP (t) 
3/2.
Proof: Let u((q1 , q2 ), v) be the utility of the principal for mixed prole (q1 , q2 ) when his value
for the project is v. Let P (q1 , q2 ) denote the total payment to both agents if the project is
successful. Similarly, let u((a1 , a2 ), v) be the utility of the principal for pure prole (a1 , a2 )
when his value is v.
For a given value v, let (q1 , q2 ) be the optimal mixed contract, and let (a1 , a2 ) be the
u((q1 ,q2 ),v)
optimal pure contract. We show that for any value v it holds that u((a
 3/2, which
1 ,a2 ),v)
is sucient to prove the theorem.
If the optimal mixed prole is a pure prole, the ratio is 1, thus we only need to handle
the case that the prole (q1 , q2 ) is not pure (a non-degenerate mixed contract). In this case,
as u((q1 , q2 ), v) = t(q1 , q2 )(vP (q1 , q2 )) > 0, it holds that vP (q1 , q2 ) > 0. By corollary C.9
this implies that u((1, 0), v) > 0 as P (q1 , q2 )  c1 . Thus u((a1 , a2 ), v)  u((1, 0), v) > 0, so
u((q1 , q2 ), v)
u((q1 , q2 ), v)
t(q1 , q2 )(v  P (q1 , q2 ))
t(q1 , q2 )
t(1, 1)
t2




=
c
u((a1 , a2 ), v)
u((1, 0), v)
t(1, 0)(v  1 )
t(1, 0)
t(1, 0)
t1
363

fiBabaioff, Feldman & Nisan

Now we consider two cases. First we consider the case that t0  2 . In this case
t2
t0 +  1 +  2
2 +   2 +  2
2+
1
3
u((q1 , q2 ), v)

=

=
=1+

u((a1 , a2 ), v)
t1
t0 +  1
2 +   2
1+
1+
2
to replace t0 with 2 we use Lemma C.13.
Next we consider the case that t0 < 2 . In this case we look at the value v  for which
the principal is independent between contracting with 1 or 2 agents. At v = v  it holds
c
that t(1, 0)  (v  c1 ) = t(1, 1)  (v  2c2 ), thus v  2 = v  (t2  t1 ) = t2 2c2  t1  
, thus
2
c


it holds that v = (2 )2 (2  t2  t1 ). For a value v  v it is enough to bound the ratio
1 ,q2 ),v)
while for a value v  v  it is enough to bound the ratio u((q
u((1,1),v) . We bound
each of these ratios separately.
2
1 +2
By Lemma C.13, for the case that 0  t0 < 2 , tt21 = t0 +
 (1+)
= 1 + 1 .
t0 +1
2

For a value v  v
)
(
v  2c1
u((q1 , q2 ), v)
t(q1 , q2 )(v  P (q1 , q2 ))
t2 v  P (q1 , q2 )
1





1
+

u((1, 0), v)
t(1, 0)(v  c1 )
t1
v  c1

v  c1
)
) (
(
1
1
 1  v
1+

c  1  1

u((q1 ,q2 ),v)
u((1,0),v) ,

Now, as

2
t2

v
c

=

2
t0 +(1+)2

1
=
 1  1



2
2 +(1+)2

1
(2
(2 )2

=

1
2+ ,

we conclude that

1
2
2
=

=
2  t2  t1  2
(2  1)  t2
 t2  t1 )  1
1
(2  1)(2 + )

Thus
u((q1 , q2 ), v)

u((1, 0), v)

(

1
1+


) (
 1

v
c

1
 1  1

)

(


1
1+


) (
 1

1
(2  1)(2 + )

)

Lemma C.11 shows that the function on the RHS is bounded by 3/2 for any   1.
1 ,q2 ),v)
Finally, for a value v  v  , it is enough to bound the ratio u((q
u((1,1),v) .
v
u((q1 , q2 ), v)
t(q1 , q2 )(v  P (q1 , q2 ))
=

2c
u((1, 1), v)
t(1, 1)(v  2 )
v

2c
1
2c
2

=

v
v

2c
2
 2c2

Intuitively, as the fraction goes to 1 as  goes to 1, this implies that for suciently small 
the fraction is less than 3/2. Formally,
v

2c
2
 2c2

=1+

v
)
(
1

1+2


2c
2



v

2
(2
(2 )2

2c
2
2c
2

2(1  1 )
1+2
=1+ v
c  2  2

(

1


)


v
c

1

 2  2

1
2(  1)2
2(  1)2
1+
=1+

2

t

t

2


(2  1)t1
 t2  t1 )  2
2
1
2
364

fiMixed Strategies in Combinatorial Agency

1+

2(  1)
(2  1)

2(1)
is
We nd the maximum of the RHS. The derivative by  of 1 + (21)

maximum is obtained at  = 1 +


for  = 1 +

2
2 ),


2
2

2(22 4+1)
.
(21)2 2

The

(it is a maximum as the second derivative is negative

and the maximum is 1 +


2 

(1+ 2)(1+ 22 )

2

< 1.35.

Lemma C.11 For   1 it holds that
(
) (
)
1
1
1+
 1
 3/2

(2  1)(2 + )
Proof:
(
f () =
Let h() =

3+ 3
4 ,

1
1+


22 +33
(21) .

) (
 1

1
(2  1)(2 + )

)

(
=

The derivative of h() by  is

1
1
+2

)


82 +123
,
2 (21)2

22 + 3  3
(2  1)
it has a maximum at

and the value of the maximum is lower than 2.072.
1
We look at  = 8/5. As the function 1  +2
is an increasing function of  (for   1),
(
)
1
we get that for any   , f ()  1  +2  2.072 = 13
18  2.072 < 3/2 To conclude the
proof we show that f () is a decreasing function of , for any    = 8/5. The derivative
of f () by  is
2(24 + 43  42  9 + 3)
2 (2  1)2 (2 + )2
Thus we only need to show that 24 + 43  42  9 + 3 > 0 for any    = 8/5. This
holds as 43 42 = 42 (1) > 0 for any  > 1, and 24 9+3  24 9+3 = 1067
625 > 0
4
3
for any    (as the function 2  9 + 3 has derivative 8  9 which is positive for any
  91/3 /2, thus it is a monotonically increasing function for    = 8/5 > 1.05 > 91/3 /2
).
2
Theorem C.12 For any technology t (even non-anonymous) with 2 agents and identical
costs, it holds that the P OP (t)  2.
Proof: If the technology is anonymous, we have already proved a stronger claim. Assume
that it is not, then w.l.o.g. assume that t(1, 0)  t(0, 1). We have shown that the prole
(0, 1) is never optimal, this implies (by the same argument as we have seen in the case that
the technology is anonymous), that
P OP 

u((q1 , q2 ), v)
u((q1 , q2 ), v)
t(1, 1)


u((a1 , a2 ), v)
u((1, 0), v)
t(1, 0)

If the technology exhibits IRS, then we know that POP=1. To conclude the proof we show
t(1,1)
that if the technology does not exhibits IRS then t(1,1)
t(1,0)  2. Assume that t(1,0) > 2, we
show that the technology exhibits IRS. This is true since

t(1,1)
t(1,0)

> 2 implies:

t(1, 1)  t(1, 0) > t(1, 0)  t(1, 0)  t(0, 0)
365

fiBabaioff, Feldman & Nisan

and as t(1, 0 > t(0, 1) it also holds
t(1, 1)  t(0, 1) > t(1, 1)  t(1, 0)  t(1, 0)  t(0, 1)  t(0, 1)  t(0, 0)
2

which implies IRS.
Lemma C.13 If a  b  0 and x  y > 0 then

a+x
a+y



b+x
b+y .

Appendix D. The Robustness of Mixed Nash Equilibria
Theorem 6.2 If the mixed optimal contract q includes at least two agents that truly mix
(i, j s.t. qi , qj  (0, 1)), then q is not a strong equilibrium.
Proof: Let Q be the support of q (i.e., Q = {i|qi > 0}), and let k = |Q|. Recall that
ci
the optimal payments that induce the strategy prole q are pi = i (q
(where i (qi ) =
i )
t(1, qi )  t(0, qi )) for any i  Q, and pi = 0 for any i  N \ Q. Let  = {i|qi  (0, 1)}
(||  2 by assumption), and consider a deviation of the coalition  into a pure strategy
prole q , in which for any i  , qi = 1. q  denote the new prole (i.e., q  = (q , q )).
We next show that for any i  , ui (q) < ui (q  ), thus q is not resilient to a deviation
by . Since qi  (0, 1), i must be indierent between ai = 0 and ai = 1 (see claim 2.1);
therefore, is utility in q is:
ui (q) = ui (0, qi ) = ci

t(0, qi )
i (qi )

The utility of i in q  is:
ci
ui (q ) = t(q )pi ci = t(q )
ci = ci
i (qi )






(

t(q  )
1
i (qi )

)

(
= ci

t(q  )  t(1, qi ) + t(0, qi )
i (qi )

)

Therefore, ui (q  ) > ui (q) if and only if t(q  )  t(1, qi ) > 0, which holds by the assumption
that ||  2 and the monotonicity of t.
2

Appendix E. Algorithmic Aspects
E.1 Results for the Mixed Case
We next show that in the black box model, exponential number of queries is needed to
determine the optimal mixed contract. We have proved this for the optimal pure contract
(for completeness we present the claim as Theorem E.2, taken from (Babaio et al., 2006a)),
and now show that it also holds for the mixed case.
Theorem 7.1 Given as input a black box for a success function t (when the costs are
identical), and a value v, the number of queries that is needed, in the worst case, to nd the
optimal mixed contract is exponential in n.
Proof: We show that the optimal mixed contract for the technology presented in Theorem E.2 at the value c(k + 1/2) has support exactly T , thus the claim is a direct result of
Theorem E.2.
366

fiMixed Strategies in Combinatorial Agency

Assume that q is optimal mixed contract at the value c(k + 1/2). The support of q must
be of size at most k, otherwise the payment in case of success is at least c(k +1) > c(k +1/2)
(as each agent in the support must be paid at least c), which implies negative utility. If he
support is of size at most k and is not exactly T , then there is at least one agent that is
paid c/ > c(k + 1/2) for suciently small  > 0. Thus in any such case the utility is again
negative.
2
Next we show that for read-one network the optimal mixed contract is #P -hard. It is
based on a theorem from the work of Babaio et al. (2006a) cited as Theorem E.3 below.
Theorem 7.2 The Optimal Mixed Contract Problem for Read Once Networks is #P -hard
(under Turing reductions).
Proof: We use the reduction presented in Theorem E.3. We prove that for x close enough
to 1/2, at the transition point from E to E  {x} of the pure case, the optimal mixed
contract is pure (also E and E  {x}). This implies that we can use the same argument
of Theorem E.3 to calculate the network reliability (which is #P -hard) using an algorithm
for the optimal mixed contract.
Lemma E.1 below presents a generalization of a lemma from the work of Babaio et al.
(2006a) to the mixed case. The lemma implies that at the value v that x is rst entered
to the support of the optimal mixed contract q, the contract for x is optimal for the value
v  t(E). But for a single edge, the only optimal mixed contracts are pure, thus x exerts
eort with probability 1. Additionally, the contract for the original graph (with edges E)
is optimal for the value v  (1  x ), thus for x close enough to 1/2, v is large enough such
that the optimal mixed contract is with all agents exerting eort with probability 1 (pure).
2

Let g and h be two Boolean functions on disjoint inputs and let f = g h (i.e., take
their networks in series). The optimal mixed contract for f for some v, denoted by qS , is
composed of the h-part and the g-part, call them mixed prole for these parts qT and qR
respectively.

Lemma E.1 Let qS be an optimal mixed contract for f = g h on v. Then, qT is an
optimal mixed contract for h on v  tg (qR ), and qR is an optimal mixed contract for g on
v  th (qT ).
The proof is the same as the proof for the pure case, presented in the work of Babaio et al.
(2006b).
E.2 Results from the work of Babaio et al. (2006b) for the Pure Case
The following results are cited from the work of Babaio et al. (2006b), for completeness.
Theorem E.2 Given as input a black box for a success function t (when the costs are
identical), and a value v, the number of queries that is needed, in the worst case, to nd the
optimal contract is exponential in n.
Proof: Consider the following family of technologies. For some small  > 0 and k = n/2
we dene the success probability for a given set T as follows. If |T | < k, then t(T ) = |T |  .
If |T | > k, then t(T ) = 1  (n  |T |)  . For each set of agents T of size k, the technology
tT is dened by t(T ) = 1  (n  |T |)   and t(T ) = |T |   for any T = T of size k.
367

fiBabaioff, Feldman & Nisan

For the value v = c  (k + 1/2), the optimal contract for tT is T (for the contract T the
utility of the principal is about v  c  k = 1/2  c > 0, while for any other contract the utility
is negative).
( n )
 2 sets of size k, then it cannot always
If the algorithm queries about at most n/2
determine the optimal contract (as any
( n of) the sets that it has not queried about might be
the optimal one). We conclude that n/2
 1 queries are needed to determine the optimal
contract, and this is exponential in n.
2
Let t(E) denote the probability of success when each edge succeeds with probability
e . We rst notice that even computing the value t(E) is a hard problem: it is called the
network reliability problem and is known to be #P  hard (Provan & Ball, 1983). Just a
little eort will reveal that our problem is not easier:
Theorem E.3 The Optimal Contract Problem for Read Once Networks is #P -hard (under
Turing reductions).
Proof: We will show that an algorithm for this problem can be used to solve the network
reliability problem. Given an instance of a network reliability problem < G, {e }eE >
(where e denotes es probability of success), we dene an instance of the optimal contract
problem as follows: rst dene a new graph G which is obtained by Anding G with a
new player x, with x very close to 12 and x = 1  x . For the other edges, we let e = e
and e = e /2. By choosing x close enough to 12 , we can make sure that player x will enter
the optimal contract only for very large values of v, after all other agents are contracted (if
we can nd the optimal contract for any value, it is easy to nd a value for which in the
original network the optimal contract is E, by keep doubling the value and asking for the
c
is larger than that
optimal contract. Once we nd such a value, we choose x s.t. 12
x
value). Let us denote x = 1  2x .
The critical value of v where player x enters the optimal contract of G , can be found
using binary search over the algorithm that supposedly nds the optimal contract for any
network and any value. Note that at this critical value v, the principal is indierent between
the set E and E  {x}. Now when we write the expression for this indierence, in terms of
t(E) and ti (E) , we observe the following.
(
t(E)x  v 


iE

c
x  ti (E \ i)

)

(
= t(E)(1x ) v 


iE

c
c

(1  x )  ti (E \ i) t(E)  x

)

if and only if
(1  x )  c
(x )2  v
thus, if we can always nd the optimal contract we are also able to compute the value
of t(E).
2
t(E) =

References
Aumann, R. (1959). Acceptable Points in General Cooperative n-Person Games. In Contributions to the Theory of Games, Vol. 4.
368

fiMixed Strategies in Combinatorial Agency

Babaio, M., Feldman, M., & Nisan, N. (2006a). Combinatorial agency. In ACM EC06,
pp. 1828.
Babaio, M., Feldman, M., & Nisan, N. (2006b). Combinatorial agency. In Full version.
Feldman, M., Chuang, J., Stoica, I., & Shenker, S. (2007). Hidden-Action in Multi-Hop
Routing.. In IEEE JSAC Special Issue on Non-Cooperative Behavior in Networking.
Harsanyi, J. C. (1973). Games with randomly disturbed payos: a new rationale for mixedstrategy equilibrium points. International Journal of Game Theory, 2 (1), 123.
Holmstrom, B. (1982). Moral Hazard in Teams. Bell Journal of Economics, 13, 324340.
Mass-Colell, A., Whinston, M., & Green, J. (1995). Microeconomic Theory. Oxford University Press.
Nisan, N., & Ronen, A. (2001). Algorithmic mechanism design. Games and Economic
Behaviour, 35, 166  196. A preliminary version appeared in STOC 1999.
Nisan, N., Roughgarden, T., Tardos, E., & Vazirani, V. V. (2007). Algorithmic Game
Theory. Cambridge University Press.
Provan, J. S., & Ball, M. O. (1983). The complexity of counting cuts and of computing the
probability that a graph is connected. SIAM J. Comput., 12 (4), 777788.
Strausz, R. (1996). Moral hazard in sequential teams. Departmental Working Paper. Free
University of Berlin.
Winter, E. (2004). Incentives and Discrimination. American Economic Review, 94, 764773.

369

fi