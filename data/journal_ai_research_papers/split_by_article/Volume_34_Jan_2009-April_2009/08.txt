Journal of Artificial Intelligence Research 34 (2009) 675-706

Submitted 11/08; published 04/09

Planning over Chain Causal Graphs for Variables with
Domains of Size 5 Is NP-Hard
Omer Gimenez

omer.gimenez@upc.edu

Dept. de Llenguatges i Sistemes Informatics
Universitat Politecnica de Catalunya
Jordi Girona, 1-3
08034 Barcelona, Spain

Anders Jonsson

anders.jonsson@upf.edu

Dept. of Information and Communication Technologies
Universitat Pompeu Fabra
Roc Boronat, 138
08018 Barcelona, Spain

Abstract
Recently, considerable focus has been given to the problem of determining the boundary
between tractable and intractable planning problems. In this paper, we study the complexity of planning in the class Cn of planning problems, characterized by unary operators and
directed path causal graphs. Although this is one of the simplest forms of causal graphs a
planning problem can have, we show that planning is intractable for Cn (unless P = NP),
even if the domains of state variables have bounded size. In particular, we show that plan
existence for Ckn is NP-hard for k  5 by reduction from Cnf-Sat. Here, k denotes the
upper bound on the size of the state variable domains. Our result reduces the complexity
gap for the class Ckn to cases k = 3 and k = 4 only, since C2n is known to be tractable.

1. Introduction
There is an ongoing effort in the planning community to determine the complexity of different classes of planning problems. Known tractable classes are usually characterized by
a simple causal graph structure accompanied by additional restrictions on variables and
operators. However, the boundary between tractable and intractable planning problems is
still not clearly established. The present paper contributes a novel complexity result for
a class of planning problems with simple causal graph structure from the literature, in an
effort to reduce this complexity gap.
The problem of determining tractable classes of planning problems is not purely of theoretical interest. For instance, complex planning problems can be projected onto tractable
fragments of planning problems to generate heuristics to be used during search (Katz &
Domshlak, 2008b). Also, the causal graph heuristic (Helmert, 2006) exploits the hierarchical structure of a planning problem by transforming it into a more tractable form: first, it
translates propositional variables into multi-valued variables, a process that simplifies the
causal graph of the problem; then, it keeps relaxing the problem until the causal graph
becomes acyclic.
The present paper aims to study the complexity of planning problems in the class Cn ,
defined by Domshlak and Dinitz (2001). The class Cn contains planning problems with
c
2009
AI Access Foundation. All rights reserved.

fiGimenez & Jonsson

Ckn
k=2
k  {3, 4}
k5

Plan generation
P
EXP
EXP

Macro plan generation
P
?
Intractable

Plan existence
P
?
NP-hard

Table 1: Overview of the complexity results for the class Ckn .

multi-valued variables and chain causal graphs, i.e., the causal graph is just a directed path
(implying that operators are unary). The notation n indicates that the number of state
variables is unbounded. In particular, we study the complexity of plan existence for Cn ,
i.e., determining whether or not there exists a plan that solves a planning problem in Cn .
Even though planning problems in Cn exhibit an extremely basic form of causal structure, i.e., linear dependence between state variables, solving planning problems in Cn is not
necessarily tractable, even if we impose additional restrictions. Let Ckn be the subclass of
Cn for which state variables have domains of size at most k. It is known that class C2n is
polynomial-time solvable (Brafman & Domshlak, 2003) and that plan existence for class
Cn is NP-hard (Gimenez & Jonsson, 2008a). Our aim is to study the complexity of plan
existence for those classes in between, namely Ckn for k  3.
Domshlak and Dinitz (2001) showed that there are solvable instances of C3n that require
exponentially long plans. This means that there is no polynomial-time plan generation
algorithm for Ckn with k  3, as was the case for C2n . However, this does not rule out the
existence of a polynomial-time algorithm that determines plan existence for class Ckn , or
even an algorithm that generates plans in some succinct form, like those of Jonsson (2007)
and Gimenez and Jonsson (2008a). This is not incompatible with Cn being NP-hard.
In this paper, we prove that plan existence for the class Ckn is NP-hard for k  5.
In other words, even if the causal graph is a directed path and the domains of the state
variables are restricted to contain no more than 5 values, deciding whether or not a plan
exists for solving the corresponding planning problem is NP-hard. Our result implies that it
is not sufficient for a planning problem to exhibit linear variable dependence and restricted
variable domain sizes; additional restrictions are necessary to make planning tractable.
Table 1 shows an overview of the complexity results for the class Ckn to date. By
Macro plan generation we mean any algorithm for generating a compact representation
of the solution, such as in the work of Jonsson (2007) and Gimenez and Jonsson (2008a).
The Intractable result for this column means that the complexity is yet unknown but
cannot be in P unless P = NP (else plan existence would be in P). The row for k = 2 is due
to Brafman and Domshlak (2003), the column for plan generation is due to Domshlak and
Dinitz (2001), and the contributions of the present paper are marked in boldface. Note that
the novel result subsumes that of Gimenez and Jonsson (2008a), who showed NP-hardness
for k = O(n).
This paper is organized as follows. In Section 2 we relate our results to previous work,
and in Section 3 we introduce the notation used throughout. In Section 4 we give formal
proof of a reduction from Cnf-Sat to planning problems in C11
n . The main result, a
5
reduction from Cnf-Sat to planning problems in Cn , is then proved in Section 5. Although
11
the result for C5n subsumes that for C11
n , we believe that the intuitive idea behind the Cn
676

fiChain Causal Graphs with Domains of Size 5

reduction is easier to understand, and may be of interest for anyone trying to prove hardness
results under similar circumstances. In Section 6 we discuss the complexity of the remaining
classes C3n and C4n .
We also prove the correctness of a third reduction, this time from Cnf-Sat to C7n , in
7
Appendix A. The reductions for C11
n and Cn previously appeared in a conference paper
(Gimenez & Jonsson, 2008b), and the present paper provides formal proof of their correctness.

2. Related Work
The complexity of planning has been studied extensively over the last twenty years (Bylander, 1994; Chapman, 1987; Erol, Nau, & Subrahmanian, 1995). Many tractable classes of
planning problems exploit the notion of a causal graph in one way or another. Knoblock
(1994) is usually credited with introducing the causal graph in his work on hierarchical
planning. Williams and Nayak (1997) required planning problems to have acyclic causal
graphs in an effort to ensure tractability. Jonsson and Backstrom (1998) defined the class
3S of planning problems, also with acyclic causal graphs, and showed that plan existence
is tractable for this class.
Domshlak and Dinitz (2001) introduced the class Cn of planning problems studied in
this paper, as well as several related classes, all of which have a particular causal graph
structure. Brafman and Domshlak (2003) designed a polynomial-time algorithm for solving planning problems with binary state variables and polytree causal graphs of bounded
indegree, proving that planning is tractable for the class C2n . Brafman and Domshlak
(2006) presented complexity results related to the tree-width of the causal graph. Katz
and Domshlak (2008a) used causal graph structure to prove several complexity results for
optimal planning.
Jonsson (2007) and Gimenez and Jonsson (2008a) designed polynomial-time algorithms
that solve planning problems with restricted causal graphs by generating a hierarchy of
macros. Recently, Chen and Gimenez (2008) showed that the complexity of planning is
intractable unless the size of the largest connected component of the causal graph is bounded
by a constant. Consequently, causal graph structure alone is not enough to guarantee
tractability, implying that additional restrictions are needed.

3. Notation
Throughout the paper, we use [i..n] to denote the set {i, . . . , n}.
Let V be a set of state variables, and let D(v) be the finite domain of state variable
v  V . We define a state s as a function on V that maps each state variable v  V to
a value s(v)  D(v) in its domain. A partial state p is a function on a subset Vp  V of
state variables that maps each state variable v  Vp to p(v)  D(v). We frequently use the
notation (v1 = x1 , . . . , vk = xk ) to denote a partial state p defined by Vp = {v1 , . . . , vk } and
p(vi ) = xi for each vi  Vp .
A planning problem is a tuple P = hV, init, goal, Ai, where V is the set of variables, init
is an initial state, goal is a partial goal state, and A is a set of operators. An operator
a = hpre(a); post(a)i  A consists of a partial state pre(a) called the pre-condition and a
677

fiGimenez & Jonsson

v1

v2

v3

v4

v5

Figure 1: Example causal graph of a planning problem in the class Ck5 .
partial state post(a) called the post-condition. Operator a is applicable in any state s such
that s(v) = pre(a)(v) for each v  Vpre(a) , and applying operator a in state s results in a
new state s such that s (v) = post(a)(v) if v  Vpost(a) and s (v) = s(v) otherwise.
A partial plan  for planning problem P is a sequence of operators a1 , . . . , ak  Ak ,
k  0, such that a1 is applicable in the initial state init and, for each i  [2..k], ai is
applicable following the application of a1 , . . . , ai1 starting in init. Note that a partial plan
does not necessarily solve P . A plan  for solving P is a partial plan such that the goal
state goal is satisfied following the application of a1 , . . . , ak . P is solvable if and only if
there exists such a plan .
The causal graph of a planning problem P is a directed graph (V, E) with the state
variables as nodes. There is an edge (u, v)  E if and only if u 6= v and there exists an
operator a  A such that u  Vpre(a)  Vpost(a) and v  Vpost(a) . Figure 1 shows an example
causal graph in the form of a directed path. The structure of the causal graph implies that
each operator a  A is unary, i.e., the post-condition of a is specified on a single variable
v, and the pre-condition of a is specified on (at most) v and its predecessor v  in the causal
graph.
In this paper we study the class Ckn of planning problems, defined as follows:
Definition 3.1. A planning problem P belongs to the class Ckn if and only if the causal
graph of P is a directed path and, for each v  V , |D(v)|  k.
For planning problems in Ckn , the domain transition graph, or DTG, of a state variable
v is a labelled, directed graph (D(v), E  ) with the values in the domain of v as nodes.
There is an edge (x, y)  E  with label l  D(v  ) if and only if there exists an operator
hv  = l, v = x; v = yi in A, where v  is the predecessor of v in the causal graph. An edge
without label indicates that the pre-condition of the corresponding operator is defined on v
alone. An edge with more than one label indicates the existence of multiple operators with
the same pre- and post-condition on v but different pre-conditions on v  .

4. C11
n Is NP-hard
In this section we prove that C11
n is NP-hard by reduction from Cnf-Sat. In other words,
to every CNF formula F we associate a planning instance P11 (F ) of C11
n such that P11 (F )
is solvable if and only if F is satisfiable. We first describe the planning problem P11 (F ),
then explain the intuitive idea behind the reduction, and finally provide formal proof of its
correctness.
Let F = C1      Ck be a CNF formula on k clauses and n variables x1 , . . . , xn . We
define the planning problem P11 (F ) = (V, init, goal, A) as follows. The variable set V is
{si | i  [1..2n  1]}  {vs }  {vij | i  [1..k], j  [1..n]}  {ve }  {ei | i  [1..2n  1]},
with domains D(si ) = D(ei ) = D(ve ) = {0, 1} for i  [1..2n  1], D(vs ) = {0, 1, x}, and
D(vij ) = {gx , g0 , g1 , ax , a0 , a1 , b0 , b1 , cx , c0 , c1 } for i  [1..k], j  [1..n]. The initial state is
defined by init(si ) = init(ei ) = init(ve ) = 0, i  [1..2n  1], init(vs ) = x, and init(vij ) = ax
678

fiChain Causal Graphs with Domains of Size 5

s1

s2n1

vs

v1n

v11

vk1

vkn

ve

e1

e2n1

Figure 2: Causal graph of the planning problem P11 (F ).
0
1
1

0

0
0

1

0
1

1

x
1
0

0 0

1
1

Figure 3: DTGs of the variables s1 , s2 , . . . , s2n1 , vs .
for i  [1..k], j  [1..n], and the goal state is a partial state defined by goal(vin ) = gx for
each i  [1..k], goal(ve ) = 0, and goal(ei ) = (i mod 2) for each i  [1..2n  1].
Before providing a formal definition of the operators in A, we give an intuitive overview
of the planning problem P11 (F ). To do this, we present the causal graph of P11 (F ) as well
as the DTGs of each state variable. A reader who is only interested in the formal proof
of the correctness of the reduction may skip to Section 4.2, where we introduce the formal
definitions of operators in order to prove several theoretical properties of P11 (F ).
4.1 Intuition
The planning problem P11 (F ) associated to each CNF formula F consists of three parts, each
with a clearly defined role. The three parts are illustrated in Figure 2, showing the causal
graph of P11 (F ). The first part of P11 (F ) corresponds to state variables s1 , . . . , s2n1 , vs ,
the second part corresponds to state variables v11 , . . . , v1n , . . . , vk1 , . . . , vkn , and the third
part corresponds to state variables ve , e1 , . . . , e2n1 . The role of the first part is to generate
a message corresponding to an assignment to the variables of the CNF formula F . The
role of the second part is to verify whether this assignment satisfies each clause Ci , and to
remember this fact (using a value of state variable vin ). Finally, the role of the third part
is to make sure that the message is propagated all the way to the end of the chain.
The DTGs of state variables s1 , . . . , s2n1 , vs appear in Figure 3. These state variables
are used to generate an assignment  to the variables x1 , . . . , xn of the CNF formula F . To
do this, the operators of P11 (F ) are defined in such a way that the value of vs can change
from x to either 0 or 1, while from 0 or 1 it can only change back to x. Thus, by applying
the operators of P11 (F ) it is possible to generate a sequence x, m1 , x, . . . , x, mn , x of values
of vs , where mj  {0, 1} for each j  [1..n].
We define a message m as the sequence m1 , . . . , mn of n symbols (either 0 or 1) corresponding to a sequence of values of vs . In what follows, we refer to these symbols as the
bits of the message. The value x is used as a separator to distinguish between consecutive
bits of the message. Given a message m, the assignment  is defined as (xj ) = mj for
each j  [1..n]. Thus, the assignment to x1 is determined by the first choice of whether to
change the value of vs from x to 0 or 1, and so on. The only purpose of the remaining state
variables si of the first part is to restrict the message m to contain no more than n bits.
679

fiGimenez & Jonsson

(a)

(b)
a0

g0

a0

g0

c0

b0

c0

b0
a0,b0,g0

0

0

x
0

gx
1

ax

1

x
cx

x

gx
a1,b1,g1

1

x

ax,cx,gx

a0,b0,g0

x

ax,cx,gx

ax
ax,cx,gx

a0,b0,g0

ax,cx,gx

a1,b1,g1

ax,cx,gx

cx

x
a1,b1,g1

g1

a1

c1

b1

g1

a1

b1

ax,cx,gx
c1

(c)
a0

g0
a0,b0
c0,g0

cx,gx g
0
gx

c1,g1

cx,gx g1

ax

a1,b1
g1

c0

b0
ax,cx

c0

c0

cx

c1

cx

ax,cx
a1

cx

cx

c1
b1

cx
c1

Figure 4: DTGs of (a) v11 , (b) vi1 for i > 1, and (c) vij for j > 1. Dashed edges are
explained in the text.

The DTGs of state variables vij , i  [1..k] and j  [1..n], appear in Figure 4. The
dashed edges in the DTGs indicate that the corresponding operators depend on the CNF
formula F . For example, if the assignment (x1 ) = 1 satisfies the clause C1 , the edge from
v11 = ax with label 1 in Figure 4(a) points to g1 , else it points to b1 . Likewise, if (x1 ) = 0
satisfies C1 , the edge from v11 = ax with label 0 points to g0 , else it points to b0 .
Recall that the role of the second part is to check whether the assignment  generated
by the first part satisfies the CNF formula F . For each clause Ci and each variable xj of
F , the main function of state variable vij is to check whether the assignment (xj ) = mj
satisfies Ci . To do this, state variable vij acts as a finite state automaton that propagates
each bit of the message m while keeping track of when the j-th bit of the message arrives.
Since the domain size of state variables is restricted, there is no way for vij to count the
number of bits it has received. Instead, the fact that the j-th bit has arrived is indicated
to it by vi(j1) . Moreover, the last state variable vin for each clause Ci has to remember
whether or not Ci has been satisfied by the assignment to some variable xj .
In summary, each state variable vij in the second part performs the following functions
through its values and operators:
1. Propagate the message m generated by vs .
2. Check whether the assignment to xj (the j-th bit of m) satisfies the clause Ci .
680

fiChain Causal Graphs with Domains of Size 5

0

0
a0,a1,
b0,b1, 0
g0,g1

ax
cx
gx
1

0
1

1

0

1
1

Figure 5: The domain transition graph of the variables ve , e1 , . . . , e2n1 .
3. Remember whether Ci was satisfied by the assignment to some xl , l  j.
4. If j < n and Ci has been satisfied, propagate this fact.
5. If j < n, let vi(j+1) know when the (j + 1)-th bit of the message has arrived.
Note that the third function is only strictly necessary for j = n. However, including it for
all state variables makes the reduction more compact because of symmetry.
Next, we briefly describe how vij implements each of these functions. Each value in
the domain of vij has subscript 0, 1, or x. To propagate the message, vij always moves
to a value whose subscript matches that of its predecessor (in the case of v11 , its subscript
should match the value of vs ). Unless Ci is satisfied by the assignment to xl , l < j, the
value of vij remains in the subdomain {a0 , a1 , ax } prior to the arrival of the j-th bit.
The clause Ci is encoded into the dashed edges of the DTGs of variables vij . These
operators are such that when the j-th bit mj arrives, vij moves from ax to gmj if the
assignment (xj ) = mj satisfies Ci , and to bmj otherwise. The fact that the value of vij
is in the subdomain {g0 , g1 , gx } indicates that Ci was satisfied by the assignment to some
xl , l  j. This fact is propagated all the way to vin since each subsequent state variable
for Ci is forced to move to a value in the subdomain {g0 , g1 , gx } whenever the value of its
predecessor is in {g0 , g1 , gx }. Whether or not a clause Ci has been satisfied is checked by
defining a goal state vin = gx .
Finally, if j < n and vij moves to bmj , then vi(j+1) moves to amj . From there, vij has
no choice but to move to cx , causing vi(j+1) to return to ax . When the next bit arrives, vij
moves to either c0 or c1 , correctly indicating to vi(j+1) that the (j + 1)-th bit has arrived.
Consequently, vi(j+1) moves to either g0 (g1 ) or b0 (b1 ), depending on whether or not the
assignment to xj+1 satisfies Ci . Hence, the values of type b are used to delay the transition
of vi(j+1) from a value of type a to either b or g. This is the mechanism that allows a
variable vij to react to the j-th bit. For each clause Ci , the operators for vi1 are defined
such that vi1 always reacts to the first bit.
The DTGs of state variables ve , e1 , . . . , e2n1 appear in Figure 5. The function of these
state variables is to make sure that all n bits of the message m are propagated to the end
of the causal graph. A state variable (strictly speaking, a planner solving the planning
problem) is never forced to select an operator, so it can choose not to propagate a bit of the
message and instead wait for the next bit to arrive before acting. In turn, this may cause
another state variable to incorrectly conclude that a clause has (not) been satisfied. The
variables of the third part prevent this from happening, since the goal state is defined in
such a way that it cannot be reached unless all bits of the message arrive at the end of the
causal graph.
681

fiGimenez & Jonsson

Variable
s1
si ,
i  [2..2n  1]
vs

Operator
hs1 = 0; s1 = 1i
hsi1 = 0, si = 0; si = 1i
hsi1 = 1, si = 1; si = 0i
hs2n1 = 0, vs = x; vs = mi
hs2n1 = 1, vs = m; vs = xi

Qualifier

m  {0, 1}
m  {0, 1}

Table 2: Operators for the variables s1 , s2 , . . . , s2n1 , vs .

4.2 Formal Proof
In this section, we prove that C11
n is NP-hard by showing that the planning problem P11 (F )
is solvable if and only if the formula F has a satisfying assignment. To start with, we provide
formal definitions of the operators of P11 (F ). The operators for s1 , . . . , s2n1 , vs appear in
Table 2, and the corresponding DTGs appear in Figure 3. The operators for variables vij ,
i  [1..k] and j  [1..n], appear in Table 3, and the DTGs appear in Figure 4. Finally, the
operators for ve , e1 , . . . , e2n1 appear in Table 4, and the DTGs appear in Figure 5.
To reduce the space requirement we use shorthand in the definitions of operators. In
other words, hv  = m, v = c; v = mi, m  {a, b}, denotes the existence of two operators
hv  = a, v = c; v = ai and hv  = b, v = c; v = bi. Similarly, hv   {a, b}, v = c; v = di denotes
the existence of two operators hv  = a, v = c; v = di and hv  = b, v = c; v = di. For state
variables vij we also introduce reference numbers that allow us to easily refer to operators.
Furthermore, some operators are conditional on properties of the CNF formula F ; such
an operator only exists if the indicated property is satisfied. For example, the operator
hv22 = c0 , v23 = ax ; v23 = g0 i only exists if the clause C2 is satisfied by x3 , and the operator
hv22 = c0 , v23 = ax ; v23 = b0 i only exists if C2 is not satisfied by x3 . We use the set notation
xj  Ci to denote that the literal xj appears in the clause Ci .
The proof is organized as follows. We begin with a series of technical definitions and
lemmas (4.14.6) related to the operators and their implications. Definition 4.7 then introduces the notion of admissible plans, and Lemma 4.8 states that any plan for solving P11 (F )
has to be admissible. Next, Lemma 4.10 establishes that any admissible plan corresponds
to an assignment to the variables of the CNF formula F , and that all operator choices of the
plan are forced given this assignment. Finally, Lemma 4.13 determines the exact sequence
of values taken on by each state variable during the execution of an admissible plan, making
it possible to check whether the goal state is reached at the end of the execution. Theorem
4.14 then concludes that the only admissible plans solving P11 (F ) are those corresponding
to satisfying assignments of F .
Definition 4.1. Given a partial plan  for P11 (F ) and a variable v  V , (v) is the number
of times the value of v is changed by operators in .
Lemma 4.2. For each partial plan  for P11 (F ), it holds that
 (si )  i for i  [1..2n  1], and
 (vs )  2n.
682

fiChain Causal Graphs with Domains of Size 5

Variable
v11

vi1 ,
i  [2..k]

vij ,
i  [1..k],
j  [2..n]

Ref.
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(10)
(11)
(12)
(13)
(14)
(15)
(16)
(17)
(18)
(19)
(20)
(21)

Operator
hvs = 1, v11 = ax ; v11 = g1 i
hvs = 1, v11 = ax ; v11 = b1 i
hvs = 0, v11 = ax ; v11 = g0 i
hvs = 0, v11 = ax ; v11 = b0 i
hvs = m, v11 = cx ; v11 = cm i
hvs = m, v11 = gx ; v11 = gm i
hvs = x, v11 = bm ; v11 = cx i
hvs = x, v11 = cm ; v11 = cx i
hvs = x, v11 = gm ; v11 = gx i
hv(i1)n  {a1 , b1 , g1 }, vi1 = ax ; vi1 = g1 i
hv(i1)n  {a1 , b1 , g1 }, vi1 = ax ; vi1 = b1 i
hv(i1)n  {a0 , b0 , g0 }, vi1 = ax ; vi1 = g0 i
hv(i1)n  {a0 , b0 , g0 }, vi1 = ax ; vi1 = b0 i
hv(i1)n  {am , bm , gm }, vi1 = cx ; vi1 = cm i
hv(i1)n  {am , bm , gm }, vi1 = gx ; vi1 = gm i
hv(i1)n  {ax , cx , gx }, vi1 = bm ; vi1 = cx i
hv(i1)n  {ax , cx , gx }, vi1 = cm ; vi1 = cx i
hv(i1)n  {ax , cx , gx }, vi1 = gm ; vi1 = gx i
hvi(j1) = c1 , vij = ax ; vij = g1 i
hvi(j1) = c1 , vij = ax ; vij = b1 i
hvi(j1) = c0 , vij = ax ; vij = g0 i
hvi(j1) = c0 , vij = ax ; vij = b0 i
hvi(j1)  {am , bm }, vij = ax ; vij = am i
hvi(j1) = gm , vij = ax ; vij = gm i
hvi(j1) = cm , vij = cx ; vij = cm i
hvi(j1)  {cm , gm }, vij = gx ; vij = gm i
hvi(j1)  {ax , cx }, vij = am ; vij = ax i
hvi(j1) = cx , vij = bm ; vij = cx i
hvi(j1) = cx , vij = cm ; vij = cx i
hvi(j1)  {cx , gx }, vij = gm ; vij = gx i

Qualifier
x1  C1
x1 
/ C1
x1  C1
x1 
/ C1
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
x1  Ci
x1 
/ Ci
x1  Ci
x1 
/ Ci
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
xj  Ci
xj 
/ Ci
xj  Ci
xj 
/ Ci
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}

Table 3: Operators for the variables v11 , . . . , vkn .

Variable
ve

hvkn

e1
ei , i  [2..2n  1]

Operator
 {a0 , a1 , b0 , b1 , g0 , g1 }, ve
hvkn  {ax , cx , gx }, ve
hve = 1, e1
hve = 0, e1
hei1 = 1, ei
hei1 = 0, ei

= 0; ve = 1i
= 1; ve = 0i
= 0; e1 = 1i
= 1; e1 = 0i
= 0; ei = 1i
= 1; ei = 0i

Table 4: Operators for the variables ve , e1 , . . . , e2n1 .

683

fiGimenez & Jonsson

Proof. By induction on i. For i = 1, variable s1 can only change once, so (s1 )  1. For
i  [2..2n  1], it follows from inspection of the operators that we cannot change the value
of si twice without changing the value of si1 once in between (the operator for setting si
to 1 has si1 = 0 as a pre-condition, and the operator for resetting si to 0 has si1 = 1
as a pre-condition). Since we can change the value of si once in the initial state without
first changing the value of si1 , it follows that (si )  (si1 ) + 1  (i  1) + 1 = i by
induction. The same argument holds for variable vs and its predecessor s2n1 , so (vs ) 
(s2n1 ) + 1  (2n  1) + 1 = 2n.
Lemma 4.3. For each partial plan  for P11 (F ) and each vij , i  [1..k] and j  [1..n], it
holds that (vij )  (v  ), where v  is the predecessor of vij in the causal graph.
Proof. Just as before, it follows by inspection of the operators that we cannot change the
value of vij twice without changing the value of v  in between. To see this, note that the
subscript of each value in D(vij ) is either x, 0, or 1. An operator for vij either changes
its value from one with subscript x to one with subscript 0 (1), if v  also has a value with
subscript 0 (1), or from one with subscript 0 (1) to one with subscript x, if v  also has a value
with subscript x (the same argument holds for v11 , although the values of its predecessor
vs are x, 0, and 1 without subscripts).
Note that the value of vij cannot change in the initial state without first changing the
value of v  , since v  has to have a value with subscript 0 or 1 for the value of vij to change
from its initial value ax . Consequently, the value of vij cannot change more times than the
value of v  , so (vij )  (v  ) as claimed.
Lemma 4.4. For each vij , i  [1..k] and j  [1..n], and each partial state (v  = x, vij = y),
where v  is the predecessor of vij in the causal graph, there is at most one applicable operator
for changing the value of vij .
Proof. By inspecting the operators it is easy to see that each pair of operators for vij have
different pre-conditions. The only exception to this rule are operators that do not exist
simultaneously due to properties of the CNF formula F (e.g. operators (1) and (2)).
Lemma 4.5. For each partial plan  for P11 (F ), it holds that
 (ve )  (vkn ),
 (e1 )  (ve ), and
 (ei )  (ei1 ) for i  [2..2n  1].
Proof. Let v be a variable among ve , e1 , . . . , e2n1 , and let v  be its predecessor in the causal
graph. As before, we cannot change the value of v twice without changing the value of v 
once in between. If v  {e1 , . . . , e2n1 }, the operator setting v to 1 requires v  = 1, and the
operator resetting v to 0 requires v  = 0. For v = ve , the operator setting v to 1 requires
v  to have a value with subscript 0 or 1, while the operator resetting v to 0 requires v  to
have a value with subscript x. Note that, in either case, we cannot change the value of v in
the initial state without first changing the value of v  . Thus, (v)  (v  ) for each of these
variables, as claimed.
684

fiChain Causal Graphs with Domains of Size 5

We now turn to the problem of finding a plan  that solves P11 (F ).
Lemma 4.6. Let  be a plan that solves P11 (F ). Then
 (ei )  2n  i for i  [1..2n  1], and
 (ve )  2n.
Proof. By descending induction on i. For i = 2n  1, goal(e2n1 ) = 1, so the value of
e2n1 has to change at least once from its initial value init(e2n1 ) = 0, implying (e2n1 ) 
1 = 2n  (2n  1). For i  [1..2n  2], assume that (ei+1 )  2n  (i + 1) holds by
induction. From Lemma 4.5 it follows that (ei )  (ei+1 )  2n  (i + 1). However,
since goal(ei ) 6= goal(ei+1 ) and since  solves P11 (F ), it follows that (ei ) 6= (ei+1 ).
Hence (ei ) > (ei+1 ), from which it follows that (ei )  2n  i, as claimed. The same
argument applies to e1 and its predecessor ve , since goal(ve ) = 0 6= 1 = goal(e1 ), yielding
(ve )  2n.
Definition 4.7. An admissible plan  for planning problem P11 (F ) is a partial plan such
that (si ) = i, (vs ) = (v11 ) = . . . = (vkn ) = (ve ) = 2n, and (ei ) = 2n  i, for each
i  [1..2n  1].
Lemma 4.8. Any plan  that solves P11 (F ) is admissible.
Proof. By Lemmas 4.3 and 4.5 we have that (vs )  (v11 )      (vkn )  (ve ). But,
by Lemmas 4.2 and 4.6, all these values are equal to 2n, since 2n  (vs ) and (ve )  2n.
From the proof of Lemma 4.2 we have that (si )  (si1 ) + 1, i  [2..2n  1], and
(vs )  (s2n1 ) + 1, which together with Lemma 4.2 and (vs ) = 2n implies (si ) = i,
i  [1..2n  1]. From the proof of Lemma 4.6 we have that (ve ) > (e1 ), (ei ) > (ei+1 ),
i  [1..2n  2], and (e2n1 )  1, which together with Lemma 4.6 and (ve ) = 2n implies
(ei ) = 2n  i, i  [1..2n  1].
Please note that the converse of Lemma 4.8 is not true, that is, not all admissible plans
do solve the planning problem P11 (F ).
As a consequence of Lemma 4.8, to find a plan that solves P11 (F ) we only need to
consider admissible plans. In particular, an admissible plan changes the value of variable vs
exactly 2n times, generating a sequence of 2n + 1 values. Note that the value of vs always
changes from x to either 0 or 1, and then back to x.
Definition 4.9. Let  be an admissible plan, and let x, m1 , x, . . . , x, mn , x be the sequence
of 2n + 1 values that variable vs takes on during the execution of , where mj  {0, 1} for
each j  [1..n]. We use m to denote the message m1 , . . . , mn induced by , and we use
 to denote the formula assignment  (xj ) = mj for each j  [1..n].
As it turns out, the operators that are part of an admissible plan  are completely
determined by the message m induced by .
Lemma 4.10. Let  be an admissible plan for P11 (F ) and let m be its induced message.
The operators in  for changing the value of variable vij , i  [1..k] and j  [1..n], as well
as the sequence of values that variable vij takes on during the execution of , are completely
determined by m .
685

fiGimenez & Jonsson

Proof. For each v  {v11 , . . . , vkn }, let v  be its causal graph predecessor. From the proof of
Lemma 4.3 we know that we cannot change the value of v twice without changing the value
of v  in between, and that in the initial state, we have to change the value of v  before we can
change the value of v. From the definition of admissible we know that (v  ) = (v) = 2n.
The only way an admissible plan can change the value of v 2n times without changing the
value of v  more than 2n times is to first change the value of v  , then v, then v  , and so on.
Now, from Lemma 4.4 we know that, given a partial state (v  = x, v = y), there is at
most one applicable operator for changing the value of v. Thus, each time the admissible
plan changes the value of v for some value of v  , there is at most one operator for doing so.
The plan has no choice but to select this operator since it is not allowed to change the value
of v  again before changing the value of v. Consequently, if the sequence of values taken
on by v  is completely determined, the operators for v, as well as the sequence of values
it takes on, are completely determined also. The proof follows by a double induction on i
and j, since the sequence of values taken on by vs (the predecessor of v11 ) is completely
determined by the message m .
It follows from Lemma 4.10 that the only relevant degree of freedom of an admissible
plan  is selecting the elements of the message m , by repeatedly deciding whether to move
to vs = 0 or vs = 1 from vs = x. Once m has been selected, all other operator choices are
forced, else the plan is not admissible. In particular, for each message m there is a unique
state s such that executing any admissible plan starting from init results in s. It remains
to determine whether this unique state matches the goal state.
Remark. Note that Lemma 4.10 does not mention the operator order of an admissible plan.
Indeed, we can change the order of the operators of an admissible plan without making the
plan inadmissible. As an example, let v1 , v2 , and v3 be three consecutive variables in the
causal graph, and let ha11 , a12 , a13 , a21 , a22 , a23 i be a subsequence of operators for changing their
values, such that aji is the j-th operator for changing the value of vi . Then the subsequence
i
ha11 , a12 , a21 , a13 , a22 , a23 i achieves the same result. As long as the partial order haji , aji+1 , aj+1
i
is respected for each i and j, we can change the operator order as we please.
We proceed to determine the sequence of values that variable vij , i  [1..k] and j 
[1..n], takes on during the execution of an admissible plan  with induced message m .
First, we define the satisficing index of clauses, and the sequence of values of a plan.
Definition 4.11. Let  be an admissible plan with induced message m = m. For each
clause Ci , let the satisficing index Ti  [1..n+1] be the smallest number such that  (xTi ) =
mTi satisfies Ci . If no such number exists, Ti = n + 1.
Definition 4.12. Let  be an admissible plan. For each clause Ci and each t  [1..2n + 1],
let the sequence of values Qti () be the vector of n values representing, for each variable
vij , j  [1..n], the t-th value taken on by vij during the execution of .
The following lemma is key to understanding the idea behind the reduction for C11
n , since
it specifies the sequences of values that an admissible plan induces during its execution.
Lemma 4.13. Let  be an assignment to variables x1 , . . . , xn of formula F .
686

fiChain Causal Graphs with Domains of Size 5

1) Existence. There exists an admissible plan  of planning problem P11 (F ) with induced assignment  = .
2) Claim. Let Qti be the sequences of values described in Part 3) of this lemma. All
admissible plans  with  =  have the same sequences of values Qti () = Qti , for
all i  [1..k] and t  [1..2n + 1].
3) Sequence of values. The sequence of values Qti , for i  [1..k] and t  [1..2n + 1],
is as follows.
a) If j < Ti , then
nj

j1

z }| {
c x    cx
Qi2j1 =
2j
Qi = cmj    cmj
2j+1
=
c x    cx
Qi

ax
bmj
cx

z }| {
ax    ax
amj    amj
ax    ax

ax
gmj
gx

z }| {
ax    ax
gmj    gmj
gx    gx

b) If j = Ti , then
nj

j1

Qi2j1
Q2j
i
Q2j+1
i

z }| {
c x    cx
=
= cmj    cmj
=
c x    cx

c) If j > Ti , then
jTi

nj

z }| {
gx    gx
gmj    gmj
gx    gx

z }| {
gx    gx
gmj    gmj
gx    gx

Ti 1

Qi2j1
Q2j
i
Q2j+1
i

z }| {
=
c x    cx
= cmj    cmj
=
c x    cx

gx
gmj
gx

Proof. Before proving the lemma, we must check that the definition of Qti given in Part 3
is consistent. This is necessary due to the overlapping of the statements, namely, for every
odd t other than 1 and 2n + 1, the sequence Qti is defined twice, once as Qi2j1 for j =  2t ,

and another time as Qi2j +1 for j  =  2t . However, these sequences of values are well-defined
 +1
because the definitions of Qi2j1 and Q2j
match for any combination of j and j  = j  1,
i
as shown in the following table.


j

Qi2j +1 = Qi2j1

Case (a)

z }| { z }| {
cx    cx ax    ax

Case (b)

z }| { z }| {
cx    cx ax    ax

Case (c)

z }| { z }| {
cx    cx gx    gx

Case (c)

z }| { z }| {
cx    cx gx    gx

j

j

1 < j < Ti :

Case (a)

j

1 < j = Ti :

Case (a)

Ti 1

j = Ti + 1  n:

Case (b)

Ti 1

Ti + 1 < j  n:

Case (c)

687

nj 

nj 

nTi +1
nTi +1

fiGimenez & Jonsson

Now, we prove Parts 2 and 3 of the lemma. Assume  is an admissible plan with induced
assignment  = . The proof proceeds by a double induction on i and j. In particular,
2j+1
we prove the validity of the three statements of type Qi2j1 , Q2j
, assuming that all
i , Qi


t

statements of type Qi (for any i < i and any t) and that all statements of type Qi2j 1 , Q2j
i

and Qi2j +1 (for any j  < j) already hold. We first prove the validity of Qi2j1 . For j = 1,
Qi2j1 = Q1i = ax    ax in Cases (a) and (b) corresponds to the initial state of vi1 , . . . , vin
(note that Case (c) cannot hold for j = 1). When j > 1 we know that, since the statements

are consistent, Qi2j1 = Qi2j +1 for j  = j  1, hence the correctness of Qi2j1 follows by
induction on j.
2j+1
Next, we prove the statements relative to Q2j
. Consider the variable v  that
i and Qi
precedes vi1 in the causal graph, and values number 2j  1, 2j, and 2j + 1 it takes on
during the execution of . If i = 1, then v  = vs and the values are x, mj , x. If i > 1,
then v  = v(i1)n and, by induction on i, the values are ax , amj , ax if j < Ti1 and j < n;
ax , bmj , cx if j = n < Ti1 ; ax , gmj , gx if j = Ti1 ; or gx , gmj , gx if j > Ti1 .
The proof is divided into 6 parts, depending on the values of j and Ti .
I) 1 = j < Ti . Consider the following table, where we write m instead of mj = m1 to
simplify the notation.
v
vi1
2j  1
{x, ax , gx }
ax
{m, am , bm , gm } 
2j
2j + 1 {x, ax , cx , gx }


vi2
ax








vin
ax



The three rows of the table correspond to values number 2j  1, 2j, and 2j + 1 of
variables v  , vi1 , . . . , vin . The first column corresponds to the possible values that the
predecessor v  of vi1 can take on. The first row is given by Qi2j1 , while the second
2j+1
and third rows, to be filled, correspond to Q2j
.
i and Qi
Let A2j be the operator causing the 2j-th value of vi1 . According to the previous
table, the pre-condition of A2j must be compatible with
hv   {m1 , am1 , bm1 , gm1 }, vi1 = ax i
that is, the values of variables v  and vi1 when A2j is applied. Since Ti > 1,  (x1 ) =
m1 does not satisfy clause Ci , so the operator A2j must be one of those labelled (2)
and (4) in Table 3. (Only one of these operators is applicable, depending on the value
of m1 and whether v  is vs or v(i1)n .) In either case, the application of A2j causes
the value of vi1 to become bm1 , so we can fill in a blank in the previous table.
v
vi1
vi2
2j  1
{x, ax , gx }
ax
ax
2j
{m, am , bm , gm } bm (2, 4) 
2j + 1 {x, ax , cx , gx }








vin
ax



In the same way, we can check that A2j+1 , the operator causing the (2j + 1)-th value
of vi1 , must be one of those labelled (7) in Table 3; the new value of vi1 is cx . As for
688

fiChain Causal Graphs with Domains of Size 5

the remaining variables, it is easy to check that variables vi2 , . . . , vin become am1 , due
to operators of type (14), and then become ax , due to operators of type (18). The
table is now complete:
v
vi1
vi2    vin
2j  1
{x, ax , gx }
ax
ax    ax
2j
{m, am , bm , gm } bm (2, 4) am    am (14)
2j + 1 {x, ax , cx , gx }
cx (7)
ax    ax (18)
This shows that Case (a) of Lemma 4.13 holds when j = 1 and Ti > 1.
II) 1 = j = Ti . The proof is similar to that of Case (I). Since Ti = 1,  (x1 ) = m1
satisfies clause Ci . As a result, the admissible operators for causing the 2j-th value
of vi1 are now those labelled (1) and (3). In either case, the value of vi1 becomes gm1 .
Consequently, the admissible operators for vi2 , . . . , vin are different from before. This
is the resulting table:
v
vi1
vi2    vin
2j  1
{x, ax , gx }
ax
ax    ax
2j
{m, am , bm , gm } gm (1, 3) gm    gm (15)
2j + 1 {x, ax , cx , gx }
gx (9)
gx    gx (21)
III) 1 < j < Ti . In this case, as in the remaining ones, we just show the resulting table.
We always write m = mj . In what follows, we omit the column for v  since its possible
values are always the same.
vi1
vi2    vi(j1)
vij
vi(j+1)    vin
2j  1 cx
c x    cx
ax
ax    ax
cm (5)
cm    cm (16) bm (11, 13)
am    am (14)
2j
2j + 1 cx (8)
cx    cx (20) cx (19)
ax    ax (18)
IV) 1 < j = Ti .
vi1
vi2    vi(j1)
vij
vi(j+1)    vin
2j  1 cx
c x    cx
ax
ax    ax
cm (5)
cm    cm (16) gm (10, 12)
gm    gm (15)
2j
2j + 1 cx (8)
cx    cx (20) gx (21)
gx    gx (21)
V) 1 = Ti < j.
vi1
vi2    vin
2j  1 gx
gx    gx
2j
gm (6) gm    gm (17)
2j + 1 gx (9) gx    gx (21)
VI) 1 < Ti < j.
vi1
vi2    vi(Ti 1)
viTi    vin
2j  1 cx
c x    cx
gx    gx
2j
cm (5)
cm    cm (16) gm    gm (17)
cx    cx (20) gx    gx (21)
2j + 1 cx (8)
689

fiGimenez & Jonsson

It just remains to check that Case (a) of Lemma 4.13 follows from parts (I) and (III),
Case (b) from parts (II) and (IV), and Case (c) from parts (V) and (VI). This proves Part
2 and 3 of the lemma.
Finally, note that the existence of an admissible plan  directly follows from the previous
discussion, since we have always specified which operators should be used in every situation,
and not just assumed their existence. This proves Part 1 of the lemma.
Theorem 4.14. There exists a plan that solves the planning problem P11 (F ) if and only if
there exists an assignment  that satisfies the CNF formula F .
Proof. : Given an assignment  that satisfies F , construct an admissible plan  whose
induced formula assignment  equals , by choosing the sequence of values of vs accordingly. It follows that Ti  n for each clause Ci , since there exists a variable xj such that
 (xj ) = mj satisfies Ci . Then, Q2n+1
has the form indicated in Case (b) or (c) of Lemma
i
4.13. In either case, the (2n + 1)-th value of variable vin is gx , as required by the goal state.
The plan  thus solves P11 (F ).
: Let  be a plan that solves the planning problem P11 (F ). By Lemma 4.8 the plan 
is admissible. We show by contradiction that  =  satisfies F . Assume not. Then there
exists a clause Ci not satisfied by , implying Ti = n + 1. Since n < Ti , the (2n + 1)-th
value of variable vin is cx according to Case (a) of Lemma 4.13. This contradicts  solving
P11 (F ), since the goal value of vin is not cx but gx .
Proposition 4.15. Plan existence for C11
n is NP-hard.
Proof. The largest variable domains of the planning problem P11 (F ) are those of variables
v11 , . . . , vkn , which contain 11 values. The proof follows immediately from the well-known
NP-hardness of Cnf-Sat, Theorem 4.14, and the fact that we can produce the planning
problem P11 (F ) in polynomial time given the CNF formula F .
4.3 Example
We illustrate the reduction using a small example CNF formula F = (x1  x2 ) on one
clause and two variables x1 and x2 . The variable set of the corresponding planning problem
P11 (F ) is V = {s1 , s2 , s3 , vs , v11 , v12 , ve , e1 , e2 , e3 }. An admissible plan  can induce any of
four different messages (0, 0), (0, 1), (1, 0), and (1, 1). Only the message (0, 0) corresponds
to an assignment that does not satisfy F . A plan  that solves P11 (F ) with induced
message (0, 1) appears in Table 5. Note that, following execution of the plan, the goal state
goal = (v12 = gx , ve = 0, e1 = 1, e2 = 0, e3 = 1) is satisfied as desired; the last value change
of each variable appearing in the goal state is marked using boldface.

5. C5n Is NP-hard
In this section, we describe a reduction from Cnf-Sat to C5n . To each CNF formula F we
associate a planning problem P5 (F ). For each clause Ci and variable xj of F , P5 (F ) contains
1 , with domain D(v 1 ) = {a , a , a , b }, and v 2 , with domain D(v 2 ) =
two state variables vij
x 0 1 x
ij
ij
ij
2 , so D(v 2 ) = {a , b , b }. The
{ax , a0 , a1 , b0 , b1 }. The values a0 and a1 are omitted for vin
x 0 1
in
690

fiChain Causal Graphs with Domains of Size 5

..
.
hs1 = 0, s2 = 0; s2 = 1i
hs2 = 1, s3 = 1; s3 = 0i
hs3 = 0, vs = x; vs = 1i
hvs = 1, v11 = cx ; v11 = c1 i
hv11 = c1 , v12 = ax ; v12 = g1 i
hv12 = g1 , ve = 0; ve = 1i
hve = 1, e1 = 0; e1 = 1i
hs1 = 0; s1 = 1i
hs1 = 1, s2 = 1; s2 = 0i
hs2 = 0, s3 = 0; s3 = 1i
hs3 = 1, vs = 1; vs = xi
hvs = x, v11 = c1 ; v11 = cx i
hv11 = cx , v12 = g1 ; v12 = gx i
hv12 = gx , ve = 1; ve = 0i

hs3 = 0, vs = x; vs = 0i
hvs = 0, v11 = ax ; v11 = b0 i
hv11 = b0 , v12 = ax ; v12 = a0 i
hv12 = a0 , ve = 0; ve = 1i
hve = 1, e1 = 0; e1 = 1i
he1 = 1, e2 = 0; e2 = 1i
he2 = 1, e3 = 0; e3 = 1i
hs2 = 0, s3 = 0; s3 = 1i
hs3 = 1, vs = 0; vs = xi
hvs = x, v11 = b0 ; v11 = cx i
hv11 = cx , v12 = a0 ; v12 = ax i
hv12 = ax , ve = 1; ve = 0i
hve = 0, e1 = 1; e1 = 0i
he1 = 0, e2 = 1; e2 = 0i
..
.

Table 5: A plan that solves the planning problem P11 (F ) for the example formula F .
(a)

(b)

(c)

(d)

a0

a0

a0

a0
a0

x

0

b0

x

ax

bx

ax

x

x

b1

ax

ax b0

ax

ax b1

bx
ax

ax
a1

1

ax a0

ax

a1

ax bx

ax

ax
a1

a1

b0
a0

ax
a0

bx

ax

(e)
b0
ax bx

a1

ax a1
a1

ax bx
b1

ax bx

a1
b1

1 , (b) v 1 , i > 1, (c) v 1 , j > 1, (d) v 2 , j < n, (e) v 2 .
Figure 6: DTGs of (a) v11
i1
ij
ij
in

state variables s1 , . . . , s2n1 , vs , ve , e1 , . . . , e2n1 , as well as their domains and corresponding
2 .
operators, are the same as before, except the predecessor of ve is now vkn
1 ) = init(v 2 ) = a , i  [1..k] and
The initial state on the new state variables is init(vij
x
ij
1
j  [1..n], and the goal state is goal(vi1 ) = ax , i  [1..k]. Table 6 lists the operators for
1 and v 2 , i  [1..k] and j  [1..n], and Figure 6 shows the corresponding DTGs.
variables vij
ij
Table 6 also lists the new operators for variable ve , which have different pre-conditions now
2 .
that the predecessor of ve is vkn
5.1 Intuition
The reduction for C5n is based on the following idea: instead of using an explicit value to
remember that a clause has been satisfied, the goal is to remain in the initial value ax .
This way we were able to reduce the size of the variable domains needed for the reduction.
Somewhat surprisingly, the new reduction uses fewer total operators than that for C11
n .
691

fiGimenez & Jonsson

Variable
1
v11

1,
vi1
i  [2..k]
1,
vij
i  [1..k],
j  [2..n]
2,
vij
i  [1..k],
j  [1..n  1]

2 ,
vin
i  [1..k]

ve

Ref.
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(10)
(11)
(12)
(13)
(14)
(15)
(16)
(17)
(18)
(19)
(20)
(21)
(22)

Operator
1 = a ; v1 = a i
hvs = m, v11
x 11
m
1 = a ; v1 = a i
hvs = x, v11
m 11
x
1 = a ; v1 = b i
hvs = x, v11
m 11
x
1 = a ; v1 = a i
2
= bm , vi1
hv(i1)n
x i1
m
2
1 = a ; v1 = a i
hv(i1)n
= ax , vi1
x
m i1
2
1 = a ; v1 = b i
hv(i1)n
= ax , vi1
m i1
x
1 = a ; v1 = a i
2
= am , vij
hvi(j1)
m
x ij
2
1 = a ; v1 = a i
hvi(j1)
= ax , vij
m ij
x
1 = b ; v1 = a i
2
= bm , vij
hvi(j1)
m
x ij
1
1
2
hvi(j1) = ax , vij = am ; vij = bx i
1 = a , v2 = a ; v2 = a i
hvij
m
x ij
m ij
1 = a , v2 = a ; v2 = a i
hvij
x
x ij
m ij
2
2
1
hvij = am , vij = ax ; vij = bm i
1 = a , v2 = b ; v2 = a i
hvij
x
x ij
1 ij
1 = b , v2 = b ; v2 = a i
hvij
x ij
1 ij
x
1 = a , v2 = b ; v2 = a i
hvij
x ij
0 ij
x
1 = b , v2 = b ; v2 = a i
hvij
x ij
0 ij
x
1 = a , v2 = a ; v2 = b i
hvin
m
x in
m in
1 = a , v2 = b ; v2 = a i
hvin
x in
1 in
x
1 = b , v2 = b ; v2 = a i
hvin
x
1 in
x in
1 = a , v2 = b ; v2 = a i
hvin
x
x in
0 in
1 = b , v2 = b ; v2 = a i
hvin
x
0 in
x in
2 = b , v = 0; v = 1i
hvkn
m e
e
2 = a , v = 1; v = 0i
hvkn
x e
e

Qualifier
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
xnj+1  Ci
xnj+1 
/ Ci
xnj+1  Ci
xnj+1 
/ Ci
m  {0, 1}
x1  Ci
x1 
/ Ci
x1  Ci
x1 
/ Ci
m  {0, 1}

1 , v 2 , and v , i  [1..k] and j  [1..n].
Table 6: Operators for variables vij
e
ij

692

fiChain Causal Graphs with Domains of Size 5

Our reduction for C5n also uses another new idea. In the reduction for C11
n , information
was propagated forward, i.e., variable vij changed its value according to the value of its
predecessor vi(j1) . The reduction for C5n , however, is constructed such that some information is propagated forward (in particular, the bits of the message) but other information
is propagated backwards (the index of the bit we are currently checking). The planning
problem is arranged such that a variable v may have several applicable operators, but only
one of them satisfies the pre-condition of an applicable action for its successor v  . The result
is that the value of v at time t + 1 depends on the value of v  at time t.
We explain the planning problem P5 (F ) in a bit more detail. Due to the backward
propagation mechanism, the bits of the message are checked in reverse order. In other
words, vin now checks the first bit, vi(n1) checks the second bit, and vi1 checks the n-th
2 is to check whether the (n  j + 1)-th bit satisfies the clause C ,
bit. The purpose of vij
i
1 is to inform v 2
whereas the purpose of vij
that
the
(n

j
+
2)-th
bit
has
arrived.
i(j1)
1 also keeps track of whether C has been satisfied after the first (n  j + 1)
Implicitly, vij
i
bits.
Assume without loss of generality that the message is 0    0. Let us see what happens
if the corresponding assignment does not satisfy the clause Ci . Upon arrival of the first bit,
2 has to move to b . This requires v 1 = a as a pre-condition, which in
state variable vin
0
0
in
l , j  [1..n  1] and l  {1, 2}, to be in a . Next, v 2 has
turn requires state variables vij
0
in
1 = b . In turn, this requires state
to move back to ax , which requires the pre-condition vin
x
l , j  [1..n  1] and l  {1, 2}, to be in a . When v 1 moves again it is from b
variables vij
x
x
in
2
to a0 , requiring vi(n1) = b0 as a pre-condition.
1 is in b following the (nj +1)We see that, as long as the clause remains unsatisfied, vij
x
1 is in b following the last bit. Assume now that the
th bit. In particular, this means vi1
x
2 moves from b to a , this requires v 1 to
(n  j + 1)-th bit satisfies clause Ci . When vij
0
x
ij
1
move to ax instead of bx . From there, there is no way for vi(j1)
to be in bx following the
1 will be in a following the last bit, satisfying the goal
(n  j + 2)-th bit. In particular, vi1
x
state.
5.2 Formal Proof
The proof for C5n is organized much in the same way as that for C11
n . Note that variables
s1 , . . . , s2n1 , vs , ve , e1 , . . . , e2n1 are the same as before, so Lemmas 4.2 and 4.6 still apply
to P5 (F ). It is easy to check that Lemmas 4.3, 4.5 and 4.8 also hold for P5 (F ). However,
Lemma 4.4 no longer holds, since several operators share the same preconditions, namely
operators (2) and (3), (5) and (6), (8) and (10), and (11) and (13). In spite of this, the
operators and sequences of values of an admissible plan  are completely determined by its
induced message m , just as for P11 (F ) (as shown in Lemma 4.10):
Lemma 5.1. Let  be an admissible plan for P5 (F ) and let m be its induced message. The
l , i  [1..k], j  [1..n], and l  {1, 2},
operators in  for changing the value of variable vij
l takes on during the execution of , are
as well as the sequence of values that variable vij
completely determined by m .
1 , and assume without loss of generality that its value is a .
Proof. First consider variable v11
0
1 , namely (2), changing its value to
Given (vs = x), there are two applicable operators for v11

693

fiGimenez & Jonsson

ax , and (3), changing its value to bx . At first sight, an admissible plan  can choose either.
2 in between each pair of
However, for  to be admissible, it has to change the value of v11
1 . Note that when v 1 = a , v 2 can have either of two values, namely
value changes for v11
0
11
11
2 is a , the only admissible operator for v 2 is (12), which has
a0 or b0 . If the value of v11
0
11
1 = a . Thus, if  changes the value of v 1 to b it is no longer admissible,
pre-condition v11
x
x
11
2 is b , the correct choice depends on the
so it has to choose operator (2). If the value of v11
0
2 is (16) with
CNF formula F . If xn satisfies clause C1 , the only admissible operator for v11
1 = a , so  should choose operator (2). Otherwise, the only admissible
pre-condition v11
x
2
1 = b , so  should choose operator (3). In
operator for v11 is (17) with pre-condition is v11
x
2 .
1
either case, the operator choice for v11 is forced given the value of v11
1 , i  [2..k], v 1 , i  [1..k] and j  [2..k],
The same reasoning applies to variables vi1
ij
2 , i  [1..k] and j  [1..n  1], and the corresponding operators that share the same
and vij
pre-conditions. The only degree of freedom of an admissible plan is selecting its induced
message m by choosing the operators for vs accordingly. The remaining operator choices
and, consequently, sequences of values are completely determined by the induced message
m .
We now prove a lemma similar to Lemma 4.13, establishing the sequence of values taken
on by state variables in P5 (F ) during the execution of an admissible plan.
Definition 5.2. Let  be an admissible plan for P5 (F ). For each clause Ci and each
t  [1..2n + 1], let the sequence of values Qti () be the vector of 2n elements representing,
l , j  [1..n] and l  {1, 2}, the t-th value taken on by variable v l during
for each variable vij
ij
l ]. We define the diagonal value
the execution of . Let us denote this value by Qt ()[vij
1
qji (), for i  [1..k] and j  [1..n], as the value Q2j+1 ()[vi(nj+1)
].
Lemma 5.3. Let  be an assignment to variables x1 , . . . , xn of formula F .
1) Existence. There exists an admissible plan  of planning problem P5 (F ) with induced
assignment  = .
2) Claim. Let qji be as described in Part 3) of this lemma. All admissible plans  with
 =  have the same diagonal values qji () = qji for each i  [1..k] and j  [1..n].
3) Diagonal values. The diagonal values qji , for i  [1..k] and j  [1..n], are as
follows.
a) If j < Ti , then qji = bx .
b) If j  Ti , then qji = ax .
Proof. Note that, according to Lemma 5.1, not only the diagonal values qji (), but also the
full sequences of values Qti (), are completely determined for an admissible plan . We
have to prove, then, that admissible plans exist for any assignment , as claimed in Part 1,
and that the diagonal values match the expression given in Part 3. We prove these two facts
by doing a careful, general analysis of the planning problem P5 (F ), and then explaining
how this analysis implies the lemma. Incidentally, the sequences of values Qti () can also
694

fiChain Causal Graphs with Domains of Size 5

be obtained from our analysis; we do not study them because they are not important for
our purposes.
l be some variable of P (F ). Clearly, the
Let  be an admissible plan, and let v = vij
5
t
subscript of the t-th value Q ()[v] that v takes on depends on the parity of t, since all
operators affecting v change its subscript from x to m = {0, 1} and from there back to x.
Namely, the subscript of Qt ()[v] is x if t = 2p  1, and m if t = 2p, where m is the p-th
bit of the message m .
1,
Now, for some j  [2..n  1] and i  [1..k], consider the t-th values that variables vij
2 , v1
vij
i(j+1) take on, for t = 2p  1, 2p, 2p + 1. The previous observation on the subscripts
implies that we (trivially) know something about these values.
1 ] Qt ()[v 2 ] Qt ()[v 1
Qt ()[vij
ij
i(j+1) ]
t = 2p  1 {ax , bx }
ax
{ax , bx }
t = 2p
am
{am , bm }
am
t = 2p + 1 {ax , bx }
ax
{ax , bx }
1
] affects the other values on the diagonal,
We study how the value Q2p1 ()[vi(j+1)
2p1
1
2p+1
1
2p
2
()[vi(j+1)
] = ax , then we can check there
()[vij ]. If Q
namely Q ()[vij ] and Q
is only one possible outcome.
1
2]
1]
Rule I
]
Qt ()[vi(j+1)
Qt ()[vij
Qt ()[vij
t = 2p  1 {ax , bx }
ax
ax
t = 2p
am
am
(11)
am
(7)
t = 2p + 1
ax
(8)
ax
(12)
{ax , bx }

That is, a value of type ax is propagated along the diagonal to another value ax . We
call this Propagation Rule I.
1
] = bx . In this
Now we study which are the possible outcomes when Q2p1 ()[vi(j+1)
2p
2
2p+1
1
case, the other values Q ()[vij ] and Q
()[vij ] on the diagonal depend on whether
the p-th bit m of the message m is such that clause Ci is satisfied by xnj+1 = m (c.f.
operators (14)(17) and (18)(22) in Table 6). If Ci is satisfied by xnj+1 = m, it follows
that these values must be bm and ax . This is Propagation Rule II.
1]
2]
1
Rule II
Qt ()[vij
Qt ()[vij
Qt ()[vi(j+1)
]
t = 2p  1 {ax , bx }
ax
bx
am
bm
(13)
am
(9)
t = 2p
t = 2p + 1
ax
(8)
ax
(14, 16)
{ax , bx }

On the contrary, if clause Ci is not satisfied, then these values must be bm and bx . We
call this Propagation Rule III.
1
2]
1]
Rule III Qt ()[vij
Qt ()[vi(j+1)
]
Qt ()[vij
t = 2p  1 {ax , bx }
ax
bx
t = 2p
am
bm
(13)
am
(9)
t = 2p + 1
bx
(10)
ax
(15, 17)
{ax , bx }

695

fiGimenez & Jonsson

Finally, let us consider the cases j = 1 and j = n, which have not been treated in the
2 do not have values of type a . Also note that
previous analysis. Note that variables vin
m
1 cannot take on value b at time t < 2n + 1, for then it cannot change further,
variables vi1
x
since the pre-conditions of operators (1)(3), if i = 1, or (4)(6), if i  [2..k], are not
1 = b . Thus, the only possible outcome for these two variables when
compatible with vi1
x
p < n is the following.
1
2 ]
1 ]
]
Qt ()[v(i+1)1
Qt ()[vin
Qt ()[vin
t = 2p  1 {ax , bx }
ax
ax
t = 2p
am
bm
(18)
am
(4)
ax
(19, 21; 20, 22)
ax
(5)
t = 2p + 1 {ax , bx } (8; 10)
1
] can be either ax or bx , using operators
Note that, when p = n, the value Q2p+1 ()[v(i+1)1
1 , where
(5) and (6). The reader can check that a similar analysis applies to variable v11
operators (1)(3) take the role of operators (4)(6).
Let us summarize the previous analysis in the following table.

t=1
t=2
t=3
t=4
..
.

1
2
1
vi1
vi1
vi2

ax ax ax   
am
ax
am
..
.

t = 2n  2 am
t = 2n  1 ax
t = 2n
am
t = 2n + 1 





1 v2
2
1
vin
vi(n1)
vi(n1)
in
ax
ax ax ax
bm
ax
bm
..
.



bm
ax
bm
 ax

The first row in the previous table contains the initial state of the planning problem: all
variables are set to ax . The leftmost column and the rightmost column contain the values
1 and v 2 . Then, the values b of the right column are propagated
taken on by variables vi1
m
in
along the diagonals using the three propagation rules already discussed: a value of type a
yields more values of type a according to Rule I; a value of type b yields a value of type
a if the clause is satisfied by Rule II, and of type b if it is not satisfied, by Rule III. The
same applies when propagating the values of the first row: since they are all of type a, all
values of the top-left triangle are of type a, according to Rule I. Note also that the longest
diagonal coincides with the diagonal values qji of Definition 5.2.
After this discussion we proceed to prove the lemma. Let  be an assignment of formula
F . The existence of a plan  with  =  is implied from the analysis already done on the
l ], since we have shown which operators can be used in each case to produce
values Qt [vij
the actual changes of value.
1 ],
Finally, consider the diagonal values qji () for j = 1, . . . , n, that is, the values Q3 ()[vin
5
1
2n+1
1
Q ()[vi(n1) ], . . ., Q
()[vi1 ]. Let j < Ti as in Case (a), that is, the first j bits of the
message m , when assigned to variables x1 , . . . , xj , do not satisfy clause Ci . Consequently,
i
2j+1 ()[v 1
1 ], q i = Q5 ()[v 1
the diagonal values q1i = Q3 ()[vin
2
i(n+1j) ] must
i(n1) ], . . ., qj = Q
696

fiChain Causal Graphs with Domains of Size 5

all be bx , according to Rule III. On the contrary, if we assume j  Ti as in Case (b), then
it follows that qpi = bx for p < Ti due to Rule III, that qpi = ax for p = Ti due to Rule II,
and that qpi = ax for j  p > Ti due to Rule I.
Theorem 5.4. There exists a valid plan for solving the planning problem P5 (F ) if and only
if there exists an assignment  that satisfies the CNF formula F .
Proof. : By Lemma 5.3, the existence of an assignment  that satisfies F implies that all
admissible plans  with  =  satisfy qji () = qji . Since Ti  n for all i  [1..k], it follows
that qni = ax , as required by the goal state of P5 (F ). The plan  thus solves P5 (F ).
: Let  be a plan solving the planning problem P5 (F ). Since Lemma 4.8 holds
for P5 (F ), the plan  is admissible. We show by contradiction that  =  satisfies F .
Assume not. Then there exists a clause Ci not satisfied by . Thus, Lemma 5.3 implies that
1 following the execution of  is b .
qji () = bx for all j  [1..n]. In particular, the value of vi1
x
1)=a .
This contradicts  solving P5 (F ), since bx is different from the goal state goal(vi1
x
Proposition 5.5. Plan existence for C5n is NP-hard.
Proof. The largest variable domains of the planning problem P5 (F ) are those of variables
2 , i  [1..k] and j  [1..n  1], which contain 5 values. The proof follows immediately
vij
from the NP-hardness of Cnf-Sat, Theorem 5.4, and the fact that we can produce the
planning problem P5 (F ) in polynomial time given the CNF formula F .

6. Discussion
In this paper, we have shown that the problem of determining whether a solution plan exists
for planning problems in the class Ckn is NP-hard whenever k  5. In contrast, Brafman
and Domshlak (2003) developed a polynomial-time algorithm for generating plans that solve
planning problems in the class C2n . What can be said about the intermediate cases, namely
Ckn for k  {3, 4}? In what follows, we sketch some arguments for and against tractability
of these cases. Although the discussion is mostly based on intuition gained from studying
these classes, it might prove helpful for someone trying to determine their complexity.
On one hand, it seems likely to us that plan existence for C4n is also NP-hard. Our
reduction for C5n only uses one type of state variable whose domain is larger than 4, namely
2 . Finding a reduction for C4 seems possible, although it will likely be difficult since the
vij
n
available options become increasingly restricted as the state variable domains get smaller.
In particular, we tried but failed to find a reduction for C4n .
Domshlak and Dinitz (2001) showed that there exist planning problems in C3n with
exponential length minimal solutions. Although this often indicates that a planning class
is difficult, it does not imply that plan existence is intractable. This is exemplified by
Jonsson and Backstrom (1998) who define a class of planning problems with exponential
length minimal solutions but where plan existence could be checked in polynomial time.
The present authors (Gimenez & Jonsson, 2008a) showed that even plan generation for
this particular class could be done in polynomial time, if the resulting plans are given in a
compact format such as macros.
A second argument in favor of the hardness of C3n is that there may be multiple ways
to transition between two values of a variable. For example, consider a planning problem
697

fiGimenez & Jonsson

such that there are two actions for changing the value of a variable v from 0 to 1, namely
a = hv  = 0, v = 0; v = 1i and a = hv  = 1, v = 0; v = 1i. Since variables can have 3 values,
it is possible that neither v  = 0 nor v  = 1 hold in the current state. A planner would
thus have to choose whether to satisfy v  = 0 or v  = 1. In contrast, for C2n the same two
actions could be replaced by a single action hv = 0; v = 1i since one of a and a is always
applicable. As a consequence, even if the minimal plan length is bounded for a planning
problem in C3n , there may be exponentially many plans of that length (in fact, this is the
main idea behind our reductions).
Another observation regards the number of possible domain transition graphs for each
state variable. For each k  2, it is possible to show that a state variable in Ckn may have
2
2k (k1) distinct domain transition graphs. In other words, the number of graphs grows
exponentially in k. In particular, while state variables in C2n can only have 24 = 16 distinct
graphs, the same number for C3n is 218 . Although a large number of possibilities does not
guarantee hardness, it is clear that the expressive power of C3n is much higher than that of
C2n .
The evidence provided above suggests that C3n is significantly harder than C2n . However,
we are not sure that C3n is hard enough to be intractable. State variables with just three
values do not lend themselves well to the type of reduction we have presented, since just
propagating the message requires three values. If there is such a reduction for C3n , the idea
underlying it may not be the message-passing mechanism we have exploited. On the other
hand, maybe there is some way to determine plan existence of C3n in polynomial time. Such
an algorithm would take into consideration the multiple (but finite) combinations of domain
transition graphs of three values, as well as any inherent structure of the graphs. We know
that the expressive power of domain transition graphs of 5 values is just too large to handle
in polynomial time; maybe this is not the case when using just 3 values.

Acknowledgments
This work was partially funded by APIDIS and MEC grant TIN2006-15387-C03-03.

Appendix A. C7n Is NP-hard
In this appendix, we describe how to modify the reduction for C11
n so that the resulting
planning problem, which we call P7 (F ), only needs variable domains of size 7. This reduction previously appeared in a conference paper (Gimenez & Jonsson, 2008b), but without
proof. The main idea of the reduction is the same, but the construction used to check
if the assignment  satisfies a clause Ci is more involved. Previously, we used n variables {vij }j[1 . . n] whose role was, essentially, to check whether the j-th bit  (xj ) of the
propagated message satisfies Ci . In the modified reduction, each variable vij is replaced
1 , v 2 , and v 3 , that collectively play the same role. The variables
by three variables vij
ij
ij
s1 , . . . , s2n1 , vs , ve , e1 , . . . , e2n1 , as well as their domains and corresponding operators, are
3 .
the same as before, except the predecessor of ve is now vkn
1 ) = D(v 3 ) = {a , a , a , b , b , b , g } and
The domains of these new variables are D(vij
x 0 1 x 0 1 x
ij
2
D(vij ) = {gx , g0 , g1 , ax , a0 , a1 , bx } for each i  [1..k], j  [1..n]. The initial state on these
1 ) = init(v 2 ) = init(v 3 ) = a , i  [1..k] and j  [1..n], and the goal
variables is init(vij
x
ij
ij
698

fiChain Causal Graphs with Domains of Size 5

Variable
1
v11

1,
vi1
i  [2..k]

1,
vij
i  [1..k],
j  [2..n]

Ref.
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(10)
(11)
(12)
(13)
(14)
(15)
(16)
(17)

Operator
1 = a ; v1 = g i
hvs = 1, v11
x
x 11
1 = a ; v1 = b i
hvs = 1, v11
x 11
1
1 = a ; v1 = g i
hvs = 0, v11
x
x 11
1 = a ; v1 = b i
hvs = 0, v11
x 11
0
1 = g ; v1 = b i
hvs = m, v11
x 11
m
1 = b ; v1 = b i
hvs = m, v11
x 11
m
1 = b ; v1 = b i
hvs = x, v11
m 11
x
3
1 = a ; v1 = g i
hv(i1)n
 {a1 , b1 }, vi1
x
x i1
1 = a ; v1 = b i
3
 {a1 , b1 }, vi1
hv(i1)n
x i1
1
1
1
3
hv(i1)n  {a0 , b0 }, vi1 = ax ; vi1 = gx i
3
1 = a ; v1 = b i
hv(i1)n
 {a0 , b0 }, vi1
x i1
0
3
1 = g ; v1 = b i
hv(i1)n
 {am , bm }, vi1
x i1
m
3
1 = b ; v1 = b i
hv(i1)n
 {am , bm }, vi1
x i1
m
1
1
3
hv(i1)n  {ax , bx }, vi1 = bm ; vi1 = bx i
3
1 = a ; v1 = g i
hvi(j1)
= b1 , vij
x ij
x
1
1
3
hvi(j1) = b1 , vij = ax ; vij = b1 i
3
1 = a ; v1 = g i
hvi(j1)
= b0 , vij
x ij
x
1 = a ; v1 = b i
3
= b0 , vij
hvi(j1)
x ij
0
3
1 = a ; v1 = g i
hvi(j1)
= gx , vij
x ij
x
1
1
3
hvi(j1) = am , vij = ax ; vij = am i
3
1 = g ; v1 = b i
hvi(j1)
= bm , vij
m
x ij
3
1 = b ; v1 = b i
hvi(j1) = bm , vij
x ij
m
3
1 = a ; v1 = a i
hvi(j1)
 {ax , bx }, vij
x
m ij
1 = b ; v1 = b i
3
= bx , vij
hvi(j1)
m ij
x

Qualifier
x1  C1
x1 
/ C1
x1  C1
x1 
/ C1
m  {0, 1}
m  {0, 1}
m  {0, 1}
x1  Ci
x1 
/ Ci
x1  Ci
x1 
/ Ci
m  {0, 1}
m  {0, 1}
m  {0, 1}
xj  Ci
xj 
/ Ci
xj  Ci
xj 
/ Ci
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}

1 , i  [1..k] and j  [1..n].
Table 7: Operators for variables vij

2 ) = g , i  [1..k]. Table 7 shows the operators for variables v 1 , i  [1..k]
state is goal(vin
x
ij
2 and v 3 , i  [1..k] and
and j  [1..n], and Table 8 shows the operators for variables vij
ij
j  [1..n]. Figures 7 and 8 shows the corresponding domain transition graphs. Table 8 also
shows the new operators for variable ve , which have different pre-conditions now that the
3 .
predecessor of ve is vkn

A.1 Intuition
The intuition behind the reduction for C7n is largely the same as that for C11
n . The planning
problem P7 (F ) corresponding to a CNF formula F consists of three parts, the first and
third being identical to those of P11 (F ). Thus, the difference lies in the second part. Recall
that in the reduction for C11
n , for each clause Ci and each variable xj of F , the planning
problem P11 (F ) contains a state variable vij that performs the following functions:
1. Propagate the message m generated by vs .
699

fiGimenez & Jonsson

Variable
2,
vij
i  [1..k],
j  [1..n]

Ref.
(18)
(19)
(20)
(21)
(22)
(23)
(24)
(25)
(26)
(27)
(28)
(29)
(30)
(31)

3,
vij
i  [1..k],
j  [1..n]

ve

Operator
1  {a , b }, v 2 = a ; v 2 = a i
hvij
m m
x ij
m
ij
1 = g , v2 = a ; v2 = g i
hvij
x
x ij
x ij
1 = b , v2 = g ; v2 = g i
hvij
m ij
x ij
m
1 = b , v2 = b ; v2 = a i
hvij
m
x ij
m ij
1 = a , v2 = a ; v2 = a i
hvij
x ij
m ij
x
1 = b , v2 = a ; v2 = b i
hvij
x
m ij
x ij
1 = b , v2 = g ; v2 = g i
hvij
x ij
m ij
x
2 = a , v3 = a ; v3 = a i
hvij
m ij
x ij
m
2 = g , v3 = a ; v3 = g i
hvij
x
x ij
x ij
2 = g , v3 = g ; v3 = b i
hvij
m ij
x ij
m
2  {a , g }, v 3 = b ; v 3 = b i
hvij
m
x ij
m m
ij
2 = a , v3 = a ; v3 = a i
hvij
x ij
m ij
x
3
3
2
hvij = bx , vij = am ; vij = bx i
2  {b , g }, v 3 = b ; v 3 = b i
hvij
x
x x
m ij
ij
3
hvkn  {a0 , a1 , b0 , b1 }, ve = 0; ve = 1i
3  {a , b }, v = 1; v = 0i
hvkn
x x
e
e

Qualifier
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}
m  {0, 1}

2 , v 3 , and v , i  [1..k] and j  [1..n].
Table 8: Operators for variables vij
e
ij

(a)

(b)

(c)

b0

b0

a0

0
ax

0

0
bx

gx
1

x

ax
1

1

a0
a0,b0 b0

a0,b0

x

gx

a1, b1

a1, b1

ax
bx

b0

bx

ax

gx

a1
b1

ax
bx

b1
ax,bx

b1

b0
ax,bx

a0

b1

b0

b0

bx
bx

gx
b1

bx

b1

a1
a1

b1

1 , (b) v 1 for i  [2..k], (c) v 1 for i  [1..k], j  [2..n].
Figure 7: DTGs of (a) v11
ij
i1

2. Check whether the assignment to xj (the j-th bit of m) satisfies the clause Ci .
3. Remember whether Ci was satisfied by the assignment to some xl , l  j.
4. If j < n and Ci has been satisfied, propagate this fact.
5. If j < n, let vi(j+1) know when the (j + 1)-th bit of the message has arrived.
The first and fourth function is to propagate information and thus has to be performed
by all state variables if information is not to be lost. However, the other functions can be
performed by different state variables. The idea behind the reduction for C7n is to split vij
1 , that performs the second function, v 2 , that performs the third,
into three variables: vij
ij
3
and vij , that performs the fifth.
700

fiChain Causal Graphs with Domains of Size 5

(a)

(b)
a0

g0
b0

a0
bx

bx
a0,b0
gx

gx

g1

b0

ax

bx

ax
a1,b1

b1

bx

ax

a1

a0

ax

b0

bx

g0
a0,g0

ax

bx

gx

bx,gx
bx

gx
bx,gx

ax

b1

a1
a1

bx

a1,g1

g1
b1

2 and (b) v 3 for i  [1..k], j  [1..n].
Figure 8: DTGs of (a) vij
ij

Just as before, the message m is propagated using the subscripts of values in the domains
1 moves
of state variables. When the j-th bit mj of the message arrives, state variable vij
1 moves
from ax to gx if the assignment (xj ) = mj satisfies Ci , and to bmj otherwise. If vij
to gx , it is forced to move to bmj next, forgetting that Ci was satisfied. However, while the
1 is g , all subsequent state variables for C can also move to g , propagating the
value of vij
x
i
x
2 is able to remember that
fact that Ci has been satisfied. Consequently, state variable vin
Ci has been satisfied by remaining within the subdomain {g0 , g1 , gx }.
1 moves to b , causing v 2 and v 3 to move to a .
If (xj ) = mj does not satisfy Ci , vij
mj
mj
ij
ij
1
3
2
1
From there, vij , vij , and vij all move to bx . When the next bit arrives, vij moves to b0 (b1 ),
2 to move to a (a ) and v 3 to b (b ). This indicates to v 1
causing vij
0
1
0
1
ij
i(j+1) that the (j + 1)-th
bit has arrived, causing it to act accordingly. Just as before, the operators are defined such
1 always reacts to the first bit for each clause C .
that vi1
i
A.2 Formal Proof
Since variables s1 , . . . , s2n1 , vs , ve , e1 , . . . , e2n1 are the same as before, Lemmas 4.2 and
4.6 both apply to P7 (F ). However, Lemma 4.3 is violated since it is sometimes possible
to change the value of a variable twice without changing the value of its predecessor (e.g.
using operators (1) and (5)). Consequently, Lemma 4.8, which states that all plans that
solve P11 (F ) are admissible, no longer holds for P7 (F ).
l ) for variables in the middle of
To prove equivalent lemmas for P7 (F ), we redefine (vij
the causal graph:
l , i  [1..k], j  [1..n], and
Definition A.1. Given a partial plan  and variable vij
l ) be the number of subscript changes of v l during the execution of .
l  {1, 2, 3}, let (vij
ij
l , i  [1..k], j  [1..n], and
Lemma A.2. For each partial plan  for P7 (F ) and each vij
l )  (v  ), where v  is the predecessor of v l in the causal
l  {1, 2, 3}, it holds that (vij
ij
graph.
l . Each operator that
Proof. Follows immediately from inspection of the operators for vij
l
changes the subscript of vij to z  {0, 1, x} has a pre-condition on v  with subscript z (or
1 and its predecessor v ). There are operators for changing the value
value z in the case of v11
s
1 to g that have a pre-condition on v  with a subscript (or value) different from x, but
of vij
x
1 since their pre-condition on v 1 is a .
these operators do not change the subscript of vij
x
ij

701

fiGimenez & Jonsson

3 ).
Lemma A.3. For each partial plan  for P7 (F ), (ve )  (vkn
3 ) denotes
Proof. Note that (ve ) still denotes the number of value changes of ve , while (vkn
3 . Each time we change the value of v we need to
the number of subscript changes of vkn
e
3
change the subscript of vkn in between. In addition, the first value change of ve requires a
3 different from that in the initial state. Thus, (v )  (v 3 ).
subscript for vkn
e
kn

Definition A.4. An admissible plan  for planning problem P7 (F ) is a partial plan such
1 ) = . . . = (v 3 ) = (v ) = 2n, and (e ) = 2n  i, for each
that (si ) = i, (vs ) = (v11
e
i
kn
i  [1..2n  1].
Lemma A.5. Any plan  that solves the planning problem P7 (F ) is admissible.
1 )      (v 3 )  (v ). We
Proof. By Lemmas A.2 and A.3 we have that (vs )  (v11
e
kn
can now use Lemmas 4.2 and 4.6 and apply the same reasoning as in the proof of Lemma
4.8.
l exactly 2n
In other words, an admissible plan has to change the subscript of each vij
l an extra time by moving through g . However,
times, although it can change the value of vij
x
l ), we cannot prove an equivalent of Lemma 4.10 for
even with the new definition of (vij
l , l  {1, 2}, can choose not to follow its predecessor to g without
P7 (F ), since a variable vij
x
making the plan inadmissible. Consequently, the sequences of values Qti () of an admissible
plan  are no longer completely determined by the induced message m . Nevertheless, we
can still prove a lemma similar to Lemma 4.13.

Definition A.6. Let  be an admissible plan. For each clause Ci and each t  [1..2n + 1],
let the sequence of values Qti () be the vector of 3n elements representing, for each variable
l , j  [1..n] and l  {1, 2, 3}, the first value following the (t  1)-th subscript change of
vij
l during the execution of .
vij
Lemma A.7. Let  be an assignment of variables x1 , . . . , xn of formula F .
1) Existence. There exists an admissible plan  of planning problem P7 (F ) with induced
assignment  = .
2) Claim. Let Qti be the sequences of values described in Part 3) of this lemma. If 
satisfies F , then there exists an admissible plan  with  =  such that Qti () = Qti ,
for all t  [1..2n+1] and i  [1..k]. If  does not satisfy clause Ci , then all admissible
plans  with  =  have Qti () = Qti , for all t  [1..2k + 1].
3) Sequence of values. The sequence of values Qti , for i  [1..k] and t  [1..2n + 1],
is as follows.
a) If j < Ti , then
j1

Qi2j1
Q2j
i
Q2j+1
i

nj
}|
{
z
z
}|
{
bx bx bx    bx bx bx
ax ax ax
ax ax ax    ax ax ax
=
= bm am bm    bm am bm bm am am am am am    am am am
=
bx bx bx    bx bx bx
bx bx bx
ax ax ax    ax ax ax

702

fiChain Causal Graphs with Domains of Size 5

b) If j = Ti , then
j1

Qi2j1
Q2j
i
2j+1
Qi

nj
z
}|
{
z
}|
{
=
bx bx bx    bx bx bx
ax ax ax
ax ax ax    ax ax ax
= bm am bm    bm am bm bm gm bm bm gm bm    bm gm bm
=
bx bx bx    bx bx bx
bx gx bx
bx gx bx    bx gx bx

c) If j > Ti , then
jTi

Ti 1

Qi2j1
Q2j
i
2j+1
Qi

nj

z
z
}|
{
}|
{
}|
{
z
bx gx bx    bx gx bx bx gx bx bx gx bx    bx gx bx
= bx bx bx    bx bx bx
= bm am bm    bm am bm bm gm bm    bm gm bm bm gm bm bm gm bm    bm gm bm
= bx bx bx    bx bx bx
bx gx bx    bx gx bx bx gx bx bx gx bx    bx gx bx

Proof. Note the similarity of this lemma with Lemma 4.13. As before, we must show that
there are operators, this time in Tables 7 and 8, whose post-conditions equal the values
2j+1
given by Qi2j1 , Q2j
. Again, we must check for consistency in the statements
i and Qi
2j  +1
2j1

with j = j  1. This implies, as in Lemma 4.13, that the statements
and Qi
of Qi
for Qi2j1 are valid, due to the initial state being ax    ax and by induction on j. It just
2j+1
remains to show that the statements for Q2j
are also valid.
i and Qi
The proof is divided into the same six parts as that of Lemma 4.13. Note that, in
contrast to that lemma, here we aim to show that, when  satisfies F , there exists an
admissible plan with given Qti , not that all admissible plans have this form. This is because
sometimes during the execution of the plan more than one operator could have been chosen,
and the resulting plan would still be admissible. In the tables that follow, which are alike
to those in the proof of Lemma 4.13, we only indicate the operator choice that leads to the
desired Qti , and we use boldface to remark that these operators are not forced. We add
an extra row to the tables to indicate that sometimes we need to apply two operators for
each variable before changing its subscript. These disparities with respect to Lemma 4.13
only occur in parts II and IV of the proof, which require Ti  n, that is,  satisfying clause
Ci , for some fixed i. Thus, when  does not satisfy clause Ci , all admissible plans  have
the same sequences of values Qti for each t  [1..2n + 1].
I) 1 = j < Ti .
1 v2 v3
1 v 2 v 3 |k  [2..n]
vi1
vik
i1 i1
ik ik
2j  1 ax ax ax
ax ax ax
2j
bm am am (2, 4; 18; 25) am am am (13; 18; 25)
ax ax ax (16; 22; 29)
2j + 1 bx bx bx (7; 23; 30)

II) 1 = j = Ti .
1 v2 v3
1 v 2 v 3 |k  [2..n]
vi1
vik
i1 i1
ik ik
2j  1 ax ax ax
ax ax ax
gx gx gx (1, 3; 19; 26)
gx gx gx (12; 19; 26)
2j
bm gm bm (5; 20; 27)
bm gm bm (14; 20; 27)
bx gx bx (7; 24; 31)
bx gx bx (17; 24; 31)
2j + 1

703

fiGimenez & Jonsson

III) 1 < j < Ti .
1 v 2 v 3 |k  [1..j  1] v 1 v 2 v 3
1 v 2 v 3 |k  [j + 1..n]
vik
vik
ij ij ij
ik ik
ik ik
2j  1
b x bx bx
ax ax ax
ax ax ax
2j
bm am bm (6, 15; 21; 28) bm am am (9, 11; 18; 25) am am am (13; 18; 25)
bx bx bx (7, 17; 23; 31)
bx bx bx (17; 23; 30)
ax ax ax (16; 22; 29)
2j + 1

IV) 1 < j = Ti .
1 v 2 v 3 |k  [1..j  1] v 1 v 2 v 3
1 v 2 v 3 |k  [j + 1..n]
vik
vik
ij ij ij
ik ik
ik ik
2j  1
b x bx bx
ax ax ax
ax ax ax
bm am bm (6, 15; 21; 28) gx gx gx (8, 10; 19; 26)
gx gx gx (12; 19; 26)
2j
bm am bm
bm gm bm (14; 20; 27)
bm gm bm (14; 20; 27)
2j + 1
bx bx bx (7, 17; 23; 31)
bx gx bx (17; 24; 31)
bx gx bx (17; 24; 31)

V) 1 = Ti < j.
1 v 2 v 3 |k  [2..n]
1 v2 v3
vik
vi1
i1 i1
ik ik
2j  1
bx gx bx
bx gx bx
2j
bm gm bm (6; 20; 28) bm gm bm (15; 20; 28)
2j + 1
bx gx bx (7; 24; 31)
bx gx bx (17; 24; 31)

VI) 1 < Ti < j.
1 v 2 v 3 |k  [1..T  1] v 1 v 2 v 3 |k  [T ..n]
vik
i
i
ik ik
ik ik ik
2j  1
bx bx bx
bx gx bx
2j
bm am bm (6, 15; 21; 28)
bm gm bm (15; 20; 28)
2j + 1
bx bx bx (7, 17; 23; 31)
bx gx bx (17; 24; 31)

Theorem A.8. There exists a plan that solves the planning problem P7 (F ) if and only if
there exists an assignment  that satisfies the CNF formula F .
Proof. : Given an assignment  that satisfies F , construct an admissible plan whose
induced formula assignment  equals , by choosing the sequence of values of vs accordingly. It follows that for each clause Ci , Ti  n, since there exists a variable xj such that
 (xj ) = mj satisfies Ci . Since n  Ti , there exists an admissible plan  for which Qi2n+1
has the form indicated in Case (b) or (c) of Lemma A.7. In either case, the (2n + 1)-th
2 is g , as required by the goal state. The plan  thus solves P (F ).
value of variable vin
x
7
: Let  be a plan that solves the planning problem P7 (F ). By Lemma A.5 the plan
 is admissible. We show by contradiction that  =  satisfies F . Assume not. Then
there exists a clause Ci not satisfied by . Thus, Lemma A.7 applies to the sequence of
2 following the execution
values Q2n+1
of . In particular, this means that the value of vin
i
of  is bx according to Case (a) of the lemma. This contradicts  solving P7 (F ), since bx
2 )=g .
is different from the goal state goal(vin
x
Proposition A.9. Plan existence for C7n is NP-hard.
704

fiChain Causal Graphs with Domains of Size 5

Proof. The largest variable domains of the planning problem P7 (F ) are those of variables
1 , . . . , v 3 , which contain 7 values. The proof follows immediately from the NP-hardness
v11
kn
of Cnf-Sat, Theorem A.8, and the fact that we can produce the planning problem P7 (F )
in polynomial time given a CNF formula F .

References
Brafman, R., & Domshlak, C. (2003). Structure and Complexity in Planning with Unary
Operators. Journal of Artificial Intelligence Research, 18, 315349.
Brafman, R., & Domshlak, C. (2006). Factored Planning: How, When, and When Not. In
Proceedings of the 21st National Conference on Artificial Intelligence, pp. 809814.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning.
Artificial Intelligence, 69, 165204.
Chapman, D. (1987). Planning for conjunctive goals. Artificial Intelligence, 32(3), 333377.
Chen, H., & Gimenez, O. (2008). Causal Graphs and Structurally Restricted Planning. In
Proceedings of the 18th International Conference on Automated Planning and Scheduling, pp. 3643.
Domshlak, C., & Dinitz, Y. (2001). Multi-Agent Off-line Coordination: Structure and Complexity. In Proceedings of the 6th European Conference on Planning, pp. 277288.
Erol, K., Nau, D., & Subrahmanian, V. (1995). Complexity, Decidability and Undecidability
Results for Domain-Independent Planning. Artificial Intelligence, 76(1-2), 7588.
Gimenez, O., & Jonsson, A. (2008a). The Complexity of Planning Problems with Simple
Causal Graphs. Journal of Artificial Intelligence Research, 31, 319351.
Gimenez, O., & Jonsson, A. (2008b). In Search of the Tractability Boundary of Planning
Problems. In Proceedings of the 18th International Conference on Automated Planning
and Scheduling, pp. 99106.
Helmert, M. (2006). The Fast Downward Planning System. Journal of Artificial Intelligence
Research, 26, 191246.
Jonsson, A. (2007). The Role of Macros in Tractable Planning Over Causal Graphs. In
Proceedings of the 20th International Joint Conference on Artificial Intelligence, pp.
19361941.
Jonsson, P., & Backstrom, C. (1998). Tractable plan existence does not imply tractable
plan generation. Annals of Mathematics and Artificial Intelligence, 22(34), 281296.
Katz, M., & Domshlak, C. (2008a). New Islands of Tractability of Cost-Optimal Planning.
Journal of Artificial Intelligence Research, 32, 203288.
Katz, M., & Domshlak, C. (2008b). Structural Patterns Heuristics via Fork Decompositions. In Proceedings of the 18th International Conference on Automated Planning
and Scheduling, pp. 182189.
Knoblock, C. (1994). Automatically generating abstractions for planning. Artificial Intelligence, 68(2), 243302.
705

fiGimenez & Jonsson

Williams, B., & Nayak, P. (1997). A reactive planner for a model-based executive. In
Proceedings of the 15th International Joint Conference on Artificial Intelligence, pp.
11781185.

706

fi