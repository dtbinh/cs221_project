Journal of Artificial Intelligence Research 40 (2011) 353-373

Submitted 07/10; published 01/11

Clause-Learning Algorithms with Many Restarts
and Bounded-Width Resolution
Albert Atserias

atserias@lsi.upc.edu

Universitat Politecnica de Catalunya
Barcelona, Spain

Johannes Klaus Fichte

fichte@kr.tuwien.ac.at

Vienna University of Technology
Vienna, Austria

Marc Thurley

marc.thurley@googlemail.com

University of California at Berkeley
Berkeley, USA

Abstract
We offer a new understanding of some aspects of practical SAT-solvers that are based on
DPLL with unit-clause propagation, clause-learning, and restarts. We do so by analyzing
a concrete algorithm which we claim is faithful to what practical solvers do. In particular,
before making any new decision or restart, the solver repeatedly applies the unit-resolution
rule until saturation, and leaves no component to the mercy of non-determinism except
for some internal randomness. We prove the perhaps surprising fact that, although the
solver is not explicitly designed for it, with high probability it ends up behaving as width-k
resolution after no more than O(n2k+2 ) conflicts and restarts, where n is the number of
variables. In other words, width-k resolution can be thought of as O(n2k+2 ) restarts of the
unit-resolution rule with learning.

1. Introduction
The discovery of a method to introduce practically feasible clause learning and non-chronological backtracking to DPLL-based solvers layed the foundation of what is sometimes called
modern SAT-solving (Silva & Sakallah, 1996; Bayardo & Schrag, 1997). These methods
set the ground for new effective implementations (Moskewicz, Madigan, Zhao, Zhang, &
Malik, 2001) that spawned tremendous gains in the efficiency of SAT-solvers with many
practical applications. Such great and somewhat unexpected success seemed to contradict
the widely assumed intractability of SAT, and at the same time uncovered the need for a
formal understanding of the capabilities and limitations underlying these methods.
Several different approaches have been suggested in the literature for developing a rigorous understanding. Among these we find the proof-complexity approach, which captures
the power of SAT-solvers in terms of propositional proof systems (Beame, Kautz, & Sabharwal, 2003, 2004; Hertel, Bacchus, Pitassi, & Gelder, 2008; Pipatsrisawat & Darwiche,
2009), and the rewriting approach, which provides a useful handle to reason about the
properties of the underlying algorithms and their correctness (Nieuwenhuis, Oliveras, &
Tinelli, 2006). In both approaches, SAT-solvers are viewed as algorithms that search for
proofs in some underlying proof system for propositional logic. With this view in mind, it
was illuminating to understand that the proof system underlying modern solvers is always
c
2011
AI Access Foundation. All rights reserved.

fiAtserias, Fichte, & Thurley

a subsystem of resolution (Beame et al., 2003). In particular, this means that their performance can never beat resolution lower bounds, and at the same time it provides many
explicit examples where SAT-solvers require exponential time. Complementing this is the
result that an idealized SAT-solver that relies on non-determinism to apply the techniques
in the best possible way will be able to perform as good as general resolution (weak forms
of this statement were first established in Beame et al., 2003, 2004; Hertel et al., 2008, and
in the current form in Pipatsrisawat & Darwiche, 2009). As Beame et al. (2004) put it, the
negative proof complexity results uncover examples of inherent intractability even under
perfect choice strategies, while the positive proof complexity results give hope of finding a
good choice strategy.
In this work we add a new perspective to this kind of rigorous result. We try to avoid
non-deterministic choices on all components of our abstract solver and still get positive proof
complexity results. Our main finding is that a concrete family of SAT-solvers that do not
rely on non-determinism besides mild randomness is at least as powerful as bounded-width
resolution. The precise proof-complexity result is that under the unit-propagation rule and
a standard learning scheme considered by state-of-the-art solvers, the totally random decision strategy needs no more than O(k 2 ln(kn)n2k+1 ) conflicts and deterministic restarts to
detect the unsatisfiability of any CNF formula on n variables having a width-k resolution
refutation, with probability at least 1/2. Remarkably, the analysis will provide an exact expression for this upper bound that holds for all values of n and k and in particular the bound
we get is not asymptotic. Another remarkable feature is that our analysis is insensitive to
whether the algorithm implements non-chronological backtracking or heuristic-based decisions provided it restarts often enough, and provided it performs totally random decisions
often enough. Further details about this are given in Section 2.
By itself this result has some nice theoretical consequences, which we shall sketch briefly.
First, although not explicitly designed for that purpose, SAT-solvers are able to solve instances of 2-SAT in polynomial time since every unsatisfiable 2-CNF formula has a resolution
refutation of width two. More strongly, our result can be interpreted as showing that widthk resolution can be simulated by O(k 2 ln(kn)n2k+1 ) rounds of unit-clause propagation. To
our knowledge, such a tight connection between width-k resolution and repeated application
of width-one methods was unknown before. Another consequence is that SAT-solvers are
able to solve formulas of bounded branch-width (and hence bounded treewidth) in polynomial time. We elaborate on this later in the paper. Finally, from the partial automatizability
results of Ben-Sasson and Wigderson (1999), it follows that SAT-solvers are able to solve
formulas having polynomial-size tree-like resolution proofs in quasipolynomial time, and
formulas having polynomial-size general resolution proofs in subexponential time.
Concerning our techniques, it is perhaps surprising that the proof of our main result
does not proceed by showing that the width-k refutation is learned by the algorithm. For
all we know the produced proof has much larger width. The only thing we show is that
every width-k clause in the refutation is absorbed by the algorithm, which means that it
behaves as if it had been learned, even though it might not. In particular, if a literal and
its complement are both absorbed, the algorithm correctly declares that the formula is
unsatisfiable. This sort of analysis is the main technical contribution of this paper.
354

fiClause-Learning Algorithms

1.1 Related Work
The first attempt to compare the power of SAT-solvers with the power of resolution as
a proof system was made by Beame et al. (2003, 2004). The main positive result from
their work is that clause learning with a specific learning scheme and without restarts can
provide exponentially shorter proofs than proper refinements of resolution such as tree, or
regular, or positive resolution. Furthermore, they show that the modification of a standard
solver to allow multiple assignments on the same variable would be able to simulate general
resolution efficiently, assuming an ideal decision strategy. Following work showed that the
requirement for multiple assignments on the same variable is a technical issue that can be
avoided if the given CNF formula is pre-processed appropriately (Hertel et al., 2008). In
our work we avoid these two maneuvers by introducing the concept of clause-absorption to
help us analyze the standard algorithms directly.
Interestingly, for clauses that are logical consequences of the input formulas, our concept
of clause-absorption turns out to be dual to the concept of 1-empowerment introduced
independently by Pipatsrisawat and Darwiche (2009)1 . They used 1-empowerment to show
that SAT-solvers without any conceptual modification in their operation are able to simulate
general resolution efficiently, again assuming an ideal decision strategy. For comparison,
our goal settles for a weaker simulation result, bounded-width resolution instead of general
resolution, but does not rely on the non-determinism of ideal decision. We show that the
totally random decision strategy is good enough for this purpose, provided we restart often
enough. To complete this point, it is worth noting that the non-automatizability results of
Alekhnovich and Razborov (2008) indicate that we cannot expect an efficient simulation of
general resolution and completely avoid non-determinism at the same time.
The fact that both concepts were discovered independently adds confidence to our belief
that they will play a role in subsequent studies of the power of SAT-solvers. Indeed, our
techniques were recently extended to show that SAT-solvers with a totally random decision
strategy are able to efficiently simulate local consistency techniques for general constraint
satisfaction problems (Jeavons & Petke, 2010).
1.2 Organization
In Section 2 we introduce basic notation and we define the algorithm we analyze. We also
discuss the dependence of our results on our choice of the learning scheme, the restart policy
and the decision strategy used by the algorithm. Section 3 starts with some elementary
facts about the runs of the algorithm, continues with the key definitions of absorption and
beneficial rounds, and then with the analysis of the running time of the algorithm. Section 4
contains a discussion of the consequences, including the implications for formulas of bounded
treewidth.

2. Clause Learning Algorithms
In this section we will define the algorithm and discuss our choice of its components. We
start with some preliminary definitions.
1. Note that, originally, a weaker version of 1-empowerment was introduced by Pipatsrisawat and Darwiche
(2008).

355

fiAtserias, Fichte, & Thurley

2.1 Preliminaries
Let V = {v1 , . . . , vn } be a fixed set of propositional variables. A literal is a propositional
variable x or its negation x. We use the notation x0 for x and x1 for x. Note that xa is
defined in such a way that the assignment x = a satisfies it. For a  {0, 1}, we also use
a for 1  a, and for a literal ` = xa we use ` for x1a . A clause is a set of literals, and
a formula in conjunctive normal form (CNF-formula) is a set of clauses. The width of a
clause is the number of literals in it. In the following, all formulas are over the same set of
variables V and every clause contains only literals on variables from V .
For two clauses A = {x, `1 , . . . , `r } and B = {x, `01 , . . . , `0s } we define the resolvent of A
and B on x by Res(A, B, x) = {`1 , . . . , `r , `01 , . . . , `0s }. If the variable we resolve on, x, is
implicit we simply write Res(A, B). A clause may contain a literal and its negation. Note
that the resolvent Res(A, B, x) of A and B on x is still well-defined in this case. A resolution
refutation of a CNF formula F is a sequence of clauses C1 , . . . , Cm such that Cm =  and
each clause Ci in the sequence either belongs to F or is a resolvent of previous clauses in
the sequence. The length of a refutation is the number m of clauses in the sequence. For
a clause C, a variable x, and a truth value a  {0, 1}, the restriction of C on x = a is the
constant 1 if the literal xa belongs to C, and C \ {x1a } otherwise. We write C|x=a for the
restriction of C on x = a.
A partial assignment is a sequence of assignments (x1 = a1 , . . . , xr = ar ) with all
variables distinct. Let  be a partial assignment. We say that  satisfies a literal xa if it
contains x = a. We say that  falsifies it if it contains x = 1  a. If C is a clause, we let
C| be the result of applying the restrictions x1 = a1 , . . . , xr = ar to C. Clearly the order
does not matter. We say that  satisfies C if it satisfies at least one of its literals; i.e., if
C| = 1. We say that  falsifies C if it falsifies all its literals; i.e., if C| = . If D is a set
of clauses, we let D| denote the result of applying the restriction  to each clause in D,
and removing the resulting 1s. We call D| the residual set of clauses.
2.2 Definition of the Algorithm
A state is a sequence of assignments (x1 = a1 , . . . , xr = ar ) in which all variables are
d
distinct and some assignments are marked as decisions. We use the notation xi = ai
to denote that the assignment xi = ai is a decision assignment. In this case xi is called a
decision variable. The rest of assignments are called implied assignments. We use S and T to
denote states. The empty state is the one without any assignments. Define the decision level
of an assignment xi = ai as the number of decision assignments in (x1 = a1 , . . . , xi = ai ).
When convenient, we identify a state with the underlying partial assignment where all
decision marks are ignored.
2.2.1 Operation
The algorithm maintains a current state S and a current set of clauses D. There are four
modes of operation DEFAULT, CONFLICT, UNIT, and DECISION. The algorithm starts in
DEFAULT mode with the empty state as the current state and the given CNF formula as
the current set of clauses:
356

fiClause-Learning Algorithms

 DEFAULT. If S sets all variables in D and satisfies all clauses in D, stop and output
SAT together with the current state S. Otherwise, if D|S contains the empty clause,
move to CONFLICT mode. Otherwise, if D|S contains a unit clause, move to UNIT
mode. Finally, if control reaches this point, move to DECISION mode.
 CONFLICT. Apply the learning scheme to add a new clause C to D. If C is the empty
clause, stop and output UNSAT. Otherwise, apply the restart policy to decide whether
to continue further or to restart in DEFAULT mode with the current D and S initialized
to the empty state. In case we continue further, repeatedly remove assignments from
the tail of S as long as C|S = , and then go to UNIT mode.
 UNIT. For any unit clause {xa } in D|S , add x = a to S and go back to DEFAULT
mode.
d

 DECISION. Apply the decision strategy to determine a decision x = a to be added to
S and go back to DEFAULT mode.

To guarantee correctness and termination, the learning scheme will always add a clause C
that is a logical consequence of D, for which C|S =  holds at the time it is added, and that
contains at most one variable of maximum decision level. It is not hard to see that these
properties prevent such a clause from being learned twice, and since the number of clauses
on the variables of D is finite, this implies termination. Clauses with these characteristics
always exist as they include the asserting clauses (Zhang, Madigan, Moskewicz, & Malik,
2001) that will be discussed in Section 2.3.3.
The well-known DPLL-procedure is a precursor of this algorithm where, in CONFLICT
mode, the learning scheme never adds any new clause, the restart policy does not dictate
any restart at all, and assignments are removed from the tail of S up to the latest decision
d
d
assignment, say x = a, which is replaced by x = 1  a. We say that the DPLL-procedure
backtracks on the latest decision. In contrast, modern SAT-solvers implement learning
schemes and backtrack on a literal, as determined by the learned clause, which is not necessarily the latest decision. This is called non-chronological backtracking. Besides learning
schemes and non-chronological backtracking, modern SAT-solvers also implement restart
policies and appropriate decision strategies. We discuss our choice of these components of
the algorithm in Section 2.3.
2.2.2 Runs of the Algorithm
Consider a run of the algorithm started in DEFAULT mode with the empty state and initial
set of clauses D, until either a clause is falsified or all variables are set. Such a run is called
a complete round started with D and we represent it by the sequence of states S0 , . . . , Sm
that the algorithm goes through, where S0 is the empty state and Sm is the state where
either all variables are set, or the falsified clause is found. More generally, a round is an
initial segment S0 , . . . , Sr of a complete round up to a state where either D|Sr contains the
empty clause or D|Sr does not contain any unit clause. If D|Sr contains the empty clause
we say that the round is conclusive. If a round is not conclusive we call it inconclusive. The
357

fiAtserias, Fichte, & Thurley

term inconclusive means to reflect the fact that no clause can be learned from such a round.
In particular, a (complete) round that ends in a satisfying assignment is inconclusive2 .
For a round S0 , . . . , Sr , note that for i  {1, . . . , r}, the state Si extends Si1 by exactly
d
one assignment of the form xi = ai or xi = ai depending on whether UNIT or DECISION
is executed at that iteration; no other mode assigns variables. When this does not lead to
confusion, we identify a round with its last state interpreted as a partial assignment. In
particular, we say that the round satisfies a clause C if C|Sr = 1, and that it falsifies it if
C|Sr = .
2.3 Restart Policy, Learning Scheme, and Decision Strategy
In the following we will discuss our choice of the learning scheme, the restart policy and
the decision strategy used by the algorithm. Our discussion will particularly focus on the
dependence of our results on this choice.
2.3.1 Restart Policy
The restart policy determines whether to restart the search after a clause is learned. The
only important characteristic that we need from the restart policy is that it should dictate
restarts often enough. In particular, our analysis will work equally well for the most aggressive of the restart policies, the one that dictates a restart after every conflict, as for
a less aggressive strategy that allows any bounded number of conflicts between restarts.
The fact that our analysis is insensitive to this will follow from a monotonicity property of
the performance of the algorithm that we will prove in Lemma 5. More precisely, it will
follow from the monotonicity lemma that if we decide to use a policy that allows c > 1
conflicts before a restart, then the upper bound on the number of required restarts can
only decrease (or stay the same). Only the upper bound on the number of conflicts would
appear multiplied by a factor of c, even though the truth might be that even those decrease
as well. For simplicity of exposition, for the rest of the paper we assume that the restart
policy dictates a restart after every conflict.
2.3.2 Decision Strategy
The decision strategy determines which variable is assigned next, and to what value. Again,
the only important characteristic that we need from the decision strategy is that it should
allow a round of totally random decisions often enough. Here, a totally random decision
is defined as follows: if the current state of the algorithm is S, we choose a variable x
uniformly at random among the variables from V that do not appear in S, and a value a in
{0, 1} also uniformly at random and independently of the choice of x. Thus, our analysis
actually applies to any decision strategy that allows any bounded number of rounds with
heuristic-based decisions between totally random ones. More precisely, if we allow say c > 1
rounds of non-random decisions between random ones, then the number of required restarts
and conflicts would appear multiplied by a factor of c. Again this will follow from the
2. Let us note that the definitions of round, conclusive round and inconclusive round differ slightly from
those given in the conference version of this paper (Atserias, Fichte, & Thurley, 2009). The current
definitions make the concepts more robust.

358

fiClause-Learning Algorithms

monotonicity lemma referred to above. That said, for simplicity of exposition we assume in
the following that every decision is totally random.
2.3.3 Learning Scheme
The learning scheme determines which clause will be added to the set of clauses when a
conflict occurs. Let S0 , . . . , Sr be a conclusive round started with the set of clauses D that
d
ends up falsifying some clause of D. Let xi = ai or xi = ai be the i-th assignment of the
round. We annotate each Si by a clause Ai by reverse induction on i  {1, . . . , r}:
1. Let Ar+1 be any clause in D that is falsified by Sr .
d

2. For i  r for which xi = ai is a decision, let Ai = Ai+1 .
3. For i  r for which xi = ai is implied, let Bi be any clause in D such that Bi |Si1 is
the unit clause {xai i }, and let Ai = Res(Ai+1 , Bi , xi ) if these clauses are resolvable on
xi , and let Ai = Ai+1 otherwise.
It is quite clear from the construction that each Ai has a resolution proof from the clauses
in D. In fact, the resolution proof is linear and even trivial in the sense of Beame et al.
(2004). We call each clause Ai a conflict clause. If d denotes the maximum decision level
of the assignments in Sr , a conflict clause is called an asserting clause if it contains exactly
one variable of decision level d. Asserting clauses, originally defined by Zhang et al. (2001),
capture the properties of conflict clauses learned by virtually any modern SAT-solver. For
brevity, we describe only two concrete learning schemes in detail. For other schemes see the
work of Zhang et al. (2001).
The Decision learning scheme adds clause A1 to the current set of clauses after each
conflict. It is not hard to check that A1 is an asserting clause. Furthermore, every literal
in A1 is the negation of some decision literal in Sr ; this will be important later on. The
1UIP learning scheme, which stands for 1st Unique Implication Point, is the one that adds
a clause Ai such that i  r is maximal subject to the condition that Ai is an asserting
clause.
In the following we will assume, tacitly, that the algorithm employs some asserting
learning scheme, that is, one whose learned clauses are always asserting, except for the
empty clause.
2.3.4 Clause Bookkeeping
It should be mentioned that our analysis relies crucially on the assumption that the learned
clauses are never removed from the current set of clauses. However, practical SAT-solvers
periodically delete some of the learned clauses to save memory and to avoid the overhead
they introduce. Thus an interesting question is whether our results can be made to work
without the assumption. In this respect, the strong proof-complexity results of Nordstrom
(2009) showing that not every small-width resolution refutation can be made to work in
small clause-space seems to indicate that an assumption similar to ours is indeed needed.
Another remark worth making at this point concerns the width of the learned clauses.
Since our goal is to show that the algorithm can simulate small-width resolution, it seems
natural to ask whether we can restrict the learning scheme to learn clauses of small width
359

fiAtserias, Fichte, & Thurley

only. As mentioned in the introduction, our analysis does not seem to allow it. Moreover,
recent results by Ben-Sasson and Johannsen (2010) show that, in general, learning short
clauses only is a provably weaker scheme than learning arbitrarily long clauses. Thus,
while the examples of Ben-Sasson and Johannsen (2010) do not have small-width resolution
refutations and therefore do not show that keeping long clauses is actually required in this
case, it is conceivable that it might.

3. Analysis of the Algorithm
In this section we will analyze the running time of the algorithm. Before we can do this,
however, we will have to introduce our key technical concepts of absorption and beneficial
rounds, and study some of their most important properties.
3.1 Runs of the Algorithm
Let R and R0 be rounds, and let C be a clause. We say that R0 subsumes R if, up to decision
marks, every assignment in R appears also in R0 . We say that R and R0 agree on C if the
restrictions of R and R0 to variables in C are equal: every variable in C is either unassigned
in both, or assigned to the same value in both. We say that R branches in C if all decision
variables of R are variables in C. Note that the properties agree on C and branches in C
depend only on the set of variables of C. We define them for clauses to simplify notation
later on.
We prove two rather technical lemmas. The goal is to show that inconclusive rounds
are robust with respect to the order in which assignments are made. For example, the first
lemma shows that any inconclusive round subsumes any other round that agrees with it on
its decisions. In fact we will need a slightly stronger claim that involves rounds from two
different sets of clauses.
Lemma 1. Let D and D0 be sets of clauses with D  D0 , let C be a clause, and let R0 be an
inconclusive round started with D0 . Then, for every round R started with D that branches
in C and agrees with R0 on C, it holds that R0 subsumes R.
Proof. Let R = (S0 , . . . , Sr ). By induction on i, we prove that for every i  {0, . . . , r}, every
assignment in Si is also made in R0 . For i = 0 there is nothing to prove since S0 = . Let
d
i > 0 and assume that every assignment in Si1 is also made in R0 . Let x = a or x = a be
the last assignment in Si . Since R and R0 agree on C and R branches in C, every decision
d
assignment made in R is also made in R0 . This takes care of the case x = a. Suppose then
that the last assignment x = a in Si is implied. This means that there exists a clause A
in D such that A|Si1 = {xa }. Since D  D0 and every assignment made in Si1 is also
made in R0 , necessarily x = a appears in R0 because R0 is inconclusive and cannot leave
unit clauses unset.
The next lemma shows that the universal quantifier in the conclusion of the previous
lemma is not void. In addition, the round can be chosen inconclusive.
Lemma 2. Let D and D0 be sets of clauses with D  D0 , let C be a clause, and let R0 be
an inconclusive round started with D0 . Then, there exists an inconclusive round R started
with D that branches in C and agrees with R0 on C, and such that R0 subsumes R.
360

fiClause-Learning Algorithms

Proof. Let R0 = (T0 , . . . , Tt ). Define I  {0, . . . , t} as the set of indices i such that the i-th
d
assignment of R0 assigns some variable in C. For i  I, let xi = ai or xi = ai be the i-th
assignment in R0 .
We will construct a round R = (S0 , . . . , Ss ) started with D inductively. Associated with
each Sj is the set Ij  I of indices i such that xi is left unassigned in Sj . Recall that S0 is
the empty state by definition. Hence I0 = I. We define the following process:
1. If Sj falsifies some clause in D or it sets all variables in V then set s = j and stop.
2. Otherwise, if there is a unit clause {xa } in D|Sj then let Sj+1 be Sj plus x = a.
3. Otherwise, if Ij is non-empty, let i be the minimum element of Ij , and let Sj+1 be
d
obtained by adding the decision xi = ai to Sj .
If none of the above cases applies set s = j and stop the process.
By construction R is a valid round started with D. Let us see that R0 subsumes R: let
A be the set of literals made true by decisions in R. By construction, R and R0 agree on
A and hence R0 subsumes R by Lemma 1. Furthermore, R is inconclusive: By D  D0
and R0 being inconclusive, D|R0 does not contain the empty clause, and as R0 subsumes
R, also D|R does not contain the empty clause. Further, as every variable in C belongs
to V and R is inconclusive, the process stops with Is = . Together with the fact that R0
subsumes R, this shows that R and R0 agree on C. Note finally that R branches in C by
construction.
3.2 Absorption
One key feature of the definition of a round is that if it is inconclusive, then the residual set of
clauses does not contain unit clauses and, in particular, it is closed under unit propagation.
This means that for an inconclusive round R started with D, if A is a clause in D and R
falsifies all its literals but one, then R must satisfy the remaining literal, and hence A as
well. Besides those in D, other clauses may have this property, which is important enough
to deserve a definition:
Definition 3 (Absorption). Let D be a set of clauses, let A be a non-empty clause and let
xa be a literal in A. We say that D absorbs A at xa if every inconclusive round started with
D that falsifies A \ {xa } assigns x to a. We say that D absorbs A if D absorbs A at every
literal in A.
Naturally, when D absorbs A at xa we also say that A is absorbed by D at xa .
Intuitively, one way to think of absorbed clauses is as being learned implicitly. The rest
of this section is devoted to make this intuition precise. For now, let us note that if there are
no inconclusive rounds started with D, then every clause is absorbed. This agrees with the
given intuition since the absence of inconclusive rounds means that unit-clause propagation
applied on D produces the empty clause. In this section we also show that the notion
of clause-absorption is tightly connected to the concept of 1-empowerment independently
introduced by Pipatsrisawat and Darwiche (2009).
361

fiAtserias, Fichte, & Thurley

3.2.1 Properties of Absorption
Before we continue, let us discuss some key properties of absorption. We argued already
that every clause in D is absorbed by D. We give an example showing that D may absorb
other clauses. Let D be the set consisting of the three clauses
a  b

bc

a  b  d  e.

In this example, the clause a  c does not belong to D but is absorbed by D since every inconclusive round that sets a = 0 must set c = 1 by unit-propagation, and every inconclusive
round that sets c = 0 must set a = 1 also by unit-propagation. While D may absorb other
clauses as we just saw, we note that every non-empty clause absorbed by D is a logical
consequence of D. We write D |= C, if every satisfying assignment of D satisfies C.
Lemma 4. Let D be a set of clauses and let C be a non-empty clause. If D absorbs C,
then D |= C.
Proof. Let S be a full assignment that satisfies all clauses in D. We want to show that S
satisfies C as well. Let R = (S0 , . . . , Sr ) be a complete round of the algorithm started with
D that sets all its decision variables as they are set in S. By induction on i  {0, . . . , r}, we
will show that Si  S and it will follow that R is not stopped by a conflict and therefore
Sr = S. In particular R is inconclusive, and if it falsifies all literals of C but one, it must
satisfy the remaining one because C is absorbed. Since R sets all variables in C and Sr = S,
this means that S satisfies C.
It remains to show that Si  S for every i. For i = 0 there is nothing to show since
d
S0 = . Fix i > 0 and assume that Si1  S. Let x = a or x = a be the last assignment in
d
Si . The case x = a is taken care by the assumption that all decision variables of R are set as
in S. Suppose then that the last assignment x = a is implied. This means that there exists
a clause A in D such that A|Si1 = {xa }. Since S satisfies D and Si1  S, necessarily x
is set to a in S.
Next, let us see that the converse of the above lemma does not hold; namely, we see
that not every implied clause is absorbed. In the previous example, for instance, note that
bde is a consequence of D (resolve the first and the third clause on a) but is not absorbed
d
d
by D (consider the inconclusive round d = 0, e = 0).
One interesting property that is illustrated by this example is that if C is the resolvent
of two absorbed clauses A and B, and C is not absorbed at some literal `, then ` appears
in both A and B. In the example above, D does not absorb b  d  e at b, and b appears in
the clauses a  b and a  b  d  e from D, whose resolvent is precisely b  d  e. We will
prove this general fact in the next section where the objects of study will be non-absorbed
resolvents of absorbed clauses.
Next we show three key monotonicity properties of clause-absorption, where the first is
the one that motivated its definition.
Lemma 5. Let D and E be sets of clauses and let A and B be non-empty clauses. The
following hold:
1. if A belongs to D, then D absorbs A,
362

fiClause-Learning Algorithms

2. if A  B and D absorbs A, then D absorbs B,
3. if D  E and D absorbs A, then E absorbs A.
Proof. To prove 1. assume for contradiction that there is a literal ` in A and an inconclusive
round S0 , . . . , Sr started with D which falsifies A\{`} but does not satisfy A. As the round is
inconclusive, we cannot have A|Sr = , which means then that A|Sr = {`}, in contradiction
to the definition of round.
For the proof of 2. let ` be a literal of B and define B 0 = B \ {`}. We consider two
different cases. If ` 
/ A then A  B 0 and, as A is absorbed by D, there is no inconclusive
round which falsifies B 0 . Thus B is absorbed in this case. If `  A, let A0 = A \ {`} and let
S0 , . . . , Sr be an inconclusive round started with D which falsifies B 0 . Then it falsifies A0
and satisfies A by absorption. Thus it satisfies B, and B is absorbed in this case as well.
It remains to prove 3. Let ` be some literal in A and A0 = A \ {`}. Let R0 be an
inconclusive round started with E which falsifies A0 . By Lemma 2, there is an inconclusive
round R started with D which falsifies A0 and which is subsumed by R0 . As A is absorbed
by D, we see that R (and hence R0 ) satisfies A.
3.2.2 Absorption and Empowerment
Our next goal is to show that absorption and empowerment are dual notions. For assignments ,  we write    if every assignment in  is also in . Let us reproduce the
definition of 1-empowerment in the work of Pipatsrisawat and Darwiche (2009), slightly
adapted to better suit our notation and terminology.
Definition 6 (1-Empowerment in Pipatsrisawat & Darwiche, 2009). Let D be a set of
clauses, let C be a non-empty clause and let xa be a literal in C. Let  be the assignment
that sets y = 1  b for every literal y b in C \ {xa }. We say that C is 1-empowering via xa
with respect to D, if the following three conditions are met:
1. C is a logical consequence of D; i.e. D |= C,
2. repeated applications of unit-clause propagation on D| do not yield the empty clause,
3. repeated applications of unit-clause propagation on D| do not assign x to a.
We also say that xa is an empowering literal of C. We say that C is 1-empowering if it is
1-empowering via some literal in C.
A preliminary version of this definition was given by Pipatsrisawat and Darwiche (2008)
where the second of the three conditions was not required.
By the definition of absorption, we see that if some non-empty clause A is not absorbed
by a set of clauses D, then there is an inconclusive round R started with D and a literal xa in
A such that R falsifies A \ {xa } but does not satisfy {xa }. When A is a logical consequence
of D, this witnesses precisely the fact that A is 1-empowering via xa . We show that the
converse is also true:
Lemma 7. Let D be a set of clauses, let C be a non-empty clause such that D |= C, and
let xa be a literal in C. Then, C is 1-empowering via xa with respect to D if and only if D
does not absorb C at xa .
363

fiAtserias, Fichte, & Thurley

Proof. Let C 0 = C\{xa }. Assume first that D does not absorb C at xa . Let R = (S0 , . . . , Sr )
be an inconclusive round started with D witnessing this fact, i.e. Sr falsifies C 0 and does
not assign x = a. In particular   Sr . Furthermore, for every unit clause {y b } in D|
we have y = b in Sr , as R is an inconclusive round. By a straightforward induction, we
see that every  obtained from  by repeated applications of unit-clause propagation from
D| also satisfies   Sr . This directly implies conditions 2. and 3. in the definition of
1-empowerment. Condition 1. is met by assumption.
For the converse, assume that C is 1-empowering via xa with respect to D. We have to
show that there is an inconclusive round started with D that falsifies C 0 but does not assign
x = a. Let R = (S0 , . . . , Sr ) be a round started with D in which every decision assignment
is chosen to falsify a literal in C 0 , and that, among all rounds with this property, assigns as
many literals from C 0 as possible. Clearly such a maximal round exists since the one that
does not make any decision meets the property.
We shall show that R is the round we seek. For each i  {0, . . . , r}, let i   be the
maximal assignment such that i  Si , let i be obtained from i by repeated applications
of unit-clause propagation from D|i , and let i be the subset of assignments in i that are
also in Si . In particular i  Si . We shall prove, by induction on i, that Si  i and hence
Si = i .
The base case i = 0 is trivial since S0 = . Assume now that i > 0 and Si1  i1 . If
the i-th assignment of Si is a decision assignment, then by construction it falsifies a literal
in C 0 and hence belongs to . But then it also belongs to i , i and i as required. If
the i-th assignment of Si is implied we distinguish two cases: whether it also belongs to
 or not. If the implied assignment is also in , then it is in i , i and i as required. If
the implied assignment is not in , then i = i1 and hence i = i1 . But then, since
Si1  i1 by induction hypothesis and i1  i1 , the unit clause responsible for the
definition of Si appears in the process of forming i1 and hence in the process of forming
i . Therefore the assignment will also be in i .
This completes the induction and shows, in particular, that Sr = r . By point 2. in the
definition of 1-empowerment, R is inconclusive. Furthermore, by point 3. in the definition
of 1-empowerment, Sr does not assign x = a. It remains to show that Sr falsifies C 0 . First
note that, by the maximality of R and the fact that R is inconclusive, every literal in C 0
is assigned by R. Moreover, since the decision assignments of R are chosen to falsify the
literals in C 0 , it suffices to show that the implied assignments of R do not satisfy any literal
in C 0 . Thus, suppose for contradiction that y = b is an implied assigned in R and that
y b is a literal in C 0 . Let i  {0, . . . , r} be such that {y b } is a unit-clause in D|Si . Since
Si  Sr  r and y is assigned to 1  b in , the unit-clause {y b } in D|Si appears as the
empty clause in the closure under unit-clause propagation of D| ; this contradicts point 2.
in the definition of 1-empowerment and completes the proof.

Let us note at this point that if condition 1. in the definition of 1-empowerment is
dropped, then the hypothesis that D |= C can also be dropped from Lemma 7. This would
make 1-empowerment and absorption literally dual of each other.
364

fiClause-Learning Algorithms

3.3 Beneficial Rounds
We shall now study the key situation that explains how the algorithm can possibly simulate
resolution proofs. Consider the resolvent C = Res(A, B) of two absorbed clauses A and B
which itself, however, is not absorbed. Our goal is to study what A, B and C look like
in such a case. We start by showing that if C is not absorbed at a literal `  C, then `
appears in both A and B. This property held the key for discovering the concept of clauseabsorption and its relevance to the simulation of resolution proofs. A similar connection to
clause learning was observed by Pipatsrisawat and Darwiche (2008), where it is also pointed
out that the condition that some literal from C appears in both A and B is known as merge
resolution (Andrews, 1968).
Lemma 8. Let D be a set of clauses, let A and B be two resolvable clauses that are absorbed
by D, and let C = Res(A, B). If ` is a literal in C and D does not absorb C at `, then `
appears in both A and B.
Proof. Let y be such that C = Res(A, B, y), and let A0 = A \ {y} and B 0 = B \ {y}. Let
` = xa be a literal in C and assume D does not absorb C at `. Then there exists an
inconclusive round R that falsifies C \ {xa } but does not set x to a. Since ` belongs to C
and C = A0  B 0 we have that ` belongs to A or to B, or to both. If it belongs to both,
we are done. Otherwise, assume without loss of generality that it belongs to A but not to
B. In this case R falsifies B \ {y}, and since B is absorbed, y is set to 0 in R. But then R
falsifies A \ {xa }, and since A is absorbed, x is set to a in R. This contradicts the choice of
R where x was not set to a.
We continue by showing that in the situation of interest, there always exist a beneficial
round of the algorithm which predicts eventual absorption.
Definition 9 (Beneficial Round). Let D be a set of clauses, let A be a non-empty clause,
let xa be a literal of A, and let R be an inconclusive round started with D. We say that R is
beneficial for A at xa if it falsifies A \ {xa }, branches in A \ {xa }, leaves x unassigned, and
d
yields a conclusive round if extended by the decision x = a . The conclusive round obtained
d
by extending R by x = a is also called beneficial for A at xa . We say that R is beneficial
for A if it is beneficial for A at some literal in A.
In other words, a round started with D that is beneficial for A at xa is a witness that
D does not absorb A at xa , which is minimal with this property, and yet yields a conflict
when x is set to the wrong value. Thus, informally, a beneficial round is a witness that D
almost absorbs A at xa .
Lemma 10. Let D be a set of clauses, let A and B be two resolvable clauses that are
absorbed by D, and let C = Res(A, B). If C is non-empty and not absorbed by D, then
there is a round started with D that is beneficial for C.
Proof. We identify a literal xa in C for which we are able to build a beneficial round for C
at xa .
Let y be such that C = Res(A, B, y), and let A0 = A \ {y} and B 0 = B \ {y}. As C is
non-empty and not absorbed by D, there is a literal xa in C and an inconclusive round R0
365

fiAtserias, Fichte, & Thurley

started with D which falsifies C 0 = C \ {xa } but does not set x to a. Also x is not assigned
a in R0 since otherwise it would falsify C, and as C = A0  B 0 and D absorbs both A and
B, both y and y would be satisfied by R0 . This shows that x is unassigned in R0 .
Let R be the inconclusive round started with D which is obtained by applying Lemma 2
to C 0 and the given inconclusive round R0 . We claim that R is beneficial for C at xa : The
round R falsifies C 0 , as it agrees with R0 on C 0 . Also R branches in C 0 and, as R0 subsumes
R, leaves x unassigned. Finally, note that R and R0 also agree on A \ {y} and B \ {y}.
d
Hence extending the round R by a decision x = a yields a conclusive round; otherwise both
y and y would be satisfied since both A and B are absorbed by D.
3.4 Main Technical Lemma
We will now start analyzing the number of complete rounds it takes until the resolvent of
two absorbed clauses is absorbed as a function of its width. However, as this is not trivial we
first have to determine the number of complete rounds it takes until a sufficient prerequisite
of absorption occurs: a beneficial round.
Lemma 11. Let D be a set of clauses, and let A and B be two resolvable clauses that
are absorbed by D and that have a non-empty resolvent C = Res(A, B). Let n be the total
number of variables in D, and k be the width of C. For every t  1, let R0 , . . . , Rt1 denote
the t consecutive complete rounds of the algorithm started with D, and let D0 , . . . , Dt1
denote the intermediate sets of clauses. Then, the probability that none of the Ri is beneficial
k
for C and none of the Di absorbs C is at most et/(4n ) .
Proof. Let R0 , . . . , Rt1 denote the t consecutive complete rounds of the algorithm started
with D, and let D0 , . . . , Dt1 be the intermediate sets of clauses. In particular D0 = D and
Ri is a round started with Di . For every i  {0, . . . , t  1} let Ri be the event that Ri is
not beneficial and let Di be the event that Di does not absorb C. We want to compute an
upper bound for the joint probability of these events. Note that
"t1
# t1 "
# t1 "
#
j1
fi j1
fi
\
Y
Y
\
fi \
fi
Pr
Ri  D i =
Pr Rj  Dj fi
Ri  D i 
Pr Rj fi Dj 
Ri  D i
(1)
i=0

j=0

i=0

j=0

i=0

Hence, we shall give appropriate upper bounds for the factors on the right hand side of
this inequality. To do this, let us first bound Pr Rj | Dj , Rj1 , Dj1 , . . . , R0 , D0 from
below. Under the conditions Dj , Rj1 , Dj1 , . . . , R0 , D0 , Lemma 10 implies that there is
an inconclusive round R started with Dj which is beneficial for C at some xa  C. The
probability that Rj is beneficial for C is bounded from below by the probability that Rj is
beneficial for C at xa . We will therefore bound the latter from below.
First let us compute a lower bound on the probability that the first k  1 decisions of the
d
decision strategy are chosen to falsify C \ {xa } and the k-th choice is x = a. The probability
that these choices are made is at least




 

k1
k2
1
1
(k  1)!
1


 k.
k
k
2n
2(n  1)
2(n  k + 2)
2(n  k + 1)
2 n
4n
Note that a round started with Dj that follows these choices may not even be able to do
some of the decisions as the corresponding assignments may be implied. However, before
366

fiClause-Learning Algorithms

d

the decision x = a is made, a round following these choices will only perform decisions that
agree with R in C \ {xa } and therefore stay subsumed by R after every new decision, by
d
Lemma 1. In particular, right before the decision x = a it will be inconclusive, it will falsify
C \ {xa }, and it will leave x unset. Also by Lemma 1 it has performed the same assignments
d
as R up to order, and therefore the addition of x = a will make it conclusive. It follows
that the probability that the round will be beneficial for C at xa can only be bigger.
Consequently, the probability of Rj conditional on Dj , Rj1 , Dj1 , . . . , R0 , D0 is bounded
from above by 1  4n1k . Therefore, by equation (1) we have
Pr

"t1
\
i=0

#
Ri  D i



1 t
k
 1 k
 et/(4n )
4n

where in the second inequality we used the fact that 1 + x  ex for every real number x.
3.5 Bounds
With the tools given above, we are now able to prove the main result of the paper: the
simulation of width-k resolution by the algorithm. We shall first give the proof for the
algorithm employing the Decision learning scheme. Not only is the proof easier and more
instructive, but also we get slightly better bounds for this special case. Afterwards, we will
see the result for asserting learning schemes in general.
3.5.1 The Decision Scheme
The fact that makes Decision easier to analyze is that, for this learning scheme, the
occurrence of a beneficial round immediately yields absorption at the next step. Indeed, if
R is beneficial for C, then it branches in C, which means that the clause learned in this
complete round is a subset of C. In particular this means that the next set of clauses will
absorb a subset of C, and hence C as well by Lemma 5. We obtain the following result as
a direct consequence to Lemma 11.
Lemma 12. Let D be a set of clauses, and let A and B be two resolvable clauses that
are absorbed by D and that have a non-empty resolvent C = Res(A, B). Let n be the total
number of variables in D and k be the width of C. Then, for all t  1, using the Decision
learning scheme, the probability that C is not absorbed by the current set of clauses after t
k
restarts is at most et/(4n ) .
Proof. Let R0 , . . . , Rt1 denote the t consecutive complete rounds of the algorithm started
with D, and let D0 , . . . , Dt be the intermediate sets of clauses. In particular D0 = D
and Ri is a round started with Di . For every i  {0, . . . , t  1} let Ri be the event that
Ri is not beneficial for C and let Di be the event that Di does not absorb C. If one of
the Ri is beneficial for C, then Di+1 absorbs C. To see this, note that as R branches in
C, the clause Ci learned from Ri satisfies Ci  C. Hence Di+1 absorbs both Ci and C by
Lemma 5. Further, Dt also absorbs C, if one of the Di absorbs it again by Lemma
T 5. Hence,
the probability that C is not absorbed by Dt is bounded from above by Pr[ t1
i=0 Ri  Di ].
k)
t/(4n
Lemma 11 implies that this is bounded by e
.
367

fiAtserias, Fichte, & Thurley

Theorem 13. Let F be a set of clauses on n variables having a resolution refutation of
width k and length m. With probability at least 1/2, the algorithm started with F , using
the Decision learning scheme, learns the empty clause after at most 4m ln(4m)nk conflicts
and restarts.
Proof. The resolution refutation must terminate with an application of the resolution rule
of the form Res(x, x). We will show that for both ` = x and ` = x, the probability that
{`} is not absorbed by the current set of clauses after 4m ln(4m)nk restarts is at most 1/4.
Thus, both {x} and {x} will be absorbed with probability at least 1/2. If this is the case, it
is straightforward that every complete round of the algorithm is conclusive. In particular,
the round that does not make any decision is conclusive, and in such a case the empty
clause is learned.
Let C1 , C2 , . . . , Cr = {`} be the resolution proof of {`} that is included in the width-k
resolution refutation of F . In particular r  m1 and every Ci is non-empty and has width
at most k. Let D0 , D1 , . . . , Ds be the sequence of clause-sets produced by the algorithm
where s = rt and t = d4 ln(4r)nk e. For every i  {0, . . . , r}, let Ei be the event that every
clause in the initial segment C1 , . . . , Ci is absorbed by Dit , and let E i be its negation. Note
that Pr[ E0 ] = 1 vacuously and hence Pr[ E 0 ] = 0. For i > 0, we bound the probability that
Ei does not hold conditional on Ei1 by cases. Let pi = Pr[ E i | Ei1 ] be this probability. If
Ci is a clause in F , we have pi = 0 by Lemma 5. If Ci is derived from two previous clauses,
k
we have pi  et/(4n ) by Lemma 12, which is at most 1/(4r) by the choice of t.
The law of total probability gives
 



 

Pr E i = Pr E i | Ei1 Pr [Ei1 ] + Pr E i | E i1 Pr E i1




 Pr E i | Ei1 + Pr E i1 .
 


P
Adding up over all i  {1, . . . , r}, together with Pr E 0 = 0, gives Pr E r  ri=1 pi 
r
1
4r = 4 . Since the probability that Cr is not absorbed by Drt is bounded by Pr[ E r ], the
proof follows.
3.5.2 Asserting Learning Schemes in General
We shall now study the algorithm applying an arbitrary asserting learning scheme. The
analysis is a bit more complex than that of the Decision scheme since in general a clause
learned from a complete round R cannot be assumed to be a subset of the decisions in R.
Therefore we can only show that the resolvent is eventually absorbed by a little detour. We
note that this proof has to overcome similar difficulties as, and is inspired by3 , the proof of
Proposition 2 in the work of Pipatsrisawat and Darwiche (2009).
We need some preparation. Let C be a clause and D be a set of clauses. Let WC,D
denote the set of literals ` in C such that there exists an inconclusive round started with
D that is beneficial for C at `. Let u`,C,D denote the number of variables left unassigned
by an inconclusive round started with D which is beneficial for C at `. If no such round
exists, we define u`,C,D = 0. Note that this number is well-defined, as it follows easily from
3. We thank an anonymous reviewer for pointing out that the original proof of Proposition 2 in the work
of Pipatsrisawat and Darwiche (2009) contained an error that was corrected in the version of the paper
on their webpage. Our proof is not affected by this error.

368

fiClause-Learning Algorithms

Lemma 1 that every inconclusive round started with D which is beneficial for C at ` leaves
the same number of variables unassigned. Further, define
uC,D =

X

u`,C,D .

`WC,D

Note that if C is absorbed by D, then WC,D = . Moreover, under the hypothesis of
Lemma 10, the converse is also true. Analogously, if C is absorbed by D, then uC,D = 0
and, under the hypothesis of Lemma 10, the converse is also true.
Lemma 14. Let D and D0 be sets of clauses with D  D0 . Let A and B be two resolvable
clauses that are absorbed by D, and let C = Res(A, B). Then, WC,D0  WC,D and u`,C,D0 
u`,C,D for all `  WC,D .
Proof. If WC,D0 = , nothing is to be shown. Otherwise, for xa in WC,D0 , we start by
showing that xa belongs to WC,D . Let R0 be an inconclusive round started with D0 which is
beneficial for C at `. Application of Lemma 2 to R0 and C \{xa } yields an inconclusive round
R started with D with the following properties: R0 subsumes R, both agree on C \ {xa },
and R branches in C \ {xa }. To show that R is beneficial for C at xa , it only remains to
d
prove that extending R by x = a yields a conclusive round. Let R be a round defined by
this extension. Let y be such that C = Res(A, B, y). Then R falsifies B \ {y} and A \ {y}.
By absorption, R cannot be inconclusive, as otherwise, y and y would be satisfied by R .
This proves WC,D0  WC,D .
Now, we show that u`,C,D0  u`,C,D for every ` in WC,D . If ` does not belong to WC,D0
nothing is to be shown since u`,C,D0 = 0 in that case. Otherwise, let R0 and R be inconclusive
rounds beneficial for C at ` such that R0 is started with D0 and R is started with D. By
Lemma 1, R0 subsumes R, which finishes the proof.
Lemma 15. Let D be a set of clauses, let A and B be two resolvable clauses that are
absorbed by D, and let C = Res(A, B). Let R be a conclusive round started with D and let
D0 be obtained from D by adding the asserting clause learned from R. If C is not empty
and R is beneficial for C at some `  C, then u`,C,D0 < u`,C,D and uC,D0 < uC,D .
Proof. By Lemma 14 we already know that uC,D0  uC,D and u`,C,D0  u`,C,D . Therefore,
it suffices to demonstrate that, in the presence of R, the second inequality is strict.
By hypothesis, R is beneficial for C at `. Let C 0 be the asserting clause learned by R.
Let R be the unique inconclusive round contained in R which is beneficial for C at `; this
is the round which does not contain the last decision made by R. By Lemma 1, the number
of assignments made by any two rounds started with D and beneficial for C at ` are the
same. Hence, the number of variables left unassigned by R equals u`,C,D , and u`,C,D  1
since at least one variable is unset.
If u`,C,D0 = 0 then already u`,C,D0 < u`,C,D . Therefore, assume that u`,C,D0  1. In
particular, there exists an inconclusive round R0 started with D0 which is beneficial for C at
`. By Lemma 1 the round R0 subsumes R . By the definition of asserting clauses, C 0 |R is a
unit clause, and since C 0 belongs to D0 , it is absorbed by D0 and hence R0 satisfies C 0 . This
proves that R0 sets at least one more variable than R and therefore u`,C,D0 < u`,C,D .
369

fiAtserias, Fichte, & Thurley

With these two technical lemmas in hand we are ready to state and prove the analogue
of Lemma 12 for arbitrary asserting learning schemes.
Lemma 16. Let D be a set of clauses, and let A and B be two resolvable clauses that
are absorbed by D and that have a non-empty resolvent C = Res(A, B). Let n be the total
number of variables in D and let k be the width of C. Then, for all t  1, using an arbitrary
asserting learning scheme, the probability that C is not absorbed by the current set of clauses
k
after kn  t restarts is at most kn  et/(4n ) .
Proof. Let b = uC,D , and s = bt, and let D0 , . . . , Ds be the sequence of sets of clauses
produced by the algorithm, starting with D0 = D. For every i  {0, . . . , b}, let Xi = uC,Dit
and let Ei be the event that Xi  b  i.
We will bound the probability that C is not absorbed by Dbt from above. Since this
event implies that Xb 6= 0, it suffices to bound Pr[ E b ]. Note that Pr[ E0 ] = 1 vacuously
and hence Pr[ E 0 ] = 0. For i > 0, we bound the probability that Ei does not hold. The law
of total probability gives
 



 

Pr E i = Pr E i | Ei1 Pr [Ei1 ] + Pr E i | E i1 Pr E i1




 Pr E i | Ei1 + Pr E i1 .
Let pi = Pr[ E i | Ei1 ] and note that Pr[ E i | Xi1 < b  i + 1 ] = 0. Hence we have pi 
Pr[ E i | Xi1 = b  i + 1 ]. Consider the sequence D(i1)t+1 , . . . , Dit of sets of clauses and
the corresponding complete rounds of the algorithm. Conditional on Xi1 = b  i + 1, the
event E i implies that Xi = Xi1 6= 0 and hence none of the above sets of clauses absorbs
C. Furthermore, by Lemma 15, none of the corresponding rounds is beneficial for C. Thus,
k
by Lemma 11, we have pi  et/(4n ) . Adding up over all i  {1, . . . , r}, together with
 


Pb
k
Pr E 0 = 0, gives Pr E b  i=1 pi  b  et/(4n ) . The Lemma follows as necessarily
b  kn.
We are now able to prove the main theorem.
Theorem 17. Let F be a set of clauses on n variables having a resolution refutation of width
k and length m. With probability at least 1/2, the algorithm started with F , using an arbitrary asserting learning scheme, learns the empty clause after at most 4km ln(4knm)nk+1
conflicts and restarts.
Proof. The proof is analogous to the proof of Theorem 13 with Lemma 16 playing the role
of Lemma 12, and choosing t = d4 ln(4m  kn)nk e now.

4. Consequences

The total number of clauses of width k on n variables is bounded by 2k nk , which is at most
2nk for every n and k. Therefore, if F has n variables and a resolution refutation of width
k, we may assume that its length is at most 4nk by the following estimate
 
 k

k
k
X
X
n 1
i n
i
1+2
n = 1 + 2n 
 4nk .
2
i
n1
i=0

i=1

We obtain the following consequence to Theorem 17.
370

fiClause-Learning Algorithms

Corollary 18. Let F be a set of clauses on n variables having a resolution refutation of
width k. With probability at least 1/2, the algorithm started with F , using an arbitrary
asserting learning scheme, learns the empty clause after at most 16k(k + 1) ln(16kn)n2k+1
conflicts and restarts.
An application of Corollary 18 is that, even though it is not explicitly defined for the
purpose, the algorithm can be used to decide the satisfiability of CNF formulas of treewidth
at most k in time O(k 2 log(kn)n2k+3 ). This follows from the known fact that every unsatisfiable formula of treewidth at most k has a resolution refutation of width at most k + 1
(Alekhnovich & Razborov, 2002; Dalmau, Kolaitis, & Vardi, 2002; Atserias & Dalmau,
2008).
If we are interested in producing a satisfying assignment when it exists, we proceed by
self-reducibility: we assign variables one at a time, running the algorithm log2 (n) + 1 times
after each assignment to detect if the current partial assignment cannot be extended any
further, in which case we choose the complementary value for the variable. For this we use
the fact that if F has treewidth at most k, then F |x=a also has treewidth at most k. For
the analysis, note that since each run of the algorithm is correct with probability at least
1/2, each new assignment is correct with probability at least
1  2(log2 (n)+1) = 1 

1
.
2n

This means that all iterations are correct with probability at least (1 
running time of this algorithm is O(k 2 (log(kn))2 n2k+4 ).

1 n
2n )



1
2.

The

Acknowledgments
We thank Martin Grohe for suggesting the problem of comparing the power of SAT-solvers
with bounded-width resolution. We also thank Knot Pipatsrisawat and Adnan Darwiche
for pointing out the connection between 1-empowering and absorption. Thanks also to
Peter Jeavons for comments on the conference version of this paper, and to the anonymous
referees for very detailed comments.
The first author was supported in part by CYCIT TIN2007-68005-C04-03. The second
author was supported in part by the European Research Council (ERC), Grant 239962. The
third author was supported in part by a fellowship within the Postdoc-Programme of the
German Academic Exchange Service (DAAD). A preliminary version of this paper appeared
in the Proceedings of the 12th International Conference on Theory and Applications of
Satisfiability Testing, SAT09 (Atserias et al., 2009).

References
Alekhnovich, M., & Razborov, A. A. (2002). Satisfiability, branch-width and Tseitin tautologies. In Proceedings of the 43rd Symposium on Foundations of Computer Science
(FOCS 2002), pp. 593603. IEEE Computer Society.
Alekhnovich, M., & Razborov, A. A. (2008). Resolution is not automatizable unless W[P]
is tractable. SIAM J. Comput., 38 (4), 13471363.
371

fiAtserias, Fichte, & Thurley

Andrews, P. B. (1968). Resolution with merging. J. ACM, 15 (3), 367381.
Atserias, A., & Dalmau, V. (2008). A combinatorial characterization of resolution width.
J. Comput. Syst. Sci., 74 (3), 323334.
Atserias, A., Fichte, J. K., & Thurley, M. (2009). Clause-learning algorithms with many
restarts and bounded-width resolution. In Kullmann, O. (Ed.), Proceedings of the 12th
International Conference on Theory and Applications of Satisfiability Testing (SAT),
Vol. 5584 of Lecture Notes in Computer Science, pp. 114127. Springer.
Bayardo, R. J., & Schrag, R. C. (1997). Using CSP look-back techniques to solve real-world
SAT instances. In Proceedings of the Fourtheenth National Conference on Artificial
Intelligence (AAAI97), pp. 203208.
Beame, P., Kautz, H. A., & Sabharwal, A. (2003). Understanding the power of clause
learning. In Gottlob, G., & Walsh, T. (Eds.), Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI-03), pp. 11941201. Morgan
Kaufmann.
Beame, P., Kautz, H. A., & Sabharwal, A. (2004). Towards understanding and harnessing
the potential of clause learning. J. Artif. Intell. Res. (JAIR), 22, 319351.
Ben-Sasson, E., & Johannsen, J. (2010). Lower bounds for width-restricted clause learning
on small width formulas. In Strichman, O., & Szeider, S. (Eds.), Proceedings of 13th
International Conference on Theory and Applications of Satisfiability Testing (SAT),
Vol. 6175 of Lecture Notes in Computer Science, pp. 1629. Springer.
Ben-Sasson, E., & Wigderson, A. (1999). Short proofs are narrow - resolution made simple.
In Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing
(STOC 1999), pp. 517526.
Dalmau, V., Kolaitis, P. G., & Vardi, M. Y. (2002). Constraint satisfaction, bounded
treewidth, and finite-variable logics. In CP 02: Proceedings of the 8th International
Conference on Principles and Practice of Constraint Programming, pp. 310326, London, UK. Springer-Verlag.
Fox, D., & Gomes, C. P. (Eds.). (2008). Proceedings of the Twenty-Third AAAI Conference
on Artificial Intelligence, AAAI 2008, Chicago, Illinois, USA, July 13-17, 2008. AAAI
Press.
Hertel, P., Bacchus, F., Pitassi, T., & Gelder, A. V. (2008). Clause learning can effectively
p-simulate general propositional resolution.. In Fox, & Gomes (Fox & Gomes, 2008),
pp. 283290.
Jeavons, P., & Petke, J. (2010). Local consistency and sat-solvers. In Proceedings of the
16th International Conference on Principles and Practice of Constraint Programming
- CP 2010, Vol. 6308 of Lecture Notes in Computer Science, pp. 398413. Springer.
Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering an efficient SAT solver. In Proceedings of the 38th Design Automation Conference
(DAC01).
Nieuwenhuis, R., Oliveras, A., & Tinelli, C. (2006). Solving SAT and SAT Modulo Theories: From an abstract DavisPutnamLogemannLoveland procedure to DPLL(T).
Journal of the ACM, 53 (6), 937977.
372

fiClause-Learning Algorithms

Nordstrom, J. (2009). Narrow proofs may be spacious: Separating space and width in
resolution. SIAM J. Comput., 39 (1), 59121.
Pipatsrisawat, K., & Darwiche, A. (2008). A new clause learning scheme for efficient unsatisfiability proofs.. In Fox, & Gomes (Fox & Gomes, 2008), pp. 14811484.
Pipatsrisawat, K., & Darwiche, A. (2009). On the power of clause-learning SAT solvers
with restarts. In Gent, I. P. (Ed.), Proceedings of the 15th International Conference
on Principles and Practice of Constraint Programming - CP 2009, Vol. 5732 of Lecture
Notes in Computer Science, pp. 654668. Springer.
Silva, J. P. M., & Sakallah, K. A. (1996). Grasp - a new search algorithm for satisfiability.
In Proceedings of IEEE/ACM International Conference on Computer-Aided Design,
pp. 220227.
Zhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Efficient conflict driven
learning in a boolean satisfiability solver. In International Conference on ComputerAided Design (ICCAD01), pp. 279285.

373

fi