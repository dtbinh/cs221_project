Journal of Artificial Intelligence Research 51 (2014) 71-131

Submitted 5/14; published 9/14

On the Testability of BDI Agent Systems
Michael Winikoff
Stephen Cranefield

michael.winikoff@otago.ac.nz
stephen.cranefield@otago.ac.nz

Department of Information Science
University of Otago
New Zealand

Abstract
Before deploying a software system we need to assure ourselves (and stakeholders) that
the system will behave correctly. This assurance is usually done by testing the system.
However, it is intuitively obvious that adaptive systems, including agent-based systems,
can exhibit complex behaviour, and are thus harder to test. In this paper we examine this
obvious intuition in the case of Belief-Desire-Intention (BDI) agents. We analyse the
size of the behaviour space of BDI agents and show that although the intuition is correct,
the factors that influence the size are not what we expected them to be. Specifically, we
found that the introduction of failure handling had a much larger effect on the size of the
behaviour space than we expected. We also discuss the implications of these findings on
the testability of BDI agents.

1. Introduction
Increasingly we are called upon to develop software systems that operate in dynamic environments, that are robust in the face of failure, that are required to exhibit flexible behaviour, and that operate in open environments. One approach for developing such systems
that has demonstrated its effectiveness in a range of domains is the use of the metaphor
of software agents (Wooldridge, 2002). Agent-based systems have been increasingly finding
deployment in a wide range of applications (e.g. Munroe, Miller, Belecheanu, Pechoucek,
McBurney, & Luck, 2006; Benfield, Hendrickson, & Galanti, 2006).
As agent-based systems are increasingly deployed, the issue of assurance rears its head.
Before deploying a system, we need to convince those who will rely on the system (or those
who will be responsible if it fails) that the system will, in fact, work. Traditionally, this
assurance is done through testing1 . However, it is generally accepted that adaptive systems
can exhibit a wide and complex range of behaviours, making testing hard. For example:
Validation through extensive tests was mandatory . . . . However, the task proved
challenging . . . . Agent-based systems explore realms of behaviour outside peoples expectations and often yield surprises. (Munroe et al., 2006, Section 3.7.2)
That is, there is an intuition that agent systems exhibit complex behaviour, which makes
them hard to test. In this paper we explore this intuition, focusing on the well known BeliefDesire-Intention (BDI) approach to realising adaptive and flexible agents (Rao & Georgeff,
1. Although there is considerable research on formal methods in the context of agent systems (Dastani,
Hindriks, & Meyer, 2010), it is not yet ready for real world application (see Section 7), and there are
concerns about the scope of the work and its applicability (Winikoff, 2010).
c
2014
AI Access Foundation. All rights reserved.

fiWinikoff & Cranefield

1991; Bratman, 1987), which has been demonstrated to be practically applicable, resulting
in reduced development cost and increased flexibility (Benfield et al., 2006).
We explore the intuition that agent systems are hard to test by analysing both the
space of possible behaviours of BDI agents, that is, the number of paths through a BDI
program, and the probability of failure. We focus on BDI agents because they provide a welldefined execution mechanism that can be analysed, and also because we seek to understand
the complexities (and testability implications) of adaptive and intelligent behaviour in the
absence of parallelism (since the implications of parallelism are already well known).
We derive the number of paths through a BDI program as a function of various parameters (e.g. the number of applicable plans per goal and the failure fate). This naturally
leads us also to consider how the number of paths is affected by these various parameters.
As might be expected, we show that the intuition that agent systems are hard to test is
correct, i.e. that agent systems have a very large number of paths. We also show that BDI
agents are harder to test than procedural programs, by showing that the number of paths
through a BDI program is much larger than the number of paths through a similarly-sized
procedural program.
The contribution of this paper is threefold. Firstly, it confirms the intuition that BDI
programs are hard to test. Secondly, it does so by quantifying the number of paths, as a
function of parameters of the BDI program. Thirdly, we find some surprising results about
how the parameters influence the number of paths.
Although there has recently been increasing interest in testing agent systems (Zhang,
Thangarajah, & Padgham, 2009; Ekinci, Tiryaki, Cetin, & Dikenelli, 2009; Gomez-Sanz,
Bota, Serrano, & Pavon, 2009; Nguyen, Perini, & Tonella, 2009b), there has been surprisingly little work on determining the feasibility of testing agent systems in the first place.
Padgham and Winikoff (2004, pp. 1719) analyse the number of successful executions of a
BDI agents goal-plan tree (defined in Section 3), but they do not consider failure or failure
handling in their analysis, nor do they consider testability implications. Shaw, Farwer and
Bordini (2008) have analysed goal-plan trees and shown that checking whether a goal-plan
tree has an execution schedule with respect to resource requirements is NP-complete. This
is a different problem to the one that we tackle: they are concerned with the allocation of
resources amongst goals, rather than with the behaviour space.
We now briefly address a number of possible criticisms of this work, by considering
existing work.
1. Is the number of paths a useful metric for assessing testability?
We consider the related area of software testing (Section 1.1) and argue that the
metric is a well established one, and is appropriate to use to assess testability.
2. Isnt this just an obvious corollary of the complexity of HTN planning?
We consider in detail the HTN planning problem (Section 1.2) and argue that although
the BDI execution cycle has certain similarities with HTN planning, the differences
are significant, and, in particular, they mean that the problem of HTN planning is
simply different from the problem of testing BDI programs.
3. Why use combinatorial analysis, rather than complexity analysis?
Our combinatorial analysis is more precise: it yields formulae for the exact number
72

fiOn the Testability of BDI Agent Systems

of paths, and the exact probabilities of failure. The latter (see Section 4.5) is more
informative than just having an order of magnitude complexity. Additionally it allows
us to consider issues that complexity analysis would not address, such as the effect of
number of failures on the number of paths.
1.1 Software Testing
We are trying to assess how hard agent systems are to test. More concretely, given a BDI
agent program, we want to know how hard that program is to test. This can be reduced
directly to the question of test set adequacy. An agent program P is easy to test precisely
to the extent that there exists a test set T which is adequate for testing P , where T is
not infeasibly large. Conversely, an agent program P is hard to test to the extent that an
adequate test set T would have to be infeasibly large. In other words, the hardness of
testing a program is directly assessed by the size required for a test set to be adequate with
respect to a suitable adequacy criteria.
There are many criteria that can be used to assess whether a given set of tests is adequate (for a recent overview, see Mathur, 2008). Given that we are interested in assessing
the difficulty of testing a given program, we are clearly looking at white box testing. Furthermore, we will be working with abstract goal-plan trees rather than detailed programs
(see Section 2). This means that we need to consider control-flow based metrics, rather
than data-flow, since an abstract goal-plan tree does not contain data-flow information.
Focussing on white box testing criteria that are control-flow based, a basic and very
long-standing criterion for assessing test set adequacy is that all paths in the program be
covered (Miller & Maloney, 1963). For example, consider a program of the following form.
3. ... then do A
1. Input x

2. If condition ...

5. endif

6. do C

4. ... else do B

There are two paths through this program: (1, 2, 3, 5, 6) and (1, 2, 4, 5, 6), and an
adequate test set must have at least two tests to be adequate: one to exercise the first path,
and another to exercise the second. In this case a test set with only a single test will be
inadequate, and will result in part of the program not being executed at all during testing.
An obvious complication in covering all paths in a program is that any loop will result
in an infinite number of paths, since the loop can potentially be executed any number of
times. The standard technique for dealing with this is to bound the length of paths, or the
number of executions of a loop (Zhu, Hall, & May, 1997, p. 375). Bounding the execution of
loops can be done either by calculating an upper bound on the number of iterations based
on the data (Mathur, 2008, p. 53), or by only considering paths in which loops are executed
zero times or one time (Mathur, 2008, p. 408).
One question that might be asked is why we consider all paths, rather than a weaker
criterion. Agent applications typically involve environments that are non-episodic. That is,
the environments history matters. This means that the behaviour of a given plan or goal
is, in general, sensitive to the agents history, and hence we need to consider the different
possible histories. Achieving a goal may be different if it is being done as the first thing the
73

fiWinikoff & Cranefield

agent does, or after a failed plan which has already performed a number of actions. This
means that it makes sense to consider a path-based criterion for testing.
Furthermore, although the all paths adequacy criterion is often considered to be impractical, the reason appears to be primarily the existence of an infinite number of paths in
the presence of loops. For instance, Zhu et al. (1997, p. 375) say the plan coverage criterion
is too strong to be practically useful for most programs, because there can be an infinite
number of different paths in a program with loops. In our setting, where we do not have
loops, the existence of an infinite number of paths is not an issue, so considering the number
of paths is possible.
We therefore use the number of paths as our proxy measure for testing difficulty: if
there are few paths through the program, then an adequate test set (according to the all
paths criterion) will not need to be large. On the other hand, if the number of paths is
very large, then any adequate test set will need to be very large.
There is one issue we need to consider: since all paths is a strong criterion, it is
possible that, even in the absence (or bounding) of loops, this criterion always results in
an infeasibly large numbers of paths. In order to address this issue we also do an analysis
of the number of paths in procedural programs (of equivalent size), and compare this with
the number of paths for BDI programs (see Section 6).
Finally, it bears noting that the all paths criterion only considers which parts of the
program were traversed during testing, but ignores the values of variables. So, for example,
a trivial program consisting of the single statement x := x  x has a single one-step path,
which is trivially covered, but many traces (x = 0, 1, 2 . . .).
1.2 HTN Planning
There are similarities between Hierarchical Task Network (HTN) planning (Erol, Hendler,
& Nau, 1994) and BDI execution (de Silva & Padgham, 2004): both use a hierarchical
representation with goals (non-primitive tasks in HTN terminology), plans (decomposition methods) and goal-plan trees (task networks). The complexity of HTN planning
has been explored. Given these similarities, can we simply exploit these known complexity
results?
It turns out that we cannot do so, for the simple reason that the complexity of HTN
planning concerns the plan finding problem, which is different to BDI plan execution, as
Sardina and Padgham explain:
BDI agent systems and HTN planners come from different communities and
differ in many important ways. The former focus on the execution of plans,
whereas the latter is concerned with the actual generation of such plans. The
former are generally designed to respond to goals and information; the latter
are designed to bring about goals. In addition, BDI systems are meant to be
embedded in the real world and therefore take decisions based on a particular
(current) state. Planners, on the other hand, perform hypothetical reasoning
about actions and their interactions in multiple potential states. Thus, failure
has very different meaning for these two types of systems. In the context
of planning, failure means that a plan or potential plan is not suitable; within
BDI agent systems failure typically means that an active (sub)plan ought to be
74

fiOn the Testability of BDI Agent Systems

aborted. Whereas backtracking upon failure is an option for planning systems, it
is generally not for BDI systems, as actions are taken in the real world. (Sardina
& Padgham, 2011, p. 45, bold emphasis added)
In other words, HTN systems plan ahead of execution, whereas BDI systems interleave
execution and planning2 .
The HTN plan existence problem answers the question does a plan exist? and its
complexity has been studied. In settings that correspond to BDI execution (many goals,
total ordering within plans, and with variables) it is known to be EXPSPACE-hard and
in DEXPTIME (Erol, Hendler, & Nau, 1994, 1996). However, this work does not address
the question of BDI execution. When considering the complexity of plan existence in HTN
planning we are asking about the computational complexity of a search process that will
result in a plan. On the other hand, when we are asking about the number of paths in a
goal-plan tree we are asking about the possibilities that arise when executing a plan.
To illustrate this point, consider the following example. Suppose we have a single goal
G which can be decomposed into two alternative plans, P1 and P2 . Plan P1 consists of the
sequential execution of actions a, b, and c; and plan P2 consists of the sequential execution
of actions d and e. The plan existence problem boils down to considering the options P1
and P2 , since in this case the search space is very simple, offering only two options. On the
other hand, the question of how many paths exist in BDI execution considers the different
ways in which the goal-plan tree can be executed. Whereas HTN planning considers P1 as a
single atomic decomposition, BDI execution needs to consider the sequence of actions a, b, c
as distinct steps. It is possible for all three actions to succeed (giving the trace a, b, c), but
it also possible for action b to fail, followed by P2 being (successfully) used (giving the trace
a, b8, d, e), or for action c to fail, followed by P2 being (successfully) used (giving the trace
a, b, c8, d, e).
Overall, this means that the complexity analysis of Erol et al. (1994, 1996) is of a
different problem, and that the HTN complexity results are not relevant. Finally, we note
that, in fact, in our setting, the plan existence problem is actually trivially true: since
BDI programs do not have constraints there is always an expansion of the program into a
sequence of actions.
The remainder of this paper is structured as follows. We begin by briefly presenting
the BDI execution model (Section 2) and discussing how BDI execution can be viewed as a
process of transforming goal-plan trees (Section 3). Section 4 is the core of the paper where
we analyse the number of paths in a BDI-style goal-plan tree. We then consider how our
analysis and its assumptions hold up against a real system and a real platform (Section 5),
and how our analysis of BDI programs compares with the same analysis (number of paths)
of conventional procedural programs (Section 6). Finally, we conclude with a discussion of
the implications for testing and future work (Section 7).
2. There are approaches that blur this difference by adding look-ahead planning to BDI or online execution
to HTNs, for example the planner in the RETSINA multi-agent system (Paolucci, Shehory, Sycara, Kalp,
& Pannu, 2000) has the ability to interleave planning and execution. However, no theoretical analysis
of this extension has been reported, and the analysis of Erol, Hendler, and Nau (1994, 1996) applies to
classical HTN planning.

75

fiWinikoff & Cranefield

2. The BDI Execution Model
Before we describe the Belief-Desire-Intention (BDI) model we explain why we chose this
model of agent execution. In addition to being well known and widely used, the BDI model
is well defined and generic. That it is well defined allows us to analyse the behaviour spaces
that result from using it. That it is generic implies that our analysis applies to a wide range
of platforms.
The BDI model can be viewed from philosophical (Bratman, 1987) and logical (Rao
& Georgeff, 1991) perspectives, but we are interested here in the implementation perspective, as exhibited in a range of architectures and platforms, such as JACK (Busetta,
Ronnquist, Hodgson, & Lucas, 1999), JAM (Huber, 1999), dMARS (dInverno, Kinny, Luck,
& Wooldridge, 1998), PRS (Georgeff & Lansky, 1986; Ingrand, Georgeff, & Rao, 1992),
UM-PRS (Lee, Huber, Kenny, & Durfee, 1994), Jason (Bordini, Hubner, & Wooldridge,
2007), SPARK (Morley & Myers, 2004), Jadex (Pokahr, Braubach, & Lamersdorf, 2005)
and IRMA (Bratman, Israel, & Pollack, 1988). For the purposes of our analysis here, a
formal and detailed presentation is unnecessary. Those interested in formal semantics for
BDI languages are referred to the work of Rao (1996), Winikoff, Padgham, Harland, and
Thangarajah (2002) and Bordini et al. (2007), for example.
In the implementation of a BDI agent the key concepts are beliefs (or, more generally,
data), events and plans. The reader may find it surprising that goals are not key concepts in
BDI systems. The reason is that goals are modelled as events: the acquisition of a new goal
is viewed as a new goal event, and the agent responds by selecting and executing a plan
that can handle that event3 . In the remainder of this section, in keeping with established
practice, we will describe BDI plans as handling events (not goals).
A BDI plan consists of three parts: an event pattern specifying the event(s) it is relevant
for, a context condition (a Boolean condition) that indicates in what situations the plan can
be used, and a plan body that is executed. A plans event pattern and context condition
may be terms containing variables, so a matching or unification process (depending on the
particular BDI system) is used by BDI interpreters to find plan instances that respond to
a given event. In general the plan body can contain arbitrary code in some programming
language4 , however for our purposes we assume5 that a plan body is a sequence of steps,
where each step is either an action6 (which can succeed or fail) or an event to be posted.
For example, consider the simple plans shown in Figure 1. The first plan, Plan A, is
relevant for handling the event achieve goal go-home, and it is applicable in situations
where the agent believes that a train is imminent. The plan body consists of a sequence of
four steps (in this case we assume that these are actions, but they could also be modelled
as events that are handled by further plans).
A key feature of the BDI approach is that each plan encapsulates the conditions under
which it is applicable by defining an event pattern and context condition. This allows
for additional plans for a given event to be added in a modular fashion, since the invoking
3. Other types of event typically include the addition and removal of beliefs from the agents belief set.
4. For example, in JACK a plan body is written in a language that is a superset of Java.
5. This follows abstract notations such as AgentSpeak(L) (Rao, 1996) and Can (Winikoff et al., 2002)
which aim to capture the essence of a range of (more complex) BDI languages.
6. This includes both traditional actions that affect the agents environment, and internal actions that
invoke code, or that check whether a certain condition follows from the agents beliefs.

76

fiOn the Testability of BDI Agent Systems

Plan A: handles event:
achieve goal go-home
context condition:
train imminent
plan body:
(1) walk to train station
(2) check train running on time
(3) catch train
(4) walk home
Plan B: handles event:
achieve goal go-home
context condition:
not raining and have bicycle
plan body:
(1) cycle home
Plan C: handles event:
achieve goal go-home
context condition:
true (i.e. always applicable)
plan body:
(1) walk to bus stop
(2) check buses running
(3) catch bus
(4) walk home
Figure 1: Three Simple Plans
context (i.e. where the triggering event is posted) does not contain code that selects amongst
the available plans, and this is a key reason for the flexibility of BDI programming.
A typical BDI execution cycle is an elaboration of the following event-driven process
(summarised in Figure 2)7 :
1. An event occurs (either received from an outside source, or triggered from within the
agent).
2. The agent determines a set of instances of plans in its plan library with event patterns
that match the triggering event. This is the set of relevant plan instances.
3. The agent evaluates the context conditions of the relevant plan instances to generate
the set of applicable plan instances. A relevant plan instance is applicable if its context
condition is true. If there are no applicable plan instances then the event is deemed
to have failed, and if it has been posted from a plan, then that plan fails. Note that a
single relevant plan may lead to no applicable plan instances (if the context condition
is false), or to more than one applicable plan instance (if the context condition, which
may contain free variables, has multiple solutions).
4. One of the applicable plan instances is selected and is executed. The selection mechanism varies between platforms. For generality, our analysis does not make any as7. BDI engines are, in fact, more complicated than this as they can interleave the execution of multiple
active plan instances (or intentions) that were triggered by different events.

77

fiWinikoff & Cranefield

Boolean function execute(an-event)
let relevant-plans = set of plan instances resulting from
matching all plans event patterns to an-event
let tried-plans = 
while true do
let applicable-plans = set of plan instances resulting from
solving the context conditions of relevant-plans
applicable-plans := applicable-plans \ tried-plans
if applicable-plans is empty then return false
select plan p  applicable-plans
tried-plans := tried-plans  {p}
if execute(p.body) = true then return true
endwhile
Boolean function execute(plan-body)
if plan-body is empty then return true
elseif execute(first(plan-body)) = false then return false
else return execute(rest(plan-body))
endif
Boolean function execute(action)
attempt to perform the action
if action executed successfully then return true else return false endif

Figure 2: BDI Execution Cycle
sumptions about plan selection. The plans body may create additional events that
are handled using this process.
5. If the plan body fails, then failure handling is triggered.
For brevity, in the remainder of the paper we will use the term plan loosely to mean
either a plan or plan instance where the intention is clear from context.
Regarding the final step, there are a few approaches to dealing with failure. Perhaps
the most common approach, which is used in many of the existing BDI platforms, is to
select an alternative applicable plan, and only consider an event to have failed when there
are no remaining applicable plans. In determining alternative applicable plans one may
either consider the existing set of applicable plans, or re-calculate the set of applicable
plans (ignoring those that have already been tried), as is done in Figure 2. This makes
sense because the situation may have changed since the applicable plans were determined.
Many (but not all) BDI platforms use the same failure-handling mechanism of retrying
plans upon failure, and our analysis applies to all of these platforms.
One alternative failure-handling approach, used by Jason (Bordini et al., 2007), is to
post a failure event that can be handled by a user-provided plan. Although this is more
flexible, since the user can specify what to do upon failure, it does place the burden of
78

fiOn the Testability of BDI Agent Systems

specifying failure handling on the user. Note that Jason provides a pattern that allows the
traditional BDI failure-handling mechanism to be specified succinctly (Bordini et al., 2007,
pp. 171172). Another alternative failure-handling approach is used by 2APL (Dastani,
2008) and its predecessor, 3APL: they permit the programmer to write plan repair rules
which conditionally rewrite a (failed) plan into another plan. This approach, like Jasons,
is quite flexible, but is not possible to analyse in a general way because the plan rules can
be quite arbitrary. Another well known BDI architecture is IRMA, which is described at a
high-level and does not prescribe a specific failure-handling mechanism:
A full development of this architecture would have to give an account of the
ways in which a resource-bounded agent would monitor her prior plans in the
light of changes in belief. However this is developed, there will of course be
times when an agent will have to give up a prior plan in light of a new belief
that this plan is no longer executable. When this happens, a new process of
deliberation may be triggered (Bratman et al., 1988).
Given the BDI execution cycle discussed above, the three example plans given earlier
(Figure 1) can give rise to a range of behaviours, including the following:
 Suppose the event achieve goal go-home is posted and the agent believes that a
train is imminent. It walks to the train station, finds out that the train is running on
time, catches the train, and then walks home.
 Suppose that upon arrival at the train station the agent finds out that trains are
delayed. Step (2) of Plan A fails, and the agent considers alternative plans. If it is
raining at the present time, then Plan B is not applicable, and so Plan C is adopted
(to catch the bus).
 Suppose that the agent has decided to catch the bus (because no train is believed to
be imminent, and it is raining), and that attempting to execute Plan C fails (e.g. there
is a bus strike). The agent will reconsider its plans and if the rain has stopped (and
it has a bicycle) it may then use Plan B.
Note that correct (respectively incorrect) behaviour is distinct from successful
(respectively failed) execution of a plan. Software testing is in essence the process of running a system and checking whether an observed behaviour trace is correct (i.e. conforms
to a specification, which we do not model). On the other hand, BDI agents behaviour traces
are classified as being successful or failed. However, the correctness of a given execution
trace is independent of whether the trace is of a successful or failed execution. A successful
execution may, in fact, exhibit behaviour that is not correct, for instance, a traffic controller
agent may successfully execute actions that set all traffic signals at an intersection to green
and achieve a goal by doing so. This is a successful execution, but incorrect behaviour. It is
also possible for a failed execution to be correct. For instance, if a traffic controller agent is
attempting to route cars from point A to point B, but a traffic accident has blocked a key
bridge between these two points, then the rational (and correct) behaviour for the agent is
to fail to achieve the goal.
79

fiWinikoff & Cranefield

3. BDI Execution as Goal-Plan Tree Expansion
BDI execution, as summarised in Figure 2, is a dynamic process that progressively executes
actions as goals are posted. In order to more easily analyse this process, we now present an
alternative view that is more declarative. Instead of viewing BDI execution as a process,
we view it as a data transformation from a (finite) goal-plan tree into a sequence of action
executions.
The events and plans can be visualised as a tree where each goal8 has as children the
plan instances that are applicable to it, and each plan instance has as children the sub-goals
that it posts. This goal-plan tree is an and-or tree: each goal is realised by one of its plan
instances (or) and each plan instance needs all of its sub-goals to be achieved (and).
Viewing BDI execution in terms of a goal-plan tree and action sequences makes the
analysis of the behaviour space size9 easier. We consider BDI execution as a process of taking
a goal-plan tree and transforming it into a sequence recording the (failed and successful)
executions of actions, by progressively making decisions about which plans to use for each
goal and executing these plans.
This process is non-deterministic: we need to choose a plan for each goal in the tree.
Furthermore, when we consider failure, we need to consider for each action whether it fails
or not, and if it does fail, what failure recovery is done.
We now define the transformation process in detail. Prolog code implementing the
process can be found in Figure 3. It defines a non-deterministic predicate exec with its first
argument being the (input) goal-plan tree, and the second argument an (output) sequence
of actions. A goal-plan tree is represented as a Prolog term conforming to the following
simple grammar (where GPT abbreviates Goal-Plan Tree, AoGL abbreviates Action or
Goal List, and A is a symbol):
hGPT i ::= goal([]) | goal([hPlanListi])
hPlanListi ::= hPlani | hPlani,hPlanListi
hPlani ::= plan([]) | plan([hAoGLi])
hAoGLi ::= act(A) | hGPT i | act(A),hAoGLi | hGPT i,hAoGLi
For example, the simple goal-plan tree shown in Figure 4 is modelled by the Prolog term
goal([plan([act(a)]), plan([act(b)])]).
In our analysis we make a simplifying assumption. Instead of modelling the instantiation
of plans to plan instances, we assume that the goal-plan tree contains applicable plan
instances. Thus, in order to transform a goal node into a sequence of actions we (nondeterministically) select one of its applicable plan instances. The selected plan is then
transformed in turn, resulting in an action sequence (line 2 in Figure 3). When selecting a
plan, we consider the possibility that any of the applicable plans could be chosen, not just
the first plan. This is done because at different points in time different plan instances may
be applicable. We saw an example of this earlier, where Plan A was chosen and failed, then
8. In order to be consistent with existing practice we shall use the term goal rather than event in the
remainder of this paper.
9. In the remainder of this paper we will use the term behaviour space size, rather than the more
cumbersome term number of paths through a BDI program.

80

fiOn the Testability of BDI Agent Systems

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

exec ( goal ([]) ,[]).
exec ( goal ( Plans ) , Trace ) : - remove ( Plans , Plan , Rest ) , exec ( Plan , Trace1 ) ,
( failed ( Trace1 ) -> recover ( Rest , Trace1 , Trace ) ; Trace = Trace1 ).
exec ( plan ([]) , []).
exec ( plan ([ Step | Steps ]) , Trace ) : - exec ( Step , Trace1 ) ,
( failed ( Trace1 ) -> Trace = Trace1 ; continue ( Steps , Trace1 , Trace )).
exec ( act ( Action ) , [ Action ]).
exec ( act ( Action ) , [ Action , fail ]).
failed ( Trace ) : - append (X ,[ fail ] , Trace ).
recover ( Plans , Trace1 , Traces ) : exec ( goal ( Plans ) , Trace2 ) , append ( Trace1 , Trace2 , Traces ).
continue ( Steps , Trace1 , Trace ) : - exec ( plan ( Steps ) , Trace2 ) ,
append ( Trace1 , Trace2 , Trace ).
remove ([ X | Xs ] ,X , Xs ).
remove ([ X | Xs ] ,Y ,[ X | Z ]) : - remove ( Xs ,Y , Z ).

Figure 3: Prolog Code to Expand Goal-Plan Trees
goal
plan

plan

a

b

Figure 4: A Simple Goal-Plan Tree

Plan C was selected (and also failed), and then finally Plan B (which was not applicable
when Plan A failed) was selected.
If the selected plan executes successfully (i.e. the action trace doesnt end with a fail
marker; line 9), then the resulting trace is the trace for the goals execution (line 3). Otherwise, we perform failure recovery (line 10), which is done by taking the remaining plans
and transforming the goal with these plans as options. The resulting action sequence is
appended to the action sequence of the failed plan to obtain a complete action sequence for
the goal.
This process can easily be seen to match that described in Figure 2 (with the exception,
discussed above, that we begin with applicable plans, not relevant plans). Specifically, an
applicable plan is selected and executed, and if it is successful then execution stops. If it
is not successful, then an alternative plan is selected and execution continues (i.e. action
sequences are appended).
In order to transform a plan node we first transform the first step of the plan, which is
either a sub-goal or an action (line 5). If this is successful, then we continue to transform
the rest of the plan, and append the two resulting traces together (lines 6 and 12). If the
first step of the plan is not successful, then the trace is simply the trace of the first step
(line 6); in other words we stop transforming the plan when a step fails. Again, this process
can easily be seen to correspond to plan body execution in Figure 2.
81

fiWinikoff & Cranefield

Finally, in order to transform an action into an action sequence we simply take the
action itself as a singleton sequence (line 7). However, we do need to also take into account
the possibility that an action may fail, and thus a second possibility is the action followed
by a failure indicator (line 8). Again, this process can easily be seen to correspond to action
execution in Figure 2. Note that in our model we dont concern ourselves with why an
action fails: it could be because of a lack of resources, or other environmental issues.
An example of applying this process to two example goal-plan trees can be found in
Appendix A.

4. Behaviour Space Size of BDI Agents
We now consider how many paths there are through a goal-plan tree that is being used by
a BDI agent to realise a goal10 using that tree. We use the analysis of the previous section
as our basis; that is, we view BDI execution as transforming a goal-plan tree into action
traces. Thus, the question of how large the behaviour space is for BDI agents, is answered
by deriving formulae that allow one to compute the number of behaviours, both successful
and unsuccessful (i.e. failed), for a given goal-plan tree.
We make the following uniformity assumptions that allow us to perform the analysis.
These simplifying assumptions concern the form of the goal-plan tree.
1. We assume that all subtrees of a goal or plan node have the same structure. That is,
all of the leaves of the goal-plan tree are the same distance (number of edges) away
from the root of the tree. We can therefore define the depth of a goal-plan tree as
the number of layers of goal nodes it contains. A goal-plan tree of depth 0 is a plan
with no sub-goals, while a goal-plan tree of depth d > 0 is either a plan node with
children that are goal nodes at depth d or a goal node with children that are plan
nodes at depth d  1. Note that this definition of depth is the reverse of the usual
definition (where the depth of the trees root is defined as 0). We use this definition
as it simplifies the presentation of the derivations later in this section.
2. We assume that all plan instances at depth d > 0 have k sub-goals.
3. We assume that all goals have j applicable plan instances. This can be the case if
each goal has j relevant plans, each of which results in exactly one applicable plan
instance, but can also be the case in other ways. For instance, a goal may have 2j
relevant plans, half of which are applicable in the current situation, or a goal may have
a single relevant plan that has j applicable instances. Note that this assumption rules
out the possibility of there being an infinite number of applicable plan instances, which
would be the case if a plans context condition has an infinite number of solutions.
This cannot occur if the context condition is defined in terms of conjunctions over
propositions that refer to a finite belief base. However, it can occur if the agents
context conditions can also make use of a Prolog-like knowledge base (as is the case in
some agent-oriented programming languages, such as Jason or Goal). Nevertheless,
since we deal with applicable plans, we dont model context conditions.
10. We focus on a single goal in our analysis: multiple goals can be treated as the concurrent interleaving
of the individual goals. Multiple agents can also be treated as concurrent interleaving, but some care
needs to be taken with the details where an agent is waiting for another agent to respond.

82

fiOn the Testability of BDI Agent Systems

Figure 5 shows a uniform goal-plan tree of depth 2.
g2

d=2

@
R pj1
p11	 . . . @
..
.
@
	
R
@
g11 . . . gk1
..
.
@
	
R
@
p10 . . . pj0

d=1
d=1
d=0

Figure 5: A uniform goal-plan tree
The assumptions made are clearly unrealistic. This means that we have to consider
the possibility that real agent programs behave quite differently, since they do not meet
these assumptions. We address this issue in a number of ways. Firstly, in Section 4.4
we consider a relaxation of the assumptions by defining semi-uniform trees, in which the
number of available plan instances (j) can vary across different levels of the tree. Secondly,
in Section 5.2 we consider an example of a (non-uniform) goal-plan tree from an industrial
application. We derive the number of paths for this real goal-plan tree and compare it to
the analysis of similarly-sized uniform goal-plan trees to see whether a real (non-uniform)
tree has a significantly lower number of paths than a uniform tree. Finally, in Section 4.7,
we consider the issue of infinite trees by allowing trees to be recursive, and defining the
number of paths (up to a bound on the path length) of a recursive tree.
Our analysis uses the following terminology:
 Our uniformity assumptions mean that the structure of the subtree rooted at a goal
or plan node is determined solely by its depth, and we can therefore denote a goal or
plan node at depth d as gd or pd (respectively).
 We use n4(xd ) to denote the number of successful execution paths of a goal-plan tree
of depth d rooted at x (where x is either a goal g or a plan p). Where specifying d is
not important we will sometimes elide it, writing n4(x).
 Similarly, we use n8(xd ) to denote the number of unsuccessful execution paths of a
goal-plan tree of depth d with root x (either g or p).
 We extend this notation to plan body segments, i.e. sequences x1 ; . . . ; xn where each xi
is a goal or action and ; denotes sequential composition. We abbreviate a sequence
of n occurrences of x by xn (for example, g13 = g1 ; g1 ; g1 ).
4.1 Base Case: Successful Executions
We begin by calculating the number of successful paths through a goal-plan tree in the
absence of failure (and of failure handling). This analysis follows that of Padgham and
Winikoff (2004, pp. 1719).
Roughly speaking, the number of ways a goal can be achieved is the sum of the number
of ways in which its children can be achieved (since the children represent alternatives,
83

fiWinikoff & Cranefield

i.e. the goal is represented by an or node). On the other hand, the number of ways a plan
can be achieved is the product of the number of ways in which its children can be achieved
(since the children must all be achieved, i.e. the plan is represented by an and node).
More precisely, n4(x1 ; x2 ) = n4(x1 ) n4(x2 ); that is, the sequence is successful if both x1 and
x2 are successful.
Given a tree with root g (a goal), assume that each of its j children can be achieved in
n different ways11 ; then, because we select one of the children, the number of ways in which
g can be achieved is jn. Similarly, for a tree with root p (a plan), assume that each of its
k children can be achieved in n different ways, then, because we execute all of its children,
the number of ways in which p can be executed is n    n, or nk . A plan with no children
(i.e. at depth 0) can be executed (successfully) in exactly one way. This yields the following
definition:
n4(gd ) = j n4(pd1 )
n4(p0 ) = 1
n4(pd ) = n4(gd k ) = n4(gd )k
Expanding this definition we obtain
n4(g1 ) = j n4(p0 ) = j 1 = j
k

n4(g2 ) = j n4(p1 ) = j (n4(g1 ) ) = j (j k ) = j k+1
n4(g3 ) = j n4(p2 ) = j (j k+1 )k = j k
n4(g4 ) = j n4(p3 ) = j (j k

2 +k+1

2 +k+1

)k = j k

3 +k 2 +k+1

which can be generalised to:
n4(gd ) = j

Pd1
i=0

ki

If k > 1 this can be simplified using the equivalence k i1 + . . . + k 2 + k + 1 = (k i  1)/(k  1)
to give the following closed form definition: (and if k = 1 we have n4(gd ) = n4(pd ) = j d )
n4(gd ) = j (k
4

n (pd ) = j

d 1)/(k1)

k (kd 1)/(k1)

(1)
(2)

Note that the equation for n4(pd ) assumes that sub-goals are achieved sequentially. If
they are executed in parallel then the number of options is higher, since we need to consider
all possible interleavings of the sub-goals execution. For example, suppose that a plan pd
has two sub-goals, g1d and g2d , where each of the sub-goals has n4(gd ) successful executions,
and each execution has l steps (we assume for ease of analysis that both execution paths
have the same length). The number of ways of interleaving two parallel executions, each of
length l, can be calculated as follows (Naish, 2007, Section 3):


(2 l)!
2l
=
l
(l!) (l!)
11. Because the tree is assumed to be uniform, all of the children can be achieved in the same number of
ways, and are thus interchangeable in the analysis, allowing us to write j n rather than n1 + . . . + nj .

84

fiOn the Testability of BDI Agent Systems

and hence the number of ways of executing pd with parallel execution of subgoals is:
4

4

2



n (pd ) = n (gd )

2l
l



= n4(gd )2

(2 l)!
(l!) (l!)

In the remainder of this paper we assume that the sub-goals of a plan are achieved
sequentially, since this is the common case, and since it yields a lower figure which, as we
shall see, is still large enough to allow for conclusions to be drawn.
4.2 Adding Failure
We now extend the analysis to include failure, and determine the number of unsuccessful
executions, i.e. executions that result in failure of the top-level goal. For the moment we
assume that there is no failure handing (we add failure handling in Section 4.3).
In order to determine the number of failed executions we have to know where failure
can occur. In BDI systems there are two places where failure occurs: when a goal has no
applicable plan instances, and when an action (within an applicable plan instance) fails.
However, our uniformity assumption means that we do not address the former caseit is
assumed that a goal will always have j instances of applicable plans. Note that this is a
conservative assumption: relaxing it results in the number of unsuccessful executions being
even larger.
In order to model the latter case we need to extend our model of plans to encompass
actions. For example, suppose that a plan has a body of the form a1; ga; a2; gb; a3 where ai
are actions, ga and gb are sub-goals, and ; denotes sequential execution. Then the plan
has the following five cases of unsuccessful (i.e. failed) executions:
1. a1 fails
2. a1 succeeds, but then ga fails
3. a1 and ga succeed, but a2 fails
4. a1, ga, and a2 succeed, but then gb fails
5. a1, ga, a2 and gb succeed, but a3 fails
Suppose that ga can be executed successfully in n4(ga) different ways. Then the third
case corresponds to n4(ga) different failed executions: for each successful execution of ga,
extend it by adding a failed execution of a2 (actions can only be executed in one way,
i.e. n4(a) = 1 and n8(a) = 1). Similarly, if gb has n4(gb) successful executions then the fifth
case corresponds to n4(ga) n4(gb) different failed executions. If ga can be unsuccessfully
executed in n8(ga) different ways then the second case corresponds to n8(ga) different executions. Similarly, the fourth case corresponds to n4(ga) n8(gb) different executions. Putting
this together, we have that the total number of unsuccessful executions for a plan p with
body a1; ga; a2; gb; a3 is the sum of those for the above five cases:
1 + n8(ga) + n4(ga) + n4(ga) n8(gb) + n4(ga) n4(gb)
85

fiWinikoff & Cranefield

More formally, n8(x1 ; x2 ) = n8(x1 ) + n4(x1 ) n8(x2 ); that is, the sequence can fail if either
x1 fails, or if x1 succeeds but x2 fails. It follows that n4(xk ) = n4(x)k and n8(xk ) =
n8(x) (1 +    + n4(x)k1 ), which can easily be proven by induction.
More generally, we assume there are ` actions before, after, and between the sub-goals
in a plan, i.e. the above example plan corresponds to ` = 1, and the following plan body
corresponds to ` = 2: a1; a2; g3; a4; a5; g6; a7; a8. A plan with no sub-goals (i.e. at depth
0) is considered to consist of ` actions (which is quite conservative: in particular, when we
use ` = 1 we assume that plans at depth 0 consist of only a single action).
The number of unsuccessful execution traces of a goal-plan tree can then be defined,
based on the analysis above, as follows. First we calculate the numbers of successes and
failures of the following repeated section of a plan body: gd ; a` :
n4(gd ; a` ) = n4(gd ) n4(a` )
= n4(gd ) n4(a)`
= n4(gd ) 1`
= n4(gd )
n8(gd ; a` ) = n8(gd ) + n4(gd ) n8(a` )
= n8(gd ) + n4(gd ) n8(a) (1 +    + n4(a)`1 )
= n8(gd ) + n4(gd ) `
We then have for d > 0:
n8(pd ) = n8(a` ; (gd ; a` )k )
= n8(a` ) + n4(a` ) n8((gd ; a` )k )
= n8(a) (1 +    + n4(a)`1 )) + n4(a)` n8((gd ; a` )k )
= ` + 1 n8(gd ; a` ) (1 +    + n4(gd ; a` )k1 )
= ` + (n8(gd ) + n4(gd ) `) (1 +    + n4(gd )k1 ))
n4(gd )k  1
= ` + (n8(gd ) + ` n4(gd )) 4
(assuming n4(gd ) > 1)
n (gd )  1
This yields the following definitions for the number of unsuccessful executions of a goalplan tree, without failure handling. The equation for n8(gd ) is derived using the same
reasoning as in the previous section: a single plan is selected and executed, and there are j
plans.
n8(gd ) = j n8(pd1 )
n8(p0 ) = `
n4(gd )k  1
n4(gd )  1
4
(for d > 0 and n (gd ) > 1)

n8(pd ) = ` + (n8(gd ) + ` n4(gd ))

Finally, we note that the analysis of the number of successful executions of a goal-plan
tree in the absence of failure handling presented in Section 4.1 is unaffected by the addition
of actions to plan bodies. This is because there is only one way for a sequence of actions to
succeed, so Equations 1 and 2 remain correct.
86

fiOn the Testability of BDI Agent Systems

4.3 Adding Failure Handling
We now consider how the introduction of a failure-handling mechanism affects the analysis.
A common means of dealing with failure in BDI systems is to respond to the failure of a
plan by trying an alternative applicable plan for the event that triggered that plan. For
example, suppose that a goal g (e.g. achieve goal go-home) has three applicable plans pa,
pb and pc, that pa is selected, and that it fails. Then the failure-handling mechanism will
respond by selecting pb or pc and executing it. Assume that pc is selected. Then if pc fails,
the last remaining plan (pb) is used, and if it too fails, then the goal is deemed to have
failed.
The result of this is that, as we might hope, it is harder to fail: the only way a goal
execution can fail is if all of the applicable plans are tried and each of them fails12 .
The number of executions can then be computed as follows: if a goal gd has j applicable plan instances, each having n8(pd1 ) unsuccessful executions, then we have n8(pd1 )j
unsuccessful executions of all of these plans in sequence. Since the plans can be selected in
any order we multiply this by j! yielding n8(gd ) = j! n8(pd1 )j .
The number of ways in which a plan can fail is still defined by the same equation
because failure handling happens at the level of goalsbut where n8(g) refers to the new
definition:
j

n8(gd ) = j! n8(pd1 )

(3)

8

n (p0 ) = `

(4)
4

)k

n (gd  1
n4(gd )  1
4
(for d > 0 and n (gd ) > 1)

n8(pd ) = ` + (n8(gd ) + ` n4(gd ))

(5)

Turning now to the number of successful executions (i.e. n4(x)) we observe that the
effect of adding failure handling is to convert failures to successes, i.e. an execution that
would otherwise be unsuccessful is extended into a longer execution that may succeed.
Consider a simple case: a depth 1 tree consisting of a goal g (e.g. achieve goal go-home)
with three children: pa, pbandpc. Previously the successful executions corresponded to each
of the pi (i.e. select a pi and execute it). However, with failure handling, we now have
the following additional successful executions (as well as additional cases corresponding to
different orderings of the plans, e.g. pb failing and then pa being successfully executed):
 pa fails, then pb is executed successfully
 pa fails, pb is then executed and fails, and then pc is executed and succeeds
This leads to a definition of the form
n4(g) = n4(pa) + n8(pa) n4(pb) + n8(pa) n8(pb) n4(pc)
12. In fact, this is actually an underestimate: it is also possible for the goal to fail because none of the untried
relevant plans are applicable in the resulting situation. As noted earlier, we assume in our analysis that
goals cannot fail as a result of there being no applicable plan instances. This is a conservative assumption:
relaxing it results in the number of behaviours being even larger.

87

fiWinikoff & Cranefield

However, we need to account for different orderings of the plans. For instance, the case
where the first selected plan succeeds (corresponding to the first term, n4(pa)) in fact applies
for each of the j plans, so the first term, including different orderings, is j n4(p).
Similarly, the second term (n8(pa) n4(pb)), corresponding to the case where the initially
selected plan fails but the next plan selected succeeds, in fact applies for j initial plans, and
then for j  1 next plans, yielding j (j  1) n8(p) n4(p).
Continuing this process (for j = 3) yields the following formulae:
2

n4(g) = 3 n4(p) + 32 n8(p) n4(p) + 3! n8(p) n4(p)
which generalises to
j1

n4(g) = j n4(p) + j (j  1) n8(p) n4(p) +    + j! n8(p)

n4(p)

resulting in the following equations (again, since failure handling is done at the goal level,
the equation for plans is the same as in Section 4.1):
4

n (gd ) =

j
X

i1

n8(pd1 )

n4(pd1 )

i=1

n4(p0 ) = 1
4

j!
(j  i)!

(6)
(7)

4

n (pd ) = n (gd )

k

(for d > 0 )

(8)

We have used the standard BDI failure-handling mechanism of trying alternative
applicable plans. Now let us briefly consider an alternative failure-handling mechanism
that simply re-posts the event, without tracking which plans have already been attempted.
It is fairly easy to see that this, in fact, creates an infinite number of behaviours: suppose
that a goal g can be achieved by pa or pb, then pa could be selected, executed resulting
in failure, and then pa could be selected again, fail again, etc. This suggests that the
standard BDI failure-handling mechanism is, in fact, more appropriate, in that it avoids
an infinite behaviour space, and the possibility of an infinite loop. As discussed earlier (in
Section 2), the failure recovery mechanism used by 3APL and 2APL (Dastani, 2008) cannot
be analysed in a general way, since it depends on the details of the specific agent program;
and IRMA (Bratman et al., 1988) does not provide sufficient details to allow for analysis.
Tables 1 and 2 make the various equations developed so far concrete by showing illustrative values for n8 and n4 for a range of reasonable (and fairly low) values for j, k and
d and using ` = 1. The Number of columns show the number of goals, plans and actions in the tree. The number of actions in brackets is how many actions are executed in a
single (successful) execution with no failure handling. The number of goals is calculated
as follows. At depth 1 there is a single goal (see Figure 5). At depth n + 1 there are
1 + (j  k  G(n)) goals, where G(n) denotes the number of goals in a depth n tree. This
gives G(n) = 1 + (j  k) + (j  k)2 +    + (j  k)n1 . For example, for j = k = 2, we have
G(3) = 1 + 4 + 16 = 21. Since each goal has exactly j plans, the number of plans in a tree
of depth n is just j  G(n). We now consider the number of actions. Each non-leaf plan has
`  (k + 1) actions (since it has k goals, there are k + 1 places where there are ` actions).
Each leaf plan has ` actions. A tree of depth n has j  (j  k)n1 leaf plans. Let P (n)
be the number of plans in a depth n tree, which is comprised of Pn (n) non-leaf plans and
88

fiOn the Testability of BDI Agent Systems

Parameters
j k
d
2 2
3
3 3
3
2 3
4
3 4
3

goals
21
91
259
157

Number
plans
42
273
518
471

of
actions
62 (13)
363 (25)
776 (79)
627 (41)

n4(g)
128
1,594,323

n8(g)
614
6,337,425

1,099,511,627,776

6,523,509,472,174

10,460,353,203

41,754,963,603

Table 1: Illustrative values for n4(g) and n8(g) without failure handling. The first number under actions (e.g. 62) is the number of actions in the tree, the second
(e.g. 13) is the number of actions in a single execution where no failures occur.

Parameters
j k
d
2 2
3
3 3
3
2 3
4
3 4
3

goals
21
91
259
157

Number
plans
42
273
518
471

of
actions
62 (13)
363 (25)
776 (79)
627 (41)

n4(g)
 6.33  1012
 1.02  10107
 1.82  10157
 3.13  10184

n8(g)
 1.82  1013
 2.56  10107
 7.23  10157
 7.82  10184

Table 2: Illustrative values for n4(g) and n8(g) with failure handling
Pl (n) leaf plans, i.e. P (n) = Pn (n) + Pl (n). Then the number of actions in a depth n tree
is (`  (k + 1))  Pn (n) + `  Pl (n). For example, for j = k = 2 and ` = 1, we have that
P (3) = 2  G(3) = 42, which is comprised of 32 leaf plans and 10 non-leaf plans. There are
therefore (1  3  10) + (1  32) = 62 actions.
4.4 Recurrence Relations
The equations in the previous sections define the functions n4 and n8 as a mutual recurrence
on the depth d of a goal-plan tree with a uniform branching structure. The effect of
increasing the parameters k and ` is evident at each level of the recursion, but it is not
so clear what the effect is of increasing the number of applicable plan instances j for any
given goal. The aim of this section is to explore the effects of changing j. We do this by
relaxing our uniformity assumption. Specifically, we allow the number of plans available to
vary for goal nodes at different depths in the tree, while still assuming that all nodes at a
given depth have the same structure. We refer to these as semi-uniform goal-plan trees.
We then derive a set of recurrence relations for n4 and n8 in the presence of failure handling
that explicitly show the effect of adding a new plan for a goal at the root of any particular
sub-tree.
We begin by defining the generalised notation n8(gj ) and n4(gj ) where j is a list13
(jd , jd1 , . . . , j0 ) in which each element ji represents the number of plans available for goals
at depth i of the goal-plan tree. We denote the empty list by hi and write j  j to represent
the list with head j and tail j.
13. The order corresponds to our definition of depth, which decreases down the tree.

89

fiWinikoff & Cranefield

We can generalise Equations 3 and 6 to apply to semi-uniform goal-plan trees, as the
derivation of these equations depended only on the sub-nodes of each goal or plan node
having the same structure. This assumption is preserved in this generalised setting. We
therefore rewrite these equations below using this new notation, and also express the right
hand sides as functions f 8 and f 4 of n8(pj ) and (for f 4 ) n4(pj ). Our aim is to find a recursive
definition of f 8 and f 4 as a recurrence on j.
n8(gjj ) = f 8 (j, n8(pj ))
n4(gjj ) = f 4 (j, n8(pj ), n4(pj ))
where
f 8 (j, a) = j! aj
f 4 (j, a, b) =

j
X

b ai1

i=1

j!
(j  i)!

(change bounds on i to 0 . . . n, hence replace i by i + 1)
=

j1
X

b a(i+1)1

i=0

j!
(j  (i + 1))!

(simplify using (j  (i + 1))! = (j  i)!/(j  i) )
=

j1
X
i=0

b ai

j!(j  i)
(j  i)!

(multiple by i!/i! and reorder)
=

j1
X
i=0

j!
i! ai (j  i) b
i!(j  i)!

 
j
(use definition of binomial:
= j!/i!(j  i)!)
i
j1  
X
j
i! ai (j i) b
=
i

(9)

i=0

The expression on the right of the last line above corresponds to the following combinatorial analysis of f 4 . For a goal gjj , each successful execution will involve a sequence of
i plan executions thatfail (for some i, 0  i  j  1) followed by one plan execution that
succeeds. There are ji ways of choosing the failed plans, which can be ordered in i! ways,
and each plan has a = n8(pj ) ways to fail. There are then j i ways of choosing the final
successful plan, which has b = n4(pj ) ways to succeed.
Our goal is now to find an explicit characterisation of the incremental effect of adding an
extra plan on n8(gjj ) and n4(gjj ) by finding definitions of f 8 and f 4 as recurrence relations
in terms of the parameter j. Deriving the recurrence relation for f 8 is straightforward:
f 8 (j, a) = j! aj = (j (j  1) . . . 21) (a
. . a a}) = (j a) ((j  1) a) . . . (2 a) (1 a)
| a .{z
j times
90

fiOn the Testability of BDI Agent Systems

n4(gjj ) = f 4 (j, n8(pj ), n4(pj ))
n8(gjj ) = f 8 (j, n8(pj ))
f 4 (0, a, b) = 0
f 4 (j +1, a, b) = (j +1) (b + a f 4 (j, a, b))

(10)

8

f (0, a) = 1
8

f (j +1, a) = (j +1) a f 8 (j, a)
n4(phi ) = 1
n8(phi ) = `
n4(pj ) = n4(gj )k , for j 6= hi
 n4(gj )k  1
, for j 6= hi
n8(pj ) = ` + n8(gj ) + ` n4(gj )
n4(gj )  1
Figure 6: Recurrence relations for the numbers of failures and successes of a goal plan tree
in the presence of failure handling

This shows that f 8 (0, a) = 1 and f 8 (j +1, a) = (j +1) a f 8 (j, a)
However, the derivation of a recurrence relation for f 4 is not as simple. Here we use
the technique of first finding an exponential generating function (e.g.f.) (Wilf, 1994) for the
sequence {f 4 (j, a, b)}
j=0 , and then using that to derive a recurrence relation. The details
are given in Appendix B, and yield equation 10 in Figure 6.
Equation 10 (copied from Equation 25 in Appendix B) gives us the recurrence relation
14
for the sequence {f 4 (j, a, b)}
j=0 that we have been seeking . Figure 6 brings together the
equations we have so far for the failure-handling case (including those from the previous
section defining n4(pd ) and n8(pd ), generalised for semi-uniform trees).
This formulation gives us a different way of looking at the recurrence, and allows us to
more easily see how the behaviour space grows as the number of applicable plans, j, for a
goal grows. Considering the meaning of the parameters a and b as the numbers of failures
and successes (respectively) of a plan at a level below the current goal node, the equation
for f 4 (j +1, a, b) can be seen to have the following combinatorial interpretation. One plan
must be selected to try initially (there are j +1 choices) and it can either succeed (in one
of b different ways), meaning no further plans need to be tried, or fail (in one of a different
ways). If it fails, then the goal must then succeed using the remaining j plans, which can
occur in f 4 (j, a, b) ways.
We can see that the growth in the number of successful executions for a goal grows at
a rate greater than j!aj , because of the presence of the b term. The relaxed uniformity
14. In the simple case when a = b = 1 this is listed as sequence A007526 in the On-Line Encyclopedia of
Integer Sequences (Sloane, 2007): the number of permutations of nonempty subsets of {1,    , n}.

91

fiWinikoff & Cranefield

constraint used in these recurrence relations also gives us a way to investigate the numbers
of traces for goal-plan trees of different semi-uniform shapes. However, in the remainder of
this paper we will focus on uniform trees using our original parameter j (with the exception
of Section 4.7).
4.5 The Probability of Failing
In Section 4.3 we said that introducing failure handling makes it harder to fail. However,
Tables 1 and 2 appear at first glance to contradict this, in that there are many more ways
of failing with failure handling than there are without failure handling.
The key to understanding the apparent discrepancy is to consider the probability of
failing: Tables 1 and 2 merely count the number of possible execution paths, without
considering the likelihood of a particular path being taken. Working out the probability of
failing (as we do below) shows that although there are many more ways of failing (and also
of succeeding), the probability of failing is, indeed, much lower.
Let us denote the probability of an execution of a goal-plan tree with root x and depth
d failing as p8(xd ), and the probability of it succeeding as p4(xd ) = 1  p8(xd ).
We assume that the probability of an action failing is a 15 . Then the probability of a
given plans actions all succeeding is simply (1  a )x where x is the number of actions.
Hence the probability of a plan failing because of the failure of (one of) its actions is simply
1  (1  a )x , i.e. for a plan at depth 0 the probability of failure is:
0 = 1  (1  a )`
and for a plan at depth greater than 0 the probability of failure due to actions is:
 = 1  (1  a )` (k+1)
(recall that such a plan has ` actions before, after, and between, each of its k sub-goals).
Considering not only the actions but also the sub-goals g1 , . . . , gk of a plan p, we have
that for the plan to succeed, all of the sub-goals must succeed, and additionally, the plans
actions must succeed giving p4(pd ) = (1  ) p4(gd )k . We can easily derive from this an
equation for p8(pd ) (given below). Note that the same reasoning applies to a plan regardless
of whether there is failure handling, because failure handling is done at the goal level.
In the absence of failure handling, for a goal g with possible plans p1 , . . . , pj to succeed
we must select one plan and execute it, so the probability of success is the probability of
that plan succeeding, i.e. p4(gd ) = p4(pd1 ). We ignore for the moment the possibility of a
goal failing because there are no applicable plans. This assumption is relaxed later on.
Formally, then, we have for the case without failure handling:
p8(gd ) = p8(pd1 )
p8(p0 ) = 0
k

p8(pd ) = 1  [(1  ) (1  p8(gd )) ]
15. For simplicity, we assume that the failure of an action in a plan is independent of the failure of other
actions in the plan.

92

fiOn the Testability of BDI Agent Systems

a
0.05

0.01

d
2
3
4
2
3
4

No failure handling
30%
72%
98%
07%
22%
55%

With failure handling
0.64%
0.81%
0.86%
0.006%
0.006%
0.006%

Table 3: Goal failure probabilities with and without failure handling
Now consider what happens when failure handling is added. In this case, in order for
a goal to fail, all of the plans must fail, i.e. p8(gd ) = p8(pd1 )j . Since failure handling is at
the goal level, the equation for plans is unchanged, giving:
p8(gd ) = p8(pd1 )j
p8(p0 ) = 0
k

p8(pd ) = 1  [(1  ) (1  p8(gd )) ]
It is not easy to see from the equations what the patterns of probabilities actually are,
and so, for illustration purposes, Table 3 shows what the probability of failure is, both with
and without failure handling, for two scenarios. These values are computed using j = k = 3
(i.e. a relatively small branching factor) and with ` = 1. We consider two cases: where
a = 0.05 and hence   0.185 (which is rather high), and where a = 0.01 and hence
  0.04.
As can be seen, without failure handling, failure is magnified : the larger the goalplan tree is, the more actions are involved, and hence the greater the chance of an action
somewhere failing, leading to the failure of the top-level goal (since there is no failure
handling). On the other hand, with failure handling, the probability of failure is both low,
and doesnt appear to grow significantly as the goal-plan tree grows.
We now relax the assumption that a goal cannot fail because there are no applicable
plans, i.e. that a goal will only fail once all plans have been tried. Unfortunately, relaxing
this assumption complicates the analysis as we need to consider the possibility that none
of the remaining plans are applicable at each point where failure handling is attemped.
Let us begin by reconsidering the case where there is no failure handling. We use g to
denote the probability of a goal failing because none of the remaining plans are applicable.
For the case with no failure handling a non-zero g indicates that there are situations
where a goal does not have applicable plans, which may indicate an error on the part of
the programmer, or that in certain situations a goal may not be possible to achieve. We
assume, for analysis purposes, that this probability is constant, and in particular, that it
does not depend on which plans have already been tried nor on the number of relevant
plans remaining.
Then the probability of a goal failing is p8(gd ) = g + (1  g ) p8(pd1 ), i.e. the goal fails
either because no plans are applicable or because there are applicable plans and the selected
plan fails. As before, the equation for plans is unchanged, since failure handling is done at
93

fiWinikoff & Cranefield

the goal level. We now have the following equations for the case without failure handling:
p8(gd ) = g + (1  g ) p8(pd1 )
p8(p0 ) = 0
k

p8(pd ) = 1  [(1  ) (1  p8(gd )) ]
Observe that setting g = 0 yields the equations derived earlier, where we assumed that a
goal cannot fail due to inapplicable plans.
We now consider the probability of failure with failure handling. For a goal with two
plans we have the following cases:
 The goal can fail because no plans are applicable (g )
 If there are applicable plans ((1  g ) . . .) then the goal can fail if the first selected
plan fails (p8(pd1 ) . . .) and if failure handling is not successful, which can occur if
either there are no applicable plans (g ) or if there are applicable plans ((1  g ) . . .)
and the selected plan fails (p8(pd1 )).
Putting this together, for a goal with two plans we have:
p8(gd ) = g + (1  g ) p8(pd1 ) (g + (1  g ) p8(pd1 ))
In the general case of j available plans, we have that a goal can fail if:
A. there are no applicable plans at the outset, with probability g , or
B. there are applicable plans (1  g ), but the selected plan fails (p8(pd1 )) and then
either there are no further applicable plans (g ), or
C. there are applicable plans (1  g ), but the selected plan fails (p8(pd1 )) and then
either there are no further applicable plans (g ),
D. and so on: the reasoning of B is repeated j times.
This gives a definition of the following form:
g + (1  g ) p8(pd1 ) (g + (1  g ) p8(pd1 ) (g + . . .g ))
|{z} |
{z
}|
{z
} |{z}
B
C
D
A
This can be defined in terms of an auxiliary function p8(gd , i) which defines the probability
of failure for goal g at depth d where there are i remaining relevant plan instances that may
(or may not) yield any applicable plan instances:
p8(gd ) = p8(gd , j)
p8(gd , 1) = g + (1  g ) p8(pd1 )
p8(gd , i + 1) = g + (1  g ) p8(pd1 ) p8(gd , i)
p8(p0 ) = 0
k

p8(pd ) = 1  [(1  ) (1  p8(gd )) ]
94

fiOn the Testability of BDI Agent Systems

a
0.05

a
0.01

d
2
3
4
d
2
3
4

No failure handling
g = 0
g = 0.01 g = 0.05
30%
33%
43%
72%
76%
86%
98%
99%
100%
g = 0 g = 0.005 g = 0.01
7%
9%
10%
22%
27%
32%
55%
63%
70%

With failure handling
g = 0
g = 0.01 g = 0.05
0.64%
2.2%
9.4%
0.81%
2.6%
12.8%
0.86%
2.8%
16.5%
g = 0 g = 0.005 g = 0.01
0.006%
0.5%
1.1%
0.006%
0.6%
1.1%
0.006%
0.6%
1.1%

Table 4: Goal failure probabilities with and without failure handling when goals can have
no applicable plans

Observe that setting g = 0 reduces this to the definition derived earlier, since g +(1g ) X
simplifies to X, and hence p8(gd , i) = p8(pd1 )i .
As before, it is not immediately clear from the formulae what the actual patterns of
probability are. Considering illustrative examples, Table 4 shows that (a) the overall behaviour is the same as before, and (b) if g is assumed to be relatively low compared with the
probability of action failure ( and 0 ), then it doesnt significantly affect the probabilities.
4.6 Analysis of the Rate of Failures
In this section we briefly examine how the number of traces for a goal-plan tree is affected by
placing a bound on the rate of action failures that can occur within a trace. For simplicity,
we work with uniform goal-plan trees, but the construction below extends trivially to semiuniform goal-plan trees.
In Figure 6 we presented equations for calculating the total number of behaviours for a
goal-plan tree (with failure handling). But how many of these behaviours involve a possibly
unrealistic number of action failures? If we make an assumption that there is an upper
limit to the rate of action failures16 , i.e. the number of failures divided by the length of the
trace, how does this affect the number of possible behaviours? Do the large numbers that
we have seen reduce significantly?
For instance, considering j = k = 2, ` = 1 and d = 2, there are 1,922 possible executions
that result in failure. How many of these involve a high rate of action failure and how many
involve only a small percentage of failures? Figure 7 contains (cumulative) counts that
were generated by looking at all possible executions in this (small) case, plotted against the
number of action failures. The x axis shows for a given value N  {0, . . . , 6} how many
traces there are that have N or fewer action failures. For instance, for N = 2, there are 426
traces that have 2 or fewer action failures. Of these 426 traces, 328 are successful and 98 are
unsuccessful. Figure 8 shows the equivalent graph for the rate of action failure: each trace
has its failure rate computed (the number of failures divided by the length of the trace),
16. Bounding the rate of action failures allows us to model an assumption that the environment has limited
unpredictability, or perhaps that the programmer has limited incompetence!

95

fiWinikoff & Cranefield

ok"

failed"

both"

3500"

Number'of'traces'(cumula0ve)'

3000"

2500"

2000"

1500"

1000"

500"

0"

0"

1"

2"

3"

4"

5"

6"

ok"

8"

80"

328"

704"

960"

1024"

1024"

failed"

0"

0"

98"

546"

1282"

1794"

1922"

both"

8"

80"

426"

1250"

2242"

2818"

2946"

Number'of'failures'

Figure 7: Number of traces (cumulative) vs. number of failures for j = k = 2, ` = 1, d = 2
3500

3000

Number of traces (cumulative)

2500

2000

1500

1000

500

0
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Failure Rate

Figure 8: Number of traces (cumulative) vs. failure rate for j = k = 2, ` = 1, d = 2

96

fiOn the Testability of BDI Agent Systems

and the number of traces are counted for each range of failure rate. For instance, the first
data point in the graph shows that there are 40 traces with a failure rate  0.1.
The question is how to generalise this analysis for larger execution spaces. Clearly,
counting all possible executions is not feasible. Instead, we turn to generating functions.
For a given plan body segment17 s (and particularly for s = gd ), we are interested in
computing the numbers of successful and failed traces in which the failure rate is bounded
by a given ratio r between the number of failed actions and the total number of actions,
i.e. the proportion of actions in an execution trace that fail. We denote these by n4r(s)
and n8r(s). To compute these values, we first determine for integers m > 0 and n  0 the
numbers of successful and failed traces that have length m and contain exactly n action
failures, denoted n4r(s, m, n) and n8r(s, m, n), respectively. We define the length of a trace
to be the number of actions (both successful and unsuccessful) that it contains. Note that
for any finite goal-plan tree, such as a uniform or semi-uniform one, there is a maximum
possible trace length and so n4r(s, m, n) and n8r(s, m, n) can only be non-zero for a finite
number of integer pairs (m, n) in the positive quadrant of the plane or on the positive m
axis (in the case that n = 0). Once we have these values, we can calculate n4r(s) as the
n
 r, and similarly for n8rs using n8r(s, m, n).
sum of all n4r(s, m, n) for which m
We begin by considering ordinary 18 and bivariate generating functions (Wilf, 1994) for
the values n4r(s, m, n) and n8r(s, m, n):
4

Fr (s, x, y) =
Fr8(s, x, y) =

 X

X

n4r(s, m, n) xm y n

m=0 n=0
 X

X

n8r(s, m, n) xm y n

m=0 n=0

An action a has one successful execution, which has length 1 and contains no action
failures, so Fr4(a, x, y) = x (a power series with the coefficient of x1 y 0 being 1 and all other
coefficients being 0). Similarly, Fr8(a, x, y) = x1 y 1 = xy, as there is one failed execution,
which has length 1 and one action failure.
We now consider Fr4(s1 ; s2 ):
Fr4(s1 ; s2 , x, y) =
=

 X

X

n4r(s1 ; s2 , m, n) xm y n

m=0 n=0
 X
 
X
m=0 n=0

X

X


nr(s1 , p, t) nr(s2 , q, u) xm y n
4

4

p+q=m t+u=n

The double sum in parentheses considers, for any trace, all possible ways of allocating
the number of actions m and number of action failures n to the (necessarily) successful
executions of s1 and s2 , and the sums are over non-negative integer values of p, q, t and u.
17. Recall that, as defined towards the start of Section 4 (page 83), a plan body segment s is a sequence
x1 ; . . . ; xn where each xi is either a goal or an action.
18. Ordinary generating functions differ from exponential generating functions by not including denominators
that are factorials of the powers of the variable(s).

97

fiWinikoff & Cranefield

We then have:
Fr4(s1 ; s2 , x, y) =
=


 X
X
X X

n4r(s1 , p, t) xp y t n4r(s2 , q, u) xq y u

m=0 p+q=m n=0 t+u=n
 X
 X
 X

X

n4r(s1 , p, t) xp y t n4r(s2 , q, u) xq y u

p=0 q=0 t=0 u=0

X
X

 X

 X

4
p t
4
q u
=
nr(s1 , p, t) x y
nr(s2 , q, u) x y
p=0 t=0

q=0 u=0

4

4

= Fr (s1 , x, y) Fr (s2 , x, y)
P
P P
P
The second line above is derived using the identity 
q
p
m=0
p+q=m f (p, q) =
f (p, q). Both expressions sum over all non-negative integers p and q, but the first expression
does this by first summing over all non-negative values m on the horizontal axis, and then
summing over all pairs (p, q) of non-negative integers lying on a line with slope 1 that
intersects the horizontal axis at m.
Considering Fr8(s1 ; s2 , x, y), we have:
Fr8(s1 ; s2 , x, y) =
=

 X

X

n8r(s1 ; s2 , m, n) xm y n

m=0 n=0
 X
 
X

n8r(s1 , m, n)

m=0 n=0

+

=

X

X



nr(s1 , p, t) nr(s2 , q, u) xm y n
4

8

p+q=m t+u=n


XX

n8r(s1 , m, n) xm y n

m=0 n=0
 X
 
X

+

m=0 n=0

X

X


nr(s1 , p, t) nr(s2 , q, u) xm y n
4

8

p+q=m t+u=n

8

= Fr (s1 , x, y)
X
 X

 X

 X

+
n4r(s1 , p, t) xp y t
n8r(s2 , q, u) xq y u
p=0 t=0

q=0 u=0

= Fr8(s1 , x, y) + Fr4(s1 , x, y) Fr8(s2 , x, y)
The second line above is based on the observation that each failed execution of s1 ; s2 of
length m and with n action failures is either a failed execution of s1 of length m and with n
action failures occurring in that execution, or is a successful execution of s1 of length p and
with t failures followed by a failed execution of s2 of length q and with u failures, where
p + q = m and t + u = n.
Now, assuming that we know Fr4(gd , x, y) and Fr8(gd , x, y) for some depth d, we can
construct the functions Fr4(pd , x, y) and Fr8(pd , x, y) by applying the results above to expand
the right hand sides of the following equations (which simply replace pd with its plan body):
98

fiOn the Testability of BDI Agent Systems

Fr4(pd , x, y) = Fr4(a` ; (gd ; a` )k , x, y)
Fr8(pd , x, y) = Fr8(a` ; (gd ; a` )k , x, y)

It remains to define Fr4(gd , x, y) and Fr8(gd , x, y) in terms of Fr4(pd1 , x, y) and Fr8(pd1 ,
x, y). To count the successful executions of gd of length m and with n action failures, we
must first choose one of the j applicable plans to be the one that ultimately succeeds. We
must then choose between 0 and j1 of the remaining applicable plans that were tried but
failed, and consider all possible orderings of these plans. The m actions in the trace and
the n action failures must be distributed across the failed and successful plans. This leads
us to the following derivation of a procedure to construct Fr4(gd , x, y):
Fr4(gd , x, y)
 X

X
=
n4r(gd , m, n) xm y n
m=0 n=0

=

 X

X


j

m=0 n=0

= j

p=0


j1 
X
j 1
p

p=0

= j


j1 
X
j 1

p!

p

X

p!

X

n4r(pd1 , `0 , f0 )

p
Y


X

X


m=0 n=0

n8r(pd1 , `i , fi ) xm y n

i=1

`0 ++`p =m f0 ++fp =n

 X

X



n4r(pd1 , `0 , f0 )

p
Y


n8r(pd1 , `i , fi ) xm y n

i=1

`0 ++`p =m f0 ++fp =n

j1 
X
p=0

 X
 X
p
 X

 X

j 1
4
` f
8
` f
p!
nr(pd1 , `, f ) x y
nr(pd1 , `, f ) x y
p
`=0 f =0

`=0 f =0


j1 
X
j 1
= j
p! Fr4(pd1 , x, y) Fr8(pd1 , x, y)p
p
p=0

Constructing Fr8(gd , x, y) is simpler. A failed execution of a goal involves failed attempts
to execute all j applicable plans. All j! orderings of these plans must be considered. This
gives us the following construction for Fr8(gd , x, y):
Fr8(gd , x, y) =
=

 X

X

n8r(gd , m, n) xm y n

m=0 n=0
 X
 
X

X

j!

m=0 n=0

= j!

X
 X


X

`1 ++`j =m f1 ++fj =n
8

` f

nr(pd1 , `, f ) x y

`=0 f =0

= j! Fr8(pd1 , x, y)j
99

j



nr(pd1 , `1 , f1 )    nr(pd1 , `j , fj ) xm y n
8

8

fiWinikoff & Cranefield

The equations above define a recursive procedure for computing Fr4(gd , x, y) and Fr8(gd ,
x, y) for given values of d, j, k and `. As discussed earlier in this section, given a way of
n
calculating n4r(s, m, n), we can calculate n4r(s) as a sum of all n4r(s, m, n) for which m
 r,
8
and similarly for nrs. We have used the Python rmpoly and GMPY2 libraries to generate
polynomial representations of the functions Fr4(gd , x, y) and Fr8(gd , x, y) for any specified
values of d, j, k and l, and to calculate n4r(s) and n8r(s) for various ratios r19 . Figure 9
shows the results for d = j = k = 3 and ` = 1.
Examining Figure 9 we can conclude two things. On the one hand, the number of traces
really explodes for larger rates of action failures. For example, in Figure 9 most traces have
a failure rate greater than 0.4. On the other hand, although making assumptions about the
failure rate does reduce the number of possible traces, the number of traces is still quite
large (note the scale on the y-axis). For instance, for a failure rate of  0.1 there are around
4.8  1044 failed executions and 8.7  1047 successful executions. For a failure rate of  0.2
the respective numbers are 1.0  1077 and 6.7  1077 , and for a failure rate of  0.3 they
are 1.2  1096 and 2.7  1096 .
The shape of Figure 9 can be explained as follows. Firstly, the occurrence of an action
failure triggers further activity (alternative plans), so more failures result in longer traces.
Secondly, there are more longer traces than there are shorter traces, simply because the
longer the trace, the more possibilities there are for variations (e.g. different orders of trying
plans). This explains why the increase in Figure 9 starts off slowly and then accelerates:
as we get more failures, we have longer traces, and for these longer traces there are more
of them. In other word, if we were to plot the non-cumulative number of paths against the
ratio of action failures we would see an initial increase: as the ratio grows, there are more
paths. What this doesnt explain is why beyond a certain point we get fewer traces, and
the cumulative graph levels out. The explanation here is quite simple: beyond a certain
ratio (which appears to be around 0.4) there are no successful traces, and the number of
failed traces also declines.
4.7 Recursive Trees
In Section 4.4 we developed recurrence relations that allowed us to relax the assumption
that goal-plan trees are uniform, and considered semi-uniform trees. In this section we
relax the assumption that goal-plan trees are finite, and we also allow trees to have any
shape. We do this by considering arbitrary trees that are allowed to contain labels that
refer to other parts of the tree, i.e. we allow trees to be recursive. We then derive generating
functions, which can be seen as an extension of those derived in the previous section, for
the number of paths (both successful and unsuccessful) in executing these recursive goalplan trees. Obviously, an infinite tree has an infinite number of paths, and so we define
generating functions that take as a parameter a bound on the lengths of the paths counted.

19. There are a finite number of actions that can be attempted during any execution of a goal-plan tree, and
this bounds the length of its possible traces and the number of action failures that can occur within them.
Thus Fr4(gd , x, y) and Fr8(gd , x, y) are polynomials of finite orderonly a finite number of coefficients are
non-zero in the infinite sums that define them.

100

fiOn the Testability of BDI Agent Systems

Failed executions (cumulative)

Successful executions (cumulative)

Both (cumulative)

4E+107

3.5E+107

Number of traces (cumulative)

3E+107

2.5E+107

2E+107

1.5E+107

1E+107

5E+106

0.005
0.025
0.045
0.065
0.085
0.105
0.125
0.145
0.165
0.185
0.205
0.225
0.245
0.265
0.285
0.305
0.325
0.345
0.365
0.385
0.405
0.425
0.445
0.465
0.485
0.505
0.525
0.545
0.565
0.585
0.605
0.625
0.645
0.665
0.685
0.705
0.725
0.745
0.765
0.785
0.805
0.825
0.845
0.865
0.885
0.905
0.925
0.945
0.965
0.985

0

Failure rate

Figure 9: Number of traces (cumulative) vs. failure rate for j = k = d = 3 and ` = 1
For a given upper bound on path length  the equations specify the number of paths that
have at most that many actions20 .
We begin by defining some notation for representing recursive trees: goals, plan-body
multisets, plans, variables and bindings. A goal is represented by a term of the form
goal(plan-body-multiset) where plan-body-multiset is a multiset representing the different
applicable plan instances that can be used to satisfy the goal. This is a multiset because
for our combinatorial analysis, only the structure of plans is significant. Therefore we
use a single abstract action a to represent all actions21 , and a goal may be achievable
using multiple plan instances that have the same structure, but which we must treat as
distinct. We only need to represent the bodies of the plan instances, so each element in
the multiset (i.e. plan) is a sequence of terms separated by the right-associative sequential
composition operator ;. Each term in the sequence is either the abstract action term a,
a goal term as defined above (representing a sub-goal), or a label (see below). Formally,
a plan-body multiset P M is a multiset of plans, written {p1 :c1 , . . . , pj :cj } where each of
the ci is the number of times that the associated plan pi appears in the multiset. We
define the following multiset operations: set(P M ) is a set of all the pi in the multiset P M ,
P M (pi ) is the characteristic function denoting the number of times plan pi appears in
the multiset (i.e. ci ); and P M1  P M2 is multiset subtraction, defined as P M1 P M2 (x) =
max(P M1 (x)  P M2 (x), 0). Finally |P M | is the size of the multiset, i.e. the sum of the ci .

20. We can also use the equations derived in this section for non-recursive trees, in which case we allow
 = , where we define   1 =  and F power(x) = F .
21. However, to avoid confusion, we will use numeric subscripts (a1 , a2 , . . .) to distinguish different occurrences of actions.

101

fiWinikoff & Cranefield

In order to allow recursive trees to be represented, it is possible for a step in a plan to
be a label (denoted , i or  0 ) referring to a term in the provided binding, which is simply
a mapping from labels to terms (either goal or plan terms). If b is a binding then we write
b[] to denote the item that  is mapped to in b, or  if there is no entry for  in b.
For example, consider the simple tree below, consisting of a goal with two plans, together
with a binding that maps the variable  to the root of the tree. The first plan (on the left)
has two steps: an action (a1 ), and a recursive reference to the root of the tree (). The
second plan (on the right) just has a single action (a2 ).
 : goal
plan

plan
a1



a2

This recursive tree can be represented as follows. We define the binding b = { 7
goal({(a1 ; ):1, a2 :1})} which maps  to the whole tree, and then the tree itself is just .
Before we proceed to defining generating functions, we introduce some auxiliary notation. If P is a power series then we use the standard notation [xp11    xpnn ]P to denote
the coefficient of the term xp11    xpnn in the series. We define P cond to denote the power
xn

series containing all the terms in P that satisfy the condition cond. We define f  g as
(f  g) power(x)n , i.e. f  g with any terms having a power of x greater than n removed.
n
We define f mx as (f )m power(x)n , i.e. (f )m with any terms having a power of x greater
than n removed.22
We are now in a position to derive generating functions that specify the number of
paths through an arbitrary, and possible recursive, goal-plan tree, given a bound  on the
path length. We define s to be the BDI program represented as a term (i.e. goal, plan,
plan multiset, action, or label), and b to be a binding mapping labels to terms (as defined
above). We then define n4(s, m, n, b) to be the number of successful paths, with respect
to s and binding b, that have m actions, n of which are failed actions. Similarly we define
n8(s, m, n, b) to be the number of failed paths, with respect to s and b, that have m actions,
n of which are failed actions. We now want to derive recurrence relations for the generating
functions23 :
4
F
(s, x, y, b, ) =

8
F
(s, x, y, b, ) =

 X

X
m=0 n=0
 X

X

n4(s, m, n, b)xm y n
n8(s, m, n, b)xm y n

m=0 n=0

where  is an upper bound on the number of actions in a path.
22. This, and the previous operation, are directly supported by the rmpoly Python library for multivariate
polynomials and series, which we have used to compute these generating functions.
23. The subscript  is used to distinguish these generating functions, that allow for a recursive tree, from
other generating functions defined elsewhere in the paper.

102

fiOn the Testability of BDI Agent Systems

In order to simplify the presentation, the details of the more complex derivations are
given in Appendix C. The resulting equations are shown in Figure 10. The first two
equations (Equations 11 and 12 in Figure 10), which are applicable for any term t, capture
the assumption that  > 0 (and the remaining equations only apply when  > 0). The next
two equations simply specify that labels are looked up in the provided binding. Equation 15
indicates that there is a single successful path through action a, and that it has a single
action and no unsuccessful actions (i.e. the generating function is 1x1 y 0 ). Equation 16
similarly indicates that there is a single unsuccessful path through a single action a, which,
unsurprisingly, has a single unsuccessful action (so the generating function is 1x1 y 1 ).
Equations 17 and 18 deal with sequences: for a sequence s1 ; s2 to succeed both s1 and
s2 must succeed, and we count the paths by concatenating sub-paths, which corresponds to
multiplying power series. A sequence s1 ; s2 can fail if either s1 fails, or if s1 succeeds and
s2 then fails (alternatives correspond to the addition of power series). For both equations
there is a special case: if s1 is an action, then we can divide the overall path-length limit
 precisely: s1 must have a trace of length 1 (since it is an action) and s2 must therefore
have a maximum length of   1.
Having dealt with labels (), single actions, and sequences, we next turn to goals (equations 19 and 20). In both cases the derivation is complex, and is covered in Appendix C.
4
For F
(Equation 19 and Appendix C.1), the intuition is that a successful path through a
goals execution involves a single successful plan p, and some number of failed executions of
plan selected from the remaining multiset of plans (P M  {p:1}). In the case where a plan
appears more than once in the multiset, then we can select any of its occurrences, hence
the multiplication by P M (p). For the number of failed paths of a goal (Equation 20 and
Appendix C.2) we introduce an auxiliary generating function G8(P M, x, y, z, b, ), where
P M is a multiset of plans, and z is a variable whose power z o indicates the exact number of plans from P M that are used. In other words, given the power series denoted by
G8(P M, x, y, z, b, ), the term cmno xm y n z o /o! indicates that there are cmno paths that involve m actions, n of which failed, and exactly o of the plans in P M . The generating
8
function G8 is a technical device that allows us to derive the definition of F
that we need.
8
Given this power series, the definition of F simply selects the terms that have |P M | as
the power of z (since all plans must fail for a goal to fail) using  and then removes the
z |P M | terms by dividing. Because G8 is an exponential generating function in z, which
means that it includes a division by a factorial, we need to multiply by the factorial |P M |!
to remove it.
8
Equation 21 defines F
(P M, x, y, b, ), which is used in Equation 19, in terms of the
8
auxiliary function G. Its derivation is given in Appendix C.3. The intuition here is that
for each possible number of plans that could be used (o) we limit the power series G8 to
that value of o, and remove the z o by dividing. The o! is due to G8 being an exponential
generating function in z (see Appendix C).

Finally, Equations 22 and 23 give the definition of G8(P M, x, y, z, b, ) (see Appendix C.4
for the derivation). Intuitively, Equation 22 creates the power series for each plan type, and
x

then combines them (using  ). Equation 23 is a little more complex: there is a single way
of failing (when no plans are used, corresponding to the term x0 y 0 z 0 = 1). Otherwise we
can select any o of the c plans, and each of the plans must fail (corresponding to the term
103

fiWinikoff & Cranefield

4
F
(t, x, y, b, ) = 0 if   0

(11)

8

F(t, x, y, b, ) = 0 if   0

(12)

4

4

(13)

8

8

(14)

F(, x, y, b, ) = F(b[], x, y, b, )
F(, x, y, b, ) = F(b[], x, y, b, )
4

(15)

8

(16)

F(a, x, y, b, ) = x
F(a, x, y, b, ) = xy
4

F(s1 ; s2 , x, y, b, )
(
4
4
F
(s1 , x, y, b, 1) F
(s2 , x, y, b,   1) if s1 is an action
=
x
4
4
F(s1 , x, y, b, )  F
(s2 , x, y, b, ) otherwise
8
F
(s1 ; s2 , x, y, b, )
(
4
8
8
(s1 , x, y, b, 1)+F
(s1 , x, y, b, 1) F
(s2 , x, y, b,   1) if s1 is an action
F
=
x
8
4
8
F
(s1 , x, y, b, )+F
(s1 , x, y, b, )  F
(s2 , x, y, b, ) otherwise
4
F
(goal(P M ), x, y, b, )
X
x
4
8
=
P M (p)F
(p, x, y, b, )  F
(P M {p:1}, x, y, b, )

(17)

(18)

(19)

pset(P M )
8
F
(goal(P M ), x, y, b, ) = |P M |!

|P M |
8
F
(P M, x, y, b, ) =

X
o=0

o!

G8(P M, x, y, z, b, ) power(z)=|P M |
z |P M |
G8(P M, x, y, z, b, ) power(z)=o
zo

(20)
(21)

G8({p1 :c1 , . . . , pj :cj }, x, y, z, b, )
x

x

G8({p1 :c1 }, x, y, z, b, )      G8({pj :cj }, x, y, z, b, )

=

c  
X
c
G({p:c}, x, y, z, b, ) = 1 +
F 8 (p, x, y, b, )ox z o
o 
8

(22)

(23)

o=1

Figure 10: Equations for Recursive Goal-Plan Trees
8
F
(p, x, y, b, )), giving the number of failed traces across these o plans as:
x

x

8
8
8
F
(p, x, y, b, )ox = F
(p, x, y, b, )      F
(p, x, y, b, )
|
{z
}

o times

We have used the Python rmpoly and GMPY2 libraries to generate polynomial repre4
8
sentations of the functions F
(t, x, y, b, ) and F
(t, x, y, b, ) (as defined in Figure 10) for
any specified values of t, b, and . Then we defined a simple tree (the one given earlier in
this section as an example) and computed the number of paths for different values of .
104

fiOn the Testability of BDI Agent Systems

The values of  have been chosen to correspond to values in Table 2 (which is where the
values for n4(g) and n8(g) come from24 ). In Table 2, the values of 62 and 363 correspond to
the longest path, and so we argue that when comparing a recursive tree to a uniform tree,
we should consider the same path length limit. The results are shown in Table 5.

62
363

n4(g)
 6.33  1012
 1.02  10107

n8(g)
 1.82  1013
 2.56  10107

n4(s)
 3.8  1013
 1.9  1076

n8(s)
 4.3  109
 6.1  1054

Table 5: Comparing n4 and n4 (respectively n8 and n8).
Looking at the numbers in Table 5, it is worth noting that the recursive tree that we
have used is extremely simple: two plans, each with only a single action. The low number
of actions (and sparseness of the tree) account for the relatively low number of unsuccessful
paths. For instance, if we modify the tree by adding extra actions (giving the tree and
binding below) then for  = 62 there are around 3.9  1013 successful paths, and 1.5  1011
unsuccessful paths. Unfortunately, Python was unable to calculate n4 or n8 for this tree
with  = 363, but it did manage  = 362, for which there are 1.26  1064 successful paths,
and 3.281063 unsuccessful paths. This shows, as expected, that the number of unsuccessful
paths is higher for the more complex tree. That there are fewer successful paths for the
more complex tree can be explained by observing that, for this tree, traces are longer (more
actions need to be done), and so more of the traces are excluded by the bound on trace
length .
 : goal
plan

plan
a1

a3



a2

a4

Overall, the analysis in this section, and its application to  = 62 and 363 confirms
that the number of paths in a recursive tree depends on the trees structure (which is
unsurprising), but also indicates that even for a very simple recursive tree, the number of
paths for a given upper bound on path length quickly becomes extremely large.

5. A Reality Check
In the previous section we analysed an abstract model of BDI execution in order to determine
the size of the behaviour space. The analysis yielded information about the size of the
behaviour space and how it is affected by various factors, and on the probability of a goal
failing.
In this section we consider the two issues of whether this analysis is faithful, and whether
it is applicable to real systems. The analysis made a number of simplifying assumptions,
24. They correspond to the first two rows of the table, which respectively involve 62 and 363 actions.

105

fiWinikoff & Cranefield

and these mean that the results may not be faithful to the semantics of a real BDI platform,
or that they may not apply to real systems. We thus conduct two reality checks to assess
whether our analysis is faithful (Section 5.1) and whether it is applicable (Section 5.2).
We firstly assess whether our analysis is faithful to real BDI platforms, i.e. that it does
not omit significant features, or contain errors. We do this by comparing our abstract
BDI execution model with results from a real BDI platform, namely JACK (Busetta et al.,
1999). This comparison allows us to assess to what extent the analysis of our abstract BDI
execution model matches the execution that takes place in a real (industrial strength) BDI
platform. This comparison is, in essence, a basic reality check: we are simply checking that
the analysis in the previous section does indeed match the execution semantics of a typical
BDI platform. We do this by modelling an artificial goal-plan tree in the BDI platform.
Next, in order to assess to what extent our analysis results apply to real systems, we
analyse a goal-plan tree from a real industrial application. This analysis allows us to
determine the extent to which the conclusions of our analysis of uniform (and semi-uniform)
goal-plan trees applies to real applications, where the goal-plan trees are not likely to be
uniform. In other words, to what extent do the large numbers in Tables 1 and 2 apply to
real applications?
5.1 A Real Platform
In order to compare a real BDI platforms execution with the results of our abstract BDI
execution model we implemented the two goal-plan trees in Appendix A in the JACK agent
programming language25 . The structure of the plans and events26 precisely mirrors the
structure of the tree. As in the goal-plan tree, each event has two relevant plans, both
of which are always applicable, and selectable in either order. Actions were implemented
using code that printed out the action name, and then, depending on a condition (described
below), either continued execution or triggered failure (and printed out a failure indicator):
System.out.print("a"); // Action "a"
if ((N.i & 1)==0) {
System.out.print("x");
false; // trigger failure
}
The conditions that determined whether an action failed or succeeded, and which plan
was selected first, were controlled by an input (N.i, a Java class variable). A test harness
systematically generated all inputs, thus forcing all decision options to be explored.
The results matched those computed by the Prolog code of Figure 3, giving precisely
the same six traces for the smaller tree, and the same 162 traces for the larger tree. This
indicates that our abstract BDI execution model is indeed an accurate description of what
takes place in a real BDI platform (specifically JACK).
Note that we selected JACK for two reasons. One is that it is a modern, well known,
industry-strength BDI platform. The other, more important, reason, is that JACK is a descendent of a line of BDI platforms going back to PRS, and thus is a good representative for
25. The code is available upon request from the authors.
26. JACK models a goal as a BDIGoalEvent.

106

fiOn the Testability of BDI Agent Systems

Parameters
Number of
j k
d
goals
actions
2 2
3
21
62 (13)
3 3
3
91 363 (25)
Workflow with 57 goals(*)
(*) The paper says 60 goals,
but Figure 11 has 57 goals.

No failure handling
(secs 4.1 and 4.2)
n4(g)
n8(g)
128
614
1,594,323 6,337,425
294,912 3,250,604
294,912 1,625,302
294,912
812,651

With failure handling
(Section 4.3)
n4(g)
n8(g)
 6.33  1012
 1.82  1013
107
 1.02  10
 2.56  10107
 2.98  1020
 9.69  1020
15
 6.28  10
 8.96  1015
 9.66  1011
 6.27  1011

Table 6: Illustrative values for n4(g) and n8(g) (bottom part is ` = 4 in first row, ` = 2 in
second, and ` = 1 in last row)

a larger family of BDI platforms. In other words, by showing that the BDI execution model
analysed matches JACKs model, we are also able to argue that it matches the execution of
JACKs predecessors (including PRS and dMARS), and close relatives (e.g. UM-PRS and
JAM).
5.2 A Real Application
We now consider to what extent real systems have deep and branching goal-plan trees,
and to what extent the large numbers shown in Tables 1 and 2 apply to real applications,
rather than to uniform goal-plan trees. As an example of a real application we consider an
industrial application at Daimler which used BDI agents to realise agile business processes
(Burmeister, Arnold, Copaciu, & Rimassa, 2008). Note that finding a suitable application
is somewhat challenging: we need an application that is real (not a toy system). However,
in order to be able to analyse it, the application has to be BDI-based, and furthermore,
details about the applications goal-plan tree need to be available. Unfortunately, many of
the reported BDI-based industrial applications do not provide sufficient details about their
internals to allow analysis to be carried out.
Figure 11 shows27 a goal-plan tree from the work of Burmeister et al. (2008) which
has 60 achieve goals in up to 7 levels. 10 maintain goals, 85 plans and about 100 context
variables (Burmeister et al., 2008, p. 41). Unlike the typical goal-plan trees used in BDI
platforms, the tree in Figure 11 consists of layers of and-refined goals, with the only or
refinements being at the leaves (where the plans are). In terms of the analysis presented
in this paper we can treat a link from a goal g to a set of goals, say, g1 , g2 , g3 as being
equivalent to the goal g having a single plan p which performs g1 , g2 , g3 (and has no actions,
i.e. ` = 0 for non-leaf plans).
The last row of Table 6 gives the various n values for this goal-plan tree, for ` = 4 (top
row), ` = 2 (middle row) and ` = 1 (bottom row). Note that these figures are actually
lower bounds because we assumed that plans at depth 0 are simple linear combinations
of ` actions, whereas it is clear from Burmeister et al. (2008) that their plans are in fact
27. The details are not meant to be legible: the structure is what matters.

107

fiWinikoff & Cranefield

model
LS/AB
differe
model
keep th

figuretree6:from
goal
of ACM
prototype
Figure 11: Goal-plan
thehierarchy
work of Burmeister
et al. (2008,
Figure 6) (reproduced
with permission from IFAAMAS)

An advantage of this modeling approach is that it implicitly offers
support for parallel execution of the process parts that do not
depend on each other. This can reduce the overall time needed for
more complicated, and can contain nested decision making (e.g., see Burmeister et al., 2008,
process
execution. Moreover maintain goals are a good means to
Figure 4).
provide
process
with
the
agent
monitors
A roughthe
indication
of the size
of aadditional
goal-plan tree isagility:
the number
of goals.
With
57 goals,
the tree of Figure
has sizeto
in be
between
the firstthroughout
two rows of Table
Comparing(e.g.
the
conditions
that11 have
fulfilled
the6. process
number of possible behaviours of the uniform goal-plan trees against the real (and nontime
constraints)
and
pro-actively
activities
avoid
uniform)
goal-plan tree, we
see that
the behaviour initiates
space is somewhat
smaller to
in the
real
tree, but thatbefore
it is stillthey
quite appear.
large, especially in the case with failure handling. However,
problems
we do note the following points:

During development of the prototype the support for rapid
1. The tree of Figure 11 only has plans at the leaves, which reduces its complexity. In
prototyping
and execution of process models provided by
other words a goal-plan tree that was more typical in having plans alternating with
goals would
have
a larger number
possible
behaviours.
LS/ABPM
has
proven
to be ofvery
helpful.
The developed models
represent
living process models, which can be directly executed
2. The figures for the tree are a conservative estimate, since we assume that leaf plans
and visualized.
The
part ofIn the
interface
thatcalculated
is coupled
have only simple
behaviour.
otherweb
words,user
the number
of paths
is an
of theis
actual
number of directly
paths in thefrom
real application.
with under-estimate
the workflow
generated
the process model.
The
interface is computed directly from the parameters of the
6. Comparison with Procedural Programs
corresponding task: context variables, their types and possible
In order to argue that BDI programs are harder to test than non-agent programs, we need
values.
With
this approach
in the ofprocess
can be programs,
quickly
a comparison.
Specifically,
we need to changes
analyze the number
paths in non-agent
and compareand
with tested.
those in agent
programs.
us to address
concern that
modeled
Thus
errorsThis
in will
theallow
models
can bethediscovered
the all paths criterion for test suite adequacy always requires an infeasibly large number
and
corrected
in briefly
a short
of tests.
This section
doestime.
this, by analyzing the number of paths in a procedural
program.
As
stated above the starting point for building the ACM-prototype
model was the ACM-reference 108
process model developed for the
software demonstrator. The underlying agent engine of this
demonstrator (JadeX) has a partially different modeling and
execution semantics compared to the LS/ABPM tool. There were

The m
model
prototy
them
compl
depend
challen
and to
execut
depend
proces

Based
be con
of the
contex
manip
model
plans,
of the
compl
possib
variab
variab
one or
proces
variab
startin
goals.
create
but h
model

fiOn the Testability of BDI Agent Systems

Number of actions / statements
62
363
776
627

n(m)
6,973,568,802
 5.39  1057
 2.5  10123
 5.23  1099

n4(g)
 6.33  1012
 1.02  10107
 1.82  10157
 3.13  10184

n8(g)
 1.82  1013
 2.56  10107
 7.23  10157
 7.82  10184

Table 7: Comparison of values between n(m), n4(g) and n8(g).
We define a program as being composed of primitive statements s, sequences of statements P1 ; P2 , or conditionals that select between two sub-programs. Since we do not capture
the conditions of statements, we elide the condition, and write a conditional as P1 + P2 indicating that one of the Pi is selected. Note that, as for BDI analysis, we exclude loops.
We define the number of paths in a program P as n(P ). It is straightforward28 to see
that the definition of n(P ) is:
n(s) = 1
n(P1 ; P2 ) = n(P1 )  n(P2 )
n(P1 + P2 ) = n(P1 ) + n(P2 )
In order to compare with BDI programs, we consider the size of the program, and
compare programs of the same size. The key question then is: does a procedural program
with m nodes have significantly fewer paths than a BDI program of the same size? We define
the size of a program P as the number of primitive statements it contains, and denote it
|P |. Note that this means that we do not count the internal nodes of the syntax tree
(i.e. the + or ;). Therefore, when comparing with BDI programs, we consider the size
of a BDI program to be the number of actions29 .
We now work out how the number of paths varies with the size of the program P . If m is
the size of a program (and therefore a natural number), then we define n(m)  max{n(P ) :
|P | = m}. That is, n(m) is the largest number of paths possible for a program of size m.
Appendix D contains the derivation of n(m), resulting in the following definition (where
m  6 is a multiple of 3):
n(1)
n(3)
n(5)
n(m + 1)

=
=
=
=

1
3
6
4
3

 3m/3

n(2)
n(4)
n(m)
n(m + 2)

=
=
=
=

2
4
3m/3
2  3m/3

Table 7 shows some comparison values between n(m) and n4(g) and n8(g), for same-sized
programs, based on Table 2. It is worth emphasising that n(m) is the highest possible value:
it is defined as the maximum over all possible programs. However, the maximal program
is highly atypical. For example, considering all programs with seven statements, there are
28. A path of P1 ; P2 simply concatenates a path of P1 with a path of P2 , hence the product; and a path of
P1 + P2 is either a path of P1 or a path of P2 , hence the addition.
29. Using the total number of nodes in the tree yields almost identical results.

109

fiWinikoff & Cranefield

a total of 8,448 possible programs. Of these 8448 programs, only 32 have 12 paths (the
maximum). Figure 12 shows for each number of paths (112) how many programs have that
many paths. The maximum of 12 is clearly not typical: indeed, the mean number of paths
for a seven statement program is 4.379, and the median is 4. If we consider all programs
with 9 statements, then there are 366,080 such programs, but only 16 have the maximal
number of paths (which is 27). The average number of paths across all the programs is
5.95.
Overall, looking at Table 7, we conclude that the number of paths for BDI programs is
much larger than even the (atypical) maximal number of paths for a procedural program
of the same size. This supports the conclusion that BDI programs are harder to test than
procedural programs.
2500"

Number'of'programs'

2000"

1500"

1000"

500"

0"
1"

2"

3"

4"
5"
6"
7"
8"
9"
Number'of'paths'in'a'procedural'program'

10"

11"

12"

Figure 12: Profile of number of paths for all 7-statement programs

7. Conclusion
To summarise, our analysis has found that the space of possible behaviours for BDI agents is,
indeed, large, both in an absolute sense, and in a relative sense (compared with procedural
programs of the same size).
As expected, the number of possible behaviours grows as the trees depth (d) and breadth
(j and k) grow. However, somewhat surprisingly, the introduction of failure handling makes
a very significant difference to the number of behaviours. For instance, for a uniform goalplan tree with depth 3 and j = k = 2, adding failure handling took the number of successful
behaviours from 128 to 6,332,669,231,104.
Before we consider the negative consequences of our analysis, it is worth highlighting
one positive consequence: our analysis provides quantitative support for the long-held belief
110

fiOn the Testability of BDI Agent Systems

that BDI agents allow for the definition of highly flexible and robust agents. Flexibility is
defined as the number of possible behaviours of an agent, which we have shown to be large.
Robustness is defined as the ability of an agent to recover from failure. The analysis in
Section 4.6 showed that the BDI failure recovery mechanism is effective at achieving a low
rate of actual failure (< 1%), even when each action has a reasonable chance of failing (5%).
So what does the analysis in this paper tell us about the testability of BDI agent systems?
Before we can answer this question, we need to consider what is being tested. Testing is
typically carried out at the levels of individual components (unit testing), collections of
components (integration testing), and the system as a whole.
Consider testing of a whole system. The behaviour space sizes depicted in Tables 1, 2
and 6 suggest quite strongly that attempting to obtain assurance of a systems correctness
by testing the system as a whole is not feasible. The reason for this is that (as discussed in
Section 1.1), an adequate test suite (using the all paths criterion for adequacy) requires
at least as many tests as there are paths in the program being tested. If a program has, say,
 1013 paths, then even a test suite with tens of thousands of tests is not just inadequate,
but is hugely inadequate, since it only covers a tiny fraction of a percent of the number of
paths.
In fact, this situation is even worse when we consider not only the number of possible
executions but also the probability of failing: the space of unsuccessful executions is particularly hard to test, since there are many unsuccessful executions (more than successful ones),
and the probability of an unsuccessful execution is low, making this part of the behaviour
space hard to reach. Furthermore, as shown in Section 4.6, although making assumptions
about the possible numbers of action failures that can occur in a given execution reduces
the number of possible behaviours, there are still many many behaviours, even for relatively
small trees (e.g. j = k = d = 3).
So system testing of BDI agents seems to be impractical. What about unit testing
and integration testing? Unfortunately, it is not always clear how to apply them usefully
to agent systems where the interesting behaviour is complex and possibly emergent. For
example, given an ant colony optimisation system (Dorigo & Stutzle, 2004), testing a single
ant doesnt provide much useful information about the correct functioning of the whole
system. Similarly, for BDI agents, when testing a sub-goal it can be difficult to ensure that
testing covers all the situations in which the goal may be attempted. Consequently, it is
difficult to draw conclusions about the correctness of a goal from the results of testing its
sub-goals.
We do need to acknowledge that our analysis is somewhat pessimistic: real BDI systems
do not necessarily have deep or heavily branching goal-plan trees. Indeed, the tree from
a real application described in Section 5 has a smaller behaviour space than the abstract
goal-plan trees analysed in Section 4. However, even though smaller, it is still quite large,
and this did cause problems in validation:

One of the big challenges during the test phase was to keep the model consistent
and to define the right context conditions that result in the correct execution
for all scenarios. Therefore more support for dependency analysis, automated
111

fiWinikoff & Cranefield

simulation and testing of the process models is needed (Burmeister et al., 2008,
p. 42)30 .
So where does that leave us with respect to testing agent systems? The conclusion
seems to be that testing a whole BDI system is not feasible. There are a number of possible
approaches for dealing with this issue of testability that could be recommended:
 Keep BDI goal-plan trees shallow and sparse. This keeps the number of behaviours small. The issue with this approach is that we lose the benefits of the BDI
approach: a reasonably large number of behaviours is desirable in that it provides
flexibility and robustness.
 Avoid failure handling. Since failure handling is a large contributor to the behaviour space, we could modify agent languages to disable failure handling. Again,
this is not a useful approach because disabling failure handling removes the benefits
of the approach, specifically the ability to recover from failures.
 Make testing more sophisticated. Could testing coverage perhaps be improved
by incorporating additional information such as domain knowledge, and a detailed
model of the environment (which indicates the possible failure modes and their probabilities)? The answer is not known, but this is a potentially interesting area for
further work. However, the large number of paths does not encourage much optimism
for this approach.
Another, related, direction is to see whether patterns exist in the behaviour space.
Since the failure recovery mechanism has a certain structure, it may be that this
results in a behaviour space that is large, but, in some sense, structured. If such
structure exists, it may be useful in making agents more testable. However, at this
point in time, this is a research direction that may or may not turn out to be fruitful;
but is not a viable testing strategy.
Finally, a related direction is to try and be more intelligent about the selection of
test cases, in order to gain more coverage from a given number of test cases. One
approach for doing this, which has been recently described, is evolutionary testing
(Nguyen, Miles, Perini, Tonella, Harman, & Luck, 2009a), in which genetic evolution
is used to find good (i.e. challenging) test cases.
 Supplement testing with alternative means of assurance. Since testing is not
able to cover a large behaviour space, we should consider other forms of assurance.
A promising candidate here is some form of formal method31 . Unfortunately, formal
methods techniques are not yet applicable to industry-sized agent systems (we return
to this below, in Section 7.1).
30. Burmeister et al. made the following observation: With this approach changes in the process can be
quickly modeled and tested. Thus errors in the models can be discovered and corrected in a short time.
They were discussing the advantages of executable models, and arguing that being able to execute the
model allowed for testing, which was useful in detecting errors in the model. While being able to execute
a model is undoubtedly useful, there is no evidence given (nor is a specific claim made) that testing is
sufficient for assuring the correctness of an agent system.
31. See the volume edited by Dastani et al. (2010) for a recent overview of the current state-of-the-art,
including a chapter on the role of formal methods in the assurance of agents (Winikoff, 2010).

112

fiOn the Testability of BDI Agent Systems

 Proceed with caution. Accept that BDI agent systems are in general robust (due
to their failure-handling mechanisms), but that there is, at present, no practical way
of assuring that they will behave appropriately in all possible situations. It is worth
noting that humans are similar in this respect. Whilst we can train, examine and
certify a human for a certain role (e.g. a pilot or surgeon), there is no way of assuring
that he/she will behave appropriately in all situations. Consequently, in situations
where incorrect behaviour may have dire consequences, the surrounding system needs
to have safety precautions built in (e.g. a process that double-checks information, or
a backup system such as a co-pilot).
7.1 Future Work
There is room for extending the analysis of Section 4. Firstly, our analysis is for a single
goal within a single agent. Multiple agents that are collaborating to achieve a single highlevel goal can be viewed as having a shared goal-plan tree where certain goals and/or plans
are allocated to certain agents. Of course, in such a distributed goal plan tree there
is concurrency. Once concurrency is introduced, it would be useful to consider whether
certain interleavings of concurrent goals are in fact equivalent. Furthermore, we have only
considered achievement goals. It would be interesting to consider other types of goals (van
Riemsdijk, Dastani, & Winikoff, 2008). Secondly, our analysis has focused on BDI agents,
which are just one particular type of agent. It would be interesting to consider other sorts
of agent systems, and, more broadly, other sorts of adaptive systems.
Another extension of the analysis is to consider other criteria for test suite adequacy.
In this paper we have used the all paths criterion, arguing why it is appropriate. We
do recognize that all paths is actually quite a strong criterionit subsumes many other
criteria (Zhu et al., 1997, Figure 7). An alternative criterion that we could consider is all
edges, also known as branch coverage or decision coverage. It requires that where
there is a choice in the program, such as an if statement, then the tests in the test suite
exercise all options, i.e. that all edges in the program graph be covered. The all edges
criterion is weaker than all paths and is regarded as the generally accepted minimum
(Jorgensen, 2002).
Another area for refinement of the analysis is to make it less abstract. Two specific areas
where it could be made more detailed are resources and the environment. Our analysis does
not consider resources or the environment directly, instead, it considers that actions may
fail for a range of reasons which might include resource issues, or environmental issues. The
analysis could be extended to explicitly consider resources and their interaction with goals
(Thangarajah, Winikoff, Padgham, & Fischer, 2002). It could also be extended with an
explicit model of the environment.
Whilst our analysis did consider a real application, it would be desirable to consider a
range of applications. This could provide additional evidence that the analysis is not unduly
pessimistic, and would also lead to an understanding of the variance in goal-plan trees and
their characteristics across applications. A key challenge is finding suitable applications that
are BDI-based, are sufficiently complex (ideally real applications), and have detailed design
information available (and preferably source code). Another challenge is the methodology:
we analysed the shape of the goal-plan tree of the Daimler workflow application, but did
113

fiWinikoff & Cranefield

not have access to run the system. An alternative methodology, which requires access to
the implemented system and probably the source code, is to run it, and force it to generate
all traces for sub-goals32 (which would require modification of either the source code or
the underlying agent platform). Once we have collected data on the shape of real-world
industrial applications, we will be able to analyse whether uniform and semi-uniform goalplan trees are good models of these types of system, or whether we should seek ways to
further relax our uniformity assumption.
More importantly, having highlighted the difficulties in assuring BDI agent systems
through testing, we need to find other ways of assuring such systems.
An approach that has some promise is the automatic generation of test cases for agent
systems (Nguyen, Perini, & Tonella, 2007; Zhang, Thangarajah, & Padgham, 2009). However, the size of the behaviour space suggests that the number of test cases needed may
be very large, and that testing for failed plan execution is difficult. One interesting, and
potentially promising, avenue is to use formal techniques to help guide the test generation
process (e.g. symbolic execution or specification-guided testing) (Dwyer, Hatcliff, Pasareanu, Robby, & Visser, 2007).
Another approach33 that has attracted interest is model checking of agent systems
(Wooldridge, Fisher, Huget, & Parsons, 2002; Bordini, Fisher, Pardavila, & Wooldridge,
2003; Raimondi & Lomuscio, 2007). This work is promising because model checking techniques use a range of abstractions to cover a large search space without having to deal
with individual cases one-at-a-time (Burch, Clarke, McMillan, Dill, & Hwang, 1992; Fix,
Grumberg, Heyman, Heyman, & Schuster, 2005). Furthermore, because verifying a subgoal considers all possibilities, it is possible to combine the verification of different sub-goals.
However, more work is needed: Raimondi and Lomuscio (2007) verify systems where agents
are defined abstractly, i.e. not in terms of plans and goals. The MABLE agent programming
language (Wooldridge et al., 2002) is actually an imperative language augmented with certain agent features, not a BDI language; and the work of Bordini et al. (2003) does not
include failure handling. In general, the state of the art in model checking agent system
implementations is still limited to quite small systems (Dennis, Fisher, Webster, & Bordini,
2012).
Acknowledgements
We would like to thank members of the Department of Information Science at the University
of Otago for discussions relating to this paper. We would also like to thank Lin Padgham
for her comments on a draft of this paper. Finally, we would like to thank the anonymous
reviewers for their insightful comments which helped to improve this paper. Some of the
work on this paper was done while Winikoff was on sabbatical from RMIT, visiting the
University of Otago.

32. Generating all traces of the top level goal is not likely to be feasible.
33. There has also been work on deductive verification, but (based on research into the verification of
concurrent systems) this appears to be less likely to result in verification tools that are both (relatively)
easy to use and applicable to real systems.

114

fiOn the Testability of BDI Agent Systems

Appendix A. Example Goal-Plan Trees and their Expansions
Suppose we have the following two trees: sample (left) and sample2 (right). The trees
correspond to j = 2, k = ` = 1, d = 1 for sample and d = 2 for sample2.
goal
plan
a

goal

plan

goal

b c

goal

d

plan

plan

plan

plan

plan

plan

a

b

e

f

g

h

These trees can be expanded respectively into the following sequences of actions, where
a letter indicates the execution of an action, and a 8 indicates failure34 . As predicted by
our formulae, there are four successful executions and two unsuccessful executions for the
first tree:
a
b

a8b
b8a

a8b8
b8a8

For the second tree, the expansions are the following 162 possibilities (consisting of 64
successful and 98 unsuccessful traces).
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a

e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e

b
b8cgd
b8cgd8
b8cg8hd
b8cg8hd8
b8cg8h8
b8chd
b8chd8
b8ch8gd
b8ch8gd8
b8ch8g8
b8c8
8fb
8fb8cgd
8fb8cgd8
8fb8cg8hd
8fb8cg8hd8
8fb8cg8h8
8fb8chd
8fb8chd8

a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a

f
f
f
f
f
f
f
f
f
f
f
f
f
f
f
f
f
f
f
f

b8chd
b8chd8
b8ch8gd
b8ch8gd8
b8ch8g8
b8c8
8eb
8eb8cgd
8eb8cgd8
8eb8cg8hd
8eb8cg8hd8
8eb8cg8h8
8eb8chd
8eb8chd8
8eb8ch8gd
8eb8ch8gd8
8eb8ch8g8
8eb8c8
8e8cgd
8e8cgd8

c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c

g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g

d8
d8
d8
d8
d8
d8
d8
d8
d8
d8
d8
8h
8h
8h
8h
8h
8h
8h
8h
8h

aeb
aeb8
ae8fb
ae8fb8
ae8f8
afb
afb8
af8eb
af8eb8
af8e8
a8
d
d8aeb
d8aeb8
d8ae8fb
d8ae8fb8
d8ae8f8
d8afb
d8afb8
d8af8eb

c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c

h
h
h
h
h
h
h
h
h
h
h
h
h
h
h
h
h
h
h
h

d8afb8
d8af8eb
d8af8eb8
d8af8e8
d8a8
8gd
8gd8aeb
8gd8aeb8
8gd8ae8fb
8gd8ae8fb8
8gd8ae8f8
8gd8afb
8gd8afb8
8gd8af8eb
8gd8af8eb8
8gd8af8e8
8gd8a8
8g8aeb
8g8aeb8
8g8ae8fb

34. Note that the failure marker isnt counted when considering the length of the trace in Section 4.6.

115

fiWinikoff & Cranefield

a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a

e8fb8ch8gd
e8fb8ch8gd8
e8fb8ch8g8
e8fb8c8
e8f8cgd
e8f8cgd8
e8f8cg8hd
e8f8cg8hd8
e8f8cg8h8
e8f8chd
e8f8chd8
e8f8ch8gd
e8f8ch8gd8
e8f8ch8g8
e8f8c8
fb
fb8cgd
fb8cgd8
fb8cg8hd
fb8cg8hd8
fb8cg8h8

af8e8cg8hd
af8e8cg8hd8
af8e8cg8h8
af8e8chd
af8e8chd8
af8e8ch8gd
af8e8ch8gd8
af8e8ch8g8
af8e8c8
a8cgd
a8cgd8
a8cg8hd
a8cg8hd8
a8cg8h8
a8chd
a8chd8
a8ch8gd
a8ch8gd8
a8ch8g8
a8c8
cgd

c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c

g8hd8af8eb8
g8hd8af8e8
g8hd8a8
g8h8aeb
g8h8aeb8
g8h8ae8fb
g8h8ae8fb8
g8h8ae8f8
g8h8afb
g8h8afb8
g8h8af8eb
g8h8af8eb8
g8h8af8e8
g8h8a8
hd
hd8aeb
hd8aeb8
hd8ae8fb
hd8ae8fb8
hd8ae8f8
hd8afb

c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c

h8g8ae8fb8
h8g8ae8f8
h8g8afb
h8g8afb8
h8g8af8eb
h8g8af8eb8
h8g8af8e8
h8g8a8
8aeb
8aeb8
8ae8fb
8ae8fb8
8ae8f8
8afb
8afb8
8af8eb
8af8eb8
8af8e8
8a8

Appendix B. Analysis of Recurrence Relations
This appendix contains details of the derivation in Section 4.4.
The exponential generating function F (x) of the sequence {f 4 (j, a, b)}
j=0 is the function
defined by the following power series:
F (x) =


X

f 4 (j, a, b)

j=0

xj
j!

(24)

(by definition of f 4 )
!
!
j1  


  
j
X
X
X
X
x
xj
j
j
=
i!ai (j i)b
=
i!ai (j i)b
i
j!
i
j!
j=0

i=0

j=0

i=0

On the right hand side above we have
 changed the upper limit of the inner sum to  based
j
on the generalised definition of i as j(j 1)(j 2) . . . (j i + 1)/i!, which is valid for all

complex numbers j and non-zero integers i (Wilf, 1994) and gives ji = 0 for i > j.
The right hand side has the form of a product of exponential generating functions (Wilf,
1994, Rule 30 , Section 2.3):



!



  
j
j
X
X
X
X
x
x
j
xj

(j)  
(j)  =
(i)(j i)
j!
j!
i
j!
j=0

j=0

j=0

i=0

where, for our case, (j) = j! aj and (j) = j b. Therefore, we can write:





j
j
X
X
(ax)  
x
F (x) = 
j!
jb 
j!
j!
j=0

j=0

116

fiOn the Testability of BDI Agent Systems

P
1
The left hand sum is G(ax) where G(y) = n y n = 1y
(Wilf, 1994, Equation 2.5.1)35 .

P
n
x
d x
d
0
The right hand sum is equal to bx dx
n! (Wilf, 1994, Rule 2 , Section 2.3) = bx dx e
x
(Wilf, 1994, Equation 2.5.3) = bxe . Thus we have:
F (x) =

1
bxex
bxex =
1  ax
1  ax

P
xj
4
Therefore, f 4 (0, a, b) is the constant term in the power series 
j=0 f (j, a, b) j! , which
is F (0) = 0. To find a recurrence relation defining f 4 (j + 1, a, b) we equate the original
definition of F (x) in Equation 24 with our closed form of this function, differentiate each
side (to give us a power series with the f 4 (j, a, b) values shifted one position to the left),
and multiply by the denominator of the closed form, giving us the following derivation.





d X 4
d
bxex
xj 
(1  ax)
= (1  ax)
f (j, a, b)
dx
j!
dx 1  ax
j=0



X
xj1
b(x+1)ex
abxex
4
= (1  ax)
f (j, a, b)j
= (1  ax)
+
j!
1  ax
(1  ax)2
j=0

=


X
j=0



bxex
xj1 X 4
xj

= b(x+1)ex + a
f (j, a, b)j
af (j, a, b)j
j!
j!
1  ax
4

j=0

4

(recall that f (0, a, b) = 0)


X
X
xj
xj
4
=
f (j +1, a, b)(j +1)

ajf 4 (j, a, b)
(j +1)!
j!
j=0

j=0

= bxex + bex + a


X

f 4 (j, a, b)

j=0

(recall that

bxex

=

j=0

Equating the coefficients of

xj
j!

xj
j=0 jb j! ,

j
X

and ex =

j=0

j=0

P


X
xj
=b
j +b
j!

xj
j!
xj
j=0 j! )

P



X
xj
x
+a
f 4 (j, a, b)
j!
j!

we get:

f 4 (j +1, a, b)  ajf 4 (j, a, b) = bj + b + af 4 (j, a, b)
= f 4 (j +1, a, b) = b(j +1) + af 4 (j, a, b) + ajf 4 (j, a, b)
= (j +1)(b + af 4 (j, a, b))

(25)

35. Note that many of the operations performed on generating functions (and all those used in this paper) are
valid without concern about convergence of the series. In combinatorics, generating functions are often
treated not as analytic functions to be evaluated for specific variable values, but rather as formal (possibly
infinite) algebraic objects, which have well defined operations such as addition and multiplication. The
set of formal power series over a finite set of variables has the structure of a ring from abstract algebra,
and in this ring there is no notion of function convergence and evaluation (Wilf, 1994, ch. 2).

117

fiWinikoff & Cranefield

Appendix C. Analysis of Recursive Goal-Plan Trees
This appendix contains detailed derivations relating to Section 4.7.
4
C.1 Derivation of F
(goal(P M ), x, y, b, )
4
We can define F
(goal(P M ), x, y, b, ) in terms of n4 in the usual way, noting the upper
bound of  to realise the length bound:

4
F
(goal(P M ), x, y, b, ) =

 X

X

n4(goal(P M ), m, n, b)xm y n

m=0 n=0
4

where n(goal(P M ), m, n, b) is as defined in Section 4.7. We also make use of the nonbounded version (which has only four arguments):
4
F
(goal(P M ), x, y, b) =

 X

X

n4(goal(P M ), m, n, b)xm y n

m=0 n=0
4

We then can define n by counting successful traces:
n4(goal(P M ), m, n, b)
X
=
P M (p)

X

n4(p, m1 , n1 , b) n8(P M  {p:1}, m2 , n2 , b)

m1 +m2 =m
n1 +n2 =n

pset(P M )

where n8(P M, m, n, b) is the number of unsuccessful paths using zero or more of the plans
in the plan multiset P M (with respect to binding b) that have m actions, n of which are
failed actions.
The inner sum considers all ways to partition the numbers of actions (m) and action
failures (n) into those caused by a single plan of shape p and P
those P
caused by all the

other
plans.
As
in
Section
4.6
(page
98)
we
use
the
identity
m=0
p+q=m f (p, q) =
P P
p=0
q=0 f (p, q) to rewrite:
4
F
(goal(P M ), x, y, b)
 X

X
X
X
=
P M (p)
n4(p, m1 , n1 , b) n8(P M {p:1}, m2 , n2 , b)xm y n

m1 +m2 =m
n1 +n2 =n

m=0 n=0 pset(P M )

X

=

P M (p)

pset(P M )

 X

X

X

n4(p, m1 , n1 , b) n8(P M {p:1}, m2 , n2 , b)xm y n

m=0 n=0 m1 +m2 =m
n1 +n2 =n

to give us:
4
F
(goal(P M ), x, y, b)
X
=
P M (p)

pset(P M )


X
X

 X

X

n4(p, m1 , n1 , b)xm1 y n1 n8(P M {p:1}, m2 , n2 , b)xm2 y n2

m1 =0 m2 =0 n1 =0 n2 =0

118

fiOn the Testability of BDI Agent Systems

=

X

P M (p)

pset(P M )
 X

X

4

n(p, m1 , n1 , b)x

y

=

n8(P M {p:1}, m2 , n2 , b)xm2 y n2

m2 =0 n2 =0

m1 =0 n1 =0

X

 X

X

m1 n1

4

8

P M (p) F(p, x, y, b) F(P M  {p:1}, x, y, b)

pset(P M )
8
where F
(P M, x, y, b) is the generating function for n8(P M, m, n, b). In Section C.3 we
8
provide a definition of F
(P M, x, y, b) in terms of an auxiliary function G8 (see Section C.4).
We then introduce the bound on the length of paths  giving:
4
F
(goal(P M ), x, y, b, )
X
x
4
8
=
P M (p) (F
(p, x, y, b)  F
(P M  {p : 1}, x, y, b))

pset(P M )

=

X

x

4
8
P M (p) (F
(p, x, y, b, )  F
(P M  {p : 1}, x, y, b, ))

pset(P M )
8
C.2 Derivation of F
(goal(P M ), x, y, b, )

Similarly to the previous derivation, we define:
8
F
(goal(P M ), x, y, b, ) =

 X

X

n8(goal(P M ), m, n, b)xm y n

m=0 n=0
8
(goal(P M ), . . . ) in terms of the plans in P M , we
To derive a recursive definition of F
8
first define a new function n(P M, m, n, o, b), which denotes the number of unsuccessful
paths that use o of the plans in the multiset P M . We then have:

n8(goal(P M ), m, n, b) = n8(P M, m, n, |P M |, b)
This states that for the goal to fail, all |P M | plans in the multiset must be tried.
We define a generating function G8(P M, x, y, z, b, ) for n8(P M, m, n, o, b) that is ordinary in x and y but exponential in z, i.e. the coefficients of xm y n z o /o! are the values of
n8(P M, m, n, o, b).
We now have:
8
F
(goal(P M ), x, y, b, ) =

 X

X

n8(P M, m, n, |P M |, b)xm y n

m=0 n=0

which we wish to rewrite in terms of G8 . We do this by generalising the right hand side
to sum over possible values for the number of plans used (o), followed by a restriction to
select only values where o = |P M |:

119

fiWinikoff & Cranefield

8
F
(goal(P M ), x, y, b, )

= |P M |!

 X

X
n8 (P M, m, n, |P M |, b) z |P M |


|P M |! z |P M |

xm y n

m=0 n=0

 X
  P
8
o
X
o=0 n(P M, m, n, o, b)z /o! power(z)=|P M |
|P M |!
xm y n
|P M |
z
m=0 n=0

=

P
= |P M |!

P P 8

m n o
m=0
n=0
o=0 n(P M, m, n, o, b)x y z /o!



power(z)=|P M |

z |P M |

Since the nested sum is just the definition of G8 (see Section C.4), we can simplify this to:
8

F(goal(P M ), x, y, b, ) = |P M |!

G8(P M, x, y, z, b, ) power(z)=|P M |
z |P M |

8
In Section C.4 we derive a definition of G8(P M, . . .) in terms of F
(p, . . .) for each p 
set(P M ).

8
C.3 Definition of F
(P M, x, y, b, )

Recall that n8(P M, m, n, b) is the number of unsuccessful paths using zero or more of the
plans in the plan multiset P M (with respect to binding b) that have m actions, n of which
8
are failed actions, and F
(P M, x, y, b, ) is its ordinary generating function.
First we consider the case when P M is empty. In this case, there is precisely one way
8
to fail, and it generates a trace of length zero. Therefore, F
({}, x, y, b, ) = 1x0 y 0 = 1.
For the case when P M is non-empty we can sum over the number of plans used during
execution, which yields the following definition:
|P M |
8

n(P M, m, n, b) =

X

n8(P M, m, n, o, b)

o=0

where n8(P M, m, n, o, b) is, as before, the number of unsuccessful paths through the plan
8
multiset
M , using o of the plans. Therefore, using the definition of F
(P M, x, y, b, ) =
P PP

8
m
n
n
(P
M,
m,
n,
o,
b)x
y
,
we
have:
m=0
n=0 
8
F
(P M, x, y, b, )

=

M|
 X
 |P
X
X

n8(P M, m, n, o, b)xm y n

m=0 n=0 o=0

(replace n8 by looking up the coefficient of the corresponding term in G8 ,
the o! accounts for the division by o! in G8 ; we also reorder the summations)
|P M |

=

 X

X X

o![xm y n z o ]G8(P M, x, y, z, b, )xm y n

o=0 m=0 n=0

120

fiOn the Testability of BDI Agent Systems

(we shift o! outwards, and multiply by z o /z o )
P
|P M | P
m n o
8
m n o
X
n=0 [x y z ]G(P M, x, y, z, b, )x y z
m=0
=
o!
zo
o=0

|P M |

=

X
o=0

o!

G8(P M, x, y, z, b, ) power(z)=o
zo

C.4 Definition of G8(P M, x, y, z, b, )
We define G8(P M, x, y, z, b, ) as a generating function for n8(P M, m, n, o, b) that is ordinary in x and y but exponential in z (hence the division by o! below), with ( 0) as the
maximum allowed trace length:
G8(P M, x, y, z, b, ) =

 X
 X

X

n8(P M, m, n, o, b)

m=0 n=0 o=0

xm y n z o
o!

Recall that n8(P M, m, n, o, b) denotes the number of unsuccessful paths that use o of the
plans in the multiset P M . For an empty multiset of plans there is no successful execution,
and there is a single unsuccessful execution with 0 actions, that uses 0 plans, hence:
(
1 if m = n = o = 0
8
n({}, m, n, o, b) =
0 otherwise
Therefore, G8({}, x, y, z, b, ) = 1. For non-empty multisets we must partition the actions
in each trace, the action failures, and numbers of plans used, across the different plan bodies
in the multiset, and also consider all ways that the plans of the various plan shapes can be
interleaved to give an overall order for attempting plans:
n8({p1 :c1 , . . . , pj :cj }, m, n, o, b)
X
=
 n8({p1 :c1 }, m1 , n1 , o1 , b)    n8({pj :cj }, mj , nj , oj , b)
m1 ++mj =m
n1 ++nj =n
o1 ++oj =o

where  is the multinomial coefficient
Thus:

o
o1 ...oj



=

o!
o1 !...oj !

G8({p1 :c1 , . . . , pj :cj }, x, y, z, b, )
(by definition of G8, but using restriction, rather than a bounded sum on m,
and expanding n8 as above)



X
X
o
=
n8({p1 :c1 }, m1 , n1 , o1 , b)
o
.
.
.
o
1
j
m ++m =m
m,n,o=0

1

j

n1 ++nj =n
o1 ++oj =o

xm y n z o
   n({pj :cj }, mj , nj , oj , b)
o!
8

121

!
power(x)

fiWinikoff & Cranefield

=


X

X

o!
n8({p1 :c1 }, m1 , n1 , o1 , b)
o
!
.
.
.
o
!
1
j
=m

m,n,o=0 m1 ++mj
n1 ++nj =n
o1 ++oj =o

xm y n z o
   n8({pj :cj }, mj , nj , oj , b)
o!

!
power(x)

(cancelling o! and distributing the oi ! and the xmi , y ni and z oi )
=


X

X

n8({p1 :c1 }, m1 , n1 , o1 , b)

m,n,o=0 m1 ++mj =m
n1 ++nj =n
o1 ++oj =o

xm1 y n1 z o1
o1 !

xmj y nj z oj
   n({pj :cj }, mj , nj , oj , b)
oj !

!

8

(replacing


X

X

with

m=0 m1 +m2 =m


= 


X



X
X

and redistributing sums)

m1 =0 m2 =0

n8({p1 :c1 }, m1 , n1 , o1 , b)

xm1 y n1 z o1

m1 ,n1 ,o1 =0




X



power(x)

o1 !




n8({pj :cj }, mj , nj , oj , b)

xmj y nj z oj

mj ,nj ,oj =0

oj !


 power(x)

x

(replacing restriction  with  )



m
n
o
X
1
1
1
x y z  x
=
n8({p1 :c1 }, m1 , n1 , o1 , b)

o1 !
m1 ,n1 ,o1 =0



m
n
o
X
j
j
j
x
x y z 
  
n8({pj :cj }, mj , nj , oj , b)
oj !
mj ,nj ,oj =0

8

(by definition of G . . . )
x

x

= G8({p1 :c1 }, x, y, z, b, )      G8({pj :cj }, x, y, z, b, )

We now need to define G8({pi :ci }, x, y, z, b, ).
Consider n8({p:c}, m, n, o, b). The simple cases are where o = 0: if we do not use any
plans, then there is only a single unsuccessful
path, which has no actions (m = n = 0). On

c!
the other hand, if o > 0 then we have oc = o!(co)!
ways of selecting o out of the c available
copies of the plan p. These selected plans can be executed in o! different orders. For each
execution we sum over the possible distributions of actions (successful and unsuccessful)
122

fiOn the Testability of BDI Agent Systems

amongst the plans. This gives:
 
X
c


o!
n8(p, m1 , n1 , b)    n8(p, mo , no , b)


o

m1 ++mo =m
n1 ++no =n
n8({p:c}, m, n, o, b) =


1
if m = n = o = 0



0
otherwise

if o > 0

We therefore have the following definition of G8({p:c}, x, y, z, b, ), where the initial 1 abbreviates 1x0 y 0 z 0 /0!, i.e. the base case where m = n = o = 1, and the rest is from the
definition of G8 , expanding n8 using the above definition.
G8({p:c}, x, y, z, b, )
= 1+

 

X
c
o!
o
m


X

X

n8(p, m1 , n1 , b)    n8(p, mo , no , b)

1 ++mo =m
n1 ++no =n

m=0 n=0,o=1

xm y n z o
o!

(cancel o!/o!, rearrange sums and replace an upper bound of  on m
with a restriction)





   X
 X
 X
X

c 
8
8
m
n
o

= 1+
n(p, m1 , n1 , b)    n(p, mo , no , b)x y 

power(x) z
o 

o=1
m=0 n=0
m1 ++mo =m
n1 ++no =n


X

(replacing

X

m=0 m1 +m2 =m

= 1+

with



X
X

and redistributing sums)

m1 =0 m2 =0

  
X
c
o=1

o
 X

X

!
n8(p, m1 , n1 , b)xm1 y n1



m1 =0 n1 =0

 X

X

!!
n8(p, mo , no , b) xmo y no

mo =0 no =0
o

power(x) z
!o
   X
 X

X
c
= 1+
n8(p, m, n, b) xm y n
power(x) z o
o
m=0 n=0
o=1
XX
8
(Replace
n8(p, m, n, b)xm y n with F
(p, x, y, b, ) as per its definition)
m

n

c  
X
c
= 1+
F 8 (p, x, y, b, )o power(x) z o
o 
o=1
c  
X
c
F 8 (p, x, y, b, )ox z o
= 1+
o 
o=1

123

fiWinikoff & Cranefield

Appendix D. Analysis of Procedural Code Structures
We seek to derive an expression for the largest possible number of paths that a program of
given size m can have, i.e. a definition of n(m) = max{n(P ) : |P | = m}. Recall that a
program is either an (atomic) statement s which has a single path (i.e. n(s) = 1), a sequence
of two programs P1 ; P2 where n(P1 ; P1 ) = n(P1 )  n(P2 ), or a conditional P1 + P2 where
n(P1 + P2 ) = n(P1 ) + n(P2 ).
It is relatively easy to see by examining possible programs that for m  3 we have
n(m) = m. For instance, the largest number of paths for m = 3 is obtained by the program
s + s + s. It is also easy to show that for m = 4 the largest number of paths possible is 4.
But what about larger values of m? We observe that for all m > 4 the program36 with
the largest number of paths follows a particular form. For m = 5 the program with the
largest path can be written as P5 = (s + s + s); (s + s), and we have n(P5 ) = 3  2. More
generally, we define S2 to be s + s, and S3 to be s + s + s, and we then have the following
result, which shows that programs that have a maximal number of paths for their size, can
be considered to be of a particular form.
Theorem D.1 Any program of size i (for i > 4) that has the largest possible number of
paths can be written as Pi = Pi1 ; Pi2 ; . . . ; Pik where each of the Pij (1  j  k) is either S2
or S3 .
Proof: We establish this result by induction. We assume that it holds for all n such that
4 < n  m, and then show that it must also hold for m + 1. So, let us assume that
there is a program Pm+1 which has a maximal number of paths, but is not in the form
j
1
2
k
Pm+1
; Pm+1
; . . . ; Pm+1
where each Pm+1
is either S2 or S3 . There are two cases, depending
on the structure of Pm+1 . We consider each case in turn and show that in fact either (a)
Pm+1 can be rewritten to be in the desired form, preserving the number of paths and the
program size; or (b) Pm+1 cannot be maximal, since we can construct a program with size
m + 1 that has a larger number of paths than Pm+1 .
j
1
2
k
Case 1: Pm+1 has the form Pm+1
; Pm+1
; . . . ; Pm+1
but at least one of the Pm+1
is neither
i
S2 nor S3 . Let Pm+1 be one of the sub-programs that is neither S2 nor S3 . For convenience
i
we define P i as shorthand for Pm+1
. Now, since P i has size less than m + 1, the induction
hypothesis applies37 , and so it can be written in the form Pi1 ; Pi2 ; . . . Pil where each Pij is
either S2 or S3 . It is easy to see that one can then rewrite Pm+1 into the desired form by
exploiting the associativity of ;, rewriting it as follows:
i1
i+1
i1
i+1
. . . Pm+1
; (Pi1 ; Pi2 ; . . . Pij ); Pm+1
; . . . = . . . Pm+1
; Pi1 ; Pi2 ; . . . Pij ; Pm+1
;...
i
Applying this rewriting to all Pm+1
that are not S2 or S3 yields a program that has size
m + 1, the same number of paths as the original program, but that is in the desired form: a
sequence of sub-programs, each of which is either S2 or S3 . This shows that the result holds
for m + 1, i.e. that a maximal-path program can be written in the desired form.
1
2
k
Case 2: Pm+1 does not have the form Pm+1
; Pm+1
; . . . ; Pm+1
for any k, which means that
1
k
Pm+1 must consist of a single conditional, i.e. Pm+1 = Pm+1 + . . . + Pm+1
for some k > 1.

36. In fact there will be more than one maximal-path program, but they all have the same structure, modulo
swapping the order of arguments to + and ;.
37. Or, if it has size 4, then it can be written as S2 ; S2 which has the maximal number of paths for a program
of size 4 and meets the desired form.

124

fiOn the Testability of BDI Agent Systems

1
2
Without loss of generality we can view Pm+1 as being of the form Pm+1
+ Pm+1
(by viewing
1
k
1
k
Pm+1 + . . . + Pm+1 as (Pm+1 + . . .) + Pm+1 if k > 2). We now consider the following
1
2
sub-cases, depending on the values of n(Pm+1
) and n(Pm+1
).
1
2
Case 2a: Both n(Pm+1
) and n(Pm+1
) are greater than 2. We can then show that Pm+1 is
0
1
2
not maximal. Consider the program Pm+1
= Pm+1
; Pm+1
(i.e. where + is replaced
1
2
1
2
by ;). We know that n(Pm+1 ; Pm+1 ) = n(Pm+1 )  n(Pm+1
). Without loss of gen1
2
erality, lets assume that n(Pm+1 )  n(Pm+1 ). We then show that the original Pm+1
0
1
has fewer paths than Pm+1
. The number of paths of Pm+1 is n(Pm+1 ) = n(Pm+1
)+
2
1
2
1
2
n(Pm+1 ). Since n(Pm+1 )  n(Pm+1 ), we have that n(Pm+1 ) = n(Pm+1 ) + n(Pm+1 ) 
2
2
2
2
1
n(Pm+1
) + n(Pm+1
) = 2  n(Pm+1
). Since n(Pm+1
) and n(Pm+1
) are both greater
2
1
2
0
than 2, we then have that 2  n(Pm+1 ) < n(Pm+1 )  n(Pm+1 ) = n(Pm+1
), i.e. that
0
Pm+1 has more paths than Pm+1 , and hence Pm+1 is not maximal for m + 1.
1
2
Case 2b: At least one of n(Pm+1
) and n(Pm+1
) is not greater than 2. Without loss of
1
2
1
generality, we assume that n(Pm+1 )  n(Pm+1
). There are then two cases: n(Pm+1
)
can be either 2 or 1.
1
) = 1. Now the only
Sub-case 2b(i): Let us consider first the case where n(Pm+1
program that has one path is a statement s, or a sequence of statements s; s; . . . ; s.
Clearly the latter is not maximal since replacing it with s + s + . . . + s would
result in a program of the same size but with more paths. So, therefore if Pm+1
1
2
2
is maximal, then Pm+1
must be just s, so Pm+1 = s + Pm+1
. Therefore Pm+1
has
size m. There are now two sub-cases: either m is still greater than 4, or m = 4.
The second sub-case is simple: if m is 4 then we can show, by inspecting possible
2
programs of size 4, that n(4) = 4, and we therefore have that n(s + Pm+1
) 
1 + 4 = 5. However, we also know that (s + s + s); (s + s) has size 5 but 6 paths,
and hence in this sub-case Pm+1 cannot have the maximal number of paths. In
the first sub-case, where m is still greater than 4, the induction hypothesis applies
2
2
can be written in the desired form. We abbreviate Pm+1
by
and therefore Pm+1
j
i
1
2
P2 , and then have Pm+1 = s + (P2 ; P2 ; . . . ; P2 ) where each P2 is either S2 or
00
S3 . Consider now the variant program Pm+1
= ((s + P21 ); P22 ; . . . P2j ), which
00
clearly has the same size as Pm+1 . We now show that Pm+1
has more paths than
j
00
1
2
2
Pm+1 : n(Pm+1 ) = ((1 + n(P2 ))  n(P2 ; . . . ; P2 )) = n(P2 ; . . . ; P2j ) + (n(P21 ) 
n(P22 ; . . . ; P2j )). Now, n(Pm+1 ) = 1 + (n(P21 )  n(P22 ; . . . ; P2j )). In order to show
00
that n(Pm+1 ) < n(Pm+1
) we just need to show that 1 < n(P22 ; . . . ; P2j ) which
follows from the fact that there must be at least one P2i , and that, since each P2i
is either S2 or S3 , it has size of at least 2.
1
2
1
Sub-case 2b(ii): We know that n(Pm+1
) = 2 and that 2  n(Pm+1
). Since n(Pm+1
)
2
2
2
n(Pm+1 ) we have that n(Pm+1 )  2 and hence that n(Pm+1 ) = 2 + n(Pm+1 ) 
2
0
2
2  n(Pm+1
) = n(Pm+1
). Now, if n(Pm+1
) is strictly greater than 2 then we have
0
that n(Pm+1 ) is strictly less than n(Pm+1 ) and we have shown that Pm+1 actually
2
does not have a maximal number of paths. On the other hand, if n(Pm+1
)=2
2
then we have that n(Pm+1 ) = 2 + n(Pm+1 ) = 2 + 2 = 4. However, for values of
m where this theorem applies, we know that n(m) > 4, and so we therefore have
shown that in this sub-case Pm+1 is not maximal for m + 1.

125

fiWinikoff & Cranefield

We have shown that if we assume that Pm+1 is maximal but does not have the structure
specified, then in fact one can derive another program, also of size m + 1, but which either
does satisfy the desired structure, or has a larger number of paths than Pm+1 , which contradicts our assumption that Pm+1 is maximal. This establishes the desired property for Pm+1 .
By induction the result then applies for all m > 4, as desired.
The previous result shows that when considering programs of a given size m that have
the largest possible number of paths (denoted Pm ), we can limit ourselves to considering
programs that are of the form P1m ; P2m ; . . . ; Pkm where each Pim is either s + s or s + s + s.
We now derive a definition for n(m). Firstly, we observe that, by inspecting cases:
n(m) = m, if m  4
n(5) = 6
n(6) = 9
The two first cases have been discussed above. For the last case, there are only two programs
which have the appropriate structure and have size 6: S2 ; S2 ; S2 (with 8 paths) and S3 ; S3
(with 9 paths).
We now consider m > 6. Adding a statement to the program (i.e. going from m to m+1)
in effect modifies Pm by adding an s to one of the Pim , which increments n(Pim ) by one.
Since multiplication is commutative and associative, without loss of generality, we assume
m )  n(P m ) and
that we increment n(Pkm ). We therefore have that n(Pm ) = n(P1m ; . . . ; Pk1
k
m
m
m
that n(Pm+1 ) = n(P1 ; . . . ; Pk1 )  (n(Pk ) + 1). There are two cases:
m )3 and that therefore
Case 1: If all the Pim are S3 , then we have n(Pm ) = n(P1m ; . . . ; Pk1
m )  4 = n(P )  4 . Note that in this case P
n(Pm+1 ) = n(P1m ; . . . ; Pk1
m
m+1 can be
3
m
m
written as P1 ; . . . ; Pk1 ; S2 ; S2 .

Case 2: if some Pim are S2 and some are S3 then we observe that replacing a 2 with a 3 gives
a greater increase to the number of paths than replacing a 3 with a 4, and hence (after
m )2
possibly reordering the Pim so that Pkm = S2 ) we have n(Pm ) = n(P1m ; . . . ; Pk1
3
m
m
and that n(Pm+1 ) = n(P1 ; . . . ; Pk1 )  3 = n(Pm )  2 .
We therefore have a recursive definition for n(m) depending on the form of Pm . We next
observe that in fact the form of Pm follows a simple cycle. We know that for m = 6, case 1
holds (as above, P6 = S3 ; S3 ). We therefore have that P7 can be written as S3 ; S2 ; S2 , hence
P8 can be written as S3 ; S3 ; S2 or S3 ; S2 ; S3 , and hence P9 can be written as S3 ; S3 ; S3 .
More generally, we can prove by induction that Pm can be written as P1m ; . . . ; Pkm where
the following holds: (a) if m is a multiple of 3, then all of the Pim are S3 ; and (b) if m is
one more than a multiple of 3, then exactly two of the Pim are S2 and the rest are S3 ; and
(c) if m is two more than a multiple of 3, then exactly one of the Pim is S2 and the rest are
S3 . This gives us the following recursive definition, where m  6 is a multiple of 3:
n(m + 1) = n(m) 

4
3

n(m + 2) = n(m + 1) 
126

3
2

fiOn the Testability of BDI Agent Systems

n(m + 3) = n(m + 2) 

3
2

Which can be simplified to:
4
3
34
n(m + 2) = n(m) 
= 2  n(m)
23
334
= 3  n(m)
n(m + 3) = n(m) 
223
n(m + 1) = n(m) 

We can easily derive a non-recursive definition by focusing on the last case and observing
that as n(6) = 9 = 32 and n(m + 3) = 3  n(m) (for m  6 being a multiple of 3), then
we have that n(m) = 3m/3 . We can substitute this in the definition above to obtain the
following complete definition for n(m), where m  6 is a multiple of 3:
n(1) = 1
n(2) = 2
n(3) = 3
n(4) = 4
n(5) = 6
n(m) = 3m/3
4
n(m + 1) =
 3m/3
3
n(m + 2) = 2  3m/3

127

fiWinikoff & Cranefield

References
Benfield, S. S., Hendrickson, J., & Galanti, D. (2006). Making a strong business case for
multiagent technology. In Stone, P., & Weiss, G. (Eds.), Proceedings of the Fifth International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS),
pp. 1015. ACM Press.
Bordini, R. H., Fisher, M., Pardavila, C., & Wooldridge, M. (2003). Model checking AgentSpeak. In Proceedings of the Second International Joint Conference on Autonomous
Agents and Multiagent Systems (AAMAS), pp. 409416. ACM Press.
Bordini, R. H., Hubner, J. F., & Wooldridge, M. (2007). Programming multi-agent systems
in AgentSpeak using Jason. Wiley.
Bratman, M. E., Israel, D. J., & Pollack, M. E. (1988). Plans and resource-bounded practical
reasoning. Computational Intelligence, 4, 349355.
Bratman, M. E. (1987). Intentions, Plans, and Practical Reason. Harvard University Press,
Cambridge, MA.
Burch, J., Clarke, E., McMillan, K., Dill, D., & Hwang, J. (1992). Symbolic model checking:
1020 states and beyond. Information and Computation, 98 (2), 142170.
Burmeister, B., Arnold, M., Copaciu, F., & Rimassa, G. (2008). BDI-agents for agile goaloriented business processes. In Proceedings of the Seventh International Conference on
Autonomous Agents and Multiagent Systems (AAMAS) [Industry Track], pp. 3744.
IFAAMAS.
Busetta, P., Ronnquist, R., Hodgson, A., & Lucas, A. (1999). JACK Intelligent Agents Components for Intelligent Agents in Java. AgentLink News (2).
Dastani, M. (2008). 2APL: A practical agent programming language. Autonomous Agents
and Multi-Agent Systems, 16 (3), 214248.
Dastani, M., Hindriks, K. V., & Meyer, J.-J. C. (Eds.). (2010). Specification and Verification
of Multi-agent systems. Springer, Berlin/Heidelberg.
de Silva, L., & Padgham, L. (2004). A comparison of BDI based real-time reasoning and
HTN based planning. In Webb, G., & Yu, X. (Eds.), AI 2004: Advances in Artificial
Intelligence, Vol. 3339 of Lecture Notes in Computer Science, pp. 11671173. Springer,
Berlin/Heidelberg.
Dennis, L. A., Fisher, M., Webster, M. P., & Bordini, R. H. (2012). Model checking agent
programming languages. Automated Software Engineering, 19 (1), 363.
dInverno, M., Kinny, D., Luck, M., & Wooldridge, M. (1998). A formal specification of
dMARS. In Singh, M., Rao, A., & Wooldridge, M. (Eds.), Intelligent Agents IV:
Proceedings of the Fourth International Workshop on Agent Theories, Architectures,
and Languages, Vol. 1365 of Lecture Notes in Artificial Intelligence, pp. 155176,
Berlin/Heidelberg. Springer.
Dorigo, M., & Stutzle, T. (2004). Ant Colony Optimization. MIT Press.
Dwyer, M. B., Hatcliff, J., Pasareanu, C., Robby, & Visser, W. (2007). Formal software analysis: Emerging trends in software model checking. In Future of Software Engineering
2007, pp. 120136, Los Alamitos, CA. IEEE Computer Society.
128

fiOn the Testability of BDI Agent Systems

Ekinci, E. E., Tiryaki, A. M., Cetin, O., & Dikenelli, O. (2009). Goal-oriented agent testing
revisited. In Luck, M., & Gomez-Sanz, J. J. (Eds.), Agent-Oriented Software Engineering IX, Vol. 5386 of Lecture Notes in Computer Science, pp. 173186, Berlin/Heidelberg. Springer.
Erol, K., Hendler, J., & Nau, D. (1996). Complexity results for HTN planning. Annals of
Mathematics and Artificial Intelligence, 18 (1), 6993.
Erol, K., Hendler, J. A., & Nau, D. S. (1994). HTN planning: Complexity and expressivity.
In Proceedings of the 12th National Conference on Artificial Intelligence (AAAI), pp.
11231128. AAAI Press.
Fix, L., Grumberg, O., Heyman, A., Heyman, T., & Schuster, A. (2005). Verifying very
large industrial circuits using 100 processes and beyond. In Peled, D., & Tsay, Y.K. (Eds.), Automated Technology for Verification and Analysis, Vol. 3707 of Lecture
Notes in Computer Science, pp. 1125, Berlin/Heidelberg. Springer.
Georgeff, M. P., & Lansky, A. L. (1986). Procedural knowledge. Proceedings of the IEEE,
Special Issue on Knowledge Representation, 74 (10), 13831398.
Gomez-Sanz, J. J., Bota, J., Serrano, E., & Pavon, J. (2009). Testing and debugging of
MAS interactions with INGENIAS. In Luck, M., & Gomez-Sanz, J. J. (Eds.), AgentOriented Software Engineering IX, Vol. 5386 of Lecture Notes in Computer Science,
pp. 199212, Berlin/Heidelberg. Springer.
Huber, M. J. (1999). JAM: A BDI-theoretic mobile agent architecture. In Proceedings of
the Third International Conference on Autonomous Agents (Agents99), pp. 236243.
ACM Press.
Ingrand, F. F., Georgeff, M. P., & Rao, A. S. (1992). An architecture for real-time reasoning
and system control. IEEE Expert, 7 (6), 3344.
Jorgensen, P. (2002). Software Testing: A Craftsmans Approach (Second edition). CRC
Press.
Lee, J., Huber, M. J., Kenny, P. G., & Durfee, E. H. (1994). UM-PRS: An implementation of the procedural reasoning system for multirobot applications. In Proceedings of the Conference on Intelligent Robotics in Field, Factory, Service, and Space
(CIRFFSS94), pp. 842849. American Institute of Aeronautics and Astronautics.
Mathur, A. P. (2008). Foundations of Software Testing. Pearson.
Miller, J. C., & Maloney, C. J. (1963). Systematic mistake analysis of digital computer
programs. Communications of the ACM, 6 (2), 5863.
Morley, D., & Myers, K. (2004). The SPARK agent framework. In Proceedings of the
Third International Joint Conference on Autonomous Agents and Multiagent Systems
(AAMAS), pp. 714721, New York. ACM.
Munroe, S., Miller, T., Belecheanu, R., Pechoucek, M., McBurney, P., & Luck, M. (2006).
Crossing the agent technology chasm: Experiences and challenges in commercial applications of agents. Knowledge Engineering Review, 21 (4), 345392.
129

fiWinikoff & Cranefield

Naish, L. (2007). Resource-oriented deadlock analysis. In Dahl, V., & Niemela, I. (Eds.),
Proceedings of the 23rd International Conference on Logic Programming, Vol. 4670 of
Lecture Notes in Computer Science, pp. 302316. Springer, Berlin/Heidelberg.
Nguyen, C., Miles, S., Perini, A., Tonella, P., Harman, M., & Luck, M. (2009a). Evolutionary testing of autonomous software agents. In Proceedings of the 8th International
Conference on Autonomous Agents and Multiagent Systems (AAMAS), pp. 521528.
IFAAMAS.
Nguyen, C. D., Perini, A., & Tonella, P. (2009b). Experimental evaluation of ontology-based
test generation for multi-agent systems. In Luck, M., & Gomez-Sanz, J. J. (Eds.),
Agent-Oriented Software Engineering IX, Vol. 5386 of Lecture Notes in Computer
Science, pp. 187198, Berlin/Heidelberg. Springer.
Nguyen, C. D., Perini, A., & Tonella, P. (2007). Automated continuous testing of multiagent systems. In Proceedings of the Fifth European Workshop on Multi-Agent Systems
(EUMAS).
Padgham, L., & Winikoff, M. (2004). Developing Intelligent Agent Systems: A Practical
Guide. John Wiley and Sons.
Paolucci, M., Shehory, O., Sycara, K. P., Kalp, D., & Pannu, A. (2000). A planning component for RETSINA agents. In Jennings, N. R., & Lesperance, Y. (Eds.), Proceedings
of the 6th International Workshop on Agent Theories, Architectures, and Languages
(ATAL), Vol. 1757 of Lecture Notes in Computer Science, pp. 147161, Berlin/Heidelberg. Springer.
Pokahr, A., Braubach, L., & Lamersdorf, W. (2005). Jadex: A BDI reasoning engine. In
Bordini, R. H., Dastani, M., Dix, J., & El Fallah Seghrouchni, A. (Eds.), Multi-Agent
Programming: Languages, Platforms and Applications, chap. 6, pp. 149174. Springer.
Raimondi, F., & Lomuscio, A. (2007). Automatic verification of multi-agent systems by
model checking via ordered binary decision diagrams. J. Applied Logic, 5 (2), 235
251.
Rao, A. S. (1996). AgentSpeak(L): BDI agents speak out in a logical computable language.
In de Velde, W. V., & Perrame, J. (Eds.), Agents Breaking Away: Proceedings of
the Seventh European Workshop on Modelling Autonomous Agents in a Multi-Agent
World (MAAMAW96), Vol. 1038 of Lecture Notes in Artificial Intelligence, pp. 4255,
Berlin/Heidelberg. Springer.
Rao, A. S., & Georgeff, M. P. (1991). Modeling rational agents within a BDI-architecture.
In Allen, J., Fikes, R., & Sandewall, E. (Eds.), Proceedings of the Second International
Conference on Principles of Knowledge Representation and Reasoning, pp. 473484.
Morgan Kaufmann.
Sardina, S., & Padgham, L. (2011). A BDI agent programming language with failure handling, declarative goals, and planning. Autonomous Agents and Multi-Agent Systems,
23 (1), 1870.
Shaw, P., Farwer, B., & Bordini, R. (2008). Theoretical and experimental results on the
goal-plan tree problem. In Proceedings of the Seventh International Conference on
Autonomous Agents and Multiagent Systems (AAMAS), pp. 13791382. IFAAMAS.
130

fiOn the Testability of BDI Agent Systems

Sloane, N. J. A. (2007). The on-line encyclopedia of integer sequences. http://www.research.
att.com/njas/sequences/.
Thangarajah, J., Winikoff, M., Padgham, L., & Fischer, K. (2002). Avoiding resource
conflicts in intelligent agents. In van Harmelen, F. (Ed.), Proceedings of the 15th
European Conference on Artificial Intelligence (ECAI), pp. 1822. IOS Press.
van Riemsdijk, M. B., Dastani, M., & Winikoff, M. (2008). Goals in agent systems: A
unifying framework. In Proceedings of the Seventh Conference on Autonomous Agents
and Multiagent Systems (AAMAS), pp. 713720. IFAAMAS.
Wilf, H. S. (1994). generatingfunctionology (Second edition). Academic Press Inc., Boston,
MA. http://www.math.upenn.edu/wilf/gfology2.pdf.
Winikoff, M. (2010). Assurance of Agent Systems: What Role should Formal Verification
play?. In Dastani, M., Hindriks, K. V., & Meyer, J.-J. C. (Eds.), Specification and
Verification of Multi-agent systems, chap. 12, pp. 353383. Springer, Berlin/Heidelberg.
Winikoff, M., Padgham, L., Harland, J., & Thangarajah, J. (2002). Declarative & procedural goals in intelligent agent systems. In Proceedings of the Eighth International
Conference on Principles of Knowledge Representation and Reasoning (KR2002), pp.
470481, Toulouse, France. Morgan Kaufmann.
Wooldridge, M. (2002). An Introduction to MultiAgent Systems. John Wiley & Sons,
Chichester, England.
Wooldridge, M., Fisher, M., Huget, M.-P., & Parsons, S. (2002). Model checking multi-agent
systems with MABLE. In Proceedings of the First International Joint Conference on
Autonomous Agents and Multi-Agent Systems (AAMAS), pp. 952959. ACM Press.
Zhang, Z., Thangarajah, J., & Padgham, L. (2009). Model based testing for agent systems.
In Filipe, J., Shishkov, B., Helfert, M., & Maciaszek, L. (Eds.), Software and Data
Technologies, Vol. 22 of Communications in Computer and Information Science, pp.
399413, Berlin/Heidelberg. Springer.
Zhu, H., Hall, P. A. V., & May, J. H. R. (1997). Software unit test coverage and adequacy.
ACM Computing Surveys, 29 (4), 366427.

131

fi