Journal of Artificial Intelligence Research 51 (2014) 377-411

Submitted 7/14; published 10/14

A Novel SAT-Based Approach to Model Based Diagnosis
Amit Metodi

AMITMET @ CS . BGU . AC . IL

Department of Computer Science,
Ben Gurion University of the Negev, Beer-Sheva, Israel

Roni Stern
Meir Kalech

RONI . STERN @ GMAIL . COM
KALECH @ BGU . AC . IL

Department of Information Systems Engineering,
Ben Gurion University of the Negev, Beer-Sheva, Israel

Michael Codish

MCODISH @ CS . BGU . AC . IL

Department of Computer Science,
Ben Gurion University of the Negev, Beer-Sheva, Israel

Abstract
This paper introduces a novel encoding of Model Based Diagnosis (MBD) to Boolean Satisfaction (SAT) focusing on minimal cardinality diagnosis. The encoding is based on a combination
of sophisticated MBD preprocessing algorithms and the application of a SAT compiler which optimizes the encoding to provide more succinct CNF representations than obtained with previous
works. Experimental evidence indicates that our approach is superior to all published algorithms
for minimal cardinality MBD. In particular, we can determine, for the first time, minimal cardinality diagnoses for the entire standard ISCAS-85 and 74XXX benchmarks. Our results open the way
to improve the state-of-the-art on a range of similar MBD problems.

1. Introduction
Automated diagnosis is concerned with reasoning about the health of systems, including the identification of abnormal behavior, isolation of faulty components and prediction of system behavior
under normal and abnormal conditions. As systems become large-scale and more complex, their
automated diagnosis becomes more challenging. Model Based Diagnosis (MBD) is an artificial
intelligence based approach that aims to cope with the diagnosis problem (Reiter, 1987; de Kleer
& Williams, 1987). In MBD, a model of the system is first built. A diagnoser then observes the
system to predict its behavior by the model. Discrepancies between the observation and the prediction are used as the input for a diagnosis algorithm which produces a set of possible faults that
can explain the observation. MBD has been deployed in several real-world applications, including
spacecrafts (Williams & Nayak, 1996), satellite decision support systems (Feldman, de Castro, van
Gemund, & Provan, 2013), the automotive industry (Struss & Price, 2003) and spreadsheets (Jannach & Schmitz, 2014). Also, there exist several commercial MBD tools (Feldman, 2012; Dressler
& Struss, 1995).
MBD is known to be a hard problem where algorithms have exponential runtime (exponential
in the number of components in the diagnosed system). Moreover, the number of potential diagnoses for a given observation can be huge. Therefore, MBD algorithms typically focus on minimal
c
2014
AI Access Foundation. All rights reserved.

fiM ETODI , S TERN , K ALECH & C ODISH

diagnoses: minimal subset  that do not contain other diagnoses, and minimal cardinality  that
are smallest in size. Computing the first minimal diagnosis is in P , but computing the next one is
NP-hard (Bylander, Allemang, Tanner, & Josephson, 1991). Computing the minimal cardinality is
NP-hard, even for the first diagnosis (Selman & Levesque, 1990). In this work we focus on this
hard task of finding minimal cardinality diagnoses.
The study of Model-Based Diagnosis has resulted in a variety of computational and modeling
challenges. In this paper we focus on one such challenge which has received much attention over
the years. Originally defined by Reiter (1987) and by de Kleer and Williams (1987), this problem
aims to diagnose multiple faulty components in the so-called weak fault model, which ignores the
mode of abnormal behavior of components. This problem has been extensively researched for more
than 25 years and a wide range of papers propose different algorithms to solve it, including a range
of papers from recent years (Feldman & van Gemund, 2006; Williams & Ragno, 2007; Feldman,
Provan, & van Gemund, 2010a; Siddiqi & Huang, 2007, 2011). When addressing this challenge, it
is common practice to focus on the diagnosis of Combinational Logic Circuits. Namely, Boolean
circuits where the single output of each component is determined only by the logical function of its
current input state (independent of time and with no feedback).
In the basic setting a diagnosis considers a single observation on the inputs and outputs of
the system. Variations consider additional information such as probabilities on component failure,
multiple observations on the inputs and outputs of the system, and observations on internal positions
of the system (probes). In this paper we focus on the basic setting. Extensions and variations are
discussed in Section 8.
Even in the basic setting, solving an MBD problem is often impractical, especially for highcardinality faults. For instance, in a system of 1000 components, to find a minimal cardinality
diagnosis of size 5, a diagnosis engine must verify the absence of a diagnosis consisting of 4 components (there are more than 1010 such combinations). To overcome the complexity of the problem
we consider a novel encoding to SAT.
In recent years, Boolean SAT solving techniques have improved dramatically. Todays SAT
solvers are considerably faster and able to manage larger instances than yesterdays. Moreover, encoding and modeling techniques are better understood and increasingly innovative. SAT is currently
applied to solve a wide variety of hard and practical combinatorial problems, often outperforming
dedicated algorithms. For a survey on the state-of-the-art in SAT solving see the work by Biere,
Heule, van Maaren, and Walsh (2009) or the draft of the forthcoming volume of The Art of Computer Programming (Knuth, 2014).
The general idea is to encode a (typically, NP) hard problem instance, , to a Boolean formula,
 , such that the solutions of  correspond to the satisfying assignments of  . Given the encoding,
a SAT solver is then applied to solve .
SAT-based solutions for MBD have already been proposed. Smith et al. (2005) encode a circuit,
representing each component through its clauses and add constraints for cardinality. This is the basis
for all the other SAT-based encodings, including the one we contribute in this paper. Bauer (2005)
introduces a tailored SAT solver specifically designed to return many diagnoses. Stein et al. (2006)
address diagnosis of qualitative models of physical systems with multiple fault modes. More recently, Feldman et al. (2010) propose an encoding to MAX-SAT and demonstrate that off-the-shelf
solvers require more calls to a SAT solver than the stochastic diagnosis algorithm SAFARI (Feldman
et al., 2010a).
378

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

These previous applications of SAT for MBD appear to indicate that SAT and MAX-SAT solvers
are doomed to perform poorly on the standard benchmarks (Feldman et al., 2010). This paper proves
the contrary. Our SAT-based approach differs from previous SAT encodings in several key aspects.
First, sophisticated MBD preprocessing techniques are applied to facilitate the construction of a
carefully designed constraint model, which includes constraints that exploit unique substructures in
the diagnosed system. Second, this constraint model is compiled to a corresponding CNF using a
constraint compiler called BEE (Metodi & Codish, 2012), that simplifies constraints and generates
an encoding to CNF which significantly improves the subsequent runtime of the underlying SAT
solver. Lastly, a structural abstraction inspired by Siddiqi and Huang (2007) is used to decompose
the diagnosis problem, such that the SAT solver is only used to find top-level diagnoses, and
we show a simple poly-time algorithm to expand these top-level diagnoses to find all minimal
cardinality diagnoses. Our approach requires some preprocessing of the diagnosed system, but the
complexity of that preprocessing is a low-order polynomial, and negligible (both theoretically and
empirically) compared to the cost of the actual SAT solving.
We evaluated our SAT-based approach using two standard benchmarks: ISCAS-85 (Brglez,
Bryan, & Kozminski, 1989) and 74XXX. These are the standard benchmarks in the MBD literature, used extensively from the time they were made available until today (Feldman & van Gemund,
2006; Feldman et al., 2010a; Siddiqi & Huang, 2007, 2011; Stern, Kalech, Feldman, & Provan,
2012; Nica, Pill, Quaritsch, & Wotawa, 2013). Finding minimal cardinality diagnoses for hard sets
of observations in the ISCAS-85 has been a long standing challenge in the MBD community and
used in diagnosis competitions (DXC, 2009). The ISCAS-85 systems were also used as a standard
for automatic benchmark generation (Wang & Provan, 2010).
We consider three known sets of observations with minimal cardinalities between 131, and
for the first time succeed to compute a minimal cardinality diagnosis for all observations in the
benchmark. We compare our approach to a wide collection of state-of-the-art algorithms for MBD,
including: HA* (Feldman & van Gemund, 2006), CDA* (Williams & Ragno, 2007), SAFARI (Feldman et al., 2010a), HDIAG (Siddiqi & Huang, 2007) and DCAS (Siddiqi & Huang, 2011). Results
are unequivocal. Our approach outperforms the others, often by orders of magnitude, in terms of
runtime. This result is even more significant, as SAFARI is a stochastic algorithm, known as fast,
which does not even aim to guarantee minimal cardinality. Our approach, on the other hand, guarantees a minimal cardinality diagnosis and runs faster than SAFARI.
This paper goes beyond our preliminary version of this work (Metodi, Stern, Kalech, & Codish,
2012a). We provide a detailed description of each of the components of our approach, we present
detailed algorithms, prove correctness, provide additional examples and present a more elaborate
experimental evaluation. In the next section we discuss additional related work. Section 3 presents
the required background on MBD. In Section 4 we present the standard approach to model MBD
with SAT. Section 5 is the main part of this paper in which we describe the building blocks of our tool
to find minimal cardinality diagnosis. Section 6 describes how these building blocks are combined
into a diagnosis algorithm. Comprehensive evaluation of our approach is given in Section 7. Section
8 discusses the applicability of our approach in a more general setting and Section 9 concludes.

2. Related Work
Since the late 80s, the Model Based Diagnosis problem with weak fault model has been widely
researched and a wide range of papers propose different algorithms to solve it (Reiter, 1987; de Kleer
379

fiM ETODI , S TERN , K ALECH & C ODISH

& Williams, 1987; Feldman & van Gemund, 2006; Williams & Ragno, 2007; Feldman et al., 2010a;
Siddiqi & Huang, 2007, 2011). Till today it is considered a challenge as reflected by the synthetic
track in the annual DXC diagnosis competition (DXC, 2009).
Many of the existing diagnosis techniques propose to apply a combination of deterministic reasoning and search algorithms. One classic approach involves a two stage process. First, it identifies
conflict sets, each of which includes at least one fault. Then, it applies a hitting set algorithm to
compute sets of multiple faults that explain the observation (de Kleer & Williams, 1987; Williams
& Ragno, 2007). These methods guarantee sound diagnoses, and some of them are even complete.
However, they tend to fail for large systems due to infeasible runtime or space requirements.
An alternative method is to directly search for diagnoses by trying different assumptions on
which components are faulty. For example, the DRUM-II diagnosis engine finds a minimal diagnosis by performing an iterative deepening search, limiting in every iteration, the number of
components that are assumed to be faulty (Frohlich & Nejdl, 1997). DRUM-II also analyzes the
dependencies between components to prune irrelevant diagnoses. Recent work presents empirical
evidence suggesting that direct search for diagnoses is often better than conflict-directed diagnosis algorithms (Nica et al., 2013). Nica et al. did not compare against our SAT-based approach,
as it uses pre-processing. In this work we show that the proposed pre-processing is very efficient
computationally and results in huge speedups during the search for a diagnosis. This form of preprocessing is a key ingredient which enables us to find very large minimal cardinality diagnoses,
even with sizes up to 31.
Another approach considers the diagnosis problem in terms of inductive learning. Here, one
tries to learn relations between the symptoms and the faults (Murray, Hughes, & Kreutz-Delgado,
2006). One disadvantage of most works in this approach is that they learn only a single fault rather
than multiple faults (Balakrishnan & Honavar, 1998). In addition, inductive learning methods do
not guarantee sound diagnoses nor completeness. We, on the other hand, propose a method which
addresses multiple faults and guarantees sound and complete minimal cardinality diagnoses.
Feldman et al. (2010a) propose a stochastic diagnosis algorithm, called SAFARI. Although this
method is not guaranteed to return diagnoses of minimal cardinality, it presents solutions which are
close to minimal cardinality in very low runtime. In Section 7, we demonstrate that our approach
outperforms SAFARI in terms of runtime, and also guarantees that minimal cardinality diagnoses
are returned.
Compilation-based methods have also been proposed in the MBD context. Torasso and Torta
(2006) proposed to compile the system description to a Binary Decision Diagrams (BDDs). Darwiche (2001) proposed to compile the system description into Decomposable Negation Normal
Form (DNNF). In both cases, the compiled model allowed finding minimal cardinality diagnosis
in time that is polynomial in the size of the compiled model. However, in these works, the size of
the compiled model (BDD or DNNF) may grow exponentially and is shown to become a bottleneck (Siddiqi & Huang, 2007).
Siddiqi and Huang (2007) suggest to optimize MBD by identifying components that dominate
others. We adopt this idea and apply it in our SAT-based approach. Another compilation-based
diagnosis algorithm is the HA* algorithm (Feldman & van Gemund, 2006). HA* is designed to
exploit a given hierarchy of the diagnosed system. This is done by converting a given system
hierarchy to a DNF hierarchy. Each element in this DNF hierarchy is then solved by a simple
best-first search using as a heuristic function given a prior probability on the health of the system
components. In Section 7, we demonstrate that our approach substantially outperforms HA*.
380

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

= {X1 , X2 , A1 , A2 , O1 }
OBS = {A, B, C, D, E}
COMPS

Figure 1: An MBD problem: A (faulty) full adder.
Another previously proposed approach imposes a tree structure over a given system description.
A system in a tree structure can be diagnosed by joining the diagnoses of its constituent subsystems.
El Fattah and Dechter (1995) obtained a tree structure by converting the diagnosed system into a
chordal graph and then decomposed it to a tree of maximal cliques. The TREE* algorithm is another
such tree-decomposition algorithm, initially proposed only for tree-structured systems (Stumptner
& Wotawa, 2001). TREE* was later generalized to perform on any system by embedding a hyper
tree over a specific representation of the diagnosed system (Stumptner & Wotawa, 2003). Follow up
work further generalized TREE* to support various forms of diagnosis optimization tasks, such as
finding minimal cardinality diagnoses, or finding subset minimal diagnoses, or finding most probable diagnoses (Sachenbacher & Williams, 2004). Note that the complexity of TREE* is exponential
in the width of the hyper-tree embedded in the system description as defined in these works.

3. Model-Based Diagnosis: Preliminaries
This section introduces the background on Model Based Diagnosis. In addition to the basic definitions, we review several other concepts from the literature that we build on in this paper.
Model Based Diagnosis problems arise when the normal behavior of a system is violated due
to faulty components as indicated by certain observations. We focus on weak fault models, which
ignore the mode of abnormal behavior of components. An MBD problem is specified as a triplet
hSD, COMPS , OBS i where: SD is a system description, COMPS is a set of components, and OBS is an
observation. The system description takes into account that some components might be abnormal
(faulty). This is specified by an unary predicate h() on components such that h(c) is true when
component c is healthy and false when c is faulty. Denoting the correct behavior of c as a propositional formula, c , SD is given formally as
^
SD =
h(c)  c
cCOMPS

Namely, each component which is not faulty follows its correct behavior. A diagnosis problem
arises when, under the assumption that none of the components are faulty, there is an inconsistency
between the system description and the observations (de Kleer & Williams, 1987; Reiter, 1987).
Definition 1 [Diagnosis Problem]. Given an MBD problem, hSD, COMPS , OBS i, a diagnosis problem
arises when
^
SD 
h(c)  OBS ` 
cCOMPS

381

fiM ETODI , S TERN , K ALECH & C ODISH

For example, a diagnosis problem arises for the MBD of Figure 1 as normal behavior would give
output E = 1. Once there is an inconsistency, a diagnosis algorithm tries to find a subset   COMPS
which, if assumed faulty, explains the observation.
Definition 2 [Diagnosis] Given an MBD problem, hSD, COMPS , OBS i, the set of components  
COMPS is a diagnosis if
^
^
h(c)  OBS 0 
SD 
h(c) 
c

c
/

We say that  is a minimal diagnosis if no proper subset 0   is a diagnosis, and that  is a
minimal cardinality diagnosis if no other diagnosis 0  COMPS exists such that |0 | < ||.
For the MBD of Figure 1, 1 ={X1 , X2 }, 2 ={O1 }, 3 ={A2 } are minimal diagnoses, and 2 ,
3 are minimal cardinality diagnoses, as there is no smaller diagnosis.
An important concept that we make use of in this paper is that of gate domination, used
for automatic test pattern generation (ATPG) (Kirkland & Mercer, 1987; Fujiwara, Member, Shimono, & Member, 1983) and in some modern SAT solvers (Marques-Silva, Lynce, & Malik, 2009),
sometimes under the name unique sensitization. Siddiqi and Huang (2007) applied gate domination in model-based diagnosis, introducing the notion of a cone. The following wording is
taken from Siddiqi and Huangs paper in a setting where the system is a Boolean circuit and the
components are its gates.
Definition 3 (Dominator and Cone) A gate X in the fan-in region of gate G is dominated by G and
conversely G is a dominator of X if any path from X to an output of the circuit contains G. The cone
corresponding to a gate G is the set of gates dominated by G. A maximal cone is one that is either
contained in no other cone or contained in exactly one other cone which is the entire circuit.
For example, in the circuit depicted as Figure 1, the components {A1 , A2 , O1 } form a cone, since
any path from A1 or from A2 to a system output contains O1 . Here O1 is the dominator and A1 and A2
are the dominated gates.
Although Definition 3 is stated in terms of Boolean circuits and logical gates, the notions of
dominators and cones can be generalized for many systems, where components correspond to gates,
and a component C1 dominates a component C2 if all of the paths passing through C2 also pass
through C1 . For example, in the system illustrated in Figure 3 components C1 and C2 form a cone,
where C2 dominates C1 .
The importance of cones to MBD algorithms is rooted in two observations presented by Siddiqi
and Huang. Firstly, cones are single-output sub-systems and as such, a minimal cardinality diagnosis will always, independent of the observation, indicate at most one unhealthy component per cone.
Secondly, if C is a cone in SD, then without loss of generality, we may assume that all dominated
components in C are healthy. This is correct because if X is unhealthy in some minimal cardinality
diagnosis and dominated by G, then G must be healthy. So, there exists another minimal cardinality
diagnosis where X is healthy and G is not. For example, in the circuit depicted in Figure 1, 3 is
a minimal cardinality diagnosis that signifies dominated A2 as unhealthy, and there exists another
minimal cardinality diagnosis, 2 , in which A2 is healthy but O1 , which dominates A2 , is unhealthy.
Based on these observations we can restrict the search for minimal cardinality diagnoses, to
so-called top-level minimal cardinality diagnoses. The notion of top-level diagnoses was introduced by Siddiqi and Huang.
382

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Definition 4 (top-level diagnosis (TLD)) We say that a minimal cardinality diagnosis is top-level
if it does not contain any dominated components.
To formally justify the focus on top-level diagnoses we make explicit the following Propositions 1 and 2, which are left implicit in previous work.
Proposition 1 Let 0 be a minimal cardinality diagnosis for a given MBD problem. Then there is
a top-level diagnosis , of the same cardinality.
Proof: Straightforward. To obtain , replace each dominated component from 0 by its corresponding dominator.

We further note that the set of all minimal cardinality diagnoses can be obtained by expanding the set of all top-level minimal cardinality diagnoses in the following sense: Given a minimal
cardinality top-level diagnosis,  = {c1 , . . . , c` } consisting of ` dominators from corresponding
cones {C1 . . . , C` }, denote
fi
n
o
fi
i = c0i  Ci fi  \ {ci }  {c0i } is a diagnosis
(1)
We say that  expands to the set of minimal cardinality diagnoses defined in terms of a crossproduct by: () = 1      ` . For example, consider the system from Figure 1 with the
observation OBS = {A, B, C, D, E}. The cones in the system are C1 = {X1 }, C2 = {X2 }, and C3 =
{A1 , A2 , O1 }. The corresponding MBD problem has two top-level minimal cardinality diagnoses,
1 = {X1 , O1 } and 2 = {X2 , O1 } and we have (1 ) = {X1 }  {O1 } = {{X1 , O1 }} and (2 ) =
{X2 }  {A1 , O1 } = {{X2 , A1 }, {X2 , O1 }}.
Proposition 2 0 is a minimal cardinality diagnosis if and only if there is a top-level minimal
cardinality diagnosis  that expands to include 0 .
Proof: The proof is straightforward from the construction.

Finally, we comment that the sets i which specify the expansion of a top-level diagnosis 
in Equation (1) are easy to compute: for each component c0i  Ci checking if  \ {ci }  {c0i } is
a diagnosis means propagating the observed inputs through the system, flipping the outputs when
propagating through a component in  \ {ci }  {c0i } and checking if there is no conflict to the
observed outputs. This observation is not explicit in previous work and it is essential to justify the
focus on top-level diagnoses. Proposition 2 is important as it applies for any diagnosis algorithm.
As such, diagnosis algorithms in general can focus, and be compared on finding TLDs, instead of
finding all minimal cardinality diagnoses.

4. The Standard Approach to SAT-Based MBD
The standard encoding of an MBD problem hSD, COMPS , OBS i to Boolean Satisfiability (as introduced in Smith et al., 2005) associates each component c  COMPS with a propositional formula,
c , denoting its correct behavior, and with a Boolean variable, Hc , signifying if c is healthy.
Viewing the observation as a propositional statement, an encoding is obtained by specifying
^
 = OBS 
Hc  c
(2)
cCOMPS

383

fiM ETODI , S TERN , K ALECH & C ODISH

In a satisfying assignment for , the health variables assigned the value false determine a (not
necessarily minimal) diagnosis .
For example, consider the MBD problem of Figure 1, and let comp(A, B, C) with
comp  {and, or, xor} denote the propositional formula describing the behavior of the component which is an and00 , or00 or xor00 gate with inputs A, B and output C. So, Equation (2) takes
the form:


A  B  C  D  E  HX1  xor(A, B, Z1 ) 


(3)
 =  HA1  and(A, B, Z2 )
 HX2  xor(Z1 , C, D)  
HA2  and(Z1 , C, Z3 )  HO1  or(Z2 , Z3 , E)
This formula is satisfied by the assignment of variables {A, C, HA1 , HA2 , HO1 } to true and of variables
{B, D, E, Z1 , Z2 , Z3 , HX1 , HX2 } to false. This assignment indicates that  = {X1 , X2 } is a diagnosis.
To obtain a minimal cardinality diagnosis we seek a satisfying assignment with a minimal number of health variables taking value false. For example the assignment of variables
{A, C, Z1 , Z3 , HX1 , HX2 , HA1 , HA2 } to true and of variables {B, D, E, Z2 , HO1 } to false which also satisfies Equation (3) and indicates only one faulty component. This can be achieved using a MAX-SAT
solver (Feldman et al., 2010), or using a SAT solver as done in the implementation underlying this
paper, where a cardinality constraint (encoded to CNF) is introduced to constrain the number of
faulty components as detailed in the next section.
No matter how the cardinality constraint is encoded to CNF, for a setting with |COMPS | = n and
a constant k, The formula
fi
n
o
fi
k =   sum leq( Hc fi c  COMPS , k)
(4)
is satisfied only if at most k of the n health variables take the value false. More specifically, we seek
a minimal value of k such that (the CNF corresponding to) k is satisfiable. This involves iterating
over calls to the SAT solver with formulae k for decreasing values of k until k is satisfiable but
k1 is not. This approach takes advantage of the fact that SAT solvers are typically incremental:
adding clauses to a satisfiable instance allows to solve again while maintaining all of the derived
information about the search space from the previous call.

5. Our Approach to SAT-Based MBD
Our approach to encoding an MBD problem hSD, COMPS , OBS i to SAT proceeds as follows: First, we
adopt a finite domain constraint based representation to express the basic model. Second, we analyze
the structure and substructures of the SD to introduce additional (redundant) constraints that will
later boost the search for a minimal cardinality analysis. Third, we introduce constraints to model
the given observation OBS with an additional constraint that imposes a bound on the cardinality
of the diagnosis (the number of unhealthy components). This additional constraint reduces the
subsequent number of iterations in search of the minimal cardinality diagnosis. Each such iteration
involves a call to the underlying SAT solver and hence has worst-time exponential complexity. So,
reducing this number is important. Given all of these constraints, we apply a finite domain constraint
compiler (Metodi & Codish, 2012; Metodi, Codish, & Stuckey, 2013) to simplify and encode them
to a corresponding CNF. Finally we apply a SAT solver to seek a suitable satisfying assignment
and solve the problem. In the rest of this section we describe these phases in more detail. An
384

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Figure 2: Modeling component c by composition with xor
experimental evaluation illustrating the impact of the various constraints in the model is presented
in Section 7.
5.1 The Basic Model for MBD
We build on the standard approach, as in Equation (2). However, we observe that for model based
diagnosis in the weak fault model with a single observation and when searching for a minimal
diagnosis, the behavior of a faulty component can be assumed to produce an output opposite to that
of its normal behavior. This is because any diagnosis that assumes that a component c is faulty but
still produces its normal output can be replaced by a smaller diagnosis that does not contain c. Thus,
if  is a minimal diagnosis (i.e, no subset of  is a diagnosis), this means that all the components
in  are assumed to produce the opposite of their normal output. In this paper we focus on minimal
cardinality diagnoses, which are in particular also minimal subset, so we modify Equation (2) as
follows, replacing the implication by a bi-implication.
 = OBS 

^

Hc  c

(5)

cCOMPS

We model the behavior (Hc  c ) of a possibly faulty component c as if encapsulated together
with a xor gate as illustrated in Figure 2. Here, the output of the encapsulated component is the
xor of the usual output of c and its negated health variable Hc . One can observe that if Hc is
true then this composition is equivalent to the normal behavior of c, otherwise it is equivalent to
component c with a negated output.
Our decision to model the relation between a component c and its health variable Hc by introducing an additional xor gate (instead of just introducing CNF clauses to directly encode Hc  c )
has two motivations: (1) to improve CNF encodings we provide tools to reason about, and simplify
system components  so there is an advantage to a uniform representation where all of the logic is
expressed in the system model itself; and (2) the underlying SAT solver that we apply, CryptoMiniSat (Soos, 2010), offers direct support for xor clauses. Because of (1) our MBD problem is more
amenable to simplification, and because of (2) the underlying SAT solver can optimize the search
for a satisfying assignment. We comment that it is straightforward to apply our technique with other
SAT solvers, which do not support xor clauses, by adding their CNF encodings to the model. The
finite domain constraint compiler, BEE (Metodi & Codish, 2012), which we apply, is configurable
to work with both types of solvers.
As in Equation (3), we write comp(A, B, C) with comp  {and, or, xor} to represent a component which is an and00 , or00 or xor00 gate with inputs A, B and output C. We also write
compH (A, B, C) to represent the corresponding encapsulated component with a health variable H.
So,
compH (A, B, C) = comp(A, B, C0 )  xor(H, C0 , C)
385

fiM ETODI , S TERN , K ALECH & C ODISH

and we view
compH (A, B, C)

(Constraints 1)

as a constraint on the Boolean variables A, B, C and H. Given this notation, the system depicted as
Figure 1 is modeled by the following constraints:
xorHX1 (A, B, Z1 )  andHA1 (A, B, Z2 )  xorHX2 (Z1 , C, D) 
andHA2 (Z1 , C, Z3 )  orHO1 (Z2 , Z3 , E)
Finally, we add to the constraints representing the system components an additional cardinality
constraint:
fi
o
n
fi
sum leq( Hc fi c  COMPS , k)
(Constraint 2)
to specify for an integer constant k that the number of faulty components must be at most k.
For example, for the system depicted as Figure 1 and a constant k, we introduce the constraint
sum leq({HX1 , HX2 , HA1 , HA2 , HO1 }, k). Later we will require to satisfy the constraints of the
model and also to minimize the value of k.
To summarize this presentation of the basic model, we show the complete constraint model
for the minimal cardinality diagnosis of the MBD problem of Figure 1. For an integer value k, a
solution of these constraints is a diagnosis of cardinality  k:
xorHX1 (A, B, Z1 )  andHA1 (A, B, Z2 )  xorHX2 (Z1 , C, D) 
andHA2 (Z1 , C, Z3 )  orHO1 (Z2 , Z3 , E) 
sum leq({HX1 , HX2 , HA1 , HA2 , HO1 }, k) 
A=1  B=0  C=1  D=0  E=0
This type of constraint model can be solved by encoding it to a CNF formula and then applying
a SAT solver. By repeatedly seeking a solution for decreasing values of k we can find a minimal
cardinality diagnosis. However, we do not apply this basic modeling. Instead we further refine it as
described in the rest of this section.
5.2 Encoding Cardinality Constraints
The encoding of cardinality constraints to CNF is the topic of a large body of research papers. Many
of these, such as that described by Een and Sorensson (2006), are based on the use of Batchers oddeven sorting network (Batcher, 1968). A sorting network is a Boolean circuit with n inputs and n
outputs. Given Boolean values on its inputs, the output consists of the same values but sorted: say,
zeroes before ones. In our context we apply such a sorting network where the n inputs are the health
variables of the n components in the given system, and the n outputs are the sorted values. Now, to
encode that at most k health variables take the value false we assert that the (k + 1)th output of the
sorting network is a one. Because its outputs are sorted this implies that the last n  k outputs are
also ones thus imposing that at most all of the k remaining outputs are zero. Looking backwards
through the sorting network this implies that at most k of its inputs take the value false.
Sorting networks, like other Boolean circuits are straightforward to encode to a CNF formula.
With Batchers odd-even construction this results in a CNF with O(n log2 (n)) clauses. Further
improvements enable an encoding with O(n log2 (k)) clauses to constrain the sum of the n Boolean
inputs to be less than k (Asn, Nieuwenhuis, Oliveras, & Rodrguez-Carbonell, 2009, 2011; Codish
386

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

& Zazon-Ivry, 2010). In this paper we encode cardinality constraints to CNF using BEE (Metodi &
Codish, 2012; Metodi et al., 2013) which takes such an improved approach.
5.3 From Cones to Sections
Reasoning about relations between the components in a system description SD enables to infer additional constraints on the number of unhealthy components in certain subsystems of SD. These
constraints when compiled into the CNF, help boost the search, by the SAT solver, for a minimal
cardinality diagnosis. Proposition 2 enables a diagnosis algorithm to focus on top-level diagnoses
based on a partitioning of the system into cones: each cone contains at most one unhealthy component, and without loss of generality, it can be assumed to be the dominator of the cone.
To restrict the SAT-based search to top-level minimal cardinality diagnoses we simply add the
following constraints where D denotes the set of dominated components.
V

(Constraint 3)

cD Hc

Introducing constraints to indicate healthy components reduces the number of (unassigned) health
variables and hence boosts the search for minimal cardinality diagnosis. In Section 7 we show that
reasoning about cones to restrict the search to top-level diagnoses improves considerably the search
for minimal cardinality diagnosis.
Motivated by the utility of partitioning a system into cones, we seek a more general partitioning,
which enables to apply similar cardinality constraints to larger subsystems of components. To this
end we introduce the notion of a section. We denote by sysout(c) the set of system outputs which
occur at the end of a path from a component c. As an example, in the system depicted in Figure 3
sysout(C1 ) = {O2 , O3 } and sysout(C5 ) = {O1 , O2 }.
Definition 5 (Section) Given a system description SD with components COMPS we define a disjoint
partitioning COMPS = S1  S2      Sn such that for every c1 , c2  COMPS , c1 and c2 are in the
same section Si if and only if sysout(c1 ) = sysout(c2 ).

C5
C1
C3

C2
C4

S1

S2

C6

S3

C7

C8

C9

C10

O1
S4

S5

O2

O3

Figure 3: Partitioning a system into cones and sections.
Figure 3 shows a partitioning of a system into maximal cones and sections. The cones are depicted with dotted lines, and the sections with dashed. For example, components {C1 , C2 } form a
cone, and section S1 consists of three cones. We observe that partitioning a system into sections can
be done in polynomial time as demonstrated by Algorithm 1 presented below. Given a partitioning
387

fiM ETODI , S TERN , K ALECH & C ODISH

{S1 , . . . , Sn } to sections, we introduce to the constraint model the following constraints which further improve the encoding and hence the subsequent search for minimal cardinality diagnosis. For
each section Si , the constraint
fi
o
n
fi
sum leq( Hc fi c  Si , bi )
(Constraints 4)
expresses that the sum of the negated health variables in Si is bounded from above by a constant bi
that is the smaller of the following two bounds on the number of unhealthy components in section
Si : (a) The number of outputs from Si ; and (b) The value of |sysout(c)| for some component
c  Si . Note that by Definition 5, this value is the same for any c  Si . We justify this statement
below in Proposition 3.
To illustrate the utility of sections, consider again the system given as Figure 3 and its partition
into 5 sections. Observe that the section labeled S1 has 3 outputs, but each component c  S1
has only 2 corresponding system outputs (|sysout(c)| = 2). So, b1 = min{3, 2} and hence 2
is an upper bound on the number of unhealthy components in S1 . This is also an improvement
over the reasoning with cones where the bound on the number of unhealthy components in S1 is 3
(since there are three cones). Similarly, b2 = min{1, 2}, b3 = min{1, 1}, b4 = min{1, 1} and
b5 = min{1, 1}.
Reasoning about constraints on the number of faulty components per section facilitates the
MBD encoding in another way. For Constraints 4 we have already encoded the number of faulty
components per section. These numbers are partial sums in the context of Constraint 2 which
specifies the total number of faulty components in the system and can be reused in the encoding.
The following justifies Constraints 4 .
Proposition 3 Let hSD, COMPS , OBS i be an MBD problem, S  SD be a section, c  S be a component and  be a minimal cardinality diagnosis. Then, both (a) the number of outputs from S, and
(b) the value |sysout(c)| are bounds on the number of unhealthy components (from ) in S.
Proof: The statement regarding the number of outputs from S follows directly from an assertion
by de Kleer (2008) that the number of outputs from any (sub-) system is a bound on the number of
its unhealthy components. So, it remains to prove the statement regarding |sysout(c)|.
Assume the premise of the proposition, denote || = k and |S  | = t (so t  k). Assume
for contradiction that t > |sysout(c)|. We construct a diagnosis 0 with less than k unhealthy
components. First note the obvious: that given  we can propagate the observed system inputs
to the system outputs where in each step we choose a component with known inputs and produce
its normal output if the component is healthy, or its opposite to normal output otherwise. Because
 is a diagnosis this process will result in no contradictions between propagated outputs and the
observed outputs.
Now, take 0 =  \ S. This is not (yet) a diagnosis. With 0 , propagate the observed system
inputs in the same way as before with . Now, because 0 is not a diagnosis there will be some
flipped system outputs (those which contradict the observed outputs). Each such flipped output
o must be due to one of the unhealthy components in S that was marked healthy in 0 and so we
have o  sysout(c). Now consider the component g which outputs o. If g  0 , then remove it;
and if g 6 0 , then add it. So, now 0 is a diagnosis and k 0 = |0 |  k  t + |sysout(c)| < k. 
Algorithm 1 describes how to partition a system into sections. Denoting the components and
outputs of the system as COMPS = {c1 , . . . , cn } and OUTS = {o1 , . . . , om }, an n  m Boolean
388

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

matrix b is computed so that bij = true if oj  sysout(ci ) and false otherwise. Figure 4 shows an
example of this matrix b for the system in Figure 3. So, by Definition 5, a pair of components ci , cj
are in the same section if and only if row i and row j in matrix b are identical. For instance, section
S5 includes the components C9 and C10 since their system output O3 is identical. The computational
complexity of this partitioning process is the complexity of running a graph search algorithm for
every system output and is in the worst case O(n2  m). The algorithm returns a mapping from
components to bit vectors which can be seen as section identifiers. So, the algorithm returns a
mapping of components to sections.
Algorithm 1 partitioning a system into sections
input: A system (view it as a graph)
output: A partitioning of the system into sections
= {c1 , . . . , cn }
the system components
OUTS
= {o1 , . . . , om } the system outputs
b
= (bij )
an n  m Boolean matrix
for all (oj  OUTS ) do
apply DFS on the reverse edges of the system, with source = oj
for all (ci  COMPS ) do
bij
fi oj )
	
 = (ci is reachable from
return ci 7 hbi1 , . . . , bim i fi 1  i  n

1: Denote:

2:
3:
4:
5:
6:

COMPS

Example 1 (partition into sections) Consider
the (abstract) system depicted as Figure 3 where COMPS = {c1 , . . . , c10 } and
OUTS = {o1 , . . . , o3 }. The Boolean matrix evaluated by application of Algorithm 1 is illustrated
in Figure 4.

Figure 4: Partitioning the system
from Figure 3 into sections
There is another benefit of partitioning into sections: the identification of cones may be performed per section which is more efficient. This works because, if component X is dominated by component G then sysout(X ) = sysout(G) implying that the components of a cone
are always in the same section. For example, in Figure 3 component C1 is dominated by C2 and
sysout(C1 ) = sysout(C2 ) = {O1 , O2 }.
The recursively defined Algorithm 2 shows how to compute cones given a partition into sections.
It computes the set of dominators for a component c in a section S of the system. We denote by
succ(c) the set of components that c feeds into directly. If c  S feeds into a component that is
not in S then it is only dominated by itself. Otherwise, c is dominated by c0  S only if c0 is
dominated by all elements of succ(c). For instance, given section S1 and component C1 in Figure 3
succ(C1 ) = {C2 }. In the next recursive call succ(C2 ) does not include any component of S1
389

fiM ETODI , S TERN , K ALECH & C ODISH

(condition in line 2) and thus C2 is returned (line 5). The union of both calls (C1 , C2 ) is returned as
a cone (line 3).
It is straightforward to implement Algorithm 2 efficiently using a memoization table to avoid
recomputing dominators for components already encountered. Since a system is a directed acyclic
graph, the recursion in Algorithm 2 will halt when a leaf node is reached. Thus the complexity of
calculating the dominators of every component c in a section S is O(|S|2 ). Given the sets of dominators per component, it is straightforward to specify the set of maximal cones. A component c is a
dominator of a maximal cone, if it is only dominated by itself, and the maximal cone corresponding
to such a c is the set of components which have c as dominator.
To find all cones in a system, Algorithm 2 is applied once per component per section, and the
cost depends on the size of the largest section. In contrast, without the partition into sections, the
same algorithm is applied, but considering all of the components in the system instead of all the
components in a section. Practice shows that the partition into sections benefits the computation of
cones.
Algorithm 2 dominators (component c, section S, system C)
input: component c in section S of system C
output: The set of dominators of c
fi

	
1: Denote: succ(c) = c0  C fi the output of c is an input to c0
2: if (succ(c)  S) then \
3:
return {c} 
dominators(c0 , S, C)
c0 succ(c)

4: else
5:
return {c}

5.4 Modeling the Observation and Further Boosting the Search
Let OBS + and OBS  denote the sets of variables assigned true and false in OBS , respectively. Then,
to model the observation we add the obvious constraints.
V
V
(Constraint 5)
xOBS  x
xOBS + x 
To improve the search for a minimal cardinality diagnosis one can introduce an upper bound
on the minimal cardinality: the number of outputs in a system is an upper bound on the minimal
cardinality (de Kleer, 2008). Such a bound, as well as the section-specific constraint given above
(Constraints 4 ) ignores the observed inputs and outputs. Siddiqi and Huang (2011) propose to
obtain a tighter upper bound on the minimal cardinality for a given observation by propagating
the input values through the system, and taking as an upper bound the number of contradictions
between the observed and the propagated outputs. For example, considering the MBD problem
from Figure 1, k = 2 is an upper bound on the size of a minimal cardinality diagnosis because the
system has 2 outputs. Siddiqi and Huangs proposal states that also 1 is an upper bound because
when propagating the inputs through the system there is only one contradiction to the observed
outputs.
While Siddiqi and Huangs (2011) proposal is intuitively appealing, it is correct only in case
that no observed output is also input to another component, and in fact their results are restricted
to systems where this is the case. This does not work for the example in Figure 5. Propagating the
390

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Figure 5: Minimal cardinality diagnosis is of size 2, but propagating observed inputs leads to 1
contradiction to the observed outputs.
observed inputs through the system assigns 0 to both outputs indicating a single contradiction with
the observation (on O1 ). However, the smallest diagnosis for this example has cardinality 2. This
example is not contrived: 83 of the 350 observations for system 74181 of the 74XXX benchmark,
exhibit a minimal cardinality diagnosis larger than the (erroneous) bound obtained when counting
conflicts between propagated and observed outputs.
Algorithm 3 is about computing an upper bound on the number of faulty components by propagating observed inputs and counting conflicts. The algorithm computes a diagnosis , and || is
thus an upper bound on the minimal cardinality of a diagnosis. The basic idea is to propagate inputs
as long as they do not contradict observed, or other already computed, outputs. The components
in the system are processed one at a time. At line 3 we select some component c whose inputs
are already determined (initially only the system inputs are determined). For this c we consider its
already determined output, oobs , and denote oobs =  if its output is not yet determined. We also
consider its propagated output oprop which is obtained by propagating the inputs through c assuming that c is healthy. Now there are three cases (lines 610): if c has no already determined output
then we fix its output to oprop and mark c as healthy. If c has an already determined output and it
is consistent with oprop then we also mark c as healthy. Otherwise we mark c as not healthy, but do
not propagate its output (which is already determined).
Algorithm 3 Find a diagnosis  (and upper bound || on min. card.)
input: A system with components, COMPS , and observation, OBS
output: A diagnosis 
1: C  COMPS ,  = 
2: while (C 6= ) do
3:
select c  C such that the inputs of c are determined
4:
oobs  the value on the output of c (N/A if it is undefined)
5:
oprop  the value if propagating the inputs of c (assume c is healthy)
6:
if (oobs = N/A then
7:
set output of c to oprop and mark c as healthy
8:
else if (oobs = oprop ) then
9:
mark c as healthy
10:
else
11:
mark c as faulty and  =   {c}
12:
C  C \ {c}
13: Return 

When Algorithm 3 terminates we have marked all components as healthy or faulty and have
in fact determined a correct diagnosis. As such applying Algorithm 3 provides an upper bound
on a minimal cardinality diagnosis  the number of components marked as faulty in the returned
diagnosis. Note that Algorithm 3 is correct also when given probes (observed values on the outputs
391

fiM ETODI , S TERN , K ALECH & C ODISH

from internal components). Assuming that the components are maintained in a data-structure where
components are sorted (topologic) according to their depth, Algorithm 3 is performed as a single
linear traversal of this data-structure with complexity O(|COMPS |).
As an example application of Algorithm 3, consider the circuit in Figure 5. Propagating the
inputs of gate A1 gives the output 0 in contradiction to the observation on O1 . Hence, we mark A1 as
unhealthy and propagate the observation O1 = 1 as an input to A2 together with I3 = 1. This results
in an additional contradiction to the observation O2 = 0 and so we mark A2 as unhealthy too, and
report  = {A1 , A2 } hence the value 2 as an upper bound for the minimal cardinality.
Let kUB be the bound found by application of Algorithm 3. We refine Constraint 2 and introduce
instead:
fi
n
o
fi
sum leq( Hc fi c  COMPS , kUB )
(Constraint 20 )
To appreciate the impact of Algorithm 3 we note that, for the benchmark considered in this
paper, Algorithm 3 determines an upper bound equal to the actual minimal cardinality for 81% of
the 28,527 observations considered. Of course, even when given a precise upper bound, an MBD
algorithm still needs to validate its minimality. In our SAT-based approach this requires one single
iteration with the underlying SAT solver. Typically, this is the hardest iteration as it involves a call
which is unsatisfiable and is of the largest cardinality for which the instance is unsatisfiable.
5.5 Compiling Constraints to CNF
Metodi and Codish (2012) introduced a compiler called BEE that encodes finite domain constraints
to CNF. Besides facilitating the encoding process, this compiler also applies partial evaluation and
other optimizations to simplify the constraints before encoding them to CNF. In particular, it applies
equi-propagation (Metodi, Codish, Lagoon, & Stuckey, 2011) which is the process of identifying
equalities between literals (and constants) implied by other such equations and a given constraint.
If X=L is implied by a constraint (where X is a variable and L is a literal or a Boolean constant), then
all occurrences of X can be replaced by L, reducing the number of variables in the subsequent CNF
encoding. We illustrate constraint simplification for the diagnosis of the circuit in Figure 1. Consider
the following constraints (we have omitted some of the constraints as they do not contribute to the
example):
(1)
(2)
(3)
(4)
(5)

xorHX1 (A, B, Z1 )  andHA1 (A, B, Z2 )  xorHX2 (Z1 , C, D) 
andHA2 (Z1 , C, Z3 )  orHO1 (Z2 , Z3 , E) 
sum leq({HX1 , HX2 , HA1 , HA2 , HO1 }, k) 
A=1  B=0  C=1  D=0  E=0
HA1 = 1  HA2 = 1

The constraints on lines (1)  (3) comprise the basic constraint model described in Section 5.1; the
constraints on line (4) model the observation; and the constraints in line (5) express that without
loss of generality the dominated components {A1 , A2 } from the cone {A1 , A2 , O1 } are healthy. We
observe the following equi-propagation steps:
1. (A = 1)  (B = 0)  xorHX1 (A, B, Z1 ) |= (Z1 = HX1 )
2. (A = 1)  (B = 0)  (HA1 = 1)  andHA1 (A, B, Z2 ) |= (Z2 = 0)
392

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

3. (C = 1)  (HA2 = 1)  andHA2 (Z1 , C, Z3 ) |= (Z1 = Z3 )
4. (C = 1)  (D = 0)  xorHX2 (Z1 , C, D) |= (Z1 = HX2 )
5. (E = 1)  (Z2 = 0)  orHO1 (Z2 , Z3 , E) |= (Z3 = HO1 )
From these (and the other given) equalities between literals we obtain a substitution:
)
(
A 7 1, B 7 0, C 7 1, D 7 0, E 7 0, Z1 7 HX1 , Z2 7 0,
=
Z3 7 HX1 , HX2 7 HX1 , HA1 7 1, HA2 7 1, HO1 7 HX1
Applying  to specialize the constraint system we get:
(1)
(2)
(3)
(4)
(5)

xorHX1 (1, 0, HX1 )  and1 (1, 0, 0)
 xorHX1 (HX1 , 1, 0) 
and1 (HX1 , 1, HX1 )  or(HX1 ) (0, HX1 , 0) 
sum leq({HX1 , HX1 , 0, 0, HX1 }, k) 
1=1  0=0  1=1  0=0  0=0
1=1  1=1

Now, most of the constraints are tautologies and we remove them. All that remains is a single
constraint:
(3) sum leq({HX1 , HX1 , HX1 }, k)
which is satisfied for k = 1 when HX1 = 1, and as implied from  then we have
HA1 = 1, HA2 = 1, HX2 = 1, HO1 = 0. This example illustrates how equi-propagation and partial evaluation are applied to simplify constraints prior to their encoding to CNF.
We summarize with the following observations:
1. The constraint model for MBD is polynomial in the size of the system: each component
contributes a constraint and a fresh health variable, each cone contributes an assignment to
the health variables for its dominated components, each section contributes a cardinality constraint, and finally the observation contributes an assignment to the input and out variables of
the system.
2. Constraint simplification using BEE is polynomial in the size of the constraint model. This is
because: (a) each simplification step reduces the number of Boolean variables in the model by
at least one  so there are a linear number of steps, and (b) each step checks the applicability
of a fixed number of simplification patterns to each constraint.
3. The CNF encoding of the constraint model is polynomial in size, as each of the constraints
introduces a polynomial number of clauses to the CNF (all of the constraints supported by
BEE have this property).

6. Process and Implementation
In this section we summarize the different phases of the diagnosis process in our approach. In
Section 6.1 we focus on the case where we seek a single minimal cardinality diagnosis, and then in
Section 6.2, on the case when we seek all minimal cardinality diagnoses.
393

fiM ETODI , S TERN , K ALECH & C ODISH

6.1 Single Minimal Cardinality Diagnosis
The process for a single minimal cardinality diagnosis consists of four phases. Let  =
hSD, COMPS , OBS i be an MBD problem. In the first two phases we construct a constraint model.
First, focusing on SD, to introduce constraints which are independent of the observation, and then
per observation to introduce further constraints. In the third phase we encode the constraint model
to a CNF, k where k is an upper bound on the size of the minimal cardinality diagnosis. In the
fourth phase, solving k using a SAT solver results in a diagnosis with cardinality at most k. We
now detail these four phases.
Phase 1. Modeling the system (offline): The system SD is first preprocessed to partition it into
sections (Algorithm 1) and cones (Algorithm 2). Then, we introduce Constraints 1 to model SD in
terms of its components behavior and introduce Constraints 4 to bound the number of unhealthy
components per section. Finally, using information about cones, we add Constraint 3 which asserts
that, without loss of generality, all dominated components are healthy. All of the system preprocessing is performed offline, once per system.
Phase 2. Modeling the observation (online): Constraint 5 is added to model the observation
and Constraint 20 is added to bound the total number of unhealthy components by the upper
bound kUB obtained by application of Algorithm 3.
OBS ,

Phase 3. Encoding: The constraint system is then simplified online, for each observation and
encoded to a CNF k , applying the optimizing CNF compiler (Metodi et al., 2011). The parameter k
reflects the bound set in Constraint 20 to bound the number of unhealthy components in a diagnosis.
Initially, k is computed by Algorithm 3.
Phase 4. Solving: To compute a diagnosis, , we seek a satisfying assignment for the encoding, k ,
by applying the CryptoMiniSat solver (Soos, 2010).  is then the set of health variables assigned
false by this assignment. Denoting || = k 0 , we again seek a satisfying assignment, but this time
0
for the formula k 1 . If a satisfying assignment is found, it indicates a smaller diagnosis, 0 .
Otherwise,  is of minimal cardinality. This process is invoked repeatedly, each time finding a
0
smaller diagnosis, until for some k 0 the formula k 1 is not satisfiable. Then, the diagnosis found
in the previous iteration is of minimal cardinality.
To facilitate the search for a minimal cardinality diagnosis, we apply the SAT solver wrapper, SCryptoMiniSat (Metodi, 2012b). SCryptoMiniSat takes as input a CNF formula (k ) and
the Boolean variables representing the number k. It provides a satisfying assignment which minimizes k. SCryptoMiniSat takes advantage of the incrementality of the underlying SAT solver which
maintains learned clauses over consecutive calls which only add clauses.
Algorithm 4 illustrates the process of finding a single minimal cardinality diagnosis (identified
at line 17), and of returning the set of all minimal cardinality diagnoses (line 23).
6.2 All Minimal Cardinality Diagnoses
To find all minimal cardinality diagnoses we first apply the process described in Section 6.1 to find
a single minimal cardinality diagnosis. This provides us with the value k 0 indicating the number of
faulty components in a minimal cardinality diagnosis.
Then, to enumerate the set of all top-level minimal cardinality diagnoses (each of size k 0 ) we
apply an additional functionality of SCryptoMiniSat which allows to enumerate (possibly with a
394

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Algorithm 4 SATbD
input: A system SD with components COMPS and an observation OBS
output: , the set of minimal cardinality diagnoses
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:

// Phase 1: Offline pre-processing

Sections  partition SD into sections
Constraints  
for all (S  Sections) do
for all (c  S) do
Add Constraints 1 to Constraints
Dominators  dominators(c, S, SD)
if |Dominators| > 1 then
Add Constraint 3 for component c to Constraints

// Algorithm 1

// describes normal behavior of component c
// Algorithm 2
// sets dominated gates to healthy

// Phase 2: Modeling the observation

Add Constraint 5 to Constraints
  Find initial diagnosis
Add Constraint 20 to Constraints with kUB = ||

// add constraints representing OBS
// Algorithm 3

// Phase 3: Encoding

  BEE(Constraints)

// run the constraint compiler to obtain a CNF

// Phase 4: Solving

MC  SCryptoMiniSatMinimize(k,)

// find min. card. diagnosis (assignment that minimizes k = ||MC )

// Finding all diagnoses of minimal cardinality

    cnf(kUB = |M C |)
  , T LD  SCryptoMiniSatAllSolutions()
for all (  T LD ) do
Add to  all the diagnoses expanded from 
return 

395

// restrict Constraint 20 to use kUB = |M C |
// find all top-level diagnoses
// Proposition 2

fiM ETODI , S TERN , K ALECH & C ODISH

Name
74181
74182
74283
c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

|COMP|
65
19
36
160
202
383
546
880
1193
1669
2307
2416
3512

System Details
in
out
offline
14
8
0.02
9
5
0.01
9
5
0.01
36
7
0.03
41
32
0.08
60
26
0.06
41
32
0.24
33
25
0.37
233 140
0.29
50
22
0.71
178 123
1.50
32
32
1.48
207 108
1.73

Feldman
#obs.
350
250
202
301
835
1182
836
846
1162
756
2038
404
1557

DXC-09

1-10

11-20

21-30

100
100
100
100
93
44
87
93
66
98
47
100
49

0
0
0
0
7
44
13
7
34
2
45
0
46

0
0
0
0
0
12
0
0
0
0
8
0
5

#obs.
54
50
30
45
141
198
98
127
168
36
248
1
176

1-10

11-20

21-30

100
100
100
100
73
41
79
74
52
100
43
100
45

0
0
0
0
27
40
21
26
43
0
40
0
41

0
0
0
0
0
19
0
0
5
0
17
0
14

Sidd.
#obs.
700
400
800
800
800
800
40
40
40

Table 1: The Benchmark suite: systems 74XXX and ISCAS-85, and observations: Feldman, DXC-09
and Siddiqi.

specified time-out) all, or a specified number of, satisfying assignments for a given CNF. We apply
this option to enumerate all satisfying assignments for the formula, k described in Section 6.1 with
k = k0 .
Finally, based on Proposition 2 we expand the obtained top-level diagnoses to provide all minimal cardinality diagnoses. Note that the observation that a TLD can be expanded easily to all
minimal cardinality diagnoses applies for any diagnosis algorithm. As such, diagnosis algorithms
in general can focus, and be compared on finding TLDs, instead of finding all minimal cardinality
diagnoses.

7. Experimental Results
This section presents an experimental evaluation of our proposed SAT-based encoding for MBD.
In Section 7.1, we consider the search for a single minimal cardinality diagnosis and compare the
performance of SATbD to the algorithms: HA* (Feldman & van Gemund, 2006), CDA* (Williams
& Ragno, 2007) and SAFARI (Feldman et al., 2010a). In Section 7.2, we consider the search for
all minimal cardinality diagnoses and compare SATbD to the algorithms: HDIAG (Siddiqi & Huang,
2007) and DCAS (Siddiqi & Huang, 2011). Finally, in Section 7.3, we evaluate the impact of the
various components of our SAT-based encoding of MBD. All experiments were run on an Intel Core
2 Duo (E8400 3.00GHz CPU, 4GB memory) under Linux (Ubuntu lucid, kernel 2.6.32-24-generic)
unless stated otherwise. The entire set of our tools, range of benchmarks, as well as a more detailed
report of the results can be found online (Metodi, 2012a; Metodi, Stern, Kalech, & Codish, 2012b).
Table 1 provides basic details concerning the systems and three observation sets in our benchmark suite. The systems are 74XXX (Hansen, Yalcin, & Hayes, 1999), described in the first 3 rows,
and ISCAS-85 (Brglez et al., 1989), described in the following 10 rows. The left column in the
table specifies the system name. The next four columns (from the left) describe the systems: the
numbers of components, inputs and outputs in each of the systems, and also the preprocessing time
per system for the SAT-based approach. This includes all actions performed once per system as
described in Section 6.1: decomposing the system to sections and cones and computing the bounds
per section.
396

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

The rest of the columns are divided to three groups describing experiments with the three observation sets. The first two describe the observation set generated by Feldman et al. (2010a) and
the DXC-09 observation set used in the diagnosis competition (DXC) of 2009. These are applied in
our experimentation to evaluate the search for a single minimal cardinality diagnosis. The minimal
cardinality of the diagnoses in these observations is between 1 and 30. The columns in each of these
two groups indicate the number of observations and a distribution of the observations according to
the size of their minimal cardinality diagnoses. The observations in these sets are considered hard
and many of them, have high minimal cardinality diagnoses. The third group (the rightmost column
in the table) presents the observation set generated by Siddiqi and Huang (2011) where minimal
cardinality is bounded by 8 and the observations are distributed uniformly according to the size of
their minimal cardinality diagnoses. This set is used in the evaluation of the search for all minimal
cardinality diagnoses.
Table 1 illustrates a comprehensive experimental benchmark involving a total of 28,527 observations of varied minimal cardinality diagnosis size. Observe also that the (offline) preprocessing
time per system is negligible. For instance, reprocessing the largest system, c7552, takes less than
two seconds.
7.1 SATbD vs. Other MBD Algorithms: Single Minimal Cardinality Diagnosis
We now compare SATbD to the algorithms: HA* (Feldman & van Gemund, 2006), CDA* (Williams
& Ragno, 2007) and SAFARI (Feldman et al., 2010a) in their application to search for a single minimal cardinality diagnosis. HA* and CDA* are based on a complete algorithm to find all minimal
subset diagnoses  those that do not contain other diagnoses. They can be configured such that the
first minimal subset diagnosis is guaranteed to be also of minimal cardinality and it is this configuration that we apply for comparison with SATbD. SAFARI applies an algorithm based on stochastic
search which does not guarantee minimal cardinality and not even minimal subset diagnosis. Feldman et al. (2010a) report that even for single and double fault cardinalities, SAFARI does not always
find the minimal cardinality. So, at the expense of minimality, SAFARI is often faster, comparing to
HA* and CDA*.
Name

HA*
Succ.
Time
rate%
Sec.

74181
68.3
74182
100.0
74283
100.0
c432
78.1
c499
24.1
c880
11.9
c1355
11.4
c1908
6.4
c2670
12.3
c3540
3.7
c5315
2.7
c6288
13.6
c7552
4.2
80 sec timeout
c7552
7.3

CDA*
Succ.
Time
rate%
Sec.

Succ.
rate%

SAFARI
Min Diag.
card.%
ratio

3.15
0.00
0.04
3.63
5.45
3.76
3.90
1.75
4.83
4.30
11.94
7.87
1.06

46.3
100.0
100.0
38.2
10.1
6.3
0.0
0.0
0.0
0.0
0.0
0.0
0.0

4.51
0.01
1.45
5.15
1.22
6.66
-

100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
53.5
0.0

44.0
91.0
57.0
28.0
7.0
48.0
5.0
17.0
14.0
9.0
9.0
25.0
-

20.77

0.0

0.0

99.5

13.0

Time
Sec.

SATbD
Succ.
Time
rate%
Sec.

1.33
1.04
1.28
1.68
2.00
1.09
1.96
1.92
1.52
2.06
1.96
7.88
-

0.00
0.00
0.00
0.03
0.05
0.18
0.37
1.08
2.71
5.25
13.34
16.18
-

100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
99.3

0.02
0.01
0.02
0.03
0.04
0.05
0.07
0.14
0.15
0.27
0.42
0.56
1.07

1.68

43.50

100.0

1.49

Table 2: Single minimal cardinality diagnosis, Feldmans observations (30 sec. timeout).
397

fiM ETODI , S TERN , K ALECH & C ODISH

Algorithm
System
74181
74182
74283
c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

Min
0.00
0.00
0.00
0.00
0.02
0.01
0.04
0.44
0.05
0.22
0.19
0.21
0.47

HA*
Max
29.40
0.00
0.76
29.53
21.43
29.43
22.12
14.78
27.91
29.42
29.68
28.32
9.47

St. dev.
6.04
0.00
0.08
6.33
5.03
6.70
3.88
2.51
6.88
6.26
11.98
8.38
1.86

Min
0.00
0.00
0.00
0.04
0.88
0.24
-

CDA*
Max
St. dev.
29.01
7.30
0.08
0.02
28.14
2.79
26.26
7.00
1.55
0.21
29.87
8.18
-

Min
0.00
0.00
0.00
0.02
0.04
0.14
0.32
0.95
2.44
4.78
12.24
13.27
30.00

SAFARI
Max
St. dev.
0.01
0.00
0.00
0.00
0.00
0.00
0.03
0.00
0.06
0.00
0.21
0.01
0.43
0.02
1.19
0.04
3.03
0.09
6.20
0.16
14.68
0.36
30.96
4.78
30.22
0.01

Min
0.00
0.00
0.00
0.00
0.01
0.01
0.02
0.03
0.04
0.06
0.09
0.10
0.14

SATbD
Max
St. dev.
0.03
0.01
0.02
0.00
0.03
0.01
0.05
0.01
0.07
0.01
0.14
0.01
0.10
0.02
0.52
0.04
0.22
0.04
0.84
0.10
5.93
0.31
1.27
0.22
24.30
2.03

Table 3: Single minimal cardinality diagnosis, Feldmans observations, additional statistics.
Table 2 presents the evaluation focusing on Feldmans observations imposing a 30 second timeout (except for the bottom line). The columns indicate for each algorithm, the percentage of observations solved within the prescribed timeout (Succ. rate %) and the average search time (Time
Sec.) where the average is computed over the set of observations excluding timeouts. For SATbD,
the search time: (1) includes all actions performed once per observation as described in Section
6.1 (Modeling the observation (online)); (2) Excludes the cost of actions performed once per system as described in Table 1 of Section 6.1 (column offline); and (3) includes times for adding the
observation and the cardinality constraints, encoding to CNF and solving with SCryptoMiniSat.
The results in Table 2 show clearly that SATbD outperforms all of the other evaluated algorithms,
both in terms of success rate as well as in terms of average runtime. SATbD also outperforms
SAFARI which succeeds to compute a diagnosis for almost all of the systems. However, only a
small percentage of these are of minimal cardinality as indicated by the column Min card%
which shows the percentage (excluding timeouts) of observations where the diagnosis found by
SAFARI is actually of minimal cardinality. We also show, in the column titled Diag. ratio,
the ratio between the average cardinality of the diagnoses found by SAFARI and the average minimal
cardinality. So for example looking at the data for system 74181, 44% of the diagnoses found by
SAFARI are minimal, and the average diagnosis size found is 1.33 times larger than the average
size of the minimal cardinality diagnosis. We observe that SATbD computes and verifies minimal
cardinality diagnoses even for observations with a minimal cardinality of 30. To the best of our
knowledge, no algorithm before succeeded to compute minimal cardinality diagnosis for such hard
observations.
Table 3 details additional statistics for the running times presented in Table 2, showing the
minimum, maximum, and standard deviation of the runtime for the solved observations. As can
be seen, the standard deviation of SATbD is very small compared to the other algorithms. The
displayed statistics are only over cases solved within the 30 second timeout. Table entries with
- mark cases where the corresponding algorithms could not find a minimal cardinality diagnosis
(within the timeout) even for a single observation.
Observe in Table 2 that 99.3% of the 1,557 observations for system c7552 are solved by SATbD
within the 30 second timeout (only 11 observations are not solved). All of the observations are,
however, solved within 80 seconds each, as indicated by the last row in the table. One may observe
that while SATbD solves all observations given 80 seconds, the other algorithms are still not able to
398

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

solve all of them, with the exception of SAFARI. Given the extended 80 seconds timeout, SAFARI
is also able to solve almost all of the observations for this system, but returns minimal cardinality
diagnoses only in 13% of the cases, and in average, the size of the diagnosis found by SAFARI is
1.68 times larger than the actual minimal cardinality.
Name

HA*
Succ.
Time
rate%
Sec.

CDA*
Succ.
Time
rate%
Sec.

Succ.
rate%

SAFARI
Min
card.%

Time
Sec.

SATbD
Succ. Time
rate%
Sec.

74181
74182
74283
c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

94.4
100.0
100.0
75.6
12.8
10.1
9.2
7.1
11.3
11.1
1.2
100
2.3

57.4
100.0
100.0
40.0
5.7
4.5
0.0
0.0
0.0
0.0
0.0
0.0
0.0

100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
0.0

65
90
80
22
3
48
4
14
18
31
7
100
-

0.00
0.00
0.00
0.03
0.05
0.18
0.38
1.12
2.85
5.83
13.12
25.28
-

100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0

3.86
0.00
0.01
3.70
4.81
5.51
3.33
3.10
5.86
1.23
19.77
0.24
0.47

5.19
0.01
0.32
7.17
1.20
9.66
-

0.02
0.00
0.01
0.03
0.05
0.05
0.07
0.20
0.14
0.29
0.62
0.1
1.01

Table 4: Single minimal cardinality diagnosis, DXC-09 observations (30 sec. timeout).
Table 4 shows the evaluation for the DXC-09 benchmark and is in the same format as Table 2
(except that we omit the details regarding the size of the diagnoses found by SAFARI). The results
exhibit the same trend: our SAT-based method is substantially faster than all of the previous algorithms. Note that this benchmark even contains observations with minimal cardinality diagnoses of
31 (!), which were also solved by SATbD under the 30 seconds timeout. Table 5 provides additional
statistics for these runtimes in the same format as in Table 3. Here too, we see a small standard
deviation for SATbD compared to the other algorithms. Note that the data for the c6288 system is
not given, as there is only a single observation for this system in the DXC-09 observation set.
Figure 6 details the evaluation for a single minimal cardinality diagnosis with Feldmans observations for four systems (from smaller to larger). For each system we plot the average runtime
to find a single minimal cardinality diagnosis (including timeouts) as a function of the value of
the minimal cardinality. The black diamond labeled Timeout marks the time limit, after which
algorithms were halted.
Typically, the diagnosis problem becomes harder as the minimal cardinality increases. First
consider the three plots in Figures 6a, 6b and 6c. The two upper curves correspond to the systems
HA* and CDA* and they quickly converge to the 30 seconds timeout. The curves for SAFARI are
more or less constant but only a minority of the diagnoses are actually of minimal cardinality (7%
in c499, 48% in c880 and 9% in c5315). The performance of SAFARI is not affected by the
cardinality since it first finds an arbitrary diagnosis and then proceeds stochastically to minimize the
diagnosis using a pre-defined number of attempts. This process involves consistency checks which
are affected only by the size of the system and not by the cardinality of the diagnosis.
Now consider the plot in Figure 6d where we omit the curves for HA* and CDA* as they depict
a constant 80 second timeout. The performance of SAFARI is more or less constant (around the
average 43.5 seconds) but only 13% of the diagnoses found are actually of minimal cardinality. In
contrast, SATbD is considerably faster and scales to solve even the hardest observations.
399

fiM ETODI , S TERN , K ALECH & C ODISH

Algorithm
System
System
74181
74182
74283
c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c7552

Min
Min
0.00
0.00
0.00
0.00
0.01
0.01
2.74
0.85
0.05
0.31
9.86
0.47

HA*
Max
Max
27.26
0.00
0.02
23.06
11.34
29.60
6.52
15.34
26.04
3.44
28.39
0.47

St. dev.
St. dev.
6.70
0.00
0.01
5.98
4.99
8.34
1.20
4.63
8.06
1.49
9.34
0.00

CDA*
Max
St. dev.
Max
St. dev.
20.12
7.44
0.08
0.02
1.22
0.40
26.14
8.75
1.42
0.16
20.33
8.97
-

Min
Min
0.00
0.00
0.01
0.05
0.93
0.27
-

SAFARI
Max
St. dev.
Max
St. dev.
0.01
0.00
0.00
0.00
0.00
0.00
0.04
0.00
0.07
0.01
0.24
0.01
0.42
0.02
1.25
0.05
3.07
0.11
6.18
0.16
14.11
0.32
-

Min
Min
0.00
0.00
0.00
0.03
0.04
0.16
0.34
1.00
2.56
5.53
12.10
-

Min
Min
0.00
0.00
0.00
0.01
0.01
0.02
0.02
0.03
0.05
0.06
0.10
0.17

SATbD
Max
St. dev.
Max
St. dev.
0.03
0.01
0.02
0.00
0.03
0.01
0.04
0.01
0.07
0.01
0.07
0.01
0.09
0.02
1.36
0.16
0.21
0.03
0.84
0.20
10.06
0.90
11.54
1.54

100 Timeout

100

Time (sec.), log scale

Time (sec.), log scale

Table 5: Single minimal cardinality diagnosis, DXC-09 observations (30 sec. timeout), additional
statistics.

10
CDA*

HA*

Safari

SATbD

1
0.1

10
CDA*

HA*

Safari

SATbD

1
0.1

0.01

0.01
1

3

5
7
9
11
Minimal Cardinality

13

15

1

(a) System c499 (30 sec. timeout).
100

Time (sec.), log scale

10
CDA*

HA*

Safari

3

5

7

9 11 13 15 17 19 21 23 25
Minimal Cardinality

(b) System c880 (30 sec. timeout).

100 Timeout

Time (sec.), log scale

Timeout

SATbD

1

Timeout

10

Safari

SATbD

1

0.1

0.1

0.01

0.01
1

3

5

7

9 11 13 15 17 19 21 23 >24
Minimal Cardinality

1

(c) System c5315 (30 sec. timeout).

3

5

7

9 11 13 15 17 19 21 >22
Minimal Cardinality

(d) System c7552 (80 sec. timeout).

Figure 6: Single minimal cardinality diagnosis, Feldmans observations, average search time per
size of the minimal cardinality diagnosis.

The results of this section clearly indicate that our SAT based approach outperforms the other
three algorithms in the search for a single minimal cardinality diagnosis.
400

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Name
c432
c499
c880
c1355
c1908
c2670
c5315
c6288
c7552

IntelXeon X3220, 2.4GHz, 2Gb RAM
HDIAG
DCAS
Succ.
Time
Succ.
Time
rate%
Sec.
rate%
Sec.
100.0
0.21
100.0
0.31
100.0
0.12
100.0
0.20
99.0
0.07
99.0
0.12
99.5
0.16
99.5
0.15
90.5
368.13
76.5
82.25
90.0
176.17
100.0
3.15
0.0
97.5
52.34
0.0
27.5
305.10
0.0
87.5
260.93

Intel Core 2-Duo E8400, 3.00GHz, 4GB RAM
SATbD
Succ.
TLD
Time
TLD
ALL
rate%
Sec.
Sec.
count
count
100.0
0.07
0.09
7.9
72
100.0
0.08
0.10
2.4
345
100.0
0.08
0.11
10.3
963342
100.0
0.13
0.16
2.8
331927
100.0
0.25
0.30
19.9
1894733
100.0
0.23
0.29
6.7
8492
100.0
0.58
0.67
26.4
356949
50.0
104.58
105.14
7231.8
37499
100.0
1.01
1.12
64.9
68396

Table 6: Siddiqis observation set: search for all minimal cardinality diagnoses (1800 sec. timeout).
7.2 SATbD vs. Other MBD Algorithms: All Minimal Cardinality Diagnosis
We now compare SATbD to the algorithms HDIAG (Siddiqi & Huang, 2007) and DCAS (Siddiqi
& Huang, 2011) in their application to search for all minimal cardinality diagnosis. Both algorithms search for a complete set of the minimal cardinality diagnoses. We consider the observations
generated by Siddiqi and Huang (2011) where minimal cardinality is bounded by 8.
Table 6 presents the results of our evaluation. The results for the HDIAG and DCAS are quoted
from Siddiqi and Huangs work (2011) where experiments are reported for an IntelXeon X3220
2.4GHz, 2Gb RAM. We present results only for the systems for which Siddiqi and Huang reported
results. Although the machines differ (with an advantage for SATbD), the results show a clear
advantage for SATbD which is faster in orders of magnitude for the larger systems.
For each of the three algorithms the table reports on:
Succ. rate% indicating the percentage of the observations for which the algorithm finds all
minimal cardinality diagnoses within an 1800 second timeout; and
Time sec. indicating the average computation times to find all minimal cardinality diagnoses
(taking the average over the set of observations for which there is no time out).
For SATbD we report also
TLD sec. the average runtime to compute all top level diagnoses;
TLD count the number of top level diagnoses; and
ALL count the total number of minimal cardinality diagnoses found.
Table 6 illustrates that SATbD clearly outperforms HDIAG and DCAS. It succeeds to compute all
minimal cardinality diagnoses for all observations for all of the systems except for c6288 where
it succeeds on 50% of the 40 observations compared to 26.5% for DCAS. Note that because of
the higher success rate, the average runtimes for SATbD involve harder observations not solved by
DCAS.
Observe that most of the diagnosis time for SATbD is spent to find all top level diagnoses indicated in column TLD sec. The cost to compute all minimal cardinality diagnoses is indicated in
column Time sec and the difference between these two columns is negligible. This reflects the
401

fiM ETODI , S TERN , K ALECH & C ODISH

fact that the set of all minimal cardinality diagnoses is derived as a cross product representation of
the set of all minimal cardinality diagnoses. Observe also that the number of TLDs (column TLD
count) is small in comparison to the huge number of minimal cardinality diagnoses (column ALL
count). The focus on TLDs is essential as each additional solution invokes an additional call to
the SAT solver. Using the SAT solver to find the minimal cardinality diagnoses directly would be
hopeless due to their sheer number.
7.3 Impact of the Components of SATbD
We proceed to illustrate the impact of the various components of our SAT-based encoding of MBD.
SATbD is designed using a variety of techniques that distinguish it from the simple vanilla encoding of an MBD problem to a SAT problem described in Section 5.1. We present here an evaluation
of the impact of these techniques based on several experiments using the following five configurations of our SAT based system. These configurations are incremental: starting from the basic
model, each one adds another component, ending with the final model applied in SATbD.
1. Vanilla. This is the minimal basic SAT encoding for MBD described in Section 5.1. Here
we assume the naive upper bound on the minimal cardinality determined as the number of
outputs of the given system.
2. Improved Cardinality Bound. Here we assume the same vanilla setting but consider the
improved bound on the minimal cardinality of a diagnosis using Algorithm 3.
3. E.P. This setting is the same as the previous but applies the Equi-Propagation constraint compiler of Metodi and Codish (2011, 2012) to optimize the encoding as described in Section 5.5.
4. Cones. This setting is the same as the previous but also partitions the system into its cones
and adds constraints to restrict the search to find top-level diagnoses (TLDs), as described in
Section 3.
5. Sections. This setting is the same as the previous but also partitions the system into its
sections and introduces corresponding redundant cardinality constraints as described in Section 5.3.
Figure 7 illustrates the impact of each of the five settings on the search for a single minimal
cardinality diagnosis for 1182 observations from Feldmans observation set for system c880. On
the horizontal axis, we consider the observations according to the size of their minimal cardinality
diagnosis. On the vertical axis, we illustrate the average runtime in seconds. All runs apply a 300
second timeout. We choose system c880 to present these results as: (a) it is the only midsize system
for which the observation sets contain observations with minimal cardinality diagnosis larger than
20; and (b) it is the largest system which exhibits an interesting behavior for all five configurations
without too many timeouts which shadow the results. With larger systems, such as c3515 and
c7552 considered below, only the last two of the five configurations exhibit interesting curves.
The other three configurations timeout on most of the observations.
The upper curve in Figure 7 describes the Vanilla setting and one may observe that as the cardinality increases the curve converges to the 300 second timeout. The second curve down describes
the Improved Bound setting and illustrates the impact of Algorithm 3, especially for the observations with minimal cardinality diagnoses of size 1  10. Here, using the improved bound reduces
402

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Figure 7: Impact of the different settings on the search for a single minimal cardinality diagnosis
for system c880.

the number of iterations with the SAT solver and this is the source of the improvement. To explain
why we see no improvement when the minimal cardinality diagnosis involves a larger number of
faults, consider first that for large minimal cardinalities, the results are meaningless as both of the
upper curves converge on the timeout. As for the medium sized minimal cardinalities, consider
that with both techniques the overwhelming part of the runtime is spent on the last UNSAT iteration. Moreover, the number of iterations with the SAT solver with both techniques is more or
less the same. This is because system c880 has only 26 outputs which is the naive bound used
in the vanilla setting which then jumps down in each iteration to a smaller bound (but not using a
one-by-one decrement). Given this evaluation we might consider omitting the constraints for the
improved lower bound depending on the parameters of the instance. However, the cost of running
Algorithm 3 is negligible so we always impose the corresponding constraints.
The third curve down (E.P.) shows the additional impact when applying the Equi-Propagation
constraint compiler. This results in substantial speedups over the first two settings. For example,
finding a diagnosis of minimal cardinality 20 requires an average of 18.5 seconds with this setting
in comparison to 214.9 seconds without it. The two lower curves of the graph coincide, and it
is the fourth setting (cones) which makes the dramatic impact on performance for system c880.
The average runtime required to find the first minimal cardinality using this setting is under 0.1
seconds for all observations. This includes finding diagnoses with minimal cardinality of 26 (!) in
58 milliseconds, on average. The runtimes with this setting are so small that we cannot observe any
additional added value when applying the fifth setting (sections). To this end we consider in the
next experiment a comparison using two larger systems, namely c5315 and c7552.
Figure 8 illustrates the impact of the fifth setting which involves the partitioning of a system into
sections. The left graph illustrates the impact of sections when seeking a single minimal cardinality
diagnosis for the observations in system c5315 and the right graph illustrates the impact when
seeking all top-level minimal cardinality diagnoses (TLDs). The lower curve (in both graphs), summarizes the results using sections and the upper curve without. For example, for the observations
with minimal cardinality 24, with sections finding the first minimal cardinality diagnosis requires
403

fiM ETODI , S TERN , K ALECH & C ODISH

Figure 8: Impact of sections and cones on the search for a single minimal cardinality diagnosis (left)
and on the search for all TLDs (right) using system c5315.

Figure 9: Impact of sections and cones on the search for a single minimal cardinality diagnosis (left)
and on the search for all TLDs (right) using system c7552.
an average of 1.13 seconds, while without it requires 2.43 seconds. For the same observations, with
sections, we find all TLDs in an average of 6 seconds, and without it requires 15 seconds.
Similar trends are illustrated in Figure 9 which depicts the same information for system c7552.
Here we apply a timeout of 300 seconds, and this timeout is encountered for 48 of the 1,557 observations when searching for all minimal cardinality TLDs (timeout observations are not considered in
the average runtimes). However, even for these 48 observations, using sections provides on average
50% more TLDs than without (15,785 vs. 9,585 TLDs) before reaching the timeout.
Table 7 details, for the ISCAS-85 benchmark with Feldmans observations, the average sizes
of the SAT encodings when using the full SATbD algorithm. The table indicates the number of
System
# Components
# Variables
# Clauses

c432
160
190
556

c499
202
240
1193

c880
383
227
758

c1908
880
1026
4063

c2670
1193
636
2055

c3540
1669
2051
7456

c5315
2307
2407
11277

c6288
2416
7161
22061

c7552
3512
3525
12731

Table 7: Average SAT encoding sizes for the ISCAS-85 benchmark with Feldmans observations.
404

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

components in each system and the number of variables and clauses in the resulting CNFs, taking
the average over all observations in the Feldman benchmark. Notably, as indicated by the table, the
SAT encodings are extremely small with (in the worst case) less than three CNF variables and ten
CNF clauses per system component.

8. Discussion
This paper focuses on an MBD problem considering possibly multiple faulty components in a weak
fault model. The presentation is restricted to assume that: every component has a single output, the
observation includes a single input/output, there are no queries about observations of specific components (probes), and there is no information regarding the probability of component failures. Even
with these restrictions, the problem addressed in this paper is computationally hard and has been the
focus of many prior works in the model-based diagnosis literature (Feldman & van Gemund, 2006;
Williams & Ragno, 2007; Feldman et al., 2010a; Siddiqi & Huang, 2007, 2011).
We discuss here briefly the applicability of our approach in a more general setting. Deeper
analysis of how to adapt our approach to a more general setting is a research topic on its own. We
believe that our success in applying SAT solvers to MBD problems in this simplified setting paves
the way to their application in other more general settings.
8.1 Boolean Extensions
Our approach applies directly in any setting where the components are described by propositional
formulae and where their mode of fault can be ignored (i.e., any weak fault model setting). Boolean
circuits are just one straightforward example where this is obvious and where the community has
focused attention. Other examples with similar assumptions and where our SAT-based approach can
be expected to apply directly include the works by: Abreu et al. (2009) where the authors model
software components as propositional formulae and apply an MBD algorithm to find bugs; Kalech
and Kaminka (2005, 2006) where the authors model robots in a multi-robot system and diagnose
the violation of coordination constraints among robots; and Felfernig et al. (2012) where the authors
model finite domain constraints and diagnose inconsistent constraint sets.
Note that restricting components to have a single output is not really a restriction as it is straightforward to represent a component with multiple outputs as a conjunction of single output components. In this way the partition into cones and sections is fully compatible with multiple-output
components.
8.2 Probabilities
Real world applications of MBD typically come with information regarding the probability of a
component to be faulty and many MBD algorithms exploit this information to prioritize diagnoses
with respect to their likelihood (interalia, see de Kleer & Williams, 1989; Williams & Ragno,
2007). Sachenbacher and Williams (2004) showed how to incorporate fault probabilities in a treedecomposition diagnosis algorithm. Extending our approach tonconsider
fi probabilities
o is straightfi
forward. The essential difference is in Constraint 2, sum leq( Hc fi c  COMPS , k), which
specifies the objective function we n
aim to minimize.fiIt can be replaced
o with a constraint that takes
fi
probabilities into account: sum leq( Hc  (1  pc ) fi c  COMPS , k) where pc is the probabil405

fiM ETODI , S TERN , K ALECH & C ODISH

ity that component c is faulty. So, constraints which are more likely to be faulty contribute less to the
objective function. Note that it is straightforward to normalize the constraint so that the coefficients
are integers. Constraints of this form are called Pseudo-Boolean constraints and their encoding to
CNF is well studied (Een & Sorensson, 2006).
8.3 Testing and Probes
Another extension that is straightforward to model in SAT concerns testing and probing (de Kleer
& Williams, 1987). Here, the diagnosis algorithm is given multiple observations on the input/output
behavior of the system (in testing) or additional observations on internal wires in the system (in
probing). Under the assumption that faulty components are consistently faulty, we can invalidate
diagnoses that are inconsistent with multiple observations. Similarly, probes can invalidate diagnoses that are not consistent with the new internal observation. Both methods can be run iteratively
until there is a single consistent diagnosis. Both techniques are straightforward to encode to SAT.
For testing, to improve the diagnosis we simply take the conjunction of encodings with respect to
different observations, but using the same health variables. For probing we also take a conjunction
with the internal observations. The main challenge for both methods is to reduce the number of
probes (or tests) required to find the actual diagnosis. A common, greedy, approach to address this
challenge is to choose a probe (test) that maximizes the information gain as described by Feldman
et al. (2010b).
8.4 The Strong Fault Model
Now consider an extension of our approach to a setting in which components are associated with
a wider range of possible faulty behavior modes. This is called the Strong Fault Model. For
instance, a setting where a circuit component may be stuck at 0 (always returns output 0), stuck
at 1(always returns output 1), or flip (always flips its output) (Struss & Dressier, 1989; de Kleer
& Williams, 1989). In the context of this example, a naive SAT model may be obtained as follows.
Instead of considering only a single propositional health variable Hc , consider one additional varif
s1
able per fault mode: Hs0
c (stuck at zero), Hc (stuck at one), and Hc (flip). Now, introduce clauses
f
s1
s0
(a) to express that any fault mode is a fault (Hc  Hc  Hc  Hc ); and (b) to express that there is at
s1
f
most one fault on a component sum leq({Hs0
c , Hc , Hc }, 1). In this way the propositional health
variable Hc , as before, indicates if a component is healthy but a diagnosis is now an assignment of
fault types to each component. However, this extension requires to reconsider the definitions of
minimal diagnosis and cardinality and presents a new challenge in identifying useful partitions of
the system and in solving the problem with SAT. We consider this as future work.
8.5 Diagnosis for Physical Systems
This is the most challenging problem. Physical systems are typically dynamic, involve components
with time dependent behavior, and described in terms of continuous variables. One common approach to apply MBD to physical systems is to use qualitative models where the behavior of the
system is modeled as a set of constraints over non-numerical (discrete) descriptions (Subramanian
& Mooney, 1996). A well-known example of an MBD engine that makes such relaxations is the
Livingstone Model-Based Diagnosis System (Williams & Nayak, 1996). Livingstone has been successfully applied in Deep Space One, the first spacecraft for NASAs New Millennium program.
406

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

A first and important step for a SAT based approach for the diagnosis of physical systems is to
provide a setting for MBD in the strong fault model and able to capture probabilities. Of course,
there are many additional challenges and the modeling of such systems using SAT is an important
but feasible challenge.

9. Conclusion
This paper addresses an MBD challenge which has been extensively researched for more than 25
years and for which a wide range of papers propose different algorithms. We present a novel SATbased solution for this problem and determine for the first time, minimal cardinality diagnoses for
the entire standard benchmarks. We present an extensive experimental evaluation comparing our
algorithm to HA*, CDA*, SAFARI, HDIAG and DCAS. Results are unequivocal. Our algorithm outperforms the others, often by orders of magnitude, both for the search of a single minimal cardinality
diagnosis as well as for the search for all minimal cardinality diagnoses. We succeed to find and
verify a minimal cardinality diagnosis for all but 11 of the 28,257 observations of the benchmark
in under 30 seconds per observation, and for the remaining 11 in under 80 seconds each. To the
best of our knowledge, our SATbD algorithm is the first algorithm to find the minimal cardinality of
these standard benchmarks discussed above. Further details regarding the experimental evaluation
as well as a prototype implementation of our SAT-based MBD tool can be found online (Metodi,
2012a; Metodi et al., 2012b).
A major contribution to the success of our approach is the range of preprocessing techniques
presented in Section 5. Their impact is demonstrated through five configurations of the system
in Section 7.3 and their full combination is the fifth such configuration. Even as SAT, and other
related solvers, improve we conjecture that careful modeling choices involving combinations of
these techniques are invaluable to the success of future MBD algorithms. It is our belief that the
results of this paper will pave the way to develop and apply SAT-based methodologies to other
MBD problems. In particular, extensions for diagnosis with probabilities of components to be
faulty, for sequential diagnosis with testing and probes, and, most challenging, for the diagnosis
of physical systems with qualitative models. We expect that our methodology, which combines
domain dependent preprocessing, clever modeling in SAT, and application of tools to optimize the
CNF encodings, is relevant to other hard problems in AI where SAT-based techniques are applicable.
Acknowledgments
This research was supported by the Israel Science Foundation, grant 182/13.

References
Abreu, R., Zoeteweij, P., Golsteijn, R., & van Gemund, A. J. C. (2009). A practical evaluation of
spectrum-based fault localization. Journal of Systems and Software, 82(11), 17801792.
Asn, R., Nieuwenhuis, R., Oliveras, A., & Rodrguez-Carbonell, E. (2009). Cardinality networks
and their applications. In Kullmann, O. (Ed.), SAT, Vol. 5584 of Lecture Notes in Computer
Science, pp. 167180. Springer.
Asn, R., Nieuwenhuis, R., Oliveras, A., & Rodrguez-Carbonell, E. (2011). Cardinality networks:
a theoretical and empirical study. Constraints, 16(2), 195221.
407

fiM ETODI , S TERN , K ALECH & C ODISH

Balakrishnan, K., & Honavar, V. (1998). Intelligent diagnosis systems. Journal of Intelligent Systems, 8(3/4), 239290.
Batcher, K. E. (1968). Sorting networks and their applications. In AFIPS Spring Joint Computing
Conference, Vol. 32 of AFIPS Conference Proceedings, pp. 307314.
Bauer, A. (2005). Simplifying diagnosis using LSAT: a propositional approach to reasoning from
first principles. In Bartak, R., & Milano, M. (Eds.), International Conference on Integration of
AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems
(CP-AI-OR), Vol. 3524 of Lecture Notes in Computer Science, pp. 4963, Berlin, Heidelberg.
Springer-Verlag.
Biere, A., Heule, M., van Maaren, H., & Walsh, T. (Eds.). (2009). Handbook of Satisfiability, Vol.
185 of Frontiers in Artificial Intelligence and Applications. IOS Press.
Brglez, F., Bryan, D., & Kozminski, K. (1989). Combinatorial profiles of sequential benchmark
circuits. In IEEE International Symposium on Circuits and Systems, pp. 19291934.
Bylander, T., Allemang, D., Tanner, M. C., & Josephson, J. R. (1991). The computational complexity of abduction. Artificial Intelligence, 49(1-3), 2560.
Codish, M., & Zazon-Ivry, M. (2010). Pairwise cardinality networks. In Logic for Programming,
Artificial Intelligence, and Reasoning (LPAR), pp. 154172.
Darwiche, A. (2001). Decomposable negation normal form. Journal of the ACM, 48(4), 608647.
de Kleer, J., & Williams, B. C. (1987). Diagnosing multiple faults. Artificial Intelligence, 32(1),
97130.
de Kleer, J. (2008). An improved approach for generating max-fault min-cardinality diagnoses. In
International Workshop on Principles of Diagnosis (DX).
de Kleer, J., & Williams, B. C. (1989). Diagnosis with behavioral modes. In International Joint
Conference on Artificial Intelligence (IJCAI), pp. 13241330.
Dressler, O., & Struss, P. (1995). Occm. http://www.occm.de.
DXC

(2009).
International diagnostic
https://sites.google.com/site/dxcompetition/.

competition

series.

Website.

Een, N., & Sorensson, N. (2006). Translating pseudo-Boolean constraints into SAT. Journal on
Satisfiability (JSAT), 2(1-4), 126.
El Fattah, Y., & Dechter, R. (1995). Diagnosing tree-decomposable circuits. International Joint
Conference on Artificial Intelligence (IJCAI), 95, 17421749.
Feldman, A., Provan, G., de Kleer, J., Robert, S., & van Gemund, A. (2010). Solving model-based
diagnosis problems with Max-SAT solvers and vice versa. In International Workshop on
Principles of Diagnosis (DX), pp. 185192.
Feldman, A. (2012). Lydia-ng. http://www.general-diagnostics.com/products.
php.
Feldman, A., de Castro, H. V., van Gemund, A., & Provan, G. (2013). Model-based diagnostic
decision-support system for satellites. In IEEE Aerospace Conference, pp. 114. IEEE.
Feldman, A., Provan, G., & van Gemund, A. (2010a). Approximate model-based diagnosis using
greedy stochastic search. Journal of Artificial Intelligence Research (JAIR), 38, 371413.
408

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Feldman, A., Provan, G., & van Gemund, A. (2010b). A model-based active testing approach to
sequential diagnosis. Journal of Artificial Intelligence Research (JAIR), 39, 301334.
Feldman, A., & van Gemund, A. J. C. (2006). A two-step hierarchical algorithm for model-based
diagnosis. In Conference on Artificial Intelligence (AAAI), pp. 827833.
Felfernig, A., Schubert, M., & Zehentner, C. (2012). An efficient diagnosis algorithm for inconsistent constraint sets. Artificial Intelligence for Engineering Design, Analysis and Manufacturing, 26(1), 5362.
Frohlich, P., & Nejdl, W. (1997). A static model-based engine for model-based reasoning. In
International Joint Conference on Artificial Intelligence (IJCAI), pp. 466473.
Fujiwara, H., Member, S., Shimono, T., & Member, S. (1983). On the acceleration of test generation
algorithms. IEEE Transactions on Computers, 32, 11371144.
Hansen, M. C., Yalcin, H., & Hayes, J. P. (1999). Unveiling the ISCAS-85 benchmarks: A case
study in reverse engineering. IEEE Des. Test, 16, 7280.
Jannach, D., & Schmitz, T. (2014). Model-based diagnosis of spreadsheet programs: a constraintbased debugging approach. Automated Software Engineering, 1, 140.
Kalech, M., & Kaminka, G. A. (2005). Towards model-based diagnosis of coordination failures. In
Conference on Artificial Intelligence (AAAI), pp. 102107.
Kalech, M., Kaminka, G. A., Meisels, A., & Elmaliach, Y. (2006). Diagnosis of multi-robot coordination failures using distributed CSP algorithms. In Conference on Artificial Intelligence
(AAAI), pp. 970975.
Kirkland, T., & Mercer, M. R. (1987). A topological search algorithm for ATPG. In ACM/IEEE
Design Automation Conference, DAC, pp. 502508.
Knuth, D. E. (2014). The Art of Computer Programming: Volume 4B, Pre-fascicle 6A, Section
7.2.2.2: Satisfiability. Unpublished. Draft available from: http://www-cs-faculty.
stanford.edu/knuth/fasc6a.ps.gz.
Marques-Silva, J., Lynce, I., & Malik, S. (2009). Conflict-driven clause learning SAT solvers.
Handbook of satisfiability, 185, 131153.
Metodi, A. (2012a). SCryptodiagnoser: A SAT based MBD solver. http://amit.metodi.
me/research/mbdsolver.
Metodi, A. (2012b). SCryptominisat. http://amit.metodi.me/research/scrypto.
Metodi, A., & Codish, M. (2012). Compiling finite domain constraints to SAT with BEE. Theory
and Practice of Logic Programming (TPLP), 12(4-5), 465483.
Metodi, A., Codish, M., Lagoon, V., & Stuckey, P. J. (2011). Boolean equi-propagation for optimized SAT encoding. In CP, pp. 621636.
Metodi, A., Codish, M., & Stuckey, P. J. (2013). Boolean equi-propagation for concise and efficient
SAT encodings of combinatorial problems. Journal of Artificial Intelligence Research (JAIR),
46, 303341.
Metodi, A., Stern, R., Kalech, M., & Codish, M. (2012a). Compiling model-based diagnosis to
Boolean satisfaction. In Conference on Artificial Intelligence (AAAI).
409

fiM ETODI , S TERN , K ALECH & C ODISH

Metodi, A., Stern, R., Kalech, M., & Codish, M. (2012b). Compiling model-based diagnosis to
Boolean satisfaction: Detailed experimental results and prototype implementation. http:
//www.cs.bgu.ac.il/mcodish/Papers/Pages/aaai-2012.html.
Murray, J., Hughes, G., & Kreutz-Delgado, K. (2006). Machine learning methods for predicting failures in hard drives: A multiple-instance application. Journal of Machine Learning Research
(JMLR), 6(1), 783.
Nica, I., Pill, I., Quaritsch, T., & Wotawa, F. (2013). The route to success - a performance comparison of diagnosis algorithms. In International Joint Conference on Artificial Intelligence
(IJCAI), pp. 10391045.
Reiter, R. (1987). A theory of diagnosis from first principles. Artificial Intelligence, 32(1), 5795.
Sachenbacher, M., & Williams, B. (2004). Diagnosis as semiring-based constraint optimization. In
Eureopean Conference on Artificial Intelligence (ECAI), pp. 873877.
Selman, B., & Levesque, H. J. (1990). Abductive and default reasoning: A computational core. In
National Conference on Artificial Intelligence (AAAI), pp. 343348.
Siddiqi, S. A., & Huang, J. (2007). Hierarchical diagnosis of multiple faults. In International Joint
Conference on Artificial Intelligence (IJCAI), pp. 581586.
Siddiqi, S. A., & Huang, J. (2011). Sequential diagnosis by abstraction. Journal of Artificial Intelligence Research (JAIR), 41, 329365.
Smith, A., Veneris, A. G., Ali, M. F., & Viglas, A. (2005). Fault diagnosis and logic debugging
using Boolean satisfiability. IEEE Trans. on CAD of Integrated Circuits and Systems, 24(10),
16061621.
Soos, M. (2010). Cryptominisat, v2.5.1. http://www.msoos.org/cryptominisat2.
Stein, B., Niggemann, O., & Lettmann, T. (2006). Speeding up model-based diagnosis by a heuristic
approach to solving SAT. In IASTED international conference on Artificial intelligence and
applications, pp. 273278.
Stern, R. T., Kalech, M., Feldman, A., & Provan, G. M. (2012). Exploring the duality in conflictdirected model-based diagnosis. In AAAI.
Struss, P., & Dressier, O. (1989). Physical negation: Integrating fault models into the general
diagnostic engine. In International Joint Conference on Artificial Intelligence (IJCAI), pp.
13181323.
Struss, P., & Price, C. (2003). Model-based systems in the automotive industry. AI magazine, 24(4),
1734.
Stumptner, M., & Wotawa, F. (2001). Diagnosing tree-structured systems. Artificial Intelligence,
127(1), 129.
Stumptner, M., & Wotawa, F. (2003). Coupling CSP decomposition methods and diagnosis algorithms for tree-structured systems. In International Joint Conference on Artificial Intelligence
(IJCAI), pp. 388393.
Subramanian, S., & Mooney, R. J. (1996). Qualitative multiple-fault diagnosis of continuous dynamic systems using behavioral modes. In National Conference on Artificial Intelligence
(AAAI), pp. 965970.
410

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Torasso, P., & Torta, G. (2006). Model-based diagnosis through OBDD compilation: A complexity
analysis. In Reasoning, Action and Interaction in AI Theories and Systems, pp. 287305.
Wang, J., & Provan, G. (2010). A benchmark diagnostic model generation system. Part A: Systems
and Humans, IEEE Transactions on Systems, Man and Cybernetics, 40(5), 959981.
Williams, B. C., & Nayak, P. P. (1996). A model-based approach to reactive self-configuring systems. In National Conference on Artificial Intelligence (AAAI), pp. 971978.
Williams, B. C., & Ragno, R. J. (2007). Conflict-directed A* and its role in model-based embedded
systems. Discrete Applied Mathematics, 155(12), 15621595.

411

fi