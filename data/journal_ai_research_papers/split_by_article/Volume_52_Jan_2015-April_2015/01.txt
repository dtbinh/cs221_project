Journal of Artificial Intelligence Research 52 (2015) 97-169

Submitted 05/14; published 01/15

Deterministic Oversubscription Planning as Heuristic Search:
Abstractions and Reformulations
Carmel Domshlak
Vitaly Mirkis

dcarmel@ie.technion.ac.il
mirkis80@gmail.com

Faculty of Industrial Engineering & Management,
Technion - Israel Institute of Technology,
Haifa, Israel

Abstract
While in classical planning the objective is to achieve one of the equally attractive goal
states at as low total action cost as possible, the objective in deterministic oversubscription
planning (OSP) is to achieve an as valuable as possible subset of goals within a fixed
allowance of the total action cost. Although numerous applications in various fields share
the latter objective, no substantial algorithmic advances have been made in deterministic
OSP. Tracing the key sources of progress in classical planning, we identify a severe lack of
effective domain-independent approximations for OSP.
With our focus here on optimal planning, our goal is to bridge this gap. Two classes
of approximation techniques have been found especially useful in the context of optimal
classical planning: those based on state-space abstractions and those based on logical landmarks for goal reachability. The question we study here is whether some similar-in-spirit,
yet possibly mathematically different, approximation techniques can be developed for OSP.
In the context of abstractions, we define the notion of additive abstractions for OSP, study
the complexity of deriving effective abstractions from a rich space of hypotheses, and reveal
some substantial, empirically relevant islands of tractability. In the context of landmarks,
we show how standard goal-reachability landmarks of certain classical planning tasks can
be compiled into the OSP task of interest, resulting in an equivalent OSP task with a lower
cost allowance, and thus with a smaller search space. Our empirical evaluation confirms the
effectiveness of the proposed techniques, and opens a wide gate for further developments
in oversubscription planning.

1. Introduction
The tools of automated action planning allow autonomous systems selecting a course of
action to get things done. Deterministic planning is probably the most basic, and thus
the most fundamental, setting of automated action planning (Russell & Norvig, 2009). It
can be viewed as the problem of finding trajectories of interest in large-scale yet concisely
represented state-transition systems. Computational approaches to deterministic planning
vary around the way those trajectories of interest are defined.
The basic structure of acting in situations with underconstrained or overconstrained
resources is respectively captured by what these days is called classical deterministic
planning (Fikes & Nilsson, 1971), and by what Smith (2004) termed oversubscription
deterministic planning (OSP). In classical planning, the task is to find the most cost-effective
trajectory possible to a goal-satisfying state. In oversubscription planning, the task is to
find the most goal-effective (or valuable) state possible via a cost-satisfying trajectory. In
c
2015
AI Access Foundation. All rights reserved.

fiDomshlak & Mirkis

optimal classical planning and in optimal OSP, the tasks are further constrained to finding
only most cost-effective trajectories and most goal-effective states, respectively. Classical
planning and OSP can be viewed as foundational variants of deterministic planning, with
many other variants, such as net-benefit planning and cost-bounded planning, being defined
in terms of mixing and relaxing the two.1
While OSP has been extensively advocated over the years, the theory and practice of
classical planning have been studied and advanced much more intensively. The remarkable
success and continuing progress of heuristic-search solvers for classical planning is one notable example. Primary enablers of this success are the advances in domain-independent
approximations, or heuristics, of the cost needed to achieve a goal state from a given state.
It is thus possible that having a similarly rich palette of effective heuristic functions for
OSP would advance the state of the art in that problem.
Two classes of approximation techniques have been found especially useful in the context of optimal classical planning: those based on state-space abstractions (Edelkamp, 2001;
Haslum, Botea, Helmert, Bonet, & Koenig, 2007; Helmert, Haslum, Hoffmann, & Nissim,
2014; Katz & Domshlak, 2010a) and those based on logical landmarks for goal reachability (Karpas & Domshlak, 2009; Helmert & Domshlak, 2009; Domshlak, Katz, & Lefler,
2012; Bonet & Helmert, 2010; Pommerening & Helmert, 2013). Considering OSP as heuristic search, a question is then whether some similar-in-spirit, yet possibly mathematically
different, approximation techniques can be developed for heuristic-search OSP. This is precisely the question we study here.
 Starting with the most basic question of what state-space abstractions for OSP actually are, we show that the very notion of abstraction differs substantially for classical planning and OSP. Hence, first we define (additive) abstractions and abstraction
heuristics for OSP. We then investigate the computational complexity of deriving
effective abstraction heuristics in the scope of homomorphic abstraction skeletons,
paired with cost, value, and budget partitions. Along with revealing some significant
islands of tractability, this study exposes an interesting interplay between knapsackstyle problems of combinatorial optimization, continuous convex optimization, and
certain principles borrowed from explicit abstractions for classical planning.
 We introduce and study -landmarks, the logical properties of OSP plans that achieve
valuable states. We show that -landmarks correspond to regular goal-reachability
landmarks of certain classical planning tasks that can be straightforwardly derived
from the OSP tasks of interest. We then show how such -landmarks can be compiled
back into the OSP task of interest, resulting in an equivalent OSP task, but with a
stricter cost satisfaction constraint, and thus with a smaller effective search space.
Finally, we show how such landmark-based task enrichment can be combined in a
mutually stratifying way with the best-first branch-and-bound search used for OSP
planning, resulting in an incremental procedure that interleaves search and landmark
discovery. The entire framework is independent of the OSP planner specifics, and in
particular, of the heuristic functions it employs.
1. The connections and differences between some popular variants of deterministic planning are discussed
in Section 2.

98

fiOn Oversubscription Planning as Heuristic Search

Our empirical evaluation on a large set of OSP tasks confirms the effectiveness of the proposed techniques. Moreover, to the best of our knowledge, our implementation constitutes
the first domain-independent solver for optimal OSP, and we hope that more advances in
this important computational problem will follow.
This work is a revision and extension of the formulations and results presented by the
authors at ICAPS-2013 and ECAI-2014 (Mirkis & Domshlak, 2013, 2014). The paper is
structured as follows. In Section 2 we formulate a general model of deterministic planning,
define several variants of deterministic planning in terms of this model, and, in particular,
show that oversubscription planning differs conceptually not only from classical planning,
but also from other popular variants of deterministic planning such as net-benefit planning
and cost-bounded planning. We also specify a simple model representation language for
OSP, as well as provide the essential background on heuristic search, and, in particular,
on OSP as heuristic search. Sections 3 and 4 are devoted, respectively, to abstractions
and abstraction approximations for OSP. Section 5 is devoted to exploiting reachability
landmarks in OSP tasks. In Section 6 we conclude and discuss some promising directions
for future work. For the sake of readability, some of the proofs are relegated to Appendix A,
and some details of the empirical results are relegated to Appendix B.

2. Background
As mentioned in the introduction, specific variants of deterministic planning differ in the
way the interest and preference over trajectories are defined. For instance, in classical
planning (Fikes & Nilsson, 1971), a trajectory is of interest if it connects a designated initial
state to one of the designated goal states, with the preference being towards trajectories
with lower total cost of the transitions along them. Among other, non-classical variants
of deterministic planning are
 oversubscription planning (Smith, 2004), the topic of interest here;
 net-benefit planning (van den Briel, Sanchez, Do, & Kambhampati, 2004; Sanchez
& Kambhampati, 2005; Baier, Bacchus, & McIlraith, 2009; Bonet & Geffner, 2008;
Benton, Do, & Kambhampati, 2009; Coles & Coles, 2011; Keyder & Geffner, 2009);
 cost-bounded (also known as resource-constrained) planning (Haslum & Geffner, 2001;
Hoffmann, Gomes, Selman, & Kautz, 2007; Gerevini, Saetti, & Serina, 2008; Thayer &
Ruml, 2011; Thayer, Stern, Felner, & Ruml, 2012; Haslum, 2013; Nakhost, Hoffmann,
& Muller, 2012); and
 planning with preferences over temporal properties of the trajectories (Baier et al.,
2009; Gerevini, Haslum, Long, Saetti, & Dimopoulos, 2009; Benton, Coles, & Coles,
2012).
Interestingly, while working on this paper, we have learned that quite a few different
variants of deterministic planning are often collectively referred to as oversubscription
planning. As a result, the difference between them in terms of expressiveness is not necessarily clear, and thus, the relationship between what we do here and what has already been
done in the collective sense of oversubscription planning is not always apparent. This is
the issue we will address first.
99

fiDomshlak & Mirkis

2.1 Models
Adopting and extending the notation of Geffner and Bonet (2013), we can view many
variants of deterministic planning, including classical planning, as well as many popular
non-classical variants, as special cases of a state model
M = hS, s0 , u, O, , c, Qi

(1)

with:
 a finite set of states S,
 an initial state s0  S,
 a state value function u : S 7 R0+  {},
 operators O(s)  O applicable in each state s  S,
 a deterministic state transition function (s, o) such that s0 = (s, o) stands for the
state resulting from applying o  O(s) in s,
 an operator cost function c : O  R0+ , and
 a quality measure Q : P 7 R  {}, where P is the (infinite) set of trajectories
from s0 along operators O. A trajectory in P is a sequence of operators ho1 , . . . , on i
such that o1  O(s0 ) and, inductively, oi  O(((. . . (s0 , o1 ) . . . , oi2 ), oi1 )).
In this model, any trajectory   P is a solution, with preference towards solutions of
higher quality. In what
P follows, sJK stands for the end-state of a trajectory  applied at
state s, and c() = o c(o) is the additive cost of . Likewise, the graphical skeleton
GM = hS, T , Oi of a model M refers to the edge-annotated, unweighted digraph induced
by M where the nodes of GM are the states S, the edge labels are the operators O, and T
contains an edge from s to s0 labeled with o iff o  O(s) and s0 = (s, o).
First, consider a quality measure
Q+ () = u(sJK)  c().

(2)

This measure assumes that state values and operator costs are comparable, and thus represents a tradeoff between the value of the end-state and the cost of the trajectory. Consider
now a fragment of the state model (1), instances of which all have the quality measure Q+ ,
and for each instance, the value function
(
,
s  Sgoal
u(s) =
(3)
, otherwise
partitions the state space into Sgoal  S, on which u takes a finite value   0, and the
rest of the states, on which u takes the value of . Finding an optimal solution for an
instance M of this fragment corresponds to finding a shortest path from s0 to a single node
s in an edge-weighted digraph G, which is obtained from GM by (i) annotating the edges
of the latter with costs c, and (ii) adding a dummy node s and zero-cost edges from all
100

fiOn Oversubscription Planning as Heuristic Search

constraint

preference

Net Benefit

Oversubscription

constraint

End-state value

Action cost
preference

Classical

Cost-bounded

Figure 1: Schematic classification of four deterministic planning models along the strictness
with which they approach the cost of operator sequences and the value of the
operator sequence end-states. White blocks are for planning models that can be
solved as single-source single-target shortest path problems.

goal nodes s  Sgoal to s . While specified in a non-canonical way, this fragment can be
easily verified to correspond to the model of classical planning, with Sgoal being the classical
planning goal states.
Staying with the quality measure Q+ and removing now the requirement on u to comply
with Eq. 3, we obtain a fragment that generalizes classical planning, and constitutes the
basic model of what is called net-benefit planning (Sanchez & Kambhampati, 2005). Importantly, any instance M of this fragment can be reduced to finding a shortest path from
a single node s0 to a single node s in an edge-weighted digraph G, obtained from GM by
(i) annotating edges of GM with costs c, (ii) adding a dummy node s andPedges from all
nodes s  S to s , and (ii) setting the cost of each such new edge (s, s ) to s0 S\{s} u(s0 ).
This reduction works because net-value maximization over the end state s is equivalent
to minimization of the net-loss of giving up on all the other possible end states. This
same basic idea underlies Keyder and Geffners (2009) scheme for compiling certain standard representation formalisms for net-benefit planning into a standard classical planning
formalism.2
Consider now an alternative quality measure
(
u(sJK), c()  b
Q () =
,
,
otherwise
b

(4)

2. It is worth noting that the wost-case complexity equivalence between classical planning and net-benefit
planning has been shown prior to the work of Keyder and Geffner (2009) by van den Briel et al. (2004).
However, this equivalence was not prescriptive enough to suggest practically effective compilations of
compactly represented net-benefit planning tasks to classical planning tasks.

101

fiDomshlak & Mirkis

where b  R0+ is a predefined bound on the cost of the trajectories. The fragment of the
basic model, instances of which are characterized by having the quality measure Qb and
the  or  value functions as in Eq. 3, constitutes the model of what is called costbounded planning (Thayer & Ruml, 2011). Here as well, finding an optimal solution for a
problem instance M corresponds to finding a shortest path from s0 to s in an edge-weighted
digraph G, which is derived from GM identically to the case of classical planning.3 This,
in particular, explains why it is only natural for heuristic-search methods for cost-bounded
planning to exploit heuristics developed for classical planning (Haslum, 2013).
We now arrive to a fourth fragment of the basic model. Staying with the quality measure Qb and removing the requirement on u to comply with Eq. 3, we obtain a fragment
that generalizes cost-bounded planning, and constitutes the model of oversubscription planning (Smith, 2004). As illustrated in Figure 1, the hard constraint of classical planning
translates to soft preference in OSP, and the hard constraint of OSP translates to soft preference in classical planning. However, in contrast to cost-optimal, net-benefit, and classical
planning, this fragment does not appear to be reducible to the single-source single-target
shortest path problem. In terms of the digraph G obtained from GM by annotating the
edges with costs c, finding an optimal solution to an instance of oversubscription planning
requires (i) finding shortest paths from s0 to all states s  S with u(s) > 0, (ii) filtering out
from these states those that are not reachable from s0 within the cost allowance b, and (iii)
selecting from the remaining states a state that maximizes u.
This contrast between oversubscription planning and the three other popular variants of
deterministic planning discussed above has at least two important implications. First, while
a single shortest path can be searched for using best-first forward search procedures such
as A , searching for shortest paths to numerous targets simultaneously requires a different,
more exhaustive, forward search framework such as branch-and-bound. Second, net-benefit
and cost-bounded planning clearly have the potential to (directly or indirectly) reuse the rich
toolbox of heuristic functions developed over the years for classical planning. In contrast,
due to the differences in the underlying computational model, the same is not necessarily
true for oversubscription planning, and examining the prospects of heuristic functions in
OSP is precisely the focus of our work here.
2.2 Notation
For k  N+ , by [k] we denote the set {1, 2, . . . , k}. The indicator function of a subset A of
a set X is a function 1A : X  {0, 1} defined as 1A (x) = 1 if x  A and 1A (x) = 0 if x 6 A.
Following Nebel (2000), when we talk about the size of a mathematically well-defined object
x, symbolically ||x||, we mean the size of a (reasonable) encoding of x. An assignment of a
variable v to value d is denoted by hv/di; we often refer to such single variable assignments
as propositions.

3. Strictly speaking, once a shortest path  from s0 to s is found, it should still be checked against the
cost bound b. This test, however, is local to , and problem solving finishes independently of the tests
outcome.

102

fiOn Oversubscription Planning as Heuristic Search

2.3 Model Representation
Departing from a very general model of oversubscription planning, in what follows we restrict our attention to instances of that model that are compactly representable in a language
close to the sas+ language for classical planning (Backstrom & Klein, 1991; Backstrom &
Nebel, 1995). In this language, a deterministic oversubscription planning (OSP) task
is given by a sextuple
 = hV, s0 , u; O, c, bi,

(5)

where
(1) V = {v1 , . . . , vn } is a finite set of finite-domain state variables, with each complete
assignment to V representing a state, and S = dom(v1 )      dom(vn ) being the state
space of the task;
(2) s0  S is a designated initial state;
(3) u is an efficiently computable state value function u : S  R0+ ;
(4) O is a finite set of operators, with each operator o  O being represented by a pair
hpre(o), eff(o)i of partial assignments to V , called preconditions and effects of o, respectively;
(5) c : O  R0+ is an operator cost function;
(6) b  R0+ is a cost budget allowed for the task.
Now consider the semantics of such a task description in terms of 
our basic model. An
ff
OSP task  = hV, s0 , u; O, c, bi can be said to induce the model M = S, s0 , u, O, , c, Qb ,
with Qb being the quality measure (4) instantiated with the s budget b, and the transition
function  being specified as follows. For a partial assignment p to V , let V(p)  V denote
the subset of variables instantiated by p, and, for v  V(p), p[v] denote the value provided
by p to the variable v. Similarly to the classical planning semantics of sas+ , operator o
is applicable in a state s iff s[v] = pre(o)[v] for all v  V(pre(o)). Applying o changes the
value of each v  V(eff(o)) to eff(o)[v], and the resulting state is denoted by sJoK. This
notation is only defined if o is applicable in s. Denoting an empty sequence of operators by ,
applying a sequence of operators ho1 , . . . , om i to a state s is defined inductively as sJK := s
and sJo1 , . . . , oj K := sJo1 , . . . , oj1 KJoj K. An operator sequence  is called an s-plan if it is
applicable in state s and Qb () 6= , that is, c()  b.
Some
S auxiliary notation is used later on: For an OSP task  = hV, s0 , u; O, c, bi, by
D = vV dom(v) we denote the union of the (uniquely labeled) state-variable domains.
For a state s and a proposition hv/di  D, hv/di  s is used as a shortcut notation for
s[v] = d.
An example of a simple OSP task in Figure 2 is used to illustrate this model representation. In this example, a truck is initially at location A, and it can drive (only) from location
A to location B and from location B to location C. Two packages, x and y, are initially
at location B. When a package and the truck are in the same location, the package can
be loaded onto the truck, and when a package is on the truck, it can be unloaded at the
103

fiDomshlak & Mirkis

x
y
A

B

C

(a)
oi
pre(oi )
eff(oi )

driveAB
i=1
{ht/Ai}
{ht/Bi}

driveBC
i=2
{ht/Bi}
{ht/Ci}

loadBx
i=3
{ht/Bi , hx/Bi}
{hx/T i}

loadBy
i=4
{ht/Bi , hy/Bi}
{hy/T i}

unloadCx
i=5
{ht/Ci , hx/T i}
{hx/Ci}

oi
pre(oi )
eff(oi )

unloadBx
i=6
{ht/Bi , hx/T i}
{hx/Bi}

unloadBy
i=7
{ht/Bi , hy/T i}
{hy/Bi}

unloadCy
i=8
{ht/Ci , hy/T i}
{hy/Ci}

loadCx
i=9
{ht/Ci , hx/Ci}
{hx/T i}

loadCy
i = 10
{ht/Ci , hy/Ci}
{hy/T i}

(b)
u=1

CBB

o2
ABB

o1

BBB

BTB
o6
o3
o7
o4
BBT

CTB

o9
o5

CCB

BTT

o2

CTT

o2
o7
o4
o3
o6
o2

o10
o8
u=1

o10
o8

CBC

CTB

o9
o5

CCB

BTT

o2

CTT

CBT

u=1

o9
o5

CTC

u=1
CCT

o9 u=2
o5
CCC

o10
o8

(c)
u=1

CBB

o2
ABB

o1

BBB

BTB
o6
o3
o7
o4
BBT

o2
o7
o4
o3
o6
o2

o10
o8
u=1

CBT

o10
o8

u=1

o9
o5

CTC

u=1
CCT

o9 u=2
o5
CCC

o10
o8

CBC

(d)

Figure 2: A simple running example of an OSP task, with (a) illustrating the story, (b) listing the operators, and (c)-(d) depicting the graphical skeleton of the induced state
model; (c) shows the region of the graphical skeleton GM that is structurally
reachable from the initial state ABB, and the grayed area in (d) corresponds to
the sub-region that cannot be reached from the initial state under the budget
b = 4.

trucks current location. Each (drive, load, and unload) operator in the task costs one unit
of cost, and the cost budget is set to four units of cost. Finally, a value of one (value unit)
is earned for each package present at location C.
This OSP task  is described here using three state variables V = {t, x, y}, with
dom(t) = {A, B, C} and dom(x) = dom(y) = {A, B, C, T }, corresponding to the possible
locations of the truck and the two packages, respectively.

 The operator set ffO = {o1 , . . . , o10 }
is detailed in Figure 2(b). In the state model M = S, s0 , u, O, , c, Qb induced by this
104

fiOn Oversubscription Planning as Heuristic Search

BFBB ( = hV, s0 , u; O, c, bi)
open := new max-heap ordered by f (n) = h(shni, b  g(n))
initialize best solution n := make-root-node(s0 )
open.insert(n )
closed:= ;
best-cost:= 0
while not open.empty()
n := open.pop-max()
if f (n)  u(shn i): break
if u(shni) > u(shn i): update n := n
if shni 6 closed or g(n) < best-cost(shni):
closed:= closed  {shni}
best-cost(shni) := g(n)
foreach o  O(shni):
n0 := make-node(shniJoK, n)
if g(n0 ) > b or f (n0 )  u(shn i): continue
open.insert(n0 )

return n
Figure 3: Best-first branch-and-bound (BFBB) search for OSP
task, we have S = dom(t)dom(x)dom(y), the initial state s0 = ABB (with the three letters in the names of the states capturing the three components of the domain cross-product),
operator cost c(oi ) = 1 for all operators oi , cost budget b = 4, and state values


1, s  {?AC, ?BC, ?CA, ?CB}
u(s) = 2, s  {?CC}


0, otherwise

.

The graphical skeleton GM is depicted in Figures 2(c) and 2(d): Figure 2(c) shows the
region of the graphical skeleton GM that is structurally reachable from the initial state
ABB, and the grayed area in Figure 2(d) corresponds to the sub-region that cannot be
reached from the initial state under the budget b = 4.
2.4 OSP as Heuristic Search
The two major ingredients of any heuristic-search planner are its search algorithm and
heuristic function. In classical planning, the heuristic is typically a function h : S  R0+ 
{}, with h(s) estimating the cost h (s) of optimal s-plans. A heuristic h is admissible
if it is lower-bounding, that is, h(s)  h (s) for all states s. All common heuristic search
algorithms for optimal classical planning, such as A , require admissible heuristics.
In contrast, a heuristic in OSP is a function h : S  R0+  R0+ , with h(s, b) estimating
the value h (s, b) of optimal s-plans under cost budget b. A heuristic h is admissible if it is
upper-bounding, that is, h(s, b)  h (s, b) for all states s and all cost budgets b. Here as well,
105

fiDomshlak & Mirkis

search algorithms for optimal OSP, such as best-first branch-and-bound (BFBB),4 require
admissible heuristics for pruning search branches without violating solution optimality.
Figure 3 depicts a pseudo-code description of BFBB for OSP; shni there denotes the state
associated with search node n, and cost-so-far g(n) is the total cost of the action sequence
associated with n. Unlike in A , the order in which the nodes are selected from the OPEN
list does not affect the optimality guarantees (though it may, of course, seriously affect the
empirical efficiency of the search). In Figure 3, the ordering of OPEN corresponds to the
decreasing order of h(shni, b  g(n)). The duplicate detection and reopening mechanisms
in BFBB are similar to those in A (Pearl, 1984). In addition, BFBB maintains the best
solution n found so far and uses it to prune all generated nodes evaluated no higher than
u(shn i). Likewise, complying with the semantics of OSP, all generated nodes n with costso-far g(n) higher than the problems budget b are also immediately pruned. When the
OPEN list becomes empty or the node n selected from the list promises less than the lower
bound, BFBB returns (the plan associated with) the best solution n . If h is admissible,
that is, the h-based pruning of the generated nodes is sound, then the returned plan is
guaranteed to be optimal.
Let us now return to the heuristic functions. In domain-independent planning they
should be automatically derived from the description of the model in the language of choice.
A useful heuristic function must be both efficiently computable from the description of the
model, as well as relatively accurate in its estimates. Improving the accuracy of a heuristic
function without substantially worsening the time complexity of computing it translates
into faster search for plans.
In classical planning, numerous approximation techniques, such as monotonic relaxation (Bonet & Geffner, 2001, 2001; Hoffmann & Nebel, 2001), critical trees (Haslum
& Geffner, 2000), network flow (van den Briel, Benton, Kambhampati, & Vossen, 2007;
Bonet, 2013), logical landmarks for goal reachability (Richter, Helmert, & Westphal, 2008;
Karpas & Domshlak, 2009; Helmert & Domshlak, 2009; Bonet & Helmert, 2010), and
abstractions (Edelkamp, 2001; Helmert, Haslum, & Hoffmann, 2007; Katz & Domshlak,
2010a), have been translated to effective heuristic functions. Likewise, different heuristics
for classical planning can also be combined into their point-wise maximizing and/or additive
ensembles (Edelkamp, 2001; Haslum, Bonet, & Geffner, 2005; Coles, Fox, Long, & Smith,
2008; Katz & Domshlak, 2010b; Helmert & Domshlak, 2009).
In contrast, development of heuristic functions for OSP has not progressed beyond the
initial ideas of Smith (2004). In principle, the reduction of Keyder and Geffner (2009) from
net-benefit to classical planning can be used to reduce OSP to classical planning with realvalued state variables (Koehler, 1998; Helmert, 2002; Fox & Long, 2003; Hoffmann, 2003;
Gerevini, Saetti, & Serina, 2003; Gerevini et al., 2008; Edelkamp, 2003; Dvorak & Bartak,
2010; Coles, Coles, Fox, & Long, 2013). So far, however, progress in heuristic-search classical
planning with numeric state variables has mostly been achieved around direct extensions
of delete relaxation heuristics via numeric relaxed planning graphs (Hoffmann, 2003;
Edelkamp, 2003; Gerevini et al., 2003, 2008). Unfortunately, these heuristics do not preserve
information on consumable resources such as budgeted operator cost in oversubscription
4. BFBB is also extensively used for net-benefit planning (Benton, van den Briel, & Kambhampati, 2007;
Coles & Coles, 2011; Do, Benton, van den Briel, & Kambhampati, 2007), as well as some other variants
of deterministic planning (Bonet & Geffner, 2008; Brafman & Chernyavsky, 2005).

106

fiOn Oversubscription Planning as Heuristic Search

planning: the negative action effects that decrease the values of numeric variables are
ignored, possibly up to some special handling of so-called cyclic resource transfer (Coles
et al., 2013).
As a first step in overcoming the lack of effective heuristics for OSP, in the next section
we study abstractions for OSP, from their very definition and properties, to the prospects
of deriving admissible abstraction heuristics. In Section 5 we then study the prospects of
adapting to OSP the toolbox of logical landmarks for goal reachability. To date, abstractions
and landmarks are responsible for most state-of-the-art admissible heuristics for classical
planning, and thus are of special interest here.

3. Abstractions
The term abstraction is usually associated with simplifying the original model, factoring
out details less crucial in the given context. Context determines which details can be reduced, which should better preserved, and how the abstraction is created and used (Cousot
& Cousot, 1992; Clarke, Grumberg, & Peled, 1999; Helmert et al., 2014; Domshlak, Hoffmann, & Sabharwal, 2009; Katz & Domshlak, 2010b). In general terms, abstracting a model
M corresponds to associating it with a set of (typically computationally more attractive)
models M1 , . . . , Mk such that solutions to these models satisfy certain properties with respect to the solutions of M . In particular, in deterministic planning as heuristic search,
abstractions are used to derive heuristic estimates for the states of the model of interest M :
Given a state s of M and an abstraction M1 , . . . , Mk ,
(1) s is mapped to some abstract states s1  M1 , . . . , sk  Mk ,
(2) the k models of the abstraction are solved for the respective initial states s1 , . . . , sk ,
and
(3) an aggregation of the quality of the resulting k solutions is used as the heuristic estimate
for s.
Sometimes schematically and sometimes precisely, the process of constructing abstractions as above for a state model M = hS, s0 , u, O, , c, Qi can be seen as a two-step process
of
(1) selecting an abstraction skeleton AS = {(G1 , 1 ), . . . , (Gk , k )}, where each pair
(Gi , i ) comprises an edge-labeled digraph Gi = hSi , Ti , Oi i, with nodes Si , edges Ti ,
and edge labels Oi , and a state mapping i : S  Si , and
(2) extending AS to a set of abstract models M = {M1 , . . . , Mk }, such that, for i  [k],
Gi is the graphical skeleton GMi of Mi .
To qualify as a valid abstraction of the model M , the resulting set of abstract models
M should satisfy certain conditions specific to the variant of the deterministic planning
under consideration. For instance, the optimal solutions of abstract models in classical
planning are required to be at most as costly as the respective solutions in the original
models, with that constraint to be satisfied by individual abstract models in case of maxaggregation (Pearl, 1984), or by the k abstract models jointly, in case of additive abstractions (Yang, Culberson, Holte, Zahavi, & Felner, 2008; Katz & Domshlak, 2010b). As we
107

fiDomshlak & Mirkis

now show, the concept of abstractions in general, and additive abstractions in particular, is
very different in OSP, and, for better or for worse, has many more degrees of freedom than
the respective concepts in classical planning.
3.1 Abstractions of OSP Problems
Given
an abstraction


ff skeleton AS = {(G1 , 1 ), . . . , (Gk , k )} for an OSP state model M =
S, s0 , u, O, , c, Qb , each digraph Gi = hSi , Ti , Oi i implicitly defines a set of OSP state
models consistent with it. This set is given by Ci  Ui  Bi , where Ci is the set of all
functions from operators Oi to R0+ , Ui is the set of all functions from states Si to R0+ ,
and Bi = R0+ . In these terms, each point (c, u, b)  Ci  Ui  Bi induces an OSP model
consistent with Gi , and vice versa.
Connecting between these sets of models for all the digraphs in AS, let
C = C1      Ck ,
U = U1      Uk ,
B = B1      Bk .
For each state s  M , every point (c, u, b)  C  U  B induces a set of models
n
o
(c,u,b)
(c,u,b)
M(c,u,b) = M1
, . . . , Mk
,
(c,u,b)

with Mi



ff
= Si , i (s0 ), u[i], Oi , i , c[i], Qb[i] :

 the states Si and operators Oi correspond to the nodes and edge labels of Gi ;
 the transition function i (s, o) = s0 iff Ti contains an arc from s to s0 labeled with
o  Oi ;
 the initial state i (s0 ) is determined by the initial state s0 and the state mapping i ;
and
 the operator cost function, state value function, and cost budget are all directly determined by the choice of (c, u, b).
For some choices (c, u, b) from C  U  B, the induced sets of models M(c,u,b) can be
used for deriving admissible estimates for the state of interest s0 , while others cannot. The
respective qualification is defined below.
Definition
 1 (Additive OSP
ff Abstraction)
Let M = S, s0 , u, O, , c, Qb be an OSP model and AS = {(G1 , 1 ), . . . , (G1 , k )} be
an abstraction skeleton for M . For (c, u, b)  C  U  B, M(c,u,b) is an (additive)
abstraction for M , denoted as
M(c,u,b) AAS M,
if and only if
def

h (s0 , b)  hM(c,u,b) (s0 , b) =

X

hi (i (s0 ), b[i]),

i[k]

that is, when hM(c,u,b) (s0 , b) is an admissible estimate of h (s0 , b).
108

fiOn Oversubscription Planning as Heuristic Search

GM

= s1
o1 |||
||
||
/ s2
s0
o2

o3

/ s3

G1

G2

s
= 2;1
o1 zz
z
zz
zz

o1

o5
o4

/ s4

s1;0

o2

/ s1;2

(a)

o4

/ s 1;4

s2;0

o2

o3

/ s2;3
o5



/ s2;4

(b)
Figure 4: Illustration for our running example

In simple terms, a set of models forms an additive OSP abstraction if jointly the models
in it do not underestimate the value that can be obtained from the initial state, within the
5 For example, let G
given cost budget.
4a be the graphical skeleton of a state
M in Figure ff


model M = {s0 , . . . , s4 }, s0 , u, {o1 , . . . , o5 }, , c, Qb , with c(oi ) = 1 for all operators oi ,
b = 2, and u(si ) = 1{4} (i). Let AS = {(G1 , 1 ), (G2 , 2 )} be an abstraction skeleton for
M , with G1 and G2 as in Figure 4b and with state mappings
(
s1;4 , i  {1, 3}
1 (si ) =
,
s1;i , otherwise
(
s2;4 , i = 2
2 (si ) =
.
s2;i , otherwise
Consider a set of models M(c,u,b) , with constant c[1]() = c[2]() = 1, b[1] = b[2] = 2, and,
for j  [2], u[i](si;j ) = 1{4} (j). The optimal plan s0 -plan for M is  = h(s0 , o2 , s2 ), (s2 , o4 , s4 )i,
(c,u,b)

with Qb () = 1, while the optimal 1 (s0 )-plan for M1
is 1 = h(s1;0 , o1 , s1;4 )i, with
(c,u,b)
b[1]
Q (1 ) = 1, and the optimal 2 (s0 )-plan for M2
is 2 = h(s2;0 , o2 , s2;4 )i, with
Qb[2] (2 ) = 1. Since
h (s0 , b) = Qb ()  Qb[1] (1 ) + Qb[2] (2 ) = h1 (1 (s0 ), b[1]) + h2 (2 (s0 ), b[2]),
M(c,u,b) is an additive abstraction for M .
Theorem 1 For any OSP task  = hV, s0 , u; O, c, bi, any abstraction skeleton AS =
{(G1 , 1 ), . . . , (Gk , k )} of M , and any M AAS M , if the digraphs of AS are given
explicitly, then hM (s0 , b) can be computed in time polynomial in |||| and ||M||.


ff
Proof: Let M = {Mi }i[k] , with Mi = Si , i (s0 ), ui , Oi , i , ci , Qbi , be an additive abstraction for M on the basis of AS. For i  [k], let Si0 = {s  Si | ci (i (s0 ), s)  bi }. Since
5. In optimal classical planning, the requirement for the abstraction to not overestimate the costs is typically
posed for all the states of the original model, not just for the initial state (Yang et al., 2008; Katz &
Domshlak, 2010b; Helmert et al., 2014). This extra requirement, however, is for pragmatic reasons of
efficiency as it allows the abstraction to be computed in preprocessing and not individually for every
state examined by the search. Heuristics for OSP, however, are functions not only of the state but also
of the available cost budget, and the latter directly applies to the initial (aka current) state only. In
sum, while defining abstractions with respect to the entire state space is not a necessity in classical
planning, in OSP it is not even clear whether defining abstractions with respect to a specific pair of a
state and a budget can deliver any practical benefits. This should not, however, be interpreted as a
formal impossibility claim, and further investigation in this direction is definitely worthwhile.

109

fiDomshlak & Mirkis

(, , )

SSSS
kk
SS
kkkk
(, u, )
SSSSkk (c, , ) SSSSkk (, , b)
kkkkSS
kkkkSS
(c, u, )

(, u, b)
(c, , b)
SSS
SSS
kkk
kkk
(c, u, b)

Figure 5: Fragments of restricted optimization over the abstractions A  C  U  B
the digraphs of AS are given explicitly, shortest paths from i (s0 ) to all states in Gi (and
thus, in particular, determining Si0 ) can be computed in time polynomial
in ||M|| for all
P
i  [k]. In turn, since hi (i (s0 ), bi ) = maxsSi0 ui (s), hM (s0 , b) = i[k] hi (i (s0 ), bi ) can
be computed in time polynomial in ||M||.

The message of Theorem 1 is positive, yet it establishes only a necessary condition for
the relevance of OSP abstractions in practice. Given an OSP task , and having fixed an
abstraction skeleton AS with a joint performance measure space C  U  B, we should
be able to automatically separate between those (c, u, b)  C  U  B that constitute
abstractions for M and those that do not, and within the former set, denoted as
A  C  U  B,
home in on an abstraction that provides us with as accurate (aka as low) an estimate of
h (s0 , b) as possible. Here, even the first item on the agenda is not necessarily trivial as,
in general, A seems to lack convenient combinatorial properties. For instance, generally
A does not form a combinatorial rectangle in C  U  B: Consider the OSP state model
GM and abstraction skeleton AS from our running example. Let c  C be a cost function
vector with both c[1] and c[2] being constant functions with value of 1, and two performance
measures (c, u, b), (c, u0 , b0 )  CUB defined via budget vectors b = {b[1] = 2, b[2] = 0}
and b0 = {b0 [1] = 0, b0 [2] = 2}, and value function vectors u and u0 , with u[1], u[2], u0 [1],
and u0 [2] evaluating to zero on all states except for u[1](s1;4 ) = u0 [2](s2;4 ) = 1. It is not
0 0
hard to verify that both M(c,u,b) AAS M and M(c,u ,b ) AAS M : In M(c,u,b) , the state
(c,u,b)
s1;4 with u[1](s1;4 ) = 1 is reachable in M1
from s1;0 = 1 (s0 ) under b[1] = 2, while
0
0
(c,u0 ,b0 )
(c,u
,b
)
0
in M
, the state s2;4 with u [2](s2;4 ) = 1 is reachable in M2
from s2;0 = 2 (s0 )
0
0
under b0 [2] = 2. In contrast, both M(c,u ,b) 6AAS M and M(c,u,b ) 6AAS M : In both sets
of models, each model either comes with no budget (and the initial state in the model has
0
the value of zero), or has no states with non-zero value at all. Hence, both M(c,u ,b) and
0
M(c,u,b ) will estimate h (s0 , b) as zero, while h (s0 , b) = 1.
In light of the above, we approach the overall agenda of complexity analysis of abstractionbased heuristic functions in steps, under different fixations of some of the three dimensions
of A: If, for instance, we are given a vector of value functions u that is known to belong to
the projection of A on U, then we can search for a quality abstraction from the abstraction
subset A(, u, )  A, corresponding to the projection of A on {u}. As we show below,
even some constrained optimizations of this kind can be challenging. The lattice in Figure 5 depicts the range of options for such constrained optimization; at the extreme settings,
110

fiOn Oversubscription Planning as Heuristic Search

o1

G1

G2

: s2;1
uu
u
u
uu

o3

/ s2;3

o1

s1;0

o2

/ s1;2

o4

/ s 1;4
j

s2;0

o3 ,o5

o2



o5

/ s2;4
j

o4

Figure 6: Homomorphic abstraction skeleton for G() in Figure 4
A(, , ) is simply a renaming of A, and A(c, u, b) corresponds to a single abstraction
M(c,u,b)  A.
3.2 Partitions and Homomorphic Abstractions
We now proceed to consider a specific family of additive abstractions, reveal some of its
interesting properties, and show that it contains substantial islands of tractability. With
Definition 1 allowing for very general abstraction skeletons, in this work we focus on homomorphic abstraction skeletons6 (Helmert et al., 2014).
Definition 
2 An abstraction skeleton
AS = {(G1 , 1 ), . . . , (Gk , k )} for an OSP state
ff
model M = S, s0 , u, O, , c, Qb is homomorphic if, for i  [k], Oi = O, and (s, o) = s0
only if (i (s), o, i (s0 ))  Ti .
For instance, in our running example, the abstraction skeleton in Figure 4b is not homomorphic (since, e.g., (s1 , o3 , s3 )  GM yet (1 (s1 ), o3 , 1 (s3 )) = (s1;4 , o3 , s1;4 ) 6 GM1 ), while
the abstraction skeleton in Figure 6 is homomorphic. Furthermore, we focus on a fragment
of additive abstractions
Ap = A  [Cp  Up  Bp ] ,
where Cp  C, Up  U, and Bp  B correspond to cost, value, and budget partitions,
respectively.


ff
Definition 3 Given an OSP state model M = S, s0 , u, O, , c, Qb , and a homomorphic
abstraction skeleton AS = {(G1 , 1 ), . . . , (Gk , k )} for M with a joint performance measure
C  U  B,
P
 c  C is a cost partition iff, for each operator o  O, i[k] c[i](o)  c(o);
P
 u  U is a value partition iff, for each state s  S, i[k] u[i](i (s))  u(s); and
P
 b  B is a budget partition iff, i[k] b[i]  b.
In what follows, for any node x of the lattice in Figure 5, by Ap (x) we refer to A(x)Ap ;
e.g., Ap (, u, ) = A(, u, )  Ap .
We begin our analysis of Ap by establishing an interesting completeness relationship
between the sets Cp and Bp , as well as an even stronger individual completeness of Cp and
Bp . Formulated in Theorem 2, these properties of Ap play a key role in our computational
analysis later on.
6. All the results also hold verbatim for the more general labeled paths preserving abstraction skeletons
studied by Katz and Domshlak (2010b) in the context of optimal classical planning. However, the
presentation is somewhat more accessible when restricted to homomorphic abstraction skeletons.

111

fiDomshlak & Mirkis

c

Cp

b

Bp

Up

(1)

b

c

Bp

Cp

Up

(2)

Figure 7: Illustration for sub-claims (1) and (2) of Theorem 2: In (1), the gray ellipse
within Bp stands for the subset of budget partitions b that pair with c in some
abstraction, that is, Ap (c, , b) 6= . However, while pairing some of these budget
partitions b with c requires then a careful selection of a value partition u (so that
M(c,u,b) will be an abstraction), there exists some budget partition b for which
any choice of u will do the job.

Theorem 2 Given an OSP task  = hV, s0 , u; O, c, bi and a homomorphic abstraction
skeleton AS = {(G1 , 1 ), . . . , (Gk , k )} of M ,
(1) for each cost partition c  Cp , there exists a budget partition b  Bp such that

M(c,u,b ) As AS for all value partitions u  Up ;

(2) for each budget partition b  Bp , there exists a cost partition c  Cp such that

M(c ,u,b) As AS for all value partitions u  Up .
The proof of Theorem 2 appears in Appendix A, p. 145. Figure 7 illustrates the statement of sub-claim (1) of Theorem 2, as well as, indirectly, some of its corollaries.7 The first
corollary of Theorem 2 is that the projections of Ap on Cp , Up , and Bp are the entire sets
Cp , Up , and Bp , respectively. That is, any cost partition c (and similarly, any budget partition and any value partition) can be matched with an abstraction that has that partition
as its component. Second, while not any budget partition b can be paired with a given cost
partition c in abstractions for M , that is, not for all b  Bp , Ap (c, , b) 6= , there are
always some budget partitions that can be paired with c. Finally, while pairing some of
these c-compatible budget partitions b with c requires then a careful selection of a value
partition u, there exists some c-compatible budget partition b for which any choice of
u will result in M(c,u,b) being an abstraction of M .
A priori, these properties of Ap should simplify the task of abstraction discovery and
optimization within the space of partitions Cp  Up  Bp , and later we show that this is
indeed the case. However, complexity analysis of abstraction discovery within Cp Up Bp
in most general terms is still problematic because the OSP formalism is parametric in
7. The respective illustration of sub-claim (2) of Theorem 2 is completely similar, mutatis mutandis.

112

fiOn Oversubscription Planning as Heuristic Search

the representation of value functions. Hence, here we proceed with examining abstraction
discovery for OSP in the context of fixed value partitions u  Up .

4. From Value Partitions to Complete Abstractions
Let  be an OSP task, AS be an explicitly given homomorphic abstraction skeleton of M ,
and u  Up be a value partition over AS. An immediate corollary of Theorem 2 is that
Ap (, u, ) is not empty, and thus we can try computing min(c,u,b)Ap (,u,) hM(c,u,b) (s0 ).
As of yet, however, we do not know whether this task is polynomial-time solvable for any
non-trivial class of value partitions. In fact, although Ap (, u, ) is known, by Theorem 2,
to be non-empty, and so, too, are all of its subsets Ap (, u, b) and Ap (c, u, ), finding even
just any abstraction (c, u, b)  Ap (, u, ) is not necessarily easy.
4.1 0-Binary Value Partitions
As a first step, we now examine abstraction discovery within a fragment of Ap in which all
value functions u[i] of the abstract models are what we call 0-binary. Later, in Section 4.2,
we show how our findings for 0-binary abstract value functions can be extended to general
value partitions.
Definition 4 A real-valued function f is called 0-binary if the codomain of f is {0, } for
some   R+ . A set F of 0-binary functions is called strong if all the functions in F have
the same codomain {0, }.
On the one hand, 0-binary functions constitute a rather basic family of value functions.
Hence, if abstraction optimization is hard for them, it is likely to be hard for any nontrivial family of abstract value functions. On the other hand, 0-binary abstract value
functions seem to fit well abstractions of planning tasks in which value functions are linear
combinations of indicators, each representing achievement of a goal value for some state
variable.
In that respect, our first tractability results are for abstraction discovery in Ap (, u, )
where u is a strong 0-binary value partition. The first (and the simpler) result in Theorem 3
further assumes a fixed action cost partition, while the next result, in Theorem 7, is on
simultaneous selection of admissible pairs of cost and budget partitions. In Corollary 4 and
Theorem 10 we then show how the results of Theorem 3 and Theorem 7, respectively, can
be extended to pseudo-polynomial algorithms for general 0-binary value partitions.
4.1.1 Strong 0-Binary Value Partitions and the Knapsack problem
Our first tractability result is for abstraction discovery within Ap (c, u, ) where u is a strong
0-binary value partition and c is an arbitrary cost partition. The key role here is played by
the well-known
Knapsackffproblem (Dantzig, 1930; Kellerer, Pferschy, & Pisinger, 2004). An


instance {wi , i }i[n] , W of the Knapsack problem is given by a weight allowance W and
a set of objects [n], with each object i  [n] being annotated
i .
Pwith a weight wi and a value
0  [n]
The objective
is
to
find
a
subset
Z

[n]
that
maximizes

over
all
subsets
Z
iZ i
P
with
w

W.
By
strict
Knapsack
we
refer
to
a
variant of Knapsack in which
0
i
iZ
that inequality constraint is strict. Knapsack is NP-hard (Karp, 1972; Garey & Johnson,
113

fiDomshlak & Mirkis

1978), but there exist pseudo-polynomial algorithms for it that run in time polynomial in the
description of the problem and in the unary representation of W (Dudzinski & Walukiewicz,
1987). The latter property makes solving Knapsack practical in many applications where the
ratio minWi wi is reasonably low. Likewise, if i = j for all i, j  [n], then a greedy algorithm
solves the problem in linear time by iteratively expanding Z by one of the weight-wise
lightest objects in [n] \ Z, until Z cannot be expanded any further within W .
Theorem 3 (Ap (c, u, ) & strong 0-binary u)
Let  = hV, s0 , u; O, c, bi be an OSP task, AS be an explicit homomorphic abstraction skeleton of M , and u  Up be a strong 0-binary value partition. Given a cost partition c  Cp ,
finding an abstraction (c, u, b)  Ap (c, u, ) and computing the corresponding heuristic
estimate hM(c,u,b) (s0 , b) can be done in time polynomial in |||| and ||AS||.
Proof: The proof is by reduction to the polynomial fragment of the Knapsack problem
corresponding to all items having identical value. Let AS = {(G1 , 1 ), . . . , (Gk , k )}, and,
given that u is a strong 0-binary value partition, let the codomain of all u[i] be {0, } for
some   R+ .
For i  [k], let wi be the cost of the cheapest path in Gi from i (s0 ) to (one of the)
states s  Si with u[i](s) = . Since AS is an explicit abstraction skeleton, the set {wi }i[k]
can be computed in time polynomial in ||AS|| using one of the standard algorithms
for the


ff
single-source shortest paths problem. Consider now a Knapsack problem {wi , }i[k] , b ,
with weights wi being as above and value  being identical for all objects. Let Z  [k]
be a solution to that (optimization) Knapsack problem; recall that it is computable in
polynomial time. Given that, we define budget profile b  B as follows:
(
wi , i  Z
for i  [k], b [i] =
0,
otherwise.
What remains to be shown is that (c, u, b ) actually induces an additive abstraction

for M . Assume to the contrary that M(c,u,b ) 6AAS M , and let  be an optimal s0 -plan
for . By the construction of our Knapsack problem and of b , for each i  Z, there is

(c,u,b )
a i (s)-plan P
with Qb [i] (i ) = . By Definition 1, our assumption implies
i for Mi

that Qb () > iZ Qb [i] (i ) =   |Z|. However, by Theorem 2, there exists at least one
budget partition b  Bp such that M(c,u,b) AAS M . Note that this budget partition
induces aP
feasible solution Z 0 = {i | wi  b[i]} for our Knapsack problem, satisfying
Qb ()  iZ 0 Qb[i] (i ) =   |Z 0 |. This, however, implies |Z| < |Z 0 |, contradicting the

optimality of Z, and thus accomplishing the proof that M(c,u,b ) AAS M .

The construction in the proof of Theorem 3 may appear somewhat counterintuitive:
while we are interested in minimizing the heuristic estimate of h (s0 , b), the abstraction

M(c,u,b ) is selected via the value-maximizing Knapsack problem. Indeed, while ultimately
we would like to obtain
min
hM(c,u,b) (s0 , b),
(6)
b : (c,u,b)Ap

the heuristic we manage to compute in polynomial time is actually
max
b : (c,u,b)Ap

hM(c,u,b) (s0 , b).
114

(7)

fiOn Oversubscription Planning as Heuristic Search

At the same time, note that, for a fixed pair of c  Cp and u  Up , this estimate in Eq. 7 is
still at least as (and possibly much more) accurate as the estimate that would be obtained
by providing each of the k abstract models with the entire budget b. Later we show that
this superior accuracy is verified in our experiments, but first we proceed with examining
working with general 0-binary value partitions.
While strong 0-binary value partitions are rather restrictive, finding an element of
Ap (c, u, ) for general 0-binary u is no longer polynomiala reduction from Knapsack
is straightforward. However, Knapsack is solvable in pseudo-polynomial time, and plugging
that Knapsack algorithm into the proof of Theorem 3 results in a search algorithm for
Ap (c, u, ) with general 0-binary u.
Corollary 4 (Ap (c, u, ) & 0-binary u)
Let  = hV, s0 , u; O, c, bi be an OSP task, AS be an explicit homomorphic abstraction skeleton of M , and u  Up be a 0-binary value partition. Given a cost partition c  Cp , finding
an abstraction (c, u, b)  Ap (c, u, ) and computing the corresponding heuristic estimate
hM(c,u,b) (s0 , b) can be done in time polynomial in ||||, ||AS||, and the unary representation
of the budget b of .
To test and illustrate the value that additive abstractions can bring to heuristic-search
OSP, we implemented a prototype heuristic-search OSP solver8 on top of the Fast Downward
planner (Helmert, 2006). Since, unlike classical and net-benefit planning, OSP still lacks
a standard suite of benchmarks for comparative evaluation, we have cast in this role the
STRIPS classical planning tasks from the International Planning Competitions (IPC) 19982006. This translation to OSP was done by associating a separate unit-value with each
proposition in the conjunctive goal of the corresponding classical IPC task.
Within our prototype, we implemented the BFBB search for OSP, and provided support
for some basic pattern-database abstraction skeletons, action cost partitions, and abstraction selection in Ap (c, u, ) for strong 0-binary value partitions as in the proof of Theorem 3.
Specifically, for a task with k sub-goals:
(i) The abstraction skeleton comprised a set of k projections of the planning task onto
connected subsets of ancestors of the respective k goal variables in the causal graph.
The size of each projection was limited to 1000 abstract states, and the ancestors of
the goal variable v were added to the corresponding projection (initialized to contain
v) in a breadth-first manner, from v back along the arcs of the causal graph, until the
abstraction could not be expanded within the aforementioned size limit.
(ii) The value partition u associated the entire value of each sub-goal hv/di (only) with
the projection associated with v.
(iii) The cost partition c distributed the cost of each operator o uniformly between all the
projections that did not invalidate o, i.e., that reflected at least one state variable
affected by o.
In our evaluation, we compared BFBB node expansions with three heuristic functions,
tagged blind, basic, and hM . With all three heuristics, the h-value of a node n is set to 0
if the cost budget at n is over-consumed. If the cost budget is not over-consumed, then:
8. We are not aware of any other domain-independent planner for optimal OSP.

115

fiDomshlak & Mirkis

airport (25)
blocks (23)
depot (3)
driverlog (12)
freecell (5)
grid (2)
gripper (6)
logistics (10)
miconic (50)
mystery (4)
openstacks (7)
rovers (10)
satellite (9)
tpp (7)
trucks (9)
pipesw-t (12)
pipesw-nt (7)
psr-small (30)
zenotravel (10)
total

hM
23
23
3
12
5
2
6
10
50
4
7
10
9
7
9
12
7
30
10
239

25%
basic
23
23
3
12
5
2
6
10
50
4
7
10
8
7
9
12
7
30
10
238

blind
23
23
3
12
5
2
6
10
50
4
7
10
8
7
9
12
7
30
10
238

hM
20
23
3
12
5
2
6
10
50
4
7
10
7
7
9
12
7
30
10
234

50%
basic
20
23
3
12
5
2
6
10
50
4
7
7
6
7
8
12
7
30
9
228

blind
20
23
3
11
5
2
6
10
50
4
7
7
6
7
8
12
7
30
8
226

hM
19
22
3
11
5
2
6
10
50
4
7
7
6
6
6
12
7
30
9
222

75%
basic
20
18
3
9
5
2
6
10
50
4
7
6
4
6
5
11
7
30
8
211

blind
18
17
3
9
5
2
6
10
50
4
7
6
5
6
5
11
7
30
8
209

hM
19
17
3
10
5
1
6
10
50
3
7
6
5
6
5
11
7
30
8
209

100%
basic
20
17
2
7
5
1
6
10
45
3
7
5
4
5
5
10
6
30
7
195

blind
18
17
2
6
5
1
6
10
45
2
7
5
4
5
5
10
6
30
7
191

Table 1: Number of problems solved across the different budgets using the OPEN list ordered by the heuristic evaluation as in Figure 3

 Blind BFBB constitutes a trivial baseline in which h(n) is simply set to the total value
of all goals.
 In basic BFBB, h(n) is set to the total value of goals, each of which can be individually
achieved within the respective projection abstraction (see Theorem 1) given the entire
remaining budget.
 hM is an additive abstraction heuristic that is selected from Ap (c, u, ) as in the
proof of Theorem 3.
The evaluation contained all the planning tasks for which we could determine offline
the minimal cost budget needed to achieve all the goals. Each such task was approached
under four different budgets, corresponding to 25%, 50%, 75%, and 100% of the minimal
cost needed to achieve all the goals in the task, and each run was restricted to 10 minutes.
Table 1 shows the number of tasks solved within each domain for each level of cost budget.9
Figure 8 depicts the results in terms of expanded nodes across the four levels of cost budget.
(Figures 18-21 in Appendix B provide a more detailed view of the results in Figure 8 by
breaking them down into different levels of cost budget.) Despite the simplicity of the
abstraction skeletons we used, the number of nodes expanded by BFBB with hM was
typically substantially lower than the number of nodes expanded by basic BFBB, with the
difference sometimes reaching three orders of magnitude.
9. We reiterate that a task is considered solved only upon the termination of BFBB, that is, when an
optimal plan is found and proven to be optimal.

116

fiOn Oversubscription Planning as Heuristic Search

(a)
108

unsolved

107
106
105
hM

104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
blind

(b)
108

unsolved

107
106
hM

105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
basic

Figure 8: Comparative view of empirical results from Table 1 in terms of expanded nodes

4.1.2 Freeing Cost Partition: Knapsack Meets Convex Optimization
Returning now to the algorithmic analysis in the context of strong 0-binary value partitions,
we now proceed with relaxing the constraint of sticking to a fixed action cost partition c.
This buys more flexibility in selecting abstractions from Ap (, u, ), allowing us to improve
the accuracy of the heuristic estimates, while still retaining computational tractability.
117

fiDomshlak & Mirkis

input:  = hV, s0 , u; O, c, bi, AS = {(G1 , 1 ), . . . , (Gk , k )} of M ,
strong 0-binary value partition u  Up
output: (u)
for i = 1 to k do
reduce Gi to only nodes reachable from i (s0 )
for m = k downto 1 do
if always-achievable(m) then return m
return 0
always-achievable(m):
m
ellipsoid-method(separation-oracle-Lm
1 ) 7 solution x  dom(X ) to L1
if x[]  b then return true
else return false
(a)
separation-oracle-Lm
1 (x  dom(X )):
let  be a permutation of [k] such that
x[b[
P(1)]]  x[b[ (2)]]      x[b[ (k)]]
if x[]  i[m] x[b[ (i)]] then return Yes
P
else return constraint   i[m] b[ (i)]
(b)
Figure 9: A polynomial-time algorithm for computing (u) for a strong 0-binary value
partition u  Up (Theorem 7)

Given an OSP task  = hV, s0 , u; O, c, bi, a homomorphic abstraction skeleton AS, and
a value partition u  Up over AS, let


(u) = min
max
(8)
hM(c,u,b) (s0 , b) .
cCp

b : (c,u,b)Ap

Obviously, the estimate h(s0 , b) = (u) is at least as accurate as the estimate in Eq. 7 that
is derived with respect to a fixed cost partition c.
We now show that, for any OSP task , any abstraction skeleton AS = {(G1 , 1 ), . . . ,
(Gk , k )} of M , and any strong 0-binary value partition u  Up over AS, (u) can be
computed in polynomial time. The corresponding algorithm is shown in Figure 9, with
Figure 9a depicting the macro-flow of the algorithm and Figure 9b depicting the specific
implementation of the solve sub-routine that makes the overall time complexity of the
algorithm polynomial.
The high-level flow of the algorithm in Figure 9a is as follows. Since u is a strong 0binary value partition, let the codomain of all the abstract value functions u[i] be {0, } for
some   R+ . Given that, for each (c, u, b)  Ap (, u, ), it holds that hM(c,u,b) (s) = m
for some m  {0}  [k]. This is because each of the k abstract models in M(c,u,b) can
contribute to the additive estimate hM(c,u,b) (s) either  or 0.
118

fiOn Oversubscription Planning as Heuristic Search

The first loop of the algorithm is a preprocessing for-loop that eliminates from the
abstraction skeleton all the nodes that are structurally unreachable from the abstract initial
states 1 (s0 ), . . . , k (s0 ).10 For ease of presentation, in what follows we assume that this
cleanup of the abstraction skeleton leaves each Gi with at least one state whose value is
. The second for-loop of the algorithm decreasingly iterates over all the values {k, (k 
1), . . . , 2, } that can possibly come from the abstractions in Ap (, u, ) as a positive
estimate of h (s0 , b). Each of these candidates for (u) is tested in turn via the sub-routine
always-achievable. If and when this test returns positive for the first time, then we are done,
and the tested candidate m is identified as (u). Otherwise, if the test fails for all m  [k],
then (u) = 0, in particular implying that no state with value greater than 0 can be reached
from s0 under budget b.
The test of always-achievable for (u) = m is based on a linear program (LP) Lm
1 , given
by Eq. 10. This linear program is defined over variables
#
"
[
[
(9)
{c[i](o)} ,
X = {} 
{d(s)}sGi  {b[i]} 
oO

i[k]

constraints (10a)-(10c), and the objective of maximizing the value of the variable .
Lm
1 :
max 
subject to


d(i (s0 )) = 0,
i  [k] : d(s)  d(s0 ) + c[i](o), (s0 , o, s)  Gi
,


b[i]  d(s),
s  Gi s.t. u[i](s) = 
(
c[i](o)  0,
i  [k]
o  O : P
,
i[k] c[i](o)  c(o)
X
Z  [k], |Z| = m :  
b[i].

(10a)

(10b)
(10c)

iZ

The roles of the different variables in Lm
1 are as follows.
 Variable c[i](o) captures the cost to be associated with label o in the digraph Gi of
AS.
 For a state s in Gi , variable d(s) captures the cost of the cheapest path in Gi from
i (s0 ) to s, given that the edges of Gi are weighted consistently with the values of the
variables c[i]().
 Variable b[i] captures the minimal budget needed for reaching in Gi a state with value
 from state i (s0 ), given that, again, the edges of Gi are weighted consistently with
the variable vector c[i].
10. This preprocessing step can be replaced by adding some extra constraints in the linear program described
below. However, that would unnecessarily complicate the presentation without adding much value.

119

fiDomshlak & Mirkis

 The singleton variable  captures the minimal total cost of reaching states with value
 in precisely m out of k models in M(c,u,b) .
The semantics of the constraints in Lm
1 are as follows.
 The first two sets of constraints in (10a) come from a simple LP formulation of
the
P single
P source shortest paths problem with the source node i (s0 ): Optimizing
i[k]
sGi d(s) under a fixed weighting c of the edges leads to computing precisely
that, for all k digraphs in AS simultaneously.
 The third set of constraints in (10a) establishes the costs of the cheapest paths in {Gi }
from states i (s0 ) to states valued , enforcing the semantics of variables b[1], . . . , b[k].
 Constraints (10b) are the cost partition constraints that enforce c  Cp .
 Constraints (10c) enforce the aforementioned semantics of the objective variable .
Two things are worth noting here. First, if all the nodes in the digraphs G1 , . . . , Gk
are structurally reachable from the source nodes 1 (s0 ), . . . , k (s0 ), respectively (as it is
m
ensured by the first for-loop of the algorithm), then
S the polytope induced by L1 is bounded
and non-empty. Indeed, for any assignment to oO {c[i](o)} that is consistent with the
positiveness constraints in (10b), all the variables d() are bounded from above by the
lengths of the respective shortest paths. In turn, this bounding of d() bounds from above
the variables c[1], . . . , c[k] via the third set of constraints in (10a), and the constraints (10c)
then bound from above the objective .
Second, while the number of variables, as well as the number of constraints in (10a)
and

k
(10b), are polynomial in |||| and ||AS||, the number of constraints in (10c) is m
. Thus,
solving Lm
1 using standard methods for linear programming is infeasible. In Lemma 5 below
we show that this problem can actually be mitigated, and then, in Lemma 6 we show that
the semantics of Lm
1 match our objective of finding (u).
Lemma 5 The algorithm in Figure 9 terminates in time polynomial in |||| and ||AS||.
Proof: The runtime complexity of the algorithm boils down to the complexity of solving
Lm
1 , and, while the number of variables in L1 (m), as well as the number of constraints in
(10a)
are polynomial in |||| and ||AS||, the number of constraints in (10c) is
 and (10b),
k
m cannot be solved in polynomial time using standard methods for linear
.
Thus,
L
1
m
programming, such as the Simplex algorithm (Dantzig, 1963) or the Interior-Point methods (Nemirovsky & Yudin, 1994). However, using some other algorithms, such as the
Ellipsoid algorithm (Grotschel, Lovasz, & Schrijver, 1981) and the Random Walks family
of algorithms originating in the work of Bertsimas and Vempala (2004), an LP with an
exponential number of constraints can be solved in polynomial time, provided that we have
a polynomial time separation oracle for that LP. A polynomial-time separating oracle for
a convex set K  Rn is a procedure which given x  Rn , either verifies that x  K or
returns a hyperplane separating x from K. The procedure should run in polynomial time.
In our case, the separation problem is, given an assignment to the variables of Lm
1 , to test
whether it satisfies (10a), (10b), and (10c), and if not, produce an inequality among (10a),
(10b), and (10c) violated by that assignment.
120

fiOn Oversubscription Planning as Heuristic Search

We now show how our separation problem for Lm
1 can be solved in polynomial time
using what is called m-sum minimization LPs (Punnen, 1992), and this is precisely what the
(parametrized with m) procedure separation-oracle-Lm
1 in Figure 9b does. As the number of
constraints in (10a) and (10b) is polynomial, their satisfaction by an assignment x  dom(X )
can be tested directly by substitution. For constraints (10c), letP be a permutation of [k]
such that x[b[ (1)]]  x[b[ (2)]]      x[b[ (k)]]. If x[]  i[m] x[b[ (i)]], then it is
easy to see that
Px satisfies all the constraints in (10c). Otherwise, we have our violated
inequality   i[m] b[ (i)].

Lemma 6 The algorithm in Figure 9a computes (u).
The proof of Lemma 6 appears in Appendix A, p. 146. Combining the statements of
Lemmas 5 and 6, Theorem 7 summarizes our tractability result for abstraction discovery in
Ap (, u, ) for strong 0-binary value partitions u.
Theorem 7 (Ap (, u, )(s) & strong 0-binary u)
Given an OSP task  = hV, s0 , u; O, c, bi, a homomorphic explicit abstraction skeleton AS of
M , and a strong 0-binary value partition u  Up , (u) can be computed in time polynomial
in |||| and ||AS||.
Unfortunately, the practical value of the result in Theorem 7 is yet to be evaluated. So
far, we have not found a reasonably efficient implementation of the Ellipsoid method for
linear inequalities, while, to the best of our knowledge, the Random Walks algorithms (Bertsimas & Vempala, 2004) have never been implemented at all. We hope that this state of
affairs will change soon, allowing these powerful algorithms to be used not only in theory,
but also in practice.
4.1.3 From Strong to General 0-Binary Value Partitions
Recall that the polynomial result of Theorem 3 for strong 0-binary value partitions easily
extends in Corollary 4 to a pseudo-polynomial algorithm for general 0-binary value partitions. It turns out that a pseudo-polynomial extension of Theorem 7 is possible as well,
though it is technically more involved. The corresponding algorithm is shown in Figure 10.
Following the format of Figure 9, Figure 10a depicts the macro-flow of the algorithm and
Figure 10b shows the specific implementation of the solve sub-routine by which the desired
time complexity can be achieved.
Similarly to the algorithm in Figure 9, a preprocessing for-loop of the algorithm first
eliminates from the abstraction skeleton all the nodes that are structurally unreachable
from the abstract initial states 1 (s0 ), . . . , k (s0 ). Next, the algorithm performs a binary
search over an interval containing (u).11 Since u is a 0-binary value partition, for i  [k],
by {0, i }, i  R+ , we denote the codomain of the abstract value
P function u[i]. Given that,
for each (c, u, b)  Ap (, u, ), it holds that h(c,u,b) (s) = iZ i for some Z  [k]. As
the size of this combinatorial hypothesis space is prohibitive, the while-loop in Figure 10
performs a binary search over a relaxed hypothesis space, corresponding to the continuous
11. While a binary search could have been used in the algorithm in Figure 9 as well, there it would be a
mere optimization, while here it is necessary to avoid an exponential blowup of the time complexity.

121

fiDomshlak & Mirkis

input:  = hV, s0 , u; O, c, bi, AS = {(G1 , 1 ), . . . , (Gk , k )} of M ,
0-binary value partition u  Up
output: s (u)
for i = 1 to k do
reduce Gi to only nodes reachable from i (s0 )
let 0 <  < mini[k] i
P
0
  i[k] i
while    >  do
v   + (  )/2
if always-achievable(v) then   v
else   v
if  = 0 then return 0
else return 
always-achievable(v):
ellipsoid-method(separation-oracle-Lv2 ) 7 solution x  dom(X ) to Lv2
if x[]  b then return true
else return false
(a)
separation-oracle-Lv2
(x  dom(X )):
ff
strict-Knapsack( {x[b[i]], i }i[k] , x[] ) 7 solution Z  [k]
P
if iZ i < v then return Yes
P
else return constraint   iZ b[i]
(b)
Figure 10: A pseudo-polynomial algorithm for approximating (u) for general 0-binary
value partitions u  Up (Theorem 10)

P
interval [0, i[k] i ] of R+0 . The parameter  serves as the sufficient precision criterion
for termination.
At an iteration corresponding to an interval [, ], the algorithm uses its sub-routine
always-achievable to test the hypothesis (u)  v, where v is the mid-point of [, ]. If the
test is positive, then the next tested hypothesis is s (u)  v 0 , where v 0 is the midpoint
of [v, ]. Otherwise, the next hypothesis corresponds to the midpoint of [, v). When the
while-loop is done, the reported estimate is set to ; while there still might be some lag
between  and (u), this lag can be arbitrarily reduced by reducing , and anyway,   (u)
ensures admissibility of the estimate. If, however, the while-loop terminates with  = 0,
then (u)     < mini[k] i implies (u) = 0, and this is what we return.
The test of always-achievable for (u)  v is based on a linear program Lv2 , which is
defined over variables X as in Eq. 9, and is obtained from Lm
1 by replacing constraints (10c)
with constraints (11c):
122

fiOn Oversubscription Planning as Heuristic Search

Lv2 :
max 
subject to


d(i (s0 )) = 0,
i  [k] : d(s)  d(s0 ) + c[i](o), (s0 , o, s)  Gi
,


b[i]  d(s),
s  Gi s.t. u[i](s) = i
(
c[i](o)  0,
i  [k]
o  O : P
,
i[k] c[i](o)  c(o)
X
X
Z  [k] s.t.
i  v :  
b[i].
iZ

(11a)

(11b)
(11c)

iZ

While the semantics of all variables but  remains as in Lm
1 ,  now captures the minimal
total cost ofPreaching some states {si }i[k] in the abstract models M(c,u,b) such that the
total value i[k] u[i](si )  v. The new constraint (11c) enforces this semantics of .
Lemma 8 For any  > 0, the algorithm in Figure 10 terminates in time polynomial in
||||, ||AS||, log 1 , and a unary representation of the budget b of .
P

i

Proof: The number of iterations of the while-loop is approximately log2 i[k]
, and the

run-time of each of its iterations boils down to the complexity of solving Lv2 . Here, as in
v
Lemma 5 with linear programs Lm
1 , the number of variables in L2 , as well as the number
of constraints in (11a) and (11b), are polynomial in |||| and ||AS||, while the number
of constraints in (11c) is (2k ). Therefore, always-achievable(v) also employs the ellipsoid
method with a sub-routine separation-oracle-Lv2 for the associated separation problem. We
now show how that separation problem for Lv2 can be solved in pseudo-polynomial time
using a standard pseudo-polynomial procedure for the strict Knapsack problem.
Given an assignment x  dom(X ), its feasibility with respect to (11a) and (11b) can be
tested directly by substitution. 
For constraints (11c),
ff let Z  [k] be an optimal solution
to the strict Knapsack problem {x[b[i]], i }i[k] , x[] , with a weight allowance x[] and k
objects, with each object i  [k] being associated with weight x[b[i]] and value i .
P
 If the value iZ i of Z is smaller than v, then x satisfies all the constraints in
(11c). Assume to the contrary that x violatesP
some constraint in (11c), corresponding
0
to a setPZ  [k]. By definition of (11c),
iZ 0 i  v, and by our assumption,
x[] >
x[b[i]].
That,
however,
implies
that Z 0 is a feasible solution for our
0
iZ
strict Knapsack, and of value higher than that of presumably optimal Z.
P
 Otherwise, if iZ i  v, then Z itselfPprovides us with a constraint in (11c) that is
violated by x. This is because x[] > 
iZ x[b[i]] holds by the
ff virtue of Z being a
solution to the strict Knapsack problem {x[b[i]], i }i[k] , x[] .


123

fiDomshlak & Mirkis

Lemma 9 For any 0 <  < mini[k] i , the algorithm in Figure 10a computes  such that
  (u)  .
The proof of Lemma 9 appears in Appendix A, p. 147. Combining the statements of
Lemmas 8 and 9, Theorem 10 summarizes our result for optimized abstraction discovery in
Ap (, u, ) for general 0-binary value partitions u. Importantly, note that the algorithm in
Figure 10 depends on the unary representation of only the budget, and not of the possible
state values. In particular, it means that dependence of the complexity on the number of
alternative sub-goals in the OSP task of interest is only polynomial. Finally, Theorem 10 is
formulated in terms of the estimate precision only because the i values of the abstract value
functions u[i] can be arbitrary real numbers. In the case of integer-valued sets of functions
u, as well as in various special cases of real-valued functions, (u) can be determined
precisely using a simplification of the algorithm in Figure 10. For instance, if all 1 , . . . , k
are integers, then setting  to any value in (0, 1) results in the while-loop terminating with
 = (u). These details, however, are more of a theoretical interest; for reasonably small
values of , in practice there will be no difference between estimates h(s, b) and h(s, b) + .
Theorem 10 (Ap (, u, )(s) & 0-binary u)
Given an OSP task  = hV, s0 , u; O, c, bi, a homomorphic explicit abstraction skeleton AS =
{(G1 , 1 ), . . . , (Gk , k )} of M , a 0-binary value partition u  Up , and  > 0, it is possible
to approximate s (u) within an additive factor of  in time polynomial in ||||, ||AS||, log 1 ,
and a unary representation of the budget b of .
4.2 General Value Partitions
While 0-binary value partitions can be rather useful by themselves, it turns out that the
pseudo-polynomial algorithms for abstraction discovery with explicit homomorphic abstraction skeletons and 0-binary value partitions can be extended rather easily to arbitrary value
partitions, using the following observations:
(1) for any OSP task  = hV, s0 , u; O, c, bi, any homomorphic abstraction skeleton AS =
{(G1 , 1 ), . . . , (Gk , k )} of M , and any value partition u over AS, the number of
distinct values taken by u[i] is trivially upper-bounded by the number of states in Gi ;
and
(2) the pseudo-polynomial solvability of the Knapsack problem extends to its more general
variant known as Multiple-Choice Knapsack (Dudzinski & Walukiewicz, 1987; Kellerer
et al., 2004).
The Multiple-Choice (MC) Knapsack problem hN1 , . . . , Nm ; W i is given by a weight
allowance W and m classes of objects N1 , . . . , Nm , with each object j  Ni being annotated
with a weight wij and a value ij . The objective
is to find a set Z that contains at most
P
one
P object from each class and maximizes (i,j)Z ij over all such sets while satisfying
(i,j)Z wij  W. By strict MC-Knapsack, we refer to a variant of MC-Knapsack in
which that inequality constraint is strict. MC-Knapsack generalizes regular Knapsack and
thus it is NP-hard. However, similarly to the regular Knapsack problem, MC-Knapsack also
admits a pseudo-polynomial, dynamic programming algorithm that runs in time polynomial
124

fiOn Oversubscription Planning as Heuristic Search

in the description of the problem and in the unary representation of W (Dudzinski &
Walukiewicz, 1987; Kellerer et al., 2004).
Theorem 11 (Ap (c, u, ))
Let  = hV, s0 , u; O, c, bi be an OSP task, let AS = {(G1 , 1 ), . . . , (Gk , k )} be an explicit homomorphic abstraction skeleton of M , and let u  Up be an arbitrary value
partition over AS. Given a cost partition c  Cp , it is possible to find an abstraction
(c, u, b)  Ap (c, u, ) and compute the corresponding heuristic estimate hM(c,u,b) (s0 , b) in
time polynomial in ||||, ||AS||, and the unary representation of the budget b.
Proof: The proof is very similar to the proof of Theorem 3, but with the compilation being
to the MC-Knapsack problem.
For i  [k], let ni be the number of distinct values taken by u[i], let {i1 , . . . , ini }  R+
be the codomain of u[i], and, for j  [ni ], let wij be the cost of the cheapest path in Gi from
i (s0 ) to (one of the) states s  Si with u[i](s) = ij . Since AS is an explicit abstraction
skeleton, for i  [k], it holds that ni  |Si |, and the set {wij }i[k],j[ni ] can be computed in
time polynomial in ||AS|| using one of the standard algorithms for the single-source shortest
paths problem.
Consider now an MC-Knapsack problem with a weight allowance b and k classes of
objects N1 , . . . , Nk , with |Ni | = ni and each object j  Ni annotated with a weight wij and
S
a value ij . Let Z  ki=1 Ni be a solution to that (optimization) MC-Knapsack problem;
recall that it is computable in pseudo-polynomial time. Given that, we define budget profile
b  B as follows:
(
wij , (i, j)  Z

for i  [k], b [i] =
0,
otherwise.
Showing that (c, u, b ) actually induces an additive abstraction for M is completely identical to the proof of the corresponding argument in Theorem 3, and thus omitted.

Theorem 12 (Ap (, u, ))
Given an OSP task  = hV, s0 , u; O, c, bi, a homomorphic explicit abstraction skeleton AS =
{(G1 , 1 ), . . . , (Gk , k )} of M , an arbitrary value partition u  Up over AS, and  > 0, it
is possible to approximate s (u) within an additive factor of  in time polynomial in ||||,
||AS||, log 1 , and a unary representation of the budget b of .
An algorithm for abstraction discovery as in Theorem 12 is depicted in Figure 11. Its
high-level flow differs from the flow of the algorithm from Figure 10 for general 0-binary
value partitions only in the initialization of parameters  and . The major difference
between the algorithms is that here the tests of candidate values v are based on linear
programs Lv3 , which are defined as follows.
For i  [k], let {i1 , . . . , ini }  R+ be the codomain of u[i]. For v  R+ , the linear
program Lv3 is defined in Eq. 13 over variables


[
[
[
{d(s)}sGi 
X = {} 
{b[i, j]} 
{c[i](o)}.
(12)
i[k]

j[ni ]

125

oO

fiDomshlak & Mirkis

input:  = hV, s0 , u; O, c, bi, AS = {(G1 , 1 ), . . . , (Gk , k )} of M ,
0-binary value partition u  Up
output: s (u)
for i = 1 to k do
reduce Gi to only nodes reachable from i (s0 )
let 0 <  < mini[k] minj[ni ] ij
P
0
  i[k] maxj[ni ] ij
while    >  do
v   + (  )/2
if always-achievable(v) then   v
else   v
if  = 0 then return 0
else return 
always-achievable(v):
ellipsoid-method(separation-oracle-Lv3 ) 7 solution x  dom(X ) to Lv3
if x[]  b then return true
else return false
(a)
separation-oracle-Lv3 (x 
 dom(X )):
ff
strict-MC-Knapsack( {x[b[1, j]], 1j }j[n1 ] , . . . , {x[b[k, j]], kj }j[nk ] ; x[] )
7 solution Z  [n1 ]      [nk ]
P
if i[k] iZ(i) < v then return Yes
P
else return constraint   i[k] b[i, Z(i)]
(b)
Figure 11: (a) A modification of the algorithm from Figure 10 to arbitrary value partitions
u  Up (Theorem 12), and (b) a pseudo-polynomial time separation oracle for
the corresponding linear programs Lv3 in Eq. 13

These variables differ from the variable set of Lv2 (see Eq. 9) by a larger set of b-variables:
Variable b[i, j] here captures the minimal budget needed for reaching in Gi a state with
value i,j from state i (s0 ), given that the edges of Gi are weighted consistently with the
variable vector c[i].
126

fiOn Oversubscription Planning as Heuristic Search

Lv3 :
max 
subject to


d(i (s0 )) = 0,
i  [k] : d(s)  d(s0 ) + c[i](o), (s0 , o, s)  Gi
,


b[i, j]  d(s),
j  [ni ]s  Gi s.t. u[i](s) = ij
(13a)
(
c[i](o)  0,
i  [k]
o  O : P
,
(13b)
i[k] c[i](o)  c(o)
Z  [n1 ]      [nk ]
X
X
s.t.
iZ(i)  v :  
b[i, Z(i)].
i[k]

(13c)

i[k]

Like what we had in Lemma 8 with linear programs Lv2 , while the number of variables
in Lv3 , as well as the number of constraints in (13a) and (13b), are polynomial in ||||
and ||AS||, the number of constraints in (13c) is (dk ) where d = maxi[k] ni . Therefore,
always-achievable(v) also employs the ellipsoid method with a pseudo-polynomial time separation oracle, but here the latter is based on solving a strict MC-Knapsack problem (see
Figure 11b). Otherwise, solving Lv2 and solving Lv3 are similar.
Lemma 13 For any  > 0, the algorithm in Figure 11 terminates in time polynomial in
||||, ||AS||, log 1 , and a unary representation of the budget b of .
Lemma 14 Given an OSP task  = hV, s0 , u; O, c, bi, a homomorphic explicit abstraction
skeleton AS = {(G1 , 1 ), . . . , (Gk , k )} of M , an arbitrary value partition u  Up over
AS, and  > 0, the algorithm in Figure 11 computes  such that   (u)  .
The proof of Lemma 13 is similar to the proof of Lemma 8, with strict Knapsack
separation problems being replaced with strict MC-Knapsack separation problems. The
proof of Lemma 14 is also similar to the proof of Lemma 9, mutatis mutandis. Together,
Lemmas 14 and 13 establish Theorem 12.

5. Landmarks in OSP
In addition to state-space abstractions, a family of approximation techniques that have been
found extremely effective in the context of optimal classical planning is based on the notion
of logical landmarks for goal reachability (Karpas & Domshlak, 2009; Helmert & Domshlak,
2009; Domshlak et al., 2012; Bonet & Helmert, 2010; Pommerening & Helmert, 2013). In
this section we proceed with examining the prospects of such reachability landmarks in
heuristic-search OSP planning.
127

fiDomshlak & Mirkis

5.1 Landmarks in Classical Planning
For a state s in a classical planning task , a landmark is a property of operator sequences
that is satisfied by all s-plans (Hoffmann, Porteous, & Sebastia, 2004). For instance, a
fact landmark for a state s is an assignment to a single variable that is true at some point
in every s-plan. Most state-of-the-art admissible heuristics for classical planning use what
are called disjunctive action landmarks, each corresponding to a set of operators such
that every s-plan contains at least one operator from that set (Karpas & Domshlak, 2009;
Helmert & Domshlak, 2009; Bonet & Helmert, 2010; Pommerening & Helmert, 2013). In
what follows we consider this popular notion of landmarks, and simply refer to disjunctive
action landmarks for a state s as s-landmarks. For ease of presentation, most of our discussion will take place in the context of landmarks for the initial state of the task, and these
will simply be referred to as landmarks (for ).
Deciding whether an operator set L  O is a landmark for classical planning task  is
PSPACE-hard (Porteous, Sebastia, & Hoffmann, 2001). Therefore, all landmark heuristics
employ landmark discovery methods that are polynomial-time and sound, but incomplete.
In what follows we assume access to such a procedure; the actual way the landmarks are
discovered is tangential to our contribution. For
a landmark cost
P a set L of s-landmarks,

0+
function lcost : L  R is admissible if
LL lcost(L)  h (s). For a singleton set
L = {L}, lcost(L) := minoL c(o) is a natural admissible landmark cost function, and it
extends directly to non-singleton sets of pairwise disjoint landmarks. For more general sets
of landmarks, lcost can be devised in polynomial time via operator cost partitioning (Katz
& Domshlak, 2010b), either given L (Karpas & Domshlak, 2009), or within the actual
process of generating L (Helmert & Domshlak, 2009).
5.2 -Landmarks and Budget Reduction
While landmarks play an important role in (both satisficing and optimal) classical planning,
so far they have not been exploited in OSP. At first glance, this is probably no surprise,
and not only because OSP has been investigated much less than classical planning: Since
landmarks must be satisfied by all plans and because an empty operator sequence is always
a plan for any OSP task, the notion of landmark does not seem useful here. Having said
that, consider the anytime output improvement property of the BFBB forward search.
The empty plan is not interesting there not only because it is useless, but also because it
is found by BFBB right at the very beginning. In general, at all stages of the search,
anytime search algorithms like BFBB maintain the best-so-far solution , and prune all
branches that promise value lower or equal to Qb (). Hence, in principle, such algorithms
may benefit from information about properties that are satisfied by all plans with value
larger than Qb (). Polynomial-time discovery of such value landmarks for arbitrary OSP
tasks is still an open problem. However, looking at what is needed and what is available,
here we show that the classical planning machinery of reachability landmarks actually can
be effectively exploited in OSP.
P In what follows, we assume that the value function of  is additive, with u(s) =
hv/dis uv (d), with uv (d)  0 for all variable-value pairs hv/di. That is, the value of state
s is the sum of the (mutually independent) non-negative marginal values of the propositions
comprising s. With the value of different s-plans in an OSP task  varying between zero
128

fiOn Oversubscription Planning as Heuristic Search

and the value of the optimal s-plan (which may also be zero), let -landmark for state
s be any property that is satisfied by any s-plan  that achieves something valuable. For
instance, with the disjunctive action landmarks we use here, if L  O is an -landmark for
s, then every s-plan  with Qb () > 0 contains an operator from L. In what follows, unless
stated otherwise, we focus on -landmarks for (the initial state of) .
Definition 5 Given an OSP task  = hV, s0 , u; O, c, bi, the -compilation of  is a classical planning task  = hV , s0 , G ; O , c i where
V = V  {g},
with dom(g) = {0, 1},
s0 = s0  {hg/0i},
G = {hg/1i},

	
O = O  Og = O  ohv/di | hv/di  D, uv (d) > 0 ,
with pre(ohv/di ) = {hv/di} and eff(ohv/di ) = {hg/1i},
(
c(),  = o  O
c (o) =
.
0,
 = ohv/di  Og
To put it simply, the semantics of the value hg/1i of the auxiliary variable g in  is
that it has been verified that some proposition with a positive value has been achieved.
In these terms,  simply extends the structure of  with a set of zero-cost actions such
that applying any of them corresponds to verifying that a positive value can be achieved
in . Constructing  from  is trivially polynomial time, and it allows us to discover
-landmarks for  using the standard machinery for classical planning landmark discovery.
Theorem 15 For any OSP task , any landmark L for  such that L  O is an landmark for .
Proof: The proof is rather straightforward. Let P be the set of all plans  for  with
Qb () > 0 and P the set of all plans for  . By the definition of P, for any plan   P,
there exists a proposition hv/di  D such that uv (d) > 0 and hv/di  s0 JK. Likewise, since
s0
 := s0ff {hg/0i} and O  O,  is applicable in

 s0 . ffHence, by definition


ff of ohv/di  O ,
 ohv/di is applicable in s0 and 
hg/1i 
s
J
o
K,
that
is,

o
0
hv/di
hv/di  P . In turn,
ff
if L is a landmark for  , then  ohv/di contains an operator from L, and if L  O, then
 contains an operator from L as well. This proves that all landmarks L for  over the
operators O of  are -landmarks for .

With Theorem 15 in hand, we can now derive -landmarks for  using any method
for classical planning landmark extraction, such as that employed by the LAMA planner (Richter et al., 2008) or the LM-Cut family of techniques (Helmert & Domshlak, 2009;
Bonet & Helmert, 2010). However, at first glance, the discriminative power of knowing
what is needed to achieve something valuable seems to be negligible when it comes to deriving effective heuristic estimates for OSP. The good news is that, in OSP, such information
can be effectively exploited in a slightly different way.
129

fiDomshlak & Mirkis

Consider a schematic example of searching for an optimal plan for an OPS task  with
budget b, using BFBB with an admissible heuristic h. Suppose that there is only one
sequence of (all unit-cost) operators,  = ho1 , o2 , . . . , ob+1 i, applicable in the initial state
of , and that the only positive value state along  is its end-state. While clearly no
value higher than zero can be achieved in  under the given budget of b, the search will
continue beyond the initial state, unless h(s0 , ) counts the cost of all the b + 1 operators
of . Now, suppose that h(s0 , ) counts only the cost of {oi , . . . , ob+1 } for some i > 0, but
{o1 }, {o2 }, . . . , {oi1 } are all discovered to be -landmarks for . Given that, suppose that
we modify  by (a) setting the cost of operators o1 , o2 , . . . , oi1 to zero, and (b) reducing
the budget to b  i + 1. Since all the operators o1 , o2 , . . . , oi1 have to be applied anyway
along any value collecting plan for , this modification seems to preserve the semantics of
. At the same time, on the modified task, BFBB with the same heuristic h will prune the
initial state and thus establish without any search that the empty plan is an optimal plan
for . Of course, the way  is modified in this example is as simplistic as the example itself.
Yet, this example does motivate the idea of landmark-based budget reduction for OSP, as
well as illustrates the basic idea behind the generically sound task modifications that we
discuss next.

Definition 6 Let  = hV, s0 , u; O, c, bi be an OSP task, L = {L1 , . . . , Ln } be a set of
pairwise disjoint -landmarks for , and lcost be an admissible landmark cost function from
L. The budget reducing compilation of  is an OSP task L = hVL , s0L , uL ; OL , cL , bL i
where
n
X
bL = b 
lcost(Li )
(14)
i=1

and
VL = V  {vL1 , . . . , vLn }
with dom(vLi ) = {0, 1},
s0L = s0  {hvL1 /1i , . . . , hvLn /1i},
uL = u,
OL = O 

n
[
i=1

OLi = O 

n
[

{o | o  Li },

i=1

with pre(o) = pre(o)  {hvLi /1i} and eff(o) = eff(o)  {hvLi /0i},
(
c(o),
=oO
cL () =
.
c(o)  lcost(Li ),  = o  OLi
In other words, L extends the structure of  by
 mirroring the operators of each -landmark Li with their cheaper by lcost(Li ) versions,
130

fiOn Oversubscription Planning as Heuristic Search

CBB

o2
o2

o2 o2
ABB

o1
o1

o3
BTB
o6
o3
BBB
o7
o4
BBT
o4

CTB

o4
o7
o4
BTT
o3
o3
o6
o2
CBT
o2

u=1

o5
o9
o5

u=1

CCB

o8
o10
o8
o5
CTT
o9
o5
u=1

o2
o2
o8
o10
o8

CTC

u=1
CCT

o5
u=2
o9
o5
o8
CCC
o10
o8

CBC

(a)
u=1

CBB
CTB

o2
ABB

o1

BBB

BTB
o6
o3
o7
o4
BBT

o2
o7
o4
BTT

o3
o6
o2

o9
o5

o2

CBB

o10
o8
CTT

u=1
CBT

o10
o8

u=1

CCB

o9
o5

CTC

o2 o2

o9 u=2

o5
u=1
CCT

CCC

ABB

o10
o8

CBC

o1
o1

o3
BTB
o6
o3
BBB
o7
o4
BBT
o4

o2
o2

CTB

o4
o7
o4
BTT
o3
o3
o6
o2
CBT
o2

o5
o9
o5

o2
o2
o8
o10
o8

u=1
CCB

o8
o10
o8
o5
CTT
o9
o5
u=1

u=1
CTC

u=1
CCT

o5
u=2
o9
o5
o8
CCC
o10
o8

CBC

Figure 12: Illustrations for our example of the landmark-based budget reducing compilation
L : (a) The structurally reachable parts of the graphical skeleton of the model
induced by L , illustrated on the projection of L on the variables of the original
task , along with a comparison between the budget-wise reachable parts of the
graphical skeletons induced by the models of the (b) original task  and (c) the
compiled task L .

 using the disposable propositions hvL1 /1i , . . . , hvLn /1i to ensure that at most one
instance of these discounted operators for each Li can be applied along an operator
sequence from the initial state12 , and
 compensating for the discounted operators for Li by reducing the budget by precisely
lcost(Li ).
For example, consider the simple OSP task  from Figure 2 (p. 104) with cost budget
b = 4, and assume we are provided with a set of four landmarks L = {L1 , . . . , L4 } where
L1 = {o1 }, L2 = {o2 }, L3 = {o3 , o4 } and L4 = {o5 , o8 }, and with admissible landmark cost
function lcost(Li ) = 1 for i  [4]. Compiling (L, lcost) into  using the budget reducing
compilation in Definition S
6 results in a task L with budget bL = 0 and c(o) = 0 for all the
discounted operators o  ni=1 OLi = {o1 , o2 , o3 , o4 , o5 , o8 }.
While the states of  correspond to complete assignments to only three variables V =
{t, x, y}, L already has seven variables VL = {t, x, y, vL1 , vL2 , vL3 , vL4 }. Thus, depicting
12. Note that, while the auxiliary variable g in the -compilation  of  can effectively change its value only
from hg/0i to hg/1i, the auxiliary variables vLi in L change their values (only) from hvLi /1i to hvLi /0i.
This difference reflects the positive semantics that is usually associated with the value 1, aka value
true, of the planning propositions: The semantics of a state s of L containing the proposition hvLi /1i
is that we are still allowed to apply (one of the) discounted operators associated with the landmark Li
from s onwards.

131

fiDomshlak & Mirkis

compile-and-BFBB ( = hV, s0 , u; O, c, bi)
 := -compilation of 
L := a set of landmarks for 
lcost := admissible landmark cost function from L
L := budget reducing compilation of (L, lcost) into 
n := BFBB(L )
return plan for  associated with n
Figure 13: BFBB search with landmark-based budget reduction
the structurally reachable parts of the graphical skeleton GML is problematic. Still, to
illustrate the search space of , in Figure 12(a) we show the (structurally reachable parts
of the) graphical skeleton of the model induced by the projection of  on the variables
{t, x, y} only. The arcs corresponding to discounted operators are colored, with each color
distinguishing the landmark responsible for the respective discounted operators.
Figures 12(b) and 12(c) illustrate the effect of the budget-reducing compilation by depicting the parts of the graphical skeletons GM and GML that are actually reachable
under the respective cost budgets b = 4 and bL = 0: While the states BTT and CTT are
reachable from the initial state of  under the budget allowance of 4, the states corresponding to BTT and CTT are no longer reachable in L , reducing the size of the search space
for BFBB. At the same time, as formulated in Theorem 16 below, this reduction of the
search space does not affect plans for  that lead to valuable states, resulting in an effective
equivalence between  and L .
Theorem 16 Let  = hV, s0 , u; O, c, bi be an OSP task, L be a set of pairwise disjoint
-landmarks for , lcost be an admissible landmark cost function from L, and L be the
respective budget reducing compilation of . For every  for  with Qb () > 0, there is a
plan L for L with QbL (L ) = Qb (), and vice versa.
The proof of Theorem 16 appears in Appendix A, p. 149. The budget reducing OSPto-OSP compilation in Definition 6 is clearly polynomial time. The compile-and-BFBB
procedure, depicted in Figure 13,
(1) generates an -compilation  of ;
(2) uses off-the-shelf tools for classical planning to generate a set of landmarks L for 
and an admissible landmark cost function lcost; and
(3) compiles (L, lcost) into , obtaining an OSP task L .
The optimal solution for L (and thus for ) is then searched for using a search algorithm
for optimal OSP such as BFBB.
Before we proceed to consider more general sets of landmarks, a few comments concerning the setup of Theorem 16 are in order. First, if the reduced budget bL turns out to
be lower than the cost of the cheapest action applicable in the initial state, then obviously
no search is needed, and the empty plan can be reported as optimal right away. Second,
132

fiOn Oversubscription Planning as Heuristic Search

zero-cost landmarks are useless in our compilation as much as they are useless in deriving
landmark heuristics for optimal planning. Hence, lcost in what follows is assumed to be
strictly positive. Third, having both o and o applicable at a state of  brings no benefits
yet adds branching to the search. Hence, in our implementation, for each landmark Li  L
and each operator o  Li , the precondition of the regular operators o in OL is extended
with {hvLi /0i}. It is not hard to verify that this extension preserves the correctness of
L in terms of Theorem 16. Finally, if the value of the initial state is not zero, that is,
the empty plan has some positive value, then -compilation  of  will have no positive
cost landmarks at all. However, this can easily be fixed by considering as valuable only
propositions hv/di such that both uv (d) > 0 and hv/di 6 s0 . We ignore for the time being
the problem of non-zero-value initial states (and assume that Qb () = 0), but return to it
later for a more systematic discussion.
5.3 Non-Disjoint -Landmarks
While the budget reducing compilation L above is sound for pairwise disjoint landmarks,
this is not so for more general sets of -landmarks. For example, consider a planning task
 in which, for some operator o, we have c(o) = b, Qb (hoi) > 0, and Qb () = 0 for all other
operator sequences  6= hoi. That is, a value greater than zero is achievable in , but only
via the operator o. Suppose now that our set of -landmarks for  is L = {L1 , . . . , Ln },
n > 1, with lcost(Li ) > 0 for all i  [n], and
Pnthat all of these -landmarks contain o. In this
case, while the budget in L is bL = b  i=1 lcost(Li ), the cost of the cheapest replica o
of o, that is, the cost of the cheapest operator sequence achieving a non-zero value in , is
n

n

i=1

i=1

c(o)  max lcost(Li ) = b  max lcost(Li ) > b 

n
X

lcost(Li ) = bL .

i=1

Hence, no state with positive value will be reachable from s0L in L , and thus  and L
are not value equivalent in the sense of Theorem 16.
This example shows why compiling non-disjoint -landmarks into  independently is
not sound. In principle, it can be made sound as follows. Let  = hV, s0 , u; O, c, bi be an
OSP task, let L = {L1 , . . . , Ln } be a set of -landmarks for , and let lcost be an admissible
landmark cost function from L. All the components in L = hVL , s0L , uL ; OL , cL , bL i are
still defined as in Definition 6, except for the operator sets OL1 , . . . , OLn . The latter are
now constructed not independently of each other, but sequentially, with the content of
OLi depending on the content of all OLj , j < i. The ordering in which the sets OLi are
constructed can be arbitrary.
For each operator o  O and each 1  i  n, let Oo;i denote the set of all cost
discounted representatives of o introduced
during the construction of OL1 , . . . , OLi . For
S
1  i  n, if for some operator o  o0 Li Oo0 ;i1 we have cL (o) = 0, then OLi := .
Otherwise, OLi contains an operator o for each operator
o  Li 

[
o0 Li

133

Oo0 ;i1 ,

(15)

fiDomshlak & Mirkis

with o being defined very similarly to Definition 6 as:
pre(o) = pre(o)  {hvLi /1i},
eff(o) = eff(o)  {hvLi /0i},
(
c(o)  lcost(Li ),
cL (o) =
cL (o)  lcost(Li ),

o  Li ,
.
S
o  o0 Li Oo0 ;i1

(16)

The compilation extended this way is sound for arbitrary sets of -landmarks, and
on pairwise disjoint landmarks it reduces to the basic compilation used in Theorem 16.
In general, however, this extended compilation is no longer polynomial in the size of the
explicit representation of  because
|Oo;i | = 2|{Lj |ji,oLj }| .
For example, let L = {L1 , L2 , L3 }, L1 = {a, b}, L2 = {a, c}, L3 = {a, d}. Generation of
OL1 := {a1 , b1 } effectively follows Definition 6, but for OL2 , the base set of operators as in
Eq. 15 is already {a, c, a1 }. Thus, OL2 := {a2 , c1 , a3 }, where, for i  {2, 3} and denoting a
by a0 , ai is derived according to Eq. 16 from ai2 . Consequently, the base set of operators
for OL3 is {a, d, a1 , a2 , a3 }, resulting in OL3 = {a4 , d1 , a5 , a6 , a7 }, where, for i  {4, 5, 6, 7},
ai is derived from ai4 . In sum, L ends up with 8 = 2|L| representatives of the operator a.
Since non-disjoint landmarks can bring more information, and they are typical to outputs
of standard techniques for landmark extraction in classical planning, we now present a
different, slightly more involved, compilation that is both polynomial and sound for arbitrary
sets of -landmarks.
Definition 7 Let  = hV, s0 , u; O, c, bi be an OSP task, L = {L1 , . . . , Ln } be a set of
pairwise disjoint -landmarks for , and lcost be an admissible landmark cost function
from L. For each operator o, let L(o) denote the set of all landmarks in L that contain
o. Then, the generalized budget reducing compilation of  is an OSP task L =
hVL , s0L , uL ; OL , cL , bL i where
bL = b 

n
X

lcost(Li ),

i=1

VL = V  {vL1 , . . . , vLn }
with dom(vLi ) = {0, 1},
s0L = s0  {hvL1 /1i , . . . , hvLn /1i},
uL = u,
OL = O  {o | o  LL L}  {get(L) | L  L}
with
pre(o) = pre(o)  {hvL /1i | L  L(o)},
eff(o) = eff(o)  {hvL /0i | L  L(o)},

(17)

and
pre(get(L)) = {hvL /0i},
eff(get(L)) = {hvL /1i},
134

(18)

fiOn Oversubscription Planning as Heuristic Search

and


c(o), P
cL () = c(o)  LL(o) lcost(L),


lcost(L),

=oO
.
=o

(19)

 = get(L)

To illustrate this compilation, we will let L = {L1 , L2 , L3 },
L1 = {a, b},
L2 = {b, c},
L3 = {a, c},
with all operators having the cost of 2, and let
lcost(L1 ) = lcost(L2 ) = lcost(L3 ) = 1.
In L , we have VL = V  {vL1 , vL2 , vL3 } and
OL = O  {a, b, c, get(L1 ), get(L2 ), get(L3 )},
with, e.g.,
pre(a) = pre(a)  {hvL1 /1i , hvL3 /1i},
eff(a) = eff(a)  {hvL1 /0i , hvL3 /0i},
cL (a) = 0,
and, for get(L1 ),
pre(get(L1 )) = {hvL /0i},
eff(get(L1 )) = {hvL /1i},
cL (get(L1 )) = 1.
The intuition behind the compilation in Definition 7 is as follows. By Eq. 19, applying
a discounted operator o saves the total cost of all landmarks containing o. Therefore,
 o can be executed only at states s in which all the corresponding control propositions
{hvL /1i | L  L(o)} hold, indicating that the cost of no landmark in L(o) has already
been saved before reaching s, and
 to avoid double savings around L(o), applying o in s turns off all these control propositions in sJoK.
However, considering the example above, suppose that the optimal plan  for the original
task contains an instance of operator a, followed by an instance of operator b, and no
instance of operator c. Applying a instead of a would block us from applying b instead
of b, and thus the value of the optimal plan in the compilation can be lower than Qb ().
The rescue here comes from the get(L) actions that allow for selective spending of the
individual landmark costs lcost(L). In our example, while applying a in s saves the cost
of the landmarks L1 and L3 , applying get(L1 ) will then spend lcost(L1 ) and safely set the
135

fiDomshlak & Mirkis

control proposition hvL1 /1i. In turn, this will enable b to be applied at the next steps,
and applying b will then save the cost of L2 and re-save the cost of L1 . This way, the
compilation leads to equivalence between  and L , formulated in Theorem 17 below and
proven in Appendix A, p. 149.
Theorem 17 Let  = hV, s0 , u; O, c, bi be an OSP task, let L = {L1 , . . . , Ln } be a set of
-landmarks for , let lcost be an admissible landmark cost function from L, and let L
be the (generalized) budget reducing compilation of . For every  for  with Qb () > 0,
there is a plan L for L with QbL (L ) = Qb (), and vice versa.
5.4 -Landmarks & Incremental BFBB
As we discussed earlier, if the value of the initial state is not zero, then the empty plan
has some positive value, and thus the -compilation  of  as in Definition 5 will have no
landmarks with positive cost. In passing we noted that this small problem can be remedied
by considering as valuable only facts hv/di such that both uv (d) > 0 and hv/di 6 s0 . We
now consider this aspect of OSP more closely, and show how the discovery of -landmarks
and the incremental revelation of plans by BFBB can be combined in a mutually stratifying
way.
Let  = hV, s0 , u; O, c, bi be the OSP task of interest, and suppose we are given a set
of plans 1 , . . . , n for . If so, then we are no longer interested in searching for plans
that achieve something, but in searching for plans that achieve something beyond what
1 , . . . , n already achieve. Specifically, let si = s0 Ji K be the end-state of i , and for any
set of propositions s  D, let goods(s)  s be the set of all propositions hv/di  s such that
uv (d) > 0. If a new plan  with end-state s achieves something beyond what 1 , . . . , n
already achieve, then, for all 1  i  n,
goods(s) \ goods(si ) 6= .
We now put this observation to work.
Definition 8 Given an OSP task  = hV, s0 , u; O, c, bi and a set of reference states Sref =
{s1 , . . . , sn } of , the (, Sref )-compilation of  is a classical planning task (,Sref ) =
hV , s0 , G ; O , c i with
V = V  {x1 , . . . , xn , search, collect},
with dom(xi ) = dom(search) = dom(collect) = {0, 1},
s0 = s0  {hsearch/1i , hcollect/0i , hx1 /0i , . . . , hxn /0i},
G = {hx1 /1i , . . . , hxn /1i},
n
[
O = O 
Oi  {f inish},
i=1

where
136

fiOn Oversubscription Planning as Heuristic Search

 O = {o | o  O},
pre(o) = pre(o)  {hsearch/1i},
eff(o) = eff(o),
c (o) = c(o).

pre(f inish) = ,
eff(f inish) = {hcollect/1i , hsearch/0i},
c (f inish) = 0.
 Oi = {oi,g | si  Sref , g  goods(D) \ si },
pre(oi,g ) = {g, hcollect/1i},
eff(oi,g ) = {hxi /1i},
c (oi,g ) = 0.
Note that
 the goal G cannot be achieved without applying the f inish operator;
 the regular operators o can be applied only before f inish; and
 the subgoal achieving operators oi,g can be applied only after f inish.
This way, the first part of any plan for (,Sref ) determines a plan for , and the second part
verifies that the end-state of that plan achieves a subset of value-carrying propositions
goods(D) that is included in no state from Sref .13
Theorem 18 Let  = hV, s0 , u; O, c, bi be an OSP task, Sref = {s1 , . . . , sn } be a subset of
s states, and L be a landmark for (,Sref ) such that L  O. For any plan  for  such
that goods(s0 JK) \ goods(si ) 6=  for all si  Sref ,  contains an instance of at least one
operator from L0 = {o | o  L}.
Proof: Assume to the contrary that there exists a plan  = ho1 , . . . , ok i for  such that
goods(s0 JK) \ goods(si ) 6=  for all si  Sref , and yet   L0 = . Let {g1 , . . . , gn } be an
arbitrary set of propositions from goods(s0 JK) \ goods(s1 ), . . . , goods(s0 JK) \ goods(sn ),
respectively. By the construction of (,Sref ) , it is immediate that
(,Sref ) = ho1 , . . . , ok , f inish, o1,g1 , . . . , on,gn i
is a plan for (,Sref ) and, by our assumption about  and L0 , it holds that (,Sref )  L = .
This, however, contradicts that L is a landmark for (,Sref ) .

13. This solve & verify technique appears to be helpful in many planning formalism compilations; see,
e.g., the work of Keyder and Geffner (2009).

137

fiDomshlak & Mirkis

inc-compile-and-BFBB ( = hV, O; s0 , c, u, bi)
initialize global variables:
n := s0
// best solution so far
Sref := {s0 } // current reference states
loop:
(,Sref ) = (, Sref )-compilation of 
L := a set of landmarks for (,Sref )
lcost := admissible landmark cost function from L
L := budget reducing compilation of (L, lcost) into 
if inc-BFBB(L , Sref , n ) = done:
return plan for  associated with n
inc-BFBB (, Sref , n )
open := new max-heap ordered by f (n) = h(shni, b  g(n))
open.insert(make-root-node(s0 ))
closed:= 
best-cost:= 0
while not open.empty()
n := open.pop-max()
if f (n)  u(shn i): break
if u(shni) > u(shn i): update n := n
if goods(shni) 6 goods(s0 ) for all s0  Sref :
Sref := Sref  {shni}
if termination criterion: return updated
// the rest is similar to BFBB in Figure 3

if shni 6 closed or g(n) < best-cost(shni):
closed:= closed  {shni}
best-cost(shni) := g(n)
foreach o  O(shni):
n0 := make-node(shniJoK, n)
if g(n0 ) > b or f (n0 )  u(shn i): continue
open.insert(n0 )
return done
Figure 14: Iterative BFBB with landmark enhancement
Theorem 18 allows us to define an iterative version of BFBB, inc-compile-and-BFBB,
depicted in Figure 14. The successive iterations of inc-compile-and-BFBB correspond to
running the regular BFBB on successively more informed (, Sref )-compilations of , with
the states discovered at iteration i making the (, Sref )-compilation used at iteration i + 1
more informed.
inc-compile-and-BFBB maintains as a pair of global variables: a set of reference states
Sref and the best solution so far n . At each iteration of the loop, a modified version of
BFBB, inc-BFBB, is called with an (, Sref )-compilation of , created on the basis of the
138

fiOn Oversubscription Planning as Heuristic Search

current Sref . The reference set Sref is then extended by inc-BFBB with all the non-redundant
value-carrying states discovered during the search, and n is updated if the search discovers
nodes of higher value.
If and when the OPEN list becomes empty or the node n selected from the list promises
less than the lower bound, inc-BFBB returns an indicator, done, that the best solution
n found so far, across the iterations of inc-compile-and-BFBB, is optimal. In that case,
inc-compile-and-BFBB leaves its loop and extracts that optimal plan from n . However,
inc-BFBB may also terminate in a different way, if a certain complementary termination
criterion is satisfied. The latter criterion comes to assess whether the updates to Sref
performed in the current session of inc-BFBB warrant updating the (, Sref )-compilation
and restarting the search. If terminated this way, inc-BFBB returns a respective indicator,
and inc-compile-and-BFBB goes into another iteration of its loop, with the updated Sref and
n . We note that, while the optimality of the algorithm holds for any such termination
condition, the latter should greatly affect the runtime efficiency of the algorithm.
Theorem 19 The inc-compile-and-BFBB search algorithm is sound and complete for optimal OSP.
Proof: First, for any complementary termination criterion employed by the inc-BFBB procedure, inc-compile-and-BFBB is guaranteed to terminate. This is because that complementary termination criterion is checked in inc-BFBB only after a proper expansion of the
global reference set Sref , and thus the number of calls to inc-BFBB by inc-compile-and-BFBB
is upper-bounded by |S|.
It terms of search, inc-BFBB is no different from the regular BFBB procedure. In turn, by
Theorem 18, the additional pruning power of the budget-reducing compilation with reference
states Sref affects only search nodes n such that u(shni) < maxsSref u(s). Note also that,
each time the best solution so far n is updated in inc-BFBB, it is necessarily added to Sref
(since goods(shn i) of the new n can be included in no goods(s) for s  Sref ). Thus, optimal
solutions cannot be pruned out by inc-BFBB and the overall search by inc-compile-and-BFBB
is therefore sound.

5.5 Empirical Evaluation
To evaluate the merits of the landmark-based budget reducing compilation, we have extended our prototype OSP solver from Section 3 with the following components:
 (, Sref )-compilation of OSP tasks  for arbitrary sets of reference states Sref ;
 generation of disjunctive action landmarks for (, Sref )-compilations using the LM-Cut
procedure (Helmert & Domshlak, 2009) of Fast Downward; and
 the incremental BFBB procedure inc-compile-and-BFBB as in Figure 14, with the
search termination criterion being satisfied (only) if the examined node n improves
over the current value lower bound, i.e., n becomes the new best-so-far node n .
After some preliminary evaluation, we also added two optimality preserving enhancements to the search. Because the auxiliary variables of our compilations increase the dimensionality of the problem, and this is known to negatively affect the quality of the abstraction
139

fiDomshlak & Mirkis

(a) blind
108

unsolved

107
106
105
104
103
102

unsolved

compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

unsolved

106
105
104
103
102

unsolved

compile-and-BFBB

107

101

100
100 101 102 103 104 105 106 107 108
BFBB

Figure 15: Comparative view of empirical results in terms of expanded nodes, for BFBB
vs. compile-and-BFBB, with (a) blind and (b) abstraction hM heuristics

heuristics (Domshlak et al., 2012), we first devised the projections with respect to the original OSP problem , and the open list was ordered as if the search is done on the original
problem, that is, by


X
h shniV , b  g(n) +
lcost(L) ,
vL 6shni

where sV is the projection of the L s state s on the variables of the original OSP task .
This change in heuristic evaluation is sound, as Theorem 17 in particular implies that any
140

fiOn Oversubscription Planning as Heuristic Search

admissible heuristic for  is also an admissible heuristic for L , and vice versa. Second,
when a new node n is generated, we check whether
X
X
lcost(L),
lcost(L)  g(n0 ) +
g(n) +
L:hvL /0ishn0 i

L:hvL /0ishni

for some previously generated node n0 that corresponds to the same state of the original
problem , that is, shn0 iV = shniV . If so, then n is pruned right away. Optimality
preservation of this enhancement is established in Lemma 20 and proven in Appendix A,
p. 151.
Lemma 20 Let  be an OSP task, (,Sref ) be a (, Sref )-compilation of , L be a set of
landmarks for (,Sref ) , lcost be an admissible landmark cost function for L, and L be the
respective budget reducing compilation of (L, lcost) into . Let 1 and 2 be a pair of plans
V
for L with end-states s1 and s2 , respectively, such that sV
1 = s2 and
cL (1 ) +

X

lcost(L)  cL (2 ) +

L:hvL /0is1

X

lcost(L).

(20)

L:hvL /0is2

Then, for any plan 10 that extends 1 , there exists a plan 20 that extends 2 such that
= QbL (10 ).

QbL (20 )

Our evaluation included the regular BFBB planning for , solving  using landmarkbased compilation via compile-and-BFBB, and the simple setting of inc-compile-and-BFBB
described above. All three approaches were evaluated under the blind heuristic and the
additive abstraction heuristic hM described in Section 3. Figures 15-17 depict the results
of our evaluation in terms of expanded nodes. Similarly to the experiment reported in
Section 3, each task was approached under four different budgets, corresponding to 25%,
50%, 75%, and 100% of the minimal cost needed to achieve all the goals in the task,
and each run was restricted to 10 minutes. Figures 15a and 15b compare the number
of expanded nodes of BFBB and compile-and-BFBB across the four levels of cost budget,
under blind (a) and abstraction hM (b) heuristics. Figures 16a and 16b provide a similar
comparison between BFBB and inc-compile-and-BFBB. Figures 17a and 17b do the same
for compile-and-BFBB and inc-compile-and-BFBB.14 Figures 22-25 and Figures 26-29 in
Appendix B provide a more detailed view of the results in Figures 15 and 16, respectively,
by breaking them down into different levels of cost budget.
As Figure 8 shows, the results were very satisfactory. With no informative heuristic
guidance at all, the number of nodes expanded by compile-and-BFBB was typically much
lower than the number of nodes expanded by BFBB, with the difference reaching three
orders of magnitude more than once. Of the 760 task/budget pairs behind Figure 8a, 81
pairs were solved by compile-and-BFBB with no search at all (by proving that no plan can
achieve value higher than that of the initial state), while, unsurprisingly, only 4 of these
tasks were solved with no search by BFBB.
14. We do not present here a detailed comparison in terms of the running times, but the per-node CPU
time overhead due to landmark-based budget reduction was  10%. Some technical difficulties with our
implementation of inc-compile-and-BFBB led us to limit our comparison of it in each graph only to tasks
solved by both methods.

141

fiDomshlak & Mirkis

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108
inc-compile-and-BFBB

107
106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

Figure 16: Comparative view of empirical results in terms of expanded nodes, for BFBB
vs. inc-compile-and-BFBB, with (a) blind and (b) abstraction hM heuristics

As expected, the impact of the landmark-based budget reduction is lower when the
search is equipped with a meaningful heuristic (Figure 15b). Nonetheless, even with our
abstraction heuristic in hand, the number of nodes expanded by compile-and-BFBB was
often substantially lower than the number of nodes expanded by BFBB. Here, BFBB and
compile-and-BFBB solved with no search 39 and 85 task/budget pairs, respectively. Finally, despite the rather ad hoc setting of our incremental inc-compile-and-BFBB procedure,
switching from compile-and-BFBB to inc-compile-and-BFBB was typically beneficial. Obvi142

fiOn Oversubscription Planning as Heuristic Search

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100 0
10 101 102 103 104 105 106 107 108
compile-and-BFBB

(b) hM
108
inc-compile-and-BFBB

107
106
105
104
103
102
101
100 0
10 101 102 103 104 105 106 107 108
compile-and-BFBB

Figure 17: Comparative view of empirical results in terms of expanded nodes, for
compile-and-BFBB vs. inc-compile-and-BFBB, with (a) blind and (b) abstraction hM heuristics

ously, much deeper investigation and development of inc-compile-and-BFBB is still required,
especially in the context of the choice of the iteration termination criterion.

6. Summary and Future Work
Deterministic oversubscription planning captures the computational core of one of the most
important setups of automated action selection, and yet, despite the apparent importance of
143

fiDomshlak & Mirkis

this problem, it has not been sufficiently investigated. In this work, we progressed towards
translating the spectacular advances in classical deterministic planning to deterministic
OSP. Tracing the key sources of progress in classical planning, we identified a severe lack
of effective approximations for OSP, and worked towards bridging this gap.
Our focus was on two classes of approximation techniques that underly most state-ofthe-art optimal heuristic-search solvers for classical planning: state-space abstractions and
goal-reachability landmarks. First, we defined the notion of additive abstractions for OSP,
studied the complexity of deriving effective abstractions from a rich space of hypotheses,
and revealed some substantial, empirically relevant islands of tractability of this abstraction
discovery problem. Next, we showed how standard goal-reachability landmarks of certain
classical planning tasks can be compiled into the OSP task of interest, resulting in an
equivalent OSP task with a lower cost allowance, and thus with a sometimes dramatically
smaller search space.
All the techniques proposed here satisfy the properties required by the efficient search
algorithms for optimal OSP. However, we believe that these techniques, and especially
landmark-based budget reducing compilations, should be as beneficial in satisficing OSP
as in optimal OSP, in particular because the difference between optimal and satisficing
planning appears to be much smaller in OSP than in classical deterministic planning.
Many interesting questions remain open for future work, and the prospects for further
developments in oversubscription planning now appear quite promising. Within the specific
context of our work, the two most interesting research directions are (1) optimization of value
partitions given cost partitions, that is, optimizing abstraction discovery in Ap (c, , ),
and (2) thoroughly investigating the interleaved landmark discovery and search for OSP
introduced in Section 5.4. In a broader context, we propose, as well, additional candidates
for future research:
 Following the work of Katz and Domshlak (2010a) on implicit abstractions for classical planning, the computational merits of implicit abstractions for OSP should be
investigated. This will inevitably give us a better understanding of the computational
tractability boundaries of deterministic OSP.
 The basic model of deterministic planning in Section 2.1 was used to provide a unifying
comparative view of the basic models of classical, cost-bounded, net-benefit, and
oversubscription planning. One practically motivated extension of this model is to lift
action costs to vectors of action costs. Such a variant of cost-bounded planning has
already been investigated (Nakhost et al., 2012), and it is only natural to examine
this extension in the context of OSP.
Unfortunately, our results on abstractions do not seem to extend directly to vectors of
costs: At the level of the planning model, adding cost measures shifts problem solving
from polynomial time shortest path(s) problems to NP-hard restricted shortest path(s)
problems (Handler & Zang, 1980). Nonetheless, like the Knapsack problem, the restricted shortest path problem can be solved in pseudo-polynomial time (Desrochers
& Soumis, 1988), and thus some extension of our results to vectors of costs might still
be achievable.
At the same time, the machinery of landmark-based budget reducing compilations
for OSP straightforwardly extends to vectors of costs and budgets. Hence, even if no
144

fiOn Oversubscription Planning as Heuristic Search

quality heuristic for OSP with multiple cost measures is available, the blind search
can still be stratified with information coming from problem landmarks.
 While the pruning mechanism of BFBB must rely on admissible, upper-bounding
heuristic estimates, no special properties are required from a heuristic used to guide the
search choices of BFBB. Thus, developing informative yet not necessarily admissible
heuristics for OSP is clearly of interest.
Acknowledgments
This work was partially supported by the EOARD grant FA8655-12-1-2096, and the ISF
grant 1045/12.

Appendix A. Proofs
Theorem 2 Given an OSP task  = hV, s0 , u; O, c, bi and a homomorphic abstraction
skeleton AS = {(G1 , 1 ), . . . , (Gk , k )} of M ,
(1) for each cost partition c  Cp , there exists a budget partition b  Bp such that

M(c,u,b ) As AS for all value partitions u  Up ;
(2) for each budget partition b  Bp , there exists a cost partition c  Cp such that

M(c ,u,b) As AS for all value partitions u  Up .
Proof: Let  = h(s0 , o1 , s1 ), (s1 , o2 , s2 ), . . . , (sn1 , on , sn )i be an optimal s0 -plan for M ,
and, for i  [k], let i = h(i (s0 ), o1 , i (s1 )), . . . , (i (sn1 ), on , i (on ))i be the mapping of
 to Gi . Since AS is homomorphic, the paths 1 , . . . , k are well-defined.
(1) P
Given a cost partition c  Cp , let budget profile b  B be defined as b [i] =

j[n] c[i](oj ), for i  [k]. First, note that b  Bp since
X
i[k]

()

X X

b [i] =

c[i](oj ) 

i[k] j[n]

X

()

c(oj )  b,

j[n]

where () is by c being a cost partition, and () is by  being an s0 -plan for M .
Second, for any u  U, by the construction of b , i is an i (s0 )-plan for the abstract
(c,u,b )
model Mi
. Now, let u  Up , and for i  [k], let i be an optimal i (s0 )-plan for
(c,u,b )
Mi
. We have
X
i[k]

Qb

 [i]

()

(i ) 

X

 [i]

Qb

()

(i )  Qb (),

(21)

i[k]

where () is by optimality of i , and () is by i (sn ) being the end-state of i and u
being a value partition. Therefore, (c, u, b ) induces an additive abstraction for , that

is, M(c,u,b ) AAS M .
145

fiDomshlak & Mirkis

(2) Given a budget partition b, let cost profile c  C be defined as c [i](o) = c(o)  b[i]
b ,
forPall operators o  O, and all i  [k]. First, we have c  Cp since b  Bp implies
1

i[k] b[i]  [0, 1]. Second, for any u  U, by the construction of c , i is an i (s0 )b
(c ,u,b)

plan for Mi
. Following now exactly the same line of reasoning as for Eq. 21 above

accomplishes the proof that M(c ,u,b) AAS M for any u  Up .

Lemma 6 The algorithm in Figure 9a computes (u).
Proof: Due to the boundness and non-emptiness of the polytope induced by Lm
1 , the termination of the algorithm is straightforward. Thus, given a strong 0-binary partition u, the
only question is whether the value with which the algorithm terminates is (u). First, let
us show that:
() For m  [k], if x is a solution of Lm
1 , then x[]  b if and only if, for each cost partition
c  Cp , there exists a budget partition b  Bp such that (c, u, b) is an abstraction
for M and hM(c,u,b) (s0 )  m.
() Assume to the contrary that, for each cost partition c  Cp , there exists a budget partition b  Bp with hM(c,u,b)
S (s0 )  m, and yet x[] > b. Given the values provided by x to the cost variables oO {c[i](o)}, let c be the corresponding cost partition,
and 1 , . . . , k be the induced lengths of the shortest paths from 1 (s0 ), . . . , k (s0 ) to valued states in G1 , . . . , Gk , respectively. By our assumption, let b be a budget partition
such that hM(c,u,b) (s0 )  m. First, by the definition of strong 0-binary value partitions,
hM(c,u,b) (s0 )  m implies that there exists Z  k, |Z| = m such that, for i  Z, b[i]  i .
Second, constraint (10c), maximization of , and the fact that the only bound on each b[i]
is by i imply together that, for i  Z, x[b[i]] = i . Putting things together, we obtain
bBp

b 

X

b[i] 

iZ

X

i =

iZ

X

(10c)

x[b[i]]  ,

iZ

contradicting our assumption.
() Assume to the contrary that, x[]  b, and yet there exists a cost partition c  Cp
such that, for all budget partitions b  Bp with (c, u, b)  Ap , we have hM(c,u,b) (s0 ) < m.
Let the shortest path lengths 1 , . . . , k be defined as above, but now with respect to the
specific cost partition c from the assumption.
Likewise, let xc be a solution to Lm
1 with an
S
extra constraint on the cost variables oO {c[i](o)} to be assigned to c. Since the objective
in Lm
1 is to maximize the value of , we have
x[]  xc [].

(22)

Now, let
Z=

argmax

X

Z 0 [k],|Z 0 |=m iZ 0

146

i .

fiOn Oversubscription Planning as Heuristic Search

Together, constraint (10c), maximization of , and the fact that the only bound on each
b[i] is by i (via the cost variables) imply that
xc [] =

X

xc [b[i]] =

iZ

X

i .

(23)

iZ

In turn, together with x[]  b and Eq. 22, Eq. 23 implies that
(
xc [b[i]],
b[i] =
0,

iZ
otherwise

is a budget partition with (c, u, b)  Ap , and hM(c,u,b) (s0 )  m, contradicting our assumption.
Having proved the sub-claim (), which basically captures the semantics of Lm
1 , suppose
that the algorithm terminates within the loop, and returns m for some m > 0. By the
construction of the algorithm, if x is a solution of Lm
1 , then x[]  b. By (), for each cost
partition c  Cp , there exists (c, u, b)  Ap such that h(c,u,b) (s)  m. If m = k, then
trivially s (u) = m. Otherwise, if m < k, we know that the algorithm did not terminate
at the previous iteration corresponding to m + 1. Again, () then implies that there exists a
cost partition c  Cp for which no (c, u, b)  Ap will induce h(c,u,b) (s)  (m + 1). Hence,
by the definition of s (u), s (u) < (m + 1), and in turn, since u is a strong 0-binary value
partition, we have s (u) = m. Finally, if the algorithm terminates after the loop and
returns 0, then precisely the same argument on the basis of () implies s (u) = 0.

Lemma 9 For any 0 <  < mini[k] i , the algorithm in Figure 10a computes  such that
  (u)  .
Proof: The arguments for the boundness and non-emptiness of the polytope induced by
Lv2 are precisely the same as for the polytope of Lm
1 studied in Lemma 6, and thus the
termination of the algorithm is straightforward. In what follows, we prove that the value
returned by the algorithm satisfies the claim of the lemma. Let u be the given 0-binary
partition. Similarly to the proof of Lemma 9, first we prove a sub-claim that:
() For v  R0+ , if x is a solution of Lv2 , then x[]  b if and only if, for each cost partition
c  Cp , there exists a budget partition b  Bp such that (c, u, b) is an abstraction
for M and hM(c,u,b) (s0 )  v.
The proof of () mirrors the proof of the respective sub-claim in Lemma 5, mutatis mutandis,
and thus it is provided here only for ease of verification.
() Assume to the contrary that, for each cost partition c  Cp , there exists a budget
partition b  Bp with hM(c,u,b) (s0 )  v, and yet x[] > b.
S
Given the values provided by x to the cost variables oO {c[i](o)}, let c be the corresponding cost partition, and, for i  [k], let i be the induced length of the shortest
path from i (s0 ) to the i -valued states in Gi . By our assumption, let b be a budget
partition such that hM(c,u,b) (s0 )  v. First, by the
P definition of 0-binary value partitions,
hM(c,u,b) (s0 )  v implies that there exists Z  k, iZ i  v such that, for i  Z, b[i]  i .
147

fiDomshlak & Mirkis

Second, constraint (11c), maximization of , and the fact that the only bound on each b[i]
is by i , imply together that, for i  Z, x[b[i]] = i . Putting things together, we obtain
bBp

b 

X

b[i] 

iZ

X

i =

iZ

X

(11c)

x[b[i]]  ,

iZ

contradicting our assumption.
() Assume to the contrary that, x[]  b, and yet there exists a cost partition c  Cp
such that, for all budget partitions b  Bp with (c, u, b)  Ap , we have hM(c,u,b) (s0 ) < v.
Let the shortest path lengths 1 , . . . , k be defined as above, but now with respect to the
specific cost partition c from the assumption.
Likewise, let xc be a solution to Lv2 with an
S
extra constraint on the cost variables oO {c[i](o)} to be assigned to c. Since the objective
in Lv2 is to maximize the value of , we have
x[]  xc [].

(24)

Now, let
Z = argmax

X

0
PZ [k], iZ 0
iZ 0 i v

i .

Together, constraint (11c), maximization of , and the fact that the only bound on each
b[i] is by i (via the cost variables) imply that
xc [] =

X

xc [b[i]] =

iZ

X

i .

(25)

iZ

In turn, together with x[]  b and Eq. 24, Eq. 25 implies that
(
xc [b[i]], i  Z
b[i] =
,
0,
otherwise
is a budget partition with (c, u, b)  Ap , and hM(c,u,b) (s0 )  v, contradicting our assumption.
This finalizes the proof of the sub-claim (). Now,Pconsider the interval end-points 
and  at the termination
of the while-loop. If  =
i[k] i , then, trivially, (u)  .
P
Otherwise, if  < i[k] i , then, by the construction of the algorithm, at some iteration of
the while loop, a test always-achievable() was issued, came back negative, and thus, for the
solutions x of L2 , we have x [] > b. Hence, by (), (u) < . Now, if  6= 0, then, by the
construction of the algorithm, at some iteration of the while loop, a test always-achievable()
was issued, came back positive, and thus, for the solutions x of L2 , we have x []  b.
Hence, by (), (u)  . Putting these properties on  and  together with the while-loops
termination condition      implies   (u) =   (u)  . Finally, if  = 0, then
 < mini[k] i implies  < mini[k] i . In turn, since (u) corresponds to a sum of values of
some states in the k models of M(c,u,b) , (u)   concluded above implies  = (u) = 0.

148

fiOn Oversubscription Planning as Heuristic Search

Theorem 16 Let  = hV, s0 , u; O, c, bi be an OSP task, L be a set of pairwise disjoint
-landmarks for , lcost be an admissible landmark cost function from L, and L be the
respective budget reducing compilation of . For every  for  with Qb () > 0, there is a
plan L for L with QbL (L ) = Qb (), and vice versa.
Proof: Let L be a plan
Snfor L , and let  be the operator sequence obtained by replacing
all operators o from i=1 OLi along L with the respective operators o  O. By the
definition S
of the action set of L in Eq. 15, we have  applicable in s0 , and s0 JK =
s0L JL K \ ni=1 dom(vLi ). Thus, Qb () = QbL (L ). Likewise, again by the definition of
the action set of L in Eq. 15 and the fact that no operator in OL achieves the control
propositions {hvL1 /1i , . . . , hvLn /1i}, we have |OLi  L |  1. From that, we have

c()  cL (L ) +

n
X

lcost(Li ).

i=1

P
In turn, b = bL + ni=1 lcost(Li ) by Eq. 14, and cL (L )  bL by the virtue of L being a
plan for L . Therefore, it holds that c()  b, and thus  is a plan for .
In the opposite direction, let  be a plan for  with Qb () > 0, and let L be an
operator sequence obtained by replacing, for each -landmark L  L, every first occurrence
of an operator from L with the respective cost reduced operator from OL . It is easy to
verify that L is applicable in s0L , and that QbL (L ) = Qb (). Likewise, by the definition
of -landmarks, every L  L will have a presence along . From that, we have

c(L ) = c() 

n
X

lcost(Li )  b 

i=1

n
X

lcost(Li ) = bL ,

i=1

where the first equality is by pairwise disjointness of {L1 , . . . , Ln }, the inequality is by 
being a plan for , and the second equality is by Eq. 14. Thus, L is a plan for L .


Theorem 17 Let  = hV, s0 , u; O, c, bi be an OSP task, let L = {L1 , . . . , Ln } be a set of
-landmarks for , let lcost be an admissible landmark cost function from L, and let L
be the (generalized) budget reducing compilation of . For every  for  with Qb () > 0,
there is a plan L for L with QbL (L ) = Qb (), and vice versa.
Proof: Let L be a plan for L , and let  be the operator sequence obtained by (i) replacing
all operators o with the respective operators o  O, and (ii) removal of all get operators. By
Eq. 17, we have  applicable in s0 , and s0 JK = s0L JL K \ {hvL1 /1i , . . . , hvLn /1i}. Thus,
Qb () = QbL (L ). Now, for each -landmark L  L, let (L) be the number of instances
of the cost reduced counterparts o of the operators from L along L . By Eqs. 17 and 18,
for each L  L, L must contain at least (L)  1 instances of operator get(L). From that,
we have
149

fiDomshlak & Mirkis

X

c()  cL (L ) +

X

lcost(L) 

oL LL(o)

= cL (L ) +

X
X

((L)  1)lcost(L)

LL

(L)lcost(L) 

LL

= cL (L ) +

X

X

((L)  1)lcost(L)

LL

lcost(L)

LL

 bL +

X

lcost(L)

LL

= b,
and thus  is a plan for .
In the opposite direction, let  = ho1 , . . . , om i be a plan for  with Qb () > 0. By
the definition of -landmarks, every landmark Li  L will have a presence along . Let
of (i) , f (i)  [n], be the first occurrence
of an ffoperator from Li along , that is, f (i) =


let  = o(1) , . . . , o(k) , k  n, be the operator sequence obtained
argminj[m] {oj  Li }, and S
by ordering the operators i[n] {of (i) } consistently with . Note that, since -landmarks
in L are not necessarily disjoint, we may have f (i) = f (j) for some 1  i 6= j  n, and thus
k can be strictly smaller than n.
Given the above, let L be an operator sequence obtained from  based on  by
(1) replacing each o(i) along  with o(i) , and
(2) inserting right before each o(i) an arbitrary ordered sequence of actions
i1
[

{get(L) | L  L, {o(j) , o(i) }  L}.

(26)

j=1

Note the set union semantics of Eq. 26: even if multiple operators from {o(1) , . . . , o(i1) }
appear in some landmark L together with o(i) , only one instance of the operator get(L) is
inserted in step (2) before o(i) .
It is not hard to verify that L is applicable in s0L , and that QbL (L ) = Qb (). Now,
step (1) of expanding  to L reduces the cost of the operator sequence by
k
X

X

lcost(L) =

i=1 LL(o(i) )

X

(L)lcost(L),

LL

where (L) is the number of all occurrences of the operators fromP
L in . In turn, step (2) of
expanding  to L increases the cost of the operator sequence by LL ((L)  1)lcost(L).
This is because, by Eq. 26, among all (L) operators o(i) along L such that o(i)  L, all
but the first are preceded by the dedicated instances of the operator get(L). Thus,
X
X
cL (L ) = c() 
lcost(L)  b 
lcost(L) = bL ,
LL

LL

that is, L is a plan for L .


150

fiOn Oversubscription Planning as Heuristic Search

Lemma 20 Let  be an OSP task, (,Sref ) be a (, Sref )-compilation of , L be a set of
landmarks for (,Sref ) , lcost be an admissible landmark cost function for L, and L be the
respective budget reducing compilation of (L, lcost) into . Let 1 and 2 be a pair of plans
V
for L with end-states s1 and s2 , respectively, such that sV
1 = s2 and
cL (1 ) +

X

lcost(L)  cL (2 ) +

Then, for any plan
b
L
Q  (20 ) = QbL (10 ).

lcost(L).

(20)

L:hvL /0is2

L:hvL /0is1

10

X

that extends 1 , there exists a plan 20 that extends 2 such that

Proof: Under the notation in the claim, the proof is by a constructive mapping of the plan
10 to the corresponding plan 20 .
First, we derive from 10 a plan 01 for  by (i) removing the f inish operator and all
the get() operators, and (ii) replacing all instances of each discounted operator o with
instances of the respective original operator o. This results in a plan 01 := 1  1e for 
P
with s0 [[1 ]] = sV
1 and c(1 ) = cL (1 ) +
L:hvL /0is1 lcost(L). To see the latter, for each

operator   OL , let ()  0 denote the number of instances of  along 1 . Given that,
we have
c(1 ) = cL (1 ) 

X

(get(L))lcost(L) +

LL

X

= cL (1 ) +

lcost(L) 

LL

= cL (1 ) +

X

X

X

(o)

LL

o:LL(o)






X

lcost(L)

(o)  (get(L))

o:LL(o)

(27)

lcost(L)  1s1 (hvL /0i)

LL

= cL (1 ) +

X

lcost(L),

L:hvL /0is1

where the second and fourth equalities are just formula manipulations, the first equality is
direct from the construction of 1 , and the third equality is by the definition of the budget
reducing compilation, and specifically, by Eqs. 17 and 18.
Similarly to the construction of P
1 from 1 , we can construct 2 from 2 , with and

s0 [[2 ]] = sV
and
c(
)
=
c
(
)
+
2
2
L
2
L:hvL /0is2 lcost(L). Thus, by Eq. 20, c(1 )  c(2 ),
and also, by the setting of the lemma, s0 [[1 ]] = s0 [[2 ]]. Hence, 02 = 2  1e is also a plan
for , and Qb (01 ) = Qb (02 ).
As the last step, we now construct from 02 a plan 20 for L as in the claim. First, by
the properties of 2 in the claim, the plan 2 for  achieves all the landmarks L6s2 = {L |
hvL /0i  s2 }. Second, by the definition of the landmark set L, 1e must satisfy the rest of
the landmarks, that is, Ls2 = {L | hvL /1i  s2 }. Let us denote the operator instances along
1e as ho1 , . . . , ok i, k = |1e |, and let {L1 , . . . , Lk } be a partition of Ls2 with Li  Ls2
being the subset of all landmarks from Ls2 for which oi is their first achiever along 1e .
Given that, consider an operator sequence 2e :=  (k) , recursively defined via  (0) = ,
and, if Li = , then  (i) =  (i1)  hoi i, else  (i) =  (i1)    hoi i, where  is some (arbitrary)
151

fiDomshlak & Mirkis

sequencing of operators
{get(L) | L  Li  hvL /0i  s0 J2 KJ (i1) K}.
Finally, we set 20 := 2  2e .
By Eqs. 17 and 18 in the definition of the budget reducing compilation,
it is easy to
P
verify that the above construction of 2e ensures cL (2e ) = c(1e ) hvL /1is2 lcost(L) and
QbL (2e ) = Qb (02 ). In turn, by the properties of 2 , this implies that QbL (20 ) = QbL (10 )
and cL (20 ) = cL (2 ) + cL (2e ).
Finally, since
X
lcost(L)
cL (2 ) = c(2 ) 
hvL /0is2

and
X

cL (2e ) = c(1e ) 

lcost(L),

hvL /1is2

we have
cL (20 ) = c(2 ) + c(1e ) 

X

lcost(L).

LL

Thus, since c(1 )  c(2 ) and 01 = 1  1e is a valid plan for , we have
X
cL (20 )  c(1 ) + c(1e ) 
lcost(L)
LL



c(01 )



X

lcost(L)

LL

b

X

lcost(L),

LL

finalizing the proof that 20 is a plan for L as in the claim.

152



fiOn Oversubscription Planning as Heuristic Search

Appendix B. Detailed Evaluation Results
(a)
108

unsolved

107
106
105
hM

104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
blind

(b)
108

unsolved

107
106
hM

105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
basic

Figure 18: The comparison in Figure 8, p. 117, restricted to the tasks budgeted with 25%
of the minimal cost of achieving the entire set of subgoals

153

fiDomshlak & Mirkis

(a)
108

unsolved

107
106
105
hM

104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
blind

(b)
108

unsolved

107
106
hM

105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
basic

Figure 19: The comparison in Figure 8, p. 117, restricted to the tasks budgeted with 50%
of the minimal cost of achieving the entire set of subgoals

154

fiOn Oversubscription Planning as Heuristic Search

(a)
108

unsolved

107
106
105
hM

104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
blind

(b)
108

unsolved

107
106
hM

105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
basic

Figure 20: The comparison in Figure 8, p. 117, restricted to the tasks budgeted with 75%
of the minimal cost of achieving the entire set of subgoals

155

fiDomshlak & Mirkis

(a)
108

unsolved

107
106
105
hM

104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
blind

(b)
108

unsolved

107
106
hM

105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
basic

Figure 21: The comparison in Figure 8, p. 117, restricted to the tasks budgeted with 100%
of the minimal cost of achieving the entire set of subgoals

156

fiOn Oversubscription Planning as Heuristic Search

(a) blind
108

unsolved

107
compile-and-BFBB

106
105
104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

unsolved

compile-and-BFBB

107
106
105
104
103
unsolved

102
101

100
100 101 102 103 104 105 106 107 108
BFBB

Figure 22: The comparison in Figure 15, p. 140, restricted to the tasks budgeted with 25%
of the minimal cost of achieving the entire set of subgoals

157

fiDomshlak & Mirkis

(a) blind
108

unsolved

107
compile-and-BFBB

106
105
104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

unsolved

compile-and-BFBB

107
106
105
104
103
unsolved

102
101

100
100 101 102 103 104 105 106 107 108
BFBB

Figure 23: The comparison in Figure 15, p. 140, restricted to the tasks budgeted with 50%
of the minimal cost of achieving the entire set of subgoals

158

fiOn Oversubscription Planning as Heuristic Search

(a) blind
108

unsolved

107
compile-and-BFBB

106
105
104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

unsolved

compile-and-BFBB

107
106
105
104
103
unsolved

102
101

100
100 101 102 103 104 105 106 107 108
BFBB

Figure 24: The comparison in Figure 15, p. 140, restricted to the tasks budgeted with 75%
of the minimal cost of achieving the entire set of subgoals

159

fiDomshlak & Mirkis

(a) blind
108

unsolved

107
compile-and-BFBB

106
105
104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

unsolved

compile-and-BFBB

107
106
105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
BFBB

Figure 25: The comparison in Figure 15, p. 140, restricted to the tasks budgeted with 100%
of the minimal cost of achieving the entire set of subgoals

160

fiOn Oversubscription Planning as Heuristic Search

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

inc-compile-and-BFBB

107
106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

Figure 26: The comparison in Figure 16, p. 142, restricted to the tasks budgeted with 25%
of the minimal cost of achieving the entire set of subgoals

161

fiDomshlak & Mirkis

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

inc-compile-and-BFBB

107
106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

Figure 27: The comparison in Figure 16, p. 142, restricted to the tasks budgeted with 50%
of the minimal cost of achieving the entire set of subgoals

162

fiOn Oversubscription Planning as Heuristic Search

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

inc-compile-and-BFBB

107
106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

Figure 28: The comparison in Figure 16, p. 142, restricted to the tasks budgeted with 75%
of the minimal cost of achieving the entire set of subgoals

163

fiDomshlak & Mirkis

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100 0
10 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

inc-compile-and-BFBB

107
106
105
104
103
102
101
100 0
10 101 102 103 104 105 106 107 108
BFBB

Figure 29: The comparison in Figure 16, p. 142, restricted to the tasks budgeted with 100%
of the minimal cost of achieving the entire set of subgoals

164

fiOn Oversubscription Planning as Heuristic Search

References
Backstrom, C., & Klein, I. (1991). Planning in polynomial time: The SAS-PUBS class.
Computational Intelligence, 7 (3), 181197.
Backstrom, C., & Nebel, B. (1995). Complexity results for SAS+ planning. Computational
Intelligence, 11 (4), 625655.
Baier, J. A., Bacchus, F., & McIlraith, S. (2009). A heuristic search approach to planning
with temporally extended preferences. Artificial Intelligence, 173 (5-6), 593618.
Benton, J., Coles, A. J., & Coles, A. I. (2012). Temporal planning with preferences and
time-dependent continuous costs. In Proceedings of the 22nd International Conference
on Automated Planning and Scheduling (ICAPS), pp. 210.
Benton, J., Do, M., & Kambhampati, S. (2009). Anytime heuristic search for partial satisfaction planning. Artificial Intelligence, 173 (5-6), 562592.
Benton, J., van den Briel, M., & Kambhampati, S. (2007). A hybrid linear programming
and relaxed plan heuristic for partial satisfaction planning problems. In Proceedings
of the Seventeenth International Conference on Automated Planning and Scheduling
(ICAPS), pp. 3441.
Bertsimas, D., & Vempala, S. (2004). Solving convex programs by random walks. Journal
of the ACM, 51 (4), 540556.
Bonet, B. (2013). An admissible heuristic for SAS+ planning obtained from the state
equation. In Proceedings of the 23rd International Joint Conference on Artificial
Intelligence (IJCAI), pp. 22682274.
Bonet, B., & Geffner, H. (2001). Planning as heuristic search. Artificial Intelligence, 129 (1
2), 533.
Bonet, B., & Geffner, H. (2008). Heuristics for planning with penalties and rewards formulated in logic and computed through circuits. Artificial Intelligence, 172 (12-13),
15791604.
Bonet, B., & Helmert, M. (2010). Strengthening landmark heuristics via hitting sets. In
Proceedings of the 19th European Conference on Artificial Intelligence (ECAI), pp.
329334.
Brafman, R. I., & Chernyavsky, Y. (2005). Planning with goal preferences and constraints.
In Proceedings of the International Conference on Automated Planning and Scheduling, pp. 182191.
Clarke, E., Grumberg, O., & Peled, D. (1999). Model Checking. MIT Press.
Coles, A. I., Fox, M., Long, D., & Smith, A. J. (2008). Additive-disjunctive heuristics for
optimal planning. In Proceedings of the 18th International Conference on Automated
Planning and Scheduling (ICAPS), pp. 4451.
Coles, A. J., Coles, A., Fox, M., & Long, D. (2013). A hybrid LP-RPG heuristic for modelling
numeric resource flows in planning. Journal of Artificial Intelligence Research, 46,
343412.
165

fiDomshlak & Mirkis

Coles, A. J., & Coles, A. I. (2011). LPRPG-P: Relaxed plan heuristics for planning with
preferences. In Proceedings of the 21st International Conference on Automated Planning and Scheduling (ICAPS), pp. 3745.
Cousot, P., & Cousot, R. (1992). Abstract interpretation frameworks. Journal of Logic and
Computation, 2 (4), 511547.
Dantzig, G. B. (1963). Linear Programming and Extensions. Princeton University Press.
Dantzig, T. (1930). Number: The Language of Science. Macmillan.
Desrochers, M., & Soumis, F. (1988). A generalized permanent labelling algorithm for
the shortest path problem with time windows. Information Systems and Operations
Research, 26, 191212.
Do, M. B., Benton, J., van den Briel, M., & Kambhampati, S. (2007). Planning with goal
utility dependencies. In Proceedings of the 20th International Joint Conference on
Artificial Intelligence (IJCAI), pp. 18721878.
Domshlak, C., Hoffmann, J., & Sabharwal, A. (2009). Friends or foes? On planning as
satisfiability and abstract CNF encodings. Journal of Artificial Intelligence Research,
36, 415469.
Domshlak, C., Katz, M., & Lefler, S. (2012). Landmark-enhanced abstraction heuristics.
Artificial Intelligence, 189, 4868.
Dudzinski, K., & Walukiewicz, S. (1987). Exact methods for the Knapsack problem and its
generalizations. European Journal of Operational Research, 28, 321.
Dvorak, F., & Bartak, R. (2010). Integrating time and resources into planning. In Proceedings of the 22nd IEEE International Conference on Tools with Artificial Intelligence
(ICTAI), pp. 7178.
Edelkamp, S. (2001). Planning with pattern databases. In Proceedings of the European
Conference on Planning (ECP), pp. 8490.
Edelkamp, S. (2003). Taming numbers and durations in the model checking integrated
planning system. Journal of Artificial Intelligence Research, 20, 195238.
Fikes, R. E., & Nilsson, N. (1971). STRIPS: A new approach to the application of theorem
proving to problem solving. Artificial Intelligence, 2, 189208.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal
planning problems. Journal of Artificial Intelligence Research, 20, 61124.
Garey, M. R., & Johnson, D. S. (1978). Computers and Intractability: A Guide to the Theory
of NP-Completeness. W.H. Freeman and Company, New York.
Geffner, H., & Bonet, B. (2013). A Concise Introduction to Models and Methods for Automated Planning. Synthesis Lectures on Artificial Intelligence and Machine Learning.
Morgan & Claypool.
Gerevini, A., Haslum, P., Long, D., Saetti, A., & Dimopoulos, Y. (2009). Deterministic
planning in the fifth international planning competition: PDDL3 and experimental
evaluation of the planners. Artificial Intelligence, 173 (5-6), 619668.
166

fiOn Oversubscription Planning as Heuristic Search

Gerevini, A., Saetti, A., & Serina, I. (2003). Planning through stochastic local search and
temporal action graphs in LPG. Journal of Artificial Intelligence Research, 20, 239
290.
Gerevini, A., Saetti, A., & Serina, I. (2008). An approach to efficient planning with numerical
fluents and multi-criteria plan quality. Artificial Intelligence, 172 (8-9), 899944.
Grotschel, M., Lovasz, L., & Schrijver, A. (1981). The ellipsoid method and its consequences
theorems in combinatorial optimization. Combinatorica, 1, 169197.
Handler, G., & Zang, I. (1980). A dual algorithm for the constrained shortest path problem.
Networks, 10, 293310.
Haslum, P. (2013). Heuristics for bounded-cost search. In Proceedings of the 23rd International Conference on Automated Planning and Scheduling (ICAPS), pp. 312316.
Haslum, P., Bonet, B., & Geffner, H. (2005). New admissible heuristics for domainindependent planning. In Proceedings of the 20th National Conference on Artificial
Intelligence (AAAI), pp. 11631168.
Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independent
construction of pattern database heuristics for cost-optimal planning. In Proceedings
of the 19th National Conference on Artificial Intelligence (AAAI), pp. 10071012.
Haslum, P., & Geffner, H. (2000). Admissible heuristics for optimal planning. In Proceedings of the 15th International Conference on Artificial Intelligence Planning Systems
(AIPS), pp. 140149.
Haslum, P., & Geffner, H. (2001). Heuristic planning with time and resources. In Proceedings
of the 6th European Conference on Planning (ECP), pp. 107112.
Helmert, M. (2002). Decidability and undecidability results for planning with numerical
state variables. In Proceedings of the Sixth International Conference on Artificial
Intelligence Planning and Scheduling (AIPS), pp. 4453.
Helmert, M. (2006). The Fast Downward planning system. Journal of Artificial Intelligence
Research, 26, 191246.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths and abstractions: Whats
the difference anyway?. In Proceedings of the 19th International Conference on Automated Planning and Scheduling (ICAPS), pp. 162169.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics for optimal
sequential planning. In Proceedings of the 17th International Conference on Automated
Planning and Scheduling (ICAPS), pp. 200207.
Helmert, M., Haslum, P., Hoffmann, J., & Nissim, R. (2014). Merge-and-shrink abstraction:
A method for generating lower bounds in factored state spaces. Journal of the ACM,
61 (3), 16:163.
Hoffmann, J. (2003). The Metric-FF planning system: Translating ignoring delete lists
to numeric state variables. Journal of Artificial Intelligence Research, 20, 291341.
Hoffmann, J., Gomes, C. P., Selman, B., & Kautz, H. A. (2007). SAT encodings of statespace reachability problems in numeric domains. In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI), pp. 19181923.
167

fiDomshlak & Mirkis

Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through
heuristic search. Journal of Artificial Intelligence Research, 14, 253302.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks in planning. Journal
of Artificial Intelligence Research, 22, 215278.
Karp, R. (1972). Reducibility among combinatorial problems. In Complexity of Computer
Computations, pp. 85103. Plenum Press, New York.
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning with landmarks. In Proceedings
of the International Joint Conference on Artificial Intelligence (IJCAI-09), pp. 1728
1733.
Katz, M., & Domshlak, C. (2010a). Implicit abstraction heuristics. Journal of Artificial
Intelligence Research, 39, 51126.
Katz, M., & Domshlak, C. (2010b). Optimal admissible composition of abstraction heuristics. Artificial Intelligence, 174, 767798.
Kellerer, H., Pferschy, U., & Pisinger, D. (2004). Knapsack Problems. Springer-Verlag
Berlin.
Keyder, E., & Geffner, H. (2009). Soft goals can be compiled away. Journal of Artificial
Intelligence Research, 36, 547556.
Koehler, J. (1998). Planning under resource constraints. In Proceedings of the 13th European
Conference on Artificial Intelligence (ECAI), pp. 489493.
Mirkis, V., & Domshlak, C. (2013). Abstractions for oversubscription planning. In Proceedings of the 23rd International Conference on Automated Planning and Scheduling
(ICAPS), pp. 153161.
Mirkis, V., & Domshlak, C. (2014). Landmarks in oversubscription planning. In Proceedings
of the 23rd European Conference on Artificial Intelligence (ECAI), pp. 633638.
Nakhost, H., Hoffmann, J., & Muller, M. (2012). Resource-constrained planning: A Monte
Carlo random walk approach. In Proceedings of the 22nd International Conference on
Automated Planning and Scheduling (ICAPS), pp. 181189.
Nebel, B. (2000). On the compilability and expressive power of propositional planning
formalisms. Journal of Artificial Intelligence Research, 12, 271315.
Nemirovsky, A., & Yudin, N. (1994). Interior-Point Polynomial Methods in Convex Programming. SIAM.
Pearl, J. (1984). Heuristics - Intelligent Search Strategies for Computer Problem Solving.
Addison-Wesley.
Pommerening, F., & Helmert, M. (2013). Incremental LM-Cut. In Proceedings of the 23rd
International Conference on Automated Planning and Scheduling (ICAPS), pp. 162
170, Rome, Italy.
Porteous, J., Sebastia, L., & Hoffmann, J. (2001). On the extraction, ordering, and usage
of landmarks in planning. In Proceedings of the 6th European Conference on Planning
(ECP 01), pp. 3749.
168

fiOn Oversubscription Planning as Heuristic Search

Punnen, A. P. (1992). K-sum linear programming. The Journal of the Operational Research
Society, 43 (4), 359363.
Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks revisited. In Proceedings of
the 23rd AAAI Conference on Artificial Intelligence (AAAI-08), pp. 975982.
Russell, S., & Norvig, P. (2009). Artificial Intelligence: A Modern Approach (3 edition).
Pearson.
Sanchez, R., & Kambhampati, S. (2005). Planning graph heuristics for selecting objectives in over-subscription planning problems. In Proceedings of the 15th International
Conference on Automated Planning and Scheduling (ICAPS), pp. 192201.
Smith, D. (2004). Choosing objectives in over-subscription planning. In Proceedings of the
14th International Conference on Automated Planning and Scheduling (ICAPS), pp.
393401.
Thayer, J. T., & Ruml, W. (2011). Bounded suboptimal search: A direct approach using
inadmissible estimates. In Proceedings of the 22nd International Joint Conference on
Artificial Intelligence (IJCAI), pp. 674679.
Thayer, J. T., Stern, R. T., Felner, A., & Ruml, W. (2012). Faster bounded-cost search
using inadmissible estimates. In Proceedings of the 22nd International Conference on
Automated Planning and Scheduling (ICAPS), pp. 270278.
van den Briel, M., Sanchez, R., Do, M. B., & Kambhampati, S. (2004). Effective approaches
for partial satisfaction (over-subscription) planning. In Proceedings of the 19th AAAI
Conference on Artificial Intelligence (AAAI), pp. 562569.
van den Briel, M., Benton, J., Kambhampati, S., & Vossen, T. (2007). An LP-based heuristic for optimal planning. In Proceedings of the 13th International Conference on
Principles and Practice of Constraint Programming (CP), pp. 651665.
Yang, F., Culberson, J., Holte, R., Zahavi, U., & Felner, A. (2008). A general theory
of additive state space abstractions. Journal of Artificial Intelligence Research, 32,
631662.

169

fi