Journal of Artificial Intelligence Research 43 (2012) 329-351

Submitted 11/11; published 03/12

Local Consistency and SAT-Solvers
Peter Jeavons
Justyna Petke

Peter.Jeavons@cs.ox.ac.uk
Justyna.Petke@cs.ox.ac.uk

Department of Computer Science, University of Oxford
Wolfson Building, Parks Road, Oxford, OX1 3QD, UK

Abstract
Local consistency techniques such as k-consistency are a key component of specialised
solvers for constraint satisfaction problems. In this paper we show that the power of
using k-consistency techniques on a constraint satisfaction problem is precisely captured by
using a particular inference rule, which we call negative-hyper-resolution, on the standard
direct encoding of the problem into Boolean clauses. We also show that current clauselearning SAT-solvers will discover in expected polynomial time any inconsistency that can
be deduced from a given set of clauses using negative-hyper-resolvents of a fixed size. We
combine these two results to show that, without being explicitly designed to do so, current
clause-learning SAT-solvers efficiently simulate k-consistency techniques, for all fixed values
of k. We then give some experimental results to show that this feature allows clause-learning
SAT-solvers to efficiently solve certain families of constraint problems which are challenging
for conventional constraint-programming solvers.

1. Introduction
One of the oldest and most central ideas in constraint programming, going right back to
Montanaris original paper in 1974, is the idea of using local consistency techniques to prune
the search space (Bessiere, 2006). The idea of arc-consistency was introduced by Mackworth
(1977), and generalised to k-consistency by Freuder (1978). Modern constraint solvers
generally employ specialised propagators to prune the domains of variables to achieve some
form of generalised arc-consistency, but typically do not attempt to enforce higher levels of
consistency, such as path-consistency.
By contrast, the software tools developed to solve propositional satisfiability problems,
known as SAT-solvers, generally use logical inference techniques, such as unit propagation
and clause-learning, to prune the search space.
One of the most surprising empirical findings of the last few years has been the remarkably good performance of general SAT-solvers in solving constraint satisfaction problems.
To apply such tools to a constraint satisfaction problem one first has to translate the instance into a set of clauses using some form of Boolean encoding (Tamura, Taga, Kitagawa,
& Banbara, 2009; Walsh, 2000). Such encoding techniques tend to obscure the structure of the original problem, and may introduce a very large number of Boolean variables
and clauses to encode quite easily-stated constraints. Nevertheless, in quite a few cases,
such approaches have out-performed more traditional constraint-solving tools (van Dongen,
Lecoutre, & Roussel, 2008, 2009; Petke & Jeavons, 2009).
c
2012
AI Access Foundation. All rights reserved.

fiJeavons & Petke

In this paper we draw on a number of recent analytical approaches to try to account
for the good performance of general SAT-solvers on many forms of constraint problems.
Building on the results of Atserias, Bulatov, and Dalmau (2007), Atserias and Dalmau
(2008), and Hwang and Mitchell (2005), we show that the power of using k-consistency
techniques in a constraint problem is precisely captured by using a single inference rule in
a standard Boolean encoding of that problem. We refer to this inference rule as negativehyper-resolution, and show that any conclusions deduced by enforcing k-consistency can be
deduced by a sequence of negative-hyper-resolution inferences involving Boolean clauses in
the original instance and negative-hyper-resolvents with at most k literals. Furthermore,
by using the approach of Atserias, Fichte, and Thurley (2011), and Pipatsrisawat and
Darwiche (2009), we show that current clause-learning SAT-solvers will mimic the effect of
such deductions in polynomial expected time, even with a random branching strategy. Hence
we show that, although they are not explicitly designed to do so, running a clause-learning
SAT-solver on a straightforward encoding of a constraint problem efficiently simulates the
effects of enforcing k-consistency for all values of k.

2. Preliminaries
In this section we give some background and definitions that will be used throughout the
rest of the paper.
2.1 Constraint Satisfaction Problems and k-Consistency
Definition 1 An instance of the Constraint Satisfaction Problem (CSP) is specified
by a triple (V, D, C), where
 V is a finite set of variables;
 D = {Dv | v  V } where each set Dv is the set of possible values for the variable v,
called the domain of v;
 C is a finite set of constraints. Each constraint in C is a pair (Ri , Si ) where
 Si is an ordered list of mi variables, called the constraint scope;
 Ri is a relation over D of arity mi , called the constraint relation.
Given any CSP instance (V, D, C), a partial assignment is a mapping f from some
S
subset W of V to Dv such that f (v)  Dv for all v  W . A partial assignment satisfies
the constraints of the instance if, for all (R, (v1 , v2 , . . . , vm ))  C such that vj  W for
j = 1, 2, . . . , m, we have (f (v1 ), f (v2 ) . . . , f (vm ))  R. A partial assignment that satisfies
the constraints of an instance is called a partial solution1 to that instance. The set of
variables on which a partial assignment f is defined is called the domain of f , and denoted
Dom(f ). A partial solution g extends a partial solution f if Dom(g)  Dom(f ) and
g(v) = f (v) for all v  Dom(f ). A partial solution with domain V is called a solution.
One way to derive new information about a CSP instance, which may help to determine
whether or not it has a solution, is to use some form of constraint propagation to enforce
1. Note that not all partial solutions extend to solutions.

330

fiLocal Consistency and SAT-Solvers

some level of local consistency (Bessiere, 2006). For example, it is possible to use the notion
of k-consistency, defined below. We note that there are several different but equivalent ways
to define and enforce k-consistency described in the literature (Bessiere, 2006; Cooper, 1989;
Freuder, 1978). Our presentation follows that of Atserias et al. (2007), which is inspired by
the notion of existential k-pebble games introduced by Kolaitis and Vardi (2000).
Definition 2 (Atserias et al., 2007) For any CSP instance P , the k-consistency closure
of P is the set H of partial assignments which is obtained by the following algorithm:
1. Let H be the collection of all partial solutions f of P with |Dom(f )|  k + 1;
2. For every f  H with |Dom(f )|  k and every variable v of P , if there is no g  H
such that g extends f and v  Dom(g), then remove f and all its extensions from H;
3. Repeat step 2 until H is unchanged.
Note that computing the k-consistency closure according to this definition corresponds
precisely to enforcing strong (k+1)-consistency according to the definitions given by Bessiere
(2006), Cooper (1989), and Freuder (1978).
Throughout this paper, we shall assume that the domain of possible values for each
variable in a CSP instance is finite. It is straightforward to show that for any fixed k,
and any fixed maximum domain size, the k-consistency closure of an instance P can be
computed in polynomial time (Atserias et al., 2007; Cooper, 1989).
Note that any solution to P must extend some element of the k-consistency closure of
P . Hence, if the k-consistency closure of P is empty, for some k, then P has no solutions.
The converse is not true in general, but it holds for certain special cases, such as the class of
instances whose structure has tree-width bounded by k (Atserias et al., 2007), or the class
of instances whose constraint relations are 0/1/all relations, as defined in Cooper, Cohen,
and Jeavons (1994), or connected row-convex relations, as defined in Deville, Barette,
and Hentenryck (1997). For these special kinds of instances it is possible to determine in
polynomial time whether or not a solution exists simply by computing the k-consistency
closure, for an appropriate choice of k. Moreover, if a solution exists, then it can be
constructed in polynomial time by selecting each variable in turn, assigning each possible
value, re-computing the k-consistency closure, and retaining an assignment that gives a
non-empty result.
The following result gives a useful condition for determining whether the k-consistency
closure of a CSP instance is empty.
Lemma 1 (Kolaitis & Vardi, 2000) The k-consistency closure of a CSP instance P is
non-empty if and only if there exists a non-empty family H of partial solutions to P such
that:
1. If f  H, then |Dom(f )|  k + 1;
2. If f  H and f extends g, then g  H;
3. If f  H, |Dom(f )|  k, and v 
/ Dom(f ) is a variable of P , then there is some
g  H such that g extends f and v  Dom(g).
A set of partial solutions H satisfying the conditions described in Lemma 1 is sometimes
called a strategy for the instance P (Barto & Kozik, 2009; Kolaitis & Vardi, 2000).
331

fiJeavons & Petke

2.2 Encoding a CSP Instance as a Propositional Formula
One possible approach to solving a CSP instance is to encode it as a propositional formula
over a suitable set of Boolean variables, and then use a program to decide the satisfiability
of that formula. Many such programs, known as SAT-solvers, are now available and can
often efficiently handle problems with thousands, or sometimes even millions, of Boolean
variables (Zhang & Malik, 2002).
Several different ways of encoding a CSP instance as a propositional formula have been
proposed (Prestwich, 2009; Tamura et al., 2009; Walsh, 2000).
Here we consider one common family of encodings, known as sparse encodings (this term
was introduced in Hoos, 1999). For any CSP instance P = (V, D, C), a sparse encoding
introduces a set of Boolean variables of the form xvi for each v  V and each i  Dv . The
Boolean variable xvi is assigned True if and only if the original variable v is assigned the
value i. We will say that a partial assignment f falsifies a clause C if C consists entirely of
literals of the form xvf (v) , for variables v  Dom(f ). Otherwise, we will say that a partial
assignment f satisfies a clause C.
Example 1 Let P be a CSP instance such that V = {u, v, w}, Du = Dv = {0, 1}, Dw =
{0, 1, 2} and C contains a single ternary constraint with scope (u, v, w) specifying that
u  v < w. A sparse encoding of P will introduce seven Boolean variables:
xu0 , xu1 , xv0 , xv1 , xw0 , xw1 , xw2 .
Sparse encodings usually contain certain clauses known as at-least-one and at-most-one
clauses, to ensure that each variable v is assigned a value, say i, and that no other value,
W
j 6= i, is assigned to v. The at-least-one clauses are of the form iDv xvi for each variable
v. The at-most-one clauses can be represented as a set of binary clauses xvi  xvj for all
i, j  Dv with i 6= j.
Example 2 In the case of the CSP instance from Example 1 the at-least-one clauses are:
xu0  xu1 , xv0  xv1 , xw0  xw1  xw2
The at-most-one clauses are:
xu0  xu1 , xv0  xv1 , xw0  xw1 , xw0  xw2 , xw1  xw2
The various different sparse encodings differ in the way they encode the constraints of a
CSP instance. Two methods are most commonly used. The first one encodes the disallowed
variable assignments - the so-called conflicts or no-goods. The direct encoding (Prestwich,
W
2009), for instance, generates a clause vS xvf (v) for each partial assignment f that does
not satisfy the constraint (R, S)  C. Using the direct encoding, the ternary constraint
from Example 1 would be encoded by the following clauses:
xu0  xv0  xw0 ,
xu0  xv1  xw0 ,
xu0  xv1  xw1 ,
xu1  xv0  xw0 ,
332

fiLocal Consistency and SAT-Solvers

xu1  xv0  xw1 ,
xu1  xv0  xw2 ,
xu1  xv1  xw0 ,
xu1  xv1  xw1 .
Another way of translating constraints into clauses is to encode the allowed variable
assignments - the so-called supports. This has been used as the basis for an encoding of
binary CSP instances, known as the support encoding (Gent, 2002), defined as follows.
For each pair of variables v, w in the scope of some constraint, and each value i  Dv ,
W
the support encoding will contain the clause xvi  jA xwj , where A  Dw is the set of
values for the variable w which are compatible with the assignment v = i, according to the
constraint.
Note that the support encoding is defined for binary CSP instances only. However, some
non-binary constraints can be decomposed into binary ones without introducing any new
variables. For instance, the ternary constraint from Example 1 can be decomposed into two
binary constraints specifying that u  v and v < w. Using the support encoding, these
binary constraints would then be represented by the following clauses:
xu0  xv0  xv1 , xu1  xv1 , xv0  xu0 , xv1  xu0  xu1 ,
xv0  xw1  xw2 , xv1  xw2 , xw0 , xw1  xv0 , xw2  xv0  xv1 .
2.3 Inference Rules
Given any set of clauses we can often deduce further clauses by applying certain inference
rules. For example, if we have two clauses of the form C1 x and C2 x, for some (possibly
empty) clauses C1 , C2 , and some variable x, then we can deduce the clause C1  C2 . This
form of inference is known as propositional resolution; the resultant clause is called the
resolvent (Robinson, 1965).
In the next section, we shall establish a close connection between the k-consistency
algorithm and a form of inference called negative-hyper-resolution (Buning & Lettmann,
1999), which we define as follows:
Definition 3 If we have a collection of clauses of the form Ci  xi , for i = 1, 2, . . . , r,
and a clause C0  x1  x2      xr , where each xi is a Boolean variable, and C0 and
each Ci is a (possibly empty) disjunction of negative literals, then we can deduce the clause
C0  C1      Cr .
We call this form of inference negative-hyper-resolution and the resultant clause
C0  C1      Cr the negative-hyper-resolvent.
In the case where C0 is empty, the negative-hyper-resolution rule is equivalent to the
nogood resolution rule described by Hwang and Mitchell (2005) as well as the H5-k rule
introduced by de Kleer (1989) and the nogood recording scheme described by Schiex and
Verfaillie (1993).
Note that the inference obtained by negative-hyper-resolution can also be obtained by a
sequence of standard resolution steps. However, the reason for introducing negative-hyperresolution is that it allows us to deduce the clauses we need in a single step without needing
to introduce intermediate clauses (which may contain up to r  1 more literals than the
333

fiJeavons & Petke

negative-hyper-resolvent). By restricting the size of the clauses we use in this way we are
able to obtain better performance bounds for SAT-solvers in the results below.
Example 3 Assume we have a collection of clauses of the form Ci xi , for i = 1, 2, . . . , r,
and a clause C0  x1  x2      xr , as specified in Definition 3, where each Ci = C0 . The
negative-hyper-resolvent of this set of clauses is C0 .
The clause C0 can also be obtained by a sequence of standard resolution steps, as follows.
First resolve C0  x1  x2      xr with C0  xr to obtain C0  x1  x2      xr1 . Then
resolve this with the next clause, C0  xr1 , and so on for the other clauses, until finally
we obtain C0 . However, in this case the intermediate clause C0 x1 x2   xr1 contains
r  1 more literals than the negative-hyper-resolvent.
Example 4 Note that the no-good clauses in the direct encoding of a binary CSP instance
can each be obtained by a single negative-hyper-resolution step from an appropriate support
clause in the support encoding together with an appropriate collection of at-most-one clauses.
Let A  Dw be the set of values for the variable w which are compatible with the assignment
W
v = i, then the support encoding will contain the clause C = xvi  jA xwj . If there are
any values k  Dw which are incompatible with the assignment v = i, then we can form the
negative-hyper-resolvent of C with the at-most-one clauses xwk  xwj for each j  A, to
obtain the corresponding no-good clause, xvi  xwk .
A negative-hyper-resolution derivation of a clause C from a set of initial clauses  is
a sequence of clauses C1 , C2 , . . . , Cm , where Cm = C and each Ci follows by the negativehyper-resolution rule from some collection of clauses, each of which is either contained in
 or else occurs earlier in the sequence. The width of this derivation is defined to be the
maximum size of any of the clauses Ci . If Cm is the empty clause, then we say that the
derivation is a negative-hyper-resolution refutation of .

3. k-Consistency and Negative-Hyper-Resolution
It has been pointed out by many authors that enforcing local consistency is a form of
inference on relations analogous to the use of the resolution rule on clauses (Bacchus, 2007;
Bessiere, 2006; Hwang & Mitchell, 2005; Rish & Dechter, 2000). The precise strength of the
standard resolution inference rule on the direct encoding of a CSP instance was considered
in the work of Walsh (2000), where it was shown that unit resolution (where one of the
clauses being resolved consists of a single literal), corresponds to enforcing a weak form of
local consistency known as forward checking. Hwang and Mitchell (2005) pointed out that
the standard resolution rule with no restriction on clause length is able to simulate all the
inferences made by a k-consistency algorithm. Atserias and Dalmau (2008) showed that
the standard resolution rule restricted to clauses with at most k literals, known as the kresolution rule, can be characterised in terms of the Boolean existential (k +1)-pebble game.
It follows that on CSP instances with Boolean domains this form of inference corresponds
to enforcing k-consistency. An alternative proof that k-resolution achieves k-consistency for
instances with Boolean domains is given in the book by Hooker (2006, Thm. 3.22).
Here we extend these results a little, to show that for CSP instances with arbitrary
finite domains, applying the negative-hyper-resolution rule on the direct encoding to obtain
334

fiLocal Consistency and SAT-Solvers

clauses with at most k literals corresponds precisely to enforcing k-consistency. A similar
relationship was stated in the work of de Kleer (1989), but a complete proof was not given.
Note that the bound, k, that we impose on the size of the negative-hyper-resolvents,
is independent of the domain size. In other words, using this inference rule we only need
to consider inferred clauses of size at most k, even though we make use of clauses in the
encoding whose size is equal to the domain size, which may be arbitrarily large.
Theorem 1 The k-consistency closure of a CSP instance P is empty if and only if its direct
encoding as a set of clauses has a negative-hyper-resolution refutation of width at most k.
The proof is broken down into two lemmas inspired by Lemmas 2 and 3 in the work
of Atserias and Dalmau (2008).
Lemma 2 Let P be a CSP instance, and let  be its direct encoding as a set of clauses.
If  has no negative-hyper-resolution refutation of width k or less, then the k-consistency
closure of P is non-empty.
Proof. Let V be the set of variables of P , where each v  V has domain Dv , and let
X = {xvi | v  V, i  Dv } be the corresponding set of Boolean variables in . Let  be the
set of all clauses having a negative-hyper-resolution derivation from  of width at most k.
By the definition of negative-hyper-resolution, every non-empty clause in  consists entirely
of negative literals.
Now let H be the set of all partial assignments for P with domain size at most k + 1
that do not falsify any clause in    under the direct encoding.
Consider any element f  H. By the definition of H, f does not falsify any clause of
, so by the definition of the direct encoding, every element of H is a partial solution to
P . Furthermore, if f extends g, then g is also an element of H, because g makes fewer
assignments than f and hence cannot falsify any additional clauses to f .
If  has no negative-hyper-resolution refutation of width at most k, then  does not
contain the empty clause, so H contains (at least) the partial solution with empty domain,
and hence H is not empty.
Now let f be any element of H with |Dom(f )|  k and let v be any variable of P
that is not in Dom(f ). For any partial assignment g that extends f and has Dom(g) =
Dom(f )  {v} we have that either g  H or else there exists a clause in    that is
falsified by g. Since g is a partial assignment, any clause C in    that is falsified by g,
must consist entirely of negative literals. Hence the literals of C must either be of the form
xwf (w) for some w  Dom(f ), or else xvg(v) . Moreover, any such clause must contain the
literal xvg(v) , or else it would already be falsified by f .
Assume, for contradiction, that H does not contain any assignment g that extends f and
has Dom(g) = Dom(f )  {v}. In that case, we have that, for each i  Dv ,    contains a
clause Ci consisting of negative literals of the form xwf (w) for some w  Dom(f ), together
with the literal xvi . Now consider the clause, C, which is the negative-hyper-resolvent
W
of these clauses Ci and the at-least-one clause iDv xvi . The clause C consists entirely
of negative literals of the form xwf (w) for some w  Dom(f ), so it has width at most
|Dom(f )|  k, and hence is an element of . However C is falsified by f , which contradicts
the choice of f . Hence we have shown that for all f  H with |Dom(f )|  k, and for
335

fiJeavons & Petke

all variables v such that v 6 Dom(f ), there is some g  H such that g extends f and
v  Dom(g).
We have shown that H satisfies all the conditions required by Lemma 1, so we conclude
that the k-consistency closure of P is non-empty.
2

Lemma 3 Let P be a CSP instance, and let  be its direct encoding as a set of clauses.
If the k-consistency closure of P is non-empty, then  has no negative-hyper-resolution
refutation of width k or less.
Proof. Let V be the set of variables of P , where each v  V has domain Dv , and let
X = {xvi | v  V, i  Dv } be the corresponding set of Boolean variables in .
By Lemma 1, if the k-consistency closure of P is non-empty, then there exists a nonempty set H of partial solutions to P which satisfies the three properties described in
Lemma 1.
Now consider any negative-hyper-resolution derivation  from  of width at most k. We
show by induction on the length of this derivation that the elements of H do not falsify any
clause in the derivation. First we note that the elements of H are partial solutions, so they
satisfy all the constraints of P , and hence do not falsify any clause of . This establishes
the base case. Assume, for induction, that all clauses in the derivation earlier than some
clause C are not falsified by any element of H.
Note that, apart from the at-least-one clauses, all clauses in  and  consist entirely of
negative literals. Hence we may assume, without loss of generality, that C is the negativehyper-resolvent of a set of clauses  = {Ci  xvi | i  Dv } and the at-least-one clause
W
iDv xvi , for some fixed variable v.
If f  H falsifies C, then the literals of C must all be of the form xwf (w) , for some
w  Dom(f ). Since the width of the derivation is at most k, C contains at most k literals,
and hence we may assume that |Dom(f )|  k. But then, by the choice of H, there must
exist some extension g of f in H such that v  Dom(g). Any such g will falsify some
clause in , which contradicts our inductive hypothesis. Hence no f  H falsifies C, and,
in particular, C cannot be empty.
It follows that no negative-hyper-resolution derivation of width at most k can contain
the empty clause.
2
Note that the proof of Theorem 1 applies to any sparse encoding that contains the
at-least-one clauses for each variable, and where all other clauses are purely negative. We
will call such an encoding a negative sparse encoding. As well as the direct encoding, other
negative sparse encodings exist. For example, we may use negative clauses that involve only
a subset of the variables in the scope of some constraints (to forbid tuples where all possible
extensions to the complete scope are disallowed by the constraint). Another example of
a negative sparse encoding is a well-known variant of the direct encoding in which the
at-most-one clauses are omitted.
Corollary 1 The k-consistency closure of a CSP instance P is empty if and only if any
negative sparse encoding of P has a negative-hyper-resolution refutation of width at most k.
336

fiLocal Consistency and SAT-Solvers

4. Negative-Hyper-Resolution and SAT-Solvers
In this section we adapt the machinery from Atserias et al. (2011), and Pipatsrisawat and
Darwiche (2009) to show that for any fixed k, the existence of a negative-hyper-resolution
refutation of width k is likely to be discovered by a SAT-solver in polynomial-time using
standard clause learning and restart techniques, even with a totally random branching
strategy.
Note that previous results about the power of clause-learning SAT-solvers have generally
assumed an optimal branching strategy (Beame, Kautz, & Sabharwal, 2004; Pipatsrisawat
& Darwiche, 2009) - they have shown what solvers are potentially capable of doing, rather
than what they are likely to achieve in practice. An important exception is the paper
by Atserias et al. (2011), which gives an analysis of likely behaviour, but relies on the
existence of a standard resolution proof of bounded width. Here we show that the results
of Atserias et al. can be extended to hyper-resolution proofs, which can be shorter and
narrower than their associated standard resolution proofs.
We will make use of the following terminology from Atserias et al. (2011). For a clause
C, a Boolean variable x, and a truth value a  {0, 1}, the restriction of C by the assignment
x = a, denoted C|x=a , is defined to be the constant 1, if the assignment satisfies the clause,
or else the clause obtained by deleting from C any literals involving the variable x. For
any sequence of assignments S of the form (x1 = a1 , x2 = a2 , . . . , xr = ar ) we write C|S to
denote the result of computing the restriction of C by each assignment in turn. If C|S is
empty, then we say that the assignments in S falsify the clause C. For a set of clauses ,
we write |S to denote the set {C|S | C  } \ {1}.
Most current SAT-solvers operate in the following way (Atserias et al., 2011; Pipatsrisawat & Darwiche, 2009). They maintain a database of clauses  and a current state
S, which is a partial assignment of truth values to the Boolean variables in the clauses of
. A high-level description of the algorithms used to update the clause database and the
state, derived from the description given in Atserias et al., is shown in Algorithm 1 (a similar framework, using slightly different terminology, is given in Pipatsrisawat & Darwiche,
2009).
Now consider a run of the algorithm shown in Algorithm 1, started with the initial
database , and the empty state S0 , until it either halts or discovers a conflict (i.e.,   |S ).
Such a run is called a complete round started with , and we represent it by the sequence
of states S0 , . . . , Sm , that the algorithm maintains. Note that each state Si extends the
state Si1 by a single assignment to a Boolean variable, which may be either a decision
assignment or an implied assignment.
More generally, a round is an initial segment S0 , S1 , . . . , Sr of a complete round started
with , up to a state Sr such that either |Sr contains the empty clause, or |Sr does not
contain any unit clause. For any clause C, we say that a round S0 , S1 , . . . , Sr satisfies C if
C|Sr = 1, and we say that the round falsifies C if C|Sr is empty.
If S0 , S1 , . . . , Sr is a round started with , and |Sr contains the empty clause, then
the algorithm either reports unsatisfiability or learns a new clause: such a round is called
conclusive. If a round is not conclusive we call it inconclusive 2 . Note that if S0 , S1 , . . . , Sr
is an inconclusive round started with , then |Sr does not contain the empty clause,
2. Note that a complete round that assigns all variables and reports satisfiability is called inconclusive.

337

fiJeavons & Petke

and does not contain any unit clauses. Hence, for any clause C  , if Sr falsifies all the
literals of C except one, then it must satisfy the remaining literal, and hence satisfy C. This
property of clauses is captured by the following definition.
Definition 4 (Atserias et al., 2011) Let  be a set of clauses, C a non-empty clause, and
l a literal of C. We say that  absorbs C at l if every inconclusive round started with 
that falsifies C \ {l} satisfies C.
If  absorbs C at each literal l in C, then we simply say that  absorbs C.
Note that a closely related notion is introduced by Pipatsrisawat and Darwiche (2009) for
clauses that are not absorbed by a set of clauses ; they are referred to as 1-empowering with
respect to . (The exact relationship between 1-empowering and absorption is discussed
in Atserias et al., 2011.)
We will now explore the relationship between absorption and negative-hyper-resolution.
Example 5 Let  be the direct encoding of a CSP instance P = (V, D, C), where V =
{u, v, w}, Du = Dv = Dw = {1, 2} and C contains two binary constraints: one forbids the
assignment of the value 1 to u and v simultaneously, and the other forbids the simultaneous
assignment of the value 2 to u and 1 to w. Let C also contain a ternary constraint that
forbids the assignment of the value 2 to all three variables simultaneously.
 = { xu1  xu2 , xv1  xv2 , xw1  xw2 ,
xu1  xu2 , xv1  xv2 , xw1  xw2 ,
xu1  xv1 , xu2  xw1 , xu2  xv2  xw2 }.
The clause xv1  xw1 is not contained in , but can be obtained by negative-hyperresolution from the clauses xu1  xu2 , xu1  xv1 , xu2  xw1 .
This clause is absorbed by , since every inconclusive round that sets xv1 = true must
set xw1 = f alse by unit propagation, and every inconclusive round that sets xw1 = true
must set xv1 = f alse also by unit propagation.
Example 5 indicates that clauses that can be obtained by negative hyper-resolution from a
set of clauses  are sometimes absorbed by . The next result clarifies when this situation
holds.
Lemma 4 Any negative-hyper-resolvent of a set of disjoint clauses is absorbed by that set
of clauses.
Proof. Let C be the negative-hyper-resolvent of a set of clauses  = {Ci  xi | i =
1, 2, . . . , r} and a clause C 0 = C0  x1  x2      xr , where each Ci is a (possibly empty)
disjunction of negative literals, for 0  i  r. Then C = C0  C1      Cr by Definition 3.
By Definition 4, we must show that   C 0 absorbs C at each of its literals. Assume all
but one of the literals of C are falsified. Since the set of clauses   C 0 are assumed to be
disjoint, the remaining literal l must belong to exactly one of the clauses in this set. There
are two cases to consider.
1. If l belongs to the clause C 0 , then all clauses in  have all but one literals falsified, so
the remaining literal xi in each of these clauses is set to true, by unit propagation.
Hence all literals in C 0 are falsified, except for l, so l is set to true, by unit propagation.
338

fiLocal Consistency and SAT-Solvers

2. If l belongs to one of the clauses Ci  xi , then all of the remaining clauses in  have
all but one literals falsified, so the corresponding literals xj are set to true, by unit
propagation. Hence all literals in C 0 are falsified, except for xi , so xi is set to true, by
unit propagation. But now all literals in Ci  xi are falsified, except for l, so l is set
to true by unit propagation.
2
The next example shows that the negative-hyper-resolvent of a set of clauses that is not
disjoint will not necessarily be absorbed by those clauses.
Example 6 Recall the set of clauses  given in Example 5, which is the direct encoding of
a CSP instance with three variables {u, v, w}, each with domain {1, 2}.
The clause xu2  xv2 is not contained in , but can be obtained by negative-hyperresolution from the clauses xw1  xw2 , xu2  xv2  xw2 , xu2  xw1 .
This clause is not absorbed by , since an inconclusive round that sets xv2 = true will
not necessarily ensure that xu2 = f alse by unit propagation.
The basic approach we shall use to establish our main results below is to show that any
clauses that can be obtained by bounded width negative-hyper-resolution from a given set
of clauses, but are not immediately absorbed (such as the one in Example 6) are likely
to become absorbed quite quickly because of the additional clauses that are added by
the process of clause learning. Hence a clause-learning SAT-solver is likely to fairly rapidly
absorb all of the clauses that can be derived from its original database of clauses by negativehyper-resolution. In particular, if the empty clause can be derived by negative-hyperresolution, then the solver will fairly rapidly absorb some literal and its complement, and
hence report unsatisfiability (see the proof of Theorem 2 for details).
The following key properties of absorption are established by Atserias et al. (2011).
Lemma 5 (Atserias et al., 2011) Let  and 0 be sets of clauses, and let C and C 0 be
non-empty clauses.
1. If C belongs to , then  absorbs C;
2. If C  C 0 and  absorbs C, then  absorbs C 0 ;
3. If   0 and  absorbs C, then 0 absorbs C.
To allow further analysis, we need to make some assumptions about the learning scheme,
the restart policy and the branching strategy used by our SAT-solver.
The learning scheme is a rule that creates and adds a new clause to the database
whenever there is a conflict. Such a clause is called a conflict clause, and each of its literals
is falsified by some assignment in the current state. If a literal is falsified by the i-th decision
assignment, or some later implied assignment before the (i + 1)-th decision assignment, it is
said to be falsified at level i. If a conflict clause contains exactly one literal that is falsified
at the maximum possible level, it is called an asserting clause (Pipatsrisawat & Darwiche,
2009; Zhang, Madigan, Moskewicz, & Malik, 2001).
Assumption 1 The learning scheme chooses an asserting clause.
339

fiJeavons & Petke

Algorithm 1 Framework for a typical clause-learning SAT-solver
Input:  : set of clauses;
S : partial assignment of truth values to variables.
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.

while |S 6=  do
if   |S then
Conflict
if S contains no decision assignments then
print UNSATISFIABLE and halt
else
apply the learning scheme to add a new clause to 
if restart policy says restart then
set S = 
else
select most recent conflict-causing unreversed decision assignment in S
reverse this decision, and remove all later assignments from S
end if
end if
else if {l}  |S for some literal l then
Unit Propagation
add to S the implied assignment x = a which satisfies l
else
Decision
apply the branching strategy to choose a decision assignment x = a
add this decision assignment to S
end if
end while
print SATISFIABLE and output S

Most learning schemes in current use satisfy this assumption (Pipatsrisawat & Darwiche, 2009; Zhang et al., 2001), including the learning schemes called 1UIP and Decision (Zhang et al., 2001).
We make no particular assumption about the restart policy. However, our main result
is phrased in terms of a bound on the expected number of restarts. If the algorithm restarts
after r conflicts, our bound on the expected number of restarts can simply be multiplied
by r to get a bound on the expected number of conflicts. This means that the results
will be strongest if the algorithm restarts immediately after each conflict. In that case,
r = 1 and our bound will also bound the expected number of conflicts. Existing SATsolvers typically do not employ such an aggressive restart policy, but we note the remark
in the work of Pipatsrisawat and Darwiche (2009, p.666) that there has been a clear trend
towards more and more frequent restarts for modern SAT solvers.
The branching strategy determines which decision assignment is chosen after an inconclusive round that is not complete. In most current SAT solvers the strategy is based on
some heuristic measure of variable activity, which is related to the occurrence of a variable in
conflict clauses (Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001). However, to simplify
the probabilistic analysis, we will make the following assumption.

340

fiLocal Consistency and SAT-Solvers

Assumption 2 The branching strategy chooses a variable uniformly at random amongst
the unassigned variables, and assigns it the value TRUE.
As noted by Atserias et al. (2011), the same analysis we give below can also be applied
to any other branching strategy that randomly chooses between making a heuristic-based
decision or a randomly-based decision. More precisely, if we allow, say, c > 1 rounds of nonrandom decisions between random ones, then the number of required restarts and conflicts
would appear multiplied by a factor of c.
An algorithm that behaves according to the description in Algorithm 1, and satisfies
the assumptions above, will be called a standard randomised SAT-solver.
Theorem 2 If a set of non-empty clauses  over n Boolean variables has a negativehyper-resolution refutation of width k and length m, then the expected number of restarts
requiredby a standard randomised SAT-solver to discover that  is unsatisfiable is less than
mnk 2 nk .
Proof. Let C1 , C2 , . . . , Cm be a negative-hyper-resolution refutation of width k from ,
where Cm is the first occurrence of the empty clause. Since each clause in  is non-empty,
Cm must be derived by negative-hyper-resolution from some collection of negative literals
x1 , x2 , . . . xd and a purely positive clause x1  x2      xd  .
Now consider a standard randomised SAT-solver started with database . Once all of
the unit clauses xi are absorbed by the current database, then, by Definition 4, any further
inconclusive round of the algorithm must assign all variables xi false, and hence falsify the
clause x1  x2     xd . Since this happens even when no decision assignments are made, the
SAT-solver will report unsatisfiability.
It only remains to bound the expected number of restarts required until each clause
Ci is absorbed, for 1  i < m. Let each Ci be the negative-hyper-resolvent of clauses
0 x , together with a clause C = C x x   x
Ci1 , Ci2 , . . . , Cir , each of the form Cij
j
i0
0
1
2
r
from , where C0 is a (possibly empty) disjunction of negative literals. Assume also that
each clause Cij is absorbed by  for j = 0, 1, . . . , r.
If  absorbs Ci , then no further learning or restarts are needed, so assume now that 
does not absorb Ci . By Definition 4, this means that there exists some literal l and some
inconclusive round R started with  that falsifies Ci \ {l} and does not satisfy Ci . Note
that R must leave the literal l unassigned, because one assignment would satisfy Ci and
0 , and hence force all of the literals x used in the
the other would falsify C0 and each Cij
j
negative-hyper-resolution step to be satisfied, because each Cij is absorbed by , so Ci0
would be falsified, contradicting the fact that R is inconclusive.
Hence, if the branching strategy chooses to falsify the literals Ci \ {l} whenever it has
a choice, it will construct an inconclusive round R0 where l is unassigned (since all the
decision assignments in R0 are also assigned the same values in R, any implied assignments
in R0 must also be assigned the same values3 in R, but we have shown that R leaves l
unassigned). If the branching strategy then chooses to falsify the remaining literal l of Ci ,
then the algorithm would construct a conclusive round R00 where Ci0 is falsified, and all
3. See Lemmas 5, 8 and 10 in the work of Atserias et al. (2011) for a more formal statement and proof of
this assertion.

341

fiJeavons & Petke

decision assignments falsify literals in Ci . Hence, by Assumption 1, the algorithm would
then learn some asserting clause C 0 and add it to  to obtain a new set 0 .
Since C 0 is an asserting clause, it contains exactly one literal, l0 , that is falsified at the
highest level in R00 . Hence, any inconclusive round R started with 0 that falsifies Ci \ {l}
will falsify all but one literal of C 0 , and hence force the remaining literal l0 to be satisfied,
by unit propagation. If this new implied assignment for l0 propagates to force l to be true,
then R satisfies Ci , and hence 0 absorbs Ci at l. If not, then the branching strategy can
once again choose to falsify the remaining literal l of Ci , which will cause a new asserting
clause to be learned and added to . Since each new asserting clause forces a new literal to
be satisfied after falsifying Ci \ {l} this process can be repeated fewer than n times before
it is certain that 0 absorbs Ci at l.
Now consider any sequence of k random branching choices. If the first k  1 of these
each falsify a literal of Ci \ {l}, and the final choice falsifies l, then we have shown that the
associated round will reach a conflict, and add an asserting clause to . With a random
branching strategy, as described in Assumption 2, the probability that this happens is at
least the probability that the first k  1 random choices consist of a fixed set of variables
(in some order), and the final choice is the variable associated with l. The number of
random choices that fall in a fixed set follows the hypergeometric distribution, so the overall
1
probability of this is n1 (nk+1)
= 1/(k nk ).
(k1)
To obtain an upper bound on the expected number of restarts, consider the worst case
where we require n asserting clauses to be added to absorb each clause Ci at each of its k
literals l. Since we require only an upper bound,
we will treat each round as an independent
n
trial with success probability p = 1/(k k ), and consider the worst case where we have to
achieve (m  1)nk successes to ensure that Ci for 1  i < m is absorbed. In this case the
total number of restarts will follow a negative binomial distribution, with expected value
(m  1)nk/p. Hence in all cases the expected number of restarts is less than mnk 2 nk . 2
A tighter bound on the number of restarts can be obtained if we focus on the Decision
learning scheme (Atserias et al., 2011; Zhang et al., 2001), as the next result indicates.
Theorem 3 If a set of non-empty clauses  over n Boolean variables has a negative-hyperresolution refutation of width k and length m, then the expected number of restarts required
by a standard randomised SAT-solver
using the Decision learning scheme to discover that

 is unsatisfiable is less than m nk .
Proof. The proof is similar to the proof of Theorem 2, except that the Decision learning scheme has the additional feature that the literals in the chosen conflict clause falsify a
subset of the current decision assignments. Hence in the situation we consider, where the
decision assignments all falsify literals of some clause Ci , this learning scheme will learn a
subset of Ci , and hence immediately absorb Ci , by Lemma 5 (1,2). Hence the maximum
number of learnt clausesrequired is
reduced from (m  1)nk to (m  1), and the probability

is increased from 1/(k nk ) to 1/ nk , giving the tighter bound.
2
Note that a similar argument shows that the standard deviation of the number of restarts
is less than the standard deviation of a negative binomial distribution with parameters m
342

fiLocal Consistency and SAT-Solvers




and 1/ nk , which is less than m nk . Hence, by Chebyshevs inequality (one-tailed version),
the probability that a standard randomised SAT-solver using the decision learning scheme

will discover that  is unsatisfiable after (m + m) nk restarts is greater than 1/2.

5. k-Consistency and SAT-Solvers
By combining Theorem 1 and Theorem 3 we obtain the following result linking k-consistency
and SAT-solvers.
Theorem 4 If the k-consistency closure of a CSP instance P is empty, then the expected
number of restarts required by a standard randomised SAT-solver using the Decision learning scheme to discover that the direct encoding of P is unsatisfiable is O(n2k d2k ), where n
is the number of variables in P and d is the maximum domain size.
Proof. The length m of a negative-hyper-resolution refutation of width k is bounded
Pk
i n
by the number of possible no-goods of length at most
k
for
P
,
which
is
i=1 d i . Hence,



by Theorem 1 and Theorem 3 we obtain a bound of


i n
i=1 d i

Pk

nd
k ,

which is O(n2k d2k ). 2

Hence a standard randomised SAT-solver with a suitable learning strategy will decide
the satisfiability of any CSP instance with tree-width k with O(n2k d2k ) expected restarts,
even when it is set to restart immediately after each conflict. In particular, the satisfiability
of any tree-structured binary CSP instance (i.e., with tree-width 1) will be decided by such
a solver with at most O(n2 d2 ) expected conflicts, which is comparable with the growth rate
of an optimal arc-consistency algorithm for binary constraints. Note that this result cannot
be obtained directly from the work of Atserias et al. (2011), because the direct encoding of
an instance with tree-width k is a set of clauses whose tree-width may be as high as dk.
Moreover, a standard randomised SAT-solver will decide the satisfiability of any CSP
instance, with any structure, within the same polynomial bounds, if the constraint relations
satisfy certain algebraic properties that ensure bounded width (Barto & Kozik, 2009).
Examples of such constraint types include the 0/1/all relations, defined by Cooper et al.
(1994), and the connected row-convex relations, defined by Deville et al. (1997), which
can both be decided by 2-consistency.
It was shown by Gent (2002) that the support encoding of a binary CSP instance can
be made arc-consistent (that is, 1-consistent) by applying unit propagation alone. Hence, a
standard SAT-solver will mimic the effect of enforcing arc-consistency on such an encoding
before making any decisions or restarts. By combining Theorem 4 with the observation in
Example 4 that the direct encoding can be obtained from the support encoding by negativehyper-resolution, we obtain the following corollary concerning the support encoding for all
higher levels of consistency.
Corollary 2 For any k  2, if the k-consistency closure of a binary CSP instance P
is empty, then the expected number of restarts required by a standard randomised SATsolver using the Decision learning scheme to discover that the support encoding of P is
unsatisfiable is O(n2k d2k ), where n is the number of variables in P and d is the maximum
domain size.
343

fiJeavons & Petke

The CSP literature describes many variations on the notion of consistency. In this
paper we have considered k-consistency only. We note that our results can be generalised
to some other types of consistency such as singleton arc-consistency (Bessiere, 2006). The
extension to singleton arc-consistency follows from the recent discovery that if a family of
CSP instances is solvable by enforcing singleton arc-consistency, then the instances have
bounded width (Chen, Dalmau, & Gruien, 2011). In other words, all such instances can
be solved by enforcing k-consistency, for some fixed k. Hence, by Theorem 4, they will be
solved in polynomial expected time by a standard randomised SAT-solver.

6. Experimental Results
The polynomial upper bounds we obtain in this paper are not asymptotic, they apply for
all values of n, m and k. However, they are very conservative, and are likely to be met very
easily in practice.
To investigate how an existing SAT-solver actually performs, we measured the runtime
of the MiniSAT solver (Een & Sorensson, 2003), version 2.2.0, on a family of CSP instances
that can be decided by a fixed level of consistency. For comparison, we also ran our experiments on two state-of-the-art constraint solvers: we used Minion (Gent, Jefferson, &
Miguel, 2006), version 0.12, and the G12 finite domain solver (Nethercote et al., 2007),
version 1.4.
To match the simplified assumptions of our analysis more closely, we ran a further
set of experiments on a core version of MiniSAT in order to get a solver that uses only
unit propagation and conflict-directed learning with restarts. We also modified the solver to
follow the random branching strategy described above. Our solver does not delete any learnt
clauses and uses an extreme restart policy that makes it restart whenever it encounters a
conflict. It uses the same learning scheme as MiniSAT. We refer to this modified solver as
simple-MiniSAT.
As the characteristic feature of the instances tested is their relatively low tree-width,
we also used the Toulbar2 solver (Sanchez et al., 2008). This solver implements the BTD
(Backtracking with Tree-Decomposition) technique which has been shown to be efficient
in practice, in contrast to earlier methods that had been proposed to attempt to exploit
tree-decompositions of the input problem (Jegou & Terrioux, 2003). As the problem of
finding a tree-decomposition of minimal width (i.e., the tree-width) is NP-hard, the BTD
technique uses some approximations (described in Jegou & Terrioux, 2003). We note here
that Toulbar2 is designed for solving optimization problems, namely weighted CSPs, or
WCSPs. In a WCSP instance, certain partial assignments have an associated cost. However,
the Toulbar2 solver can be used to solve standard CSPs by simply setting all costs to 0.
For all of the results, the times given are elapsed times on a Lenovo 3000 N200 laptop
with an Intel Core 2 Duo processor running at 1.66GHz with 2GB of RAM. Each generated
instance was run five times and the mean times and mean number of restarts are shown4 .
Example 7 We consider a family of instances specified by two parameters, w and d. They
have ((d1)w+2)w variables arranged in groups of size w, each with domain {0, ..., d1}.
4. MiniSAT and simple-MiniSAT were run with different seeds for each of the five runs of an instance.
Instances marked with * were run once only. The runtime of simple-MiniSAT on those instances
exceeded 6 hours. Moreover, Toulbar2 was run with parameter B = 1 which enables BTD.

344

fiLocal Consistency and SAT-Solvers

We impose a constraint of arity 2w on each pair of successive groups, requiring that the
sum of the values assigned to the first of these two groups should be strictly smaller than
the sum of the values assigned to the second. This ensures that the instances generated are
unsatisfiable. An instance with w = 2 and d = 2 is shown diagrammatically and defined
using the specification language MiniZinc (Nethercote et al., 2007) in Figure 1 (a) and (b)
respectively5 . A similar format is used for Toulbar2 6 and the same instance encoded in
this format is shown in Figure 1 (c) (note that each hard constraint has cost 0).

(a) Graphical representation.

chain
x1 0 1
x2 0 1
x3 0 1
x4 0 1
x5 0 1
x6 0 1
x7 0 1
x8 0 1
hard( x1 + x2 < x3 + x4 )
hard( x3 + x4 < x5 + x6 )
hard( x5 + x6 < x7 + x8 )

array[1..4] of var 0..1 : X1;
array[1..4] of var 0..1 : X2;
constraint
forall(i in 1..3)(
X1[i] + X2[i] < X1[i + 1] + X2[i + 1]);
solve satisfy;
(b) Specification in MiniZinc.

(c) Specification in cp format.

Figure 1: An example of a CSP instance with w = 2, d = 2 and tree-width = 3.

The structure of the instances described in Example 7 has a simple tree-decomposition as a
path of nodes, with each node corresponding to a constraint scope. Hence the tree-width of
these instances is 2w  1 and they can be shown to be unsatisfiable by enforcing (2w  1)consistency (Atserias et al., 2007). However, these instances cannot be solved efficiently
using standard propagation algorithms which only prune individual domain values.
The structure of the direct encoding of these instances also has a tree-decomposition
with each node corresponding to a constraint scope in the original CSP instance. However,
because the direct encoding introduces d Boolean variables to represent each variable in the
5. In order to run an instance on a CP solver one must usually use a translator to convert the original
model. The MiniZinc distribution provides an mzn2fzn translator while for Minion one can use Tailor
(available at http://www.cs.st-andrews.ac.uk/andrea/tailor/).
6. A cp2wcsp translator and a description of the cp and wcsp formats is available at
http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/SoftCSP.

345

fiJeavons & Petke

original instance, the tree-width of the encoded SAT instances is larger by approximately a
factor of d; it is in fact 2wd  1 (see Figure 2).

(a) Tree-decomposition of the original instance.

(b) Tree-decomposition of its direct
encoding.

Figure 2: Tree-decompositions of the CSP instance from Figure 1.
Table 1 shows the runtimes of simple-MiniSAT and the original MiniSAT solver on
this family of instances, along with times for the two state-of-the-art CP solvers and the
WCSP solver Toulbar2. By far the best solver for this set of instances is Toulbar2,
which is explicitly designed to exploit low tree-width by constructing a tree-decomposition.
For the class of instances we are considering, the widths of the tree-decompositions found
by Toulbar2 matched the tree-widths of the instances tested (i.e., 2w  1).
However, we also note that MiniSAT is remarkably effective in solving these chains
of inequalities, compared to Minion and G12, even though the use of MiniSAT requires
encoding each instance into a large number of clauses with a much larger tree-width than
the original. Although our simplified version of the MiniSAT solver takes a little longer
than the current highly optimised version, it still performs very well on these instances in
comparison with the conventional CP solvers. Moreover, the number of restarts (and hence
the number of conflicts) appears to grow only polynomially with the size of the instance
(see Figure 3). In all cases the actual number of restarts is much lower than the polynomial
upper bound on the expected number of restarts given in Theorem 4.
Our best theoretical upper bounds on the expected run-time were obtained for the
Decision learning scheme (Theorem 4), but the standard version of MiniSAT uses the
1UIP learning scheme with conflict clause minimization. To allow a direct comparison
with these theoretical upper bounds, we implemented the Decision scheme in simpleMiniSAT. As the 1UIP learning scheme has generally been found to be more efficient
in practice (Zhang et al., 2001), we switched off conflict clause minimization in simpleMiniSAT in order to compare the two standard learning schemes and ran a further set of
experiments. We counted the number of restarts for these two modified solvers on instances
of the form described in Example 7 - see Table 2.
346

fiLocal Consistency and SAT-Solvers

group
size
(w)
2
2
2
2
2
2
2
2
2
3
3
3
3
3
4
4
4

domain
size
(d)
2
3
4
5
6
7
8
9
10
2
3
4
5
6
2
3
4

CSP
variables
(n)
8
12
16
20
24
28
32
36
40
15
24
33
42
51
24
40
56

Minion

G12

(sec)
0.055
0.053
0.057
0.084
1.048
47.295
> 20 min
> 20 min
> 20 min
0.055
0.412
> 20 min
> 20 min
> 20 min
0.060
> 20 min
> 20 min

(sec)
0.010
0.011
0.013
0.047
0.959
122.468
> 20 min
> 20 min
> 20 min
0.010
0.034
7.147
> 20 min
> 20 min
0.015
11.523
> 20 min

Toulbar2

MiniSAT

(sec)
0.021
0.023
0.040
0.091
0.199
0.549
1.214
2.523
4.930
0.024
0.103
0.860
5.646
28.663
0.046
1.246
20.700

(sec)
0.003
0.005
0.015
0.043
0.126
0.362
0.895
2.407
5.656
0.004
0.066
1.334
20.984
383.564
0.012
4.631
1,160.873

simpleMiniSAT
(sec)
0.002
0.007
0.034
0.188
0.789
2.884
9.878
34.352
111.912
0.008
0.503
20.054
817.779
> 20 min
0.118
260.656
> 20 min

simpleMiniSAT
restarts
19
157
820
3 039
7 797
17 599
36 108
65 318
114 827
167
5 039
41 478
210 298
731 860
1 617
108 113
1 322 784*

Table 1: Average performance of solvers on instances from Example 7.
group
size
(w)

domain
size
(d)

CSP
variables
(n)

no. of clauses
in the direct
encoding

2
2
2
2
2
2
2
2
2
3
3
3
3
3
4
4

2
3
4
5
6
7
8
9
10
2
3
4
5
6
2
3

8
12
16
20
24
28
32
36
40
15
24
33
42
51
24
40

49
298
1 162
3 415
8 315
17 724
34 228
61 257
103 205
198
3 141
23 611
113 406
408 720
863
34 666

simpleMiniSAT
1UIP
(sec)
0.002
0.008
0.048
0.272
1.399
5.780
24.417
95.278
309.980
0.009
0.643
53.067
2,266.627
> 6 hours
0.141
603.241

simpleMiniSAT
1UIP
restarts
21
203
1 026
4 068
12 029
27 356
56 193
109 862
199 399
192
5 952
63 952
375 849
1 584 012*
1 937
155 842

simpleMiniSAT
Decision
(sec)
0.002
0.010
0.057
0.323
1.526
6.035
20.436
69.144
207.342
0.012
0.750
71.778
2,036.456
> 6 hours
0.192
938.836

simpleMiniSAT
Decision
restarts
23
267
1 424
5 283
14 104
33 621
64 262
113 460
190 063
287
7 308
91 283
391,664
1 365 481*
2 592
253 153

Table 2: Average performance of simple-MiniSAT with the 1UIP and the Decision learning schemes on instances from Example 7.

347

fiJeavons & Petke

Figure 3: Log-log plot of the number of restarts/conflicts used by simple-MiniSAT on the

instances from Example 7. The solid lines show a growth function of d2w2 nd/w
,
3
where n is the number of CSP variables. This empirically derived polynomial
function appears to fit the experimental data well, and is much lower than the
upper bound on the expected number of restarts calculated in Theorem 4 which
is O(d4w2 n4w2 ).

348

fiLocal Consistency and SAT-Solvers

Although the performance of simple-MiniSAT with the Decision learning scheme
and the 1UIP scheme are significantly worse than the performance of the original simpleMiniSAT solver, only about twice as many restarts were required for each instance. Hence,
our theoretical upper bounds are still easily met for both of these standard learning schemes.

7. Conclusions
We have shown that the notion of k-consistency can be precisely captured by a single
inference rule on the direct encoding of a CSP instance, restricted to deriving only clauses
with at most k literals. We used this to show that a clause-learning SAT-solver with a purely
random branching strategy will simulate the effect of enforcing k-consistency in expected
polynomial time, for all fixed k. This is sufficient to ensure that such solvers are able to
solve certain problem families much more efficiently than conventional CP solvers relying
on GAC-propagation.
In principle clause-learning SAT-solvers can also do much more. It is known that, with
an appropriate branching strategy and restart policy, they are able to p-simulate general
resolution (Beame et al., 2004; Pipatsrisawat & Darwiche, 2009), and general resolution
proofs can be exponentially shorter than the negative-hyper-resolution proofs we have considered here (Hwang & Mitchell, 2005). In practice, it seems that current clause-learning
SAT-solvers with highly-tuned learning schemes, branching strategies and restart policies
are often able to exploit structure in the Boolean encoding of a CSP instance even more
effectively than local consistency techniques. Hence considerable work remains to be done
in understanding the relevant features of instances which they are able to exploit, in order
to predict their effectiveness in solving different kinds of CSP instances.

Acknowledgments
We would like to thank Albert Atserias and Marc Thurley for comments on the conference
version of this paper, as well as the anonymous referees. The provision of an EPSRC
Doctoral Training Award to Justyna Petke is also gratefully acknowledged.
A preliminary version of this paper appeared in Proceedings of the 16th International
Conference on Principles and Practice of Constraint Programming - CP2010.

References
Atserias, A., Bulatov, A. A., & Dalmau, V. (2007). On the power of k-consistency. In
International Colloquium on Automata, Languages and Programming - ICALP07,
pp. 279290.
Atserias, A., & Dalmau, V. (2008). A combinatorial characterization of resolution width.
Journal of Computer and System Sciences, 74 (3), 323334.
Atserias, A., Fichte, J. K., & Thurley, M. (2011). Clause-learning algorithms with many
restarts and bounded-width resolution. Journal of Artificial Intelligence Research
(JAIR), 40, 353373.
Bacchus, F. (2007). GAC via unit propagation. In Principles and Practice of Constraint
Programming - CP07, pp. 133147.
349

fiJeavons & Petke

Barto, L., & Kozik, M. (2009). Constraint satisfaction problems of bounded width. In
Symposium on Foundations of Computer Science - FOCS09, pp. 595603.
Beame, P., Kautz, H. A., & Sabharwal, A. (2004). Towards understanding and harnessing
the potential of clause learning. Journal of Artificial Intelligence Research (JAIR),
22, 319351.
Bessiere, C. (2006). Constraint propagation. In Rossi, F., van Beek, P., & Walsh, T. (Eds.),
Handbook of Constraint Programming, chap. 3. Elsevier.
Buning, H., & Lettmann, T. (1999). Propositional logic: deduction and algorithms. Cambridge tracts in theoretical computer science. Cambridge University Press.
Chen, H., Dalmau, V., & Gruien, B. (2011). Arc consistency and friends. Computing
Research Repository - CoRR, abs/1104.4993.
Cooper, M. C. (1989). An optimal k-consistency algorithm. Artificial Intelligence, 41 (1),
8995.
Cooper, M. C., Cohen, D. A., & Jeavons, P. (1994). Characterising tractable constraints.
Artificial Intelligence, 65 (2), 347361.
de Kleer, J. (1989). A comparison of ATMS and CSP techniques. In International Joint
Conference on Artificial Intelligence - IJCAI89, pp. 290296.
Deville, Y., Barette, O., & Hentenryck, P. V. (1997). Constraint satisfaction over connected
row convex constraints. In International Joint Conference on Artificial Intelligence IJCAI97 (1), pp. 405411.
Een, N., & Sorensson, N. (2003). An extensible SAT-solver. In Theory and Applications of
Satisfiability Testing - SAT03, pp. 502518.
Freuder, E. C. (1978). Synthesizing constraint expressions. Communications of the ACM,
21 (11), 958966.
Gent, I. P. (2002). Arc consistency in SAT. In European Conference on Artificial Intelligence
- ECAI02, pp. 121125.
Gent, I. P., Jefferson, C., & Miguel, I. (2006). Minion: A fast scalable constraint solver. In
European Conference on Artificial Intelligence - ECAI06, pp. 98102.
Hooker, J. N. (2006). Integrated Methods for Optimization (International Series in Operations Research & Management Science). Springer-Verlag New York, Inc., Secaucus,
NJ, USA.
Hoos, H. H. (1999). SAT-encodings, search space structure, and local search performance.
In International Joint Conference on Artificial Intelligence - IJCAI99, pp. 296303.
Hwang, J., & Mitchell, D. G. (2005). 2-way vs. d-way branching for CSP. In Principles and
Practice of Constraint Programming - CP05, pp. 343357.
Jegou, P., & Terrioux, C. (2003). Hybrid backtracking bounded by tree-decomposition of
constraint networks. Artificial Intelligence, 146 (1), 4375.
Kolaitis, P. G., & Vardi, M. Y. (2000). A game-theoretic approach to constraint satisfaction. In Conference on Artificial Intelligence - AAAI00 / Innovative Applications of
Artificial Intelligence Conference - IAAI00, pp. 175181.
350

fiLocal Consistency and SAT-Solvers

Mackworth, A. K. (1977). Consistency in networks of relations. Artificial Intelligence, 8 (1),
99118.
Montanari, U. (1974). Networks of constraints: Fundamental properties and applications to
picture processing. Information Sciences, 7, 95132.
Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering an efficient SAT solver. In Design Automation Conference - DAC01, pp.
530535.
Nethercote, N., Stuckey, P. J., Becket, R., Brand, S., Duck, G. J., & Tack, G. (2007).
MiniZinc: Towards a standard CP modelling language. In Principles and Practice of
Constraint Programming - CP07, pp. 529543.
Petke, J., & Jeavons, P. (2009). Tractable benchmarks for constraint programming. Technical Report RR-09-07, Department of Computer Science, University of Oxford.
Pipatsrisawat, K., & Darwiche, A. (2009). On the power of clause-learning SAT solvers with
restarts. In Principles and Practice of Constraint Programming - CP09, pp. 654668.
Prestwich, S. D. (2009). CNF encodings. In Biere, A., Heule, M., van Maaren, H., & Walsh,
T. (Eds.), Handbook of Satisfiability, pp. 7597. IOS Press.
Rish, I., & Dechter, R. (2000). Resolution versus search: Two strategies for SAT. Journal
of Automated Reasoning, 24 (1/2), 225275.
Robinson, J. A. (1965). A machine-oriented logic based on the resolution principle. Journal
of the ACM, 12 (1), 2341.
Sanchez, M., Bouveret, S., de Givry, S., Heras, F., Jegou, P., Larrosa, J., Ndiaye, S., Rollon,
E., Schiex, T., Terrioux, C., Verfaillie, G., & Zytnicki, M. (2008). Max-CSP competition 2008: Toulbar2 solver description. In Proceedings of the Third International
CSP Solver Competition.
Schiex, T., & Verfaillie, G. (1993). Nogood recording for static and dynamic constraint
satisfaction problems. In International Conference on Tools with Artificial Intelligence
- ICTAI93, pp. 4855.
Tamura, N., Taga, A., Kitagawa, S., & Banbara, M. (2009). Compiling finite linear CSP
into SAT. Constraints, 14 (2), 254272.
van Dongen, M., Lecoutre, C., & Roussel, O. (2008). 3rd international CSP solver competition. Instances and results available at http://www.cril.univ-artois.fr/CPAI08/.
van Dongen, M., Lecoutre, C., & Roussel, O. (2009). 4th international CSP solver competition. Instances and results available at http://www.cril.univ-artois.fr/CPAI09/.
Walsh, T. (2000). SAT v CSP. In Principles and Practice of Constraint Programming CP00, pp. 441456.
Zhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Efficient conflict driven
learning in Boolean satisfiability solver. In International Conference on ComputerAided Design - ICCAD01, pp. 279285.
Zhang, L., & Malik, S. (2002). The quest for efficient Boolean satisfiability solvers. In
Computer Aided Verification - CAV02, pp. 1736.

351

fi