Journal of Artificial Intelligence Research 54 (2015) 471492

Submitted 05/15; published 11/15

Weighted Regret-Based Likelihood: A New Approach to
Describing Uncertainty
Joseph Y. Halpern

halpern@cs.cornell.edu

Computer Science Department
Cornell University
Ithaca, NY 14853, USA

Abstract
Recently, Halpern and Leung suggested representing uncertainty by a set of weighted
probability measures, and suggested a way of making decisions based on this representation
of uncertainty: maximizing weighted regret. Their paper does not answer an apparently
simpler question: what it means, according to this representation of uncertainty, for an
event E to be more likely than an event E 0 . In this paper, a notion of comparative
likelihood when uncertainty is represented by a set of weighted probability measures is
defined. It generalizes the ordering defined by probability (and by lower probability) in
a natural way; a generalization of upper probability can also be defined. A complete
axiomatic characterization of this notion of regret-based likelihood is given.

1. Introduction
Recently, Samantha Leung and I (Halpern & Leung, 2012) suggested representing uncertainty by a set of weighted probability measures, and suggested a way of making decisions
based on this representation of uncertainty: maximizing weighted regret. However, we did
not answer an apparently simpler question: given this representation of uncertainty, what
does it mean for an event E to be more likely than an event E 0 ? This is what I do in this
paper. To explain the issues, I start by reviewing the Halpern-Leung approach.
It has frequently been observed that there are many situations where an agents uncertainty is not adequately described by a single probability measure. Specifically, a single
measure may not be adequate for representing an agents ignorance. For example, there
seems to be a big difference between a coin known to be fair and a coin whose bias an agent
does not know, yet if the agent were to use a single measure to represent her uncertainty,
in both of these cases it would seem that the measure that assigns heads probability 1/2
would be used.
One approach that has been suggested for representing ignorance is to use a set P of
probability measures. This idea is an old one, apparently going back to the work of Boole
(1854, ch. 1621) and Ostrogradsky (1838); some authors (e.g., Campos & Moral, 1995;
Couso, Moral, & Walley, 1999; Gilboa & Schmeidler, 1993; Levi, 1985; Walley, 1991) have
additionally required the set P to be convex (so that if 1 and 2 are in P, then so is
a1 + b2 , where a, b  [0, 1] and a + b = 1). This approach has the benefit of representing
uncertainty in general, not by a single number, but by a range of numbers. This allows us
to distinguish the certainty that a coin is fair (in which case the uncertainty of heads is
represented by a single number, 1/2) from knowing only that the probability of heads could
be anywhere between, say, 1/3 and 2/3.
c
2015
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiHalpern

But this approach also has its problems. For example, consider an agent who believes
that a coin may have a slight bias. Thus, although it is unlikely to be completely fair, it
is close to fair. How should we represent this with a set of probability measures? Suppose
that the agent is quite sure that the bias is between 1/3 and 2/3. We could, of course, take
P to consist of all the measures that give heads probability between 1/3 and 2/3. But how
does the agent know that the possible biases are exactly between 1/3 and 2/3. Does she
not consider 2/3 +  possible for some small ? And even if she is confident that the bias is
between 1/3 and 2/3, this representation cannot take into account the possibility that she
views biases closer to 1/2 as more likely than biases further from 1/2.
There is also a second well-known concern: learning. Suppose that the agent initially
considers possible all the measures that gives heads probability between 1/3 and 2/3. She
then starts tossing the coin, and sees that, of the first 20 tosses, 12 are heads. It seems that
the agent should then consider a bias of greater than 1/2 more likely than a bias of less than
1/2. But if we use the standard approach to updating with sets of probability measures
(Halpern, 2003), and condition each of the measures on the observation, since the coin
tosses are viewed as independent, the agent will continue to believe that the probability of
the next coin toss is between 1/3 and 2/3. The observation has no impact as far as learning
to predict better. The set P stays the same, no matter what observation is made.
There is a well-known solution to these problems: putting a measure of uncertainty on
these probability measures in P. This idea too has a long history. One special case is to put
a second-order probability on these probability measures; see (Good, 1980) for discussion
of this approach and further references. For example, an agent can express the fact that
the bias of a coin is more likely to be close to 1/2 than far from 1/2. In addition, the
problem of learning can be dealt with by straightforward conditioning. But this approach
leads to other problems. Essentially, it seems that the ambiguity that an agent might feel
about the outcome of the coin toss seems to have disappeared. For example, suppose that
the agent has no idea what the bias is. The obvious second-order probability to use is the
uniform probability on possible biases. While we cannot talk about the probability that the
coin is heads (there is a set of probabilities, after all, not a single probability), the expected
probability of heads is 1/2. Why should an agent that has no idea of the bias of the coin
know or believe that the expected probability of heads is 1/2? Of course, if one had to use
a single probability measure to describe uncertainty, symmetry considerations dictate that
it should be the one that ascribes equal likelihood to heads and tails; similarly, if one had
to put a single second-order probability on the set of possible biases, uniform probability
seems like the most obvious choice. Moreover, if our interest is in making decisions, then
maximizing the expected utility using the expected probability again does not take the
agents ignorance into account. Kyburg (1988) and Pearl (1987) have even argued that
there is no need for a second-order probability on probabilities; whatever can be done with
a second-order probability can already be done with a basic probability.
Nevertheless, when it comes to decision-making, it does seem useful to use an approach
that represents ambiguity, while still maintaining some of the features of having a secondorder probability on probabilities. This idea goes back to at least Gardenfors and Sahlin
(1982, 1983). Walley (1997) suggested putting a possibility measure (Dubois & Prade, 1998;
Zadeh, 1978) on probability measures; this was also essentially done by Cattaneo (2007),
Chateauneuf and Faro (2009), and de Cooman (2005). All of these authors and others, such
472

fiWeighted Regret-Based Likelihood

as Klibanoff et al. (2005), Maccheroni et al. (2006), and Nau (1992), proposed approaches
to decision making using their representations of uncertainty.
Leung and I similarly suggested putting weights on each probability measure in P. Since
we assumed that the weights are normalized so that the supremum of the weights is 1, these
weights can also be viewed as a possibility measure. If the set P is finite, we can also
normalize so as to view the weights as being second-order probabilities. As with secondorder probabilities, the weights can vary over time, as more information is acquired. For
example, we can start with a state of complete ignorance (modeled by assuming that all
probability measures have weight 1), and update the weights after making an observation
ob, we take the weight of a measure Pr to be the relative likelihood of ob if Pr were the
true measure. (See Section 2 for details.) With this approach, called likelihood updating by
Halpern and Leung (2012), if there is a true underlying measure generating the data, over
time, the weight of the true measure approaches 1, while the weight of all other measures
approaches 0. Thus, this approach allows learning in a natural way. If, for example, the
actual bias of the coin was 5/8 in the example above, no matter what the initial weights, as
long as 5/8 had positive weight, then its weight would almost surely converge to 1 as more
observations were made, while the weight of all other measures would approach 0. This,
of course, is exactly what would happen if we had a second-order probability on P. The
weights can also be used to represent the fact that some probabilities in the set P are more
likely than others.
Like essentially all others who considered a representation of uncertainty based on a set
of probability with weights, Leung and I also suggested a way of using this representation
to make decisions. However, our approach was different than those suggested earlier. We
based our approach on regret, a standard approach to decision-making that was introduced
(independently) by Niehans (1948) and Savage (1951). If uncertainty is represented by
a set P of probability measures, then regret works as follows: for each act a and each
measure Pr  P, we can compute the expected regret of a with respect to Pr; this is
the difference between the expected utility of a and the expected utility of the act that
gives the highest expected utility with respect to Pr. We can then associate with an act
a its worst-case expected regret of a, over all measures Pr  P, and compare acts with
respect to their worst-case expected regret. With weights in the picture, we modify the
procedure by multiplying the expected regret associated with measure Pr by the weight of
Pr, and compare acts according to their worst-case weighted expected regret. This approach
to making decisions is very different from the others mentioned above that incorporate a
likelihood on probabilities. Moreover, using the weights in the way means that we cannot
simply replace a set of weighted probability measures by a single probability measure; the
objections of Kyburg (1988) and Pearl (1987) do not apply.
Leung and I (Halpern & Leung, 2012) show that this approach seems to do reasonable
things in a number of examples of interest, and provide an axiomatization of decision-making
with this approach. Since sets of weighted probabilities are certainly intended to be a way
of representing uncertainty, it seems natural to ask whether they can be used to represent
relative likelihood in a direct way. Surprisingly, this is something largely not considered in
earlier papers using sets of weighted probabilities, since their focus was on decision-making
(although the work of Nau discussed in Section 3 is an exception).
473

fiHalpern

Representing relative likelihood is straightforward if uncertainty is represented by a
single probability measure: E is more likely than E 0 exactly if the probability of E is greater
than the probability of E 0 . When using sets of probability measures, various approaches
have been considered in the literature. The most common takes E to be more likely than
E 0 if the lower probability of E is greater than the lower probability of E 0 , where the lower
probability of E is its worst-case probability, taken over the measures in P (see Section 3).
We could also compare E and E 0 with respect to their upper probabilities (the best-case
probability with respect to the measures in P). Another possibility is to take E to be
more likely than E 0 if Pr(E)  Pr(E 0 ) for all measures Pr  P; this gives a partial order
on likelihood.1 But what should we do if uncertainty is represented by a set of weighted
probability measures?
In this paper, I define a notion of relative likelihood when uncertainty is represented
by a set of weighted probability measures that generalizes the ordering defined by lower
probability in a natural way; I also define a generalization of upper probability. We can then
associate with an event E two numbers that are analogues of lower and upper probability. If
uncertainty is represented by a single measure, then these two numbers coincide; in general,
they do not. The interval can be thought of as representing the degree of ambiguity in
the likelihood of E. Indeed, in the special case when all the weights are 1, the numbers
are essentially just the lower and upper probability (technically, they are 1 minus the lower
and upper probability, respectively). Interestingly, the approach to assigning likelihood is
based on the approach to decision-making. Essentially, what I am doing is the analogue of
defining probability in terms of expected utility, rather than the other way around. The
approach can be viewed as generalizing both probability and lower probability, while at
the same time allowing a natural approach to updating.
Why we should be interested in such a representation? If all that we ever did with probability was to use it to make decisions, then arguably this wouldnt be of much interest; my
work with Leung already shows how sets of weighted probabilities can be used in decisionmaking. The results of this paper add nothing further to that question. However, we often
talk about the likelihood of events quite independent of their use in decision-making. There
are clearly many examples in physics. The issue arises in AI applications as well: a typical
explanation of why we did A rather than B is that we thought some event E was more
likely than F . And computations of expectation, which clearly involve a representation of
uncertainty, arise in many AI applications. Thus, having an analogue of probability seems
important and useful in its own right.
The rest of this paper is organized as follows. After reviewing the relevant material
from (Halpern & Leung, 2012) in Section 2, I define regret-based likelihood in Section 3,
and compare it to lower probability. I provide an axiomatic characterization of regret-based
likelihood in Section 4, and show how it relates to the axiomatic characterization of lower
probability. I conclude in Section 5.

1. There is a long tradition of considering partially ordered notions of likelihood; see (Halpern, 1997) and
the references therein, and the work of Walley (1991).

474

fiWeighted Regret-Based Likelihood

2. Weighted Expected Regret: A Review
Consider the standard setup in decision theory. We have a state space S and an outcome
space O. An act is a function from S to O; it describes an outcome for each state. Suppose
that we have a utility function u on outcomes and a set P + of weighted probability measures.
That is, P + consists of pairs (Pr, Pr ), where Pr is a weight in [0, 1] and Pr is a probability
on S. Let P = {Pr : ((Pr, )  P + )}. For each Pr  P there is assumed to be
exactly one , denoted Pr , such that (Pr, )  P + . It is further assumed that weights
have been normalized so that there is at least one measure Pr  P such that Pr = 1.
Finally, P + is assumed to be weakly closed, so that if (Prn , n )  Pr+ for n = 1, 2, 3, . . .,
(Prn , n )  (Pr, Pr ), and Pr > 0, then (Pr, Pr )  P + . (I discuss below why I require
P + to be just weakly closed, rather than closed.)
The assumption that at least one probability measure has a weight of 1 is convenient
for comparison to other approaches; see below. However, making this assumption has no
impact on the results of this paper; as long as we restrict to sets where the weight is bounded,
all the results hold without change. This assumption is, of course, incompatible with the
weights being probabilities. Note that the assumption that the weights are probabilities
runs into difficulties if we have an infinite number of measures in P; for example, if P
includes all measures on heads from 1/3 to 2/3, as discussed in the Introduction, using a
uniform probability, we would be forced to assign each individual probability measure a
weight of 0, which would not work well for our later definitions.
Where are the weights in P + coming from? In general, they can be viewed as subjective,
just like the probability measures. However, as Leung and I (Halpern & Leung, 2012)
observed, there is an important special case where the weights can be given a natural
interpretation. Suppose that, as in the case of the biased coin in the Introduction, we make
observations in a situation where the probability of making a given observation is determined
by some objective source. Then we can start by giving all probability measures a weight of 1.
Given an observation ob (e.g., sequence of coin tosses in the example in the Introduction),
we can compute Pr(ob) for each measure Pr  P; we can then update the weight of Pr
to be Pr(ob)/ supPr0 P Pr0 (ob). Thus, the more likely the observation is according to Pr,
the higher the updated weight of Pr relative to other probability measures in P.2 (The
denominator is just a normalization to ensure that some measure has weight 1.) With this
approach to updating, if there is a true underlying measure generating the data, then as an
agent makes more observations, almost surely, the weight of the true measure approaches
1, while the weight of all other measures approaches 0.3 In addition, this approach gives
an agent a natural way of determining weights for each probability measure in P. While,
in general, this means that the agent may need to carry around a lot of information (not
2. The idea of putting a possibility on probabilities in P that is determined by likelihood also appears in the
work of Moral (1992), although he does not consider a general approach to dealing with sets of weighted
probability measures.
3. The almost surely is due to the fact that, with probability approaching 0, as more and more observations are made, it is possible that an agent will make misleading observations that are not representative
of the true measure. This also depends on the set of possible observations being rich enough to allow
the agent to ultimately discover the true measure generating the observations; for example, an agent will
never learn the distributions of outcomes of a die she never gets to observe the die when it lands 5 or 6.
Since learning is not a focus of this paper, I do not make this notion of rich enough precise here.

475

fiHalpern

only a possibly infinite set of probabilities, but a weight associated with each one), if the
set P has a reasonable parametric representation, then the weight can often be evaluated
in terms of the parameters, so should admit a compact representation (see Example 3.2).
The weight associated with a probability Pr can be viewed as an upper bound on an
agents confidence that Pr actually describes the situation. That is why an agent who has
no idea of what is going on is modeled as starting by placing weight 1 on all probability
measures. I believe that having the weights will allow agents to express nuances that they
consider important, and that such weights will not be hard to elicit. Whether this is the
case is really an empirical question, one which I believe deserves further exploration, but is
beyond the scope of this paper.
I now review the definition of weighted regret, and introduce the notion of absolute
(weighted) regret. I start with regret. The regret of an act a in a state s  S is the
difference between the utility of the best act at state s and the utility of a at s. Typically,
the act a is not compared to all acts, but to the acts in a set M , called a menu. Thus, the
regret of a in state s relative to menu M , denoted reg M (a, s), is supa0 M u(a0 (s))  u(a(s)).4
There are typically some constraints put on M to ensure that supa0 M u(a0 (s)) is finitethis
is certainly the case if M is finite, or the convex closure of a finite set of acts, or if there is a
best possible outcome in the outcome space O. The latter assumption holds in this paper,
so I assume throughout that supa0 M u(a0 (s)) is finite.
For simplicity, I assume that the state space S is finite. Given a probability measure
Pr on S, the expected regret of an act a with respect to Pr relative to menu M is just
P
M
reg M
sS reg (a, s) Pr(s). The (expected) regret of a with respect to P and a menu
Pr (a) =
M is just the worst-case regret, that is,
M
reg M
P (a) = sup reg Pr (a).
PrP

Similarly, the weighted (expected) regret of a with respect to P + and a menu M is just the
worst-case weighted regret, that is,
M
wr M
P + (a) = sup Pr reg Pr (a).
PrP

Thus, regret is just a special case of weighted regret, where all weights are 1.
Note that, as far weighted regret goes, it does not hurt to augment a set P + of weighted
probability measures by adding pairs of the form (Pr, 0) for Pr 
/ P. But if we start with a set
+
P of unweighted probability measures, the set P = {(Pr, 1) : Pr  P}{(Pr, 0) : Pr 
/ P} is
not closed in general, although it is weakly closed. There may well be a sequence Prn  Pr,
where Prn 
/ P for all n, but Pr  P. But then we would have (Prn , 0)  P + converging to
+
(Pr, 0) 
/ P . This is exactly why I required only weak closedness. Note for future reference
that, since P + is assumed to be weakly closed, if wr M
P + (a) > 0, then there is some element
M
+
M
(Pr, Pr )  P such that wr P + (a) = Pr reg Pr (a).
Weighted regret induces an obvious preference order on acts: act a is at least as good
0
0
M
M
as a0 with respect to P + and M , written a reg
P + ,M a , if wr P + (a)  wr P + (a ). As usual, I
4. Recall that if X is a set of real numbers, sup X, the supremum of X, is the smallest real numbers that
is greater than or equal to all the elements of X. If X is finite, then the sup is the same as the max.
But if X is, say, the interval (0, 1), then sup X = 1. Similarly, inf X is the largest real number that is
less than or equal to all the elements in X.

476

fiWeighted Regret-Based Likelihood

reg
reg
0
0
0
write a reg
P + ,M a if a P + ,M a but it is not the case that a P + ,M a. The standard notion
of regret is the special case of weighted regret where all weights are 1. I sometimes write
0
+
a reg
P,M a to denote the unweighted case (i.e., where all the weights in P are 1).
In this setting, using weighted regret gives an approach that allows an agent to transition
smoothly from regret to expected utility. It is well known that regret generalizes expected
M 0
utility in the sense that if P is a singleton {Pr}, then wr M
P (a)  wr P (a ) iff EUPr (a) 
0
EUPr (a ) (where EUPr (a) denotes the expected utility of act a with respect to probability
Pr); this follows from the observation that, given a menu M , there is a constant cM such
that, for all acts a  M , wr M
{Pr} (a) = cM  EUPr (a). (In particular, this means that if P
is a singleton, regret is menu independent.) If we start with all the weights being 1, then,
as observed above, the weighted regret is just the standard notion of regret. As the agent
makes observations, if there is a measure Pr generating the uncertainty, the weights will
get closer and closer to a situation where Pr gets weight 1, with the weights of all other
measures dropping off quickly to 0, so the ordering of acts will converge to the ordering
given by expected utility with respect to Pr.
There is another approach with some similar properties, which again starts with uncertainty being represented by a set P of (unweighted) probability measures. Define wc P (a) =
inf PrP EUPr (a). Thus wc P (a) is the worst-case expected utility of a, taken over all Pr  P.
Then define a mm
a0 if wc P (a)  wc P (a0 ). This is the maxmin expected utility rule, quite
P
often used in economics (Gilboa & Schmeidler, 1989). There are difficulties in getting a
weighted version of maxmin expected utility (Halpern & Leung, 2012) (discussed further in
Section 3); however, Epstein and Schneider (2007) propose another approach that can be
combined with maxmin expected utility. They fix a parameter   (0, 1), and update P
after an observation ob by retaining only those measures Pr such that Pr(ob)  . For any
choice of  < 1, we again end up converging almost surely to a single measure, so again
this approach converges almost surely to expected utility.
I conclude this section with a discussion of menu dependence. Maxmin expected utility
is not menu dependent; the preference ordering on acts induced by regret can be, as the
following example illustrates.

Example 2.1: Take the outcome space to be {0, 1}, and the utility function to be the
identity, so that u(1) = 1 and u(0) = 0. As usual, if E  S, 1E denotes the indicator
function on E, where, for each state s  S, we have 1E (s) = 1 if s  E, and 1E (s) = 0
if s 
/ E. Let S = {s1 , s2 , s3 , s4 }, E1 = {s1 }, E2 = {s2 }, E3 = {s2 , s3 }, M1 = {1E1 , 1E2 },
M2 = {1E1 , 1E2 , 1E3 }, and P = {Pr1 , Pr2 }, where Pr1 (s1 ) = Pr1 (s3 ) = Pr1 (s4 ) = 1/3,
1
Pr2 (s2 ) = 1/4, and Pr2 (s3 ) = 3/4. A straightforward calculation shows that reg M
Pr1 (1E1 ) =
M1
M1
M1
M2
M2
0, reg Pr1 (1E2 ) = 1/3, reg Pr2 (1E1 ) = 1/4, reg Pr2 (1E2 ) = 0, reg Pr1 (1E1 ) = 1/3, reg Pr1 (1E2 ) =
M1
M1
M2
2
2/3, reg M
Pr2 (1E1 ) = 1, and reg Pr2 (1E2 ) = 3/4. Thus, 1/4 = reg P (1E1 ) < reg P (1E2 ) = 1/3,
M2
2
while 1 = reg M
P (1E1 ) > reg P (1E2 ) = 3/4. The preference on 1E1 and 1E2 depends on
whether we consider the menu M1 or the menu M2 .
Suppose that there is an outcome o  O that gives the maximum utility; that is,
 u(o) for all o  O. If o is the constant act that gives outcomes o in all states,
then o is clearly the best act in all states. If there is such a best act, an absolute,
menu-independent notion of weighted expected regret can be defined by always comparing

u(o )

477

fiHalpern

to o . That is, define
reg(s, a) = u(o )  u(a(s));
P
reg Pr (a) = sS (u(o )  u(a(s)) Pr(s) = u(o )  EUPr (a);
P
reg P (a) = supPrP sS (u(o )  u(a(s)) Pr(s) = u(o )  inf PrP (EUPr (a);
P
wr P + (a) = supPrP Pr sS (u(o )  u(a(s)) Pr(s) = supPrP Pr (u(o )  EUPr (a)).
If there is a best act, then I write a P + a0 if wr P + (a)  wr P + (a0 ); similarly in the
unweighted case, I write a P a0 if wr P (a)  wr P (a0 ).
Conceptually, we can think of the agent as always being aware of the best outcome o ,
and comparing his actual utility with a to u(o ). Equivalently, the absolute notion of regret
is equivalent to a menu-based notion with respect to a menu M that includes o (since if
the menu includes o , it is the best act in every state). As we shall see, in our setting, we
can always reduce menu-dependent regret to this absolute, menu-independent notion, since
there is in fact a best act: 1S .

3. Relative Ordering of Events Using Weighted Regret
In this section, I consider how a notion of comparative likelihood can be defined using sets
of weighted probability measures.
As in Example 2.1, take the outcome space to be {0, 1}, the utility function to be the
identity, and consider indicator functions. It is easy to see that EUPr (1E ) = Pr(E), so that
with this setup, we can recover probability from expected utility. Thus, if uncertainty is
represented by a single probability measure Pr and we make decisions by preferring those
acts that maximize expected utility, then we have 1E  1E 0 iff Pr(E)  Pr(E 0 ).
Consider what happens if we apply this approach to maxmin expected utility. Now we
have that 1E mm
1E 0 iff inf PrP Pr(E)  inf PrP Pr(E 0 ). In the literature, inf PrP Pr(E),
P
denoted P (E), is called the lower probability of E, and is a standard approach to describing likelihood. The dual upper probability, supPrP Pr(E), is denoted P  (E). An easy
calculation shows that
P  (E) = 1  P (E),
where, as usual, E denotes the complement of E. The interval [P (E), P  (E)] can be
thought of as describing the uncertainty of E; the larger the interval, the greater the ambiguity.
What happens if we apply this approach to regret? First consider unweighted regret.
If we restrict to acts of the form 1E , then the best act is clearly 1S , which is just the
constant function 1. Thus, we can (and do) use the absolute notion of regret here, and
for the remainder of this paper. We then get that 1E reg
P 1E 0 iff supPrP (1  Pr(E)) 
0
0
supPrP (1  Pr(E )) iff supPrP Pr(E)  supPrP Pr(E ); that is,
0



1E reg
P 1E 0 iff P (E)  P (E ).

478

fiWeighted Regret-Based Likelihood

Moreover, easy manipulation shows that supPrP (1  Pr(E)) = 1  inf PrP Pr(E) = 1 
P (E). It follows that
1E reg
P 1E 0
iff (1  P (E))  (1  P (E 0 ))
iff P (E)  P (E 0 )
iff 1E mm
1E 0 .
P
That is, both regret and maxmin expected utility put the same ordering on events.
+ (E), the (weighted) regret-based
The extension to weighted regret is immediate. Let Preg
likelihood of E, be defined by taking
+
Preg
(E) = sup Pr Pr(E).
PrP

If P + is unweighted, so that all the weights are 1, I write Preg (E) to denote supPrP Pr(E).
Note that Preg (E) = 1  P (E), so
Preg (E)  Preg (E 0 ) iff P (E)  P (E 0 ).
That is, the ordering induced by Preg is the opposite of that induced by P . So, for example,
Preg () = 1 and Preg (S) = 0; smaller sets have larger regret-based likelihood. However, since
an act with smaller regret is viewed as better, the ordering on acts of the form 1E induced
by regret is the same as that induced by maxmin expected utility.
Regret-based likelihood provides a way of associating a number with each event, just
as probability and lower probability do. Moreover, just as lower probability gives a lower
+ (E) as giving an upper bound on the uncertainty.
bound on uncertainty, we can think of Preg
(It is an upper bound rather than a lower bound because larger regret means less likely,
just as smaller lower probability does.) The naive corresponding lower bound is given by
inf PrP Pr Pr(E). This lower bound is not terribly interesting; if there are probability
measures Pr0  P such that Pr0 is close to 0, then this lower bound will be close to 0,
independent of the agents actual feeling about the likelihood of E. A more reasonable
+
lower bound is given by the expression P +
reg (E) = 1  Preg (E) (recall that the analogous
expression relates upper probability and lower probability). The intuition for this choice
is the following. If nature were conspiring against us, she would try to prove us wrong
by making Pr Pr(E) as large as possiblethat is, make the weighted probability of being
wrong as large as possible. On the other hand, if nature were conspiring with us, she would
try to make Pr Pr(E) as large as possible, or, equivalently, make 1  Pr Pr(E) as small
as possible. Note that this is different from making Pr Pr(E) as large as possible, unless
Pr = 1 for all Pr  P. An easy calculation shows that
+ (E) = 1  sup
1  Preg
PrP Pr Pr(E)
= inf PrP (1  Pr Pr(E)).

This motivates the definition of P +
reg .
The following lemma clarifies the relationship between these expressions, and shows that
+
[P +
reg (E), Preg (E)] really does give an interval of ambiguity.
+ (E)  P + (E).
Lemma 3.1: inf PrP Pr Pr(E)  1  Preg
reg

479

fiHalpern

Proof: Clearly
inf Pr Pr(E) = inf Pr (1  Pr(E)).

PrP

PrP

Since, as observed above,
+
1  Preg
(E) = inf (1  Pr Pr(E)),
PrP

and for all Pr  P, we have
1  Pr Pr(E)  Pr (1  Pr(E)),
+ (E).
it follows that inf PrP Pr Pr(E)  1  Preg
Since, by assumption, there is a probability measure Pr0  P such that Pr0 = 1, it
follows that
+ (E) = 1  sup
1  Preg
PrP Pr Pr(E)
 1  Pr0 (E)
= Pr0 (E)
 supPrP Pr Pr(E)
+ (E).
 Preg

In general, equality does not hold in Lemma 3.1, as shown by the following example. The
example also illustrates how the ambiguity interval can decrease with weighted regret, if
the weights are updated as Leung and I (Halpern & Leung, 2012) suggested.
Example 3.2: Suppose that the state space consists of {h, t} (for heads and tails); let Pr
be the measure that puts probability  on h. Let P0+ = {(Pr , 1) : 1/3    2/3}. That is,
we initially consider all the measures that put probability between 1/3 and 2/3 on heads. We
toss the coin and observe it lands heads. Intuitively, we should now consider it more likely
that the probability of heads is greater than 1/2. Indeed, applying likelihood updating, we
get the set P1+ = {(Pr , 3/2) : 1/3    2/3}; the probability measures that give h higher
probability get higher weight. In particular, the weight of Pr2/3 is still 1, but the weight of
Pr1/3 is only 1/2. (The weight of Pr is the likelihood of observing heads according to Pr ,
which is just , normalized by the likelihood of observing heads according to the measure
that gives heads the highest probability, namely 2/3.) If the coin is tossed again and this
time tails is observed, we update further to get P2+ = {(Pr , 4(1  )) : 1/3    2/3}.
Before going on, it is worth noting here how the simple parametric form of P0+ leads to
simple parametric forms for P1+ and P2+ .
+
+
+
An easy calculation shows that [P +
0,reg (h), P0,reg (h)] = [1/3, 2/3], [P 1,regret (h), P1,reg (h)] =
+
+
[1/3, 3/8], and [P 2,reg (h), P2,reg (h)] = [11/27, 16/27]. In more detail, since Pr (h) =  and
Pr (t) = 1  , so we have the following:
0
 P0,reg
(h) = sup[1/3,2/3] (1  ) = 2/3.

 P 00,reg (h) = inf   [1/3, 2/3](1  ) = 1/3.
0
 P1,reg
(h) = sup[1/3,2/3] (3/2)(1). Taking the derivative shows that (3/2)(1)
0
is maximized when  = 1/2, so P1,reg
(h) = 3/8.

480

fiWeighted Regret-Based Likelihood

 P 01,reg (h) = inf [1/3,2/3] (1  (3/2)). Now 1  (3/2) is minimized, when (3/2)
is maximized; for   [1/3, 2/3], this happens when  = 2/3, so P 01,reg (h) = 1/3.
0
 P2,reg
(h) = sup[1/3,2/3] 4(1)(1). Taking the derivative shows that 4(1)2
is maximized when  = 1/3, in which case it is 16/27.

 P 02,reg (h) = inf [1/3,2/3] (1  4(1  )). Now 1  4 2 (1  ) is minimized when
4 2 (1) is maximized; for   [1/3, 2/3], this happens when  = 2/3, so P 01,reg (h) =
11/27.
It is also easy to see that inf Pr 4(1  ) Pr (t) = inf [1/3,2/3] 4(1  )2 = 8/27, so
+
+
inf 4(1  )Pr (t) < 1  P2,reg
(t) < P2,reg
(h).

PrP2

Thus, for P2+ , we get strict inequalities for the expressions in Lemma 3.1.
+
The width of the interval [P +
reg (E), Preg (E)] can be viewed as a measure of the ambiguity
the agent feels about E, just as the interval [P (E), P  (E)]. Indeed, if all the weights are 1,
+ (E) and P  (E) = 1  P + (E)
the two intervals have the same width, since P (E) = 1  Preg
reg
in this case.
However, weighted regret has a significant advantage over upper and lower probability.
If the true bias of the coin is, say 5/8, then if the set Pk+ represents the uncertainty after
+
k steps, as k increases, almost surely, [P +
k,reg (h), Pk,reg (h)] will be a smaller and smaller
interval containing 1  5/8 = 3/8. More generally, using likelihood updated combined with
weighted regret provides a natural way to model the reduction of ambiguity via learning.
It is worth at this point comparing the approach to representing likelihood taken here
to the work of Nau (1992). Nau starts with a preference order on lotteries (functions from
some finite state space S to the reals) satisfying certain axioms, and derives from that what
he calls confidence-weighted (lower and upper) probabilities. Roughly speaking, rather than
just associating with each event its lower and upper probability, Nau can associate with
 of probabilities
each event E, confidence c  [0, 1], and probability p  [0, 1] the set Pc,p
that give event E lower probability p with confidence at least c. If c0  c, then Pc0 ,p  Pc,p
(every probability measures that gives E lower probability p with the higher confidence
c0 will also give it lower probability p with confidence c, but the converse may not hold).
Similarly, we can consider the probability measures that give E upper probability p with
confidence c. With a set P of unweighted probabilities, an agents uncertainty regarding an
event E can be characterized by a single interval [P (E), P  (E)]. In Naus framework, an
agents uncertainty regarding E can be characterized by a family of intervals [Pc (E), P c (E)],
indexed by the confidence c, where Pc (E) is the largest p such that E has lower probability
with confidence c, and P c (E) is defined similarly. Clearly these intervals are nested; if
0
c0 > c, then [Pc0 (E), P c (E)] contains [Pc (E), P c (E)]. Thus, Naus approach provides a
more fine-grained representation of uncertainty than the single intervals [P (E), P  (E)] or
+
[P +
reg (E), Preg (E)]. To some extent, this distinction is due to the fact that Naus preference
order on lotteries is only a partial order; the preference order induced by max=min expected
+ , and P + all put a
utility regret is total. However, note that even though P , P  , Preg
reg

+ , and P + together,
total order on events, when considering both P and P or both Preg
reg

481

fiHalpern

we can also obtain a partial order on events; in particular, these approaches can express
ambiguity.
One benefit of the regret-based approach is that it provides a natural way of updating.
Nau does not consider updating; it would be interesting to see if an analogue of likelihood
updating could be defined axiomatically in Naus framework, perhaps in the spirit of the
characterization that Leung and I (Halpern & Leung, 2012) gave for likelihood updating in
the context of regret.
One concern with the use of regret has been the dependence of regret on the menu;
Naus approach, and other approaches to decision-making that are not based on regret, do
not require a menu. While there is evidence from the psychology literature suggesting that
people are quite sensitive to menus, it is also worth noting that when dealing with likelihood,
there is a sense in which we can work with the absolute notion of weighted regret without
loss of generality: if we restrict to indicator functions, then a preference relative to a menu
can always be reduced to an absolute preference. Given a menu M consisting of indicator
functions, let EM = {E : 1E  M }; that is, EM is the union of the events for which the
corresponding indicator function is in M . The following property shows that, when restrict
to indicator functions, regret satisfies satisfies an axiom similar in spirit to Naus (1992)
cancellation axiom.
Proposition 3.3: If M is a menu consisting of indicator functions, and 1E1 , 1E2  M ,
reg
then 1E1 reg
P + ,M 1E2 iff 1E1 + 1E M P + 1E2 + 1E M .
Proof: Let M 0 be any menu consisting of indicator functions that includes 1E1 + 1E M ,
reg
1E2 + 1E M , and 1S . Recall that 1E1 + 1E M reg
P + 1E2 + 1E M iff 1E1 + 1E M M 0 ,P + 1E2 + 1E M ;
the absolute notion of regret is equivalent to the menu-based notion, as long as the menu
includes the best act, which in this case is 1S . It clearly suffices to show that, for all states
s  S and all acts 1E  M ,
0

reg M (1E , s) = reg M (1E + 1E M , s).
This is straightforward. There are two cases, depending on whether s  EM .
If s  EM , then, by definition, there is some act 1E 0  M such that s  E 0 , so
supaM u(a(s)) = u(1). Clearly supaM 0 u(a(s)) = u(1), since 1S  M 0 . Moreover,
1E M (s) = 0, so (1E + 1E M )(s) = 1E (s). Thus, for s  EM ,
reg M (1E , s) = supaM u(a(s))  u(1E (s))
= supaM 0 u(a(s))  u((1E + 1E M )(s))
0
= reg M (1E + 1E M , s).
For s 
/ E M , we have a(s) = 0 for all a  M and 1E (s) = 0, so supaM u(a(s))  u(1E (s)) =
0. On the other hand, supaM 0 u(a(s)) = u(1), and u((1E + 1E M )(s)) = u(1), so again
0
supaM 0 u(a(s))  u((1E + 1E M )(s)) = 0. Thus, we again have reg M (1E , s) = reg M (1E +
1E M , s).

482

fiWeighted Regret-Based Likelihood

4. Characterizing Weighted Regret-Based Likelihood
The goal of this section is to characterize weighted regret-based likelihood axiomatically.
In order to do so, it is helpful to review the characterizations of probability and lower
probability. For ease of exposition in this discussion, I assume that the sample space is
finite and all sets are measurable.
A probability measure on a finite set S maps subsets of S to [0, 1] in a way that satisfies
the following three properties:
Pr1. Pr(S) = 1.
Pr2. Pr() = 0.5
Pr3. Pr(E  E 0 ) = Pr(E) + Pr(E 0 ) if E  E 0 = .
These three properties characterize probability in the sense that any function f : 2S  [0, 1]
that satisfies these properties is a probability measure.
Lower probabilities satisfy analogues of these properties:
LP1. P (S) = 1.
LP2. P () = 0.
LP30 . P (E  E 0 )  P (E) + P (E 0 ) if E  E 0 = .
However, these properties do not characterize lower probability. There are functions that
satisfy LP1, LP2, and LP30 that are not the lower probability corresponding to some set
of probability measures. (See (Halpern & Pucella, 2002, Proposition 2.2) for an example
showing that analogous properties do not characterize P  ; the same example also shows
that they do not characterize P .)
Various characterizations of P (and P  ) have been proposed in the literature (Anger &
Lembcke, 1985; Giles, 1982; Huber, 1976, 1981; Lorentz, 1952; Williams, 1976; Wolf, 1977),
all similar in spirit. I discuss one due to Anger and Lembcke (1985) here, since it makes
the contrast between lower probability and regret particularly clear. The characterization
is based on the notion of set cover: a set E is said to be covered n times by a multiset
M if every element of E appears at least n times in M . It is important to note here that
M is a multiset, not a set; its elements are not necessarily distinct. (Of course, a set is a
special case of a multiset.) Let t denote multiset union; thus, if M1 and M2 are multisets,
then M1 t M2 consists of all the elements in M1 or M2 , which appear with multiplicity that
is the sum of the multiplicities in M1 and M2 . For example, using the {{. . .}} notation to
denote a multiset, then {{1, 1, 2}} t {{1, 2, 3}} = {{1, 1, 1, 2, 2, 3}}.
If E  S, then an (n, k)-cover of (E, S) is a multiset M that covers S k times and
covers E n + k times. Multiset M is an n-cover of E if M covers E n times. For example, if
S = {1, 2, 3}, then {{1, 1, 1, 2, 2, 3}} is a (2, 1)-cover of ({1}, S), a (1, 1)-cover of ({1, 2}, S),
and a 3-cover of {1}.
We will be interested in whether a multiset of the form E 1 t . . . t E m is an (n, k)-cover
of (E, S). This is perhaps best thought of in terms of indicator functions. E 1 t . . . t E m
5. This property actually follows from the other two, using the observation that Pr(S  ) = Pr(S) + Pr();
I include it here to ease the comparison to other approaches.

483

fiHalpern

is an (n, k)-cover of (E, S) if and only if 1E1 +    + 1Em  n1E + k1S . The use of equalities and inequalities involving sums of indicator functions in axiomatic characterizations of
uncertainty has a long history; for example, they were used by Scott (1964) to characterize
qualitative probability. Set covers are just a special case of such inequalities. Typically, such
axioms make it possible to apply results from linear programming to prove characterization
results. As we shall see, that will be the case here too.
Consider the following property:
LP3. For all integers m, n, k and all subsets E1 , . . . , Em of S, if E1 t . . . t Em is an (n, k)P
6
cover of (E, S), then k + nP (E)  m
i=1 P (Ei ).
There is an analogous property for upper probability, where  is replaced by . It is easy
to see that LP3 implies LP30 (since E t E 0 is a (1, 0) cover of (E  E 0 , S)). It follows
by a straightforward induction from LP30 that if E1 , . . . , Em are pairwise disjoint, then
P (E1  . . .  Em )  P (E1 ) +    + P (E1 ). LP3 generalizes this property to allow for sets
that are not necessarily disjoint. The soundness of LP3 for lower probability follows using
the same techniques as given below for the soundness of the property REG3. As Anger
and Lembcke (1985) show, LP3 is just the property that is needed to characterize lower
probability.
Theorem 4.1: (Anger & Lembcke, 1985) If f : 2S  [0, 1], then there exists a set P of
probability measures with f = P if and only if f satisfies LP1, LP2, and LP3.
Moving to regret-based likelihood, clearly we have
+ (S) = 0.
REG1. Preg
+ () = 1.
REG2. Preg

The whole space S has the least regret; the empty set has the greatest regret. Again, we see
that regret-based likelihood inverts the standard ordering of probability; larger regret-based
likelihood corresponds to probability.
In the unweighted case, since Preg (E) = P  (E), REG1, REG2, and the following analogue of LP3 (appropriately modified for P  ) clearly characterize Preg :
REG30 . For all integers m, n, k and all subsets E1 , . . . , Em of S, if E 1 t . . . t E m is an
P
(n, k)-cover of (E, S), then k + nPreg (E)  m
i=1 Preg (Ei ).
Note that complements of sets (E 1 , . . . , E m , E) are used here, since regret is minimized if
the probability of the complement is maximized. This need to work with the complement
makes the statement of the properties (and the proofs of the theorems) slightly less elegant,
but seems necessary.
It is not hard to see that REG30 does not hold for weighted regret-based likelihood.
For example, suppose that S = {a, b, c} and P + = ((Pr1 , 2/3), (Pr2 , 2/3), (Pr3 , 1)), where,
identifying the probability Pr with the tuple (Pr(a), Pr(b), Pr(c)), we have
 Pr1 = (2/3, 0, 1/3);
6. Note that LP3 implies LP2, using the fact that  t  is a (1,0)-cover of (, S).

484

fiWeighted Regret-Based Likelihood

 Pr2 = (1/3, 0, 2/3);
 Pr3 = (1/3, 1/3, 1/3).
+ ({a, b}) = P + ({b, c}) = 4/9, while P + ({b}) = 2/3. Since {a, b} t {b, c} is a
Then Preg
reg
reg
(1,1)-cover of ({b}, {a, b, c}), REG30 would require that
+
+
+
Preg
({a, b}) + Preg
({b, c})  1 + Preg
({b}),

which is clearly not the case.
We must thus weaken REG30 to capture weighted regret-based likelihood. It turns out
that the appropriate weakening is the following:
REG3. For all integers m, n and all subsets E1 , . . . , Em of S, if E 1 t . . . t E m is an n-cover
+ (E)  Pm P + (E ).
of E, then nPreg
i
i=1 reg
Although REG3 is weaker than REG30 , it still has some nontrivial consequences. For
+ is anti-monotonic. If E  E 0 , then E is a 1-cover
example, it follows from REG3 that Preg
0
+ (E)  P + (E 0 ). Since E t E 0 is trivially a 1-cover of
of E , so by REG3, we must have Preg
reg
+ (E) + P + (E 0 )  P + (E  E 0 ). REG3 also implies REG1,
E  E 0 , it also follows that Preg
reg
reg
since  (= S) is an n-cover of itself for all n.
I can now state the representation theorem. It says that a representation of uncertainty
satisfies REG1, REG2, and REG3 iff it is the weighted regret-based likelihood determined
by some set P + . The set P + is not unique, but it can be taken to be maximal, in the
sense that if weighted regret-based likelihood with respect to some other set (P 0 )+ gives
the same representation, then for all pairs (Pr, 0 )  (P 0 )+ , there exists   0 such that
(Pr, )  P + . This (unique) maximal set P + can be viewed as the canonical representation
of uncertainty.
Theorem 4.2: If f : 2S  [0, 1], then there exists a weakly closed set P + of weighted
+ if and only if f satisfies REG1, REG2, and REG3;
probability measures with f = Preg
moreover, P + can be taken to be maximal.
Proof: Clearly, given a weakly closed set P + of weighted probability measures, the function
+ satisfies REG1 and REG2. To see that it satisfies REG3, suppose that E t . . . t E is
Preg
1
m
+ (E) = 0, then REG3 trivially holds. If P + (E) > 0, then since P +
an n-cover of E. If Preg
reg
+ (E) =  Pr(E).
is weakly closed, there must be some probability Pr  P such that Preg
Pr
Since E 1 t. . .tE m is an n-cover of E, it is easy to see that Pr(E 1 )+  +Pr(E m ) = n Pr(E),
+ (E), by construction,
so Pr Pr(E 1 ) +    + Pr Pr(E m ) = nPr Pr(E). But Pr Pr(E) = Preg
P
m
+ (E ), i = 1, . . . , n. Thus, nP + (E) 
+
and Pr Pr(E i )  Preg
i
reg
i=1 Preg (Ei ).
S
For the opposite direction, suppose that f : 2  [0, 1] satisfies REG1, REG2, and
REG3. Let P = (S), the set of all probability measures on S, and for Pr  P, define
Pr = sup{ :  Pr(E)  f (E) for all E  S}.
Note that, for all Pr  P, we have 0 Pr(E)  f (E) for all E  S, since f (E)  [0, 1], and
1 Pr() = f () = 1. It follows that Pr  [0, 1] for all Pr  P. Let P + = {(Pr, Pr ) :
485

fiHalpern

Pr  (S)}. It is easy to see that P + is weakly closed. Moreover, if we can show that P +
+ ), it is immediate that P + is maximal among all sets of weighted
represents f (i.e., f = Preg
probability measures that represent f . Thus, it suffices to show that there exists Pr  (S)
such that (1) Pr = 1 (since this is one of the conditions on sets of weighted measures) and
+ (E) for all E  S.
(2) f (E) = Preg
The proof of this result makes critical use of the following variant of Farkas Lemma
(Farkas, 1902) (see also Schrijver, 1986, pg. 89) from linear programming, where A is a
matrix, b is a column vector, and x is a column vector of distinct variables:
Lemma 4.3: If Ax  b is unsatisfiable, then there exists a row vector  such that
1.   0
2. A = 0
3. b > 0.
Intuitively,  is a witness of the fact that Ax  b is unsatisfiable. This is because if there
were a vector x satisfying Ax  b, then 0 = (A)x = (Ax)  b > 0, a contradiction.
To prove the first claim, suppose that S = {s1 , . . . , sN }. I now construct a set of linear
equations in the variables x1 , . . . , xN such that a solution to the equations guarantees the
existence of a probability measure Pr  (S) such that Pr = 1. Intuitively, we want
xi to be Pr(si ). Since we must have Pr(E)  f (E) for all E  S,7 for each E  S, we
P
have the inequality {i:si E}
xi  f (E). Note that since f () = 1, the equation when
/
E =  is x1 +    + xN  1. In addition, we require that xi  0 for i = 1, . . . , N , and that
x1 +  +xN = 1. It suffices to require that x1 +  +xn  1, since, as I observed earlier, the
equation corresponding to E =  already says x1 +    + xn  1. To apply Farkas Lemma
all the inequalities need to involve , so this collection of inequalities must be rewritten as:
 {i:si E}
xi  f (E), for all E  S
/
xi  0, for i = 1, . . . , N
x1 +    + xN  1.
P

This system of inequalities can be expressed in the form Ax  b. Note that A is a matrix all
of whose entries are either 1, 0, or 1, and, in the first 2N  1 rows (the lines corresponding
to equations for each E  S), all the entries are either 0 or 1, while in the final N + 1
rows, all the entries are either 0 or 1.
A solution of this system of inequalities provides the desired Pr. But if this systems has
no solution, then by Farkas Lemma, there exists a nonnegative vector  such that A = 0
and b > 0. Since all the entries of A are either 1, 0, or 1, it follows from standard
observations (cf., Fagin, Halpern, & Megiddo, 1990, Lemma 2.7) we can take  to a vector
of all whose entries are rational.8 Since we can multiply each term in  by the product
7. I use  to denote strict subset.
8. There is a slight subtlety here since  also has to satisfy b > 0, and b may involve irrational numbers
(since f (E) may be irrational for some sets E). However, if there is a nonnegative  that satisfies A = 0
and b > 0, then there is a nonnegative  that satisfies A = 0 and b0 > 0, where b0 consists only of
rational entries and b0  b. Thus, there is a vector  with rational entries such that A = 0 and b0 > 0,
so b > 0.

486

fiWeighted Regret-Based Likelihood

of the denominators of the entries of , we can assume without loss of generality that the
entries of  are natural numbers.
Since A has 2N + N rows,  is a vector of the form (1 , . . . , 2N +N ). Let A1 , . . . , A2N +N
be the rows of A; each of these is a vector of length N . Since A = 0, that means that
1 A1 +    + 2N +N A2N +N = 0. Suppose for now that 2N , . . . , 2N +N 1 (the coefficients
for the rows corresponding to the inequalities xi  0 for i = 1, . . . , N ) are all 0; as I show
below, this assumption can be made without loss of generality.
With this assumption, we can rewrite the equations as 1 A1 +. . . 2N 1 A2N 1 = 2N +N A2N +N .
If E1 , . . . , E2N 1 are the subsets of S that correspond to the equations for A1 , . . . , A2N 1 ,
respectively, this equation says that 1 copies of E 1 , 2 copies of E 2 , . . . , and 2N 1 copies
of E 2N 1 form a 2N +N -cover of S. (Recall that A2N +N is a row of all 1s, so A2N +N corresponds to S.) Thus, by REG3, 1 f (E1 ) +    + 2N 1 f (E2N 1 )  2N +N f () = 2N +N .
But Farkas Lemma requires that b > 0, where, by construction, bi = f (Ei ) for i =
1, . . . , 2N  1, bi = 0 for i = 2N , . . . , 2N + N  1, and b2N +N = 1. Thus, we must have
(1 f (E1 )+  +2N 1 f (E2N 1 )) > 2N +N . Clearly, this gives a contradiction. Thus, we
can conclude, as desired, that the equations are solvable, and that there exists a probability
measure Pr such that Pr = 1.
N
N
It remains to show that we can assume without loss of generality that  2 , . . . ,  2 +N 1
are all 0. Note that since   0, they must all be nonnegative. I prove by induction on
2N +    + 2N +N 1 that if there is a vector   0 such that A = 0 and b > 0, then
there is such a vector with 2N +    + 2N +N 1 = 0.
So suppose that there is a solution  with 2N +    + 2N +N 1 > 0. Suppose without
loss of generality that 2N > 0. Recall that A2N corresponds to the inequality x1  0.
Choose j  {0, . . . , 2N  1} such that j > 0 and s1 
/ Ej . There must be such a j, for
otherwise we would not have A = 0. Let j 0 be such that Ej 0 = Ej  {s1 }. Define a vector
/ {j, j 0 , 2N }.
 0 such that 20 N = 2N  1, j0 = j  1, j0 0 = j + 1, and i0 = i if i 
0
0
0
It is easy to check that  A = 0 and that 2N +    + 2N +N 1 < 2N +    + 2N +N 1 .
It remains to show that  0 b > 0. Since Ej  Ej 0 , we must have f (Ej )  f (Ej 0 ), so
 0 b = b + f (Ej )  f (Ej 0 )  b > 0. This completes the inductive step of the argument.
+ (E) for
Now we must show the second required property holds, namely, that f (E) = Preg
all E  S. By construction, Pr Pr(E)  f (E) for all E  S, so it suffices to show that there
is some Pr  P such that Pr Pr(E) = f (E). For this, it suffices to show that there exists a
measure Pr such that Pr(E) = 1, and for each E 0  S, we have f (E) Pr(E 0 )  f (E 0 ), since
then Pr = f (E), so Pr Pr(E) = f (E), as desired.
To show that such a measure exists, we again construct a set of linear inequalities
much as above, and apply Farkas Lemma. Using the same notation as above, suppose for
simplicity that E = {s1 , . . . , sM }, where M  N . Now the required inequalities just involve
the variables x1 , . . . , xM :
0

 {i:s EE 0 } xi  f (E 0 )/f (E), for all E 0  S such that E  E 6= 
i
xi  0, for i = 1, . . . , M
x1 +    + xM  1.
P

Again, the requirement that x1 +    + xM  1 follows from the equation for E.
If this system of inequalities is satisfiable, then we have the required probability measure,
so suppose that it is not satisfiable. Again, writing this system of equations as Ax  b, by
487

fiHalpern

Farkas Lemma, there exists a nonnegative vector  such that A = 0 and b > 0. We now
proceed much as before. Again, we can assume that  is a vector of natural numbers. If
M
M
we assume for now that  2 , . . . ,  2 +M 1 (the coefficients for the rows corresponding to
the inequalities xi  0 for i = 1, . . . , N ) are all 0, then the fact that A = 0 means that
we have 2M +M cover of E. We get a contradiction to REG3 in an almost identical way to
above. This completes the argument.
As I said earlier, the set P + guaranteed to exist by Theorem 4.2 is not unique, although
it is canonical, in the sense of being the unique maximal set of weighted probability measures
that represents f . We might wonder if we can actually get uniqueness by imposing a few
extra requirements, particularly since Leung and I were able to do so in our representation
theorem. The answer seems to be no. To explain why, it is helpful to review some material
from (Halpern & Leung, 2012).
Define a sub-probability measure p on S to be like a probability measure (i.e., a function
mapping measurable subsets of S to [0, 1] such that p(T  T 0 ) = p(T ) + p(T 0 ) for disjoint
sets T and T 0 ), without the requirement that p(S) = 1. We can identify a weighted
probability distribution (Pr, ) with the sub-probability measure  Pr. Conversely, given a
sub-probability measure p, there is a unique pair (, Pr) such that P =  Pr: we simply
take  = p(S) and Pr = p/. Thus, in the sequel, I identify a set of sub-probability
measures with a set of weighted probability measures.
A set B of sub-probability measures is downward-closed if, whenever p  B and q  p,
then q  B.
One advantage of considering sub-probability measures is that while it is not clear what
it would mean for a set of weighted probabilities to be convex (indeed, it is not obvious what
should count as a convex combination of (Pr, ) and (Pr0 , 0 )), it is quite clear what counts
as a convex combination of sub-probability measures. Moreover, a convex combination of
sub-probability measures is itself a sub-probability measure.
Call a set of subprobability measures regular if it is convex, downward-closed, closed,
and contains at least one proper probability measure. (The latter requirement corresponds
to having Pr = 1 for some Pr  P + .) Leung and I provide a set of axioms for preference
orders, and show that a family of preference orders M indexed by menus satisfies these
axioms iff there is a unique regular set of weighted probability measures P + such that, for
M
all a M b iff wr M
P + (a)  wr P + (b). Thus, we might hope that we can get uniqueness by
imposing a regularity requirement. It is easy to see that the canonical maximal set P +
constructed in the proof of Theorem 4.2 is regular, which lends some credence to this hope.
Unfortunately, as the following example shows, regularity does not suffice for uniqueness.
Example 4.4: Let S = {s1 , s2 }, and let f be defined on 2S by taking f ({s1 }) = 1/4 and
f ({s2 }) = 1 (and f (S) = 0 and f () = 1). A sub-probability measure p on S can be
identified with the pair (p(s1 ), p(s2 )), which makes it easy to think about sub-probability
measures on S geometrically. A set of sub-probability measures is just a region in IR2
contained in the triangle bounded by the lines x = 0, y = 0, and y = 1  x. A set P +
of subprobability measures is downward closed if, whenever it contains a point (x, y), it
contains all (x0 , y 0 ) in the rectangle defined by the points (0, 0), (x, 0), (0, y), and (x, y).
With this intuition, let P0+ be the set of subprobabilities in the quadrilateral bounded
by x = 0, y = 0, y = 1  x, and y = 1/4 (the region marked by vertical lines in Figure 1). It
488

fiWeighted Regret-Based Likelihood

is not hard to show that P0+ is the maximal set of weighted probabilities representing f . It
+
is clearly regular. Since it contains the subprobability (1, 0), it follows that P0,reg
({s2 }) = 1.
+
+
It is also easy to see that, since (0, 1/4)  P0 and p(s2 )  1/4 for all p  P0 , we have that
+
P0,reg
({s1 }) = 1/4.
But now let P1+ consist of all sub-probabilities in the triangle bounded by x = 0, y = 0,
+
and y = 1x
4 (the region marked by horizontal lines in Figure 1). Clearly P1 is a strict
+
subset of of P0 , but it is clear from the figure that it is also regular. Moreover, since it
contains the points ( 41 , 0) and (0, 1), it also represents f . Indeed, it easily follows from
the geometry of the situation that there are uncountably many regular sets of weighted
probabilities representing f ; for all z  [0, 34 ], the regular set bounded by the lines x = 0,
y = 0, y = 14 , and the line from (z, 41 ) to (1, 0).
y
1

( 34 , 14 )

1
4

0

3
4

1

x

Figure 1: Regular sets of weighted probability measures that represent f .

Intuitively, the problem here is that a function on S does not contain enough information
to uniquely determine a regular set of weighted probability measures. It is not clear whether
there are natural further conditions that can be imposed that we lead to uniqueness. It
seems that the closest that we can come to uniqueness is to consider the maximal set.

5. Conclusion
I have defined an approach for associating with an event E a numerical representation of
its likelihood when uncertainty is represented by a set of weighted probability measures.
The representation consists of a pair of a numbers, which can be thought of as upper and
lower bounds on the uncertainty. The difference between these numbers can be viewed
as a measure of ambiguity. The two numbers coincide when uncertainty is represented
by a single probability. Moreover, if each probability measure gets weight 1, then the
two numbers can essentially be viewed as the lower and upper probabilities of E (more
precisely, 1  P (E) and 1  P  (E)). Thus, the approach can be viewed as a generalization
of lower and upper probability to the case of weighted probability measures, with regretbased likelihood corresponding to upper probability. The definitions show that there is
489

fiHalpern

an interesting connection between regret-based approaches and minimization/maximization
approaches when it comes to defining likelihood; this connection breaks down when it comes
to more general utility calculations (Halpern & Leung, 2012).
The main technical result of the paper is a complete characterization of the likelihood
in the case where the state space is finite. The notion of likelihood can easily be extended
to the case of an infinite state space (of course, an integral has to be used instead of a sum
to calculate expected utility). I conjecture that the characterization theorem will still hold
with essentially no change, although I have not checked details carefully.
Of course, it would be useful to get a better understanding of this numerical representation, to see if it really captures an agents feelings about both the ambiguity and the risk
associated with an event, and to understand its technical properties. I leave this to future
work.

Acknowledgments
I thank Samantha Leung, the reviewers of ECSQARU, and the JAIR referees for many useful
comments on the paper. The work was supported in part by NSF grants IIS-0812045, IIS0911036, and CCF-1214844, by AFOSR grants FA9550-08-1-0438, FA9550-09-1-0266, and
FA9550-12-1-0040, and by ARO grant W911NF-09-1-0281.

References
Anger, B., & Lembcke, J. (1985). Infinitely subadditive capacities as upper envelopes of
measures. Zeitschrift fur Wahrscheinlichkeitstheorie und Verwandte Gebiete, 68, 403
414.
Boole, G. (1854). An Investigation into the Laws of Thought on Which Are Founded the
Mathematical Theories of Logic and Probabilities. Macmillan, London.
Campos, L. M. d., & Moral, S. (1995). Independence concepts for sets of probabilities.
In Proc. Eleventh Conference on Uncertainty in Artificial Intelligence (UAI 95), pp.
108115.
Cattaneo, M. E. G. V. (2007). Statistical decisions based directly on the likeihood function.
Ph.D. thesis, ETH.
Chateauneuf, A., & Faro, J. (2009). Ambiguity through confidence functions. Journal of
Mathematical Economics, 45, 535  558.
Couso, I., Moral, S., & Walley, P. (1999). Examples of independence for imprecise probabilities. In Proc. First International Symposium on Imprecise Probabilities and Their
Applications (ISIPTA 99).
de Cooman, G. (2005). A behavioral model for vague probability assessments. Fuzzy Sets
and Systems, 154 (3), 305358.
Dubois, D., & Prade, H. (1998). Possibility measures: qualitative and quantitative aspects.
In Gabbay, D. M., & Smets, P. (Eds.), Quantified Representation of Uncertainty and
490

fiWeighted Regret-Based Likelihood

Imprecision, Vol. 1 of Handbook of Defeasible Reasoning and Uncertainty Management
Systems, pp. 169226. Kluwer, Dordrecht, Netherlands.
Epstein, L., & Schneider, M. (2007). Learning under ambiguity. Review of Economic
Studies, 74 (4), 12751303.
Fagin, R., Halpern, J. Y., & Megiddo, N. (1990). A logic for reasoning about probabilities.
Information and Computation, 87 (1/2), 78128.
Farkas, J. (1902). Theorie der enfachen ungleichungen. J. Reine und Angewandte Math.,
124, 127.
Gardenfors, P., & Sahlin, N. (1982). Unreliable probabilities, risk taking, and decision
making. Synthese, 53, 361386.
Gardenfors, P., & Sahlin, N. (1983). Decision making with unreliable probabilities. British
Journal of Mathematical and Statistical Psychology, 36, 240251.
Gilboa, I., & Schmeidler, D. (1989). Maxmin expected utility with a non-unique prior.
Journal of Mathematical Economics, 18, 141153.
Gilboa, I., & Schmeidler, D. (1993). Updating ambiguous beliefs. Journal of Economic
Theory, 59, 3349.
Giles, R. (1982). Foundations for a theory of possibility. In Gupta, M. M., & Sanchez, E.
(Eds.), Fuzzy Information and Decision Processes, pp. 183195. North-Holland.
Good, I. J. (1980). Some history of the hierarchical Bayesian methodology. In Bernardo,
J. M., DeGroot, M. H., Lindley, D., & Smith, A. (Eds.), Bayesian Statistic I, pp.
489504. University Press: Valencia.
Halpern, J. Y. (1997). Defining relative likelihood in partially-ordered preferential structures. Journal of A.I. Research, 7, 124.
Halpern, J. Y. (2003). Reasoning About Uncertainty. MIT Press, Cambridge, Mass.
Halpern, J. Y., & Leung, S. (2012). Weighted sets of probabilities and minimax weighted
expected regret: new approaches for representing uncertainty and making decisions. In
Proc. Twenty-Ninth Conference on Uncertainty in Artificial Intelligence (UAI 2012),
pp. 336345. To appear, Theory and Decision.
Halpern, J. Y., & Pucella, R. (2002). A logic for reasoning about upper probabilities.
Journal of A.I. Research, 17, 5781.
Huber, P. J. (1976). Kapazitaten statt Wahrscheinlichkeiten? Gedanken zur Grundlegung
der Statistik. Jahresbericht der Deutschen Mathematiker-Vereinigung, 78, 8192.
Huber, P. J. (1981). Robust Statistics. Wiley, New York.
Klibanoff, P., Marinacci, M., & Mukerji, S. (2005). A smooth model of decision making
under ambiguity. Econometrica, 73 (6), 18491892.
491

fiHalpern

Kyburg, Jr., H. E. (1988). Higher order probabilities and intervals. International Journal
of Approximate Reasoning, 2, 195209.
Levi, I. (1985). Imprecision and uncertainty in probability judgment. Philosophy of Science,
52, 390406.
Lorentz, G. G. (1952). Multiply subadditive functions. Canadian Journal of Mathematics,
4 (4), 455462.
Maccheroni, F., Marinacci, M., & Rustichini, A. (2006). Ambiguity aversion, robustness,
and the variational representation of preferences. Econometrica, 74 (6), 14471498.
Moral, S. (1992). Calculating uncertainty intervals from conditional convex sets of probabilities. In Proc. Eighth Conference on Uncertainty in Artificial Intelligence (UAI
95), pp. 199206.
Nau, R. F. (1992). Indeterminate probabilities on finite sets. Annals of Statistics, 40 (4),
17371767.
Niehans, J. (1948). Zur preisbildung bei ungewissen erwartungen. Schweizerische Zeitschrift
fur Volkswirtschaft und Statistik, 84 (5), 433456.
Ostrogradsky, M. V. (1838). Extrait dun memoire sur la probabilite des erreurs des tribuneaux. Memoires dAcademie St. Petersbourg, Series 6, 3, xixxxv.
Pearl, J. (1987). Do we need higher-order probabilities and, if so, what do they mean?. In
Proc. Third Workshop on Uncertainty in Artificial Intelligence (UAI 87), pp. 4760.
Savage, L. J. (1951). The theory of statistical decision. Journal of the American Statistical
Association, 46, 5567.
Schrijver, A. (1986). Theory of Linear and Integer Programming. Wiley, New York.
Scott, D. (1964). Measurement structures and linear inequalities. Journal of Mathematical
Psychology, 1, 233247.
Walley, P. (1991). Statistical Reasoning with Imprecise Probabilities, Vol. 42 of Monographs
on Statistics and Applied Probability. Chapman and Hall, London.
Walley, P. (1997). Statistical inferences based on a second-order possibility distribution.
International Journal of General Systems, 26 (4), 337383.
Williams, P. M. (1976). Indeterminate probabilities. In Przelecki, M., Szaniawski, K., &
Wojcicki, R. (Eds.), Formal Methods in the Methodology of Empirical Sciences, pp.
229246. Reidel, Dordrecht, Netherlands.
Wolf, G. (1977). Obere und untere Wahrscheinlichkeiten. Ph.D. thesis, ETH, Zurich.
Zadeh, L. A. (1978). Fuzzy sets as a basis for a theory of possibility. Fuzzy Sets and Systems,
1, 328.

492

fi