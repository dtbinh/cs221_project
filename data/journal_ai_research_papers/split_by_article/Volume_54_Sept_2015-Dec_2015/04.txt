Journal of Artificial Intelligence Research 54 (2015) 631-677

Submitted 7/15; published 12/15

On a Practical, Integer-Linear Programming Model for Delete-Free
Tasks and its Use as a Heuristic for Cost-Optimal Planning
Tatsuya Imai

TATSUYA . IMAI .30100041@ GMAIL . COM

Graduate School of Information Science and Engineering
Tokyo Institute of Technology
Tokyo, Japan

Alex Fukunaga

FUKUNAGA @ IDEA . C . U - TOKYO . AC . JP

Graduate School of Arts and Sciences
The University of Tokyo
Tokyo, Japan

Abstract
We propose a new integer-linear programming model for the delete relaxation in cost-optimal
planning. While a straightforward IP for the delete relaxation is impractical, our enhanced model
incorporates variable reduction techniques based on landmarks, relevance-based constraints, dominated action elimination, immediate action application, and inverse action constraints, resulting in
an IP that can be used to directly solve delete-free planning problems. We show that our IP model
is competitive with previous state-of-the-art solvers for delete-free problems. The LP-relaxation
of the IP model is often a very good approximation to the IP, providing an approach to approximating the optimal value of the delete-free task that is complementary to the well-known LM-cut
heuristic. We also show that constraints that partially consider delete effects can be added to our
IP/LP models. We embed the new IP/LP models into a forward-search based planner, and show
that the performance of the resulting planner on standard IPC benchmarks is comparable with the
state-of-the-art for cost-optimal planning.

1. Introduction
The delete relaxation of a classical planning problem is a relaxation of a planning problem such
that all delete effects are eliminated from its operators. In the delete relaxation, every proposition
that becomes true remains true and never becomes false again. The delete relaxation has been
studied extensively in the classical planning literature because it can be used to estimate the cost
of an optimal plan for the original planning problem and is therefore useful as a basis for heuristic
functions for search-based domain-independent planning algorithms. A solution for the original
planning problem is a solution for its delete relaxation, and the cost of the optimal solution to a
delete-relaxed problem can be lower than the cost of the original problem because in the relaxation,
every proposition only needs to be established once. Thus, the optimal cost of the delete relaxation
of a planning problem (denoted h+ ) is a lower bound on the optimal cost of the original planning
problem. Despite the fact that computing h+ is easier than solving the original planning problem,
computing h+ is itself NP-equivalent (Bylander, 1994) and poses a challenging problem.
In addition to its importance as a basis for heuristic functions for standard classical planning,
the delete relaxation is also interesting in its own right, because there are some problems that can
be naturally modeled as delete-free problems (i.e., problems where there are no actions with delete
effects). For example, the minimal seed set problem, a problem in systems biology which seeks
c
2015
AI Access Foundation. All rights reserved.

fiI MAI & F UKUNAGA

the minimal set of nutrients that are necessary for an organism to fully express its metabolism,
can be mapped to a delete-free planning problem (Gefen & Brafman, 2011). Another application
is in relational database query plan generation (Robinson, McIlraith, & Toman, 2014), where the
problem of determining join orders can be modeled as a delete-free problem.
In this paper, we propose a new, integer programming (IP) approach to computing h+ .1 We show
that this model allows fast computation of h+ , and that the linear programming (LP) relaxation of
this model can be used successfully as the heuristic function for an A* -based planner. The rest of
this paper is structured as follows: We begin with a review of previous work on the delete relaxation
as well as applications of LP to planning. Then we introduce IP(T + ), a basic integer programming
model for a delete-free planning problem (Section 3) and show that it correctly computes h+ . Since
the straightforward IP(T + ) model is often intractable and not useful in practice for computing
h+ , we develop an enhanced model, IPe (T + ), which reduces the number of variables in the IP by
using techniques such as landmark-based constraints, relevance analysis (Section 4). We evaluate
the performance of the basic IP(T + ) and enhanced IPe (T + ) models in Section 5, and show that
IPe (T + ) is competitive with the state-of-the-art methods for computing h+ .
While our objective is to use our IP models as a basis for a heuristic for forward state-space
search based planning, solving an IP at every node in the search algorithm is computationally daunting, so in Section 6, we propose and evaluate two relaxations to our IP(T + )-based IP models. We
consider the LP(T + ) and LPe (T + ), LP-relaxation of IP(T + ) and IPe (T + ), and show that the
LP-relaxations usually closely approximate h+ . We also introduce a time-relaxation of the IP and
LP models (IPetr (T + ) and LPetr (T + ), respectively) which further reduces the number of variables,
at the cost of sometimes underestimating h+ , and show that these time-relaxations usually closely
approximate h+ . We experimentally compare how closely these relaxed, delete-free models approximate h+ with the LM-cut heuristic (Helmert & Domshlak, 2009) and show that these approaches
are complementary.
Next, in Section 7, we evaluate the utility of our IP and LP models as heuristics for forwardsearch based planning by embedding them into an A* -based planner. Our results show that although
LPetr (T + ) is not competitive with the LM-cut heuristic overall, there are some domains where
LPetr (T + ) yields state-of-the-art performance, outperforming LM-cut.
We then turn to strengthening our IP and LP models by partially considering delete effects
(Section 8). We add constraints that enforce lower bounds on the number of times an action must be
used. These correspond to the net change constraints that were recently proposed by Pommerening
et al. (2014), as well as the action order relaxation by van den Briel et al. (2007). This tightened
bound IPc (T ) dominates IP(T + ). Counting constraints can also be added to the LP-relaxation


LPec (T ), as well as the time-relaxed LP-relaxation LPectr (T ). However, the additional counting
constraints makes the IP and LP more difficult, so in a A* -based planner that uses these bounds, there
is a tradeoff between a tighter bound (fewer nodes searched by A* ) and the time spent per node. As a
result, we find that although counting constraints result in enhanced performance on some domains,
it significantly degrades performance on other domains. We experimentally compare our countingconstraint enhanced models with the LMC-SEQ LP model of Pommerening et al. (2014) which
combines landmark and net-change constraints, and show that, like LM-cut vs our delete-free LPs,
these models are complementary.
1. This paper revises and extends the work originally reported by the authors in a paper presented at ECAI2014 (Imai &
Fukunaga, 2014). Formal results and proofs which were not in the ECAI paper are included, and this paper contains
a much more thorough experimental evaluation of our models (all of the experimental data is new).

632

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

Table 1 provides an overview of all of the IP/LP models discussed in Sections 3-8, and also
serves as a roadmap of this paper . For each model, we indicate the section in the text where the
model is introduced, the constraints used in the model, and the variable elimination optimizations
used in the model. Figure 1 is a directed graph showing the dominance relationships among the
optimal costs of the IP/LP models.
Finally, because there is no clear dominance relationship among our LP models (with respect
to the performance of A* -based planners that use these LP models as the heuristic function), we
propose and evaluate a simple automatic configuration heuristic which selects the LP to use as the
heuristic for A* (Section 9). This simple automated bound selection significantly boosts performance, resulting in a ensemble-based LP-heuristic that is competitive with state-of-the-art heuristics. Section 10 concludes the paper with a summary and discussion of our results and some directions for future work.

2. Background and Related Work
This section first introduces the notation for planning tasks which will be used in the rest of the paper, then surveys related work on solving delete-free planning tasks as well as previous applications
of IP/LP to domain-independent planning.
2.1 Preliminary Definitions
A STRIPS planning task is defined by a 4-tuple T = hP, A, I, Gi. P is a set of propositions. A
is a set of actions. A state is represented by a subset of P , and applying an action to a state adds
some propositions and removes some propositions in the state. Each action a  A is composed
of three subsets of P , hpre(a), add(a), del(a)i which are called the preconditions, add effects, and
delete effects. An action a is applicable to a state S iff it satisfies pre(a)  S. By applying a to
S, propositions in S change from S to S(a) = ((S \ del(a))  add(a)). For a sequence of actions
 = (a0 ,    , an ), we use S() to denote ((((S \ del(a0 ))  add(a0 )) \ del(a1 ))     )  add(an ).
Let I  P be the initial state and G  P the goal. A solution to a planning task is a sequence
of actions that transform I to a state S that satisfies G  S. Formally, a feasible solution, i.e., a
plan, is a sequence of actions  = (a0 ,    , an ) that satisfies (i) i, pre(ai )  I((a0 ,    , ai1 )),
and (ii) G  I().
The basic STRIPS planning task can be extended to STRIPS planning with action costs, where
each action a  A has an associated (non-negative) cost c(a). The objective of cost-optimal planning in a STRIPS
model with action costs is to find a plan  that minimizes the sum of the costs of
P
its actions i=n
c(a
i ).
i=0
The delete relaxation of a task T , denoted by T + , is a task hP, A+ , I, Gi where A+ is a set of
delete-free actions defined as A+ = {hpre(a), add(a), i | a  A}. We also use T + to denote a
task that is delete-free from the beginning without being relaxed.
2.2 Previous Work on Computing h+ and its Relaxations
The delete relaxation has been used as the basis for planning heuristics since the beginning of the
recent era of interest in forward-state space search based planning (Bonet & Geffner, 2001). Unfortunately, computing h+ is known to be NP-equivalent by reduction from vertex cover (Bylander,
633

fiI MAI & F UKUNAGA

Model
IP(T + ) (Sec. 3)
IPe (T + ) (Sec. 4)

Constraints
C1, C2, C3, C4,
C5, C6,
C1, C2a C3, C4,
C5, C6

Variable Eliminations
None
Landmarks (4.1), relevance (4.2), dominated
action elimination (4.3),
immediate action application (4.4)
None
Same as IPe (T + )
Same as IPe (T + )

LP(T + ) (Sec. 6.1)
LPe (T + ) (Sec. 6.1)
LPetr (T + ) (Sec. 6.2)

Same as IP(T + )
Same as IPe (T + )
C1, C2a C3, C4,

IPc (T ) (Sec. 8)

C1, C2, C3, C4,
C5, C6, C7 C8

None

IPec (T + ) (Sec. 8)

C1, C2a C3, C4,
C5, C6 C7 C8

LPc (T ) (Sec. 8)

LPec (T ) (Sec. 8)

LPectr (T ) (Sec. 8)

Same as IPc (T )

Same as IPec (T )
C1, C2a C3, C4,
C7 C8

Landmarks (4.1), relevance
(4.2), modified dominated
action elimination (Definition 2)
None

Same as IPec (T )

Same as IPec (T )

A* /autoconf (Sec. 9)

Selects among LPe (T + ), LPetr (T + ), LPec (T ),

LPectr (T ).



Basic delete-free task IP
model (computes h+ )
Enhanced IP model (computes h+ )

LP relaxation of IP(T + )
LP relaxation of IPe (T + )
LP-relaxation of timerelaxation of IPe (T + )
Basic delete-free task
IP model enhanced with
counting constraints
Enhanced IP model with
counting constraints

LP relaxation of IPc (T )

LP relaxation of IPec (T )
LP-relaxation of time
relaxation of IPec (T )



Automatic LP Model Selection

Table 1: Overview of delete-relaxation based IP/LP models in this paper

LP(T+)

LPtr(T+)

LPe(T+)

IP(T+) = IPe(T+) =aaa
h+

IPcec(T)

LPec
c(T)

LPtre(T+)

IPtre(T+)

ec(T)
IPctr

e (T)
c
LPctr

IPtr(T+)

Figure 1: Dominance relationships among our IP/LP models. Edge modeli  modelj indicates the
optimal cost of modeli  the optimal cost of modelj . The 4 highlighted LPs are the components
of the A* /autoconf model.

634

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

1994), and therefore, from the beginning, researchers avoided direct computation of h+ , and instead
sought approximations to h+ .
In satisficing planning, where optimal solutions are not required, a successful approach to deriving heuristics has been to approximate the delete relaxation. The additive heuristic (hadd ) assumes
that subgoals are independent and computes the sum of achieving each subgoal in the delete-relaxed
model (Bonet & Geffner, 2001). The FF heuristic (Hoffmann & Nebel, 2001) constructs a planning
graph (Blum & Furst, 1997) for the delete-relaxed problem, extracts a relaxed plan, and computes
the number of actions in the relaxed plan, which is an upper bound on h+ .
In the case of cost-optimal planning, where each action is assigned a cost and the objective is to
find a minimal cost plan, lower bounds on h+ are the basis for several admissible heuristic functions
that have been used in the literature. Bonet and Geffner (2001) proposed the hmax heuristic, which
computes the highest cost associated with achieving the most costly, single proposition. While
hmax is admissible, it is often not very informative (i.e, the gap between hmax and h+ is large)
because it only considers the single most costly goal proposition. The admissible landmark cut
(LM-cut) heuristic (Helmert & Domshlak, 2009), approximates h+ as follows. For state s, the LMcut heuristic first computes hmax (s), and if this is zero or infinite, then h+ is zero or infinite, so
hLM cut (s) = hmax (s). Otherwise, a disjunctive action landmark L (a set of actions at least one of
which must be included in any relaxed plan) is computed, and the cost of all actions in L is reduced
by c(m), the cost of the minimal-cost action m  L, and hLM cut is increased by c(m). This process
is repeated until hmax (s) (for the remaining, reduced problem) becomes 0. Other approximations to
h+ that are more informative than hmax include the set-additive heuristic (Keyder & Geffner, 2008)
and cost-sharing approximations to hmax (Mirkis & Domshlak, 2007).
Previous planners have avoided direct computation of h+ because the extra search efficiency
gained from using h+ is offset by the high cost of computing h+ . As far as we are aware, the first
actual use of h+ inside a cost-optimal planner was by Betz and Helmert (2009), who implemented
domain-specific implementations of h+ for several domains. More recently, Haslum et al. evaluated
the use of a domain-independent algorithm for h+ (Haslum, Slaney, & Thiebaux, 2012) as the
heuristic function for A* -based cost-optimal planning, but found that the performance was relatively
poor (Haslum, 2012).
In recent years, there have been several advances in the computation of h+ . Since, as described
above, the LM-cut heuristic (Helmert & Domshlak, 2009) is a lower bound on h+ , a cost-optimal
planner using the A* search algorithm and the LM-cut heuristic can be directly applied to the delete
relaxation of a classical planning problem in order to compute h+ . It is possible to improve upon
this by developing methods that exploit the delete-free property and are specifically tailored for
solving the delete relaxation. Pommerening and Helmert (2012) developed an approach which uses
IDA* or branch-and-bound with an incrementally computed LM-cut heuristic. Gefen and Brafman
(2012) proposed action pruning for delete-free problems.
A different approach to computing h+ is based on the observation that h+ could be formulated
as the problem of finding a minimal hitting set for sets of disjunctive action landmarks (Bonet &
Helmert, 2010). This led to methods for computing h+ by searching for minimum-cost hitting set
for a complete set of action landmarks for the delete-relaxed planning problem (Bonet & Castillo,
2011; Haslum et al., 2012). While the original implementation of Haslum et al.s hitting-set based
h+ solver used a problem-specific branch-and-bound algorithm (Haslum et al., 2012), an improved
implementation (which we use in our experimental evaluation in Section 5) uses integer programming to solve the hitting set problem (Haslum, 2014a).
635

fiI MAI & F UKUNAGA

2.3 Integer/Linear Programming for Classical Planning
Another related line of research is the modeling of classical planning as integer/linear programs
(ILP). The use of very high-performance, general problem solvers to solve planning problems was
pioneered by Kautz and Selman, who solved planning problems by encoding them as propositional
satisfiability (SAT) and applied state-of-the-art SAT solvers. The basic approach is to instantiate a
SAT formula for which a satisfying assignment implies a t-step plan. SATPLAN starts with a small
value of t (e.g., trivially, 1, or some other lower bound), instantiates a propositional formula F (t)
which is satisfiable if and only if a plan of t parallel steps or less exists. If F (t) is satisfiable, then
a minimal parallel makespan plan has been found. Otherwise, t is incremented, and this process
is repeated until a plan is found. While the initial encodings were modestly successful (Kautz &
Selman, 1992), advances in both SAT solver technology as well as improvements to the encoding
and the integration of planning graphs (Blum & Furst, 1997) led to dramatic performance improvements (Kautz & Selman, 1996, 1999). Recent work on SAT-based planning includes improved
encodings as well as execution strategies for SAT strategies that improve upon simply incrementing
t as above (Rintanen, Heljanko, & Niemela, 2006). In addition, improvements to SAT solvers which
specifically target domain-independent planning have been investigated (Rintanen, 2012)
Since the expressiveness of integer programming (IP) subsumes SAT, SAT encodings can be
straightforwardly translated to IP. However, direct translation of SAT encodings to IP resulted in
poor performance, and a state-change formulation which replaces the original fluents in the SAT
encoding with a set of variables that directly expresses the addition, deletion, and persistence of
fluents was shown to be more successful as the basis for an IP model for planning (Vossen, Ball,
Lotem, & Nau, 1999). This formulation was strengthened with additional mutual exclusion constraints (Dimopoulos, 2001). The Optiplan model (van den Briel & Kambhampati, 2005) combined
the state-change IP formulation with the planning-graph based model refinement strategies and improvements by Dimopoulous (2001). As with the SAT-based approaches described above, IP models
which are feasible if and only if a plan of up to t steps exists are constructed. However, unlike the
SAT formulation, it is easy to directly encode action costs into the objective function for the IP
model, so the IP models can be used to directly solve the cost-optimal planning problems. Another
approach decomposes a planning instance into a set of network flow problems, where each subproblem corresponds to a state variable in the original planning problem (van den Briel, Vossen, &
Kambhampati, 2008).
Instead of modeling and directly solving a classical planning problem as an IP, another approach, which we adopt in this paper, uses ILP models to provide a heuristic function which guides
a state-space search planning algorithms such as A* . An early instance of this approach (which,
to our knowledge, is also the earliest application of LP to classical planning) is LPlan, where an
LP encoding of the classical planning problem is used as a heuristic function for a partial order
planner (Bylander, 1997). Van den Briel et al. (2007) developed an admissible heuristic based on
an LP model which represents a planning problem where the order in which actions are executed
is relaxed, and each variable represents the number of times an action is executed. Delete effects
are considered, in that there are constraints such that the number of actions that delete values can
be incremented only if there are actions that add the value. Although this LP-based heuristic was
not integrated into a planning system, they compared the relaxed problem cost found by their model
with Bylanders LPlan LP model, as well as an LP model for h+ .
636

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

To our knowledge, the h+ implementation by van den Briel et al. (2007) is the first implementation of an IP model of h+ . First, a relaxed planning graph (Blum & Furst, 1997) was expanded
until quiescence, which results in the instantiation of all actions that are relevant for the optimal
delete-free task as well as an upper bound on the number of steps in the optimal delete-free task.
Then, h+ was computed using a delete-relaxed, step-based encoding of the planning problem of
Optiplan (van den Briel, 2015).
Cooper et al. (2011) showed that the optimal solution to the dual of an LP model which relaxes the action ordering corresponds to the best lower bound that can be obtained by applying
transformations to the original planning problem that shift costs among actions that affect the same
fluents.
Bonet proposed hSEQ , an admissible, flow-based LP heuristic based on Petri Net state equations (Bonet, 2013) which was used as the heuristic for an A* -based planner. Bonet and van den
Briel (2014) enhanced Bonets flow-based LP model by adding action landmark constraint and implementing variable merging strategies, resulting in a competitive, admissible heuristic. Karpas and
Domshlak (2009) proposed an LP formulation to compute optimal partitioning for landmarks. Pommerening et al. (2014) proposed an operator counting framework which enabled the unification of a
number of ideas, including the state equation formulation (Bonet, 2013), post-hoc optimization constraints (Pommerening, Roger, & Helmert, 2013), as well as landmarks (the formulation by Bonet
& Helmert, 2010, which is the dual of the formulation in Karpas & Domshlak, 2009) and state
abstraction heuristics (Katz & Domshlak, 2010). They showed that combinations of constraints resulted in strong heuristics which significantly outperformed the LM-cut heuristic. A recent survey
by Roger and Pommerening (2015) presents a survey of LP-based heuristics for planning which
includes an earlier conference version of this paper (Imai & Fukunaga, 2014) and suggests how our
delete-relaxation model could be incorporated into the operator counting framework by associating
a operator-counting variable for each action variable (see below) in the delete-relaxed problem.

3. IP(T + ): The Basic IP Formulation of a Delete-Free Task
We now define the integer program IP(T + ), which is the IP formulation of the delete free task
T + = hP, A+ , I, Gi. Note that for any feasible solution to IP(T + ) (not just the optimal solution),
we can derive a corresponding, feasible and non-redundant (i.e., each action appears only once)
plan for T + that has the same cost as the IP(T + ) solution.
First, we define the variables of IP(T + ). In addition to being able to derive a plan from IP(T + ),
there always exists an injective mapping from a feasible non-redundant plan for an IP(T + ) solution.
Thus, we also show the feasible assignments of variables that can be derived from a feasible plan
for T + , as well as the meanings and roles of the variables. We use  = (a0 ,    , an ) to denote a
plan for T + corresponding to a solution for IP(T + ). We say that a is the first achiever of p in plan
 if p 6 I, and a is the first action that achieves (establishes) p.
proposition: p  P, U (p)  {0, 1}. U (p) = 1 iff p  I(). U (p) indicates whether proposition p
is achieved in a relaxed plan for T + .
action: a  A, U (a)  {0, 1}. U (a) = 1 iff a   holds. U (a) indicates whether the action a is
used in a relaxed plan.
add effect: a  A, p  add(a), E(a, p)  {0, 1}. E(a, p) = 1 iff a   holds and a is the first
achiever of p. E(a, p) = 0 if p is true in I, or p is not achieved.
637

fiI MAI & F UKUNAGA

time (proposition): p  P, T (p)  {0,    , |A|}. T (p) = t when p  I() and p is added by
at1 first. T (p) = 0 if p is a member of I. T (p) indicates the time step where p is first
achieved by its first achiever.
time (action): a  A, T (a)  {0,    , |A|}. T (a) = t when a = at . T (a) = |A| when a 6 .
T (a) indicates the time step where a is first used.
initial proposition: p  P, I(p)  {0, 1}. I(p) = 1 iff p  I.
If p  P is achieved more than once, i.e., p appears in the add effects of multiple actions in ,
we assign T (p) the index of the first such action in . If p is not achieved, i.e., p 6 I() holds, we
can assign an arbitrary value in {0,    , |A|} to T (p). Given a delete-free task T + and its feasible
and non-redundant plan , we call the above assignment a solution derived from .
We use
Pthe following fact in later proofs: a solution derived from a feasible solution satisfies (a) a A s.t.padd(a ) E(a , p)  1 for any proposition p such that U (p) = 1, and (b)
P

a A s.t.padd(a ) E(a , p) = 0 for any proposition p such that U (p) = 0.
Variables I(p) are auxiliary variables for computing h+ . Although they are redundant when
solving a delete-free task only one time, they are useful to avoid reconstructing constraints for each
state when IP(T + ) or LP(T + ) are embedded as a heuristic function in a forward-search planner
and called for each state.
The objective function is defined as follows:
X
minimize:
c(a)U (a).
(1)
aA

Because of this objective function, the cost of a solution to IP(T + ) is equal to the cost of the
corresponding (delete-free) plan.
Finally we define the following six constraints.
(C1) p  G, U (p) = 1. (The goals must be achieved).
(C2) a  A, p  pre(a), U (p)  U (a). (Actions require their preconditions).
(C3) a  A, p  add(a), U (a)  E(a, p). (An action can be the first achiever only if it is used).
P
(C4) p  P, I(p) + a A s.t.padd(a ) E(a , p) = U (p). (If a proposition is achieved, it must be
true in the initial state or is the effect of some action).
(C5) a  A, p  pre(a), T (p)  T (a). (Actions must be preceded by the satisfaction of their
preconditions).
(C6) a  A, p  add(a), T (a) + 1  T (p) + (|A| + 1)(1  E(a, p)). (If a is the first achiever
of p, then a must precede p).
Now we can show that a solution of IP(T + ) derived from a feasible non-redundant plan of
is feasible. For a variable V of IP(T + ), VF describes the assignment of V on a solution F of
IP(T + ).
T+

Proposition 1. Given a delete-free task T + and a feasible, non-redundant plan  for T + , the
solution F to IP(T + ) derived from  is a feasible solution to IP(T + ).
638

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

Proof. F clearly satisfies constraint C1 since  satisfies G  I().
Constraint C2 is not satisfied only if there exists an action a  A and a proposition p  pre(a)
such that U (a)F = 1 and U (p)F = 0. However, if U (a)F = 1, then U (p)F = 1 because  is a
delete-free feasible plan and p has to be established at some point. We can show that F satisfies
constraints C3 and C4 by similar arguments. If there exists an action a  A and a proposition
p  add(a) such that E(a, p)F = 1, U (a)F = 1 must hold according to the definition of F . In
addition, if there exists a proposition p such that U (p)F = 1, there exists a first achiever a  A of p
such that E(a, p)F = 1, or p is a member of the initial state I.
If an action a  A is a member of , then all propositions in its precondition must be achieved
before a is used. Hence, according to the definition of F , we have T (p)F  T (a)F for any action a
in the plan . If an action a  A is not a member of , then we have T (a)F = |A|. Thus, constraint
C5 is satisfied for any action a not in the plan , regardless of the values of T (p)F .
Finally F satisfies constraint C6 for any action a  A and for any proposition in its precondition
p  pre(a). If a is not the first achiever of p, i.e., E(a, p) = 0, then constraint C6 is satisfied
regardless of the values of T (p)F and T (a)F . If a is the first achiever of p, then, according to the
definition of F , we have T (p)F = T (a)F + 1 , which satisfies constraint C6.
In addition, there exists a feasible plan only if IP(T + ) has a feasible solution. When IP(T + ) is
solved optimally, an optimal plan for T + is obtained according to the following proposition.
Proposition 2. Given a feasible solution F for IP(T + ), the action sequence  = (a0 ,    , an )
obtained by ordering actions in the set {a | U (a)F = 1} in ascending order of T (a)F is a feasible
plan for T + .
Proof. First we show that  satisfies the condition (ii) of a plan (i.e., G  I()) using a proof by
contradiction. Assume that there exists a proposition g  G that satisfies g 6 I(). Then, there
exists no action achieving g in . Since F is a solution to IP(T + ), U (g)F = 1 due to constraint
C1. Since g 6 I() implies g 6 I, I(g)F = 0. Therefore, to satisfy constraint C4, there must
exist an action a  A such that g  add(a) and E(a, g)F = 1. However, to satisfy constraint C3,
U (a)F = 1 has to hold. This means a  , which contradicts the assumption.
Next we show that  satisfies condition (i) (i.e., i, pre(ai )  I((a0 ,    , ai1 ))). For the base
case of an inductive proof, assume that there exists a proposition p  P satisfying p  pre(a0 )
and p 6 I. Since a0  , U (a0 )F = 1 has to hold, and U (p)F = 1 has to hold according to the
constraint U (p)F  U (a0 )F . Then, similar to the proof of condition (ii), there must exist an action
a  A such that p  add(a), U (a)F = 1, and E(a, p)F = 1. However, to satisfy constraint C5,
T (p)  T (a0 ) must be true, and T (a) + 1  T (p) has to hold to satisfy constraint C6. Therefore
we have U (a)F = 1 and T (a) < T (a0 ), but a0 is the first action of , a contradiction.
Similar to the case of i = 0, when i > 0, if pre(ai )  I((a0 ,    , ai1 )) is not true, there must
exist an action a 6 (a0 ,    , ai1 ) such that U (a)F = 1 and T (a) < T (ai ), contradicting the fact
that ai is the i-th action of the sequence .
Corollary 1. Given an optimal solution F of IP(T + ), a sequence of actions built by ordering
actions in the set {a | U (a)F = 1} by ascending order of T (a)F is an optimal plan for T + .
P
+ ) is 3|P | + 2|A| +
The number of variables
in
IP(T
|add(a)|. The number of constraints
P
P
is
Pless than 2|P
P| + 2 aA |pre(a)| + 2 aA |add(a)|. The number of terms is also O(|P | +
|pre(a)| + |add(a)|).
639

fiI MAI & F UKUNAGA

4. Enhanced IP Model
While IP(T + ) provides an IP model for exactly computing h+ , we shall see in Section 5 that
IP(T + ) by itself is not competitive with previous methods for computing h+ . Thus, in this section,
we introduce some variable elimination techniques and some modifications to constraints in order
to speed up the computation h+ . As we will show in the experimental results, IPe (T + ), which
incorporates these enhancements, computes h+ significantly faster than IP(T + ). Some of the enhancements below are adopted into our IP framework from previous work in planning research. In
particular, a landmark-based variable reduction method plays a key role.
Note that some of the enhancements introduce constraints that render some solutions of IP(T + )
mapped from feasible plans for T + infeasible. However, we show that in such cases, at least one
optimal plan will always remain valid in the enhanced model, so the optimal cost of the enhanced
model still corresponds to h+ .
4.1 Landmark-Based IP Model Reduction
A landmark is an element which needs to be used in every feasible solution (Hoffmann, Porteous,
& Sebastia, 2004). We use two kinds of landmarks, called fact landmarks and action landmarks as
in the work of Gefen and Brafman (2012). A fact landmark of a planning task T is a proposition
that becomes true in some state of every feasible plan, and an action landmark for a planning task
T is an action that is included in every feasible plan. We also say that a fact or action landmark
l is a landmark for a proposition p if l is a landmark for the task hP, A, I, {p}i. Similarly we say
that a landmark l is a landmark for an action a if l is a landmark for the task hP, A, I, pre(a)i. In
the IP model of a delete-free task T + , if a proposition p is a fact landmark for a proposition in the
goal G, then we can substitute U (p) = 1. Similarly, if an action a is an action landmark, then we
can substitute U (a) = 1. Landmark extraction and substitution clearly do not prune any feasible
solutions of IP(T + ).
To actually extract the set of landmarks that satisfy the above intensional definitions, a landmark
extraction algorithm is necessary. It is easy to see that given
a feasible delete-free task,
ff a proposition
add
p  P is a fact landmark if and only if p  I holds or P, A \ Ap , I \ {p}, G is infeasible,
= {a | p  add(a)}. Similarly an action a  A is an action landmark if and only
where Aadd
p
if hP, A \ {a}, I, Gi is infeasible. Hence, for each landmark candidate, we can test whether it is
a landmark by checking the feasibility of the delete-free task which excludes that candidate. The
feasibility of a delete-free task can be checked using the following, straightforward algorithm based
on the delete-relaxed planning graph method by Hoffmann and Nebel (2001): For each fluent, let
e(p)  {0, 1} represent whether p is achievable or not. For each action, let e(a)  {0, 1} represent
whether the preconditions of a are satisfied or not. Initially, e(p) = 1 for all p  I , e(p) = 0
for all other fluents. and e(a) = 0 for all a. At each step of the algorithm, for all actions for
which e(a) = 0 and whose preconditions are satisfied; (1) set e(a) = 1, and (2) set e(p) = 1 for
all e  add(a). The algorithm terminates when it reaches quiescence, i.e., no actions for which
e(a) = 0 and whose preconditions are satisfied can be found. This takes at most |A| steps. By
repeating this feasibility check for all facts and actions, we have an algorithm that collects all fact
landmarks and action landmarks satisfying the definitions above in O(|T + |2 )-time.
If we were only interested in computing h+ once, a straightforward method such as the one
described above would be sufficient. However, since we intend to use our h+ -based models as
heuristic functions for forward state-space search planning, the landmark extraction needs to be
640

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

performed repeatedly during the search, so the efficiency of the extraction procedure is important.
We experimented with several methods, and describe our most effective method below.
Our method for extracting landmarks is based on the method by Zhu and Givan (2003), who
proposed a planning based propagation method for collecting causal landmarks. Their method was
later generalized by Keyder et al. to an AND-OR graph based landmark extraction method (Keyder,
Richter, & Helmert, 2010).
Zhu and Givan (2003) define a proposition p as a causal landmark if hP, A \ Apre
p , I \ {p}, Gi
pre
is infeasible, where Ap = {a | p  pre(a)}. They focus on causal landmarks, ignoring other
(non-causal) landmarks because they are nonessential (even misleading) from the point of view of
guiding a search algorithm that uses a landmark-based heuristic. In contrast, we use landmarks in
order to reduce the number of variables in our IP model of the delete relaxation. Thus, instead of
focusing on causal landmarks and using Zhu and Givans criteria, we seek a larger set of landmarks
by slightly modifying 
the criterion for landmark
detection. If hP, A \ Apre
p , I \ {p}, Gi does not
ff
have a solution, then P, A \ Aadd
,
I
\
{p},
G
must
also
be
infeasible,
and furthermore, using
p
pre
add
Ap instead of Ap can extract a larger set of fact landmarks. In addition, while Zhu and Givan
used a forward propagation algorithm based on the layered planning graph of the delete-free task
T + , we use the following, open-list based propagation algorithm.
For each proposition p, we compute a set of fact landmarks for p, using an iterative method
based on the following update equations characterizing fact landmarks:
 If p is a member of the initial state I, then {p} is the set of fact landmarks to achieve p.
T
 If p is not a member of I, then the set of fact landmarks for p is {p} aA s.t.padd(a) (add(a)
S

p pre(a) (fact landmarks for p )).
The pseudocode for this open list based propagation algorithm is shown in Algorithm 1. In the
initialization phase, the candidate set for each proposition p 6 I is set to P , and the fact landmarks
for each p  I is set to {p} (Lines 1-3). In addition, an action a is inserted into a FIFO queue Q if it
satisfies pre(a)  I (Lines 4-7). The main loop of the iterative method is similar to the straightforward method described above. At each iteration, an action a is retrieved from Q, and the candidate
set of fact landmarks is updated for each p  add(a) based on the second equation (Lines 12-14).
Moreover, the method memorizes the achievability of p (Line 11), and action a is inserted into Q
if all members of pre(a ) are achievable and if the candidate set of p  pre(a ) is changed (Lines
15-17). This process continues until Q becomes empty. For clarity and simplicity, some implementation details/optimizations are omitted from Algorithm 1, e.g., instead of literally inserting every
member of P into L[p] in Line 3, we use a single flag to represent L[p] = P  Updating a candidate set always reduces the number of its elements, so this method always terminates. Unlike the
simpler O|T + |2 algorithm described above, this algorithm is not complete (not all landmarks will
be extracted). However, the soundness of this method is guaranteed by the following proposition.
Proposition 3. Given a delete-free STRIPS planning task hP, A+ , I, Gi, assume all propositions
in P can be achieved. Let L(p) be the set of fact landmark candidates for p computed by some
landmark extracting method. If
(i) L(p) = {p} for p  I, and
S
T
(ii) L(p) = {p}  aA s.t.padd(a) (add(a)  p pre(a) L(p )) for p 6 I
641

fiI MAI & F UKUNAGA

Algorithm 1 Our landmark extracting method
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:

// L[p] are sets of candidates of fact landmarks for p  P .
L[p]  P for each p 6 I;
L[p]  {p} for each p  I;
S  I;
for a  A do
insert a into a FIFO queue Q if pre(a)  S;
end for
while Q is not empty do
retrieve an action a from Q.
for p  add(a) do
S  S  {p}.
S
X  L[p]  (add(a)  p pre(a) L[p ]);
if L[p] 6= X then
L[p]  X.
for a  Apre
p do

insert a into Q if pre(a )  S and a 6 Q;
end for
end if
end for
end while
// At this point, L[p] contain sets of fact landmarks for p  P .

are satisfied, then all elements of L(p) are fact landmarks for p.
Proof. Assume that some proposition q satisfies q  L(p) and q is not a fact landmark for p. We
have p 6= q since any proposition is a fact landmark for itself. Then, L(p) has more than one
proposition, and from condition (i) and (ii), p 6 I holds. Since q is not a landmark, there exists a
non-empty feasible plan for the delete-free task hP, A+ , I, {p}i that does not achieve q.
Let  = (a0 ,    , an ) be such a plan, and let ai be the action in  that achieves p first. We have
p 6= q as stated above, andS
we have q 6 add(ai ) since  does not achieve q. Hence, according to
condition (ii), we have q  p pre(ai ) L(p ). Let p be a member of pre(ai ) that satisfies q  L(p ).
Since  is a feasible plan that does not achieve q, p is achieved by , and thus p 6= q holds. Then,
L(p ) has more than one proposition, and again, p 6 I holds. Hence,   = (a0 ,    , ai1 ) is a
non-empty feasible plan for a delete-free task hP, A+ , I, {p }i that does not achieve q.
This argument can be extended ad infinitum, but the length of  is clearly finite, so we have a
contradiction. Thus, all members of L(p) are fact landmarks for p for each proposition p  P .

In addition to the fact landmarks which are extracted using the above procedure, our algorithm
extracts action landmarks using the criterion: if a proposition p is a fact landmark of G, and if only
one action a can achieve p, then a is used as an action landmark of G.
642

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

4.2 Relevance Analysis
Backchaining relevance analysis is widely used to eliminate propositions and actions that are irrelevant to a task. An action a is relevant if (i) add(a)  G 6= , or (ii) there exists a relevant action
a satisfying add(a)  pre(a ) 6= . A proposition p is relevant if (i) p  G, or (ii) there exists a
relevant action a and p  pre(a) holds.
In addition, as noted by Haslum et al. (2012), it is sufficient to consider relevance with respect to only a subset of first achievers of an add effect. Although they defined a first achiever
by achievability of a proposition, it is equivalent to the following definition: an action a is a first
achiever of a proposition p if p  add(a) and p is not a fact landmark for a. Let fadd(a) denote
{p  add(a) | a is a first achiever of p}. It is sufficient to use fadd instead of add in the above
definition of relevance.
If a  A or p  P is not relevant, we can eliminate a variable as U (a) = 0 or U (p) = 0.
In addition to this, if p  add(a) but a is not a first achiever of p, we can eliminate a variable as
E(a, p) = 0. It is possible for a fact landmark fact to be irrelevant, in which case we set U (p) = 1.
While this variable elimination prunes some feasible solutions, it clearly does not prune any optimal
solutions.
4.3 Dominated Action Elimination
In a delete-free task, if two actions have the same add effects, then it is clearly sufficient to use
at most one of these two actions. This idea can be generalized to the following reduction, which
eliminates useless (dominated) actions.
Proposition 4. Given a feasible delete-free task T + , there exists an optimal plan that does not
contain a  A if there exists an action a  A satisfying the following: (i) fadd(a)  fadd(a ), (ii)
for all p  pre(a ), p is a fact landmark for a or p  I, and (iii) c(a)  c(a ).
Proof. For any plan  = (a0 ,    , ai1 , a, ai+1 ,    , an ) of T + , we show that a sequence of actions
  = (a0 ,    , ai1 , a , ai+1 ,    , an ) is also a feasible plan. Each proposition of pre(a ) is a fact
landmark for a, hence, if pre(a)  I((a0 ,    , ai1 )), then pre(a )  I((a0 ,    , ai1 )) also
holds. By the definition of first achievers, add(a) \ fadd(a)  I((a0 ,    , ai1 )), so we also have
I((a0 ,    , ai1 , a))  I((a0 ,    , ai1 , a ). Therefore G  I(  ) (  is a feasible plan).
Finally, c()  c(  ) because c(a)  c(a ). Therefore, if a plan contains a, it is not optimal, or
there exists another optimal plan which does not contain a.
If there exists a dominated action a, we can eliminate a variable by setting U (a) = 0. This
variable elimination prunes some feasible solutions of IP(T + ). Moreover, it sometimes prunes
some optimal solutions if c(a) = c(a ) holds for the condition (iii). However, as shown in the proof
above, at least one optimal solution remains.
This is a slight generalization of a similar set of constraints by Robinson (2012)[Definition
5.3.4, p. 108] for a MaxSAT-based planner. Robinsons dominance condition checks whether (R1)
add(a) \ I  add(a ) \ I, (R2) pre(a ) \ I  pre(a) \ I, and (R3) c(a)  c(a ). While our
condition (iii) and (R3) are equivalent, our condition (i) is less strict than condition (R1) because
instead of checking all add effects, condition (i) only tests whether the propositions for which a is a
first achiever is subsumed by those of a . Furthermore, our condition (ii) subsumes (R2) because if
each proposition of pre(a ) is a fact landmark for a, then if pre(a)  I((a0 ,    , ai1 )), pre(a ) 
I((a0 ,    , ai1 )) also holds, satisfying (R2).
643

fiI MAI & F UKUNAGA

4.4 Immediate Action Application
On a delete-free task T + , some actions can be immediately applied to the initial state without
affecting the optimality of the relaxed plan. We adopt immediate application of zero-cost actions
(Gefen & Brafman, 2011) as well as immediate application of action landmarks (Gefen & Brafman,
2012). For a delete-free task T + , if an action a  A satisfies c(a) = 0 and pre(a)  I, then a
sequence made by placing a before an optimal plan for hP, A \ {a}, I  add(a), Gi is an optimal
plan for T + . Similarly, if an action a is an action landmark for T + and a is applicable to I, a can
be applied to I immediately.
In the IP(T + ) model, variables T (p) for p  I can be eliminated by substituting zero for
their values. Given a sequence of immediately applicable actions (a0 ,    , ak ) (it must be a correct
applicable sequence), we can eliminate some variables as follows: (i) U (ai ) = 1, (ii) T (ai ) = i,
(iii) p  pre(ai ), U (p) = 1, (iv) p  add(ai ) \ I((a0 ,    , ai1 )), U (p) = 1, T (p) = i and
E(ai , p) = 1, and (v) p  add(ai ) \ I((a0 ,    , ai1 )), a  A \ {a0 ,    , ai }, E(a, p) = 0.
4.5 Iterative Application of Variable Eliminations
The variable elimination techniques described above can interact synergistically with each other
resulting in a cascade of eliminations. Therefore, we used an iterative variable elimination algorithm
which applies eliminations until quiescence. The order in which each elimination is applied is shown
in Algorithm 2. A full landmark extraction pass after each variable elimination would be extremely
expensive. Therefore, we perform a landmark extraction only once before the iterative application
of the other eliminations.
Algorithm 2 Iterative Variable Elimination
relevance analysis;
landmark extraction;
While a variable can be eliminated do
immediate action application;
dominated actions elimination;
relevance analysis;

4.6 Inverse Action Constraints
We define the following inverse relationship between a pair of actions for a delete-free task T + .
Definition 1 (inverse action). For two actions a1 , a2  A, a1 is an inverse action of a2 if: (i)
add(a1 )  pre(a2 ), and (ii) add(a2 )  pre(a1 ).
By definition, it is clear that if a1 is an inverse action of a2 , then a2 is an inverse action of a1 .
Inverse actions satisfy the following fact.
Proposition 5. Given a delete-free task T + , let  = (a0 ,    , an ) be a feasible plan. If ai   is
an inverse action of aj  , and if i < j holds, then   = (a0 ,    , aj1 , aj+1 ,    , an ) is also a
feasible plan.
Proof. Since  is a feasible plan for T + , pre(ai )  I((a0 ,    , ai1 ))  I((a0 ,    , aj1 )). By the
definition of inverse actions, add(aj )  pre(ai ) holds, and add(aj )  pre(ai )  I((a0 ,    , aj1 )) =
644

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

I((a0 ,    , aj )). Hence (aj+1 ,    , an ) is applicable to I((a0 ,    , aj1 )), and G  I(  ) =
I().
Corollary 2. For a delete-free task T + , a feasible solution  = (a0 ,    , an ) is not optimal if
ai   is an inverse action of aj   and both of ai and aj have non-zero cost.
There are several possible ways to use the above proposition (e.g., U (a) + U (a )  1, for all
 inv(a), where inv(a) is the set of inverse actions of a). In order to avoid adding a large number
of constraints to the IP(T + ) model (|A/2|2 in the worst case where half of the actions are inverses
of the other), we modify constraint C2 as follows:
P
(C2a) a  A, p  pre(a), U (p) a inv(a,p) E(a , p)  U (a), where inv(a, p) denotes the set
of inverse actions of a which have p as an add effect.
a

Proposition 6. Given a delete-free task T + , if IP(T + ) with constraint C2 has a feasible solution,
then an optimal solution to IP(T + ) with constraint C2 is also feasible for IP(T + ) with constraint
C2a.
Proof. Let F  be an optimal solution to IP(T + ) with constraint C2 derived from an optimal plan
for T + . Since F  satisfies all the constraints of IP(T + ) with constraint C2, it suffices to show that
F  satisfies constraint C2a for any action a  A and proposition p  pre(a).
P
Recall that a feasible solution derived from a feasible plan satisfies a A s.t.padd(a ) E(a , p) 
P
1 for any proposition p such that U (p) = 1, and it also satisfies a A s.t.padd(a ) E(a , p) = 0 for
P
P
any proposition p such that U (p) = 0. Since a A s.t.padd(a ) E(a , p)  a inv(a,p) E(a , p)
for any action a  A and proposition p  pre(a), F  clearly satisfies constraint C2a if U (p)F  = 1


and U (a)F  = 0, or
Pif U (p)F = 0 and U (a)F = 0 hold.

To show that a inv(a,p) E(a , p)F = 0 holds when U (a)F  = U (p)F  = 1, assume there
exists an action a  inv(a, p) such that E(a , p)F  = 1. According to constraint C3, U (a )F  = 1.
However, since F  is derived from an optimal plan for T + , there must exist an optimal plan for T +
that contains both a and a . This contradicts Corollary 2.
Since F  is a feasible solution, there does not exist any action a  A and proposition p  pre(a)
such that U (a)F  = 1 and U (p)F  = 0. Hence F  satisfies constraint C2a for any a  A and
p  pre(a).
4.7 IPe (T + ): The Enhanced IP Model for h+
We define IPe (T + ) as the integer programming model that is the result of first adding the inverse
action constraints described in Section 4.6 to the basic IP(T + ) model and then applying the iterative reduction algorithm in Algorithm 2 (which applies the reductions in Sections 4.1-4.4) until
quiescence. As previously noted, IPe (T + ) computes h+ . As we shall see below, the cumulative
effects of these enhancements is quite significant, resulting in a much more practical IP model for
computing h+ . See Table 1 for a summary of the relationship between IPe (T + ) and IP(T + ).

5. Experimental Evaluation of IP Models for Delete-Free Planning (Exact
Computation of h+ )
In this section, we evaluate the effectiveness of our integer programming model of the delete relaxation as a method for solving delete-free tasks and computing h+ exactly. We evaluate the following
models:
645

fiI MAI & F UKUNAGA

 IP(T + ): our basic IP model (Section 3).
 IP(T + )+LM: IP(T + ) with the landmark-based variable reduction method (Section 4.1).
 IPe (T + ): the enhanced model which includes all of the enhancements described in Sections
4.1-4.6 which are designed to speed up the computation of h+ (landmark-based reduction,
relevance analysis, dominated action elimination, immediate action application, inverse action constraints).
We emphasize that (unlike the other models which will be evaluated in later sections) all of
these IP models compute h+ exactly.
Following previous work on solvers for delete-free problems, our main results are based on
an evaluation using delete-free versions of standard IPC benchmark problems (Section 5.1). In
addition, in Section 5.2, we also present results of a much smaller scale study on a set of natural,
delete-free problems from systems biology (Gefen & Brafman, 2011).
5.1 Evaluation on Delete-Free Versions of IPC Benchmark Instances
Following the methodology for evaluating delete-free planning in previous work (Haslum et al.,
2012; Pommerening & Helmert, 2012; Gefen & Brafman, 2012), we evaluate our IP models by
solving International Planning Contest (IPC) benchmark instances for which the delete effects of
all actions are ignored. Below, all experiments used the CPLEX 12.61 solver to solve integer and
linear programs. All experiments were single-threaded and executed on a Xeon E5-2680, 2.8GHz.
Because previous work on computing h+ has been evaluated using several different sets of
experimental settings (different CPU limits and different problem instances), we present the results
of 4 sets of comparisons. In the first 3 sets of comparisons, we compare benchmark results reported
in previous publications with results obtained by running our solvers on the same problem instances,
while the fourth set of results compares our models with an improved implementation of the minimal
hitting set based approach (Haslum et al., 2012) by one of the the original authors.
 Comparison with the results by Pommerening and Helmert (2012) (experimental setup described in Section 5.1.1, results shown in Table 2).
 Comparison with the results by Gefen and Brafman (2012) (experimental setup described in
Section 5.1.2, results shown in Table 3).
 Comparison with the results by Haslum et al. (2012) (experimental setup described in Section
5.1.2, results shown in Table 4).
 Comparison with HST/CPLEX, an improved implementation of the algorithm in (Haslum
et al., 2012) (experimental setup described in Section 5.1.3, results shown in Table 5 and
Figures 2-3).
The results copied from previous work (Pommerening & Helmert, 2012; Haslum et al., 2012;
Gefen & Brafman, 2012) in Tables 2-4 were obtained using hardware available several years ago
when these original papers were written, while our results for IP(T + ), IPe (T + ), and HST/CPLEX
were obtained with slightly more recent hardware. Since coverage is a coarse metric based on binary results (solved/unsolved), it can be significantly impacted by differences in machine speed,
646

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

e.g., if many problems are at the threshold such that a slightly faster machine (equivalent to running
slightly longer) results in many more instances being solved. In order to eliminate the possibility
that improvements in hardware since 2010 (when the first of the results we compared against were
published) explain the improvements obtained using our approach, we also include results of running our best IP model (IPe (T + )) with a significantly shorter CPU time limit than the previous
experiments, in addition to results that use the same CPU time limit as previous experiments.
5.1.1 C OMPARISON WITH R ESULTS BY P OMMERENING
D ELETE -F REE V ERSIONS OF IPC B ENCHMARKS

AND

H ELMERT (2012)

ON

The first comparison is with the results by Pommerening and Helmert (2012). Table 2 shows the
results of running IP(T + ), IP(T + )+LM, and IPe (T + ) with a 5 minute time limit and 2GB memory
limitation. Coverage (# of problem instances solved) on each domain is shown. The columns where
the solver name contains PH12 in Table 2 are copied from the paper by Pommerening and Helmert
(2012). FD/PH12 is Fast Downward using A* and the LM-cut heuristic applied to the deleterelaxed problems, BC/PH12 is the hitting set based approach by Bonet and Castillo (2011), and
BnB/PH12 and IDA*/PH12 are the best performing strategies using the incremental LM-cut
heuristic for delete-free problems proposed by Pommerening and Helmert (2012). Pommerening
and Helmert obtained their results using a AMD Opteron 2356 processor with a 2GB memory limit
and 5 minute time limit.
Table 2 includes a column IPe (T + )/1min, which shows the results for 1-minute runs of
IPe (T + ). All other columns in Table 4 are for 5 minute runs.
5.1.2 C OMPARISONS WITH R ESULTS BY G EFEN AND B RAFMAN (2012) AND H ASLUM ET AL .
(2012) ON D ELETE -F REE V ERSIONS OF IPC B ENCHMARKS
Next, we evaluated our h+ solvers with previous results that were obtained with a 30-minute time
limit and 2GB memory limit. Table 3 compares IP(T + ), IP(T + )+LM, and IPe (T + ) with some
results from (Gefen & Brafman, 2012, p. 62, Table 2). The LM-cut/GB12 column is A* with the
LM-cut heuristic (Helmert & Domshlak, 2009) applied directly to delete-free instances in order to
compute h+ . The LM-cut+Pruning/GB12 column is A* with LM-cut using the pruning techniques
for delete-free instances proposed by Gefen and Brafman (2012). Table 4 compares IP(T + ) and
IPe (T + ) with some results by Haslum et al. (2012, p. 356, Table 1). The BC/HST12 column is
the method by Bonet and Castillo (2011). The ML/HST12 column is the minimal landmark method
proposed by Haslum et al.. In the original work by Haslum et al. (2012), the minimum-cost hitting
set problem was solved using a specialized branch-and-bound algorithm, and the ML/HST12 column reflects the performance of this original algorithm. However, the Minimal Landmark method
was later significantly improved by replacing the hitting set solver with a CPLEX-based solver
(Haslum, 2014b), so Table 4 also includes the HST/CPLEX column, which shows the results of
Minimal Landmark method using the CPLEX hitting set solver. We obtained these HST/CPLEX
results by running the HST/CPLEX code on the same machine used to run our IP models.
Table 4 includes a column IPe (T + )/5min, which shows the results for 5-minute runs of
IPe (T + ) (all other columns in Table 4 are for 30 minute runs).
Note that in Table 4, the instances from IPC2008 and IPC2011 are from the sequential satisfying track (i.e., -sat08 and -sat11 in the domain names), in accordance with the original paper
(Haslum et al., 2012).
647

fiI MAI & F UKUNAGA

5.1.3 C OMPARISON

WITH

HST/CPLEX

ON

D ELETE -F REE V ERSIONS OF IPC B ENCHMARKS

The most detailed comparison is with an improved implementation of the hitting-set based method
of Haslum et al. (2012). Although the original version of this algorithm used a problem-specific
branch-and-bound method to solve the hitting set problems, we used a more recent version of
Haslums h+ solver (source dated 2014-1-17), configured to use CPLEX 12.61 to solve the hitting set subproblem. This configuration is abbreviated as HST/CPLEX. As shown in Table
4, HST/CPLEX significantly outperforms the original HST implementation described in (Haslum
et al., 2012), and compares favorably vs. other previous methods.
Tables 5-6 and Figures 2-3 compare IP(T + ), IPe (T + ), IP(T + )+LM, and HST/CPLEX on 1376
IPC benchmark instances. All algorithms were run with a 2GB memory limit. Table 5 shows results
with a 30 minute time limit, while Table 6 shows results with a 5 minute time limit. Tables 5 and
6 compares coverage and runtimes per domain, while Figure 2 compares the cumulative number
of instances solved as a function of time, and Figure 3 compares the runtimes of all individual
instances.
In contrast to the previous set of experiments described in Section 5.1.2, we used optimal track
instances (-opt08 and -opt11 in the domain names) when both satisficing and optimal track
instances were available in the benchmark sets. This is because in the subsequent sections, we
focus on applying our models as the basis for heuristics for forward-search, cost-optimal planning.
5.1.4 D ISCUSSION OF R ESULTS ON D ELETE -F REE V ERSIONS OF IPC B ENCHMARKS
Not surprisingly, the basic IP(T + ) model is not competitive with previous state-of-the-art methods that were specifically developed for computing h+ (Haslum et al., 2012; Pommerening &
Helmert, 2012). However, Table 3 shows that the basic IP(T + ) model is at least competitive with
A* with LM-cut enhanced with Gefen and Brafmans pruning methods for delete-free instances
(Prune/GB12). IP(T + ) also significantly outperforms standard A* with LM-cut (Table 3, LMcut/GB12 and Table 2, FD/PH12).
On the other hand, enhancing IP(T + ) with our landmark-based model reduction method results
in significant improvement, and IP(T + )+LM is competitive with all previous methods except for
HST/CPLEX.
The IPe (T + ) model, which includes all of the enhancement described in Section 4 for reducing
the model in order to compute h+ faster, performs very well overall, and is competitive with all
previous methods. For example, in Table 4, IPe (T + ) has the highest coverage (or is tied for highest)
on 19/28 domains. Table 5, Figure 2, and Figure 3 show that while IPe (T + ) and HST/CPLEX
have similar coverage with a 30-minute time limit, IPe (T + ) tends to be somewhat faster overall.
However, there is no clear dominance relationship between IPe (T + ) and HST/CPLEX, since there
are some domains where IPe (T + ) clearly performs better (e.g., rovers, satellite, freecell) , and other
domains where HST/CPLEX performs better (e.g., airport, pegsol, scanalyzer, transport). Thus, the
IP-based approach and minimal landmark approaches seem to have complementary strengths with
respect to solving delete-free problems.
Aside from coverage, Figure 3 shows that many delete-free instances are solved much faster by
IPe (T + ) than HST/CPLEX. The difference between solving an easy delete-free instance in 0.1
vs. 0.5 seconds may not seem very important if we only need to solve the instance once. However,
the speed difference between IPe (T + ) and HST/CPLEX on such easy delete-free instances has a
significant implication when we consider using the h+ solvers as heuristic functions for A* -based
648

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

planners, where we may need to solve delete-free problems many thousands of times in the course
of a single A* search. As a result, we see below in Section 7, A* using IPe (T + ) as a heuristic
significantly outperforms A* using HST/CPLEX as a heuristic.
In order to eliminate the possibility that CPU speed differences account for the qualitative improvements in coverage obtained by our IP models compared to previously published results, Table
2 includes a column IPe (T + )/1min, which is the result for 1-minute runs of IPe (T + ), and Table
4 includes a column IPe (T + )/5min, which is the result for 5-minute runs of IPe (T + ) In effect,
these simulate machines that run at 1/5 and 1/6 (respectively) of the speed of the machine we used
in our experiments in Tables 2 and 4. This more than offsets improvements in single-core CPU
performance between 2010-2015. The coverage achieved by IPe (T + )/1min (753) in Table 2 is
higher than that of all other solvers in Table 2 which were given 5 minutes. Similarly, the coverage
achieved IPe (T + )/5min (847) in Table 4 is higher than that of than all other solvers in Table 4 which
were given 30 minutes.
Therefore, overall, IPe (T + ) is competitive with previous state-of-the-art delete-free solvers, and
our results indicate that direct computation of h+ using integer programming is a viable approach,
at least for computing each delete-free task once.
5.2 Comparison with HST/CPLEX on Minimal Seed Set Problem
To assess the performance of our best IP model, IPe (T + ) on a natural, delete-free task, we also
compared IPe (T + ) with HST/CPLEX on a set of minimal seed set problem instances from systems
biology (Gefen & Brafman, 2011). These consist of 22 instances originally evaluated by Gefen and
Brafman, as well as three additional versions of these 22 instances which were also provided by the
original authors, where each version uses a different set of action costs (Gefen & Brafman, 2011, p.
322), for a total of 22  4 = 88 instances. The solvers were run with a 1 hour CPU time limit per
instance and a 2GB RAM limit.
Figure 4 shows a scatter plot comparing the runtimes on each problem instance. The coverage
of IPe (T + ) was 87 instances, while the coverage of HST/CPLEX was 88 instances. On one hand,
Figure 4 shows that the majority of instances were solved significantly faster by IPe (T + ), and
IPe (T + ) solves 22 instances more than 10 times faster than HST/CPLEX. On the other hand, there
was one instance on which HST/CPLEX was more than 10 times faster than IPe (T + ), and there
was one instance which was solved in 40.7 seconds by HST/CPLEX but was not solved within the
time limit by IPe (T + ) (The dre instance with the type 2 preprocessing by Gefen & Brafman,
2011, p. 322).

6. Relaxations of the h+ Models
Although delete-free planning problems are interesting in their own right, our main motivation for
developing an efficient IP model for delete-free problems is to be able to use it as the basis for a
heuristic function for a forward-state space search based domain-independent planner. So far, we
have presented IP(T + ), a basic IP model which computes h+ , and then proposed IPe (T + ), which
incorporates a number of enhancements which, as shown in the experimental results in Section
5, significantly increase the scalability of the model and provide a new approach to computing h+
which is competitive with the previous state-of-the-art methods. It is possible to simply use IPe (T + )
as the heuristic function for a forward search based planner. However, as shown in Section 5,
computing h+ remains relatively expensive even using IPe (T + ), which is not surprising, given that
649

fiI MAI & F UKUNAGA

(Pommerening & Helmert, 2012, Table 2)
Domain (# problems)
airport(50)
blocks(35)
depot(22)
driverlog(20)
freecell(80)
grid(5)
gripper(20)
logistics00(28)
logistics98(35)
miconic(150)
no-mprime(35)
no-mystery(30)
openstacks-opt08(30)
pathways-noneg(30)
pipes-notankage(50)
pipes-tankage(50)
psr-small(50)
rovers(40)
satellite(36)
tpp(30)
trucks(30)
zenotravel(20)
Total coverage (876)
# Best Domains

IP(T + )

IP(T + )+LM

IPe (T + )

IPe (T + )/1min

FD/PH12

BC/PH12

BnB/PH12

IDA*/PH12

solved
22
35
6
14
11
0
20
24
8
150
15
15
2
30
8
5
50
40
31
11
30
14
541
7

solved
36
35
19
14
17
4
20
28
21
150
20
21
30
30
13
9
50
40
30
24
30
14
655
9

solved
36
35
21
15
80
5
20
28
27
150
31
30
30
30
11
9
50
40
34
30
30
20
762
19

solved
35
35
21
14
80
5
20
28
24
150
30
28
30
30
10
9
50
40
34
30
30
20
753
15

solved
34
35
7
14
6
1
20
23
9
150
27
26
5
5
17
10
50
13
6
13
7
13
491
5

solved
50
35
5
2
1
1
20
26
7
150
14
16
0
4
3
2
50
12
6
12
3
8
427
5

solved
50
35
14
15
2
2
20
28
16
150
27
28
5
5
18
9
50
19
8
23
9
13
546
7

solved
50
35
14
15
3
2
20
28
15
150
26
28
4
5
19
10
50
19
9
24
9
13
548
9

Table 2: Coverage (# of instances solved) for delete-free problems (exact computation of h+ ).
5-minute time limit (except for IPe (T + )/1min which was run with a 1-minute time limit), 2GB
RAM. Comparison with data from Table 2 in the paper by Pommerening and Helmert (2012). #
Best domains is the number of domains for which a each solver achieves the highest coverage
(including ties).
(Gefen & Brafman, 2012, Table 2)
Domain (# problems)
blocks(35)
depot(22)
driverlog(20)
freecell(80)
gripper(20)
logistics00(28)
logistics98(35)
miconic(150)
no-mystery(30)
pipesworld-notankage(50)
pipesworld-tankage(50)
rovers(40)
Total coverage (560)
# Best Domains

IP(T + )

IP(T + )+LM

IPe (T + )

LM-cut/GB12

Prune/GB12

solved
35
8
14
12
20
24
8
150
21
11
7
40
350
4

solved
35
19
14
20
20
28
23
150
23
17
9
40
398
6

solved
35
21
15
80
20
28
28
150
30
17
9
40
473
11

solved
35
7
14
6
20
23
10
150
26
17
10
13
331
5

solved
35
12
15
2
20
28
16
150
26
9
9
23
345
5

Table 3: Coverage (# of instances solved) for delete-free problems (exact computation of h+ ).
30-minute time limit, 2GB RAM. Comparison with data from Table 2 in the paper by Gefen and
Brafman (2012).

650

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

(Haslum et al, 2012,
Table 2)
IP(T + )

Domain (# problems)
airport(50)
barman-sat11(20)
blocks(35)
depot(22)
driverlog(20)
elevators-sat08(30)
floortile-sat11(20)
freecell(80)
gripper(20)
logistics98(35)
logistics00(28)
miconic(150)
no-mprime(35)
nomystery-sat11(20)
parcprinter-08(30)
pegsol-08(30)
pipesworld-notankage(50)
pipesworld-tankage(50)
psr-small(50)
rovers(40)
satellite(36)
scanalyzer-08(30)
sokoban-sat08(30)
transport-sat08(30)
trucks(30)
visitall-sat11(20)
woodworking-sat08(30)
zenotravel(20)
Total coverage (1041)
# Best Domains

solved
22
7
35
8
14
1
19
12
20
8
24
150
20
11
30
25
11
7
50
40
31
10
25
2
30
8
29
15
664
7

IP(T + )+LM

solved
40
8
35
19
14
5
20
20
20
23
28
150
23
13
30
24
17
9
50
40
31
10
29
3
30
7
30
15
743
10

IPe (T + )

solved
39
9
35
21
15
30
20
80
20
28
28
150
34
19
30
26
17
9
50
40
34
10
29
7
30
8
30
20
868
19

HST/CPLEX

solved
50
20
35
20
14
30
12
76
20
20
28
150
31
7
30
30
24
10
50
32
14
21
30
15
30
16
29
14
858
16

IPe (T + )

HST/CPLEX

5min

5min

solved
36
6
35
21
15
30
19
80
20
27
28
150
31
19
30
25
11
9
50
40
34
9
29
6
30
7
30
20
847
16

solved
50
20
35
20
14
30
12
48
20
18
28
150
26
4
30
30
17
10
50
31
11
16
30
12
30
10
29
12
793
12

ML/HST12

BC/HST12

solved
50
18
35
18
13
27
12
17
20
15
27
150
28
5
30
30
20
15
50
18
8
15
30
6
30
2
19
13
721
10

solved
50
5
35
12
8
11
9
0
20
6
27
99
17
4
30
30
9
6
50
19
5
4
30
6
30
0
9
10
541
8

Table 4: Coverage (# of instances solved) for delete-free problems (exact computation of h+ ).
30-minute time limit (except for IPe (T + )/5min and HST/CPLEX/5min which were run with a 5minute time limit), 2GB RAM. Comparison with data from Table 2 in the paper by Haslum et al.
(2012).

651

fiI MAI & F UKUNAGA

IP(T + )/30min

Domain (# problems)
airport(50)
barman-opt11(20)
blocks(35)
depot(22)
driverlog(20)
elevators-opt08(30)
elevators-opt11(20)
floortile-opt11(20)
freecell(80)
grid(5)
gripper(20)
logistics98(35)
logistics00(28)
miconic(150)
no-mprime(35)
no-mystery(30)
nomystery-opt11(20)
openstacks(30)
openstacks-opt08(30)
openstacks-opt11(20)
parcprinter-08(30)
parcprinter-opt11(20)
parking-opt11(20)
pathways-noneg(30)
pegsol-08(30)
pegsol-opt11(20)
pipesworld-notankage(50)
pipesworld-tankage(50)
psr-small(50)
rovers(40)
satellite(36)
scanalyzer-08(30)
scanalyzer-opt11(20)
sokoban-opt08(30)
sokoban-opt11(20)
tpp(30)
transport-opt08(30)
transport-opt11(20)
trucks(30)
visitall-opt11(20)
woodworking-opt08(30)
woodworking-opt11(20)
zenotravel(20)
Total coverage (1376)
# Best Domains

solved

22
8
35
8
14
2
1
20
12
0
20
8
24
150
20
21
13
5
3
0
30
20
2
30
25
13
11
7
50
40
31
10
7
29
20
13
4
0
30
20
30
20
15

time
253.97
1616.97
0.08
151.07
19.05
294.94
525.76
4.67
130.82
0
0.02
194.01
12.21
0.08
202.01
187.66
180.88
114.55
506.63
0
0.08
0.06
529.75
1.50
229.13
360.87
370.96
154.58
0.03
11.77
35.88
306.24
442.44
34.12
39.14
256.03
289.63
0
1.94
3.97
2.04
2.40
35.54
843
14

IP(T + )+LM/30min
solved

40
8
35
19
14
20
13
20
20
4
20
23
28
150
23
23
17
25
30
20
30
20
18
30
24
14
17
9
50
40
31
10
7
29
20
24
4
0
30
20
30
20
15

time
173.58
1522.41
0.00
12.75
15.77
201.74
179.16
1.76
259.96
5.59
0.02
89.77
0.03
0.09
221.48
129.89
224.40
82.48
0.08
0.04
0.04
0.03
172.21
1.13
39.01
105.91
198.51
22.87
0.02
0.34
38.40
292.41
439.54
0.61
0.47
55.71
45.00
0
0.70
1.76
0.52
0.47
36.69
1044
17

IPe (T + )/30min
solved

39
20
35
21
15
30
20
20
80
5
20
28
28
150
34
30
20
30
30
20
30
20
20
30
26
15
17
9
50
40
34
10
7
30
20
30
15
16
30
20
30
20
20

time  sd
134.68  452.99
14.29  40.80
0.00  0.00
0.92  1.90
5.47  18.32
0.38  0.46
0.32  0.42
1.08  3.02
0.32  0.21
6.50  11.29
0.00  0.00
39.07  132.25
0.01  0.02
0.01  0.01
53.06  132.87
12.84  44.49
0.11  0.11
0.39  1.09
0.01  0.01
0.01  0.01
0.02  0.01
0.01  0.01
0.30  0.23
0.05  0.03
40.72  126.79
86.91  183.21
221.80  306.90
18.39  44.42
0.01  0.05
0.13  0.22
0.96  1.64
86.52  173.64
129.49  213.41
56.97  305.42
0.23  0.28
4.58  9.54
151.31  421.56
203.80  424.60
0.03  0.02
1.07  2.93
0.02  0.01
0.02  0.01
3.21  9.13
1214
34

HST/CPLEX/30min
solved

50
20
35
20
14
30
20
15
76
5
20
20
28
150
31
30
8
27
30
20
30
20
20
30
30
20
24
10
50
32
14
21
13
30
20
28
27
20
30
20
30
20
14

time  sd
9.99  36.34
0.04  0.08
0.00  0.00
3.50  8.70
17.30  56.93
0.09  0.07
0.07  0.04
54.56  193.72
320.71  433.35
1.41  1.61
0.01  0.01
146.85  339.48
0.03  0.06
0.04  0.05
106.60  242.37
12.43  29.27
0.36  0.49
81.80  258.73
0.04  0.04
0.03  0.02
0.07  0.12
0.04  0.05
15.97  30.89
2.55  3.08
0.01  0.01
0.01  0.01
223.55  358.14
4.32  11.94
0.01  0.05
34.36  123.88
205.10  384.71
242.91  460.55
338.77  536.07
0.07  0.12
0.07  0.13
142.13  272.08
100.16  146.57
18.30  35.03
1.32  2.10
0.21  0.38
0.15  0.27
0.09  0.07
179.65  453.63
1202
31

Table 5: Detailed comparison of IP(T + ), IP(T + )+LM, IPe (T + ), and HST/CPLEX on 1376 deletefree tasks (exact computation of h+ ). 30-minute time limit, 2GB RAM. Coverage and mean 
standard deviation of runtimes (average of successful runs only, excludes unsuccessful runs).

652

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

IP(T + )/5min

Domain (# problems)
airport(50)
barman-opt11(20)
blocks(35)
depot(22)
driverlog(20)
elevators-opt08(30)
elevators-opt11(20)
floortile-opt11(20)
freecell(80)
grid(5)
gripper(20)
logistics98(35)
logistics00(28)
miconic(150)
no-mprime(35)
no-mystery(30)
nomystery-opt11(20)
openstacks(30)
openstacks-opt08(30)
openstacks-opt11(20)
parcprinter-08(30)
parcprinter-opt11(20)
parking-opt11(20)
pathways-noneg(30)
pegsol-08(30)
pegsol-opt11(20)
pipesworld-notankage(50)
pipesworld-tankage(50)
psr-small(50)
rovers(40)
satellite(36)
scanalyzer-08(30)
scanalyzer-opt11(20)
sokoban-opt08(30)
sokoban-opt11(20)
tpp(30)
transport-opt08(30)
transport-opt11(20)
trucks(30)
visitall-opt11(20)
woodworking-opt08(30)
woodworking-opt11(20)
zenotravel(20)
Total coverage (1376)
# Best Domains

solved

22
0
35
6
14
1
0
20
11
0
20
8
24
150
15
15
11
5
2
0
30
20
0
30
22
9
8
5
50
40
31
7
4
28
19
11
3
0
30
20
30
20
14

time  sd
0.82
0
0.08
29.35
17.33
25.40
0
4.74
73.07
0
0.02
20.45
11.64
0.08
28.01
9.35
37.85
66.39
16.89
0
0.07
0.05
0
1.53
74.55
131.78
5.53
31.71
0.03
10.26
29.87
57.26
34.20
27.27
22.22
12.42
8.64
0
1.60
3.80
1.98
2.17
4.02
790
13

IP(T + )+LM/5min

time
0.33
0
0.00
12.85
17.04
41.09
30.13
1.64
43.14
5.39
0.02
19.56
0.03
0.08
30.02
27.74
42.15
31.37
0.08
0.04
0.03
0.03
69.50
1.14
16.60
36.09
37.58
21.57
0.02
0.33
28.81
48.99
15.28
0.58
0.46
49.31
43.16
0
0.67
1.83
0.49
0.46
1.04

solved

36
0
35
19
14
16
11
20
17
4
20
21
28
150
20
21
14
24
30
20
30
20
15
30
23
12
13
9
50
40
30
7
4
29
20
24
4
0
30
20
30
20
14
994
17

IPe (T + )/5min
solved

36
20
35
21
15
30
20
20
80
5
20
27
28
150
31
30
20
30
30
20
30
20
20
30
25
13
11
9
50
40
34
9
6
29
20
30
13
13
30
20
30
20
20

time  sd
4.10  23.83
13.60  38.23
0.00  0.00
0.93  1.95
5.86  19.83
0.39  0.47
0.31  0.41
1.05  2.93
0.30  0.20
6.35  11.05
0.00  0.00
13.94  36.73
0.01  0.02
0.01  0.01
14.91  51.52
12.04  41.80
0.10  0.10
0.37  1.00
0.01  0.01
0.01  0.01
0.01  0.01
0.01  0.01
0.29  0.22
0.04  0.03
16.24  37.01
16.65  20.17
16.55  52.18
14.65  34.93
0.01  0.04
0.13  0.23
1.03  1.79
41.39  56.98
52.22  66.89
0.25  0.33
0.23  0.28
4.60  9.66
11.60  24.25
28.55  42.33
0.03  0.02
1.11  3.08
0.02  0.01
0.02  0.01
3.38  9.70
1190
33

HST/CPLEX/5min
solved

50
20
35
20
14
30
20
14
48
5
20
18
28
150
26
30
8
24
30
20
30
20
20
30
30
20
17
10
50
31
11
16
9
30
20
24
24
20
30
20
30
20
12

time  sd
9.44  34.94
0.04  0.08
0.00  0.00
3.47  8.57
17.03  56.02
0.08  0.07
0.07  0.04
2.80  4.21
60.87  80.81
1.37  1.54
0.01  0.00
34.28  67.68
0.03  0.06
0.04  0.05
11.27  23.42
12.88  30.69
0.34  0.46
12.20  35.90
0.04  0.04
0.03  0.02
0.07  0.11
0.04  0.05
15.07  28.61
2.47  2.92
0.01  0.01
0.01  0.01
21.71  35.68
4.31  11.93
0.01  0.05
12.55  28.76
16.92  40.99
21.91  45.07
23.20  54.45
0.07  0.12
0.07  0.13
46.47  81.70
56.58  87.08
17.45  32.84
1.74  3.16
0.21  0.38
0.14  0.26
0.08  0.07
20.86  65.51
1134
31

Table 6: Detailed comparison of IP(T + ), IP(T + )+LM, IPe (T + ), and HST/CPLEX on 1376 deletefree tasks (exact computation of h+ ). 5-minute time limit, 2GB RAM. Coverage and mean 
standard deviation of runtimes (average of successful runs only, excludes unsuccessful runs).

653

fiI MAI & F UKUNAGA

1400
1200

Instances solved

1000
800
600
400
IPe(T+)
HST/CPLEX

200
0
0.0001

IP(T+)+LM
IP(T+)

0.001

0.01

0.1

1

10

100

1000

Time (seconds)
Figure 2: Comparison of IP(T + ), IP(T + )+LM, IPe (T + ), and HST/CPLEX on delete-free tasks
(exact computation of h+ ). 30-minute time limit, 2GB RAM. The cumulative number of instances
(out of the same 1376 instances as Table 5) solved within T ime seconds is shown.
computing h+ is NP-equivalent (Bylander, 1994). Haslum (2012) reported some previous, baseline
results using a direct computation of h+ using the hitting-set method proposed in his earlier work
(Haslum et al., 2012) as a heuristic for A* , and reported poor results. Although we show in Section
7 that A* using IPe (T + ) performs well on some domains, using h+ directly as a heuristic for A*
continues to pose a significant challenge. Thus, we turn next to relaxations of IP(T + ) and IPe (T + )
that are lower bounds on h+ and can be computed faster, making them more suitable as admissible
heuristics for a forward-search planner than our IP models.
6.1 LP(T + ) and LPe (T + ): LP Relaxations of the Delete-Relaxation (h+ ) Models
The linear programming (LP) relaxations of the IP models are obvious candidates for tractable
alternatives to computing h+ using IP(T + ) and IPe (T + ). The LP-relaxations are trivially derived
from the IP models by eliminating the integer constraints on the variables, and the optimal cost of
the LP-relaxation is a lower bound on the optimal cost of the IP. We denote the LP relaxation of
IP(T + ) as LP(T + ) and the LP relaxation of IPe (T + ) as LPe (T + ) (see Table 1). In the case of
problem domains with integer action costs, the ceiling of the LP costs are used.
Although LPe (T + ) can be solved quickly, tight theoretical bounds on the gap between IP(T + )
and LP(T + ) or the gap between IPe (T + ) and LPe (T + ) are difficult to obtain  it has been proven
by Betz and Helmert (2009) that there exists no constant c > 0 and no polynomial-time algorithm
for computing a lower bound h such that for all states s, h(s)  ch+ , unless P = N P (i.e.,
h+ is not polynomial-time approximable for any constant factor c). Fortunately, the worst-case
654

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

100*x

10*x

x

x/100

x/10

1

10

100

1000
100

IPe(T+)

10
1
0.1
0.01
0.001
0.001

0.01

0.1

1000

HST/CPLEX

Figure 3: Comparison of runtimes of IPe (T + ) and HST/CPLEX on 1376 delete-free instances (exact computation of h+ , same instances as Table 5). 30-minute time limit, 2GB RAM. Each point represents a problem instance. The x-axis represents the runtime of HST/CPLEX, while the y-axis represents the runtime of
IPe (T + ). For example, a point below the diagonal (y = x) indicates that IPe (T + ) solved the problem represented by that point faster than HST/CPLEX, and a point below the y = x/10 line indicates that IPe (T + )
solved the problem represented by that point at least 10 times faster than HST/CPLEX. If an algorithm failed
to solve an instance within the 30-minute time limit, the runtime is shown as 1800 seconds.

theoretical approximation results do not necessarily apply to real-world problem instances. In fact,
our experimental results below show that the LP-relaxations often provide fast, accurate, lower
bounds on h+ for standard planning benchmark problems.
6.2 Time-Relaxation of h+ Models
If our motivation is to embed a computation for h+ (or an approximation thereof) as an admissible
heuristic for A* , we are not necessarily interested in the actual optimal delete-free plan for T + , but
only the cost of that plan (or its approximation). In particular, if the exact order in which actions are
executed in the delete-relaxed plan does not matter, the necessity of all time-related variables can
be brought into question.
The time-relaxation of IP(T + ), which is IP(T + ) without constraints C5 and C6, is denoted
IPtr (T + ). The LP relaxation of IPtr (T + ) is denoted LPtr (T + ). Table 1 summarizes the relationships among these models.
If the propositions and actions of the task satisfy some conditions, eliminating the time-related
variables does not affect the cost of the optimal solution to IP(T + ). For example, if the relaxed
causal AND/OR graph (Gefen & Brafman, 2012) of the task does not have a cycle, then we can
decide the values of T (p) and T (a) such that constraints C5 and C6 of IP(T + ) are satisfied in655

fiI MAI & F UKUNAGA

1000

IPe(T+)

100
10
1

0.1
0.01
0.001
0.001

x
10*x
x/10
0.01

0.1

1

10

100

1000

HST/CPLEX

Figure 4: Runtime comparisons of IPe (T + ) and HST/CPLEX on minimal seed set problem (88 natural,
delete-free instances from Gefen & Brafman, 2011). 60-minute time limit, 2GB RAM. Each point represents
a problem instance. If an algorithm failed to solve an instance within the 60-minute time limit, the runtime
is shown as 3600 seconds. The coverage of IPe (T + ) was 87 instances, while the coverage of HST/CPLEX
was 88 instances.

dependently of the values of the other variables, in which case the optimal costs of IP(T + ) and
LP(T + ) are the same as the optimal costs of IPtr (T + ) and LPtr (T + ), respectively.
Indeed, we shall show experimentally in Section 6.3 that the relaxation is quite tight, i.e.,
IP(T + ) and IPtr (T + ) often have the same cost, and that IPtr (T + ) can be computed significantly faster than IP(T + ). Similarly, LPtr (T + ), LPetr (T + ), and IPetr (T + ), the time-relaxations
of LP(T + ), LPe (T + ), and IPe (T + ), can be computed much faster than their non-time-relaxed
counterparts.
6.3 Experimental Evaluation of LP and Time Relaxation Gaps
We evaluated the quality of the LP(T + ), LPe (T + ), and LPetr (T + ) linear programming bounds described above by comparing optimal costs computed for these bounds to exact h+ values (computed
using IPe (T + )). We used the same set of 1376 instances as in Table 5. Table 7 shows the mean ratio
of the optimal cost of each LP model to h+ , on all instances where h+ could be computed using
IPe (T + ). The perfect columns indicate the fraction of instances where the optimal cost of the
LP model was equal to h+ . Note that we used the ceiling of the LP cost, since the IPC benchmark
instances have integer costs. A stacked histogram representation of the same data (aggregated over
all domains) which classifies the ratios of the optimal costs of the LP relaxations to the value of h+
is shown in Figure 5.
We should expect that the variable-fixing constraints in our enhanced LPe (T + ) model would
tend to increase the value of the optimal solution to LPe (T + ) compared to the optimal value of the
base LP relaxation, LP(T + ). In addition, we would also expect that the optimal value for LPe (T + )
would tend to be greater than the optimal value of its time relaxation, LPetr (T + ). Table 7 shows that
656

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

in general, LPe (T + )  LPetr (T + )  LP(T + ). For 10/43 domains, LPe (T + ) matches h+ perfectly,
i.e., LPe (T + )/h+ = 1. For 20/43 domains, LPe (T + )/h+  0.95. On almost every single domain,
the optimal LP value of the enhanced model LPe (T + ) is significantly better (higher) than the basic
formulation LP(T + ), confirming that variable elimination and the additional constraints serve to
tighten the LP bound. Thus, the enhancements to the basic model described in Section 4 provide a
significant benefit beyond the speedups that were demonstrated in Section 5. The time-relaxation
LPetr (T + ) is usually very close to LPe (T + ), indicating that the time relaxation can potentially
achieve a good tradeoff between computation cost and accuracy (and in fact, as we see later in
Section 7, LPetr (T + ) performs quite well when used as a heuristic for A* ).
For comparison, we also evaluated the ratio of the value of the LM-cut heuristic (Helmert &
Domshlak, 2009) to h+ . Comparing the average ratios of each lower bound to h+ , we see that:
 LP(T + ) is less informative than LM-cut on 31 domains, more informative than LM-cut on 5
domains, and equivalent on 6 domains.
 LPe (T + ) is less informative than LM-cut on 16 domains, more informative than LM-cut on
19 domains, and equivalent on 8 domains.
 LPetr (T + ) is less informative than LM-cut on 17 domains, more informative than LM-cut on
17 domains, and equivalent on 9 domains.
Thus, while LM-cut is a better approximation to h+ than the basic LP-relaxation, LP(T + ),
and LPetr (T + ) are roughly equivalent to LM-cut. Interestingly, the LP-relaxation approach appears to be highly complementary to the cost-partitioning approach of LM-cut, in that the
LP-relaxation and LM-cut are each more informative than the other on roughly half of the cases
compared to each other.

LPe (T + )

1

1.0
[0.8-1.0)
[0.6-0.8)
[0.4-0.6)
[0.2-0.4)
[0.0-0.2)

0.9

Fraction of Instances

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

LP

LP

e

LP

e
tr

Figure 5: Ratio between optimal LP costs and h+ , categorized into buckets. [x:y) = fraction of
instances where the ratio LP/h+ is in the range [x:y). For example, the fraction of instances where
the ratio between the optimal value of LPetr (T + ) and h+ was in the range [0.8,1,0) is approximately
0.24 (this stacked histogram is based on the same data as Table 6.3).
657

fiI MAI & F UKUNAGA

LM-cut
perfect
1.00
.74
.74
0
.99
.97
.64
0
.89
.20
.77
.06
.80
.10
.94
.05
.29
0
.67
.40
1.00
1.00
.98
.40
.99
.92
1.00
1.00
.76
.20
.79
.28
.93
.50
.61
0
1.00
1.00
1.00
1.00
.99
.70
.99
.65
.87
0
.87
.13
.60
.26
.55
.05
.68
.02
.75
0
1.00
1.00
.87
.12
.95
.23
.95
.32
.97
.26
.94
.53
.96
.60
.98
.55
.87
.03
.84
.05
.92
0
.69
.10
.89
.13
.88
.10
.95
.50

LM-cut/h+

airport
barman-opt11
blocks
depot
driverlog
elevators-opt08
elevators-opt11
floortile-opt11
freecell
grid
gripper
logistics98
logistics00
miconic
no-mprime
no-mystery
nomystery-opt11
openstacks
openstacks-opt08
openstacks-opt11
parcprinter-08
parcprinter-opt11
parking-opt11
pathways-noneg
pegsol-08
pegsol-opt11
pipesworld-notankage
pipesworld-tankage
psr-small
rovers
satellite
scanalyzer-08
scanalyzer-opt11
sokoban-opt08
sokoban-opt11
tpp
transport-opt08
transport-opt11
trucks
visitall-opt11
woodworking-opt08
woodworking-opt11
zenotravel

LP(T + )
perfect
.46
.02
.17
0
.92
.20
.50
0
.85
.10
.21
0
.20
0
.95
.10
.12
0
.31
.20
1.00
1.00
.39
.02
.46
.03
1.00
1.00
.42
0
.39
0
.96
.60
.23
.03
1.00
1.00
1.00
1.00
.99
.66
.99
.70
.88
0
.90
.13
.26
.03
.20
0
.52
0
.58
0
.87
.82
.48
0
.82
.13
.94
.30
.96
.25
.33
.13
.28
.15
.28
.13
.08
0
.09
0
.40
0
.98
.65
.81
0
.80
0
.91
.25

LP(T + )/h+

LPe (T + )
perfect
.98
.94
.38
0
1.00
1.00
.92
.22
.87
.21
.65
0
.64
0
.95
.10
.94
.35
.81
.20
1.00
1.00
.89
.11
.99
.85
1.00
1.00
.71
.33
.77
.33
1.00
.95
1.00
.96
1.00
1.00
1.00
1.00
.99
.66
.99
.70
.92
.10
.98
.60
.64
.03
.65
0
.83
.38
.93
.55
1.00
1.00
.65
.35
.82
.21
.94
.75
.96
.71
.95
.73
.97
.80
.85
.26
.35
.08
.41
0
1.00
1.00
.98
.65
1.00
1.00
1.00
1.00
.92
.31

LPe (T + )/h+

LPetr (T + )
+
LPe
(T
)/h+
perfect
tr
.98
.38
1.00
.91
.83
.64
.62
.95
.92
.79
1.00
.88
.99
1.00
.63
.72
1.00
.88
1.00
1.00
.99
.99
.87
.98
.64
.65
.79
.91
1.00
.65
.82
.94
.96
.94
.97
.85
.35
.41
1.00
.97
1.00
1.00
.89

.70
0
1.00
.18
.05
0
0
.10
.23
.20
1.00
.05
.78
1.00
.17
.30
.95
1.00
1.00
1.00
.66
.70
0
.60
.03
0
.08
.36
1.00
.30
.20
.34
.29
.66
.75
.26
.03
0
1.00
.65
1.00
1.00
.30

Table 7: Gaps between LP models and h+ : The mean ratio of each LP model to h+ (on the 1228
instances solved using IPe (T + ) is shown. The perfect columns indicate the fraction of instances
where the optimal cost of the LP model was equal to h+ .

658

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

Figure 6 compares the runtimes the CPLEX LP solver on the relaxed h+ models. LPe (T + ) is
significantly faster than LP(T + ), solving many instances 2-10 times faster (and solving some instances more than 10 times faster), demonstrating the benefits of our enhanced model. The comparison of LPetr (T + ) and LPe (T + ) shows that using the time relaxation results in an addition speedup
of up to a factor of 2. While this additional speedup may not seem very significant when solving a
single LP instance that takes a fraction of a second, the cumulative effects when using the LP models as a heuristic for forward-search based planning is significant, and as we show in Section 7, this
results in increased coverage when using LPetr (T + ) as a heuristic for A* , compared to LPe (T + ).

100

100

10

10

LPetr(T+)

1000

LPe(T+)

1000

1

0.1

0.1

x
10*x
2*x
x/2
x/10

0.01
0.001
0.001

1

0.01

0.1

1

LP(T+)

10

100

x
10*x
2*x
x/2
x/10

0.01

1000

0.001
0.001

0.01

0.1

1

LPe(T+)

10

100

1000

Figure 6: Runtime comparisons for relaxed h+ models. on 1376 delete-free instances (exact computation of
h+ , same instances as Table 5). 30-minute time limit, 2GB RAM. Each point represents a problem instance.
The left subfigure compare LP(T + ) vs LPe (T + ), showing the impact of our enhancements to the basic LP
model, and the right subfigure compares LPe (T + ) vs LPetr (T + ), showing the impact of the time relaxation.
If an algorithm failed to solve an instance within the 30-minute time limit, the runtime is shown as 1800
seconds.

7. Cost-Optimal Planners Using Our h+ -Based Heuristics
We embedded the IP and LP models that have been introduced so far into an A* -based, cost-optimal
forward search planner (our own planner implementation, which uses a propositional representation
internally) and evaluated their performance. Note that this particular experiment is limited to admissible heuristics whose value is bounded above by h+ . The later results in Section 8 and 9 include
heuristics that are not necessarily bounded above by h+ . Specifically, we evaluated the following
solver configurations:
 A* /IP(T + ) : A* with the basic delete-free IP model IP(T + ) as a heuristic.
 A* /IPe (T + ) : A* with the enhanced delete-free IP model IPe (T + ) as a heuristic.
 A* /LPe (T + ) : A* with the LP relaxation of the enhanced delete-free IP model IPe (T + ) as a
heuristic.
 A* /LPetr (T + ) : A* with the LP relaxation of the time-relaxed, enhanced delete-free IP model
IPe (T + ) as a heuristic.
659

fiI MAI & F UKUNAGA

 hsp/HST/CPLEX : A* where the heuristic is the hitting-set based h+ solver HST/CPLEX
(Haslum et al., 2012) using CPLEX to solve hitting set instances (hsp planner provided by
Patrik Haslum).
 FD/hmax : Fast Downward using the hmax heuristic (Bonet & Geffner, 2001).
 FD/LM-cut : Fast Downward using the landmark cut heuristic (Helmert & Domshlak, 2009)
(the standard seq-opt-lmcut configuration)
As per standard IPC sequential optimal track settings, all solver configurations were run with a
30 minute time limit per problem and a 2GB RAM limit. A set of 1376 instances from IPC1998IPC-2011 were used. Our planner currently handles the STRIPS subset of PDDL with action costs.
Table 8 compares the coverage of these heuristics. Figure 7a shows the cumulative coverage
(out of 1376) solved as a function of time for the solver configurations compared in Table 8, and
Figure 7b shows cumulative coverage as a function of the number of node evaluations (calls to the
heuristic function by A* ).
While we compare our IP/LP-based A* -heuristics with other planners, note that there are significant implementation-level differences other than the heuristic function that can affect execution
speed. For example, Fast Downward uses a multi-valued SAS+ representation (Backstrom & Nebel,
1995) internally to represent states, while our planner uses a STRIPS propositional representation,
so there are significant differences in internal data structures and implementation details. Thus,
these results should only be used for qualitative comparisons.
Table 8 shows that A* /IP(T + ), which uses the basic IP(T + ) model, had the worst coverage
among our IP models (403), comparable to that of A* /HST/CPLEX(398). As noted by Haslum
(2012), straightforward use of h+ as a heuristic can be unsuccessful (even worse than FD using
hmax , which has a coverage of 540) if the cost of computing h+ at each search node is too high.
However, as shown in Section 5, solving the IPe (T + ) IP model is significantly faster than
IP(T + ) and A* /HST/CPLEX. This makes it much more viable as a heuristic function for A* , and
as a result, A* /IPe (T + ) has a coverage of 635, significantly outperforming both A* /HST/CPLEX as
well as FD/hmax.
As shown in Section 6.3, the LP relaxations of our IP models provide relatively tight lower
bounds for h+ . Since the LP models can be solved much faster than IP, they are quite effective
when used as heuristics for A* . Thus, A* /LPe (T + ), which uses the LP-relaxation of the enhanced
IPe (T + ) model, has a coverage of 696, and A* /LPetr (T + ), which uses the LP-relaxation of the
time-relaxed, enhanced IP model, has a coverage of 705.
In Section 6.3, we showed that the LPe (T + ) and LPetr (T + ) models are complementary to LMcut with respect to informativeness, which suggests that at least with respect to search efficiency,
our LP models should be competitive with LM-cut. Figure 7b shows that in fact, A* /LPe (T + ) and
A* /LPetr (T + ) tend to search quite efficiently, and it can be seen that both of these lines are above
the LM-cut line (i.e., more problems were solved using a given number of evaluations) until between 105  106 node evaluations, at which point they are overtaken by the LM-cut line. While
the informativeness comparison in Section 6.3 showed that the LP models are comparable and complementary to LM-cut with respect to informativeness, FD/LM-cut outperforms A* /LPetr (T + ) and
A* /LPetr (T + ) on most domains. This is because the LM-cut implementation in Fast Downward
is often significantly faster than the current implementation of our LP-based heuristics. Nevertheless, there are several domains (freecell, parcprinter-08, parcprinter-opt11, satellite, trucks, visitall),
660

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

Domain (# problems)
airport(50)
barman-opt11(20)
blocks(35)
depot(22)
driverlog(20)
elevators-opt08(30)
elevators-opt11(20)
floortile-opt11(20)
freecell(80)
grid(5)
gripper(20)
logistics98(35)
logistics00(28)
miconic(150)
no-mprime(35)
no-mystery(30)
nomystery-opt11(20)
openstacks(30)
openstacks-opt08(30)
openstacks-opt11(20)
parcprinter-08(30)
parcprinter-opt11(20)
parking-opt11(20)
pathways-noneg(30)
pegsol-08(30)
pegsol-opt11(20)
pipesworld-notankage(50)
pipesworld-tankage(50)
psr-small(50)
rovers(40)
satellite(36)
scanalyzer-08(30)
scanalyzer-opt11(20)
sokoban-opt08(30)
sokoban-opt11(20)
tpp(30)
transport-opt08(30)
transport-opt11(20)
trucks(30)
visitall-opt11(20)
woodworking-opt08(30)
woodworking-opt11(20)
zenotravel(20)
Total coverage (1376)
# Best domains

FD/hmax

FD/LM-cut

hsp/HST/CPLEX

A* /IP(T + )

A* /IPe (T + )

A* /LPe (T + )

solved
21
4
18
4
9
15
13
4
15
2
7
2
10
50
23
17
8
7
19
14
14
10
0
4
27
17
16
7
49
6
6
9
6
27
20
6
11
6
7
9
9
4
8
540
15

solved
28
4
28
7
14
22
18
7
15
2
7
6
20
141
23
16
14
7
19
14
19
14
3
5
27
17
17
8
49
7
7
15
12
30
20
6
11
6
10
11
17
12
13
748
36

solved
24
0
17
1
7
3
1
1
19
1
2
3
10
79
15
15
8
5
7
2
19
14
0
4
17
4
9
6
19
4
5
5
2
6
3
5
7
2
3
15
14
8
7
398
0

solved
14
0
19
2
9
0
0
2
8
0
4
3
16
137
10
5
8
0
2
0
19
14
0
5
1
0
3
2
43
7
8
5
2
3
1
5
2
0
7
9
12
7
9
403
0

solved
24
0
27
7
10
9
7
4
54
2
5
5
19
140
20
15
14
7
10
5
21
16
2
5
10
2
10
8
48
7
10
5
2
17
13
6
7
2
13
10
17
11
9
635
13

solved
25
0
28
7
11
13
10
6
44
2
6
6
20
140
18
13
14
7
11
6
20
16
1
5
26
16
12
7
48
7
10
8
5
23
19
6
9
4
15
16
16
10
10
696
14

+
A* /LPe
tr (T )

solved
25
0
28
7
13
13
10
7
43
2
6
6
20
141
17
12
14
7
11
6
20
16
1
5
26
16
13
7
48
7
10
8
5
25
19
6
10
5
15
16
17
11
11
705
17

Table 8: Comparison of forward search (A* ) planners, part 1: Number of problems solved with 30
minute, 2GB RAM limit using A* and our IP/LP models which are bounded above by h+ (Sections
3-7) as heuristic functions. Comparison with Fast Downward with hmax , Fast Downward with
Landmark Cut, and the hsp planner using HST/CPLEX (Haslum et al., 2012) to compute h+ , as the
heuristic function.

where A* /LPetr (T + ) achieves higher coverage than FD/LM-cut. Thus, A* /LPetr (T + ), our best
model among those which are bounded above by h+ , can be considered a fairly powerful, admissible heuristic function for forward-state search based planning.
661

fiI MAI & F UKUNAGA

800
700

Instances solved

600
500
400
300
FD/LMcut
A*/LPetr(T+)
A*/LPe(T+)
A*/IPe(T+)
FD/hmax

200
100
0
0.1

1

10

100

1000

Time (seconds)
(a) Cumulative number of problems solved (out of 1376) vs time (30 minute time limit).

800
700

Instances solved

600
500
400
300
FD/LMcut
A*/LPetr(T+)
A*/LPe(T+)
A*/IPe(T+)
FD/hmax

200
100
0

1

10

100

1000

10000 100000 1e+06

1e+07

1e+08

Evaluations
(b) Cumulative number of problems solved (out of 1376) vs number of search nodes evaluated (30 minute
time limit).

Figure 7: Comparison of forward search (A* ) planners, part 1 ( heuristics that are bounded above
by h+ ).

662

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

8. Incorporating Counting Constraints
So far, we have concentrated on efficient computation of h+ as well as relaxations of h+ , and all of
our models so far have been bounded above by h+ . However, our IP model can be extended with
constraints that consider delete effects. By adding variables and constraints related to delete effects
of actions, our model can also calculate lower bounds on the number of times each action must be
applied. New variables are defined as follows:
 a  A, N (a)  {0, 1,    } : N (a) = n iff a is used n times.
 p  P, G(p)  {0, 1} : G(p) = 1 iff p  G.
G(p) is an auxiliary variable similar to I(p). Furthermore, in this extended model, the meaning
of U (a)  {0, 1} is slightly modified to mean that action a is used at least once in the optimal
solution (in the basic model proposed in Section 3, which was a pure delete-free model, U (a)
denoted whether a was used exactly once or not at all in the optimal solution).
New constraints are defined as follows:
(C7) a  A, N (a)  U (a).
P
P
(C8) p  P, G(p) + as.t.ppredel(a) N (a)  I(p) + as.t.padd(a) N (a),
where
predel(a) = pre(a)  del(a). Finally, the objective function is modified so as to minimize
P
aA c(a)N (a). Given a planning task T , we use IPc (T ) to denote an IP problem which adds the
and above new variables and constraints to IP(T + )
The idea for these types of constraints have been previously proposed several times (for a SAS+
formulation), and correspond to the action order relaxation by van den Briel et al. (2007), the state
equation heuristic by Bonet (2013), and the net change constraints by Pommerening et al. (2014).
Intuitively, the final constraint states that the number of uses of actions adding p must be greater
than or equal to the number of uses of actions requiring and deleting p at the same time in a feasible
plan for T . Any feasible plan for a STRIPS planning task always satisfies this condition. Hence,
for any task T and any feasible plan  for T , we can clearly derive a feasible solution to IPc (T )
with the same cost as . In addition to this, a stronger proposition can be proved for modifications
of models by the enhancements in Section 4.
Proposition 7. Given a task T , for any feasible plan  = (a0 ,    , an ) of T , there exists a feasible
solution to IPc (T ) that has the same cost as the cost of . In addition to this, there exists a feasible solution to IPc (T ) with any combination of landmark extraction and substitution, relevance
analysis, and inverse action constraints that has the same cost as the cost of .
Proof. Let  + be the delete relaxation of the subsequence of the plan  extracted by Algorithm 3.
First we show that the subsequence  + is a feasible delete-free plan for T + , and then we show that
the assignment derived from  + satisfies the constraints.
+
+
+
+
We use (a+
0 ,    , am ) to denote the elements of  . To show that  is feasible in T , assume
+
+
a+
i is the first infeasible action in  . Let p be a proposition such that p  pre(ai ) and p 6
+
+
I((a0 ,    , ai1 )). Since  is a valid feasible plan for T , the delete-relaxation of the entire sequence
of  is a valid feasible plan for T + . Hence, if a+
i is not feasible, then this is because Algorithm 3
+
skipped all the actions that add p before ai is applied. Since S on line 5 in Algorithm 3 is equal to
+
I((a+
0 ,    , ai1 )) for each i, all the skipped actions that add p satisfy add(ai ) \ S 6= , and thus
663

fiI MAI & F UKUNAGA

Algorithm 3 Extracting a subsequence of  = (a0 ,    , an ) (for the proof of Proposition 7)
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:

 +  (); // empty
S  I;
for a = a0 ,    , an do
Let a be the delete-relaxation of a.
if a is relevant to T + and add(a ) \ S 6=  then
append a at the end of  + ;
S  S  add(a );
end if
end for
return  + ;

they are irrelevant to T + . However this contradicts the definition of the relevance analysis and the
+
+
fact that a+
i is relevant. Similar to this argument, we have G  I( ). Hence  is a valid feasible
plan for T + .
Define an assignment F for IPc (T ) as:
 VF := VF + for each variable V that is defined for IP(T + ), where F + is the assignment
derived from  + for IP(T + ), and
 N (a)F := (the number of occurrences of a in ) for each a  A.
The assignment F clearly satisfies constraints C1 through C6. The assignment F also satisfies
constraint C8 since  is a valid plan for T , and F satisfies constraint C7 since U (a)F = 0 if a is not
included in . Hence F is a feasible solution to IPc (T ) which has the same cost as .
In addition, F is also a feasible solution to IPc (T ) with any combination of landmark extraction
and substitution, relevance analysis, and inverse action constraints. We can see this by checking
the feasibility of F with each type of modified constraints independently. If F satisfies each of the
modified constraints, then it satisfies any combination of such constraints.
F satisfies the constraints added by the landmark extraction and substitution (i.e. substituting 1 for variables corresponding to landmarks) since  + is a valid feasible plan for T + . F also
satisfies constraints added by the relevance analysis (i.e. substituting 0 for irrelevant actions and
propositions) since  + contains only relevant actions. Finally, we can show
P that F satisfies inverse
action constraints similarly to the proof of Proposition 6. We have a inv(a,p) E(a , p)F = 0
P
when U (a)F = 0 and U (p)F = 0 hold, and we also have a inv(a,p) E(a , p)F  1 when
P
U (a)F = 0 and U (p)F = 1 hold. In addition, we can show that a inv(a,p) E(a , p)F = 0 for
each U (a)F = U (p)F = 1. Assume that there exists a  inv(a, p) such that E(a , p)F = 1. Then,
by constraint C3, U (a )F = 1, and this means a is also a member of  + . Without loss of generality,
assume a is applied before a is applied in  + . Since add(a )  pre(a) by the definition of inverse
actions, nothing new is added to the state after applying a . S on line 5 in Algorithm 3 is equal to

I((a+
0 ,    , a )), and this contradicts add(ai ) \ S 6= .
Unfortunately, the counting constraints conflict with dominated action elimination (Section 4.3)
and zero cost immediate action application (Section 4.4). When counting constraints are used,
it is necessary to disable zero cost immediate action application and to modify the condition of
dominated actions as follows:
664

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

Definition 2 (modified dominated action definition). Given a feasible task T , an action a is dominated by action a if (i) add(a)  add(a ), (ii) for any p  pre(a ), p is a fact landmark of a or
p  I, (iii) c(a)  c(a ), and (iv) pre(a )  del(a )  pre(a)  del(a).
We can no longer use the modified dominated actions to make a feasible plan for T , since fact
landmarks are sometimes deleted after they are achieved. However the following fact can be proved.
Proposition 8. Given a task T , let  = (a0 ,    , an ) be a feasible solution to T . There exists a
feasible solution to IPc (T ) with any combination of landmark extraction and substitution, relevance
analysis, inverse action constraints, and the modified dominated action elimination that has cost
equal to or less than the cost of .
Proof. Recall that the dominated action elimination constraints substitute 0s for U (a) for each dominated action a. If  does not contain any modified dominated actions, then the proposition holds
due to Proposition 7.
Otherwise, we can derive a feasible solution using the sequence of actions made by replacing
modified dominated actions in  with their corresponding dominating actions. Let   be such a
sequence. Note that the sum of the costs of the actions in   is clearly less than or equal to that of .
Let  + be the relaxation of the subsequence of   extracted by Algorithm 3. Since we can
prove that the delete-relaxation of   is a feasible plan for T + by an argument similar to the proof
of Proposition 4, we can prove that  + is also a feasible plan for T + by an argument similar to the
proof of Proposition 7.
If  + is a feasible plan, then we can derive a feasible solution for IPc (T ) with the constraints
from   as in the proof of Proposition 7. The solution satisfies constraints C1 through C6 with
any combination of landmark extraction and substitution, relevance analysis, and inverse action
constraints. It satisfies constraint C7 because U (a) = 0 if a is not included in   , and it satisfies
constraint C8 because replacing dominated actions does not invalidate constraint C8 if  is a feasible
plan for T . It also satisfies dominated action elimination constraints (i.e. U (a) = 0 for each
dominated action a) since   does not contain any modified dominated action.




IPec (T ) and LPec (T ) denote the models constructed by applying all of the valid reductions to
IPc (T ) and LPc (T ) respectively. The LP and time relaxations for IP(T + ) described in Section 6

can be applied to IPc (T ) as well, and LPectr (T ) is the time-relaxed, LP-relaxation of the enhanced

IPec (T ) model. Table 1 summarizes the relationships among these models.
8.1 Experimental Results for Models Enhanced with Counting Constraints


To see the impact of adding counting constraints, we evaluated the informativeness of LPec (T ),

LPectr (T ), LPe (T + ), and LPetr (T + ) by comparing their values with the LM-cut heuristic values


(Helmert & Domshlak, 2009). Table 9 shows the values of LPec (T ), LPectr (T ), LPe (T + ), and
LPetr (T + ) as a multiple of the LM-cut values (means for each domain are shown). Note that in
contrast to Table 7, which was limited to the 1228 instances for which h+ could be computed
exactly, Table 9 includes all 1376 instances (because the LM-cut values could be computed for all
1376 instances).
On the majority of domains, the counting constraints result in a more informative heuristic,

compared to the models without the counting constraints, so in most cases, LPe (T + )  LPec (T )

and LPetr (T + )  LPectr (T ). It is sometimes possible for the optimal value of LPe (T + ) to be larger
665

fiI MAI & F UKUNAGA





than the optimal value of LPec (T ) and for LPetr (T + ) to have a larger optimal value than LPectr (T )
because as explained in Section 8, some of the additional constraints that are part of IPe (T + ) are

incompatible with IPc (T ) and are excluded from IPec (T ), resulting in different LP polytopes for
their LP-relaxations.
Next, to see the impact of adding counting constraints on forward-search planning using these


delete-relaxation LP models, we compare A* /LPec (T ) with A* /LPe (T + ), and A* /LPectr (T ) with
A* /LPetr (T + ). Coverage on the same instances as our previous experiment are shown in Table 10.
There is a tradeoff between the improved search efficiency due to the additional informativeness in
the heuristic provided by the counting constraints, and the additional time required to solve the LPs
(because the additional constraints make the LP more difficult to solve). Table 10 shows that the

overall effects of enhancing our delete-relaxation model are mixed. A* /LPec (T ) attains a coverage

of 672 instances, which is lower than the coverage for A* /LPe (T + ), while A* /LPectr (T ) solves 716
problems compared to the 705 problems solved by A* /LPetr (T + ). There are some domains where
adding the counting constraints significantly improved coverage, including parcprinter, pathwaysnoneg, rovers, woodworking. On the other hand, coverage dropped significantly in elevators, freecell, openstacks as a result of adding the counting constraints. The time relaxation seems to be
advantageous overall, resulting in an increase from 672 instances for A* /LPe (T + ) to 716 problems
for A* /LPetr (T + ).
Table 9 also shows the value for the LMC-SEQ LP value (Pommerening et al., 2014). This combination of the landmark constraints and net change constraints in their operator-counting framework is analogous to the combination of our delete-free model with counting constraints, so it is


interesting to compare their optimal LP values. LPec (T ) and LPectr (T ) have a higher average value
than LMC-SEQ on 16 and 15 domains, respectively, while LMC-SEQ has a higher value than both


LPec (T ) and LPectr (T ) on 17 domains. Thus, as with our previous comparison of LM-cut with
LPe (T + ) and LPetr (T + ) in Section 6.2, our delete-relaxation approach seems to be complementary
to the LMC-SEQ combination in the operator-counting framework. On the other hand, comparing
the results of forward search based optimal planning using these LP models, we see that FD/LMC


SEQ has significantly higher coverage than A* /LPec (T ) and A* /LPectr (T ), as well as A* /LPec (T )

and A* /LPectr (T ).

9. Automatic LP Model Selection
From the definitions of the models, we know that for any STRIPS planning task T with action
costs, the relationships among the IP models are as follows: IPtr (T + )  IPetr (T + )  IP(T + ) =

IPe (T + ) = h+  IPc (T ) = IPec (T ). As for the LP relaxations, we know that LP(T + ) 




LPe (T + ), LPetr (T + )  LPe (T + ), LPectr (T )  LPec (T ), and LPectr (T )  LPec (T ). Note that

LPec (T ) does not always dominate LPe (T + ), because the dominated action elimination and immediate action application eliminate different sets of variables in these two LP models. Figure 1
illustrates the dominance relationships among the bounds.

While the time-relaxed LPetr (T + ) and LPectr (T ) are dominated by the non-time-relaxed models

LPe (T + ) and LPec (T ), respectively, the time-relaxed LPs are significantly cheaper to compute than
their non-relaxed counterparts.

Similarly, although IPec (T ) dominates IPe (T + ), it is possible for LPe (T + ) to be larger than

LPec (T ). Furthermore, if two LPs have the same optimal value, the one that can be solved faster is
clearly preferable because the LPs must be solved at each node in the A* search. Thus, we have a set
666

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

airport
barman-opt11
blocks
depot
driverlog
elevators-opt08
elevators-opt11
floortile-opt11
freecell
grid
gripper
logistics98
logistics00
miconic
no-mprime
no-mystery
nomystery-opt11
openstacks
openstacks-opt08
openstacks-opt11
parcprinter-08
parcprinter-opt11
parking-opt11
pathways-noneg
pegsol-08
pegsol-opt11
pipesworld-notankage
pipesworld-tankage
psr-small
rovers
satellite
scanalyzer-08
scanalyzer-opt11
sokoban-opt08
sokoban-opt11
tpp
transport-opt08
transport-opt11
trucks
visitall-opt11
woodworking-opt08
woodworking-opt11
zenotravel

LMC-SEQ

LPe (T + )

1.00
2.23
1.07
1.10
1.04
1.02
1.01
1.05
2.64
1.09
1.00
1.00
1.00
1.00
1.00
1.01
1.03
1.36
1.00
1.00
1.08
1.05
1.00
1.53
1.34
1.33
1.45
1.32
2.60
1.23
1.00
1.00
1.01
1.15
1.11
1.43
1.11
1.08
1.00
1.50
1.04
1.05
1.00

.85
.51
1.00
1.43
1.01
.84
.80
1.01
3.14
1.20
1.00
.91
.99
1.00
.89
.98
1.07
1.61
1.00
1.00
1.00
1.00
1.04
1.13
1.09
1.10
1.18
1.27
1.00
.72
.83
.98
.98
1.01
1.01
.89
.49
.49
1.08
1.42
1.12
1.13
.96

+
LPe
tr (T )

.85
.51
1.00
1.42
.99
.82
.77
1.01
3.07
1.19
1.00
.90
.99
1.00
.78
.90
1.07
1.43
1.00
1.00
1.00
1.00
.99
1.13
1.05
1.10
1.16
1.26
1.00
.72
.75
.94
.98
1.00
1.01
.89
.49
.49
1.08
1.41
1.12
1.13
.94





LPe
c (T )

LPe
ctr (T )

.98
3.59
1.07
1.54
1.12
.71
.67
1.08
3.08
1.55
1.00
1.01
1.00
1.00
.82
.84
1.10
1.61
1.00
1.00
1.08
1.05
1.06
1.72
1.25
1.22
1.73
1.35
2.61
.81
.85
.97
.97
1.13
1.12
1.42
.18
.18
1.08
1.48
1.18
1.19
.94

.98
3.59
1.07
1.54
1.12
.71
.67
1.08
3.07
1.55
1.00
1.01
1.00
1.00
.82
.81
1.10
1.43
1.00
1.00
1.08
1.05
1.00
1.72
1.23
1.22
1.70
1.20
2.61
.81
.75
.93
.97
1.13
1.12
1.42
.18
.18
1.08
1.47
1.18
1.19
.93

Table 9: Optimal values of LP models relative to LM-cut value for 1376 IPC instances. Means for
each domain are shown. E.g., for barman-opt11, the mean LMC-SEQ value was 2.23 times the LM
cut value, the LPe (T + ) and LPetr (T + ) values were 0.51 times the LM-cut value, and the LPec (T )

and LPectr (T ) values were 3.59 times the LM-cut value.

667

fiI MAI & F UKUNAGA

800
700

Instances solved

600
500
400
300

FD/LMC-SEQ
A*/Autoconf
FD/LMC
A*/LPe
ctr(T)
A*/LPetr(T+)
FD/SEQ

200
100
0
0.1

1

10

100

1000

Time (seconds)
(a) Cumulative number of problems solved (out of 1376) vs time (30 minute time limit).

800
700

Instances solved

600
500
400
300

FD/LMC-SEQ
A*/Autoconf

200

FD/LMC
A*/LPe
ctr(T)

100

A*/LPetr(T+)
FD/SEQ

0

1

10

100

1000

10000 100000 1e+06

1e+07

1e+08

Evaluations
(b) Cumulative number of problems solved (out of 1376) vs number of search nodes evaluated (30 minute
time limit).

Figure 8: Comparison of forward search (A* ) planners, part 2.

668

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

of 4 viable LP heuristics, none of which dominate the others when considering both accuracy and
time. The best choice to optimize this tradeoff between heuristic accuracy and node expansion
rate depends on the problem instance. It is difficult to choose the best heuristic a priori because in
general, we do not know (1) whether it is worthwhile to use the counting constraints or not, and (2)
whether the time-relaxation is tight or not for a particular problem instance.
Thus, we implemented a simple mechanism for automatically selecting the LP to be used for

each problem which works as follows: First, we compute LPe (T + ), LPec (T ), LPetr (T + ), and

LPectr (T ) for the problem instance (i.e., at the root node of the A* search). We then select one
based on the following rule: Choose the heuristic with the highest value, and break ties by choosing the heuristic that is cheapest to compute. Although the cheapest heuristic could be identified
according to the CPU time required to compute each heuristic, for many problems, the computations are too fast for robust timing measurements, so we simply break ties in order of LPetr (T + ),


LPectr (T ), LPe (T + ), LPec (T ), because this ordering usually accurately reflects the timing order.
This mechanism makes the simplistic assumption that ranking and behavior of the LP bounds at the
root node will be similar to the ranking of the LP bounds throughout the search graph. A more sophisticated method for heuristic selection may result in better performance (c.f. Domshlak, Karpas,
& Markovitch, 2012), and is an avenue for future work.
9.1 Experimental Results for Automated Model Selection and Comparison with the
State-of-the-Art
We compared A* using our LP-based heuristics, including A* /autoconf, with state-of-the-art heuristics. Specifically, we compared:
 FD/LM-cut : Fast Downward using the landmark cut heuristic (Helmert & Domshlak, 2009)
(the standard seq-opt-lmcut configuration)
 FD/LMC : Fast Downward using an LP-model for the optimal cost partitioning for landmark
cut constraints (Pommerening et al., 2014)
 FD/SEQ : Fast Downward using the lower-bound net change constraints (Pommerening et al.,
2014), corresponding to the state-equation heuristic by Bonet (2013).
 FD/OPT-SYS1, FD/PHO-SYS1, FD/PHO-SYS2 : Fast Downward using optimal cost partitioning constraints for projections on goal variables (OPT-SYS1), and post-hoc optimization
constraints (PHO-SYS1, PHO-SYS2) (Pommerening et al., 2014).
 FD/LMC-SEQ : Fast Downward using both the landmark cut and net change constraints.
 A* /LPe (T + ) : A* with the LP relaxation of the enhanced delete-free IP model IPe (T + )
(Section 4) as a heuristic.
 A* /LPetr (T + ) : A* with the LP relaxation of the time-relaxed, enhanced delete-free IP model
IPe (T + ) as a heuristic.


 A* /LPec (T ) : A* with the LP relaxation of the enhanced delete-free IP model with counting

constraints IPec (T ) as a heuristic.


 A* /LPectr (T ) : A* with the LP relaxation of the time-relaxed, enhanced delete-free IP model

with counting constraints IPec (T ) as a heuristic.
669

fiI MAI & F UKUNAGA

9.1.1 C OVERAGE R ESULTS
The coverage results (number of problems solved) are shown in Tables 10. The time spent at the
root node by A* /autoconf for LP model selection is included in the runtimes, and also counts against
the 30-minute runtime limit. Figures 8a-8b show the cumulative number of instances solved as a
function of the number time and number of node evaluations, respectively (for legibility, only a
subset of the algorithms are included in Figures 8a-8b). Table 11 shows a summary of total coverage
results for all forward-search configurations that are included in Tables 8 and 10.
Our results indicate that automatic LP model selection significantly boosts the performance of
an A* -based planner compared to relying on a single LP model. A* /autoconf achieved a coverage of 761 out of 1376 instances, which is significantly better than its 4 individual components.
Furthermore, A* /autoconf attained higher coverage than all other solver configurations in Table
10 except for FD/LMC-SEQ (Pommerening et al., 2014), which solved 781 instances. Note that
A* /autoconf has higher coverage than FD/LMC-SEQ on 11/43 domains (floortile-opt11, freecell,
grid, logistics98, nomystery-opt11, pathways-noneg, rovers, satellite, trucks, woodworking-opt08,
woodworking-opt11).
9.1.2 ACCURACY OF A* / AUTOCONF M ODEL S ELECTION
We analyzed the accuracy of the model selection by evaluating the performance of A* /autoconf on
each problem instance vs the performance of each of its four component models. If only coverage
is considered, then in 96.4% of the instances, A* /autoconf made the correct decision with respect to
coverage, where the model selection by A* /autoconf was deemed to be correct if either A* /autoconf
solved the problem instance, or none of the 4 components solved the problem instance. On the other
hand, when runtimes are considered as well as coverage, then in 83.0% of the instances, A* /autoconf
made the correct decision, where the selection was deemed to be correct if A* /autoconf selected the
model that had the best runtime (including ties), or none of the 4 components solved the problem

instance. As a baseline, LPectr (T ), which had the best coverage among all of the component models,
is the correct choice according to this criterion 49.9% of the time. Mistakes in the selections made
by A* /autoconf can be seen in Table 10 coverage results  for example, in the woodworking-opt11

domain, A* /autoconf solved 18 instances compared 20 instances solved by LPectr (T ). Thus, there
is significant room for improvement when runtimes are considered in addition to coverage, and
improving the model selection using machine learning techniques is a direction for future work.

10. Discussion and Conclusion
This paper proposed a new, integer-linear programming formulation of the delete relaxation h+
for cost-optimal, domain-independent planning. We started with a basic IP model IP(T + ), and
showed that an enhanced model IPe (T + ), which incorporates landmark-based variable reduction,
relevance analysis, and action elimination, is competitive with previous methods for solving deletefree versions of the standard IPC planning benchmarks tasks (i.e., exact computation of h+ ).
The results of embedding our IP model as the heuristic function in a A* -based forward search
planner confirmed that the plain IP(T + ) model is not practical (coverage of 403/1367 instances
vs. 540 for Fast Downward using hmax ). However, we showed that the IPe (T + ) model, which
uses variable reduction methods to reduce the size of the IP models and exactly computes h+ ,
performed much better, with a coverage of 635 instances. According to the summary results in
670

fiFD/SEQ

A* /LPe (T + )

+
A* /LPe
tr (T )

22
4
28
7
12
11
9
2
15
1
7
4
16
50
21
15
12
7
19
14
15
11
5
4
27
17
14
8
49
6
6
12
9
24
19
6
11
6
6
16
10
5
9
571
10

28
4
27
7
13
19
16
2
15
2
7
5
21
54
21
15
16
7
19
14
17
13
1
4
27
17
16
8
49
6
6
7
4
29
20
6
11
6
7
16
16
11
11
620
12

22
4
28
7
12
10
8
4
39
1
7
4
16
52
20
15
10
7
17
12
28
20
4
4
28
18
15
8
50
6
6
14
11
20
17
8
11
6
9
17
14
9
9
627
12

25
0
28
7
11
13
10
6
44
2
6
6
20
140
18
13
14
7
11
6
20
16
1
5
26
16
12
7
48
7
10
8
5
23
19
6
9
4
15
16
16
10
10
696
5

25
0
28
7
13
13
10
7
43
2
6
6
20
141
17
12
14
7
11
6
20
16
1
5
26
16
13
7
48
7
10
8
5
25
19
6
10
5
15
16
17
11
11
705
6

A* /autoconf

FD/PHO-SYS2

20
4
26
4
10
8
6
2
8
1
6
2
14
45
19
13
8
7
11
6
11
7
1
4
22
12
13
7
48
6
5
10
7
18
15
6
9
4
3
15
8
3
8
462
2



FD/PHO-SYS1

30
4
29
7
13
19
16
6
33
2
6
6
20
141
22
16
12
7
16
11
29
20
2
5
28
18
14
8
50
7
7
14
11
29
20
8
11
6
10
19
21
16
12
781
18

A* /LPe
ctr (T )

FD/OPT-SYS1

28
4
28
7
13
20
16
6
15
2
6
6
20
141
23
16
14
7
19
14
18
13
2
5
27
17
17
8
49
7
7
14
11
28
20
6
11
6
10
10
16
11
12
730
13



FD/LMC-SEQ

28
4
28
7
14
22
18
7
15
2
7
6
20
141
23
16
14
7
19
14
19
14
3
5
27
17
17
8
49
7
7
15
12
30
20
6
11
6
10
11
17
12
13
748
22

25
0
29
7
12
6
4
6
17
2
6
7
20
139
15
11
8
7
6
2
29
20
1
14
22
12
12
7
50
11
9
7
4
22
19
8
6
1
12
17
30
20
10
672
12

25
3
29
7
13
8
6
7
21
3
6
7
20
140
16
11
11
7
10
5
29
20
1
14
26
16
13
7
50
11
9
8
5
26
19
8
6
1
15
17
30
20
10
716
15

25
2
29
7
13
13
10
7
44
3
6
7
20
141
18
12
14
7
11
6
29
20
1
14
26
16
13
7
50
11
10
8
5
25
19
8
10
5
15
17
28
18
11
761
16

A* /LPe
c (T )

FD/LMC

Domain
airport(50)
barman-opt11(20)
blocks(35)
depot(22)
driverlog(20)
elevators-opt08(30)
elevators-opt11(20)
floortile-opt11(20)
freecell(80)
grid(5)
gripper(20)
logistics98(35)
logistics00(28)
miconic(150)
no-mprime(35)
no-mystery(30)
nomystery-opt11(20)
openstacks(30)
openstacks-opt08(30)
openstacks-opt11(20)
parcprinter-08(30)
parcprinter-opt11(20)
parking-opt11(20)
pathways-noneg(30)
pegsol-08(30)
pegsol-opt11(20)
pipesworld-notankage(50)
pipesworld-tankage(50)
psr-small(50)
rovers(40)
satellite(36)
scanalyzer-08(30)
scanalyzer-opt11(20)
sokoban-opt08(30)
sokoban-opt11(20)
tpp(30)
transport-opt08(30)
transport-opt11(20)
trucks(30)
visitall-opt11(20)
woodworking-opt08(30)
woodworking-opt11(20)
zenotravel(20)
Total coverage (1376)
# Best domains

FD/LM-cut

O N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

Table 10: Comparison of forward search (A* ) planners, part 2: Number of problems solved with
30 minute, 2GB RAM limit using A* and our IP/LP models as heuristic functions. Includes LP


models that incorporate counting constraints (LPec (T ), LPectr (T ), Section 8), as well as A* /autoconf
(Section 9). Comparison with Fast Downward using operator-counting LP models (Pommerening
et al., 2014).

671

fiI MAI & F UKUNAGA

Configuration
FD/LM-cut

# solved
748

FD/hmax
FD/SEQ
FD/PHO-SYS1
FD/PHO-SYS2
FD/LMC

540
627
571
620
730

FD/OPT-SYS1
FD/LMC-SEQ
A* /HST/CPLEX

462
781
398

A* /IP(T + )
A* /IPe (T + )
A* /LPe (T + )
A* /LPetr (T + )

A* /LPec (T )
*
e
A /LPctr (T )
A* /autoconf

403
635
696
705
672
716
761

Description
Fast Downward (FD) using standard Landmark Cut heuristic
(seq-opt-lmcut)
FD using hmax heuristic
FD using SEQ LP heuristic (Pommerening et al., 2014)
FD using PHO-SYS1 LP heuristic (Pommerening et al., 2014)
FD using PHO-SYS2 LP heuristic (Pommerening et al., 2014)
FD using LP model of optimal cost partitioning on landmark constraints (Pommerening et al., 2014)
FD using OPT-SYS1 LP heuristic (Pommerening et al., 2014)
FD using LMC+SEQ LP heuristic (Pommerening et al., 2014)
hsp planner using A* and h+ heuristic (Haslum et al., 2012; Haslum,
2012)
basic IP formulation for h+
IP(T + ) with all enhancements in Sections 4.1-4.6
LP relaxation of IPe (T + )
LP relaxation of the time-relaxed model IPetr (T + )

LP relaxation of IPec (T )

LP relaxation of the time-relaxed model IPectr (T )
Automated selection of LP at root node(Section 9)

Table 11: Summary of coverage (# solved) on 1376 IPC benchmark problems instances with 30
minute time limit and 2GB RAM (see Tables 8-10 for detailed results)
Table 11, the aggregate coverage of IPe (T + ) is comparable to the coverage obtained by the LPbased SEQ, OPT-SYS1, PHO-SYS1, and PHO-SYS2 heuristics recently implemented using the
operator-counting framework by Pommerening et al. (2014). However, the aggregate coverage on
the IPC benchmarks is skewed by the miconic domain, where SEQ, OPT-SYS1, PHO-SYS1, and
PHO-SYS2 perform particularly poorly compared to other heuristics. If the miconic domain is not
included, then IPe (T + ) is not competitive with these LP-based models. Note that on the freecell
domain, A* with the IPe (T + ) heuristic solved 54/80 instances, which is significantly higher than all
other methods, so there is at least 1 domain where exact h+ computation using the IPe (T + ) model
performs extremely well compared to other state-of-the-art heuristics.
We then showed that the gap between the optimal value of the LP relaxations of our IP models
and h+ tended to be quite small (the gap was often zero), suggesting that the LP relaxations, which
can be computed much faster than the IP models, could be used as a heuristic for A* -based planning.
A time-relaxation that eliminates all time-related constraints was also proposed as another way to
reduce the model in order to be solvable faster. A comparison of our LP-relaxed delete relaxation
models with the LM-cut (Helmert & Domshlak, 2009) heuristic values showed that these approaches
are complementary with respect to how closely they approximate h+ . Thus, the LP-relaxation of
our delete-free models provides a novel, practical alternative to approximating h+ . We showed
that A* search using LPe (T + ) (LP-relaxation of delete-free task) and LPetr (T + ) (time relaxed,
LP-relaxation of delete-free task) significantly improves upon the IP models, solving 696 and 705
instances, respectively, making them usable as practical heuristics.
A major advantage of LP-based heuristics is the relative ease with which additional constraints
can be added in order to obtain improved heuristics. We showed that the counting constraints,
corresponding to the net change constraints proposed in previous work (van den Briel et al., 2007;

Pommerening et al., 2014), could be added to our LP model. The resulting heuristic, LPectr (T )
had mixed results, improving performance on some domains, but degrading performance on other

domains, i.e., LPetr (T + ) and LPectr (T ) are complementary heuristics.
672

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL



Since there is no dominance relationship among A* /LPe (T + ), A* /LPetr (T + ), A* /LPec (T ) and

*
A /LPectr (T ), we proposed A* /autoconf , a simple method which automatically selects among these
4 heuristics by computing all 4 heuristic values at the root node and using the most accurate heuristic
(breaking ties according to speed). We showed that overall, A* /autoconf significantly improves upon
its 4 components, and is competitive with the landmark-cut heuristic, solving 761/1367 instances
and achieving state-of-the-art performance on several domains.
While A* /autoconf has lower total coverage compared to Fast Downward using the LMC-SEQ
LP-based heuristic (Pommerening et al., 2014), the LP(T + )-based approach outperforms LMCSEQ on several domains including freecell, pathways-noneg, rovers, satellite, trucks, and woodworking. Although A* /autoconf includes LP models with counting constraints that consider some
delete effects, note that A* /LPetr (T + ), which uses a pure delete-free LP, performs quite well, obtaining higher coverage than all of the operator-count based heuristics of Pommerening et al. (2014)
in the floortile, freecell, nomystery-opt11, satellite, and trucks domains, so the counting constraints
are not required in order for A* using the delete-relaxation based LPs to achieve state-of-the-art
performance on some domains.
A comparison of the optimal values of our counting-constraint enhanced delete-relaxation LP


models LPec (T ) and LPectr (T ) with the optimal LP values of the LMC-SEQ model showed that
they are complementary, with each class of models outperforming the other on roughly the same
number of domains (Section 8.1). Thus, integrating these two approaches in a single LP model
is a promising direction for future work. In a recent survey of LP-based heuristics for planning,
Roger and Pommerening (2015) noted that our delete-relaxation model can be incorporated into the
operator counting framework of Pommerening et al. (2014) by adding operator-counting variables
for each operator in the delete-relaxed problem  this is a promising direction for future work. Note
that while both Pommerening et al. (2014) and our approach use landmarks, they are used for very
different purposes. The landmark constraints used by Pommerening et al. (2014) are used directly
as operator counting constraints. In contrast, our approach uses landmarks order to decrease the
size of the IP/LP models for the delete-free task and is used for the purpose of speeding up the
computation of the IP/LP models, i.e., landmark based reduction does not change the optimal value
of IP(T + ).

We showed that adding counting constraints that consider some delete effects (i.e., LPec (T ) and

LPectr (T )) can improve performance on some domains, but in some domains, coverage dropped
significantly. This is because the additional constraints make the LP more difficult to solve, so the
increased search efficiency due to the tighter bound is not enough to overcome the increased cost
of solving the LP at each search node. A* /autoconf attempts to address this by selecting the models
with counting constraints only when they return a higher value than the model without counting constraints at the root node, and otherwise uses a model that does not include the counting constraints
(i.e., LPe (T + ) or LPetr (T + )). On the other hand, strengthening the delete-relaxation by considering
some of the delete effects has been an active area of research, and recently, two frameworks that allow flexible interpolation between the delete relaxation and the original model have been proposed.
Keyder, Hoffmann, and Haslum (2014) propose an approach which adds new fluents that represent
conjunctions of fluents in the original planning task. Red-black planning (Domshlak, Hoffmann, &
Katz, 2015) is a framework which separates state variables into two groups  red variables which are
relaxed, and black variables that are not relaxed. Combining these flexible relaxation frameworks
with our IP approach and developing a more principled approach to deciding when to use counting
constraints is an avenue for future work.
673

fiI MAI & F UKUNAGA

Our current implementation uses the CPLEX solver naively, relying entirely on default control
parameters. Systematically tuning and improving the implementation of our IP/LP models in order
to make better use of incremental IP/LP solving capabilities is a promising direction for future work.
Although we have shown that our LP models often compute h+ exactly, there are some domains
where there are significant gaps between h+ and the optimal cost of the LP models. Improved
modeling techniques may allow tighter LP bounds. For example, Constraint C6 uses straightforward
a big-M encoding, and it may be possible to obtain tighter bounds using other methods.
Furthermore, although solving and IP at each node in a forward-search based planner has previously been considered impractical, we have shown that our IPe (T + ) model, which computes h+
exactly, is almost useful as a practical heuristic, and improving the techniques used to solve the IP
for the IPe (T + ) may result in a balance of accuracy and speed necessary for a practical general
purpose heuristic. For example, significant performance improvements might be obtainable by improving the use of the IP solver. For example, in contrast to LP solvers, where parallel speedups are
often difficult to obtain, IP solvers can often be sped up significantly by parallelization, and current
IP solvers already provide parallel search algorithms (which we did not use in this paper because
we limited our experiments to single threads). As the number of cores per processor continues to increase, it is possible that in some cases, IP-based heuristics may become more useful than LP-based
heuristics.

Acknowledgments
Thanks to Patrik Haslum for assistance with his code for computing h+ and his hsp f planner.
Thanks to Florian Pommerening for assistance with the code for the LP heuristic-based Fast Downward (Pommerening et al., 2014). Thanks to the anonymous reviewers for numerous helpful suggestions which significantly improved the paper. This research was supported by a JSPS Grant-in-Aid
for JSPS Fellows and a JSPS KAKENHI grant.

References
Backstrom, C., & Nebel, B. (1995). Complexity Results for SAS+ Planning. Computational Intelligence, 11(4), 625655.
Betz, C., & Helmert, M. (2009). Planning with h+ in theory and practice. In KI 2009, pp. 916.
Springer.
Blum, A., & Furst, M. (1997). Fast Planning Through Planning Graph Analysis. Artificial Intelligence, 90(1-2), 281300.
Bonet, B. (2013). An admissible heuristic for SAS+ planning obtained from the state equation.
In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), pp.
22682274.
Bonet, B., & Castillo, J. (2011). A complete algorithm for generating landmarks. In Proceedings of
the International Conference on Automated Planning and Scheduling (ICAPS).
Bonet, B., & Geffner, H. (2001). Planning as heuristic search. Artificial Intelligence, 129(1-2),
533.
Bonet, B., & Helmert, M. (2010). Strengthening landmark heuristics via hitting sets. In Proceedings
of the European Conference on Artificial Intelligence (ECAI), pp. 329334.
674

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

Bonet, B., & van den Briel, M. (2014). Flow-based heuristics for optimal planning: Landmarks
and merges. In Proceedings of the International Conference on Automated Planning and
Scheduling (ICAPS).
Bylander, T. (1994). The Computational Complexity of Propositional STRIPS Planning. Artificial
Intelligence, 69(12), 165204.
Bylander, T. (1997). A linear programming heuristic for optimal planning. In Proceedings of the
National Conference on Artificial Intelligence (AAAI), pp. 694699.
Cooper, M. C., de Roquemaurel, M., & Regnier, P. (2011). Transformation of optimal planning
problems. Journal of Experimental & Theoretical Artificial Intelligence, 23(2), 181199.
Dimopoulos, Y. (2001). Improved integer programming models and heuristic search for ai planning.
In Proceedings of 6th European Conference on Planning (ECP), pp. 5057.
Domshlak, C., Karpas, E., & Markovitch, S. (2012). Online speedup learning for optimal planning.
Journal of Artificial Intelligence Research, 44, 709755.
Domshlak, C., Hoffmann, J., & Katz, M. (2015). Red-black planning: A new systematic approach
to partial delete relaxation. Artificial Intelligence, 221, 73114.
Gefen, A., & Brafman, R. (2011). The minimal seed set problem. In Proceedings of the International Conference on Automated Planning and Scheduling (ICAPS), pp. 319322.
Gefen, A., & Brafman, R. (2012). Pruning methods for optimal delete-free planning. In Proceedings
of the International Conference on Automated Planning and Scheduling (ICAPS), pp. 5664.
Haslum, P. (2012). Incremental lower bounds for additive cost planning problems. In Proceedings
of the International Conference on Automated Planning and Scheduling (ICAPS), pp. 7482.
Haslum, P. (2014a) Personal communication.
Haslum, P. (2014b). Hsp* code and documentatoin http://users.cecs.anu.edu.au/
patrik/un-hsps.html..
Haslum, P., Slaney, J., & Thiebaux, S. (2012). Minimal landmarks for optimal delete-free planning. In Proceedings of the International Conference on Automated Planning and Scheduling
(ICAPS), pp. 353357.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths and abstractions: Whats the difference anyway?. In Proceedings of the International Conference on Automated Planning and
Scheduling (ICAPS), pp. 162169.
Hoffmann, J., & Nebel, B. (2001). The FF Planning System: Fast Plan Generation Through Heuristic Search. Journal of Artificial Intelligence Research, 14, 253302.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks in planning. Journal of
Artificial Intelligence Research, 22, 215278.
Imai, T., & Fukunaga, A. (2014). A practical, integer-linear programming model for the deleterelaxation in cost-optimal planning. In Proceedings of the European Conference on Artificial
Intelligence (ECAI).
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning with landmarks. In Proceedings of the
International Joint Conference on Artificial Intelligence (IJCAI), pp. 17281733.
675

fiI MAI & F UKUNAGA

Katz, M., & Domshlak, C. (2010). Optimal admissible composition of abstraction heuristics. Artificial Intelligence, 174(12-13), 767798.
Kautz, H., & Selman, B. (1992). Planning as Satisfiability. In Proceedings of the European Conference on Artificial Intelligence (ECAI), pp. 359363.
Kautz, H. A., & Selman, B. (1996). Pushing the envelope: Planning, propositional logic and stochastic search. In Proceedings of the National Conference on Artificial Intelligence (AAAI), pp.
11941201.
Kautz, H. A., & Selman, B. (1999). Unifying sat-based and graph-based planning. In Proceedings
of the International Joint Conference on Artificial Intelligence (IJCAI), pp. 318325.
Keyder, E., Richter, S., & Helmert, M. (2010). Sound and complete landmarks for and/or graphs.
In Proceedings of the European Conference on Artificial Intelligence (ECAI), pp. 335340.
Keyder, E., & Geffner, H. (2008). Heuristics for planning with action costs revisited. In Proceedings
of the European Conference on Artificial Intelligence (ECAI), pp. 588592.
Keyder, E. R., Hoffmann, J., & Haslum, P. (2014). Improving delete relaxation heuristics through
explicitly represented conjunctions. Journal of Artificial Intelligence Research, 50, 487533.
Mirkis, V., & Domshlak, C. (2007). Cost-sharing approximations for h+. In Proceedings of the
International Conference on Automated Planning and Scheduling (ICAPS), pp. 240247.
Pommerening, F., & Helmert, M. (2012). Optimal planning for delete-free tasks with incremental LM-cut. In Proceedings of the International Conference on Automated Planning and
Scheduling (ICAPS), pp. 363367.
Pommerening, F., Roger, G., Helmert, M., & Bonet, B. (2014). LP-based heuristics for costoptimal planning. In Proceedings of the International Conference on Automated Planning
and Scheduling (ICAPS).
Pommerening, F., Roger, G., & Helmert, M. (2013). Getting the most out of pattern databases
for classical planning. In Proceedings of the International Joint Conference on Artificial
Intelligence (IJCAI).
Rintanen, J. (2012). Planning as satisfiability: Heuristics. Artificial Intelligence, 193, 4586.
Rintanen, J., Heljanko, K., & Niemela, I. (2006). Planning as satisfiability: parallel plans and algorithms for plan search. Artificial Intelligence, 170(12-13), 10311080.
Robinson, N. (2012). Advancing Planning-as-Satisfiability. Ph.D. thesis, Griffith University.
Robinson, N., McIlraith, S. A., & Toman, D. (2014). Cost-based query optimization via AI planning.
In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July 27 -31,
2014, Quebec City, Quebec, Canada., pp. 23442351.
Roger, G., & Pommerening, F. (2015). Linear programming for heuristics in optimal planning. In
AAAI2015 Workshop on Planning, Search, and Optimization.
van den Briel, M. (2015) Personal communication.
van den Briel, M., Benton, J., Kambhampati, S., & Vossen, T. (2007). An LP-based heuristic for
optimal planning. In Proceedings of International Conference on Principles and Practice of
Constraint Programming (CP).
676

fiO N A P RACTICAL , I NTEGER -L INEAR P ROGRAMMING M ODEL

van den Briel, M., & Kambhampati, S. (2005). Optiplan: A planner based on integer programming.
Journal of Artificial Intelligence Research, 24, 919931.
van den Briel, M., Vossen, T., & Kambhampati, S. (2008). Loosely coupled formulation for automated planning: An integer programming perspective. Journal of Artificial Intelligence
Research, 31, 217257.
Vossen, T., Ball, M. O., Lotem, A., & Nau, D. S. (1999). On the use of integer programming models
in AI planning. In Proceedings of the International Joint Conference on Artificial Intelligence
(IJCAI), pp. 304309.
Zhu, L., & Givan, R. (2003). Landmark extraction via planning graph propagation. In Proceedings
of ICAPS Doctoral Consortium, pp. 156160.

677

fi