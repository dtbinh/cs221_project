Journal of Artificial Intelligence Research 45 (2012) 79-124

Submitted 03/12; published 09/12

An Approximative Inference Method for Solving SO
Satisfiability Problems
Hanne Vlaeminck
Joost Vennekens
Marc Denecker
Maurice Bruynooghe

hanne.vlaeminck@cs.kuleuven.be
joost.vennekens@cs.kuleuven.be
marc.denecker@cs.kuleuven.be
maurice.bruynooghe@cs.kuleuven.be

Department of Computer Science,
Celestijnenlaan 200a
3001 Heverlee, Belgium

Abstract
This paper considers the fragment SO of second-order logic. Many interesting problems, such as conformant planning, can be naturally expressed as finite domain satisfiability problems of this logic. Such satisfiability problems are computationally hard (P
2 ) and
many of these problems are often solved approximately. In this paper, we develop a general
approximative method, i.e., a sound but incomplete method, for solving SO satisfiability
problems. We use a syntactic representation of a constraint propagation method for firstorder logic to transform such an SO satisfiability problem to an SO(ID) satisfiability
problem (second-order logic, extended with inductive definitions). The finite domain satisfiability problem for the latter language is in NP and can be handled by several existing
solvers. Inductive definitions are a powerful knowledge representation tool, and this motivates us to also approximate SO(ID) problems. In order to do this, we first show how
to perform propagation on such inductive definitions. Next, we use this to approximate
SO(ID) satisfiability problems. All this provides a general theoretical framework for a
number of approximative methods in the literature. Moreover, we also show how we can
use this framework for solving practical useful problems, such as conformant planning, in
an effective way.

1. Introduction
Finite model generation is a logical paradigm for solving constraint problems. A successful
instance is the field of SAT, where efficient solvers for the low level CNF language are developed. Other instances, but for more expressive languages, are Answer Set Programming
(ASP) (Baral, 2003) and model expansion (MX) for (extensions of) first order logic. In ASP,
e.g., finite Herbrand models of an answer set program are computed (Baral, 2003). Model
expansion (MX) (Mitchell & Ternovska, 2005) generalizes Herbrand model generation and
aims at computing one or more models of a theory T that expand a finite interpretation I0
for a (possibly empty) subset of symbols of T . MX for first order logic (MX(FO)) is formally
equivalent to the finite domain satisfiability checking problem for existential second-order
logic (SAT (SO))1 which is known from Fagins celebrated theorem to capture NP (Fagin,
1974). That is, the problems in NP are exactly those that are in a precise sense equivalent
to an SO satisfiability problem, and hence an MX(FO) problem. A range of solvers exists
1. Or more specifically, to the search problem for a witness of such a problem.
c
2012
AI Access Foundation. All rights reserved.

fiVlaeminck, Vennekens, Denecker & Bruynooghe

for finite model generation, e.g., an overview of state-of-the-art ASP and MX(FO()) solvers
(here, FO() refers to the family of extensions of FO) can be found in the reports of the
ASP competition (e.g., Denecker, Vennekens, Bond, Gebser, & Truszczynski, 2009).
Example 1.1. Here is a bounded planning problem modeled as a Finite Model Generation
problem. The problem is deliberately kept simple as it will serve as the running example
in this paper: a glass may be clean or not, and can be cleaned by the action of wiping. We
can represent this dynamic domain by the following FO theory Tact :
t : (Clean(t + 1)  Clean(t)  W ipe(t)).
Clean(0)  InitiallyClean.

(1)
(2)

The bounded planning problem we are considering is then to turn a dirty glass into a clean
one in n steps, where n  N is a given constant. This can indeed be formulated as a
Model Expansion problem: find a model that satisfies Tact while InitiallyClean is false,
and Clean(n) true. We can formulate this problem equivalently as an SO finite domain
satisfiability problem, namely as the satisfiability problem in the range [0 . . . n] of time
points of the following SO formula:
W ipe, Clean, InitiallyClean : (act  InitiallyClean  Clean(n)),

(3)

where with act we denote the conjunction of sentences in Tact . For n > 0, this formula is
indeed satisfiable in the suitable interpretation of constants 0 and n and the binary function
+, and, moreover, each witness W for its satisfiability provides a plan. For instance, wiping
at time point 0 does the job, as is verified by the witness W for which W ipeW = {0} and
CleanW = {1, . . . , n}.
While a large number of search problems can indeed be seen as Finite Model Generation
problems, there are also a number of problems that are of a higher complexity than NP,
and consequently cannot be formulated as an MX(FO) problem. Indeed, in this paper we
are not interested in NP, but in the next level P2 of the polynomial hierarchy. Perhaps
the prototypical such problem is finite domain satisfiability for SO: satisfaction in finite
interpretations is in P2 for every SO sentence and is P2 -hard for some such sentences
(Immerman, 1998). An interesting P2 problem is that of conformant planning, which we
discuss in detail in Section 7, but already introduce in the next example.
Example 1.2. Extending Example 1.1, suppose that we do not know whether the object is
initially clean or dirty, but still want a plan that is guaranteed to make it clean, no matter
what the initial situation was. This is no longer a standard planning problem, but is called
a conformant planning problem. We can formulate this as the following SO satisfiability
problem:
 W ipe InitiallyClean, Clean : (act  Clean(n)).
(4)
In words, we need an assignment to the action W ipe such that the goal Clean(n) is satisfied
for every initial situation InitiallyClean and fluent Clean that satisfy the action theory.
Solving problems like this would require us to make a choice for the existentially quantified predicates and then check that the implication is satisfied for every interpretation of
80

fiAn Approximative Inference Method for SO

the universally quantified predicates. While this can be done in principle, in practice it
is often too expensive. In this paper, we explore an alternative based on a propagation
method for first order logic developed by Wittocx, Denecker, and Bruynooghe (2010). This
method computes in polynomial time, for a given theory T and a partial interpretation I,
an approximation of what has to be certainly true (= true in all models of T that expand
I) and certainly false (= false in all such models). Now, an interesting property of this
propagation method is that it can be syntactically represented as a monotone inductive
definition (Denecker & Ternovska, 2008) that defines (in an approximative way) these underestimates of the predicates in T and of their complements. Such a monotone inductive
definition is essentially just a set of propagation rules, similar to a definite logic program,
that is interpreted by the least fixpoint of its immediate consequence operator. For any
given theory T we can obtain this approximating definition by a linear transformation of
the original FO formula.
Returning to the above example, we need to find an interpretation for the action predicates, such that for every interpretation of the other predicates, the implication act 
Clean(n) is satisfied, i.e., such that without knowing anything about these other predicates, we should already be certain that the implication is satisfied. The basic idea behind
our method is to approximate an SO problem of the form P Q , using the approximate definition from Wittocx et al. to check whether an interpretation for the existentially
quantified predicates P has the property of making  true, regardless of the predicates Q.
Essentially, this reduces an SO problem to an SO(ID) problem (where with SO(ID) we
refer to SO extended with inductive definitions).
In Section 5, we extend our method to SO(ID) problems. As argued by Denecker
and Ternovska, inductive definitions are a useful tool for knowledge representation. For
example, many dynamic domains can be formulated naturally and in a modular way using
inductive definitions, while this can be quite tedious in FO. We already mentioned conformant planning as a typical SO satisfiability problem. Typically, these conformant
planning problems require the modeling of a dynamic domain. We will come back to the
syntax and semantics of inductive definitions in the next section, but the dynamic domain of
Example 1.1 can, as an alternative to the action theory Tact , be formulated as the following
inductive definition act :


 Clean(t + 1)  Clean(t).

Clean(t + 1)  W ipe(t).
(5)


Clean(0)
 InitiallyClean.
The conformant planning problem can then be formulated alternatively as the satisfiability problem of the formula  W ipe InitiallyClean, Clean : (act  Clean(n)). However,
this is no longer a SO satisfiability problem, but a SO(ID) satisfiability problem.
This motivates us to see how we can extend our approximation method to such SO(ID)
satisfiability problems. For this purpose, we first show how to symbolically represent propagation on inductive definitions. Next, we show how we can use this together with the
representation of propagation for FO to approximate finite domain SO(ID) satisfiability
problems.
Our approximation method has a number of benefits. First of all, it is a general method,
that can be applied automatically to approximately solve any SO problem. Second, the
81

fiVlaeminck, Vennekens, Denecker & Bruynooghe

required computation can be carried out by any off-the-shelf MX(FO(ID)) solver, allowing
our method to benefit effortlessly from improvements in solver technology, such as the
IDP system by Marien, Wittocx, and Denecker (2006). Finally, as we show in Section 7,
our method elegantly generalizes a number of approximate reasoning methods from the
literature (e.g., Baral, Gelfond, & Kosheleva, 1998; Son, Tu, Gelfond, & Morales, 2005;
Denecker, Cortes Calabuig, Bruynooghe, & Arieli, 2010; Doherty, Magnusson, & Szalas,
2006; Son et al., 2005).
Parts of this work have already been presented at the JELIA 2011 conference (Vlaeminck, Wittocx, Vennekens, Denecker, & Bruynooghe, 2010).

2. Preliminaries
We assume familiarity with classical first-order logic (FO) and second-order logic (SO). In
this section we introduce some of the notations and conventions used throughout this paper.
2.1 First-order Logic
A vocabulary  is a finite set of predicate symbols P and function symbols F , each with
an associated arity. Constants are function symbols with arity 0. We often denote a symbol
S with arity n by S/n. A interpretation I consists of a domain D and an assignment
of a relation P I  Dn to each predicate symbol P/n   and an assignment of a function
F I : Dn  D to each function symbol F/n  . We assume that P contains the equality
predicate = interpreted as the identity relation. A pre-interpretation of  consists of a
domain and an interpretation of the function symbols. If I is a -interpretation and 0  ,
we denote by I|0 the restriction of I to the symbols of 0 . If 1 and 2 are two disjoint
vocabularies, I a 1 -interpretation with domain D and J a 2 -interpretation with the same
domain, then I + J denotes the unique (1  2 )-interpretation with domain D such that
(I + J)|1 = I and (I + J)|2 = J.
Terms and formulas over a vocabulary  are defined as usual. An expression of the form
 where P is an n-ary predicate and d  Dn is called a domain atom. A domain literal
P (d)
 or the negation P (d)
 thereof. As usual, we denote a formula 
is a domain atom P (d)
by [x] to indicate that the set of free variables of  is a subset of x. A formula without
free variables is called a sentence. The satisfaction relation |= is defined as usual. For an
 we
interpretation I, a formula  with n free variables and a tuple of n domain elements d,


use I |= [d] as a shorthand for I, [x : d] |= [x], where  is a variable assignment, and
 is the variable assignment that is the same as  except that it maps the variables
[x : d]
 We define the truth evaluation function ([d])
 I as follows:
x to the domain elements d.
I
I



([d]) = t iff I |= [d] and ([d]) = f otherwise. We say that a formula  is in negation
normal form if  contains no implications or equivalences, and all negations occur directly
in front of atoms. We define the inverse on truth values as follows: (f )1 = t and (t)1 = f .
We also define the following strict order on the truth values: f <t t. The truth order
point-wise extends to interpretations: if I and J are two -interpretations, then we say
that I t J if for every predicate symbol P and tuple of domain elements d it holds that
 t P J (d).

P I (d)
Similar to how a real number r can be approximated by an interval [l, u] such that l  r 
u, in this paper we approximate -interpretations K by a pair (I, J) of -interpretations,
82

fiAn Approximative Inference Method for SO

such that I t K t J. We denote by [I, J] the interval of all such interpretations K.
This interval is empty if and only if I 6t J. It follows easily from well-known monotonicity
results, that if we evaluate all positive occurrences (i.e., in the scope of an even number of
negations) of atoms in some formula  by I, and all negative occurrences (i.e., in the scope
of an odd number of negations) by J, we are underestimating the truth of  in the interval
[I, J]. Conversely, if we evaluate positive occurrences in J and negative occurrences in I,
we are overestimating the truth of  in [I, J]. To state this property more formally, we
introduce the following notation.
Definition 2.1 (Pos-neg evaluation relation +IJ ). Let  be a -formula and let I and J
be -interpretations. We define the pos-neg evaluation of  in I and J, denoted by +IJ ,
by induction over the size of :
 for an atom  = P (t), +IJ = I ;
 for  = , +IJ = ( +JI )1 ;
 for  = 1  2 , +IJ = t iff i+IJ = t for both i = 1, 2;
 for  = x , +IJ = t iff there is a d  D such that  +I[x/d]J[x/d] = t.
We now indeed have that, for each K  [I, J], +IJ  K  +JI . Also, we have
that K = +KK .
There is an intimate connection between the approximation of an interpretation by a
pair of interpretations and Belnaps four-valued logic (1977). We denote the truth values
true, false, unknown and inconsistent of four-valued logic by respectively t, f , u and i. On
these truth values, the truth order t and precision order p are defined as shown in Figure
1.
A four-valued relation of arity n on some domain D is a function from Dn to {t, f , u, i}.
A four-valued interpretation I of vocabulary  consists of a pre-interpretation and of P I ,
a four-valued relation of arity n on D for each predicate symbol P/n  . Again, the
precision order pointwise extends to interpretations: if I and J are two -interpretations,
then we say that I p J if for every predicate symbol P and tuple of domain elements d it
 p P J (d).
 Similarly, also the truth order is extended to interpretations.
holds that P I (d)
@t^
<t

<p

<t

u^

@i

<p

f_

<t

<t

@i^

?t
<p

<p

u

f

Figure 1: The truth and precision order
83

fiVlaeminck, Vennekens, Denecker & Bruynooghe

There is a natural isomorphism between Belnaps four truth values and pairs of the two
standard truth values:
 (t, t) = t;
 (f , t) = u;
 (t, f ) = i;
 (f , f ) = f .
Intuitively, this mapping  interprets its first argument as an underestimate to the real
truth value, and its second argument as an overestimate: if the underestimate is f and the
overestimate is t, then the real truth value is indeed unknown; whereas, if the underestimate
is t and the overestimate if f , then there cannot exist a real truth value, since t 6 f , so we
end up with inconsistency. This isomorphism  extends in an obvious way to an isomorphism
between pairs (I, J) of two-valued interpretations and four-valued interpretations I which
all share the same pre-interpretations: (I, J) and I are isomorphic iff, for each predicate
 =  (P I (d),
 P J (d)).
 We also denote this isomorphism by  .
P/n and tuple d  Dn , P I (d)
There is a tight link between the pos-neg evaluation function +IJ and the Belnap
evaluation I :
I =  (+IJ , +JI ), where  (I, J) = I.
When I is a three-valued structure (i.e., it never assigns i) this corresponds to the standard
Kleene evaluation (1952). In the rest of this paper, we will often omit the isomorphism  ,
and, e.g., simply denote the four-valued truth value of a formula  in a pair of interpretations
(I, J) as (I,J) . An important property, that we already stated above in different notation,
is that (I,J) p K for all K  [I, J].
There is a natural and well-known alternative way of using an interval [I, J] for which
I t J to assign a truth value to a formula : the supervaluation (van Fraassen, 1966).
Definition 2.2 (Supervaluation sv(I,J) (.)). The supervaluation sv(I,J) () of a sentence 
in a pair of interpretations (I, J) (or equivalently, a three-valued interpretation  (I, J)) is
defined as
sv(I,J) () = glbp ({K |K  [I, J]}).
It is easy to see that always sv(I,J) () p (I,J) . This inequality may be strict. For
instance, if we take  = Q  Q and interpretations I and J such that Q(I,J) = u, then
sv(I,J) () = t, but (I,J) = u. The supervaluation has the following interesting property.
Let I be an interpretation for the free vocabulary of a SO formula  = Q , and let (J1 , J2 )
 =u
be the least precise pair of interpretations for Q in the domain D of I (i.e., Q(J1 ,J2 ) (d)
n

for all Q/n  Q and d  D ). We then have that sv(I+J1 ,I+J2 ) () = t if and only if I = t.
Key to our approach is that we can simulate the four-valued truth evaluation in pairs
of interpretations by encoding what is certainly true and certainly false, using a single
two-valued structure I tf over a new vocabulary tf . As we show in the next section, this
gives us a convenient vocabulary to syntactically represent the construction of such an
approximation. The new vocabulary tf contains the function symbols F of  and, for
each predicate P  P , two symbols P ct and P cf . The interpretations of P ct and P cf
 is certainly true and those for
in I tf contain, respectively, those tuples d for which P I (d)
which it is certainly false. Formally, for a vocabulary  and a four-valued -interpretation
84

fiAn Approximative Inference Method for SO

I =  (I, J), the tf -interpretation I tf has the same pre-interpretation as I, and is defined
by:
(P ct )I

tf

 I (d)
 p t} = P I ,
= {d|P

(P cf )I

tf

 I (d)
 p f } = Dn \ P J .
= {d|P
tf

tf

An interpretation I is three-valued iff (P ct )I and (P cf )I are disjoint for any P  . I
tf
tf
is two-valued iff (P ct )I and (P cf )I are each others complement in Dn . Also, if I p J ,
tf
tf
tf
tf
then, for each P , (P ct )I  (P ct )J and (P cf )I  (P cf )J .
Definition 2.3 (ct and cf ). For any given -formula [x], let ct [x] be the tf -formula
obtained by first reducing to negation normal form and then replacing all occurrences of
positive literals P (t) by P ct (t) and all negative literals P (t) by P cf (t), and let cf [x] be
the formula ([x])ct .
An interesting property of the formulas ct and cf is that they do not contain negations.
Also, the following proposition is well-known.
Proposition 2.1 (Feferman, 1984). For every -formula  and interpretation I, it holds
 I p t if and only if [d]
 +IJ = t if and only if (ct [d])
 I tf = t. Also, [d]
 I p f
that [d]
tf
+JI
cf
I


if and only if [d]
= f if and only if ( [d])
= t.
2.2 FO(ID)
In this subsection we recall FO(ID) (Denecker & Ternovska, 2008), the extension of FO
with a construct to respresent some of the most common forms of inductive definitions,
such as monotone induction, induction over a well-founded order or iterated induction. As
illustrated by Denecker and Ternovska, FO(ID) can be used to represent different sorts
of common knowledge, such as temporal and dynamic domains, the closed world assumption, defaults, causality, etc. In this paper, we use definitions to symbolically represent
propagation, not only for FO formulas, as already mentioned in the introduction, but also
propagation for inductive definitions themselves.
A definitional rule over a vocabulary  is an expression of the form x P (t)   where
P (t) is an atomic formula and  an FO formula. The symbol  is a new connective, called
the definitional implication, to be distinguished from the FO material implication symbol
 (or its converse ). A definition  is a finite set of definitional rules. A predicate
symbol P in the head of a rule of  is called a defined predicate; all other predicate and
function symbols in  are called the open symbols or the parameters of the definition; the
set of defined predicates is denoted Def (), the remaining symbols Open() (note that
Open() therefore also includes F ).
Given an interpretation for its open predicates, each definition will have a unique model,
that can be constructed by firing its rules in an appropriate order. Before defining this
formally, we first consider an example.
Example 2.1. Reachability in a graph is not expressible in FO. That is, there is no FO
formula  over the vocabulary consisting of two predicates Edge/2 and Reach/2 such that
in any model M of , (d1 , d2 )  ReachM iff there is a non-empty path from d1 to d2 in the
85

fiVlaeminck, Vennekens, Denecker & Bruynooghe

graph represented by EdgeM . We can represent reachability with an inductive definition
however. The following definition defines the predicate Reach in terms of the open predicate
Edge.
(
)
xy Reach(x, y)  Edge(x, y).
xy Reach(x, y)  z(Reach(x, z)  Reach(z, y)).
O ). With a definition  and a given Open()-interpretation O,
Definition 2.4 (Operator T
O on two-valued Def ()-interpretations
we define the immediate consequence operator T
O
such that T (I) = J iff for each defined predicate P/n and tuple d  Dn , it holds that
 = t iff there exists a rule x P (t)  [x], such that t(O+I) = d and (O+I) [d]
 = t.
P J (d)

The model of a positive definition (i.e., no defined predicates occur negatively in the
body of rules) can be defined as the least fixpoint of this immediate consequence operator.
We use M odI|Open() () to denote the model of the definition  extending the restriction
of I to the open predicates and function symbols of . When  has no open predicates,
we omit the subscript and simply use M od(). We postpone going into more detail about
how to construct the model of a general (non-monotonic) inductive definition until Section
5. In the next two sections, we only use positive definitions.
FO(ID) formulas are inductively defined by the same rules as standard FO formulas,
augmented with one extra case:
 A definition  over  is an FO(ID) formula (over )).
Note that rule bodies do not contain definitions, and that rules only occur inside definitions
and are not FO(ID) formulas themselves whereas definitions can be used in FO(ID) formulas
anywhere atoms can be used.
We can now define the satisfaction relation I |=  of FO(ID) using the standard inductive
rules of FO, augmented with one extra rule:
 I |=  if I = M odI|Open() (),
From now on, we assume without loss of generality that for any definition , it holds that
every defined predicate P  Def () is defined by exactly one rule, denoted by x(P (x) 
P [x]). Indeed, any definition  can be brought into this form by a process similar to
predicate completion. The transformation consists of first transforming rules of the form
x(P (t)  ) into equivalent rules y(P (y)  x(y = t  )). Next, one merges all rules
of the form x(P (x)  i [x]) into x(P (x)  1 [x]  . . .  n [x]).

3. Propagation for FO
In this section we give a general, symbolic representation of propagation for first-order logic.
For this, we base ourselves on the work by Wittocx et al. (2010). We come back to the
precise relation between the material presented in this section and their work at the end of
this section.
Suppose we have an FO theory T in vocabulary , a pre-interpretation of , and a
finite three-valued interpretation I that represents some (incomplete) knowledge about the
86

fiAn Approximative Inference Method for SO

t (Clean(t + 1)  (Clean(t)  W ipe(t))).
t

A1
Act
1

Clean(t + 1)  (Clean(t)  W ipe(t))
t for t = 3

Clean(t + 1)
f for t = 3

A2 (t)
Act
2 (3)

Clean(t)  W ipe(t)
t for t = 3

Clean(t)
t for t = 3

A3 (t)
Act
3 (3)

Clean(t + 1)
Cleancf (4)

W ipe(t)
t for t = 3

Clean(t)
Cleancf (3)

W ipe(t)
W ipecf (3)

Figure 2: Propagation for FO.
predicates of . We would now like to know the implications of this knowledge, assuming
the theory T is satisfied in the context of I. To find this out, we can look at the set M
of all models of T that complete this three-valued interpretation, i.e., M = {M | M |=
T and I p M }. Given the partial information I, everything that is true in all M  M
must certainly be true according to T , while everything that is false in all such M must
certainly be false according to T . In other words, all the information that T allows us to
derive from I can be captured by the greatest lower bound G = glbp M.
In general, computing this greatest lower bound may be too expensive (the data complexity is in P2 ) to be of practical use. However, we may still achieve useful results by
computing some approximation M such that I p M p G. We can compute such an
approximation by propagating the three-valued interpretation I through the parse tree of
T . We illustrate this with the following example.
Example 3.1. Consider the sentence : t Clean(t + 1)  Clean(t)  W ipe(t). Rewriting
this into negation normal form, it becomes:
t Clean(t + 1)  (Clean(t)  W ipe(t)).
Now, assume that  is satisfied, and that we know that Clean is false at timepoint 4.
From the knowledge that  is satisfied, it immediately follows that, for all timepoints t,
the disjunctive formula Clean(t + 1)  (Clean(t)  W ipe(t)) is satisfied. Using the fact
that Clean is false at timepoint 4, we can now deduce that the conjunction (Clean(t) 
W ipe(t)) is true for timepoint 3. Therefore, in all models of  where Clean is false at
timepoint 4, W ipe and Clean have to be false at timepoint 3. This reasoning process is
illustrated on the left part of Figure 2.
We now construct a symbolic representation of this propagation process. First, we
introduce some additional vocabulary Aux to refer to the different nodes of the parse
tree on which this process operates. We then use this additional vocabulary to transform
an FO formula into an equivalence normal form formula. This is similar to the Tseitin
transformation (1968) for propositional logic.
Definition 3.1 (EN F ()). For an FO formula  in negation normal form, we introduce
a new predicate symbol A of arity n for each non-literal subformula [x] of  with n
87

fiVlaeminck, Vennekens, Denecker & Bruynooghe

free variables. We denote the set of these new predicates by Aux(). Each of these new
predicate symbols is defined by a formula Eq(A ) as follows. To make notation simpler
we assume that each 1 , . . . , n is a non-literal subformula. The definitions are analogous
whenever a i is a literal, but instead of Ai the literal i itself is used in the body of the
definition.
 If [x] is a subformula of the form 1 [x1 ]  2 [x2 ]  . . .  n [xn ], then Eq(A ) is
x (A (x)  A1 (x1 )  A2 (x2 )  . . .  An (xn )).
 If [x] is a subformula of the form 1 [x1 ]  2 [x2 ]  . . .  n [xn ], then Eq(A ) is
x (A (x)  A1 (x1 )  A2 (x2 )  . . .  An (xn )).
 If [x] is a subformula of the form y 1 [x, y], then Eq(A ) equals x (A (x) 
y A1 (x, y)).
 If [x] is a subformula of the form y 1 [x, y], then Eq(A ) equals x (A (x) 
y A1 (x, y)).
We define the equivalence normal form of  as the set of all such Eq(A ), and denote
it as EN F ().
Example 3.2. According to this definition, the EN F () theory from Example 3.1 is:
A1  t A2 (t).
t A2 (t)  Clean(t + 1)  A3 (t).
t A3 (t)  Clean(t)  W ipe(t).
This is illustrated in the right side of Figure 2.
Using the auxiliary vocabulary, we can now write down the propagations shown in
Figure 2 as the following implications.
A1
A2 (3)  Clean(4)
A3 (3)
A3 (3)






A2 (3).
A3 (3).
Clean(3).
W ipe(3).

Note that these rules are all top-down rules, that is, implications that propagate information
about a subformula down the parse tree, to a component of that subformula (possibly
using also information about other components of the subformula, as in the implication
A2 (3)Clean(4)  A3 (3)). In general, also bottom-up propagations are of course possible.
For instance, from Clean(4) we could derive A2 (3). For every predicate A , we can derive
from Eq(A ) a set of implications 1  2 , such that each such propagation corresponds
to deriving the consequent 2 from the antecedent 1 (so, different implications can be
logically equivalent). This is defined in Table 1. The last column of this table indicates
whether the rule is top-down (TD) or bottom-up (BU).
Definition 3.2 (IN F ()). Given an equivalence   EN F () for a certain formula , we
denote with Imp() the set of all implications obtained through Table 1.
S We define the implication normal form of , denoted by IN F (), as follows: IN F () = EN F () Imp().
88

fiAn Approximative Inference Method for SO

 = Eq(A )

Imp()

x (L  L1  . . .  Ln ).

x
x
x
x

(L1  . . .  Ln  L).
(Li  L).
(L  Li ).
(L  L1  . . .  Li1  Li+1  . . .  Ln  Li ).

1in
1in
1in

BU
BU
TD
TD

x (L  L1  . . .  Ln ).

x
x
x
x

(L1  . . .  Ln  L).
(Li  L).
1in
(L  Li ).
1in
(L  L1  . . .  Li1  Li+1  . . .  Ln  Li ). 1  i  n

BU
BU
TD
TD

x (L[x]  y L0 [x, y]).

x ((y L0 [x, y])  L[x]).
x(y L0 [x, y])  L[x]).
xy (L[x]  L0 [x, y]).
xy ((L[x]  z (y 6= z  L0 [x, y][y/z]))  L0 [x, y]).

BU
BU
TD
TD

x (L[x]  y L0 [x, y]).

x ((y L0 [x, y])  L[x]).
x(y L0 [x, y])  L[x]).
xy (L[x]  L0 [x, y]).
xy ((L[x]  z (y 6= z  L0 [x, y][y/z]))  L0 [x, y]).

BU
BU
TD
TD

Table 1: From ENF to INF

In the work of Wittocx et al. (2010) it is proven that models of  and models of IN F ()
where A is true correspond, in the sense that the restriction of a model of IN F ()  A
to  is also a model of , and vice versa, every model of  can be extended to a model
of IN F ()  A . These implications will form the core of our approximation method.
While our approximation could be made more complete by adding more implications to
IN F (), the above definition tries to strike a balance between completeness and the ease
of automatically deriving the implications.
Example 3.3. For each of the three formulas  in EN F () in Example 3.2, the following
table shows the corresponding set of implications Imp(). The complete theory IN F ()
consists of the union of these three sets.
A1  t A2 (t).
(t A2 (t))  A1 .
(t A2 (t))  A1 .
t (A1  A2 (t)).
t ((A1  t0 (t 6= t0
 A2 (t0 )))  A2 (t)).

t (A2 (t)  Clean(t + 1)  A3 (t)).
t (Clean(t + 1)  A3 (t)  A2 (t)).
t (Clean(t + 1)  A2 (t)).
t (A3 (t)  A2 (t)).
t (A2 (t)  Clean(t + 1)).
t (A2 (t)  A3 (t)).
t (A2 (t)  A3 (t)  Clean(t + 1)).
t (A2 (t)  Clean(t + 1)  A3 (t)).

t (A3 (t)  (Clean(t)  W ipe(t))).
t (Clean(t)  W ipe(t)  A3 (t)).
t (Clean(t)  A3 (t)).
t (W ipe(t)  A3 (t)).
t (A3 (t)  Clean(t)).
t (A3 (t)  W ipe(t)).
t (A3 (t)  W ipe(t)  Clean(t)).
t (A3 (t)  Clean(t)  W ipe(t)).

The reader can verify that the four implications representing the propagation in Example 3.1
all indeed belong to IN F ().
The propagation process in Example 3.1 can now be described as a least fixpointcomputation, where we apply the implications (i.e., infer the head when the body is
already inferred), until we no longer can infer any new information. We will represent this
fixpoint computation as an inductive definition in the syntax of FO(ID). However, there are
two complications.
89

fiVlaeminck, Vennekens, Denecker & Bruynooghe

First, in this paper, we do not always need all of the implications in IN F (). Indeed,
there will typically be some subset    of symbols about which we already know all there
is to know. In the conformant planning example, for instance, this will be the case for the
existentially quantified predicate W ipe/2, simply because we will use a model expansion
system to guess a complete interpretation for this predicate. The job of the propagation
process is then to figure out the consequences of each particular guess. For this, the implications with a predicate from  (i.e., W ipe/2) in their head are obviously not needed.
Second, the fixpoint computation not only needs to infer that atoms are true but also
that they are false. However, the syntax of FO(ID) does not allow negative literals in the
heads of rules. Therefore, our definition will not contain rules with the predicates P of the
original vocabulary  in their head, but will instead use predicates P ct and P cf from the
tf -vocabulary. Since we do not need rules with the fully known predicates  in the head,
we will only introduce these P ct and P cf predicates for those P that are in  \ . For a
ct
ct
given formula , we therefore define ct
 as the formula  (see Definition 2.3) but with P
cf
replaced by P and P by P for every predicate P  .
Definition 3.3 (Approx ()). For a formula  and   , we define Approx () as the
inductive definition that contains, for every sentence x (  L[x]) of IN F () in which L
ct
is a literal of a predicate not in , the definitional rule x(L[x]ct
   ). We also define
TD
ApproxBU
 () (and Approx ()) in the same way as Approx (), but only containing
definitional rules coming from the bottom-up (respectively, top-down) rules of IN F ().
We can often assume without loss of generality that  = . Whenever this is the case
we drop the  and use Approx() rather than Approx (), to denote the approximative
definition.
Example 3.4. Using the implications IN F () of Example 3.3, we obtain the definition
shown in Figure 3 for Approx(). If we take  = {W ipe}, we get the same definition for
Approx () as in Figure 3, apart from the last seven definitional rules that are replaced by
the following five definitional rules.


..




.






ct
cf


A
(t)

Clean
(t)

W
ipe(t).


3


 cf

ct
A3 (t)
 Clean (t).


 W ipe(t).
 Acf

3 (t)




cf
ct




Clean
(t)

A
(t).
3






cf
ct
Clean (t)  A3 (t)  W ipe(t).
In contrast with Approx() this definition no longer approximates the predicate W ipe. The
definition Approx () can be used to find out what certainly holds or not holds given a two
valued interpretation for the predicates in .
Example 3.5. For a larger example, we look again at the Example 1.1. Let us again take
 = act and  = {W ipe}. Then the definition Approx () can be found in the Appendix
A.
This approximative definition has some useful properties, which we formulate in the
next two theorems. The first property is that, when using the approximative definition
90

fiAn Approximative Inference Method for SO

 ct
A1



cf


A
1


ct


A2 (t)




Acf

2 (t)







Acf

2 (t)


ct

A

 2 (t)

ct


A2 (t)



Cleancf (t + 1)


 cf
A3 (t)
Cleanct (t + 1)




Act

3 (t)







Act

3 (t)


cf

A

3 (t)


cf


A
3 (t)


cf


Clean
(t)


cf


W
ipe
(t)




Cleanct (t)



W ipect (t)


 t Act

2 (t).




 t Acf
(t).
2


ct


 A1 .


cf
0
0
ct 0

 A1  t (t 6= t  A2 (t )).







cf
cf
 Clean (t + 1)  A3 (t). 



ct

 Clean (t + 1).



ct

 A3 (t).



cf


 A2 (t).



cf
 A2 (t).
cf

 Act
2 (t)  A3 (t).


ct


 A2 (t)  Cleancf (t + 1).






cf
cf

 Clean (t)  W ipe (t). 




 Cleanct (t).





 W ipect (t).




 Act
(t).
3




 Act
(t).
3


cf

cf

 A3 (t)  W ipe (t).



cf
cf
 A3 (t)  Clean (t).

A1
t
A2 (t)


A3 (t)

Clean(t + 1)



Clean(t)

W ipe(t)

Figure 3: Example of an approximative definition
together with an encoding of a three-valued interpretation I of the original vocabulary, we
can give an exact characterization of what the approximative definition computes. Indeed,
in this setting, ApproxBU () actually encodes the three-valued Kleene evaluation of  in
I. Moreover, adding the top-down rules does not change this, since they will not compute
actually anything, as long as only information about the original vocabulary is provided
as input. Before we can formally state this property, we need to define how we encode a
four-valued interpretation as a definition. From here on, we assume that for any vocabulary
 and -pre-interpretation I,  contains a constant symbol Cd for every domain element
d in the domain D of I, and that for the pre-interpretation I it holds that (Cd )I = d. This
allows us to identify Cd and d and therefore, abusing notation, we will use d to denote Cd
in what follows.
Definition 3.4 (I ). Given a four-valued -interpretation I, the definition associated to
I is denoted by I and is defined by
I

=

  t | P I (d)
 p t}
{P ct (d)
cf
I


 {P (d)  t | P (d) p f }

Theorem 3.1. Given a -formula  and a four-valued -interpretation I, the following
holds:
a) In the case that I is three-valued it holds that Approx()  I is logically equivalent
to ApproxBU ()  I , that is, M od(Approx()  I ) = M od(ApproxBU ()  I )
91

fiVlaeminck, Vennekens, Denecker & Bruynooghe

b) Let M be M od(Approx()  I ), v1 the truth value of Act
 in M and v2 be the truth
I
value of Acf
 in M , then (v1 , v2 ) corresponds to the four-valued truth value  , i.e.,
 I =  (v1 , v2 ).

Proof. See Appendix B.
In summary, what this theorem says is that, first of all, the approximation always
computes the four-valued Belnap evaluation of  in the four-valued structure I. Moreover,
this computation is done by the bottom-up rules of the approximation alone. If I is threevalued, then the top-down rules actually have no effect at all. If I is four-valued, then
they may still serve a purpose, however: once the bottom-up rules have derived that some
subformula is inconsistent, they can then propagate this information to derive that smaller
formulas are also inconsistent. To see this, consider the following formula P  Q, and take
for I the four-valued interpretation such that P = i and Q = t. Then one can verify that
cf
the bottom-up rules in Approx()  I will infer that both Act
P Q and AP Q are true.
However, now the top-down rules can also infer that Qcf has to be true.
In the theorem above the only information we add to the approximative definition is in
the form of the definition I , i.e., we only assert the truth, resp. falsity of domain atoms.
The following definition now allows us to assert the truth or the falsity of any grounded

subformula [d].
Definition 3.5 ( ). Given a -formula , a -pre-interpretation I, and a set  of
 such that [x] is a subformula of  of arity n and d  Dn where D is the
formulas ()[d],
domain of I, we then define  as follows:
cf 



 = {Act
 (d)  t | [d]  }  {A (d)  t | [d]  }.

If we assert in this way the truth (or the falsity) of a set of grounded subformulas ,
then we will obtain an approximation of everything that holds (respectively, does not hold)
in all models of . However, as opposed to the theorem above, the next theorem does not
give an exact characterization of the approximation we get.
Theorem 3.2. Given a -formula , a set  as defined above and a subformula 0 [x0 ] of
cf 0
0 0
0
. Let M be M od(Approx()   ). If M |= Act
0 (d ) (resp. A0 (d )), then  |=  [d ]
(resp.  |= 0 [d0 ]).
Note that an interesting special case of this theorem is where we take  equal to {} and
thus add Act
  t to Approx(). Then this definition gives an approximation of everything
that is certainly true resp. certainly false in all models of .
Returning now to the exact relationship between the work of Wittocx et al. (2010) and
the content of this section, we see that Wittocx et al. are only interested in this special
case, i.e., in approximating all models of a theory. For this reason their transformation
from a formula  to EN F () already includes a formula A  t, which will cause the rule
Act
  t to always be included in the approximating definition. All their soundness results
have also been formulated and proven in this setting. However, it is not difficult to see that
the proofs can be trivially adapted to a proof of Theorem 3.2 in the more general setting
used in this section.
92

fiAn Approximative Inference Method for SO

4. Approximating SO-Satisfiability Problems
We now use the approximate definition from the previous section to approximate the following problem. Take an SO formula F = P Q : . For ease of presentation, we
assume that the second-order formulas in this paper contain no free predicate symbols, but
all results generalize to the setting where there are free predicate symbols. We also assume
that Q contains only predicate symbols. In what follows, we denote the vocabulary of 
by . The question we want to answer is whether the formula F is satisfied in a given
finite-domain pre-interpretation I of the constant and function symbols of the formula.
This satisfiability problem boils down to deciding whether we can find a witness for the
satisfiability of this formula, in the following sense.
Definition 4.1 (Witness). We call J a witness for the satisfiability of a formula P Q : 
given a finite  pre-interpretation I, if J is an interpretation of  \ Q extending I (i.e., J
is an interpretation of the whole vocabulary without the universally quantified predicates)
such that Q :  is satisfied in J. Equivalently, J is a witness if in the three-valued  it holds that
interpretation J that expands J by assigning u to each domain atom Q(d),
svJ () = t.
Our goal in this section is now to approximate an SO satisfiability problems by an
SO satisfiability problem in the following sense.
Definition 4.2 (Sound approximation). Consider the SO satisfiability problem for a
formula P Q : , where  is an FO formula in alphabet . An SO(ID) formula of
the form P R :  0 , where  0 is an FO(ID) formula in the alphabet  \ Q  R, is a sound
approximation of this satisfiability problem if, whenever J is a witness for the satisfiability
of P R :  0 , then J|\Q is a witness for the satisfiability of P Q : .
In other words, a sound approximation G of the satisfiability problem for an SO
formula F is a stronger SO(ID) formula, i.e., one that has fewer witnesses for P .
4.1 A Naive Method
We can now use the results of Theorem 3.1 to construct a sound approximation for a given
SO formula.
Definition 4.3 (APP(F )). Given a formula F = P Q : . Take  to be the alphabet
of all function symbols in  and the predicates P . We define APP(F ) as the SO formula
tf
P R : Approx ()  Act
 in the vocabulary   R, where R = (Q  Aux()) .
The intuition here is that for any -interpretation I, Approx () will give the result
of the four-valued evaluation  I in the -interpretation I that expands I by assigning unknown to all universally quantified predicates Q. If the entire FO formula  evaluates to
true in this four-valued interpretation, we know that  will be satisfied in any  interpretation that expands I (in other words, for every interpretation of the Q predicates), and thus
that I is a witness for the satisfiability of the entire formula F . The auxiliary predicates
Aux()  introduced by the transformation to ENF  are needed because of the way in
which the propagation works, but their value is completely determined by that of P .
93

fiVlaeminck, Vennekens, Denecker & Bruynooghe

Proposition 4.1. For each SO formula F of the form P Q : , it holds that APP(F )
is a sound approximation of F .
Proof. This follows immediately from Theorem 3.1, where we take as three-valued inter I = u for all Q  Q and d  Dn , and
pretation, the interpretation I such that (Q(d))
 I = (P (d))
 I for all P  P and d  Dn , with D the domain of I.
(P (d))
For example, if we take F to be the formula P Q :  where  = P  Q, then APP(F )
becomes:
 ct

ct
A

P

Q






 Acf  P  Qcf 

cf
ct
cf
ct

P, Q , Q , A , A :
 Act
.
ct  Act  P
Q







 cf

Q  Acf

We start from an interpretation O of the open predicate P of the definition Approx{P } ().
Let us take the interpretation O that makes P true. The unique model I of the definition
ct
cf and
that extends O is then the interpretation that assigns true to Act
 and false to Q , Q
ct
Acf
 . Therefore, this I satisfies both Approx{P } () and A . Hence, it is a witness for the
satisfiability of APP(F ), and, indeed, it is also a witness for the satisfiability of the original
formula P Q : P  Q.
This approximation method is sound, but for many applications still too incomplete.
Indeed, let us look at the following formula: F = Q : Q  Q. Then APP(F ) becomes:



 Qct  Qcf 
Act






cf
cf  Qct 


A

Q






 Qct  Act  Qct 

cf

:
,
A
Qct , Qcf , Act
 Act

.
cf  Acf



Q






cf 


Qcf  Act


 Q




 Qct  Acf



The definition does not entail that Act
 , so APP(F ) is unsatisfiable, even though the original formula F is clearly always satisfied. The problem here is that, as we showed in the
previous section, the definition encodes the three-valued Kleene evaluation, which is not
strong enough to find out that the formula F is satisfied. To do this, we need the stronger
supervaluation.
Recall that in the preliminaries we saw that supervaluation and Kleene evaluation are
in general not equal. However, for some formulas  they are equal. In the literature, several
classes of formulas for which they agree have been proposed, e.g., in the context of locally
closed databases (Denecker et al., 2010), or in the context of reasoning with incomplete
first-order knowledge (Liu & Levesque, 1998). The latter introduces a normal form N F for
first-order formulas, for which the supervaluation coincides with the Kleene evaluation, and
proves for certain classes of formulas that they are in the normal form N F. One such class
is that of all CNF formulas in which every two literals are conflict-free: a pair of literals
is conflict-free if they either have the same polarity, or they use different predicates, or
they use different constants at some argument position. It immediately follows that our
94

fiAn Approximative Inference Method for SO

approximation is complete for SO formulas in which the first-order formula satisfies this
condition.
Proposition 4.2. Each SO formula F of the form P Q : , where  is in the N F
normal form (according to Liu & Levesque, 1998) is satisfiable with respect to a given finite
pre-interpretation I if and only if the SO-formula APP(F ) is satisfiable w.r.t. I.
Proof. This follows immediately from the results by Liu and Levesque and Theorem 3.1.
4.2 A More Complete Method
Unfortunately, many applications give rise to formulas in which the first-order part falls
outside the class N F, which means that completeness of our method is not guaranteed.
Particularly troublesome in practice are formulas of the common form P Q : 1  2 .
For such formulas, the naive approximation method of the previous section tries to find
interpretations for P such that the implication  = (1  2 ) holds for all Q. However, if
we look at the details of the approximative definitions, we find that Act
 is defined by a rule
cf
ct
with a body 1  2 . In other words, the approximation will only derive that  holds for
all Q if it is either the case that 1 is false for all Q or that 2 is true for all Q. However,
this will rarely be the case. In most practical applications, the witnesses of interest will
typically satisfy the implication 1  2 not because they always falsify 1 or always
satisfy 2 , but rather because each interpretation for Q that satisfies 1 also satisfies 2.
For instance, in the conformant planning example, there will always be interpretations for
the fluents that do not satisfy the action theory act , because they arbitrarily assign some
fluent a value that is wrong for its initial value and the actions that are performed. Even if
a set of actions is a completely correct conformant plan, it therefore cannot make the goal
certainly true, because it will still be unsatisfied in some of these wrong interpretations of
the fluents. Of course, this should not bother a good method for finding conformant plans.
The only thing that should matter is that the goal is satisfied in those interpretations of
the fluents that do satisfy the action theory.
Luckily, our approximation method can also be used to discover this kind of witnesses.
The only thing that is required is to add to the approximative definition  = Approx ()
a rule Act
1  t. By doing do, we seed our approximation with the assumption that 1
holds. Starting from this assumption, the top-down rules will then derive properties of
the predicates Q that are shared by all interpretations for Q that actually satisfy 1 . The
bottom-up rules will then propagate this information upwards and discover whether these
properties suffice to ensure that 2 also holds. If they do, then we know that 2 indeed
must hold in every interpretation for Q that satisfies 1 and that we therefore have found
a witness for our formula.
If we want to find both witnesses of this kind and degenerate witnesses that either make
1 false for all Q or 2 true for all Q, we could simply combine our new method with the old
ct
ct
one and check either whether Act
2 holds according to   {A1  t} or whether A holds
according to just  itself. However, it turns out that this is not necessary: we can achieve
ct
the same effect by just checking whether   {Act
1  t} implies A . This is because, first,
ct
the definition   {Act
1  t} will be able to derive A whenever  itself can: if  can
ct
ct
derive that A2 then   {A1  t} will obviously still be able to do so; if  would be
95

fiVlaeminck, Vennekens, Denecker & Bruynooghe

ct
able to derive that Acf
1 , then   {A1  t} will also be able to do so, simply because
our approximation has no flow of information between the ct and cf variants of the same
formula, so the additional assumption that Act
1 holds will not change the original derivation
ct
ct
ct
of Acf
1 . Second, if   {A1  t} can derive A2 , then it also derives A , simply because
cf
ct
it contains the rule Act
  A1  A2 . Therefore, we can find both kinds of witnesses by
ct
checking whether Act
 is implied by the single definition   {A1  t}.

Definition 4.4 (APP  (F )). For an SO formula F = P Q : , where  is of the
 is the definition
form 1  2 , we define APP  (F ) as P R :   Act
 , where 
ct
Approx (1  2 )  {A1  t}.
Note that we obtain Definition 4.3 as a special case when taking the trivial formula t
for 1 . This approximation method is still sound, as the following proposition states.
Proposition 4.3. Given a formula F of the form P Q : , where  = 1  2 , the
SO(ID) formula APP  (F ) is a sound approximation of F .
Proof. See Appendix C.
Since the approximative definition  in APP  (F ) contains all the rules of Approx(F ),
it is not hard to see that this new approximation method is at least as complete as the one
using APP(F ) (Definition 4.3). Moreover, as can be seen from the following example, it is
also strictly more complete.
Example 4.1. Let us consider the following formula F = P Q : (Q  P )  Q. We have
that P = t is clearly a witness for this satisfiability problem. If we denote (Q  P )  Q
by 1 and (Q  P ) by 2 , then APP(F ) is the following SO formula.

Act

1


cf


A



 ct1
A2
P R :

Acf
2



ct

Q


 cf
Q








ct
Acf
2  Q
ct
A2  Qcf
P  Qct
P  Qcf
Act
2  P
Acf
2











 Act
1 .










Now, even for P = t, the definition in the body of this formula will not entail Act
1 = t.

Therefore, APP(F ) is not satisfiable. On the other hand, APP (F ) is the same formula
as above, apart from that the definition contains one more rule, that is, the rule Act
2  t.
It is easy to verify that APP  (F ) is satisfiable, and indeed has P = t as a witness.
Obviously, the new method is still complete on formulas 1  2 , where 1  2
satisfies the normal form N F. However, our method also works for many formulas outside
this class. Unfortunately, it is difficult to characterize precisely how much more complete the
new method is. For instance, one source of loss in completeness comes from the fact that our
current translation to ENF cannot recognize multiple occurrences of the same subformula,
and will introduce a different Tseitin predicate for each occurrence. Even though we cannot
96

fiAn Approximative Inference Method for SO

guarantee completeness for our method in general, we always found all solutions in the
conformant planning benchmarks we considered in Section 6.
A final remark about this method is that the approximative definition Approx (1 
2 ) contains a number of rules that are superfluous in our context. Indeed, with our method,
this definition takes as its input an interpretation for P together with the assumption that
1 is certainly true. It then uses the bottom-up and top-down rules derived from 1 to
compute the effect of these inputs on the predicates Q. Finally, the rules derived from 2
then compute whether the derived information about Q suffices to make 2 certainly true.
However, as we know from Theorem 3.1, only the bottom-up rules for 2 are needed for
this. Therefore, the top-down rules for 2 actually contribute nothing and could just as

TD
well be removed. Adapting Definition 4.4 to use 
BU =  \ Approx (2 ) instead of

 leads to the following definition.
Definition 4.5 (APP 
BU (F )). For an SO formula F = P Q : , where  is of the
ct

form 1  2 , we define APP 
BU (F ) as P R : BU  A , where
TD
ct

BU = Approx (1  2 ) \ Approx (2 )  {A1  t}.

It follows directly from Theorem 3.1 and Proposition 4.3 that this too is a sound approximation. Having removed the top-down rules from the approximation of 2 , the remaining
rules just serve, as we already know, to compute the Kleene evaluation of 2 . They do
this by computing the Kleene evaluation of each subformula  of 2 , for which they use
pt
the Tseitin predicates Act
 and A . An alternative is to avoid these Tseitin predicates by
defining Act
2 directly by the single rule:
ct
Act
2  (2 )

This variant is summarized in the following definition.
Definition 4.6 (APP 
BU,U nf (F )). For an SO formula F = P Q : , where  is
ct

1  2 , we define APP 
BU,U nf (F ) as P R : BU,U nf  A , where
ct
ct
ct

BU,U nf = Approx () \ Approx (2 )  {A2  (2 ) }  {A1  t}.

This approximation is actually equivalent to that of Def. 4.5. This follows from the
fact that all bottom-up rules for 2 are positive and non-recursive, which allows us to
eliminate the Tseitin predicates introduced for the parse tree of 2 by applying the unfolding
procedure from Tamaki and Sato (1984). By iteratively applying this equivalence preserving
procedure, we can reduce all the rules that were generated to approximate 2 to just the
ct
single rule Act
2  (2 ) .

5. Approximating SO(ID)-Satisfiability Problems
Inductive definitions are important for knowledge representation. As argued by Denecker
and Ternovska (2008), inductive definitions are not only used to represent mathematical
concepts, but also the sort of common sense knowledge that is often represented by logic
programs, such as dynamic domains, the closed world assumption, defaults, causality, etc.
97

fiVlaeminck, Vennekens, Denecker & Bruynooghe

Therefore, inductive definitions can make the task of representing a problem in logic considerably easier. An example of this is the use of inductively defined Situation Calculus for
reasoning about actions (Denecker & Ternovska, 2007). Recall that in the introduction we
showed how to represent Tact from Example 1.1 as an inductive definition act :


 Clean(t + 1)  Clean(t).

Clean(t + 1)  W ipe(t).
.


Clean(0)
 InitiallyClean.
The associated conformant planning problem can then be expressed as an SO(ID) satisfiability problem:
W ipe Clean, InitiallyClean : act  Clean(n).
As we will show in more detail in Section 7, a general conformant planning problem can
be seen as a satisfiability problem of the form
 F : (act  init )  (prec  goal ),
AI
where the predicates A represent the actions, I the initial fluents and F the other fluents.
The definition act defines how the fluents change in terms of the action, init is a first
order formula about the initial situation, prec describes the preconditions of the actions
and goal the goal. This motivates the extension of our approximation method to formulas
including definitions. However, we do not analyze the general case where definitions may
appear at arbitrary locations in a formula, but instead restrict attention to formulas of the
form
P Q : (  1 )  2 ,
where  is a definition such that Def ()  Q and 1 and 2 are FO formulas. Even
though these restrictions are not strictly necessary, they allow us to keep the technical
details relatively simple (in particular, we avoid the need for approximation rules that infer
that a definition as a whole is certainly true/false), while still covering the way in which
definitions are typically used: under the assumption that all predicates indeed are what the
definition  and the formula 1 say they should be, 2 then states what properties they
should satisfy.
To extend our approximative method to (  1 )  2 satisfiability problems, we
need a syntactic representation (i.e., an approximative definition) that describes sound
inferences that can be made from the definition in a three-valued context. In this section
we propose two ways to obtain such an approximative definition, and accordingly, two ways
to approximate (  1 )  2 satisfiability problems. Before we can continue, we first
need to recall some more preliminaries.
5.1 Preliminaries on the Well-founded Semantics for Inductive Definitions
Earlier, we defined the model of a positive inductive definition given a two-valued interpretation for the open predicates. From here on, the inductive definitions are no longer only
positive definitions, so the model of a definition can no longer always be computed as the
least fixpoint of the immediate consequence operator introduced in Section 2. Moreover,
98

fiAn Approximative Inference Method for SO

in what follows we want to use inductive definitions together with four-valued information
about the open predicates (for example, information obtained through propagation on a
first order theory). Therefore, we now recall (see, e.g., Denecker & Ternovska, 2008) how to
define the well-founded model of a non-monotone inductive definition  (that is, negation
in the body of rules is allowed), given some four-valued information O about its open predicates, which we denote by W F MO (). In order to do this, we first need to define some
additional concepts. Recall that P denotes the body of the unique rule with predicate P
in the head.
Definition 5.1 (Operator TO ). For a definition  and a given (potentially 4-valued)
Open()-interpretation O, we define the operator TO on 4-valued Def ()-interpretations
with the same domain as Open() such that TO (I) = J iff for each defined predicate P/n
and n-tuple d  Dn , it holds that
 = O+I [d]

P J (d)
P
Recall that in the preliminaries we defined the isomorphism  that maps a pair of
interpretations (I, J) to the corresponding four-valued interpretation I.
Definition 5.2 (W F MO ()). We define the well-founded model of  in O as the 4-valued
O,
interpretation  (I, J) such that (I, J) is the maximal oscillation pair of the operator ST
O
O
where ST is the operator J(lf p(K(T (K, J)1 )). I.e., (I, J) is the least precise pair of
2-valued interpretations such that
O
O
I = ST
(J) and J = ST
(I).

Some explanation is in order. First look at the operator K(TO (K, J)1 ). This operator takes a Def ()-structure K, turns it into a 4-valued one by combining it with J,
applies the operator TO , and projects the result on its first argument. We can see that
K(TO (K, J)1 ) = L iff for each defined predicate P/n and n-tuple d  Dn , it holds that
 = t iff (P [d])
 +(O1 +L)(O2 +J) = t
P L (d)
In other words, positive occurrences of atoms are evaluated in O1 + L, negative occurrences
in O2 + J. For each J, this operator K(TO (K, J)1 ) is monotone, and therefore has a
O now maps J to this least fixpoint. It can be proven that
least fixpoint. The operator ST
this operator is antimonotone, and therefore has a maximal oscillation pair. The definition
O is a nonof the well-founded model as the maximal oscillation pair of the operator ST
constructive definition. This maximal oscillation pair can be constructed by iterating the
following operator, starting from the least precise interpretation I that extends O, until it
reaches its least fixpoint.
O
Definition 5.3 (Stable operator ST O
 ). We define the operator ST  on pairs of interpretations as:
O
O
ST O
 (I, J) = (ST (J), ST (I)).

The stable operator is monotone w.r.t. the precision order p on pairs of interpretations
and its fixpoints therefore form a complete lattice. The fixpoints of this operator are called
99

fiVlaeminck, Vennekens, Denecker & Bruynooghe

the four-valued stable fixpoints of , and the least precise of these fixpoints is precisely the
well-founded model of  given O.
We can now define the semantics of inductive definitions in the general case. The
reader can easily verify that this indeed generalizes the definition of M odO () for positive
definitions we gave in Section 2.2.
Definition 5.4 (Satisfaction relation for definitions). I |=  iff (I|Def () , I|Def () ) is the
well-founded model of  in I|Open() .
Note that when the definition  has a three-valued well-founded model for every possible
interpretation of the open predicates Open(), the definition has no model (i.e. there
does not exists an interpretation I such that I |= ). We call a definition total if it has
a two-valued well-founded model for every possible two-valued interpretation of its open
predicates.
The above definitions generalize in a rather obvious way the standard well-founded
semantics of propositional logic programs and are strongly linked to the stable semantics (Gelfond & Lifschitz, 1988). In the case of a propositional logic program , where
Open() = {}, the operator K(T (K, J)1 ) is nothing else than the immediate consequence operator TJ of the Gelfond Lifschitz reduct J of , and the operator that maps
J to lf p(K(T (K, J)1 ) is the stable operator of . As shown by Van Gelder (1993), its
maximal oscillation pair is indeed the well-founded model of .
5.2 Approximating SO(ID)-Satisfiability Problems
Assume we have a formula , where  is an FO(ID) formula instead of an FO. The
concepts of witness (Definition 4.1) and sound approximation (Definition 4.2) can straightforwardly be generalised for  being a FO(ID) formula. This allows us to develop two
approaches. The first one, in Section 5.2.1, replaces the definition by its completion and
then applies the method of Section 4. However, the completion can be weaker than the
definition. Therefore, in Section 5.2.2, we develop another approach that constructs an
approximation for the conjunction of a definition with a FO formula.
5.2.1 Using the Completion of a Definition
Our first approach is based on the use of the completion (Clark, 1978). The completion
of a definition  is the conjunction of the equivalences x P (x)  P (x) for all predicates
P  Def (), where P (x) is the body of the unique rule with P in its head. A useful
property is that each definition  implies its completion compl(). Moreover, if  is nonrecursive, then the two are actually equivalent. Replacing the definition by its completion
in (  1 )  2 we obtain the formula (comp()  1 )  2 . As every model of  is
a model of comp(), every model of (comp()  1 )  2 is a model of (  1 )  2
and every witness of the  (compl()  1 )  2 satisfiability problem is a witness of the
 (  1 )  2 satisfiability problem. Hence we can use the results of Section 4 and
formulate the following proposition.
Proposition 5.1. The formula APP 
BU ((compl()  1 )  2 ) is a sound approximation
of P Q(  1 )  2 .
100

fiAn Approximative Inference Method for SO

The disadvantage of using the completion is that no matter how complete the approximation method defined in Definition 4.4 is, it will never be able to infer something that
follows from  but not from compl(). For instance, the inductive definition {P  P }
entails P , but its completion P  P does not.
Denecker and Ternovska (2008) have proven that, in addition to non-recursive definitions, a class of recursive definitions are equivalent to their completion. In particular, this
is the case for definitions over a strict well-founded order 2 . We can therefore replace
those definitions by their completion without losing precision. The theory Tact in Example
1.1 is actually the completion of the definition act . Since act is a recursive definition
over a strict well-founded order (we can make use of the time argument in the predicates
to construct such a well-founded order), act and Tact are equivalent.
The Gaspipe conformant planning problem (Son et al., 2005), on the other hand, uses
a dynamic domain for which the completion does not suffice. Summarized, the objective
of this conformant planning problem is to start a flame in a burner which is connected to
a gas tank through a pipe line. The pipe line consists of sections connected to each other
with valves. When a valve is opened with gas on one side and not on the other, the gas
will spread as far as possible. This can be formalized by an inductive definition of the
reachability relation on the pipe line:
(
)
x, t Gas(x, t)  y Gas(y, t)  v Connected(x, y, v)  Open(v, t).
x, t Gas(x, t)  T ank(x).
Such reachability definitions are not equivalent to their completion. Therefore, the approximative method presented in this subsection will not work. The problem with the completion
in this case is that it does not correctly minimize the defined predicates in the presence of
recursion, which would allow models in which a loop in the pipe line is filled with gas even
when it is not connected to a tank. What is missing, therefore, is the unfounded set reasoning that allows the well-founded semantics to correctly minimize the defined predicates.
5.2.2 Using a Certainly True/Possibly True Approximation
The approximative definition Approx () used in Section 4 has the nice property that it
defines, for each subformula of  (including  itself), whether it is certainly true or certainly
false. It was this property that allowed us to find witnesses by simply asserting that Act

had to hold according to this definition. If we want to apply the same method to formulas
 that contain a definition , we have to construct an approximative definition that defines
whether each of the subformulas of  (including  itself) is certainly true or certainly
false. In Section 5.2.1, our naive method managed to do this by simply replacing  by its
completion. We now want to improve on this method by constructing an approximation that
also takes into account the unfounded set reasoning that is performed by the well-founded
semantics.
Once we also take this aspect of the well-founded semantics into account, however,
it becomes difficult to define when a definition as a whole is certainly true or certainly
false. Luckily, this is not needed if we stick to our assumption that definitions appear only
in the antecedent of the implication . Indeed, because we approximate implications by
2. An order < is well-founded if there are no infinite descending chains . . . < xn < xn1 < . . . < x1

101

fiVlaeminck, Vennekens, Denecker & Bruynooghe

assuming that their antecedent is certainly true (Definition 4.4), all that we really need
is an approximation of the consequences of a definition. To this end, we will transform
the original definition  into an approximative definition 0 such that the well-founded
model of 0 , given an approximation O of the open predicates of , approximates each
of the well-founded models of  given an interpretation O for the open predicates that is
approximated by O. In other words, we construct an approximative definition 0 whose
two-valued well-founded model encodes the potentially four-valued well-founded model of
the original definition , given a potentially four-valued interpretation for the predicates of
. We therefore again represent a four-valued interpretation of the orginal vocabulary  of
 by a two-valued interpretation of a larger vocabulary 0 . However, instead of introducing,
for each predicate P of , a predicate P ct (P is certainly true) and P cf (P is certainly false),
as we did before, we now introduce predicates P ct and P pt (P is possibly true, i.e., P is not
certainly false). Let ct/pt denote this vocabulary F  {P ct | P  }  {P pt | P  }. For
a four-valued -interpretation I, we define the corresponding ct/pt -interpretation I ct/pt
ct/pt
as the interpretation with the same pre-interpretation as I such that (P ct )I
= {d |
ct/pt
I
pt
I
I



P (d) p t} and (P )
= {d | (P (d) p t)}.
Also, for a -formula , we define the formula ct/pt as the formula that we obtain after
replacing all positive occurrences of a predicate P in  by P ct , and all negative occurrences
by P pt , and finally reducing to negational normal form. It is easy to see that ct/pt can also
be obtained from ct by replacing, for every predicate P , all occurrences of P cf by P pt .
Unlike ct , ct/pt is not always a positive formula as it can contain negations. In particular,
P ct occurs only positively while P pt occurs only negatively. For a subvocabulary   ,
ct/pt

again denotes ct/pt but with both P ct and P pt replaced by P for every predicate
P  . Again, in what follows we will use  to denote predicates that do not need to be
approximated because we have two-valued information about them.
ct/pt

ct/pt

Definition 5.5 (App ()). For a definition , we define App
{Rct  Rpt } where Rct consists of the rules

() as the definition

x(P ct (x)  ct/pt
)

and Rpt consists of the rules
x(P pt (x)  ()ct/pt
)

for every definitional rule x (P (x)  ) in .
We again assume for the rest of this paragraph without loss of generality that  is empty,
ct/pt
and we drop it in the notation of App .
Example 5.1. Consider the following inductive definition.


B  B  A
A  D
Assume  = {}. Then

Appct/pt

 ct
B


 ct
A
=
pt
B


 pt
A





102

B ct  Apt
Dpt
B pt  Act
Dct









.

fiAn Approximative Inference Method for SO

We see that for a three-valued interpretation {D = u}, which translates to {Dct = f , Dpt =
t}, the approximative definition will correctly infer that B ct is false and B pt is true. If we
take {D = f } as an interpretation for the open predicate D, we see that the approximative
definition correctly infers that both B ct and B pt are false. This is an example of unfounded
set reasoning: once A is known to be true, the approximation detects that B could only be
derived from B itself and therefore must be false. This kind of reasoning could not be done
by our previous, completion-based approximation method, since it is only sound w.r.t. the
semantics of the definition itself, and not w.r.t. its weaker completion.
This example also demonstrates why we have to use the vocabulary ct/pt instead of
ct/cf , since the latter would have yielded a definition:
 ct

B
 B ct  Acf 



 ct

A
 Dcf
.
B cf  B cf  Act 



 cf

A
 Dct
For {D = f }, this definition would fail to infer B cf . Intuitively, the reason for this is that
the unfounded set reasoning of the well-founded semantics tries to minimize the extension
of the defined predicates by making as many atoms false as possible. Using the ct/cf
vocabulary, the well-founded semantics of the approximating definition therefore attempts
 as possible, which actually corresponds to maximizing the
to falsify as many atoms P cf (d)
possible extension of the original predicates P , instead of minimizing it as the well-founded
semantics of the original definition does.
Each two-valued interpretation of the double vocabulary ct/pt corresponds to a fourvalued interpretation of the original vocabulary . We again want to establish a link
ct/pt
between the well-founded model of the original definition  and that of App . A complict/pt
cating factor here is that, as the above example shows, the definition App
is no longer
monotone and therefore it is no longer guaranteed to have a two-valued well-founded model.
Because a three-valued interpretation of ct/pt no longer corresponds to even a four-valued
interpretation of the original vocabulary , we can only prove such a correspondence if the
ct/pt
well-founded model of App
is two-valued.
Theorem 5.2. Let O be a four-valued interpretation for the open predicates of a definition
. Appct/pt () has a two-valued well-founded model given Oct/pt if and only if  has a
unique four-valued stable fixpoint given O. Moreover, if Appct/pt () has a two-valued wellfounded model I, then the unique four-valued stable fixpoint of  is the unique interpretation
I for which I ct/pt = I.
Proof. See Appendix D.
This theorem requires that  has a unique four-valued stable model for each four-valued
input interpretation O. This is a stronger requirement than the more common condition of
totality, which only requires a definition to have a two-valued well-founded model given a
two-valued input interpretation O. As the following example shows, this stronger condition
is indeed necessary.
103

fiVlaeminck, Vennekens, Denecker & Bruynooghe

Example 5.2. Consider the following definition:




 A  B.

B  A  C.




C  O  O.
This definition is total, because, for each two-valued interpretation for the open predicate
O, it has ({A}, {A}) as its two-valued well-founded model. However, for the three-valued
interpretation ({}, {O}) (i.e., O is unknown) for the open predicate O, the three-valued
well-founded model ({}, {O, A, B, C}) is not the unique three-valued stable fixpoint, since
({A}, {O, A, C}) is also such a fixpoint. And indeed, we find that
 ct
A





B ct



 C ct
ct/pt
App
() =

Apt



 B pt



 pt
C

 B pt .






 Apt  C ct . 


ct
pt 
 O  O .

 B ct .



ct
pt 
 A  C . 


pt
ct 
 O  O .

does not have a two-valued well-founded model given {Opt }. The easiest way to see this is
to fill in the fact that we know that Opt is t and Oct is f and propagate this information:
 ct

A  B pt .






ct
pt
ct



B  A  C .






 C ct  f  t.



Apt  B ct .








pt
ct
pt


B

A

C
.




 pt

C  t  f .

 ct

A  B pt .






ct
pt



B  A  f .









 ct

A  B pt .


















 ct

A  B pt .




















Apt  B ct .








pt
ct


B

A

t.




 pt

C 


Apt  f . 







pt
ct 


B

A
.




 pt

C 



Apt 








pt
ct


B

A
.




 pt

C 

So, we are left with a loop over negation, which means that Act and B pt will remain unknown
in the three-valued well-founded model ({Apt , C pt }, {Act , Apt , C pt , B pt }) of the definition.
By computing the three-valued well-founded model of  given O, the approximative definition Appct/pt () can produce more precise results than the approximation of compl();
in particular it can detect that atoms in an unfounded set must be false, as illustrated in
Example 5.2 above. To use Appct/pt () in an approximation of an ()  2 -problem,
we still need to show how it can be combined with the approximation Approx () of  to
produce a sound approximation of   . To do this, we need to combine one definition of
ct/cf-predicates with another definition of ct/pt-predicates. We achieve this by first merging
the two definitions and then adding rules that copy information from the one vocabulary
to the other.
104

fiAn Approximative Inference Method for SO

Definition 5.6 (D ). Given a vocabulary , a subvocabulary   , an inductive
definition  and first-order formula . We define D as the following inductive definition.
ct/pt

App

{Ocf

()

Approx ()  {Act
  t}

{Opt  Ocf | for every predicate O  Open() \ }

{P cf  P pt | for every predicate P  Def () \ }

ct
 f , O  f | for every predicate O  Open() \  that does not occur in }

This definition indeed contains both the rules from the approximation of  and the rules
from the approximation of , that is, Appct/pt () and Approx()  {Act
  t}, respectively,
but also a number of extra rules that make a connection between these two approximations.
To approximate a defined predicate Q the approximation of  uses the pair of predicates
Qct and Qpt while the approximation of  uses Qct and Qcf . Hence, a number of extra
rules are needed to transfer information between the predicates Qpt and Qcf . The rules
{Opt  Ocf } transfer information that the approximation of  has derived about the
truth of an open predicate O (by means of Ocf ) to the corresponding predicate Opt of the
approximation of the definition. The rules {P cf  P pt } in turn propagate information
derived about the truth of a defined predicate in the approximation of the definition to the
corresponding predicate P cf of the approximation of . Finally, the rules {Ocf  f , Oct 
f } make sure that Ocf and Oct are defined atoms (instead of open ones) and that their
default value is u. The following proposition relates the well founded model of D with
the models of   .
Proposition 5.3. Given a vocabulary , a subvocabulary  and an FO(ID) formula   .
 (resp. P cf (d)),
 then it holds
Then, for every -interpretation I, if W F MI (D ) |= P ct (d)
 (resp. M |= P (d)).

for every model M of    extending I that M |= P (d)
Proof. See Appendix E.
This proposition is the analogue for inductive definitions of the result that Theorem 3.2
states for FO formulas. One difference between the two results is that the above proposition always assumes that the definition  itself holds, while Theorem 3.2 makes no such
assumption about the FO formula  that is approximated. As discussed in the beginning of
this section, this restriction is not a problem, because of the way in which we approximate
implications and because we only allow definitions to appear in the antecedent. A second
difference is that Theorem 3.2 applies to arbitrary subformulas  of , while the above
 It is, however, an easy corrolary of this proposition
proposition only considers atoms P (d).
that the result in fact holds for each formula  that contains only predicates defined by
 (or  cf (d)),
 then for every model M of   
D , i.e., whenever W F MI (D ) |=  ct (d)
 (resp. M |= (d)).

extending I, it holds that M |= (d)
We introduced the approximation Appct/pt () with the aim of being more complete than
the completion-based approximation. As long as only a single definition  was considered
105

fiVlaeminck, Vennekens, Denecker & Bruynooghe

in isolation, we succeeded in this goal. However, now that we have also incorporated the
additional formula , this is no longer the case. For instance, consider the following FO(ID)
theory:

	
Q  P  Q.
Here, the approximation D cannot derive that P is certainly true, simply because the
ct/pt-approximation Appct/pt () does not contain rules for head-to-body propagation, i.e.,
there are no rules to infer something about the body of a definitional rule, given information
about its head. By contrast, the approximation of the completion does contain such rules
and therefore has no problems reaching this conclusion. This motivates us to not just use
D but to use D(compl()) instead. Because each definition implies its completion,
this is sound.
To obtain a sound approximation for an SO(ID) formula P Q  with  = ( 
)  2 , we now just need to plug in our approximation D(compl()) for  into a
suitable SO(ID) formula, similar to the one we defined in Definition 4.4 for an SO
formula P Q 1  2 . A small complication, however, is that, as discussed previously,
cf
our approximation of a definition does not define predicates Act
 and A that tell us when
the definition  as a whole is certainly true or certainly false. Therefore, we can no longer
use our normal approximation of when the entire implication  is certainly true. Before
we present the approximation for SO(ID), let us first introduce a reformulation of our
original approximation for SO, that avoids the use of this Act
.
Proposition 5.4. For an SO formula F = P Q : , where  is of the form 1  2 ,
the approximation defined in Definition 4.4, i.e., the formula
ct
P R : (Approx (1  2 )  {Act
1  t})  A

is equivalent to
cf
ct
P R : (Approx (1 )  Appox (2 )  {Act
1  t})  (A1  A2 )

Proof. This is obvious from the fact that the difference between Approx (1  2 ) and
Approx (1 )  Appox (2 ) is precisely a set of rules that ensure that Act
 is equivalent to
ct
Acf
1  A2 .

Our approximation for SO(ID) now essentially consists of just replacing Approx (1 )
compl()
cf
 {Act
and Acf
 in the above form.
1  t} and A1 respectively by D
Proposition 5.5. Given an SO(ID) formula F = P Q (  )  2 . We define
APP wf (F ) as the following SO(ID) formula.
ct
P R : (Dcompl()  Approx (2 ))  (Acf
  A2 ).

Then APP wf (F ) is a sound approximation of F .
compl()

In some cases, the approximating D
instead of D will not gain us anything. For instance, consider an P Q(  )  2 problem, where  only contains open
predicates of  (as is the case for the conformant planning problems we consider in the next
106

fiAn Approximative Inference Method for SO

sections). In this case, we will never need head-to-body propagation, and therefore D
compl()
is just as complete as D
, and we are therefore better off using the former.
As was the case for our approximation method for SO , here as well not all rules from
the definition in APP wf are necessary. Indeed, only the bottom-up rules from Approx (2 )
are needed, and can be unfolded into a single rule. Therefore, below we define two more
variants of Definition 5.5.
Definition 5.7 (APP wf
BU (F )). Given an SO(ID) formula F = P Q (  )  2 .
wf
We define APP BU (F ) as the following SO(ID) formula,
cf
ct
P R : (Dcompl()  ApproxBU
 (2 ))  (A  A2 ),

and we define APP wf
BU,U nf (F ) as the following SO(ID) formula,
ct
cf
ct
P R : (Dcompl()  {Act
2  (2 ) })  (A  A2 ).

6. Experimental Evaluation
In this paper we have seen a number of methods to approximate SO and SO(ID)
satisfiability problems. In this subsection, we explore, through a number of experiments,
how we can use these methods to solve practically useful problems as fast as possible. We
performed these experiments on a number of conformant planning benchmarks from the
paper of Son et al. (2005). As we show in Section 7, all these benchmarks are of the
form F =   , where  is a stratified definition, and is therefore equivalent to its
completion. Therefore, F is equivalent to the SO formula  compl()  , which
we denote by F cp . All experiments were run on a dual core 2.4 Ghz CPU, 2.8 Gb RAM
Linux machine, using the IDP model expansion system for FO(ID) (Marien et al., 2006).
A time-out of twenty minutes was used.
A first question we want to answer is whether for these definitions, the completion
based approximation is faster than the ct/pt approximation. It is not hard to see that, even
though Approx(compl()) is linear in the size of the parse tree of compl(), this definition
may contain more rules than Appct/pt (), and moreover, these rules may contain a lot of
recursion. This can pose a challenge for current solvers, and suggests that it is likely to be
more efficient to use the ct/pt approximation for definitions. The first column in Table 2
shows times for using the completion of the definition , that is, APP  (F cp ), while for the
second column, the ct/pt-approximation of  was used, that is, APP wf (F ). As expected,
the ct/pt-approximation was consistently faster.
Table 2 also compares solving times of the full completion-based approximative definition
cp
(in the first column) with the approximation APP 
BU (F ) (Def. 4.5), from which the topdown propagation rules for  have been removed (third column). We see that in the BT
and BTC benchmarks we get an order of magnitude improvement. The fourth column of
cp
Table 2 shows timings for the unfolded approximation of 2 , APP 
BU,U nf (F ), in which the
intermediate Tseitin predicates have been removed (Def. 4.6). We see that this unfolding
consistently provides a speed-up.
These results suggest that combining the above techniques, that is, using the ct/pt
approximation for  and the unfolding of the bottom-up approximation of 2 together, will
107

fiVlaeminck, Vennekens, Denecker & Bruynooghe

APP  (F cp )

APP wf (F )

cp
APP 
BU (F )

cp
APP 
BU,U nf (F )

APP wf
BU,U nf (F )

BT(2,2)
BT(4,2)
BT(6,2)
BT(8,4)
BT(10,4)

0,151
3,404
38,93
-

0,109
3,493
14,76
-

0,115
0,312
0,876
32,91
-

0,065
0,153
0,409
1,774
-

0,031
0,064
0,113
0,462
1,643

BTC(2,2)
BTC(4,2)
BTC(6,2)
BTC(8,4)

0,210
-

0,131
-

0,171
40,081
-

0,116
8,408
-

0,037
0,109
0,335
41,894

0,390
1,101
6,597
31,275
-

0,026
0,036
0,067
0,120
0,231

0,507
1,250
8,995
42,583
-

0,473
1,266
6,997
28,387
-

0,049
0,052
0,128
0,396
1,530

7,023
-

0,374
-

5,217
-

2,792
-

0,100
0,358
6,650
193,290
2485

Problem

Domino(100)
Domino(200)
Domino(500)
Domino(1000)
Domino(2000)
Ring(2)
Ring(4)
Ring(6)
Ring(8)
Ring(10)

Table 2: The first column gives the name of the benchmark and the other ones different
execution times. The second column gives the execution time for the approximation of the
completion and the third for the cp/pt approximation. The fourth and fifth column use
variants of the completion approximation. For the fourth column, the top-down rules for
2 are removed while in addition, for the fifth column, the remaining bottom-up rules are
unfolded. The last column combines the cp/pt approximation with both other changes. -
means the execution was interrupted after 20 minutes.
give us the fastest way of approximating (  1 )  2 satisfiability problems. Indeed,
this is what formula APP wf
BU,U nf (F ) (Definition 5.7) does, and the results of this method
are shown in the last column of Table 2. As expected, this is by far the fastest method.

7. Applications and Related Work
In the literature, many examples can be found of approaches that perform some kind of
approximate reasoning about the models of a logical theory. Often, these approaches, which
are specific to the problem at hand, seem to boil down to an instantiation of the general
methods presented here. In this section we give some examples.
7.1 Conformant Planning
In general, a conformant planning problem is a planning problem in a non-deterministic
domain where the initial state may be not fully known. The goal is to come up with a
plan (i.e., a sequence of actions) that is nevertheless guaranteed to work. This is a hard
problem: the decision problem of deciding whether a conformant plan with a fixed length
k exists is P2 -complete3 (Baral, Kreinovich, & Trejo, 2000; Turner, 2002). Therefore, one
3. For planning domains where the executability of actions in a given state cannot be determined polynomially, this is even P
3 (Turner, 2002)

108

fiAn Approximative Inference Method for SO

typically attempts to solve it approximately. In this section, we show how we can apply our
approximative methods to solve conformant planning problems.
Example 7.1. Let us consider the Clogged Bombs in the Toilet domain (McDermott, 1987;
Son et al., 2005). There are a number of packages and a toilet. Each of the packages may
contain a bomb which can be disarmed by dunking the package in the toilet. Dunking a
package into a toilet also clogs the toilet and we cannot throw a package in a clogged toilet.
Flushing the toilet unclogs it. The effects of the actions on the fluents are modeled by the
following definition act , and the preconditions by the conjunction prec of sentences in
Tprec .

act



Clogged(0)  Init Clogged.





 Clogged(t + 1)  p : Dunk(p, t)  (Clogged(t)  F lush(t)).

=


Armed(p, 0)  Init Armed(p).






Armed(p, t + 1)  Armed(p, t)  Dunk(p, t).

Tprec

 p t : Dunk(p, t)  Clogged(t).
( p t : Dunk(p, t)  F lush(t)).
=
 p p2 t : Dunk(p, t)  Dunk(p2 , t)  p = p2 .
 p t t2 : Dunk(p, t)  Dunk(p, t2 )  t = t2 .

Now consider the following regular planning problem: given a completely specified initial
situation (specified by a formula init ), find a plan such that all packages are disarmed. We
can formulate this problem as the following formula:
A, F , I : act  prec  init  (t p Armed(p, t)),
where with A, we denote the action predicates {Dunk/2, F lush/1}, with F we denote
the fluent predicates {Armed/2, Clogged/1} and with I we denote the predicates used to
describe the initial situation {Init Clogged/0, Init Armed/1}. Now imagine that initial
situation is not specified, and we want to find a plan that works for all possible initial
situations, in other words a conformant plan. We can formulate the problem of finding such
a plan as follows.
A F , I : act  (prec  t p Armed(p, t)).
All this can be formalized in general as follows.
Definition 7.1 (Conformant planning). Let  be a vocabulary, consisting of a set of
predicates A, denoting actions, I, denoting initial fluents, and F denoting fluents. Let
Tact be an FO(ID) theory and Tinit , Tprec and Tgoal FO theories, all over , such that Tact
specifies the values of the fluents given an interpretation for the actions and initial fluents,
Tinit is a theory specifying the initial situation, Tprec contains preconditions for the actions,
and Tgoal specifies the goal of the planning problem. With act we denote the conjunction
of the sentences and possibly definitions in Tact and similarly for the other theories. The
problem of conformant planning is then to decide the satisfiability of the following formula:
A I F : (act  init )  (prec  goal ).
109

(6)

fiVlaeminck, Vennekens, Denecker & Bruynooghe

AR :


Cloggedct (0)



ct (t + 1)

Clogged




Armedct (p, 0)




Armedct (p, t + 1)




Cloggedpt (0)




Cloggedpt (t + 1)




Armedpt (p, 0)




Armedpt (p, t + 1)




Init Cloggedct




Init
Armedct (p)

Init Cloggedpt


Init Cloggedcf




Init
Armedpt (p)




Armedcf
Init



cf (t)

Clogged



cf (p, t)

Armed




Act

2

































Init Cloggedct .
p : Dunk(p, t)  (Cloggedct (t)  F lush(t)).
Init Armedct (p).
Armed(p, t)  Dunk(p, t).
Init Cloggedpt .
p : Dunk(p, t)  (Cloggedpt (t)  F lush(t)).
Init Armedpt (p).
Armed(p, t)  Dunk(p, t).
f.
f.
Init Cloggedcf .
f.
Init Armedcf (p).
f.
Cloggedpt (t).
Armedpt (p, t).
pt : Dunk(p, t)  Cloggedcf (t)
 (pt : Dunk(p, t)  F lush(t))
 p1 p2 t : Dunk(p, t)  Dunk(p2 , t)  p1 = p2
 pt1 t2 : Dunk(p, t1 )  Dunk(p, t2 )  t1 = t2
 tp : Armedcf (p, t).














































































Act
2 .

Figure 4: The complete approximation of the Clogged Bombs in the Toilet example.
In words, there must be a plan (A), such that no matter how the nondeterministic
 F ), as long as the specification of the effects of the actions (act )
aspects turn out (I,
and the (partial) specification of the initial situation (init ) are obeyed, the plan will be
executable (prec ) and achieve the goal (goal ).
Formula 6 is now exactly of the form we assumed above, and we can thus use one of our
methods to approximate conformant planning problems.
Example 7.1. (continued) Continuing the Clogged Bombs in the Toilet example, by
using the ct/pt-approximation for the definition, and unfolding the constraint (prec 
t p Armed(p, t))ct , we get the approximating SO formula APP wf
BU,U nf (Definition 5.7),
shown in Figure 4, where R are the ct- and cf-predicates introduced by the approximation
method.
The result of applying our general approximation method to a conformant planning
problem, as specified by Tact , Tprec , Tgoal and Tinit as above, is very similar to the approximation of an AL action theory by a logic program as in the work of Son et al. (2005).
However, there are some small differences in the details that make it difficult to formally
compare the two. Nevertheless, for all experiments discussed in this section, our method
always finds a correct solution (unless it times out), as does the method of Son et al.
Moreover, the two approaches also found these solutions in comparable execution times.
In more detail, Table 3 presents the following results. We implemented a conformant
planner by iteratively calling the IDP model generator for FO(ID) (Marien et al., 2006)
on our approximation, giving it an increasing number of timesteps until either a plan is
110

fiAn Approximative Inference Method for SO

Problem

IDP

Smodels

Cmodels

BT(2,2)
BT(4,2)
BT(6,2)
BT(8,4)
BT(10,4)

0.438
0.513
1.050
1.55
2.80

0.199
0.219
0.587
30.9
-

0.145
0.212
0.425
2.39
5.80

BTC(2,2)
BTC(4,2)
BTC(6,2)
BTC(8,4)

0.273
0.844
1.60
43.7

0.136
0.412
3.88
-

0.139
0.389
1.23
102

Cleaner(2,2)
Cleaner(2,5)
Cleaner(2,10)
Cleaner(4,2)
Cleaner(4,5)
Cleaner(4,10)
Cleaner(6,2)
Cleaner(6,5)

0.644
1.57
1.55
2460
8.30
-

0.226
72.5
13.8
-

0.376
1.36
1.13
6.16
-

Domino(100)
Domino(200)
Domino(500)
Domino(1000)
Domino(2000)

0.176
0.181
0.212
0.236
0.339

0.096
0.114
0.324
0.618
1.22

0.090
0.151
0.354
0.660
1.32

0.655
1.56
7.35
157
1537

0.285
2.092
19.1
-

0.296
0.937
3.542
19.860
232

Ring(2)
Ring(4)
Ring(6)
Ring(8)
Ring(10)

Table 3: Comparison IDP vs Cmodels vs Smodels

found or a maximum number of timesteps is reached. We then compared this planner to
the CPASP conformant planner (Son et al., 2005), using the same experimental setup as
in Section 6. CPASP takes an action theory in the action language AL, and encodes an
approximation of the transition diagram corresponding to that action theory, by means of
an answer set program. Then any answer set solver can be used to find conformant plans.
As Son et al., we used as the ASP solver behind CPASP both CModels (E. Giunchiglia &
Maratea, 2011) and SModels (Niemela, Simons, & Syrjanen, 2000). As Table 3 shows, the
combination of our approximation and the IDP system is comparable to, but overall slightly
worse, than the combination of CModels and Son et al.s approximation. When compared
to the same approximation given to SModels, our method tends to be a bit better. These
results are in line with results from the ASP competition (Denecker et al., 2009) concerning
the performance of SModels, CModels and IDP in general, suggesting that, for conformant
planning, our approximation and that of Son et al. are of comparable quality.
Another approximative method for solving conformant planning problems can be found
in the work of Palacios and Geffner (2009). In their paper, the authors consider conformant
planning problems, specified in the language Strips extended with conditional effects and
negation. They define a transformation K0 that transforms such a conformant planning
problem into a classical planning problem in a sound but incomplete way. For each fluent
literal L in the conformant planning specification, two new literals KL and KL are created,
111

fiVlaeminck, Vennekens, Denecker & Bruynooghe

denoting that L is known to be true, resp. known to be not true, and the initial situation,
action preconditions and effects are translated into an initial situation, preconditions and
effects with reference to these new knowledge literals. It is not hard to verify that our
approximation method generalizes this transformation: if we take an SO encoding of a
conformant planning problem P , the SO approximation obtained by our method can be
interpreted as a classical planning problem in the ct/cf vocabulary. This planning problem
will exactly be the planning problem specified by K0 (P ) (i.e., the action preconditions and
effects correspond), apart from the initial situation. The K0 transformation does not do
propagation on knowledge about the initial situation: given an initial situation I (specified
as a set of clauses), then K0 (I) consists of only those literals KL where L is a unit clause
in I. This means that, e.g., for an initial situation I = {P  Q, P }, K0 (I) will not include
the literal KQ, while our method will be able to infer that Qct holds (which means our
approximation method will be more complete than the K0 transformation).
Being a general method, ours does not only allow for solving conformant planning problems, but also allows for approximating a number of related problems in temporal domains.
Consider, for example, the following problem: Given that a certain action A happens at
timepoint t, will this certainly lead to a property  being true ? This can be formalized as
the following SO satisfiability problem, to which our method applies again.
AIF : ((act  init  prec  A(t))  ).
This formula is true if for all possible plans in which A(t) happens, the property  holds.
A variant on this problem is the so-called projection problem: Given that we exactly know
which actions happened (we can thus assume that the preconditions were satisfied), does
the property  hold ? In order to formulate this problem as a SO satisfiability problem, we
need to express that these and only these actions happened. This can be done, for example,
by using an inductive definition A . The projection problem can then be expressed as the
AIF : ((act  init  A )  ) satisfiability problem. Another variant is the following
problem: If the property 1 holds for a certain plan, does property 2 also hold?, which
can be expressed as the AIF ((act  init  prec  1 )  2 ) satisfiability problem.
7.2 Querying and Reasoning in Open Databases
Approximate methods similar to ours have been used in the context of databases without
complete information, in particular in databases without CWA, such as open databases
(Baral et al., 1998; Liu & Levesque, 1998) or databases that make forms of local closed
world assumptions (Denecker et al., 2010; Doherty et al., 2006). In most of these papers
the goal is to compute certain or possible answers to queries. Because this task has a
high complexity (from CoNP for a locally closed database without integrity constraints to
possibly P2 for databases with first-order constraints - assuming a given finite domain),
approximate methods are presented which translate an FO query into an approximate FO
or FO(FP)4 query that can be solved directly against the database tables using standard
(polynomial) query methods.
The method presented in this paper can provide a similar functionality. Let DB be a
set of ground literals, representing an incomplete database. Let  be a background theory:
4. FO(FP) is the extension of FO with least and greatest fixpoint constructs.

112

fiAn Approximative Inference Method for SO

it may contain integrity constraints, view definitions (datalog view programs are a special
case of FO(ID) definitions), local closed world statements expressed in FO, etc. For a given
 holds in all Herbrand models
FO query Q [x], the goal is to find all tuples d such that Q [d]
of DB  . The problem of deciding whether a given tuple d is an answer corresponds to
the satisfiability problem of the formula

R(DB    Q [d]),

(7)

and we can directly use our approximation method on this problem. While this allows us
to answer yes/no queries as well as to decide whether a given tuple d is a certain answer
to a query, our approximation method does not directly provide a method to compute (an
approximation of) all such tuples.
However, let us look at the following SO satisfiability problem.
R0 : DDB  ApproxBU (Q [x]),
It looks very much like our approximation of (  1 )  2 satisfiability problems (as
formulated in Proposition 5.5). We again have the definition DDB approximating the
database DB and background knowledge  (note that  possibly contains definitions), and
the bottom up evaluation of the query, only now the constraint Act
Q has been dropped.
The definition DDB  ApproxBU (Q [x]) consists of rules describing propagations allowed by the database and the theory , and rules defining the predicate symbol Act
Q , where
AQ is the Tseitin predicate representing the query Q [x]. In the unique Herbrand model
of this definition, the interpretation of Act
Q contains those tuples for which our propagation
can derive that they certainly satisfy the query  a sound approximation of the full set of
answers!
In the work of Denecker et al. (2010), a locally closed database LCDB is assumed. Such
a locally closed database consists of a standard database DB, i.e. a set of atoms, together
with a set of local closed world assumptions LCWA(P (x), [x]). Each of these LCWA
statements expresses that the databases knowledge about P is complete for those tuples x
 is therefore true if it is in DB and it is false
that satisfy the formula [x]. An atom P (d)
 holds in the domain
if it is not in DB and there is a LCWA(P (x), [x]) such that [d]
of discourse; otherwise it is unknown. The authors then present an approximate reasoning
method for query answering in locally closed databases and show how this approximate
query answering can be formulated as a fixpoint query. Basically, this boils down to the
following. One constructs the following definition




...






 P ct (x)  P (x)

,
LCWA =
 P cf (x)  P ct (x)  ct


P [x]






...
for every relation P and every local closed world assumption LCWA(P (x), [x]). Although
the authors do not phrase it in this form, their method for finding an approximation of the
certain answers to a query Q [x] actually boils down to solving the following satisfiability
problem:
R0 : DB  CW A(DB)  LCWA  ApproxBU (Q [x]),
113

fiVlaeminck, Vennekens, Denecker & Bruynooghe

Here R0 denotes all predicates and auxiliary predicates occurring in the body of the existential formula. With CW A(DB), we denote the formula expressing closed world assumption
for the database DB. The presence of this closed world assumption might seem strange at
first sight, since the whole idea behind locally closed world databases is to not assume CWA
per default. However, in order to correctly apply the local closed world assumptions, we
need an exact specification of what is in the database and what is not, and this is precisely
what is expressed by DB  CW A(DB). Indeed, given DB  CW A(DB), LCWA can be
seen as an approximative definition of what is certainly true and false in the context of the
locally closed world assumptions. Again the predicate Act
Q will contain an approximate
answer to the query Q [x], i.e., a lower bound on all the tuples for which the query Q [x]
is certainly true. Similarly, the predicate Acf
Q will contain a lower bound on all the tuples
for which the query is false.
A limitation of the approach by Denecker et al. is that they extend the above method
for only one type of integrity constraints, namely functional dependencies. The way these
functional dependencies are handled is by extending LCWA with extra propagation rules
taking these functional dependencies into account. By contrast, our more general method
can be used to easily extend this to arbitrary integrity constraints. This works as follows.
Let Tint be a set of first-order integrity constraints. We can then approximate the problem
of finding certain queries by the following satisfiability problem.
BU
ct  t}  DB  CW A(DB)  LCWA  Approx
(Q [t]).
R0 : Approx(Tint )  {ATint

Again, the predicate Act
Q will contain an approximate answer to the query Q [x].
Doherty et al. (2006), propose yet another approach to asking queries to an incomplete
database. The authors use the term approximate database to denote a database, consisting
of two layers: an extentional and an intensional layer. Both of these layers have an external
representation towards the user, and an internal representation.
The extentional database consists of positive and negative literals, and is internally
stored as a classical database, using the Feferman transformation. For example, the extentional database (EDB), as entered by a user,
Color(Car1, Black), Color(Car1, Red), Color(Car2, Red),
is internally stored as
Colorct (Car1, Black), Colorcf (Car1, Red), Colorct (Car2, Red).
The intentional database consists of rules to infer additional information from the facts in
the EDB. The user can write down rules of the form ()P1 (x1 ). . .()Pn (xn )  ()P (x)),
which are then internally stored as (()P1 (x1 ))ct  . . .  (()Pn (xn ))ct  (()P (x)))ct . An
example of such a IDB rule is the following rule
Color(x, y1 )  y1 6= y2  Color(x, y2 ),
which is internally stored as
Colorct (x, y1 )  y1 6= y2  Colorcf (x, y2 ).
114

fiAn Approximative Inference Method for SO

To evaluate a query, a naive algorithm based on exhaustively applying all rules on the EDB
is used.
The rules in the IDB resemble our IN F formulas in the sense that both describe valid
inferences that can be made based on incomplete information. The internal representation
of the IDB is indeed similar to our representation of IN F formulas as definitional rules.
However, a key difference is that in the approach of Doherty et al., when a user wants to add
a property  to the database (e.g., a car can only have one color), he has to write down all
inferences that are valid according to that property, while in our approach these inference
rules are automatically generated from the property itself. Manually writing down all valid
inferences sanctioned by a property is not an easy task. For example, take the property a
car has to be inspected if and only if it was suspect and black from the paper by Doherty
et al.. This can be expressed in FO as the formula  = c(Suspect(c)  Color(c, Black) 
Investigate(c)). While, in our method, Approx() constructs an approximation of all valid
inferences that can be made from this formula, the user has to write down the following
rules in Doherty et al.s approach:
Suspect(c)  Color(c, Black)  Investigate(c)
Suspect(c)  Investigate(c)  Color(c, Black)
Suspect(c)  Investigate(c)
...
Our method therefore generalizes the work of Doherty et al. by deriving these rules automatically from a general first-order theory.
Liu and Levesque (1998) propose another type of reasoning in open databases. They
only consider a simple form of first order knowledge bases, called proper knowledge bases.
An interesting feature of these knowledge bases is that it is easy to obtain a complete
characterization of what is certainly true, resp. certainly false. In our terminology, that
 if and only if  |= P ct (d)

means that one can construct a definition , such that KB |= P (d)
cf

and KB |= P (d) if and only if  |= P . It holds that every two valued extension of the
three valued interpretation encoded by  is a model of the KB. Then Levesque et al. use
an evaluation procedure based on the three-valued Kleene-evaluation to check whether a
query holds in the knowledge base. As mentioned earlier, they also define a normal form
N F for queries, for which they prove that the Kleene-evaluation is complete. Our work
extends their work, in the sense that we can take a general first order knowledge base
and approximately solve queries, as we have shown above. Of course, since in general we
can no longer guarantee a complete characterization of what is certainly true/false, we can
no longer guarantee completeness, even if the query is in the normal form N F. Another
difference between the work of Liu and Levesque and our work here, is that they assume a
fixed countable infinite domain, while we assume a fixed finite domain. While this is indeed
a theoretical difference, in practice it does not make any difference, since their evaluation
method only considers a finite set of domain elements that can be determined up-front.

8. Conclusions and Future Work
Even if a problem is computationally hard in general, specific instances of it might still
be solved efficiently. This is why approximate methods are important: they cannot solve
115

fiVlaeminck, Vennekens, Denecker & Bruynooghe

every instance, but the instances they can solve, they solve quickly. In computational
logic, hard problems arise quite readily. It is therefore not surprising that the literature
contains numerous examples of algorithms that perform approximate reasoning tasks for
various logical formalisms in various specific contexts. Since many of these algorithms share
common ideas, it is a natural question whether they can be seen as instances of some more
general method for a more general language.
This paper presents such a method. We start from the propagation method for FO()
developed by Wittocx, Marien, and Denecker (2008) and its symbolic expression (Wittocx,
2010) and generalize this to a method for approximating the P2 -complete SO(ID) satisfiability problem by solving an NP problem. Importantly, this is a syntactic method that
transforms the SO(ID) formula into an SO(ID) formula. This affords us the freedom
to use any off-the-shelf solver for such a language to perform the approximative reasoning.
Moreover, it also makes it significantly easier to update the method by adding (or removing)
specific propagations.
Since our method is an approximation, it is necessarily incomplete. Nevertheless, our
experiments have shown that, in practice, it often does manage to find a solution. An
interesting topic for future work is to determine classes of problems, for which our method
can be shown to be complete.
In summary, the contributions of this paper are that (1) we have extended the logical
representation describing the propagation process to a general method for approximating
SAT (SO) problems; (2) we have shown how to approximate inductive definitions, and use
this to approximate a class of useful SAT (SO(ID))-problems; and (3) we have examined
how existing approximation methods fit into our general framework.

Acknowledgments
This work is supported by Research Foundation - Flanders FWO-Vlaanderen, projects
G.0489.10 and G.035712, and by Research Fund KULeuven, project GOA/08/008. Hanne
Vlaeminck is supported by IWT-Vlaanderen.

Appendix A. An Example of an Approximation
Figure 5 shows the full approximation of act as in Example 1.1.

Appendix B. Proof of Theorem 3.1
Proof. First, remark that Feferman (1984) showed that the four-valued evaluation of a
formula  in an interpretation I can be simulated by computing the standard two-valued
evaluation of ct and cf in I tf . It is easy to verify that the bottom-up rules in Approx()
inductively encode this evaluation. We split the proof in two parts. First we assume that I
is three-valued. We show that in this case only the bottom-up rules are used, i.e., leaving
out the top-down rules does not change the model of the definition. This proves the first
part of the theorem, and together with the above remark also proves the second part of
the theorem for the case that I is three-valued. Then, all that is left to prove, is that the
second part of the theorem also holds for four-valued I.
116

fiAn Approximative Inference Method for SO

























































































































































































Act
act
Acf
act
Acf
act
Act
0
Act
8
Acf
0
Acf
8









Act
0
Acf
0
Act
1 (t)
Acf
1 (t)
Acf
1 (t)
Acf
1 (t)
Act
1 (t)
Act
2 (t)
Acf
2 (t)
Act
5 (t)
Acf
5 (t)
Act
2 (t)
Act
2 (t)
Acf
2 (t)
Cleanct (t + 1)
Cleancf (t + 1)
Acf
4 (t)
Act
4 (t)
Act
4 (t)
Act
4 (t)
Acf
4 (t)
Cleancf (t)
Cleanct (t)
Act
5 (t)
Act
5 (t)
Acf
5 (t)
Acf
6 (t)
Act
6 (t)
Cleancf ((t + 1))
Cleanct ((t + 1))
Acf
6 (t)
Acf
6 (t)
Act
6 (t)
Cleancf (t)
Cleanct (t)





































Acf
8
Acf
8
Act
8
Act
9
Acf
9
Act
11
Acf
11
Act
9
(t : Act
Act
1 (t)).
9
(t : Acf
Acf
1 (t)).
9
Act
Cleanct (0)
0.
ct
cf
(Acf
0  (t1 : (t1 = t  A1 (t1 )))). Clean (0)
cf
Acf
(t).
InitiallyClean
2
cf
A5 (t).
InitiallyCleanct
ct
ct
(A2 (t)  A5 (t)).
Act
11
Act
(t).
Act
1
11
ct
(Acf
Acf
1 (t)  A5 (t)).
11
ct
A1 (t).
Acf
12
ct
(Acf
Act
12
1 (t)  A2 (t)).
Cleancf ((t + 1)).
Cleancf (0)
Act
(t).
Cleanct (0)
4
cf
ct
(Clean (t + 1))  A4 (t)).
Act
12
cf
A2 (t).
Acf
12
cf
(Act
InitiallyCleancf
2 (t)  A4 (t)).
cf
A2 (t).
InitiallyCleanct
ct
(Act
2 (t)  Clean (t + 1)).
Cleanct (t).
W ipe(t).
(Cleancf (t)  W ipe(t)).
Acf
4 (t).
(Act
4 (t)  W ipe(t)).
Act
6 (t).
Cleanct (t + 1).
cf
(Acf
6 (t)  Clean (t + 1)).
cf
A5 (t).
cf
(Act
5 (t)  Clean (t + 1)).
cf
A5 (t).
cf
(Act
5 (t)  A6 (t)).
ct
Clean (t).
W ipe(t).
(Cleancf (t)  W ipe(t)).
Act
6 (t).
(Acf
6 (t)  W ipe(t)).
ct
Act
0  A8 .
cf
A0 .
Acf
8 .
Act
act .
Act
act .
ct
Acf
act  A8 .
cf
Aact  Act
0.



























Acf
9 .
Acf
11 .
ct
(Act
9  A11 ).
ct
A8 .
ct
(Acf
8  A11 ).
ct
A8 .
ct
(Acf
8  A9 ).
cf
Clean (0).
InitiallyCleanct .
(Cleanct (0)  InitiallyCleancf ).
Acf
9 .
cf
(Act
9  InitiallyClean ).
Acf
.
9
ct
(Act
9  Clean (0).
ct
A12 .
Cleanct (0).
cf
(Acf
12  Clean (0)).
cf
A11 .
cf
(Act
11  Clean (0)).
Acf
.
11
cf
(Act
11  A12 ).
InitiallyCleancf .
InitiallyCleanct .
Act
12 .
Acf
12 .

























































































































































































Figure 5: Approx{W ipe} (act ), with act taken from Example 1.1.
So let us assume that I is three-valued. We prove that M od(ApproxBU ()  I ) =
M od(Approx()  I ) by contradiction. Assume there is a predicate Act
 (the proof goes
cf
ct
analogously for A ) such that M od(Approx()  I ) |= A but M od(ApproxBU () 
I ) 6|= Act
 . In the preliminaries we recalled that the model of a positive inductive definition
O . The model of such a
is the least-fixpoint of the immediate consequence operator T
117

fiVlaeminck, Vennekens, Denecker & Bruynooghe

definition is thus the limit of a sequence of applications of the immediate consequence
operator. One can prove (see, e.g., Denecker & Ternovska, 2004) that we do not have to
apply the immediate consequence operator of the complete definition in every step. I.e.,
applying the immediate consequence operator of a subset of the definition, until there no
longer exists such a immediate consequence operator that will give something new, gives
the same model. Suppose we take such a sequence where we first apply all the bottom-up
rules, and only after no bottom-up rules are applicable we try to apply the top-down rules.
Suppose Act
 is the first atom we infer with the top down rules in this sequence. Obviously
Act
cannot
be the top-level atom Act

 , since there are no top-down rules for this. We can now
do a case study on the type of (sub)formula  occurs in, e.g., assume that  is a subformula
of the formula  where  =   0 . From the fact that Act
 is true, it follows that the body
cf
cf
ct
ct
of the top down rule A  A  A0 has to be true, and thus that Act
 and A0 are true.
ct
Since Act
 was the first atom to be inferred by a top-down rule, we have that since A is
ct
ct
ct
true, also A  A0 must be true. Now since A only became true in the last step of the
sequence, we have that Act
0 must have been true already. This means that after applying
cf
the bottom-up rules Act
0 and A0 are both true, which is a contradiction with the fact that
I was three-valued and that the bottom-up rules encode the four-valued evaluation. The
proof is analogous for the other types of subformulas.
Now in the case that I is four-valued, and not three-valued it is no longer the case
that only the bottom-up rules contribute to the model (i.e., M od(ApproxBU ()  I ) 6=
M od(Approx()  I )). To see this, consider the following formula P  Q, and take for
I the four-valued interpretation such that P = i and Q = t. Then one can verify that
cf
the bottom-up rules in Approx()  I will infer that both Act
P Q and AP Q are true.
However, now the top-down rules can also infer that Qcf has to be true. What happens is
that once an inconsistency is inferred for a certain subformula, this propagates back down
the parse-tree. However, similar to above, we can again do a case study on the structure of
cf
 to prove that (for the top formula  ) M od(ApproxBU ()  I ) |= Act
  A if and only
cf
BU () is clearly a direct
if M od(Approx()  I ) |= Act
  A . Now since since Approx
encoding of the four-valued evaluation, this concludes the proof.

Appendix C. Proof of Proposition 4.3
Proof. Take a witness I for the satisfiability of APP  (F ). First let us remark that
Open(Approx (1  2 )  {Act
1  t}) = . From the fact that I is a witness of the
satisfiability of APP  (F ) we know that the model M of this definition extending I concf
tains Act
 and by construction of Approx (1  2 ) it must also contain either A1 or
Act
2 .
Assume first that Acf
1 is true in M . Then application of Theorem 3.2 (where we take
 = {1 } and 0 = 1 ) gives: if M extends I and M |= 1 , then M 6|= 1 , so the assumption
that M |= 1 results in a contradiction and hence M 6|= 1 , in which case 1  2 holds
for every M extending I, and thus is I a witness for the satisfiability of F .
Next, assume that Act
2 is true in M . Again applying Theorem 3.2 (where this time
 = {1 } and 0 = 2 ) gives: if M extends I and M |= 1 then M |= 2 , hence also in this
118

fiAn Approximative Inference Method for SO

case does 1  2 hold for every M extending I, and again this means that I is a witness
of the satisfiability of F .

Appendix D. Proof of Theorem 5.2
A key ingredient in the proof of Theorem 5.2 is the following property of Appct/pt ().
Oct/pt
Its immediate consequence operator TApp
ct/pt () on two-valued interpretations simulates
(O ,O )

the immediate consequence operator T 1 2 on four-valued interpretations of the original
definition. This is made more precise in the following lemma.
Definition D.1. For a pair of -interpretations (I, J), we use t(I, J) to denote the ct/pt interpretation (I, J)ct/pt .
Lemma D.1. For each (O1 , O2 ) and (I, J),
(O1 ,O2 )

T

(O1 ,O2 )

Proof. Let (I 0 , J 0 ) be T

t(O ,O )

(I, J) = t1 (TApp1ct/pt2 () (t(I, J))).
t(O ,O )

(I, J) and let F = TApp1ct/pt2 () (t(I, J)). We first show that

F |ct = I 0 . Since F |ct depends only on the rules of Appct/pt () with a predicate from ct ,
we can discard all rules with a head from pt . As a result, we are left with a single copy of 
in which positive occurrences of atoms have been replaced by their ct variant and negative
ones by their pt variant. This implies that the evaluation of the bodies of these remaining
rules according to t(O1  I, O2  J) will be identical to the evaluation of the bodies of the
original rules by (O1  I, O2  J) in the construction of I 0 , thus proving the equality. The
proof of the remaining equality F |pt = J 0 is analoguous.
Proof of Theorem 5.2. First, recall that, given some partial knowledge (O1 , O2 ), the threevalued well-founded models of , resp. Appct/pt () are the least fixpoints of operators
(O ,O )
t(O ,O2 )
ST  1 2 resp. ST App1ct/pt
(note that since t(O1 , O2 ) is two-valued, we abuse notation
()
here and in the rest of the proof and denote the two-valued pair (t(O1 , O2 ), t(O1 , O2 )) by
t(O1 , O2 )).
Now, the latter operator is rather peculiar, in the sense that it is actually juggling four
different interpretations of the original alphabet . In more detail, each element in its
domain looks like this:


Ict
Jct
(I, J) =   ,   .
Ipt
Jpt
where Ict and Jct interpret the alphabet ct , and Ipt and Jpt interpret pt . If we now apply
t(O ,O2 )
the operator ST App1ct/pt
, we obtain a new such pair:
()

0
0
Ict
Jct
(I 0 , J 0 ) =   ,   .
0
0
Ipt
Jpt


119

fiVlaeminck, Vennekens, Denecker & Bruynooghe

0
0
From the general definition of the ST O
 construction, it is obvious that Ict Ipt depends only
on Jct  Jpt . However, in this particular case, the operator exhibits even more structure.
(O ,O2 )
The operator STApp1ct/pt
(J) uses its argument J as a fixed interpretation for the negative
()
occurrences, which remains constant throughout the least fixpoint computation over the
positive occurrences. Now, Appct/pt () contains two copies of  which interact only through
negative occurrences (that is, all occurrences of a pt predicate in the body of a rule with
a ct predicate in its head are always negative ones, and vice versa). This means that as
long as we keep the interpretation of the negative occurrence fixed to a constant value J,
0 , we can discard
these two copies of  do not interact at all. Consequently, to construct Ict
all rules with a pt predicate in its head. This means we are left with rules whose head
is a ct predicate and whose body contains only positive occurrences of ct predicates and
0 depends only on J . Moreover, the
negative occurrences of pt predicates. Therefore, Ict
pt
0 will be such that if we map its symbols back to the original alphabet  (let
value of Ict
0 ) = ST (O1 ,O2 ) (orig(J )). Similarly,
orig( ct ) = orig( pt ) =  for all   ), then orig(Ict
pt

we also obtain that:
(O1 ,O2 )

(orig(Jct )),

(O1 ,O2 )

(orig(Ipt )),

(O1 ,O2 )

(orig(Ict )).

0
orig(Ipt
) = ST

0
orig(Jct
) = ST

0
orig(Jpt
) = ST

In other words,
(O ,O2 )

0
0
(orig(Ict
), orig(Jpt
)) = ST  1
0
0
(orig(Ipt
), orig(Jct
)) = ST

(orig(Ict ), orig(Jpt )),

(O1 ,O2 )
(orig(Ipt ), orig(Jct )).


Now, if we consider the construction of the well-founded model of Appct/pt (), we have a
sequence of this form:

 1

 2

 

 0
0
1
2

Ict
Jct
Ict
Jct
Ict
Jct
Ict
Jct
  ,   7   ,   7   ,   7    7   ,   .
0
0
1
1
2
2


Ipt
Jpt
Ipt
Jpt
Ipt
Jpt
Ipt
Jpt
Let (I i , J i )i0 be the well-founded model construction for the original definition , i.e., for
 I 0 = f and
all predicates P/n  Def () and domain tuples d  Dn we have that (P (d))
 J 0 = t, and (I n+1 , J n+1 ) = ST (O1 ,O2 ) (I n , J n ) for n  0. It is easy to see that we have
(P (d))

0  J 0 ) = (I , J ). This provides a base case, while the above equation provides
that t1 (Ict
0 0
pt
i  J i ). In other words, the
the inductive step to prove that, for each i, (I i , J i ) = t1 (Ict
pt
well-founded model construction for the original definition  is tracked by these elements
of the well-founded model construction for Appct/pt ():
 0

 1

 2

 

Ict

Ict

Ict

Ict

  ,   7   ,   7   ,   7    7   ,   .
0
1
2


Jpt

Jpt

Jpt

Jpt
What about the other diagonal? There we have that t1 (J0ct  I0ct ) = (>, ), which is
the most precise element >p in the lattice of pairs of interpretations. Therefore, we find
120

fiAn Approximative Inference Method for SO

(O ,O )

that the other diagonal actually tracks the construction of the greatest fixpoint of ST  1 2 .
Combining these two results, we see that if (L1 , L2 ) and (G1 , G2 ) are these least and greatest
fixpoint, respectively, the well-founded model of Appct/pt () looks like this:


L1
G1
  ,  .
G2
L2
Note that a unique four-valued stable fixpoint is both the least and greatest stable fixpoint
and hence also the well-founded fixpoint. This immediately concludes the proof.

Appendix E. Proof of Proposition 5.3
Lemma E.1. Given a -definition , and a FO-formula . Let  be a subset of 0 (a
renamed copy of ). Consider the definition
D = Appct/pt ()  {P ct  P 0ct }P   {Opt  O0pt }OOpen(0 ) .
Assume that we have a three-valued interpretation I that approximates all models of   .
Then it holds that W F MI ct/pt (D) also approximates   , i.e.,
  W F M ct/pt (D), then |= (  )  P (d),

- if P ct (d)
I
 6 W F M ct/pt (D), then |= (  )  P (d).

- if P pt (d)
I
Proof. We prove this through induction over a well-founded model construction alternative
to the one we described in this paper, which can be found in the work by Denecker and
Vennekens (2007). Assume we have an induction sequence (Ii )0in , of four-valued Def (D)interpretations such that I0 is the interpretation in which everything is completely unknown,
and In = W F MI ct/pt (D). We prove for every i that Ii is a sound approximation of   .
This is trivially the case for n = 0. So now assume that Ik is a sound approximation of
  . We have to prove that this is also the case for Ik+1 . We need to prove two things for
 cannot be true in Ik+1 if P (d)
 is not true in all models of   ,
this: first, an atom P ct (d)
pt
 cannot be false in Ik+1 if it is not false in all models of
and second, that an atom P (d)
  . We prove both cases by contradiction.
We start with the first case. So assume that in the k-th well-founded induction step,
 is incorrectly deduced, i.e., there
for a certain predicate P and domain tuple D, P ct (d)

 was inferred in the k-th step,
exists a model M |=   , s.t. M 6|= P (d). Since P ct (d)
ct
 that is, (P )ct [d]
 was already made
this means that the body of the rule defining P (d),
true in a previous step. The induction hypothesis then tells us that in every model M of
 but then the semantics of inductive definitions says that
   it holds that M |= P [d],
also M |= P , which is a contradiction with our assumption.
Next, we consider the second case. This time, assume that in the k-th well-founded
 is inferred to be false, while there exists a model M of   , s.t.
induction step, P pt (d)

M |=     P (d). Now, using this alternative version of the well-founded semantics, there
are two ways for a domain atom to become false. Indeed, a domain atom can become false
121

fiVlaeminck, Vennekens, Denecker & Bruynooghe

because the body of the defining rule was already false, or because it is part of an unfounded
set.
 was made false because the body of the defining rule (P )pt was already false,
If P pt (d)
an argument completely analogous to the one above - using the induction hypothesis - again

gives a contradiction with the assumption. So now, all that is left to prove, is that P pt (d)
pt

cannot be incorrectly made false through the application of an unfounded set rule. If P (d)
is made false through the application of the unfounded set rule, this means that there is a
set U S of atoms, that are unknown in Ik , such that when made false in the bodies of the
rules defining these atoms, the Kleene evaluation of these bodies returns false. It is possible
to verify that we can always find an U S such that it only contains pt -atoms.
Now let us take such a model M of   . Such an M is obviously also a model
 such that
of . Consider the corresponding set U S 0 , consisting of domain atoms P (d),
pt
pt
pt


P (d)  U S. For every atom Q [d] in the body (P ) not in the set U S, the induction
 M t (Qpt [d])
 Ik . Similarly, for every atom Qct in
hypothesis actually tells us that (Q[d])
pt
ct
I
 k t (Q[d])
 M . Now, since Qpt atoms occur only
the body of (P ) , it says that (Q [d])
positively and and Qct only negatively in (P )pt , it follows that M interprets literals that
are not in U S 0 in a more false way than Ik . Thus, U S 0 is also an unfounded set (indeed,
turning all the atoms in U S 0 to false will make all the bodies of the defining rules false), and
 which is again a contradiction with the assumption, and which concludes
thus M |= P (d),
the proof of this lemma.

Proof of Proposition 5.3. The proof of this proposition is now an easy proof over induction
on the construction of the well-founded model of D , using the lemma above, and the
soundness of Approx().

References
Baral, C. (2003). Knowledge Representation, Reasoning, and Declarative Problem Solving.
Cambridge University Press, New York, NY, USA.
Baral, C., Gelfond, M., & Kosheleva, O. (1998). Expanding queries to incomplete databases
by interpolating general logic programs. J. Log. Program., 35 (3), 195230.
Baral, C., Kreinovich, V., & Trejo, R. (2000). Computational complexity of planning and
approximate planning in the presence of incompleteness. Artif. Intell., 122 (1-2), 241
267.
Belnap, N. D. (1977). A useful four-valued logic. In Dunn, J. M., & Epstein, G. (Eds.),
Modern Uses of Multiple-Valued Logic, pp. 837. Reidel, Dordrecht. Invited papers
from the Fifth International Symposium on Multiple-Valued Logic, held at Indiana
University, Bloomington, Indiana, May 13-16, 1975.
Clark, K. L. (1978). Negation as failure. In Logic and Data Bases, pp. 293322. Plenum
Press.
Denecker, M., Cortes Calabuig, A., Bruynooghe, M., & Arieli, O. (2010). Towards a logical
reconstruction of a theory for locally closed databases. ACM Transactions on Database
Systems, 35 (3), 22:122:60.
122

fiAn Approximative Inference Method for SO

Denecker, M., & Ternovska, E. (2004). A logic of non-monotone inductive definitions and
its modularity properties. In Lifschitz, V., & Niemela, I. (Eds.), LPNMR, Vol. 2923
of LNCS, pp. 4760. Springer.
Denecker, M., & Ternovska, E. (2007). Inductive situation calculus. Artificial Intelligence,
171 (5-6), 332360.
Denecker, M., & Ternovska, E. (2008). A logic of nonmonotone inductive definitions. ACM
Transactions on Computational Logic (TOCL), 9 (2), Article 14.
Denecker, M., & Vennekens, J. (2007). Well-founded semantics and the algebraic theory of
non-monotone inductive definitions. In Baral, C., Brewka, G., & Schlipf, J. S. (Eds.),
LPNMR, Vol. 4483 of LNCS, pp. 8496. Springer.
Denecker, M., Vennekens, J., Bond, S., Gebser, M., & Truszczynski, M. (2009). The second
Answer Set Programming competition. In Erdem, E., Lin, F., & Schaub, T. (Eds.),
LPNMR, Vol. 5753 of LNCS, pp. 637654. Springer.
Doherty, P., Magnusson, M., & Szalas, A. (2006). Approximate databases: a support tool
for approximate reasoning. Journal of Applied Non-Classical Logics, 16 (1-2), 87118.
E. Giunchiglia, Y. L., & Maratea, M. (2011). Cmodels homepage. http://www.cs.utexas.
edu/users/tag/cmodels.html.
Fagin, R. (1974). Generalized first-order spectra and polynomial-time recognizable sets.
Complexity of Computation, 7, 4374.
Feferman, S. (1984). Toward useful type-free theories. Journal of Symbolic Logic, 49 (1),
75111.
Gelfond, M., & Lifschitz, V. (1988). The stable model semantics for logic programming. In
Kowalski, R. A., & Bowen, K. A. (Eds.), ICLP/SLP, pp. 10701080. MIT Press.
Immerman, N. (1998). Descriptive Complexity. Springer Verlag.
Kleene, S. C. (1952). Introduction to Metamathematics. Van Nostrand.
Liu, Y., & Levesque, H. J. (1998). A completeness result for reasoning with incomplete
first-order knowledge bases. In KR, pp. 1423.
Marien, M., Wittocx, J., & Denecker, M. (2006). The IDP framework for declarative problem
solving. In Search and Logic: Answer Set Programming and SAT, pp. 1934.
McDermott, D. (1987). A critique of pure reason. Computational Intelligence, 3, 151160.
Mitchell, D. G., & Ternovska, E. (2005). A framework for representing and solving NP
search problems. In Veloso, M. M., & Kambhampati, S. (Eds.), AAAI, pp. 430435.
AAAI Press / The MIT Press.
Niemela, I., Simons, P., & Syrjanen, T. (2000). Smodels: A system for answer set programming. In Proceedings of the 8th International Workshop on Non-Monotonic Reasoning,
Breckenridge, Colorado, USA. CoRR, cs.AI/0003033.
Palacios, H., & Geffner, H. (2009). Compiling uncertainty away in conformant planning
problems with bounded width. Journal of Artificial Intelligence Research (JAIR), 35,
623675.
123

fiVlaeminck, Vennekens, Denecker & Bruynooghe

Son, T. C., Tu, P. H., Gelfond, M., & Morales, A. R. (2005). An approximation of action
theories of and its application to conformant planning. In Baral, C., Greco, G., Leone,
N., & Terracina, G. (Eds.), LPNMR, Vol. 3662 of LNCS, pp. 172184. Springer.
Tamaki, H., & Sato, T. (1984). Unfold/fold transformations of logic programs. In ICLP,
pp. 127138.
Tseitin, G. S. (1968). On the complexity of derivation in propositional calculus. In Slisenko,
A. O. (Ed.), Studies in Constructive Mathematics and Mathematical Logic II, pp. 115
125. Consultants Bureau, N.Y.
Turner, H. (2002). Polynomial-length planning spans the polynomial hierarchy. In JELIA,
pp. 111124.
van Fraassen, B. (1966). Singular terms, truth-value gaps and free logic. Journal of Philosophy, 63 (17), 481495.
Van Gelder, A. (1993). The alternating fixpoint of logic programs with negation. Journal
of Computer and System Sciences, 47 (1), 185221.
Vlaeminck, H., Wittocx, J., Vennekens, J., Denecker, M., & Bruynooghe, M. (2010). An
approximate method for solving SO problems. In Fisher, M., van der Hoek, W.,
Konev, B., & Lisitsa, A. (Eds.), JELIA, Lecture Notes in Computer Science, pp.
326338. Springer.
Wittocx, J. (2010). Finite Domain and Symbolic Inference Methods for Extensions of FirstOrder Logic. Ph.D. thesis, Department of Computer Science, K.U.Leuven, Leuven,
Belgium.
Wittocx, J., Denecker, M., & Bruynooghe, M. (2010). Constraint propagation for extended
first-order logic. CoRR, abs/1008.2121.
Wittocx, J., Marien, M., & Denecker, M. (2008). Approximate reasoning in first-order logic
theories. In Brewka, G., & Lang, J. (Eds.), KR, pp. 103112. AAAI Press.

124

fi