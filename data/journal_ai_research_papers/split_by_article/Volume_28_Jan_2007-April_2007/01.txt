Journal of Artificial Intelligence Research 28 (2007) 49-105

Submitted 2/06; published 02/07

The Strategy-Proofness Landscape of Merging
Patricia Everaere
Sebastien Konieczny
Pierre Marquis

everaere@cril.fr
konieczny@cril.fr
marquis@cril.fr

CRIL  CNRS
Faculte des Sciences, Universite dArtois
62300 Lens, France

Abstract
Merging operators aim at defining the beliefs/goals of a group of agents from the
beliefs/goals of each member of the group. Whenever an agent of the group has preferences
over the possible results of the merging process (i.e., the possible merged bases), she can
try to rig the merging process by lying on her true beliefs/goals if this leads to a better
merged base according to her point of view. Obviously, strategy-proof operators are highly
desirable in order to guarantee equity among agents even when some of them are not
sincere. In this paper, we draw the strategy-proof landscape for many merging operators
from the literature, including model-based ones and formula-based ones. Both the general
case and several restrictions on the merging process are considered.

1. Introduction
Merging operators aim at defining the beliefs/goals of a group of agents from the beliefs/goals of each member of the group. Though beliefs and goals are distinct notions,
merging operators can typically be used for merging either beliefs or goals. Thus, most of
the logical properties from the literature (Revesz, 1993, 1997; Konieczny & Pino Perez, 1998,
2002) for characterizing rational belief merging operators can be used for characterizing as
well rational goal merging operators.
Whatever beliefs or goals are to be merged, there are numerous situations where agents
have preferences on the possible results of the merging process (i.e., the merged bases). As
far as goals are concerned, an agent is surely satisfied when her individual goals are chosen
as the goals of the group. In the case of belief merging, an agent can be interested in
imposing her beliefs to the group (i.e., convincing the other agents), especially because
the result of a further decision stage at the group level may depend on the beliefs of the
group.
So, as soon as an agent participates to a merging process, the strategy-proofness problem
has to be considered. The question is: is it possible for a given agent to improve the result of
the merging process with respect to her own point of view by lying on her true beliefs/goals,
given that she knows (or at least she assumes) the beliefs/goals of each agent of the group
and the way beliefs/goals are merged?
As an illustration, let us consider the following scenario of goal merging (that will be
used as a running example in the rest of the paper):

c
2007
AI Access Foundation. All rights reserved.

fiEveraere, Konieczny & Marquis

Example 1 Three friends, Marie, Alain and Pierre want to spend their summer holidays
together. They have to determine whether they will go to the seaside and/or to the mountains, or to stay at home, and also to determine whether they will take a long period of
vacations or not. The goals of Marie are to go to the seaside and to the mountains if it is
for a long period; otherwise she wants to go to the mountains, only, or to stay at home. The
goals of Alain are to go to the seaside if it is for a long period; or to go to the mountains
if it is for a short period. Finally, Pierre is only interested in going to the seaside for a
long period, otherwise he prefers to stay at home. If one uses a common merging operator
for defining the choice of the group,1 then the goals of the group will be either to go to the
seaside for a long period, or to go to the mountains or to stay at home for a short period.
Accordingly, the group may choose to go to the seaside, only, for a long period, which is not
among the goals of Marie. However, if Marie lies and claims that, for a short period, she
wants to go to the mountains only, or to stay at home, then the result of the merging process
will be different. Indeed, in this case, the goals of the group will be to go to the mountains
for a short period, or to stay at home, which corresponds to the goals of Marie.
Similarly, the strategy-proofness issue has to be considered in many belief merging scenarios, just because rational decision making typically takes account for the true state
of the world. When agents have conflicting beliefs about it, belief merging can be used
to determine what is the true state of the world for the group; manipulating the belief
merging process is a way for an agent to change the resulting beliefs at the group level so as
to make them close to her own beliefs. As a consequence, the decisions made by the group
may also change and become closer to those the agent would made alone. For instance,
assume that the three friends agree that the mountains must be avoided when the weather
is bad. If the beliefs of the group is that the weather is bad, then the decision to go to
the mountains will be given up. If Pierre believes that the weather is bad, then he may
be tempted to make the weather is bad accepted at the group level. Therefore, a collective
decision will be not to go to the mountains.
There are several multi-agent settings in which some agents exchange information and
must make individual decisions based on their beliefs. In many scenarios, agents are tempted
to get an informational advantage over other agents, which can be achieved by gathering as
much information as possible and by hiding their own ones. Indeed, being better informed
may help an agent making better decisions than the other agents of the group. For instance,
Shoham and Tennenholtz (2005) investigate non-cooperative computation: each agent delivers some piece of information (truthfully or not), all such pieces are used to compute
the value of a (commonly-known) function, and this value is given back to the agents; the
aim of each agent is to get the true value of the function, and if possible to be the only
one to get it. In the work of Shoham and Tennenholtz (2005), information is considered at
an abstract level; assuming that information represent beliefs and the function is a belief
merging operator, each agent wants to get the true merged base and possibly to be the only
one to get it. Contrastingly, in other scenarios, where decisions have to be made collectively
and are based on the beliefs of the group, agents are satisfied if the beliefs of the group
1. Formally, the model-based operator 4dH , , using the Hamming distance and the sum aggregation function, defined in Section 3.1.

50

fiThe Strategy-Proofness Landscape of Merging

are close to their own beliefs. In this paper, we focus on such an issue, which has to be
addressed in many everyday life situations. Let us illustrate this on an example:
Example 2 There is a position available in some university. The committee in charge
of the recruitment has to determine the right profile for this position. Four criteria are
considered: research skills, teaching skills, relationship skills, and the past positions of the
candidate. Suppose that a member of the committee believes that the important criteria for
the job are research skills and relationship skills, and that it is better to recruit a candidate
who got a good position in the past. She will be pleased by the recruitment if the group shares
her beliefs about the right profile. So she can be tempted to manipulate the merging process
in order to achieve such a situation.
Determining whether a belief/goal merging operator is strategy-proof, and in the negative case, identifying restrictions under which strategy-proofness can be ensured is thus an
important issue. Indeed, merging operators are intended to characterize the beliefs/goals
of a group of agents, from the beliefs/goals of each agent from the group; obviously, this
objective cannot be reached if the agents do not report their true beliefs/goals, which
can easily be the case when manipulable merging operators are used (since agents will be
tempted to manipulate the process in such a case).
Since merging operators are typically used in artificial systems, one can wonder whether
strategy-proofness is really a relevant issue in this context. The answer actually depends
on the sophistication of the agents under consideration. Thus, in a distributed database
setting, the (low-level) agents (i.e., the databases) have typically no evaluation/preference
on the merged base, and the strategy-proofness issue does not make sense. It is not the
same story when the agents have goals and reasoning capacities. In this case, it cannot be
discarded that some agents will be able to foresee weakenesses in the aggregation process
and to exploit them for their own benefits. When high-level artificial agents are involved,
the strategy-proofness problem is even more stricking than in the case of human agents
because of the superior computational abilities of artificial systems.
The strategy-proofness issue has been studied for years in the domain of Social Choice
Theory (Arrow, Sen, & Suzumura, 2002). An important objective is to design preference
aggregation procedures (and, in particular, voting procedures) which are strategy-proof. A
very famous result, known as Gibbard-Sattherwaite theorem, is that this objective cannot
be reached in an absolute manner: under a number of sensible requirements, no strategyproof voting procedure may exist (Gibbard, 1973; Satterthwaite, 1975). Strategy-proofness
can only be achieved by relaxing some of those requirements, which is enough to escape
from Gibbard-Sattherwaite theorem. We shall return to this topic in Section 7 where the
connections between belief merging and preference aggregation will be considered in more
depth.
The very objective of this paper is to draw the strategy-proofness landscape for many
merging operators from the literature, including model-based ones and formula-based ones.
We focused on operators for merging bases that are sets of propositional formulas, where no
priorities between the bases are available. The (classical) propositional logic framework can
be argued as a representation setting expressive enough for many AI scenarios; furthermore,
it is natural to investigate first the key problems raised by aggregation and manipulation in
this simple setting, before considering more sophisticated logics. For each operator under
51

fiEveraere, Konieczny & Marquis

consideration, we aim at determining whether it is strategy-proof in the general case, and
under some restrictions on the merging process (including the number of agents and the
presence of integrity constraints) and on the set of available strategies for the agents.
The rest of the paper is organized as follows. In Section 2, some formal preliminaries are
provided. In Section 3, the definitions of the main propositional merging operators from the
literature are recalled. Several definitions of strategy-proofness based on a general notion of
satisfaction index are given in Section 4 and our strategy-proofness results are reported in
Section 5. They are discussed in Section 6. Then, connections with Social Choice Theory
and other related works are pointed out in Section 7, just before the conclusion. Proofs are
reported at the end of the paper.

2. Formal Preliminaries
We consider a propositional language L defined from a finite (and non-empty) set of propositional variables P and the standard connectives, including >, the Boolean constant always
true, and , the Boolean constant always false.
An interpretation (or world)  is a total function from P to {0, 1}, denoted by a bit
vector whenever a strict total order on P is specified. The set of all interpretations is noted
W. An interpretation  is a model of a formula   L if and only if it makes it true in the
usual truth functional way.
[] denotes the set of models of formula , i.e., [] = {  W |  |= }. In order to
avoid too heavy notations, we identify each interpretation  with the canonical term on P
which has  as its unique model. For instance, if P = {a, b} and (a) = 1, (b) = 0,  is
identified with the term a  b.
A formula  from L is consistent if and only if [] 6= .  is a logical consequence of a
formula , noted  |=  if and only if []  []. Two formulas are logically equivalent ()
if and only if they share the same models.
A belief/goal base K denotes the set of beliefs/goals of an agent. It is a finite and
consistent set of propositional formulas, interpreted conjunctively.VWhen K is a belief/goal
b denotes the singleton base containing the conjunction K of all formulas from
base, K
K. A base is said to be complete if and only if it has exactly one model. Each belief/goal
base K characterizes a bipartition of the set of all interpretations: the models of K are the
interpretations which are acceptable for the agent, and the countermodels are not. When
K is a belief base, an interpretation  is acceptable when there is enough evidence that  is
the true state of the world; when K is a goal base,  is acceptable when it is sufficiently
desired. Such a bipartition can be considered as an approximation of the full belief/goal
preference structure of the corresponding agent: in the belief case,  is at least as preferred
as  0 means that the fact that  is the true state of the world is at least as plausible as
the fact that  0 is the true state of the world; in the goal case,  is at least as preferred as
 0 means that the fact that  would be the true state of the world is at least as desired
as the fact that  0 would be the true state of the world.
A belief/goal profile E is associated with the group of n agents involved in the merging
process. It is a non-empty multi-set (bag) of belief/goal bases E = {K1 , . . . , Kn } (hence
different agents are allowed to exhibit identical bases). Note that profiles are non-ordered
(multi-)sets; thus, the profile representation of groups of agents induces an anonymity prop52

fiThe Strategy-Proofness Landscape of Merging

erty: each agent has the same importance as the other agents of the group and the result
of the merging process only depends on the bases themselves (i.e., exchanging the bases of
two agents gives the same profile, hence the same merged base).
V
V
V
WeVdenote by E the conjunction
of
bases
of
E
=
{K
,
.
.
.
,
K
},
i.e.,
E
=
(
1
n
W
W
V K1 ) 
. . .  (V Kn ), and we denote by E the disjunction of bases of E, i.e., E = ( K1 ) 
. . .  ( Kn ).
V
A profile E is said to be consistent if and only if E is consistent. The multi-set union
is noted t and the multi-set containment relation is noted v. The cardinal of a finite set
(or a finite multi-set) A is noted #(A).  will denote set containment and  strict set
containment, i.e., A  B if and only if A  B and A 6= B.
If E denotes a pre-order on W (i.e., a reflexive and transitive relation), then <E denotes
the associated strict ordering defined by ,  0  W,  <E  0 if and only if  E  0 and
 0 6E .
The result of the merging of (the bases from) a profile E with the merging operator 4,
under the integrity constraints  is the base, noted 4 (E), called the merged base. The
integrity constraints consist of a consistent formula (or, equivalently, a (finite) consistent
conjunction of formulas) the merged base has to satisfy (it may represent some physical laws,
some norms, etc.); in other words, models of the merged base are models of the integrity
constraints.

3. Merging Operators
We recall in this section the two main families of merging operators from the literature. The
first family is defined by a selection of some interpretations (model-based operators). The
second family is defined by a selection of some formulas in the union of the bases (formulabased operators). For more details on those two families, see for example (Konieczny, Lang,
& Marquis, 2004).
3.1 Model-Based Operators
The first family is based on the selection of some models of the integrity constraints, the
closest ones to the profile. Closeness is usually defined from a notion of distance and an
aggregation function (Revesz, 1997; Konieczny & Pino Perez, 1998, 1999; Lin & Mendelzon,
1999; Liberatore & Schaerf, 1998).
Definition 1 (pseudo-distances)
 A pseudo-distance between interpretations is a total function d : W  W 7 R+ s.t.
for any ,  0 ,  00  W: d(,  0 ) = d( 0 , ), and d(,  0 ) = 0 if and only if  =  0 .
 A distance between interpretations is a pseudo-distance that satisfies the triangular
inequality: ,  0 ,  00  W, d(,  0 )  d(,  00 ) + d( 00 ,  0 ).
Two widely used distances between interpretations are Dalal distance (Dalal, 1988),
denoted dH , that is the Hamming distance between interpretations (the number of propositional atoms on which the two interpretations differ); and the drastic distance, denoted
53

fiEveraere, Konieczny & Marquis

dD , that is one of the simplest pseudo-distances one can define: it gives 0 if the two interpretations are the same one, and 1 otherwise.
Definition 2 (aggregation functions) An aggregation function f is a total function associating a nonnegative real number to every finite tuple of nonnegative real numbers s.t.
for any x1 , . . . , xn , x, y  R+ :
 if x  y, then f (x1 , . . . , x, . . . , xn )  f (x1 , . . . , y, . . . , xn ).

(non-decreasingness)

 f (x1 , . . . , xn ) = 0 if and only if x1 = . . . = xn = 0.
 f (x) = x.

(minimality)
(identity)

Widely used functions are the max (Revesz, 1997; Konieczny & Pino Perez, 2002), the
sum  (Revesz, 1997; Lin & Mendelzon, 1999; Konieczny & Pino Perez, 1999), or the
leximax GM ax (Konieczny & Pino Perez, 1999, 2002).
The chosen distance between interpretations induces a distance2 between an interpretation and a base, which in turn gives a distance between an interpretation and a profile,
using the aggregation function. This latter distance gives the needed notion of closeness represented by a pre-order on W induced by E, noted E . Such a pre-order can be interpreted
as a plausibility ordering associated with the merged base.
Definition 3 (distance-based merging operators) Let d be a pseudo-distance between
interpretations and f be an aggregation function. The result 4d,f
 (E) of the merging of E
given the integrity constraints  is defined by:
0
0
[4d,f
 (E)] = min([], E ) = {  [] | @  [],  <E }

where the pre-order E on W induced by E is defined by:
  E  0 if and only if d(, E)  d( 0 , E), where
 d(, E) = fKE (d(, K)), where
 d(, K) = min0 |=K d(,  0 ).
Observe that dd,f (, E) would be a more correct notation than d(, E); however, since
there is no ambiguity in the choice of the function f and the distance between interpretations
d in the following, we prefer the lighter notation d(, E).
Let us step back to the example given in the introduction in order to illustrate modelbased merging operators:
Example 3 Consider the set P with three propositional variables l(long period), s(easide)
and m(ountains), taken in this order. The goals of the three agents are then given by the
following bases: [K1 ] = {000, 001, 111} (Maries wishes), [K2 ] = {001, 110} (Alains wishes)
and [K3 ] = {000, 110} (Pierres wishes). There is no integrity constraint (  >).
2. Abusing words since it is not a distance from the mathematical standpoint.

54

fiThe Strategy-Proofness Landscape of Merging

We have [dH , ({K1 , K2 , K3 })] = {000, 001, 110}. Table 1 gives some details of the
computation. The first column gives all possible words. The Ki (i = 1 . . . 3) columns give
for each interpretation  the value dH (, Ki ). Finally, the rightmost column gives for
each interpretation  the value of dH (, {K1 , K2 , K3 }). The interpretations  for which
dH (, {K1 , K2 , K3 }) is minimal (in bold) are the models of the merged base dH , ({K1 , K2 ,
K3 }).

000
001
010
011
100
101
110
111

K1
0
0
1
1
1
1
1
0

K2
1
0
1
1
1
1
0
1

d

>H

K3
0
1
1
2
1
2
0
1

,

({K1 , K2 , K3 })
1
1
3
4
3
4
1
2

Table 1: Merging with dH , .

3.2 Formula-Based Operators
The other main family of merging operators gather the so-called formula-based operators
or syntax-based operators. Formula-based operators are based on the selection of consistent subsets of formulas in the union of the bases of the profile E. Several operators are
obtained by letting vary the selection criterion. The result of the merging process is the
set of consequences that can be inferred from all selected subsets (Baral, Kraus, Minker, &
Subrahmanian, 1992; Rescher & Manor, 1970; Konieczny, 2000). For these operators, the
syntactic form of the bases may easily influence the result of the merging process: replacb = {1  . . .  n } may
ing a base K = {1 , . . . , n } by the (logically equivalent) base K
lead to change the corresponding merged base (while this is not the case for model-based
operators).
Definition 4 (maximal consistent subsets) Let K be a base and  be an integrity constraint. maxcons(K, ) is the set of all the maximal (w.r.t. set inclusion) consistent
subsets (maxcons for short) of K  {} that contains , i.e., maxcons(K, ) is the set of
all consistent M that satisfy:
 M  K  {}, and
   M , and
 If M  M 0  K  {}, then M 0 is not consistent.
When maximality must be taken with respect to cardinality (instead of set inclusion), we
shall use the notation maxconscard (K, ).
Now, for any profile E and integrity constraint , we set
[
maxcons(E, ) = maxcons(
Ki , )
Ki E

55

fiEveraere, Konieczny & Marquis

Observe that set-theoretic union (and not multi-set union) is used here.
The following operators have been defined so far (Baral, Kraus, & Minker, 1991; Baral
et al., 1992; Konieczny, 2000):
Definition 5 (formula-based merging operators) Let E be a profile and let  be an
integrity constraint:
W
V
 4C1
 (E) 
M maxcons(E,) ( M ).
V
W
 4C3
 (E) 
M |M maxcons(E,>) and M {} consistent ( M ).
W
V
 4C4
 (E) 
M maxconscard (E,) ( M ).
V
 W
 M maxcons(E,>) and M {} consistent ( {M  {}})
 4C5
if consistent,
 (E) 

 otherwise.
Those operators clearly select as much formulas as they can from the union of the bases,
under the consistency requirement. The differences between them lie in the meaning of
as much. Those operators were defined by Baral et al. (1992), except 4C5 which is a
modification of 4C3 that ensures consistency. Indeed, unlike the other operators listed here,
C2 operator
4C3
 may generate inconsistent merged bases (as the empty disjunction). A 4
has also been introduced by Baral et al. (1992), and shown equivalent to 4C1 (this is why
it is not listed above). An important drawback of those operators is that they do not take
account for the sources from which the formulas are issued.3 Nevertheless, they have an
appealing, simple definition.
To illustrate the behaviour of formula-based operators, let us step back to the example
given in the introduction. Since the absence of constraints makes the operators 4C1 , 4C3
and 4C5 coincide, we shall add the following constraint:  = l  s, i.e., it turns out that
the group will have to take holidays for a long period and that they cannot go to the seaside.
Example 4 Suppose that Marie, Alain and Pierres goals are encoded by the following
bases: K1 = {l  s, l  m}, K2 = {l  s, s  m}, and K3 = {l  s, m}. With the
integrity constraints  = l  s, maxcons(E, ) contains two sets: {l  m, s  m} and
C3
C4
C5
{m}. We get 4C1
 (E)  , 4 (E)  , 4 (E)  l  s  m, and 4 (E)  .
The syntax sensitivity of those operators is due to the fact that the comma symbol
, which appears in the expression of the bases, is a specific, yet not truth-functional,
connective (Konieczny, Lang, & Marquis, 2005) that is usually not equivalent to standard
conjunction in the formula-based framework. Such operators may easily lead to merged
bases which differ from their counterparts where commas are replaced by conjunctions in
the input bases. For example, with  = >, K1 = {a  b}, K2 = {(a  b)} and K10 =
C1
0
{a, b}, the fact that K10  K1 does not imply that 4C1
 ({K1 , K2 })  4 ({K1 , K2 }), since
C1
C1
0
4 ({K1 , K2 })  > and 4 ({K1 , K2 })  a  b. See (Konieczny et al., 2005) for a more
3. It is possible to avoid it by taking advantage of a further selection function (Konieczny, 2000).

56

fiThe Strategy-Proofness Landscape of Merging

detailed discussion on the meaning of the comma connective in frameworks for reasoning
under inconsistency.
b the singleton base containing the
Clearly enough, if one replaces each base K by K,
b
conjunction of its elements before making the union, the resulting operators, noted 4C
 , are
not any longer sensitive to the syntactic presentation of the bases (replacing every base by
a logically equivalent one leads to the same merged base). Formally, we have:
Definition 6 (other formula-based merging operators) Let E = {K1 , . . . , Kn } be a
profile and let  be an integrity constraint:
c
Ci c
c
4Ci
 (E) = 4 ({K1 , . . . , Kn }).

Remark 1 Observe that 4C4 is equivalent to the model-based operator dD , = dD ,GM ax .
c
Indeed, 4C4 returns the disjunction of the maximal (for cardinality) consistent subsets of
the profile under the constraints. This is exactly what the operator dD , = dD ,GM ax
achieves since it amounts to define the set of models of the merged base as the set of interpretations that satisfy the constraints and a maximal number of bases of the profile, i.e.,
the interpretations that are models of a maximal (for cardinality) consistent subset of the
profile under the constraints.
c

4. Strategy-Proofness
The strategy-proofness issue for a merging operator can be stated as follows: is it possible
for a given agent to improve the result of the merging process with respect to her own
point of view by lying on her true beliefs/goals, given that she knows the beliefs/goals of
each agent of the group and the way beliefs/goals are merged? If this question can be
answered positively, then the operator is not strategy-proof (the agent may benefit from
being untruthful). Thus, a merging operator is not strategy-proof if one can find a profile
E = {K1 , . . . , Kn } which represents the bases of the other agents, an integrity constraint ,
and two bases K and K 0 s.t. the result of the merging of E and K 0 is better for the agent
than the result of the merging of E with her true base K (called the initial base).
Definition 7 (strategy-proofness) Let i be a satisfaction index, i.e., a total function
from L  L to IR.
 A profile E is said to be manipulable by a base K for i given a merging operator  and
an integrity constraint  if and only if there exists a base K 0 such that i(K,  (E t
{K 0 })) > i(K,  (E t {K})).
 A merging operator  is strategy-proof for i if and only if there are no integrity
constraint  and profile E = {K1 , . . . , Kn } such that E is manipulable for i.
Given two bases (interpreted conjunctively) K, K , the value of i(K, K ) is intended to
indicate how much a base K is close to the merged base K . The need for such satisfaction
indexes comes from the fact that the only information given by each agent is her own base
K: if the full preference structure over sets of interpretations were available for each agent
57

fiEveraere, Konieczny & Marquis

as an additional input (e.g., under the form of a utility function), then one could use it to
define strategy-proofness directly for a given agent (as it is done in Social Choice Theory,
Arrow et al., 2002) and not in a uniform way for all agents. This explains why we call i a
satisfaction index and not a utility function.
Clearly, there are many different ways to define the satisfaction of an agent given a
merged base. While many ad hoc definitions can be considered, we consider the following
three indexes which are, according to us, the most meaningful ones when no additional
information about the agents are available. As far as we know, this is the first time such
indexes are considered in the context of pure propositional merging.
The first two indexes are drastic ones: they range to {0, 1}, so the agent is either fully
satisfied or not satisfied at all.
Definition 8 (weak drastic index)

1
idw (K, K ) =
0

if K  K is consistent,
otherwise.

This index takes value 1 if the result of the merging process (noted K in the definition) is consistent with the agents base (K), and 0 otherwise. It means that the agent is
considered fully satisfied as soon as its beliefs/goals are consistent with the merged base.
Definition 9 (strong drastic index)

ids (K, K ) =

1
0

if K |= K,
otherwise.

This index takes value 1 if the agents base is a logical consequence of the result of the
merging process, and 0 otherwise. In order to be fully satisfied, the agent must impose her
beliefs/goals to the whole group.
The last index is not a Boolean one, leading to a more gradual notion of satisfaction.
The more compatible the merged base with the agents base the more satisfied the agent.
The compatibility degree of K with K is the (normalized) number of models of K that
are models of K as well:
Definition 10 (probabilistic index) If #([K ]) = 0, then ip (K, K ) = 0, otherwise:
ip (K, K ) =

#([K]  [K ])
.
#([K ])

ip (K, K ) is the probability to get a model of K from a uniform sampling in the models
of K . This index takes its minimal value when no model of K is in the models of the
merged base K , and its maximal value when each model of the merged base is a model of
K.
Strategy-proofness for these three indexes are not independent notions:
Theorem 1
1. If a merging operator is strategy-proof for ip , then it is strategy-proof for idw .
58

fiThe Strategy-Proofness Landscape of Merging

2. Consider a merging operator  that generates only consistent bases.4 If it is strategyproof for ip , then it is strategy-proof for ids .
On the other hand, it is easy to prove that strategy-proofness for idw and strategyproofness for ids are logically independent in the general case (an operator can be strategyproof for one of them without being strategy-proof for the other, and it can be strategy-proof
for both of them or for neither).
Let us conclude this section with our running example, and give formal arguments
explaining how Marie can manipulate the merging process:
Example 5 We consider three bases [K1 ] = {000, 001, 111} (Maries wishes), [K2 ] =
{110, 001} (Alains wishes) and [K3 ] = {110, 000} (Pierres wishes). There is no constraint
(  >).
dH ,
({K1 , K2 , K3 })] = {000, 001, 110} and ids (K1 , d>H , ({K1 , K2 , K3 })) = 0.
[>
If Marie reports [K10 ] = {000, 001} instead of K1 , then [d>H , ({K10 , K2 , K3 })] = {000,
001} and ids (K1 , d>H , ({K10 , K2 , K3 })) = 1.
See Table 2 for details of the computations.

000
001
010
011
100
101
110
111

K1
0
0
1
1
1
1
1
0

K10
0
0
1
1
1
1
2
2

K2
1
0
1
1
1
1
0
1

K3
0
1
1
2
1
2
0
1

d

>H

,

({K1 , K2 , K3 })
1
1
3
4
3
4
1
2

d

>H

,

({K10 , K2 , K3 })
1
1
3
4
3
4
2
4

Table 2: dH , is not strategy-proof for ids .
In the rest of this paper, we shall focus on those three indexes, idw , ids and ip . Note
that investigating other indexes can be interesting. In particular, the probabilistic index
can be viewed as a rough measure of similarity between the bases. Could more complex
similarity measures between sets (see e.g., Tversky, 2003) also prove useful to define other
sensible indexes is an interesting question that we let for further research.

5. Strategy-Proofness Results
In the general case, both the family of model-based operators and the family of formulabased operators are not strategy-proof for the three indexes we consider. This means that
there are operators from those families which are not strategy-proof. However, imposing
further restrictions may lead to some strategy-proofness results. Considering them in a
systematic way allows us to draw the strategy-proofness landscape for both families.
In the following, we consider four natural restrictions for the merging process, as listed
below:
4. I.e.,  (E) is always consistent.

59

fiEveraere, Konieczny & Marquis

 A first restriction concerns the number of bases to be merged. The question is the
following: does the number of bases involved in the merging process have an influence
on the strategy-proofness of an operator? In general, we can answer positively to
this question. More precisely, there is a distinction between the cases #(E) = 2 and
#(E) > 2. In some situations, no manipulation is possible with two bases, while
with more bases, it becomes possible. Since a base {>} typically plays the role of a
neutral element for all the operators we consider (i.e., 4 (E)  4 (E t{>})), if an
operator is not strategy-proof for profiles with n bases, then it is not strategy-proof
for profiles with m > n bases.
 A second parameter is the completeness of the beliefs/goals of the agent who aims at
manipulating. In some cases, having such strong beliefs/goals renders any manipulation impossible. Working with complete bases (i.e., singleton sets of models) makes
the merging process close to a uninominal vote, i.e., a vote for a unique interpretation.
 A third significant parameter is the presence of integrity constraints. On the one hand,
having nontrivial integrity constraints ( 6 >) can make a manipulation possible,
while it is not the case when no integrity constraints are considered, and the converse
also holds.
 Another restriction bears on the available manipulations. In the general case the untruthful agent is free to reporting any base, even if it is quite far from her true base.
However, there are numerous situations where the other agents participating to the
merging process have some information about her true base. In these cases, the agents
have to report some bases close to the real ones. Two particular manipulations will
be studied: erosion manipulation when the agent pretends to believe/desire more that
she does (the agent gives only some parts of its models); and dilatation manipulation
when the agent pretends to believe/desire less that she does (the agent gives only
parts of its countermodels).
5.1 Model-Based Operators
The first result is that there is no general strategy-proofness result (i.e., for any aggregation
function and any distance) for model-based operators. This is not very surprising when
one reminds the existence of Gibbard-Satterthwaite theorem, which states that there is no
good strategy-proof preference aggregation method (see Section 7).
However, some quite general strategy-proofness results can be obtained. The following
theorem gives some of them, organized from the most general one (for any aggregation
function when the drastic distance dD is considered), to more specific ones (for any distance
d when the aggregation function is ):
Theorem 2
 Let f be any aggregation function. dD ,f is strategy-proof for ip , idw and ids .
 Let d be any distance. Provided that only two bases are to be merged, d,
> is strategyproof for the indexes idw and ids .
60

fiThe Strategy-Proofness Landscape of Merging

 For any distance d, d,
is strategy-proof for the indexes ip , idw and ids when the

initial base K is complete.
It is interesting to note that dD , (which coincides with dD ,GM ax ) is close to a voting
procedure called approval voting (Brams & Fishburn, 1983), where each agent can vote for
(approve) as many candidates as she wants, and the elected candidates are the ones who
get the greatest number of votes.
As shown by the running example, the family of merging operators dH ,f obtained
by considering the Hamming distance and letting the aggregation function f vary is not
strategy-proof. Let us now focus on this family, and consider successively the two operators
obtained by considering  and GM ax as aggregation functions.
As to dH , , the number of bases, the presence of integrity constraints and the completness of the bases are significant. For this operator, the next theorem makes precise the
boundaries between strategy-proofness and manipulation (in the following properties, K
represents the initial base and #(E) the number of bases in the profile E):
Theorem 3
 dH , is strategy-proof for idw or ids if and only if (  > and #(E) = 2) or K is
complete.
 dH , is strategy-proof for ip if and only if K is complete.
In contrast to dH , , dH ,GM ax is not strategy-proof even in very restricted situations:
Theorem 4
 dH ,GM ax is not strategy-proof for the satisfaction indexes idw and ip (even if   >,
K is complete and #(E) = 2).
 dH ,GM ax is strategy-proof for the satisfaction index ids if and only if   >, K is
complete and #(E) = 2.
5.2 Formula-Based Operators
C3
C4
For the probabilistic index, none of the formula-based operators 4C1
 , 4 , 4 , and
C5
4 is strategy-proof. But, for the two drastic indexes, there are some situations where
strategy-proofness can be ensured:

Theorem 5
C3
C4
C5
 4C1
 , 4 , 4 , and 4 are not strategy-proof for ip (even if   >, K is complete
and #(E) = 2).

 4C1
 is strategy-proof for idw and ids .
 4C3
 is strategy-proof for idw and ids if and only if   >.
 4C4
 is not strategy-proof for idw and ids (even if   >, K is complete and #(E) = 2).
61

fiEveraere, Konieczny & Marquis

 4C5
 is strategy-proof for idw if and only if   > or K is complete, and is strategyproof for ids if and only if   >.
C3
C4
C5
For the other formula-based merging operators 4C1
 , 4 , 4 , 4 , the results are
more balanced, with more strategy-proofness results:
c

c

c

c

Theorem 6
 4C1
 is strategy-proof for idw and ids , and is strategy-proof for ip if and only if
#(E) = 2.
c

 4C3
 is strategy-proof for idw and ids if and only if   >, and is strategy-proof for ip
if and only if #(E) = 2 and   >.
c

 4C4
 is strategy-proof for ip , idw and ids .
c

 4C5
 is strategy-proof for idw if and only if #(E) = 2 or   > or K is complete.
c

C5
4C5
 is strategy-proof for ids if and only if #(E) = 2 or   >. Finally, 4 is
strategy-proof for ip if and only if #(E) = 2.
c

c

5.3 Ensuring Strategy-Proofness: The Case of Complete Bases
Let us now focus on a very specific case: the situation where every base is complete. While
this situation is rather infrequent when dealing with usual belief bases, it can be imposed
in a goal merging setting, especially if it guarantees strategy-proofness. This explains why
we consider such a case in this paper. As said above, it is also interesting because of the
relationship with uninominal voting systems if one interprets each complete base as a vote
for the corresponding interpretation.
Theorem 7 The strategy-proofness results reported in Table 3 hold, under the restriction
that each base is complete (f stands for any aggregation function, and d for any distance).
sp means strategy-proof , sp means non strategy-proof  even if #(E) = 2 and   >,
sp means non strategy-proof  even if either #(E) = 2 or   >, but strategy-proof  if
both #(E) = 2 and   >. Finally, sp> means non strategy-proof  even if #(E) = 2, but
strategy-proof  whenever   >.
As Theorem 7 shows, no operator among the dH ,GM ax and the 4C
 ones ensures
full strategy-proofness in the restricted case where two complete bases are merged and
no integrity constraint is considered. Contrastingly, all the other operators offer strategyproofness for the three indexes whenever every base is complete.
5.4 Dalal Index
As explained before, the fact that ip is based on model counting allows some form of
graduality in the corresponding notion of satisfaction, and this contrasts with the drastic
indexes. Actually, other non drastic indexes can be defined. In particular, in cases where
the agent knows that the result could not fit her beliefs/goals (e.g., if her beliefs/goals are
62

fiThe Strategy-Proofness Landscape of Merging



ip

idw

ids

dD ,f
d,

dH ,GM ax

4C1

4C3

4C4

4C5

c
4C1

c
4C3

c
4C4

c
4C5


sp
sp
sp
sp
sp
sp
sp

sp
sp
sp
sp
sp>
sp
sp

sp
sp
sp
sp
sp>
sp
sp>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

Table 3: Strategy-proofness: complete bases
.
not consistent with the integrity constraints), she still can be interested in achieving a result
that is close to her beliefs/goals. Closeness can be captured by a notion of distance, and a
possible satisfaction index is the following Dalal index:
Definition 11 (Dalal index) iDalal (K, K ) = 1 

min({dH (,K ) | |=K})
.
#(P)

As far as we know, this index has never been carried out. For the sake of homogeneity
with previous indexes, the greater iDalal (K, K ) the more satisfied the agent associated
with K. iDalal grows antimonotonically with the Hamming distance between the two bases
under consideration, i.e., the minimal distance between a model of the first base and a
model of the second one. Thus, this index takes its minimal value when every variable must
be flipped to obtain a model of K from a model of K, while it takes its maximal value
whenever K is consistent with K (no flip is required).
A direct observation is that iDalal (K, K )  idw (K, K ), whatever the bases K and
K . Investigating the strategy-proofness of a profile E for the Dalal index given a merging
operator  and an integrity constraint  makes sense only in the situation K   (E) is
inconsistent. Indeed, in the remaining case, iDalal (K,  (E)) takes the maximal value 1
and no manipulation is possible.
In contrast to the three previous indexes we have considered, merging operators are not
strategy-proof for iDalal , even in very restricted situations.
Theorem 8 None of dD , , dD ,GM ax , dH , or dH ,GM ax is strategy-proof for iDalal ,
even in the restricted case where E consists of two complete bases.
C
Theorem 9 None of the 4C
 operators (hence, none of the 4 operators) is strategy-proof
for iDalal , even in the restricted case where E consists of two complete bases.
b

63

fiEveraere, Konieczny & Marquis

5.5 Restricted Strategies
There are situations where the other agents participating to the merging process have some
information about the bases of the other agents. For instance, in cooperative problem
solving, it can be decided that whenever an agent is able to answer a query within a
limited amount of time, she has to communicate it to the other agents. Contrastingly, the
communication protocol may force an agent to inform the other agents that she is definitely
not able to answer the query. Such information exchanges allow the other agents to get a
partial view of the models or the countermodels of the true beliefs/goals of the agent, and if
this conflicts with the reported beliefs/goals, the untruthful agent can be unmasked. That
is clearly a wrong thing for the untruthful agent since her opinion could then be ignored;
she can even be punished for her guilty behaviour.
We consider here two restrictions on available manipulations (and the corresponding
notions of strategy-proofness): erosion manipulation is when the agent pretends to believe/desire more that she does (the agent gives only some parts of its models); and dilatation manipulation is when the agent pretends to believe/desire less that she does (the agent
gives only parts of its countermodels).
Definition 12 (erosion and dilation)
 Erosion manipulation holds when the reported base K 0 is logically stronger than the
true one K: K 0 |= K
 Dilation manipulation holds when the reported base K 0 is logically weaker than the
true one K: K |= K 0 .
Erosion (resp. dilation) manipulation is safe for the untruthful agent when the other
agents may only have access to a subset of the countermodels (resp. models) of her true
beliefs/goals, while it is unsafe in general when the other agents may have access to a subset
of the models (resp. countermodels).
The next theorem gives the dilation strategy-proofness of model-based operators:
Theorem 10 Let d be a pseudo-distance and let f be an aggregation function. d,f
is

dilation strategy-proof for the indexes ip , idw and ids .
This result has to be compared with the ones in the unrestricted case (previous sections),
where most of the operators are not strategy-proof.
It is not the same story for erosion. One can easily find profiles that can be manipulated
using erosion manipulation (see the running example). Interestingly, focusing on erosion
strategy-proofness proves sufficient in some situations. Indeed, when d is any distance, 
is the aggregation function and any drastic index id are considered, d,
is strategy-proof

for id if and only if it is erosion strategy-proof for id :
Theorem 11 Let d be any distance. If d,
is not strategy-proof for the index idw (resp.

ids ), then it is not erosion strategy-proof for idw (resp. ids ).
This result has a corollary, showing that it it enough to focus on each complete base
that implies K to determine whether a profile E is manipulable by a base K for idw :
64

fiThe Strategy-Proofness Landscape of Merging

Corollary 12 A profile E is manipulable by K for idw (resp. ids ) given d,
 and  if and
only if the manipulation is possible using a complete base K |= K, i.e., there exists K |= K
d,
d,
s.t. idw (K, d,
 (E t {K })) > idw (K,  (E t {K})) (resp. ids (K,  (E t {K })) >
d,
ids (K,  (E t {K}))).

6. Discussion
In this paper, we have drawn the strategy-proofness landscape for many merging operators,
including model-based ones and formula-based ones. While both families are not strategyproof in the general case, we have shown that several restrictions on the merging framework
or on the available strategies may lead to strategy-proofness.
As to model-based operators, the choice of a right distance appears crucial. Thus,
model-based operators are strategy-proof when based on the drastic distance, while they
are typically not strategy-proof when based on Dalal distance.
Among formula-based merging operators 4C1
 achieves the highest degree of strategyproofness in the sense that it is strategy-proof for the drastic indexes.
Most of the results are summed up in Table 4 (sp means strategy-proof and sp means
not strategy-proof). For space reasons, the results on restricted strategies are not reported
there (see Section 5.5), as well as the ones concerning complete bases (see Table 3).
From the derived results, it appears that strategy-proofness is easier to achieve with
formula-based operators than with model-based ones, especially when the bases are singlec
tons (i.e., with the 4Ci operators). This could be explained by the fact that the latter
operators obey an all-or-nothing principle  a base is either selected as a whole (and included as such in a maxcons) or it is not selected at all  and this may forbid some subtle
manipulations.
We have also exhibited some restricted strategies that constrain the agent who wants
to manipulate. For example, all model-based operators are strategy-proof for dilation.
Most of the results of this paper are based on three satisfaction indexes, that are,
according to us, the most natural ones when no additional information about the merging
process is available. These three indexes share the property that if two bases are jointly
inconsistent, then the satisfaction is minimal. We call it the consistency property. In
order to handle scenarios where the consistency property is not discriminant enough, we
introduced the Dalal index. It turns out that none of the operators considered in the paper
is strategy-proof for this index.
The choice of a satisfaction index has (by definition) a major impact on the existence
of manipulation. As explained before, if the full preferences of all the agents over sets of
interpretations were available, strategy-proofness could be easily defined as in Social Choice
Theory: a manipulation occurs if and only if the merged base obtained when the agent lies
is strictly preferred (w.r.t. her own preference) to the the merged base obtained when she
reports her true base. When such information are not available, several choices for an
index are possible, capturing different intuitions.
When beliefs are to be merged, indexes satisfying the consistency property seem more
suited than the remaining ones; indeed, for the latter indexes, even if a merged base is close
to the agents beliefs, it is still not compatible with them. Drawing such a conclusion is not
so easy when goals are to be merged, since for instance, it can be the case that for some
65

fiEveraere, Konieczny & Marquis

i

#(E)

K



d

D

,f

d

H

,

d

H

,Gmax

4C1


4C3


4C4


4C5


4C1


4C3


4C4


4C5


c

c

c

c

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>
not
complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>
not
complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>
not
complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>
not
complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>
not
complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>
not
complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

complete
=2

ip
complete
>2

complete
=2

idw
complete
>2

complete
=2

ids
complete
>2

Table 4: Synthesis of the results.

66

fiThe Strategy-Proofness Landscape of Merging

agents, the more goals satisfied, the better. Nevertheless, our three satisfaction indexes idw ,
ids and ip are still meaningful in such scenarios, since an agent is typically more satisfied if
the goals of the group are compatible with her own ones than if it is not the case.
In light of our study, strategy-proofness appears as a property independent of the computational complexity of query answering from a merged base (see Konieczny et al., 2004).
It means that having a low/high complexity does not prevent/imply strategy-proofness.
Strategy-proofness appears also independent of the fact that the operator satisfies the
rationality postulates given by Konieczny and Pino Perez (1999, 2002). Indeed, as a direct
consequence of Theorems 2 and 3, we have that some majority (resp. arbitration) merging
operators (Konieczny & Pino Perez, 2002) are strategy-proof, while others are not. Thus,
satisfying the rationality postulates for merging proves not sufficient to ensure strategyproofness or manipulability. Nevertheless, we can note that arbitration operators, like
d,GM ax , are more sensitive to manipulation than majority operators, like d, . This is
easily explained by the fact that arbitration operators are egalitarist ones: they aim at
giving a result that is close to each base of the profile. Intuitively, a small change in a
base can heavily change the whole result. Contrastingly, majority operators, that listen to
majority wishes for defining the merged base, often do not take into account bases that are
far from the majority. So, when using majority operators, it is likely that a small change
in a base has no impact on the merged base.
Thus, strategy-proofness can be viewed as a further dimension that can be used to
compare merging operators, besides the computational complexity and rationality criteria.
Its independence to the latter criteria may also explain why no strategy-proofness results
for wide families of operators seem to exist.

7. Related Work
As explained through this paper, the manipulation problem has been studied extensively
in Social Choice Theory for years. In the next subsection we will relate our work to this
stream of research. In a second subsection we mention some other related work concerning
the strategy-proofness issue for weighted bases.
7.1 Social Choice Theory
In the propositional merging framework considered in the paper, the beliefs/goals K of each
agent induce a two-strata partition of the interpretations: all the models of K are equally
preferred, and strictly preferred to its countermodels, which are equally disliked. When
agents report full preference relations (that can be encoded in various ways, e.g., explicitly,
or by a prioritized base, an ordinal conditional function, etc.), the aggregation problem
consists in defining a global preference relation from individual preference relations. This
problem has been addressed for centuries in Social Choice Theory. This can be traced back
at least to Condorcet (1785) and Borda (1781).
In Social Choice Theory (Arrow et al., 2002), the strategy-proofness problem has received great attention. In this framework, an agent A is untruthful when she reports a
preference relation (a complete pre-order over the set of alternatives) that is not the true
one. A social choice function (associating an alternative to a profile of such preference
relations) is not strategy-proof when the alternative chosen by the function when A lies
67

fiEveraere, Konieczny & Marquis

is ranked higher for A than the alternative chosen when she reports her true preferences.
One of the most famous result in Social Choice Theory is that there is no good strategyproof preference aggregation procedure. This result is known as Gibbard-Satterthwaite
impossibility theorem (Gibbard, 1973; Satterthwaite, 1975; Moulin, 1988).
Formally, consider a set of agents (individuals) N = {1, . . . , n}, and a set of alternatives
A = {a, b, . . .}. Each agent i has a preference relation on those alternatives, that is supposed
to be a complete, reflexive and transitive binary relation, noted i . A preference profile
P = (1 , . . . , n ) assigns a preference relation to each agent. Let us note P the set of
all possible preference profiles. A given preference profile can be noted P = (Pi , i ),
i  N , where Pi denotes the profile P without (the preferences of) individual i. A social
choice function f is a mapping from P to A. A social choice function is manipulable if
there is an individual i  N , a preference relation 0 , and a preference profile P such that
f (Pi , 0i ) >i f (P ), i.e., when there is an agent i that is best satisfied with the result when
she claims her preferences are 0i instead of her true preference i . If a social choice function
is not manipulable, it is said to be strategy-proof. A social choice function is dictatorial if
there is an individual i  N (the dictator), such that f (P ) i a for all a  A and for all
P  P. A social choice function is onto if for each alternative a  A there is a preference
profile P  P such that f (P ) = a. Then Gibbard-Satterthwaite theorem (Gibbard, 1973;
Satterthwaite, 1975) can be stated as:
Theorem 13 (Gibbard, 1973; Satterthwaite, 1975) If A contains at least three alternatives, then there is no social choice function f that is onto, strategy-proof and non-dictatorial.
Since this result has been stated, there has been a lot of work for deriving strategyproofness results under some restrictions (see Kelly, 1988; Arrow et al., 2002). In some
sense, our work is relevant to such approaches. Nonetheless, our work is original - as far as
we know - from two points of view: on the one hand, the preference relations considered
here are two-strata total pre-orders, and not arbitrary pre-orders; on the other hand, the
result of a merging process is usually not a single interpretation but still a two-strata total
pre-order (and the number of models of the merged base is not constrained a priori). This
leads to more complex notions of strategy-proofness where different definitions are possible,
depending on an index which formalizes one of the various intuitive notions of how satisfied
an agent is by the result of the merging process.
In social choice theory, there are also some works on social choice correspondences, that
are mapping from P to 2A , and that are closer to our framework than social choice functions. The data coming from individuals are preference relations on A, and the problem is
to shift them to preference relations on 2A . The standard way to achieve it is to consider
that even if a set is chosen by the correspondence, then ultimately only one alternative will
be realized, and to suppose that each individual has a subjective probability measure on
this realization. Then a social choice correspondance is strategy-proof if it is not possible
for an individual to increase her expected utility of the result. In this case, results similar to Gibbard-Satterthwaite theorems can be derived (see e.g., Barbera, Dutta, & Sen,
2001; Chin & Zhou, 2002; Duggan & Schwartz, 2000). These works are related to the one
conducted in this paper, but they all suppose that each agent makes available not only its
full preference relation on alternatives under the form of a utility function  typically not
reducible to a two-strata complete pre-order  but also its subjective probability measure
68

fiThe Strategy-Proofness Landscape of Merging

on alternatives. Contrastingly, in this work, the only information coming from each agent
is the corresponding base, which typically approximates her full preference relation, and is
of pure ordinal nature.
7.2 Strategy-Proofness for Weighted-Bases Merging
A study of strategy-proofness of some merging operators has been carried out by Meyer,
Ghose, and Chopra (2001). The framework they consider is distinct from the one used
in our work. On the one hand, agents may report full preference relations (encoded as
ordinal conditional functions, also called -functions, see Spohn, 1987). On the other hand,
the merging operators under consideration escape Gibbard-Satterthwaite theorem since
Meyer et al. (2001) make a commensurability assumption between the agents preference
relations (the same remark applies also to possibilistic base merging as defined by Benferhat,
Dubois, Kaci, & Prade, 2002). Roughly, this commensurability assumption amounts to
consider that the weights (or the levels) associated to formulas have the same meaning
for all the agents, i.e., that a weight 3 for agent 1 is the same that a weight 3 for agent
2. The commensurability assumption is sensible in many situations, but when dealing
with agents preferences, commensurability must be used carefully. For human agents, it
is commonly accepted in Social Choice Theory that this assumption is very strong. Arrow
(1963) illustrates this idea by quoting Bentham:
 This is vain to talk of adding quantities which after the addition will continue
distinct as they were before, one mans happiness will never be another mans
happiness: a gain to one man is no gain to another; you might as well pretend
to add 20 apples to 20 pears...
The notion of strategy-proofness and the merging operators of Meyer et al. (2001) and
Chopra, Ghose, and Meyer (2006) are defined in the framework of ordinal conditional functions. In this section, we study the corresponding operators in the pure propositional
framework, i.e., when the profile contains flat belief/goal bases, in order to compare them
with our approach.
An ordinal conditional function (OCF)  is a total function from the set of interpretations W to the set of non-negative integers (originally, an OCF maps an interpretation
to the class of ordinals, and is such that at least one interpretation is mapped to zero,
but considering integers is sufficient here). Intuitively, the greater the number, the less
credible the interpretation. To each OCF  one can associate a base Bel() defined as
[Bel()] = {  W | () = min0 W (( 0 ))}. The aim of OCF merging operators is,
from a profile of OCFs E = {1 , . . . , n } to define an OCF  (E) that best represents the
profile. The operators studied by Meyer et al. (2001) are the following ones:
 max (E)() = maxi E i (),

21 () if i () = j () for all i , j  E
 min1 (E)() =
2 mini E i () + 1 otherwise,

1 () if i () = j () for all i , j  E
 min2 (E)() =
mini E i () + 1 otherwise,
69

fiEveraere, Konieczny & Marquis

  (E)() =

P

i E

i ().

The straightforward way to translate the framework of propositional merging into ordinal conditional functions is to consider a propositional base as a special case of OCF: a
propositional base is a two-strata OCF, with the models of the bases having rank 0 and the
countermodels having rank 1. If we consider only two-strata OCFs i and note Ki = Bel(i )
and  = Bel( ), the previous definitions of merging operators give:
V
 max (E)  min2 (E)  E if consistent and max (E)  min2 (E)  > otherwise.
V
W
 min1 (E)  E if consistent and min1 (E)  E otherwise.
  (E)  dD , (E).
The resulting propositional merging operators max , min1 , min2 , and  are quite
simple and well-known. max (or equivalently min2 ) is the so-called basic merging operator (in absence of integrity constraints) (Konieczny & Pino Perez, 1999). min1 is the
1-quota operator defined by Everaere, Konieczny, and Marquis (2005) (without integrity
constraints).  corresponds to the intersection operator defined by Konieczny (2000).
All those operators are strategy-proof for our indexes:
Theorem 14 max , min1 , min2 , and  are strategy-proof for idw , ids and ip .
Besides those operators, Meyer, Chopra and Ghose also proposed general definitions of
strategy-proofness for OCF merging. More precisely, they have studied two properties. The
first one is the (IP) property (Meyer et al., 2001):
Definition 13 (IP) An OCF merging operator  satisfies the (IP) property if and only
if for every OCF profile E, for every agent i, we have whatever the OCF 
  W, | (E)()  i ()|  | (rep(E, {i}, )()  i ()|
where rep(E, {i}, ) is the profile identical to E except that the OCF i is replaced by .
Focusing on two-strata OCFs, we say that a merging operator (= Bel( )) is strategyproof for (IP) if and only if  satisfies the (IP) property for every agent given any profile.
We have obtained the following characterization:
Theorem 15  is strategy-proof for (IP) if and only if for every profile E and every pair
of bases K and K 0 :
 K  (E t {K}) |= (E t {K 0 }), and
 K  (E t {K}) |= (E t {K 0 }).
The second strategy-proofness property that Meyer, Chopra and Ghose have investigated is (WIP):
70

fiThe Strategy-Proofness Landscape of Merging

Definition 14 (WIP) An OCF merging operator  satisfies the (WIP) property if and
only if for every profile E, for every agent i, we have whatever the OCF :
W | (E)()  i ()|  W | (rep(E, {i}, )()  i ()|.
(WIP) is weaker than (IP) in the sense that if an OCF merging operator  satisfies
(IP) for an agent i, then  satisfies (WIP) for i (but the converse does not always hold).
Again, focusing on two-strata OCFs, we say that a merging operator (= Bel( )) is
strategy-proof for (WIP) if and only if  satisfies the (WIP) property for every agent
given any profile.
V
V
V
V
Let us note  the exclusive or operator, i.e., K  K 0 = ( K   K 0 )  ( K  K 0 ).
Then (WIP) can be characterized in our framework by :
Theorem 16 Let iwip (K, K ) =
if it is strategy-proof for iwip .

1
#([KK ])+1 .

 satisfies the (WIP) property if and only

Note that the wip index iwip is very close to the probabilistic index ip . The probabilistic index measures the closeness of the merged base to the agent base, whereas the wip
index measures the difference between the merged base and the agent base.
However, the corresponding notion of strategy-proofness (and a fortiori the one induced
by (IP)) appears too strong in the pure propositional setting. Consider the following belief
merging scenario:
Example 6 Consider K = a and K1 = b.We have dH , ({K, K1 })  a  b. If the
agent gives K 0 = {a  b} instead of K, then the merged base is dH , ({K 0 , K1 })  a.
Accordingly, this an example of manipulation for (WIP) (iwip (dH , ({K, K1 })) = 12 <
iwip (dH , ({K 0 , K1 })) = 1).
In this example, the untruthful agent actually manages to change the merged base to
one which is more similar to her initial base (with respect to iwip ). This is because she is
not fully satisfied by the merged base equivalent to a  b but still strictly prefers her initial
base {a}, despite the fact that a  b refines her own beliefs. Accordingly, such an agent
wants to preserve both her beliefs and her ignorance. In many scenarios when an agent
participates to a merging process in order to get new information, this is counter-intuitive.
Chopra et al. (2006) give more general definitions of strategy-proofness, by considering other
similarity relations. In the propositional case, they all suffer from the same above-mentioned
drawback. This explains why we did not investigate the strategy-proofness of the purely
propositional model-based operators and formula-based operators for criteria like (WIP)
or (IP).

8. Conclusion
Investigating the strategy-proofness of merging operators is important from a multi-agent
perspective whenever some agents can get the information conveyed by the other agents
participating to the merging process. When strategy-proofness is not guaranteed, it may be
questioned whether the result of the merging process actually represents the beliefs/goals
of the group.
71

fiEveraere, Konieczny & Marquis

In this paper, we have drawn the strategy-proofness landscape for many existing merging
operators, including model-based ones and formula-based ones, both in the general case and
under several natural restrictions. Strategy-proofness appears as independent of complexity
and rationality aspects, and can be used as such, as a further criterion to evaluate merging
operators. All those results have been discussed in Section 6.
This work calls for a number of perspectives. A first perspective is to identify the complexity of determining whether a profile can be manipulated by a base given an operator.
Indeed, using a merging operator that is not strategy-proof is not necessarily harmful if finding out a strategy is computationally hard. Such a complexity issue has been investigated for
voting schemes (Conitzer & Sandholm, 2003; Conitzer, Lang, & Sandholm, 2003; Conitzer
& Sandholm, 2002a, 2002b) when individual preferences are given explicitly (which is not
the case in our framework). A first result follows easily from Theorem 11: if the distance d
between interpretations can be computed in polynomial time in the input size (which is not
a strong assumption), determining whether a given profile can be manipulated by a base
p
for a drastic index given d,
 and  is in 2 .
In Social Choice Theory, the Gibbard-Sattertwhaite theorem states that every sensible
social choice function is manipulable. Taking into account the fact that the agents are
tempted to manipulate transforms the aggregation process into a game between agents.
For ensuring strategy-proofness, it can prove sufficient to build a game where telling the
truth is an optimal strategy for each agent. How to achieve it is the aim of implementation
theory (also called mechanism design), see e.g., Maskin & Sjostrom, 2002. A perspective
is to determine whether building such mechanisms is possible in a belief merging setting in
order to force the agents to tell the truth. Most of the work on mechanism design assume
transferable utility, and use payments as part as the process. Importing such ideas in a
fully qualitative framework surely is a hard task.
Another interesting perspective is to study the strategy-proofness problem when coalitions are allowed. Instead of considering manipulation by single agents, one can be interested in manipulation by coalition of agents who coordinate to improve the result for the
coalition. See (Meyer et al., 2001; Chopra et al., 2006) for such a definition in a different
framework. Since manipulation by a single agent is a particular case of manipulation by a
coalition, and since we have seen that many operators are not strategy-proof for a single
agent, it is clear that strategy-proofness results for coalitions will be very hard to achieve.

Acknowledgements
The authors would like to thank the anonymous referees for their thoughful comments which
helped us a lot to improve the paper. The authors have been supported by the Universite
dArtois, the Region Nord/Pas-de-Calais, the IRCICA Consortium, and by the European
Community FEDER Program.

72

fiThe Strategy-Proofness Landscape of Merging

Appendix A. Proofs
Theorem 1
1. If a merging operator is strategy-proof for ip , then it is strategy-proof for idw .
2. Consider a merging operator  that generates only consistent bases.5 If it is strategyproof for ip , then it is strategy-proof for ids .
Proof:
1. Assume that  is not strategy-proof for idw . Then there exists a profile E, a base
K, a base K 0 and an integrity constraint  s.t. (1)  (E t {K})  K is inconsistent,
#([K][ (Et{K})])
= 0. (2)
and (2)  (E t {K 0 })  K is consistent. (1) implies that #([ (Et{K})])
implies that

#([K][ (Et{K 0 })])
#([ (Et{K 0 })])

> 0. Hence,  is not strategy-proof for ip .

2. Assume that  is not strategy-proof for ids . Then there exists a profile E, a base
K, a base K 0 and an integrity constraint  s.t. (1)  (E t {K}) 6|= K, and (2)
#([K][ (Et{K})])
 (E t {K 0 }) |= K. (1) implies that #([ (Et{K})])
6= 1. (2) implies that
#([K][ (Et{K 0 })])
#([ (Et{K 0 })])

= 1 if  (E t {K 0 }) is consistent. Hence,  is not strategy-

proof for ip .


Theorem 2
 Let f be any aggregation function. dD ,f is strategy-proof for ip , idw and ids .
 Let d be any distance. Provided that only two bases are to be merged, d,
> is strategyproof for the indexes idw and ids .
 For any distance d, d,
is strategy-proof for the indexes ip , idw and ids when the

initial base K is complete.
Proof:
 Let f be any aggregation function. dD ,f is strategy-proof for ip , idw and ids .
The proof is organized in three steps: by reduction ad absurdum, we show that the
minimal drastic distance between a model of  and E t {K} is equal to the minimal
drastic distance between a model of  and E t {K 0 }. Then, it is easy to show that
the number of Ks models is greater in E t {K} than in E t {K 0 }. Finally, we prove
that the number of countermodels of K is greater in E t {K 0 } than in E t {K}, which
entails a contradiction.
5. I.e.,  (E) is always consistent.

73

fiEveraere, Konieczny & Marquis

From Theorem 1, we know that if any operator dD ,f is strategy-proof for ip , it is also
strategy-proof for both idw and ids (indeed, dD ,f (E) is always consistent). So it is
sufficient to prove the strategy-proofness of dD ,f for ip to prove its strategy-proofness
for the three indexes.
Let us prove it by reductio ad absurdum: assume that there is an operator dD ,f , where
dD is the drastic distance and f is any aggregation function, that is not strategy-proof
for ip . Then there exist an integrity constraint , a profile E, and two bases K and
K 0 s.t. ip (K, dD ,f ({K} t E)) < ip (K, dD ,f ({K 0 } t E)), which is equivalent to
#([K]  [E 4dD ,f K])
#([E 4dD ,f K])

<

#([K]  [E 4dD ,f K 0 ])
#([E 4dD ,f K 0 ])

where E 4dD ,f K is a light notation for dD ,f ({K} t E)). Let us note dmin (E tdD ,f
{K}) = min({dD (, E t {K}) |  |= }, ). We now show that dmin (E tdD ,f {K}) =
dmin (E tdD ,f {K 0 }):
 Let us first notice that we have ip (K, E 4dD ,f K) 6= 1: if ip (K, E 4dD ,f K) = 1,
then the probabilistic satisfaction index takes its maximal value, so it is impossible to increase it.
Since ip (K, E 4dD ,f K) < 1, we have that #([K][E 4dD ,f K]) < #([E 4dD ,f K]),
so at least one model of E 4dD ,f K does not belong to K:
1 |= (K)  , dD (1 , E t {K}) = dmin (E tdD ,f {K}).
Since 1 |= (K)  , we have dD (1 , K) = 1 and this distance is maximal
(because we use the drastic distance). We get immediately that dD (1 , K) 
dD (1 , K 0 ). Hence dD (1 , E t{K})  dD (1 , E t{K 0 }) (because the aggregation
function f satisfy non-decreasingness). Since dD (1 , E t {K}) = dmin (E tdD ,f
{K}), we get dmin (E tdD ,f {K})  dD (1 , E t {K 0 }). Since dD (1 , E t {K 0 }) 
dmin (E tdD ,f {K 0 }) by definition of min and since 1 |= , we have
dmin (E tdD ,f {K})  dmin (E tdD ,f {K 0 }) ().
 We can also conclude that ip (K, E 4dD ,f K 0 ) 6= 0: if ip (K, E 4dD ,f K 0 ) = 0, then
ip (K, E 4dD ,f K 0 ) is minimal, so the value taken by ip has not increased, and
this contradicts the assumption (manipulation).
If ip (K, E 4dD ,f K 0 ) 6= 0, then we can find at least one model of K   in
E 4dD ,f K 0 : 1 |= K , dD (1 , E t{K 0 }) = dmin (E tdD ,f {K 0 }). Since 1 |= K,
we have dD (1 , K) = 0 and since this distance is minimal, we get dD (1 , E t
{K})  dD (1 , E t {K 0 }), and then dD (1 , E t {K})  dmin (E tdD ,f {K 0 }),
because dD (1 , E t {K 0 }) = dmin (E tdD ,f {K 0 }). Furthermore, since dD (1 , E t
{K})  dmin (E tdD ,f {K}) by definition of min and because 1 |= , we have:
dmin (E tdD ,f {K})  dmin (E tdD ,f {K 0 }) ().
74

fiThe Strategy-Proofness Landscape of Merging

From the inequations (*) and (**), we get:
dmin (E tdD ,f {K}) = dmin (E tdD ,f {K 0 }).

(1)

Let us show now that we can only increase the number of countermodels of K in
E 4dD ,f K 0 , and decrease the number of models of K in E 4dD ,f K 0 .
 Let  be a countermodel of K which is a model of E 4dD ,f K:  |= (K) 
(E 4dD ,f K).
Since  |= K, we have dD (, K) = 1 and this distance is maximal. Hence
dD (, K)  dD (, K 0 ). So:
dD (, E t {K})  dD (, E t {K 0 })

(2)

because the aggregation function f satisfies non-decreasingness.
Since  |= E 4dD ,f K, we have dD (, E t {K}) = dmin (E tdD ,f {K}). With (2),
we get dmin (E tdD ,f {K})  dD (, E t {K 0 }).
Since dmin (E tdD ,f {K}) = dmin (E tdD ,f {K 0 }) with (1), we obtain: dmin (E tdD ,f
{K 0 })  dD (, E t {K 0 }). By definition of min and since  |=  (because  |=
E 4dD ,f K), we deduce that  is a model of E 4dD ,f K 0 . We can conclude that
every model of E 4dD ,f K which is not a model of K is a model of E 4dD ,f K 0 .
Hence: [K]  [E 4dD ,f K]  [K]  [E 4dD ,f K 0 ].
 Finally, let  be a model of K which is a model of E 4dD ,f K 0 :  |= K  (E 4dD ,f
K 0 ). Since  |= K, we have dD (, K) = 0 and this distance is minimal. Hence
dD (, K)  dD (, K 0 ). So:
dD (, E t {K})  dD (, E t {K 0 })

(3)

because the aggregation function is non-decreasing.
Since  |= E 4dD ,f K 0 , we have dD (, E t {K 0 }) = dmin (E tdD ,f {K 0 }). With
(3), we get dD (, E t {K}  dmin (E tdD ,f {K 0 }). Since dmin (E tdD ,f {K}) =
dmin (E tdD ,f {K 0 }) with (1), we obtain dD (, E t {K}  dmin (E tdD ,f {K}). By
definition of min and since  |=  (because  |= E 4dD ,f K 0 ), we deduce that 
is a model of E 4dD ,f K. We can conclude that every model of E 4dD ,f K 0 which
is a model of K is a model of E 4dD ,f K. It follows that [K]  [E 4dD ,f K 0 ] 
[K]  [E 4dD ,f K].
Since we can only increase the number of countermodels of K in E 4dD ,f K 0 and
decrease the number of models of K in E 4dD ,f K 0 , the proportion of models of K in
E 4dD ,f K 0 is smaller than in E 4dD ,f K. This contradicts the assumption and shows
that dD ,f is strategy-proof for ip .
 Let d be any distance. Provided that only two bases are to be merged, d,
is
>
strategy-proof for the indexes idw and ids .
75

fiEveraere, Konieczny & Marquis

In this proof, we first show that the merging of two bases is consistent with each base.
Then, the property follows directly.
Strategy-proofness for the two drastic indexes is a direct consequence of the following
property:
d,
Lemma 1 If E = {K1 , K2 }, then d,
> (E)  K1 and > (E)  K2 are consistent.

Proof:
We show that d,
> (E)  K1 is consistent (the remaining case is similar
by symmetry). Reductio ad absurdum. Let us suppose that for two bases K1 and K2 ,
d,
> ({K1 , K2 }) is inconsistent with K1 . We can deduce that:
 0 |= K1 ,  |= K1 , d(, K1 4d, K2 ) > d( 0 , K1 4d, K2 ),
where K1 4d, K2 is a light notation for d,
> ({K1 , K2 }).
Since  |= K1 , d(, K1 ) = 0, we get that  0 |= K1 ,  |= K1 , d(, K2 ) >
d( 0 , K1 ) + d( 0 , K2 ). In particular, if we consider 1 |= K1 s.t. d( 0 , 1 ) = d( 0 , K1 )
(such an 1 exists by definition of d( 0 , K1 )), we have: d(1 , K2 ) > d( 0 , 1 ) +
d( 0 , K2 ). Similarly, if we consider 2 |= K2 s.t. d( 0 , 2 ) = d( 0 , K2 ), we get:
d(1 , K2 ) > d( 0 , 1 ) + d( 0 , 2 ) ().
By definition of d, we have  |= K2 , d(1 , K2 )  d(1 , ); in particular, d(1 , K2 ) 
d(1 , 2 ). By transitivity of , and with (*), we get d(1 , 2 ) > d( 0 , 1 ) + d( 0 , 2 ).
This contradicts the triangular inequality.

Let us now prove the main theorem:
Weak drastic index. For two bases K1 and K2 , we always have idw (K1 , K1 4 K2 ) = 1,
because d,
> ({K1 , K2 })  K1 is consistent (Lemma 1), so no manipulation is possible
(idw is maximal).
0
Strong drastic index. If d,
> is not strategy-proof, then we can find K1 s.t.:
d,
0
ids (K1 , d,
> ({K1 , K2 }) < ids (K1 , > ({K1 , K2 }).

For the strong drastic index, this means exactly that:
d,
> ({K1 , K2 }) 6|= K1

(4)

0
d,
> ({K1 , K2 }) |= K1 .

(5)

and:
0
Since d,
> ({K1 , K2 })  K2 is consistent (Lemma 1), we can find 2 |= K2 s.t. 2 |=
0
d,
> ({K1 , K2 }). With (5), we can conclude that 2 |= K1 as well.

Since we have 2 |= K1 K2 , we can conclude that for every model  of d,
> ({K1 , K2 }),
d,
we have d(, {K1 , K2 }) = 0. So  |= > ({K1 , K2 }), d(, K1 ) = d(, K2 ) = 0.
Hence  |= d,
> ({K1 , K2 }),  |= K1  K2 . This contradicts (4), so no manipulation
is possible.
76

fiThe Strategy-Proofness Landscape of Merging

 For any distance d, d,
is strategy-proof for the indexes ip , idw and ids when the

initial base K is complete.
For the drastic indexes, the result is a consequence of Theorem 11, showing that if a
manipulation occurs with an initial base K, then a manipulation with a complete base
K |= K is possible. If K is complete, no such manipulation not possible.
For the probabilistic index, the result is a consequence of the triangular inequality.
Drastic indexes. The property is a direct consequence of Theorem 11, showing that
if d,
 is manipulable for idw and ids by a base K, then it is manipulable by erosion.
But manipulation by erosion is impossible whenever K is complete.
Probabilistic index. By reductio ad absurdum: let us suppose that there is an operator
d,
 , where d is any distance, that is manipulable for ip given a complete base K =
{1 }. So, there exists an integrity constraint , a profile E, and a base K 0 s.t.:
d,
0
ip ({1 }, d,
 ({1 } t E)) < ip ({1 },  ({K } t E)).
d,
If ip ({1 }, d,
 ({1 } t E)) = 0, then idw ({1 },  ({1 } t E)) = 0 too. In that case,
manipulation for ip implies manipulation for idw and we have seen that no manipulation is possible for idw . As a consequence, we can suppose that ip ({1 }, d,
 ({1 } t
E)) 6= 0. Equivalently:
#({1 }  [E 4
 {1 }])
6= 0

#([E 4 {1 }])
d,
(where E 4
 {1 } is a light notation for  ({1 } t E)).
This statement allows us to infer that 1 is a model of E 4
 {1 }. In order to
d,
0
0
increase ip ({1 },  (K t E)), we have to reduce the number of models of E 4
 K


0
compared to E 4 {1 }, without removing 1 from [E 4 K ]. So we have to find

0
2 6= 1 s.t. 2 |= E 4
 {1 } and 2 6|= E 4 K . So, 2 |=  and we have d(2 , E t
0
{1 }) = d(1 , E t {1 }) and: d(2 , E t {K }) > d(1 , E t {K 0 }) (because 1 is a

0
model of both E 4
 {1 } and E 4 K ). With the aggregation function , we get:
d(2 , 1 ) + d(2 , E) = d(1 , E) and d(2 , K 0 ) + d(2 , E) > d(1 , K 0 ) + d(1 , E).

Replacing d(1 , E) by d(2 , 1 )+d(2 , E), we obtain d(2 , K 0 )+d(2 , E) > d(1 , K 0 )+
d(2 , 1 ) + d(2 , E), so d(2 , K 0 ) > d(1 , K 0 ) + d(2 , 1 ). If 10 is a model of K 0 s.t.
d(1 , K 0 ) = d(1 , 10 ), then we have d(2 , K 0 ) > d(1 , 10 ) + d(2 , 1 ). Furthermore by
definition of min, we have d(2 , 10 )  d(2 , K 0 ), so d(2 , 10 ) > d(1 , 10 ) + d(2 , 1 )
which contradicts the triangular inequality.

Theorem 3
 dH , is strategy-proof for idw or ids if and only if (  > and #(E) = 2) or K is
complete.
 dH , is strategy-proof for ip if and only if K is complete.
77

fiEveraere, Konieczny & Marquis

Proof:
Theorem 2 entails straightforwardly the  part of the proof, taking the
Hamming distance dH for d.
For the  part of the proof, we shall show by examples of manipulation that dH , is not
strategy-proof in other cases.
 The first examples show that dH , is not strategy-proof for idw or ids if ( 6 > or
#(E) 6= 2), and if K is not complete.
Weak drastic index.
 idw and  6 > (K is not complete)
We consider the constraint  = ab and the two bases K1 and K2 defined by their
set of models: [K1 ] = {00, 01} and [K2 ] = {10}. We have [dH , ({K1 , K2 })] =
{10} and idw (K1 , dH , ({K1 , K2 })) = 0. On the other hand, if the agent whose
base is K1 gives K10 , with [K10 ] = {01} instead of K1 , we obtain [dH , ({K10 ,
K2 })] = {01, 10, 11} and idw (K1 , dH , ({K10 , K2 }) = 1. This example shows the
manipulability of dH , if  6 >, even if there are only two bases in the profile.
Computations are detailed in Table 5. Interpretations that do not satisfy the
constraint are shaded.

00
01
10
11

dH (, K1 )
0
0
1
1

dH (, K10 )
1
0
2
1

dH (, K2 )
1
2
0
1

d

H

,

d

H

({K1 , K2 })
1
2
1
2

,

({K10 , K2 })
2
2
2
2

Table 5: Manipulability of dH , for idw with  6 >.
 idw and #(E) 6= 2 (K is not complete)
Let us consider the three bases [K1 ] = {00, 10}, [K2 ] = {01, 10, 11} and [K3 ] =
{01}. Then d>H , ({K1 , K2 , K3 }) has a unique model 01 and idw (K1 , d>H , ({K1 ,
K2 , K3 }) = 0. If we consider now [K10 ] = {10} instead of K1 , then [d>H , ({K10 ,
K2 , K3 })] = {01, 10, 11} and idw (K1 , dH , ({K10 , K2 , K3 }) = 1. See Table 6.

00
01
10
11

K1
0
1
0
1

K10
1
2
0
1

K2
1
0
0
0

K3
1
0
2
1

d

>H

,

({K1 , K2 , K3 })
2
1
2
2

d

>H

,

({K10 , K2 , K3 })
3
2
2
2

Table 6: Manipulability of d>H , for idw with #(E) 6= 2.
Strong drastic index.
78

fiThe Strategy-Proofness Landscape of Merging

 ids and  6 > (K is not complete)
We consider the constraint  = (a  b)  (a  b  c) and the two bases K1 and
K2 defined by their sets of models: [K1 ] = {000, 111} and [K2 ] = {000, 001}. We
have [dH , ({K1 , K2 })] = {111, 100} and ids (K1 , dH , ({K1 , K2 })) = 0. On the
other hand, if the agent whose base is K1 gives K10 , with [K10 ] = {111} instead
of K1 , we obtain [dH , ({K10 , K2 })) = {111} and ids (K1 , dH , ({K10 , K2 }) = 1.
This example shows the manipulability of dH , for ids if  6 >, even if there
are only two bases in the profile. Details of the computation are reported in
Table 7.

000
001
010
011
100
101
110
111

K1
0
1
1
1
1
1
1
0

K10
3
2
2
1
2
1
1
0

K2
0
0
1
1
1
1
2
2

d

H

,

({K1 , K2 })
0
1
2
2
2
2
3
2

d

H

,

({K10 , K2 })
3
2
3
2
3
2
3
2

Table 7: Manipulability of dH , for ids with  6 >.
 ids and #(E) 6= 2 (K is not complete)
Let us consider the three bases [K1 ] = {000, 001, 111}, [K2 ] = {110, 001} and
[K3 ] = {110, 000}. Then [d>H , ({K1 , K2 , K3 })] = {000, 001, 110} and
ids (K1 , d>H , ({K1 , K2 , K3 }) = 0.
If we consider [K10 ] = {000, 001} instead of K1 , then [d>H , ({K1 , K2 , K3 })] =
{000, 001} and ids (K1 , d>H , ({K10 , K2 , K3 }) = 1. See Table 8.

000
001
010
011
100
101
110
111

K1
0
0
1
1
1
1
1
0

K10
0
0
1
1
1
1
2
2

K2
1
0
1
1
1
1
0
1

K3
0
1
1
2
1
2
0
1

d

>H

,

({K1 , K2 , K3 })
1
1
3
4
3
4
1
2

d

>H

,

({K10 , K2 , K3 })
1
1
3
4
3
4
2
4

Table 8: Manipulability of dH , for ids with #(E) 6= 2.
 The following example shows that dH , is not strategy-proof for ip if K is not complete. Table 9 shows the manipulability of d>H , for ip (even if there are only two bases
in the profile and if   >). Let us consider the two bases K1 and K2 defined by their
sets of models: [K1 ] = {000, 001, 010, 100} and [K2 ] = {110, 011, 101, 111}. We have
79

fiEveraere, Konieczny & Marquis

[d>H , ({K1 , K2 })] = {001, 010, 100, 110, 011, 101} and ip (K1 , d>H , ({K1 , K2 })) = 21 .
On the other hand, if the agent whose base is K1 gives K10 , with [K10 ] = {000} instead of K1 , we obtain [d>H , ({K10 , K2 })] = {000, 001, 010, 100, 110, 011, 101} and
ip (K1 , d>H , ({K10 , K2 }) = 47 .

000
001
010
011
100
101
110
111

K1
0
0
0
1
0
1
1
2

K10
0
1
1
2
1
2
2
3

d

>H

K2
2
1
1
0
1
0
0
0

,

({K1 , K2 })
2
1
1
1
1
1
1
2

d

>H

,

({K10 , K2 })
2
2
2
2
2
2
2
3

Table 9: Manipulability of d>H , for ip if K is not complete.


Theorem 4
 dH ,GM ax is not strategy-proof for the satisfaction indexes idw and ip (even if   >,
K is complete and #(E) = 2).
 dH ,GM ax is strategy-proof for the satisfaction index ids if and only if   >, K is
complete and #(E) = 2.
Proof:
 Table 10 shows the manipulability of dH ,GM ax for the weak satisfaction index idw
even if   >, K is complete and #(E) = 2. We consider K1 s.t. [K1 ] = {001}, K2
with [K2 ] = {111}, and   >. We have [dH ,GM ax ({K1 , K2 })] = {011, 101}, so no
model of K1 belongs to [dH ,GM ax ({K1 , K2 })] and idw (K1 , dH ,GM ax ({K1 , K2 }) = 0.
If agent 1 gives K10 with [K10 ] = {000} instead of K1 , then [dH ,GM ax {K10 , K2 })] =
{001, 010, 011, 100, 101, 110} and idw (K1 , dH ,GM ax ({K10 , K2 }) = 1.

000
001
010
011
100
101
110
111

K1
1
0
2
1
2
1
3
2

K10
0
1
1
2
1
2
2
3

K2
3
2
2
1
2
1
1
0

d

H

,GM ax

({K1 , K2 })
(3, 1)
(2, 0)
(2, 2)
(1, 1)
(2, 1)
(1, 1)
(3, 1)
(2, 0)

d

H

,GM ax

({K10 , K2 })
(3, 0)
(2, 1)
(2, 1)
(2, 1)
(2, 1)
(2, 1)
(2, 1)
(3, 0)

Table 10: Manipulability of dH ,GM ax for idw .
80

fiThe Strategy-Proofness Landscape of Merging

Since manipulability for idw holds, manipulability for ip holds as well (cf. Theorem 1).
 As to ids , we first show that dH ,GM ax is strategy-proof for this index if   >,
#(E) = 2 and K is complete. Then, we give examples of manipulation if  6 >, or
#(E) 6= 2, or K is not complete.
 d>H ,GM ax is strategy-proof when E = {K1 , K2 } and   >, if K1 is complete.
We consider E 0 = {K10 , K2 } with K10 = K0 1 complete (thanks to the forthcoming
Lemma 2, we know that if the operator is manipulable, it is manipulable for
a complete base), and   >. Let #(P) = n and let d(K10 , K2 ) = m  n.
Then there exists a model 2 of K2 s.t. dH (K0 1 , 2 ) = m. By definition of the
Hamming distance, 2 can be generated from 1 by flipping m variables (since
K0 1 and 2 differ on the truth values of m variables x1 , . . . , xm ).
If m = 2k + 1 (m odd), then d(>, E 0 ) = (k + 1, k); otherwise m = 2k (m
even) and d(>, E 0 ) = (k, k). In the first case (m odd), there exist at least two
interpretations  and  0 s.t. d(, E 0 ) = d( 0 , E 0 ) = d(>, E 0 ) (for instance,  is
generated from 1 by flipping x1 , . . . , xk and  0 is generated from 2 by flipping
xk+1 , . . . , xm ).
A similar conclusion can be derived in the second case (m even) as soon as k  1.
In these two cases, d>H ,GM ax (E 0 ) has at least two models, hence we cannot have
d>H ,GM ax (E 0 )  K1 with K1 complete: E cannot be manipulated by K1 for ids .
The remaining case is d(>, E 0 ) = (0, 0). It imposes that K0 1  K2 is consistent.
Since K0 1 is complete, we have d>H ,GM ax (E 0 )  K0 1 , hence no manipulation is
dH ,GM ax
possible for ids (since >
(E 0 )  K1 if and only if K1  K0 1 if and only if
dH ,GM ax
>
({K1 , K2 })  K1 ).
 For showing the manipulability for ids , we consider the following scenarios:
  6 >, even if #(E) = 2 and K is complete.
Let us consider [K1 ] = {01}, [K2 ] = {11},  = a  b. Then [dH ,GM ax ({K1 ,
K2 }] = {01, 11}, and ids (K1 , dH ,GM ax ({K1 , K2 }) = 0. If agent 1 gives K10
with [K10 ] = {00} instead of K1 , then the result is [dH ,GM ax ({K10 , K2 })] =
{01} and ids (K1 , dH ,GM ax ({K10 , K2 }) = 1. (see Table 11).

00
01
10
11

K1
1
0
2
1

K10
0
1
1
2

K2
2
1
1
0

d

H

,GM ax

({K1 , K2 })
(2, 1)
(1, 0)
(2, 1)
(1, 0)

d

H

,GM ax

({K10 , K2 })
(2, 0)
(1, 1)
(1, 1)
(2, 0)

Table 11: Manipulability of dH ,GM ax for ids if  6 >
 #(E) 6= 2, even if   > and K is complete.
Let us consider [K1 ] = {01}, [K2 ] = {11}, and [K3 ] = {00, 01, 11}. Then
[d>H ,GM ax ({K1 , K2 , K3 }] = {01, 11}, so ids (K1 , d>H ,GM ax ({K1 , K2 , K3 }) =
81

fiEveraere, Konieczny & Marquis

0. If agent 1 gives K10 with [K10 ] = {00} instead of K1 , then [d>H ,GM ax ({K10 ,
K2 , K3 })] = {01} and ids (K1 , d>H ,GM ax ({K10 , K2 , K3 }) = 1. (see Table 12).

00
01
10
11

K1
1
0
2
1

K10
0
1
1
2

K2
2
1
1
0

K3
0
0
1
0

d

H

,GM ax

d

H

({K1 , K2 , K3 })
(2, 1, 0)
(1, 0, 0)
(2, 1, 1)
(1, 0, 0)

,GM ax

({K10 , K2 , K3 })
(2, 0, 0)
(1, 1, 0)
(1, 1, 1)
(2, 0, 0)

Table 12: Manipulability of d>H ,GM ax for ids if #(E) 6= 2.
 K is not complete, even if   > and #(E) = 2.
The example given Table 13 shows that manipulation is possible if the initial base is not complete. Consider [K1 ] = {01, 10}, [K2 ] = {11}, and  
>. Then [dH ,GM ax ({K1 , K2 }] = {01, 10, 11}, and ids (K1 , dH ,GM ax ({K1 ,
K2 }) = 0. If agent 1 gives K10 with [K10 ] = {00} instead of K1 , then
[dH ,GM ax ({K10 , K2 })] = {01, 10} and ids (K1 , dH ,GM ax ({K10 , K2 }) = 1.

00
01
10
11

K1
1
0
0
1

K10
0
1
1
2

K2
2
1
1
0

d

H

,GM ax

({K1 , K2 })
(2, 1)
(1, 0)
(1, 0)
(1, 0)

d

H

,GM ax

({K10 , K2 })
(2, 0)
(1, 1)
(1, 1)
(2, 0)

Table 13: Manipulability of dH ,GM ax for ids if K is not complete.



Theorem 5
C3
C4
C5
 4C1
 , 4 , 4 , and 4 are not strategy-proof for ip (even if   >, K is complete
and #(E) = 2).

 4C1
 is strategy-proof for idw and ids .
 4C3
 is strategy-proof for idw and ids if and only if   >.
 4C4
 is not strategy-proof for idw and ids (even if   >, K is complete and #(E) = 2).
 4C5
 is strategy-proof for idw if and only if   > or K is complete, and is strategyproof for ids if and only if   >.
Proof:
82

fiThe Strategy-Proofness Landscape of Merging

 We first give an example of manipulation of 4C1
 for ip , with #(E) = 2, a complete
base K1 , and   >.
Consider E = {K1 , K2 }, with K1 = {a  b} and K2 = {(a  b)}. Then 4C1
> (E)  >,
1
0 = {a, b} instead of K , then
and ip (K1 , 4C1
(E))
=
.
But
if
agent
1
gives
K
1
1
>
4
1
0
C1
0
4C1
> ({K1 , K2 })  a  b, and ip (K1 , 4> ({K1 , K2 })) = 3 . So E is manipulable by K1
C1
C3
for ip . The same example holds for 4C4
 . It remains to note now that 4> = 4> =
4C5
> to conclude the first point of the proof.
 4C1
 is strategy-proof for idw and ids .
Weak drastic index.
For any K  E there are two cases:
 K
subset M of
S   is consistent. Then there is at least one maximal consistent
C1
Ki E Ki which contains  and all the formulas of K. So 4 (E t{K})  M R
(where R denotes the disjunction of the other maxcons) is consistent with K  .
So idw (K, 4C1
 (E t {K})) = 1 and no manipulation is possible.
0
 K   is not consistent. Since for any K 0 , we have 4C1
 (E t {K })) |= , we also
C1
0
have idw (K, 4 (E t {K })) = 0 and no manipulation is possible.

Strong drastic index.
By reductio ad absurdum. Assume that 4C1
 is not strategy-proof for ids . It means
that
K s.t. 4C1
(6)
 (E t {K}) 6|= K,
0
K 0 s.t. 4C1
 (E t {K }) |= K.

(7)

From statement (7) we get that M  maxcons(E t {K 0 }, ), M |= K. So if we
0
0
0
consider 4C1
 (E t {K } t {K}), every M  maxcons(E t {K } t {K}, ) is of the
0
C1
0
form M  {K}, so M |= K and 4 (E t {K } t {K}) |= K ().
From statement (6) we get that M  maxcons(E t {K}, ), M 6|= K. Since M is a
maximal subset, it means that M  K is not consistent. So if we consider 4C1
 (E t
{K 0 } t {K}), then M  M 0 , with M 0  maxcons(E t {K 0 } t {K}, ). So M 0  K
0
is not consistent. Hence M 0 6|= K and 4C1
 (E t {K} t {K }) 6|= K, which contradicts
().
 4C3
 is strategy-proof for idw and ids if and only if   >.
Weak drastic index.
C3
C1
C3
Since 4C1
> = 4> , it follows immediately from the above proof for 4 that 4> is
strategy-proof for idw .

For showing that manipulation is possible for 4C3
 if  6 >, even with two bases and a
complete initial base K1 , consider the following example: let K1 = {ab}, K2 = {a},
 = b and K10 = {a}. We have C3
 ({K1 , K2 })  a, which is inconsistent with K1 .
0 , K })  >, which is consistent with K .
We also have C3
({K
2
1

1
83

fiEveraere, Konieczny & Marquis

Strong drastic index.
C3
C3
Since 4C1
> = 4> , it follows immediately from the point above that 4> is strategyproof for ids .

For showing that a manipulation is possible for 4C3
 for ids if  6 >, even with two
bases and a complete initial base K1 , we consider the following example: let K1 = {a
b}, K2 = {a},  = a  b and K10 = {a  b}. We have C3
 ({K1 , K2 })  a, hence
C3
C3
0
0
 ({K1 , K2 }) 6|= K1 . We also have  ({K1 , K2 })  , hence C3
 ({K1 , K2 }) |=
K1 .
 4C4
 is not strategy-proof for idw and ids (even if   >, K is complete and #(E) = 2).
Weak drastic index.
For showing that manipulation is possible for 4C4
 with two bases, a complete initial base K1 and   >, we consider the following example: let K1 = {a}, K2 =
{a, a  >},  = > and K10 = {a, a  >}. We have C4
 ({K1 , K2 })  a, hence
C4
0
 ({K1 , K2 })  K1 is not consistent. We also have C4
 ({K1 , K2 })  >, hence
C4
0
 ({K1 , K2 })  K1 is consistent.
Strong drastic index.
For showing that 4C4
 is not strategy-proof for ids with two bases, a complete initial
base K1 and   >, consider the following example: let K1 = {a}, K2 = {a}, and
C4
K10 = {a, a  >}. We have C4
 ({K1 , K2 })  >, hence  ({K1 , K2 }) 6|= K1 . We also
0
C4
0
have C4
 ({K1 , K2 })  a, hence  ({K1 , K2 }) |= K1 .
 4C5
 is strategy-proof for idw if and only if   > or K is complete, and is strategyproof for ids if and only if   >.
Weak drastic index.
C5
C1
C5
Since 4C1
> = 4> , it follows from the above proof for 4 that 4 is strategy-proof
for idw if   >.

If the initial base K1 is complete, 4C5
 is also strategy-proof. There are two cases:
S
 K1 |= . Let S
M = {  KE K | K1 |= }. By construction, M is an element
of maxcons( KE K, >). Since K1 |= , M is consistent with  (K1 is a model
of each of them). Since we have both K1 |= M and M |= C5
 (E) (by definition
C5 (E)  K is consistent,
of the operator), we also have K1 |= C5
(E).
Hence

1


and this prevents E from being manipulable by K1 for idw given C5
 and .
 K1 |= . By definition of the operator, for any base K10 and any profile E 0
0
0
(especially the profile obtained by removing K1 from E), we have C5
 ({K1 }tE )
0
0
C5
0
0
is consistent and C5
 ({K1 } t E ) |= . This implies that  ({K1 } t E )  K1
is inconsistent, and no manipulation is possible for idw .
For showing that manipulation is possible for 4C5
 if  6 > and if the initial base K1
is not complete, we consider the following example:
84

fiThe Strategy-Proofness Landscape of Merging

let K1 = {a}, K2 = {b, a},  = ab and K10 = {ab}. We have C5
 ({K1 , K2 }) 
C5
C5
b  a, hence  ({K1 , K2 })  K1 is not consistent. We also have  ({K10 , K2 }) 
0
(a  b)  (b  a), hence C4
 ({K1 , K2 })  K1 is consistent.
Strong drastic index.
C5
C1
C5
Since 4C1
> = 4> , it follows immediately from the above proof for 4 that 4 is
strategy-proof for ids if   >.

For showing that manipulation is possible for 4C5
 if  6 >, even with two bases
and a complete initial base K1 , we consider the following example: let K1 = {a  b},
K2 = {b},  = a and K10 = {a  b, b  a}. We have C5
 ({K1 , K2 })  a, hence
C5
C5
0
0
 ({K1 , K2 }) 6|= K1 . We also have  ({K1 , K2 })  ab. Hence C5
 ({K1 , K2 }) |=
K1 .

Theorem 6
 4C1
 is strategy-proof for idw and ids , and is strategy-proof for ip if and only if #(E) =
2.
c

 4C3
 is strategy-proof for idw and ids if and only if   >, and is strategy-proof for ip
if and only if #(E) = 2 and   >.
c

 4C4
 is strategy-proof for ip , idw and ids .
c

 4C5
 is strategy-proof for idw if and only if #(E) = 2 or   > or K is complete.
c

C5
4C5
 is strategy-proof for ids if and only if #(E) = 2 or   >. Finally, 4 is
strategy-proof for ip if and only if #(E) = 2.
c

c

Proof:
 4C1
 is strategy-proof for idw and ids , and is strategy-proof for ip if and only if #(E) =
2.
c

Drastic indexes. The strategy-proofness of 4C1
 comes from the strategy-proofness of
c

C1
C1
4C1
 as reported in Theorem 5, because 4 is a specialization of 4 . Furthermore,
C1
in the examples given in the proof of Theorem 5 concerning 4 , every base is a
c

singleton, so these examples hold for 4C1
 too.
c

Probabilistic index.
The proof for the probabilistic index and a profile E s.t. #(E) = 2 is based on the fact
c
that the merging of two bases with 4C1
 is either the conjunction of the two bases, or
their disjunction. In both cases, we shall show that no manipulation can occur.
For the  part of the proof, suppose that #(E) = 2. we shall show that 4C1
 and
c

4C5
 (we group here the two cases, because their proofs are similar) is strategy-proof
for ip . By case analysis:
c

85

fiEveraere, Konieczny & Marquis

 If K1 is consistent with , then there are two cases:
C5
 4C1
 ({K1 , K2 })  4 ({K1 , K2 })  K1  K2   if it is consistent.
c

c

C5
 4C1
 ({K1 , K2 })  4 ({K1 , K2 })  (K1  K2 )   otherwise.
c

c

C5
In the first case, 4C1
 ({K1 , K2 }) |= K1 and 4 ({K1 , K2 }) |= K1 so ip takes its
maximal value, and no manipulation is possible.
c

c

C5
Let us consider the second case for 4C1
 (the case for 4 is similar): we assume
c

c

that 4C1
 ({K1 , K2 })  (K1  K2 )  .
c

C1
0
Since for every base K10 , the definition of 4C1
 requires that we have 4 ({K1 ,
c

c

K2 }) |=  and since we have K1   |= 4C1
 ({K1 , K2 }), the following inequation
0
holds for every base K1 :
c

0
C1
#([K1 ]  [4C1
 ({K1 , K2 })])  #([K1 ]  [4 ({K1 , K2 })]).
c

c

0
0
If K10  K2   is consistent, then 4C1
 ({K1 , K2 })  K1  K2  , hence
c

0
#([K1 ][4C1
 ({K1 , K2 })]) = 0 is minimal since we have assumed that K1 K2 
is inconsistent.
If K10  K2   is inconsistent, then there are two cases:
c

0
 K10   is inconsistent and K2   is inconsistent. We have 4C1
 ({K1 , K2 }) 
c

. Since we have assumed K1   consistent, we also have 4C1
 ({K1 , K2 }) 
K1  . Hence:
c

c

#([K1 ]  []
,
#([])

ip (K1 , 4C1
 ({K1 , K2 })) =

#([K1 ]  [K1  ]
.
#([K1  ])

0
ip (K1 , 4C1
 ({K1 , K2 })) =

and
c

Since the numerators of the two fractions coincide while #([K1 ])  #([]),
no manipulation is possible in this case.
0
 K10   is consistent or K2   is consistent. We have 4C1
 ({K1 , K2 }) 
0
(K1  K2 )  . Since K1  K2   is inconsistent, we have
c

0
ip (K1 , 4C1
 ({K1 , K2 })) =

#([K1  K10  ])
.
#([(K10  K2 )  ])

ip (K1 , 4C1
 ({K1 , K2 })) =

#([K1  ])
.
#([(K1  K2 )  ])

c

We also have:
c

Now, since K10  K2   is inconsistent, we have #([(K10  K2 )  ]) =
#([K10  ]) + #([K2  ]). Similarly, since K1  K2   is inconsistent, we
have #([(K1  K2 )  ]) = #([K1  ]) + #([K2  ]). Subsequently, suppose
86

fiThe Strategy-Proofness Landscape of Merging

0
C1
that we have ip (K1 , 4C1
 ({K1 , K2 })) > ip (K1 , 4 ({K1 , K2 })). This is the
case if and only if #([K1  K10  ])(#([K1  ]) + #([K2  ])) > #([K1 
])(#([K10  ]) + #([K2  ])).
If we note a = #([K1  K10  ]) and b = #([K2  ]), then there exist two
natural integers a0 and a00 such that #([K1  ]) = a + a0 and #([K10  ]) =
a + a00 . Replacing in the previous inequation, it comes:
c

c

a(a + a0 + b) > (a + a0 )(a + a00 + b)
which simplifies to 0 > aa00 + a0 a00 + a0 c, which is impossible. Hence no
manipulation is possible in this case as well.
0
C5
0
 If K1 is not consistent with , then, since E 0 , 4C1
 (E ) |=  and 4 (E ) |= ,
c

c

0
C5
0
we have: E 0 , ip (K1 , 4C1
 (E )) = 0 and ip (K1 , 4 (E )) = 0, so no manipulation
is possible.
c

c

For the  part of the proof, the following example shows that strategy-proofness
c
c
C5
for ip does not hold any longer for 4C1
 or 4 when #(E) 6= 2, even if the initial base is complete and   >. We consider K1 = {a  b}, K2 = {a  b} and
K3 = {a}, with the integrity constraint  = >. There are two maximal consistent sets in maxcons({K1 , K2 , K3 }, ): M1 = {a  b, >} and M2 = {a, >}. Hence
c
c
1
C1
4C1
 ({K1 , K2 , K3 })  (a  b)  (a). We get ip (K1 , 4 ({K1 , K2 , K3 })) = 3 . If
agent 1 gives K10 = {a  b} instead of K1 , then there are two maximal consistent sets M10 = {a  b, >}, M20 = {a  b, a, >} in maxcons({K10 , K2 , K3 }, ), so
c
c
1
0
C1
0
4C1
 ({K1 , K2 , K3 })  (a  b)  (a  b). We get ip (K1 , 4 ({K1 , K2 , K3 })) = 2 , so
this is an example of manipulation of 4C1
> for ip .
c

C5
C5
Since 4C1
> = 4> , this example shows the manipulability of 4 as well.
c

c

c

 4C3
 is strategy-proof for idw and ids if and only if   >, and is strategy-proof for ip
if and only if #(E) = 2 and   >.
c

Drastic indexes.
C3
Since 4C3
> is strategy-proof for idw and ids , its specialization 4 is also strategy-proof
for idw and ids .
c

In the example showing the manipulation for 4C3
 with two bases and a complete
initial base K1 , every base is a singleton, so this example holds for 4C3
 too.
c

Probabilistic index.
C3
C1
C3
Since 4C1
> = 4> , it follows immediately from the above proof for 4 that 4> is
strategy-proof for ip when two bases are considered, and it is not the case when three
agents or more are taken into account.
c

c

For showing that manipulation is possible for 4C3
 with two bases and a complete initial base K1 , when the integrity constraint  is not true, consider the following examc
ple: let K1 = {a  b}, K2 = {a},  = b and K10 = {a}. We have 4C3
 ({K1 , K2 }) 
c

87

fiEveraere, Konieczny & Marquis

a, which is inconsistent with K1 , so ip (K1 , 4C3
 ({K1 , K2 })) = 0. We also have
c

0
C3
0
4C3
 ({K1 , K2 })  >, which is consistent with K1 , so ip (K1 , 4 ({K1 , K2 })) > 0.
c

c

 4C4
 is strategy-proof for ip , idw and ids . This is a direct consequence of Remark 1
and Theorem 2.
c

 4C5
 is strategy-proof for idw if and only if #(E) = 2 or   > or K is complete.
c

C5
4C5
 is strategy-proof for ids if and only if #(E) = 2 or   >. Finally, 4 is
strategy-proof for ip if and only if #(E) = 2.
c

c

Weak drastic index.
As 4C5
 is strategy-proof for ip with two bases, it is also strategy-proof for idw in that
case.
c

C5
Since 4C5
> is strategy-proof for idw , we have that 4 > is also strategy-proof for idw .
c

Finally, as no manipulation is possible for 4C5
 when the initial base K1 is complete
(Theorem 5), no manipulation exists for 4C5
 in this cas.
c

Contrastingly, a manipulation example exists for 4C5
 if #(E) 6= 2 and  6 >
and the initial base K1 not complete. We consider the three (singleton) bases:
c
K1 = {b}, K2 = {a}, K3 = {a  b}, and  = a. We have 4C5
 ({K1 , K2 , K3 }) 
c

0
a  b, so idw (K1 , 4C5
 ({K1 , K2 , K3 })) = 0. And with K1 = {b  a}, we have
c

0
C5
0
4C5
 ({K1 , K2 , K3 })  a, and idw (K1 , 4 ({K1 , K2 , K3 })) = 1.
c

c

Strong drastic index.
C5
As 4C5
> is strategy-proof for ids , 4> is also strategy-proof for ids .
c

C5
As 4C5
 is strategy-proof for ip when there are two bases in E, 4 is also strategyc

c

proof for ids in this case, since for any profile E, 4C5
 (E) is consistent.
c

A manipulation example exists for 4C5
 if #(E) 6= 2 and  6 >, even if the initial
base K1 is complete: K1 = {a  b}, K2 = {a  b}, K3 = {a  b}, and  = a.
There are two maximal consistent sets in maxcons({K1 , K2 , K3 }, >): M1 = {a  b}
c
and M2 = {a  b}. Hence 4C5
 ({K1 , K2 , K3 })  (a  b)  (a  b). We get
c

0
ids (K1 , 4C5
 ({K1 , K2 , K3 })) = 0. With K1 = {a  b}, there are two maximal
consistent sets in maxcons({K1 , K2 , K3 }, >): M10 = {a  b} and M20 = {a  b}.
c
c
0
C5
0
Hence 4C5
 ({K1 , K2 , K3 })  (a  b), and ids (K1 , 4 ({K1 , K2 , K3 })) = 1.
c

Probabilistic index.
C1
The proof for 4C5
 is similar to the proof for 4 .
c

c


Theorem 7 The strategy-proofness results reported in Table 14 hold, under the restriction
that each base is complete (f stands for any aggregation function, and d for any distance).
88

fiThe Strategy-Proofness Landscape of Merging

f is any aggregation function, d is any distance, sp means strategy-proof , sp means non
strategy-proof  even if #(E) = 2 and   >, sp means non strategy-proof  even if either
#(E) = 2 or   >, but strategy-proof  if both #(E) = 2 and   >. Finally, sp> means
non strategy-proof  even if #(E) = 2, but strategy-proof  whenever   >.



ip

idw

ids

dD ,f
d,

dH ,GM ax

4C1

4C3

4C4

4C5

c
4C1

c
4C3

c
4C4

c
4C5


sp
sp
sp
sp
sp
sp
sp

sp
sp
sp
sp
sp>
sp
sp

sp
sp
sp
sp
sp>
sp
sp>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

Table 14: Strategy-proofness: complete bases.
Proof:

The first line of the table (dD ,f ) is a direct consequence of Theorem 2.

The second line of the table (d,
 ) is a direct consequence of Theorem 2.
The third line of the table (dH ,GM ax ) comes from the proof of Theorem 4.
The first column of the fourth line (4C1
 and ip ) comes from the following example. Let
K1 = {a, b}, K2 = {a, b}, K10 = {a  b} and  = >. We have 4C1
 ({K1 , K2 })  >, hence
1
C1
0
C1
ip (K1 , 4 ({K1 , K2 })) = 4 , while we have 4 ({K1 , K2 })  (a  b)  (a  b), showing
1
0
C1
that ip (K1 , 4C1
 ({K1 , K2 })) = 2 . The rightmost columns of the fourth line (4 and idw ,
ids ) come directly from Theorem 5.
The first column of the fifth line (4C3
 and ip ) comes from the first column of the fourth
line given that the example is s.t.   > (in that case both operators coincide). Similarly
C3
for the second and the third columns (4C3
 and idw , ids ) in the case   > (4> coincides
C3
with 4C1
> ). In the remaining case, 4 is not strategy-proof for idw even if #(E) = 2 as
the following example shows: take E = {K1 , K2 } with K1 = {a  b  c}, K2 = {a  b, c}
and  = b; we have 4C3
 (E)  a  b  c, which is inconsistent with K1 ; if the agent
0
gives K10 = {a, b  c} instead of K1 , we obtain 4C3
 ({K1 , K2 })  (a  c)  (a  b  c),
which is consistent with K1 . Finally, 4C3
 is not strategy-proof for ids even if #(E) = 2
when  6= >; let K1 = {a, b}, K2 = {a, b}, K10 = {a  b} and  = b. We have
C3
4C3
 ({K1 , K2 })  (a  b)  (a  b), hence ids (K1 , 4 ({K1 , K2 })) = 0, while we have
0
C3
0
4C3
 ({K1 , K2 })  a  b, showing that ids (K1 , 4 ({K1 , K2 })) = 1.
The sixth line (4C4
 ) comes from the proof of Theorem 5.
89

fiEveraere, Konieczny & Marquis

The first column of the seventh line (4C5
 and ip ) comes from the first column of the fourth
line given that the example is s.t.   > (in that case both operators coincide). The second
C5
column (4C5
 and idw ) comes directly from Theorem 5. The third column (4 and ids ) in
C5
the case   > comes from the third column of the fourth line (4> coincides with 4C1
> ).
C5
Finally, 4 is not strategy-proof for ids even if #(E) = 2 when  6 >; let K1 = {a, b},
K2 = {a, b}, K10 = {a  b} and  = b. We have 4C5
 ({K1 , K2 })  (a  b)  (a  b),
C5
C5
hence ids (K1 , 4 ({K1 , K2 })) = 0, while we have 4 ({K10 , K2 })  a  b, showing that
0
ids (K1 , 4C5
 ({K1 , K2 })) = 1.
C4
Finally, it remains to consider the 4C
 operators. As to 4 , we know from Theorem 6 that
it is strategy-proof for ip (hence for idw and ids ) since 4C4
 is strategy-proof for ip when all
c

b

C3
C5
bases are singletons. Let us focus on 4C1
 , 4 and 4 . Since each base is complete and
can be assumed to be a singleton without loss of generality, we have
c

c
4C1
 ({K1 , . . . , Kn })



c

c

c
4C5
 ({K1 , . . . , Kn })

(

n
_

Ki )   if consistent,

i=1
C5
4C1
 ({K1 , . . . , Kn })  4 ({K1 , . . . , Kn })   otherwise.
c

c

We also have:
4C3
 ({K1 , . . . , Kn })  (
c

n
_

Ki )   if consistent,

i=1
c
4C3
 ({K1 , . . . , Kn })

  otherwise.

C1
C3
C5
Let 4C
 be any operator among 4 , 4 and 4 . There are two cases:
b

c

c

c

 4C
 consistent. There are again two cases:
b

0
C5
0
 K1 |= . Since for every profile E 0 we have 4C1
 (E ) |=  and 4 (E ) |= ,
c

c

0
C5
0
we also have 4C1
 (E )  K1 inconsistent and 4 (E )  K1 inconsistent, showing
that no manipulation is possible for ip , hence for idw and ids . In the specific case
we consider (all bases are singletons and are complete), we also have for every
c
0
0
profile E 0 , 4C3
 (E ) |=  since each base from E that is kept as an element from
c

c

0
maxcons(E 0 , >) must satisfy  and if no base is kept, 4C3
 (E ) is inconsistent,
c

0
hence 4C3
 (E ) |=  trivially holds. The previous argument can be used to show
c

that no manipulation is possible with 4C3
 for ip , hence for idw (and ids under
c

the assumption 4C3
 (E) consistent).
c

 K1 |= . We necessarily have #([K1 ]  [4C
 ({K1 , . . . , Kn })]) = 1. By reductio
ad absurdum. A manipulation for ip is possible only if we can find a complete
b
b
0
C
0
base K10 s.t. (1) K1 |= 4C
 ({K1 , . . . , Kn }) and (2) #([4 ({K1 , . . . , Kn })]) <
b

0
#([4C
 ({K1 , . . . , Kn })]). (2) requires that K1 |= . (1) imposes that K1 |=
K10  K2  . . .  Kn . Since K1 |=  while K10 |= , we have K1 6 K10 . Subsequently, there exists Kj (j  2, . . . , n) s.t. K1  Kj . Since Kj is a model of
b

90

fiThe Strategy-Proofness Landscape of Merging

0
C
4C
 ({K1 , . . . , Kn }), inequation (2) cannot be satisfied. Hence, 4 is strategyb

b

proof for ip , hence for idw . Since 4C
 (E) is assumed consistent, no manipulation
is possible for ids .
b

C
C3
 4C
 (E) inconsistent. This is only possible for 4 = 4 and requires that each Ki
b

b

c

C3
(i  1, . . . , n) is s.t. Ki |= . Since 4C3
 (E) is inconsistent, we have ip (K1 , 4 (E)) =
c

c

0
0. Since for every K10 complete, K1 is not a model of 4C3
 ({K1 , . . . , Kn }), we have
c

C3
0
C3
ip (K1 , 4C3
 (4 ({K1 , . . . , Kn }))) = 0 as well. This shows that 4 is strategy-proof
c

c

C3
for ip , hence for idw . Finally, when 4C3
 (E) is inconsistent, we have 4 (E) |= K1 ,
showing that no manipulation is possible for ids as well.
c

c


Theorem 8 None of dD , , dD ,GM ax , dH , or dH ,GM ax is strategy-proof for iDalal ,
even in the restricted case E consists of two complete bases.
Proof:
 dD , = dD ,GM ax . Let us consider [K1 ] = {000}, [K2 ] = {110} and  = a  b  c
where P = {a, b, c}. We have [dD , ({K1 , K2 })] = {110} and iDalal (K1 , dD , ({K1 ,
K2 })) = 1  23 . With [K10 ] = {001}, we get [dD , ({K10 , K2 })] = {110, 001} and
iDalal (K1 , dD , ({K10 , K2 })) = 1  13 , showing the manipulation (details are reported
in Table 15).

000
001
010
011
100
101
110
111

K1
0
1
1
1
1
1
1
1

K10
1
0
1
1
1
1
1
1

K2
1
1
1
1
1
1
0
1

d

D

,

({K1 , K2 })
1
2
2
2
2
2
1
2

d

D

,

({K10 , K2 })
2
1
2
2
2
2
1
2

Table 15: Manipulation of dD , for iDalal with two complete bases.
 dH , . Let us consider [K1 ] = {000}, [K2 ] = {110} and  = ((a  b  c)  (a 
b  c)  (a  b  c)) where P = {a, b, c}. We have [dH , ({K1 , K2 })] = {110} and
iDalal (K1 , dH , ({K1 , K2 })) = 1 23 . With [K10 ] = {001}, we get [dH , ({K10 , K2 })] =
{110, 001, 011, 111} and iDalal (K1 , dH , ({K10 , K2 })) = 1  13 , showing the manipulation (details are reported in Table 16).
 dH ,GM ax . Let us consider [K1 ] = {0001}, [K2 ] = {0111} and  = (a  b 
c  d)  (a  b  c)  (a  b  c)  (a  b  c  d)  (a  b  c  d) 
(a  b  c  d) where P = {a, b, c, d}. We have [dH ,GM ax ({K1 , K2 })] = {0111} and
91

fiEveraere, Konieczny & Marquis


000
001
010
011
100
101
110
111

K10
1
0
2
1
2
1
3
2

K1
0
1
1
2
1
2
2
3

d

H

K2
2
3
1
2
1
2
0
1

,

({K1 , K2 })
2
4
2
4
2
4
2
4

d

H

,

({K10 , K2 })
3
3
3
3
3
3
3
3

Table 16: Manipulation of dH , for iDalal with two complete bases.
iDalal (K1 , dH ,GM ax ({K1 , K2 })) = 1 42 . With [K10 ] = {1000}, we get [dH ,GM ax ({K10 ,
K2 })] = {0000, 0110, 1001, 1010, 1100, 1111} and iDalal (K1 , dH ,GM ax ({K10 , K2 })) =
1  41 , showing the manipulation (details are reported in Table 17).

0000
0001
0010
0011
0100
0101
0110
0111
1000
1001
1010
1011
1100
1101
1110
1111

K1
1
0
2
1
2
1
3
2
2
1
3
2
3
2
4
3

K10
1
2
2
3
2
3
3
4
0
1
1
2
1
2
2
3

K2
3
2
2
1
2
1
1
0
4
3
3
2
3
2
2
1

d

H

,GM ax

({K1 , K2 })
(3, 1)
(2, 0)
(2, 2)
(1, 1)
(2, 2)
(1, 1)
(3, 1)
(2, 0)
(4, 2)
(3, 1)
(3, 3)
(2, 2)
(3, 3)
(2, 2)
(4, 2)
(3, 1)

d

H

,GM ax

({K10 , K2 })
(3, 1)
(2, 2)
(2, 2)
(3, 1)
(2, 2)
(3, 1)
(3, 1)
(4, 0)
(4, 0)
(3, 1)
(3, 1)
(2, 2)
(3, 1)
(2, 2)
(2, 2)
(3, 1)

Table 17: Manipulation of dH ,GM ax for iDalal with two complete bases.

C
Theorem 9 None of the 4C
 operators (hence, none of the 4 operators) is strategy-proof
for iDalal , even in the restricted case E consists of two complete bases.
b

Proof:
Let us consider the complete bases K1 = {a  b} and K2 = {a  b}, with  =
(ab). We have maxcons({K1 , K2 }, ) = {{ab, (ab)}} = maxconscard ({K1 , K2 },
c
) and maxcons({K1 , K2 }, >) = {{a  b, >}, {a  b, >}}, hence 4C1
 ({K1 , K2 }) 
C4
C5
4C3
 ({K1 , K2 })  4 ({K1 , K2 })  4 ({K1 , K2 })  a  b.
c

c

c

2
We get iDalal (K1 , 4C
 ({K1 , K2 })) = 1  2 = 0.
With K10 = {a  b}, we have maxcons({K10 , K2 }, ) = {{a  b, (a  b)}, {a  b, (a 
b)}} = maxconscard ({K10 , K2 }, ) and maxcons({K10 , K2 }, >) = {{a  b, >}, {a 
b

92

fiThe Strategy-Proofness Landscape of Merging

0
C3
0
C4
0
C5
0
b, >}}, hence 4C1
 ({K1 , K2 })  4 ({K1 , K2 })  4 ({K1 , K2 })  4 ({K1 , K2 }) 
(a  b)  (a  b)  a.
b
1
0
Thus iDalal (K1 , 4C

 ({K1 , K2 })) = 1  2 , showing the manipulation.
c

c

c

c

Theorem 10 Let d be a pseudo-distance and let f be an aggregation function. d,f
is

dilation strategy-proof for the indexes ip , idw and ids .
Proof:
The idea is that if the untruthful base K 0 contains all the models of the true
base K, then the merged base when K 0 is provided contains at most the same models of K
as those appearing in the merged base when K is reported, and more countermodels of K.
So no manipulation is possible.
From Theorem 1, it is sufficient to show that d,f
 is strategy-proof for ip . By reductio ad
absurdum. Let us suppose that there is an operator d,f
 , where d and f are respectively a
pseudo-distance and an aggregation function, which is manipulable by dilation for ip . Under
this assumption, we can find an integrity constraint , a profile E, two bases K and K 0
d,f
0
with K |= K 0 , s.t. ip (K, d,f
 ({K} t E)) < ip (K,  ({K } t E)). Using the light notation
E 4 K instead of d,f
 ({K} t E), we have:
#([K]  [E 4 K 0 ])
#([K]  [E 4 K])
<
.
#([E 4 K])
#([E 4 K 0 ])
Since K |= K 0 , for any pseudo-distance d, we have   W, d(, K)  d(, K 0 ). So, for any
aggregation function f (that satisfies non-decreasingness):
  W, d(, E t {K})  d(, E t {K 0 }).

(8)

Let us note dmin (E t {K}) = min({d(, E t {K}) |  |= }, ). With (8), we can
immediately infer: dmin (E t {K})  dmin (E t {K 0 }). Two cases have to be considered:
 dmin (E t {K}) > dmin (E t {K 0 }) (*).
If 1 is a model of K   then, since K |= K 0 , d(1 , K) = d(1 , K 0 ) = 0, so d(1 , E t
{K}) = d(1 , E t {K 0 }) . If furthermore 1 is a model of E 4 K 0 , then d(1 , E t
{K 0 }) = dmin (E t {K 0 }), and d(1 , E t {K}) = dmin (E t {K 0 }). By definition of
min, we have d(1 , E t {K})  dmin (E t {K}), because 1 |= . So we can conclude
that dmin (E t {K})  dmin (E t {K 0 }), but this contradicts (*). So, no model of
K   is a model of E 4 K 0 . Consequently, ip (K, E 4 K 0 ) = 0 and is minimal, and
this prevents from any manipulation for d,f
 . So, we can exclude case (*).
 dmin (E t {K}) = dmin (E t {K 0 }) (**).
If  is a model of E 4 K, then we have both  |=  and d(, E t {K}) = dmin (E t
{K}). So, d(, E t {K}) = dmin (E t {K 0 }) with the equation (**). Furthermore,
with the inequation (8), we infer that d(, E t {K})  d(, E t {K 0 }). Hence,
d(, E t {K 0 })  dmin (E t {K 0 }). Since  is a model of , we can finally infer that
93

fiEveraere, Konieczny & Marquis

 is a model of E 4 K 0 as well. So we have that any model of E 4 K is a model of
E 4 K 0 , and then:
#([E 4 K])  #([E 4 K 0 ]).
(9)
We can deduce as well that any model of E 4 K which is a model of K   is a model
of E 4 K 0 (and of K), so:
#([K]  [E 4 K])  #([K]  [E 4 K 0 ]).
Furthermore, if 1 |= K   is a model of E 4 K 0 , then we have both:
 d(1 , E t {K 0 }) = dmin (E t {K 0 }) = dmin (E t {K}) with (**), and
 d(1 , E t {K}) = d(1 , E t {K 0 }) because K |= K 0 : since d(1 , K) = 0, we have
d(1 , K 0 ) = 0 too.
We obtain: d(1 , E t{K}) = dmin (E t {K}) and 1 |= , so 1 is a model of E 4 K.
Then we can state #([K]  [E 4 K])  #([K]  [E 4 K 0 ]). So we get:
#([K]  [E 4 K]) = #([K]  [E 4 K 0 ]).

(10)

With (9) and (10), we get immediately that:
#([K]  #([E 4 K 0 ])
#([K]  [E 4 K])

.
#([E 4 K])
#([E 4 K 0 ])

(11)

d,f
0
As a consequence, ip (K, d,f
 ({K} t E)  ip (K,  ({K } t E)). This inequation
d,f
shows that  is not manipulable for ip , which contradicts the assumption. So case
(**) has to be excluded as well, and this concludes the proof.


Theorem 11 Let d be any distance. If d,
is not strategy-proof for the index idw (resp.

ids ), then it is not erosion strategy-proof for idw (resp. ids ).
Proof:

We first need the following lemma:

Lemma 2 Let d be a pseudo-distance and let f be an aggregation function. If a profile E
is manipulable by K for idw (resp. ids ) given d,f
 and , then one can find a complete base
K 0  the base the agent gives instead of her true base K  s.t. idw (K,  (E t {K 0 })) >
idw (K,  (E t {K})) (resp. ids (K,  (E t {K 0 })) > ids (K,  (E t {K}))).
Proof:
This lemma is mainly a consequence of the definition of the distance between an
interpretation and a base K 0 , as the minimal distance between an interpretation and a model
 00 of the base; the complete base whose unique model is  00 allows as well a manipulation
Weak drastic index.
94

fiThe Strategy-Proofness Landscape of Merging

We suppose that d,f
 is manipulable for idw , i.e., we can find an integrity constraint , a
profile E = {K1 , . . . , Kn }, and two bases K and K 0 s.t.:
d,f
0
idw (K, d,f
 ({K} t E)) < idw (K,  ({K } t E)).

(12)

This is equivalent to: idw (K, E 4 K) = 0 and idw (K, E 4 K 0 ) = 1, where d,f
 ({K} t E)
is noted E 4 K for simplifying notations.
Statement (13) states that idw (K, E 4 K) = 0: no model of K   is a model of E 4 K;
statement (14) states that idw (K, E 4 K 0 ) = 1: there is as least one model of K   in
E 4 K 0 :
 |= K  ,  0 |= (K)  , d( 0 , E t {K}) < d(, E t {K}).

(13)

1 |= K  ,  |= , d(1 , E t {K 0 })  d(, E t {K 0 }).

(14)

Since in (13) the choice of  0 can be made apart from , (13) is equivalent to:
 0 |= (K)  ,  |= K  , d( 0 , E t {K}) < d(, E t {K}).

(15)

Let  00 |= K 0 s.t. d(1 , K 0 ) = d(1 ,  00 ). We consider the complete base K 00 s.t. [K 00 ] = { 00 }.
we shall show in the rest of the proof that d,f
 is manipulable with that base. If the agent
whose beliefs/goals are K gives K 00 as a base instead of K, then, since d(1 , K 00 ) = d(1 , K 0 ),
we have:
d(1 , E t {K 00 }) = d(1 , E t {K 0 }),
(16)
and then:
 |= , d(1 , E t {K 00 })  d(, E t {K 0 }),

(17)

with (14) and (16).
Furthermore, since the aggregation function f is non-decreasing (by definition) and since
K 00 |= K 0 , we have  |= , d(, E t {K 0 })  d(, E t {K 00 }), so we get immediately with
(17):
 |=  : d(1 , E t {K 00 })  d(, E t {K 00 }).
(18)
d,f
00
00
So 1 is a model of d,f
 (E t {K }), and we have idw (K,  ({K } t E)) = 1 and
d,f
d,f
00
idw (K, d,f
 ({K} t E)) < idw (K,  ({K } t E)). This shows that  is manipulable
00
for a complete base K .

Strong drastic index. Let us assume that an operator d,f
 , where d is any pseudo-distance
and f any aggregation function, is manipulable for the strong drastic index ids .Then we
can find an integrity constraint , a profile E and bases K and K 0 s.t. ids (K, d,f
 (E t
0 }). This implies that i (K, d,f (E t {K}) = 0, and i (K,
{K}) < ids (K, d,f
(E
t
{K


ds
ds
d,f
0
d,f
 (E t {K }) = 1. This means, by definition of the index, that  (E t {K}) 6|= K, and
0
d,f
 (E t {K }) |= K.
0
0
0
Given a model 1 of d,f
 (E t {K }) and a model 2 of K s.t. d(1 , K ) = d(1 , 2 ),
we define K 00 = {2 }. Then we have d(1 , K 00 ) = d(1 , K 0 ), and: d(1 , E t {K 00 }) =
d(1 , E t {K 0 }).

95

fiEveraere, Konieczny & Marquis

0
0
Let us note dmin (E td,f
 {K }) = min({d(, E t {K }) |  |= }, ). Since 1 is a model of
d,f
0
 (E t {K 0 }), we have d(1 , E t {K 0 }) = dmin (E td,f
 {K }). Hence:
0
d(1 , E t {K 00 }) = dmin (E td,f
 {K }).

(19)

00
By definition of min and since 1 |= , we also have: d(1 , E t {K 00 })  dmin (E td,f
 {K }).
So we get:
0
d,f
00
dmin (E td,f
(20)
 {K })  dmin (E t {K }).

On the other hand, since K 00 |= K 0 , we have:   W, d(, K 0 )  d(, K 00 ). Since the
aggregation function f is non-decreasing, we get:
  W, d(, E t {K 0 })  d(, E t {K 00 }),

(21)

d,f
d,f
0
00
0
and then dmin (E td,f
 {K })  dmin (E t {K }). With (20) we get dmin (E t {K }) =
d,f
d,f
00
00
00
dmin (E t {K }). Then, with (19), we obtain d(1 , E t {K }) = dmin (E t {K }). Since
00
1 |= , we have that 1 is a model of d,f
 (E t {K }) too.
d,f
00
00
00
Let  be a model of d,f
 (E t{K }). Then,  |=  and d(, E t{K }) = dmin (E t {K }).
d,f
d,f
0
00
00
Then, since dmin (E td,f
 {K }) = dmin (E t {K }), we have d(, E t {K }) = dmin (E t
0
{K 0 }). With (21), we get d(, E t {K 0 })  dmin (E td,f
 {K }).
0
Then, by definition of min we have d(, E t {K 0 }) = dmin (E td,f
 {K }).
0
This implies that  is a model of d,f
 (E t {K }) too (because  |= ), so we can write:
d,f
d,f
00
0
0
d,f
 (E t {K }) |=  (E t {K }). Since we have  (E t {K }) |= K, we can infer that
d,f
00
00
d,f
 (E t {K }) |= K, and then ids (K,  (E t {K }) = 1.

We get then a manipulation for ids with a complete base K 00 , and this completes the proof
of the lemma.

Let us now give the proof of the main theorem:
Weak drastic index. By reductio ad absurdum. We assume that d,
is a manipulable

operator and that it is not manipulable by erosion. Then we can find an integrity constraint
, a profile E, and two bases K and K 0 with K 0 6|= K s.t.:
d,
0
idw (K, d,
 (E t {K})) < idw (K,  (E t {K })).

Lemma 2 shows that that we can assume [K 0 ] = {10 } complete; it comes:
d,
0
idw (K, d,
 (E t {K})) < idw (K,  (E t {1 })).

This implies that:
idw (K, d,
 (E t {K}) = 0
0
idw (K, d,
 (E t {1 }) = 1.

96

(22)

fiThe Strategy-Proofness Landscape of Merging

This means there is no model of K   which is a model of d,
 (E t {K}), and that there
d,
is at least one model 1 of K   which is a model of  (E t {10 }). We can express those
facts by two statements:
 |= K  ,  0 |= K  , d( 0 , E t {K}) < d(, E t {K})
and:
1 |= K  ,  |= , d(1 , E t {10 })  d(, E t {10 }).
Hence:
1 |= K  ,  |= , d(1 , 10 ) + d(1 , E)  d(, 10 ) + d(, E)

(23)

Let us now define a new base K 00 = {1 }. Since we have supposed the operator not
manipulable by erosion and since K 00 |= K, we can then state that it is strategy-proof for
d,
00
idw with K 00 : idw (K, d,
 (E t {K}))  idw (K,  (E t {K })). This implies that:
 either idw (K, d,
 (E t {K})) = 1,
d,
00
 or idw (K, d,
 (E t {K})) = idw (K,  (E t {K })) = 0.
00
From equation (22), we can infer that idw (K, d,
 (E t {K })) = 0, and we have  |=
0
0
00
00
K  ,  |= K  , d( , E t {K }) < d(, E t {K }).

Since K 00 = {1 } and the choice of  0 can be made independently of 1 , we have 2 |=
(K)  ,  |= K  , d(2 , E t {1 }) < d(, E t {1 }), that is:
2 |= K  ,  |= K  , d(2 , 1 ) + d(2 , E) < d(, 1 ) + d(, E).
In particular, this statement holds for  = 1 , because 1 |= K  . Hence:
d(2 , 1 ) + d(2 , E) < d(1 , 1 ) + d(1 , E).
Since d(1 , 1 ) = 0, we obtain finally:
d(2 , 1 ) + d(2 , E) < d(1 , E).

(24)

On the other hand, since 2 |= , with (23), we get:
d(1 , 10 ) + d(1 , E)  d(2 , 10 ) + d(2 , E).
Summing (24) and (25) side by side, we get:
d(2 , 1 ) + d(2 , E) + d(1 , 10 ) + d(1 , E) < d(1 , E) + d(2 , 10 ) + d(2 , E).
Simplifying by d(1 , E) and d(2 , E), we obtain:
d(2 , 1 ) + d(1 , 10 ) < d(2 , 10 ).
97

(25)

fiEveraere, Konieczny & Marquis

This contradicts the triangular inequality. So, if manipulation is possible, then it is possible
by erosion with a complete base K 00 = {1 }.
Strong drastic index. Let us assume that d,
is manipulable for ids . So we can find a

profile E, an integrity constraint  and two bases K and K 0 s.t.:
d,
0
ids (K, d,
 (E t {K})) < ids (K,  (E t {K })).

This implies that:
ids (K, d,
 (E t {K}) = 0

(26)

and
0
ids (K, d,
 (E t {K }) = 1.

This means that there is at least one model of d,
 (E t {K}) which is not a model of K,
0 }) is a model of K  . Let us consider a model 
(E
t
{K
and that every model of d,

1
0
of d,
 (E t {K }). We can write that 1 |= K   and:
 |= , d(1 , E t {K 0 })  d(, E t {K 0 }).
So we have:
 |= , d(1 , K 0 ) + d(1 , E)  d(, K 0 ) + d(, E).
Let us define K 00 = {1 } and show that there is manipulation with this base. Let us assume
d,
00
00
00
that we can find  00 |= d,
 (E t {K }) s.t.  6|= K. Since  |=  (E t {1 }), we have
 00 |=  and
d(, E t {1 })  d(1 , E t {1 }),
and then:
d(, 1 ) + d(, E)  d(1 , E)
(as d(1 , 1 ) = 0).
0
We know that  00 6|= K and  00 |= , so we can infer that  00 6|= d,
 (E t {K }) (else we
d,
00
0
should have  |= K). Since 1 is a model of  (E t {K }), we have:
d(, E t {K 0 }) > d(1 , E t {K 0 }).
Equivalently:
d(, K 0 ) + d(, E) > d(1 , K 0 ) + d(1 , E).
Since d(1 , E)  d(, 1 ) + d(, E), we obtain:
d(, K 0 ) + d(, E) > d(1 , K 0 ) + d(, 1 ) + d( 00 , E).
Simplifying this equation by d(, E), we get:
d(, K 0 ) > d(1 , K 0 ) + d(, 1 ).
If 2 is a model of K 0 s.t. d(1 , K 0 ) = d(1 , 2 ), we have:
d(, K 0 ) > d(1 , 2 ) + d(, 1 ),
98

fiThe Strategy-Proofness Landscape of Merging

and finally, since d(, 2 )  d(, K 0 ) by definition of min, we get:
d(, 2 ) > d(1 , 2 ) + d(, 1 ).
This contradicts the triangular inequality.
d,
00
We have shown that every model of d,
 (E t{K }) is a model of K. Hence, ids (K,  (E t
{K 00 }) = 1. Since ids (K, d,
 (E t {K}) = 0 with (26), we have:
d,
00
ids (K, d,
 (E t {K})) < ids (K,  (E t {K })),

and a manipulation by erosion with a complete base is possible.

Corollary 12 A profile E is manipulable by K for idw (resp. ids ) given d,
 and  if and
only if the manipulation is possible using a complete base K |= K, i.e., there exists K |= K
d,
d,
s.t. idw (K, d,
 (E t {K })) > idw (K,  (E t {K})) (resp. ids (K,  (E t {K })) >
ids (K, d,
 (E t {K}))).
Proof:
(): This is a consequence of Theorem 11 and of Lemma 2, which enable to
state that if K is manipulable for i = idw or i = ids given d,
 and E, then one can find a
d,f
0
0
0
base K = { } |= K complete such that i(K,  (E t { })) > i(K, d,f
 (E t {K})).
(): If K is strategy-proof for i = idw or i = ids given d,
and E, then [K 0 ] 

d,
d,
0
W, i(K,  (E t {K })  i(K,  (E t {K})). This is in particular true when K 0 is
reduced to a singleton.

Theorem 14 max , min1 , min2 , and  are strategy-proof for idw , ids and ip .
V
Proof:
max (or equivalently min2 ) is strategy-proof for ip . Indeed, if E is
consistent, then all the models
V of the merged base are models of K1  E, thus the satisfaction
of K1 is maximal for ip . If E is not consistent,
V then the merged base is valid. Assume that
agent 1 reports K10 instead of K1 . If K10  {K2 , . . . , Kn } isVconsistent, then no model of
the resulting merged base is a model of K1 . In the case K10  {K2 , . . . , Kn } is inconsistent,
then the resulting merged base is still valid. From Theorem 1, max (or equivalently min2 )
is also strategy-proof for the two drastic indexes.
V
V
E
is
consistent
is
as
above.
If
E
min1 is also strategy-proof for ip . The case when
W
is not consistent, the result of the merging is E and all the models of K1 are models
of the merged base. So, in order to increase the value of the ip index, it is not possible
to increase the number of models of K1 in the result of the merging. Hence one needs to
decrease the number of countermodels of K1 in the merged base. But we shall
show that
V
it is not possible: assume that agent 1 reports K10 instead of K1 . If K10  {KV
2 , . . . , Kn }
is consistent, then no model of the resulting merged base is a model of K1 (as E is not
consistent).
99

fiEveraere, Konieczny & Marquis

Then K10 

V

{K2 , . . . , Kn } is not consistent, and we have:
ip (K1 , min1 (K1 t {K2 , . . . , Kn })) =

and
ip (K1 , min1 (K10

#([K1 

#([K1 ])
W
{K2 , . . . , Kn }])

W
#([K1  (K10  {K2 , . . . , Kn })])
W
.
t {K2 , . . . , Kn })) =
#([K10  {K2 , . . . , Kn }])

The numerator of ip (K1 , min1 (K1 t {K2 , . . . , Kn })) is maximal, so in order to increase
ip (K1 , min1 (K10 t{K2 , . . . ,W
Kn })), we have to decrease the denominator of ip (K1 , min1 (K10
0
t{K2 , . . . , Kn })), #([K1  {K2 , . . . , Kn }]).
We can write the following equality:
#([K10 

_

_
{K2 , . . . , Kn }]) = #([K10  K1  ( {K2 , . . . , Kn })])+
_
_
#([K10  K1  ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }]).

W
In this sum, #([ {K2 , . . . , Kn }]) cannot
be changed. We have to decrease the two other
W
0 K ( {K , . . . , K })]) is minimal if K 0 is such that #([K 0 
terms of this
sum:
#([K
1
2
n
1
1
1
W
KW1  ( {K2 , . . . , Kn })]) = 0. In the following, we suppose then that #([K10  K1 
( {K2 , . . . , Kn })]) = 0.
W
For the first term of the sum, #([K10  K1  ( {K2 , . . . , Kn })]), we can write:
_
#([K10  K1  ( {K2 , . . . , Kn })]) =
_
_
#([K1  ( {K2 , . . . , Kn })])  #([K1  K10  ( {K2 , . . . , Kn })])
So we obtain for the probabilistic index:
ip (K1 , min1 (K10 t {K2 , . . . , Kn })) =
W
#([K1 ])  #([K1  K10  ( {K2 , . . . , Kn })])
W
W
W
.
#([K1  ( {K2 , . . . , Kn })])  #([K1  K10  ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])
a
Now remark that if k is an integer and if a  b, then ak
bk  b . If we subtract the same
W
0
integer #([K1  K1  ( {K2 , . . . , Kn })]) from the numerator and the denominator, then
we get the following inequation:

W
#([K1 ])  #([K1  K10  ( {K2 , . . . , Kn })])
W
W
W

#([K1  ( {K2 , . . . , Kn })])  #([K1  K10  ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])
#([K1 ])
W
W
.
#([K1  ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])

So:
ip (K1 , min1 (K10 t {K2 , . . . , Kn })) 

#([K1 ])
W
W
#([K1  ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])
100

fiThe Strategy-Proofness Landscape of Merging

then
ip (K1 , min1 (K10 t {K2 , . . . , Kn }))  ip (K1 , min1 (K1 t {K2 , . . . , Kn })).
No manipulation is possible, and min1 is strategy-proof for ip . From Theorem 1, min1 is
also strategy-proof for the two drastic indexes.
Finally,  is strategy-proof for the three indexes (see Theorem 2).



Theorem 15  satisfies the (IP) property if and only if for every profile E and every pair
of bases K and K 0 :
 K  (E t {K}) |= (E t {K 0 }), and
 K  (E t {K}) |= (E t {K 0 }).
Proof:
Suppose that a merging operator  = Bel( )) does not satisfy the (IP)
property. Then there is a profile E, an agent i, an OCF , an interpretation   W s.t.
| (E)()  i ()| > | (rep(E, {i}, )()  i ()|
where rep(E, {i}, ) is the profile identical to E except that the OCF i is replaced by . In
the following we note (E t {K}) for Bel( (E)): it is the initial merged base when agent
i reports her true base K  Bel(i ), and we note (E t {K 0 }) for Bel( (rep(E, {i}, )):
it is the merged base obtained by replacing the base K of agent i by another K 0  Bel().
Focusing on two-strata OCFs, this inequation entails that | (E)()  i ()| = 1 and
| (rep(E, {i}, )()  i ()| = 0. Since | (rep(E, {i}, )()  i ()| = 0,  is a model
of both (E t {K 0 }) and of K (*), or  is a countermodel of both (E t {K 0 }) and of K
(**).
To get | (E)()  i ()| = 1, there are also two cases:
 either  (E)() = 1 and i () = 0: then  is a model of K and a countermodel
of (E t {K}). Since  is a model of K, with (*), we know that  is a model of
(E t {K 0 }). Then  is a model of K, of ((E t {K})) and not of (E t {K 0 }):
it entails that
K  (E t {K}) 6|= (E t {K 0 }).
 or  (E)() = 0 and i () = 1: then  is a countermodel of K and a model of (E t
{K}). Since  is a countermodel of K, with (**), we know that  is a countermodel
of (E t {K 0 }). Then  is a model of K, of (E t {K}) and not of (E t {K 0 }):
it entails that
K  (E t {K}) 6|= (E t {K 0 }).
Hence it is not the case that both
 K  (E t {K}) |= (E t {K 0 }), and
101

fiEveraere, Konieczny & Marquis

 K  (E t {K}) |= (E t {K 0 }).
are satisfied.
As to the converse, suppose that there is a profile E, an agent i with a base K, and another
base K 0 s.t.:
K  (E t {K}) 6|= (E t {K 0 })
or
K  (E t {K}) 6|= (E t {K 0 }).
In the first case, there is a model  of K  (E t {K}) which is a countermodel of
(E t {K 0 }) :
 (E)() = 1, i () = 0,  (rep(E, {i}, )() = 0.
So
| (E)()  i ()| > | (rep(E, {i}, )()  i ()|.
In the second case, there is a model  of K  (E t {K}) which is a countermodel of
(E t {K 0 }):
 (E)() = 0, i () = 1,  (rep(E, {i}, )() = 1.
So
| (E)()  i ()| > | (rep(E, {i}, )()  i ()|.
In both cases,  does not satisfy the (IP) property.
1
#([KK ]))+1 .

Theorem 16 Let iwip (K, K ) =
only if it is strategy-proof for iwip .
Proof:



 satisfies the (WIP) property if and

By definition K  K  (K  K )  (K  K ) So we can write:
iwip (K, K ) =

1
#([(K  K )  (K  K )]) + 1

if and only if
iwip (K, K ) =

1
.
#([K  K ]) + #([K  K ]) + 1

Suppose that a merging operator  = Bel( )) does not satisfy the (WIP) property. Then
there is a profile E, an agent i, an OCF  s.t.
W | (E)()  i ()| > W | (rep(E, {i}, )()  i ()|

()

In the following we note (E t {K}) for Bel( (E)), that is the initial merged base when
agent i reports her true base K  Bel(i ), and we note (E t {K 0 }) for Bel( (rep(E, {i},
)), i.e., the merged base obtained by replacing the base K of the agent i by another
K 0  Bel().
In the two-strata case, | (E)()  i ()| is equal to 0 or 1. In fact, | (E)()  i ()| = 1
if and only if:
102

fiThe Strategy-Proofness Landscape of Merging

 either  (E)() = 1 and i () = 0: this is equivalent to  |= K  (E t {K}).
 or  (E)() = 0 and i () = 1: this is equivalent to  |= K  (E t {K}).
We deduce the following equation:
W | (E)()  i ()| = #([K  (E t {K})]) + #([K  (E t {K})]).
Similarly, we get:
W | (rep(E, {i}, )()  i ()| = #([K  (E t {K 0 })]) + #([K  (E t {K 0 })])
The inequation (*) is then equivalent to:
#([K  (E t {K})]) + #([K  (E t {K})]) > #([K  (E t {K 0 })]) + #[K  (E t {K 0 })])

which is equivalent to
1
<
#([K  (E t {K})]) + #([K  (E t {K})]) + 1
1
#([K  (E t {K 0 })]) + #([K  (E t {K 0 })]) + 1
which is equivalent to
iwip (K, (E t {K})) < iwip (K, (E t {K 0 }))
which is equivalent to the fact that  is not strategy-proof for iwip .


References
Arrow, K. J. (1963). Social choice and individual values (second edition). Wiley, New York.
Arrow, K., Sen, A. K., & Suzumura, K. (Eds.). (2002). Handbook of Social Choice and
Welfare, Vol. 1. North-Holland.
Baral, C., Kraus, S., & Minker, J. (1991). Combining multiple knowledge bases. IEEE
Transactions on Knowledge and Data Engineering, 3 (2), 208220.
Baral, C., Kraus, S., Minker, J., & Subrahmanian, V. S. (1992). Combining knowledge
bases consisting of first-order theories. Computational Intelligence, 8 (1), 4571.
Barbera, S., Dutta, B., & Sen, A. (2001). Strategy-proof social choice correspondences.
Journal of Economic Theory, 101 (2), 374394.
Benferhat, S., Dubois, D., Kaci, S., & Prade, H. (2002). Possibilistic merging and distancebased fusion of propositional information. Annals of Mathematics and Artificial Intelligence, 34 (13), 217252.
Borda, J. (1781). Memoire sur les elections au srutin. Histoire de lAcademie Royale des
Sciences.
103

fiEveraere, Konieczny & Marquis

Brams, S. J., & Fishburn, P. C. (1983). Approval voting. Springer Verlag.
Chin, S., & Zhou, L. (2002). Multi-valued strategy-proof social choice rules. Social Choice
and Welfare, 19 (3), 569580.
Chopra, S., Ghose, A., & Meyer, T. (2006). Social choice theory, belief merging and strategyproofness. Information Fusion, 7 (1), 6179.
Condorcet, M. (1785). Essai sur lapplication de lanalyse a la probabilite des decisions
rendues a la pluralite des voix. Paris.
Conitzer, V., Lang, J., & Sandholm, T. (2003). How many candidates are needed to make
elections hard to manipulate?. In Proceedings of the Ninth Conference on Theoretical
Aspects of Rationality and Knowledge (TARK03), pp. 201214.
Conitzer, V., & Sandholm, T. (2002a). Complexity of manipulating elections with few candidates. In Proceedings of the Eighteenth National Conference on Artificial Intelligence
(AAAI02), pp. 314319.
Conitzer, V., & Sandholm, T. (2002b). Vote elicitation: complexity and strategyproofness. In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI02), pp. 392397.
Conitzer, V., & Sandholm, T. (2003). Universal voting protocol tweaks to make manipulation hard. In Proceedings of the Eighteenth International Joint Conference on
Artificial Intelligence (IJCAI03), pp. 781788.
Dalal, M. (1988). Investigations into a theory of knowledge base revision: preliminary report.
In Proceedings of the Seventh American National Conference on Artificial Intelligence
(AAAI88), pp. 475479.
Duggan, J., & Schwartz, T. (2000). Strategic manipulability without resoluteness or shared
beliefs: Gibbard-satterthwaite generalized. Social Choice and Welfare, 17, 8593.
Everaere, P., Konieczny, S., & Marquis, P. (2005). Quota and gmin merging operators. In
Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence
(IJCAI05), pp. 424429.
Gibbard, A. (1973). Manipulation of voting schemes. Econometrica, 41, 587602.
Kelly, J. S. (1988). Social Choice Theory : An Introduction. Springer-Verlag.
Konieczny, S. (2000). On the difference between merging knowledge bases and combining them. In Proceedings of the Seventh International Conference on Principles of
Knowledge Representation and Reasoning (KR00), pp. 135144.
Konieczny, S., Lang, J., & Marquis, P. (2004). DA2 merging operators. Artificial Intelligence,
157 (1-2), 4979.
Konieczny, S., Lang, J., & Marquis, P. (2005). Reasoning under inconsistency: the forgotten connective. In Proceedings of the Nineteenth International Joint Conference on
Artificial Intelligence (IJCAI05), pp. 484489.
Konieczny, S., & Pino Perez, R. (1998). On the logic of merging. In Proceedings of the Sixth
International Conference on Principles of Knowledge Representation and Reasoning
(KR98), pp. 488498.
104

fiThe Strategy-Proofness Landscape of Merging

Konieczny, S., & Pino Perez, R. (1999). Merging with integrity constraints. In Proceedings of
the Fifth European Conference on Symbolic and Quantitative Approaches to Reasoning
with Uncertainty (ECSQARU99), LNAI 1638, pp. 233244.
Konieczny, S., & Pino Perez, R. (2002). Merging information under constraints: a logical
framework. Journal of Logic and Computation, 12 (5), 773808.
Liberatore, P., & Schaerf, M. (1998). Arbitration (or how to merge knowledge bases). IEEE
Transactions on Knowledge and Data Engineering, 10 (1), 7690.
Lin, J., & Mendelzon, A. O. (1999). Knowledge base merging by majority. In Dynamic
Worlds: From the Frame Problem to Knowledge Management. Kluwer.
Maskin, E., & Sjostrom, T. (2002). Handbook of Social Choice and Welfare, Vol. 1, chap.
Implementation Theory, pp. 237288. North-Holland.
Meyer, T., Ghose, A., & Chopra, S. (2001). Social choice, merging and elections. In Proceedings of the Sixth European Conference on Symbolic and Quantitative Approaches
to Reasoning with Uncertainty (ECSQARU01), pp. 466477.
Moulin, H. (1988). Axioms of cooperative decision making, chap. 9. Econometric society
monographs. Cambridge University Press.
Rescher, N., & Manor, R. (1970). On inference from inconsistent premises. Theory and
Decision, 1, 179219.
Revesz, P. Z. (1993). On the semantics of theory change: arbitration between old and
new information. In Proceedings of the Twelfth ACM SIGACT-SIGMOD-SIGART
Symposium on Principles of Databases, pp. 7192.
Revesz, P. Z. (1997). On the semantics of arbitration. International Journal of Algebra and
Computation, 7 (2), 133160.
Satterthwaite, M. (1975). Strategy-proofness and Arrows conditions. Journal of Economic
Theory, 10, 187217.
Shoham, Y., & Tennenholtz, M. (2005). Non-cooperative computation: Boolean functions
with correctness and exclusivity. Theoretical Computer Science, 343 (1-2), 97113.
Spohn, W. (1987). Ordinal conditional functions: a dynamic theory of epistemic states.
In Harper, W. L., & Skyrms, B. (Eds.), Causation in Decision, Belief Change, and
Statistics, Vol. 2, pp. 105134.
Tversky, A. (2003). Preference, Belief, and Similarity. MIT Press.

105

fi