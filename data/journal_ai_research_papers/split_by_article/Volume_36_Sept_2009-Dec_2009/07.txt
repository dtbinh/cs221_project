Journal of Artificial Intelligence Research 36 (2009) 513-546

Submitted 08/09; published 12/09

RoxyBot-06: Stochastic Prediction and Optimization
in TAC Travel
Amy Greenwald

amy@cs.brown.edu

Department of Computer Science, Brown University
Providence, RI 02912 USA

Seong Jae Lee

seongjae@u.washington.edu

Computer Science and Engineering, University of Washington
Seattle, WA 98195 USA

Victor Naroditskiy

vnarodit@cs.brown.edu

Department of Computer Science, Brown University
Providence, RI 02912 USA

Abstract
In this paper, we describe our autonomous bidding agent, RoxyBot, who emerged victorious in the travel division of the 2006 Trading Agent Competition in a photo finish. At
a high level, the design of many successful trading agents can be summarized as follows:
(i) price prediction: build a model of market prices; and (ii) optimization: solve for an
approximately optimal set of bids, given this model. To predict, RoxyBot builds a stochastic model of market prices by simulating simultaneous ascending auctions. To optimize,
RoxyBot relies on the sample average approximation method, a stochastic optimization
technique.

1. Introduction
The annual Trading Agent Competition (TAC) challenges its entrants to design and build
autonomous agents capable of effective trading in an online travel1 shopping game. The first
TAC, held in Boston in 2000, attracted 16 entrants from six countries in North America,
Europe, and Asia. Excitement generated from this event led to refinement of the game
rules, and continuation of regular tournaments with increasing levels of competition over
the next six years. Year-by-year, entrants improved their designs, developing new ideas
and building on previously successful techniques. Since TACs inception, the lead author
has entered successive modifications of her autonomous trading agent, RoxyBot. This paper
reports on RoxyBot-06, the latest incarnation and the top scorer in the TAC-06 tournament.
The key feature captured by the TAC travel game is that goods are highly interdependent
(e.g., flights and hotels must be coordinated), yet the markets for these goods operate
independently. A second important feature of TAC is that agents trade via three different
kinds of market mechanisms, each of which presents distinct challenges. Flights are traded
in a posted-price environment, where a designated party sets a price that the other parties
1. There are now four divisions of TAC: Travel, Supply Chain Management (SCM), CAT (TAC backwards),
and Ad Auctions (AA). This paper is concerned only with the first; for a description of the others, see the
papers by Arunachalam and Sadeh (2005), Cai et al. (2009), Jordan and Wellman (2009), respectively.
In this paper, when we say TAC, we mean TAC Travel.

c
2009
AI Access Foundation. All rights reserved.

fiGreenwald, Lee, & Naroditskiy

must take or leave. Hotels are traded in simultaneous ascending auctions, like the FCC
spectrum auctions. Entertainment tickets are traded in continuous double auctions, like
the New York Stock Exchange. In grappling with all three mechanisms while constructing
their agent strategies, participants are confronted by a number of interesting problems.
The success of an autonomous trading agent such as a TAC agent often hinges upon
the solutions to two key problems: (i) price prediction, in which the agent builds a model
of market prices; and (ii) optimization, in which the agent solves for an approximately
optimal set of bids, given this model. For example, at the core of RoxyBots 2000 architecture (Greenwald & Boyan, 2005) was a deterministic optimization problem, namely how to
bid given price predictions in the form of point estimates. In spite of its effectiveness in the
TAC-00 tournament, a weakness of the 2000 design was that RoxyBot could not explicitly
reason about variance within prices. In the years since 2000, we recast the key challenges
faced by TAC agents as several different stochastic bidding problems (see, for example, the
paper by Greenwald & Boyan, 2004), whose solutions exploit price predictions in the form
of distributions. In spite of our perseverance, RoxyBot fared unimpressively in tournament
conditions year after year, until 2006. Half a decade in the laboratory spent searching for
bidding heuristics that can exploit stochastic information at reasonable computational expense finally bore fruit, as RoxyBot emerged victorious in TAC-06. In a nutshell, the secret
of RoxyBot-06s success is: (hotel) price prediction by simulating simultaneous ascending
auctions, and optimization based on the sample average approximation method. Details of
our approach are the subject of the present article.
Overview This paper is organized as follows. Starting in Section 2, we summarize the
TAC market game. Next, in Section 3, we present a high-level view of RoxyBots 2006
architecture. In Section 4, we describe RoxyBots price prediction techniques for flights, hotels, and entertainment, in turn. Perhaps of greatest interest is our hotel price prediction
method. Following Wellman et al. (2005), we predict hotel prices by computing approximate competitive equilibrium prices. Only, instead of computing those prices by running
the tatonnement process, we simulate simultaneous ascending auctions. Our procedure is
simpler to implement than tatonnement, yet achieves comparable performance, and runs
sufficiently fast. In Section 5, we describe RoxyBots optimization technique: sample average
approximation. We argue that this approach is optimal in pseudo-auctions, an abstract
model of auctions. In Section 6.1, we describe simulation experiments in a controlled testing environment which show that our combined approachsimultaneous ascending auctions
for hotel price prediction and sample average approximation for bid optimizationperforms
well in practice in comparison with other reasonable bidding heuristics. In Section 6.2, we
detail the results of the TAC-06 tournament, further validating the success of RoxyBot-06s
strategy, and reporting statistics that shed light on the bidding strategies of other participating agents. Finally, in Section 7, we evaluate the collective behavior of the autonomous
agents in the TAC finals since 2002. We find that the accuracy of competitive equilibrium
calculations has varied from year to year and is highly dependent on the particular agent
pool. Still, generally speaking, the collective appears to be moving toward competitive
equilibrium behavior.

514

fiRoxyBot-06

2. TAC Market Game: A Brief Summary
In this section, we summarize the TAC game. For more details, see http://www.sics.se/
tac/.
Eight agents play the TAC game. Each is a simulated travel agent whose task is to
organize itineraries for its clients to travel to and from TACTown during a five day (four
night) period. In the time allotted (nine minutes), each agents objective is to procure
travel goods as inexpensively as possible, trading off against the fact that those goods are
ultimately compiled into feasible trips that satisfy its client preferences to the greatest
extent possible. The agents know the preferences of their own eight clients only, not the
other 56.
Travel goods are sold in simultaneous auctions as follows:
 Flight tickets are sold by TACAir in dynamic posted-pricing environments. There
are flights both to and from TACTown on each applicable day. No resale of flight
tickets by agents is permitted.
Flight price quotes are broadcast by the TAC server every ten seconds.
 Hotel reservations are sold by the TAC seller in multi-unit ascending call markets.
Specifically, 16 hotel reservations are sold in each hotel auction to the 16 highest
bidders at the 16th highest price. The TAC seller runs eight hotel auctions, one per
night-hotel combination (recall that travel takes place during a four night period;
moreover, there are two hotels: a good one and a bad one). No resale of hotel
reservations by agents is permitted. Nor is bid withdrawal allowed.
More specifically, the eight hotel auctions clear on the minute with exactly one auction
closing at each of minutes one through eight. (The precise auction to close is chosen
at random, with all open auctions equally likely to be selected.) For the auction that
closes, the TAC server broadcasts the final closing price, and informs each agent of its
winnings. For the others, the TAC server reports the current ask price, and informs
each agent of its hypothetical quantity won (HQW).
 Agents are allocated an initial endowment of entertainment tickets, which they trade
among themselves in continuous double auctions (CDAs). There are three entertainment events scheduled each day.
Although the event auctions clear continuously, price quotes are broadcast only every
30 seconds.
One of the primary challenges posed by TAC is to design and build autonomous agents
that bid effectively on interdependent (i.e., complementary or substitutable) goods that are
sold in separate markets. Flight tickets and hotel reservations are complementary because
flights are not useful to a client without the corresponding hotel reservations, nor vice
versa. Tickets to entertainment events (e.g., the Boston Red Sox and the Boston Symphony
Orchestra) are substitutable because a client cannot attend multiple events simultaneously.

515

fiGreenwald, Lee, & Naroditskiy

REPEAT
{start bid interval }
0. Download current prices and winnings from server
1. predict: build stochastic models
a. flights: Bayesian updating/learning
b. hotels: simultaneous ascending auctions
c. entertainment: sample historical data
2. optimize: sample average approximation
3. Upload current bids to server
(three separate threads)
{end bid interval }
UNTIL game over

Table 1: A high-level view of RoxyBot-06s architecture.

3. RoxyBot-06s Architecture: A High-Level View
In our approach to the problem of bidding on interdependent goods in the separate TAC
markets, we adopt some simplifying assumptions. Rather than tackle the game-theoretic
problem of characterizing strategic equilibria, we focus on a single agents (decision-theoretic)
problem of optimizing its own bidding behavior, assuming the other agents strategies are
fixed. In addition, we assume that the environment can be modeled in terms of the agents
predictions about market clearing prices. These prices serve to summarize the relevant information hidden in other agents bidding strategies. These two assumptionsfixed otheragent behaviors and market information encapsulated by pricessupport the modular design of RoxyBot-06 and many other successful TAC agents, which consists of two key stages:
(i) price prediction; and (ii) optimization.
The optimization problem faced by TAC agents is a dynamic one that incorporates
aspects of sequentiality as well as simultaneity in auctions. The markets operate simultaneously, but in addition, prices are discovered incrementally over time. In principle, a
clairvoyant agentone with knowledge of future clearing pricescould justifiably employ
an open-loop strategy: it could solve the TAC optimization problem once at the start of the
game and place all its bids accordingly, never reconsidering those decisions. A more practical alternative (and the usual approach taken in TAC2 ), is to incorporate into an agents
architecture a closed loop, or bidding cycle, enabling the agent to condition its behavior
on the evolution of prices. As price information is revealed, the agent improves its price
predictions, and reoptimizes its bidding decisions, repeatedly.
One distinguishing feature of RoxyBot-06 is that it builds stochastic models of market
clearing prices, rather than predicting clearing prices as point estimates. Given its stochastic
price predictions, stochastic optimization lies at the heart of RoxyBot-06. Assuming time is
2. An exception is livingagents (Fritschi & Dorer, 2002), the winner of TAC 2001.

516

fiRoxyBot-06

discretized into stages, or bid intervals, during each iteration of its bidding cycle, RoxyBot-06
faces an n-stage stochastic optimization problem, where n is the number of stages remaining
in the game. The key input to this optimization problem is a sequence of n  1 stochastic
models of future prices, each one a joint probability distribution over all goods conditioned
on past prices and past hotel closings. The solution to this optimization problem, and the
output of each iteration of the bidding cycle, is a vector of bids, one per good (or auction).
Table 1 presents a high-level view of RoxyBot-06s architecture, emphasizing its bidding
cycle. At the start of each bid interval, current prices and winnings are downloaded from
the TAC server. Next, the key prediction and optimization routines are run. In the prediction module, stochastic models of flight, hotel, and entertainment prices are built. In
the optimization module, bids are constructed as an approximate solution to an n-stage
stochastic optimization problem. Prior to the end of each bid interval, the agents bids
are uploaded to the TAC server using three separate threads: (i) the flight thread bids on
a flight only if its price is near its predicted minimum; (ii) the hotel thread bids on open
hotels only if it is moments before the end of a minute; and (iii) the entertainment thread
places bids immediately.
We discuss the details of RoxyBot-06s price prediction module first, and its optimization
module second.

4. Price Prediction
In this section, we describe how RoxyBot-06 builds its stochastic models of flight, hotel, and
event prices. Each model is a discrete probability distribution, represented by a set of scenarios. Each scenario is a vector of future pricesprices at which goods can be bought
and sold after the current stage. For flights, the price prediction model is not stochastic: the
future buy price is simply RoxyBot-06s prediction of the expected minimum price during the
current stage. For hotels, the future buy prices are predicted by Monte Carlo simulations
of simultaneous ascending auctions to approximate competitive equilibrium prices. There
are no current buy prices for hotels. For entertainment, RoxyBot-06 predicts future buy and
sell prices based on historical data. Details of these price prediction methods are the focus
of this section.
4.1 Flights
Efforts to deliberate about flight purchasing start with understanding the TAC model of
flight price evolution.
4.1.1 TAC Flight Prices Stochastic Process
Flight prices follow a biased random walk. They are initialized uniformly in the range
[250, 400], and constrained to remain in the range [150, 800]. At the start of each TAC
game instance, a bound z on the final perturbation value is selected for each flight. These
bounds are not revealed to the agents. What is revealed to the agents is a sequence of
random flight prices. Every ten seconds, TACAir perturbs the price of each flight by a
random value that depends on the hidden parameter z and the current time t as follows:
given constants c, d  R and T > 0, each (intermediate) bound on the perturbation value

517

fiGreenwald, Lee, & Naroditskiy

is a linear function of t:

t
(z  c)
(1)
T
The perturbation value at time t is drawn uniformly from one of the following ranges (see
Algorithm 1):
x(t, z) = c +

 U [c, x(t, z)], if x(t, z) > 0
 U [c, +c], if x(t, z) = 0
 U [x(t, z), +c], if x(t, z) < 0
Observe that the expected perturbation value in each case is simply the average of the
corresponding upper and lower bounds. In particular,
 if x(t, z) > c, then the expected perturbation is positive;
 if x(t, z)  (0, c), then the expected perturbation is negative;
 if x(t, z)  (c, 0), then the expected perturbation is positive;
 otherwise, if x(t, z)  {c, 0, c}, then the expected perturbation is zero.
Moreover, using Equation 1, we can compute the expected perturbation value conditioned
on z:
 if z  [0, c], then x(t, z)  [0, c], so prices are expected not to increase;
 if z  [c, c + d], then x(t, z)  [c, c + d], so prices are expected not to decrease;
 if z  [c, 0], then x(t, z)  [c, c], so prices are expected not to increase while t 
cT
.
and they are expected not to decrease while t  cz

cT
cz

The TAC parameters are set as follows: c = 10, d = 30, T = 540, and z uniformly
distributed in the range [c, d]. Based on the above discussion, we note the following:
given no further information about z, TAC flight prices are expected to increase (i.e.,
the expected perturbation is positive); however, conditioned on z, TAC flight prices may
increase or decrease (i.e., the expected perturbation can be positive or negative).
4.1.2 RoxyBot-06s Flight Prices Prediction Method
Although the value of the hidden parameter z is never revealed to the agents, recall that
the agents do observe sample flight prices, say y1 , . . . , yt , that depend on this value. This
information can be used to model the probability distribution Pt [z]  P [z | y1 , . . . , yt ].
Such a probability distribution can be estimated using Bayesian updating. Before RoxyBot06, agents Walverine (Cheng et al., 2005) and Mertacor (Toulis et al., 2006) took this approach.
Walverine uses Bayesian updating to compute the next expected price perturbation and then
compares that value to a threshold, postponing its flight purchases if prices are not expected
to increase by more than that threshold. Mertacor uses Bayesian updating to estimate the
time at which flight prices will reach their minimum value. RoxyBot uses Bayesian updating
to compute the expected minimum price, as we now describe.
518

fiRoxyBot-06

Algorithm 1 getRange(c, t, z)
compute x(t, z) {Equation 1}
if x(t, z) > 0 then
a = c; b = x(t, z)
else if x(t, z) < 0 then
a = x(t, z); b = +c
else
a = c; b = +c
end if
return [a, b] {range}
RoxyBot-06s implementation of Bayesian updating is presented in Algorithm 2. Letting

Q0 [z] =

1
c+d

= P [z], the algorithm estimates Pt+1 [z] = P [z | y1 , . . . , yt+1 ] as usual:
P [y1 , . . . , yt | z]P [z]



z  P [y1 , . . . , yt | z ]P [z ] dz

where

P [z | y1 , . . . , yt ] = P
P [y1 , . . . , yt | z] =
=

t
Y

i=1
t
Y

(2)

P [yi | y1 , . . . , yi1 , z]

(3)

P [yi | z]

(4)

i=1

Equation 4 follows from the fact that future observations are independent of past observations; observations depend only on the hidden parameter z.
The only thing left to explain is how to set the values P [yi | z], for i = 1, . . . , t. As
described in the pseudocode, this is done as follows: if yt+1 is within the appropriate range at
that time, then this probability is set uniformly within the bounds of that range; otherwise,
it is set to 0. Presumably, Walverines and Mertacors implementations of Bayesian updating
are not very different from this one.3 However, as alluded to above, how the agents make
use of the ensuing estimated probability distributions does differ.
RoxyBot-06 predicts each flights price to be its expected minimum price. This value is
computed as follows (see Algorithm 3): for each possible value of the hidden parameter z,
RoxyBot simulates an expected random walk, selects the minimum price along this walk,
and then outputs as its prediction the expectation of these minima, averaging according to
Pt [z]. We call this random walk expected, since the perturbation value  is an expectation
(i.e.,  = ba
2 ) instead of a sample (i.e.,   U [a, b]). By carrying out this computation,
RoxyBot generates flight price predictions that are point estimates. The implicit decision
to make only RoxyBot-06s hotel and event price predictions stochastic was made based on
our intuitive sense of the time vs. accuracy tradeoffs in RoxyBots optimization module, and
hence warrants further study.
3. We provide details here, because corresponding details for the other agents do not seem to be publicly
available.

519

fiGreenwald, Lee, & Naroditskiy

Algorithm 2 Flight Prediction(c, d, t, yt+1 , Qt )
for all z  {c, c + 1, . . . , d} do
[a, b] = getRange(c, t, z)
if yt+1  [a, b] then
1
P [yt+1 | z] = ba
else
P [yt+1 | z] = 0
end if
Qt+1 [z] = P [yt+1 | z]Qt [z]
end for{update probabilities}
for all z  {c, c + 1, . . . , d} do
t+1 [z]
Pt+1 [z] = P  Q


z Qt+1 [z ] dz
end for{normalize probabilities}
return Pt+1 {probabilities}
Algorithm 3 Expected Minimum Price(c, t, t , pt , Pt )
for all z  R do
min[z] = +
for  = t + 1, . . . , t do
[a, b] = getRange(c, , z)
 = ba
2 {expected perturbation}
p = p 1 +  {perturb price}
p = max(150, min(800, p ))
if p < min[z] then
min[z] = p
end if
end for
end forP
return z Pt [z] min[z] dz
4.2 Hotels
In a competitive market where each individuals effect on prices is negligible, equilibrium prices are prices at which supply equals demand, assuming all producers are profitmaximizing and all consumers are utility-maximizing. RoxyBot-06 predicts hotel prices by
simulating simultaneous ascending auctions (SimAA) (Cramton, 2006), in an attempt to
approximate competitive equilibrium (CE) prices. This approach is inspired by Walverines (Cheng et al., 2005), where the tatonnement method (Walras, 1874) is used for the
same purpose.
4.2.1 Simultaneous Ascending Auctions
Let p~ denote a vector of prices. If ~y (~
p) denotes the cumulative supply of all producers, and
if ~x(~
p) denotes the cumulative demand of all consumers, then ~z(~
p) = ~x(~
p)~y (~
p) denotes the

520

fiRoxyBot-06

excess demand in the market. The tatonnement process adjusts the price vector at iteration
n + 1, given the price vector at iteration n and an adjustment rate n as follows: p~n+1 =
p~n + n~z(~
pn ). SimAA adjusts the price vector as follows: p~n+1 = p~n +  max{~z(~
pn ), 0}, for
some fixed value of . Both of these processes continue until excess demand is non-positive:
i.e., supply exceeds demand.
Although competitive equilibrium prices are not guaranteed to exist in TAC markets (Cheng et al., 2003), the SimAA adjustment process, is still guaranteed to converge:
as prices increase, demand decreases while supply increases; hence, supply eventually exceeds demand. The only parameter to the SimAA method is the magnitude  of the price
adjustment. The smaller this value, the more accurate the approximation (assuming CE
prices exist), so the value of  can be chosen to be the lowest value that time permits.
The tatonnement process, on the other hand, is more difficult to apply as it is not
guaranteed to converge. The Walverine team dealt with the convergence issue by decaying
an initial value of . However, careful optimization was required to ensure convergence to
a reasonable solution in a reasonable amount of time. In fact, Walverine found it helpful
to set initial prices to certain non-zero values. This complexity is not present when using
simultaneous ascending auctions to approximate competitive equilibrium prices.
4.2.2 Prediction Quality
In TAC, cumulative supply is fixed. Hence, the key to computing excess demand is to
compute cumulative demand. Each TAC agent knows the preferences of its own clients, but
must estimate the demand of the others. Walverine computes a single hotel price prediction (a
point estimate) by considering its own clients demands together with those of 56 expected
clients. Briefly, the utility of an expected client is an average across travel dates and hotel
types augmented with fixed entertainment bonuses that favor longer trips (see the paper
by Cheng et al., 2005, for details). In contrast, RoxyBot-06 builds a stochastic model of
hotel prices consisting of S scenarios by considering its own clients demands together with
S random samples of 56 clients. A (random or expected) clients demand is simply the
quantity of each good in its optimal package, given current prices. The cumulative demand
is the sum total of all clients individual demands.
In Figure 1, we present two scatter plots that depict the quality of various hotel price
predictions at the beginning of the TAC 2002 final games. All price predictions are evaluated using two metrics: Euclidean distance and the expected value of perfect prediction
(EVPP). Euclidean distance is a measure of the difference between two vectors, in this case
the actual and the predicted prices. The value of perfect prediction (VPP) for a client is the
difference between its surplus (value of its preferred package less price) based on actual and
predicted prices. EVPP is the VPP averaged over the distribution of client preferences.4
On the left, we plot the predictions generated using the competitive equilibrium ap1
proximation methods, tatonnement and SimAA, both with fixed  = 24
, making expected,
random, and exact predictions. The exact predictions are computed based on the actual
clients in the games, not just the client distribution; hence, they serve as a lower bound
on the performance of these techniques on this data set. Under both metrics, and for both
expected and random, SimAAs predictions outperform tatonnements.
4. See the paper by Wellman et al. (2004) for details.

521

fiGreenwald, Lee, & Naroditskiy

44

70
livingagents
PackaTAC
Southampton
RoxyBot UMBCTAC
whitebear
SICS_baseline
ATTac

Expected Value of Perfect Prediction

Expected Value of Perfect Prediction

65
tatonnement, random

42

SimAA, random
40

tatonnement, expected
38

36

SimAA, expected

SimAA, exact
tatonnement, exact

60
55
50
harami

cuhk

45
kavayaH

SimAA, random

40
Walverine
35

34
180

190

200

210

220

30
180

230

Euclidean Distance

ATTac01
190

200

210

220

230

240

250

260

Euclidean Distance

Figure 1: EVPP and Euclidean Distance for the CE price prediction methods (tatonnement
1
; expected, random, and exact) and the TAC 2002 agents
and SimAA with  = 24
predictions in the 2002 finals (60 games). The plot on the left shows that SimAAs
predictions are better than tatonnements and that expecteds are better than
randoms. RoxyBot-06s method of hotel price prediction (SimAA, Random) is
plotted again on the right. Note the differences in scales between the two plots.

Since  is fixed, and tatonnement is not guaranteed to converge under this condition,
this outcome is not entirely surprising. What is interesting, though, is that SimAA expected
performs comparably to Walverine (see the right plot).5 This is interesting because SimAA
has fewer parameter settings than tatonnementonly a single  value as compared to
an initial  value together with a decay scheduleand moreover, we did not optimize
its parameter setting. Walverines parameter settings, on the other hand, were highly
optimized.
We interpret each prediction generated using randomly sampled clients as a sample
scenario, so that a set of such scenarios represents draws from a probability distribution
over CE prices. The corresponding vector of predicted prices that is evaluated is actually
the average of multiple (40) such predictions; that is, we evaluate an estimate of the mean
of this probability distribution. The predictions generated using sets of random clients are
not as good as the predictions with expected clients (see Figure 1 left), although with more
than 40 sets of random clients, the results might improve. Still, the predictions with random
clients comprise RoxyBot-06s stochastic model of hotel prices, which is key to its bidding
strategy. Moreover, using random clients helps RoxyBot-06 make better interim predictions
later in the game as we explain next.
4.2.3 Prediction Quality over Time: Interim Price Prediction
The graphs depicted in Figure 1 pertain to hotel price predictions made at the beginning of
the game, when all hotel auctions are open. In those CE computations, prices are initialized
to 0. As hotel auctions close, RoxyBot-06 updates the predicted prices of the hotel auctions
5. With the exception of the RoxyBot-06 data point (i.e., SimAA random), this plot was produced by the
Walverine team (Wellman et al., 2004).

522

fi22

140

tatonnement, expected clients
SimAA, expected clients
tatonnement, random clients
SimAA, random clients
tatonnement, random clients, with distribution
SimAA, random clients, with distribution

20
18
16

tatonnement, expected clients
SimAA, expected clients
tatonnement, random clients
SimAA, random clients
tatonnement, random clients, with distribution
SimAA, random clients, with distribution

120
Euclidean Distance per Hotel

Expected Value of Perfect Prediction per Hotel

RoxyBot-06

14
12
10
8
6
4

100
80
60
40
20

2
0

0
0

1

2

3

4

5

6

7

0

Minute

1

2

3

4

5

6

7

Minute

Figure 2: EVPP and Euclidean Distance in TAC 2006 finals (165 games) of the CE price
prediction methods with and without distribution as the game progresses. Distribution improves prediction quality.

that remain open. We experimented with two ways of constructing interim price predictions.
The first is to initialize and lower bound the prices in the hotel markets at their closing
(for closed auctions) or current ask (for open auctions) prices while computing competitive
equilibrium prices.6 The second differs in its treatment of closed auctions: we simulate a
process of distributing the goods in the closed auctions to the clients who want them most,
and then exclude the closed markets (i.e., fix prices at ) from further computations of
competitive equilibrium prices.
Regarding the second methodthe distribution methodwe determine how to distribute goods by computing competitive equilibrium prices again. As explained in Algorithm 4, all hotels (in both open and closed auctions) are distributed to random clients
by determining who is willing to pay the competitive equilibrium prices for what. It is not
immediately obvious how to distribute goods to expected clients; hence, we enhanced only
the prediction methods with random clients with distribution.
Figure 2, which depicts prediction quality over time, shows that the prediction methods
enhanced with distribution are better than the predictions obtained by merely initializing
the prices of closed hotel auctions at their closing prices. Hotels that close early tend to
sell for less than hotels that close late; hence, the prediction quality of any method that
makes decent initial predictions is bound to deteriorate if those predictions remain relatively
constant throughout the game.
4.2.4 Run Time
Table 2 shows the run times of the CE prediction methods on the TAC 2002 (60 games)
and TAC 2006 (165 games) finals data set at minute 0, as well as their run times during
6. At first blush, it may seem more sensible to fix the prices of closed hotels at their closing prices, rather
than merely lower bound them (i.e., allow them to increase). If some hotel closed at an artificially low
price, however, and if that price were not permitted to increase, then the predicted prices of the hotels
complementing the hotel in question would be artificially high.

523

fiGreenwald, Lee, & Naroditskiy

Algorithm 4 Distribute
1: for all hotel auctions h do
2:
initialize price to 0
3:
initialize supply to 16
4: end for
5: compute competitive equilibrium prices {Tatonnement or SimAA}
6: for all closed hotel auctions h do
7:
distribute units of h to those who demand them at the computed competitive equilibrium prices
8:
distribute any leftover units of h uniformly at random
9: end for
minutes 17 on the TAC 2006 finals data set. What the numbers in this table convey is
that SimAAs run time, even with distribution, is reasonable. For example, at minute 0,
SimAA sample takes on the order of 0.1 seconds. At minutes 1-7, this method without
distribution runs even faster. This speed increase occurs because CE prices are bounded
below by current ask prices and above by the maximum price a client is willing to pay for
a hotel, and current ask prices increase over time, correspondingly reducing the size of the
search space. SimAA sample with distribution at minutes 1-7 takes twice as long as SimAA
sample without distribution at minute 0 because of the time it takes to distribute goods, but
the run time is still only (roughly) 0.2 seconds. Our implementation of tatonnement runs
so slowly because we fixed  instead of optimizing the tradeoff between convergence rate
and accuracy, so the process did not converge, and instead ran for the maximum number
of iterations (10,000). In summary, SimAA is simpler than tatonnement to implement, yet
performs comparably to an optimized version of tatonnement (i.e., Walverine), and runs
sufficiently fast.

2002, minute 0
2006, minute 0
2006, average 17

Exp Tat
2213
2252
2248

Exp SimAA
507
508
347

Sam Tat
1345
1105
1138

Sam SimAA
157
130
97

Dist Tat

1111
2249

Dist SimAA

128
212

Table 2: Run times for the CE price prediction methods, in milliseconds. Experiments were
run on AMD Athlon(tm) 64 bit 3800+ dual core processors with 2M of RAM.

4.2.5 Summary
The simulation methods discussed in this sectionthe tatonnement process and simultaneous ascending auctionswere employed to predict hotel prices only. (In our simulations,
flight prices are fixed at their expected minima, and entertainment prices are fixed at 80.)
In principle, competitive equilibrium (CE) prices could serve as predictions in all TAC markets. However, CE prices are unlikely to be good predictors of flight prices, since flight
prices are determined exogenously. With regard to entertainment tickets, CE prices might
524

fiRoxyBot-06

have predictive power; however, incorporating entertainment tickets into the tatonnement
and SimAA calculations would have been expensive. (In our simulations, following Wellman et al., 2004, client utilities are simply augmented with fixed entertainment bonuses
that favor longer trips.) Nonetheless, in future work, it could be of interest to evaluate the
success of these or related methods in predicting CDA clearing prices.
Finally, we note that we refer to our methods of computing excess demand as clientbased because we compute the demands of each client on an individual basis. In contrast,
one could employ an agent-based method, whereby the demands of agents, not clients,
would be calculated. Determining an agents demands involves solving so-called completion, a deterministic (prices are known) optimization problem at the heart of RoxyBot-00s
architecture (Greenwald & Boyan, 2005). As TAC completion is NP-hard, the agent-based
method of predicting hotel prices is too expensive to be included in RoxyBot-06s inner
loop. In designing RoxyBot-06, we reasoned that an architecture based on a stochastic pricing model generated using the client-based method and randomly sampled clients would
outperform one based on a point estimate pricing model generated using the agent-based
method and some form of expected clients, but we did not verify our reasoning empirically.
4.3 Entertainment
During each bid interval, RoxyBot-06 predicts current and future buy and sell prices for tickets
to all entertainment events. These price predictions are optimistic: the agent assumes it
can buy (or sell) goods at the least (or most) expensive prices that it expects to see before
the end of the game. More specifically, each current price prediction is the best predicted
price during the current bid interval.
RoxyBot-06s estimates of entertainment ticket prices are based on historical data from
the past 40 games. To generate a scenario, a sample game is drawn at random from this
collection, and the sequences of entertainment bid, ask, and transaction prices are extracted.
Given such a history, for each auction a, let trade ai denote the price at which the last trade
before time i transacted; this value is initialized to 200 for buying and 0 for selling. In
addition, let bid ai denote the bid price at time i, and let ask ai denote the ask price at time
i.
RoxyBot-06 predicts the future buy price in auction a after time t as follows:
future buy at =

min

i=t+1,...,T

min{trade ai , ask ai }

(5)

In words, the future buy price at each time i = t + 1, . . . , T is the minimum of the ask price
after time i and the most recent trade price. The future buy price at time t is the minimum
across the future buy prices at all later times. The future sell price after time t is predicted
analogously:
(6)
future sell at = max max{trade ai , bid ai }
i=t+1,...,T

Arguably, RoxyBot-06s entertainment predictions are made in the simplest possible way:
past data are future predictions. It is likely one could improve upon this naive approach by
using a generalization technique capable of learning a distribution over these data, and
then sampling from the learned distribution.

525

fiGreenwald, Lee, & Naroditskiy

4.4 Summary
In this section, we described RoxyBot-06s price prediction methods. The key ideas, which
may be transferable if not beyond TAC, at least to other TAC agents, are as follows:
1. RoxyBot makes stochastic price predictions. It does so by generating a set of so-called
scenarios, where each scenario is a vector of future prices.
2. For each flight, RoxyBot uses Bayesian updating to predict its expected minimum price.
3. For hotels, RoxyBot-uses a method inspired by Walverines: it approximates competitive
equilibrium prices by simulating simultaneous ascending auctions, rather than the
usual tatonnement process.

5. Optimization
Next, we characterize RoxyBot-06s optimization routine. It is (i) stochastic, (ii) global, and
(iii) dynamic. It takes as input stochastic price predictions; it considers its flight, hotel,
and entertainment bidding decisions in unison; and it simultaneously reasons about bids to
be placed in both current and future stages of the game.
5.1 Abstract Auction Model
Recall that our treatment of bidding is decision-theoretic, rather than game-theoretic. In
particular, we focus on a single agents problem of optimizing its own bidding behavior, assuming the other agents strategies are fixed. In keeping with our basic agent architecture,
we further assume that the environment can be modeled in terms of the agents predictions
about market clearing prices. We introduce the term pseudo-auction to refer to a market
mechanism defined by these two assumptionsfixed other-agent behaviors and market information encapsulated by prices. The optimization problem that RoxyBot solves is one of
bidding in pseudo-auctions, not (true) auctions. In this section, we formally develop this
abstract auction model and relate it to TAC auctions; in the next, we define and propose
heuristics to solve various pseudo-auction bidding problems.
5.1.1 Basic Formalism
In this section, we formalize the basic concepts needed to precisely formulate bidding under uncertainty as an optimization problem, including: packagessets of goods, possibly
multiple units of each; a function that describes how much the agent values each package; pricelinesdata structures in which to store the prices of each unit of each good; and
bidspairs of vectors corresponding to buy and sell offers.
Packages Let G denote an ordered set of n distinct goods and let N  Nn represent the
multiset of these goods in the marketplace, with Ng denoting the number of units of each
good g  G. A package M is a collection of goods, that is, a submultiset of N . We write
M  N whenever Mg  Ng for all g  G.
It is instructive to interpret this notation in the TAC domain. The flights, hotel rooms,
and entertainment events up for auction in TAC comprise an ordered set of 28 distinct

526

fiRoxyBot-06

goods. In principle, the multiset of goods in the TAC marketplace is:
N TAC = h, . . . , , 16, . . . , 16, 8, . . . , 8i  N28
| {z } | {z } | {z }
8 flights

8 hotels

12 events

In practice, however, since each agent works to satisfy the preferences of only eight clients,
it suffices to consider the multiset of goods:
N TAC8 = h8 . . . , 8, 8, . . . , 8, 8, . . . , 8i  N TAC
| {z } | {z } | {z }
8 flights

8 hotels

12 events

A trip corresponds to a package, specifically some M  N TAC8 that satisfies the TAC
feasibility constraints.
Given A, B  N , we rely on the two basic operations,  and , defined as follows: for
all g  G,
(A  B)g  Ag + Bg
(A  B)g  Ag  Bg
For example, if G = {, , } and N = h1, 2, 3i, then A = h0, 1, 2i  N and B = h1, 1, 1i 
N . Moreover, (A  B) = 1, (A  B) = 2, and (A  B) = 3; and (A  B) = 1,
(A  B) = 0, and (A  B) = 1.
Value Let N denote the set of all submultisets of N : i.e., packages comprised of the goods
in N . We denote v : N  R a function that describes the value the bidding agent attributes
to each viable package.
In TAC, each agents objective is to compile packages for m = 8 individual clients. As
such, the agents value function takes special form. Each client c is characterized by its own
value function vc : N  R, and the agents value for a collection of packages is the sum of its
~ = (X1 , . . . , Xm ),
clients respective values for those packages: given a vector of packages X
~ =
v(X)

m
X

vc (Xc ).

(7)

c=1

N

Pricelines A buyer priceline for good g is a vector p~g  R+g , where the kth component,
pgk , stores the marginal cost to the agent of acquiring the kth unit of good g. For example,
if an agent currently holds four units of a good g, and if four additional units of g are
available at costs of $25, $40, $65, and $100, then the corresponding buyer priceline (a
vector of length 8) is given by p~g = h0, 0, 0, 0, 25, 40, 65, 100i. The leading zeros indicate
that the four goods the agent holds may be acquired at no cost.
We assume buyer pricelines are nondecreasing. Note that this assumption is WLOG,
since an optimizing agent buys cheaper goods before more expensive ones.
Given a set of buyer pricelines P = {~
pg | g  G}, we define costs additively, that is, the
cost of the goods in multiset Y  N is given by:
g,

Costg (Y, P ) =

Yg
X

pgk ,

X

Costg (Y, P ).

k=1

Cost(Y, P ) =

gG

527

(8)

fiGreenwald, Lee, & Naroditskiy

N

A seller priceline for good g is a vector ~g  R+g . Much like a buyer priceline, the kth
component of a seller priceline for g stores the marginal revenue that an agent could earn
from the kth unit it sells. For example, if the market demands four units of good g, which
can be sold at prices of $20, $15, $10, and $5, then the corresponding seller priceline is given
by ~g = h20, 15, 10, 5, 0, 0, 0, 0i. Analogously to buyer pricelines, the tail of zero revenues
indicates that the market demands only four of those units.
We assume seller pricelines are nonincreasing. Note that this assumption is WLOG,
since an optimizing agent sells more expensive goods before cheaper ones.
Given a set of seller pricelines  = {~g | g  G}, we define revenue additively, that is,
the revenue associated with multiset Z  N is given by:
g,

Revenueg (Z, ) =

Zg
X

gk ,

X

Revenueg (Z, ).

(9)

k=1

Revenue(Z, ) =

(10)

gG

If a priceline is constant, we say that prices are linear. We refer to the constant value
as a unit price. With linear prices, the cost of acquiring k units of good g is k times the
unit price of good g.
Bids An agent submits a bid  expressing offers to buy or sell various units of the goods
in the marketplace. We divide  into two components h~b, ~ai, where for each good g the bid
consists of a buy offer, ~bg = hbg1 , . . . , bgNg i, and a sell offer, ~ag = hag1 , . . . , agNg i. The bid
price bgk  R+ (resp. agk  R+ ) represents an offer to buy (sell) the kth unit of good g at
that price.
By definition, the agent cannot buy (sell) the kth unit unless it also buys (sells) units
1, . . . , k  1. To accommodate this fact, we impose the following constraint: Buy offers must
be nonincreasing in k, and sell offers nondecreasing. In addition, an agent may not offer to
sell a good for less than the price at which it is willing to buy that good: i.e., bg1 < ag1 .
Otherwise, it would simultaneously buy and sell good g. We refer to these restrictions as
bid monotonicity constraints.
5.1.2 Pseudo-Auction Rules
Equipped with this formalism, we can specify the rules that govern pseudo-auctions. As
in a true auction, the outcome of a pseudo-auction dictates the quantity of each good to
exchange, and at what prices, conditional on the agents bid. The quantity issue is resolved
by the winner determination rule whereas the price issue is resolved by the payment rule.
Definition 5.1 [Pseudo-Auction Winner Determination Rule] Given buyer and seller pricelines P and , and bid  = h~b, ~ai, the agent buys the multiset of goods Buy(, P ) and sells
the multiset of goods Sell(, ), where
Buyg (, P ) = max k such that bgk  pgk
k

Sellg (, ) = max k such that agk  gk
k

528

fiRoxyBot-06

Note that the monotonicity restrictions on bids ensure that the agents offer is better than
or equal to the price for every unit it exchanges, and that the agent does not simultaneously
buy and sell any good.
There are at least two alternative payment rules an agent may face. In a first-price
pseudo-auction, the agent pays its bid price (for buy offers, or is paid its bid price for sell
offers) for each good it wins. In a second-price pseudo-auction, the agent pays (or is paid) the
prevailing prices, as specified by the realized buyer and seller pricelines. This terminology
derives by analogy from the standard first- and second-price sealed bid auctions (Krishna,
2002; Vickrey, 1961). In these mechanisms, the high bidder for a single item pays its bid (the
first price), or the highest losing bid (the second price), respectively. The salient property
is that in first-price pseudo-auctions, the price is set by the bid of the winner, whereas in
second-price pseudo-auctions an agents bid price determines whether or not it wins but
not the price it pays.
In this paper, we focus on the second-price model. That is, our basic problem definitions
presume second-price auctions; however, our bidding heuristics are not tailored to this
case. As in true auctions, adopting the second-price model in pseudo-auctions simplifies the
problem for the bidder. It also provides a reasonable approximation to the situation faced
by TAC agents, as we now argue:
 In TAC entertainment auctions, agents submit bids (i.e., buy and sell offers) of the
form specified above. If we interpret an agents buyer and seller pricelines as the
current order book (not including the agents own bid), then the agents immediate winnings are as determined by the winner determination rule, and payments are
according to the second-price rule (i.e., the order-book prices prevail).
 In TAC hotel auctions, only buy bids are allowed. Assuming once again an order
book that reflects all outstanding bids other than the agents own, an accurate buyer
priceline would indicate that the agent can win k units of a good if it paysfor all
k unitsa price just above the (17  k)th existing (other-agent) offer. The actual
price it pays will be that of the 16th-highest unit offer (including its own offer). Since
the agents own bid may affect the price,7 this situation lies between the first- and
second-price characterizations of pseudo-auctions described above.
 In TAC flight auctions, agents may buy any number of units at the posted price. The
situation at any given time is modeled exactly by the second-price pseudo-auction
abstraction.
5.2 Bidding Problems
We are now ready to discuss the optimization module repeatedly employed by RoxyBot-06
within its bidding cycle to construct its bids. The key bidding decisions are: what goods to
bid on, at what price, and when?
7. It can do so in two ways. First, the agent may submit the 16th-highest unit offer, in which case it sets
the price. Second, when it bids for multiple units, the number it wins determines the price-setting unit,
thus affecting the price for all winning units. Note that this second effect would be present even if the
auction cleared at the 17th-highest price.

529

fiGreenwald, Lee, & Naroditskiy

Although RoxyBot technically faces an n-stage stochastic optimization problem, it solves
this problem by collapsing those n stages into only two relevant stages, current and
future, necessitating only one stochastic model of future prices (current prices are known).
This simplification is achieved by ignoring the potentially useful information that hotel
auctions close one by one in a random, unspecified order, and instead operating (like most
TAC agents) under the assumption that all hotel auctions close at the end of the current
stage. Hence, there is only one model of hotel prices: a stochastic model of future prices.
Moreover, the only pressing decisions regarding hotels are what goods to bid on now and
at what price. There is no need to reason about the timing of hotel bid placement.
In contrast, since flight and entertainment auctions clear continuously, a trading agent
should reason about the relevant tradeoffs in timing its placement of bids on these goods.
Still, under the assumption that all hotel auctions close at the end of the current stage,
in future stages, hotel prices, and hence hotel winnings, are known, so the only remaining
decisions are what flight and entertainment tickets to buy. A rational agent will time its
bids in these markets to capitalize on the best prices. (The best prices are the minima for
buying and the maxima for selling.) Hence, it suffices for an agents model of future prices
in these markets to predict only the best prices (conditioned on current prices). That is, it
suffices to consider only one stochastic pricing model. No further information is necessary.
Having established that it suffices for RoxyBot to pose and solve a two-stage, rather than
an n-stage, stochastic optimization problem, we now proceed to define an abstract series
of such problems that is designed to capture the essence of bidding under uncertainty in
TAC-like hybrid markets that incorporate aspects of simultaneous and sequential, one-shot
and continuously-clearing, auctions. More specifically, we formulate these problems as twostage stochastic programs with integer recourse (see the book by Birge & Louveaux, 1997,
for an introduction to stochastic programming).
In a two-stage stochastic program, there are two decision-making stages, and hence two
sets of variables: first- and second-stage variables. The objective is to maximize the sum of
the first-stage objectives (which depend only on the first-stage variables) and the expected
value of the ensuing second-stage objectives (which can depend on both the first- and secondstage variables). The objective value in the second stage is called the recourse value, and if
any of the second-stage variables are integer-valued, then the stochastic program is said to
have integer recourse.
At a high-level, the bidding problem can be formulated as a two-stage stochastic program
as follows: in the first stage, when current prices are known but future prices are uncertain,
bids are selected; in the second stage, all uncertainty is resolved, and goods are exchanged.
The objective is to maximize the expected value of the second-stage objective, namely the
sum of the inherent value of final holdings and any profits earned, less any first-stage costs.
Since the second stage involves integer-valued decisions (the bidder decides what goods to
buy and sell at known prices), the bidding problem is one with integer recourse.
In this section, we formulate a series of bidding problems as two-stage stochastic programs with integer recourse, each one tailored to a different type of auction mechanism,
illustrating a different type of bidding decision. The mechanisms we study, inspired by
TAC, are one-shot and continuously-clearing variants of second-price pseudo-auctions. In
the former, bids can only be placed in the first stage; in the latter, there is an opportunity

530

fiRoxyBot-06

for recourse. Ultimately, we combine all decision problems into one unified problem that
captures what we mean by bidding under uncertainty.
In our formal problem statements, we rely on the following notation:
 Variables:
 Q1 is a multiset of goods to buy now
 Q2 is a multiset of goods to buy later
 R1 is a multiset of goods to sell now
 R2 is a multiset of goods to sell later
 Constants:
 P 1 is a set of current buyer pricelines
 P 2 is a set of future buyer pricelines
 1 is a set of current seller pricelines
 2 is a set of future seller pricelines
Note that P 1 and 1 are always known, whereas P 2 and 2 are uncertain in the first stage
but their uncertainty is resolved in the second stage.
Flight Bidding Problem An agents task in bidding in flight auctions is to decide how
many flights to buy now at current prices and later at the lowest future prices, given (known)
current prices and a stochastic model of future prices. Although in TAC all units of each
flight sell for the same price at any one time, we state the flight bidding problem more
generally: we allow for different prices for different units of the same flight.
Definition 5.2 [Continuously-Clearing, Buying] Given a set of current buyer pricelines P 1
and a probability distribution f over future buyer pricelines P 2 ,
FLT(f ) = max
EP 2 f
1
n
Q Z




max
v(Q1  Q2 )  Cost(Q1 , P 1 ) + Cost(Q1  Q2 , P 2 )  Cost(Q1 , P 2 )
2
n

Q Z



(11)

Note that there are two cost terms referring to future pricelines (Cost(, P 2 )). The first of
these terms adds the total cost of the goods bought in the first and second stages. The
second term subtracts the cost of the goods bought in just the first stage. This construction
ensures that, if an agent buys k units of a good now, any later purchases of that good incur
the charges of units (k + 1, k + 2, ...) in the goods future priceline.
Entertainment Bidding Problem Abstractly, the entertainment buying problem is the
same as the flight bidding problem. An agent must decide how many entertainment tickets
to buy now at current prices and later at the lowest future prices. The entertainment selling
problem is the opposite of this buying problem. An agent must decide how many tickets to
sell now at current prices and later at the highest future prices.

531

fiGreenwald, Lee, & Naroditskiy

Definition 5.3 [Continuously-Clearing, Buying and Selling] Given a set of current buyer
and seller pricelines (P, )1 and a probability distribution f over future buyer and seller
pricelines (P, )2 ,

ENT(f ) = max E(P,)2 f
max v((Q1  Q2 )  (R1  R2 ))
Q1 ,R1 Zn
Q2 ,R2 Zn

 Cost(Q1 , P 1 ) + Cost(Q1  Q2 , P 2 )  Cost(Q1 , P 2 )

+ Revenue(R1 , 1 ) + Revenue(R1  R2 , 2 )  Revenue(R1 , 2 )
(12)

subject to Q1  R1 and Q1  Q2  R1  R2 , for all (P, )2 .

The constraints ensure that an agent does not sell more units of any good than it buys.
Hotel Bidding Problem Hotel auctions close at fixed times, but in an unknown order.
Hence, during each iteration of an agents bidding cycle, one-shot auctions approximate
these auctions well. Unlike in the continuous setup, where decisions are made in both the
first and second stages, in the one-shot setup, bids can only be placed in the first stage; in
the second stage, winnings are determined and evaluated.
Definition 5.4 [One-Shot, Buying] Given a probability distribution f over future buyer
pricelines P 2 ,


(13)
HOT(f ) = max EP 2 f v(Buy( 1 , P 2 ))  Cost(Buy( 1 , P 2 ), P 2 )
 1 =h~b,0i

Hotel Bidding Problem, with Selling Although it is not possible for agents to sell
TAC hotel auctions, one could imagine an analogous auction setup in which it were possible
to sell goods as well as buy them.
Definition 5.5 [One-Shot, Buying and Selling] Given a probability distribution f over
future buyer and seller pricelines (P, )2 ,


max E(P,)2 f v(Buy( 1 , P 2 )  Sell( 1 , 2 ))  Cost(Buy( 1 , P 2 ), P 2 ) + Revenue(Sell( 1 , 2 ), 2 )

 1 =h~b,~
ai

(14)

1

2

1

2

2

subject to Buy( , P )  Sell( ,  ), for all (P, ) .

Bidding Problem Finally, we present (a slight generalization of) the TAC bidding problem by combining the four previous stochastic optimization problems into one. This abstract
problem models bidding to buy and sell goods both via continuously-clearing and one-shot
second-price pseudo-auctions, as follows:
Definition 5.6 [Bidding Under Uncertainty] Given a set of current buyer and seller pricelines (P, )1 and a probability distribution f over future buyer and seller pricelines (P, )2 ,
BID(f ) =
max

Q1 ,R1 Zn , 1 =h~b,~
ai

E(P,)2 f



max

Q2 ,R2 Zn

v((Q1  Q2 )  (R1  R2 )  Buy( 1 , P 2 )  Sell( 1 , P 2 ))


 Cost(Q1 , P 1 ) + Cost(Q1  Q2 , P 2 )  Cost(Q1 , P 2 ) + Cost(Buy( 1 , P 2 ), P 2 )


+ Revenue(R1 , 1 ) + Revenue(R1  R2 , 2 )  Revenue(R1 , 2 ) + Revenue(Sell( 1 , 2 ), 2 )
(15)
532

fiRoxyBot-06

subject to Q1  R1 and Q1  Q2  R1  R2 and Buy( 1 , P 2 )  Sell( 1 , 2 ), for all (P, )2 .

Once again, this bidding problem is (i) stochastic: it takes as input a stochastic model
of future prices; (ii) global: it seamlessly integrates flight, hotel, and entertainment bidding
decisions; and (iii) dynamic: it facilitates simultaneous reasoning about current and future
stages of the game.
Next, we describe various heuristic approaches to solving the problem of bidding under
uncertainty.
5.3 Bidding Heuristics
In this section, we discuss two heuristic solutions to the bidding problem: specifically,
the expected value method (EVM), an approach that collapses stochastic information, and
sample average approximation (SAA), an approach that exploits stochastic information and
characterizes RoxyBot-06.
5.3.1 Expected Value Method
The expected value method (Birge & Louveaux, 1997) is a standard way of approximating
the solution to a stochastic optimization problem. First, the given distribution is collapsed
into a point estimate (e.g., the mean); then, a solution to the corresponding deterministic optimization problem is output as an approximate solution to the original stochastic
optimization problem. Applying this idea to the problem of bidding under uncertainty
yields:
Definition 5.7 [Expected Value Method] Given a probability distribution f over buyer
and seller pricelines, with expected values P 2 and 2 , respectively,
BID EVM(P 2 , 2 ) =
max

Q1 ,R1 Zn , 1 =h~b,~
ai,Q2 ,R2 Zn

v((Q1  Q2 )  (R1  R2 )  (Buy( 1 , P 2 )  Sell( 1 , P 2 ))


 Cost(Q1 , P 1 ) + Cost(Q1  Q2 , P 2 )  Cost(Q1 , P 2 ) + Cost(Buy( 1 , P 2 ), P 2 )


+ Revenue(R1 , 1 ) + Revenue(R1  R2 , 2 )  Revenue(R1 , 2 ) + Revenue(Sell( 1 , 2 ), 2 )
(16)
subject to Q1  R1 and Q1  Q2  R1  R2 .

In practice, without full knowledge of the distribution f , we cannot implement the
expected value method; in particular, we cannot compute P 2 or 2 so we cannot solve
BID EVM(P 2 , 2 ) exactly. We can, however, solve an approximation of this problem in
which the expected buyer and seller pricelines P 2 and 2 are replaced by an average scenario
(P 2 , 2 ) (i.e., average buyer and seller pricelines), defined as follows:
P 2 =

S
1X 2
Pi ,
S

2 =

i=1

S
1X 2
i .
S
i=1

533

fiGreenwald, Lee, & Naroditskiy

Algorithm 5 EVM(G, N, f, S)
1: sample S scenarios (P, )21 , . . . , (P, )2S  f
P

PS
S
2
2,
2:   BID EVM

P
i=1 i
i=1 i
3: return 
5.3.2 Sample Average Approximation
Like the expected value method, sample average approximation is an intuitive way of approximating the solution to a stochastic optimization problem. The idea is simple: (i) generate
a set of sample scenarios, and (ii) solve an approximation of the problem that incorporates
only the sample scenarios. Applying the SAA heuristic (see Algorithm 6) involves solving
the following approximation of the bidding problem:
Definition 5.8 [Sample Average Approximation] Given a set of S scenarios,
(P, )21 , . . . , (P, )2S  f ,
BID SAA((P, )21 , . . . , (P, )2S ) =
max

S
X

max

v((Q1  Q2 )  (R1  R2 )  (Buy( 1 , Pi2 )  Sell( 1 , Pi2 ))

2
2
n
Q1 ,R1 Zn , 1 =h~b,~
ai i=1 Q ,R Z
1
1
1


 Cost(Q , P ) + Cost(Q  Q2 , Pi2 )  Cost(Q1 , Pi2 ) + Cost(Buy( 1 , Pi2 ), Pi2 )


+ Revenue(R1 , 1 ) + Revenue(R1  R2 , 2i )  Revenue(R1 , 2i ) + Revenue(Sell( 1 , 2i ), 2i )
(17)
subject to Q1  R1 and Q1  Q2  R1  R2 .

Algorithm 6 SAA(G, N, f, S)
1: sample S scenarios (P, )21 , . . . , (P, )2S  f
2:   BID SAA((P, )21 , . . . , (P, )2S )
3: return 
Using the theory of large deviations, Ahmed and Shapiro (2002) establish the following
result: as S  , the probability that an optimal solution to the sample average approximation of a stochastic program with integer recourse is an optimal solution to the original
stochastic optimization problem approaches 1 exponentially fast. Given hard time and space
constraints, however, it is not always possible to sample sufficiently many scenarios to infer
any reasonable guarantees about the quality of a solution to a sample average approximation. Hence, we propose a modified SAA heuristic, in which SAA is fed some tailor-made
important scenarios, and we apply this idea to the bidding problem.
5.3.3 Modified Sample Average Approximation
The bids that SAA places are sample prices that appear in its scenarios. SAA never bids
higher on any good than its highest sampled price, because as far as it knows, bidding that
price is enough to win that good in all scenarios. However, there is some chance that the
534

fiRoxyBot-06

highest sampled price falls below the clearing price. Let us compute this probability in the
case of a single-unit auction, or a uniform-price multi-unit auction: i.e., one in which all
units of the good being auctioned off clear at the same price.
Let F denote the cumulative distribution function over the predicted prices, let f denote
the corresponding density function, and let G denote the cumulative distribution function
over the clearing prices. Using this notation, the term 1  G(x) is the probability the
clearing price is greater than x. Further, let X be a random variable that represents
the highest value among S sample price predictions. Then P (X  x) = F (x)S is the
probability that all S samples (and hence the highest among them) are less than x; and
P (X = x) = (F (x)S ) = S(F (x))S1 f (x) is the probability that the highest value among
the S samples equals x. Putting these two terms togethernamely, the probability the
highest sample price prediction is exactly x, and the probability the clearing price is greater
than xwe can express the probability the highest of SAAs sample price predictions is less
than the clearing price as follows:
Z 

S(F (x))S1 f (x)(1  G(x))dx
(18)



Assuming perfect prediction (so that G = F ), this complex expression simplies as follows:
Z 
S(F (x))S1 f (x)(1  F (x))dx

Z 
Z 
S1
(F (x))S f (x)dx
(F (x))
f (x)dx  S
= S






(F (x))S 
(F (x))S+1 
= S
S
S
S+1


1
=
S+1
Hence, the probability that all SAAs sample price predictions are less than the clearing
price is 1/(S + 1). In particular, assuming perfect prediction and that the clearing prices in
the TAC hotel auctions are independent, the probability that an SAA agent with 49 scenarios
bidding in TAC Travel has any chance of winning all eight hotels (i.e., the probability that
a sample price in at least one of its scenarios is greater than the clearing price) is only
8

1
= 0.988  0.85.
1  49+1
To remedy this situation, we designed and implemented a simple variant of SAA in
RoxyBot-06. The SAA* heuristic (see Algorithm 7) is a close cousin of SAA, the only difference
arising in their respective scenario sets.
P Whereas SAA samples S scenarios, SAA* samples
only S  |N | scenarios, where |N | = g Ng . SAA* creates an additional |N | scenarios as
follows: for each unit k of each good g  G, it sets the price of the kth unit of good g to the
upper limit of its range of possible prices and, after conditioning on this price setting, it sets
the prices of the other goods to their mean values. Next, we describe experiments with a
test suite of bidding heuristics, including SAA and SAA*, in a controlled testing environment.

535

fiGreenwald, Lee, & Naroditskiy

Algorithm 7 SAA(G, N, f, S)
Require: S  |N |
1: hard-code |N | scenarios (P, )21 , . . . , (P, )2|N |
2: sample S  |N | scenarios (P, )2|N |+1 , . . . , (P, )2S  f
3:   BID SAA((P, )21 , . . . , (P, )2S )
4: return 
Agent
SMU
AMU

Predictions
Average scenario
S scenarios

TMU
BE
TMU*

Average scenario
S scenarios
Average scenario

BE*

S scenarios

Bids
Marginal utilities
Calculates marginal utilities in each scenario
Bids average marginal utilities across scenarios
Marginal utilities
Best of S TMU solutions
Marginal utilities, assuming only goods
in a target set are available
Best of S TMU*solutions

On
All goods
All goods
Goods in a target set
Goods in a target set
Goods in a target set
Goods in a target set

Table 3: Marginal-utility-based agents. The marginal utility of a good is defined as the
incremental utility that can be achieved by winning that good, relative to the
utility of the set of goods already held.

5.4 Summary
In this section, we developed a series of bidding problems, and heuristics solutions to those
problems, that captures the essence of bidding in the one-shot and continuously-clearing
auctions that characterize TAC. The bulk of our presentation was deliberately abstract, so
as to suggest that our problems and their solutions are applicable well beyond the realm of
TAC: e.g., to bidding for interdependent goods in separate eBay auctions. Still, it remains
to validate our approach in other application domains.

6. Experiments
We close this paper with two sets of experimental results, the first in a controlled testing
environment, and the second the results from the final round of the 2006 TAC Travel competition. The combined strategy of hotel price prediction via SimAA and bid optimization
via SAA emerged victorious in both settings.
6.1 Controlled Experiments
To some extent at least, our approach to bidding has been validated by the success of
RoxyBot-06 in TAC-06. Nonetheless, we ran simulations in a controlled testing environment
to further validate our approach. These results are reported by Lee (2007) and Greenwald et
al. (2008), but we summarize them here as well.

536

fiRoxyBot-06

We built a test suite of agents, all of which predict using RoxyBot-06s SimAA random
mechanism with distribution. The agents differ in their bidding strategies; the possibilities
include SAA,8 SAA*, and the six marginal-utility-based heuristics studied by Wellman et
al. (2007), and summarized in Table 3.
Our experiments were conducted in a TAC Travel-like setting, modified to remove any
aspects of the game that would obscure a controlled study of bidding. Specifically, we
eliminated flight and entertainment trading, and endowed all agents with eight flights in
and eight flights out on each day. Further, we assumed all hotels closed after one round
of bidding (i.e., hotel auctions are one-shot, so that the ensuing bid optimization problem
adheres to Definition 5.4).
We designed two sets of experiments: one decision-theoretic and one game-theoretic. In
the former, hotel clearing prices are the outcome of a simulation of simultaneous ascending
auctions, but depend on the actual clients in each game, not a random sampling. (Our
simulator is more informed than the individual agents.) In the latter, hotel clearing prices
are determined by the bids the agents submit using the same mechanism as in TAC Travel:
the clearing price is the 16th highest bid (or zero, if fewer than 16 bids are submitted).
We first ran experiments with 8 agents per game, but found that hotel prices were
often zero: i.e., there was insufficient competition. We then changed the setup to include a
random number of agents drawn from a binomial distribution with n = 32 and p = 0.5, with
the requisite number of agents sampled uniformly with replacement from the set of possible
agents. The agents first sample the number of competitors from the binomial distribution,
and then generate scenarios assuming the sampled number of competitors.
Because of the game-theoretic nature of TAC, an individual agents performance can
depend heavily on the other agents included in the agent pool. In our experiments, we
attempted to mitigate any artificial effects of the specific agents we chose to include in
our pool by sampling agents from the pool to play each game, with replacement. Thus,
an agents average score from the games is a measure of the agents performance against
various combinations of opponents.
In Figures 3(a) and 3(b), we plot the mean scores obtained by each agent type in each
setting, along with 95% confidence intervals. These averages were computed based on 1000
independent observations, obtained by playing 1000 games. Scores were averaged across
agent types in each game to account for any game dependencies. SAAB and SAAT9 are
the best performing agents in the game-theoretic experiments and among the best in the
decision-theoretic setting.
6.2 TAC 2006 Competition Results
Table 4 lists the agents entered in TAC-06 and Table 5 summarizes the outcome. The
TAC-06 finals comprised 165 games over three days, with the 80 games on the last day
weighted 1.5 times as much as the 85 over the first two days. On the first day of the finals,
RoxyBot finished third, behind Mertacor and Walverinethe top scorers in 2005. As it happens,
RoxyBots optimization routine, which was designed for stochastic hotel and entertainment
8. The particular implementation details explaining how RoxyBot-06 applied SAA in the TAC domain are
relegated to Appendix A.
9. SAAB is SAA, and SAAT is a slight variant of SAA*. See the paper by Greenwald et al. (2008) for
details.

537

fiGreenwald, Lee, & Naroditskiy

1

0.85

0.95
Score (thousands)

Score (thousands)

0.8
0.75
0.7
0.65
0.6

0.9
0.85
0.8
0.75
0.7

0.55
0.65
0.5
0.6
SAAT SAAB

TMU

TMU*
BE
Agent

BE*

AMU

SMU

(a) Decision-theoretic setting

SAAT SAAB

TMU

TMU*
BE
Agent

BE*

AMU

SMU

(b) Game-theoretic setting

Figure 3: Mean scores and confidence intervals.

price predictions, was accidentally fed deterministic predictions (i.e., point price estimates)
for entertainment. Moreover, these predictions were fixed, rather than adapted based on
recent game history.
On days 2 and 3, RoxyBot ran properly, basing its bidding in all auctions on stochastic
information. Moreover, the agent was upgraded after day 1 to bid on flights not just once,
but twice, during each minute. This enabled the agent to delay its bidding somewhat at
the end of a game for flights whose prices are decreasing. No doubt this minor modification
enabled RoxyBot to emerge victorious in 2006, edging out Walverine by a whisker, below the
integer precision reported in Table 5. The actual margin was 0.22a mere 22 parts in
400,000. Adjusting for control variates (Ross, 2002) spreads the top two finishers a bit
further.10
Agent
006
kin agent
L-Agent
Mertacor
RoxyBot
UTTA
Walverine
WhiteDolphin

Affiliation
Swedish Inst Comp Sci
U Macau
Carnegie Mellon U
Aristotle U Thessaloniki
Brown U
U Tehran
U Michigan
U Southampton

Reference
Aurell et al., 2002
Sardinha et al., 2005
Toulis et al., 2006; Kehagias et al., 2006
Greenwald et al., 2003, 2004, 2005; Lee et al., 2007
Cheng et al., 2005; Wellman et al., 2005
He & Jennings, 2002; Vetsikas & Selman, 2002

Table 4: TAC-06 participants.

10. Kevin Lochner computed these adjustment factors using the method described by Wellman et al. (2007,
ch. 8).

538

fiRoxyBot-06

Agent
RoxyBot
Walverine
WhiteDolphin
006
Mertacor
L-Agent
kin agent
UTTA

Finals
4032
4032
3936
3902
3880
3860
3725
2680

Adjustment Factor
5
17
2
27
16
7
0
14

Table 5: TAC-06 final scores, with adjustment factors based on control variates.

Mean scores, utilities, and costs (with 95% confidence intervals) for the last day of the
TAC-06 finals (80 games) are plotted in Figure 4 and detailed statistics are tabulated in
Table 6. There is no single metric such as low hotel or flight costs that is responsible for
RoxyBots success. Rather its success derives from the right balance of contradictory goals.
In particular, RoxyBot incurs high hotel and mid-range flight costs while achieving mid-range
trip penalty and high event profit.11
Let us compare RoxyBot with two closest rivals: Walverine and WhiteDolphin. Comparing to
Walverine first, Walverine bids lower prices (by 55) on fewer hotels (49 less), yet wins more (0.8)
and wastes less (0.42). It would appear that Walverines hotel bidding strategy outperforms
RoxyBots, except that RoxyBot earns a higher hotel bonus (15 more). RoxyBot also gains an
advantage by spending 40 less on flights and earning 24 more in total entertainment profit.
A very different competition takes place between RoxyBot and WhiteDolphin. WhiteDolphin
bids lower prices (120 less) on more hotels (by 52) than RoxyBot. RoxyBot spends much more
(220) on hotels than WhiteDolphin but makes up for it by earning a higher hotel bonus (by
96) and a lower trip penalty (by 153). It seems that WhiteDolphins strategy is to minimize
costs even if that means sacrificing utility.
6.3 Summary
As already noted, TAC Travel bidding, viewed as an optimization problem, is an n-stage
decision problem. We solve this n-stage decision problem as a sequence of 2-stage decision
problems. The controlled experiments reported in this section establish that our bidding
strategy, SAA, is the best in our test suite in the setting for which it was designed, with
only 2 stages. The TAC competition results establish that this strategy is also effective in
an n-stage setting.

7. Collective Behavior
The hotel price prediction techniques described in Section 4.2 are designed to compute (or at
least approximate) competitive equilibrium prices without full knowledge of the client pop11. An agent suffers trip penalties to the extent that it assigns its clients packages that differ from their
preferred.

539

fiGreenwald, Lee, & Naroditskiy

# of Hotel Bids
Average of Hotel Bids
# of Hotels Won
Hotel Costs
# of Unused Hotels
Hotel Bonus
Trip Penalty
Flight Costs
Event Profits
Event Bonus
Total Event Profits
Average Utility
Average Cost
Average Score

Rox
130
170
15.99
1102
2.24
613
296
4615
110
1470
1580
9787
5608
4179

Wal
81
115
16.79
1065
1.82
598
281
4655
26
1530
1556
9847
5693
4154

Whi
182
50
23.21
882
9.48
517
449
4592
6
1529
1535
9597
5468
4130

SIC
33
513
13.68
1031
0.49
617
340
4729
-6
1498
1492
9775
5765
4010

Mer
94
147
18.44
902
4.86
590
380
4834
123
1369
1492
9579
5628
3951

L-A
58
88
14.89
987
1.89
592
388
4525
-93
1399
1306
9604
5605
3999

kin
15
356
15.05
1185
0.00
601
145
4867
-162
1619
1457
10075
6213
3862

UTT
24
498
9.39
786
0.48
424
213
3199
-4
996
992
6607
3989
2618

Table 6: 2006 Finals, Last day. Tabulated Statistics. We omit the first two days because
agents can vary across days, but cannot vary within. Presumably, the entries on
the last day are the teams preferred versions of the agents.
2006 Finals, Last Day

2006 Finals, Last Day

2006 Finals, Last Day

4.5

6.5

10

6

3.5
3

9
8
7

2.5

6

2

5

Rox Wal Whi SIC Mer LA kin UTT
Agent

Cost (thousands)

Utility (thousands)

Score (thousands)

4

5.5
5
4.5
4
3.5

Rox Wal Whi SIC Mer LA kin UTT
Agent

3

Rox Wal Whi SIC Mer LA kin UTT
Agent

Figure 4: 2006 Finals, Last day. Mean scores, utilities, and costs, and 95% confidence
intervals.

ulation. In this section, we assume this knowledge and view the output of the tatonnement
and SimAA calculations not as predictions but as ground truth. We compare the actual
prices in the final games to this ground truth in respective years since 2002 to determine
whether TAC market prices resemble CE prices. What we find is depicted in Figure 5.
Because of the nature of our methods, these calculations pertain to hotel prices only.
The results are highly correlated on both metrics (Euclidean distance and EVPP). We
observe that the accuracy of CE price calculations has varied from year to year. 2003
was the year in which TAC Supply Chain Management (SCM) was introduced. Many
participants diverted their attention away from Travel towards SCM that year, perhaps
leading to degraded performance in Travel. Things seem to improve in 2004 and 2005. We

540

fiRoxyBot-06

cannot explain the setback in 2006, except by noting that performance is highly dependent
on the particular agent pool, and in 2006 there were fewer agents in that pool.
260

45

tatonnement, exact
simAA, exact
Expected Value of Perfect Prediction

240

Euclidean Distance

220
200
180
160
140
120
100
2002

2003

2004
Year

2005

2006

tatonnement, exact
simAA, expact

40

35

30

25

20
2002

2003

2004
Year

2005

2006

Figure 5: A comparison of the actual (hotel) prices to the output of competitive equilibrium
price calculations in the final games since 2002. The label exact means: full
knowledge of the client population.

8. Conclusion
The foremost aim of trading agent research is to develop a body of techniques for effective
design and analysis of trading agents. Contributions to trading agent design include the
invention of trading strategies, together with models and algorithms for realizing their
computation and methods to measure and evaluate the performance of agents characterized
by those strategies. Researchers seek both specific solutions to particular trading problems
and general principles to guide the development of trading agents across market scenarios.
This paper purports to contribute to this research agenda. We described the design and
implementation of RoxyBot-06, an able trading agent as demonstrated by its performance in
TAC-06.
Although automated trading in electronic markets has not yet fully taken hold, the
trend is well underway. Through TAC, the trading agent community is demonstrating the
potential for autonomous bidders to make pivotal trading decisions in a most effective way.
Such agents offer the potential to accelerate the automation of trading more broadly, and
thus shape the future of commerce.

Acknowledgments
This paper extends the work of Lee et al. (2007). The material in Section 5.1 is based on
the book by Wellman et al. (2007). We are grateful to several anonymous reviewers whose
constructive criticisms enhanced the quality of this work. This research was supported by
NSF Career Grant #IIS-0133689.

541

fiGreenwald, Lee, & Naroditskiy

Appendix A. TAC Bidding Problem: SAA
The problem of bidding in the simultaneous auctions that characterize TAC can be formulated as a two-stage stochastic program. In this appendix, we present the implementation
details of the integer linear program (ILP) encoded in RoxyBot-06 that approximates an
optimal solution to this stochastic program.12
We formulate this ILP assuming current prices are known, and future prices are uncertain in the first stage but revealed in the second stage. Note that whenever prices are
known, it suffices for an agent to make decisions about the quantity of each good to buy,
rather than about bid amounts, since choosing to bid an amount that is greater than or
equal to the price of a good is equivalent to a decision to buy that good.
Unlike in the main body of the paper, this ILP formulation of bidding in TAC assumes
linear prices. Table 7 lists the price constants and decision variables for each auction type.
For hotels, the only decisions pertain to buy offers; for flights, the agent decides how many
tickets to buy now and how many to buy later; for entertainment events, the agent chooses
sell quantities as well as buy quantities.
Hotels
bid now

Price
Yas

Flights and Events
buy now
buy later
Events
sell now
sell later

Variable (bid)
apq
Price
Ma
Yas

Price
Na
Zas

Variable (qty)
a
as

Variable (qty)
a
as

Table 7: Auction types and associated price constants and decision variables.

A.1 Index Sets
a  A indexes the set of goods, or auctions.
af  Af indexes the set of flight auctions.
ah  Ah indexes the set of hotel auctions.
ae  Ae indexes the set of event auctions.
c  C indexes the set of clients.
p  P indexes the set of prices.
12. The precise formulation of RoxyBot-06s bidding ILP appears in the paper by Lee et al. (2007). The
formulation here is slightly simplified, but we expect it would perform comparably in TAC. The key
differences are in flight and entertainment bidding.

542

fiRoxyBot-06

q  Q indexes the set of quantities
(i.e., the units of each good in each auction).
s  S indexes the set of scenarios.
t  T indexes the set of trips.
A.2 Constants
Gat indicates the quantity of good a required to complete trip t.
Ma indicates the current buy price of af , ae .
Na indicates the current sell price of ae .
Yas indicates the future buy price of af , ah , ae in scenario s.
Zas indicates the future sell price of ae in scenario s.
Ha indicates the hypothetical quantity won of hotel ah .
Oa indicates the quantity of good a the agent owns.
Uct indicates client cs value for trip t.
A.3 Decision Variables
 = {cst } is a set of boolean variables indicating whether or not client c is allocated
trip t in scenario s.
 = {apq } is a set of boolean variables indicating whether to bid price p on the qth
unit of ah .
M = {a } is a set of integer variables indicating how many units of af , ae to buy now.
N = {a } is a set of integer variables indicating how many units of ae to sell now.
Y = {as } is a set of integer variables indicating how many units of af , ae to buy later
in scenario s.
Z = {as } is a set of integer variables indicating how many units of ae to sell later in
scenario s.
A.4 Objective Function


flight cost

 current}| future {
hotel cost
z }| {
z X }|
{
X z }| { z }| {
X
X


Ma a + Yas as 
Uct cts 
Yas apq +
max


,,M,N,Y,Z
Af
Ah ,Q,pYas
S  C,T
trip value

z

543

(19)

fiGreenwald, Lee, & Naroditskiy


 event revenue
event cost
}|
{ z
z
}|
{
current
future
future 
current

z
}|
{
z
z
}|
{
}|
{
}| {
z
X


 Na a + Zas as  Ma a  Yas as 


Ae 

A.5 Constraints
X

cst  1 c  C, s  S

(20)

T

allocation

buy
own
z }| { z}|{
z }| {
X
cst Gat  Oa + (a + as )

a  Af , s  S

(21)

a  Ah , s  S

(22)

C,T

buy

allocation

own
z }| { z}|{
z X}|
{
X
cst Gat  Oa +
apq
C,T

Q,pYas

allocation


  sell 
own
buy
z }| { z}|{
z }| {
X
z }| {
cst Gat  Oa + a + as   a + as 
C,T

a  Ae , s  S

X

apq  Ha

(23)

a  Ah

(24)

apq  1 a  Ah , q  Q

(25)

P,Q

X
P

Equation (20) limits each client to one trip in each scenario. Equation (21) prevents the
agent from allocating flights that it does not own or buy. Equation (22) prevents the agent
from allocating hotels that it does not own or buy. Equation (23) prevents the agent from
allocating event tickets that it does not own or buy and not sell. Equation (24) ensures the
agent bids on at least HQW units in each hotel auction. Equation (25) prevents the agent
from placing more than one buy offer per unit in each hotel auction.
An agent might also be constrained not to place sell offers on more units of each good
than it owns, and/or not to place buy (sell) offers for more units of each good than the
market supplies (demands).
Note that there is no need to explicitly enforce the bid monotonicity constraints in this
ILP formulation:
 Buy offers must be nonincreasing in k, and sell offers nondecreasing.
The ILP does not need this constraint because prices are assumed to be linear.
In effect, the only decisions the ILP makes are how many units of each good to bid
on. Hence, the bids (10, 15, 20) and (20, 15, 10) are equivalent.
 An agent may not offer to sell for less than the price it is willing to buy.
544

fiRoxyBot-06

The ILP would not choose to place both a buy offer and a sell offer on a good if
the buy price of that good exceeds the sell price, because that would be unprofitable.

References
Ahmed, S., & Shapiro, A. (2002). The sample average approximation method for
stochastic programs with integer recourse. Optimization Online, http://www.
optimization-online.org.
Arunachalam, R., & Sadeh, N. M. (2005). The supply chain trading agent competition.
Electronic Commerce Research and Applications, 4 (1), 6684.
Aurell, E., Boman, M., Carlsson, M., Eriksson, J., Finne, N., Janson, S., Kreuger, P., &
Rasmusson, L. (2002). A trading agent built on constraint programming. In Eighth
International Conference of the Society for Computational Economics: Computing in
Economics and Finance, Aix-en-Provence.
Birge, J., & Louveaux, F. (1997). Introduction to Stochastic Programming. Springer, New
York.
Cai, K., Gerding, E., McBurney, P., Niu, J., Parsons, S., & S.Phelps (2009). Overview of
CAT: A market design competition. Tech. rep. ULCS-09-005, University of Liverpool.
Cheng, S., Leung, E., Lochner, K., K.OMalley, Reeves, D., Schvartzman, L., & Wellman,
M. (2003). Walverine: A Walrasian trading agent. In Proceedings of the Second
International Joint Conference on Autonomous Agents and Multi-Agent Systems, pp.
465472.
Cheng, S., Leung, E., Lochner, K., K.OMalley, Reeves, D., Schvartzman, L., & Wellman,
M. (2005). Walverine: A Walrasian trading agent. Decision Support Systems, 39 (2),
169184.
Cramton, P. (2006). Simultaneous ascending auctions. In Cramton, P., Shoham, Y., &
Steinberg, R. (Eds.), Combinatorial Auctions. MIT Press.
Fritschi, C., & Dorer, K. (2002). Agent-oriented software engineering for successful TAC participation. In Proceedings of the First International Joint Conference on Autonomous
Agents and Multiagent Systems, pp. 4546.
Greenwald, A. (2003). Bidding marginal utility in simultaneous auctions. In Workshop on
Trading Agent Design and Analysis.
Greenwald, A., & Boyan, J. (2004). Bidding under uncertainty: Theory and experiments.
In Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence, pp.
209216.
Greenwald, A., Naroditskiy, V., & Lee, S. (2008). Bidding heuristics for simultaneous
auctions: Lessons from tac travel. In Workshop on Trading Agent Design and Analysis.
Greenwald, A., & Boyan, J. (2005). Bidding algorithms for simultaneous auctions: A case
study. Journal of Autonomous Agents and Multiagent Systems, 10 (1), 6789.
He, M., & Jennings, N. (2002). SouthamptonTAC: Designing a successful trading agent. In
Proceedings of the Fifteenth European Conference on Artificial Intelligence, pp. 812.
545

fiGreenwald, Lee, & Naroditskiy

Jordan, P. R., & Wellman, M. P. (2009). Designing an ad auctions game for the trading
agent competition. In Workshop on Trading Agent Design and Analysis.
Kehagias, D., Toulis, P., & Mitkas, P. (2006). A long-term profit seeking strategy for continuous double auctions in a trading agent competition. In Fourth Hellenic Conference
on Artificial Intelligence, Heraklion.
Krishna, V. (2002). Auction Theory. Academic Press.
Lee, S. J. (2007). Comparison of bidding algorithms in simultaneous auctions. B.S. honors thesis, Brown University, http://list.cs.brown.edu/publications/theses/
ugrad/.
Lee, S., Greenwald, A., & Naroditskiy, V. (2007). Roxybot-06: An (SAA)2 TAC travel agent.
In Proceedings of the 20th International Joint Conference on Artificial Intelligence,
pp. 13781383.
Ross, S. M. (2002). Simulation (Third edition). Academic Press.
Sardinha, J. A. R. P., Milidiu, R. L., Paranhos, P. M., Cunha, P. M., & de Lucena, C.
J. P. (2005). An agent based architecture for highly competitive electronic markets.
In Proceedings of the Eighteenth International Florida Artificial Intelligence Research
Society Conference, Clearwater Beach, Florida, USA, pp. 326332.
Toulis, P., Kehagias, D., & Mitkas, P. (2006). Mertacor: A successful autonomous trading
agent. In Fifth International Joint Conference on Autonomous Agents and Multiagent
Systems, pp. 11911198, Hakodate.
Vetsikas, I., & Selman, B. (2002). WhiteBear: An empirical study of design tradeoffs for autonomous trading agents. In Workshop on Game-Theoretic Decision-Theoretic Agents.
Vickrey, W. (1961). Counterspeculation, auctions, and competitive sealed tenders. Journal
of Finance, 16, 837.
Walras, L. (1874). Elements deconomie politique pure. L. Corbaz, Lausanne.
Wellman, M. P., Greenwald, A., & Stone, P. (2007). Autonomous Bidding Agents: Strategies
and Lessons from the Trading Agent Competition. MIT Press.
Wellman, M. P., Reeves, D. M., Lochner, K. M., & Suri, R. (2005). Searching for Walverine
2005. In Workshop on Trading Agent Design and Analysis, No. 3937 in Lecture Notes
on Artificial Intelligence, pp. 157170. Springer.
Wellman, M., Reeves, D., Lochner, K., & Vorobeychik, Y. (2004). Price prediction in a
Trading Agent Competition. Artificial Intelligence Research, 21, 1936.

546

fi