Journal of Artificial Intelligence Research 31 (2008) 319-351

Submitted 09/07; published 02/08

The Complexity of Planning Problems
With Simple Causal Graphs
Omer Gimenez

omer.gimenez@upc.edu

Dept. de Llenguatges i Sistemes Informatics
Universitat Politecnica de Catalunya
Jordi Girona, 1-3
08034 Barcelona, Spain

Anders Jonsson

anders.jonsson@upf.edu

Dept. of Information and Communication Technologies
Passeig de Circumvallacio, 8
08003 Barcelona, Spain

Abstract
We present three new complexity results for classes of planning problems with simple
causal graphs. First, we describe a polynomial-time algorithm that uses macros to generate plans for the class 3S of planning problems with binary state variables and acyclic
causal graphs. This implies that plan generation may be tractable even when a planning
problem has an exponentially long minimal solution. We also prove that the problem of
plan existence for planning problems with multi-valued variables and chain causal graphs
is NP-hard. Finally, we show that plan existence for planning problems with binary state
variables and polytree causal graphs is NP-complete.

1. Introduction
Planning is an area of research in artificial intelligence that aims to achieve autonomous
control of complex systems. Formally, the planning problem is to obtain a sequence of
transformations for moving a system from an initial state to a goal state, given a description
of possible transformations. Planning algorithms have been successfully used in a variety
of applications, including robotics, process planning, information gathering, autonomous
agents and spacecraft mission control. Research in planning has seen significant progress
during the last ten years, in part due to the establishment of the International Planning
Competition.
An important aspect of research in planning is to classify the complexity of solving
planning problems. Being able to classify a planning problem according to complexity
makes it possible to select the right tool for solving it. Researchers usually distinguish
between two problems: plan generation, the problem of generating a sequence of transformations for achieving the goal, and plan existence, the problem of determining whether
such a sequence exists. If the original STRIPS formalism is used, plan existence is undecidable in the first-order case (Chapman, 1987) and PSPACE-complete in the propositional
case (Bylander, 1994). Using PDDL, the representation language used at the International
Planning Competition, plan existence is EXPSPACE-complete (Erol, Nau, & Subrahmanian, 1995). However, planning problems usually exhibit structure that makes them much
c
2008
AI Access Foundation. All rights reserved.

fiGimenez & Jonsson

easier to solve. Helmert (2003) showed that many of the benchmark problems used at the
International Planning Competition are in fact in P or NP.
A common type of structure that researchers have used to characterize planning problems is the so called causal graph (Knoblock, 1994). The causal graph of a planning
problem is a graph that captures the degree of independence among the state variables
of the problem, and is easily constructed given a description of the problem transformations. The independence between state variables can be exploited to devise algorithms for
efficiently solving the planning problem. The causal graph has been used as a tool for
describing tractable subclasses of planning problems (Brafman & Domshlak, 2003; Jonsson
& Backstrom, 1998; Williams & Nayak, 1997), for decomposing planning problems into
smaller problems (Brafman & Domshlak, 2006; Jonsson, 2007; Knoblock, 1994), and as the
basis for domain-independent heuristics that guide the search for a valid plan (Helmert,
2006).
In the present work we explore the computational complexity of solving planning problems with simple causal graphs. We present new results for three classes of planning problems studied in the literature: the class 3S (Jonsson & Backstrom, 1998), the class Cn
(Domshlak & Dinitz, 2001), and the class of planning problems with polytree causal graphs
(Brafman & Domshlak, 2003). In brief, we show that plan generation for instances of the
first class can be solved in polynomial time using macros, but that plan existence is not
solvable in polynomial time for the remaining two classes, unless P = NP. This work first
appeared in a conference paper (Gimenez & Jonsson, 2007); the current paper provides
more detail and additional insights as well as new sections on plan length and CP-nets.
A planning problem belongs to the class 3S if its causal graph is acyclic and all state
variables are either static, symmetrically reversible or splitting (see Section 3 for a precise definition of these terms). The class 3S was introduced and studied by Jonsson and
Backstrom (1998) as an example of a class for which plan existence is easy (there exists a
polynomial-time algorithm that determines whether or not a particular planning problem
of that class is solvable) but plan generation is hard (there exists no polynomial-time algorithm that generates a valid plan for every planning problem of the class). More precisely,
Jonsson and Backstrom showed that there are planning problems of the class 3S for which
every valid plan is exponentially long. This clearly prevents the existence of an efficient
plan generation algorithm.
Our first contribution is to show that plan generation for 3S is in fact easy if we are
allowed to express a valid plan using macros. A macro is simply a sequence of operators and
other macros. We present a polynomial-time algorithm that produces valid plans of this
form for planning problems of the class 3S. Namely, our algorithm outputs in polynomial
time a system of macros that, when executed, produce the actual valid plan for the planning
problem instance. The algorithm is sound and complete, that is, it generates a valid plan
if and only if one exists. We contrast our algorithm to the incremental algorithm proposed
by Jonsson and Backstrom (1998), which is polynomial in the size of the output.
We also investigate the complexity of the class Cn of planning problems with multivalued state variables and chain causal graphs. In other words, the causal graph is just a
directed path. Domshlak and Dinitz (2001) showed that there are solvable instances of this
class that require exponentially long plans. However, as it is the case with the class 3S,
there could exist an efficient procedure for generating valid plans for Cn instances using
320

fiComplexity of Planning Problems

macros or some other novel idea. We show that plan existence in Cn is NP-hard, hence
ruling out that such an efficient procedure exists, unless P = NP.
We also prove that plan existence for planning problems whose causal graph is a polytree (i.e., the underlying undirected graph is acyclic) is NP-complete, even if we restrict to
problems with binary variables. This result closes the complexity gap that appears in Brafman and Domshlak (2003) regarding planning problems with binary variables. The authors
show that plan existence is NP-complete for planning problems with singly connected causal
graphs, and that plan generation is polynomial for planning problems with polytree causal
graphs of bounded indegree. We use the same reduction to prove that a similar problem on
polytree CP-nets (Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004) is NP-complete.
1.1 Related Work
Several researchers have used the causal graph to devise algorithms for solving planning
problems or to study the complexity of planning problems. Knoblock (1994) used the
causal graph to decompose a planning problem into a hierarchy of increasingly abstract
problems. Under certain conditions, solving the hierarchy of abstract problems is easier than
solving the original problem. Williams and Nayak (1997) introduced several restrictions on
planning problems to ensure tractability, one of which is that the causal graph should be
acyclic. Jonsson and Backstrom (1998) defined the class 3S of planning problems, which
also requires the causal graphs to be acyclic, and showed that plan existence is polynomial
for this class.
Domshlak and Dinitz (2001) analyzed the complexity of several classes of planning
problems with acyclic causal graphs. Brafman and Domshlak (2003) designed a polynomialtime algorithm for solving planning problems with binary state variables and acyclic causal
graph of bounded indegree. Brafman and Domshlak (2006) identified conditions under
which it is possible to factorize a planning problem into several subproblems and solve
the subproblems independently. They claimed that a planning problem is suitable for
factorization if its causal graph has bounded tree-width.
The idea of using macros in planning is almost as old as planning itself (Fikes & Nilsson,
1971). Minton (1985) developed an algorithm that measures the utility of plan fragments
and stores them as macros if they are deemed useful. Korf (1987) showed that macros can
exponentially reduce the search space size of a planning problem if chosen carefully. Vidal
(2004) used relaxed plans generated while computing heuristics to produce macros that
contribute to the solution of planning problems. Macro-FF (Botea, Enzenberger, Muller,
& Schaeffer, 2005), an algorithm that identifies and caches macros, competed at the fourth
International Planning Competition. The authors showed how macros can help reduce the
search effort necessary to generate a valid plan.
Jonsson (2007) described an algorithm that uses macros to generate plans for planning
problems with tree-reducible causal graphs. There exist planning problems for which the
algorithm can generate exponentially long solutions in polynomial time, just like our algorithm for 3S. Unlike ours, the algorithm can handle multi-valued variables, which enables it
to solve problems such as Towers of Hanoi. However, not all planning problems in 3S have
tree-reducible causal graphs, so the algorithm cannot be used to show that plan generation
for 3S is polynomial.
321

fiGimenez & Jonsson

1.2 Hardness and Plan Length
A contribution of this paper is to show that plan generation may be polynomial even when
planning problems have exponential length minimal solutions, provided that solutions may
be expressed using a concise notation such as macros. We motivate this result below and
discuss the consequences. Previously, it has been thought that plan generation for planning
problems with exponential length minimal solutions is harder than NP, since it is not
known whether problems in NP are intractable, but it is certain that we cannot generate
exponential length output in polynomial time.
However, for a planning problem with exponential length minimal solution, it is not
clear if plan generation is inherently hard, or if the difficulty just lies in the fact that the
plan is long. Consider the two functional problems
f1 (F ) = w(1, 2|F | ),
f2 (F ) = w(t(F ), 2|F | ),
where F is a 3-CNF formula, |F | is the number of clauses of F , w(, k) is a word containing
k copies of the symbol , and t(F ) is 1 if F is satisfiable (i.e., F is in 3Sat), and 0 if it is
not. In both cases, the problem consists in generating the correct word. Observe that both
f1 and f2 are provably intractable, since their output is exponential in the size of the input.
Nevertheless, it is intuitive to regard problem f1 as easier than problem f2 . One way
to formalize this intuition is to allow programs to produce the output in some succinct
notation. For instance, if we allow programs to write w(,k) instead of a string containing
k copies of the symbol , then problem f1 becomes polynomial, but problem f2 does not
(unless P = NP).
We wanted to investigate the following question: regarding the class 3S, is plan generation intractable because solution plans are long, like f1 , or because the problem is intrinsically hard, like f2 ? The answer is that plan generation for 3S can be solved in polynomial
time, provided that one is allowed to give the solution in terms of macros, where a macro
is a simple substitution scheme: a sequence of operators and/or other macros. To back up
this claim, we present an algorithm that solves plan generation for 3S in polynomial time.
Other researchers have argued intractability using the fact that plans may have exponential length. Domshlak and Dinitz (2001) proved complexity results for several classes of
planning problems with multi-valued state variables and simple causal graphs. They argued
that the class Cn of planning problems with chain causal graphs is intractable since plans
may have exponential length. Brafman and Domshlak (2003) stated that plan generation
for STRIPS planning problems with unary operators and acyclic causal graphs is intractable
using the same reasoning. Our new result puts in question the argument used to prove the
hardness of these problems. For this reason, we analyze the complexity of these problems
and prove that they are hard by showing that the plan existence problem is NP-hard.

2. Notation
Let V be a set of state variables, and let D(v) be the finite domain of state variable v  V .
We define a state s as a function on V that maps each state variable v  V to a value
s(v)  D(v) in its domain. A partial state p is a function on a subset Vp  V of state
322

fiComplexity of Planning Problems

variables that maps each state variable v  Vp to p(v)  D(v). For a subset C  V of
state variables, p | C is the partial state obtained by restricting the domain of p to Vp  C.
Sometimes we use the notation (v1 = x1 , . . . , vk = xk ) to denote a partial state p defined by
Vp = {v1 , . . . , vk } and p(vi ) = xi for each vi  Vp . We write p(v) = to denote that v 
/ Vp .
Two partial states p and q match, which we denote pq, if and only if p | Vq = q | Vp ,
i.e., for each v  Vp Vq , p(v) = q(v). We define a replacement operator  such that if q and
r are two partial states, p = q  r is the partial state defined by Vp = Vq  Vr , p(v) = r(v)
for each v  Vr , and p(v) = q(v) for each v  Vq  Vr . Note that, in general, p  q 6= q  p.
A partial state p subsumes a partial state q, which we denote p  q, if and only if pq and
Vp  Vq . We remark that if p  q and r  s, it follows that p  r  q  s. The difference
between two partial states q and r, which we denote q  r, is the partial state p defined by
Vp = {v  Vq | q(v) 6= r(v)} and p(v) = q(v) for each v  Vp .
A planning problem is a tuple P = hV, init, goal, Ai, where V is the set of variables,
init is an initial state, goal is a partial goal state, and A is a set of operators. An operator
a = hpre(a); post(a)i  A consists of a partial state pre(a) called the pre-condition and a
partial state post(a) called the post-condition. Operator a is applicable in any state s such
that spre(a), and applying operator a in state s results in the new state s  post(a). A
valid plan  for P is a sequence of operators that are sequentially applicable in state init
such that the resulting state s satisfies s goal.
The causal graph of a planning problem P is a directed graph (V, E) with state variables
as nodes. There is an edge (u, v)  E if and only if u 6= v and there exists an operator
a  A such that u  Vpre(a)  Vpost(a) and v  Vpost(a) .

3. The Class 3S
Jonsson and Backstrom (1998) introduced the class 3S of planning problems to study the
relative complexity of plan existence and plan generation. In this section, we introduce
additional notation needed to describe the class 3S and illustrate some of the properties of
3S planning problems. We begin by defining the class 3S:
Definition 3.1 A planning problem P belongs to the class 3S if its causal graph is acyclic
and each state variable v  V is binary and either static, symmetrically reversible, or
splitting.
Below, we provide formal definitions of static, symmetrically reversible and splitting.
Note that the fact that the causal graph is acyclic implies that operators are unary, i.e., for
each operator a  A, |Vpost(a) | = 1. Without loss of generality, we assume that 3S planning
problems are in normal form, by which we mean the following:
 For each state variable v, D(v) = {0, 1} and init(v) = 0.
 post(a) = (v = x), x  {0, 1}, implies that pre(a)(v) = 1  x.
To satisfy the first condition, we can relabel the values of D(v) in the initial and goal
states as well as in the pre- and post-conditions of operators. To satisfy the second condition,
for any operator a with post(a) = (v = x) and pre(a)(v) 6= 1  x, we either remove it if
323

fiGimenez & Jonsson

v

V0

u
v=0
v

v=0

w=0
w
w=1

w

V*

s

u
v=0
v

t

(a)

v=0

w=0
w
w=1

w

s

V0

t

V1

w

(b)

Figure 1: Causal graph with splitting variable partitions for (a) v, (b) w.
pre(a)(v) = x, or we let pre(a)(v) = 1  x if previously undefined. The resulting planning
problem is in normal form and is equivalent to the original one. This process can be done
in time O(|A||V |).
The following definitions describe the three categories of state variables in 3S:
Definition 3.2 A state variable v  V is static if and only if one of the following holds:
1. There does not exist a  A such that post(a)(v) = 1,
2. goal(v) = 0 and there does not exist a  A such that post(a)(v) = 0.
Definition 3.3 A state variable v  V is reversible if and only if for each a  A such that
post(a) = (v = x), there exists a  A such that post(a ) = (v = 1  x). In addition, v is
symmetrically reversible if pre(a ) | (V  {v}) = pre(a) | (V  {v}).
From the above definitions it follows that the value of a static state variable cannot or
must not change, whereas the value of a symmetrically reversible state variable can change
freely, as long as it is possible to satisfy the pre-conditions of operators that change its
value. The third category of state variables is splitting. Informally, a splitting state variable
v splits the causal graph into three disjoint subgraphs, one which depends on the value
v = 1, one which depends on v = 0, and one which is independent of v. However, the
precise definition is more involved, so we need some additional notation.
For v  V , let Qv0 be the subset of state variables, different from v, whose value is
changed by some operator that has v = 0 as a pre-condition. Formally, Qv0 = {u  V  {v} |
a  A s.t. pre(a)(v) = 0  u  Vpost(a) }. Define Qv1 in the same way for v = 1. Let
Gv0 = (V, E0v ) be the subgraph of (V, E) whose edges exclude those between v and Qv0  Qv1 .
Formally, E0v = E  {(v, w) | w  Qv0  w 
/ Qv1 }. Finally, let V0v  V be the subset of state
variables that are weakly connected to some state variable of Qv0 in the graph Gv0 . Define
V1v in the same way for v = 1.
Definition 3.4 A state variable v  V is splitting if and only if V0v and V1v are disjoint.
Figure 1 illustrates the causal graph of a planning problem with two splitting state
variables, v and w. The edge label v = 0 indicates that there are operators for changing
the value of u that have v = 0 as a pre-condition. In other words, Qv0 = {u, w}, the graph
Gv0 = (V, E0v ) excludes the two edges labeled v = 0, and V0v includes all state state variables,
324

fiComplexity of Planning Problems

since v is weakly connected to u and w connects to the remaining state variables. The set
Qv1 is empty since there are no operators for changing the value of a state variable other
than v with v = 1 as a pre-condition. Consequently, V1v is empty as well. Figure 1(a) shows
the resulting partition for v.
w
w
In the case of w, Qw
0 = {s}, G0 = (V, E0 ) excludes the edge labeled w = 0, and
w
V0 = {s}, since no other state variable is connected to s when the edge w = 0 is removed.
Likewise, V1w = {t}. We use Vw = V  V0w  V1w to denote the set of remaining state
variables that belong neither to V0w nor to V1w . Figure 1(b) shows the resulting partition
for w.
Lemma 3.5 For any splitting state variable v, if the two sets V0v and V1v are non-empty,
v belongs neither to V0v nor to V1v .
Proof By contradiction. Assume that v belongs to V0v . Then v is weakly connected to
some state variable of Qv0 in the graph Gv0 = (V, E0v ). But since E0v does not exclude edges
between v and Qv1 , any state variable in Qv1 is weakly connected to the same state variable of
Qv0 in Gv0 . Consequently, state variables in Qv1 belong to both V0v and V1v , which contradicts
that v is splitting. The same reasoning holds to show that v does not belong to V1v .
Lemma 3.6 The value of a splitting state variable never needs to change more than twice
on a valid plan.
Proof Assume  is a valid plan that changes the value of a splitting state variable v at
least three times. We show that we can reorder the operators of  in such a way that the
value of v does not need to change more than twice. We need to address three cases: v
belongs to V0v (cf. Figure 1(a)), v belongs to V1v , or v belongs to Vv (cf. Figure 1(b)).
If v belongs to V0v , it follows from Lemma 3.5 that V1v is empty. Consequently, no
operator in the plan requires v = 1 as a pre-condition. Thus, we can safely remove all
operators in  that change the value of v, except possibly the last, which is needed in case
goal(v) = 1. If v belongs to V1v , it follows from Lemma 3.5 that V0v is empty. Thus, no
operator in the plan requires v = 0 as a pre-condition. The first operator in  that changes
the value of v is necessary to set v to 1. After that, we can safely remove all operators in 
that change the value of v, except the last in case goal(v) = 0. In both cases the resulting
plan contains at most two operators changing the value of v.
If v belongs to Vv , then the only edges between V0v , V1v , and Vv are those from v  Vv
to Qv0  V0v and Qv1  V1v . Let 0 , 1 , and  be the subsequences of operators in  that
affect state variables in V0v , V1v , and Vv , respectively. Write  = h , av1 ,  i, where av1 is
the last operator in  that changes the value of v from 0 to 1. We claim that the reordering
h0 ,  , av1 , 1 ,  i of plan  is still valid. Indeed, the operators of 0 only require v = 0,
which holds in the initial state, and the operators of 1 only require v = 1, which holds
due to the operator av1 . Note that all operators changing the value of v in  can be safely
removed since the value v = 1 is never needed as a pre-condition to change the value of a
state variable in Vv . The result is a valid plan that changes the value of v at most twice
(its value may be reset to 0 by  ).

325

fiGimenez & Jonsson

Variable
v1
v2
v3
v4
v5
v6
v7
v8

Operators
av11 = h(v1 = 0); (v1 = 1)i
av01 = h(v1 = 1); (v1 = 0)i
av12 = h(v1 = 1, v2 = 0); (v2 = 1)i
av13 = h(v1 = 0, v2 = 1, v3 = 0); (v3 = 1)i
av15
av16
av06
av17
av18

= h(v3
= h(v3
= h(v3
= h(v6
= h(v6

= 0, v4
= 1, v6
= 1, v6
= 1, v7
= 0, v7

= 0, v5 = 0); (v5 = 1)i
= 0); (v6 = 1)i
= 1); (v6 = 0)i
= 0); (v7 = 1)i
= 1, v8 = 0); (v8 = 1)i

V0vi
V

V1vi
V


{v4 , v5 }
V  {v4 }

V

V
{v6 , v7 , v8 }


V




V


Table 1: Operators and the sets V0vi and V1vi for the example planning problem.

v4
v1

v5
v7

v3
v6

v2

v8

Figure 2: Causal graph of the example planning problem.
The previous lemma, which holds for splitting state variables in general, provides some
additional insight into how to solve a planning problem with a splitting state variable v.
First, try to achieve the goal state for state variables in V0v while the value of v is 0, as in
the initial state. Then, set the value of v to 1 and try to achieve the goal state for state
variables in V1v . Finally, if goal(v) = 0, reset the value of v to 0.
3.1 Example
We illustrate the class 3S using an example planning problem. The set of state variables
is V = {v1 , . . . , v8 }. Since the planning problem is in normal form, the initial state is
init(vi ) = 0 for each vi  V . The goal state is defined by goal = (v5 = 1, v8 = 1), and
the operators in A are listed in Table 1. Figure 2 shows the causal graph (V, E) of the
planning problem. From the operators it is easy to verify that v4 is static and that v1
and v6 are symmetrically reversible. For the planning problem to be in 3S, the remaining
state variables have to be splitting. Table 1 lists the two sets V0vi and V1vi for each state
variable vi  V to show that indeed, V0vi  V1vi =  for each of the state variables in the set
{v2 , v3 , v5 , v7 , v8 }.
326

fiComplexity of Planning Problems

4. Plan Generation for 3S
In this section, we present a polynomial-time algorithm for plan generation in 3S. The
algorithm produces a solution to any instance of 3S in the form of a system of macros. The
idea is to construct unary macros that each change the value of a single state variable. The
macros may change the values of other state variables during execution, but always reset
them before terminating. Once the macros have been generated, the goal can be achieved
one state variable at a time. We show that the algorithm generates a valid plan if and only
if one exists.
We begin by defining macros as we use them in the paper. Next, we describe the
algorithm in pseudo-code (Figures 3, 4, and 5) and prove its correctness. To facilitate
reading we have moved a straightforward but involving proof to the appendix. Following
the description of the algorithm we analyze the complexity of all steps involved. In what
follows, we assume that 3S planning problems are in normal form as defined in the previous
section.
4.1 Macros
A macro-operator, or macro for short, is an ordered sequence of operators viewed as a unit.
Each operator in the sequence has to respect the pre-conditions of operators that follow
it, so that no pre-condition of any operator in the sequence is violated. Applying a macro
is equivalent to applying all operators in the sequence in the given order. Semantically,
a macro is equivalent to a standard operator in that it has a pre-condition and a postcondition, unambiguously induced by the pre- and post-conditions of the operators in its
sequence.
Since macros are functionally operators, the operator sequence associated with a macro
can include other macros, as long as this does not create a circular definition. Consequently,
it is possible to create hierarchies of macros in which the operator sequences of macros on
one level include macros on the level below. The solution to a planning problem can itself
be viewed as a macro which sits at the top of the hierarchy.
To define macros we first introduce the concept of induced pre- and post-conditions of
operator sequences. If  = ha1 , . . . , ak i is an operator sequence, we write i , 1  i  k, to
denote the subsequence ha1 , . . . , ai i.
Definition 4.1 An operator sequence  = ha1 , . . . , ak i induces a pre-condition pre() =
pre(ak )  pre(a1 ) and a post-condition post() = post(a1 )  post(ak ). In addition,
the operator sequence is well-defined if and only if (pre(i1 )post(i1 ))pre(ai ) for each
1 < i  k.
In what follows, we assume that P = (V, init, goal, A) is a planning problem such that
Vpost(a)  Vpre(a) for each operator a  A, and that  = ha1 , . . . , ak i is an operator sequence.
Lemma 4.2 For each planning problem P of this type and each , Vpost()  Vpre() .
Proof A direct consequence of the definitions Vpre() = Vpre(a1 )   Vpre(ak ) and Vpost() =
Vpost(a1 )      Vpost(ak ) .
327

fiGimenez & Jonsson

Lemma 4.3 The operator sequence  is applicable in state s if and only if  is well-defined
and spre(). The state sk resulting from the application of  to s is sk = s  post().
Proof By induction on k. The result clearly holds for k = 1. For k > 1, note that
pre() = pre(ak )  pre(k1 ), post() = post(k1 )  post(ak ), and  is well-defined if
and only if k1 is well-defined and (pre(k1 )  post(k1 ))pre(ak ).
By hypothesis of induction the state sk1 resulting from the application of k1 to s is
sk1 = s  post(k1 ). It follows that sk = sk1  post(ak ) = s  post().
Assume  is applicable in state s. This means that k1 is applicable in s and that ak
is applicable in sk1 = s  post(k1 ). By hypothesis of induction, the former implies that
spre(k1 ) and k1 is well-defined, and the latter that (s  post(k1 ))pre(ak ). This
last condition implies that (pre(k1 )  post(k1 ))pre(ak ) if we use that pre(k1 )  s,
which is a consequence of spre(k1 ) and s being a total state. Finally, we deduce
s(pre(ak )  pre(k1 )) from spre(k1 ) and (s  post(k1 ))pre(ak ), by using that
Vpost(k1 )  Vpre(k1 ) . It follows that  is well-defined and that spre().
Conversely, assume that  is well-defined and spre(). This implies that k1 is
well-defined and spre(k1 ), so by hypothesis of induction, k1 is applicable in state s.
It remains to show that ak is applicable in state sk1 , that is, (s  post(k1 ))pre(ak ).
From (pre(k1 )  post(k1 ))pre(ak ) it follows that post(k1 )pre(ak ). The fact that
s(pre(ak )  pre(k1 )) and Vpost(k1 )  Vpre(k1 ) completes the proof.
Since macros have induced pre- and post-conditions, Lemmas 4.2 and 4.3 trivially extend
to the case for which the operator sequence  includes macros. Now we are ready to
introduce our definition of macros:
Definition 4.4 A macro m is a sequence  = ha1 , . . . , ak i of operators and other macros
that induces a pre-condition pre(m) = pre() and a post-condition post(m) = post() 
pre(). The macro is well-defined if and only if no circular definitions occur and  is
well-defined.
To make macros consistent with standard operators, the induced post-condition should
only include state variables whose values are indeed changed by the macro, which is achieved
by computing the difference between post() and pre(). In particular, it holds that for a
3S planning problem in normal form, derived macros satisfy the second condition of normal
form, namely that post(m) = (v = x), x  {0, 1}, implies pre(m)(v) = 1  x.
Definition 4.5 Let Ancv be the set of ancestors of a state variable v in a 3S planning
problem. We define the partial state prev on Vprev = Ancv as
1. prev (u) = 1 if u  Ancv is splitting and v  V1u ,
2. prev (u) = 0 otherwise.
Definition 4.6 A macro m is a 3S-macro if it is well-defined and, for x  {0, 1}, post(m) =
(v = x) and pre(m)  prev  (v = 1  x).
328

fiComplexity of Planning Problems

Macro
mv11
mv01
mv12
mv13
mv15
mv16
mv06
mv17
mv18

Sequence

Pre-condition

hav11 i
hav01 i
hmv11 , av12 , mv01 i
hav13 i
hav15 i
hav16 i
hav06 i
hmv16 , av17 , mv06 i
hav18 i

(v1
(v1
(v1
(v1
(v3
(v3
(v3
(v3
(v3

= 0)
= 1)
= 0, v2
= 0, v2
= 0, v4
= 1, v6
= 1, v6
= 1, v6
= 1, v6

= 0)
= 1, v3
= 0, v5
= 0)
= 1)
= 0, v7
= 0, v7

Post-condition

= 0)
= 0)

= 0)
= 1, v8 = 0)

(v1
(v1
(v2
(v3
(v5
(v6
(v6
(v7
(v8

= 1)
= 0)
= 1)
= 1)
= 1)
= 1)
= 0)
= 1)
= 1)

Table 2: Macros generated by the algorithm in the example planning problem.

The algorithm we present only generates 3S-macros. In fact, it generates at most one
macro m = mvx with post(m) = (v = x) for each state variable v and value x  {0, 1}. To
illustrate the idea of 3S-macros and give a flavor of the algorithm, Table 2 lists the macros
generated by the algorithm in the example 3S planning problem from the previous section.
We claim that each macro is a 3S-macro. For example, the operator sequence hav16 i
induces a pre-condition (v3 = 1, v6 = 0) and a post-condition (v3 = 1, v6 = 0)  (v6 = 1) =
(v3 = 1, v6 = 1). Thus, the macro mv16 induces a pre-condition pre(mv16 ) = (v3 = 1, v6 = 0)
and a post-condition post(mv16 ) = (v3 = 1, v6 = 1)  (v3 = 1, v6 = 0) = (v6 = 1). Since v2
and v3 are splitting and since v6  V1v2 and v6  V1v3 , it follows that prev6  (v6 = 0) =
(v1 = 0, v2 = 1, v3 = 1, v6 = 0), so pre(mv16 ) = (v3 = 1, v6 = 0)  prev6  (v6 = 0).
The macros can be combined to produce a solution to the planning problem. The idea
is to identify each state variable v such that goal(v) = 1 and append the macro mv1 to the
solution plan. In the example, this results in the operator sequence hmv15 , mv18 i. However,
the pre-condition of mv18 specifies v3 = 1 and v7 = 1, which makes it necessary to insert mv13
and mv17 before mv18 . In addition, the pre-condition of mv13 specifies v2 = 1, which makes
it necessary to insert mv12 before mv13 , resulting in the final plan hmv15 , mv12 , mv13 , mv17 , mv18 i.
Note that the order of the macros matter; mv15 requires v3 to be 0 while mv18 requires
v3 to be 1. For a splitting state variable v, the goal state should be achieved for state
variables in V0v before the value of v is set to 1. We can expand the solution plan so that
it consists solely of operators in A. In our example, this results in the operator sequence
hav15 , av11 , av12 , av01 , av13 , av16 , av17 , av06 , av18 i. In this case, the algorithm generates an optimal
plan, although this is not true in general.
4.2 Description of the Algorithm
We proceed by providing a detailed description of the algorithm for plan generation in 3S.
We first describe the subroutine for generating a unary macro that sets the value of a state
variable v to x. This algorithm, which we call GenerateMacro, is described in Figure 3.
The algorithm takes as input a planning problem P , a state variable v, a value x (either 0
329

fiGimenez & Jonsson

1
2
3
4
5
6
7
8
9
10
11
12
13
14

function GenerateMacro(P , v, x, M )
for each a  A such that post(a)(v) = x do
S0  S1  hi
satisf y  true
U  {u  Vpre(a)  {v} | pre(a)(u) = 1}
for each u  U in increasing topological order do
if u is static or mu1 
/ M then
satisf y  false
else if u is not splitting and mu0  M and mu1  M then
S0  hS0 , mu0 i
S1  hmu1 , S1 i
if satisf y then
return hS1 , a, S0 i
return f ail
Figure 3: Algorithm for generating a macro that sets the value of v to x.

or 1), and a set of macros M for vs ancestors in the causal graph. Prior to executing the
algorithm, we perform a topological sort of the state variables. We assume that, for each
v  V and x  {0, 1}, M contains at most one macro mvx such that post(mvx ) = (v = x). In
the algorithm, we use the notation mvx  M to test whether or not M contains mvx .
For each operator a  A that sets the value of v to x, the algorithm determines whether
it is possible to satisfy its pre-condition pre(a) starting from the initial state. To do this, the
algorithm finds the set U of state variables to which pre(a) assigns 1 (the values of all other
state variables already satisfy pre(a) in the initial state). The algorithm constructs two
sequences of operators, S0 and S1 , by going through the state variables of U in increasing
topological order. If S is an operator sequence, we use hS, oi as shorthand to denote an
operator sequence of length |S| + 1 consisting of all operators of S followed by o, which can
be either an operator or a macro. If it is possible to satisfy the pre-condition pre(a) of some
operator a  A, the algorithm returns the macro hS1 , a, S0 i. Otherwise, it returns f ail.
Lemma 4.7 If v is symmetrically reversible and GenerateMacro(P , v, 1, M ) successfully generates a macro, so does GenerateMacro(P , v, 0, M ).
Proof Assume that GenerateMacro(P , v, 1, M ) successfully returns the macro hS1 , a, S0 i
for some operator a  A such that post(a) = 1. From the definition of symmetrically
reversible it follows that there exists an operator a  A such that post(a ) = 0 and
pre(a ) | V  {v} = pre(a) | V  {v}. Thus, the set U is identical for a and a . As
a consequence, the values of S0 , S1 , and satisf y are the same after the loop, which
means that GenerateMacro(P , v, 0, M ) returns the macro hS1 , a , S0 i for a . Note
that GenerateMacro(P , v, 0, M ) may return another macro if it goes through the operators of A in a different order; however, it is guaranteed to successfully return a macro.
Theorem 4.8 If the macros in M are 3S-macros and GenerateMacro(P , v, x, M )
generates a macro mvx 6= f ail, then mvx is a 3S-macro.
330

fiComplexity of Planning Problems

1
2
3
4
5
6
7
8
9
10

function Macro-3S(P )
M 
for each v  V in increasing topological order do
mv1  GenerateMacro(P , v, 1, M )
mv0  GenerateMacro(P , v, 0, M )
if mv1 6= f ail and mv0 6= f ail then
M  M  {mv1 , mv0 }
else if mv1 6= f ail and goal(v) 6= 0 then
M  M  {mv1 }
return GeneratePlan(P , V , M )
Figure 4: The algorithm Macro-3S.
The proof of Theorem 4.8 appears in Appendix A.

Next, we describe the algorithm for plan generation in 3S, which we call Macro-3S.
Figure 4 shows pseudocode for Macro-3S. The algorithm goes through the state variables
in increasing topological order and attempts to generate two macros for each state variable
v, mv1 and mv0 . If both macros are successfully generated, they are added to the current
set of macros M . If only mv1 is generated and the goal state does not assign 0 to v, the
algorithm adds mv1 to M . Finally, the algorithm generates a plan using the subroutine
GeneratePlan, which we describe later.
Lemma 4.9 Let P be a 3S planning problem and let v  V be a state variable. If there
exists a valid plan for solving P that sets v to 1, Macro-3S(P ) adds the macro mv1 to M .
If, in addition, the plan resets v to 0, Macro-3S(P ) adds mv0 to M .
Proof First note that if mv1 and mv0 are generated, Macro-3S(P ) adds them both to M .
If mv1 is generated but not mv0 , Macro-3S(P ) adds mv1 to M unless goal(v) = 0. However,
goal(v) = 0 contradicts the fact that there is a valid plan for solving P that sets v to 1
without resetting it to 0. It remains to show that GenerateMacro(P , v, 1, M ) always
generates mv1 6= f ail and that GenerateMacro(P , v, 0, M ) always generates mv0 6= f ail
if the plan resets v to 0.
A plan for solving P that sets v to 1 has to contain an operator a  A such that
post(a)(v) = 1. If the plan also resets v to 0, it has to contain an operator a  A such
that post(a )(v) = 0. We show that GenerateMacro(P , v, 1, M ) successfully generates
mv1 6= f ail if a is the operator selected on line 2. Note that the algorithm may return another
macro if it selects another operator before a; however, if it always generates a macro for a,
it is guaranteed to successfully return a macro mv1 6= f ail. The same is true for mv0 and a .
We prove the lemma by induction on state variables v. If v has no ancestors in the
causal graph, the set U is empty by default. Thus, satisf y is never set to false and
GenerateMacro(P , v, 1, M ) successfully returns the macro mv1 = hai for a. If a exists,
GenerateMacro(P , v, 0, M ) successfully returns mv0 = ha i for a .
If v has ancestors in the causal graph, let U = {u  Vpre(a)  {v} | pre(a)(u) = 1}.
Since the plan contains a it has to set each u  U to 1. By hypothesis of induction,
Macro-3S(P ) adds mu1 to M for each u  U . As a consequence, satisf y is never set to
331

fiGimenez & Jonsson

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

function GeneratePlan(P , W , M )
if |W | = 0 then
return hi
v  first variable in topological order present in W
if v is splitting then
v0  Generate-Plan(P , W  (V0v  {v}), M )
v1  Generate-Plan(P , W  (V1v  {v}), M )
v  Generate-Plan(P , W  (V  V0v  V1v  {v}), M )
if v0 = f ail or v1 = f ail or v = f ail or (goal(v) = 1 and mv1 
/ M ) then
return f ail
else if mv1 
/ M then return hv , v0 , v1 i
else if goal(v) = 0 then return hv , v0 , mv1 , v1 , mv0 i
else return hv , v0 , mv1 , v1 i
  Generate-Plan(P , W  {v}, M )
if  = f ail or (goal(v) = 1 and mv1 
/ M ) then return f ail
else if goal(v) = 1 then return h, mv1 i
else return 
Figure 5: Algorithm for generating the final plan

false and thus, GenerateMacro(P , v, 1, M ) successfully returns mv1 for a. If a exists,
let W = {w  Vpre(a )  {v} | pre(a )(w) = 1}. If the plan contains a , it has to set each
w  W to 1. By hypothesis of induction, Macro-3S(P ) adds mw
1 to M for each w  W
and consequently, GenerateMacro(P , v, 0, M ) successfully returns mv0 for a .
Finally, we describe the subroutine GeneratePlan(P , W , M ) for generating the final
plan given a planning problem P , a set of state variables W and a set of macros M . If
the set of state variables is empty, GeneratePlan(P , W , M ) returns an empty operator
sequence. Otherwise, it finds the state variable v  W that comes first in topological order.
If v is splitting, the algorithm separates W into the three sets described by V0v , V1v , and
Vv = V  V0v  V1v . The algorithm recursively generates plans for the three sets and if
necessary, inserts mv1 between V0v and V1v in the final plan. If this is not the case, the
algorithm recursively generates a plan for W  {v}. If goal(v) = 1 and mv1 , the algorithm
appends mv1 to the end of the resulting plan.
Lemma 4.10 Let W be the plan generated by GeneratePlan(P , W , M ), let v be the
first state variable in topological order present in W , and let V = ha , W , b i be the final
plan generated by Macro-3S(P ). If mv1  M it follows that (pre(a )post(a ))pre(mv1 ).
Proof We determine the content of the operator sequence a that precedes W in the final
plan by inspection. Note that the call GeneratePlan(P , W , M ) has to be nested within
a sequence of recursive calls to GeneratePlan starting with GeneratePlan(P , V , M ).
Let Z be the set of state variables such that each u  Z was the first state variable in
topological order for some call to GeneratePlan prior to GeneratePlan(P , W , M ).
Each u  Z has to correspond to a call to GeneratePlan with some set of state variables
U such that W  U . If u is not splitting, u does not contribute to a since the only
332

fiComplexity of Planning Problems

possible addition of a macro to the plan on line 16 places the macro mu1 at the end of the
plan generated recursively.
Assume that u  Z is a splitting state variable. We have three cases: W  V0u , W  V1u ,
and W  Vu = V  V0u  V1u . If W  Vu , u does not contribute to a since it never places
macros before u . If W  V0u , the plan u is part of a since it precedes u0 on lines 11,
12, and 13. If W  V1u , the plans u and u0 are part of a since they both precede u1 in
all cases. If mu1  M , the macro mu1 is also part of a since it precedes u1 on lines 12 and
13. No other macros are part of a .
Since the macros in M are unary, the plan generated by GeneratePlan(P , U , M )
only changes the values of state variables in U . For a splitting state variable u, there are
no edges from Vu  {u} to V0u , from Vu  {u} to V1u , or from V0u to V1u . It follows that the
plan u does not change the value of any state variable that appears in the pre-condition
of a macro in u0 . The same holds for u with respect to u1 and for u0 with respect to u1 .
Thus, the only macro in a that changes the value of a splitting state variable u  Ancv is
mu1 in case W  V1u .
Recall that prev is defined on Ancv and assigns 1 to u if and only if u is splitting and
v  V1u . For all other ancestors of v, the value 0 holds in the initial state and is not
altered by a . If u is splitting and v  V1u , it follows from the definition of 3S-macros that
pre(mv1 )(u) = 1 or pre(mv1 )(u) =. If pre(mv1 )(u) = 1, it is correct to append mu1 before
mv1 to satisfy pre(mv1 )(u). If mu1 
/ M it follows that u 
/ Vpre(mv1 ) , since pre(mv1 )(u) = 1
would have caused GenerateMacro(P , v, 1, M ) to set satisf y to false on line 8. Thus,
the pre-condition pre(mv1 ) of mv1 agrees with pre(a )  post(a ) on the value of each state
variable, which means that the two partial states match.
Lemma 4.11 GeneratePlan(P , V , M ) generates a well-defined plan.
Proof Note that for each state variable v  V , GeneratePlan(P , W , M ) is called
precisely once such that v is the first state variable in topological order. From Lemma 4.10
it follows that (pre(a )  post(a ))pre(mv1 ), where a is the plan that precedes W in
the final plan. Since v is the first state variable in topological order in W , the plans v0 ,
v1 , v , and , recursively generated by GeneratePlan, do not change the value of any
state variable in pre(mv1 ). It follows that mv1 is applicable following ha , v , v0 i or ha , i.
Since mv1 only changes the value of v, mv0 is applicable following ha , v , v0 , mv1 , v1 i.
Theorem 4.12 Macro-3S(P ) generates a valid plan for solving a planning problem in 3S
if and only if one exists.
Proof GeneratePlan(P , V , M ) returns f ail if and only if there exists a state variable
v  V such that goal(v) = 1 and mv1 
/ M . From Lemma 4.9 it follows that there does
not exist a valid plan for solving P that sets v to 1. Consequently, there does not exist a
plan for solving P . Otherwise, GeneratePlan(P , V , M ) returns a well-defined plan due
to Lemma 4.11. Since the plan sets to 1 each state variable v such that goal(v) = 1 and
resets to 0 each state variable v such that goal(v) = 0, the plan is a valid plan for solving
the planning problem.
333

fiGimenez & Jonsson

v1

v2

v3

v4

v5

Figure 6: Causal graph of the planning problem P5 .
4.3 Examples
We illustrate the algorithm on an example introduced by Jonsson and Backstrom (1998) to
show that there are instances of 3S with exponentially sized minimal solutions. Let Pn =
hV, init, goal, Ai be a planning problem defined by a natural number n, V = {v1 , . . . , vn },
and a goal state defined by Vgoal = V , goal(vi ) = 0 for each vi  {v1 , . . . , vn1 }, and
goal(vn ) = 1. For each state variable vi  V , there are two operators in A:
av1i = h(v1 = 0, . . . , vi2 = 0, vi1 = 1, vi = 0); (vi = 1)i,
av0i = h(v1 = 0, . . . , vi2 = 0, vi1 = 1, vi = 1); (vi = 0)i.
In other words, each state variable is symmetrically reversible. The causal graph of the planning problem P5 is shown in Figure 6. Note that for each state variable vi  {v1 , . . . , vn2 },
v
v
pre(a1i+1 )(vi ) = 1 and pre(a1i+2 )(vi ) = 0, so vi+1  Qv1i and vi+2  Q0vi . Since there is
an edge in the causal graph between vi+1 and vi+2 , no state variable in {v1 , . . . , vn2 } is
v
splitting. On the other hand, vn1 and vn are splitting since V0 n1 =  and V0vn = V1vn = .
Backstrom and Nebel (1995) showed that the length of the shortest plan solving Pn is 2n 1,
i.e., exponential in the number of state variables.
For each state variable vi  {v1 , . . . , vn1 }, our algorithm generates two macros mv1i and
vi
m0 . There is a single operator, av1i , that changes the value of vi from 0 to 1. pre(av1i )
only assigns 1 to vi1 , so U = {vi1 }. Since vi1 is not splitting, mv1i is defined as mv1i =
v
v
v
v
hm1i1 , av1i , m0i1 i. Similarly, mv0i is defined as mv0i = hm1i1 , av0i , m0i1 i. For state variable
vn , U = {vn1 }, which is splitting, so mv1n is defined as mv1n = hav1n i.
To generate the final plan, the algorithm goes through the state variables in topological order. For state variables v1 through vn2 , the algorithm does nothing, since these
state variables are not splitting and their goal state is not 1. For state variable vn1 ,
the algorithm recursively generates the plan for vn , which is hmv1n i since goal(vn ) = 1.
v
Since goal(vn1 ) = 0, the algorithm inserts m1n1 before mv1n to satisfy its pre-condition
v
vn1 = 1 and m0n1 after mv1n to achieve the goal state goal(vn1 ) = 0. Thus, the final plan
vn1
v
vn
is hm1 , m1 , m0n1 i. If we expand the plan, we end up with a sequence of 2n  1 operators. However, no individual macro has operator sequence length greater than 3. Together,
the macros recursively specify a complete solution to the planning problem.
We also demonstrate that there are planning problems in 3S with polynomial length
solutions for which our algorithm may generate exponential length solutions. To do this,
we modify the planning problem Pn by letting goal(vi ) = 1 for each vi  V . In addition,
for each state variable vi  V , we add two operators to A:
bv1i = h(v1 = 1, . . . , vi1 = 1, vi = 0); (vi = 1)i,
bv0i = h(v1 = 1, . . . , vi1 = 1, vi = 1); (vi = 0)i.
334

fiComplexity of Planning Problems

We also add an operator cv1n = h(vn1 = 0, vn = 0); (vn = 1)i to A. As a consequence, state variables in {v1 , . . . , vn2 } are still symmetrically reversible but not splitting.
vn1 is also symmetrically reversible but no longer splitting, since pre(av1n )(vn1 ) = 1 and
v
v
pre(cv1n )(vn1 ) = 0 implies that vn  V0 n1 V1 n1 . vn is still splitting since V0vn = V1vn = .
Assume that GenerateMacro(P , vi , x, M ) always selects bvxi first. As a consequence, for
each state variable vi  V and each x  {0, 1}, GenerateMacro(P , vi , x, M ) generates
v
v
the macro mvxi = hm1i1 , . . . , mv11 , bvxi , mv01 , . . . , m0i1 i.
Let Li be the length of the plan represented by mvxi , x  {0, 1}. From the definition of
v
i
mx above we have that Li = 2(L1 + . . . + Li1 ) + 1. We show by induction that Li = 3i1 .
The length of any macro for v1 is L1 = 1 = 30 . For i > 1,
Li = 2(30 + . . . + 3i2 ) + 1 = 2

3i1  1
3i1  1
+1=2
+ 1 = 3i1  1 + 1 = 3i1 .
31
2

To generate the final plan the algorithm has to change the value of each state variable
from 0 to 1, so the total length of the plan is L = L1 + . . . + Ln = 30 + . . . + 3n1 =
(3n  1)/2. However, there exists a plan of length n that solves the planning problem,
namely hbv11 , . . . , bv1n i.
4.4 Complexity
In this section we prove that the complexity of our algorithm is polynomial. To do this
we analyze each step of the algorithm separately. A summary of the complexity result for
each step of the algorithm is given below. Note that the number of edges |E| in the causal
graph is O(|A||V |), since each operator may introduce O(|V |) edges. The complexity result
O(|V | + |E|) = O(|A||V |) for topological sort follows from Cormen, Leiserson, Rivest, and
Stein (1990).
Constructing the causal graph G = (V, E)
Calculating V1v and V0v for each v  V
Performing a topological sort of G
GenerateMacro(P , v, x, M )
GeneratePlan(P , V , M )
Macro-3S(P )

O(|A||V |)
O(|A||V |2 )
O(|A||V |)
O(|A||V |)
O(|V |2 )
O(|A||V |2 )

Lemma 4.13
Lemma 4.14
Lemma 4.15
Lemma 4.16
Theorem 4.17

Lemma 4.13 The complexity of constructing the causal graph G = (V, E) is O(|A||V |).
Proof The causal graph consists of |V | nodes. For each operator a  A and each state
variable u  Vpre(a) , we should add an edge from u to the unique state variable v  Vpost(a) .
In the worst case, |Vpre(a) | = O(|V |), in which case the complexity is O(|A||V |).
Lemma 4.14 The complexity of calculating the sets V0v and V1v for each state variable
v  V is O(|A||V |2 ).
Proof For each state variable v  V , we have to establish the sets Qv0 and Qv1 , which requires
going through each operator a  A in the worst case. Note that we are only interested in
the pre-condition on v and the unique state variable in Vpost(a) , which means that we do not
335

fiGimenez & Jonsson

need to go through each state variable in Vpre(a) . Next, we have to construct the graph Gv0 .
We can do this by copying the causal graph G, which takes time O(|A||V |), and removing
the edges between v and Qv0  Qv1 , which takes time O(|V |).
Finally, to construct the set V0v we should find each state variable that is weakly connected to some state variable u  Qv0 in the graph Gv0 . For each state variable u  Qv0 ,
performing an undirected search starting at u takes time O(|A||V |). Once we have performed search starting at u, we only need to search from state variables in Qv0 that were
not reached during the search. This way, the total complexity of the search does not exceed
O(|A||V |). The case for constructing V1v is identical. Since we have to perform the same
procedure for each state variable v  V , the total complexity of this step is O(|A||V |2 ).
Lemma 4.15 The complexity of GenerateMacro(P , v, x, M ) is O(|A||V |).
Proof For each operator a  A, GenerateMacro(P , v, x, M ) needs to check whether
post(a)(v) = x. In the worst case, |U | = O(|V |), in which case the complexity of the
algorithm is O(|A||V |).
Lemma 4.16 The complexity of GeneratePlan(P , V , M ) is O(|V |2 ).
Proof Note that for each state variable v  V , GeneratePlan(P , V , M ) is called recursively exactly once such that v is the first variable in topological order. In other words,
GeneratePlan(P , V , M ) is called exactly |V | times. GeneratePlan(P , V , M ) contains
only constant operations except the intersection and difference between sets on lines 6-8.
Since intersection and set difference can be done in time O(|V |), the total complexity of
GeneratePlan(P , V , M ) is O(|V |2 ).
Theorem 4.17 The complexity of Macro-3S(P ) is O(|A||V |2 ).
Proof Prior to executing Macro-3S(P ), it is necessary to construct the causal graph G,
find the sets V0v and V1v for each state variable v  V , and perform a topological sort
of G. We have shown that these steps take time O(|A||V |2 ). For each state variable
v  V , Macro-3S(P ) calls GenerateMacro(P , v, x, M ) twice. From Lemma 4.15 it
follows that this step takes time O(2|V ||A||V |) = O(|A||V |2 ). Finally, Macro-3S(P ) calls
GeneratePlan(P , V , M ), which takes time O(|V |2 ) due to Lemma 4.16. It follows that
the complexity of Macro-3S(P ) is O(|A||V |2 ).
We conjecture that it is possible to improve the above complexity result for Macro3S(P ) to O(|A||V |). However, the proof seems somewhat complex, and our main objective
is not to devise an algorithm that is as efficient as possible. Rather, we are interested in
establishing that our algorithm is polynomial, which follows from Theorem 4.17.
4.5 Plan Length
In this section we study the length of the plans generated by the given algorithm. To begin
with, we derive a general bound on the length of such plans. Then, we show how to compute
the actual length of some particular plan without expanding its macros. We also present
an algorithm that uses this computation to efficiently obtain the i-th action of the plan
336

fiComplexity of Planning Problems

from its macro form. We start by introducing the concept of depth of state variables in the
causal graph.
Definition 4.18 The depth d(v) of a state variable v is the longest path from v to any
other state variable in the causal graph.
Since the causal graph is acyclic for planning problems in 3S, the depth of each state variable
is unique and can be computed in polynomial time. Also, it follows that at least one state
variable has depth 0, i.e., no outgoing edges.
Definition 4.19 The depth d of a planning problem P in 3S equals the largest depth of
any state variable v of P , i.e., d = maxvV d(v).
We characterize a planning problem based on the depth of each of its state variables. Let
n = |V | be the number of state variables, and let ci denote the number of state variables
with depth i. If the planning problem has depth d, it follows that c0 + . . . + cd = n. As an
example, consider the planning problem whose causal graph appears in Figure 2. For this
planning problem, n = 8, d = 5, c0 = 2, c1 = 2, c2 = 1, c3 = 1, c4 = 1, and c5 = 1.
Lemma 4.20 Consider the values Li for i  {0, . . . , d} defined by Ld = 1, and Li =
2(ci+1 Li+1 + ci+2 Li+2 + . . . + cd Ld ) + 1 when i < d. The values Li are an upper bound on
the length of macros generated by our algorithm for a state variable v with depth i.
Proof We prove it by a decreasing induction on the value of i. Assume v has depth i = d.
It follows from Definition 4.18 that v has no incoming edges. Thus, an operator changing
the value of v has no pre-condition on any state variable other than v, so Ld = 1 is an upper
bound, as stated.
Now, assume v has depth i < d, and that all Li+k for k > 0 are upper bounds on the
length of the corresponding macros. Let a  A be an operator that changes the value of v.
From the definition of depth it follows that a cannot have a pre-condition on a state variable
u with depth j  i; otherwise there would be an edge from u to v in the causal graph, causing
the depth of u to be greater than i. Thus, in the worst case, a macro for v has to change
the values of all state variables with depths larger than i, change the value of v, and reset
the values of state variables at lower levels. It follows that Li = 2(ci+1 Li+1 + . . . + cd Ld ) + 1
is an upper bound.
Theorem 4.21 The upper bounds Li of Lemma 4.20 satisfy Li = dj=i+1 (1 + 2cj ).
Proof Note that
Li = 2(ci+1 Li+1 + ci+2 Li+2 + . . . + cd Ld ) + 1 =
= 2ci+1 Li+1 + 2(ci+2 Li+2 + . . . + cd Ld ) + 1 =
= 2ci+1 Li+1 + Li+1 = (2ci+1 + 1)Li+1 .
The result easily follows by induction.
337

fiGimenez & Jonsson

Now we can obtain an upper bound L on the total length of the plan. In the worst
case, the goal state assigns a different value to each state variable than the initial state,
i.e., goal(v) 6= init(v) for each v  V . To achieve the goal state the algorithm applies one
macro per state variable. Hence
L = c0 L0 + c1 L1 + . . . + cd Ld = c0 L0 +

d
L0  1
(1 + 2c0 )L0  1
1Y
1
=
=
(1 + 2cj )  .
2
2
2
2
j=0

The previous bound depends on the distribution of the variables on depths according
to the causal graph. To obtain a general bound that does not depend on the depths of the
variables we first find which distribution maximizes the upper bound L.
Q
Lemma 4.22 The upper bound L = 21 dj=0 (1+2cj ) 12 on planning problems on n variables
and depth d is maximized when all ci are equal, that is, ci = n/(d + 1).
Proof Note that ci > 0 for all i, and that c0 +    + cd = n. The result follows from a direct
application of the well known AM-GM (arithmetic mean-geometric mean) inequality, which
states that the arithmetic mean of positive values xi is greater or equal than its geometric
mean, with equality only when all xi are the same.
This implies that the product of positive
P
factors xi = (1 + 2ci ) with fixed sum A = dj=0 xj = 2n + d is maximized when all are
equal, that is, ci = n/(d + 1).
Theorem 4.23 The length of a plan generated by the algorithm for a planning problem in
3S with n state variables and depth d is at most ((1 + 2n/(d + 1))d+1  1)/2.
Proof This is a direct consequence of Lemma 4.22. Since c0 , . . . , cd are discrete, it may not
be possible to set c0 = . . . = cd = n/(d + 1). Nevertheless, ((1 + 2n/(d + 1))d+1  1)/2 is an
upper bound on L in this case.
Observe that the bound established in Theorem 4.23 is an increasing function of d. This
implies that for a given d, the bound also applies to planning problems in 3S with depth
smaller than d. As a consequence, if the depth of a planning problem in 3S is bounded
from above by d, our algorithm generates a solution plan for the planning problem with
polynomial length O(nd+1 ). Since the complexity of executing a plan is proportional to
the plan length, we can use the depth d to define tractable complexity classes of planning
problems in 3S with respect to plan execution.
Theorem 4.24 The length of a plan generated by the algorithm for a planning problem in
3S with n state variables is at most (3n  1)/2.
Proof In the worst case, the depth d of a planning problem is n1. It follows from Theorem
4.23 that the length of a plan is at most ((1 + 2n/n)n  1)/2 = (3n  1)/2.
Note that the bound established in Theorem 4.24 is tight; in the second example in Section
4.3, we showed that our algorithm generates a plan whose length is (3n  1)/2.
338

fiComplexity of Planning Problems

1
2
3
4
5
6
7
8
9

function Operator(S, i)
o  first operator in S
while length(o) < i do
i  i  length(o)
o  next operator in S
if primitive(o) then
return o
else
return Operator(o, i)
Figure 7: An algorithm for determining the i-th operator in a sequence

Lemma 4.25 The complexity of computing the total length of any plan generated by our
algorithm is O(|V |2 ).
Proof The algorithm generates at most 2|V | = O(|V |) macros, 2 for each state variable. The
operator sequence of each macro consists of one operator and at most 2(|V |  1) = O(|V |)
other macros. We can use dynamic programming to avoid computing the length of a macro
more than once. In the worst case, we have to compute the length of O(|V |) macros, each
of which is a sum of O(|V |) terms, resulting in a total complexity of O(|V |2 ).
Lemma 4.26 Given a solution plan of length l and an integer 1  i  l, the complexity of
determining the i-th operator of the plan is O(|V |2 ).
Proof We prove the lemma by providing an algorithm for determining the i-th operator,
which appears in Figure 7. Since operator sequences S consist of operators and macros,
the variable o represents either an operator in A or a macro generated by Macro-3S. The
function primitive(o) returns true if o is an operator and f alse if o is a macro. The function
length(o) returns the length of o if o is a macro, and 1 otherwise. We assume that the length
of macros have been pre-computed, which we know from Lemma 4.25 takes time O(|V |2 ).
The algorithm simply finds the operator or macro at the i-th position of the sequence,
taking into account the length of macros in the sequence. If the i-th position is part of
a macro, the algorithm recursively finds the operator at the appropriate position in the
operator sequence represented by the macro. In the worst case, the algorithm has to go
through O(|V |) operators in the sequence S and call Operator recursively O(|V |) times,
resulting in a total complexity of O(|V |2 ).
4.6 Discussion
The general view of plan generation is that an output should consist in a valid sequence of
grounded operators that solves a planning problem. In contrast, our algorithm generates a
solution plan in the form of a system of macros. One might argue that to truly solve the
plan generation problem, our algorithm should expand the system of macros to arrive at the
sequence of underlying operators. In this case, the algorithm would no longer be polynomial,
since the solution plan of a planning problem in 3S may have exponential length. In fact, if
the only objective is to execute the solution plan once, our algorithm offers only marginal
benefit over the incremental algorithm proposed by Jonsson and Backstrom (1998).
339

fiGimenez & Jonsson

On the other hand, there are several reasons to view the system of macros generated by
our algorithm as a complete solution to a planning problem in 3S. The macros collectively
specify all the steps necessary to reach the goal. The solution plan can be generated and
verified in polynomial time, and the plan can be stored and reused using polynomial memory.
It is even possible to compute the length of the resulting plan and determine the i-th
operator of the plan in polynomial time as shown in Lemmas 4.25 and 4.26. Thus, for all
practical purposes the system of macros represents a complete solution. Even if the only
objective is to execute the solution plan once, our algorithm should be faster than that of
Jonsson and Backstrom (1998). All that is necessary to execute a plan generated by our
algorithm is to maintain a stack of currently executing macros and select the next operator
to execute, whereas the algorithm of Jonsson and Backstrom has to perform several steps
for each operator output.
Jonsson and Backstrom (1998) proved that the bounded plan existence problem for 3S
is NP-hard. The bounded plan existence problem is the problem of determining whether or
not there exists a valid solution plan of length at most k. As a consequence, the optimal
plan generation problem for 3S is NP-hard as well; otherwise, it would be possible to
solve the bounded plan existence problem by generating an optimal plan and comparing
the length of the resulting plan to k. In our examples we have seen that our algorithm
does not generate an optimal plan in general. In fact, our algorithm is just as bad as the
incremental algorithm of Jonsson and Backstrom, in the sense that both algorithms may
generate exponential length plans even though there exists a solution of polynomial length.
Since our algorithm makes it possible to compute the total length of a valid solution
in polynomial time, it can be used to generate heuristics for other planners. Specifically,
Katz and Domshlak (2007) proposed projecting planning problems onto provably tractable
fragments and use the solution to these fragments as heuristics for the original problem. We
have shown that 3S is such a tractable fragment. Unfortunately, because optimal planning
for 3S is NP-hard, there is no hope of generating an admissible heuristic. However, the
heuristic may still be informative in guiding the search towards a solution of the original
problem. In addition, for planning problems with exponential length optimal solutions, a
standard planner has no hope of generating a heuristic in polynomial time, making our
macro-based approach (and that of Jonsson, 2007) the only (current) viable option.

5. The Class Cn
Domshlak and Dinitz (2001) defined the class Cn of planning problems with multi-valued
state variables and chain causal graphs. Since chain causal graphs are acyclic, it follows that
operators are unary. Moreover, let vi be the i-th state variable in the chain. If i > 1, for
each operator a such that Vpost(a)  {vi } it holds that Vpre(a) = {vi1 , vi }. In other words,
each operator that changes the value of a state variable vi may only have pre-conditions on
vi1 and vi .
The authors showed that there are instances of Cn with exponentially sized minimal
solutions, and therefore argued that the class is intractable. In light of the previous section,
this argument on the length of the solutions does not discard the possibility that instances
of the class can be solved in polynomial time using macros. We show that this is not the
case, unless P = NP.
340

fiComplexity of Planning Problems

v1

vk

w

Figure 8: Causal graph of P (F ).
C1

C1, C1

0,1
Cn,Cn
Cn

C1

0,1
0

S

S

0,1

S

1

C1, C1
0,1

Cn,Cn

Cn

Figure 9: Domain transition graph for vi .
We define the decision problem Plan-Existence-Cn as follows. A valid input of PlanExistence-Cn is a planning instance P of Cn . The input P belongs to Plan-ExistenceCn if and only if P is solvable. We show in this section that the problem Plan-ExistenceCn is NP-hard. This implies that, unless P = NP, solving instances of Cn is a truly
intractable problem, namely, no polynomial-time algorithm can distinguish between solvable
and unsolvable instances of Cn . In particular, no polynomial-time algorithm can solve Cn
instances by using macros or any other kind of output format.1
We prove that Plan-Existence-Cn is NP-hard by a reduction from Cnf-Sat, that is,
the problem of determining whether a CNF formula F is satisfiable. Let C1 , . . . , Cn be the
clauses of the CNF formula F , and let v1 , . . . , vk be the variables that appear in F . We
briefly describe the intuition behind the reduction. The planning problem we create from
the formula F has a state variable for each variable appearing in F , and plans are forced
to commit a value (either 0 or 1) to these state variables before actually using them. Then,
to satisfy the goal of the problem, these variables are used to pass messages. However, the
operators for doing this are defined in such a way that a plan can only succeed when the
state variable values it has committed to are a satisfying assignment of F .
We proceed to describe the reduction. First ,we define a planning problem P (F ) =
hV, init, goal, Ai as follows. The set of state variables is V = {v1 , . . . , vk , w}, where D(vi ) =
{S, 0, 1, C1 , C1 , . . . , Cn , Cn } for each vi and D(w) = {S, 1, . . . , n}. The initial state defines
init(v) = S for each v  V and the goal state defines goal(w) = n. Figure 8 shows the
causal graph of P (F ).
The domain transition graph for each state variable vi is shown in Figure 9. Each node
represents a value in D(vi ), and an edge from x to y means that there exists an operator
a such that pre(a)(vi ) = x and post(a)(vi ) = y. Edge labels represent the pre-condition of
such operators on state variable vi1 , and multiple labels indicate that several operators
are associated with an edge. We enumerate the operators acting on vi using the notation
a = hpre(a); post(a)i (when i = 1 any mention of vi1 is understood to be void):
1. A valid output format is one that enables efficient distinction between an output representing a valid
plan and an output representing the fact that no solution was found.

341

fiGimenez & Jonsson

S

C1, C1

n1

1

Cn,Cn

n

Figure 10: Domain transition graph for w.
(1) Two operators hvi1 = S, vi = S; vi = 0i and hvi1 = S, vi = S; vi = 1i that allow vi
to move from S to either 0 or 1.
(2) Only when i > 1. For each clause Cj and each X  {Cj , Cj }, two operators
hvi1 = X, vi = 0; vi = Cj i and hvi1 = X, vi = 1; vi = Cj i. These operators allow vi to move to Cj or Cj if vi1 has done so.
(3) For each clause Cj and each X  {0, 1}, an operator hvi1 = X, vi = 0; vi = Cj i if v i
occurs in clause Cj , and an operator hvi1 = X, vi = 1; vi = Cj i if vi occurs in clause
Cj . These operators allow vi to move to Cj or Cj even if vi1 has not done so.
(4) For each clause Cj and each X = {0, 1}, two operators hvi1 = X, vi = Cj ; vi = 0i
and hvi1 = X, vi = Cj ; vi = 1i. These operators allow vi to move back to 0 or 1.
The domain transition graph for state variable w is shown in Figure 10. For every clause
Cj the only two operators acting on w are hvk = X, w = j  1; w = ji, where X  {Cj , Cj }
(if j = 1, the pre-condition w = j  1 is replaced by w = S).
Proposition 5.1 A CNF formula F is satisfiable if and only if the planning instance P (F )
is solvable.
Proof The proof follows from a relatively straightforward interpretation of the variables
and values of the planning instance P (F ). For every state variable vi , we must use an
operator of (1) to commit to either 0 or 1. Note that, once this choice is made, variable vi
cannot be set to the other value. The reason we need two values Cj and Cj for each clause
is to enforce this commitment (Cj corresponds to vi = 0, while Cj corresponds to vi = 1).
To reach the goal the state variable w has to advance step by step along the values 1, . . . , n.
Clearly, for every clause Cj there must exist some variable vi that is first set to values Cj
or Cj using an operator of (3). Then, this message can be propagated along variables
vi+1 , . . . , vk using operators of (2). Note that the existence of an operator of (3) acting on
vi implies that the initial choice of 0 or 1 for state variable vi , when applied to the formula
variable vi , makes the clause Cj true. Hence, if  is a plan solving P (F ), we can use the
initial choices of  on state variables vi to define a (partial) assignment  that satisfies all
clauses of F .
Conversely, if  is some assignment that satisfies F , we show how to obtain a plan 
that solves P (F ). First, we set every state variable vi to value (vi ). For every one of the
clauses Cj , we choose a variable vi among those that make Cj true using assignment .
Then, in increasing order of j, we set the state variable vi corresponding to clause Cj to a
value Cj or Cj (depending on (vi )), and we pass this message along vi+1 , . . . , vk up to w.
Theorem 5.2 Plan-Existence-Cn is NP-hard.
342

fiComplexity of Planning Problems

vx
vC

vC

vC

vC

vC

vC

1

2

3

vx

vy

vy

vz

vz

1

2

v1

v2

v3

v4

v5

3

Figure 11: Causal graph of PF when F = C1  C2  C3 on three variables x, y, z.
Proof Producing a planning instance P (F ) from a CNF formula F can be easily done in
polynomial time, so we have a polynomial-time reduction Cnf-Sat p Plan-ExistenceCn .

6. Polytree Causal Graphs
In this section, we study the class of planning problems with binary state variables and
polytree causal graphs. Brafman and Domshlak (2003) presented an algorithm that finds
plans for problems of this class in time O(n2 ), where n is the number of variables and
 is the maximum indegree of the polytree causal graph. Brafman and Domshlak (2006)
also showed how to solve in time roughly O(n ) planning domains with local depth  and
causal graphs of tree-width . It is interesting to observe that both algorithms fail to solve
polytree planning domains in polynomial time for different reasons: the first one fails when
the tree is too broad (unbounded indegree), the second one fails when the tree is too deep
(unbounded local depth, since the tree-width  of a polytree is 1).
In this section we prove that the problem of plan existence for polytree causal graphs
with binary variables is NP-hard. Our proof is a reduction from 3Sat to this class of
planning problems. As an example of the reduction, Figure 11 shows the causal graph of
the planning problem PF that corresponds to a formula F with three variables and three
clauses (the precise definition of PF is given in Proposition 6.2). Finally, at the end of this
section we remark that the same reduction solves a problem expressed in terms of CP-nets
(Boutilier et al., 2004), namely, that dominance testing for polytree CP-nets with binary
variables and partially specified CPTs is NP-complete.
Let us describe briefly the idea behind the reduction. The planning problem PF has two
 , . . . , and v ) depends on
different parts. The first part (state variables vx , vx , . . . , vC1 , vC
1
1
the formula F and has the property that a plan may change the value of v1 from 0 to 1 as
many times as the number of clauses of F that a truth assignment can satisfy. However, this
condition on v1 cannot be stated as a planning problem goal. We overcome this difficulty
by introducing a second part (state variables v1 , v2 , . . . , vt ) that translates it to a regular
planning problem goal.
We first describe the second part. Let P be the planning problem hV, init, goal, Ai
where V is the set of state variables {v1 , . . . , v2k1 } and A is the set of 4k  2 operators
{1 , . . . , 2k1 , 1 , . . . , 2k1 }. For i = 1, the operators are defined as 1 = hv1 = 1; v1 = 0i
343

fiGimenez & Jonsson

and 1 = hv1 = 0; v1 = 1i. For i > 1, the operators are i = hvi1 = 0, vi = 1; vi = 0i and
i = hvi1 = 1, vi = 0; vi = 1i. The initial state is init(vi ) = 0 for all i, and the goal state
is goal(vi ) = 0 if i is even and goal(vi ) = 1 if odd.
Lemma 6.1 Any valid plan for planning problem P changes state variable v1 from 0 to 1
at least k times. There is a valid plan that achieves this minimum.
Proof Let Ai and Bi be, respectively, the sequences of operators h1 , . . . , i i and h1 , . . . , i i.
It is easy to verify that the plan hB2k1 , A2k2 , B2k3 , . . . , B3 , A2 , B1 i solves the planning
problem P . Indeed, after applying the operators of Ai (respectively, the operators of Bi ),
variables v1 , . . . , vi become 0 (respectively, 1). In particular, variable vi attains its goal
state (0 if i is even, 1 if i is odd). Subsequent operators in the plan do not modify vi , so
the variable remains in its goal state until the end. The operator 1 appears k times in the
plan (one for each sequence of type Bi ), thus the value of v1 changes k times from 0 to 1.
We proceed to show that k is the minimum. Consider some plan  that solves the
planning problem P , and let i be the number of operators i and i appearing in  (in
other words, i is the number of times that the value of vi changes, either from 0 to 1 or
from 1 to 0). Note that the number of times operator i appears is equal to or precisely one
more than the number of occurrences of i . We will show that i1 > i . Since 2k1  1,
this implies that 1  2k  1, so that plan  has, at least, k occurrences of 1 , completing
the proof.
We show that i1 > i . Let Si be the subsequence of operators i and i in plan .
Clearly, Si starts with i (since the initial state is vi = 0), and the same operator cannot
appear twice consecutively in Si , so Si = i , i , i , i , etc. Also note that, for i > 1, i has
vi1 = 1 as a pre-condition, and i has vi1 = 0, hence there must be at least one operator
i1 in plan  betweeen any two operators i and i . For the same reason we must have
at least one operator i1 between any two operators i and i , and one operator i1
before the first operator i . This shows that i1  i . On the other hand, variables vi and
vi1 have different values in the goal state, so subsequences Si and Si1 must have different
lengths, that is, i1 6= i . Together, this implies i1 > i , as desired.
Proposition 6.2 3Sat reduces to plan existence for planning problems with binary variables and polytree causal graphs.
Proof Let F be a CNF formula with k clauses and n variables. We produce a planning
problem PF with 2n + 4k  1 state variables and 2n + 14k  3 operators. The planning
problem has two state variables vx and vx for every variable x in F , two state variables vC
 for every clause C in F , and 2k  1 additional variables v , . . . , v
and vC
1
2k1 . All variables
are 0 in the initial state. The (partial) goal state is defined by Vgoal = {v1 , . . . , v2k1 },
goal(vi ) = 0 when i is even, and goal(vi ) = 1 when i is odd, like in problem P of Lemma
6.1. The operators are:
(1) Operators hvx = 0; vx = 1i and hvx = 0; vx = 1i for every variable x of F .
 = 0; v  = 1i, hv  = 0, v = 0; v = 1i and hv  = 1, v = 1; v = 0i
(2) Operators hvC
C
C
C
C
C
C
C
for every clause C of F .

344

fiComplexity of Planning Problems

(3) Seven operators for every clause C, one for each partial assignment that satisfies C.
Without loss of generality, let x, y, and z be the three variables that appear in clause C.
Then for each operator a among these seven, Vpre(a) = {vx , vx , vy , vy , vz , vz , vC , v1 },
Vpost(a) = {v1 }, pre(a)(vC ) = 1, pre(a)(v1 ) = 0, and post(a)(v1 ) = 1. The precondition on state variables vx , vx , vy , vy , vz , vz depends on the corresponding satisfying partial assignment. For example, the operator corresponding to the partial
assignment {x = 0, y = 0, z = 1} of the clause C = x  y  z has the pre-condition
(vx = 0, vx = 1, vy = 0, vy = 1, vz = 1, vz = 0).
(4) An operator h(C, vC = 0), v1 = 1; v1 = 0i.
(5) Operators i = hvi1 = 0, vi = 1; vi = 0i and i = hvi1 = 1, vi = 0; vi = 1i for
2  i  2k  1 (the same operators as in problem P except for 1 and 1 ).
We note some simple facts about problem PF . For any variable x, state variables vx and
vx in PF start at 0, and by applying the operators in (1) they can change into 1 but not
back to 0. In particular, a plan  cannot reach both of the partial states hvx = 1, vx = 0i
and hvx = 0, vx = 1i during the course of its execution.
Similarly, if C is a clause of F , state variable vC can change from 0 to 1 and, by first
 into 1, v can change back to 0. No further changes are possible, since no
changing vC
C
 to 0.
operator brings back vC
Now we interpret operators in (3) and (4), which are the only operators that affect v1 .
To change v1 from 0 to 1 we need to apply one of the operators in (3), thus we require
vC = 1 for a clause C. But the only way to bring back v1 to 0 is applying the operator in
(4) which has as pre-condition that vC = 0. We deduce that every time that v1 changes its
value from 0 to 1 and then back to 0 in plan , at least one of the k state variables vC is
used up, in the sense that vC has been brought from 0 to 1 and then back to 0, and cannot
be used again for the same purpose.
We show that F is in 3Sat if and only if there is a valid plan for problem PF . Assume
F is in 3Sat, and let  be a truth assignment that satisfies F . Consider the following plan
 . First, we set vx = (x) and vx = 1  (x) for all variables x using the operators of (1).
Then, for a clause C in F , we set vC = 1, we apply the operator of (3) that corresponds to
 restricted to the variables of clause C (at this point, v1 changes from 0 to 1), then we set
 = 1 and v = 0, and we apply the operator of (4) (at this point, v change from 1 to
vC
1
C
0). By repeating this process for every clause C of F we are switching the state variable v1
exactly k times from 0 to 1. Now, following the proof of Lemma 6.1, we can easily extend
this plan  to a plan  that sets all variables vi to their goal values.
We show the converse, namely, that the existence of a valid plan  in PF implies that F
is satisfiable. Define an assignment  by setting (x) = 1 if the partial state {vx = 1, vx = 0}
appears during the execution of , and (x) = 0 otherwise. (Recall that at most one of the
partial states {vx = 1, vx = 0} and {vx = 0, vx = 1} can appear during the execution of any
plan). By Lemma 6.1,  must be such that state variable v1 changes from 0 to 1 at least k
times. This implies that k operators of (3), all of them corresponding to different clauses,
have been used to move v1 from 0 to 1. But to apply such an operator, the values of state
variables {vx , vx } must satisfy the corresponding clause. Thus the assignment  satisfies all
the k clauses of F .
345

fiGimenez & Jonsson

Theorem 6.3 Plan existence for planning problems with binary variables and polytree
causal graph is NP-complete.
Proof Due to Proposition 6.2 we only need to show that the problem is in NP. But
Brafman and Domshlak (2003) showed that this holds in the more general setting of planning
problems with causal graphs where each component is directed-path singly connected (that
is, there is at most one directed path between any pair of nodes). Their proof exploits a
non-trivial auxiliary result: solvable planning problems on binary variables with a directedpath singly connected causal graph have plans of polynomial length (the same is not true
for non-binary variables, or unrestricted causal graphs).
6.1 CP-nets
Boutilier et al. (2004) introduced the notion of a CP-net as a graphical representation of
user preferences. In brief, a CP-net is a network of dependences on a set of variables: the
preferences the user has for a variable depend on the values of some of the others, under the
ceteris paribus (all else being equal) assumption, that is, the user preferences on the variable
are completely independent of the values of the variables not mentioned. The preferences
for a variable given its parent variables in the network are stored in conditional preference
tables, or CPTs.
Boutilier et al. (2004) showed that the dominance query problem in acyclic CP-nets,
that is, the problem of deciding if one variable outcome is preferable to another, can be
expressed in terms of a planning problem. The network of dependences of the CP-net
becomes the causal graph of the planning problem.
However, under certain conditions, we can perform the opposite process: transform
a planning problem into a CP-net and a dominance query problem, such that answering
the query amounts to solving the planning problem. This is possible under the following
conditions on planning problems with acyclic causal graph and binary variables:
1. Two operators that modify the same variable in opposing directions must have nonmatching prevail conditions (the prevail condition of an operator a is the partial state
pre(a) | V  Vpost(a) ).
2. We must allow partially specified CPTs in the CP-net description.
The first condition guarantees that we obtain consistent CPTs from the planning instance
operators. The second condition ensures that the reduction is polynomial-size preserving,
since fully specified CPTs are exponential in the maximum node indegree of the CP-net.
In particular, the planning instance PF we reduced F to satisfies the first condition.
(Note that this is not true for the planning problem P of Lemma 6.1, but we drop the
reversing operators 1 and 1 when constructing PF in Proposition 6.2.) As a consequence,
we can claim the following:
Theorem 6.4 Dominance testing for polytree CP-nets with binary variables and partially
specified CPTs is NP-complete.
346

fiComplexity of Planning Problems

7. Conclusion
We have presented three new complexity results for planning problems with simple causal
graphs. First, we provided a polynomial-time algorithm that uses macros to generate solution plans for the class 3S. Although the solutions are generally suboptimal, the algorithm
can generate representations of exponentially long plans in polynomial time. This has several implications for theoretical work in planning, since it has been generally accepted that
exponentially sized minimal solutions imply that plan generation is intractable. Our work
shows that this is not always the case, provided that one is allowed to express the solution
in a succinct notation such as macros. We also showed that plan existence for the class Cn
is NP-hard, and that plan existence for the class of planning problems with binary variables
and polytree causal graph is NP-complete.
Jonsson and Backstrom (1998) investigated whether plan generation is significantly
harder than plan existence. Using the class 3S, they demonstrated that plan existence
can be solved in polynomial time, while plan generation is intractable in the sense that
solution plans may have exponential length. Our work casts new light on this result: even
though solution plans have exponential length, it is possible to generate a representation
of the solution in polynomial time. Thus, it appears as if for the class 3S, plan generation
is not inherently harder than plan existence. We are not aware of any other work that
determines the relative complexity of plan existence and plan generation, so the question
of whether plan generation is harder that plan existence remains open.
A potential criticism of our algorithm is that a solution in the form of macros is not
standard, and that it is intractable to expand the system of macros to arrive at the possibly
exponentially long sequence of underlying operators. Although this is true, we have shown
that the system of macros share several characteristics with a proper solution. It is possible
to generate and validate the solution in polynomial time, and the solution can be stored
using polynomial memory. We also showed that it is possible to compute the total length
of the solution in polynomial time, as well as determine which is the i-th operator in the
underlying sequence.
Since they are relatively simple, the class Cn and the class of planning problems with
binary state variables and polytree causal graphs could be seen as promising candidates for
proving the relative complexity of plan existence and plan generation. However, we have
shown that plan existence for Cn is NP-hard, and that plan existence for planning problems
with polytree causal graphs is NP-complete. Consequently, these classes cannot be used
to show that plan generation is harder than plan existence, since plan existence is already
difficult. Our work also closes the complexity gaps that appear in the literature regarding
these two classes.
It is however possible that there exist subsets of planning problems in these classes
for which plan existence can be solved in polynomial time. In fact, for polytree causal
graphs in binary variables we know that this is the case, due to the algorithms of Brafman
and Domshlak (2003, 2006) mentioned in Section 6. Hence the plan generation problem
is polynomial if we restrict to polytree causal graphs with either bounded indegree  or
bounded local depth . Consequently, our reduction from 3Sat exhibits both unbounded
indegree and unbounded local depth.
347

fiGimenez & Jonsson

Similarly, one may ask if the class Cn of planning problems has some parameter that,
when bounded, would yield a tractable subclass. The state variables in our reduction have
domains whose size depends on the number of clauses of the corresponding CNF formula,
so the domain size appears as an interesting candidate. Planning problems of Cn with
binary variables are tractable due to the work of Brafman and Domshlak (2003), but the
ideas they use do not extend to domain sizes other than 2. Hence it would be interesting
to investigate whether the problem of plan existence for the class Cn is easier if the size of
the state variable domains is bounded by a constant.

Appendix A. Proof of Theorem 4.8
Assume that GenerateMacro(P , v, x, M ) successfully returns the macro mvx = hS1 , a, S0 i.
Let U = {u  Vpre(a)  {v} | pre(a)(u) = 1} and let W = {w1 , . . . , wk }  U be the set
wi
i
of state variables in U such that wi is not splitting, {mw
0 , m1 }  M , and wi comes before wj in topological order if and only if i < j. It follows that no u  U is static, that
wk
w1
w1
k
S1 = hmw
1 , . . . , m1 i and that S0 = hm0 , . . . , m0 i. Since each state variable wi  W is
not splitting, it has to be symmetrically reversible.
Lemma A.1 For each wi  W , prewi  prev .
Proof Since wi  Vpre(a) and v  Vpost(a) , there is an edge from wi to v in the causal graph.
Thus, any ancestor of wi is also an ancestor of v, so Ancwi  Ancv . For a state variable
u  Ancwi , prewi (u) = 1 if and only if u is splitting and wi  V1u . The graph Gu1 = (V, E1u )
includes the edge from wi to v, which means that v  V1u if and only if wi  V1u . It follows
that prewi (u) = 1 if and only if prev (u) = 1, and as a consequence, prewi  prev .
i
Let  = hS0 , a, S1 i. For each wi  W and y  {0, 1}, let w
y be the sequence preceding
wi1
w
w
w
w
i+1
w
i
1
i
k
i.
the macro my i in , that is, 1 = hm1 , . . . , m1 i and 0 = hS0 , a, mw
0 , . . . , m0
a
a
Further, let  be the sequence appearing before a, that is,  = hS0 i.

wi
a
i
Lemma A.2 For each 1  i  k, the post-conditions of sequences w
1 ,  , and 0 are
i
 post(w
1 ) = (wi+1 = 1, . . . , wk = 1),

 post(a ) = (w1 = 1, . . . , wk = 1),
i
 post(w
0 ) = (w1 = 0, . . . , wi1 = 0, wi = 1, . . . , wk = 1, v = x).
i
Proof A direct consequence of post(ha1 , . . . , ak i) = post(a1 )  post(ak ) and post(mw
y )=
(wi = y), post(a) = (v = x).

wi
a
i
Lemma A.3 For each 1  i  k, the pre-conditions of sequences w
1 ,  , 0 , and 
wi
v
a
i
satisfy pre(w
1 )  pre( )  pre(0 )  pre()  pre  (v = 1  x).
a
i
Proof Since pre(ha1 , . . . , ak i) = pre(ak )  pre(a1 ), it follows that pre(w
1 )  pre( ) 
wi
v
pre(0 )  pre(). We prove that pre()  pre  (v = 1  x). For a state variable u
such that pre()(u) 6=, let mu be the first operator in hS0 , a, S1 i such that u  Vpre(mu ) ,
so that pre()(u) = pre(mu )(u).

348

fiComplexity of Planning Problems

u
wi  (w = 0)  prev , where we have
i
If mu = mw
i
1 , then it follows that pre(m )  pre
wi
used that m1 is a 3S-macro, wi is symmetrically reversible, and that prewi  prev due to
Lemma A.1. In particular, pre(mu )(u) = prev (u).
Since we assume that planning problems are in normal form, u = wi implies that
wi
u
i
u  Vpre(mwi ) . It follows that if mu 6= mw
1 for all i, then u 6= wi for all i. If m = m0
1
we have that pre(mu )  prewi  (wi = 1), but due to u 6= wi , we deduce pre(mu )(u) =
prewi (u) = prev (u).
Finally, consider the case mu = a. If u = v then pre(mu )(u) = 1  x, as desired. If
u 6= v is splitting, then either v belongs to V0u and pre(mu )(u) = 0, or v belongs to V1u and
pre(mu )(u) = 1. That is, pre(mu )(u) = prev (u). If u 6= v is symmetrically reversible it
follows that pre(mu )(u) = 0, since the case pre(mu )(u) = 1 would have forced the algorithm
to either fail or include u in W . If u 6= v is static, pre(mu )(u) = 0, else the algorithm would
have failed.

Lemma A.4 Let p, p , q and r be partial states. If p  p and (p  q)r, then (p  q)r.
Proof A direct consequence of p  q  p  q.
Lemma A.5 The macro mvx generated by the algorithm is well-defined.
Proof Since  only includes macros for the ancestors of v in the causal graph, and since
the causal graph is acyclic, no cyclic definitions occur. It remains to show that, for a macro
m in  and a sequence m preceding m in , it holds that (pre(m )  post(m ))pre(m).
Note that due to Lemmas A.3 and A.4 it is enough to show that
wi
i
(a) (prev  (v = 1  x)  post(w
1 ))pre(m1 ),

(b) (prev  (v = 1  x)  post(a ))pre(a),
wi
i
(c) (prev  (v = 1  x)  post(w
0 ))pre(m0 ).
wi
i
Case (a) follows easily since Vpost(wi ) Vpre(mwi ) =  and pre(mw
1 ) = pre (wi = 0) 
1
1
w
prev . Case (c) is similar, although this time we must use that post(0 i )(wi ) = 1 and
wi
wi  (w = 1). Finally, case (b)
i
post(w
i
0 )(wj ) = 0 for j < i, as required by pre(m0 ) = pre
holds because a variable u  Vpre(a) can be either u = v, which is covered by (v = 1  x),
splitting or static, which is covered by prev , or symmetrically reversible, which is covered
by prev (u) = 0 if pre(a)(u) = 0, and by post(a )(u) = 1 if pre(a)(u) = 1.

In remains to show that mvx is a 3S-macro. It follows from Lemmas A.3 and A.5 that it
is well-defined and it satisfies pre(mvx ) = pre()  prev  (v = 1  x). Finally, post(mvx ) =
post()pre() = (v = x) is a direct consequence of post() = (w1 = 0, . . . , wk = 0, v = x)
from Lemma A.2, and pre()(wi ) = 0, pre()(v) = 1  x from the proof of Lemma A.3.

Acknowledgments
This work was partially funded by MEC grants TIN2006-15387-C03-03 and TIN2004-07925C03-01 (GRAMMARS).
349

fiGimenez & Jonsson

References
Backstrom, C., & Nebel, B. (1995). Complexity Results for SAS+ Planning. Computational
Intelligence, 11 (4), 625655.
Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI
Planning with Automatically Learned Macro-Operators. Journal of Artificial Intelligence Research, 24, 581621.
Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2004). CP-nets: A Tool for
Representing and Reasoning with Conditional Ceteris Paribus Preference Statements.
Journal of Artificial Intelligence Research, 21, 135191.
Brafman, R., & Domshlak, C. (2003). Structure and Complexity in Planning with Unary
Operators. Journal of Artificial Intelligence Research, 18, 315349.
Brafman, R., & Domshlak, C. (2006). Factored Planning: How, When, and When Not. In
Proceedings of the 21st National Conference on Artificial Intelligence.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning.
Artificial Intelligence, 69, 165204.
Chapman, D. (1987). Planning for conjunctive goals. Artificial Intelligence, 32(3), 333377.
Cormen, T., Leiserson, C., Rivest, R., & Stein, C. (1990). Introduction to Algorithms. MIT
Press and McGraw Hill.
Domshlak, C., & Dinitz, Y. (2001). Multi-Agent Off-line Coordination: Structure and Complexity. In Proceedings of the 6th European Conference on Planning, pp. 277288.
Erol, K., Nau, D., & Subrahmanian, V. (1995). Complexity, decidability and undecidability
results for domain-independent planning. Artificial Intelligence, 76(1-2), 7588.
Fikes, R., & Nilsson, N. (1971). STRIPS: A new approach to the application of theorem
proving to problem solving. Artificial Intelligence, 5 (2), 189208.
Gimenez, O., & Jonsson, A. (2007). On the Hardness of Planning Problems With Simple
Causal Graphs. In Proceedings of the 17th International Conference on Automated
Planning and Scheduling, pp. 152159.
Helmert, M. (2003). Complexity results for standard benchmark domains in planning.
Artificial Intelligence, 143(2), 219262.
Helmert, M. (2006). The Fast Downward Planning System. Journal of Artificial Intelligence
Research, 26, 191246.
Jonsson, A. (2007). The Role of Macros in Tractable Planning Over Causal Graphs. In
Proceedings of the 20th International Joint Conference on Artificial Intelligence, pp.
19361941.
Jonsson, P., & Backstrom, C. (1998). Tractable plan existence does not imply tractable
plan generation. Annals of Mathematics and Artificial Intelligence, 22(3-4), 281296.
Katz, M., & Domshlak, C. (2007). Structural Patterns Heuristics: Basic Idea and Concrete
Instance. In Workshop on Heuristics for Domain-independent Planning: Progress,
Ideas, Limitations, Challenges (ICAPS-07).
350

fiComplexity of Planning Problems

Knoblock, C. (1994). Automatically generating abstractions for planning. Artificial Intelligence, 68(2), 243302.
Korf, R. (1987). Planning as search: A quantitative approach. Artificial Intelligence, 33(1),
6588.
Minton, S. (1985). Selectively generalizing plans for problem-solving. In Proceedings of the
9th International Joint Conference on Artificial Intelligence, pp. 596599.
Vidal, V. (2004). A Lookahead Strategy for Heuristic Search Planning. In Proceedings of the
14th International Conference on Automated Planning and Scheduling, pp. 150159.
Williams, B., & Nayak, P. (1997). A reactive planner for a model-based executive. In
Proceedings of the 15th International Joint Conference on Artificial Intelligence, pp.
11781185.

351

fi