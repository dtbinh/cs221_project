Journal of Artificial Intelligence Research 31 (2008) 273-318

Submitted 07/07; published 02/08

Modular Reuse of Ontologies: Theory and Practice
Bernardo Cuenca Grau
Ian Horrocks
Yevgeny Kazakov

berg@comlab.ox.ac.uk
ian.horrocks@comlab.ox.ac.uk
yevgeny.kazakov@comlab.ox.ac.uk

Oxford University Computing Laboratory
Oxford, OX1 3QD, UK

Ulrike Sattler

sattler@cs.man.ac.uk

School of Computer Science
The University of Manchester
Manchester, M13 9PL, UK

Abstract
In this paper, we propose a set of tasks that are relevant for the modular reuse of ontologies. In order to formalize these tasks as reasoning problems, we introduce the notions
of conservative extension, safety and module for a very general class of logic-based ontology
languages. We investigate the general properties of and relationships between these notions
and study the relationships between the relevant reasoning problems we have previously
identified. To study the computability of these problems, we consider, in particular, Description Logics (DLs), which provide the formal underpinning of the W3C Web Ontology
Language (OWL), and show that all the problems we consider are undecidable or algorithmically unsolvable for the description logic underlying OWL DL. In order to achieve a
practical solution, we identify conditions sufficient for an ontology to reuse a set of symbols safelythat is, without changing their meaning. We provide the notion of a safety
class, which characterizes any sufficient condition for safety, and identify a family of safety
classescalled localitywhich enjoys a collection of desirable properties. We use the notion
of a safety class to extract modules from ontologies, and we provide various modularization algorithms that are appropriate to the properties of the particular safety class in use.
Finally, we show practical benefits of our safety checking and module extraction algorithms.

1. Motivation
Ontologiesconceptualizations of a domain shared by a community of usersplay a major role in the Semantic Web, and are increasingly being used in knowledge management
systems, e-Science, bio-informatics, and Grid applications (Staab & Studer, 2004).
The design, maintenance, reuse, and integration of ontologies are complex tasks. Like
software engineers, ontology engineers need to be supported by tools and methodologies
that help them to minimize the introduction of errors, i.e., to ensure that ontologies are
consistent and do not have unexpected consequences. In order to develop this support, important notions from software engineering, such as module, black-box behavior, and controlled
interaction, need to be adapted.
Recently, there has been growing interest in the topic of modularity in ontology engineering (Seidenberg & Rector, 2006; Noy, 2004a; Lutz, Walther, & Wolter, 2007; Cuenca
Grau, Parsia, Sirin, & Kalyanpur, 2006b; Cuenca Grau, Horrocks, Kazakov, & Sattler,
c
2008
AI Access Foundation. All rights reserved.

fiCuenca Grau, Horrocks, Kazakov, & Sattler

2007), which has been motivated by the above-mentioned application needs. In this paper,
we focus on the use of modularity to support the partial reuse of ontologies. In particular,
we consider the scenario in which we are developing an ontology P and want to reuse a set
S of symbols from a foreign ontology Q without changing their meaning.
For example, suppose that an ontology engineer is building an ontology about research
projects, which specifies different types of projects according to the research topic they
focus on. The ontology engineer in charge of the projects ontology P may use terms such
as Cystic Fibrosis and Genetic Disorder in his descriptions of medical research projects. The
ontology engineer is an expert on research projects; he may be unfamiliar, however, with
most of the topics the projects cover and, in particular, with the terms Cystic Fibrosis and
Genetic Disorder. In order to complete the projects ontology with suitable definitions for
these medical terms, he decides to reuse the knowledge about these subjects from a wellestablished medical ontology Q.
The most straightforward way to reuse these concepts is to construct the logical union
P  Q of the axioms in P and Q. It is reasonable to assume that the additional knowledge
about the medical terms used in both P and Q will have implications on the meaning of the
projects defined in P; indeed, the additional knowledge about the reused terms provides new
information about medical research projects which are defined using these medical terms.
Less intuitive is the fact that importing Q may also result in new entailments concerning
the reused symbols, namely Cystic Fibrosis and Genetic Disorder. Since the ontology engineer
of the projects ontology is not an expert in medicine and relies on the designers of Q, it is
to be expected that the meaning of the reused symbols is completely specified in Q; that
is, the fact that these symbols are used in the projects ontology P should not imply that
their original meaning in Q changes. If P does not change the meaning of these symbols
in Q, we say that P  Q is a conservative extension of Q
In realistic application scenarios, it is often unreasonable to assume the foreign ontology
Q to be fixed; that is, Q may evolve beyond the control of the modelers of P. The ontology
engineers in charge of P may not be authorized to access all the information in Q or,
most importantly, they may decide at a later time to reuse the symbols Cystic Fibrosis and
Genetic Disorder from a medical ontology other than Q. For application scenarios in which
the external ontology Q may change, it is reasonable to abstract from the particular Q
under consideration. In particular, given a set S of external symbols, the fact that the
axioms in P do not change the meaning of any symbol in S should be independent of the
particular meaning ascribed to these symbols by Q. In that case, we will say that P is safe
for S.
Moreover, even if P safely reuses a set of symbols from an ontology Q, it may still
be the case that Q is a large ontology. In particular, in our example, the foreign medical
ontology may be huge, and importing the whole ontology would make the consequences
of the additional information costly to compute and difficult for our ontology engineers in
charge of the projects ontology (who are not medical experts) to understand. In practice,
therefore, one may need to extract a module Q1 of Q that includes only the relevant information. Ideally, this module should be as small as possible while still guarantee to capture
the meaning of the terms used; that is, when answering queries against the research projects
ontology, importing the module Q1 would give exactly the same answers as if the whole
medical ontology Q had been imported. In this case, importing the module will have the
274

fiModular Reuse of Ontologies: Theory and Practice

same observable effect on the projects ontology as importing the entire ontology. Furthermore, the fact that Q1 is a module in Q should be independent of the particular P under
consideration.
The contributions of this paper are as follows:
1. We propose a set of tasks that are relevant to ontology reuse and formalize them as
reasoning problems. To this end, we introduce the notions of conservative extension,
safety and module for a very general class of logic-based ontology languages.
2. We investigate the general properties of and relationships between the notions of
conservative extension, safety, and module and use these properties to study the relationships between the relevant reasoning problems we have previously identified.
3. We consider Description Logics (DLs), which provide the formal underpinning of the
W3C Web Ontology Language (OWL), and study the computability of our tasks. We
show that all the tasks we consider are undecidable or algorithmically unsolvable for
the description logic underlying OWL DLthe most expressive dialect of OWL that
has a direct correspondence to description logics.
4. We consider the problem of deciding safety of an ontology for a signature. Given that
this problem is undecidable for OWL DL, we identify sufficient conditions for safety,
which are decidable for OWL DLthat is, if an ontology satisfies our conditions
then it is safe; the converse, however, does not necessarily hold. We propose the
notion of a safety class, which characterizes any sufficiency condition for safety, and
identify a family of safety classescalled localitywhich enjoys a collection of desirable
properties.
5. We next apply the notion of a safety class to the task of extracting modules from
ontologies; we provide various modularization algorithms that are appropriate to the
properties of the particular safety class in use.
6. We present empirical evidence of the practical benefits of our techniques for safety
checking and module extraction.
This paper extends the results in our previous work (Cuenca Grau, Horrocks, Kutz, &
Sattler, 2006; Cuenca Grau et al., 2007; Cuenca Grau, Horrocks, Kazakov, & Sattler, 2007).

2. Preliminaries
In this section we introduce description logics (DLs) (Baader, Calvanese, McGuinness,
Nardi, & Patel-Schneider, 2003), a family of knowledge representation formalisms which
underlie modern ontology languages, such as OWL DL (Patel-Schneider, Hayes, & Horrocks, 2004). A hierarchy of commonly-used description logics is summarized in Table 1.
The syntax of a description logic L is given by a signature and a set of constructors. A
signature (or vocabulary) Sg of a DL is the (disjoint) union of countably infinite sets AC
of atomic concepts (A, B, . . . ) representing sets of elements, AR of atomic roles (r, s, . . . )
representing binary relations between elements, and Ind of individuals (a, b, c, . . . ) representing constants. We assume the signature to be fixed for every DL.
275

fiCuenca Grau, Horrocks, Kazakov, & Sattler

DLs

Constructors
Con
>, A, C1 u C2 , R.C
pp, C
pp

Axioms [ Ax ]
TBox
ABox
A  C, C1 v C2 a : C, r(a, b)
pp
pp
pp
pp

Rol
RBox
EL
r
ALC pp
S pp
Trans(r)
+ I
r
+ H
R 1 v R2
+ F
Funct(R)
+ N
(> n S)
+ Q
(> n S.C)
+ O
{i}
Here r  AR, A  AC, a, b  Ind, R(i)  Rol, C(i)  Con, n  1 and S  Rol is a simple
role (see (Horrocks & Sattler, 2005)).
Table 1: The hierarchy of standard description logics

Every DL provides constructors for defining the set Rol of (general) roles (R, S, . . . ),
the set Con of (general) concepts (C, D, . . . ), and the set Ax of axioms (, , . . . ) which is
a union of role axioms (RBox), terminological axioms (TBox) and assertions (ABox).
EL (Baader, Brandt, & Lutz, 2005) is a simple description logic which allows one to
construct complex concepts using conjunction C1 u C2 and existential restriction R.C
starting from atomic concepts A, roles R and the top concept >. EL provides no role
constructors and no role axioms; thus, every role R in EL is atomic. The TBox axioms of
EL can be either concept definitions A  C or general concept inclusion axioms (GCIs)
C1 v C2 . EL assertions are either concept assertions a : C or role assertions r(a, b). In this
paper we assume the concept definition A  C is an abbreviation for two GCIs A v C and
C v A.
The basic description logic ALC (Schmidt-Schau & Smolka, 1991) is obtained from EL
by adding the concept negation constructor C. We introduce some additional constructors
as abbreviations: the bottom concept  is a shortcut for >, the concept disjunction C1 t C2
stands for (C1 u C2 ), and the value restriction R.C stands for (R.C). In contrast
to EL, ALC can express contradiction axioms like > v . The logic S is an extension of
ALC where, additionally, some atomic roles can be declared to be transitive using a role
axiom Trans(r).
Further extensions of description logics add features such as inverse roles r (indicated
by appending a letter I to the name of the logic), role inclusion axioms (RIs) R1 v R2 (+H),
functional roles Funct(R) (+F), number restrictions (> n S), with n  1, (+N ), qualified
number restrictions (> n S.C), with n  1, (+Q)1 , and nominals {a} (+O). Nominals make
it possible to construct a concept representing a singleton set {a} (a nominal concept) from
an individual a. These extensions can be used in different combinations; for example ALCO
is an extension of ALC with nominals; SHIQ is an extension of S with role hierarchies,
1. the dual constructors (6 n S) and (6 n S.C) are abbreviations for (> n + 1 S) and (> n + 1 S.C),
respectively

276

fiModular Reuse of Ontologies: Theory and Practice

inverse roles and qualified number restrictions; and SHOIQ is the DL that uses all the
constructors and axiom types we have presented.
Modern ontology languages, such as OWL, are based on description logics and, to a certain extent, are syntactic variants thereof. In particular, OWL DL corresponds to SHOIN
(Horrocks, Patel-Schneider, & van Harmelen, 2003). In this paper, we assume an ontology
O based on a description logic L to be a finite set of axioms in L. The signature of an
ontology O (of an axiom ) is the set Sig(O) (Sig()) of atomic concepts, atomic roles and
individuals that occur in O (respectively in ).
The main reasoning task for ontologies is entailment: given an ontology O and an axiom
, check if O implies . The logical entailment |= is defined using the usual Tarski-style
set-theoretic semantics for description logics as follows. An interpretation I is a pair I =
(I , I ), where I is a non-empty set, called the domain of the interpretation, and I is the
interpretation function that assigns: to every A  AC a subset AI  I , to every r  AR
a binary relation rI  I  I , and to every a  Ind an element aI  I . Note that the
sets AC, AR and Ind are not defined by the interpretation I but assumed to be fixed for
the ontology language (DL).
The interpretation function I is extended to complex roles and concepts via DLconstructors as follows:
(>)I
(C u D)I
(R.C)I
(C)I
(r )I

=
=
=
=
=


C I  DI
{x  I | y.hx, yi  RI  y  C I }
I \ C I
{hx, yi | hy, xi  rI }

(> n R)I = { x  I | ]{y  I | hx, yi  RI }  n }
(> n R.C)I = { x  I | ]{y  I | hx, yi  RI  y  C I }  n }
{a}I = {aI }
The satisfaction relation I |=  between an interpretation I and a DL axiom  (read as I
satisfies , or I is a model of ) is defined as follows:
I |= C1 v C2 iff C1I  C2I ;
I |= R1 v R2 iff R1I  R2I ;

I |= a : C iff aI  C I ;
I |= r(a, b) iff haI , bI i  rI ;

I |= Trans(r) iff x, y, z  I [ hx, yi  rI  hy, zi  rI  hx, zi  rI ];
I |= Funct(R) iff x, y, z  I [ hx, yi  RI  hx, zi  RI  y = z ];
An interpretation I is a model of an ontology O if I satisfies all axioms in O. An
ontology O implies an axiom  (written O |= ) if I |=  for every model I of O. Given
a set I of interpretations, we say that an axiom  (an ontology O) is valid in I if every
interpretation I  I is a model of  (respectively O). An axiom  is a tautology if it is valid
in the set of all interpretations (or, equivalently, is implied by the empty ontology).
We say that two interpretations I = (I , I ) and J = (J , J ) coincide on the subset
S of the signature (notation: I|S = J |S ) if I = J and X I = X J for every X  S. We
say that two sets of interpretations I and J are equal modulo S (notation: I|S = J|S ) if for
every I  I there exits J  J such that J |S = I|S and for every J  J there exists I  I
such that I|S = J |S .
277

fiCuenca Grau, Horrocks, Kazakov, & Sattler

Ontology of medical research projects P:
P1

Genetic Disorder Project  Project u has Focus.Genetic Disorder

P2

Cystic Fibrosis EUProject  EUProject u has Focus.Cystic Fibrosis

P3

EUProject v Project

P4

has Focus.> v Project

E1

Project u (Genetic Disorder ::
u Cystic Fibrosis) v 

E2

 has Focus.Cystic Fibrosis v has Focus.Genetic Disorder

::

Ontology of medical terms Q:
M1 Cystic Fibrosis  Fibrosis u located In.Pancreas u has Origin.Genetic Origin
M2 Genetic Fibrosis  Fibrosis u has Origin.Genetic Origin
M3 Fibrosis u located In.Pancreas v Genetic Fibrosis
M4 Genetic Fibrosis v Genetic Disorder
M5 DEFBI Gene v Immuno Protein Gene u associated With.Cystic Fibrosis
Figure 1: Reusing medical terminology in an ontology on research projects

3. Ontology Integration and Knowledge Reuse
In this section, we elaborate on the ontology reuse scenario sketched in Section 1. Based on
this application scenario, we motivate and define the reasoning tasks to be investigated in
the remainder of the paper. In particular, our tasks are based on the notions of a conservative
extension (Section 3.2), safety (Sections 3.2 and 3.3) and module (Section 3.4). These notions
are defined relative to a language L. Within this section, we assume that L is an ontology
language based on a description logic; in Section 3.6, we will define formally the class of
ontology languages for which the given definitions of conservative extensions, safety and
modules apply. For the convenience of the reader, all the tasks we consider in this paper
are summarized in Table 2.
3.1 A Motivating Example
Suppose that an ontology engineer is in charge of a SHOIQ ontology on research projects,
which specifies different types of projects according to the research topic they are concerned
with. Assume that the ontology engineer defines two conceptsGenetic Disorder Project and
Cystic Fibrosis EUProjectin his ontology P. The first one describes projects about genetic
disorders; the second one describes European projects about cystic fibrosis, as given by the
axioms P1 and P2 in Figure 1. The ontology engineer is an expert on research projects: he
knows, for example, that every instance of EUProject must be an instance of Project (the
concept-inclusion axiom P3) and that the role has Focus can be applied only to instances
of Project (the domain axiom P4). He may be unfamiliar, however, with most of the topics
the projects cover and, in particular, with the terms Cystic Fibrosis and Genetic Disorder
mentioned in P1 and P2. In order to complete the projects ontology with suitable definitions
278

fiModular Reuse of Ontologies: Theory and Practice

for these medical terms, he decides to reuse the knowledge about these subjects from a wellestablished and widely-used medical ontology.
Suppose that Cystic Fibrosis and Genetic Disorder are described in an ontology Q containing the axioms M1-M5 in Figure 1. The most straightforward way to reuse these concepts
is to import in P the ontology Qthat is, to add the axioms from Q to the axioms in P
and work with the extended ontology P  Q. Importing additional axioms into an ontology
may result in new logical consequences. For example, it is easy to see that axioms M1M4
in Q imply that every instance of Cystic Fibrosis is an instance of Genetic Disorder:
Q |=  := (Cystic Fibrosis v Genetic Disorder)

(1)

Indeed, the concept inclusion 1 := (Cystic Fibrosis v Genetic Fibrosis) follows from axioms
M1 and M2 as well as from axioms M1 and M3;  follows from axioms 1 and M4.
Using inclusion  from (1) and axioms P1P3 from ontology P we can now prove that
every instance of Cystic Fibrosis EUProject is also an instance of Genetic Disorder Project:
P  Q |=  := (Cystic Fibrosis EUProject v Genetic Disorder Project)

(2)

This inclusion , however, does not follow from P alonethat is, P 6|= . The ontology
engineer might be not aware of Entailment (2), even though it concerns the terms of primary
scope in his projects ontology P.
It is natural to expect that entailments like  in (1) from an imported ontology Q result
in new logical consequences, like , in (2), over the terms defined in the main ontology P.
One would not expect, however, that the meaning of the terms defined in Q changes as a
consequence of the import since these terms are supposed to be completely specified within
Q. Such a side effect would be highly undesirable for the modeling of ontology P since the
ontology engineer of P might not be an expert on the subject of Q and is not supposed to
alter the meaning of the terms defined in Q not even implicitly.
The meaning of the reused terms, however, might change during the import, perhaps due
to modeling errors. In order to illustrate such a situation, suppose that the ontology engineer
has learned about the concepts Genetic Disorder and Cystic Fibrosis from the ontology Q
(including the inclusion (1)) and has decided to introduce additional axioms formalizing
the following statements:
Every instance of Project is different from every instance of Genetic Disorder
and
every instance of Cystic Fibrosis.
:::

(3)

::::::
Every::::::::
project that has Focus on Cystic Fibrosis, also has Focus on Genetic Disorder

(4)

Note that the statements (3) and (4) can be thought of as adding new information about
projects and, intuitively, they should not change or constrain the meaning of the medical
terms.
Suppose the ontology engineer has formalized the statements (3) and (4) in ontology
P using axioms E1 and E2 respectively. At this point, the ontology engineer has introduced modeling errors and, as a consequence, axioms E1 and E2 do not correspond to (3)
and (4): E1 actually formalizes the following statement: Every instance of Project is different from every common instance of Genetic Disorder and Cystic Fibrosis, and E2 expresses
279

fiCuenca Grau, Horrocks, Kazakov, & Sattler

that Every object that either has Focus on nothing, or has Focus only on Cystic Fibrosis,
also has Focus on Genetic Disorder. These kinds of modeling errors are difficult to detect,
especially when they do not cause inconsistencies in the ontology.
Note that, although axiom E1 does not correspond to fact (3), it is still a consequence
of (3) which means that it should not constrain the meaning of the medical terms. On the
other hand, E2 is not a consequence of (4) and, in fact, it constrains the meaning of medical
terms. Indeed, the axioms E1 and E2 together with axioms P1-P4 from P imply new axioms
about the concepts Cystic Fibrosis and Genetic Disorder, namely their disjointness:
P |=  := (Genetic Disorder u Cystic Fibrosis v )

(5)

The entailment (5) can be proved using axiom E2 which is equivalent to:
> v has Focus.(Genetic Disorder t Cystic Fibrosis)

(6)

The inclusion (6) and P4 imply that every element in the domain must be a projectthat
is, P |= (> v Project). Now, together with axiom E1, this implies (5).
The axioms E1 and E2 not only imply new statements about the medical terms, but also
cause inconsistencies when used together with the imported axioms from Q. Indeed, from
(1) and (5) we obtain P  Q |=  := (Cystic Fibrosis v ), which expresses the inconsistency
of the concept Cystic Fibrosis.
To summarize, we have seen that importing an external ontology can lead to undesirable
side effects in our knowledge reuse scenario, like the entailment of new axioms or even inconsistencies involving the reused vocabulary. In the next section we discuss how to formalize
the effects we consider undesirable.
3.2 Conservative Extensions and Safety for an Ontology
As argued in the previous section, an important requirement for the reuse of an ontology Q
within an ontology P should be that P  Q produces exactly the same logical consequences
over the vocabulary of Q as Q alone does. This requirement can be naturally formulated
using the well-known notion of a conservative extension, which has recently been investigated in the context of ontologies (Ghilardi, Lutz, & Wolter, 2006; Lutz et al., 2007).
Definition 1 (Deductive Conservative Extension). Let O and O1  O be two Lontologies, and S a signature over L. We say that O is a deductive S-conservative extension
of O1 w.r.t. L, if for every axiom  over L with Sig()  S, we have O |=  iff O1 |= .
We say that O is a deductive conservative extension of O1 w.r.t. L if O is a deductive
S-conservative extension of O1 w.r.t. L for S = Sig(O1 ).

In other words, an ontology O is a deductive S-conservative extension of O1 for a
signature S and language L if and only if every logical consequence  of O constructed
using the language L and symbols only from S, is already a logical consequence of O1 ; that
is, the additional axioms in O \ O1 do not result into new logical consequences over the
vocabulary S. Note that if O is a deductive S-conservative extension of O1 w.r.t. L, then
O is a deductive S1 -conservative extension of O1 w.r.t. L for every S1  S.
The notion of a deductive conservative extension can be directly applied to our ontology
reuse scenario.
280

fiModular Reuse of Ontologies: Theory and Practice

Definition 2 (Safety for an Ontology). Given L-ontologies O and O0 , we say that O
is safe for O0 (or O imports O0 in a safe way) w.r.t. L if O  O0 is a deductive conservative
extension of O0 w.r.t. L.

Hence, the first reasoning task relevant for our ontology reuse scenario can be formulated
as follows:
T1.

given L-ontologies O and O0 , determine if O is safe for O0 w.r.t. L.

We have shown in Section 3.1 that, given P consisting of axioms P1P4, E1, E2, and Q
consisting of axioms M1M5 from Figure 1, there exists an axiom  = (Cystic Fibrosis v )
that uses only symbols in Sig(Q) such that Q 6|=  but P  Q |= . According to Definition 1,
this means that P  Q is not a deductive conservative extension of Q w.r.t. any language
L in which  can be expressed (e.g. L = ALC). It is possible, however, to show that if the
axiom E2 is removed from P then for the resulting ontology P1 = P \ {E2}, P1  Q is a
deductive conservative extension of Q. The following notion is useful for proving deductive
conservative extensions:
Definition 3 (Model Conservative Extension, Lutz et al., 2007).
Let O and O1  O be two L-ontologies and S a signature over L. We say that O is a model
S-conservative extension of O1 , if for every model I of O1 , there exists a model J of O
such that I|S = J |S . We say that O is a model conservative extension of O1 if O is a model
S-conservative extension of O1 for S = Sig(O1 ).

The notion of model conservative extension in Definition 3 can be seen as a semantic
counterpart for the notion of deductive conservative extension in Definition 1: the latter is
defined in terms of logical entailment, whereas the former is defined in terms of models.
Intuitively, an ontology O is a model S-conservative extension of O1 if for every model of
O1 one can find a model of O over the same domain which interprets the symbols from S
in the same way. The notion of model conservative extension, however, does not provide
a complete characterization of deductive conservative extensions, as given in Definition 1;
that is, this notion can be used for proving that an ontology is a deductive conservative
extension of another, but not vice versa:
Proposition 4 (Model vs. Deductive Conservative Extensions, Lutz et al., 2007)
1. For every two L-ontologies O, O1  O, and a signature S over L, if O is a model
S-conservative extension of O1 then O is a deductive S-conservative extension of O1
w.r.t. L;
2. There exist two ALC ontologies O and O1  O such that O is a deductive conservative
extension of O1 w.r.t. ALC, but O is not a model conservative extension of O1 .
Example 5 Consider an ontology P1 consisting of axioms P1P4, and E1 and an ontology
Q consisting of axioms M1M5 from Figure 1. We demonstrate that P1  Q is a deductive
conservative extension of Q. According to proposition 4, it is sufficient to show that P1  Q
is a model conservative extension of Q; that is, for every model I of Q there exists a model
J of P1  Q such that I|S = J |S for S = Sig(Q).
281

fiCuenca Grau, Horrocks, Kazakov, & Sattler

The required model J can be constructed from I as follows: take J to be identical to I except for the interpretations of the atomic concepts Genetic Disorder Project,
Cystic Fibrosis EUProject, Project, EUProject and the atomic role has Focus, all of which
we interpret in J as the empty set. It is easy to check that all the axioms P1P4, E1 are
satisfied in J and hence J |= P1 . Moreover, since the interpretation of the symbols in Q
remains unchanged, we have I|Sig(Q) = J |Sig(Q) and J |= Q. Hence, P1  Q is a model
conservative extension of Q.
For an example of Statement 2 of the Proposition, we refer the interested reader to the
literature (Lutz et al., 2007, p. 455).

3.3 Safety of an Ontology for a Signature
So far, in our ontology reuse scenario we have assumed that the reused ontology Q is fixed
and the axioms of Q are just copied into P during the import. In practice, however, it
is often convenient to keep Q separate from P and make its axioms available on demand
via a reference. This makes it possible to continue developing P and Q independently. For
example, the ontology engineers of the project ontology P may not be willing to depend
on a particular version of Q, or may even decide at a later time to reuse the medical terms
(Cystic Fibrosis and Genetic Disorder) from another medical ontology instead. Therefore, for
many application scenarios it is important to develop a stronger safety condition for P
which depends as little as possible on the particular ontology Q to be reused. In order to
formulate such condition, we abstract from the particular ontology Q to be imported and
focus instead on the symbols from Q that are to be reused:
Definition 6 (Safety for a Signature). Let O be a L-ontology and S a signature over L.
We say that O is safe for S w.r.t. L, if for every L-ontology O0 with Sig(O)  Sig(O0 )  S,
we have that O is safe for O0 w.r.t. L; that is, O  O0 is a deductive conservative extension
of O0 w.r.t. L.

Intuitively, in our knowledge reuse scenario, an ontology O is safe for a signature S w.r.t.
a language L if and only if it imports in a safe way any ontology O0 written in L that shares
only symbols from S with O. The associated reasoning problem is then formulated in the
following way:
T2.

given an L-ontology O and a signature S over L,
determine if O is safe for S w.r.t. L.

As seen in Section 3.2, the ontology P consisting of axioms P1P4, E1, E2 from Figure 1,
does not import Q consisting of axioms M1M5 from Figure 1 in a safe way for L = ALC.
According to Definition 6, since Sig(P)  Sig(Q)  S = {Cystic Fibrosis, Genetic Disorder},
the ontology P is not safe for S w.r.t. L.
In fact, it is possible to show a stronger result, namely, that any ontology O containing
axiom E2 is not safe for S = {Cystic Fibrosis, Genetic Disorder} w.r.t. L = ALC. Consider an
ontology O0 = {1 , 2 }, where 1 = (> v Cystic Fibrosis) and 2 = (Genetic Disorder v ).
Since E2 is equivalent to axiom (6), it is easy to see that O  O0 is inconsistent. Indeed E2,
1 and 2 imply the contradiction  = (> v ), which is not entailed by O0 . Hence, O  O0
is not a deductive conservative extension of O0 . By Definition 6, since Sig(O)  Sig(O0 )  S,
this means that O is not safe for S.
282

fiModular Reuse of Ontologies: Theory and Practice

It is clear how one could prove that an ontology O is not safe for a signature S: simply find
an ontology O0 with Sig(O)  Sig(O0 )  S, such that O  O0 is not a deductive conservative
extension of O0 . It is not so clear, however, how one could prove that O is safe for S. It
turns out that the notion of model conservative extensions can also be used for this purpose.
The following lemma introduces a property which relates the notion of model conservative
extension with the notion of safety for a signature. Intuitively, it says that the notion of
model conservative extension is stable under expansion with new axioms provided they
share only symbols from S with the original ontologies.
Lemma 7 Let O, O1  O, and O0 be L-ontologies and S a signature over L such that
O is a model S-conservative extension of O1 and Sig(O)  Sig(O0 )  S. Then O  O0 is a
model S0 -conservative extension of O1  O0 for S0 = S  Sig(O0 ).
Proof. In order to show that OO0 is a model S0 -conservative extension of O1 O0 according
to Definition 3, let I be a model of O1  O0 . We just construct a model J of O  O0 such
that I|S0 = J |S0 .
(])
Since O is a model S-conservative extension of O1 , and I is a model of O1 , by Definition 3
there exists a model J1 of O such that I|S = J1 |S . Let J be an interpretation such
that J |Sig(O) = J1 |Sig(O) and J |S0 = I|S0 . Since Sig(O)  S0 = Sig(O)  (S  Sig(O0 )) 
S  (Sig(O)  Sig(O0 ))  S and I|S = J1 |S , such interpretation J always exists. Since
J |Sig(O) = J1 |Sig(O) and J1 |= O, we have J |= O; since J |S0 = I|S0 , Sig(O0 )  S0 , and
I |= O0 , we have J |= O0 . Hence J |= O  O0 and I|S0 = J |S0 , which proves (]).
Lemma 7 allows us to identify a condition sufficient to ensure the safety of an ontology
for a signature:
Proposition 8 (Safety for a Signature vs. Model Conservative Extensions)
Let O be an L-ontology and S a signature over L such that O is a model S-conservative
extension of the empty ontology O1 = ; that is, for every interpretation I there exists a
model J of O such that J |S = I|S . Then O is safe for S w.r.t. L.
Proof. In order to prove that O is safe for S w.r.t. L according to Definition 6, take any
SHOIQ ontology O0 such that Sig(O)  Sig(O0 )  S. We need to demonstrate that O  O0
is a deductive conservative extension of O0 w.r.t. L.
(])
Indeed, by Lemma 7, since O is a model S-conservative extension of O1 = , and
Sig(O)Sig(O0 )  S, we have that OO0 is a model S0 -conservative extension of O1 O0 = O0
for S0 = S  Sig(O0 ). In particular, since Sig(O0 )  S0 , we have that O  O0 is a deductive
conservative extension of O0 , as was required to prove (]).
Example 9 Let P1 be the ontology consisting of axioms P1P4, and E1 from Figure 1.
We show that P1 is safe for S = {Cystic Fibrosis, Genetic Disorder} w.r.t. L = SHOIQ. By
Proposition 8, in order to prove safety for P1 it is sufficient to demonstrate that P1 is a
model S-conservative extension of the empty ontology, that is, for every S-interpretation I
there exists a model J of P1 such that I|S = J |S .
Consider the model J obtained from I as in Example 5. As shown in Example 5, J is
a model of P1 and I|Sig(Q) = J |Sig(Q) where Q consists of axioms M1M5 from Figure 1.
In particular, since S  Sig(Q), we have I|S = J |S .

283

fiCuenca Grau, Horrocks, Kazakov, & Sattler

3.4 Extraction of Modules from Ontologies
In our example from Figure 1 the medical ontology Q is very small. Well established medical
ontologies, however, can be very large and may describe subject matters in which the designer of P is not interested. For example, the medical ontology Q could contain information
about genes, anatomy, surgical techniques, etc.
Even if P imports Q without changing the meaning of the reused symbols, processing
that is, browsing, reasoning over, etcthe resulting ontology P  Q may be considerably
harder than processing P alone. Ideally, one would like to extract a (hopefully small) fragment Q1 of the external medical ontologya modulethat describes just the concepts that
are reused in P.
Intuitively, when answering an arbitrary query over the signature of P, importing the
module Q1 should give exactly the same answers as if the whole ontology Q had been
imported.
Definition 10 (Module for an Ontology). Let O, O0 and O10  O0 be L-ontologies.
We say that O10 is a module for O in O0 w.r.t. L, if O  O0 is a deductive S-conservative
extension of O  O10 for S = Sig(O) w.r.t. L.

The task of extracting modules from imported ontologies in our ontology reuse scenario
can be thus formulated as follows:
T3.

given L-ontologies O, O0 ,
compute a module O10 for O in O0 w.r.t. L.

Example 11 Consider the ontology P1 consisting of axioms P1P4, E1 and the ontology Q
consisting of axioms M1M5 from Figure 1. Recall that the axiom  from (1) is a consequence of axioms M1, M2 and M4 as well as of axioms M1, M3 and M4 from ontology Q.
In fact, these sets of axioms are actually minimal subsets of Q that imply . In particular,
for the subset Q0 of Q consisting of axioms M2, M3, M4 and M5, we have Q0 6|= . It can
be demonstrated that P1  Q0 is a deductive conservative extension of Q0 . In particular
P1  Q0 6|= . But then, according to Definition 10, Q0 is not a module for P1 in Q w.r.t.
L = ALC or its extensions, since P1  Q is not an deductive S-conservative extension of
P1  Q0 w.r.t. L = ALC for S = Sig(P1 ). Indeed, P1  Q |= , Sig()  S but P1  Q0 6|= .
Similarly, one can show that any subset of Q that does not imply  is not a module in Q
w.r.t. P1 .
On the other hand, it is possible to show that both subsets Q1 = {M1, M2, M4} and
Q2 = {M1, M3, M4} of Q are modules for P1 in Q w.r.t. L = SHOIQ. To do so, Definition 10, we need to demonstrate that P1  Q is a deductive S-conservative extension of
both P1  Q1 and P1  Q2 for S = Sig(P1 ) w.r.t. L. As usual, we demonstrate a stronger
fact, that P1  Q is a model S-conservative extension of P1  Q1 and of P1  Q2 for S which
is sufficient by Claim 1 of Proposition 4.
In order to show that P1  Q is a model S-conservative extension of P1  Q1 for S =
Sig(P1 ), consider any model I of P1  Q1 . We need to construct a model J of P1  Q
such that I|S = J |S . Let J be defined exactly as I except that the interpretations of the
atomic concepts Fibrosis, Pancreas, Genetic Fibrosis, and Genetic Origin are defined as the
interpretation of Cystic Fibrosis in I, and the interpretations of atomic roles located In and
284

fiModular Reuse of Ontologies: Theory and Practice

has Origin are defined as the identity relation. It is easy to see that axioms M1M3 and M5
are satisfied in J . Since we do not modify the interpretation of the symbols in P1 , J also
satisfies all axioms from P1 . Moreover, J is a model of M4, because Genetic Fibrosis and
Genetic Disorder are interpreted in J like Cystic Fibrosis and Genetic Disorder in I, and I is
a model of Q1 , which implies the concept inclusion  = (Cystic Fibrosis v Genetic Disorder).
Hence we have constructed a model J of P1  Q such that I|S = J |S , thus P1  Q is a
model S-conservative extension of P1  Q1 .
In fact, the construction above works if we replace Q1 with any subset of Q that implies
. In particular, P1  Q is also a model S-conservative extension of P1  Q2 . In this way, we
have demonstrated that the modules for P in Q are exactly those subsets of Q that imply
.

An algorithm implementing the task T3 can be used for extracting a module from an
ontology Q imported into P prior to performing reasoning over the terms in P. However,
when the ontology P is modified, the module has to be extracted again since a module Q1
for P in Q might not necessarily be a module for the modified ontology. Since the extraction
of modules is potentially an expensive operation, it would be more convenient to extract a
module only once and reuse it for any version of the ontology P that reuses the specified
symbols from Q. This idea motivates the following definition:
Definition 12 (Module for a Signature). Let O0 and O10  O0 be L-ontologies and S
a signature over L. We say that O10 is a module for S in O0 (or an S-module in O0 ) w.r.t.
L, if for every L-ontology O with Sig(O)  Sig(O0 )  S, we have that O10 is a module for O
in O0 w.r.t. L.

Intuitively, the notion of a module for a signature is a uniform analog of the notion of a
module for an ontology, in a similar way as the notion of safety for a signature is a uniform
analog of safety for an ontology. The reasoning task corresponding to Definition 12 can be
formulated as follows:
T4.

given a L-ontology O0 and a signature S over L,
compute a module O10 for S in O0 .

Continuing Example 11, it is possible to demonstrate that any subset of Q that implies
axiom , is in fact a module for S = {Cystic Fibrosis, Genetic Disorder} in Q, that is, it can
be imported instead of Q into every ontology O that shares with Q only symbols from S. In
order to prove this, we use the following sufficient condition based on the notion of model
conservative extension:
Proposition 13 (Modules for a Signature vs. Model Conservative Extensions)
Let O0 and O10  O0 be L-ontologies and S a signature over L such that O0 is a model
S-conservative extension of O10 . Then O10 is a module for S in O0 w.r.t. L.
Proof. In order to prove that O10 is a module for S in O0 w.r.t. L according to Definition 12,
take any SHOIQ ontology O such that Sig(O)  Sig(O0 )  S. We need to demonstrate
that O10 is a module for O in O0 w.r.t. L, that is, according to Definition 10, O  O0 is a
deductive S0 -conservative extension of O  O10 w.r.t. L for S0 = Sig(O).
(])
285

fiCuenca Grau, Horrocks, Kazakov, & Sattler

Indeed, by Lemma 7, since O0 is a model S-conservative extension of O10 , and Sig(O0 ) 
Sig(O)  S, we have that O0  O is a model S00 -conservative extension of O10  O for
S00 = S  Sig(O). In particular, since S0 = Sig(O)  S00 , we have that O0  O is a deductive
S0 -conservative extension of O10  O w.r.t. L, as was required to prove (]).
Example 14 Let Q and  be as in Example 11. We demonstrate that any subset Q1 of Q
which implies  is a module for S = {Cystic Fibrosis, Genetic Disorder} in Q. According to
Proposition 13, it is sufficient to demonstrate that Q is a model S-conservative extension of
Q1 , that is, for every model I of Q1 there exists a model J of Q such that I|S = J |S . It is
easy to see that if the model J is constructed from I as in Example 11, then the required
property holds.

Note that a module for a signature S in Q does not necessarily contain all the axioms that
contain symbols from S. For example, the module Q1 consisting of the axiom M1, M2 and
M4 from Q does not contain axiom M5 which mentions the atomic concept Cystic Fibrosis
from S. Also note that even in a minimal module like Q1 there might still be some axioms
like M2 that do not mention symbols from S at all.
3.5 Minimal Modules and Essential Axioms
One is usually not interested in extracting arbitrary modules from a reused ontology, but
in extracting modules that are easy to process afterwards. Ideally, the extracted modules
should be as small as possible. Hence it is reasonable to consider the problem of extracting
minimal modules; that is, modules that contain no other module as a subset.
Examples 11 and 14 demonstrate that a minimal module for an ontology or a signature
is not necessarily unique: the ontology Q consisting of axioms M1M5 has two minimal modules Q1 = {M1, M2, M4}, and Q2 = {M1, M3, M4}, for the ontology P1 = {P1, P2, P3, E1}
as well as for the signature S = {Cystic Fibrosis, Genetic Disorder}, since these are the minimal sets of axioms that imply axiom  = (Cystic Fibrosis v Genetic Disorder). Depending
on the application scenario, one can consider several variations of tasks T3 and T4 for computing minimal modules. In some applications it might be necessary to extract all minimal
modules, whereas in others any minimal module suffices.
Axioms that do not occur in a minimal module in Q are not essential for P because
they can always be removed from every module of Q, thus they never need not be imported
into P. This is not true for the axioms that occur in minimal modules of Q. It might be
necessary to import such axioms into P in order not to lose essential information from Q.
These arguments motivate the following notion:
Definition 15 (Essential Axiom). Let O and O0 be L-ontologies, S a signature and 
an axiom over L. We say that  is essential for O in O0 w.r.t. L if  is contained in any
minimal module in O0 for O w.r.t. L. We say that  is an essential axiom for S in O0 w.r.t.
L (or S-essential in O0 ) if  is contained in some minimal module for S in O0 w.r.t. L. 
In our example above the axioms M1M4 from Q are essential for the ontology P1 and
for the signature S = {Cystic Fibrosis, Genetic Disorder}, but the axiom M5 is not essential.
In certain situations one might be interested in computing the set of essential axioms of
an ontology, which can be done by computing the union of all minimal modules. Note that
286

fiModular Reuse of Ontologies: Theory and Practice

Notation

Input

Task

Checking Safety:
T1

O, O0 , L

Check if O is safe for O0 w.r.t. L

T2

O, S, L

Check if O is safe for S w.r.t. L

Extracting of [all / some / union of] [minimal] module(s):
T3[a,s,u][m]

O, O0 , L

Extract modules in O0 w.r.t. O and L

T4[a,s,u][m]

O0 , S, L

Extract modules for S in O0 w.r.t. L

where O, O0 are ontologies and S a signature over L
Table 2: Summary of reasoning tasks relevant for ontology integration and reuse
computing the union of minimal modules might be easier than computing all the minimal
modules since one does not need to identify which axiom belongs to which minimal module.
In Table 2 we have summarized the reasoning tasks we found to be potentially relevant
for ontology reuse scenarios and have included the variants T3am, T3sm, and T3um of the
task T3 and T4am, T4sm, and T4um of the task T4 for computation of minimal modules
discussed in this section.
Further variants of the tasks T3 and T4 could be considered relevant to ontology reuse.
For example, instead of computing minimal modules, one might be interested in computing
modules with the smallest number of axioms, or modules of the smallest size measured in
the number of symbols, or in any other complexity measure of the ontology. The theoretical
results that we will present in this paper can easily be extended to many such reasoning
tasks.
3.6 Safety and Modules for General Ontology Languages
All the notions introduced in Section 3 are defined with respect to an ontology language.
So far, however, we have implicitly assumed that the ontology languages are the description
logics defined in Section 2that is, the fragments of the DL SHOIQ. The notions considered in Section 3 can be applied, however, to a much broader class of ontology languages.
Our definitions apply to any ontology language with a notion of entailment of axioms from
ontologies, and a mechanism for identifying their signatures.
Definition 16. An ontology language is a tuple L = (Sg, Ax, Sig, |=), where Sg is a set
of signature elements (or vocabulary) of L, Ax is a set of axioms in L, Sig is a function
that assigns to every axiom   Ax a finite set Sig()  Sg called the signature of , and
|= is the entailment relation between sets of axioms O  Ax and axioms   Ax, written
O |= . An ontology over L is a finiteSset of axioms O  Ax. We extend the function Sig
to ontologies O as follows: Sig(O) := O Sig().

Definition 16 provides a very general notion of an ontology language. A language L is
given by a set of symbols (a signature), a set of formulae (axioms) that can be constructed
over those symbols, a function that assigns to each formula its signature, and an entailment
relation between sets of axioms. The ontology language OWL DL as well as all description
287

fiCuenca Grau, Horrocks, Kazakov, & Sattler

logics defined in Section 2 are examples of ontology languages in accordance to Definition 16.
Other examples of ontology languages are First Order Logic, Second Order Logic, and Logic
Programs.
It is easy to see that the notions of deductive conservative extension (Definition 1), safety
(Definitions 2 and 6) and modules (Definitions 10 and 12), as well as all the reasoning tasks
from Table 2, are well-defined for every ontology language L given by Definition 16. The
definition of model conservative extension (Definition 3) and the propositions involving
model conservative extensions (Propositions 4, 8, and 13) can be also extended to other
languages with a standard Tarski model-theoretic semantics, such as Higher Order Logic.
To simplify the presentation, however, we will not formulate general requirements on the
semantics of ontology languages, and assume that we deal with sublanguages of SHOIQ
whenever semantics is taken into account.
In the remainder of this section, we establish the relationships between the different
notions of safety and modules for arbitrary ontology languages.
Proposition 17 (Safety vs. Modules for an Ontology) Let L be an ontology language,
and let O, O0 , and O10  O0 be ontologies over L. Then:
1. O0 is safe for O w.r.t. L iff the empty ontology is a module for O in O0 w.r.t. L.
2. If O0 \ O10 is safe for O  O10 then O10 is a module for O in O0 w.r.t. L.
Proof. 1. By Definition 2, O0 is safe for O w.r.t. L iff (a) O  O0 is a deductive conservative
extension of O w.r.t. L. By Definition 10, the empty ontology O00 =  is a module for O in
O0 w.r.t. L iff (b) O  O0 is a deductive S-conservative extension of O  O00 = O w.r.t. L
for S = Sig(O). It is easy to see that (a) is the same as (b).
2. By Definition 2, O0 \ O10 is safe for O  O10 w.r.t. L iff (c) O  O10  (O0 \ O10 ) = O  O0
is a deductive conservative extension of O  O10 w.r.t. L. In particular, O  O0 is a deductive
S-conservative extension of O  O10 w.r.t. L for S = Sig(O), which implies, by Definition 10,
that O10 is a module for O in O0 w.r.t. L.
We also provide the analog of Proposition 17 for the notions of safety and modules for
a signature:
Proposition 18 (Safety vs. Modules for a Signature) Let L be an ontology language,
O0 and O10  O0 , ontologies over L, and S a subset of the signature of L. Then:
1. O0 is safe for S w.r.t. L iff the empty ontology O00 =  is an S-module in O0 w.r.t. L.
2. If O0 \ O10 is safe for S  Sig(O10 ) w.r.t. L, then O10 is an S-module in O0 w.r.t. L.
Proof. 1. By Definition 6, O0 is safe for S w.r.t. L iff (a) for every O with Sig(O0 )  Sig(O) 
S, it is the case that O0 is safe for O w.r.t. L. By Definition 12, O00 =  is an S-module
in O0 w.r.t. L iff (b) for every O with Sig(O0 )  Sig(O)  S, it is the case that O00 =  is
a module for O in O0 w.r.t. L. By Claim 1 of Proposition 17, it is easy to see that (a) is
equivalent to (b).
2. By Definition 6, O0 \ O10 is safe for S  Sig(O10 ) w.r.t. L iff (c) for every O, with
Sig(O0 \ O10 )  Sig(O)  S  Sig(O10 ), we have that O0 \ O10 is safe for O w.r.t. L. By
288

fiModular Reuse of Ontologies: Theory and Practice

Definition 12, O10 is an S-module in O0 w.r.t. L iff (d) for every O with Sig(O0 )Sig(O)  S,
we have that O10 is a module for O in O0 w.r.t. L.
In order to prove that (c) implies (d), let O be such that Sig(O0 )  Sig(O)  S. We need
to demonstrate that O10 is a module for O in O0 w.r.t. L.
(?)
0
0
0
0
0
0
Let O := O  O1 . Note that Sig(O \ O1 )  Sig(O) = Sig(O \ O1 )  (Sig(O)  Sig(O1 )) 
(Sig(O0 \ O10 )  Sig(O))  Sig(O10 )  S  Sig(O10 ). Hence, by (c) we have that O0 \ O10 is safe
for O = O  O10 w.r.t. L which implies by Claim 2 of Proposition 17 that O10 is a module
for O in O0 w.r.t. L (?).

4. Undecidability and Complexity Results
In this section we study the computational properties of the tasks in Table 2 for ontology
languages that correspond to fragments of the description logic SHOIQ. We demonstrate
that most of these reasoning tasks are algorithmically unsolvable even for relatively inexpressive DLs, and are computationally hard for simple DLs.
Since the notions of modules and safety are defined in Section 3 using the notion of
deductive conservative extension, it is reasonable to identify which (un)decidability and
complexity results for conservative extensions are applicable to the reasoning tasks in Table 2. The computational properties of conservative extensions have recently been studied
in the context of description logics. Given O1  O over a language L, the problem of
deciding whether O is a deductive conservative extension of O1 w.r.t. L is 2-EXPTIMEcomplete for L = ALC (Ghilardi et al., 2006). This result was extended by Lutz et al.
(2007), who showed that the problem is 2-EXPTIME-complete for L = ALCIQ and undecidable for L = ALCIQO. Recently, the problem has also been studied for simple DLs; it
has been shown that deciding deductive conservative extensions is EXPTIME-complete for
L = EL(Lutz & Wolter, 2007). These results can be immediately applied to the notions of
safety and modules for an ontology:
Proposition 19 Given ontologies O and O0 over L, the problem of determining whether
O is safe for O0 w.r.t. L is EXPTIME-complete for L = EL, 2-EXPTIME-complete for
L = ALC and L = ALCIQ, and undecidable for L = ALCIQO. Given ontologies O, O0 ,
and O10  O0 over L, the problem of determining whether O10 is a module for O in O0 is
EXPTIME-complete for L = EL, 2-EXPTIME complete for L = ALC and L = ALCIQ,
and undecidable for L = ALCIQO.
Proof. By Definition 2, an ontology O is safe for O0 w.r.t. L iff O  O0 is a deductive
conservative extension of O0 w.r.t. L. By Definition 2, an ontology O10 is a module for O in
O0 w.r.t. L if O  O0 is a deductive S-conservative extension of O  O10 for S = Sig(O) w.r.t.
L. Hence, any algorithm for checking deductive conservative extensions can be reused for
checking safety and modules.
Conversely, we demonstrate that any algorithm for checking safety or modules can be
used for checking deductive conservative extensions. Indeed, O is a deductive conservative
extension of O1  O w.r.t. L iff O\O1 is safe for O1 w.r.t. L iff, by Claim 1 of Proposition 17,
O0 =  is a module for O1 in O \ O1 w.r.t. L .

289

fiCuenca Grau, Horrocks, Kazakov, & Sattler

Corollary 20 There exist algorithms performing tasks T1, and T3[a,s,u]m from Table 2
for L = EL and L = ALCIQ that run in EXPTIME and 2-EXPTIME respectively. There
is no algorithm performing tasks T1, or T3[a,s,u]m from Table 2 for L = ALCIQO.
Proof. The task T1 corresponds directly to the problem of checking the safety of an ontology,
as given in Definition 2.
Suppose that we have a 2-EXPTIME algorithm that, given ontologies O, O0 and O10 
0
O , determines whether O10 is a module for O in O0 w.r.t. L = ALCIQ. We demonstrate
that this algorithm can be used to solve the reasoning tasks T3am, T3sm and T3um for
L = ALCIQ in 2-EXPTIME. Indeed, given ontologies O and O0 , one can enumerate all
subsets of O0 and check in 2-EXPTIME which of these subsets are modules for O in O0
w.r.t. L. Then we can determine which of these modules are minimal and return all of them,
one of them, or the union of them depending on the reasoning task.
Finally, we prove that solving any of the reasoning tasks T3am, T3sm and T3um is not
easier than checking the safety of an ontology. Indeed, by Claim 1 of Proposition 17, an
ontology O is safe for O0 w.r.t. L iff O0 =  is a module for O0 in O w.r.t. L. Note that
the empty ontology O0 =  is a module for O0 in O w.r.t. L iff O0 =  is the only minimal
module for O0 in O w.r.t. L.
We have demonstrated that the reasoning tasks T1 and T3[a,s,u]m are computationally
unsolvable for DLs that are as expressive as ALCQIO, and are 2-EXPTIME-hard for ALC.
In the remainder of this section, we focus on the computational properties of the reasoning
tasks T2 and T4[a,s,u]m related to the notions of safety and modules for a signature. We
demonstrate that all of these reasoning tasks are undecidable for DLs that are as expressive
as ALCO.
Theorem 21 (Undecidability of Safety for a Signature) The problem of checking
whether an ontology O consisting of a single ALC-axiom is safe for a signature S is undecidable w.r.t. L = ALCO.
Proof. The proof is a variation of the construction for undecidability of deductive conservative extensions in ALCQIO (Lutz et al., 2007), based on a reduction to a domino tiling
problem.
A domino system is a triple D = (T, H, V ) where T = {1, . . . , k} is a finite set of tiles
and H, V  T  T are horizontal and vertical matching relations. A solution for a domino
system D is a mapping ti,j that assigns to every pair of integers i, j  1 an element of T ,
such that hti,j , ti,j+1 i  H and hti,j , ti+1,j i  V . A periodic solution for a domino system
D is a solution ti,j for which there exist integers m  1 , n  1 called periods such that
ti+m,j = ti,j and ti,j+n = ti,j for every i, j  1.
Let D be the set of all domino systems, Ds be the subset of D that admit a solution and
Dps be the subset of Ds that admit a periodic solution. It is well-known (Borger, Gradel,
& Gurevich, 1997, Theorem 3.1.7) that the sets D \ Ds and Dps are recursively inseparable,
that is, there is no recursive (i.e. decidable) subset D0  D of domino systems such that
Dps  D0  Ds .
We use this property in our reduction. For each domino system D, we construct a
signature S = S(D), and an ontology O = O(D) which consists of a single ALC-axiom such
that:
290

fiModular Reuse of Ontologies: Theory and Practice

(q1 )

> v A1 t    t Ak

where T = {1, . . . , k}

(q2 )

At u At0 v 
F
At v rH .( ht,t0 iH At0 )
F
At v rV .( ht,t0 iV At0 )

1  t < t0  k

(q3 )
(q4 )

1tk
1tk

Figure 2: An ontology Otile = Otile (D) expressing tiling conditions for a domino system D
(a) if D does not have a solution then O = O(D) is safe for S = S(D) w.r.t. L = ALCO,
and
(b) if D has a periodic solution then O = O(D) is not safe for S = S(D) w.r.t. L = ALCO.
In other words, for the set D0 consisting of the domino systems D such that O = O(D)
is not safe for S = S(D) w.r.t. L = ALCO, we have Dps  D0  Ds . Since D \ Ds and Dps
are recursively inseparable, this implies undecidability for D0 and hence for the problem of
checking if O is S-safe w.r.t. L = ALCO, because otherwise one can use this problem for
deciding membership in D0 .
The signature S = S(D), and the ontology O = O(D) are constructed as follows. Given
a domino system D = (T, H, V ), let S consist of fresh atomic concepts At for every t  T and
two atomic roles rH and rV . Consider an ontology Otile in Figure 2 constructed for D. Note
that Sig(Otile ) = S. The axioms of Otile express the tiling conditions for a domino system
D, namely (q1 ) and (q2 ) express that every domain element is assigned with a unique tile
t  T ; (q3 ) and (q4 ) express that every domain element has horizontal and vertical matching
successors.
Now let s be an atomic role and B an atomic concept such that s, B 
/ S. Let O := {}
where:
i
hF
 := > v s.
(Ci vDi )Otile (Ci u Di ) t (rH .rV .B u rV .rH .B)
We say that rH and rV commute in an interpretation I = (I , I ) if for all domain
elements a, b, c, d1 and d2 from I such that ha, bi  rH I , hb, d1 i  rV I , ha, ci  rV I , and
hc, d2 i  rH I , we have d1 = d2 . The following claims can be easily proved:
Claim 1.

If Otile (D) has a model I in which rH and rV commute, then D has a solution.

Indeed a model I = (, I ) of Otile (D) can be used to guide the construction of a solution
ti,j for D as follows. For every i, j  1, we construct ti,j inductively together with elements
ai,j  I such that hai,j , ai,j+1 i  rV I and hai,j , ai+1,j i  rH I . We set a1,1 to any element
from I .
Now suppose ai,j with i, j  1 is constructed. Since I is a model of axioms (q1 ) and
(q2 ) from Figure 2, we have a unique At with 1  t  k such that ai,j  At I . Then we set
ti,j := t. Since I is a model of axioms (q3 ) and (q4 ) and ai,j  At I there exist b, c  I
and t0 , t00  T such that hai,j , bi  rH I , hai,j , ci  rV I , ht, t0 i  H, ht, t00 i  V , b  At0 I ,
and c  At00 I . In this case we assign ai,j+1 := b, ai+1,j := c, ti,j+1 := t0 , and ti+1,j := t00 .
Note that some values of ai,j and ti,j can be assigned two times: ai+1,j+1 and ti+1,j+1 are
constructed for ai,j+1 and ai,j+1 . However, since rV and rH commute in I, the value for
291

fiCuenca Grau, Horrocks, Kazakov, & Sattler

ai+1,j+1 is unique, and because of (q2 ), the value for ti+1,j+1 is unique. It is easy to see that
ti,j is a solution for D.
Claim 2.

If I is a model of Otile  O, then rH and rV do not commute in I.

Indeed, it is easy to see that Otile  O |= (> v s.[rH .rV .B u rV .rH .B]). Hence, if
I = (I , I ) is a model of Otile  O, then there exist a, b, c, d1 and d2 such that hx, ai  sI
for every x  I , ha, bi  rH I , hb, d1 i  rV I , d1  B I , ha, ci  rV I , hc, d2 i  rH I , and
d2  (B)I . This implies that d1 6= d2 , and so, rh and rV do not commute in I.
Finally, we demonstrate that O = O(D) satisfies properties (a) and (b).
In order to prove property (a) we use the sufficient condition for safety given in Proposition 8 and demonstrate that if D has no solution then for every interpretation I there
exists a model J of O such that J |S = I|S . By Proposition 8, this will imply that O is safe
for S w.r.t. L.
Let I be an arbitrary interpretation. Since D has no solution, then by the contra-positive
of Claim 1 either (1) I is not a model of Otile , or (2) rH and rV do not commute in I. We
demonstrate for both of these cases how to construct the required model J of O such that
J |S = I|S .
Case (1). If I = (I , I ) is not a model of Otile then there exists an axiom (Ci v Di ) 
Otile such that I 6|= (Ci v Di ). That is, there exists a domain element a  I such that
a  CiI but a 6 DiI . Let us define J to be identical to I except for the interpretation of the
atomic role s which we define in J as sJ = {hx, ai | x  }. Since the interpretations of
the symbols in S have remained unchanged, we have a  CiJ , a  DiJ , and so J |= (> v
s.[Ci u Dj ]). This implies that J |= , and so, we have constructed a model J of O such
that J |S = I|S .
Case (2). Suppose that rH and rV do not commute in I = (I , I ). This means that
there exist domain elements a, b, c, d1 and d2 from I with ha, bi  rH I , hb, d1 i  rV I ,
ha, ci  rV I , and hc, d2 i  rH I , such that d1 6= d2 . Let us define J to be identical to I except
for the interpretation of the atomic role s and the atomic concept B. We interpret s in J as
sJ = {hx, ai | x  }. We interpret B in J as B J = {d1 }. Note that a  (rH .rV .B)J and
a  (rV .rH .B)J since d1 6= d2 . So, we have J |= (> v s.[rH .rV .B u rV .rH .B])
which implies that J |= , and thus, we have constructed a model J of O such that
J |S = I|S .
In order to prove property (b), assume that D has a periodic solution ti,j with the
periods m, n  1. We demonstrate that O is not S-safe w.r.t. L. For this purpose we
construct an ALCO-ontology O0 with Sig(O)  Sig(O0 )  S such that O  O0 |= (> v ),
but O0 6|= (> v ). This will imply that O is not safe for O0 w.r.t. L = ALCO, and, hence,
is not safe for S w.r.t. L = ALCO.
We define O0 such that every model of O0 is a finite encoding of the periodic solution ti,j
with the periods m and n. For every pair (i, j) with 1  i  m and 1  j  n we introduce
a fresh individual ai,j and define O0 to be an extension of Otile with the following axioms:
(p1 ) {ai1 ,j } v rV .{ai2 ,j }

(p2 ) {ai1 ,j } v rV .{ai2 ,j },

i2 = i1 + 1

mod m

(p3 ) {ai,j1 } v rH .{ai,j2 }

(p4 ) {ai,j1 } v rH .{ai,j2 },
j2 = j1 + 1
F
(p5 ) > v 1im, 1jn {ai,j }

mod n

292

fiModular Reuse of Ontologies: Theory and Practice

The purpose of axioms (p1 )(p5 ) is to ensure that rH and rV commute in every model of
O0 . It is easy to see that O0 has a model corresponding to every periodic solution for D with
periods m and n. Hence O0 6|= (> v ). On the other hand, by Claim 2, since O0 contains
Otile , then in every model of O0  O, rH and rV do not commute. This is only possible if
O0  O have no models, so O0  O |= (> v ).
A direct consequence of Theorem 21 and Proposition 18 is the undecidability of the
problem of checking whether a subset of an ontology is a module for a signature:
Corollary 22 Given a signature S and ALC-ontologies O0 and O10  O0 , the problem of
determining whether O10 is an S-module in O0 w.r.t. L = ALCO is undecidable.
Proof. By Claim 1 of Proposition 18, O is S-safe w.r.t. L if O0 =  is an S-module in O
w.r.t. L. Hence any algorithm for recognizing modules for a signature in L can be used for
checking if an ontology is safe for a signature in L.
Corollary 23 There is no algorithm that can perform tasks T2, or T4[a,s,u]m for L =
ALCO.
Proof. Theorem 21 directly implies that there is no algorithm for task T2, since this task
corresponds to the problem of checking safety for a signature.
Solving any of the reasoning tasks T4am, T4sm, or T4um for L is at least as hard as
checking the safety of an ontology, since, by Claim 1 of Proposition 18, an ontology O is
S-safe w.r.t. L iff O0 =  is (the only minimal) S-module in O w.r.t. L.

5. Sufficient Conditions for Safety
Theorem 21 establishes the undecidability of checking whether an ontology expressed in
OWL DL is safe w.r.t. a signature. This undecidability result is discouraging and leaves
us with two alternatives: First, we could focus on simple DLs for which this problem is
decidable. Alternatively, we could look for sufficient conditions for the notion of safety
that is, if an ontology satisfies our conditions, then we can guarantee that it is safe; the
converse, however, does not necessarily hold.
The remainder of this paper focuses on the latter approach. Before we go any further,
however, it is worth noting that Theorem 21 still leaves room for investigating the former
approach. Indeed, safety may still be decidable for weaker description logics, such as EL,
or even for very expressive logics such as SHIQ. In the case of SHIQ, however, existing
results (Lutz et al., 2007) strongly indicate that checking safety is likely to be exponentially
harder than reasoning and practical algorithms may be hard to design. This said, in what
follows we will focus on defining sufficient conditions for safety that we can use in practice
and restrict ourselves to OWL DLthat is, SHOIQontologies.
5.1 Safety Classes
In general, any sufficient condition for safety can be defined by giving, for each signature
S, the set of ontologies over a language that satisfy the condition for that signature. These
ontologies are then guaranteed to be safe for the signature under consideration. These
intuitions lead to the notion of a safety class.
293

fiCuenca Grau, Horrocks, Kazakov, & Sattler

Definition 24 (Class of Ontologies, Safety Class). A class of ontologies for a language
L is a function O() that assigns to every subset S of the signature of L, a subset O(S)
of ontologies in L. A class O() is anti-monotonic if S1  S2 implies O(S2 )  O(S1 ); it is
compact when O  O(S  Sig(O)) for each O  O(S); and it is subset-closed if O1  O2
and O2  O(S) implies O1  O(S); it is union-closed if O1  O(S) and O2  O(S) implies
(O1  O2 )  O(S).
A safety class (also called a sufficient condition to safety) for an ontology language L
is a class of ontologies O() for L such that for each S it is the case that (i)   O(S), and
(ii) each ontology O  O(S) is S-safe for L.

Intuitively, a class of ontologies is a collection of sets of ontologies parameterized by a
signature. A safety class represents a sufficient condition for safety: each ontology in O(S)
should be safe for S. Also, w.l.o.g., we assume that the the empty ontology  belongs to
every safety class for every signature. In what follows, whenever an ontology O belongs to
a safety class for a given signature and the safety class is clear from the context, we will
sometimes say that O passes the safety test for S.
Safety classes may admit many natural properties, as given in Definition 24. Antimonotonicity intuitively means that if an ontology O can be proved to be safe w.r.t. S
using the sufficient condition, then O can be proved to be safe w.r.t. every subset of S.
Compactness means that it is sufficient to consider only common elements of Sig(O) and S
for checking safety. Subset-closure (union closure) means that if O (O1 and O2 ) satisfy the
sufficient condition for safety, then every subset of O (the union of O1 and O2 ) also satisfies
this condition.
5.2 Locality
In this section we introduce a family of safety classes for L = SHOIQ that is based on the
semantic properties underlying the notion of model conservative extensions. In Section 3,
we have seen that, according to Proposition 8, one way to prove that O is S-safe is to show
that O is a model S-conservative extension of the empty ontology.
The following definition formalizes the classes of ontologies, called local ontologies, for
which safety can be proved using Proposition 8.
Definition 25 (Class of Interpretations, Locality). Given a SHOIQ signature S,
we say that a set of interpretations I is local w.r.t. S if for every SHOIQ-interpretation I
there exists an interpretation J  I such that I|S = J |S .
A class of interpretations is a function I() that given a SHOIQ signature S returns a set
of interpretations I(S); it is local if I(S) is local w.r.t. S for every S; it is monotonic if S1  S2
implies I(S1 )  I(S2 ); it is compact if for every S1 , S2 and S such that (S1 M S2 )  S = 
we have that I(S1 )|S = I(S2 )|S , where S1 M S2 is the symmetric difference of sets S1 and
S2 defined by S1 M S2 := S1 \ S2  S2 \ S1 .
Given a class of interpretations I(), we say that O() is the class of ontologies O() based
on I() if for every S, O(S) is the set of ontologies that are valid in I(S); if I() is local then
we say that O() is a class of local ontologies, and for every S and O  O(S) and every
  O, we say that O and  are local (based on I()).


294

fiModular Reuse of Ontologies: Theory and Practice

r
Example 26 Let IA
() be a class of SHOIQ interpretations defined as follows. Given a
r
signature S, the set IA (S) consists of interpretations J such that rJ =  for every atomic
r
role r 
/ S and AJ =  for every atomic concept A 
/ S. It is easy to show that IA
(S)
I
I
is local for every S, since for every interpretation I = ( ,  ) and the interpretation
J = (J , J ) defined by J := I , rJ =  for r 
/ S, AJ =  for A 
/ S, and X J := X I
r
r
r
for the remaining symbols X, then J  IA (S) and I|S = J |S . Since IA
(S1 )  IA
(S2 )
r
r
for every S1  S2 , it is the case that IA () is monotonic; IA () is also compact, since for
r
r
(S2 ) are defined differently
(S1 ) and IA
every S1 and S2 the sets of interpretations IA
only for elements in S1 M S2 .
r
r
Given a signature S, the set AxA
(S) of axioms that are local w.r.t. S based on IA
(S)
r
consists of all axioms  such for every J  IA (S), it is the case that J |= . Then the
r
r
r
(S).
(S) iff O  AxA
() is defined by O  OA
class of local ontologies based on IA


Proposition 27 (Locality Implies Safety) Let O() be a class of ontologies for SHOIQ
based on a local class of interpretations I(). Then O() is a subset-closed and union-closed
safety class for L = SHOIQ. Additionally, if I() is monotonic, then O() is anti-monotonic,
and if I() is compact then O() is also compact.
Proof. Assume that O() is a class of ontologies based on I(). Then by Definition 25 for
every SHOIQ signature S, we have O  O(S) iff O is valid in I(S) iff J |= O for every
interpretation J  I(S). Since I() is a local class of interpretations, we have that for
every SHOIQ-interpretation I there exists J  I(S) such that J |S = I|S . Hence for
every O  I(S) and every SHOIQ interpretation I there is a model J  I(S) such that
J |S = I|S , which implies by Proposition 8 that O is safe for S w.r.t. L = SHOIQ. Thus
O() is a safety class.
The fact that O() is subset-closed and union-closed follows directly from Definition 25
since (O1  O2 )  O(S) iff (O1  O2 ) is valid in I(S) iff O1 and O2 are valid in I(S) iff
O1  O(S) and O2  O(S). If I() is monotonic then I(S1 )  I(S2 ) for every S1  S2 , and
so O  O(S2 ) implies that O is valid in I(S2 ) which implies that O is valid in I(S1 ) which
implies that O  O(S1 ). Hence O() is anti-monotonic.
If I() is compact then for every S1 , S2 and S such that (S1 M S2 )  S =  we have
that I(S1 )|S = I(S2 )|S , hence for every O with Sig(O)  S we have that O is valid in
I(S1 ) iff O is valid in I(S2 ), and so, O  O(S1 ) iff O  O(S2 ). In particular, O  O(S) iff
O  O(S  Sig(O)) since (S M (S  Sig(O)))  Sig(O) = (S \ Sig(O))  Sig(O) = . Hence,
O() is compact.
r
Corollary 28 The class of ontologies OA
(S) defined in Example 26 is an anti-monotonic
compact subset-closed and union-closed safety class.

Example 29 Recall that in Example 5 from Section 3, we demonstrated that the ontology
P1  Q given in Figure 1 with P1 = {P1, . . . , P4, E1} is a deductive conservative extension
of Q for S = {Cystic Fibrosis, Genetic Disorder}. This has been done by showing that every
S-interpretation I can be expanded to a model J of axioms P1P4, E1 by interpreting
the symbols in Sig(P1 ) \ S as the empty set. In terms of Example 26 this means that
295

fiCuenca Grau, Horrocks, Kazakov, & Sattler

r
r
P1  OA
(S). Since OA
() is a class of local ontologies, by Proposition 27, the ontology
P1 is safe for S w.r.t. L = SHOIQ.


Proposition 27 and Example 29 suggest a particular way of proving the safety of ontologies. Given a SHOIQ ontology O and a signature S it is sufficient to check whether
r
(S); that is, whether every axiom  in O is satisfied by every interpretation from
O  OA
r
IA (S). If this property holds, then O must be safe for S according to Proposition 27.
It turns out that this notion provides a powerful sufficiency test for safety which works
surprisingly well for many real-world ontologies, as will be shown in Section 8. In the next
section we discuss how to perform this test in practice.
5.3 Testing Locality
r
In this section, we focus in more detail on the safety class OA
(), introduced in Example 26. When ambiguity does not arise, we refer to this safety class simply as locality.2
r
From the definition of AxA
(S) given in Example 26 it is easy to see that an axiom  is
r
local w.r.t. S (based on IA (S)) if  is satisfied in every interpretation that fixes the interpretation of all atomic roles and concepts outside S to the empty set. Note that for defining
locality we do not fix the interpretation of the individuals outside S, but in principle, this
could be done. The reason is that there is no elegant way to describe such interpretations.
Namely, every individual needs to be interpreted as an element of the domain, and there is
no canonical element of every domain to choose.
In order to test the locality of  w.r.t. S, it is sufficient to interpret every atomic concept
and atomic role not in S as the empty set and then check if  is satisfied in all interpretations
of the remaining symbols. This observation suggests the following test for locality:

Proposition 30 (Testing Locality) Given a SHOIQ signature S, concept C, axiom 
and ontology O let  (C, S),  (, S) and  (O, S) be defined recursively as follows:
 (C, S) ::=

 (>, S)
|  (A, S)
|  ({a}, S)
|  (C1 u C2 , S)
|  (C1 , S)
|  (R.C1 , S)
|  (> n R.C 1 , S)

= >;
=  if A 
/ S and otherwise = A;
= {a};
=  (C1 , S) u  (C2 , S);
=  (C1 , S);
=  if Sig(R) * S and otherwise = R. (C1 , S);
=  if Sig(R) * S and otherwise = (> n R. (C1 , S)).

 (C1 v C2 , S) = ( (C1 , S) v  (C2 , S));
|  (R1 v R2 , S) = ( v ) if Sig(R1 ) * S, otherwise
= R1 .> v  if Sig(R2 ) * S, otherwise = (R1 v R2 );
|  (a : C, S)
= a :  (C, S);
|  (r(a, b), S)
= > v  if r 
/ S and otherwise = r(a, b);
|  (Trans(r), S) =  v  if r 
/ S and otherwise = Trans(r);
|  (Funct(R), S) =  v  if Sig(R) * S and otherwise = Funct(R).
S
 (O, S) ::=
O  (, S)
 (, S) ::=

2. This notion of locality is exactly the one we used in our previous work (Cuenca Grau et al., 2007).

296

(a)
(b)
(c)
(d)
(e)
(f )
(g)
(h)
(i)
(j)
(k)
(l)
(m)
(n)

fiModular Reuse of Ontologies: Theory and Practice

r
Then, O  OA
(S) iff every axiom in  (O, S) is a tautology.

Proof. It is easy to check that for every atomic concept A and atomic role r from  (C, S),
we have A  S and r  S, in other words, all atomic concepts and roles that are not in S
are eliminated by the transformation.3 It is also easy to show by induction that for every
r
interpretation I  IA
(S), we have C I = ( (C, S))I and that I |=  iff I |=  (, S). Hence
r
an axiom  is local w.r.t. S iff I |=  for every interpretation I  IA
(S) iff I |=  (, S)
r
for every Sig()-interpretation I  IA (S) iff  (, S) is a tautology.
Example 31 Let O = {} be the ontology consisting of axiom  = M2 from Figure 1. We
demonstrate using Proposition 30 that O is local w.r.t. S1 = {Fibrosis, Genetic Origin}, but
not local w.r.t. S2 = {Genetic Fibrosis, has Origin}.
Indeed, according to Proposition 30, in order to check whether O is local w.r.t. S1 it is
sufficient to perform the following replacements in  (the symbols from S1 are underlined):

M2

 [by (f)]
 [by (b)]
}|
{
z
}|
{
z
Genetic Fibrosis  Fibrosis u has Origin.Genetic Origin

(7)

Similarly, in order to check whether O is local w.r.t. S2 , it is sufficient to perform the
following replacements in  (the symbols from S2 are underlined):
 [by (b)]
 [by (b)]
}|
{
z }| {
z
M2 Genetic Fibrosis  Fibrosis u has Origin.Genetic Origin

(8)

In the first case we obtain  (M2, S1 ) = (  Fibrosis u ) which is a SHOIQ-tautology.
Hence O is local w.r.t. S1 and hence by Proposition 8 is S1 -safe w.r.t. SHOIQ. In the
second case  (M2, S2 ) = (Genetic Fibrosis   u has Origin.) which is not a SHOIQ
tautology, hence O is not local w.r.t. S2 .

5.4 A Tractable Approximation to Locality
One of the important conclusions of Proposition 30 is that one can use the standard capabilities of available DL-reasoners such as FaCT++ (Tsarkov & Horrocks, 2006), RACER
(Moller & Haarslev, 2003), Pellet (Sirin & Parsia, 2004) or KAON2 (Motik, 2006) for testing
locality since these reasoners, among other things, allow testing for DL-tautologies. Checking for tautologies in description logics is, theoretically, a difficult problem (e.g. for the
DL SHOIQ it is known to be NEXPTIME-complete, Tobies, 2000). There are, however,
several reasons to believe that the locality test would perform well in practice. The primary
reason is that the sizes of the axioms which need to be tested for tautologies are usually
relatively small compared to the sizes of ontologies. Secondly, modern DL reasoners are
highly optimized for standard reasoning tasks and behave well for most realistic ontologies.
In case reasoning is too costly, it is possible to formulate a tractable approximation to the
locality conditions for SHOIQ:
3. Recall that the constructors , C1 t C2 , R.C, and (6 n R.C) are assumed to be expressed using >,
C1 u C2 , R.C and (> n R.C), hence, in particular, every role R with Sig(R ) * S occurs in O as either
R .C, (> n R .C), R v R, R v R , Trans(R ), or Funct(R ), and hence will be eliminated. All atomic
concepts A 
/ S will be eliminated likewise. Note that it is not necessarily the case that Sig( (, S))  S,
since  (, S) may still contain individuals that do not occur in S.

297

fiCuenca Grau, Horrocks, Kazakov, & Sattler

Definition 32 (Syntactic Locality for SHOIQ). Let S be a signature. The following
grammar recursively defines two sets of concepts Con(S) and Con(S) for a signature S:
Con(S) ::= A | C  | C u C  | C  u C | R .C | R.C  | (> n R .C) | (> n R.C  ) .
Con(S) ::= > | C  | C1 u C2 .
where A 
/ S is an atomic concept, R (possibly the inverse of) an atomic role r 
/ S, C
  Con(S), and i  {1, 2}.
any concept, R any role, C   Con(S), C(i)
An axiom  is syntactically local w.r.t. S if it is of one of the following forms: (1) R v R,
or (2) Trans(r ), or (3) Funct(R ), or (4) C  v C, or (5) C v C  , or (6) a : C  . We denote
r
by AxA
(S) the set of all SHOIQ-axioms that are syntactically local w.r.t. S.
r
A SHOIQ-ontology O is syntactically local w.r.t. S if O  AxA
(S). We denote by
r
OA (S) the set of all SHOIQ ontologies that are syntactically local w.r.t. S.

Intuitively, syntactic locality provides a simple syntactic test to ensure that an axiom is
r
satisfied in every interpretation from IA
(S). It is easy to see from the inductive definitions


of Con (S) and Con (S) in Definition 32 that for every interpretation I = (I , I ) from
r
IA
(S) it is the case that (C  )I =  and (C  )I = I for every C   Con(S) and

C  Con(S). Hence, every syntactically local axiom is satisfied in every interpretation
r
I from IA
(S), and so we obtain the following conclusion:
r
r
Proposition 33 AxA
(S)  AxA
(S).

Further, it can be shown that the safety class for SHOIQ based on syntactic locality
enjoys all of the properties from Definition 24:
r
Proposition 34 The class of syntactically local ontologies OA
() given in Definition 32
is an anti-monotonic, compact, subset-closed, and union-closed safety class.
r
r
() is a safety class by Proposition 33. Anti-monotonicity for OA
() can
Proof. OA



be shown by induction, by proving that Con (S2 )  Con (S1 ), Con (S2 )  Con(S1 )
r
r
and AxA
(S2 )  AxA
(S1 ) when S1  S2 . Also one can show by induction that
r
r
r
r


  AxA (S) iff   AxA (S  Sig()), so OA
() is compact. Since O  OA
(S)
r
r

iff O  AxA (S), we have that OA () is subset-closed and union-closed.

Example 35 (Example 31 continued) It is easy to see that axiom M2 from Figure 1 is
syntactically local w.r.t. S1 = {Fibrosis, Genetic Origin}. Below we indicate sub-concepts in
 from Con(S1 ):

M2

 Con(S1 ) [matches A ]
 Con(S1 ) [matches R .C]
z
}|
{
z
}|
{
Genetic Fibrosis  Fibrosis u has Origin.Genetic Origin
(9)
|
{z
}
 Con(S1 ) [matches C u C  ]

It is easy to show in a similar way that axioms P1 P4, and E1 from Figure 1 are syntactically local w.r.t. S = {Cystic Fibrosis, Genetic Disorder}. Hence the ontology P1 =
{P1, . . . , P4, E1} considered in Example 29 is syntactically local w.r.t. S.

298

fiModular Reuse of Ontologies: Theory and Practice

r (S)
IA

r, A 6 S :

r
IA
(S)
r
IA
(S)
rid (S)
IA

rJ

AJ

r (S)
IA





r
IA
(S)



r
IA
(S)



rid (S)
IA

J  J
{hx, xi | x  J }

r, A 6 S :

rJ

AJ



J

J  J
{hx, xi | x  J }

J
J

Table 3: Examples for Different Local Classes of Interpretations
The converse of Proposition 33 does not hold in general since there are semantically
local axioms that are not syntactically local. For example, the axiom  = (A v A t B) is
local w.r.t. every S since it is a tautology (and hence true in every interpretation). On the
other hand, it is easy to see that  is not syntactically local w.r.t. S = {A, B} according to
Definition 32 since it involves symbols in S only. Another example, which is not a tautology,
is a GCI  = (r.A v r.B). The axiom  is semantically local w.r.t. S = {r}, since
 (, S) = (r. v r.) is a tautology, but not syntactically local. These examples show
that the limitation of our syntactic notion of locality is its inability to compare different
occurrences of concepts from the given signature S. As a result, syntactic locality does not
detect all tautological axioms. It is reasonable to assume, however, that tautological axioms
do not occur often in realistic ontologies. Furthermore, syntactic locality checking can be
performed in polynomial time by matching an axiom according to Definition 32.
Proposition 36 There exists an algorithm that given a SHOIQ ontology O and a sigr
nature S, determines whether O  OA
(S), and whose running time is polynomial in
|O| + |S|, where |O| and |S| are the number of symbols occurring in O and S respectively.4
5.5 Other Locality Classes
r
The locality condition given in Example 26 based on a class of local interpretations IA
()
is just a particular example of locality which can be used for testing safety. Other classes
of local interpretations can be constructed in a similar way by fixing the interpretations
of elements outside S to different values. In Table 3 we have listed several such classes of
local interpretations where we fix the interpretation of atomic roles outside S to be either
the empty set , the universal relation   , or the identity relation id on , and the
interpretation of atomic concepts outside S to either the empty set  or the set  of all
elements.
Each local class of interpretations in Table 3 defines a corresponding class of local
ontologies analogously to Example 26. In Table 4 we have listed all of these classes together
with examples of typical types of axioms used in ontologies. These axioms are assumed
to be an extension of our project ontology from Figure 1. We indicate which axioms are
local w.r.t. S for which locality conditions assuming, as usual, that the symbols from S are
underlined.
It can be seen from Table 4 that different types of locality conditions are appropriate
r
for different types of axioms. The locality condition based on IA
(S) captures the domain
axiom P4, definition P5, the disjointness axiom P6, and the functionality axiom P7 but

4. We assume that the numbers in number restrictions are written down using binary coding.

299

fiCuenca Grau, Horrocks, Kazakov, & Sattler

r
A

r
A

rid
A

r
A

r
A

rid
A

3

7

7

3

3

3

3

3

3

7

7

7

P6 Project u Bio Medicine v 

3

3

3

7

7

7

P7 Funct(has Focus)

3

7

3

3

7

3

P8 Human Genome : Project

7

7

7

3

3

3

P9 has Focus(Human Genome, Gene)

7

3

7

7

3

7

7

7

7

7

7

7



?   Ax

Axiom

P4 has Focus.> v Project
P5

E2

BioMedical Project  Project u
u has Focus.Bio Medicine

has Focus.Cystic Fibrosis v
v has Focus.Cystic Fibrosis

Table 4: A Comparison between Different Types of Locality Conditions

neither of the assertions P8 or P9, since the individuals Human Genome and Gene prevent
us from interpreting the atomic role has Focus and atomic concept Project with the empty
r
(S), where the atomic roles and concepts outside
set. The locality condition based on IA
S are interpreted as the largest possible sets, can capture such assertions but are generally
poor for other types of axioms. For example, the functionality axiom P7 is not captured
by this locality condition since the atomic role has Focus is interpreted as the universal
relation , which is not necessarily functional. In order to capture such functionality
rid (S) or I rid (S), where every atomic role outside
axioms, one can use locality based on IA
A
S is interpreted with the identity relation id on the interpretation domain. Note that the
modeling error E2 is not local for any of the given locality conditions. Note also that it is
not possible to come up with a locality condition that captures all the axioms P4P9, since
in P6 and P8 together imply axiom  = ({Human Genome} u Bio Medicine v ) which
uses the symbols from S only. Hence, every subset of P containing P6 and P8 is not safe
w.r.t. S, and so cannot be local w.r.t. S.
It might be possible to come up with algorithms for testing locality conditions for the
classes of interpretation in Table 3 similar to the ones presented in Proposition 30. For
r
example, locality based on the class IA
(S) can be tested as in Proposition 30, where the
case (a) of the definition for  (C, S) is replaced with the following:
 (A, S)

= > if A 
/ S and otherwise = A

(a0 )

r
rid (S), checking
For the remaining classes of interpretations, that is for IA
(S) and IA
locality, however, is not that straightforward, since it is not clear how to eliminate the
universal roles and identity roles from the axioms and preserve validity in the respective
classes of interpretations.
Still, it is easy to come up with tractable syntactic approximations for all the locality
conditions considered in this section in a similar manner to what has been done in Section 5.4. The idea is the same as that used in Definition 32, namely to define two sets
Con(S) and Con(S) of concepts for a signature S which are interpreted as the empty

300

fiModular Reuse of Ontologies: Theory and Practice

Con(S) ::= C  | C u C  | C  u C

Con(S) ::= > | C  | C1 u C2

| R.C  | > n R.C 

r ():
for IA

| A

r ():
for IA

| A

r
for IA
():

| R .C  | (> n R .C  )

r
for IA
():

| R .C | > n R .C

rid ():
for IA

| Rid .C  | (> 1 Rid .C  ) .

rid ():
for IA

| (> m Rid .C), m  2 .

r (S) ::= C  v C | C v C  | a : C 
AxA
r
for IA
():

| R v R | Trans(r ) | Funct(R )

r
for IA
():

| R v R | Trans(r ) | r (a, b)

rid ():
for IA

| Trans(rid ) | Funct(Rid )

Where:
A , A , r , r , rid 6 S;
Sig(R ), Sig(R ), Sig(Rid ) * S;
  Con(S);
C   Con(S), C(i)
C is any concept, R is any role

Figure 3: Syntactic Locality Conditions for the Classes of Interpretations in Table 3
set and, respectively, as I in every interpretation I from the class and see in which situations DL-constructors produce the elements from these sets. In Figure 3 we gave recursive
r (S) that correspond to classes I r (S) of
definitions for syntactically local axioms AxA
A
interpretations from Table 3, where some cases in the recursive definitions are present only
for the indicated classes of interpretations.
5.6 Combining and Extending Safety Classes
In the previous section we gave examples of several safety classes based on different local
classes of interpretations and demonstrated that different classes are suitable for different
types of axioms. In order to check safety of ontologies in practice, one may try to apply
different sufficient tests and check if any of them succeeds. Obviously, this gives a more
powerful sufficient condition for safety, which can be seen as the union of the safety classes
used in the tests.
Formally, given two classes of ontologies O1 () and O2 (), their union (O1  O2 )() is a
class of ontologies defined by (O1 O2 )(S) = O1 (S)O2 (S). It is easy to see by Definition 24
that if both O1 () and O2 () are safety classes then their union (O1  O2 )() is a safety
class. Moreover, if each of the safety classes is also anti-monotonic or subset-closed, then
the union is anti-monotonic, or respectively, subset-closed as well. Unfortunately the unionclosure property for safety classes is not preserved under unions, as demonstrated in the
following example:
r
r
Example 37 Consider the union (OA
 OA
)() of two classes of local ontologies
r
r
OA () and OA () defined in Section 5.5. This safety class is not union-closed since,
for example, the ontology O1 consisting of axioms P4P7 from Table 4 satisfies the first
locality condition, the ontology O2 consisting of axioms P8P9 satisfies the second locality
condition, but their union O1 O2 satisfies neither the first nor the second locality condition
and, in fact, is not even safe for S as we have shown in Section 5.5.


As shown in Proposition 33, every locality condition gives a union-closed safety class;
however, as seen in Example 37, the union of such safety classes might be no longer unionclosed. One may wonder if locality classes already provide the most powerful sufficient
301

fiCuenca Grau, Horrocks, Kazakov, & Sattler

conditions for safety that satisfy all the desirable properties from Definition 24. Surprisingly
this is the case to a certain extent for some locality classes considered in Section 5.5.
Definition 38 (Maximal Union-Closed Safety Class). A safety class O2 () extends
a safety class O1 () if O1 (S)  O2 (S) for every S. A safety class O1 () is maximal unionclosed for a language L if O1 () is union-closed and for every union-closed safety class O2 ()
that extends O1 () and every O over L we have that O  O2 (S) implies O  O1 (S).

r
r
Proposition 39 The classes of local ontologies OA
() and OA
() defined in Section 5.5
are maximal union-closed safety classes for L = SHIQ.

Proof. According to Definition 38, if a safety class O() is not maximal union-closed for a
language L, then there exists a signature S and an ontology O over L, such that (i) O 
/
O(S), (ii) O is safe w.r.t. S in L, and (iii) for every P  O(S), it is the case that O  P is
safe w.r.t. S in L; that is, for every ontology Q over L with Sig(Q)  Sig(O  P)  S it is
the case that O  P  Q is a deductive conservative extension of Q. We demonstrate that
r
r
this is not possible for O() = OA
() or O() = OA
()
r
We first consider the case O() = OA () and then show how to modify the proof for
r
the case O() = OA
().
Let O be an ontology over L that satisfies conditions (i)(iii) above. We define ontologies
P and Q as follows. Take P to consist of the axioms A v  and r.> v  for every atomic
r
concept A and atomic role r from Sig(O) \ S. It is easy to see that P  OA
(S). Take Q
to consist of all tautologies of form  v A and  v r.> for every A, r  S. Note that
Sig(O  P)  Sig(Q)  S. We claim that O  P  Q is not a deductive Sig(Q)-conservative
extension of Q.
(])
r
Intuitively, the ontology P is chosen in such a way that P  OA
(S) and O  P  Q
r
has only models from IA
(S). Q is an ontology which implies nothing but tautologies and
uses all the atomic concepts and roles from S.
r
r
Since O 
/ OA
(S), there exists an axiom   O such that  
/ AxA
(S). Let
 :=  (, S) where  (, ) is defined as in Proposition 30. As has been shown in the proof of
r
this proposition, I |=  iff I |=  for every I  IA
(S). Now, since O |=  and O  P  Q
r
has only models from IA (S), it is the case that O  P  Q |= . By Proposition 30, since 
r
does not contain individuals, we have that Sig()  S = Sig(Q) and, since  
/ AxA
(S),
 is not a tautology, thus Q 6|= . Hence, by Definition 1, O  P  Q is not a deductive
Sig(Q)-conservative extension of Q (]).
r
For O() = OA
() the proof can be repeated by taking P to consist of axioms > v A
and r.> v  for all A, r  Sig(O) \ S, and modifying  (, ) as has been discussed in
Section 5.5.
There are some difficulties in extending the proof of Proposition 39 to other locality
classes considered in Section 5.5. First, it is not clear how to force interpretations of roles
to be the universal or identity relation using SHOIQ axioms. Second, it is not clear how
to define the function  (, ) in these cases (see a related discussion in Section 5.5). Note
also that the proof of Proposition 39 does not work in the presence of nominals, since
this will not guarantee that  =  (, S) contains symbols from S only (see Footnote 3 on
r
r
p. 297). Hence there is probably room to extend the locality classes OA
() and OA
()
for L = SHOIQ while preserving union-closure.
302

fiModular Reuse of Ontologies: Theory and Practice

6. Extracting Modules Using Safety Classes
In this section we revisit the problem of extracting modules from ontologies. As shown in
Corollary 23 in Section 4, there exists no general procedure that can recognize or extract
all the (minimal) modules for a signature in an ontology in finite time.
The techniques described in Section 5, however, can be reused for extracting particular
families of modules that satisfy certain sufficient conditions. Proposition 18 establishes the
relationship between the notions of safety and module; more precisely, a subset O1 of O is
an S-module in O provided that O \ O1 is safe for S  Sig(O1 ). Therefore, any safety class
O() can provide a sufficient condition for testing modulesthat is, in order to prove that
O1 is a S-module in O, it is sufficient to show that O \ O1  O(S  Sig(O1 )). A notion of
modules based on this property can be defined as follows.
Definition 40 (Modules Based on Safety Class).
Let L be an ontology language and O() be a safety class for L. Given an ontology O and
a signature S over L, we say that Om  O is an O()-based S-module in O if O \ Om 
O(S  Sig(Om )).

Remark 41 Note that for every safety class O(), ontology O and signature S, there exists
at least one O()-based S-module in O, namely O itself; indeed, by Definition 24, the empty
ontology  = O \ O also belongs to O(S) for every O() and S.
Note also that it follows from Definition 40 that Om is an O()-based S-module in O iff
Om is an O()-based S0 -module in O for every S0 with S  S0  (S  Sig(Om )).

It is clear that, according to Definition 40, any procedure for checking membership of a
safety class O() can be used directly for checking whether Om is a module based on O().
In order to extract an O()-module, it is sufficient to enumerate all possible subsets of the
ontology and check if any of these subsets is a module based on O().
In practice, however, it is possible to avoid checking all the possible subsets of the
input ontology. Figure 4 presents an optimized version of the module-extraction algorithm.
The procedure manipulates configurations of the form Om | Ou | Os , which represent a
partitioning of the ontology O into three disjoint subsets Om , Ou and Os . The set Om
accumulates the axioms of the extracted module; the set Os is intended to be safe w.r.t.
S  Sig(Om ). The set Ou , which is initialized to O, contains the unprocessed axioms. These
axioms are distributed among Om and Os according to rules R1 and R2. Given an axiom 
from Ou , rule R1 moves  into Os provided Os remains safe w.r.t. S  Sig(Om ) according
to the safety class O(). Otherwise, rule R2 moves  into Om and moves all axioms from
Os back into Ou , since Sig(Om ) might expand and axioms from Os might become no longer
safe w.r.t. S  Sig(Om ). At the end of this process, when no axioms are left in in Ou , the
set Om is an O()-based module in O.
The rewrite rules R1 and R2 preserve invariants I1I3 given in Figure 4. Invariant I1
states that the three sets Om , Ou and Os form a partitioning of O; I2 states that the set Os
satisfies the safety test for S  Sig(Om ) w.r.t. O(); finally, I3 establishes that the rewrite
rules either add elements to Om , or they add elements to Os without changing Om ; in other
words, the pair (|Om |, |Os |) consisting of the sizes for these sets increases in lexicographical
order.
303

fiCuenca Grau, Horrocks, Kazakov, & Sattler

Input:

an ontology O, a signature S, a safety class O()

Output:

a module Om in O based on O()
unprocessed


Configuration: Om | Ou | Os ;




module

safe

Initial Configuration =

|O|

Termination Condition: Ou = 

Rewrite rules:
R1. Om | Ou  {} | Os = Om | Ou | Os  {}

if (Os  {})  O(S  Sig(Om ))

R2. Om | Ou  {} | Os = Om  {} | Ou  Os | 

if (Os  {}) 6 O(S  Sig(Om ))

Invariants for Om | Ou | Os :
I1. O = Om ] Ou ] Os

0 | O0 | O0 :
Invariant for Om | Ou | Os = Om
u
s
0 |, |O 0 |)
I3. (|Om |, |Os |) <lex (|Om
s

I2. Os  O(S  Sig(Om ))
Figure 4: A Procedure for Computing Modules Based on a Safety Class O()
Proposition 42 (Correctness of the Procedure from Figure 4) Let O() be a safety
class for an ontology language L, O an ontology over L, and S a signature over L. Then:
(1) The procedure in Figure 4 with input O, S, O() terminates and returns an O()based S-module Om in O; and
(2) If, additionally, O() is anti-monotonic, subset-closed and union-closed, then there
is a unique minimal O()-based S-module in O, and the procedure returns precisely this
minimal module.
Proof. (1) The procedure based on the rewrite rules from Figure 4 always terminates for
the following reasons: (i) for every configuration derived by the rewrite rules, the sets Om ,
Ou and Os form a partitioning of O (see invariant I1 in Figure 4), and therefore the size
of every set is bounded; (ii) at each rewrite step, (|Om |, |Os |) increases in lexicographical
order (see invariant I3 in Figure 4). Additionally, if Ou 6=  then it is always possible to
apply one of the rewrite rules R1 or R2, and hence the procedure always terminates with
Ou = . Upon termination, by invariant I1 from Figure 4, O is partitioned into Om and Os
and by invariant I2, Os  O(S  Sig(Om )), which implies, by Definition 40, that Om is an
O()-based S-module in O.
(2) Now, suppose that, in addition, O() is an anti-monotonic, subset-closed, and union0 is an O()-based S-module in O. We demonstrate
closed safety class, and suppose that Om
by induction that for every configuration Om | Ou | Os derivable from  | O |  by rewrite
0 . This will prove that the module computed
rules R1 and R2, it is the case that Om  Om
by the procedure is a subset of every O()-based S-module in O, and hence, is the smallest
O()-based S-module in O.
0 . The rewrite rule R1 does not change
Indeed, for the base case we have Om =   Om
the set Om . For the rewrite rule R2 we have: Om | Ou  {} | Os = Om  {} | Ou  Os | 
if (Os  {}) 6 O(S  Sig(Om )).
(])
304

fiModular Reuse of Ontologies: Theory and Practice

Input: an ontology O, a signature S, a safety class O()
Output: a module Om in O based on O()
Initial Configuration =

|O|

Termination Condition: Ou = 

Rewrite rules:
R1.

Om | Ou  {} | Os = Om | Ou | Os  {}

if {}  O(S  Sig(Om ))

R2. Om | Ou  {} | Os  Os = Om  {} | Ou  Os | Os if {} 6 O(S  Sig(Om )), and
Sig(Os )  Sig()  Sig(Om )
Figure 5: An Optimized Procedure for Computing Modules Based on a Compact SubsetClosed Union-Closed Safety Class O()
0 but O  {} * O 0 . Then   O 0 := O \ O 0 .
Suppose, to the contrary, that Om  Om
m
m
s
m
0 is an O()-based S-module in O, we have that O 0  O(S  Sig(O 0 )). Since O()
Since Om
s
m
0 )). Since O
0
is subset-closed, {}  O(S  Sig(Om
m  Om and O() is anti-monotonic, we
have {}  O(S  Sig(Om )). Since by invariant I2 from Figure 4, Os  O(S  Sig(Om )) and
O() is union-closed, Os  {}  O(S  Sig(Om )), which contradicts (]). This contradiction
0 .
implies that the rule R2 also preserves property Om  Om

Claim (1) of Proposition 42 establishes that the procedure from Figure 4 terminates for
every input and produces a module based on a given safety class. Moreover, it is possible
to show that this procedure runs in polynomial time assuming that the safety test can be
also performed in polynomial time.
If the safety class O() satisfies additional desirable properties, like those based on classes
of local interpretations described in Section 5.2, the procedure, in fact, produces the smallest
possible module based on the safety class, as stated in claim (2) of Proposition 42. In this
case, it is possible to optimize the procedure shown in Figure 4. If O() is union closed,
then, instead of checking whether (Os  {})  O(S  Sig(Om )) in the conditions of rules
R1 and R2, it is sufficient to check if {}  O(S  Sig(Om )) since it is already known that
Os  O(S  Sig(Om )). If O() is compact and subset closed, then instead of moving all the
axioms in Os to Ou in rule R2, it is sufficient to move only those axioms Os that contain
at least one symbol from  which did not occur in Om before, since the set of remaining
axioms will stay in O(S  Sig(Om )). In Figure 5 we present an optimized version of the
algorithm from Figure 4 for such locality classes.
Example 43 In Table 5 we present a trace of the algorithm from Figure 5 for the ontology O
consisting of axioms M1M5 from Figure 1, signature S = {Cystic Fibrosis, Genetic Disorder}
r
and safety class O() = OA
() defined in Example 26. The first column of the table lists
the configurations obtained from the initial configuration  | O |  by applying the rewrite
rules R1 and R2 from Figure 5; in each row, the underlined axiom  is the one that is being
tested for safety. The second column of the table shows the elements of S  Sig(Om ) that
have appeared for the current configuration but have not been present for the preceding
configurations. In the last column we indicate whether the first conditions of the rules R1
r
and R2 are fulfilled for the selected axiom  from Ou that is, whether  is local for IA
().
The rewrite rule corresponding to the result of this test is applied to the configuration.
305

fiCuenca Grau, Horrocks, Kazakov, & Sattler

Om | Ou ,  | Os

New elements in S  Sig(Om )

1  | M1, M2, M3, M4, M5 |  Cystic Fibrosis, Genetic Disorder

{}  O(S  Sig(Om ))?
Yes



R1

2

 | M1, M3, M4, M5 | M2



Yes



R1

3

 | M1, M4, M5 | M2, M3



No



R2

4

M1 | M2, M3, M4, M5 | 

Fibrosis, located In, Pancreas,
has Origin, Genetic Origin

No



R2

5

M1, M3 | M2, M4, M5 | 

Genetic Fibrosis

No



R2

6

M1, M3, M4 | M2, M5 | 



Yes



R1

7

M1, M3, M4 | M2 | M5



No



R2

8

M1, M2, M3, M4 |  | M5



Table 5: A trace of the Procedure in Figure 5 for the input Q = {M1, . . . , M5} from Figure 1
and S = {Cystic Fibrosis, Genetic Disorder}

Note that some axioms  are tested for safety several times for different configurations,
because the set Ou may increase after applications of rule R2; for example, the axiom
 = M2 is tested for safety in both configurations 1 and 7, and  = M3 in configurations
2 and 4. Note also that different results for the locality tests are obtained in these cases:
both M2 and M3 were local w.r.t. S  Sig(Om ) when Om = , but became non-local when
new axioms were added to Om . It is also easy to see that, in our case, syntactic locality
produces the same results for the tests.
In our example, the rewrite procedure produces a module Om consisting of axioms M1
M4. Note that it is possible to apply the rewrite rules for different choices of the axiom
 in Ou , which results in a different computation. In other words, the procedure from
Figure 5 has implicit non-determinism. According to Claim (2) of Proposition 42 all such
r
computations should produce the same module Om , which is the smallest OA
()-based
S-module in O; that is, the implicit non-determinism in the procedure from Figure 5 does
not have any impact on the result of the procedure. However, alternative choices for 
may result in shorter computations: in our example we could have selected axiom M1 in
the first configuration instead of M2 which would have led to a shorter trace consisting of
configurations 1, and 48 only.

It is worth examining the connection between the S-modules in an ontology O based on
a particular safety class O() and the actual minimal S-modules in O. It turns out that any
O()-based module Om is guaranteed to cover the set of minimal modules, provided that
O() is anti-monotonic and subset-closed. In other words, given O and S, Om contains all
the S-essential axioms in O. The following Lemma provides the main technical argument
underlying this result.
Lemma 44 Let O() be an anti-monotonic subset-closed safety class for an ontology language L, O an ontology, and S a signature over L. Let O1 be an S-module in O w.r.t. L
and Om an O()-based S-module in O. Then O2 := O1  Om is an S-module in O w.r.t. L.
306

fiModular Reuse of Ontologies: Theory and Practice

Proof. By Definition 40, since Om is an O()-based S-module in O, we have that O \ Om 
O(S  Sig(Om )). Since O1 \ O2 = O1 \ Om  O \ Om and O() is subset-closed, it is the case
that O1 \ O2  O(S  Sig(Om )). Since O() is anti-monotonic, and O2  Om , we have that
O1 \ O2  O(S  Sig(O2 )), hence, O2 is an O()-based S-module in O1 . In particular O2 is
an S-module in O1 w.r.t. L. Since O1 is an S-module in O w.r.t. L, O2 is an S-module in
O w.r.t. L.
Corollary 45 Let O() be an anti-monotonic, subset-closed safety class for L and Om be
an O()-based S-module in O. Then Om contains all S-essential axioms in O w.r.t. L.
Proof. Let O1 be a minimal S-module in O w.r.t. L. We demonstrate that O1  Om . Indeed,
otherwise, by Lemma 44, O1  Om is an S-module in O w.r.t. L which is strictly contained
in O1 . Hence Om is a superset of every minimal S-module in O and hence, contains all
S-essential axioms in O w.r.t. L.
As shown in Section 3.4, all the axioms M1M4 are essential for the ontology O and
signature S considered in Example 43. We have seen in this example that the locality-based
S-module extracted from O contains all of these axioms, in accordance to Corollary 45. In
our case, the extracted module contains only essential axioms; in general, however, localitybased modules might contain non-essential axioms.
An interesting application of modules is the pruning of irrelevant axioms when checking
if an axiom  is implied by an ontology O. Indeed, in order to check whether O |= 
it suffices to retrieve the module for Sig() and verify if the implication holds w.r.t. this
module. In some cases, it is sufficient to extract a module for a subset of the signature of
 which, in general, leads to smaller modules. In particular, in order to test subsumption
between a pair of atomic concepts, if the safety class being used enjoys some nice properties
then it suffices to extract a module for one of them, as given by the following proposition:
Proposition 46 Let O() be a compact union-closed safety class for an ontology language
L, O an ontology and A, B atomic concepts. Let OA be an O()-based module in O for
S = {A} in O. Then:
1 If O |=  := (A v B) and {B v }  O() then OA |= ;
2 If O |=  := (B v A) and {> v B}  O() then OA |= ;
Proof. 1. Consider two cases: (a) B  Sig(OA ) and (b) B 
/ Sig(OA ).
(a) By Remark 41 it is the case that OA is an O()-based module in O for S = {A, B}.
Since Sig()  S, by Definition 12 and Definition 1, it is the case that O |=  implies
OA |= .
(b) Consider O0 = O {B v }. Since Sig(B v ) = {B} and B 
/ Sig(OA ), {B v } 
O() and O() is compact, by Definition 24 it is the case that {B v }  O(S  Sig(OA )).
Since OA is an O()-based S-module in O, by Definition 40, then O \ OA  O(S  Sig(OA )).
Since O() is union-closed, it is the case that (O \ OA )  {B v }  O(S  Sig(OA )). Note
that B v  6 OA , since B 6 Sig(OA ), hence (O \ OA )  {B v } = O0 \ OA , and, by
Definition 40, we have that OA is an O()-based S-module in O0 . Now, since O |= (A v B),
it is the case that O0 |= (A v ), and hence, since OA is a module in O0 for S = {A}, we
have that OA |= (A v ) which implies OA |= (A v B).
307

fiCuenca Grau, Horrocks, Kazakov, & Sattler

2. The proof of this case is analogous to that for Case 1: Case (a) is applicable without
changes; in Case (b) we show that OA is an O()-based module for S = {A} in O0 =
O  {> v B}, and, hence, since O0 |= (> v A), it is the case that OB |= (> v A), which
implies O0 |= (B v A).
r () and
Corollary 47 Let O be a SHOIQ ontology and A, B atomic concepts. Let OA
r () be locality classes based on local classes of interpretations of form I r () and
OA
A
r
r () and
IA (), respectively, from Table 3. Let OA be a module for S = {A} based on OA
r (). Then O |= (A v B) iff O |= (A v B) iff
OB be a module for S = {B} based on OA
A
OB |= (A v B).
r () and {> v A}  O r ().
Proof. It is easy to see that {B v }  OA
A

Proposition 46 implies that a module based on a safety class for a single atomic concept
A can be used for capturing either the super-concepts (Case 1), or the sub-concepts (Case
2) B of A, provided that the safety class captures, when applied to the empty signature,
axioms of the form B v  (Case 1) or (> v B) (Case 2). That is, B is a super-concept or
a sub-concept of A in the ontology if and only if it is such in the module. This property
can be used, for example, to optimize the classification of ontologies. In order to check if
the subsumption A v B holds in an ontology O, it is sufficient to extract a module in
O for S = {A} using a modularization algorithm based on a safety class in which the
ontology {B v } is local w.r.t. the empty signature, and check whether this subsumption
holds w.r.t. the module. For this purpose, it is convenient to use a syntactically tractable
approximation of the safety class in use; for example, one could use the syntactic locality
conditions given in Figure 3 instead of their semantic counterparts.
It is possible to combine modularization procedures to obtain modules that are smaller
than the ones obtained using these procedures individually. For example, in order to check
r ()-based module M for
the subsumption O |= (A v B) one could first extract a OA
1
S = {A} in O; by Corollary 47 this module is complete for all the super-concepts of A in
O, including Bthat is, if an atomic concept is a super-concept of A in O, then it is also a
r ()-based module M for S = {B} in
super-concept of A in M1 . One could extract a OA
2
M1 which, by Corollary 47, is complete for all the sub-concepts of B in M1 , including A.
Indeed, M2 is an S-module in M1 for S = {A, B} and M1 is an S-module in the original
ontology O. By Proposition 46, therefore, it is the case that M2 is also an S-module in O.

7. Related Work
We have seen in Section 3 that the notion of conservative extension is valuable in the formalization of ontology reuse tasks. The problem of deciding conservative extensions has been
recently investigated in the context of ontologies (Ghilardi et al., 2006; Lutz et al., 2007;
Lutz & Wolter, 2007). The problem of deciding whether P  Q is a deductive S-conservative
extension of Q is EXPTIME-complete for EL (Lutz & Wolter, 2007), 2-EXPTIME-complete
w.r.t. ALCIQ (Lutz et al., 2007) (roughly OWL-Lite), and undecidable w.r.t. ALCIQO
(roughly OWL DL). Furthermore, checking model conservative extensions is already undecidable for EL (Lutz & Wolter, 2007), and for ALC it is even not semi-decidable (Lutz
et al., 2007).
308

fiModular Reuse of Ontologies: Theory and Practice

In the last few years, a rapidly growing body of work has been developed under the
headings of Ontology Mapping and Alignment, Ontology Merging, Ontology Integration,
and Ontology Segmentation (Kalfoglou & Schorlemmer, 2003; Noy, 2004a, 2004b). This field
is rather diverse and has roots in several communities.
In particular, numerous techniques for extracting fragments of ontologies for the purposes of knowledge reuse have been proposed. Most of these techniques rely on syntactically
traversing the axioms in the ontology and employing various heuristics to determine which
axioms are relevant and which are not.
An example of such a procedure is the algorithm implemented in the Prompt-Factor
tool (Noy & Musen, 2003). Given a signature S and an ontology Q, the algorithm retrieves a fragment Q1  Q as follows: first, the axioms in Q that mention any of the
symbols in S are added to Q1 ; second, S is expanded with the symbols in Sig(Q1 ). These
steps are repeated until a fixpoint is reached. For our example in Section 3, when S =
{Cystic Fibrosis, Genetic Disorder}, and Q consists of axioms M1M5 from Figure 1, the algorithm first retrieves axioms M1, M4, and M5 containing these terms, then expands S with
the symbols mentioned in these axioms, such that S contains all the symbols of Q. After
this step, all the remaining axioms of Q are retrieved. Hence, the fragment extracted by
the Prompt-Factor algorithm consists of all the axioms M1-M5. In this case, the PromptFactor algorithm extracts a module (though not a minimal one). In general, however, the
extracted fragment is not guaranteed to be a module. For example, consider an ontology
Q = {A  A, B v C} and  = (C v B). The ontology Q is inconsistent due to the
axiom A  A: any axiom (and  in particular) is thus a logical consequence of Q. Given
S = {B, C}, the Prompt-Factor algorithm extracts Q2 = {B v C}; however, Q2 6|= , and
so Q2 is not a module in Q. In general, the Prompt-Factor algorithm may fail even if Q is
consistent. For example, consider an ontology Q = {> v {a}, A v B},  = (A v r.A),
and S = {A}. It is easy to see that Q is consistent, admits only single element models,
and  is satisfied in every such a model; that is, Q |= . In this case, the Prompt-Factor
algorithm extracts Q1 = {A v B}, which does not imply .
Another example is Seidenbergs segmentation algorithm (Seidenberg & Rector, 2006),
which was used for segmentation of the medical ontology GALEN (Rector & Rogers, 1999).
Currently, the full version of GALEN cannot be processed by reasoners, so the authors
investigate the possibility of splitting GALEN into small segments which can be processed
by reasoners separately. The authors describe a segmentation procedure which, given a set
of atomic concepts S, computes a segment for S in the ontology. The description of
the procedure is very high-level. The authors discuss which concepts and roles should be
included in the segment and which should not. In particular, the segment should contain
all super- and sub- concepts of the input concepts, concepts that are linked from the
input concepts (via existential restrictions) and their super-concepts, but not their subconcepts; for the included concepts, also their restrictions, intersection, union, and
equivalent concepts should be considered by including the roles and concepts they contain,
together with their super-concepts and super-roles but not their sub-concepts and
sub-roles. From the description of the procedure it is not entirely clear whether it works
with a classified ontology (which is unlikely in the case of GALEN since the full version of
GALEN has not been classified by any existing reasoner), or, otherwise, how the super-
and sub- concepts are computed. It is also not clear which axioms should be included in
309

fiCuenca Grau, Horrocks, Kazakov, & Sattler

the segment in the end, since the procedure talks only about the inclusion of concepts and
roles.
A different approach to module extraction proposed in the literature (Stuckenschmidt
& Klein, 2004) consists of partitioning the concepts in an ontology to facilitate visualization
of and navigation through an ontology. The algorithm uses a set of heuristics for measuring
the degree of dependency between the concepts in the ontology and outputs a graphical
representation of these dependencies. The algorithm is intended as a visualization technique,
and does not establish a correspondence between the nodes of the graph and sets of axioms
in the ontology.
What is common between the modularization procedures we have mentioned is the lack
of a formal treatment for the notion of module. The papers describing these modularization
procedures do not attempt to formally specify the intended outputs of the procedures, but
rather argue what should be in the modules and what not based on intuitive notions. In
particular, they do not take the semantics of the ontology languages into account. It might
be possible to formalize these algorithms and identify ontologies for which the intuitionbased modularization procedures work correctly. Such studies are beyond the scope of this
paper.
Module extraction in ontologies has also been investigated from a formal point of view
(Cuenca Grau et al., 2006b). Cuenca Grau et al. (2006) define a notion of a module QA in an
ontology Q for an atomic concept A. One of the requirements for the module is that Q should
be a conservative extension of QA (in the paper QA is called a logical module in Q). The
paper imposes an additional requirement on modules, namely that the module QA should
entail all the subsumptions in the original ontology between atomic concepts involving A and
other atomic concepts in QA . The authors present an algorithm for partitioning an ontology
into disjoint modules and proved that the algorithm is correct provided that certain safety
requirements for the input ontology hold: the ontology should be consistent, should not
contain unsatisfiable atomic concepts, and should have only safe axioms (which in our
terms means that they are local for the empty signature). In contrast, the algorithm we
present here works for any ontology, including those containing non-safe axioms.
The growing interest in the notion of modularity in ontologies has been recently
reflected in a workshop on modular ontologies5 held in conjunction with the International
Semantic Web Conference (ISWC-2006). Concerning the problem of ontology reuse, there
have been various proposals for safely combining modules; most of these proposals, such
as E-connections (Cuenca Grau, Parsia, & Sirin, 2006a), Distributed Description Logics
(Borgida & Serafini, 2003) and Package-based Description Logics (Bao, Caragea, & Honavar,
2006) propose a specialized semantics for controlling the interaction between the importing
and the imported modules to avoid side-effects. In contrast to these works, we assume here
that reuse is performed by simply building the logical union of the axioms in the modules
under the standard semantics, and we establish a collection of reasoning services, such as
safety testing, to check for side-effects. The interested reader can find in the literature a
detailed comparison between the different approaches for combining ontologies (Cuenca
Grau & Kutz, 2007).
5. for information see the homepage of the workshop http://www.cild.iastate.edu/events/womo.html

310

fiModular Reuse of Ontologies: Theory and Practice

8. Implementation and Proof of Concept
In this section, we provide empirical evidence of the appropriateness of locality for safety
testing and module extraction. For this purpose, we have implemented a syntactic locar
r
lity checker for the locality classes OA
() and OA
() as well as the algorithm for
extracting modules given in Figure 5 from Section 6.
r
First, we show that the locality class OA
() provides a powerful sufficiency test for
r
safety which works for many real-world ontologies. Second, we show that OA
()-based
modules are typically very small compared to both the size of the ontology and the modules
extracted using other techniques. Third, we report on our implementation in the ontology
editor Swoop (Kalyanpur, Parsia, Sirin, Cuenca Grau, & Hendler, 2006) and illustrate the
r
r
combination of the modularization procedures based on the classes OA
() and OA
().
8.1 Locality for Testing Safety
r
We have run our syntactic locality checker for the class OA
() over the ontologies from a
library of 300 ontologies of various sizes and complexity some of which import each other
(Gardiner, Tsarkov, & Horrocks, 2006).6 For all ontologies P that import an ontology Q,
we check if P belongs to the locality class for S = Sig(P)  Sig(Q).
It turned out that from the 96 ontologies in the library that import other ontologies, all
but 11 were syntactically local for S (and hence also semantically local for S). From the 11
non-local ontologies, 7 are written in the OWL-Full species of OWL (Patel-Schneider et al.,
2004) to which our framework does not yet apply. The remaining 4 non-localities are due
to the presence of so-called mapping axioms of the form A  B 0 , where A 
/ S and B 0  S.
Note that these axioms simply indicate that the atomic concepts A, B 0 in the two ontologies
under consideration are synonyms. Indeed, we were able to easily repair these non-localities
as follows: we replace every occurrence of A in P with B 0 and then remove this axiom from
the ontology. After this transformation, all 4 non-local ontologies turned out to be local.

8.2 Extraction of Modules
In this section, we compare three modularization7 algorithms that we have implemented
using Manchesters OWL API:8
A1: The Prompt-Factor algorithm (Noy & Musen, 2003);
A2: The segmentation algorithm proposed by Cuenca Grau et al. (2006);
r
A3: Our modularisation algorithm (Algorithm 5), based on the locality class OA
().

The aim of the experiments described in this section is not to provide a throughout comparison of the quality of existing modularization algorithms since each algorithm extracts
modules according to its own requirements, but rather to give an idea of the typical size
of the modules extracted from real ontologies by each of the algorithms.
6. The library is available at http://www.cs.man.ac.uk/~horrocks/testing/
7. In this section by module we understand the result of the considered modularization procedures which
may not necessarily be a module according to Definition 10 or 12
8. http://sourceforge.net/projects/owlapi

311

fiCuenca Grau, Horrocks, Kazakov, & Sattler

(a) Modularization
of NCI
(a)
Modularization
of NCI

(b) Modularization
Modularization of of
GALEN-Small
(b)
GALEN-Small

(c) Modularization
Modularization of SNOMED
(c)
of SNOMED

(d) Modularization
Modularization of GALEN-Full
(d)
of GALEN-Full

(e) Small
Small modules
of of
GALEN-Full
(e)
modules
GALEN-Full

(f) Large
Large modules
of of
GALEN-Full
(f)
modules
GALEN-Full

Figure 6: Distribution for the sizes of syntactic locality-based modules: the X-Axis gives the
number of concepts in the modules and the Y-Axis the number of modules extracted for
each size range.

312

fiModular Reuse of Ontologies: Theory and Practice

A2: Segmentation

A3: Loc.-based mod.

] Atomic

A1: Prompt-Factor

Concepts

Max.(%)

Avg.(%)

Max.(%)

Avg.(%)

Max.(%)

Avg.(%)

NCI

27772

87.6

75.84

55

30.8

0.8

0.08

SNOMED

255318

100

100

100

100

0.5

0.05

GO

Ontology

22357

1

0.1

1

0.1

0.4

0.05

SUMO

869

100

100

100

100

2

0.09

GALEN-Small

2749

100

100

100

100

10

1.7

GALEN-Full

24089

100

100

100

100

29.8

3.5

SWEET

1816

96.4

88.7

83.3

51.5

1.9

0.1

DOLCE-Lite

499

100

100

100

100

37.3

24.6

Table 6: Comparison of Different Modularization Algorithms

As a test suite, we have collected a set of well-known ontologies available on the Web,
which we divided into two groups:
Simple. In this group, we have included the National Cancer Institute (NCI) Ontology,9
the SUMO Upper Ontology,10 the Gene Ontology (GO),11 and the SNOMED Ontology12 .
These ontologies are expressed in a simple ontology language and are of a simple structure;
in particular, they do not contain GCIs, but only definitions.
Complex. This group contains the well-known GALEN ontology (GALEN-Full),13 the
DOLCE upper ontology (DOLCE-Lite),14 and NASAs Semantic Web for Earth and Environmental Terminology (SWEET)15 . These ontologies are complex since they use many
constructors from OWL DL and/or include a significant number of GCIs. In the case of
GALEN, we have also considered a version GALEN-Small that has commonly been used as
a benchmark for OWL reasoners. This ontology is almost 10 times smaller than the original
GALEN-Full ontology, yet similar in structure.
Since there is no benchmark for ontology modularization and only a few use cases are
available, there is no systematic way of evaluating modularization procedures. Therefore
we have designed a simple experiment setup which, even if it may not necessarily reflect
an actual ontology reuse scenario, it should give an idea of typical module sizes. For each
ontology, we took the set of its atomic concepts and extracted modules for every atomic
concept. We compare the maximal and average sizes of the extracted modules.
It is worth emphasizing here that our algorithm A3 does not just extract a module for
the input atomic concept: the extracted fragment is also a module for its whole signature,
which typically includes a fair amount of other concepts and roles.
9.
10.
11.
12.
13.
14.
15.

http://www.mindswap.org/2003/CancerOntology/nciOncology.owl
http://ontology.teknowledge.com/
http://www.geneontology.org
http://www.snomed.org
http://www.openclinical.org/prj_galen.html
http://www.loa-cnr.it/DOLCE.html
http://sweet.jpl.nasa.gov/ontology/
313

fiCuenca Grau, Horrocks, Kazakov, & Sattler

r
r
(a) Concepts DNA Sequence and (b) OA
(S)-based module for (c) OA
(S)-based module for
Microanatomy in NCI
DNA Sequence in NCI
Micro Anatomy in the fragment 7b

Figure 7: The Module Extraction Functionality in Swoop
The results we have obtained are summarized in Table 6. The table provides the size
of the largest module and the average size of the modules obtained using each of these
algorithms. In the table, we can clearly see that locality-based modules are significantly
smaller than the ones obtained using the other methods; in particular, in the case of SUMO,
DOLCE, GALEN and SNOMED, the algorithms A1 and A2 retrieve the whole ontology as
the module for each input signature. In contrast, the modules we obtain using our algorithm
are significantly smaller than the size of the input ontology.
For NCI, SNOMED, GO and SUMO, we have obtained very small locality-based modules. This can be explained by the fact that these ontologies, even if large, are simple
in structure and logical expressivity. For example, in SNOMED, the largest locality-based
module obtained is approximately 0.5% of the size of the ontology, and the average size of
the modules is 1/10 of the size of the largest module. In fact, most of the modules we have
obtained for these ontologies contain less than 40 atomic concepts.
For GALEN, SWEET and DOLCE, the locality-based modules are larger. Indeed, the
largest module in GALEN-Small is 1/10 of the size of the ontology, as opposed to 1/200
in the case of SNOMED. For DOLCE, the modules are even bigger1/3 of the size of
the ontologywhich indicates that the dependencies between the different concepts in the
ontology are very strong and complicated. The SWEET ontology is an exception: even
though the ontology uses most of the constructors available in OWL, the ontology is heavily
underspecified, which yields small modules.
In Figure 6, we have a more detailed analysis of the modules for NCI, SNOMED,
GALEN-Small and GALEN-Full. Here, the X-axis represents the size ranges of the ob314

fiModular Reuse of Ontologies: Theory and Practice

tained modules and the Y-axis the number of modules whose size is within the given range.
The plots thus give an idea of the distribution for the sizes of the different modules.
For SNOMED, NCI and GALEN-Small, we can observe that the size of the modules
follows a smooth distribution. In contrast, for GALEN-Full, we have obtained a large number
of small modules and a significant number of very big ones, but no medium-sized modules
in-between. This abrupt distribution indicates the presence of a big cycle of dependencies in
the ontology. The presence of this cycle can be spotted more clearly in Figure 6(f); the figure
shows that there is a large number of modules of size in between 6515 and 6535 concepts.
This cycle does not occur in the simplified version of GALEN and thus we obtain a smooth
distribution for that case. In contrast, in Figure 6(e) we can see that the distribution for
the small modules in GALEN-Full is smooth and much more similar to the one for the
simplified version of GALEN.
The considerable differences in the size of the modules extracted by algorithms A1 
A3 are due to the fact that these algorithms extract modules according to different requirements. Algorithm A1 produces a fragment of the ontology that contains the input atomic
concept and is syntactically separated from the rest of the axiomsthat is, the fragment
and the rest of the ontology have disjoint signatures. Algorithm A2 extracts a fragment of
the ontology that is a module for the input atomic concept and is additionally semantically
separated from the rest of the ontology: no entailment between an atomic concept in the
module and an atomic concept not in the module should hold in the original ontology. Since
our algorithm is based on weaker requirements, it is to be expected that it extracts smaller
modules. What is surprising is that the difference in the size of modules is so significant.
In order to explore the use of our results for ontology design and analysis, we have
integrated our algorithm for extracting modules in the ontology editor Swoop (Kalyanpur
et al., 2006). The user interface of Swoop allows for the selection of an input signature and
the retrieval of the corresponding module.16
Figure 7a shows the classification of the concepts DNA Sequence and Microanatomy in
r
the NCI ontology. Figure 7b shows the minimal OA
()-based module for DNA Sequence,
r
as obtained in Swoop. Recall that, according to Corollary 47, a OA
()-based module for an
atomic concept contains all necessary axioms for, at least, all its (entailed) super-concepts
in O. Thus this module can be seen as the upper ontology for A in O. In fact, Figure 7
shows that this module contains only the concepts in the path from DNA Sequence to
the top level concept Anatomy Kind. This suggests that the knowledge in NCI about the
particular concept DNA Sequence is very shallow in the sense that NCI only knows that a
DNA Sequence is a macromolecular structure, which, in the end, is an anatomy kind. If one
wants to refine the module by only including the information in the ontology necessary to
r
entail the path from DNA Sequence to Micro Anatomy, one could extract the OA
()based module for Micro Anatomy in the fragment 7b. By Corollary 47, this module contains
all the sub-concepts of Micro Anatomy in the previously extracted module. The resulting
module is shown in Figure 7b.

16. The tool can be downloaded at http://code.google.com/p/swoop/

315

fiCuenca Grau, Horrocks, Kazakov, & Sattler

9. Conclusion
In this paper, we have proposed a set of reasoning problems that are relevant for ontology
reuse. We have established the relationships between these problems and studied their computability. Using existing results (Lutz et al., 2007) and the results obtained in Section 4, we
have shown that these problems are undecidable or algorithmically unsolvable for the logic
underlying OWL DL. We have dealt with these problems by defining sufficient conditions
for a solution to exist, which can be computed in practice. We have introduced and studied
the notion of a safety class, which characterizes any sufficiency condition for safety of an
ontology w.r.t. a signature. In addition, we have used safety classes to extract modules from
ontologies.
For future work, we would like to study other approximations which can produce small
modules in complex ontologies like GALEN, and exploit modules to optimize ontology
reasoning.

References
Baader, F., Brandt, S., & Lutz, C. (2005). Pushing the EL envelope. In IJCAI-05, Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence,
Edinburgh, Scotland, UK, July 30-August 5, 2005, pp. 364370. Professional Book
Center.
Baader, F., Calvanese, D., McGuinness, D. L., Nardi, D., & Patel-Schneider, P. F. (Eds.).
(2003). The Description Logic Handbook: Theory, Implementation, and Applications.
Cambridge University Press.
Bao, J., Caragea, D., & Honavar, V. (2006). On the semantics of linking and importing in
modular ontologies. In Proceedings of the 5th International Semantic Web Conference
(ISWC-2006), Athens, GA, USA, November 5-9, 2006, Vol. 4273 of Lecture Notes in
Computer Science, pp. 7286.
Borger, E., Gradel, E., & Gurevich, Y. (1997). The Classical Decision Problem. Perspectives
of Mathematical Logic. Springer-Verlag. Second printing (Universitext) 2001.
Borgida, A., & Serafini, L. (2003). Distributed description logics: Assimilating information
from peer sources. J. Data Semantics, 1, 153184.
Cuenca Grau, B., Horrocks, I., Kazakov, Y., & Sattler, U. (2007). A logical framework
for modularity of ontologies. In IJCAI-07, Proceedings of the Twentieth International
Joint Conference on Artificial Intelligence, Hyderabad, India, January 2007, pp. 298
304. AAAI.
Cuenca Grau, B., & Kutz, O. (2007). Modular ontology languages revisited. In Proceedings
of the Workshop on Semantic Web for Collaborative Knowledge Acquisition, Hyderabad, India, January 5, 2007.
Cuenca Grau, B., Parsia, B., & Sirin, E. (2006a). Combining OWL ontologies using Econnections. J. Web Sem., 4 (1), 4059.
Cuenca Grau, B., Parsia, B., Sirin, E., & Kalyanpur, A. (2006b). Modularity and web ontologies. In Proceedings of the Tenth International Conference on Principles of Knowledge
316

fiModular Reuse of Ontologies: Theory and Practice

Representation and Reasoning (KR-2006), Lake District of the United Kingdom, June
2-5, 2006, pp. 198209. AAAI Press.
Cuenca Grau, B., Horrocks, I., Kazakov, Y., & Sattler, U. (2007). Just the right amount:
extracting modules from ontologies. In Proceedings of the 16th International Conference on World Wide Web (WWW-2007), Banff, Alberta, Canada, May 8-12, 2007,
pp. 717726. ACM.
Cuenca Grau, B., Horrocks, I., Kutz, O., & Sattler, U. (2006). Will my ontologies fit
together?. In Proceedings of the 2006 International Workshop on Description Logics
(DL-2006), Windermere, Lake District, UK, May 30 - June 1, 2006, Vol. 189 of CEUR
Workshop Proceedings. CEUR-WS.org.
Gardiner, T., Tsarkov, D., & Horrocks, I. (2006). Framework for an automated comparison of description logic reasoners. In Proceedings of the 5th International Semantic
Web Conference (ISWC-2006), Athens, GA, USA, November 5-9, 2006, Vol. 4273 of
Lecture Notes in Computer Science, pp. 654667. Springer.
Ghilardi, S., Lutz, C., & Wolter, F. (2006). Did I damage my ontology? a case for conservative extensions in description logics. In Proceedings of the Tenth International
Conference on Principles of Knowledge Representation and Reasoning (KR-2006),
Lake District of the United Kingdom, June 2-5, 2006, pp. 187197. AAAI Press.
Horrocks, I., Patel-Schneider, P. F., & van Harmelen, F. (2003). From SHIQ and RDF to
OWL: the making of a web ontology language. J. Web Sem., 1 (1), 726.
Horrocks, I., & Sattler, U. (2005). A tableaux decision procedure for SHOIQ. In Proceedings
of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI-05),
Edinburgh, Scotland, UK, July 30-August 5, 2005, pp. 448453. Professional Book
Center.
Kalfoglou, Y., & Schorlemmer, M. (2003). Ontology mapping: The state of the art. The
Knowledge Engineering Review, 18, 131.
Kalyanpur, A., Parsia, B., Sirin, E., Cuenca Grau, B., & Hendler, J. A. (2006). Swoop: A
web ontology editing browser. J. Web Sem., 4 (2), 144153.
Lutz, C., Walther, D., & Wolter, F. (2007). Conservative extensions in expressive description
logics. In Proceedings of the Twentieth International Joint Conference on Artificial
Intelligence (IJCAI-07), Hyderabad, India, January 2007, pp. 453459. AAAI.
Lutz, C., & Wolter, F. (2007). Conservative extensions in the lightweight description logic
EL. In Proceedings of the 21st International Conference on Automated Deduction
(CADE-21), Bremen, Germany, July 17-20, 2007, Vol. 4603 of Lecture Notes in Computer Science, pp. 8499. Springer.
Moller, R., & Haarslev, V. (2003). Description logic systems. In The Description Logic
Handbook, chap. 8, pp. 282305. Cambridge University Press.
Motik, B. (2006). Reasoning in Description Logics using Resolution and Deductive
Databases. Ph.D. thesis, Univesitat Karlsruhe (TH), Karlsruhe, Germany.
Noy, N. F. (2004a). Semantic integration: A survey of ontology-based approaches. SIGMOD
Record, 33 (4), 6570.
317

fiCuenca Grau, Horrocks, Kazakov, & Sattler

Noy, N. F. (2004b). Tools for mapping and merging ontologies. In Staab, & Studer (Staab
& Studer, 2004), pp. 365384.
Noy, N., & Musen, M. (2003). The PROMPT suite: Interactive tools for ontology mapping
and merging. Int. Journal of Human-Computer Studies, Elsevier, 6 (59).
Patel-Schneider, P., Hayes, P., & Horrocks, I. (2004). Web ontology language OWL Abstract
Syntax and Semantics. W3C Recommendation.
Rector, A., & Rogers, J. (1999). Ontological issues in using a description logic to represent
medical concepts: Experience from GALEN. In IMIA WG6 Workshop, Proceedings.
Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions with complements. Artificial Intelligence, Elsevier, 48 (1), 126.
Seidenberg, J., & Rector, A. L. (2006). Web ontology segmentation: analysis, classification
and use. In Proceedings of the 15th international conference on World Wide Web
(WWW-2006), Edinburgh, Scotland, UK, May 23-26, 2006, pp. 1322. ACM.
Sirin, E., & Parsia, B. (2004). Pellet system description. In Proceedings of the 2004 International Workshop on Description Logics (DL2004), Whistler, British Columbia,
Canada, June 6-8, 2004, Vol. 104 of CEUR Workshop Proceedings. CEUR-WS.org.
Staab, S., & Studer, R. (Eds.). (2004). Handbook on Ontologies. International Handbooks
on Information Systems. Springer.
Stuckenschmidt, H., & Klein, M. (2004). Structure-based partitioning of large class hierarchies. In Proceedings of the Third International Semantic Web Conference (ISWC2004), Hiroshima, Japan, November 7-11, 2004, Vol. 3298 of Lecture Notes in Computer Science, pp. 289303. Springer.
Tobies, S. (2000). The complexity of reasoning with cardinality restrictions and nominals
in expressive description logics. J. Artif. Intell. Res. (JAIR), 12, 199217.
Tsarkov, D., & Horrocks, I. (2006). FaCT++ description logic reasoner: System description.
In Proceedings of the Third International Joint Conference on Automated Reasoning
(IJCAR 2006), Seattle, WA, USA, August 17-20, 2006, Vol. 4130 of Lecture Notes in
Computer Science, pp. 292297. Springer.

318

fi